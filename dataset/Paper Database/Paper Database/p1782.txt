HAL Id: hal-00578550
 
 
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of scientific research documents, whether they are published or not.
The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Quantile-based optimization of Noisy Computer
Experiments with Tunable Precision
Victor Picheny, David Ginsbourger, Yann Richet, Grégory Caplin
To cite this version:
Victor Picheny, David Ginsbourger, Yann Richet, Grégory Caplin. Quantile-based optimization of
Noisy Computer Experiments with Tunable Precision. 2012. ￿hal-00578550v3￿
Quantile-Based Optimization of Noisy
Computer Experiments with Tunable
Victor Picheny
42 Avenue Gaspard Coriolis, 31057 Toulouse, France
phone: +33 (0)5 61 19 30 99; email: 
David Ginsbourger
Departement of Mathematics and Statistics, University of Bern
Alpeneggstrasse 22, 3012 Bern, Switzerland
phone: +41 (0)31 631 54 62; email: 
Yann Richet
Institut de Radioprotection et de Sˆuret´e Nucl´eaire
31 avenue de la Division Leclerc, 92260 Fontenay-aux-Roses, France
phone: +33 (0)1 58 35 88 84;email: 
Gregory Caplin
Institut de Radioprotection et de Sˆuret´e Nucl´eaire
31 avenue de la Division Leclerc, 92260 Fontenay-aux-Roses, France
phone: +33 (0)1 58 35 90 08; email: 
This article addresses the issue of kriging-based optimization of stochastic simulators. Many of these simulators depend on factors that tune the level of precision of
the response, the gain in accuracy being at a price of computational time. The contribution of this work is two-fold: ﬁrstly, we propose a quantile-based criterion for the
sequential design of experiments, in the fashion of the classical Expected Improvement
criterion, which allows an elegant treatment of heterogeneous response precisions. Secondly, we present a procedure for the allocation of the computational time given to each
measurement, allowing a better distribution of the computational eﬀort and increased
eﬃciency. Finally, the optimization method is applied to an original application in
nuclear criticality safety. This article has supplementary material online.
Keywords: Kriging, Expected Improvement, stochastic simulators.
technometrics tex template (do not remove)
INTRODUCTION
Using metamodels for facilitating optimization and statistical analysis of computationally
expensive simulators has become commonplace. In particular, the kriging-based Eﬃcient
Global Optimization (EGO) algorithm has been recognized as an eﬃcient tool for deterministic black-box optimization.
The way a simulator response follows the function of interest is called ﬁdelity. Oftentimes,
a large range of response ﬁdelities is available by tuning factors that control the complexity
of numerical methods. For instance, the precision of a ﬁnite element analysis can be controlled by the discretization technique or the solver convergence. When the response stems
from Monte Carlo methods (which are often referred to as stochastic simulators), accuracy
(measured by the inverse of the response variance) is proportional to sample size.
simulators are often called noisy simulators, since they return approximate solutions that
depart from the exact value by an error term that can be considered as a random quantity.
In an optimization context, having noise in the responses requires a proper adaptation of
criteria and algorithms. Furthermore, for each simulation run, the user has to set a trade-oﬀ
between computational cost and response precision. This additional degree of freedom may
greatly improve the eﬃciency of the optimization, but requires appropriate tools to choose
this trade-oﬀand the ability to work with heterogeneous precisions.
Using metamodels for noisy optimization has been addressed by several authors. Huang,
Allen, Notz and Zeng and Forrester, Keane and Bressloﬀ proposed krigingbased strategies for optimization of uniformly noisy functions.
However, little work can
be found in the case of heterogeneous noise. Most approaches combining optimization and
variable precision are found in the multiﬁdelity framework , but consider only two ﬁdelity levels, the
low-ﬁdelity model being used as a helping tool to choose the high-ﬁdelity evaluations.
This article proposes two contributions to this framework. First, we deﬁne an extension
of EI based on quantiles that enables an elegant treatment of both continuous or discrete
ﬁdelities. The proposed criterion not only depends on the noise variances from the past, but
also on the ﬁdelity of the new candidate measurement. Second, we study a procedure taking
advantage of the possibility to choose the ﬁdelity level at each iteration.
In the next section, we deﬁne the “noisy” framework we are considering and present brieﬂy
the kriging model. Section 3 describes the classical kriging-based optimization procedure,
and its limitation with noisy functions. In Section 4, we propose a new inﬁll criterion, called
Expected Quantile Improvement (EQI), well-suited for the noisy framework, and in Section
5 we propose a numerical trick for tuning one of the EQI parameters to account for ﬁnite
computational budgets. Section 6 describes a procedure for on-line decision on precision
level. Finally, this procedure is compared to existing kriging-based methods, and applied to
an original application in nuclear criticality safety.
NOTATIONS AND CONCEPTS
The noisy optimization problem
We consider a single objective, unconstrained minimization problem over a compact set D.
The deterministic objective function y : x ∈D ⊂Rd −→y(x) ∈R is here observed with
noise, that is, the user only has access to measurements of the form eyi = y(xi) + ǫi, where ǫi
is assumed to be one realization of a “noise” random variable ε. In the rest of this article,
we make the assumption that the observation noises are normally distributed, centered and
independent from one run to each other: εi ∼N (0, τ 2
i ) independently.
Noise in computer experiments
In classical experiments, noise usually accounts for a large number of uncontrolled variables
(variations of the experimental setup, measurement precision, etc.). In computer experiments, noise can have many sources, including modeling and discretization error, incomplete
convergence, and ﬁnite sample size for Monte-Carlo methods, see for instance Forrester,
Keane and Bressloﬀ or Gramacy and Lee for a detailed discussion.
The nature of the noise depends on the associated simulator. When classical Monte-
Carlo simulations are involved in the output evaluation, error is independent from one run
to each other, even for measurements with the same input variables. Such simulators are
often referred to as stochastic, and are the main target for the method presented here. The
industrial application described in Section 7.2 belongs to this category.
Errors due to a simpliﬁcation of the physics, geometry, or meshing, tend to show strong
correlations, especially for simulations with similar ﬁdelities, and repeated experiments provide the same observations. This situation has been addressed in the multi-ﬁdelity literature
 and Qian and Wu for modeling, Forrester et al.
 and Huang et al. for optimization) and is not considered here, although many
of the concepts presented here may apply with a proper adaptation of the kriging model.
Error due to incomplete convergence can be either treated as correlated noise or not. In
Forrester, Bressloﬀand Keane , it is observed that simulations tend to converge in
unison, which makes the partial convergence equivalent to a multi-ﬁdelity problem. However, when the output convergence behavior varies substantially across the design space, the
hypothesis of independence of the error between runs may become reasonable, especially if
experiments are well spread in the design space and diﬀerent convergence levels are used.
Experiments with tunable precision
As mentioned in the introduction, the precision of many simulators can be tuned by the
user, for instance by changing the number of solver steps for incomplete convergence or the
sample size for Monte-Carlo methods. Here, we consider that, for every measurement, the
noise variance τ 2
i = τ(ti) is a monotonically decreasing function of computation time ti.
A perhaps “canonical” example of tunable precision is when the response considered is
obtained by averaging an arbitrary number bi of independent drawings (which is a typical
situation in the framework of robust optimization for instance):
y(xi) + εi,j,
when εi,j ∼N (0, ν2). We have then eYi ∼N
, so τ 2(t) = ρν2/t, ρ being the time
needed for a single drawing. The value of bi chosen by the user tunes the precision of eYi.
In this work, we make two strong assumptions: (a) the computation time, and hence the
error variance, is controllable, and (b) the function τ(t) is accurately known. Although some
stochastic simulators, such as the one described in Section 7.2, directly provide an accurate
estimate of the output uncertainty, in most real applications a learning study is necessary,
typically assuming a (simple) parametric form for the variance. In the case of Monte-Carlo
simulators and assuming small variations of the output across the design space, we have
τ 2(t) = C/t, where C is an unknown constant which can be estimated when building the
kriging model, as described in Section 2.4.
Finally, for simulators relying on Monte Carlo or on iterative solvers, the response corresponding to a given precision is not obtained directly but more as a limit of intermediate
responses of lower precisions. For each measurement, the noisy response eyi is thus obtained
as last term of a sequence of measurements eyi , . . ., eyi[bi], where bi ∈N is the number of
calculation steps at the ith measurement.
Figure 1 represents two examples of response convergence. First, the convergence of the
output of the stochastic simulator of Section 7.2 is drawn for its nominal design values. Here,
the variance is known accurately, and depicted by the 95% conﬁdence interval. The curve
ytilde represents the sequence ey[j], j = 1 . . . 100. The second ﬁgure is taken from Forrester,
Bressloﬀand Keane and represents the convergence of an objective function (namely
the L/D ratio) calculated using an Euler simulation of an aerofoil, as a function of the number
of solver steps. The response oscillates around its ﬁnal value with decreasing amplitude.
Here, error variance is not available directly and requires the speciﬁcation of and inferences
for a parametric model for τ based on a couple of trial responses such as this one.
Time increments
Figure 1: Examples of tunable precision responses.
Left: convergence of the output of
MORET for its nominal design values; right: partially converged response of a CFD code.
The Kriging metamodel
In this work, we use a (generalized) Gaussian Process regression model , chapter 2), where y is assumed to be one realization of a random process
Y with an unknown constant trend µ ∈R, and a stationary covariance kernel k, i.e. of the
form k : (x, x′) ∈D2 −→k(x, x′) = σ2r(x −x′; ψ) for some admissible correlation function
r with parameters ψ. Provided that the process Y and the Gaussian measurement errors
εi are stochastically independent and that the error variances are given, the distribution of
Y (x) conditional on the event f
An = {Y (xi) + εi = eyi, 1 ≤i ≤n} is:
An ∼N (mn(x), s2
where mn(.) and s2
n(.) are respectively the kriging mean and variance, given by:
bµn + kn(x)T(Kn + ∆n)−1(eyn −bµn1n),
σ2 −kn(x)T(Kn + ∆n)−1kn(x) +
n(Kn + ∆n)−1kn(x)
1Tn(Kn + ∆n)−11n
with σ2 = k(x, x), eyn = (ey1, . . . , eyn)T, Kn = (k(xi, xj))1≤i,j≤n, kn(x) = (k(x, x1), . . . , k(x, xn))T,
∆n is a diagonal matrix of diagonal terms τ 2
1 . . . τ 2
n, 1n is a n × 1 vector of ones, and
n(Kn + ∆n)−1eyn/1T
n(Kn + ∆n)−11n is the best linear unbiased estimate of µ.
As for a classical kriging model, the covariance parameters σ2 and ψ usually need to
be estimated, using maximum likelihood (ML) for instance and considering the noise variances as known. If the noise variances are not known but a simple parametric functional
relashionship is assumed between the τ 2
i ’s and the ti’s, the corresponding parameters may be
embedded within the ML procedure. For instance, assuming a Monte-Carlo-type behavior
of the form τ 2
i = C/ti, the likelihood would depend on C through ∆n and bµn.
KRIGING-BASED OPTIMIZATION; LIMITATIONS WITH NOISY FUNCTIONS
The EGO algorithm builds a sequential design with the goal of ﬁnding a
global minimum of a black-box function. It consists in sequentially evaluating y at a point
maximizing a ﬁgure of merit relying on Kriging, the Expected Improvement criterion (EI),
and updating the metamodel after each new observation.
In the noiseless case, with yi = y(xi) (1 ≤i ≤n), yn = (y1, . . ., yn)T, Xn = {x1, . . ., xn}
and An denoting the event Y (Xn) = yn, the improvement provided by sampling at x is
deﬁned by I = max (0, min (Y (Xn)) −Y (x)), and the EI is its expectation given by the GP
EIn(x) := E
(min(Y (Xn)) −Y (x))+ |An
(min(yn) −Y (x))+ |An
An integration by parts yields the well-known analytical expression:
EIn(x) := (min(yn) −mn(x)) Φ
min(yn) −mn(x)
min(yn) −mn(x)
where Φ and φ are respectively the cumulative distribution function and the probability
density function of the standard Gaussian law. The latter analytical expression is very convenient since it allows fast evaluations of EI, and even analytical calculation of its gradient.
Now, in the context of noisy evaluations, (5) is not very satisfactory for at least two
reasons. Firstly, the current minimum min(Y (Xn)) is not deterministically known conditionally on the noisy observations, unlike the noiseless case. Secondly, the EI is based on the
improvement produced by a deterministic evaluation of y at the candidate point x. Now, if
the next evaluation is noisy, Y (x) will remain inexactly known. It would hence beneﬁt from
a new criterion taking the precision of the next measurement into account.
In Huang et al. , a heuristic modiﬁcation of the EI called Augmented Expected
Improvement (AEI) is proposed for uniformly noisy observations. The mean predictor at
the training point with smallest kriging quantile is used as a surrogate value for min(Y (Xn)),
and the EI is multiplied by a penalization function 1 −
s2n(x)+τ 2 to limit replications.
A more rigorous alternative, as noted in Gramacy and Lee and Gramacy and Polson , consists of computing the EI based on the joint distribution of (min(Y (Xn)), Y (x))
conditional on f
An; however, in this form the EI must be estimated by expensive Monte-Carlo
simulations, which makes the EI maximization challenging.
Finally, the Integrated Expected Conditional Improvement (IECI), proposed in Gramacy
and Lee , evaluates by how much a candidate measurement at a given point would
aﬀect the expected improvement over the design space, thereby naturally taking past and
future noises into account. However, this criterion requires a numerical integration over the
design space, which can be time-consuming, especially in high dimensions.
The next section presents a class of criteria (indexed by a parameter β tuning a quantile
level) that takes into account past and future noises with transparent probabilistic foundations, and which can be derived analytically as a function of the future point and its
associated noise level.
EXPECTED QUANTILE IMPROVEMENT
Our aim is to get a kriging-based optimization criterion measuring which level of improvement can be statistically expected from evaluating y at a new x with a noise of given variance
τ 2. A ﬁrst question to be addressed is of decision-theoretic nature: what does the term “improvement” mean when comparing two sets of noisy observations? What criterion should
be used to judge that a set of noisy observations, or the associated metamodel, is better (in
terms of minimization) after the (n + 1)th measurement than before it?
Using only the noisy observations f
yn and eyn+1 is a highly risky strategy, since the noise
may introduce errors in the ranking of the observations. Here we propose to use the βquantiles given by the Kriging conditional distribution, for a given level β ∈[0.5, 1): a point
is declared “best” over a set of candidates Xn whenever it has the lowest β-quantile:
x∗= argminx∈Xn [qn (x)] = argminx∈Xn
mn (x) + Φ−1(β)sn (x)
This is the criterion also considered by Huang et al. .
Now, we propose to deﬁne an improvement that is consistent with our decision criterion:
we deﬁne improvement I to be the decrease of the lowest β-quantile, between the present
step n and the forthcoming step n + 1:
 min (qn (Xn)) −qn+1
Of course, like in the noiseless case, this improvement cannot be known in advance, because qn+1 (xn+1) depends on the future observation ˜yn+1. However, thanks to the particular
form of the kriging equations, the future quantile qn+1 can be predicted, and consequently
the EI calculated, based on the GP model at step n, as we show below.
In our improvement (8), we restrict attention to the observed points (Xn and xn+1), even
though a similar criterion could be deﬁned over the entire design space:
I = (minD (qn (x)) −minD (qn+1 (x)))+. However, such a restriction allows simpliﬁcation,
yielding a criterion in closed form.
Let us denote by Qi(x) the kriging quantile qi(x) (i ≤n + 1) where the measurements
are still in their random form, and deﬁne the Expected Quantile Improvement (EQI) as:
EQIn(xn+1, τ 2
i≤n (Qn(xi)) −Qn+1(xn+1)
where the dependence on the future noise τ 2
n+1 appears through Qn+1(x)’s distribution.
The randomness of Qn+1(x) conditional on f
An is indeed a consequence from g
Y (xn+1) + εn+1 having not been observed yet at step n. However, following the fact that
An is Gaussian with known mean and variance, one can show that Qn+1(.) is a GP
conditional on f
An (see proof and details in appendix).
Furthermore, mini≤n(Qn(xi)) is
known conditional on f
An. As a result, the proposed EQI is analytically tractable, and we
get by a similar calculation as in (6):
EQIn(xn+1, τ 2
 min(qn) −mQn+1
min(qn) −mQn+1
min(qn) −mQn+1
where qn := {qn(xi), i ≤n} is the set of current quantile values at the already visited points,
mQn+1 := E[Qn+1(xn+1)|f
An] is Qn+1(xn+1)’s conditional expectation —seen from step n, and
Qn+1 := V ar[Qn+1(xn+1)|f
An] is its conditional variance, both derived in appendix.
Properties
The EQI criterion has the following important properties:
- in absence of future noise (τ 2
n+1 = 0), the future quantile at xn+1 coincides with the
observation ˜yn+1 = y(xn+1); it follows directly that Qn+1(xn+1)|f
An = Yn+1|f
An, so the EQI
is equal to the classical EI with a plugin of the kriging quantiles for min(yn)
- in absence of past noise (for the n ﬁrst observations), min(qn) is equal to the minimum
of the observations, min(yn)
- in absence of both past and future noise, the EQI is then equal to the classical EI.
The parameter β tunes the level of reliability wanted on the ﬁnal result ). With β = 0.5, the design points are compared based on the kriging
mean predictor only, without taking into account the prediction variance at those points,
while high values of β (i.e. near to 1) penalize designs with high uncertainty, which is a
more conservative approach.
Hence, with a high β, the criterion is more likely to favor
observation repetitions or clustering, in order to locally decrease the prediction variance,
while with β = 0.5, the criterion can be expected to be more exploratory.
The future noise τ 2
n+1 also strongly aﬀects the shape of the EQI. Indeed, a very noisy
future observation can only have a very limited inﬂuence on the kriging model. Then, the
only way to get a non-zero improvement is either to sample where qn(x) is minimum if this
point is not in Xn (the lowest quantile will then be chosen on the set Xn+1 instead of Xn,
which will bring an improvement even if qn+1 = qn), or to sample at the current best point,
which may decrease its uncertainty and brings a small but measurable improvement. On the
contrary, if τ 2
n+1 is very small, the EQI behaves like the classical EI, making the well-known
trade-oﬀbetween exploration and exploitation.
Figure 2 illustrates the dependence of the EQI on both τ 2
n+1 and β. The actual function
+ 3x3cos(5x) + 10(x −0.5)2 −0.6
, the initial design consists of ﬁve
equally-spaced measurements, with noise variances equal to 0.02.
Kriging and actual function
EQI with β = 0.9
EQI with β = 0.5
Figure 2: Actual function, kriging, and corresponding EQI for three future noise levels and
two quantile levels. The bars of the upper graph show the noise amplitude (±2 × τi).
We can see that the choice of the future noise level has a substantial inﬂuence on the
criterion. With small noise variance, the EQI behaves like the classical EI, with highest values
in regions with high uncertainty and low mean predictions. With higher noise variances and
high quantiles, the criterion becomes very conservative since is it high only in the vicinity
of existing measurements.
With β = 0.5, the EQI is high even for the largest variance.
However, here ﬁve curves out of six return similar optimal locations (i.e. x near 0.4 or 0.6),
which indicates that the inﬂuence of τ and β may not be critical during the ﬁrst optimization
EQI as a function of computational time
EQI measures the eﬀect of a new measurement with variance τ 2
n+1, while we deﬁned in Section
2 a measurement at location xi as depending on a computational time ti. In our framework
of tunable precision, two cases have to be distinguished. Let tn+1 be the computational time
used at iteration n + 1. At unsampled locations, the EQI criterion is simply evaluated with
n+1 = τ 2(tn+1). At existing observations, a diﬀerent value has to be used; if not, the EQI
would estimate the value of a new measurement with variance τ 2(tn+1), instead of estimating
the value of improving the existing measurement. To compute this value, we use the fact
that it is equivalent for the kriging model to have several measurements at the same point
with independent noises or a single equivalent measurement which is the weighted average
of the observations (see supplementary material for proof). For instance, let eyi,1 and eyi,2 be
two measurements with noise levels τ 2
i,1 and τ 2
i,2 respectively. They are equivalent to
eyi,eq = τ −2
i,1 eyi,1 + τ −2
i,1 + τ −2
with variance τ 2
i,eq the harmonic mean of τ 2
i,1 and τ 2
i,2, namely:
Now, we want to measure the eﬀect of improving a measurement with initial error variance
τ 2(ti) until the variance τ 2(ti + tn+1) is reached. This is equivalent, in terms of the kriging
model, to taking a new measurement with noise variance:
τ 2(ti →ti + tn+1) :=
τ 2(ti)τ 2(ti + tn+1)
τ 2(ti) −τ 2(ti + tn+1).
This formula is obtained from (12), with τ 2
i,eq = τ 2(ti + tn+1), τ 2
i,1 = τ 2(ti) and τ 2
i,2 = τ 2(ti →
ti + tn+1). Hence, at xi, EQI may be evaluated with τ 2
n+1 = τ 2(ti →ti + tn+1).
The next section proposes a numerical trick for tuning tn+1 to account for ﬁnite computational budgets.
OPTIMIZATION WITH FINITE COMPUTATIONAL BUDGET
It is well-known that the EGO algorithm is a so-called myopic strategy, since its criterion EI
always considers the next step as if it were the last one. However, for most computer experiments, the total computational budget is bounded, and prescribed by industrial constraints
such as time and power limitations. In the deterministic framework, this results in a limited
(given) number of observations for optimization. It has been shown followed
by Ginsbourger and Le Riche ) that taking into account the ﬁnite budget may modify
the optimization strategy and improve signiﬁcantly its eﬃciency.
Here, the concept of ﬁnite budget is particularly critical, since each observation requires a
trade-oﬀbetween accuracy and rapidity, and in general, the user has to trade oﬀbetween the
total number of observations and their precision. In linear modeling, this problem is typical
of the theory of optimal designs , with the notable diﬀerence that
we face it here within a sequential strategy, and a non-linear (kriging) model.
The computational constraint implies that the sum of all computational times is ﬁxed to a
given budget, say T0. At step n, the remaining budget for optimization is Tn+1 = T0−Pn
The EQI criterion allows taking into account such computational budget in the choice of
the new candidate observations. Indeed, the future noise level τ 2
n+1, which is a parameter of
EQI, will stand here for the ﬁnite budget. Given a computational budget Tn+1, the smallest
noise variance achievable (i.e. the largest precision) for a new measurement is τ 2(Tn+1),
and τ 2(ti →ti + Tn+1) at xi (1 ≤i ≤n), assuming that all the remaining budget will be
attributed to this measurement. Note that in the course of the optimization process, the
remaining budget decreases, so τ 2 (Tn+1) (respectively τ 2(ti →ti + Tn+1)) increases with n.
Then, we propose to set τ 2
n+1 = τ 2(Tn+1) (resp. τ 2(ti →ti+Tn+1)) for the EQI calculation,
meaning that the EQI will measure the potential improvement if all the remaining budget
would be attributed to the next observation. Of course, the actual budget tn+1 for the next
observation may be a lot smaller than Tn+1 so the optimization does not stop after one step.
With this setting, the new experiment is chosen knowing that even if all the budget was used
for a single observation, its noise variance would not decrease below a certain value.
Consequently, the EQI will behave diﬀerently at the beginning and at the end of the
optimization.
When the budget is high, EQI will tendencially be higher in unexplored
regions, since it is where accurate measurements are likely to be most eﬃcient (the EQI will
actually be almost similar to a classical EI). At the end of the optimization, however, when
the remaining time is small, the EQI will be small in unexplored regions since even if the
actual function is low, there is not enough computational time to obtain a lower quantile
than the current best one. In that case, the EQI will be highest close to or at the current
best point(s) and favor local search.
ALLOCATION OF RESOURCE
This section proposes two algorithmic schemes based on EQI. First, the baseline approach
is described, where a ﬁxed time is allocated at each iteration; then, a strategy is proposed
to take advantage of the response convergence monitoring to dynamically adapt the budget
to each measurement.
Constant allocation
First, we assume that the computational budget T0 can be divided in elementary time steps
te, so that T0 = N × te. An elementary step can correspond to a given number of solver
iterations for partial convergence, or to a number of drawings for stochastic simulators. An
algorithm with constant allocation will then proceed to attribute each of the N elementary
time steps to either generate new measurements or improve accuracy on existing ones.
At step n, a budget n × te < T0 as already been spent on the measurements, so Tn+1 =
T0 −n × te. The EQI criterion is maximized over D with τ 2
n+1 = τ 2(Tn+1) at unsampled
locations and τ 2
n+1 = τ 2(ti →ti +Tn+1) at xi (1 ≤i ≤n). Once the new point xn+1 is chosen
and the measurement is made, the kriging model has to be updated, by either adding xn+1
to Xn if xn+1 /∈Xn or by replacing the previous values of eyi[bi] and τ 2
i [bi] by eyi[bi + 1] and
i [bi + 1], respectively, in the kriging equations.
The trade-oﬀbetween precision and number of measurements is here determined by EQI,
depending if it is maximum at a sampled or an unsampled design. Taking the ﬁnite budget
into account aﬀects the trade-oﬀ, since with large budget it is more exploratory, hence likely
to be maximum at unsampled points, while with small budget it is more likely to be maximal
at existing points (see Figure 2, EQI with β = 0.9 and τ 2 = 0.1 or 0.01).
Note that this procedure allows the (closely related) problem of optimization of a homogeneously noisy function to be addressed, considering that each observation requires a
constant time te, and has a constant noise variance ν2. At each optimization step, the user
has the option of either sampling at a new location or duplicating an existing measurement,
so allocating all the remaining budget to a measurement means performing N −n replications at this point, hence leading to the situation described in Section 2.3 (equation 1). In
that case, it is straightforward to get τ 2(ti →ti + Tn+1) =
N−n = τ 2(Tn+1), so the criterion is written similarly at sampled and unsampled locations. Thus, in this framework, the
procedure simpliﬁes to maximizing at each step EQIn(.,
On-line allocation
The constant allocation strategy of the previous section performs N −n0 EGO iterations,
and each requires the running of an inner optimization loop for the maximization of the
EQI, which can be very time-consuming. Hence, the elementary time step te must be chosen
to be large enough to limit the number of EQI optimizations (otherwise choosing the next
measurement could take more time than performing it!). Typically, with partial convergence
or stochastic simulators, te must be chosen to be much larger than a single solver iteration
or drawing, respectively. This limitation can greatly hinder the ﬂexibility and potential of
tunable precision, since it reduces the possibilities of a quasi-continuum of ﬁdelities to a few
discrete precision levels.
Here, we propose a heuristic for dynamically choosing the computational resource given
to an experiment. A simple way to do so is to monitor the evolution of the EQI at the
current observation point. Indeed, instead of maximizing the EQI after each te is spent,
we will choose an observation point, and allocate several time steps on it until a criterion is
met. As for the constant allocation case, the EQI is updated after each step, by replacing the
previous values of response and noise eyi[bi] and τ 2
i [bi] by eyi[bi + 1] and τ 2
i [bi + 1], respectively,
in the kriging equations, and by replacing the future noise level τ 2(ti →ti + Tn+1) by
τ 2(ti + te →ti + Tn+1 −te).
By construction, the updated EQI tends to decrease when computation time is added,
since (a) the kriging uncertainty reduces at the observation point, and (b) EQI decreases
when τ 2(ti →ti + Tn+1) increases. However, if the measurement converges to a good (small)
value, EQI can increase temporarily. Conversely, if the measurement converges to a high
value, EQI decreases faster. Hence, we can deﬁne a (“point switching”) stopping criterion
for resource allocation based on EQI. If the EQI decreases below a certain value, carrying on
the calculations is not likely to help the optimization, so the observation process should stop
and another point should be chosen. Here, we propose the interruption of a measurement
and search for a new point when the current value of the EQI is less than a proportion of
the initial EQI value (that is, the value of EQI when starting the measurement process at
that point), for instance 50%.
The sequence of this new procedure is as follows: ﬁrst, ﬁnd xn+1 = argmaxx∈D(EQI(x), τ 2(Tn+1)),
store the corresponding value EQI(xn+1), τ 2(Tn+1)) as reference, and then invest elementary
measurements at this point until the EQI with updated data falls under a given proportion
γ ∈]0, 1[ of the reference value.
The operation of choosing the most promising point is
then started again, and so on until the total computational budget has been spent. Note
that the ﬁnal number of measurements and EQI maximizations are not determined beforehand but adapts automatically to the budget and resource distribution, and may be a lot
smaller than the number of steps N (especially with small γ). The algorithm is presented
in pseudo-code form in Table 1. For conciseness, this algorithm does not consider the case
where xn+1 ∈Xn, which requires diﬀerent treatement, as in Section 6.1. In the examples in
Section 7, xn+1 ∈Xn is considered.
EXPERIMENTS
Comparison to the Augmented Expected Improvement (AEI) procedure
The strategy proposed in Section 6.2 is compared to the AEI method as proposed in Huang
et al. for the optimization of homogeneously noisy experiments, which has already
been found to be very competitive compared to other local or global optimizers such as the
revised simplex search or DIRECT . Both EQI and AEI heuristics are compared to the classical EI, using a noisy kriging
model (as in Section 2.4) and with the minimal value of the observations replaced by the
minimum of the kriging mean at the observations, which can be considered as the baseline
approach. As test problems, we employed two analytical benchmark problems, the d = 6
dimensional Hartman function and the d = 5 dimensional Ackley
Table 1: EQI algorithm with on-line resource allocation
- Build initial design Xn0, generate observations eyn0 using Tn0 computational time, ﬁt kriging model
- Set n = n0 and Tn = T0 −Tn0
while Tn > 0
- Choose new design point xn+1 that maximizes EQIn
 ., τ 2(Tn)
- Generate eyn+1 with one time increment on xn+1
- Augment design and response: Xn+1 =
, (eyn+1)T =
- Update kriging with Xn+1, eyn+1 and τ 2
n+1 = τ 2(te)
- Set Tn+1 = Tn −te, j = 1, and tn+1 = te
while EQIn+1
 xn+1, τ 2(tn+1 →tn+1 + Tn+1)
 xn+1, τ 2(Tn)
- Improve measurement: generate eyn+1[j + 1] by adding one time increment
- Replace eyn+1[j] by eyn+1[j + 1] in eyn+1, set τ 2
n+1 = τ 2(tn+1 + te) and update kriging
- Set Tn+1 = Tn+1 −te, j = j + 1, and tn+1 = tn+1 + te
- Set n = n + 1
function .
aji (xj −pji)2




y(x) = −20 exp
+ 20 + exp(1) (15)
Both functions are normalized so their design region D is d and their standard deviation is 1.0 over D. Their minima are zero for Ackley and -1.94 for Hartman. Gaussian noise
ǫ ∼N (0, 10τ 2) is added to the analytical functions. An ordinary kriging model (constant
trend) with Matern 5/2 anisotropic covariance function is used for both functions.
In order to model a tunable ﬁdelity framework while allowing a fair comparison between
methods, each noisy measurement ˜yi is taken as the average of several function evaluations
as described in Section 2.3. For the AEI procedure, which is designed for homoscedastic
noise, ten time steps are used for each observation, so the noise variance is τ 2. For the EQI
procedure, the noise variance potentially varies between 10τ 2 and 10τ 2/T0.
For both methods, the initial design sets are chosen as LHS designs with maximin criterion, and are generated using ten time steps for each observation. The total optimization
budget is chosen to be equal to two times the budget needed to generate the initial design
set. Two versions of EQI are tested, with β = 0.5 (decision based on kriging mean only) and
with β = 0.9; the criteria are referred to as EQI.50 and EQI.90, respectively.
Several budgets, noise levels and initial design sizes are tested. The diﬀerent conﬁgurations are summarized in Table 2. The noise level τ can be compared to objective function
standard deviation (SD), which is one for both functions. With τ = 0.2, the optimization
problem can be considered as very noisy. The total budget is deliberately chosen to be very
small since it may correspond to typical situations in real-life applications.
For each conﬁguration, 40 initial designs and observations are generated to account for
randomness in the LHS designs and the observations. The kriging parameters are estimated
only at the initial step, using the R package DiceKriging , so all the methods use the same models. Sequential parameter re-estimation is not
done here (even though it might result in better precision) so the algorithms can be compared
in terms of kriging variance or quantile.
Table 2: Summary of the test problem conﬁgurations
Initial design size n0
1000 steps
1200 steps
The current minimizer for AEI or EQI.90 is x∗= argmin1≤i≤nqn(xi), and argmin1≤i≤nmn(xi)
for EQI.50 or EI. The optimization performances are compared based on y(x∗) (actual value
at x∗) and sn(x∗) (kriging SD), which are represented using boxplots on Figure 3.
Kriging SD
Kriging SD
Kriging SD
Figure 3: Boxplots of actual value (y) and kriging standard deviation (sn) at x∗for the
diﬀerent methods on 1) the Ackley function with τ = 0.05 and 500 steps, 2) the Ackley
function with τ = 0.2 and 1000 steps, 3) the Hartman function τ = 0.2 and 1200 steps.
For the Ackley function, with τ = 0.05, EQI outperforms AEI in terms of actual value and
kriging uncertainty at x∗. The choice of β = 0.5 provides the best results. With τ = 0.2, AEI
provides the best results in terms of optimization (y(x∗)). However, sn(x∗) is signiﬁcantly
lower for EQI.90 than for the other methods, which illustrates the tendency of this method
to reduce uncertainty at the expense of exploration.
For the Hartman function, EQI slightly outperforms the two other methods in terms of
y(x∗). In terms of kriging uncertainty, EI and AEI are clearly less eﬃcient than EQI. The
diﬀerence between the strategies β = 0.5 and β = 0.9 appear clearly; indeed, with β = 0.5,
the choice of the best design is made on the kriging mean only; on the other hand, with
β = 0.9, observations with high uncertainty are penalized so that sn(x∗) is always small.
Table 3 shows the average number of distinct measurements and the average number
of time steps at x∗. Even though EI and AEI use uniform allocation, their values are not
constant because some measurements are repeated (i.e.
criteria are maximal at existing
measurements during optimization). For instance, the ﬁrst row and last column of the table
indicates that for EI, there is on average four repeated measurements at x∗.
For the small budget and small noise on the Ackley function, the online allocation of
Section 6.2 resulted with more measurements than for AEI and EI. Here, online allocation
was used to improve exploration by having more measurement locations and resulted in
better performance in terms of y(x∗) (see Figure 3). On the contrary, for the large budget
and large noise, it resulted in accurate measurements at x∗to the detriment of exploration.
For the Hartman function, the number of measurements is almost equivalent for all methods.
It is interesting to note that for the Ackley function with τ = 0.05 and the Hartman
function, the average number of time steps at x∗is smaller for EQI than for EI and AEI
but sn(x∗) is also smaller (Figure 3), which is counter-intuitive. For EQI, the small sn(x∗)
is obtained because the measurements form a cluster around x∗.
Table 3: Computational time allocation during optimization
Conﬁguration
Nb of distinct measurements
Time steps at x∗
(Function, Initial design, Budget, τ)
Ackley, 25 points, 500 steps, 0.05
Ackley, 50 points, 1000 steps, 0.2
Hartman, 60 points, 1200 steps, 0.2
Application to a 2D benchmark from nuclear criticality safety assessments
In this section, the optimization algorithm is applied to the problem of safety assessment
of a nuclear system involving ﬁssile materials. The benchmark system used is an interim
storage of dry PuO2 powder into a regular array of storage tubes. The criticality safety
of this system is evaluated through the neutron multiplication factor (called k-eﬀective or
keﬀ), which models the nuclear chain reaction trend: keﬀ> 1 implies an increasing neutron
production leading to an uncontrolled chain reaction, and keﬀ< 1 is the safety state required
for fuel storage.
The neutron multiplication factor depends on many parameters such as the composition
of ﬁssile materials, operation conditions, geometry, etc. For a given set of parameters, the
value of keﬀcan be evaluated using the MORET stochastic simulator , which is based on Markov Chain Monte-Carlo (MCMC)
simulation techniques. The precision of the evaluation depends on the amount of simulated
particles (neutrons), which is tunable by the user.
When assessing the safety of a system, one has to ensure that, given a set of admissible
values D for the parameters x, there are no physical conditions under which the keﬀcan reach
the critical value of one. The search for the worst combination of parameters x deﬁnes a noisy
optimization problem which is often challenging in practice, due to the high computational
expense of the simulator. An eﬃcient resolution technique for this problem is particularly
crucial since this optimization may be done numerous times.
In this article, we focus on the maximization of keﬀwith respect to two parameters, the
other possible inputs being ﬁxed to their most penalizing values (based on expert knowledge):
- d.puo2, the powder density, with original range [0.5, 4] g.cm−3, rescaled to ,
- d.water, the density of water between storage tubes, with range , which accounts
for the possible ﬂooding of the storage (leading to an interstitial moderation of the neutrons
interacting from a storage tube to another one).
Hence, to agree with previous notations, we set: x = (d.puo2, d.water), and y(x) =
−keﬀ(x). Simulation time is assumed to be proportional to the number of neutrons simulated
(the entry cost of a new simulation being neglected). Since the simulator is based on Monte-
Carlo, the variance of the keﬀestimate is exactly inversely proportional to the number of
neutrons. The variance slightly varies with input parameters, but this dependence can be
considered negligible here.
For practical considerations, the optimization space D is discretized in a 75 × 75 grid,
and for each new measurement the EQI maximization is performed by an exhaustive search
on the grid. The incremental time step te is deﬁned by the simulation of 4000 particles,
which takes about half a minute on a 3 GHz CPU. The response noise standard deviation
can take values between 5.67 × 10−2 (one time step) and 4.01 × 10−3 (200 time steps).
To evaluate the eﬃciency of our algorithm, all 5625 points of the grid have been evaluated
with high precision, which gives an accurate estimation of the shape (represented in Figure
4 A), minimal value and minimizer x∗of the function. With this accurate dataset we ﬁnd
that x∗= [0.1892, 0.0811] and f(x∗) = −0.9847.
The keﬀrange is approximately [0.3, 1.0], so with one time step, the measurement 95%
conﬁdence interval length is 4 × 0.0567 = 0.226, which is about 30% of the response range.
With 200 time steps, this length is 2% of the range. We consider a computational budget of
T0 = 100, which corresponds to a single observation with standard deviation of 5.7 × 10−3.
This can be considered as very small budget regarding the problem complexity. The initial
design consists of a 20-point random design (with optimized maximin distance), with one
time step used for each measurement (so 20% of the budget is allocated to the initial design).
The kriging ﬁt is made using the R package DiceKriging . The
chosen model has a constant trend (ordinary kriging) and Matern 5/2 anisotropic covariance
function. The covariance parameters are re-estimated after each new observation.
Figure 4 shows the contour lines of the actual response, the ﬁnal kriging (mean, standard
deviation and 90th percentile) and measurements. During optimization, 14 measurements
have been added with time steps varying from one to 36. The best design point found is
x∗= [0.189, 0.068] has a kriging standard deviation of 0.0071 and is almost equal to the
actual minimizer. Here, approximately one third of the computational budget is allocated to
˜y(x∗). The ﬁnal kriging (Figure 4 B and D) is relatively accurate, even though the standard
deviation remains high in all the regions with high response values (top left quadrant). In
the region of the optimum, the kriging 90th percentile (Figure 4 C) is almost equal to the
actual function.
CONCLUSION AND PERSPECTIVES
In this paper, we have proposed a quantile-based expected improvement for the optimization
of noisy back-box simulators. This criterion allows an elegant treatment of heterogeneous
noise and takes into account the noise level of the candidate measurements. In the context of
simulators with tunable ﬁdelity, we proposed an on-line procedure for an adapted distribution
of the computational eﬀort. One of the advantages of such procedure is that it guards against
A) Actual response
B) Kriging mean
D) Kriging SD
C) Kriging quantile
Figure 4: Optimization results for a T = 100 budget. The x-axes correspond to d.PuO2, the
y-axes to d.water. Triangles represent the inital measurements and circles the added ones;
the markers are proportional to computational time.
the allocation of too much time to poor designs, and focuses more eﬀort on the best ones.
Another remarkable property of this algorithm is that, unlike EGO, it takes into account the
limited computational budget. Indeed, the algorithm is more exploratory when there is much
budget left, and favors a more local search when resources are scarce. The online allocation
optimization algorithm was ﬁrst compared to existing methods on two analytical benchmark
functions and was found to be very competitive.
Finally, it was applied to an original
application in nuclear criticality safety, the Monte Carlo criticality simulator MORET5.
The algorithm showed promising results, using coarse measurements for exploration and
accurate measurements at best designs. Future work may include a deeper comparison of
the EQI to other criteria for point selection on an extended benchmark of test functions,
analysis of the eﬀect of on-line allocation compared to a uniform allocation strategy, and an
adaptation of the algorithm in the case of correlated errors.
ACKNOWLEDGEMENTS
This work was partially supported by French National Research Agency (ANR) through
COSINUS program (project OMD2 ANR-08-COSI-007).
SUPPLEMENTARY MATERIAL
Equivalent measurement for two noisy observations at the same point: Proof of equivalence between including two independant noisy observations at the same point in the
kriging equations and including a single equivalent observation. (pdf ﬁle)