GANomaly: Semi-Supervised Anomaly
Detection via Adversarial Training
Samet Akcay1, Amir Atapour-Abarghouei1, and Toby P. Breckon1,2
Department of {Computer Science1, Engineering2}, Durham University, UK
{ samet.akcay, amir.atapour-abarghouei, toby.breckon }@durham.ac.uk
Abstract. Anomaly detection is a classical problem in computer vision, namely the determination of the normal from the abnormal when
datasets are highly biased towards one class (normal) due to the insuﬃcient sample size of the other class (abnormal). While this can be
addressed as a supervised learning problem, a signiﬁcantly more challenging problem is that of detecting the unknown/unseen anomaly case that
takes us instead into the space of a one-class, semi-supervised learning
paradigm. We introduce such a novel anomaly detection model, by using
a conditional generative adversarial network that jointly learns the generation of high-dimensional image space and the inference of latent space.
Employing encoder-decoder-encoder sub-networks in the generator network enables the model to map the input image to a lower dimension
vector, which is then used to reconstruct the generated output image.
The use of the additional encoder network maps this generated image to
its latent representation. Minimizing the distance between these images
and the latent vectors during training aids in learning the data distribution for the normal samples. As a result, a larger distance metric from
this learned data distribution at inference time is indicative of an outlier from that distribution — an anomaly. Experimentation over several
benchmark datasets, from varying domains, shows the model eﬃcacy and
superiority over previous state-of-the-art approaches.
Keywords: Anomaly Detection · Semi-Supervised Learning · Generative Adversarial Networks · X-ray Security Imagery.
Introduction
Despite yielding encouraging performance over various computer vision tasks,
supervised approaches heavily depend on large, labeled datasets. In many of the
real world problems, however, samples from the more unusual classes of interest
are of insuﬃcient sizes to be eﬀectively modeled. Instead, the task of anomaly detection is to be able to identify such cases, by training only on samples considered
to be normal and then identifying these unusual, insuﬃciently available samples
(abnormal) that diﬀer from the learned sample distribution of normality. For
example a tangible application, that is considered here within our evaluation, is
that of X-ray screening for aviation or border security — where anomalous items
S. Akcay et al.
(a) Normal Data (X-ray Scans)
(b) Normal + Abnormal Data (X-ray Scans)
Fig. 1. Overview of our anomaly detection approach within the context of an X-ray
security screening problem. Our model is trained on normal samples (a), and tested
on normal and abnormal samples (b). Anomalies are detected when the output of the
model is greater than a certain threshold A(x) > φ.
posing a security threat are not commonly encountered, exemplary data of such
can be diﬃcult to obtain in any quantity, and the nature of any anomaly posing a potential threat may evolve due to a range of external factors. However,
within this challenging context, human security operators are still competent
and adaptable anomaly detectors against new and emerging anomalous threat
signatures.
As illustrated in Figure 1, a formal problem deﬁnition of the anomaly detection task is as follows: given a dataset D containing a large number of normal
samples X for training, and relatively few abnormal examples ˆX for the test, a
model f is optimized over its parameters θ. f learns the data distribution pX of
the normal samples during training while identifying abnormal samples as outliers during testing by outputting an anomaly score A(x), where x is a given test
example. A Larger A(x) indicates possible abnormalities within the test image
since f learns to minimize the output score during training. A(x) is general in
that it can detect unseen anomalies as being non-conforming to pX.
There is a large volume of studies proposing anomaly detection models within
various application domains . Besides, a considerable amount of work
taxonomized the approaches within the literature . In parallel to
the recent advances in this ﬁeld, Generative Adversarial Networks (GAN) have
emerged as a leading methodology across both unsupervised and semi-supervised
problems. Goodfellow et al. ﬁrst proposed this approach by co-training a
pair networks (generator and discriminator). The former network models high
dimensional data from a latent vector to resemble the source data, while the
latter distinguishes the modeled (i.e., approximated) and original data samples.
Several approaches followed this work to improve the training and inference
stages . As reviewed in , adversarial training has also been adopted by
recent work within anomaly detection.
Schlegl et al. hypothesize that the latent vector of a GAN represents
the true distribution of the data and remap to the latent vector by optimizing
a pre-trained GAN based on the latent vector. The limitation is the enormous
computational complexity of remapping to this latent vector space. In a follow-up
study, Zenati et al. train a BiGAN model , which maps from image space
to latent space jointly, and report statistically and computationally superior
results albeit on the simplistic MNIST benchmark dataset .
Motivated by , here we propose a generic anomaly detection architecture comprising an adversarial training framework. In a similar vein to ,
we use single color images as the input to our approach drawn only from an
example set of normal (non-anomalous) training examples. However, in contrast, our approach does not require two-stage training and is both eﬃcient
for model training and later inference (run-time testing). As with , we also
learn image and latent vector spaces jointly. Our key novelty comes from the
fact that we employ adversarial autoencoder within an encoder-decoder-encoder
pipeline, capturing the training data distribution within both image and latent
vector space. An adversarial training architecture such as this, practically based
on only normal training data examples, produces superior performance over
challenging benchmark problems. The main contributions of this paper are as
– semi-supervised anomaly detection — a novel adversarial autoencoder within
an encoder-decoder-encoder pipeline, capturing the training data distribution within both image and latent vector space, yielding superior results to
contemporary GAN-based and traditional autoencoder-based approaches.
– eﬃcacy — an eﬃcient and novel approach to anomaly detection that yields
both statistically and computationally better performance.
– reproducibility — simple and eﬀective algorithm such that the results could
be reproduced via the code1 made publicly available.
Related Work
Anomaly detection has long been a question of great interest in a wide range
of domains including but not limited to biomedical , ﬁnancial and security such as video surveillance , network systems and fraud detection .
Besides, a considerable amount of work has been published to taxonomize the
approaches in the literature . The narrower scope of the review
is primarily focused on reconstruction-based anomaly techniques.
The vast majority of the reconstruction-based approaches have been employed to investigate anomalies in video sequences. Sabokrou et al. investigate the use of Gaussian classiﬁers on top of autoencoders (global) and nearest
neighbor similarity (local) feature descriptors to model non-overlapping video
patches. A study by Medel and Savakis employs convolutional long shortterm memory networks for anomaly detection. Trained on normal samples only,
1 The code is available on 
S. Akcay et al.
the model predicts the future frame of possible standard example, which distinguishes the abnormality during the inference. In another study on the same
task, Hasan et al. considers a two-stage approach, using local features and
fully connected autoencoder ﬁrst, followed by fully convolutional autoencoder for
end-to-end feature extraction and classiﬁcation. Experiments yield competitive
results on anomaly detection benchmarks. To determine the eﬀects of adversarial training in anomaly detection in videos, Dimokranitou uses adversarial
autoencoders, producing a comparable performance on benchmarks.
More recent attention in the literature has been focused on the provision
of adversarial training. The seminal work of Ravanbakhsh et al. utilizes
image to image translation to examine the abnormality detection problem
in crowded scenes and achieves state-of-the-art on the benchmarks. The approach
is to train two conditional GANs. The ﬁrst generator produces optical ﬂow from
frames, while the second generates frames from optical-ﬂow.
The generalisability of the approach mentioned above is problematic since in
many cases datasets do not have temporal features. One of the most inﬂuential
accounts of anomaly detection using adversarial training comes from Schlegl et
al. . The authors hypothesize that the latent vector of the GAN represents
the distribution of the data. However, mapping to the vector space of the GAN
is not straightforward. To achieve this, the authors ﬁrst train a generator and
discriminator using only normal images. In the next stage, they utilize the pretrained generator and discriminator by freezing the weights and remap to the
latent vector by optimizing the GAN based on the z vector. During inference,
the model pinpoints an anomaly by outputting a high anomaly score, reporting
signiﬁcant improvement over the previous work. The main limitation of this work
is its computational complexity since the model employs a two-stage approach,
and remapping the latent vector is extremely expensive. In a follow-up study,
Zenati et al. investigate the use of BiGAN in an anomaly detection task,
examining joint training to map from image space to latent space simultaneously,
and vice-versa. Training the model via yields superior results on the MNIST
 dataset.
Overall prior work strongly supports the hypothesis that the use of autoencoders and GAN demonstrate promise in anomaly detection problems .
Motivated by the idea of GAN with inference studied in and , we introduce a conditional adversarial network such that generator comprises encoderdecoder-encoder sub-networks, learning representations in both image and latent
vector space jointly, and achieving state-of-the-art performance both statistically
and computationally.
Our Approach: GANomaly
To explain our approach in detail, it is essential to brieﬂy introduce the background of GAN.
Generative Adversarial Networks (GAN) are an unsupervised machine
learning algorithm that was initially introduced by Goodfellow et al. . The
Real / Fake
Input/Output
ConvTranspose
Fig. 2. Pipeline of the proposed approach for anomaly detection.
original primary goal of the work is to generate realistic images. The idea being
that two networks (generator and discriminator) compete with each other during
training such that the former tries to generate an image, while the latter decides
whether the generated image is a real or a fake. The generator is a decoderalike network that learns the distribution of input data from a latent space.
The primary objective here is to model high dimensional data that captures the
original real data distribution. The discriminator network usually has a classical
classiﬁcation architecture, reading an input image, and determining its validity
(i.e., real vs. fake).
GAN have been intensively investigated recently due to their future potential
 . To address training instability issues, several empirical methodologies have
been proposed . One well-known study that receives attention in the literature is Deep Convolutional GAN (DCGAN) by Radford and Chintala , who
introduce a fully convolutional generative network by removing fully connected
layers and using convolutional layers and batch-normalization throughout
the network. The training performance of GAN is improved further via the use
of Wasserstein loss .
Adversarial Auto-Encoders (AAE) consist of two sub-networks, namely an
encoder and a decoder. This structure maps the input to latent space and remaps
back to input data space, known as reconstruction. Training autoencoders with
adversarial setting enable not only better reconstruction but also control over
latent space. .
GAN with Inference are also used within discrimination tasks by exploiting latent space variables . For instance, the research by suggests that
networks are capable of generating a similar latent representation for related
S. Akcay et al.
high-dimensional image data. Lipton and Tripathi also investigate the idea
of inverse mapping by introducing a gradient-based approach, mapping images
back to the latent space. This has also been explored in with a speciﬁc focus
on joint training of generator and inference networks. The former network maps
from latent space to high-dimensional image space, while the latter maps from
image to latent space. Another study by Donahue et al. suggests that with
the additional use of an encoder network mapping from image space to latent
space, a vanilla GAN network is capable of learning inverse mapping.
Proposed Approach
Problem Deﬁnition. Our objective is to train an unsupervised network that
detects anomalies using a dataset that is highly biased towards a particular
class - i.e., comprising normal non-anomalous occurrences only for training. The
formal deﬁnition of this problem is as follows:
We are given a large tranining dataset D comprising only M normal images,
D = {X1, . . . , XM}, and a smaller testing dataset ˆD of N normal and abnormal
images, ˆD = {( ˆX1, y1), . . . , ( ˆXN, yN)}, where yi ∈ denotes the image label.
In the practical setting, the training set is signiﬁcantly larger than the test set
such that M ≫N.
Given the dataset, our goal is ﬁrst to model D to learn its manifold, then
detect the abnormal samples in ˆD as outliers during the inference stage. The
model f learns both the normal data distribution and minimizes the output
anomaly score A(x). For a given test image ˆx, a high anomaly score of A(ˆx))
indicates possible anomalies within the image. The evaluation criteria for this is
to threshold (φ) the score, where A(ˆx) > φ indicates anomaly.
Ganomaly Pipeline. Figure 2 illustrates the overview of our approach, which
contains two encoders, a decoder, and discriminator networks, employed within
three sub-networks.
First sub-network is a bow tie autoencoder network behaving as the generator part of the model. The generator learns the input data representation and
reconstructs the input image via the use of an encoder and a decoder network,
respectively. The formal principle of the sub-network is the following: The generator G ﬁrst reads an input image x, where x ∈Rw×h×c, and forward-passes
it to its encoder network GE. With the use of convolutional layers followed by
batch-norm and leaky ReLU() activation, respectively, GE downscales x by compressing it to a vector z, where z ∈Rd. z is also known as the bottleneck features
of G and hypothesized to have the smallest dimension containing the best representation of x. The decoder part GD of the generator network G adopts the
architecture of a DCGAN generator , using convolutional transpose layers,
ReLU() activation and batch-norm together with a tanh layer at the end. This
approach upscales the vector z to reconstruct the image x as ˆx. Based on these,
the generator network G generates image ˆx via ˆx = GD(z), where z = GE(x).
The second sub-network is the encoder network E that compresses the image ˆx that is reconstructed by the network G. With diﬀerent parametrization,
it has the same architectural details as GE. E downscales ˆx to ﬁnd its feature
representation ˆz = E(ˆx). The dimension of the vector ˆz is the same as that of
z for consistent comparison. This sub-network is one of the unique parts of the
proposed approach. Unlike the prior autoencoder-based approaches, in which the
minimization of the latent vectors is achieved via the bottleneck features, this
sub-network E explicitly learns to minimize the distance with its parametrization. During the test time, moreover, the anomaly detection is performed with
this minimization.
The third sub-network is the discriminator network D whose objective is to
classify the input x and the output ˆx as real or fake, respectively. This subnetwork is the standard discriminator network introduced in DCGAN .
Having deﬁned our overall multi-network architecture, as depicted in Figure
2, we now move on to discuss how we formulate our objective for learning.
Model Training
We hypothesize that when an abnormal image is forward-passed into the network
G, GD is not able to reconstruct the abnormalities even though GE manages to
map the input X to the latent vector z. This is because the network is modeled
only on normal samples during training and its parametrization is not suitable
for generating abnormal samples. An output ˆX that has missed abnormalities
can lead to the encoder network E mapping ˆX to a vector ˆz that has also
missed abnormal feature representation, causing dissimilarity between z and ˆz.
When there is such dissimilarity within latent vector space for an input image
X, the model classiﬁes X as an anomalous image. To validate this hypothesis,
we formulate our objective function by combining three loss functions, each of
which optimizes individual sub-networks.
Adversarial Loss. Following the current trend within the new anomaly detection approaches , we also use feature matching loss for adversarial
learning. Proposed by Salimans et al. , feature matching is shown to reduce
the instability of GAN training. Unlike the vanilla GAN where G is updated
based on the output of D (real/fake), here we update G based on the internal
representation of D. Formally, let f be a function that outputs an intermediate
layer of the discriminator D for a given input x drawn from the input data distribution pX, feature matching computes the L2 distance between the feature
representation of the original and the generated images, respectively. Hence, our
adversarial loss Ladv is deﬁned as:
Ladv = Ex∼pX∥f(x) −Ex∼pXf(G(x)∥2.
Contextual Loss. The adversarial loss Ladv is adequate to fool the discriminator D with generated samples. However, with only an adversarial loss, the
generator is not optimized towards learning contextual information about the
input data. It has been shown that penalizing the generator by measuring the
S. Akcay et al.
distance between the input and the generated images remedies this issue .
Isola et al. show that the use of L1 yields less blurry results than L2. Hence,
we also penalize G by measuring the L1 distance between the original x and the
generated images (ˆx = G(x)) using a contextual loss Lcon deﬁned as:
Lcon = Ex∼pX∥x −G(x)∥1.
Encoder Loss. The two losses introduced above can enforce the generator to
produce images that are not only realistic but also contextually sound. Moreover,
we employ an additional encoder loss Lenc to minimize the distance between the
bottleneck features of the input (z = GE(x)) and the encoded features of the
generated image (ˆz = E(G(x))). Lenc is formally deﬁned as
Lenc = Ex∼pX∥GE(x) −E(G(x))∥2.
In so doing, the generator learns how to encode features of the generated image
for normal samples. For anomalous inputs, however, it will fail to minimize the
distance between the input and the generated images in the feature space since
both G and E networks are optimized towards normal samples only.
Overall, our objective function for the generator becomes the following:
L = wadvLadv + wconLcon + wencLenc
where wadv, wadv and wadv are the weighting parameters adjusting the impact
of individual losses to the overall objective function.
Fig. 3. Comparison of the three models. A) AnoGAN , B) Eﬃcient-GAN-Anomaly
 , C) Our Approach: GANomaly
Model Testing
During the test stage, the model uses Lenc given in Eq 3 for scoring the abnormality of a given image. Hence, for a test sample ˆx, our anomaly score A(ˆx) or
sˆx is deﬁned as
A(ˆx) = ∥GE(ˆx) −E(G(ˆx))∥1.
To evaluate the overall anomaly performance, we compute the anomaly score
for individual test sample ˆx within the test set ˆD, which in turn yields us a set
of anomaly scores S = {si : A( ˆxi), ˆxi ∈ˆD}. We then apply feature scaling to
have the anomaly scores within the probabilistic range of .
si −min(S)
max(S) −min(S)
The use of Eq 6 ultimately yields an anomaly score vector S′ for the ﬁnal
evaluation of the test set ˆD.
Experimental Setup
To evaluate our anomaly detection framework, we use three types of dataset
ranging from the simplistic benchmark of MNIST , the reference benchmark
of CIFAR and the operational context of anomaly detection within X-ray
security screening .
MNIST. To replicate the results presented in , we ﬁrst experiment on
MNIST data by treating one class being an anomaly, while the rest of the
classes are considered as the normal class. In total, we have ten sets of data,
each of which consider individual digits as the anomaly.
CIFAR10. Within our use of the CIFAR dataset, we again treat one class
as abnormal and the rest as normal. We then detect the outlier anomalies as
instances drawn from the former class by training the model on the latter labels.
University Baggage Anomaly Dataset — (UBA). This sliding window
patched-based dataset comprises 230,275 image patches. Normal samples are extracted via an overlapping sliding window from a full X-ray image, constructed
using single conventional X-ray imagery with associated false color materials
mapping from dual-energy . Abnormal classes (122, 803) are of 3 sub-classes
— knife (63, 496), gun (45, 855) and gun component (13, 452) — contain manually cropped threat objects together with sliding window patches whose intersection over union with the ground truth is greater than 0.3.
Full Firearm vs. Operational Benign — (FFOB). In addition to these
datasets, we also use the UK government evaluation dataset , comprising both
expertly concealed ﬁrearm (threat) items and operational benign (non-threat)
imagery from commercial X-ray security screening operations (baggage/parcels).
Denoted as FFOB, this dataset comprises 4, 680 ﬁrearm full-weapons as full
abnormal and 67, 672 operational benign as full normal images, respectively.
The procedure for train and test set split for the above datasets is as follows:
we split the normal samples such that 80% and 20% of the samples are considered
S. Akcay et al.
Digit designated as anomalous class
EGBAD 
Class designated as anomalous class
plane car bird cat deer dog frog horse ship truck
AnoGAN 
Fig. 4. Results for MNIST (a) and CIFAR (b) datasets. Variations due to the use of
3 diﬀerent random seeds are depicted via error bars. All but GANomaly results in (a)
were obtained from .
as part of the train and test sets, respectively. We then resize MNIST to 32×32,
DBA and FFOB to 64 × 64, respectively.
Following Schlegl et al. (AnoGAN) and Zenati et al. (EGBAD), our
adversarial training is also based on the standard DCGAN approach for
a consistent comparison. As such, we aim to show the superiority of our multinetwork architecture regardless of using any tricks to improve the GAN training.
In addition, we also compare our method against the traditional variational
autoencoder architecture (VAE) to show the advantage of our multi-network
architecture. We implement our approach in PyTorch (v0.4.0 with Python
3.6.5) by optimizing the networks using Adam with an initial learning rate
lr = 2e−3, and momentums β1 = 0.5, β2 = 0.999. Our model is optimized based
on the weighted loss L (deﬁned in Equation 4) using the weight values wbce = 1,
wrec = 50 and wenc = 1, which were empirically chosen to yield optimum results.
(Figure 5 (b)). We train the model for 15, 25, 25 epochs for MNIST, UBA and
FFOB datasets, respectively. Experimentation is performed using a dual-core
Intel Xeon E5-2630 v4 processor and NVIDIA GTX Titan X GPU.
We report results based on the area under the curve (AUC) of the Receiver
Operating Characteristic (ROC), true positive rate (TPR) as a function of false
positive rate (FPR) for diﬀerent points, each of which is a TPR-FPR value for
diﬀerent thresholds.
Figure 4 (a) presents the results obtained on MNIST data using 3 diﬀerent
random seeds, where we observe the clear superiority of our approach over previous contemporary models . For each digit chosen as anomalous, our
model achieves higher AUC than EGBAD , AnoGAN and variational
autoencoder pipeline VAE . Due to showing its poor performance within relatively unchallenging dataset, we do not include VAE in the rest of experiments.
Figure 4 (b) shows the performance of the models trained on the CIFAR10
dataset. We see that our model achieves the best AUC performance for any of
the class chosen as anomalous. The reason for getting relatively lower quantitative results within this dataset is that for a selected abnormal category, there
exists a normal class that is similar to the abnormal (plane vs. bird, cat vs. dog,
horse vs. deer and car vs. truck).
gun-parts knife overall full-weapon
AnoGAN 0.598
0.599 0.569
EGBAD 
0.587 0.597
0.520 0.643
Table 1. AUC results for UBA and FFOB datasets
For UBA and FFOB datasets shown in Table 1, our model again outperforms
other approaches excluding the case of the knife. In fact, the performance of the
models for knife is comparable. Relatively lower performance of this class is its
shape simplicity, causing an overﬁt and hence high false positives. For the overall
performance, however, our approach surpasses the other models, yielding AUC
of 0.666 and 0.882 on the UBA and FFOB datasets, respectively.
Figure 5 depicts how the choice of hyper-parameters ultimately aﬀect the
overall performance of the model. In Figure 5 (a), we see that the optimal performance is achieved when the size of the latent vector z is 100 for the MNIST
dataset with an abnormal digit-2. Figure 5 (b) demonstrates the impact of tuning
the loss function in Equation 4 on the overall performance. The model achieves
the highest AUC when wbce = 1, wrec = 50 and wenc = 1. We empirically
observe the same tuning-pattern for the rest of datasets.
Figure 6 provides the histogram of the anomaly scores during the inference
stage (a) and t-SNE visualization of the features extracted from the last convolutional layer of the discriminator network (b). Both of the ﬁgures demonstrate
a clear separation within the latent vector z and feature f(.) spaces.
Table 2 illustrates the runtime performance of the GAN-based models. Compared to the rest of the approaches, AnoGAN is computationally rather
expensive since optimization of the latent vector is needed for each example.
For EGBAD , we report similar runtime performance to that of the original
paper. Our approach, on the other hand, achieves the highest runtime performance. Runtime performance of both UBA and FFOB datasets are comparable
to MNIST even though their image and network size are double than that of
S. Akcay et al.
Digit designated as anomalous class
Weight range for
Fig. 5. (a) Overall performance of the model based on varying size of the latent vector
z. (b) Impact of weighting the losses on the overall performance. Model is trained on
MNIST dataset with an abnormal digit-2
Perplexity: 40, LR: 140, Iter: 1000
Fig. 6. (a) Histogram of the scores for both normal and abnormal test samples. (b)
t-SNE visualization of the features extracted from the last conv. layer f(.) of the
discriminator
A set of examples in Figure 7 depict real and fake images that are respectively
the input and output of our model. We expect the model to fail when generating
anomalous samples. As can be seen in Figure 7(a), this is not the case for the
class of 2 in the MNIST data. This stems from the fact that MNIST dataset is
relatively unchallenging, and the model learns suﬃcient information to be able
to generate samples not seen during training. Another conclusion that could be
drawn is that distance in the latent vector space provides adequate details for
detecting anomalies even though the model cannot distinguish abnormalities in
MNIST CIFAR DBA FFOB
AnoGAN 
EGBAD 
Table 2. Computational performance of the approaches. (Runtime in terms of millisecond)
the image space. On the contrary to the MNIST experiments, this is not the case.
Figures 7 (b-c) illustrate that model is unable to produce abnormal objects.
Overall these results purport that our approach yields both statistically and
computationally superior results than leading state-of-the-art approaches .
Conclusion
We introduce a novel encoder-decoder-encoder architectural model for general
anomaly detection enabled by an adversarial training framework. Experimentation across dataset benchmarks of varying complexity, and within the operational anomaly detection context of X-ray security screening, shows that the
proposed method outperforms both contemporary state-of-the-art GAN-based
and traditional autoencoder-based anomaly detection approaches with generalization ability to any anomaly detection task. Future work will consider employing emerging contemporary GAN optimizations , known to improve
generalized adversarial training.