Best Practices for Transparency
in Machine Generated Personalization
Laura Schelenz, Avi Segal, Kobi Gal∗
Machine generated personalization is increasingly used in
online systems. Personalization is intended to provide users
with relevant content, products, and solutions that address
their respective needs and preferences. However, users are
becoming increasingly vulnerable to online manipulation
due to algorithmic advancements and lack of transparency.
Such manipulation decreases users’ levels of trust, autonomy, and satisfaction concerning the systems with which
they interact. Increasing transparency is an important goal
for personalization based systems and system designers benefit from guidance in implementing transparency in their
In this work we combine insights from technology ethics
and computer science to generate a list of transparency best
practices for machine generated personalization. We further develop a checklist to be used by designers to evaluate
and increase the transparency of their algorithmic systems.
Adopting a designer perspective, we apply the checklist to
prominent online services and discuss its advantages and
shortcomings. We encourage researchers to adopt the checklist and work towards a consensus-based tool for measuring
transparency in the personalization community.
CCS CONCEPTS
• General and reference →Design; • Computing methodologies →Artificial intelligence; • Information systems
→Personalization; Personalization; • Social and professional topics →Codes of ethics.
∗Laura Schelenz, University of Tübingen, Germany: ; Avi Segal, Ben-Gurion University of the Negev, Israel: ; Kobi Gal, The University of Edinburgh, UK:
 
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear
this notice and the full citation on the first page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior specific permission and/or a fee. Request
permissions from .
UMAP ’20 Adjunct, July 14–17, 2020, Genoa, Italy
© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-7950-2/20/07...$15.00
 
transparency, responsible personalization, personalized transparency, checklist, ethics
ACM Reference Format:
Laura Schelenz, Avi Segal, Kobi Gal. 2020. Best Practices for Transparency in Machine Generated Personalization. In Adjunct Proceedings of the 28th ACM Conference on User Modeling, Adaptation and
Personalization (UMAP ’20 Adjunct), July 14–17, 2020, Genoa, Italy.
ACM, New York, NY, USA, 8 pages. 
INTRODUCTION
Recent years saw significant increase in personalization approaches for online systems . Such personalization
can be used to direct users’ attention to relevant content ,
increase their motivation when working online , improve their performance , extend their engagement 
and more. These approaches rely on social theories of human behavior (e.g. ) as well as on machine learning
based abilities to predict human reaction to various interventions .
Yet, personalization technology that focuses on maximizing system designers goals runs the risk of marginalizing
users 1. Personalized recommendations usually attempt to
influence a person’s decision-making. When such influences
are hidden and subtly try to persuade users (maybe even
against their expressed goals), this constitutes a form of
manipulation . Subverting a person’s decision-making
abilities reduces their autonomy. Especially with regard to
personalized advertisement, personlization can exploit users’
vulnerabilities and may even threaten democratic processes .
Applying transparency to the design of personalized content can help address these challenges. First, transparency
can balance power asymmetry, empowering users while curtailing the influence of companies on customer behavior .
Second, transparency can increase user autonomy. For example, recommender systems usually filter content according
to preference models that easily create a feedback loop .
When users lack exposure to information diversity, their
autonomy and ability to make independent decisions is impacted . Third, transparency can boost privacy rights and
1 
user trust in algorithmic systems. Users can only give meaningful informed consent when they understand the risks of
algorithmic decision-making . Fourth, transparency can
increase subjects’ ability to understand the cause of decisions
made by algorithms and assess whether a decision-making
process is fair and non-discriminatory [4, p.2].
The computer science community has affirmed the importance of transparency in its profession. The ACM Code
of Ethics reads: “The entire computing profession benefits
when the ethical decision-making process is accountable to
and transparent to all stakeholders” . Also political bodies identify transparency as a pivotal principle in Artificial
Intelligence based software .
Especially with the advent of legal frameworks that prescribe transparency in data collection, processing, and storage , system designers require increased awareness and
guidance about transparency in their systems . Recent
and emerging scholarship on explainable AI underlines the
importance of transparency in computer systems .
Additionally, attempts to operationalize ethics principles for
AI respond to the increased call for practical guidance .
We take a three step approach to developing best practices
for transparency in machine generated personalization: 1)
developing a new definition of transparency for algorithmic
systems by drawing on prior art, 2) deriving best practices
for the implementation of transparency in machine generated personalization, and 3) translating these best practices
into questions for system designers to be used as a reflection
and assessment tool. The outcome is an online checklist for
open usage based on best practices which constitute ethical
guidelines for system designers. The checklist can be used
by systems designers to evaluate and operationalize transparency in their systems. It encourages (self-)reflection and
an ongoing exchange with the personalization community
towards ethically responsible personalization.
TRANSPARENCY DEFINITION
To generate a list of best practices, we began by asking: What
is transparency in the context of AI systems? According to
Turilli and Floridi , transparency is not a principle of
ethics per se, but a practice that can achieve ethics goals such
as autonomy and accountability. Adopting this understanding, we investigated views on transparency from technology
ethics, the philosophy of technology, computer sciences, as
well as ethics guidelines and legal documents. This literature
review and qualitative analysis of work on "transparency"
allowed us to formulate the following definition for the computer science community:
Transparency is a practice of system design that centers on
the disclosure of information to users, whereas this information
should be understandable to the respective user and provide
insights about the system. Specifically, the information disclosed should enable the user to understand why and how the
system may produce or why and how it has produced a certain outcome (e.g. why a user received a certain personalized
recommendation).
The first important component of transparency is the notion that the user of a system must be able to comprehend
the information disclosed to them. According to Chromnik
et al. , transparency is an enabling condition for the
user to “understand the cause of a decision." Ananny and
Crawford describe transparency as a form of “seeing” an
actor-network. Transparency then means not merely looking inside a system but across systems, and explaining a
model as it interacts with other actors in an algorithmic
system . Floridi et al. understand transparency as
explainability, whereas explainability incorporates both intelligibility (being able to grasp how a model works) and
accountability (understanding who is responsible for it). Following Vakarelov and Rogerson , transparency means
communication of information under two conditions: information must be a) sufficient and b) accessible, i.e. the user
must be able to comprehend and act upon the information.
According to the GDPR , information about data collection and processing must be provided in “clear and plain
language and it should not contain unfair terms” [3, p. 8].
Here, we can see how transparency is a relational practice.
Whether the information provided is transparent depends on
the individual user or data subject, their cognitive abilities,
their language skills, and epistemic conditions .
Another crucial element of transparency is information
disclosure about deliberation or decision-making processes.
The IEEE Guideline for “Ethically Aligned Design” states
that transparency means the possibility to ascertain why a
certain decision was made . For Turilli and Floridi ,
disclosing information refers to communication about the
deliberation process because it reveals the values that guide
organizations in their everyday practices and illustrate how
they make decisions. Hence, the disclosure of the dataset
may be less relevant than the actual factors (such as inferences made from the data) that inform a model and its effects
on users . Also Zerilli et al. argue that, similar to
explanations in human decision-making, a system should
reveal factors in decision-making and how they are weighted.
Dahl even argues that it is not necessary to reveal the inner working of a model but to provide key details about how
the results came about, e.g. offering expert testimony about
how the system usually works. Burrell suggests that
reducing opacity of classifications means "exposing some of
the logic of this classification.”
Finally, there can be an element of participation in transparency. The user is expected to assess the system with
regard to its trustworthiness based on the information that
is disclosed. Furthermore, the user may become active in
choosing between different models, i.e. different options of
personalization . The user is thus becoming involved in
the process of transparency.
TRANSPARENCY BEST PRACTICES
From our definition of transparency, we derived nine principles of transparency for responsible personalization with
particular relevance ascribed to three practices. These practices reflect the three core elements of transparency: information provided must be understandable to users, information
must be disclosed about why and how a model reaches a
certain outcome, and users should have a say in personalization processes. The best practices further reflect additional
needs for information about the data collection processes,
the composition of datasets, the functionality of a model,
the responsibilities for the model or system, and how the
model may interact with other models across algorithmic
systems. The best practices are necessarily generic, which
allows system designers in the personalization community
to adapt them to their context.
Table 1 shows the list of the best practices as well as
the sources on which these practices build. It also identifies the relevant system architecture components for each
best practice based on the Input-Processing-Output architecture model . We extend this architecture with a "Control"
component to represent the control given to the user over the
system’s personalization behavior. We define user control as
the possibility of users to interact with the system to adjust
elements thereof to their respective needs and preferences. It
is important that users not only “feel” that they have control
because this can put them at risk of exploitation. If users
think that they have control, they might feel encouraged to
share more data . Possible misuse of transparency measures and the potential abuse of our approach are addressed
in the discussion.
Based on the definition and best practices, we have defined
a checklist for system designers to assess the transparency
of machine generated personalization. The checklist codifies transparency practices as developed in the previous
section. For instance, practice number 3 requires "disclosing relevant and detailed information about the goals of the
designer/system." We reframed this best practice into a question and asked at the top of the checklist: "Does the system
inform the user about the purpose of personalization?" In this
fashion, we formulated checklist questions for all the Input,
Processing, Output and Control best practices identified in
Table 1. In this process, we prioritize some best practices that
were overwhelmingly affirmed by the literature. We note
the qualitative nature of our methodology and expect future
work to extend our approach to a consensus-based tool for
measuring transparency in the personalization community.
The resulting checklist is presented at Table 2. The checklist’s web version is given at: 
The checklist includes a total of 23 questions. After filling
it online, the system designer can download a PDF file with
their responses. They can also print an empty copy of the
checklist to be filled offline if needed. We note that the checklist is supplied as an assessment tool for system designers,
enabling them to identify areas in their systems which suffer
from lack of transparency. Ideally, a system designer has implemented transparency so that they can check yes for every
question. However, the goal should not be to score high on
the checklist but rather to honestly reflect and decide on
priorities and next steps.
CASE STUDY: APPLYING THE CHECKLIST
We performed an initial application of the proposed checklist
as a reflective and assessment tool for the following online
services that use personalization: Facebook, Netflix, YouTube,
Spotify, and Amazon. For each of these destinations, we
took a system designer’s point of view, and asked "(how)
are the transparency elements from the checklist supported
on this particular site?". For this assessment we adopted the
checklist and examined the above web services using one of
the authors account on these sites. Specifically, we checked
the information available to registered users on the sites
including the privacy policy, the legal terms and conditions
and other information that is shared with the user and covers
any of the checklist elements. We answered each checklist
question for each site with a "yes", "no" or "partial" reply.
To conduct a preliminary comparison between the different sites and between the different sections of the checklist
for each site, we then computed the percentage of "Yes" and
"Partial" replies for each checklist section. For each checklist
question, we gave a "Yes" reply a value of 1 and a "Partial"
reply a value of 0.5. We then summed these values for each
section and divided it by the total number of questions in the
corresponding section. Figure 1 presents the result of this
comparison. We discuss these results in the next section.
DISCUSSION
The major advantage of the transparency checklist is that it
helps system designers understand where they are strong on
transparency and where improvements are needed. Looking
at Figure 1, we notice that existing online systems primarily
focus on realizing transparency in the "Input" category, i.e.
with regard to data collection and the handling of user data.
They are particularly weak in providing information about
why and how models bring about certain personalization
("Processing"). They also lack participatory elements such
Description of transparency standard
Input, Processing,
Output, Control
Disclosing accessible and actionable information, meaning that
the user can comprehend and act upon the information
Input, Processing
Disclosing relevant and detailed information about data collection and processing; notification about the data collected for
personalization, information about pre-processing and possible
biases in the dataset
 
Processing
Disclosing relevant and detailed information about the goals of
the designer/system, the reasoning of a system, the factors and
criteria used (potentially also how they are weighted), as well as
the inferences made to reach an algorithmic decision
 
Processing
If possible, providing expert testimony (e.g. by a member of the
design team) about how a system works and reaches a certain
Processing
If possible, disclosing information about how a model may affect the user and how it may interact with other models across
Disclosing that a machine is communicating with the user and
not a real person
Disclosing information about those responsible for the model
(e.g. name of the company or designer)
Proposing alternative choices for user interaction with the system, e.g. different options for personalization
Providing the user with opportunities to adjust personalization
or specify their goals as these goals are expected to drive personalization
Table 1: Transparency Best Practices for Machine Generated Personalization
as offering the user different options of personalization or
allowing the user to supply feedback ("Control").
This trend to follow best practices of data or "Input" transparency may be attributable to the rise of data protection
laws such as the GDPR. System designers so far pay less
attention to transparency about the reasoning and underlying logic of personalization. This is a severe shortcoming
as ethics literature clearly identifies the need to disclose information about how a certain outcome (personalization)
emerged. We suspect that transparency about the reasoning
of a system will gain relevance in the future. In fact, there
is an ongoing debate whether the GDPR even provides a
legal right to receive an explanation for algorithmic decisionmaking .
Literature also points to the need for user control to fulfill
transparency . Our application of the checklist points
to significant shortcomings in existing systems in the realm
of "user control." As a system designer, having applied the
checklist and seen some blind spots, one would now be able
to make a deliberate decision about whether to increase user
control in one’s own system.
For instance, being responsible for the personalization
systems in Figure 1, designers might want to invest in transparency with regard to the how and why of personalized
recommendations. The reasoning behind personalized recommendations may not be clear to the user. Did the services
factor age, gender, frequency of engagement, previous likes
and shares in other social media platforms? What assumptions were made about the user that motivated the designers
to present them a certain option? How does the social network of the user affect the recommendations they receive?
Information about these questions and others can help
users make autonomous decisions about their usage and
consumption. It is possible that some users want to explore
content beyond their age group to broaden their perspectives. Similarly, some users may not agree with gender-based
recommendations and thus, information about how gender
factors into personalized content may encourage them to
explore the service for higher diversity. Paired with the opportunity to provide feedback and adjust the system’s personalization behavior (user control), transparency practices
enable a deeper and more meaningful engagement with the
Does the system inform the user about the purpose of personalization?
Does the system inform the user who developed the technology and is liable in cases of wrongdoing?
Does the system inform the user about their rights under data protection law?
Does the system inform the user about possible risks of engaging with the system?
Have users given informed consent about the collection, processing, and storage of their data?
Does the system inform the user about the fact that data is collected for personalization?
Does the system inform the user about which data is collected to produce personalized content for them?
Does the system inform the user about pre-processing done with the data collected for personalization purposes?
Does the system inform the user if their data is used and shared beyond the goals of personalization?
Processing:
Does the system inform the user about the kind of data that is processed to create a certain personalized item?
Does the system explain to the user why they are receiving a certain personalization?
Does the system inform the user about the behavioral models underlying the personalization system?
Does the system inform the user about possible constraints of the model such that may result from pre-processing
or biases in the dataset?
Does the system present information to the user in a location where they can notice it and access it easily?
Does the system provide information to the user in a comprehensible way and can they act upon this information?
Does the system provide the user with information in a clear and simple language that avoids technical terms?
Does the system make it clear to the user that they interact with a machine?
Does the system provide the user with the opportunity to specify their goals which are then used for personalization?
Does the system provide the user with different options as to the personalized content they receive?
Does the system provide the user with opt-in and opt-out options (e.g. for data collection)?
If applicable, can the user adjust frequency and timing of personalized content?
Does the user have a say in which data or models are used for personalization?
Does the system encourage the user to give feedback and express their opinion about the personalization
mechanisms used (type, frequency, duration, etc.)?
Table 2: Transparency Checklist
service at hand. Users can thus grasp how a system behavior affects their personal choices and can better adjust this
behavior for their needs.
As with many practices, transparency has limits. Providing information does not guarantee that we understand a
model, e.g. due to lack of resources, human capital , and
basic digital or technical literacy . Disclosing information
can also confuse users rather than adding to clarity . A
particular concern here is that systems may provide scores of
information that cannot be processed by users and that may
encourage trust without increasing user autonomy and control. Transparency may further clash with important ethics
principles such as privacy. Full disclosure of input or output data may put users at risk of being re-identified. Other
concerns are protecting business interests (e.g. proprietary
information) as well as using transparency to “game the system,” i.e. users which manipulate their input data to receive
the desired outcome . These limitations also put a checklist in perspective as the level of transparency depends on
the unique use case. A checklist further may be misused to
prove compliance with transparency best practices without
meaningfully changing practices.
Another significant issue concerns the relationship of information to the user. Transparency is a relational practice:
the same information may make something transparent to
one group or individual but not to others . It follows that
transparency must be configured to the individual user. In
fact, we may need a personalization technology to fulfill the
transparency best practices for machine generated personalizaion . A relational approach to transparency best
Figure 1: Preliminary checklist, online sites: Y-axis is the percentage of positive and partial replies in each checklist section
practices also requires considering the implications of networks on personalization outcomes. How is a user affected by
other users’ behavioral patterns? How can we disclose information beyond individual personalization without violating
users’ privacy?
Finally, while an ethics perspective promotes user control
and meaningful transparency, it is not certain that users desire transparency and control. From privacy research, we
know that users claim privacy to be an important issue for
them but rarely take steps to protect their data (“privacy
paradox”) . Similar dynamics may apply to transparency.
Nevertheless, users should have the opportunity to take advantage of transparency. System designers then have an
ethical responsibility to implement transparency best practices.
CONCLUSION AND FUTURE WORK
In this work, we developed a transparency definition, best
practices, and a checklist for system designers to better implement transparency in machine generated personalization.
We applied the checklist to prominent online services that
use personalization and found that systems lack transparency
with regard to "processing" and "user control." System designers may want to spend more time explaining why and
how their systems reach a certain outcome (personalization)
and provide more options for users to adjust personalization.
In this context, we note that transparency is a relational
practice and information should be personalized to ensure
that diverse users understand the disclosed information.
While we propose a first transparency and user control
checklist, we recognize that it may be amended in the future.
Ideally, the items in the checklist should be discussed by
experts in the field and present a consensus of the personalization community . We encourage system designers to
provide feedback on the checklist, and suggest the organization of workshops to develop tangible design solutions that
implement transparency in personalization. Finally, more
conceptual work on transparency and related concepts such
as understandability, explainability, controllability, and accountability can help advance the discourse on responsible
personalization.
ACKNOWLEDGEMENTS
This project has received funding from the European Union’s
Horizon 2020 WeNet project ( 
under grant agreement No 823783. The authors would like
to kindly thank PD Dr. Jessica Heesen for her valuable comments on draft versions of the paper.