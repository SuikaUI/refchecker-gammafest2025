Learn From Thy Neighbor: Parallel-Chain and
Regional Adaptive MCMC
Radu V. Craiu
Department of Statistics
University of Toronto
Toronto, ON, M5S 3G3, Canada
 
Jeﬀrey Rosenthal
Department of Statistics
University of Toronto
Toronto, ON M5S 3G3, Canada
 
Department of Statistics
University of Toronto
Toronto, M5S 3G3, Canada
 
July 2008; last revised April 2009
Starting with the seminal paper of Haario, Saksman and Tamminen ), a substantial amount of work has been done to validate adaptive
Markov chain Monte Carlo algorithms. In this paper we focus on two practical aspects of adaptive Metropolis samplers. First, we draw attention to the
deﬁcient performance of standard adaptation when the target distribution is
multi-modal. We propose a parallel chain adaptation strategy that incorporates multiple Markov chains which are run in parallel. Second, we note that
the current adaptive MCMC paradigm implicitly assumes that the adaptation is
uniformly eﬃcient on all regions of the state space. However, in many practical
instances, diﬀerent “optimal” kernels are needed in diﬀerent regions of the state
space. We propose here a regional adaptation algorithm in which we account
for possible errors made in deﬁning the adaptation regions. This corresponds to
the more realistic case in which one does not know exactly the optimal regions
for adaptation. The methods focus on the random walk Metropolis sampling
algorithm but their scope is much wider. We provide theoretical justiﬁcation
for the two adaptive approaches using the existent theory build for adaptive
Markov chain Monte Carlo. We illustrate the performance of the methods using simulations and analyze a mixture model for real data using an algorithm
that combines the two approaches.
Keywords: Adaptive Markov chain Monte Carlo, Metropolis sampling, random
walk Metropolis sampling , parallel chains, regional adaptation.
Introduction
Markov chain Monte Carlo (MCMC) techniques have become an important tool in
the statistician’s arsenal for solving complex analyses. One of the most widely used
algorithms is the Metropolis and its generalization, the
Metropolis-Hastings (MH) sampler. If the goal is to sample from a
distribution π with support S, the MH sampler is started with a random value X0 ∼µ
and, at each iteration t, a proposal Y is drawn from a proposal distribution Q(y|Xt)
with density q(y|Xt) and is retained as the next state of the chain with probability
α(Xt, Y ) = min
1, π(Y )q(Xt|Y )
π(Xt)q(Y |Xt)
. If q(y|x) is the density of y = x + ǫ where ǫ has a
symmetric distribution, we obtain the random walk Metropolis algorithm.
In order to design an eﬃcient Metropolis algorithm it is necessary to carefully
adapt the parameters of the proposal distribution Q so that the performance of the
algorithm is optimal (note that there are multiple deﬁnitions of “optimal” available).
On one hand one can argue that many modern MCMC algorithms incorporate a cer-
tain notion of local adaptation in their design, e.g. Gilks et al. , Liu et al.
 and Craiu and Lemieux , Green and Mira , Eidsvik and Tjelmeland . In this paper, we refer to a more global version of adaptation which
is based on learning the geography of π “on the ﬂy” from all the samples available
up to the current time t. Such an approach violates the Markovian property as the
subsequent realizations of the chain depend not only on the current state but also on
all past realizations. This implies that one can validate theoretically this approach
only if one is able to prove from ﬁrst principles that the adaptive algorithm is indeed sampling from π. In Haario et al. the authors provide such a theoretical
justiﬁcation for adapting the covariance matrix Σ of the Gaussian proposal density
used in a random walk Metropolis. They continually adapt Σ using the empirical
distribution of the available samples. Their choice of adaptation is motivated by the
optimal results proved by Roberts et al. and Roberts and Rosenthal .
Subsequently, the convergence results of adaptive algorithms have been made more
general in Andrieu and Robert , Andrieu et al. , Andrieu and Moulines
 , Atchade and Rosenthal , and Roberts and Rosenthal . An adaptive algorithm for the independent Metropolis sampler was proposed by Gasemyr
 and Haario et al. extended their previous work to Metropolis-within-
Gibbs sampling. A class of quasi-perfect adaptive MCMC algorithms is introduced
by Andrieu and Atchade and a nice tutorial on adaptive methods is given by
Andrieu and Thoms . Alternative approaches to adaptation within MCMC
can be found in Brockwell and Kadane , Nott and Kohn , Giordani and
Kohn . We quote from Giordani and Kohn :
Although more theoretical work can be expected, the existing body of
results provides suﬃcient justiﬁcation and guidelines to build adaptive
MH samplers for challenging problems. The main theoretical obstacles
having been solved, research is now needed to design eﬃcient and reliable
adaptive samplers for broad classes of problems.
In the present paper we try to close some of the gap between theory and practice by
focusing on the practical aspects of adaptive MCMC (AMCMC). More precisely, we
discuss complications arising when using AMCMC, especially adaptive random walk
Metropolis, for sampling from multi-modal targets and also when the optimal proposal
distribution is regional, i.e. the optimal proposal should change across regions of the
state space. In the next section we discuss the inter-chain adaptation. In Section
3 we discuss the regional adaptation. The theoretical challenge is to show that the
algorithms proposed here fall within the scope of general theorems that are used to
validate adaptive MCMC. These results are presented in Section 4 while simulation
examples and a real data analysis are shown in Section 5. We close with discussion
of further research.
Inter-chain Adaptation (INCA)
To begin, consider a simulation setting where the target distribution is a mixture of
two ten-dimensional Gaussian distributions. More precisely, the target distribution
π(x|µ1, µ2, Σ1, Σ2) = 0.5n10(x; µ1, Σ1) + 0.5n10(x; µ2, Σ2),
with nd(x; µ, Σ) denoting the density of a d-dimensional Gaussian random variable
with mean µ and covariance matrix Σ and where µ1 = (0.03, −0.06, −0.24, −1.39, 0.52,
0.61, 1.26, −0.71, −1.38, −1.53)T, µ1i −µ2i = 6, ∀1 ≤i ≤10, Σ1 = I10 and Σ2 = 4I10.
In Figure 1 we present the results of a simulation in which we applied the adaptive
Metropolis sampler of Haario et al. with an initialisation period of 10,000
samples. The chain is started in one of the target’s modes (the one corresponding to
µ1). Although the ﬁnal sample size is N = 250, 000, we can see that the chain does
not visit the second mode. In this case, the adaptation can not improve much on the
unadapted version of the Metropolis sampler as the second mode ”is invisible” in the
initialization period and it will likely take a long time for a chain incorrectly adapted
to a unimodal distribution to discover the second high probability region.
In the classic MCMC literature diﬃculties related to sampling from a multi-modal
Single chain adaptation
Figure 1: Boxplots of N=250,000 samples obtained using a single-chain adaptive
Metropolis; each boxplot correspond to one component of the 10-dimensional random
vector. The red lines represent the entries of the target’s mean vector. The chain does
not visit the second mode of the target.
distribution are tackled using multiple parallel chains as in Gelman and Rubin 
and tempering as in Neal and Geyer and Thompson . Both ideas inﬂuence our approach.
The parallel chains implementation has been proven helpful for a more systematic
exploration of the sample space as in Craiu and Meng . In the present setting
we use it to detect the diﬀerent regions of signiﬁcant mass under the posterior distribution and our starting example shows that such detection is extremely important for
adaptive MCMC. We thus propose running in parallel a number, say K, of Markov
chains. We can further robustify the performance of the algorithm if the chains are
started from a distribution µ that is overdispersed with respect to π. It should be
noted that ﬁnding µ can be quite challenging. The problem of ﬁnding good starting
points for parallel chains is also discussed by Jennison , Applegate et al. ,
Gelman and Rubin and Brooks and Gelman . We would like to add a
word of caution following Gill which states that a bad choice for µ can be
deleterious and may dramatically alter the simulation results.
A question of interest in adaptive MCMC is whether one should wait a short or
a long time before starting the adaptation. In Gasemyr , the burn-in time
is random but bounded below, while Giordani and Kohn propose a diﬀerent
strategy in which adaption starts early and is performed frequently in what they
call intensive adaptation. However, they also warn that one should make sure that
enough distinct samples are obtained in order to avoid singularity problems. In the
multi-modal situation considered here we adopt a longer burn-in, partly because
the multi-modality of π makes it diﬃcult to have a good idea about its geography
when only a few draws are available. A longer burn-in increases the stability of the
inferences obtained and reduces the risk of missing one important mode.
We thus propose a new strategy, inter-chain adaptive MCMC (INCA), as follows.
We run K diﬀerent chains in parallel, each started independently from the same
overdispersed starting distribution. After the burn-in period the K kernels are simultaneously adapted using all the samples provided by the K chains so far. In the
case of a random walk Metropolis with Gaussian proposals we do this by setting the
proposal covariance to the sample covariance matrix of all the available samples. Denote γm the adaptation parameter, e.g. the variance of the random walk Metropolis
proposal distribution, used at step m in each marginal transition kernel. We run the
chains independently conditional on the {γm}, so the joint transition kernel, ˜Tγm is
obtained as the product of K identical copies of the marginal transition kernel Tγm
˜Tγm(˜x, ˜A) = Tγm(x1; A1) ⊗Tγm(x2; A2) ⊗. . . ⊗Tγm(xK; AK),
where ˜A = A1 × . . . × AK and ˜x = (x1, . . . , xK).
The motivation for using multiple chains lies in our attempt to discover as early
as possible all the modal regions of π (or at least all the important ones). After
the chains have explored the regions of interest and the simulation parameters are
updated one may wish to return to a single chain. A question of interest is then
how to decide when the exchange of information between chains has stopped. The
criterion we use is the well-known Brooks-Gelman-Rubin (BGR) diagnostic, R, as
developed in Gelman and Rubin and Brooks and Gelman . Given a
number, say K, of parallel chains, the potential scale reduction R is a normalized
ratio of the between-chain and within-chain variances computed from the available
samples , page 465). While R was originally designed as
a convergence indicator, here it is used to determine whether the chains contribute
diﬀerent information about π.
In Figure 2 we show for the mixture of Gaussian distributions the evolution of the
R statistics. One can see that the exchange of information between chains is gradually
decreasing along with the adaptation. An astute reader may wonder whether the
learning process can be accelerated using tempering strategies in order to learn the
geography of π more quickly.
Evolution of BGR statistics
Figure 2: The evolution of BGR’s R statistic. It takes approximately 18,000 iterations
to reach below 1.1.
Tempered INCA (TINCA)
Tempering in MCMC relies on a series of “canonical” distributions, πT, each of which
are obtained by varying a “temperature” parameter T in a set {t1, t2, . . . , tmax} such
that πt1 = π and while πtj is not too diﬀerent from πtj+1, there is a substantial
diﬀerence between π and πtmax in that the latter has less isolated modes (or is ”ﬂatter”)
so that it is considerably easier to sample using MCMC algorithms. One generic
procedure (although not the only one) deﬁnes πT = π1/T for T ≥1. In Figure 3 we
illustrate the eﬀect of tempering on a bivariate mixture of Gaussian distributions.
One expects that for large values of T (or hot temperatures), adaptive algorithms
designed for πT will be more eﬃcient.
For instance, if INCA is implemented we
expect the running time needed to stabilize R ≈1 to be much shorter than at the
”cool” temperature T = 1. One could possibly envision a gradual temperature-driven
adaptation following Meng . Start with T = tmax and at each temperature
perform the following steps:
Step I For T = tj perform INCA for target density πT until R is below a pre-speciﬁed
Contour plot with T=1
Contour plot with T=2
Contour plot with T=4
Contour plot with T=8
Figure 3: Tempered distributions with T = 1 (original target), T = 2, T = 4 and
threshold 1 + ξ.
Step II Keep the simulation parameters obtained and perform Step I with the next
colder temperature T = tj−1. Stop after T = 1.
The implementation assumes that the kernel learned/adapted at temperature tj
is a reasonable starting choice for the kernel used at temperature tj−1. In addition
to speeding up the adaptation process, this tempered INCA (TINCA) is aimed at
solving the diﬃcult task of producing a reasonable starting proposal in a high dimensional problem. We implemented TINCA with T ∈{1, 2, 4, 8, 16} for the example
discussed in this section and the total number of iterations, including those produced
at temperatures T > 1, required to reach R ≤1.1 at T = 1 was 10,000, compared
to the 18,000 reported without tempering. Additional simulations using TINCA are
discussed in Section 5.
It should be noted that INCA and/or TINCA can be implemented along many
other adaptive MCMC strategies. As mentioned by many authors working in the
ﬁeld, the performance of the algorithm during the initialization (or burn-in) period,
when no adaption is taking place, is crucial. We believe that INCA is most useful in
the initial stage of the simulation since it accelerates the ”data gathering” about the
geography of π and improves the overall performance of the adaptive process.
Regional Adaptation (RAPT)
In the previous section, we considered a simple example in which the target distribution had its mass equally divided between the two modes. However, examples abound
where the modes of the distribution have diﬀerent relative mass and in these situations a simple remedy such as INCA may be ineﬀective. One can easily see that in
such cases there is no “universal” good proposal, i.e. the learning must be adapted
to diﬀerent regions of the state space. Regional adaptation has been suggested in a
diﬀerent form by Andrieu and Robert and Roberts and Rosenthal . For
our discussion assume that there is a partition of the space S made of two regions
S01, S02 such that adaptation should be carried over independently in the two regions.
In other words, in the case of a Metropolis algorithm, in region S0i we would use proposals from distribution Qi while only samples from this region will be used to adapt
Qi. Such an algorithm is valid as long as one carefully computes acceptance ratios
for proposed moves that switch regions, as was also noted by Roberts and Rosenthal
 . In the case of two regions the acceptance ratio is then
r(x, xnew) =
if x, xnew ∈S0i
π(xnew)q1(x|xnew)
π(x)q2(xnew|x) ,
if x ∈S02, xnew ∈S01
π(xnew)q2(x|xnew)
π(x)q1(xnew|x) ,
if x ∈S01, xnew ∈S02.
where qi is the density of Qi.
While there exist sophisticated methods to detect the modes of a multimodal
distribution , it is not always clear how to use such techniques since deﬁning a good partition
of the sample space may need more than just the location of the modes. In Craiu and
Di Narzo we follow the methods of Andrieu and Moulines and Capp´e
Exact boundary
Approximate boundary
Figure 4: Illustration of the regional adaptive MCMC sampler. The dashed black line
represents the exact boundary (unknown), between regions S01 and S02. The dashed
red line delimitates the regions S1 and S2 used for the regional adaptation.
and Moulines to propose a mixture-based approach for adaptively determining
the boundary between high probability regions. Suppose we approximate the target
distribution using the mixture of Gaussians
˜Q(x) = βn(x; µ1, Σ1) + (1 −β)n(x; µ2, Σ2).
Then Craiu and Di Narzo deﬁne the regions Sk as the set in which the k-th
component of the mixture density ˜Q dominates the other one., i.e.
Sk = {x : arg max
n(x; µk′, Σk′) = k}.
Regardless of the method used, in most cases we do not have enough knowledge
to choose the partition made exactly of regions S01 and S02. Instead, suppose we
deﬁne a partition made of regions S1 and S2. An illustration of this idea is shown
in Figure 4. The solid black line represents the exact boundary (unknown), between
regions S01 and S02. The dashed red line delimitates the regions S1 and S2 used for
the regional adaptation. If we were to apply the simple regional adaptive algorithm
described above, when the chain is in one of the states situated between the two
dashed lines the wrong proposal would be used. Therefore, in order to account for
the error made when specifying the boundary between regions we propose to sample
our proposals from a mixture that includes both Q1 and Q2. However, the mixture
proportions are diﬀerent in each region Si and are adaptively modiﬁed. The resulting
Regional Adaptive (RAPT) algorithm has proposal distribution
Qγ(x, dy) =
1Si(x)[λ(i)
1 Q1(x, dy) + λ(i)
2 Q2(x, dy)],
where λ(i)
2 = 1. In this case, we use the index γ on Q to emphasize the fact that
the proposal is adapted with the adaption parameter γ = (λ(1)
1 ) ∈Y = 2.
The mixture proportions λ(i)
j , 1 ≤i, j ≤2 are chosen to reﬂect which of the two
proposals is more “appropriate” to use in the given region. Evidently, one has some
freedom over what can be considered a good proposal in this setup. For instance, one
could choose
where n(i)
j (t) is the number of accepted moves up to time t computed when the
accepted proposals are distributed with Qj and the current state of the chain lies in
Si. However, this choice would favor small steps of the chain since these have higher
acceptance rates. To counterbalance, we take into account the average squared jump
distance so that
where d(i)
j (t) is the average squared jump distance up to time t computed when the
proposals were sampled from Qj and the current state of the chain lies in Si. More
precisely, suppose {xj}t
j=0 are the samples obtained until time t and Ni(t) is the
number of elements in the set {xi
g=1 which contains all the samples generated up
to time t that are lying in Si. We also deﬁne the set of time points at which the
proposal is generated from Qj and the current state is in Si, W (i)
j (t) = {0 ≤s ≤t :
xs ∈Si and proposal at time s is generated from Qj}. Then
(t) |xs+1 −xs|2
where |W (i)
j (t)| denotes the number of elements in the set W (i)
j (t). If W (i)
j (t) = ∅then
j (t) = 0. If we implement RAPT within INCA/TINCA with K parallel chains then
in the calculation of d(i)
j (t) we need to consider all the samples obtained up to time t
by all the K chains.
Better performance can be achieved using the algorithm (3) for which both the
mixture weights and the proposals, Q1, Q2, are adapted, which is called Dual RAPT.
We suggest here to adapt the covariance matrix of each proposal distribution in the
same vein as Haario et al. .
When the current state Xt−1 lies in Si, the components of the mixture (3) are the
Gaussian distributions with densities q(t)
and with mean at the current point Xt−1
and covariance Ci(t), where Ci(t) is deﬁned below.
t2, · · ·, Xi
tNi(t)) + sdǫ Id,
, i = 1, 2,
where sd = (2.4)2/d. This form of adaption follows (separately within each region)
the Adaptive Metropolis algorithm of Haario et al. , and is based on the results
of Gelman et al. , Roberts et al. , and Roberts and Rosenthal who
showed that this choice optimizes the mixing of random walk Metropolis at least in
the case of Gaussian targets and Gaussian proposals. The implicit premise is that in
each region the Gaussian approximation of the target is reasonable. The addition of
sdǫ Id, where ǫ > 0 is a small constant, guarantees that the matrices Ci(t) are all in
M(c1, c2) for some ﬁxed constants 0 < c1 ≤c2 < ∞, where M(c1, c2) is the set of all
k × k positive deﬁnite matrices M such that c1Ik ≤M ≤c2Ik, i.e. such that both
M −c1Ik and c2Ik −M are non-negative deﬁnite.
The adaption parameter is then
1 , C1, C2) ∈Y = × × M(c1, c2) × M(c1, c2).
An observant reader may notice that while the algorithm may perform well in
each region, there is no guarantee that there will be a good ﬂow between
For this reason, in practice we consider the Mixed RAPT algorithm in which we add
a third adaptive component to the mixture (3). In this variant,
Qγ(x, dy) = (1 −β)
1Si(x)[λ(i)
1 Q1(x, dy) + λ(i)
2 Q2(x, dy)] + βQwhole(x, dy),
where Qwhole is adapted using all the samples in S and β is constant throughout
the simulation. Once more we adapt the ideas in Haario et al. and use the
covariance of all the simulations available at time t to adapt the covariance of the
Gaussian proposal density qwhole in (6). We shall use
sd Cov(X0, X1, · · ·, Xt) + sdǫ Id,
t > t0 and Tr(C(t)) ≤M
Given that all the distributions and parameters (except β) in (6) are evolving, the
adaption parameter is
1 , C1, C2, C) ∈Y = × × M(c1, c2) × M(c1, c2) × M(c1, c2).
INCA/TINCA Versions of RAPT
The descriptions so far of the various RAPT, Dual RAPT, and Mixed RAPT algorithms have all been for a single chain. However, it is also possible to combine these
algorithms with the INCA approach of Section 2.
Indeed, for RAPT, all that is required is to compute the quantities d(i)
equation (4) using all of the proposals from all of the K parallel chains.
For Dual RAPT, it is required in addition that the covariance matrix adaptions
of equation (5) use the appropriate samples X from all of the K parallel chains.
And, for Mixed RAPT, it is required in addition that the covariance matrix adaptions of equation (7) also use the appropriate samples X from all of the K parallel
Similarly, it is possible to combine all of this with the tempered (TINCA) approach of Section 2.1. Indeed, all that is required is to run each of the chains on the
distribution πTj = π1/Tj until R < 1 + ǫ, and then to replace j by j −1 and continue,
until such time as we reach Tj = 1 corresponding to πTj = π.
Theoretical Results
In this section, we prove that each of our previously-deﬁned adaptive algorithms is
“ergodic to π”, i.e. that
|P(Xn ∈A) −π(A)| = 0 ,
assuming the following compactness condition:
(A1) There is a compact subset S ⊆Rk such that the target density π is continuous
on S, positive on the interior of S, and zero outside of S.
We believe that it is possible to remove the assumption that S is compact, but the
resulting arguments are more technical, so we will pursue them elsewhere . Of course, even compact sets can be arbitrarily large, so in practice (A1) does
not impose any signiﬁcant limitation.
We shall ﬁrst prove ergodicity of the RAPT algorithm, where only the weights
are adapted, as in (4). In this case, since the proposal densities qi are arbitrary,
we also need to assume that they are continuous and positive throughout S.
Theorem 4.1. Assuming (A1), and that the proposal densities qi are continuous and
positive throughout S × S, the RAPT algorithm is ergodic to π.
We shall then prove ergodicity of the Dual RAPT algorithm. In this case, since
the proposal distributions are assumed to be Gaussian, no further assumptions are
necessary.
Theorem 4.2. Assuming (A1), the Dual RAPT algorithm is ergodic to π.
Finally, we shall prove ergodicity of the full Mixed RAPT algorithm, again with
no further assumptions required since the proposals are Gaussian.
Theorem 4.3. Assuming (A1), the Mixed RAPT algorithm is ergodic to π.
Note that Theorems 4.1, 4.2, and 4.3 apply both to the single-chain versions
of RAPT / Dual RAPT / Mixed RAPT as described in Section 3, and to the
INCA/TINCA modiﬁcations as described in Section 3.1.
Theorem Proofs
For notational simplicity, we prove the theorems for the case of a single adaptive
chain, but the proofs go through virtually without change for the INCA versions of
these algorithms as described in Section 3.1, and also (by iterating) for the TINCA
versions as described in Sections 2.1 and 3.1.
To facilitate our proofs, we introduce some notation. Let γ be shorthand for all
of the parameters being adapted, e.g.
for the RAPT algorithm, while
2 , C1, C2)
for the Dual RAPT algorithm, etc. Let Γn be the actual (random) adaptive parameters in use at time n, so that PΓn is the (random) Markov chain kernel used to
update the state at time n. Write Pγ for the Markov chain kernel corresponding to a
particular ﬁxed choice γ, so that
Pγ(x, A) = P(Xn+1 ∈A | Xn = x, Γn = γ) .
A basic assumption of adaptive MCMC is that each individual kernel Pγ preserves
the stationarity of π, i.e. that
Pγ(x, A) π(dx) = π(A) ,
for ﬁxed γ, which is certainly true for the adaptive algorithms introduced here. However, when the parameters {γn} are modiﬁed during the run, then stationarity of π no
longer holds, and the resulting ergodicity is much more subtle. For a simple graphical
illustration of this, see Rosenthal .
Our proofs shall make use of Theorem 5 of Roberts and Rosenthal , which
implies that an adaptive algorithm is ergodic to π if it satisﬁes (a) the diminishing
adaption property that
|PΓn+1(x, A) −PΓn(x, A)| = 0
in probability, i.e. that the amount of adaptive change from time n to time n+1 goes
to zero as n →∞, and (b) the simultaneous uniform ergodicity property that there
is ρ < 1 with
γ (x, A) −π(A)| ≤ρn ,
n ∈N, γ ∈Y, x ∈S, A ⊆S .
So, to prove Theorem 4.1, it suﬃces to establish (9) and (10), which we do in the
following two lemmas.
Lemma 4.1. Under the conditions of the Theorem 4.1, the simultaneous uniform
ergodicity property (10) holds.
Proof. Since S is compact, by positivity and continuity we have d ≡supx∈S π(x) < ∞
and ǫ ≡min{infx,y∈S q1(x, y), infx,y∈S q2(x, y)} > 0. From (3), it follows that
qγ(x, y) ≡
1Si(x)[λ(i)
1 q1(x, y) + (1 −λ(i)
1 )q2(x, y)] ≥ǫ ,
For x ∈S and B ⊆S, denote
y ∈B : π(y)qγ(y, x)
π(x)qγ(x, y) < 1
and Ax,γ(B) = B \ Rx,γ(B). Then we have
qγ(x, y) min
π(y)qγ(y, x)
π(x)qγ(x, y), 1
qγ(x, y) min
π(y)qγ(y, x)
π(x)qγ(x, y), 1
π(y)qγ(y, x)
µLeb(dy) +
qγ(x, y)µLeb(dy)
π(y)µLeb(dy) + ǫ
π(y)µLeb(dy) = ǫ
Thus S is small since
Pγ(x, B) ≥ν(B) ,
x ∈S, γ ∈Y, B ⊆S,
where ν(B) = ǫ
dπ(B) is a non-trivial measure on S. Condition (10) then follows from
Theorem 16.0.2 of Meyn and Tweedie , with ρ = 1 −ν(S) = 1 −ǫ
Lemma 4.2. Under the conditions of the Theorem 4.1, the diminishing adaption
condition (9) holds.
Proof. Let fλ(x, y) = λq1(x, y) + (1 −λ)q2(x, y). Since S is compact, we have that
M ≡max{supx,y∈S q1(x, y), supx,y∈S q2(x, y)} < ∞. For any x ∈S1 and A ∈B(S),
1 (k)(x, y) · min
1 (k)(x, y) min
1 (k)(x, y)
1 (k)(x, y)
1 (k)(x, y) ·
1 (k)(x, y)
1 (k)(x, y)
1 (k)(x, y)
Denote the ﬁrst term Ik(x, A), the second term IIk(x, A), the third term IIIk(x, A)
and the fourth term IVk(x, A). Then we have:
|Pγk+1(x, A) −Pγk(x, A)|
|Iγk+1(x, A) −Iγk(x, A)| + |IIγk+1(x, A) −IIγk(x, A)|
|IIIγk+1(x, A) −IIIγk(x, A)| + |IVγk+1(x, A) −IVγk(x, A)|.
1 (x, y) = min
1, π(y)[λ(i)
1 (k)q1(y, x) + (1 −λ(i)
1 (k))q2(y, x)]
1 (k)q1(x, y) + (1 −λ(1)
1 (k))q2(x, y)]
|IIγk+1(x, A) −IIγk(x, A)|
1 (k+1)(x, y)α(k+1)(2)
1 (x, y) −fλ(1)
1 (k)(x, y)αk(2)
1 (x, y)|dy
1 (k+1)(x, y)α(k+1)(2)
1 (x, y) −fλ(1)
1 (k+1)(x, y)αk(2)
1 (k+1)(x, y)αk(2)
1 (x, y) −fλ(1)
1 (k)(x, y)αk(2)
1 (x, y)|dy
1 (k+1)(x, y)|α(k+1)(1)
1 (x, y) −αk(1)
1 (x, y))|dy
1 (x, y))|fλ(1)
1 (k+1)(x, y) −fλ(1)
1 (k)(x, y)|dy
|α(k+1)(1)
1 (x, y) −αk(1)
1 (x, y))|dy
1 (k+1)(x, y) −fλ(1)
1 (k)(x, y)|dy .
|α(k+1)(1)
1 (x, y) −αk(1)
1 (x, y))|dy
k+1(x, y) −
k+1(x, y) −
and |fλ(1)
1 (k+1)(x, y) −fλ(1)
1 (k)(x, y)| ≤2M|λ(1)
1 (k + 1) −λ(1)
1 (k)|. We shall prove that
limk→∞|λ(i)
1 (k + 1) −λ(i)
1 (k)| = 0; it will then follow that limk→∞|fλ(2)
k+1 −fλ(1)
and hence (again by compactness) that |IIγk+1(x, A) −IIγk(x, A)| →0.
To that end, recall that λ(i)
1 (k)+d(i)
2 (k), i = 1, 2; j = 1, 2. Therefore,
1 (k + 1) −λ(1)
1 (k + 1) + d(1)
1 (k) + d(1)
1 (k + 1)d(1)
2 (k) −d(1)
1 (k + 1) + d(1)
2 (k + 1)][d(1)
1 (k) + d(1)
(k + 1)−1{[kd(1)
1 (k) + (xk+1 −xk)2]d(1)
2 (k) −d(1)
1 (k)[kd(1)
2 (k) + (xk+1 −xk)2]}
1 (k + 1) + d(1)
2 (k + 1)][d(1)
1 (k) + d(1)
(k + 1)−1{[kd(1)
1 (k) + (xk+1 −xk)2]d(1)
2 (k) + d(1)
1 (k)[kd(1)
2 (k) + (xk+1 −xk)2]}
1 (k + 1) + d(1)
2 (k + 1)][d(1)
1 (k) + d(1)
(k + 1)(d(1)
1 (k + 1) + d(1)
2 (k + 1))
i=1 (xi −xi−1)2 .
Now, since S is compact, there are δ, ǫ > 0 such that P
(xi −xi−1)2 > ǫ | γi−1
all xi−1 and γi−1. It follows that limk→∞
i=1 (xi −xi−1)2 = ∞with probability 1,
hence that |λ(1)
1 (k + 1) −λ(1)
1 (k)| →0, and hence that |IIγk+1(x, A) −IIγk(x, A)| →0.
Similarly we can prove that |Iγk+1(x, A)−Iγk(x, A)| →0, |IIIγk+1(x, A)−IIIγk(x, A)| →
0, and |IVγk+1(x, A) −IVγk(x, A)| →0. Therefore, diminishing adaptation holds.
Proof of Theorem 4.1. In light of Lemmas 4.1 and 4.2, the result follows immediately
from Theorem 5 of Roberts and Rosenthal .
Proof of Theorem 4.2. Recall that M(c1, c2) is the set of all the k ×k positive deﬁnite
matrices M such that c1Ik ≤M ≤c2Ik. It follows from the proof of Theorem 1 in
Haario et al. that there are c1, c2 > 0 such that all the covariances C = C(t)
are in M(c1, c2).
Since S is compact, infx,y∈S, M∈M(c1,c2) qM(x, y) > 0 (where qM denotes the density function of Gaussian distribution with covariance matrix M). Hence, we have
infx,y∈S,γ∈Y qγ(x, y) > 0. Then following a similar proof to that of Lemma 4.1, one
can show that the simultaneous uniform ergodicity condition (10) holds. Similarly to
the proof of Lemma 4.2, we can prove that the diminishing adaptation condition (9)
holds for Dual RAPT. The result then follows as in the proof of Theorem 4.1.
Proof of Theorem 4.3. It follows as in the previous proof that infx,y∈S,γ∈Y qγ(x, y) >
0. Then, similar to Lemma 4.1, it follows that the simultaneous uniform ergodicity
condition (10) holds. Diminishing adaptation (9) follows similarly to Lemma 4.2. The
result then follows as in the proof of Theorem 4.1.
Simulated Examples
We study the performance of the methods proposed using a bimodal target distribution which is a mixture of two Gaussians. By varying the means and variances of the
mixture components we try to cover a wider variety of situations. Let us consider the
target distribution
π(x) = 0.5 × N(µ1, Σ1) + 0.5 × N(µ2, Σ2),
where µi are ten-dimensional vectors and Σi = (σi −ρi)I10 + ρi110, i = 1, 2, where 1d
is the d × d matrix of 1’s. The considered scenarios are:
Scenario A: ρ1 = 0.2, ρ2 = 0.3, σ1
3, µ1j = 3, µ2j = −3, 1 ≤j ≤10.
Scenario B: ρ1 = 0.2, ρ2 = 0.3, σ1
3, µ1j = 0.5, µ2j = −0.5, 1 ≤j ≤10.
Scenario C: ρ1 = −0.1, ρ2 = 0.1, σ1
3, µ1j = 3, µ2j = −3, 1 ≤j ≤10.
Scenario D: ρ1 = 0.1, ρ2 = −0.1, σ1
3, µ1j = 3, µ2j = −3, 1 ≤j ≤10.
Scenario E: ρ1 = −0.1, ρ2 = 0.1, σ1
3, µ1j = 1, µ2j = −1, 1 ≤j ≤10.
Scenario F: ρ1 = 0.1, ρ2 = −0.1, σ1
3, µ1j = 1.5, µ2j = −1.5, 1 ≤j ≤10.
It should be noted that scenarios C and D and E and F are diﬀerent due to the diﬀerent
standard deviations. In our study we chose to implement the HST algorithm , the Dual RAPT and the Mixed RAPT either for only one chain or,
within the paradigm of INCA or TINCA, for ﬁve chains in parallel.
The starting value for the i−th chain is xi,0 = (3−i, 3−i, . . . , 3−i)T for 1 ≤i ≤5
and in the case we implement any of the above algorithms using a single chain, the
starting value is x0 = (0, . . ., 0). The initial values for the covariance matrices are
Σ1 = Σ2 = I10 and Σwhole = 25I10. The HST algorithm has initial value Σ = I10. The
ǫ used in (5) and (7) is set to 0.01. The initialization period contains a total of 10,000
samples which means that in the case of ﬁve parallel chains each has an initialization
period of 2000 simulations. Throughout the simulation, in the case of Mixed RAPT,
we set β = 0.2. Under all scenarios the partition is deﬁned using S1 = P10
and S2 = P10
i=1 xi > 0. This choice produces a partition that is, in all examples,
relatively far from the optimal one.
In order to assess the performance of the algorithm we show the histograms of the
ﬁrst two and last two coordinates, i.e. x1, x2, x9, x10. In a unimodal setting one could
compare the covariance of the proposal with the optimal covariance. Unfortunately,
when the target is a mixture of unimodal distributions the optimal proposal is not
known. One can still compare the number of inter-mode transitions (switches) which
is roughly the same as the number of times the chain has crossed from S1 to S2 and
vice-versa.
Under Scenario A, after 100,000 iterations the mixture parameters of the proposal
(6) are λ(1)
= 0.681 and λ(2)
The histograms show that a single mixed RAPT chain does a much better job
at ﬁnding both modes, see Figure 6, compared to a single chain constructed using
the simpler dual RAPT algorithm, Figure 5, or the HST algorithm, Figure 7. These
results reinforce the intuitive idea that when the modes are far apart neither the HST
nor the dual RAPT are eﬃciently exploring the space. We had similar ﬁndings in all
scenarios in which the distance between the modes was large, i.e. Scenarios A, C and
Figure 5: Scenario A: Histograms of 100,000 samples obtained for X1, X2, X9, X10
using the dual RAPT algorithm.
It is important for the initial variances of Qwhole to be large enough so that during
the initialization period, both modes are visited.
For instance, under scenario D
running a single mixed RAPT algorithm with starting value x0 = (0, . . . , 0)T, β = 0.3
and Σwhole = diag(10, . . ., 10) the algorithm does not detect both modes even after an
initialization period of 10,000 samples. If we use the initial Σwhole = diag(25, . . ., 25)
then the performance of mixed RAPT is quite good. In real applications, one does not
always have this information and in that case we recommend using INCA or TINCA
to reduce the risk of missing regions with high probability under π.
For the same scenario D, we ran ﬁve parallel chains, each of them for 20,000
iterations. To test the robustness of INCA we used Σwhole = I10. The histograms of
the samples corresponding to the ﬁrst two coordinates and the last two coordinates
are as shown in Figure 9.
The results conﬁrm that, although the initial variances are small, the process is
mixing well after the initialization period. We also used TINCA with four temperature
levels T = {1, 2, 4, 8} and once again the algorithm yields the correct samples as can
Figure 6: Scenario A: Histograms of 100,000 samples obtained for X1, X2, X9, X10
with mixed RAPT.
Figure 7: Scenario A: Histograms of 100,000 samples obtained for X1, X2, X9, X10
with the HST algorithm.
Figure 8: Scenario D: Histogram of 100,000 samples obtained for X1, X2, X9, X10
using TINCA with temperatures T = {1, 2, 4, 8} for ﬁve mixed RAPT chains.
be seen from Figure 8.
In the case in which the modes are close, as speciﬁed in
Scenario B the performance of the HST algorithm is similar to that of mixed RAPT.
Our simulations also show that the number of mode switches are comparable for
both algorithms. Not surprisingly, the pattern changes when the distance between
the modes is increased, as illustrated by Figure 10.
Real Data Example: Genetic Instability of Esophageal
Cancer cells undergo a number of genetic changes during neoplastic progression, including loss of entire chromosome sections. We call the loss of a chromosome section
containing one allele by abnormal cells by the term “Loss of Heterozygosity” (LOH).
When an individual patient has two diﬀerent alleles, LOH can be detected using
laboratory assays. Chromosome regions with high rates of LOH are hypothesized
to contain genes which regulate cell behavior so that loss of these regions disables
important cellular controls.
Figure 9: Scenario D: Histogram of 100,000 samples obtained for X1, X2, X9, X10
using ﬁve parallel mixed RAPT chains.
Figure 10: Scenario E: Number of switches for the HST algorithm (dotted line) and
for the mixed RAPT (solid line).
To locate “Tumor Suppressor Genes”(TSGs), the Seattle Barrett’s Esophagus research project has collected LOH rates from esophageal cancers
for 40 regions, each on a distinct chromosome arm. A hierarchical mixture model has
been constructed by Warnes in order to determine the probability of LOH for
both the “background” and TSG groups. The labeling of the two groups is unknown
so we model the LOH frequency using a mixture model, as described by Desai .
We obtain the hierarchical Binomial-BetaBinomial mixture model
Xi ∼ηBinomial(Ni, π1) + (1 −η)Beta-Binomial(Ni, π2, γ),
with priors
η ∼Unif ,
π1 ∼Unif ,
π2 ∼Unif ,
γ ∼Unif[−30, 30],
where η is the probability of a location being a member of the binomial group, π1 is
the probability of LOH in the binomial group, π2 is the probability of LOH in the
beta-binomial group, and γ controls the variability of the beta-binomial group. Here
we parameterize the Beta-Binomial so that γ is a variance parameter deﬁned on the
range −∞≤γ ≤∞. As γ →−∞the beta-binomial becomes a binomial and as
γ →∞the beta-binomial becomes a uniform distribution on . This results in
the unnormalized posterior density
π(η, π1, π2, γ|x) ∝ΠN
i=1f(xi, ni|η, π1, π2, ω2)
on the prior range, where
f(x, n|η, π1, π2, ω2)
1(1 −π1)n−x +
ω2)Γ( 1−π2
Γ(n −x + 1−π2
Whole space
Table 1: Simulation results for the LOH data.
2(1+eγ). In order to use the random walk Metropolis we have used the logistic
transformation on all the parameters with range . However, all our conclusions
are presented on the original scale for an easier interpretation.
Using the optimization procedures used by Warnes we determine that
the two modes of π are reasonably well separated by the partition made of S1 =
{(η, π1, π2, γ) ∈ × × × [−30, 30]|π2 ≥π1} and S2 = {(η, π1, π2, γ) ∈
 × × × [−30, 30]|π2 ≤π1}.
Simulation results
We have run ﬁve parallel mixed RAPT algorithms to simulate from π using the
partition S1 ∪S2. The initialization period contained 5,000 iterations for each chain.
The covariance matrices were initialized as Σ1 = Σ2 = 0.1I4 and Σwhole = 20I4. After
50, 000 iterations from each chain, we obtain λ(1)
= 0.923 and λ(2)
= 0.412. The
estimates for the parameters of interest are shown in Table 5.2.1.
Figure 11 gives a two dimensional scatterplot of the (π1, π2) samples.
similar to the ﬁndings of Warnes (Figure 8). To illustrate the exchange of
information between the parallel the chains, we use the BGR diagnostic statistic,
R. When the BGR R statistics is close to to 1, we can assume all chains have the
same information regarding π. For this example, after 20,000 iterations the BGR’s R
statistics stabilizes below 1.1 as one can see in Figure 12.
To compare the performance of the mixed RAPT with and without INCA we
Figure 11: Scatterplot of the 250,000 samples for (π1, π2).
Figure 12: LOH Data Example: The evolution of BGR’s R statistics for 5 mixed
RAPT chain; the dotted line represents the threshold 1.1.
Figure 13: The total number of switches times for the ﬁve parallel Mixed RAPT chains
(run for 60,000 iterations each) vs the number of switch times of a single Mixed RAPT
(run for 300,000 iterations).
monitor the number of switches between S1 and S2. We run a single Mixed RAPT
algorithm for 300,000 iterations, and independently ﬁve parallel Mixed RAPT algorithms for 60,000 iterations each. In Figure 13 we plot the total number of switches
for the ﬁve parallel processes up to time t and the switch time for the single run up
to time 5t for a fair comparison. One can see that the Mixed RAPT performs better
together with INCA than by itself.
Conclusions and Further Work
This work is concerned with the practical aspects of adaptive MCMC, particularly
related to sampling from multimodal distributions. The aim for most of our theoretical results is the adaptive random walk Metropolis since it is one of the most
used algorithms in practice. The inter-chain adaptation strategy is widely applicable
and could be used for a large number of adaptive MCMC algorithms with signiﬁcant
potential gains. The regional adaptation algorithm proposed here has been discussed
in the context of two separate regions. Evidently, the construction can be generalized
but one has to keep in mind that besides good sampling properties within each region
the sampler should be also required to visit all regions often enough. In the case of
many regions this could present complications.
Acknowledgment
The authors acknowledge the support of the Natural Sciences and Engineering
Research Council of Canada. We thank Gregory Warnes for discussion and for generously providing the data set used in section 5, and Xiao-Li Meng and Eric Moulines
for helpful discussions and suggestions. We are grateful to two referees, one Associate
Editor and the Editor for a set of thorough and very helpful reviews.