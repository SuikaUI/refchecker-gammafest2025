Machine learning force ﬁelds: Construction,
validation, and outlook
V. Botu,∗,† R. Batra,‡ J. Chapman,¶ and R. Ramprasad‡
Department of Chemical & Biomolecular Engineering, University of Connecticut, Storrs, CT,
Department of Materials Science & Engineering, University of Connecticut, Storrs, CT, and
Department of Materials Science, University of Connecticut, Storrs, CT
E-mail: 
Force ﬁelds developed with machine learning methods in tandem with quantum mechanics
are beginning to ﬁnd merit, given their (i) low cost, (ii) accuracy, and (iii) versatility. Recently,
we proposed one such approach, wherein, the vectorial force on an atom is computed directly
from its environment. Here, we discuss the multi-step workﬂow required for their construction,
which begins with generating diverse reference atomic environments and force data, choosing a
numerical representation for the atomic environments, down selecting a representative training
set, and lastly the learning method itself, for the case of Al. The constructed force ﬁeld is
then validated by simulating complex materials phenomena such as surface melting and stressstrain behavior - that truly go beyond the realm of ab initio methods both in length and time
scales. To make such force ﬁelds truly versatile an attempt to estimate the uncertainty in force
predictions is put forth, allowing one to identify areas of poor performance and paving the way
for their continual improvement.
∗To whom correspondence should be addressed
†Department of Chemical & Biomolecular Engineering, University of Connecticut, Storrs, CT
‡Department of Materials Science & Engineering, University of Connecticut, Storrs, CT
¶Department of Materials Science, University of Connecticut, Storrs, CT
 
Introduction
Materials modeling approaches largely fall in two broad categories: one based on quantum mechanical methods (e.g., density functional theory), and the other based on semi-empirical analytical interatomic potentials or force ﬁelds (e.g., Stillinger-Weber potentials, embedded atom method,
etc.)1–7 Choosing between the two approaches depends on which side of the cost-accuracy tradeoff ones wishes to be at. Quantum mechanical methods (also referred to as ab initio or ﬁrst principles methods) are versatile, and offer the capability to accurately model a range of chemistries
and chemical environments. But such methods remain computationally very demanding. Practical
and routine applications of these methods at the present time are limited to studies of phenomena
whose typical length and time scales are of the order of nanometers and picoseconds, respectively.
Semi-empirical methods capture the essence of these interatomic interactions in a simple manner
via parameterized analytical functional forms, and thus offer inexpensive solutions to the materials
simulation problem. However, their applicability is severely restricted to the domain of chemistries
and chemical environments intended, or considered during parameterization.8 It is unclear whether
the underlying framework allows for a systematic and continuous improvement in the predictive
capability of newer environments.
The present contribution pertains to a data-driven approach by which ﬂexible and adaptive force
ﬁelds may be developed, potentially addressing the challenges posed. By using carefully created
benchmark data (say, from quantum mechanics based materials simulations) as the starting point,
non-linear associations between atomic conﬁgurations and potential energies (or forces, more pertinent to the present contribution) may be learned by induction.9–11 This data-driven paradigm,
popularly referred to as machine learning, has been shown by many groups to lead to viable pathways for the creation of interatomic potentials that; (1) surpass conventional interatomic potentials
both in accuracy and versatility, (2) surpass quantum mechanical methods in cost (by orders of
magnitude), and (3) rival quantum mechanics in accuracy,12–14 at least within the conﬁgurational
and chemical domains encompassed by the benchmark dataset used in the training of the potential.
A new recent development within the topic of machine learning based interatomic potentials
is the realization that the vectorial force experienced by a particular atom may be learned and
predicted directly given just a conﬁguration of atoms.15–17 This capability is particularly appealing
as the atomic force is a local quantity purely determined by its local environment, in contrast to
the total potential energy which is a global property of the system as a whole. A large body of
materials simulations, such as geometry optimization and molecular dynamics simulations, require
the atomic force as the sole necessary input ingredient.1 Note that partitioning the total potential
energy into individual atomic contributions, conventionally adopted in semi-empirical interatomic
potentials, is a matter of convenience of construction, rather than being a fundamental requirement.
Figure 1: Flowchart illustrating the workﬂow in constructing AGNI force ﬁelds - generating reference atomic conﬁgurations and forces with quantum mechanical methods, ﬁngerprinting atomic
environments, rational selection of training and test datasets, mapping atomic ﬁngerprints to forces
using machine learning methods, and quantifying uncertainty in predictions made.
This article deals speciﬁcally with using machine learning methods to create an atomic force
prediction capability, i.e., a force ﬁeld. As recently pointed out, this force ﬁeld is Adaptive (i.e.,
new conﬁgurational environments can be systematically added to improve the versatility of the
force ﬁeld, as required), Generalizable (i.e., the scheme can be extended to any collection of elements for which reliable reference calculations can be performed), and is Neighborhood Informed
(i.e., a numerical ﬁngerprint that represents the atomic environment around the reference atom is
mapped to the atomic force with chemical accuracy).15,16 The force ﬁeld is henceforth dubbed
The workﬂow in constructing AGNI force ﬁelds includes ﬁve key steps. These include: (1)
creation of a reference dataset derived from a plethora of diverse atomic environments of interest
and the corresponding atomic forces computed using a chosen quantum mechanical method, (2)
ﬁngerprinting every atomic environment in a manner that will allow the ﬁngerprint to be mapped to
atomic force components, (3) choosing a subset of the reference dataset (the “training” set) using
clustering techniques to optimize the learning process while insuring that the training set represents
the diversity encompassed by the original reference dataset, (4) learning from the training set, thus
leading to a non-linear mapping between the training set ﬁngerprints and the forces, followed
by testing the learned model on the remainder of the dataset using best-statistical practices, and
(5) ﬁnally, estimation of the expected levels of uncertainty of each force prediction, so that one
may determine when the force ﬁeld is being used outside its domain of applicability. The entire
workﬂow involved in the construction of AGNI force ﬁelds is portrayed schematically in Figure 1.
In our previous work, a preliminary version of the AGNI force ﬁeld for Al was used to demonstrate its capability with respect to predicting structural, transport or vibrational properties of materials.16 Here, we further extends its scope, by including more diverse atomic environments and
its ability to simulate even more complex phenomena - such as surface melting and stress-strain
behavior. Furthermore, although AGNI is built to provide atomic forces, we demonstrate that accurate total potential energies can be retrieved either during the course of a molecular dynamics
simulation or along a reaction coordinate, through appropriate integration of atomic forces.
Additional comments pertaining to the last step of the workﬂow in Figure 1 are in order. Uncertainty quantiﬁcation is essential to recognize when the force ﬁeld is operating outside its domain
of applicability. Ideally, larger the uncertainty of the force prediction for an atom in a given environment, greater is the likelihood that the environment is “new". By imposing a threshold and
monitoring the uncertainty we may wish to augment the training set with the corresponding new
atomic environment(s), and follow the workﬂow in Figure 1. This helps build force ﬁelds that are
truly adaptable. Initial steps towards quantifying this uncertainty in force predictions are undertaken.
The rest of the paper is organized as follows. In the ﬁrst half of the work we guide the readers
through the rigors of each step in the force ﬁeld construction workﬂow, shown in Figure 1, to
develop a general-purpose Al force ﬁeld. The applicability of the force ﬁeld is then validated by
demonstrating its use in atomistic simulations. A discussion on measures to estimate uncertainties
in force predictions made is then put forth. Lastly, we conclude with an outlook on using machine
learning force ﬁelds in the ﬁeld of atomistic materials modeling, and the challenges that yet remain
to be addressed.
Generating reference data
The construction of AGNI force ﬁelds begins with data. We start by building several periodical
and non-periodical equilibrium conﬁgurations (c.f., Figure 2), such as; (i) defect free bulk, (ii)
surfaces, (iii) point defects - vacancies and adatoms, (iv) isolated clusters, (v) grain boundaries,
(vi) lattice expansion and compression, and (vii) edge type dislocations. These conﬁgurations are
so chosen to mimic the diverse environments an atom could exist in, and forms a critical ﬁrst
step in constructing generalizable force ﬁelds. It is by no means a complete list and one could
continuously add non-redundant conﬁgurations to it (methods to identify such redundancies are
discussed later). The vectorial force components on each atom, in the equilibrium conﬁgurations
amassed, are then computed by quantum mechanical based density functional theory (DFT) calculations.18,19 To correctly describe the non-equilibrium behavior of an atom, in response to a
perturbation due to thermal vibrations, pressure or other sources, it is equally necessary to construct non-equilibrium atomic environments - to learn the complete array of forces experienced by
an atom. A convenient and quick means to sampling such non-equilibrium environments is with ab
initio molecular dynamics (MD) simulations.20 Here, starting with the equilibrium conﬁgurations
in Figure 2 constant temperature MD simulations were carried out across a range of temperatures
between 200 - 800 K, resulting in a diverse set of reference atomic environments and forces (c.f.,
Table 1) - needed to learn (indirectly) the underlying potential energy surface.
Figure 2: Reference conﬁgurations used to sample atomic environments for training and testing
of AGNI force ﬁelds; (i) bulk, (ii) surfaces, (iii) defects (vacancies and adatoms), (iv) isolated
clusters, (v) grain boundaries, (vi) lattice expansion and compression, and (vii) dislocation.
Table 1: Atomic environment makeup for the ﬁve datasets; A, B, C, D and E. For each dataset we
generate a training and test set (except for dataset E, where only a test set is created) - the former
used to construct the force ﬁeld and the later to validate it. The number of new environments added
is indicated in the last column.
Atomic Envs. from Reference Conﬁgurations
Number of Envs.
Defect free bulk fcc and bcc.
Dataset A +
(100), (110), (111), (200), and (333) surfaces.
Dataset B +
Defects in bulk fcc with 1, 2 and 6 randomly
distributed vacancies and adatom on (100),
(110) and (111) surfaces.
Dataset C +
Isolated clusters of 5Å, 8Å, 10Å, and 12Å.
Σ3 (111), Σ5 (210), Σ5 (310), Σ13 (320), and Σ13 (510) grain
boundaries, varying lattice vectors by ±7 % of equilibrium,
edge dislocation along (11¯2) direction.
From within the millions of reference atomic environments collected, a subset of them are
chosen as training environments to construct the force ﬁelds. The particular choice of environments
plays a critical role in the generalizability of such data-driven force ﬁelds. To better understand
such limits imposed by data choices we construct four datasets, labeled as A, B, C, and D, with
increasing complexity and diversity of atomic environments contained (c.f., Table 1). For each
dataset, training and test sets were created - the former used to construct the force ﬁeld and the
later used to validate its predictive prowess. Also a ﬁfth dataset, E, consisting of conﬁgurations
never used during force ﬁeld construction (see Table 1) was created, solely to demonstrate the
transferability of AGNI force ﬁelds.
All force and MD calculations were done using VASP - a plane-wave based DFT software.21,22
The PBE functional to treat the electronic exchange-correlation interaction, the projector augmented wave potentials, and plane-wave basis functions up to a kinetic energy cutoff of 520 eV
were used.23,24 A 14×14×14 Γ-centered k-point mesh was used for the primitive Al unit cell, and
scaled according to the unit cell size. A timestep of 0.5 fs was chosen for the MD simulations.
Fingerprinting reference environments
Choosing a representation for an atom and it’s environment is the most critical step in the entire
workﬂow. In order to learn the vectorial force components, Fu, where u refers to any arbitrary
direction, necessitates a numerical representation that conforms with this directional dependence.
Further, it should also remain invariant to the basic atomic transformation operations, such as translation, rotation or permutation. One such representation (commonly referred to as as ﬁngerprint)
with the necessary prerequisites is given below,
· fd(ri j).
Here, ri j is the distance between atoms i and j (||rj −ri||), while ru
i j is a scalar projection of
this distance along a direction u (c.f., Figure 3). η is the Gaussian function width.
fd(ri j) =
is a damping function for atoms within the cutoff distance (Rc), and is zero
elsewhere. The summation in Eq. ?? runs over all neighboring atoms within an arbitrarily large Rc
(8 Å, in the present work).
Figure 3: A schematic demonstrating the scalar projection for an atom i (the reference atom) and
one of its neighbor (1) along a direction u. To generate the ﬁnal ﬁngerprint for atom i, a summation
over the atoms within the cutoff sphere, as indicated by the dashed line, are considered.
To better understand the ﬁngerprint described in Eq. ??, one can deconvolute it into three subcomponents (as separated by “·"). The exponential term (e−
) imposes a coordination shell
around an atom i with η describes the extent of the shell. By using multiple such η values both
nearby and distant coordination information are contained within the ﬁngerprint. In this work, η’s
were sampled on a logarithmic grid between [0.8Å, 16Å], ensuring a sufﬁcient description of the
neighbor interactions. One could also use the peak positions of a radial distribution function as
a starting point in choosing the η values. The normalized scalar projection term (
ri j ) adds directionality to the ﬁngerprint by selectively resolving the coordination information along the desired
direction (u), and is necessary to map the individual force components. Lastly, the damping function ( fd(ri j)) diminishes the inﬂuence of far away atoms smoothly. The combination of these three
features makes this particular choice of representation suitable for mapping atomic force components. Similar coordination based ﬁngerprints have been developed in the past.12,25 However, these
were tailored for the purpose of mapping the total potential energy (a scalar quantity) for a given
conﬁguration of atoms, unlike the vectorial force components as done here.
Further, the atomic ﬁngerprint representation chosen conforms with the required invariance operations, such as permutation, translation, and rotation of atoms. For instance consider a reference
atom, i, and its neighboring atoms within a cutoff sphere (as shown in Figure 3). Information pertaining to atoms neighboring atom i is passed into the summand of Eq. ?? as pair-wise distances,
thereby, permutation or translation of atoms does not alter V u
i . In the case of rotations, both the
ﬁngerprint and vectorial force components change in a manner governed by the rotation matrix.
For example, by rotating atoms along the z-axis one can redeﬁne the forces (shown here for the
force but equally applicable to the ﬁngerprint) along the Cartesian directions as,
Nevertheless, the magnitude of the net force before and after rotation remains the same, as one
would expect. The concurrence to this rotational behavior implies that both the forces and ﬁngerprints transform in an identical manner upon rotation, as needed to capture the directional behavior
of forces. Another important aspect of the ﬁngerprint is that it remains unique for the diverse
atomic environment situations. Numerically this implies that identical ﬁngerprints should map to
the same atomic force value. Here, we do this by using multiple η values. In the limit that number
of η values tends to ∞uniqueness can be ensured, nevertheless, for all practical purposes one can
make do with a much smaller subset, as determined by running convergence tests.
Now, using Eq. ?? the atomic ﬁngerprint along the Cartesian directions for each atom within
the database is computed (since the force components obtained from DFT are along the Cartesian
directions). By taking advantage of the rotational behavior, further, for each atom several arbitrary
directions (u in Figure 3) are deﬁned along a spherical mesh for which the atomic force and ﬁngerprint are reconstructed. By doing so, the pre-existing ab initio reference database can be expanded
upon with no additional costly ab initio calculations. Though such an undertaking ensures diversity
and completeness in the reference atomic environments it builds in extensive redundancies. Training a force ﬁeld on millions of reference atomic environments is impractical, computationally very
demanding, and might lead to misbehaved models, therefore, further down-sampling from within
this big pool of data is an essential step in the construction workﬂow.
Clustering reference data
The next step in the construction workﬂow is to select a representative set of atomic environments
for training purposes. To do so, it is necessary to identify the redundant and non-contributing data
points from within the millions sampled. An obvious place to start is by comparing amongst the individual atomic ﬁngerprints. However, given its high-dimensionality understanding or unraveling
the ﬁngerprint directly is non-trivial. Therefore, we rely on dimensionality reduction techniques
such as principal component analysis (PCA) to project V u
i onto a lower dimension space.26
In PCA the original atomic ﬁngerprint is linearly transformed into uncorrelated and orthogonal
pseudo variables, also known as principal components (PCs). Often times the information content
contained within the original ﬁngerprint can be captured by a few such PCs. To demonstrate this,
here, for all the reference atomic environments we compute and transform an 8-dimensional ﬁngerprint (the rationale for which shall be discussed shortly). Two such PCs captured more than 99% of
the information content of the original ﬁngerprint, allowing us to visualize the atomic environments
on a two-dimensional manifold known as a scores plot (c.f., Figure 4). Immediately, we observe
clustering of the atomic ﬁngerprints that correspond to similar neighborhood environments. For
clarity environments corresponding to a few such cases, e.g. adatoms, surfaces, vacancies, etc., are
labeled. Further, by color coding atoms according to the dataset they were sampled from, i.e. A,
B, C, D or E, we qualitatively observe their extent of diversity. For instance, dataset D (c.f., Figure
4) spans a diverse set of atomic environments as it populates majority of the space, suggesting that
isolated cluster conﬁgurations are a good starting point to sample reference data from. Interestingly, atomic environments from dataset E lie within the domain of dataset D. This suggests that a
force ﬁeld trained on dataset D should accurately predict the forces for environments in dataset E,
though they were never explicitly included during training.
Thus far, the dimensionality reductions methods used provided a visual means to identifying redundancies, but for an efﬁcient force ﬁeld construction an automated sampling of the nonredundant training environments is necessary. One way of doing so is to choose the data randomly. Unfortunately, this biases sampling according to the underlying probability distribution of
the dataset and fails to sample sparsely populated regions. To avoid such irregularities, here we
adopt a simple grid-based sampling on the PCA space. The PCA transformed data is split into
uniform sub-grids, the bounds of which are determined by the minimum and maximum of the relevant PCs (which can be more than 2). Training points are then randomly sampled from within
each sub-grid. By using a ﬁne grid one can ensure uniform and diverse sampling from all regions
of the PC space. Note that in the limit the grid size becomes large this approach is equivalent to the
random sampling approach. Also, the test sets for validation purposes are generated in a similar
manner from the remaining non-sampled data. Other dimensionality reduction algorithms, such
Figure 4: A projection of an 8 dimensional (i.e., 8 η values) atomic ﬁngerprint for all entries within
dataset A, B, C, D, and E onto a 2-dimensional manifold, transformed by principal component
analysis. Identical atomic environments cluster together and highlights the extent of redundancies
within the reference dataset.
as kernel-PCA27 or multi-dimensional scaling,28 could similarly be adopted to sample for a representative dataset. Irrespective of the choice, such clustering methods are critical as the learning
and prediction cost scales as O(n3) and O(n), respectively (where n is the training dataset size).
Learning algorithm
The next vital ingredient required in putting together a predictive framework is the learning algorithm itself. Deep learning neural networks29 and non-linear regression processes13 have been the
methods of choice for models describing atomic interactions. Their capability to handle highly
non-linear relations, as is in the case of mapping an atom’s environment to the force it experiences, makes them a suitable choice here as well. Here, we choose non-linear kernel ridge regression (KRR) method as the machine learning workhorse.11,30 KRR works on the principle of
(dis)similarity, wherein, by comparing an atom’s ﬁngerprint (V u
i (η)) with a set of reference cases,
an interpolative prediction of the uth component of the force (Fu
i ) can be made,
Here, t labels each reference atomic environment, and V u
t (η) is its corresponding ﬁngerprint.
Nt is the total number of reference environments considered. du
i,t = ||V u
i (η) −V u
t (η)||, is the Euclidean distance between the two atomic ﬁngerprints, though other distance metrics can be used.
αts and l are the weight coefﬁcients and length scale parameter, respectively. The optimal values
for αts and l are determined during the training phase, with the help of cross-validation and regularization methods. For further details concerning the learning algorithm the reader is directed to
these sources.10,31,32
Finally, in order to evaluate the performance of a developed force ﬁeld, three error metrics;
mean absolute error (MAE), maximum absolute error (MAX), and the standard deviation (in particular 2σ), were chosen. Relying on multiple metrics reduces any bias, unknowingly, introduced
during model selection as shall be discussed shortly.
Constructing the force ﬁeld
At this stage all the pieces required to construct AGNI force ﬁelds, as illustrated by the ﬂowchart in
Figure 1, have been laid out. In the upcoming sections we discuss how one chooses the appropriate
number of η values to adequately describe an atomic environment, and the minimum number of
training environments to use, as needed to construct accurate force ﬁelds. The accepted force ﬁeld
is then put to test by predicting forces on atoms outside the domain of training environments used,
to ensure its generalizability.
Convergence tests
The ﬁrst step to attaining an optimal force ﬁeld is to ensure convergence with respect two parameters: (i) the number of η values used for the atomic ﬁngerprint, and (ii) the training dataset size.
As mentioned earlier the number of η values governs the resolution with which an atom’s local
coordination environment is described, while, the size (and choice, as shall be elaborated in the
next section) of training data governs AGNI’s interpolative predictive capability. In order to identify this optimal parameter set, we systematically increase the ﬁngerprint resolution from 2 to 16
η values and the training dataset size from 100 to 2000 atomic environments, while monitoring
test set error (in this case the chosen error metric was the MAE). To remind the reader, η values
were sampled on a logarithmic grid between [0.8Å, 16Å], while training data environments were
sampled using the PCA projection followed by a grid-based sampling.
For each of the four training datasets (A, B, C and D), partitioned in the data generation stage,
and for all combinations of the convergence parameters an AGNI force ﬁeld was constructed.
Each force ﬁeld is then validated on the respective test datasets (A, B, C, D and E). The force ﬁelds
are denoted as M j
i , where i and j label the training and test environments used, respectively (the
superscript is omitted when referring to the training environments only). Figure 5 illustrates heat
Figure 5: Heat maps illustrating model error (mean absolute error) as a function of number of eta
values and the training dataset size. The ﬁngerprint was varied from 2 to 16 η values, while the
training dataset size was varied from 100 to 2000 environments. We report the MAE for models
trained on datasets A, B, C, and D and tested on datasets A, B, C, D, and E. For example the top
row corresponds to models trained on dataset A, while each column corresponds to a test datasets
of the ﬁve cases. The errors quickly converge for a ﬁngerprint with 8 η values and a training size
of 1000 diverse environments.
maps of the error for different training and test datasets, and convergence parameter combinations.
Two key ﬁndings stand out: (i) by increasing the ﬁngerprint resolution the error drops and quickly
converges below ≈0.05 eV/Å (expected chemical accuracy), and (ii) increasing the training dataset
size reduces error only beyond a reasonable ﬁngerprint resolution. For example, in MA
C increasing
the training dataset size for a ﬁngerprint with 2 or 4 η values has no effect on the predictive
capability. Such a manifestation implies that 8 or more η values are required to “uniquely” discern
amongst the atomic environments, in order for the learning algorithm to work. Nevertheless, this
relation only holds for force ﬁelds used in an interpolative manner, as seen in the failure of MB
A . Here, the diversity in the training data chosen plays a more prominent role in governing
performance, as shall be elaborated in the next section. Overall, we ﬁnd that a ﬁngerprint of 8 η
values and a training size of 1000 atomic environments is sufﬁcient, beyond which the models
exhibit diminishing returns, i.e. increased model training costs with no signiﬁcant drop in model
error, and are the parameters chosen for all subsequent discussions. The computational burden of
each AGNI prediction is ≈0.1ms/atom/core, while DFT costs ≈1ks/atom/core.
Training data choice
Figure 6: (a) Mean absolute error, (b) maximum absolute error, and (c) 2 * standard deviation
error metric, for models trained on A, B, C and D and tested on dataset A, B, C, D and E. The
errors are reported for an 8 dimensional ﬁngerprint vector (i.e., 8 η values) chosen to represent the
environment around an atom, and a training set size of 1000 environments obtained from the PCA
grid-based sampling.
The particular choice of atomic environments included during training is a crucial factor, as
brieﬂy alluded to earlier. Given that the learning algorithm is interpolative by nature, a force ﬁeld
trained say only on bulk type environments (MA) cannot predict the forces corresponding to other
environments types, e.g. datasets with surfaces and other features - MB
increasing the diversity in training environments, MB, MC and MD, we make the force ﬁelds more
generalizable once the optimal parameters are chosen, as given by their low test error in Figure
5. Surprisingly, it appears as though predictions made with MB are equally as good as MC or MD.
However, this is purely a manifestation of using the MAE as the error metric. Along with the MAE,
we report test set errors computed with two other metrics - MAX and 2σ, as illustrated in Figure
6 (shown only for the optimal 8-component ﬁngerprint and 1000 training atomic environments).
For MB, with MAX as the metric, the prediction error is high outside its domain of applicability
(test set C, D or E), and a similar behavior is observed for MC. It should be recognized that MAX
reports the worst prediction made, while MAE reports a mean error skewed by test set size. By
combining the two metrics with the actual variance in the errors, as measured by the 2σ metric,
we can ensure that the error is indeed under control. We observe that in MD, by sampling atomic
environments from a very diverse set of conﬁgurations all the error metrics are low, and the force
ﬁeld is highly generalizable, and is the force ﬁeld used in subsequent discussions.
Testing out of domain conﬁgurations
The conﬁgurations contained in dataset E, grain boundaries, lattice expansion and compression,
and dislocations, were never “observed” during the training phase. Being able to accurately predict
the forces will further demonstrate the ﬁdelity in using a local-neighborhood based force predictive
capability. The PCA scores plot, shown in Figure 4, provided a glimpse of what one could expect.
Given that the transformed atomic ﬁngerprints for dataset E lies within the domain of environments
from dataset D, one can expect the force predictions made by MD to be interpolative, and thus
accurate. However, a more stringent test is to predict forces on all the atoms in dataset E and
compare them to those obtained by DFT methods. As is done and shown in Figure 7. For all
three cases, the AGNI predicted forces are in excellent agreement with DFT. This demonstrates the
intended goal of AGNI force ﬁelds, i.e. to retain quantum mechanical accuracy, be computationally
Figure 7: Parity plots comparing force predictions, for test environments in dataset E, made with
the AGNI model, MD, EAM interatomic potential, and DFT. The plots have been further separated
according to the conﬁguration they were sampled from, (a) grain boundaries, (b) lattice expansion/compression, and (c) edge dislocation, respectively.
inexpensive, and remain generalizable. The last feature in particular, generalizability, is often
lacking with traditional semi-empirical methods. For comparison, we recompute the forces for
atoms in dataset E using traditional semi-empirical potentials. Here, we particularly use an Al
EAM potential,33 as it accurately captures interactions in close-packed metallic type systems. As
with AGNI force ﬁeld, EAM methods equally predict forces accurately for grain boundaries and
lattice expansion/compression but fails for dislocation type of environments.8
Validating the force ﬁeld
Having demonstrated a robust scheme that allows accurate atomic force predictions for a diverse
set of situations, in the subsequent sections, we demonstrate the true prowess of such AGNI force
ﬁelds in facilitating atomistic simulations. Our previous work provided a glimpse of such simulations, whereby, structural optimization, vibrational property estimation, and simple MD simulations of materials were undertaken.16 Here, we extend the realm of such force ﬁelds to simulate
more complex atomistic phenomena, such as surface melting and stress-strain behavior. These are
particularly challenging as the atoms traverse through a multitude of environments, and an accurate
prediction of the forces requires undertaking the rigorous construction workﬂow discussed thus far.
The simulations were carried out using the LAMMPS molecular dynamics code.34 The source
code and force ﬁeld ﬁles required to carry out the simulations are provided as supplemental ﬁles.
Melting behavior of an Al (111) surface
Figure 8: (a) A schematic of the (111) Al surface model and the regions classiﬁed as surface or
bulk atoms. (b) The Lindemann index (LI) as function of temperature simulated with both the
AGNI and EAM force ﬁelds. Melting occurs once the LI transitions from a slow linear increase to
a sudden spike. With the AGNI force ﬁeld the surface begins to melt ∼950 K, and propagates to
the bulk by ∼1100 K.
The melting temperature of condensed matter is a property often estimated by MD simulations.
Here, starting with a surface model with over 1000 atoms and dimensions of 19 Å × 17 Å (c.f.,
Figure 8(a)), constant temperature MD simulations were carried out for over 50 ps and across
a temperature range of 300 - 1300 K, to estimate the melting temperature. In traditional MD
simulations energy is used as the metric to distinguish between a solid and liquid state. Since this
metric is not at our disposal we rely on the Lindemann Index (LI) order parameter instead. The
LI measures the thermal perturbations of atoms - for solids this value is around ≈0.03 while for
liquids it is ≈0.13. A sudden increase in the LI as a function of temperature is attributed to a
solid-liquid phase transition, and can thus be utilized in MD simulations to estimate the melting
temperature.35–37 The LI is deﬁned as,
i j⟩−⟨ri j⟩2
where ri j is the distance between atom i and j, N is the total number of atoms, and ⟨..⟩indicate
time averaged quantities.38 For the range of temperatures considered the LI was computed using
Eq. ?? and reported in Figure 8(b) (red lines). Further, we distinguish between the surface and bulk
LI values (c.f., 8(a)) as it is well known that the melt front initiates at the surface and propagates
inwards. Starting at 300 K, the LI rises due to a systematic increase in thermal vibrations up to 900
K. Between 900 - 1000 K, the sudden increase in LI signiﬁes the onset of surface melting, which
then propagates into the bulk by 1200 K. With AGNI force ﬁelds this onset of melting is observed
at ∼950 K, similar to the known experimental value at ∼933 K for Al.39 Even though the training
environments used in building MD did not explicitly contain Al in a liquid state, by including high
temperature MD reference data we were able to predict forces for environments in such extreme
conditions. Similar LI curves computed by an EAM force ﬁeld, as pure ab initio studies of this
size and timescale are intractable, yielded an overestimated melting temperature of ∼1100 K.
Stress-strain behavior of an Al (001) surface
Another important material property determined by atomistic simulations is the stress-strain behavior. Beginning with a (001) fcc Al surface, of dimensions 8 Å × 8 Å × 80 Å, the surface atoms
(ﬁxed in their position) are displaced, ∆l, resulting in a uniaxial strain along the surface normal
 as illustrated in Figure 9(a). Atoms within the strained region are then relaxed to minimize
the forces acting upon them. This imposes a net force (Fs) on the ﬁxed surface atoms towards the
bulk (c.f., Figure 9(a)). Using the stress tensor relation, σs,p = Fs
Ap, for a plane p with an area Ap,
across varying values of strain, εs,p = ∆l
l0 , one can deduce the stress-strain behavior of the material. In Figure 9(b) we report the computed stress for varying strain deformations. The slope of
this curve, for the direction considered, yields the C11 elastic coefﬁcient, a property that can be
compared with atomistic theories. Using the AGNI force ﬁeld we report a C11 value of 107 GPa,
Figure 9: (a) A schematic of the surface model and procedure adopted to extract stress-strain behavior. (b) Stress vs. strain behavior of uni-axially strained Al as computed using forces predicted
by the AGNI and an EAM force ﬁeld. The inset shows stress at low strain (< 0.35 %).
which is in good agreement with a past ab initio result of 105 GPa.40 Clearly, this suggests that
besides forces the force ﬁeld can predict their derivatives, i.e., the stresses, at quantum mechanical
accuracy as well. Further, we recomputed the C11 value with an EAM potential, resulting in a
value of 106 GPa. Though, the combination of AGNI force prediction and stress relation result in
quantum mechanically accurate elastic coefﬁcients, the procedure laid out can only describe the
stress along non-periodical directions, a limitation of the force based implementation.
Energy prediction
We now brieﬂy touch upon the topic of energy. Energy is a unique, and important, global quantity
describing the state of a conﬁguration of atoms. It is often used to ensure stable MD simulations,
estimate phase diagrams, compute minimum energy reaction pathways, etc. Given the principium
of AGNI, whereby, the force on an atom is learnt based on its environment deprives the means to
predicting energy directly. Nevertheless, we now discuss some alternative strategies to estimating
energy, be it in dynamic or static simulations.
During a molecular dynamics simulation
The rate of change of the total potential energy, in an MD simulation, can be expressed as a function
of the individual atomic forces and velocities by invoking the chain rule,
E is the total potential energy of the system, ru
i are the position and velocity of atom i
along one of the three coordinates, u ⊂(x,y,z). In the limit that ∂t →0, in Eq. ??, an analytical
expression for the rate of change in energy for inﬁnitesimally small time difference (∆t), albeit
from the initial conﬁguration, can be expressed as,
Et = Et−∆t −∆t
In MD simulations this translates to choosing a small time step to ensure accurate force integrations, and minimize numerical noise propagation, providing a pathway to indirectly monitor the
energy evolution during the course of the simulation.
To validate this scheme, constant temperature MD simulations of bulk fcc Al (∼250 atoms)
were carried out at different temperatures using the MD AGNI force ﬁeld. A timestep of 0.5 fs was
chosen. Using the reference forces and velocities, along with Eq. ??, the rate of change in energy
was computed as a function of time. The results are plotted in Figure 10(a). Clearly, the computed
energies (from AGNI predicted forces) is conserved in time and maintains the correct ordering as
a function of temperature. Note that the change in energy is reported with reference to the starting
conﬁguration. For comparison DFT energies (and scaled with respect to the starting conﬁguration)
for snapshots of atomic conﬁgurations along the dynamic trajectory are also reported. The error
between the computed and ab initio predicted energies is ≈4 meV/atom, close to the order of
numerical noise that one can expect in such simulations. For completeness, we also report the
change in energy for MD simulations run with an EAM force ﬁeld (Figure 10(b)). All 3 methods
Figure 10: Evolution of energy of bulk fcc Al using the (a) AGNI with Eq. ??, and (b) EAM
potential. DFT computed energies of a few conﬁgurations are also marked in (a) for validation. In
all the cases, the energy is in reference to that of the perfect fcc Al. The energy is conserved with
time and maintains the correct ordering with temperature.
display similar trends suggesting that the dynamics undertaken with an AGNI force ﬁeld does
indeed concur with the thermodynamic driving forces in a system.
During a static simulation
A second, and equally simple, approach to estimating the potential energy directly from forces is
by integrating them using a Taylor series approximation of the potential energy
i −ro)2 +....
i ,u ⊂(x,y,z)
Here, E is once again the total potential energy, which to a ﬁrst order approximation can be derived from the atomic forces. ru
i is once again the atomic position. A discretization along the
atomic positions governs the accuracy by which we can predict the energy. For these reasons Eq.
?? is particularly more suited for static simulations, e.g. computing reaction barriers along a reaction coordinate, when the velocities are zero. The validity of this approach was demonstrated
to be consistent with the underlying potential energy surface in our previous work, whereby, the
migration energy for a vacancy in bulk Al was within 3% of the DFT predicted value.16
Eqs. ?? and ?? both provide a restricted means to computing the energy, whereby, it is necessary that a pathway connecting the different conﬁgurations in phase space (either in time or along
a reaction coordinate) exists, in order to accurately carry out force integration. This is a limitation
of using a truly force based force ﬁeld, wherein, one cannot predict energies by simply choosing
two arbitrary points in the phase space. Nevertheless, these ﬁndings ascertain that Eq. ?? and ??
can indeed be used to compute change in the total potential energy as a function of time or reaction
coordinate, as needed by a majority of atomistic simulations.
Uncertainty quantiﬁcation
The ﬁnal component to a successful predictive model is to be able to quantify the error (ε) in the
force predictions made. If this uncertainty can be estimated, a priori, conﬁdence estimates for the
force predictions given a new atomic environment can be provided. At the same time, it allows one
to understand the force ﬁeld’s domain of applicability, providing a pathway for their subsequent
and continual improvement. Below is one such attempt to quantify these uncertainties.
To compute the force on an atom, within the learning framework (c.f., Eq. ??), begins by
calculating the distance between its ﬁngerprint and the reference training ﬁngerprints, resulting in
a total of Nt distances. The ﬁnal prediction is then a weighted sum of these distances, making
them an important metric on predictive accuracy. Amongst the list of distances the minimum
distance, dmin = min{d1,d2,.....,dNt}, in particular provides a measure of “closeness" of the new
observation compared to the reference cases, and can be thought of as a descriptor in estimating ε.
To capture this hypothesis, the dmin and ε for every observation in the test dataset was computed
with the constructed AGNI force ﬁeld, MD. The results are summarized in the scatter plot of
Figure 11. Clearly, as dmin increases the variance in ε increases - suggesting that for instances
far away from reference training environments the interpolative performance fails. By binning
Figure 11: Top panel: a scatter plot of the minimum distance (dmin) vs. the predicted force error
(ε). The range of dmin is further sub-divided into small groups for statistical analysis. The gray
regions were not considered for any statistical purposes, due to the lack of sufﬁcient data (left) and
high errors (right). Bottom panel: a standard normal distribution ﬁt for each sub-group (though
only shown for three such bins), used to estimate the variance in model errors.
Figure 12: The uncertainty model, created for force ﬁeld MD, whereby dmin is used as a descriptor
to measure the expected variance in the prediction made. The markers show the actual behavior,
while the blue dashed line indicates a polynomial ﬁt to the uncertainty.
the range of dmins observed into uniform and smaller sub-groups, a standard normal distribution
is ﬁt to the observed ε. The histogram insets in Figure 11 demonstrate this for three such bins.
During the binning process, dmin < 10−3 and > 10−1 were ignored due data scarcity and large
predictive errors, respectively (c.f., gray-shaded regions in Figure 11). Collecting statistics across
the range dmins allowed us to ﬁt a polynomial relation between standard deviation (s) and dmin,
providing an analytical form to quickly estimating uncertainties. The exact functional form is
s = 49.1d2
min −0.9dmin +0.05. This is illustrated by the red circle markers and the blue dashed line
in Figure 12. Note that by using s the conﬁdence level in the uncertainties provided is at 68.2%,
though one can use higher conﬁdence levels such as 2s and beyond. A call that the user needs to
make depending on the need and availability of computational resources.
Now to demonstrate this uncertainty model, for each atom in the validation conﬁgurations
(grain boundaries, lattice expansion/compression, dislocation) we estimate the uncertainty in the
force predictions made. In Figure 13 we re-plot the reference DFT and ML force predictions,
along with the corresponding uncertainty in each prediction as highlighted by the error bars (color
coded according to the conﬁguration subclass marker). Immediately, those atomic environments
with high uncertainties is evident and can now be ﬂagged. These environments can be accumulated
and used to retrain the force ﬁeld. The preliminary steps undertaken here allows for identifying
regions of poor force ﬁeld performance in a systematic manner, and is integral to the continual
improvement in accuracy and generalizability of AGNI force ﬁelds - making them truly adaptive.
Figure 13: Parity plot of force predictions for test environments (grain boundaries, lattice expansion/compression, and dislocation) of dataset E, predicted by DFT and the ML model, MD. These
values are identical to those in Figure 7. For each prediction the uncertainty is highlighted, as
indicated by the error bars (color coded according to the conﬁguration subclass).
Outlook and Summary
A new machine learning framework to circumvent the accuracy, cost, and generalizability issues
facing current atomistic models has been proposed. By directly mapping quantum mechanical
derived force components to the numerical representation of an atom’s local environment, accurate and computationally inexpensive force ﬁelds, herein called AGNI, were developed. In this
manuscript a workﬂow for their systematic construction, which includes generating reference data,
representing the atomic environments with a numerical ﬁngerprint, sampling non-redundant data,
learning the forces, were all demonstrated for the example of elemental Al. Further, methods to
quantify uncertainties in the force predictions are proposed. This is crucial to understanding the
domain of applicability of such data-driven methods, in turn paving the way for their adaptive
reﬁnement.
Nevertheless, to make such methods a mainstream tool for atomistic simulations a few challenges yet remain that need to be addressed. Firstly, to explore diverse chemistries it is necessary
to come up with AGNI force ﬁelds for multi-elemental systems in an equally quick and rational
manner. Though the framework discussed here was for an elemental system, the recipe is directly
transferable to multi-elemental situations. Secondly, as materials science or chemical systems
become ever increasingly complex, the conﬁguration space to be explored will increase exponentially. This poses a challenge for the non-linear regression learning algorithm proposed here, and
for a continued realization of machine learning force ﬁelds adopting methodologies, wherein, large
quantities of data can be handled will be required.
Irrespective of these challenges, the prospect of using AGNI force ﬁelds as a tool to accelerate
atomistic simulations is indeed very promising. Access to such high ﬁdelity force predictions at
a fraction of the cost has already made signiﬁcant in roads to studying materials and chemical
phenomena. Our previous work demonstrated an expose of some atomistic simulations, such as;
geometry optimization of atomic structures with several 100s of atoms, dynamical evolution of
defects over long time scales (vacancies and adatoms) to determine diffusion barriers, computing
vibrational properties of materials, and estimating reaction energy barriers, all using AGNI force
ﬁelds.16 Here, we further extended the scope of such force ﬁelds by simulating even more complex
phenomena - estimating the melting and stress-strain behavior of Al surfaces. Also, methods to
reconstruct energies entirely from forces were proposed. The force ﬁeld construction workﬂow put
in place here allowed us to study these more complex materials and chemical phenomena, and such
strategies are only going to become increasingly important in pushing the envelope of atomistic
simulations.
Acknowledgment
This work was supported ﬁnancially by the Ofﬁce of Naval Research (Grant No. N00014-14-1-
0098). The authors would like to acknowledge helpful discussions with K. B. Lipkowitz, G. Pilania, T. D. Huan, and A. Mannodi-Kanakkithodi. Partial computational support through a Extreme
Science and Engineering Discovery Environment (XSEDE) allocation is also acknowledged.