Received March 11, 2020, accepted March 22, 2020, date of publication March 25, 2020, date of current version April 13, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.2983186
A Survey for Cervical Cytopathology Image
Analysis Using Deep Learning
MD MAMUNUR RAHAMAN
1, CHEN LI
1, XIANGCHEN WU
YUDONG YAO
3, (Fellow, IEEE), ZHIJIE HU
1, TAO JIANG
XIAOYAN LI
5, AND SHOULIANG QI
1Microscopic Image and Medical Image Analysis Group, College of Medicine and Biological Information Engineering,
Northeastern University, Shenyang 110169, China
2Suzhou Ruiguan Technology Company Ltd., Suzhou 215000, China
3Department of Electrical and Computer Engineering, Stevens Institute of Technology, Hoboken, NJ 07030, USA
4Control Engineering College, Chengdu University of Information Technology, Chengdu 610103, China
5Cancer Hospital of China Medical University, Liaoning Hospital and Institute, Shenyang 110042, China
Corresponding author: Chen Li ( )
This work was supported in part by the National Natural Science Foundation of China under Grant 61806047, in part by the Fundamental
Research Funds for the Central Universities under Grant N180719020 and Grant N2019003, in part by the Scientiﬁc Research Launched
Fund of Liaoning Shihua University under Grant 2017XJJ-061, in part by the Scientiﬁc Research Fund of Sichuan Provincial Science and
Technology Department under Grant 2017TD0019, in part by the Scientiﬁc Research Fund of Chengdu Science and Technology Bureau
under Grant 2017-GH02-00049-HZ and Grant 2018-YF05-00981-GX, and in part by the China Scholarship Council under
Grant 2018GBJ001757.
ABSTRACT Cervical cancer is one of the most common and deadliest cancers among women. Despite that,
this cancer is entirely treatable if it is detected at a precancerous stage. Pap smear test is the most extensively
performed screening method for early detection of cervical cancer. However, this hand-operated screening
approach suffers from a high false-positive result because of human errors. To improve the accuracy and
manual screening practice, computer-aided diagnosis methods based on deep learning is developed widely to
segment and classify the cervical cytology images automatically. In this survey, we provide a comprehensive
study of the state of the art approaches based on deep learning for the analysis of cervical cytology images.
Firstly, we introduce deep learning and its simpliﬁed architectures that have been used in this ﬁeld. Secondly,
we discuss the publicly available cervical cytopathology datasets and evaluation metrics for segmentation and
classiﬁcation tasks. Then, a thorough review of the recent development of deep learning for the segmentation
and classiﬁcation of cervical cytology images is presented. Finally, we investigate the existing methodology
along with the most suitable techniques for the analysis of pap smear cells.
INDEX TERMS Cervical cancer, cytopathology, convolutional neural networks, deep learning, segmentation, classiﬁcation, pap smear.
I. INTRODUCTION
Cancer is the deadliest disease of independent growth of body
cells, which is accountable for around 9.6 million deaths each
year . This statistic ﬂuctuates enormously among developing and developed countries. Approximately 70% of deaths
from cancer occur in low- and middle-income countries .
As reported in the most recent world cancer statistics, cervical cancer is the fourth most common cancer (estimated
570000 new cases each year) worldwide and the second most
common cancer in women, who are living in developing and
The associate editor coordinating the review of this manuscript and
approving it for publication was Varuna De Silva
low-income countries with an annual death of 311000 women
approximately, where 85% of these deaths are occurring in
low- and middle-income countries , . So, women with
ages between 30 to 49, who are living in developing and
least developed countries are at the highest risk for cervical
cancer because of the lack of awareness and limited access
to health services . Research shows that human papillomavirus (HPV) is the main cause of cervical cancer .
HPV is the most prevalent sexually transmitted viral infection worldwide, and the most sexually active individuals of
both sexes are usually affected with HPV in their lifetime .
There are around 200 types of HPV that have been identiﬁed
so far. Among them, 13 are high-risk types, and HPV type
VOLUME 8, 2020
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see 
M. M. Rahaman et al.: Survey for Cervical Cytopathology Image Analysis Using DL
16 and 18 account for roughly 70% of all cervical cancer
 , . HPV type 16 has been detected in about 24%
of women and type 18 has been detected in about 9%
 , , . Pregnancy and ﬁrst intercourse at an early
age, having sex with multiple partners, weak immune system, smoking, use of oral contraceptives and improper menstrual hygiene are the common risk factors that are linked
with cervical cancer. The common symptoms associated with
cervical cancer include abnormal vaginal bleeding, vaginal
discharge, and moderate pain during sexual intercourse .
Cervical cancer is treatable if it is detected timely and treated
properly .
When the cervical tissue cells begin to grow and replicate
abnormally, these infected cells are called cervical intraepithelial neoplasia (CIN). CIN is classiﬁed into low-grade CIN
and high-grade CIN based on the cell intensity . The most
common ways of diagnosis to detect cervical malignancy is
cervical cytopathology (pap smear or liquid-based cytology)
because of its cost-effectiveness , . These tests consist
of a sample of cells that are collected from the patient’s uterine cervix and analyzing the changes under a microscope by
expert cytologists to check the HPV effects. However, manual
screening is difﬁcult, tedious, time consuming, expensive and
subjected to errors because each slide contains around three
million cells with different orientation and overlapping .
A. MOTIVATION OF COMPUTER AIDED DIAGNOSIS
For the past 60 years, the pap smear test has a signiﬁcant
effect of lowering the death rate due to cervical cancer .
Traditionally, the test is performed by collecting cells from
the squamocolumnar terminal of the cervix by using brush or
spatula and then smeared into glass slides , . Next,
the glass slides are examined under a light microscope by
cytotechnologists to check the malignancy of the cell, which
allows early and effective treatment. The screening processes
usually take 5–10 minutes based on the difﬁculty of cell
orientation. A cytotechnologist cannot analyze more than
70 samples a day . This process also needs full attention
all the time in order not to miss any cancerous cells. So, it is
always a major concern to get an expert cytotechnologist to
screen and diagnose the pap slides, which leads us to develop
an automated computerized system that can analyze the pap
slides efﬁciently and accurately . Besides, to handle a
large scale of image data sets, rigorous measurements of
image features for clinical follow-up, comparative study, and
personalized medicine, a computerized system is essential.
In comparison with manual assessment, digital pathology
and microscope play a signiﬁcant role in disease diagnosis by
providing information for computer-aided diagnosis (CAD).
Over the past few decades, there has been extensive research
on the development of CAD systems, which can help doctors
in tracking cervical cancer. This system can automatically
detect and classify the abnormal cell form the cytology specimen , . This automated system traditionally consists
of three steps: Cell segmentation (cytoplasm and nuclei),
feature extraction, and classiﬁcation.
When training of data became possible at the end of
the 1990s, an automated computer-assisted system began to
develop. Active shape models, handcrafted feature extraction
methods, pattern recognition, statistical classiﬁers started to
grow very popular for the development of the new system.
Later, the computer learned features based on the artiﬁcial
neural network became very successful .
In a traditional CAD system, ﬁrstly, some preprocessing
work is done by ﬁltering methods to improve the image
quality. Then, cell nuclei are extracted through segmentation
method (k-means, clustering, super pixel, etc.) and postprocessing work is done to correct the segmented nucleus.
Next, features (morphological, color metric, texture) are
extracted from each nucleus, and feature selection is applied
to select the most discriminant feature. Finally, a classiﬁer is
designed to classify the cell .
The main limitation of the above method is that the features
extracted for the classiﬁcation are usually handcrafted that
cannot guarantee the optimality of the classiﬁcation stage.
However, the deep learning approach reviewed in this paper
is a kind of learning method that can directly process raw
data (e.g., RGB images) and offers automated learning of
features based on speciﬁc objective function such as detection, segmentation and classiﬁcation . Nowadays, deep
learning techniques have signiﬁcant contributions in the ﬁeld
of artiﬁcial intelligence and successfully applied to computer
vision, natural language processing, image understanding,
medical imaging, and computational biology , .
B. DEEP LEARNING IN CERVICAL CYTOPATHOLOGY
IMAGE ANALYSIS
In this subsection, we will give a brief review about the
importance of deep learning among other machine learning
techniques and its development trend in the domain of cervical cancer.
Machine learning under a broad category of artiﬁcial
intelligence (AI) is the science to develop algorithms that
can autonomously learn from data and make predictions
without being explicitly programmed. It is a tool that can
be used to enhance human capabilities to solve problems.
The learning style can be supervised, unsupervised, and
semi-supervised. Despite the various learning styles, all combinations of machine learning algorithms consist of representation, evaluation, and optimization. Representation is a
set of classiﬁers or languages like support vector machine,
K-nearest neighbor, decision tree and a neural network that a
computer understands. The evaluation function is needed to
distinguish good classiﬁers from the poor one through ﬁnding
accuracy, precision, and recall. Optimization is to ﬁnd the
highest accurate representation through evaluation , .
The performance of machine learning heavily rely on
data representations (or features). In order to get a good
illustration of data, a signiﬁcant effort in data preprocessing and transformation is needed, which is labor-intensive
and highlights the incompetence of automatic learning.
In order to get an optimized learning process, a deep
VOLUME 8, 2020
M. M. Rahaman et al.: Survey for Cervical Cytopathology Image Analysis Using DL
learning (DL) approach can extract hierarchical features without human cooperation. Over the past decades, DL has made
signiﬁcant advantages over other machine learning algorithms by achieving state of the art results on challenging
computer vision tasks such as image classiﬁcation, segmentation, object recognition and face recognition , . This
model requires a labeled training set, from which it will learn
the features. A critical thing about DL is that the features
are not human-understandable though it affords more accurate outcomes . Another compromise is that it typically
requires a considerable number of labeled data sets compared
with other machine learning approaches .
1) DEEP LEARNING IN CERVICAL CYTOPATHOLOGY
The acceptance of DL procedures in the medical image
analysis is now the most repeatedly designed and successful
type of machine learning algorithms, and analysis of cervical
cytopathology images are no exclusion. A prevalent deep
architecture in this ﬁeld is convolutional neural networks
(CNNs), which have obtained a great success in cell detection, segmentation, classiﬁcation and extraction of the region
of interest (ROIs) . In supervised learning, the CNN
model is determined to generate hierarchical data features
from a given labeled image dataset to accurately classify the
cells into normal and abnormal . However, it demands a
large number of annotated data, which is not apparent in the
medical domain. On the other hand, unsupervised learning
through a neural network for feature learning has produced
an encouraging performance for the study of microscopic
images , . Autoencoder is one top-rated unsupervised
neural network. Fig. 1 reports the popularity of deep learning
overtime for the analysis of cervical cytology image.
FIGURE 1. Development trend for the segmentation and classification of
cervical cytopathology image analysis in deep learning.
2) DEEP LEARNING IN SEGMENTATION TASK
In medical image analysis segmentation is one of the most
effective and extensive research ﬁelds. The main goal of
segmentation is to partition the image into multiple regions
to quickly analyze the cell . A manual autopsy is challenging because each slide contains up to 300000 cells with
different orientation and overlapping. Moreover, it also
contains mucus, bacteria, blood, inﬂammation, and dust
particles, which prompt for automatic segmentation .
Accurate segmentation of nuclei and cytoplasm is vital since
the nucleus carries reliable information for the detection of
cancer. In the medical domain, automatic segmentation saves
the life of a patient by providing fast, reliable, and accurate diagnosis of diseases. Because of the advantages, many
researchers are performing segmentation task for cervical
cancer using deep learning. Fig. 1 shows the increasing trend
of segmentation of cervical cancer in deep learning.
Numerous works have been performed on automatic segmentation of cytoplasm and nucleus of a cervical cell. In this
study, we brieﬂy describe all those segmentation methods in
Sec. IV. From the papers we have studied so far gives a general pipeline for cervical cancer image segmentation, which
is shown in Fig. 2. This workﬂow includes image acquisition, pre-processing, deep learning methods, and application.
From the general pipeline in Fig. 2, we can ﬁnd that:
• The ﬁrst step of segmentation is image acquisition. Most
of the research work performed by collecting the images
from some accessible public databases identiﬁed as
Helev University database and ISBI challenge database.
Herlev database contains single-cell images with ground
truth. In the ISBI challenge database, there are images
with overlapping cells. Few researchers used private
databases collected from different hospitals or research
institutes.
• The 2nd step of segmentation is image pre-processing.
Here, image contrast enhancement, noise extraction,
augmentation, and ﬂipping operations are usually performed. Image enhancement may occur in noisy,
blurred, or low contrast images. These challenges are not
prevalent in laboratory pap smear imaging. Moreover,
the pre-processing task is not apparent in some work
where a hybrid segmentation algorithm is implemented.
• The 3rd step is the use of deep learning techniques for
feature representation. There are three approaches in
this section, which are supervised, unsupervised, and
hybrid feature learning. In most of the reviewed articles,
we have observed to use of supervised learning methods, where CNN’s (VGG, ResNet, U-net) or custommade CNNs are the most popular deep architecture.
Patch-based CNN, super pixel-wise CNN, structured
regression-based CNN, multiscale CNN and instant relation network are also employed. Under hybrid feature
learning, one machine learning algorithm usually coupled with CNNs. For instance, fuzzy c means clustering
is linked with backpropagation neural network, CNN is
connected with the graph-based method, mask regional
CNN is combined with fully connected conditional random ﬁeld and so on. However, Unsupervised feature
learning is not common in cervical cytopathology image
• The ﬁnal step is the segmentation, where accurate
nucleus segmentation is the primary goal because the
nucleus carries vital information for the diagnosis of
cancer. In some papers, cytoplasm, and background are
VOLUME 8, 2020
M. M. Rahaman et al.: Survey for Cervical Cytopathology Image Analysis Using DL
FIGURE 2. General deep learning algorithm for automatic cervical cytopathology image analysis. It includes (1) Image acquisition,
(2) Image preprocessing, (3) Feature representation, (4) Application.
also segmented. It is observed that minimal effort has
been made so far for the segmentation of overlapping
cells. Most of the segmentation works are performed
based on single-cell.
3) DEEP LEARNING IN CLASSIFICATION TASK
Image classiﬁcation is a principal area of research in medical
image analysis. In this area, a deep learning-based method
made a tremendous contribution by providing state-of-the-art
accuracies . Image classiﬁcation is a process in computer
vision that takes multiple images as inputs and then classiﬁes
according to its visual content.
Generally, to train a neural network from scratch requires
a considerable amount of data and computing power,
which also result in longer training times. The solution
to all these problems is transfer learning, which uses the
pre-trained model form one task to solve a different task .
In medical imaging transfer learning beneﬁts signiﬁcantly,
since to arrange good quality imaging datasets is complicated, and the dataset is generally small (of an order
of 102 −104).
Two popular techniques are identiﬁed for transfer learning.
One is by using a pre-trained network as a feature representator, and two is by ﬁne-tuning the pre-trained network
on image data. The increasing trend of cervical cancer cell
classiﬁcation using deep learning, is displayed in Fig. 1,
which indicates its popularity.
Many authors use different deep learning algorithms for
the classiﬁcation of cervical cells into normal, abnormal,
and pre-cancerous cells. In Sec. V, we brieﬂy describe all
those classiﬁcation methods. The general pipeline for the
classiﬁcation of cervical cancer exhibits in Fig. 2 after having
prior knowledge and understanding of the papers we have
• The stereotype image classiﬁcation algorithm starts
with image acquisition, then pre-processing of the data.
VOLUME 8, 2020
M. M. Rahaman et al.: Survey for Cervical Cytopathology Image Analysis Using DL
The ﬁrst two steps are similar to the segmentation task,
which we have already discussed in the previous subsection.
• The following stage is the feature extraction, which
is the most important stage to get better classiﬁcation accuracy. Most of the paper we studied are using
supervised learning. VGGNet, pre-trained CNN using
AlexNet, ResNet, multilayer perceptron neural network (MLPNN) are found to be the most commonly
used feature extractor in the literature. Some authors
use hybrid feature learning techniques, where they combine different machine learning algorithms with deep
• Finally, the feature vectors are supplied to the classiﬁers.
SVM, decision tree, deep ANN, fully connected layers,
transfer learning, softMax regression are the leading
classiﬁers in this stage. In some articles, segmentation
tasks perform ﬁrst, then the features of the cytoplasm
and nucleus are extracted to perform the classiﬁcation
C. MOTIVATION OF OUR REVIEW PAPER
The motivation of this article is to give a comprehensive
overview of deep learning in cervical cytopathology image
analysis as well as popular deep learning techniques, and
their architectures with overview tables and ﬁgures are also
presented for precise understanding. Besides, this paper also
discusses potential techniques for the analysis of cervical
cells in deep learning.
Cytology and histology both are the examinations of
cells at a microscopic level. Histology examination is usually performed by investigating the sample of whole tissue, whereas cytology is the examination of cell samples
 – . The preparation of histology slides involves lots
of stages compared to the preparation of cytology slides,
which makes it costlier. Histology slide preparation involves
ﬁxing, preprocessing, embedding, sectioning, and staining.
However, preparation of cytology slides does not involve
any stages . Cytology examination gives the best cellular
details, which is an essential factor for the analysis of cervical cells. For cervical cancer screening, a cytology-based
examination is preferred over histology and is performed
traditionally .
In our study, we have obtained around ten survey papers
related to machine learning in medical image analysis.
Among those ten studies, one survey is based on an artiﬁcial neural network in cytopathology . Other two documents focus on the detection of microscopic image analysis
 , , two papers concentrate on deep learning techniques in medical image analysis , , one gives priority
on deep learning in microscopic image analysis . However, four survey papers only concentrate on cervical cancer,
and out of the four, one article directs on the classiﬁcation
tasks based on the neural network . Additional two focus
on the segmentation tasks for cervical cancer , , and
the ﬁnal one presents a survey on automated machine learning
techniques for cervical cancer image analysis .
Pouliakis et al. publishes a research survey in 2016,
focusing on the importance of employing ANN in cytopathology. He explored that ANN is a powerful ﬁeld for the application of cervical cytopathology image. However, he explored
all the related ﬁeld in cytopathology but gave less priority of
cervical cytology images. He summarized 31 papers in the
summary table but no paper related to cervical cancer and
deep learning.
Xing and Yang in 2016 provides a comprehensive
summary of the new state of the art cell segmentation
approaches on different microscopic images. In that survey,
we found about nine papers related to cervical cell segmentation, and among them, two articles are based on the neural
network. He
publishes another survey paper in 2017 by
reviewing some popular deep learning methods in various
tasks such as segmentation, detection, and classiﬁcation in the
microscopic image analysis . This paper also explained
the architecture and working principles of CNN, RNN, FCN,
stacked autoencoders, deep belief networks. We detect over
65 summarized paper based on microscopic images, and
among them, only one paper is related to cervical cancer.
Carneiro et al. in 2017 summarizes current deep learning techniques in various tasks like segmentation, detection,
and classiﬁcation in different imaging modalities. In the summarizing table, we found around 28 papers on various imaging modalities. Among them, only one paper is on cervical
Litjens et al. provides a very comprehensive review
on deep learning in medical image analysis, and they summarized over 300 papers based on deep learning in the year
of 2017. Among them, only three papers are on our topic.
Hu et al. , in 2018, give a review concentrating on
deep learning in image-based cancer detection and diagnosis.
In the study, he has explained some leading deep learning
architectures (CNN, fully convolutional networks, autoencoders, and deep belief networks) for the detection of cancer
and its diagnosis. Later, they provided a summary survey
on studies exploiting deep learning for the determination of
various types of cancer such as breast, lung, skin, prostate,
brain, colonial, cervical, liver, and bladder. In the summary
survey, we obtain three papers based on the topic of our
interest among 76 documents that they have reviewed.
Devi et al. in 2016 summarize 30 papers based on an
artiﬁcial neural network for the classiﬁcation task of cervical cancer. Among them, only one article is based on deep
learning. Besides, a detailed description of ANN, Multi-layer
perceptron, BPNN, Gene expression, Radial basis function
network, CNN, feed-forward neural network, knowledgebased network, Modular neural network is provided. In the
same year, she publishes another review article focusing on
cervical cancer image classiﬁcation algorithm based on SVM
and fuzzy-based techniques . This article does not include
any paper centering on the neural network or deep learning
among the 32 papers that they have summarized.
VOLUME 8, 2020
M. M. Rahaman et al.: Survey for Cervical Cytopathology Image Analysis Using DL
Sarwar et al. , in 2019, exhibits a very new survey article based on the segmentation of cervical cells. This review
consists of a total of 78 papers in a period stats from 1997 to
2018. In this study mostly cover classical machine learning
approaches for the segmentation of cervical cells. Among
those 78 studies, mainly two papers employ deep learning
techniques for cell segmentation.
William et al. presents an overview of the state of
the art in notable recent publications focusing on automated
detection of cervical cancer from pap smear images in 2018.
They reviewed 30 journal papers collected through four scientiﬁc databases, but among them, only three articles are on
deep learning in cervical cancer.
Total number of summarized papers in an individual survey
Number of papers related to deep learning in cervical cytopathology image
FIGURE 3. Comparative study among recent survey papers. Number of
summarized papers found in the existing literature review in comparison
to their contribution to deep learning in cervical cytopathology image
By studying all the recent survey papers, we have identiﬁed
that there is very little or no contribution at all, especially
in the ﬁeld of deep learning in cervical cytopathology image
analysis. For a clear overview, we made a histogram diagram
(Fig. 3) for a comparison purpose to show each of the present
survey papers and their contribution to cervical cancer with
our proposed studies.
D. STRUCTURE OF THIS REVIEW
The motivation of this review is to look extensively and
speciﬁcally at the new state of the arts on the automated
cervical cytopathology cell segmentation and classiﬁcation. To prepare this comprehensive review, we looked for
databases including PubMed, arXiv, Google Scholar, IEEE,
ACM, Springer and Elsiver. Additionally, proceedings of the
international conference on SPIE, ISBI, MBC and international conference on medical imaging with deep learning.
We also checked the references in all the selected papers.
We excluded papers that are not based on deep learning or
cytopathology images. We considered the most important
publications in the case of overlapping one. We set the cut
off time of the search is February 10th, 2020, since new
publications are coming out every month. We have considered research motivation, contribution, dataset, workﬂow,
and results, while summarizing one paper. Considering the
convenience of future researchers, this paper includes several
tables and a ﬂowchart for quick access to the topic of their
The structure of this review is as follows: we begin by
introducing the deep convolutional neural networks and their
popular architectures that have been used for cervical cancer cell analysis in Sec. II. Sec. III includes an overview
of publicly available datasets and evaluation methods. It is
followed by a comprehensive review of segmentation and
classiﬁcation work of cervical cytology image based on deep
learning in Sec. IV and Sec. V, respectively. Then, a thorough
methodology analysis of suitable segmentation and classiﬁcation techniques and future potential methods are discussed
in Sec. VI. Sec. VII summarizes the review and discusses
prospective applications.
II. DEEP CONVOLUTIONAL NEURAL NETWORKS
After thorough studies, we have observed that CNN models
are the most commonly used supervised machine learning
models for the analysis of cervical cancer. CNN’s are a distinct kind of supervised multilayer perceptron that requires
minimal preprocessing to detect visual patterns. To obtain
satisfying accuracies, CNN’s demand a considerable amount
of data. However, accumulating a well-annotated high-grade
quality dataset is very challenging and costly, which leads
to a larger but noisy dataset that is easy to obtain. Studies
have shown that CNN’s are robust to the noise until a certain label. Increasing noise reduces the batch size. Hence,
increasing the batch size and lessening the learning rate can
elevate the performance . Besides, CNN’s are invariant
to translation, rotation, or size , . Therefore, it can
accurately analyze the objects even if it is placed in a different orientation. The architecture of CNN is composed of
convolution, pooling, and fully connected layers. Convolution and pooling layers, mainly extract features from the
image, whereas fully connected layers classify by mapping
the extracted features .
Convolution layer is the primary building block of CNN
architecture. It takes an image as input and extracts high-level
features. The ﬁrst layer usually extracts low-level features,
and consequently, as the layer gets deep, it extracts highlevel features and gives the network a good understanding of
the image . Then, there is a pooling layer after the convolution layer to reduce the size of the convoluted features.
Max pooling and average pooling are the two popular types
of the pooling operation. Max pooling extracts the maximum
value, and average pooling returns the average of all values
from the portion of the image covered by the kernel .
A fully connected layer serves the same principle as a multilayer perceptron (MLP). It connects every neuron of each
layer to every neuron of another layer. The feature map goes
through a fully connected layer to classify the image.
A. EVOLUTION OF CONVOLUTIONAL NEURAL NETWORKS
In the mid of the 20th century, Hubel and Wiesel ﬁrst
proposed the concepts of ‘‘receptive ﬁeld’’ in their experiments on cat’s visual cortex cells, which later introduced
VOLUME 8, 2020
M. M. Rahaman et al.: Survey for Cervical Cytopathology Image Analysis Using DL
into the research work of CNNs. In the 1980s, the ﬁrst
artiﬁcial neural network called ‘‘neocognitron’’ is proposed
by Fukushima and Miyake to recognize the handwritten number and other pattern recognition tasks based
on the receptive ﬁeld, which served as a motivation for
CNN’s . Later, the researchers focused on studying
computerized features using an MLP rather than handcrafted features to train the network with back-propagation
(BP) algorithm . Next, in 1990, Y. LeCun stated and
explained a back-propagation algorithm for the recognition
of handwritten digits . His advised CNN architecture
is known as ‘‘LeNet-5’’ , which performs better than
any other algorithm at that time. However, it encounters
some problems such as local optimum, vanishing gradient,
and overﬁtting with the increasing number of network layers. Hinton in 2006 uncovered that the neural network has
excellent feature learning ability for image analysis, and
the drawbacks can be alleviated by normalized initialization
 – . Since then, deep learning gained popularity.
With an ever-increasing number of image databases and
computing power, it makes it easier to train deep learning
for image classiﬁcation and recognition problems. Starts
from 2010, there is a global contest for object detection and
classiﬁcation known as the ImageNet Large Scale Visual
Classiﬁcation Challenge (ILSVRC). From 2012 till now,
the algorithm based on CNN won the prestigious international
contest, where tech giants like Google and Microsoft take
part. Krizhevsky et al. won the ILSVRc-2012 competition
by presenting a CNN model called AlexNet that reach a top
5 classiﬁcation error of 15.31%. For comparison, the 2nd
best entry that does not use CNN got a classiﬁcation error
of 26.1% , .
Following the path of AlexNet later ZFNet ,
Inception-v2
PReLU , Inception-v3 , ResNet , ResNeXt ,
DenseNet and SENet are proposed mostly by using
ImageNet dataset or CIFAR-10 and showed the leading
performance results in the top-5 (test) error rate starting from
15.31% to 2.251% .
B. POPULAR CNN ARCHITECTURE THAT ARE USED IN
CERVICAL CYTOPATHOLOGY IMAGE ANALYSIS
AlexNet, VGG-16, and ResNet are found to be the most frequently used network architecture for the segmentation and
classiﬁcation tasks for cervical cancer. The work of ﬁnds
that ResNet is the preferable network for the classiﬁcation
problem compared with the VGG network. In this subsection,
we will give a brief description of AlexNet, VGGNet, ResNet
and Inception Net with their network architecture.
1) AlexNet
AlexNet is the ﬁrst neural network to win the 2012 ILSVRC
competition. The signiﬁcance of AlexNet is that they use
the Rectiﬁed Linear Unit (ReLU) as an activation function
instead of the sigmoid or hyperbolic tangent function. Overlapping pooling, optimization for multiple GPU’s to speeding
up network training also introduced here. They solved the
overﬁtting problem by data augmentation and dropout. The
network architecture consists of eight hidden weight layers,
ﬁve convolution layers, and three fully-connected layers. This
network consists of 60 million parameters . The architecture is given in Fig. 4-(a).
Simonyan and Zisserman from the University of Oxford
proposed a CNN model called VGGNet that won the
2014 ILSVRC competition. The main idea of VGGNet is
a deeper network with a smaller ﬁlter, and there can be
16-19 layers. The input of VGG is a ﬁxed size of 224 × 224
RGB image. They use the smallest possible convolutional
ﬁlters (3 × 3) with the stride of 1 pixel to preserve the spatial
resolution after convolution. There is also a 1×1 convolution
ﬁlter, which is a linear transformation of input followed
by activation function ReLU. After convolution, pooling is
performed by ﬁve max-pooling layers with a window size of
2 × 2 and stride 2. At the end, it has three fully connected
layers. The ﬁrst two have 4096 channels, and the 3rd has
1000 channels, 1 for each class. The last and ﬁnal layer is
a SoftMax layer.
The main discovery of the VGGNet is the application of
3 × 3 small convolution ﬁlters. The stack of three 3 × 3
convolutions layers has the same receptive ﬁeld as one 7 × 7
Conv layer, which gives 55% less parameters. This small size
of the receptive ﬁeld allows VGG to have more weight layers,
which results to improve performance. VGG-16 and VGG-19
comprise of 138 and 144 millions of parameters . The
network architecture is given in Fig. 4-(b).
In the previous description, we have mentioned that AlexNet
has eight weight layers, and VGG has 16 or 19 weight layers.
So, increasing the depth or weight of a neural network can
give better performance results. However, He et al. observed
that with the increasing number of network depth accuracy
gets saturated and then degrades rapidly . They trained
the CIFAR-10 data with 20 layers and 56 layers and observed
that deeper network has higher training error and thus test
To solve the above problem, they introduced a novel
approach pathway called skip connection (Identity mapping)
so that network depth can increase for improved performance. In this way, there can be up to 1000 weight layers
in ResNet .
If a convolution layer takes X (feature map) as input and
residual function is denoted as F(x). Then, input of the ﬁrst
layer (x) is copied to the output layer, H(x). then, H(x) =
F(x) + X or F(x) = H(x) −X. Fig. 4-(d) shows the structure
of residual learning block. So, the primary purpose of the
residual network is that a deeper network can be made form
a shallow network by copying weight layers in the shallow
network and setting other layers in the deeper network to be
VOLUME 8, 2020
M. M. Rahaman et al.: Survey for Cervical Cytopathology Image Analysis Using DL
FIGURE 4. Network architectures of three commonly used CNNs. (a) is AlexNet, (b) is VGGNet, (c) is ResNet and
(d) is the structure of a residual learning block.
identity mapping. ResNet won the 2015 image classiﬁcation
competition. The network architecture is given in Fig. 4-(c).
4) GoogLeNet/ INCEPTION Version 1 to 3
It is evident from the previous observations that Alexnet has
60 million, VGG-16 has 138 million, and ResNet-50 has
25.6 million parameters. However, GoogLeNet / Inceptionv1 has only 7 million parameters. Lower parameters mean
less computational cost. The inception model can describe the
input data very thoroughly by expanding the depth and width
of the model. The module has been regularly modernized
since it ﬁrst states in the 2014 ILSVRC image classiﬁcation
competition. Inception- v1 ﬁrst introduces 1×1 convolutional
kernel, which can reduce the network parameters. It also
employs kernel of 1 × 1, 3 × 3, and 5 × 5 that considerably improve the efﬁciency of the classiﬁcation problem
 , . Fig. 5 exhibits the network architecture and its
In the version 2 network, batch normalization is added, and
two 3×3 convolutional kernels are employed instead of 5×5
to increase the network depth .
In version 3, different shapes of convolutions are introduced. In this module, 5 × 5 convolution is replaced by
two 3 × 3. Moreover, 5 × 5 convolution is followed by
1 × 7 and 7 × 1, and 3 × 3 substitutes by 1 × 3 and 3 × 1
convolutions to make each of the block more deeper .
inception-
incorporated .
VOLUME 8, 2020
M. M. Rahaman et al.: Survey for Cervical Cytopathology Image Analysis Using DL
FIGURE 5. Network architectures of GoogLeNet/Inception. (a) is inception
network and (b) is inception block.
III. DATASETS AND EVALUATION METHODS
In this section, we discuss some commonly used datasets
and evaluation metrics for the segmentation and classiﬁcation
A. PUBLICLY AVAILABLE CERVICAL CYTOLOGY DATASETS
In our study, we have found that the Herlev database and ISBI
(International Symposium on Biomedical Imaging) challenge
database are the most commonly used publicly available
databases. Herlev and ISBI databases are mainly used for segmentation purposes. However, the Herlev database is mostly
used for the classiﬁcation task. We have found a new publicly
available database named ‘‘SIPAKMED’’ that can be utilized
for the classiﬁcation task. Tab. 1 gives the download link for
the databases, as mentioned earlier.
1) PAP SMEAR BENCHMARK DATABASE (Herlev DATASET)
The pap smear benchmark database was prepared and analyzed by the staff at Herlev University Hospital, Denmark.
They prepared the database by using a commercially available software package CHAMP (Dimac) for the segmentation of images. They prepared two databases, the old one
in 2003 and the new one in 2005 comprise 500 and 917 single cell images, respectively, with an average image size of
156 × 140. The old database has 150 normal and 350 abnormal cell images, whereas the new database has 242 and
675 benign and malignant cells, respectively. The database
has distributed into seven important classes: (a) superﬁcial
squamous epithelia, (b) intermediate squamous epithelia,
(c) columnar epithelia, (d) mild squamous non-keratinizing
dysplasia, (e) moderate dysplasia, (f) severe dysplasia, and
(g) carcinoma in situ. Among those seven classes, the ﬁrst
TABLE 1. Download link for the open access cervical cytology image
databases.
three classes correspond to healthy cells, and the rest of the
classes corresponds to the abnormal cells .
2) ISBI CHALLENGE DATABASE
The ISBI 2014 and 2015 are the publicly available database
that contains overlapping cervical cells and their ground
truth , . The ﬁrst dataset contains
135 synthetic and eight real cervical cytology EDF (extended
depth of focus) images in the training set, whereas, in the test
set, there are 810 synthetic and eight real cervical cytology
EDF images. The number of overlapping cells differs from
2 to 5 in the 2014 dataset. The ISBI 2015 dataset contains
eight real cervical cytology EDF images in training set along
with their volume images, whereas the test set has nine
real cervical cytology EDF images along with their volume
images . The number of overlapping cells ranges here
from 2 to 10.
3) SIPAKMED DATABASE
This database consists of 966 pap smear slide images and
4049 single-cell images. Based on the cell structure and morphology, the cells are classiﬁed into ﬁve distinct categories.
They are intermediate, parabasal, koilocytotic, metaplastic,
and dyskeratotic. The ﬁrst two classes can be further categorized as normal cells. Then, the next two classes are
considered as abnormal cells, where morphological changes
of the nucleus start to appear. The ﬁnal class (Dyskeratotic)
is the malignant cells level, where cervical precancerous and
cancerous conditions start to develop .
B. EVALUATION METHODS
In this subsection, we present the evaluation methods for
segmentation and classiﬁcation algorithms with all necessary
equations.
1) EVALUATION OF SEGMENTATION METHODS
Choosing the appropriate evaluation metric can reduce the
bias in the differentiation of algorithms. The automated segmentation algorithms for segmenting the region of interest
is an exciting area of research. To evaluate the automated
segmented images, we need ground truth images, which have
been prepared by pathologists. As a result, there must have
appropriate techniques to evaluate the results of the segmentation algorithm .
To evaluate the quality of segmentation, detection accuracy and segmentation accuracy are the most commonly
VOLUME 8, 2020
M. M. Rahaman et al.: Survey for Cervical Cytopathology Image Analysis Using DL
used measures. Detection accuracy is the ability to identify
the region of interest by a segmentation algorithm. Segmentation accuracy measures how close or similar are the regions of
interest obtained with comparison to the ground truth image
by applying the automatic segmentation algorithm .
Precision, Recall, and F-measure are the extensively used
detection accuracy metrics.
Precision is the number of correctly recognized pixels from
all the detected pixels. A recall is the number of identiﬁed
pixels from all the pixels in the ground truth. F1 score is the
harmonic mean of precision and recall . Mathematical
expression for precision, recall, and F1 score is shown in
table 2. In table 2 TP represents the number of correctly
detected positive samples, TN is the number of correctly
detected negative samples, FP indicates the number of negative instances that are misclassiﬁed as positive, FN denotes
the number of positive instances that are misclassiﬁed as
TABLE 2. Evaluation metrics.
Now, to evaluate the segmentation accuracy Dice coefﬁcient , , Zijdenbos similarity index (ZSI) , 
are the most popular measures.
1) Dice co-efﬁcient (D): let S denote the automatically
segmented shape consisting of points s1, s2, s3, . . . , sn
and let G represents the ground truth shape with points
g1, g2, . . . , gn. Dice coefﬁcient(D) measures the overlap between the two regions and is given by
D(S, G) = 2|A ∩G|
where D(S, G) ∈ . A higher D(S, G) value indicates better segmentation performance.
2) Zijdenbos similarity index (ZSI): ZSI considers TP, FP,
and FN in all aspects. If the ZSI score is higher than 0.7,
it indicates that the segmentation result is well-matched
with ground truth . It can be denoted as
2TP + FP + FN
2) EVALUATION OF CLASSIFICATION METHODS
After training a classiﬁer with samples, an unknown test
sample is provided to check whether the classiﬁer can
classify the samples correctly or not . Precision, recall,
F1 score, sensitivity, speciﬁcity, and accuracy are observed
as the most popular techniques to measure the classiﬁcation
results – .
Precision, recall and F1 score we have discussed in
Sec. III-B.1 and their mathematical expressions are given
Tab. 2. Sensitivity can also refer to the correct positive rate
or recall. Speciﬁcity indicates the percentage of negative
labeled instances that are predicted as unfavorable. Accuracy
identiﬁes the proportion of correct predictions. Equations for
sensitivity, speciﬁcity, and accuracy is exhibited in Tab. 2.
Though accuracy and F1 score are considered to be the
most conventional standards for binary classiﬁcation tasks,
they can generate misleading returns on imbalanced datasets.
The Matthews Correlation Coefﬁcient (MCC), in that case,
produce more authentic and informative scores. MCC returns
a value between −1 and +1. A coefﬁcient of +1 signiﬁes
a perfect classiﬁcation, 0 is the expected value for arbitrary prediction, and −1 indicates perfect misclassiﬁcation
 , . The mathematical representation for MCC
displays in Tab. 2.
IV. DEEP LEARNING FOR THE SEGMENTATION OF
CERVICAL CYTOLOGY IMAGE
An overview of deep learning for cervical cytopathological
image segmentation work is compiled in this section. We have
summarized the proposed methodology, dataset, image preprocessing, and evaluation method of each paper in the reference review subsection. Next, we analyzed the suitable deep
learning approach in the method analysis section. Finally,
we concluded by summarizing the chapter.
A. REFERENCE REVIEW
In , a super-pixel and CNN based segmentation methods
are proposed for cervical cell segmentation. The author performs the cytoplasm segmentation ﬁrst since the background,
and cytoplasm contrast is not evident. Then CNN is applied
here to detect the region of interest. In this experiment, they
acquire the data privately. They use 1200 cell samples to train
the network and 200 cell units for testing. For performance
evaluation, they use 21 images (15 images have abnormal,
and six have normal nuclei). Image size is 1024×1360 pixels.
Pre-processing is done to reduce the noise of the image by the
trimmed mean ﬁlter. They achieved an F1 score above 0.89.
In , the author has developed a deep learning method
via a multiscale convolutional neural network (MSCN) for
feature extraction and graph partitioning for nucleus segmentation. The MSCN and graph partitioning algorithms can separate cytoplasm, nuclei, and background. However, to solve
the overlapping nucleus in the cell image, a new robust nuclei
clump algorithm is introduced. They privately collect the
dataset, which consists of 21 images (15 abnormal and six
normal) for this experiment. By using MSCN and graph
partitioning, they got cytoplasm and nucleus segmentation
accuracy of 90% and 85%, respectively.
VOLUME 8, 2020
M. M. Rahaman et al.: Survey for Cervical Cytopathology Image Analysis Using DL
An automated CAD system is proposed in . The author
in this study improves the existing Fuzzy c-means clustering
algorithm for nucleus segmentation by ﬁnding the optimum
number of clusters instead of ﬁxed clusters. Moreover, BPNN
is used to extract the shape features to match the regions as a
nucleus or non-nucleus. Publicly available Herlev University
database is used in this experiment. Pre-processing work is
done by using Perona-Malik diffusion (an isotropic diffusion)
ﬁlter to reduce noise. They obtained a precision, recall, and
ZSI value of 0.86, 0.90 and 0.85, individually.
In this experiment , the author proposed a unique deep
CNN-based framework that can accurately segment the cervical cells form overlapping clumps. This proposed method has
three parts. The ﬁrst part is the cell component segmentation.
The second part is multiple cell labeling, and the ﬁnal part is
cell boundary reﬁnement and inference. For the evaluation
of the segmentation method, they use two datasets: ISBI
2015 challenge dataset and one privately acquired dataset.
ISBI dataset consists of 8 cervical cytology images, and the
private dataset has 21 cervical cytology images. 5650 background, 8590 cytoplasms, and 8560 nucleus pixels are taken
from eight images in the SZU dataset to establish our training
set. For testing, they have used 1200 cells. Pre-processing has
been done by rotating the cell images from 0 to 180 degrees
with a step of 15 degrees. They transform the training sample
color into YUV to enhance performance. Figure 6 shows the
segmentation outcome of both of the datasets. They achieved
the dice coefﬁcient (DC) value 0.91 for cytoplasm and 0.93
for nucleus in the ISBI challenge dataset and 0.90 and 0.92
for cytoplasm and nucleus respectively in the private dataset.
FIGURE 6. Samples of the segmentation result for qualitative evaluation
of proposed approach. The upper row is from ISBI 2015 dataset, while the
bottom row derives from the private dataset .
Segmentation of the nucleus is essential because it carries
vital information about the cells. Considering that fact, 
in his paper proposed an automated cervical nucleus segmentation method. Usually, there are two methods for automatic
nucleus segmentation, one is initial segmentation, and the
other is ﬁne segmentation. For initial segmentation, a fully
convolutional network (FCN) image-patch based classiﬁcation method is suggested, which does not need any pre or
post-analysis. For ﬁne segmentation, a graph-based method
is proposed that can detect the nucleus boundary as a globally
optimal solution. For FCN training, VGGNet architecture
is deployed. Herlev dataset has utilized in this experiment.
ZSI value is calculated to check the performance of the
proposed algorithm. The ZSI value of 0.92 demonstrates the
outstanding performance of this experiment.
The author in presents a robust variational segmentation framework based on pixel-wise CNN and a learned
shape prior, that can successfully segment nuclei and cytoplasm form densely overlapping mass. The proposed method
ﬁrst classiﬁes the cellular components into the background,
nuclei, and cytoplasm using CNN. Later, individual cytoplasm segmentation work is performed with Voronoi segmentation and dynamic shape prior based level set evaluation. Figure 7. shows the detailed workﬂow of the proposed
method. In this work, they used two datasets form ISBI
2014. The ﬁrst one is the preliminary version of the baseline
method of the ISBI 2014 challenge. The 2nd one is the ISBI
challenge dataset. Two datasets contain a total of 159 cervical
cytology images with 870 cells in total. For quantitative pixellevel nucleus segmentation, the proposed method achieved
precision, recall, and ZSI index is 0.94, 0.95, and 0.94,
respectively, on the 2nd dataset. Moreover, they achieved ZSI
value 0.90, TP value 0.95 for cytoplasm segmentation. The
workﬂow of this work is shown in Fig. 7.
FIGURE 7. The workflow of the proposed learning methodology. (I) is the
3-class cellular components classification stage, including (1) cellular
patches generation and (2) CNN-based classification. (II) is the individual
cytoplasm segmentation stage, including (3) Voronoi segmentation and
(4) learned shape prior-based evolution .
The author presents a CNN based approach for the detection of nuclei from overlapping cervical cytology images
in . They used a Lightweight library called Lasagne
to construct CNN that is written in python and is build and
trained in Theano. The trained network can classify each pixel
to one of the classes: Nucleus, cytoplasm, or background.
Pixel that belongs to the nucleus is used for training. Then,
they apply the rectiﬁed linear unit as an activation function to
all convolutional and fully connected layers. ISBI 2014 challenge dataset is used in this experiment. Among 945 images,
45 images are used for training, 90 is for testing, and 810
is for evaluation. The proposed system yielded a precision
and recall value of 0.929 and 0.917, respectively, for nucleus
detection.
VOLUME 8, 2020
M. M. Rahaman et al.: Survey for Cervical Cytopathology Image Analysis Using DL
In this paper , the author proposes a patch-based
CNN approach using selective pre-processing for nuclei segmentation. VGGNet has used as CNN architecture to extract
features. Herlev dataset is employed to evaluate the performance of the proposed method. 70% images of each class are
used for training, 15% for validation and 15% is for testing.
Contrast enhancement has been performed for small and
compact nuclei as pre-processing. Their proposed method
achieved a similar ZSI and F1 value of 0.90.
In this study , the author suggests a unique method
to segment cervical cancer cell nuclei. They merge a mask
regional convolutional neural network (Mask-RCNN) for
coarse segmentation and local fully connected conditional
random ﬁeld (LFCCRF) to reﬁne the nuclear boundary.
ResNet based on feature pyramid network uses as a foundation of Mask-RCNN. Herlev dataset is used to evaluate the
performance of the proposed method. The suggested study
obtained 0.96, 0.96 and 0.95 for the precision, recall, and ZSI
value, respectively.
The author in presents an approach to segment the
whole cervical cell image by using Mask R-CNN and transfer
learning. ResNet10 is the backbone of Mask R-CNN. In the
beginning, the cell areas are partitioned by using MASK
R-CNN. Later, the cell areas are classiﬁed into nucleus
and cytoplasm. The network is pre-trained using the COCO
dataset consisting of 25, 00, 000 labeled objects with 91 categories. The introduced technique is evaluated using the Herlev dataset. In the preprocessing stage, images are resized
into 200 pixels, then the data augmentation technique is performed. The proposed algorithm produced a precision, recall,
and ZSI value of 92%, 91%, and 90%, respectively.
Deformable Multiple Ensemble Model(D-MEM), a unique
computerized segmentation technique based on deep neural
networks, is addressed in , for the segmentation of cervical cell nuclei. U-net is the backbone of the ensemble model.
The deformable convolution can segment objects with various appearances and dimensions. Moreover, they introduce
dense blocks to overcome the information vanishing problem.
The recommended methodology reached ZSI, Precision, and
Recall value of 0.933, 0.946, and 0.984 on the Herlev dataset.
A cell segmentation method from a special resolution of the
pap smear image is proposed in . This approach is composed based on fully convolutional neural networks (FCN-8
and FCN-16) and classical(superpixel-based) segmentation
approach. VGG-16 is the backbone of FCNs. A high resolution of 6 digitalized images, each with 94, 000 × 84000
pixels are taken to monitor the performance of the proposed
algorithm. Those large images are split into sub-images with
a resolution of 2000 × 2000 pixels. Seven hundred sixtyseven images are considered for training, and 315 images
are considered for testing. The data augmentation measure
is implemented to increase the volume of the dataset. They
reached a segmentation accuracy of 86.67% by combing all
the three techniques.
In , the author suggests a deep learning algorithm
based on LeNet architecture to segment both free-lying and
overlapping clumps of the abnormal cell from conventional
digitized pap smear images and rank those images according
to their level of abnormalities. A preprocessing system eliminates images before segmentation if it only holds background
or inadequate information, which improves the computational cost. They created two different datasets, speciﬁcally
training and test datasets contains 26 (24 abnormal and two
normal) and 168 (84 abnormal) images respectively from
Brazilian Health System (BHS). They used those datasets
to evaluate the performance of the proposed methodology.
Mean average precision (MAP) is used to evaluate the ranking
quality of the abnormal images. They achieved F score, precision, recall, and MAP value of 0.69, 0.73, 0.65, and 0.936,
individually.
A progressive growing U-net model (PGU-net+) introduces in to segment the nucleus of a cervical cell.
Two modiﬁcations are made to the classical U-net model.
Firstly, residual learning blocks attach to the different scales
of U-net. Secondly, a continuous developing training model
is selected, where the most inferior part with the downsample
images are trained ﬁrst and then following to the ﬁner part
for training until the full model is incorporated. Four sets of
measures are conducted to investigate the performance of the
recommended design on the Herlev dataset. It is explored that
among the classical U-net, U-net+, PGU-net, and PGUnet+,
PGUnet + gives the highest segmentation accuracy of ZSI,
precision, and recall value of 0.926, 0.901, and 0.968
sequentially.
In , A novel Instant Relation Network (IR-Net) is
advised to segment the overlapping cervical cell. ResNet-
50 is the backbone of the IR-Net. In this system, ﬁrstly,
object candidates are formed by the region proposal network
(RPN). Then the characteristics are obtained by the RoIAlign
layer and passed into two branches for the detection and
segmentation of the cell. Cervical pap smear (CPS) dataset
consisting of 4439 cytoplasms and 4789 nuclei is adopted to
evaluate the performance of the suggested method. 70% of
the dataset is accepted for training, 10% is for validation, and
20% is testing. They achieved Average Jaccard Index (AJI)
and F1 value of 0.7185 and 0.7497 for cytoplasm and 0.5496
and 0.7554 for nucleus segmentation.
B. METHOD ANALYSIS
It is observed from the reference review that most of the
research work has been conducted using the publicly available databases, which we have discussed in section III. The
research group that employs Herlev datasets is the only
one to perform nucleus segmentation. Zijdenbos similarity
index (ZSI) is a trendy method to evaluate the segmentation
result. The higher ZSI value symbolizes more reliable exactness. In , the author implements a backpropagation neural
network for feature extraction and fuzzy c-means clustering
to segment the nucleus. They obtain a ZSI value of 0.85.
However, in , the author proposes a combine Mask-
RCNN and LFCCRF to segment the nucleus and achieve a
ZSI value of 0.95. So, it is clear that the following approach
VOLUME 8, 2020
M. M. Rahaman et al.: Survey for Cervical Cytopathology Image Analysis Using DL
TABLE 3. Summary of reviewed works for the segmentation of cervical cytology image. (Multiscale convolutional neural network (MSCN), Back
propagation neural network (BPNN), Fully convolutional neural network (FCN), Regional convolutional neural network (RCNN), Local fully connected
conditional random field (LFCCRF), Accuracy (Acc), Precision (P), Recall (R), Zijdenbos similarity index (ZSI), Dice coefficient (DC), Deformable Multiple
Ensemble Model (D-MEM), Mean average precision (MAP), progressive growing U-net model (PGU-net+), Instant Relation Network (IR-Net), Cervical pap
smear (CPS), Average Jaccard Index (AJI)).
is more accurate for the segmentation of cervical cancer cell
Studies that are performing the segmentation of overlapping cervical cell employs private datasets or CPS or ISBI
challenge datasets. For the overlapping cells, segmentation
of cytoplasm and nucleus are both carried out. Segmentation
work, which combines pixel-wise CNN and a learned shape
prior, obtain the highest precision, recall, and ZSI value for
the overlapping cytoplasm and nucleus . Besides, one
task is recognized for the segmentation of the CPS dataset
based on IR-Net . So these are the preferable approaches
for the segmentation of overlapping cervical cells.
C. SUMMARY OF SEGMENTATION METHOD
A summary of the deep learning method for the segmentation
of cervical cancer cell is exhibited in table 3. This table
comprises of some essential attributes of any research paper.
publication
reference,
segmented region, segmentation techniques, dataset, data preprocessing, and result of an individual paper. From the
table, it can be perceived that most of the work reached an
exactitude of over 85%. Thus, it delivers a direction to the
new researchers to utilize the most suitable algorithm for the
segmentation of cervical cancer cells.
V. DEEP LEARNING FOR THE CLASSIFICATION OF
CERVICAL CYTOLOGY IMAGE
An overview of deep learning for cervical cytopathological image classiﬁcation practice is compiled in this section.
We summarize the proposed methodology, dataset, image
preprocessing, and evaluation method of each paper in the
reference review subsection. Next, we examine the suitable
deep learning strategy in the method analysis subsection.
Finally, we conclude by summarizing the chapter.
VOLUME 8, 2020
M. M. Rahaman et al.: Survey for Cervical Cytopathology Image Analysis Using DL
A. REFERENCE REVIEW
In , the author introduces a deep learning-based computerized vision system that is capable of classifying pap smear
cells into normal and dysplastic. The proposed architecture
has two steps for extracting the hierarchical data features,
which is supervised by independent neural agents. ANN is
pre-trained with a distinctive reticle pattern to develop a
prominent ability to recognize the unseen pap cells. Herlev
dataset is employed in this research. Images are resized into
100-by-100 pixels. Noise balanced training set has been utilized for training the dataset. One hundred images of each
class have been used for training, and 150 images of each
class are used for testing. The proposed method yielded a
sensitivity of 97% and speciﬁcity 96%.
A general-purpose (GP) system is stated in to
check the performance of different classiﬁers on twenty-ﬁve
datasets, among them, 14 are image datasets. Since our review
is based on cervical cytology images. Therefore, we only
consider the performance on cervical cytology images and
the best performing algorithms. The GP system can take care
of multiple datasets and a large number of problems. Local
Ternary Patterns (LTP) and Local Phase Quantization (LPQ)
are the two-texture descriptors that have used to extract
features for the image datasets. This experiment compares
the result of several classiﬁers (Gaussian process classiﬁer
(GPC), RS of AdaBoost (RS AB), RS of rotation boosting
(RS RB), RS of support vector machine (RS SVM) and deep
learning (DL)) with LibSVM library. The area of the ROC
curve (AUC) evaluates the performance of the GP system.
Ensemble four(E4) comprised of GPC, RS AB, RS RB,
RS SVM, and DL obtained the highest performance for all the
image datasets. On the Herlev dataset, E4 achieved an AUC
value of 0.92.
In , the author proposes an automatic CAD system
for the detection of cervical cancer from pap smear images.
They introduce a hybrid classiﬁer by combining SVM and
neural network-based adaptive neuro-fuzzy interface system
(ANFIS). GLCM, Local binary pattern features, grey level
features, histogram features wavelet features, and laws texture features are extracted. Herlev dataset was used to test the
proposed algorithm. Images are resized to 256 × 256 pixels,
and RGB to grey level color conversion has executed in the
preprocessing step. The proposed method has reached an
accuracy of 99.1% in a 2-class classiﬁcation problem.
A neural network-based automated system is developed
to classify the cervical cytology images into non-cancerous,
low-grade, and high-grade in . MATLAB image processing toolbox is used to extract features to train the backpropagation neural network algorithms. A private dataset
consisting of 38 images (12 high-grade, 10 low-grade,
16 non-cancerous cells) and 228 single cells are used to
evaluate the performance of this algorithm. In the preprocessing step, RGB to grey color conversion, morphological
operation, edge detection, and labeling work has performed.
The accuracy is obtained 79%, with sensitivity and speciﬁcity
of 94% and 68.2%, respectively.
In order to get much higher classiﬁcation accuracy,
the author in suggests a hybrid ensemble technique
for the screening of cervical cancer from pap smear. The
proposed ensemble technique combines 15 different classiﬁcation algorithms such as Random subset space, Radial
basis function network, Multiclass classiﬁer, Random forest,
Bagging, Rotation Forest, J48 graft, Ensemble of Nested
Dichotomies (END). Decorate, PART, Random Committee,
Filtered Classiﬁer, Decision Table, Multiple back propagation artiﬁcial neural network, and Naïve Bayes. To test
the proposed methodology, the Herlev dataset has considered. 75% of 1417 images are
granted for training, and rest are kept for testing. For
the 7-class classiﬁcation problem, the proposed technique
achieved an efﬁciency of 78%, and for the 2-class problem,
the hybrid ensemble has an efﬁciency of about 98%. The
hybrid ensemble technique performs better than any individually applied algorithm.
A deep convolutional neural network-based classiﬁcation
algorithm is recommended in . In this experiment, deep
features are extracted by using CNN, and later an unsupervised feature selection task is accomplished. AlexNet architecture is used as a base of CNN. After that, the feature
vectors are fed into two classiﬁers, namely a least-square
version of the support vector machine (LSSVM) and SoftMax
regression, to check the performance of these two classi-
ﬁers. Privately acquired single-cell image database containing 1611 images and Herlev dataset consisting of 917 images
are considered to check the performance of the proposed
study. 70% of instances are accounted for training, and rest
are counted for testing. Study has found that after the application of feature selection, the accuracy has improved to
90 −95% from 84 −87%. On the private database, SoftMax
regression achieved an accuracy of 93.1%, whereas LSSVM
achieved 92.24% on a 3-class classiﬁcation problem. For a
2-class problem, LSSVM and SoftMax yielded 98.88% and
99.32% of accuracy independently. On the Herlev database,
the accuracy is 89.97% and 88.88% by LSSVM and SoftMax
respectively on a 3-class classiﬁcation problem. Moreover,
for 2-class classiﬁcation, the accuracy is 94.61% and 91.81%
by LSSVM and SoftMax individually.
In , the experimenter’s design and train a CNN and
machine learning classiﬁers-based model to classify the cervical pap images into normal and abnormal. A privately
acquired pap smear dataset consisting of 71344 images are
used to evaluate the performance of the proposed method.
VGG16 has used to extract features. In preprocessing work,
the actual image is divided into several pieces, since VGG
can take input of an image size of 224 × 224. 80% of images
are used for training, and 20% is for testing. They explored
that SVM performs better compared to logistic regression,
random forest, and adaboost and achieved a 78% F1 score.
In , the author proposes a pre-trained CNN architecture rather than designing and training from scratch
to extract the in-depth features to train an SVM classiﬁer. AlexNet architecture has used in this experiment.
VOLUME 8, 2020
M. M. Rahaman et al.: Survey for Cervical Cytopathology Image Analysis Using DL
The proposed method achieved precision, recall, speciﬁcity,
and accuracy of 99.51%, 99.5%, 97.67%, 99.19% independently on Herlev dataset on a 2-class classiﬁcation problem.
70% of the images are used for training, and rest are used for
In order to investigate the effectiveness of the artiﬁcial
neural network, a multilayer perceptron based neural network (MLP-ANN) has proposed in to classify cervical
pap image into benign and malignant. A privately acquired
database consisting of 416 liquid-based cytology images u
sed for this experiment. 50% of the datasets are used to
train MPL-ANN, and the other 50% is used to evaluate the
performance and stability of ANN. The percentage classiﬁer
gives an overall accuracy of 95.91%, compared to 90.87% in
the simple numeric classiﬁer.
To automatically detect the morphology and chromatinassociated changes of the cervical cell nucleus, a CNN based
approach has been developed in . VGG16 and ResNet
architecture is used as CNN. CerviSCAN and Herlev dataset
is used to evaluate the performance of the proposed method.
CerviSCAN is a private dataset consisting of 9809 healthy
and 2234 abnormal single-cell images. In the preprocessing work, the variance of Laplacian was used to ﬁnd the
image with the best focus. Then, they resize the image into
100 × 100 pixels, and images are augmented to expand the
dataset. For the CerviSCAN dataset, both of the network
architecture achieved an accuracy and F score of over 84%.
Herlev dataset yielded an accuracy of 86% on both network
architectures, and F1 scores 82% on VGGNet and 83% on
ResNet. They explored that for the cervical cell classiﬁcation
task, ResNet is more suitable over VGG.
A very ﬁrst application of deep learning and transfer
learning methods for the classiﬁcation of the cervical cell
into normal and abnormal is proposed in . Herlev and
HEMLBC (private) datasets have utilized to evaluate the proposed method. HEMLBC dataset consists of 989 abnormal
and 1381 normal cells. Patch extraction and data augmentation are performed in the preprocessing work. On Herlev dataset sensitivity, speciﬁcity, accuracy and F1 measure
are 98.2%, 98.3%, 98.3% and 98.8%, separately. On the
HEMLBC dataset, they yielded sensitivity 98.3%, speciﬁcity
99%, and accuracy 98.6%.
A few general-purpose (GP) systems are available that
can provide results comparable with the state of the art system. Some researchers build a GP system that can operate
up to 16 datasets, but no system has developed so far that
can work well across all the dataset. In , the author
has developed a better performing GP ensemble model by
comparing and combining state of the art handcrafted features with non-handcrafted features that can handle an extensive range of image classiﬁcation problems. Deep transfer
learning features based on CNN, principle component analysis, and compact binary descriptor are considered to extract
the non-handcrafted features. Local ternary patterns, local
phase quantization, and so on are examined to extract the
handcrafted features. Among 18 different image datasets,
the Herlev dataset is reviewed to evaluate the performance
of the suggested system. They explored that performance
of the transfer learning is more excellent than the standard
approach. Besides, a combination of handcrafted with nonhandcrafted features performs better than their individual.
They obtained an accuracy of 95.1% with transfer learning,
whereas 91.4% by standard approaches on the Herlev dataset.
In , the author proposes a deep learning-based cervical cell analysis system–detection, segmentation, and classi-
ﬁcation. Based on the purpose of our study, we only focus on
the classiﬁcation approach. Feature level analysis using transfer learning on AlexNet has proposed for the classiﬁcation of
the Herlev dataset. They proved that accurate segmentation is
not necessary for classiﬁcation. For a 2-class problem, they
achieved an accuracy of 99.3% and 93.75% for the 7-class
classiﬁcation problem on the Herlev dataset.
In , a unique cervical cell study is presented by connecting morphological and appearance-based characteristics
with in-depth features. They examined that the combination
of appearance and morphology-based CNNs provides more
positive classiﬁcation accuracy than their individual. CNN
models such as AlexNet, GoogLeNet, ResNet, and DenseNet
Image are pre-trained on the ImageNet dataset and later ﬁnetuned on the cervical cell dataset. Herlev dataset is utilized to
test the performance of the recommended model. patch and
cell morphology extraction, along with data augmentation
task is executed in the preprocessing step. Among the four
CNN’s, GoogLeNet obtains the highest classiﬁcation accuracies of 94.5%, 71.3%, and 64.5% for 2-class, 4-class, and
7-class classiﬁcation problems. It is to be remarked that the
segmentation of the nucleus and cytoplasm are pre-required
to employ this method.
In , pre-segmented cervical cell images are fed into
the VGG-like network to perform the classiﬁcation task.
The VGG-like network is the compact version of its original
consists of 7 layers to reduce the computing costs. Segmented
images are resized, augmented, and copied to speciﬁc folders
for 2 and 7-class classiﬁcation cases in the preprocessing step.
For a binary classiﬁcation problem, they achieved 96.7%
sensitivity, 98.6% speciﬁcity, and 98.1% accuracy. Similarly,
for 7-class problems, they achieved 96.2% sensitivity, 99.3%
speciﬁcity, and 95.9% accuracy on the Herlev dataset.
A comparative analysis of the cervical cytopathology
image in deep learning is introduced in . Five deep
learning models, such as ResNet101, DenseNet161, AlexNet,
VGG19_bn, and SqueezeNet1_1 are assessed to compare the
performance on the Herlev dataset. 70% of pap images are
accepted for training, 20% is for validation, and 10% is for
testing. They investigate that DenseNet161 is the best DL
model among those 5 DL models to provide the maximum
accuracy of 94.38% and 68.54% in binary and 7 level classi-
ﬁcation problem.
In , a mask regional convolutional neural network
(Mask R-CNN) is recommended to identify the nucleus of
pap smear slides and organize it into healthy and irregular.
One hundred seventy-eight images from the pap smear slides
VOLUME 8, 2020
M. M. Rahaman et al.: Survey for Cervical Cytopathology Image Analysis Using DL
TABLE 4. Summary of reviewed works for the classification of cervical cytology image. (Sensitivity (Sn), Specificity (Sp), Efficiency (Eff ), Area of the ROC
curve (AUC), Precision (P), Recall (R), General purpose (GP), Accuracy (Acc), Gaussian process classifier (GPC), RS of AdaBoost (RS_AB), RS of rotation
boosting (RS_RB), RS of support vector machine (RS_SVM), Deep learning (DL), Multilayer perceptron (MLP), Variance of Laplacian (VL), Mean average
precision (mAP)).
are collected from Thammasat University hospital to check
the performance of the recommended algorithm. 20% of the
datasets are used for testing, and the rest are considered for
training and validation. ResNet-50, which is pre-trained on
the ImageNet dataset, is used as a backbone network for the
feature pyramid of Mask R-CNN. During the training process, the images are preprocessed by resizing, augmentation,
and mean subtraction. The mean average precision (mAP)
value represents the performance of a combined detection and
classiﬁcation task. They achieved an mAP value of 57.8%
and an accuracy of 97.1% per image.
In , a feature concatenation and ensemble approaches
are suggested by coupling several CNNs (Inception-v3,
Resnet152, and Inception-Resnet-v2) with different depths
and structures to classify biomedical images. Three publicly available datasets such as the 2D Hela dataset, PAP
VOLUME 8, 2020
M. M. Rahaman et al.: Survey for Cervical Cytopathology Image Analysis Using DL
smear dataset, and Hep-2 cell image datasets have considered
checking the performance of the introduced method. It is
noticed that an ensemble of different models obtain more reliable results than individual ones. Ensemble of Inception-v3,
Resnet152, Inception-Resnet-v2, and feature concatenation
of those three achieved 93.04% accuracy on the Herlev
B. METHOD ANALYSIS
It is apparent from the reference review that openly accessible
databases have been examined widely to check the performance of the recommended model. Out of eighteen studies,
14 of them utilize the Herlev dataset to check the performance
of their introduced algorithms and compare the outcome with
Some researchers employ hybrid ensemble techniques,
where they combine lots of classiﬁcation algorithms along
with different image datasets. However, they could not
accomplish a state of the art accuracy on any speciﬁc dataset.
Most of the contributors utilize CNN to extract the deep
features and then manage classiﬁers like SVM to analyze the
cell images. The author in compares the results obtained
from ResNet and VGGNet and verify that ResNet is more
suitable for the classiﬁcation of the cervical cytology images.
Most of the researchers achieve accuracies over 80%. The
highest classiﬁcation accuracy achieved for 2-class is 99.3%
and 93.7% for 7-class problems on the Herlev dataset by
using the algorithm combination of deep learning and transfer
learning . Moreover, a VGG-like network reaches the
highest correctness of 95.9% on 7-class problem .
C. SUMMARY OF CLASSIFICATION METHOD
A summary of the deep learning methods for the classiﬁcation of the cervical cytopathological image is presented in
Tab. 4. The given index is composed of all the key attributes
of any research paper. Each row designates publication year,
reference, proposed method, types of classiﬁcation problem,
dataset, preprocessing, and result. From the table, it can
be noticed that most of the work achieves an accuracy of
over 80%. Thus, it provides a direction for new researchers
to pick the most suitable algorithm for the classiﬁcation of
cervical cells.
VI. METHODOLOGY ANALYSIS
Various deep learning-based algorithms have been designing for the segmentation and classiﬁcation of the cervical
cytological image. Among them, few algorithms have shown
tremendous results. Thus, a corresponding in-depth analysis
of the best performing algorithms is given in the subsection
A. ANALYSIS OF THE SEGMENTATION METHOD
The segmentation of cervical cancer cells can be divided
into two parts. One is overlapping, and the other is nonoverlapping. Cytoplasm and nucleus segmentation tasks have
performed in the case of an overlapping cell. Segmentation of
cytoplasm from an overlapping cell is always challenging.
MS-CNN, along with shape priors-based methods, are found
to have more prominent result , over others , ,
 , – . MS-CNN has some advantages over conventional CNN. Small size inputs of a regular CNN provides
below standard observations, whereas large dimension inputs
not only expands the network parameter but also add noise,
which is challenging to manage. On the other hand, multiscale CNN takes an input size of 32 × 32 pixels and can offer
an observation of 128×128 pixels, which can eliminate noise
and also merge the network parameters. Multiple cell labeling
model is also proposed in this algorithm since MS-CNN
cannot predict the speciﬁc cell that gives the pixels of cytoplasm and nucleus. Moreover, the portion of overlapping
regions can have multiple cell labeling. Therefore, a multitemplate deformation model is proposed to recover the weak
boundary of an overlapping cell. This proposed template
yielded the dice coefﬁcient value of 0.91 and 0.93 for the
segmentation of the cytoplasm and nucleus independently
on the ISBI 2015 challenge dataset . Super pixel-wise
CNN and a learned shape prior, based model have shown
superior performance for the segmentation of overlapping
cytoplasm and nucleus on the ISBI 2014 challenge dataset.
However, the overlapping cell ratio is higher in the 2015 challenge dataset than in 2014. So, we can say that MS-CNN,
along with shape priors, is preferable for the segmentation of
overlapping cells.
Among non-overlapping cells, the nucleus segmentation
task has been conducted widely because the nucleus of a cell
sustains essential diagnostic information for cervical cancer.
A MASK-RCNN merged with a LFCCRF gives superior performance over other methods , , . MASK-
RCNN performs the coarse segmentation of the nucleus.
It is composed of feature extraction, region proposal network
(RPN), and prediction. In the ﬁrst step, a feature pyramid
network (FPN) based on ResNet along with feature extraction
layer work as a foundation of MASK-RCNN. Then, RPN
uses the feature map provided by FPN to create the proposal
for the objects. Finally, in the RoIAlign layer, the features
from RPN are converted into small feature maps with a ﬁxed
dimensional scale (H × W), which leads to the accurate
deployment of the nuclear boundary. In the LFCCRF part,
coarse segmentation results from Mask-RCNN, intensity, and
pixel-level information has employed to reﬁne the nuclear
boundary. This proposed approach yielded the highest precision, recall, and ZSI value of 0.96, 0.96, and 0.95 on the
Herlev dataset.
For overlapping cell segmentation, publicly available ISBI
2014 and 2015 datasets have been utilized widely. Herlev
dataset has considered for the evaluation of non-overlapping
cervical cells. A detailed explanation of the dataset has been
given in Sec. III.
B. ANALYSIS OF THE CLASSIFICATION METHOD
We have observed that more than 90% of studies have utilized the Herlev dataset to check the performance of their
VOLUME 8, 2020
M. M. Rahaman et al.: Survey for Cervical Cytopathology Image Analysis Using DL
classiﬁcation algorithms. This dataset is divided into seven
classes. However, most of them further categorized these
seven classes into two classes as normal and abnormal. So far,
it is observed that in the proposed algorithm 2-class classi-
ﬁcation problem achieves higher accuracy than the 7-class
classiﬁcation problem.
The heterogeneous GP ensemble system has been developed in , to classify various types of microscopic
images. The result they produce is comparable with the
state-of-the-art systems. In , deep learning, RS_SVM,
RS_AB, and GPC are merged to examine on 25 datasets.
On the Herlev dataset, the proposed GP system got an AUC
value of 0.92, which is very promising. Similarly, in ,
a combination of CNN with transfer learning is introduced to
create a general-purpose system that can classify 18 different
types of image datasets and yield an accuracy of 95.1% on
Herlev dataset.
It is discerned that a combination of two or three algorithms has a better recognition ability than the individual one.
 , , proposes classiﬁcation algorithm based on
single classiﬁers, for instance, Deep ANN or BPNN 
or CNN . Those algorithms need multiple data preprocessing operations, such as data resize, augmentation,
edge detection, and cell labeling. Moreover, they failed to
give state of the art accuracies. On the other hand, studies , – , that combined CNN with SVM,
transfer learning, or decision tree performed out of the
box for the classiﬁcation of cervical cancer with a little
or no preprocessing. A combination of CNN (AlexNet)
along with transfer learning and decision tree-based algorithm provides superior performance over others
 , – , – . AlexNet is considering to
have a smaller architecture with efﬁcient performance. Since
there is a more inadequate availability of annotated cells in the
medical domain, so the use of transfer learning is beneﬁcial
in this regard. It also reduces training time. Besides, for
the multiclass classiﬁcation problem, a decision tree-based
algorithm is proposed. This advanced combined technique
yielded an accuracy of 99.3% for 2-class and 93.75% for
7-class classiﬁcation on the Herlev dataset . Moreover,
a compact version of the VGG-like network, consisting of
only seven layers, has employed on pre-segmented images
of the Herlev dataset and reaches an accuracy of 95.9% on
7 class classiﬁcation problems .
C. POTENTIAL RELATED FIELDS FOR THE APPLICATION OF
SIMILAR SEGMENTATION AND CLASSIFICATION METHOD
Segmentation algorithms that have been discussed in this
review are not only applicable for cervical cytopathology images but also in some other medical ﬁelds such
as pleural effusion images, breast cytology images, sperm
cells, and microorganisms. A cytological pleural effusion
has been examined by pathologists because of its simplicity, cost-effectiveness, and less invasive over X-ray, ultrasound, computed tomography (CT), and magnetic resonance
imaging (MRI). There are many CAD systems developed
for the detection or segmentation of the nucleus of pleural images. Most of them are based on machine learning
techniques. Particular examples are automated cell nuclei
segmentation , detection of cancer cells , ,
segmentation, and isolation of touching nuclei . Next,
the nucleus segmentation of breast ﬁne-needle aspiration
cytology (FNAC) images will be a handy ﬁeld in this
regard – . For a more precise diagnostic, FNAC is
performed by a patient. Then, the same segmentation technique can be applied for the sperm cell segmentation, detection, tracking, and counting – . Moreover, the discussed segmentation algorithms also have potential applications in the microorganism. Microorganisms are signiﬁcant
for our ecosystem, and the segmentation of microorganisms
is essential in order to ﬁnd the harmful and useful one.
In the literature, there are many classical – and
machine learning – based segmentation methods
that has been applied for the segmentation of microorganisms.
Furthermore, the discussed deep learning algorithms can ﬁnd
signiﬁcant use in segmentation of microorganisms.
Similarly, the deep learning-based classiﬁcation algorithm
discussed in this paper also has potential in some other medical ﬁelds such as cytology of the gastrointestinal system,
thyroid gland, breast, and effusion system. First of all, the
gastrointestinal system incorporates all organs in between
mouth and anus. Based on the morphometry of the nucleus,
they classify the smears into cancer, gastric, and ulcer
 – . Secondly, FNAC based on thyroid examination
is another potential ﬁeld for application. Depending on the
classiﬁcation result, it can be found out whether the patient
needs surgery or not – . Thirdly, many efforts have
been made for the classiﬁcation of cells form malignant
ones – . Finally, in the ﬁeld of effusion cytopathology, to differentiate the reactive lymphocytosis from malignant lymphoma and classify the benign cases from
malignant ones is another potential research area.
D. OTHER POTENTIAL METHODS FOR THE
SEGMENTATION AND CLASSIFICATION OF
CERVICAL CYTOPATHOLOGY IMAGE
In this subsection, we introduce some potential deep learning
methods that have been successfully implemented in some
other medical imaging ﬁelds and have potential in cervical
cytopathology image analysis as well.
1) POTENTIAL SEGMENTATION METHODS
Lack of training data is a big challenge in biomedical image
segmentation. Considering the fact CNN based U-Net architecture has been developed by combining the low- and highlevel features through skip connections for biomedical image
segmentation . To the best of our knowledge, there
is no previous work using the U-Net structure on cervical
cytopathology image segmentation.
Rift Valley virus segmentation work is proposed in ,
based on U-Net architecture. Even though there were insuf-
ﬁcient data and minimal annotated images, they achieved
a promising result of the dice coefﬁcient value of 0.90.
VOLUME 8, 2020
M. M. Rahaman et al.: Survey for Cervical Cytopathology Image Analysis Using DL
Similarly,
leishmania
segmentation
performed in , depending on U-Net architecture.
Thirty-seven images are used to train the algorithm. Outstanding performance has achieved with 82.30% recall value.
Both of those microscopic image datasets share some
similar segmentation challenges with pap smear images like
noise, debris, poor contrast, and scarcity of dataset. So, we
believe that U-Net can show outstanding performance for the
segmentation of cervical cytopathology images.
2) POTENTIAL CLASSIFICATION METHODS
Generative Adversarial Networks (GANs) is one of the most
recent discoveries of deep learning. It is a particular type of
neural network that can train two networks at the same time.
One of them focuses on image generation, and the other is for
discrimination. A discriminative model distinguishes features
of the input image by providing labels, whereas the generative
model does the opposite. Rather than giving labels based on
features, they give features on individual labels . With
the addition of a new class parallel with generated images,
discriminator can be used as a classiﬁer . Some notable
applications of GANs for image classiﬁcation problems are
introduced below.
A combination of Wasserstein-GAN(WGAN) and information maximizing GAN (InfoGAN) is proposed in 
for unsupervised cell level feature representation that can
be further used for cell-level classiﬁcation, nuclei segmentation, and cell counting. The proposed system yielded an
outstanding performance on bone marrow cellular components. Moreover, the dermoscopy image classiﬁcation algorithm is proposed in by adding WGAN and categorical
GAN(catGAN) in an unsupervised and semi-supervised feature learning manner. The proposed model yielded an average precision value of 0.424, with only 140 labeled images.
Furthermore, traditional feature extraction practices such as
histogram of oriented gradients (HOG) , a combination
of K-means with fuzzy c-means clustering , and a fusion
of textual and statistical information are potent procedures in analyzing the pap cell. However, they fail to produce
the state of the art accuracies. Therefore, a mix of traditional
and deep features can deliver a more effective result in examining the pap cells. These instances demonstrate the potential
of the proposed method, which can be applied for the cervical
cytopathology image classiﬁcation problem where limited
labeled data is available.
VII. CONCLUSION AND FUTURE WORK
In this paper, we examined studies related to cervical
cytopathology image segmentation and classiﬁcation based
on deep learning techniques. Besides, major deep learning
concepts and their popular architectures are also explained.
The review showed that cervical cytopathology image analysis in deep learning is an increasing topic of interest.
Most of the state-of-the-art methods that have been proposed for the segmentation and classiﬁcation are applied to
the same dataset. Thus, it is obvious to distinguish which
algorithm is better than others. The Herlev dataset and
ISBI challenge dataset are the publicly available benchmark
datasets. MS-CNN, along with shape prior based method
and MASK-RCNN merged with LFCCRF give superior
performance for the segmentation of overlapping and nonoverlapping cervical cell respectively. For the classiﬁcation
work, the combination of CNN(AlexNet) along with transfer
learning and decision tree-based algorithm has better recognition ability. So, it is observed that compound algorithms can
improve the performance of a classiﬁer. AlexNet, VGGNet,
and ResNet are found to be the most popular CNN architecture for feature extraction in this ﬁeld.
It is perceived that CNN has achieved outstanding performance in the task of segmentation and classiﬁcation, which
will help the patient for the early detection, diagnosis, and
treatment of cervical cancer. However, there is still room for
improvement. First of all, texture feature is a signiﬁcant lowlevel feature that can describe the content or region of an
image very adequately. Hence, concatenation of some novel
texture descriptors such as hybrid color local binary patterns
(HCLBP) , moment invariant features, wavelet features,
local binary pattern (LBP) and elongated quinary pattern (EQP) with deep features can lead to a superior
performance of network model. Secondly, researchers can
develop entirely new CNN architecture for the analysis of
cervical pap smear cells. Thirdly, the analysis of overlapping
cells is still a big challenge. Fourthly, designing an algorithm
that can analyze whole slide images, which may contain
millions of cells, is still an open challenge. Fifthly, to the
best of our knowledge, there are only three open sources pap
smear database is available with a signiﬁcantly imbalanced
ratio of positive and negative, so to create a public dataset will
be beneﬁcial for future researchers. Finally, attempts have
been made to create deep learning enhanced mobile phone
microscopy . So to develop a mobile phone application
that can use the mobile phone microscopy to automatically
analyze pap slides would be extremely useful.
ACKNOWLEDGMENT
(Chen Li is co-ﬁrst author.) The authors ﬁrst thank Zixian Li
and Guoxian Li for their important discussion and also
Afnan Ghazi and B. E. Frank Kulwa for their great proofreading work.