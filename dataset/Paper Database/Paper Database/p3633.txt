Federated Learning
Predicting Human Decision-Making: From Prediction to Action
Ariel Rosenfeld and Sarit Kraus
Game Theory for Data Science: Eliciting Truthful Information
Boi Faltings and Goran Radanovic
Multi-Objective Decision Making
Diederik M. Roijers and Shimon Whiteson
Lifelong Machine Learning
Zhiyuan Chen and Bing Liu
Statistical Relational Artiﬁcial Intelligence: Logic, Probability, and Computation
Luc De Raedt, Kristian Kersting, Sriraam Natarajan, and David Poole
Representing and Reasoning with Qualitative Preferences: Tools and Applications
Ganesh Ram Santhanam, Samik Basu, and Vasant Honavar
Metric Learning
Aurélien Bellet, Amaury Habrard, and Marc Sebban
Graph-Based Semi-Supervised Learning
Amarnag Subramanya and Partha Pratim Talukdar
Robot Learning from Human Teachers
Sonia Chernova and Andrea L. Thomaz
General Game Playing
Michael Genesereth and Michael Thielscher
Judgment Aggregation: A Primer
Davide Grossi and Gabriella Pigozzi
An Introduction to Constraint-Based Temporal Reasoning
Roman Barták, Robert A. Morris, and K. Brent Venable
Reasoning with Probabilistic and Deterministic Graphical Models: Exact Algorithms
Rina Dechter
Introduction to Intelligent Systems in Traﬃc and Transportation
Ana L.C. Bazzan and Franziska Klügl
A Concise Introduction to Models and Methods for Automated Planning
Hector Geﬀner and Blai Bonet
Essential Principles for Autonomous Robotics
Henry Hexmoor
Case-Based Reasoning: A Concise Introduction
Beatriz López
Answer Set Solving in Practice
Martin Gebser, Roland Kaminski, Benjamin Kaufmann, and Torsten Schaub
Planning with Markov Decision Processes: An AI Perspective
Mausam and Andrey Kolobov
Active Learning
Burr Settles
Computational Aspects of Cooperative Game Theory
Georgios Chalkiadakis, Edith Elkind, and Michael Wooldridge
Representations and Techniques for 3D Object Recognition and Scene Interpretation
Derek Hoiem and Silvio Savarese
A Short Introduction to Preferences: Between Artiﬁcial Intelligence and Social Choice
Francesca Rossi, Kristen Brent Venable, and Toby Walsh
Human Computation
Edith Law and Luis von Ahn
Trading Agents
Michael P. Wellman
Visual Object Recognition
Kristen Grauman and Bastian Leibe
Learning with Support Vector Machines
Colin Campbell and Yiming Ying
Algorithms for Reinforcement Learning
Csaba Szepesvári
Data Integration: The Relational Logic Approach
Michael Genesereth
Markov Logic: An Interface Layer for Artiﬁcial Intelligence
Pedro Domingos and Daniel Lowd
Introduction to Semi-Supervised Learning
Xiaojin Zhu and Andrew B. Goldberg
Action Programming Languages
Michael Thielscher
Representation Discovery using Harmonic Analysis
Sridhar Mahadevan
Essentials of Game Theory: A Concise Multidisciplinary Introduction
Kevin Leyton-Brown and Yoav Shoham
A Concise Introduction to Multiagent Systems and Distributed Artiﬁcial Intelligence
Nikos Vlassis
Intelligent Autonomous Robotics: A Robot Soccer Case Study
Peter Stone
© Springer Nature Switzerland AG 2022
Reprint of original edition © Morgan & Claypool 2020
All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted in
any form or by any means—electronic, mechanical, photocopy, recording, or any other except for brief quotations
in printed reviews, without the prior permission of the publisher.
Federated Learning
Qiang Yang, Yang Liu, Yong Cheng, Yan Kang, Tianjian Chen, and Han Yu
ISBN: 978-3-031-00457-5
ISBN: 978-3-031-01585-4
ISBN: 978-3-031-00030-0
DOI 10.1007/978-3-031-01585-4
A Publication in the Springer series
SYNTHESIS LECTURES ON ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING
Lecture #43
Series Editors: Ronald J. Brachman, Jacobs Technion-Cornell Institute at Cornell Tech
Francesca Rossi, IBM Research AI
Peter Stone, University of Texas at Austin
Series ISSN
Synthesis Lectures on Artiﬁcial Intelligence and Machine Learning
Print 1939-4608
Electronic 1939-4616
Federated Learning
Qiang Yang
WeBank and Hong Kong University of Science and Technology, China
WeBank, China
Yong Cheng
WeBank, China
WeBank, China
Tianjian Chen
WeBank, China
Nanyang Technological University, Singapore
SYNTHESIS LECTURES ON ARTIFICIAL INTELLIGENCE AND
MACHINE LEARNING #43
l publishers
How is it possible to allow multiple data owners to collaboratively train and use a shared prediction model while keeping all the local training data private? Traditional machine learning
approaches need to combine all data at one location, typically a data center, which may very
well violate the laws on user privacy and data conﬁdentiality. Today, many parts of the world
demand that technology companies treat user data carefully according to user-privacy laws. The
European Union’s General Data Protection Regulation (GDPR) is a prime example. In this
book, we describe how federated machine learning addresses this problem with novel solutions
combining distributed machine learning, cryptography and security, and incentive mechanism
design based on economic principles and game theory. We explain diﬀerent types of privacypreserving machine learning solutions and their technological backgrounds, and highlight some
representative practical use cases. We show how federated learning can become the foundation of
next-generation machine learning that caters to technological and societal needs for responsible
AI development and application.
federated learning, secure multi-party computation, privacy preserving machine
learning, machine learning algorithms, transfer learning, artiﬁcial intelligence, data
conﬁdentiality, GDPR, privacy regulations
Preface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiii
Acknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xvii
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
Federated Learning as a Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
The Deﬁnition of Federated Learning . . . . . . . . . . . . . . . . . . . . . . . . . . 4
Categories of Federated Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
Current Development in Federated Learning . . . . . . . . . . . . . . . . . . . . . . . . . . 10
Research Issues in Federated Learning . . . . . . . . . . . . . . . . . . . . . . . . 10
Open-Source Projects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
Standardization Eﬀorts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
The Federated AI Ecosystem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
Organization of this Book . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
Privacy-Preserving Machine Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
PPML and Secure ML . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
Threat and Security Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
Privacy Threat Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
Adversary and Security Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
Privacy Preservation Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
Secure Multi-Party Computation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
Homomorphic Encryption . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
Diﬀerential Privacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
Distributed Machine Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
Introduction to DML . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
The Deﬁnition of DML . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
DML Platforms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
Scalability-Motivated DML . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
Large-Scale Machine Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
Scalability-Oriented DML Schemes . . . . . . . . . . . . . . . . . . . . . . . . . . 37
Privacy-Motivated DML . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
Privacy-Preserving Decision Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
Privacy-Preserving Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
Privacy-Preserving DML Schemes . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
Privacy-Preserving Gradient Descent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
Vanilla Federated Learning. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
Privacy-Preserving Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
Horizontal Federated Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
The Deﬁnition of HFL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
Architecture of HFL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
The Client-Server Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51
The Peer-to-Peer Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
Global Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
The Federated Averaging Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
Federated Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
The FedAvg Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
The Secured FedAvg Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
Improvement of the FedAvg Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
Communication Eﬃciency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
Client Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
Related Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
Challenges and Outlook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
Vertical Federated Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
The Deﬁnition of VFL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
Architecture of VFL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
Algorithms of VFL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
Secure Federated Linear Regression. . . . . . . . . . . . . . . . . . . . . . . . . . . 73
Secure Federated Tree-Boosting. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
Challenges and Outlook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
Federated Transfer Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
Heterogeneous Federated Learning. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
Federated Transfer Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
The FTL Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86
Additively Homomorphic Encryption . . . . . . . . . . . . . . . . . . . . . . . . . 88
The FTL Training Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
The FTL Prediction Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
Security Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
Secret Sharing-Based FTL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
Challenges and Outlook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92
Incentive Mechanism Design for Federated Learning . . . . . . . . . . . . . . . . . . . . 95
Paying for Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
Proﬁt-Sharing Games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
Reverse Auctions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
A Fairness-Aware Proﬁt Sharing Framework . . . . . . . . . . . . . . . . . . . . . . . . . . 98
Modeling Contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
Modeling Cost . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
Modeling Regret . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
Modeling Temporal Regret . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
The Policy Orchestrator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
Computing PayoﬀWeightage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
Discussions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
Federated Learning for Vision, Language, and Recommendation . . . . . . . . . 107
Federated Learning for Computer Vision . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
Federated CV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
Related Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
Challenges and Outlook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
Federated Learning for NLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
Federated NLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112
Related Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
Challenges and Outlook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
Federated Learning for Recommendation Systems . . . . . . . . . . . . . . . . . . . . 114
Recommendation Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
Federated Recommendation System . . . . . . . . . . . . . . . . . . . . . . . . . 116
Related Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
Challenges and Outlook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
Federated Reinforcement Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
Introduction to Reinforcement Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
Policy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
Reward . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
Value Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
Model of the Environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
RL Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
Reinforcement Learning Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
Distributed Reinforcement Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
Asynchronous Distributed Reinforcement Learning. . . . . . . . . . . . . 125
Synchronous Distributed Reinforcement Learning . . . . . . . . . . . . . . 126
Federated Reinforcement Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
Challenges and Outlook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
Selected Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
Finance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
Healthcare . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
Education . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
Urban Computing and Smart City . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
Edge Computing and Internet of Things . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
Blockchain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
5G Mobile Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
Summary and Outlook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
Legal Development on Data Protection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
Data Protection in the European Union . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
The Terminology of GDPR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
Highlights of GDPR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
Impact of GDPR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150
Data Protection in the USA. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
Data Protection in China . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
Authors’ Biographies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
This book is about how to build and use machine learning (ML) models in artiﬁcial intelligence
(AI) applications when the data are scattered across diﬀerent sites, owned by diﬀerent individuals or organizations, and there is no easy solution to bring the data together. Nowadays, we
often hear that we are in the era of big data, and big data is an important ingredient that fuels
AI advances in today’s society. However, the truth is that we are in an era of small, isolated, and
fragmented data silos. Data are collected and located at edge devices such as mobile phones.
Organizations such as hospitals often have limited views on users’ data due to their specialties.
However, privacy and security requirements make it increasingly infeasible to merge the data at
diﬀerent organizations in a simple way. In such a context, federated machine learning (or federated learning, in short) emerges as a functional solution that can help build high-performance
models shared among multiple parties while still complying with requirements for user privacy
and data conﬁdentiality.
Besides privacy and security concerns, another strong motivation for federated learning is
to maximally use the computing power at the edge devices of a cloud system, where the communication is most eﬃcient when only the computed results, rather than raw data, are transmitted
between devices and servers. For example, autonomous cars can handle most computation locally and exchange the required results with the cloud at intervals. Satellites can ﬁnish most of
the computation for information that they are to gather and communicate with the earth-based
computers using minimal communication channels. Federated learning allows synchronization
of computation between multiple devices and computing servers by exchanging only computed
We can explain federated learning with an analogy. That is, an ML model is like a sheep
and the data is the grass. A traditional way to rear sheep is by buying the grass and transferring
it to where the sheep is located, much like when we buy the datasets and move them to a central
server. However, privacy concerns and regulations prevent us from physically moving the data.
In our analogy, the grass can no longer travel outside its local area. Instead, federated learning
employs a dual methodology. We can let the sheep graze multiple grasslands, much like our ML
model that is built in a distributed manner without the data traveling outside its local area. In
the end, the ML model grows from everyone’s data, just like the sheep feed on everyone’s grass.
Today, our modern society demands more responsible use of AI, and user privacy and
data conﬁdentiality are important properties of AI systems. In this direction, federated learning is already making signiﬁcant positive impact, ranging from securely updating user models
on mobile phones to improving medical imaging performance with multiple hospitals. Many
existing works in diﬀerent computer science areas have laid the foundation for the technology,
such as distributed optimization and learning, homomorphic encryption, diﬀerential privacy,
and secure multi-party computation.
There are two types of federated learning, horizontal and vertical. The Google GBoard system adopts horizontal federated learning and shows an example of B2C (business-to-consumer)
applications. It can also be used to support edge computing, where the devices at the edge of a
cloud system can handle many of the computing tasks and thus reduce the need to communicate via raw data with the central servers. Vertical federated learning, proposed and advanced by
WeBank, represents the B2B (business-to-business) model, where multiple organizations join
an alliance in building and using a shared ML model. The model is built while ensuring that
no local data leaves any sites and maintaining the model performance according to business
requirements. In this book, we cover both the B2C and B2B models.
To develop a federated learning system, multiple disciplines are needed, including ML algorithms, distributed machine learning (DML), cryptography and security, privacy-preserving
data mining, game theory and economic principles, incentive mechanism design, laws and regulatory requirements, etc. It is a daunting task for someone to be well-versed in so many diverse
disciplines, and the only sources for studying this ﬁeld are currently scattered across many research papers and blogs. Therefore, there is a strong need for a comprehensive introduction to
this subject in a single text, which this book oﬀers.
This book is an introduction to federated learning and can serve as one’s ﬁrst entrance
into this subject area. It is written for students in computer science, AI, and ML, as well as
for big data and AI application developers. Students at senior undergraduate or graduate levels, faculty members, and researchers at universities and research institutions can ﬁnd the book
useful. Lawmakers, policy regulators, and government service departments can also consider it
as a reference book on legal matters involving big data and AI. In classrooms, it can serve as a
textbook for a graduate seminar course or as a reference book on federated learning literature.
The idea of this book came about in our development of a federated learning platform at
WeBank known as Federated AI Technology Enabler (FATE), which became the world’s ﬁrst
open-source federated learning platform and is now part of the Linux Foundation. WeBank
is a digital bank that serves hundreds of millions of people in China. This digital bank has a
business alliance across diverse backgrounds, including banking, insurance, Internet, and retail
and supply-chain companies, just to name a few. We observe ﬁrsthand that data cannot be easily
shared, but the need to collaborate to build new businesses supported by ML is very strong.
Federated learning was practiced by Google at large-scale in its mobile services for consumers as an example of B2C applications. We took one step further in expanding it to enable
partnerships between multiple businesses in a partnership for B2B applications. The horizontal, vertical, and transfer learning-based federated learning categorization was ﬁrst summarized
in our survey paper published in ACM Transactions on Intelligent Systems and Technology (ACM
TIST) [Yang et al., 2019] and was also presented at the 2019 AAAI Conference on Artiﬁcial Intelligence (organized by the Association for the Advancement of Artiﬁcial Intelligence)
in Hawaii. Subsequently, various tutorials were given at conferences such as the 14th Chinese
Computer Federation Technology Frontier in 2019. In the process of developing this book, our
open-source federated learning system, FATE, was born and publicized [WeBank FATE, 2019]
(see and the ﬁrst international standard on federated learning via
IEEE is being developed [IEEE P3652.1, 2019]. The tutorial notes and related research papers
served as the basis for this book.
Qiang Yang, Yang Liu, Yong Cheng, Yan Kang, Tianjian Chen, and Han Yu
November 2019, Shenzhen, China
Acknowledgments
The writing of this book involved huge eﬀorts from a group of very dedicated contributors.
Besides the authors, diﬀerent chapters were contributed by Ph.D. students, researchers, and
research partners at various stages. We express our heartfelt gratitude to the following people
who have made contributions toward the writing and editing of this book.
• Dashan Gao helped with writing Chapters 2 and 3.
• Xueyang Wu helped with writing Chapters 3 and 5.
• Xinle Liang helped with writing Chapters 3 and 9.
• Yunfeng Huang helped with writing Chapters 5 and 8.
• Sheng Wan helped with writing Chapters 6 and 8.
• Xiguang Wei helped with writing Chapter 9.
• Pengwei Xing helped with writing Chapters 8 and 10.
Finally, we thank our family for their understanding and continued support. Without
them, the book would not have been possible.
Qiang Yang, Yang Liu, Yong Cheng, Yan Kang, Tianjian Chen, and Han Yu
November 2019, Shenzhen, China