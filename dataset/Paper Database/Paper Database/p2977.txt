Translating
Higher-Order
First-Order
Jia Meng ( )
National ICT, Australia
Lawrence C. Paulson ( )
Computer Laboratory, University of Cambridge, U.K.
Interactive provers typically use higher-order logic, while automatic
provers typically use ﬁrst-order logic. In order to integrate interactive provers with
automatic ones, it is necessary to translate higher-order formulae to ﬁrst-order form.
The translation should ideally be both sound and practical. We have investigated
several methods of translating function applications, types and λ-abstractions. Omitting some type information improves the success rate, but can be unsound, so the
interactive prover must verify the proofs. This paper presents experimental data
that compares the translations in respect of their success rates for three automatic
Introduction
Interactive theorem provers, such as HOL4 , Isabelle and
PVS are widely used for formal speciﬁcation and veriﬁcation. They
provide expressive formalisms and tools for managing large scale proof
projects. However, a weakness of interactive provers is their lack of
automation. In order to overcome this weakness, we have integrated
Isabelle with automatic theorem provers (ATPs) . ATPs utilize a
variety of reasoning methods and do not require hints on how or when to
use an axiom. For example, they do not expect users to orient equalities
or instantiate quantiﬁers.
Many interactive provers implement some form of higher-order logic
(HOL). Isabelle supports a variety of logics, but most users know it
only as Isabelle/HOL. In contrast, the most powerful ATPs are all
based on ﬁrst-order logic (FOL). Therefore, a successful integration
requires translating HOL problems into ﬁrst-order form.
Our criteria for these translations are pragmatic and relate to the
requirements of our integration. We do not expect to obtain automation
of full higher-order logic. We do not expect the translations to have
interesting theoretical properties, such as completeness. We merely seek
a translation that achieves a high success rate for problems containing
higher-order features. As will be seen, we even consider unsound transc⃝2007 Kluwer Academic Publishers. Printed in the Netherlands.
translations.tex; 7/09/2007; 15:18; p.1
lations, for our integration can verify the soundness of proofs when
importing them into Isabelle (Sect. 2.8).
We build upon the work of Hurd. He has integrated Metis, his own
ﬁrst-order prover, with the HOL4 interactive proof environment .
We consider alternatives to Hurd’s treatments of function applications,
types and λ-abstractions, backing up our choices with extensive experimentation. A translation should preserve type information; a sound
approach is to include types for all terms. Unfortunately, full type
information takes up much space. A more compact representation yields
better results, as we demonstrate below. Omitting some type information can lead to unsound proofs. We outline an algorithm to translate
proofs from an unsound translation into a sound one, which can be
used to test the soundness of the original proofs.
A contrasting approach is Otter-λ: Beeson has modiﬁed the
source code of the Otter theorem prover, in particular its uniﬁcation algorithm, to provide limited higher-order features. Beeson notes,
however, that Otter-λ does not implement higher-order logic:
We do not regard Otter-λ as a “combination of ﬁrst-order logic and
higher-order logic.” Lambda logic is not higher-order, it is untyped.
. . . While there probably are interesting connections to typed logics,
some of the questions about those relationships are open at present
. . . [2, p. 313]
Even with an ATP for higher-order logic , we would somehow need
to formalize Isabelle/HOL’s unusual type system (Sect. 2.2). Our translations permit the use of high-performance ATPs, unmodiﬁed. ATP
technology is developing rapidly, and we do not wish to be tied to a
single system such as Otter.
Bouillaguet et al. have developed a translation from higher-order
logic to ﬁrst-order logic. They eliminate type information and have
proved this to be sound and complete. They even use Isabelle/HOL.
Their work is impressive in its speciﬁc application of data structure
veriﬁcation. However, they do not translate λ-abstractions and their
formulas may only refer to the types of integers and Java objects.
We have implemented three HOL to FOL translations, two of which
are new. We have also developed an optimization technique, which essentially produces two additional translations. We have also addressed
the question of how to remove λ-abstractions from the HOL problems.
We have implemented both λ-lifting, which replaces λ-abstractions by
newly-deﬁned functions , and two diﬀerent combinator translations
 . We have carried out extensive experiments on all of these translations, using the provers E , SPASS and Vampire 8.1 . One
compact translation signiﬁcantly outperforms the basic, fully-typed
translations.tex; 7/09/2007; 15:18; p.2
Compared with our previous work , we test more translations,
we use a larger problem set, and we take strong measures to ensure
that only sound proofs are counted.
Paper outline. We ﬁrst describe three approaches to translating
types and discuss their soundness (Sect. 2), then describe our experimental results (Sect. 3). Next, we present three approaches to
translating λ-abstractions, along with experimental results (Sect. 4).
Finally, we oﬀer some conclusions (Sect. 5). Appendix A presents
examples of the translations.
The Three Translations
Any problem that involves function variables, Boolean variables or
λ-abstractions is clearly higher-order, but the precise criteria are surprisingly subtle. Consider that an equation such as hd(Cons X L) = X
is ﬁrst-order if X is of polymorphic type, but higher-order if its type is
Boolean. This situation seems odd: the polymorphic equation encompasses all types, including type bool. However, only in the Boolean
case can hd(Cons X L) be seen as a formula as opposed to a term. In
higher-order logic, formulas are simply terms of Boolean type.
True higher-order reasoning requires deductive mechanisms, such as
higher-order uniﬁcation, to generate suitable λ-abstractions and logical
formulas as the proof develops. We merely aim to allow reasoning about
the ﬁrst-order aspects of higher-order problems. Our methods allow use
of the equation hd(Cons X L) = X even for Boolean lists, but we do
not expect to prove hd(Cons X L) except in trivial cases. Our methods
accept problems containing functions expressed in λ-notation, and can
simplify the results of applying such functions to arguments, but we do
not expect proofs to ﬁnd interesting instantiations of function variables.
If a higher-order formula is essentially ﬁrst-order, then translating
it to ﬁrst-order logic is straightforward; otherwise, its higher-order features must be removed as described below. We use the following criteria
for a formula to be essentially ﬁrst-order:
No function has an argument involving function or Boolean types.
There are no variables of function or Boolean types.
There are no higher-type instances of overloaded constants.
An example of the last criterion is the constant 1, which Isabelle/HOL
allows to have any type. (Users can overload 1 with multiple deﬁnitions,
even at function types.) If it appears with a function type, then the
translations.tex; 7/09/2007; 15:18; p.3
problem counts as higher-order, because potentially 1 can appear both
as a constant and as a function symbol.
2.1. Features Common to All Translations
Our translations act on the output of the clause form transformation,
which takes place inside Isabelle. Thus, their input consists of clauses
that contain higher-order features. The translations are designed to
preserve the ﬁrst-order aspects of the problem while making them acceptable to a ﬁrst-order prover. Higher-order logic extends ﬁrst-order
logic in several respects: chieﬂy, that HOL terms can denote truth
values and functions.
Function values can be expressed using λ-abstractions or by currying: that is, by applying a function to fewer than the maximum number
of arguments. In FOL, a function must always be supplied the same
number of arguments. Not so in HOL, as we can see by considering the
function map, which applies a function to every element of a list. It can
appear with no arguments, with one argument, or with two arguments:
map id = id
map F [] = []
In translating from HOL to FOL, the natural treatment of currying is to
regard all HOL functions as constants while providing a two-argument
function (called @ below) to express function application.
HOL formulas are simply Boolean terms, but in ﬁrst-order logic,
formulas and terms are distinct. A HOL term such as X < g(Y) can
appear as an assertion, but it can also be a function argument, as in
f(X < g(Y)). Our translations address this distinction by providing a
predicate, called B below, to convert a Boolean term to a formula. Logically, B(x) means x=True. Ignoring types, we translate the assertion
X < g(Y) to the formula B(@(@(less,X),@(g,Y))) and the term f(X
< g(Y)) to the term @(f,@(@(less,X),@(g,Y))).
Equality requires special treatment: a HOL equality assertion must
be translated to use the ATP’s built-in equality primitive. However,
equality in HOL may appear in a Boolean-valued term, for example
f(X=0). We translate such occurrences to a new constant symbol,
fequal, yielding for our example @(f,@(@(fequal,X),0)). Reasoning steps may promote this constant to the predicate level, where it
expresses an ordinary equality. To handle such situations, we deﬁne
fequal in Isabelle/HOL using the axiom
∀X Y [fequal X Y ⇐⇒X = Y ].
Ignoring types again, this corresponds to the following two clauses:
translations.tex; 7/09/2007; 15:18; p.4
-B(@(@(fequal,X),Y)) | X = Y
B(@(@(fequal,X),X))
Following Hurd (based of course on Turner ), we remove
λ-abstractions by translating them to Curry’s combinators S, K, I,
B and C. These are easily deﬁned in higher-order logic by the usual
combinator reduction equations. This and alternative approaches are
examined in Sect. 4.
A basic axiom of HOL is function extensionality:
∀fg [(∀x f(x) = g(x)) →f = g].
It has the following clause form, where ext is a reserved Skolem function
symbol. Given f and g, it yields some x such that f(x) ̸= g(x).
@(F,@(@(ext,F),G)) != @(G,@(@(ext,F),G)) | F = G
There is no need for ext to be available as a constant.1 Converting it
to a function would abbreviate this axiom as follows:
@(F,ext(F,G)) != @(G,ext(F,G)) | F = G
Generalizing this idea, we might eliminate unnecessary uses of the
constants @ and B by preprocessing the set of clauses. We examine
this optimization in Sect. 2.7 below.
All of the examples shown above ignore types. The translations
described below diﬀer in their treatment of types. They translate terms
involving the constants fequal and ext in the same manner as they
translate other constants.
2.2. Types in Isabelle/HOL
Isabelle supports polymorphism. This expresses universal quantiﬁcation over types, though with no explicit type quantiﬁer. For example, a
polymorphic identity function might have type ’a=>’a, allowing it to
take on any type of the form T=>T by instantiating ’a. For purposes
of deduction, type variables come in two forms. Schematic type variables, written ?’a, ?’b, . . . , can be instantiated by types. Free type
variables, written ’a, ’b, . . . , are not really variables but represent
ﬁxed, unknown, types; they typically occur in conjecture clauses, and
are essentially Skolem constants for polymorphism.
An example may be illustrative. Consider proving that map id, the
function that applies the identity function to every element of a list,
equals the identity function for lists:
1 Miller notes that providing Skolem functions as constants yields the eﬀect
of the axiom of choice. Isabelle/HOL includes this axiom anyway, so we see this as
no danger.
translations.tex; 7/09/2007; 15:18; p.5
map id = id
When this equation is stated as a conjecture, the functions have the
following types:2
map: (’a=>’a) => (’a list => ’a list)
id (ﬁrst occurrence): ’a => ’a
id (second occurrence): ’a list => ’a list
Proving this equation for the arbitrary, ﬁxed type ’a establishes it for
all types. Isabelle replaces ’a by ?’a once the theorem has been proved,
to express this generality.
The Isabelle/HOL type system has further reﬁnements. An axiomatic type class denotes a set of types. For example, real (the
type of real numbers) is a member of type class linorder. A type
class is axiomatic because it may have a set of properties—speciﬁed
by axioms—that all its member types should satisfy. A type may belong to several type classes and an intersection of type classes is a
sort. Moreover, each type constructor has one or more arities, which
describe how the result type class depends upon the arguments’ type
classes. For example, the type constructor list has an arity that says
if its argument is a member of class linorder then the resulting list’s
type is also a member of linorder. This claim is justiﬁed by Isabelle
declarations that deﬁne a lexicographic ordering for lists and prove it
to satisfy the axioms of a linear order.
A constant can be overloaded by giving it a polymorphic type,
with diﬀerent deﬁnitions for various types. For example, the ≤operator has the polymorphic type ’a=>’a=>bool; when it has type
nat=>nat=>bool it denotes the usual ordering of the natural numbers,
and when it has type ’a set =>’a set => bool it denotes the subset
relation. The latter type is still polymorphic in the type of the set’s
elements. Isabelle’s overloading cannot be eliminated by preprocessing
because polymorphic theorems about ≤are applicable to all instances
of this function, despite their diﬀerent meanings.
2.3. Translating Types and Terms to First-Order Logic
Type information—at least some of it—must be preserved when translating higher-order formulae to ﬁrst-order logic. This in turn requires
that we translate Isabelle types to FOL terms. A translation should
2 Type constructors in Isabelle use a postﬁx syntax, so we write ’a list rather
than list(’a).
translations.tex; 7/09/2007; 15:18; p.6
respect overloading, ensuring that Isabelle theorems involving polymorphic functions are only used for appropriate types. Isabelle’s axiomatic
type class information can be formalized as a collection of simple facts
and implications, and easily translated to Horn clauses .
Isabelle types are translated to ﬁrst-order logic as follows:
Schematic type variables are translated to ﬁrst-order variables; for
example, ?’a is translated to T a. (An initial capital signiﬁes a
variable in most ATPs.)
Free type variables are translated to ﬁrst-order constants; for
example, ’a is translated to t a. (Lower case signiﬁes a constant.)
Compound types are formed by the application of a type constructor to arguments. The type constructor is translated to a
ﬁrst-order function, preﬁxed with tc_, and its arguments are
translated recursively. For example, the function type ?’a=>nat
is translated to tc fun(T a,tc nat). This example contains two
type constructors, fun and nat, the latter taking zero arguments.
The translation of ’a set set is tc set(tc set(t a)).
Our three translations diﬀer in how much type information they
retain. As a starting point, consider a translation that retains no
type information at all. The input is a HOL term from which all λabstractions have been removed, as discussed in Sect. 4. There are four
remaining kinds of terms:
Schematic variables express generality and are translated to ﬁrstorder variables.
Free variables are essentially Skolem constants.
Constants, even those of function type, are translated to ﬁrst-order
constants.
Function applications are translated using the @ operator, as shown
in Sect. 2.1 above.
This basic translation resembles the one for types mentioned above.
Variable and constant names are given preﬁxes to ensure correct capitalization and to distinguish entities of diﬀerent kinds that have the
same name; we omit the details.
Omitting types yields a compact result, but the resulting proofs can
be unsound: that is, meaningless in higher-order logic. In an unsound
proof, the empty clause is reached through violations of the (omitted)
type constraints rather than by refuting the conjecture, which typically
translations.tex; 7/09/2007; 15:18; p.7
plays no role in the proof. For example, in Isabelle we can declare a
two-element enumeration type, two.
datatype two = a | b
The Isabelle theory will then include the theorem
∀x::two. x=a ∨x=b
An untyped translation from Isabelle/HOL to ﬁrst-order logic will
discard the constraint to type two:
It therefore asserts that the universe consists of two elements; given a
few axioms about the natural numbers or lists, ATPs easily detect the
inconsistency.
Combinator axioms can also give rise to unsound proofs. If their
types are omitted, then they can express ﬁxedpoint operators, thus
deriving a formula φ such that φ = ¬φ. This eﬀect can occur not only
with the traditional combinators S, K and I, but with any higher-order
functions that may be present.
Unsound proofs fail during proof reconstruction, because Isabelle’s
inference system enforces type constraints. Therefore, they cannot
cause Isabelle to accept false theorems. However, they can prevent the
discovery of sound proofs. Including type information in the translation can prevent unsound proofs, but it can make problems too large,
again preventing the discovery of sound proofs. We have a tradeoﬀ
between sound and prolix translations and unsound but compact ones.
Below we discuss three possible treatments of types, the fully-typed,
partially-typed and constant-typed translations. Finally, we say more
about soundness and proof reconstruction.
2.4. The Fully-Typed Translation
The fully-typed translation, due to Hurd , is sound. A special function ti pairs each term with its type. For instance, the term X ≤Y is
translated to
ti(@(ti(@(ti(le, T_a => T_a => bool),
ti(X, T_a)),
T_a => bool),
ti(Y, T_a)),
translations.tex; 7/09/2007; 15:18; p.8
For clarity of presentation, we omit the predicate B, needed if X ≤Y
occurs as a literal. We also leave the type constructors => and bool
in their Isabelle form rather than translating them as tc fun (T a,
tc bool), etc. Although the equality predicate built into ATPs is untyped, this translation preserves the types of the two operands: the
equality literal X = Y is translated to
ti(X,T_a) = ti(Y,T_a).
In detail, the translation works as follows:
A schematic variable is translated to ti(V ,T), where V is a logical
variable and T is a translation of its type.
A free variable or constant is translated to ti(c,T), where c is a
constant and T is a translation of its type.
A function application is translated to ti(@(t,u),T), where t and
u are translations of the two subterms and T is the translation of
the resulting type.
This translation is sound because it includes types for all terms and
subterms, right down to the variables. When two terms are uniﬁed
during a resolution step, their types are uniﬁed as well. For example, unifying ti(X, T_a) with ti(0, nat) instantiates T_a to nat,
preventing the uniﬁcation of ti(Y, nat) with ti(b, two). This instantiation of types guarantees that terms created in the course of
a proof continue to carry correct types. Isabelle uniﬁes polymorphic
terms similarly. In fact, the resolution steps performed by an ATP
could in principle be reconstructed in Isabelle. Each FOL axiom clause
corresponds to an Isabelle theorem. If two FOL clauses are resolved,
then the resolvant FOL clause will correspond to the Isabelle theorem
produced by Isabelle’s own resolution rule.
As the example illustrates, the fully-typed translation introduces
much redundancy. Every part of a function application is typed: the
function’s type includes its argument and result types, which are repeated in the translation of the function’s argument and by including
the type of the returned result. These large terms are likely to yield a
poor success rate, compared with more compact translations.
The size of the type information grows quadratically. To see this,
consider how many times the type τ occurs in the application of a
translations.tex; 7/09/2007; 15:18; p.9
function f that takes n arguments:
occs. of τ
(f : τ →τ)(x : τ) : τ
(((f : τ →τ →τ)(x : τ)) : τ →τ)(x : τ) : τ
As we increase the arity of f from n to n + 1, we replace f : τ n →τ by
(f : τ n+1 →τ)(x : τ) : τ n →τ.
Therefore, the number h(n) of occurrences of τ satisﬁes the recurrence
h(0) = 1 and h(n + 1) = h(n) + n + 3. A simple induction allows us to
prove that h(n) = (n2 + 5n + 2)/2.
To achieve a compact HOL translation, we must omit some type
information, potentially admitting unsound proofs. Hurd uses an
untyped translation, relying on proof reconstruction to verify the proofs
and reject unsound ones. If reconstruction fails, Hurd calls the ATP
again, using the fully-typed translation. Combining an eﬃcient but
unsound translation with a soundness check achieves both eﬃciency
and soundness.
We cannot use an untyped translation because our requirements
diﬀer from Hurd’s. His tactic gives the ATP a list of theorems chosen
by the user. In contrast, we send ATPs hundreds of theorems, many
involving overloading. Omitting all types from this large collection
would result in many absurd proofs, where for example, the operator ≤
simultaneously denoted an integer ordering and the subset relation. We
have designed and experimented with two compact HOL translations:
the partially-typed and constant-typed translations. These attach the
most important type information (such as type instantiations of polymorphic constants) that can block some incorrect resolutions. Neither
attaches type information to variables, so neither correctly handles type
two, described in Sect. 2.2 above.
2.5. The Partially-Typed Translation
The partially-typed translation is intended to preserve enough type information to prevent most unsound proofs, while avoiding the extreme
redundancy of the fully-typed translation. It only includes the types of
functions in function calls. The type is translated to a FOL term and
is inserted as a third argument of the application operator (@). Taking
the previous formula X ≤Y as an example, we translate it to
@(@(le, X, T_a => T_a => bool), Y, T_a => bool)
translations.tex; 7/09/2007; 15:18; p.10
Here, the type of < is a=>a=>bool, and we include this type as an
additional argument of function application @.
In detail, the translation works as follows:
A schematic variable is translated to a logical variable.
A free variable or constant is translated to a constant.
A function application is translated to @(t,u,T), where t and u
are translations of the two subterms and T is the translation of
the function’s type.
This translation includes the type of every term, whether a constant
or not, that is used as a function. It still contains some redundant type
information, as the example shows.
2.6. The Constant-Typed Translation
The constant-typed translation is designed to be as compact as possible. It retains the minimum type information needed to ensure correct
overloading of constants. Each polymorphic constant carries type information. We do not include a constant’s full type but only the
instantiated values of its type variables. Monomorphic constants do not
need to carry types because their names alone determine the types of
their arguments. A polymorphic constant is translated to a ﬁrst-order
function symbol. Its arguments, which represent types, are obtained by
matching its actual type against its declared type. For example, the ≤
operator is declared to have type ’a=>’a=>bool; if it appears with the
type nat=>nat=>bool, then the type argument used in its translation
is nat. This treatment of types is similar to the one we use for problems
that are already ﬁrst-order.
Again considering our standard example, if X and Y are natural
numbers (type nat), we translate the formula X ≤Y to
@(@(le(nat), X), Y)
If X and Y are sets (type α set), we translate the formula to
@(@(le(set(T_a)), X), Y)
Equality literals use the built-in equality symbol and contain no type
information. If equality appears as a constant in a Boolean-valued term,
then we use the equality function fequal mentioned in Sect. 2.1 above.
This constant is treated like any other, and is translated to fequal(T),
where T expresses the type of its operands.
In detail, the translation works as follows:
translations.tex; 7/09/2007; 15:18; p.11
A schematic variable is translated to a logical variable.
A free variable is translated to a constant.
A constant is translated to a function applied to translated types,
as described above.
A function application is translated to @(t,u), where t and u are
translations of the two subterms.
This translation can reduce the size of terms signiﬁcantly. However,
it includes little type information and can be expected to admit many
unsound proofs.
2.7. First-Order Versions of the Translations
As remarked above, our translations do not aim to achieve higherorder reasoning, but merely to put higher-order problems into a form
acceptable to ﬁrst-order provers. For example, the function map can
appear sometimes with one argument and sometimes with two, due to
currying. We obtain a single arity for map by introducing a function
application operator, @.
The application operator naturally captures the syntax of higherorder logic, but it produces large terms. Are there more compact
alternatives? The simplest way of avoiding arity conﬂicts is to regard
function occurrences with diﬀerent arities as denoting diﬀerent functions: say, map1 and map2. However, such an approach could preclude
many proofs, given the importance of currying. A lemma about map1
could not be used in a theorem about map2.
We have therefore investigated a hybrid approach that attempts
to minimize uses of @ while not eliminating them. We examine the
set of clauses to ﬁnd the minimum arity of each function. If some
function f always appears with at least n arguments, then we use @
only for arguments in excess of this minimum. For example, if map
always appears with at least one argument, then (ignoring types) we
translate map F L as @(map(F),L).
This approach also precludes some proofs, namely those that disassemble function applications. For example, suppose we have the
following axiom:
∀F G X Y [dominates F G ∧Y < GX −→Y < FX].
This axiom expects terms of the form @(f,x) and @(g,x); it will not
be able to take part in proofs where the application operator has been
suppressed. However, note that if dominates f g appears in the problem, then both functions will have minimum arities of zero, forcing the
translations.tex; 7/09/2007; 15:18; p.12
use of @ for all of their arguments. We do not expect many natural
problems to be aﬀected by this optimization; recall that our concern is
the overall success rate rather than any notion of completeness.
This optimization is easily applied to our translations. We simply
modify them to pass the ﬁrst n arguments of function f directly to that
function, provided all occurrences of f in the problem have at least n
arguments. A related optimization is to eliminate the predicate B for
boolean-valued functions that are used exclusively as predicates and
never as arguments of functions.
For the fully-typed translation, suppose that the operator ≤always
appears with two arguments. Then, the term X ≤Y is translated to
ti(le(ti(X,T_a), ti(Y,T_a)), bool).
If it occurs as a literal, and if the operator ≤only appears in literals,
then we omit the predicate B and the constraint to type bool:
le(ti(X,T_a), ti(Y,T_a)).
This translation is still sound: as before, all terms and subterms carry
types, right down to the variables. The diﬀerence from the unoptimized
version is that there are fewer subterms.
For the partially-typed translation, omitting @ could mean omitting
all type information, so we do not consider this option.
For the constant-typed translation, if X and Y have type nat
then X ≤Y becomes simply le(X,Y,nat). This is very close to the
translation we already use for ﬁrst-order problems.
2.8. Soundness Issues
We can contemplate the use of unsound translations because all proofs
are reconstructed in Isabelle. We use Hurd’s Metis prover, which generates proof objects speciﬁcally to assist reconstruction . Metis has now
been integrated with Isabelle/HOL . Hurd envisaged users calling
Metis with a list of hand-chosen theorems, to be supplied as axiom
clauses to assist the proof. Our integration, however, allows all known
theorems to be considered as lemmas. Given a conjecture, we apply our
simple relevance ﬁlter to reduce the number of clauses from thousands to hundreds, and then call an ATP such as Vampire. From the
resulting proof, we discover which lemmas were actually used, ﬁnally
generating a Metis call referring to a few existing theorems. In other
words, we use Vampire as a powerful relevance ﬁlter, making the problem small enough for Metis to prove it. Some ﬁve percent of problems
are too diﬃcult for Metis even with this reduction . However, with
a prover such as E that outputs TSTP format , we can use Metis
translations.tex; 7/09/2007; 15:18; p.13
to reconstruct each proof line individually. Each clause is translated to
the corresponding Isabelle/HOL assertion; it is proved by a Metis call
whose arguments refer to the proof lines justifying that inference. The
idea is similar to that of the Otterﬁer proof transformation service ,
which pushes arbitrary resolution proofs through Otter.
Our implementation of proof reconstruction is an instance
of a general approach to converting TSTP proofs from an unsound
translation to a sound one. The constant-typed and partially-typed
translations contain enough information to reconstruct full types using
standard type inference techniques . Failure of type inference would
indicate that the proof was unsound. Success would not necessarily
produce a correct TSTP proof, as the reconstructed term could contain
new type variables, so a ﬁnal Otterﬁer phase might be necessary.
We approach the soundness problem pragmatically. Unsound proofs
cannot produce false theorems in Isabelle, but they can block the discovery of well-typed proofs. Therefore, rather than giving our linkup all
existing theorems, we ﬁlter out those having certain harmful features:
speciﬁcally, expressions of ﬁniteness. In particular, the Isabelle/HOL
type unit contains only one element. It exists for technical reasons,
but has few serious uses. Theorems containing variables of this type
easily lead to unsound proofs, so we forbid them. The Isabelle/HOL
type bool contains only two elements, and similarly leads to unsound
proofs. Of course, the type of truth values is hugely more important
than type unit. However, reasoning about truth values is the job of
the ATP; lemmas concerning bool would allow higher-order reasoning
in a few cases, but at excessive cost. An example may be helpful. The
following two clauses allow us to derive Boolean equality (P = Q) from
logical equivalence (P ⇐⇒Q).
B(P) | B(Q) | P=Q
~B(P) | ~B(Q) | P=Q
These clauses cause numerous unsound proofs unless we use the fullytyped translation. They might be useful for proving equations between
sets coded as characteristic functions, but they do not appear to be
relevant to many Isabelle proofs. We suppress certain other clauses
that tend to cause unsound proofs. Typical are induction rules that
are highly unlikely to yield bona ﬁde proofs by induction; note that
Beeson’s achievements concerning induction require modifying the
ATP’s uniﬁcation algorithm.
translations.tex; 7/09/2007; 15:18; p.14
Experiments
We have to choose between a sound but prolix treatment of types
and two treatments that are more compact but admit ill-typed proofs.
Applying the ﬁrst-order optimization of §2.7 gives another sound and
another unsound translation, for a total of ﬁve. Which translation allows the most sound proofs to be found? The answer can be found
empirically, based on data presented below.
3.1. Experimental Setup
For our experiments, we took 153 problems generated by Isabelle, most
of which contain higher-order features. Since our HOL translation can
also be used for purely FOL problems and our experiments were aimed
at testing the eﬃcacy of the translation methods, we translated all
problems (both HOL and FOL) using the three translation methods
described in the previous section. We eliminated λ-abstractions by
translating them to combinators. We used our relevance ﬁlter to
reduce each problem. We ran these tests on a bank of Dual AMD
Opteron processors running at 2400MHz, using Condor3 to manage
our batch jobs.
Readers may wonder, however, how a comparison between sound
and unsound translations can be fair. We have taken steps to ensure
that no unsound proofs are being counted as successful.
Rather than integrating Isabelle with our test harness, which would
be complicated, we simulate proof reconstruction using similar ideas.
When a proof is found using an unsound translation, we can identify
which axioms were actually used in the proof and generate a new
problem by selecting those axioms from the fully-typed translation.
Thus, we automatically convert each solved problem to a sound one,
while greatly reducing the number of clauses. If some ATP can prove
the converted problem, then we regard the original proof as sound.
We automated this process and applied it to all of the translations
under test. We used all of the ATPs under consideration, in order to
see whether any of them were ﬁnding unsound proofs. In each trial,
Vampire conﬁrmed at least 94 percent of the proofs. The remainder
were supplied to other ATPs, and those still failing were inspected
manually. Problems containing no conjecture clauses could immediately
be classiﬁed as unsound. (No problem set contained more than two such
cases.) A few problems looked correct but were large, so we devoted
some time to deleting needless clauses. We eventually obtained machine
3 
translations.tex; 7/09/2007; 15:18; p.15
conﬁrmation of the soundness of all the proofs that used conjecture
Therefore, in the graphs presented below, we count a proof as sound
provided it uses at least one conjecture clause. In making this choice,
we are discounting three risks as unlikely:
We have only veriﬁed the soundness of proofs found by ATPs run
with a limit of 300 seconds per problem. The graphs include proofs
found by ATPs run with many smaller time limits. Conceivably
some of these proofs are diﬀerent from the ones we veriﬁed.
Showing that the axioms used in the original proof can be used to
express a well-typed proof does not ensure that the original proof
was sound. This possibillity is not merely unlikely but harmless:
Metis, given the fully-typed translation, will ﬁnd only the sound
The ATPs themselves could be unsound.
The manual steps described in this section were done to make our
graphs as accurate as possible. They also suggest steps that a user
can take when proof reconstruction fails. Our approach to proof reconstruction is to deliver an Isabelle proof script based on the automatic
resolution proof . Users do occasionally simplify these scripts by
hand. Of course, if the work environment requires full automation,
failure of proof reconstruction simply means failure.
Unsound proofs look very diﬀerent from sound ones. They typically
bear no relation to the problem at hand, ignoring the conjecture clauses
and instead ﬁnding a contradiction from unrelated axioms. The terms
in these proofs are crazy combinations of functions of various types.
3.2. Results
Each graph compares the success rates of the ﬁve translations, for some
prover, as the runtime per problem increases from 20 to 300 seconds.
These short runtimes are appropriate for our application of ATPs to
support interactive proofs.
“Success rate” denotes the percentage of the 153 problems proved.
“Runtime” denotes the time spent in the ATPs alone. The problem
ﬁles were generated in advance using Isabelle. Translation time is
negligible; other processing within Isabelle takes a few seconds per
translations.tex; 7/09/2007; 15:18; p.16
Table I. Common to All Translations
Number of clauses
329 (40 non-Horn; 126 unit)
Number of literals
681 (171 equality)
Maximal clause size
5 (2 average)
Table II. Diﬀerences between Three Translations
Function symbols
Max. term depth
constant (FO)
39 (7 constant)
6 (2 average)
42 (7 constant)
9 (3 average)
42 (39 constant)
11 (5 average)
40 (12 constant)
13 (4 average)
43 (39 constant)
18 (8 average)
We tested three provers: E 0.99 “Singtom” (Fig. 1), SPASS 2.2 (Fig. 2)
and Vampire 8 (Fig. 3). SPASS ran with SOS enabled and splitting
disabled.4 Although SOS makes SPASS incomplete, it greatly improves
SPASS’s success rate for our problems by making the proof search
more goal-directed. Vampire ran with its CASC option, which is highly
The graphs show that the constant-typed translation does indeed
yield the highest success rate, while the fully-typed translation yields
the lowest. The ﬁrst-order optimization is beneﬁcial to both translations. The optimized, constant-typed translation is clearly best for all
three ATPs. SPASS gives the widest spread of success rates, depending
on the translation used.
To obtain a quantitative picture of the diﬀerences between the three
translations, we chose one of the problems and used tptp2X to
summarize its syntactic features. This problem is of median size in our
problem set. It has 329 clauses after relevance ﬁltering, of which 310
are non-trivial; the remaining 19 constitute a monadic Horn theory
that describes Isabelle’s type class system. Table I shows the ﬁgures
common to all three translations. Table II shows variations among the
translations. The ﬁgures shown under “Words” were obtained by the
UNIX wc utility, since a problem’s size is better measured in words
than in bytes.
4 The precise option string is -Splits=0 -FullRed=0 -SOS=1.
translations.tex; 7/09/2007; 15:18; p.17
constant (FO)
Figure 1. E, Version 0.99: percent solved against runtime
constant (FO)
Figure 2. SPASS (SOS Enabled): percent solved against runtime
constant (FO)
Figure 3. Vampire (CASC Mode): percent solved against runtime
translations.tex; 7/09/2007; 15:18; p.18
A major diﬀerence is the maximal term depth, which increases
monotonically as we move from the best-performing translation to
the worst. Shallower terms are presumably less complex. The problem
size in words also increases for the poorer-performing translations: the
largest number exceeds the smallest by a factor of 3.2. For the fullytyped translation, the ﬁrst-order optimization halves the number of
words. This optimization also reduces the number of constants in the
problem because it formalizes functions as functions rather than relying
exclusively on the apply operator.
The workshop version of this paper presents somewhat diﬀerent
results. In a few cases,5 the partially-typed translation comes top. There
are many diﬀerences between the two sets of experiments. Our problem
set is larger: 153 rather than 79. Our current problem set includes the
original 79 but adds many harder problems, especially to test reasoning
about λ-expressions. We have reﬁned the code that generates problems.
In particular, we exclude clauses that we expect could harm the success
rate, such as low-level deﬁnitions of certain primitives. We now use our
relevance ﬁlter rather than supplying substantially the same axioms
to all problems.
When choosing a translation, we should also take account of soundness. As mentioned in §3.1 above, we tested all proofs for type
correctness by using them to generate reduced, fully-typed versions.
Nearly all proofs turned out to be sound, and all the bad ones had
the tell-tale sign of using no conjecture clauses. Unsound proofs are
not shown in the graphs. As expected, the fully-typed translation produced no unsound proofs. With the partially-typed translation, one
proof was unsound. With the constant-typed translation, two proofs
were unsound, but with the ﬁrst-order optimization, no proofs were
unsound. The additional freedom oﬀered by the apply operator seems
to lend itself mainly to unsound proofs. The optimized, constant-typed
translation is obviously the best. If soundness is essential, then we
suggest the optimized fully-typed one.
Translating λ-Abstractions: An Empirical Comparison
ﬁrst-order
λabstractions. The literature on functional programming discusses a
variety of diﬀerent methods for translating λ-abstractions. A well
known approach is to use the ﬁve combinators S, K, I, B and C.
The ﬁrst two combinators suﬃce in theory, but they yield an output
5 For Vampire 8.0, with a time limit below 300 seconds
translations.tex; 7/09/2007; 15:18; p.19
that is exponential in the number of nested λ-abstractions. Even with
all ﬁve combinators, the size of the output is quadratic . They are
ineﬃcient: during a β-reduction, namely the evaluation of a function
application, numerous occurrences of combinators must be expanded
in the function body.
In an attempt to improve the success rate, we decided to experiment
with two alternatives to the venerable Curry combinators: Turner’s
extended combinator set and λ-lifting. We were surprised to discover that they yielded no convincing improvement. We feel that these
experiments are of interest despite this outcome. Future research may
improve upon these translations.
4.1. The Five Curry Combinators
S and K alone can express all λ-abstractions. The identity combinator,
I, can be deﬁned by SKK. As Turner relates , Curry improved upon
this system by introducing two new combinators, B and C, to handle
special cases of S. The full set can be deﬁned as follows.
S x y z = x z(y z)
B x y z = x(y z)
C x y z = x z y
Note that B x y yields the function composition of x and y.
A λ-expression can be translated to combinators by the following
rewrite rules.
λx. x 7−→I
λx. p 7−→K p
(x not free in p)
λx. p x 7−→p
(x not free in p)
λx. p q 7−→B p (λx. q)
(x not free in p)
λx. p q 7−→C (λx. p) q
(x not free in q)
λx. p q 7−→S(λx. p)(λx. q)
(x free in p and q)
Unfortunately, this translation is quadratic in the nesting depth of λabstractions. For example, consider the translation of the expression
λxyz. pq, where p and q may be arbitrary terms. As each abstraction
translations.tex; 7/09/2007; 15:18; p.20
is translated, the preﬁx grows dramatically.
λxyz. pq 7−→λxy. S(λz. p)(λz. q)
7−→λx. S(B S(λyz. p))(λyz. q)
7−→S(B S(B(B S)(λxyz. p)))(λxyz. q)
Three nested λ-abstractions arise quite easily in our examples, so it is
natural to seek improvements.
4.2. The Turner Combinators
Turner introduced three new combinators, S′, B′ and C′, in order
to address the quadratic behaviour shown above. Peyton Jones 
claims that Turner’s system can be further improved if B′ is replaced
by B∗, yielding the following deﬁnitions of the new combinators.6
S′ w x y z = w(x z)(y z)
B∗w x y z = w(x(y z))
C′ w x y z = w(x z) y
This system is used by ﬁrst translating to the Curry combinators, then
simplifying the result by applying the following optimizations:
B p (B q r) = B∗p q r
C(B p q)r = C′ p q r
S(B p q)r = S′ p q r
The optimized result is more compact and allows shorter derivations.
This might be expected to yield a higher success rate.
4.3. Defining New Functions: λ-lifting
The idea of λ-lifting is that the functions actually present in the expression being translated should serve as the combinators . These
are sometimes called super-combinators. No built-in combinators are
required. Instead, λ-abstractions are translated from the inside out.
Each abstraction is replaced by a call to a newly deﬁned function. This
function obviously has as arguments those of the λ-abstraction, with
additional arguments for all variables free in that abstraction. With
λ-lifting, we can expect a compact output. (See Appendix A.5 for an
example.) Moreover, β-reduction should take only one rewriting step
rather than many.
During our experiments, it became clear that λ-lifting delivers poor
results unless several points are noted:
6 Turner’s B′ satisﬁes B′ w x y z = wx(y z).
translations.tex; 7/09/2007; 15:18; p.21
Every occurrence of λx.fx, where x is not free in f, should be
replaced by f.
An equation between a constant and a λ-expression should be
translated directly to another equation. For example, the formula
h = λx. f(x, g(x)) should be translated to h(x) = f(x, g(x)).
Multiple abstractions can be translated as a unit. Although the
general treatment of nested abstractions will yield a correct result,
it will needlessly introduce a series a function deﬁnitions.
Existing function deﬁnitions must be re-used as often as possible.
In some of these points, we deviate from Hughes . He did not combine
multiple abstractions. For the additional arguments, he used not the
free variables but the maximal free subexpressions. His prime motivation was to obtain fully lazy evaluation, which is of no concern to us.
However, in future work we may experiment with his approach. Our
current λ-lifting algorithm is straightforward.
Traverse the formula recursively.
If the abstraction λx1 . . . xn. t is encountered, where t does not
begin with a λ, then recursively perform λ-lifting on t, yielding
the the λ-free term t′. Let y1, . . . , ym be variables that are free in
λx1 . . . xn. t′.
Choose a new function symbol f, deﬁne it by fy1 . . . ym x1 . . . xn =
t′, and return fy1 . . . ym as the translation. However, if an instance
of an existing function symbol can express λx1 . . . xn. t′, use that
instead of deﬁning a new function.
Re-use of existing functions is essential because equal abstractions
should have identical translations. Combinators automatically have this
valuable property: because they are syntax directed, they are guaranteed to give the same output for the same input. Even with diﬀerent
inputs, the combinator translations sometimes have a similar form, as
in KX and K(SK). With λ-lifting, the outputs will always be diﬀerent
unless functions are re-used. Such diﬀerences can only be overcome in
a proof by an explicit application of extensionality:
∀fg [(∀x f(x) = g(x)) →f = g].
translations.tex; 7/09/2007; 15:18; p.22
This theorem states that functions f and g are equal provided they
deliver the same results for equal arguments. Proofs take much longer,
and often fail, if they are forced to perform such a step.7
4.4. Experimental Results for the λ-Translations
The ﬁrst question to settle is whether our three (or ﬁve) translations
obey the same ranking with λ-lifting as they do with combinators. As
Figs. 4 and 5 indicate, they largely do. It is surprising, however, that the
two constant-typed translations are approximately equal for Vampire
To compare λ-lifting with combinators, we ﬁrst consider the optimized constant-typed translation. Fig. 7 plots six graphs, showing the
results for E, SPASS and Vampire with both treatments of abstractions.
This graph shows some interesting eﬀects. For E, λ-lifting delivers a
clear beneﬁt. For SPASS, λ-lifting delivers worse results, to a similar
degree. For Vampire, λ-lifting is slightly inferior. This graph also shows
that E delivers poor results with all of our higher-order translations;
this is puzzling, since with our ﬁrst-order translations it is generally
superior to SPASS .
The comparison of λ-lifting with combinators is complicated by its
interaction with our relevance ﬁlter. Relevance ﬁltering behaves diﬀerently with λ-lifting because the abstraction functions are declared as
“real” functions early in the translation to clauses. With our current
problem set, we have found that relevance ﬁltering makes several easy
problems impossible by omitting essential axioms, so this could be
biasing the results.
To eliminate this bias, we have also run tests with relevance ﬁltering
switched oﬀ. An unﬁltered problem typically contains 8500 clauses.
With such large axiom sets, the constant-typed translation admits far
too many unsound proofs. In a typical test, all 153 problems were
“proved”, but only 53 (or 35 percent) of these proofs used any conjecture clauses. We therefore use the optimized, fully-typed translation
for this test (Fig. 8). Now λ-lifting delivers a small beneﬁt for both E
and SPASS, but a deﬁcit for Vampire. The dismal success rates demonstrate the contributions of our work on both relevance ﬁltering and
higher-order translations.
Thus, λ-lifting is beneﬁcial with two automatic provers, but is harmful with a third. This ﬁnding is surprising, given that the combinator
translation is quadratic. Of course, theorem proving is very diﬀerent
7 Joe Hurd tells us that the very presence of the extensionality axiom in a problem
greatly harms the success rate. We ran experiments with E, SPASS and Vampire,
but found that the presence of this axiom had no eﬀect on the success rate.
translations.tex; 7/09/2007; 15:18; p.23
constant (FO)
Figure 4. E, Version 0.99: percent solved against runtime
constant (FO)
Figure 5. SPASS (SOS Enabled): percent solved against runtime
constant (FO)
Figure 6. Vampire (CASC Mode): percent solved against runtime
translations.tex; 7/09/2007; 15:18; p.24
combinators, vampire
lambda-lifting, vampire
combinators, spass
lambda-lifting, spass
combinators, E
lambda-lifting, E
Figure 7. λ-lifting versus combinators (relevance ﬁltering)
combinators, vampire
lambda-lifting, vampire
combinators, spass
lambda-lifting, spass
combinators, E
lambda-lifting, E
Figure 8. λ-lifting versus combinators (no relevance ﬁltering)
from functional programming, which is concerned entirely with the
reduction of huge λ-expresssions. Few of our problems have even three
nested λ-abstractions, and many of them remain unsolved with both
approaches. Note that λ-lifting generates many equations, compared
with the ﬁve equations deﬁning the combinators: perhaps this degrades
Vampire’s performance.
We were very surprised to ﬁnd that Turner’s combinators yielded
no improvement over Curry’s. They performed worse by a tiny margin.
Upon closer investigation, we discovered that Turner’s optimizations
were not yielding dramatic reductions in the size of the output. Despite
Turner’s claim [24, p. 269] that “the sizes of the successive terms now
[form] only a linear progression,” the translation as a whole is still
quadratic . We observed reductions of approximately 30%, in the
number of combinators produced. Set against this modest reduction is
the larger number of combinator equations that must be used in proofs.
translations.tex; 7/09/2007; 15:18; p.25
Conclusions
We have described three HOL to FOL translations, which diﬀer in
their treatment of types. Two of these admit a “ﬁrst-order” optimization, which uses real function application whenever possible, so the
number of translations is eﬀectively ﬁve. We have carried out extensive experiments to evaluate the eﬀectiveness of these translations.
We have also obtained some statistics concerning how compact our
translations are. Of the three translations—fully-typed, partially-typed
and constant-typed—the constant-typed translation produces the most
compact output. Our optimization, which applies to the fully-typed and
constant-typed translations, reduces the term depth and the problem
size. Naturally, we would expect a prover’s success rate to increase with
a more compact clause form. That is what we observed, with all three
provers tested. The diﬀerence between best and worst was up to 20
percentage points.
Because only the fully-typed translations are sound, proofs found
using the other translations must be validated in some way, such as
by proof reconstruction. The proportion of unsound proofs depends
on which and how many axioms are present. In our experiments, it
ranged from zero (for our standard conﬁguration) to 65 percent (for
huge problems containing thousands of irrelevant axioms). Therefore,
the choice of translation must be made with care.
We have implemented methods for using the sound and unsound
translations in concert. A proof found using an unsound translation
can be used to generate a version of the same problem using a sound
translation, but containing only the axioms necessary for the proof.
Thus the unsound translation is used as a means of relevance ﬁltering,
which improves the success rate of the sound but prolix translation.
This method simulates, using resolution alone, the approach to proof
reconstruction implemented in Isabelle.
We also compared three approaches to eliminating λ-abstractions:
the ﬁve Curry combinators, the eight Turner combinators (modiﬁed),
and λ-lifting. We obtained evidence in favour of λ-lifting, but it was
inconclusive and we expect further gains to be made here.
The higher-order logic we have investigated is Isabelle/HOL. However, our translations should be equally applicable to the similar logic
implemented in the HOL4 system. Any translations for PVS would
have to take account of predicate subtyping, but their treatment of
basic types might be based on our techniques.
The test data used in our experiments is available at 
cl.cam.ac.uk/∼lp15/Data/ho-translations/.
translations.tex; 7/09/2007; 15:18; p.26
Acknowledgements
The research was funded by the epsrc grant GR/S57198/01 Automation for Interactive Proof and by the L4.veriﬁed project of National
ICT Australia. Joe Hurd has given much helpful advice on how to
translate from HOL to FOL. Christoph Benzm¨uller and various referees
made many useful suggestions for improving this paper.