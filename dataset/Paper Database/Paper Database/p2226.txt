Semi-supervised Domain Adaptation via Minimax Entropy
Kuniaki Saito1, Donghyun Kim1, Stan Sclaroff1, Trevor Darrell2 and Kate Saenko1
1Boston University, 2University of California, Berkeley
1{keisaito, donhk, sclaroff, saenko}@bu.edu,
 
Contemporary domain adaptation methods are very effective at aligning feature distributions of source and target domains without any target supervision.
we show that these techniques perform poorly when even
a few labeled examples are available in the target domain.
To address this semi-supervised domain adaptation (SSDA) setting, we propose a novel Minimax Entropy
(MME) approach that adversarially optimizes an adaptive
few-shot model.
Our base model consists of a feature
encoding network, followed by a classiﬁcation layer that
computes the features’ similarity to estimated prototypes
(representatives of each class).
Adaptation is achieved
by alternately maximizing the conditional entropy of unlabeled target data with respect to the classiﬁer and minimizing it with respect to the feature encoder.
We empirically demonstrate the superiority of our method over
many baselines, including conventional feature alignment
and few-shot methods, setting a new state of the art for
SSDA. Our code is available at 
bu.edu/keisaito/research/MME.html.
1. Introduction
Deep convolutional neural networks have signiﬁcantly improved image classiﬁcation accuracy with the help
of large quantities of labeled training data, but often generalize poorly to new domains. Recent unsupervised domain
adaptation (UDA) methods improve
generalization on unlabeled target data by aligning distributions, but can fail to learn discriminative class boundaries
on target domains (see Fig. 1.) We show that in the Semi-
Supervised Domain Adaptation (SSDA) setting where a few
target labels are available, such methods often do not improve performance relative to just training on labeled source
and target examples, and can even make it worse.
We propose a novel approach for SSDA that overcomes
the limitations of previous methods and signiﬁcantly improves the accuracy of deep classiﬁers on novel domains
with only a few labels per class. Our approach, which we
Labeled Source
Conventional Domain Classifier Based Method
Minimax Entropy (Ours)
Train Domain Classifier
Update features
Update prototype
Domain Classifier
Minimize entropy
on unlabeled target
Domain Classifier
Labeled Target
Unlabeled Target
Estimated Prototypes
Task-specific
Classifier
Estimate prototype
with labeled examples
Maximize entropy
on unlabeled target
Update features
Figure 1: We address the task of semi-supervised domain adaptation. Top: Existing domain-classiﬁer based methods align source
and target distributions but can fail by generating ambiguous features near the task decision boundary. Bottom: Our method estimates a representative point of each class (prototype) and extracts
discriminative features using a novel minimax entropy technique.
call Minimax Entropy (MME), is based on optimizing a
minimax loss on the conditional entropy of unlabeled data,
as well as the task loss; this reduces the distribution gap
while learning discriminative features for the task.
We exploit a cosine similarity-based classiﬁer architecture recently proposed for few-shot learning . The
classiﬁer (top layer) predicts a K-way class probability vector by computing cosine similarity between K class-speciﬁc
weight vectors and the output of a feature extractor (lower
layers), followed by a softmax. Each class weight vector is
an estimated “prototype” that can be regarded as a representative point of that class. While this approach outperformed
more advanced methods in few-shot learning and we con-
ﬁrmed its effectiveness in our setting, as we show below it
is still quite limited. In particular, it does not leverage unlabeled data in the target domain.
Our key idea is to minimize the distance between the
class prototypes and neighboring unlabeled target samples,
thereby extracting discriminative features. The problem is
how to estimate domain-invariant prototypes without many
 
Step1: Update Estimated Prototypes
Step2: Update Feature Extractor
Estimated Prototypes
Labeled Source
Labeled Target
Unlabeled Target
Entire Network Optimization without unlabeled examples
Baseline Few-shot Learning Method
Proposed Method
Entropy Maximization
Entropy Minimization
Classification loss
minimization
Figure 2: Top: baseline few-shot learning method, which estimates class prototypes by weight vectors, yet does not consider
unlabeled data. Bottom: our model extracts discriminative and domain-invariant features using unlabeled data through a
domain-invariant prototype estimation. Step 1: we update the estimated prototypes in the classiﬁer to maximize the entropy
on the unlabeled target domain. Step 2: we minimize the entropy with respect to the feature extractor to cluster features
around the estimated prototype.
labeled target examples. The prototypes are dominated by
the source domain, as shown in the leftmost side of Fig. 2
(bottom), as the vast majority of labeled examples come
from the source. To estimate domain-invariant prototypes,
we move weight vectors toward the target feature distribution. Entropy on target examples represents the similarity
between the estimated prototypes and target features. A uniform output distribution with high entropy indicates that the
examples are similar to all prototype weight vectors. Therefore, we move the weight vectors towards target by maximizing the entropy of unlabeled target examples in the ﬁrst
adversarial step. Second, we update the feature extractor to
minimize the entropy of the unlabeled examples, to make
them better clustered around the prototypes. This process
is formulated as a mini-max game between the weight vectors and the feature extractor and applied over the unlabeled
target examples.
Our method offers a new state-of-the-art in performance
on SSDA; as reported below, we reduce the error relative to
baseline few-shot methods which ignore unlabeled data by
8.5%, relative to current best-performing alignment methods by 8.8%, and relative to a simple model jointly trained
on source and target by 11.3% in one adaptation scenario.
Our contributions are summarized as follows:
• We highlight the limitations of state-of-the-art domain
adaptation methods in the SSDA setting;
• We propose a novel adversarial method, Minimax Entropy (MME), designed for the SSDA task;
• We show our method’s superiority to existing methods
on benchmark datasets for domain adaptation.
2. Related Work
Domain Adaptation. Semi-supervised domain adaptation (SSDA) is a very important task , however it
has not been fully explored, especially with regard to deep
learning based methods. We revisit this task and compare
our approach to recent semi-supervised learning or unsupervised domain adaptation methods. The main challenge
in domain adaptation (DA) is the gap in feature distributions between domains, which degrades the source classi-
ﬁer’s performance. Most recent work has focused on unsupervised domain adaptation (UDA) and, in particular, feature distribution alignment. The basic approach measures
the distance between feature distributions in source and target, then trains a model to minimize this distance. Many
UDA methods utilize a domain classiﬁer to measure the distance . The domain-classiﬁer is trained
to discriminate whether input features come from the source
or target, whereas the feature extractor is trained to deceive
the domain classiﬁer to match feature distributions. UDA
has been applied to various applications such as image classiﬁcation , semantic segmentation , and object detection . Some methods minimize task-speciﬁc decision boundaries’ disagreement on target examples 
to push target features far from decision boundaries. In this
respect, they increase between-class variance of target features; on the other hand, we propose to make target features
well-clustered around estimated prototypes. Our MME approach can reduce within-class variance as well as increasing between-class variance, which results in more discriminative features. Interestingly, we empirically observe that
UDA methods often fail in improving accuracy
Semi-supervised learning (SSL). Generative ,
Labeled Example
Backward path for unlabeled target examples
Backward path for labeled source and target examples
Labeled Source
Labeled Target
Unlabeled Target
W = Weight Matrix
= Temperature
Lce (p, y)
= Feature Extractor
Lce(p, y) = Cross Entropy Loss
= Classifier
Figure 3: An overview of the model architecture and MME. The inputs to the network are labeled source examples (y=label),
a few labeled target examples, and unlabeled target examples. Our model consists of the feature extractor F and the classiﬁer
C which has weight vectors (W) and temperature T. W is trained to maximize entropy on unlabeled target (Step 1 in Fig.
2) whereas F is trained to minimize it (Step 2 in Fig. 2). To achieve the adversarial learning, the sign of gradients for entropy
loss on unlabeled target examples is ﬂipped by a gradient reversal layer .
model-ensemble , and adversarial approaches have
boosted performance in semi-supervised learning, but do
not address domain shift. Conditional entropy minimization
(CEM) is a widely used method in SSL . However,
we found that CEM fails to improve performance when
there is a large domain gap between the source and target
domains (see experimental section.) MME can be regarded
as a variant of entropy minimization which overcomes the
limitation of CEM in domain adaptation.
Few-shot learning (FSL). Few shot learning aims to learn novel classes given a few labeled examples
and labeled “base” classes. SSDA and FSL make different assumptions: FSL does not use unlabeled examples and
aims to acquire knowledge of novel classes, while SSDA
aims to adapt to the same classes in a new domain. However both tasks aim to extract discriminative features given a
few labeled examples from a novel domain or novel classes.
We employ a network with ℓ2 normalization on features before the last linear layer and a temperature parameter T,
which was proposed for face veriﬁcation and applied
to few-shot learning . Generally, classiﬁcation of a
feature vector with a large norm results in conﬁdent output. To make the output more conﬁdent, networks can try
to increase the norm of features. However, this does not
necessarily increase the between-class variance because increasing the norm does not change the direction of vectors.
ℓ2 normalized feature vectors can solve this issue. To make
the output more conﬁdent, the network focuses on making
the direction of the features from the same class closer to
each other and separating different classes. This simple architecture was shown to be very effective for few-shot learning and we build our method on it in our work.
3. Minimax Entropy Domain Adaptation
In semi-supervised domain adaptation, we are given
source images and the corresponding labels in the source
domain Ds = {(xs
i, yis)}ms
i=1. In the target domain, we
are also given a limited number of labeled target images
i, yit)}mt
i=1, as well as unlabeled target images
Our goal is to train the model on
Ds, Dt, and Du and evaluate on Du.
3.1. Similarity based Network Architecture
Inspired by , our base model consists of a feature extractor F and a classiﬁer C. For the feature extractor F,
we employ a deep convolutional neural network and perform ℓ2 normalization on the output of the network. Then,
the normalized feature vector is used as an input to C
which consists of weight vectors W = [w1, w2, . . . , wK]
where K represents the number of classes and a temperature parameter T. C takes
∥F (x)∥as an input and outputs
∥F (x)∥. The output of C is fed into a softmaxlayer to obtain the probabilistic output p ∈Rn. We denote
p(x) = σ( 1
∥F (x)∥), where σ indicates a softmax function. In order to classify examples correctly, the direction
of a weight vector has to be representative to the normalized features of the corresponding class. In this respect, the
weight vectors can be regarded as estimated prototypes for
each class. An architecture of our method is shown in Fig. 3.
3.2. Training Objectives
We estimate domain-invariant prototypes by performing
entropy maximization with respect to the estimated prototype. Then, we extract discriminative features by performing entropy minimization with respect to feature extractor.
Entropy maximization prevents overﬁtting that can reduce
the expressive power of the representations. Therefore, entropy maximization can be considered as the step of selecting prototypes that will not cause overﬁtting to the source
examples. In our method, the prototypes are parameterized
by the weight vectors of the last linear layer. First, we train
F and C to classify labeled source and target examples correctly and utilize an entropy minimization objective to extract discriminative features for the target domain. We use
a standard cross-entropy loss to train F and C for classiﬁcation:
L = E(x,y)∈Ds,DtLce (p(x), y) .
With this classiﬁcation loss, we ensure that the feature extractor generates discriminative features with respect to the
source and a few target labeled examples. However, the
model is trained on the source domain and a small fraction
of target examples for classiﬁcation. This does not learn
discriminative features for the entire target domain. Therefore, we propose minimax entropy training using unlabeled
target examples.
A conceptual overview of our proposed adversarial
learning is illustrated in Fig. 2. We assume that there exists
a single domain-invariant prototype for each class, which
can be a representative point for both domains. The estimated prototype will be near source distributions because
source labels are dominant. Then, we propose to estimate
the position of the prototype by moving each wi toward target features using unlabeled data in the target domain. To
achieve this, we increase the entropy measured by the similarity between W and unlabeled target features. Entropy is
calculated as follows,
H = −E(x,y)∈Du
p(y = i|x) log p(y = i|x)
where K is the number of classes and p(y = i|x) represents
the probability of prediction to class i, namely i th dimension of p(x) = σ( 1
∥F (x)∥). To have higher entropy, that
is, to have uniform output probability, each wi should be
similar to all target features. Thus, increasing the entropy
encourages the model to estimate the domain-invariant prototypes as shown in Fig. 2.
To obtain discriminative features on unlabeled target examples, we need to cluster unlabeled target features around
the estimated prototypes. We propose to decrease the entropy on unlabeled target examples by the feature extractor
F. The features should be assigned to one of the prototypes
to decrease the entropy, resulting in the desired discriminative features. Repeating this prototype estimation (entropy
maximization) and entropy minimization process yields discriminative features.
To summarize, our method can be formulated as adversarial learning between C and F. The task classiﬁer C is
trained to maximize the entropy, whereas the feature extractor F is trained to minimize it. Both C and F are also
trained to classify labeled examples correctly. The overall
adversarial learning objective functions are:
ˆθF = argmin
ˆθC = argmin
where λ is a hyper-parameter to control a trade-off between
minimax entropy training and classiﬁcation on labeled examples. Our method can be formulated as the iterative minimax training. To simplify training process, we use a gradient reversal layer to ﬂip the gradient between C and
F with respect to H. With this layer, we can perform the
minimax training with one forward and back-propagation,
which is illustrated in Fig. 3.
3.3. Theoretical Insights
As shown in , we can measure domain-divergence by
using a domain classiﬁer. Let h ∈H be a hypothesis, ϵs(h)
and ϵt(h) be the expected risk of source and target respectively, then ϵt(h) ⩽ϵs(h) + dH(p, q) + C0 where C0 is a
constant for the complexity of hypothesis space and the risk
of an ideal hypothesis for both domains and dH(p, q) is the
H-divergence between p and q.
dH(p, q) ≜2 sup
xs∼p [h(f s) = 1] −Pr
h(f t) = 1
where f s and f t denote the features in the source and target
domain respectively. In our case the features are outputs of
the feature extractor. The H-divergence relies on the capacity of the hypothesis space H to distinguish distributions p
and q. This theory states that the divergence between domains can be measured by training a domain classiﬁer and
features with low divergence are the key to having a wellperforming task-speciﬁc classiﬁer. Inspired by this, many
methods train a domain classiﬁer to discriminate different domains while also optimizing the feature
extractor to minimize the divergence.
Our proposed method is also connected to Eq. 4. Although we do not have a domain classiﬁer or a domain classiﬁcation loss, our method can be considered as minimizing
domain-divergence through minimax training on unlabeled
target examples. We choose h to be a classiﬁer that decides
a binary domain label of a feature by the value of the entropy, namely,
if H(C(f)) ≥γ,
where C denotes our classiﬁer, H denotes entropy, and
γ is a threshold to determine a domain label.
we assume C outputs the probability of the class prediction for simplicity. Eq. 4 can be rewritten as follows,
dH(p, q) ≜2 sup
f s∼p [h(f s) = 1] −Pr
h(f t) = 1
f s∼p [H(C(f s)) ≥γ] −Pr
f t∼q [H(C(f t)) ≥γ]
H(C(f t)) ≥γ
In the last inequality, we assume that Pr
fs∼p [H(C(f s)) ≥γ] ≤
H(C(f t)) ≥γ
. This assumption should be realistic
because we have access to many labeled source examples
and train entire networks to minimize the classiﬁcation
loss. Minimizing the cross-entropy loss (Eq. 1) on source
examples ensures that the entropy on a source example
is very small.
Intuitively, this inequality states that the
divergence can be bounded by the ratio of target examples
having entropy greater than γ.
Therefore, we can have
the upper bound by ﬁnding the C that achieves maximum
entropy for all target features.
Our objective is ﬁnding
features that achieve lowest divergence. We suppose there
exists a C that achieves the maximum in the inequality
above, then the objective can be rewritten as,
H(C(f t)) ≥γ
Finding the minimum with respect to f t is equivalent to ﬁnd
a feature extractor F that achieves that minimum. Thus,
we derive the minimax objective of our proposed learning
method in Eq . 3. To sum up, our maximum entropy process can be regarded as measuring the divergence between
domains, whereas our entropy minimization process can be
regarded as minimizing the divergence. In our experimental section, we observe that our method actually reduces
domain-divergence (Fig. 6c). In addition, target features
produced by our method look aligned with source features
and are just as discriminative. These come from the effect
of the domain-divergence minimization.
4. Experiments
4.1. Setup
We randomly selected one or three labeled examples per
class as the labeled training target examples (one-shot and
three-shot setting, respectively.) We selected three other labeled examples as the validation set for the target domain.
The validation examples are used for early stopping, choosing the hyper-parameter λ, and training scheduling. The
other target examples are used for training without labels,
their labels are only used to evaluate classiﬁcation accuracy
(%). All examples of the source are used for training.
Datasets. Most of our experiments are done on a subset
of DomainNet , a recent benchmark dataset for largescale domain adaptation that has many classes (345) and six
domains. As labels of some domains and classes are very
noisy, we pick 4 domains (Real, Clipart, Painting, Sketch)
and 126 classes.
We focus on the adaptation scenarios
where the target domain is not real images, and construct
7 scenarios from the four domains. See our supplemental
material for more details. Ofﬁce-Home contains 4 domains (Real, Clipart, Art, Product) with 65 classes. This
dataset is one of the benchmark datasets for unsupervised
domain adaptation. We evaluated our method on 12 scenarios in total. Ofﬁce contains 3 domains (Amazon,
Webcam, DSLR) with 31 classes. Webcam and DSLR are
small domains and some classes do not have a lot of examples while Amazon has many examples. To evaluate on the
domain with enough examples, we have 2 scenarios where
we set Amazon as the target domain and DSLR and Webcam as the source domain.
Implementation Details. All experiments are implemented
in Pytorch . We employ AlexNet and VGG16 
pre-trained on ImageNet. To investigate the effect of deeper
architectures, we use ResNet34 in experiments on DomainNet. We remove the last linear layer of these networks
to build F, and add a K-way linear classiﬁcation layer C
with a randomly initialized weight matrix W. The value of
temperature T is set 0.05 following the results of in
all settings. Every iteration, we prepared two mini-batches,
one consisting of labeled examples and the other of unlabeled target examples. Half of the labeled examples comes
from source and half from labeled target. Using the two
mini-batches, we calculated the objective in Eq. 3. To implement the adversarial learning in Eq. 3, we use a gradient
reversal layer to ﬂip the gradient with respect to
entropy loss. The sign of the gradient is ﬂipped between C
and F during backpropagation. We adopt SGD with momentum of 0.9. In all experiments, we set the trade-off parameter λ in Eq. 3 as 0.1. This is decided by the validation
performance on Real to Clipart experiments. We show the
performance sensitivity to this parameter in our supplemental material, as well as more details including learning rate
scheduling.
Baselines. S+T is a model trained with the labeled
source and labeled target examples without using unlabeled
target examples. DANN employs a domain classiﬁer
to match feature distributions. This is one of the most popular methods in UDA. For fair comparison, we modify this
method so that it is trained with the labeled source, labeled
target, and unlabeled target examples. ADR utilizes a
task-speciﬁc decision boundary to align features and ensure
that they are discriminative on the target. CDAN is
one of the state-of-the art methods on UDA and performs
domain alignment on features that are conditioned on the
output of classiﬁers. In addition, it utilizes entropy minimization on target examples. CDAN integrates domainclassiﬁer based alignment and entropy minimization. Comparison with these UDA methods (DANN, ADR, CDAN)
Table 1: Accuracy on the DomainNet dataset (%) for one-shot and three-shot settings on 4 domains, R: Real, C: Clipart, P:
Clipart, S: Sketch. Our MME method outperformed other baselines for all adaptation scenarios and for all three networks,
except for only one case where it performs similarly to ENT.
Ofﬁce-Home
Table 2: Results on Ofﬁce-Home and Ofﬁce dataset (%).
The value is the accuracy averaged over all adaptation scenarios. Performance on each setting is summarized in supplementary material.
reveals how much gain will be obtained compared to the
existing domain alignment-based methods. ENT is a
model trained with labeled source and target and unlabeled
target using standard entropy minimization. Entropy is calculated on unlabeled target examples and the entire network
is trained to minimize it. The difference from MME is that
ENT does not have a maximization process, thus comparison with this baseline clariﬁes its importance.
Note that all methods except for CDAN are trained with
exactly the same architecture used in our method. In case
of CDAN, we could not ﬁnd any advantage of using our
architecture. The details of baseline implementations are in
our supplemental material.
4.2. Results
Overview. The main results on the DomainNet dataset are
shown in Table 1. First, our method outperformed other
baselines for all adaptation scenarios and all three networks
except for one case. On average, our method outperformed
S+T with 9.5% and 8.9% in ResNet one-shot and three-shot
setting respectively. The results on Ofﬁce-Home and Ofﬁce
are summarized in Table 2, where MME also outperforms
all baselines. Due to the limited space, we show the results
averaged on all adaptation scenarios.
Comparison with UDA Methods.
Generally, baseline
UDA methods need strong base networks such as VGG
or ResNet to perform better than S+T. Interestingly, these
methods cannot improve the performance in some cases.
The superiority of MME over existing UDA methods is supported by Tables 1 and 2. Since CDAN uses entropy minimization and ENT signiﬁcantly hurts the performance for
AlexNet and VGG, CDAN does not consistently improve
the performance for AlexNet and VGG.
Comparison with Entropy Minimization. ENT does not
improve performance in some cases because it does not account for the domain gap. Comparing results on one-shot
and three-shot, entropy minimization gains performance
Table 3: Results on the DomainNet dataset in the unsupervised domain adaptation setting (%).
(a) AlexNet
Figure 4: Accuracy vs the number of labeled target examples. The ENT method needs more labeled examples to obtain similar performance to our method.
S+T (Standard Linear)
S+T (Few-shot )
MME (Standard Linear)
MME (Few-shot )
Table 4: Comparison of classiﬁer architectures on the DomainNet dataset using AlexNet, showing the effectiveness
of the architecture proposed in .
with the help of labeled examples. As we have more labeled
target examples, the estimation of prototypes will be more
accurate without any adaptation. In case of ResNet, entropy
minimization often improves accuracy. There are two potential reasons. First, ResNet pre-trained on ImageNet has
a more discriminative representation than other networks.
Therefore, given a few labeled target examples, the model
can extract more discriminative features, which contributes
to the performance gain in entropy minimization. Second,
ResNet has batch-normalization (BN) layers . It is reported that BN has the effect of aligning feature distributions . Hence, entropy minimization was done on
aligned feature representations, which improved the performance. When there is a large domain gap such as C to S,
S to P, and R to S in Table 1, BN is not enough to handle
the domain gap. Therefore, our proposed method performs
much better than entropy minimization in such cases. We
show an analysis of BN in our supplemental material, revealing its effectiveness for entropy minimization.
4.3. Analysis
Varying Number of Labeled Examples. First, we show
the results on unsupervised domain adaptation setting in Table 3. Our method performed better than other methods
on average. In addition, only our method improved performance compared to source only model in all settings.
Furthermore, we observe the behavior of our method when
the number of labeled examples in the target domain varies
from 0 to 20 per class, which corresponds to 2520 labeled
examples in total. The results are shown in Fig. 4. Our
method works much better than S+T given a few labeled examples. On the other hand, ENT needs 5 labeled examples
per class to improve performance. As we add more labeled
examples, the performance gap between ENT and ours is
reduced. This result is quite reasonable, because prototype
estimation will become more accurate without any adaptation as we have more labeled target examples.
Effect of Classiﬁer Architecture. We introduce an ablation study on the classiﬁer network architecture proposed
in with AlexNet on DomainNet. As shown in Fig.
3, we employ ℓ2 normalization and temperature scaling. In
this experiment, we compared it with a model having a standard linear layer without ℓ2 normalization and temperature.
The result is shown in Table 4. By using the network architecture proposed in , we can improve the performance of both our method and the baseline S+T model
(model trained only on source examples and a few labeled
target examples.)
Therefore, we can argue that the network architecture is an effective technique to improve performance when we are given a few labeled examples from
the target domain.
Feature Visualization. In addition, we plot the learned features with t-SNE in Fig. 5. We employ the scenario
Real to Clipart of DomainNet using AlexNet as the pretrained backbone. Fig 5 (a-d) visualizes the target features
and estimated prototypes. The color of the cross represents
its class, black points are the prototypes. With our method,
the target features are clustered to their prototypes and do
not have a large variance within the class. We visualize features on the source domain (red cross) and target domain
(blue cross) in Fig. 5 (e-h). As we discussed in the method
section, our method aims to minimize domain-divergence.
Indeed, target features are well-aligned with source features
with our method. Judging from Fig. 5f, entropy minimization (ENT) also tries to extract discriminative features, but
it fails to ﬁnd domain-invariant prototypes.
Quantitative Feature Analysis. We quantitatively investigate the characteristics of the features we obtain using the
same adaptation scenario. First, we perform the analysis on
the eigenvalues of the covariance matrix of target features.
We follow the analysis done in . Eigenvectors represent
the components of the features and eigenvalues represent
their contributions. If the features are highly discrimina-
Figure 5: Feature visualization with t-SNE. (a-d) We plot the class prototypes (black circles) and features on the target domain
(crosses). The color of a cross represents its class. We observed that features on our method show more discrimative features
than other methods. (e-h) Red: Features of the source domain. Blue: Features of the target domain. Our method’s features
are well-aligned between domains compared to other methods.
(a) Eigenvalues
(b) Entropy
(c) A-distance
Figure 6: (a) Eigenvalues of the covariance matrix of the features on the target domain. Eigenvalues reduce quickly in our
method, which shows that features are more discriminative than other methods. (b) Our method achieves lower entropy than
baselines except ENT. (c) Our method clearly reduces domain-divergence compared to S+T.
tive, only a few components are needed to summarize them.
Therefore, in such a case, the ﬁrst few eigenvalues are expected to be large, and the rest to be small. The features are
clearly summarized by fewer components in our method as
shown in Fig. 9a. Second, we show the change of entropy
value on the target in Fig. 9b. ENT diminishes the entropy
quickly, but results in poor performance. This indicates that
the method increases the conﬁdence of predictions incorrectly while our method achieves higher accuracy at the
same time. Finally, in Fig. 6c, we calculated A-distance
by training a SVM as a domain classiﬁer as proposed in .
Our method greatly reduces the distance compared to S+T.
The claim that our method reduces a domain divergence is
empirically supported with this result.
5. Conclusion
We proposed a novel Minimax Entropy (MME) approach that adversarially optimizes an adaptive few-shot
model for semi-supervised domain adaptation (SSDA). Our
model consists of a feature encoding network, followed by a
classiﬁcation layer that computes the features’ similarity to
a set of estimated prototypes (representatives of each class).
Adaptation is achieved by alternately maximizing the conditional entropy of unlabeled target data with respect to the
classiﬁer and minimizing it with respect to the feature encoder. We empirically demonstrated the superiority of our
method over many baselines, including conventional feature
alignment and few-shot methods, setting a new state of the
art for SSDA.
6. Acknowledgements
This work was supported by Honda, DARPA, BAIR,
BDD, and NSF Award No. 1535797.