This document is downloaded from DR‑NTU ( 
Nanyang Technological University, Singapore.
Inferring cognitive wellness from motor patterns
Chen, Yiqiang; Hu, Chunyu; Hu, Bin; Hu, Lisha; Yu, Han; Miao, Chunyan
Chen, Y., Hu, C., Hu, B., Hu, L., Yu, H., & Miao, C.  . Inferring cognitive wellness from
motor patterns. IEEE Transactions on Knowledge and Data Engineering, 30(12), 2340‑2353.
doi:10.1109/tkde.2018.2820024
 
 
© 2018 IEEE. Personal use of this material is permitted. Permission from IEEE must be
obtained for all other uses, in any current or future media, including
reprinting/republishing this material for advertising or promotional purposes, creating new
collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted
component of this work in other works. The published version is available at:
 
Downloaded on 27 Mar 2025 02:00:39 SGT
Inferring Cognitive Wellness from Motor Patterns
Yiqiang Chen, Chunyu Hu, Bin Hu, Lisha Hu, Han Yu and Chunyan Miao
Abstract—Changes in the motor pattern have been shown to be useful advanced indicators of cognitive disorders, such as
Parkinson’s disease (PD) and cerebral small vessel disease (SVD). It would be highly advantageous to tap into data containing
people’s motor patterns from motion sensing devices to analyze subtle changes in cognitive abilities, thereby providing personalized
interventions before the actual onset of such conditions. However, this goal is very challenging due to two main technical problems: 1)
the size of data labeled by doctors is small, and 2) the available data tends to be highly imbalanced (the vast majority tend to be from
normal subjects with only a small fraction from subjects with cognitive disorder). In order to effectively deal with these challenges to
infer cognitive wellness from motor patterns with high accuracy, we propose the MOtor-Cognitive Analytics (MOCA) framework. The
proposed MOCA ﬁrst uses the random oversampling iterative random forest based feature selection method to reduce the feature
space dimensionality and avoid overﬁtting, and then adds a bias in the optimization problem of weighted extreme learning machine to
achieve good generalization ability in handling imbalanced small-sampling dataset. Experimental results on two real-world datasets
including SVD and stroke patients show that MOCA can effectively reduce the rate of misdiagnosis and signiﬁcantly outperform
state-of-the-art methods in inferring people’s cognitive capabilities. This work opens up opportunities for population-level pre-screening
using motion sensing devices and can inform current discussions on reforming the health-care infrastructure.
Index Terms—Correlation analysis, motor pattern, cognitive wellness, imbalanced small-sampling feature selection, imbalanced
classiﬁcation.
INTRODUCTION
EURODEGENERATIVE disease is one of the most serious
types of disease among the elderly population, which threatens the lives of millions of people and causes many social problems. The traditional view in medicine divides neurodegeneration
into two categories: 1) cognitive disorders and 2) dyskinesia. They
are usually treated with different approaches. In recent years,
it has been shown that cognitive disorders are often accompanied by movement disorders while dyskinesia is associated with
cognitive degeneration symptoms. In , executive functioning
was shown to be an important factor for explaining the motorcognitive link and the predictive power of ﬁne motor skills for
early academic achievement. In , cognition was found to be
closely associated with gait in complex ways. Irene M.J. van
der Fels et al. reviewed current literature and concluded that
weak-to-strong relations were found between motor functions
and cognitive skills, and complex motor intervention programs
can be used to stimulate both motor and higher order cognitive
skills in prepubertal children. Inspired by these ﬁndings, many
researchers analyzed the correlation between motor patterns and
cognitive abilities with motion sensing technologies , , ,
sometimes with the help of crowdsourcing , . Their ﬁndings
laid the foundations for personalized monitoring. In , apraxia
was suggested to be useful in differentiating Alzheimer’s disease
Yiqiang Chen, Chunyu Hu and Lisha Hu are with the Institute of
Computing Technology, Chinese Academy of Sciences, Beijing, China,
with University of Chinese Academy of Sciences, Beijing, China, and
also with Beijing Key Laboratory of Mobile Computing and Pervasive
Device, Beijing, China (Corresponding author: Yiqiang Chen, e-mail:
 ).
Bin Hu is with the School of Information Science and Engineering,
Lanzhou University, China.
Han Yu and Chunyan Miao are with Joint NTU-UBC Research Centre of
Excellence in Active Living for the Elderly (LILY), Nanyang Technological
University, Singapore.
(AD) from frontotemporal dementia. Previous studies also showed
the importance of measuring an elderly person’s gait and balance
for detecting cognitive diseases such as cerebral small vessel
disease (SVD) and white matter changes .
Despite its obvious allure, leveraging technology that people
already have in their pockets for detecting medically important
events is not as simple as it appears. In general, it is very expensive
and difﬁcult to label a lot of data for the training of cognitive
disorder detection model. Magnetic Resonance Imaging (MRI),
which is essential for the diagnosis of cognitive wellness, is very
costly. Besides, it is hard to ﬁnd a large number of patients
with cognitive disorder to participate in the data collection. Thus,
data collected for cognitive disorder detection often suffers from
the negative effects of small-sampling , , and data
imbalance . With an imbalanced small-sampling dataset, it is
difﬁcult to identify the most discriminant motor pattern features
for accurate diagnosis , , . Imbalanced datasets 
will lead to a natural tendency that the majority class (normal
people) is favored in comparison with the minority class (patients
with cognitive disorder).
However, many existing works do not address these two
problems in motor cognitive analysis. In , the AMOS 19
software was used to construct structural equation models
to analyze the correlations between motor pattern and cognitive
capability. The inﬂuence of imbalanced small-sampling dataset
was overlooked in this study. In , multivariate linear regression
and Spearman’s correlation techniques were adopted to investigate
the associations between cognition and gait. In this research, the
imbalanced data distribution was not taken into consideration in
their statistical analysis. In , step-wise multiple-regression was
applied to analyze the relationship between mental rotation and
motor processes. Although there were only 65 participants, they
didn’t pay attention to the small-sampling issue in their correlation
analysis. All the above works did not address the small-sampling
and imbalanced issues.
In our previous work , we proposed a coarse-to-ﬁne feature
selection method to discover the most signiﬁcant features from a
high dimensional feature set from small-sampling data. In this
paper, we propose a novel MOtor-Cognitive Analytics (MOCA)
framework, which aims at inferring cognitive wellness from motor
patterns. MOCA extends the IRFFS feature selection method from
our previous work to IRFFS-O to handle the oversampling
issue as a result of imbalanced small-sampling datasets in this
work. In addition, we propose a novel classiﬁcation method, b-
WELM, which adds a bias in the optimization process of weighted
extreme learning machine in order to achieve good generalization
ability in handling imbalanced small-sampling datasets.
Experimental results based on real-world datasets demonstrate
that the proposed MOCA is effective in feature selection and performs better than other state-of-the-art feature selection methods
in . Furthermore, experimental results obtained from MOCA
also demonstrate its effectiveness in accurate classiﬁcation of
imbalanced data. The proposed framework opens up opportunities
for population-level pre-screening using smart mobile devices and
can inform current policy discussions on reforming the health-care
infrastructure.
The rest of the paper is organized as follows. Section 2
introduces existing works most related to the proposed framework.
Section 3 describes the proposed correlation analysis framework.
In Section 4, we conduct experiments on two datasets to demonstrate the effectiveness of the proposed framework. Conclusions
and future work are given in Section 5.
RELATED WORK
From Motor Patterns to Cognitive Wellness
In recent years, the rapid advancement of computer science makes
it possible for machine learning to be used for inferring cognitive
wellness based on motor patterns. For example, Termenon et al.
 built a brain MRI morphological pattern extraction tool based
on Extreme Learning Machine (ELM) and majority voting
classiﬁcation. Chen proposed an approach for automatic stroke
detection with high accuracy through a Trail Making Test .
In , Support Vector Machine (SVM) was trained and tested
on Fractional Anisotropy and Mean Diffusivity data to detect
patients with AD. Savio et al. proposed a feature extraction
method based on artiﬁcial neural network and SVM to detect
two neurological disorders with cognitive impairment: Myotonic
Dystrophy of Type 1 and AD.
Changes in the motor pattern have been shown to be associated
with cognitive impairment in PD , AD and SVD .
Some researches have been conducted to study the correlation
between motor pattern and cognitive impairment with different
data collection and correlation analysis methods. Delaram et al.
 used the e-AR sensor to collect acceleration data for PD
patients. An iterative algorithm was proposed for gait analysis
in their work. Ana Lisa et al. adopted the quantitative
digitography (QDG), which used a MIDI interfaced keyboard to
collect the data in repetitive alternating ﬁnger-tapping task, to
analyze the relationship between QDG and UPDRS III scores. In
 , Kita et al. proposed two smart sensing systems to detect the
speciﬁc motion symptoms of PD. One of their systems consisted
of a single sensor integrated in the headphone, and the other
one was composed of two sensors on the shins. Accelerometer,
gyroscope, and magnetometer were integrated into each sensor
unit. In , low-cost motion detectors and labeled images were
used to monitor the abnormal behavior of AD patients and alarm
triggering. To improve the efﬁciency of data annotation, Yang
et al. proposed a novel video annotation method, which
exploited Web images to help learn robust semantic video indexing
classiﬁer. In recent years, game-based data collection systems have
also emerged which investigated people’s cognitive capabilities
in the forms of digital games and unobtrusively collected ﬁnegrained complex inter-temporal decisions-making behaviors ,
 , .
The Challenges of Imbalanced Small-sampling
In disease detection, a common challenge is how to select the
most signiﬁcant features from an imbalanced small-sampling
dataset for accurate detection. Furthermore, the imbalance characteristic often leads to false negative phenomenon in which the
majority class (i.e. normal people) are favored in comparison to
the minority class (i.e. patients with cognitive disorder). Feature
expression is an important part in correlation analysis. A good
feature expression is critical to the performance of the correlation
analysis method. Many researchers have paid attention to this
issue. In , Jun et al. proposed a novel stacked deep polynomial
network algorithm for the texture feature representation learning
on small ultrasound datasets. In , discriminating features for
the detection of PD were selected using mutual information based
approach. In , the features selected by genetic programming
were signiﬁcant in the survival prediction of a small size of oral
cancer prognosis. In , Zhu et al. proposed a novel self-taught
dimensionality reduction approach, which was the ﬁrst work that
employed external information for dimensionality reduction on the
high dimensional and small-sized data. However, additional external information was required to assist the dimensionality reduction
on high-dimensional and small-sized target data. In , Genuer et
al. proposed a feature selection strategy based on random forests.
However, feature selection using random forests is not suitable for
imbalanced small-sampling dataset. This is mainly because even
a little perturbation would cause a large difference in out-of-bag
error for small-sampling data. On the other hand, information gain
or Gini index based algorithms, such as decision tree and random
forests, always show poor performance on imbalanced datasets,
which can be attributed to the skew sensitive splitting criteria .
To solve the problems caused by imbalanced data distribution, random oversampling, random under-sampling and synthetic
minority oversampling technique (SMOTE) are the most common used data sampling methods. With random undersampling
technique, all minority instances are reserved and some majority
instances are randomly removed, which will lead to serious
information loss of majority class for small-sampling dataset.
With SMOTE, new synthetic data for the minority training set
is generated by randomly interpolating pairs of nearest neighbors.
However, SMOTE is not very effective for high-dimensional data
 . For classiﬁcation of the imbalanced dataset, Rahman et al.
 proposed an improved under-sampling technique to balance
cardiovascular data, and Niehaus applied the random undersampling technique to factor out the class imbalance. Ren et al.
proposed an adaptive over-sampling algorithm in , which has
gained good performance in detection of microaneurysm. Another
category of methods to tackle imbalanced dataset is the weighted
approach. Weighted SVM and weighted ELM have been
successfully applied to handle with many imbalanced issues.
In order to address these problems, we propose the MOCA
framework, which is effective even when only imbalanced smallsampling data is available. In this framework, we ﬁrst propose
the IRFFS-O approach to reduce the feature space dimensionality
and reduce the problem of over-ﬁtting. The random over-sampling
technique is adopted to balance the training data, and repeated
random sampling and iterative mechanism are used to reduce the
effect caused by perturbation on small-sampling datasets. Then,
we propose a novel classiﬁcation model b-WELM which adds a
bias in the optimization problem of weighted ELM to improve the
generalization ability which enables the framework to distinguish
only a few patients with cognitive disorders from a large number
of normal control subjects better.
THE MOCA FRAMEWORK
In Figure 1, we give an illustration of the proposed MOCA
framework. The most important components of MOCA are feature
selection and classiﬁcation. In addition, data collection and feature
extraction are also presented.
In our MOCA framework, feature selection aims to reduce
the feature space dimensionality and reduce the problem of over-
ﬁtting. With this measure, we can simplify the activity data
collected. Only the motion corresponding to the selected features
should be collected in the subsequent data collection phase.
Once the optimal features are selected, we hope to build a light
classiﬁcation model, which is able to reduce the rate of missed
diagnosis by appropriately improving the sensitivity. With such
a classiﬁcation model, we are able to incorporate it into a light
smart devices to assist the diagnosis. Thus, we propose a lightweight classiﬁcation model – b-WELM, which is very effective in
handling imbalanced datasets.
Data Collection
Activity data collected in this step are usually summarized and
simpliﬁed according to several existing and widely accepted
scales. These include the Scale for Assessment and Rating of
Ataxia , the Short Physical Performance Battery , the
Tinetti Mobility Test (TMT) and the Uniﬁed Parkinson
Rating Scale (UPDRS) . Different data collection schemes
are designed for different research purposes. For example, the
activities from the UPDRS are summarized to study the correlation
between motor pattern and PD. As TMT is an effective indicator
for brain damages and a powerful predictor of stroke , it
is usually used for stroke detection.
Various data collection devices (e.g., Kinect, smartphone and
smart band) can be used to collect motion related data from
the subjects in this step. Different data collection devices are
suitable for different data acquisition requirements. In order to
reduce the disturbance of data collection devices on the subjects,
we collect the raw motion data using the depth sensor and the
RGB camera embedded in Kinect. The data acquired by Kinect
is usually recorded in the format of depth image, RGB image
and skeleton data. Accelerometers and gyroscopes embedded in
wearable devices (e.g., smart band, smartwatch and smartphone)
are commonly used to collect motion data in daily life for a long
time. The readings from accelerometers and gyroscope record
the accelerated velocity and angular velocity respectively. Electromyographic (EMG) armband mounted on the upper arm, which
contains some electrodes, is a kind of wearable EMG devices.
The data from EMG armband is electric potential generated by
Motor Pattern
Data Collection
Raw Motor Pattern Features
for specific actions
Raw Motor Pattern Features
for specific actions
Significant Feature
Random Forest
Feature Selection
Imbalanced
Classification
Feature Extraction
Fig. 1. The proposed MOCA framework.
muscle cells. Wearable EMG armband, which is made up of
electrodes, can be used to collect EMG signal in a wearable way.
The data acquired from EMG armband is a set of electric potentials
generated by muscle cells.
Feature Extraction
Feature extraction is commonly used to identify numeric variables
that can reﬂect the intrinsic data properties . In this step, we
try to uncover hidden information from raw motion data which
can reﬂect the correlation analysis between motion behavior and
cognitive ability. In this work, we focus on three types of features:
1) time domain features, 2) frequency domain features and 3)
motor features. Time domain features commonly refer to timevarying features (e.g., mean, standard deviation, zero crossing rate
and maximum/minimum). Frequency domain features are often
used to ﬁnd out the periodical information of signals (e.g., direct
current, amplitude and power spectral density). Motor features
are related to speciﬁc actions performed by the person being
monitored. These features are used to extract the characteristics of
actions. Medical instructions from doctors and characteristics used
in clinical cognitive assessment are taken into consideration in the
feature extraction step of MOCA, which makes the research more
reasonable. Though the selection of motor features is largely dependent on the empirical knowledge of researchers, these features
are able to reﬂect the intrinsic characteristics of motor pattern,
which is useful for the correlation analysis.
Feature Selection
Through feature extraction, we have obtained sufﬁcient features to
describe the acquired motor patterns. However, there are two main
problems to be solved. On one hand, the number of extracted
features could be huge. This high dimensional data will cause the
curse of dimensionality. On the other hand, a large number of irrelevant features will increase the difﬁculty for further correlation
analysis. Feature selection is a useful data preprocessing method
to deal with these issues. Thus, in Step 3, feature selection is
performed to reduce the feature space dimensionality and reduce
the problem of over-ﬁtting.
In this subsection, we propose a novel feature selection
method, named random Oversampling Iterative Random Forestbased Feature Selection (IRFFS-O) which is an extension to
the random forest feature selection technique . This method
automatically measures the importance of the extracted features,
retain the most signiﬁcant features and discard unnecessary ones.
Its main advantage is the ability to handle imbalanced smallsampling dataset.
The whole process of IRFFS-O is ﬁrst brieﬂy introduced.
Before constructing the random forests, we randomly divide the
whole dataset into training sets and testing sets repeatedly and
perform the random over-sampling technique on each training
set. Then, the IRFFS-O enters an iterative process. Several random forests will be constructed following the learning method
proposed by Breiman et al. . In each loop, IRFFS-O ranks
the features according to their occurrence frequencies and select
the most common and frequent features to rebuild new random
forests. The process is repeated until no further classiﬁcation
performance improvements can be achieved. Let T = (xi, ti) ∈
Rn × Rm, i ∈{1, 2, ..., N} denote the initial training set, where
xi = [xi1, xi2, ..., xin]T is an input vector with n features, and
ti = [ti1, ti2, ..., tim]T is the corresponding target vector. n(t) is
the number of features in the tth iteration.
Figure 2 shows the ﬂow chart of IRFFS-O method. The main
procedure of IRFFS-O is described as the following:
Initialization. Set iterative index t = 0, initial training set
T (0) = T , initial average classiﬁcation accuracy (acc =
Random sampling. Randomly sample Nr samples from
the training set T (t) for S times, obtaining S sub-training
sets T s(t) = {xi, ti} ∈Rn(t)×Rm, i ∈{1, 2, ..., Nr}
and S sub-testing sets V s(t) = {xi, ti} ∈Rn(t) ×
Rm, i ∈{Nr + 1, Nr + 2, ..., N}, s ∈{1, 2, ..., S}.
Random oversampling on sub-training set. Samples from
the minority class are randomly selected with replacement to balance the sub-training sets T s(t). After random
oversampling, the balanced sub-training sets are represented by T
Random forest building. Build S random forests based
on S balanced sub-training sets T
′s(t) using the learning
method proposed in . Here, the number of trees in
each random forest is set to B, and ⌊
(n(t)⌋features
are used in each split.
Feature validation. Compute the average classiﬁcation
accuracy acc(t) of the S built random forests using the
corresponding sub-testing sets V s(t). If acc(t) is higher
than acc, set acc to acc(t) and go to Step 6; else drop
the iterative process and select the current n(t) features
as the most signiﬁcant features.
Feature sorting. In order to measure the importance of
each feature fj, j ∈{1, 2, ..., n(t)}, we introduce two
variables: (1) the number of random forests where fj
occurs, denoted as Nj, and (2) the frequency at which fj
appears in the random forests, denoted as Fj. Nj can be
counted directly. Fj is computed as follows:
bj and N s
b denote the number of internal nodes
testing on feature fj and the number of total internal
nodes in the bth tree of the sth random forest, respectively. Since a more discriminant feature would be
selected in more trees of more random forests built using
different training sets, a feature with large Nj and Fj
values is of greater importance. IRFFS-O then sorts the
n(t) features according to Nj and Fj in descending
Feature selection. In this step, Nj is ﬁrstly considered.
When the number of built random forests where fj
occurs is the same as another feature fi, then we further
compare Fi and Fj. The feature with a larger value of
F is considered more important. Select the top r ranked
features as the most discriminant features. Since a large
r would cause redundant looping, while a small r may
discard signiﬁcant features, we set r as half of the current
number of features, i.e. r = ⌊n(t)
2 ⌋. If r is greater
than the minimum number of features nmin, assign r to
n(t + 1) and go to Step 8; else drop the iterative process
and select the current n(t) features as the most signiﬁcant
Loop. Set t = t + 1 and go to Step 4.
With a small-sampling dataset, even a little perturbation would
cause a large difference in the out-of-bag error, which will result
in a very different feature selection result. Thus, we adopt the
repeated random sampling technique and iterative mechanism in
Sub-training
Sub-training
Sub-training
Select the top r features as the most discriminant features
The number of built random
forests where fj occurs
The frequency at which fj
appears in the built random
Initialization
Random sampling
Random forest building
Feature validation
Feature sorting
Feature selection
Sub-training
Random oversampling on subtraining set
Sub-testing
Sub-testing
Sub-testing
Sub-training
Sub-training
Small-sampling
and imbalanced
Fig. 2. The ﬂow chart of the IRFFS-O method.
the proposed IRFFS-O method. The repeated random sampling,
which corresponds to step 2), is used to decrease the perturbation
caused by a single division, and the iterative mechanism is used to
reduce the perturbation caused by a singe feature selection process
and select the optimal features step by step.
To avoid the problems caused by imbalanced data distribution,
the random over-sampling technique (presented in step 3)) is used
in IRFFS-O. For each training set, we perform the random oversampling technique, which will contribute to balanced training
sets. Then, the impact of imbalanced data distribution on feature
selection is decreased before the building of random forests.
Classiﬁcation
In order to build an accurate correlation analysis model with
imbalanced data, we propose a novel classiﬁcation approach –
b-WELM. b-WELM is a learning method built on b-COELM
 and weighted Extreme Learning Machine (weighted ELM)
 , which achieves good generalization in dealing with data with
imbalanced class distribution. Since it is difﬁcult to obtain patient
data while comparatively easy to collect data from healthy people,
the bias in performance caused by imbalanced class distribution
is very common in disease detection. b-WELM is designed to
distinguish patients with cognitive disorders from normal control
Extreme Learning Machine (ELM) is a single hidden layer
feedforward neural network, which is proposed as a uniﬁed framework for binary, multiclass classiﬁcation and regression problems
 . In ELM, learning is made without iterative tuning and is very
efﬁcient and effective when the training set is small . With
comparable predictive accuracy with SVM, ELM performs with
a faster learning speed. To improve the generalization ability of
ELM, Hu et al. proposed the b-COELM by adding a bias item
in the optimization problem of COELM. To cope with imbalanced
data distribution in the training samples, weighted ELM 
constructs a model using the weighted trade-off parameters for
different training samples. In this paper, we propose a novel
learning method, named b-WELM, with better generalization
ability in handling imbalanced datasets.
Given N arbitrary distinct samples (xi, ti) ∈Rn × Rm, i ∈
{1, ..., N}, where xi is a n × 1 input vector xi = [xi1, ..., xin]T
and ti is an m × 1 target vector ti = [ti1, ..., tim]T . The network
architecture of b-WELM is shown in ﬁgure 3.
The architecture of b-WELM consists of three layers (from
Fig. 3. The network architecture of b-WELM.
left to right): the input layer, the hidden layer and the output
layer. Given each arbitrary sample (x, t), the n nodes in the
input layer correspond to the features of the input vector x.
In the hidden layer, x is nonlinearly mapped into the vector
h(x) = (h1(x), . . . , hL(x))T in an L-dimensional feature
space. hk represents the kth element of the L-dimensional vector
when x is not speciﬁed. Notations aik from the input layer to
the hidden layer in Figure 3 are the parameters relevant to the
nonlinear mapping. In the output layer, h(x) is mapped into
the target vector t according to a linear transformation with two
variables, an L×m dimensional weight matrix β and a bias vector
b = (b1, . . . , bm)T , both can be analytically solved.
The primal optimization problem of b-WELM is as follows:
2(||β||2+||b||2) + C
Wii||ξ:,i||2
βT h(xi) + b = ti −ξ:,i, i ∈{1, ..., N}
Several parameter values need to be determined beforehand.
C is the penalty parameter balancing the maximum generalization
ability (the ﬁrst term of objective function) and minimum training
error (the second term of objective function). W is a N × N
dimensional diagonal weight matrix in which Wii is the weight of
sample xi.
Based on the parameters above, when the training process
starts, the two variables β and b are computed. β is an L × m
dimensional output matrix, b is an m × 1 bias vector b =
(b1, . . . , bm)T . Besides, ξ is an m×N dimensional slack variable
in which the ith column of ξ, denoted by ξ:,i, is the training error
of the instance xi.
In (2), W is the weight matrix, which is associated with individual training instance xi. If xi belongs to a minority class, Wii
will be assigned a larger value. In contrast, Wii will be assigned
a smaller value if xi belongs to a majority class. Thus, with W ,
the weights of the minority and majority classes are rebalanced
with this technique during the classiﬁcation process. With the
bias item ‘b’, b-WELM has strong convexity and satisﬁes the
non-essential requirement of Mercer’s positive deﬁnition condition
 . With both W and b introduced, b-WELM achieves a better
generalization ability in handling imbalanced datasets.
Based on the Karush-Kuhn-Tucker (KKT) theorem, the problem in (2) is equivalent to its dual problem. The objective function
of its dual problem is as shown in (4).
LDb-WELM = 1
2(||β||2 + ||b||2) + C
Wii||ξ:,i||2
:,jh(xi) + bj −ti,j + ξj,i)
α is a N ×m matrix in which the ith column of α is the Lagrange
multiplier of sample xi. We refer to α as the Lagrange matrix.
Furthermore, let the partial derivative of LDb-WELM with respect to
all the variables be 0, we have the following equations:
αi,jh(xi) = 0, ∀j ⇔β = HT α (5a)
αi,j = 0, ∀j ⇔b = αT 1vec
= CWiiξj,i −αi,j = 0, ∀i, j
⇔CξW = αT ⇔ξT = 1
:,jh(xi) + bj −ti,j + ξj,i = 0, ∀i, j
⇔Hβ + 1vecbT + ξT = T
H is a N × L matrix in which each row is h(xi)T . 1vec is a
N × 1 vector with all elements being 1. Substitute (5a) - (5c) into
(5d), we can get (6).
α∗= (W HHT + W 1mat + 1
1mat is a N × N matrix with all elements being 1. Substitute (6)
into (5a), we can get:
b∗= (α∗)T 1vec
At last, the output function of b-WELM is:
f(x) = (β∗)T h(x) + b∗= (α∗)T (Hh(x) + 1vec)
For any testing sample x, f(x) is a m × 1 vector. The prediction
of b-WELM on x is in (10). fk(x) is the kth element of f(x).
Prediction(x) = arg max
k∈{1,...,m}
In (6), replace HHT in (6) by the Gram matrix Ω(Ωij =
k(xi, xj), i, j = 1, ..., N) of a kernel k(u, v) and Hh(x) in
(9) by the kernel form, we have the output function of kernel
based b-WELM:
f(x) = T T W (ΩW + 1matW + 1
C I)−1([k(x1, x),
..., k(xN, x)]T + 1vec)
EXPERIMENTAL EVALUATION
To study the effectiveness of the proposed framework, we conduct
experiments on two datasets. The ﬁrst dataset is collected on SVD
patients, and the second dataset is gathered from stroke patients.
Comparison methods
Six feature selection methods embedded in WEKA and
IRFFS are used as comparison methods against the proposed
IRFFS-O approach. They are:
CorrelationAttributeEval. Evaluates the usefulness of a
subset of attributes by considering the individual predictive
power of each feature along with the degree of redundancy
among them;
GainRatioAttributeEval. Evaluates the usefulness of an
attribute by measuring the gain ratio with respect to the
InfoGainAttributeEval. Evaluates the usefulness of an attribute by measuring the information gain with respect to
the class;
OneRAttributeEval. Evaluates the usefulness of an attribute by using the OneR classiﬁer;
ReliefFAttributeEval. Evaluates the usefulness of an attribute by repeatedly sampling an instance and considering
the value of the given attribute for the nearest instance of
the same and different class;
SymmetricalUncertAttributeEval. Evaluates the usefulness
of an attribute by measuring the symmetrical uncertainty
with respect to the class;
IRFFS. Evaluates the usefulness of attributes with the
method proposed in .
Four state-of-the-art classiﬁcation methods are used for comparison with the proposed b-WELM approach. They are:
b-constrained-optimization-based extreme learning machine (b-COELM) ;
Weighted extreme learning machine (weighted ELM) ;
Weighted support vector machine (weighted SVM) ;
Back propagation (BP) algorithm .
SVD Detection
Dataset Description
The MRI Characteristics of the SVD Patients
Fazekas Scale
Fazekas Scale
No. lacunar
(periventricular
(deep white
white matter
Eight SVD patients and 43 healthy subjects were recruited
for our experiments. The SVD patients are aged from 62 to 76
and consist of 4 women and 4 men. The healthy subjects are
aged from 22 to 76 and consist of 17 women and 26 men. Each
subject corresponds to one sample in the dataset. Thus, there are
51 samples in SVD detection dataset with 8 samples of SVD
patients and 43 samples of healthy subjects. Each subject was
asked to perform all 17 motor actions in order. The completion
time for each subject ranged from 3.05 minutes to 8.42 minutes.
The individual and MRI characteristics of the 8 SVD patients are
shown in Table 1.
Data Collection
We use Kinect to collect raw depth sensor data and RGB camera
data of 17 predeﬁned clinical actions. These 17 actions are
classiﬁed into three categories: gait, balance and agility.
Gait Test. Gait test includes natural walking test, 3-meter
walking and 180 degree turning test. A subject is asked to
walk in front of the Kinect camera. Crutches are allowed
if the subject has difﬁculty walking unaided. Figure 4(a)
shows the data collection process of 3-meter walking and
180 degree turning test as an example of the gait test. The
subject is asked to walk 3 meters in a natural way, then
turned back and walk back to the starting line.
Balance Test. In these tests, a subject is asked to perform
some speciﬁc actions to test their balance capability. These
actions include standing up from a seated position, repeated standing up from a seated position with arms folded
across the chest, pulling test, side by side standing, semitandem standing, tandem standing, tandem walking and
nudge. If there is any notable left or right skew, trend of
falling down or difﬁculty to complete the test, the test will
immediately stop. Figure 4(b) shows the data collection
process of tandem walking as an example of balance test.
The subject is asked to walk in a straight line with the toe
of one foot touching the heel of the other foot.
Agility Test. In order to judge whether a subject has agility
problems, we ask the subject to perform actions as quickly
as possible. The tests include: ﬁnger tracking, ﬁngerto-nose test, rapid alternating up and down movements
of the hand, rapid alternating movements of the hand,
ﬁnger tapping and tapping heel on the ground in rapid
successions while raising the entire leg. Figure 4(c) shows
the data collection process of ﬁnger tracking and tapping
heel on the ground as examples of agility test. In ﬁnger
tracking, the subject is asked to track the doctor’s ﬁnger
with his own foreﬁnger as quickly as possible. In tapping
heel on the ground, the subject is asked to raise the heel
up and down as quickly as possible 10 times.
Feature Extraction
Some potential SVD related motor pattern features are extracted
from the collected dataset. These features include: 1) gait related
features, such as stride length, step width, step height, walking velocity, and sagittal and coronal-angular excursions of the
shoulder, elbow, hip, knee and trunk, which are calculated as
the method proposed in ; 2) balance related features, such as
angular excursions of the trunk and stand velocity; and 3) agility
related features, including smoothness of movement trajectory
and variability of movement velocity. In total, 739 features are
extracted.
Fig. 4. Data collection for SVD test: (a) Gait test. (b) Balance test. (c)
Agility test.
Feature Selection
We perform feature selection experiment on the data of the 51
subjects with IRFFS-O. In our experiment, the training rate is set
as 70%. Thus, the number of training samples is Nr = ⌊43 ×
70%⌋+ ⌊8 × 70%⌋= 35 and the size of testing set is 51 −35 =
16. To eliminate the splitting effect, we set the sampling time to
1,000 and the experimental results are averaged. To ﬁnd out the
most discriminant features, IRFFS-O tests different sets of features
from all 739 features to a single feature.
The average accuracy at each iteration of IRFFS-O is presented
in ﬁgure 5. With the number of features decreases from 739 to
2, the average classiﬁcation accuracy shows a continuous rising
trend. The classiﬁcation accuracy is improved from 78.76%–
79.46% to 88.18%–91.86%. This indicates that the proposed
IRFFS-O method is able to discard redundant features and preserve signiﬁcant features continuously. With the number of features decreases from 2 to 1, the average classiﬁcation accuracy
drops from 88.18%–91.86% to 83.67%–90.80%, which means
some useful features are discarded in this iteration. Thus, the
iterative process is terminated and 2 most discriminant features
are selected. With the number of features set as 2, the average
classiﬁcation accuracy obtains the highest value at B = 100.
Then, we take the feature selection results at this parameter
settings as the most signiﬁcant features. The selected features are
shown in Table 2. As we can see, the selected features include
an agility related feature and a balance related feature. With this
experimental result, we can infer that rapid alternating movements
of the hand and tandem walking may be more relevant to the
detection of SVD.
To further validate the discriminating ability of the feature selected by IRFFS-O, we conduct a group of comparison
Number of Features
Avg. Classification Accuracy
Fig. 5. The average classiﬁcation accuracy of the random forest model
at each iteration using the IRFFS-O method on the SVD dataset.
Two Most Discriminant Features for SVD Detection (Selected by the
IRFFS-O Method with B = 100)
Feature Type
Motor Action
Feature Extracted
Mean pronation velocity of the
alternating
right hand
hand movements
Mean of the maximum angular
excursions of the trunk in the z
experiments against IRFFS and 6 other feature selection
methods provided in WEKA . Ten classiﬁcation tests with
AdaBoostM1 and MultilayerPerceptron are performed in WEKA
on the features selected by different feature selection methods with
default parameter settings. Ten folds cross-validation is adopted
in this experiment. The average test accuracies are listed in
Table 3. From Table 3, it can be observed that the proposed
IRFFS-O and IRFFS both gains the best classiﬁcation results with
AdaBoostM1 algorithm. While with the MultilayerPerceptron
algorithm, IRFFS-O slightly outperforms IRFFS. Overall, the test
accuracy on SVD dataset of both AdaBoostM1 and MultilayerPerceptron algorithm based on two features selected by the IRFFS-
O method is better than that based on two features selected by
other feature selection methods, which indicates that the IRFFS-O
method is more effective in selecting the most signiﬁcant features
for accurate SVD detection from imbalanced small-sampling data.
The SVD Detection Performance of AdaBoostM1 and
MultilayerPerceptron based on the Two Features Selected by Different
Feature Selection Methods
Feature Selection Method
AdaBoostM1
MultilayerPerceptron
CorrelationAttributeEval
GainRatioAttributeEval
InfoGainAttributeEval
OneRAttributeEval
ReliefFAttributeEval
SymmetricalUncertAttributeEval
Classiﬁcation
With the features selected by IRFFS-O, we adopt the proposed
b-WELM algorithm to construct an accurate model with high
classiﬁcation accuracy and G-mean.
To evaluate the effectiveness of b-WELM, the repeated random
sub-sampling (RRSS) technique is used to generate the training
and testing datasets separately. Besides, b-COELM, weighted
ELM, weighted SVM and back-propagation (BP) are used for
comparisons.
(k(xi, xj)
exp(−g∥xi −xj∥2)) is adopted by all models except for BP.
There are two parameters, penalty parameter C and kernel parameter g, used by b-WELM, b-COELM, weighted ELM and
weighted SVM; and another two parameters, number of hidden nodes L and learning rate lr, used by BP. In order to
fairly compare the performances of the ﬁve models, we need
to ﬁnd the optimal parameter pairs for each algorithm. Grid
search technique is employed in this paper. Fifty different values
{2−24, 2−23, · · · , 224, 225} are tested for both C and g, and 15
different values {2−15, 2−14, · · · , 2−1} are tested for lr. For BP,
the number of input nodes is commonly set between the number
of features (2 in this experiment) and the number of output nodes
is commonly set as 1 . Thus, 2 different values {20, 21} are
tested for L.
With RRSS technique, we select 70% of the samples for
training and 30% of the samples for testing. Therefore, the training
set and testing set consist of 35 and 16 instances, respectively. The
weights in b-WELM, weighted ELM and weighted SVM are both
set as 1/#(ti), where #(ti) is the number of samples belonging
to class ti(i = 1, · · · , m). Figure 6 presents the testing accuracy
of b-WELM, b-COELM, weighted ELM, weighted SVM and BP
with different parameter pairs. The optimal parameter values for
each model are listed in Table 4.
The optimal parameter for each model
weighted ELM
weighted SVM
Classiﬁcation Performance To evaluate the performance of b-
WELM on SVD detection, we adopt test accuracy, test sensitivity,
test speciﬁcity and test G-mean as evaluation metrics. They are
calculated as follows:
Accuracy =
tp + fp + tn + fn
Sensitivity =
Speciﬁcity =
Sensitivity × Speciﬁcity
where tp, fp, tn and fn denote true positive, false positive, true
negative and false negative, respectively.
Accuracy is one of the most common metrics used to evaluate
the effectiveness of a classiﬁer. For imbalanced dataset, sensitivity
and speciﬁcity are able to give more insight into the accuracy
obtained within each class. G-mean provides an overall view to
(a) b-WELM
(b) b-COELM
(c) weighted ELM
(d) weighted SVM
Fig. 6. Experimental results on the accuracy of b-WELM, b-COELM,
weighted ELM, weighted SVM and BP with different parameter pairs.
evaluate a classiﬁer, which is calculated as the geometric mean of
sensitivity and speciﬁcity. In this section, b-COELM, weighted
ELM, weighted SVM and BP are presented as comparisons.
Experiments with the optimal parameters are repeated for 1,000
times. Table 5 shows the average SVD detection performances
of b-WELM, b-COELM, weighted ELM, weighted SVM and BP
based on feature selected by the IRFFS-O method with B = 100.
The SVD Detection Performance
Test Accuracy
Test Sensitivity
Test Speciﬁcity
Test G-mean
b-COELM(C = 211, g = 23)
b-COELM(C = 221, g = 25)
Weighted ELM
Weighted SVM
As shown in Table 5, b-WELM outperforms the other four algorithms in accuracy, sensitivity, speciﬁcity, and G-mean. Among
these methods, BP achieves the worst performance in accuracy,
sensitivity, and G-mean. Except for BP, the advantages of b-
WELM over the other three methods are not signiﬁcant. This is
an indirect evidence that the features selected by the proposed
IRFFS-O approach are signiﬁcant in distinguishing SVD patients
from healthy persons, which contribute to good classiﬁcation
results of different classiﬁers. The average accuracy of b-WELM
is 97.87%, which is the highest among all comparison approaches.
With imbalanced data distribution, SVD patients are the minority
in the dataset. Generally, there is a natural tendency that the
majority class (i.e. healthy people) are favored in comparison
to the minority class (i.e. SVD patients). In other words, SVD
patients are more prone to be misclassiﬁed as healthy people.
However, with b-WELM, all SVD patients have been classiﬁed
correctly (i.e. the test sensitivity is as high as 100.00%). This is
especially important to disease detection. For speciﬁcity, although
all ﬁve methods obtained good performance, b-WELM performs
the best, which means b-WELM can also classify the healthy
people better. G-mean is the square root of (positive class accuracy
× negative class accuracy). It is usually used to measure the
overall effectiveness of a classiﬁer. As shown in Table 5, b-
WELM is able to achieve the highest score in G-mean among
all comparison approaches.
The above experimental results suggest that there is a strong
correlation between the motor pattern changes and SVD, which
is consistent with clinical observations. Besides, our MOCA
framework is able to reduce the rate of missed diagnosis by appropriately improving the sensitivity of the algorithm. Therefore,
the proposed framework is shown to be useful in the diagnosis
of SVD and thus can assist doctors in the correlation analysis
between motor patterns and SVD.
Stroke Detection
Dataset Description
We collected motion data from 14 patients (8 males and 6 females)
and 55 healthy subjects (30 males and 25 females) aged from 30
to 68. Each subject corresponds to one sample. Thus, there are 69
sample instances in stroke detection dataset. All patients suffered
from stroke for the ﬁrst time. They have recovered well and were
discharged from the hospital. Each subject was asked to play the
speciﬁcally designed body sensing game BSG-TMT , which
is developed based on the traditional TMT to indicate possible
cognitive impairment.
Data Collection
In this experiment, Kinect is used for single ﬁngertip tracking of
any palm pose. We adopt the palm-pose-adaptive single ﬁngertip
tracking method to detect ﬁngertips in natural palm poses. In
TMT, the trajectory coordinates and time are recorded in a text
The interfaces of BSG-TMT are shown in Figure 7. Subjects
should connect a set of 11 dots in order as quickly as possible
while maintaining accuracy. If the subject does not connect the
dots in order, the game will remind the subject to correct the error
before moving on to the next dot.
(a) Pre-start
(b) Connecting error
(c) Final state
Fig. 7. The user interface of BSG-TMT .
Feature Extraction
After data collection, we analyzed the BSG-TMT data and extracted eight features. The drawing length between two numbers is
deﬁned as l, the straight-line distance between two consecutively
numbered dots is deﬁned as L, and the time needed to connect
two consecutively numbered dots is deﬁned as T. The eight
extracted features are the total time required to complete the
test (ATime), the trail accuracy (TAccuracy), the time the subject
took to correct an error (CTime), the mean (M-R-Length), and
variance (V-Length), of the N −1 ratios of l to L, the mean time
duration spent by ﬁngertips at the dots (M-Fingertip), the mean
(M-R-Time), and variance (V-Time), of the ratios of T to l.
Feature Selection
In this experiment, we try to ﬁnd the most distinguishing features
for detection of stroke and discard the redundant features. The
training rate is set as 70% and the number of sampling is set as
1,000, which are the same as the experimental settings in Section
4.2.4. Thus, the size of training set is Nr = ⌊14 × 70%⌋+
⌊55 × 70%⌋= 47. To ﬁnd out the most discriminant features, we
decrease the number of features from 8 to 1.
As shown in Figure 8, with the number of features declining from 8 to 1, the average classiﬁcation accuracy ﬁrst rises
from 73.99% -75.04% to 74.88% -77.11% and then falls down
to 64.44% -66.95%, which means some redundant features are
abandoned at the ﬁrst iteration and some useful information
are dropped at the next two iterations. Thus, four signiﬁcant
features are selected by IRFFS-O. With B set as 30, the average
classiﬁcation accuracy reaches the maximum value 77.11%. The
details of the four selected features are listed in Table 6. With this
experimental result, we can build a more effective stroke detection
Number of Features
Avg. Classification Accuracy
Fig. 8. The average classiﬁcation accuracy of the random forest model
at each iteration using the IRFFS-O method on the stroke dataset.
To further evaluate the effectiveness of the IRFFS-O method,
we compare it with IRFFS and the other 6 feature selection
methods presented in WEKA . AdaBoostM1 and Multilayer-
Perceptron are both used as classiﬁers. The experimental settings
are the same as in SVD dataset. As show in Table 7, the stroke
detection accuracy of both AdaBoostM1 and MultilayerPerceptron
based on the four features selected by the IRFFS-O method
The Four Most Discriminant Features for Stroke Detection (Selected by
the IRFFS-O method with B = 30)
Feature Name
Feature Calculation
i=1 Ti, N is the number of lines drawn in TMT.
i=1 Ti, NC is the number of connecting error.
li , ti is the time spend on drawing the ith
line, li is the drawing corresponding to the ith line.
M-Fingertip
i=1 I(|pos −pi|< µ), I is an indicator function,
Np is the number of points, pos is the position of tester ﬁnger,
pi is the position of points i and µ is a threshold value.
are better than the other seven feature selection methods, which
further demonstrates that the IRFFS-O method is very effective in
selecting the most signiﬁcant features for accurate stroke detection
and also further validates the effectiveness of IRFFS-O in handling
imbalanced small-sampling data.
The Stroke Detection Performance of AdaBoostM1 and
MultilayerPerceptron based on the Four Features Selected by Different
Feature Selection Methods
Feature Selection Method
AdaBoostM1
MultilayerPerceptron
CorrelationAttributeEval
GainRatioAttributeEval
InfoGainAttributeEval
OneRAttributeEval
ReliefFAttributeEval
SymmetricalUncertAttributeEval
Classiﬁcation
With the four selected features, we build a stroke detection model
with b-WELM. The RRSS technique is used to generate training
and testing datasets. b-COELM, weighted ELM, weighted SVM
and BP are used for comparisons.
Parameter Selection Similar to Section 4.2.5, we adopt the
Gaussian kernel (k(xi, xj) = exp(−g∥xi −xj∥2)) for all
comparison approaches except BP. The penalty parameter C
and the kernel parameter g are tuned for b-WELM, b-COELM,
weighted ELM and weighted SVM, while the number of hidden
nodes L and the learning rate lr are tuned for BP. We adopt
the grid search technique to select the optimal parameters for b-
WELM, b-COELM, weighted ELM, weighted SVM and BP. Fifty
different values {2−24, 2−23, · · · , 224, 225} are tested for both C
and g, and 15 different values {2−15, 2−14, · · · , 2−1} are tested
for lr. We use 70% of the samples for training and 30% of the
samples for testing. The weights in b-WELM, weighted ELM and
weighted SVM are set to 1/#(ti), where #(ti) is the number of
samples belonging to class ti(i = 1, · · · , m).
Figure 9 presents the accuracy achieved by b-WELM, b-
COELM, weighted ELM, weighted SVM and BP with different
parameter settings. The optimal parameter values for each model
are shown in Table 8.
The optimal parameter for each model
weighted ELM
weighted SVM
Classiﬁcation Performance To evaluate the performance of
b-WELM on stroke detection, we also adopt accuracy, sensitivity,
(a) b-WELM
(b) b-COELM
(c) weighted ELM
(d) weighted SVM
Fig. 9. Experimental results on the accuracy of b-WELM, b-COELM,
weighted ELM, weighted SVM and BP with different parameter pairs.
speciﬁcity, and G-mean as evaluation metrics. Experiments using
the optimal parameters obtained above in Table 8 are repeated
for 1,000 times. Table 9 shows the average stroke detection
performance of b-WELM, b-COELM, weighted ELM, weighted
SVM and BP based on the features selected by the IRFFS-O
method with B = 30.
The Stroke Detection Performance
Test Accuracy
Test Sensitivity
Test Speciﬁcity
Test G-mean
weighted ELM
Weighted SVM
As shown in Table 9, the accuracy of each classiﬁer is above
79%, which demonstrates that the features selected by IRFFS-
O are signiﬁcant in distinguishing stroke patients from healthy
persons. In this experiment, ﬁve methods show comparable performance in test accuracy, while presenting signiﬁcant differences
in test sensitivity, test speciﬁcity, and test G-mean. For sensitivity,
b-WELM and weighted ELM perform similarly, which are both
about 73%. By contrast, the other three methods, especially
BP, show poor performance in sensitivity. However, these three
methods show relatively better performances in speciﬁcity, which
means they perform better in classifying the healthy subjects. For
G-mean, b-WELM shows the best performance, which indicates
that b-WELM achieves the best overall performance in the detection of stroke. For imbalanced datasets, b-WELM can classify
the patients more accurately, which is very useful for diagnosing
Based on the experimental results shown above, it can be
seen that TMT is useful for the detection of stroke. The connectthe-dots behavior can be analyzed for the indication of stroke.
MOCA is an effective tool for the doctors to make analysis of the
correlation between motor patterns and stroke.
CONCLUSIONS
In this paper, we propose the MOCA framework to inferring cognitive wellness from motor patterns. We propose a novel feature
selection method – IRFFS-O – and a novel classiﬁcation method
– b-WELM – under the MOCA framework which can be used
to deal with imbalanced small-sampling data prevalent among
disease datasets. Various sensors can be used for data collection
in conjunction with our framework. Motor pattern features are
extracted according to the collected data. Experimental results on
two real-world datasets, including SVD and stroke patients’ data,
demonstrate that MOCA is suitable for the analysis of correlation
between motor patterns and cognitive wellness, where the datasets
are usually imbalanced small-sampling. It is able to reduce the rate
of missed diagnosis by appropriately improving the sensitivity of
the algorithm. Therefore, MOCA can be employed as an effective
tool to assist doctors in the diagnosis of cognitive disorders.
In the future, we will conduct experiments on more cognitive
disorder related datasets to study the effectiveness of this framework. Besides, we will investigate how to jointly consider the
feature selection and extraction steps, possibly with the help of
deep learning neural networks.
ACKNOWLEDGMENTS
This work is supported by the National Key Research and Development Program of China (No. 2017YFB1002801); Natural
Science Foundation of China under Grant No. 61572471 and No.
61502456; Science and Technology Planning Project of Guangdong Province under Grant No. 2015B010105001; the National
Research Foundation, Prime Minister’s Ofﬁce, Singapore under its
IDM Futures Funding Initiative; the Lee Kuan Yew Post-Doctoral
Fellowship Grant; and the Singapore Ministry of Health under its
National Innovation Challenge on Active and Conﬁdent Ageing
 . The corresponding
author is Yiqiang Chen.