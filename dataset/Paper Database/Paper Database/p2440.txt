INSTITUTE OF PHYSICS PUBLISHING
PHYSICS IN MEDICINE AND BIOLOGY
Phys. Med. Biol. 47 1–20
PII: S0031-9155(02)22526-9
Clinically feasible reconstruction of 3D whole-body
PET/CT data using blurred anatomical labels
Claude Comtat1, Paul E Kinahan2,3, Jeffrey A Fessler4, Thomas Beyer5,
David W Townsend3, Michel Defrise6 and Christian Michel5
1 Service Hospitalier Fr´ed´eric Joliot, Orsay, France
2 Department of Radiology, University of Pittsburgh, Pittsburgh, PA, USA
3 Department of Radiology, University of Washington, Seattle, WA, USA
4 Department of Electrical Engineering and Computer Science, University of Michigan,
Ann Arbor, MI, USA
5 CTI PET Systems Inc., Knoxville, TN, USA
6 Division of Nuclear Medicine, Vrije Universiteit Brussel, AZ-VUB, Brussels, Belgium
E-mail: 
Received 5 March 2001, in ﬁnal form 10 September 2001
Published 29 November 2001
Online at stacks.iop.org/PMB/47/1
We present the results of utilizing aligned anatomical information from CT
images to locally adjust image smoothness during the reconstruction of threedimensional (3D) whole-body positron emission tomography (PET) data. The
ability of whole-body PET imaging to detect malignant neoplasms is becoming
widely recognized. Potentially useful, however, is the role of whole-body PET
in quantitative estimation of tracer uptake. The utility of PET in oncology is
often limited by the high level of statistical noise in the images. Reduction in
noise can be obtained by incorporating a priori image smoothness information
from correlated anatomical information during the reconstruction of PET data.
A combined PET/CT scanner allows the acquisition of accurately aligned
PET and x-ray CT whole-body data. We use the Fourier rebinning algorithm
(FORE) to accurately convert the 3D PET data to two-dimensional (2D) data to
accelerate the image reconstruction process. The 2D datasets are reconstructed
with successive over-relaxation of a penalized weighted least squares (PWLS)
objective function to model the statistics of the acquisition, data corrections,
and rebinning. A 3D voxel label model is presented that incorporates the
anatomical information via the penalty weights of the PWLS objective function.
This combination of FORE + PWLS + labels was developedas it allows for both
reconstruction of 3D whole-body data sets in clinically feasible times and also
the inclusion of anatomical information in such a way that convergence can be
guaranteed. Since mismatches between anatomical (CT) and functional (PET)
data are unavoidable in practice,the labels are ‘blurred’ to reﬂect the uncertainty
associated with the anatomical information. Simulated and experimental results
show the potential advantage of incorporating anatomical information by using
blurred labels to calculate the penalty weights. We conclude that while the
0031-9155/02/010001+20$30.00
© 2002 IOP Publishing Ltd
Printed in the UK
C Comtat et al
effect of this method on detection tasks is complicated and unclear, there is an
improvement on the estimation task.
1. Introduction
The role of whole-body PET imaging with [18F] ﬂuorodeoxyglucose (FDG) in oncology
research and patient care is increasing , and its ability to
detect malignant neoplasms is becoming widely recognized. Potentially useful, however, is
the role of whole-body PET in quantitative estimation of tracer uptake for the purposes of
patient management, including staging, monitoring for the effect of therapeutic interventions
and/or recurrence and for therapy planning.
The utility of whole-body FDG PET scanning, however, is often limited by the high
level of statistical noise in the images. Incorporating a model of the data acquisition statistics
can reduce noise propagation in the reconstructed image, as discussed in the reviews by
Ollinger and Fessler and Leahy and Qi . In addition, several studies have shown
advantages of using aligned anatomical information to guide the reconstruction of PET data
 . In other words, reduction in noise can be obtained by incorporating
a priori image smoothness information from correlated anatomical information during the
reconstruction of the PET data. For thorax or abdomen imaging, however, it is difﬁcult to
accurately align anatomical information with PET data. The combined three-dimensional
(3D) PET/CT scanner resolves the alignment problem by acquiring both
functional (PET) and anatomical (CT) data in a single patient scan. The primary goal of
acquiring accurately aligned PET and CT data is to provide accurate anatomical localization
of the functional data, for example, determining the precise location of a focal point of FDG
accumulation indicative of a malignant neoplasm. The CT data can be acquired as a rapid
post-injection transmission scan and used to correct the PET data for attenuation , which makes the PET/CT scanner ideal for the estimation of tracer uptake
concentration. An additional synergistic combination of the PET and CT data includes using
the CT data for guiding the reconstruction of whole-body PET data, with the goal of reducing
statistical noise, improving quantitation and potentially improving lesion detectability.
The method we currently use clinically (without including anatomical information) to
reduce the effect of statistical noise in the PET images is a combination of Fourier rebinning
(FORE) followed by reconstruction with the accelerated two-dimensional
(2D) ordered-subsets EM reconstruction algorithm (OSEM) developed by Hudson and Larkin
 , or the attenuation weighted OSEM algorithm (AWOSEM) .
In these methods 3D PET data are accurately rebinned to a set of contiguous 2D sinograms
by applying the Fourier rebinning technique (FORE) prior to the iterative reconstruction.
This approach allows reconstruction of 3D PET data in clinically feasible computation
times as the use of rebinning methods signiﬁcantly accelerate image
reconstruction since the back- and forward-projection steps are much less computationally
demanding in 2D than in 3D. The FORE algorithm causes a small spatially varying distortion
of the reconstructed point spread function (PSF) . In whole-body PET
imaging with current scanner geometries, however, the effective image resolution is dominated
by the count-limited statistics, and there is no signiﬁcant difference in image SNR between
FORE + AWOSEM and the more accurate fully-3D AWOSEM .
Reconstruction of 3D PET/CT data with blurred labels
The aim of this paper is to investigate the potential gains in image signal-to-noise ratio by
incorporating the anatomical information derived from aligned CT images in the reconstruction
of 3D whole-body PET data, with the constraint that the technique is routinely useable in a
clinical environment. An important consideration is to retain the fast reconstruction times of
the FORE + OSEM approach. To this end, we combine FORE-rebinning with minimizing a
penalized weighted least-squares (PWLS) cost function. The PWLS algorithm is used, rather
than OSEM or AWOSEM, as it is straightforward to include (i) anatomical information in
such a way that rapid convergence can be guaranteed and (ii) the 3D nature of the regularizing
prior, as described below. The ‘weighting’ in the PWLS includes the statistics of the data
acquisition and processing and the FORE algorithm . The PWLS objective
function used in 2D image reconstruction is given by
+ βU(x; l).
In equation (1), x = {xi | i = 1, . . . , n} is a vector of the n voxel values of the image,
y = {yj | j = 1, . . . , m} are the m projection values, σ = {σj | j = 1, . . . , m} are the
known (or estimated) standard deviations for the projection data, A = {Aji} is the m × n
system matrix such that the expectation value for yj is given by 
i Ajixi. The parameter β
controls the inﬂuence of the quadratic image roughness penalty function, U(x; l), which we
modify to incorporate the 3D anatomical information, termed labels, l = {li | i = 1, . . . , n},
as described in the next section. The images are reconstructed by minimizing (x) while
keeping l constant.
As (x) is a quadratic function it can be readily minimized by the
successive over-relaxation (SOR) algorithm in 10–20 iterations . The PWLS method is based on the assumption that the mean and variance of
the sinogram data are known after the necessary quantitative corrections are applied for effects
such as detector efﬁciency variations, attenuation, and random and scattered coincidences. If
the data are Gaussian distributed, then the PWLS method converges to a maximum-likelihood
estimator. This avoids the complexity of accurately propagating the Poisson distribution of
the raw sinogram data through a data acquisition model, but requires a separate estimate of
the data variance.
In our implementation the 3D PET data are ﬁrst rebinned with FORE to a set of transaxial
2D sinograms. The effects on the sinogram data variance of all correction steps, including
corrections for attenuation, scattered and random coincidences, detector efﬁciencies and the
effect of FORE, are included in σ 2 . To retain the 3D nature of the
patient tracer distribution, the regularizing term U(x; l) is estimated using a 26-voxel threedimensional local neighbourhood of each voxel, as proposed by Mumcuoglu et al .
An important aspect of any reconstruction method that incorporates anatomical a priori
information is the effect of positional and/or signal mismatch between the anatomical and
functional data. We expect some level of positional mismatch between the PET and CT images
due to, for example, respiration or patient movement during the scan. By signal mismatch
we mean that changes in the PET emission distribution are not matched with corresponding
changes in the anatomical image, or vice versa. It is important to emphasize that positional
and signal mismatches are fundamentally different effects, as we have shown below.
There are two types of signal mismatch. The ﬁrst is where a change in the PET emission
distribution is not matched by a correspondingchangein the anatomical image. In other words,
there is no change in the labelling or classiﬁcation of voxels that cross the change in emission
distribution, which corresponds to regularization without using anatomical information. This
is termed a missing label. The second type of signal mismatch is the opposite situation where
a truly uniform emission region has two or more different label sub-regions. The introduction
C Comtat et al
of such false labels can lead to dramatic changes in the noise texture, as illustrated below. Both
types of signal mismatch are known to occur in practice, due to, for example, the heterogeneous
uptake of PET tracers within a single anatomical structure such as a tumour .
Any improvement in task performancewould necessarily depend on the type of study, such
as tracer uptake quantitation versus tumour detection. Estimating the effect on detectability is
complicated by the availability of the aligned CT image. In this paper we do not try to answer
these questions, but rather focus on the estimation task by using simulations to investigate
changes in root mean square (RMS) errors and contrast/noise trade-offs by incorporating
CT anatomical information into the PET reconstruction.
This is done by modifying the
regularizing term, U(x; l), and comparing the results to the standard PWLS method . Simulation studies allow the mean and
standard deviation images to be estimated from multiple independent realizations. The effects
of both positional and signal mismatches between the PET and CT data, which are unavoidable
in practice, are also evaluated. We also evaluate a ‘blurred label’ method (described in the next
section) of including the CT data in U(x; l) that attempts to reduce the deleterious effects of
mismatches between the PET and CT data. Finally, we demonstrate the efﬁcacy of the blurred
labels method with experimental phantom data obtained from the PET/CT scanner.
2. Inclusion of anatomical information
To include anatomical information we modify the regularizing term, U(x; l), which is a
quadratic roughness penalty based on a 3D voxel neighbourhood (N3D) consisting of a voxel’s
26 closest neighbours. The penalty is deﬁned by:
U(x; l) = 1
where dik is the Euclidean distance between voxels i and k, and the penalty weights, ωik(l), are
derived from the anatomical data by using voxel labels, l. Voxel labels have previously been
used to incorporateanatomical information into emission tomographyreconstruction . In this approach two quantities are associated with an image voxel: the estimated
emission density and the class of material to which it belongs (e.g. lung, bone, or soft tissue).
In the present paper we deﬁne binary penalty weights with ωik set to one if both voxels i and k
belong to the same class and to zero otherwise. We refer to this as the binary label method.
In other words, at the boundary between voxels with different labels it is assumed that there is
a potential change in the underlying tracer concentration. In this case no smoothing is applied
between these voxels, allowing preservation of the edge in the tracer concentration image.
With the use of an edge-preserving penalty function (equation (2)), the smoothing parameter,
β (equation (1)), can be increased to reduce statistical noise in areas that are assumed to be
smoothly varying or uniform, without any blurring of the edges.
The use of binary penalty weights, however, may introduce unacceptable artefacts if
there are mismatches between the anatomical and functional images. Alternative methods
of including anatomical prior information include the joint estimation approach used with
the ‘line-site’ method proposed by Geman and Geman , where the line-sites reﬂect the
boundaries between voxels in the emission image. The use of anatomical a priori information,
such as CT or MRI images, to ‘guide’ the positions of emission boundaries, estimated jointly
with the emission distribution, has been investigated by Leahy and Yan , Gindi et al
 , and Bowsher et al and others. Joint estimation can thus potentially compensate
for alignment errors , as the ﬁxed anatomical a priori information is not
used to force the position of functional boundaries, but rather is combined with the PET
Reconstruction of 3D PET/CT data with blurred labels
emission data to determine the boundary locations. Joint estimation of the anatomical and
functional data has also been proposed . These methods are computationally
intensive in the 2D image reconstruction and are currently not suitable for routine clinical
processing, particularly for 3D whole-body PET imaging. In addition, the use of a full set of
3D regular and diagonal ‘plane’ sites between voxels for the 3D penalty term, U(x; l), would
lead to complex book-keeping. Rather than compensating for positional or signal mismatch, a
simpler (non-Bayesian) but less precise alternative consists of degrading the resolution of the
anatomical information before incorporation into the PET image reconstruction as proposed
by Fessler et al in his 2D blurred weight method. This has the effect of reducing
the deleterious effects of anatomical/functional mismatches, but at the same time limits the
maximum achievable accuracy (e.g. resolution recovery) that can be obtained by using the
anatomical information.
In contrast, Bayesian approaches can potentially utilize the full
accuracy of the anatomical information while also circumventing the problems introduced by
anatomical and functional mismatches , albeit at the cost
of increased computation time.
In the blurred weight method the binary penalty weights used for reconstructing an image
plane are smoothed with a 2D kernel whose width corresponds to the uncertainty in the
anatomical information. We have developed and implemented a 3D extension of the blurred
weight method that we refer to as the 3D blurred label method that is useable with any 3D
topology. In our implementation, rather than smoothing the binary weights ωik, we introduce
an intermediate representation of 3D object labels, which are smoothed. The penalty weights
in equation 2 are then derived from the blurred labels, as described next.
In the blurred label method, 3D label maps lc = {lic|i = 1, . . ., n; 0 ⩽lic ⩽1} are
deﬁned for each class (or label) c of the C classes of material. An example with C = 5 could
be c = 1 for voxels in the lung region, c = 2 for soft tissue, c = 3 for bone, c = 4 for outside the
body and c = 5 for voxels of unknown type. In this case l1 = {li1|i = 1, . . . , n; 0 ⩽li1 ⩽1}
is an image or support map of the lung, that is li1 = 1 if voxel i is considered to be in the
lung, and is li1 = 0 if not. The label maps are initialized with mutually exclusive binary
values (only one label is associated with each voxel) according to the CT image segmented
into the C classes. Each label map is then blurred with the same 3D Gaussian kernel whose
width corresponds to the PET–CT alignment accuracy. Thus, before and after smoothing the
labels satisfy the relationship 
c=1,C lic = 1, for every voxel i. The labels, with or without
smoothing, are used to deﬁne the penalty weights between voxels as
c=1 liklkc
which have the desirable properties that 0 ⩽ωik ⩽1 and ωik = ωki. If ωik = 1 (from the
anatomical data) then voxels i and k are assumed to be related functionally in some sense and
the full amount of smoothing, as determined by β in equation (1), is applied. If ωik < 1 then
voxels i and k are considered less likely to be related functionally and a reduced level of local
smoothing is imposed. If ωik = 0, no roughness penalty is imposed between voxels i and k.
Note that in the case of unsmoothed labels, the weights are binary, with ωik = 0 or 1, which
we deﬁne as the binary labels method. For the case of no labels, ωik = 1 for all voxels i and
k, and we return to the PWLS algorithm.
Initial anatomical classiﬁcation of the voxels can be obtained by segmenting the CT image
with thresholding or statistical methods, such as described by Karssemeijer . For the
studies reported here, the voxel labeling was accomplished with simple thresholding. The CT
image planes are 512 × 512, compared to 128 × 128 for PET, for the same ﬁeld of view of
∼50 cm. To convert the anatomical information to the larger PET voxel size, we set the label
of the PET voxel to that of the majority of the CT sub-voxels. Other initialization methods
C Comtat et al
Figure 1. Emission distribution and label maps used for simulation studies. From left to right:
(a) emission distribution (contrast varies with diameter), (b) original label map, (c) shifted label
map, and (d) subtraction of original and shifted labels showing the different directions of the label
can be envisaged, however, such as setting lic to the fraction of the sub-voxels belonging to
tissue class c. We note that since ωik are ﬁxed, (x) (equation (1)) is still a convex quadratic
objective function and so convergence to a unique minimum solution is guaranteed.
3. Methods
3.1. Simulation studies
The simulation studies use a technique that allows us to generate multiple realizations of
3D sinogram datasets in a feasible computing time . We do not simulate the detection of individual true, random and scattered
coincidences, as is done with Monte Carlo methods, but rather simulate their effect on the
noise of the emission data. We assume that the measured data are accurately corrected for
attenuation and random and scattered coincidences. With the exception of the noiseless 2D
simulation, all simulations with statistical noise were performed in 3D and reconstructed with
FORE + PWLS. For each of these volume images, only the central transverse image plane
is displayed. In all simulation studies two label classes were used: one for the cylinder
background and one for the embedded discs.
3.1.1. Noiseless 2D data.
We ﬁrst investigated the effect of accurate and mismatched labels
in a noiseless 128 × 128 (2D only) simulation. The simulation was of a large uniform disc
(30-pixel diameter) with a smaller disc (2-pixel diameter) in the centre. The 2D image was
reconstructed with a ﬁxed β and the following variations of the labels and penalty weights:
(i) no labels, (ii) correct binary labels, (iii) correct blurred labels, (iv) shifted binary labels,
and (v) shifted blurred labels.
3.1.2. Noisy 3D data.
A large uniform cylinder (30 cm diameter) with six embedded smaller
discs of different sizes and contrast levels was the basis for 100 realizations with added
statistical noise. Figure 1 shows the original object and the corresponding labels.
The size of the contrast discs ranged from 1 to 6 cm in diameter and were chosen such
that the disc area approximately doubled for each increase in diameter. The contrast levels of
the discs varied inversely with area, as proposed by Furuie et al , with the smallest disc
having the maximum contrast level of 2.25 relative to the uniform disc. The inverse variation
of contrast with area results in the integrated contrast for each object being the same.
The statistical noise level was set to correspond to a total of 2 × 107 coincident events
(5.5 × 106 true coincidences, 4.5 × 106 scattered coincidences and 10 × 106 random
coincidences), typical of the detected counts (before data corrections) in a 10 min clinical scan
Reconstruction of 3D PET/CT data with blurred labels
with the PET/CT scanner. The effects of random and scattered coincidences and attenuation
correction were included, with the attenuation coefﬁcient of all objects set to that of water.
Simulation studies were performed for three conditions:
1. with accurate alignment;
2. with the labels of the six contrast discs shifted, in different directions, by 5 mm relative
to the true source distribution using the displacements shown in ﬁgure 1(d);
3. with the emission source distribution set to a uniform activity distribution, but with the
(un-shifted) labels still included as ‘false’ labels.
For each of the three-label variations (accurate, shifted and false), the 100 realizations were
reconstructed with ﬁve different types of penalty weights:
1. no labels (ωik = 1);
2. binary labels (ωik = 0 or 1);
3–5. blurred labels (0 ⩽ωik ⩽1), smoothed with a Gaussian kernel of FWHM 4.0, 5.0 and
The images were reconstructed with a set of image smoothness parameters (β in equation (2))
that, when used with PWLS, roughly matched the range of cut-off frequencies used with
standard ﬁltered-backprojection in clinical imaging .
For each of the combinations of reconstruction parameters, voxel-wise mean and standard
deviation images were calculated from the N = 100 realizations. Additionally, 2D region of
interest (ROI) ﬁgures of merit were calculated for each of the i = 1, . . ., 6 objects: the mean
estimated bias, the standard deviation and the RMS error.
Mean estimated bias: bi, of object i, is given by
i is the true contrast for object i. The mean contrast for each object is given by
The contrast for each realization of each object is given by
Cij = ¯Rij −B
where B is the true background activity and ¯Rij is the mean ROI value of object i for realization
j, j = 1, . . ., N.
Standard deviation: si, of object i, is given by
where the object and background variances are given by
( ¯Ci −Cij)2
 ¯RBi −¯RBij
with mean background
Here, ¯RBij is the mean ROI value in a background region of the same size as object i. The
standard deviation ﬁgure of merit was chosen to include the effect of background noise, which
C Comtat et al
can be substantially affected by the use of anatomical a priori information, as changes in the
background noise can inﬂuence detection tasks.
The location and size of the ROIs for the mean estimated bias and the standard deviation
coincide with the true object and their locations were the same for all three cases of accurate
labels, shifted labels and false labels . The mean estimated bias and standard deviation were
plotted for each object as a function of the smoothness parameter, β, and for each of the ﬁve
types of penalty weights listed above.
RMS error: RMSi, of object i, is given by
(xj,k −tk)2
where xj,k is the value of voxel k for realization j and tk is the true voxel value. Because the use
of labels modiﬁes the voxel values not only within, but also around the object i, the summation
of the squared difference (xj,k −tk)2 was taken over the voxels k within a circular ROI centered
on the true location of object i and with a radius 1 cm larger than the object radius. The RMS
errors were plotted as a function of the smoothness parameter, β, for four types of penalty
weights (no labels, binary labels and labels blurred with a kernel FWHM of 5 and 7.5 mm).
3.2. Experimental studies
To evaluate the efﬁcacy of the blurred label method in practice, we acquired CT and aqueous
[18F] PET scans of a 30 cm (major axis) elliptical torso phantom in the PET/CT scanner. The
phantom had a series of hot and cold contrast spheres, each of which also contained a dilute
iodine-based CT contrast agent to aid the segmentation process. The volume of the spheres
ranged from 1 to 15 ml. The CT scan was acquired in a spiral mode, with an axial motion of
3 mm per scanner rotation and the images were reconstructed with a 3.4 mm axial spacing to
match that of the PET images. The PET scan, with a deadtime of 5% and random coincidence
fraction of 20%, collected ∼107 coincidences to match a typical 10 min clinical scan.
PrecisealignmentofthePETand CTimageswasobtained with two calibration procedures.
In the ﬁrst procedurean array of parallel 18-gaugesteel needles (<0.5 mm diameter) ﬁlled with
aqueous[18F] solution was scanned in both CT and PET mode. From the reconstructed images
a precise determination of the pixel size of each modality was made. The residual translation
and rotation offsets in the transverse plane between modalities was also measured. For the
second procedure, an array of four-point sources (each ∼1.5 mm diameter) was attached to
the top of the torso phantom by means of glass capillary tubes (∼0.5 mm diameter). The point
sources were scanned in CT mode with a 1 mm axial spacing. From the reconstructed PET
and CT images the precise axial offset and out-of-plane rotation of the torso phantom was
Finally the CT image of the torso phantom was re-sampled to correct for the residual
PET-CT alignment errors, converted to voxel labels as described above and incorporated in
the PET image reconstruction according to equations (1)–(3).
4. Results
4.1. Simulation studies
4.1.1. Noiseless 2D data.
Figure 2 shows the noiseless 2D test object and the horizontal
proﬁles through the reconstructed images for the ﬁve different combinations of labels and
reconstruction methods described above in section 3.1.1. Figure 2(i) shows a typical loss of
Reconstruction of 3D PET/CT data with blurred labels
Binary labels
Shifted binary labels
Shifted binary labels
Blurred labels
Blurred labels
Shifted blurred labels
Shifted blurred labels
Figure 2. The noiseless test object and horizontal proﬁles through the reconstructed PET emission
images using PWLS with ﬁve different combinations of labels and penalty terms: (i) no labels,
(ii) correct labels with binary weights, (iii) correct labels with blurred weights, (iv) shifted labels
with binary weights, and (v) shifted labels with blurred weights. For the later graph (v), to the
blurred weights proﬁle drawn in bold, the binary weights proﬁle (iv) is superposed. All ﬁve PWLS
reconstructions were performed with the same image smoothness parameter β. For comparison,
the horizontal proﬁle through the original (simulated) object is shown with a dashed line in each
resolution due to regularization, while the inclusion of binary labels in ﬁgure 2(ii) allows for
near-perfect contrast recovery. The use of blurred label maps (ﬁgure 2(iii)) results in a small
loss in contrast recovery, as expected. When mispositioned labels are used, the reconstructed
image is distorted (ﬁgure 2(iv)), which is marginally mitigated by the use of blurred labels
(ﬁgure 2(v), indicated by the bold proﬁle with reduced over- and undershoot around pixel
12 and 26).
4.1.2. Noisy 3D data.
Two of the 100 realizations are shown in ﬁgure 3 for the three cases
of: no labels, binary labels and blurred labels (FWHM of 5 mm). The corresponding mean
and standard deviation images are shown in ﬁgure 4 for each of the three label combinations.
For comparison, the individual realizations and the mean images shown below are scaled to
the same maximum and minimum display range as the original object shown in ﬁgure 1(a).
Figure 4 illustrates increased contrast recovery when binary labels are used. The noise also
increases, particularly around the edges of the contrast objects, as expected for an edgepreserving prior.
The use of blurred labels results in contrast recovery and noise levels
that lie between the cases of no labels and binary labels. The measured noise levels are
shown in ﬁgure 5, which plots the standard deviation, s, (equation (7)), relative to the no
labels case, as a function of the object size. The relative standard deviations are given for
two representative amounts of smoothing, as controlled by the regularization parameter β in
equation (1).
The results from simulating the case where there is a 5 mm positioning error are shown
in ﬁgures 6 and 7 for the same image smoothness parameter. Figure 6 shows the mean and
standard deviation images for reconstructions with binary labels and blurred labels (FWHM
C Comtat et al
Realization A:
Realization B:
Binary labels
Blurred labels
Figure 3. Reconstructions of two representative realizations of the 100 simulations with accurate
labels. The top and bottom rows are the two independent realizations, while the columns are, from
left to right, images reconstructed with: no labels, binary labels and blurred labels.
Binary labels
Blurred labels
Figure 4. Mean and standard deviation images of the 100 realizations of simulations with accurate
labels. Top row: mean images. Bottom row: standard deviation images. The columns correspond
to ﬁgure 3 and are, from left to right: no labels, binary labels and blurred labels.
of 5 mm). Images reconstructed without labels are identical to those shown in ﬁgure 4. Also
indicated is the location of the proﬁles plotted in ﬁgure 7 for the original and shifted labels.
Figure 7 shows that when binary labels are used, mis-positioning of the label essentially results
in mis-positioning of the corresponding objects in the emission image, similar to ﬁgure 2(iv).
The use of blurred labels mitigates this distortion, but at the cost of reduced contrast
The bias (equation (4)) versus standard deviation (equation (7)) curves were plotted for all
combinations of label type and image smoothness parameter β, for both accurate and shifted
labels. The results for all the objects varied gradually according to the size of the object and
β, so only representative results are shown in ﬁgure 8 for the 15 and 40 mm diameter objects,
shown at the top of ﬁgure 1(a). These plots show that the use of accurate labels improves
noise/contrast trade-off, with the amount of improvement increasing with object diameter.
The use of mispositioned labels, however, yields results that are equivalent to not using labels
Reconstruction of 3D PET/CT data with blurred labels
Spot diameter [mm]
Spot diameter [mm]
Relative Std. Dev.
log2( )=-19
Binary labels
Blurred labels (fwhm = 5 mm)
Blurred labels (fwhm = 7.5 mm)
Figure 5. Ensemble standard deviation of ROI mean values relative to that for the reconstruction
without labels. These are shown as a function of the diameter of the six labels for two different
levels of regularization. The left plot, with β = 2−16 in equation (1), corresponds to increased
regularization or image smoothness compared to the right plot, where β = 2−19.
Binary labels
Blurred labels
Figure 6. Mean and standard deviation images of the 100 reconstructed images with shifted labels.
Top row: mean images. Bottom row: standard deviation images. The columns are, left: binary
labels, right: blurred labels. Also indicated is the location of the proﬁles plotted in ﬁgure 7.
at all. Figure 8 also indicates the complex relation between the width of the kernel used to
blur the labels and the regularization parameter, β. As either β or the kernel width increase,
the noise is reduced and the bias increases.
The RMS error (equation (10)) curves were calculated over a wide range of the image
smoothness parameter β to see the asymptotic RMS values corresponding to the case of no
penalization (log2(β) < −30) and to the case of almost ‘full’ penalization (log2(β) > −6).
Typical values that match the range of cutoff frequencies used with ﬁltered-backprojection in
clinical imaging are −20 ⩽log2(β) ⩽−14 . The results are shown in
ﬁgure 9 for the three smallest objects (diameters from 10 to 20 mm). As expected, when β
tends to zero (log2(β) < −30), the regularization has almost no effect and the RMS errors
are the same regardless of the type of penalty weight. At the other extreme (log2(β) > −6),
C Comtat et al
PWLS with binary labels
PWLS with binary labels
PWLS with binary labels
Aligned labels
Shifted labels
PWLS with blurred labels, fwhm=5mm
PWLS with blurred labels, fwhm=5mm
PWLS with blurred labels, fwhm=5mm
Figure 7. Line proﬁles corresponding to ﬁgure 6 showing the effect of shifted labels. Left: Original
(true) and 5 mm positional shift of labels. Effect on images reconstructed using labels: binary
labels (centre), blurred labels (right). Note the change in vertical scales and that the horizontal axis
is in units of reconstructed image pixels. The true image proﬁle is also shown for reference.
Aligned labels
Spot diameter = 15 mm
5 mm shifted labels
Std. Dev. (si)
Spot diameter = 15 mm
Aligned labels
Spot diameter = 40 mm
5 mm shifted labels
Std. Dev. (si)
Spot diameter = 40 mm
Binary labels
Blurred labels (fwhm = 4 mm)
Blurred labels (fwhm = 5 mm)
Blurred labels (fwhm = 7.5 mm)
Figure 8. Standard deviation (si) versus bias (bi) graphs for both accurate and shifted labels for
the top two contrast objects in ﬁgure 1(a) as a function of the regularization parameter and type of
penalty weight.
for aligned labels, the use of binary labels results in a lower asymptotic RMS value. For the
5 mm shifted labels, for the same image smoothness parameter β, the RMS error is increased
relative to the use of aligned labels.
For typical values of the image smoothness parameter β(−20 ⩽log2(β) ⩽−14), the
use of binary labels, even perfectly aligned, results in some RMS values higher than those
without using labels. Table 1 summarizes the RMS error values for the image smoothness
parameter β that minimizes the RMS value without labels (RMSMIN). For the 5 mm shifted
labels, the RMS values for the binary labels are always higher than RMSMIN, while the RMS
values for the blurred labels are slightly lower.
The effect of false labels is demonstrated in the two realizations shown in ﬁgure 10 and
the mean and standard deviation images shown in ﬁgure 11. The relative standard deviations
Reconstruction of 3D PET/CT data with blurred labels
Aligned labels
Spot diameter = 10 mm
5 mm shifted labels
Spot diameter = 10 mm
Aligned labels
Spot diameter = 15 mm
5 mm shifted labels
Spot diameter = 15 mm
Aligned labels
Spot diameter = 20 mm
5 mm shifted labels
Spot diameter = 20 mm
Binary labels
Blurred labels (fwhm = 5 mm)
Blurred labels (fwhm = 7.5 mm)
Figure 9. RMS error versus image smoothness parameter β for the three smallest objects in
ﬁgure 1(a), for both accurate (left) and shifted (right) labels.
for the case of false labels were essentially identical to those shown in ﬁgure 5, indicating
that while false labels do not add bias, they substantially increase variance for the regions
associated with the false labels. The effect of false labels could thus lead to false-positives for
the detection task, as indicated by ﬁgure 10. It is interesting to note the similarity between the
standard deviation images in ﬁgures 6(true labels) and 11 (false labels) while the corresponding
mean images show the lack of bias in both cases.
4.2. Experimental studies
The needle sources measured in PET and CT showed that the voxel dimensions differed by
1.8% throughout the ﬁeld of view. There was a residual in-plane rotational offset of 0.5◦but
no residual transverse shift or out-of-plane rotation between modalities. By inspection of the
overlaid PET and CT images of the needle and point source arrays, the ﬁnal image alignment
C Comtat et al
Table 1. RMS error values for the three smallest object in ﬁgure 1(a). The image smoothness
parameter β that minimizes the RMS in absence of labels (‘no label’ column) was selected for
each object. For this parameter, the RMS is reported for three different types of labels, with both
accurate and shifted labels.
Blurred labels
Blurred labels
Binary labels
FWHM = 5 mm
FWHM = 7.5 mm
Spot diameter
log2(β) No labels
5 mm shift
5 mm shift
5 mm shift
Realization C:
Realization D:
Binary labels
Blurred labels
Figure 10. Effect of false labels. Two realizations from simulations with false labels and a uniform
emission distribution. The top and bottom rows are independent realizations, while the columns
are, from left to right: no labels, binary labels and blurred labels.
Binary labels
Blurred labels
Figure 11. Mean and standard deviation images of the 100 realizations of simulations with false
labels. Top row: mean images. Bottom row: standard deviation images. The columns correspond
to ﬁgure 10 and are, from left to right: no labels, binary labels and blurred labels.
Reconstruction of 3D PET/CT data with blurred labels
Transverse
PET (no labels)
Fused PET/CT
Figure 12. Transverse and coronal sections through the CT and fused (overlaid) PET/CT volume
images of the torso phantom showing the location of the seven contrast spheres (one is in the right
lung region). The object at the top of the CT transverse section is a small post taped to the inside of
the phantom and the dark spots are trapped air bubbles. The PET image was reconstructed without
anatomical information.
Profile location
Binary labels
Blurred labels
Figure 13. Transverse sections through reconstructed volume images of the measured 3D phantom
(with β = 2−15) showing four hot contrast objects and three cold contrast objects.
accuracy after correcting for the voxel-scaling difference and residual rotation offset was
estimated to be <2 mm throughout the ﬁeld of view. Figure 12 shows the transverse and
frontal sections through the reconstructed CT and PET volume images and the fused PET/CT
volume image.
Transverse sections through the reconstructed volume PET images are shown in ﬁgure 13.
Representative images are shown for penalty weights based on the three cases of no labels,
binary labels, and blurred labels.
The image reconstructed with binary labels clearly
demonstrates improved contrast for the smaller hot and cold spheres, while the use of the
blurred labels results in contrast levels in between those obtained with and without binary
labels. Proﬁles through the reconstructed images are displayed in ﬁgure 14, demonstrating
the improved contrast with the use of binary and blurred labels.
The processing time for the FORE-rebinning, the PWLS and PWLS + labels
reconstructions given separately in table 2. For reference, the reconstruction time using 2D
ﬁltered-backprojection (FBP) is also given. Comparisons of images reconstructed (without
anatomical a priori information), by FORE + FBP, and the combinations of FORE + PWLS,
FORE + OSEM, and FORE + AWOSEM, were discussed by Comtat et al .
C Comtat et al
Figure 14. Proﬁles through the images of ﬁgure 13 showing the effect of including anatomical
information with measured data. Solid line: no labels, dotted line: binary labels, dashed line:
blurred labels.
Table 2. Computation time of the FORE + PWLS reconstruction method on a Sun Blade 1000
workstation, the for one-bed position of the PET/CT scanner (47 image planes). For purposes of
comparison, we also reported the computation time of 2D-FBP .
Computation time (s)
PWLS, 30 iterations, no labels
PWLS, 30 iterations, binary labels
PWLS, 30 iterations, blurred labels
5. Discussion and conclusions
As mentioned in section 1, our goal was not necessarily to develop a method that includes
anatomical a priori information more accurately than existing methods , but rather to develop a method that would (i) reconstruct
3D multi-bed data in clinically feasible time (achieved with the FORE and SOR algorithms,
as shown in table 2), (ii) include a reasonably accurate model of the positron imaging statistics
(achieved by estimating the data variance) (iii) converge (achieved by using ﬁxed weights in
the penalty function), and (iv) introduce few free parameters (achieved by only allowing the
width of the blurring kernel as a free parameter).
To utilize anatomical (CT) information in the functional (PET) image reconstruction we
presented a 3D voxel label model that can accommodate any 3D voxel labeling topology.
This information is incorporated anatomical information via the penalty weights of the PWLS
objective function. This combination of FORE + PWLS + labels was developed as it allows for
both reconstruction of 3D whole-body datasets in clinically feasible times and also inclusion
of anatomical information in such a way that convergence can be guaranteed.
To reduce the deleterious effects of mismatches between the PET and CT data, the
anatomical labels derived fromtheCT data are blurred by a pre-speciﬁed amount corresponding
Reconstruction of 3D PET/CT data with blurred labels
to the alignment accuracy. The blurred label information is not updated during the PET image
reconstruction.
An alternative approach to that taken here is to estimate the anatomical
boundaries jointly with emission distribution, with the CT or MRI image used to ‘guide’
estimated positions of functional boundaries . Joint estimation can potentially compensatefor alignment errors ,
and can be incorporated into the blurred label approach. This could be done by, for example,
re-estimating the label maps at pre-determined iterations ofthe PET imagereconstruction using
both the CT image and the current PET image. With the joint estimation methods mentioned
above, Bayesian modelling of the prior probability of the anatomical and functional boundaries
can allow for more accurate alignment. These techniques can thus potentially circumvent the
problems introduced by anatomical and functional mismatches , albeit at the cost of increased computation time. In addition, the use of variable
weights ωik can lead to a non-convex penalty function and so global convergence would
no longer be assured unless more sophisticated estimation methods are used. Keeping the
anatomical information ﬁxed, however, while estimating the PET image leads to a simpler and
faster procedure with fewer free parameters to be pre-speciﬁed, a consideration important for
the methods intended for routine clinical use, particularly with 3D whole-body PET scanning.
But this simplicity has a price: to allow for mismatches, the overall quality of the anatomical
information is degraded by the use of ﬁxed blurred labels, limiting the maximum achievable
accuracy in the PET image that can be obtained, while Bayesian joint-estimation methods
can potentially recover from mismatches and thus retain, at least locally, the original quality
of the anatomical information. If rapidity and simplicity are not a critical issue, or with
sufﬁcient processing speed, the use of Bayesian joint-estimation methods could utilize the full
accuracy of the anatomical information in the PET image reconstruction, even if (i) there is
an alignment error between the CT and PET data (positional mismatch) or (ii) if there is a true
object boundary present in the PET data that is not present in the CT data (signal mismatch).
The latter situation can arise in oncology imaging for tumours with heterogeneous uptake and
uniform tissue density. It is thus possible that both estimation and detection tasks could be
improved with a carefully chosen Bayesian joint-estimation method, relative to the use of the
blurred labels method described here. However, the reliability of Bayesian joint-estimation
methods with the low count levels typical of clinical 3D whole-body PET imaging has not
been investigated, as most implementationshave been tested with the signiﬁcantly highercount
levels encountered in PET brain imaging studies. In our investigation we did not compare the
blurred label method with fully 3D implementations of the alternative approaches of including
anatomical a priori information mentioned above, but rather relied on our comparisons with
the standard PWLS method to demonstrate the efﬁcacy of the blurred label approach for
clinical 3D whole-body PET imaging.
Some of the potential advantages and problems of including anatomical information are
apparent in ﬁgure 2. With accurate alignment, near-perfect contrast recovery is obtained for
these simple (piecewise-constant) objects. With the use of binary labels, however, a positional
mismatch distorts the reconstructed object as shown by ﬁgures 2 and 7. Label maps blurred
with a one-pixel Gaussian kernel (FWHM) reduce edge artefacts while also retaining a better
contrast than the PWLS reconstruction without anatomical information.
For the simulations with statistical noise the improvements in the noise-bias trade-offs
were more apparent for the larger objects (ﬁgure 8) even though they had a lower contrast and
varied with the type of anatomical label used. In general, the use of binary labels resulted
in a dramatic increase in variance, which was reduced by blurring the label maps (ﬁgures 4,
5 and 8). Even with accurate labels, the RMS error can be increased by the use of binary
labels (ﬁgure 9 and table 1) for values of β that match the range of cut-off frequencies used
C Comtat et al
with ﬁltered-backprojection in clinical imaging . The RMS error ﬁgure of
merit accounts not only for bias in the image, but also for noise. With binary labels, image
variance also increases in the neighbourhood of the label boundaries (ﬁgure 4); this effect
counterbalances the decreased bias.
Although we are interested in improving the estimation by including anatomical a priori
information, we can also consider the effects on detection. One potential pitfall of including
anatomical information is the temptation to over-smooth images to improve the contrast. In
the presence of signal mismatches this may lead to increased false-positive detection rates
(due to false labels) and/or false-negative detection rates (due to missing labels). This is
anecdotally illustrated in ﬁgure 3 for missing labels (the ‘no labels’ case) and ﬁgure 10 for
false labels. These effects are more dramatic for the false labels case when binary labels are
used, rather than blurred labels, as shown by the standard deviation images in ﬁgure 11. The
use of blurred labels reduced, but did not eliminate the variance in the regions of the false
labels. Not surprisingly, the standard deviation images in the cases of accurate and false labels
were very similar. The appearance of false-positive and/or false-negative objects (ﬁgures 3
and 10) are speciﬁc to the parameters of the study. In the case of a positional mismatch it
is difﬁcult to make any conclusions on the effect of labels for the detection task. The plots
in ﬁgures 8 and 9 show that the use of accurate labels improves noise/contrast trade-offs and
reduces RMS error, while mis-positioned labels yield results that are roughly equivalent to not
using labels at all. The reasons for this are not clear, but it may be that mis-positioning the
labels is somehow equivalent to over-smoothing the images. The use of labels, however, in
the case of a positioning mismatch, does not lead to an increase in bias relative to not using
labels; an important consideration for quantitation tasks.
Even with observer ROC studies it is not obvious what task performance should be
measured. For example, in the case of a positional mismatch where detection is improved at
the expense of a localization error, it is not clear if this should be considered an improvement
or not as the PET image (reconstructed with labels) could be used for lesion detection, while
the CT image is used for localization. Other variations are possible and these questions cannot
be answered until considerably more experience is gained with combined PET/CT studies.
For the estimation task, in the case where the labels were shifted by 5 mm (one pixel)
from the true emission contrast regions, there was a reduction in image contrast, as shown by
comparing the mean images in ﬁgures 4 and 6. In addition, there was a shift in the apparent
centroid of the objects that corresponded to the shift in the label locations, as shown in ﬁgure 7.
There was also a signiﬁcant reduction in ROI variance. The net effect is shown in ﬁgure 8
for two of the objects, indicating that a 5 mm shift is sufﬁcient to remove any advantage of
using anatomical information in terms of contrast/noise trade-off. We note, however, that this
amount of label misalignment does not degrade the noise-bias performance relative to PWLS
without anatomical information.
The experimental studies, which had an alignment accuracy of better than 2 mm, indicate
that the use of both binary and blurred labels leads to improved contrast for the hot and cold
contrast objects of all sizes, as illustrated in ﬁgure 13. It should be noted, however, that both
the experimental and simulated phantoms are piece-wise continuous objects and are ideally
suited for this type of reconstruction method. It may be, in practice, that methods favouring
piece-wise-linear objects, such as those proposed by Lee et al , provide more accurate
reconstructions. It should be emphasized that the blurred labels method is not a substitute for
the Bayesian joint functional/anatomical estimation methods proposed in the literature, but
rather a simpler and faster, but potentially less precise, alternative for clinically feasible 3D
whole-body PET imaging with a PET/CT scanner.
Reconstruction of 3D PET/CT data with blurred labels
In summary, PET/CT tomographs, by directly acquiring aligned PET and CT data, offer
the possibility of using anatomical information to guide the reconstruction of whole-body PET
data. With mismatches between the PET and CT data, the effects on detection or estimation
tasks should be considered separately. For detection tasks, signal mismatches will likely
increase the false-positive and/or false-negative detection rates, depending on the type of
mismatch, although the increased variance introduced by the false labels can be reduced by
the use of blurred labels. The effect of positional mismatches is difﬁcult to evaluate in a realistic
manner. For estimation procedures with either positional or signal mismatches, the use of
blurred labels appears to lead to a performance no worse than that of images reconstructed
without anatomical information. With accurate PET-CT alignment, the use of anatomical
labels improves the RMS error and bias–variance trade-off relative to images reconstructed
without anatomical information. In this case the performancefor both detection and estimation
tasks will likely be improved.
Acknowledgments
This work is supported by a grant from the Swiss National Science Foundation and NIH grants
CA74135 and CA65856.