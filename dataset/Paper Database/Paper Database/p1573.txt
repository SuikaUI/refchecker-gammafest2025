A Support Vector Method for Multivariate Performance Measures
Thorsten Joachims
 
Cornell University, Dept. of Computer Science, 4153 Upson Hall, Ithaca, NY 14853 USA
Method for optimizing multivariate nonlinear performance measures like the F1score. Taking a multivariate prediction approach, we give an algorithm with which such
multivariate SVMs can be trained in polynomial time for large classes of potentially
non-linear performance measures, in particular ROCArea and all measures that can be
computed from the contingency table. The
conventional classiﬁcation SVM arises as a
special case of our method.
1. Introduction
Depending on the application, measuring the success
of a learning algorithm requires application speciﬁc
performance measures. In text classiﬁcation, for example, F1-Score and Precision/Recall Breakeven Point
(PRBEP) are used to evaluate classiﬁer performance
while error rate is not suitable due to a large imbalance between positive and negative examples. However, most learning methods optimize error rate, not
the application speciﬁc performance measure, which is
likely to produce suboptimal results. How can we learn
rules that optimize measures other than error rate?
Current approaches that address this problem fall into
three categories.
Approaches of the ﬁrst type aim
to produce accurate estimates of the probabilities of
class membership of each example ). While based on these
probabilities many performance measures can be (approximately) optimized , estimating the
probabilities accurately is a diﬃcult problem and arguably harder than the original problem of optimizing the particular performance measure.
class of approaches circumvents this problem by op-
Appearing in Proceedings of the 22 nd International Conference on Machine Learning, Bonn, Germany, 2005. Copyright 2005 by the author(s)/owner(s).
timizing many diﬀerent variants of convenient and
tractable performance measures, aiming to ﬁnd one
that performs well for the application speciﬁc performance measure after post-processing the resulting
model ). However, in particular for non-linear performance measures like F1score or PRBEP, the relationship to tractable measures is at best approximate and requires extensive
search via cross-validation. The ﬁnal category of approaches aims to directly optimize the application speciﬁc performance measure.
Such methods exist for
some linear measures. In particular, most learning algorithms can be extended to incorporate unbalanced
misclassiﬁcation costs via linear loss functions in the context of
SVMs). Also, methods for optimizing ROCArea have
been proposed in the area of decision trees , neural networks , boosting , and SVMs . However, for non-linear performance measures like F1-score, the few previous attempts towards their direct optimization noted their
computational diﬃculty .
In this paper, we present a Support Vector Method
that can directly optimize a large class of performance
measures like F1-score, Precision/Recall Breakeven
Point (PRBEP), Precision at k (Prec@k), and ROC-
Area. One diﬃculty common to most application speciﬁc performance measures is their non-linear and multivariate nature. This results in decision theoretic risks
that no longer decompose into expectations over individual examples. To accommodate this problem, we
propose an approach that is fundamentally diﬀerent
from most conventional learning algorithms: instead
of learning a univariate rule that predicts the label
of a single example, we formulate the learning problem as a multivariate prediction of all examples in the
dataset. Based on the sparse approximation algorithm
for structural SVMs , we
propose a method with which the training problem
can be solved in polynomial time. We show that the
A Support Vector Method for Multivariate Performance Measures
method applies to any performance measure that can
be computed from the contingency table, as well as to
the optimization of ROCArea. The new method can
be thought of as a direct generalization of classiﬁcation
SVMs, and we show that the conventional classiﬁcation SVM arises as a special case when using error rate
as the performance measure. We present experiments
that compare our algorithm to a conventional classiﬁcation SVMs with linear cost model and observe good
performance without diﬃcult to control heuristics.
2. Multivariate Performance Measures
In this section we ﬁrst review the typical assumptions
(often implicitly) made by most existing learning algorithms . This gives insight into why
they are not suitable for directly optimizing non-linear
performance measures like the F1-Score.
Most learning algorithms assume that the training
data S = ((x1, y1), ..., (xn, yn)) as well as the test data
S′ is independently identically distributed (i.i.d.) according to a learning task Pr(X, Y ). The goal is to
ﬁnd a rule h ∈H from the hypothesis space H that
optimizes the expected prediction performance on new
samples S′ of size n′.
1), ..., h(x′
1, ..., y′
n′)) d Pr(S′)
If the loss function ∆over samples decomposes linearly
into a sum of a loss function δ over individual examples
1), ..., h(x′
1, ..., y′
and since the examples are i.i.d., this expression can
be simpliﬁed to
R∆(h) = Rδ(h) =
δ (h(x′), y′) d Pr(x′, y′)
Discriminative learning algorithms approximate this
expected risk Rδ(h) using the empirical risk on the
training data S.
δ (h(xi), yi)
S(h) is an estimate of Rδ(h) for each h ∈H. Selecting a rule with low empirical risk ˆRδ
S(h) (e.g. training
error) in this decomposed form is the strategy followed
by virtually all discriminative learning algorithms.
many performance measures (e.g.
PRBEP) do not decompose linearly like in Eq. (1).
They are a non-linear combination of the individual classiﬁcations.
An example is the F1 score
∆F1((h(x1), ..., h(xn)), (y1, ..., yn)) = 2 P rec Rec
P rec+Rec , where
Prec and Rec are the precision and the recall of h
on the sample (x1, y1), ..., (xn, yn). There is no known
example-based loss function δ which can be used to decompose ∆. Therefore, learning algorithms restricted
to optimizing an empirical risk of the kind in Eq. (2)
are of questionable validity. What we need instead are
learning algorithms that directly optimize an empirical
risk that is based on the sample loss ∆.
S (h) = ∆((h(x1), ..., h(xn)), (y1, ..., yn))
Clearly, at least if the size n of the training set and
the size n′ of the test set are equal, ˆR∆
S (h) is again an
estimate of R∆(h) for each h ∈H. Note that ˆR∆
does not necessarily have higher variance than a decomposed empirical risk ˆRδ
S(h) just because it does
not “average” over multiple examples. The key factor
is the variance of ∆with respect to samples S drawn
from Pr(X, Y ). This variance can be low.
To design learning algorithms that do discriminative
training with respect to ˆR∆
S (h), we need algorithms
that ﬁnd an h ∈H that minimizes ˆR∆
S (h) over the
training sample S. Since ∆is some non-linear function
of S, this can be a challenging computational problem.
We will now present a general approach to this problem based on Support Vector Machines.
3. SVM Approach to Optimizing
Non-Linear Performance Measures
Support Vector Machines (SVMs) were developed by
Vapnik et al. as a method for learning linear
and, through the use of Kernels, non-linear rules. For
the case of binary classiﬁcation with unbiased hyperplanes1, SVMs learn a classiﬁer
h(x) = sign
by solving the following optimization problem.
Optimization Problem 1. (Unbiased SVMorg)
2 w · w + C
i=1 : yi[w · xi] ≥1 −ξi
The ξi are called slack variables. If a training example
lies on the “wrong” side of the hyperplane, the corresponding ξi is greater than 1. Therefore Pn
i=1 ξi is an
upper bound on the number of training errors. This
means that the SVM ﬁnds a hyperplane classiﬁer that
1Unbiased hyperplanes assume a threshold of 0 in the
classiﬁcation rule.
This is not a substantial restriction,
since a bias can be introduced by adding an artiﬁcial feature to each example.
A Support Vector Method for Multivariate Performance Measures
optimizes an approximation of the training error regularized by the L2 norm of the weight vector.
factor C in (3) controls the amount of regularization.
To diﬀerentiate between diﬀerent types of SVMs, we
will denote this version as SVMorg.
In the following, we will use the same principles used
in SVMorg to derive a class of SVM algorithms that
optimize a broad range of non-linear performance measures. The key idea is to treat the learning problem as
a multivariate prediction problem. Instead of deﬁning
our hypotheses h as a function from a single feature
vector x to a single label y ∈{−1, +1},
we will consider hypotheses ¯h that map a tuple ¯x ∈¯
of n feature vectors ¯x = (x1, ..., xn) to a tuple ¯y ∈¯Y
of n labels ¯y = (y1, ..., yn)
X = X × ... × X and ¯Y ⊆{−1, +1}n is the
set of all admissible label vectors2. To implement this
multivariate mapping, we will use linear discriminant
functions of the following form.
¯hw(¯x) = argmax
wT Ψ(¯x, ¯y′)
Intuitively, the prediction rule ¯hw(¯x) returns the tuple of labels ¯y′ = (y′
1, ..., y′
n) which scores highest
according to a linear function.
w is a parameter
vector and Ψ is a function that returns a feature
vector describing the match between (x1, ..., xn) and
1, ..., y′
n). Whether this argmax can be computed ef-
ﬁciently hinges on the structure of Ψ. For the purposes
of this paper, we can restrict Ψ to be of the following
simple form:
Ψ(¯x, ¯y′) =
For this Ψ(¯x, ¯y) and ¯Y = {−1, +1}n, the argmax is
achieved when y′
i is assigned to h(xi). So, in terms
of the resulting classiﬁcation rule, this is equivalent to
SVMorg. But did we gain anything from the reformulation of the prediction rule?
Thinking about the prediction problem in term of a
multivariate rule ¯h instead of a univariate rule h allows us to formulate the SVM optimization problem
in a way that enables inclusion of a sample-based loss
function ∆instead of the example-based loss function
in SVMorg. Following , we
formulate the following alternative optimization problem for non-negative ∆.
2Note that ¯Y can be a strict subset for some measures,
e.g. for Prec@k it is restricted to label vectors with k positive predictions.
Optimization Problem 2. (Multivar. SVM∆
2∥w∥2 + C ξ
∀¯y′ ∈¯Y\¯y: wT [Ψ(¯x, ¯y) −Ψ(¯x, ¯y′)]≥∆(¯y′,¯y)−ξ
Like for the SVMorg, this optimization problem is a
convex quadratic program. In contrast to the SVMorg,
however, there is one constraint for each possible ¯y ∈
¯Y. Due to the exponential size of ¯Y, this may seem like
an intractably large problem. However, by adapting
the sparse approximation algorithm of implemented in SVMstruct3, we will show
that this problem can be solved in polynomial time for
many types of multivariate loss functions ∆. Unlike in
the SVMorg optimization problem there is only one
slack variable ξ in this training problem. Similar to
P ξi in SVMorg, the value of this slack variable is an
upper bound on the training loss.
optimization
data ¯x with labels ¯y, the value of ξ∗is an upper bound
on the training loss ∆(¯hw∗(¯x), ¯y).
Proof. Let ¯y′
= ¯hw∗(¯x) be the prediction of the
learned multivariate hypothesis on the training data
itself. Following from the deﬁnition of ¯h, this is the labeling ¯y′ that minimizes w∗T [Ψ(¯x, ¯y) −Ψ(¯x, ¯y′)], and
this quantity will be less than zero unless ¯y′ = ¯y.
Therefore ξ ≥∆(¯y′, ¯y) −wT [Ψ(¯x, ¯y) −Ψ(¯x, ¯y′)] ≥
∆(¯y′, ¯y).
This shows that the multivariate SVM∆
multi is similar
to the original SVMorg in the sense that it optimizes
a convex upper bound on the training loss regularized
by the norm of the weight vector. We will later show
that, in fact, both formulations are identical if ∆is the
number of training errors.
straightforward
multivariate
multi to non-linear classiﬁcation rules via the dual
representation of ¯h. Similar to the univariate SVMorg,
the Wolfe dual of Optimization Problem 2 can be expressed in terms of inner products between feature vectors, allowing the use of kernels. We omit this extension for brevity.
4. Eﬃcient Algorithm
How can the optimization problem of the multivariate
multi be solved despite the huge number of constraints? This problem is a special case of the multivariate prediction formulations in as well as in . The
3 
A Support Vector Method for Multivariate Performance Measures
Algorithm 1 Algorithm for solving quadratic program of multivariate SVM∆
1: Input: ¯x = (x1, . . . , xn) ¯y = (y1, . . . , yn), C, ϵ, ¯Y
¯y′ ←argmax¯y′∈¯
∆(¯y′, ¯y) + wT Ψ(¯x, ¯y′)
ξ ←max¯y′∈C{max{0,∆(¯y′,¯y)−wT[Ψ(¯x,¯y)−Ψ(¯x,¯y′)]}}
if ∆(¯y′, ¯y)−wT [Ψ(¯x, ¯y)−Ψ(¯x, ¯y′)] > ξ+ϵ then
C ←C ∪{¯y′}
w ←optimize SVM∆
multi objective over C
10: until C has not changed during iteration
11: return(w)
algorithm proposed in for solving
these types of large quadratic programs is not applicable to non-linear loss functions ∆, since it assumes that
the loss decomposes linearly. The sparse approximation algorithm of does not
have this restriction, and we will show in the following
how it can be used to solve Optimization Problem 2 in
polynomial time for a large class of loss functions ∆.
Algorithm 1 is the sparse approximation algorithm
adapted to the multivariate SVM∆
multi. The algorithm
iteratively constructs a suﬃcient subset of the set of
constraints in Optimization Problem 2. The algorithm
starts with an empty set of constraints C and adds the
currently most violated constraint in each iteration,
i.e. the constraint corresponding to the label ¯y′ that
maximizes ∆(¯y′, ¯y) + wT Ψ(¯x, ¯y′). The next approximation to the solution of Optimization Problem 2 is
then computed on the new set of constraints.
algorithm stops when no constraint of Optimization
Problem 2 is violated by more than ϵ. It is easy to see
that the solution w∗returned by Algorithm 1 fulﬁlls all
constraints up to precision ϵ, and that the norm of w∗
is no bigger than the norm of the exact solution of Optimization Problem 2.
Furthermore, Tsochantaridis
et al. show that the algorithm terminates after
a polynomial number of iterations. We restate the theorem adapted to the SVM∆
multi optimization problem.
Theorem 2. For any ϵ > 0 and a training sample ¯x =
(x1, . . . , xn) and ¯y = (y1, . . . , yn) with R = maxi ||xi||
and L = max¯y′∈¯
Y ∆(¯y′, ¯y), Algorithm 1 terminates after incrementally adding at most
ϵ , 8Cn2R2L
constraints to the working set C.
The bound is rather lose. In our experiments we observe that the algorithm often converges after a few
hundred iterations even for large problems.
search for the most violated constraint
∆(¯y′, ¯y) + wT Ψ(¯x, ¯y′)
can be performed in polynomial time, the overall algorithm has polynomial time complexity. We will show
in the following that solving the argmax eﬃciently is
indeed possible for a large class of multivariate loss
functions ∆. We will ﬁrst consider multivariate loss
functions that can be computed from the contingency
table, and then consider the case of ROC Area.
4.1. Loss Functions Based on Contingency
An exhaustive search over all ¯y′ ∈¯Y is not feasible.
However, the computation of the argmax in Eq. (7)
can be stratiﬁed over all diﬀerent contingency tables,
so that each subproblem can be computed eﬃciently.
Algorithm 2 is based on the observation that there
are only order O(n2) diﬀerent contingency tables for a
binary classiﬁcation problem with n examples. Therefore, any loss function ∆(a, b, c, d) that can be computed from the contingency table can take at most
O(n2) diﬀerent values.
Lemma 1. Algorithm 2 computes the solution of
∆(a, b, c, d) + wT Ψ(¯x, ¯y′)
in polynomial time for any loss function ∆(a, b, c, d)
that can be computed from the contingency table in
polynomial time.
Proof. By iterating over all possible contingency tables, the algorithm iterates over all possible values l
of ∆(a, b, c, d). For each contingency table (a, b, c, d) it
computes the argmax over all ¯Yabcd, which is the set
of ¯y that correspond to this contingency table.
wT Ψ(¯x, ¯y′)
Since the objective function is linear in ¯y′, the solution
can be computed by maximizing ¯y′ element wise. The
maximum value for a particular contingency table is
achieved when the a positive examples with the largest
value of (wT xi) are classiﬁed as positive, and the d
negative examples with the lowest value of (wT xi) are
A Support Vector Method for Multivariate Performance Measures
Algorithm 2 Algorithm for computing argmax with
loss functions that can be computed from the contingency table.
1: Input: ¯x = (x1, . . . , xn), ¯y = (y1, . . . , yn), and ¯Y
1, . . . , ip
#pos) ←sort {i : yi = 1} by wT xi
1, . . . , in
#neg) ←sort {i : yi = −1} by wT xi
4: for a ∈[0, . . . , #pos] do
c ←#pos −a
1, . . . , y′
a to 1 AND set y′
a+1, . . . , y′
for d ∈[0, . . . , #neg] do
b ←#neg −d
1 , . . . , y′
b to1 AND set y′
b+1, . . . , y′
v ←∆(a, b, c, d) + wT Pn
if v is the largest so far then
1, ..., y′
15: end for
16: return(¯y∗)
classiﬁed as negative. The overall argmax can be computed by maximizing over the stratiﬁed maxima plus
their constant loss.
By slightly rewriting the algorithm, it can be implemented to run in time O(n2). Exploiting that many
loss functions are upper bounded, pruning can further
improve the runtime of the algorithm. We will now
give some examples of how this algorithm applies to
the loss functions we will later use in experiments.
The Fβ-Score is a measure typically used
to evaluate binary classiﬁers in natural language applications like text classiﬁcation. It is particularly preferable over error rate for highly unbalanced classes. The
Fβ-Score is a weighted harmonic average of Precision
and Recall. It can be computed from the contingency
(1 + β2) a
(1 + β2) a + b + β2c.
The most common choice for β is 1. For the corresponding loss ∆F1(¯y′, ¯y) = 100(1 −Fβ), Algorithm 2
directly applies.
Precision/Recall at k
In Web search engines, most
users scan only the ﬁrst few links that are presented.
Therefore, a common way to evaluate such systems is
to measure precision only on these (e.g. ten) positive
predictions. Similarly, in an archival retrieval system
not precision, but recall might be the most indicative
measure. For example, what fraction of the total number of relevant documents did a user ﬁnd after scanning the top 100 documents. Following this intuition,
Prec@k and Rec@k measure the precision and recall of
a classiﬁer that predicts exactly k documents to be
Prec@k(h) =
Rec@k(h) =
For these measures, the space of possible prediction
vectors ¯Y is restricted to those that predict exactly k
examples to be positive. For this ¯Y, the multivariate
discriminant rule ¯hw(¯x) in Eq. (5) can be computed
by assigning label 1 to the k examples with highest
wT xi. Similarly, a restriction to this ¯Y can easily be
incorporated into Algorithm 2 by excluding all ¯y′ ̸= ¯y
from the search for which a + b ̸= k.
Precision/Recall Break-Even Point
The Precision/Recall Break-Even Point (PRBEP) is a performance measure that is often used to evaluate text
classiﬁers. It requires that the classiﬁer makes a prediction ¯y so that precision and recall are equal, and
the value of the PRBEP is deﬁned to be equal to
both. As is obvious from the deﬁnition of precision
and recall, this equality is achieved for contingency
tables with a + b = a + c and we restrict ¯Y appropriately. Again, we deﬁne the corresponding loss as
∆P RBEP (¯y′, ¯y) = 100(1−PRBEP) and it is straightforward to compute ¯hw(¯x) and modify Algorithm 2 for
4.2. ROC Area
ROCArea is a performance measure that cannot be
computed from the contingency table, but requires
predicting a ranking.
However, both SVMorg and
multi naturally predict a ranking by ordering all
examples according to wT xi.
From such a ranking, ROCArea can be computed from the number of
swapped pairs
SwappedPairs = |{(i,j) : (yi>yj) and (wTxi<wTxj)}|,
i.e. the number of pairs of examples that are ranked
in the wrong order.
ROCArea = 1 −SwappedPairs
#pos · #neg
We can adapt the SVM∆
multi to optimizing ROC-
Area by (implicitly) considering a classiﬁcation problem of all #pos·#neg pairs (i, j) of a positive example
(xi, 1) and a negative example (xj, −1), forming a new
classiﬁcation problem ¯¯X and ¯¯Y = {−1, 1}#pos·#neg as
Each pos/neg pair (i, j) receives the target
A Support Vector Method for Multivariate Performance Measures
Algorithm 3 Algorithm for computing argmax with
ROCArea-loss.
1: Input: ¯x = (x1, . . . , xn), ¯y = (y1, . . . , yn)
2: for i ∈{i : yi = 1} do si ←−0.25 + wT xi
3: for i ∈{i : yi = −1} do si ←0.25 + wT xi
4: (r1, . . . , rn) ←sort {1, . . . , n} by si
5: sp = #pos, sn = 0
6: for i ∈{1, . . . , n} do
if yri > 0 then
cri ←(#neg −2 sn)
cri ←(−#pos + 2 sp)
sn ←sn + 1
14: end for
15: return(c1, . . . , cn)
label yij = 1 and is described by the feature vector
xij = xi −xj.
In this representation, the discriminant rule ¯¯hw(¯¯x) = argmax¯¯y′∈¯¯Y
wT Ψ(¯¯x, ¯¯y′)
corresponds to labeling a pair (i, j) as sign(wT xi −wT xj),
i.e. according to the ordering w.r.t wT xi as desired.
Note that the error between the prediction ¯¯y′ and the
true pairwise labels ¯¯y = (1, ..., 1)T is proportional to
1 −ROCArea of the original data ¯x and ¯y. We call
this quantity the ROCArea-loss.
∆ROCArea(¯¯y′, ¯¯y) =
ij) = SwappedPairs
Actually representing all #pos · #neg pairs would be
rather ineﬃcient, but can be avoided using the following representation which is linear in the number of
examples n.
Ψ(¯¯x, ¯¯y)=
cixi with ci =
if(yi =−1)
Note that ∆ROCArea(¯¯y′, ¯¯y) can now be computed as
∆ROCArea(¯¯y′, ¯¯y) =
i=1 yi(ci −c′
Algorithm 3
computes the argmax in this representation.
Lemma 2. For ¯x and ¯y of size n, Algorithm 3 computes the solution c1, . . . , cn corresponding to
∆ROCArea(¯¯y′, ¯¯y) + wT Ψ(¯¯x, ¯¯y′)
in time O(n log n).
Proof. The argmax can be written as follows in the
pairwise representation.
ijwT (xi −xj)
Since the loss function decomposes linearly over the
pairwise representation, we can maximize each yij individually.
ij∈{−1,+1}
ijwT (xi −xj)
ij∈{−1,+1}
yij[(wT xi −1
4) −(wT xj + 1
This means that a pair (i, j) should be labeled as
yij = 1, if the score wT xi of the positive example
decremented by 1
4 is larger than the score wT xj of the
negative example incremented by 1
4. This is precisely
how the algorithm assigns the labels and collects them
in the compressed representation. The runtime of the
algorithm is dominated by a single sort operation.
multi Generalizes SVMorg
The following theorem shows that the multivariate
multi is a direct generalization of the conventional
classiﬁcation SVM. When using error rate as the loss
function, the conventional SVM arises as a special case
Theorem 3. Using error as the loss function, in particular ∆Err(¯y′, ¯y) = 2 (b + c), SVMErr
multi with regularization parameter Cmulti computes the same hyperplane w as SVMorg with Corg = 2 Cmulti.
Proof. We will show that both optimization problems
have the same objective value and an equivalent set
of constraints. In particular, for every w the smallest
feasible ξ and P
i ξi are related as ξ = 2 P
For a given w, the ξi in SVMorg can be optimized
individually, and the optimum is achieved for ξi =
max{0, 1−yi(wT xi)}. For the SVMErr
multi, the optimal
ξ for a given w is
∆Err(¯y′, ¯y) +
Since the function is linear in the y′
i, each y′
optimized independently. Denote with δErr(y′
i, yi) the
univariate loss function that returns 2 if both arguments diﬀer, and 0 otherwise.
i, yi) + y′
iwT xi −yiwT xi
0, 2 −2yiwT xi
Therefore, if Corg = 2 Cmulti, the objective functions
of both optimization problems are equal for any w,
and consequently so are their optima w.r.t. w.
A Support Vector Method for Multivariate Performance Measures
Table 1. Comparing an SVM optimized for the performance measure to one that is trained with linear cost model.
Reuters (90 classes)
Examples: 9603/3299
Features: 27658
improvement
+5.9 (51/20)**
+2.5 (16/8)**
+1.1 (14/8)
+0.5 (43/33)*
ArXiv (14 classes)
Examples: 1168/32487
Features: 13525
improvement
+7.2 (9/5)*
+0.5 (9/4)
-1.1 (1/13)**
+0.1 (8/6)
Optdigits (10 classes)
Examples: 3823/1797
Features: 64
improvement
+1.0 (8/2)*
+1.2 (5/1)*
-0.3 (1/5)
Covertype (7 classes)
Examples: 1000/2000
Features: 54
improvement
-0.1 (3/4)
+1.1 (5/2)
-1.6 (2/5)
+0.5 (4/3)
6. Experiments
To evaluate the proposed SVM approach to optimizing
non-linear performance measures, we conducted experiments on four diﬀerent test collection. We compare
F1-score, PRBEP, Rec@k for k twice the number of
positive examples (Rec@2p), and ROCArea achieved
by the respective SVM∆
multi with the performance of
a classiﬁcation SVM that includes a cost model. The
cost model is implemented by allowing diﬀerent regularization constants for positive and negative examples . Using the parameter j of
SVMlight, the C parameter of positive examples is
multiplied by j to increase their inﬂuence. This setup
is a strong baseline to compare against.
For example, David Lewis won the TREC-2001 Batch Filtering
Evaluation using SVMlight with such
cost models.
Furthermore, Musicant et al.
make a theoretical argument that such cost models
approximately optimize F1-score.
We compare performance on four test collections,
namely the ModApte Reuters-21578 text classiﬁcation
benchmark4, a dataset of abstracts from the Physics
E-Print ArXiv, and the OPTDIGITS and COVER-
TYPE benchmarks 5. Train/test split and the number
of features are given in Table 1.
Initial experiments indicated that biased hyperplane
adjustable threshold) outperform unbiased hyperplanes. We therefore add a constant feature with
value 1 to each training example for the SVM∆
use biased hyperplanes for the regular SVM as implemented in SVMlight. To select the regularization parameter C for the SVM∆
multi, and C and j for the classiﬁcation SVM, we used holdout testing with a random 2
3 split of the training set for each class in a collection.
4 
5 
We search within C ∈[2−6, ..., 26] and j ∈[20, ..., 27],
but extended the search space if the most frequently
selected parameter setting over all classes in the collection was on a boundary.
Our implementation of SVM∆
is available at
 
Table 1 shows the macro-average of the performance
over all classes in a collection. Each “improvement”
line shows the amount by which the SVM∆
multi outperforms (or underperforms) the regular SVM. Both
the diﬀerence in performance, as well as the number
of classes on which the SVM∆
multi won/lost are shown.
Stars indicate the level of signiﬁcance according to a
two-tailed Wilcoxon test applied to pairs of results over
classes. One star indicates a signiﬁcance level of 0.9,
two stars a level of 0.95. Overall, 11 macroaverages
in Table 1 show an improvement (6 signiﬁcant), and
only 4 cases (1 signiﬁcant) show a decline in performance. Comparing the results between datasets, the
improvements are largest for the two text classiﬁcation
tasks, while especially for COVERTYPE there is no
signiﬁcant diﬀerence between the two methods. With
respect to diﬀerent performance measures, the largest
gains are observed for F1-score on the text classiﬁcation tasks. PRBEP and ROCArea also show consistent, but smaller gains. On Rec@2p, the regular SVM
appears to perform better on average.
Figure 1 further analyzes how the performance diﬀers
between the individual binary tasks in the Reuters collection. The 90 tasks were binned into 5 sets by their
ratio of positive to negative examples. Figure 1 plots
the average performance improvement in each bin from
the most popular classes on the left to the least popular classes on the right. For most measures, especially
F1-score, improvements are larger for the less popular
categories.
A Support Vector Method for Multivariate Performance Measures
Average Performance Improvement
Categories (binned by frequency)
Figure 1. Improvement
prediction
performance
Reuters of SVM∆
multi over SVMorg depending on the balance between positive and negative examples. Results are
averaged by binning the 90 categories according to their
number of examples.
7. Conclusions
This paper generalized SVMs to optimizing large
classes of multivariate non-linear performance measures often encountered in practical applications. We
presented a training algorithm and showed that is it
computationally tractable.
The new approach leads
to improved performance particularly for text classiﬁcation problems with highly unbalanced classes. Furthermore, it provides a principled approach to optimizing such measures and avoids diﬃcult to control
heuristics.
This work was funded in part under NSF awards IIS-
0412894 and IIS-0412930.