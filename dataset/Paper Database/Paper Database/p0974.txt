Fast and Light Boosting for Adaptive Mining of Data
Fang Chu and Carlo Zaniolo
University of California, Los Angeles, CA 90095, USA
{fchu, zaniolo}@cs.ucla.edu
Abstract. Supporting continuous mining queries on data streams requires
algorithms that (i) are fast, (ii) make light demands on memory resources,
and (iii) are easily to adapt to concept drift. We propose a novel boosting
ensemble method that achieves these objectives. The technique is based on
a dynamic sample-weight assignment scheme that achieves the accuracy of
traditional boosting without requiring multiple passes through the data. The
technique assures faster learning and competitive accuracy using simpler
base models. The scheme is then extended to handle concept drift via change
detection. The change detection approach aims at signiﬁcant data changes
that could cause serious deterioration of the ensemble performance, and
replaces the obsolete ensemble with one built from scratch. Experimental results
conﬁrm the advantages of our adaptive boosting scheme over previous approaches.
Keywords: Stream data mining, adaptive boosting ensembles, change detection
Introduction
A substantial amount of recent work has focused on continuous mining of data streams . Typical applications include network trafﬁc monitoring, credit card fraud
detection and sensor network management systems. Challenges are posed by data ever
increasing in amount and in speed, as well as the constantly evolving concepts underlying
the data.Two fundamental issues have to be addressed by any continuous mining attempt.
Performance Issue. Constrained by the requirement of on-line response and by limited computation and memory resources, continuous data stream mining should conform
to the following criteria: (1) Learning should be done very fast, preferably in one pass
of the data; (2) Algorithms should make very light demands on memory resources, for
the storage of either the intermediate results or the ﬁnal decision models. These fast and
light requirements exclude high-cost algorithms, such as support vector machines; also
decision trees with many nodes should preferably be replaced by those with fewer nodes
as base decision models.
Adaptation Issue. For traditional learning tasks, the data is stationary. That is, the
underlyingconceptthatmapsthefeaturestoclasslabelsisunchanging .Inthecontext
of data streams, however, the concept may drift due to gradual or sudden changes of the
external environment, such as increases of network trafﬁc or failures in sensors. In fact,
mining changes is considered to be one of the core issues of data stream mining .
H. Dai, R. Srikant, and C. Zhang (Eds.): PAKDD 2004, LNAI 3056, pp. 282–292, 2004.
c⃝Springer-Verlag Berlin Heidelberg 2004
Fast and Light Boosting for Adaptive Mining of Data Streams
In this paper we focus on continuous learning tasks, and propose a novel Adaptive
Boosting Ensemble method to solve the above problems. In general, ensemble methods
combine the predictions of multiple base models, each learned using a learning algorithm
called the base learner . In our method, we propose to use very simple base models,
such as decision trees with a few nodes, to achieve fast and light learning. Since simple
models are often weak predictive models by themselves, we exploit boosting technique
to improve the ensemble performance. The traditional boosting is modiﬁed to handle
data streams, retaining the essential idea of dynamic sample-weight assignment yet
eliminating the requirement of multiple passes through the data. This is then extended to
handle concept drift via change detection. Change detection aims at signiﬁcant changes
that would cause serious deterioration of the ensemble performance. The awareness of
changes makes it possible to build an active learning system that adapts to changes
RelatedWork.
Ensemble methods are hardly the only approach used for continuous
learning. Domingos et al. devised a novel decision tree algorithm, the Hoeffding tree,
that performs asymptotically the same as or better than its batched version. This was
extended to CVFDT in an attempt to handle concept drift . But, Hoeffding-tree like
algorithms need a large training set in order to reach a fair performance, which makes
them unsuitable to situations featuring frequent changes. Domeniconi et al. designed
an incremental support vector machine algorithm for continuous learning.
There has been work related to boosting ensembles on data streams. Fern et al. 
proposed online boosting ensembles, and Oza et al. studied both online bagging and
online boosting. Frank et al. used a boosting scheme similar to our boosting scheme.
But none of these work took concept drift into consideration.
Previous ensemble methods for drifting data streams have primarily relied on
bagging-style techniques . Street et al. gave an ensemble algorithm that
builds one classiﬁer per data block independently. Adaptability relies solely on retiring
old classiﬁers one at a time. Wang et al. used a similar ensemble building method.
But their algorithm tries to adapt to changes by assigning weights to classiﬁers proportional to their accuracy on the most recent data block. As these two algorithms are
the most related, we call them Bagging and Weighted Bagging, respectively, for later
references in our experimental comparison. 1
This paper is organized as follows. Our adaptive boosting ensemble method is presented in section 2, followed by a change detection technique in section 3. Section 4
contains experimental design and evaluation results, and we conclude in section 5.
Adaptive Boosting Ensembles
We use the boosting ensemble method since this learning procedure provides a number
of formal guarantees. Freund and Schapire proved a number of positive results about its
generalization performance . More importantly, Friedman et al. showed that boosting
is particularly effective when the base models are simple . This is most desirable for
fast and light ensemble learning on steam data.
1 The name “bagging” derives from their analogy to traditional bagging ensembles .
F. Chu and C. Zaniolo
Algorithm 1 Adaptive boosting ensemble algorithm
Ensure: Maintaining a boosting ensemble Eb with classiﬁers {C1, · · · , Cm}, m ≤M.
1: while (1) do
Given a new block Bj = {(x1, y1), · · · , (xn, yn)}, where yi ∈{0, 1},
Compute ensemble prediction for sample i: Eb(xi) = round( 1
k=1 Ck(xi)),
Change Detection: Eb ⇐∅if a change detected!
if (Eb ̸= ∅) then
Compute error rate of Eb on Bj: ej = E[1Eb(xi)̸=yi],
Set new sample weight wi = (1 −ej)/ej if Eb(xi) ̸= yi; wi = 1 otherwise
set wi = 1, for all i.
Learn a new classiﬁer Cm+1 from weighted block Bj with weights {wi},
Update Eb: add Cm+1, retire C1 if m = M.
13: end while
In its original form, the boosting algorithm assumes a static training set. Earlier
classiﬁers increase the weights of misclassiﬁed samples, so that the later classiﬁers will
focus on them. A typical boosting ensemble usually contains hundreds of classiﬁers.
However, this lengthy learning procedure does not apply to data streams, where we have
limited storage but continuous incoming data. Past data can not stay long before making
place for new data. In light of this, our boosting algorithm requires only two passes of
the data. At the same time, it is designed to retain the essential idea of boosting—the
dynamic sample weights modiﬁcation.
Algorithm 1 is a summary of our boosting process. As data continuously ﬂows
in, it is broken into blocks of equal size. A block Bj is scanned twice. The ﬁrst pass
is to assign sample weights, in a way corresponding to AdaBoost.M1 . That is, if
the ensemble error rate is ej, the weight of a misclassiﬁed sample xi is adjusted to
be wi = (1 −ej)/ej. The weight of a correctly classiﬁed sample is left unchanged.
The weights are normalized to be a valid distribution. In the second pass, a classiﬁer is
constructed from this weighted training block.
The system keeps only the most recent classiﬁers, up to M. We use a traditional
scheme to combine the predictions of these base models, that is, by averaging the probability predictions and selecting the class with the highest probability. Algorithm 1 is for
binary classiﬁcation, but can easily be extended to multi-class problems.
Adaptability
Note that there is a step called “Change Detection” (line 4) in
Algorithm 1. This is a distinguished feature of our boosting ensemble, which guarantees
that the ensemble can adapt promptly to changes. Change detection is conducted at every
block. The details of how to detect changes are presented in the next section.
Our ensemble scheme achieves adaptability by actively detecting changes and discarding the old ensemble when an alarm of change is raised. No previous learning
algorithm has used such a scheme. One argument is that old classiﬁers can be tuned to
the new concept by assigning them different weights. Our hypothesis, which is borne
out by experiment, is that obsolete classiﬁers have bad effects on overall ensemble performance even they are weighed down. Therefore, we propose to learn a new ensemble
Fast and Light Boosting for Adaptive Mining of Data Streams
from scratch when changes occur. Slow learning is not a concern here, as our base learner
is fast and light, and boosting ensures high accuracy. The main challenge is to detect
changes with a low false alarm rate.
Change Detection
In this section we propose a technique for change detection based on the framework
of statistical decision theory. The objective is to detect changes that cause signiﬁcant
deterioration in ensemble performance, while tolerating minor changes due to random
noise. Here, we view ensemble performance θ as a random variable. If data is stationary
and fairly uniform, the ensemble performance ﬂuctuations are caused only by random
noise, hence θ is normally assumed to follow a Gaussian distribution.When data changes,
yet most of the obsolete classiﬁers are kept, the overall ensemble performance will
undergo two types of decreases. In case of an abrupt change, the distribution of θ will
change from one Gaussian to another. This is shown in Figure 1(a). Another situation is
when the underlying concept has constant but small shifts. This will cause the ensemble
performance to deteriorate gradually, as shown in Figure 1(b). Our goal is to detect both
types of signiﬁcant changes.
Fig. 1. Two types of signiﬁcant changes. Type I: abrupt changes; Type II: gradual changes over a
period of time. These are the changes we aim to detect.
Every change detection algorithm is a certain form of hypothesis test. To make a
decision whether or not a change has occurred is to choose between two competing
hypotheses: the null hypothesis H0 or the alternative hypothesis H1, corresponding to
a decision of no-change or change, respectively. Suppose the ensemble has an accuracy
θj on block j. If the conditional probability density function (pdf) of θ under the null
hypothesis p(θ|H0) and that under the alternative hypothesis p(θ|H1) are both known,
we can make a decision using a likelihood ratio test:
L(θj) = p(θj|H1)
The ratio is compared against a threshold τ. H1 is accepted if L(θj) ≥τ, and rejected
otherwise. τ is chosen so as to ensure an upper bound of false alarm rate.
F. Chu and C. Zaniolo
Now consider how to detect a possible type I change. When the null hypothesis H0
(no change) is true, the conditional pdf is assumed to be a Gaussian, given by
where the mean µ0 and the variance σ2
0 can be easily estimated if we just remember
a sequence of most recent θ’s. But if the alternative hypothesis H1 is true, it is not
possible to estimate P(θ|H1) before sufﬁcient information is collected. This means a
long delay before the change could be detected. In order to do it in time fashion, we
perform a signiﬁcance test that uses H0 alone. A signiﬁcant test is to assess how well
the null hypothesis H0 explains the observed θ. Then the general likelihood ratio test in
Equation 1 is reduced to:
When the likelihood p(θj|H0) ≥τ, the null hypothesis is accepted; otherwise it is
rejected. Signiﬁcant tests are effective in capturing large, abrupt changes.
For type II changes, we perform a typical hypothesis test as follows. First, we split
the history sequence of θ’s into two halves. A Gaussian pdf can be estimated from each
half, denoted as G0 and G1. Then a likelihood ratio test in Equation 1 is conducted.
So far we have described two techniques aiming at two types of changes. They
are integrated into a two-stage method as follows. As a ﬁrst step, a signiﬁcant test is
performed. If no change is detected, then a hypothesis test is performed as a second step.
This two-stage detection method is shown to be very effective experimentally.
Experimental Evaluation
In this section, we ﬁrst perform a controlled study on a synthetic data set, then apply the
method to a real-life application.
In the synthetic data set, a sample x is a vector of three independent features < xi >,
xi ∈ , i = 0, 1, 2. Geometrically, samples are points in a 3-dimension unit cube.
The class boundary is a sphere deﬁned as: B(x) = 2
i=0(xi −ci)2 −r2 = 0, where
c is the center of the sphere, r the radius. x is labelled class 1 if B(x) ≤0, class 0
otherwise. This learning task is not easy, because the feature space is continuous and the
class boundary is non-linear.
We evaluate our boosting scheme extended with change detection, named asAdaptive
Boosting, and compare it with Weighted Bagging and Bagging.
In the following experiments, we use decision trees as our base model, but the
boosting technique can, in principle, be used with any other traditional learning model.
The standard C4.5 algorithm is modiﬁed to generate small decision trees as base models,
with the number of terminal nodes ranging from 2 to 32. Full-grown decision trees
generated by C4.5 are also used for comparison, marked as fullsize in Figure 2-4 and
Table 1-2.
Fast and Light Boosting for Adaptive Mining of Data Streams
Average Accuracy
# Decision Tree Terminal Nodes
Adaptive Boosting
Fig. 2. Performance comparison of the adaptive boosting vs the bagging on stationary data. The
weighted bagging is omitted as it performs almost the same as the bagging.
Evaluation of Boosting Scheme
The boosting scheme is ﬁrst compared against two bagging ensembles on stationary data.
Samples are randomly generated in the unit cube. Noise is introduced in the training data
by randomly ﬂipping the class labels with a probability of p. Each data block has n samples and there are 100 blocks in total. The testing data set contains 50k noiseless samples
uniformly distributed in the unit cube. An ensemble of M classiﬁers is maintained. It is
updated after each block and evaluated on the test data set. Performance is measured
using the generalization accuracy averaged over 100 ensembles.
Figure 2 shows the generalization performance when p=5%, n=2k and M=30.
Weighted bagging is omitted from the ﬁgure because it makes almost the same predictions as bagging, a not surprising result for stationary data. Figure 2 shows that the
boosting scheme clearly outperforms bagging. Most importantly, boosting ensembles
with very simple trees performs well. In fact, the boosted two-level trees(2 terminal
nodes) have a performance comparable to bagging using the full size trees. This supports the theoretical study that boosting improves weak learners.
Higher accuracy of boosted weak learners is also observed for (1) block size n of
500, 1k, 2k and 4k, (2) ensemble size M of 10, 20, 30, 40, 50, and (3) noise level of 5%,
10% and 20%.
Learning with Gradual Shifts
Gradualconceptshiftsareintroducedbymovingthecenteroftheclassboundarybetween
adjacent blocks. The movement is along each dimension with a step of ±δ. The value
of δ controls the level of shifts from small to moderate, and the sign of δ is randomly
assigned. The percentage of positive samples in these blocks ranges from 16% to 25%.
Noise level p is set to be 5%, 10% and 20% across multiple runs.
The average accuracies are shown in Figure 3 for small shifts (δ = 0.01), and in
Figure 4 for moderate shifts (δ = 0.03). Results of other settings are shown in Table 1.
These experiments are conducted where the block size is 2k. Similar results are obtained
for other block sizes. The results are summarized below:
F. Chu and C. Zaniolo
Average Accuracy
# Decision Tree Terminal Nodes
Adaptive Boosting
Weighted Bagging
Fig. 3. Performance comparison of the three ensembles on data with small gradual concept shifts.
Average Accuracy
# Decision Tree Terminal Nodes
Adaptive Boosting
Weighted Bagging
Fig. 4. Performance comparison of the ensembles on data with moderate gradual concept shifts.
Table 1. Performance comparison of the ensembles on data with varying levels of concept shifts.
Top accuracies shown in bold fonts.
Adaptive Boosting
89.2% 93.2% 93.9% 94.9%
92.2% 94.5% 95.7% 95.8%
Weighted Bagging
– Adaptive boosting outperforms two bagging methods at all time, demonstrating the
beneﬁts of the change detection technique; and
– Boosting is especially effective with simple trees (terminal nodes ≤8), achieving a
performance compatible with, or even better than, the bagging ensembles with large
Learning with Abrupt Shifts
We study learning with abrupt shifts with two sets of experiments. Abrupt concept shifts
are introduced every 40 blocks; three abrupt shifts occur at block 40, 80 and 120. In one
Fast and Light Boosting for Adaptive Mining of Data Streams
Table 2. Performance comparison of three ensembles on data with abrupt shifts or mixed shifts.
Top accuracies are shown in bold fonts.
δ2 = ±0.01
Adaptive Boosting
Weighted Bagging
Data Blocks
Adaptive Boosting
Weighted Bagging
Fig. 5. Performance comparison of the three ensembles on data with abrupt shifts. Base decision
trees have no more than 8 terminal nodes.
set of experiments, data stays stationary between these blocks. In the other set, small
shifts are mixed between adjacent blocks. The concept drift parameters are set to be
δ1 = ±0.1 for abrupt shifts , and δ2 = ±0.01 for small shifts.
Figure 5 and Figure 6 show the experiments when base decision trees have no more
than 8 terminal nodes. Clearly the bagging ensembles, even with an empirical weighting scheme, are seriously impaired at changing points. Our hypothesis, that obsolete
classiﬁers are detrimental to overall performance even if they are weighed down, are
proved experimentally. Adaptive boosting ensemble, on the other hand, is able to respond promptly to abrupt changes by explicit change detection efforts. For base models
of different sizes, we show some of the results in Table 2. The accuracy is averaged over
160 blocks for each run.
Experiments on Real Life Data
In this subsection we further verify our algorithm on a real life data containing 100k
credit card transactions. The data has 20 features including the transaction amount, the
time of the transaction, etc. The task is to predict fraudulent transactions. Detailed data
description is given in . The part of the data we use contains 100k transaction each
F. Chu and C. Zaniolo
Data Blocks
Adaptive Boosting
Weighted Bagging
Fig. 6. Performance comparison of the three ensembles on data with both abrupt and small shifts.
Base decision trees have no more than 8 terminal nodes.
with a transaction amount between $0 and $21. Concept drift is simulated by sorting
transactions by changes by the transaction amount.
Data Blocks
Adaptive Boosting
Weighted Bagging
Fig. 7. Performance comparison of the three ensembles on credit card data. Concept shifts are
simulated by sorting the transactions by the transaction amount.
We study the ensemble performance using varying block sizes (1k, 2k, 3k and 4k),
and different base models (decision trees with terminal nodes no more than 2, 4, 8 and
full-size trees). We show one experiment in Figure 7, where the block size is 1k, and
the base models have at most 8 terminal nodes. The curve shows three dramatic drops
in accuracy for bagging, two for weighted bagging, but only a small one for adaptive
boosting. These drops occur when the transaction amount jumps. Overall, the boosting
Fast and Light Boosting for Adaptive Mining of Data Streams
ensemble is much better than the two baggings.This is also true for the other experiments,
whose details are omitted here due to space limit.
The boosting scheme is also the fastest. Moreover, the training time is almost not
affected by the size of base models. This is due to the fact that the later base models tend
to have very simple structures; many of them are just decision stumps (one level decision
trees). On the other hand, training time of the bagging methods increases dramatically
as the base decision trees grow larger. For example, when the base decision tree is fullgrown, the weighted bagging takes 5 times longer to do the training and produces a
tree 7 times larger on average. The comparison is conducted on a 2.26MHz Pentium 4
Processor. Details are shown in Figure 8.
To summarize, the real application experiment conﬁrms the advantages of our boosting ensemble methods: it is fast and light, with good adaptability.
Fig. 8. Comparison of the adaptive boosting and the weighted bagging, in terms of (a) building
time, and (b) average decision tree size. In (a), the total amount of data is ﬁxed for different block
Summary and Future Work
In this paper, we propose an adaptive boosting ensemble method that is different from
previous work in two aspects: (1) We boost very simple base models to build effective
ensembles with competitive accuracy; and (2) We propose a change detection technique
to actively adapt to changes in the underlying concept. We compare adaptive boosting
ensemble methods with two bagging ensemble-based methods through extensive experiments. Results on both synthetic and real-life data set show that our method is much
faster, demands less memory, more adaptive and accurate.
The current method can be improved in several aspects. For example, our study of
the trend of the underlying concept is limited to the detection of signiﬁcant changes. If
changes can be detected on a ﬁner scale, new classiﬁers need not be built when changes
are trivial, thus training time can be further saved without loss on accuracy. We also plan
to study a classiﬁer weighting scheme to improve ensemble accuracy.
F. Chu and C. Zaniolo