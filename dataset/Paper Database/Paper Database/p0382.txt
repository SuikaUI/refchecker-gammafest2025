Received November 21, 2018, accepted December 4, 2018, date of publication December 19, 2018,
date of current version January 7, 2019.
Digital Object Identifier 10.1109/ACCESS.2018.2886457
DeepAnT: A Deep Learning Approach for
Unsupervised Anomaly Detection
in Time Series
MOHSIN MUNIR
1,2, SHOAIB AHMED SIDDIQUI
ANDREAS DENGEL1,2, AND SHERAZ AHMED
1Fachbereich Informatik, Technische Universität Kaiserslautern, 67663 Kaiserslautern, Germany
2German Research Center for Artiﬁcial Intelligence (DFKI GmbH), 67663 Kaiserslautern, Germany
Corresponding author: Mohsin Munir ( )
This work was supported in part by the BMBF project DeFuseNN under Grant 01IW17002 and in part by the NVIDIA AI Lab (NVAIL)
ABSTRACT Traditional distance and density-based anomaly detection techniques are unable to detect
periodic and seasonality related point anomalies which occur commonly in streaming data, leaving a big gap
in time series anomaly detection in the current era of the IoT. To address this problem, we present a novel deep
learning-based anomaly detection approach (DeepAnT) for time series data, which is equally applicable to
the non-streaming cases. DeepAnT is capable of detecting a wide range of anomalies, i.e., point anomalies,
contextual anomalies, and discords in time series data. In contrast to the anomaly detection methods where
anomalies are learned, DeepAnT uses unlabeled data to capture and learn the data distribution that is used to
forecast the normal behavior of a time series. DeepAnT consists of two modules: time series predictor and
anomaly detector. The time series predictor module uses deep convolutional neural network (CNN) to predict
the next time stamp on the deﬁned horizon. This module takes a window of time series (used as a context)
and attempts to predict the next time stamp. The predicted value is then passed to the anomaly detector
module, which is responsible for tagging the corresponding time stamp as normal or abnormal. DeepAnT
can be trained even without removing the anomalies from the given data set. Generally, in deep learningbased approaches, a lot of data are required to train a model. Whereas in DeepAnT, a model can be trained
on relatively small data set while achieving good generalization capabilities due to the effective parameter
sharing of the CNN. As the anomaly detection in DeepAnT is unsupervised, it does not rely on anomaly
labels at the time of model generation. Therefore, this approach can be directly applied to real-life scenarios
where it is practically impossible to label a big stream of data coming from heterogeneous sensors comprising
of both normal as well as anomalous points. We have performed a detailed evaluation of 15 algorithms on
10 anomaly detection benchmarks, which contain a total of 433 real and synthetic time series. Experiments
show that DeepAnT outperforms the state-of-the-art anomaly detection methods in most of the cases, while
performing on par with others.
INDEX TERMS
Anomaly detection, artiﬁcial intelligence, convolutional neural network, deep neural
networks, recurrent neural networks, time series analysis.
I. INTRODUCTION
Anomaly detection has been one of the core research areas
for a long time due to its ubiquitous nature. In everyday life,
we observe the abnormalities that are the focus of our attention. When something deviates largely from rest of the distribution, it is labeled as an anomaly or an outlier. In the context
of this paper, anomalies and outliers are used interchangeably as stated in . In computer science, anomaly detection
refers to the techniques of ﬁnding speciﬁc data points, that
do not conform to the normal distribution of the data set.
The most relevant deﬁnition of an anomaly with respect to
computer science is given by Grubbs : ‘‘An outlying observation, or ‘outlier’, is one that appears to deviate markedly
from other members of the sample in which it occurs’’. The
term ‘anomaly’, is widely used and it refers to different
problems in different domains. For example, an anomaly in
network security system could be an activity related to a
malicious software or a hacking attempt . Whereas, in the
VOLUME 7, 2019
2018 IEEE. Translations and content mining are permitted for academic research only.
Personal use is also permitted, but republication/redistribution requires IEEE permission.
See for more information.
M. Munir et al.: DeepAnT: Deep Learning Approach for Unsupervised Anomaly Detection in Time Series
manufacturing domain a faulty product is considered as an
anomaly. It is very important to detect anomalies as early as
possible to avoid big issues like ﬁnancial system hack, total
machine failure, or a cancerous tumor in human body.
Companies from different sectors including manufacturing, automotive, healthcare, lodging, traveling, fashion, food,
and logistics are investing a lot of resources , in collecting big data and exploring the hidden anomalous patterns
in them to facilitate their customers. In most of the cases,
the collected data are streaming time series data and due to
their intrinsic characteristics of periodicity, trend, seasonality,
and irregularity, it is a challenging problem to detect point
anomalies precisely in them. Furthermore, in most of real
life scenarios, it is practically impossible to label enormous
amount of data, therefore, we are using an unsupervised
method. Although many unsupervised methods are available, they don’t handle the intrinsic characteristics of time
series data. For example, traditional distance based anomaly
detection techniques do not incorporate context of a time
series, due to which they are unable to ﬁnd point anomalies
occurring in cycles. The proposed unsupervised approach
incorporates context, seasonality, and trend into account for
detecting anomalies. This approach can be adapted for different scenarios and use cases, and works on data from different
This paper presents DeepAnT, a novel unsupervised deep
learning based anomaly detection approach for streaming
data. This approach doesn’t rely on labeling of anomalies
rather it leverages the original time series data even without
removing anomalies (given that the number of anomalies in
the data set is less than 5% ). DeepAnT employs CNN
as its forecasting module. This module predicts the next
time stamp of a given time series window. Subsequently,
the forecasted value is passed to a detector module, which
compares that value with the actual data point to detect
anomalies in real-time. The approach is realistic and suitable
even for domains where time series data are collected from
heterogeneous sources and sensors. DeepAnT achieves good
generalization capabilities in data scarce scenarios where less
training data are available. Only a few number of training
samples (depending on the data set, e.g. 568 data points from
Yahoo data set and 140 data points from Ionosphere data set)
are sufﬁcient to build a prediction model due to its effective
parameter sharing during feature extraction. DeepAnT when
tested on publicly available anomaly detection benchmarks,
outperformed the state-of-the-art anomaly detection methods in most of the cases. Instead of classifying whole time
series as normal or abnormal (as done in – ), DeepAnT’s
objective is to robustly detect point anomalies. In particular,
following are the main contributions of this paper:
1) To the best of our knowledge, DeepAnT is the ﬁrst deep
learning based approach which is capable of detecting
point anomalies, contextual anomalies, and discords in
time series data in an unsupervised setting.
2) The proposed pipeline is ﬂexible and can be easily
adapted for different use cases and domains. It can
be applied to uni-variant as well as multi-variant time
3) In contrast to the LSTM based approach, CNN based
DeepAnT is not data hungry. It is equally applicable to
big data as well as small data. We are only using 40% of
a given time series to train a model.
4) We gathered different anomaly detection benchmarks at
one place and provided extensive evaluation of 15 stateof-the-art methods in different settings on 10 data
sets (covering both steaming and non-streaming cases)
which contain 433 time series in total. DeepAnT has
gained the state-of-the-art performance on most of the
data sets.
The rest of the paper is organized as follows. Section II provides an overview of existing methods for anomaly detection.
The state-of-the-art anomaly detection methods are mentioned and summarized in Section III, which are evaluated
and compared with the proposed technique in Section V.
Section IV provides details about the presented approach for
anomaly detection in time series data. Section V provides a
detailed evaluation of the DeepAnT along with a solid comparison with other state-of-the-art anomaly detection methods on different benchmarks. This section is further divided
into sub-sections which elaborates on the details of the used
data sets and the experimental settings of the state-of-theart methods. Finally, Section VI concludes the paper and
sketches direction for possible future work.
II. LITERATURE REVIEW OF ANOMALY
DETECTION METHODS
Due to the large variety of scenarios and algorithms,
anomaly detection problem is categorized in many ways.
The most common categorization is based on the level of
supervision required by the algorithm; supervised, semisupervised, and unsupervised. Another categorization, followed by Aggarwal , is based on the underlying used
methods. Examples of such methods for outlier detection are
probabilistic models, statistical models, linear models, proximity based models, and outlier detection in high dimensions.
In addition, anomaly detection methods also exist based on
different machine learning and deep learning techniques.
In this section, an overview of commonly used anomaly
detection techniques is provided. First, we talk about anomaly
detection techniques which are widely used for point anomalies. Then, an overview of anomaly detection techniques
designed for time series data is given. In the end, anomaly
detection techniques based on deep neural networks are
discussed.
Statistical anomaly detection techniques are most commonly employed to detect anomalies. k-NN anomaly
detection method is the simplest and most widely used unsupervised global anomaly detection method for point anomalies. This distance based algorithm calculates the anomaly
score based on k-nearest-neighbors distance . This technique is computationally expensive, highly dependent on the
value of k, and may fail if normal data points do not have
VOLUME 7, 2019
M. Munir et al.: DeepAnT: Deep Learning Approach for Unsupervised Anomaly Detection in Time Series
enough neighbors. Breunig et al. presented the most
widely used unsupervised method for local density-based
anomaly detection known as Local Outlier Factor (LOF).
In LOF, k-nearest-neighbors set is determined for each
instance by computing the distances to all other instances.
The basic assumption of this algorithm is that the neighbors of
the data instances are distributed in a spherical manner. However, in some application scenarios, where normal data points
are distributed in a linearly connected way, the spherical estimation of density becomes inappropriate . Tang et al. 
proposed an improved version of LOF known as Connectivity
based Outlier Factor (COF), which improves the linear structure taken into account. A shortcoming of this algorithm is
incorrect outlier score estimation in some cases when clusters
with different densities are very close to each other. In such
cases, instances at the border of the low-density clusters are
local outliers with respect to the high density clusters .
This shortcoming is further resolved in Inﬂuenced Outlierness (INFLO) algorithm.
Other than nearest neighbor based algorithms, clustering
based algorithms are also used for unsupervised outlier detection. As name suggests, Cluster-Based Local Outlier Factor (CBLOF) is a clustering based anomaly detection
algorithm, in which data points are clustered using k-means
(or any other) clustering algorithm. The anomaly score of
an instance is the distance to the next large cluster. As this
approach is based on clustering algorithm, the problem of
choosing the right number of clusters arises, and reproduction
of the same anomaly score also becomes impossible due to
non-deterministic nature of clustering algorithms.
Histogram-Based Outlier Score (HBOS) is another
statistical unsupervised anomaly detection algorithm. This
algorithm is computationally far less expensive as compared
to nearest neighbor and clustering based anomaly detection
methods. HBOS works on arbitrary data by offering a standard ﬁxed bin width histogram as well as dynamic bin width
(ﬁxed amount of items in each bin).
Semi-supervised and unsupervised variants of anomaly
detection algorithms exist based on One-Class Support Vector Machine (OCSVM). Unsupervised variant of OCSVM
was introduced by Amer et al. . Based on the idea
of , no prior training data are required for this technique.
It attempts to learn a decision boundary that achieves the maximum separation between the points and the origin. This technique is also used for detecting anomalies in activities of daily
life for example sleeping, sitting, and walking patterns .
Another time series anomaly detection technique based on
OCSVM was proposed by Hu et al. . In this technique, six
meta-features on actual univariate or multivariant time series
are deﬁned ﬁrst and then OCSVM is applied on meta-featurebased data space to ﬁnd abnormal states. In general, OCSVM
is sensitive to the outliers when there are no labels. It is also
used as a novelty detection technique. Liu et al. proposed
an approach to detect outliers based on Support Vector Data
Description (SVDD) .
Shyu et al. proposed an approach for anomaly
detection based on Principle Component Analysis (PCA),
where predictive model is constructed from the major
and minor principle components of the normal instances.
Kwitt and Hofmann 
this technique, in which Minimum Covariance Determinant (MCD) is used for calculation of covariance and
correlation matrix instead of standard estimators.
To incorporate time series characteristics, there exist different anomaly detection techniques which are designed to
ﬁnd anomalies speciﬁcally for streaming time series data.
Netﬂix open-sourced it’s anomaly detection function called
Robust Anomaly Detection (RAD) in 2015 . The function
is based on Robust Principle Component Analysis (RPCA)
to detect anomalies. To detect anomalous time series in
multi-terabyte data set, a disk aware algorithm is proposed
in . Statistical autoregressive-moving-average (ARMA)
model and its variations such as ARIMA and ARMAX are
used widely for time series prediction and anomaly detection. Yu et al. presented an anomaly detection technique for trafﬁc control in wireless sensor networks, which
is based on ARIMA model. They proposed that short step
exponential weighted average method is the key to make
better anomaly detection judgment in the network trafﬁc.
In the same domain, Yaacob et al. proposed a technique
for early warnings detection of Denial-of-Service (DoS)
attacks. By comparing actual network trafﬁc with the predicted patterns generated by ARIMA, anomalous behaviors
are identiﬁed.
Nowadays, Artiﬁcial Neural Networks (ANN) have been
successfully employed in a wide range of domains, such as
hand writing recognition, speech recognition, document analysis, activity recognition, and many more; mainly for classiﬁcation and prediction purposes. Different ANN architectures
have been successfully leveraged for time series analysis. The
anomaly detection technique proposed by Malhotra et al. 
is based on stacked LSTMs. Their predictive model is trained
on normal time stamps, which is further used to compute error
vectors for given sequences. Based on the error threshold,
a time series sequence is marked as normal or anomalous.
Chauhan and Vig used similar approach to detect anomalies in ECG data. They used RNN, augmented with LSTM,
to detect 4 different types of anomalies. Another deep learning based anomaly detection technique was recently proposed
by Kanarachos et al. , in which they combine wavelet
and Hilbert transform with deep neural networks. They aim
to detect anomalies in time series patterns.
Lipton et al. used LSTM to classify a time series as
normal or abnormal. They applied their technique on a clinical data set and demonstrated that LSTM trained on only
raw time series with target replication outperforms MLP
trained on hand engineered features. Zheng et al. used
CNN for multivariate time series classiﬁcation. They proposed Multi-Channel Deep CNN (MC-DCNN) where each
channel takes a single dimension of multivariate time series
VOLUME 7, 2019
M. Munir et al.: DeepAnT: Deep Learning Approach for Unsupervised Anomaly Detection in Time Series
data as input and learns the features individually. This is
followed by a layer of MLP to perform classiﬁcation. Experimental results show that MC-DCNN outperforms competing
baseline methods which are K-nearest neighbor (based on
Euclidean Distance and Dynamic Time Wrapping). All of
the aforementioned deep learning based time series anomaly
detection techniques are used for classifying a sequence or a
subsequence as normal or abnormal.
Autoencoder is a type of neural network which is
trained to reproduce its input. Typically, autoencoders are
used for dimensionality reduction which helps in classi-
ﬁcation and visualization tasks. Due to its efﬁcient data
encoding in an unsupervised manner, it is also gaining
popularity for anomaly and novelty detection problems.
Amarbayasgalan et al. proposed a novelty detection
technique based on deep autoencoders. Their approach gets
compressed data and error threshold from deep autoencoders
and apply density-based clustering on the compressed data
to get novelty groups with low density. Schreyer et al. 
also used deep autoencoders to detect anomalies in largescale accounting data in the area of fraud detection.
III. THE STATE-OF-THE-ART METHODS
USED FOR COMPARISON
This section summarizes the state-of-the-art methods used for
comparison with the proposed approach. Twitter Inc. opensourced it’s anomaly detection1 package in 2015, which is
based on Seasonal Hybrid ESD (S-H-ESD) algorithm .
This technique is based on Generalized Extreme Studentized
Deviate (ESD) test to handle more than one outliers, and
Seasonal and Trend Decomposition using Loess (STL) 
to deal with the decomposition of time series data and seasonality trends. Twitter Anomaly Detection can detect both
global and local anomalies. They have provided two anomaly
detection functions for detecting anomalies in seasonal
univariate time series:
(i) AnomalyDetectionTS function is used when input is a
series of < timestamp, value > pairs.
(ii) AnomalyDetectionVec function is used when input is a
series of observations.
Another anomaly detection method, EGADS , which
detects anomalies in large scale time series data was released
by Yahoo Labs.2 EGADS (Extensible Generic Anomaly
Detection System) consists of two main components: Time
series Modeling Module (TMM) and Anomaly Detection
Module (ADM). For a given time series, TMM models the
time series and produces an expected value at time stamp t.
ADM compares the expected value with the actual value and
computes number of errors E. Automatic threshold is determined on E and most probable anomalies are given as output.
There are seven time series models which are supported by
TMM and three anomaly detection models.
Detection:
 
twitter/AnomalyDetection/releases
2EGADS Java Library: 
ContextOSE is based on Contextual Anomaly Detection (CAD) method. As name indicates, CAD is based on
the contextual/local information of time series instead of
global information. This unsupervised approach takes a set of
similar time series and a window size. First, a subset of time
series is selected and then centroid of the selected time series
is calculated. The centroid values are further used along with
other time series features to predict the values of time series.
Numenta and NumentaTM , are two variants of
Numenta’s anomaly detection method based on Hierarchical
Temporal Memory (HTM). These techniques model the temporal sequences in a given data stream. At a given time t,
HTM makes multiple predictions for next time-stamp. These
predictions are further compared with actual value to determine if a value is normal or anomalous. For each time stamp,
anomaly likelihood score is calculated which is thresholded to
ﬁnally reach a conclusion regarding the presence or absence
of anomaly.
Skyline is a real-time anomaly detection method
developed by Etsy, Inc. This method ensembles votes from
different expert approaches. They make the use of different
simple detectors which vote to calculate the ﬁnal anomaly
Isolation Forest (iForest) is a model based anomaly
detection technique, which is built on the idea of random trees. Here, ‘isolation’ means separating an anomalous instance from the rest of the instances. iForest isolates
instances by random partitioning of a tree followed by random selection of the features. This random partitioning produces shorter paths for anomalies. The path length from the
root node to the terminating node is averaged over a forest of
random trees.
Twitter anomaly detection method is speciﬁcally designed
to detect seasonal anomalies in the context of social network
data. This technique performs good when anomalies arise in
periodic data which are not much different from the previous
data. But, it struggles in ﬁnding anomalies when a time series
trend is changing over time. Availability of different time
series models makes EGADS a good candidate for a general
purpose anomaly detection method. This method is capable of
adapting itself to different use-cases and its parallel architecture enables the detection of anomalies in real-time anomaly.
ContextOSE leverages the contextual information which is
very important to detect time series anomalies. NumentaTM
is capable of detecting spatial and temporal anomalies as it is
based on an online sequence memory algorithm. The results
provided in their study are based only on NAB score. This
score is designed to evaluate the early detection of anomalies
and cannot be directly used for point anomalies comparison.
IV. DeepAnT: THE PROPOSED APPROACH FOR
ANOMALY DETECTION IN TIME SERIES
The proposed DeepAnT consists of two modules. The ﬁrst
module, Time Series Predictor predicts time stamps for a
given horizon and the second module, Anomaly Detector is
responsible for tagging the given time series data points as
VOLUME 7, 2019
M. Munir et al.: DeepAnT: Deep Learning Approach for Unsupervised Anomaly Detection in Time Series
normal or abnormal. Deep learning has been employed in a
wide range of applications primarily because of its capability to automatically discover complex features without having any domain knowledge. This automatic feature learning
capability makes the neural network a good candidate for
time series anomaly detection problem. Therefore, DeepAnT
employs CNN and makes use of raw data. Also, it is robust
to variations as compared to other neural networks and statistical models. It is shown in literature , that LSTM
performs well on temporal data due to its capability to extract
long-term trends in the encountered time series. However,
we have shown in this study that CNN can be a good alternate
for uni-variate as well as multi-variate time series data due to
its parameter efﬁciency. Generally, CNN and LSTM are used
for time series classiﬁcation problem in literature , ,
but we are using CNN (and LSTM for a comparison) for a
time series regression problem.
A. TIME SERIES PREDICTOR
The predictor module of DeepAnT is based on CNN. CNN is
a type of artiﬁcial neural network which has been widely
used in different domains like computer vision and natural
language processing in a range of different capacities due to
its parameter efﬁciency. As the name indicates, this network
employs a mathematical operation called convolution. Normally, CNN consists of sequence of layers which includes
convolutional layers, pooling layers, and fully connected
layers. Each convolutional layer typically has two stages.
In the ﬁrst stage, the layer performs the convolution operation
which results in linear activations. In the next stage, a nonlinear activation function is applied on each linear activation.
In simplest form, convolution is a mathematical operation on
two functions of real valued arguments to produce a third
function. The convolution operation is normally denoted as
s(t) = (x ∗w)(t)
This new function s can be described as a smoothed
estimate or a weighted average of the function x(τ) at the
time-stamp t, where weighting is given by w(−τ) shifted
by amount t. In (1), function x is referred to as the input
and function w is referred to as the kernel. The output is
referred to as the feature map. One dimensional convolution
is deﬁned as:
x(τ)w(t −τ)
well-known
methods , , the output of a convolutional layer is further modiﬁed by a pooling function in a pooling layer.
A pooling function statistically summarizes the output of
the convolutional layer at a certain location based on its
neighbors. Most commonly used max-pooling operation is
used in DeepAnT which outputs the maximum activation in a
deﬁned neighborhood. Since there are more than one feature
maps, individually the pooling function is applied on all of
these feature maps.
After pair of convolutional and max-pooling layer, the ﬁnal
layer of connections in DeepAnT is a fully connected layer.
In this layer, each neuron from a previous layer is connected
to all output neurons. The activation for convolutional and
fully connected layers is given in (4) and (6) respectively
where k is deﬁned as ⌊FilterSize/2⌋.
In (4), al
ji refers to the activation of the jth neuron in the
lth layer at the ith input location of a convolutional layer.
Whereas, al
j refers to the activation of the jth neuron in the
lth fully connected layer in (6).
Like other artiﬁcial neural networks, a CNN uses training
data to adapt its parameters (weights and biases) to perform
the desired task. In DeepAnT, parameters of the network
are optimized using Stochastic Gradient Descent (SGD). The
idea of training or learning of a neural network is to reduce
a cost function C. In this predictor module, the cost function
computes the difference between the network’s predictions
and the desired prediction. In the learning process, that difference is minimized by adapting the weights and biases of
the network. The process of calculating the gradient, which is
required to adjust the weights and biases, is called backpropagation. It is obtained by calculating the partial derivatives
of the cost function with respect to any weight w or bias b
as ∂C/∂w and ∂C/∂b respectively. Network weights are
updated by SGD.
In order to leverage CNN for forecasting, time series data
need to be changed in a compatible form for the system to
operate on them. For each element xt at time stamp t in a
time series, next element xt+1 at time stamp t + 1 is used as
its label. Input data are transformed into several sequences
of overlapping windows of size w. This window size deﬁnes
the number of time stamps in history, which are taken into
account (referred as a history window). It also serves as the
context to xt. The number of time stamps required to be
predicted is referred to as prediction window (p_w). In some
studies, prediction window is also called as (Forecasting)
Horizon , .
Consider a time series:
{x0, x1, ..., xt−1, xt, xt+1, ...}
For w = 5 and p_w = 1, the sequence at index t will be as
xt−4, xt−3, xt−2, xt−1, xt →xt+1
In a regression problem as ours, the left hand side is treated as
input data and right hand side is treated as label. In this case,
VOLUME 7, 2019
M. Munir et al.: DeepAnT: Deep Learning Approach for Unsupervised Anomaly Detection in Time Series
FIGURE 1. DeepAnT architecture for time series prediction: A convolutional neural network with two convolutional layers, two max pooling, and a
fully connected layer.
it can be called as many_to_one prediction. When p_w > 1,
it can be called as many_to_many prediction.
1) ARCHITECTURE SUMMARY
We did extensive experiments to ﬁnalize the architecture and
its hyperparameters. Two convolutional layers, each followed
by a max-pooling layer, are used in this architecture as shown
in Fig. 1. The input layer has w input nodes as we have
converted the data into w vectors. Each convolution layer
is composed of 32 ﬁlters (kernels) followed by an elementwise activation function, ReLU as given in (7). Last layer of
the network is a fully connected (FC) layer in which each
neuron is connected to all the neurons in the previous layer.
This layer represents the network prediction for the next time
stamp. The number of nodes used in the output layer are equal
to p_w. In our case, we are predicting only the next time
stamp, so the number of output node is 1. In later sections
of this paper, when we are predicting a sequence instead of
a single data point, the number of nodes in output layer is
changed accordingly.
f (x) = max(0, x)
2) LOSS FUNCTION
Mean Absolute Error (MAE), given in (8) has been employed
as an indicator of the discrepancy between the actual yj and
the predicted ˆyj output. By reducing the error between the
actual and the predicted value, the network can learn to
predict the normal behavior of the time series. We normalized
each time series based on the training data.
B. ANOMALY DETECTOR
Once the prediction of the next time stamp xt+1 is made
by the Time Series Predictor, this module detects anomalies
in a given time series. The value predicted by the predictor
module is passed to this module and the difference between
actual and predicted value is calculated. Euclidean distance
given in (9) is used as a measure of the discrepancy.
(yt −y′t)2
where yt is actual value and y′
t is predicted value.
The Euclidean distance is used as anomaly score. A large
anomaly score indicates a signiﬁcant anomaly at the given
time stamp. A threshold, based on the time series type needs
to be deﬁned for this module, which is required in most of the
anomaly detection algorithms.
V. EXPERIMENTAL SETUPS
We have evaluated DeepAnT on 10 different data sets
(433 time series) and provided a detailed comparison with
15 anomaly detection methods which include several stateof-the-art methods. Both synthetic and real time series data
from different domains are used for experiments. We divide
our experimental setup into several parts, because different
anomaly detection methods in literature are evaluated on
different benchmarks based on different metrics. The division
of this section is based on Yahoo, NAB, classic anomaly
detection benchmark, and NASA space shuttle valve data sets
respectively. Detailed description of each benchmark and its
evaluation setup are also provided in this section.
A. EXPERIMENTAL SETTING I: YAHOO DATA SET
1) DATA SET DESCRIPTION
Yahoo Webscope3 data set is a publicly available data set
released by Yahoo Labs. This data set consists of 367 real and
synthetic time series with point anomaly labels. Each time
series contains 1, 420 - 1, 680 instances. This anomaly detection benchmark is further divided into four sub-benchmarks
namely A1 Benchmark, A2 Benchmark, A3 Benchmark, and
A4 Benchmark.
A1 Benchmark contains real Yahoo membership login
data, which tracks the aggregate status of logins on
Yahoo network , whereas, other three sub-benchmarks
contain synthetic data. A2Benchmark and A3Benchmark
contain only outliers, while A4Benchmark also contains
3ydata-labeled-time-series-anomalies-v1_0:
 
yahoo.com/catalog.php?datatype=s&did=70
VOLUME 7, 2019
M. Munir et al.: DeepAnT: Deep Learning Approach for Unsupervised Anomaly Detection in Time Series
FIGURE 2. Sample time series from each Yahoo sub-benchmark are shown in this figure. Actual streaming data are shown in blue,
whereas red vertical lines highlight anomalous data points based on the provided labels. Plots (a) and (b) have random seasonality, trend,
and noise, whereas, plots (c) and (d) have trends with three pre-specified seasonalities.
change-point anomalies. In synthetic data, outliers are present
on random positions. In each data ﬁle, there is a Boolean
attribute – label – indicating if the value at a particular time
stamp is considered as anomalous or normal. In addition
to value and label, A3Benchmark and A4Benchmark contain additional ﬁelds such as change-point, trend, noise, and
seasonality. However, we are discarding all the additional
attributes and only using value attribute for all the experiments. Fig. 2 shows time series samples from the four subbenchmarks. Actual data streams are shown in blue color and
anomalous data points are highlighted by red vertical line.
The main reason for selecting this data set for evaluation is
the availability of the point anomalies labels, which are not
commonly available in publicly available streaming data sets
(available at ).
2) EVALUATION METRIC AND EXPERIMENTAL SETUP
F-score is most commonly used singleton metric which
serves as an indicator of the model’s performance. Therefore,
we employed F-score (Eq. 10) as the evaluation metric for
our models. All the anomaly detection methods in this experimental setting are applied on each time series separately.
Average F-scores per sub-benchmark are reported for each
F-score = 2 · Precision · Recall
Precision + Recall
We run all the algorithms on same machine having Intel
Xeon(R) processor with 8 cores and NVIDIA GeForce
GTX 1070. It took on average 0.076 seconds to get anomaly
detection results on a given Yahoo Webscope time series
which have 852 - 1008 instances in test data.
a: DeepAnT PARAMETERS
We are using only 40% of each time series as training set
and rest of the 60% data as test set. We further split the
training set and use 10% of it for validation. Since this is an
unsupervised approach, we don’t use any label information in
training process. For each time series, only next time stamp
is predicted and marked as either normal or anomalous data
point. To compare the performance of CNN with LSTM in
the context of anomaly detection, we have also used LSTM
in DeepAnT’s Time Series Predictor module. We used the
same 40% training data scheme for training LSTM as we did
for CNN. For LSTM based model, we used two LSTM layers
(as done in ) of 32 memory cells each. For both techniques,
we used same w for a sub-benchmark.
Finding the best threshold is very important for evaluation. Normally, each time series has its own characteristics, and ﬁnding a generic threshold which works for all
of the time series is not a straightforward task. Since each
Yahoo sub-benchmark shares common properties, therefore,
we searched for the best threshold for each sub-benchmark
based on the validation data. To get an automatic threshold on
a single time series (a) parametric approach – K σ deviation
and (b) non-parametric approach – density distribution can be
used as explained in 
History Window (w) is another hyperparameter that plays
a vital role in improving the prediction model of DeepAnT.
Again, there is no generic ﬁxed window size which can be
used for all of the time series. For the purpose of reproducibility, we list the combination of thresholds and window
size yielding the best F-score in Table 1. We shortlisted the
window sizes of 25, 35, and 45 after hyperparameter optimization. One can use grid search to ﬁnd the best window
size for new time series. The knowledge of period size in a
VOLUME 7, 2019
M. Munir et al.: DeepAnT: Deep Learning Approach for Unsupervised Anomaly Detection in Time Series
TABLE 1. This table shows the selected history window and thresholds
which are used to evaluate DeepAnT on Yahoo data set.
particular time series can be a good starting point for the grid
search to ﬁnd the optimal window size. Fig. 3 shows the effect
of w on average F-score in each sub-benchmark. These plots
also show the importance of selecting the right number of w.
b: TWITTER ANOMALY DETECTION PARAMETERS
We used AnomalyDetectionTS function provided in Twitter
anomaly detection for A2Benchmark, A3Benchmark, and
A4Benchmark. For A1Benchmark, we used AnomalyDetectionVec function, because time stamps are replaced by integers with an increment of 1 in this data set by the publisher.
We used all default parameters of this method except the
following two:
(i) Alpha: This parameter deﬁnes the level of statistical
signiﬁcance with which to accept or reject anomalies.
We used three values for this parameter i.e. 0.05, 0.1,
(ii) Direction: This parameter deﬁnes the directionality
(positive or negative) of anomalies to be detected.
We used ‘both’, as anomalies can be in any direction in
this data set.
c: YAHOO EGADS PARAMETERS
We used Olympic Model in TMM and EGADS ExtremeLow-
DensityModel Outlier in ADM. Default values of all the
other parameters are used. Both Twitter anomaly detection
and EGADS calculate threshold themselves for each time
series and give time stamps or indexes (if input data do not
contain time stamp) of the anomalous data points as output.
To evaluate these two methods, we used the same 60% test
data of each time series which is used to evaluate DeepAnT.
3) RESULTS
DeepAnT anomaly detection results on a single time series
are shown in Fig. 4. In this ﬁgure, the actual series is depicted
in blue, the predictions on training data are depicted in yellow
(not used in reported results) and the predictions on test data
FIGURE 3. Average F-score of each Yahoo sub-benchmark is plotted per history window used in DeepAnT. Plots of three shortlisted windows per
sub-benchmark are shown. For A1Benchmark and A2Benchmark, w = 45 provides better average F-score, but for A3Benchmark and A4Benchmark,
w = 35 performs good. (1) A1Benchmark. (b) A2Benchmark. (c) A3Benchmark. (d) A4Benchmark.
FIGURE 4. An example of time series prediction and anomaly detection using DeepAnT is shown in this figure. Actual time
series is shown in blue. Predictions on training data are shown in yellow and predictions on test data are shown in red.
Vertical blue lines are anomalies ground truth, and vertical blue lines with dotes on it show point anomalies detected by
DeepAnT (true positive). DeepAnT F-score is 1 for this time series, whereas, EGADS and Twitter anomaly detection
F-score is 0.
VOLUME 7, 2019
M. Munir et al.: DeepAnT: Deep Learning Approach for Unsupervised Anomaly Detection in Time Series
TABLE 2. Average F-Score of Twitter Anomaly Detection, Yahoo EGADS, DeepAnT, and LSTM (DeepAnT using LSTM as time series predictor) on Yahoo data
set is given in this table. Bold F-scores are the best scores for corresponding Yahoo sub-benchmark.
are depicted in red. Vertical blue lines are anomalies ground
truth in training and testing data. Whereas, blue vertical
lines with dotes show point anomalies detected by DeepAnT
(true positive). It can be seen in this example that there are
anomalies in training data, but the network correctly captured
those data generating distribution disregarding the anomalies.
Predicted data points (red) are super imposed on the actual
time series in order to highlight the generalization capabilities
of our model. The observed time series is a combination of
periodicity and a trend. In such cases, anomaly is not just a
spike which is clearly distinguishable, but it can be a data
point which is locally deviated from the actual cycle. These
local deviations are hard to detect robustly. A couple of such
anomalies are magniﬁed in Fig. 4. It can also be seen in
this ﬁgure that w data points are missing from the beginning
of training and testing data sets. In both of the cases, this
is the starting sequence (history window) after which the
predictions are made.
On a detailed level, Table 2 shows a comparison of
DeepAnT with EGADS, Twitter, and LSTM (DeepAnT using
LSTM as a predictor) on the whole data set. DeepAnT
outperforms other methods in two sub-benchmarks and for
the rest, it is runner up. A1Benchmark consists of anomalies where there is no trend and seasonality effect. Mostly,
the anomalies are just the spikes in A1Benchmark. Since
we are computing F-score based on the sub-benchmark level
threshold, therefore, DeepAnT is not on top. Whereas, other
methods are computing threshold separately for each time
series. For A3Benchmark and A4Benchmark, F-scores for
DeepAnT are signiﬁcantly better than other methods. Twitter
anomaly detection didn’t work at all on A2Benchmark. This
table also shows that the parameter ‘Alpha’ does not have a
signiﬁcant impact in this case. It is also important to note
in this table that CNN based DeepAnT performs better than
LSTM on three sub-benchmarks and performs slightly poor
in one sub-benchmark. It shows that CNN could be used in the
cases when only limited amount of training data is available.
As DeepAnT’s Anomaly Detector module is dependent on
the Time Series Predictor module, so good forecasting performance results in better anomalous points detection. Fig. 5
shows a plot of actual values (ground truth) vs. predicted
values of a time series. Ideally, it should be a smooth diagonal
line because actual and predicted values should be same or
close to each other. But, in practice, it is an uneven diagonal
line due to minor errors in the prediction model. When there
is a difference between the actual and the predicted value,
FIGURE 5. For a single time series, actual time series values are plotted
against the time series predictions to show the accuracy of prediction
model. When actual and predicted values are same (or close to each
other), they form a diagonal line. Whereas, when actual and predicted
values are not same (or not close to each other), they end up away from
the diagonal line – which represent anomalies in the observed time
then the data point lies away from the diagonal line – showing
anomaly at a particular time stamp.
B. EXPERIMENTAL SETTING II: NAB DATA SET
1) DATA SET DESCRIPTION
NAB (Numenta Anomaly Benchmark) is a publicly
available streaming anomaly detection benchmark, released
by Numenta.4 This data set consists of 58 data streams,
each with 1, 000 - 22, 000 instances. This data set contains
streaming data from different domains including road trafﬁc,
network utilization, on-line advertisement, and internet traf-
ﬁc. The data set is labeled either based on the known root
cause of an anomaly or as a result of following the deﬁned
labeling procedure (described in ). Each data ﬁle consists
of time stamps and actual data values. Anomaly labels of each
data ﬁle are given in a separate set of ﬁles.
Although NAB provides a diverse labeled streaming
anomaly detection data set, there are a few challenges 
which make it hard to be used as a practical anomaly detection
benchmark. Each data point with ground truth anomaly label
is centered by a deﬁned anomaly window (10% the length
of a data ﬁle), which makes the ground truth label of normal
data points also as anomalous. For example, for an anomaly
window of size 350, all of the 350 data points in a data stream
are labeled anomalous, whereas there are just 2-3 actual
anomalies in the middle of this anomaly window. This kind
4 
VOLUME 7, 2019
M. Munir et al.: DeepAnT: Deep Learning Approach for Unsupervised Anomaly Detection in Time Series
TABLE 3. Comparative evaluation of different state-of-the-art algorithms and the proposed algorithm on 20 NAB time series from different domains.
Precision and recall are reported in this table.
of labeling helps in calculating good NAB score and leaves
the recall very low. NAB score is introduced in as an
anomaly detection score which is designed to reward early
anomaly detections and penalize later detections based on the
true and false detections within an anomaly window.
2) EXPERIMENTAL SETUP AND EVALUATION METRIC
A high NAB score shows that a particular algorithm has a
higher tendency to detect early anomalies. However, it does
not show how good that algorithm is in terms of true detections of anomalies and false alarms. In real life scenarios,
in addition to early anomaly detection, it is equally important
to detect correct number of anomalies. It is shown in 
that for some cases NAB score is high, but the precision
and recall is low, which means that the algorithm was not
able to detect maximum number of anomalies. Two levels
of same experiment are shown in this section. On the ﬁrst
level, we applied ﬁve time series anomaly detection algorithms, in addition to DeepAnT, on 20 NAB time series
from different domains. We picked same time series as
mentioned in . The algorithms are evaluated on the basis
of precision and recall. On the second level of this experiment, we have done the detailed analysis of 11 algorithms
and compared them with DeepAnT on whole NAB benchmark. The evaluated algorithms include Twitter’s Anomaly
Detection (Twitter ADVec), context OSE, Skyline, Numenta,
Multinomial
Entropy ,
changepoint
detection , EXPoSE , and simple sliding threshold.
All of these algorithms are used in same settings and with
same parameters as mentioned in , as they have done
extensive parameter tuning for each algorithm and used the
optimal parameters. We have used F-score for this detailed
evaluation so that an overall performance of an algorithm
can be reported. We are not reporting NAB score here
because we want to evaluate an algorithm on the basis of
the number of detected and rejected anomalies and the other
arguments made in . Since NAB benchmark consists
of multiple time series from different domains, therefore,
we have reported the mean F-score per domain.
3) RESULTS
Table 3 shows results of the ﬁrst level of our NAB experiment.
In most of the cases, high precision is followed by low recall.
The main reason of such low recall is the labeling mechanism
used in the NAB data set. It can be observed in this table
that each algorithm is capable of achieving the precision close
to 1, but recall stays in between 0.001 −0.36. In such cases,
algorithms detect 1−4 anomalies out of 346−401 anomalies.
Whereas, DeepAnT gives relatively better recall with equivalent precision as other algorithms (e.g., ec2-request-latencysystem-failure, speed-t4013). Table 4 shows mean F-scores of
a wide range of algorithms on the whole NAB data set (results
of second level). It can be noted here that DeepAnT outperforms other algorithms by signiﬁcant margin. DeepAnT is
2 −13 times better than the best performing algorithm for
different domains in the NAB data set.
VOLUME 7, 2019
M. Munir et al.: DeepAnT: Deep Learning Approach for Unsupervised Anomaly Detection in Time Series
TABLE 4. Comparative evaluation of the state-of-the-art anomaly detection methods on the NAB data set. Mean F-score is reported for each domain as
each domain contains different number of time series. DeepAnT out-performs all the other methods on whole data set (best mean F-score in bold).
TABLE 5. Data properties of the anomaly detection benchmarks.
C. EXPERIMENTAL SETTING III: CLASSIC
ANOMALY DETECTION BENCHMARK
1) DATA SET DESCRIPTION
In this section, we have used 7 natural and 1 synthetic data set
which are most commonly used in classic anomaly detection
setting. These multi-variant data sets are available at UCI
Machine Learning Repository and OpenML.5 Known
anomaly cases are marked as ground truth in these data
sets. We have removed all non-continuous attributes as done
in and . A brief description of each data set is given
1) Shuttle is NASA’s shuttle data set which is already
divided into train and test set by the publisher. As in ,
we have removed all the data instances which belong to
class 4. Rest of the classes except class 1, are treated as
anomalies.
2) Pima is a diabetes data set collected at the National
Institute of Diabetes and Digestive and Kidney Diseases, USA. This diagnostic data shows if a patient has
signs of diabetes or not. The target value ‘pos’ indicates
that a patient is suffering from diabetes and the corresponding data point is treated as anomalous.
3) ForestCover data set (also known as Covertype in UCI
repository) has target values in integers, which are different tree species. The data set is comprised of 54 features
in total, where 44 features are categorical. Therefore,
we only use 10 non-categorical features for training our
model. Out of the 7 target classes, we use 2 classes
as done in . All the instances from class 4 are
5 
considered anomalous, while instances from class 2 are
considered normal.
4) Ionosphere is a radar data set. The target attribute is
ionosphere, which is considered as ‘good’ if radar shows
evidence of some type of structure in the ionosphere,
otherwise it is considered as ‘bad’. ‘Bad’ ionospheres
are considered as anomalous.
5) HTTP is a subset of KDD CUP ‘99 network intrusion
data. A wide variety of anomalies (i.e. network attack)
were hand-injected in the normal network data. This data
set is used in a lot of studies. We have used this data set
in the standard way described in .
6) SMTP is also a subset of KDD CUP ‘99 network intrusion data. This data set is also used as described in .
7) Mulcross data set is obtained from a synthetic data
generator known as Mulcross . It generates a multivariate normal distribution with a selectable number of
anomaly clusters. We have used same settings (contamination ratio, distance factor, and anomaly clusters) for
this data set as mentioned in .
8) Mammography data set is publicly available at OpenML
and has 6 features. All the data instances with class 1 are
considered anomalous.
Properties of these data sets are shown in Table 5. The number of features and anomaly percentage varies signiﬁcantly
between these data sets. The target class (anomaly) of each
data set is also mentioned in this table.
2) EVALUATION METRIC AND EXPERIMENTAL SETUP
For the evaluation of different anomaly detection algorithms
and DeepAnT, AUC measure has been utilized. AUC is used
VOLUME 7, 2019
M. Munir et al.: DeepAnT: Deep Learning Approach for Unsupervised Anomaly Detection in Time Series
most commonly for reporting results of anomaly detection
techniques for mentioned data sets. The evaluation is done in
a semi-supervised fashion. In a semi-supervised setting (also
known as novelty detection ), training data consist of only
normal data. In this setting, all the anomalies from the training
set are removed in a pre-processing step. We compare the
results of three state-of-the-art anomaly detection methods
with DeepAnT on the aforementioned data sets. For model
based methods (iForest, OCSVM, and DeepAnT), 40% of the
actual data are used for training and rest for testing. To train
iForest model, we have used the default parameters i.e. ψ =
128 and t = 100, as suggested in . For OCSVM, we have
used RBF (Radial Basis Function) kernel. Commonly used
setting of k = 10 is applied for LOF. For DeepAnT, history
window of 2 is used, with the rest of the parameters being
TABLE 6. Comparison of the state-of-the-art anomaly detection methods
in semi-supervised (novelty detection) setting. DeepAnT performs best in
most of the cases (best AUC in bold).
3) RESULTS
Evaluation results of semi-supervised or novelty detection
setting are shown in Table 6. DeepAnT shows best AUCs
for most of the used data sets. In novelty detection setting,
OCSVM is considered the best method, however, DeepAnT
outperforms it in most of the data sets. These results show that
DeepAnT is capable of ﬁnding anomalies in multi-variant
data set too.
D. EXPERIMENTAL SETTING IV: DISCORD DETECTION
In the previous sub-sections, we have shown that DeepAnT
has the capability of detecting point anomalies as well as
contextual anomalies in streaming and non-streaming data.
In this section, we show that DeepAnT is also applicable
to time series discord detection. Time series discords are
subsequences of a longer time series, which are different from
rest of the subsequences . Discords are considered as the
anomalous sequences in a time series. For this experiment,
we have picked NASA space shuttle valve data set .
The time series in this data set are current measurements
on a Marotta MPV-41 series valve. These valves are used
to control ﬂow of fuel on the space shuttle. In this data set,
some subsequences are normal whereas a few are abnormal.
Originally, each subsequence consists of 1, 000 data points
at a rate of 1 ms per sample. But, we have down sampled
this data set by 70% to show that time series discord can be
detected on far less data using CNN. Normal subsequences
FIGURE 6. DeepAnT is also applicable to detect time series discords.
Normal subsequences of a time series are highlighted in blue color in
plot (a), whereas subsequence highlighted in red color is a discord. Lower
plot (b) shows corresponding point wise anomaly score of a subsequence,
which is accumulated (per subsequence) to detect a discord.
are shown in blue highlighted area of Fig. 6 (a), whereas
the abnormal subsequence is shown in red highlighted area.
Each subsequence is separated by a blue vertical line in
this ﬁgure. Instead of extracting all the subsequences and
converting them to some symbolic representation (as done
in ), we simply train our predictor model on normal
subsequences. Same DeepAnT architecture and parameters
are used here except the history window and the horizon.
On a given test data, the DeepAnT predictor tries to predict
the whole subsequence. By aggregating the anomaly score
calculated at each time stamp (shown in Fig. 6 (b)) of a
subsequence, an anomaly score of whole subsequence is
calculated. A discord is detected by applying a threshold on
the calculated subsequence anomaly score. In addition to the
discord detection, the behavior of subsequence which actually caused the discord can also be identiﬁed using DeepAnT.
It can be observed in the red highlighted area of Fig. 6 (b), that
the anomaly score of the corresponding abnormal behavior is
much higher which actually caused the discord.
VI. CONCLUSION
We presented a deep learning based approach for the detection of anomalies in time series data. Since the approach is
unsupervised, it requires no labels for anomalies. Instead,
the method models the regular data distribution and marks
data points which don’t conform to this model as anomalous.
The method is capable of handling minor data contamination
(less than 5%). This technique is accurate even in the detection of small deviations/anomalies in time series cycles which
are generally overlooked by other distance based and density
based anomaly detection techniques.
We evaluated DeepAnT on 10 different data sets comprising of 433 time series in total and provided a detailed
comparison with 15 state-of-the-art anomaly detection methods. To highlight the generic nature of the proposed technique, we tested it on real as well as synthetic datasets
from different domains including road trafﬁc , network utilization , on-line advertisement , internet
trafﬁc , space shuttle , and health . In most of
VOLUME 7, 2019
M. Munir et al.: DeepAnT: Deep Learning Approach for Unsupervised Anomaly Detection in Time Series
the cases, DeepAnT outperformed the state-of-the-art methods while remained on par with others. The proposed
approach is capable of detecting point anomalies and contextual anomalies in time series data even with periodic and
seasonality characteristics, and it is also applicable to time
series discords detection. DeepAnT demonstrated generalization capabilities on small as well as big data scenarios.
This approach can be practically applied in situations
where there is availability of a large amount of data without
any possibility of labeling it. However, poor data quality can
corrupt the data modelling phase. On the other hand, if the
contamination level is too high (more than 5%), the system
will try to model those instances, hence, considering them as
normal at inference time. Another limitation is the selection
of the network architecture and the corresponding hyperparameters. This can be circumvented by employing the recent
architecture search techniques trading human expertise
with compute time. One of the most severe limitation is
perhaps adversarial examples limiting the usage of this
method (and most of the prior data-driven methods) in security critical scenarios. Signiﬁcant strides have been made in
understanding and defending against these adversarial examples. However, no generic technique has yet been developed
to circumvent this issue.
We are working on extending the model and using the concept of domain adaptation and transfer learning for anomaly
detection in time series analysis. It will also be interesting to
evaluate the impact of incorporating different pre-processing
techniques on the ﬁnal time series forecast.
ACKNOWLEDGMENT
The authors would like to thank the reviewers for their
valuable feedback in improving the quality of this paper.
They also appreciate the technical support provided by
Mr. Muhammad Naseer Bajwa.