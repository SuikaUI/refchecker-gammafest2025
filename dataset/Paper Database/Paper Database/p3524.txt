Causal inference using invariant prediction:
identiﬁcation and conﬁdence intervals
Jonas Peters♭,♯, Peter B¨uhlmann♯and Nicolai Meinshausen♯
♭MPI for Intelligent Systems, T¨ubingen, Germany
♯Seminar f¨ur Statistik, ETH Z¨urich, Switzerland
{peters,buhlmann,meinshausen}@stat.math.ethz.ch
May 24, 2024
What is the diﬀerence of a prediction that is made with a causal model and a noncausal model? Suppose we intervene on the predictor variables or change the whole
environment. The predictions from a causal model will in general work as well under
interventions as for observational data.
In contrast, predictions from a non-causal
model can potentially be very wrong if we actively intervene on variables. Here, we
propose to exploit this invariance of a prediction under a causal model for causal
inference: given diﬀerent experimental settings (for example various interventions) we
collect all models that do show invariance in their predictive accuracy across settings
and interventions. The causal model will be a member of this set of models with high
probability. This approach yields valid conﬁdence intervals for the causal relationships
in quite general scenarios. We examine the example of structural equation models in
more detail and provide suﬃcient assumptions under which the set of causal predictors
becomes identiﬁable. We further investigate robustness properties of our approach
under model misspeciﬁcation and discuss possible extensions. The empirical properties
are studied for various data sets, including large-scale gene perturbation experiments.
Introduction
Inferring cause-eﬀect relationships between variables is a primary goal in many applications.
Such causal inference has its roots in diﬀerent ﬁelds and various concepts have
contributed to its understanding and quantiﬁcation. Among them are the framework of
potential outcomes and counterfactuals [cf. Dawid, 2000, Rubin, 2005]; or structural equation modelling [cf. Bollen, 1989, Robins et al., 2000, Pearl, 2009] and graphical modeling
[cf. Lauritzen and Spiegelhalter, 1988, Greenland et al., 1999, Spirtes et al., 2000], where
the book by Pearl provides a nice overview. Richardson and Robins make a
connection between the frameworks using single-world intervention graphs.
A typical approach for causal discovery, in the context of unknown causal structure, is
to characterise the Markov equivalence class of structures (or graphs) [Verma and Pearl,
1991, Andersson et al., 1997, Tian and Pearl, 2001, Hauser and B¨uhlmann, 2012], estimate
 
the correct Markov equivalence class based on observational or interventional data [Spirtes
et al., 2000, Chickering, 2002, Castelo and Kocka, 2003, Kalisch and B¨uhlmann, 2007, He
and Geng., 2008, Hauser and B¨uhlmann, 2015, cf.], and ﬁnally infer the identiﬁable causal
eﬀects or provide some bounds [Maathuis et al., 2009, VanderWeele and Robins, 2010,
cf.]. More recently, within the framework of structural equation models, interesting work
has been done for fully identiﬁable structures exploiting additional restrictions such as
non-Gaussianity [Shimizu et al., 2006], nonlinearity [Hoyer et al., 2009, Peters et al., 2014]
or equal error variances [Peters and B¨uhlmann, 2014]. Janzing et al. exploit an
independence between causal mechanisms.
We propose here a new method for causal discovery. The approach of the paper is
to note that if we consider all “direct causes” of a target variable of interest, then the
conditional distribution of the target given the the direct causes will not change when
we interfere experimentally with all other variables in the model except the target itself.
This does not necessarily hold, however, if some of the direct causes are ignored in the
conditioning.1 We exploit, in other words, that the conditional distribution of the target
variable of interest (often also termed “response variable”), given the complete set of corresponding direct causal predictors, has to remain identical under interventions on variables
other than the target variable. This invariance idea is closely linked to causality and has
been discussed, for example, under the term “autonomy” and “modularity” [Haavelmo,
1944, Aldrich, 1989, Hoover, 1990, Pearl, 2009, Sch¨olkopf et al., 2012] or also “stability”
[Dawid and Didelez, 2010] [Pearl, 2009, Sec. 1.3.2]. While it is well-known that causal
models have an invariance property, we try to exploit this fact for inference. Our proposed
procedure gathers all submodels that are statistically invariant across environments in a
suitable sense. The causal submodel consisting of the set of variables with a direct causal
eﬀect on the target variable will be one of these invariant submodels, with controlled high
probability, and this allows to control the probability of making false causal discoveries.
Our method is tailored for (but not restricted to) the setting where we have data
from diﬀerent experimental settings or regimes [Didelez et al., 2006]. For example, two
diﬀerent interventional data samples, or a combination of observational and interventional
data [cf. He and Geng., 2008] belong to such a scenario. For known intervention targets,
Cooper and Yoo incorporate the intervention eﬀects as mechanism changes [Tian
and Pearl, 2001] into a Bayesian framework and Hauser and B¨uhlmann modify
the greedy equivalence search [Chickering, 2002] for perfect interventions. Our framework
does not require to know the location of interventions. For this setting, Eaton and Murphy
 use intervention nodes with unknown children and Tian and Pearl consider
changes in marginal distributions, while Dawid make use of diﬀerent regimes
for a decision-theoretic approach. In contrast to these approaches, our framework does
not require the ﬁtting of graphical, structural equation or potential outcome models and
comes with statistical guarantees. Further advantages are indicated below in Section 1.2.
We primarily consider the situation with no hidden (confounder) variables that in-
ﬂuence the target variable. A rigorous treatment with hidden variables would be more
1We thank a referee for suggesting this succinct description of the main idea.
An example including three environments. The invariance (1) and (2) holds
if we consider S∗= {X2, X4}. Considering indirect causes instead of direct ones (e.g.
{X2, X5}) or an incomplete set of direct causes (e.g.
{X4}) may not be suﬃcient to
guarantee invariant prediction.
involved [see Richardson and Spirtes, 2002, for graphical language] but we provide an example with instrumental variables in Section 5 to illustrate that the method could also
work more generally in the context of hidden variables. We do not touch very much on
the framework of feedback models [Lauritzen and Richardson, 2002, Mooij et al., 2011,
Hyttinen et al., 2012, cf.], although a constrained form of feedback is allowed. It is an open
question whether our approach could be generalised to include general feedback models.
Data from multiple environments or experimental settings
We consider the setting where we have diﬀerent experimental conditions e ∈E and have
an i.i.d. sample of (Xe, Y e) in each environment, where Xe ∈Rp is a predictor variable
and Y e ∈R a target variable of interest. While the environments e ∈E can be created
by precise experimental design for Xe (for example by randomising some or all elements
of Xe), we are more interested in settings where such careful experimentation is not possible
and the diﬀerent distributions of Xe in the environments are generated by unknown and not
precisely controlled interventions. If a subset S∗⊆{1, . . . , p} is causal for the prediction
of a response Y , we assume that
for all e ∈E :
Xe has an arbitrary distribution and
Y e = g(Xe
εe ∼Fε and εe ⊥⊥Xe
where g : R|S∗| × R →R is a real-valued function in a suitable function class, Xe
vector of predictors Xe with indices in a set S∗and both the error distribution εe ∼Fε and
the function g are assumed to be the same for all the experimental settings. Equations (1)
and (2) can also be interpreted as requiring that the conditionals Y e | Xe
S∗and Y f | Xf
are identical for all environments e, f ∈E (this equivalence is proved in Section 6.1).
An example of a set of environments can be seen in Figure 1.
The invariance (1)
and (2) holds if the set S∗consists of all direct causes of the target variable Y and if we
do not intervene on Y , see Proposition 1.
Sections 5, 6.2 and 6.3 discuss violations and possible relaxations of this assumption.
New contribution
The main and novel idea is that we can use the invariance of the causal relationships
under diﬀerent settings e ∈E for statistical estimation, which opens a new road for causal
discovery and inference.
For the sake of simplicity, we will mostly focus on a linear model with a target or
response variable and various predictor variables, where Equation (1) is unchanged and (2)
then reads Y e = µ+Xeγ∗+εe, with µ a constant intercept term. The set S∗of predictors
is then given by the support of γ∗, that is S∗:= {k; γ∗
k ̸= 0}. Assumption 1 in Section 2
summarises all requirements. Proposition 1 shows that structural equation models with
the traditional notion of interventions [Pearl, 2009] satisfy Assumption 1 if we choose the
set S∗to be the parents of Y . Proposition 6 in Appendix D sheds some light on the
relationship to potential outcomes.
Obtaining conﬁdence statements for existing causal discovery methods is often diﬃcult as one would need to determine the distribution of causal eﬀects estimators after
having searched and estimated a graphical structure of the model. It is unknown how
one could do this, except relying on data-splitting strategies which have been found to
perform rather poorly in such a setting [B¨uhlmann et al., 2013]. We propose in Section
3 a new method for the construction of (potentially) conservative conﬁdence statements
for causal predictors S∗and of (potentially) conservative intervals for γ∗
j for j = 1, . . . , p
without a-priori knowing or assuming a causal ordering of variables. The method provides
conﬁdence intervals without relying on assumptions such as faithfulness or other identi-
ﬁability assumptions. If a causal eﬀect is not identiﬁable from the given data, it would
automatically detect this fact and not make false causal discoveries.
Another main advantage of our methodology is that we do not need to know how
the experimental conditions arise or which type of interventions they induce. We only
assume that the intervention does not change the conditional distribution of the target
given the causal predictors (no intervention on the target or a hidden confounder): it is
simply a device exploiting the grouping of data into blocks, where every block corresponds
to an experimental condition e ∈E.
We will show in Section 3.2 that such grouping
can be misspeciﬁed and the coverage statements are still correct. This is again a major
bonus in practice as it is often diﬃcult to specify what an intervention or change of
environment actually means. In contrast, for a so-called do-intervention for structural
equation models [Pearl, 2009] it needs to be speciﬁed on which variables it acts. Interesting
areas of applications include studies where observational data alone are not suﬃcient to
infer causal eﬀects but randomised studies are infeasible to conduct.
We believe that the method’s underlying invariance principle is rather general. However, for simplicity, we present our main results for linear Gaussian models, including some
settings with instrumental variables and hidden variables.
Organization
The invariance assumption is formulated and discussed in Section 2. Using this invariance
assumption, a general way to construct conﬁdence statements for causal predictors and
associated coeﬃcients is derived in Section 3.
Two speciﬁc methods are shown, using
regression eﬀects for various sets of predictors as the main ingredient. Identiﬁability results
for structural equation models are given in Section 4. The relation to instrumental variables
and the behaviour in presence of hidden variables is discussed in Section 5. We will discuss
extensions to the nonlinear model (2) in Section 6.1 and extenstions to intervened targets
in Section 6.2. Some robustness property against model misspeciﬁcations is discussed in
Section 6.3.
Simulations and applications to a biological gene perturbation data set and an educational study related to instrumental variables are presented in Section 7. We discuss the
results and provide an outlook in Section 8.
The methods are available in the package InvariantCausalPrediction for the R-language
[R Core Team, 2014].
Assumed invariance of causal prediction
We formulate here the invariance assumption and discuss the notion of identiﬁable causal
predictors. Let E denote again the index set of |E| possible interventional or experimental
settings. As stated above, we have variables (Xe, Y e) with a joint distribution that will
in general depend on the environment e ∈E. In the simplest case, |E| = 2, and we have
for example in the ﬁrst setting observational data and interventions of some (possibly
unknown) nature in the second setting.
Our discussion will rest on the following assumption. We assume the existence of a
model that is invariant under diﬀerent experimental or intervention settings. Let for any
set S ⊆{1, . . . , p}, XS be the vector containing all variables Xk, k ∈S.
Assumption 1 (Invariant prediction) There exists a vector of coeﬃcients γ∗= (γ∗
1, . . . , γ∗
with support S∗:= {k : γ∗
k ̸= 0} ⊆{1, . . . , p} that satisﬁes
for all e ∈E :
Xe has an arbitrary distribution and
Y e = µ + Xeγ∗+ εe,
εe ∼Fε and εe ⊥⊥Xe
where µ ∈R is an intercept term, εe is random noise with mean zero, ﬁnite variance and
the same distribution Fε across all e ∈E.
The distribution Fε is not assumed to be known in general. If not mentioned otherwise, we
will always assume that an intercept µ is added to the model (3). To simplify notation, we
will from now on refrain from writing the intercept down explicitly. We discuss the invariance assumption with the help of some examples in Figure 1 and 2; see also Appendix A
for another artiﬁcial example.
Some examples from the gene-knockout experiments in Kemmeren et al. ,
which will be discussed in more detail in Section 7.2. Each panel shows the distribution of
a target gene activity Y (on the respective y-axis), conditional on a predictor gene activity
X (shown on respective x-axis). Blue crosses show observational data and red dots show
interventional data.
The interventions do not occur on any of the shown genes.
conditional distribution of Y , given X, is not invariant for the examples in the ﬁrst row,
while invariance cannot be rejected for the two examples in the bottom row. Take the
example of the bottom left panel. The variance of the activity of gene YMR321C is clearly
higher for interventional than observational data, so we can reject that the invariance
assumption holds for the empty set S = ∅. However, if conditioning on the activity X
of gene YPL273W , the conditional distribution of the activity Y of gene YMR321C is
not signiﬁcantly diﬀerent between interventional and observational data, so that the set
S = {YPL273W } fulﬁls the invariance assumption (3), at least approximately.
We observe each unit i in only one experimental setting. The distribution of the error
εe is assumed to stay identical across all environments (though see Sections 6.2 and 6.3 for
approaches when this assumption is violated). It is in general not possible to estimate the
correlation between the noise variables εe
i for a single unit i in diﬀerent hypothetical
environments e and f, as the outcome is observed for only one environment [Dawid, 2006,
2012]. Knowledge of the correlation would be necessary to answer counterfactual questions
about the outcome. Knowledge of the correlation is not necessary for our method.
We deliberately avoid the term “causality” in Assumption 1 in order to keep it purely
mathematical. Proposition 1 establishes a link to causality by showing that the parents
of Y in a structural equation model (SEM) satisfy Assumption 1. In other words, the
variables that have a direct causal eﬀect on Y in a SEM form a set S∗for which Assumption 1 is satisﬁed. This must not necessarily be true for the variables that have an
(in)direct eﬀect on Y , i.e., the ancestors of Y . However, the set S∗is not necessarily
unique. For a given set of experimental conditions E, there can be multiple vectors γ∗that
satisfy (3). For example, if only observational data are available, i.e. all environments are
identical, it is apparent that for any model (3) the distribution Fε of the residuals εe does
not depend on e. If additionally (X, Y ) have a joint Gaussian distribution and X and Y
are not independent, for example, then one can ﬁnd a solution γ∗to (3) for every subset
S∗⊆{1, . . . , p}. The inference we propose works for any possible choice among the set of
solutions. We can at most identify the subset of S∗that is common among all possible
solutions of (3), see Section 4 for settings with complete identiﬁability.
It is perhaps easiest to think about the example of a linear structural equation model
(SEM), as deﬁned in Section 4.1, see also Figure 8 in Appendix A. We show in the following
proposition that the set of parents of Y in a linear SEM is a valid set S∗satisfying (3).
Proposition 1 Consider a linear structural equation model, as formally deﬁned in Section 4.1, for the variables (X1 = Y, X2, . . . , Xp, Xp+1), with coeﬃcients (βjk)j,k=1,...,p+1,
whose structure is given by a directed acyclic graph. The independence assumption on the
noise variables in Section 4.1 can here be replaced by the strictly weaker assumption that
j; j ∈AN(1)} for all environments e ∈E, where AN(1) are the ancestors of Y .
Then Assumption 1 holds for the parents of Y , namely S∗= PA(1), and γ∗= β1,· as
deﬁned in Section 4.1, under the following assumption:
for each e ∈E: the experimental setting e arises by one or several interventions
on variables from {X2, . . . , Xp+1} but interventions on Y are not allowed; here,
we allow for do-interventions [Pearl, 2009] (see also Section 4.2.1, and note
that the assigned values can be random, too), or soft-interventions [Eberhardt
and Scheines, 2007] (see also Sections 4.2.2 and 4.2.3).
Proof. It follows by the deﬁnition of the interventions in Section 4.2 and because the
interventions do not act on the target variable Y , that Y e = P
j∈PA(1) β1,jXe
e ∈E, where εe
1 is independent of XPA(1) and has the same distribution for all e ∈E.
Thus, Assumption 1 holds.
We remark that Proposition 1 can be generalised to include some hidden variables: the
exact statement is given in Proposition 4 in Appendix B.
Instead of allowing only do- or soft-interventions in Proposition 1, we can allow for
more general interventions which could change the structural equations for X2, . . . , Xp+1
(including for example a change in the graphical structure of the model among the variables X2, . . . , Xp+1), as long as the conditional distribution of Y e given Xe
S∗remains the
same. Such a weaker requirement is sometimes referred to as “modularity” [Pearl, 2009]
or what is called “autonomy” [Haavelmo, 1944, Aldrich, 1989]; structural equations are
autonomous if whenever we replace one of them due to an intervention, all other structural
equations do not change, they remain invariant. The remaining part of the condition in
Proposition 1 about excluding interventions on the target variable Y is often veriﬁable in
many applications; see Sections 6.2 and 6.3 for violations of this assumption.
Proposition 1 refers to standard linear SEMs that do not allow for feedback cycles.
We may, however, include feedback into the SEM and consider equilibrium solutions of
the new set of equations. The independence assumption between εe and Xe
S∗allows for
some feedback cycles in the linear SEM. The independence assumption prohibits, however,
cycles that include the target variable Y . We will leave it as an open question to what
extent the approach can be generalised to more general forms of feedback models.
It is noteworthy that our inference is valid for any set that satisﬁes Assumption 1 and
not only parents in a linear SEM. For the following statements we do not specify whether
the set S∗refers to the set of parents in a linear SEM or any other set that satisﬁes (3),
as the conﬁdence guarantees will be valid in either case. Proposition 6 in Appendix D
discusses some relationship to the potential outcome framework.
Plausible causal predictors and identiﬁable causal predictors
In general, (γ∗, S∗) is not the only pair that satisﬁes the assumption of invariance in (3).
We therefore deﬁne for γ ∈Rp and S ⊆{1, . . . , p} the null hypothesis H0,γ,S(E) as
H0,γ,S(E) :
γk = 0 if k /∈S
∃Fε such that for all e ∈E
Y e = Xeγ + εe, where εe ⊥⊥Xe
S and εe ∼Fε.
As stated above, we have dropped the constant intercept notationally. The variables
that appear in any set S that satisﬁes H0,S(E), we call plausible causal predictors.
Deﬁnition 1 (Plausible causal predictors and coeﬃcients)
(i) We call the variables S ⊆{1, . . . , p} plausible causal predictors under E if the following null hypothesis holds true:
∃γ ∈Rp such that H0,γ,S(E) is true.
(ii) The identiﬁable causal predictors under interventions E are deﬁned as the following
subset of plausible causal predictors
S : H0,S(E) is true
{k : γk ̸= 0}.
Here, Γ(E) is deﬁned in (13) below (the second equation in (6) can be ignored for now).
Under Assumption 1, H0,γ∗,S∗(E) is true and therefore S∗are plausible causal predictors,
that is H0,S∗(E) is correct, too. The identiﬁable causal predictors are thus a subset of the
true causal predictors,
This fact will guarantee the coverage properties of the estimators we deﬁne below. Furthermore, the set of identiﬁable causal predictors under interventions E is growing monotonically if we enlarge the set E,
S(E1) ⊆S(E2)
for two sets of environments E1, E2 with
In particular, if |E| = 1 (for example, there is only observational data), then S(E) = ∅
because H0,∅(E) will be true.
The set of identiﬁable causal predictors under a single
environment is thus empty and we make no statement as to which variables are causal.
In Section 4, we examine conditions for structural equation models (see Proposition 1)
under which S(E) is identical to the parents of Y we thus have complete identiﬁability of
the causal coeﬃcients. In practice, the set E of experimental settings might often be such
that S(E) identiﬁes some but not all parents of Y in a SEM.
Plausible causal coeﬃcients
We have seen that the null hypothesis (4) H0,γ,S(E) is in general not only fulﬁlled for γ∗
and its support S∗but also potentially for other vectors γ ∈Rp. This is true especially if
the experimental settings E are very similar to each other. If we consider again the extreme
example of just a single environment, |E| = 1, and a multivariate Gaussian distribution
for (X, Y ), we can ﬁnd for any set S ⊆{1, . . . , p} a vector γ with support S that fulﬁlls
the null hypothesis H0,γ,S(E), namely by using the regression coeﬃcient when regressing
Y on XS. If the interventions that produce the environments E are stronger and we have
more of those environments, the set of vectors that fulﬁll the null becomes smaller. We
call vectors that fulﬁll the null hypothesis plausible causal coeﬃcients.
Deﬁnition 2 (Plausible causal coeﬃcients) We deﬁne the set ΓS(E) of plausible causal
coeﬃcients for the set S ⊆{1, . . . , p} and the global set Γ(E) of plausible causal coeﬃcients
under E as
ΓS(E) := {γ ∈Rp :
H0,γ,S(E) is true},
S⊆{1,...,p}
Γ(E1) ⊇Γ(E2)
for two sets of environments E1, E2 with
The global set of plausible causal coeﬃcients Γ(E) is, in other words, shrinking as we
enlarge the set E of possible experimental settings.
The null hypothesis H0,S(E) in (5) can be simpliﬁed. Writing
βpred,e(S) := argminβ∈Rp:βk=0 if k/∈S E(Y e −Xeβ)2
for the least-squares population regression coeﬃcients when regressing the target of interest
onto the variables in S in experimental setting e ∈E, we obtain the equivalent formulation
of the null hypothesis for set S ⊆{1, . . . , p},
∃β ∈Rp and ∃Fε such that for all e ∈E we have
βpred,e(S) ≡β and Y e = Xeβ + εe, where εe ⊥⊥Xe
S and εe ∼Fε.
We conclude that
if H0,S(E) is false
βpred,e(S)
otherwise.
In other words, the set of plausible causal coeﬃcients for a set S is either empty or
contains only the population regression vector. We will make use of this fact further below
in Section 3 when computing empirical estimators.
Estimation of identiﬁable causal predictors
We would like to estimate the set S(E) of identiﬁable causal predictors (6) when observing the distribution of (Xe, Y e) under diﬀerent experimental conditions e ∈E. At the
same time, we might be interested in obtaining conﬁdence intervals for the linear causal
coeﬃcients.
Recall again the deﬁnition (5) of the null hypothesis H0,S(E). Suppose for the moment
that a statistical test for H0,S(E) with size smaller than a signiﬁcance level α is available. Then the construction of an estimator ˆS(E) and conﬁdence sets ˆΓ(E) for the causal
coeﬃcients can work as follows.
Generic method for invariant prediction
1) For each set S ⊆{1, . . . , p}, test whether H0,S(E) holds at level α (we will discuss
later concrete examples).
2) Set ˆS(E) as
S:H0,S(E) not rejected
3) For the conﬁdence sets, deﬁne
S⊆{1,...,p}
H0,S(E) can be rejected at level α
otherwise.
Here, ˆC(S) is a (1 −α)-conﬁdence set for the regression vector βpred(S) that is
obtained by pooling the data.
As an example, consider again Figure 2. Taking the example in the bottom left panel,
we cannot reject H0,S(E) for S = {YPL273W }. Hence we can see already from this plot
that ˆS(E) is either empty or that ˆS(E) = {YPL273W }. The latter case happens if no
further set of variables is accepted that does not include the activity of gene YPL273W
as predictor.
A justiﬁcation for pooling the data in (14) is given in Section 3.2. (The construction
is also valid if the conﬁdence set is based only on data from a single environment, but a
conﬁdence set for the pooled data will be smaller in general.) This deﬁnes a whole family
of estimators and conﬁdence sets as we have ﬂexibility in the test we are using for the null
hypothesis (5) and how the conﬁdence interval ˆC(S) is constructed.
If the test and pooled conﬁdence interval have the claimed size and coverage probability,
we can guarantee coverage of the true causal predictors and the true causal coeﬃcient, as
shown below in Theorem 1.
Theorem 1 Assume that the estimator ˆS(E) is constructed according to (12) with a
valid test for H0,S(E) for all sets S ⊆{1, . . . , p} at level α in the sense that for all S,
supP : H0,S(E) true P[H0,S(E) rejected] ≤α. Consider now a distribution P over (Y, X) and
consider any γ∗and S∗such that Assumption 1 holds. Then, ˆS(E) satisﬁes
 ˆS(E) ⊆S∗
If, moreover, for all (γ, S) that satisfy Assumption 1, the conﬁdence set ˆC(S) in (14)
satisﬁes P[γ ∈ˆC(S)] ≥1 −α then the set ˆΓ(E) (13) has coverage at least level 1 −2α:
Proof. The ﬁrst property follows immediately since
 ˆS(E) ⊆S∗
S:H0,S(E) not rejected
H0,S∗(E) not rejected
where the last inequality follows by the assumption that the test for H0,S is valid at level α
for all sets S ⊆{1, . . . , p}. The second property follows since
H0,S∗(E) rejected or γ∗/∈ˆC(S∗)
≤α + α = 2α.
The conﬁdence sets thus have the correct (conservative) coverage. The estimator of the
causal predictors will, with probability at least 1 −α, not erroneously include non-causal
predictors. Note that the statement is true for any set of experimental or intervention
settings. In the worst case, the set ˆS(E) might be empty but the error control is valid
nonetheless.
Since Theorem 1 holds for any γ∗, S∗which fulﬁl Assumption 1, and assuming the
setting of Proposition 1, we obtain the corresponding conﬁdence statements for the causal
coeﬃcients and causal variables in a linear structural equation model, that is for γ∗= β1,·
and S∗= PA(1) in the notation of Proposition 1.
(i) We obtain the following empirical version of (6):
{k : γk ̸= 0} =
S:H0,S(E) not rejected at α
provided that if H0,S(E) is not rejected, then for all γ ∈ˆΓS(E) we have supp(γ) ⊆S
and H0,supp(γ)(E) is not rejected either.
(ii) In (14), we have constructed conﬁdence sets ˆΓS(E) based on a test for H0,S(E). Alternatively, conﬁdence sets ˆΓS(E) may be available that are not based on a test procedure
for H0,S(E). In this case, we may take them as a starting point and deﬁne ˆS(E) using the ﬁrst equality in (15), instead of (12). Analogously to Theorem 1, the correct
coverage property of ˆΓS∗(E) then implies conﬁdence statements for ˆΓ(E) and ˆS(E).
Two concrete proposals
The missing piece in the generic procedure given by (12) and (13) is a test for H0,S(E)
that is valid at level α for any given set of variables S ⊆{1, . . . , p} and thus implies
H0,S∗(E) rejected
To specify a concrete procedure and derive its statistical properties, we assume throughout
the paper that the data consist of n independent observations. Within each experimental
setting e, we assume that we receive ne independent and identically distributed data points
from (Xe, Y e) and thus, P
e∈E ne = n.
We now propose a way to construct such a test, but acknowledge that diﬀerent choices
are possible. Our construction will be based on the fact that the causal coeﬃcients are
identical to the regression eﬀects in all experimental settings e ∈E if we consider only
variables in the set S∗of causal predictors.
For experimental setting e ∈E and a subset S of variables, deﬁne the regression
coeﬃcients βpred,e(S) ∈Rp as above in (9). Deﬁne further the population residual standard
deviations when regressing Y e on variables Xe
σe(S) := [E(Y e −Xeβpred,e(S))2]1/2.
These deﬁnitions are population quantities.
The corresponding sample quantities are
denoted with a hat. As mentioned above, under Assumption 1, for S = S∗, the regression
eﬀects are identical to the causal coeﬃcients: for all e ∈E,
βpred,e(S∗) ≡γ∗
σe(S∗) ≡Var(Fε)1/2.
To get a test valid at level α for all subsets S of predictor variables, we ﬁrst weaken H0,S(E)
in (10) to
˜H0,S(E) :
∃(β, σ) ∈Rp×R+ such that βpred,e(S) ≡β and σe(S) ≡σ for all e ∈E. (16)
The null hypothesis ˜H0,S(E) is true whenever the original null hypothesis (10) is true. As
in (14), we set
˜H0,S(E) can be rejected at level α
otherwise.
We now give a concrete example which we will use in the numerical examples under
the assumption of Gaussian errors and that the design matrix Xe of all ne samples in
experimental setting e ∈E has full rank. (We write the design matrix in bold letters, as
opposed to the random variables Xe.) The whole procedure is then a speciﬁc version of
the general procedure given further above, where we use a speciﬁc test in the ﬁrst step
(the second step is unchanged).
Method I: Invariant prediction using test on regression coeﬃcients
1) For each S ⊆{1, . . . , p} and e ∈E:
(a) Let Ie with ne = |Ie| be the set of observations where experimental setting e ∈
E was active.
Likewise, let I−e = {1, . . . , n} \ Ie with n−e := |I−e| be the set of
observations when using only observations where experimental setting e ∈E was not
active. Let Xe,S be the ne × (1 + |S|)-dimensional matrix when using all samples in
Ie and all predictor variables in S, adding an intercept term to the design matrix as
mentioned previously. If S = ∅, the matrix consists only of a single intercept column.
Analogously, X−e,S is deﬁned with the samples in I−e. Let ˆYe be the predictions for
observations in set Ie when using the OLS estimator computed on samples in I−e and
let D := Ye −ˆYe be the diﬀerence between the actual observations Ye on Ie and the
predictions.
(b) Under Gaussian errors, if (16) is true for a set S, then [Chow, 1960]
∼F(ne, n−e −|S| −1),
where ˆσ2 is the estimated variance on the set I−e on which the OLS estimator is
computed. The covariance matrix ΣD is given by
ΣD = 1ne + Xe,S(Xt
−e,SX−e,S)−1Xt
letting 1n be the identity matrix in n-dimensions. For any set S, we reject the null
hypothesis ˜H0,S(E) if the p-value of (17) is below α/|E| for any e ∈E.
2) As in the generic algorithm, using (12).
3) If we do reject a set S we set ˆΓS(E) = ∅.
Otherwise, we set ˆΓS(E) to be a (1 −α)conﬁdence interval for βpred(S) when using all data simultaneously. For simplicity, we will
use a rectangular conﬁdence region where the constraint for βpred(S)k is identically 0 if
k /∈S and for coeﬃcients in S given by (ˆβpred(S))S±t1−α/(2|S|),n−|S|−1·ˆσ diag((Xt
where XS is the design matrix of the pooled data when using variables in S, t1−α;q is the
(1−α)-quantile of a t-distribution with q degrees of freedom, and ˆσ2 the estimated residual
A justiﬁcation of the pooling in step 3 is given in Section 3.2. The procedure above
has some shortcomings. For example, the inversion of the covariance matrix in (17) might
be too slow if we have to search many sets and the sample size is large. One can then
just work with a random subsample of the set Ie of size, say, a few hundred, to speed
up the computation. It also depends on the assumption of Gaussian errors, although this
could be addressed by using rank tests or other nonparametric procedures. Lastly, it is
not straightforward to extend this approach to classiﬁcation and nonlinear models.
We thus provide a second possibility. The fast approximate version below is not ﬁtting a
model on each experimental setting separately as in Method I, but is just ﬁtting one global
model to all data and comparing the distribution of the residuals in each experimental
setting. This is ignoring the sampling variability of the coeﬃcient estimates but leads to
a faster procedure.
Method II: Invariant prediction using fast(er) approximate test on
1) For each S ⊆{1, . . . , p} and e ∈E:
(a) Fit a linear regression model on all data to get an estimate ˆβpred(S) of the optimal
coeﬃcients using set S of variables for linear prediction in regression. Let R = Y −
X ˆβpred(S).
(b) Test the null hypothesis that the mean of R is identical for each set Ie and e ∈E,
using a two-sample t-test for residuals in Ie against residuals in I−e and combing
via Bonferroni correction across all e ∈E. Furthermore, test whether the variances
of R are identical in Ie and I−e, using an F-test, and combine again via Bonferroni
correction for all e ∈E. Combine the two p-values of equal variance and equal mean
by taking twice the smaller of the two values. If the p-value for the set S is smaller
than α, we reject the set S.
2) As in the generic algorithm, using (12).
3) If we do reject a set S we set ˆΓS(E) = ∅. Otherwise, we set ˆΓS(E) to be the conventional
(1 −α)-conﬁdence region for βpred(S) when using all data simultaneously. For simplicity,
we will use rectangular conﬁdence regions, exactly as in step 3 of Method I.
Besides a computational advantage, the method can also easily be extended to nonlinear and logistic regression models. For logistic regression, one can test the residuals
R = Y −ˆf(X) for equal mean across the experimental settings, for example.
Data pooling
So far, we have assumed that the set E of experimental settings is given and ﬁxed. An
experimental setting e ∈E can for example correspond to
(i) observational data;
(ii) a known intervention of a certain type at a known variable;
(iii) a random intervention at an unknown and random location;
(iv) observational data in a changed environment.
We have used data pooling in Methods I and II to get conﬁdence intervals for the regression
coeﬃcients (which is not necessary but increases power in general).
A justiﬁcation of
this pooling is in order.
The joint distribution of (Xe
S∗, Y e) will vary in general with
e ∈E. Under Assumption 1, however, the conditional distribution Y e | Xe
S∗is constant as
a function of e ∈E, see Section 6.1. As long as our tests and conﬁdence intervals require
only an invariant conditional distribution for S∗(which is the case for the procedures given
above), we can pool data from various e ∈E.
To make it more precise, assume there is a set of countably many experimental settings
or interventions J and (Xj, Y j) follow a certain distribution Fj for each j ∈J . Then
each encountered experimental setting e can be considered to be equivalent to a probability
mixture distribution over the experimental settings in J , that is
j corresponds to the probability that an observation under setting e follows the
distribution Fj.
We can then pool two experimental settings e1 and e2, for example,
thereby creating a new experimental setting with the averaged weights (we1 + we2)/2.
Pooling is a trade-oﬀbetween identiﬁability and statistical power, assuming that Assumption 1 holds for the settings from J . The richer the set E of experimental settings,
the smaller the set Γ(E) of plausible causal coeﬃcients will be and the larger the set of
identiﬁable causal predictors S(E). By pooling data, we make the set of identiﬁable causal
variables smaller, that is S(E) is shrinking as we reduce the number |E| of diﬀerent settings. The trade-oﬀcan either be settled a-priori (for example if we know that we have
“suﬃciently” many observations in each known experimental setting, we would typically
not pool data) or one can try various pooling procedures and combine all results, after
adjusting the level α to account for the increased multiplicity of the associated testing
problem. Section 4 discusses conditions on the interventions under which all true causal
eﬀects are identiﬁable.
Splitting purely observational data
In the case of purely observational data, the null hypothesis (4) is correct for γ = 0 and
S = ∅. Therefore, S(E) = ∅and ˆS(E) = ∅with high probability, i.e., our method stays
conservative and does not make any causal claims.
In a reverse operation to data pooling across experiments, the question arises whether
we can identify the causal predictors by artiﬁcially separating data into several blocks
although the data have been generated under only one experimental setting (e.g. the data
are purely observational). If the distribution is generated by a SEM (see Section 4.1), we
may consider a variable U that is not Y and known to be a non-descendant of the target
variable Y , that is, there is no directed path from Y to U, for example as it precedes Y
chronologically. (This is similar as in an instrumental variable setting, see Section 5.) We
may now split the data by conditioning on this variable U or any function h(U). Our
method then still has the correct coverage for any function h(U) as long as U is a nondescendant of Y , because the conditional distribution of Y given its true causal predictors
XS∗does not change and for all z in the image of h,
Y | XS∗, h(U) = z
Note that U might or might not be part of the set XS∗but we expect the method to have
more power if it is not. Equation (18) is a direct implication of the local Markov property
that is satisﬁed for a SEM [Pearl, 2009, Theorem 1.4.1]. The conﬁdence intervals remain
valid but the implication on (partial) identiﬁability of the causal predictors remains as an
open question.
Even without data splitting, there might still be some directional information in the
data set that is not exploited by our method; this may either be information in the
conditional independence structure [Spirtes et al., 2000, Chickering, 2002], information
from non-Gaussianity [Shimizu et al., 2006], nonlinearities [Hoyer et al., 2009, Peters et al.,
2014, B¨uhlmann et al., 2014], equal error variances [Peters and B¨uhlmann, 2014] or shared
information between regression function and target variable [Janzing et al., 2012]. Our
method does not exploit these sources of identiﬁability. We believe, however, that it might
be possible to incorporate the identiﬁability based on non-Gaussianity or nonlinearity.
Computational requirements
The construction of the conﬁdence regions for the set of plausible causal coeﬃcients and
the identiﬁable causal predictors requires to go through all possible sets of variables in
step 1) of the procedures given above. The computational complexity of the brute force
scheme seems to grow super-exponentially with the number of variables.
There are several aspects to this issue. Firstly, we often do not have to go through
all sets of variables.
If we are looking for a non-empty set ˆS(E), it is worthwhile in
general to start generating the conﬁdence regions ˆΓS(E) for the empty set S = ∅, then
for all singletons and so forth. If the empty set is not rejected, we can stop the search
immediately, as then ˆS(E) = ∅. If the empty set is rejected, we can stop early as soon as
we have accepted more than one set S and the sets have an empty overlap (as ˆS = ∅in
this case no matter what other sets are accepted). The method can thus ﬁnish quickly if
ˆS = ∅. However, in a positive case (where we do hope to get a non-empty conﬁdence set)
we will still have to go through all sets of variables eventually. There are two options to
address the computational complexity.
The ﬁrst option is to limit a-priori the size of the set of causal predictors. Say we are
willing to make the assumption that the set of causal variables is at most s < p. Then we
just have to search over all subsets of size at most s and incur a computational complexity
that grows like O(ps) as a function of the number of variables.
A second option (which can be combined with the ﬁrst one) is an adaptation of the
conﬁdence interval deﬁned above, in which the number of variables is ﬁrst reduced to a
subset of small size that contains the causal predictors with high probability. Let ˆB ⊆
{1, . . . , p} be, for the pooled data, an estimator of the variables with non-zero regression
coeﬃcient when using all variables as predictors.
For example, ˆB could be the set of
variables with non-zero regression coeﬃcient with square-root Lasso estimation [Belloni
et al., 2011], Lasso [Tibshirani, 1996] or boosting [Schapire et al., 1998, Friedman, 2001,
B¨uhlmann and Yu, 2003] with cross-validated penalty parameter. If the initial screening is
chosen such that the causal predictors are contained with high probability, P
1 −α, and we construct the conﬁdence set ˆS(E) as above, but just letting S be a subset
of ˆB instead of {1, . . . , p}, it will have coverage at least 1 −2α. Suﬃcient assumptions
of such a coverage (or screening) condition are discussed in the literature [e.g. B¨uhlmann
and van de Geer, 2011].
If the second option is combined with the ﬁrst option, the
computational complexity would then scale like O(qs) instead of O(ps), where q is the
maximal size of the set ˆB of selected variables. For the sake of simplicity, we will not
develop this argument further here but rather focus on the identiﬁability results for the
low(er)-dimensional case.
Identiﬁability results for structural equation models
The question arises whether the proposed conﬁdence sets for the causal predictors can
recover an assumed true set of causal predictors. Such identiﬁability issues are discussed
next. Sections 4.1 and 4.2 describe possible data generating mechanisms and Section 4.3
provides corresponding identiﬁability results.
Linear Gaussian SEMs
We consider linear Gaussian structural equation models (SEMs) [e.g. Wright, 1921, Duncan, 1975]. We assume that each element e ∈E represents a diﬀerent interventional setup.
Let the ﬁrst block of data (e = 1) always correspond to an “observational” (linear) Gaussian SEM. Here, a distribution over (X1
1, . . . , X1
p+1) is said to be generated from a Gaussian
j = 1, . . . , p + 1,
j ), j = 1, . . . , p + 1. The corresponding directed graph is obtained by
drawing arrows from variables X1
k on the right-hand side of (19) with β1
jk ̸= 0 to the
variables X1
j of the left-hand side. This graph is assumed to be acyclic. Without loss
of generality let us assume that Y 1 := X1
1 is the target variable and we write X :=
(X2, . . . , Xp+1). We further assume that all variables are observed; this assumption can
be weakened, see Proposition 4 in Appendix B and Section 5.
The parents of Y are given by
PA(Y ) = PA(1) = {k ∈{2, . . . , p + 1} : β1
1,k ̸= 0}.
Here, we adapt the usual notation of graphical models [e.g. Lauritzen, 1996]. For example,
we write PA(j), DE(j), AN(j) and ND(j) for the parents, descendants, ancestors and
non-descendants of Xj, respectively.
Let us assume that the other data blocks are generated by a linear SEM, too:
j = 1, . . . , p + 1,
Assumption 1 states that the inﬂuence of the causal predictors remains the same under
interventions, that is Y e = Xeγ∗+ ε1
1 for γ∗= (β1
1,2, . . . , β1
1,p+1)t and εe
1 for e ∈E.
The other coeﬃcients βe
j,k and noise variables εe
j, j ̸= 1, however, may be diﬀerent from
the ones in the observational setting (19). Within this setting, we now deﬁne various sorts
of interventions.
Interventions
We next discuss three diﬀerent types of interventions that all lead to identiﬁability of the
causal predictors for the target variable.
Do-interventions
These types of interventions correspond to the classical do-operation from Pearl [2009,
e.g.]. In the e-th experiment, we intervene on variables Ae ⊆{2, . . . , p + 1} and set them
to values ae
j ∈R, j ∈Ae. For the observational setting e = 1, we have A1 = ∅. We specify
the model (20), for e ̸= 1, as follows:
The do-interventions correspond to ﬁxing the intervened variable at a speciﬁc value. The
following two types of interventions consider “softer” forms of interventions which might
be more realistic for certain applications.
Noise interventions
Instead of ﬁxing the intervened variable at a speciﬁc value, noise interventions correspond
to “disturbing” the variable by changing the distribution of the noise variable. This is an
instance of what is sometimes called a “soft intervention” [e.g. Eberhardt and Scheines,
2007]. We now consider a kind of soft intervention, in which we scale the noise distributions
of variables Ae ⊆{2, . . . , p + 1} by a factor Ae
j, j ∈Ae. Alternatively, we may also shift
the error distribution by a variable Ce
j . More precisely, we specify the model in (20), for
e ̸= 1, as follows:
for all j,
The factors Ae
j and the shifts Ce
j are considered as random but may be constant with
probability one. They are assumed to be independent of each other and independent of
all other random variables considered in the model except for Xe
k for k ∈DE(j).
Simultaneous noise interventions
The noise interventions above operate on clearly deﬁned variables Ae which can vary
between diﬀerent experimental settings e ∈E. In some applications, it might be diﬃcult to
change or inﬂuence the noise distribution at a single variable but instead one could imagine
interventions that change the noise distributions at many variables simultaneously. As a
third example, we thus consider a special case of the preceding Section 4.2.2, in which we
pool all interventional experiments into a single data set. That is, |E| = 2 and, for all
j ∈{2, . . . , p + 1},
j,k = βe=1
The random variables Aj ≥0 are assumed to have a distribution that is absolutely continuous w.r.t. Lebesgue measure with EA2
j < ∞and to be independent of all other variables
and among themselves. The pooling can either happen explicitly or, as stated above, as we
cannot control the target of the interventions precisely and a given change in environment
might lead to changes in the error distributions in many variables simultaneously. As an
example we mention gene knock-out experiments with oﬀ-target eﬀects in biology [e.g.
Jackson et al., 2003, Kulkarni et al., 2006].
Identiﬁability results
The following Theorem 2 gives suﬃcient conditions for identiﬁability of the causal predictors. We then discuss some conditions under which the assumptions can or cannot be
relaxed further below. Proofs can be found in Appendix F.
Theorem 2 Consider a (linear) Gaussian SEM as in (19) and (20) with interventions.
Then, with S(E) as in (6), all causal predictors are identiﬁable, that is
S(E) = PA(Y ) = PA(1)
if one of the following three assumptions is satisﬁed:
i) The interventions are do-interventions (Section 4.2.1) with ae
j ) and there
is at least one single intervention on each variable other than Y , that is for each
j ∈{2, . . . , p + 1} there is an experiment e with Ae = {j}.
ii) The interventions are noise interventions (Section 4.2.2) with 1 ̸= E(Ae
and again, there is at least one single intervention on each variable other than Y . If
the interventions act additively rather than multiplicatively, we require ECe
0 < Var Ce
iii) The interventions are simultaneous noise interventions (Section 4.2.3).
result still holds if we allow changing linear coeﬃcients βe=2
in (21) with
(possibly random) coeﬃcients βe=2
The statements remain correct if we replace the null hypothesis (10) with its weaker version (16).
These are examples for suﬃcient conditions for identiﬁability but there may be many
more. For example, one may also consider random coeﬃcients or changing graph structures
(only the parents of Y must remain the same).
In general, the conditions given above are not necessary. The following remarks, however, provide two speciﬁc counter examples that show the necessity of some
conditions.
i) We cannot remove the condition ae
j ) from Theorem 2 i): the following
SEMs correspond to observational data in experiment e = 1, interventional data
with do(X2 = 0) in experiment e = 2, and interventional data with do(X3 = 0) in
experiment e = 3:
with ε2 and ε3 having the same distribution. Then, we cannot identify the correct
set of parents S∗= {1, 2}. The reason is that even S = ∅leads to a correct null
hypothesis (10).
ii) If we only check the null hypothesis (16) instead of the stronger version (10) (namely
whether the residuals have the same variance rather than the same distribution),
the condition E(Ae
j)2 ̸= 1 is essential.
Consider a two-dimensional observational
distribution from experiment e = 1 and an intervention distribution from experiment
Y 1 = X1 + εY ,
X2 = A · εX,
Y 2 = X2 + εY ,
with E(A)2 = 1 and εX, εY
∼N(0, 1). Then we cannot identify the correct set of
parents PA(Y ) = {X} because again S = ∅leads to the same residual variance and
therefore a correct null hypothesis (16). If we use hypothesis (10), however, condition
j)2 ̸= 1 can be weakened (if densities exist), see the proof of Theorem 2 (iii).
In practice, we expect stronger identiﬁability results than Theorem 2. Intuitively, intervening on (some of) the ancestors of Y should be suﬃcient for identiﬁability in many
cases. Note that the two counter-examples above are non-generic in the way that they
violate faithfulness [e.g. Spirtes et al., 2000]. The following theorem shows for some graph
structures (which need not to be known) that even one interventional setting with an
intervention on a single node may be suﬃcient, as long as the data generating model is
chosen “generically” (see Appendix A for an example).
Theorem 3 Assume a linear Gaussian SEM as in (19) and (20) with all non-zero parameters drawn from a joint density w.r.t. Lebesgue measure. Let Xk0 be a youngest parent
of target variable Y = X1, that is there is no directed path from Xk0 to any other parent
of Y . Assume further that there is an edge from any other parent of Y to Xk0. Assume
that there is only one intervention setting, where the intervention took place on Xk0, that
is |E| = 2 and Ae=2 = {k0} (k0 does not need to be known).
Then, with probability one, all causal predictors are identiﬁable, that is
S(E) = PA(Y ) = PA(1)
if one of the following two assumptions is satisﬁed:
i) The intervention is a do-intervention (Section 4.2.1) with ae=2
ii) The intervention is a noise intervention (Section 4.2.2) with 1 ̸= E(Ae=2
̸= 0, respectively.
It is, of course, also suﬃcient for identiﬁability if the interventional setting Ae=2 =
{k0} is just a member of a larger number of interventional settings. We anticipate that
more identiﬁability results of similar type can be derived in speciﬁc settings. Theorem 3
shows that interving on the youngest parent can reveal the whole set of parents of the
target variable so this intervention is in a sense the most informative intervention under
the made assumptions. Intervening on descendants of Y will, in contrast, only rule out
these variables as parents of Y . Some interventions are also completely non-informative;
intervening on a variable that is independent of all other variables (including the target)
will, for example, not help with identiﬁcation of the set of parents of the target variable.
Instrumental and hidden variables with confounding
We now discuss an extension of the invariance idea that is suitable in the presence of hidden
variables. Instrumental variables can sometimes be used when the causal relationship of
interest is confounded and there are no randomised experiments available [Wright, 1928,
Bowden and Turkington, 1990, Angrist et al., 1996, Didelez et al., 2010]. For simplicity,
let us assume that I is binary. We assume that the SEM for a p-dimensional predictor X,
Figure 3: In this example of a graph of model that satisﬁes (23), variable Y has a direct
causal eﬀect only on X2, while there is a feedback between Y and X1.
a univariate target variable Y of interest and a q-dimensional hidden variable H can be
written as
X = f(I, H, Y, η),
Y = Xγ∗+ g(H, ε),
where γ∗is the unknown vector of causal coeﬃcients, f, g are unknown real-valued functions and η and ε are random noise variables in p dimensions and one dimension respectively. As it is commonly done for SEMs, we require the noise variables H, η, ε, I to be
jointly independent. Figure 3 shows an example of a SEM that satisﬁes (23).
Again, we are interested in the causal coeﬃcient γ∗. Because of the hidden variable H,
however, regressing Y on X does not yield a consistent estimator for γ∗.
Two remarks on the model (23) are in place. First, the model requires that I has no
direct eﬀect on Y , which is standard assumption for instrumental variable models. For
a discussion on why a violation of this assumption usually leads to no false conclusions
(only a reduction in power), see Section 6.3. Second, the model (23) allows for feedback
between X and Y , that is the corresponding graph in a SEM is not required to be acyclic.
If feedback exists, the solutions are typically understood to be stable equilibrium solutions
of (23) but we will here only require that the solutions satisfy equations (23).
We can use I as an instrument in a classical sense and estimate γ∗by the following
well-known two-stage least squares procedure [Angrist et al., 1996]: ﬁrst we estimate the
inﬂuence of I on X and then we regress Y on the predicted values of X given I. For nonlinear models one can use two-stage predictor substitution or two-stage residual inclusion;
see [Terza et al., 2008] for an overview. If we strive for identiﬁcation of γ∗, three limitations
with this approach are:
(i) The target Y is not allowed to be a parent of any component of X, i.e., f(I, H, Y, η) =
f(I, H, η). This also excludes the possibility of feedback between X and Y .
(ii) The conditional expectation E(X | I) is not allowed to be constant for I ∈{0, 1}.
(iii) The predictor X has to be univariate for a univariate instrument I, that is p = 1 is
What happens if we interpret the two diﬀerent values of I as two experimental settings?
In other words: what happens if I plays the role of the indicator of environment (that
we call E at the end of Section 6.1) and we apply the method described above? We can
deﬁne E as two distinct environments by collecting all samples with I = 0 in the ﬁrst
environment and all samples with I = 1 in the second environment. Of course, another
split into distinct environments is also possible and allowed as long as the split into distinct
environments is not a function of Y , a descendant of Y or the hidden variables H.
We stated in Proposition 1 that SEMs (with interventions) satisfy the assumptions
of invariant predictions if there are no hidden variables between the target variable and
the causal predictors. Because here there is the hidden variable H we cannot justify our
method using Proposition 1 (nor with Proposition 4 in general). However, the invariant
prediction procedure (3) can be extended to cover models of the form (23) as these models
for all e ∈E :
Xe has an arbitrary distribution
Y e = Xeγ∗+ g(He, εe),
with unknown causal coeﬃcients γ∗∈Rp and unknown function g : Rq × R →R.
In the absence of hidden variables, the residuals Y e −Xeγ∗are independent of the
causal predictors Xe
supp(γ∗) and have the same distribution across all environments.
In the presence of hidden variables, we cannot require independence of the residuals and
the causal predictors XS∗but can adapt the null hypothesis H0,S in (5) to the weaker form
H0,S,hidden(E) :
∃γ ∈Rp such that γk = 0 if k /∈S and
the distribution of Y e −Xeγ is identical for all e ∈E.
Testing the null hypothesis (25) is computationally more challenging than for the corresponding null hypothesis in the absence of hidden confounders (5). In contrast to (5), we
cannot attempt to ﬁnd for a given set S the vector γ by regressing Y e on Xe. The reason
is that even if (25) holds, it does not require the residuals Y e −Xeγ to be independent of
Suppose nevertheless that we have a test for the null hypothesis H0,S,hidden(E) and
deﬁne in analogy to (12) the estimated set of causal predictors as
S:H0,S,hidden(E) not rejected
Then the coverage property follows immediately in the following sense.
Proposition 2 Consider model (23) and let S∗= {k : γ∗
k ̸= 0}. Suppose the test for
H0,S,hidden(E) is conducted at level α and ˆS is deﬁned as in (26). Then
P[ ˆS(E) ⊆S∗] ≥1 −α.
Proof. The hypothesis H0,S,hidden(E) is obviously true for S∗as Y e −Xeγ∗= g(He, εe)
and the distribution of g(He, εe) is invariant across the environments e ∈E (deﬁned by I)
as I is independent of H and ε.
The method has thus guaranteed coverage for model (23) even if the necessary assumptions (i)-(iii) for identiﬁcation under a two-stage instrumental-variable approach are
violated. The power of the procedure depends again on the type of interventions, the function class and the chosen test for the null hypothesis. We can ask for speciﬁc examples
whether ˆS(E) = S∗in the population limit.
Proposition 3 Assume as a special case of (23) a shift in the variance of X under I = 1
compared to I = 0 observations:
X = f(H, η) + Z · 1I=1
Y = Xγ∗+ g(H, ε),
where the p-dimensional mean-zero random variable Z is independent of H, ε, η and I and
has a full-rank covariance matrix. Then γ∗and S∗are identiﬁable in a population sense.
Speciﬁcally, if the test of H0,S,hidden(E) has power 1 against any alternative, then
P[ ˆS(E) = S∗] ≥1 −α.
A proof is given in Appendix E. Note that the causal variables and coeﬃcients can be
identiﬁed for (27), even though the model violates the above-mentioned assumptions (ii)
and (iii) for identiﬁability with a classical two-stage instrumental variable analysis: X can
be of arbitrary dimension even though the instrumental variable I is univariate and there
is no shift in E(X | I) between I = 1 and I = 0.
A further advantage of the invariance approach might be that no test for a weak
inﬂuence of I on X is necessary. A weak instrument can lead to ampliﬁcation of biases
in conventional instrumental variable regression [Hern´an and Robins, 2006].
invariance approach, the conﬁdence intervals for γ∗are naturally wide in case of a weak
inﬂuence of I on X, leading to small sets ˆS of selected causal variables.
Ignoring the computational diﬃculties, this shows that the approach can be generalised
to include hidden variables that violate assumption (ii) c) in Proposition 4, for example by
replacing (5) with the null hypothesis (25). As a possible implementation of the general
approach we must therefore test (25) for every set S ⊆{1, . . . , p}. We are faced with a
formidable computational challenge because the coeﬃcients γ∗cannot be found by simple
linear regression anymore. One possibility is to place a stricter constraint on the form of
allowed interventions. For shifted soft interventions from Section 4.2.3, for example, such
an approach is described in Rothenh¨ausler et al. . For general interventions, we can
test (25) in a brute-force way by testing the invariance of the distribution over a grid of
γ-values. However, the computational complexity of this approach is exponential in the
predictor dimension and it would be valuable to identify computationally more eﬃcient
ways of testing the null hypothesis (25).
Further extensions and model misspeciﬁcation
Nonlinear models
We have shown an approach to obtain conﬁdence intervals for the causal coeﬃcients in
linear models. We might be interested in identifying the set of causal predictors S∗in the
more general nonlinear setting (2). The equivalent null-hypothesis to (5) is then
H0,S,nonlin(E) :
There exists g : R|S| × R →R and εe such that
Y e = g(Xe
εe ∼Fε and εe ⊥⊥Xe
S for all e ∈E.
It is interesting to note that S satisﬁes (28) if and only if it satisﬁes
H0,S,nonlin(E) :
∀e, f ∈E the conditional distributions Y e | Xe
S = x and Y f | Xf
are identical for all x such that both cond. distr. are well-deﬁned.
The “only if” part is immediate and for the “if” part we can use a similar idea as in
[Peters et al., 2014, Prop. 9], for example, and choose a Uniform( )-distributed ε and
g(a, b) = ge(a, b) := F −1
S=a(b), where FY e | Xe
S=a is the cdf of Y e | Xe
As in the linear case, we can consider a SEM with environments corresponding to
diﬀerent interventions and, again, the parents of Y satisfy the null hypothesis.
precisely, we have the following remark.
Remark 2 Proposition 1 and Proposition 4 still hold if we replace linear SEMs (19) with
nonlinear SEMs
Yj = fj(XPA(j), εj),
j = 1, . . . , p + 1
and replace Assumption 1 with the assumption that there exists S∗satisfying (28).
Proof. Again, the proof is immediate. Only the case with hidden variables requires an
argument. From the SEM, we are given Y e = f(Xe
H, ˜εe) with S0
H being the hidden
parents of Y and (Xe
H, ˜εe) ⊥⊥Xe
S0. We can then write Y e = g(XS0, εe) for a uniformly
distributed εe that is independent of XS0 and g(x, n) := F −1
,˜εe)(n). The function g
does not depend on e because Xe
H and ˜εe have the same distribution for all e ∈E.
Assume we have a test for the null hypothesis H0,S,nonlin(E). Then, testing all possible
sets S ⊆{1, . . . , p}, we can get a conﬁdence set for S∗in a similar way as in the linear
setting (15) by
S:H0,S,nonlin(E) not rejected
If all tests are conducted individually at level α, we have again the property that for any
S∗which fulﬁlls (28) or (29), P( ˆS(E) ⊆S∗) ≥1 −α since the null hypothesis for S∗will
be accepted with probability at least 1 −α.
Constructing suitable tests for (29) is easier if we are willing to assume that the function
g in (28) is additive in the noise component, that is
H0,S,additive(E) :
there exists g : R|S| →R and εe such that
Y e = g(Xe
εe ∼Fε and εe ⊥⊥Xe
S for all e ∈E.
Then, we can construct tests for the null hypothesis (28) that are similar as in the linear
case. Analogously to Method I in Section 3.1, we can perform nonlinear regression in each
environment and test whether the regression functions are identical [e.g. Durot et al., 2013,
for isotonic regression functions]. As an alternative, we can also ﬁt a regression model on
the pooled data set and test whether the residuals have the same distribution in each
environment, see Method II in Section 3.1.
We may also test (29) without assuming additivity of the noise component. This could
be addressed by introducing an environment variable E and then performing a conditional
independence test for Y ⊥⊥E | XS, see also Appendix C. The details of these approaches
lie beyond the scope of this paper.
Interventions on the target variable and its causal mechanism
So far, we have assumed that the error distribution of the target variable is unchanged
across all environments e ∈E, see Assumption 1 for linear models. This precludes interventions on Y and precludes a change of the causal mechanism for the target variable. For
the gene-knockout experiments mentioned in Section 2 and treated in detail in Section 7.2,
we would for example know whether we have intervened on the target gene or not. In other
situations, we might not be sure whether an intervention on the target variables occurred
If interventions are sparse, other approaches are possible, too. For any given target
variable Y , we might not be sure whether an intervention on Y occurred or not, but we can
assume that an intervention on Y happened in at most V ≪|E| diﬀerent environments,
even if we do not know in which of the environments it occurred, see Kang et al. 
for a related setting in instrumental variable regression. The null hypothesis (29) in the
general nonlinear case can then be weakened to
0,S,nonlin(E) :
∃E′ ⊆E with |E′| ≥|E| −V s.t. ∀e, f ∈E′ the cond. distr. Y e | Xe
and Y f | Xf
S = x are identical ∀x s.t. both cond. distr. are well-deﬁned.
The null hypothesis H′
0,S∗,nonlin is then still true even when interventions happen on Y
in some environments, where S∗is the causal set of variables that satisﬁes the invariance
assumption in the absence of interventions on Y . Any test for (29) can be extended as
a test for the weaker null hypothesis (32) by testing all subsets E′ with |E′| ≥|E| −V
at level α, e.g. using a test for (28), and rejecting (32) only if we can reject all such
subsets. We can then treat H0,S,nonlin(E) as being “accepted” if we ﬁnd one subset E′
whose corresponding null hypothesis cannot be rejected.
Model misspeciﬁcation
We have shown how the approach can be extended to cover hidden variables, nonlinear
models and interventions on the target variable.
The question arises how the original
approach behaves if these model assumptions are violated but we use the original approach
instead of the proposed extensions. We again write ˆS(E) as in (15) as
S:H0,S not rejected
Our approach still satisﬁes the coverage property P( ˆS(E) ⊆S∗) ≥1 −α for any set S∗
that satisﬁes Assumption 1. Let S∗
c be a set that is considered to be causal, for example,
because it is the set of observed parents of Y in a SEM. Under no model misspeciﬁcation, Proposition 1 shows that this set will satisfy Assumption 1 or, in the general case
Equation (29). If the model assumptions are violated, however, then either H0,S∗c is still
true (in which case the desired conﬁdence statements P( ˆS(E) ⊆S∗
c ) ≥1 −α is still valid)
or H0,S∗c is not longer true. The latter case thus warrants our attention. There are two
possibilities. If H0,S is also false for all other sets S ⊆{1, . . . , p}, then ˆS(E) = ∅for a test
that has maximal power to reject false hypotheses. Thus, the desired coverage property
P( ˆS(E) ⊆S∗
c ) ≥1 −α is still valid, even though the method will now have no power to
detect the causal variables. It could happen, on the other hand, that there exists some
set S′ ⊆{1, . . . , p} with S′ \ S∗
c ̸= ∅for which H0,S′ is true. Proposition 5 in Appendix C
shows that under some assumptions even in this case, the mistake is not too severe: then
there exists a diﬀerent set ˜S, for which H0,S′ is true, and that contains only ancestors of
the target Y and no descendants. Then, by construction, the same also holds for ˆS(E),
with probability greater than 1 −α.
Numerical results
We apply the method to simulated data, gene perturbation experiments from biology
with interventional data and and an instrumental variable type setting from educational
Simulation experiments
For the simulations, we generate data from randomly chosen linear Gaussian structural
equation models (SEMs) and compare various approaches to recover the causal predictors
of a target variable.
The generation of linear Gaussian SEMs is described in Appendix G. We sample 100
diﬀerent settings and for each of those 100 settings, we generate 1000 data sets. We tried
to cover a wide range of scenarios, some (but not all of which) correspond to the theoretical
results developed in Section 4.3. After randomly choosing a node as target variable, we
can then test how well various methods recover the parents (the causal predictors) of
this target. We check whether false variables were selected as parents (false positives) or
whether the correct parents were recovered (true positives).
For the proposed invariant prediction method, we divide the data into a block of observational data and a block of data with interventions. Some other existing methods
make use of the exact nature of the interventions but for our proposed method this information is discarded or presumed unknown. The estimated causal predictors ˆS(E) at
conﬁdence 95%, computed as in Method I in Section 3.1, are then compared to the true
causal predictors S∗of a target variable in the causal graph (which can sometimes be the
empty set). The results of Method II are very similar in the simulations and are not shown
separately. We record whether any errors were made ( ˆS(E) ⊈S∗) and whether the correct
set was recovered ( ˆS(E) = S∗). We compare the proposed conﬁdence intervals with point
estimates given by several procedures for linear SEMs:
1. Greedy equivalence search (GES) [Chickering, 2002]. In the case of purely observational data, we can identify the so-called Markov equivalence class of the correct graph
from the joint distribution, i.e. we can ﬁnd its skeleton and orient the v-structures,
i.e. some of the edges [Verma and Pearl, 1991]. Although, many directions remain
ambiguous in the general case, it might be that we can orient some connections of the
target variable Xj −Y . If the edge is pointing towards Y , we identify Xj as a direct
cause of Y . The GES searches greedily over equivalence classes of graph structures
in order to maximise a penalised likelihood score. Here, we apply GES on the pooled
data set, pretending that all data are observational.
2. Greedy interventional equivalence search (GIES) with known intervention targets
[Hauser and B¨uhlmann, 2012]. The greedy interventional equivalence search (GIES)
considers soft interventions (at node j) where the conditional p(xj | xPA(j)) is replaced by a Gaussian density in xj. One can identify interventional Markov equivalence classes from the available distributions that are usually smaller than the Markov
equivalence classes obtained from observational data. GIES is a search procedure over
interventional Markov equivalence classes maximising a penalised likelihood score. In
comparison, a beneﬁt of our new approach is that we do not need to specify the different experimental conditions. More precisely, we do not need to know which nodes
have been intervened on.
3. Greedy interventional equivalence search (GIES) with unknown intervention targets.
To obtain a more fair comparison to the other methods, we hide the intervention
targets from the GIES algorithm and pretend that every variable has been intervened
4. Linear non-Gaussian acyclic models (LiNGAM) [Shimizu et al., 2006]. The assumption of non-Gaussian distributions for the structural equations leads to identiﬁability.
We use an R-implementation [R Core Team, 2014] of LiNGAM which is based on
independent component analysis, as originally proposed by Shimizu et al. . In
the observational setting, the structural equation of a speciﬁc variable Xj reads
whereas in the interventional setting (if the coeﬃcients βj,k remain the same), we
One may want to model the pooled data set as coming from a structural equation
model of the form
βj,k ˜Xk + ˜εj,
where ˜εj follows a distribution of the mixture of ε1
j and thus has a non-Gaussian
distribution (Kun Zhang mentioned this idea to JP in a private discussion). The new
noise variables ˜ε1, . . . , ˜εp are not independent of each other: if, for any j ̸= k, ˜εj
comes from the ﬁrst mixture, then ˜εk does so, too. We can neglect this violation of
LiNGAM and apply the method nevertheless. There is no theoretical result which
would justify LiNGAM for interventional data.
5. Regression. We pool all data and use a linear least-squares regression and retain
all variables which are signiﬁcant at level α/p, in an attempt to control the familywise error rate (FWER) of falsely selecting at least a single variable at level α in a
regression (not causal) sense. As a regression technique, this method cannot correctly
identify causal predictors.
6. Marginal regression. We pool all data and retain all variables that have a correlation
with the outcome at signiﬁcance level α/p. As above, this regression method cannot
correctly identify causal predictors.
We show the (empirical) probability of false selections, P( ˆS(E) ⊈S∗), in Figure 5 for
all methods. The probability of success, P( ˆS(E) = S∗), is shown in Figure 4.
The success probabilities show some interesting patterns. First, there is (as expected)
not a method that performs uniformly best overall scenarios. However, regression and
The probability of success, deﬁned as P( ˆS(E) = S∗) for various methods,
including our new proposed invariant prediction in the rightmost column. Each dot within
a column (the x-oﬀset within a column is uniform) corresponds to one of the 100 simulation
scenarios. The dot’s height shows the empirical probability of success over 1000 simulations
and the small bars indicate a 95% conﬁdence for the true success probability. Identical
scenarios are connected by grey solid lines. For each method, the maximal and minimal
values along with the quartiles of each distribution are indicated by horizontal solid bars.
The probability of erroneous selections P( ˆS(E) ⊈S∗) (FWER) for the considered methods, including the proposed invariant prediction to the right. The ﬁgure is
otherwise analogously generated as Figure 4. The dotted line indicates the 0.05 level at
which the invariant prediction method was (successfully) controlled. All other methods
do not oﬀer FWER control.
marginal regression are dominated across all 100 scenarios by GIES (both with known and
unknown interventions), LiNGAM and the proposed invariant prediction). Among the 100
settings, there were 3 where GES performed best on the given criterion, 14 where GIES
(with known interventions) performed best, 54 for LiNGAM and 23 where the proposed
invariant prediction were optimal for exact recovery. There is no clear pattern as to which
parameter is driving the diﬀerences in the performances: Spearman’s correlation between
the parameter settings and the diﬀerences in performances between all pairs of methods
was less than 0.3 for all parameters. The interactions between the parameter settings seem
responsible for the relative merits of one method over another.
The pattern for false selections in Figure 5 is very clear on the other hand.
proposed invariant prediction method controls the rate at which mistakes are made at
the desired 0.05 (and often lower due to a conservativeness of the procedure). All other
methods have FWE rates that reach 0.4 and higher. No other method oﬀers a control
of FWER and the results show that the probability of erroneous selections can indeed be
very high. The control of the FWER (and the associated conﬁdence intervals) is the key
advantage of the proposed invariant prediction.
Gene perturbation experiments
We applied our method to a yeast (Saccharomyces cerevisiae) data set [Kemmeren et al., 2014]. Genome-wide mRNA expression levels in yeast were measured and we
therefore have data for p = 6170 genes. There are nobs = 160 “observational” samples of
wild-types and nint = 1479 data points for the “interventional” setting where each of them
corresponds to a strain for which a single gene k ∈K := {k1, . . . , k1479} ⊂{1, . . . , 6170}
has been deleted (meanwhile, there is an updated data set with ﬁve more mutants). If the
method suggests, for example, gene 5954 as a cause of gene 4710, and there is a deletion
strain corresponding to gene 5954, we can use this data point to determine whether gene
5954 indeed has a (possibly indirect) causal inﬂuence on 4710. We say that the pair is a
true positive if the expression level of gene 4710 after intervening on 5954 lies in the 1%
lower or upper tail of the observational distribution of gene 4710, see also Figure 6 below.
(We additionally require that the intervention on gene 5954 appears to be “successful” in
the sense that the expression level of gene 5954 after intervening on this gene 5954 lies
in the 1% lower or upper tail of the observational distribution of gene 5954. This was
not the case for 38 out of the 1479 interventions.) With this criterion, there are about
9.2% relevant eﬀects, which corresponds to the proportion of true positives for a random
guessing method.
Separation into observational and interventional data.
For predicting a causal
inﬂuence of, say, gene 5954 on another gene we do not want to use interventions on the
same gene 5954 (this would use information about the ground truth). We therefore apply
the following procedure: for each k ∈K we consider the observational data as e = 1 and
the remaining 1478 = 1479 −1 data points corresponding to the deletions of genes in
K \ {k} as the interventional setting e = 2. Since this would require nint × p applications
of our method, we instead separate K into B = 3 subsets of equal size, consider the
two subsets not containing k as the interventional data, and do not make any use of the
subset containing k. This leaves some information in the data unused but yields a huge
computational speed-up, since we need to apply our method in total only 3 × p times.
Additionally, when looking for potential causes of gene 4710, we do not consider data
points corresponding to interventions on this gene (if it exists), see Proposition 1.
Goodness of ﬁt and p-values.
If we would like to avoid making a single mistake on
the data set with high probability 1 −α, we can set the signiﬁcance level to for each gene
to α/nint, using a Bonferroni correction in order to take into account the nint = 1479
genes that have been intervened on. We work with α = 0.01 if not mentioned otherwise.
The guarantee requires, however, that the model is correct (for example the linearity
assumption is correct and there are no hidden variables with strong eﬀects on both genes of
interest). These assumptions are likely violated, and the implications have been partially
discussed in the previous Section 6.
To further guard against false positives that are
due to model misspeciﬁcation we require that there is at least one model (one subset
S ⊆{1, . . . , p}) for which the model ﬁts reasonably well: we deﬁne this by requiring a
p-value above 0.1 for testing H0,S(E) for the best-ﬁtting set S of variables (the set with
the highest p-value), if not mentioned otherwise (but we also vary the threshold to test
how sensitive our method is with regard to parameter settings). If no set of variables
attains this threshold, we discard the models and make no prediction.
We use L2-boosting [Friedman, 2001, B¨uhlmann and Yu, 2003] from the Rpackage mboost [Hothorn et al., 2010] with shrinkage 0.1 as a way to preselect for each
response variable ten potentially causal variables, to which we then apply the causal inference methods. We primarily use Method II as Method I requires subsampling for computational reasons. Subsampling can lead to a loss of power as there is a not-negligible
probability of loosing the few informative data points in the subsampling process. For a
computational speed-up we only consider subsets of size ≤3 as candidate sets S. Furthermore, we only retain results where just a single variable has been shown to have a causal
inﬂuence to avoid testing more diﬃcult scenarios where one would have to intervene on
multiple genes simultaneously.
Comparisons.
As alternative methods we consider IDA [Maathuis et al., 2009] based
on the PC algorithm [Spirtes et al., 2000] and a method that ranks the absolute value
of marginal correlation (j1 →j2 and j2 →j1 obtain the same score and are ranked
randomly), both of which make use only of the observational data. We also compare with
IDA based on greedy interventional equivalence search (GIES) [Hauser and B¨uhlmann,
2015] and a correlation-based method that ranks pairs according to correlation on the
pooled observational and interventional data. It was not feasible to run LiNGAM [Shimizu
et al., 2011] on this data set.
The three rows correspond to the three most signiﬁcant eﬀects found by
the proposed method (with the most signiﬁcant eﬀect on top, suggesting a causal eﬀect
of gene 5954 on gene 4710).
The left column shows the observational data, while the
second column shows the interventional data (that are neither using interventions on the
target variable itself nor using interventions on the examined possible causal predictors
of the target variable); these two data sets are used as two environments for training the
invariant prediction model.
The regression line for a joint model of observational and
interventional data, as proposed in Method II, is shown in both plots; we cannot reject
the hypothesis that the regression is diﬀerent for observational and interventional data
here. The third column ﬁnally shows the test data (with the 1%-99% quantile-range of
the observational data shown as a shaded box as in the ﬁrst column). There, we use the
intervention data point on the chosen gene and look at the eﬀect on the target variable.
The ﬁrst two predicted causal eﬀects can be seen to be correct (true positives) in the
following sense: after successfully intervening on the predicted cause, the target gene
shows reduced activity; the third suggested pair is unsuccessful (false positive) since the
intervention reduces the activity of the cause but the target gene remains as active as in
the observational data.
The number of true eﬀects among the strongest 8 eﬀects that have been found in
the interventional test data (the number 8 has been chosen to correspond to the number
of signiﬁcant eﬀects under the proposed Method II). Method I is based on 1000 samples
and required roughly 10 times more computational time than Method II.
marginal corr.
2 (95% quantile)
3 (99% quantile)
(out of 8)
4 (99.9% quantile)
The proposed method (Method II) outputs eight gene pairs that can be checked
because the corresponding interventional experiments are available. There are in total
eight causal eﬀects that are signiﬁcant at level 0.01 after a Bonferroni correction. Out
of these eight pairs, six are correct (random guessing has a success probability of 9.2%).
Figure 6 shows the three pairs that obtained the highest rank, i.e.
smallest p-values.
The rows in the ﬁgure therefore correspond to the three causal eﬀects in the data set
that were regarded as most signiﬁcant by our method. One note regarding the plot: we
plot all available data even though only two-thirds of it was eﬀectively used for training
due to the discussed cross-validation scheme. Many outlying points in the interventional
training data of the false positive (second column of third row in Figure 6) are in particular
not part of the training data and the method might have performed better with a more
computationally-intensive validation scheme that would split the data into B blocks with
B larger than the currently used B = 3.
In order to compare with other methods (none of which provide a measure of signiﬁcance), we always consider the eight highest-ranked pairs. Table 1 summarises the results.
In this data set, the alternative methods were not able to exceed random guessing.
To test sensitivity of the results to the chosen implementation details of the method,
the variable pre-selection, the goodness-of-ﬁt cutoﬀhave also all been varied (for example
using Lasso instead of boosting as pre-selection and using a cutoﬀof 0.1 instead of 0.01).
For Method II, variable selection with Lasso instead of boosting leads to a true positive
rate of 0.63 (5 out of 8). Choosing the goodness-of-ﬁt cutoﬀat 0.01 rather than 0.1 leads
to true positive rates of 0.43 (9 out of 21) for boosting and 0.47 (8 out of 17) for Lasso.
Method I without forcing eight decisions leads to a true positive rate of 0.75 (3 out of 4)
for boosting and 1.00 (1 out of 1) for Lasso. Choosing the goodness-of-ﬁt cutoﬀat 0.01
rather than 0.1 leads to true positive rates of 0.86 (6 out of 7) for boosting and 0.75 (3
out of 4) for Lasso. (Using 500 instead of 1000 subsamples for Method I leads to increased
speed and worse performance.) We regard it as encouraging that the true positive rate
is always larger than random guessing, irrespective of the precise implementation of the
Among the reasons for false positives (e.g. 2 out of 8 for Method II in Table 1, there
are at least the following options: (a) noise ﬂuctuations, (b) nonlinearities, (c) hidden
variables, (d) issues with the experiment (for example the intervention might have changed
The 90% conﬁdence intervals for the inﬂuence of various variables on the
probability of receiving a BA degree (or higher) are shown in blue. Of all 8192 possible
sets S, we accept 1565 sets (the empty set is not accepted as the probability of receiving
a degree is suﬃciently diﬀerent for people within a close distance to a 4-year college and
further away). The point-estimates for the coeﬃcients are shown for these 1565 sets as red
dots and the corresponding conﬁdence intervals as vertical red bars. The blue conﬁdence
intervals are then the union of all 1565 conﬁdence intervals, as in our proposed procedure.
The variables score (test score) and fcollege no (active if father did not receive a college
degree) show signiﬁcant eﬀects.
other parts of the network) and (e) the pair is a true positive but is -by chance- classiﬁed as
a false positive by our criterion (see “Data set” above). Missing causal variables in the prescreening by boosting or Lasso falls under category (c). We control (a) and have provided
arguments why (b) and (c) will lead to rejection of the whole model rather than lead
to false positives. Lowering the goodness-of-ﬁt-threshold seemed indeed to lead to more
spurious results, as expected from the discussion in the previous Section 6.3. Validating a
potential issue with the experiment as in reason (d) is beyond our possibilities. We could
address (e) if we had access to multiple repetitions of the intervention experiments.
Educational attainment
We look at a data set about educational attainment of teenagers [Rouse, 1995]. For 4739
pupils from approximately 1100 US high schools, 13 attributes are recorded, including gen-
der, race, scores on relevant achievement tests, whether the parents are college graduates,
or family income. Here we work with the data as provided in Stock and Watson ,
where we can see the length of education pupils received. We make a binary distinction
into whether pupils received a BA degree or higher (equivalent to at least 16 years of
education in the classiﬁcation used in Stock and Watson ) and ask whether we can
identify a causal predictive model that allows to forecast whether students will receive a
BA degree or not and this forms a binary target Y .
The distance to the nearest 4-year college is recorded in the data and we use it to
split the dataset into two parts in the sense of (18); we assume that this variable has
no direct inﬂuence on the target variable. As discussed, this variable does not have to
satisfy the usual assumptions about instrumental variables for our analysis but just has to
be independent of the noise in the outcome variable (it must be a non-descendant of the
target), which seems satisﬁed in this dataset as the distance to the 4-year college precedes
the educational attainment chronologically. One set of observations are thus all pupils
who live closer to a 4-year college than the median distance of 10 miles. The second set
are all other pupils, who live at least 10 miles from the nearest 4-year college. We ask for
a classiﬁcation that is invariant in both cases in the sense that the conditional distribution
of Y , given X, is identical for both groups, where X are the set of collected attributes and
Y is the binary outcome of whether they attained a BA degree or higher. We use the fast
approximate Method II of Section 3.1, with the suggested extension to logistic regression.
Figure 7 shows the outcome of the analysis, which is also included as an example in the
R-package InvariantCausalPrediction. Factors were split into dummy variables so that
“ethnicity afam” is 1 if the ethinicity is african-american and 0 otherwise, “fcollege no”
is 1 if the father did not receive a college degree and so forth. We provide 90% conﬁdence
intervals. All of them include 0 except for the conﬁdence interval for the inﬂuence of the
test score (positive eﬀect) and the indicator that the father did not receive a college degree
(negative eﬀect). A high score on the achievement test thus seems to have a positive causal
inﬂuence on the probability of obtaining a BA degree, which seems plausible.
As it is diﬃcult to verify the ground truth in this case, we refrain from comparisons with
other possible approaches to the same data set and just want to use it as an example of a
possible practical application. The example shows that we can use instrumental-variabletype variables to split the data set into diﬀerent “experimental” groups. If the distributions
of the outcome are suﬃciently diﬀerent in the created groups, we can potentially have
power to detect invariant causal prediction eﬀects.
Discussion and Future Work
An advantage of causal predictors compared to non-causal ones is that their inﬂuence on
the target variable remains invariant under diﬀerent changes of the environment (which
arise for example through interventions). We have described this invariance and exploit
it for the identiﬁcation of the causal predictors. Conﬁdence sets for the causal predictors and conﬁdence intervals for relevant parameters follow naturally in this framework.
In the special case of Gaussian structural equation models with interventions we have
proved identiﬁability guarantees for the set of causal predictors. We discussed some of the
questions that require more work: suitable tests for equality of conditional distributions
for nonlinear models, feedback models and increased computational eﬃciency both in the
absence and presence of hidden variables.
The approach of invariant prediction provides new concepts and methods for causal
inference, and also relates to many known concepts but considers them from a diﬀerent
angle. It constitutes a new understanding of causality that opens the way to a novel class
of theory and methodology in causal inference.
Acknowledgements
The research leading to these results has received funding from the People Programme
(Marie Curie Actions) of the European Union’s Seventh Framework Programme under REA grant agreement no 326496. The authors would like to thank seven
anonymous referees for their helpful comments on an earlier version of the manuscript and
would like to thank Alain Hauser, Thomas Richardson, Bernhard Sch¨olkopf and Kun
Zhang for helpful discussions.