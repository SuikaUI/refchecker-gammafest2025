Domain Transfer for Person Re-identiﬁcation
Ryan Layne, Timothy M. Hospedales, Shaogang Gong
Queen Mary University of London
London, England
{rlayne, tmh, sgg}@eecs.qmul.ac.uk
Automatic person re-identiﬁcation in is a crucial capability underpinning many applications in public space video surveillance. It is
challenging due to intra-class variation in person appearance when
observed in different views, together with limited inter-class variability.
Various recent approaches have made great progress in
re-identiﬁcation performance using discriminative learning techniques. However, these approaches are fundamentally limited by
the requirement of extensive annotated training data for every pair
of views. For practical re-identiﬁcation, this is an unreasonable assumption, as annotating extensive volumes of data for every pair
of cameras to be re-identiﬁed may be impossible or prohibitively
expensive.
In this paper we move toward relaxing this strong assumption
by investigating ﬂexible multi-source transfer of re-identiﬁcation
models across camera pairs. Speciﬁcally, we show how to leverage
prior re-identiﬁcation models learned for a set of source view pairs
(domains), and ﬂexibly combine these to obtain good re-identiﬁcation
performance in a target view pair (domain) with greatly reduced
training data requirements in the target domain.
Categories and Subject Descriptors
I.5.4 [Pattern Recognition]: Applications; I.4.8 [Image Processing and Computer Vision]: Scene Analysis
General Terms
Surveillance, Transfer Learning
Person Re-identiﬁcation, Support Vector Machines
INTRODUCTION
Person re-identiﬁcation, or inter-camera entity association, is the
task of recognizing an individual across heterogeneous non-overlapping
camera views against a background of similar persons. When an individual disappears from one view they need be differentiated from
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from .
ARTEMIS’13, October 21, 2013, Barcelona, Spain.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2393-2/13/10 ...$15.00.
 
numerous possible alternative people and re-identiﬁed in another
view, potentially under a different and unknown view angle, pose,
lighting conditions and clutter or occlusion (see Figure 1 for examples). This is critical to a variety of safety, security and efﬁciency
tasks which require long-term maintenance of consistent identity
across space and time. In particular, it is a fundamental capability
for long-term tracking across multiple disjoint camera views .
Relying on manual re-identiﬁcation in large camera networks is
prohibitively costly and error prone. For these reasons, there has
recently been extensive work in the computer vision community
on automated re-identiﬁcation . This is very challenging because of extreme intra-class (person identity) variability in
appearance across views with different lighting, pose and occlusion; and limited inter-class variability in appearance among many
similarly clothed pedestrians. Existing approaches can be broadly
broken down into two complementary categories: those which focus on developing effective feature representations , and those
which focus on developing learning methods to better discriminate
identity using a given representation .
Feature design approaches suffer from the problem that it
is extremely challenging if not impossible to design features that
are discriminative enough to distinguish people reliably; while simultaneously being invariant to all the covariates which occur in
practice such as, motion blur, view angle and pose change, lighting and occlusion. In contrast, learning approaches 
try to improve on a given set of features, and focus on discriminative training of models to maximize re-identiﬁcation performance,
for example distance metric learning and support vector
machines (SVM) . Recently, discriminative approaches have
signiﬁcantly improved state of the art benchmark performance treating re-identiﬁcation as a binary (same versus different
person) rather than multi-class (person identity) problem.
A central limitation of existing discriminative learning approaches,
is that they are more suited to closed-world benchmark problems
than realistic open-world scenarios. In particular they require many
pairs of person images annotated by same/different, for each camera pair between which the system is required to operate. This
is reasonable for training/testing splits on benchmark datasets that
are already exhaustively annotated by person identity. However it
is highly impractical for real-world use, where there may be very
many pairs of cameras in a given network, each requiring exhaustive annotation – making this “calibration” requirement of such a
system impossible or prohibitively expensive. Ideally, we would
like to deploy a re-identiﬁcation system between a pair of cameras
with minimal calibration/training annotation. What a system learns
from annotations of one camera pair should be exploited by another
pair without requiring exhaustive annotation in the new pair.
Figure 1: Examples from all of the datasets we use in our experiments; from the top: VIPeR, PRID, GRID, and CUHK.
Note the dramatic appearance variations in both the people and
backgrounds; as well as how image quality varies.
This is an issue in transfer learning . Transfer learning is already important for many classical vision problems such
as object recognition with multiple classes or domains. However it is critically important for re-identiﬁcation because the number of domains (camera pairs) is quadratic in the number of cameras. Therefore obtaining exhaustive training data for each domain
is even more impractical than for conventional vision applications,
and transfer learning becomes critical. Nevertheless, no prior reidentiﬁcation studies have addressed this issue, relying solely on
benchmark datasets with sufﬁcient annotated data in each camerapair of interest.
In this paper we relax the practically unrealistic assumption of
exhaustive training data within each domain by generalizing recent
ideas in learning re-identiﬁcation and SVM transfer learning
 . Speciﬁcally, we consider re-identiﬁcation based on binaryrelation learning , and show how to generalize this approach
to to achieve effective cross-domain learning by combining nonlinear decision boundaries from source domains to create a more
accurate target domain re-id classiﬁer. In this way we are able to
improve on within-domain learning both for sparse and even nonsparse training data volumes. Moreover we show how to achieve
this while systematically avoiding negative transfer, even when there
are multiple and irrelevant source domains.
RELATED WORK
Feature design
Contemporary approaches to re-identiﬁcation (re-id) typically
exploit features such as color, texture, spatial structure, or combinations thereof . Once a representation has been designed, nearest-neighbor may be used for re-identiﬁcation given
a suitable distance metric (e.g., Euclidean) to measure the similarity
between two samples. Beyond the intrinsic challenge of designing
view invariant but identity variant features, a fundamental problem
is that features which are most effective in one domain (re-id view
pair) may be less effective in another domain (a new re-id view
pair) as we will show in Section 4.5. For this reason among others,
learning techniques have been studied that are trained to maximize
re-identiﬁcation performance within a given domain.
Learning re-identiﬁcation
Learning approaches to re-identiﬁcation typically learn distance
metrics , or model-based matching procedures such as
boosting and ranking based on annotated training pairs.
These have recently improved state of the art re-id performance
signiﬁcantly . Another line of research learns mid-level attributes to replace or augment low level features. In this case
inter-camera invariance is obtained via the generalization performance of learned attribute classiﬁers. However, this only applies
within domains where annotated attribute data is available. The recently proposed binary relation learning approach obtains
state of the art re-id results by exploiting strong SVM classiﬁers
trained to make same/different judgements on pairs of images. This
strategy does not assume that instances of the same person are more
similar than instances of different people, and instead implicitly
learns the mapping between appearance in pairs of training cameras. A serious issue with all these approaches is that they do not
generalize well across domains (different re-id view pairs; see Section 4.5); and hence require extensive volumes of training data for
each pair of cameras to be re-identiﬁed between. This is possible
for benchmark scenarios, but unreasonable in practice.
Cameras and Domains
In this work we consider a camera pair to make up a domain, and
this should not be confused with some other studies which consider
a particular camera to be a domain . For classiﬁcation and
detection , an individual camera encompasses the notion of a domain because a camera’s parameters impart a systematic impact on
the observations, which the model must learn to interpret. However
in re-identiﬁcation, a model’s task is to infer something about pairs
of observations, and the systematic impact of the environment is
therefore deﬁned by the pair of cameras.
Transfer Learning
Transfer learning has been used to good effect in numerous classical computer vision problems, for example object categorization . The motivation is typically to scale systems to
many classes or domains without requiring prohibitive
amounts of training data. While transfer learning is already an important issue in classical vision tasks, it will turn out to be even
more central to the re-identiﬁcation problem. This is because since
pairs deﬁne domains in this context, it is unreasonable to collect
exhaustive training data for a quadratic number of domains.
Only very recently has transfer learning for re-identiﬁcation begun to be considered . However these studies consider only
improving within-domain (camera pair) re-identiﬁcation by transferring knowledge learned from one group of people to help identify another group of people. This is intrinsically a much more
restricted scenario than the more general and useful case of transferring across domains to permit re-identiﬁcation in a new camera
pair with sparse annotations.
A central issue in transfer learning is that of from where to
transfer. When there is only one source of information available,
and that source is known to be highly relevant to the task of interest, then transfer learning is much simpler than in the more general
and realistic case where there are multiple sources of information
of greatly varying relevance. In this latter case, it is non-trivial to
design models which avoid negative transfer . Our problem of
transferring mappings across camera pairs falls squarely into the
latter more difﬁcult case. Since the relevance of one camera pair
to another depends on similarity in their viewing angles and lighting, many pairs will not be similar and working out from where to
transfer is of critical importance.
Our Approach.
We address all the mentioned issues by generalizing the state of
the art binary relation approach to re-id , but tackle the new challenges in addressing the training data requirements via multi-source
transfer. There are many potential approaches to transfer learning
 , but in this study we will develop a SVM multi-kernel learning (MKL) transfer strategy. This will allow us to integrate multiple source domains of unknown relevance, while avoiding negative transfer via an inter-kernel sparsity regularizer
We make the following speciﬁc contributions: (i) Framing the
problem of generalizing re-identiﬁcation as a domain-transfer problem; (ii) Developing a speciﬁc framework for domain-transfer reid for multiple domains of varying relevance by way of expressing
the task as a SVM multi-kernel learning problem; (iii) Revealing
the limitations of existing approaches to re-identiﬁcation by way
of a systematic and quantitative cross-domain evaluation; and (iv)
Extensive evaluation of our proposed method on four of the largest
public re-id datasets available.
Concept Illustration
To provide intuition before introducing the details of the proposed method, Figure 2 provides an schematic illustration of our reid transfer learning framework. In this illustration, the feature space
within each camera is one dimensional. A domain, consisting of
pairs of observations made by two cameras, can thus be represented
as a point on a two dimensional plane. Pairs of cross-view images
corresponding to the same person are shown with circles, and pairs
corresponding to different people with crosses. Binary-relation 
based re-id is the strategy of learning a decision boundary in this
space (Figure 2, blue lines). In an easy re-identiﬁcation scenario,
the feature-space is the same in each view, so distinguishing true
pairs from false pairs requires only a simple decision boundary
(Figure 2(a)). In a realistic scenario, there will be a non-trivial
and unknown transformation in feature space from one camera
view relative to another (Figure 2(b) and (c)). In this case a strong
non-linear classiﬁer could learn the decision boundary separating
true from false pairs, and hence an implicit inter-camera mapping.
In this illustration, we assume there are three source domains
(camera pairs; Figure 2(a)-(c)) for which annotated data (red and
green symbols) is plentiful, and good binary relation based re-id
models have been learned (blue lines). Now suppose we wish to
deploy our re-identiﬁcation system to a new location where we can
only annotate a very limited amount of training data. With limited
data, a re-identiﬁcation classiﬁer learned in the conventional way –
solely from local data – will be much less accurate, clearly misclassifying many regions of the input space (Figure 2(e), unlabeled grey
symbols on the wrong side of the decision boundary). In contrast,
a re-identiﬁcation classiﬁer taking advantage of our domain transfer framework will realize that the limited data is best explainable
by the model learned from the second source domain (Figure 2(b)),
No Transfer
Source Domains
Target Domain
Figure 2: An illustration of how domain transfer can assist reidentiﬁcation. Symbols indicate same/different pairs, grey symbols are un-annotated and lines indicate decision boundaries.
and borrow that classiﬁer’s strength to help learn a much more informative and accurate boundary than is possible using local data
alone (Figure 2(d) vs (e)). (The intuition for how this works is
ﬁnding a source domain classiﬁer or combination thereof which ﬁt
the few available data points in the target domain). Finally, note
that simple averaging of all the source classiﬁers is insufﬁcient: in
this example the mean of source classiﬁers (a)-(c) is very similar
to classiﬁer (a) which will be wrong for the target domain (d). We
shall validate these intuitive observations experimentally in our experiments (Section 4.4).
Within Domain Re-identiﬁcation
We ﬁrst consider the case of learning to re-identify people within
one particular domain corresponding to a camera pair a and b.
Here we largely follow a binary-relation learning approach ,
but review the method for completeness. We assume training data
i=1 describing NA people observed in camera a, and {xa
describing NB people appearing in camera B, where x represents a
feature vector, and z indicates the identity of each person. From
this data we can generate:
• A set of cross-camera positive pairs of the same person:
{yk = 1,xk = [xa
j]k}, ∀(zi = z j),
• A set of cross-camera negative pairs of different people:
{yk = −1,xk = [xa
j]k}, ∀(zi ̸= zj),
where [·||·] denotes concatenation and k = 1...N indexes observation pairs xk. Note that there are a quadratic number of negative
pairings, and actually constructing all pairs is typically prohibitive,
so using a random subset of negative examples is typically adopted
To learn a re-identiﬁcation model, we train a classiﬁer on pair
data {yk,xk}N
k=1 to distinguish matching pairs from non-matching
pairs. This can be formalized as a support vector machine learning
problem as:
w,ξ ∥w∥2 + C
s.t. ykwT φ(xk) ≥1−ξk, ∀k,
where φ(·) is a non-linear mapping, and we maximize the margin subject to the soft constraint (slack variable ξk) that true pairs
should be positive and false pairs should be negative.
Discussion.
Note that this objective (Eq. 1) pursues positive true pairs and
negative false pairs, without any assumption of their visual similarity/dissimilarity. With the RBF kernel, binary-relation SVM implicitly learns an arbitrarily complex transformation mapping between cameras, e.g., uncovering their lighting or view transformation, as well as relative relevance for each feature within that
domain. In contrast, the common RankSVM approach has two
limitations: (i) it only models a ﬁrst-order weighting of features,
without considering their covariance, and (ii) it operates under the
explicit assumption that true pairs should be more similar than false
pairs (i.e., Figure 2(a)). In practice this means that for camera pairs
which deviate sharply from a simple linear transformation model
(e.g., Figure 2(a)) to a more complex transformation (e.g., Figure
2(b) or (c)), binary relation SVM outperforms RankSVM, as shown
in . Mahalanobis metric learning objectives are more
powerful than RankSVM in modelling feature covariance, however
they also still assume that true pairs are more similar than false
Re-identiﬁcation
For online re-identiﬁcation of persons across cameras, putative
pairs of images are concatenated x∗= [xa∗,xb∗] and the score of a test
pair x∗is is evaluated as f(x∗) = wT φ(x∗). The pair can be classiﬁed as same or different via sign f(x∗), or the continuous score
itself can be used to relatively rank putative matches. Given this reidentiﬁcation framework, we next address how to transfer learned
models across domains.
Domain Transfer Re-Identiﬁcation (DTR)
Assume a set of source domains s = 1...S are given, for which
we have learned re-identiﬁcation models as per Section 3.2. To
leverage the learned experience of these domains in a new target
domain t, we take the strategy of multi-kernel learning . Each
source domain s can be seen as providing a score fs(x) indicating
its conﬁdence that a given pair x is a matching pair under the model
of that domain. We therefore formalize a domain transfer prediction task, which classiﬁes a pair x in the target domain, taking into
account both target and source domain knowledge, as:
s φs(fs(x)),
where parameters w = [wt, ws] to be determined weight the relative informativeness of the target domain and each source domain
knowledge.
Given this task formulation, the within-domain learning objective in Eq (1) can be generalized to the case of domain-transfer
Source Domains
Target Domain
Figure 3: Schematic overview of our framework.
learning to estimate w as:
L(w,xk,yk),
where L denotes the hinge loss
1−ywT φ(x)
and Ω(w) denotes the weight regularizer. Note that use a linear kernel φ for computational tractability. In our case, because
the problem is binary, we are able to use the RBF kernel instead
without great penalty. This is indeed necessary because we need to
learn a complex transformation.
Evaluating Domain Relevance.
An important issue for domain transfer in the general unconstrained case is that we do not know in advance which source domain is going to be relevant, and indeed the majority are likely to
be irrelevant. For this reason we seek a sparse solution for the optimization problem in Eq (3). Previously l1 norm regularizers have
been proposed to provide sparsity across kernels. However this is
hard to optimize effectively . The lp (1 < p ≤2) norm regularizer has recently been shown to effectively induce sparsity while
providing signiﬁcantly easier optimization . We therefore take
the (2, p) group-norm as the regularizer: providing l2 regularization within domains, while encouraging lp sparsity across the set
of S +1 kernels which reﬂect the cues from the target domain and
the S source domains:
2 ∥[∥wt∥2 ,∥w1∥2 ,...,∥wS∥2]∥2
This avoids negative transfer because any source kernels which
mismatch the available target domain data will be allocated zero
coefﬁcients. Expressed in this form, we can exploit existing ef-
ﬁcient stochastic gradient-descent algorithms for solving the
cross-domain re-identiﬁcation learning problem in Eq (3).
EXPERIMENTS
Feature Extraction
The main imagery feature that we will use with our DTR model
is the 150 dimensional HSV color descriptor as detailed in . Additionally we compared the commonly used ensemble of local features (ELF) which encodes both color and texture in 2784 dimensions as detailed in ; as well as symmetry driven accumulation of local features (SDALF) as detailed in . Note that SDALF
provides a distance matrix directly, rather than a feature encoding.
Experimental Settings
We tested the model using the four largest publicly available
re-id datasets: VIPER , PRID , GRID and CUHK ,
which provide 316, 200, 250, and 971 matched pairs respectively.
These datasets cover a diverse variety of image sizes (in the region
of [128x48] to [128x64].), typical view angles and camera conditions (Figure 1). We evaluated cross-domain re-identiﬁcation performance on these datasets in four “leave one dataset out” folds.
In each case we considered three datasets as source domains and
the fourth dataset as the target domain. For the source domains
we learned within-domain re-identiﬁcation models with all available data for each (Section 3.2). For the held out domain, we performed 2-fold cross-validation, training the domain transfer model
on half (or less) of the data (Section 3.3), and using the held out
half for testing. For testing, we consider the matched pairs between
cameras within the domain, taking each person in turn (probe) and
matching them against the people in the other camera (gallery).
Within the source domains, SVM slack parameter C was crossvalidated to optimize expected rank. In the target domain we set
C = 10 throughout. We ﬁxed the RBF kernel parameter γ to the
median of each distance matrix. For the SVM methods we select
10 negative examples per positive pair.
Evaluation
As baselines we consider where relevant three non-learning methods and three learning methods. For non-learning methods we consider: (i) HSV features , (ii) ELF and (iii) SDALF ; in each
case with nearest neighbor (NN) matching and Euclidean distance
where relevant. For learning methods, we consider:
ATTR: Re-identiﬁcation using Euclidean NN matching on learned
mid-level attributes from ELF features.
BR-SVM: Binary-relation based re-identiﬁcation using SVMs . Note that BR-SVM has already been shown to decisively outperform the commonly applied RankSVM 
and prior metric learning methods .
DTR: Our proposed new Domain-Transfer re-identiﬁcation model,
using multi-kernel learning.
We evaluate re-identiﬁcation performance using two metrics: For
visualization, the normalized Cumulative Matching Characteristic
(nCMC) curve, which indicates the probability of the correct match
to a probe image appearing in the top n results from the gallery for
varying n1. For quantitative summarization, we use the expected
rank (ER) metric , which is the mean rank of the true result2.
This metric has the advantage that it reﬂects a physically meaningful quantity, which is how many items an operator has to scan in a
ranked list before reaching the true match for the probe, and hence
the average time it takes a human operator to ﬁnd the true match
using such a system .
Domain Transfer Experiments
1Here, higher curves are better; enclosing an area of 1 is perfect;
and an area of 0.5 is random
2Lower is better; a mean rank of 1 is perfect; and a mean rank
of half the gallery size is random
Expected Rank
Fraction of Target Domain Train Data
Expected Rank
Fraction of Target Domain Train Data
Expected Rank
Fraction of Target Domain Train Data
Expected Rank
Fraction of Target Domain Train Data
Figure 4: Re-identiﬁcation performance as a function of volume of training data. Lower expected rank is better. Each
dataset is evaluated as a leave-one-dataset out domain transfer problem. Our proposed DTR model systematically outperforms BR-SVM within-domain learning.
Domain transfer compensation for a lack of
target domain data
We ﬁrst evaluate re-identiﬁcation performance as a function of
target domain training data volume. Figure 4 summarizes the expected rank (ER) of each model for logarithmically varying volumes of training data. Also shown (ﬂat lines) are the performance
of LLF models SDALF (red), HSV (blue) and ELF (black). Clearly
performance for the learning models degrades with sparser training
data (Figure 4, ER of learned models higher to the right). However, our proposed DTR model (magenta) systematically outperforms the within-domain BR-SVM model (green), especially
with increasingly sparse data. We obtain between a margin of improvement over BR-SVM of 5-20%, 6-16% and 6-17% for VIPER,
GRID and CUHK respectively. Meanwhile we obtain a margin of
improvement over SDALF of up to 70%, 5%, 25% and 31% for
VIPER, GRID and CUHK. At some point, for all learning models, the data will be sufﬁciently sparse that LLF approaches will
be best. However DTR’s margin over BR-SVM, means that standard LLFs can be outperformed with less training data than before.
DTR model outperforms the best LLF with down to 1/16th data
for VIPER, 1/4 data for GRID and 1/8th data for CUHK. Importantly, performance of DTR is usually dramatically better than simple nearest-neighbor on HSV (blue), which is the feature on which
DTR was trained. Note that our weaker result on the PRID dataset
can be understood by the generally poor performance of the HSV
feature used by our DTR in this domain (see Section 4.5). This
could in general be ameliorated by including other feature types
within our MKL framework.
These results are also visualized in Figure 5, showing the CMC
curve for each domain and data sparsity condition (line-style), of
BR-SVM-based re-identiﬁcation versus our domain-transfer model
(color). The magenta CMC curves representing the transfer condition enclose the green non-transfer curves in each case. Finally, for
GRID and CUHK we observe that even with the maximum volume
of training data, transfer learning is still able to improve perfor-
Recognition Rate
Recognition Rate
Recognition Rate
Recognition Rate
BR−SVM 1/2
BR−SVM 1/4
BR−SVM 1/8
BR−SVM 1/16
Figure 5: CMC curves for re-identiﬁcation with and without
transfer. Each line-type illustrates a different volume of training data. Ir each case the transfer CMC curve encloses the
non-transfer curve.
mance (Figure 5, solid magenta CMC curves enclosing solid green
CMC curves; Figure 4, magenta curves under green curves).
Some visual examples of the improvement provided by our DTR
approach over BR-SVM in each dataset are shown in Figure 7. In
each case, the correct match to the probe is highlighted in green
and the upper rows show the ranked matches by DTR versus ranked
matches by BR-SVM in lower rows. Finally, Table 3 summarises
some accuracies of each method at different ranks under the various
conditions. In the majority of cases DTR clearly outperforms BR-
Cross-Domain Analysis
To provide some insight into the cross-domain results above,
we present some analysis of the afﬁnity between the major reidentiﬁcation datasets by way of the learned weights for each kernel. Figure 6 plots the weights for re-identiﬁcation for each target
domain (rows) against the data source (columns). As expected,
each dataset is highly relevant to itself (strong diagonal). Crossdataset transfer is illustrated by the off-diagonal weights. It is evident that the VIPER re-identiﬁer is relevant to assist both GRID and
CUHK, but not PRID. Interestingly, there is some degree of transferability between VIPER, GRID and CUHK. However, the PRID
dataset is neither useful as a source for any others, nor making use
of any others as a source. This reﬂects the previous (Figure 4) results showing that the transfer performance for PRID was no better
than the local only performance. Nevertheless, it is reassuring that
in this case of an irrelevant source, the sparsity prior of our transfer
framework was able to apply zero weighting (Figure 6) and hence
avoided automatically negative transfer (Figure 4).
Additional Analysis
We next provide some additional analysis about the existing models and datasets to provide some insight into the domain transfer
problem, and further validate our contribution as illustrated in Sections 3.1 and 4.4.
Cross-domain generalization of low-level features
Figure 6: Cross-dataset afﬁnity for re-identiﬁcation. Darker
blocks indicate a stronger cue.
Table 1: Low-Level Features (LLFs) often do not generalize
across domains. Columns are LLFs used in NN re-id on four
public datasets (rows). We report Expected Rank (ER), lower
scores are better. Bold scores are best; red scores are worst.
To investigate the generalisation of low-level features, we perform re-identiﬁcation using non-learned nearest-neighbor matching on the four datasets. The results are shown in Table 1, expressed
as expected rank. The best results are highlighted in bold, and the
worst in red. The important point to note here is that the best and
worst low-level feature vary signiﬁcantly by domain. That is, the
ranking of different feature types does not generalize across domain. This highlights that selecting a generic good feature for all
domains is not plausible, and leveraging learning based methods
to adapt to the appearance of a given camera view is critical. We
note that while SDALF is the most effective feature overall, it is
extremely computationally extensive to extract and thus of limited
suitability for practical real-time applications.
Cross-domain generalization of learning models
We next perform re-identiﬁcation using two learning methods:
BR-SVM and attribute learning , each of which provides at
least near state-of-the-art performance when applied within a single domain. To evaluate cross-domain generalization, we train the
methods on each domain (VIPER, PRID, GRID, CUHK) and apply them to all domains, thus obtaining 16 conditions3 per method
as shown in Table 2. The important points to note here are that
(i) for both learning methods, the within-domain performance (diagonal of the table) is signiﬁcantly better than the across-domain
performance, i.e., the methods do not directly generalize acrossdomain; and (ii) the performance of the learning methods when
applied across-domains is actually worse than the low-level feature methods (Table 1). This shows that achieving a useful level of
performance with learning methods outside of closed-world benchmarks is non-trivial, and hence highlights the value of our contribution in this paper.
The above results together show that neither low-level features
nor learning methods generalize directly and reliably across-domains.
The only viable route to good performance therefore is to learn a
new model for each pair of cameras. However the quadratic num-
3Minus ATTR for CUHK because we had no attribute annotation for this domain.
Figure 7: Some examples of early-rank matches from our system. The leftmost image is the probe image, with gallery images ranked by similarity to the right. The correct match to the
probe is highlighted in green. From top to bottom, we present
two examples from VIPeR, PRID, GRID and CUHK.
Table 2: Learning-based re-id methods may transfer “blind”
and retain some utility on untrained datasets but performance
is penalised. Rows are training sources, columns are testing
targets. Scores are the Expected Rank (ER), lower scores are
ber of pairs means that in practice exhaustive annotation is unreasonable beyond benchmark dataset testing exercises. This is turn
shows the value of our contribution of transferring re-identiﬁcation
models for reducing training data requirements.
Computational Efﬁciency
The practically relevant aspect of performance is online matching efﬁciency. As with any SVM approach, our model is linear in
the number of support vectors at test time. In particular it requires
S times the computation of for S source domains. In practice
this means that our multi-kernel matching took about a millisecond
per comparison (79ms including ELF feature extraction) with our
unoptimized Matlab implementation. We note that despite making
use of a strong model, this is still faster than state of the art LLFs
such as SDALF , which requires approximately 460ms per comparison.
CONCLUSION
In this paper we introduced the problem of domain transfer for
re-identiﬁcation. This is a highly relevant challenge for taking reidentiﬁcation out of closed-world benchmarks and making it useful
for real-world applications. By formulating domain-transfer re-id
as a SVM multi-kernel learning problem, we were able to achieve
good performance on a wide variety of public benchmark datasets
with a fraction of the training data required by previous methods.
Moreover, our approach is able to evaluate available source domains automatically, weighting the relevant sources appropriately
and ignoring irrelevant sources, thus avoiding negative transfer. We
achieved these results despite the fact that the datasets used were
unrelated and independently collected. With a wider selection of
source datasets to choose from, the ability to construct a mapping
to the target domain of interest (Figure 2) will be increased ,
and our results are therefore expected to only improve further as
additional datasets are released.
There are many remaining issues for future work in order to
improve performance and further reduce the amount of training
required data for good performance can be achieved. So far we
have only used the simplest color feature available, absolute performance should improve using better features as input, and multiple
features can readily be included our MKL framework. With regards to negative instance selection, we thus far randomly selected
10 negative pairs per positive pair for training. Re-identiﬁcation
accuracy can be increased at the cost of additional computation by
increasing this ratio . However, more interesting is investigating
active learning or instance mining approaches to optimally select
the right instances from the quadratic number of pairs is there-
VIPeR, Rank:
BR-SVM 1/2
BR-SVM 1/4
BR-SVM 1/8
BR-SVM 1/16
PRID, Rank:
BR-SVM 1/2
BR-SVM 1/4
BR-SVM 1/8
BR-SVM 1/16
GRID, Rank:
BR-SVM 1/2
BR-SVM 1/4
BR-SVM 1/8
BR-SVM 1/16
CUHK, Rank:
BR-SVM 1/2
BR-SVM 1/4
BR-SVM 1/8
BR-SVM 1/16
Table 3: We present rank scores for each of the target datasets
and target annotation volumes for both Binary-Rank SVM
(BR-SVM) and our Domain Transfer Re-identiﬁcation (DTR)
Higher scores are more desirable, as are earlier
ranks which are more useful to human operators.
Our approach shows that even with extremely reduced annotations
on the target dataset, re-identiﬁcation knowledge can be transferred in order to improve performance over low-level features
fore an important open question. Finally, we would also like to
transductively exploit the unlabeled data distribution in the target
domain, and eventually move towards completely annotation free
transfer learning for re-id.