Textons, Contours and Regions: Cue Integration in Image Segmentation
Jitendra Malik, Serge Belongie, Jianbo Shi and Thomas Leung
Computer Science Division
University of California at Berkeley
Berkeley, CA 94720
fmalik,sjb,jshi,leungt 
This paper makes two contributions. It provides (1) an
operational deﬁnition of textons, the putative elementary
units of texture perception, and (2) an algorithm for partitioning the image into disjoint regions of coherent brightness and texture, where boundaries of regions are deﬁned
by peaks in contour orientation energy and differences in
texton densities across the contour.
Julesz introduced the term texton, analogous to a
phoneme in speech recognition, but did not provide an operational deﬁnition for gray-level images. Here we re-invent
textons as frequently co-occurring combinations of oriented
linear ﬁlter outputs. These can be learned using a K-means
approach. By mapping each pixel to its nearest texton, the
image can be analyzed into texton channels, each of which
is a point set where discrete techniques such as Voronoi diagrams become applicable.
Local histograms of texton frequencies can be used with
2 test for signiﬁcant differences to ﬁnd texture boundaries. Natural images contain both textured and untextured
regions, so we combine this cue with that of the presence of
peaks of contour energy derived from outputs of odd- and
even-symmetric oriented Gaussian derivative ﬁlters. Each
of these cues has a domain of applicability, so to facilitate
cue combination we introduce a gating operator based on a
statistical test for isotropy of Delaunay neighbors. Having
obtained a local measure of how likely two nearby pixels
are to belong to the same region, we use the spectral graph
theoretic framework of normalized cuts to ﬁnd partitions of
the image into regions of coherent texture and brightness.
Experimental results on a wide range of images are shown.
Introduction
This paper has twin objectives. It provides (1) an operational deﬁnition of textons, the putative elementary units of
image analysis, and (2) an algorithm for partitioning the image into disjoint regions based on both brightness and texture. These objectives are coupled—cue integration relies
on, and thus reveals, the advantages of the texton representation.
Introducing Textons
Julesz introduced the term texton, analogous to a
phoneme in speech recognition, more than 20 years ago 
as the putative units of preattentive human texture perception.
He described them qualitatively for simple binary line segment stimuli—oriented segments, crossings
and terminators—but did not provide an operational deﬁnition for gray-level images. Subsequently, texton theory
fell into disfavor as a model of human texture discrimination as accounts based on spatial ﬁltering with orientation
and scale-selective mechanisms which could be applied to
arbitrary gray-level images became popular.
There is a fundamental, well recognized, problem with
linear ﬁlters. Generically, they respond to any stimulus. Just
because you have a response to an oriented odd-symmetric
ﬁlter doesn’t mean there is an edge at that location. It could
be that there is a higher contrast bar at some other location
in a different orientation which has caused this response.
Tokens such as edges or bars or corners can not be associated with the output of a single ﬁlter. Rather it is the signature of the outputs over scales, orientations and order of the
ﬁlter that is more revealing.
Here we introduce a further step by focussing on the
outputs of these ﬁlters considered as points in a high dimensional space (typically on the order of
36 ﬁlters are
used). We perform vector quantization, or clustering, in this
high-dimensional space to ﬁnd prototypes. Call these prototypes textons—we will ﬁnd empirically that these do tend
to correspond to oriented bars, terminators and so on. One
can construct a universal texton vocabulary by processing
a large number of natural images, or we could ﬁnd them
adaptively in windows of images. In each case the
technique can be used. By mapping each pixel to the texton nearest to its vector of ﬁlter responses, the image can be
analyzed into texton channels, each of which is a point set.
It is our opinion that the analysis of an image into textons will prove useful for a wide variety of visual processing
tasks. For instance, in we use the related notion of 3D
textons for recognition of textured materials. In the present
paper, our objective is to develop an algorithm for the segmentation of an image into regions of coherent brightness
and texture–we will ﬁnd that the texton representation will
enable us to address the key problems in a very natural fashion. Let’s begin with a review of the outstanding issues in
low level image segmentation.
Challenges in image segmentation
Scale selection in textured regions continues to be a fundamental problem–whatever one’s choice of textured descriptor, it has to be computed over a local window whose
size and shape need to be determined adaptively.
makes scale selection a challenge is that the technique must
deal with the wide range of textures–regular such as the
polka dots in Figure 8(b), stochastic in Figure 8(a), or intermediate cases such as the stripes of the tiger in Figure 8(c)–in a seamless way. Furthermore it would be desirable if in the neighborhoodof boundaries, the windows over
which texture descriptors are computed could be shaped to
lie largely on the correct side of the boundary.
The other major issue is dealing with images which have
both textured and untextured regions. Here boundaries must
be found using both contour and texture analysis. However
what we ﬁnd in the literature are approaches which concentrate on one or the other.
Contour analysis (e.g. edge detection) may be adequate
for untextured images, but in a textured region it results in
a meaningless tangled web of contours. Think for instance
of what an edge detector would return on the snow region
in Figure 8(a). The traditional “solution” for this problem
in edge detection is to use a high threshold so as to minimize the number of edges found in the texture area. This is
obviously a non-solution–such an approach means that lowcontrast extended contours will be missed as well. There is
no recognition of the fact that extended contours, even weak
in contrast, are perceptually signiﬁcant.
While the perils of using edge detection in textured regions have been noted before (see eg. ), a complementary problem of contours constituting a problem for texture analysis does not seem to have been recognized before.
Typical approaches are based on measuring texture descriptors over local windows, and then computing differences
between window descriptors centered at different locations.
Boundaries can then give rise to thin strip-like regions, as
in Figure 1. For speciﬁcity, assume that the texture descriptor is a histogram of linear ﬁlter outputs computed over a
window. Any histogram window near the boundary of the
two regions will contain large ﬁlter responses from ﬁlters
oriented along the direction of the edge. However, on both
sides of the boundary, the histogram will indicate a featureless region. A segmentation algorithm based on, say,
distances between histograms, will inevitably partition the
boundary as a group of its own. As is evident, the problem is
not conﬁned to the use of a histogram of ﬁlter outputs as texture descriptor. Figure 1 (b) shows the actual groups found
by an EM style algorithm using an alternative color/texture
descriptor .
Figure 1. Demonstration of the “contour-as-a-texture”problem using a real image. (a) Original image of a bald eagle.
(b) The groups found by an EM style algorithm .
Our approach
We pursue image segmentation in the framework of Normalized Cuts introduced by Shi and Malik . The image
is considered to be a weighted graph where the nodes are
pixels and arc weights denote a local measure of similarity
between the two pixels. Grouping is performed by ﬁnding
eigenvectors of the Normalized Laplacian of this graph. The
fundamental issue then is that of specifying the arc weights
ij; we rely on normalized cuts to go from these local measures to a globally optimal partition of the image.
The algorithm begins by analyzing the image into textons ( x2). In the next stage ( x3), we determine for every
pixel a suitable local neighborhood,the appropriate window
for computing the local texture descriptor, and a measure of
the anisotropy of this neighborhood. A histogram of texton
densities is used as the texture descriptor. We use a gating
operator based on a statistical test for isotropy of Delaunay
neighbors. These computations critically rely on the spatial
analysis of individual texton channels. The fact that each
texton channel is a point set is very convenient, because it
enables one to use discrete techniques such as Voronoi diagrams and Delaunay triangulations.
We are now ready ( x4) to specify the arc weights
combining both brightness and texture information. The
texture cue is coded by making the arc weight dependent
2 differences between local texton histograms; and the
brightness cue is treated in the intervening contour framework of Leung and Malik using peaks in contour orientation energy. The anisotropy of the local descriptor window at a pixel serves to gate between these cues so as to
circumvent the problems listed in
Results from the algorithm are presented in
Filters and Textons
Since the early 1980s, many approaches have been proposed in the computer vision literature that employ ﬁlterbased descriptions of images . By the term ﬁlterbased we mean that the fundamental representation for a
pixel in an image includes not only its brightness or color
information, but also the inner product of the neighborhood
centered on that pixel with a set of ﬁlters tuned to various
orientations and spatial frequencies. (See Figure 2 for an
example of such a ﬁlter set.)
Figure 2. Gaussian derivative ﬁlter set consisting of 2 phases
(even and odd), 3 scales (spaced by half-octaves), and 6 orientations (equally spaced from 0 to
). The basic ﬁlter is
a difference-of-Gaussian quadrature pair with
1 elongation. Each ﬁlter is divided by its
1 norm for scale invariance.
As discussed for example in , vectors of ﬁlter responses have many appealing properties, including relationships to physiological ﬁndings in the primate visual system and to the basic mathematical notion of a Taylor
series expansion.
Though the representation of textures using ﬁlter responses is extremely versatile, one might say that it is overly
redundant (each pixel values is represented by
responses, where
il is usually around
36). Moreover, it
should be noted that we are characterizing textures, entities with some spatially repeating properties by deﬁnition.
Therefore, we do not expect the ﬁlter responses to be totally
different at each pixel over the texture. Thus, there should
be several distinct ﬁlter response vectors and all others are
noisy variations of them.
This observation leads to our proposal of clustering the
ﬁlter responses into a small set of prototype response vectors. We call these prototypes textons.
Algorithmically,
each texture is analyzed using the ﬁlter bank shown in Figure 2. There are a total of
36 ﬁlters. Each pixel is now
transformed to a
36 dimensional vector of ﬁlter
response These vectors are clustered using a
K-means algorithm. The criterion for this algorithm is to ﬁnd
K “centers” such that after assigning each data vector to the nearest
center, the sum of the squared distance from the centers is
minimized.
K-means is a greedy algorithm that ﬁnds a local minimum of this criterion1. In this paper, we use the
1For more discussions and variations of the K-means algorithm, the
reader is referred to .
kmeans function in the NETLAB toolbox .
It is useful to visualize the resulting cluster centers in
terms of the original ﬁlter kernels. To do this, recall that
each cluster center represents a set of projections of each
ﬁlter onto a particular image patch. We can solve for the
image patch corresponding to each cluster center in a least
squares sense by premultiplying the vectors representing the
cluster centers by the pseudoinverse of the ﬁlterbank .
The matrix representing the ﬁlterbank is formed by concatenating the ﬁlter kernels into columns and placing these
columns side by side. The set of synthesized image patches
for two test images are shown in Figures 3(b) and 4(b).
These are our textons. The textons represent assemblies of
ﬁlter outputs that are characteristic of the local image structure present in the image.
Figure 3. (a) Polka-dot image. (b) Textons found via
Kmeans with
25, sorted in decreasing order by norm.
(c) Mapping of pixels to the texton channels. The dominant
structures captured by the textons are translated versions of
the dark spots. We also see textons corresponding to faint
oriented edge and bar elements. Notice that some channels
contain activity inside a textured region or along an oriented
contour and nowhere else.
Looking at the polka-dot example, we ﬁnd that many of
Figure 4. (a) Penguin image. (b) Textons found via
Kmeans with
25, sorted in decreasing order by norm.
(c) Mapping of pixels to the texton channels. Among the
textons we see edge elements of varying orientation and
contrast along with elements of the stochastic texture in the
the textons correspond to translated versions of dark spots2.
Also included are a number of oriented edge elements of
low contrast and two textons representing nearly uniform
brightness. The pixel-to-texton mapping is shown in Figure 3(c). Each subimage shows the pixels in the image that
are mapped to the corresponding texton in Figure 3(b). We
refer to this collection of discrete point sets as the texton
channels. Since each pixel is mapped to exactly one texton,
the texton channels constitute a partition of the image.
Textons and texton channels are also shown for the penguin image in Figure 4. Notice in the two examples how
much the texton set can change from one image to the
next. The spatial characteristics of both the deterministic
2It is straightforward to develop a method for merging translated versions of the same basic texton, though we have not found it necessary.
Merging in this manner decreases the number of channels needed but necessitates the use of phase-shift information.
polka dot texture and the stochastic rocks texture are captured across several texton channels. In general, the texture
boundaries emerge as point density changes across the different texton channels. In some cases, a texton channel contains activity inside a particular textured region and nowhere
else. By comparison, vectors of ﬁlter outputs generically respond with some value at every pixel – a considerably less
clean alternative.
Texton Channel Analysis
As discussed in the preceding section, the mapping from
pixel to texton channel provides us with a number of discrete point sets where before we had continuous-valued ﬁlter vectors. Such a representation is well suited to the application of techniques from computational geometry and
point process statistics. With these tools, one can approach
questions such as, “what is the neighborhood of a texture
element?” and “how similar are two pixels inside a textured
Deﬁning Local Scale Selection
The texton channel representation provides us a natural
way to deﬁne texture scale. If the texture is composed of
texels, we might want to deﬁne a notion of texel neighbors
and consider the mean distance between them to be a measure of scale. Of course, many textures are stochastic and
detecting texels reliably may be hard even for regular textures.
With textons we have a “soft” way to deﬁne neighbors.
For a given pixel in a texton channel, ﬁrst consider it as
a “thickened point”— a disk centered at it.
The idea is
that while textons are being associated with pixels, since
they correspond to assemblies of ﬁlter outputs, it is better
to think of them as corresponding to a small image disk de-
ﬁned by the scale used in the Gaussian derivative ﬁlters. Recall Koenderink’s aphorism about a point in image analysis
being a Gaussian blob of small
Now consider the Delaunay neighbors of all the pixels in
the thickened point of a pixel
i which lie closer than some
outer scale.3. The statistics of Delaunay edge lengths provides a natural measure of scale. In passing, we note that
this neighborhood tends to be in the same image region as
i, since all the nodes in it belong to the same texton
channel and are proximal.
In Figure 5a, the Delaunay triangulation of a zoomed-in
portion of one of the texton channels in the rocky region of
Figure 4 is shown atop a brightened version of the image.
Here the nodes represent points that are similar in the image
while the edges provide proximity information.
3This is set to 13 pixels in our experiments.
Characterizing Isotropy
We will ﬁnd it necessary later in this paper when we examine cue integration to have a statistical test for whether a
pixel is in the interior of a textured region or on its boundary. The notion of Delaunay neighborhood for a thickened
point deﬁned previously can be used. We consider the orientations of the vector from pixel
i to each of these points. 4
We obtain the local estimate of isotropy by performing
a simple statistical test for randomness on the neighborhood the pixels inside each texton channel. The following
description will use Figure 5 to illustrate this by example;
here we consider two sample pixels in the penguin image,
the ﬁrst on the wing boundary, the second inside the rocky
The neighborhood for a point on the wing boundary is
shown in Figure 5c; the ﬁlled circle marks pixel
open circles mark its neighbors. For this pixel, the neighborhood is clearly not isotropic. This is quantiﬁed by computing the modiﬁed Kuiper statistic
V from the angles
of the vectors connecting pixel
i to its neighbors. Denoting
the sorted angles by
n, the test proceeds as follows.
and compute the statistics
= maximum of
= maximum of
Intuitively, this is like a Kolmogorov-Smirnov test for uniformity where the data points are angles. Tabulated values
for this test are given in ; from this we ﬁnd that when
2 the neighborhood fails the isotropy test at an upper
percentage point of
0:01. The value of
V for the pixel on
the wing boundary is
2:3; hence it is labelled “not isotropic.”
By contrast, a pixel chosen in the rocky ground area gives
0:8, and is therefore labelled “isotropic.”
Computing windowed texton histogram
Pairwise texture similarities can be computed by comparing windowed texton histograms, where the windows are
centered around the two pixels being compared. Each histogram has
K bins, one for each texton channel. The value
kth histogram bin for a pixel
i is found by counting
how many pixels fall inside a box5 centered around pixel
4We exclude immediate 8 grid neighbors of
i as they deﬁnitely do not
constitute samples independent from
5At this stage we have not implemented scale selection and just use
boxes of size
11 pixels.
in texton channel
k. Thus the histogram represents texton
frequencies in a local neighborhood. We can write this as
(i) is the set of pixels in the box centered on
[] is the indicator function, and
) returns the texton
assigned to pixel
Vn=0.83803
uniform quantiles
sample quantiles
uniform quantiles
sample quantiles
Figure 5. (a,b) Illustration of the Delaunay neighbors in
zoomed in regions of two different texton channels on the
penguin image. The ﬁlled circle marks pixel
i and the open
circles mark its neighbors. (c,d) Visualization of the computation of the statistical test for isotropy. The test value for
0:8 while that of (b) is
2:3. Using a signiﬁcance level of
0:01, the isotropy hypothesis is rejected
Cue combination strategy
The obvious approach to cue integration (integrating information from both contours and textures) is to deﬁne
the weight between pixels
j as the product of the
contribution from texture and that from contour:
. We have to be careful to avoid the problems
listed in the Introduction ( x1.2) by suitably gating the cues.
The spirit of the gating method is to make each cue “harmless” in the vicinity of regions where one or the other cue
should not be operating. This will manifest itself as suppression of oriented energy inside regions when computing the contour weights, and suppression of textons along
boundaries when computing the texture weights.
Here is our way of deﬁning the individual components
and combining them:
The deﬁnition of
is adopted from that deﬁned
Contour information in an image is computed
“softly” through orientation energies (OE) from elongated
quadrature ﬁlter pairs. We introduce a slight modiﬁcation
here to allow for exact sub-pixel localization of the contour
by ﬁnding the local maxima in the orientation energy perpendicular to the contour orientation . The conﬁdence
of this contour is given by the orientation energy.
then deﬁned as follows:
ij is the set of local maxima along the line joining
j. In words, two pixels will have a weak link
between them if there is a strong local maximum of orientation energy along the line joining the two pixels. On the
contrary, if there is little energy, for example in a constant
brightness region, the link between the two pixels will be
Measuring Texture Similarity
Pairwise texture similarities can be computed by comparing windowed texton histograms computed using the
technique described previously (x3.3). A number of methods are available for comparing histograms; among them a
simple and effective choice is the
2 test, deﬁned as
j are the two histograms. For a comparison
2 test versus other texture similarity measures, the
readers are referred to .
is deﬁned using the
2 distance between texton
histograms at pixels
Cue Combination
Cue combination is accomplished in the following steps.
1. We ﬁrst compute the isotropic measure
(i) and unisotropic measure
(i) at each point,
i, in the image.
One can think of
(i) as the 1D-ness measure, while
(i) as the texture-ness measure. Deﬁne
  sigmoid(V
To simplify the computaton, a discrete version of the
sigmoid is used in our experiments.
We select the
V at 2.0 at each pixel as discussed in
Figure 6 shows one such computed
tiger image.
Figure 6. Subplot (a) and (b) shows the computed
measure in a tiger image. The
values are thresholded at
2:0, and masked on the original image.
2. We then compute the texture feature descriptor at each
pixel of the image, gated by the function
main idea is to ignore any neighboringpixels which are
near a region boundary in the histogram computation.
Deﬁne the gated histogram as:
)). This deﬁnition of
texture histogram avoids the problem of texture comparison near object boundaries. At intensity boundaries, the boundaries themselves can no longer be used
as features, and therefore will not form groups on their
own. This deﬁnition of the gated histogram also has
a desirable behavior near texture boundaries: it tends
to pool information from the correct side of the region.
Figure 7 illustrates this point. From the gated texture
Neighborhood
Figure 7. At the texture boundary, the proposed gated histogram tends to pool information from the “correct region”.
Take the point marked “A” in the boundary region between
the dashed lines as an example. By masking out all features
in the boundary neighborhood, the texture histogram computed for “A” will contain only the information from region
1. This avoids the problem of having corrupted texture histogram information as we get closer to the region boundary.
histogram, we can compute the pair-wise texture similarity,
As we move deeper into the boundary region, we have
fewer points in the neighborhood to compute the histogram. In that case, the histogram difference becomes
less reliable, and therefore should be discounted. We
deﬁne the reliability measure for each histogram measure at pixel
our experiments, the
p is set to
3. In parallel to the texture computation, the intervening
contour cue gated by the texture-ness can be used to
group/segment pixels. The computation is same as in
x4.1, except the ﬁlter energy is suppressed by textureness measure
4. Let the two pair-wise feature distance functions computed in the two previous steps be
), from the texture cue and intervening contour cue respectively. Since the test for isotropy is
purely a local one, one expects the
to misﬁre sometimes. By combining the two cues, and
applying global grouping algorithm to this data, we
hope to “smooth out” these errors in the
estimates. The rule we have for combining two cues is:
= min(p(i);
)) is the signiﬁcance of
the histogram comparison between pixels
5. Applying grouping algorithm to the combined pairwise similarity measure to obtain the ﬁnal segmentation. We used the normalized cut algorithm for this
step . The global nature of the normalized cut algorithm help us overcome the errors in the local
computation.
We have run our algorithm on a variety of natural images.
Figures 8 and 9 show typical segmentation results. In all
the cases, the regions are cleanly separated from each other
using combined texture and contour cues.
Grouping based on each of the cues alone would result in severe artifacts: In Figure 8a, the contours on the
penguin would form isolated groups using the texture cue.
Similar problems would occur at the intensity boundaries
in 8b and 8c. Grouping based on contour information alone
would result in over-fragmentation of the pebbles in 8a
and 9a, and the tiger body in 8c. On the other hand, in Figure 8b the lower arm can not be separated from the upper
arm without using contour information.
Figure 8. Segmentation results of three images using combined texture and intervening contour cue. The image regions are cleanly segmented from each other using the combined cues. In all three cases, grouping by each of the cues
alone will not produce the right results.
Acknowledgement
This research was supported by (ARO) DAAH04-96-1-0341, the Digital Library Grant IRI-9411334, NSF Graduate Fellowships to SB and JS
and a Berkeley Fellowship to TL.