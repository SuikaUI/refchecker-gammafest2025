UC Berkeley
UC Berkeley Previously Published Works
A local nearest-neighbor convex-hull construction of home ranges and utilization
distributions
 
Ecography, 27(4)
Getz, Wayne M
Wilmers, C C
Publication Date
2004-08-01
Peer reviewed
eScholarship.org
Powered by the California Digital Library
University of California
A local nearest-neighbor convex-hull construction of home ranges and
utilization distributions
Wayne M. Getz and Christopher C. Wilmers
Getz, W. M. and Wilmers, C. C. 2004. A local nearest-neighbor convex-hull
construction of home ranges and utilization distributions. / Ecography 27: 489/505.
We describe a new method for estimating the area of home ranges and constructing
utilization distributions (UDs) from spatial data. We compare our method with
bivariate kernel and a-hull methods, using both randomly distributed and highly
aggregated data to test the accuracy of area estimates and UD isopleth construction.
The data variously contain holes, corners, and corridors linking high use areas. Our
method is based on taking the union of the minimum convex polygons (MCP)
associated with the k/1 nearest neighbors of each point in the data and, as such, has
one free parameter k. We propose a ‘‘minimum spurious hole covering’’ (MSHC) rule
for selecting k and interpret its application in terms of type I and type II statistical
errors. Our MSHC rule provides estimates within 12% of true area values for all 5 data
sets, while kernel methods are worse in all cases: in one case overestimating area by a
factor of 10 and in another case underestimating area by a factor of 50. Our method
also constructs much better estimates for the density isopleths of the UDs than kernel
methods. The a-hull method does not lead directly to the construction of isopleths and
also does not always include all points in the constructed home range. Finally we
demonstrate that kernel methods, unlike our method and the a-hull method, does not
converges to the true area represented by the data as the number of data points
W. M. Getz ( ) and C. C. Wilmers, Dept of Environmental
Sciences, Policy and Management, Univ. of California Berkeley, CA 94720, USA.
The construction of space use maps from points
representing distributions of animals or plants in space
or time are critical in addressing a range of questions in
ecology from the behavioral to the landscape level.
Ecologists are generally interested in building two types
of such maps: home range maps that
delineate the spatial extent or outside boundary of an
animals movement, and utilization distributions (UDs)
 
that represent the density of space used by animals.
The simplest method for constructing home ranges is
the minimum convex polygon (MCP). This method is
still widely employed 
despite recent recognition that it provides an extremely
poor fit to data when the home range of an animal or the
distribution of a population is strongly non-convex
 . In search of a better method,
Burgman and Fox propose using a-hull constructions, which involve producing Delauney triangulations
of the data and then removing all sides that are a times
longer than the median of the original sides. Like the
MCP, this method does not explicitly reveal high and
low density use areas or clusters of points in cores. Also,
in applications to real data, a-hull constructions leave
some points hanging outside the area they bound,
resulting in area estimates of home ranges that are often
too conservative.
In the context of statistical errors, a home range or
UD map can be regarded as a hypothesis about the
Accepted 9 February 2004
Copyright # ECOGRAPHY 2004
ISSN 0906-7590
ECOGRAPHY 27: 489/505, 2004
ECOGRAPHY 27:4 
expected space use of an organism and is subject to both
type I (excluding valid areas) and type II (including
adjustable
parameters one can trade-off these errors, where the
optimal trade depends on the consequence of each type
of error. Thus, if one is looking at the association of the
UD of an animal population with background vegetation types, the balance may be tipped in favor of type I
over type II errors (i.e. reducing false associations of
animals with particular vegetation types). On the other
hand, if one is looking for areas in a landscape that
contain hidden factors causing some disease in a
population, then type II errors may be more serious
than type I errors in generating a list of putative factors
common to all areas , such as kernel
methods . Kernel methods construct UDs by taking weighted sums of local
parametric distributions (e.g. bivariate normal kernels)
centered on each point in the data set being modeled
 . Hence they perform
well in constructing multimodal UDs for data generated
as the sum of several bivariate normal distributions
 . The simplest of the kernel
methods is the fixed method: it uses the same smoothing
parameter value h at each point (this value determines
the relative peakedness of the local distributions). A
‘‘best’’ value for h can be found by minimizing the
mean-integrated-square-error of the UD fitted to the
data as a function of h . Adaptive kernel
methods require additional computations to implement:
they modify the value of h from point to point, based
on local densities of points. In theory, adaptive methods
should perform even better than fixed methods in
characterizing the tails of the UD, but in practice
this is not always true. Also, kernel methods are
estimating
 .
In this paper, we demonstrate that kernel methods
perform poorly when fitted to distributions arising in
landscapes that have distinct boundaries determined by
geographic or physiographic features such as cliffs,
rivers, or abrupt changes in soil types leading to abrupt
changes in vegetation or other ecological determinants.
Our method performs much better than kernel methods
in fitting UDs to home ranges with distinct boundaries
and better than the a-hull methods in incorporating all
points into the home range. We do not compare our
method to grid or rectangular methods because these
methods appear to have no advantages over ours. In
particular, they are sensitive to the size of the underlying
paving units and they use ad-hoc criteria to fill in holes
after paving has been completed . We have also not compared our
method to those based on spatial statistics or on cluster analysis because the implementation of these
is more complicated even than adaptive kernel methods,
and they have not been widely applied.
Our method is direct and easily implemented. It
involves constructing a UD from the union of convex
hulls associated with each point and its k/1 nearest
neighbors. We refer to this union as a k-NNCH
(k nearest neighbor convex hull) covering, while the
subcovering obtained from a union of the smallest of
these convex hulls covering x% of points provides for the
construction of the x% isopleth (e.g. the decile isopleths:
10%, 20%. . .100%). In the first part of this paper, we
describe the method and then use it to map the UDs
associated with computer-generated data that has sharp
boundaries, multinuclear cores 
and corridors. We then demonstrate that our algorithm
performs better than kernel methods in identifying these
features and in estimating area. Finally, we discuss where
our method is superior to the a-hull method in
constructing home ranges and utilization distributions
(as characterized by the isopleths associated the density
of points used to construct home ranges).
A k-NNCH covering for constructing UDs
Given a set of specified points the method begins by
constructing the convex hull associated with each point
and its (k/1) nearest neighbors. We refer to the area
covered by the union of all these convex hulls as a k-
NNCH covering. We then order the hulls from the
smallest to the largest. By progressively taking the union
of these from the smallest upwards, until x% of points
are included (with some rounding error), we construct
the areas whose boundaries represent the x% isolpleth of
the densest set of points in our k-NNCH covering. (See
Appendix for technical details.)
ECOGRAPHY 27:4 
Kernel methods
Both fixed and adaptive bivariate normal kernel methods were coded in MATLAB using algorithms described
in Worton . MATLAB routines were then used to
draw isopleths at the p% of the kernel density function.
We used the p/0.99 as the outer boundary for area
calculations, although some studies rather use p/0.95.
This choice does not affect our conclusions regarding the
poor estimation performance of kernel methods because
kernel methods both greatly over and under estimate the
areas involved. See Appendix for details regarding
implementation of the reference or the least-squares
cross-validated smoothing parameter values hREF and hLSCV respectively for both the fixed and
adaptive kernel methods.
The a-hull method for constructing UDs
Following the method of Burgman and Fox , we
constructed a Delauney tessellation to bound the data.
We then calculated the mean length of all connections in
this tesselation and removed those that were a times
greater than this mean for specific values of a. Finally,
we added up the area of the remaining triangles to
obtain our estimate of the area. Based on Burgman and
Fox’s finding that a/3 is the most robust integer
value of a with regard to sampling artifacts, we focused
our analysis on this value and, for purposes of comparison, on twice this value (a/6). We also explored other
values of a to get a sense of how the a-hull method
performs as a function of a. Currently, no rule (such as
the MSHC rule we propose below for selecting k for our
algorithm) has been proposed for selecting an appropriate or ‘‘best’’ value for a: a value that is bound to
differ for different sets of data.
Computer-generated data sets
We generated the five data sets below using Monte Carlo
methods . The data are designed to test
how well the methods perform at different ends of the
data spectrum (random vs highly aggregated data), on
contrasting shapes (donuts, squares, and multicore
constructs), and identifying high use and odd-shaped
boundaries (e.g. edges of lakes or land used on only one
side of a the confluence of a river and one of its
tributaries). Specifically, our idealized data sets are: 1)
Random square (RS) (Fig. 6A): 1089 points where
placed at random on the unit square. (Area/1 arbitrary
unit.) 2) Aggregated square (AS) (Fig. 5A): 1089 points
were randomly assigned x/y coordinates on the unit
square. These coordinates were then cubed leading to
increasingly higher densities of points having lower (x,y)
values (i.e. strongly aggregating around the axes, especially the origin). (Area/1 arbitrary unit). 3) Random
donut (RD) (Fig. 4A): We distributed 1089 points at
random on a donut that has an inner radius of 1 and an
outer radius of 5. The radius of each point was obtained
from the equation r14
where j is a random
variable rectangularly distributed on and an angle
between 0 and 2p was assigned at random. (Area/75.4
arbitrary units). 4) Aggregated donut (AD) (Fig. 1A):
We distributed 1089 points, as in 3 above, except in this
case we used the formula r14j3: This results in an
extremely strong clustering around the inner boundary
of the donut. (Area/75.4 arbitrary units). 5) Multicore
(MC) (Fig. 8A): This data set was constructed by placing
less dense versions of the above 4 data sets at corners of a
25/25 unit quadrant and then connecting them with
corridors. (Area is approximately 320 arbitrary / see
Appendix for details.)
The MSHC rule for selecting k
For relatively low values of k the resulting k-NNCH
coverings contain a number of holes that disappear with
increasing k. For areas with known topologies (squares,
donuts, etc.) the ‘‘minimum spurious hole covering’’
(MSHC) rule is to select the smallest value of k-that
produces a covering that has the same topology as the
given set. If the topology of the space associated with the
data is not known, we can guess its genus (number of
holes) by identifying relatively large physical features,
such as lakes, mountain peaks, or inhospitable habitats
at comparable scales. We expect these objects to produce
real holes in the data. Of course, real holes at scales that
are relatively small compared with the size of the home
range may well be missed. Differences between real and
spurious holes in k-NNCH coverings of data sets should
also be evident in plots of the number of holes in a
particular k-NNCH covering against the value of k: the
covering of spurious holes should correspond to a
leveling off of the resulting graph. Only experience
with the method, however, will reveal appropriate
methods for deciding when this leveling off has been
achieved. In our case, we know the topology of the data;
and we use k* to denote the value obtained using our
MSHC rule.
The AD data (Fig. 1 A) and various k-NNCH coverings
(k/2, 6, 10, k*/17, and k/301, where the latter is the
smallest k that covers the permanent hole in the center)
are plotted in Fig. 1. UDs and shaded deciles are drawn
in Fig. 2 for the 17-NNCH and 50-NNCH coverings
(panels A and B) for the hREF and hLSCV fixed and
ECOGRAPHY 27:4 
adaptive kernel methods (panels C/F). The areas
associated with some of these constructions are plotted
(Fig. 3A) for decile isopleths (kernel constructions) with
the number of points and associated densities covered by
each decile interval plotted in Figs 3B and C.
Decile shadings of the RD (Fig. 4A), AS (Fig. 5A)
and RS (Fig. 6A) data are plotted for the 5-NNCH,
k*-NNCH, and 50-NNCH coverings (panels B/D in
Figs 4/7), and for both fixed and adaptive kernel
methods using hREF (panels E/F in Figs 4/7) and
hLSCV (panels G/H in Figs 4/7) smoothing parameter
values. For the RS, we also include the area, number
and density plots associated with these decile intervals
(Figs 7A/C). Finally, for MC data (Fig. 8A), we plot
Fig. 1. k-NNCH coverings
(recall that k is the number of
nearest neighbors used to
construct local minimum
convex polygons) of the (A) AD
data are illustrated for the cases
(B) k/2, (C) k/6, (D) k/10,
(E) k*/17 and (F) k/301.
 
decile shadings of the 5-NNCH (Fig. 8B), k*-NNCH
(k*/17, Fig. 8C) and 50-NNCH (Fig. 8D) coverings.
For comparison we plot decile shadings of the fixed and
adaptive kernel distributions for this data for the hREF
(Fig. 8E/F) and hLSCV (Fig. 8I/J) cases.
To examine how well the methods converge to the area
associated with the AD data (Fig. 1A), we sub-sampled
five sets for each of a 30-point, 100-point and 300-point
assessment of the performance of our method (Table 1).
The UDs obtained form the k*-NNCH covering and
Fig. 2. Decile-shaded k-
NNCH coverings of the AD
(see Fig. 1A, data generated in
an area of ca 75 units) are
illustrated for the cases (A)
k*/17 (area/66 units) and
(B) k/50 (area/68 units).
Decile isopleths are plotted for
distributions obtained using the
REF smoothing parameters for
the ﬁxed (C) hREF/0.78
(area99%/99 units) and
adaptive (D) hREF/0.78
( area99%/107 units) kernel
methods and using the LSCV
smoothing parameter value for
the ﬁxed (E) hLSCV/0.058
(area99%/27 units) and
adaptive (F) hLSCV/0.058
(area99%/21 units) kernel
ECOGRAPHY 27:4 
hLSCV adaptive kernel method are illustrated in Fig. 9 for
one of the five 100 and 300 data point subsets (Fig. 9A/
B). Area estimates averaged over the five different sets
for each of the three cases are given in Table 1.
The 3-hull coverings of all five data sets are illustrated
in Fig. 10A/E. The comparison of areas estimated by
these coverings, as well as 6-hull coverings, with those of
selected k-NNCH coverings and kernel methods are
tabulated in Table 2.
Discussion
Minimum convex polygon (MCP) and kernel methods
are currently the mainstay of the home range construction literature. The reason could be the ease of calculating areas from MCPs and the existence of software
packages for implementation of kernel methods including the more complicated adaptive kernel method .
Our k-NNCH covering method is a simple extension
of MCP to a union of a set of local MCPs. As such, our
method is easy to understand and relatively easy to
implement. The primary challenge in producing a
k-NNCH covering is deciding for a particular set of
data what the ‘‘best’’ value for k might be. The best value
for k should clearly equal or exceed k*, as evident from
Fig. 1B/E. For the first four data sets (AD, RD, AS and
RS), however, k/50 provides slightly better area
estimates than k* (Table 2). This is not the case for the
fifth data set (MC: Table 2): the value of k producing the
best area estimate is likely to vary for different data sets.
Selecting the best value for k could be based on
minimizing changes in area as a function of k, but the
question remains open until more experience is gained
using our approach. The question, however, appears to
be much less pressing than that of finding the best value
of the smoothing parameter h for kernel methods
because of the vast range of area estimates obtained
for different values of h (cf. panels E/J in Fig. 8). By
contrast, comparisons of k-NNCH area estimates indicate very little difference between area estimates using
k* and the ad-hoc value k/50 for 4 of the 5 data sets
(Table 2).
Also of consideration in selecting a value for k is the
issue, as discussed in the introduction, of the relative
importance of avoiding type I vs type II errors. Errors
are unavoidable and the smaller the data set the greater
the error rate should be (although, this sensible requirement is not always true for kernel methods / Table 1).
Relatively large smoothing parameter values for the
fixed and adaptive kernel methods (i.e. hREF/0.78)
may avoid type II errors (the donut is completely
covered / see Fig. 2C, D) but produce large type I
errors (at least 32% and 43% respectively of the area are
misidentified) through the inclusion of regions that lie
beyond the outer circumference of the AD (Table 2).
Further the fixed kernel method misidentifies the AD
hole as the most heavily utilized part of the home range
(Fig. 2D).
At the other extreme, for relatively small values of the
smoothing parameter (i.e. hLSCV/0.058), both the fixed
and adaptive kernel methods do well at minimizing type
II errors, but only at considerable expense with regard to
type I errors and extensive fragmentation of the identified area (Fig. 2E, F). In particular, these methods under
estimate the area of the aggregated donut by 64% and
72% respectively (Table 2). The a-hull method performs
hardly better for the case a/3 in underestimating the
area of the AD by 49%, although the underestimate for
the case a/6 is much improved at 16% (Table 2). On the
other hand, our k-NNCH method performs well over a
large range of k values, underestimating the area of the
AD data by 12% for the 17-NNCH covering and only
9% for the 50-CH covering (Table 2).
Comparisons of home ranges constructed using k-
NNCH coverings and kernel methods for both the AD
(Fig. 2) and AS (Fig. 4) data sets indicate how much
better the former are than the latter when the data
includes heavily used boundaries and intersections of
Fig. 3. The (A) area, (B) number of points, and (C) corresponding density (number of points divided by area) included in each
decile partition are graphed for each of the two k-NNCH
coverings and two adaptive kernel distributions of the AD data
plotted in Fig. 2.
ECOGRAPHY 27:4 
Fig. 4. Decile-shaded k-
NNCH coverings of the (A)
RD data (generated in an area
of approximately 75 units) are
plotted for the cases (B) k/5
(area/44 units), (C) k*/17
(area/72 units), and (D) k/
50 (area/75 units). Decile
isopleths are plotted for
distributions obtained the
following kernel methods: (E)
ﬁxed, hREF/2.2 (area99%/
382 units); (F) adaptive,
hREF/2.2 (area99%/382); (G)
ﬁxed, hLSCV/0.44 (area99%/
110 units); and (H) adaptive
hLSCV/0.44 
Fig. 5. Decile-shaded
k-NNCH coverings of the (A)
AS data (generated in an area
of 1 unit) are plotted for the
cases (B) k*/5 (area/0.51
units), (C) k/29 (area/0.95
units), and (D) k/50 (area/
0.95 units). Decile isopleths are
plotted for distributions obtained using the following kernel methods: (E) ﬁxed, hREF/
0.025 (area99%/0.73 units); (F)
adaptive, hREF/0.025
(area99%/0.29 units); (G)
ﬁxed, hLSCV/0.0037
(area99%/0.13 units): and (H)
adaptive, hLSCV/0.0037
(area99%/0.015 units).
ECOGRAPHY 27:4 
Fig. 6. Decile-shaded k-
NNCH coverings of the (A) RS
data (generated in an area of 1
unit) are plotted for the cases
(B) k/5 (area/0.56 units),
(C) k*/22 (area/0.97), and
(D) k/50 (area/0.98 units).
Decile isopleths are plotted for
distributions obtained using the
following kernel methods: (E)
ﬁxed, hREF/0.026 (area99%/
1.21 units); (F) adaptive,
hREF/0.026 (area99%/1.23
units); (G) ﬁxed, hLSCV/0.057
(area99%/1.52 units); and (H)
adaptive, hLSCV/0.057
(area99%/1.61 units).
ECOGRAPHY 27:4 
boundaries
(corners).
For example,
k-NNCH coverings (Fig. 5B/D) clearly identify the
high-density
(lower-left)
medium-density
(upper-left and lower-right) corners of the aggregated
square (AS). Only the low-density (upper-right) corner is
not detected, and then only because no data point falls
close enough to this corner to permit identification
under any method. On the other hand, kernel methods
by design are unable to trace out corners. For the
relatively large smoothing parameter value hREF/
0.025 corners are obscured (Fig. 5E/F), and for the
much smaller smoothing parameter value hLSCV/
0.0037 the area is extraordinarily fragmented (Fig.
5G/H). Further, the estimated areas are off by orders
of magnitude: 87% and 98% underestimates respectively
for the fixed and adaptive kernel methods (Table 2).
Kernel methods perform better on non-aggregated
than aggregated data, but still have problems with
corners and donut holes. For the random square (RS)
data (Fig. 6), kernel methods smear out the corners and,
surprisingly,
algorithmically
complicated
smoothing parameter construction (Fig. 6G/H) overestimates the area of the square by more than twice that
of the much simpler hREF case (Fig. 6E/F). Also
surprisingly, in both cases the adaptive kernel method
performs marginally worse than the fixed kernel method
in estimating area (see Table 2). By contrast, provided k
is sufficiently large to cover all of the spurious holes, our
Fig. 7. The (A) area, (B)
number of points, and (C)
corresponding density (number
of points divided by area)
included in each decile partition
are graphed for the larger two
k-NNCH coverings and two
adaptive kernel distributions of
the RS data plotted in Fig. 6.
ECOGRAPHY 27:4 
Fig. 8. Decile-shaded
k-NNCH coverings of the (A)
MC data (generated in an area
of approximately 320 units are
plotted for the cases (B) k/5
(area/199) units; (C) k*/17
(area/347 units) and (D) k/
50 (area/449 units). Decile
isopleths are plotted for distributions obtained the following
kernel methods: (E) ﬁxed,
hREF/28 (area99%/3459
units), (F) adaptive, href/28
(area99%/3459 units); (G)
ﬁxed h/2.8 (area99%/1429
units); (H) adaptive h/2.8,
area99%/1445 units); (I) ﬁxed,
hLSCV/0.12 (area99%/228
units); and (J) adaptive,
hLSCV/0.12 
k-NNCH coverings accurately maps out the home range
and its associated distributions of points (higher and
lower densities areas arise at random). In particular, k-
NNCH coverings underestimates the area of the square
by 3% for k*/22 and by 2% when k/50 (Table 2).
(Note because the points always fall within the defined
unit square, the actual area represented by the points is
always B/1, so the best method should always give a
slight underestimate.) The a-hull method does comparatively well in underestimating the area of the square by
5% when a/3 and only 2% when a/6.
For the random donut (RD) data (Fig. 4A), our k-
NNCH method continues to provided good estimates of
the area, underestimating it by 5% for the k*-NNCH
(k*/18) covering and by only 1% for selected 50-
NNCH covering. Kernel methods, on the other hand fail
to locate the hole in all case (Fig. 4E/H). Further, kernel
methods provide very poor estimates of the RD area
using hREF, overestimating it by 409% in the case of both
the fixed and adaptive kernel methods (Table 2). Even
the ‘‘optimized’’ hLSCV parameter performs poorly,
overestimating the area by 48% for the fixed and 53%
for the adaptive kernel methods (Table 2). Again, the ahull method does well in underestimating the area by 8%
when a/3 and 4% when a/6, which we can compare
with 5% and 1% underestimates for the k*-NNCH and
50-NNCH constructions respectively (Table 2).
Multimodal data also challenges the construction of
UDs. Although kernel methods are regularly used to fit
distributions to multimodal data, Casear et al. 
have demonstrated that the Thiessen method, employing
a simple Dirichelet tessellations of the data, is superior
to kernel methods in identifying core usage areas. The
Thiessen method itself provides an estimate of area equal
to MCP, which is generally very poor . From Fig. 8, it is clear that kernel methods
perform very poorly in mapping out the home range
distribution of the MC data (Fig. 8A). In the case of
hREF/28.4, the fixed and adaptive kernel methods
completely fail to identify high use areas (Fig. 8E/F);
and they overestimate the area by an order of magnitude
(Table 2). In the case of hLSCV/0.12, the fixed and
adaptive kernel methods yield highly fragmented home
ranges (Fig. 8I/J); and they underestimate the area by
close to 33% (Table 2). For the completely ad-hoc
intermediate case h/2.84 the core areas are identified
without unduly fragmenting the home range (Fig. 8G/
H), but even then very poor representations are obtained
of the shape and size of the core areas and associated
corridors.
Our k-NNCH coverings capture very well the shape of
the core areas and the corridors (Fig. 8B/C) associated
with the MC data. Additionally, the k*-NNCH covering
identifies both donut holes and only overestimates the
area by 8% (Table 2). The more arbitrary 50-NNCH
covering does not do quite as well: it covers one of the
donut holes and overestimates the area by 41%. For a/
3, though, the a-hull method, provides an area estimate
matching the 8% performance of the k*-NNCH covering, except it provides an under rather than an over
estimate. The 3-hull method, however, does not identify
corridors as well as k-NNCH coverings (Fig. 10E),
yielding one fragmented corridor and leaving two of
the remaining three corridors linked by lines rather than
area segments.
A critical weakness of kernel methods is that unlike
hull methods (both the a-hull and k-NNCH constructions) they do not provide convergent area estimates with
increasing number of points. As demonstrated by Seaman et al. , this holds even for bivariate normal
data. The problem is much worse for aggregated data
sets, such as AD (Fig. 1A). Rather than reaching an
asymptote, the area estimates get worse in the case of the
hLSCV adaptive kernel method. Specifically, for subsamples of 30, 100, 300, and the full 1089 points the
method underestimates the area by 69%, 52%, 68% and
72% respectively (Table 1 / Fig. 9B, D, and F) which
should be compared with the converging sequence 62%,
45%, 23% and 12% for the k*-NNCH coverings (Table
1 / Fig. 9A, C, and E) and the converging sequence.
Table 1. Estimates of area from k-NNCH coverings and the
99th percentile of LSCV-optimized adaptive kernel distributions
obtained using each of ﬁve 30-point, 100-point and ﬁve 300point randomly sampled subsets of the 1089 points in the AD
data (Fig. 1A).
Sample size
Adaptive kernel
28.4 (2.6)
23.6 (7.7)
Percent error1
41.6 (4.8)
36.5 (8.3)
Percent error1
58.1 (2.9)
24.1 (5.0)
Percent error1
Percent error1
1The percentage of the known actual value that would have to
be added or subtracted (negative numbers) to this value to
obtain the estimated value.
ECOGRAPHY 27:4 
Beyond the questions of the accuracy and convergence
of area estimates, and of identifying high-density regions
in multimodal data, is the question of the accuracy of the
density isopleths themselves. For example, a plot of
decile isopleths against the number of points actually
bounded by those isopleths should be flat. This is nearly
the case for the k-NNCH constructions plotted in Figs
3B and 7B (AD and RS data), although the lines are
flatter for the smaller than larger values of k because of
rounding errors (the union of groups of k/N points
into precise decile intervals of size N/10 produces smaller
rounding errors for smaller values of k). The number-ofpoints plotted per decile isopleth is not at all flat for the
kernel UDs. Specifically, for the adaptive hREF/0.78
UD constructed from the AD data, the tails (the first,
second, and last deciles of the distribution) contain at
least twice as many of points as they should, thereby
producing erroneous area (Fig. 3A and C) and density
estimates of the associated UD.
Errors associated with the adaptive hLSCV/0.06 UD
are even more severe with hardly any points included in
the first seven decile intervals and most of the points in
the last decile interval (Fig. 3B) resulting to nonsensical
area and density plots (Fig. 3A and C). For the RS data,
Fig. 9. k*-NNCH and adaptive
kernel constructions of UDs
using 100-point (A) k*/11,
(B) hLSCV/0.33; 300-point (C)
k*/14, (D) hLSCV/0.15; and
1000-point (E) k*/16, (F)
hLSCV/0.06 sub samples of the
AD data (Fig. 1A). (See Table 1
for information on area
estimates.)
ECOGRAPHY 27:4 
Fig. 10. For the case a/3, ahull coverings of the 5 data sets
(A) AD (area 38 units), (B) RD
(area 69 units), (C) AS (area
0.50 units), (D) RS, (area 0.95
units) and (E) MC 
the adaptive kernel UDs now completely underestimate
the number of points in the tail for both the hREF/
0.026 and hLSCV/0.077 constructions (Fig. 7B: most of
the points are covered by the seventh and eight decile
intervals in the former case and fourth and fifth deciles
intervals in the latter case). Again, the inability of these
kernel methods to demarcate decile intervals of points
with any reasonable accuracy translates into hopelessly
erroneous area (Fig. 7B) and density (Fig. 7C) plots.
Conclusion
The construction of unbiased high resolution UDs
ultimately depends on the quantity and quality of the
data available, and issues such as serial correlations and sampling errors affect all methods
to a greater or lesser degree. Modern radio telemetry,
however, provides data in much greater quantities and of
much higher quality than ever before. Thus our k-
NNCH covering, which converges on the true distribution as the quality and quantity of data increases,
provides a superior alternative to methods such as kernel
methods, which do not converge. Further, we have
demonstrated that k-NNCH provide much better fits
than kernel methods across a spectrum of distributions
of data, from uniform to highly aggregated, and multimodal.
Kernel methods perform particularly poorly on aggregated and clustered data. Also, they were unable to
clearly demarcate boundaries and tended to fill in real
holes. We are certainly not the first to recognize this
problem. Creel and Creel , p. 37, for example, in
their application of the adaptive kernel module of the
CALHOME program to construct
utilization distributions from GPS data on the movement of wild dogs in Africa state ‘‘. . .[we] modified the
shapes of several home ranges to exclude areas that
could not be used (lakes) . . . [by] overlaying the home
range contours onto a base map of the study area and
cutting out the unusable areas by manual onscreen
digitizing.’’ Further, the poor performance of kernel
methods in estimating home range areas is well documented , as
is the problem of non convergence of kernel methods
with increasing sample size to some unbiased area
estimate .
Yet kernel methods continue to be widely used. The
reason for this might be that other relatively simple
methods, such as MCP and a-hulls, do not produce
density isopleths; even though an algorithm can be
devised to construct density isopleths associated with a
given a-hull construction. Our k-NNCH does not have
this deficiency and leads directly to the construction of
density isopleths. It appears to provide very good area
estimates for challenging data sets and converges to the
true area as the number of data points increase.
Although a-hull methods, also satisfy this latter property, they suffer from the deficiency of not always
including all points within or on the boundary of the
constructed area (i.e. some points may no be included at
all or they may be joined to an area by a line segment).
In short, k-NNCH coverings provide a general approach
to home range and UD construction that is superior to
existing kernel and hull methods, particularly when the
data reflects the existence of real boundaries, is multimodal, and topologically complex.
Acknowledgements / This research was funded in part by the
Foundation
Infectious Disease Grant DEB-0090323 and a James S.
McDonnell Foundation Complex Systems Award to WMG
and by an Environmental Protection Agency STAR Fellowship
to CCW. We thank Paul Cross and Sadie Ryan for valuable
discussion and comments during the preparation of this paper.