Transferring Activities: Updating Human Behavior Analysis
Fabian Nater∗† 1
Tatiana Tommasi∗2,3
Helmut Grabner 1
Luc Van Gool 1,4
Barbara Caputo 2
1 Computer Vision Laboratory, ETH Zurich, Switzerland
2 Idiap Research Institute, Martigny, Switzerland
3 Swiss Federal Institute of Technology in Lausanne (EPFL), Lausanne, Switzerland
4 ESAT-PSI/IBBT, K.U. Leuven, Belgium
One of the great open challenges in visual recognition
is the ability to cope with unexpected stimuli. In this work,
we present a technique to interpret detected anomalies and
update the existing knowledge of normal situations. The addressed context is the analysis of human behavior in indoor
surveillance scenarios, where new activities might need to
be learned, once the system is already in operation. Our
approach is based on human tracking with multiple activity trackers. The main contribution is to integrate a learning stage, where labeled and unlabeled information is collected and analyzed. To this end we develop a new multiclass version of transfer learning which requires minimal
human interaction but still provides semantic labels of the
new classes. The activity model is then updated with the
new activities. Experiments show promising results.
1. Introduction
Biological cognitive systems have the great capability to
recognize and interpret unknown situations. Equally, they
can integrate new observations easily within their existing
knowledge base. Autonomous artiﬁcial agents to a large
extent still lack such capacities.
In this paper, we work
towards this direction, as we do not only detect abnormal
situations, but are also able to learn new concepts during
From the multiple application domains, we aim at the interpretation of human behavior in indoor environments. The
goal is to monitor elderly or handicapped people in their
homes in order to ensure their well-being. This setting triggers interesting issues, such as the adaptation of pre-trained
knowledge to a particular living-room scene ﬁlmed with a
different camera or to an unknown person with an individ-
∗Fabian Nater and Tatiana Tommasi contributed equally to this paper.
†Primary contact: 
ual behavior style, whereas real abnormalities must still be
One main limitation of automated surveillance approaches is their need for an ofﬂine prior training with many
labeled data. Furthermore, no training sequence contains
a comprehensive set of all the situations to expect and any
surprising new event can appear in only a few frames. In order to overcome these limitations, we propose to start from
an initially trained set of basic activities and incorporate an
on-line update mechanism. Minimal human annotation, i.e.,
labeling one sample per new activity is required to include
semantic meaning. Hence, we are able to incorporate new
activity concepts during runtime and recognize them in the
In the rest of the paper we review related work in Sec. 2
and present our approach in Sec. 3. The employed techniques for human activity tracking and transfer learning are
discussed respectively in Sec. 4 and Sec. 5. Sec. 6 reports on
our experimental results, while Sec. 7 concludes the paper.
2. Related Work
The detection of abnormal events is a popular ﬁeld of
research, many techniques detect abnormalities as outliers
to previously trained models of normality. Successes include surveillance scenarios (e.g., ) or human behavior analysis (e.g., ). On the other hand, abnormalities
can also be modeled explicitly. This is often done in our
target scenario, the visual detection of a fall (e.g., ),
possibly integrated in a human posture classiﬁcation system .
In order to interpret human motion, the person in the
scene usually has to be tracked ﬁrst. This means that the
persons motion is followed throughout the video, and various appearance and scale changes are accounted for. To
this end, methods reach from generic blob-trackers to
sophisticated articulated body motion trackers in trackingby-detection frameworks . One step further, the recog-
Figure 1. Schematic overview of our approach to combine activity tracking with transfer learning. In surveillance videos, an initial model
recognizes familiar activities (1) or detects abnormalities (2). Together with minimal human interaction (3), the transfer learning algorithm
returns labels (4) such that the activity model can be extended with new classes.
nition of human actions often refers to the classiﬁcation
of tracked motion patterns into multiple action categories
(e.g., ).In order to learn these action classes, a vast
amount of labelled training data is required in most cases
and it is thus hard to model very speciﬁc or unexpected activities that only occur rarely.
Transfer learning can help in this context, as it focuses
on storing knowledge gained while solving some tasks and
exploiting it when solving a new but related task .
This approach has been successfully used in several papers where action recognition was based on observations
from state-change sensors . Some recent publication reports the application of transfer learning for cross
view action recognition and visual domain adaptation
 . However none of these consider the possibility to
update the set of class knowledge models when the newly
acquired information contains actions which were not seen
before. More in general, in object classiﬁcation, knowledge transfer has been applied to solve a N ′ class problem
when N objects are already known, with N ′ and N disjoint
groups . On the other hand, training to discriminate (N +N ′) classes when the model for an N-class problem was previously learned, is known as class-incremental
learning and only few attempts have been made to determine a principled technique for this process .
3. Proposed Approach
In order to recognize the activities of a person in an inhouse scenario, we propose to use a set of activity trackers. Each tracker is trained to one speciﬁc activity class.
Known concepts can be recognized and labeled, while abnormal events are detected as unknown activities.
For an increased ﬂexibility and to learn the unknown activities, we propose to augment this static model with an update procedure, based on transfer learning. To classify the
unknown samples, we build a multiclass model which exploits prior knowledge of known classes and incrementally
learns the new actions. The procedure is outlined in Fig. 1.
The central block receives labeled (Arrow 1) and unknown
(Arrow 2) samples from the activity trackers. Based on minimal human annotation (Arrow 3), it labels the previously
unknown activities (Arrow 4). In a ﬁnal step, the newly labeled activities are integrated in the previous model besides
the initial trackers. In this sense, the transfer learning algorithm acts as an artiﬁcial expert.
The interaction of the two techniques is useful due to
their complementary nature:
• Generative tracking with multiple activity trackers provides labels for familiar activities and detects abnormal
situations. In both cases, the location of the person is
determined as bounding box. (Sec. 4)
• Discriminative classiﬁcation interprets the abnormal
situations in order to label new activities. Knowledge
transfer uses prior information from known classes for
a more efﬁcient and accurate labeling of new ones. Human annotation of at least one frame is necessary to
provide the desired semantic label. (Sec. 5)
The approach has several application-speciﬁc advantages. Firstly, if only few labeled samples of some actions
are available, we can exploit prior knowledge acquired under different conditions in terms of location, observed person and employed recording camera. Furthermore, human
annotation of one sample per class enables the semantic interpretation of the activities. For example, it is now desirable to include a fall in the model, in order to automatically
take appropriate action in case it is detected again, i.e., call
an ambulance. Besides that, the model continuously becomes richer in what it knows, such that diverse activity
concepts can be recognized and the performance increases
over time. Finally, a shift in an activity concept, e.g., a person gradually starts to limp, can also be integrated.
In the following two sections we provide details for the
activity tracking and the transfer learning and show how the
two parts interact.
4. Activity Tracking for Unusual Event Detection
In tracking, the aim is to follow the motion of the person
throughout the video and account for various appearance
Figure 3. Schematic overview of the tracking technique: In a particle ﬁlter approach, samples live both, the image space and the manifold
space. Comparison and likelihood estimation is performed on the silhouettes, and a posterior probability density is obtained.
Figure 2. Simultaneous tracking and activity spotting: A person in
the scene is always tracked by the foreground blob tracker in black.
This tracker provides unlabeled samples (Arrow (2) in Fig. 1). The
more speciﬁc activity trackers simultaneously track the person and
determine his activity. If one is active (picking up in green), it
overrules the blob tracker and provides labeled bounding boxes
(Arrow (1) in Fig. 1).
and scale changes.
We follow the work of Nater et. al. where simultaneously a person is tracked and the action is determined.
Multiple activity trackers are used to interpret the behavior of a person. Each of the trackers is trained to a speciﬁc aspect of human motion. As long as the person in the
scene behaves according to the expectations, there will be
one speciﬁc tracker which recognizes the activity, as shown
in Fig. 2. However, if none of the generative activity trackers can explain the situation, but a less informed foreground
blob tracker still tracks the target, this performance reversal
signals an abnormal event.
In the following we brieﬂy review the employed methods.
Activity modeling and tracking.
In the same way as
in , we create a low dimensional model in order to describe the observed training data. To this end, silhouettes
of a human person are extracted from the training video sequences and are represented on a three-dimensional manifold. Isomap is used as the dimensionality reduction
technique, because it ensures that local distances remain
similar as in the original data. To be able to infer the original silhouette space from the model, we learn a Gaussian
Process regression on the training data. One model
is learned for each activity. Initially, walking, sitting down
and picking up are learned from training data in a lab setup.
Typically, several hundred frames are required per activity
to train non-overﬁtting models.
The models are subsequently applied to new sequences
in living-room settings. After background subtraction, the
binary observation image and the low dimensional manifold are sampled with a particle ﬁlter. From frame to frame,
particles are propagated and re-weighted with respect to the
likelihood between model prediction and observation. This
is sketched in Fig. 3. At each time step, a posterior probability is available which gives an indication of how well the
tracker explains the observation.
All available trackers are run in parallel. A user-deﬁned
threshold, applied on the activity trackers’ posterior probabilities, determines active and inactive trackers. Of all the
active trackers, the one with the maximal posterior probability determines the activity label the current frame and
the bounding box of the person. The cropped and labeled
frames are delivered to the transfer learning stage (Arrow
(1) in Fig. 1).
Blob tracking.
A foreground blob tracker (CamShift
in our implementation ), initialized by a person detector , tracks the human target as long as it is in the scene.
In case of an abnormal event, this tracker determines the
bounding box of the person, which is handed over (Arrow
(2) in Fig. 1).
Update. Given the frames ﬁrst labeled as abnormal and
the new semantic activity labels obtained from the classiﬁer
stage, a new activity model is learned for each new class.
The new activity trackers are added besides the existing
ones and the initial and the new activities will be detected
and recognized from now on. If a shift in one of the known
concepts is observed, i.e., activity detection with the initial
set of trackers does not match the labeling of the transfer
learning, existing activity models need to be replaced.
Figure 4. Description of the multiclass one-vs-all transfer learning strategy. The activity classes on the left (marked in red) correspond to
prior knowledge. The classes on the right (marked in blue) correspond to the new target task. The new hyperplanes for classes 1,2 and 3
are obtained through transfer learning from the corresponding source knowledge while for classes 4 and 5 a weighted combination of all
the known hyperplanes is used as prior.
5. Knowledge Transfer for Unusual Event
Transfer learning can help to reduce the labeling effort
which is in general necessary when recognizing a new set
of activities. The idea is to transfer only the useful part of
information from the already known activity classes when
solving the new multiclass problem.
In the following we summarize the binary transfer learning method presented in and describe how to extend it
to multiclass with the one-vs-all approach.
5.1. Adaptive knowledge transfer
Given a set of l samples {xi, yi}l
i=1, where xi ∈X ⊂
Rd and yi ∈Y = {−1, 1}, we want to learn a linear function f(x) = w · φ(x) + b which assigns the correct label to
an unseen test sample x. The function φ(x) maps the input
samples to a high dimensional feature space where the inner
product can be easily calculated through a kernel function
K(x, x′) = φ(x) · φ(x′) .
In Least-Square Support Vector Machine (LS-SVM) the
model parameters (w, b) are found by solving the following
optimization problem :
ζi[yi −w · φ(xi) −b]2 .
The weight ζi is introduced to take care of unbalanced distributions and it depends on the number of positive and negative available samples . It can be shown that the
optimal w is expressed by w = Pl
i=1 αiφ(xi), and (ααα, b)
are obtained from:
where W = diag{ζ−1
2 , . . . , ζ−1
}. Let us call G the
ﬁrst term in left-hand side of Eq. (2). Thus the optimization
problem in Eq. (1) can be solved by simply inverting G.
By slightly changing the classical LS-SVM regularization term, it is possible to deﬁne a learning method based
on adaptation . The idea is to constrain a new model to
be close to a set of k pre-trained models:
ζi[yi−w·φ(xi)−b]2, (3)
j is the parameter describing each old model and βj
is a scaling factor necessary to control the degree to which
the new model is close to the old one. The LS formulation
gives the possibility to write the Leave-One-Out (LOO) prediction for each sample ˜yi in closed form:
˜yi = yi −
where αi and α′
i(j) are respectively elements of the vectors
ααα = (K + 1
C W)−1y and αj
αj′ = (K + 1
C W)−1 ˆyj. y is
the vector of the yi and ˆyj is the vector of the predictions of
the jth known model ˆyi(j) = (w′
j · φ(xi)). Thus the LOO
error can be easily evaluated as r(−i)
= yi −˜yi. It is an
unbiased estimator of the classiﬁer generalization error and
can be used to ﬁnd the best value of βββ.To deﬁne a convex
formulation, it is possible to use the following loss function:
loss(yi, ˜yi) = ζi max [1 −yi˜yi, 0]
Then the objective function is:
loss(yi, ˜yi)
∥βββ∥2 ≤1 .
5.2. One-vs-All multiclass extension
Let’s start from a prior knowledge problem with N different activities and train a multiclass SVM classiﬁer with
the one-vs-all approach. Only the parameters that describe
the hyperplanes {w′
j=1 are memorized while the data are
not stored. As target task we consider to solve a (N + N ′)
multiclass problem where N categories are the same as in
the original source task and N ′ classes are new. However,
now only very few samples for each class are available.
The binary transfer approach described previously can
be used separately to learn each of the (N + N ′) one-vsall hyperplanes (see Fig. 4). The N hyperplanes associated
to the same classes considered in prior knowledge, are now
trained to separate some new positive samples against a different negative set due to the presence of N ′ new classes. In
these cases the βββ vector reduces to one single value ranging
in . The method also exploits a linear combination of
prior knowledge hyperplanes to separate each of the N ′ new
categories from all the others. Here the idea is that a combination of visual characteristics which differentiate among
walk, sit and pick up can still be useful to carachterize lie
down and fall and can help when only few samples of the
different actions are available.
6. Experiments
We demonstrate the activity classiﬁcation via transfer
learning, and show the newly learned classes improve the
performance of the activity model. We use the same data
for both tasks.
6.1. Dataset and setting
In our experiments, we include 5 different activities to
be recognized. These are walk, sit down, pick up, lie down
and fall. We consider different cases that might also appear
in real-life scenarios. As depicted in Fig. 5, we include two
different indoor scenes, two camera types that were used for
recording and three different persons.
Camera 1 has V GA resolution and records
at 15 frames per second. The used lens introduces minimal
distortion. Camera 2 has a resolution of 1624 × 1234 pixels and records at 12 frames per second. A ﬁsh-eye lens
with a large ﬁeld of view introduces distortion, that needs
to be corrected. To this end, we apply the technique of 
and rectify the images cylindrically, i.e. straight, physically
vertical lines are preserved. For visualization purposes, the
relevant image region is cropped out in Fig. 5(c).
Sequences.
We dispose of 12 video sequences, which
were recorded as detailed in Tab. 11. They contain between
1000 and 3000 frames and depict a single person who performs all the ﬁve activities. We manually provide a frame
1Data available from www.vision.ee.ethz.ch/fnater
(a) Camera 1, Scene 1
(b) Camera 1, Scene 2
(c) Camera 2, Scene 1
(d) Persons 1, 2, 3
Figure 5. Different settings are used for the experiments.
recorded in two different indoor scenes, with two different cameras and three persons perform the activities.
by frame ground truth annotation for each sequence. Transitions (e.g., standing up after a fall) are termed with no
Seq 1a, Seq 1b, Seq1c : {Scene 1, Person 1, Camera 2}
Seq 2a, Seq 2b, Seq2c : {Scene 1, Person 2, Camera 2}
Seq 3a, Seq 3b, Seq3c : {Scene 1, Person 3, Camera 1}
Seq 4a, Seq 4b, Seq4c : {Scene 2, Person 3, Camera 1}
Table 1. Three sequences were recorded for every parameter combination.
Initial processing.
We run the three initial activity
trackers (walk, sit down, pick up) and the blob tracker on
all the sequences. The known activities are spotted and abnormal events are detected. Each frame is labeled and the
bounding box of the person is obtained. This forms the basis for further analysis.
6.2. Transfer learning
As explained in Sec. 3 the transfer learning step is used
as an expert exploiting prior knowledge and labeling new
samples that are then used to update the tracking system.
Having an accurate classiﬁcation process is crucial for the
efﬁciency of the ﬁnal action recognition method. We validate the proposed transfer approach with four experiments.
As prior knowledge we used Seq ∗a with the N = 3 activities labeled in the initial processing. Seq ∗b is used to
extract randomly 10 frames for each of all the N + N ′ = 5
actions (initial processing and new activities). This deﬁnes
the training set for the target task. Finally Seq ∗c is used as
The PHOG features (histogram bins=9, angle=180,
levels=3) are calculated on the provided bounding box
around the person and they are used together with the RBF
kernel in all the experiments. The learning parameters are
chosen by cross validation on prior knowledge.
To implement the multiclass transfer learning method we started
from using the code released by the authors2.
We compare three methods that are applied to the test
• Initial Model: The prior knowledge model learned on
the 3 initial activities.
• No Transfer: The model learned on few samples of the
5 activities.
• Transfer: The model learned on few samples of the 5
activities transferring from prior knowledge.
The plotted values correspond to the average recognition
rate on 10 runs of the experiment (the random selection of
training frames from Seq ∗b is repeated 10 times).
signiﬁcance of the comparison between Transfer and No
Transfer is evaluated through the sign test : a square
marker is reported on the graph if p < 0.05 (see Fig. 6).
The four experiments differ by the existing relation between
prior knowledge and target task.
Case 1: same person, same camera, same scene. The
acting person, the background scene and the recording camera are the same in prior and new sequence. Speciﬁcally
we used Seq 1a, Seq 1b and Seq 1c. Classiﬁcation results
are reported in Fig. 6 (a): transferring from prior knowledge guarantees a signiﬁcant advantage compared to learning from scratch. The same experiment was repeated using
Seq 3a, Seq 3b and Seq 3c, with equal results.
different person,
same camera,
The background scene and the recording camera
are ﬁxed, but the acting person in prior knowledge is different with respect to the one in the training and test videos.
We used respectively Seq 2a, Seq 1b and Seq 1c. The results are reported in Fig. 6 (b). Even if the actions in prior
knowledge are performed by a different person, transferring
information still guarantees an advantage in learning. The
same experiment was repeated inverting the role of the two
acting persons and using Seq 1a, Seq 2b and Seq 2c with
analogous results.
different person, different camera, same
scene. Prior knowledge and new task involve different persons, they are also recorded with a different camera but the
scene remains the same. Speciﬁcally we considered Seq 3a,
Seq 1b and Seq 1c. Fig. 6 (c) shows the results: here Transfer is still signiﬁcantly better than No Transfer but the gain
in terms of recognition performance is small.
Case 4: different person, different camera, different
scene. Finally we consider a prior knowledge setting where
2 code.html
(a) Case 1
(b) Case 2
(c) Case 3
(d) Case 4
Figure 6. Average recognition rate results on ten runs evaluated
varying the number of samples per class in the training set. The
signiﬁcance of the comparison between Transfer and No Transfer
is evaluated through the sign test : a square marker is reported
on the graph if p < 0.05. Passing from case 1 to case 4 the prior
knowledge is less and less relevant, consequently the advantage of
Transfer w.r.t. No Transfer decreases.
the person, the camera used and the background scene are
different with respect to the one used in the training and
test videos. We used Seq 4a, Seq 1b and Seq 1c and the
results are reported in Fig. 6 (d). Here the transfer learning
system automatically realizes that the information coming
from prior knowledge is not useful for the new task and
Transfer performs as No Transfer.
Comparing all the four graphs in Fig. 6, the progressively
lower relevance of prior knowledge with respect to the new
target task can be read in the decreasing recognition rate result for the Initial Model. Globally, the classiﬁers obtained
with Transfer learning perform better or at least equally to
No transfer. Therefore we use the transfer learning to ﬁx the
activity class labels that are delivered to update the activity
6.3. Activity tracking
Given an updated set of activity trackers, we evaluate
how the activity recognition performance increases with respect to the initial processing. The predicted activities are
compared to the ground truth. We use Seq ∗b since it was
not used previously for testing the classiﬁcation. Activities
are predicted for three cases: (i) the initial tracker set, (ii)
the tracker set after the update with one-shot learning and
(iii) after the update with 10 manually labeled frames.
In Fig. 7 we provide detailed insights for the activity update. The cases 1 (same scene, same person, same camera)
and 4 (different scene, different person, different camera)
updated one−shot
updated 10 samples
False Positive Rate
True Positive Rate
GROUND TRUTH
No activity
PREDICTION
No activity
PREDICTION
(a) Case 1: ROC, conﬁdence matrices for learning with 1 (left) and 10 (right) annotated samples
updated one−shot
updated 10 samples
False Positive Rate
True Positive Rate
GROUND TRUTH
No activity
PREDICTION
GROUND TRUTH
No activity
PREDICTION
(b) Case 4: ROC, conﬁdence matrices for learning with 1 (left) and 10 (right) annotated samples
Figure 7. Activity tracking results. ROC curves and confusion matrices for case 1 (top row, corresponding to Fig. 6(a)) and case 4 (bottom
row, corresponding to Fig. 6(d)). In the ﬁrst row, the performances for one-shot learning and learning with 10 samples match, whereas in
the more difﬁcult case in the bottom row, more annotations improve the performance.
Tracker test sequence
Tracker update sequence
Transfer prior sequence
Corresponds to case
Initial processing
Updated (1-shot)
Updated (10 samples)
Table 2. Results for different sequences, the predicted activity is compared to the ground truth. Different cases are reported in terms of
true positive rate (TPR) and false positive rate (FPR). The updated activity set outperforms the initial one. In most situations, the results
obtained with 10 labeled samples are only marginally better than using one-shot learning.
are depicted. In Fig. 7, ROC curves are shown for the initial and updated (one-shot and 10 samples) tracker sets. To
this end, the threshold that determines the active trackers,
is gradually increased. This results in different numbers of
true-positives and false-positives. For the confusion matrices in Fig. 7 and all further experiments, the threshold is
One-shot labeling already improves the activity tracking
performance considerably with respect to the initial tracker
If the labels provided by the one-shot learning are
correct as in case 1, the beneﬁt of labeling 10 frames is
marginal. If it turns out that one manually labeled sample is not sufﬁcient for a good classiﬁcation accuracy, as in
the most difﬁcult case 4, manual annotation of 10 frames
improves the ﬁnal performance. In the confusion matrices,
the predicted activities are reported vs. the ground truth in
terms of number of frames and underlie this ﬁnding. Cases
2 and 3 are very similar to case 1, i.e., the transfer learning
with one manually labeled sample is sufﬁcient.
In Tab. 2, we report the evaluation of the activity recognition in terms of overall true-positive-rate and false-positiverate for different cases of prior knowledge and target tasks.
The ﬁrst four columns report results obtained on the same
sequences used for the experiments in Fig. 6, the last two
columns contain the results for other test sequences. In all
cases, the augmentation of the tracker set with new trackers learned from the transferred labels helps. In ﬁve of the
six evaluated cases however, the annotation of ten frames
vs. one frame only improves the performance marginally.
We underline that the number of labelled training samples
needed is in any case two or at least one order of magnitude
smaller than what originally requested to update the activity
tracker in .
7. Conclusions
Starting from the output of a method that detects known
activities and unusual events in surveillance videos, we presented here a strategy to learn these new events. We only
need a very small number of training samples since we
exploit prior knowledge of activities that were known already. We extended an efﬁcient transfer learning method
from binary to multiclass and we tested it on the realistic
and challenging scenario of learning new human activities.
Finally, we show that the combination of activity tracking
techniques with transfer learning can aid in determining the
behavior of a person in an indoor scene.
8. Acknowledgments
This work was sponsored by the EU project DIRAC IST-