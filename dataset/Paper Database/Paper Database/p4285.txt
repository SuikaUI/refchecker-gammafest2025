Bayesian Inference with Optimal Maps
Tarek A. El Moselhy, Youssef M. Marzouk
Massachusetts Institute of Technology, Cambridge, MA 02139, USA
We present a new approach to Bayesian inference that entirely avoids Markov
chain simulation, by constructing a map that pushes forward the prior measure to
the posterior measure. Existence and uniqueness of a suitable measure-preserving
map is established by formulating the problem in the context of optimal transport
theory. We discuss various means of explicitly parameterizing the map and computing it eﬃciently through solution of an optimization problem, exploiting gradient
information from the forward model when possible. The resulting algorithm overcomes many of the computational bottlenecks associated with Markov chain Monte
Carlo. Advantages of a map-based representation of the posterior include analytical
expressions for posterior moments and the ability to generate arbitrary numbers of
independent posterior samples without additional likelihood evaluations or forward
solves. The optimization approach also provides clear convergence criteria for posterior approximation and facilitates model selection through automatic evaluation
of the marginal likelihood. We demonstrate the accuracy and eﬃciency of the approach on nonlinear inverse problems of varying dimension, involving the inference of
parameters appearing in ordinary and partial diﬀerential equations.
Bayesian inference, optimal transport, measure-preserving maps,
inverse problems, polynomial chaos, numerical optimization
1. Introduction
The estimation of model parameters from observations is a ubiquitous problem in
science and engineering. Inference or “inversion” are central challenges in geophysics
and atmospheric science, chemical kinetics, quantitative biology, and a host of additional domains. In all these settings, observational data may be indirect, noisy, and
limited in number or resolution. Quantifying the resulting uncertainty in parameters
is then an essential part of the inference process. Uncertainty in model parameters in
turn drives uncertainty in predictions; characterizing the latter is vital to the use of
Email addresses: (Tarek A. El Moselhy), conditioned on data, represents one’s state of knowledge about that
Characterizing the posterior—simulating the distribution with samples;
marginalizing; evaluating moments, quantiles, or credibility intervals—thus becomes
one of the central computational challenges in Bayesian inference.
In specialized cases (e.g., simple statistical models with conjugate priors) expectations with respect to the posterior may be evaluated in closed form. But in the
general setting—and particularly when complex physical models enter the likelihood
function—computational approaches are needed. By far the most widespread and versatile method for posterior simulation in this context is Markov chain Monte Carlo
(MCMC) . MCMC requires only pointwise evaluations of an unnormalized
density, and generates a stream of samples that can be used to evaluate posterior
expectations.
Despite its power and practical utility, MCMC suﬀers from many limitations.
Samples generated by the algorithm are necessarily correlated; strong correlation
among successive samples leads to smaller eﬀective sample sizes and larger errors in
posterior estimates . An eﬃcient MCMC algorithm endeavors to make the eﬀective
sample size after N steps as close to N as possible, as the posterior evaluation(s)
required at each step may be costly. Eﬃcient sampling in Metropolis-Hastings MCMC
 rests on the design of eﬀective proposal distributions, but this task is diﬃcult for
target distributions that contain strong correlations or localized structure, particularly
in high dimensions. Improvements to MCMC proposal mechanisms are therefore the
subject of intense current interest. A non-exhaustive list of recent methodological
advances includes adaptivity based on past samples , Langevin methods , the use of Hessian information and Hessians with low-rank structure ,
Hamiltonian dynamics , the exchange of information among multiple chains , multi-stage proposals incorporating approximate models , and the use of
surrogate or reduced models to accelerate likelihood evaluations .
Even with these advances, MCMC remains a computationally intensive process;
typical problems require many thousands or even millions of posterior evaluations.
Moreover, the sampling process does not come with a clear convergence criterion,
indicating when the chain has adequately explored the distribution or how many initial samples to discard as “burn-in.” Convergence diagnostics for MCMC are largely
heuristic and remain something of an art . Finally, the nature of MCMC is to
represent the posterior distribution with samples; this may seem an obvious remark,
but a sample representation immediately favors the use of Monte Carlo methods
for subsequent uncertainty propagation steps. For computationally intensive models, however, sampling may be impractical. More eﬃcient uncertainty propagation
methods already exist and it would be desirable to use them. Even sequential
Monte Carlo methods , designed with recursive inference and forecasting in mind,
still rely on a weighted-sample representation of the posterior.
In this paper, we present a novel approach to Bayesian inference that relies on the
construction of maps. We entirely avoid Markov chain simulation, and instead explicitly construct a map that pushes forward the prior measure to the posterior measure.
In other words, the map transforms a random variable X, distributed according to
the prior, into a random variable Z, distributed according to the posterior. Existence
and uniqueness of a monotone map is assured under rather weak conditions . The
map is actually found through solution of an optimization problem, which requires
only the ability to evaluate the posterior density up to a normalizing constant (exactly
as in Metropolis-Hastings MCMC). If gradients of the likelihood function or forward
model are available, however, then we immediately take advantage of them. To make
the optimization problem ﬁnite dimensional, the map is described by multivariate
orthogonal polynomials; it therefore becomes a polynomial chaos expansion 
of the posterior.
As a byproduct of the optimization procedure, the scheme automatically calculates
the posterior normalizing constant, i.e., the marginal likelihood or evidence, which is
an essential quantity in Bayesian model selection . We show that the optimization
procedure also provides an unambiguous convergence criterion, with a quantity that
can be monitored in order to decide whether to terminate iterations or to enrich the
polynomial space used to describe the map. With a map in hand, one can cheaply
generate independent posterior samples by simulating from the prior. Also, as the
map is represented by polynomials orthogonal with respect to standard measures,
posterior moments may be evaluated algebraically.
To place the map-based scheme in context, we note that variational Bayesian
methods also convert inference into an optimization problem, by approximating the posterior with a simpler distribution from a parameterized family, perhaps
also chosen to have a particular conditional independence structure. These are approximations of the posterior (or posterior predictive) distribution function, however.
Distributions must be chosen from particular families to facilitate optimization and
sampling—in contrast to the present scheme, which approximates random variables
directly. The present scheme has closer links to implicit ﬁltering methods 
for sequential data assimilation. These methods rely on a weighted-sample representation of each probability distribution, but use maps to transport particles to highprobability regions of the posterior. Implicit ﬁltering eﬀectively uses many maps,
though, one for each particle and assimilation step. Unlike the present scheme, maps
are not constructed explicitly; rather one evaluates the action of each map on a single
particle. The role of optimal transport in data assimilation has also been raised in
This paper is organized as follows: In Section 2 we present the basic formulation
and several alternative versions of the optimization problem that yields the map (Sections 2.3 and 2.4). Methods for solving these optimization problems are presented
in Section 3. Section 4 presents a range of numerical results. First, we demonstrate
our inferential approach on a linear problem where the posterior has known analytical form (Section 4.1). Then we perform parameter inference in several nonlinear
ODE systems with strongly non-Gaussian posteriors, and where the posterior differs markedly from the prior (Sections 4.2 and 4.3). Finally, we demonstrate the
approach on high-dimensional inverse problems involving the estimation of spatially
heterogeneous coeﬃcients in elliptic PDEs (Section 4.4).
2. Formulation
2.1. Bayesian framework
We begin by describing the Bayesian inference framework and setting notation
for the subsequent developments. Consider the task of inferring model parameters x
from observations d. For simplicity, we will let both the parameters and observations
be real-valued and ﬁnite-dimensional. In the Bayesian setting, the parameters and
observations are treated as random variables. Let (Ω, F, P) be a probability space,
where Ωis a sample space, F is a σ-ﬁeld, and P is a probability measure on (Ω, F).
Then the model parameters X : Ω→Rn are associated with a prior measure µ0 on
Rn, such that µ0(A) = P (X−1 (A)) for A ∈Rn. We then deﬁne p(x) = dµ0/dx to
be the density of X with respect to Lebesgue measure. For the present purposes,
we assume that such a density always exists. We then deﬁne the expectation with
respect to the prior measure as E [g(X)] =
g(x)dµ0(x) =
g(x)p(x)dx, for any
Borel-measurable function g on Rn. The observational data are described by a random
variable d taking values in Rm. Inference requires that we deﬁne a probabilistic model
for the data; in terms of probability densities, this model is simply p(d|x). Viewed as a
function of x, this conditional density deﬁnes the likelihood function L(x; d) ≡p(d|x).
Bayes’ rule then yields the posterior probability density q(x) ≡p(x|d):
q(x) = L(x; d) p(x)
where β is the evidence or marginal likelihood β =
L(x; d)p(x) dx. This posterior
density q is associated with a posterior measure µ on Rn, such that dµ(z) = q(z)dz
and the likelihood function is proportional to the Radon-Nikodym derivative of µ
with respect to µ0, L(z) ∝dµ/dµ0 .
In inverse problems , the likelihood frequently incorporates a deterministic
function h mapping the parameters to some idealized observations. This function
h : Rn →Rm is termed the forward model. The discrepancy between the idealized
model predictions and the actual data is often assumed to be additive: d = h(x) + ε,
where ε is a random variable. A common further assumption is that ε is Gaussian,
zero-mean, and independent of the model parameters, i.e., ε ∼N(0, Σ), leading to
the following form for the likelihood function:
(2π)m/2 (det Σ)1/2 exp
2 ∥h(x) −d∥2
where ∥u∥A := ∥A−1
2u∥, for any positive symmetric matrix A.
While the Bayesian formulation of inverse problems commonly leads to likelihood
functions that take the form of (2), we emphasize that this particular form is not an
assumption or requirement of the map-based inference method described below.
2.2. Inference with a map
The core idea of our approach is to ﬁnd a map that pushes forward the prior
measure to the posterior measure.
In other words, suppose that X is a random
variable distributed according to the prior and that Z is a random variable distributed
according to the posterior. Then we seek a map f : Rn →Rn that satisﬁes the
following constraint, where equality is in distribution:
Z = f(X), with X ∼µ0, Z ∼µ.
Equivalently, we seek a map f which pushes forward µ0 to µ, i.e., for which µ = f♯µ0.
A schematic of such a map is given in Figure 1. The map necessarily depends on the
data and the form of the likelihood function. (In the case of (2), the map would thus
depend on the data d, the forward model h, and the distribution of the observational
noise ε.) If the posterior distribution were equal to the prior distribution, an identity
map would suﬃce; otherwise more complicated functions are necessary. Note that,
for clarity, we adhere to the strict association of a random variable with a distribution. Thus the prior and posterior distributions are associated with distinct random
variables (X and Z, respectively) representing distinct states of knowledge about the
same set of parameters. This view is slightly diﬀerent than the usual notion of a
single random variable for which we “update” our belief.
Assuming that a map satisfying (3) exists and is monotone,1 the measure of Z,
represented by the posterior probability density q, can be transformed into a probability density ˜p for the input random variable X:
˜p(x) = q (f(x)) |det Dxf| = L (f(x); d) p (f(x))
where Dxf = ∂f/∂x is the Jacobian of the map. But we already have a density
for X, namely the prior density p. This in turn deﬁnes an alternate criterion for
1A monotone (non-decreasing) map f(x) on Rn is one for which (x2 −x1)T (f(x2) −f(x1)) ≥0
for every pair of distinct points x1, x2 ∈Rn. Issues of existence and monotonicity will be addressed
in the next two subsections.
an inferential map: the transformed density ˜p should be equal to p, as depicted in
˜p(x) = p(x).
The Bayesian inference problem can thus be cast in the following equivalent form:
Problem 2.1. Find a monotone map f(x) such that2
[L ◦f] (x) [p ◦f] (x)
|det Dxf| = p(x).
In many cases (e.g., when the likelihood function and the prior density contain
exponentials) the following expression is more appropriate for computation than (6):
log (L ◦f) + log (p ◦f) −log β + log |det Dxf| −log p = 0.
We emphasize that despite the appearance of the posterior normalizing constant β in
the problem above, our ﬁnal formulation will never require knowledge of β. Indeed,
the value of β will emerge as a by-product of identifying the map.
Instead of aiming for exact equality in (6), we will deﬁne an optimization problem
that seeks to minimize the discrepancy between the prior density p and the approximate and map-dependent prior density ˜p. This discrepancy can be expressed, for
instance, as the Kullback-Leibler divergence or the Hellinger distance from p to ˜p.
We will begin by rewriting these discrepancies in a more convenient form. For the
Hellinger distance Q(p, ˜p) we have:
p(x) + ˜p(x) −2
p(x)˜p(x) dx
p(x)˜p(x) dx
Similarly, the Kullback-Leibler (KL) divergence from p to ˜p can be rewritten as follows:
DKL (p||˜p) =
p(x) log p(x)
˜p(x) dx = −E
2To simplify notation we use [L ◦f](x) to denote L(f(x)). We also drop the explicit dependence
of L on the data d.
Both the square root in (8) and the log in (9) are concave functions Φ, and Jensen’s
inequality provides that
To minimize either Hellinger distance (8) or KL divergence (9) we would therefore like
to achieve equality above, but equality holds if and only if the ratio ˜p/p is constant in
x . Consistent with (6), the value of this constant should be unity. Re-arranging
equation (4), we obtain the following expression for β
β = [L ◦f] (x) [p ◦f] (x)
|det Dxf| .
Taking the logarithm of this expression we obtain
T(x; f) := log (L ◦f) + log (p ◦f) + log |det Dxf| −log p = log β.
Equation (12) is the cornerstone of our analysis. It states that T(x; f) should be
constant over the support of the prior.
Setting T to be a constant suggests the
following problem formulation:
Problem 2.2. Find f ∗(x) such that
f ∗= arg min
Var [T(X; f)]
where X ∼µ0.
Note that this formulation is equivalent to minimizing either of the discrepancy
measures between ˜p and p considered above (and others as well). Moreover, if f is
allowed to lie within a suﬃciently rich function space, we know exactly what minimum
value of Var [T] can be attained: zero. As emphasized earlier, f ∗is computed without
any knowledge of the evidence β, since the latter does not appear in T. However, β
can be evaluated as
β = exp (E [T(X)]) .
An alternative optimization problem can obtained by observing that
DKL (p||˜p) = −E
= log β −E [T(X)] .
Since log β is a constant, minimizing DKL (p||˜p) is equivalent to seeking:
f ∗= arg max
E [T(X; f)].
In other words, we maximize the numerical estimate of the evidence. Unlike Problem 2.2, this formulation does not have a known optimal value of the objective function, but Var[T] can nonetheless be monitored to assess convergence.
2.3. The optimal transport formulation
The multivariate map f : Rn →Rn takes the following general form:
zi = fi(x1, x2, . . . , xn),
i = 1 . . . n
where fi are the components of f. Using the classic measure transform literature
 one can show that a map pushing µ0 forward to µ exists under relatively
weak conditions, but is not unique. To guarantee uniqueness, extra constraints or
penalties must be enforced. Two types of constraints are employed in this paper. The
ﬁrst, discussed in this section, is an optimal transport constraint. It can be shown
 , under remarkably general conditions, that the optimization problem
∥X −f(X)∥2
subject to µ = f♯µ0
has a unique solution f ∗and that this solution is monotone. Conditions for existence
and uniqueness essentially require that the measure µ0 (here, the prior) not contain
any atoms. We restate this result more precisely as follows:
Theorem 2.3. (After ) Let µ0 and µ be Borel probability measures on Rn with
µ0 vanishing on subsets of Rn having Hausdorﬀdimension less than or equal to n−1.
Then the optimization problem (17) has a solution f that is uniquely determined µ0almost everywhere. This map is the gradient of a convex function and is therefore
For a detailed proof of this theorem see, e.g., .
To be sure, our true objective is not to ﬁnd the optimal transport of Theorem 2.3
per se. Instead we want to add enough regularity to Problem 2.2 such that we can
ﬁnd a monotone map satisfying f♯µ0 ≈µ (or equivalently ˜p ≈p). To this end, we use
the optimal transport problem (17) to motivate the following penalized objective:
DKL (p||˜p) + λE
∥X −f(X)∥2
By analogy with Problem 2.2, (18) can be replaced by:
Problem 2.4. Find f to solve the following optimization problem
Var [T(X)] + λE
∥X −f(X)∥2
Equations (18) and (19) should be understood as follows.
The ﬁrst term enforces the measure transformation from prior to posterior,3 while the second term is
3See Appendix A for a discussion of the relative magnitudes of Var[T] and the KL divergence.
a penalty inspired by the optimal transport formulation to promote regularity and
monotonicity in f. The magnitude of the penalty term is controlled by the multiplier
λ. In the optimization scheme to be detailed in Section 3, this multiplier is chosen
adaptively, such that the magnitude of the penalty term is a prescribed fraction (e.g.,
1/10) of the magnitude of Var [T] or DKL (p||˜p) at the start of each cycle. The stopping criterion for the optimization scheme evaluates only the ﬁrst term of (18) or
(19), since this is the term that enforces the accuracy of the posterior representation.
We also emphasize that in every example tested below (see Section 4), the value of λ
was not a critical parameter in the optimization procedure. In fact λ can be assigned
a zero value when Var [T(X)] is suﬃciently small.
One could also, of course, revert to solving the constrained optimization problem (17) and thus ﬁnd the true L2-optimal transport.
We do not pursue such a
scheme here, however, because our core interest is in satisfying the measure transformation condition, not in ﬁnding the optimal transport per se.
2.4. Triangular formulation
An alternative method for guaranteeing a unique solution is to enforce a “triangular” structure for the map. This construction is inspired by the Rosenblatt transformation , where now the ith component of f can depend only on the ﬁrst i
zi = fi(x1, . . . , xi).
In this formulation, the regularity of the problem is provided by the triangular
structure and no additional penalty term is required to ensure uniqueness. Indeed,
 shows that there exists a unique monotone map f of the form (20) satisfying
µ = f♯µ0.4 This map is known as the Knothe-Rosenblatt re-arrangement .
The Rosenblatt re-arrangement is typically computed via an iterative procedure
 that involves evaluating and inverting a series of marginalized conditional cumulative distribution functions. This procedure is computationally very intensive,
since it involves computing a large number of high-dimensional integrals. Instead of
explicitly computing the Rosenblatt transformation in this way, we propose to solve
the following problem:
Problem 2.5. Find
f ∗= arg min
Var [T(X)] ,
where f is subject to the structure (20).
One could modify the optimization problem by replacing Var [T(X)] with DKL (p||˜p)
in (21). We thus propose to ﬁnd a Rosenblatt-type re-arrangement all-at-once rather
4This result places conditions on µ0 essentially requiring that the marginals of µ0 have no
atoms. A suﬃcient condition is that µ0 be absolutely continuous with respect to Lebesgue measure.
Also, just as in Theorem 2.3, uniqueness of the map holds µ0-almost everywhere.
than component by component, and with a stopping criterion that involves the magnitude of the entire objective function being smaller than a prescribed threshold.
We must acknowledge, however, that the current theory does not preclude the
existence of non-monotone measure-preserving maps that have the triangular structure. Thus the question of whether minimizing Var [T(X)] subject to (20) guarantees
monotonicity of the map remains open. In numerical tests on a wide variety of inference problems, however, the solutions we obtain using the triangular constraint
are consistently monotone. Monotonicity is easily veriﬁed by examining det Dxf; it
should have the same sign (µ0-a.e.) over the support of the prior.
Note that one can exploit the triangular structure in order to express the determinant of the Jacobian of the map as a product of the diagonal terms:
det Dxf = det ∂f
∂fi(x1, . . . , xi)
3. Solution Algorithm
Problem 2.4 and its triangular variant are stochastic optimization problems, in
that they involve expectations with respect to the prior distribution.
also inﬁnite-dimensional, in that f (in principle) may be an element of an inﬁnitedimensional function space. Moreover, they may involve likelihood functions L that
are deﬁned implicitly through the solution of forward problems h and that are computationally intensive. We will describe algorithms for the solution of these problems,
taking into account all of the above challenges. The algorithms involve sample approximations of the prior expectation, a ﬂexible parameterization of f, and eﬃcient
gradient-based optimization. Later we describe a continuation-type method for solving a sequence of simpler optimization problems to yield a “cascade” or sequence of
3.1. Monte Carlo sampling
It is in general complicated or impossible to compute moments of T(X) using
analytical formulae. Instead, we use Monte Carlo sampling to approximate the expectation operator
E [T(X)] ≈1
where x(i) ∼µ0.
Notice that the expectation is taken with respect to the prior,
which is assumed to be a distribution from which one can easily generate independent
samples. (Extensions to the method may address situations where prior sampling is
diﬃcult; see Section 5.) The number of samples Ns is chosen adaptively over the
course of the optimization algorithm, as described in Section 3.4. Moreover, the set
x(i) is “refreshed” with a new batch of i.i.d. samples between cycles. In this sense, the
present scheme bears strong similarities to the SAA (sample average approximation)
approach to stochastic programming .
3.2. Polynomial approximation of f
As noted above, the optimization problems posed in Section 2.3 and 2.4 are
inﬁnite-dimensional. To make them more computationally feasible, the map f(x)
is approximated using a ﬁnite set of basis functions. In a high dimensional inference problem, the use of localized basis functions is in general not eﬃcient; instead,
a global basis is more suitable. In our implementation, we represent f using multivariate polynomials orthogonal with respect to the prior measure; in other words,
we write the map as a polynomial chaos expansion . Some additional
intuition for polynomial maps is as follows. An identity map f : Rn →Rn yields
a posterior that is equal to the prior. An aﬃne map containing a diagonal linear
transformation, i.e., where fi depends only on xi, allows changes of location and scale
in each component of the parameter vector, from prior to posterior, but preserves the
form of each distribution. An aﬃne map containing a general linear transformation
(with each fi depending on all components of x) allows the introduction of new correlations in the posterior. Quadratic, cubic, and higher-degree maps allow even more
complex distributional changes from prior to posterior.
We write the polynomial expansion of f as:
where i = (i1, i2, ..., in) ∈Nn is a multi-index, gi ∈Rn are the expansion coeﬃcients,
and ψi are n-variate polynomials. We write each of these polynomials as
where ϕij is a univariate polynomial of order ij in the variable xj, orthogonal with
respect to the distribution of xj. For simplicity, we assume here that the prior can be
described, perhaps after some transformation, by a set of independent random variables. That said, orthogonal polynomial expansions for dependent random variables
with arbitrary probability measure can certainly be constructed . The set of multiindices J describes the truncation of the expansion. For example J = {i : |i|1 ≤n0}
corresponds to a total-order expansion of degree n0, containing
K = card (J ) =
= (n + n0)!
The orthogonal polynomial representation of the map oﬀers several advantages,
besides being convenient and ﬂexible (by choice of J ). First, moments of the posterior distribution—i.e., moments of f(X), with X ∼µ0—can be evaluated analytically,
without the need for further sampling or additional forward model solves. For example, the posterior covariance is a weighted sum of outer products of the coeﬃcients:
Cov(Z) = P
i ]. Higher moments can be evaluated using known formulas
for the expectations of products of orthogonal polynomials . Second, obtaining a polynomial chaos expansion of the posterior facilitates eﬃcient propagation of
data-conditioned uncertainty through subsequent computational models. This is a
key step in posterior prediction and in sequential data assimilation (e.g., ﬁltering).
With a polynomial chaos representation in hand, a vast array of stochastic Galerkin
and stochastic collocation methods can be employed for uncertainty propagation.
Treating each coeﬃcient gi ∈Rn as a column vector, we assemble the set {gi}i∈J
into a matrix F T of size n × K, where K denotes card (J ):
In the optimal transport formulation all n × K coeﬃcients are considered the optimization variables, whereas in the triangular formulation some of these coeﬃcients
are ﬁxed to zero. The map f is then then represented as
f(x) = F TΨ(x)
where Ψ(x) is a column vector containing every basis polynomial ψi, i ∈J .
3.3. Newton’s method and nonlinear least squares
In our implementation we use two alternative algorithms to solve the optimization
problem: Newton’s method and nonlinear least squares. In the standard Newton’s
method, we compute both the ﬁrst and second derivatives of the objective function. It
is then necessary to compute the derivatives of T(x) with respect to the optimization
variables F:
T(x; F) = log (L ◦f) + log (p ◦f) + log |det Dxf| −log p
∂F + DxΨ (Dxf)−1
where ∂f/∂F = [In ⊗Ψ(z)]. The last term is obtained as follows:
(log |det Dxf|)
trace((Dxf)−1 EjiDxΨ)
trace((Dxf)−1 ej [DxΨ] (i, :))
[DxΨ] (i, :) (Dxf)−1 ej
∂F (log |det Dxf|)
DxΨ (Dxf)−1
where Eji is a matrix of all zeros except for a single 1 at the location (j, i) and ej is
a vector of zeros except for a 1 in row j.
The second derivatives of T can be obtained in a similar fashion. In the case of
a Gaussian prior and Gaussian additive noise, explicit expressions for the ﬁrst and
second derivatives are given in Appendix C. Note that to compute any derivatives of
the likelihood function, derivatives of the forward model are required. Using modern
adjoint techniques, gradients and Hessian-vector products can typically be computed
at the cost of O(1) forward solves, independent of the dimension of the parameter
space . In many problems, however, the forward model and its derivatives can be
accurately approximated using surrogate models .
The second derivatives of the log-determinant can be calculated explicitly as:
(log |det Dxf|)
−DxΨ (Dxf)−1 (EjiDxΨ) (Dxf)−1
−DxΨ (Dxf)−1 (ej [DxΨ] (i, :)) (Dxf)−1
 DxΨ (Dxf)−1 ej
  [DxΨ] (i, :) (Dxf)−1
From the previous relations it is clear that in order to compute the Hessian of the
log-determinant, we must ﬁrst compute the matrix DxΨ (Dxf)−1 and then use the
outer product of appropriate column and row vectors to assemble the desired Hessian.
Alternatively, one can use a nonlinear least squares (NLS) method to solve the
problem. This method is particularly suited to the triangular formulation of Section 2.4, which does not have a penalty term. To cast the optimization objective
as a nonlinear least squares problem, it is observed that the zero variance condition
Var [T(X)] = 0 is equivalent to T
= constant, for x(i) ∼p. In other words, T is
constant in an L2 sense. This leads to the set of equations
If the number of optimization parameters ℓ< nK in F is less than Ns, then (31) is
an overdetermined set of nonlinear equations in F, which can be solved via
where the rectangular matrix M ∈RNs×ℓand the column vector b ∈RNs are:
Here, the derivative of a scalar with respect to a vector is assumed to be a row vector.
We have observed that in certain cases, e.g., weakly multi-modal posteriors, convergence of the algorithm from arbitrary initial maps is more reliable if the objective
function is modiﬁed to become
Var [T(X)] + λE
where ˜β is an estimate of the evidence computed from the previous iteration. In
this case, the nonlinear least squares formulation proceeds from the following set of
equations:
i = 1 . . . Ns.
In general, we initialize our algorithm using the identity map, f(x) = x. Alternatively, if the likelihood contains additive Gaussian noise and the prior is Gaussian,
we linearize the forward model and compute the resulting map analytically. This
approximate linear map is then used to initialize the algorithm.
3.4. Algorithm structure
We solve the optimization problem in stages, by iterating over the order of the
polynomial representation of f(x). We typically start the algorithm with only linear
basis functions in Ψ(x). After computing the best linear map, the total order of the
polynomial basis is increased and a new corresponding map is computed—allowing
coeﬃcients of all the polynomial terms to be adjusted, not just those of the highest
degree. This process is repeated until reaching a stopping criterion Var [T(X)] < δ,
where δ is a preset threshold. The samples used to approximate the prior expectation
or variance are renewed each time the order of the expansion is increased. The number
of samples Ns is chosen such that approximations of the mean or variance obtained
with successive sample batches lie within some predetermined relative tolerance α of
each other, typically 5%.
Algorithm 1 summarizes our complete approach. Notice that the multiplier λ
is used only when computing the penalized map of Problem 2.4. The value of this
multiplier is adjusted each time the order of the expansion is increased; it is chosen
such that the penalty term is 10% of the total value of the objective function at
the start of the current stage. Thus λ decreases as f converges towards the desired
measure transformation.
3.5. Composite map
In certain problems, the map from prior to posterior can be accurately approximated only with very high-degree polynomials. Unfortunately, the number of coeﬃcients in a multivariate polynomial expansion grows very rapidly with degree, leading
to a more challenging optimization problem.
Algorithm 1: Structure of optimization algorithm for computing the map.
Data: Likelihood function L, observed data, prior density p, stopping criterion
δ, sample tolerance α
Result: Map f(x)
f(x) = x, i = 0, and λ = 1;
while Var [T(X)] > δ do
i = i + 1;
Generate Ns i.i.d. samples of the prior random variable;
if i > 1 then
Compute Var[T(X)];
if |(Var[T(X)]/V ∗) −1| > α then
Double the number of samples Ns ←2Ns;
Solve the optimization problem for f(x) up to desired order n0, stopping
when ∆F is smaller than a threshold;
Get current Var[T(X)] and store it in V ∗= Var[T(X)];
Increase order of expansion: n0 ←n0 + 2;
If applicable compute a new λ = 0.1 V ∗/E [∥X −f(X)∥2]
To overcome this diﬃculty, we can use a composition of maps to eﬃciently approximate a high-degree transformation from prior to posterior. That is, instead of
mapping the prior to the posterior with a single map, we introduce a sequence of
intermediate distributions that evolve gradually from prior to posterior. With this
sequence of distributions, we introduce a corresponding sequence of maps. Intuitively,
this approach “relaxes” the measure transformation problem; if the input and output
distributions are similar to each other, then the presumably the map can be well
approximated using low-degree polynomials. Letting the number of steps approach
inﬁnity, one could imagine a continuous transformation from prior to posterior, for
instance as proposed in .
Here we focus on ﬁnite sequences of intermediate distributions. There are many
ways that one could create such a sequence: iterating over the accuracy of the forward
model, gradually introducing components of the data vector d, or iterating over the
scale of the noise covariance in the likelihood function. We choose the latter tactic,
beginning with a large covariance Σ1 and introducing k stages such that the variance
of the last stage is the true Σ of the original inference problem:
Σ1 > Σ2 > · · · > Σk = Σ
For a given noise variance Σi, a composite map
φi ≡f i ◦f i−1 ◦· · · ◦f 1
is computed such that it maps the prior distribution µ0 (with density p) to the intermediate posterior distribution µi (with density qi) corresponding to ith-stage noise
level. Then we can minimize, e.g.,
with a regularization term added above as needed. Here only the parameters F i of
the ith map f i are optimization variables! Coeﬃcients of the preceding maps are
ﬁxed, having been determined in the previous stages’ optimization problems. See
Figure 3 for a schematic. The resulting map f = φk ≡f k ◦f k−1 ◦· · · ◦f 1 will have
been computed with signiﬁcantly less eﬀort (and fewer degrees of freedom) than a
total-order polynomial of the same maximum degree.
One advantage of the sequential construction above is that the accuracy of an
intermediate map, transforming the prior to any of the intermediate distributions
qi, does not aﬀect the accuracy of the ﬁnal map. Because the prior density p always
appears in (38), the ﬁnal stage can be be computed with tight error tolerances to yield
the appropriate measure transformation. Intermediate maps may be computed with
looser tolerances, as they serve in a sense only to ﬁnd distributions that are closer in
shape to the actual posterior. Any error in an intermediate f can be compensated for
by the ﬁnal f k. In our implementation, we have observed that this scheme is robust
and that it allows for simple error control.
Alternatively, one could think of computing the map one stage at a time—i.e., at
each step computing a transformation f i from qi−1 to qi by minimizing
The ﬁnal map is again f = φk ≡f k◦f k−1◦· · ·◦f 1. A possible advantage of this second
construction is that one needs to consider only a single map at a time. Each stage
must be solved exactly, however, as the construction depends on satisfying µi = φi
for all i. If φi does not push forward µ0 to µi, then any error incurred in the ﬁrst i
stages of the sequence will remain and corrupt the ﬁnal stage. Also, because the error
tolerances in the intermediate stages cannot be relaxed, the diﬃculty of computing
any of the intermediate maps could conceivably be as great as that of computing the
full map. For these reasons, we prefer the ﬁrst construction (38) and will use it when
demonstrating composite maps in the numerical examples (Section 4.3) below.
4. Results
We now demonstrate map-based inference on a series of example problems, ranging
from parameter estimation in linear-Gaussian models (allowing veriﬁcation against a
known analytical solution) to nonlinear ODEs and high-dimensional PDEs.
4.1. Linear-Gaussian model
Here we demonstrate the accuracy and convergence of our method on over- and
under-determined linear-Gaussian models. We evaluate both the optimal transport
formulation and the triangular formulation.
Consider a linear forward model h(x) = Ax, where the parameters x are endowed
with a Gaussian prior, x ∼N(0, ΣP), and additive measurement noise ε yields the
d = h(x) + ε = Ax + ε .
If the noise is further assumed to be Gaussian, ε ∼N(0, ΣN), then the posterior is
Gaussian, and the map f is linear and available in closed form:
f(x) = z0 + Z1x
µpost = ΣATΣ−1
In addition, the evidence can be computed in closed form:
A detailed derivation of the previous relations is given in Appendix B.
We ﬁrst test the two optimization formulations (the penalized optimal transport
objective of Section 2.3 and the triangular construction of Section 2.4) on an overdetermined inference problem with 10 parameters and 16 observations. The forward
model, represented by A ∈R16×10, is randomly generated with entries of A independently sampled from a standard normal distribution. We use an identity prior
covariance ΣP = I and put ΣN = σ2I with σ = 0.06.
With both formulations (Problem 2.4 and Problem 2.5), we observe convergence
to a map matching (42) after 15 iterations. The evidence β also converges to its
analytical value, to within machine precision. With the optimal transport formulation, we observe that our Z1 diﬀers from the symmetric matrix square root of the
posterior covariance by roughly 5%. More precisely, the Frobenius norm ∥· ∥F of the
diﬀerence, ∥Z1 −Σ1/2
post∥F, is roughly 5% of ∥Σ1/2
post∥F. When the triangular construction is employed, the Frobenius norm of Z1 −L is less than 10−6∥L∥F, where L is
the lower-triangular Cholesky factor of Σpost, i.e., Σpost = LLT. With the optimal
transport formulation, we have further observed that if the map f is forced to remain
symmetric and if the penalty factor λ is gradually reduced to zero, then Z1 matches
post with a relative error of less than 10−6.
Next we consider a larger but under-determined linear-Gaussian problem with 100
parameters and 8 observations, again randomly generating A. Using the triangular
construction, we compute the map. Convergence plots of Var [T] and the Kullback-
Leibler divergence DKL (p||˜p) are given in Figure 4, while convergence of the evidence
β is shown in Figure 5. The optimization iterations begin with the identity map,
and the variance and KL divergence decrease rapidly to zero as the correct map
is identiﬁed. (Note that KL divergence is not shown in the ﬁrst ﬁve iterations of
Figure 4, because the sample-estimated divergence is inﬁnity.) Near convergence, it
is observed that the value of the Kullback-Leibler divergence is approximately half
the variance of T(X). This relation is proven in Appendix A.
4.2. Reaction kinetics
This example demonstrates map-based inference on a nonlinear problem that
yields a non-Gaussian posterior, with a sharp lower bound and strong correlations.
The problem is two-dimensional, enabling direct visualization of the map. We examine the impact of truncating the polynomial order on convergence and monotonicity
of the map.
The objective of the problem is to infer the forward and reverse rates of reaction
in the chemical system A
k2 B . The governing equations are as follows, with u
representing the concentration of component A and v the concentration of component
−k1u + k2v
k1u −k2v .
The initial condition is ﬁxed at u(0) = 1 and v(0) = 0. The rate parameters k1 and
k2 are endowed with independent Gaussian prior distributions, k1 ∼N and
k2 ∼N . The “true” parameter values are set to k1 = 2, k2 = 4, and synthetic
data consisting of noisy observations of u at times t = 2, 4, 5, 8, and 10 are generated.
Observational noise is assumed to be i.i.d. Gaussian. Because the observations occur
relatively late in the dynamics of the ODE initial value problem, the only information
which can be inferred is the ratio of k1 and k2—i.e., the equilibrium constant of the
We compute a map using the algorithm detailed in Section 3. The map is represented using a total-order polynomial expansion. We begin with a linear map and
progressively increase its order; at the end of iterations with a 5th-order map (n0 = 5),
the Kullback-Leibler divergence DKL (p||˜p) is less than 10−3. The algorithm requires
a total of 30 inner-loop optimization steps to reach this level of accuracy.
Figure 6 shows 104 samples from both the prior and posterior distributions. As
expected, the posterior samples concentrate around the line k2 = 2k1. Also, posterior
samples are localized in the upper left quadrant of the k1-k2 plane, which corresponds
to stable trajectories of the ODE. In both Figures 6(a) and 6(b), sample points at
which the determinant of the Jacobian Dxf is negative are shown in red. Elsewhere
(blue points), the Jacobian determinant is positive. This sign change corresponds to
regions of the parameter space where monotonicity of the map is lost; we note that
all of these points are relegated to the tails of the prior distribution. Only 0.08% of
the samples have negative determinant.
Figures 7(a) and 7(b) show components of the map itself, via surface plots of
f1(k1, k2) and f2(k1, k2). The two components of the map are nearly identical up to a
scaling factor of two, which is to be expected, as the posterior distribution contains
a strong correlation between the parameters.
4.3. Genetic toggle switch
In this example we demonstrate the composite map on a six-dimensional nonlinear
parameter inference problem using real experimental data. We compare the accuracy
of our results to those obtained with a standard MCMC algorithm.
The example involves the dynamics of a genetic “toggle switch” . The toggle
switch consists of two repressible promotors arranged in a mutually inhibitory network: promoter 1 transcribes a repressor for promoter 2, while promoter 2 transcribes
a repressor for promoter 1. Either repressor may be induced by an external chemical
or thermal signal. Genetic circuits of this form have been implemented on E. coli
plasmids, and the following ODE model has been proposed :
1 + [IPTG]
Here u is the concentration of the ﬁrst repressor and v is the concentration of the
second repressor. [IPTG] is the concentration of IPTG, the chemical compound that
induces the switch. At low values of [IPTG], the switch is in the ‘low’ state, reﬂected
in low values of v; conversely, high values of [IPTG] lead to strong expression of v.
As in , we would like to infer the six model parameters α1, α2, β, γ, η and κ. To
this end, we employ actual experimental data5 consisting of normalized steady-state
values of v at selected IPTG concentrations, spanning the ‘low’ and ‘high’ sides of
the switch: [IPTG] ∈{10−3, 0.6, 1, 3, 6, 10} × 10−3.
5Data are courtesy of Dr. T. S. Gardner.
At steady state, the model yields the following relations
1 + [IPTG]
which can be expressed as an implicit function v = g(v, ξ), where ξ = (α1, α2, β, γ, η, κ).
The elements of ξ are endowed with independent uniform prior distributions, centered
at the nominal values ξ0 suggested in :
 156.25, 15.6, 2.5, 1, 2.0015, 2.9618 × 10−5
In other words, we have
ξi = ξ0,i (1 + σiθi)
where θ is a vector of uniformly-distributed random variables, θi ∼U(−1, 1), and
entries of σ are (0.20, 0.15, 0.15, 0.15, 0.30, 0.20). As detailed in , the observational
error is assumed Gaussian and zero-mean, with a standard deviation that depends on
whether the expression level is low or high. This simpliﬁed error model is consistent
with experimental observations.
The use of uniform priors adds an extra constraint on the map: since the prior
support is a unit hypercube (with appropriate scaling), the range of the map must
be an improper subset of the unit hypercube, just as the support of the posterior is
contained within the support of the prior. This constraint is diﬃcult to satisfy when
the map is approximated using global polynomials. To circumvent this diﬃculty, we
ﬁrst map the uniform random variables θ to independent standard normal random
variables x ∼N(0, I) using the error function:
Computation of the map can now proceed using a Gaussian prior on the input x. After
computing the map f(x), the posterior random variable ξpost is obtained through the
same transformation:
ξpost = ξ0
All derivatives of ξ with respect to x are computed analytically using (46) and (47),
Using the implicit expression for v, we can compute the derivatives of v with
respect to any model parameter ξi:
The second derivatives are:
To compute derivatives with respect to the transformed Gaussian random variables
x, the chain rule is applied:
With these transformations in place, we turn to the numerical results in Figures 8–
10. In this problem, a high-order map is required to accurately capture the posterior
distribution, and thus we employ the composite map of Section 3.5. In particular,
we compute the overall map using a four-stage cascade of third order maps, f =
f 1 ◦· · · ◦f 4. The distributions obtained after each stage are shown in Figures 8(a)–
8(d), using a scatter plot of output samples from each map (φ1, φ2, etc). While the
posterior is six-dimensional, these plots focus on the pairwise marginal distribution
of α1 and γ; this is the most “complex” pairwise marginal and is particularly sensitive
to the accuracy of f. These distributions are shown on the transformed Gaussian
domain, and thus they correspond to the ﬁrst and fourth components of x: xα1 and
xγ. For comparison, Figure 8(e) shows results obtained using a long run of delayedrejection adaptive Metropolis (DRAM) MCMC , with 106 samples.
In Figures 9(a)–9(f) we show the marginal posterior probability density of each
component of ξ, obtained at the end of the four-map sequence. These densities are
compared with densities obtained using the long MCMC run; the map-based results
show good agreement with the latter. Figure 10 shows samples from the joint prior
of xα1 and xα2. As speciﬁed above, these parameters are independent and standard
normal. The point of this ﬁgure is not the distribution per se, but rather the color
labeling, which diagnoses the monotonicity of the map. The map is evaluated on 106
samples from the prior. Among these samples, only 861 have Jacobian determinants
that are negative; all the rest are positive. As in the previous example, the few samples
with negative Jacobian determinant are concentrated in the tails of the distribution.
Away from the tails, the map is monotone.
4.4. PDE-constrained inverse problems
Examples in this section focus on high-dimensional inverse problems involving
partial diﬀerential equations (PDEs). In particular, our objective is to estimate a
spatially heterogeneous coeﬃcient κ appearing in an elliptic PDE, from noisy and limited observations of the solution ﬁeld . We solve the problem on one-dimensional
(Section 4.4.1) and two-dimensional (Section 4.4.2) spatial domains. We employ the
triangular parameterization of the map, performing quantitative comparisons of computational eﬃciency and accuracy with MCMC for a range of data sets and observational noise magnitudes.
4.4.1. One-dimensional domain
Consider a linear elliptic PDE on the unit interval S = 
∇· (κ(s)∇u) = −f(s)
where s ∈S is the spatial coordinate, ∇≡∂/∂s, and f is a known source term.
In the subsurface context, this equation describes Darcy ﬂow through porous media,
where κ represents a permeability ﬁeld and u is the pressure. We apply boundary
conditions ∂u
s=0 = 0 and u|s=1 = 1. The source term is given by:
f(s) = a exp
2b2 (s −sm)2
with a = 100, sm = 0.5, and b = 0.01.
We place a log-normal prior on the permeability ﬁeld κ,
log [κ(s, ω) −κ0] ∼GP (0, C)
and let the covariance kernel c(s, s′) of the Gaussian process have exponential form
c (s, s′) = σ2 exp
6 We use a prior standard deviation of σ = 1.5 and a correlation length Lc = 0.5,
along with an oﬀset κ0 = 0.5. Realizations of this spatial process are rough; in fact,
they are not mean-square diﬀerentiable.
6Note that c(s, s′) is the Green’s function of the diﬀerential operator
with appropriate boundary conditions . Hence the inverse covariance operator C−1 is explicitly represented by (56).
The problem is spatially discretized using ﬁnite diﬀerences on a uniform grid, with
spacing ∆s = 1/100. The log-normal permeability ﬁeld is stochastically discretized
using the Karhunen-Loève expansion of the underlying Gaussian process:
log [κ(s, ω) −κ0] ≈
where xi ∼N(0, 1) are independent standard normal random variables, and φi, λi
are the eigenfunctions and eigenvalues of the linear operator corresponding to the
covariance kernel:
S c(s, s′)φi(s)ds = λiφ(s′). We discretize the eigenfunctions on
the same grid used to discretize the PDE solution ﬁeld u. To capture 99% of the
spatially-integrated variance of the log-normal process, we retain n = 66 Karhunen-
Loève modes.
Noisy observations of u are obtained at m points in space. The noise is additive
and i.i.d. Gaussian, such that dj = u(sj; x) + εj with εj ∼N(0, σ2
n), j = 1 . . . m. The
observational data is generated by choosing a “true” permeability ﬁeld κ, solving the
full PDE model (52) to obtain the corresponding pressure ﬁeld u(s), then corrupting
u(s) at the m measurement locations with independent realizations of the noise. In
the inference process, on the other hand, we use the polynomial chaos expansion (58)
as the forward model. This discrepancy ensures that we do not commit an “inverse
crime” .
Any Bayesian inference strategy, whether the map-based optimization approach
or MCMC, requires repeated evaluations of the forward model. As suggested in ,
exploiting regularity in the dependence of u on the parameters x can make these
evaluations more computationally tractable. We therefore approximate u(s; x) using
a polynomial chaos expansion. We apply the iterative algorithm developed in ,
for the solution of high-dimensional stochastic PDEs, to obtain an approximation of
u in the form:
uk(s)ψk(x)
where uk are coeﬃcients and ψk(x) are multivariate Hermite polynomials, chosen
adaptively within a very large basis set K.
Algorithm 1 allows the expansion order of the map f(x) to be increased in stages;
i.e., we begin by ﬁnding a linear map, then a cubic map, and so on. Since inference problems involving distributed parameters are typically high-dimensional (in
the current problem f maps R66 onto itself, for example), writing f as a total-order
polynomial expansion in all n of its components will lead to a very large number of degrees of freedom, most of which are not needed to achieve an accurate representation
of the posterior. Instead, we reﬁne the polynomial description of the map in a more
ﬁnely-grained fashion. Recall that f(x) = F TΨ(x), where Ψ is a vector of orthogonal
polynomials in x1 . . . xn. In the structure of Algorithm 1, decisions to expand the
polynomial description of the map are made outside of the inner optimization loop,
after checking whether Var[T] satisﬁes the desired threshold δ. Now, rather than raising the polynomial degree of the entire map (e.g., n0 ←n0 + 2), we choose a subset
of the inputs {xi : i ∈I} and introduce higher-degree polynomial terms in these
variables only. The index set I initially consists of {1, 2, . . . , i1 < n}. At the next
iteration, if the variance threshold is still not satisﬁed, i1 is replaced with a larger
index i2, where i1 < i2 < n. This process continues until the largest element in I is
n or until Var[T] stagnates. Now I is reset and new polynomial terms of even higher
degree, involving only x1 through xi1, are added to the expansion. Then the index
set is expanded once again. In any of these iterations, adding terms to the expansion
is equivalent to adding rows to Ψ(x) and to the matrix of polynomial coeﬃcients F.
To make this process more concrete, consider what happens in the present inference problems. We begin by solving for the polynomial coeﬃcients of a linear map
(possibly subject to the triangular constraint). The optimal linear map is not able to
reduce Var[T] below the requisite threshold. Polynomial terms of total order n0 = 3
in the ﬁrst i1 = 10 (for example) components of x are then introduced, and all the
coeﬃcients collected in F are adjusted via optimization. This reﬁnement of f is still
not suﬃcient, so now the order-3 expansion is extended to the ﬁrst i2 = 20 (again for
example) components of x. Extension to additional components of x is observed to
yield little decrease in the minimal value of Var[T], so now the polynomial space is
enriched by adding terms of total order n0 = 5 in the ﬁrst i1 components of x. Iterations continue until convergence, resulting an “adapted” map f whose components
are a subset of a total-order expansion in x1 . . . xn.
Results of our algorithm are shown in Figures 11–13, where we also report comparisons with MCMC. We consider three cases, corresponding to diﬀerent numbers of
observations m and diﬀerent noise levels σ2
n. In Case I, we have m = 31 observations
and a noise standard deviation of σn = 0.05; in Case II, we increase the number of
data points to m = 101 and retain σn = 0.05; in Case III we keep m = 101 observations and reduce the noise standard deviation to σn = 0.01. In all cases, the maximum
polynomial order of the map is 5 and the optimization routine is terminated when
Var[T] < δ = 0.1. We use the triangular formulation and a single map (rather than
a composite map) for these problems.
Figures 11(a)–11(f) plot the posterior mean and standard deviation of the logpermeability ﬁeld as computed with optimal maps and with MCMC. The “truth”
log-permeability ﬁeld, used to generate the data, is shown in black. As expected in
this ill-conditioned problem, only the smooth part of the permeability ﬁeld can be
reconstructed. As the number of data points increases and the noise level decreases,
however, more features of the permeability ﬁeld can be recovered.
The posterior
covariance is non-stationary, and we note that the posterior variance is much smaller
at the right boundary, where there is a Dirichlet boundary condition, than at the
left boundary, where a zero Neumann condition was imposed.
Overall, posterior
uncertainty decreases from Case I to Case III, reﬂecting additional information in
the data. Good agreement between the map and MCMC results is observed, though
MCMC yields a slightly larger standard deviation in the left half of the domain. The
current MCMC results were obtained using 106 samples of DRAM, with the ﬁrst
5×105 samples discarded as burn-in. Simple MCMC convergence diagnostics suggest
that this is an adequate number of samples, but it is not entirely clear which set of
results is more authoritative. Indeed, we observed that DRAM failed to converge
in almost half the attempted runs of Case III. (These runs were initiated from the
prior mean; diﬀerences among the attempted runs result from randomness in the
proposals.) On the other hand, the optimal map algorithm reliably converges to the
desired tolerance δ.
Figure 12 shows posterior realizations for Case I and Case III, as computed with
the map and with MCMC. Note that the realizations are diﬀerent in character than
the posterior mean; they are signiﬁcantly rougher, as one would expect given the
exponential covariance kernel in the Gaussian process prior. But the map and MCMC
results yield posterior realizations of similar character.
In Figure 13 we plot the posterior covariance of log (κ −κ0) from Case I. We choose
this case because of the apparent discrepancy in posterior standard deviations shown
in Figure 11(b). Figure 13(a) is a surface plot of the posterior covariance as computed
using our map algorithm. The exponential prior covariance has a discontinuity in its
derivative at the diagonal, smoothed slightly due to truncation at a ﬁnite number of
Karhunen-Loève modes. This feature is preserved in the posterior, reﬂecting the fact
that posterior realizations are also rough and that data are not informative at the
smallest scales. The overall scale of the covariance is reduced signiﬁcantly from prior
to posterior, however. While the prior covariance was stationary with σ2 = 1.5, the
posterior shows smaller variance throughout the spatial domain.
In Figure 13(b) we compare the contours of posterior covariance obtained with the
map to those obtained using MCMC algorithm. The 16 contour levels range uniformly
from −0.1 to 1.4. Contours computed using the two methods are remarkably similar.
It should be emphasized that ﬁnding the map f enables the posterior covariance to
be computed analytically.
4.4.2. Two-dimensional domain
To explore the performance of our algorithm in a more challenging setting, we
solve the same inverse problem as in Section 4.4.1 but on a two-dimensional spatial
domain S = 2. The governing equation is still (52), but now s ≡(s1, s2) ∈S
and ∇≡(∂/∂s1, ∂/∂s2). We apply deterministic Dirichlet boundary conditions on
all four sides of S, with u(0, 0) = 0, u(0, 1) = 1, u(1, 1) = −1, u(1, 0) = 2 and a
linear variation on ∂S between these corners. The source term f is of the form (53),
centered at sm = (0.5, 0.5) and with width b =
10/40. The equation is discretized
on a 41 × 41 grid.
Again we place a log-normal prior on the permeability ﬁeld (54) with κ0 = 1,
choosing an isotropic exponential covariance kernel c(s, s′) with σ = 1.25 and Lc =
0.5. To capture 95% of the spatially integrated variance of the prior permeability
ﬁeld, the next two cases employ n = 39 Karhunen-Loève modes.
Two diﬀerent data conﬁgurations are considered. The ﬁrst (Case A) uses m = 121
observations randomly scattered on the spatial domain, with noise standard deviation
σn = 0.08; the second (Case B) involves m = 234 randomly scattered observations and
noise standard deviation σn = 0.04. As in the one-dimensional problem, a polynomial
chaos approximation of u(s, x) is used as the forward model for inversion.
We ﬁrst focus our analysis on the posterior distribution of the Karhunen-Loève
mode weights {zi}, where z = f(x) and xi ∼N(0, 1). Figure 14(a) shows a boxplot
of the mode weights computed using the map. The extent of each blue box marks the
25% and 75% quantiles of the posterior marginal of each zi, while the vertical lines
or “whiskers” span the entire range of the posterior samples drawn via the map. We
also plot the posterior mean of zi obtained with the map (circle) and with MCMC
(an ×). Finally we show the mode weights corresponding to the “true” permeability
ﬁeld used to generate the data, before the addition of observational noise. The map
and MCMC means agree reasonably well. Comparing the results of inference with the
true weights, it is observed that the ﬁrst few modes are accurately identiﬁed, whereas
the higher-index modes are not. This is because the higher-index modes are rougher;
they correspond to higher-frequency components of the permeability ﬁeld, which are
smoothed by the elliptic operator and therefore diﬃcult to identify from observations
of u. This trend is further demonstrated by Figure 14(b), which shows the posterior
standard deviation of each mode, computed with the map and with MCMC. As the
mode indices increase, their posterior variances approach unity—which is exactly the
prior variance on xi.
Thus the data contained little information to constrain the
variability of these modes.
Turning from analysis of the Karhunen-Loève modes to analysis of the permeability ﬁeld itself, Figure 15 shows the truth log-permeability ﬁeld used to generate the
data (which here reﬂects truncation to n = 39 Karhunen-Loève modes). Figure 16(a)
shows the posterior mean log-permeability obtained with the map in Case A. Given
the smoothing character of the forward model, the presence of noise on the data, and
mismatch between the full PDE model used to generate the noiseless data and the
PC approximation used for inversion, we should not expect the posterior mean and
the true permeability ﬁeld to match exactly. Indeed, the posterior mean matches the
true ﬁeld in its large-scale behavior, but most of the localized or small-scale features
are lost; the corresponding mode weights necessarily revert to their prior mean of
zero. Figure 16(b) shows the posterior standard deviation of the log-permeability as
computed with the map, while Figures 17(a) and 17(b) show the posterior mean and
standard deviation ﬁelds computed with MCMC. Results obtained via the two algorithms are very similar. The computational time required to solve the optimization
problem for the map, with tolerance δ = 0.5, is equal to the time required for 5 × 105
steps of MCMC.
Figures 18–20 show analogous results for Case B, with roughly twice as many observations and half the noise standard deviation of Case A. The boxplot of Karhunen-
Loève (KL) mode weights in Figure 18(a) shows that a larger number of modes (at
higher index) are accurately identiﬁed, compared to Case A. In Figure 18(b), the
posterior standard deviation of the modes is less than in Case A, reﬂecting the additional information carried by the data.
Figure 19(a) shows the posterior mean
log-permeability obtained with the map for Case B; though this ﬁeld is still smooth,
more of the small-scale features of the true permeability ﬁeld are captured. MCMC
results shown in Figure 20 are quite similar to those obtained with the map.
The MCMC results reported here were obtained using a DRAM chain of 106
samples, half of which were discarded as burn-in. We make no claim that this is most
eﬃcient MCMC approach to this problem; certainly a carefully hand-tuned algorithm
could yield better mixing.
However, we do claim that it represents good MCMC
performance. Because the inference problem has been transformed to the Karhunen-
Loève modes, which have unit variance and are uncorrelated in the prior, the adaptive
Metropolis algorithm starts from a favorable parameterization with known scaling.
Even with a good parameterization and an adaptive algorithm, however, MCMC
mixing remains a challenge in these ill-posed inverse problems. Figure 21 shows the
eﬀective sample size (ESS) of each component of the chain corresponding to N =
5 × 105 post burn-in samples. The eﬀective sample size is computed by integrating
the chain autocorrelation ρi at lag i:
The ESS for most of the chain components lies between 1500 and 4000. In order
to obtain a reasonable number of posterior samples—e.g., for an accurate estimate
of a posterior moment, or to propagate posterior uncertainty through a subsequent
simulation—an unreasonable number of MCMC steps is thus required. For instance,
if one desires 105 eﬀectively independent posterior samples, then at least 30 million
MCMC steps are needed (here, corresponding to about 2 days of simulation time). On
the same computational platform and for the same problem, using the map algorithm
to generate 105 independent samples requires about 45 minutes of wallclock time to
solve the optimization problem and construct f, followed by 5 minutes to pass 105
prior samples through the map and generate the desired posterior samples.
corresponds to a factor of 50 reduction in computational time.
We also note that when the noise standard deviation is reduced to σn = 0.01, then
the adaptive MCMC algorithm fails to converge, producing a chain with near-zero
acceptance rate regardless of how many times we rerun it (starting from the prior
On the other hand, the map algorithm has no trouble converging to the
desired accuracy δ in roughly 55 minutes of wallclock time (only 10 minutes more
than that required for Case B).
As a ﬁnal example we consider a more reﬁned stochastic discretization of the prior
log-normal process. We now retain n = 139 Karhunen-Loève modes, such that 97.5%
of the input permeability ﬁeld’s integrated variance is preserved. We make m = 227
noisy observations, with a noise standard deviation of σn = 0.04. In this example
we focus on comparing the computational performance of MCMC and map-based
inference.
Two diﬀerent MCMC chains are run, each of length 106 samples. Both chains start
from the prior mean and proceed with adaptive random-walk proposals. It is observed
that the burn-in period is relatively long; we thus remove half the chain and use the
remaining 5 × 105 samples to compute all quantities below. Each chain takes approximately 5 hours to produce. The map algorithm is run until the variance of T(X) is
less than 1% of the mean of T(X); this corresponds to a KL divergence DKL (p||˜p)
of 1 nat. The computational time required to solve the optimization problem to this
threshold is less than 3 hours.
Figure 22 shows the posterior mean values of the Karhunen-Loève modes computed using MCMC and the map. The two MCMC runs shown in Figure 22(a) diﬀer
signiﬁcantly in their higher-index modes, indicating that these components of the
chain mix rather poorly. Comparing the map-based posterior means with the “truth”
shows, as usual, that the smoother modes are well identiﬁed in the posterior while
the rougher modes are not, reverting instead to the prior. Poor mixing of the MCMC
algorithm is also evident in Figure 23, which shows the posterior standard deviation
of each mode weight. For mode indices larger than 10, the two MCMC runs yield
very diﬀerent standard deviations. And the standard deviations of the higher-index
modes plateau below 0.8.
The discrepancy between the chains suggests that this
value is not credible, and that the chains are in fact not exploring the full parameter
space (despite using 106 samples). One would instead expect the rough highest-index
modes to revert to the prior standard deviation of 1.0, exactly as observed in the
map-based results. Indeed, agreement of the prior and posterior distributions on the
high-index KL modes is a consequence of absolute continuity of the posterior with
respect to the prior . Limitations of standard MCMC algorithms in this context
have been discussed in .
In Figure 24 we compute eﬀective sample sizes for one of the MCMC chains
from the previous ﬁgures.
The minimum ESS over all chain components is 275;
the median, mean, and max ESS are 543, 561, 1100, respectively.
Extrapolating
these numbers lets us determine the total computational (wallclock) time needed to
compute any number of eﬀectively independent samples via MCMC. Figure 25 thus
compares the computational eﬀort of MCMC to that required by the map. We neglect
the computational time associated with any MCMC burn-in period, eﬀectively giving
MCMC a signiﬁcant boost in the performance comparison. The time required by
the MCMC algorithm grows linearly with the number of independent samples. On
the other hand, the map requires a ﬁxed amount of time at the outset, in order to
solve the optimization problem, while the computational cost for each new sample
point is almost negligible. (The latter still grows linearly with the number of samples
but with a very small slope.) Here, if one is interested in generating fewer than 300
independent samples, then MCMC is faster; otherwise ﬁnding the optimal map is
more eﬃcient.
Figure 26 shows a similar comparison, but uses the number of forward model evaluations as a measure of computational eﬀort, rather than wallclock time. We assume
that derivatives of the forward model output with respect to the model parameters
can be computed with an adjoint method, which means that the cost of computing the
ﬁrst derivatives is equivalent to approximately two forward solves. Furthermore, per
the current implementation, we assume that second derivatives of the forward model
with respect to the parameters are not computed. In this comparison, the break-even
point is approximately 200 samples. If the desired number of samples is smaller, then
MCMC is more eﬃcient; otherwise the map algorithm can oﬀer order-of-magnitude
reductions in computational eﬀort.
Finally, we note that all of the computations above have used a serial implementation of the map-based inference approach. It should be emphasized, however, that
the bulk of the computational eﬀort involved in solving the optimization problem for
the map and subsequently generating samples is embarrassingly parallel.
5. Conclusions
We have presented a new approach to Bayesian inference, based on the explicit
construction of a map that pushes forward the prior measure to the posterior measure.
The approach is a signiﬁcant departure from Markov chain methods that characterize the posterior distribution by generating correlated samples. Instead, the present
approach ﬁnds a deterministic map f through the solution of an optimization problem. Existence and uniqueness of a monotone measure-preserving map is established
using results from optimal transport theory. We adapt these results and propose two
alternative optimization formulations, one with an explicit regularization term in the
objective and one that regularizes the problem by constraining the structure of f.
The new formulation oﬀers several advantages over previous methods for Bayesian
computation:
• The optimization problem provides a clear convergence criterion, namely that
Var[T(X)] →0, with T(X) deﬁned in (12). Monitoring this criterion can be
used to terminate iterations or to adaptively enrich the function space used to
describe the map, until a desired level of accuracy is reached.
• The posterior normalizing constant, or evidence, is computed “for free” as an
output of the optimization problem.
• Because we describe the map using standard orthogonal polynomials, posterior
moments may be computed analytically from the polynomial coeﬃcients.
• Once a map is in hand, arbitrary numbers of independent posterior samples
may be generated with minimal computational cost, by applying the map to
samples from the prior.
• While the optimization objective involves prior expectations and is thus stochastic, eﬃcient gradient-based methods (e.g., Newton or quasi-Newton methods,
with the full machinery of adjoints) can nonetheless be used to solve the optimization problem.
• A sequence of low-order maps may be composed to capture the transition from
prior to posterior; this construction allows a complex change of measure to be
captured more economically than with a single map.
We demonstrate the map-based approach on a range of examples. Fast convergence
to the exact solution is observed in a linear parameter inference problem. We also
infer parameters in a nonlinear ODE system, using real experimental data, where the
posterior is of complicated form and diﬀers in shape from the prior. Finally, we use
the map to tackle several high-dimensional, ill-posed, and nonlinear inverse problems,
involving inference of a spatially heterogeneous diﬀusion coeﬃcient in an elliptic PDE.
Overall, inference with maps proceeds with greater reliability and eﬃciency than
MCMC—particularly on high-dimensional inverse problems. Speedup can be quantiﬁed in simple ways, such as counting the computational eﬀort required to produce
a certain number of eﬀectively independent posterior samples. In the present problems, the cost of computing the map with typical tolerances is equivalent to obtaining
roughly 200 independent samples with MCMC. But these comparisons are necessarily
insuﬃcient, because inference with maps provides more information and more useful
diagnostics than MCMC, as detailed above.
Several promising avenues exist for future work.
There is ample opportunity
to improve the eﬃciency of the optimization algorithms. First, we note that each
optimization step can be made embarrassingly parallel, as it relies on prior sampling.
Among the most computationally intensive elements of the optimization procedure
is the evaluation of the forward model h, composed with the map, on each prior
sample. Parallelizing these computations and their corresponding adjoint solves would
lead to immediate and substantial computational gains. More eﬃcient optimization
approaches may also employ importance sampling to compute the variance or mean
of T, or introduce stochastic expansions for T itself.
The map itself is a polynomial chaos expansion of the posterior distribution, and
thus it is readily suited to propagation of posterior uncertainty through subsequent
dynamics. With this posterior propagation step comes an immediate extension to
recursive inference problems, i.e., ﬁltering and prediction with sequential data. Moreover, in the present work, we have focused on measure transformations from prior
to posterior, but one could also create maps that push forward some third “base”
measure to both the posterior and prior. Such a construction could be useful when
it is not convenient or easy to generate independent prior samples, or if the prior is
There are several types of static inference problem for which the map approach
must be further developed. The examples presented in this paper had only one ‘level’;
extensions of map-based inference to include hyperparameters, or more generally, to
exploit the structure of Bayesian hierarchical models, are currently ongoing. Another
challenge arises when the posterior has bounded support, with signiﬁcant probability
mass accumulating near a boundary. The range of the map must be appropriately
bounded in such cases. Thus far we have circumvented such problems by reparameterization, transforming bounded domains into unbounded ones. This trick comes at
a computational price, e.g., greater nonlinearity. We ask, then, how more directly to
bound the range of the map, whether on a bounded or unbounded input domain, via
constraints in optimization or perhaps a non-polynomial basis.
We would also like to better understand the limiting behavior of the map in illposed and high-dimensional problems. When inferring distributed parameters with
some meaningful correlation structure—in the elliptic inverse problem, for example—
there is a natural ordering of the random variables and adaptive enrichment of the
map works well. But in high-dimensional nonlinear problems with no natural ordering (for instance, nonlinear ODE systems with hundreds of unknown parameters),
a high-order polynomial expansion in all the modes is computationally prohibitive.
Further exploration of adaptive methods, perhaps coupled with dimensionality reduction, is needed. We ask, for example, whether inferential maps have a low-rank
tensorial representation or a sparse representation in some basis. Finally, we note
that generating multi-modal posterior distributions from unimodal priors will require
more localized structure in the maps than global polynomial basis functions can feasibly provide. Piecewise polynomials, multi-element polynomial chaos , and similar
representations may be quite useful in such problems.
Acknowledgments
The authors would like to acknowledge support from the US Department of Energy, Oﬃce of Science, Oﬃce of Advanced Scientiﬁc Computing Research (ASCR)
under grant numbers DE-SC0002517 and DE-SC0003908.