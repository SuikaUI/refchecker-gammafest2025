HAL Id: hal-00283769
 
Submitted on 30 May 2008
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of scientific research documents, whether they are published or not.
The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Spectral and Spatial Classification of Hyperspectral
Data Using SVMs and Morphological Profiles
Mathieu Fauvel, Jon Atli Benediktsson, Jocelyn Chanussot, Johannes R.
To cite this version:
Mathieu Fauvel, Jon Atli Benediktsson, Jocelyn Chanussot, Johannes R. Sveinsson. Spectral and Spatial Classification of Hyperspectral Data Using SVMs and Morphological Profiles. IEEE Transactions
on Geoscience and Remote Sensing, 2008, 46 (11 - part 2), pp.3804-3814. ￿hal-00283769￿
Spectral and Spatial Classiﬁcation of Hyperspectral
Data Using SVMs and Morphological Proﬁles
Mathieu Fauvel∗† Student Member, IEEE, J´on Atli Benediktsson† Fellow, IEEE, Jocelyn Chanussot∗Senior
Member, IEEE and Johannes R. Sveinsson† Senior Member, IEEE
∗GIPSA-LAB, Signal & Image Department, Grenoble Institute of Technology - INPG
BP 46 - 38402 St Martin d’Heres - FRANCE
†Department of Electrical and Computer Engineering, University of Iceland
Hjardarhagi 2-6, 107 Reykjavik, ICELAND
E-mail: {mathieu.fauvel, jocelyn.chanussot}@gipsa-lab.inpg.fr, {benedikt, sveinsso}@hi.is
Abstract—A method is proposed for the classiﬁcation of urban
hyperspectral data with high spatial resolution. The approach is
an extension of previous approaches and uses both the spatial
and spectral information for classiﬁcation. One previous approach
is based on using several principal components from the hyperspectral data and building several morphological proﬁles. These
proﬁles can be used all together in one extended morphological
proﬁle. A shortcoming of that approach is that it was primarily
designed for classiﬁcation of urban structures and it does not fully
utilize the spectral information in the data. Similarly, the commonly
used pixel-wise classiﬁcation of hyperspectral data is solely based
on the spectral content and lacks information on the structure
of the features in the image. The proposed method overcomes
these problems and is based on the fusion of the morphological
information and the original hyperspectral data, i.e., the two
vectors of attributes are concatenated into one feature vector.
After a reduction of the dimensionality the ﬁnal classiﬁcation is
achieved using a Support Vector Machines classiﬁer. The proposed
approach is tested in experiments on ROSIS data from urban areas.
Signiﬁcant improvements are achieved in terms of accuracies when
compared to results obtained for approaches based on the use of
morphological proﬁles based on PCs only and conventional spectral
classiﬁcation. For instance, with one data set, the overall accuracy
is increased from 79% to 83% without any feature reduction and
to 87% with feature reduction. The proposed approach also shows
excellent results with a limited training set.
Index Terms—Data fusion, hyperspectral data, support vector
machines, feature extraction, extended morphological proﬁle, high
spatial resolution.
I. INTRODUCTION
In classiﬁcation of remote sensing data from urban areas,
the identiﬁcation of relatively small objects, e.g., houses and
narrow streets is important. Therefore, high spatial resolution
of the imagery is necessary for accurate classiﬁcation. The
most commonly available remote sensing data of high spatial
resolution from urban areas are single-band panchromatic data.
However, using only one high-resolution panchromatic data
channel is usually not sufﬁcient for accurate classiﬁcation of
structural information. To overcome that problem, Pesaresi and
Benediktsson proposed the use of morphological transformations to build a Morphological Proﬁle (MP). In the
method in was extended for hyperspectral data with high
spatial resolution. The approach in is based on using several
Principal Components (PCs) from the hyperspectral data. From
each of the PCs, a morphological proﬁle is built. These proﬁles
are used all together in one Extended Morphological Proﬁle
(EMP), which is then classiﬁed by a neural network. The method
in has been shown to perform well in terms of accuracies
when compared to more conventional classiﬁcation approaches.
However, a shortcoming of the approach is that it is primarily
designed for classiﬁcation of urban structures and it does not
fully utilize the spectral information in the multispectral or
hyperspectral data.
However this type of data contains a lot of information about
the spectral properties and the land cover of the data. A ﬁner
deﬁnition of the classes is possible and more classes can be
considered. Based on the spectral signatures of the classes,
many advanced pixel-based classiﬁers have been proposed including advanced statistical classiﬁers and distribution free
approaches such as neural networks and support vector machines . The later one has shown remarkable abilities to deal
with remote multispectral data, especially with hyperspectral
data. However, if the spatial content of the image is not used the
resulting thematic map sometimes looks noisy (salt and pepper
classiﬁcation noise). Approaches involving Markov Random
Field (MRF) and Monte Carlo optimization have been proposed
in , . These approaches use the contextual information. The
main shortcoming of such algorithms is the computing time,
which can be high even for small data sets. Regarding the high
dimensionality of recently acquired data, both in the spectral
and in the spatial domain, computationally light algorithm are
of interest. In this sense, the MP has been proposed as an
alternative way to use spatial information , . Relatively
to the MRF-based classiﬁers, the MP and its extension to a
multiband image, the EMP, have the possibility to use geometrical contextual information (shape, size, etc) and perform
well on many kinds of data (panchromatic, multispectral and
hyperspectral data). However, as stated above, a shortcoming of
this approach is it does not fully utilize the spectral information
in the data, and consequently several approaches based on the
MP/EMP have been proposed to fully exploit the spatial and
the spectral information – .
Each data set has its own properties, deﬁning its ability to
deal with different natures of classes. Table I sums up the
properties of spectral and morphological/spatial data. The ﬁrst
main consideration is the complementary characteristics of the
data. It has a consequence in the discrimination ability of such
a feature, as will be seen in the experiments. The fusion of
two types of information should clearly results in an increase
of the classiﬁcation in terms of global accuracy. The use of
spectral information can be critical for classiﬁcation of nonstructured information in urban areas, e.g., vegetation and soil
classes while the use of spatial information can be useful
for classiﬁcation of structured objects, e.g., road and building
The second consideration is the possible redundancy of each
features set, see for the spectral features and for the
spatial features. Hence feature extraction (FE) algorithms could
be of an interest.
To include both type of information an extension to the
approach in is proposed in this paper. The proposed method
is based on the data fusion of the morphological information
and the original data: First, an extended morphological proﬁle is
created based on the PCs from the hyperspectral data. Secondly,
feature extraction is applied on the original hyperspectral data
and the extended morphological proﬁle. Finally, the extracted
feature vectors from both the original data and the extended
morphological proﬁle are concatenated into one stacked vector
and classiﬁed. The proposed approach is different from approaches in – , where the authors had extracted spatial
information and used composite kernel to include both type
of information. Here, feature extraction algorithms are used to
select informative feature from the spectral and spatial domain.
For the multisource classiﬁcation, Support Vector Machines
(SVM) are used rather than a Neural Network, which was
used in our previous experiment with MP/EMP. The superiority
of SVM, implementing structural risk minimization, over the
neural classiﬁers, implementing empirical risk minimization, has
been discussed in (in Chapters 9.6 and 12) and in ,
 . SVM aim to discriminate two classes by ﬁtting an optimal
separating hyperplane to the training data within a multidimensional feature space, by using only the closest training
samples. Thus, the approach only considers samples close to
the class boundary and works well with small training set,
even when high dimensional data sets are classiﬁed. SVM have
already been applied for multisource classiﬁcation in where
several output coding methods were investigated.
In this paper, the proposed approach has been compared
to statistical classiﬁcation methods and SVM classiﬁcation.
Experiments were conducted on two different high resolution
remote sensing data sets from urban areas. The effectiveness of
the proposed methodology with a limited training set has been
also assessed.
The paper is organized as follows. Section II reviews the
use of morphological transformations for processing of hyperspectral imagery in urban areas. In Section III, the considered
supervised feature extraction approaches are introduced. Support Vectors Machines (SVM) are discussed in Section IV.
The applied data fusion schemes are discussed in Section V.
Experimental results obtained on two ROSIS data sets from
urban areas are presented in Section VI. Finally, conclusions
are drawn in Section VII.
SPECTRAL AND SPATIAL DATA PROPERTIES. ’ր’ INDICATES A GOOD
PROPERTY, ’∼’ INDICATES THAT THE PROPERTY MIGHT BE HARMFUL AND
’ց’ INDICATES A CRITICAL PROPERTY.
Spectral features
Morphological features
Fine physical description
Geometrical information
Directly accessible
Needs to be extracted
Redundancy
Redundancy
No spatial information
Reduced spectral information
II. EXTENDED MORPHOLOGICAL PROFILE
Mathematical Morphology is a theory aiming to analyze spatial relationship between pixels. For a remote sensing application, several morphological operators are available for extracting
geometrical information. An overview of operators can be found
in . In the following sub-section, some basic notions of
mathematical morphology are reviewed. Then, the concept of
the Morphological Proﬁle and its extension to multivalued data
are detailed.
A. Mathematical Morphology
The two fundamental operators in mathematical morphology
are erosion and dilation . These operators are applied to an
image with a set of known shape, called a structuring element
(SE). To erode an image consists of ﬁnding where the SE ﬁts the
objects in the image. The dilation, which is dual to the erosion,
shows where the SE hits the objects.
Opening and closing are combinations of erosion and dilation.
These operators remove from an original image structures of
size less than the SE. But they also modify structures which are
still present in the image after the opening/closing. Thus, they
can introduce fake objects in the image. To avoid this problem,
geodesic morphology and reconstruction should be used .
Opening and closing by reconstructions are connected operators
that satisfy the following assertion: If the structure of the image
cannot contain the SE, then it is totally removed, else it is totally
preserved. For a given SE, geodesic opening or geodesic closing
allows to know the size or shape of some objects present in the
image: The objects that are smaller than the SE are deleted
while the other (that are bigger than the SE) are preserved. To
determine the shape or size of all elements present in an image,
it is necessary to use a range of different SE sizes. This concept
is called Granulometry.
Granulometries are typically used for the analysis of the size
distribution of the structures in the images. Classical granulometry by opening is built by successive opening operations
with an SE of an increasing size. By doing so, the image
is progressively simpliﬁed. Using connected operators, like
opening by reconstruction, no shape noise is introduced.
Morphological Proﬁles (MPs) are deﬁned using the granulometry. An MP is composed of the opening proﬁle (OP) and
the closing proﬁle (CP). The OP at the pixel x of the image I
is deﬁned as an n-dimensional vector:
OPi(x) = γ(i)
R (x), ∀i ∈[0, n]
where γ(i)
is the opening by reconstruction with an SE of a
size i and n is the total number of openings. Also, the CP at
Simple morphological proﬁle with two opening and two closings. In
the shown proﬁle, circular structuring elements are used with radius increment
4 (r = 4, 8 pixels). The processed image is a part of Fig. 4.(a).
the pixel x of image I is deﬁned as an n-dimensional vector:
CPi(x) = φ(i)
R (x), ∀i ∈[0, n]
where φ(i)
R is the closing by reconstruction with an SE of a size
i. Clearly we have CP0(x) = OP0(x) = I(x). By collating
the OP and the CP, the MP of image I is deﬁned as 2n + 1dimensional vector:
MP(x) = {CPn(x), . . . , I(x), . . . , OPn(x)}
Example of MP is shown in Fig.1. Thus, from a single image
results a multiband image, whose dimension corresponds to
the number of transformations and spatial information is now
contained in the MP for each pixel. However, an MP is built with
only one band. Therefore, the spectral information is lost. One
approach to deal with this problem is to extract several images
that contain some parts of the spectral information and then
build the MP on each of the individual images. This approach,
namely the Extended Morphological Proﬁle (EMP), is discussed
in the following.
B. Extended Morphological Proﬁle
In order to apply this approach to hyperspectral data, characteristic images need to be extracted. In , it was suggested
to use several principal components of the hyperspectral data
for such a purpose. Hence, the MP is applied on the ﬁrst PCs,
corresponding to a certain amount of the cumulative variance
and a stacked vector is built with the MP on each PC. This
yields to the extended morphological proﬁle (EMP). Following
the previous notation, the EMP is an m(2n + 1)-dimensional
MPext(x) = {MPP C1(x), . . . , MPP Cm}
where m is the number of retaining PCs. Example of EMP is
shown in Fig. 2.
As with multispectral data, the MP/EMP may include some
redundancy. Classical feature reduction algorithm can be applied, as detailed in the following section.
III. SUPERVISED FEATURE EXTRACTION
Feature extraction can be viewed as ﬁnding a set of vectors
that represents an observation while reducing the dimensionality.
In pattern recognition, it is desirable to extract features that are
focused on discriminating between classes of interest. Although
a reduction in dimensionality is desirable, the error increment
due to the reduction in dimension has to be without sacriﬁcing the discriminative power of classiﬁers. In linear feature
extraction, the number of input dimensions corresponds to the
number of selected eigenvectors . The transformed data are
determined by
where Φ is the transformation matrix composed of the eigenvectors of the feature matrix, x is the data in the input space
and x is the transformed data in the feature space. We have
in general dim(x) ≥dim(x). Several statistical extraction
approaches have been proposed for remote sensing data ,
including Decision Boundary Feature Extraction (DBFE) and
Nonparametric Weighted Feature Extraction (NWFE).
A. Decision Boundary Feature Extraction
It was shown in , that both discriminantly informative features and redundant features can be extracted from the decision
boundary between two classes. The features are extracted from
the decision boundary feature matrix (DBFM). The eigenvectors
of the DBFM corresponding to non-zero eigenvalues are the
necessary feature vectors to achieve the same classiﬁcation
accuracy as in the original space. The efﬁciency of the DBFE is
related to the training set and can be computationally intensive.
B. Nonparametric Weighted Feature Extraction
To overcome the limitations of the DBFE, Kuo and Landgrebe proposed the nonparametric weighted feature extraction. NWFE is based on the Discriminant Analysis Feature
Extraction by focusing on samples near the eventual decision
boundary. The main ideas of the NWFE are 1) putting different
weights on every sample to compute the local means and 2)
deﬁning nonparametric between-class and within-class scatter
matrices .
Many experiments have shown the effectiveness of these
approaches for the classiﬁcation of hyperspectral data . They
are usually applied on the spectral data, but it was successfully
applied to the EMP .
IV. CLASSIFICATION BY THE SUPPORT VECTOR MACHINE
So far, in our previous approach , , , the classiﬁcation was done with either a statistical classiﬁer (Gaussian
Maximum Likelihood), a neural network or a fuzzy classiﬁer.
Here it is proposed to use the Support Vector Machines (SVM).
Early work in classiﬁcation of remotely sensed images by SVM
showed excellent results , , . In , several SVMbased classiﬁers were compared to other classical classiﬁers
such as a K-nearest neighbors classiﬁer and a neural network
classiﬁer and the SVM using the kernel method outperformed
the other classiﬁers in terms of accuracy. Multiclass SVM
performances were also positively compared with a discriminant
analysis classiﬁer, a decision tree classiﬁer and a feedforward
neural network classiﬁer with a limited training set . SVM
show good results in the situation of limited training set in .
Semisupervised SVM were also investigated for multi-spectral
data classiﬁcation , .
SVM are surely among the most used kernel learning algorithm. It performs robust non-linear classiﬁcation of samples
using the kernel trick. The idea is to ﬁnd a separating hyperplane
Extended morphological proﬁle of two images. Each of the original proﬁle has two openings and two closings. Circular structuring element with radius
increment 4 was used (r = 4, 8). The processed image is a part of Fig. 4.(a).
in some feature space induced by the kernel function while
all the computations are done in the orignal space . A
good introduction to SVM for pattern recognition can be found
in . Given a training set S = {(x1, y1), . . . , (xℓ, yℓ)} ∈
Rn × {−1; 1}, the decision function is found by solving the
convex optimization problem:
αiαjyiyjk(xi, xj)
subject to
0 ≤αi ≤C and Pℓ
i=1 αiyi = 0
where α are the Lagrange coefﬁcients, C a constant that is used
to penalize the training errors, and k the kernel function. To
be an acceptable kernel, k should be a positive semi-deﬁnite
function . One classical effective kernel is the Gaussian
kσ(xi, xj) = exp
−∥xi −xj∥2
where the norm is the Euclidean-norm and σ ∈R+ tunes
the ﬂexibility of the kernel. A short comparison of kernels for
remotely sensed image classiﬁcation can be found in .
When the optimal solution of (6) is found, i.e., the αi, the
classiﬁcation of a sample x is achieved by looking to which
side of the hyperplane it belongs:
αiyik(xi, x) + b
To deal with multiclass classiﬁcation problem, the pairwise
approach was used in our experiments . More advanced
multiclass approaches applied to remote sensing data can be
found in . For the particular case of one-class-classiﬁcation,
a dedicated methodology is proposed in .
The SVM are mainly a non-parametric method, yet some
parameters need to be tuned before the optimization. In the
Gaussian kernel case, there are two parameters: C, the penalty
term, and σ, the with of the exponential. It is usually done by
a cross-validation step, where several values are tested. In our
experiments, C was ﬁxed to 200 and σ2 ∈{0.5, 1, 2, 4} was
selected using a 5-fold cross validation. The SVM optimization
problem was solved using the LIBSVM .
V. DATA FUSION
The proposed method is based on the data fusion of the
morphological information and the original data. In a previous
work , it was proposed to fuse the classiﬁcation results of
two SVM classiﬁers, each one working with either the spectral
or the EMP data. It consisted in an appropriate adaptive fusion
Proposed data fusion scheme.
scheme based on the output’s characteristics of the SVM. The
results in terms of accuracy were increased but it needed two
training of SVM, that could be time consuming.
Here it is proposed to use a multisource strategy to fuse
spectral and spatial information. First, an EMP is created based
on applying the PCA on the hyperspectral data. Secondly,
feature extraction is applied on both the EMP and the original
hyperspectral data. Finally, the extracted feature vectors are
concatenated into one stacked vector and classiﬁed by the SVM.
In the morphological processing we usually retain PCs corresponding to 99% of the cumulative variance. This is done in
order to reduce the redundancy in the data but keep most of the
variation. The EMP is built using the m PCs that correspond
to the 99% variance. Each MP is composed of n geodesic
openings, n geodesic closing and the corresponding PC. The
SE is a disk with initial radius of r pixels. The size increment
is s. Hence, each MP has 2n + 1 features and the EMP has
m(2n + 1) features. Noting xϕ the features associated to the
spectral bands and xω the features associated to the EMP, the
corresponding extracted features from the FE algorithm are:
The stack vector is ﬁnally x = [xϕ, xω]T .
Fig. 3 presents the data fusion scheme. Note that in this work,
only morphological information is extracted, but it is possible to
extract other types of spatial information with other processing
and include them in the stacked vector.
VI. EXPERIMENTS
A. Data set
Airborne data from the ROSIS-03 (Reﬂective Optics System
Imaging Spectrometer) optical sensor are used for the experiments. The ﬂight over the city of Pavia, Italy, was operated
by the Deutschen Zentrum fur Luft- und Raumfahrt (DLR, the
German Aerospace Agency) in the framework of the HySens
project, managed and sponsored by the European Union. According to speciﬁcations, the number of bands of the ROSIS-03
sensor is 115 with a spectral coverage ranging from 0.43 to
INFORMATION CLASSES AND TRAINING-TEST SAMPLES FOR THE
UNIVERSITY AREA DATA SET.
Metal Sheets
INFORMATION CLASSES AND TRAINING-TEST SAMPLES FOR THE PAVIA
CENTER DATA SET.
0.86µm. The data have been atmospherically corrected but not
geometrically corrected. The spatial resolution is 1.3m per pixel.
Two data sets were used in the experiment:
1) University Area: The ﬁrst test set is around the Engineering School at the University of Pavia. It is 610 by
340 pixels. Some channels (twelve) have been removed
due to noise. The remaining 103 spectral dimensions
are processed. Nine classes of interest are considered,
i.e., trees, asphalt, bitumen, gravel, metal sheets, shadow,
bricks, meadows and soil.
2) Pavia Center: The second test set is the center of Pavia.
The Pavia center image was originally 1096 by 1096
pixels. A 381 pixel wide black stripe in the left part of
image was removed, resulting in a “two parts” image. This
“two parts” image is 1096 by 715 pixels. Some channels
(thirteen) have been removed due to noise. The remaining
102 spectral dimensions are processed. Nine classes of
interest are considered, i.e., water, trees, meadows, bricks,
soil, asphalt, bitumen, tiles and shadows.
Available training and testing set for each data set are given in
Table II and III and Fig. 4 presents false colors images for both
The classiﬁcation accuracy was assessed with:
• An overall accuracy(OA) which is the number of well
classiﬁed samples divided by the number of test’s samples
• An average accuracy (AA) which represents the average of
class classiﬁcation accuracy
• A kappa coefﬁcient of agreement (κ) which is the percent-
ROSIS data: (a) University Area, (b) Pavia Center. Three-channel
color composite of the areas used for the classiﬁcation. Data characteristics are
detailed in Sub-Sections VI-B and VI-C.
age of agreement corrected by the amount of agreement
that could be expected due to chance alone .
These criteria were used to compare classiﬁcation results and
were computed using the confusion matrix. Furthermore, the
statistical signiﬁcance of differences was computed using Mc-
Nemar’s test, which is based upon the standardized normal test
statistic :
√f12 + f21
where f12 indicates the number of samples classiﬁed correctly
by classiﬁer 1 and incorrectly by classiﬁer 2. The difference in
accuracy between classiﬁers 1 and 2 is said to be statistically
signiﬁcant if |Z| > 1.96. The sign of Z indicates whether
classiﬁer 1 is more accurate than classiﬁer 2 (Z > 0) or viceversa (Z < 0). This test assumes related testing samples and
thus is adapted to our situation since the training and testing set
were the same for each experiment.
The feature extractions were done with MultiSpec c⃝ while
the morphological operations were done with the Image Processing Toolbox of Matlab c⃝. The SVM classiﬁcation was done
using the LIBSVM through its Matlab c⃝interface . From
previous experiments on the same data set, the Gaussian kernel
provides the best results and was used for the experiments .
The range of each feature, be it spectral or morphological, was
stretched between 0 and 1.
To obtain a baseline result for comparison, the classiﬁcation
was also done using the Gaussian Maximum Likelihood (ML)
classiﬁer on the hyperspectral data using MultiSpec c⃝1. Feature
extraction was done using the two FE algorithms (DBFE and
NWFE) but only the best results have been reported for both
data sets. The results were compared to those obtained by the
proposed approach.
1For the ML, the kappa coefﬁcient was not accessible.
UNIVERSITY AREA. EIGENVALUES OF PRINCIPAL COMPONENTS IN
PERCENTAGE.
Cumulative Val.
B. University Area data set
PCs were computed from the hyperspectral data. The results
for the eigenvalues are shown in Table IV. The left column gives
the component number, the center column the eigenvalues in
percentage of the total amount of variance and the right column
the cumulative amount of variance. From the table, three PCs
were necessary to retain 99% of the variance criterion. EMPs
were built according to the scheme presented in the Section V:
A circular SE with a step size increment of 2 was used. Four
openings and closings were computed for each PC, resulting in
an EMP of dimension 27.
First, the classiﬁcation with SVM was done using the spectral
information and the extended morphological proﬁle. The best
ML accuracy was obtained using 8 features extracted with the
NWFE, following Landgrebe’s recommendations in . The
results are reported in Table V. Regarding the global accuracies,
both SVM approaches perform equally well, for instance the
difference between the classiﬁcation using the spectral information and the EMP is not statistically signiﬁcant, see Table VI.
Note that it is consistent with the characteristics of the scene:
The University Area is a mix between man-made structures and
natural materials. Therefore, the morphological information is
not as useful as it could be in a very dense urban area. When
a careful analysis is done on the class-speciﬁc accuracies, we
can see from Table V that each approach performed well for
complementary classes, e.g. the spectral approach performed
better for classes 3, 6, 9 while the EMP approach performed
better for classes 1, 2, 7, 8. After the data fusion we have to
look at these classes and see if the best information was used,
i.e., if the classiﬁcation accuracy increased for these classes.
The experiment was then performed with the concatenated
vector. The vector was made of the 103 spectral bands and the
27 features of the EMP. The vector was directly used as an input
to the SVM. The classiﬁcation results are reported in Table V.
As can be seen from the table, the global accuracies increased.
The κ value in percentage is 79.13% against 74.47% for the
spectral approach and 73.25% for the EMP and the differences
are statistically signiﬁcant (see Table VI). Regarding the classspeciﬁc accuracies, the results in terms of accuracies have
increased for classes 1, 7, 8 when compared to both individual
approaches. In fact all the classes are more accurately classiﬁed
than the worst respective cases for the individual approaches.
In the last experiment, feature reduction was applied on the
morphological data and the original data before the concatenation. Then the stacked vector was classiﬁed by the SVM.
Table VII summarizes the test accuracies for several values of
the variance criterion for the DBFE and NWFE. Best results
were obtained with 95% and 80% variance criterion for the
UNIVERSITY AREA. GLOBAL ACCURACIES IN PERCENTAGE WITH
DIFFERENT FEATURE EXTRACTION METHODS. THE NUMBERS OF FEATURES
FROM THE SPECTRAL DATA AND THE MORPHOLOGICAL DATA,
RESPECTIVELY, ARE GIVEN IN BRACKETS.
Feature extraction
60 (45,15)
27 (27,10)
62 (42,20)
28 (16,12)
DBFE and NWFE, respectively. Using 95% of the variance
criterion with DBFE, the hyperspectral data were reduced to
27 features and the EMP to 10 features. With NWFE and 80%,
7 features were extracted from the hyperspectral data and 6 from
the EMP. Again, as can be seen in Table VI, differences between
the classiﬁcation accuracies are statistically signiﬁcant.
Considering the class-speciﬁc accuracies, the DBFE approach
improved the classiﬁcation for class 2 while class 3 was less accurately classiﬁed than with the concatenated full hyperspectral
data and EMP. However, the DBFE outperformed the individual
classiﬁcations of the spatial or spectral information. On this
data set, the classiﬁcation of the DBFE feature extracted data
gave the best classiﬁcation results. Similar comments can be
made for the accuracies obtained with classiﬁcations of the
NWFE. Still, the number of features needed to achieve the
same accuracy is signiﬁcantly lower for the NWFE approach
than for the DBFE. Since the SVM is linearly related to the
dimensionality of the data, lower dimensional data reduced the
training time and increased the speed of the classiﬁcation.
To assess this increase, comparison of the processing time
(training and classiﬁcation process) for the different approaches
was made. Table VIII summarizes the results, which are clearly
different according to the features used. The training time could
depend on several factors:
1) The dimension of the data;
2) The size of the training set;
3) The number of parameters for the kernel.
For our given problem, items 2) and 3) are the same. Reducing
the size of the data is beneﬁcial for the processing time, since
data with lower dimensionality (EMP and NWFE) have the
shortest processing time. For the best case (NWFE), the gain is
about 73%.
For the classiﬁcation processing time, two factors have an
inﬂuence: The dimension of the data and the number of support
vectors (non-zero αi in (8)). Thus, approaches with low dimensionality and few support vectors perform the classiﬁcation
task of the whole image faster (EMP and NWFE). Nevertheless,
the classiﬁcation processing is really fast by comparison to the
training time, in all the cases.
Classiﬁcation maps for the different approaches are shown in
UNIVERSITY AREA. SUMMARY OF THE GLOBAL AND THE CLASS-SPECIFIC TEST ACCURACIES IN PERCENTAGE FOR THE CLASSIFICATION. THE NUMBERS
OF FEATURES FROM THE SPECTRAL DATA AND THE MORPHOLOGICAL DATA, RESPECTIVELY, ARE GIVEN IN BRACKETS.
37 (27,10)
UNIVERSITY AREA. STATISTICAL SIGNIFICANCE OF DIFFERENCES IN CLASSIFICATION ACCURACIES.
EMP/Spectral
Spectral/Spec. EMP
Spectral/DBFE 95%
Spectral/NWFE 80%
Spec. EMP/DBFE 95%
Spec. EMP/NWFE 80%
DBFE 95%/NWFE 80%
TABLE VIII
UNIVERSITY AREA. PROCESSING TIME IN SECONDS AS FUNCTION OF DIMENSIONALITY AND NUMBER OF SUPPORT VECTORS.
Number of SVs
Classiﬁcation
University Area: Classiﬁcation map obtained with SVM from: (a) the original hyperspectral data, (b) the EMP, (c) 37 DBFE features and (d) 13 NWFE
features. Classiﬁcation accuracies are reported in the Table V.
C. Pavia Center data set
For the second test, the scene is a very dense urban area in
the center of the city of Pavia. Because of that, morphological
information should be useful for the discrimination. PCs were
computed from the hyperspectral data. The results for the
eigenvalues are shown in Table IX. From the Table, three PCs
were necessary to retain 99% of the variance criterion. The EMP
was built according to the scheme presented in the section V:
A circular SE with a step size increment of 2 was used. Four
openings and closings were computed for each PC, resulting in
PAVIA CENTER. EIGENVALUES OF PRINCIPAL COMPONENTS IN
PERCENTAGE.
Cumulative Val.
an EMP of dimension 27.
SVM classiﬁcation was applied to the original hyperspectral
data and the EMP. The best ML accuracy was obtained using 29
features extracted with the DBFE. The results are reported in
Table X. From the Table, it can be seen that SVM classiﬁer
achieved excellent global accuracies. In these experiments,
the morphological approach performs better than the spectral
based approach. Table XI shows the statistical signiﬁcance of
differences between the classiﬁcation accuracies for the different
approaches. This is consistent with the characteristics of the picture: it is a very dense urban area and morphological processing
provides discriminative information. In terms of accuracies, the
main improvement in the classiﬁcation is achieved for class 4.
The other classes are classiﬁed equally accurately. The data
fusion should thus improve the classiﬁcation of class 4 while
preserving very good results for the others classes.
Next, the experiment was performed using the concatened
vector. The vector was made of the 102 spectral bands and the
27 features of the EMP. This vector was used as an input for
the SVM without any additional processing. The classiﬁcation
results are reported in Table X. The differences of classiﬁcation
accuracies between the EMP and the concatened vector are not
statistically signiﬁcant, since the McNemar’s test is almost equal
to zero, see Table XI. Thus, both EMP and concatened vector
perform equally well.
As in the previous experiment, feature reduction was applied
both on the morphological data and on the original data before
the concatenation. Then, the stacked vector was classiﬁed by
the SVM. Table XII summarizes the test accuracies for several
values for the variance criterion for the DBFE and NWFE. The
best results are obtained with 99% variance criterion for both
DBFE and NWFE. Using 99% of the variance with the DBFE,
the hyperspectral data is reduced to 51 features and the EMP is
reduced to 15 features. With the NWFE and 99% of the variance
criterion, 44 features were extracted from the hyperspectral data
and 20 from the EMP. The results are given in Table X.
For this experiment, the DBFE does not help for the classiﬁcation since the Z test is not signiﬁcant. On the other
hand, similar classiﬁcation accuracy is reached with far less
features, nearly half the size of the previous feature set, thus
decreasing the total training and classiﬁcation time. The NWFE
leads to a signiﬁcant increase of the classiﬁcation accuracies,
|Z|= 7.75 by comparison to the best results obtained with
the concatenation vector, which is contrary to the previous
experiment. Classiﬁcation maps for the different approaches are
shown in Fig. 6. Visually, the thematic map produced with the
classiﬁcation of the NWFE features seems less noisy than the
one obtained with the classiﬁcation of the DBFE features. This
is especially true in the top-left corner which correspond to a
PAVIA CENTER. GLOBAL ACCURACIES IN PERCENTAGE WITH DIFFERENT
FEATURE EXTRACTION METHODS. THE NUMBERS OF FEATURES FROM THE
SPECTRAL DATA AND THE MORPHOLOGICAL DATA, RESPECTIVELY, ARE
GIVEN IN BRACKETS.
Feature extraction
66 (51,15)
41 (31,10)
66 (44,20)
31 (19,12)
UNIVERSITY AREA. SUMMARY OF THE GLOBAL TEST ACCURACIES IN
PERCENTAGE FOR SVM CLASSIFICATION USING A LIMITED TRAINING
SET.THE NUMBERS IN BRACKETS ARE THE NUMBERS OF FEATURES FROM
THE SPECTRAL DATA AND FROM THE MORPHOLOGICAL DATA,
RESPECTIVELY.
66 (44,12)
53 (35,18)
25 (14,11)
very dense urban area.
Regarding the computing time, the results for the training and
the classiﬁcation are reported in Table XIII. As expected, using
feature extraction methods reduces the processing time for both
the training and the classiﬁcation.
Classiﬁcation maps for the different approaches are shown in
D. Small training set experiment: University Area
To assess the effectiveness of the proposed methodology for a
limited training set, we have randomly extracted a few training
samples from the training set. For this experiment, we used
20 samples for each class, which represents less than 5% of
the original training set. We have used the same EMP but had
some problems with the DBFE, the covariance matrix was noninvertible (the NWFE does not suffer from this problem). In
order to overcome this shortcoming and to apply the DBFE
anyway, we use the leave on out covariance (LOOC) to estimate
the covariance matrix and perform a statistical enhancement
with unlabeled samples, both algorithms were implemented in
the MultiSpec c⃝software , . We have repeated the
training samples selection and the classiﬁcation process ﬁve
times, and the mean classiﬁcation results are reported in the
PAVIA CENTER. SUMMARY OF THE GLOBAL AND THE CLASS-SPECIFIC TEST ACCURACIES IN PERCENTAGE FOR SVM CLASSIFICATION. THE NUMBERS OF
FEATURES FROM THE SPECTRAL DATA AND THE MORPHOLOGICAL DATA, RESPECTIVELY, ARE GIVEN IN BRACKETS.
66 (51,15)
64 (44,20)
PAVIA CENTER. STATISTICAL SIGNIFICANCE OF DIFFERENCES IN CLASSIFICATION ACCURACIES.
EMP/Spectral
EMP/Spec. EMP
EMP/DBFE 99%
EMP/NWFE 99%
Spec. EMP/DBFE 95%
Spec. EMP/NWFE 80%
DBFE 95%/NWFE 80%
TABLE XIII
PAVIA CENTER. PROCESSING TIME IN SECONDS AS FUNCTION OF DIMENSIONALITY AND NUMBER OF SUPPORT VECTORS.
Training (s)
Number of SVs
Classiﬁcation (s)
Pavia Center: Classiﬁcation map obtained with SVM from: (a) the original hyperspectral data, (b) the EMP, (c) 66 DBFE features and (d) 64 NWFE
features. Classiﬁcation accuracies are reported in the Table X.
As with the previous experiments, we perform the classiﬁcation using the spectral or the morphological feature with SVM.
The ML produced very poor results, simply close to random
classiﬁcation and hence not reported. The global accuracies are
reported in Table XIV. Statistical signiﬁcance of differences is
reported in Table XV.
First of all, the test results are lower than those in Table V
and VII, due to the limited training set. For instance, with the
concatened feature vector, the overall accuracy and the κ are
respectively, 83.53% and 79.13% for the original training set
while using a limited training set, the overall accuracy and the
κ are respectively, 75.35% and 68.66%. Nevertheless, with a
very small training set, the results are still good.
For the feature extraction, NWFE with 99% of the cumulative
variance provides the best results: The obtained overall accuracy
is 85.42% and the κ is 80.87%, which is closed to the best
results obtained with the full training set (OA=97.87% and κ
= 84.40%, see Table V). The |Z| between the best results with
limited training and the best results with full training set is equal
Furthermore, the accuracies are better than those obtained
with the full training set with the spectral or morphological
information alone. It is also important to note that NWFE
outperforms better DBFE without any statistical enhancement.
Considering the processing time, with only 20 samples for
each class, the training as well as the classiﬁcation of the entire
data set are done in 1 or 2 seconds.
VII. CONCLUSION
Classiﬁcation of hyperspectral data with a ﬁne spatial resolution has been investigated. The contribution of this work is a
methodology to include both spatial and spectral information in
the classiﬁcation process by a data fusion scheme. Experimental
results on two ROSIS data sets showed excellent accuracies
and improvements compared to those obtained with pixel-based
classiﬁers and the EMP-based classiﬁer.
The use of feature extraction was motivated by the fact that
the full stacked vector contains a lot of redundancy, because
there is a redundancy in the hyperspectral data as well as
in the EMP , which was conﬁrmed by the experiments. On
the other hand, SVM are known to be robust to dimensionality.
Therefore, the use of feature reduction for SVM could be
disputable. However, in the experiments lower dimensional data
decreased the processing time, which can be crucial for some
applications, and more important it has been showed that SVM
can suffer from the dimensionality when many features are
irrelevant . By construction, the stacked vector may contain
many copies of the same information and a feature extraction
step may ﬁnally be needed to ensure correct classiﬁcation
on every data set, which is conﬁrmed by the experiments
(Usefulness of features reduction for the classiﬁcation of remote
sensing data with SVM was also assessed in ).
It is clear that feature extraction helps for the classiﬁcation
of hyperspectral data but it is not clear which one of the
feature extraction methods should be used for the fusion of
morphological and spectral features. From a theoretical point
of view, the NWFE was derived because of some intrinsic
problems with the DBFE , i.e., ”DBFE can involve lengthly
calculations and more signiﬁcantly it does not perform as well
for small numbers of training samples”. Hence, the NWFE
might be more preferable, especially when a small training set
is available. The experiments performed with a limited training
set conﬁrmed that.
In conclusion, the proposed fusion method succeed in taking
advantage of the spatial and the spectral information simultaneously. It outperformed previous results , . Our current
research is oriented to the deﬁnition of additional spatial features, such as textural characteristics , to be include in the
feature vectors.
ACKNOWLEDGMENT
The authors appreciate the contributions of Mr. Jon Aevar
Palmason to this research. Furthermore, the authors would like
to thank the IAPR - TC7 for providing the data and Prof. Paolo
Gamba and Prof. Fabio Dell’Acqua of the University of Pavia,
Italy, for providing reference data. The authors also thank the
reviewers for their many helpful comments. This research was
supported in part by the Research Fund of the University of
Iceland and the Jules Verne Program of the French and Icelandic
governments (PAI EGIDE).