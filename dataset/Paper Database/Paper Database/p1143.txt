University of California, Berkeley
U.C. Berkeley Division of Biostatistics Working Paper Series
Causal Inference in Epidemiological Studies
with Strong Confounding
Kelly L. Moore∗
Romain S. Neugebauer†
Mark J. van der Laan‡
Ira B. Tager∗∗
∗Division of Biostatistics, School of Public Health, University of California, Berkeley, 
†Division of Research,
Kaiser Permanente Northern California,
CA, 
‡Division of Biostatistics, School of Public Health, University of California, Berkeley,
 
∗∗Division of Epidemiology, School of Public Health, University of California, Berkeley,
 
This working paper is hosted by The Berkeley Electronic Press (bepress) and may not be commercially reproduced without the permission of the copyright holder.
 
Copyright c⃝2009 by the authors.
Causal Inference in Epidemiological Studies
with Strong Confounding
Kelly L. Moore, Romain S. Neugebauer, Mark J. van der Laan, and Ira B. Tager
One of the identiﬁabilty assumptions of causal effects deﬁned by marginal structural model (MSM) parameters is the experimental treatment assignment (ETA)
assumption. Practical violations of this assumption frequently occur in data analysis, when certain exposures are rarely observed within some strata of the population. The inverse probability of treatment weighted (IPTW) estimator is particularly sensitive to violations of this assumption, however, we demonstrate that
this is a problem for all estimators of causal effects. This is due to the fact that
the ETA assumption is about information (or lack thereof) in the data. A new
class of causal models, causal models for realistic individualized exposure rules
(CMRIER), introduced in van der Laan and Petersen , is based on dynamic
interventions. CMRIER generalize MSM, and their parameters remain fully identiﬁable from the observed data, even when the ETA assumption is violated, if the
dynamic interventions are set to be realistic. Examples of such realistic interventions are provided. We argue that causal effects deﬁned by CMRIER may be
more appropriate in many situations, particularly those with policy considerations.
Through simulation studies, we examine the performance of the IPTW estimator
of the CMRIER parameters in contrast to that of the MSM parameters. We also
apply the methodology to a real data analysis in air pollution epidemiology to
illustrate the interpretation of the causal effects deﬁned by CMRIER.
Introduction
Marginal structural models (MSM) were introduced in Robins as a class of causal
models for the investigation of the eﬀect of a treatment or exposure on an outcome. They
can be applied in air pollution epidemiology for the investigation of the eﬀect of exposure
to air pollutants on health outcomes, particularly in those studies whose results are likely
to have policy relevance. More speciﬁcally in that context, they represent the distribution
of potential outcomes that are deﬁned based on air pollution interventions that result in
identical pollutant levels experienced by all experimental units in the target population. We
refer to such interventions as static interventions to compare them to dynamic interventions,
which may not result necessarily in identical pollutant levels for all experimental units.
Ideally, ﬁtting an MSM requires the design of an experiment where one could observe
for each unit its outcome under each possible exposure level. Such an experiment cannot be
conducted in practice and, instead, only one of the potential outcomes can be observed on
each unit in a real life experiment (e.g., randomized or observational study). This explains
why potential outcomes are also referred to as counterfactual outcomes. The hypothetical
data from the ideal experiment are referred to as full data. When the eﬀects of interest
are deﬁned by interventions on air pollution exposure at one point in time, the full data
are denoted by X = (W, (Ya : a ∈A)), where Ya represents the counterfactual outcome
that corresponds to pollutant level a; A represents the set of possible pollutant levels;
and W is a vector of covariates measured before the exposure. This is opposed to the
observed data from a real life experiment denoted by O = (W, A, Y ), where Y and A are
the outcome and pollutant level actually observed. Note that this counterfactual framework
and notation can easily be generalized to longitudinal data problems, where the eﬀects of
interest are deﬁned based on interventions on a history of pollutant levels. For clarity only,
the results presented in this paper are not illustrated with the more complex longitudinal
data structures.
MSM are models for the full data distribution. Speciﬁcally, MSM represent the aggregate eﬀects on the outcome Y caused by static interventions on the exposure A at
the population-level or possibly conditional on some baseline covariate(s) (denoted with
V ⊂W) that deﬁne population subgroups of interest. Typically, in practice, MSM are
models for E(Ya), i.e., the mean of the counterfactual outcomes Ya. The coeﬃcients of
such MSM can thus be interpreted causally as representing the average population-level
eﬀect of the exposure on the outcome.
If particular subgroups of the target population are of interest, then MSM are typically models for E(Ya | V ), i.e., the mean of
the counterfactual outcomes Ya for each population stratum deﬁned by V .
coeﬃcients of such MSM represent the average eﬀect of the exposure on the outcome
within each subgroup deﬁned by the baseline covariate(s) V , e.g., gender.
The general notation for an MSM in this paper is m(a, V | β) where β is the coeﬃcient (a.k.a
causal parameter of interest) for which investigators wish to draw inference. For instance,
m(a, V | β) = β0 + β1a + β2V + β3aV is a linear MSM that can be used with continuous
outcomes and m(a, V | β) = 1/(1+exp −((β0 + β1a + β2V + β3aV )) is a logistic MSM that
can be used with dichotomous outcomes.
The fundamental problem of causal inference and, thus, of MSM estimation is that the
ideal experiment cannot be implemented in practice; only a subset of the full data can be
Hosted by The Berkeley Electronic Press
collected in real life: the observed data. Therefore, causal inference based on MSM is a
missing data problem. This statement is reﬂected by the so-called consistency assumption
denoted with Y = YA, i.e., the actual outcome collected on any unit is one of the potential
outcomes for that unit contained in the full data. Based on this assumption, the observed
data O = (W, A, YA) indeed can be viewed as a missing data structure on the full data
X = (W, (Ya : a ∈A)), with the exposure A being the missingness variable.
In practice, proper causal inference must rely on identiﬁability assumptions, i.e., assumptions that guarantee that there is enough information contained in the observed data
to infer the MSM parameter deﬁned from the full data. Two such assumptions have been
emphasized ; Neugebauer and van der Laan ; van der Laan and Robins
 ) in the literature: the untestable sequential randomization assumption (SRA) and
the testable experimental treatment assignment (ETA) assumption.
The ﬁrst assumption also is known as the no unmeasured confounders assumption. It
ensures that a causal association between the exposure and the outcome can be disentangled
from any other potential “spurious” associations between the exposure and the outcome.
By deﬁnition, such “spurious” associations are not explained by the eﬀect of the exposure
on the outcome. The information that allow such disentanglement can be referred to as
measurements on confounders of the eﬀect of the exposure on the outcome. The SRA states
that the collection of baseline variables W contain all such confounders. Formally, the SRA
can be deﬁned based on the concept of the exposure mechanism. We denote the conditional
probability distribution of a discrete exposure A given the full data with g(a | X) ≡P(A =
a | X) and refer to it as the exposure mechanism. In our air pollution example, the SRA
states that the pollutant level, A, experienced by any unit is conditionally independent of
the unit’s full data, X, given the unit’s baseline characteristics, W: g(A | X) = g(A | W).
In words, the exposure to the pollutant, A, is randomized within strata deﬁned by the
potential confounders W of the target population.
The second assumption is also known as the positivity assumption. It requires that
there is suﬃcient information in the observed data to separate the eﬀect of the exposure
from the eﬀects of the aforementioned measured confounders by imposing that each subject
in the target population can experience all possible pollutant levels, A, no matter what
values that the confounders take. Formally, the ETA is deﬁned as,
a∈A g(a | W) > 0, a.e.
For example, consider the study described in Moore et al. , which aims to estimate
the causal eﬀect of ozone concentration on the proportion of asthma-related hospital discharges. In this study, geographical grids are the independent experimental units (rather
than the inhabitants in the grids). Suppose that no grids with average temperatures under
65 degrees are exposed to high ozone levels. Thus, the ozone level (above or below the
standard) is set deterministically based on the grid’s temperature. In such a situation, it is
impossible to fully disentangle the eﬀect of ozone exposure on the outcome from the eﬀect
of temperature in the target population without making additional untestable assumptions.
This limitation is due to the violation of the ETA assumption.
Scenarios such as the one just described are common occurrences that can result in
biased estimation of the MSM causal parameter, β. Four approaches to estimate MSM parameters have been proposed ; Robins and Rotnitzky ;
 
van der Laan and Robins ; van der Laan and Rubin ): the G-computation,
Inverse Probability of Treatment Weighted (IPTW), Augmented IPTW (A-IPTW), and
Targeted Maximum Likelihood (TMLE) estimators.
The IPTW estimator has been the most widely applied estimator of MSM parameters
in practice. When the ETA assumption is violated theoretically, the IPTW estimator is
inconsistent (i.e., biased in practice). When the ETA assumption is violated practically,
it suﬀers from important ﬁnite-sample bias and large variability. Intuitively, the IPTW
estimator can be viewed as a statistical tool that properly reweights the observations in
the observed data such that the resulting “ghost” data mimic the data that could have
been collected from a randomized trial where confounding of the exposure eﬀect on the
outcome does not exist ). If certain exposures in the observed data
never (or rarely) occurred for a subgroup deﬁned by certain characteristics (e.g., high
ozone concentration in grids with under-represented minorities), then, there is insuﬃcient
information to mimic the data that could have be obtained from a randomized trial, since
reweighting can only modify the distribution of observations that are observed at least once.
The poor ﬁnite-sample performance of the IPTW estimator has been demonstrated even in
the presence of practical ETA violations in Neugebauer and van der Laan , and also
in Wang et al. . In the latter reference, a diagnostic tool to evaluate the potential
bias in the IPTW estimator due to ETA violations is provided. These practical violations
occur commonly in observational studies where the investigator does not control exposure
assignment but can also occur in randomized trials due to chance only, particularly in the
circumstance when the sample size is small.
The G-computation, A-IPTW or TMLE estimators can consistently estimate the MSM
parameters even when the ETA assumption is violated in theory, and, with good ﬁnitesample performance when the ETA assumption is violated practically.
However, their
good properties in such scenarios depend heavily on artiﬁcial information from parametric
modeling assumptions instead of real information in the data ; Neugebauer ). Consider again the ozone study example where no grids with
average temperatures under 65 degrees are exposed to high ozone levels. To estimate the
eﬀect of ozone on the proportion of asthma-related hospital discharges, one could assume
a linear model in temperature and ozone. Extrapolation to the area of the curve that
corresponds with low temperature and high ozone based on the model ﬁt could then be
used. However, since there are no data in this area of the curve, the extrapolated estimates
rely entirely on the parametric modeling assumptions (i.e., the linear model one assumed
for the association between ozone and temperature with the proportion of asthma-related
hospital discharges). These parametric modeling assumptions cannot be tested from the
data, and; therefore, it is desirable not to rely on such assumptions in practice to avoid
drawing incorrect inferences and, in particular, to avoid over-conﬁdence in the inference
derived from these estimation procedures.
In the next section, we illustrate with a simulation study the diﬃculties in drawing
reliable causal inference with MSM when the ETA assumption is violated. Several ad hoc
methods have been proposed to overcome the poor practical performance of MSM estimation when the ETA assumption is violated. We discuss these approaches in section 3. Each
of these attempts maintain the same objective: to estimate the eﬀect of static interventions
on the exposure of interest. An ETA violation should be regarded as an indication that
Hosted by The Berkeley Electronic Press
there are insuﬃcient data available to support the proposed analysis(es); the proposed investigation is too ambitious and unrealistic at the time the study was conducted. In some
instances one may even regard the investigation of such interventions as irrelevant if such
interventions cannot be implemented with the current state of knowledge. For instance,
we could argue that it is not possible (with the current air pollution regulatory policies
in place or feasible in the future) to lower ambient ozone concentrations beyond a certain
threshold concentration, on high temperature days, in the face of extant concentrations of
transported pollutants. Thus, it would be irrelevant to investigate the eﬀect of low exposure to ozone when temperature is high under such circumstances. Instead, one could try
to answer a more realistic causal question that remains of interest, i.e., more realistic in
that the question can be addressed with the data at hand without the need for additional
and untestable parametric modeling assumptions. Such causal questions can be deﬁned
based on the concept of dynamic interventions on the exposure of interest that are deemed
“realistic”.
A class of causal models that generalize MSM has been developed independently by
van der Laan ) and Orellana L 
 ) and illustrated recently )
to investigate such “realistic” causal questions. In section 4, we review this class of models referred to as causal models for realistic individualized exposure rules (CMRIER) and
further illustrate their importance as they apply to air pollution epidemiology in section
5. Finally, we discuss the application of the results presented in this paper in section 6.
First, however, we provide a simulation study in section 2 that underscores the practical
limitations of causal inference with MSM but also with traditional regression methods in
air pollution problems with extreme confounding. The motivational example presented
in section 2 will be carried forward to illustrate the material presented in the subsequent
sections and in particular in section 3 where we review some ad hoc methods that have
been proposed to overcome the problem of practical or theoretical violation of the ETA
assumption.
Motivational Example
Speciﬁc aim
To illustrate the diﬃculties in drawing inference about causal eﬀects deﬁned with static
interventions when the ETA assumption is violated, we present the following example. In a
simulation study, we examine the eﬀect of a continuous exposure A on an outcome Y that
is confounded by a single confounder W1. The simulated data were constructed such that
the exposure level experienced by any unit is almost deterministically set by the confounder
level. The goal of the study is to illustrate the issues that arise in MSM estimation in the
presence of ETA violations.
In addition, we also illustrate the failure of traditional estimation approaches in this
setting. Traditionally, the causal eﬀect of an exposure A on an outcome Y is investigated
by regressing Y on A and the confounders, W, allowing for a ﬂexible adjustment for W
through model selection, e.g., squared and/or logarithmic functions of W. This traditional
approach relies on the correct speciﬁcation of the parametric model for E(Y | A, W). Note
 
that in practice, no interaction terms between the exposure A and confounders W typically
are considered in the model selection involved in this approach. Thus, in practice, the
accuracy of the derived causal inference often relies on the assumption that none of the
potential confounders W also are eﬀect modiﬁers, i.e., interactions between A and W indeed
can be omitted from the model for E(Y | A, W).
Furthermore, it is important to note that investigators often are not aware of the estimation challenge that is posed by violations of the ETA assumption whether the estimation approach adopted is based on a traditional regression model or an MSM with
G-computation estimation. This is in contrast to IPTW estimation of MSM parameters in
which the violations of the ETA assumption become apparent from the inﬂated variance
estimates due to extreme weighting (for more details see section 3.1.2). Through the simulation study presented in this section, we not only illustrate the poor practical performance
in estimating causal parameters with MSM but also with traditional regression models.
Simulation protocol
The simulated data were generated according to the following distributions:
• W4 = 0.6(W1 −20)/5 +
(1 −0.62) + ϵ1, ϵ1 ∼N(0, 10)
• W5 ∼U(0, 3)
• P(W6 = 0) = 0.5 and P(W6 = 1) = 0.5,
• A = W1 + ϵ2, ϵ2 ∼N(0, 5),
• Y = 4A + 5W1 + ϵ3, ϵ3 ∼N(0, 400),
where a) N(µ, Σ) represents the (multivariate) normal distribution with mean µ and standard error (matrix of variance-covariance) Σ, b) U(a, b) represents the uniform distribution
between a and b. We denote W = (W1, ..., W6). In this simulation, the true causal eﬀect
on Y from static interventions on A can thus be represented with the following MSM for
E(Ya): 100 + 4a. The above data generating distributions were used to simulate 25000
datasets for sample sizes ranging from 100 to 1000.
We denote with ρX,Z the correlation between X and Z. The simulation protocol just
described results in the following correlation structure between the baseline covariates:
• ρW1,W2 =
• ρW1,W3 =
• ρW1,W4 = 0.6
• ρW1,W5 = ρW1,W6 = 0
Hosted by The Berkeley Electronic Press
The simulated variable W1 is correlated with W4 and is moderately correlated with W2 and
W3. Similarly, W1 is relatively highly correlated with the exposure of interest A. Thus,
disentanglement of the eﬀect of A on Y from the potential eﬀects of W1 on Y is a diﬃcult
problem in this simulation study due to the relatively high correlation between W1 and some
of the potential confounders but also between W1 and A. We evaluated the performances
of the IPTW and G-computation estimator of the MSM parameters and contrasted them
to that of the traditional regression approach in this scenario.
Firstly, we applied the G-computation and IPTW estimators to ﬁt the MSM, m(a |
β) = β0 + β1a, where the true value of the causal parameter deﬁned by this MSM is
β = (β0, β1) = (100, 4).
• Implementation of the G-computation estimator is based on an estimate for E(Y |
A, W). The G-computation estimate is obtained from the estimate for E(Y | A, W)
by averaging out W through a second regression involving the MSM m were used to
derive three G-computation estimators. First, the estimate for E(Y | A, W) was
obtained with a stepwise (backward) model selection algorithm based on the Akaike
Information Criterion (AIC) (stepAIC routine in R). The base model in this procedure
is linear with a main term for A and all other potential confounders (W1, ..., W6).
Second, the same stepwise procedure was run without forcing A into the model. In
the case that A was not selected by the algorithm, the G-computation estimate was
thus 0. Third, the estimator for E(Y | A, W) was obtained by ﬁtting the correct
linear model for E(Y | A, W) known from the simulation protocol: α0 +α1A+α2W1.
Note that in practice this model is typically unknown.
• Implementation of the IPTW estimator is based on an estimate for the exposure
mechanism, g(A | W). In the simulation study, the estimate for g(A | W) was always
obtained based on the correctly speciﬁed model known from the simulation protocol:
N(γ0 + γ1W1, σ). For further details on IPTW estimation, see section 3.1.2.
Secondly, we applied a traditional regression approach to estimate the eﬀect of A on
Y . This approach relies on an estimator for E(Y | A, W). In the traditional approach, the
coeﬃcient for the main term of A is selected as the estimate of the eﬀect of A on Y . Thus, no
interaction terms between A and W can be considered when using this approach. If E(Y |
A, W) is estimated with a linear model with no interaction terms between A and W, then
the estimate of coeﬃcient in front of A in that model is always equal to the corresponding
G-computation estimate of the MSM slope parameter β1 based on this same estimate for
E(Y | A, W). For simplicity in demonstrating the results of this motivational simulation
example, no interaction terms with A were considered in the stepwise model selection for
E(Y | A, W). Thus, the traditional and G-computation estimates are equivalent in this
particular example. We note this equivalence does not hold generally.
Simulation results
The performance of the estimators is assessed based on two quantities: bias and mean
squared error (MSE). The bias is estimated by computing the diﬀerence between the average
 
of the 25000 estimates and the true value at each sample size. The bias as a percent of the
true value by sample size is provided in graph a) in Figure 1 for each estimator. We can
immediately observe from this plot that the bias of the IPTW estimates is the largest of
the four estimators across all sample sizes. Although less severe than the IPTW estimator,
the bias of the traditional estimator based on the stepwise estimate of E(Y | A, W) with
A forced into the model is 12.8% at sample size 1000. The positive bias is a result of the
correlation between A and W1. Disentangling their individual eﬀects on Y is diﬃcult and
thus the combined eﬀect of A and W1 is often attributed to A only when A is forced into
the model for E(Y | A, W). In contrast, the traditional estimator based on the stepwise
estimate of E(Y | A, W) without forcing A into the model is negatively biased. This is
a result of incorrectly ascribing the combined eﬀect of A and W1 on Y largely to W1. In
practice, when the eﬀect is entirely attributed to W1, one would incorrectly conclude that
there is no eﬀect of the exposure A on the outcome Y . Finally, the traditional estimator
(which is also the G-computation estimator) based on the correctly (in practice unknown)
speciﬁed E(Y | A, W) is consistent (bias ≈0%). We note the simulation was also run for a
sample size of 50000 to verify that all estimators converged (bias ≈0%), however we have
omitted those results for clarity of presentation.
The MSE can be decomposed as the sum of the squared bias of the given estimator
and its variance. Therefore, the MSE was computed by summation of the squared bias, as
explained above, and the sample variance of the 25000 estimates. For two estimators with
similar bias, we can obtain a sense of their relative variance by comparing the MSE. Graph
b) in Figure 1 provides the mean squared error (MSE) for the 25000 estimates for each of the
four estimators. The comparison of the IPTW and G-computation estimates with respect
to the MSE is striking. The relatively large MSE of the IPTW estimates is in part due
to its larger bias but can also be attributed to its large variability. The IPTW estimator’s
poor ﬁnite sample performance is due to practical ETA violations. Since the exposure is
assigned in a nearly deterministic fashion, for given values of W1, the estimated probabilities
of exposure are very low causing an inﬂation of the weights (see section 3.1.2 for details).
Clearly the inference drawn from the IPTW estimator in this simulation study is unreliable.
The MSE of the G-computation estimates based on the stepwise estimate of E(Y | A, W)
where A is forced into the model is comparable to the G-computation estimates based on
the correctly speciﬁed E(Y | A, W). Forcing A into the model for E(Y | A, W) results in
inﬂating the estimated eﬀect of A on Y as explained above. This results in only a small
amount of variability in that this inﬂated estimate is consistently estimated in the 25000
simulated datasets for each sample size. Thus, although this estimator is not variable,
it is nonetheless biased.
The G-computation estimator based on the stepwise selected
E(Y | A, W) without forcing A into the model is slightly more varible than the one the
forces A into the model. Although it converges to the truth more quickly, again for any
given dataset, the eﬀect can be entirely attributed to either A or W1 which results in a
more variable estimator.
This simulation study illustrates the severe limitation from which the IPTW estimator
suﬀers when the ETA assumption is violated. However, this issue is not exclusive to IPTW
estimation of the MSM parameters, as as evidenced by the results from the G-computation
and traditional estimation techniques. Even when the exposure is forced into the model,
the eﬀect estimator remains biased in ﬁnite sample sizes due to the fact that the data lack
Hosted by The Berkeley Electronic Press
information to enable identiﬁcation of the eﬀects of the exposure A versus confounders
W on the outcome Y . With the G-computation and traditional estimation methods, we
would often conclude incorrectly that there is no eﬀect of the exposure on the outcome
when the exposure is not forced into the model for E(Y | A, W). In addition, if we ran
this simulation with no eﬀect of A on Y , these overly optimistic estimators (with respect
to precision) could lead to false positive ﬁndings. Even though the IPTW estimator is also
biased, due to its high variability, the danger of incorrectly concluding that there is an
eﬀect is not as high. Thus, in practice none of these estimators are reliable to answer the
causal question of interest.
To overcome this issue, several methods have been proposed that we outline in section 3.
Each of these methods (where applicable) is illustrated by applying them to these simulated
data. We also apply the newly proposed CMRIER to an extension of these simulated data
in section 5.
 
Sample Size
STEPWISE FORCE A
(a) Consistency
Sample Size
STEPWISE FORCE A
Motivational Simulation Study:
Consistency and MSE of IPTW and Gcomputation Estimates. “CORRECT” is the G-computation estimator, and equivalently
in this simulation study the traditional estimator, when the model for E(Y |A, W) is
correctly speciﬁed; “STEPWISE” is the G-computation/traditional estimator when A is
not forced into the selected model for E(Y |A, W); “STEPWISE FORCE A” is the Gcomputation/traditional estimator when A is forced into the selected model for E(Y |A, W);
and “IPTW” is the IPTW estimator.
Hosted by The Berkeley Electronic Press
Causal eﬀect estimation with MSM when the ETA
assumption is violated
Several methods have been proposed to overcome the poor IPTW estimation performance
illustrated above when the ETA assumption is violated. In the following subsections, we
review these methods. The ﬁrst subsection outlines three methodological proposals that
attempt to improve estimation of the original MSM parameters from Robins , described in the previous section. The next subsection outlines three methodological proposals
that signiﬁcantly diﬀer in their approach to the problem, in that they focus on diﬀerent
MSM parameters for which violations of the ETA assumption are mitigated. In the last
subsection, we discuss the practical importance and limitations of the diﬀerent approaches
proposed and motivate the application of CMRIER beyond or in combination with these
approaches. Where applicable, we apply the speciﬁc method to the simulation study from
section 2.
Methods bound to the original MSM parameter
Beyond IPTW estimation
Investigators can rely on the G-computation, A-IPTW or TMLE estimators for MSM estimation instead of the IPTW estimator in practice. The choice of the IPTW estimator
often has been driven by its ease of implementation. However, it may be appealing to
turn to a diﬀerent estimator when a violation of the ETA assumption is detected in practice. In theory, and unlike the IPTW estimator, the other estimators indeed can maintain
their consistency and eﬃciency properties, even when the ETA assumption is violated.
However, it is important to realize that causal inferences drawn by these estimators in
practice depend heavily on untestable parametric model assumptions instead of real causal
information in the data when the ETA assumption is violated in theory or empirically
 ; Neugebauer and van der Laan ; Neugebauer ).
Indeed, all three estimators can artiﬁcially allow disentanglement of the eﬀect of the exposure from the eﬀects of confounders by relying on extrapolations from parametric models.
In addition, another major concern with blind application of these estimators is the risk
of not recognizing violations of the ETA assumption, since they will not provide signs of
poor performance through inﬂated variability estimates unlike the IPTW estimator. We
illustrated these points in section 2 with the application of the G-computation estimator.
IPTW estimation with weight truncation
As noted above, IPTW estimation can be implemented easily in practice. Its implementation is based on a two-step procedure. The ﬁrst step involves the estimation of the exposure
mechanism, g(A | W) (under the SRA assumption). The second step involves a weighted
regression of the outcome on the exposure of interest with weights inversely proportional to
the exposure mechanism evaluated at the experienced exposure and confounder levels. The
consistency of IPTW estimation – i.e., in practice its unbiasedness – relies on consistent
estimation of the IPTW weights (i.e., the exposure mechanism), but also on the upholding
of the ETA assumption as illustrated in section 2.
 
It is clear from the implementation of the IPTW estimator that some weights will be
largely inﬂated when an exposure level is rarely observed in the data for some levels of the
confounders, i.e., when the ETA assumption is so-called practically violated. Such inﬂated
weights result in an MSM ﬁt driven by a few observations in the data, which, in turn,
leads to important ﬁnite sample bias and weak precision in the derived IPTW estimate
 ).
One approach that has been proposed to overcome this poor ﬁnite sample performance of
the IPTW estimator is to truncate the weights, e.g., between 1.11 and 10 which corresponds
with conditional probabilities of exposure given the confounder levels between 0.1 and
0.9 respectively ).
This approach aims to limit the maximum
contribution that any observation in the data can have on the MSM ﬁt. A direct result of
weight truncation is the reduction in the variability of the IPTW estimator. However, a
side eﬀect of weight truncation is the introduction of bias in the estimation of the weights
that, in turn, leads to bias in IPTW estimation. This proposed approach can be viewed as
balancing the bias-variance trade-oﬀin IPTW estimation: the increase in the precision of
IPTW estimation through weight truncation is at the cost of increased IPTW bias due to
inconsistent estimation of the exposure mechanism. The performance of weight truncation
can be assessed in practice by comparison of the MSE achieved by the truncated IPTW
estimator and the (untruncated) IPTW estimator. Such comparisons have demonstrated
that weight truncation, based on an ad hoc truncation level like the one suggested above,
can actually lead to an increase in MSE ). That is
why it has been argued that the level of weight truncation should involve the sample size
in practice, e.g., no observation should receive a weight greater than 10% of the sample
size. To this end, Bembom and van der Laan proposed a data-adaptive method
for selection of the truncation level that achieves the optimal bias-variance trade-oﬀ, i.e.,
minimization of the MSE from the truncated IPTW estimator.
Finally, it is important to realize that weight truncation has been proposed to overcome
the poor ﬁnite sample performance of IPTW estimation when the ETA assumption is only
practically violated. Indeed, this approach is not suitable to address theoretical violations
of the ETA assumption; the IPTW weights do not even suﬀer from the inﬂation described
above when some exposure levels are not observed at all for certain levels of the confounders
in the data.
For an illustration of this approach, we return to the simulation example provided in
section 2 where the MSM was ﬁt with the IPTW estimator with the correctly speciﬁed
exposure model. For comparison purposes, the truncated IPTW estimator was applied to
this simulation study. The truncation levels for the weights are 1/0.9=1.1 and 1/0.1=10.
Graph a) in Figure 2 provides the consistency results for the IPTW and truncated IPTW
estimators. Clearly, a large amount of bias was introduced by truncating the weights, by
a factor of approximately 2 over the IPTW estimator with the correctly speciﬁed exposure
mechanism. Furthermore, the truncated IPTW estimator is not converging towards the
true value as the sample size increases, whereas, the IPTW estimator with the correctly
speciﬁed exposure mechanism is in fact slowly converging. Note that the bias is reduced
from 19% at a sample size of 1000 to 15% at a sample size of 50000. The MSE for the two
estimators provided in graph b) in Figure 2 demonstrates the large reduction in variability
as a result of truncating the weights.
In comparison to the IPTW estimator with the
Hosted by The Berkeley Electronic Press
correctly speciﬁed exposure mechanism, the bias of the truncated IPTW estimator is more
severe, whereas its variability is signiﬁcantly lower, resulting in an overall substantially
smaller MSE. This example clearly demonstrates the bias-variance trade-oﬀthat is a result
of truncating the weights.
In the case that there is truly no eﬀect of A on Y , such a
biased estimator with overly optimistic precision can lead to incorrect rejection of the null
hypothesis of no eﬀect.
IPTW estimation with curtailed adjustment for confounding
Another approach has been proposed to address extreme weighting with IPTW estimation.
It is based on the exclusion of the confounder(s) that are causing weight inﬂation. In particular, if one confounder is highly predictive of the exposure but is known to have only a
weak eﬀect on the outcome or is weakly associated with it, then one may consider removing
this covariate from the adjustment set of confounders used to estimate the exposure mechanism. Removing such confounders can result in an important increase in the precision of
IPTW estimation at the cost of only a small increase in bias. Indeed, the confounder that
is ignored can be deemed a weak confounder due to its weak eﬀect on (or association with)
the outcome. Ignoring weak confounders results in a limited violation of the aforementioned SRA assumption and, thus, negligible estimation bias compared to the large gain in
estimation precision due to the weight stabilization induced by ignoring such confounders.
Note that, in practice, and as a ﬁrst approximation, identiﬁcation of weak confounders can
be based on subject-matter knowledge or based on the assessment of the crude univariate association between the confounder and the outcome. In Bembom and van der Laan
 , a formal method for selecting the adjustment set of confounders was proposed.
This approach can be illustrated in our study of the eﬀect of ozone on the proportion
of asthma-related hospital discharges ). Only those covariates with
univariate association p-values less than 0.05 with ozone and the proportion of asthmarelated hospital discharges were considered as candidates for the exposure model. However,
we could have further reduced this set by excluding PM10 which had a p-value for the
univariate association with ozone and proportion of asthma-related hospital discharges of
< 10−163 and 0.01 respectively. Under the assumption that PM10 is only a weak confounder,
we could have removed it from the exposure model to potentially reduce the variability due
to the extreme weights with the knowledge that a certain amount of bias (hopefully small)
could result.
Methods that explore diﬀerent MSM parameters
MSM with categorical exposures
Research questions that involve exposure(s) measured on a continuous scale also typically
involve important practical violations of the ETA assumption. This is because of the very
low probability of observing any given exposure level in each of the population subgroups
deﬁned by the levels of the confounders. In this situation, an approach that can be used
by investigators consists of discretizing the exposure into two or more categories with the
expectation that the ETA assumption associated with the new categorical exposure will
no longer be violated or at least less violated. Beside mitigating the violation of the ETA
 
assumption, this approach also alters the deﬁnition of the causal eﬀect of interest, i.e., new
MSM parameters are deﬁned based on the categorical exposure variables (see Appendix
For an illustration of this method, we return to the simulation study introduced in
section 2. We ﬁrst discretize the exposure into a three level categorical exposure variable
from the original continuous exposure variable, at roughly the 33rd and 66th percentiles,
deﬁned by,
if 15 ≤A < 25
The observed data become O = (W, A∗, Y ). We now investigate the eﬀect of A∗on Y with
the MSM: E(Ya∗): m(a∗| β) = β0 + β1I(a∗= 1) + β2I(a∗= 2). From the simulation
protocol, we can derive the true value for the new MSM parameter β ≈(148.2, 31.7, 63.5)
(see Appendix A.1 for details on obtaining the true values of the new MSM parameter).
Note that this approach is based on the deﬁnition of interventions on A corresponding with
setting A∗to 0 and 1 (see Appendix for such deﬁnitions).
The MSM was ﬁt with the IPTW estimator, based on the correctly speciﬁed exposure
model for P(A∗| W) (for details see Appendix A.1). Figure 3 provides the consistency
results by plotting the bias of the 25000 IPTW estimates of β0, β1 and β2 by sample size as
a percent of the true value. Even at a sample size of 1000, the estimates of β1 and β2 have
not yet converged to their true values. Since the exposure mechanism is correctly speciﬁed
and convergence is still not achieved for at sample size 1000, evidently discretizing exposure
into three categories did not adequately remove the ETA violations.
In a more aggressive attempt to mitigate the ETA violations, a binary variable A∗was
created where A∗computed from A as A∗= 1, if A > θ, θ = 20, and A∗= 0 if A ≤θ. Note
that the cutoﬀvalue of 20 is near the median of A. We now investigate the eﬀect of A∗on
Y with the MSM: m(a∗| β) = β0 + β1a∗. We can again derive the true value for the new
MSM parameter β as described in Appendix A.1: β ≈(161.9, 36.2).
The MSM was again ﬁt with the IPTW approach, also based on the correctly speciﬁed
exposure model (for details see Appendix A.1).
Figure 4 provides the consistency results for the IPTW estimator of the intercept (β0)
and slope (β1) parameters from the MSM with the binary exposure. With a comparison of
Figure 4 to Figure 3, we can observe visually that the biases of the IPTW estimates of β0
and β1 for the binary exposure are smaller than those of β0, β1 and β2 for the categorical
exposure. The average bias for the IPTW estimates of β0 and β1 for the binary exposure is
approximately 3% as compared to the average bias of the IPTW estimates of β0, β1 and β2
for the categorical exposure of 8%. This indicates that reducing the number of categories
for the exposure variable reduces the ETA violations.
This simulation demonstrates that one can potentially mitigate the ETA issue by discretizing a continuous exposure variable, given an adequate sample size. However, this is at
the expense of signiﬁcant alteration of the causal question of interest. Thus, this approach
should only be applied if the new causal question is of interest from a subject matter perspective. For instance, this approach is reasonable in air pollution epidemiology to test the
eﬀect of air pollutants, e.g., dichotomized pollutant levels based on the current regulatory
standard (low versus high). One can more closely approximate the original eﬀect of interest
Hosted by The Berkeley Electronic Press
by creating a number of categories, however this of course increases the potential for ETA
violations.
 
Sample Size
IPTW Truncated
(a) Consistency
Sample Size
IPTW Truncated
Figure 2: Simulation Study: IPTW and IPTW with truncated weights
Hosted by The Berkeley Electronic Press
Sample Size
Figure 3: Simulation Study with discretized categorical exposure: Consistency
Sample Size
Figure 4: Simulation Study with discretized binary exposure: Consistency
 
MSM for data-driven population subgroup(s)
Filtering out from an MSM analysis the observations with no exposure experimentation,
i.e., those that violate the ETA assumption, is a natural approach to overcome the poor
ﬁnite sample performance of the IPTW estimator. Indeed, if one removes the observations
for which the levels of the confounders deterministically limit the set of exposure levels
that can be experienced by an experimental unit, then, the IPTW weights associated with
the remaining observations in the data do not suﬀer from abnormal inﬂation. While this
approach is appealing, it is important to realize that such a ﬁltering of the data amounts to
implicit modiﬁcation of the scope of the initial research question by focusing on a subgroup
of the initial target population.
In other words, a new MSM parameter becomes the
parameter of interest; and the relevance of this parameter to address the subject-matter
research question of interest is not guaranteed.
Indeed, the exposure mechanism is based on a number of confounders in practice; and
violation of the ETA assumption is typically not caused by one such confounder only but a
combination of these confounders. The population subgroup that results from ﬁltering out
the observations that violate the ETA assumption cannot easily be interpreted necessarily
since it is composed of observations characterized by complex combinations of confounder
levels. While these complex combinations justify their inclusion in the analysis, they likely
do not lead to the deﬁnition of an interesting population subgroup for the purpose of deﬁning a relevant exposure eﬀect for the subject-matter research of interest. In particular, this
approach cannot be applied successfully to research questions that involve time-dependent
confounders (longitudinal data where cumulative eﬀects over time are of interest) that cause
ETA violations and that are also on one of the causal pathways of interest ). In general, this approach will thus not apply to problems that involve the investigation of the eﬀect of a history of exposure (i.e., experienced over more than one time
point) on an outcome.
Thus, the application of this approach is limited in practice to isolated cases where the
ETA assumption is clearly violated due to only one or two baseline covariates which deﬁne
interesting population subgroups of interest. In such situations, instead of removing the
observations with no exposure experimentation, one may instead rely on a stratiﬁed MSM
analysis conditional on the one or two covariates identiﬁed as causing ETA violation. Alternatively, one may rely on a pooled MSM analysis conditional on these covariates with the
implementation of the stabilized IPTW estimator proposed by Robins et al. . Note
that whichever analytic strategy is adopted (exclusion of observations or stratiﬁcation),
the sample size of each analysis involved is reduced. Such a sample size reduction may in
turn result in new practical violations of the ETA assumptions (since such violations are a
function of the sample size).
History-restricted MSM
This approach pertains to problems with longitudinal data which involve the investigation
of the eﬀect of a history of exposure (i.e., experienced over more than one time point) on
an outcome. History-restricted MSM (HRMSM) for longitudinal data ; Neugebauer et al. ), allow estimation of the causal eﬀect of an exposure on
an outcome based on a curtailed portion of the exposure history rather than the entire
Hosted by The Berkeley Electronic Press
exposure history of interest as is the case with standard MSM applications. By restricting
the scope of the exposure history that deﬁnes the eﬀect of interest, one mitigates practical
violations of the ETA assumptions as noted by Joﬀe et al. .
In our ozone data analysis, the eﬀect of the history of quarterly ozone levels over 20
years on quarterly proportions of asthma-related hospital discharges during the same time
span is of interest. In particular, one is interested in investigating the eﬀect of ozone on the
ﬁrst quarter of the second year monitored. It is not reasonable to assume that ozone levels
from the previous year would have a signiﬁcant eﬀect on the current quarter’s proportion
of asthma-related hospital discharges. In fact in Moore et al. , it was reasoned that
the eﬀect of only the current quarter exposure to ozone on the same quarter proportion of
asthma-related hospital discharges was sensible. Reducing the exposure history of interest
to the latest experienced quarterly exposure is thus both sensible from a subject-matter
point of view, but can also reduce the extent of the violation of the ETA assumption.
Beyond these proposed approaches
As discussed in the introduction, the violation of the ETA assumption can be viewed as
a lack of information in the data to fully disentangle the exposure eﬀect of interest from
that of the confounders of this eﬀect.
Two fundamentally diﬀerent paths can then be
taken to address the lack of information in the data: 1) maintain the complexity of the
initial research question and either a) heavily rely on parametric modeling assumptions
that may not hold to draw causal inferences (e.g., rely on the G-computation estimator)
or b) tolerate estimation bias (e.g., weight truncation); or 2) simplify the research question
and draw causal inferences that can be supported fully by the information in the data (e.g.,
discretize exposure into a categorical variable).
We have described several methodologies that illustrate both of these paths. Among
them, subject-matter investigators are most often dissatisﬁed with the methodology that
consists in discretizing the exposure of interest due to the resulting simpliﬁcation in the
causal inference that can be attained with this methodology. Nevertheless, one can argue that such a simpliﬁcation is typically necessary in practice because the information
contained in ﬁnite sample data is often too limited to reliably (i.e., with a minimum of
untestable assumptions) investigate eﬀects deﬁned based on continuous exposures. We believe that while the ﬁrst path can provide exploratory information about subject-matter
research problems on which future research can be based, it does not constitute a strong
scientiﬁc basis for decision making (e.g., for regulatory/intervention purpose like setting air
pollution standards). The second path should then be considered.
We described in section 3.2 three proposed methodologies that follow the second path
described above.
While some of these approaches can lead to reliable causal inference
in practice, they typically need to be combined to successfully achieve reliable inference.
However, even when these approaches are combined, the information in the data may
still remain too limited to allow proper estimation of the MSM parameter of interest, i.e.,
the ETA assumption remains violated. This limitation motivates further exploration of
the deﬁnition of less ambitious causal parameters that, nevertheless, can provide relevant
causal inference for decision making. Such exploration lead to the deﬁnition of CMRIER
introduced in van der Laan and Petersen . This class of models builds on the coun-
 
terfactual framework on which is based the deﬁnition of MSM and constitutes, in fact, a
generalization of MSM. We introduce them in the next section.
Before doing so, we would like to emphasize that, while the CMRIER parameters can be
seen as less ambitious as MSM parameters when the ETA assumption is violated, they are,
in fact, a class of causal models that can be used in situations where the ETA assumption
holds. In other words, their use should not only be considered in cases where the ETA assumption is violated. Indeed, these models not only allow the investigation of causal eﬀects
deﬁned by static interventions but also the eﬀect of dynamic interventions that do not result
in identical exposure levels for all experimental units. In fact, the eﬀect of such dynamic
interventions may be more interesting for some subject-matter research than the eﬀect
of static interventions (e.g., to optimize drug treatments) for examples).
Causal eﬀect models for realistic individualized exposure rules
As noted before, MSM are models which represent the eﬀect of static interventions on an
exposure of interest. A static intervention is one particular type of exposure intervention
which results in a single exposure level a that is experienced by all units in the target population. However, an exposure intervention does not necessarily have to result in identical
exposure levels for all units in the target population. Such interventions are deemed dynamic, since they may result in an exposure level experienced by a given unit that depends
on that unit’s characteristics W, i.e., the same dynamic intervention applied to two units
could result in two diﬀerent exposure levels experienced by each unit. We denote such a
dynamic intervention with d. These interventions are a mapping from the unit’s characteristics W to one of the possible exposure levels d(W) ∈A; therefore, they are also referred
to as exposure rules. The eﬀects of such dynamic interventions can be represented with a
class of causal models, CMRIER. They are models for the distribution of the counterfactual
outcome Yd(W). Note that one particular dynamic intervention is a static intervention, i.e.,
d(W) = a, and CMRIER can thus be viewed as a generalization of MSM.
When the ETA assumption is violated, we have argued that MSM parameters cannot be
identiﬁed without making untestable assumptions due to the lack of true causal information
in the data. This is because static interventions are not realistic interventions in the sense
that the exposure levels resulting from these interventions are never seen in the collected
data for some strata of the population deﬁned by certain confounder levels.
Similarly, the estimation of CMRIER parameters also relies on an assumption analogous
to the ETA assumption for MSM. This assumption requires that all units can experience
the exposure levels resulting from the dynamic interventions, d(W), for all values for the
confounding variables that characterize each unit, W. We refer to such dynamic interventions as realistic dynamic interventions (or realistic exposure rules) to distinguish them
from dynamic interventions (exposure rules) for which the ETA assumption is violated.
Unlike MSM where investigators are limited to the investigation of eﬀects from static interventions, CMRIER allow the investigation of eﬀects from dynamic interventions that
can be deﬁned by the investigators themselves, so that the exposure rules considered are
Hosted by The Berkeley Electronic Press
always realistic and meaningful in the context of the subject matter. This control over
the deﬁnition of causal eﬀects is particularly appealing to overcome the limitation of the
application of MSM when the ETA assumption is violated. Indeed, the investigators can
focus their eﬀorts on the investigation of causal eﬀects that remain of interest but that also
are fully identiﬁable from the data without additional untestable modeling assumptions
like the ones that would be required to ﬁt an MSM. Below, we discuss the interpretation
of causal eﬀects represented by CMRIER applied to the ozone data analysis, but ﬁrst, we
describe one method that investigators can use to deﬁne a dynamic intervention that can
be deemed realistic based on any given static intervention from an MSM.
Realistic dynamic interventions
Consider a binary exposure variable, e.g., low versus high concentration of ambient ozone
A dynamic intervention can be deemed realistic for a given unit only if the
estimated probability of the exposure which results from that intervention, given the unit’s
confounder history, is greater than some threshold not too close to 0, e.g., 0.1. We denote
such threshold value with α and later develop the practical meaning of our statement “not
too close”. The simplest and most natural dynamic interventions that can be considered are
static interventions, e.g., exposure of every unit to an exposure level a that is independent of
the confounder history for each unit. By deﬁnition of the violation of the ETA assumption,
such static interventions are not realistic when the ETA assumption is violated. Instead,
the investigators can then deﬁne a dynamic intervention that is realistic as follows: a unit
is exposed to level a (0 or 1) if the probability of the unit’s being exposed to level a given
the unit’s confounder history is greater than α and otherwise the unit is exposed to level
1 −a. Formally, the proposed dynamic interventions above for a binary exposure A, are
denoted with:
if P(A = 1 | W) > α
if P(A = 0 | W) > α
otherwise.
We refer to d(a) for a = 0 or a = 1 as exposure rules, because they are mapping from the
unit’s characteristics W into an exposure level d(a)(W). The deﬁnition of such realistic
dynamic interventions can be generalized easily to categorical exposures. For instance,
consider an exposure with three ordered levels: 0, 1 and 2. Each of these three static
interventions can be mapped into the following realistic dynamic interventions:
if P(A = 0 | W) > α
if P(A = 0 | W) < α and P(A = 1 | W) > P(A = 2 | W) > α
if P(A = 0 | W) < α and P(A = 2 | W) > P(A = 1 | W) > α
if P(A = 1 | W) > α
if P(A = 1 | W) < α and P(A = 0 | W) > P(A = 2 | W) > α
if P(A = 1 | W) < α and P(A = 2 | W) > P(A = 0 | W) > α
 
if P(A = 2 | W) > α
if P(A = 2 | W) < α and P(A = 0 | W) > P(A = 1 | W) > α
if P(A = 2 | W) < α and P(A = 1 | W) > P(A = 0 | W) > α.
Alternatively, each of the three static interventions a can be mapped into realistic dynamic
interventions where the alternative exposure level assigned when g(a | W) < α is not the
most likely exposure levels based on g(A | W) as described above, but the nearest exposure
level among all exposure levels a that are also realistic, i.e., such that P(A = a | W) > α:
if P(A = 0 | W) > α
min{a : P(A = a | W) > α}
if P(A = 0 | W) < α
if P(A = 1 | W) > α
min{| a −1 |: P(A = a | W) > α}
if P(A = 1 | W) < α
if P(A = 2 | W) > α
min{| a −2 |: P(A = a | W) > α}
if P(A = 2 | W) < α.
The realistic exposure rules deﬁned above can be used to deﬁne causal eﬀects of the
exposure of interest on an outcome through the speciﬁcation of an CMRIER for E(Yd(a)(W) |
V ) denoted with m(a, V | β). Note, that like MSM, CMRIER that are deﬁned based on
the realistic exposure rules described above are also functions of an exposure level a and
the baseline covariate V that deﬁne population subgroups of interest. However, the causal
interpretation of CMRIER is diﬀerent from that of MSM in general and causal eﬀects
deﬁned by such CMRIER may appear, at ﬁrst, as irrelevant for the investigation of the
original research question of interest.
Therefore, we motivate their use in practice by
illustrating their application and interpretation with the ozone study in the next section.
Causal interpretation
Returning to our ozone exposure data analysis, assume again that no grid with average
temperatures below 65 degrees experienced ozone concentrations above the standard (i.e.,
level 1 of ozone). For these grids, the static intervention “ set ozone above the standard”
would not fall in the set of possible exposures. The static intervention of setting ozone to
level 1 thus is not deemed to be realistic. One might be aware of such a violation of the
ETA assumption in practice a priori. Most often, however, ETA violation is not discovered
until the data are collected, as is the case in the ozone study. Certain exposure levels
may be rare or not represented at all in the collected data for an unexpected subset of the
population deﬁned by a particular combination of confounder levels, e.g., low temperature
levels. Whether the violation of the ETA assumption associated with static interventions is
known a priori or discovered a posteriori, we can always deﬁne realistic dynamic interventions that map each observed confounder history into an exposure level as described in the
previous section. In the ozone data analysis, the following two exposure rules can be used
to deﬁne a causal eﬀect of ozone on the proportion of asthma-related hospital discharges
with an CMRIER:
Hosted by The Berkeley Electronic Press
• rule 1, d(1): if the probability of experiencing an ozone concentration above the
standard, given a unit’s confounder history is less than α (i.e., the ETA assumption
is violated at the α level); then, the exposure level should be set to 0, i.e., below the
standard and otherwise to 1, i.e., above the standard.
• rule 2, d(0): if the probability of experiencing an ozone concentration below the
standard, given a unit’s confounder history, is less than α (i.e., the ETA assumption
is violated at the α level); then, the exposure level should be set to 1, i.e., above the
standard and otherwise to 0, i.e., below the standard.
Investigation of the eﬀect of ozone on the proportion of asthma-related hospital discharges
can be based on the CMRIER associated with the exposure rules above: E(Yd(a)(W)) =
1a to overcome the limitation of the application of the MSM: E(Ya) = β0 + β1a due
to violation of the ETA assumption. The interpretation of the causal parameter deﬁned by
the CMRIER can easily be understood by analogy with the interpretation of the MSM parameter. The MSM parameter β1 in the ozone study represents the causal eﬀect of ozone on
the proportion of asthma-related hospital discharges by comparing: a) the mean proportion
of asthma-related hospital discharges over all grids had all grids been exposed to an ozone
level above the current standard (static intervention 1), E(Y1), to b) the mean proportion
of asthma-related hospital discharges over all grids had all grids been exposed to an ozone
level below the current standard (static intervention 2), E(Y0). Similarly, an CMRIER
parameter β
1 represents the causal eﬀect of ozone on the proportion of asthma-related hospital discharges by comparing the mean proportion of asthma-related hospital discharges
under two diﬀerent dynamic interventions: E(Yd(1)(W)) −E(Yd(0)(W)). A diﬀerence in the
two means of proportions of asthma-related hospital discharges is interpreted as resulting
from the interventions considered on ozone. This comparison under two diﬀerent interventions is more relevant to policy considerations than the static intervention, since it restricts
the intervention to units where such an intervention is possible. The CMRIER allows the
approximation of the original causal eﬀect deﬁned by the MSM and, like MSM parameters,
CMRIER parameters remain interpretable at the population level. Unlike MSM, however,
CMRIER parameters remain fully identiﬁable from the observed data even when the ETA
assumption is violated as long as the dynamic interventions on which the CMRIER are
based are realistic such as the ones we proposed above.
In addition, it should be clear from the example above that CMRIER are a generalization of MSM. Indeed, if the ETA assumption was not violated in the ozone study, the
realistic dynamic interventions above would correspond to the static intervention on ozone
and the CMRIER would thus reduce to the standard MSM. Note, that when the set of
possible exposure levels is limited to two exposure levels, then, the causal contrast, β1 represented by an CMRIER converges to zero as the ETA assumption becomes more violated,
i.e., it becomes more and more diﬃcult to identify an eﬀect due to interventions on the
exposure of interest.
The methods used to estimate MSM parameters can be generalized to the estimation
of CMRIER parameters. For the development of the estimation of CMRIER parameters
see van der Laan and Petersen . The details on the implementation of the IPTW
estimator, see Appendix A.2. In addition, note that deﬁnition of causal eﬀects in the ozone
study above based on dynamic interventions on the dichotomized ozone exposures is based
 
on an implicit deﬁnition of the interventions “set A∗= a∗”. Formal deﬁnition of such
interventions is provided in Appendix A.2.
Applications
We provide two applications of the CMRIER methodology presented in section 4 through:
1) simulation studies, and 2) data analysis. The simulation studies are continuations of the
simulation study introduced in section 2. The data analysis in which we demonstrate the
application of the CMRIER methodology is the study that has been discussed throughout
this paper which aims to investigate the eﬀect of reductions of ozone concentrations on the
proportion of asthma-related hospital discharges ).
Illustration of the CMRIER methodology with simulation
Data were again simulated according to the data generating distribution provided in section
To demonstrate the CMRIER methodology described above, a categorical exposure
variable was created from the continuous exposure variable. The two discretization schemes
described in section 3.2.1 were applied to obtain two exposure variables: the ﬁrst binary and
second categorical with three exposure levels. The eﬀect of the new exposure variable A∗
on the outcome Y was investigated by using both an MSM and an CMRIER (see Appendix
for a detailed deﬁnition of this eﬀect).
The parameters of both the CMRIER and MSM are estimated with the the IPTW
estimation procedure. In both instances, the correctly speciﬁed exposure mechanism was
applied (for details see Appendix A.1).
Binary exposure
The CMRIER for the binary exposure variable A∗is given by,
E(Yd(a∗)(W)) = β
where d(a∗)(W) is the rule presented in section 4 applied to A∗with α = 0.1. The MSM is
E(Ya) = β0 + β1a∗.
The true parameter values for the CMRIER coeﬃcients are given by β
′ ≈(166.4, 27.1), and
for the MSM coeﬃcients they are given by, β ≈(161.9, 36.2). Since the data were simulated
such that the ETA assumption is violated, the parameter values are not equal. In this
simulation, β
1 is approximately 25% lower than β1. The CMRIER parameter is typically
shrunk towards zero as compared to the corresponding MSM parameter. If there exist units
in the data for whom an intervention is not possible, as deﬁned by gn(a | W) < α, then
there is no information in the data to estimate the eﬀect for these units. The contribution
of these units that are never exposed (to a given level) to the overall population-level eﬀect
deﬁned by the two dynamic interventions is zero. Thus, the parameter of the CMRIER
with a binary exposure is conservative (closer to zero) as compared to the MSM parameter.
Hosted by The Berkeley Electronic Press
The consistency results of the IPTW estimators of the CMRIER and MSM parameters
are provided in graphs a) and b) in Figure 5. The IPTW estimator of the CMRIER is
largely outperforming that of the MSM with respect to bias. Across all sample sizes, the
bias of the IPTW estimator of the CMRIER parameter is substantially lower than that of
the IPTW estimator of the MSM parameter with a maximum bias for the former of 3% in
comparison to 13% for the latter.
Not only is the IPTW estimator of the CMRIER parameter outperforming the IPTW
estimator of the MSM parameter with respect to bias, but also with respect to MSE. The
MSE of the IPTW estimator of the MSM parameter is as high as 3 times that of the IPTW
estimator of the CMRIER (Figure 6). Thus clearly the parameters of the CMRIER can
be consistently estimated with far less uncertainty using the IPTW method even when the
ETA is violated as it is in this example with an average across all simulated datasets of 20%
(and median 20%) of the units meeting the criterion gn(A | W) < α or gn(A | W) > (1−α)
Categorical Exposure
To more closely approximate the original eﬀect of interest, that is the eﬀect of the continuous
exposure A on Y , the exposure was also discretized into three levels. With a categorical
exposure variable, more choices for the realistic intervention rule are available than the
simple rule for binary exposures as described in section 4.1.
In this simulation study, we apply the rule that sets the realistic intervention to the
corresponding static intervention when the probability of experiencing that intervention
level is greater than α, otherwise it is set to the intervention that is most likely based on
The CMRIER for the categorical exposure variable A∗is given by,
E(Yd(a∗)(W)) = β
1I(a∗= 1) + β
2I(a∗= 2),
where d(a∗)(W) is the rule applied to A∗with α = 0.1. The MSM is given by,
E(Ya∗) = β0 + β1I(a∗= 1) + β2I(a∗= 2).
The true values for the CMRIER parameters are given by, β
′ = (148.2, 31.7, 63.5), and for
the MSM parameters they are given β = (161.6, 18.4, 36.9) (see Appendix A.2 for details
on how these values were derived).
The consistency results for the IPTW estimator of the CMRIER and MSM parameters
are provided in graphs a), b) and c) in Figure 7. The results are similar to those of the
binary exposure in that the IPTW estimator of the CMRIER is largely outperforming that
of the MSM with respect to bias. The bias is of the IPTW estimators of the CMRIER
parameters is close to zero across all sample sizes and all parameters; the maximum absolute
value of the bias for any of the parameters β0, β1 and β2 is 2% at a sample size of 100,
and decreases further as the sample size increases. In comparison, the bias for the IPTW
estimator of the MSM parameter is much higher, with an absolute value of bias of 26% for
β1 at a sample size of 100, and, even at a sample size of 1000 the bias of the estimator of
this parameter is 8%.
 
The MSE for the IPTW estimators of the CMRIER and MSM parameters are provided
in graphs a), b) and c) in Figure 8. The comparison of the MSE indicates that in addition
to the reduction in bias, there is also a large reduction in variability as in the binary
simulation example.
Hosted by The Berkeley Electronic Press
Sample Size
(a) β0 and β
Sample Size
(b) β1 and β
Figure 5: Simulation study with binary exposure: IPTW estimator of MSM and CMRIER
parameters, consistency
 
Sample Size
(a) β0 and β
Sample Size
(b) β1 and β
Figure 6: Simulation study with binary exposure: IPTW estimator of MSM and CMRIER
parameters, MSE
Hosted by The Berkeley Electronic Press
Sample Size
(a) β0 and β
Sample Size
(b) β1 and β
Figure 7: Simulation study with categorical exposure: IPTW estimator of MSM and CM-
RIER parameters, consistency
 
Sample Size
(c) β2 and β
Figure 7: Simulation Study with categorical exposure: IPTW estimator of MSM and
CMRIER parameters, consistency, continued
Hosted by The Berkeley Electronic Press
Sample Size
(a) β0 and β
Sample Size
(b) β1 and β
Figure 8: Simulation study with categorical exposure: IPTW estimator of MSM and CM-
RIER parameters, MSE
 
Sample Size
(c) β2 and β
Figure 8: Simulation study with categorical exposure: IPTW estimator of MSM and CM-
RIER parameters, MSE, continued
Hosted by The Berkeley Electronic Press
Simulation Summary
The simulation study demonstrates that in contrast to MSM parameters, CMRIER parameters can reliably be estimated in the presence of ETA violations. In both the binary and
three-level categorical discretized exposure simulations, the behavior of the IPTW estimator of the CMRIER parameters largely outperformed the IPTW estimator of the MSM
parameters with respect to both bias and MSE.
In addition to their usefulness in terms of mitigating estimation issues in the presence of
ETA violations, the real data example provided in the next section demonstrates that they
may be more sensible from a subject-matter perspective to draw causal inferences that can
be fully supported by the information in the data.
Illustration with real data: air pollution study
The application of the CMRIER was motivated by the study brieﬂy described throughout
this paper, with the aim of estimating the extent to which reductions in ambient ozone concentrations were associated with measurable health beneﬁts, speciﬁcally on the proportion
of asthma-related hospital discharges. The fact that ozone is a continuous variable immediately raised concerns about possible ETA violations. Initial investigations did indeed show
large practical violations of the ETA assumption. For this reason, the initial analysis relied
on the G-computation estimator ). However, as mentioned previously,
consistency of this estimator relies entirely on untestable model assumptions. This study
demonstrated the need to aim for a parameter that was fully identiﬁable from the data by
restricting the analysis to interventions for which the data carries information.
We apply the CMRIER methodology to this air pollution study that aimed to investigate the eﬀect of reduction in ozone concentrations consequent to regulations propagated
since 1980 by the California Air Resources Board in the Los Angeles Basin on the proportion of asthma-related hospital discharges ). The data consist of n=195
geographical grids, with quarterly measurements of confounders, quarterly average ambient ozone concentrations and quarterly proportions of asthma-related hospital discharges,
where W(t) is a multivariate vector of potential confounders measured at quarter t; A(t) is
the ozone concentration measured at quarter t and Y (t) is the proportion of asthma-related
hospital discharges measured in this same quarter t. The ozone concentration at quarter
t, A(t) was discretized to deﬁne A∗(t), where A∗(t) = 1 if A(t) > 90, where 90 ppb was
the California one-hour average ozone standard through the study years, and A∗(t) = 0
otherwise. We aim to investigate the the eﬀect of A∗(t−1) on Y (t). Although the outcome
at time t (Y (t)) and exposure at time t −1 (A∗(t −1)) are actually measured during the
same quarter, we make the assumption that the exposure precedes the outcome.
For speciﬁcs as to the choice of the consideration of only a single quarter exposure as
opposed to the whole history see Moore et al. .
Since only part of the exposure
history is considered relevant, an HRMSM was applied to investigate the eﬀect of interest
 ). For the ease of presentation, we drop the t-notation and from
this point on we refer only to A∗and Y . We modeled the expectation of counterfactual
outcomes Ya∗with the following HRMSM,
E(Ya∗) = β0 + β1a∗.
 
The coeﬃcient β1 can be interpreted as the population-level eﬀect of the same quarter ozone
level falling above versus below the 90ppb standard on the proportion of asthma-related
hospital discharges during any given quarter (see Appendix A.1 for an explicit deﬁnition).
As noted earlier, this parameter is only identiﬁable under the ETA assumption.
The Deletion/Subsitution/Addition ) was applied to obtain the estimate gn(A | W) of the exposure mechanism from which gn(A∗| W) was obtained as described in Appendix A.1. Based on this estimate, the ETA is strongly violated,
with 59% of the grids with probabilities of exposure less than 0.1 or greater than 0.9. Thus,
it is apparent that it is not reasonable to assume that all grids could possibly be exposed to
all levels of ozone at each point in time. This is an example where it is natural to reconsider
the modeling approach to be used to answer the research question of interest. Based on
subject matter and regulatory contexts, we consider modeling the population-level eﬀect
of ozone dichotomized above or below the standard on the proportion of asthma-related
hospital discharges based on dynamic exposure interventions such that only those grids for
which the intervention (ozone above or below the standard) is possible (in the sense of the
realistic interventions) indeed receive the intervention.
To investigate this eﬀect, we also applied the CMRIER-HRMSM,
E(Yd(a∗)(W)) = β
where rule d(a∗)(W) is deﬁned in section 4.1, with α = 0.1.
The IPTW estimator was used to estimate the parameters β and β
′ of the HRMSM and
CMRIER-HRMSM respectively. The results are provided in Table 1. The point estimates
of the HRMSM and CMRIER-HRMSM are drastically diﬀerent, with negative eﬀect and
positive eﬀect estimates, respectively.
The results from the original HRMSM analysis based on the continuous ozone variable
estimated with the G-computation method resulted in an estimate of an increase of 1.44e-
06 in the proportion of asthma-related hospital discharges for a one unit increase in ozone
 ).
Unlike results from the HRMSM analysis with the continuous ozone variable, the
CMRIER results are not signiﬁcant. Note that the HRMSM analysis was based on Gcomputation estimation which artiﬁcially relies on untestable parametric modeling assumptions to estimate HRMSM parameters when the ETA assumption is violated. Thus, in this
ozone study, signiﬁcant results from the G-computation analysis may be a consequence of
the approach taken and not solely based on the information in the data. Moreover, the
fact that the CMRIER analysis does not provide signiﬁcant results may be due to the lack
of power to detect an eﬀect with inverse weighting estimation. A more eﬃcient estimation
approach like Targeted Maximum Likelihood estimation van der Laan and Rubin 
could improve the estimation precision for CMRIER parameters and may thus be implemented in the future in combination with CMRIER to provide a more deﬁnite conclusion
regarding the eﬀect of ozone in this study.
Hosted by The Berkeley Electronic Press
Table 1: Air pollution example: HRMSM and CMRIER-HRMSM
Standard Error
HRMSM (β1)
CMRIER-HRMSM (β
 
Discussion
In epidemiology, an increasing body of causal inference relies fundamentally on the concept of counterfactuals/potential outcomes. Causal modeling that explicitly relies on this
concept is appealing for two reasons: 1) it allows the clear deﬁnition of the causal eﬀect of
interest; and 2) it reveals the critical assumptions on which causal inference from real data
must rely: the no unmeasured confounders and the experimental treatment assignment assumptions. Marginal Structural Models were a break-through in causal inference because
they allowed the development of a general modeling and estimation approach based on
the counterfactual statistical framework with both point-treatment and longitudinal data.
However, in practice, the validity of estimates based on their application has been hampered by frequent practical violations of the ETA assumption, on which accurate causal
inference with MSM relies. This assumptions ensures that the data contain suﬃcient information to identify the causal eﬀect of interest without requiring additional untestable
parametric modeling assumptions to disentangle fully the eﬀects of confounders from that
of the exposure of interest. As described and illustrated in this article, several approaches
have been proposed to draw reliable inference with MSM when the ETA assumption is
violated. While these approaches can provide a satisfactory solution in practice in certain
situations, they often fall short, as described in section 3. In addition, the ETA assumption is not unique to causal modeling with MSM; traditional regression models also rely
on this assumption to draw reliable causal inference without making additional untestable
parametric modeling assumptions.
The poor practical performance of MSM when the ETA assumption is violated should
not be viewed as a drawback but an advantage of the approach. Indeed, unlike the traditional modeling approach, the MSM approach allows investigators to detect situations
when the ETA assumption is violated or practically violated ). Detection of violations of the ETA assumption is essential to avoid drawing causal
inferences that cannot be supported fully by the data. Moreover, it suggests that perhaps
one should be aiming for a parameter that is identiﬁable with the data at hand.
Recent methodological work, based on the counterfactual framework, has resulted in the
deﬁnition of a new class of causal models that generalize MSM: CMRIER. These models
allow the investigation of causal eﬀects that often may be more relevant for some subjectmatter research, since these eﬀects are deﬁned based on dynamic exposure interventions
which are actually possible for each of the units in the population. In addition, these models
provide a general solution to the problem of causal inference when the ETA assumption is
violated. The application of CMRIER for this purpose relies on the basic understanding
of the interpretation of CMRIER parameters in order to properly deﬁne realistic exposure
rules that will allow extraction of relevant information to address the original research
question of interest. We provided a general methodology to deﬁne realistic exposure rules,
but the investigator is not limited to the deﬁnition of causal eﬀects based on such rules and,
in fact, should consider carefully other alternative rules that could result in the deﬁnition of
more interesting causal eﬀects for their own research endeavors ). In addition, while CMRIER provide an appealing solution to the problem of ETA
violation in causal inference, their use in practice can be combined with other approaches
that have been described in this article: exposure discretization, curtailed adjustment for
Hosted by The Berkeley Electronic Press
confounding or subgroup analysis.
When the research question of interest involves the
investigation of the eﬀect of interventions on a history of exposure then CMRIER also
can be used in combination with restriction of the exposure history as proposed with the
HRMSM procedure referenced in this paper ). Furthermore, note
that under the often reasonable assumption that a causal eﬀect represented by a CMRIER
is smaller than the eﬀect represented by an MSM, one can use a CMRIER to test that a
causal eﬀect represented by an MSM is null (no eﬀect of static interventions) even when
the ETA assumption does not allow identiﬁcation of the MSM parameter with the observed
In this paper, the ﬁtting of CMRIER focused on the IPTW estimation approach. Note
however that the A-IPTW or targeted maximum likelihood approaches provide additional
robustness to modeling assumptions and improved estimation eﬃciency/presicion. One
appeal for a targeted maximum likelihood approach over an A-IPTW analysis is its ease of
implementation ).
Finally, the general methodology described in this paper to deﬁne realistic exposure
rules relies on an arbitrary choice for α which ensures that the probability of the exposure resulting from such exposure rules is not too close to 0. The choice for α is critical
in two ways: 1) if chosen too small, the corresponding exposure rules are not realistic
(ﬁnite-sample bias due to practical ETA violation remains a concern); and 2) if chosen
too large, the causal eﬀects deﬁned based on these rules becomes less relevant and may be
more diﬃcult to detect. Therefore, the goal should be to select α as small as possible so
that the CMRIER parameter is as close to the MSM parameter as possible while remaining
identiﬁable from the data. Bembom and van der Laan proposed the following approach to select and estimate the wished CMIER parameter: 1) Deﬁne a level of acceptable
identiﬁability (as measured by bias, variance or both). Such a decision maps into a family
of α levels, each of which ensures the deﬁnition of a CMRIER causal parameter that is
deemed identiﬁable. The smallest α level in this family is chosen to deﬁne the CMRIER
parameter of interest; 2) Estimate the CMIER parameter deﬁned by the α level previously
selected with the preferred method such as targeted maximum likelihood estimation involving cross-validation to select ﬁne tuning parameters ;
Dudoit and van der Laan ).
As suggested in Bembom and van der Laan ,
estimators of CMIER parameters deﬁned by other α levels may be considered as candidate
estimators of the actual CMIER parameter of interest. The estimator selected is chosen so
that it minimizes the mean squared error associated with the CMIER parameter of interest.
Dichotomized exposure and eﬀect deﬁnition
In this section, we brieﬂy outline the framework on which the deﬁnitions of causal eﬀects
with dichotomized exposures is based. This framework enables the deﬁnition of causal effects based on not only static interventions (MSM) on the dichotomized exposure but also on
dynamic interventions (CMRIER). Note that the framework detailed in this section is based
on the extended counterfactual framework from which causal eﬀect models for intention-totreat were derived in van der Laan and Petersen . In this section, we also describe
 
the procedure implemented in the simulation studies of this paper that can be used to derive
the true value of causal eﬀects with discretized exposures from the chosen data generating
distribution along with a brief description of the maximum-likelihood and inverse-weighing
estimator of the causal eﬀects ). The
results in this section can be generalized to discretization of exposures with more than two
levels. Such a generalization was applied in the simulation studies from this paper when
the continuous exposure was discretized in three categories.
Eﬀect deﬁnition with MSM and dichotomized exposure
The observed data are O = (W, A, Y ) where A is a continuous exposure variable. We deﬁne
the following sets of continuous treatment levels:
D0 ≡{a : a ≤θ} and D1 ≡{a : a > θ},
where θ is the cut-oﬀlevel used to dichotomize the continuous treatment into two categories.
Similar to the approach taken to extend the counterfactual framework in van der Laan and Petersen
 , we deﬁne the full data as:
X = (W, (Ad(a∗), Yd(a∗))a∗∈A∗),
• A∗≡{0, 1} are the two possible levels for the dichotomized exposure.
• Ad(a∗) ≡AI(A ∈Da∗) + Aa∗I(A /∈Da∗).
• g(Aa∗= a | W) = I(a ∈Da∗)g(A = a | A ∈Da∗, W) .
• Yd(a∗) ≡YAd(a∗).
The observed data can then be viewed as a censored version of these full data with censoring
variable ∆(a∗) ≡I(A ∈Da∗):
O = (W, A, Y ) = (W, (∆(a∗), ∆(a∗)(Ad(a∗), Yd(a∗)))a∗∈A∗.
Based on this extended counterfactual framework, the following causal parameter β =
(β0, β1) can be deﬁned:
E(Yd(a∗)) = β0 + β1a∗for a∗∈A∗.
This causal parameter represents the eﬀect of a “low” versus “high” exposure to A where
“low” and “high” are deﬁned by the cut-oﬀvalue θ. This parameter can be viewed as
an MSM parameter deﬁned by static interventions on the dichotomized exposure variable
A∗≡I(A > θ) when the observed data are viewed as O∗= (W, A∗, Y ) and the full data
are viewed as X∗= (W, (Ya∗)a∗∈A∗) where Ya∗≡Yd(a∗):
E(Ya∗) = β0 + β1a∗for a∗∈A∗.
Hosted by The Berkeley Electronic Press
Likelihood-based estimation. Under the no unobserved confounder assumption, A ⊥
X | W and the ETA assumption, P(mina∗∈A∗g(A ∈Da∗| W) > 0) = 1, the probability distribution of (W, Ad(a∗), Yd(a∗)) at (w, a, y) is identiﬁable with the observed data distribution
through the following G-computation formula:
P(w, a, y) = PW(w)ga∗(a | w)PY |A,W(y | a, w),
ga∗(a | w)
g(A = a | W = w, A ∈Da∗)
I(a ∈Da∗) g(A = a | W = w)
P(A ∈Da∗| W = w).
Given the marginal distribution of W, PW, the conditional distribution of A given W,
ga∗(implied by g), and the conditional distribution of Y given A and W, PY |W,A, one can
generate the counterfactuals (W, Ad(a∗), Yd(a∗)) as follows: 1) Generate W from PW; 2) Generate Ad(a∗) from distribution (2); 3) generate Yd(a∗) from PY |W,A. By applying this data
generating experiment to an estimate of the data generating distribution, one obtains a
large sample ( ˆWb, ˆAd(a∗),b, ˆYd(a∗,b)), b = 1, . . . , B for all a∗∈A∗which yields a simulationbased estimate of the distribution of (W, Ad(a∗), Yd(a∗)). Such an estimate could now also
be mapped into an estimate of β by least squares regression of the simulated ˆYd(a∗),b on
a∗according to the parametric model m(a∗| β) = β0 + β1a∗. Note that in a simulation
study, the observed data generating distribution is known and thus need not be estimated.
This procedure applied with B very large will thus provide a good approximation of the
true value of the causal parameter of interest in a simulation study. Note that to draw an
observation from distribution (2), one can draw a from g(A | W) until a ∈Da∗. In our simulation study where the conditional distribution of A given W is Gaussian, the conditional
distribution of A given W, ga∗(A | W), corresponds to a truncated normal distribution.
Inverse Weighting estimation. The following estimating function is unbiased for any
non-null function h of I(A > θ):
Dh(O | β, g)
h(I(A > θ))
P(A ∈DI(A>θ) | W)(Y −m(I(A > θ) | β))
I(A ≤θ) h(I(A > θ))
P(A ≤θ | W)(Y −m(I(A > θ) | β)) +
I(A > θ) h(I(A > θ))
P(A > θ | W)(Y −m(I(A > θ) | β))
If the observed data are viewed as O∗then this estimating function can be rewritten as:
Dh(O∗| β, g) =
P(A∗| W)(Y −m(A∗| β)).
If one chooses, h(A∗) = λ(A∗) d
dβm(A∗| β), then the inverse probability of treatment
weighted (IPTW) estimator of β can be obtained with the observed data O∗through a
 
weighted least squares regression of Y on A∗with the parametric model m and weights
P(A∗|W) where λ is any non-null function of A∗, e.g., λ(A∗) = 1 (unstabilized weighting) or
λ(A∗) = P(A∗) (stabilized weighting).
Note that in our simulation study where g(A | W) is known (conditional Gaussian
distribution), one can also derive P(A∗| W) (the discretized exposure mechanism) as
P(A∗= 1 | W)
P(I(A > θ) = 1 | W)
g(a | W)da,
P(A∗= 0 | W)
P(I(A > θ) = 0 | W)
g(a | W)da.
Eﬀect deﬁnition with CMRIER and dichotomized exposure
We deﬁne the following sets of continuous treatment levels for α > 0:
Dw ≡{a∗: P(a∗| w) > α}
where α represents the probability level at which the dichotomized exposure is deemed realistic (e.g., α = 0.1). Similar to the approach taken to extend the counterfactual framework
above, we deﬁne the full data as:
X = (W, (Ad(a∗), Yd(a∗))a∗∈A∗),
• A∗≡{0, 1} are the two possible levels for the dichotomized exposure.
• Ad(a∗) ≡I(a∗∈DW)
AI(A ∈Da∗) + Aa∗I(A /∈Da∗)
+ I(a∗/∈DW)
D1−a∗) + A1−a∗I(A /∈D1−a∗)
• g(Aa∗= a | W) = I(a ∈Da∗)g(A = a | A ∈Da∗, W) .
• Yd(a∗) ≡YAd(a∗).
The observed data can then be viewed as a censored version of these full data with censoring
variable ∆(a∗) ≡I( (a∗∈DW & A ∈Da∗) or (a∗/∈DW & A ∈D1−a∗) ):
O = (W, A, Y ) = (W, (∆(a∗), ∆(a∗)(Ad(a∗), Yd(a∗)))a∗∈A∗.
Hosted by The Berkeley Electronic Press
Based on this extended counterfactual framework, the following causal parameter β =
(β0, β1) can be deﬁned:
E(Yd(a∗)) = β0 + β1a∗for a∗∈A∗.
Likelihood-based estimation. Under the no unobserved confounder assumption, A ⊥
X | W and the ETA assumption, P(mina∗∈A∗P(I(Ad(a∗) > θ) ∈DW)) = 1, the probability distribution of (W, Ad(a∗), Yd(a∗)) at (w, a, y) is identiﬁable with the observed data
distribution through the following G-computation formula:
P(w, a, y) = PW(w)ga∗(a | w)PY |A,W(y | a, w),
ga∗(a | w)
g(A = a | W = w, A ∈Da∗)I(a∗∈Dw)g(A = a | W = w, A ∈D1−a∗)I(a∗/∈Dw)
ga∗(a | w)
I(a ∈Da∗) g(A = a | W = w)
P(A ∈Da∗| W = w)
I(a ∈D1−a∗)
g(A = a | W = w)
P(A ∈D1−a∗| W = w)
¶I(a∗/∈Dw)
Similar to the procedure described in the previous section with MSM, given the marginal
distribution of W, PW, the conditional distribution of A given W, ga∗(implied by g), and
the conditional distribution of Y given A and W, PY |W,A, one can generate the counterfactuals (W, Ad(a∗), Yd(a∗)) to obtain a large sample ( ˆWb, ˆAd(a∗),b, ˆYd(a∗),b), b = 1, . . . , B for all
a∗∈A∗which yields a simulation-based estimate of the distribution of (W, Ad(a∗), Yd(a∗)).
Such an estimate could now also be mapped into an estimate of β by least squares regression of the simulated ˆYd(a∗),b on a∗according to the parametric model m(a∗| β) = β0+β1a∗.
Note that in a simulation study, the observed data generating distribution is known and
thus need not be estimated. This procedure applied with B very large will thus provide
a good approximation of the true value of the causal parameter of interest in a simulation study. Note that to draw an observation from distribution (2), one can draw a from
g(A | W) until i) a ∈Da∗if a∗∈DW or ii) a ∈D1−a∗if a∗/∈DW.
Inverse Weighting estimation. The following estimating function is unbiased for any
non-null function h of I(A > θ):
Dh(O | β, g)
P(A ∈DI(A>θ) | W)h(I(A > θ))(Y −m(I(A > θ) | β))
If the observed data are viewed as O∗then this estimating function can be rewritten as:
Dh(O∗| β, g) =
P(A∗| W)h(A∗)(Y −m(A∗| β)).
If one chooses, h(A∗) = λ(A∗) d
dβm(A∗| β) (see previous section regarding choices for
λ(A∗)), then the inverse probability of treatment weighted (IPTW) estimator of β can
be obtained with the observed data O∗through weighted least squares regression of Y
on A∗with the parametric model m where every observation in O∗is repeated for each
a∗∈A∗and each such repeated observation is weighted separately with
P(A∗|W)λ(A∗) for more details).