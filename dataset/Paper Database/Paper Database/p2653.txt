Conditional Adversarial Network for Semantic
Segmentation of Brain Tumor
Mina Rezaei, Konstantin Harmuth, Willi Gierke, Thomas Kellermeier, Martin
Fischer, Haojin Yang, Christoph Meinel
Hasso Plattner Institute for Digital Engineering,
Prof.-Dr.-Helmert-Strae 2-3, 14482 Potsdam, Germany
{mina.rezaei,haojin.yang,christoph.meinel}@hpi.de{konstantin.harmuth,
willi.gierke,thomas.kellermeier,martin.fischer}@student.hpi.uni-potsdam.
Abstract. Automated medical image analysis has a signiﬁcant value
in diagnosis and treatment of lesions. Brain tumors segmentation has a
special importance and diﬃculty due to the diﬀerence in appearances
and shapes of the diﬀerent tumor regions in magnetic resonance images. Additionally the data sets are heterogeneous and usually limited
in size in comparison with the computer vision problems. The recently
proposed adversarial training has shown promising results in generative
image modeling. In this paper we propose a novel end-to-end trainable
architecture for brain tumor semantic segmentation through conditional
adversarial training. We exploit conditional Generative Adversarial Network (cGAN) and train a semantic segmentation Convolution Neural
Network (CNN) along with an adversarial network that discriminates
segmentation maps coming from the ground truth or from the segmentation network for BraTS 2017 segmentation task . We also propose an end-to-end trainable CNN for survival day prediction based on
deep learning techniques for BraTS 2017 prediction task . The
experimental results demonstrate the superior ability of the proposed approach for both tasks. The proposed model achieves on validation data
a DICE score, Sensitivity and Speciﬁcity respectively 0.68, 0.99 and 0.98
for the whole tumor, regarding online judgment system.
Keywords: Conditional Generative Adversarial Network, Brain Tumor
Semantic Segmentation, Survival day prediction
Introduction
Medical imaging plays an important role in disease diagnosis and treatment planning as well as clinical monitoring. The diversity of magnetic resonance imaging
(MRI) acquisition regarding its settings (e.g. echo time, repetition time, etc.) and
geometry (2D vs. 3D) also the diﬀerence in hardware (e.g. ﬁeld strength, gradient performance, etc.) can yield variation in the appearance of the tumors that
makes the automated segmentation challenging . An accurate brain lesion segmentation algorithm based on multi-modal MR images might be able to improve
 
M.Rezaei et al.
the prediction accuracy and eﬃciency for a better treatment planning and monitoring the disease progress. As mentioned by Menze et al. , in last few decades
the number of clinical study for automatic brain lesion detection has grown signiﬁcantly. In the last three years, Generative Adversarial Network(GAN) 
become a very popular approach in various computer vision studies for example
for classiﬁcation , object detection , video prediction , image segmentation and even mass segmentation for mammogram analysis .
In this work we address two tasks by BraTS-2017 challenges by two
diﬀerent approaches. Semantic segmentation is the task of classifying parts of
images together that belong to the same object class. Inspired by the power
of cGAN networks , we propose an end-to-end trained adversarial deep
structural network to perform brain High and Low Grade Glioma (HGG/LGG)
tumor segmentation. We also illustrate how this model could be used to learn
a multi-modal images, and provide preliminary results of an application for semantic segmentation. To this end we consider patient-wise ”U-Net” as a
generator and ”Markovian GAN” as an discriminator. For the second task
of BraTS-2017 , we designed an end-to-end trainable CNNs on clinical
data which enables to predict the survival day. The architecture use parallel
CNN which one way is responsible to learn patient-wise MR images and another
learned representation of clinical data. A detailed evaluation of the parameters
variations and network architecture is provided. The contribution of this work
can be summarized as following:
– We proposed a robust solution for brain tumors segmentation through conditional GAN. We achieved promising results on two type of brain tumor
segmentation (The overall Dice for whole-tumor region is 0.68, Speciﬁcity
0.99 and Sensitivity 0.98).
– We proposed an automatic and trainable deep learning architecture for survival day prediction based on clinical data and MR images.
The rest of the paper is organized as follows: Chapter 2 describes the proposed
approaches for semantic segmentation and survival day prediction, Chapter 3
presents the detailed experimental results. Chapter 4 concludes the paper and
gives an outlook on future work.
Methodology
In this chapter we will describe ﬁrst our proposed approach to the brain tumor
sub-region segmentation based on deep learning and then our approach to the
survival day prediction. The core techniques applied in our approach are depicted as well. In the GAN theory , the Discriminator Network (D) tries to
decide if a certain input is sourced from the reference distribution, or has been
generated by the Generator Network (G). The training procedure in G uses the
pixel labels of certain multi-modal images and D tries to distinguish this certain
boundary regions (we have three sub region tumor) comes from reference distribution or generative network. In order to incorporate more classes to this output
cGANs for Semantic Segmentation of Brain Tumor
Fig. 1. The proposed architecture for semantic segmentation of brain tumor
while keeping with the GAN spirit of distinguishing distribution class instead
of one example class, we could add additional input sources. As suggested by
Goodfellow , one can consider the cGAN models with multi-class labels as:
1. GAN model with class-conditional models: which make the input label rather
than the output. We ask GAN to generate specic classes. 
2. GAN model with N diﬀerent output classes: that network trained by N
diﬀerent ”real” and no ”fake” classes. 
3. GAN models with N+1 diﬀerent output classes: which the network train by
N diﬀerent ”real” and an additional ”fake” class. This type works very well
for semi-supervised learning when it combined with feature matching GANs
Therefor our proposed method lies in the second category as we consider for each
multi-modal image three segmentation classes. Figure 1 describes the proposed
approach to the brain tumor segmentation. In continue we describe the detail of
techniques of pixel label classes for prediction in section 2.1 and for survival day
prediction in section 2.2.
Brain Tumor Semantic Segmentation
We adapt the generator and discriminator architectures from . We applied Virtual-BatchNorm-Convolution on generator network to make the ”U-
Net” patient-wise. We choose ”U-Net” architecture as generator because
most of the deep learning approaches are patch-wise learning models, which
ignore the contextual information within the whole image region. Like winner
of BraTS-2016 , we come over this problem by leveraging global-based CNN
methods (e.g. Seg-Net, Encoder-Decoder and FCN) and incorporating multimodal of MRI data. We use Virtual-BatchNorm in the generator network
and Reference-BatchNorm in the discriminator network to reduce over-ﬁtting.
M.Rezaei et al.
The discriminative network is based on ”Markovian GAN” . Then two models
trainable simultaneously through back propagation, corresponds to a minimax
two-player game. An ”U-Net” generative model G; Captures the data distribution, pixel segmentation and train to minimize the probability of D making a
mistake. A ”Markovian GAN” discriminative model D: to estimate the probability that a sample came from the training data rather than G.
Survival Day Prediction
Figure 2 describes our solution for survival day prediction. We proposed a two
path way architecture which one has several CNN and it is responsible for multimodal image representation and another learned the clinical data features. The
extracted features from each path way, concatenated in next step to shared
the learned features. Then they passed to two fully connected layers to learn
the survival day. We use Virtual-BatchNorm on the CNNs network which
learned image representation. To prevent over-ﬁtting, we generated augmented
images through horizontal and vertical ﬂipping and re-scaling. We applied Mean
squared error as Loss function. We mapped the clinical data (Ages and survival
days) into ﬂoat .
Experiments
In order to evaluate the performance of the proposed cGANs method, we test
the method on two types of brain tumor data provided by BraTs 2017 challenge . We applied a bias ﬁeld correction on the MR images to correct
the intensity non-uniformity in MR images by using N4ITK . In next step of
pre-processing we applied histogram matching normalization . We train both
the generator and the discriminator to make them stronger together and avoid
making one network signiﬁcantly stronger than the other by taking turn. We
consider multi-madal images from same patient in each batch during training
and use all the released data by BraTS 2017 challenge in training time
which is 75 patients with Low Grade Glioma(LGG) and 210 patients with High
Grade Glioma(HGG). We used all prepared image-modal from three axes of x,y,z
(3x4x155x285) that the input and output are 4-3 channel images(4:image-modal;
3:three sub-region of each tumor type). We get better result when don’t shuﬄe
input data in generator network. In generator network Sign function helps for
noise reduction. The generator for all layers use ReLU activation function except
output layer which use Tanh. Qualitative results are shown in Figures 3. On this
size data sets (530100 2D images with the size of 250x250) training took around
72 hours on parallel Pascal Titan X GPUs. Table 11 shows the results of the
proposed models evaluated at BraTS 2017 online judge system. The evaluation
system uses three tasks. The online system provides the results as follows: The
tumor structures are grouped in three diﬀerent tumor regions. This is mainly due
to practical clinical applications. As described by BraTS 2017 , tumor
regions are deﬁned as:
cGANs for Semantic Segmentation of Brain Tumor
Fig. 2. The propose architecture for survival day prediction
M.Rezaei et al.
1. WT: Whole tumor region represents the area with all labels 1,2,3,4 which 0
for normal tissue, 1 for edema, 2 for non-enhancing core, 3 for necrotic core,
4 shows enhancing core.
2. CT: Core tumor region represent only tumor core region, it measures label
3. ET: Enhancing tumor region (label 4)
There are four kinds of evaluation criteria for segmentation task like Dice
score, Hausdorﬀdistance, Sensitivity and Speciﬁcity has provided by BraTS
2017 challenge organizer as an online judgment system.
Table 1. Preliminary results till now from BraTS-2017 online judge system on Validation data(unseen data)
Whole Tumor Core of Tumor Enhanced Tumor
Sensitivity 0.68
Speciﬁcity 0.99
Fig. 3. The output segmentation result on training data
Table 1 shows the preliminary results but our work is still on the progress.
Table2 shows the survival day prediction results.
Table 2. Preliminary results on survival day prediction. We used 70% of the data
(115 patients) for training, 10% (16 patients) for validation and 20% (32 patients) for
testing. The ﬁrst path way of CNN has seven input channel which four from multimodal images and three from segmented regions. We translated ages from interval into ﬂoat and also for survival day did from days into ﬂoat of .
Validation 73.1%
cGANs for Semantic Segmentation of Brain Tumor
Fig. 4. The output segmentation result on training data
Fig. 5. The preliminary segmentation result on validation data
Fig. 6. clinical data distribution from training set
M.Rezaei et al.
Fig. 7. diﬀerent regression techniques (e. g. Support Vector Regression, Polynomial
Regression, ) for survival day prediction.
Conclusion
In this paper, we propose and evaluated approaches for two important clinical tasks: brain tumor segmentation and prediction of survival day after tumor
diagnosis. The proposed approach for tumor segmentation is end-to-end trainable based on the newly proposed conditional generative adversarial network.
Furthermore, adversarial training is used to handle the global-based CNN in
generator to reduce over-ﬁtting and increase robustness. We proposed an automated trainable parallel convolution neural network to predict the survival day
as the second task in the challenge. These networks learn a loss adapted to the
task and data at hand, which makes it applicable in unseen data. For the future
work, we look for further improvement on generative network by incorporating
recurrent neural network(RNN) inside of our Encoder-Decoder.