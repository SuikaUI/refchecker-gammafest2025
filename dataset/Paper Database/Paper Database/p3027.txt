HAL Id: hal-01588611
 
Submitted on 15 Sep 2017
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of scientific research documents, whether they are published or not.
The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Distributed under a Creative Commons Attribution - ShareAlike 4.0 International License
An application of MCMC methods for the multiple
change-points problem
Marc Lavielle
To cite this version:
Marc Lavielle. An application of MCMC methods for the multiple change-points problem. Signal
Processing, 2001, 81, pp.39-53. ￿10.1016/S0165-1684(00)00189-4￿. ￿hal-01588611￿
1Also at UniversiteH Paris-V, France.
*Corresponding author. Tel.: #33-1-6915-5743; fax: #33-
1-6915-7234.
E-mail addresses: (M. Lavielle),
 (E. Lebarbier).
Signal Processing 81 39}53
An application of MCMC methods for the multiple
change-points problem
M. Lavielle*,1, E. Lebarbier
Equipe de Probabilite&s, Statistique et Mode&lisation, Universite& Paris Sud, BaL t 425, 91400 Orsay, Cedex, France
Received 1 May 1999; received in revised form 10 April 2000
We present in this paper a multiple change-point analysis for which an MCMC sampler plays a fundamental role. It is
used for estimating the posterior distribution of the unknown sequence of change-points instants, and also for estimating
the hyperparameters of the model. Furthermore, a slight modi"cation of the algorithm allows one to compute the
change-points sequences of highest probabilities. The so-called reversible jump algorithm is not necessary in this
framework, and a very much simpler and faster procedure of simulation is proposed. We show that di!erent interesting
statistics can be derived from the posterior distribution. Indeed, MCMC is powerful for simulating joint distributions,
and its use should not be restricted to the estimation of marginal posterior distributions, or posterior means. , and
many theoretical results have been obtained in
various contexts, (see, for example, ).
Among the di!erent approaches, we can mention
the on-line (or sequential) detection of changepoints.
sequence of change-points instants can be estimated by minimizing a well-suitable contrast
function (see ). We shall adopt here a Bayesian
approach. Then, the change-point problem consists
mainly in estimating the posterior distribution of
change-points
example, to estimate the probability that a change
has occurred at a given instant t. The posterior
distribution of the number of changes can also be
derived. The maximum a posteriori (MAP) estimator is obtained by maximizing this posterior
distribution. When the changes a!ect the mean of
the signal, we show that the MAP estimator is
a penalized least-squares estimator, that possesses
good statistical properties .
An MCMC method is really suitable for estimating the posterior distribution of the change-points
sequence. The reversible jump algorithm proposed
0165-1684/01/$- see front matter 0 0 1 8 9 - 4
by Green , is based on the fact that the dimension of the model can change, according to the
number of segments. Unfortunately, this algorithm
converges slowly, and many iterations are needed
for estimating correctly the posterior distribution.
Another parametrization is shown to be more
appropriate than the sequence (qk) of change points.
It consists in introducing a sequence (rt) that takes
the value 1 at the change-points instants, and 0 between two jumps. The advantage of this parametrization is that the dimension of the sequence r is
"xed. When the length of the observed signal is n,
the Hastings}Metropolis method proposed in this
paper simply consists in sampling sequences of
0 and 1, of "xed length n!1. Furthermore, running this algorithm at a low temperature allows to
estimate the most likely con"gurations of changes.
An hybrid MCMC algorithm, combining the basic
Hastings}Metropolis algorithm with the Gibb's
sampler , can be used for estimating also the
distribution of the mean sequence. Nevertheless, we
show that the posterior expectation of the mean is
not appropriate in this context, since it yields
a smooth version of the signal, instead of a step
function. The distribution of the mean sequence,
conditionally to the most likely con"guration of
change-points, has more sense, and provides a good
estimation. At the end, we show that another slight
modi"cation of our MCMC algorithm allows to
estimate the hyper-parameters of the model. The
stochastic approximation of expectation maximization (SAEM) procedure proposed by Delyon et al.
 merely consists in updating the set of hyperparameters at each iteration of MCMC. This algorithm converges to a maxima of the likelihood, and
provides automatically a `gooda prior distribution
for the unknown sequences.
The paper is organized as follows. Section 2 describes the model of change-points in the mean and
details the prior modelling. The Hastings}Metropolis samplers used for estimating the posterior
distribution of the change-points instants are described in Section 3. Section 4 addresses the
problem of recovering also the sequence of means,
and the reversible jump algorithm is presented.
Section 5 is dedicated to the SAEM algorithm,
for the estimation of the hyper-parameters of the
2. Model and notations
Let y"(yt, t*1), be a real process such that, for
yt"s(t)#et,
where (et, t*1) is a sequence of zero-mean random
variables. Here, the function s to recover is assumed
to be piecewise constant. Thus, there exists some
instants (qk, k*0), such that the function s is constant between two successive change-points instants. In other words, there exists a sequence
(mk, k*1) such that, for any k*1,
for all qk~1#1)t)qk
with the convention q0"0.
As already suggested by Lavielle or Tourneret et al. , it is convenient to introduce
a change-points process (rt, t*1) that takes the
value 1 at the change instants and is zero between
two changes:
if there exists k such that t"qk,
otherwise.
The estimation of the change-points instants reduces to the estimation of the sequence (rt). Then,
the unknown function s will be recovered by estimating the sequences (rt) and (mk).
To solve this inverse problem, we shall adopt
a Bayesian approach. That means, we have to de-
"ne the distribution of the non-observed sequences,
conditionally to the set of observations. This distribution is usually called the posterior distribution
and requires to de"ne "rst the prior distribution of
(rt) and (mk).
Assume that the observed sequence (yt) is available between instants t"1 and n. First, we
consider that (rt) is a sequence of independent
and identically distributed (i.i.d.) Bernoulli random variables with parameter j. Then, for any
r"(rt, 1)t)n!1) in X"M0,1Nn~1,
n(r; j)"j&n~1
t/1 rt (1!j)n~1~&n~1
On the other hand, (s(t), 1)t)n) is modeled as
a sequence of i.i.d. Gaussian random variables with
M. Lavielle, E. Lebarbier / Signal Processing 81 39}53
mean k and variance <. Then,
p(s(1),2, s(n);k,<)
(2p<)~1@2 expG! 1
2<(s(t)!k)2H.
For a given con"guration of change-points r,
rt is the number of change-points. Then, let
rt#1 be the number of segments,
nk"qk!qk~1 be the length of segment k and
m"(mk,1)k)Kr) be the vector of means. Then,
p(mDr;k, <)"p(m1,2,mKr Dr;k, <)
"p(s(1),2, s(n), s(t)"mk,
qk~1#1)t)qk,
1)k)Kr;k, <)
~1@2 expG! nk
2<(mk!k)2H.
Thus, the mk's are independent, and mk is Gaussian
with mean k and variance </nk.
On the other hand, (et, t*1) is assumed to
be a sequence of independent Gaussian random
variables with mean 0 and variance p2. Thus,
the conditional distribution of the observations is
h(yDr,m;p2)
"(2pp2)~n@2 expG! 1
(yt!mk)2H.
Let h"(k, j, <,p2) be the set of hyper-parameters of the model. Then, the prior distribution of
(r, m) is given by
p(r, m;h)"p(mDr; k, <)p(r;j),
the complete likelihood of (y, r, m) is
f (y, r, m;h)"h(yDr, m;p2)p(mDr;k, <)p(r;j),
and the posterior distribution of (r, m) can be decomposed as
p(r, mDy;h)"p(rDy;h)p(mDy, r;h).
For a given value of r, the conditional distribution of m is easy to compute. Indeed, let
t/qk~1`1yt be the empirical mean of y in
segment k. Then, Eqs. (6) and (7) yield
p(mDy,r;h)
(2p<k)~1@2 expG! 1
(mk!kk)2H,
Thus, conditionally to the observations, the mk's
remain independent and Gaussian (a short demonstration of these formulae is given in Appendix A).
The following Lemma gives the posterior distribution of r:
Lemma 1. For any conxguration of change-points
be the number of segments and let
t/qk~1`1(yt!y6 k)2. Then, the posterior
distribution of r is dexned by
p(rDy;h)"C(y,h)expM!/Sr!cKrN
2p2(p2#<),
and where C(y,h) is a normalizing constant.
(The proof of the Lemma is in Appendix A.)
Remark. (1) It is important to insist on the fact that
the posterior distribution p(rDy;h) is the joint distribution of a vector of size n!1. Thus, it cannot be
used as it stands and should be summarized to
some characteristics. Between many others, we can
consider the following characteristics:
f For any 1)t)n!1, the marginal posterior
distribution p(rtDy;h) gives the probability to have
M. Lavielle, E. Lebarbier / Signal Processing 81 39}53
a change-point at instant t, conditionally to the
observations.
f The MAP estimator is the particular value of
r that maximizes p(rDy;h). In other words, it is the
most likely con"guration of change-points, according to the prior and to the observations.
f For any instants qa and qb,P(+qbt/qa rt"kDy;h) is
the probability to have exactly k change-points
between these two instants. In particular, when
qa"1 and qb"n!1, we consider the posterior
distribution of the total number of changepoints.
(2) The posterior distribution of r can be written
p(rDy;h)"C(y,h)expM!;h(y, r)N,
where ;h(y, r)"/Sr#cKr is a penalized contrast,
usually called energy function, and which is the sum
of two terms: the "rst term Sr, measures the "delity
to the observations y while the second term
Kr corresponds to a penalization term, related to
the number of change-points. The coe$cients
/ and c indicate the relative weights given to these
two criteria. A small value of c in front of / favours
con"gurations with a large number of changepoints, while a big value of c penalizes such con"gurations. The MAP estimator of r minimizes the
energy function ;h(y, r). In this particular example,
the MAP estimator reduces to a penalized leastsquares estimate. We can mention that theoretical
results concerning this estimator have been obtained by Lavielle and Moulines under very
general conditions.
(3) Unfortunately, the normalizing constant
C(y,h) in (14) and (15) cannot be computed, since it
is the sum over all the possible con"gurations r
of expM!;h(y, r)N, that is, a sum of 2n~1 terms. In
other words, the posterior distribution of r is
known up to this constant and a Markov chain
Monte-Carlo method should be used to sample it
and estimate some of its characteristics.
The Hastings}Metropolis algorithm
3.1. The basic algorithm
The main idea of this algorithm is to generate an
ergodic Markov chain (r(i), i*0) so that p( ) D y;h) is
stationary
distribution.
Theorem implies that, for any measurable function f,
is a strongly consistent estimator of E( f (r)Dy;h), i.e.
fMN converges almost surely to E( f (r)Dy;h) when
NPR (see, for example, ).
An interesting application of this result is the
estimation of probabilities of speci"ed events, when
f is an indicator function. For example, the marginal posterior distributions of the rt's and the
posterior distribution of the number of segments
Kr, can easily be estimated. Indeed, for any
1)t)n!1 and any k*0,
r(i)t PP(rt"1Dy;h)
1(K(i)r /k)PP(Kr"kDy;h)
where K(i)r "+n~1
t/1r(i)t #1 is the number of segments in the con"guration r(i).
The Hastings}Metropolis algorithm is an iterative procedure. At iteration i, we carry out the
following two steps:
f an admissible new value r8 is drawn from a proposal kernel q(r(i),r8 )
f r8 is accepted as the new state, i.e. r(i`1)"r8 , with
the following probability:
a(r(i),r8 )"minG1, p(r8 Dy;h)
p(r(i)Dy;h)
q(r8 , r(i))
q(r(i),r8 )H.
Remark. (1) If the kernel q is irreducible, then the
Markov chain (r(i)) is irreducible. Furthermore, the
aperiodicity of the chain is ensured if there exists
two con"gurations (r, r@) such that a(r, r@)(1.
Under these conditions, the chain (r(i)) is uniformly
ergodic, since it takes its values in a "nite space.
(2) An initial burn-in period is introduced before
collecting samples, so that the estimation weakly
depends on the initial guess (see ). If Nb is the
length of this burn-in period, then, the estimator of
M. Lavielle, E. Lebarbier / Signal Processing 81 39}53
E( f (r)Dr;h) proposed in (16) is replaced by
(r, r@), let
*;(r, r@)";h(y, r@)!
;h(y, r). Then, (15) yields
p(rDy;h) "e~*U(r,r{).
Since the energy ;h(y, r) is a sum of local potentials, a local perturbation of the current state r(i) will
a!ect few terms of this sum and the probability of
acceptance a(r(i), r8 ) will be easy to compute.
3.2. The proposal kernels
As it is mentioned just above, any irreducible
proposal kernel q can be used. From a practical
point of view, it is important to allow more communications between the states of high probability
in order to increase the convergence speed. In our
example of application, that can be done by using
successively the following three kernels at each
iteration:
1. q1 is such that the candidate r8 is drawn independently of the current state r: q1(r,r8 )"p(r8 ;h). Let
b"12 log((p2#<)/p2). Then, we obtain
a(r,r8 )"minM1, expM!/(Sr8 !Sr)
!b(Kr8 !Kr)NN.
2. q2 is such that a new change-point is created or
an existing change-point is removed. An instant
s is chosen randomly in M1,2, n!1N and we set
r8 t"rt for all tOs while r8 s"1!rs. The acceptance probability turns out to be
a(r,r8 )"minM1, expM!/[Sr8 !Sr]$cNN.
3. With the third considered kernel q3, an existing
change-point instant is moved. Two instants
(s, s@) are randomly chosen such that rs"1 and
rs{"0. Then, r8 t"rt for all tOs, s@ while r8 s"0
and r8 s{"1. In this case, the acceptance probability is
a(r,r8 )"minM1, expM!/(Sr8 !Sr)NN.
We propose an example to illustrate this algorithm. We simulate a sequence y"(y1,2, yn) with
n"500. There are four change-points at q1"75,
q2"150, q3"250, and q4"400. The vector of
mean is m"(0.125, 0.5, 0.4, 0.5, 0.125). The variance
of the additive noise is p2"0.1. The observed series
and the mean are plotted in Fig. 1(a) and (b).
First of all, because the set of hyper-parameters
h is unknown, it is estimated by using the SAEM
procedure described in Section 5. Then, the estimated value hK "(jK ,k( ,<K ,p( 2)"(0.012, 0,346, 2.688,
0.106) is used in the MCMC algorithm. We run the
MCMC algorithm with 5000 burn-in iterations.
The estimations of the marginal posterior probabilities
MP(rt"1Dy;h)N
and 150 000 iterations are plotted in Fig. 2. The
posterior distribution of the number of segments
Kr is displayed Fig. 2c (estimated after 150 000
iterations).
First of all, we can remark that the estimations
obtained after 15 000 iterations are closed to those
obtained after 150 000 iterations. That means that
this algorithm converges quite quickly, and only
`few iterationsa are enough to detect very well the
four change-points. Theoretical aspects concerning
the convergence control of MCMC methods can be
found in .
These diagrams can be seen as histograms
around each change-points. For example, we obtain a very accurate estimation of the position of
the "rst change-point (at 75) since the estimated
posterior distribution of r is very spiky around
this instant: the estimates of P(r75"1Dy;h) and
P(r76"1Dy;h), obtained with 150 000 iterations,
are, respectively, 0.42 and 0.49. On the other hand,
the jumps of the mean are smaller at 150 and 250,
and the detection of these two change-points is not
so accurate: the estimated marginal probabilities
are very small around 150 and 250 (around 0.1).
Nevertheless, the probability of a change-point is
very high in a neighborhood of these two instants.
For example, the estimated probability to have
a change point in the interval (resp.
 ) is 0.85 (resp. 0.77).
In other words, it is not convenient to apply
directly a threshold on the sequence of estimated
marginal probabilities MP(rt"1Dy;h)N, for detecting
the change-points. A "rst solution consists in estimating the probability to have a change-point in an
interval, instead of an instant. Of course, the
M. Lavielle, E. Lebarbier / Signal Processing 81 39}53
Fig. 1. (a) The observed signal y and (b) the mean of y and the change-point instants.
distribution
Hastings}Metropolis algorithm.
distributions
MP(rt"1Dy;h), 1)t)n!1N estimated with: (a) 15 000 iterations, (b) 150000 iterations and (c) the posterior distribution of the number
Kr of segments.
M. Lavielle, E. Lebarbier / Signal Processing 81 39}53
positions of the change-points will not be precisely
estimated with this method. To overcome this loss
of accuracy, a second approach consists in estimating
the con"gurations of change-points of higher probability. That can easily be done, by using a slight
variation of the Hastings}Metropolis algorithm.
3.3. Running the Hastings}Metropolis algorithm at a
low temperature
For any ¹'0, we can consider the distribution
pT( ) Dy;h), based on the original distribution p( ) Dy;h),
and de"ned as follows:
pT(rDy;h)"CT(y;h) expG!;h(y, r)
"CT(y;h) expG!/
The role of the parameter ¹ (usually called temperature) is mainly to discriminate the global and
the local maxima of the posterior distribution
p( ) Dy;h). Indeed, any maximum (local or global) of
p( ) Dy;h) is a minimum of ;h(y, r), and also a maximum of pT( ) Dy;h). However, pT(rDy;h)P0 when
¹P0 if r is not a global maximum. Thus, when
¹P0, pT( ) Dy;h) converges to the uniform distribution on the set of global maxima of p( ) Dy;h).
The Hastings}Metropolis algorithm described
above can be used for simulating pT( ) Dy;h). Indeed,
from (26), the only modi"cation to introduce in the
algorithm is the replacement of the parameters (/,c)
by (//¹,c/¹).
The simulated annealing algorithm consists in
using a sequence of temperatures (¹i) that decreases at each iteration. Then, the Markov chain
(r(i)) is no longer homogeneous, and converges to
the global maxima of p( ) Dy;h) (the MAP estimator)
if ¹i behaves like ¹0/log(i) (see ). Unfortunately, this schedule of temperature cannot be used
in the practice, since it would require a very large
number of iterations.
In fact, there exists a very e$cient and attractive
alternative for detecting the most likely con"guration of change-points. It consists merely in running
the Hastings}Metropolis algorithm at a "xed low
temperature ¹.
We can observe the in#uence of a low temperature on the chain's construction during the
algorithm: consider two states r and r@ such
that ;h(y, r)(;h(y, r@). When ¹ tends to 0,
expM!(;h(y, r@)!;h(y, r))/¹N tends to 0. So a(r, r@)
tends to 0 and a move from r to r@ has a very low
probability. Consequently, when ¹ is a low temperature, the Hastings}Metropolis algorithm will
favor the con"gurations of change-points of highest
probabilities.
To set ¹"0 leads to the so-called iterative conditional modes (ICM) algorithm (see ). This
deterministic procedure usually leads to a local
minima of the posterior distribution of r.
On the other hand, for any ¹'0, the Markov
chain (r(i)) simulated with this algorithm remains
homogeneous and ergodic: its distribution converges to pT( ) Dy;h).
Fig. 3 shows the results obtained with three temperatures: ¹"0.5, 0.2 and 0.01. Looking at these
results, we can make two main remarks:
1. The false alarms are removed, and only the main
events are left. Even a `higha temperature, such
as ¹"0.5, cleans the results. With ¹"0.5, the
estimated probability to have "ve segments is
0.97. This estimated probability is 1 for ¹)0.3.
That clearly shows that the most likely con"gurations are made up of "ve segments.
2. When the temperature decreases, the posterior
distribution becomes more and more concentrated around the MAP estimator of the
change-points instants. In this example, the
MAP is q( "(q( 1,q( 2,q( 4,q( 4)"(76, 147, 256, 400).
4. The estimation of the mean
Assume now that we are interested in the joint
distribution
m"(mk) and the change-points instants q"(qk) (or
r"(rt), according to the parametrization), instead
of the posterior distribution of q. One iteration of
the Hastings}Metropolis algorithm will consist
now in drawing a candidate (m8 ,q8 ) (or (m8 ,r8 )), with
a new proposal b, and to accept it with a probability a((m(i),q(i)), (m8 ,q8 )). Di!erent approaches can be
adopted for choosing a proposal b.
M. Lavielle, E. Lebarbier / Signal Processing 81 39}53
Fig. 3. Running the Hastings}Metropolis algorithm at a low temperature: (a) ¹"0.5, (b) ¹"0.2 and (c) ¹"0.01.
4.1. The reversible jump MCMC algorithm
A "rst approach is the so-called reversible jump
algorithm, proposed by Green . This method is
an adaptation of MCMC algorithms, when the
dimensionality of the parameter vector is not "xed.
Then, the Markov chain can `jumpa between models with parameter spaces of di!erent dimensions.
As before, di!erent kernels should be used. For
example, we can make use of the four following
1. One of the mean mk is randomly changed. The
proposed mean m8 k is such that log(m8 k/mk) is
uniformly distributed on [!12;12], in order to
avoid big jumps.
2. A change-point is added in segment k. The position q8 k is drawn uniformly in [qk~1#1,qk!1].
The mean mk is split into two means m8 k and
m8 k`1 such that
(q8 k!qk~1)m8 k#(qk!q8 k)m8 k`1"nkmk,
where nk"qk!qk~1 is the length of segment k.
This condition is satis"ed with
m8 k"mk!uS
m8 k`1"mk#uS
where u is uniformly distributed on the interval
[!0.2,0.2], for the same reason as in the "rst
3. A change-point qk is removed. Then, the means
mk and mk`1 are replaced by a unique m8 k such
(nk#nk`1)m8 k"nkmk#nk`1mk`1.
4. A change-point qk is moved. A new position q8 k is
drawn uniformly on [qk~1#1,qk`1!1] and
the means remain unchanged.
At each iteration, an independent random choice
is made between these four move types. These have
probabilities 0.3 for the moves 1 and 4, and 0.2 for
two others.
M. Lavielle, E. Lebarbier / Signal Processing 81 39}53
Fig. 4. The posterior distributions of (r, m) estimated with the Reversible Jump algorithm. The marginal distributions
MP(rt"1Dy;h), 1)t)n!1N estimated with: (a) 15 000 iterations, (b) 150 000 iteration, (c) (-) the posterior mean of m; (- -) the posterior
mean of m, conditionaly to Kr"5.
Following Green , the probabilities of
acceptance can be computed for these di!erent
kernels. The formulae are given in Appendix B.
We applied this algorithm on the same series y
displayed Fig. 1a. Fig. 4 presents the estimation of
the probabilities MP(rt"1Dy;h)N after 15 000 and
150 000 iterations. Comparing Fig. 4a with Fig. 2a,
we remark that the reversible jump algorithm converges much more slowly than the Hastings}
Metropolis algorithm described in the previous
section. Indeed, we are now simulating a pair of
variables (m, r) instead of simulating only r. The
introduction of a new (continuous) variable to
sample slows down the algorithm.
One explanation is the fact that the reversible
jump algorithm does not take use of the natural
p(m, rDy;h)"p(rDy;h)p(mDr,y;h)
for its proposal kernels, and many candidates (m8 ,r8 )
are rejected. Then, a big amount of iterations are
required for estimating correctly the posterior distribution of interest.
4.2. An hybrid algorithm
A second approach consists in combining the
Hastings}Metropolis algorithm described in Section 3.1 for simulating r, with the Gibb's sampler
 for simulating m.
The proposal kernels are de"ned by
b((m(i),q(i)), (m8 ,q8 ))"qi(q(i),q8 )p(m8 Dq8 , y;h),
where qi is one of the proposal kernels de"ned in
Section 3.2. Then, the probability of acceptance is
a(m(i),q(i),(m8 ,q8 ))
"minG1, p(m8 ,q8 Dy;h)
p(m(i),q(i)Dy;h)
b((m8 ,q8 ),(m(i),q(i)))
b((m(i),q(i)),(m8 ,q8 ))H
"minG1, p(q8 Dy;h)
p(q(i)Dy;h)
qi(q8 ,q(i))
qi(q(i),q8 )H.
That means that the probability of acceptance does
not depend on the mean vectors m(i) and m8 , but
only on the con"gurations of changes r(i) and r8 . In
other words, we use the Hastings}Metropolis
M. Lavielle, E. Lebarbier / Signal Processing 81 39}53
algorithm described in Section 3.1 for generating
the sequence (r(i)), while m(i) is drawn at iteration
i with the conditional distribution p(mDr(i), y;h). This
algorithm was shown to converge much more faster
than the Reversible Jump algorithm, since a very
good approximation of the marginal posterior
probabilities MP(rt"1Dy;h)N is obtained after only
15 000 iterations (see Fig. 2a).
4.3. What can we do with a joint distribution?
algorithms
chains (s(i), r(i)) that converge to the joint posterior
distribution p(s, rDy;h). Once more, this joint distribution cannot be described completely, but should
be reduced to some interesting and tractable characteristics. Most of the times, MCMC is only used
for estimating the posterior mean of the non observed variable. In our context, that would mean to
estimate E(s(t)Dy;h), 1)t)n, by the empirical
mean N~1+Nb`N
i/Nb`1s(t)(i) (or eventually, by using
the Rao}Blackell version described in ). This
estimated posterior mean is displayed Fig. 4.
Unfortunately, this posterior mean is uninteresting in our context. Indeed, let X"M0,1Nn~1 be the
set of possible con"gurations of change-points.
Then, the marginal posterior distribution p(sDy;h)
is the sum of the joint posterior distributions
p(s, rDy;h), over all the possible con"gurations:
p(sDy;h)"+
p(s, rDy;h)
and the posterior mean can also be decomposed as
weighted sum of conditional means, over all the
possible con"gurations:
E(sDy;h)"+
E(sDr, y;h)p(rDy;h).
That means, we are mixing con"gurations without
any change-points with con"gurations with one,
two, 10 or more change-points. Then, the meaning
of this posterior mean is not obvious at all.
Green proposes to estimate this posterior mean,
conditionally to a given number of segments (or to
a given number of change-points). Such an example
is presented in Fig. 4, for "ve segments. The estimated mean remains smooth, since we are now
integrating over all the con"gurations with "ve
segments. Actually, this curve can be seen as
a smooth version of the original data. It is a little bit
embarrassing to obtain a smooth function, when
we are looking for a step function.
Another approach consists in estimating m, conditionally to a given con"guration of change-points
r. That is very easy, since the conditional distribution p(sDr,y;h) is a Gaussian distribution with
known parameters. For example, it seems natural
to consider the most
con"guration of
change-points, that is, the MAP estimate of r. Then,
conditionally
particular
con"guration,
(m1, m2, m3, m4, m5) is Gaussian with mean (0.106,
0.534, 0.338, 0.548, 0.114) and variance (13, 14, 9, 7,
5. Estimation of h using SAEM algorithm
The implementation of an MCMC algorithm as
described above, assumes that the set of parameters
of the model is known. Recall that these hyperparameters are, respectively, the prior proportion
of change-points j, the parameters k and < of the
Gaussian distribution for the vector of means m,
and p2 the variance of the additive noise. Instead of
setting the hyper-parameters h to a particular
value, as it is usually done in a Bayesian framework, we propose to estimate h.
The maximum likelihood estimator (MLE) of
h maximizes the likelihood of the observed data
g(y;h). Unfortunately, the MLE cannot be computed in a closed form in a context of incomplete
data. The SAEM is well suitable for computing the
MLE in this kind of situation, see for some
examples of application. This stochastic version of
the expectation maximization (EM), algorithm
just consists in updating the estimate of the hyperparameters h at each iteration of the MCMC algorithm described above. This update is based on
a stochastic approximation of the minimal su$cient statistics of the complete data model (r, y).
Thus, the "rst thing to do is to write the complete
likelihood f(r, y;h) in a standard exponential form.
We have the following Lemma:
Lemma 2. For any conxguration of changes r,
k +qkt/qk~1`1yt,
y6 "n~1+nt/1yt
M. Lavielle, E. Lebarbier / Signal Processing 81 39}53
Sr"+Krk/1+qkt/qk~1`1(yt!y6 k)2. Then, the likelihood
of the complete data is dexned by
f (y, r;h)"(2pp2)~n@2A
~Kr@2jKr~1(1!j)n~Kr
and the maximum likelihood estimator of h (i.e. the
value of h that maximizes the complete likelihood
f (y, r; ) )) is hI "(k8 ,jI ,p8 2,<I ), where
(yt!y6 )2!Sr
(The proof of this Lemma is in Appendix A.)
Remark. (1) The maximum likelihood of k is y6 and
therefore does not depend on the non-observed
data r. Thus, y6 is also the value of k that maximizes
the observed likelihood g(y;h). The SAEM algorithm will be used for estimating the others parameters j, p2 and <.
(2) Just like in an analysis of variance (ANOVA)
likelihood
(yt!y6 k)2, that is, the total sum of
residual squares Sr divided by the degrees of freedom n!Kr (see [18, pp. 185}186]).
(3) Considering the observed series y as a constant,
likelihood
(j,p2, <) only depends on the missing sequence r via
the two statistics Kr and Sr. As we shall see just
below, the SAEM algorithm is based on this remark.
The proposed SAEM algorithm is an iterative
algorithm that requires an initial con"guration of
change-points r(0) and an initial guess h(0). Then, at
iteration i, a simulation step and an estimation step
are performed as follows:
v Simulation step: a new con"guration r(i) is generated with M iterations of the MCMC algorithm,
using the current values of the hyper-parameters
h(i~1) and the current con"guration r(i~1).
v Estimation step: h(i) is updated by using the new
con"guration r(i), and according to the two following steps:
1. Stochastic approximation: update the approximation of the su$cient statistics as follows:
s(i)1 "s(i~1)
#ai(Kr(i)!s(i~1)
s(i)2 "s(i~1)
#ai(Sr(i)!s(i~1)
where Kr(i) and Sr(i) are the su$cient statistics of
the complete model, computed at the point
(y, r(i)) and where (ai) is a sequence of decreasing
stepsizes such that +ai"R and +a2i )R.
2. Maximization step: compute h(i)"(j(i), p2(i), <(i))
by maximizing the complete likelihood (see
(35)}(37)):
j(i)"s(i)1 !1
<(i)"+nt/1(yt!y6 )2!s(i)2
Remarks. (1) We choose a decreasing sequence (ai)
in order to obtain a pointwise convergence of the
sequence (h(i)) to a value hw (see for results
concerning stochastics algorithms and the many
references therein). A satisfactory schedule consists
in setting ai"1 during some iterations (about 10
iterations in the practice), for converging quickly
to a neighborhood of hw and then, (ai) decreases
(2) It was shown by Delyon et al. that SAEM
onverges to a (local or global) maximum of the
observed data likelihood g(y;h) under very general
conditions, but assuming exact and independent
simulations of the missing data at each iterations.
Here, the sequence of missing data (r(i)) is a Markov
chain, and this result does not apply directly.
Nevertheless, by using the results of Metivier and
M. Lavielle, E. Lebarbier / Signal Processing 81 39}53
Fig. 5. Estimation of the hyper-parameters. (a) the signal y, the mean m and the change-point instants q, simulated with
j"0.01, <"1.5 and p2"0.1, (b), (c) and (d) the sequences of estimates (j(i)), (<(i)) and (p2(i)).
Priouret for this kind of situation, we can
show that the algorithm described above converges
to a maximum of g(y;h) if the sequence of parameters (h(i)) belongs to a compact set. Then, the
slight technical stabilization device proposed by
Delyon et al. for the SAEM algorithm ensures
the compactness of (h(i)), and its convergence to
a maximum of the observed likelihood.
We propose in Fig. 5 a numerical example of this
algorithm. A series y of length 1000 was simulated
with the following parameters: j"0.01, <"1 and
p2"0.1. The change-points sequence r and the
vector of means m were obtained using (4) and (6).
Then, y was obtained using (7). This series is
displayed Fig. 5(a) together with the sequence
of means and the change-points. The number of
iterations of MCMC to perform before updating
h(i) was "xed to M"1000. The sequence of stepsizes (ai) was such that ai"1 for 1)i)10, and
ai"1/(i!10) for i*11. The sequences (j(i)), (<(i))
and (p2(i)) are displayed Fig. 5(b)}(d). The algorithm
quickly converges, and after 30 iterations, the estimated parameters are j(30)"0.007, <(30)"1.469
and p2(30)"0.091.
6. Conclusion
We have proposed an attractive methodology for
the change-points problem, in a Bayesian context.
The probabilistic model makes use of an non-observed sequence r, and a MCMC algorithm can be
used for estimating the posterior distribution of this
change-points process r. Numerical experiments
have clearly shown that this procedure is much
more faster than the Reversible Jump algorithm.
Furthermore, the hyperparameters of the model are
estimated, rather than arbitrarily chosen. We have
also seen that a slight modi"cation of the sampler
allows to select the most likely con"gurations of
change-points.
The main advantage of this method is the ability
to perform automatically di!erent tasks. We think
that this kind of approach should not be restricted
to the problem of detecting change-points in a
M. Lavielle, E. Lebarbier / Signal Processing 81 39}53
signal contaminated by an additive (or a multiplicative) noise. Indeed, it should be interesting and
useful to extend this approach for detecting
changes in the spectrum of a signal, for example.
Appendix A
Proof of formulae (11)+(13). Using Eqs. (6) and (7),
p(mDy,r;h)h(yDr;h)
"h(yDr, m;p2)p(mDr;k, <)
"(2pp2)~n@2e~(1@2p2)+ Kr
t/qk~1`1(yt~mk)2
~1@2e~(nk@2V)(mk!k)2
(2p<k)~1@2e~(1@2Vk)(mk~kk)2
](2pp2)~n@2 Kr<
+qkt/qk~1`1y2t
By identi"cation, we obtain the distribution of
m conditional on a given con"guration r and the
observations y
p(mDy,r;h)" Kr<
(2p<k)~1@2e~(1@2Vk)(mk!kk)2,
where kk and <k are, respectively, the posterior
mean and variance of mk.
Proof of Lemma 1. First, remark that according to
h(yDr;h)"(2pp2)~n@2 Kr<
"(2pp2)~n@2A
~Kr@2expG!
We can then obtain Lemma 1 using (4) and (A.2).
p(rDy;h)"h(yDr;h)p(r;j)
"C(y;h)expM!/Sr!cKrN,
2p2(p2#<),
Proof of Lemma 2. Since f (y, r;h)"h(yDr;h)p(r;j),
we can directly obtain (33) from (4) and (A.2). Then,
the expression of the maximum likelihood estimate
of h is obtained by maximizing f (y, r;h) with respect
Appendix B
Probabilities of acceptance for the Reversible Jump
algorithm. Let (m,q) be the current state and (m8 ,q8 )
be the proposed candidate. The probability of acceptance is
a((m,q),(m8 ,q8 ))"minG1, p(m8 ,q8 Dy;h)
p(m,qDy;h)]j((m8 ,q8 ),(m,q))q2(u@)
j((m,q),(m8 ,q8 ))q1(u)
L(m8 ,q8 , u@)
L(m,q,u)KH
M. Lavielle, E. Lebarbier / Signal Processing 81 39}53
"minG1,h(yDm8 ,q8 ;p2)
h(yDm,q;p2)]p(m8 ;q8 ;h)
]j((m8 ,q8 ),(m,q))q2(u@)
j((m,q),(m8 ,q8 ))q1(u)]K
L(m8 ,q8 , u@)
L(m,q, u)KH
"minM1, AN,
f j((m8 ,q8 ),(m,q)) (resp. j((m,q),(m8 ,q8 ))) is the probability
of choosing the move from (m8 ,q8 ) to (m,q) (resp.
from (m,q) to (m8 ,q8 )).
f u (resp. u@) is generated from the proposal density
q1(u) (resp. q2(u@)) such that (m8 ,q8 , u@)"f (m,q, u)
where f is a speci"c invertible function.
f the "nal term is the Jacobian arising from the
change of variables from (m,q, u) to (m8 ,q8 , u@).
We can compute A for the di!erent moves:
A"h(yDm8 ,q8 ;h)
h(yDm,q;h)]expG! 1
2<(m8 2k!m2k)(qk!qk~1)H
A"h(yDm8 ,q8 ;h)
h(yDm,q;h)]
](2p)~1@2A
(qk!q8 k)(q8 k!qk~1)
(qk!qk~1) B
2<(m8 2k(q8 k!qk~1)#m8 2k`1(qk!q8 k)
!m2k(qk!qk~1))H
((q8 k!qk~1)(qk!q8 k))1@2B.
A"h(yDm8 ,q8 ;h)
h(yDm,q;h)]1!j
(qk`1!qk~1)
(qk`1!qk)(qk!qk~1)B
2<(m8 2k(qk`1!qk~1)
!m2k`1(qk`1!qk)!m2k(qk!qk~1))H
((qk`1!qk)(qk!qk~1))1@2
A"h(yDm8 ,q8 ;h)
h(yDm,q;h)]A
(qk`1!q8 k)(q8 k!qk~1)
(qk`1!qk)(qk!qk~1)B
2<(m2k!m2k`1)(q8 k!qk)H.