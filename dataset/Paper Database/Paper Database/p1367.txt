Memorizing Normality to Detect Anomaly: Memory-augmented Deep
Autoencoder for Unsupervised Anomaly Detection
Dong Gong1, Lingqiao Liu1, Vuong Le2, Budhaditya Saha2,
Moussa Reda Mansour3, Svetha Venkatesh2, Anton van den Hengel1
1The University of Adelaide, Australia
2A2I2, Deakin University
3University of Western Australia
 
Deep autoencoder has been extensively used for
anomaly detection. Training on the normal data, the autoencoder is expected to produce higher reconstruction error for the abnormal inputs than the normal ones, which
is adopted as a criterion for identifying anomalies. However, this assumption does not always hold in practice. It
has been observed that sometimes the autoencoder “generalizes” so well that it can also reconstruct anomalies
well, leading to the miss detection of anomalies. To mitigate this drawback for autoencoder based anomaly detector, we propose to augment the autoencoder with a memory module and develop an improved autoencoder called
memory-augmented autoencoder, i.e. MemAE. Given an input, MemAE ﬁrstly obtains the encoding from the encoder
and then uses it as a query to retrieve the most relevant
memory items for reconstruction. At the training stage, the
memory contents are updated and are encouraged to represent the prototypical elements of the normal data. At the test
stage, the learned memory will be ﬁxed, and the reconstruction is obtained from a few selected memory records of the
normal data. The reconstruction will thus tend to be close to
a normal sample. Thus the reconstructed errors on anomalies will be strengthened for anomaly detection. MemAE is
free of assumptions on the data type and thus general to be
applied to different tasks. Experiments on various datasets
prove the excellent generalization and high effectiveness of
the proposed MemAE.
1. Introduction
Anomaly detection is an essential task with critical applications in various areas, such as video surveillance .
The unsupervised anomaly detection is
to learn a normal proﬁle given only the normal data examples and then identify the samples not conforming to the
normal proﬁle as anomalies, which is challenging due to
the normal
Encodeding of normal input
Encoding of abnormal input
Prototypical normal patterns
in memory slots
Addressing memory
Signiﬁcant recon. error
on abnormal sample
Small recon. error
on normal sample
Figure 1. Anomaly detection via the proposed MemAE. After
training on the dataset only with normal samples, the memory in
MemAE records the prototypical normal patterns. Given an abnormal input, MemAE retrieves the most relevant normal patterns
in memory for reconstruction, resulting in an output signiﬁcantly
different to the abnormal input. To simplify the visualization, we
assume only one memory item is addressed here.
the lack of human supervision. Notably, the problem becomes even more difﬁcult when the data points lay in a
high-dimensional space (i.e. videos), since modeling the
high-dimensional data is notoriously challenging .
Deep autoencoder (AE) is a powerful tool to
model the high-dimensional data in the unsupervised setting. It consists of an encoder to obtain a compressed encoding from the input and a decoder that can reconstruct the
data from the encoding. The encoding essentially acts as an
information bottleneck which forces the network to extract
the typical patterns of high-dimensional data. In the context
of anomaly detection, the AE is usually trained by minimizing the reconstruction error on the normal data and then
uses the reconstruction error as an indicator of anomalies.
It is generally assumed that the reconstruction
error will be lower for the normal input since they are close
to the training data, while the reconstruction error becomes
higher for the abnormal input.
However, this assumption may not always hold, and
sometimes the AE can “generalize” so well that it can also
reconstruct the abnormal inputs well. This observation has
 
been made in the existing literature [47, Figure 1] and also
in this paper (See Figure 4 and 6). The assumption that
anomaly incurs higher reconstruction error might be somehow questionable since there are no training samples for
anomalies and the reconstruction behavior for anomaly inputs should be unpredictable. If some anomalies share common compositional patterns (e.g. local edges in images)
with the normal training data or the decoder is “too strong”
for decoding some abnormal encodings well, AE is very
likely to reconstruct the anomalies well.
To mitigate the drawback of AEs, we propose to augment the deep autoencoder with a memory module and introduce a new model memory-augmented autoencoder, i.e.
MemAE. Given an input, MemAE does not directly feed its
encoding into the decoder but uses it as a query to retrieve
the most relevant items in the memory. Those items are
then aggregated and delivered to the decoder. Speciﬁcally,
the above process is realized by using attention based memory addressing. We further propose to use a differentiable
hard shrinkage operator to induce sparsity of the memory
addressing weights, which implicitly encourage the memory items to be close to the query in the feature space.
In the training phase of MemAE, we update the memory
content together with the encoder and decoder. Due to the
sparse addressing strategy, the MemAE model is encouraged to optimally and efﬁcient use the limited number of
memory slots, making the memory to record the prototypical normal patterns in the normal training data to obtain
low average reconstruction error (See Figure 3). In the test
phase, the learned memory content is ﬁxed, and the reconstruction will be obtained by using a small number of the
normal memory items, which are selected as the neighborhoods of the encoding of the input. Because the reconstruction is obtained normal patterns in memory, it tends to be
close to the normal data. Consequently, the reconstruction
error tends to be highlighted if the input is not similar to
normal data, that is, an anomaly. The schematic illustration is shown in Figure 1. The proposed MemAE is free of
the assumption on the types of data and thus can be generally applied to solve different tasks. We apply the proposed
MemAE on various public anomaly detection datasets from
different applications. Extensive experiments prove the excellent generalization and high effectiveness of MemAE.
2. Related Work
Anomaly detection In unsupervised anomaly detection,
only normal samples are available as training data . A
natural choice for handling the problem is thus the oneclass classiﬁcation methods, such as one-class SVM 
and deep one-class networks , which seeks to learn
a discriminative hyperplane surrounding the normal samples. Unsupervised clustering methods, such as the k-means
method and Gaussian Mixture Models (GMM) ,
have also been applied to build a detailed proﬁle of the normal data for identifying the anomalies. These methods usually suffer from suboptimal performance when processing
high-dimensional data.
Reconstruction-based methods are proposed relying on
an assumption that the anomalies cannot be represented and
reconstructed accurately by a model learned only on normal data . Different techniques, such as PCA methods
 and sparse representation , have been used
to learn the representation of the normal patterns. Speciﬁcally, sparse representation methods jointly learn
a dictionary and the sparse representation of the normal
data for detecting anomalies. The restricted feature representations limit the performances. Some very recent works
 train deep autoencoders for anomaly detection. For example, structured energy based deep neural network is used to model the training samples. Zong et
al. proposed to jointly model the encoded features and
the reconstruction error in a deep autoencoder. Although the
reconstruction based methods have achieved fruitful results,
their performances are restricted by the under-designed representation of the latent space.
Due to the critical application scenario, a series of methods are speciﬁcally designed for video anomaly detection
 . Kim and Grauman use a mixture of
probabilistic PCA (MPPCA) to model optical ﬂow features.
Mahadevan et al. model the video via a mixture of
dynamic textures (MDT). Lu et al. proposed an efﬁcient sparse coding-based method with multiple dictionaries. Zhao et al. update the dictionary in an online manner. Deep learning based methods are proposed to use the information in both the spatial and temporal domain. Hasan et al. detect the anomalies according
to the reconstruction error of a convolutional AE. Zhao et
al. proposed to use 3D convolution based reconstruction and prediction. Luo et al. iteratively update the
sparse coefﬁcients via a stacked RNN to detect anomalies in
videos. Liu et al. train a frame prediction network by
incorporating different techniques including gradient loss,
optical ﬂow, and adversarial training. However, these methods lack a reliable mechanism to encourage the model to
induce large reconstruction error on the anomalies.
Memory networks Memory-augmented networks have attracted increasing interest for solving different problems
 . Graves et al. use external memory to extend
the capability of neural networks, in which content-based
attention is used for addressing the memory. Considering
that memory can record information stably, Santoro et al.
 use a memory network to handle the one-shot learning problem. The external memory has also been used for
multi-modal data generation , for circumventing the
mode collapse issue and preserving detailed data structure.
Addressing
Attention based addressing
with Hard shrinkage
Memory module
Figure 2. Diagram of the proposed MemAE. The memory addressing unit takes the encoding z as query to obtain the soft addressing
weights. The memory slots can be used to model the whole encoding or the features on one pixel of the encoding (as shown in the ﬁgure).
Note that bw is normalized after the hard shrinkage operation.
3. Memory-augmented Autoencoder
3.1. Overview
The proposed MemAE model consists of three major
components - an encoder (for encoding input and generating
query), a decoder (for reconstruction) and a memory module (with a memory and the associated memory addressing operator). As shown in Figure 2, given an input, the
encoder ﬁrst obtains the encoding of the input. By using
the encoded representation as a query, the memory module retrieves the most relevant items in the memory via the
attention-based addressing operator, which are then delivered to the decoder for reconstruction. During training, the
encoder and decoder are optimized to minimize the reconstruction error. The memory contents are simultaneously
updated to record the prototypical elements of the encoded
normal data. Given a testing sample, the model performs
reconstruction merely using a restricted number of the normal patterns recorded in the memory. As a result, the reconstruction tends to be close to the normal sample, resulting
in small reconstruction errors for normal samples and large
errors on anomalies, which will be used as a criterion to
detect the anomalies.
3.2. Encoder and Decoder
The encoder is used to represent the input in an informative latent domain. The encoded representation performs as
a query to retrieve the relevant items in the memory. In our
model, the encoder can be seen as a query generator. The
decoder is trained to reconstruct the samples by taking the
retrieved memories as input.
We ﬁrst deﬁne X to represent the domain of the data samples and Z to represent the domain of the encodings. Let
fe(·) : X →Z denote the encoder and fd(·) : Z →X
denote the decoder. Given a sample x ∈X, the encoder
converts it to an encoded representation as z ∈Z; and the
decoder is trained to reversely mapping a latent representation bz ∈Z to the domain X as follows
z = fe(x; θe),
bx = fd(bz; θd),
where θe and θd denote the parameters of the encoder fe(·)
and decoder fd(·), respectively. In the proposed MemAE, z
is used to retrieve the relevant memory items; and bz is obtained using the retrieved items. For the standard AE model,
there is bz = z. Our method is agnostic to the structures of
the encoder and decoder, which can be specially selected
for different applications.
In testing, given a sample x, we use the ℓ2-norm based
mean square error (MSE), i.e. e = ∥x −bx∥2
2, to measure of
the reconstruction quality, which is used as the criterion for
anomaly detection.
3.3. Memory Module with Attention-based Sparse
Addressing
The proposed memory module consists of a memory to
record the prototypical encoded patterns and an attentionbased addressing operator for accessing the memory.
Memory-based Representation
The memory is designed as a matrix M ∈RN×C containing N real-valued vectors of ﬁxed dimension C. For convenience, we assume C is same to the dimension of z and
let Z = RC. Let the row vector mi, ∀i ∈[N] denote the
i-th row of M, where [N] denotes the set of integers from 1
to N. Each mi denotes a memory item. Given a query (i.e.
encoding) z ∈RC, the memory network obtains bz relying
a soft addressing vector w ∈R1×N as follows
where w is a row vector with non-negative entries that sum
to one and wi denotes the i-th entry of w. The weight vector
w is computed according to z. As shown in Eq. (3), the
addressing weight w is required for accessing the memory.
The hyper-parameter N deﬁnes the maximum capacity of
the memory. Although it is non-trivial to ﬁnd the optimal
N for different datasets, MemAE is insensitive to the setting
of N, fortunately (See Section 4.2). A large enough N can
work well for each dataset.
Attention for Memory Addressing
In MemAE, the memory M is designed to explicitly record
the prototypical normal patterns during training. We deﬁne
the memory as a content addressable memory with
an addressing scheme that computes attention weights w
based on the similarity of the memory items and the query
z. As visualized in Figure 1, we compute each wight wi via
a softmax operation:
exp(d(z, mi))
j=1 exp(d(z, mj))
where d(·, ·) denotes a similarity measurement. Similar to
 , we deﬁne d(·, ·) as cosine similarity:
d(z, mi) =
As shown in Eq. (3), (4) and (5), the memory module
retrieves the memory items most similar to z to obtain the
representation bz. Due to the restricted memory size and the
sparse addressing technique (introduced in Section 3.3.3),
only a small number of memory items can be addressed every time. Accordingly, the beneﬁcial behaviors of the memory module can be interpreted as follows.
In training phase, the decoder in MemAE is restricted to
perform reconstruction merely using a very small number
of addressed memory items, rendering the requirement for
efﬁcient utilization of the memory items. The reconstruction supervision thus forces the memory to record the most
representative prototypical patterns in the input normal patterns. In Figure 3, we visualize the trained single memory
slots, which shows that each single memory slot records the
prototypical normal patterns in the training data.
In testing phase, given the trained memory, only the
normal patterns in the memory can be retrieved for reconstruction. Thus the normal samples can naturally be reconstructed well. Conversely, the encoding of an abnormal input will be replaced by the retrieved normal patterns, resulting in signiﬁcant reconstruction errors on anomalies (See
visualized examples in Figure 4).
Hard Shrinkage for Sparse Addressing
As discussed above, performing reconstruction with a restricted number of normal patterns in the memory helps
to induce large reconstruction error on anomalies.
attention-based addressing tends to approach this naturally
 . However, some anomalies may still have the chance
to be reconstructed well with a complex combination of the
memory items via a dense w containing many small elements. To alleviate this issue, we apply a hard shrinkage
operation to promote the sparsity of w:
bwi = h(wi; λ) =
if wi > λ,
otherwise,
where bwi denotes the i-th entry of the memory addressing
weight vector bw after shrinkage and λ denotes the shrinkage threshold. It is not easy to directly implement the backward of the discontinuous function in Eq. (6). For simplicity, considering that all entries in w are non-negative, we
rewrite the hard shrinkage operation using the continuous
ReLU activation function as
bwi = max(wi −λ, 0) · wi
|wi −λ| + ϵ
where max(·, 0) is also known as ReLU activation, and ϵ is
a very small positive scalar. In practice, setting the threshold λ as a value in the interval [1/N, 3/N] can render desirable results. After the shrinkage, we re-normalize bw by
letting bwi = bwi/∥bw∥1, ∀i. The latent representation bz will
be obtained via bz = bwM.
The sparse addressing encourages the model to represent an example using fewer but more relevant memory
items, leading to learning more informative representations
in memory. In addition, similar to the sparse representation methods , encouraging sparsity of the addressing
weights is beneﬁcial in testing due to that the memory M
is trained to adapt the sparse w. Encouraging sparsity in w
will also alleviate the issue that an abnormal sample may
be fairly reconstructed well with dense addressing weights.
Comparing with the sparse representation methods ,
the proposed method obtains the desired sparse w via once
efﬁcient forward operation, instead of the iterative updating.
3.4. Training
Given a dataset {xt}T
t=1 containing T samples, let bxt denote the reconstructed sample corresponding the each training sample xt. We ﬁrstly conduct to minimize the reconstruction error on each sample:
R(xt, bxt) = ∥xt −bxt∥2
where the ℓ2-norm is used to measure the reconstruction
error. Let bwt denote the memory addressing weights for
each sample xt. To further promote the sparsity of bw, in
addition to the shrinkage operation in Eq. (7), we minimize
a sparsity regularizer on bw during training. Considering
that all entries of bw are non-negative and ∥bw∥1 = 1, we
minimize the entropy of bwt:
i=1 −bwi · log( bwi).
The hard shrinkage operation in Eq. (7) and the entropy
loss Eq. (9) jointly promote the sparsity of the generated
addressing weights. More detailed ablation studies and discussions can be found in Section 4.4.
By combining loss functions in Eq. (8) and (9), we construct the training objective for MemAE as:
L(θe, θd, M) = 1
 R(xt, bxt) + αE(bwt)
where α is a hyper-parameter in training.
In practice,
α = 0.0002 leads to desirable results in all our experiments. During training, the memory M is updated through
optimization via backpropagation and gradient descent. In
backward pass, only the gradients for the memory items
with non-zero addressing weights wi can be non-zero.
4. Experiments
In this section, we validate the proposed MemAE for
anomaly detection.
To show the generality and applicability of the proposed model, we conduct experiments on
ﬁve datasets of three different tasks. The results are compared with different baseline models and state-of-the-art
techniques. The proposed MemAE is applied to all datasets
following previous sections. MemAE and its variants are
implemented using PyTorch and trained using the optimizer Adam with a learning rate of 0.0001. We make
them and other encoder-decoder models such as VAE to
have the similar model capacity.
4.1. Experiments on Image Data
We ﬁrst conduct the experiments to detect outliers image
 and evaluate the performance on two image datasets:
MNIST and CIFAR-10 , both of which contain images belonging to 10 classes. For each dataset, we construct
10 anomaly detection (i.e. one-class classiﬁcation) datasets
by sampling images from each class as normal samples and
sampling anomalies from the rest classes. The normal datums are split into training and testing set with a rate of 2:1.
Following the setting used in , the training set only
consists of normal samples and has no overlapping with the
testing set. The anomaly proposition is controlled around
30%. 10% of the original training data is left for validation.
In this experiment, we focus on validating the proposed
memory module and implement the encoder and decoder
as plain convolutional neural networks.
We ﬁrst deﬁne
Conv2(k, s, c) to denote a 2D convolution layer, where k, s
and c are the kernel size, stride size and the number of kernels, respectively. For MNIST, we implement the encoder
using three convolution layers: Conv2(1, 2, 16)-Conv2(3,
2, 32)-Conv2(3, 2, 64).
The decoder is implemented as
Dconv2(3, 2, 64)-Dconv2(3, 2, 32)-Dconv2(3, 2, 1), where
Dconv2 denotes the 2D deconvolution layer. Except for the
last Dconv2, each layer is followed by a batch normalization (BN) and a ReLU activation . Such design
is applied for all datasets in the following.
Considering
the higher data complexity of CIFAR-10, we use the encoder and decoder with larger capacities: Conv2(3, 2, 64)-
Conv2(3, 2, 128)-Conv2(3, 2, 128)-Conv2(3, 2, 256) and
Dconv2(3, 2, 256)-Dconv2(3, 2, 128)-Dconv2(3, 2, 128)-
Dconv2(3, 2, 3).
We process the MNIST and CIFAR-
10 datasets as gray images and RGB images, respectively.
Memory sizes N for MNIST and CIFAR-10 are set as 100
and 500, respectively.
We compare the proposed model with several conventional and deep learning based methods for general anomaly
detection as baselines, including one-class SVM (OC-
SVM) , kernel density estimation (KDE) , a deep
variational autoencoder (VAE) , a deep autoregressive
generative model PixCNN and the deep structured
energy-based model (DSEBM) . Speciﬁcally, for the
density estimation methods (e.g. KDE and PixCNN) and
the reconstruction based methods (e.g. VAE and DSEBM),
the log-likelihood and reconstruction error are used to calculate the regularity score, respectively. Note that for fair
comparison with other methods, we calculate the regularity score of VAE based on only reconstruction error. We
also conduct the comparisons with some baseline variants
of MemAE to show the importance of the major components, including the antueocoder without memory module
(AE) and a variant of MemAE without the sparse shrinkage
and the entropy loss (MemAE-nonSpar). In all experiments,
AE, MemAE-nonSpar, and VAE share a similar capacity
with the full MemAE model by using the same encoder and
decoder. In testing, we scale the reconstruction error to the
range as the criterion to identify the anomalies. Following , we use the AUC (Area Under Curve)
as the measurement for performance evaluation, which is
obtained by calculating the area under the Receiver Operation Characteristic (ROC) with a varying threshold. Table 1
shows the average AUC values on the 10 sampled datasets.
As shown in Table 1, the proposed MemAE generally outperforms the compared methods.
The memoryaugmented models signiﬁcantly outperform the AE without
memory. And the MemAE model with sparse addressing
yields better results. Images in MNIST only contain simple patterns, i.e. digits, which is easy to model. VAE can
thus produce satisfactory results by using a simple Gaussian distribution to model latent space. All methods perform better on MNIST than CIFAR-10, since the images
in CIFAR-10 have more complex content and exhibit larger
intra-class variance on several classes, which incurs unsat-
Table 1. Experimental results on image data. Average AUC values on 10 anomaly detection datasets sampled from MNIST and
CIFAR-10 are shown.
OC-SVM 
PixCNN 
DSEBM 
MemAE-nonSpar
isfactory average ACU. Nevertheless, among the compared
models with similar capacities, MemAE achieves superior
performance than the competitors, which proves the effectiveness of the proposed memory module.
Visualizing How the Memory Works
Considering that the images in MNIST contain the patterns
easy to identify, we use it to show how the proposed memory module works for anomaly detection.
What the memory learns.
We ﬁrst visualize what the
memory learns from MNIST by randomly sampling a single memory slot and performing decoding on it. Figure 3
visualizes the memory learned on the MNIST digits “9” by
treating them as normal samples. Since MemAE usually
performs reconstruction via a combination of several addressed items, the decoded single slot appears blurry and
noisy. Nevertheless, as shown in Figure 3(b), the memory
slots record the different prototypical patterns of the normal
training samples (i.e. digits “9”).
(a) Training samples
(b) Decoded single memory item
Figure 3. Visualization of the memory slots learned on MNIST by
treating digits “9” as normal data. We randomly select a single
memory item and perform decoding. The decoded single memory
slot in (b) appears as a prototypical pattern of the normal samples.
How memory augments reconstruction. In Figure 4, we
visualize the image reconstruction process under the memory augmentation. Since the trained memory only records
the normal prototypical patterns, given an abnormal input
“9”, the MemAE trained on “5” reconstructs a “5”, resulting in signiﬁcant reconstruction error on the abnormal input.
Note that the reconstructed “5” of MemAE has a similar
shape of the input “9” since the memory module retrieves
the most similar normal patterns. The AE model without
memory tends to learn some representations more locally.
Thus an abnormal sample may also be reconstructed well.
(a) Training on the normal “5”
(b) Training on the normal “2”
Figure 4. Visualization of the reconstruction results of AE and
MemAE on MNIST. (a) The models are trained on “5”. The input
is an image of “9”. (b) The models are trained on “2”. The input is
an image of “4”. The MemAE retrieves the normal memory items
for reconstructions and obtains the results signiﬁcantly different
from the input anomalies.
Normal pedestrians
Anomaly: cycling
(a) UCSD-Ped2
Normal pedestrians
Anomaly: chasing
(b) ShanghaiTech
Figure 5. Normality scores of the video frames obtain by MemAE.
The score decreases immediately when some anomalies appear in
the video frame.
4.2. Experiments on Video Anomaly Detection
Anomaly detection on video aims to identify the unusual contents and moving patterns in the video, which
is an essential task in video surveillance.
We conduct
experiments on three real-world video anomaly detection
datasets, i.e. UCSD-Ped2 , CUHK Avenue and
ShanghaiTech .
Speciﬁcally, the most recent benchmark dataset ShanghaiTech contains more than 270,000
training frames and more than 42,000 frames (with about
17,000 abnormal frames) for testing, which covers 13 different scenes. In the datasets, objects except for pedestrians
(e.g. vehicles) and strenuous motion (e.g. ﬁghting and chasing) are treated as anomalies.
To preserve the video temporal information, we implement the encoder and decoder using 3D convolutions to extract the spatial-temporal features in video . Accordingly, the input of the network is a cuboid constructed by
stacking 16 neighbor frames in grayscale. The structures
of encoder and decoder are designed as: Conv3(3, 2, 96)-
Conv3(3, 2, 128)-Conv3(3, 2, 256)-Conv3(3, 2, 256) and
Dconv3(3, 2, 256)-Dconv3(3, 2, 256)-Dconv3(3, 2, 128)-
Dconv3(3, 2, 1), where Conv3 and Dconv3 denote 3D
convolution and deconvolution, respectively. A BN and a
ReLU activation follow each layer (except the last one). We
set N = 2000. Considering the complexity of the video
data, we let each memory slot record the features on one
pixel in the feature maps, corresponding to a sub-area of the
video clip. The memory is thus a matrix of 2000 × 256. In
testing, the normality of each frame is evaluated by the reconstruction error of the cuboid centering on it. Following
 , we obtain the normality score pu of the u-th frame
by normalizing the errors to range :
Table 2. AUC of different methods on video datasets UCSD-Ped2,
CUHK Avenue and ShanghaiTech.
Method\Dataset
Non-Recon.
MPPCA 
MPPCA+SFA 
Unmasking 
MT-FRCN 
Frame-Pred 
AE-Conv2D 
AE-Conv3D 
StackRNN 
MemAE-nonSpar
eu −minu(eu)
maxu(eu) −minu(eu),
where eu denotes the reconstruction error the u-th frame in
a video episode. The value of pu closer to 0 indicates the
frame is more likely an abnormal frame. Figure 5 shows
that the normality score obtained by MemAE immediately
decreases when some anomalies appear in the video frame.
Due to the complexity of the video data, many general anomaly detection methods without speciﬁc design cannot work well on videos. To show the effectiveness of the proposed memory module, we compare
the proposed MemAE with many well-designed reconstruction based state-of-the-art methods including AE methods
with 2D and 3D convolution (AE-Conv2D and
AE-Conv3D), a temporally-coherent sparse coding method
(TST) , a stacked recurrent neural network (StackRNN)
 and many video anomaly detection baselines. The variants of MemAE are also compared as baselines.
Table 2 shows the AUC values on video datasets.
MemAE produces much better results than TSC and Stack-
RNN , which also apply the sparse regularization. The
comparisons with AE and MemAE-nonSpar show that the
memory module with the sparse addressing is steadily beneﬁcial. Figure 6 visualizes the reconstruction error on one
abnormal frame in UCSD-Ped2. The error map of MemAE
signiﬁcantly highlights the abnormal event (i.e. vehicle and
bicycle moving on the sidewalk), inducing low normality
score. However, AE reconstructs the anomaly well and induces some random errors.
The proposed MemAE obtains better or comparative performance than other methods, while our model solves a
more general problem and can be ﬂexibly applied to different types of data. By merely using the reconstruction
error, the proposed method can obtain superior results with
the minimum knowledge of the speciﬁc application. Even
comparing with the method (i.e. Frame-Pred in Ta-
Figure 6. Reconstruction error of AE and MemAE on an abnormal
frame of UCSD-Ped2. MemAE can signiﬁcantly highlight the abnormal parts (in red bounding box) in the scene.
ble 2) that uses many non-reconstruction techniques specifically for video data, e.g. optical ﬂow, frame prediction, and
adversarial loss, the performance of the proposed MemAE
is still comparable. Note that the purpose of our experiment
is not pursuing the highest accuracy on certain applications
but to demonstrate the advantages of the proposed improvement of AE, i.e. MemAE, for the general anomaly detection
problem. Our study is orthogonal to that in and can be
readily incorporated into their system to boost the performance further. On the other hand, the techniques in 
can also be used in the proposed MemAE.
Robustness to the memory size We use the UCSD-Ped2 to
study the robustness of the proposed MemAE to the memory size N. We conduct the experiments by using different
memory size settings and show the AUC values in Figure
7. Given a large enough memory size, the MemAE can robustly produce plausible results.
Memory size
Figure 7. Robustness to the setting of memory size. AUC values
of MemAE with different memory size on UCSD-Ped2 are shown.
Running time We empirically study the computing complexity of the proposed method on the video dataset UCSD-
Ped2 with an NVIDIA GeForce 1080 Ti graphics card. The
proposed MemAE averagely takes 0.0262 seconds for video
anomaly detection of one frame (i.e. 38 fps), which is on
par or faster than previous state-of-the-art deep learning
based methods such as using 0.04s, using 0.02s
and using 0.05s1. Moreover, comparing to our baseline
AE model that takes 0.0266s for each frame, our memory
module (in MemAE) induces little additional computation
time (i.e. 4×10−4s per frame).
1Running time of the compared methods are quoted from for reference, which is produced using a faster graphics card than ours.
Table 3. Experimental results of different methods on the cybersecurity dataset KDDCUP.
Method\Metric
OC-SVM 
DSEBM 
DAGMM 
MemAE-nonSpar
4.3. Experiments on Cybersecurity Data
To further validate the generalization of the proposed
method, we experiment on a widely used cybersecurity
dataset beyond the computer vision applications, i.e. KD-
DCUP99 10 percent dataset from the UCI repository .
Following the settings in , 80% of the samples labeled
as “attack” in the original dataset are treated as normal samples. Each sample can be organized as a vector with 120
dimensions . We use fully-connected layers (noted as
FC) to implement the encoder and decoder as FC(120, 60)-
FC(60, 30)-FC(30, 10)-FC(10, 3) and FC(3, 10)-FC(10,
30)-FC(30, 60)-FC(60, 120), in which FC(i, o) denotes the
FC layer with input and output size i and o. Expect the last
one, each FC layer is followed by a Tanh activation. The
structure shares a similar capacity to the model in . We
set N = 50 and thus have a memory with the size of 50×3.
As suggested in , we randomly sample 50% of
data for training and the rest for testing. Only data samples from normal class are used for training. We compare
the proposed method with previous state-of-the-art methods
on the KDDCUP dataset, including OC-SVM , a deep
clustering network (DCN) , DSEBM , DAGMM
 and the baseline variants of MemAE. Following the
standard protocol , the methods are evaluated using
the average precision, recall and F1 score after 20 runs.
DAGMM and the proposed models perform very well because of the more effective data modeling. The proposed
method obtains the superior performance since it can explicitly memorize the behavior patterns of “attack” samples.
4.4. Ablation Studies
In previous sections, extensive comparisons among
MemAE and its variants, i.e. AE and MemAE-nonSpar,
have proved the importance of the major components of the
proposed method. In this section, we will conduct several
further ablation studies to investigate other different components in details.
Study of the Sparsity-inducing Components
As introduced above, we use two components to induce
sparsity of the memory addressing weights, i.e. the hardthresholding shrinkage deﬁned in Eq. (6) and the entropy
Table 4. Ablation studies based on UCSD-Ped2 dataset.
MemAE-nonSpar
MemAE w/o Shrinkage
MemAE w/o Entropy loss
loss E(·) in Eq. (10). We experiment to study the importance of each component by removing the other one. Table
4 records the AUC on the dataset UCSD-Ped2. As shown
in Table 4, removing either the shrinkage operator or the
entropy loss will degenerate the performance. Without the
hard shrinkage, the model cannot directly encourage sparsity in testing, which may lead to non-sparse memory addressing weights with too much noise. Entropy loss plays
a vital role when the under-trained model generates unoptimized addressing weights at the early stage of training.
Comparison with AE with Sparse Regularization
The sparse memory addressing in MemAE derives a ﬂavor
of the autoencoders that induce sparsity of the encoder output (activations). We thus conduct a straightforward experiment to compare MemAE with an autoencoder with sparse
regularization on the encoded features, which is directly implemented by minimizing the ℓ1-norm of the latent compressed feature, i.e. ∥z∥1, during training, referred to as
AE-ℓ1, which shares the same encoder and decoder with
MemAE. As shown in Table 4, the performance of AE-ℓ1
is close to MemAE-nonSpar and superior to AE due to the
sparsity-inducing regularization. However, AE-ℓ1 still lacks
a clear mechanism to encourage large reconstruction errors
on anomalies or a powerful module to model the prototypical patterns of the normal samples, lead to worse performance than MemAE and other MemAE variants.
5. Conclusion
In this paper, we proposed a memory-augmented autoencoder (MemAE) to improve the performance of the
autoencoder based unsupervised anomaly detection methods. Given an input, the propose MemAE ﬁrst uses the
encoder to obtain an encoded representation and then use
the encoding as a query to retrieve the most relevant patterns in the memory for reconstruction. Since the memory is trained to record the prototypical normal patterns, the
proposed MemAE can well reconstruct the normal samples
and enlarge the reconstruction error of the anomalies, which
strengths the reconstruction error as the anomaly detection
criterion. Experiments on various datasets from different
applications prove the generalization and effectiveness of
the proposed method. In the future, we will investigate to
use the addressing weight for anomaly detection. Consid-
ering that the proposed memory module is general and agnostic to the structures of the encoder and decoder, we will
integrate it into more complicated base models and apply it
on more challenging applications.