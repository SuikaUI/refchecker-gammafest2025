Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2023–2035
Florence, Italy, July 28 - August 2, 2019. c⃝2019 Association for Computational Linguistics
Data-to-text Generation with Entity Modeling
Ratish Puduppully and Li Dong and Mirella Lapata
Institute for Language, Cognition and Computation
School of Informatics, University of Edinburgh
10 Crichton Street, Edinburgh EH8 9AB
 
 
 
Recent approaches to data-to-text generation
have shown great promise thanks to the use
of large-scale datasets and the application of
neural network architectures which are trained
end-to-end. These models rely on representation learning to select content appropriately,
structure it coherently, and verbalize it grammatically, treating entities as nothing more
than vocabulary tokens. In this work we propose an entity-centric neural architecture for
data-to-text generation.
Our model creates
entity-speciﬁc representations which are dynamically updated.
Text is generated conditioned on the data input and entity memory representations using hierarchical attention at each time step.
We present experiments on the ROTOWIRE benchmark and a
(ﬁve times larger) new dataset on the baseball
domain which we create. Our results show that
the proposed model outperforms competitive
baselines in automatic and human evaluation.1
Introduction
Data-to-text generation is the task of generating
textual output from non-linguistic input . The input may take on several guises including tables of
records, simulations of physical systems, spreadsheets, and so on. As an example, Figure 1 shows
(in a table format) the scoring summary of a major
league baseball (MLB) game, a play-by-play summary with details of the most important events in
the game recorded chronologically (i.e., in which
play), and a human-written summary.
Modern approaches to data-to-text generation
have shown great promise thanks to the use of large-scale datasets and
neural network models which are trained end-toend based on the very successful encoder-decoder
architecture .
In contrast to traditional methods which typically implement pipeline-style architectures with modules devoted to individual generation components (e.g., content selection or lexical
choice), neural models have no special-purpose
mechanisms for ensuring how to best generate a
text. They simply rely on representation learning
to select content appropriately, structure it coherently, and verbalize it grammatically.
In this paper we are interested in the generation of descriptive texts such as the game summary
shown in Figure 1.
Descriptive texts are often
characterized as “entity coherent” which means
that their coherence is based on the way entities
(also known as domain objects or concepts) are
introduced and discussed in the discourse .
Without knowing anything
about baseball or how game summaries are typically written, a glance at the text in Figure 1 reveals that it is about a few entities, namely players
who had an important part in the game (e.g., Brad
Keller, Hunter Dozier) and their respective teams
(e.g., Orioles, Royals). The prominent role of entities in achieving discourse coherence has been
long recognized within the linguistic and cognitive science literature , with Centering
Theory being most prominent
at formalizing how entities are linguistically realized and distributed in texts.
In this work we propose an entity-centric neural architecture for data-to-text generation. Instead
of treating entities as ordinary tokens, we create
entity-speciﬁc representations (i.e., for players and
teams) which are dynamically updated as text is
Inn1 Inn2 Inn3 Inn4 . . .
9 14 1 . . .
C. Mullins
Orioles . . .
Orioles . . .
W. Merriﬁeld
R. O’Hearn
. . . . . .
ER BB K . . .
A. Cashner
. . . . . .
Inn1: innings, R: runs, H: hits, E: errors, AB: at-bats,
RBI: runs-batted-in, H/V: home or visiting, W: wins,
L: losses, IP: innings pitched, ER: earned runs, BB:
walks, K: strike outs.
KANSAS CITY, Mo. – Brad Keller kept up his recent pitching surge
with another strong outing. Keller gave up a home run to the ﬁrst
batter of the game – Cedric Mullins – but quickly settled in to pitch
eight strong innings in the Kansas City Royals’ 9–2 win over the Baltimore Orioles in a matchup of the teams with the worst records in the
majors. Keller (7–5) gave up two runs and four hits with two walks
and four strikeouts to improve to 3–0 with a 2.16 ERA in his last four
starts. Ryan O’Hearn homered among his three hits and drove in four
runs, Whit Merriﬁeld scored three runs, and Hunter Dozier and Cam
Gallagher also went deep to help the Royals win for the ﬁfth time in
six games on their current homestand. With the scored tied 1–1 in the
fourth, Andrew Cashner (4–13) gave up a sacriﬁce ﬂy to Merriﬁeld
after loading the bases on two walks and a single. Dozier led off the
ﬁfth inning with a 423-foot home run to left ﬁeld to make it 3-1. The
Orioles pulled within a run in the sixth when Mullins led off with a
double just beyond the reach of Dozier at third, advanced to third on a
ﬂy ball and scored on Trey Mancini’s sacriﬁce ﬂy to the wall in right.
The Royals answered in the bottom of the inning as Gallagher hit his
ﬁrst home run of the season. . .
INN RUNS . . .
C. Mullins
A. Cashner W. Merriﬁeld Grounded into DP Royals
W. Merriﬁeld A. Cashner
B. Goodwin
A. Cashner
Figure 1: MLB statistics tables and game summary. The tables summarize the performance of the two teams and of
individual team members who played as batters and pitchers as well as the most important events (and their actors)
in each play. Recurring entities in the summary are boldfaced and colorcoded, singletons are shown in black.
being generated. Our model generates descriptive
texts with a decoder augmented with a memory
cell and a processor for each entity. At each time
step in the decoder, the processor computes an updated representation of the entity as an interpolation between a candidate entity memory and its
previous value. Processors are each a gated recurrent neural network and parameters among them
are shared. The model generates text by hierarchically attending over memory cells and the records
corresponding to them.
We report experiments on the benchmark RO-
TOWIRE dataset which
contains statistics of NBA basketball games paired
with human-written summaries. In addition, we
create a new dataset for MLB (see Figure 1). Compared to ROTOWIRE, MLB summaries are longer
(approximately by 50%) and the input records are
richer and more structured (with the addition of
play-by-play). Moreover, the MLB dataset is ﬁve
times larger in terms of data size (i.e., pairs of tables and game summaries). We compare our entity
model against a range of recently proposed neural
architectures including an encoder-decoder model
with conditional copy and
a variant thereof which generates texts while taking content plans into account . Our results show that modeling entities explicitly is beneﬁcial and leads to output which is
not only more coherent but also more concise and
grammatical across both datasets.
Our contributions in this work are three-fold: a
novel entity-aware model for data-to-text generation which is linguistically motivated, yet resource
lean (no preprocessing is required, e.g., to extract
document plans); a new dataset for data-to-text
generation which we hope will encourage further
work in this area; a comprehensive evaluation and
comparison study which highlights the merits and
shortcomings of various recently proposed datato-text generation models on two datasets.
Related Work
The sports domain has attracted considerable attention since the early days of generation systems
 .
Likewise, a variety of coherence theories have been developed over the years and their principles have
found application in many symbolic text generation systems . Modeling entities and their
communicative actions has also been shown to
improve system output in interactive storytelling
 
and dialogue generation .
More recently, the beneﬁts of modeling entities
explicitly have been demonstrated in various tasks
and neural network models. Ji et al. make
use of dynamic entity representations for language
And Clark et al. extend this
work by adding entity context as input to the decoder. Both approaches condition on a single entity at a time, while we dynamically represent and
condition on multiple entities in parallel. Kiddon
et al. make use of ﬁxed entity representations to improve the coverage and coherence of
the output for recipe generation. Bosselut et al.
 model actions and their effects on entities
for the same task.
However, in contrast to our
work, they keep entity representations ﬁxed during
generation. Henaff et al. make use of dynamic entity representations in machine reading.
Entity representations are scored against a query
vector to directly predict an output class or combined as a weighted sum followed by softmax over
the vocabulary. We make use of a similar entity
representation model, extend it with hierarchical
attention and apply it to data-to text generation.
The hierarchical attention mechanism was ﬁrst introduced in Yang et al. as a way of learning document-level representations. We apply attention over records and subsequently over entity
Several models have been proposed in the last
few years for data-to-text generation based on the very successful encoderdecoder architecture . Various attempts have also been made to improve these
models, e.g., by adding content selection and content planning mechanisms. However, we are not aware of any prior work in this
area which explicitly handles entities and their
generation in discourse context.
Background: Encoder-Decoder with
Conditional Copy
The input to our model is a table of records (see
Figure 1). Records in turn have features, represented as {rj,l}L
l=1 where L is the number of features in each record.
Examples of features are
values (rj,1; e.g., 8.0, Baltimore) or entities (rj,2;
e.g., Orioles, C. Mullins). The model output y is a
document containing words y = y1 · · · y|y| where
|y| is the document length. Following previous
work , we embed features into vectors, and then
use a multilayer perceptron to obtain a vector representation rj for each record:
rj = ReLU(Wr[rj,1; rj,2; ...; rj,L] + br)
where [; ] indicates vector concatenation, Wr ∈
Rn×nL, br ∈Rn are parameters, and ReLU is the
rectiﬁer activation function.
Let {ej}|r|
j=1 denote the output of the encoder.
We use an LSTM decoder to compute the probability of each target word, conditioned on previously generated words, and on ej. In the case of
ROTOWIRE, we follow previous work and consider
ej = rj. The ﬁrst hidden state of the decoder
is initialized by the average of the record vectors,
avg({ej}|r|
In the case of MLB, information encoded in
play-by-play is sequential.
Recall, that it documents the most important events in a game in
chronological order. To account for this, we encode MLB records into {ej}|r|
j=1 with a bidirectional LSTM. We impose an ordering on records in
the box score (i.e., home team followed by away
team) which is in turn followed by play-by-play
where records are naturally ordered by time. The
decoder is initialized with the concatenation of the
hidden states of the ﬁnal step of the encoder.
At time step t, the input to the decoder LSTM
is the embedding of the previously predicted
word yt−1. Let dt denote the hidden state of the
t-th LSTM unit. We compute attention scores αt,j
over the encoder output ej and obtain dynamic
context vector qt as the weighted sum of the hidden states of the input:
αt,j ∝exp(d⊺
= tanh(Wc[dt; qt])
where Wa ∈Rn×n, P
j αt,j = 1, Wc ∈Rn×2n,
is the attention vector.
The probability of output text y conditioned on
the input table r is modeled as:
pgen(yt|y<t, r)=softmaxyt(Wydatt
Figure 2: Diagram of entity memory network (block A) and hierarchical attention (blocks B and C). Module fθ
represents update equations (6)–(8) where θ is the set of trainable parameters. The gate represents the entity
memory update (Equation (9)). Block B covers Equations (10) and (11), and block C Equations (12) and (13).
where Wy ∈R|Vy|×n, by ∈R|Vy| are parameters
and |Vy| is the output vocabulary size.
We further augment the decoder with a copy
mechanism i.e., the ability to copy values from the
input; copy implies yt = rj,1 for some t and j
(e.g., Royals, Orioles, 9, 2 in the summary in Figure 1 are copied from r). We use the conditional
copy method proposed in Gulcehre et al. 
where a binary variable is introduced as a switch
gate to indicate whether yt is copied or not.
Entity Memory and Hierarchical
We extend the basic model from Section 3 with
entity memory and hierarchical attention. Figure 2
provides a schematic overview of our architecture.
Entity Memory
In order to render the model entity-aware, we compute xk as an average of record representation for
each unique entity k (i.e., one of rj,2 values):
(1[rj,2 = k]rj)/
1[rj,2 = k]
where 1[x] = 1 if x is true, and 0 otherwise.
We initialize ut=−1,k, the memory representation of an entity at time t = −1, as:
ut=−1,k = Wixk
where ut=−1,k ∈Rp and Wi ∈Rp×n.
To capture the fact that discourse in descriptive texts may shift from one entity to the next,
e.g., some entities may be salient in the beginning
of the game summary (see Brad Kelly in the text in
Figure 1), others only towards the end (see Dozier
in Figure 1), and a few throughout (e.g., references
to teams), we update entity representations at each
time step during decoding. We use gate γt to indicate whether there should be an update in the
entity representation:
γt = σ(Wddt + bd)
where t >= 0, σ is the sigmoid function, Wd ∈
Rp×p, and bd ∈Rp.
We also compute δt,k, the extent to which the
entity representation should change, and ˜ut,k , the
memory of the candidate entity:
δt,k =γt ⊙σ(Wedt+be+Wfut−1,k+bf)
˜ut,k =Wgdt
where ⊙denotes element-wise multiplication,
We, ∈Rp×n, Wf ∈Rp×p, be, bf ∈Rp, and
γt, δt,k ∈ p (see block A in Figure 2).
An element in gate γt will have value approaching 1 if an update in any ut−1,k is required. The
value of an element in gate δt,k will approach 1 if
the corresponding value of the element in ut−1,k
Equation (9) computes the update in
entity memory as an interpolation over the gated
representation of the previous value of the entity
memory and the candidate entity memory:
ut,k = (1 −δt,k) ⊙ut−1,k + δt,k ⊙˜ut,k
where ut,k represents entity k at time t.
Previous work employs a normalization
term over ut,k. We empirically found that normalization hurts performance and hence did not include it in our model.
Hierarchical Attention
We hypothesize that our generator should ﬁrst focus on entities (e.g., the main players and their
teams) and then on the records corresponding
to theses entities (e.g, player performance in the
game). Our model implements this view of text
generation via a hierarchical attention mechanism
which we explain below. We also expect that focusing on entities ﬁrst should improve the precision of the texts we generate as the entity distribution will constrain the probability distribution of
records corresponding to each entity.
To better understand the hierarchical attention
mechanism, we can view the encoder output ej as
a 2-dimensional array gk,z where k ∈[1, K] represents entities and z ∈[1, Z] represents records
of entities and there is a one-to-one correspondence between positions j and k, z. We compute
attention over gk,z, the encoder output, as:
αt,k,z ∝exp(d⊺
where Wa ∈Rn×n, P
z αt,k,z = 1 (see block B
in Figure 2). We compute the entity context as:
αt,k,zgk,z
while attention over entity vectors ut,k is:
Ψt,k ∝exp(d⊺
with Wh ∈Rn×p, P
k Ψt,k = 1. And the encoder
context qt (see block C in Figure 2) is computed
as follows:
compute pgen(yt|y<t, r), the probability of generating
output text y conditioned on records r, as shown
in Equation (3).
Vocab Size
# Instances
Avg Length
# Record Types
Avg Records
Table 1: Vocabulary size, number of tokens, number
of instances (i.e., record-summary pairs), average summary length, number of record types and average number of records in ROTOWIRE and MLB datasets.
We experimented with feeding P
k Ψt,kut,k as
input context along the lines of Clark et al. ;
however, results on the development dataset degraded performance, and we did not pursue this
approach further.
Training and Inference
Our training objective maximizes the log likelihood of output text given an input table of records:
log p (y|r)
where D is the training set consisting of pairs of
record tables and output game summaries. During
inference, we make use of beam search to approximately obtain the best output ˆy among candidate
outputs y′:
ˆy = arg max
Experimental Setup
experiments
datasets. The ﬁrst one is ROTOWIRE which contains NBA basketball
statistics
human-written
summaries.
In addition, we created MLB, a
new dataset which contains baseball statistics
and corresponding human-authored summaries
obtained from the ESPN website.2 Basic statistics
on the two datasets are given in Table 1.
can be seen, MLB is approximately ﬁve times
larger than ROTOWIRE, with richer vocabulary
and longer summaries. For ROTOWIRE, we used
the ofﬁcial training, development, and test splits
of 3,398/727/728 instances.
Analogously, for
MLB we created a split of 22,821/1,739/1,744 instances. Game summaries in MLB were tokenized
2 
using nltk and hyphenated words were separated.
Sentences containing quotes were removed as
they included opinions and non-factual statements
unrelated to the input tables.
Sometimes MLB
summaries contain a “Game notes” section with
incidental information which was also removed.
For MLB, the value of L in Equation (1) is 6,
and for ROTOWIRE it is 4.
The ﬁrst four features are similar in both datasets and include value
(rj,1; e.g., 8.0, Baltimore), entity (rj,2; e.g., Orioles,
C. Mullins), record type (rj,3; e.g., RBI, R,H) and
whether a player is on the home- or away- team
(rj,4). MLB has two additional features which include the inning of play (rj,5; e.g., 9, 7, and -1 for
records in the box score), and play index, a unique
play identiﬁer for a set of records in a play (rj,6;
e.g., 0, 10, and -1 for records in the box score).
Information Extraction
For automatic evaluation, we make use of the Information Extraction
(IE) approach proposed in Wiseman et al. .
The idea is to use a fairly accurate IE tool to extract
relations from gold summaries and model summaries and then quantify the extent to which the
extracted relations align or diverge (see Section 7
for the speciﬁc metrics we use).
The IE system ﬁrst identiﬁes candidate entities
(i.e., players, teams) and values (i.e., numbers),
and given an “entity, value” pair it predicts the type
of relation. For example, in ROTOWIRE, the relation for the pair “Kobe Bryant, 40” is PTS. Training data for the IE system is obtained automatically by matching entity-value pairs from summary sentences against record types. The IE system has an ensemble architecture which combines
convolutional and bidirectional LSTM models.
We reused the updated IE models from Puduppully et al. for ROTOWIRE3 and trained
our own IE system for MLB. Box and line scores
in MLB are identical in format to ROTOWIRE
and pose no particular problems to the IE system.
However, it is difﬁcult to extract information from
play-by-play and match it against the input tables.
Consider the sentences Ryan O’Hearn homered or
Keller gave up a home run from Figure 1 where we
can identify entities (Ryan O’Hearn, Keller) and
record types (home-run-batter, home-run-pitcher)
but no speciﬁc values. We created a dummy value
of -1 for such cases and the IE system was trained
to predict the record type of entity value pairs such
as (Ryan O’Hearn, -1) or (Keller, -1). Moreover,
3 
the IE system does not capture attributes such as
inning and team scores in play-by-play as it is
difﬁcult to deterministically match these against
corresponding spans in text. The IE system thus
would not be able to identify any records in the
snippet tied 1–1 in the fourth. On MLB, the system achieved 83.4% precision and 66.7% recall
(on held out data). We note that designing a highly
accurate IE module for MLB is in itself a research
challenge and outside the scope of this paper.
In order to compare our model against Puduppully et al. , we must have access to content
plans which we extracted from ROTOWIRE and
MLB by running the IE tool on gold summaries
(training set). We expect the relatively low IE recall on MLB to disadvantage their model which
relies on accurate content plans.
Training Conﬁguration
Model hyperparameters were tuned on the development set. We used
the Adagrad optimizer with
an initial learning rate of 0.15, decayed by 0.97
for every epoch after the 4th epoch.
truncated BPTT of
length 100 and made use of input feeding . We summarize the hyperparameters
of the ROTOWIRE and MLB models in the Appendix. All models were implemented on a fork
of OpenNMT-py .
System Comparison
We compared our entity
model against the following systems:
TEMPL is a template-based generator; we reused
TEMPL from Wiseman et al. for RO-
TOWIRE and created a new system for MLB.
The latter consists of an opening sentence
about the two teams playing the game.
then describes statistics of pitchers (innings
pitched, runs and hits given etc.) followed by
a description of play-by-play (home run, single, double, triple etc.).
ED+CC is the encoder-decoder model with conditional copy from Section 3 and the best performing system in Wiseman et al. .
NCP+CC is the best performing system in
Puduppully et al. ; it generates content plans by making use of pointer networks
 to point to the input ej;
the resultant content plans are then encoded
using a BiLSTM followed by an LSTM decoder with an attention and copy mechanism.
54.23 99.94
26.99 58.16
WS-2017 23.72 74.80
29.49 36.18
NCP+CC 34.28 87.47
34.18 51.22
30.11 92.69
38.64 48.51
59.93 97.96
22.82 68.46
18.69 92.19
62.01 50.12
NCP+CC 17.93 88.11
60.48 55.13
21.35 88.29
58.35 61.14
Evaluation on ROTOWIRE (RW) and MLB
test sets using relation generation (RG) count (#) and
precision (P%), content selection (CS) precision (P%)
and recall (R%), content ordering (CO) in normalized
Damerau-Levenshtein distance (DLD%), and BLEU.
Automatic Evaluation
We ﬁrst discuss the results of automatic evaluation using the metrics de-
ﬁned in Wiseman et al. . Let ˆy be the gold
output and y the model output.
Relation Generation measures how factual y is compared to
Speciﬁcally, it measures the precision
and number of relations extracted from y which
are also found in r. Content Selection measures
the precision and recall of relations between ˆy
and y. Content Ordering measures the Damerau-
Levenshtein distance between relations in y and
relations in ˆy. In addition, we also report BLEU
 with the gold summaries as
reference.
Table 2 (top) summarizes our results on the RO-
TOWIRE test set (results on the development set
are available in the Appendix). We report results
for our dynamic entity memory model (ENT),
the best system of Wiseman et al. which is an encoder-decoder model with
conditional copy, and NCP+CC . We see that ENT achieves scores comparable to NCP+CC, but performs better on the metrics of RG precision, CS precision, and CO. ENT
achieves substantially higher scores in CS precision compared to WS-2017 and NCP+CC, without any planning component; CS recall is worse
for ENT compared to NCP+CC mainly because
the latter model is trained to ﬁrst create a content
plan with good coverage of what to say.
Table 2 (bottom) also presents our results on
MLB (test set).
Note that ED+CC is a reimplementation of Wiseman et al.’s encoder-
ED+CC 22.68 79.40
29.96 34.11
30.76 93.02
33.99 44.79
27.93 90.85
34.19 42.27
31.84 91.97
36.65 48.18
ED+CC 18.69 92.65
62.29 51.36
19.02 93.71
62.84 52.12
20.28 89.19
58.19 58.94
21.32 88.16
57.36 61.50
Table 3: Ablation results on ROTOWIRE (RW) and
MLB development set using relation generation (RG)
count (#) and precision (P%), content selection (CS)
precision (P%) and recall (R%), content ordering
(CO) in normalized Damerau-Levenshtein distance
(DLD%), and BLEU.
decoder model (with conditional copy) on MLB.
We see that ENT achieves highest BLEU amongst
all models and highest CS recall and RG count
amongst neural models. The RG precision of ENT
is lower than ED+CC. Inspection of model output revealed that on MLB, ED+CC tends to focus on one or two players getting most of the
facts about them right, whereas ENT sometimes
gets the coreference wrong, and thus lower RG
precision. The TEMPL system scores highest on
RG precision and count, and CS recall on both
datasets. This is because TEMPL can make use
of domain knowledge which is not available to the
neural models. TEMPL performs poorly on MLB
in terms of BLEU, in fact it is considerably worse
compared to the similar template system on RO-
TOWIRE (see Table 2). This suggests that the task
of creating MLB game summaries is hard, even
for a template system which does not perform any
sophisticated generation.
Ablation Experiments
We further examined
how individual model components contribute to
the quality of the generated summaries.
To assess the impact of hierarchical attention (Section 4.2) over ED+CC, we report the performance
of a stripped-down variant of our model without
dynamic entity memory. Speciﬁcally, the entity
memory was kept static and set to ut=−1,k (see
Equation (5)). In this model, attention over entity
vectors is:
Ψt,k ∝exp(d⊺
t Whut=−1,k)
We next examined the contribution of dynamic
memory, by adding it to this model without the
gate γt (i.e., we set γt to one) and Equation (7)
then becomes:
δt,k = σ(Wedt + be + Wfut−1,k + bf) (15)
Finally, we obtain our ﬁnal ENT model, by incorporating the update gate mechanism.
The results of the ablation study are shown
in Table 3.
We compare ED+CC against variants “+Hier”, “+Dyn” and “+Gate” corresponding
to successively adding hierarchical attention, dynamic memory, and the update gate mechanism.
On both datasets, hierarchical attention, improves
relation generation, content selection, and BLEU.
Dynamic memory and the update gate brings further improvements to content selection and BLEU.
Because it conditions on entities, ENT is able
to produce text displaying nominal coreference
which is absent from the outputs of ED+CC and
WS-2017. We present an example in Table 4 (and
in the Appendix) where entities Dwight Howard
and James Harden are introduced and then later referred to as Howard and Harden. We also see that
while generating the last sentence about the next
game, ENT is able to switch the focus of attention
from one team (Rockets) to the other (Nuggets),
while NCP+CC verbalises Nuggets twice.
Human-Based
Evaluation
work , we also evaluated our model by asking humans to rate its output in terms of relation generation, coherence, grammaticality, and conciseness. Our studies were conducted on the Amazon Mechanical Turk platform. For ROTOWIRE,
we compared ENT against NCP+CC, Gold, and
TEMPL. We did not compare against WS-2017
or ED+CC, since prior work has shown that NCP+CC is superior to these
models in terms of automatic and human-based
evaluation. For MLB, we compared ENT against
NCP+CC, ED+CC, Gold, and TEMPL.
In the ﬁrst study, participants were presented
with sentences randomly selected from the game
summary (test set) together with corresponding
box and line score tables and were asked to count
supporting and contradicting facts in these sentences. We evaluated 30 summaries and 4 sentences per summary for each of ROTOWIRE and
MLB. We elicited 5 responses per summary.
As shown in Table 5, on ROTOWIRE ENT
yields a comparable number of supporting and
contradicting facts to NCP+CC (the difference is
The Houston Rockets (18–5) defeated the Denver Nuggets
(10–13) 108–96 on Tuesday at the Toyota Center in Houston. The Rockets had a strong ﬁrst half where they out–
scored . . . The Rockets were led by Donatas Motiejunas,
who scored a game–high of 25 points . . . James Harden
also played a factor in the win, as he went 7–for . . . Coming
off the bench, Donatas Motiejunas had a big game and ﬁnished with 25 points . . . The only other player to reach double ﬁgures in points was Arron Afﬂalo, who came off the
bench for 12 points . . . Coming off the bench, Arron Af-
ﬂalo chipped in with 12 points . . . The Nuggets’ next game
will be on the road against the Boston Celtics on Friday,
while the Nuggets will travel to Boston to play the Celtics
on Wednesday.
The Houston Rockets (18–5) defeated the Denver Nuggets
(10–13) 108–96 on Monday at the Toyota Center in Houston. The Rockets were the superior shooters in this game,
going . . . The Rockets were led by the duo of Dwight
Howard and James Harden. Howard shot 9–for–11 from
the ﬁeld and . . . Harden on the other hand recorded 24
points (7–20 FG, 2–5 3Pt, 8–9 FT), 10 rebounds and 10
assists, The only other Nugget to reach double ﬁgures in
points was Arron Afﬂalo, who ﬁnished with 12 points (4–
17 FG,. . . The Rockets’ next game will be on the road
against the New Orleans Pelicans on Wednesday, while the
Nuggets will travel to Los Angeles to play the Clippers on
Table 4: Examples of model output for NCP+CC (top)
and ENT (bottom) on ROTOWIRE. Recurring entities
in the summaries are boldfaced and colorcoded, singletons are shown in black.
not statistically signiﬁcant). TEMPL has the highest number of supporting facts, even relative to
gold summaries, and very few contradicting facts.
This is expected as TEMPL output is mostly factual, it essentially parrots statistics from the tables.
On MLB, ENT yields a number of supporting facts
comparable to Gold and NCP+CC, but signiﬁcantly lower than ED+CC and TEMPL. Contradicting facts are signiﬁcantly lower for ENT compared to NCP+CC, but comparable to ED+CC and
higher than TEMPL and Gold.
We also evaluated the quality of the generated
summaries. Following earlier work , we presented participants with two
summaries at a time and asked them to choose
which one is better in terms of Grammaticality
(is the summary written in well-formed English?),
Coherence (do the sentences in summary follow
a coherent discourse?), and Conciseness (does the
summary tend to repeat the same content?) We divided the four competing systems (Gold, TEMPL,
NCP+CC, and ENT) into six pairs of summaries
for ROTOWIRE and the ﬁve competing systems
(Gold, TEMPL, ED+CC, NCP+CC, and ENT)
into ten pairs for MLB. We used Best-Worst scaling on ROTOWIRE and MLB
datasets. Systems signiﬁcantly different from ENT are
marked with an asterisk * (using a one-way ANOVA
with posthoc Tukey HSD tests; p ≤0.05).
et al., 2015), a more reliable alternative to rating
scales. The score of a system is computed as the
number of times it was rated best minus the number of times is rated worst . Scores
range from −100 (absolutely worst) to 100 (absolutely best). We elicited judgments for 30 test
summaries for ROTOWIRE and MLB; each summary was rated by 3 participants.
As shown in Table 5, on ROTOWIRE Gold
receives highest scores in terms of Grammaticality, which is not unexpected.
close, achieving better scores than NCP+CC and
TEMPL, even though our model only enhances the
coherence of the output.
Participants ﬁnd ENT
on par with Gold on Coherence and better than
NCP+CC and TEMPL whose output is stilted and
exhibits no variability. In terms of Conciseness,
TEMPL is rated best, which is expected since it
does not contain any duplication, the presented
facts are mutually exclusive; ENT is comparable
to NCP+CC and better than Gold.
As far as MLB is concerned, ENT achieves
highest scores on Grammaticality and Coherence.
It is rated high on Conciseness also, second only to
TEMPL whose scores are lowest on Grammaticality and Coherence. Perhaps surprisingly, Gold is
rated lower than ENT on all three metrics; we hypothesize that participants ﬁnd Gold’s output too
verbose compared to the other systems. Recall that
MLB gold summaries are relative long, the average length is 542 tokens compared to ROTOWIRE
whose summaries are almost half as long (see Table 1). The average length of output summaries
for ENT is 327 tokens.
Taken together, our results show that ENT performs better than comparison systems on both RO-
TOWIRE and MLB. Compared to NCP+CC, it is
conceptually simpler and more portable, as it does
not rely on content plans which have to be extracted via an IE system which must be reconﬁgured for new datasets and domains.
Conclusions
In this work we presented a neural model for datato-text generation which creates entity-speciﬁc
representations (that are dynamically updated) and
generates text using hierarchical attention over the
input table and entity memory. Extensive automatic and human evaluation on two benchmarks,
ROTOWIRE and the newly created MLB, show
that our model outperforms competitive baselines
and manages to generate plausible output which
humans ﬁnd coherent, concise, and factually correct. However, we have only scratched the surface; future improvements involve integrating content planning with entity modeling, placing more
emphasis on play-by-play, and exploiting dependencies across input tables.
Acknowledgments
We would like to thank Adam Lopez for helpful
discussions. We acknowledge the ﬁnancial support of the European Research Council (Lapata;
award number 681760).