On-line Inference for Multiple Change Points
Paul Fearnhead and Zhen Liu
Department of Mathematics and Statistics
Fylde College,Lancaster University,UK
We propose an on-line algorithm for exact ﬁltering of multiple changepoint problems. This algorithm enables simulation from the true joint posterior distribution
of the number and position of the changepoints for a class of changepoint models. The computational cost of this exact algorithm is quadratic in the number of
observations. We further show how resampling ideas from particle ﬁlters can be
used to reduce the computational cost to linear in the number of observations, at
the expense of introducing small errors; and propose two new, optimum resampling
algorithms for this problem. One, a version of rejection control, allows the particle
ﬁlter to automatically choose the number of particles required at each time-step.
The new resampling algorithms substantially out-perform standard resampling algorithms on examples we consider; and we demonstrate how the resulting particle
ﬁlter is practicable for segmentation of human GC content.
KEY WORDS AND PHRASES : Direct simulation; Isochores; Rejection control; Sequential Monte Carlo; Stratiﬁed sampling; Particle Filtering.
Introduction
Changepoint models are commonly used to model heterogeneity of data (usually
over time).
Given a set of observations collected over time, these models introduce a (potentially random) number of changepoints which split the data into a
set of disjoint segments.
It is then assumed that the data arise from a single
model within each segment, but with diﬀerent models across the segments. Examples of changepoint problems include Poisson processes with changing intensity
 , changing linear regressions , Gaussian
models with changing variance and Markov models with timevarying transition matrices . These models have been applied to problems in a range of areas, including engineering, physical and biological
sciences and ﬁnance.
We consider Bayesian inference for changepoint models where the number of changepoints is unknown. The most common approach to such inference for these mod-
els is the use of Markov chain Monte Carlo , and reversible jump MCMC . However, for many
changepoint models 
it is possible to simulate independent realisations directly from the posterior distribution. This idea was used for DNA segmentation by Liu and Lawrence ,
and has been proposed more generally by Fearnhead and Fearnhead .
The idea for direct simulation are based on exact methods for calculating posterior
means . The advantages of direct simulation methods
over MCMC and reversible jump MCMC are that (i) there is no need to diagnose
whether the MCMC algorithm has converged; and (ii) as the draws from the posterior distribution are independent it is straightforward to quantify uncertainty in
estimates of features of the posterior distributions based on them. For examples of
the potential diﬃculties with MCMC caused by (i), compare the inferences obtained
for the Coal-mining disaster data analysed in Green with those based on the
direct simulation method of Fearnhead .
In this paper we extend the direct simulation algorithms to on-line problems; where
the data is obtained incrementally over time, and new inferences are required each
time an observation is made. The use of on-line algorithms has also been suggested
for static problems .
The computational cost of our exact on-line algorithm increases linearly over time,
however the on-line version of direct simulation is similar to particle ﬁlter algorithms,
and we consider using resampling algorithms taken from particle ﬁlters to reduce the
computational cost of our direct simulation algorithm (at the expense of introducing
error). We propose two simple extensions of existing resampling algorithms that
are particularly well-suited to changepoint models. One is a stratiﬁed extension of
the rejection-control approach of Liu et al. , which can limit the maximum
amount of error introduced by each resampling step. In simulation studies we ﬁnd
this stratiﬁed version can reduce the error of the resulting algorithm by about one
third as compared to the non-stratiﬁed version.
The resulting online algorithm can be viewed as a Rao-Blackwellised version of the
Particle Filter algorithm of Chopin : we have integrated out the parameters
associated with each segment. Note that this is an extremely eﬃcient version of Rao-
Blackwellisation. For example, consider analysing n data points. Our algorithm with
n particles will give exact inference and thus will always outperform the algorithm
of Chopin regardless of the number of particles used in that particle ﬁlter.
Note however, that the ﬁlter of Chopin can be used more widely, as it does
not require that the parameters within each segment can be integrated out.
The outline of the paper is as follows. We introduce the class of changepoint models
we consider in Section 2. In Section 3 we introduce the online direct simulation
algorithm, and approximate versions of it that utilise various resampling ideas. We
test these approximate algorithms, and compare diﬀerent resampling algorithms, on
simulated data in Section 4 before applying our algorithm to the analysis of the C+G
structure of human DNA data (Section 5). The paper concludes with a discussion.
Models and Notations
Assume we have data y1:n = (y1, y2, . . . , yn). We consider changepoint models for
the data with the following conditional independence property: given the position of
a changepoint, the data before that changepoint is independent of the data after the
changepoint. These models can be described in terms of the following hierarchical
structure.
Firstly we model the changepoint positions via a Markov process. This Markov
process is determined by a set of transition probabilities,
Pr(next changepoint at t|changepoint at s).
For this paper we make the simpliﬁcation that these transition probabilities depend
only on the distance between the two changepoints. Extending our work to the
general case, where the distribution of the length of a segment could depend on the
time at which it starts, is straightforward . Speciﬁcally we let g(·) be the probability
mass function for the distance between two successive changepoints (equivalently the
length of segments); so that (1) is g(t −s). We further let G(l) = Pl
i=1 g(i) be the
distribution function of this distance, and assume that g(·) is the probability mass
function for the position of the ﬁrst changepoint.
Note that any such model implies a prior distribution on the number of changepoints.
For example if a geometric distribution is used for g(·), then our model implies that
there is a ﬁxed probability of a changepoint at any time-point, independent of other
changepoints. Hence this model implies a binomial distribution for the number of
changepoints.
Now we condition on m changepoints at times τ1, τ2, . . . , τm. We let τ0 = 0 and
τm+1 = n, so our changepoints deﬁne m + 1 segments, with segment i consisting
of observations yτi+1:τi+1 for i = 0, . . . , m.
We allow a set of ¯p possible models
for the data from each segment, labeled {1, 2, . . . , ¯p}, and assume an arbitrary prior
distribution for models, common across segments, with the model in a given segment
being independent of the models in all other segments.
For a segment consisting of observations ys+1:t and model q we will have a set of
unknown parameters, β say. We have a prior distribution, π(β) for β (which may
depend on q), but assume that the parameters for this segment are independent of
the parameters in other segments. Finally we deﬁne
P(s, t, q)
Pr(ys+1:t|β, model q)π(β)dβ,
and assume that these probabilities can be calculated for all s < t and q. This
requires either conjugate priors for β, or the use of numerical integration. Numerical
integration is often computationally feasible in practice if the dimension of the part
of β that cannot be integrated analytically is low . Here we model the
data as piecewise linear regressions. So within a segment we have a linear regression
model of unknown order. For a given model order q, we have
ys+1:t = Hβ + ǫ
where H is a (t −s) × q matrix of basis functions, β is a vector of q regression
parameters and ǫ is a vector of iid Gaussian noise with mean 0 and variance σ2.
We assume conjugate priors. The variance of the Gaussian noise has an inverse
gamma distribution with parameters ν/2 and γ/2, and the components of the re-
gression vector have independent Gaussian priors. The prior for the jth component
is Gaussian with mean 0 and variance σ2δ2
The likelihood function of ys+1:t conditional on a model q is obtained by integrating
out the regression parameters β and variance σ2 :
P(s, t, q)
(||ys+1:t||2
P + γ)(t−s+ν)/2
Γ((t −s + ν)/2)
where M = (HTH+D−1)−1, P = (I−HMHT), ||y||2
P = yTPy, D = diag(δ2
1, . . . , δ2
and I is a (t −s) × (t −s) identity matrix.
On-line Inference
We consider on-line inference for the multiple changepoint model of Section 2. We
assume that observations accrue over time, so that yt is the observation at time t. At
each time-step, our aim is to calculate the posterior distributions of interest based
on all the observations to date. To do this eﬃciently requires updating our posterior
distributions at the previous time-step to take account of the new observation. Note
that on-line algorithms can be used to analyse batch data by introducing an artiﬁcial
time for each observation.
We focus on on-line inference of the position of the changepoints. Under the modeling assumptions of Section 2, inference for the parameters conditional on knowing
the number and position of the changepoints is straightforward. We ﬁrst describe an
exact on-line algorithm, which is an on-line version of the direct simulation method
of Fearnhead . The computational cost of this exact algorithm increases over
time, so we then present an approximate on-line algorithm, which uses resampling
ideas from particle ﬁlters, and which has constant computational cost over time.
Exact On-line Inference
We introduce a state at time t, Ct, which is deﬁned to be the time of the most
recent change-point prior to t (with Ct = 0 if there have been no change-points
before time t). Initially we focus on calculating the posterior distribution for Ct
given the observation y1:t. We then describe how, if these distributions are stored
for all t, it is straightforward to simulate from the joint posterior distribution of the
position of all changepoints prior to the current time.
Filtering Recursions
The state Ct can take values in 0, 1, . . . , t −1, and C1, C2, . . . , Ct, . . . is a Markov
chain. Conditional on Ct = j, either Ct+1 = j, which corresponds to no changepoint
at time t, or Ct+1 = t, if there is a changepoint at time t. The transition probabilities
for this Markov chain can thus be calculated as:
Pr(Ct+1 = j|Ct = i) =
1−G(t−i−1)
G(t−i)−G(t−i−1)
1−G(t−i−1)
otherwise,
where G(·) is the distribution function of distance between two successive change
Now, standard ﬁltering recursions give
Pr(Ct+1 = j|y1:t+1) ∝Pr(yt+1|Ct+1 = j, y1:t) Pr(Ct+1 = j|y1:t),
Pr(Ct+1 = j|y1:t) =
Pr(Ct+1 = j|Ct = i) Pr(Ct = i|y1:t).
Thus, if we let w(j)
t+1 = Pr(yt+1|Ct+1 = j, y1:t), and substitute in the transition
probabilities (5), we obtain
Pr(Ct+1 = j|y1:t+1) ∝
1−G(t−j−1) Pr(Ct = j|y1:t)
G(t−i)−G(t−i−1)
1−G(t−i−1)
Pr(Ct = i|y1:t)
If we deﬁne P(s, t, q) as in (2) then we get for j < t
q=1 P(j, t + 1, q)p(q)
q=1 P(j, t, q)p(q)
while if j = t then the weight is P¯p
q=1 P(t, t + 1, q)p(q).
In most situations, such as for the linear regression models described in Section 2, the
incremental weights w(j)
t+1 can be calculated eﬃciently, as each P(j, t, q) depends on a
set of summary statistics of the observations yj+1:t, which can be updated recursively.
Eﬃcient calculation of the incremental weights w(j)
t+1 is possible by storing these
summary statistics for each set of values for the time of the last changepoint, j, and
the model for the current segment, q. These can be updated to give the summary
statistics required for each P(j, t+1, q). Thus the computational cost of calculating
t+1 is ﬁxed, and does not increase with t −j.
Simulating Changepoints
If we store the ﬁltering densities Pr(Ct|y1:t) for all t = 1, . . . , n, then it straightforward to simulate from the joint posterior distribution of the position of all changepoints prior to time n, using the idea of Chopin . To simulate one realisation
from this joint density:
(1) Set t0 = n, and k = 0
(2) Simulate tk+1 from the ﬁltering density Pr(Ctk|y1:tk), and set k = k + 1.
(3) If tk > 0 return to (2); otherwise output the set of simulated changepoints,
tk−1, tk−2, . . . , t1.
A simple extension of this algorithm which enables a large sample of realisations of
sets of changepoints to be simulated eﬃciently is described in Fearnhead .
MAP estimation
We can obtain an on-line Viterbi algorithm for calculating the maximum a posteriori
(MAP) estimate of the positions of the changepoints and the model orders for each
segment as follows. We deﬁne Mj to be the event that given a changepoint at time j,
the MAP choice of changepoints and model occurs prior to time j. For t = 1, . . . , n,
j = 0, . . . , t −1 and q = 1, . . . , ¯p,
Pr(Ct = j, model q, Mj, y1:t), and
Pr(Changepoint at t, Mt, y1:t).
We obtain the following equations
Pt(j, q) = (1 −G(t −j −1))P(j, t, q)p(q)P MAP
j,q {Pt(j, q)g(t −j)/(1 −G(t −j −1)}.
At time t, the MAP estimates of Ct and the current model order are given respectively by the values of j and q which maximise Pt(j, q). Given a MAP estimate
of Ct, ˆct we can the calculate the MAP estimates of the changepoint prior to ˆct
and the model order of that segment by the values of j and q that maximised the
right-hand side of (7). This procedure can be repeated to ﬁnd the MAP estimates
of all changepoint positions and model orders.
Approximate Inference
The computational and memory costs of the recursions for exact inference presented
in Section 3.1 both increase with time. The computational cost of both the ﬁltering
recursion and MAP recursion at time t is proportional to t, the number of possible
values of Ct. While the memory cost of storing all ﬁltering densities up to time t,
necessary to simulate from the joint posterior of all changepoints prior to t, increases
quadratically with t. For large data sets, these computational and memory costs
may become prohibitive.
A similar problem of increasing computational cost occurs in the analysis of some
hidden Markov models – though generally computational cost increases exponentially with time . Particle ﬁlters have been successfully applied to these problems by using a resampling step
to limit the computational cost at each time-step. Here we show how similar resampling ideas can be applied to the online inference of the changepoint models
we are considering. We present a variation on the optimal resampling method of
Fearnhead and Cliﬀord which is speciﬁcally designed for changepoint models,
and show theoretically why this is an optimal resampling algorithm in this case. We
also present an extension of the rejection control approach of Liu et al. which
is suitable for the analysis of batch data, and for which it is possible to control the
amount of error introduced at each resampling step.
Controlling Computational Cost
Out ﬁrst approach is to control the average (and maximum) computational cost for
analysing each new observation. At time t our exact algorithm stores the complete
posterior distribution of the time of the last changepoint Pr(Ct = ct|y1:t), for ct =
0, 1, . . . , t −1. We can approximate this by a discrete distribution with fewer, N,
support points. This approximate distribution can be described by the set of support
points, c(1), . . . , c(N), henceforth called particles, and the probability mass associated
with each of these particles, w(1), . . . , w(N), which we call weights. (The particles
and their weights will depend on t; we have suppressed this dependence to simplify
notation.)
We impose a maximum number of particles to be stored at any one time, N, such
that whenever we have N particles we immediately perform resampling to reduce
the number of particles to M < N. The average computational cost per iteration
will thus be proportional to (M + N + 1)/2, and the maximum computational cost
per iteration proportional to N.
Assume that at the current time point we have N particles; and wish to reduce these
to M particles. We propose the following stratiﬁed version of the optimal resampling algorithm of Fearnhead and Cliﬀord , which we call Stratiﬁed Optimal
Resampling (SOR).
Initialisation Assume we currently have a set of ordered particles c(1) < c(2) <
· · · < c(N), with associated weights w(1), . . . , w(N), which sum to unity.
(SOR1) Calculate α the unique solution to PN
i=1 min{1, w(i)/α} = M;
(SOR2) For i = 1, . . . , N if w(i) ≥α then keep particle c(i) with weight w(i).
Assume that A particles are kept.
(SOR3) Use the stratiﬁed resampling algorithm of Carpenter et al. to resample M −A times from the ordered set of the remaining N −A particles
(without shuﬄing). Each resampled particle is assigned a weight α.
The stratiﬁed resampling algorithm used in step SOR3 is given in Appendix A.
The use of stratiﬁed resampling in step SOR3 means that at most one copy of
each particle is kept, as the expected number of times a particle with weight w
is resampled is w/α < 1 . The only diﬀerence between this
SOR algorithm and the original algorithm of Fearnhead and Cliﬀord is that
particles are ordered before resampling in step SOR3.
As shown in Fearnhead and Cliﬀord , if we denote by W (i) the (random)
weight of a particle after resampling (so W (i) = w(i), α, or 0 depending on whether
the respective particle is kept, resampled or not resampled), then SOR is optimal
over all resampling algorithms that satisfy E(W (i)) = w(i) in terms of minimising
the mean square error: E(PN
i=1(W (i) −w(i))2). By ordering the particles in step
SOR3 we obtain the further property:
Theorem 3.1 Consider a set of N particles, c(1) < c(2) < . . . < c(N) with weights
w(1), . . . , w(N). Let W (i) be the (random) weight of particle c(i) after resampling.
Deﬁne the maximum Kolmogorov Smirnov Distance for a resampling algorithm as
mKSD = max
 w(i) −W (i)
where the ﬁrst maximisation is over realisations of W (1), . . . , W (N) with positive
probability. Then the SOR algorithm above satisﬁes mKSD ≤α (where α is deﬁned
as in SOR1). Furthermore (i) for a resampling algorithm to have mKSD ≤α then all
particles with w(i) > α must be propagated without resampling;and (ii) the mKSD for
the SOR algorithm above is less than or equal to the mKSD of the optimal resampling
algorithm of Fearnhead and Cliﬀord , and the rejection control algorithm of
Liu et al. .
Proof: See Appendix B.
Kolmogorov Smirnov distance is a natural metric for the distributions of 1-dimensional
random variables. By using (8) as a measure of error of a resampling algorithm, we
are considering the bound on Kolmogorov Smirnov distance that a resampling algorithm can introduce. The theorem gives a simple interpretation of the α calculated
in step SOR1; in terms of an upper bound on the Kolmogorov Smirnov distance
between the original and resampled weights.
We deﬁne a resampling algorithm to be unbiased if E(W (i)) = w(i) for all i. . The optimal resam-
pling algorithm of Fearnhead and Cliﬀord and rejection control are currently
the only other unbiased resampling algorithm which satisfy the condition (i) of Theorem 1. (Note that rejection control will not produce a ﬁxed number of particles
after resampling; though implementing rejection control with a threshold of α will
produce on average N resampling particles, and further that while E(W (i)) = w(i),
the resampled weights do not necessarily sum to 1.) So results (i) and (ii) of Theorem 1 show that our SOR algorithm is optimal over all existing unbiased resampling
algorithms in terms of minimising mKSD.
We have presented the SOR algorithm in terms of the general case of resampling
M particles from N current particles. For on-line inference, where there is a ﬁxed
amount of time to analyse each observation, it is natural to choose N to be the
largest number of particles that enable an observation to be analysed in less than
this amount of time; and to set M = N −1. In this case there is no diﬀerence
between SOR and the existing optimal resampling algorithm. In practice, it may
be better to choose N −M > 1 (see Section 4) as this enables the particles to be
removed to be jointly chosen in a stratiﬁed manner.
Controlling Resampling Error
An alternative to basing resampling on the average and maximum number of particles to be kept at each time step, is to choose the amount of resampling to control
the size of error that is introduced at each time step. Such an approach is most
suitable for using online algorithms to analyse batch data. For real-time data, the
frequency of observations will place an upper bound on the CPU time, and hence the
number of particles, that can be used to process each observation. By controlling
the resampling error, rather than the number of particles, we cannot ensure that
the number of particles always stays below this error.
The idea behind controlling the resampling error is given by the interpretation of α
for SOR that comes from Theorem 1. The value of α deﬁnes the maximum error
(as deﬁned by Kolmogorov Smirnov distance) that is introduced by the resampling
error. So rather than specifying the number of resampled particles which in turn
deﬁnes α, and hence the amount of error we introduce, we can instead specify α
which will then deﬁne the number of resampled particles.
Our method for controlling the resampling error is to use a stratiﬁed version of
rejection control , rather than adapt the SOR algorithm. For a
prespeciﬁed value of α, our stratiﬁed rejection control (SRC) algorithm is:
Initialisation Assume we currently have a set of ordered particles c(1) < c(2) <
· · · < c(N), with associated weights w(1), . . . , w(N), which sum to unity.
(SRC1) For i = 1, . . . , N if w(i) ≥α then keep particle c(i) with weight w(i).
Assume that A particles are kept.
(SRC2) Use the stratiﬁed resampling algorithm of Carpenter et al. to resample from the ordered set of the remaining N −A particles (without shuf-
ﬂing). The expected number of times particle c(i) is resampled is w(i)/α. Each
resampled particle is assigned a weight α.
Again the use of stratiﬁed resampling in (SRC2) means that at most one copy of
each particle is kept. Note that the sum of the particles’ weights after resampling
will not necessarily sum to 1 (though they lie between 1 −α and 1 + α), and should
be normalised to produce a probability distribution.
The diﬀerence between SRC and rejection control is that particles
are ordered and stratiﬁed resampling is used in step SRC2, as opposed to independent resampling of each particles. The use of stratiﬁed resampling means that the
maximum error of the unnormalised weights introduced by SRC, as measured by
Kolmogorov Smirnov distance, is α (this can be proved in an identical manner to
Theorem 1). Furthermore, the error of the normalised weights can be shown to be
bounded above by α/(1 −α) = α + o(α) (see Appendix C).
Numerical Examples
We tested our algorithm on three simulated examples: the Blocks and Heavisine
examples from Donoho and Johnstone and a piecewise auto-regressive model.
Each of the three data-sets are analysed under a piecewise regression model. The
design matrices for the piecewise AR model and the piecewise polynomial regression
model (for the Blocks and Heavisine data) are
, and Hs:t =
respectively, where xs = s/n and n is the number of data points. In each case we
perform model choice within each segment, choosing between model orders 1, 2 and
3. We allow for diﬀerent variances of the measurement error within each segment,
although for the Blocks and Heavisine examples we simulated data with a common
error variance across segments. Further details of the model, and calculations required for calculating the P(s, t, q)s is given in Section 2 .
Our focus here is on the performance of diﬀerent possible resampling algorithms.
The Blocks data set (see Figure 1) is a particularly simple data set to analyse, and
all reasonable resampling algorithms will give almost identical results. We show the
results here to demonstrate how the SRC algorithm naturally adapts the number of
particles that are kept. The Blocks data set has a number of obvious changepoints,
and when each of these are encountered the number of particles that are needed to
be kept is reduced to close to 1.
For the Heavisine example (see Figure 1) we compared the accuracy of various
resampling algorithms: stratiﬁed rejection control (SRC), rejection control (RC),
stratiﬁed optimal resampling (SOR), and optimal resampling (OR). We considered
two values of α for SRC and RC; and for a meaningful comparison, ﬁxed the mean
number of particles in OR and SOR to the mean number of particles kept by SRC
for each of these two values. If we set the number of resampled particles (M) to be
one less than the number of particles prior to resampling (N), then OR and SOR
are identical. We tested both N = M + 1 and N = M + 5.
Our comparison is based on the Kolmogorov Smirnov distance (KSD) between the
true ﬁltering distribution of the most recent changepoint, p(Ct|y1:t) (calculated using
the online algorithm with no resampling), and its approximation based on the various
resampling algorithms, for each t. Results are given in Table 1. The results show
Blocks Data
Posteriors of changepoints
Number of Particles
Heavisine Data
Posteriors of changepoints
Number of Particles
Figure 1: The Blocks data set (left-hand column) and Heavisine data set (right-hand
column) together with results of analysis by the SRC algorithm with α = 10−6:
data and inferred signal (top); marginal probability of changepoints (middle); and
numbers of particles kept (bottom).
that the mean KSD error is reduced by one third by using SRC rather than RC.
Both of these methods perform better than the resampling algorithms that use a
ﬁxed number of particles (for the same average number of particles); showing the
advantage of allowing the number of particles used to adapt to the ﬁltering density
being approximated. Of the two algorithms considered which use a ﬁxed number
of particles, we see an improvement of using SOR where we remove 5 particles at
each resampling step over OR (or equivalently SOR) where 1 particle is removed
at each resampling step. By removing many particles in one step, SOR is able to
jointly choose the particles to remove in a stratiﬁed way so as to reduce the error
introduced. (Note OR where we remove 5 particles at each resampling step has
worse results than the OR results shown in Table 1.)
Note that while all resampling algorithms introduce small errors at each resampling
step, it is possible for these errors to accumulate. The reason for this, appears to
be that the evidence for a changepoint at a given time t can change substantially as
more data is collected. If the evidence is small (and hence the ﬁltering probability
of a changepoint at t is less than α) at a resampling step, this can lead to the
Autoregressive Data
Stratified Rejection Control
Posteriors of change points
Number of Particles
Number of Particles
Particle Filters of Chopin 
Posteriors of change points
Results of analysing the AR dataset using SRC with α = 10−6, and
the particle ﬁlter of Chopin with 50,000 particles: data (top left), marginal
probabilities of changepoint for SRC (top right) and particle ﬁlter of Chopin 
(bottom right), and number of particles kept using SRC (bottom left). The true
AR model to the four segments have model orders 1, 1, 2, and 3 respectively. The
corresponding parameters are β = 0.4; β = −0.6; β = (−1.3, −0.36, 0.25) and
β = (−1.1, −0.24) with error variances 1.22, 0.72, 1.32 and 0.92 respectively.
corresponding particle being removed. Such a particle can not be “resurrected” as
future observations are made, even if they carry strong evidence for a changepoint
at t. However stratiﬁed resampling should ensure that a particle corresponding to
a changepoint close to t is kept, and thus the error in estimating the position of the
changepoints will still be small.
We repeated this analysis for a piecewise AR model. The results of the SRC analysis
with α = 1 × 10−6 given in Figure 2, and results of the accuracy of each resampling
method given in Table 1. We observe similar results to the Heavisine example in
terms of the relative performance of the resampling algorithms. In this case SRC
again outperforms RC by about a third. The diﬀerence in performance between
Table 1: Mean Kolmogorov Smirnov Distance in P(Ct|y1:t) averaged over t for the
Heavisine and AR models and the four resampling algorithms. Stratiﬁed Rejection
Control (SRC) and Rejection Control (RC) were implemented with α = 10−6; these
algorithms used an average number of 43 and 70 particles for the Heavisine and
AR models respectively. Optimal Resampling (OR) was implemented with N =
M + 1 = 49 and N = M + 1 = 90; Stratiﬁed Optimal Resampling (SOR) used
N = M + 5 = 51 and N = M + 5 = 92 (chosen so that the average number
of particles is the same for all algorithms for each data set). Results based on 50
replications of each algorithm for one version of each data set. The true distribution,
P(Ct|y1:t), was calculated using the exact online algorithm.
SRC and RC as compared to SOR and OR is quite substantial in this case, because
towards the end of the time series it is forced to use too few particles to adequately
approximate the ﬁltering densities. This again demonstrates the potential gains to
be obtained by allowing the number of particles used to change over time and to
adapt to the ﬁltering distribution that is being approximated.
We also ran the particle ﬁlter of Chopin . This ﬁlter does not integrate out the
parameters associated with each segment, so each particle consists of a time for the
last changepoint together with a value of the parameters for the current segment.
The ﬁlter uses MCMC to update the parameters of a subset of particles at each
iteration. We ran the ﬁlter with 50,000 particles, using a Gibbs sampler update on
the parameters of 1/3 of the particles at each iteration. This took over an order of
magnitude longer to run than the SRC algorithm, and even is substantially more
time-consuming to implement than the exact online algorithm.
The results for the estimate of the marginal probabilities of the changepoints is
shown in Figure 2. The ﬁlter of Chopin suﬀers from a loss of diversity in the
particles – with many positions being assigned zero probability of being a change-
point, when in fact there is a non-negligible probability as can be seen from the
output of the SRC ﬁlter. To give a quantitative comparison of the two methods we
calculated the mean absolute error between the estimates of the marginal probabilities of the changepoints shown in Figure 2 with those based on the exact particle
ﬁlter algorithm. These were 0.010 and 0.002 for the ﬁlter of Chopin and the
SRC ﬁlter respectively.
DNA Segmentation
In recent years there has been an explosion in the amount of data describing the
genetic make-up of diﬀerent organisms; for example the complete DNA sequence of
one human genome is now known as a result of the Human Genome project. There is
interest in learning about the genomic features of diﬀerent organisms, and learning
how these features may have evolved and how they correlate with each other.
We consider the problem of understanding the structure of C+G content within
the genome. A common model for the C+G content of the human genome is that
there are large, of the order of 300 kilobases (kb), regions of roughly homogeneous
C+G content, called Isochores . Furthermore
C+G content is known to correlate with various features of the genome, such as
high recombination rates and gene density .
Currently, the most common method for segmenting an organism’s genome into regions of diﬀerent C+G content is implemented in the computer program IsoFinder
 . This is based on a recursive segmentation procedure, which
initially classiﬁes a large genomic region as consisting of a single Isochore (region of
common C+G content). It then considers in turn each possible position for adding
a changepoint, and splitting the data into two Isochores. For each possible position,
a t-statistic is calculated for testing whether the mean C+G content is diﬀerent in
the two putative Isochores. For each changepoint, a p-value is calculated for its
value of the t-statistic using a bootstrap procedure, and if the smallest p-value is
less than some predeﬁned threshold, then the corresponding changepoint is added.
This procedure is repeated, with at each step each current Isochore being tested for
whether it can be split into two Isochores. See Oliver et al. for more details.
We consider a Bayesian approach to segmenting a genomic region into Isochores.
The potential advantages of a Bayesian approach include (i) quantifying and averaging over the uncertainty in the number and positions of the Isochores; (ii) jointly
estimating all Isochore positions ; and (iii) the large amount of data available for
each organism makes it straightforward to construct sensible prior distributions.
One of the computational challenges of such an analysis is the large amount of
data that needs to be analysed (for example human chromosomes consist of around
100 million bases). We simplify this burden by ﬁrst summarising our data by the
number of DNA sites which are C or G within consecutive windows (each window
being of the order of a few kb in width), an approach which also has the advantage
of averaging our the very local high variation in C+G content caused for example by
CpG islands and Alu elements. We then hope that our online changepoint algorithm
will be able to eﬃciently analyse the resulting data, and one of the main aims of
the study we present here is to test whether such an approach is computationally
practicable for analysing the large amount of genomic data currently available.
The model we use is based on the following simple model for the data y1:n, which is
similar to the implicit model assumed by IsoFinder. A data set is shown in Figure
3. The tth data point, yt, represents the number of DNA bases which are either C
or G within the tth window. If this window lies within the ith Isochore then we
yt = µi + σiǫt,
where µi is the mean C+G content of each window within the ith Isochore, σ2
the error variance within the ith Isochore, and ǫt is some independent error. We
assume that ǫt has a Gaussian distribution and we assume standard conjugate priors
(see Section 2) for the µis and σis, with the prior parameters chosen from an initial
analysis of C+G data with a moving median ﬁlter. For each model we assumed a
geometric distribution for the length of each Isochore.
Results of our analysis using SRC with α = 10−6 are shown in Figure 3. Our main
focus is on the computational practicability of a Bayesian analysis of such data, and
Positions(kb)
Percentage of C+G
Figure 3: Analysis of 35Mb of data from human chromosome 1. The red line is the
posterior mean GC content.
our method took 6 seconds on a desktop PC to analyse this data set.
This application does not need to be analysed by an online algorithm, such as the
one we used. However Fearnhead showed that the version of our algorithm
without resampling can be more eﬃcient for analysing changepoint models than
some commonly used MCMC algorithms.
Furthermore, by using resampling we
have been able to vastly reduce the computational and storage cost of analysing
the data. For example our implementation with resampling uses an average of 117
particles at each time step; whereas without resampling the algorithm would require
an average of over 3,500 particles for each time-step.
Discussions
We have considered a class of changepoint models, which have a speciﬁc conditional
independence structure (see Section 2), and shown how the direct simulation algorithm of Fearnhead can be implemented online. Such an algorithm can be
viewed as an exact particle ﬁlter, and resampling ideas taken from particle ﬁlters
can be used to reduce the computational complexity of the direct simulation algorithm (at the cost of introducing error). We have presented two simple extensions
of existing resampling algorithms, which are particularly well suited to changepoint
problems (or any problems where the underlying state of interest is 1-dimensional).
In simulation studies, our new resampling algorithms decreased the error of the
resulting particle ﬁlter by up to one third, compared to particle ﬁlters using the
existing resampling approaches. We have shown that the new resampling algorithms
satisfy a minimax optimality criteria on the error, as measured by Kolmogorov
Smirnov distance, introduce by resampling. Furthermore this result gives a natural
interpretation of the threshold that needs to be speciﬁed in the stratiﬁed rejection
control algorithm which will aid its implementation in practice.
There is great ﬂexibility with implementing resampling algorithms within particle
ﬁlters which we have not explored. For example Liu and Chen discuss the
frequency with which resampling should occur, and Liu et al. suggest using rejection control only when the variance of the particle ﬁlter weights exceeds
some threshold. Whilst we have not fully investigated these issues, the results from
Section 4 suggests that the advantages of using stratiﬁcation within optimal resampling or rejection control will increase as the frequency of resampling decreases (or
equivalently the amount of particles resampled increases at each resampling step).
Acknowledgements This work is supported by EPSRC grant C531558. We dedicate this paper to the memory of Nick Smith who helped with the application to
detecting Isochores.