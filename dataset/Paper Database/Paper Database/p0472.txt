FedHealth: A Federated Transfer Learning Framework for Wearable Healthcare
Yiqiang Chen1,2,3∗, Jindong Wang4 , Chaohui Yu1,2 , Wen Gao3 , Xin Qin1,2
1Beijing Key Lab. of Mobile Computing and Pervasive Devices, Inst. of Computing Tech., CAS
2University of Chinese Academy of Sciences, Beijing, China
3Pengcheng Laboratory, Shenzhen, China
4Microsoft Research Asia, Beijing, China
 , 
With the rapid development of computing technology, wearable devices such as smart phones
and wristbands make it easy to get access to people’s health information including activities, sleep,
sports, etc. Smart healthcare achieves great success by training machine learning models on large
quantity of user data. However, there are two critical challenges. Firstly, user data often exists in
the form of isolated islands, making it difﬁcult
to perform aggregation without compromising privacy security. Secondly, the models trained on the
cloud fail on personalization. In this paper, we propose FedHealth, the ﬁrst federated transfer learning
framework for wearable healthcare to tackle these
challenges. FedHealth performs data aggregation
through federated learning, and then builds personalized models by transfer learning.
It is able to
achieve accurate and personalized healthcare without compromising privacy and security.
Experiments demonstrate that FedHealth produces higher
accuracy (5.3% improvement) for wearable activity
recognition when compared to traditional methods.
FedHealth is general and extensible and has the potential to be used in many healthcare applications.
Introduction
Activities of daily living (ADL) are highly related to people’s health. Recently, the development of wearable technologies helps people to understand their health status by tracking
activities using wearable devices such as smartphone, wristband, and smart glasses. Wearable healthcare has the potential to provide early warnings to several cognitive diseases
such as Parkinson’s [Chen et al., 2017; Chen et al., 2019] and
small vessel diseases [Chen et al., 2018b]. Other applications
include mental health assessment [Wang et al., 2014], fall detection [Wang et al., 2017b], and sports monitoring [Wang
et al., 2019a]. In fact, there is a growing trend for wearable healthcare over the years [Andreu-Perez et al., 2015;
Hiremath et al., 2014].
∗Corresponding Author
Smartphone
Figure 1: The data islanding and personalization problems in wearable healthcare
In healthcare applications, machine learning models are often trained on sufﬁcient user data to track health status. Traditional machine learning approaches such as Support Vector
Machines (SVM), Decision Tree (DT), and Hidden Markov
Models (HMM) are adopted in many healthcare applications [Ward et al., 2016]. The recent success of deep learning
achieves satisfactory performances by training on larger sizes
of user data. Representative networks include Convolutional
Neural Networks (CNN), Recurrent Neural Networks (RNN),
and Autoencoders [Wang et al., 2019a].
Unfortunately, there are two critical challenges in today’s
wearable healthcare (Figure 1). First of all, in real life, data
often exists in the form of isolated islands. Although there
are plenty of data in different organizations, institutes, and
subjects, it is not possible to share them due to privacy and
security concerns. In Figure 1, when the same user uses different products from two companies, his data stored in two
clouds cannot be exchanged.
This makes it hard to train
powerful models using these valuable data. Additionally, recently, China, the United States, and the European Union
enforced the protection of user data via different regularizations [Inkster, 2018; Voigt and Von dem Bussche, 2017].
Hence, the acquisition of massive user data is not possible in
real applications.
The other important issue is personalization. Most of the
methods are based on a common server model for nearly all
users. After acquiring sufﬁcient user data to train a satisarXiv:1907.09173v2 [cs.LG] 11 May 2021
factory machine learning model, the model itself is then distributed to all the user devices on which the daily health information can be tracked. This process lacks personalization.
As can be seen, different users have different physical characteristics and daily activity patterns. Therefore, the common
model fails to perform personalized healthcare.
In this paper, we propose FedHealth, the ﬁrst federated
transfer learning framework for wearable healthcare. Fed-
Health can solve both of the data islanding and personalization problems. Through federated learning [Yang et al., 2019;
Yang et al., 2018] and homomorphic encryption [Rivest et al.,
1978], FedHealth aggregates the data from separate organizations to build powerful machine learning models with the
users’ privacy well preserved. After the cloud model is built,
FedHealth utilizes transfer learning [Pan and Yang, 2010]
methods to achieve personalized model learning for each organization. The framework can incrementally update. Fed-
Health is extensible and can be deployed to many healthcare
applications to continuously enhance their learning abilities
in real life.
In summary, this paper makes the following contributions:
1. We propose FedHealth, the ﬁrst federated transfer learning framework for wearable healthcare, which aggregates
the data from different organizations without compromising
privacy security, and achieves personalized model learning
through knowledge transfer.
2. We show the excellent performance achieved by Fed-
Health in smartphone based human activity recognition. Experiments show that FedHealth dramatically improves the
recognition accuracy by 5.3% compared to traditional learning approaches.
3. FedHealth is extensible and can be the standard framework to many healthcare applications. With the users’ privacy
well preserved and good performance achieved, it can be easily deployed to other healthcare applications.
Related Work
In this section, we introduce the related work in three aspects:
wearable healthcare, federated machine learning, and transfer
Wearable Healthcare
Certain activities in daily life reﬂect early signals of some
cognitive diseases [Atkinson et al., 2007; Michalak et al.,
2009]. For instance, the change of gait may result in small
vessel disease or stroke. A lot of researchers pay attention
to monitor users’ activities using body-worn sensors [Voigt
and Von dem Bussche, 2017], through which daily activities
and sports activities can be recognized. With the development of wearable technology, smartphone, wristbands, and
smart glasses provide easy access to this information. Many
endeavors have been made [Wang et al., 2014; Albinali et al.,
2010; Wang et al., 2017b]. Other than activities, physiological signals can also help to detect certain diseases. EEG (electroencephalography) is used to detect seizures [Menshawy
et al., 2015; Hiremath et al., 2014]. Authors can also use
RGB-D cameras to detect users’ activities [Lei et al., 2012;
Rashidi and Cook, 2010]. For a complete survey on sensors
based activity recognition and healthcare, interested readers
are recommended to refer to [Wang et al., 2019a].
It is noteworthy that traditional healthcare applications often build the model by aggregating all the user data. However, in real applications, data are often separate and cannot be easily shared due to privacy issues [Inkster, 2018;
Voigt and Von dem Bussche, 2017]. Moreover, the models
built by applications lack the ability of personalization.
Federated Machine Learning
A comprehensive survey on federated learning is in [Yang et
al., 2019]. Federated machine learning was ﬁrstly proposed
by Google [Koneˇcn`y et al., 2016; Koneˇcn`y et al., 2016],
where they trained machine learning models based on distributed mobile phones all over the world. The key idea is
to protect user data during the process.
Since then, other
researchers started to focus on privacy-preserving machine
learning [Bonawitz et al., 2017; Shokri and Shmatikov, 2015;
Geyer et al., 2017], federated multi-task learning [Smith et
al., 2017], as well as personalized federated learning [Chen et
al., 2018a]. Federated learning has the ability to resolve the
data islanding problems by privacy-preserving model training
in the network.
According to [Yang et al., 2019], federated learning can
mainly be classiﬁed into three types: 1) horizontal federated
learning, where organizations share partial features; 2) vertical federated learning, where organizations share partial samples; and 3) federated transfer learning, where neither samples or features have much in common. FedHealth belongs to
federated transfer learning category. It is the ﬁrst of its kind
tailored for wearable healthcare applications.
Transfer Learning
Transfer learning aims at transferring knowledge from existing domains to a new domain. In the setting of transfer
learning, the domains are often different but related, which
makes knowledge transfer possible. The key idea is to reduce the distribution divergence between different domains.
To this end, there are mainly two kinds of approaches: 1) instance reweighting [Huang et al., 2012; Huang et al., 2007],
which reuses samples from the source domain according to
some weighting technique; and 2) feature matching, which
either performs subspace learning by exploiting the subspace
geometrical structure [Wang et al., 2018b; Sun et al., 2016;
Fernando et al., 2013; Gong et al., 2012], or distribution alignment to reduce the marginal or conditional distribution divergence between domains [Wang et al., 2019b;
Wang et al., 2018a; Wang et al., 2017a; Pan et al., 2011;
?]. Recently, deep transfer learning methods have made considerable success in many application ﬁelds [Rozantsev et al.,
2019; Ganin and Lempitsky, 2015; Tzeng et al., 2014]. For a
complete survey, please refer to [Pan and Yang, 2010].
FedHealth is mainly related to deep transfer learning. Most
of the methods assume the availability of training data, which
is not realistic. FedHealth makes it possible to do deep transfer learning in the federated learning framework without accessing the raw user data. Therefore, it is more secure.
Cloud Model
New User Model
Figure 2: Overview of the FedHealth framework. “User” represents organizations
The Proposed FedHealth Framework
In this section, we introduce the FedHealth framework for
federated transfer learning based wearable healthcare.
Problem Deﬁnition
We are given data from N different users (organizations), denoted the users by {S1, S2, · · · , SN} and the sensor readings
they provide are denoted by {D1, D2, · · · , DN}. Conventional methods train a model MALL by combining all the
data D = D1 ∪D2 ∪· · · ∪DN. All the data have different
distributions. In our problem, we want to collaborate all the
data to train a federated model MF ED, where any user Si
does not expose its data Di to each other. If we denote the accuracy as A, then the objective of FedHealth is to ensure the
accuracy of federated learning is close to that of conventional
learning denoted by:
|AF ED −AALL| < ∆,
where ∆is an extremely small non-negative real number.
Overview of the Framework
FedHealth aims to achieve accurate personal healthcare
through federated transfer learning without compromising
privacy security. Figure 2 gives an overview of the framework. Without loss of generality, we assume there are 3 users
(organizations) and 1 server, which can be extended to the
more general case. The framework mainly consists of four
procedures. First of all, the cloud model on the server end is
train based on public datasets. Then, the cloud model is distributed to all users where each of them can train their own
model on their data. Subsequently, the user model can be uploaded to the cloud to help train a new cloud model. Note that
this step does not share any user data or information but the
encrypted model parameters. Finally, each user can train personalized models by integrating the cloud model and its previous model and data for personalization. In this step, since
there is large distribution divergence between cloud and user
model, transfer learning is performed to make the model more
tailored to the user (right part in Figure 2). It is noteworthy
that all the parameter sharing processes does not involve any
leakage of user data. Instead, they are ﬁnished through homomorphic encryption [Rivest et al., 1978].
The federated learning paradigm is the main computing
model for the whole FedHealth framework.
It deals with
model building and parameter sharing during the entire process. After the server model is learned, it can be directly applied to the user. This is just what traditional healthcare applications do for model learning. It is obvious that the samples in
the server are having highly different probability distribution
with the data generated by each user. Therefore, the common
model fails in personalization. Additionally, user models cannot easily be updated continuously due to the privacy security
Federated Learning
FedHealth adopts the federated learning paradigm [Yang et
al., 2019] to achieve encrypted model training and sharing.
This step mainly consists of two critical parts: cloud and user
model learning. After obtaining the server model, it is distributed to the user end to help them train their own models.
As for each user, it trains its own model with the help of the
server model.
In FedHealth, we adopt deep neural networks to learn both
the cloud and user model. Deep networks perform end-toend feature learning and classiﬁer training by taking the raw
inputs of the user data as inputs. Let fS denote the server
model to be learned, then the learning objective becomes:
ℓ(yi, fS(xi)),
where ℓ(·, ·) denotes the loss for the network, e.g.
crossentropy loss for classiﬁcation tasks. {xi, yi}n
i=1 are samples
from the server data with n their sizes. Θ denotes all the parameters to be learned, i.e. the weight and bias.
After acquiring the cloud model, it is distributed to all the
users. As we can see from the “wall” in Figure 2, direct shar-
Figure 3: The transfer learning process of FedHealth
ing of user information is forbidden. This process uses homomorphic encryption [Rivest et al., 1978] to avoid information
leakage. Since the encryption is not our main contribution,
we will show the process of additively homomorphic encryption using real numbers. The encryption scheme of the weight
matrix and bias vector are following the same idea. The additively homomorphic encryption of a real number a is denoted
as ⟨a⟩. In additively homomorphic encryption, for any two
numbers a and b, we have ⟨a⟩+ ⟨b⟩= ⟨a + b⟩. Therefore,
the parameter sharing can be done without leaking any information from the users. Through federated learning, we can
aggregate user data without compromising privacy security.
Technically, the learning objective for user u is denoted as:
It is important to note that FedHealth does not perform parameter sharing as in [Cheng et al., 2019] for computational
efﬁciency. After all the user model fu is trained, it is uploaded
to the server for aggregation. As for aggregation, server can
align the old model with the model from each user subsequently. Considering the computational burden, server can
also achieve scheduled update (e.g. every night) using uploading user models. The result is a new server model f ′
Note that the new server model f ′
S is based on the knowledge
from all users. Therefore, it has better generalization ability.
Transfer Learning
Federated learning solves the data islanding problem. Therefore, we can build models using all the user data. Another important factor is the personalization. Even if we can directly
use the cloud model, it still performs poor on a particular user.
This is due to the distribution difference between the user and
the cloud data. The common model in the server only learns
the coarse features from all users, while it fails in learning the
ﬁne-grained information on a particular user.
In this paper, FedHealth uses transfer learning to build a
personalized model for each user. Recall that features in deep
networks are highly transferable in the lower levels of the network since they focus on learning common and low-level features. The higher layers learn more speciﬁc features to the
task [Yosinski et al., 2014]. In this way, after obtaining the
parameters of the cloud model, we can perform transfer learning on the user to learn their personalized models.
Figure 3 presents the process of transfer learning for a
speciﬁc convolutional neural network (CNN). Suppose the
Algorithm 1 The learning procedure of FedHealth
Input: Data from different users {D1, D2, · · · , DN}, η
Output: Personalized user model fu
1: Construct a cloud model fS using Eq. (2)
2: Distribute fS to all users via homomorphic encryption
3: Train user models using Eq. (3)
4: Update all user models to the server using homomorphic
encryption.
Then server update its model by aligning
with user model
5: Distribute f ′
S to all users, then perform transfer learning on each user to get their personalized model fu using
6: Repeat the above procedures with the continuously
emerging user data
network is composed of two convolutions layers (conv1,
conv2), two max-pooling layers (pool1, pool2), two
fully connected layers (fc1, fc2), and one softmax layer
for classiﬁcation. The network is designed for human activity
recognition where the input data is the activity signals for a
user and the output is his activity classes.
In model transfer, we think that the convolution layers aims
at extracting low-level features about activity recognition.
Thus we keep these layers along with the max-pooling layers frozen, which means we do not update their parameters in
backpropagation. As for the fully connected layers fc1 and
fc2, since they are higher level, we believe they focus on
learning speciﬁc features for the task and user. Therefore, we
update their parameters during training. The softmax serves
as the classiﬁcation function, which can be formulated as:
where zc denotes the learned probability for class C, and yj
is the ﬁnal classiﬁcation result.
FedHealth adapts the inputs from different domains by replacing fc2 with an alignment layer. This is strictly different that in DDC [Tzeng et al., 2014] and other recent methods where we have access to both the source and target data.
In our problem, we only have the user data and the cloud
model. To this end, we borrow the idea from [Rozantsev et
al., 2018] and regularize the weights. Given the network from
the server and user, we add a correlation alignment [Sun et
al., 2016] layer before the softmax layer to further adapt the
domains. This alignment function is used to align the secondorder statistics between the inputs. Formally, the loss of correlation alignment is computed as follows:
4d2 ∥CS −CT ∥2
where ∥·∥2
F denotes the squared matrix Frobenius norm and
d is the dimension of the embedding features. CS and CT
are the covariance matrices of the source and target weights
computed by [Sun et al., 2016]. Therefore, denote η the tradeoff parameter, the loss for the user model is computed by:
i )) + ηℓCORAL.
Learning Process
The learning procedure of FedHealth is presented in Algorithm 1. Note that this framework works continuously with
the new emerging user data. FedHealth can update the user
model and cloud model simultaneously when facing new user
data. Therefore, the longer the user uses the product, the more
personalized the model can be. Other than transfer learning,
FedHealth can also embed other popular methods for personalization such as incremental learning [Rebufﬁet al., 2017].
The entire framework can also adopt other machine learning methods other than deep networks.
For instance, the
gradient boosting decision tree can be integrated into the
framework to harness the power of ensemble learning. These
lightweight models can be deployed to computation restricted
wearable devices. This makes FedHealth more general to real
applications.
Experiments
In this section, we evaluate the performance of the proposed
FedHealth framework via extensive experiments on human
activity recognition.
We adopt a public human activity recognition dataset called
UCI Smartphone [Anguita et al., 2012]. This dataset contains 6 activities collected from 30 users.
The 6 activities are WALKING, WALKING-UPSTAIRS, WALKING-
DOWNSTAIRS, SITTING, STANDING, and LAYING.
There are 30 volunteers within an age bracket of 19-48 years.
Each volunteer wears a smartphone (Samsung Galaxy S II)
on the waist. Using its embedded accelerometer and gyroscope, collectors captured 3-axial linear acceleration and 3axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually.
The obtained dataset has been randomly partitioned into two
sets, where 70% of the volunteers were selected for generating the training data and 30% the test data. There are 10,299
instances in total. The statistical information of the dataset is
shown in Table 1.
Table 1: Statistical information of the dataset
Sampling rate
Accelerometer
In order to construct the problem situation in FedHealth,
we change the standard setting for the dataset. We extracted
5 subjects (Subject IDS 26 ∼30) and regard them as the isolated users which cannot share data due to privacy security.
Data on the remaining 25 users are used to train the cloud
model. Henceforth, the objective is to use the cloud model
and all the 5 isolated subjects to improve the activity recognition accuracy on the 5 subjects without compromising the
privacy. In short, it is a variant of the framework in Figure 2
where there are 5 users.
Table 2: Classiﬁcation accuracy (%) of the test subject
Implementation Details
On both the server and the user end, we adopt a CNN for
training and prediction. The network is composed of 2 convolutional layers, 2 pooling layers, and 3 fully connected layers.
The network adopts a convolution size of 1 × 9. It uses minibatch Stochastic Gradient Descent (SGD) for optimization.
During training, we use 70% of the training data for model
training, while the rest 30% is for model evaluation. We ﬁx
η = 0.01. We set the learning rate to be 0.01 with batch
size of 64 and training epochs ﬁxed to 80. The accuracy of
user u is computed as Au = |x:x∈Du∧ˆy(x)=y(x)|
, where y(x)
and ˆy(x) denote the true and predicted labels on sample x,
respectively.
We follow [Rivest et al., 1978] for homomorphic encryption in federated learning. During transfer learning, we freeze
all the convolutional and pooling layers in the network. Only
the parameters of the fully connected layers are updated with
SGD. To show the effectiveness of FedHealth, we compare its
performance with traditional learning, where we record the
performances on each subject using the server model only.
For notational brevity, we use NoFed to denote this setting.
We also compare the performances of KNN, SVM, and random forest (RF) with FedHealth. The hyperparameters of all
the comparison methods are tuned using cross-validation. For
the fair study, we run all the experiments 5 times to record the
average accuracies.
Classiﬁcation Accuracy
The classiﬁcation accuracies of activity recognition for each
subject are shown in Table 2. The results indicate that our proposed FedHealth achieves the best classiﬁcation accuracy on
all users. Compared to NoFed, it signiﬁcantly improves the
average results by 5.3%. Compared to the traditional methods (KNN, SVM, and RF), FedHealth also greatly improves
the recognition results. In short, it demonstrates the effectiveness of our proposed FedHealth framework.
The results also show that for activity recognition, the deep
methods (NoFed and FedHealth) achieve better results than
traditional methods. This is due to the representation capability of deep neural networks, while traditional methods have
to rely on hand-crafted feature learning. Another advantage
of deep learning is that the models can be updated online and
incrementally without retraining, while traditional methods
require further incremental algorithms. This property is extremely valuable in federated transfer learning where model
reuse is important and helpful.
Accuracy (%)
+Fine-tune
Figure 4: Extending FedHealth with other transfer learning methods
Evaluation of Extensibility
In this section, we analyze the extensibility of FedHealth with
different transfer learning approaches. We compare its performance with two methods: 1) ﬁne-tuning, which only ﬁnetunes the network on each subject without explicitly reducing
the distribution divergence between domains; and 2) transfer with MMD (Maximum Mean Discrepancy) [Wang et al.,
2018b], which replaces the alignment loss with MMD loss.
The comparison results are shown in Figure 4.
From the results, we can see that other than the alignment
loss, FedHealth can also achieve promising results using ﬁnetuning or MMD. The results of transfer learning signiﬁcantly
outperform no transfer by 4% on average accuracy. This indicates that the transfer learning procedure of FedHealth is
highly effective and extensible. Therefore, FedHealth is general and can be extended in many applications by integrating
other transfer learning algorithms. Moreover, the federated
learning procedure can also be extended using other encryption methods, which can be the future research.
Detailed Analysis
We provide detailed analysis to FedHealth via comparing its
confusion matrix with that of NoFed. The confusion matrix is
known as an effective metric to show the efﬁcacy of a method
since it provides ﬁne-grained classiﬁcation results on each
task. For simplicity, we show the confusion matrices of subject 2 in Table 3. The results of other subjects follow the same
tendency. Along with the confusion matrix, the precision (P),
recall (R), and macro F1 score (F1) are all computed to give
a thorough view of the results.
Combining the results in Table 2 and 3, we can clearly see
that FedHealth can not only achieve the best accuracy, but
also reach the best precision, recall, and F1 scores. The confusion matrix shows that FedHealth can reduce the misclassi-
ﬁcation rate, especially on class C1 (Walking). Since walking is the most common activities in healthcare, it means that
FedHealth is effective in recognizing this activity. To summarize, FedHealth is more accurate in recognizing personalized
activities, which makes it more advantageous in healthcare
applications.
Table 3: Classiﬁcation report of NoFed and FedHealth
Discussions
FedHealth is a general framework for wearable healthcare.
This paper provides a speciﬁc implementation and evaluation
of this idea. It is adaptable to several healthcare applications.
In this section, we discuss its potential to be extended and
deployed to other situations with possible solutions.
1. FedHealth with incremental learning. Incremental learning [Rebufﬁet al., 2017] has the ability to update the model
with the gradually changing time, environment, and users. In
contrast to transfer learning that focuses on model adaptation,
incremental learning makes it possible to update the model in
real-time without much computation.
2. FedHealth as the standard for wearable healthcare in
the future.
FedHealth provides such a platform where all
the companies can safely share data and train models. In
the future, we expect that FedHealth be implemeted with
blockchain technology [Zheng et al., 2018] where user data
can be more securely stored and protected. We hope that Fed-
Health can become the standard for wearable healthcare.
3. FedHealth to be applied in more applications. This work
mainly focuses on the possibility of federated transfer learning in healthcare via activity recognition. In real situations,
FedHealth can be deployed at large-scale to more healthcare
applications such as elderly care, fall detection, cognitive disease detection, etc. We hope that through FedHealth, federated learning can become federated computing which can
become a new computing model in the future.
Conclusions and Future Work
In this paper, we propose FedHealth, the ﬁrst federated transfer learning framework for wearable healthcare. FedHealth
aggregates the data from different organizations without compromising privacy security, and achieves personalized model
learning through knowledge transfer. Experiments on human
activity recognition have demonstrated the effectiveness of
the framework. We also present a detailed discussion for its
potential from speciﬁc technical improvement to the potential
for healthcare applications.
FedHealth opens a new door for future research in wearable healthcare. In the future, we plan to extend FedHealth to
the detection of Parkinson’s disease where it can be deployed
in hospitals.
Acknowledgements
This paper is supported in part by National Key R & D Plan
of China (No. 2017YFB1002802), NSFC (No. 61572471),
and Beijing Municipal Science & Technology Commission (No.Z171100000117017).