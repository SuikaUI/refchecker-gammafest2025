Deakin Research Online,
Deakin University’s Research Repository
Deakin University CRICOS Provider Code: 00113B
Credit card fraud detection using AdaBoost and majority voting
Randhawa, Kuldeep, Loo, Chu Kiong, Seera, Manjeevan, Lim, Chee Peng and Nandi, Asoke K
2018, Credit card fraud detection using AdaBoost and majority voting, IEEE access, vol. 6, pp.
14277-14284.
DOI: 10.1109/ACCESS.2018.2806420
©2018, IEEE
Reproduced by Deakin University under the terms of the Creative Commons Attribution Licence
Downloaded from DRO:
 
Received January 3, 2018, accepted February 10, 2018, date of publication February 15, 2018, date of current version March 28, 2018.
Digital Object Identifier 10.1109/ACCESS.2018.2806420
Credit Card Fraud Detection
Using AdaBoost and Majority Voting
KULDEEP RANDHAWA
1, CHU KIONG LOO
1, (Senior Member, IEEE),
MANJEEVAN SEERA
2,3, (Senior Member, IEEE), CHEE PENG LIM4,
AND ASOKE K. NANDI5,6, (Fellow, IEEE)
1Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur 50603, Malaysia
2Faculty of Engineering, Tunku Abdul Rahman University College, Kuala Lumpur 53300, Malaysia
3Faculty of Engineering, Computing and Science, Swinburne University of Technology (Sarawak Campus), Kuching 93350, Malaysia
4Institute for Intelligent Systems Research and Innovation, Deakin University, Geelong, VIC 3220, Australia
5Department of Electronic and Computer Engineering, Brunel University London, Uxbridge UB8 3PH, U.K.
6Key Laboratory of Embedded Systems and Service Computing, College of Electronic and Information Engineering, Tongji University, Shanghai 200092, China
Corresponding author: Chu Kiong Loo ( )
ABSTRACT Credit card fraud is a serious problem in ﬁnancial services. Billions of dollars are lost due
to credit card fraud every year. There is a lack of research studies on analyzing real-world credit card data
owing to conﬁdentiality issues. In this paper, machine learning algorithms are used to detect credit card fraud.
Standard models are ﬁrst used. Then, hybrid methods which use AdaBoost and majority voting methods are
applied. To evaluate the model efﬁcacy, a publicly available credit card data set is used. Then, a real-world
credit card data set from a ﬁnancial institution is analyzed. In addition, noise is added to the data samples to
further assess the robustness of the algorithms. The experimental results positively indicate that the majority
voting method achieves good accuracy rates in detecting fraud cases in credit cards.
INDEX TERMS AdaBoost, classiﬁcation, credit card, fraud detection, predictive modelling, voting.
I. INTRODUCTION
Fraud is a wrongful or criminal deception aimed to bring
ﬁnancial or personal gain . In avoiding loss from fraud,
two mechanisms can be used: fraud prevention and fraud
detection. Fraud prevention is a proactive method, where it
stops fraud from happening in the ﬁrst place. On the other
hand, fraud detection is needed when a fraudulent transaction
is attempted by a fraudster.
Credit card fraud is concerned with the illegal use of credit
card information for purchases. Credit card transactions can
be accomplished either physically or digitally . In physical
transactions, the credit card is involved during the transactions. In digital transactions, this can happen over the telephone or the internet. Cardholders typically provide the card
number, expiry date, and card veriﬁcation number through
telephone or website.
With the rise of e-commerce in the past decade, the use of
credit cards has increased dramatically . The number of
credit card transactions in 2011 in Malaysia were at about
320 million, and increased in 2015 to about 360 million.
Along with the rise of credit card usage, the number of
fraud cases have been constantly increased. While numerous
authorization techniques have been in place, credit card fraud
cases have not hindered effectively. Fraudsters favour the
internet as their identity and location are hidden. The rise in
credit card fraud has a big impact on the ﬁnancial industry.
The global credit card fraud in 2015 reached to a staggering
USD $21.84 billion .
Loss from credit card fraud affects the merchants, where
they bear all costs, including card issuer fees, charges, and
administrative charges . Since the merchants need to
bear the loss, some goods are priced higher, or discounts
and incentives are reduced. Therefore, it is imperative to
reduce the loss, and an effective fraud detection system to
reduce or eliminate fraud cases is important. There have
been various studies on credit card fraud detection. Machine
learning and related methods are most commonly used,
which include artiﬁcial neural networks, rule-induction techniques, decision trees, logistic regression, and support vector
machines . These methods are used either standalone or by
combining several methods together to form hybrid models.
In this paper, a total of twelve machine learning algorithms
are used for detecting credit card fraud. The algorithms range
from standard neural networks to deep learning models. They
are evaluated using both benchmark and real-world credit
card data sets. In addition, the AdaBoost and majority voting
VOLUME 6, 2018
This work is licensed under a Creative Commons Attribution 3.0 License. For more information, see 
K. Randhawa et al.: Credit Card Fraud Detection Using AdaBoost and Majority Voting
methods are applied for forming hybrid models. To further
evaluate the robustness and reliability of the models, noise
is added to the real-world data set. The key contribution of
this paper is the evaluation of a variety of machine learning
models with a real-world credit card data set for fraud detection. While other researchers have used various methods on
publicly available data sets, the data set used in this paper are
extracted from actual credit card transaction information over
three months.
The organization of this paper is as follows. In Section II,
related studies on single and hybrid machine learning algorithms for ﬁnancial applications is given. The machine learning algorithms used in this study are presented in Section III.
The experiments with both benchmark and real-world credit
card data sets are presented in Section IV. Concluding
remarks and recommendations for further work are given in
Section V.
II. RELATED STUDIES
In this section, single and hybrid machine learning algorithms
for ﬁnancial applications are reviewed. Various ﬁnancial
applications from credit card fraud to ﬁnancial statement
fraud are reviewed.
A. SINGLE MODELS
For credit card fraud detection, Random Forest (RF),
Support Vector Machine, (SVM) and Logistic Regression
(LOR) were examined in . The data set consisted of oneyear transactions. Data under-sampling was used to examine
the algorithm performances, with RF demonstrating a better
performance as compared with SVM and LOR . An Arti-
ﬁcial Immune Recognition System (AIRS) for credit card
fraud detection was proposed in . AIRS is an improvement
over the standard AIS model, where negative selection was
used to achieve higher precision. This resulted in an increase
of accuracy by 25% and reduced system response time
by 40% .
A credit card fraud detection system was proposed in ,
which consisted of a rule-based ﬁlter, Dumpster–Shafer
adder, transaction history database, and Bayesian learner.
The Dempster–Shafer theory combined various evidential
information and created an initial belief, which was used to
classify a transaction as normal, suspicious, or abnormal. If a
transaction was suspicious, the belief was further evaluated
using transaction history from Bayesian learning . Simulation results indicated a 98% true positive rate . A modiﬁed Fisher Discriminant function was used for credit card
fraud detection in . The modiﬁcation made the traditional
functions to become more sensitive to important instances.
A weighted average was utilized to calculate variances,
which allowed learning of proﬁtable transactions. The results
from the modiﬁed function conﬁrm it can eventuate more
proﬁt .
Association rules are utilized for extracting behavior patterns for credit card fraud cases in . The data set focused
on retail companies in Chile. Data samples were de-fuzziﬁed
and processed using the Fuzzy Query 2+ data mining
tool . The resulting output reduced excessive number
of rules, which simpliﬁed the task of fraud analysts .
To improve the detection of credit card fraud cases, a solution was proposed in . A data set from a Turkish bank
was used. Each transaction was rated as fraudulent or otherwise. The misclassiﬁcation rates were reduced by using the
Genetic Algorithm (GA) and scatter search. The proposed
method doubled the performance, as compared with previous
results .
Another key ﬁnancial loss is related to ﬁnancial statement
fraud. A number of methods including SVM, LOR, Genetic
Programming (GP) and Probabilistic Neural Network (PNN)
were used to identify ﬁnancial statement fraud . A data
set involving 202 Chinese companies was used. The t-statistic
was used for feature subset selection, where 18 and 10 features were selected in two cases. The results indicated that
the PNN performed the best, which was followed by GP .
Decision Trees (DT) and Bayesian Belief Networks (BNN)
were used in to identify ﬁnancial statement fraud.
The input comprised the ratios taken from ﬁnancial statements of 76 Greek manufacturing ﬁrms. A total of 38 ﬁnancial statements were veriﬁed to be fraud cases by auditors.
The BBN achieved the best accuracy of 90.3% accuracy,
while DT achieved 73.6% .
A computational fraud detection model (CFDM) was proposed in to detect ﬁnancial reporting fraud. It utilized textual data for fraud detection. Data samples from
10-K ﬁlings at Security and Exchange Commission were
used. The CDFM model managed to distinguish fraudulent
ﬁlings from non-fraudulent ones . A fraud detection
method based on user accounts visualization and thresholdtype detection was proposed in . The Self-Organizing
Map (SOM) was used as a visualization technique. Realworld data sets related to telecommunications fraud, computer network intrusion, and credit card fraud were evaluated.
The results were displayed with visual appeal to data analysts
as well as non-experts, as high-dimensional data samples
were projected in a simple 2-dimensional space using the
Fraud detection and understanding spending patterns to
uncover potential fraud cases was detailed in . It used the
SOM to interpret, ﬁlter, and analyze fraud behaviors. Clustering was used to identify hidden patterns in the input data.
Then, ﬁlters were used to reduce the total cost and processing
time. By setting appropriate numbers of neurons and iteration
steps, the SOM was able to converge fast. The resulting model
appeared to be an efﬁcient and a cost-effective method .
B. HYBRID MODELS
Hybrid models are combination of multiple individual models. A hybrid model consisting of the Multilayer Perceptron (MLP) neural network, SVM, LOR, and Harmony
Search (HS) optimization was used in to detect corporate
tax evasion. HS was useful for ﬁnding the best parameters for
the classiﬁcation models. Using data from the food and textile
VOLUME 6, 2018
K. Randhawa et al.: Credit Card Fraud Detection Using AdaBoost and Majority Voting
sectors in Iran, the MLP with HS optimization acquired the
highest accuracy rates at 90.07% . A hybrid clustering
system with outlier detection capability was used in to
detect fraud in lottery and online games. The system aggregated online algorithms with statistical information from the
input data to identify a number of fraud types. The training data set was compressed into the main memory while
new data samples could be incrementally added into the
stored data-cubes. The system achieved a high detection rate
at 98%, with a 0.1% false alarm rate .
To tackle ﬁnancial distress, clustering and classiﬁer
ensemble methods were used to form hybrid models in .
The SOM and k-means algorithms were used for clustering,
while LOR, MLP, and DT were used for classiﬁcation. Based
on these methods, a total of 21 hybrid models with different
combinations were created and evaluated with the data set.
The SOM with the MLP classiﬁer performed the best, yielding the highest prediction accuracy . An integration of
multiple models, i.e. RF, DR, Roush Set Theory (RST), and
back-propagation neural network was used in to build
a fraud detection model for corporate ﬁnancial statements.
Company ﬁnancial statements in period of 1998 to 2008 were
used as the data set. The results showed that the hybrid model
of RF and RST gave the highest classiﬁcation accuracy .
Methods to identify automobile insurance fraud were
described in and . A principal component analysis (PCA)-based (PCA) RF model coupled with the potential
nearest neighbour method was proposed in . The traditional majority voting in RF was replaced with the potential
nearest neighbour method. A total of 12 different data sets
were used in the experimental study. The PCA-based model
produced a higher classiﬁcation accuracy and a lower variance, as compared with those from RF and DT methods .
The GA with fuzzy c-means (FCM) was proposed in 
for identiﬁcation of automobile insurance fraud. The test
records were separated into genuine, malicious or suspicious
classes based on the clusters formed. By discarding the genuine and fraud records, the suspicious cases were further
analyzed using DT, SVM, MLP, and a Group Method of Data
Handling (GMDH). The SVM yielded the highest speciﬁcity
and sensitivity rates .
III. MACHINE LEARNING ALGORITHMS
A total of twelve algorithms are used in this experimental
study. They are used in conjunction with the AdaBoost and
majority voting methods. The details are as follows.
A. ALGORITHMS
Naïve Bayes (NB) uses the Bayes’ theorem with strong or
naïve independence assumptions for classiﬁcation. Certain
features of a class are assumed to be not correlated to others.
It requires only a small training data set for estimating the
means and variances is needed for classiﬁcation.
The presentation of data in form of a tree structure is useful
for ease of interpretation by users. The Decision Tree (DT)
is a collection of nodes that creates decision on features
connected to certain classes. Every node represents a splitting
rule for a feature. New nodes are established until the stopping criterion is met. The class label is determined based
on the majority of samples that belong to a particular leaf.
The Random Tree (RT) operates as a DT operator, with the
exception that in each split, only a random subset of features is available. It learns from both nominal and numerical
data samples. The subset size is deﬁned using a subset ratio
parameter.
The Random Forest (RF) creates an ensemble of random
trees. The user sets the number of trees. The resulting model
employs voting of all created trees to determine the ﬁnal
classiﬁcation outcome. The Gradient Boosted Tree (GBT) is
an ensemble of classiﬁcation or regression models. It uses
forward-learning ensemble models, which obtain predictive
results using gradually improved estimations. Boosting helps
improve the tree accuracy. The Decision Stump (DS) generates a decision tree with a single split only. It can be used in
classifying uneven data sets.
The MLP network consists of at least three layers of nodes,
i.e., input, hidden, and output. Each node uses a non-linear
activation function, with the exception of the input nodes.
It uses the supervised backpropagation algorithm for training.
The version of MLP used in this study is able to adjust
the learning rate and hidden layer size automatically during
training. It uses an ensemble of networks trained in parallel
with different rates and number of hidden units.
The Feed-Forward Neural Network (NN) uses the backpropagation algorithm for training as well. The connections
between the units do not form a directed cycle, and information only moves forward from the input nodes to the output
nodes, through the hidden nodes. Deep Learning (DL) is
based on an MLP network trained using a stochastic gradient descent with backpropagation. It contains a large number of hidden layers consisting of neurons with tanh, recti-
ﬁer, and maxout activation functions. Every node captures
a copy of the global model parameters on local data, and
contributes periodically toward the global model using model
averaging.
Linear Regression (LIR) models the relationship between
scalar variables by ﬁtting a linear equation to the observed
data. The relationships are modelled using linear predictor
functions, with unknown model parameters estimated from
the data set. The Akaike criterion, a measure of relative
goodness of ﬁt for a statistical model, is used for model selection. Logistic Regression (LOR) can handle data with both
nominal and numerical features. It estimates the probability
of a binary response based on one or more predictor features.
The SVM can tackle both classiﬁcation and regression
data. SVM builds a model by assigning new samples to one
category or another, creating a non-probabilistic binary linear
classiﬁer. It represents the data samples as points in the space
mapped so such that the data samples of different categories
can be separated by a margin as wide as possible. A summary
of the strengths and limitations of the methods discussed
earlier is given in Table 1.
VOLUME 6, 2018
K. Randhawa et al.: Credit Card Fraud Detection Using AdaBoost and Majority Voting
TABLE 1. Strengths and limitations of machine learning methods.
B. MAJORITY VOTING
Majority voting is frequently used in data classiﬁcation,
which involves a combined model with at least two algorithms. Each algorithm makes its own prediction for every
test sample. The ﬁnal output is for the one that receives the
majority of the votes, as follows.
Consider K target classes (or labels), with Ci, ∀i ∈3 =
{1, 2, . . . , K} represents the i-th target class predicted by a
classiﬁer. Given an input x, each classiﬁer provides a prediction with respect to the target class, yielding a total of K
prediction, i.e., P1, . . . , PK. Majority voting aims to produce
a combined prediction for input x, P (x) = j, j ∈3 from all
the K predictions, i.e., pk (x) = jk, k = 1, . . . , K. A binary
function can be used to represent the votes, i.e.,
Vk (x ∈Ci) =
if pk (x) = i, i ∈3
Then, sum the votes from all K classiﬁers for each Ci, and
the label that receives the highest vote is the ﬁnal (combined)
predicted class.
C. ADABOOST
Adaptive Boosting or AdaBoost is used in conjunction with
different types of algorithms to improve their performance.
The outputs are combined by using a weighted sum, which
represents the combined output of the boosted classiﬁer, i.e.,
where every ft is a classiﬁer (weak learner) that returns the
predicted class with respect to input x. Each weak learner
gives an output prediction, h(xi), for every training sample.
In every iteration t, the weak learner is chosen, and is allotted
a coefﬁcient, αt, so that the training error sum, Et, of the
resulting t-stage boosted classiﬁer is minimized,
E [Ft−1 (xi) + αth(xi)]
where Ft−1(x) is the boosted classiﬁer built in the previous
stage, E(F) is the error function, and ft(x) = αth(x) is weak
learner taken into consideration for the ﬁnal classiﬁer.
AdaBoost tweaks weak learners in favor of misclassiﬁed
data samples. It is, however, sensitive to noise and outliers. As long as the classiﬁer performance is not random,
AdaBoost is able to improve the individual results from different algorithms.
IV. EXPERIMENTS
In this section, the experimental setup is ﬁrstly detailed.
This is followed by a benchmark evaluation using a publicly
available data set. The real-world credit card data set is then
evaluated. All experiments have been conducted using Rapid-
Miner Studio 7.6. The standard settings for all parameters in
RapidMiner have been used. A 10-fold cross-validation (CV)
has been used in the experiments as it can reduce the bias
associated with random sampling in the evaluation stage .
A. EXPERIMENTAL SETUP
In the credit card data set, the number of fraudulent transactions is usually a very small as compared with the total
number of transactions. With a skewed data set, the resulting
accuracy does not present an accurate representation of the
system performance. Misclassifying a legitimate transaction
causes poor customer services, and failing to detect fraud
cases causes loss to the ﬁnancial institution and customers.
This data imbalance problem causes performance issues in
machine learning algorithms. The class with the majority
samples inﬂuences the results. Under-sampling has been
used by Bhattacharyya et al. , Duman et al. , and
Phua et al. to handle data imbalance problems. As such,
under-sampling is used in this paper to handle the skewed
While there is no best way of describing the true and false
positives and negatives using one indicator, the best general
measure is the Matthews Correlation Coefﬁcient (MCC) .
MCC measures the quality of a two-class problem, which
VOLUME 6, 2018
K. Randhawa et al.: Credit Card Fraud Detection Using AdaBoost and Majority Voting
takes into account the true and false positives and negatives.
It is a balanced measure, even when the classes are from
different sizes. MCC can be calculated using:
TP × TN −FP × FN
√(TP + FP)(TP + FN)(TN + FP)(TN + FN)
where the result of +1 indicates a perfect prediction, and −1 a
total disagreement.
B. BENCHMARK DATA
A publicly available data set is downloaded from .
It contains a total of 284,807 transactions made in September 2013 by European cardholders. The data set contains
492 fraud transactions, which is highly imbalanced. Due to
the conﬁdentiality issue, a total of 28 principal components
based on transformation are provided. Only the time and the
amount data are not transformed, and are provided as such.
TABLE 2. Results of various individual models.
The results from various models are shown in Table 2.
It can be seen that the accuracy rates are high, generally
around 99%. This however is not the real outcome, as the rate
of fraud detection varies from 32.5% for RT up to 83% for
NB. The rate of non-fraud detection is similar to the accuracy
rates, i.e., the non-fraud results dominate the accuracy rates.
SVM produces the highest MCC score of 0.813, while the
lowest is from NB with an MCC score of 0.219.
In addition to the standard models, AdaBoost has been
used with all 12 models. The results are shown in Table 3.
It can be seen that the accuracy and non-fraud detection rates
are similar to those without AdaBoost. However, the fraud
detection rates increase from 79.8% to 82.3% for SVM. Some
models suffer a minor reduction in the fraud detection rate up
to 1%. The MCC rates show very minor changes, in which
NB is able to improve its MCC score from 0.219 to 0.235.
Based on the models that produce good rates in Table 2,
the majority voting method is applied to the models. A total
of 7 models are reported in Table 4. The accuracy rates are
all above 99%, with DS + GBT yields a perfect non-fraud
rate. The best fraud detection rate is achieved by NN + NB
at 78.8%. The highest MCC score at 0.823 is yielded by
NN + NB, which is higher than those form individual models.
TABLE 3. Results of AdaBoost.
TABLE 4. Results of majority voting.
TABLE 5. Performance comparison with results extracted from .
For performance comparison, the results presented in Saia
and Carta are used, which used the same data set with
a 10-fold CV evaluation. The results are shown in Table 5.
Two models were used in , one from the Frequency
Domain (FD) and another with Random Forest (RF). The sensitivity rate as deﬁned in measures the number of transactions correctly classiﬁed as legitimate, which is the same
as the non-fraud detection rate in Tables 2 to 4. The best
accuracy and sensitivity acquired by RF are at 95% and 91%,
respectively, as shown in Table 5. In comparison, the best
accuracy and non-fraud (sensitivity) from the experiments in
this paper are above 99% for most of the individual models.
C. REAL-WORLD DATA
A real credit card data set from a ﬁnancial institution in
Malaysia is used in the experiment. It is based on cardholders
from the South-East Asia region from February to April 2017.
A total of 287,224 transactions are recorded, with 102 of
them classiﬁed as fraud cases. The data consist of a time
series of transactions. To comply with customer conﬁdentiality requirements, no personal identifying information is used.
The features used in the experiment are given in Table 6.
A total of 11 features are used. The codes used are based
on the standard ISO 8583 , while the last two codes
are based on ISO 4217. As PAN is a 16-digit credit card
VOLUME 6, 2018
K. Randhawa et al.: Credit Card Fraud Detection Using AdaBoost and Majority Voting
TABLE 6. Features in credit card data.
TABLE 7. Results of various individual models.
number, a running sequence of numbers is used to mask the
real numbers, in order to protect the personal information of
customers. The results from various individual models are
shown in Table 7. All accuracy rates are above 99%, with the
exception of SVM at 95.5%. The non-fraud detection rates
of NB, DT, and LIR are at 100%, while the rest are close to
perfect, with the exception of SVM. The best MCC rates are
from NB, DT, RF, and DS, at 0.990. The fraud detection rates
vary from 7.4% for LIR up to 100% for RF, GBT, DS, NN,
MLP, and LOR.
Similar to the benchmark experiment, AdaBoost has been
used with all individual models. The results are shown
in Table 8. The accuracy and non-fraud detection rates are
similar to those without AdaBoost. AdaBoost helps improve
the fraud detection rates, with a noticeable difference for NB,
DT, RT, which produce a perfect accuracy rate. The most
TABLE 8. Results of AdaBoost.
TABLE 9. Results of majority voting.
signiﬁcant improvement is achieved by LIR, i.e., from 7.4%
to 94.1% accuracy. This clearly indicates the usefulness
of AdaBoost in improvement the performance of individual classiﬁers. The best MCC score of 1 are achieved
by NB and RF.
The majority voting method is then applied to the same
models used in the benchmark experiment. The results
are shown in Table 9. The accuracy and non-fraud detection rates are perfect, or near perfect. DS+GBT, DT+DS,
DT+GBT, and RF+GBT achieve a perfect fraud detection
rate. The MCC scores are close to or at 1. The results of
majority voting are better than those of individual models.
To further evaluate the robustness of the machine learning
algorithms, all real-world data samples are corrupted noise,
at 10%, 20% and 30%. Noise is added to all data features.
Figure 1 shows the fraud detection rate while Figure 2 shows
the MCC score. It can be seen that with the addition of
noise, the fraud detection rate and MCC rates deteriorate,
as expected. The worst performance, i.e. the largest decrease
FIGURE 1. Fraud detection rates with different percentages of noise.
VOLUME 6, 2018
K. Randhawa et al.: Credit Card Fraud Detection Using AdaBoost and Majority Voting
FIGURE 2. MCC scores with different percentages of noise.
in accuracy and MCC, is from majority voting of DT+NB
and NB+GBT. DS+GBT, DT+DS and DT+GBT show
gradual performance degradation, but their accuracy rates are
still above 90% even with 30% noise in the data set.
V. CONCLUSIONS
A study on credit card fraud detection using machine learning
algorithms has been presented in this paper. A number of
standard models which include NB, SVM, and DL have been
used in the empirical evaluation. A publicly available credit
card data set has been used for evaluation using individual
(standard) models and hybrid models using AdaBoost and
majority voting combination methods. The MCC metric has
been adopted as a performance measure, as it takes into
account the true and false positive and negative predicted outcomes. The best MCC score is 0.823, achieved using majority
voting. A real credit card data set from a ﬁnancial institution
has also been used for evaluation. The same individual and
hybrid models have been employed. A perfect MCC score
of 1 has been achieved using AdaBoost and majority voting
methods. To further evaluate the hybrid models, noise from
10% to 30% has been added into the data samples. The majority voting method has yielded the best MCC score of 0.942 for
30% noise added to the data set. This shows that the majority
voting method offers robust performance in the presence of
For future work, the methods studied in this paper will be
extended to online learning models. In addition, other online
learning models will be investigated. The use of online learning will enable rapid detection of fraud cases, potentially in
real-time. This in turn will help detect and prevent fraudulent
transactions before they take place, which will reduce the
number of losses incurred every day in the ﬁnancial sector.