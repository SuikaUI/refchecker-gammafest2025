Deep neural network for the dielectric response of insulators
Linfeng Zhang
Program in Applied and Computational Mathematics,
Princeton University, Princeton, NJ 08544, USA
Mohan Chen
CAPT, HEDPS, College of Engineering, Peking University, Beijing 100871, China
Department of Physics, Temple University, Philadelphia, PA 19122, USA
Laboratory of Computational Physics, Institute of Applied Physics and
Computational Mathematics, Huayuan Road 6, Beijing 100088, China
Department of Mathematics and Program in Applied and Computational Mathematics,
Princeton University, Princeton, NJ 08544, USA and
Beijing Institute of Big Data Research, Beijing, 100871, P.R. China
Roberto Car†
Department of Chemistry, Department of Physics,
Program in Applied and Computational Mathematics,
Princeton Institute for the Science and Technology of Materials,
Princeton University, Princeton, NJ 08544, USA
We introduce a deep neural network to model in a symmetry preserving way the environmental
dependence of the centers of the electronic charge. The model learns from ab initio density functional
theory, wherein the electronic centers are uniquely assigned by the maximally localized Wannier
functions. When combined with the Deep Potential model of the atomic potential energy surface, the
scheme predicts the dielectric response of insulators for trajectories inaccessible to direct ab initio
simulation. The scheme is non-perturbative and can capture the response of a mutating chemical
environment. We demonstrate the approach by calculating the infrared spectra of liquid water at
standard conditions, and of ice under extreme pressure, when it transforms from a molecular to an
ionic crystal.
PACS numbers:
Machine learning (ML) schemes introduced in the last
decade can model accurately the potential energy
surface (PES) of a multi-atomic system upon training with
ﬁrst-principle electronic density functional theory (DFT)
data . These approaches extend the size and time
range of ab initio molecular dynamics (AIMD) ,
and make possible studies of rare events, such as crystal
nucleation, with enhanced sampling methodologies in
simulations of ab initio quality .
Most approaches, so far, focused on representing the
dependence of the PES, a scalar quantity, on the atomic
coordinates. Recently, methods to ﬁt the environmental dependence of electronic properties have been proposed . In particular, kernel based methods have
been used to represent the polarization and its time derivatives , which are needed in many studies of
materials, including calculations of infrared (IR) , Raman , and sum frequency generation (SFG) 
spectra, transport calculations in ionic liquids and superionic crystals , and simulations of ferroelectric
phase transformations . These schemes learn from
AIMD trajectories, but, so far, the calculated spectra
of liquid water do not match the quality of direct
many-body expansions of the dipole moment .
Here we propose an alternative approach based on deep
neural networks (DNNs) and maximally localized Wannier
functions (MLWFs) , i.e. electronic orbitals with
minimal spatial spread obtained from a unitary transformation of the occupied orbitals in insulators. In spin
saturated systems the MLWFs describe electron pairs.
Thus, upon assigning charges of 2e−to the Wannier centers (WCs), i.e. the centers of the MLWF distributions,
the electric polarization is the dipole moment M of the
neutral system of point charges made by the WCs and the
atomic nuclei. In extended periodic systems, M includes
an arbitrary quantum , but its derivatives and correlation functions are well deﬁned and describe observable
properties.
 
In systems with diﬀerent atomic species, the WCs ﬂuctuate near the most electronegative atoms during molecular
evolution. As a consequence of the nearsightedness of the
electronic matter , the WCs only depend on the
atoms in their local environment, and their positions can
be accurately represented by the DNN model, called Deep
Wannier (DW), which is introduced here. It is an end-toend scheme that does not use any ad hoc construction, in
addition to the coordinate information and the network
itself, to map input atomic coordinates into output WC
coordinates. The model is size extensive, preserves translational, rotational, and permutational symmetry, and
yields a polarization that varies continuously with the
atomic coordinates. As such it can describe how the polarization responds to chemical bond changes in electronic
insulators.
To demonstrate the methodology, we compute (a) the
IR absorption spectrum of liquid water at standard temperature and pressure, and (b) the frequency dependent
imaginary dielectric function in the high pressure transformation of ice VII to ice VII’, and from ice VII’ to
ice X . In ice VII there are 2 donor and 2 acceptor
H-bonds per oxygen, as stipulated by the ice rule ,
and the water molecules are always well deﬁned. In ice
VII’ the hydrogens hop between two equivalent sites near
each oxygen of an O-O bond, occasionally violating the
ice rule. In ice X the hydrogens sit in the mid O-O bonds,
the water molecules cannot be identiﬁed, and the system
is better described in terms of O2−and H+ ions. This
behavior is reﬂected in the O-H pair correlation functions
in Fig. 1. For more sophisticated analyses and a phase
diagram see e.g. Ref . The polarization change accompanying the above transformations is seamlessly described
by DW. The scheme should also work at higher temperature when ice X becomes superionic , or at even higher
temperature when the superionic crystal melts into an
ionic liquid . Similarly, the scheme should work for
proton transfer events in water at standard conditions
when neutral molecules interconvert with hydronium and
hydroxide ion complexes (see e.g. Ref. ).
In our implementation, DW is trained with valence only
pseudopotential electronic structure calculations. In the
laboratory frame, the positions of the atoms and of the
WCs are r1, r2, ..., ri, ..., rN and w1, w2, ..., wi, ..., wNw,
respectively. We assume, for simplicity, that the WCs
are only associated to one atomic species and consider
water, in which there are 4 WCs per oxygen, as a concrete
example . It is easy to select with a cutoﬀdistance
the 4 WCs with coordinates wli=1,..,4 that are closer to
the oxygen i located at ri. Their centroid
is well deﬁned even when water molecules cannot be
identiﬁed.
Our aim is to construct a vector function
rOH (Angstrom)
FIG. 1: (Color online) Schematic illustration of the transitions
from ice VII to ice VII’ and from ice VII’ to ice X by the O-H
pair correlation functions gOH(r) calculated at T=300 K and
various pressures. Inset: Idealized structure of ice VII and ice
f that gives wi if the positions of the Ni atoms rk in
the neighborhood Ni of ri, deﬁned by the radius rc, are
known, i.e.:
wi = f({rk, k ∈Ni}).
Here i is an oxygen atom but the atoms k include oxygens and hydrogens.
To ensure that f preserves the
translational, rotational, and permutational symmetry,
we generalize the scheme for the Deep Potential (DP), the
DNN representing the PES, introduced in Refs .
First, we make a local frame transformation to the
primed coordinates, which preserve translational symmetry:
ki ≡rk −ri,
i ≡wi −ri.
Then, we introduce a weight function s(r′
ki) equal to
ki at short distance r′
ki)1/2, and decaying smoothly to zero as r′
ki approaches rc.
Using s(r′
ki), we describe the atomic coordinates r′
ki) with the 4-vector qki = (q1
ki) to enforce continuous evolution when atoms enter/exit the neighborhood.
Next, we enforce permutational invariance and rotational covariance by introducing two DNNs, an embedding
DNN and a fitting DNN. The number of hidden layers
and outputs is reﬁned in the training procedure. The
embedding DNN is the matrix E = (Eik) = (Ei(s(r′
with M rows and Ni columns optimized by training, which
maps the set {s(r′
ki), k ∈Ni} onto M outputs.
The set of generalized coordinates {qki} in a neighborhood is represented by the matrix Q = (Qkλ) = (qλ
with Ni rows and 4 columns. Multiplication of E by Q
gives the matrix T = EQ with M rows and 4 columns,
whose generic element is:
Let S be the matrix formed by the ﬁrst M ′ (<M) rows of
T . Multiplication of T by ST , the transpose of S, gives
the matrix D of dimension M × M ′, called the feature
D = T ST .
D is the argument of the ﬁtting DNN, a row matrix
F (D) = {Fj(D), j = 1, ..., M} that converts the atomic
coordinate information encoded in D onto M outputs,
which are mapped onto the centroid w′
upon multiplication with with the last three columns of
Fj(D)Tj,λ+1.
Finally, wi is retrieved from w′
i using Eq. 3 and one
obtains the desired representation of Eq. 2.
We notice that wi constructed in the way introduced
above naturally preserves all the symmetry requirements.
Translational symmetry is preserved by the adoption of
a local frame and relative positions in Eq. 3. Permutational symmetry is preserved by the smooth sum over
the neighboring atoms in Eq. 4. Finally, as shown in
Eq. 4, the last three columns of T (λ = 2, 3, 4) transform
covariantly under rotation because (Qk2, Qk3, Qk4) transforms like r′
ki. Then it is straightforward to verify that
the elements of D, and hence F (D), are invariant under
rotation. Therefore, w′λ
i in Eq. 6 transforms like Tj,λ+1,
and is hence rotationally covariant. The values of M,
M ′, and of the number of layers of the DNNs are chosen
empirically based on performance. In the applications
discussed in this paper we adopt M=100 (of the same
order of the number of atoms in a neighborhood), M ′=6,
and use a 3-layer representation for all the DNNs. The
parameters γ of the embedding and ﬁtting networks are
determined by training, i.e., an optimization process that
minimizes a loss function, here the mean square diﬀerence
between the DW prediction and the training data. The
Adam stochastic gradient descent method is adopted
for the optimization. Generalization of this formalism to
tensor properties (like the polarizability) is introduced in
Ref. .
DW should be combined with a DNN for the PES to
study the evolution of the polarization along MD trajectories. For consistency, the two networks should be trained
with electronic structure data at the same level of theory,
as in the applications below, which used DW and the DP
representation of the PES . Ab initio electronic
structure data are expensive and eﬃcient learning strategies are crucial. We used the iterative learning scheme
of Ref. . In this approach, a DNN, initially trained
with a limited pool of ab initio data, is used to explore
inexpensively the conﬁguration space. A small subset
of the visited conﬁgurations is selected with a suitable
error indicator and single shot ab initio calculations are
Wavenumber (cm−1)
n(ω)α(ω) (103 cm−1)
H2O, calculated
H2O, experimental
Wavenumber (cm−1)
D2O, calculated
D2O, experimental
(Color online) IR absorption spectra of liquid
H2O (left) and D2O (right).
The continuous lines report
DPMD+DW calculations at ∼300 K. The dashed lines report
experimental data for H2O at 298 K (Ref. ) and for D2O
at 295 K (Ref. ).
performed at these conﬁgurations. Training with the new
data improves the model for further exploration and selection, followed by new data acquisition and learning. The
protocol is repeated until all the explored conﬁgurations
are described with satisfactory accuracy. The error indicator exploits the highly non-linear dependence of the DNN
models on the network parameters. As a consequence,
diﬀerent initializations of the parameters lead to diﬀerent
local minima in the landscape of the loss function, originating an ensemble of minimizing DNNs. The variance
of the predictions within this ensemble is an intrinsic
property of a DNN model and is often a reliable indicator
of its accuracy . In our experience, good DNN
models constructed with the above procedure require signiﬁcantly less ab initio data in the target thermodynamic
range than learning approaches based on independent
AIMD sampling data.
In the following we report calculations on liquid water
at STP and on ice undergoing pressure induced structural
phase transitions. For liquid water at STP, we did not use
the incremental data generation scheme, since the training
data were available and accessible online from previous
work . For high-pressure ice, electronic structure data
were not available, and we constructed DP and DW from
scratch using the incremental learning procedure outlined
above. Full details on the implementation, training, and
validation of the models (DP and DW) are given in the
Supplemental Material [SM]. The code for this work has
been integrated into the open-source software package
DeePMD-kit and we used the DP-GEN package 
for the iterative scheme.
We use DFT at the hybrid functional level (PBE0 )
with dispersion corrections for STP water. Using DW
and DP we calculate the IR absorption spectra of
liquid H2O and D2O for a cell with 512 molecules under
periodic boundary conditions. We use two microcanonical
trajectories lasting 0.5 ns each, for H2O and D2O, at an
average temperature of ∼300 K at the equilibrium density
of the simulation. The frequency dependent absorption
coeﬃcient per unit length, α(ω), times the refractive
index, n(ω), is given by the Fourier transform of the
time correlation function of the time derivative of the cell
polarization
˙M = +6e P
l ˙rOl + e P
m ˙rHm −8e P
according to:
α(ω)n(ω) = 2πβ
dte−iωt⟨˙M (0) · ˙M (t)⟩,
where V is the volume, β = 1/kBT is the inverse temperature, and kB is Boltzmann’s constant. Fig. 2 shows
that the calculated spectra are in good agreement with
the corresponding experimental observations.
Similarly accurate IR spectra of liquid water can be
obtained from representations of the PES and
the dipole moment based on many-body molecular
expansions. These powerful approaches are limited to
molecular liquids and crystals.
By contrast, our nonperturbative method works also for non-molecular systems, as we demonstrate by considering ice at T=300 K in
the pressure range from 20 to 110 GPa, wherein structural
phase transitions from ice VII to ice VII’ and to ice X
occur. We adopted the PBE functional approximation
of DFT as in Refs. . We constructed DP/DW
networks for ice in the temperature range from 240 to
330 K and pressure range from 20 to 120 GPa with the
iterative learning approach set forth earlier in this paper.
This procedure required a total of 2248 single shot DFT
calculations with a 16 molecule cell and a total of 2400
single shot DFT calculations with a 128 molecule cell. For
each cell size, the corresponding computational eﬀort was
less than the cost of a short (∼5 ps) AIMD trajectory.
We sampled the ice conﬁgurations at 300 K in the pressure range 20 - 110 GPa with constant pressure DPMD
on a variable periodic cell with 128 water molecules, using
a mild Nosé-Hoover thermostat with damping
time of 5 ps, much longer than the vibrational periods, to
control the temperature. Using DP+DW, we calculated
α(ω)n(ω) according to Eq. 7 with a set of 0.5 ns long
trajectories at various pressures. A direct AIMD study
of the spectral changes in the closely related transformations from ice VIII (the proton ordered form of ice VII)
to ice VII’ and to ice X, reported in a pioneering paper
by Bernasconi et al. , used a small 16 molecule cell
and ∼10 ps long trajectories.
Our results in Fig. 3 show a dramatic change with
pressure of the product α(ω)n(ω). We also report the
same quantity obtained from reﬂectance measurements
of pressurized ice in a diamond anvil cell . Experimental data are not available for ω ≲800 cm−1, and
for 1800 cm−1 < ω <2400 cm−1. The theoretical curves
are displayed at approximately 10 GPa higher pressure
than the experimental curves to empirically correct for
the missing nuclear quantum eﬀects in the simulation and
the inaccuracy of the adopted functional approximation.
Taking into account the limitations of theory and experiment, the experimental trend is reproduced nicely
Wavenumber (cm 1)
n(ω)α(ω)(105cm 1)
experimental
FIG. 3: (Color online) Red: IR absorption spectra of H2O ice
at 300 K and pressures from 20 to 110 GPa (128 molecules,
0.5 ns trajectories). Blue: Experimental results converted
from imaginary part of the dielectric function ϵ2(ω) of H2O at
295 K and various pressures obtained from a Kramers-Kronig
analysis of experimental reﬂectivity spectra , according to
the relationship n(ω)α(ω) = 4πωϵ2(ω). Dashed lines denote
oscillator ﬁt since there are no data in the range of strong
diamond absorption (1800 to 2400 cm−1). The curves are
oﬀset in the vertical direction for clarity.
by the DP+DW simulations. At the lowest pressures,
molecular vibration features can be discerned, such as
the H stretching band at about 3000 cm−1. These modes
soften dramatically and broaden with pressure, indicating
a progressive weakening of the covalent O-H bonds. In
the simulation, the spectral changes are quite abrupt at
∼70 GPa, suggesting that this should be approximately
the transition pressure to symmetric ice X. The same
behavior is observed in experiment at ∼60 GPa. By further increasing the pressure, two strong features emerge,
characteristic of ice X, that harden and sharpen with
The higher frequency feature has dominant
weight on H while the lower frequency feature has more O
weight. Interestingly, there is no close correspondence between the IR spectrum and the power spectrum of atomic
dynamics reported in the [SM], suggesting that extreme
anharmonicity aﬀects the IR spectrum, as pointed out in
Ref. .
Quantum eﬀects in the dynamics were ignored in our
calculations. These eﬀects are small but non-negligible
in liquid water and should be more pronounced near the
ice VII to X transition in view of the relatively large
isotope eﬀect on the transition pressure, which is ∼10
GPa higher for D2O than for H2O , suggesting that
the transition is facilitated by proton tunneling. The
calculation of dynamic quantum correlation functions is
a major challenge for statistical simulations. Quantum
IR correlations have been calculated recently for liquid
water using approximate methods like ring polymer 
and centroid MD, indicating that quantum corrections tend to red shift the classical spectral features.
It would be extremely interesting to study how quantum
corrections aﬀect the dielectric properties in the ice VII,
VII’, and X transition sequence. Further studies of these
issues will be facilitated by methods like DPMD and DW,
which improve signiﬁcantly the statistical quality of ab
initio simulations, as they are orders of magnitude faster
than DFT methods and scale linearly with system size.
Quantitative cost comparisons between direct AIMD and
DP/DW simulations are reported in Figs. S2 and S3 in
In summary, DW is a useful tool to parametrize the
dependence of the polarization on the atomic environment. The approach can be naturally extended to
the environmental dependence of the polarizability tensor Pδσ = ∂Mδ
∂Eσ (Mδ and Eσ are Cartesian components
of the polarization and of the electric ﬁeld), allowing us
to compute Raman and sum frequency generation spectra . Access to the concerted evolution
of atomic coordinates and polarization in simulations of
large systems over long time scales should also open the
way to studies of ferroelectric phase transitions with MD
simulations of ab initio quality, rather than relying on
eﬀective Hamiltonian models . Finally, related
symmetry preserving DNN schemes have been considered
in Refs. and we defer to future work a discussion
of the mathematical and machine learning aspects of the
DP/DW models.
The work of L. Z., X. W., W. E, and R.C. was conducted
at the Center “Chemistry in Solution and at Interfaces”
(CSI) funded by the DOE Award DE-SC001934. The
work of L. Z and W. E was partially supported by a gift
from iFlytek to Princeton University and by ONR grant
N00014-13-1-0338.
The work of H.W. was supported
by the NSFC under grant 11871110, and the National
Key Research and Development Program of China under
grants 2016YFB0201200 and 2016YFB0201203. We used
resources of the National Energy Research Scientiﬁc Computing Center (DoE Contract No. DE-AC02-05cH11231).
We are also grateful for computing time at the Terascale
Infrastructure for Groundbreaking Research in Science
and Engineering (TIGRESS) of Princeton University.
∗Electronic address: 
† Electronic address: 
 J. Behler and M. Parrinello, Physical Review Letters 98,
146401 .
 A. P. Bartók, M. C. Payne, R. Kondor, and G. Csányi,
Physical Review Letters 104, 136403 .
 M. Rupp, A. Tkatchenko, K.-R. Müller,
VonLilienfeld, Physical Review Letters 108, 058301
Mayagoitia, K. Hansen, A. Tkatchenko, K.-R. Müller,
and O. A. Von Lilienfeld, New Journal of Physics 15,
095003 .
 V. Botu, R. Batra, J. Chapman, and R. Ramprasad, The
Journal of Physical Chemistry C 121, 511 .
 S. Chmiela, A. Tkatchenko, H. E. Sauceda, I. Poltavsky,
K. T. Schütt,
and K.-R. Müller, Science Advances 3,
e1603015 .
 K. Schütt, P.-J. Kindermans, H. E. S. Felix, S. Chmiela,
A. Tkatchenko, and K.-R. Müller, in Advances in Neural
Information Processing Systems pp. 992–1002.
 J. S. Smith, O. Isayev,
and A. E. Roitberg, Chemical
Science 8, 3192 .
 J. Han, L. Zhang, R. Car, and W. E, Communications
in Computational Physics 23, 629 .
 L. Zhang, J. Han, H. Wang, R. Car, and W. E, Physical
Review Letters 120, 143001 .
 L. Zhang, J. Han, H. Wang, W. Saidi, R. Car,
W. E, in Advances in Neural Information Processing Systems 31, edited by S. Bengio, H. Wallach, H. Larochelle,
K. Grauman, N. Cesa-Bianchi, and R. Garnett pp. 4441–4451.
 W. Kohn and L. J. Sham, Physical Review 140, A1133
 R. Car and M. Parrinello, Physical Review Letters 55,
2471 .
 D. Marx and J. Hutter, Ab initio molecular dynamics:
basic theory and advanced methods .
 L. Bonati and M. Parrinello, Physical Review Letters 121,
265701 .
 M. Gastegger, J. Behler, and P. Marquetand, Chemical
Science 8, 6924 .
 A. Grisaﬁ, D. M. Wilkins, G. Csányi, and M. Ceriotti,
Physical Review Letters 120, 036002 .
 A. Grisaﬁ, A. Fabrizio, B. Meyer, D. M. Wilkins,
C. Corminboeuf, and M. Ceriotti, ACS Central Science
5, 57 .
 D. M. Wilkins, A. Grisaﬁ, Y. Yang, K. U. Lao, R. A.
DiStasio, and M. Ceriotti, Proceedings of the National
Academy of Sciences , 201816132 .
 A. Chandrasekaran, D. Kamal, R. Batra, C. Kim, L. Chen,
and R. Ramprasad, NPJ Computational Materials 5, 22
 L. Zepeda-Núñez, Y. Chen, J. Zhang, W. Jia, L. Zhang,
and L. Lin, arXiv preprint arXiv:1912.00775 .
 N. Raimbault, A. Grisaﬁ, M. Ceriotti, and M. Rossi, New
Journal of Physics 21, 105001 .
 V. Kapil, D. M. Wilkins, J. Lan, and M. Ceriotti, arXiv
 
 M. Sharma, R. Resta,
and R. Car, Physical Review
Letters 95, 187401 .
 A. Putrino, D. Sebastiani, and M. Parrinello, The Journal
of Chemical Physics 113, 7102 .
 Q. Wan, L. Spanu, G. A. Galli, and F. Gygi, Journal of
Chemical Theory and Computation 9, 4124 .
 Q. Wan and G. Galli, Physical Review Letters 115, 246404
 V. Rozsa, D. Pan, F. Giberti, and G. Galli, Proceedings
of the National Academy of Sciences 115, 6952 .
 J. Sun, B. K. Clark, S. Torquato, and R. Car, Nature
communications 6, 8156 .
 B. C. Wood and N. Marzari, Physical review letters 97,
166401 .
 E. Schwegler, M. Sharma, F. Gygi, and G. Galli, Proceedings of the National Academy of Sciences 105, 14779
 V. Srinivasan, R. Gebauer, R. Resta, and R. Car, in AIP
Conference Proceedings, Vol. 677 pp. 168–175.
 A. Fluri, A. Marcolongo, V. Roddatis, A. Wokaun, D. Pergolesi, N. Marzari, and T. Lippert, Advanced Science 4,
1700467 .
 H. Liu, Y. Wang, and J. M. Bowman, The Journal of
chemical physics 142, 194502 .
 N. Marzari and D. Vanderbilt, Physical Review B 56,
12847 .
 N. Marzari, A. A. Mostoﬁ, J. R. Yates, I. Souza,
D. Vanderbilt, Reviews of Modern Physics 84, 1419
 R. Resta, Reviews of Modern Physics 66, 899 .
 W. Kohn, Physical Review Letters 76, 3168 .
 E. Prodan and W. Kohn, Proceedings of the National
Academy of Sciences 102, 11635 .
 J.-A. Hernandez and R. Caracas, The Journal of Chemical
Physics 148, 214501 .
 J. D. Bernal and R. H. Fowler, The Journal of Chemical
Physics 1, 515 .
 L. Pauling, Journal of the American Chemical Society 57,
2680 .
 M. Millot, F. Coppari, J. R. Rygg, A. C. Barrios, S. Hamel,
D. C. Swift, and J. H. Eggert, Nature 569, 251 .
 M. Chen, L. Zheng, B. Santra, H.-Y. Ko, R. A. DiStasio Jr,
M. L. Klein, R. Car, and X. Wu, Nature chemistry 10,
413 .
 D. Kingma and J. Ba, in Proceedings of the International
Conference on Learning Representations (ICLR) .
 G. M. Sommers, M. F. Calegari Andrade, L. Zhang,
and R. Car, Phys. Chem. Chem. Phys. 22,
10592 .
 L. Zhang, D.-Y. Lin, H. Wang, R. Car, and W. E, Physical
Review Materials 3, 023804 .
 E. V. Podryabinkin and A. V. Shapeev, Computational
Materials Science 140, 171 .
 L. Zhang, H. Wang, and W. E, The Journal of Chemical
Physics 148, 124113 .
 H.-Y. Ko, L. Zhang, B. Santra, H. Wang, W. E, R. A.
DiStasio Jr, and R. Car, Molecular Physics , 1 .
 H. Wang, L. Zhang, J. Han, and W. E, Computer Physics
Communications 228, 178 .
 Y. Zhang, H. Wang, W. Chen, J. Zeng, L. Zhang, H. Wang,
and W. E, Computer Physics Communications , 107206
 J. E. Bertie and Z. Lan, Applied Spectroscopy 50, 1047
 J. E. Bertie, M. K. Ahmed, and H. H. Eysel, The Journal
of Physical Chemistry 93, 2210 .
 C. Adamo and V. Barone, The Journal of Chemical
Physics 110, 6158 .
 A. Tkatchenko and M. Scheﬄer, Physical Review Letters
102, 073005 .
 V. Babin, C. Leforestier,
and F. Paesani, Journal of
Chemical Theory and Computation 9, 5395 .
 A. Shank, Y. Wang, A. Kaledin, B. J. Braams, and J. M.
Bowman, The Journal of Chemical Physics 130, 144314
 S. Nosé, The Journal of Chemical Physics 81, 511 .
 W. G. Hoover, Physical review A 31, 1695 .
 M. Bernasconi, P. Silvestrelli, and M. Parrinello, Physical
Review Letters 81, 1235 .
 A. Goncharov, V. Struzhkin, M. Somayazulu, R. Hemley,
and H. Mao, Science 273, 218 .
 O. Marsalek and T. E. Markland, The Journal of Physical
Chemistry Letters 8, 1545 .
 G. R. Medders and F. Paesani, Journal of Chemical Theory and Computation 11, 1145 .
 S. Mukamel, Principles of nonlinear optical spectroscopy,
Vol. 41 pp. 591–592.
 Y. Nagata and S. Mukamel, Journal of the American
Chemical Society 132, 6434 .
 R. Resta and D. Vanderbilt, in Physics of Ferroelectrics
 pp. 31–68.
 D. Vanderbilt and W. Zhong, Ferroelectrics 206, 181
 M. Zaheer, S. Kottur, S. Ravanbakhsh, B. Poczos, R. R.
Salakhutdinov, and A. J. Smola, in Advances in Neural
Information Processing Systems 30, edited by I. Guyon,
U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett 
pp. 3391–3401.
 P. W. Battaglia, J. B. Hamrick, V. Bapst, A. Sanchez-
Gonzalez, V. Zambaldi, M. Malinowski, A. Tacchetti,
D. Raposo, A. Santoro, R. Faulkner, et al., arXiv preprint
 
 C. Esteves, C. Allen-Blanchette, A. Makadia,
K. Daniilidis, in Proceedings of the European Conference
on Computer Vision (ECCV) pp. 52–68.
 J. Han, Y. Li, L. Lin, J. Lu, J. Zhang, and L. Zhang,
arXiv preprint arXiv:1912.01765 .
 Generalizations to more than one reference atom would be
feasible to deal with situations in which the WC are shared
among covalently bonded atoms of same electronegativity.