IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 7, NO. 6, DECEMBER 1999
Optimization Flow Control—I: Basic Algorithm
and Convergence
Steven H. Low, Senior Member, IEEE, and David E. Lapsley
Abstract—We propose an optimization approach to ﬂow control
where the objective is to maximize the aggregate source utility
over their transmission rates. We view network links and sources
as processors of a distributed computation system to solve the
dual problem using a gradient projection algorithm. In this
system, sources select transmission rates that maximize their
own beneﬁts, utility minus bandwidth cost, and network links
adjust bandwidth prices to coordinate the sources’ decisions.
We allow feedback delays to be different, substantial, and time
varying, and links and sources to update at different times and
with different frequencies. We provide asynchronous distributed
algorithms and prove their convergence in a static environment.
We present measurements obtained from a preliminary prototype
to illustrate the convergence of the algorithm in a slowly timevarying environment. We discuss its fairness property.
Index Terms— Asynchronous algorithm, congestion pricing,
convergence, gradient projection, optimization ﬂow control.
I. INTRODUCTION
T SEEMS better to serve elastic trafﬁcs with variable
bandwidth using, in the context of ATM for instance,
available bit rate (ABR) rather than constant bit rate (CBR)
service. Indeed, this folklore can be formally proved in the
following abstract model: suppose a network offers ﬁxed and
variable bandwidth to a set of elastic sources and prices them
according to excess demand, and the sources freely purchase
them to maximize their own beneﬁts. The interpretation is that
a source that desires only ﬁxed bandwidth in the model would
subscribe to CBR in practice, and a source that desires both
ﬁxed and variable bandwidth would subscribe to ABR with
a minimum cell-rate guarantee. We show in , that
at equilibrium, where all sources are at their optimality and
demand equals supply, every source desires a strictly positive
amount of variable bandwidth. This observation provides perhaps another motivation for end-to-end ﬂow control because
reactive ﬂow control, where sources adjust their transmission
Manuscript
TRANSACTIONS ON NETWORKING Editor S. Keshav. This work was supported
by Melbourne IT, Melbourne, Victoria 3052, Australia. The work of S. H.
Low was supported by the Australian Research Council under Grant S499705
and Grant A49930405. The work of D. I. E. Lapsley was supported by the
Australian Commonwealth Government and ATERB under scholarships.
Department
Electrical
Electronic
Engineering, University of Melbourne, Parkville, Vic. 3052, Australia (email: ).
D. E. Lapsley was with the Department of Electrical and Electronic
Engineering, University of Melbourne, Parkville, Vic. 3052, Australia.
He is now with Ericsson, Melbourne, Vic. 3052, Australia (e-mail:
 ).
Publisher Item Identiﬁer S 1063-6692(99)09711-3.
rates in response to changes in network conditions, is a
practical way to provision variable bandwidth.
The purpose of this paper is to propose an optimization
approach to ﬂow control, where the control mechanism is
derived as a means to optimize a global measure of network
performance. We will present synchronous and asynchronous
algorithms, and prove their convergence in a static network
environment. We will then describe a prototype and present
experimental measurements to illustrate the algorithm’s convergence in a slowly time-varying environment.
A. Summary
Consider a network that consists of a set
of unidirectional
links of capacities
The network is shared by a
of sources, where source
is characterized by a utility
that is concave increasing in its transmission
The goal is to calculate source rates that maximize the
sum of the utilities
subject to capacity
constraints. Solving this problem centrally would require not
only the knowledge of all utility functions, but worse still,
complex coordination among potentially all sources due to
coupling of sources through shared links. Instead, we propose
a decentralized scheme that eliminates this requirement and
adapts naturally to changing network conditions. The key
is to consider the dual problem whose structure suggests
treating the network links and the sources as processors of
a distributed computation system to solve the dual problem
using gradient projection method. Each processor executes a
local algorithm, communicates its computation result to others,
and the cycle repeats.
The algorithm takes the familiar form of reactive ﬂow
control. Based on the local aggregate source rate each link
calculates a “price”
for a unit of bandwidth at link
is fed back the scalar price
where the sum
is taken over all links that
uses, and it chooses a transmission
that maximizes its own beneﬁt
minus the bandwidth cost. These individually optimal rates
may not be socially optimal for a general price
i.e., they may not maximize the aggregate
utility. The algorithm iteratively approaches a price vector
that aligns individual and social optimality such
indeed maximizes the aggregate utility.
The algorithm is partially asynchronous [5, Ch. 6] in
which the sources and links may compute based on outdated
information, they may communicate at different times and with
different frequencies, and the communication delays may be
substantial, different and time-varying. We prove that as long
1063–6692/99$10.00 1999 IEEE
IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 7, NO. 6, DECEMBER 1999
as the intervals between updates are bounded, the algorithm
converges to yield the optimal rate.
In equilibrium, sources that share the same links do not
necessarily equally share the available bandwidth. Rather, their
shares reﬂect how they value the resources as expressed by
their utility functions and how their use of the resources
implies a cost on others. This could be a basis to provide
differentiated services in terms of different rate allocations.
The basic algorithm is derived and its convergence proved in
a static environment, where link capacities and the set of active
sources remain unchanged. The algorithm generalizes directly
to the case of time-varying environment. We present measurements from our prototype that illustrate the convergence of the
algorithm when network condition changes.
The paper is structured as follows. In Section II, we present
the optimization problem and its dual that motivate our approach. In Section III, we derive a synchronous algorithm
and describe its convergence. This algorithm and its convergence proof are extended to an asynchronous setting in
Section IV. In Section V, we remark on fairness and pricing.
In Section VI, we present experimental results on convergence
obtained from our prototype. Proofs of convergence are in the
two Appendices.
B. Extensions
We now comment on past works and extensions. The
basic algorithm has been presented in and a preliminary
prototype is brieﬂy discussed in . In this paper, we analyze
its convergence and fairness properties through analysis and
implementation. The basic algorithm requires communication
of link prices to sources and source rates to links, and hence,
cannot be implemented on the Internet. This communication
requirement is greatly simpliﬁed in , , as follows. In
 , we describe a way for links to estimate source rates using
local information and prove that optimality is still maintained.
This eliminates the need for explicit communication from
sources to links. In the reverse direction, we proposed a
method in that accomplishes the communication from
links to sources using only binary feedback. This can be implemented using the proposed explicit congestion notiﬁcation
(ECN) bit in the IP header , . These two simpliﬁcations
are combined into a ﬂow-control scheme we call random early
marking (REM), a variant of random early detection (RED)
 , that not only stabilizes network queues, but also tracks
a global optimum. REM is made more robust in the face of
large feedback delays by having links take weighted averages
of past prices . REM and its enhancements will be detailed
in Part II of this paper.
The value of the optimization model presented in this
paper is twofold. First, although it may not be possible, or
critical, that optimality is exactly attained in a real network,
the optimization framework offers a means to explicitly steer
the entire network toward a desirable operating point. We will
see below that ﬂow control can be regarded as a distributed
computation over the network, and hence the behavior of
the network as a whole is easily understandable. Second,
it is useful to treat practical ﬂow-control schemes simply
as implementations of a certain optimization algorithm. The
optimization model then makes possible a systematic method
to design and reﬁne these schemes where modiﬁcations to a
ﬂow-control mechanism are guided by modiﬁcations to the
optimization algorithm. For instance, it is well known that the
Newton algorithm has much faster convergence than gradient
projection algorithm. By replacing the gradient projection
algorithm presented in this paper by the Newton algorithm,
we derive in a practical Newton-like ﬂow-control scheme
that can be proved to maintain optimality and has the same
communication requirement as the basic scheme here but
enjoys a much better convergence property. We have also
applied pole-placement technique in linear control to the model
here to stabilize its transient in the face of large feedback
delays. This has led to a more robust REM, presented in .
C. Related Works
An extensive literature exists on ﬂow control, including the
original TCP ﬂow control and recent enhancement in
 , the binary feedback schemes of, e.g., , , two-bit
feedback scheme of , the control theoretic approach of,
e.g., , , , etc. Also, see a recent review in .
A key premise of optimization based ﬂow control ,
 – , , , – , is that sources with
different valuation of bandwidth should react differently to
network congestion. All these works motivate ﬂow control by
an optimization problem and derive their control mechanisms
as solutions to the optimization problem. They differ in their
choice of objective functions or their solution approaches,
and result in rather different ﬂow-control mechanisms to
be implemented at the sources and the network links. Our
model is closest to that in , . Indeed, both their work
and ours have the same objective of maximizing aggregate
source utility. In , , this objective is decomposed into
optimization subproblems for the network and the sources, and
they propose a different mechanism for its solution where each
source chooses a willingness to pay and the network allocates
rates to these sources in a way that is proportionally fair. An
interesting feature of their approach is that it allows the users to
decide their payments and receive what the network allocates,
whereas in our approach, the users decide their rates and pay
what the network charges. See a more detailed comparison in
Remark 3 after Algorithm A1 in Section III.
II. OPTIMIZATION PROBLEM
In this section, we state the optimization problem that leads
to our congestion control framework, and suggest a solution
approach. Algorithms to solve the problem will be given in
the following sections.
A. Primal Problem
Consider a network that consists of a set
of unidirectional links of capacity
The network
is shared by a set
of sources. Source
characterized by four parameters
is a set of links that source
a utility function,
are the minimum and
LOW AND LAPSLEY: OPTIMIZATION FLOW CONTROL—I
maximum transmission rates, respectively, required by source
attains a utility
when it transmits at rate
that satisﬁes
is increasing and
strictly concave in its argument. Let
denote the
range in which source rate
must lie and
be the vector. For each link
be the set of sources that use link
Our objective is to choose source rates
subject to
The constraint (2) says that the aggregate source rate at any
link does not exceed the capacity. A unique maximizer, called
the primal optimal solution, exists since the objective function
is strictly concave, and hence continuous, and the feasible
solution set is compact.
Though the objective function is separable in
the source
are coupled by the constraint (2). Solving the primal
problem (1)–(2) directly requires coordination among possibly
all sources and is impractical in real networks. The key to a
distributed and decentralized solution is to look at its dual.
Dual Problem
Deﬁne the Lagrangian
Notice that the ﬁrst term are separable in
The objective function of the dual problem is
thus (e.g., [5, Sec. 3.4.2], )
and the dual problem is
The ﬁrst term of the dual-objective function
is decomposed into
separable subproblems (3)–(4). If we interpret
as the price per unit bandwidth at link
total price per unit bandwidth for all links in the path of
represents the bandwidth cost to source
it transmits at rate
represents the maximum
can achieve at the given price
We shall see below
that this scalar
summarizes all the congestion information
needs to know. A source
can be induced to
solve maximization (3) by bandwidth charging. For each
a unique maximizer, denoted by
exists since
strictly concave.
In general,
may not be primal optimal, but
by duality theory, there exists a dual optimal price
is indeed primal optimal. Hence, we
will focus on solving the dual problem (5). Once we have
the primal optimal source rates
can be computed by individual sources
by solving (3), a
simple maximization (see (6) below). The important point
to note is that, given
individual sources
can solve (3)
separately without the need to coordinate with other sources.
In a sense,
serves as a coordination signal that aligns
individual optimality of (3) with social optimality of (1).
C. Notations and Assumptions
Unless otherwise speciﬁed,
usually denotes a vector whose
th component is some
deﬁned before
is introduced. For
a vector or matrix
denotes its transpose. For a set
denotes its cardinality. For a vector
denotes the
Euclidean norm,
without subscript denotes any norm. For a matrix
denotes the corresponding induced norm.
It will sometimes be convenient to represent the information
in terms of a routing matrix
), and 0 otherwise.
For each source
th component of
is the (path) bandwidth price that
faces. For each link
the th component of
is the aggregate
source rate at link
be the unique maximizer in (3). We will abuse
notation and use
both as a function of scalar price
and of vector price
is a scalar,
by the Kuhn-Tucker theorem,
is given by
is the inverse of
which exists over the range
is continuous and
strictly concave (condition C1 below).
is the demand function in microeconomics. It is
illustrated in Fig. 1. When
is a vector,
The meaning should be clear from the context.
Assumptions on the utility functions are:
C1: on the interval
the utility functions
are increasing, strictly concave, and twice continuously
differentiable. For feasibility, assume
C2: the curvatures of
are bounded away from zero on
IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 7, NO. 6, DECEMBER 1999
Source rate xs(p) (y axis) as a function of (scalar) price p (x axis).
III. SYNCHRONOUS DISTRIBUTED ALGORITHM
In this section, we present the basic synchronous algorithm
and prove its convergence under conditions C1 and C2. This
algorithm and its convergence proof form the basis of the
asynchronous algorithm and the proof of its convergence, to
be described in the next section.
We will solve the dual problem using the gradient projection
method (e.g., , ) where link prices are adjusted in
opposite direction to the gradient
as follows:
is a stepsize, and
Recall that
denotes the unique maximizer in (3). Then
are strictly concave,
is continuously differentiable (see [5, p. 669]) with derivatives given by
is the aggregate source rate at
Substituting (8) into (7) we obtain the following price
adjustment rule for link
This is indeed consistent with the law of supply and demand: if
the demand
for bandwidth at link
exceeds the supply
raise price
otherwise, reduce
As with (3), the decentralized nature of (9) is
striking: though the dual problem is not separable in
aggregate source rate
that goes through link
adjustment algorithm (9) is completely distributed and can be
implemented by individual links using only local information.
This suggests treating the network links
and the sources
as processors in a distributed computation system to solve
the dual problem (5). In each iteration, sources
individually
solve (3) and communicate their results
on its path. Links
then update their prices
according to (9)
and communicate the new prices to sources
and the cycle
repeats. We summarize.
Algorithm A1: Synchronous Gradient Projection—
Link ’s Algorithm: At times
1) receives rates
from all sources
through link
2) computes a new price
3) communicates new price
to all sources
that use link
Source ’s Algorithm: At times
1) receives from the network the sum
of link prices in its path;
2) chooses a new transmission rate
for the next
is given by (6);
3) communicates new rate
1) As noted in Section I-B, a link
requires the aggregate
source rates
and a source
the path price
for their updates. This communication can be greatly
simpliﬁed, leading to the REM algorithm discussed in
 , .
2) Newton’s method, where the direction of price adjustment is the negative gradient scaled by the inverse of
the Hessian
typically has a much faster convergence than the gradient projection algorithm. However,
according to Lemma 3 below, this requires that a link
know the (second derivative of the) utility functions of
nonlocal sources, and hence is not practical. In , we
describe and prove the optimality of a practical Newtonlike algorithm that enjoys a better performance.
3) Our work is closely connected to Kelly’s as described
in , , . Both solve the same optimization
problem (1)–(2), but differ in the solution approach
which leads to different ﬂow-control algorithms, which
in turn lead to different marking implementation of the
algorithms.
decomposes
problems (1)–(2) into a user subproblem and a network
subproblem. The user subproblem is to choose a
willingness-to-pay
given the path price
in order to
maximize its beneﬁt, and the network subproblem is to
choose source rates
given users’ willingnessto-pay vector
in order to maximize
It is shown in that there exist path
source rates
willingness-to-pay
solves user
’s subproblem, and
solves the
1Here, we abuse notation and use xs() both as a function of time, to
denote source rate at time t under Algorithm A1, and as a function of price
given by (6). The meaning should be clear from the context.
LOW AND LAPSLEY: OPTIMIZATION FLOW CONTROL—I
network subproblem and the system (primal) problem
(1)–(2). Our approach is simply to solve the dual of
problem (1)–(2) using gradient projection algorithm.
A major effort in is to solve the network
subproblem, or equivalently, the dual of the network
subproblem [not to be confused with our dual problem
in (5)].2 To this end, they propose the following
primal algorithm:
to solve a relaxation of the network subproblem, and
the following dual algorithm to solve a relaxation of its
dual (given
The rate adjustment (10) has the attractive feature of
multiplicative decrease and additive increase common in
several popular ﬂow-control schemes. Either algorithm
(10)–(11) or (12)–(13) can be used to compute the
equilibrium source rates.
Our gradient projection algorithm is closer to Kelly’s
dual algorithm (12)–(13). Indeed, in the special case
our algorithm A1 reduces
to (12)–(13), provided we take
though this choice of
does not satisfy certain
conditions required for the stability proof in .
In , the nonnegativity constraint on the source
rates and link prices is relaxed in (10)–(13). This allows
a simple and elegant stability proof via a Lyapunov
argument. In our case, the projection to the positive
quadrant complicates the stability analysis considerably
(see the Appendices). In a sense, the dual-objective
can be thought of as a Lyapunov function
for the discrete time system (9), provided the stepsize
is sufﬁciently small.
In , a marking scheme is proposed to implement
the primal algorithm (10)–(11), where the marks convey
to a source the charge
and the source adjusts
its rate to equalize the charge with its willingnessto-pay
In Part II of this paper, we describe a
marking scheme that implements our algorithm where
the marks allow a source to estimate its path price
that is needed in its rate adjustment. In view of the
remark above, this can also be regarded as a marking
2Of course, if Us(xs) = ws log xs; then our primal problem (1)–(2) and
its dual (5) are equivalent to their network subproblem and its dual.
implementation of Kelly’s dual algorithm (12)–(13) for
a speciﬁc utility function.
Our ﬁrst main result states that Algorithm A1 generates a
sequence that approaches the optimal rate allocation, provided
conditions C1 and C2 are satisﬁed. These conditions imply
is Lipschitz which guarantees the convergence of
gradient projection algorithms. Deﬁne
is the length of a longest path used by the sources,
number of sources sharing a most congested link, and
upper bound on all
(see Section II-C).
Theorem 1: Suppose assumptions C1 and C2 hold, and
the stepsize satisﬁes
Then starting from any
initial rates
and prices
every accumulation point
of the sequence
by Algorithm A1 are primal-dual optimal.
Proof: See Appendix I.
Though there is a unique maximizer
to the primal
problem, there may be multiple dual optimal prices because at
optimality only the sum of link prices is constrained,
Theorem 1 does not guarantee convergence to
a unique pair
though any convergent subsequence
yields the optimal rate allocation
We now comment on the convergence rate when the dual
optimal price
is unique. Then letting
the deviation from the unique limit point, it can be shown that
the price process
linearized around
diagonal matrix
with diagonal elements
deﬁned by (24) in Appendix I.
Hence, the rate of convergence near the equilibrium is determined by the spectral radius of the positive semideﬁnite
IV. ASYNCHRONOUS DISTRIBUTED ALGORITHM
The synchronous model of the last section assumes that
updates at the sources and the links are synchronized to
occur at times
In this section, we will extend
the model to an asynchronous setting which better resembles
the reality of large networks. In such networks sources may
be located at different distances from the network links.
Network state (prices in our case) may be probed by different
sources at different rates, e.g., the resource management (RM)
cells in an ATM networks are sent at different rates by
different sources. Feedbacks may reach different sources after
different, and variable, delays. These complications make
our distributed computation system consisting of links and
sources asynchronous. In such a system, some processors may
compute faster and execute more iterations than others, some
processors may communicate more frequently than others,
and the communication delays may be substantial and timevarying.
We now present the asynchronous version of Algorithm A1
and prove its convergence. Our asynchronous model and the
convergence proof follow the approach of and belong to
IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 7, NO. 6, DECEMBER 1999
the class of partially asynchronous algorithms discussed in [5,
Ch. 7] (see comments after Theorem 2 below).
be a set of times at which link
adjusts its price based on its current knowledge of source
rates. At times
link prices are unchanged, i.e.,
Similarly, let
be a set of times at which source
updates its rate. At times
computes an estimate
gradient and updates its price according to
The estimate
is computed using aggregate past source
rates at link
In (15)–(16),
is the aggregate estimated
source rates. The estimate
of individual source rate is the
weighted average of its past rates [see (17)–(18)]. It depends
and can be different for different link-source pairs
and at different times
It includes the possibility of
information arriving at link
out of order. This model is very
general and allows in particular the following two popular
types of policies.
1) Latest data only: only the last received rate
some (possibly unknown)
to estimate
otherwise.
2) Latest average: only the average over the latest
received rates is used in estimate
and 0 otherwise, for some
(possibly unknown)
The interpretation in both cases is that rates
have not been received at link
have been discarded.
computes an estimate
path price and updates its rate according to
is given by (6), and
In (19)–(20), the source computation is the same as in the
synchronous case, except that it is based on its current estimate
of path prices. As in the link algorithm, the estimated link
is obtained by “averaging” over the past available
prices [see (21)–(22)], and can depend on
“averaging” model is very general and include the policy of
using only the last received price or the average over the last
prices; see above.
Note that (17) and (21) above tacitly assume that the oneway delay between any
pair is no more than
We now present the asynchronous algorithm A2. A2 is
similar to A1, except that communications are not coordinated
and computations are carried out using possibly outdated
information.
Algorithm A2: Asynchronous Gradient Projection—
Link ’s Algorithm:
1) From time to time, link
receives source rates from
sources that go through link
replaces the oldest
rates in its local memory with the newly received rates.
2) At each update time
computes an estimate
(see (15)–(18) above) and adjusts
its price according to
3) From time to time link
communicates the current price
to sources that go through link
’s Algorithm:
1) From time to time, source
receives bandwidth prices
fed back from links in its path. Source
replaces the
oldest prices in its local memory with the newly received
2) At each update time
chooses a new
rate based on its current estimate
of path price
(see (20)–(22) above)
It then transmits at this rate until the next update, i.e.,
3) From time to time, source
communicates the current
source rate to links in its path.
This concludes our description of Algorithm A2. We now
turn to its convergence.
be the ideal rate if source
knows the exact price
instead of its estimate
is given by (6) and
evolves according
to Algorithm A2. Our second main result states that the
difference between the various estimates and their true values
converges to zero and that Algorithm A2 yields the optimal
LOW AND LAPSLEY: OPTIMIZATION FLOW CONTROL—I
rate allocation, provided the following additional assumption
is satisﬁed:
C3: For all links
and sources
the time between consecutive updates (i.e., the difference between consecutive elements
is bounded.
Theorem 2: Suppose assumptions C1–C3 hold. Provided
that the stepsize
is sufﬁciently small, then starting from any
initial rates
and prices
every accumulation point
of the sequence
by Algorithm A2 are primal-dual optimal. Moreover, for all
the error in price estimation
rate calculation
converges to zero, and the
in gradient estimation by the links
converges to zero.
Proof: See Appendix II.
As in , the key to the proof is to show that the price
adjustment (14) remains in the descent direction and hence,
the value of the dual-objective function is decreased in each
iteration. The proof in our case is somewhat more complicated
because, since our minimization is a dual problem, the gradient
depends on previous prices
more complex way through (15)–(33). Moreover, a critical
assumption that is natural in the routing context there ([33,
eq. 3.11], which is needed to derive their equations (A.6)
and (A.9)) has no equivalent in our context, and hence, other
properties of our algorithm need to be exploited in order
to prove that descent direction is maintained [see Lemma
4c)–4e)] and Lemma 5 in Appendix II).
V. FAIRNESS, QUASI-STATIONARITY, AND PRICING
In this section, we comment on some fairness and implementation issues.
A. Fairness
A proportionally fair rate vector is deﬁned in as a
feasible rate vector
such that for any other feasible
the aggregate of proportional changes is
nonpositive
The primal optimal solution
is proportionally fair
when all user utilities are logarithmic,
As shown in , this follows from the optimality condition:
for all feasible
where the strict inequality follows from the strict concavity
If user utilities are all equal but not necessarily logarithmic,
then the following properties on homogeneous sources follow
Theorem 3: Suppose condition C1 holds and, for all
the primal optimal rate vector.
a) If sources
share the same path,
b) If the path of
is a subset of
c) More generally, suppose
is a dual-optimal price vector.
and equality holds if and
We now comment on these properties. If
the same path but one has a higher marginal utility, say
Hence, the choice of
utility function implements priority among connections with
the same path.
Theorem 3b) implies that our scheme discriminates against
long connections. We emphasize, however, that by “long” we
mean connections that go through more links, not necessarily
those merely having higher propagation delays in accessing the
network. This is natural from the perspective of maximizing
the total utility; since all utility functions are identical, the
longer a connection, the more resources it consumes for
each unit of increase in aggregate utility, and hence, short
connections should be favored. If this is undesirable, it can
be remedied by weighting the utility functions. Indeed, almost
any desirable rate vector can be attained in equilibrium by
appropriate choice of utility functions (see Theorem 4 below).
Theorem 3c) justiﬁes treating the bandwidth price
as a measure of congestion that
faces: the higher
the congestion the lower the rate.
A rate vector
is called feasible if it satisﬁes the capacity
constraint (2). It is called attainable if there exist utility
that satisfy condition C1 for which the unique
primal optimal rate vector is
is called saturated
with respect to
C4: every link
has a single-link connection, i.e., for each
there exists a source
We can restrict utility functions to be of the form
and choose the parameters
appropriately to achieve almost any desirable allocation in a
static network.
Theorem 4: Suppose C1 and C4 hold, and suppose utility functions are
a feasible rate vector
is attainable provided all links are
saturated and, for all
Proof: A feasible rate vector
is primal optimal if and
only if the Kuhn–Tucker condition
IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 7, NO. 6, DECEMBER 1999
and the complementary slackness are satisﬁed. Since all links
are saturated by assumption, the complementary slackness
holds. By C4, we can express
Substituting
this into the Kuhn–Tucker condition, using the appropriate
utility functions, yields the theorem.
Theorem 4 implies, in particular, that a max–min fair or
proportionally fair rate can be attained by appropriate choice
of utility functions.
B. Time-Varying Environment
Algorithms A1 and A2 are derived, and their convergence
proved, assuming that the link capacities
sources and their utility functions
are unchanged. However
the algorithms extend directly to the case when these quantities
are time varying. They have the important virtue of not
requiring to be restarted when network condition changes.
Each source that comes on board executes the same source
algorithm [(A1) or (A2)] with the time invariant utility function
replaced by the current utility
link executes the same link algorithm, except that in computing
in Step 2, the current link capacity
is used in place of the constant capacity
and the set
of currently active sources through link
is used in place of
the constant set
If the change in link capacities and sources is slow relative
to the convergence of the algorithm, the algorithm tracks the
moving optimal rates. This is illustrated by the experimental
measurements presented in Section VI below.
C. Pricing and Trafﬁc Control
Though network feedbacks are discussed in terms of bandwidth “prices,” they may or may not be part of the charge a
user pays. If they are, then bandwidth charging provides an
incentive for the sources to choose socially (primal) optimal
rates. In addition to encouraging efﬁcient sharing of resources,
pricing for network services also serves other functions. If
congestion pricing interferes too much with these functions,
then the “prices” discussed in this paper should be regarded
as simply a control signal to guide sources’ decisions.
VI. EXPERIMENTAL RESULTS
In this section, we brieﬂy summarize a user-space implementation of the basic algorithm and present experimental
measurements that illustrate its convergence in a slowly timevarying environment. A detailed description of the prototype
can be found in .
A. Overview of Implementation
Our experimental network consists of two IBM-compatible
PC’s (Pentium 233 MHz) running the FreeBSD-2.2.5 operating system. Each PC was equipped with 64 MB of RAM
and 100-MB/s PCI ethernet cards. The PC’s were connected
via ethernet. Implementing the protocol involved writing two
applications: ofc client application, and ofcd routing demon.
We refer to our algorithm as OFC.
Logical topology. Source Si transmits to destinations Di; i = 1; 2; 3:
Two instances of the ofc client application are required
for each connection: a source instance operating in ACTIVE
mode and a destination instance operating in PASSIVE mode.
Whenever the OFC transport protocol is used, the ofcd demon
must be run on all computers that have OFC clients (sources
or destinations) and on intermediate computers. The ofc client
processes communicate with each other via the ofcd routing
demons. All OFC clients transmit their packets to the routing
demon on their host, which then either forward the packet
to another machine, or deliver it to a client process on the
host. The OFC demons are also responsible for calculating the
price on their outgoing links and placing this price in special
control packets as they pass through.
Each computer has a standard internet protocol stack consisting of TCP/UDP running on IP, which sits above the
network device drivers. The OFC protocol runs on top of the
UDP layer, with OFC packets transported across the network
on UDP connections. OFC packets are 500-B long and consist
of a 10-B header, 1-B end of packet marker, and a 489-B data
payload. The header contains, among other things, ﬁelds that
indicate payload type, bandwidth price, and source rate.
An in-kernel implementation of the protocol would have
a better performance, but this would require recompiling the
kernel of every machine on which we want to implement OFC.
A user-space implementation is much more portable: we only
need to recompile the application software and execute it on
the target machine. We opted for portability over performance.
We have tried a number of different architectures and designs,
and have found that the design with the best performance was
a single context, monolithic implementation (see ) where
all of the packet processing was performed within a single
thread (see for more details).
B. Convergence
We now present two sets of experimental results and compare them with theoretical prediction. As expected, the bottlenecks of our testbed, which are links in our theoretical
model, are not the transmission medium (ethernet) but the host
processing. This set of bottlenecks can be represented by the
logical network in Fig. 2.
Experiment 1—Homogeneous Sources: Each source transmitted data for a total of 120 s, with their starting times
staggered by intervals of 40 s: source 1 started transmitting
LOW AND LAPSLEY: OPTIMIZATION FLOW CONTROL—I
Experiment 1—homogeneous sources. Heavy lines are theoretical rates and prices and light lines are measured ones. The sum of user rates is
approximately 200 cells per 500-ms measurement interval. (a) Theoretical rate is the optimal rate xs for each source (all have identical utility). (b) Theoretical
price is the path price of the longest connection that was on and should roughly equal the sum of the measured link prices.
at time 0, source 2 at time 40 s, and source 3 at time 80 s. The
utility functions of the sources were set to
equal to 1
for all sources
used by the router to adjust its link prices was set
Client applications as well as routers dumped
receive/transmit statistics to ﬁle every 500 ms. The routers also
calculated new prices every 500 ms. The target bandwidth was
set at 200 packets per 500 ms measuring interval (1.6 MB/s).
Fig. 3(a) shows the destination receive rates for each source.
The sum of the traces is constant at about 200 packets per
measuring interval, which was the target value set at the
routers. The destination receive rates varied in accordance with
the changes in link prices in Fig. 3(b). From 80 to 120 s, when
all sources were active, each destination was receiving data at
the same rate, and that the longer connections S1-D1 and S2-
D2 were not discriminated against. This was because link 1
was not saturated and hence had zero price.
Also shown in both graphs is the steady-state rate and
price calculated by solving the primal and dual problems in
Section II. Note that in Fig. 3(b), the measured prices are link
prices and the theoretical price is the path price which should
equal the sum of the link prices. We see that the prototype
behaved as expected and that, provided network conditions
vary slowly, our algorithm tracks the optimum.
Experiment 2—Heterogeneous Sources: The setup in this
experiment is the same as in Experiment 1, except that the
utility function of source 3 has
double that of
sources 1 and 2.
Fig. 4(a) and (b) show, respectively, the destination receive
rates and the link prices. As in Experiment 1, the source
rates adjusted dynamically as new sources started or stopped
transmitting. Again, note the close ﬁt between the theoretical
and the measured traces. Due to its higher marginal utility,
source 2 gained twice as much bandwidth as each of sources 1
and 3, and caused the price on link 2 to be pushed higher than
in Experiment 1. It suggests that our algorithm can support
differentiated service in terms of different shares of resource
allocation.
VII. CONCLUSION
We have described an optimization approach to reactive
ﬂow control, and derived a simple asynchronous distributed
algorithm. We allow the sources and network links to communicate and update their controls asynchronously at different
times, with different frequencies, and after substantial and
random delays. The algorithm is provably convergent to the
global optimal when network conditions are static and seems
IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 7, NO. 6, DECEMBER 1999
Experiment 2—heterogeneous sources. Heavy lines are theoretical rates and prices and light lines are measured ones. (a) Theoretical rate is for
source 1 from time = 0 to 120, and for source 2 for t = 120 to 160, and source 3 for t  160: (b) Theoretical price is the path price of the longest
connection that was on and should roughly equal the sum of the measured link prices.
to track the optimum when network conditions vary slowly.
The scheme has desirable fairness properties and is extensible
to a multicasting environment.
The algorithm presented in this paper requires communication between sources and links. As noted in Section I
a practical implementation using only binary feedback from
links to sources is the REM scheme described in and Part
II of this paper. The abstract model here serves as a convenient
framework to systematically reﬁne REM, as illustrated in
APPENDIX I
PROOF OF THEOREM 1
We will often use vector notation when it is more convenient. We start with the basic properties of the dual objective
function that follow directly from C1.
Lemma 1: Under assumption C1, the dual objective function
is convex, lower bounded, and continuously differentiable.
For any price vector
is deﬁned in (4) and
is the unique maximizer
of (3). Let
diagonal matrix with diagonal elements
Note that from
assumption C2 in Section II-C for all
Recall the routing matrix
deﬁned in Section II-C.
Lemma 2: Under condition C1, the Hessian of
where it exists.
Proof: Let
denote the
Jacobian matrix
element is
When it exists
Using (24), we have
Now from (8), we have
which together with (26) yields the result.
LOW AND LAPSLEY: OPTIMIZATION FLOW CONTROL—I
deﬁned in Section III before Theorem 1.
Lemma 3: Under conditions C1 and C2,
is Lipschitz
Proof: Given any
using Taylor theorem and
Lemma 2, we have
now show that
which yields the desired
Now (e.g., see [5, p. 635])
is upper bounded by the product of the
maximum row sum and the maximum column sum of the
is symmetric,
is the number of links in the path of source
By deﬁnition
as desired.
These lemmas establish our ﬁrst main result.
Proof of Theorem 1: The dual objective function
lower bounded and
is Lipschitz from Lemmas 1 and 3.
Then, any accumulation point
of the sequence
generated by the gradient projection algorithm for the dual
problem is dual optimal (see [5, p. 214]).
be a subsequence converging to
At least one exists since it is easy to show that the level
is compact and that
the sequence
is decreasing in
and hence, in
the level set, provided
To show that the
subsequence
converges to the
primal optimal source rate
deﬁned on a compact set
Moreover it is continuous
and one-to-one (because of the strict concavity of
hence, its inverse is continuous on
Theorem 4.17]. From (6),
is continuous. Therefore,
3Where r2D(w) may not exist, at points where ws = U0
s(Ms) for some s; derivatives should be replaced by convex
subgradients in the proof. Then, Lemma 3 and Theorem 1 hold. For simplicity,
we will ignore these issues in this paper.
APPENDIX II
PROOF OF THEOREM 2
be the vector of prices
For any vector
denote its
th component. Given any
We assume that conditions C1–C3 hold.
We start with a collection of useful facts. Recall the bound
deﬁned in assumption C2 of Section II-C, and
the gradient estimate
deﬁned in (15)–(18).
a) For all
b) There exists a constant
such that, for all
c) For any
where it exists.
d) For all
e) For all
applying the projection theorem ([4, Proposition 2.1.3]) to the scalar
This inequality
holds trivially for
and hence, for all
Summing over
yields the desired result.
b) By Lemma 2,
is symmetric and positive
semideﬁnite, and hence [4, Appendix A]
eigenvalue of the matrix
We claim that
is bounded for all
because from Lemma 2
Here, the ﬁrst inequality follows from the fact that the
trace of a matrix is the sum of all its eigenvalues and
that eigenvalues of a positive semideﬁnite matrix are all
nonnegative. The second inequality follows from (25)
and the deﬁnition of
IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 7, NO. 6, DECEMBER 1999
c) The claim follows from chain rule and (25).
is deﬁned in (27),
is deﬁned by
is deﬁned by
otherwise.
Hence, by the mean value theorem and applying part (c)
of the lemma, we have, for some
e) We have by the mean value theorem and (25)
The next lemma bounds the error in gradient estimation in
terms of the successive price change
Lemma 5: There exists a constant
Proof: From (8), (15)–(17), and (23), we have
Hence, for some constant
where the last inequality follows from (19) and (23) and from
the fact that projection is nonexpansive [4, Proposition 2.1.3].
Applying Lemma 4(d) and (e), we have
where the third inequality follows from
The proof is complete since norms in ﬁnitedimensional vector space are all equivalent.
The next lemma shows that
converges to zero.
Lemma 6: Provided
is sufﬁciently small we have for
are the constants in
Lemmas 4 and 5, respectively. Hence,
Proof: Applying Lemma 4(a) and (b) to the second-order
Taylor expansion of
we have for some
LOW AND LAPSLEY: OPTIMIZATION FLOW CONTROL—I
Applying Lemma 5, we have
where the last inequality holds because the convex function
attains a unique minimum over
at the origin. Summing (29) over
as desired.
Since the above inequality holds for all
we can choose
sufﬁciently small such that
Then, since
is lower bounded (Lemma 1), letting
we must have
These lemmas establish Theorem 2.
Proof of Theorem 2: We ﬁrst prove that the various errors
due to asynchronism all converge to zero. For all sources
we have from (20)–(21)
which by (31) converges to zero as
From (19), (23)
are projections of
Since projection is nonexpansive [4, Proposition 2.1.3], we
where the last inequality follows from Lemma 4(d). Hence, by
in gradient estimation converges to zero by Lemma 5 and (31).
We now show that every accumulation point of the sequence
generated by Algorithm A2 minimizes the dual problem. Let
be an accumulation point of
At least one
exists since the level set
compact and that the sequence
is in the level set
is sufﬁciently small [see (30)]. Moreover, since the
interval between consecutive updates is bounded (condition
is also an accumulation point of
be a sequence such that
converges to
is continuous (Lemma 1) and
(Lemma 5), we have
where the last equality follows from (31). Then the projection
theorem [4, Proposition 2.1.3]) implies
which, due to the concavity of
implies that
By duality
is the unique primal optimal rate.
We now show that it is a limit point of
generated by
Algorithm A2. Consider the subsequence
is in the compact set
there exists a sequence
converges. Since
where the second equality follows from (23). This completes
the proof.
ACKNOWLEDGMENT
The authors are grateful to F. Kelly, D. Mitra, J. Tsitsiklis,
and A. Weiss for very helpful discussions. The ﬁrst author
would also like to thank B. Doshi and Y. T. Wang of Bell
Laboratories, Lucent Technologies, for their hospitality during
a visit in 1997 where part of this work was done.