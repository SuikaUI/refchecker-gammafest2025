LOQO: AN INTERIOR POINT CODE FOR QUADRATIC PROGRAMMING
ROBERT J. VANDERBEI
Statistics and Operations Research
Princeton University
Revised: October 6, 1998
ABSTRACT. This paper describes a software package, called LOQO, which implements a primaldual interior-point method for general nonlinear programming. We focus in this paper mainly on
the algorithm as it applies to linear and quadratic programming with only brief mention of the
extensions to convex and general nonlinear programming, since a detailed paper describing these
extensions were published recently elsewhere. In particular, we emphasize the importance of establishing and maintaining symmetric quasideﬁniteness of the reduced KKT system. We show that the
industry standard MPS format can be nicely formulated in such a way to provide quasideﬁniteness.
Computational results are included for a variety of linear and quadratic programming problems.
1. INTRODUCTION
LOQO is a software package for solving general (smooth) nonlinear optimization problems. It
implements an infeasible-primal-dual path-following method. For linear programming, such methods
were ﬁrst proposed independently by Lustig and Tanabe . The method as applied to LP was
subsequently studied empirically by Lustig et.al. . Global convergence was proved by Kojima
et.al while Zhang established polynomiality of a long-step infeasible path-following method.
Finally, superlinearly convergent variants were given by Potra and Wright [?]. Detailed discussion
of the computational aspects for infeasible-interior-point methods for linear programming were given
by Lustig et.al. and by Andersen et.al. . Comprehensive modern treatments of interior-point
methods for linear programming can be found in and .
The ﬁrst extension of primal-dual path-following methods to convex optimization was given by
Monteiro and Adler with superlinear convergence being established somewhat later by Monteiro
Research supported by AFOSR through grant AFOSR-91-0359, the NSF through grant CCR-9403789, and the
ONR through grant N00014-98-1-0036.
ROBERT J. VANDERBEI
and Zhang . Preliminary computational studies were done by Breitfeld and Shanno and Shanno
and Simantiraki .
The software package LOQO has undergone many developmental phases since the ﬁrst version was
released in 1991. From the start, we recognized that quasideﬁnite matrices (introduced and studied in
 ) are important for obtaining efﬁcient algorithms for convex quadratic programming. The original
incarnation of LOQO (version 1.xx) is described in . In these early versions, quasideﬁniteness
was not present in the reduced KKT system itself but rather was introduced during the process of
matrix factorization by an appropriate choice of initial pivots. In 1994, we discovered techniques
guaranteeing quasideﬁniteness in the reduced KKT system itself. This greatly freed up the choice
of pivot elements in the factorization process. The technical report documenting these changes
was never published. This paper is derived directly from that technical report. In preparing this
paper, we updated the text to reﬂect developments taking place since 1994 and we completely redid
all computational experiments using the most current version of LOQO (3.10).
The most signiﬁcant development between 1994 and the present is that LOQO can now solve general
nonlinear optimization problems (having smoothly deﬁned objective and constraints). The changes to
the algorithm that makes this possible are described in detail in . In this paper, we describe them
only brieﬂy.
Before proceeding with a detailed treatment, we present in the following subsection on overview of
the main feature that distinguishes LOQO for other LP and QP solvers, namely, having a quasideﬁnite
reduced KKT matrix regardless of problem formulation.
1.1. Quasideﬁnite Reduced KKT Systems. Most software packages for solving linear programming problems using interior point technology take as input a linear program in the industry standard
MPS format. This is a ﬂexible format that allows variables to be free or bounded (on one side or both
sides) and allows constraints to be either inequalities or equalities with the inequalities even allowed
to be two-sided. Yet, these packages invariably map the given problem to a standard form in which all
constraints are equalities and all variables are either free, nonnegative, or bounded between zero and a
ﬁnite upper bound. The algorithm then involves solving a system of equations involving the following
reduced KKT matrix:
Here, A is the constraint matrix and D is a diagonal matrix having nonnegative values. The diagonal
elements of D are positive ﬁnite numbers with the following exceptions:
• Free variables produce zero diagonal elements.
• Variables having zero upper bound (i.e. ﬁxed variables in the original MPS ﬁle) produce inﬁnitely large diagonal elements.
Hence, free variables and ﬁxed variables pose a serious challenge to the usual approach.
It is easy to remedy the situation regarding ﬁxed variables. The inﬁnite diagonal element is a
consequence of initializing the primal variable x j and its slack t j to the upper bound u j so that the
LOQO: AN INTERIOR POINT CODE FOR QUADRATIC PROGRAMMING
slack’s deﬁnitional constraint is satisﬁed:
x j + t j = u j.
When u j = 0, this constraint forces both x j and t j to vanish, which is how an inﬁnity ends up appearing in the corresponding location on D. However, Lustig (and independently Tanabe )
showed that interior-point methods could and should be viewed as infeasible methods and that the
obvious algorithm will work toward feasibility at the same time that it works toward optimality. Once,
infeasible interior-point methods became popular with the appearance of Lustig, et.al.’s, computationally oriented paper , it became natural to relax the above constraint and initialize x j and t j to a
positive value even when the upper bound is zero. This remedy for the ﬁxed variable problem was
discovered independently by Lustig et.al. and by Vanderbei . Of course, as the algorithm
progresses, the ﬁxed variables x j and the corresponding t j will get small and this will force the corresponding diagonal element of D to grow very large. But it is well-known that even without ﬁxed
variables, every element of D approaches either inﬁnity or zero. Hence, this remedy for ﬁxed variables
makes them behave no worse than any other variables.
However, free variables have remained a problem and remedies suggested to date (such as splitting
each one into the difference between its positive and negative parts) have been less than satisfactory.
In this paper, we will give a new way to handle free variables that is analogous to the treatment of ﬁxed
variables described above. In particular, this new treatment produces positive entries on D. Hence,
combining the ﬁxed variable remedy with this new free variable remedy we arrive at an algorithm in
which D has all strictly positive (and ﬁnite) entries.
Of course, the zero matrix in the lower right-hand block of the reduced KKT matrix is also undesirable. Because of this zero matrix, most existing implementations ﬁrst choose their pivots from the
upper left block and thereby reduce the system to the so-called normal equations which involves a
matrix of the following form:
Many papers have discussed the pros and cons of working with the normal equations. The obvious
advantage is that the matrix is positive semideﬁnite. But a disadvantage appears when A has dense
columns. In this case, the positive semideﬁnite matrix is dense even if A is mostly very sparse. A related disadvantage appears when one wishes to generalize the algorithm from solving linear programs
to one that can solve quadratic programming problems.
The zero on the lower right-hand block appears because of the conversion of every problem to
equality form. If one had derived the algorithm to act on problems in inequality form (even allowing
two sided inequalities), then this lower right-hand block becomes a diagonal matrix with all strictly
negative elements. But then one must address how to handle equality constraints, if in fact the original
problem has them (as they almost always do). The obvious approach is to represent each equality
ROBERT J. VANDERBEI
constraint as a two sided inequality with the two sides agreeing:
b ≤aT x ≤b.
If one does this and relaxes the appropriate slack deﬁnitional constraints, one obtains a method for
treating equality constraints that produces strictly negative entries in the lower right-hand block. Note
that this technique is quite analogous to the technique we described above for handling ﬁxed variables.
Employing the techniques described above, the reduced KKT matrix becomes a symmetric quasideﬁnite matrix:
Here, D and E are positive deﬁnite diagonal matrices. We showed in that one can factor any
symmetric permutation of a symmetric quasi-deﬁnite matrix. Hence, using this approach it is quite
natural to solve the reduced KKT system directly instead of reducing it to the system of normal
equations.
1.2. Outline. In this paper, we describe in detail the algorithm as outlined above. We also describe
a software package, called LOQO, which implements this method. In Section 2, we describe one
iteration of the symmetrically formulated primal-dual path-following method. Section 3, describes
the starting point selection and termination criteria as implemented in LOQO. Then, in Section 4,
some more speciﬁc implementation details are presented that further deﬁne the algorithm. Section 5
discusses the extension of the algorithm to handle pure inequalities (i.e. inﬁnite ranges) and inﬁnite
upper and/or lower bounds on the variables. Finally, computational results can be found in Section 6.
2. ALGORITHM
The algorithm implemented in LOQO is a infeasible-primal-dual path-following method. As implemented, it operates directly on QP problems presented in the following general form, which for LP’s
corresponds directly to the industry standard MPS format:
f + cT x + 1
subject to
b ≤Ax ≤b + r
Here, A is the m × n matrix of coefﬁcients, b is called the right-hand side (even though it appears
on the left), r is the vector of ranges on the constraints, and u and l are the vectors of upper bounds
and lower bounds, respectively, on the variables. Each element bi of b is assumed to be a ﬁnite real
LOQO: AN INTERIOR POINT CODE FOR QUADRATIC PROGRAMMING
number. However, the elements of the other vectors are permitted to take values in the extended reals
subject to the following limitations:
−∞≤l j < ∞
−∞< u j ≤∞.
Inﬁnities require special treatment. They shall be discussed in Section 5.
The objective function, f + cT x + 1
2x T Hx, is a quadratic function. For historical reasons, the
constant term f is called the ﬁxed adjustment. The matrix H appearing in the quadratic term is
assumed to be positive semideﬁnite so that the objective function is convex.
Derivations of the infeasible-primal-dual path-following method for problems presented in simpler
forms can be found, for example, in . Hence, we proceed directly to the derivation
in the present general context.
2.1. Add Slacks. The ﬁrst step in the derivation is to introduce slack variables as appropriate to
replace all inequality constraints with simple nonnegativity constraints. Hence, we rewrite the primal
problem (2.1) as follows:
f + cT x + 1
subject to
g, w, t, p
The dual of (2.2) is:
f + bT y −1
2x T Hx + lT z −uTs −rT q
subject to
AT y + z −s −Hx
z, v, s, q
ROBERT J. VANDERBEI
2.2. Central Path. The next step in the derivation is to introduce the primal-dual central path (introduced by Megiddo —see also ). We parametrize this path by a positive real parameter
µ. Indeed, for each µ > 0, we deﬁne the associated central-path point in primal-dual space as the
unique point that simultaneously satisﬁes the conditions of primal feasibility, dual feasibility, and
µ-complementarity. Ignoring nonnegativity (which is enforced separately), these conditions are:
AT y + z −s −Hx
The last four equations are the µ-complementarity conditions. As usual, each upper case letter that
appears on the left in these equations denotes the diagonal matrix having the components of the corresponding lower-case vector on its diagonal. This is a nonlinear system of 5n+5m equations in 5n+5m
unknowns. It has a unique solution in the strict interior of the appropriate orthant in primal-dual space:
{(x, g, w, t, p, y, z, v, s, q) : g, w, t, p, z, v, s, q ≥0}.
This fact can be seen by noting that these equations are the ﬁrst order optimality conditions for an
associated strictly convex barrier problem (see, e.g. ).
As µ tends to zero, the central path converges to an optimal solution to both the primal and dual
problems. A primal-dual path-following algorithm is deﬁned as any iterative process that starts from
a point in the strict interior of (2.5) and at each iteration estimates a value of µ representing a point
on the central path that is in some sense closer to the optimal solution than the current point and then
attempts to step toward this central-path point making sure that the new point remains in the strict
interior of the appropriate orthant.
Suppose for the moment that we have already decided on the target value for µ. Let (x, . . . , q)
denote the current point in the orthant and let (x + 1x, . . . , q + 1q) denote the point on the central
path corresponding to the target value of µ. The deﬁning equations for the point on the central path
LOQO: AN INTERIOR POINT CODE FOR QUADRATIC PROGRAMMING
can be written as
AT 1y + 1z −1s −H1x
c −AT y −z + s + Hx
−1y −1q + 1v
G−1Z1g + 1z
µG−1e −z −G−11G1z
V −1W1v + 1w
µV −1e −w −V −11V 1w
ST −11t + 1s
µT −1e −s −T −11T1s
P−1Q1p + 1q
µP−1e −q −P−11P1q
where we have introduced notations ρ, . . . , γq as shorthands for the right-hand side expressions. This
is almost a linear system for the direction vectors (1x, . . . , 1q). The only nonlinearities appear on
the right-hand sides of the complementarity equations (i.e., in γz, . . . , γq).
2.3. Predictor-Corrector. LOQO implements a predictor-corrector approach to ﬁnding a good
approximate solution to equations (2.6). The predictor step consists of dropping both the µ terms and
the “delta” terms that appear on the right-hand side (i.e., γz = −z, etc.) and solving the resulting
linear system for the “delta” variables. Then an estimate of an appropriate target value for µ is made
and the µ and “delta” terms are reinstated on the right-hand side using the current estimates and the
resulting system is again solved for the “delta” variables. This second calculation is refered to as the
corrector step and the resulting step directions are used to move to a new point in primal-dual space.
2.4. Solving the Indeﬁnite System. Clearly the main computational burden is to solve system (2.6)
twice in each iteration. It is important to note that this is a large, sparse, indeﬁnite, linear system. It is,
however, symmetric if one negates certain rows and rearranges rows and columns appropriately:






As we shall see shortly, the symmetry of this system suggests a systematic process of elimination.
In other works (such as ) the analogous system is not written in a symmetric form and the
elimination process, in the early stages, is often performed in ad hoc ways until ultimately arriving
ROBERT J. VANDERBEI
at a symmetric positive semideﬁnite system (involving a matrix with the symbolic structure of either
AAT or AT A and just one of the delta variables – either 1y or 1x). These other works then assert
that this new system can be solved robustly and hence that the reduction yields a more numerically
stable procedure. However, this argument ignores the fact that, once the reduced system has been
solved, its solution must then be used to “back substitute” to get all of the other delta variables that
were eliminated and that these extra calculations represent predetermined pivots in the original system
that might reintroduce the numerical instability that one had hoped to avoid. Hence, in the end, we
are still faced with solving a large, indeﬁnite, linear system and it is this system that we should study
carefully. By employing a systematic elimination process from the beginning, one hopes to obtain a
more robust procedure for the original large system.
The most numerically robust technique for solving large, perhaps nonsymmetric, systems is to employ a full-pivoting solver. Unfortunately, such an approach yields a code that is signiﬁcantly slower
than ones based on a predetermined reduction. Also, experience shows that these predetermined
reductions (which amount to pivoting without regard for the size of the pivot element) can yield remarkably robust codes (this phenomenon is only partially understood – see, e.g., ). Hence, to be
competitive, LOQO uses a predetermined reduction, which we now describe.
Now we describe the systematic elimination process. First, we use the pivot elements −ST −1,
−G−1Z, −P−1Q, and V −1W to solve for 1t, 1g, 1p, and 1v, respectively,
S−1T(γs −1s)
GZ−1(γz −1z)
PQ−1(γq −1q)
V W −1(γw −1w),
which we then eliminate from the remaining equations to obtain
β −V W −1γw
−α + PQ−1γq
ν + GZ−1γz
−τ + S−1Tγs
where once again we have introduced abbreviated notations for some of the right-hand side expressions. Next, we use the pivot elements PQ−1, GZ−1, and S−1T to solve for 1q, 1z, and 1s,
respectively,
P−1Q(1w −ˆα)
G−1Z(ˆν −1x)
ST −1(1x −ˆτ).
LOQO: AN INTERIOR POINT CODE FOR QUADRATIC PROGRAMMING
Eliminating these variables from the remaining equations, we get
ˆβ −P−1Q ˆα
σ −G−1Z ˆν −ST −1 ˆτ
E =  V W −1 + P−1Q−1
D = G−1Z + ST −1
are positive-deﬁnite diagonal matrices. Finally, we use the pivot element −E−1 to solve for 1w,
1w = −E( ˆβ −P−1Q ˆα + 1y),
which brings us to the so-called reduced KKT equations:
 −(H + D)
 σ −G−1Z ˆν −ST −1 ˆτ
ρ −E( ˆβ −P−1Q ˆα)
2.5. Solving the Symmetric Quasideﬁnite System. Up to this point, none of the eliminations have
produced off-diagonal ﬁll-in in the remaining system. However, proceeding further will deﬁnitely
introduce such ﬁll-in. For example, if we were to use the ﬁrst equation in (2.8) to solve for 1x and
then eliminate it from the second equation, the resulting system for 1y would involve the matrix
A(D + H)−1 AT
(this is the normal-equations approach used in OB1 , CPLEX-barrier, and other codes). Similarly, if we were to solve the second equation for 1y and then eliminate this variable from the ﬁrst
equation, the resulting system for 1x would involve the matrix
(this is the approach advocated by the optimization group at the National Institute of Standards and
Technology ). Both of these will generally entail ﬁll-in, which in some cases can be considerable. For example, if the Hessian H is not a diagonal matrix or if the matrix A has a dense column,
the ﬁrst form can suffer “catastrophic ﬁll-in” (see for analysis of non-diagonal H). On the other
hand, if A has a dense row, the second form will be very bad. If A has both dense columns and dense
rows, then both of these forms will suffer unnecessarily large amounts of ﬁll-in and one would prefer,
in that case, to work with the larger system to ﬁnd a pivot order that does not generate so much ﬁll-in.
This idea was ﬁrst suggested by Turner and has been adopted by Saunders et.al. and
Mehrotra . All three use a Bunch-Parlet factorization of the indeﬁnite system. Solving the larger
system is also the approach adopted in LOQO, but LOQO does not employ a Bunch-Parlet factorization.
Instead, LOQO uses a modiﬁed Cholesky factorization code that has been altered to solve symmetric
quasideﬁnite systems (see ). Equation (2.8) is an example of such a system. The matrices deﬁning
these systems share with symmetric semideﬁnite matrices the nice property that the (diagonal) pivots
ROBERT J. VANDERBEI
can be selected based only on a ﬁll-in minimizing heuristic; i.e., without regard for the numerical
values, which may only be known later.
There are two types of ﬁll-in minimizing heuristics: myopic heuristics, such as minimum-degree ,
which sequentially minimize the ﬁll-in produced in each subsequent stage of elimination and global
heuristics, such as nested-dissection , which analyze the overall structure to ﬁnd good orderings.
In the symmetric quasideﬁnite system (2.8), there is an obvious global structure that one can exploit.
For example, the lower-right block is a diagonal matrix (as is the upper-left block whenever H is
diagonal or absent). Hence, initial pivots selected from the lower-right block can only produce ﬁll-in in
the upper-left block. It is potentially advantageous to exploit this structure. To test this hypothesis, we
compared two ordering schemes. The ﬁrst is just a straight minimum-degree heuristic implemented as
described in . The second can be described as a priority minimum-degree method. Each diagonal
element is assigned a small integer representing an elimination priority. At ﬁrst, pivots are selected
only from the elements assigned priority zero. Within this priority class, pivots are selected according
to the usual minimum degree heuristic. Only after all priority zero pivots have been eliminated do
we proceed to the priority one elements. Again, within this priority class, the elimination order is
determined using the minimum-degree heuristic. This process is continued through each priority class
until all elements are eliminated.
The priority classes are determined as follows. First a simple estimate is made of the number of
nonzeros in AAT and of the number of nonzeros in AT A. If these estimates indicate that AAT will
have less ﬁll-in than AT A, then the pivot elements from the upper-left block are assigned priority zero
and the lower-right block elements are given priority one. Otherwise, the reverse priority is assigned.
Next, the priority zero pivots are scanned to see if any of them have high degree (relative to the other
elements). Such elements are then reassigned to priority one so that these elements (which correspond
to dense columns/rows of A) are eliminated last.
Let K denote the symmetric quasideﬁnite matrix in (2.8). The ordering heuristic computes a permutation matrix P which is applied to both the rows and the columns of K and the resulting matrix
is factored into the product of a unit lower triangular matrix L times a diagonal matrix D times the
transpose of the lower triangular matrix:
PK PT = LDLT.
While we often refer to ﬁll-in produced by some ordering heuristic, a better gauge of the quality of the
ordering is to count the number of arithmetic operations, narth, required to compute the factorization.
There is a simple formula for this:
nonz(L j)2 + 3 nonz(L) + k.
Here, k denotes the number of rows/columns of K, nonz(·) denotes the number of nonzeros and L j
denotes the j-th column of L.
Table 1 shows the results of our comparison. It is clear that there can be a substantial difference
between the two methods. However, on the average they are about the same. To justify this claim, let
Ri denote the ratio of the number of arithmetic operations using the ordinary minimum-degree method
LOQO: AN INTERIOR POINT CODE FOR QUADRATIC PROGRAMMING
to the number obtained using the priority method for the i-th problem. Since a ratio of 2 and a ratio of
1/2 should be counted equally, we use the geometric mean to summarize the overall average behavior:
¯R = exp( 1
For the data in Table 1, ¯R = 0.964, which indicates that the ordinary minimum-degree heuristic was
on the average 3.6% better. But, at the 95% conﬁdence level, we must reject the hypothesis that the
ordinary minimum-degree heuristic is better since the standard deviation of the logarithm of the Ri’s
divided by the square root of one less than the sample size is 0.037 indicating that the 3.6% deviation
is only about one standard deviation away from the mean. Hence, we have no evidence to say that
one method produces a better ordering than the other. However, there is a signiﬁcant difference from
the point of view of numerical stability. The priority-minimum-degree method tends to arrange the
computations so that all additions (to positive diagonal elements) are taken ﬁrst and the subtractions
come last. This enhances the numerical stability greatly. Indeed, using the priority method, LOQO
solves essentially all of the NETLIB problems listed in Table 1 (except dfl001) whereas the ordinary
minimum-degree heuristic has trouble on 31 out of the 92 problems. For this reason, LOQO uses the
priority method.
3. OPENINGS AND ENDGAMES.
To start the algorithm we need to provide initial values for all the variables. Variables x and y are
unrestricted whereas all the others must be positive. A simple heuristic would be to set the unrestricted
variables to zero and the positive variables to one. However, it is better to try to arrange things to more
closely satisfy at least some of the equations. LOQO initializes the variables as follows. First, x and y
are found as solutions to the following system:
 −(H + I)
Then the other variables are set as follows:
max(abs(x −l), 100)
max(abs(x), 100)
max(abs(u −x), 100)
max(abs(x), 100)
max(abs(y), 100)
max(abs(y), 100)
max(abs(r −w), 100)
max(abs(y), 100),
where max() and abs() denote componentwise maximum and absolute value, respectively.
ROBERT J. VANDERBEI
Arithmetic Operations
Arithmetic Operations
1528765265
1407015715
TABLE 1. Number of arithmetic operations required to factor the symmetric indeﬁnite
system using (a) the minimum-degree heuristic and (b) the priority minimum-degree
heuristic.
LOQO: AN INTERIOR POINT CODE FOR QUADRATIC PROGRAMMING
The default stopping rule in LOQO is to stop when the primal and dual are both feasible and their
objective functions agree to eight signiﬁcant ﬁgures. The level of primal infeasibility is measured by
primal infeasibility =
∥ρ∥2 + ∥τ∥2 + ∥α∥2 + ∥ν∥2
Similarly, dual infeasibility is measured using
dual infeasibility =
∥σ∥2 + ∥β∥2
By default, a solution is primal/dual feasible if these measures are less than 10−6. The signiﬁcant
ﬁgures of agreement between the primal objective function value and the dual is computed as follows:
sigﬁg = max
|primal obj −dual obj|
|primal obj| + 1
In addition to identifying optimal solutions, it is also important to identify infeasible and unbounded
problems. This identiﬁcation is based on the observation (see, e.g., ) that the primal infeasibility
and the dual infeasibility decrease monotonically. If the primal problem is infeasible, then the primal
infeasibility will stall (and in fact start to increase) before getting close to zero. If the primal problem
is unbounded, then the dual infeasibility’s reduction will stall. LOQO tests for stalling and, if detected,
terminates with an appropriate message.
4. MIDGAME STRATEGIES.
Two midgame strategies need to be mentioned. The ﬁrst is the computation of step lengths. At
the end of each iteration, the current solution is updated to a new solution according to the following
The normalizations αp and αd should be one (since the step directions were derived based on this assumption), but they may need to be shortened to maintain strict positivity of the nonnegative variables.
ROBERT J. VANDERBEI
Hence they are calculated as follows:
Here, the inner maximizations are over all j = 1, 2, . . . , n or all i = 1, 2, . . . , m as appropriate for
each of the four terms in the argument list. If the problem is a pure linear programming problem, then
the step lengths are as given. If it is a quadratic program, then a common normalization is used:
max(αp, αd)
max(αp, αd).
The second midgame strategy is the computation of the parameter µ. To understand the heuristic
used to come up with a value for µ, ﬁrst consider a point on the central path. From (2.4), we see that
zT g = µn,
vT w = µm,
pT q = µm.
Hence, one way to recover µ from a given point on the central path is to compute
µ = zT g + vT w + sTt + pT q
We use this expression to assign a par value for µ even when the current point is not on the central path.
Since we wish to step from the current point toward a point on the central path that is “closer” to the
optimal solution it is desirable to use a value of µ that is some fraction of the par value. Simply setting
this fraction to one tenth works most of the time, but it turns out to be better to assign it dynamically
based on how much one must shorten the predictor step direction to preserve strict positivity of the
nonnegative variables. Hence, LOQO calculates values for αp and αd as described above using the
predictor directions and then multiplies the par value of µ by the following fraction:
αpd = max(αp, αd).
This fraction tends to be close to zero when αpd is close to 1 but gets close to one as αpd becomes
5. HANDLING INFINITIES.
In this section, we discuss the absense of bounds on variables and ranges on constraints.
Our basic problem formulation (2.1) shows variables having two-sided bounds (above and below).
But real-world problems contain a mix of bound types: some variables may have two-sided bounds,
while others have only one-sided bounds (either upper or lower) and yet others have no bounds whatsoever (so-called free variables). Missing bounds are easy to handle. We simply omit the slack
variable associated with the missing bound. For example, if x j is a variable having no upper bound,
LOQO: AN INTERIOR POINT CODE FOR QUADRATIC PROGRAMMING
then the primal problem (2.2) will have no upper-bound slack variable t j and the associated dual (2.3)
will be missing the corresponding variable s j. Similarly, if a lower bound is missing, then a g j and
z j are dropped. This causes no difﬁculties except for the fact that each free variable will produce a
zero on the diagonal matrix D given by (2.7). Hence, free variables must be handled separately in
the factorization of the symmetric quasideﬁnite matrix appearing in (2.8). In LOQO versions 2.16 and
earlier, free variables are treated exactly this way. The diagonal entries of the symmetric quasideﬁnite
matrix associated with these free variables are assigned to priority class two thereby ensuring that they
are eliminated last (by which time the diagonals should be nonzero). In LOQO versions 2.17 and later,
free variables are handled in a different manner – one in which the none of the diagonals are ever zero.
This produces a more robust code. The details are discussed below.
If the i-th constraint has inﬁnite range, i.e. a pure inequality constraint, then we leave out the slack
variable pi associated with this constraint and also the corresponding dual variable qi.
5.1. A New Technique for Free Variables. Let us consider a modiﬁcation of our original problem
(2.1) in which all variables are free:
f + cT x + 1
subject to
b ≤Ax ≤b + r.
Instead of thinking of a free variable as a variable without an upper or lower bound, we should think
of it as a variable having an inﬁnite upper and lower bound. More precisely, let us initially assume
that there is a very large upper bound, R, and a very small lower bound, −R. Then, (2.2) becomes:
f + cT x + 1
subject to
g, w, t, p
If we let R go to inﬁnity in (5.2), we end up with a problem that has variables that must be inﬁnite.
But, let’s take a closer look at the constraints involving R. By adding and subtracting, we see that the
are equivalent to
The ﬁrst set of equations is important but the second set just forces g and/or t to go to inﬁnity. If we
keep the ﬁrst set (dropping the factor of 2 multiplying x) and drop the second set we get the following
ROBERT J. VANDERBEI
primal problem:
f + cT x + 1
subject to
g, w, t, p
which is clearly equivalent to (5.1). The dual of (5.3) is:
f + bT y −1
2x T Hx −rT q
subject to
AT y + z −Hx
z, v, s, q
(Note the high degree of symmetry between this primal/dual pair.) The equations deﬁning the central
path for this pair of problems closely parallels those we had before in (2.4):
AT y + z −Hx
LOQO: AN INTERIOR POINT CODE FOR QUADRATIC PROGRAMMING
Continuing with the usual algorithm derivation process, the equations for the step directions now
1x −1g + 1t
AT 1y + 1z −H1x
c −AT y −z + Hx
−1y −1q + 1v
G−1Z1g + 1z
µG−1e −z −G−11G1z
V −1W1v + 1w
µV −1e −w −V −11V 1w
ST −11t + 1s
µT −1e −s −T −11T1s
P−1Q1p + 1q
µP−1e −q −P−11P1q
By appropriately arranging the variables and equations, this system can be written in a symmetric






Using the pivot elements −G−1Z, −P−1Q, S−1T, and V −1W to solve for 1g, 1p, 1s, and 1v,
respectively, we get
GZ−1(γz −1z)
PQ−1(γq −1q)
γs −ST −11t
V W −1(γw −1w),
which we then eliminate from the remaining equations to obtain
τ −γs =: ˆτ
β −V W −1γw =: ˆβ
−α + PQ−1γq =: −ˆα
ν + GZ−1γz =: ˆν
ROBERT J. VANDERBEI
Next, we use the pivot elements PQ−1 and GZ−1 to solve for 1q and 1z, respectively, we get
P−1Q(1w −ˆα)
G−1Z(ˆν −1x −1t).
Eliminating these variables from the remaining equations, we get
−(ST −1 + G−1Z)
−(V W −1 + P−1Q)
−(H + G−1Z) AT
ˆτ −G−1Z ˆν
ˆβ −P−1Q ˆα
σ −G−1Z ˆν
Finally, we use the pivot elements −(ST −1 + G−1Z) and −(V W −1 + P−1Q) to solve for 1t and
−DS−1T  GZ−1 ˆτ −ˆν + 1x
ˆβ −P−1Q ˆα + 1y
E =  V W −1 + P−1Q−1
 S−1T + GZ−1−1 .
Eliminating 1t and 1w from (5.7), we arrive at last at the reduced KKT system:
 −(H + D)
 σ −D(ˆν + S−1T ˆτ)
ρ −E( ˆβ −P−1Q ˆα)
Note that, since D and E are both positive deﬁnite, this reduced KKT system is quasideﬁnite.
6. COMPUTATIONAL RESULTS.
In this section, we attempt to characterize the performance of LOQO. Our experiments were performed on a Silicon Graphics Indigo R4600 workstation having a 133 MHz clock, 160 MBytes of real
memory, and running the IRIX 5.3 operating system.
We tested version 3.10 of LOQO which is written in ANSI C and was compiled using the -O
optimization ﬂag. Version 3.10 is the ﬁrst version of LOQO that incorporates special techniques for
general nonlinear programming. Namely, it uses a merit function to help choose an appropriate step
length and it uses diagonal perturbation of the Hessian to guarantee a descent direction when problems
are nonconvex. Associated with these new features are new parameters and new defaults for some old
parameters. It turns out that some of these parameters need to be set differently if the problem is linear
or convex quadratic as opposed to if it is a general nonlinear problem. An attempt was made to detect
if a problem is linear and to set the defaults correctly in that case. It is a little harder to detect that a
problem is convex quadratic and so in this version of LOQO these problems get the same default values
as general nonlinear optimization problems. Consequently, when a problem is known to be convex
LOQO: AN INTERIOR POINT CODE FOR QUADRATIC PROGRAMMING
quadratic, some parameters need to be changed from their defaults. The speciﬁc parameters and
their values are given below. Future releases of LOQO will automatically set the affected parameters
correctly.
6.1. Linear Programming Problems. For linear programming problems, most parameters get the
correct default values automatically but we forgot to disable diagonal perturbation for these problems. When the solution gets nearly optimal numerical issues often arise that makes the problem look
slightly nonconvex and LOQO then tries diagonal perturbation. This behaviour needs to be disabled.
It is done so by including the assertive parameter convex in the list of parameters. In a UNIX csh
environment, this can be accomplished at the shell prompt by writing
setenv loqo options "convex"
Our ﬁrst set of test problems is taken from the standard NETLIB test suite of linear programming
problems. There are currently two collections of NETLIB problems. One contains problems that have
optimal solutions and the other contains problems that are infeasible. Tables 2 and 3 show results for
the collection having optimal solutions. All the problems except for dfl001 and forplan were
solved to an acceptable level of infeasibility and with eight ﬁgures of agreement between the primal
and dual solution.
Dfl001 is a badly scaled problem: the coefﬁcients in the objective function range from about 0.1
to about 1.0e+8. The preprocessing phase of LOQO does not attempt to scale the problem, hence
there is no correction for this gross scale discrepancy. As a result, LOQO has numerical trouble with
dfl001 from the start. However, simply dividing the objective function by 1.0e+6 corrects this
defect and LOQO is then able to solve the problem in 44 iterations. It took 5201.02 seconds to get this
On iteration 30, forplan had 8 digits of agreement between primal and dual objective functions,
relative primal infeasibility of 1.89e-11, and dual infeasibility of 9.17e-04 before numerical
troubles set in which on the 36th iteration led LOQO to conclude that the problem is dual infeasible. It
should be emphasized that infeasibilities are measured in a relative sense and sometimes the relativizer
might itself be of an inappropriate magnitude. This might have been the case for both forplan since
the initial relative infeasibility was greater that 1.00e+03, which is rather large.
Table 4 shows the number of iterations needed to detect infeasibility for the collection of infeasible
problems. There are two ways in which infeasibility and unboundedness are detected. The ﬁrst, as
mentioned earlier, is if the primal or dual infeasibility increases from one iteration to the next. The
other is if some iteration produces a step direction that points in an unbounded direction away from
a feasible solution for either the primal or the dual. For several problems, infeasibility was detected
in preprocessing. Two problems, cplex2 and gosh ran 200 iterations and stopped at the iteration
limit. Problem cplex2 is interesting. It is so close to being feasible that it satisﬁes LOQO’s test for
feasibility (in both the primal and the dual), but runs into numerical trouble after achieving only ﬁve
signiﬁcant ﬁgures.
6.2. Quadratic Programming Problems. As mentioned at the beginning of this section, in LOQO
version 3.10, parameter values have different defaults depending on whether a problem is linear or
nonlinear. Consequently, quadratic programming problems are treated as general nonlinear problems
ROBERT J. VANDERBEI
Solution Statistics
Performance Stats
Significant
Iterations
5.5018459e+03
5.5018459e+03
9.8722419e+05
9.8722419e+05
2.2549496e+05
2.2549496e+05
-4.6475314e+02
-4.6475314e+02
-3.5991767e+07
-3.5991767e+07
-2.0239252e+07
-2.0239252e+07
1.0312116e+07
1.0312116e+07
-1.5862802e+02
-1.5862802e+02
3.3592486e+04
3.3592485e+04
-3.0812150e+01
-3.0812150e+01
1.9776296e+03
1.9776295e+03
1.8112365e+03
1.8112365e+03
-3.3521357e+02
-3.3521357e+02
-3.1501873e+02
-3.1501873e+02
1.3730804e+03
1.3730804e+03
1.5185099e+03
1.5185099e+03
2.6900129e+03
2.6900129e+03
-5.2263930e+00
-5.2263930e+00
2.1851967e+06
2.1851967e+06
1.2278421e+05
1.2278421e+05
3.1549167e+02
3.1549167e+02
-1.4351780e+03
-1.4351780e+03
-9.8729398e+02
-9.8729400e+02
1.1266396e+01
1.1266396e+01
-1.8751929e+01
-1.8751929e+01
-7.5571522e+02
-7.5571524e+02
5.5567957e+05
5.5567956e+05
1.7279107e+05
1.7279106e+05
-9.1463780e+03
-9.1463783e+03
9.1463782e+03
9.1463781e+03
-6.8464293e+04
-6.8464294e+04
6.8464294e+04
6.8464292e+04
-1.8207020e+02
-1.4821157e+10
-1.0958574e+05
-1.0958574e+05
6.9022360e+06
6.9022360e+06
-7.2555247e+07
-7.2555248e+07
-4.3022602e+06
-4.3022603e+06
-1.0687094e+08
-1.0687094e+08
-1.6083434e+08
-1.6083434e+08
-4.7787812e+07
-4.7787812e+07
-8.9664465e+05
-8.9664463e+05
-1.7499001e+03
-1.7499001e+03
-2.5264702e+01
-2.5264703e+01
1.4971852e+06
1.4971852e+06
-5.8063744e+04
-5.8063744e+04
3.2061973e+02
3.2061973e+02
TABLE 2. Solution and performance statistics for the NETLIB problems having optimal solutions (25fv47–modszk1).
LOQO: AN INTERIOR POINT CODE FOR QUADRATIC PROGRAMMING
Solution Statistics
Performance Stats
Significant
Iterations
1.4076037e+07
1.4076036e+07
-9.3807553e+03
-9.3807554e+03
-2.5811392e+03
-2.5811393e+03
3.0171035e+02
3.0171035e+02
-6.1131364e+03
-6.1131365e+03
-4.4972762e+03
-4.4972763e+03
-5.5748971e+02
-5.5748973e+02
-2.7201075e+06
-2.7201076e+06
-2.6661600e+02
-2.6661600e+02
-5.2202060e+01
-5.2202061e+01
-5.2202061e+01
-5.2202061e+01
-6.4575077e+01
-6.4575077e+01
-7.0000000e+01
-7.0000001e+01
-1.4753433e+07
-1.4753433e+07
-2.3313898e+06
-2.3313898e+06
1.8416759e+04
1.8416759e+04
3.6660262e+04
3.6660261e+04
5.4901255e+04
5.4901254e+04
1.8781248e+03
1.8781248e+03
9.0429696e+02
9.0429695e+02
8.6666668e+00
8.6666667e+00
5.0500000e+01
5.0500000e+01
9.0500002e+02
9.0499999e+02
1.4122500e+03
1.4122500e+03
1.7248071e+03
1.7248071e+03
1.4240000e+03
1.4240000e+03
1.5711600e+04
1.5711600e+04
-7.6589318e+04
-7.6589319e+04
-4.1573224e+02
-4.1573224e+02
1.2088253e+09
1.2088253e+09
1.7933245e+06
1.7933245e+06
1.7987147e+06
1.7987147e+06
1.9090552e+06
1.9090552e+06
1.9200982e+06
1.9200981e+06
1.4701879e+06
1.4701879e+06
1.4892361e+06
1.4892361e+06
1.5394356e+07
1.5394356e+07
-2.5126695e+02
-2.5126695e+02
1.2576995e+03
1.2576995e+03
1.4060175e+03
1.4060175e+03
-4.1131976e+04
-4.1131976e+04
-3.9024408e+04
-3.9024409e+04
2.9214778e-01
2.9214776e-01
1.2983146e+05
1.2983146e+05
1.4429025e+00
1.4429024e+00
1.3044764e+00
1.3044763e+00
TABLE 3. Solution and performance statistics for the NETLIB problems having optimal solutions (nesm–woodw).
ROBERT J. VANDERBEI
Iterations
Iterations
Iterations
TABLE 4. Iterations to detect infeasibility for the infeasible NETLIB problems. Note,
0 indicates that infeasibility was detected in preprocessing, whereas 200 indicates that
the iteration limit was reached without detecting infeasibility.
even though the appropriate default values for linear programming work much better on these problems. Therefore, the runs documented in this section were all performed with the following nondefault
parameter settings:
• convex: ensures that none of the special code for nonconvex nonlinear programming is called.
• bndpush=100: ensures that initial values are sufﬁciently far removed from their bounds.
• honor bnds=0: allows variables to violate their bounds initially.
• pred corr=1: enables the predictor-corrector method.
• mufactor=0: sets the predictor direction to the primal-dual afﬁne-scaling direction.
Future releases of LOQO will ensure that these are the defaults for convex quadratic programming
problems (as was the case in earlier releases).
We used the repository of convex quadratic programming problems collected by Maros and M´esz´aros
 . It should be noted that the problems stored in this repository are stored in an extended form,
called QPS, of the industry standard MPS format. In MPS and QPS format, a constant term for the
objective function is stored in the right-hand side section of the ﬁle. Unfortunately, LOQO does not
pick this constant out from this section and so the objective function values reported below don’t
match those given in . Spot checks veriﬁed that this is the sole source of discrepancy between our
values and those reported in .
Some of the problems in the repository are quadratic variants of problems from the NETLIB collection. Results for these problems are shown in Table 5. Of the 46 problems in this test set only two
(forplan and pivotnov) failed to achieve the conditions for the stopping rule (which is relative
primal and dual infeasibilities less that 1.0e-6 and 8 digits of agreement between primal and dual
objective functions). On iteration 30, forplan had 8 digits of agreement between primal and dual
objective functions, relative primal infeasibility of 1.89e-11, and dual infeasibility of 9.17e-04
before numerical troubles set in which on the 36th iteration led LOQO to conclude that the problem is
dual infeasible. Similarly on iteration 48, pilotnov had 6 ﬁgures of agreement, primal infeasibility of 1.43e-08, and dual infeasibility of 1.46e-02, after which numerical difﬁculties set in and
LOQO was never able to ﬁnd a dual feasible solution. As we saw with the linear programming version
LOQO: AN INTERIOR POINT CODE FOR QUADRATIC PROGRAMMING
of forplan, normalizer used in the relativization might be of the wrong magnitude. This might have
been the case for both forplan and pilotnov since the initial relative infeasibility was in both
cases greater that 1.00e+03.
Another collection of problems in the repository come from the CUTE set of problems . Results
for these problems are shown in Tables 6 and 7. All 76 problems in this set solve to optimality.
ROBERT J. VANDERBEI
Solution Statistics
Performance Stats
1.3744448e+07
1.3744447e+07
4.8031886e+05
4.8031886e+05
-1.5907818e+00
-1.5907818e+00
1.6352342e+04
1.6352342e+04
1.6471207e+05
1.6471207e+05
3.1002009e+03
3.1002008e+03
2.8375115e+04
2.8375115e+04
6.6793293e+07
6.6793293e+07
2.0554043e+02
2.0554043e+02
8.6760369e+04
8.6760369e+04
8.7314749e+05
8.7314751e+05
7.4934651e+09
3.2478707e+09
1.0079058e+11
1.0079058e+11
-1.0169364e+08
-1.0169364e+08
-1.4962895e+08
-1.4962896e+08
-4.2798714e+07
-4.2798714e+07
2.5347838e+07
2.5347838e+07
4.7285893e+06
4.7285752e+06
-2.6661600e+02
-2.6661600e+02
-5.8139535e-03
-5.8139535e-03
2.0173794e+08
2.0173794e+08
2.6865949e+07
2.6865949e+07
1.6882691e+07
1.6882691e+07
2.7776161e+07
2.7776160e+07
3.0816353e+07
3.0816353e+07
1.8805096e+03
1.8805095e+03
9.0456001e+02
9.0456001e+02
8.6666668e+00
8.6666667e+00
5.0808214e+01
5.0808214e+01
9.4076358e+02
9.4076357e+02
1.4158611e+03
1.4158611e+03
1.7350265e+03
1.7350265e+03
1.4387547e+03
1.4387547e+03
8.1481799e+07
8.1481800e+07
7.2007834e+05
7.2007833e+05
1.1703692e+04
1.1703692e+04
1.5726368e+12
1.5726368e+12
2.4200155e+06
2.4200155e+06
2.4249936e+06
2.4249937e+06
2.3760406e+06
2.3760406e+06
2.3857286e+06
2.3857287e+06
3.0188763e+06
3.0188764e+06
3.0569622e+06
3.0569622e+06
2.3750458e+07
2.3750458e+07
7.9854527e+06
7.9854528e+06
6.4118384e+03
6.4118384e+03
TABLE 5. Performance statistics for quadratic variants of the feasible NETLIB problems.
LOQO: AN INTERIOR POINT CODE FOR QUADRATIC PROGRAMMING
Solution Statistics
Performance Stats
1.6775117e+06
1.6775118e+06
1.8082680e+06
1.8082681e+06
6.4880347e+06
6.4880347e+06
6.2271119e+06
6.2271119e+06
-7.8243228e+02
-7.8243227e+02
-1.1652376e+03
-1.1652376e+03
-9.4313784e+02
-9.4313786e+02
-6.6126233e+02
-6.6126233e+02
1.0870480e+08
1.0870480e+08
1.0875115e+06
1.0875115e+06
1.1590718e+04
1.1590718e+04
8.1842458e+07
8.1842458e+07
8.2015543e+05
8.2015543e+05
8.1209405e+03
8.1209403e+03
1.1571110e+08
1.1571110e+08
1.3628287e+06
1.3628287e+06
1.1943432e+04
1.1943432e+04
2.3526248e+02
2.3526248e+02
3.5012967e-02
3.5012965e-02
3.3733677e-02
3.3733672e-02
1.3575584e-01
1.3575583e-01
7.4609085e-01
7.4609082e-01
6.1552508e+03
6.1552508e+03
3.5513077e+03
3.5513077e+03
4.2723233e+02
4.2723231e+02
1.8309359e+04
1.8309359e+04
9.2717369e-01
9.2717369e-01
1.8427677e-04
1.8425871e-04
-2.9647837e+04
-2.9647837e+04
6.6482045e+02
6.6482044e+02
4.0000001e-02
3.9999999e-02
-1.4463000e+04
-1.4463000e+04
-8.8888889e+00
-8.8888889e+00
-8.7499999e+00
-8.7500001e+00
-6.0000000e+00
-6.0000000e+00
-6.7335244e-01
-6.7335244e-01
-1.9069767e+00
-1.9069768e+00
-4.6818182e+00
-4.6818182e+00
TABLE 6. Performance statistics for quadratic CUTE problems (aug2d to hs76).