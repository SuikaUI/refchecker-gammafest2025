Bi-layer segmentation of binocular stereo video
V. Kolmogorov
A. Criminisi
Microsoft Research Ltd., 7 J J Thomson Ave, Cambridge, CB3 0FB, UK
 
input left view
input right view
automatic layer separation and background substitution in three different frames
Figure 1: An example of automatic foreground/background separation in binocular stereo sequences. The extracted foreground sequence
can be composited free of aliasing with different static or moving backgrounds; a useful tool in video-conferencing applications. Note, the
input synchronized stereo sequences used throughout this paper can be downloaded from , as well as hand-labeled segmentations.
This paper describes two algorithms capable of real-time
segmentation of foreground from background layers in
stereo video sequences.
Automatic separation of layers
from colour/contrast or from stereo alone is known to be
error-prone.
Here, colour, contrast and stereo matching
information are fused to infer layers accurately and efﬁciently. The ﬁrst algorithm, Layered Dynamic Programming (LDP), solves stereo in an extended 6-state space
that represents both foreground/background layers and occluded regions. The stereo-match likelihood is then fused
with a contrast-sensitive colour model that is learned on the
ﬂy, and stereo disparities are obtained by dynamic programming. The second algorithm, Layered Graph Cut (LGC),
does not directly solve stereo. Instead the stereo match likelihood is marginalised over foreground and background hypotheses, and fused with a contrast-sensitive colour model
like the one used in LDP. Segmentation is solved efﬁciently
by ternary graph cut.
Both algorithms are evaluated with respect to ground
truth data and found to have similar perfomance, substantially better than stereo or colour/contrast alone.
However, their characteristics with respect to computational ef-
ﬁciency are rather different. The algorithms are demonstrated in the application of background substitution and
shown to give good quality composite video output.
1. Introduction
This paper addresses the problem of separating a foreground layer from stereo video in real time. A prime application is for teleconferencing in which the use of a stereo
webcam already makes possible various transformations of
the video stream including digital pan/zoom/tilt and object
insertion1. Here we concentrate on providing the infrastructure for live background substitution. This demands foreground layer separation to near Computer Graphics quality, including α-channel determination as in video-matting
 , but with computational efﬁciency sufﬁcient to attain
live streaming speed.
Layer extraction from images has long been an active
area of research . The challenge addressed
here is to segment the foreground layer both accurately and
efﬁciently.
Conventional stereo algorithms e.g. 
have proven competent at computing depth.
Stereo occlusion is a further cue that needs to be accurately computed to achieve good layer extraction. However, the strength of stereo cues degrade over low-texture regions such as blank walls, sky or saturated image areas. Recently interactive colour/contrast-based segmentation techniques have been demonstrated to be very effective ,
even in the absence of texture.
Segmentation based on
colour/contrast alone is nonetheless beyond the capability
of fully automatic methods. This suggests a robust approach
that exploits fusion of a variety of cues. Here we propose a
model and algorithms for fusion of stereo with colour and
contrast, and a prior for intra-layer spatial coherence.
The efﬁciency requirements of live background substitution have restricted us to algorithms that are known to be
capable of near frame-rate operation, speciﬁcally dynamic
programming and ternary graph cut (i.e. α-expansion algorithm with three labels). Therefore two approaches
to segmentation are proposed here: Layered Dynamic Pro-
1research.microsoft.com/vision/cambridge/i2i
Authorized licensed use limited to: University College London. Downloaded on October 27, 2008 at 12:58 from IEEE Xplore. Restrictions apply.
Figure 2: Segmentation by fusing colour, contrast and stereo.
Results of three different segmentation algorithms run on the left
input image of ﬁg.
1 (see or video in the CD-ROM proceedings for more examples). (a) Stereo-based segmentation. (b)
Colour/contrast-based segmentation. (c) The algorithm proposed
here, by fusing colour, contrast and stereo achieves more accurate segmentation. The foreground artefacts visible in (a) and (b)
(marked in red) are corrected in (c), where the person and chair are
correctly extracted. Note, we do not just combine images (a) and
(b) to produce (c); see text for algorithmic details.
gramming (LDP) and Layered Graph Cut (LGC). Each
works by fusing likelihoods for stereo-matching, colour and
contrast to achieve segmentation quality unnattainable from
either stereo or colour/contrast on their own (see ﬁg. 2).
This claim is veriﬁed by evaluation on stereo videos with
respect to ground truth (section 5). Finally, efﬁcient postprocessing for matting is applied to obtain good video
quality as illustrated in stills and accompanying video in the
CD-ROM proceedings.
The paper is organised as follows. In section 2 we describe components of our probabilistic model that are common in both techniques. In sections 3 and 4 we present LDP
and LGC algorithms, respectively. Experimental results are
given in section 5. Finally, section 6 contains conclusions.
Note that due to space limitations some details of the algorithms have been omitted, but can be found in .
Probabilistic models for bi-layer
segmentation of stereo images
First we outline the probabilistic structure of the stereo and
colour/contrast models.
Notation and basic framework
Pixels in the left and right images are m, n respectively and
index either the entire images, or just a pair of matching
epipolar lines, as required. Over epipolar lines, the intensity
functions from left and right images are
L = {Lm, m = 0, . . . , N}, R = {Rn, n = 0, . . . , N}.
Stereo disparity along the cyclopean2 epipolar line is d =
{dk, k = 0, . . . , 2N} and disparity is simply related to image coordinates:
dk = m −n with m = (k + dk)
and n = (k −dk)
2cyclopean here means mid-way between left and right input cameras.
Figure 3: Disparity and the cyclopean image. Notation conventions for left and right epipolar lines with pixel coordinates m, n,
cyclopean coordinates k and stereo disparity d = m −n. Possible
matching path shown dashed (cf. ).
Left and right pixels are ordered by any particular matching
path (ﬁg. 3) to give 2N cyclopean pixels
z = {zk, k = 0, . . . , 2N},
where k = m + n. Only single-step horizontal and vertical moves are allowed — no diagonal or multistep moves.
This means that, for a given path, z consists of a sequence
of Lm and Rn elements, such that each left and right pixel
appears exactly once on the path. This is essential to a consistent probabilistic interpretation, as explained shortly. In
addition an array x of state variables, either in cyclopean coordinates x = {xk} or image coordinates x = {xm}, takes
values xk ∈{F, B, O} according to whether the pixels is a
foreground match, a background match or occluded.
Sets of model parameters: Φ are deﬁned for priors on
stereo; Θ for colour/contrast and match likelihoods. Details are given later. This enables Gibbs energies to be de-
ﬁned, in terms of probabilistic models, which are globally
minimised to obtain a segmentation. The LDP algorithm
minimises, independently over each epipolar line, an energy E(z, d, x; Θ, Φ) in which there is explicit dependency
on disparity d. The presence of parameters Φ indicates that
the LDP energy incorporates priors on stereo disparity as
a further constraint on the solution for segmentation. Conversely LGC minimises, globally over an image, an energy
E(z, x; Θ) in which disparity variables do not explicitly appear.
2.2. Likelihood for stereo
We need to model the stereo-matching likelihood function
p(z | x, d) and this is expanded as
p(z | x, d)
p(zk | xk, dk, z1, . . . , zk−1)
exp −Lk(xk, dk)
Authorized licensed use limited to: University College London. Downloaded on October 27, 2008 at 12:58 from IEEE Xplore. Restrictions apply.
linear region
Figure 4: Likelihood model: the empirical log-likelihood ratio
−Lk is shown for stereo matches, plotted here as a function of the
NSSD measure N(LP, RP), using the ground truth stereo data
“Teddy” from the Middlebury set . Note the linearity in the
region of L = 0, where most data falls. Similar behaviour has
been observed for other ground-truth datasets.
where the pixelwise negative log-likelihood ratio, for match
vs. non-match, is
Lk(xk, dk)
−log p(zk | xk, dk, z1, . . . , zk−1)
log p(zk | xk = O).
According to the deﬁnition, Lk(xk = O, dk) = 0. Commonly stereo matches are scored using SSD (sumsquared difference), that is L2-norm of difference between
image patches LP
n surrounding hypothetically matching pixels m, n. Like we model Lk using SSD with
additive and multiplicative normalisation for robustness to
non-Lambertian effects (NSSD - normalized SSD):
Lk(xk, dk) =
if xk ∈{F, B}
if xk = O,
where M = λN with λ a constant, and
N(LP, RP) = 1
∥LP −LP∥2 + ∥RP −RP∥2 ∈ .
This model has been tested against the Middlebury datasets and found to be reasonable — an example of results
is given in ﬁg. 4. Such analysis gives also useful working
values for λ (typical value for monochrome images is λ =
10, which holds for a variety of patch sizes; we used 3 × 7
patches for LGC and 5 × 5 patches for LGC). For M0 this
analysis yields value of approximately 0.3. However, we
found that discriminatively learned M0 is usually larger: a
typical value is M0 = 0.4, and that value gives better error
rates in practice.
Stepwise restriction for matching paths
Previous algorithms e.g. have allowed multiple
and/or diagonal moves on the stereo matching paths. However, the single-step restriction (ﬁg. 3) allows for a consistent probabilistic interpretation of the sequence matching
problem to exist (see for details). With the restriction in place, each element Lm and Rn is “explained” once
and only once: it appears once and only once as zk in the
p(zk| . . .) term of (2), as required. The existence of a probabilistic interpretation then allows a consistent account of
fusion of different modalities, by multiplication of likelihoods. The practical beneﬁt is that the weighting coefﬁcients of the various energy terms are mostly determined
automatically, from statistics, rather than having to be set
2.4. Likelihood for colour
Following previous approaches to two-layer segmentation
 we model likelihoods for colour in foreground and
background using Gaussian mixtures in RGB colour space,
learned from image frames labelled (automatically) from
earlier in the sequence. In addition, the background model
is enhanced by mixing in a probability density learned, for
each pixel, by pixelwise background maintenance .
The foreground colour model p(z | x = F) is simply a
spatially global Gaussian mixture learned from foreground
pixels. In the background there is a similar learned Gaussian
mixture p(z | x = B) and also a per-pixel single Gaussian
density pk(zk) available wherever the stability ﬂag sk ∈
{0, 1} indicates that there has been stasis over a sufﬁcient
number of previous frames. The occluding state x = O
refers to background pixels and therefore shares a colour
model with x = B. The combined colour model is then
given by an energy U C
k (zk, xk) = −log p(zk | xk) if x = F,
and for x = B, O:
k (zk, xk) = −log
2 )p(zk|xk = B) + sk
a mixture between the global background model and the
pixelwise one. This approach is both powerful and robust:
pixelwise densities U C
k are typically strongly peaked, and
hence very informative, but sensitive to movement in the
background. That sensitivity is robustiﬁed by adding in the
general background distribution p(zk|xk = B) as the contamination component in the mixture.
Contrast model
There is a natural tendency for segmentation boundaries to
align with contours of high image contrast. Similarly to ,
this is represented by an image energy of the form
Vk,k′ = Fk,k′[xk, xk′]V ∗(zk, zk′),
where k, k′ are neighbouring pixel-pairs in the cyclopean
Function Fk,k′[xk, xk′] is the potential coefﬁcient which implements geometric constraints . The exact form of Fk,k′
is different for LDP and LGC, and it is given later in corresponding sections. The term V ∗applies contrast sensitivity:
V ∗(z, z′) =
ϵ + exp −∥z −z′∥2
, a mean over all pairs of neighbours
in the left and right images.
The energy made by summing up Vk,k′ in fact represents an Ising prior for labelling coherence, modiﬁed by a
contrast factor that acts to discount partially the coherence
terms. The constant ϵ is a “dilution” constant for contrast,
previously set to ϵ = 0 for pure colour segmentation.
Here, ϵ = 1 is more appropriate — diluting the inﬂuence
of contrast in recognition of the increased diversity of segmentation cues.
Layered Dynamic Programming
The LDP algorithm solves for disparity over individual
scanlines on the (virtual) cyclopean image zk. It is based
on the classic dynamic programming approach together with augmentation of the state space to handle occlusion . The 4-state model of is described
in section 3.1. The foreground/background states are then
added in the 6-state model (section 3.2).
4-state stereo with occlusions
This can be expressed concisely as a 4-state system that
is summarised in ﬁg. 5. A basic 4-state system is annotated with transitions and associated energy terms to deﬁne
a global energy
E(z, d, x; Θ, Φ) =
Ek(dk, dk−1, xk, xk−1)
where xk ∈{M, O} in which M denotes a stereo match and
O an occlusion. Each Ek(. . .) term consists of the sum
k + Vk−1,k
of a cost Vk−1,k of transition k −1 →k (on arcs) and a
state cost U M
k (inside nodes) on the diagram of ﬁg. 5. The
occluding state xk = O is split into two sub-states (red
circles in ﬁg. 5), left-occluding and right-occluding (which
do not intercommunicate, reﬂecting geometric constraints).
The matching state xk = M also has two substates (green
circles in ﬁg. 5):
Left match
dk = dk−1 + 1
Right match
dk = dk−1 −1
M(Lm , Rn )
M(Lm , Rn )
State space for stereo matching with occlusion.
Matched and occluded states (each in left and right versions) form
a 4-state system. Successive pixels along a cyclopean epipolar line
(ﬁg. 3) incur a cost increment (e.g. b) for the arc k −1 →k traversed, plus an increment (e.g. M0) for the new node k.
representing the typical stepwise progress of the matching
path as in ﬁgure 3. There are a total then of 4 possible states:
xk ∈{L-match, R-match, L-occ, R-occ}.
parameters
{a0, b0, a, b, c} which specify the stereo prior over matching paths. It might seem problematic that so many parameters need to be set, but in fact they can be learned from
previous labelled frames as follows:
b0 = log(2WO) b = log(2WM)
where WM and WO are the mean widths of matched and
occlusion regions respectively. This follows simply from
the fact that 2 exp −b is the probability of escape from a
matched state, and similarly for 2 exp −b0 in an occluded
Then consideration of viewing geometry (details
omitted) indicates:
a = log(1 + D/b) −log(1 −1/WM),
where D is a nominal distance to objects in the scene and b
is the interocular distance (camera baseline). Lastly, probabilistic normalisation demands that
c = −log(1 −2e−b −e−a) and a0 = −log(1 −2e−b0),
so there are really just 3 independent parameters in Φ.
Match costs inside nodes are deﬁned in terms of match likelihood energy, as in (4). The total energy is then minimised
by Dynamic Programming in a manner similar to .
6-state stereo with occlusion and layers
Next, we distinguish foreground and background layers and
use an extended 6-state algorithm in which matched states
Authorized licensed use limited to: University College London. Downloaded on October 27, 2008 at 12:58 from IEEE Xplore. Restrictions apply.
Foreground
Background
M(Lm , Rn )
M(Lm , Rn )
M(Lm , Rn )
M(Lm , Rn )
Figure 6: Extended state space for LDP in which the matched state of ﬁg. 5 is split into a foregound and a background substate. Note
that from the foreground state (yellow circles), only the right occluding state is accessible, and from background (blue circles) only the left
occluding state, constraints of the geometry of occlusion.
from the 4-state system are split into foreground and background substates.
The diagram of ﬁg. 5 is cut by the
splitting of the matched states and unfolded into the diagram of ﬁg. 6. There are now a total of 6 possible states:
xk ∈{L-match-F, R-match-F, L-match-B, R-match-B, Locc, R-occ}. The model has a number of parameters Φ =
{aF , aB, aO, bF , bB, bOF , bOB, cF , cB} all of which can be
set from statistics and geometry as before, but now statistics
are collected separately for the xk = F and xk = B conditions.
The 6-state model with disparity-pull and
colour/contrast fusion
Now the stereo infrastructure for LDP is capable of representing the two layers, it remains to add in energies for the
colour and contrast likelihoods. The full energy for stereo
matching, per cyclopean pixel, is now
k + Vk−1,k + U C
k and Vk−1,k are respectively the node and transition energies from section 3.2. The nodal energy is now extended, from U M
k , to take account of additional colour and “disparity-pull” information, respectively.
The colour energy term U C
k is as described earlier (6). The
disparity-pull energy
k (zk, xk) = −log p(dk|xk)
represents the pull of each layer towards certain disparities, as determined by the densities p(dk|xk = F, B, O)
which are learned as Gaussians from labelled data in
previous frames.
Typically this term pulls the foreground/background layers towards larger/smaller values of
disparity respectively.
Finally, the transition component Vk−1,k from the 6-state
model is further modiﬁed to take account of contrast (8).
This is done by modifying each transition energy between
occluding and foreground states (ﬁg. 6) as follows:
bF →bF V ∗(zk−1, zk) and bOF →bOF V ∗(zk−1, zk),
where V ∗is the contrast term deﬁned earlier (9). Note that
colour/contrast in the 6-state model have to be computed
jointly over left and right images (see for details).
Now the full 6-state system, augmented both for bi-layer
inference and for fusion of colour/contrast with stereo can
be optimised by dynamic programming as before. Results
of this approach are shown below in section 5, but in the
meantime the alternative LGC algorithm is described.
4. Layered Graph Cut (LGC)
Layered Graph Cut (LGC) determines segmentation x as
the minimum of an energy function E(z, x; Θ), in which,
unlike LDP, stereo disparity d does not appear explicitly. Instead, disparity is marginalised to give a likelihood
p(L | x, R), in which stereo-match likelihoods have been
aggregated to compute support for each of the three labels
in x: foreground, background and occlusion (F, B, O). The
segmentation is ternary so the α-expansion form of graphcut is needed. Space forbids a detailed description of
the LGC algorithm, however, it represents another, very effective way of implementing the colour-stereo fusion idea.
Therefore, it was felt important to include a sketch of the
method. A particular difference between LDP and LGC is
that LGC is speciﬁed with respect to one (e.g. left) image,
rather than the cyclopean frame as in LDP.
The energy function for LGC is composed of three
Authorized licensed use limited to: University College London. Downloaded on October 27, 2008 at 12:58 from IEEE Xplore. Restrictions apply.
E(z, x; Θ) = U C(z, x; Θ)+V (z, x; Θ)+U S(z, x), (18)
representing energies for colour-likelihood, spatial coherence/contrast and stereo likelihood respectively. The colour
energy is simply a sum over pixels in the left image
U C(z, x; Θ) =
of the pixelwise colour energy deﬁned earlier (6). The coherence/contrast energy is a sum of pairwise energies of
the form (8) where coefﬁcient Fm,m′ is deﬁned as follows.
For vertical and diagonal cliques it acts as a switch active across a transition in or out of the foreground state:
Fm,m′[x, x′] = γ if exactly one variable x, x′ equals F,
and Fm,m′[x, x′] = 0 otherwise. For horizontal lines it implements geometric constraints: Fm,m′[x, x′] is inﬁnity for
transitions O→B and F→O, and zero for all other transitions.
Marginalisation of stereo likelihood
The remaining term in (18) is U S(z, x) which captures the
inﬂuence of stereo matching likelihood on the probability
of a particular segmentation. It is deﬁned to be
U S(z, x) =
m(xm) = −log p(Lm|xm, R)+const,
p(Lm|xm, R) =
p(Lm|xm, dm = d, R)p(dm = d|xm)
— marginalizing over disparity, and the distributions
p(dm = d|xm) for xm ∈{F, B} are learned from labelled
data in previous frames. The const term in (21) allows us
to make use of the likelihood-ratio model of section 2.2 for
stereo matches, giving
d p(dm = d|xm) exp −λM(LP
Results of LDP and LGC are given next.
5. Results
Performance of the LGC and LDP algorithms was evaluated
with respect to ground-truth segmentations of every ﬁfth
frame (left view) in each of two test stereo sequences3. The
data was labelled manually, labelling each pixel as background, foreground or unknown. The unknown label was
used to mark mixed pixels occurring along layer boundaries. Error is then measured as percentage of misclassiﬁed
pixels, ignoring “unknown” pixels.
3Ground truth segmentation data is available at .
− Col./cont.
Error: (perc. misc. pixels w.r.t. image area)
Figure 7: Measuring segmentation performance. Segmentation error (percentage of misclassiﬁed pixels) is computed on the
S1 sequence, with respect to ground truth. Average error values and 1-std bars are also plotted. Note that fused stereo and
colour/contrast (LGC and LDP) perform substantially better than
either stereo or colour/contrast alone.
Measuring accuracy of segmentation.
Segmentation
performance for the stereo sequence pair S1 (example input images in ﬁg.1) is compared for colour/contrast, for
stereo alone, and for colour/contrast and stereo fused together (ﬁg. 7). The colour/contrast algorithm here is simply
LGC in which the stereo component is switched off. The
stereo-only algorithm is 4-state DP as in section 3.1. Fusion of colour/contrast and stereo by the LGC and LDP algorithms both show similarly enhanced performance compared with colour/contrast or stereo alone. As a test of robustness, the algorithms have also been tested on a sequence
S2 with motion in the background (example input images
in ﬁg. 12). Two people enter the scene and move around
behind a person occupying the foreground. Once again the
power of fusing colour/contrast and stereo is immediately
apparent (ﬁg. 8).
An example of a segmented image is
shown in ﬁg. 9 and the spatial distribution of segmentation
errors is illustrated in ﬁg. 10: errors tend to cluster closely
around object boundaries.
Background substitution in sequences.
Finally, ﬁgs. 11-
13 demonstrate the application of segmentation to background replacement in video sequences (additional results
are available at ). Background substitution in sequences
is challenging as the human eye is very sensitive to ﬂicker
artefacts. Following foreground/background segmentation,
α-matting has been computed using SPS as a postprocess.
Both the LGC and LDP algorithms give good
results, with blended boundaries and little visible ﬂicker.
Authorized licensed use limited to: University College London. Downloaded on October 27, 2008 at 12:58 from IEEE Xplore. Restrictions apply.
− Colour/cont.
Error: (perc. misc. pixels w.r.t. image area)
Figure 8: Segmentation performance is robust to background
motion. As for ﬁg. 7 but for the S2 sequence: fusion by LDP or
LGC is robust to movement in the background.
Figure 9: Extracted foreground layer for the left view of S1,
frame 100.
6. Conclusion
This paper has addressed the important problem of segmenting stereo sequences.
Disparity-based segmentation
and colour/contrast-based segmentation alone are prone to
failure. LDP and LGC are algorithms capable of fusing the
two kinds of information with a substantial consequent improvement in segmentation accuracy. Moreover, both algorithms are suited for real-time implementation. Fast implementations of DP techniques are well known .
Ternary graph cut has been applied, in our laboratory, at
around 10 frames per second for 320×240 image on a 3GHz
Pentium desktop machine. Given that the segmentation accuracies of LDP and LGC are comparable, what is to choose
between them? In fact the choice may depend on architecture: the stereo component of LGC can be done, in principle
on a graphics co-processor, including the marginalisation
over disparities. In LDP however, although stereo-match
scores could be computed with the graphics coprocessor,
Figure 10: Spatial distribution of segmentation error. Red
pixels are misclassiﬁed (with respect to ground-truth). Results for
S1 at frame 100.
LDP, frame 0
LGC, frame 0
LDP, frame 100
LGC, frame 100
Figure 11: Segmentation and background substitution. Here
we show background substitution for two frames of the S1 sequence. Visual quality of LDP and LGC results are similar.
communicating the entire cost array Lk(xk, dk) to the general processor is beyond the bandwidth limitations of current GPU designs. On the other hand LDP is economical in
memory usage, in that it can proceed scanline by scanline.
In conclusion, we have demonstrated properties of the
LDP and LGC algorithms and underlying model as follows.
• Fusion of stereo with colour and contrast can be captured in a probabilistic model, in which parameters can
mostly be learned, or are otherwise stable.
• Fusion of stereo with colour and contrast makes
for more powerful segmentation than for stereo or
colour/contrast alone.
• Good quality segmentation of temporal sequences
(stereo) can be achieved, without imposing any explicit
temporal consistency between neighbouring frames.
Acknowledgements
We thank M. Isard and R. Szeliski for helpful discussions.
Authorized licensed use limited to: University College London. Downloaded on October 27, 2008 at 12:58 from IEEE Xplore. Restrictions apply.
Figure 12: Segmentation with non-stationary background.
(Left) Three frames of the input left sequence S2 (right frame
not shown here). (Right) Corresponding LGC segmentation and
background substitution. Note the robustness of the segmentation
to motion in the original background.