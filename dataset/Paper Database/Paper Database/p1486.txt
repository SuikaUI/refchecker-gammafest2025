Social GAN: Socially Acceptable Trajectories
with Generative Adversarial Networks
Agrim Gupta1
Justin Johnson1
Li Fei-Fei1
Silvio Savarese1
Alexandre Alahi1,2
Stanford University1
´Ecole Polytechnique F´ed´erate de Lausanne2
Understanding human motion behavior is critical for autonomous moving platforms (like self-driving cars and social robots) if they are to navigate human-centric environments. This is challenging because human motion is inherently multimodal: given a history of human motion paths,
there are many socially plausible ways that people could
move in the future. We tackle this problem by combining
tools from sequence prediction and generative adversarial networks: a recurrent sequence-to-sequence model observes motion histories and predicts future behavior, using
a novel pooling mechanism to aggregate information across
people. We predict socially plausible futures by training adversarially against a recurrent discriminator, and encourage diverse predictions with a novel variety loss. Through
experiments on several datasets we demonstrate that our
approach outperforms prior work in terms of accuracy, variety, collision avoidance, and computational complexity.
1. Introduction
Predicting the motion behavior of pedestrians is essential for autonomous moving platforms like self-driving cars
or social robots that will share the same ecosystem as humans. Humans can effectively negotiate complex social interactions, and these machines ought to be able to do the
same. One concrete and important task to this end is the
following: given observed motion trajectories of pedestrians (coordinates for the past e.g. 3.2 seconds), predict all
possible future trajectories (Figure 1).
Forecasting the behavior of humans is challenging due to
the inherent properties of human motion in crowded scenes:
1. Interpersonal. Each person’s motion depends on the
people around them.
Humans have the innate ability
to read the behavior of others when navigating crowds.
Jointly modeling these dependencies is a challenge.
2. Socially Acceptable. Some trajectories are physically
possible but socially unacceptable. Pedestrians are gov-
Figure 1: Illustration of a scenario where two pedestrians
want to avoid each other. There are many possible ways that
they can avoid a potential collision. We present a method
that given the same observed past, predicts multiple socially
acceptable outputs in crowded scenes.
erned by social norms like yielding right-of-way or respecting personal space. Formalizing them is not trivial.
3. Multimodal. Given a partial history, there is no single
correct future prediction. Multiple trajectories are plausible and socially-acceptable.
Pioneering work in trajectory prediction has tackled some
of the above challenges. The interpersonal aspect has been
exhaustively addressed by traditional methods based on
hand-crafted features .
Social acceptability has been recently revisited with data-driven techniques
based on Recurrent Neural Networks (RNNs) .
Finally, the multimodal aspect of the problem has been studied in the context of route choices given a static scene (e.g.,
which streets to take at an intersection ). Robicquet
et al. have shown that pedestrians have multiple navigation styles in crowded scenes given a mild or aggressive
style of navigation. Therefore, the forecasting task entails
outputting different possible outcomes.
While existing methods have made great progress in addressing speciﬁc challenges, they suffer from two limitations. First, they model a local neighborhood around each
person when making the prediction. Hence, they do not
have the capacity to model interactions between all people
in a scene in a computationally efﬁcient fashion. Second,
they tend to learn the “average behavior” because of the
 
commonly used loss function that minimizes the euclidean
distance between the ground truth and forecasted outputs.
In contrast, we aim in learning multiple “good behaviors”,
i.e., multiple socially acceptable trajectories.
To address the limitations of previous works, we propose
to leverage the recent progress in generative models. Generative Adversarial Networks (GANs) have been recently
developed to overcome the difﬁculties in approximating
intractable probabilistic computation and behavioral inference . While they have been used to produce photorealistic signals such as images , we propose to use
them to generate multiple socially-acceptable trajectories
given an observed past. One network (the generator) generates candidates and the other (the discriminator) evaluates
them. The adversarial loss enables our forecasting model
to go beyond the limitation of L2 loss and potentially learn
the distribution of “good behaviors” that can fool the discriminator. In our work, these behaviors are referred to as
socially-accepted motion trajectories in crowded scenes.
Our proposed GAN is a RNN Encoder-Decoder generator and a RNN based encoder discriminator with the
following two novelties: (i) we introduce a variety loss
which encourages the generative network of our GAN to
spread its distribution and cover the space of possible paths
while being consistent with the observed inputs. (ii) We
propose a new pooling mechanism that learns a “global”
pooling vector which encodes the subtle cues for all people involved in a scene. We refer to our model as “Social
GAN”. Through experiments on several publicly available
real-world crowd datasets, we show state-of-the-art accuracy, speed and demonstrate that our model has the capacity
to generate a variety of socially-acceptable trajectories.
2. Related Work
Research in forecasting human behavior can be grouped
as learning to predict human-space interactions or humanhuman interactions. The former learns scene-speciﬁc motion patterns . The latter models
the dynamic content of the scenes, i.e. how pedestrians interact with each other. The focus of our work is the latter:
learning to predict human-human interactions. We discuss
existing work on this topic as well as relevant work in RNN
for sequence prediction and Generative models.
Human-Human Interaction. Human behavior has been
studied from a crowd perspective in macroscopic models or
from a individual perspective in microscopic models (the focus of our work). One example of microscopic model is the
Social Forces by Helbing and Molnar which models
pedestrian behavior with attractive forces guiding them towards their goal and repulsive forces encouraging collision
avoidance. Over the past decades, this method has been often revisited . Tools popular in
economics have also been used such as the Discrete Choice
framework by Antonini et. al. . Treuille et. al. 
use continuum dynamics, and Wang et. al. , Tay et. al.
 use Gaussian processes. Such functions have also been
used to study stationary groups . However, all these
methods use hand crafted energy potentials based on relative distances and speciﬁc rules. In contrast, over the past
two years, data-driven methods based on RNNs have been
used to outperform the above traditional ones.
RNNs for Sequence Prediction. Recurrent Neural Networks are a rich class of dynamic models which extend
feedforward networks for sequence generation in diverse
domains like speech recognition , machine translation and image captioning . However,
they lack high-level and spatio-temporal structure .
Several attempts have been made to use multiple networks
to capture complex interactions . Alahi et al. 
use a social pooling layer that models nearby pedestrians. In
the rest of this paper, we show that using a Multi-Layer Perceptron (MLP) followed by max pooling is computationally
more efﬁcient and works as well or better than the social
pooling method from . Lee et al. introduce a RNN
Encoder-Decoder framework which uses variational autoencoder (VAE) for trajectory prediction. However, they did
not model human-human interactions in crowded scenes.
Generative Modeling.
Generative models like variational autoencoders are trained by maximizing the
lower bound of training data likelihood.
Goodfellow et
al. propose an alternative approach, Generative Adversarial Networks (GANs), where the training procedure
is a minimax game between a generative model and a discriminative model; this overcomes the difﬁculty of approximating intractable probabilistic computations. Generative
models have shown promising results in tasks like superresolution , image to image translation , and image
synthesis which have multiple possible outputs
for a given input. However, their application in sequence
generation problems like natural language processing has
lagged since sampling from these generated outputs to feed
to the discriminator is a non-differentiable operation.
Humans possess an intuitive ability to navigate crowds
taking into account the people around them. We plan our
paths keeping in mind our goal and also simultaneously taking into account the motion of surrounding people like their
direction of motion, velocity, etc. However, often in such
situations multiple possible options exist. We need models
which not only can understand these complex human interactions but can also capture the variety of options. Current
approaches have focused on predicting the average future
trajectory which minimizes the L2 distance from the ground
truth future trajectory whereas we want to predict multiple “good” trajectories. In this section, we ﬁrst present our
Figure 2: System overview. Our model consists of three key components: Generator (G), Pooling Module, and Discriminator
(D). G takes as input past trajectories Xi and encodes the history of the person i as Ht
i . The pooling module takes as input
and outputs a pooled vector Pi for each person. The decoder generates the future trajectory conditioned on Htobs
and Pi. D takes as input Treal or Tfake and classiﬁes them as socially acceptable or not (see Figure 3 for PM).
GAN based encoder-decoder architecture to address this issue, we then describe our novel pooling layer which models
human-human interactions and ﬁnally we introduce our variety loss which encourages the network to produce multiple
diverse future trajectories for the same observed sequence.
3.1. Problem Deﬁnition
Our goal is to jointly reason and predict the future trajectories of all the agents involved in a scene. We assume that
we receive as input all the trajectories for people in a scene
as X = X1, X2, ..., Xn and predict the future trajectories
ˆY = ˆY1, ˆY2, ..., ˆ
Yn of all the people simultaneously. The
input trajectory of a person i is deﬁned as Xi = (xt
from time steps t = 1, ..., tobs and the future trajectory
(ground truth) can be deﬁned similarly as Yi = (xt
from time steps t = tobs + 1, ..., tpred. We denote predictions as ˆYi.
3.2. Generative Adversarial Networks
A Generative Adversarial Network (GAN) consists of
two neural networks trained in opposition to each other
 . The two adversarially trained models are: a generative
model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample
came from the training data rather than G. The generator G
takes a latent variable z as input, and outputs sample G(z).
The discriminator D takes a sample x as input and outputs
D(x) which represents the probability that it is real. The
training procedure is similar to a two-player min-max game
with the following objective function:
D V (G, D) =
Ex∼pdata(x)[log D(x)] + Ez∼p(z)[log(1 −D(G(z)))].
GANs can used for conditional models by providing both
the generator and discriminator with additional input c,
yielding G(z, c) and D(x, c) .
3.3. Socially-Aware GAN
As discussed in Section 1 trajectory prediction is a multimodal problem. Generative models can be used with timeseries data to simulate possible futures. We leverage this
insight in designing SGAN which addresses the multimodality of the problem using GANs (see Figure 2). Our
model consists of three key components: Generator (G),
Pooling Module (PM) and Discriminator (D). G is based
on encoder-decoder framework where we link the hidden
states of encoder and decoder via PM. G takes as input Xi
and outputs predicted trajectory ˆYi. D inputs the entire sequence comprising both input trajectory Xi and future prediction ˆYi (or Yi) and classiﬁes them as “real/fake”.
Generator. We ﬁrst embed the location of each person
using a single layer MLP to get a ﬁxed length vector et
These embeddings are used as input to the LSTM cell of
the encoder at time t introducing the following recurrence:
ei = LSTM(ht−1
i; Wencoder)
where φ(·) is an embedding function with ReLU nonlinearity, Wee is the embedding weight. The LSTM weights
(Wencoder) are shared between all people in a scene.
Na¨ıve use of one LSTM per person fails to capture interaction between people. Encoder learns the state of a person and stores their history of motion. However, as shown
by Alahi et al. we need a compact representation which
combines information from different encoders to effectively
reason about social interactions. In our method, we model
human-human interaction via a Pooling Module (PM). After tobs we pool hidden states of all the people present in
the scene to get a pooled tensor Pi for each person. Traditionally, GANs take as input noise and generate samples.
Our goal is to produce future scenarios which are consistent
with the past. To achieve this we condition the generation
of output trajectories by initializing the hidden state of the
decoder as:
i = γ(Pi, ht
where γ(·) is a multi-layer perceptron (MLP) with ReLU
non-linearity and Wc is the embedding weight. We deviate
from prior work in two important ways regarding trajectory
prediction:
• Prior work uses the hidden state to predict parameters of a bivariate Gaussian distribution. However, this introduces difﬁculty in the training process
as backpropagation through sampling process in nondifferentiable. We avoid this by directly predicting the
coordinates (ˆxt
• “Social” context is generally provided as input to the
LSTM cell . Instead we provide the pooled
context only once as input to the decoder. This also
provides us with the ability to choose to pool at speciﬁc time steps and results in 16x speed increase as
compared to S-LSTM (see Table 2).
After initializing the decoder states as described above we
can obtain predictions as follows:
i = φ(xt−1
Pi = PM(ht−1
d1 , ..., ht
di = LSTM(γ(Pi, ht−1
i; Wdecoder)
where φ(·) is an embedding function with ReLU nonlinearity with Wed as the embedding weights. The LSTM
weights are denoted by Wdecoder and γ is an MLP.
Discriminator. The discriminator consists of a separate
encoder. Speciﬁcally, it takes as input Treal = [Xi, Yi] or
Tfake = [Xi, ˆYi] and classiﬁes them as real/fake. We apply
a MLP on the encoder’s last hidden state to obtain a classiﬁcation score. The discriminator will ideally learn subtle
social interaction rules and classify trajectories which are
not socially acceptable as “fake”.
Losses. In addition to adversarial loss, we also apply L2
loss on the predicted trajectory which measures how far the
generated samples are from the actual ground truth.
3.4. Pooling Module
In order to jointly reason across multiple people we need
a mechanism to share information across LSTMs. However,
there are several challenges which a method should address:
• Variable and (potentially) large number of people in a
scene. We need a compact representation which combines information from all the people.
• Scattered Human-Human Interaction. Local information is not always sufﬁcient.
Far-away pedestrians
might impact each others. Hence, the network needs
to model global conﬁguration.
Figure 3: Comparison between our pooling mechanism (red
dotted arrows) and Social Pooling (red dashed grid) for
the red person. Our method computes relative positions between the red and all other people; these positions are concatenated with each person’s hidden state, processed independently by an MLP, then pooled elementwise to compute
red person’s pooling vector P1. Social pooling only considers people inside the grid, and cannot model interactions
between all pairs of people.
Social Pooling addresses the ﬁrst issue by proposing
a grid based pooling scheme. However, this hand-crafted
solution is slow and fails to capture global context. Qi et al.
 show that above properties can be achieved by applying a learned symmetric function on transformed elements
of the input set of points. As shown in Figure 2 this can be
achieved by passing the input coordinates through a MLP
followed by a symmetric function (we use Max-Pooling).
The pooled vector Pi needs to summarize all the information a person needs to make a decision. Since, we use relative coordinates for translation invariance we augment the
input to the pooling module with relative position of each
person with respect to person i.
3.5. Encouraging Diverse Sample Generation
Trajectory prediction is challenging as given limited past
history a model has to reason about multiple possible outcomes. The method described so far produces good predictions, but these predictions try to produce the “average”
prediction in cases where there can be multiple outputs.
Further, we found that outputs were not very sensitive to
changes in noise and produced very similar predictions.
We propose a variety loss function that encourages the
network to produce diverse samples. For each scene we
generate k possible output predictions by randomly sampling z from N(0, 1) and choosing the “best” prediction in
L2 sense as our prediction.
Lvariety = min
k ∥Yi −ˆY (k)
where k is a hyperparameter.
By considering only the best trajectory, this loss encourages the network to hedge its bets and cover the space of
outputs that conform to the past trajectory. The loss is structurally akin to Minimum over N (MoN) loss but to the
SGAN (Ours)
0.84 / 1.33
0.70 / 1.09
0.73 / 1.09
0.79 / 1.13
0.75 / 1.03
0.61 / 0.81
0.60 / 0.87
0.35 / 0.39
0.55 / 0.86
0.49 / 0.79
0.71 / 1.01
0.63 / 0.90
0.48 / 0.72
0.52 / 0.67
0.56 / 0.82
0.36 / 0.61
0.41 / 0.67
0.37 / 0.60
0.36 / 0.58
0.36 / 0.60
0.44 / 0.76
0.41 / 0.62
0.25 / 0.41
0.27 / 0.47
0.25 / 0.42
0.23 / 0.38
0.21 / 0.34
0.22 / 0.35
0.53 / 0.77
0.31 / 0.52
0.33 / 0.56
0.32 / 0.52
0.29 / 0.47
0.27 / 0.42
0.29 / 0.42
0.54 / 0.79
0.43 / 0.70
0.45 / 0.72
0.49 / 0.74
0.45 / 0.67
0.39 / 0.58
0.41 / 0.61
1.60 / 2.94
1.45 / 2.41
1.48 / 2.35
1.61 / 2.21
1.52 / 2.02
1.22 / 1.52
1.19 / 1.62
0.60 / 0.72
1.17 / 1.91
1.01 / 1.76
1.44 / 2.18
1.32 / 1.97
0.95 / 1.61
1.02 / 1.37
1.01 / 1.59
0.77 / 1.31
0.84 / 1.40
0.75 / 1.28
0.73 / 1.22
0.75 / 1.26
0.84 / 1.52
0.74 / 1.21
0.53 / 0.88
0.56 / 1.00
0.53 / 0.91
0.48 / 0.84
0.42 / 0.69
0.43 / 0.68
0.95 / 1.48
0.65 / 1.11
0.70 / 1.17
0.66 / 1.11
0.61 / 1.01
0.54 / 0.84
0.58 / 0.84
0.98 / 1.59
0.91 / 1.52
0.91 / 1.54
1.00 / 1.54
0.93 / 1.41
0.78 / 1.18
0.81 / 1.21
Table 1: Quantitative results of all methods across datasets. We report two error metrics Average Displacement Error (ADE)
and Final Displacement Error (FDE) for tpred = 8 and tpred = 12 (8 / 12) in meters. Our method consistently outperforms
state-of-the-art S-LSTM method and is especially good for long term predictions (lower is better).
best of our knowledge this has not been used in the context
of GANs to encourage diversity of generated samples.
3.6. Implementation Details
We use LSTM as the RNN in our model for both decoder
and encoder. The dimensions of the hidden state for encoder
is 16 and decoder is 32. We embed the input coordinates as
16 dimensional vectors. We iteratively train the Generator
and Discriminator with a batch size of 64 for 200 epochs
using Adam with an initial learning rate of 0.001.
4. Experiments
In this section, we evaluate our method on two publicly
available datasets: ETH and UCY . These datasets
consist of real world human trajectories with rich humanhuman interaction scenarios. We convert all the data to real
world coordinates and interpolate to obtain values at every
0.4 seconds. In total there are 5 sets of data (ETH - 2, UCY-
3) with 4 different scenes which consists of 1536 pedestrians in crowded settings with challenging scenarios like
group behavior, people crossing each other, collision avoidance and groups forming and dispersing.
Evaluation Metrics. Similar to prior work we
use two error metrics:
1. Average Displacement Error (ADE): Average L2 distance between ground truth and our prediction over all
predicted time steps.
2. Final Displacement Error (FDE): The distance between
the predicted ﬁnal destination and the true ﬁnal destination at end of the prediction period Tpred.
Baselines: We compare against the following baselines:
1. Linear: A linear regressor that estimates linear parameters by minimizing the least square error.
2. LSTM: A simple LSTM with no pooling mechanism.
3. S-LSTM: The method proposed by Alahi et al. . Each
person is modeled via an LSTM with the hidden states
being pooled at each time step using the social pooling
We also do an ablation study of our model with different
control settings. We refer our full method in the section as
SGAN-kVP-N where kV signiﬁes if the model was trained
using variety loss (k = 1 essentially means no variety loss)
and P signiﬁes usage of our proposed pooling module. At
test time we sample multiple times from the model and
chose the best prediction in L2 sense for quantitative evaluation. N refers to the number of time we sample from our
model during test time.
Evaluation Methodology. We follow similar evaluation
methodology as . We use leave-one-out approach, train
on 4 sets and test on the remaining set. We observe the trajectory for 8 times steps (3.2 seconds) and show prediction
results for 8 (3.2 seconds) and 12 (4.8 seconds) time steps.
4.1. Quantitative Evaluation
We compare our method on two metrics ADE and FDE
against different baselines in Table 1. As expected Linear
model is only capable of modeling straight paths and does
especially bad in case of longer predictions (tpred = 12).
Both LSTM and S-LSTM perform much better than the linear baseline as they can model more complex trajectories.
However, in our experiments S-LSTM does not outperform
LSTM. We tried our best to reproduce the results of the pa-
Num Samples (N)
Figure 4: Effect of variety loss. For SGAN-1V-N we train a single model, drawing one sample for each sequence during
training and N samples during testing. For SGAN-NV-N we train several models with our variety loss, using N samples
during both training and testing. Training with the variety loss signiﬁcantly improves accuracy.
per. trained the model on synthetic dataset and then ﬁnetuned on real datasets. We don’t use synthetic data to train
any of our models which could potentially lead to worse
performance.
SGAN-1V-1 performs worse than LSTM as each predicted sample can be any of the multiple possible future
trajectories. The conditional output generated by the model
represents one of many plausible future predictions which
might be different from ground truth prediction. When we
consider multiple samples our model outperforms the baseline methods conﬁrming the multi-modal nature of the problem. GANs face mode collapse problem, where the generator resorts to generating a handful of samples which are
assigned high probability by the discriminator. We found
that samples generated by SGAN-1V-1 didn’t capture all
possible scenarios. However, SGAN-20V-20 signiﬁcantly
outperforms all other models as the variety loss encourages
the network to produce diverse samples. Although our full
model with proposed pooling layer performs slightly worse
we show in the next section that pooling layer helps the
model predict more “socially” plausible paths.
Speed. Speed is crucial for a method to be used in a realworld setting like autonomous vehicles where you need accurate predictions about pedestrian behavior. We compare
our method with two baselines LSTM and S-LSTM. A simple LSTM performs the fastest but can’t avoid collisions or
make accurate multi-modal predictions. Our method is 16x
faster than S-LSTM (see Table 2). Speed improvement is
because we don’t do pooling at each time step. Also, unlike
S-LSTM which requires computing a occupancy grid for
each pedestrian our pooling mechanism is a simple MLP
followed by max pooling. In real-world applications our
model can quickly generate 20 samples in the same time it
takes S-LSTM to make 1 prediction.
Evaluating Effect of Diversity. One might wonder what
will happen if we simply draw more samples from our
model without the variety loss? We compare the performance of SGAN-1V-N with SGAN-NV-N. As a reminder
Table 2: Speed (in seconds) comparison with S-LSTM. We
get 16x speedup as compared to S-LSTM allowing us to
draw 16 samples in the same time S-LSTM makes a single
prediction. Unlike S-LSTM we don’t perform pooling at
each time step resulting in signiﬁcant speed bump without
suffering on accuracy. All methods are benchmarked on
Tesla P100 GPU
SGAN-NV-N refers to a model trained with variety loss
with k = N and drawing N samples during testing. As
shown in Figure 4 across all datasets simply drawing more
samples from the model trained without variety loss does
not lead to better accuracy. Instead, we see a signiﬁcant
performance increase as we increase k with models on average performing 33% better with k = 100 .
4.2. Qualitative Evaluation
In multi-agent (people) scenarios, it is imperative to
model how actions of one person can inﬂuence the actions
of other people. Traditional approaches for activity forecasting and human trajectory prediction have focused on
hand crafted energy potentials modeling attractive and repulsive forces to model these complex interactions. We use
a purely data driven approach which models human-human
interaction via a novel pooling mechanism. Humans walking in the presence of other people plan their path taking
into account their personal space, perceived potential for
collision, ﬁnal destination and their own past motion. In
this section, we ﬁrst evaluate the effect of the pooling layer
and then analyze the predictions made by our network in
three common social interaction scenarios. Even though our
model makes joint predictions for all people in a scene we
show predictions for a subset for simplicity. We refer to
Figure 5: Comparison between our model without pooling (SGAN, top) and with pooling (SGAN-P, bottom) in four collision
avoidance scenarios: two people meeting (1), one person meeting a group (2), one person behind another (3), and two people
meeting at an angle (4). For each example we draw 300 samples from the model and visualize their density and mean. Due
to pooling, SGAN-P predicts socially acceptable trajectories which avoid collisions.
each person in the scene by the ﬁrst letter of the color in the
ﬁgure (e.g., Person B (Black), Person R (Red) and so on).
Also for simplicity we refer SGAN-20VP-20 as SGAN-P
and SGAN-20V-20 as SGAN.
Pooling Vs No-Pooling
On quantitative metrics both methods perform similarly
with SGAN slightly outperforming SGAN-P (see Table
1. However, qualitatively we ﬁnd that pooling enforces a
global coherency and conformity to social norms. We compare how SGAN and SGAN-P perform in four common social interaction scenarios (see Figure 5). We would like to
highlight that even though these scenarios were created synthetically, we used models trained on real world data. Moreover, these scenarios were created to evaluate the models
and nothing in our design makes these scenarios particularly easy or hard. For each setup we draw 300 samples and
plot an approximate distribution of trajectories along with
average trajectory prediction.
Scenario 1 and 2 depict the collision avoidance capacity
of our model by changing direction. In the case of two people heading in the same direction pooling enables the model
to predict a socially accepted way of yielding the right of
way towards the right. However, SGAN prediction leads
to a collision. Similarly, unlike SGAN, SGAN-P is able to
model group behavior and predict avoidance while preserving the notion of couple walking together (Scenario 2).
Humans also tend to vary pace to avoid collisions. Scenario 3 is depicts a person G walking behind person B albeit
faster. If they both continue to maintain their pace and direction they would collide. Our model predicts person G
overtaking from the right. SGAN fails to predict a socially
acceptable path. In Scenario 4, we notice that the model
predicts person B slowing down and yielding for person G.
Pooling in Action
We consider three real-scenarios where people have to alter
their course to avoid collision (see Figure 6).
People Merging. (Row 1) In hallways or in roads it
is common for people coming from different directions to
merge and walk towards a common destination. People use
various ways to avoid colliding while continuing towards
their destination. For instance a person might slow down,
alter their course slightly or use a combination of both depending on the context and behavior of other surrounding
people. Our model is able predict variation in both speed
and direction of a person to effectively navigate a situation.
For instance model predicts that either person B slows down
(col 2) or both person B and R change direction to avoid collision. The last prediction (col 4) is particularly interesting
as the model predicts a sudden turn for person R but also
predicts that person B signiﬁcantly slows down in response;
thus making a globally consistent prediction.
Group Avoiding. (Row 2) People avoiding each other
when moving in opposite direction is another common scenario.
This can manifest in various forms like a person
avoiding a couple, a couple avoiding a couple etc.
make correct predictions in such cases a person needs to
plan ahead and look beyond it’s immediate neighborhood.
Our model is able to recognize that the people are moving
in groups and model group behavior. The model predicts
change of direction for either groups as a way of avoiding
collision (col 3, 4). In contrast to Figure 5 even though the
convention might be to give way to the right in this particular situation that would lead to a collision. Hence, our
models makes prediction where couples give way towards
Person Following. (Row 3) Another common scenario
is when a person is walking behind someone. One might
want to either maintain pace or maybe overtake the person
Figure 6: Examples of diverse predictions from our model. Each row shows a different set of observed trajectories; columns
show four different samples from our model for each scenario which demonstrate different types of socially acceptable
behavior. BEST is the sample closest to the ground-truth; in SLOW and FAST samples, people change speed to avoid
collision; in DIR samples people change direction to avoid each other. Our model learns these different avoidance strategies
in a data-driven manner, and jointly predicts globally consistent and socially acceptable trajectories for all people in the scene.
We also show some failure cases in supplementary material.
in front. We would like to draw attention to a subtle difference between this situation and its real-life counterpart.
In reality a person’s decision making ability is restricted
by their ﬁeld of view. In contrast, our model has access
to ground truth positions of all the people involved in the
scene at the time of pooling. This manifests in some interesting cases (see col 3). The model understands that person
R is behind person B and is moving faster. Consequently,
it predicts that person B gives way by changing their direction and person R maintains their direction and speed.
The model is also able to predict overtaking (matching the
ground truth).
4.3. Structure in Latent Space
In this experiment we attempt to understand the landscape of the latent space z. Walking on the manifold that
is learnt can give us insights about how the model is able
to generate diverse samples. Ideally, one can expect that
the network imposes some structure in the latent space. We
found that certain directions in the latent space were associated with direction and speed (Figure 7).
5. Conclusion
In this work we tackle the problem of modeling humanhuman interaction and jointly predicting trajectories for all
people in a scene. We propose a novel GAN based encoderdecoder framework for trajectory prediction capturing the
multi-modality of the future prediction problem. We also
Figure 7: Latent Space Exploration. Certain directions in
the latent manifold are associated with direction (left) and
speed (right). Observing the same past but varying the input z along different directions causes the model to predict
trajectories going either right/left or fast/slow on average.
propose a novel pooling mechanism enabling the network
to learn social norms in a purely data-driven approach. To
encourage diversity among predicted samples we propose
a simple variety loss which coupled with the pooling layer
encourages the network to produce globally coherent, socially compliant diverse samples. We show the efﬁcacy of
our method on several complicated real-life scenarios where
social norms must be followed.
6. Acknowledgment
suggestions.