Bayesian Methods in Cosmology
Roberto Trotta
Abstract These notes aim at presenting an overview of Bayesian statistics, the underlying concepts and application methodology that will be useful to astronomers
seeking to analyse and interpret a wide variety of data about the Universe. The level
starts from elementary notions, without assuming any previous knowledge of statistical methods, and then progresses to more advanced, research-level topics. After an
introduction to the importance of statistical inference for the physical sciences, elementary notions of probability theory and inference are introduced and explained.
Bayesian methods are then presented, starting from the meaning of Bayes Theorem and its use as inferential engine, including a discussion on priors and posterior
distributions. Numerical methods for generating samples from arbitrary posteriors
(including Markov Chain Monte Carlo and Nested Sampling) are then covered. The
last section deals with the topic of Bayesian model selection and how it is used to
assess the performance of models, and contrasts it with the classical p-value approach. A series of exercises of various levels of difﬁculty are designed to further
the understanding of the theoretical material, including fully worked out solutions
for most of them.
Roberto Trotta
Imperial College London, Imperial Centre for Inference and Cosmology & Data Science Institute,
Blackett Laboratory, Prince Consort Road, London SW7 2AZ
www.robertotrotta.com
 
Bayesian Methods in Cosmology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Roberto Trotta
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Elementary notions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
The notion of probability . . . . . . . . . . . . . . . . . . . . . . . . . . .
Random variables, parent distributions and samples . . . . .
The Central Limit Theorem . . . . . . . . . . . . . . . . . . . . . . . . .
The likelihood function. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
The Maximum Likelihood Principle . . . . . . . . . . . . . . . . . . 10
Conﬁdence intervals (frequentist) . . . . . . . . . . . . . . . . . . . . 13
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
Solutions to exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
Bayesian parameter inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
Bayes theorem as an inference device . . . . . . . . . . . . . . . . . 25
Advantages of the Bayesian approach. . . . . . . . . . . . . . . . . 27
Considerations and caveats on priors . . . . . . . . . . . . . . . . . 29
A general Bayesian solution to inference problems. . . . . . 32
The Gaussian linear model . . . . . . . . . . . . . . . . . . . . . . . . . . 33
Markov Chain Monte Carlo methods . . . . . . . . . . . . . . . . . 35
Practical and numerical issues . . . . . . . . . . . . . . . . . . . . . . . 40
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
Solutions to selected exercises . . . . . . . . . . . . . . . . . . . . . . . 49
Bayesian model selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
The three levels of inference . . . . . . . . . . . . . . . . . . . . . . . . 55
The Bayesian evidence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
Computation of the evidence . . . . . . . . . . . . . . . . . . . . . . . . 61
Example: model selection for the inﬂationary landscape . 65
Open challenges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
Solutions to selected exercises . . . . . . . . . . . . . . . . . . . . . . . 70
Appendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
Bayesian Methods
Introductory and background material . . . . . . . . . . . . . . . . . . . . . . . . 73
The uniform, binomial and Poisson distributions . . . . . . . 73
Expectation value and variance . . . . . . . . . . . . . . . . . . . . . . 76
The exponential distribution. . . . . . . . . . . . . . . . . . . . . . . . . 79
The Gaussian (or Normal) distribution . . . . . . . . . . . . . . . . 80
The Chi-Square distribution . . . . . . . . . . . . . . . . . . . . . . . . . 83
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
1 Introduction
The purpose of physics is to learn about regularities in the natural phenomena in
the world, which we call “Laws of Physics”. Theoretical models expressed in mathematical form (e.g., Newton’s theory of gravitation) have to be validated through
experiments or observations of the phenomena they aim to describe (e.g., measurement of the time it takes for an apple to fall). Thus an essential part of physics is
the quantitative comparison of its theories (i.e., models, equations, predictions) with
observations (i.e., data, measurements). This leads to conﬁrm theories or to refute
Measurements often have uncertainties associated with them. Those could originate in the noise of the measurement instrument, or in the random nature of the
process being observed, or in selection effects. Statistics is the tool by which we
can extract information about physical quantities from noisy, uncertain and/or incomplete data. Uncertainties however are more general than that. There might be
uncertainty in the relationship between quantities in a model (as a consequence of
limited information or true intrinsic variability of the objects being studied); uncertainty in the completeness of the model itself; and uncertainty due to unmodelled
systematics (to name but a few).
The purpose of these lectures is to provide an appreciation of the fundamental
principles underpinning statistical inference, i.e., the process by which we reconstruct quantities of interest from data, subject to the various sources of uncertainty
above. The lectures will also endeavour to provide the conceptual, analytical and
numerical tools required to approach and solve some of the most common inference
problems in the physical sciences, and in particular in cosmology. References are
provided so that the reader can further their understanding of the more advanced
topics, at research level and beyond.
Probability theory, as a branch of mathematics, is concerned with studying the
properties of sampling distributions, i.e., probability distributions that describe the
relative frequency of occurrence of random phenomena. In this sense, probability
theory is “forward statistics”: given the properties of the underlying distributions, it
predicts the outcome of data drawn from such distributions.
Statistical inference, by contrast, asks the question of what can be learnt about
the underlying distributions from the observed data. It therefore is sometimes called
Bayesian Methods
“inverse probability”, in that it seeks to reconstruct the parameters of the distributions out of which the data are believed to have been generated.
Statistics addresses several relevant questions for physicists:
(i) How can we learn about regularities in the physical world given that any measurement is subject to a degree of randomness?
(ii) How do we quantify our uncertainty about observed properties in the world?
(iii) How can we make predictions about the future from past experience and theoretical models?.
Inference and statistics are today at the heart of the scientiﬁc process, not merely
an optional nuisance. Ernest Rutherford is reported to have said, over a century ago:
“If you need statistics, you did the wrong experiment”. While this might have had
some merit at the time, it completely misses the point of what science has become
today. All scientiﬁc questions at the forefront of research involve increasingly complicated models that try to explain subtle effects in complex, multidimensional data
sets. The sheer amount of data available to astrophysicists and cosmologists has
increased by orders of magnitudes in the last 20 years. Correspondingly, the sophistication of our statistical analysis tools has to keep up: increasingly, the limiting
factor of our knowledge about the Universe is not the amount of data we have, but
rather our ability of analyse, interpret and make sense of them.
To paraphrase Rutherford, in 21st Century astrophysics f you do not need statistics, it’s because you are doing the wrong kind of physics! There are (at least) ﬁve
good reasons why every professional astrophysicist and cosmologist ought to have
a solid training in advanced statistical methods:
(i) The complexity of the modelling of both our theories and observations will always increase, thus requiring correspondingly more reﬁned statistical and data
analysis skills. In fact, the scientiﬁc return of the next generation of surveys will
be limited by the level of sophistication and efﬁciency of our inference tools.
(ii) The discovery zone for new physics is when a potentially new effect is seen
at the 2–3σ level, i.e., with a nominal statistical signiﬁcance somewhere in the
region of 95% to 99.7%. This is when tantalizing suggestions for an effect start
to accumulate but there is no ﬁrm evidence yet. In this potential discovery region
a careful application of statistics can make the difference between claiming or
missing a new discovery.
(iii) If you are a theoretician, you do not want to waste your time trying to explain an
effect that is not there in the ﬁrst place. A better appreciation of the interpretation
of statistical statements might help in identifying robust claims from spurious
(iv) Limited resources mean that we need to focus our efforts on the most promising
avenues. Experiment forecast and optimization will increasingly become prominent as we need to use all of our current knowledge (and the associated uncertainty) to identify the observations and strategies that are likely to give the highest
scientiﬁc return in a given ﬁeld.
(v) Sometimes we don’t have the luxury to be able to gather better or further data.
This is the case for the many problems associated with cosmic variance limited
Bayesian Methods
measurements on large scales, for example in the cosmic background radiation,
where the small number of independent directions on the sky makes it impossible
to reduce the error below a certain ﬂoor.
2 Elementary notions
2.1 The notion of probability
There are two different ways of understanding what probability is. The classical
(so-called “frequentist”) notion of probability is that probabilities are tied to the
frequency of outcomes over a long series of trials. Repeatability of an experiment is
the key concept.
The Bayesian outlook1 is that probability expresses a degree of belief in a proposition, based on the available knowledge of the experimenter. Information is the key
concept. Bayesian probability theory is more general than frequentist theory, as the
former can deal with unique situations that the latter cannot handle (e.g., “what is
the probability that it will rain tomorrow?).
Let A,B,C,... denote propositions (e.g., that a coin toss gives tails). Let Ωdescribe the sample space (or state space) of the experiment, i.e., Ωis a list of all the
possible outcomes of the experiment.
Example 1. If we are tossing a coin, Ω= {T,H}, where T denotes “tails” and H
denotes “head”. If we are rolling a regular die, Ω= {1,2,3,4,5,6}. If we are drawing one ball from an urn containing white and black balls, Ω= {W,B}, where W
denotes a white ball and B a black ball.
Frequentist deﬁnition of probability: The number of times an event occurs
divided by the total number of events in the limit of an inﬁnite series of
equiprobable trials.
Deﬁnition 1. The joint probability of A and B is the probability of A and B happening together, and is denoted by P(A,B). The conditional probability of A given B is
the probability of A happening given that B has happened, and is denoted by P(A|B).
The sum rule:
P(A)+P(A) = 1,
where A denotes the proposition “not A”.
The product rule:
1 So-called after Rev. Thomas Bayes (1701(?)–1761), who was the ﬁrst to introduce this idea in
a paper published posthumously in 1763, “An essay towards solving a problem in the doctrine of
chances” .
Bayesian Methods
P(A,B) = P(A|B)P(B).
By inverting the order of A and B we obtain that
P(B,A) = P(B|A)P(A)
and because P(A,B) = P(B,A), we obtain Bayes theorem by equating Eqs. (2) and
P(A|B) = P(B|A)P(A)
The marginalisation rule follows from the two rules above and it reads:
P(A) = P(A,B1)+P(A,B2)+··· = ∑
P(A,Bi) = ∑
P(A|Bi)P(Bi),
where the sum is over all possible outcomes for proposition B.
Deﬁnition 2. Two propositions (or events) are said to be independent if and only if
P(A,B) = P(A)P(B).
2.2 Random variables, parent distributions and samples
Deﬁnition 3. A random variable (RV) is a function mapping the sample space Ωof
possible outcomes of a random process to the space of real numbers.
Example 2. When tossing a coin once, the RV X can be deﬁned as
if coin lands T
if coin lands H.
When rolling a regular, 6-sided die, the RV X can be deﬁned as
if a 1 is rolled
if a 2 is rolled
if a 3 is rolled
if a 4 is rolled
if a 5 is rolled
if a 6 is rolled.
When drawing one ball from an urn containing black and white balls, the RV X can
be deﬁned as
if the ball drawn is white
if the ball drawn is black.
Bayesian Methods
A RV can be discrete (only a countable number of outcomes is possible, such
as in coin tossing) or continuous (an uncountable number of outcomes is possible,
such as in a temperature measurement). It is mathematically subtle to carry out
the passage from a discrete to a continuous RV, although as physicists we won’t
bother too much with mathematical rigour here. Heuristically, we simply replace
summation sums over discrete variables with integrals over continuous variables.
Deﬁnition 4. Each RV has an associated probability distribution to it. The probability distribution of a discrete RV is called probability mass function (pmf), which
gives the probability of each outcome: P(X = xi) = Pi gives the probability of the
RV X assuming the value xi. In the following we shall use the shorthand notation
P(xi) to mean P(X = xi).
Example 3. If X is the RV of Eq. (8), and the die being tossed is fair, then Pi = 1/6
for i = 1,...,6, where xi is the outcome “a the face with i pips comes up”.
The probability distribution associated with a continuous RV is called the probability density function (pdf), denoted by p(X). The quantity p(x)dx gives the probabilty that the RV X assumes the value between x and x+dx.
The choice of probability distribution to associate to a given random process is
dictated by the nature of the random process one is investigating (a few examples
are given below).
For a discrete pmf, the cumulative probability distribution function (cdf) is given
The cdf gives the probabilty that the RV X takes on a value less than or equal to xi,
i.e. C(xi) = P(X ≤xi).
For a continuous pdf, the cdf is given by
with the same interpretation as above, i.e. it is the probability that the RV X takes a
value smaller than x.
When we make a measurement, (e.g., the temperature of an object, or we toss a
coin and observe which face comes up), nature selects an outcome from the sample
space with probability given by the associated pmf or pdf. The selection of the
outcome is such that if the measurement was repeated an inﬁnite number of times the
relative frequency of each outcome is the same as the the probability associated with
each outcome under the pmf or pdf. This is another formulation of the frequentist
deﬁnition of probability given above.
Outcomes of measurements realized by nature are called samples2. They are a series of real (or integer) numbers, {ˆx1, ˆx2,..., ˆxN}. In this notes, I will denote samples
(i.e., measured values) with a hat symbol, ˆ.
2 The probability theory notion of sample encountered here is not to be confused with the idea of
MCMC (posterior) samples, which we will introduce later in section 3.6.
Bayesian Methods
Deﬁnitions and background material on some of the most important and most
commonly-encountered sampling distributions (the uniform, Poisson, Binomial, exponential and Gaussian distributions) are given in Appendix 4.7.
2.3 The Central Limit Theorem
The Central Limit Theorem (CLT) is a very important result justifying why the
Gaussian distribution is ubiquitous.
Theorem 1. Simple formulation of the CLT: Let X1,X2,...,XN be a collection of
independent RV with ﬁnite expectation value µ and ﬁnite variance σ2. Then, for
N →∞, thir sum is Gaussian distributed with mean Nµ and variance Nσ2.
Note: it does not matter what the detailed shape of the underlying pdf for the
individual RVs is!
Consequence: whenever a RV arises as the sum of several independent effects
(e.g., noise in a temperature measurement), we can be conﬁdent that it will be very
nearly Gaussian distributed.
Theorem 2. More rigorous (and more general) formulation of the CLT: Let X1,X2,...,XN
be a collection of independent RV, each with ﬁnite expectation value µi and ﬁnite
variance σ2
i . Then the variable
i=1 Xi −∑N
is distributed as a Gaussian with expectation value 0 and unit variance.
2.4 The likelihood function
The problem of inference can be stated as follows: given a collection of samples,
{ˆx1, ˆx2,..., ˆxN}, and a generating random process, what can be said about the properties of the underlying probability distribution?
Example 4. You toss a coin 5 times and obtain 1 head. What can be said about the
fairness of the coin?
Example 5. With a photon counter you observe 10 photons in a minute. What can
be said about the average photon rate from the source?
Example 6. You measure the temperature of an object twice with two different instruments, yielding the following measurements: T = 256±10 K and T = 260±5
K. What can be said about the temperature of the object?
Bayesian Methods
Schematically, we have that:
pdf - e.g., Gaussian with a given (µ,σ) →Probability of observation
Underlying (µ,σ) ←Observed events
The connection between the two domains is given by the likelihood function.
Deﬁnition 5. Given a pdf or a pmf p(X|θ), where X represents a random variable
and θ a collection of parameters describing the shape of the pdf3 and the observed
data ˆx = {ˆx1, ˆx2,..., ˆxN}, the likelihood function L (or “likelihood” for short) is
L (θ) = p(X = ˆx|θ).
On the right-hand side of the above equation, the probability (density) of observing
the data that have been obtained (X = ˆx) is considered as a function of the parameters θ. A very important – and often misunderstood! – point is that the likelihood is
not a pdf in θ. This is why it’s called likelihood function! It is normalised over X,
but not over θ.
Example 7. In tossing a coin, let θ be the probability of obtaining heads in one
throw. Suppose we make N = 5 ﬂips and obtain the sequence ˆx = {H,T,T,T,T}.
The likelihood is obtained by taking the binomial, Eq. (199), and replacing for r the
number of heads obtained (r = 1) in N = 5 trials, and looking at it as a function of
the parameter we are interested in determining, here θ. Thus
θ 1(1−θ)4 = 5θ(1−θ)4,
which is plotted as a function of θ in Fig. 1.
If instead of r = 1 heads we had obtained a different number of heads in our
N = 5 trials, the likelihood function would have looked as shown in Fig. 2 for a few
different choices for r.
This example leads to the formulation of the Maximum Likelihood Principle:
if we are trying to determine the value of θ given what we have observed (e.g.,
the sequence of H/T in coin tossing), we should choose the value that maximises
the likelihood, because this maximises the probability of obtaining the data that we
got. Notice that this is not necessarily the same as maximising the probability of θ.
Doing so requires the use of Bayes theorem, see section 3.
3 For example, for a Gaussian θ = {µ,σ}, for a Poisson distribution, θ = λ and for a binomial
distribution, θ = p, the probability of success in one trial.
Bayesian Methods
Fig. 1 The likelihood function for the probability of heads (θ) for the coin tossing example, with
N = 5,r = 1.
Fig. 2 The likelihood function for the probability of heads (θ) for the coin tossing example, with
n = 5 trials and different values of r.
2.5 The Maximum Likelihood Principle
The Maximum Likelihood Principle (MLP): given the likelihood function L (θ)
and seeking to determine the parameter θ, we should choose the value of θ in such
a way that the value of the likelihood is maximised.
Deﬁnition 6. The Maximum Likelihood Estimator (MLE) for θ is
Bayesian Methods
It can be shown that the MLE as deﬁned above has the following properties: it
is asymptotically unbiased (i.e., θML →θ for N →∞, i.e., the ML estimate converges to the true value of the parameters for inﬁnitely many data points) and it is
asymptotically the minimum variance estimator, i.e. the one with the smallest errors.
To ﬁnd the MLE, we maximise the likelihood by requiring its ﬁrst derivative to
be zero and the second derivative to be negative:
In practice, it is often more convenient to maximise the logarithm of the likelihood
(the “log-likelihood”) instead. Since log is a monotonic function, maximising the
likelihood is the same as maximising the log-likelihood. So one often uses
∂2 lnL (θ)
Example 8. MLE of the mean of a Gaussian. Imagine we have N independent measurements of a Gaussian-distributed quantity, and let’s denote them by {ˆx1, ˆx2,..., ˆxN}.
Here the parameters we are interested in determining are µ (the mean of the
distribution) and σ (the standard deviation of the distribution), hence we write
θ = {µ,σ}.Then the joint likelihood function is given by
L (µ,σ) = p(ˆx|µ,σ) =
Often, the expression above is written as
L = L0 exp
where the so-called “chi-squared” is deﬁned as
We want to estimate the (true) mean of the Gaussian. The MLE for the mean is
obtained by solving
= 0 ⇒µML = 1
i.e., the MLE for the mean is just the sample mean (i.e., the average of the measurements).
Example 9. MLE of the standard deviation of a Gaussian. If we want to estimate the
standard deviation σ of the Gaussian, the MLE for σ is:
Bayesian Methods
(ˆxi −µ)2.
However, the MLE above is “biased”, i.e. it can be shown that
where E(˙) denotes the expectation value. I.e., for ﬁnite N the expectation value of
the ML estimator is not the same as the true value, σ2. In order to obtain an unbiased
estimator we replace the factor 1/N by 1/(N−1). Also, because the true µ is usually
unknown, we replace it in Eq. (23) by the MLE estimator for the mean, µML.
Therefore, the unbiased MLE estimator for the variance is
(ˆxi −µML)2.
In general, you should always use Eq. (25) as the ML estimator for the variance, and
not Eq. (23).
Example 10. MLE for the success probability of a binomial distribution. We go back
to the coin tossing example, but this time we solve it in all generality. Let’s deﬁne
“success” as “the coin lands heads” (H). Having observed H heads in a number
N of trials, the likelihood function of a binomial is given by Eq. (199), where the
unknown parameter is θ (the success probability for one trial, i.e., the probability
that the coin lands H):
L (θ) = P(H|θ,N) =
θ H(1−θ)N−H,
The Maximum Likelihood Estimator the success probability is found by maximising
the log likelihood:
+H lnθ +(N −H)ln(1−θ)
Thus the MLE is simpy given by the observed fraction of heads, which is intuitively
Example 11. MLE for the rate of a Poisson distribution. The likelihood function is
given by Eq. (201), using the notation θ = λ (i.e., the parameter θ we are interested
in is here the rate λ):
L (λ) = P(n|λ) = (λt)n
Bayesian Methods
The unknown parameter is the rate λ, while the data are the observed counts, n,
in the amount of time t. The Maximum Likelihood Estimate for λ is obtained by
ﬁnding the maximum of the log likelihood as a function of the parameter (here, the
rate λ). Hence we need to ﬁnd the value of λ such that:
The derivative gives
∂λ (nln(λt)−lnn!−λt) = n t
λt −t = 0 ⇔λMLE = n
So the maximum likelihood estimator for the rate is the observed average number
of counts.
We can thus summarise the MLE recipe:
(i) Write down the likelihood. This depends on the kind of random process you are
considering. Identify what is the parameter that you are interested in, θ.
(ii) Find the “best ﬁt” value of the parameter of interest by maximising the likelihood
L as a function of θ. This is your MLE, θML.
(iii) Evaluate the uncertainty on θML, i.e. compute the conﬁdence interval (see next
2.6 Conﬁdence intervals (frequentist)
Consider a general likelihood function, L (θ) and let us do a Taylor expansion of
the log-likelihood lnL around its maximum, given by θML:
lnL (θ) = lnL (θML)+ ∂lnL (θ)
(θ −θML)+ 1
∂2 lnL (θ)
(θ −θML)2+...
The second term on the RHS vanishes (by deﬁnition of the Maximum Likelihood
value), hence we can approximate the likelihood as
L (θ) ≈L (θML)exp
Σθ 2 = −∂2 lnL (θ)
A general likelihood function can be approximated to second order as a Gaussian
around the ML value, as shown by Eq. (32). Therefore, to the extent that this second
order Taylor expansion is sufﬁciently accurate, the uncertainty around the ML value,
Σθ, is approximately given by Eq. (33).
Bayesian Methods
Example 12. Let’s go back to the Gaussian problem of Eq. (19). We have seen in
Eq. (22) that the sample mean is the MLE for the mean of the Gaussian. We now
want to compute the uncertainty on this value. Applying Eq. (33) to the likelihood
of Eq. (19) we obtain
This means that the the uncertainty on our ML estimate for µ (as expressed by
the standard deviation Σµ) is proportional to 1/
N, with N being the number of
measurements.
As the likelihood function can be approximated as a Gaussian (at least around
the peak), we can use the results for a Gaussian distribution to approximate the
probability content of an interval around the ML estimate for the mean. The interval
[µmin,µmax] is called a 100α% conﬁdence interval for the mean µ if P(µmin < µ <
µmax) = α.
Example 13. For example, the interval [µML −Σµ < µ < µML +Σµ] is a 68.3% con-
ﬁdence interval for the mean (a so-called “1σ interval”), while [µML −2Σµ < µ <
µML +2Σµ] is a 95.4% conﬁdence interval (a “2σ interval”).
Example 14. In the temperature measurement example of Eq. (39), the 68.3% conﬁdence interval for the mean is 198.0K < µ < 201.2K. The 95.4% conﬁdence interval
is 196.4K < µ < 202.8K.
Generally, the value after the “±” sign will usually give the 1σ (i.e., 68.3%) region. Sometimes you might ﬁnd a notation like 50±1 (95% CL), where “CL” stands
for “Conﬁdence Level”. In this case, ±1 encompasses a region of 95% conﬁdence
(rather than 68.3%), which corresponds to 1.96 σ (see Table 4).
In the multi-dimensional case, additional parameters are eliminated from the likelihood by proﬁling over them, i.e., maximising over their value.
Deﬁnition 7. The proﬁle likelihood for the parameter θ1 (without loss of generality)
is deﬁned as
L (θ1) ≡max
where in our case L (θ) is the full likelihood function.
Thus in the proﬁle likelihood one maximises the value of the likelihood along
the hidden dimensions, rather than integrating it out as in the marginal posterior
(see Eq. (79) below).
The proﬁle likelihood can be directly interpreted as a if it were a genuine likelihood function, except that it does account for the effect of the hidden parameters.
Conﬁdence intervals from the proﬁle likelihood can be obtained via the likelihood ratio test as follows.
Classical conﬁdence intervals based on the Neyman construction are deﬁned as
the set of parameter points in which some real-valued function, or test statistic, t
evaluated on the data falls in an acceptance region Wθ = [t−,t+]. Likelihood ratios
are often chosen as the test statistic on which frequentist intervals are based. When
Bayesian Methods
θ is composed of parameters of interest, θ, and nuisance parameters, ψ, a common
choice of test statistic is the proﬁle likelihood ratio
λ(θ) ≡L (θ, ˆˆψ)
L ( ˆθ, ˆψ).
where ˆˆψ is the conditional maximum likelihood estimate (MLE) of ψ with θ ﬁxed
and ˆθ, ˆψ are the unconditional MLEs. Under certain regularity conditions4, Wilks
showed that the distribution of −2lnλ(θ) converges to a chi-square distribution
with a number of degrees of freedom given by the dimensionality of θ.
This leads to the following prescription. Starting from the best-ﬁt value in parameter space, an α% conﬁdence interval encloses all parameter values for which
minus twice the log–likelihood increases less than ∆χ2(α,n) from the best ﬁt value.
The threshold value depends on α and on the number n of parameters one is simultaneously considering (usually n = 1 or n = 2), and it is obtained by solving
n(x) is the chi–square distribution for n degrees of freedom, Eq. (235).
One has to be careful with the interpretation of conﬁdence intervals as this is
often misunderstood!
Interpretation: if we were to repeat an experiment many times, and each
time report the observed 100α% conﬁdence interval, we would be correct
100α% of the time. This means that (ideally) a 100α% conﬁdence intervals
contains the true value of the parameter 100α% of the time.
In a frequentist sense, it does not make sense to talk about “the probability of θ”.
This is because every time the experiment is performed we get a different realization
(different samples), hence a different numerical value for the conﬁdence interval.
Each time, either the true value of θ is inside the reported conﬁdence interval (in
which case, the probability of θ being inside is 1) or the true value is outside (in
which case its probability of being inside is 0). Conﬁdence intervals do not give the
probability of the parameter! In order to do that, you need Bayes theorem.
4 One important and often-overlooked condition for the validity of Wilks’ theorem is that the
parameter it is being applied to cannot lie at the boundary of the allowed parameter space. In this
case, one ought to employ Chernoff’s theorem instead . A modern discussion of the regularity
conditions necessary for the asymptotic distribution of the likelihood ratio test statistics to be valid
can be found in .
Bayesian Methods
2.7 Exercises
These exercises are designed to help you put into practice the above introductory
concepts. Please make sure you are familiar with these notions before moving on to
the next section. Exercises that are a little more challenging are denoted with a †.
(i) Gaussian 1D problem. The surface temperature on Mars is measured by a probe
10 times, yielding the following data (units of K):
191.9,201.6,206.1,200.4,203.2,201.6,196.5,199.5,194.1,202.4
a. Assume that each measurement is independently Normally distributed with
known variancee σ2 = 25 K2. What is the likelihood function for the whole
b. Find the Maximum Likelihood Estimate (MLE) for the surface temperature,
TML, and express your result to 4 signiﬁcant ﬁgures accuracy.
c. Determine symmetric conﬁdence intervals at 68.3%, 95.4% and 99% around
TML (4 signiﬁcant ﬁgures accuracy).
d. How many measurements would you need to make if you wanted to have a 1σ
conﬁdence interval around the mean of length less than 1 K (on each side)?
(ii) The surface temperature on Mars is measured by a probe 10 times, yielding the
following data (units of K):
197.2,202.4,201.8,198.8,207.6,191.4,201.4,198.2,195.7,201.2.
a. Assuming that each measurement is independently Gaussian distributed with
known variance σ2 = 25 K2, what is the likelihood function for the whole
b. What is the MLE of the mean, TML?
c. What is the uncertainty on our MLE for the mean?
(iii) A laser beam is used to measure the deviation of the distance between the Earth
and the Moon from its average value, giving the following data, in units of cm:
a. Assuming that each measurement above follows an independent Gaussian distribution of known standard deviation σ = 3 cm, write down the joint likelihood function for ∆, the deviation of the Earth-Moon distance from its average
b. Compute the maximum likelihood estimate for ∆and its uncertainty, both to
3 signiﬁcant ﬁgures.
c. How would you report the measurement of ∆(giving a 1-σ conﬁdence interval)?
(iv) You ﬂip a coin n = 10 times and you obtain 8 heads.
Bayesian Methods
a. What is the likelihood function for this measurement? Identify explicitly what
are the data and what is the free parameter you are trying to estimate.
b. What is the Maximum Likelihood Estimate for the probability of obtaining
heads in one ﬂip, p?
c. Approximate the likelihood function as a Gaussian around its peak and derive
the 1σ conﬁdence interval for p. How would you report your result for p?
d. With how many σ conﬁdence can you exclude the hypothesis that the coin is
fair? (Hint: compute the distance between the MLE for p and p = 1/2 and
express the result in number of σ).
e. You now ﬂip the coin 1000 times and obtain 800 heads. What is the MLE
for p now and what is the 1σ conﬁdence interval for p? With how many σ
conﬁdence can you exclude the hypothesis that the coin is fair now?
(v) An experiment counting particles emitted by a radioactive decay measures r particles per unit time interval. The counts are Poisson distributed.
a. If λ is the average number of counts per per unit time interval, write down the
appropriate probability distribution function for r.
b. Now we seek to determine λ by repeatedly measuring for M times the number
of counts per unit time interval. This series of measurements yields a sequence
of counts ˆr = {ˆr1, ˆr2, ˆr3, ..., ˆrM}. Each measurement is assumed to be independent. Derive the joint likelihood function for λ, L (λ) = P(ˆr|λ), given the
measured sequence of counts ˆr.
c. Use the Maximum Likelihood Principle applied to the the log likelihood
lnL (λ) to show that the Maximum Likelihood estimator for the average rate
λ is just the average of the measured counts, ˆr, i.e.
d. By considering the Taylor expansion of lnL (λ) to second order around λML,
derive the Gaussian approximation for the likelihood L (λ) around the Maximum Likelihood point, and show that it can be written as
L (λ) ≈L0 exp
where L0 is a normalization constant.
e. Compare with the equivalent expression for M Gaussian-distributed measurements to show that the variance σ2 of the Poisson distribution is given by
(vi) An astronomer measures the photon ﬂux from a distant star using a very sensitive instrument that counts single photons. After one minute of observation, the
instrument has collected ˆr photons. One can assume that the photon counts, ˆr,
Bayesian Methods
are distributed according to the Poisson distribution. The astronomer wishes to
determine λ, the emission rate of the source.
a. What is the likelihood function for the measurement? Identify explicitly what
is the unknown parameter and what are the data in the problem.
b. If the true rate is λ = 10 photons/minute, what is the probability of observing
ˆr = 15 photons in one minute?
c. Find the Maximum Likelihood Estimate for the rate λ (i.e., the number of
photons per minute). What is the maximum likelihood estimate if the observed
number of photons is ˆr = 10?
d. Upon reﬂection, the astronomer realizes that the photon ﬂux is the superposition of photons coming from the star plus “background” photons coming
from other faint sources within the ﬁeld of view of the instrument. The background rate is supposed to be known, and it is given by λb photons per minute
(this can be estimated e.g. by pointing the telescope away from the source
and measuring the photon counts there, when the telescope is only picking up
background photos). She then points to the star again, measuring ˆrt photons
in a time tt. What is her maximum likelihood estimate of the rate λs from the
star in this case? Hint: The total number of photons ˆrt is Poisson distributed
with rate λ = λs +λb, where λs is the rate for the star.
e. What is the source rate (i.e., the rate for the star) if ˆrt = 30, tt = 2 mins, and
λb = 12 photons per minute? Is it possible that the measured average rate from
the source (i.e., ˆrt/tt) is less than λb? Discuss what happens in this case and
comment on the physicality of this result.
(vii) This problem generalizes the Gaussian measurement case to the case where the
measurements have different uncertainties among them.
You measure the ﬂux F of photons from a laser source using 4 different instruments and you obtain the following results (units of 104 photons/cm2):
a. Write down the likelihood for each measurement, and explain why a Gaussian
approximation is justiﬁed in this case.
b. Write down the joint likelihood for the combination of the 4 measurements.
c. Find the MLE of the photon ﬂux, FML, and show that it is given by:
d. Compute FML from the data above and compare it with the sample mean.
e. Find the 1σ conﬁdence interval for your MLE for the mean, and show that it
is given by:
Bayesian Methods
Evaluate the conﬁdence interval for the above data. How would you summarize your measurement of the ﬂux F?
2.8 Solutions to exercises
(i) a. The measurements are independent, hence the joint likelihood is the product
of the likelihoods for each measurement:
( ˆTi −T)2
where ˆTi are the data given, T is the temperature we are trying to determine
(unknown parameter) and σ = 5 K.
b. The MLE for the mean of a Gaussian is given by the mean of the sample, see
Eq. (22), hence
Ti = 199.7K.
c. The variance of the mean is given by σ2/N, see Eq. (34). Therefore the standard deviation of our estimate TML is given by ΣT = σ/
K, which corresponds to the 68.3% interval: 199.7 ± 1.6 K, i.e. the range
[198.1,201.3] K (4 s.f. accuracy). Conﬁdence intervals at 95.4% and 99%
corresponds to symmetric intervals around the mean of length 2.0 and 2.57
times the standard deviation ΣT. Hence the required conﬁdence intervals are
[196.5,202.9] K (95.4%) and [195.6,203.8] K (99%).
d. A 1σ conﬁdence interval lenght 1 K means that the value of ΣT should be 1
K. Using that the standard deviation scales as 1/
N, we have
N ⇒N = 25.
You would need N = 25 measurements to achieve the desired accuracy.
(ii) a. The measurements are independent, hence the joint likelihood is the product
of the likelihoods for each measurement, see Eq. (19):
( ˆTi −T)2
b. the MLE for the mean of a Gaussian is given by the mean of the sample, see
Eq. (22), hence
Bayesian Methods
ˆTi = 199.6K.
c. The variance of the mean is given by Σ 2
µ = σ2/N, where σ2 = 25 K2 and
N = 10. Therefore the standard deviation of our temperature estimate TML is
given by ΣT = 5/
10 = 1.6 K. The measurement can thus be summarized as
T = 199.6 ± 1.6 K, where the ±1.6 K gives the range of the 1σ (or 68.3%)
conﬁdence interval.
(iii) a. The joint Gaussian likelihood function for ∆is given by
P(∆|d) ≡L (∆) =
where σ = 3 cm and di are the measurements given in the question.
b. The maximum likelihood estimate for ∆is found by maximising the loglikelihood function wrt ∆:
= 0 →∆MLE = 1
The numerical value is ∆MLE = 119.4 cm ≈119 (cm, 3 s.f.).
The uncertainty Σ on ∆is estimated from the inverse curvature of the log
likelihood function at the MLE point:
Numerically this gives Σ = 3/
5 = 1.34 ≈1 cm.
c. The measurement of ∆would be reported as ∆= (119±1) cm.
(iv) a. The likelihood function is given by
L (p) = P(r = H|p,n) =
pH(1−p)n−H,
where the unknown parameter is p and the data are the number of heads, H
(for a ﬁxed number of trials, n = 10 here).
b. The Maximum Likelihood Estimator (MLE) for the success probability p is
found by maximising the log likelihood:
+H ln p+(n−H)ln(1−p)
Therefore the ML value for p is pML = 0.8.
Bayesian Methods
c. We approximate the likelihood function as a Gaussian, with standard deviation
given by minus the curvature of the log-likelihood at the peak:
L (p) ≈Lmax exp
(pML −p)2)
Σ −2 = −∂2 lnL (p)
= H −2Hp+ p2n
The 1σ conﬁdence interval for p is given by Σ = 0.13. Therefore the result
would be reported as p = 0.80±0.13.
d. Following the hint, the number of σ conﬁdence with which the hypothesis
that the coin is fair can be ruled out is given by
Therefore the fairness hypothesis can be ruled out at the ∼2.3 σ level.
e. Using above equations, the MLE for the success probability is still pML = 0.8,
as before. However, the uncertainty is now much reduced, because of the large
number of trials. In fact, we get Σ = 0.013 (notice how the uncertainty has decreased by a factor of √n, as expected. I.e., 100 times more trials correspond
to a reduction in the uncertainty by a factor of 10). The fairness hypothesis
can now be excluded with much higher conﬁdence:s of p = 1/2, expressed in
number of sigmas:
number of sigmas = |pML −1
= 23.1 ≈23.
This constitutes very strong evidence against the hypothesis that the coin is
fair. Notice however that the Gaussian approximation to the likelihood we employed will most probably not be accurate so far into the tails of the likelihood
function (i.e., the Taylor expansion on which it is based is a local expansion
around the peak).
(v) a. The discrete PMF for the number of counts r of a Poisson process with average
rate λ is (assuming a unit time, t = 1 throughout)
P(r) = λ r
b. In this case
P(ˆri|λ) = λ ˆri
ˆri! e−λ ,
Bayesian Methods
for each independent measurement ˆri. So the joint likelihood is given by (as
measurements are independent)
P(ˆri|λ) =
ˆri! e−λ .
c. The Maximum Likelihood Principle states that the estimator for λ can be
derived by ﬁnding the maximum of the likelihood function. The maximum is
found more easily by considering the log of the likelihood
[ˆri ln(λ)−ln(ˆri!)−λ] .
with the maximum given by the condition dlnL /dλ = 0.
So the Maximum Likelihood (ML) estimator for λ is
which is just the average of the observed counts.
d. The Taylor expansion is
lnL (λ) = lnL (λML)+ dlnL
(λ −λML)+ 1
(λ −λML)2+... .
By deﬁnition the linear term vanishes at the maximum so we just need the
curvature around the ML point
ˆri = −MλML
Putting this into the Taylor expansion gives
Bayesian Methods
lnL (λ) = lnL (λML)−1
(λ −λML)2 ,
which gives an approximation of the likelihood function around the ML point
L (λ) ≈L0 exp
(the normalisation constant L0 is irrelevant).
So the likelihood is approximated by a Gaussian with variance
e. Comparing this with the standard result for the variance of the mean for the
Gaussian case, i.e.
where M is the number of measurements and σ is the standard deviation of
each measurement, we can conclude that the variance of the Poisson distribution itself is indeed
(vi) a. The likelihood function is given by the Poisson distribution evaluated as a
function of the parameter, λ:
L (ˆr) = P(ˆr|λ) = (λt)ˆr
where t is the time of observation in minutes. The unknown parameter is the
source strength λ (in units of photons/min), while the data are the observed
counts, ˆr.
b. We can compute the requested probability by substituting in the Poisson distribution above the values for ˆr and λ, obtaining:
P(ˆr = 15|λ = 10,t = 1 min) = 0.0347.
c. The maximum likelihood estimate is obtained by ﬁnding the maximum of the
log likelihood as a function of the parameter (here, the rate λ). Hence we need
to ﬁnd the value of λ such that:
The derivative gives
∂λ (ˆrln(λt)−ln ˆr!−λt) = ˆr t
λt −t = 0 ⇔λMLE = ˆr
Bayesian Methods
So the maximum likelihood estimator for the rate is the observed number of
counts divided by the time, in agreement with Eq. (212). In this case, t = 1
min so the MLE for λ is 10 photons per minute.
d. The likelihood function now needs to be modiﬁed to account for the fact
that the observed counts are the superposition of the background rate and the
source rate (the star). According to the hint, the likelihood for the total number
counts, ˆrt, is Poisson with rate λ = λs +λb, and thus
P(ˆrt|λ = λs +λb) = (λtt)ˆrt
exp(−λtt).
Similarly to what we have done above, the MLE estimate for λs is found by
setting to 0 the derivative of the log likelihood wrt λs:
∂lnP(ˆrt|λ = λs +λb)
(λs +λb)tt
−tt = 0 ⇔λs = ˆrt
So the MLE for the source is given by the observed average total rate ( ˆrt
minus the background rate.
e. Inserting the numerical results, we have that λs = 3. The MLE estimate for λs
gives a negative rate if ˆrt/tt < λb, which is clearly non-physical. However, this
can deﬁnitely happen because of downwards ﬂuctuations in the number counts
due to the Poisson nature of the signal (even if the background is assumed to
be known perfectly). So this is an artefact of the MLE estimator (nothing to
do with physics! We know that the actual physical source rate has to be a
non-negative quantity!). The solution is to use Bayes theorem instead.
(vii) a. The photon counts follow a Poisson distribution. We know that the MLE for
the Poisson distribution is the observed number of counts (n) and its standard
deviation is √n. However, for large n (≫20) the Poisson distribution is well
approximated by a Gaussian of mean n and standard deviation √n. In this
case, n is of order 105, hence the standard deviation intrinsic to the Poisson
process (the so-called “shot noise”) is of order
105 ≈3·102. The quoted experimental uncertainty is much larger than that (of order 104 for each datum),
hence we can conclude that the statistical error is dominated by the noise in
the detector rather than by the Poisson variance.
Therefore we can approximate the likelihood for each observation as a Gaussian with mean given by the observed counts ˆni and standard deviation given
by the quoted error, ˆσi:
(i = 1,...,4).
b. Since the measurements are independent, the joint likelihood is the product of
the 4 terms:
Bayesian Methods
c. To estimate the mean of the distribution, we apply the MLE procedure for the
mean (F), obtaining:
We thus see that the ML estimate for the mean is the mean of the observed
counts weighted by the inverse error on each on them (verify that Eq. (68) reverts to the usual expression for the sample mean for ˆσi = ˆσ for (i = 1,...,4),
i.e., if all observations have the same error). This automatically gives more
weight to observations with a smaller error.
From the given observations, one thus obtains FML = 29.2×104 photons/cm2.
By comparison the sample mean is ¯F = 30.3×104 photons/cm2.
d. The inverse variance of the mean is given by the second derivative of the loglikelihood evaluated at the ML estimate:
Σ −2 = −∂2 lnL (F)
(again, it is simple to verify that the above formula reverts to the usual N/ ˆσ2
expression if all measurements have the same error).
Therefore the variance of the mean is given by Σ 2 = 2.16×108 (photons/cm2)2,
and the standard deviation is Σ = 1.47×104 photons/cm2. Our measurement
can thus be summarized as F = (29.2±1.5)×104 photons/cm2.
3 Bayesian parameter inference
In this section we introduce the meaning and practical application of Bayes Theorem, Eq. (4), which encapsulates the notion of probability as degree of belief.
3.1 Bayes theorem as an inference device
As a mathematical result, Bayes Theorem is elementary and uncontroversial. It becomes interesting for the purpose of inference when we replace in Bayes theorem,
Eq. (4), A →θ (the parameters) and B →d (the observed data, or samples), obtaining
Bayesian Methods
P(θ|d) = P(d|θ)P(θ)
On the LHS, P(θ|d) is the posterior probability for θ (or “posterior” for short), and
it represents our degree of belief about the value of θ after we have seen the data d.
On the RHS, P(d|θ) = L (θ) is the likelihood we already encountered. It is the
probability of the data given a certain value of the parameters.
The quantity P(θ) is the prior probability distribution (or “prior” for short). It
represents our degree of belief in the value of θ before we see the data (hence the
name). This is an essential ingredient of Bayesian statistics. The Bayesian school
is divided between “subjectivists” (who maintain that the prior is a reﬂection of
the subject state of knowledge of the individual researcher adopting it) and “objectivists” (who argue for the use of “standard” priors to enforce inter-subjectivity
between different researchers). However formulated, the posterior distribution usually converges to a prior-independent regime for sufﬁciently large data sets.
In the denominator, P(d) is a normalizing constant (often called “the evidence”
or “marginal likelihood”), than ensures that the posterior is normalized to unity:
dθP(d|θ)P(θ).
The evidence is important for Bayesian model selection (see section 4).
Interpretation: Bayes theorem relates the posterior probability for θ (i.e., what
we know about the parameter after seeing the data) to the likelihood and the
prior (i.e., what we knew about the parameter before we saw the data). It can
be thought of as a general rule to update our knowledge about a quantity (here,
θ) from the prior to the posterior.
Remember that in general P(θ|d) ̸= P(d|θ), i.e. the posterior P(θ|d) and the
likelihood P(d|θ) are two different quantities with different meaning!
Example 15. We want to determine if a randomly-chosen person is male (M) or female (F)5. We make one measurement, giving us information on whether the person
is pregnant (Y) or not (N). Let’s assume we have observed that the person is pregnant, so d = Y.
The likelihood is P(d = Y|θ = F) = 0.03 (i.e., there is a 3% probability that a
randomly selected female is pregnant), but the posterior probability P(θ = F|d =
Y) = 1.0, i.e., if we have observed that the person is pregnant, we are sure she is a
woman. This shows that the likelihood and the posterior probability are in general
different!
This is because they mean two different things: the likelihood is the probability
of making the observation if we know what the parameter is (in this example, if we
know that the person is female); the posterior is the probability of the parameter
5 This example is due to Louis Lyons.
Bayesian Methods
given that we have made a certain observation (in this case, the probability of a
person being female if we know she is pregnant). The two quantities are related by
Bayes theorem (prove this in the example given here).
Bayesian inference works by updating our state of knowledge about a parameter
(or hypothesis) as new data ﬂow in. The posterior from a previous cycle of observations becomes the prior for the next.
3.2 Advantages of the Bayesian approach
Irrespectively of the philosophical and epistemological views about probability, as
physicists we might as well take the pragmatic view that the approach that yields
demonstrably superior results ought to be preferred. In many real–life cases, there
are several good reasons to prefer a Bayesian viewpoint:
(i) Classic frequentist methods are often based on asymptotic properties of estimators. Only a handful of cases exist that are simple enough to be amenable to
analytic treatment (in physical problems one most often encounters the Normal
and the Poisson distribution). Often, methods based on such distributions are employed not because they accurately describe the problem at hand, but because of
the lack of better tools. This can lead to serious mistakes. Bayesian inference is
not concerned by such problems: it can be shown that application of Bayes’ Theorem recovers frequentist results (in the long run) for cases simple enough where
such results exist, while remaining applicable to questions that cannot even be
asked in a frequentist context.
(ii) Bayesian inference deals effortlessly with nuisance parameters. Those are parameters that have an inﬂuence on the data but are of no interest for us. For
example, a problem commonly encountered in astrophysics is the estimation of
a signal in the presence of a background rate The particles of interest might be
photons, neutrinos or cosmic rays. Measurements of the source s must account
for uncertainty in the background, described by a nuisance parameter b. The
Bayesian procedure is straightforward: infer the joint probability of s and b and
then integrate over the uninteresting nuisance parameter b (“marginalization”,
see Eq. (94)). Frequentist methods offer no simple way of dealing with nuisance
parameters (the very name derives from the difﬁculty of accounting for them in
classical statistics). However neglecting nuisance parameters or ﬁxing them to
their best–ﬁt value can result in a very serious underestimation of the uncertainty
on the parameters of interest.
(iii) In many situations prior information is highly relevant and omitting it would
result in seriously wrong inferences. The simplest case is when the parameters
of interest have a physical meaning that restricts their possible values: masses,
count rates, power and light intensity are examples of quantities that must be
positive. Frequentist procedures based only on the likelihood can give best–ﬁt
estimates that are negative, and hence meaningless, unless special care is taken
Bayesian Methods
(for example, constrained likelihood methods). This often happens in the regime
of small counts or low signal to noise. The use of Bayes’ Theorem ensures that
relevant prior information is accounted for in the ﬁnal inference and that physically meaningless results are weeded out from the beginning.
(iv) Bayesian statistics only deals with the data that were actually observed, while
frequentist methods focus on the distribution of possible data that have not been
obtained. As a consequence, frequentist results can depend on what the experimenter thinks about the probability of data that have not been observed. (this
is called the “stopping rule” problem). This state of affairs is obviously absurd.
Our inferences should not depend on the probability of what could have happened but should be conditional on whatever has actually occurred. This is built
into Bayesian methods from the beginning since inferences are by construction
conditional on the observed data.
The cosmology and astrophysics communities have been embracing Bayesian mehods since the turning of the Millennium, spurred by the availability of cheap computational power that has ushered in an era of high-performance computing, thus
allowing for the ﬁrst time to deploy the power of Bayesian statistics thanks to numerical implementations (in particular, MCMC and related techniques). The steep
increase in the number of Bayesian papers in the astrophysics literature is shown in
Number of papers normalized to 1980
"Bayesian" papers
All astrophysics papers
The rise of Bayesian methods in astrophysics
Fig. 3 Number of articles in astronomy and cosmology with “Bayesian” in the title, as a function
of publication year (upper data points) and total number of articles (lower data points) as a function of publication year. Numbers are normalized to 1980 levels for each data series. The number
of Bayesian papers doubles every 4.3 years, while the total number of papers doubles “only” every 12.6 years. At the present rate, by 2060 all papers on the archive will be Bayesian. (source:
NASA/ADS).
Bayesian Methods
3.3 Considerations and caveats on priors
Bayesian inference works by updating our state of knowledge about a parameter (or
hypothesis) as new data ﬂow in. The posterior from a previous cycle of observations
becomes the prior for the next. The price we have to pay is that we have to start
somewhere by specifying an initial prior, which is not determined by the theory,
but it needs to be given by the user. The prior should represent fairly the state of
knowledge of the user about the quantity of interest. Eventually, the posterior will
converge to a unique (objective) result even if different scientists start from different
priors (provided their priors are non-zero in regions of parameter space where the
likelihood is large). See Fig. 4 for an illustration.
Fig. 4 Converging views in Bayesian inference. Two scientists having different prior believes p(θ)
about the value of a quantity θ (panel (a), the two curves representing two different priors) observe
one datum with likelihood L (θ) (panel (b)), after which their posteriors p(θ|d) (panel (c), obtained via Bayes Theorem, Eq. (4)) represent their updated states of knowledge on the parameter.
This posterior then becomes the prior for the next observation. After observing 100 data points, the
two posteriors have become essentially indistinguishable (d).
There is a vast literature about how to select a prior in an appropriate way. Some
aspects are fairly obvious: if your parameter θ describes a quantity that has e.g. to
be strictly positive (such as the number of photons in a detector, or an amplitude),
then the prior will be 0 for values θ < 0.
A standard (but by no means harmless, see below) choice is to take a uniform
prior (also called “ﬂat prior”) on θ, deﬁned as:
(θmax−θmin) for θmin ≤θ ≤θmax
With this choice of prior in Bayes theorem, Eq. (71), the posterior becomes functionally identical to the likelihood up to a proportionality constant:
P(θ|d) ∝P(d|θ) = L (θ).
In this case, all of our previous results about the likelihood carry over (but with a
different interpretation). In particular, the probability content of an interval around
Bayesian Methods
the mean for the posterior should be interpreted as a statement about our degree of
belief in the value of θ (differently from conﬁdence intervals for the likelihood).
Example 16. Let’s look once more to the temperature estimation problem of Eq. (39).
The Bayesian estimation of the temperature proceeds as follows. We ﬁrst need
to specify the likelihood function – this is the same as before, and it is given by
Eq. (39). If we want to estimate the temperature, we need to compute the posterior
probability for T, given by (up to a normalization constant)
P(T|d) ∝L (T)P(T)
where the likelihood L (T) is given by Eq. (39). We also need to specify the prior,
P(T). For this particular case, we know that T > 0 (the temperature in K of an object
needs to be positive) and let’s assume we know that the temperature cannot exceed
300 K. Therefore we can pick a ﬂat prior of the form
300 for 0K ≤T ≤300K
0 otherwise.
The posterior distribution for T then becomes
300 for 0K ≤T ≤300K
otherwise.
So the posterior is identical to the likelihood (up to a proportionality constant), at
least within the range of the ﬂat prior. Hence we can conclude that the posterior is
going to be a Gaussian (just like the likelihood) and we can immediately write the
68.3% posterior range of T as 198.0K < µ < 201.2K. This is numerically identical
to our results obtained via the MLE. However, in this case the interpretation of this
interval is that “after seeing the data, and given our prior as speciﬁed in Eq. (76),
there is 68.3% probability that the true value of the temperature lies within the range
198.0K < µ < 201.2K”.
Under a change of variable, Ψ =Ψ(θ), the prior transforms according to:
P(Ψ) = P(θ)
In particular, a ﬂat prior on θ is no longer ﬂat in Ψ if the variable transformation is
non-linear.
It is important to realize that a ﬂat prior is far from harmless, especially in parameter spaces of high dimensionality. This is the so-called “concentration of measure”
phenomenon. Sampling uniformly (i.e., with a uniform prior) along each dimension
xi ∈ of a D-dimensional hypercube leads to the radius r =
1/2 of the
samples to concentrate around the value ⟨r⟩= (D/3)1/2 with constant variance. As
a consequence, all of the samples are found on a thin shell (see Fig. 5 for an illustration). Even worse, in D dimensions the volume of the hypercube is much larger than
the volume of the hypersphere, hence most of the volume is in the corners of the hy-
Bayesian Methods
Dimensions
Concentration of measure
Theoretical maximum
Observed samples
(flat prior on coordinates)
Fig. 5 Illustration of the phenomenon of the concentration of measure in parameter spaces with a
large number of dimensions. The coloured band represents the density of samples (as a function
of the number of dimensions sampled) obtained with a ﬂat prior on the axis coordinates of a Ddimensional hypercube. It can be seen that samples from the prior concentrate in a thin shell of
constant variance, leaving most of the parameter space unexplored. The radius of the shell is given
in the vertical axis.
percube which are not sampled. This means that an MCMC in D dimensions (where
D is large) has a prior distribution that is far from being uniformly distributed in the
volume of the hypercube – although any 2-dimensional projection will apparently
belie this.
A sensitivity analysis should always be performed, i.e., change the prior in a
reasonable way and assess how robust the ensuing posterior is. Unfortunately, this
is seldom done in the astrophysics and cosmology literature.
There is a vast body of literature on different types of priors, when to use them
and what they are good for. It is a good idea to browse the literature when faced
with a new problem, as there is no point in re-inventing the wheel every time. There
are essentially two schools of thought: one maintains that priors should be chosen
according to subjective degree of belief; the other, that they should be selected according to some formal rule, i.e. priors should be chosen by convention. None of the
two approaches is free from difﬁculties. To give but some relevant examples:
• reference priors: the idea is to deﬁne a prior so that the contribution of the data to
the posterior is maximised. This is achieved by choosing a prior with maximum
entropy. For example, in the case of a Gaussian likelihood this leads to the conclusion that the proper prior for the mean µ is ﬂat on µ, while for the standard
deviation σ is should be ﬂat in logσ (with appropriate cutoffs of course).
• ignorance priors: in 1812 Laplace set forth the principle that when nothing else
is known priors should be chosen so as to give equal probability to all alternatives (“the principle of indifference”). Unfortunately this is very difﬁcult to do in
the case of continuous parameters: part of the reason is that the notion of “indifference” is not invariant under non-linear reparameterizations. In some relatively
simple cases, ignorance priors can be derived using symmetry or invariance arguments, see for examples .
Bayesian Methods
• conjugate priors: a prior is said to be conjugate to the likelihood if the resulting posterior is of the same family as the likelihood. The convenience of having
conjugate priors is that the likelihood updates the prior to a posterior which is of
the same type (i.e., same distributional family). For example, Gaussian distributions are self-conjugate, i.e., a Gaussian prior with a Gaussian likelihood leads
to a Gaussian posterior; the conjugate prior to both the Poisson and the exponential likelihood is the Gamma distribution; the conjugate prior to a Binomial
likelihood is the Beta distribution.
3.4 A general Bayesian solution to inference problems
The general Bayesian recipe to inferential problems can be summarised as follows:
(i) Choose a model containing a set of hypotheses in the form of a vector of parameters, θ (e.g., the mass of an extra–solar planet or the abundance of dark matter
in the Universe).
(ii) Specify the priors for the parameters. Priors should summarize your state of
knowledge about the parameters before you consider the new data, including
an relevant external source of information.
(iii) Construct the likelihood function for the measurement, which usually reﬂects
the way the data are obtained (e.g., a measurement with Gaussian noise will
be represented by a Normal distribution, while γ–ray counts on a detector will
have a Poisson distribution for a likelihood). Nuisance parameters related to the
measurement process might be present in the likelihood, e.g. the variance of the
Gaussian might be unknown or the background rate in the absence of the source
might be subject to uncertainty. Such nuisance parameters are included in the
likelihood (with appropriate prior). If external measurements are available for
the nuisance parameters, they can be incorporated either as an informative prior
on them, or else as additional likelihood terms.
(iv) Obtain the posterior distribution (usually, up to an overall normalisation constant)
either by analytical means or, more often, by numerical methods (see below for
MCMC and nested sampling algorithms to this effect).
The posterior pdf for one parameter at the time is obtained by marginalization,
i.e., by integrating over the uninteresting parameters. E.g., assume the the vector of
parameters is given by θ = {φ,ψ}, then the 1D posterior pdf for φ alone is given
L (φ,ψ)p(φ,ψ)dψ.
The ﬁnal inference on φ from the posterior can then be communicated by plotting
p(φ|d), with the other components marginalized over.
From an MCMC chain, one can also obtain the proﬁle likelihood, Eq. (35), by
maximising the value of the likelihood in each bin. The proﬁle likelihood is expected
to be prior-independent, as long as the scan has gathered a sufﬁcient number of sam-
Bayesian Methods
ples in the favoured region, which is in general a difﬁcult task for multi-dimensional
parameter spaces. It is also typically much more expensive to compute as it requires
a much larger number of samples than the posterior.
The proﬁle likelihood and the Bayesian posterior ask two different statistical
questions of the data: the latter evaluates which regions of parameter space are most
plausible in the light of the measure implied by the prior; the former singles out
regions of high quality of ﬁt, independently of their extent in parameter space, thus
disregarding the possibility of them being highly ﬁne tuned. The information contained in both is relevant and interesting, and for non-trivial parameter spaces the
two different approaches do not necessarily lead to the same conclusions6.
3.5 The Gaussian linear model
As idealised a case as it is, the Gaussian linear model is a great tool to hone your
computational skills and intuition. This is because it can be solved analytically, and
any numerical solution can be compared with the exact one. Furthermore, it applies
in an approximate way to many cases of interest. Here we solve analytically the general problem in n dimensions. An application to the 2-dimensional case is then given
in the Exercises, section 3.9.2. For a more complete discussion, see , where the
general case is treated (including errors on the independent variable, general correlations, missing data, upper limits, selection effects and the important subject of
Bayesian hierarchical modelling).
We consider the following linear model
where the dependent variable y is a d-dimensional vector of observations (the data),
θ = {θ1,θ2,...,θn} is a vector of dimension n of unknown parameters that we wish
to determine and F is a d × n matrix of known constants which specify the relation between the input variables θ and the dependent variables y (so-called “design
In the following, we will specialize to the case where observations yi(x) are ﬁtted
with a linear model of the form f(x) = ∑n
j=1 θ jX j(x). Then the matrix F is given by
the basis functions X j evaluated at the locations xi of the observations, Fij = X j(xi).
Notice that the model is linear in θj, not necessarily in X j, i.e. X j can very well be
a non-linear function of x.
Furthermore, ε is a d-dimensional vector of random variables with zero mean
(the noise). We assume for simplicity that ε follows a multivariate Gaussian distribution with uncorrelated covariance matrix C ≡diag(τ2
d). The likelihood
function takes the form
6 In the archetypal case of a Gaussian likelihood and uniform prior, the posterior pdf and the proﬁle
likelihood are identical (up to a normalisation constant) and thus the question of which to choose
does not arise.
Bayesian Methods
(2π)d/2 ∏j τj
2(b−Aθ)t(b−Aθ)
where we have deﬁned Ai j = Fij/τi and bi = yi/τi where A is a d ×n matrix and b
is a d-dimensional vector. This can be re-cast with some simple algebra as
p(y|θ) = L0 exp
2(θ −θ0)tL(θ −θ0)
with the likelihood Fisher matrix L (a n×n matrix) given by
and a normalization constant
(2π)d/2 ∏j τj
2(b−Aθ0)t(b−Aθ0)
Here θ0 denotes the parameter value which maximises the likelihood (i.e., the maximum likelihood value for θ), given by
θ0 = L−1Atb.
We assume as a prior pdf a multinormal Gaussian distribution with zero mean
and the n × n dimensional prior Fisher information matrix P (recall that that the
Fisher information matrix is the inverse of the covariance matrix), i.e.
p(θ) = |P|1/2
(2π)n/2 exp
where |P| denotes the determinant of the matrix P.
It can be shown that the posterior distribution for θ is given by multinormal
Gaussian with Fisher information matrix F
and mean ¯θ given by
¯θ = F −1Lθ0.
Finally, the model likelihood (or “Bayesian evidence”, i.e., the normalizing constant in Bayes theorem) is given by
|P|−1/2 exp
0(L−LF −1L)θ0
|P|−1/2 exp
0Lθ0 −¯θtF ¯θ)
Bayesian Methods
3.6 Markov Chain Monte Carlo methods
3.6.1 General theory
The purpose of a Markov chain Monte Carlo algorithm is to construct a sequence
of points (or “samples”) in parameter space (called “a chain”). The crucial property
of the chain is that the density of samples is proportional to the posterior pdf. This
allows to construct a map of the posterior distribution.
A Markov chain is deﬁned as a sequence of random variables {X(0),X(1),...,X(M−1)}
such that the probability of the (t +1)–th element in the chain only depends on the
value of the t–th element. The crucial property of Markov chains is that they can be
shown to converge to a stationary state (i.e., which does not change with t) where
successive elements of the chain are samples from the target distribution, in our
case the posterior p(θ|d).
The generation of the elements of the chain is probabilistic in nature, and is described by a transition probability T(θ (t),θ (t+1)), giving the probability of moving
from point θ (t) to point θ (t+1) in parameter space. A sufﬁcient condition to obtain a
Markov Chain is that the transition probability satisfy the detailed balance condition
p(θ (t)|d)T(θ (t),θ (t+1)) = p(θ (t+1)|d)T(θ (t+1),θ (t)).
This is perhaps clearer when recast as follows:
T(θ (t),θ (t+1))
T(θ (t+1),θ (t)) = p(θ (t+1)|d)
p(θ (t)|d) ,
i.e.˙ratio of the transition probabilities is inversely proportional to the ratio of the
posterior probabilities at the two points.
Once samples from the posterior pdf have been gathered, obtaining Monte Carlo
estimates of expectations for any function of the parameters becomes a trivial task.
The posterior mean is given by
P(θ|d)θdθ ≈1
where the (approximate) equality with the mean of the samples from the MCMC
follows because the samples θ (t) are generated from the posterior by construction.
One can easily obtain the expectation value of any function of the parameters
E[f(θ)] ≈1
It is usually interesting to summarize the results of the inference by giving the 1–
dimensional marginal probability for the j–th element of θ, θj, obtained by integrating out all other parameters from the posterior:
Bayesian Methods
P(θ|d)dθ2 ...dθn,
where P(θ1|d) is the marginal posterior for the parameter θ1. While this would usually require an n−1-dimensional integration (which can be numerically difﬁcult), it
is easily obtained from the Markov chain. Since the elements of the Markov chains
are samples from the full posterior, P(θ|d), their density reﬂects the value of the
full posterior pdf. It is then sufﬁcient to divide the range of θ1 in a series of bins
and count the number of samples falling within each bin, simply ignoring the coordinates values θ2,...,θn. A 2–dimensional posterior is deﬁned in an analogous
A 1D 2–tail symmetric α% credible region is given by the interval (for the parameter of interest) within which fall α% of the samples, obtained in such a way
that a fraction (1 −α)/2 of the samples lie outside the interval on either side. In
the case of a 1–tail upper (lower) limit, we report the value of the quantity below
(above) which α% of the sample are to be found.
Credible regions for a given probability content α can be deﬁned in an inﬁnite
number of ways. Two deﬁnitions are commonly used. The ﬁrst is “symmetric credible interval” (in 1D) given above. The second deﬁnition is that of Highest Posterior
Density (HPD) regions. They are obtained by starting from the maximum of the
posterior and reducing the level until the desired fraction α of the posterior probability mass is included. Such a deﬁnition delimits a region so that every point inside
it has by construction a higher posterior density than any point outside it. For a given
probability content α, the HPD region is also the shortest interval. For a Normal 1D
posterior, the HPD is identical to the symmetric credible region.
3.6.2 The Metropolis-Hastings algorithm
The simplest (and widely used) MCMC algorithm is the Metropolis-Hastings algorithm :
(i) Start from a random point θ (0), with associated posterior probability p0 ≡
p(θ (0)|d).
(ii) Propose a candidate point θ (c) by drawing from the proposal distribution q(θ (0),θ (c)).
The proposal distribution might be for example a Gaussian of ﬁxed width σ centered around the current point. For the Metropolis algorithm (as opposed to the
more general form due to Hastings), the distribution q satisﬁes the symmetry
condition, q(x,y) = q(y,x).
(iii) Evaluate the posterior at the candidate point, pc = p(θ (c)|d). Accept the candidate point with probability
pcq(θ (c),θ (0))
p0q(θ (0),θ (c)),1
For the Metropolis algorithm (where q is symmetric), this simpliﬁes to
Bayesian Methods
This accept/reject step can be performed by generating a random number u from
the uniform distribution [0,1) and accepting the candidate sample if u < α, and
rejecting it otherwise.
(iv) If the candidate point is accepted, add it to the chain and move there. Otherwise
stay at the old point (which is thus counted twice in the chain). Go back to (ii).
Notice from Eq. (96) that whenever the candidate sample has a larger posterior than
the previous one (i.e., pc > p0) the candidate is always accepted. Also, in order to
evaluate the acceptance function (96) only the unnormalized posterior is required, as
the normalization constant drops out of the ratio. It is easy to show that the Metropolis algorithm satisﬁes the detailed balance condition, Eq. (90), with the transition
probability given by T(θ (t),θ (t+1)) = q(θ (t),θ (t+1))α(θ (t),θ (t+1)).
Ref shows that an optimal choice of the proposal distribution is such that it
leads to an acceptance rate of approximately 25% (where acceptance rate is the ratio
of the number of accepted jumps to the total number of likelihood evaluations). The
optimal scale of the proposal distribution is approximately 2.4/
d times the scale
of the target distribution, where d is the number of dimensions of the parameter
The choice of proposal distribution q is crucial for the efﬁcient exploration of the
posterior. If the scale of q is too small compared to the scale of the target distribution,
exploration will be poor as the algorithm spends too much time locally. If instead
the scale of q is too large, the chain gets stuck as it does not jump very frequently.
To improve the exploration of the target, it is advisable to run an exploratory
MCMC, compute the covariance matrix from the samples, and then re-run with this
covariance matrix (perhaps rescaled by a factor 2.4/
d as recommended by ) as
the covariance of a multivariate Gaussian proposal distribution. This process can be
iterated a couple of times. The afﬁne invariant ensemble sampler proposed by 
evolves a series of “walkers” rather than just one sampler at the time, and uses the
position of the other points in the ensemble to generate a move with greatly reduced
auto-correlation length. This also largely dispenses with the need to ﬁne-tune the
proposal distribution to match the target density. An algorithm that includes a suitable parallelization of this sampling scheme is described in , and is implemented
in a publicly available Python package, emcee7.
3.6.3 Gibbs sampling
The Gibbs sampler is a particularly good choice when it is simple (and computationally non-expensive) to sample from the conditional distribution of one of the
parameters at the time. It has been shown to work well in a large (∼105) number of
dimensions.
7 Available from: .
Bayesian Methods
In Gibbs sampling, each of the parameters is updated in turn by drawing the
proposal distribution from the univariate conditional distribution of that variable
(conditional on all the others). This is best explained in a simple example, where the
parameter space is 2-dimensional and θ = {x,y}. In order to obtain the t-th sample,
x(t) ∼p(x|y = y(t−1))
y(t) ∼p(y|x = x(t)).
Notice that in the second step, when drawing y we condition on a value of x that has
been updated to the latest draw of x, namely x(t). In the above, p denotes the target
distribution, i.e. the posterior density (where we have omitted explicit conditioning
on the data for ease of notation).
In a higher number of dimensions of parameter space, one always draws the kth variable from the conditional distribution p(θk|θ(−k)), where θ(−k) denotes the
vector of variables without the k-th variable.
It is perhaps slightly bafﬂing that one can obtain samples from the joint posterior
merely from knowledge of the conditional distributions (although this is not generally true). An explanation of why this is the case (under only very mild conditions)
can be found in .
The Gibbs sampler can thus be seen as a special case of Metropolis-Hastings,
with one-dimensional proposal distributions and an acceptance rate of 1.
The above can also be generalised to blocks of variables, that are all updated simultaneously conditional on all the others. In the so-called “blocked Gibbs sampler”
one draws two (or more) variables simultaneously from p(θk,j|θ(−k,j)). This can be
useful in improving the convergence if the two variables k, j are strongly correlated.
A collapsed Gibbs sampler refers to the case when one of the variables has been
marginalised out in one of the sampling steps, i.e. one draws from p(θk|θ(−k,j)),
where the j-th variable has been marginalised from the joint. More sophisticated
sampling strategies can also be employed to reduced auto-correlation and improve
sampling, see for the Partially Collapsed Gibbs sampler, and for the
ancillarity-sufﬁciency interweaving strategy.
3.6.4 Hamiltonian Monte-Carlo
Hamiltonian Monte Carlo is particularly appealing for physicists, as it is built on
the formalism of Hamiltonian dynamics (as the name implies). Only a very sketchy
introduction is possible here. Refer to for further details. A Python implementation of HMC can be found at: mc-stan.org.
The idea is to augment the vector containing the variable of interest, q (representing position), by another vector of the same dimensionality, p (representing
momentum). We then deﬁne the potential energy U(q) as the negative log of the
unnormalized posterior we wish to sample from,
Bayesian Methods
U(q) = −log(π(q)L (q)),
where π(q) is the prior and L (q) the likelihood function. The Hamiltonian of this
ﬁctitious system is then given by
H(q, p) = K(p)+U(q)
where K(p) represents kinetic energy,
Here, the sum runs over the dimensionality of the parameter space, and mi are “mass
values” that are chosen for convenience. If we look at the kinetic energy term as the
negative log of a probability distribution, then it deﬁnes a multivariate Gaussian of
0 mean with variance along each direction given by m2
From analytical mechanics, we know that physical solutions are obtained by solving the Hamiltonian equations:
Such solutions have the useful properties of preserving energy (i.e., dH/dt = 0)
and conserving the phase space volume (in virtue of Liouville’s theorem). Those
properties are crucial in ensuring that the Hamiltonian MC (HMC) algorithm leaves
the desired distribution invariant.
In order to obtain a Markov Chain from the target distribution, the Hamiltonian
MC algorithm performs the following steps in each iteration:
(i) resample the momentum variables, pi ∼N (0,m2
(ii) obtain a new candidate location (qc, pc) in phase space by evolving the system
via approximate Hamiltonian dynamics (e.g. via the leapfrog method);
(iii) take a Metropolis accept/reject step at the candidate location (this is necessary as
in practice numerical approximation schemes mean that the energy of the system
is only approximately conserved).
The Hamiltonian dynamics preserves energy, but it changes the value of both the
momentum (in step (1)) and position variables (in step (2)), thus accomplishing a
large jump in the parameters of interest, namely q.
The key advantages of HMC is that it produces samples that are much less correlated than ordinary Metropolis-Hastings (in virtue of the large distance travelled via
the Hamiltonian dynamics step), and that it scales well with the number of dimensions of the parameter space.
Bayesian Methods
3.6.5 Importance sampling
Importance sampling is a useful technique when we want to sample from a target
distribution p(x) (usually the posterior), but we have samples from another distribution q(x) (perhaps because the latter is simpler to sample from). In some applications, q(x) could be the posterior from a certain data set, and we then want to
add another data set on top of it, thus obtaining p(x). As long as p(x) is not too
dissimilar from q(x), it can be obtained by importance sampling.
The expectation value under p of any function f(x) of the RV x can be written as
Ep[f(x)] =
f(x)p(x)dx =
f(x)q(x) p(x)
q(x) dx = Eq[ p(x)
q(x) f(x)].
This shows that we can obtain the expectation value under p by computing the
expectation value under q but re-weighting the function of interest by the factor
p(x)/q(x).
In terms of the sampling estimate, we can write
i=0 wi f(xi)
where wi = p(xi)/q(xi) are the importance sampling weights and xi ∼q(x). Notice
that only the unnormalized values of p and q are necessary in Eq. (106), since the
normalisation cancels in the ratio.
3.7 Practical and numerical issues
It is worth mentioning several important practical issues in working with MCMC
methods. Poor exploration of the posterior can lead to serious mistakes in the ﬁnal inference if it remains undetected – especially in high–dimensional parameter
spaces with multi–modal posteriors. It is therefore important not to use MCMC
techniques as a black box, but to run adequate tests to ensure insofar as possible that
the MCMC sampling has converged to a fair representation of the posterior.
Some of the most relevant aspects are:
(i) Initial samples in the chain must be discarded, since the Markov process is not
yet sampling from the equilibrium distribution (so–called burn–in period). The
length of the burn–in period can be assessed by looking at the evolution of the
posterior density as a function of the number of steps in the chain. When the
chain is started at a random point in parameter space, the posterior probability
will typically be small and becomes larger at every step as the chain approaches
the region where the ﬁt to the data is better. Only when the chain has moved in
the neighborhood of the posterior peak the curve of the log posterior as a function
Bayesian Methods
of the step number ﬂattens and the chain begins sampling from its equilibrium
distribution. Samples obtained before reaching this point must be discarded, see
(ii) A difﬁcult problem is presented by the assessment of chain convergence, which
aims at establishing when the MCMC process has gathered enough samples so
that the Monte Carlo estimate (93) is sufﬁciently accurate. Useful diagnostic
tools include the Raftery and Lewis statistics and the Gelman and Rubin
criterion .
(iii) One has to bear in mind that MCMC is a local algorithm, which can be trapped
around local maxima of the posterior density, thus missing regions of even higher
posterior altogether. Considerable experimentation is sometimes required to ﬁnd
an implementation of the MCMC algorithm that is well suited to the exploration
of the parameter space of interest. Experimenting with different algorithms (each
of which has its own strength and weaknesses) is highly recommended.
(iv) Successive samples in a chain are in general correlated. Although this is not prejudicial for a correct statistical inference, it is often interesting to obtain independent samples from the posterior. This can be achieved by “thinning” the chain
by an appropriate factor, i.e. by selecting only one sample every K. The autocorrelation is a good measure of the number of steps required before the chain
has “forgotten” its previous state. It can be estimated from the MCMC samples
ˆγ(k) = ∑M−k
i=0 (θi −¯θ)(θi+k −¯θ)
i=0 (θi −¯θ)2
where k is called the lag and ¯x is the sample mean (the above equation should
be understood component by component if the parameter vector θ is multidimensional). A plot of ˆγ versus lag k is called “autocorrelation function” (ACF)
and the value of the lag after which it drops close to 0 provides an estimate of the
thinning factor K required to obtain approximate independent samples from the
A discussion of samples independence and how to assess it can be found in ,
along with a convergence test based on the samples’ power spectrum.
3.8 Exercises
3.8.1 Bayesian reasoning
(i) A batch of chemistry undergraduates are screened for a dangerous medical condition called Bacillum Bayesianum (BB). The incidence of the condition in the
population (i.e., the probability that a randomly selected person has the disease)
is estimated at about 1%. If the person has BB, the test returns positive 95% of
the time. There is also a known 5% rate of false positives, i.e. the test returning
positive even if the person is free from BB. One of your friends takes the test and
Bayesian Methods
Fig. 6 Illustration of the burn-in period. Left panel: the logarithm of the log-likelihood,
−lnP(d|θ), as a function of the step number for four Monte Carlo chains. After the burn-in period
(dotted, vertical lines), the value ﬂattens and the chains are sampling from the target distribution.
Right panel: the four chains (in different colors) are started in different points of a 6-dimensional
parameter space and all converge to the same region after the burn-in. The vertical axis gives the
number of steps.
it comes back positive. Here we examine whether your friend should be worried
about her health.
a. Translate the information above in suitably deﬁned conditional probabilities.
The two relevant propositions here are whether the test returns positive (denote this with a + symbol) and whether the person is actually sick (denote
this with the symbol BB = 1. Denote the case when the person is healthy as
b. Compute the conditional probability that your friend is sick, knowing that she
has tested positive, i.e., ﬁnd P(BB = 1|+).
c. Imagine screening the general population for a very rare desease, whose incidence in the population is 10−6 (i.e., one person in a million has the disease
on average, i.e. P(BB = 1) = 10−6). What should the reliability of the test
(i.e., P(+|BB = 1)) be if we want to make sure that the probability of actually
having the disease after testing positive is at least 99%? Assume ﬁrst that the
false positive rate P(+|BB = 0) (i.e, the probability of testing positive while
healthy), is 5% as in part (a). What can you conclude about the feasibility of
such a test?
d. Now we write the false positive rate as P(+|BB = 0) = 1−P(−|BB = 0). It is
reasonable to assume (although this is not true in general) that P(−|BB = 0) =
P(+|BB = 1), i.e. the probability of getting a positive result if you have the
disease is the same as the probability of getting a negative result if you don’t
have it. Find the requested reliability of the test (i.e., P(+|BB = 1)) so that
Bayesian Methods
the probability of actually having the disease after testing positive is at least
99% in this case. Comment on whether you think a test with this reliability is
practically feasible.
(ii) In a game, you can pick one of three doors, labelled A, B and C. Behind one of
the three doors lies a highly desirable price, such as for example a cricket bat.
After you have picked one door (e.g., door A) the person who is presenting the
game opens one of the remaining 2 doors so as to reveal that there is no prize
behind it (e.g., door C might be opened). Notice that the gameshow presenter
knows that the door he opens has no prize behind it. At this point you can either
stick with your original choice (door A) or switch to the door which remains
closed (door B). At the end, all doors are opened, at which point you will only
win if the prize is behind your chosen door.
a. Given the above rules (and your full knowledge of them), should you stick
with your choice or is it better to switch?
b. In a variation, you are given the choice to randomly pick one of doors B or
C and to open it, after you have chosen door A. You pick door C, and upon
opening it you discover there is nothing behind it. At this point you are again
free to either stick with door A or to switch to door B. Are the probabilities
different from the previous scenario? Justify your answers.
(iii) In a TV debate, politician A afﬁrms that a certain proposition S is true. You trust
politician A to tell the truth with probability 4/5. Politician B then agrees that what
politician A has said is indeed true. Your trust in politician B is much weaker, and
you estimate that he lies with probability 3/4.
After you have heard politician B, what is the probability that statement S is
indeed true? You may assume that you have no other information on the truth of
proposition S other than what you heard from politicians A and B.
Hint: Start by denoting by AT the statement “politician A tells the truth”, and by
BT the statement “politician B tells the truth”. What you are after is the probability of the statement “proposition S is true” after you have heard politician B
(iv) A body has been found on the Baltimore West Side, with no apparent wounds,
although it transpires that the deceased, a Mr Fuzzy Dunlop, was a heavy drug
user. The detective in charge suggests to close the case and to attribute the death
to drugs overdose, rather than murder.
Knowing that, of all murders in Baltimore, about 30% of the victims were drug
addicts, and that the probability of a dead person having died of overdose is 50%
(without further evidence apart from the body) estimate the probability that the
detective’s hunch is correct. (For this problem, you may assume that the possible
only causes of death are overdose or murder).
Bayesian Methods
3.8.2 Bayesian parameter inference
(v) This problem takes you through the steps to derive the posterior distribution for
a quantity of interest θ, in the case of a Gaussian prior and Gaussian likelihood,
for the 1-dimensional case.
Let us assume that we have made N independent measurements, ˆx = {ˆx1, ˆx2,..., ˆxN}
of a quantity of interest θ (this could be the temperature of an object, the distance
of a galaxy, the mass of a planet, etc). We assume that each of the measurements
in independently Gaussian distributed with known experimental standard deviation σ. Let us denote the sample mean by ¯x, i.e.
Before we do the experiment, our state of knowledge about the quantity of interest θ is described by a Gaussian distribution on θ, centered around 0 (we can
always choose the units in such a way that this is the case). Such a prior might
come e.g. from a previous experiment we have performed. The new experiment is
however much more precise, i.e. Σ ≫σ. Our prior state of knowledge be written
in mathematical form as the following Gaussian pdf:
p(θ) ∼N (0,Σ 2).
a. Write down the likelihood function for the measurements and show that it can
be recast in the form:
L (θ) = L0 exp
where L0 is a constant that does not depend on θ.
b. By using Bayes theorem, compute the posterior probability for θ after the data
have been taken into account, i.e. compute p(θ|ˆx). Show that it is given by a
Gaussian of mean ¯x
Σ2+σ2/N and variance
Hint: you may drop the normalization constant from Bayes theorem, as it does
not depend on θ.
c. Show that as N →∞the posterior distribution becomes independent of the
(vi) We already encountered the coin tossing problem, but this time you’ll do it in the
Bayesian way.
A coin is tossed N times and heads come up H times.
a. What is the likelihood function? Identify clearly the parameter, θ, and the
b. What is a reasonable, non-informative prior on θ?
Bayesian Methods
c. Compute the posterior probability for θ. Recall that θ is the probability that a
single ﬂip will give heads. This integral will prove useful:
0 dθθ N(1−θ)M = Γ (N +1)Γ (M +1)
Γ (N +M +2)
d. Determine the posterior mean and standard deviation of θ.
e. Plot your results as a function of H for N = 10,100,1000.
f. † Generalize your prior to the Beta distribution,
p(θ|ν1,ν2) =
B(ν1,ν2)θ ν1−1(1−θ)ν2−1
where B(ν1,ν2) = Γ (ν1)Γ (ν2)/Γ (ν1 + ν2) is the beta function and the “hyperparameters” ν1,ν2 > 0. Clearly, a uniform prior is given by the choice
(ν1,ν2) = (1,1). Evaluate the dependency of your result to the choice of hyperparameters.
g. † What is the probability that the (N +1)-th ﬂip will give heads?
(vii) Prove Eqs. (82), (87) and (89) in the notes for the Gaussian linear model given
y = Fθ +ε.
Hint: recall this standard result for Gaussian integrals:
2(x−m)tΣ −1(x−m)
(viii) Now we specialize to the case n = 2, i.e. we have two parameters of interest,
θ = {θ1,θ2} and the linear function we want to ﬁt is given by
y = θ1 +θ2x.
(In the formalism above, the basis vectors are X1 = 1,X2 = x).
Table 1 gives an array of d = 10 measurements y = {y1,y2,...,y10}, together
with the values of the independent variable xi8. Assume that the uncertainty in the
same for all measurements, i.e. τi = 0.1 (i = 1,...,10). You may further assume
that measurements are uncorrelated. The data set is shown in the left panel of
a. Assume a Gaussian prior with Fisher matrix P = diag
 10−2,10−2
Find the posterior distribution for θ given the data, and plot it in 2 dimensions
in the (θ1,θ2) plane (see right panel of Fig. 7).
Use the appropriate contour levels to demarcate 1, 2 and 3 sigma joint credible
intervals of the posterior.
8 This data set is also provided with this arxiv submission as an ancillary data ﬁle called
LinearModelData.txt. It can be downloaded from a link below the usual article download
Bayesian Methods
Table 1 Data sets for the Gaussian linear model exercise. You may assume that all data points are
independently and identically distributed with standard deviation of the noise σ = 0.1.
Example data set
True model
Present posterior, 1−2−3m contours
Fig. 7 Left panel: data set for the Gaussian linear problem. The solid line shows the true value of
the linear model from which the data have been generated, subject to Gaussian noise. Right panel:
2D credible intervals from the posterior distribution for the parameters. The the blue diamond is the
Maximum Likelihood Estimator, from Eq. (85), whose value for this data set is x = −0.0136,y =
b. In a language of your choice, write an implementation of the Metropolis-
Hastings Markov Chain Monte Carlo algorithm, and use it to obtain samples
from the posterior distribution.
Plot equal weight samples9 in the (θ1,θ2) space, as well as marginalized 1dimensional posterior distributions for each parameter.
9 Posterior samples obtained via MCMC have a weight associated with them, given by the number of times the samplers has failed to jump from that particular location (i.e., the number of
repeat counts of the same coordinate location in parameter space). Producing a scatter plot of such
weighted samples would fail to reproduce visually their actual density, for each sample would have
a different weight associated to it. Equal weight samples are obtained from the MCMC chain by
normalizing all weights to unity (i.e, replacing weights wi by ui ≡wi/maxiwi, where i = 1,...,N
is the number of samples in the chain) and retaining each sample with probability given by ui.
Bayesian Methods
c. Compare the credible intervals that you obtained from the MCMC with the
analytical solution.
(ix) Supernovae type Ia can be used as standardizable candles to measure distances
in the Universe. This series of problems explores the extraction of cosmological
information from a simpliﬁed SNIa toy model.
The cosmological parameters we are interested in constraining are
C = {Ωm,ΩΛ,h}
where Ωm is the matter density (in units of the critical energy density) and ΩΛ
is the dark energy density, assumed here to be in the form of a cosmological
constant, i.e. w = −1 at all redshifts. In the following, we will ﬁx h = 0.72, where
the Hubble constant today is given by H0 = 100h km/s/Mpc, since the value of
H0 is degenerate with the (unknown) absolute magnitude of the SNIas, M.
In an FRW cosmology deﬁned by the parameters C , the distance modulus µ (i.e.,
the difference between the apparent and absolute magnitudes, µ = m −M) to a
SNIa located at redshift z is given by
µ(z,C ) = 5log
DL(z,Ωm,ΩΛ,h)
where DL denotes the luminosity distance to the SNIa. Recalling that DL =
cdL/H0, we can rewrite this as
µ(z,C ) = η +5logdL(z,Ωm,ΩΛ),
η = −5log 100h
and c is the speed of light in km/s. We have deﬁned the dimensionless luminosity
dL(z,Ωm,ΩΛ) = (1+z)
0 dz′[(1+z′)3Ωm+ΩΛ +(1+z′)2Ωκ]−1/2}.
The curvature parameter is given by the constraint equation
Ωκ = 1−Ωm −ΩΛ
and the function
for a ﬂat Universe (Ωκ = 0);
sin(x) for a closed Universe (Ωκ < 0);
sinh(x) for an open Universe (Ωκ > 0).
Bayesian Methods
We now assume that from each SNIa in our sample we have a measurement of
its distance modulus with Gaussian noise10, i.e., that the likelihood function for
each SNIa i (i = 1,...,N) is of the form
Li(zi,C ,M) =
( ˆµi −µ(zi,C ))2
The observed distance modulus is given by ˆµi = ˆmi−M, where ˆmi is the observed
apparent magnitude and M is the intrinsic magnitude of the SNIa. We assume that
each SN observation is independent of all the others.
The provided data ﬁle11 (SNIa SimulatedData) contains simulated observations from the above simpliﬁed model of N = 300 SNIa. The two columns
give the redshift zi and the observed apparent magnitude ˆmi. The observational
error is the same for all SNe, σi = σ = 0.4 mag for i = 1,...,N.
A plot of the data set is shown in the left panel of Fig. 8. The characteristics of
the simulated SNe are designed to mimic currently available datasets (see ).
a. We assume that the intrinsic magnitude12 is known and ﬁx M = M0 = −19.3
and that h = 0.72. We also assume that the observational error is known, given
by the value above.
Using a language of your choice, write a code to carry out an MCMC sampling
of the posterior probability for (Ωm,ΩΛ) and plot the resulting 68% and 95%
posterior regions, both in 2D and marginalized to 1D, using uniform priors on
(Ωm,ΩΛ) (be careful to deﬁne them explicitly).
You should obtain a result similar to the 2D plot shown in the right panel of
b. † Add the quantity σ (the observational error) to the set of unknown parameters and estimate it from the data along with C . Notice that since σ is a
“scale parameter”, the appropriate (improper) prior is p(σ) ∝1/σ (see for
a justiﬁcation).
c. The location of the peaks in the CMB power spectrum gives a precise measurement of the angular diameter distance to the last scattering surface, divided by the sound horizon at decoupling. This approximately translates into
an effective constraint (see , Fig. 20) on the following degenerate combi-
10 We neglect the important issue of applying the empirical corrections known as Phillip’s relations
to the observed light curve. This is of fundamental important in order to reduce the scatter of SNIa
within useful limits for cosmological distance measurements, but it would introduce a technical
complication here without adding to the fundamental scope of this exercise. Furthermore, the correct likelihood function is not of the Gaussian form given here. For a fully Bayesian treatment, see
e.g. .
11 The dataﬁle is provided with this arxiv submission as ancillary data ﬁle. It can be downloaded
from a link below the usual article download links.
12 In reality the SNIas intrinsic magnitude is not the same for all of the objects, but there is an
“intrinsic dispersion” (even after Phillips’ corrections) reﬂecting perhaps intrinsic variability in the
explosion mechanism, or environmental parameters which are currently poorly understood.
Bayesian Methods
redshift, z
observed magnitude, m
Student Version of M
Student Version of M
Fig. 8 Left: Simulated SNIa dataset, SNe simulated.dat. The solid line is the true underlying
cosmology. Right: constraints on Ωm,ΩΛ from this dataset, with contours delimiting 2D joint 68%
and 95% credible regions (uniform priors on the variables Ωm,ΩΛ, assuming M = M0 ﬁxed and
h = 0.72). The red cross denotes the true value.
nation of Ωm and ΩΛ:
1.41ΩΛ +Ωm = 1.30±0.04.
Add this constraint (assuming a Gaussian likelihood, with the above mean and
standard deviation) to the SNIa likelihood and plot the ensuing combined 2D
and 1D limits on (Ωm,ΩΛ).
d. The measurement of the baryonic acoustic oscillation scale in the galaxy
power spectrum at small redshift gives an effective constraint on the angular
diameter distance DA out to z ∼0.6. This measurement can be summarized
DA(z = 0.57) = (1408±45) Mpc.
Add this constraints (again assuming a Gaussian likelihood) to the above
CMB+SNIa limits and plot the resulting combined 2D and 1D limits on
Hint: recall that DL(z) = (1+z)2DA(z).
3.9 Solutions to selected exercises
3.9.1 Bayesian reasoning
(i) a. Let BB = 1 denote the proposition that your friend has the virus, and BB = 0
that she does not. We use + (−) to denote the test returning a positive (nega-
Bayesian Methods
tive) result. We know from the reliability of the test that
P(+|BB = 1) = 0.95
P(+|BB = 0) = 0.05 hence
P(−|BB = 0) = 0.95.
Given that 1% of the population has the virus, the probability of being one of
them (before taking the test) is P(BB = 1) = 0.01, while P(BB = 0) = 0.99.
b. The probability of your friend having the virus after she has tested positive is
P(BB = 1|+) = P(+|BB = 1)P(BB = 1)
We can compute the denominator as follows, by combining the marginalization rule with the product rule (a procedure that is sometimes called “expanding the discourse”):
P(+) = P(+|BB = 1)P(BB = 1)+P(+|BB = 0)P(BB = 0)
= 0.95·0.01+0.05·0.99 = 0.059.
Therefore the probability that your friend has the virus is much less than 95%,
P(BB = 1|+) = 0.95·0.01
= 0.16 = 16%.
c. From the above, we have that
P(BB = 1|+) =
P(+|BB = 1)P(BB = 1)
P(+|BB = 1)P(BB = 1)+P(+|BB = 0)P(BB = 0). (133)
We want to achieve 99% probability that the person has BB given that they
tested positive, i.e., P(BB = 1|+) = 0.99, and we need to solve the above
equation for the reliability, i.e. P(+|BB = 1).
We ﬁrst assume that P(+|BB = 0) = 0.05, as in part (a). Since P(BB = 1) =
10−6, it follows that P(BB = 0) = 1−P(BB = 1) ≈1. Then Eq. (133) becomes
P(+|BB = 1)10−6
P(+|BB = 1)10−6 +0.05×1 ≈P(+|BB = 1)10−6
It is clear that this equation has no solution for P(+|BB = 1) ≤1. This means
that for a 5% false positive rate and for the given incidence P(BB = 1) it is
impossible to obtain a test that is 99% reliable. Therefore in order to achieve
99% reliability, the false positive rate, P(+|BB = 0), has to be reduced, as
d. Let us denote by x = P(+|BB = 1) = P(−|BB = 0) the reliability of the test.
Then requiring a value of 99% for P(BB = 1|+) amounts to solving for x the
following equation:
Bayesian Methods
0.99 = P(BB = 1|+) =
xP(BB = 1)
xP(BB = 1)+(1−x)P(BB = 0)
where P(BB = 1) = 10−6 and P(BB = 0) = 1−10−6 ≈1. This gives for x
which means that the the reliability of the test ought to be in excess of 1 in 108.
This is obviously not feasible and hence it is important to screen people before
administering the test, i.e., to only test people who already show symptoms of
the condition.
(ii) a. Let’s assume that you have chosen door A. If the prize is indeed behind that
door, than the presenter opens randomly one of B or C (with probability 1/2).
If the prize is behind door B, then he must open door C (and viceversa). This
P(B open|prize behind A) = 1
P(C open|prize behind A) = 1
P(B open|prize behind B) = 0
P(C open|prize behind B) = 1
P(B open|prize behind C) = 1
P(C open|prize behind C) = 0
If the presenter opens door C, we obtain the probability that the prize is behind
each of the doors by inverting the order of conditioning as follows:
P(prize behind A|C open) = P(C open|prize behind A)P(A)
P(prize behind B|C open) = P(C open|prize behind B)P(B)
At the beginning of the show, the probability that the prize is behind one of
the 3 doors is the same:
P(A) = P(B) = P(C) = 1
We can compute the denominator in Eqs. (140) and (141) using again the rules
of probability (in particular, the marginalisation rule):
P(C open) = P(C open|prize behind A)P(A)
+P(C open|prize behind B)P(B)
+P(C open|prize behind C)P(C)
Bayesian Methods
From Eqs. (140) et (141) it follows
P(prize behind A|C open) = 1
P(prize behind B|C open) = 2
Therefore you should switch in order to increase your probability of winning
(from 1/3 to 2/3).
If you are still unconvinced, here is a variant to hone your intuition: there are
1000 doors, and you pick one at the beginning. The presenter then opens 998
doors, revealing that there is no prize behind them (and he knew this when he
opened them). At this point you can either switch to the last remaining closed
door, or stick with the one you had originally chosen. Which way to go is at
this point a no-brainer!
b. In the second scenario, you choose between doors B and C randomly, and
therefore the amount of information in the problem changes (in the previous
case, the presenter knew behind which door the prize is). Eqs. (138) et (139)
are modiﬁed as follows:
P(B open|prize behind B) = 1
P(C open|prize behind B) = 1
P(B open|prize behind C) = 1
P(C open|prize behind C) = 1
In this case, the probability of winning is not modiﬁed by you opening a further door at random, and in fact:
P(prize behind A|C open) = 1
P(prize behind B|C open) = 1
Another, more formal argument goes as follows. The prior is given by Eq. (142)
P(C open) = ∑
P(i open|prize behind i)P(prize behind i)
This is because
P(C open|prize behind A) = P(C open|prize behind B) = 1
P(C open|prize behind C) = 0
since this statement is incompatible with the evidence (when C is opened at
random by you, you discover that the price is not there!). So:
Bayesian Methods
P(prize behind A|C open) = P(C open|prize behind A)P(prize behind A)
= (1/2)(1/3)
as claimed.
(iii) Let ST denote the proposition “statement S is true”. Let AT denote the statement
“politician A tells the truth, AL denote the statement “politician A lies” and similarly for BT and BL. Under your prior, P(AT) = 4/5, P(AL) = 1/5, P(BT) = 1/4
and P(BL) = 3/4. Let “BST“ denote the statement “Politician B says S is true“.
Then using Bayes theorem:
P(ST|BST) = P(BST|ST)P(ST)
In the above equation, P(ST) = P(AT) = 4/5, as you don’t know anything else
about statement S except what you heard from politician A, whom you trust to be
truthful with probabilty P(AT). Also, P(BST|ST) = P(BT) = 1/4, for politician
B will say that statement S is true (if this is indeed the case) with probability
P(BT). It remains to compute
P(BST) = P(BST|ST)P(ST)+P(BST|not ST)P(not ST)
= P(BT)P(AT)+P(BL)P(AL).
So the posterior probability for S to be true after you have heard both politicians
P(ST|BST) =
P(BT)P(AT)
P(BT)P(AT)+P(BL)P(AL)
= 4/7 ≈57%.
(iv) Let us denote by od = 1 the statement “Mr Dunlop died because of drugs overdose”; by Dd = 1 the statement “Mr Dunlop is dead” and by u = 1 the statement
“Mr Dunlop used drugs”.
We are looking for the posterior probability that Fuzzy Dunlop died of overdose,
given that he was a drug addict (u = 1) and that he is dead (Dd = 1):
P(od = 1|Dd = 1,u = 1)
P(u = 1|od = 1,Dd = 1)P(od = 1|Dd = 1)
P(u = 1|od = 1,Dd = 1)P(od = 1|Dd = 1)+P(u = 1|od = 0,Dd = 1)P(od = 0|Dd = 1)
From the problem, we have that the probability of being a drug user and having
been murdered (assuming that people only die of either overdose or murder in
Baltimore) is P(u = 1|od = 0,Dd = 1) = 0.3. Also, the probability of the person
Bayesian Methods
having died of overdose (given that we have the body) is 50%, hence P(od =
1|Dd = 1) = 50% so P(od = 0|Dd = 1) = 50%.
Finally, we need to estimate the probability that Mr Dunlop was a drug user, given
that he died of overdose, P(u = 1|od = 1,Dd = 1). It seems highly unlikely that
somebody would die of overdose the ﬁrst time they try drugs, so perhaps we can
assign P(u = 1|od = 1,Dd = 1) = 0.9.
So we have that
P(od = 1|Dd = 1,u = 1) =
1+ P(u=1|od=0,Dd=1)P(od=0|Dd=1)
P(u=1|od=1,Dd=1)P(od=1|Dd=1)
1+3/9 = 75%.
How sensitive is this conclusion to our guess for P(u = 1|od = 1,Dd = 1)?
Changing this to P(u = 1|od = 1,Dd = 1) = 0.5 (we are agnostic as to whether
a drug overdose is more likely for usual drugs consumers or for novices) gives a
posterior P(od = 1|Dd = 1,u = 1) = 62%, while increasing it to P(u = 1|od =
1,Dd = 1) = 0.99 (most people overdosing are drugs users) gives P(od = 1|Dd =
1,u = 1) = 77%. So even looking at the two extreme cases we can still bracket
our conclusion to be in the range from 62% to 77%.
3.9.2 Bayesian parameter inference
(v) a. The likelihood is given by
Consider now the exponential term:
θ 2 −2θ ¯x+ ¯x2 −¯x2 + 1
2σ2 (θ −¯x)2 + N
So the likelihood can be written as
L(θ) = L0 exp
where L0 is a constant that does not depend on θ.
Bayesian Methods
b. The posterior pdf for θ is proportional to the likelihood times the prior (dropping the normalization constant in Bayes’ Theorem):
p(θ|ˆx) ∝L (θ)p(θ) ∝exp
where we have dropped normalization constants which do not depend on θ
and we have used the Gaussian form of the prior. Collecting terms that depend
on θ in the exponent and completing the square we get
p(θ|ˆx) ∝exp
which shows that the posterior for θ is a Gaussian with the mean and variance
as given in the question.
c. When N →∞, we have that the variance
→σ2/N (as N
and the mean ¯x
→¯x (as Σ 2 ≫σ2
N and the fraction goes to unity). Thus
the posterior pdf becomes
p(θ|ˆx) →exp
which shows that the posterior converges to the likelihood and the prior dependence disappears.
d. From the above result, we can use the posterior pdf to compute the posterior
mean of θ:
θ p(θ|ˆx)dθ = ¯x.
Therefore the posterior mean tends to the sample mean, ¯x, which as we know
is also the MLE for the mean.
4 Bayesian model selection
4.1 The three levels of inference
For the purpose of this discussion, it is convenient to divide Bayesian inference in
three different levels:
(i) Level 1: We have chosen a model M0, assumed true, and we want to learn about
its parameters, θ0. E.g.: we assume ΛCDM to be the true model for the Universe
and try to constrain its parameters. This is the usual parameter inference step.
Bayesian Methods
(ii) Level 2: We have a series of alternative models being considered (M1,M2,...)
and we want to determine which of those is in best agreement with the data.
This is a problem of model selection, or model criticism. For example, we might
want to decide whether a dark energy equation of state w = −1 is a sufﬁcient
description of the available observations or whether we need an evolving dark
energy model, w = w(z).
(iii) Level 3: Of the N models considered in Level 2, there is no clear “best” model.
We want to report inferences on parameters that account for this model uncertainty. This is the subject of Bayesian model averaging. For example, we want to
determine Ωm independently of the assumed dark energy model.
The Frequentist approach to model criticism is in the form of hypothesis testing
(e.g., “chi-squared-per-degree-of-freedom“ type of tests). One ends up rejecting (or
not) a null hypothesis H0 based on the p-value, i.e., the probability of getting data as
extreme or more extreme than what has been observed if one assumes that H0 is true.
Notice that this is not the probability for the hypothesis! Classical hypothesis testing
assumes the hypothesis to be true and determines how unlikely are our observations
given this assumption. This is arguably not the quantity we are actually interested
in, namely, the probability of the hypothesis itself given the observations in hand.
Ref. is a highly recommended read on this topic.
The Bayesian approach takes the view that there is no point in rejecting a model
unless there are speciﬁc alternatives available: it takes therefore the form of model
comparison. The key quantity for model comparison is the Bayesian evidence.
Bayesian model comparison automatically implements a quantitative version of Occam’s razor, i.e., the notion that simpler models ought to be preferred if they can
explain the data sufﬁciently well.
4.2 The Bayesian evidence
4.2.1 Deﬁnition
The evaluation of a model’s performance in the light of the data is based on the
Bayesian evidence. This is the normalization integral on the right–hand–side of
Bayes’ theorem, Eq. (72), which we rewrite here conditioning explicitly on the
model under consideration, M , with parameter space ΩM :
p(d|θ,M )p(θ|M )dθ
(Bayesian evidence).
The Bayesian evidence is the average of the likelihood under the prior for a speciﬁc model choice. From the evidence, the model posterior probability given the
data is obtained by using Bayes’ Theorem to invert the order of conditioning:
p(M |d) ∝p(M )p(d|M ),
Bayesian Methods
where we have dropped an irrelevant normalization constant that depends only on
the data and p(M ) is the prior probability assigned to the model itself. Usually
this is taken to be non–committal and equal to 1/Nm if one considers Nm different
When comparing two models, M0 versus M1, one is interested in the ratio of the
posterior probabilities, or posterior odds, given by
p(M1|d) = B01
Deﬁnition 8. The Bayes factor B01 is the ratio of the models’ evidences:
B01 ≡p(d|M0)
(Bayes factor).
A value B01 > (<) 1 represents an increase (decrease) of the support in favour of
model 0 versus model 1 given the observed data (see for more details on Bayes
Bayes factors are usually interpreted against the Jeffreys’ scale for the
strength of evidence, given in Table 2. This is an empirically calibrated scale, with
thresholds at values of the odds of about 3 : 1, 12 : 1 and 150 : 1, representing weak,
moderate and strong evidence, respectively.
|lnB01| Odds
Probability Strength of evidence
Inconclusive
Weak evidence
Moderate evidence
∼150 : 1 0.993
Strong evidence
Table 2 Empirical scale for evaluating the strength of evidence when comparing two models,
M0 versus M1 (so–called “Jeffreys’ scale”). Threshold values are empirically set, and they occur
for values of the logarithm of the Bayes factor of |lnB01| = 1.0, 2.5 and 5.0. The right–most
column gives our convention for denoting the different levels of evidence above these thresholds.
The probability column refers to the posterior probability of the favoured model, assuming non–
committal priors on the two competing models, i.e., p(M0) = p(M1) = 1/2 and that the two
models exhaust the model space, p(M0|d)+ p(M1|d) = 1.
4.2.2 The Occam’s razor effect
We begin by considering the example of two nested models. Consider two competing models: M0 predicting that a parameter θ = 0 with no free parameters, and M1
which assigns to it a Gaussian prior distribution with 0 mean and variance Σ 2. Assume we perform a measurement of θ described by a normal likelihood of standard
deviation σ, and with the maximum likelihood value lying λ standard deviations
away from 0, i.e. |θmax/σ| = λ. Then the Bayes factor between the two models is
Bayesian Methods
given by, from Eq. (167)
1+(σ/Σ)−2 exp
2(1+(σ/Σ)2)
For λ ≫1, corresponding to a detection of the new parameter with high signiﬁcance, the exponential term dominates and B01 ≪1, favouring the more complex
model with a non–zero extra parameter, in agreement with what one would get using Frequentist hypothesis testing. But if λ ∼
< 1 and σ/Σ ≪1 (i.e., the likelihood
is much more sharply peaked than the prior and in the vicinity of 0), then the prediction of the simpler model that θ = 0 has been conﬁrmed. This leads to the Bayes
factor being dominated by the Occam’s razor term, and B01 ≈Σ/σ, i.e. evidence accumulates in favour of the simpler model proportionally to the volume of “wasted”
parameter space. If however σ/Σ ≫1 then the likelihood is less informative than
the prior and B01 →1, i.e. the data have not changed our relative belief in the two
In the above example, if the data are informative with respect to the prior on
the extra parameter (i.e., for σ/Σ ≪1) the logarithm of the Bayes factor is given
approximately by
lnB01 ≈ln(Σ/σ)−λ 2/2,
where as before λ gives the number of sigma away from a null result (the “signiﬁcance” of the measurement). The ﬁrst term on the right–hand–side is approximately
the logarithm of the ratio of the prior to posterior volume. We can interpret it as
the information content of the data, as it gives the factor by which the parameter
space has been reduced in going from the prior to the posterior. This term is positive for informative data, i.e. if the likelihood is more sharply peaked than the prior.
The second term is always negative, and it favours the more complex model if the
measurement gives a result many sigma away from the prediction of the simpler
model (i.e., for λ ≫0). We are free to measure the information content in base–10
logarithm (as this quantity is closer to our intuition, being the order of magnitude of
our information increase), and we deﬁne the quantity I10 ≡log10 (Σ/σ). Figure 9
shows contours of |lnB01| = const for const = 1.0,2.5,5.0 in the (I10,λ) plane, as
computed from Eq. (169). The contours delimit signiﬁcative levels for the strength
of evidence, according to the Jeffreys’ scale (Table 2). For moderately informative
data (I10 ≈1 −2) the measured mean has to lie at least about 4σ away from 0 in
order to robustly disfavor the simpler model (i.e., λ ∼
> 4). Conversely, for λ ∼
highly informative data (I10 ∼
> 2) do favor the conclusion that the extra parameter
is indeed 0. In general, a large information content favors the simpler model, because Occam’s razor penalizes the large volume of “wasted” parameter space of the
extended model.
An useful properties of Figure 9 is that the impact of a change of prior can be
easily quantiﬁed. A different choice of prior width (i.e., Σ) amounts to a horizontal
shift across Figure 9, at least as long as I10 > 0 (i.e., the posterior is dominated by
the likelihood). Picking more restrictive priors (reﬂecting more predictive theoretical models) corresponds to shifting the result of the model comparison to the left of
Bayesian Methods
Figure 9, returning an inconclusive result (white region) or a prior–dominated outcome (hatched region). Notice that results in the 2–3 sigma range, which are fairly
typical in cosmology, can only support the more complex model in a very mild way
at best (odds of 3 : 1 at best), while actually being most of the time either inconclusive or in favour of the simpler hypothesis (pink shaded region in the bottom right
Notice that Bayesian model comparison is usually conservative when it comes
to admitting a new quantity in our model, even in the case when the prior width
is chosen “incorrectly” (whatever that means!). In general the result of the model
comparison will eventually override the “wrong” prior choice (although it might
take a long time to do so), exactly as it happens for parameter inference.
Bayesian model selection does not penalize parameters which are unconstrained
by the data. This is easily seen from Eq. (169): if a parameter is unconstrained, its
posterior width σ is approximately equal to the prior width, Σ, and the Occam’s
razor penalty term goes to zero. In such a case, consideration of the Bayesian model
complexity might help in judging model performance, see for details.
Fig. 9 Illustration of Bayesian model comparison for two nested models, where the more complex
model has one extra parameter. The outcome of the model comparison depends both on the information content of the data with respect to the a priori available parameter space, I10 (horizontal
axis) and on the quality of ﬁt (vertical axis, λ, which gives the number of sigma signiﬁcance of the
measurement for the extra parameter). Adapted from .
4.2.3 Comparison with p-values
Classical hypothesis testing relies on comparing the observed value of some test
statistics, T(X) (where X is a RV with density p(X|θ)) with its the expected distribution under a null hypothesis (usually denoted by H0). The hypothesis test is to
Bayesian Methods
compare H0 : θ = θ0 vs an alternative H1 : θ ̸= θ0. The test statistics is so chosen
that more extreme values denote a stronger disagreement with the null.
Deﬁnition 9. The p-value (or observed signiﬁcance level) is given by the probability under the null that T achieves values as extremes or more extremes that have
been observed (assuming here that the larger the value of T, the stronger the disagreement):
℘= p(T(X) ≥T obs|H0).
As an example, consider the case where under H0, xi ∼N (θ0,σ) for ﬁxed θ0
(the null hypothesis), while under the alternative H1, x ∼N (θ,σ) and n data samples are available (with σ known). The usual test statistics is then given by
T(X) = √n| ¯X −θ0|
The p-value is then given by
℘= 2(1−erf(T obs))
where the observed value of the test statistics is
T obs = √n|¯x−θ0|
and ¯x is the sample mean.
The classical procedure of reporting the observed℘leads to a gross misrepresentation of the evidence against the null (this is in contrast with the Neyman-Person
procedure of setting a threshold p-value before the experiment is performed, and
then only reporting whether or not that threshold has been exceeded). This is because it does not obey the frequentist principle: in repeated use of a statistical procedure, the long–run average actual error should not be greater than the long–run
average reported error . This means that, for example, of all reported 95% con-
ﬁdence results, on average many more than 5% turn out to be wrong, and typically
more than 50% are wrong.
Jeffreys famously criticised the use of p-values thus ( cited in ):
I have always considered the arguments for the use of [p-values] absurd. They amount to
saying that a hypothesis that may or may not be true is rejected because a greater departure
from the trial value was improbable; that is, that it has not predicted something that has not
An interesting illustration is given in . Consider the case described above, and
let us generate data from a random sequence of null hypothesis (H0) and alternatives
(H1), with θ0 = 0, σ = 1 and θ ∼N (0,1). Suppose that the proportion of nulls and
alternatives is equal. We then compute the p-value using Eq. (172) and we select all
the tests that give ℘∈[α −ε,α +ε], for a certain value of α and ε ≪α (the exact
value of ε is unimportant). Among such results, which rejected the null hypothesis
at the 1 −α level, we then determine the proportion that actually came from the
Bayesian Methods
null, i.e. the percentage of wrongly rejected nulls. The results are shown in Table 3.
We notice that among all the “signiﬁcant” effects at the 95% level about 50% are
wrong, and in general when there is only a single alternative at least 29% of the 95%
conﬁdence level results will be wrong.
p-value sigma fraction of true nulls lower bound
Table 3 Proportion of wrongly rejected nulls among all results reporting a certain p-value (simulation results). The ”lower bound” column gives the minimum fraction of true nulls (derived in ).
This illustrates that the reported p-value is not equal to the fraction of wrongly rejected true nulls,
which can be considerably worse.
The root of this striking disagreement with a common misinterpretation of the
p-value (namely, that the p-value gives the fraction of wrongly rejected nulls
in the long run) is twofold. While the p-value gives the probability of obtaining
data that are as extreme or more extreme than what has actually been observed
assuming the null hypothesis is true, one is not allowed to interpret this as the
probability of the null hypothesis to be true, which is actually the quantity
one is interested in assessing. The latter step requires using Bayes theorem
and is therefore not deﬁned for a frequentist. Also, quantifying how rare the
observed data are under the null is not meaningful unless we can compare this
number with their rareness under an alternative hypothesis.
A useful rule of thumb is obtained by : it is recommended to think of a nσ
result as of a (n −1)σ result. Reducing the number of sigma signiﬁcance brings
the naive p-value interpretation in better alignment with the above results. All these
points are discussed in greater detail in .
4.3 Computation of the evidence
4.3.1 Nested sampling
A powerful and efﬁcient alternative to classical MCMC methods has emerged in the
last few years in the form of the so–called “nested sampling” algorithm, out forward
by John Skilling . Although the original motivation for nested sampling was to
compute the evidence integral of Eq. (164), the development of the multi–modal
nested sampling technique (and more recently the PolyChord algorithm ,
as well as diffusive nested sampling, implemented in the DNest4 code ) provides
Bayesian Methods
a powerful and versatile algorithm that can sample efﬁciently from complex, multimodal likelihood surfaces, see Fig. 10.
Fig. 10 Example of posterior reconstruction using Nested Sampling. Left panel: target likelihood
in a 2D parameter space (x,y). Right panel: reconstructed posterior (with ﬂat priors) using Nested
Sampling. From Ref. .
The gist of nested sampling is that the multi–dimensional evidence integral is
recast into a one–dimensional integral, by deﬁning the prior volume X as dX ≡
p(θ|M )dθ so that
L (θ)>λ p(θ|M )dθ
where L (θ) ≡p(d|θ,M ) is the likelihood function and the integral is over the
parameter space enclosed by the iso–likelihood contour L (θ) = λ. So X(λ) gives
the volume of parameter space above a certain level λ of the likelihood.
The Bayesian evidence, Eq. (164), can be written as
0 L (X)dX,
where L (X) is the inverse of Eq. (174). Samples from L (X) can be obtained by
drawing uniformly samples from the likelihood volume within the iso–contour surface deﬁned by λ. This is the difﬁcult part of the algorithm.
Finally, the 1–dimensional integral of Eq. (175) can be obtained by simple
quadrature, thus
p(d|M ) ≈∑
where the weights are Wi = 1
2(Xi−1 −Xi+1), see for details13.
implementing
 
(MultiNest)
 (DNest4) .
Bayesian Methods
4.3.2 Thermodynamic integration
Thermodynamic integration computes the evidence integral by deﬁning
L (θ)µ p(θ|M )dθ,
where µ is an annealing parameter and L (θ) ≡p(d|θ,M ). Obviously the desired
evidence corresponds to E(1). One starts by performing a standard MCMC sampling with µ = 0 (i.e., sampling from the prior), then gradually increases µ to 1
according to some annealing schedule. The log of the evidence is then given by
lnE(1) = lnE(0)+
0 ⟨lnL ⟩µdµ,
where the average log-likelihood is taken over the posterior with annealing parameter µ, i.e.
ΩM (lnL )L (θ)µ p(θ|M )dθ
ΩM L (θ)µ p(θ|M )dθ
The drawback is that the end result might depend on the annealing schedule used
and that typically this methods takes 10 times as many likelihood evaluations as
parameter estimation. For an overview of so-called “population Monte Carlo” algorithms and annealed importance sampling, see .
4.3.3 Laplace approximation
An approximation to the Bayesian evidence can be obtained when the likelihood
function is unimodal and approximately Gaussian in the parameters. Expanding the
likelihood around its peak to second order one obtains the Laplace approximation
p(d|θ,M ) ≈Lmax exp
2(θ −θmax)tL(θ −θmax)
where θmax is the maximum–likelihood point, Lmax the maximum likelihood value
and L the likelihood Fisher matrix (which is the inverse of the covariance matrix for
the parameters). Assuming as a prior a multinormal Gaussian distribution with zero
mean and Fisher information matrix P one obtains for the evidence, Eq. (164)
p(d|M ) = Lmax
|P|−1/2 exp
2(θmaxtLθmax −θ
where the posterior Fisher matrix is F = L + P and the posterior mean is given by
θ = F−1Lθmax.
Bayesian Methods
4.3.4 The Savage-Dickey density ratio
A useful approximation to the Bayes factor, Eq. (167), is available for situations in
which the models being compared are nested into each other, i.e. the more complex
model (M1) reduces to the original model (M0) for speciﬁc values of the new parameters. This is a fairly common scenario when one wishes to evaluate whether
the inclusion of the new parameters is supported by the data (e.g., do we need
isocurvature contributions to the initial conditions for cosmological perturbations,
or whether a curvature term in Einstein’s equation is needed, or whether a non–scale
invariant distribution of the primordial ﬂuctuation is preferred).
Writing for the extended model parameters θ = (φ,ψ), where the simpler model
M0 is obtained by setting ψ = 0, and assuming further that the prior is separable
(which is usually the case), i.e. that
p(φ,ψ|M1) = p(ψ|M1)p(φ|M0),
the Bayes factor can be written in all generality as
B01 = p(ψ|d,M1)
This expression is known as the Savage–Dickey density ratio (see and references therein). The numerator is simply the marginal posterior under the more
complex model evaluated at the simpler model’s parameter value, while the denominator is the prior density of the more complex model evaluated at the same point.
This technique is particularly useful when testing for one extra parameter at the
time, because then the marginal posterior p(ψ|d,M1) is a 1–dimensional function
and normalizing it to unity probability content only requires a 1–dimensional integral, which is simple to do using for example the trapezoidal rule.
4.3.5 Information criteria for approximate model selection
Sometimes it might be useful to employ methods that aim at an approximate model
selection under some simplifying assumptions that give a default penalty term for
more complex models, which replaces the Occam’s razor term coming from the
different prior volumes in the Bayesian evidence .
Akaike Information Criterion (AIC): the AIC is an essentially frequentist criterion that sets the penalty term equal to twice the number of free parameters in the
AIC ≡−2lnLmax +2k
where Lmax ≡p(d|θmax,M ) is the maximum likelihood value.
Bayesian Information Criterion (BIC): the BIC follows from a Gaussian approximation to the Bayesian evidence in the limit of large sample size:
Bayesian Methods
BIC ≡−2lnLmax +klnN
where k is the number of ﬁtted parameters as before and N is the number of data
points. The best model is again the one that minimizes the BIC.
Deviance Information Criterion (DIC): the DIC can be written as
DIC ≡−2DKL +2Cb.
In this form, the DIC is reminiscent of the AIC, with the lnLmax term replaced by
the estimated KL divergence DKL and the number of free parameters by the effective
number of parameters, Cb (see for deﬁnitions).
The information criteria ought to be interpreted with care when applied to real
situations. Comparison of Eq. (185) with Eq. (184) shows that for N > 7 the BIC penalizes models with more free parameters more harshly than the AIC. Furthermore,
both criteria penalize extra parameters regardless of whether they are constrained
by the data or not, unlike the Bayesian evidence. In conclusion, what makes the information criteria attractive, namely the absence of an explicit prior speciﬁcation,
represents also their intrinsic limitation.
4.4 Example: model selection for the inﬂationary landscape
The inﬂationary model comparison carried out in Ref. is an example of
the application of the above formalism to the problem of deciding which theoretical
model is the best description of the available observations. Although the technical
details are fairly involved, the underlying idea can be sketched as follows.
The term “inﬂation” describes a period of exponential expansion of the Universe
in the very ﬁrst instants of its life, some 10−32 seconds after the Big Bang, during
which the size of the Universe increased by at least 25 orders of magnitude. This
huge and extremely fast expansion is required to explain the observed isotropy of
the cosmic microwave background on large scales. It is believed that inﬂation was
powered by one or more scalar ﬁelds. The behaviour of the scalar ﬁeld during inﬂation is determined by the shape of its potential, which is a real-valued function V(φ)
(where φ denotes the value of the scalar ﬁeld). The detailed shape of V(φ) controls
the duration of inﬂation, but also the spatial distribution of inhomogeneities (perturbations) in the distribution of matter and radiation emerging from inﬂation. It is
from those perturbations that galaxies and cluster form out of gravitational collapse.
Hence the shape of the scalar ﬁeld can be constrained by observations of the large
scale structures of the Universe and of the CMB anisotropies.
Theories of physics beyond the Standard Model motivate certain functional
forms of V(φ), which however typically have a number of free parameters, θ. The
fundamental model selection question is to use cosmological observations to discriminate between alternative models for V(φ) (and hence alternative fundamental
theories). The major obstacle to this programme is that very little if anything at all
Bayesian Methods
is known a priori about the free parameters θ describing the inﬂationary potential.
What is worse, such parameters can assume values across several orders of magnitude, according to the theory. Hence the Occam’s razor effect of Bayesian model
comparison can vary in a very signiﬁcant way depending on the prior choices for
Ψ. Furthermore, a non-linear reparameterization of the problem (which leaves the
physics invariant) does in general change the Occam’s razor factor, and hence the
model comparison result.
In Ref. inﬂationary model selection was considered from a principled point
of view. The Bayesian evidence and complexity of 198 slow-roll single-ﬁeld models
of inﬂation was computed, using the Planck 2013 Cosmic Microwave Background
data. The models considered represented an almost complete and systematic scan
of the entire landscape of inﬂationary scenarios proposed so far (More recently,
this works has been extended to more complex scenarios with more than one scalar
ﬁeld ). The analysis singled out the most probable models (from an Occam’s razor point of view) that are compatible with Planck data. The resulting Bayes factors
(normalised to the case of Higgs Inﬂation) are displayed in Fig. 11.
4.5 Open challenges
I conclude by listing what I think are some of the open questions and outstanding
challenges in the application of Bayesian model selection to cosmological model
• Is Bayesian model selection always applicable? The Bayesian model comparison approach as applied to cosmological and particle physics problems has
been strongly criticized by some authors. E.g., George Efstathiou and Bob
Cousins pointed out (in different contexts) that often insufﬁcient attention is given to the selection of models and of priors, and that this might lead to
posterior model probabilities which are largely a function of one’s unjustiﬁed assumptions. This draws attention to the difﬁcult question of how to choose priors
on phenomenological parameters, for which theoretical reasoning offers poor or
no guidance (as in the inﬂationary model comparison example above).
• How do we deal with Lindley’s paradox? It is simple to construct examples of
situations where Bayesian model comparison and classical hypothesis testing
disagree (Lindley’s paradox ). This is not surprising, as frequentist hypothesis testing and Bayesian model selection really ask different questions of the
data . Furthermore, as the scaling with the number of data points is different,
there isn’t even a guarantee that the two approaches will agree in the asymptotic
regime of large data sample size. As Louis Lyons aptly put it:
Bayesians address the question everyone is interested in by using assumptions no–one
believes, while frequentists use impeccable logic to deal with an issue of no interest to
anyone .
Bayesian Methods
Fig. 11 Bayes factors (bars) and absolute upper bound to the Bayes factors (arrows) for inﬂationary
scenarios, with Higgs inﬂation as the reference model (see for further details).
However, such a disagreement is more likely to occur in situations where the signal is weak, which are precisely the kind of “frontier science” cases which are
the most interesting ones (e.g., discovery claims). Is there a way to evaluate e.g.
the loss function from making the “wrong” decision about rejecting/accepting a
model? In this context, perhaps a decision theoretical approach would be beneﬁcial: the loss function of making the wrong decision has to be explicitly formulated, thus helping putting the user’s subjective biases and values in the open.
• How do we assess the completeness of the set of known models? Bayesian model
selection always returns a best model among the ones being compared, even
though that model might be a poor explanation for the available data. Is there
a principled way of constructing an absolute scale for model performance in a
Bayesian Methods
Bayesian context? (for example, along the lines of the notion of Bayesian doubt,
introduced in ).
• Is Bayesian model averaging useful? Bayesian model averaging can be used
to obtain ﬁnal inferences on parameters which take into account the residual model uncertainty (examples of applications in cosmology can be found
in ). However, it also propagates the prior sensitivity of model
selection to the level of model-averaged parameter constraints. Is it useful to produce model-averaged parameter constraints, or should this task be left to the user,
by providing model-speciﬁc posteriors and Bayes factors instead?
• Is there such a thing as a “correct” prior? In fundamental physics, models and parameters (and their priors) are supposed to represent (albeit in an idealized way)
the real world, i.e., they are not simply useful representation of the data (as they
are in other statistical problems, e.g. as applied to social sciences). In this sense,
one could imagine that there exist a “correct” prior for e.g. the parameters θ of
our cosmological model, which could in principle be derived from fundamental theories such as string theory (e.g., the distribution of values of cosmological
parameters across the landscape of string theory ). This raises interesting statistical questions about the relationship between physics, reality and probability.
4.6 Exercises
(i) A coin is tossed N = 250 times and it returns H = 140 heads. Evaluate the evidence that the coin is biased using Bayesian model comparison and contrast your
ﬁndings with the usual (frequentist) hypothesis testing procedure (i.e. testing the
null hypothesis that pH = 0.5). Discuss the dependency on the choice of priors.
(ii) In 1919 two expeditions sailed from Britain to measure the light deﬂection from
stars behind the Sun’s rim during the solar eclipse of May 29th. Einstein’s General Relativity predicts a deﬂection angle
where G is Newton’s constant, c is the speed of light, M is the mass of the gravitational lens and R is the impact parameter. It is well known that this result
it exaclty twice the value obtained using Newtonian gravity. For M = M⊙and
R = R⊙one gets from Einstein’s theory that α = 1.74 arc seconds.
The team led by Eddington reported 1.61 ± 0.40 arc seconds (based on the position of 5 stars), while the team headed by Crommelin reported 1.98±0.16 arc
seconds (based on 7 stars).
What is the Bayes factor between Einstein and Newton gravity from those data?
Comment on the strength of evidence.
(iii) Assume that the combined constraints from CMB, BAO and SNIa on the density
parameter for the cosmological constant can be expressed as a Gaussian posterior
Bayesian Methods
distribution on ΩΛ with mean 0.7 and standard deviation 0.05. Use the Savage-
Dickey density ratio to estimate the Bayes factor between a model with ΩΛ = 0
(i.e., no cosmological constant) and the ΛCDM model, with a ﬂat prior on ΩΛ in
the range 0 ≤ΩΛ ≤2. Comment on the strength of evidence in favour of ΛCDM.
(iv) If the cosmological constant is a manifestation of quantum ﬂuctuations of the
vacuum, QFT arguments lead to the result that the vacuum energy density ρΛ
where kmax is a cutoff scale for the maximum wavenumber contributing to the
energy density (see e.g. ). Adopting the Planck mass as a plausible cutoff
scale (i.e., kmax = c/¯hMPl) leads to “the cosmological constant problem”, i.e., the
fact that the predicted energy density
ρΛ ∼1076GeV4
is about 120 orders of magnitude larger than the observed value, ρobs ∼10−48GeV4.
a. Repeat the above estimation of the evidence in favour of a non-zero cosmological constant, adopting this time a ﬂat prior in the range 0 ≤ΩΛ/Ωobs
What is the meaning of this result? What is the required observational accuracy (as measured by the posterior standard deviation) required to override the
Occam’s razor penalty in this case?
b. It seems that it would be very difﬁcult to create structure in a universe with
ΩΛ ≫100, and so life (at least life like our own) would be unlikely to evolve.
How can you translate this “anthropic” argument into a quantitative statement,
and how would it affect our estimate of ΩΛ and the model selection problem?
(v) This problem follows up the cosmological parameter estimation problem from
supernovae type Ia (for a more thorough treatment, see ).
a. Adopt uniform priors Ωm ∼U(0,2) and ΩΛ ∼U(0,2). Produce a 2D marginalised
posterior pdf in the (Ωm,ΩΛ) plane.
b. Produce a 1D marginalised posterior pdf for the curvature parameter, Ωκ =
1−ΩΛ −Ωm, paying attention to normalising it to unity probability content.
What is the shape of the prior on Ωκ implied by your choice of a uniform
prior on Ωm,ΩΛ?
c. Use the Savage-Dickey density ratio formula to estimate from the above 1D
posterior the evidence in favour of a ﬂat Universe, Ωκ = 0, compared with a
non-ﬂat Universe, Ωκ ̸= 0, with prior P(Ωκ) = U(−1,1).
Discuss the dependency of your result on the choice of the above prior range.
Bayesian Methods
4.7 Solutions to selected exercises
(i) This is a model comparison problem, where we are comparing model M0 that
the coin is fair (i.e., pH = 0.5) with a model M1 where the probability of heads
is ̸= 0.5. We begin by assigning under model 1 a ﬂat prior to pH between 0 and
The Bayes factor (or ratio of the two models’ evidences) is given by
B = P(H = 140|M1)
P(H = 140|M0) =
N=250,H=140 =
(1/2)250 ≈0.48 ∼2 : 1
(notice that we have cancelled the “choose” terms in the numerator and denominators above). So there is not even weak evidence in favour of the model that the
coin is biased. The log of the Bayes factor is plotted as a function of H in Fig. 12.
By inspection it is apparent that values 107 ≤H ≤143 favour the fair coin model
(lnB < 0). In order to obtain “strong evidence” in favour of the biased coin model
(lnB > 5), it is necessary that either H < 94 or H > 31.
The usual Frequentist hypothesis testing procedure would be to compute the tail
probability of obtaining data as extreme or more extreme than have been observed under the null hypothesis, i.e., that the coin is fair. This gives the p-value:
Fig. 12 Natural log of the Bayes factor between the model “the coin is biased” (with ﬂat prior) and
the model ”the coin is fair”, as a function of the number of heads (H) in 250 ﬂips, see Eq. (189).
Values lnB > 0 favour the biased coin model. The Jeffreys’ threshold for “strong evidence” is at
Bayesian Methods
So for a Frequentist, the data would exclude the null hypothesis that the coin is
fair at more than the 95% CL.
How does the Bayesian result depend on the choice of prior for the alternative
hypothesis? Above we have given to pH a ﬂat prior between 0 and 1. If we wanted
to give the maximum possible advantage to a model where the coin is not fair, we
could put all of its prior probability in a delta-function concentrated at the value
of pH that maximizes the probability of what has been observed. So under this
maximally advantageous model for the unfairness hypothesis (let’s call this M2),
we would select a “prior” (in quotation marks, for this prior is actually selected
after the data have been gathered, so we are effectively using the data twice here!)
of the form P(pH) = δ(pH −H/N). In this case the odds in favour of this new
B = P(H = 140|M2)
P(H = 140|M0) = (H/N)H(1−H/N)N−H
H=140,H=250 ≈6.1.
Even in this most favourable setup for the hypothesis that the coin is biased,
we ﬁnd only weak evidence (odds of 6 to 1) against the model of a fair coin.
Therefore we can safely conclude that the data do not warrant to conclude that
the coin is unfair.
(ii) We are comparing here two models which both make exact predictions for the
deﬂection angle, with no free parameters. If you prefer, you might consider the
prior on α under each theory to be a delta-function centered at the predicted
value. This of course neglects the uncertainty associated with M⊙and R⊙.
In this case, the evidence is thus simply the likelihood function for the observed
data under each theory (you can convince yourself that this is correct by explicitly
computing the evidence for each model assuming the delta-function prior above).
This gives for the Bayes factor in favour of Einstein gravity vs Newton (assuming
Gaussian likelihoods)
where αE = 1.74′′, αN = 87′′, ˆα is maximum likelihood value of the experiment
and σ is the standard deviation.
Using the supplied data from Eddington, one obtains B ∼5, so “weak evidence”
in favour of Einstein theory according to the Jeffreys’ scale for the strength of
evidence. The Crommelin data instead give B ∼1010, so very strong evidence for
Einstein. Notice that this comes about because the measurement from Crommelin
is on the high side (i.e., higher than Einstein prediction, even), and therefore
the assumed Gaussian tail becomes tiny for α = αN. It is worth noticing that,
although the above calculation is formally correct, it is likely to overestimate
the evidence against Newton, because the Gaussian approximation made here is
certain to break down that far into the tails (i.e, αN is ∼11σ away from the value
measured by Crommelin. No distribution is exactly valid that far into the tails!).
Bayesian Methods
(iii) Here we are comparing two nested model, M0 with ΩΛ = 0 and a more complicated model, M1,where ΩΛ ≤0 and a ﬂat prior P(ΩΛ|M1) = 1/2 for 0 ≤ΩΛ ≤2
and 0 elsewhere (notice that the prior needs to be normalized, hence the factor
1/2). We can therefore use the Savage-Dickey density ratio to compute the Bayes
factor between M0 and M1:
B01 = P(ΩΛ = 0|CMB+BAO+SN,M1)
P(ΩΛ = 0|M1)
where we have assumed thart the posterior under M1 can be approximated as a
Gaussian of mean ˆΩΛ = 0.7 and standard deviation σ = 0.05. Numerical evaluation gives B01 ∼10−42, so with this prior the model that ΩΛ = 0 can be ruled out
with very strong evidence. Another way of looking at this result is the following: if, after having seen the data, you remain unconvinced that indeed ΩΛ > 0,
this means that the ratio in your relative degree of prior belief in the two models
should exceed P(M0)/P(M1) > 1042.
(iv) a. The calculation of the Bayes factor proceeds as above, but this time with a
much larger prior range for the alternative model, ΩΛ > 0. This means that
the prior height, P(ΩΛ = 0|M1) , appearing in the denominator of Eq. (193) is
very small, i.e. P(ΩΛ = 0|M1) = 10−120, as the prior needs to be normalized.
Repeating the above calculation, we get for the Bayes factor in favour of M0
(i.e., that ΩΛ = 0)
B01 ∼10−42
10−120 ∼1088.
Now the Bayes factor is positive (and huge), a reﬂection of the enormous
amount of prior range wasted by M1. Therefore under this new prior, the
Bayesian model comparison favour the hypothesis that there is no cosmological constant despite the fact that the likelihood peaks about 0.7/0.05 ∼14σ
away from ΩΛ = 0. This is an extreme example of Occam’s penalty.
In order for the Occam’s factor to be overruled by the likelihood, we require
that B01 = 1 (i.e., equal odds for the two models). This translates in the approximate condition for the number of sigma detection, λ:
where we have dropped the term 1/σ in front of the likelihood for simplicity (as the likelihood is going to be dominated by the exponential anyhow).
Solving for λ gives
240ln10 ≈23.
So we would need a ∼23σ detection of ΩΛ > 0 to override completely the
Occam’s razor penalty.
b. The outcome of the model comparison changes dramatically if one is willing
to impose a much more stringent upper cutoff to the prior range of ΩΛ, based
Bayesian Methods
e.g. on anthropic arguments. The observations that structures cannot form if
ΩΛ ≫100 (and therefore there would be no observers to measure dark energy, see e.g. the original argument by Weinberg ) can be approximately
translated in a prior range extending perhaps to ΩΛ ∼103. With this choice
of range, the Bayes factor becomes
B01 ∼10−42
10−3 ∼10−39,
thus swinging back to support M1 with enormous odds. This illustrate that
Bayesian model comparison can be difﬁcult (and strongly dependent on the
theoretical prior range adopted) in cases where there is no compelling (or
unique) argument to deﬁne the prior.
Acknowledgements I would like to thank the many colleagues who provided invaluable input and
discussions over the years: Bruce Bassett, Jim Berger, Bob Cousins, Eric Feigelson, Farhan Feroz,
Alan Heavens, Mike Hobson, Andrew Jaffe, Martin Kunz, Andrew Liddle, Louis Lyons, Daniel
Mortlock, John Peacock and David van Dyk. Many thanks to the Organizers of the 44th Saas Fee
Advanced Course on Astronomy and Astrophysics, “Cosmology with wide-ﬁeld surveys” for inviting me to present these lectures, and to the students for their piercing and
stimulating questions. I am grateful to many cohorts of students, at Imperial College London and
in various advanced schools, for their valuable feedback and comments on earlier versions of these
notes. Any remaining mistake is of course fully my own.
5 Introductory and background material
5.1 The uniform, binomial and Poisson distributions
The uniform distribution: for n equiprobable outcomes between 1 and n, the uniform discrete distribution is given by
1/n for 1 ≤r ≤n
It is plotted in Fig. 13 alongside with its cdf for the case of the tossing of a fair die
The binomial distribution: the binomial describes the probability of obtaining r
“successes” in a sequence of n trials, each of which has probability p of success.
Here, “success” can be deﬁned as one speciﬁc outcome in a binary process (e.g.,
H/T, blue/red, 1/0, etc). The binomial distribution B(n, p) is given by:
Bayesian Methods
Fig. 13 Left panel: uniform discrete distribution for n = 6. Right panel: the corresponding cdf.
P(r|n, p) ≡B(n, p) =
pr(1−p)n−r,
where the “choose” symbol is deﬁned as
for 0 ≤r ≤n (remember, 0! = 1). Some examples of the binomial for different
choices of n, p are plotted in Fig. 14.
The derivation of the binomial distribution proceeds from considering the probability of obtaining r successes in n trials (pr), while at the same time obtaining
n −r failures ((1 −p)n−r). The combinatorial factor in front is derived from considerations of the number of permutations that leads to the same total number of
successes.
The Poisson distribution: the Poisson distribution describes the probability of obtaining a certain number of events in a process where events occur with a ﬁxed
average rate and independently of each other. The process can occur in time (e.g.,
number of planes landing at Heathrow, number of photons arriving at a photomultiplier, number of murders in London, number of electrons at a detector, etc ...in a
certain time interval) or in space (e.g., number of galaxies in a patch on the sky).
Let’s assume that λ is the average number of events occuring per unit time or
per unit length (depending on the problem being considered). Furthermore, λ =
constant in time or space.
Example 17. For example, λ = 3.5 busses/hour is the average number of busses
passing by a particular bus stop every hour; or λ = 10.3 droplets/m2 is the average number of drops of water hitting a square meter of the surface of an outdoor
swimming pool in a certain day. Notice that of course at every given hour an integer
number of busses actually passes by (i.e., we never observe 3 busses and one half
passing by in an hour!), but that the average number can be non-integer (for exam-
Bayesian Methods
Fig. 14 Some examples of the binomial distribution, Eq. (199), for different choices of n, p, and
its corresponding cdf.
ple, you might have counted 7 busses in 2 hours, giving an average of 3.5 busses per
hour). The same holds for the droplets of water.
For problems involving the time domain (e.g., busses/hour), the probability of r
events happening in a time t is given by the Poisson distribution:
P(r|λ,t) ≡Poisson(λ) = (λt)r
If the problem is about the spatial domain (e.g., droplets/m2), the probability of r
events happening in an area A is given by:
Bayesian Methods
P(r|λ,A) ≡Poisson(λ) = (λA)r
Notice that this is a discrete pmf in the number of events r, and not a continuous
pdf in t or A. The probability of getting r events in a unit time interval is obtained
by setting t = 1 in Eq. (201); similarly, the probability of getting r events in a unit
area is obtained by setting A = 1 in Eq. (202)
Example 18. A particle detector measures protons which are emitted with an average rate λ = 4.5/s. What is the probability of measuring 6 protons in 2 seconds?
P(6|λ = 4.5s−1,t = 2s) = (4.5·2)6
e−4.5·2 = 0.09.
So the probability is about 9%.
The Poisson distribution of Eq. (201) is plotted in Fig. 15 as a function of r for a
few choices of λ (notice that in the ﬁgure t = 1 has been assumed, in the appropriate units). The derivation of the Poisson distribution follows from considering the
probability of 1 event taking place in a small time interval ∆t, then taking the limit
∆t →dt →0. It can also be shown that the Poisson distribution arises from the binomial in the limit pn →λ for n →∞, assuming t = 1 in the appropriate units (see
Example 19. In a post ofﬁce, people arrive at the counter at an average rate of 3
customers per minute. What is the probability of 6 people arriving in a minute?
Answer: The number of people arriving follows a Poisson distribution with average
λ = 3 (people/min). The probability of 6 people arriving in a minute is given by
P(n = 6|λ,t = 1min) = (λt)n
n! e−λt ≈0.015
So the probability is about 1.5%.
The discrete distributions above depend on parameters (such as p for the binomial, λ for Poisson), which control the shape of the distribution. If we know the
value of the parameters, we can compute the probability of an observation (as done
it the examples above). This is the subject of probability theory, which concerns itself with the theoretical properties of the distributions. The inverse problem of making inferences about the parameters from the observed samples (i.e., learning about
the parameters from the observations made) is the subject of statistical inference,
addressed later.
5.2 Expectation value and variance
Two important properties of distributions are the expectation value (which controls
the location of the distribution) and the variance or dispersion (which controls how
Bayesian Methods
Fig. 15 Some examples of the Poisson distribution, Eq. (201), for different choices of λ, and its
corresponding cdf.
much the distribution is spread out). Expectation value and variance are functions
Deﬁnition 10. The expectation value E[X] (often called “mean”, or “expected value”14)
of the discrete RV X is deﬁned as
E[X] = ⟨X⟩≡∑
14 We prefer not to use the term “mean” to avoid confusion with the sample mean.
Bayesian Methods
Example 20. You toss a fair die, which follows the uniform discrete distribution,
Eq. (198). What is the expectation value of the outcome?
Answer: the expectation value is given by E[X] = ∑i i· 1
Deﬁnition 11. The variance or dispersion Var(X) of the discrete RV X is deﬁned as
Var(X) ≡E[(X −E[X])2] = E(X2)−E[X]2.
The square root of the variance is often called “standard deviation” and is usually
denoted by the symbol σ, so that Var(X) = σ2.
Example 21. For the case of tossing a fair die once, the variance is given by
Var(X) = ∑
(xi −⟨X⟩)2Pi = ∑
For the binomial distribution of Eq. (199), the expectation value and variance are
E[X] = np,
Var(X) = np(1−p).
Example 22. A fair coin is tossed N times. What is the expectation value for the
number of heads, H? What is its variance? For N = 10, evaluate the probability of
obtaining 8 or more heads.
Answer: The expectation values and variance are given by Eq. (208), with p = 1/2
(as the coin is fair), thus
E(H) = Np = N/2
Var(H) = Np(1−p) = N/4.
The probability of obtaining 8 or more heads is given by
P(H heads|N, p = 1/2) = 1
1024 ≈0.055. (210)
So the probability of obtaining 8 or more heads is about 5.5%.
For the Poisson distribution of Eq. (201), the expectation value and variance are
E[X] = λt,
Var(X) = λt,
while for the spatial version of the Poisson distribution, Eq. (202), they are given
E[X] = λA,
Var(X) = λA.
As we did above for the discrete distribution, we now deﬁne the following properties for continuous distributions.
Deﬁnition 12. The expectation value E[X] of the continuous RV X with pdf p(X) is
E[X] = ⟨X⟩≡
Bayesian Methods
Deﬁnition 13. The variance or dispersion Var(X) of the continuous RV X is deﬁned
Var(X) ≡E[(X −E[X])2] = E(X2)−E[X]2 =
5.3 The exponential distribution
The exponential distribution describes the time one has to wait between two consecutive events in a Poisson process, e.g. the waiting time between two radioactive
particles decays. If the Poisson process happens in the spatial domain, then the exponential distribution describes the distance between two events (e.g., the separation
of galaxies in the sky). In the following, we will look at processes that happen in
time (rather than in space).
To derive the exponential distribution, one can consider the arrival time of Poisson distributed events with average rate λ (for example, the arrival time particles
in a detector). The probability that the ﬁrst particle arrives at time t is obtained by
considering the probability (which is Poisson distributed) that no particle arrives in
the interval [0,t], given by P(0|λ,t) = exp(−λt) from Eq. (201), times the probability that one particle arrives during the interval [t,t + ∆t], given by λ∆t. Taking
the limit ∆t →0 it follows that the probability density (denoted by a symbol p())
for observing the ﬁrst event happening at time t is given by
p(1st event happens at time t|λ) = λe−λt,
where λ is the mean number of events per unit time. This is the exponential distribution.
Example 23. Let’s assume that busses in London arrive according to a Poisson distribution, with average rate λ = 5 busses/hour. You arrive at the bus stop and a bus
has just departed. What is the probability that you will have to wait more than 15
Answer: the probability that you’ll have to wait for t0 = 15 minutes or more is given
p(1st event happens at time t|λ)dt =
λe−λtdt = e−λt0 = 0.29,
where we have used λ = 5busses/hour = 1/12 busses/min.
If we have already waited for a time s for the ﬁrst event to occur (and no event
has occurred), then the probability that we have to wait for another time t before the
ﬁrst event happens satisﬁes
p(T > t +s|T > s) = p(T > t).
Bayesian Methods
This means that having waited for time s without the event occuring, the time we
can expect to have to wait has the same distribution as the time we have to wait from
the beginning. The exponential distribution has no “memory” of the fact that a time
s has already elapsed.
For the exponential distribution of Eq. (215), the expectation value and variance
for the time t are given by
E(t) = 1/λ,
Var(t) = 1/λ 2.
5.4 The Gaussian (or Normal) distribution
The Gaussian pdf (often called “the Normal distribution”) is perhaps the most important distribution. It is used as default in many situations involving continuous RV,
since it naturally ﬂows from the the Central Limit Theorem, section 2.3.
The Gaussian pdf is a continuous distribution with mean µ and standard deviation
σ is given by
p(x|µ,σ) =
and it is plotted in Fig. 16 for two different choices of {µ,σ}. The Gaussian is the
famous bell-shaped curve.
Fig. 16 Two examples of the Gaussian distribution, Eq. (219), for different choices of µ,σ, and its
corresponding cdf. The expectation value µ controls the location of the pdf (i.e., when changing µ
the peak moves horizontally, without changing its shape), while the standard deviation σ controls
its width (i.e., when changing σ the spread of the peak changes but not its location).
For the Gaussian distribution of Eq. (219), the expectation value and variance are
Var(X) = σ2.
It can be shown that the Gaussian arises from the binomial in the limit n →∞and
from the Poisson distribution in the limit λ →∞. As shown in Fig. 17, the Gaussian
Bayesian Methods
approximation to either the binomial or the Poisson distribution is very good even
for fairly moderate values of n and λ.
Fig. 17 Gaussian approximation to the binomial (left panel) and the Poisson distribution (right
panel). The solid curve gives in each case the Gaussian approximation to each pmf.
The probability content of a Gaussian of standard deviation σ for a given symmetric interval around the mean of width κσ on each side is given by
P(µ −κσ < x < µ +κσ) =
where the error function erf is deﬁned as
and can be found by numerical integration (also often tabulated and available as a
built-in function in most mathematical software). Also recall the useful integral:
Eq. (221) allows to ﬁnd the probability content of the Gaussian pdf for any symmetric interval around the mean. Some commonly used values are given in Table 4.
Example 24. Measurements are often reported with the notation T = (100 ± 1) K
(in this case, we assume we have measured a temperature, T). If nothing else is
Bayesian Methods
κ P(−κ < x−µ
Usually called
“number of sigma” Probability content
1−5.7×10−7
90% probability interval
95% probability interval
99% probability interval
0.999 99.9% probability interval
Table 4 Relationship between the size of the interval around the mean and the probability content
for a Gaussian distribution.
speciﬁed, it is usually implied that the error follows a Gaussian distribution. In the
example above, ±1 K is the so-called “1σ interval”. This means that 68.3% of
the probability is contained within the range K. A “2σ interval” would
have a length of 2 K on either side, so 95.4% of the probability is contained in the
interval K. If one wanted a 99% interval, one would need a 2.57σ range
(see Table 4). Since in this case the 1σ error is 1 K, the 2.57σ error is 2.57 K and
the 99% interval is [97.43,102.57] K.
A heuristic derivation of how the Gaussian arises follows from this example involving darts throwing. Suppose we are throwing darts towards a target (located at
the center of the coordinate system, at the position x = 0,y = 0), with the following
(i) Throws are independent.
(ii) Errors in the x and y directions are independent.
(iii) Large errors are less probable than small ones.
The probability of a dart landing in an inﬁnitesimal square located at coordinates
(x,y) and of size (∆x,∆y) (i.e., the dart landing in the interval [x,x+∆x] and [y,y+
∆y]) is given by:
p(x)∆x· p(y)∆y = f(r)∆x∆y,
where p(x) is the probability density of landing at position x (and similarly for
p(y)), which is what we are trying to determine. On the l.h.s. of this equation, we
can multiply the probabilities of landing in the x and y direction because of rule
number (1) and (2). On the l.h.s., f(r) is a function that only depends on the radial
distance from the center, because of rule (2).
We now differentiate the above equation w.r.t. the polar coordinate φ:
+ p(y)dp(y)
(Note that the r.h.s. becomes 0 as it does not depend on φ). In polar coordinates,
x = rcosφ,y = rsinφ, hence
Bayesian Methods
Eq. (227) becomes
∂x y+ p(y)∂p
which implies
Since each side only depends on one of the variables, they must both equal a constant
C, and we obtain the differential equation:
∂x = Cxp(x)
(and similarly for y). Integration gives the solution
and C < 0 because of rule (3). We thus deﬁne C = −1/σ2. Requiring that the distribution is normalized gives A =
2πσ , and therefore p(x) has the shape of a Gaussian
(similarly for p(y)).
5.5 The Chi-Square distribution
We deﬁne the RV χ2 as the sum of the squares of n standardised independent identically distributed Gaussian RV, x1,...,xn, where xi ∼N (µ,σ):
The the RV χ2 is distributed according to the Chi-Square distribution with n degrees
of freedom,
Γ (n/2)2n/2 (χ2)
2 −1 exp(−1
For the Chi-Square distribution of Eq. (235), the expectation value and variance are
Var(X) = 2n.
Bayesian Methods