Unifying Divergence Minimization and
Statistical Inference via Convex Duality
Yasemin Altun1 and Alex Smola2
1 Toyota Technological Institute at Chicago, Chicago, IL 60637, USA⋆⋆
 
2 National ICT Australia, North Road, Canberra 0200 ACT, Australia
 
Abstract. In this paper we unify divergence minimization and statistical inference by means of convex duality. In the process of doing so, we
prove that the dual of approximate maximum entropy estimation is maximum a posteriori estimation. Moreover, our treatment leads to stability
and convergence bounds for many statistical learning problems. Finally,
we show how an algorithm by Zhang can be used to solve this class of
optimization problems eﬃciently.
Introduction
It has become part of machine learning folklore that maximum entropy estimation and maximum likelihood are convex duals to each other. This raises the
question whether maximum a posteriori estimates have similar counterparts and
whether such estimates can be obtained eﬃciently.
Recently Dudik et al. showed that a certain form of regularized maximum
entropy density estimation corresponds to ℓ1 regularization in the dual problem.
This is our starting point to develop a theory of regularized divergence minimization which aims to unify a collection of related approaches. By means of
convex duality we are able to give a common treatment to
– The regularized LMS minimization methods of Arsenin and Tikhonov ,
and of Morozov . There the problem of minimizing
2 subject to ∥Ax −b∥2
is studied as a means of improving the stability of the problem Ax = b.
– Ruderman and Bialek study a related problem where instead of a quadratic
penalty on x the following objective function is minimize
−H(x) subject to ∥Ax −b∥2
In other words, the problem of solving Ax = b is stabilized by ﬁnding the
maximum entropy distribution which satisﬁes the constraint.
⋆⋆Parts of this work were done when the author was visiting National ICT Australia.
Altun and Smola
– The density estimation problem of can be viewed as one of solving a
variant of the above, namely that of minimizing
−H(x) subject to ∥Ax −b∥∞≤ϵ
where the constraint encode deviations of the measured values of some moments or features and their expected values.
The problem we study can be abstractly stated as the regularized inverse problem
f(x) subject to ∥Ax −b∥B ≤ϵ.
where X and B are Banach spaces. We start by establishing a general framework
of duality to solve this problem using a convex analysis tool, namely Fenchel’s
duality. This theory is especially useful in the most general form of our problem,
where X and B are inﬁnite dimensional, since in this case Lagrangian techniques
are problematic due to diﬀerentiability issues. We apply this framework to a
generalized notion of regularized divergence minimization, since a large subset
of statistical learning literature can be analyzed within this class of problems.
By studying convex duality of two important classes of divergences, namely
Csisz´ar and Bregman divergences, we show that maximum a posteriori estimation is the convex dual of approximate maximum entropy estimation. Various
statistical inference methods, such as boosting, logistic regression, Gaussian Processes and others become instances of our framework, by using diﬀerent entropy
functions and regularization methods. Following these lines, we not only give a
common treatment to these methods, but also provide directions to develop new
inference techniques by investigating diﬀerent entropy-regularization combinations. For example, working in Banach spaces, we can perform diﬀerent regularizations on subsets of basis functions, which is useful in problems like structured
learning where there are several distinctly diﬀerent sets of basis functions.
From a regularization point of view, our approach provides a natural interpretation to the regularization coeﬃcient ϵ, which corresponds to the approximation
parameter in the primal problem. Studying the concentration of empirical means,
we show that a good value of ϵ is proportional to O(1/√m) where m is the sample
size. Noting that ϵ is generally chosen by cross validation techniques in practice,
we believe our framework gives us an enhanced interpretation of regularized optimization problems. We also provide uniﬁed bounds on the performance of the
estimate wrt loss on empirical estimates as well as the loss on true statistics,
which apply to arbitrary linear classes and divergences. Finally, we show that a
single algorithm can eﬃciently optimize this large class of optimization problems
with good convergence rates.
Related work There is a large literature on analyzing various loss functions on exponential families as the convex dual of relative entropy minimization via equality constraints of the form Ax = b. For example, Laﬀerty analyze logistic
regression and exponential loss as a special case of Bregman divergence minimization and propose a family of sequential update algorithms. Similar treat-
Divergence Minimization and Convex Duality
ments are given in . One common property of these studies is that they
investigate exact divergence minimization.
Previous work on approximate divergence minimization focused on minimizing KL divergence such that its convex dual is penalized by ℓ1 and ℓ2
norm terms, eg. . show that approximate KL divergence minimization wrt.
∥Ax −b∥∞≤ϵ has the convex dual of ℓ1 norm regularized maximum likelihood.
Recently produced similar results for ℓp norm regularization.
In this paper, we improve over previous work by generalizing to a family of
divergence functions with inequality constraints in Banach spaces. Our uniﬁed
treatment of various entropy measures (including Csisz´ar and Amari divergences)
and various normed spaces allows us to produce the cited work as special cases
and to deﬁne more sophisticated regularizations via Banach space norms. Finally
we provide risk bounds for the estimates.
Fenchel Duality
We now give a formal deﬁnition of the class of inverse problems we solve. Denote
by X and B Banach spaces and let A : X →B be a bounded linear operator
between those two spaces. Here A corresponds to an “observation operator”,
e.g. mapping distributions into a set of moments, marginals, etc. Moreover, let
b ∈B be the target of the estimation problem. Finally, denote by f : X →R
and g : B →R convex functions and let ϵ ≥0.
Problem 1 (Regularized inverse). Our goal is to ﬁnd x ∈X which solves
the following convex optimization problem:
f(x) subject to ∥Ax −b∥B ≤ϵ.
Example 2 (Density estimation). Assume that x is a density, f is the negative Shannon-Boltzmann entropy, b contains the observed values of some moments or features, A is the expectation operator of those features wrt. the density
x and the Banach space B is ℓp.
We shall see in Section 3.2 that the dual to Example 3 is a maximum a posteriori
estimation problem.
In cases where B and X are ﬁnite dimensional the problem is easily solved
by calculating the corresponding Lagrangian, setting its derivative to 0 and
solveing for x. In the inﬁnite dimensional case, more careful analysis is required
to ensure continuity and diﬀerentiability. Convex analysis provides a powerful
machinery, namely Fenchel’s conjugate duality theorem, to study this problem
by formulating the primal-dual space relations of convex optimization problems
in our general setting. We need the following deﬁnition:
Deﬁnition 3 (Convex conjugate). Denote by X a Banach space and let X∗
be its dual. The convex conjugate or the Legendre-Fenchel transformation of a
function f : X →R is f ∗: X∗→R where f ∗is deﬁned as
f ∗(x∗) = sup
{⟨x, x∗⟩−f(x)} .
Altun and Smola
We present Fenchel’s theorem where the primal problem is of the form f(x) +
g(Ax). Problem 2 becomes an instance of the latter for suitably deﬁned g.
Theorem 4 (Fenchel Duality [3, Th. 4.4.3]). Let g : B →R be a convex
function on B and other variables as above. Deﬁne t and d as follows:
x∈X {f(x) + g(Ax)} and d = sup
x∗∈B∗{−f ∗(A∗x∗) −g∗(−x∗)} .
Assume that f, g and A satisfy one of the following constraint qualiﬁcations:
a) 0 ∈core(dom g −A dom f) and both f and g are left side continuous (lsc)
b) A dom f ∩cont g ̸= ∅
Here s ∈core(S) if S
λ>0 λ(S −s) ⊆X where X is a Banach space and S ⊆X.
In this case t = d, where the dual solution d is attainable if it is ﬁnite.
We now apply Fenchel’s duality theorem to convex constraint optimization problems, such as Problem 2, since the dual problem is easier to solve in certain cases.
Lemma 5 (Fenchel duality with constraints). In addition to the assumptions of Theorem 5, let b ∈B and ϵ ≥0. Deﬁne t and d as follows:
x∈X {f(x) subject to ∥Ax −b∥B ≤ϵ}
and d = sup
x∗∈B∗{−f ∗(A∗x∗) + ⟨b, x∗⟩−ϵ ∥x∗∥B∗}
Suppose f is lower semi-continuous and that for B :=
¯b ∈B with
following constraint qualiﬁcation holds:
core(A dom f) ∩(b + ϵ int(B)) ̸= ∅.
In this case t = d with dual attainment.
Proof Deﬁne g in Theorem 5 as the characteristic function on ϵB + b, i.e.
g(¯b) = χϵB+b(¯b) =
if ¯b ∈ϵB + b
The convex conjugate of g is given by
g∗(x∗) = sup
subject to ¯b −b ∈ϵB
= −⟨x∗, b⟩+ ϵ sup
subject to ¯b ∈B
= ϵ ∥x∗∥B∗−⟨x∗, b⟩
Theorem 5 and the relation core(B) = int(B) prove the lemma.
The constraint qualiﬁcation (CQ) ensures the non-emptiness of the sub-diﬀerential.
ϵ = 0 leads to equality constraints Ax = b, for which CQ requires b to be
an element of core(A dom f). If the equality constraints are not feasible b /∈
core(A dom f), which can be the case in real problems, the solution diverges.
Divergence Minimization and Convex Duality
Such problems may be rendered feasible by relaxing the constraints (ϵ > 0),
which corresponds to expanding the search space by deﬁning an ϵ ball around b
and searching for a point in the intersection of this ball and core(A dom f). In
the convex dual problem, this relaxation is penalized with the norm of the dual
parameters scaling linearly with the relaxation parameter ϵ.
In practice it is diﬃcult to check whether (CQ) holds. One solution is to solve
the dual optimization problem and infer that the condition holds if the solution
does not diverge. To assure a ﬁnite solution, we restrict the function class such
that f ∗is Lipschitz and to perturb the regularization slightly by taking its kth
power, resulting in a Lipschitz continuous optimization. For instance Support
Vector Machines perform this type of adjustment to ensure feasibility .
Lemma 6. Denote by X a Banach space, let b ∈X∗and let k > 1. Assume that
f(Ax) is convex and Lipschitz continuous in x with Lipschitz constant C. Then
f(Ax) −⟨b, x⟩+ ϵ ∥x∥ko
does not diverge and the norm of x is bounded by ∥x∥X ≤[(∥b∥X∗+ C) /kϵ]
Proof [sketch] Note that the overall Lipschitz constant of the objective function
(except for the norm) is bounded by ∥b∥X∗+ C. The objective function cannot
increase further if the slope due to the norm is larger than what the Lipschitz
constant admits. Solving for ϵk ∥x∥k−1
= ∥b∥X∗+ C proves the claim.
Divergence Minimization and Convex Duality
Now that we established a rather general framework of duality for regularized
inverse problems, we consider applications to problems in statistics. For the
remainder of the section x will either be a density or a conditional density over
the domain T. For this reason we will use p instead of x to denote the variable
of the optimization problem.
Denote by ψ : T →B feature functions and let A : X →B be the expectation
operator of the feature map with respect to p. In other words, Ap := Et∼p [ψ(t)].
With some abuse of notation we will use the shorthand Ep[ψ] whenever convenient. Finally denote by ˜ψ = b the observed value of the features ψ(t), which are
derived, e.g. via b = m−1 Pm
i=1 ψ(ti) for ti ∈S, the sample of size m.
This setting allows us to study various statistical learning methods within
convex duality framework. It is well-known that the dual of maximum (Shannon)
entropy (commonly called MaxEnt) is maximum likelihood (ML) estimation.
One of the corollaries, which follows immediately from the more general result
in Lemma 12 is that the dual of approximate maximum entropy is maximum a
posteriori estimation (MAP).
Altun and Smola
Theorem 7. Assume that f is the negative Shannon entropy, that is f(p) :=
T log p(t)dp(t). Under the above conditions we have
−H(p) subject to
Ep[ψ] −˜ψ]
exp(⟨φ, ψ(t)⟩)dt −ϵ ∥φ∥+ e−1
Equivalently φ maximizes Pr(S|φ) Pr(φ) and Pr(φ) ∝exp(−ϵ ∥φ∥).
In order to provide a common treatment to various statistical inference techniques, as well as give insight into the development of new ones, we study two
important classes of divergence functions, Csisz´ar’s divergences and Bregman
divergences. Csisz´ar divergence, which includes Amari’s α divergences as special
cases, gives the asymmetric distance between two inﬁnite-dimensional density
functions induced by a manifold. Bregman divergences are commonly deﬁned
over distributions over a ﬁnite domain. The two classes of divergences intersect
at the KL divergence. To avoid technical problems we assume that the constraint
qualiﬁcations are satisﬁed (e.g. via Lemma 7).
Csisz´ar Divergences
Deﬁnition 8. Denote by h : R →R a convex lsc function and let p, q be two
distributions on T. Then the Csisz´ar divergence is given by
fh(q, p) =
Diﬀerent choices for h lead to diﬀerent divergence measures. For instance h(ξ) =
ξ log ξ yields the Kullback-Leibler divergence. Commonly, q is ﬁxed and optimization is performed with respect to p, which we denote by fh,q(p). Since fh,q(p) is
convex and expectation is a linear operator, we can apply Lemma 6 to obtain
the convex conjugate of Csisz´ar’s divergence optimization:
Lemma 9 (Duality of Csisz´ar Divergence). Assume that the conditions of
Lemma 6 hold. Moreover let f be deﬁned as a Csisz´ar divergence. Then
fh,q(p)|∥Ep[ψ] −˜ψ]∥B ≤ϵ
h,q(⟨φ, ψ(.)⟩) +
Moreover the solutions ˆp and ˆφ are connected by ˆp(t) = q(t)(h∗)′ D
Proof The adjoint of the linear operator A is given by ⟨Ax, φ⟩= ⟨A∗φ, x⟩. Letting A be the expectation wrt p, we have
T p(t)ψ(t), φ
T p(t) ⟨ψ(t), φ⟩dt =
(A∗φ)(p) for A∗φ = ⟨φ, ψ(.)⟩. Next note that f ∗(⟨φ, ψ(·)⟩) =
T q(t)h∗(⟨φ, ψ(t)⟩)dt.
Plugging this into Lemma 6, we obtain the ﬁrst claim.
Divergence Minimization and Convex Duality
Using attainability of the solution it follows that there exist ˆp and ˆφ which
solve the corresponding optimization problems. Equating both sides we have
dt=−f ∗(⟨φ, ψ(.)⟩) +
−ϵ∥ˆφ∥B∗=−f ∗(⟨φ, ψ(.)⟩) +
ˆφ, Eˆp[ψ]
Here the last equality follows from the deﬁnition of the constraints (see the
proof of Lemma 6). Taking the derivative at the solution ˆp (due to constraint
qualiﬁcation) and noticing that the derivative of the ﬁrst term on the RHS, we
. Using the relation (h′)−1 = (h∗)′ completes the proof.
Since we are dealing with probability distributions, it is convenient to add the
constraint
T dp(t) = 1. We have the following corollary.
Corollary 10 (Csisz´ar divergence and probability constraints). Deﬁne
all variables as in Lemma 10. We have
fh,q(p) subject to
Ep [ψ] −˜ψ
h,q (⟨φ, ψ(.)⟩−Λφ) +
−Λφ −ϵ ∥φ∥B∗
Here the solution is given by ˆp(t) = q(t)(h∗)′(
−Λ(ˆφ)) where Λ(ˆφ) is
the partition function which ensures that p be a probability distribution (λ(ˆφ) is
the minimizer of (5) with respect to λφ).
Proof [sketch] Deﬁne P = {p|
T dp(t) = 1} and f in Lemma 6 as f(p) =
fh,q(p) + χP(p). Then, for Λp = ∞if p /∈P, the convex conjugate of f is
f ∗(p∗) = supp{⟨p, p∗⟩−fh,q(p) −Λp(
T dp(t) −1) = Λp∗+ (fh,q)∗(p∗−Λp∗).
Performing the steps in the proof of Lemma 10 gives the result.
An important and well-studied special case of this duality is the minimization
of KL divergence as we investigate in the next section. Note that new inference
techniques can be derived using other h functions, eg. Tsallis’ entropy, which is
preferable over Shannon’s entropy in ﬁelds as statistical mechanics.
MAP and Maximum Likelihood via KL Divergence
Deﬁning h in (4) as h(ξ) := ξ ln(ξ) we have h∗(ξ∗) = exp(ξ∗−1). Then Csisz´ar’s
divergence becomes the KL divergence. Applying Corollary 11 we have:
Lemma 11 (KL divergence with probability constraints). Deﬁne all variables as in Lemma 11. We have
KL(p∥q) subject to
Ep [ψ] −˜ψ
q(t) exp(⟨φ, ψ(t)⟩)dt −ϵ∥φ∥B∗+ e−1
where the unique solution is given by ˆp ˆφ(t) = q(t) exp
Altun and Smola
Proof The dual of f is f ∗
T q(t) exp(x∗(t) −1)dt. Hence we have the
dual objective function
q(t) exp (⟨φ, ψ(t)⟩−Λφ −1) dt +
−Λφ −ϵ ∥φ∥B∗
We can solve for optimality in Λφ which yields Λφ = log
T q(t) exp (⟨φ, ψ(t)⟩) dt.
Substituting this into the objective function proves the claim.
Thus, optimizing approximate KL divergence leads to exponential families. Many
well known statistical inference methods can be viewed as special cases. Let
P = {p|p ∈X,
T dp(t) = 1} and q(t) = 1, ∀t ∈T.
Example 12. For ϵ = 0, we get the well known duality between Maximum Entropy and Maximum Likelihood estimation.
−H(p) subject to Ep [ψ] = ˜ψ
exp(⟨φ, ψ(t)⟩)dt + e−1
Example 13. For B = ℓ∞we get the density estimation problem of 
−H(p) subject to
Ep [ψ] −˜ψ
exp(⟨φ, ψ⟩(t))dt −ϵ∥φ∥1 + e−1
If B is a reproducing kernel Hilbert space of spline functions we obtain the density
estimator of , who use an RKHS penalty on φ.
The well-known overﬁtting behavior of ML can be explained by the constraint
qualiﬁcation (CQ) of Section 2. While it can be shown that in exponential families the constraint qualiﬁcations are satisﬁed if we consider the closure of
the marginal polytope, the solution may be on (or close to) a vertex of the
marginal polytope. This can lead to large (or possibly diverging) values of φ.
Hence, regularization by approximate moment matching is useful to ensure that
such divergence does not occur.
Regularizing ML with ℓ2 and ℓ1 norm terms is a common practice , where
the coeﬃcient is determined by cross validation techniques. The analysis above
provides a uniﬁed treatment of the regularization methods. But more importantly, it leads to a principled way of determining the regularization coeﬃcient
ϵ as discussed in Section 4.
Note that if t ∈T is an input-output pair t = (x, y) we could maximize the
entropy of either the joint probability density p(x, y) or the conditional model
p(y|x), which is what we really need to estimate y|x. If we maximize the entropy
of p(y|x) and B is a RKHS with kernel k(t, t′) := ⟨ψ(t), ψ(t′)⟩we obtain a range
of conditional estimation methods:
– For ψ(t) = yψx(x) and y ∈{±1}, we obtain binary Gaussian Process classi-
ﬁcation .
Divergence Minimization and Convex Duality
– For ψ(t) = (y, y2)ψx(x), we obtain the heteroscedastic GP regression estimates of .
– For decomposing ψ(t), we obtain various graphical models and conditional
random ﬁelds as described in .
– For ψ(t) = yψx(x) and ℓ∞spaces, we obtain as its dual ℓ1 regularization
typically used in sparse estimation methods.
The obvious advantage of using convex duality in Banach spaces is that it provides a uniﬁed approach (including bounds) for diﬀerent regularization/relaxation
schemes as listed above. More importantly, this generality provides ﬂexibility for
more complex choices of regularization. For instance, we could deﬁne diﬀerent
regularizations for features that possess diﬀerent characteristics.
Bregman Divergence
The Bregman divergence between two distributions p and q for a convex function
h acting on the space of probabilities is given by
△h(p, q) = h(p) −h(q) −⟨(p −q), ∇qh(q)⟩.
Note △h(p, q) is convex in p. Applying Fenchel’s duality theory, we have
Corollary 14. Duality of Bregman Divergence Assume that the conditions
of Lemma 6 hold. Moreover let f be deﬁned as a Bregman divergence. Then
△h(p, q) subject to
Ep [ψ] −˜ψ
−h∗(⟨φ −φq, ψ⟩) +
Deﬁning Hq(p) = h(p) −⟨p, h′(q)⟩, △h(p, q) = Hq(p) −h∗(φq). The
convex conjugate of Hq is H∗
q (φ) = supp ⟨p, φ + h′(q)⟩−h(p) = h∗(φ−φq), since
h′(q) = φq. Since q is constant, we get the equality (up to a constant) by plugging
q into Lemma 6.
As in Csisz´ar’s divergence, the KL divergence becomes a special case of Bregman
divergence by deﬁning h as h(p) :=
T p(t) ln(p(t))dt. Thus, we can achieve the
same results in Section 3.2 using Bregman divergences as well. Also, it has been
shown in various studies that Boosting which minimizes exponential loss can
be cast as a special case of Bregman divergence problem with linear equality
constraints . An immediate result of Corollary 15, then, is to generalize
these approaches by relaxing the equality constraints wrt. various norms and
achieve regularized exp-loss optimization problems leading to various regularized
boosting approaches. Due to space limitations, we omit the details.
Bounds on the Dual Problem and Uniform Stability
Generalization performances of estimators achieved by optimizing various convex
functions in Reproducing Kernel Hilbert Spaces have been studied extensively.
See e.g. and references therein. Producing similar results in the general
form of convex analysis allows us to unify previous results via simpler proofs and
tight bounds.
Altun and Smola
Concentration of empirical means
One of the key tools in the analysis of divergence estimates is the fact that
deviations of the random variable ˜ψ = 1
mψ(ti) are well controlled.
Theorem 15. Denote by T := {t1, . . . , tm} ⊆T a set of random variables drawn
from p. Let ψ : T →B be a feature map into a Banach space B which is uniformly
bounded by R. Then the following bound holds
ψ(ti) −Ep [ψ(t)]
≤2Rm(F, p) + ϵ
with probability at least 1−exp
. Here Rm(F, p) denotes the Rademacher
average wrt the function class F := {φp(·) = ⟨ψ(t), φp⟩where ∥φ∥B∗≤1}.
Moreover, if B is a RKHS with kernel k(t, t′) the RHS of (9) can be tightened
m−1Ep [k(t, t) −k(t, t′)] + ϵ. The same bound for ϵ as above applies.
See for more details and for earlier results on Hilbert Spaces.
The ﬁrst claim follows immediately from [2, Theorem 9 and 10]. The
second part is due to an improved calculation of the expected value of the LHS
of (9). We have by convexity
ψ(ti) −Ep [ψ(t)]
ψ(ti) −Ep [ψ(t)]
∥ψ(t) −Ep [ψ(t)]∥2i
Ep [k(t, t) −k(t, t′)]
The concentration inequality for bounding large deviations remains unchanged
wrt. the Banach space case, where the same tail bound holds.
The usefulness of Theorem 16 arises from the fact that it allows us to determine
ϵ in the inverse problem. If m is small, it is sensible to choose a large value of ϵ
and with increasing m our precision should improve with O(
√m). This gives us
a principled way of determining ϵ based on statistical principles.
Stability with respect to changes in b
Next we study the stability of constrained optimization problems when changing
the empirical mean parameter b. Consider the convex dual problem of Lemma 6
and the objective function of its special case (7). Both problems can be summarized as
L(φ, b) := f(Aφ) −⟨b, φ⟩+ ϵ ∥φ∥k
where ϵ > 0 and f(Aφ) is a convex function. We ﬁrst show that for any b′,
the diﬀerence between the value of L(φ, b′) obtained by minimizing L(φ, b) with
respect to φ and vice versa is bounded.
Divergence Minimization and Convex Duality
Theorem 16. Denote by φ, φ′ the minimizers of L(·, b) and L(·, b′) respectively.
Then the following chain of inequalities holds:
L(φ, b′) −L(φ′, b′) ≤⟨b′ −b, φ′ −φ⟩≤∥b′ −b∥B ∥φ′ −φ∥B∗
and L(φ, b) −L(φ′, b′) ≤⟨φ, b′ −b⟩≤∥b′ −b∥B ∥φ′∥B∗
Proof To show (11) we only need to prove the ﬁrst inequality. The second one
follows by H¨older’s theorem:
L(φ, b′) −L(φ′, b′) =L(φ, b′) −L(φ, b) + L(φ, b) −L(φ′, b) + L(φ′, b) −L(φ′, b′)
≤⟨b −b′, φ⟩+ ⟨φ′, b′ −b⟩
We used the fact that by construction L(φ′, b) ≥L(φ, b). To show (12) we use
almost the same chain of inequalities, bar the ﬁrst two terms.
In general, ∥φ −φ′∥can be bounded using Lemma 7,
∥φ′ −φ∥B∗≤∥φ∥B∗+ ∥φ′∥B∗≤2 (C/kϵ)
For the special case of B being a RKHS, however, one can obtain considerably
tighter bounds directly on ∥φ′ −φ∥in terms of the deviations in b′ and b:
Lemma 17. Assume that B is a Hilbert space and let k = 2, ϵ > 0 in (10). Let
φ and φ′ be the minimizers of L(·, b) and L(·, b′) respectively, where L is deﬁned
as in (10). The the following bound holds:
The proof idea is similar to that of . We construct an auxiliary
function R : B →R via
R(z) = ⟨A∗[f ′(Aφ) −f ′(Aφ′)] + b′ −b, z −φ′⟩+ ϵ ∥z −φ′∥2 .
Clearly R(φ′) = 0 and R is a convex function in z. Taking derivatives of R(z)
one can check that its minimum is attained at φ:
∂zR(z) = A∗f ′(Aφ) −b −A∗f ′(Aφ′) + b′ + 2ϵ(z −φ′)
For z = φ, this equals ∂φL(φ, b) −∂φ′L(φ′, b′) which vanishes due to optimality
in L. From this, we have
0 ≥⟨A∗[f ′(Aφ) −f ′(Aφ′)] + b′ −b, φ −φ′⟩+ ϵ ∥φ −φ′∥2 .
≥⟨b′ −b, φ −φ′⟩+ ϵ ∥φ −φ′∥2
≥−∥b −b′∥∥φ −φ′∥+ ϵ ∥φ −φ′∥2
Here the ﬁrst inequality follows from R(φ′) > R(φ), the second follows from the
fact that for convex functions ⟨g′(a) −g′(b), a −b⟩≥0, and the third inequality
is an application of Cauchy-Schwartz. Solving for ∥φ −φ′∥proves the claim.
Altun and Smola
Risk bounds
We are now in a position to combine concentration and stability results derived
in the previous two sections into risk bounds for the values of divergences.
Theorem 18. Assume that b = 1
i=1 ψ(t) and let b∗:= Ep [ψ(t)]. Moreover,
denote by φ, φ∗the minimizers of L(·, b) and L(·, b∗) respectively. Finally assume
that ∥ψ(t)∥≤R for all t ∈T. Then
∥φ∥[2Rm(F, p) + ϵ] ≤L(φ∗, b∗) −L(φ, b) ≤∥φ∗∥[2Rm(F, p) + ϵ]
where each inequality holds with probability 1 −exp
Proof Combination of Theorem 16 and (12) of Theorem 17.
Note that this is considerably stronger than a corresponding result of , as it
applies to arbitrary linear classes and divergences as opposed to ℓ∞spaces and
Shannon entropy. A stronger version of the above bounds can be obtained easily
for RKHSs, where the Rademacher average is replaced by a variance bound.
If we want to bound the performance of estimate x with respect to the actual
loss L(·, b∗) rather than L(·, b) we need to invoke (11). In other words, we show
that on the true statistics the loss of the estimated parameter cannot be much
larger than the loss of true parameter.
Theorem 19. With the same assumptions as Theorem 19 we have with probability at least 1 −exp
L(φ, b∗) −L(φ∗, b∗) ≤2
k−1 (2Rn(FB) + ϵ) .
Here C is the Lipschitz constant of f(A·). If B is an RKHS we have with probability at least 1 −exp
L(φ, b∗) −L(φ∗, b∗) ≤1
mEp [k(t, t) −k(t, t′)] + ϵ
Proof To prove (16) we use (11) which bounds
L(φ, b∗) −L(φ∗, b∗) ≤∥b∗−b∥B (∥φ∥B∗+ ∥φ∗∥B∗) .
The ﬁrst factor is bounded by (9) of Theorem 16. The second term is bounded via
Lemma 7. A much tighter bound is available for RKHS. Using (11) in conjunction
with (14) of Lemma (18) yields
L(φ, b∗) −L(φ∗, b∗) ≤1
ϵ ∥b −b∗∥2
Divergence Minimization and Convex Duality
We establish a bound for ∥b −b∗∥2 by a standard approach, i.e. by computing
the mean and then bounding the tail of the random variable. By construction
ψ(ti) −E [ψ(t)]
∥ψ(t) −E [ψ(t′)]∥2i
Using k(t, t′) = ⟨ψ(t), ψ(t′)⟩yields the mean term. To bound the tail we use
McDiarmid’s bound. For this, we need to check by how much ∥b −b∗∥2 changes
if we replace one term ψ(ti) by an arbitrary ψ(t′
i) for some t′
i ∈T. We have
i) −ψ(ti)) −b∗
2 −∥b −b∗∥2
i) −ψ(ti)∥
2(b + b∗) + 1
i) −ψ(ti))
for m ≥2. Plugging this into McDiarmid’s bound yields that ∥b −b∗∥2 deviates
from its expectation by more than ϵ with probability less than exp
Theorem 20 also holds for LB
ψ . Since the KL divergence is an example of Csisz´ar’s
divergence, using this bound allows us to achieve stability results for MAP estimates immediately.
Optimization Algorithm and Convergence Properties
In the most general form, our primal problem, f(x) subject to ∥Ax−b∥B ≤ϵ is an
abstract program, where both the constraint space B and the domain X may be
inﬁnite, i.e. both the primal and the dual turn out to be inﬁnite problems. Thus,
except for special cases ﬁnding an optimal solution in polynomial time may be
impossible. It turns out that a sparse greedy approximation algorithm proposed
by Zhang is an eﬃcient way of solving this class of problems eﬃciently,
providing good rates of convergence (in contrast, the question of a convergence
rate remains open in ).
Algorithm 1 Sequential greedy approximation 
1: input: sample of size n, statistics b, base function class B∗
base, approximation ϵ,
number of iterations K, and radius of the space of solutions R
2: Set φ = 0.
3: for k = 1, . . . , K do
Find (ˆı, ˆλ) such that for ei ∈B∗
base and λ ∈ the following is approximately
minimized:
L((1 −λ)φ + λRei, b)
Update φ ←(1 −ˆλ)φ + ˆλReˆı
6: end for
Algorithm 1 requires that we have an eﬃcient way of updating φ by drawing
from a base class of parameters B∗
base which “generates” the space of parameters
Altun and Smola
B∗. In other words, we require that spanB∗
base = B∗. For instance we could pick
base to be the set of vertices of the unit ball in B∗.
Note that Step 4 in Algorithm 1 only needs to be approximate. In other
words, we only need to ﬁnd (ˆı, ˆλ) such that the so-found solution is within δk of
the optimal solution, as long as δk →0 for k →∞.
Also note the dependency on R: one needs to modify the setting of to
make it applicable to arbitrary convex sets. As long as R is chosen suﬃciently
large such as to include the optimal solution the conditions of apply.
Theorem 20 ([23, Theorem II.1]). Let Mβ be an upper bound on L′′(φ). If
the optimization is performed exactly at each step (i.e. δk = 0 for all k) we have
L(φk, b) −L(ˆφ, b) ≤2M/(k + 2)
where ˆφ is the true minimizer of L(φ, b).
This has an interesting implication when considering the fact that deviations
between the optimal solution of L(φ∗, b∗) for the true parameter b∗and the
solution achieved via L(φ, b) are O(1/√m), as follows from Section 4.3. It is
essentially pointless to ﬁnd a better solution than within O(1/√m) for a sample
of size m. Hence we have the following corollary:
Corollary 21. Zhang’s algorithm only needs O(√m) steps for a set of observations of size m to obtain almost optimal performance.
When the dual is a ﬁnite program, it is possible to achieve linear convergence
rates (where the diﬀerence in Equation 18 goes exponentially fast to 0 in k)
 . The obvious special case when the dual is a ﬁnite dimensional optimization
problem is when the index set I over the statistics is ﬁnite.
Consider X itself is a ﬁnite dimensional problem, for example, when we want
to estimate the conditional density p(y|x) of a classiﬁcation task wrt. inequality
constraints in a Banach space. In that case, our primal is a semi-inﬁnite program
(SIP), i.e. optimization over a ﬁnite dimensional vector space wrt inﬁnite number
of constraints. Then, using a Helly-type theorem, one can show that the SIP can
be reduced to a ﬁnite program (i.e. with ﬁnite number of constraints) and we
immediately get a ﬁnite dual program. This is a generalization of a family of
results commonly referred to as representer theorems.
Conclusion
Our generalized framework of convex duality allowed us to unify a large class
of existing inference algorithms in a common framework, to provide statistical
bounds for the estimates, and to provide a practical algorithm.
Note that in the present paper we barely scratched the surface of alternative
divergence measures, such as Tsallis or Sharma-Mittal entropy. Also, we did not
discuss in detail what becomes of structured estimation methods when applied in
conjunction with Zhang’s algorithm. Likewise, the connection between Boosting
Divergence Minimization and Convex Duality
and an approximate solution of inverse problems has not been explored yet.
Finally, it may be possible to minimize the divergence directly in transductive
settings. We expect this set of problems to be a fertile ground for future research.
Acknowlegements: We thank Tim Sears, Thomas Gaertner and Vishy Vishwanathan. National ICT Australia is funded through the Australian Government’s Baking Australia’s Ability initiative, in part through the Australian Research Council. This work was supported by the PASCAL Network of Excellence.