Behavior Research Methods, Instruments, & Computers
1994.26 (4),454-460
On-line control of moving masks and windows
on a complex background using the ATVista
videographics adapter
PAUL M. J. VAN DIEPEN,PETER DE GRAEF, and JOHANVAN RENSBERGEN
University ofLeuven, Leuven, Belgium
In reading research, the moving mask and moving window paradigms have proved to be invaluable in determining the chronometric and spatial characteristics of processing written text. The success ofthese methods has lead to a demand for their application in research on real-world scene perception. However, we will argue that the technical implementation of eye-contingent mask (window)
movement across a stable text cannot be applied to scene research. A new technique is proposed
that allows graphical masks or windows of arbitrary form, size, and content to be moved quickly over
a complex graphical stimulus. This moving overlay technique makes use of the ATVista graphics
adapter, a board with the ability to mix an internally stored and an externally generated image into
one composite image. A high-performance moving mask or window is created by programming the
internal image to be movable and partly transparent. The technique is implemented on a standard
personal computer interfaced with an eyetracker, thus bringing mask (window) movement under online eye-movement control. Wediscuss general principles of the technique and illustrate them with
performance data from a concrete experimental setup.
A powerful paradigm used in reading research involves the presentation ofa visual mask or window, moving across the text in synchrony with the eyes. Thanks to
this paradigm, the chronometry and spatial extent of information extraction in reading are better understood . Recent research on real-world scene perception has demonstrated the potential of eye-movement registration in
studying the recognition and comprehension ofcomplex
pictorial information .
Until now, however, technical difficulties have prevented
the full exploitation of eye-movement methodology in
the study of scene perception. Specifically, the application
of the moving window and/or moving mask techniques
has proved to be quite cumbersome when realistic, fullcolor, high-resolution images are used as experimental
This research was supported by a Concerted Research Action
(G.O.A.) of the University of Leuven and by agreement RFOIAlI04
of the Incentive Program for Fundamental Research in Artificial Intelligence. The work was conducted while P.M.J.v.D. was a student at
the Nijmegen Institute for Cognition and Information, University of
Nijmegen, the Netherlands, and held an Erasmus scholarship at the
Laboratory of Experimental Psychology, Leuven, Belgium. The authors are indebted to Andreas De Troy and Noel Bovens for their assistance in implementing the eyetracking infrastructure. Further
thanks to Charles de Weert, Gery d'Ydewalle, A. Finley, Karl Verfaillie, and two anonymous reviewers for their comments on an earlier
draft. Correspondence may be addressed to P. M. 1. van Diepen or
P.De Graefat the Laboratoryof ExperimentalPsychology,Universityof
Leuven, Tiensestraat 102, B-3000 Leuven, Belgium (e-mail: paul.
 or ).
stimuli. In the present article, we will describe the nature of the encountered difficulties and will present a
new display change technique that is able to clear away
these obstacles.
At the most rudimentary level ofdescription, any eyemovement pattern across a static display consists ofa series offixations and saccades. A fixation is a period during which the eyes are in rest and information is being
extracted from the stimulus. A saccade is a ballistic eye
movement executed to jump from one fixation position
to another. During a saccade, visual resolution diminishes and sensitivity to stimulus changes decreases considerably . This
basic characterization of eye movements sets the stage
for two types of eye-contingent display changes that
have been used extensively in reading research. In the
moving window technique, all text within a window ofn
characters around the point of fixation is left unaltered
while textual information outside this window is changed
in various ways. Whenever the eyes move to a new fixation position, the window is shifted to that new position
during the saccade . Consequently, if reading is somehow disturbed under these
windowing conditions, one can infer that the changed information outside the window is instrumental to normal
reading performance. This technique has been particularly useful in determining the spatial extent oftext processing. The moving mask technique is especially suited
for examining the chronometry of foveal information
extraction. By masking an area at the fixation position,
and by manipulating the mask onset delay from the start
of the fixation, one can gain insight in the speed with
Copyright 1994 Psychonomic Society, Inc.
which foveal information is acquired .
Obviously, a first requisite for both techniques is the
accurate, on-line discrimination of fixations and saccades, as well as the precise localization of fixation position. An adequate solution to these problems depends
critically on the sampling speed ofthe eyetracker and the
quality of the algorithm for identifying periods of eye
movement and eye stability. An extensive description of
the eyetracking infrastructure underlying our proposal
can be found in Van Rensbergen and De Troy . In
the present text we will concentrate on a second requirement, the fast and precisely timed displaying ofthe
appropriate mask or window at the appropriate position.
In reading research, fulfilling this second requirement
is easier than it is in the study ofscene perception. First,
in normal left-to-right reading, the eye-movement pattern is sufficiently regular to anticipate the next fixation
position. Hence, the mask (window) can already be
shifted to the appropriate position during the eye's saccade toward that location. While saccades in reading
typically only last on the order of 20-35 msec , this saccadic interval is generally
sufficiently long to complete the desired text changes. In
free scene exploration, however, the unpredictability of
eye movements is such that the appropriate position to
display the mask (window) can only be determined when
the eye is already there. Second, text is a relatively simple sort of stimulus to present: a standardized set of
easy-to-position, monochrome characters. Consequently,
text is amenable to presentation on a vector display allowing for very fast stimulus changes. In fact, the speed
of vector displays is such that a relatively simple line
drawing of a scene can be changed in under 4 msec
 . Unfortunately, vector displays are quite expensive, are traditionally driven by a
mini- rather than a microcomputer, and are very limited
in terms of the stimuli that can be displayed: Full-color
stimuli are out of the question, and no easy transfer of
the output of graphics software onto the vector display
is available. These difficulties can be solved by opting
for a raster display, which, however, imposes a strong
limit on the speed ofstimulus change, or the refresh rate
of the display (between 50 and 100 Hz for affordable
models). Third, even under the restrictions imposed by
the use ofa raster display, fast text changes remain conceivable because, usually, only small portions oftext are
changed. Moreover, complete letters are stored in single
bytes. In contrast, full-color, high-resolution images require 1 or more bytes per pixel, which implies that
changing these images involves much larger amounts of
transfer to and from the video memory on the graphics
Several methods have already been proposed for increasing the speed of complex display changes. However, these methods fall short ofthe requirements for the
use of the moving window or mask techniques in scene
perception. Probably the best known method in visual
MOVING MASKS AND WINDOWS
perception research is the virtual screen technique . Stimuli are prepared and assigned to
several, distinct pages of video memory. Following selection of one page as the active page, the stimulus in
that page is written to the display in one screen refresh.
Note that the number of stimuli that can be stored for
such rapid presentation is strictly limited by the number
of pages that can be defined in video memory.
Wittebrood, Wansink, and de Weert and, more
recently, Dixon describe an alternative displaychange technique that makes use ofthe color lookup tables (LUTs) that are currently implemented on many
graphics boards. An LUT maps pixel values contained
in the video memory onto hardware colors. If one simply changes the content of one entry in the table, all pixels pointing to that entry will appear on the screen in the
newly assigned color. For instance, suppose that on
frame n one wishes to present a green background with
a red rectangle on it, and that on frame n + 1 the red
rectangle needs to be replaced by a nonoverlapping blue
circle. This can be achieved by assigning different pixel
values to the rectangle (value 1), the circle (value 2) and
the background (value 3). LUT entry 1 can then be
mapped onto red on frame n and onto green on frame
n + 1, while entry 2 first maps onto green and then onto
blue, and entry 3 maps onto green during both frames.
With this technique, the potential complexity of stimuli
and stimulus changes is limited by the number of available LUT entries: overlap between distinct stimulus
components, use ofmultichromatic components, partial
change of stimulus components-all require additional
LUT entries.
Although both techniques allow for fast display
changes, clearly their major drawback is that for everypossible fixation position on the screen a separate stimulusplus-mask or stimulus-plus-window configuration has
to be prepared in advance. Since in most scene perception research every portion ofthe screen may be selected
for fixation, and this in a highly unpredictable pattern,
too many prepared stimuli would be necessary to cover
all possible situations. Hence, virtual screen or color
LUT techniques will only suffice when the task strictly
constrains the viewer's eye-movement pattern.
An alternative to the clever programming of standard
graphics boards is to turn to customized hardware solutions. Saida and Ikeda developed a moving window technique where a camera image of a bright square
gated the camera image of a stimulus. The square was
generated on an oscilloscope by a function generator,
and its position was directly contingent on the position
ofthe viewer's eye. Although this technique can be quite
fast and it allows for the presentation of complex stimuli within the window, one can only blank the display
outside the window. More subtle changes of visual information are impossible, barring investigation of the
kinds of information that can be extracted at different
distances from fixation. Similarly, while this technique
could probably be modified to produce a moving mask,
VAN DIEPEN, DE GRAEF, AND VAN RENSBERGEN
this would inevitably consist of a rectangular, blanked
area and thus prevent the use of more effective pattern
masks or conceptual masks .
We now turn to a description of our own method
for realizing fast, precisely timed and positioned eyemovement-contingent display changes in high-resolution, full-color images.
THE MOVING OVERLAY MEmOD
Early reading research used a simple
but somewhat primitive moving window technique: A
mask with a hole in it was moved over a "hard-copy"
text. In essence, the technique presented here is the electronic equivalent of that first straightforward method.
The implementation of the technique is centered on the
ATVista videographics adapter (henceforth called the
Vista). The Vista,a product ofTruevision,Inc., is a graphics board for use in a standard IBM-AT-compatible
microcomputer . A version for
Apple Macintosh is also available under the name Nu-
Vista. The board contains video and instruction memory,
and a Texas Instruments TMS 34010 graphics system
processor . Several types
ofVista boards are available at prices around $4,500 (for
Europe), depending on the amount of memory and on
the processing speed. All applications discussed in this
paper were implemented on a Vista with 4Mb of video
memory, 4Mb ofprocessor memory, and a 40-MHz processor clock. Programming of the board was done in
Turbo C 2.0, using the Standard Truevision Adaptable
Graphics Environment .
All Vista boards have four video data channels with corresponding inputs and outputs: red (R), green (G), blue
(B), and a general-purpose channel (Alpha). The Vista
video inputs can take an externally generated analog
video image (e.g., the image from a camera or a VCR)
and convert it to digital data. Thus, two image sources
are available for video output: an external image generated off the board, and an internal image stored in the
on-board video memory (e.g., an image created with a
graphics software package). The Vista supports a wide
range ofuser-programmable video modes, including the
frequently used NTSC and PAL (both interlaced and
noninterlaced).
From this briefdescription, it should be clear that the
Vista has a quantitative advantage over other graphics
adapters. The large amounts of video memory in combination with a dedicated on-board graphics processor
make it possible to use the board as a powerful multichannel tachistoscope. For instance, in NTSC 8-bit video
mode, as many as 10virtual screens with a 756X486 resolution can be stored simultaneously in video memory,
while switches between screens are fast and can be precisely timed (see below). Moreover, the architecture of
the board also includes color LUTs with as many as 256
different entries,whichenablessophisticateddisplay-change
techniques. However, apart from these quantitative advantages, the special input-output architecture of the
Vista constitutes a qualitative advantage that underlies
the new display-change technique described in this paper.
As mentioned above, two video sources are simultaneously available for Vista output (Figure I). Which
source is output depends on the selected display mode.
Three main categories of display modes can be distinguished: live modes, stored modes, and overlay modes.
In live mode, only the external image is output. In stored
mode, the internal image is output. In overlay mode, either image can be output, depending on the values
stored for every individual pixel in the internal image.
This makes it possible to use an external image as background and to superimpose an internal image on top of
it that can be rendered transparent at any desired position in the image. This can be explained best with reference to the 16-bit overlay independent mode. In this
mode, R, G, and B channels can be modified independently.The data for an individual pixel in this mode consist of5 bits per channel, allowing for the selection from
a palette of 32 X 32 X 32 colors, which is quite sufficient for detailed colored pictures. The 16th bit offers
control over the transparency ofthe pixel defined in the
15 other bits: When set to 0, the pixel is opaque; when
ROB + sync
video input
ATVista internally
ROB + sync
video output
(composite
Figure1. Blockdiagram of tile VIStavideo architecture,capableofoutputtingimages from
either an external or an internal source.
set to 1, it becomes completely transparent. Importantly,
pixel bits can be write-protected, making it possible to
alter the internal image without changing the transparency bit, and vice versa. When the Vista is operating
in stored mode, the 16th bit is taken to carry alpha channel data rather than transparency information. Since our
application does not monitor the alpha channel, the very
fast process of switching between stored and overlay
modes is tantamount to switching between an opaque internal image and an internal image that is transparent at
all the predesignated pixels where it offers a view of the
external image. A switch to live mode completely disables the internal image and leaves only the external
Clearly, if the transparency of the internal image
could be made contingent on fixation position, we would
have implemented a moving mask or window across a
stable high-resolution, full-color image. Our solution to
this problem is based on the distinction between displayable resolution and addressable resolution. Every
video mode is characterized by a particular spatial resolution of the pixel matrix that it outputs to the screen:
the displayable resolution. The Vista also offers a userprogrammable spatial resolution of the on-board video
memory: the addressable resolution . The addressable
resolution has to be at least equal to the displayable resolution, but it can be bigger. In this case, only a part of
the addressable video memory can be displayed on the
screen. This part is determined by the user, who can
point an imaginary camera at any part ofthe addressable
video memory. The Vista allows changes in "camera position" (or "panning") with a l-pixel resolution. As is
illustrated in Figure 2, this implies that any pixel of the
addressable video memory can be designated as the
upper left corner of the matrix displayed on the screen,
provided that the lower right corner remains within the
addressable video memory. The panning position is defined by means of the STAGE instruction SetPanPos
We can now integrate the overlay and panning operations, thus creating a window or mask moving across the
scene in synchrony with the eyes. The scene that we
want to present to a viewer is held in a constant, external image supplied to the Vista. The mask (window) that
we want to move across this scene is stored as an opaque
(transparent) region in the internal image, which is otherwise transparent (opaque). The addressable resolution
for this internal image is set to be twice as wide and
twice as high as the displayable resolution, and the center of the mask (window) is aligned with the center of
the addressable video memory. As is shown in Figure 3,
we can now pan in addressable video memory, which
amounts to moving a large overlay over a smaller stable
image. The visible effect of this operation consists of a
series of shifts of the internally stored mask (window)
across the entire height and width ofthe external image,
which remains constant on the screen. Every time a new
fixation position on the screen is registered, the panning
MOVING MASKS AND WINDOWS
Figure 2. Panning the displayable resolution through the addressable resolution. The white rectangle represents the displayable res0lution, which isoutput to the screen. The gray rectangle represents the
addressable resolution. On the left, the upper left panning position (0,
0); on the right. an arbitrary panning position (x,y).
position is adjusted accordingly and the mask (window)
is centered on the fixation position. Appearance of the
mask (window) or scene can be terminated or initiated
at any time simply by switching display modes. In the
next section, a more detailed description is given of our
implementation ofthe moving overlay method in a concrete experimental setup.
A MULTIPLE VISTA EXPERIMENTAL SETUP
In the overlay mode, the Vista composes an output
image from the internal image stored in its own video
memory and an externally generated image supplied to
its video inputs. Any device capable of generating analog RGB + sync PALor NTSC interlaced video signals
can provide that external image. We used a second Vista
for this purpose (Figure 4), which, relative to a camera
or VCR, offers greater flexibility in preparation, on-line
selection, and timing of the sequence of images to be
presented during an experiment. The two Vista boards
were placed in two parallel-connected Intel 386 microcomputers. According to manufacturer specifications,
however, up to eight boards can be placed in one computer , which would further simplify
the implementation of the moving overlay method. Although multiple Vista boards can function independently, they do need to employ the same video timing.
Synchronization is achieved by designating one "master" Vista, which generates the synchronization signals
for all other "slave" Vistas, as well as for the monitor.
This is achieved by genlocking the slaves (STAGE instruction: EnableGenLock) to the master (STAGE instruction: DisableGenLock). In the moving overlay
setup, the master then generates the stable scene that will
be presented to the viewer while the slaves contain overlays. Transparency and movement of these overlays can
be controlled independently.
In our two-Vista setup, the boards were genlocked by
using interlaced, NTSC video timing (60-Hz field refresh rate) with a 16-bit pixel depth. Other video modes
may be selected as well. However, use of the video in-
VAN DIEPEN, DE GRAEF, AND VAN RENSBERGEN
Figure 3. A moving mask based on the moving overlay technique. In the live mode (A), the stimulus generated by an
external video source is output to the screen represented by the smaIl dark-lined rectangle. Switching to the overlay mode
(from panel A to panel B) enables the mask stored in the VIStaaddressable video memory, which is represented by the
large, Iight-lined rectangle. Panels B, C, and D show the stimulus + mask in different panning positions.
puts on the Vista limits the pixel presentation rate,
owing to a maximum analog-to-digital sample rate of
14.3 MHz. This forces us to use interlaced video, which
implies that the time to change a whole display (both
even and odd fields) is twice that for noninterlaced
The 4Mb of Vista video memory can only be organized in three configurations: 1,024 rows of 4K, 2,048
rows of 2K, or 4,096 rows of 1K. To create an addressable matrix that is twice as wide and high as the displayable matrix, a memory configuration is required
which accommodates y rows ofx bytes each, where
y = 2(displayable height),
x = 2(displayable width)(pixel depth/8).
This implies that in standard NTSC (756 X486 display
resolution), one can maximally use 16 bits to define the
appearance of each pixel.
When the master and slave Vistas have been synchronized, the full addressable resolution on the master
Vista can be used to store a number of display pages.
The potential number of pages depends on the defined
pixel depth and decreases as a greater palette of colors
is desired. In NTSC mode this means that IÂ°pages are
available in 8-bit resolution, 4 pages in 16-bit resolution,
and 2 pages in 32-bit resolution. The different pages can
each hold a background to be used in an overlay or can
simply contain subject instructions or a pretrial fixation
point. A fast switch between pages is realized by the Set-
PanPos instruction, thus enabling an effective integration of virtual screen and overlay techniques.
Weare presently using the two-Vista setup in a series
of experiments during which subjects freely explore
complex line drawings of real-world scenes in order to
count specific objects in these scenes. The scenes are
presented in interlaced, standard NTSC mode on a
Barco 6351 CRT and subtend 160 X 12
0 of visual angle
at a distance of 125 em. Eye position is sampled every
millisecond with a Generation 5.5 dual-Purkinje-image
eyetracker , and an on-line decision is made for every incoming measurement as to
whether the eye is fixating or saccading. Eye position
and state are continuously communicated to an Intel 386
personal computer that controls stimulus presentation by
MOVING MASKS AND WINDOWS
PERFORMANCE
We have proposed a method for realizing fast, carefully timed and positioned movement ofa mask or window across a stable background. This moving overlay
method is built on the ability ofthe Vista graphics board
to display a full-color, high-resolution image that is
composed of two distinct sources: a stable background
and a movable, partly transparent foreground. Possibilities for image input to the application are diverse: Instead of the master Vista, any other image source capable of providing RGB + sync interlaced video signals
can be used. In addition, shape, size, and content of the
visible foreground and background portions of the displayed image can be varied at will. Hence, with the position of the foreground brought under eye-movement
control, the basis is provided for a wide range ofexperiments aimed at unraveling the chronometry and spatial
extent ofpictorial information processing.
CONCLUSION
BOYCE, S. J., & POLLATSEK, A. . Identification of objects in
scenes: The role of scene background in object naming. Journal of
Experimental Psychology: Learning. Memory. & Cognition, 18,
CRANE , H. D., & STEELE, C. M. . Generation-V dual-Purkinjeimage eyetracker. Applied Optics, 24, 527-53 7.