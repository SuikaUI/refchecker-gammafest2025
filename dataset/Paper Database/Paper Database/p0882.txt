1063-6706 (c) 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See for more information.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TFUZZ.2020.2966163, IEEE
Transactions on Fuzzy Systems
IEEE TRANSACTIONS ON FUZZY SYSTEM
Abstract—Traditional deep learning methods are sub-optimal
in classifying ambiguity features, which often arise in noisy and
hard to predict categories, especially, to distinguish semantic
scoring. Semantic scoring, depending on semantic logic to
implement evaluation, inevitably contains fuzzy description and
misses some concepts, for example, the ambiguous relationship
between normal and probably normal always presents unclear
boundaries (normal – more likely normal - probably normal).
Thus, human error is common when annotating images. Differing
from existing methods that focus on modifying kernel structure of
neural networks, this study proposes a dominant fuzzy fully
connected layer (FFCL) for Breast Imaging Reporting and Data
System (BI-RADS) scoring and validates the universality of this
proposed structure. This proposed model aims to develop
complementary properties of scoring for semantic paradigms,
while constructing fuzzy rules based on analyzing human thought
patterns, and to particularly reduce the influence of semantic
conglutination. Specifically, this semantic-sensitive defuzzier layer
projects features occupied by relative categories into semantic
space, and a fuzzy decoder modifies probabilities of the last output
layer referring to the global trend. Moreover, the ambiguous
semantic space between two relative categories shrinks during the
learning phases, as the positive and negative growth trends of one
category appearing among its relatives were considered. We first
used the Euclidean Distance (ED) to zoom in the distance between
the real scores and the predicted scores, and then employed two
sample t test method to evidence the advantage of the FFCL
architecture. Extensive experimental results performed on the
CBIS-DDSM dataset show that our FFCL structure can achieve
superior performances for both triple and multiclass classification
in BI-RADS scoring, outperforming the state-of-the-art methods.
Manuscript received June 11, 2019; revised Nov 14, 2019; accepted Jan 1, 2020.
Date of publication XX X, 2020; date of current version Jan 8, 2020.
The work was supported under Royal Society International Exchanges Cost
Share Award (RP202G0230), Medical Research Council Confidence in
Concept (MRC CIC) Award, Hope Foundation for Cancer Research
(RM60G0680), UK.
C. Kang, and X. Yu are with the School of Informatics, the University of
Leicester,
Leicester,
 ;
 ).
S. Wang is with School of Computer Science and Technology, Henan
Polytechnic University, Jiaozuo, Henan 454000, P R China & School of
Mathematics and Actuarial Science, the University of Leicester, Leicester, LE1
7RH, United Kingdom, (e-mail: ).
D, Guttery is with the Leicester Cancer Research Centre, University of
Leicester, Leicester, United Kingdom, (email: ).
Hari Mohan Pandey is with the Department of Computer Science, Edge Hill
University, Lancashire, UK. Email: .
Y. Tian is with the Department of Electrical Engineering, The City College of
New York, 10031, USA, (e-mail: ).
Y.D. Zhang is with School of Informatics, University of Leicester, Leicester,
LE1 7RH, UK & Department of Information Systems, Faculty of Computing
and Information Technology, King Abdulaziz University, Jeddah 21589, Saudi
Arabia, (e-mail: )
*Co-correspondence authors.
Index Terms— Fuzzy deep neural networks, transfer learning,
fuzzy fully connected layer, medical image scoring.
I. INTRODUCTION
EEP learning has recently gathered huge interest across a
multitude of disciplines , which has resulted in
researchers applying deep learning to score medical images.
However, whether pre-training neural networks by natural
images can effectively identify malignant or normal features in
medical images has not yet been sufficiently investigated,
despite the fundamental features between them being diverse.
Further, big datasets may contain high amounts of noise and
uncertainties. Ambiguity features, for example, semantic
relative processing, impose great challenges on data
understanding and classification.
In order to reduce the noise inherent in these systems and
improve diagnostic accuracy, fuzzy learning strategies obtain
specific inherent logic of humans, and have been established , for example, towards image processing , image
classification , and motor control . Researchers have
engaged in developing some new neural networks with inherent
and embedded common senses to address highly challenge
tasks, such as natural language understanding , visual
question answering , and aspect extraction in opinion mining
 . Fuzzy theory to optimize multi-input and single-output
static systems affected by noise has been developed , the
linear and nonlinear defuzzifiers based on fuzzy rules,
compared with conventional deterministic representations, can
reduce the uncertainties encountered in these raw data , as
well as methods to identify nearest-neighbor memeplexes by
fuzzy systems . However, this kind of embedded inherent
knowledge has not yet referred to deep learning classification
regarding to the adjacent overlap of linear scoring. For instance,
the Breast Imaging Reporting and Data System (BI-RADS),
established by the American College of Radiology, is a scheme
for defining mammogram screening into well-defined
categories. BI-RADS scoring can evaluate patients’ status
and provide semantic diagnosis by numerical values, such as
probably benign (BI-RADS 3) or benign (BI-RADS 2), and
these two categories frequently share similar features, which
may increase the difficulty for classifying by using
convolutional neural networks (CNNs). This type of semantic
or affective diagnosis (denotative and connotative information)
 , contains ambiguous information which causes the
partial divergence of neural networks, unlike either
auto-categorization or summarization. Therefore, it is natural to
ask: regarding existing CNNs, how can we reduce the relativity
Cheng Kang, Xiang Yu, Student Member, IEEE, Shui-Hua Wang*, Member, IEEE, David S. Guttery*,
Hari Mohan Pandey*, Yingli Tian*, Fellow, IEEE, Yu-Dong Zhang*, Senior Member, IEEE
A Heuristic Neural Network Structure Relying
on Fuzzy Logic for Images Scoring
1063-6706 (c) 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See for more information.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TFUZZ.2020.2966163, IEEE
Transactions on Fuzzy Systems
IEEE TRANSACTIONS ON FUZZY SYSTEM
of adjacent categories by improving these traditional neural
networks with inherent knowledge from human thought?
Our proposed method differs from previous studies since we
are assembling priori knowledge derived from the suggestion of
experts (mainly about the property of categories), being greedy
to lead outputs to the global performance and fitting parameters
by modifying back propagation errors. Thus, based on one
previous study for self-constructing fuzzy systems, and to
verify the question about margins reinforcement and classify
ambiguous cases, we designed three experiments in this study,
including reinforcement of margins and learning of these
reinforced features through six CNNs in the first learning phase,
concatenation of the established fuzzy fully connected layers
(FFCLs) on the top of the best-performing CNN for triple in the
second learning phase and six-class classifications in third
learning phase, to gradually improve the inherent structure of
traditional neural networks. The influence of margin status is a
significant measurement to evaluate breast cancer . We
calculated margins by canny and log operators, and designed
improved neural networks to learn these important features in
this study, because these two operators are recognized as the
most generally used edge detectors.
Depending on FFCL, features represented by these
pre-trained networks were fused together in this nonlinear layer,
and then reserved, deblurred, and adjusted. It can offer
traditional neural networks the ability to build cognitive
connections among relative categories in the last output layer,
and more dependable update of weights and biases thereof. For
instance, the forming of the final probabilities for data
classification in the output layer can then partially present the
distribution of features related to high or low scores. Briefly,
after training of several epochs, the neural network without any
improvement was able to identify BI-RADS scores with
acceptable accuracy. Referring to the probabilities’ distribution
of the output layer, FFCL can reduce the uncertainties and noise
of the original data by updating these output probabilities and
back propagation errors. As a result, these updated back
propagation errors can influence the presentation of every
layer’s weights and bias. Overall, FFCL neural networks can be
applied to more difficult pattern classification tasks, such as
BI-RADS involving data ambiguity and noise. We selected
ResNet from seven simple neural networks and supplemented
FFCL, as this structure leads to better performance than other
state of the art methods in this study.
In this paper, 1) we verified that the enhancement of visual
features, such as edges, is not so beneficial to improve the
performance of CNNs, which essentially demonstrated that
CNNs can extract visual features; 2) we proved that the transfer
learning strategy, especially trained by natural categories, can
convolutional layers cannot detect new medical information
from CBIS-DDSM image dataset; 3) this proposed and
introduced FFCL architecture, which essentially focused on
fused fuzzy rules deriving from parsing logic representation
with traditional convolutional neural networks for semantic
BI-RADS scoring, weakens the fusion logic in terms of fuzzy
semantic definition, as this type of semantic diagnosis always
contains an unstable overlap between two neighbour categories;
4) these extensive experiments demonstrated that the proposed
FFCL architecture is effective and outperforms other existing
state-of-the-art methods when scoring BIRADS based on the
CBIS-DDSM dataset. Codes and models are available at:
 
II. SCORING AND FUZZY FULLY CONNECTED LAYER
A. Fuzzy scoring and structure of fuzzy fully connected layer
Let the training set be 𝑇𝑇= [(𝑥𝑥1, 𝑦𝑦1), (𝑥𝑥2, 𝑦𝑦2), . . . , (𝑥𝑥𝑛𝑛, 𝑦𝑦𝑛𝑛)],
where 𝑥𝑥𝑖𝑖 is the variable explaining the data and 𝑦𝑦𝑖𝑖 is the
corresponding label, for all 𝑖𝑖= 1,2, . . . , 𝑛𝑛 where n is the
number of training samples. We assumed that the sample was
partitioned into m scoring categories, which were defined as
real score 𝑆𝑆= [𝑆𝑆1, 𝑆𝑆2, . . . , 𝑆𝑆𝑚𝑚]. Therefore, for more accurate
evaluation, the estimated score 𝑆𝑆̃ = [𝑆𝑆̃1, 𝑆𝑆̃2, . . . , 𝑆𝑆̃𝑚𝑚] followed
by a decimal part.
1) Fuzzy Function: To minimize the influence between two
relative categories, this fuzzy function involves directed
extensional scores. For CNNs, the probabilities are defined by
sigmoid function:
𝑃𝑃(𝑥𝑥𝑖𝑖|𝑦𝑦𝑖𝑖= 𝑖𝑖) =
𝑒𝑒−𝐸𝐸(𝑦𝑦𝑖𝑖,𝑥𝑥𝑖𝑖)
𝑒𝑒−𝐸𝐸(𝑦𝑦𝑖𝑖,𝑥𝑥𝑖𝑖)
and its left and right neighbors:
𝑃𝑃൫𝑥𝑥𝑖𝑖±1ห𝑦𝑦𝑖𝑖±1 = 𝑖𝑖± 1൯=
𝑒𝑒−𝐸𝐸(𝑦𝑦𝑖𝑖±1,𝑥𝑥𝑖𝑖±1)
𝑒𝑒−𝐸𝐸(𝑦𝑦𝑖𝑖±1,𝑥𝑥𝑖𝑖±1)
where 𝐸𝐸(𝑦𝑦𝑖𝑖, 𝑥𝑥𝑖𝑖) is the expectation that 𝑥𝑥𝑖𝑖 is predicted as 𝑦𝑦𝑖𝑖, and
𝑚𝑚 is the number of the categories. According to some previous
common studies of CNNs, the 𝑃𝑃(𝑥𝑥𝑖𝑖|𝑦𝑦𝑖𝑖) ∈(0,1) and this
probabilistic distribution has the following affine forms :
𝑃𝑃(𝑥𝑥𝑖𝑖|𝑦𝑦𝑖𝑖= 𝑖𝑖) = 𝜎𝜎(𝑊𝑊𝑖𝑖𝑥𝑥𝑖𝑖+ 𝑏𝑏𝑖𝑖),
𝑃𝑃൫𝑥𝑥𝑖𝑖±1ห𝑦𝑦𝑖𝑖±1 = 𝑖𝑖± 1൯= 𝜎𝜎(𝑊𝑊𝑖𝑖±1𝑥𝑥𝑖𝑖±1 + 𝑏𝑏𝑖𝑖±1),
where 𝑊𝑊𝑖𝑖 is the weight in layer 𝑖𝑖, and 𝑏𝑏𝑖𝑖 is the bias in layer 𝑖𝑖.
To reduce the conglutination between two either neighbors or
remote classes, the recursive score was calculated by
𝑃𝑃(𝑥𝑥𝑖𝑖|𝑦𝑦𝑖𝑖)
𝑃𝑃(𝑥𝑥𝑖𝑖|𝑦𝑦𝑖𝑖)
where 𝑎𝑎 is the trend of negative growth, while 𝑏𝑏 is the trend of
positive increasing, for example, the normal trend to become
healthy, and the abnormal trend to become cancer. Therefore,
the output value modified by above operators tend to slip
forward to the global average position, and we optimized the
redistributed probabilities from Equation (1) to
𝑃𝑃෨(𝑥𝑥𝑖𝑖|𝑦𝑦𝑖𝑖= 𝑖𝑖) =
|𝑖𝑖−𝑉𝑉෩𝑜𝑜|
𝑒𝑒−𝐸𝐸(𝑦𝑦𝑗𝑗,𝑥𝑥𝑗𝑗)
𝑒𝑒−𝐸𝐸(𝑦𝑦𝑗𝑗,𝑥𝑥𝑗𝑗)
Finally, the back propagation error between the real and the
estimation was modified from
1063-6706 (c) 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See for more information.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TFUZZ.2020.2966163, IEEE
Transactions on Fuzzy Systems
IEEE TRANSACTIONS ON FUZZY SYSTEM
𝜀𝜀𝑖𝑖= 𝑦𝑦𝑖𝑖−𝑃𝑃(𝑥𝑥𝑖𝑖|𝑦𝑦𝑖𝑖= 𝑖𝑖),
𝜀𝜀̃𝑖𝑖= 𝑦𝑦𝑖𝑖−𝑃𝑃෨(𝑥𝑥𝑖𝑖|𝑦𝑦𝑖𝑖= 𝑖𝑖)
The influence of the modified 𝜀𝜀̃𝑖𝑖 can be calculated as:
𝜙𝜙= 𝜀𝜀̃𝑖𝑖−𝜀𝜀𝑖𝑖
|𝑖𝑖−𝑉𝑉෩𝑜𝑜|
𝑒𝑒−𝐸𝐸ቀ𝑦𝑦𝑗𝑗,𝑥𝑥𝑗𝑗ቁ
𝑒𝑒−𝐸𝐸ቀ𝑦𝑦𝑗𝑗,𝑥𝑥𝑗𝑗ቁ
𝑒𝑒−𝐸𝐸൫𝑦𝑦𝑖𝑖,𝑥𝑥𝑖𝑖൯
𝑒𝑒−𝐸𝐸൫𝑦𝑦𝑖𝑖,𝑥𝑥𝑖𝑖൯
Because 𝑎𝑎 and 𝑏𝑏 are variables, we can find that the distance
from 𝑎𝑎 to 𝑏𝑏 is constant. Thus, the left part of formula should be
|𝑖𝑖−𝑉𝑉෩𝑜𝑜|
If probabilities from category 𝑖𝑖−𝑎𝑎 to category 𝑖𝑖+ 𝑏𝑏 are
same, we will discover that:
|𝑖𝑖−𝑉𝑉෩𝑜𝑜|
𝑒𝑒−𝐸𝐸(𝑦𝑦𝑖𝑖,𝑥𝑥𝑖𝑖)
𝑒𝑒−𝐸𝐸(𝑦𝑦𝑖𝑖,𝑥𝑥𝑖𝑖)
Therefore, 𝜙𝜙≤0. Although probabilities from category 𝑖𝑖−
𝑎𝑎 to category 𝑖𝑖+ 𝑏𝑏 are not always equal, we define the
category 𝑖𝑖 is the highest among the entire categories, and we
find that:
𝑒𝑒−𝐸𝐸(𝑦𝑦𝑗𝑗,𝑥𝑥𝑗𝑗)
𝑒𝑒−𝐸𝐸(𝑦𝑦𝑗𝑗,𝑥𝑥𝑗𝑗)
𝑒𝑒−𝐸𝐸(𝑦𝑦𝑖𝑖,𝑥𝑥𝑖𝑖)
𝑒𝑒−𝐸𝐸(𝑦𝑦𝑖𝑖,𝑥𝑥𝑖𝑖)
Followed by above formulas, we can conclude that 𝜙𝜙≤0
during these two above conditions. That means 𝜀𝜀̃𝑖𝑖 will bring
lesser influence into whole neural networks, when considering
the globally optimal strategy in fully connected layer.
2) Gradient Related Optimization: We used the cross-entropy
function to calculate the error when implementing back
propagation step 
𝐻𝐻(𝑦𝑦𝑖𝑖, 𝑦𝑦෤𝑖𝑖) = −
∑[𝑦𝑦෤𝑖𝑖𝑙𝑙𝑙𝑙𝑙𝑙(𝑦𝑦𝑖𝑖) + (1 −𝑦𝑦෤𝑖𝑖) 𝑙𝑙𝑙𝑙𝑙𝑙(1 −𝑦𝑦𝑖𝑖)]
where 𝑦𝑦෤𝑖𝑖 is the probability of an evaluated output 𝑃𝑃෨(𝑥𝑥𝑖𝑖|𝑦𝑦𝑖𝑖= 𝑖𝑖).
Based on Equations (1), (5), (6), and (14), the gradients of
negative or positive log-probabilities in the last layer then
would be presented as:
∂|𝑦𝑦𝑖𝑖−𝑃𝑃෨(𝑥𝑥𝑖𝑖|𝑦𝑦𝑖𝑖=𝑖𝑖)|
𝑙𝑙𝑙𝑙𝑙𝑙𝑙𝑙𝑙𝑙=𝑙𝑙
where 𝜃𝜃𝑖𝑖
(𝑙𝑙) is the parameters in the 𝑙𝑙𝑡𝑡ℎ layer for category i, 𝑜𝑜𝑖𝑖
is the output lay according to category i. Therefore, we can get
the follow formulas from (3), (4), and (15):
∂𝑊𝑊𝑖𝑖(𝑙𝑙) = ∑
∂|𝑦𝑦𝑖𝑖−𝑃𝑃෨(𝑥𝑥𝑖𝑖|𝑦𝑦𝑖𝑖=𝑖𝑖)|
𝑙𝑙𝑙𝑙𝑙𝑙𝑙𝑙𝑙𝑙=𝑙𝑙
∂𝑊𝑊𝑖𝑖(𝑙𝑙),
∂|𝑦𝑦𝑖𝑖−𝑃𝑃෨(𝑥𝑥𝑖𝑖|𝑦𝑦𝑖𝑖=𝑖𝑖)|
𝑙𝑙𝑙𝑙𝑙𝑙𝑙𝑙𝑙𝑙=𝑙𝑙
Before assembling FFCL into CNNs, the parameters
connected with a specific category updated referring to
traditional errors, and this type of error can induce a chain
reaction for all layers and the inability to lead parameters to the
more properly global optimization. For example, the error
𝜀𝜀1appearing in Grade1 point which presents in Figure 1 go
through every layer from Grade1 point to input layer. The thick
green arrow shows the back propagation of 𝜀𝜀1 before
assembling FFCL into CNNs, and referring to the typical ReLU
functions which can open or close the connection between
previous and current layers, 𝐹𝐹𝑎𝑎1 connects with 𝐿𝐿1 and 𝐿𝐿2.
Figure 1. Conceptual explanation of the FFCL’s structure in CNNs. It is
composed of four parts, input layer function layers, fuzzy transformation, and
output layer.
However, after embedding FFCL into CNNs, the influence
of 𝜀𝜀1 will switch to the global optimized error. The connections
swapped to 𝐹𝐹1 with 𝐿𝐿1 and 𝐿𝐿3, because the hyperparameter
𝑾𝑾𝟏𝟏𝑭𝑭𝑭𝑭𝑭𝑭 are more likely to close to dispersive solution for neural
network training, when compared with the hyperparameter
𝑾𝑾𝟏𝟏𝑭𝑭𝑭𝑭𝑭𝑭 optimized by fuzzy strategy. Sometimes, some
redundant functions or blocks will appear in neural networks
because of the attribute of neural networks. Thus, the blue 𝐿𝐿𝑧𝑧−1
and 𝐿𝐿𝑧𝑧 are the redundant blocks or functions in this system.
Function layers in Figure 1 include the traditional structures,
for example, convolutional layers, ReLU layers, pooling layers
and so on. After such change, the structure of this proposed
neural network will be modified, more especially, these refined
Input Layers
Function Layers
Fully Connected Layers
Output Layers
Back Propagation of FFCL
Back Propagation of FCL
1063-6706 (c) 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See for more information.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TFUZZ.2020.2966163, IEEE
Transactions on Fuzzy Systems
IEEE TRANSACTIONS ON FUZZY SYSTEM
ambiguous features extracted by this type of CNNs can to some
extent achieve a high decorrelation.
3) Implementation of FFCL: We set the default accuracy rate at
65% before the beginning of FFCL training tasks. If
probabilities of normal trend (𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠 ) and possibly normal
trend (𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠 ) are approximately equal, and if they are
obviously greater than that of others, for example, the
possibility of the abnormal, this appendix can provide relative
and significant assistance to classify these two ambiguous
categories. In this study, we defined a proper THRESHOLD. If
the maximum of output probabilities located among 𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖−
1] (𝑖𝑖> 0), 𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖] and 𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖+ 1], where 𝑖𝑖 is the score
from 0 to m, there are three conditions that should be
considered by fuzzy rules (in Figure 2).
We also defined 𝑦𝑦𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↗1] and 𝑦𝑦𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↘1] as the ascending
or descending trends of normal or abnormal respectively. For
example, we define that the trend from the abnormal side to the
normal side is negative, which means more normal, and if 𝑖𝑖=2,
then 𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↗1] will be the 𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠 , and 𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↘1] will
be the 𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠 . Moreover, this FFCL is a nonlinear function,
which can partially verify the error-prone condition. If when
the probability of 𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠 is 0.32, and that of 𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠 is 0.33,
it will be frequently identified improperly under this condition,
as the difference of these two ratios is not obvious. To widen
the gap between these two ratios, the value of 𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠 should
be considered. Then, the back propagation error will be
modified by these fuzzy rules with an adaptive parameter based
on the probabilities of these three categories. During the update
of weights and bias, the effect of 𝜀𝜀𝑖𝑖 will enhance or restrain the
learning process of significant features. The key pseudocode is
illustrated in Algorithm 1.
Algorithm 1. The algorithm of FFCL
The algorithm of FFCL: Before the start of FFCL training, samples
and labels should be trained for several epochs.
Start of iteration:
If the accuracy rate is greater than the value, at 0.8× average accuracy rate
(AAR, we previously trained the neural networks and calculated the average
accuracy rate), then we start following iteration: for 𝑖𝑖= 0,1, . . . ,5
If the maximum of probabilities located among score 𝑖𝑖−1 (𝑖𝑖> 0), score 𝑖𝑖
and score 𝑖𝑖+ 1:
Rule I: If 𝑖𝑖= {2，4},
a) when probabilities of 𝑦𝑦𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↘1] and 𝑦𝑦𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖] are greater than the
THRESHOLD, but 𝑦𝑦𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↗1] is less than THRESHOLD. Modify the
output of 𝑉𝑉𝑜𝑜 by (5), where 𝑛𝑛= 𝑖𝑖−2, 𝑚𝑚= 𝑖𝑖+ 1. And get 𝑃𝑃𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↘1]
and 𝑃𝑃𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖] by (6).
b) when probabilities of 𝑦𝑦𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↗1] and 𝑦𝑦𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖] are greater than the
THRESHOLD, but 𝑦𝑦𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↘1] is less than the THRESHOLD. Modify
the output of CNNs 𝑉𝑉𝑜𝑜 by (5), where 𝑛𝑛= 𝑖𝑖−1, 𝑚𝑚= 𝑖𝑖. And get
𝑃𝑃𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↗1]and 𝑃𝑃𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖] by (6).
If 𝑖𝑖= {3},
a) when probabilities of 𝑦𝑦𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↘1] and 𝑦𝑦𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖] are greater than the
THRESHOLD, but 𝑦𝑦𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↗1] is less than the THRESHOLD. Modify
the output of CNNs 𝑉𝑉𝑜𝑜 by (5), where 𝑛𝑛= 𝑖𝑖−2, 𝑚𝑚= 𝑖𝑖+ 1. And get
𝑃𝑃𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↘1] and 𝑃𝑃𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖] by (6).
b) when probabilities of 𝑦𝑦𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↗1] and 𝑦𝑦𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖] are greater than
THRESHOLD, but 𝑦𝑦𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↘1] is less than the THRESHOLD. Modify
the output of CNNs 𝑉𝑉𝑜𝑜 by (5), where 𝑛𝑛= 𝑖𝑖−1, 𝑚𝑚= 𝑖𝑖+ 2. And get
𝑃𝑃𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↗1] and 𝑃𝑃𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖] by (6).
Rule III: If 𝑖𝑖= {2,3,4},
a) when probabilities of 𝑦𝑦𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↘1], 𝑦𝑦𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖] and 𝑦𝑦𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↗1] are greater
than the THRESHOLD, and they are approximately equal to each
other, modify the output of CNNs 𝑉𝑉𝑜𝑜 by (5) where 𝑛𝑛= 𝑖𝑖−1, 𝑚𝑚= 𝑖𝑖+
1 . And 𝑃𝑃𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖] will be 𝑚𝑚𝑚𝑚𝑚𝑚( 𝑃𝑃𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↘1], 𝑃𝑃𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖], 𝑃𝑃𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠[𝑖𝑖↗1]) , and
keep others the same.
End of iteration.
Output: the decimal score and improved CNNs with modified weights
Figure 2. The core structure of FFCL.
III. EXPERIMENTAL RESULTS
A. Dataset and Model Configurations
We used the Curated Breast Imaging Subset of Digital
Database of Screening Mammography (CBIS-DDSM) dataset
to test our proposed FFCL. The CBIS-DDSM is a large
collection of digitized film mammography images, which
includes 3,572 images referring to 2689 patient cases.
According to BI-RADS, overall BI-RADS assessment from 0
to 5 has been described in this dataset, including BI-RADS
score 0 (Incomplete cases), BI-RADS score 1 (Negative cases),
BI-RADS score 2 (Benign cases), BI-RADS score 3 (Probably
Benign cases), BI-RADS score 4 (Suspicious Abnormal cases)
and BI-RADS score 5 (Highly Suspicious Malignant cases), the
distribution of which in the CBIS-DDSM dataset is shown in
Table 1. Because there are only three normal cases, for triple
classification we redistributed three categories, including
redefining score 0 as incomplete, combining score 2 with score
3 as benign, and merging scores 4 and score 5 together as
malignancy. You can search this type of medical dataset on
Table 1. The distribution of samples of CBIS-DDSM dataset based on
BI-RADS assessment
Calcification
Training Set
Calcification
Testing Set
As shown in Figure 3, a gray-scale mammogram contains
only one gray colour channel, so strategy 1 (S1) used each gray
1063-6706 (c) 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See for more information.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TFUZZ.2020.2966163, IEEE
Transactions on Fuzzy Systems
IEEE TRANSACTIONS ON FUZZY SYSTEM
mammogram replicating onto three colour channels. Strategy 2
(S2) applied edge operators to extract margins and stacked
them into other two colour channels, while strategy 3 (S3)
utilized combination of margins and gray mammogram to
submitted other two colour channels. Red lines in Figure 3
edges of mammograms extracted by two basic edge operators,
log and canny . Because the ImageNet data has 1000
classes, the last output layer was submitted by a three-class
softmax layer, and these three categories consist of incomplete,
benign and malignant cases.`
Figure 3. Mammograms from CBIS-DDSM with the log and canny edges. (a),
The gray mammogram. (b), The gray mammogram with log edges. Red lines
are log edges. (c), The gray mammogram with canny edges. Red lines are the
canny edges.
Figure 4. Clustering arrangement allowing overlap and selecting the scores
according to the labels (or classes) attached to them.
In Figure 4, to simplify the explanation, we defined that the
X direction is negative, and its score is 1. The following
directions are the same pattern above. There are only two
conditions which can be identified with difficulty. The first is
that each adjacent category excludes the condition between
incomplete cases and negative cases, because incomplete cases
approximately have no relationship with other cases. Surfaces
XY, yZ, and xy may be difficult to be identified, which means
there may be medians between XY, yZ or xy, as their
definitions show the high internal relationship. For example,
the negative may become the benign in the future, but it
actually cannot suddenly transform to high BI-RADS scores,
such as probably benign, suspicious abnormality or high
suspicious
malignancy.
probabilities which are approximately equal to each other, such
as the probabilities of XYZ, xyZ, we defined that the middle
category has the highest probability. Moreover, if these three
rectangles seem like that their size on cohorts are not same, that
means their probabilities are equal to others.
Many existing CNNs were used in this study (in Table 2),
including the 16-layer and 19-layer VGG networks (VGG16
and VGG19) , the 18-layer, 50-layer and 101-layer residual
networks (ResNet-18, ResNet-50 and ResNet-101) , and
GoogleNet . Therefore, top layers were designed for whole
image classification. In Figure 5, after removal of the
1000-class FCL top layer, six-class FCL or FFCL was stacked
behind the top layer in all experiments. However, more
convolutional and pooling layers were trained during the
second learning phase, and these layers were also added on the
top layer. Then during every training task, when the validation
rate was reaching the top, the training process was finished and
we measured the number of epochs.
B. Statistical analysis
Table 2 presents the abbreviation of all plans and the layout
experiments,
S1-ResNet-101-
3Conv-FCLbased on FCL. In the plan of S1-ResNet-101-
(+3Conv)-FCL, (+3Conv) means that adding the last 3
convolutional layers and training them with FCL together for
classifying tasks. NC means the number of classes. Four
different learning phases were performed utilizing the
CBIS-DDSM dataset in testing the CNN models’ recognition
capacity for binary, triple and 6-class classifications. ROC
curves were generated and aACCs were calculated as a
metric of classification accuracy. The confusion matrix, which
is a table that can describe the performance of a classification
model, was used to test the true values . We used two
sample T-test to verify the significance of ACC sequences
between two CNNs, and 95% confidence intervals were
calculated for ACC values using bootstrapping methods .
The deep learning network was implemented using the Matlab
platform running on a desktop computer system with the
specifications:
 with 8 GB RAM and a Titan X Pascal
Graphics Processing Unit (GPU).
Table 2. Experiments and the structure of neural networks in this study.
Abbreviation
First Learning Phase
S1-ResNet-18-FCL
S1-ResNet-50-FCL
S1-ResNet-101-FCL
S1-VGG-16-FCL
S1-VGG-19-FCL
S1-GoogleNet-FCL
S1-ResNet-101-FCL
S1-VGG-16-FCL
S2-ResNet-101-FCL
S2-VGG-16-FCL
S3-ResNet-101-FCL
1063-6706 (c) 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See for more information.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TFUZZ.2020.2966163, IEEE
Transactions on Fuzzy Systems
IEEE TRANSACTIONS ON FUZZY SYSTEM
S3-VGG-16-FCL
Second Learning Phase
S1-ResNet-101-3Conv-FC
S1-ResNet-101-3Conv-FCL
S1-ResNet-101-(+3Conv)-F
(+3Conv)-FC
ResNet-101-(+6Conv)-FCL
(+6Conv)-FC
S1-Naive Bayes
S1-Random Forest
Third Learning Phase
S1-ResNet-101-FFCL
S1-ResNet-101-3Conv-FF
S1-ResNet-101-FCL
S1-ResNet-101-FFCL
S1-ResNet-101-3Conv-FCL
S1-ResNet-101-3Conv-FF
C. Networks training strategy
To verify whether the enhancement of visual features is
important to improve the performance of CNNs, to validate the
advantage of FFCL step-by-step, and to compare with
state-of-art, we designed our experiments according to above
purposes in this study. Figure 5 explains the structure of
training tasks.
Part Ⅰ – First learning phase: This part determined whether
the important visual edge is the significant feature for deep
learning improving, and to select the best-performing neural
network among these pre-trained CNNs. We stacked two
different edges onto two colour channels and then trained these
pre-trained neural networks. Depending on pre-trained weights
based on the ImageNet database, rather than randomly
initialized parameters, these networks were improved by
accelerating
generalizations
successfully produced to represent features. In this training
stage, parameters except the top layer were frozen before
training tasks, while simultaneously decreasing the learning
rate during training progress. In order to validate whether
margin features can be represented or not, S2 and S3 were
applied to test these pre-trained VGG-16 and ResNet-101.
Table 3 shows that S1-ResNet-101-FCL performed best among
residual neural networks, and S1-GoogleNet-FCL was slightly
inferior to S1-VGG-16-FCL, which exceeds S1-VGG-19-FCL.
After stacking with edges onto the two-colour channels, aACC
S2-ResNet-101-FCL
S2-VGG-16-FCL
decreased when compared with these two networks, which only
replicated the same mammogram figure. Some researchers’
findings supported our result, as they demonstrated that
VGG-16 and ResNet-50 have the obvious advantage to classify
mammograms . Figure 6 shows ROC curves and confusion
matrixes for ResNet-101, VGG-16 and GoogleNet. All
categories can be well-distinguished, but the incomplete cases
were the most well-defined using both ResNet-101 and
Table 3. The learning phase used pre-trained neural networks.
aACC / (ACC range)
S1-ResNet-18-FCL
72.62%/ (72.16%~73.30%)
S1-ResNet-50-FCL
73.62%/ (72.73%~74.15%)
S1-ResNet-101-FCL
74.76%/ (73.72%~75.71%)
S1-VGG-16-FCL
70.95%/ (69.89%~72.02%)
S1-VGG-19-FCL
69.44%/ (68.32%~70.31%)
S1-GoogleNet-FCL
70.82%/ (70.03%~71.73%)
For the confusion matrix of S1- ResNet-101-FCL, of the 46
incomplete cases, this model predicted that 3 cases are benign,
and 13 cases are malignant. Of the 2 normal cases, it predicts
that all were malignant. And of the 194 benign cases, 4 cases
are attached to incomplete, 100 cases are predicted to belong to
benign, and the last 90 cases are deemed to be malignant. Of the
462 malignant cases, it predicts that 11 cases are incomplete, 52
cases are benign, and 399 cases are malignant. As the matrix
shown in Figure 6, both ResNet-101 and VGG-16 have the
disadvantage to distinguish malignancy from benign; but both
networks can make obvious distinction between incomplete
cases and other types of cases. Among the six CNNs,
ResNet-101
ResNet-50,
ResNet-18, VGG-16, GoogleNet and VGG-19 in sequence.
Figure 5. The deep learning structure for improving CNNs by training deeper
last convolutional layers, adding and training the last residual convolutional
layers, and establishing fuzzy rules block on top.
While in the first learning phase, all these CNNs can
satisfactorily distinguish each BI-RADS assessment, but only
training of the FCL may result in some features that cannot be
extracted by pre-trained blocks. Due to there still being some
important features that should be represented by CNNs, the
larger dataset size or something intrinsic to the characteristics
of the DDSM dataset should be represented by our models,
therefore, only training FCL is insufficient. According to
incomplete cases, which have to be re-examined radiologically,
1063-6706 (c) 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See for more information.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TFUZZ.2020.2966163, IEEE
Transactions on Fuzzy Systems
IEEE TRANSACTIONS ON FUZZY SYSTEM
the lack of information for diagnosis can inform CNNs that
these kinds of mammograms have insufficient features and
should be re-examined. All 6 types of CNNs have an
encouraging advantage to identify incomplete and malignant
cases, but are less efficient at recognizing malignant from
benign cases. Although doctors often disagree on how a
particular exam should be classified and less than 1% of
the screening population has cancer , researchers expect
that this problem can be alleviated by using the information
about whether a person proceeded to develop breast cancer in
the future as an identifier . Even if the mammogram is
identified as normal or benign, the incomplete cases may
become the mortal potential for patients, therefore, a high rate
of incomplete cases’ recognition can make diagnosis more
reliable. In Table 4, although three different strategies had been
utilized, S1 presents the best performance, which provides the
evidence that the enhancement of margins in mammograms
will result in the graphic degeneration when using ResNet-101
and VGG-16.
To construct a better neural network structure during the
following experiments, we subsequently designed the second
and the third learning phases through S1 in those following
steps. S2 may discard some significant features, and this is the
reason why the ACC array of using S1 is significantly greater
than that of using S2 (P < 0.01). Sometimes, the enhancement
of margins for mammograms will result in overfitting, as the
ACC array of using S3 is significantly less than that of using S1
(P < 0.01). If CNNs cannot efficiently extract margins, there
may be no overfitting during this experiment, because these
margin features have been reinforced. Thus, this can explain
why deep learning can represent features that radiologists may
not distinguish.
Table 4. Considering to reinforce the visible features, we only trained the FCL
based on the pre-trained ResNet-101 and pre-trained VGG-16 in this task.
aACC / (ACC range)
S1-ResNet-101-FCL
74.76%/ (73.72%~75.71%)
S1-VGG-16-FCL
70.95%/ (69.89%~72.02%)
S2-ResNet-101-FCL
71.51%/ (70.60%~72.73%)
S2-VGG-16-FCL
68.41%/ (67.76%~69.32%)
S3-ResNet-101-FCL
69.13%/ (68.18%~70.03%)
S3-VGG-16-FCL
70.11%/ (69.32%~71.16%)
For traditional computer-aided detection or diagnosis,
predefined features are usually used for constructing models,
which require pre-emptive determination of which features will
contribute to classification tasks . However, in our study,
we believe that predefinition of the graphic features is not
necessary, and before our training tasks based on CBIS-DDSM,
these visible features have already been automatically
represented by ImageNet dataset . Obvious features, such
as margins, can be recognized by radiologists, and it also can be
detected by the learning process, while intrinsic and invisible
features which are used for imaging interpretation may not be
identified by human beings also can be automatically
recognized by CNNs .
Many studies have shown the advantage of transfer learning
to process limited medical data . We provide deeper
insights in developing optimized transfer learning strategies by
designing training experiments. However, the incremental
transfer learning and the observations made here need to be
evaluated by further analyses and comparative studies.
1063-6706 (c) 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See for more information.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TFUZZ.2020.2966163, IEEE
Transactions on Fuzzy Systems
IEEE TRANSACTIONS ON FUZZY SYSTEM
Figure 6. The ACC curve and confusion matrixes. From left to right successively (a) S1-ResNet-101-FCL, (b) S1-VGG-16-FCL and (c) S1-GoogleNet- FCL in the
first learning phase for the triple classification scenarios based on CBIS-DDSM dataset.
Part Ⅱ – The second learning phase: The second part aimed to
train the last convolutional layers, or add and train the last
convolutional layers. After the FCL was removed, parameters
from the bottom layers to the final or penultimate VGG and
residual blocks were frozen, and the remaining weights and
bias were trained and updated in the neural network. By
contrast, we also respectively added one or two VGG and
residual blocks on the top layer and only trained them to learn
features. Because some ambiguous features between two
adjacent categories were difficult to identify, we used the FFCL
to improve the performance of ResNet-101. In the second
learning phase, to carry out which kind of structure will
perform best, we selected ResNet-101 and VGG-16 to
complete these training tasks. In Table 5, the best single ACC
rate of ResNet-101 is 76.82% which was recorded during one
best-performed single training task, but significantly greater
than that of ACC array in the variance of ACC array in
S1-ResNet-101-3Conv-FCL is S1-ResNet-101-FCL (P < 0.01).
performance
S1-ResNet-101-3Conv-FCL and S1-ResNet-101-FFCL (P
=0.243). On the contrary, training 6 last layers (residual or
VGG blocks) made the ACC array dropped significantly (P <
After adding VGG or residual convolutional blocks onto the
top layer, Table 5 shows that the ACC array of S1
-ResNet-101-(+3Conv)-FCL
S1-ResNet-101-(+6Conv)-FCL (P = 0.032), which indicates
that S1-ResNet-101-(+3Conv)-FCL can represent more
features. Compared the performance of S1-ResNet-101-FCL
and S1-ResNet-101-3Conv-FCL, S1-ResNet-101-FFCL based
on FFCL algorithm can significantly increase ACC array.
Moreover, the advantage of S1-ResNet-101-3Conv-FFCL is
obvious (P < 0.01), therefore, the influence of FFCL can to
some extent improve the structures we designed above. To
teach and train computers about how to recognize can
sometimes achieve extraordinary success. If the algorithm is
not able to be strictly recognized as the ‘over uncertainties
averaged log membership’, fuzzy systems can enhance the
probability of distinguishing uncertain features .
Some traditional machine learning methods, such as Naïve
Bayes , support vector machine (SVM) and random
forest (RF) were utilized to compare each CNNs. Although
random forest can reach the same performance of
S1-ResNet-101-3Conv-FFCL, but the best single ACC was
different. The improved ResNet-101 through updated
structures and fuzzy rules has the potential to outperform these
traditional machine learning methods.
Table 5 The performance of adding and retraining three or six last layers.
S1-ResNet-101-3Con
(70.88%~76.70%)
S1-VGG-16-3Conv-F
S1-ResNet-101-6Conv
(69.32%~74.29%)
S1-ResNet-101-(+3Co
(69.74%~74.72%)
S1-VGG-16-(+3Conv)
ResNet-101-(+6Conv)
(69.89%~74.57%)
S1-ResNet-101-FFCL
(74.58%~75.92%)
S1-ResNet-101-3Con
(70.68%~76.82%)
S1- Naïve Bayes
S1-Random Forest
Part Ⅲ – The third learning phase: One aim of this part was
to check whether the plan about combining score 2 with score 3
as benign and score 4 with score 5 as malignancy will influence
the ACC and classification performance. Another aim was to
construct an FFCL based on ResNet-101 for 6-class
classification.
The first task we designed only trained the FCL. The second
task used the FFCL with ResNet-101. The third task applied the
structure which performed best in the second learning phase to
identify BI-RADS assessment, and the last task was based on
the combination of the second and the third tasks.
Table 6. The performance of ResNet-101 for 6-class classification.
aACC / (ACC range)
S1-ResNet-101-FCL
(55.54%~57.53%)
S1-ResNet-101-FFCL
(55.97%~57.88%)
S1-ResNet-101-3Conv-FCL
(54.55%~59.09%)
S1-ResNet-101-3Conv-FFCL
(55.11%~59.94%)
According to some categories, which are difficult to identify
in confusion matrices above, the third learning phase utilized
fuzzy rules to improve the neural networks’ quality after neural
networks can partially identify some classes. Finally, in order to
evaluate the distance between our trained models and the
convergent globally optimal solution, we used the Euclidean
Distance (ED) to measure the effect of classification
performance by neural networks:
𝐺𝐺𝐺𝐺(𝑝𝑝, 𝑞𝑞) = ට∑
(𝑝𝑝𝑖𝑖−𝑞𝑞𝑖𝑖)2
where 𝑝𝑝 is the value of predicted scores, 𝑞𝑞 is the value of
realistic scores, and 𝑖𝑖 is the category. When the output is a
decimal, not an integer, it means a mammogram contains
uncertain features, and the CNNs will provide radiologists
probabilities and decimal scores. The reason why we chose ED
to measure the advantage of FFCL is that the measuring
distance can be evaluated by t test. The learning rate reduction
helped us avoid unlearning important features.
1063-6706 (c) 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See for more information.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TFUZZ.2020.2966163, IEEE
Transactions on Fuzzy Systems
IEEE TRANSACTIONS ON FUZZY SYSTEM
Figure 7. ROC curves and confusion matrixes. From left to right successively (a) S1-ResNet-101-FCL, (b) S1-ResNet-101-FFCL and (c)
S1-ResNet-101-3Conv-FCL and (d) S1-ResNet-101-3Conv-FFCL for 6-class classification (Incomplete, Negative, Benign, Probably Benign, Suspicious
Abnormality and Highly Suspicious Malignancy) on the CBIS-DDSM dataset in the third learning phase.
1063-6706 (c) 2019 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See for more information.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TFUZZ.2020.2966163, IEEE
Transactions on Fuzzy Systems
IEEE TRANSACTIONS ON FUZZY SYSTEM
D. Comparison with other existing methods
For the CBIS-DDSM medical dataset, after embedding the
FFCL into some CNNs, Table 8 shows the significant
advantage of this semantic fuzzy layer when comparing with no
FFCL before. Although classifying medical images is difficult
to implement, as their poor quality, collaboration with relative
information can enhance the performance of CNNs, which
indicate that artificial neural networks need basic and inherent
knowledge to enrich themselves, and to limit them to overstep
the boundary, for example, overfitting.
Table 7. The Euclidean Distance among S1-ResNet-101-FCL,
S1-ResNet-101-FFCL and S1-ResNet-101-3Conv-FFCL.
and variance)
S1-ResNet-101-FCL
S1-ResNet-101-FFCL
1.466+0.0104~
1.482+0.0120
S1-ResNet-101-FCL
S1-ResNet-101-3Conv-FF
1.466+0.0104~
1.455+0.0464
S1-ResNet-101-FFCL
S1-ResNet-101-3Conv-FF
1.482+0.0120~
1.455+0.0464
Table 8. Comparison with existing methods on DDSM in terms of ACC.
DDSM (Scenario)
CNN+FFCL (proposed)
Geras 
68.8% (BI-RADS 0/1/2)
(BI-RADS 0/1/2)
Akselrod-Ballin
60.0%(BI-RADS
2/(3-4-5))
62.3%(BI-RADS
2/(3-4-5))
72.0%(BI-RADS
0/(2-3)/(4-5))
74.1%(BI-RADS
0/(2-3)/(4-5)))
56.34%±1.4% (BI-RADS
0/1/2/3/4/5)
57.40%±1.7% (BI-RADS
0/1/2/3/4/5)
IV. CONCLUSION
In this study, we verified that the visual enhancement method
cannot substantially improve the classification performance,
and we provided an evidence that the transfer learning strategy,
especially trained by natural categories, can extract medical
features. A novel architecture which is based on fuzzy system
and embedded in the fully connected layer for scoring images is
designed for semantic scoring of medical images.
This proposed optimal structure demonstrates its advantage
in CBIS-DDSM dataset for BI-RADS scoring. We firstly
proved the mathematical availability of the FFCL and designed
three learning phases to gradually develop CNNs based on
FFCL. Our proposed framework can also shrink the overlap
semantic space explored under an adaptive weight updating
environment in this medical dataset.
This FFCL architecture offers the advantage of weakening
the influence of equivocal and unclear semantic description for
medical diagnosis. Although this architecture can positively
deal with the classification tasks which have overlaps between
two neighbour classes, it is more likely to weaken the influence
of semantic conglutination.
The future work will focus on classifying images annotated
by linear categories and relying on another assistant CNN to
simulate the cognitive activation of human brain, such as
inhibition, disinhibition and maintenance.