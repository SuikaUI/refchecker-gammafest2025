Geometric deep learning on graphs and manifolds using mixture model CNNs
Federico Monti1∗
Davide Boscaini1∗
Jonathan Masci1,4
Emanuele Rodol`a1
Jan Svoboda1
Michael M. Bronstein1,2,3
1USI Lugano
2Tel Aviv University
3Intel Perceptual Computing
4Nnaisense
Deep learning has achieved a remarkable performance
breakthrough in several ﬁelds, most notably in speech
recognition, natural language processing, and computer vision. In particular, convolutional neural network (CNN) architectures currently produce state-of-the-art performance
on a variety of image analysis tasks such as object detection and recognition. Most of deep learning research has
so far focused on dealing with 1D, 2D, or 3D Euclideanstructured data such as acoustic signals, images, or videos.
Recently, there has been an increasing interest in geometric deep learning, attempting to generalize deep learning
methods to non-Euclidean structured data such as graphs
and manifolds, with a variety of applications from the domains of network analysis, computational social science,
or computer graphics.
In this paper, we propose a uni-
ﬁed framework allowing to generalize CNN architectures to
non-Euclidean domains (graphs and manifolds) and learn
local, stationary, and compositional task-speciﬁc features.
We show that various non-Euclidean CNN methods previously proposed in the literature can be considered as particular instances of our framework. We test the proposed
method on standard tasks from the realms of image-, graphand 3D shape analysis and show that it consistently outperforms previous approaches.
1. Introduction
In recent years, increasingly more ﬁelds have to deal
with geometric non-Euclidean structured data such as manifolds or graphs.
Social networks are perhaps the most
prominent example of such data; additional examples include transportation networks, sensor networks, functional
networks representing anatomical and functional structure
of the brain, and regulatory networks modeling gene expressions. In computer graphics, 3D objects are traditionally
modeled as Riemannian manifolds. The success of deep
learning methods in many ﬁelds has recently provoked a
∗Equal contribution
keen interest in geometric deep learning attempting to
generalize such methods to non-Euclidean structure data.
1.1. Related works
Image processing.
Classical deep learning algorithms
build on top of traditional signal processing that has been
developed primarily for linear shift-invariant systems, naturally arising when dealing with signals on Euclidean spaces.
In this framework, basic ﬁltering operations are represented
as convolutions. A signiﬁcant paradigm shift in image processing came with the pioneering work of Perona and Malik , suggesting the use of non-shift-invariant image ﬁltering preserving the edge structures. This work was the
precursor of a whole new class of PDE-based methods for
image processing. Sochen et al. brought geometric
models into image processing, considering images as manifolds and employing tools from differential geometry for
their processing and analysis. More recent graph-based image processing methods relying on spectral graph theory
 can be traced back to these works.
Manifold learning.
A similar trend of employing geometric models can also be observed in the machine learning community in the past decade.
Modelling data as
low-dimensional manifolds is the core of manifold learning
techniques such as Laplacian eigenmaps for non-linear
dimensionality reduction, spectral clustering or spectral hashing .
Signal processing on graphs.
More recent works tried to
generalize signal processing methods to graph-based data
 . Spectral analysis techniques were extended to graphs
considering the orthogonal eigenfunctions of the Laplacian
operator as a generalization of the Fourier basis. Constructions such as wavelets or algorithms
such as dictionary learning , Lasso , PCA ,
or matrix completion originally developed for the Euclidean domain, were also applied to graph-structured data.
Deep learning on graphs.
The earliest attempts to generalize neural networks to graphs we are aware of are due to
 
Scarselli et al. . This work remained practically unnoticed and has been rediscovered only recently .
The interest in non-Euclidean deep learning has recently
surged in the computer vision and machine learning communities after the seminal work of Bruna et al. , in
which the authors formulated CNN-like deep neural architectures on graphs in the spectral domain, employing the
analogy between the classical Fourier transforms and projections onto the eigenbasis of the graph Laplacian operator
 . In a follow-up work, Defferrard et al. proposed
an efﬁcient ﬁltering scheme that does not require explicit
computation of the Laplacian eigenvectors by using recurrent Chebyshev polynomials. Kipf and Welling further
simpliﬁed this approach using simple ﬁlters operating on
1-hop neighborhoods of the graph. Similar methods were
proposed in and . Finally, in the network analysis
community, several works constructed graph embeddings
 methods inspired by the Word2Vec technique .
A key criticism of spectral approaches such as is the fact that the spectral deﬁnition of convolution
is dependent on the Fourier basis (Laplacian eigenbasis),
which, in turn is domain-dependent. It implies that a spectral CNN model learned on one graph cannot be trivially
transferred to another graph with a different Fourier basis,
as it would be expressed in a ‘different language’.
Deep learning on manifolds.
In the computer graphics
community, we can notice a parallel effort of generalizing
deep learning architectures to 3D shapes modeled as manifolds (surfaces). Masci et al. proposed the ﬁrst intrinsic version of convolutional neural networks on manifolds
applying ﬁlters to local patches represented in geodesic polar coordinates . Boscaini et al. used anisotropic
heat kernels as an alternative way of extracting intrinsic
patches on manifolds. In , the same authors proposed a
CNN-type architecture in the spatio-frequency domain using the windowed Fourier transform formalism . Sinha
et al. used geometry images representation to obtain
Euclidean parametrization of 3D shapes on which standard
CNNs can be applied.
The key advantage of spatial techniques is that they generalize across different domains, which is a crucial property
in computer graphics applications (where a CNN model can
be trained on one shape and applied to another one). However, while spatial constructions such as anisotropic heat
kernels have a clear geometric interpretation on manifolds,
their interpretation on general graphs is somewhat elusive.
1.2. Main contribution
In this paper, we present mixture model networks
(MoNet), a general framework allowing to design convolutional deep architectures on non-Euclidean domains such
as graphs and manifolds. Our approach follows the general
philosophy of spatial-domain methods such as ,
formulating convolution-like operations as template matching with local intrinsic ‘patches’ on graphs or manifolds.
The key novelty is in the way in which the patch is extracted: while previous approaches used ﬁxed patches, e.g.
in geodesic or diffusion coordinates, we use a parametric
construction. In particular, we show that patch operators
can be constructed as a function of local graph or manifolds pseudo-coordinates, and study a family of functions
represented as a mixture of Gaussian kernels. Such a construction allows to formulate previously proposed Geodesic
CNN (GCNN) and Anisotropic CNN (ACNN) on
manifolds or GCN and DCNN on graphs as particular instances of our approach.
Among applications on which we exemplify our approach are classical problems from the realms of image-,
graph- and 3D- shape analysis. In the ﬁrst class of problems, the task is to classify images, treated as adjacency
graphs of superpixels. In the second class of problems, we
perform vertex-wise classiﬁcation on a graph representing
a citation network of scientiﬁc papers. Finally, we consider
the problem of ﬁnding dense intrinsic correspondence between 3D shapes, treated as manifolds. In all the above
problems, we show that our approach consistently outperforms previously proposed non-Euclidean deep learning
2. Deep learning on graphs
Let G = ({1, . . . , n}, E, W) be an undirected weighted
graph, represented by the adjacency matrix W = (wij),
where wij = wji, wij = 0 if (i, j) /∈E and wij > 0
if (i, j) ∈E. The (unnormalized) graph Laplacian is an
n×n symmetric positive-semideﬁnite matrix ∆= D−W,
where D = diag
is the degree matrix.
The Laplacian has an eigendecomposition ∆= ΦΛΦ⊤,
where Φ = (φ1, . . . φn) are the orthonormal eigenvectors
and Λ = diag(λ1, . . . , λn) is the diagonal matrix of corresponding eigenvalues. The eigenvectors play the role of
Fourier atoms in classical harmonic analysis and the eigenvalues can be interpreted as frequencies. Given a signal
f = (f1, . . . , fn)⊤on the vertices of graph G, its graph
Fourier transform is given by ˆf = Φ⊤f. Given two signals
f, g on the graph, their spectral convolution can be deﬁned
as the element-wise product of the Fourier transforms,
f ⋆g = Φ(Φ⊤f) ◦(Φ⊤g) = Φ diag(ˆg1, . . . , ˆgn)ˆf,
which corresponds to the property referred to as the Convolution Theorem in the Euclidean case.
Spectral CNN.
Bruna et al. used the spectral deﬁnition of convolution (1) to generalize CNNs on graphs, with
a spectral convolutional layer of the form
Φk ˆGl,l′Φ⊤
Here the n × p and n × q matrices Fin = (f in
1 , . . . , f in
and Fout = (f out
, . . . , f out
) represent respectively the pand q-dimensional input and output signals on the vertices
of the graph, Φ = (φ1, . . . , φk) is an n × k matrix of
the ﬁrst eigenvectors, ˆGl,l′ = diag(ˆgl,l′,1, . . . , ˆgl,l′,k) is a
k × k diagonal matrix of spectral multipliers representing
a learnable ﬁlter in the frequency domain, and ξ is a nonlinearity (e.g. ReLU) applied on the vertex-wise function
values. The analogy of pooling in this framework is a graph
coarsening procedure, which, given a graph with n vertices,
produces a graph with n′ < n vertices and transfers signals
from the vertices of the ﬁne graph to those of the coarse one.
While conceptually important, this framework has several major drawbacks. First, the spectral ﬁlter coefﬁcients
are basis dependent, and consequently, a spectral CNN
model learned on one graph cannot be applied to another
graph. Second, the computation of the forward and inverse
graph Fourier transform incurs expensive O(n2) multiplication by the matrices Φ, Φ⊤, as there is no FFT-like algorithms on general graphs. Third, there is no guarantee that
the ﬁlters represented in the spectral domain are localized in
the spatial domain; assuming k = O(n) eigenvectors of the
Laplacian are used, a spectral convolutional layer requires
pqk = O(n) parameters to train.
Smooth Spectral CNN.
In a follow-up work, Henaff et
al. argued that smooth spectral ﬁlter coefﬁcients result
in spatially-localized ﬁlters and used parametric ﬁlters of
where β1(λ), . . . , βr(λ) are some ﬁxed interpolation kernels, and α
(α1, . . . , αr) are the interpolation coefﬁcients.
In matrix notation, the ﬁlter is expressed as
diag( ˆG) = Bα, where B = (bij) = (βj(λi)) is a k×r matrix. Such a parametrization results in ﬁlters with a number
of parameters constant in the input size n.
Chebyshev Spectral CNN (ChebNet).
In order to alleviate the cost of explicitly computing the graph Fourier transform, Defferrard et al. used an explicit expansion in the
Chebyshev polynomial basis to represent the spectral ﬁlters
αjTj( ˜∆) =
αjΦTj( ˜Λ)Φ⊤,
where ˜∆= 2λ−1
n ∆−I is the rescaled Laplacian such that
its eigenvalues ˜Λ = 2λ−1
n Λ −I are in the interval [−1, 1],
α is the r-dimensional vector of polynomial coefﬁcients
parametrizing the ﬁlter, and
2λTj−1(λ) −Tj−2(λ),
denotes the Chebyshev polynomial of degree j deﬁned in a
recursive manner with T1(λ) = λ and T0(λ) = 1.
Such an approach has several important advantages.
First, it does not require an explicit computation of the
Laplacian eigenvectors. Due to the recursive deﬁnition of
the Chebyshev polynomials, the computation of the ﬁlter
gα(∆)f entails applying the Laplacian r times, resulting
in O(rn) operations. Second, since the Laplacian is a local operator affecting only 1-hop neighbors of a vertex and
accordingly its (r −1)st power affects the r-hop neighborhood, the resulting ﬁlters are localized.
Graph convolutional network (GCN).
Kipf and Welling
 considered the construction of with r
which, under the additional assumption of λn ≈2, and
α = α0 = −α1 yields single-parametric ﬁlters of the form
gα(f) = α(I + D−1/2WD−1/2)f. Such a ﬁlter is numerically unstable since the maximum eigenvalue of the matrix
I + D−1/2WD−1/2 is 2; a renormalization
α ˜D−1/2 ˜
W ˜D−1/2f,
W = W + I and ˜D = diag(P
j̸=i ˜wij) is introduced
by the authors in order to cure such problem and allow multiple convolutional levels to be casted one after the other.
Diffusion CNN (DCNN).
A different spatial-domain
method was proposed by Atwood and Towsley , who
considered a diffusion (random walk) process on the graph.
The transition probability of a random walk on a graph
is given by P = D−1W.
Different features are produced by applying diffusion of different length (the powers
P0, . . . , Pr−1),
l,j = ξ(wljPjf in
where the n × p and n × pr matrices Fin = (f in
1 , . . . , f in
1,1 , . . . , f out
p,r ) represent the p- and prdimensional input and output signals on the vertices of the
graph and W = (wlj) is the p × r matrix of weights.
3. Deep learning on manifolds
Let X be a d-dimensional differentiable manifold, possibly with boundary ∂X. Around point x ∈X, the manifold
is homeomorphic to a d-dimensional Euclidean space referred to as the tangent space and denoted by TxX. An
inner product ⟨·, ·⟩TxX : TxX × TxX →R depending
smoothly on x is called the Riemannian metric. In the following, we denote by f : X →R smooth real functions
(scalar ﬁelds) on the manifold. In shape analysis, 3D shapes
are modeled as 2-dimensional manifolds (surfaces), representing the boundaries of 3D volumes.
Several CNN-type geometric deep learning methods on graphs and manifolds can be obtained as a particular setting of the
proposed framework with an appropriate choice of the pseudo-coordinates and weight functions in the deﬁnition of the patch operator. x
denotes the reference point (center of the patch) and y a point within the patch. x denotes the Euclidean coordinates on a regular grid.
¯α, ¯σρ, ¯σθ and ¯uj, ¯θj, j = 1, . . . , J denote ﬁxed parameters of the weight functions.
Pseudo-coordinates
Weight function wj(u), j = 1, . . . , J
Local Euclidean
x(x, y) = x(y) −x(x)
Local polar geodesic
ρ(x, y), θ(x, y)
2(u −¯uj)⊤ ¯σ2
Local polar geodesic
ρ(x, y), θ(x, y)
2u⊤R¯θj ( ¯α
Vertex degree
deg(x), deg(y)
Transition probability in r hops
p0(x, y), . . . , pr−1(x, y)
Geodesic CNN (GCNN).
Masci et al. introduced a
generalization of CNNs on 2-dimensional manifolds, based
on the deﬁnition of a local charting procedure in geodesic
polar coordinates .
Such a construction, named the
patch operator
(D(x)f)(ρ, θ) =
wρ,θ(x, y)f(y)dy
maps the values of the function f at a neighborhood of the
point x ∈X into the local polar coordinates ρ, θ. Here dy
denotes the area element induced by the Riemannian metric,
and wρ,θ(x, y) is a weighting function localized around ρ, θ
(see examples in Figure 1). D(x)f can be regarded as a
patch on the manifold; the geodesic convolution
(f⋆g)(x) = max
g(ρ, θ+∆θ)(D(x)f)(ρ, θ)dρdθ,
can be thought of as matching a template g(ρ, θ) with the
extracted patch at each point, where the maximum is taken
over all possible rotations of the template in order to resolve the origin ambiguity in the angular coordinate. The
geodesic convolution is used to deﬁne an analogy of a traditional convolutional layer in GCNN, where the templates
g are learned.
Anisotropic CNN (ACNN).
Boscaini et al. considered the anisotropic diffusion equation on the manifold
ft(x, t) = −divX (A(x)∇X f(x, t)) ,
where ∇X and divX denote the intrinsic gradient and divergence, respectively, f(x, t) is the temperature at point
x and time t, and the conductivity tensor A(x) (operating
on the gradient vectors in the tangent space TxX) allows to
model heat ﬂow that is position- and direction-dependent.
In particular, they used the 2 × 2 tensor
Aαθ(x) = Rθ(x)
where matrix Rθ is a rotation by θ in the tangent plane w.r.t.
the maximal curvature direction, and the parameter α > 0
controls the degree of anisotropy (isotropic diffusion is obtained for α = 1). Using as initial condition f(x, 0) a point
source of heat at x, the solution to the heat equation (7) is
given by the anisotropic heat kernel hαθt(x, y), representing the amount of heat that is transferred from point x to
point y at time t. By varying the parameters α, θ and t (controlling respectively the elongation, orientation, and scale
of the kernel) one obtains a collection of kernels that can be
used as weighting functions in the construction of the patch
operator (see examples in Figure 1). This gives rise to an
alternative charting to the geodesic patches of GCNN, more
robust to geometric noise, and more efﬁcient to compute.
Both GCNN and ACNN operate in the spatial domain
and thus do not suffer from the inherent inability of spectral methods to generalize across different domains. These
methods were shown to outperform all the known handcrafted approaches for ﬁnding intrinsic correspondence between deformable shapes , a notoriously hard problem in computer graphics.
4. Our approach
The main contribution of this paper is a generic spatialdomain framework for deep learning on non-Euclidean domains such as graphs and manifolds.
We use x to denote, depending on context, a point on a manifold or a
vertex of a graph, and consider points y ∈N(x) in the
neighborhood of x.
With each such y, we associate a
d-dimensional vector of pseudo-coordinates u(x, y).
these coordinates, we deﬁne a weighting function (kernel)
wΘ(u) = (w1(u), . . . , wJ(u)), which is parametrized by
some learnable parameters Θ. The patch operator can therefore be written in the following general form
wj(u(x, y))f(y),
j = 1, . . . , J,
where the summation should be interpreted as an integral
in the case we deal with a continuous manifold, and J represents the dimensionality of the extracted patch. A spatial generalization of the convolution on non-Euclidean domains is then given by a template-matching procedure of
Polar coordinates ρ, θ
Figure 1. Left: intrinsic local polar coordinates ρ, θ on manifold around a point marked in white. Right: patch operator weighting functions
wi(ρ, θ) used in different generalizations of convolution on the manifold (hand-crafted in GCNN and ACNN and learned in MoNet). All
kernels are L∞-normalized; red curves represent the 0.5 level set.
(f ⋆g)(x) =
gj Dj(x)f.
The two key choices in our construction are the pseudocoordinates u and the weight functions w(u).
shows that other deep learning methods (including the classical CNN on Euclidean domains, DCN and DCNN on
graphs, and GCNN and ACNN on manifolds) can be obtained as particular settings of our framework with appropriate deﬁnition of u and w(u). For example, GCNN and
ACNN boil down to using Gaussian kernels on local polar geodesic coordinates ρ, θ on a manifold, and GCN can
be interpreted as applying a triangular kernel on pseudocoordinates given by the degree of the graph vertices.
In this paper, rather than using ﬁxed handcrafted weight
functions we consider parametric kernels with learnable parameters. In particular, a convenient choice is
wj(u) = exp(−1
2(u −µj)⊤Σ−1
j (u −µj)),
where Σj and µj are learnable d × d and d × 1 covariance
matrix and mean vector of a Gaussian kernel, respectively.
Formulae (9–10) can thus be interpreted as a gaussian mixture model (GMM). We further restrict the covariances to
have diagonal form, resulting in 2d parameters per kernel,
and a total of 2Jd parameters for the patch operator.
While extremely simple, we show in the next section that
these additional degrees of freedom afford our architecture
sufﬁcient complexity allowing it to outperform existing approaches. More complex versions of the weighting functions could include additional non-linear transformation of
the pseudo-coordinates u before feeding them to the Gaussian kernel, or even more general network-in-a-network architectures .
5. Results
5.1. Images
In our ﬁrst experiment, we applied the proposed method
on a classical task of handwritten digit classiﬁcation in the
MNIST dataset . While almost trivial by todays standards, we nevertheless use this example to visualize an
important advantage of our approach over spectral graph
CNN methods. Our experimental setup followed . The
28 × 28 images were represented as graphs, where vertices
correspond to (super)pixels and edges represent their spatial
relations. We considered two constructions: all images represented on the same graph (regular grid) and each image
represented as a different graph (Figure 2 left and right, respectively). Furthermore, we varied the graph size: the full
4 grids contained 728 and 196 vertices, respectively,
while the superpixel-based graphs contained 300, 150, and
75 vertices.
Three methods were compared: classical CNN LeNet5
architecture (containing two convolutional, two maxpooling, and one fully-connected layer, applied on regular
grids only), spectral ChebNet and the proposed MoNet.
We used a standard splitting of the MNIST dataset into
training-, testing-, and validation sets of sizes 55K, 10K,
and 5K images, respectively. LeNet used 2×2 max-pooling;
in ChebNet and MoNet we used three convolutional layers, interleaved with pooling layers based on the Graclus
method to coarsen the graph by a factor of four.
For MoNet, we used polar coordinates u = (ρ, θ) of pixels (respectively, of superpixel barycenters) to produce the
patch operator; as the weighting functions of the patch operator, 25 Gaussian kernels (initialized with random means
and variances) were used. Training was done with 350K iterations of Adam method , initial learning rate 10−4,
regularization factor 10−4, dropout probability 0.5, and
batch size of 10.
Table 2 summarizes the performance of different algorithms. On regular grids, all the methods perform approximately equally well. However, when applying ChebNet
on superpixel-based representations, the performance drops
dramatically (by up to almost 25%). The reason lies in the
key drawback of spectral CNN models, wherein the definition of the ﬁlters is basis- and thus domain-dependent.
Since in this case each image is represented as a different
Regular grid
Superpixels
Figure 2. Representation of images as graphs. Left: regular grid
(the graph is ﬁxed for all images). Right: graph of superpixel
adjacency (different for each image). Vertices are shown as red
circles, edges as red lines.
graph, the model fails to generalize well. The effect is most
pronounced on smaller graphs (150 and 75 superpixels) that
vary strongly among each other. In contrast, the proposed
MoNet approach manifests consistently high accuracy, and
only a light performance degradation is observed when the
image presentation is too coarse (75 superpixels).
Table 2. Classiﬁcation accuracy of classical Euclidean CNN
(LeNet5), spectral CNN (ChebNet) and the proposed approach
(MoNet) on different versions of the MNIST dataset. The setting
of all the input images sharing the same graph is marked with *.
LeNet5 
ChebNet 
*Full grid
300 Superpixels
150 Superpixels
75 Superpixels
5.2. Graphs
In the second experiment, we address the problem of
vertex classiﬁcation on generic graphs. We used the popular Cora and PubMed citation graphs as our datasets.
In each dataset, a vertex represents a scientiﬁc publication
(2708 vertices in Cora and 19717 in PubMed, respectively),
and an undirected unweighted edge represents a citation
(5429 and 44338 edges in Cora and PubMed). For each
vertex, a feature vector representing the content of the pa-
Table 3. Learning conﬁguration used for Cora and PubMed experiments.
Learning Algorithm
Number of epochs
Validation frequency
Learning rate
Decay rate
Decay epochs
1500, 2500
Early stopping
per is given (1433-dimensional binary feature vectors in
Cora, and 500-dimensional tf-idf weighted word vectors in
PubMed). The task is to classify each vertex into one of the
groundtruth classes (7 in Cora and 3 in PubMed).
We followed verbatim the experimental settings presented in . The training sets consisted of 20 samples per class; the validation and test sets consisted of 500
and 1000 disjoint vertices. The validation set was chosen
in order to reﬂect the probability distribution of the various
classes over the entire dataset. We compared our approach
to all the methods compared in .
For MoNet, we used the degrees of the nodes as the input
pseudo-coordinates u(x, y) = (
deg(y))⊤; these
coordinates underwent an additional transformation in the
form of a fully-connected neural network layer ˜u(x, y) =
tanh(Au(x, y) + b), where the r × 2 matrix A and r × 1
vector b were also learned (we used r = 2 for Cora and
r = 3 for PubMed). The Gaussian kernels were applied on
coordinates ˜u(x, y) yielding patch operators of the form
2 (˜u(x,y)−µj)⊤Σ−1
(˜u(x,y)−µj)fl(y),
where Σj, µj, j = 1, . . . , J are the r × r and r × 1 covariance matrices and mean vectors of the Gaussian kernels,
respectively. DCNN, GCN and MoNet were trained in the
same way in order to give a fair comparison (see training details in Table 3). The L2-regularization weights for MoNet
were γ = 10−2 and 5×10−2 for Cora and PubMed, respectively; for DCNN and GCN we used the values suggested
by the authors in and .
The vertex classiﬁcation results of different methods are
summarized in Table 4 and visualized in Figure 3. MoNet
compares favorably to other approaches.
The tuning of
the network hyper-parameters has been fundamental in this
case for avoiding overﬁtting, due to a very small size of the
training set. Being more general, our architecture is more
complex compared to GCN and DCNN and requires an appropriate regularization to be used in such settings. At the
same time, the greater complexity of our framework might
prove advantageous when applied to larger and more complex data.
Figure 3. Predictions obtained applying MoNet over the Cora dataset. Marker ﬁll color represents the predicted class; marker outline color
represents the groundtruth class.
5.3. Manifolds
The last application we consider is learning dense intrinsic correspondence between collections of 3D shapes represented as discrete manifolds. For this purpose, correspondence is cast as a labelling problem, where one tries to label
each vertex of a given query shape X with the index of a
corresponding point on some reference shape Y .
Let n and m denote the number of vertices in X and Y, respectively. For a point x on a query shape, the last layer of
the network is soft-max, producing an m-dimensional output f(x) that is interpreted as a probability distribution on
Y (the probability of x mapped to y). Learning is done by
minimizing the standard logistic regression cost .
We reproduced verbatim the experiments of on the FAUST humans dataset , comparing to the
methods reported therein. The dataset consisted of 100 watertight meshes representing 10 different poses for 10 different subjects with exact ground-truth correspondence. Each
shape was represented as a mesh with 6890 vertices; the
ﬁrst subject in ﬁrst pose was used as the reference. For all
the shapes, point-wise 544-dimensional SHOT descriptors
(local histogram of normal vectors) were used as input
data. We used MoNet architecture with 3 convolutional layers, replicating the architectures of . First 80 subjects
Table 4. Vertex classiﬁcation accuracy on the Cora and PubMed
datasets following the splitting suggested in . Learning methods (DCNN, GCNN and MoNet) were trained and tested ﬁfty
times for showing their average behavior with different initializations.
ManiReg 
SemiEmb 
DeepWalk 
Planetoid 
76.80 ± 0.60%
73.00 ± 0.52%
81.59 ± 0.42%
78.72 ± 0.25%
81.69 ± 0.48%
78.81 ± 0.44%
in all the poses were used for training (800 shapes in total);
the remaining 20 subjects were used for testing. The output
of the network was reﬁned using the intrinsic Bayesian ﬁlter
 in order to remove some local outliers.
Correspondence quality was evaluated using the Princeton benchmark , plotting the percentage of matches that
are at most r-geodesically distant from the groundtruth correspondence on the reference shape. For comparison, we report the performance of blended maps , random forests
 , GCNN , ADD , and ACNN .
Figure 1 shows the weighting functions of the patch operator that are ﬁxed in GCNN and ACNN architectures, and
part of the learnable parameters in the proposed MoNet.
The patch operators of GCNN and ACNN can be obtained
as a particular conﬁguration of MoNet, implying that if
trained correctly, the new model can only improve w.r.t.
the previous ones. Figure 4 depicts the evaluation results,
showing that MoNet signiﬁcantly outperforms the competing approaches. In particular, close to 90% of points have
zero error, and for 99% of the points the error is below 4cm.
Figure 6 shows the point-wise geodesic correspondence error of our method, and Figure 7 visualizes the obtained correspondence using texture transfer.
Range maps.
Finally, we repeated the shape correspondence experiment on range maps synthetically generated
from FAUST meshes. For each subject and pose, we produced 10 rangemaps in 100×180 resolution, covering shape
rotations around the z-axis with increments of 36 degrees
(total of 1000 range maps), keeping the groundtruth correspondence. We used MoNet architecture with 3 convolutional layers and local SHOT descriptors as input data.
Training and testing set splitting was done as previously.
Figure 5 shows the quality of correspondence computed
using the Princeton protocol. For comparison, we show the
performance of a standard Euclidean CNN in equivalent architecture (3 convolutional layers) applied on raw depth values and on SHOT descriptors. Our approach clearly shows
Geodesic error (cm)
Geodesic error (% diameter)
% correspondences
Figure 4. Shape correspondence quality obtained by different
methods on the FAUST humans dataset. The raw performance
of MoNet is shown in dotted curve.
Geodesic error (cm)
Geodesic error (% diameter)
% correspondences
CNN on depth
CNN on SHOT
Figure 5. Shape correspondence quality obtained by different
methods on FAUST range maps. For comparison, we show the
performance of a Euclidean CNN with a comparable 3-layer architecture. The raw performance is shown as dotted curve.
a superior performance.
Figure 8 shows the point-wise
geodesic correspondence error. Figure 9 shows a qualitative
visualization of correspondence using similar color code for
corresponding vertices. We also show correspondence on
shapes from SCAPE and TOSCA datasets.
6. Conclusions
We proposed a spatial-domain model for deep learning
on non-Euclidean domains such as manifolds and graphs.
Our approach generalizes several previous techniques that
can be obtained as particular instances thereof. Extensive
experimental results show that our model is applicable to
different geometric deep learning tasks, achieving state-ofthe-art results. In deformable 3D shape analysis applications, the key advantage of our approach is that it is intrinsic
and thus deformation-invariant by construction, as opposed
to Euclidean models that in general require
signiﬁcantly higher complexity and huge training sets to
learn the deformation invariance. In future works, we will
study additional promising applications of our model, for
example in the domain of computational social sciences.
Acknowledgments
This research was supported in part by the ERC Starting
Grant No. 307047 (COMET), a Google Faculty Research
Award, and Nvidia equipment grant.