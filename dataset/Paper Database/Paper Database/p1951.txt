Generative Adversarial Active Learning
Jia-Jie Zhu
Max Planck Institute for Intelligent Systems
Tübingen, Germany
 
Jose Bento
Department of Computer Science
Boston College
Chestnut Hill, Massachusetts, USA
 
We propose a new active learning by query synthesis approach using Generative
Adversarial Networks (GAN). Different from regular active learning, the resulting algorithm adaptively synthesizes training instances for querying to increase
learning speed. We generate queries according to the uncertainty principle, but
our idea can work with other active learning principles. We report results from
various numerical experiments to demonstrate the effectiveness the proposed approach. In some settings, the proposed algorithm outperforms traditional poolbased approaches. To the best our knowledge, this is the ﬁrst active learning work
using GAN.
Introduction
One of the most exciting machine learning breakthroughsin recent years is the generative adversarial
networks (GAN) . It trains a generative model by ﬁnding the Nash Equilibrium of a two-player
adversarial game. Its ability to generate samples in complex domains enables new possibilities for
active learners to synthesize training samples on demand, rather than relying on choosing instances
to query from a given pool.
In the classiﬁcation setting, given a pool of unlabeled data samples and a ﬁxed labeling budget, active learning algorithms typically choose training samples strategically from a pool to maximize the
accuracy of trained classiﬁers. The goal of these algorithms is to reduce label complexity. Such
approaches are called pool-based active learning. This pool-based active learning approach is illustrated in Figure 1 (a).
In a nutshell, we propose to use GANs to synthesize informative training instances that are adapted
to the current learner. We then ask human oracles to label these instances. The labeled data is added
back to the training set to update the learner. This protocol is executed iteratively until the label
budget is reached. This process is shown in Figure 1 (b).
The main contributions of this work are as follows:
• To the best of our knowledge, this is the ﬁrst active learning framework using deep generative models1.
• While we do not claim our method is always superior to the previous active learners in
terms of accuracy, in some cases, it yields classiﬁcation performancenot achievable even by
a fully supervised learning scheme. With enough capacity from the trained generator, our
method allows us to have control over the generated instances which may not be available
to the previous active learners.
1The appendix of mentioned three active learning attempts but did not report numerical results. Our
approach is also different from those attempts.
(a) Pool-based
Figure 1: (a) Pool-based active learning scenario. The learner selects samples for querying from
a given unlabeled pool. (b) GAAL algorithm. The learner synthesizes samples for querying using
• We conduct experiments to compare our active learning approach with self-taught learning2.
The results are promising.
• This is the ﬁrst work to report numerical results in active learning synthesis for image
classiﬁcation. See . The proposed framework may inspire future GAN applications
in active learning.
• The proposed approach should not be understood as a pool-based active learning method.
Instead, it is active learning by query synthesis. We show that our approach can perform
competitively when compared against pool-based methods.
Related Work
Our work is related to two different subjects, active learning and deep generative models.
Active learning algorithms can be categorized into stream-based, pool-based and learning by query
synthesis. Historically, stream-based and pool-based are the two popular scenarios of active learning
Our method falls into the category of query synthesis. Early active learning by queries synthesis
achieves good results only in simple domains such as X = {0, 1}3, see . In , the authors
synthesized learning queries and used human oracles to train a neural network for classifying handwritten characters. However, they reported poor results due to the images generated by the learner
being sometimes unrecognizable to the human oracles. We will report results on similar tasks such
as differentiating 5 versus 7, showing the advancement of our active learning scheme. Figure 2
compares image samples generated by the method in and our algorithm.
Figure 2: (Left) Image queries synthesized by a neural network for handwritten digits recognition.
Source: . (Right) Image queries synthesized by our algorithm, GAAL.
The popular SVMactive algorithm from is an efﬁcient pool-based active learning scheme for
SVM. Their scheme is a special instance of the uncertainty sampling principle which we also employ.
 reduces the exhaustive scanning through database employed by SVMactive. Our algorithm
shares the same advantage of not needing to test every sample in the database at each iteration of
active learning. Although we do so by not using a pool at all instead of a clever trick. proposed
active transfer learning which is reminiscent to our experiments in Section 5.1. However, we do not
consider collecting new labeled data in target domains of transfer learning.
2See the supplementary document.
There have been some applications of generative models in semi-supervised learning and active
learning. Previously, proposed a semi-supervised learning approach to text classiﬁcation based
on generative models. applied Gaussian mixture models to active learning. In that work, the
generative model served as a classiﬁer. Compared with these approaches, we apply generative models to directly synthesize training data. This is a more challenging task.
One building block of our algorithm is the groundbreaking work of the GAN model in . Our
approach is an application of GAN in active learning.
Our approach is also related to which studied GAN in a semi-supervised setting. However, our
task is active learning which is different from the semi-supervised learning they discussed. Our work
shares the common strength with the self-taught learning algorithm in as both methods use the
unlabeled data to help with the task. In the supplementary document, we compare our algorithm
with a self-taught learning algorithm.
In a way, the proposed approach can be viewed as an adversarial training procedure , where
the classiﬁer is iteratively trained on the adversarial example generated by the algorithm based on
solving an optimization problem. focuses on the adversarial examples that are generated by
perturbing the original datasets within the small epsilon-ball whereas we seek to produce examples
using active learning criterion.
To the best of our knowledge, the only previous mentioning of using GAN for active learning is in
the appendix of . The authors discussed therein three attempts to reduce the number of queries.
In the third attempt, they generated synthetic samples and sorted them by the information content
whereas we adaptively generate new queries by solving an optimization problem. There were no
reported active learning numerical results in that work.
Background
We brieﬂy introduce some important concepts in active learning and generative adversarial network.
Active Learning
In the PAC learning framework , label complexity describes the number of labeled instances
needed to ﬁnd a hypothesis with error ǫ. The label complexity of passive supervised learning, i.e.
using all the labeled samples as training data, is O( d
ǫ ) , where d is the VC dimension of the
hypothesis class H. Active learning aims to reduce the label complexity by choosing the most
informative instances for querying while attaining low error rate. For example, proved that the
active learning algorithm from has the label complexity bound O(θd log 1
ǫ), where θ is deﬁned
therein as the disagreement coefﬁcient, thus reducing the theoretical bound for the number of labeled
instances needed from passive supervised learning. Theoretically speaking, the asymptotic accuracy
of an active learning algorithm can not exceed that of a supervised learning algorithm. In practice,
as we will demonstrate in the experiments, our algorithm may be able to achieve higher accuracy
than the passive supervised learning in some cases.
Stream-based active learning makes decisions on whether to query the streamed-in instances or not.
Typical methods include . In this work, we will focus on comparing pool-based and query
synthesis methods.
In pool-based active learning, the learner selects the unlabeled instances from an existing pool based
on a certain criterion. Some pool-based algorithms make selections by using clustering techniques
or maximizing a diversity measure, e.g. . Another commonly used poolbased active learning principle is uncertainty sampling. It amounts to querying the most uncertain
instances. For example, algorithms in query the labels of the instances that are closest to
the decision boundary of the support vector machine. Figure 3 (a) illustrates this selection process.
Other pool-based works include which proposes a Bayesian active learning by disagreement
algorithm in the context of learning user preferences, which study the submodularity nature
of sequential active learning schemes.
Mathematically, let P be the pool of unlabeled instances, and f = Wφ(x) + b be the separating
hyperplane. φ is the feature map induced by the SVM kernel. The SVMactive algorithm in 
chooses a new instance to query by minimizing the distance (or its proxy) to the hyperplane
x∈P ∥Wφ(x) + b∥.
This formulation can be justiﬁed by the version space theory in separable cases or by other
analyses in non-separable cases, e.g., . This simple and effective method is widely applied in
many studies, e.g., .
In the query synthesis scenario, an instance x is synthesized instead of being selected from an existing pool. Previous methods tend to work in simple low-dimensional domains but fail in more
complicated domains such as images . Our approach aims to tackle this challenge.
For an introduction to active learning, readers are referred to .
Generative Adversarial Networks
Generative adversarial networks (GAN) is a novel generative model invented by . It can be
viewed as the following two-player minimax game between the generator G and the discriminator
Ex∼pdata log Dθ1(x) + Ez log(1 −Dθ1(Gθ2(z)))
where pdata is the underlying distribution of the real data and z is uniformly distributed random
variable. D and G each has its own set of parameter θ1 and θ2. By solving this game, a generator
G is obtained. In the ideal scenario, given random input z, we have G(z) ∼pdata. However, ﬁnding
this Nash Equilibrium is a difﬁcult problem in practice. There is no theoretical guarantee for ﬁnding
the Nash Equilibrium due to the non-convexity of D and G. A gradient descent type algorithm is
typically used for solving this optimization problem.
A few variants of GAN have been proposed since . The authors of use GAN with deep convolutional neural network structures for applications in computer vision(DCGAN). DCGAN yields
good results and is relatively stable. Conditional GAN is another variant of GAN in
which the generator and discriminator can be conditioned on other variables, e.g., the labels of images. Such generators can be controlled to generate samples from a certain category. proposed
infoGAN which learns disentangled representations using unsupervised learning.
A few updated GAN models have been proposed. proposed a few improved techniques for
training GAN. Another potentially important improvement of GAN, Wasserstein GAN, has been
proposed by . The authors proposed an alternative to training GAN which can avoid instabilities such as mode collapse with theoretical analysis. They also proposed a metric to evaluate
the quality of the generation which may be useful for future GAN studies. Possible applications of
Wasserstein GAN to our active learning framework are left for future work.
The invention of GAN triggered various novel applications. performed image inpainting task
using GAN. proposed iGAN to turn sketches into realistic images. applied GAN to single image super-resolution. proposed CycleGAN for image-to-image translation using only
unpaired training data.
Our study is the ﬁrst GAN application to active learning.
For a comprehensive review of GAN, readers are referred to .
Generative Adversarial Active Learning
In this section, we introduce our active learning approach which we call Generative Adversarial
Active Learning (GAAL). It combines query synthesis with the uncertainty sampling principle.
The intuition of our approach is to generate instances which the current learner is uncertain about,
i.e. applying the uncertainty sampling principle. One particular choice for the loss function is based
on uncertainty sampling principle explained in section 3.1. In the setting of a classiﬁer with the
decision function f(x) = Wφ(x)+b, the (proxy) distance to the decision boundary is ∥Wφ(x)+b∥.
Similar to the intuition of (1), given a trained generator function G, we formulate the active learning
synthesis as the following optimization problem
∥W ⊤φ(G(z)) + b∥,
Algorithm 1 Generative Adversarial Active Learning (GAAL)
1: Train generator G on all unlabeled data by solving (2)
2: Initialize labeled training dataset S by randomly picking a small fraction of the data to label
Solve optimization problem (3) according to the current learner by descending the gradient
∇z∥W ⊤φ(G(z)) + b∥
Use the solution {z1, z2, . . . } and G to generate instances for querying
Label {G(z1), G(z2), . . . } by human oracles
Add labeled data to the training dataset S and re-train the learner, update W, b
8: until Labeling budget is reached
where z is the latent variable and G is obtained by the GAN algorithm. Intuitively, minimizing
this loss will push the generated samples toward the decision boundary. Figure 3 (b) illustrates this
idea. Compared with the pool-base active learning in Figure 3 (a), our hope is that it may be able to
generate more informative instances than those available in the existing pool.
(a) SVMactive
Figure 3: (a) SVMactive algorithm selects the instances that are closest to the boundary to query
the oracle. (b) GAAL algorithm synthesizes instances that are informative to the current learner.
Synthesized instances may be more informative to the learner than other instances in the existing
The solution(s) to this optimization problem, G(z), after being labeled, will be used as new training
data for the next iteration. We outline our procedure in Algorithm 1. It is possible to use a state-ofthe-art classiﬁer, such as convolutional neural networks. To do this, we can replace the feature map
φ in Equation 3 with a feed-forward function of a convolutional neural network. In that case, the
linear SVM will become the output layer of the network. In step 4 of Algorithm 1, one may also
use a different active learning criterion. We emphasis that our contribution is the general framework
instead of a speciﬁc criterion.
In training GAN, we follow the procedure detailed in . Optimization problem (3) is non-convex
with possibly many local minima. One typically aims at ﬁnding good local minima rather than the
global minimum. We use a gradient descent algorithm with momentum to solve this problem. We
also periodically restart the gradient descent to ﬁnd other solutions. The gradient of D and G is
calculated using back-propagation.
Alternatively, we can incorporate diversity into our active learning principle. Some active learning
approaches rely on maximizing diversity measures, such as the Shannon Entropy. In our case, we
can include in the objective function (3) a diversity measure such as proposed in , thus
increasing the diversity of samples. The evaluation of this alternative approach is left for future
Experiments
We perform active learning experiments using the proposed approach. We also compare our approach to self-taught learning, a type of transfer learning method, in the supplementary document.
The GAN implementation used in our experiment is a modiﬁcation of a publicly available TensoFlow
DCGAN implementation3. The network architecture of DCGAN is described in .
3 
In our experiments, we focus on binary image classiﬁcation. Although this can be generalized to
multiple classes using one-vs-one or one-vs-all scheme . Recent advancements in GAN study
show it could potentially model language as well . Although those results are preliminary at the
current stage. We use a linear SVM as our classiﬁer of choice (with parameter γ = 0.001). Even
though classiﬁers with much higher accuracy (e.g., convolutional neural networks) can be used,
our purpose is not to achieve absolute high accuracy but to study the relative performance between
different active learning schemes.
The following schemes are implemented and compared in our experiments.
• The proposed generative adversarial active learning (GAAL) algorithm as in Algorithm 1.
• Using regular GAN to generate training data. We refer to this as simple GAN.
• SVMactive algorithm from .
• Passive random sampling, which randomly samples instances from the unlabeled pool.
• Passive supervised learning, i.e., using all the samples in the pool to train the classiﬁer.
• Self-taught learning from .
We initialize the training set with 50 randomly selected samples. The algorithms proceed with a
batch of 10 queries every time.
We use two datasets for training, the MNIST and CIFAR-10. The MNIST dataset is a well-known
image classiﬁcation dataset with 60000 training samples. The training set and the test set follow the
same distribution. We perform the binary classiﬁcation experiment distinguishing 5 and 7 which is
reminiscent to . The training set of CIFAR-10 dataset consists of 50000 32 × 32 color images
from 10 categories. One might speculate the possibility of distinguishing cats and dogs by training
on cat-like dogs or dog-like cats. In practice, our human labelers failed to conﬁdently identify most
of the generated cat and dog images. Figure 4 (Top) shows generated samples. The authors of 
reported attempts to generate high-resolution animal pictures, but with the wrong anatomy. We leave
this task for future studies, possibly with improved techniques such as . For this reason, we
perform binary classiﬁcation on the automobile and horse categories. It is relatively easy for human
labelers to identity car and horse body shapes. Typical generated samples, which are presented to
the human labelers, are shown in Figure 4.
Figure 4: Samples generated by GAAL (Top) Generated samples in cat and dog categories. (Bottom
Left) MNIST dataset. (Bottom Right) CIFAR-10 dataset.
Active Learning
We use all the images of 5 and 7 from the MNIST training set as our unlabeled pool to train the
generator G. Different from traditional active learning, we do not select new samples from the pool
after initialization. Instead, we apply Algorithm 1 to generate a training query. For the generator
D and G, we follow the same network architecture of . We use linear SVM as our classiﬁer
although other classiﬁers can be used, e.g. .
We ﬁrst test the trained classiﬁer on a test set that follows a distribution different from the training
set. One purpose is to demonstrate the adaptive capability of the GAAL algorithm. In addition,
because the MNIST test set and training set follow the same distribution, pool-based active learning
methods have an natural advantage over active learning by synthesis since they use real images
drawn from the exact same distribution as the test set. It is thus reasonable to test on sets that follow
different, albeit similar, distributions. To this end, we use the USPS dataset from as the test set
with standard preprocessing. In reality, such settings are very common, e.g., training autonomous
drivers on simulated datasets and testing on real vehicles; training on handwriting characters and
recognizing writings in different styles, etc. This test setting is related to transfer learning, where
the distribution of the training domain Ptr(x, y) is different from that of the target domain Pte(x, y).
Figure 5 (Top) shows the results of our ﬁrst experiment.
Number of Labeled Samples
Classification Accuracy
Active Learing, 5 vs. 7
Fully Supervised
Simple GAN
Random Sampling
Number of Labeled Samples
Classification Accuracy
Active Learing, 5 vs. 7
Fully Supervised
Simple GAN
Random Sampling
Number of Labeled Samples
Classification Accuracy
Active Learing, Horse vs. Automobile
Fully Supervised
Simple GAN
Random Sampling
Figure 5: Active learning results. (Top) Train on MNIST, test on USPS. Classifying 5 and 7. The
results are averaged over 10 runs. (Bottom Left) Train on MNIST, test on MNIST. Classifying 5 and
7. (Bottom Right) CIFAR-10 dataset, classifying automobile and horse. The results are averaged
over 10 runs. The error bars represent the empirical standard deviation of the average values. The
ﬁgures are best viewed in color.
When using the full training set, with 11000 training images, the fully supervised accuracy is at
70.44%. The accuracy of the random sampling scheme steadily approaches that level. On the
other hand, GAAL is able to achieve accuracies better than that of the fully supervised scheme.
With 350 training samples, its accuracy improves over supervised learning and even SVMactive, an
aggressive active learner . Obviously, the accuracy of both SVMactive and random sampling
will eventually converge to the fully supervised learning accuracy. Note that for the SVMactive
algorithm, an exhaustive scan through the training pool is not always practical. In such cases, the
common practice is to restrict the selection pool to a small random subset of the original data.
For completeness, we also perform the experiments in the settings where the training and test set
follow the same distribution. Figure 5 (Bottom) shows these results. Somewhat surprisingly, in
Figure 5 (Left), GAAL’s classiﬁcation accuracy starts to drop after about 100 samples. One possible
explanation is that GAAL may be generating points close to the boundary that are also close to each
other. This is more likely to happen if the boundary does not change much from one active learning
cycle to the next. This probably happens because the test and train sets are the identically distributed
and simple, like MNIST. Therefore, after a while, the training set may be ﬁlled with many similar
points, biasing the classiﬁer and hurting accuracy. In contrast, because of the ﬁnite and discrete
nature of pools in the given datasets, a pool-based approach, such as SVMactive, most likely explores
points near the boundary that are substantially different. It is also forced to explore further points
once these close-by points have already been selected. In a sense, the strength of GAAL might in
fact be hurting its classiﬁcation accuracy. We believe this effect is not so pronounced when the test
and train sets are different because the boundary changes more signiﬁcantly from one cycle to the
next, which in turn induces some diversity in the generated samples.
To reach competitive accuracy when the training and test set follow the same distribution, we might
incorporate a diversity term into our objective function in GAAL. We will address this in future
In the CIFAR-10 dataset, our human labeler noticed higher chances of bad generated samples, e.g.,
instances fail to represent either of the categories. This may be because of the signiﬁcantly higher
dimensions than the MNIST dataset. In such cases, we asked the labelers to only label the samples
they can distinguish. We speculate recent improvements on GAN, e.g., , may help mitigate
this issue given the cause is the instability of GANs. Addressing this limitation will be left to future
Balancing exploitation and exploration
The proposed Algorithm 1 can be understood as an exploitation method, i.e., it focuses on generating
the most informative training data based on the current decision boundary On the other hand, it is
often desirable for the algorithm to explore the new areas of the data. To achieve this, we modify
Algorithm 1 by simply executing random sampling every once in a while. This is a common practice
in active learning . We use the same experiment setup as in the previous section. Figure 6
shows the results of this mixed scheme.
Number of Labeled Samples
Classification Accuracy
Active Learing, 5 vs. 7
Random Sampling
GAAL + random sampling
Figure 6: Active learning results using a mixed scheme. The mixed scheme executes one iteration
of random sampling after every ﬁve iterations of GAAL algorithm. Train on MNIST, test on USPS.
Classifying 5 and 7. The results are averaged over 10 runs. The error bars represent the empirical
standard deviation of the average values. The ﬁgure is best viewed in color.
A mixed scheme is able to achieve better performance than either using GAAL or random sampling
alone. Therefore, it implies that GAAL, as an exploitation scheme, performs even better in combination with an exploration scheme. A detailed analysis such mixed schemes will be an interesting
future topic.
Discussion and Future Work
In this work, we proposed a new active learning approach, GAAL, that employs the generative adversarial networks. One possible explanation for GAAL not outperforming the pool-based approaches
in some settings is that, in traditional pool-based learning, the algorithm will eventually exhaust all
the points near the decision boundary thus start exploring further points. However, this is the not
the case in GAAL as it can always synthesize points near the boundary. This may in turn cause the
generation of similar samples, thus reducing the effectiveness. We suspect incorporating a diversity
measure into the GAAL framework as discussed at the end of Section 4 might mitigate this issue.
This issue is related to the exploitation and exploration trade-off which we explored in brief.
The results of this work are enough to inspire future studies of deep generative models in active
learning. However, much work remains in establishing theoretical analysis and reaching better performance. We also suspect that GAAL can be modiﬁed to generate adversarial examples such as in
 . The comparison of GAAL with transfer learning (see the supplementary document) is particularly interesting and worth further investigation. We also plan to investigate the possibility of using
Wasserstein GAN in our framework.