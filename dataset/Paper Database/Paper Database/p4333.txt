A Comprehensive Survey on Transfer Learning
Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Senior Member, IEEE,
Hui Xiong, Fellow, IEEE, and Qing He
Abstract—Transfer learning aims at improving the performance of target learners on target domains by transferring the knowledge
contained in different but related source domains. In this way, the dependence on a large number of target domain data can be reduced
for constructing target learners. Due to the wide application prospects, transfer learning has become a popular and promising area in
machine learning. Although there are already some valuable and impressive surveys on transfer learning, these surveys introduce
approaches in a relatively isolated way and lack the recent advances in transfer learning. Due to the rapid expansion of the transfer
learning area, it is both necessary and challenging to comprehensively review the relevant studies. This survey attempts to connect
and systematize the existing transfer learning researches, as well as to summarize and interpret the mechanisms and the strategies of
transfer learning in a comprehensive way, which may help readers have a better understanding of the current research status and
ideas. Unlike previous surveys, this survey paper reviews more than forty representative transfer learning approaches, especially
homogeneous transfer learning approaches, from the perspectives of data and model. The applications of transfer learning are also
brieﬂy introduced. In order to show the performance of different transfer learning models, over twenty representative transfer learning
models are used for experiments. The models are performed on three different datasets, i.e., Amazon Reviews, Reuters-21578, and
Ofﬁce-31. And the experimental results demonstrate the importance of selecting appropriate transfer learning models for different
applications in practice.
Index Terms—Transfer learning, machine learning, domain adaptation, interpretation.
INTRODUCTION
LTHOUGH traditional machine learning technology has
achieved great success and has been successfully applied in many practical applications, it still has some limitations for certain real-world scenarios. The ideal scenario of
machine learning is that there are abundant labeled training
instances, which have the same distribution as the test data.
However, collecting sufﬁcient training data is often expensive, time-consuming, or even unrealistic in many scenarios.
Semi-supervised learning can partly solve this problem by
relaxing the need of mass labeled data. Typically, a semisupervised approach only requires a limited number of
labeled data, and it utilizes a large amount of unlabeled
data to improve the learning accuracy. But in many cases,
unlabeled instances are also difﬁcult to collect, which usually makes the resultant traditional models unsatisfactory.
Transfer learning, which focuses on transferring the
knowledge across domains, is a promising machine learning
methodology for solving the above problem. The concept
about transfer learning may initially come from educational
psychology. According to the generalization theory of transfer, as proposed by psychologist C.H. Judd, learning to
transfer is the result of the generalization of experience. It is
possible to realize the transfer from one situation to another,
Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu,
and Qing He are with the Key Laboratory of Intelligent Information
Processing of Chinese Academy of Sciences (CAS), Institute of Computing
Technology, CAS, Beijing 100190, China and the University of Chinese
Academy of Sciences, Beijing 100049, China.
Hengshu Zhu is with Baidu Inc., No. 10 Shangdi 10th Street, Haidian
District, Beijing, China.
Hui Xiong is with Rutgers, the State University of New Jersey, 1
Washington Park, Newark, New Jersey, USA.
Zhiyuan Qi is with the equal contribution to the ﬁrst author.
Fuzhen Zhuang and Zhiyuan Qi are corresponding authors, and .
Fig. 1. Intuitive examples about transfer learning.
as long as a person generalizes his experience. According
to this theory, the prerequisite of transfer is that there
needs to be a connection between two learning activities.
In practice, a person who has learned the violin can learn
the piano faster than others, since both the violin and the
piano are musical instruments and may share some common
knowledge. Fig. 1 shows some intuitive examples about
transfer learning. Inspired by human beings’ capabilities to
transfer knowledge across domains, transfer learning aims
to leverage knowledge from a related domain (called source
domain) to improve the learning performance or minimize
the number of labeled examples required in a target domain.
It is worth mentioning that the transferred knowledge does
not always bring a positive impact on new tasks. If there
is little in common between domains, knowledge transfer
could be unsuccessful. For example, learning to ride a bicycle cannot help us learn to play the piano faster. Besides, the
similarities between domains do not always facilitate learning, because sometimes the similarities may be misleading.
For example, although Spanish and French have a close relationship with each other and both belong to the Romance
group of languages, people who learn Spanish may experience difﬁculties in learning French, such as using the wrong
vocabulary or conjugation. This occurs because previous
successful experience in Spanish can interfere with learning
the word formation, usage, pronunciation, conjugation, etc.,
in French. In the ﬁeld of psychology, the phenomenon that
previous experience has a negative effect on learning new
tasks is called negative transfer . Similarly, in the transfer
learning area, if the target learner is negatively affected by
the transferred knowledge, the phenomenon is also termed
as negative transfer , . Whether negative transfer will
occur may depend on several factors, such as the relevance
between the source and the target domains and the learners
capacity of ﬁnding the transferable and beneﬁcial part of the
knowledge across domains. In , a formal deﬁnition and
some analyses of negative transfer are given.
Roughly speaking, according to the discrepancy between
domains, transfer learning can be further divided into two
categories, i.e., homogeneous and heterogeneous transfer
learning . Homogeneous transfer learning approaches are
developed and proposed for handling the situations where
the domains are of the same feature space. In homogeneous
transfer learning, some studies assume that domains differ
only in marginal distributions. Therefore, they adapt the domains by correcting the sample selection bias or covariate
shift . However, this assumption does not hold in many
cases. For example, in sentiment classiﬁcation problem, a
word may have different meaning tendencies in different
domains. This phenomenon is also called context feature
bias . To solve this problem, some studies further adapt
the conditional distributions. Heterogeneous transfer learning refers to the knowledge transfer process in the situations
where the domains have different feature spaces. In addition
to distribution adaptation, heterogeneous transfer learning
requires feature space adaptation , which makes it more
complicated than homogeneous transfer learning.
The survey aims to give readers a comprehensive understanding about transfer learning from the perspectives
of data and model. The mechanisms and the strategies
of transfer learning approaches are introduced to allow
readers grasp how the approaches work. And a number of
the existing transfer learning researches are connected and
systematized. Speciﬁcally, over forty representative transfer
learning approaches are introduced. Besides, we conduct
experiments to demonstrate on which dataset a transfer
learning model performs well.
In this survey, we focus more on homogeneous transfer
learning. Some interesting transfer learning topics are not
covered in this survey, such as reinforcement transfer learning , lifelong transfer learning , and online transfer
learning . The rest of this survey are organized into
seven sections. Section 2 clariﬁes the difference between
transfer learning and other related machine learning techniques. Section 3 introduces the notations used in this survey and the deﬁnitions about transfer learning. Sections 4
and 5 interpret transfer learning approaches from the data
and the model perspectives, respectively. Section 6 introduces some applications of transfer learning. Experiments
are conducted and the results are provided in Section 7. The
last section concludes this survey. The main contributions of
this survey are summarized below.
• Over forty representative transfer learning approaches
are introduced and summarized, which can give readers a comprehensive overview about transfer learning.
• Experiments are conducted to compare different transfer learning approaches. The performance of over
twenty different approaches is displayed intuitively
and then analyzed, which may be instructive for the
readers to select the appropriate ones in practice.
RELATED WORK
Some areas related to transfer learning are introduced. The
connections and difference between them and transfer learning are clariﬁed.
Semi-Supervised Learning : Semi-supervised learning
is a machine learning task and method that lies between
supervised learning (with completely labeled instances)
and unsupervised learning (without any labeled instances).
Typically, a semi-supervised method utilizes abundant unlabeled instances combined with a limited number of labeled instances to train a learner. Semi-supervised learning relaxes the dependence on labeled instances, and thus
reduces the expensive labeling costs. Note that, in semisupervised learning, both the labeled and unlabeled instances are drawn from the same distribution. In contrast, in
transfer learning, the data distributions of the source and the
target domains are usually different. Many transfer learning approaches absorb the technology of semi-supervised
learning. The key assumptions in semi-supervised learning,
i.e., smoothness, cluster, and manifold assumptions, are also
made use of in transfer learning. It is worth mentioning
that semi-supervised transfer learning is a controversial
term. The reason is that the concept of whether the label
information is available in transfer learning is ambiguous
because both the source and the target domains can be
Multi-View Learning : Multi-view learning focuses on
the machine learning problems with multi-view data. A
view represents a distinct feature set. An intuitive example
about multiple views is that a video object can be described
from two different viewpoints, i.e., the image signal and
the audio signal. Brieﬂy, multi-view learning describes an
object from multiple views, which results in abundant information. By properly considering the information from all
views, the learner’s performance can be improved. There
are several strategies adopted in multi-view learning such
as subspace learning, multi-kernel learning, and co-training
 , . Multi-view techniques are also adopted in some
transfer learning approaches. For example, Zhang et al. proposed a multi-view transfer learning framework, which imposes the consistency among multiple views . Yang and
Gao incorporated multi-view information across different
domains for knowledge transfer . The work by Feuz and
Cook introduces a multi-view transfer learning approach
for activity learning, which transfers activity knowledge
between heterogeneous sensor platforms .
Multi-Task Learning : The thought of multi-task learning is to jointly learn a group of related tasks. To be
more speciﬁc, multi-task learning reinforces each task by
taking advantage of the interconnections between task, i.e.,
considering both the inter-task relevance and the inter-task
difference. In this way, the generalization of each task is enhanced. The main difference between transfer learning and
multi-task learning is that the former transfer the knowledge contained in the related domains, while the latter
transfer the knowledge via simultaneously learning some
related tasks. In other words, multi-task learning pays equal
attention to each task, while transfer learning pays more
attention to the target task than to the source task. There are
some commons and associations between transfer learning
and multi-task learning. Both of them aim to improve the
performance of learners via knowledge transfer. Besides,
they adopt some similar strategies for constructing models,
such as feature transformation and parameter sharing. Note
that some existing studies utilize both the transfer learning and the multi-task learning technologies. For example,
the work by Zhang et al. employs multi-task and transfer
learning techniques for biological image analysis . The
work by Liu et al. proposes a framework for human action
recognition based on multi-task learning and multi-source
transfer learning .
In this section, the notations used in this survey are listed for
convenience. Besides, some deﬁnitions and categorizations
about transfer learning are introduced, and some related
surveys are also provided.
For convenience, a list of symbols and their deﬁnitions are
shown in Table 1. Besides, we use ||·|| to represent the norm
and superscript T to denote the transpose of a vector/matrix.
In this subsection, some deﬁnitions about transfer learning
are given. Before giving the deﬁnition of transfer learning,
let us review the deﬁnitions of a domain and a task.
Deﬁnition 1. (Domain) A domain D is composed of two parts,
i.e., a feature space X and a marginal distribution P(X). In
other words, D = {X, P(X)}. And the symbol X denotes
an instance set, which is deﬁned as X = {x|xi ∈X, i =
1, · · · , n}.
Deﬁnition 2. (Task) A task T consists of a label space Y and a
decision function f, i.e., T = {Y, f}. The decision function
f is an implicit one, which is expected to be learned from the
sample data.
Some machine learning models actually output the predicted conditional distributions of instances. In this case,
f(xj) = {P(yk|xj)|yk ∈Y, k = 1, · · · , |Y|}.
In practice, a domain is often observed by a number
of instances with/without the label information. For example, a source domain DS corresponding to a source
task TS is usually observed via the instance-label pairs,
i.e., DS = {(x, y)|xi ∈X S, yi ∈YS, i = 1, · · · , nS};
an observation of the target domain usually consists of a
number of unlabeled instances and/or limited number of
labeled instances.
Deﬁnition 3. (Transfer Learning) Given some/an observation(s)
corresponding to mS ∈N+ source domain(s) and task(s)
Notations.
Number of instances
Number of domains
Feature space
Label space
Feature vector
Instance set
Label set corresponding to X
Source domain
Target domain
Labeled instances
Unlabeled instances
Reproducing kernel Hilbert space
Mapping/Coefﬁcient vector
Weighting coefﬁcient
Weighting coefﬁcient
Tradeoff parameter
Parameter/Error
Boundary parameter
Iteration/Kernel number
Decision function
Loss function
Scale parameter
Nonlinear mapping
Monotonically increasing function
Structural risk
Kernel function
Kernel matrix
Centering matrix
Covariance matrix
Class variable
Discriminator
Orthonormal bases
Model parameters
Probability
Expectation
Matrix variable
Matrix variable
Mapping matrix
(i.e., {(DSi, TSi)|i = 1, · · · , mS}), and some/an observation(s) about mT ∈N+ target domain(s) and task(s) (i.e.,
{(DTj, TTj)|j = 1, · · · , mT }), transfer learning utilizes
the knowledge implied in the source domain(s) to improve
the performance of the learned decision functions f Tj (j =
1, · · · , mT ) on the target domain(s).
The above deﬁnition, which covers the situation of multisource transfer learning, is an extension of the one presented
in the survey . If mS equals 1, the scenario is called singlesource transfer learning. Otherwise, it is called multi-source
transfer learning. Besides, mT represents the number of the
transfer learning tasks. A few studies focus on the setting
that mT ≥2 . The existing transfer learning studies pay
more attention to the scenarios where mT = 1 (especially
where mS = mT = 1). It is worth mentioning that the
observation of a domain or a task is a concept with broad
Transfer Learning
Problem Categorization
Solution Categorization
Homogeneous Transfer Learning
Heterogeneous Transfer Learning
Inductive Transfer Learning
Transductive Transfer Learning
Unsupervised Transfer Learning
Instance-Based Approach
Feature-Based Approach
Parameter-Based Approach
Relational-Based Approach
Symmetric Transformation
Asymmetric Transformation
Label-Setting-Based
Categorization
Space-Setting-Based
Categorization
Fig. 2. Categorizations of transfer learning.
sense, which is often cemented into a labeled/unlabeled
instance set or a pre-learned model. A common scenario is
that we have abundant labeled instances or have a welltrained model on the source domain, and we only have
limited labeled target-domain instances. In this case, the
resources such as the instances and the model are actually
the observations, and the goal of transfer learning is to learn
a more accurate decision function on the target domain.
Another term commonly used in the transfer learning
area is domain adaptation. Domain adaptation refers to the
process that adapting one or more source domains to transfer knowledge and improve the performance of the target
learner . Transfer learning often relies on the domain
adaptation process, which attempts to reduce the difference
between domains.
Categorization of Transfer Learning
There are several categorization criteria of transfer learning.
For example, transfer learning problems can be divided
into three categories, i.e., transductive, inductive, and unsupervised transfer learning . The complete deﬁnitions
of these three categories are presented in . These three
categories can be interpreted from a label-setting aspect.
Roughly speaking, transductive transfer learning refers to
the situations where the label information only comes from
the source domain. If the label information of the targetdomain instances is available, the scenario can be categorized into inductive transfer learning. If the label information is unknown for both the source and the target domains,
the situation is known as unsupervised transfer learning.
Another categorization is based on the consistency between
the source and the target feature spaces and label spaces.
If X S = X T and YS = YT , the scenario is termed as
homogeneous transfer learning. Otherwise, if X S ̸= X T
or/and YS ̸= YT , the scenario is referred to as heterogeneous transfer learning.
According to the survey , the transfer learning approaches can be categorized into four groups: instancebased, feature-based, parameter-based, and relational-based
approaches. Instance-based transfer learning approaches are
mainly based on the instance weighting strategy. Featurebased approaches transform the original features to create a
new feature representation; they can be further divided into
two subcategories, i.e., asymmetric and symmetric featurebased transfer learning. Asymmetric approaches transform
the source features to match the target ones. In contrast,
symmetric approaches attempt to ﬁnd a common latent
feature space and then transform both the source and
the target features into a new feature representation. The
parameter-based transfer learning approaches transfer the
knowledge at the model/parameter level. Relational-based
transfer learning approaches mainly focus on the problems
in relational domains. Such approaches transfer the logical
relationship or rules learned in the source domain to the
target domain. For better understanding, Fig. 2 shows the
above-mentioned categorizations of transfer learning.
Some surveys are provided for the readers who want
to have a more complete understanding of this ﬁeld. The
survey by Pan and Yang , which is a pioneering work, categorizes transfer learning and reviews the research progress
before 2010. The survey by Weiss et al. introduces and
summarizes a number of homogeneous and heterogeneous
transfer learning approaches . Heterogeneous transfer
learning is specially reviewed in the survey by Day and
Khoshgoftaar . Some surveys review the literatures related to speciﬁc themes such as reinforcement learning ,
computational intelligence , and deep learning , .
Besides, a number of surveys focus on speciﬁc application
scenarios including activity recognition , visual categorization , collaborative recommendation , computer
vision , and sentiment analysis .
Note that the organization of this survey does not strictly
follow the above-mentioned categorizations. In the next
two sections, transfer learning approaches are interpreted
from the data and the model perspectives. Roughly speaking, data-based interpretation covers the above-mentioned
instance-based and feature-based transfer learning approaches, but from a broader perspective. Model-based
interpretation covers the above-mentioned parameter-based
approaches. Since there are relatively few studies concerning relational-based transfer learning and the representative
approaches are well introduced in , , this survey does
not focus on relational-based approaches.
Covariance
Geometric Structure
Cluster Structure
Data-Based Interpretation
Measurement
Distribution Adaptation
Data Property
Preservation/Adjustment
Marginal Distribution Adaptation
Conditional Distribution Adaptation
Kullback-Leibler Divergence
Maximum Mean Discrepancy
Jensen-Shannon Divergence
Statistical Property
Instance Weighting
Feature Transformation
Feature Clustering
Feature Alignment
Feature Augmentation
Feature Reduction
Joint Distribution Adaptation
Feature Replication
Feature Encoding
Bregman Divergence
Feature Stacking
Manifold Structure
Feature Mapping
Estimation Method
Heuristic Method
Space Adaptation
Feature Space Adaptation
Label Space Adaptation
Spectral Feature Alignment
Subspace Feature Alignment
Statistic Feature Alignment
Feature Selection
Fig. 3. Strategies and the objectives of the transfer learning approaches from the data perspective.
DATA-BASED INTERPRETATION
Many transfer learning approaches, especially the databased approaches, focus on transferring the knowledge via
the adjustment and the transformation of data. Fig. 3 shows
the strategies and the objectives of the approaches from the
data perspective. As shown in Fig. 3, space adaptation is
one of the objectives. This objective is required to be satisﬁed mostly in heterogeneous transfer learning scenarios.
In this survey, we focus more on homogeneous transfer
learning, and the main objective in this scenario is to reduce
the distribution difference between the source-domain and
the target-domain instances. Furthermore, some advanced
approaches may attempt to preserve the data properties in
the adaptation process. There are generally two strategies
for realizing the objectives from the data perspective, i.e., instance weighting and feature transformation. In this section,
some related transfer learning approaches are introduced in
proper order according to the strategies shown in Fig. 3.
Instance Weighting Strategy
Let us ﬁrst consider a simple scenario in which a large
number of labeled source-domain and a limited number
of target-domain instances are available and domains differ
only in marginal distributions (i.e., P S(X) ̸= P T (X) and
P S(Y |X) = P T (Y |X)). For example, suppose we need
to build a model to diagnose cancer in a speciﬁc region
where the elderly are the majority. Limited target-domain
instances are given, and relevant data are available from
another region where young people are the majority. Directly transferring all the data from another region may
be unsuccessful, since the marginal distribution difference
exists, and the elderly have a higher risk of cancer than
younger people. In this scenario, it is natural to consider
adapting the marginal distributions. A simple idea is to
assign weights to the source-domain instances in the loss
function. The weighting strategy is based on the following
equation :
E(x,y)∼P T [L(x, y; f)] = E(x,y)∼P S
P T (x, y)
P S(x, y)L(x, y; f)
= E(x,y)∼P S
P S(x) L(x, y; f)
Therefore, the general objective function of a learning task
can be written as :
where βi (i = 1, 2, · · · , nS) is the weighting parameter.
The theoretical value of βi is equal to P T (xi)/P S(xi).
However, this ratio is generally unknown and is difﬁcult
to be obtained by using the traditional methods.
Kernel Mean Matching (KMM) , which is proposed by
Huang et al., resolves the estimation problem of the above
unknown ratios by matching the means between the sourcedomain and the target-domain instances in a Reproducing
Kernel Hilbert Space (RKHS), i.e.,
βi −1| ≤δ,
where δ is a small parameter, and B is a parameter for constraint. The above optimization problem can be converted
into a quadratic programming problem by expanding and
using the kernel trick. This approach to estimating the ratios
of distributions can be easily incorporated into many existing algorithms. Once the weight βi is obtained, a learner can
be trained on the weighted source-domain instances.
There are some other studies attempting to estimate
the weights. For example, Sugiyama et al. proposed an
approach termed Kullback-Leibler Importance Estimation
Procedure (KLIEP) . KLIEP depends on the minimization
of the Kullback-Leibler (KL) divergence and incorporates
a built-in model selection procedure. Based on the studies
of weight estimation, some instance-based transfer learning
frameworks or algorithms are proposed. For example, Sun
et al. proposed a multi-source framework termed 2-Stage
Weighting Framework for Multi-Source Domain Adaptation
(2SW-MDA) with the following two stages .
1. Instance Weighting: The source-domain instances are assigned with weights to reduce the marginal distribution
difference, which is similar to KMM.
2. Domain Weighting: Weights are assigned to each source
domain for reducing the conditional distribution difference based on the smoothness assumption .
Then, the source-domain instances are reweighted based
on the instance weights and the domain weights. These
reweighted instances and the labeled target-domain instances are used to train the target classiﬁer.
In addition to directly estimating the weighting parameters, adjusting weights iteratively is also effective. The
key is to design a mechanism to decrease the weights
of the instances that have negative effects on the target
learner. A representative work is TrAdaBoost , which
is a framework proposed by Dai et al. This framework is
an extension of AdaBoost . AdaBoost is an effective
boosting algorithm designed for traditional machine learning tasks. In each iteration of AdaBoost, a learner is trained
on the instances with updated weights, which results in
a weak classiﬁer. The weighting mechanism of instances
ensures that the instances with incorrect classiﬁcation are
given more attention. Finally, the resultant weak classiﬁers
are combined to form a strong classiﬁer. TrAdaBoost extends the AdaBoost to the transfer learning scenario; a new
weighting mechanism is designed to reduce the impact of
the distribution difference. Speciﬁcally, in TrAdaBoost, the
labeled source-domain and labeled target-domain instances
are combined as a whole, i.e., a training set, to train the
weak classiﬁer. The weighting operations are different for
the source-domain and the target-domain instances. In each
iteration, a temporary variable ¯δ, which measures the classi-
ﬁcation error rate on the labeled target-domain instances, is
calculated. Then, the weights of the target-domain instances
are updated based on ¯δ and the individual classiﬁcation
results, while the weights of the source-domain instances are
updated based on a designed constant and the individual
classiﬁcation results. For better understanding, the formulas
used in the k-th iteration (k = 1, · · · , N) for updating the
weights are presented repeatedly as follows :
2 ln nS/N)−|fk(xS
i | (i = 1, · · · , nS),
k−1,j(¯δk/(1 −¯δk))−|fk(xT
j | (j = 1, · · · , nT ).
Note that each iteration forms a new weak classiﬁer. The
ﬁnal classiﬁer is constructed by combining and ensembling
half the number of the newly resultant weak classiﬁers
through voting scheme.
Some studies further extend TrAdaBoost. The work by
Yao and Doretto proposes a Multi-Source TrAdaBoost
(MsTrAdaBoost) algorithm, which mainly has the following
two steps in each iteration.
1. Candidate Classiﬁer Construction: A group of candidate weak classiﬁers are respectively trained on the
weighted instances in the pairs of each source domain
and the target domain, i.e., DSi ∪DT (i = 1, · · · , mS).
2. Instance Weighting: A classiﬁer (denoted by j and
trained on DSj ∪DT ) which has the minimal classi-
ﬁcation error rate ¯δ on the target domain instances is
selected, and then is used for updating the weights of
the instances in DSj and DT .
Finally, the selected classiﬁers from each iteration are combined to form the ﬁnal classiﬁer. Another parameter-based
algorithm, i.e., TaskTrAdaBoost, is also proposed in the
work , which is introduced in Section 5.3.
Some approaches realize instance weighting strategy in
a heuristic way. For example, Jiang and Zhai proposed a
general weighting framework . There are three terms in
the framework’s objective function, which are designed to
minimize the cross-entropy loss of three types of instances.
The following types of instances are used to construct the
target classiﬁer.
• Labeled Target-domain Instance: The classiﬁer should minimize the cross-entropy loss on them, which is actually a
standard supervised learning task.
• Unlabeled Target-domain Instance: These instances’ true conditional distributions P(y|xT,U
) are unknown and should
be estimated. A possible solution is to train an auxiliary
classiﬁer on the labeled source-domain and target-domain
instances to help estimate the conditional distributions or
assign pseudo labels to these instances.
• Labeled Source-domain Instance: The authors deﬁne the
weight of xS,L
as the product of two parts, i.e., αi and
βi. The weight βi is ideally equal to P T (xi)/P S(xi),
which can be estimated by non-parametric methods such
as KMM or can be set uniformly in the worst case. The
weight αi is used to ﬁlter out the source-domain instances
that differ greatly from the target domain.
A heuristic method can be used to produce the value of αi,
which contains the following three steps.
1. Auxiliary Classiﬁer Construction: An auxiliary classiﬁer
trained on the labeled target-domain instances are used
to classify the unlabeled source-domain instances.
2. Instance Ranking: The source-domain instances are
ranked based on the probabilistic prediction results.
3. Heuristic Weighting (βi): The weights of the top-k
source-domain instances with wrong predictions are set
to zero, and the weights of others are set to one.
Feature Transformation Strategy
Feature transformation strategy is often adopted in featurebased approaches. For example, consider a cross-domain
text classiﬁcation problem. The task is to construct a target
Metrics Adopted in Transfer Learning.
Measurement
Related Algorithms
Maximum Mean Discrepancy 
 · · ·
Kullback-Leibler Divergence 
 · · ·
Jensen-Shannon Divergence 
 · · ·
Bregman Divergence 
 · · ·
Hilbert-Schmidt Independence Criterion 
 · · ·
classiﬁer by using the labeled text data from a related
domain. In this scenario, a feasible solution is to ﬁnd the
common latent features (e.g., latent topics) through feature transformation and use them as a bridge to transfer
knowledge. Feature-based approaches transform each original feature into a new feature representation for knowledge transfer. The objectives of constructing a new feature
representation include minimizing the marginal and the
conditional distribution difference, preserving the properties or the potential structures of the data, and ﬁnding the
correspondence between features. The operations of feature
transformation can be divided into three types, i.e., feature
augmentation, feature reduction, and feature alignment. Besides, feature reduction can be further divided into several
types such as feature mapping, feature clustering, feature
selection, and feature encoding. A complete feature transformation process designed in an algorithm may consist of
several operations.
Distribution Difference Metric
One primary objective of feature transformation is to reduce
the distribution difference of the source and the target domain instances. Therefore, how to measure the distribution
difference or the similarity between domains effectively is
an important issue.
The measurement termed Maximum Mean Discrepancy
(MMD) is widely used in the ﬁeld of transfer learning,
which is formulated as follows :
MMD(XS, XT) =
MMD can be easily computed by using kernel trick. Brieﬂy,
MMD quantiﬁes the distribution difference by calculating
the distance of the mean values of the instances in a RKHS.
Note that the above-mentioned KMM actually produces
the weights of instances by minimizing the MMD distance
between domains.
Table. 2 lists some commonly used metrics and the
related algorithms. In addition to Table. 2, there are some
other measurement criteria adopted in transfer learning,
including Wasserstein distance , , central moment
discrepancy , etc. Some studies focus on optimizing
and improving the existing measurements. Take MMD as
an example. Gretton et al. proposed a multi-kernel version
of MMD, i.e., MK-MMD , which takes advantage of
multiple kernels. Besides, Yan et al. proposed a weighted
version of MMD , which attempts to address the issue
of class weight bias.
Feature Augmentation
Feature augmentation operations are widely used in feature transformation, especially in symmetric feature-based
approaches. To be more speciﬁc, there are several ways to
realize feature augmentation such as feature replication and
feature stacking. For better understanding, we start with
a simple transfer learning approach which is established
based on feature replication.
The work by Daum´e proposes a simple domain adaptation method, i.e., Feature Augmentation Method (FAM)
 . This method transforms the original features by simple feature replication. Speciﬁcally, in single-source transfer
learning scenario, the feature space is augmented to three
times its original size. The new feature representation consists of general features, source-speciﬁc features, and targetspeciﬁc features. Note that, for the transformed sourcedomain instances, their target-speciﬁc features are set to
zero. Similarly, for the transformed target-domain instances,
their source-speciﬁc features are set to zero. The new feature
representation of FAM is presented as follows:
i , 0⟩, ΦT (xT
where ΦS and ΦT denote the mappings to the new feature
space from the source and the target domain, respectively.
The ﬁnal classiﬁer is trained on the transformed labeled
instances. It is worth mentioning that this augmentation
method is actually redundant. In other words, augmenting
the feature space in other ways (with fewer dimensions)
may be able to produce competent performance. The superiority of FAM is that its feature expansion has an elegant
form, which results in some good properties such as the
generalization to multi-source scenarios. An extension of
FAM is proposed in by Daum´e et al., which utilizes
the unlabeled instances to further facilitate the knowledge
transfer process.
However, FAM may not work well in handling heterogeneous transfer learning tasks. The reason is that directly replicating features and padding zero vectors are less
effective when the source and the target domains have
different feature representations. To solve this problem, Li
et al. proposed an approach termed Heterogeneous Feature
Augmentation (HFA) , . The feature representation
of HFA is presented below:
i ) = ⟨W SxS
i , 0T ⟩, ΦT (xT
j ) = ⟨W T xT
j , 0S, xT
where W SxS
and W T xT
have the same dimension; 0S
and 0T denote the zero vectors with the dimensions of xS
and xT , respectively. HFA maps the original features into a
common feature space, and then performs a feature stacking
operation. The mapped features, original features, and zero
elements are stacked in a particular order to produce a new
feature representation.
Feature Mapping
In the ﬁeld of traditional machine learning, there are
many feasible mapping-based methods of extracting features such as Principal Component Analysis (PCA) 
and Kernelized-PCA (KPCA) . However, these methods
mainly focus on the data variance rather than the distribution difference. In order to solve the distribution difference,
some feature extraction methods are proposed for transfer
learning. Let us ﬁrst consider a simple scenario where there
is little difference in the conditional distributions of the domains. In this case, the following simple objective function
can be used to ﬁnd a mapping for feature extraction:
 DIST(XS, XT; Φ) + λΩ(Φ)
 VAR(XS ∪XT; Φ)
where Φ is a low-dimensional mapping function, DIST(·)
represents a distribution difference metric, Ω(Φ) is a regularizer controlling the complexity of Φ, and VAR(·) represents
the variance of instances. This objective function aims to
ﬁnd a mapping function Φ that minimizes the marginal
distribution difference between domains and meanwhile
makes the variance of the instances as large as possible.
The objective corresponding to the denominator can be optimized in several ways. One possible way is to optimize the
objective of the numerator with a variance constraint. For
example, the scatter matrix of the mapped instances can be
enforced as an identity matrix. Another way is to optimize
the objective of the numerator in a high-dimensional feature
space at ﬁrst. Then, a dimension reduction algorithm such
as PCA or KPCA can be performed to realize the objective
of the denominator.
Further, ﬁnding the explicit formulation of Φ(·) is nontrivial. To solve this problem, some approaches adopt linear
mapping technique or turn to the kernel trick. In general,
there are three main ideas to deal with the above optimization problems.
• (Mapping Learning + Feature Extraction) A possible way
is to ﬁnd a high-dimensional space at ﬁrst where the objectives are met by solving a kernel matrix learning problem
or a transformation matrix ﬁnding problem. Then, the
high-dimensional features are compacted to form a lowdimensional feature representation. For example, once the
kernel matrix is learned, the principal components of the
implicit high-dimensional features can be extracted to
construct a new feature representation based on PCA.
• (Mapping Construction + Mapping Learning) Another
way is to map the original features to a constructed highdimensional feature space, and then a low-dimensional
mapping is learned to satisfy the objective function. For
example, a kernel matrix can be constructed based on
a selected kernel function at ﬁrst. Then, the transformation matrix can be learned, which projects the highdimensional features into a common latent subspace.
• (Direct Low-dimensional Mapping Learning) It is usually difﬁcult to ﬁnd a desired low-dimensional mapping
directly. However, if the mapping is assumed to satisfy
certain conditions, it may be solvable. For example, if the
low-dimensional mapping is restricted to be a linear one,
the optimization problem can be easily solved.
Some approaches also attempt to match the conditional
distributions and preserve the structures of the data. To
achieve this, the above simple objective function needs to
incorporate new terms or/and constraints. For example, the
following general objective function is a possible choice:
Φ µDIST(XS, XT ; Φ) + λ1ΩGEO(Φ) + λ2Ω(Φ)
+ (1 −µ)DIST(Y S|XS, Y T |XT ; Φ),
s.t. Φ(X)THΦ(X) = I, with H = I −(1/n) ∈Rn×n,
where µ is a parameter balancing the marginal and the
conditional distribution difference , ΩGEO(Φ) is a regularizer controlling the geometric structure, Φ(X) is the
matrix whose rows are the instances from both the source
and the target domains with the extracted new feature
representation, H is the centering matrix for constructing
the scatter matrix, and the constraint is used to maximize
the variance. The last term in the objective function denotes
the measurement of the conditional distribution difference.
Before the further discussion about the above objective
function, it is worth mentioning that the label information
of the target-domain instances is often limited or even
unknown. The lack of the label information makes it difﬁcult
to estimate the distribution difference. In order to solve
this problem, some approaches resort to the pseudo-label
strategy, i.e., assigning pseudo labels to the unlabeled targetdomain instances. A simple method of realizing this is
to train a base classiﬁer to assign pseudo labels. By the
way, there are some other methods of providing pseudo
labels such as co-training , and tri-training ,
 . Once the pseudo-label information is complemented,
the conditional distribution difference can be measured. For
example, MMD can be modiﬁed and extended to measure
the conditional distribution difference. Speciﬁcally, for each
label, the source-domain and the target-domain instances
that belong to the same class are collected, and the estimation expression of the conditional distribution difference is
given by :
k denote the numbers of the instances in
the source and the target domains with the same label Yk,
respectively. This estimation actually measures the classconditional distribution (i.e., P(x|y)) difference to approximate the conditional distribution (i.e., P(y|x)) difference.
Some studies improve the above estimation. For example,
the work by Wang et al. uses a weighted method to additionally solve the class imbalance problem . For better
understanding, the transfer learning approaches that are the
special cases of the general objective function presented in
the previous paragraph are detailed as follows.
• (µ = 1 and λ1 ̸= 0) The objective function of Maximum
Mean Discrepancy Embedding (MMDE) is given by :
K MMD(XS, XT ; Φ) −
||Φ(xi) −Φ(xj)||2
s.t. ∀(xi ∈k-NN(xj)) ∧(xj ∈k-NN(xi)),
||Φ(xi) −Φ(xj)||2 = ||xi −xj||2, (xi, xj ∈XS ∪XT ),
where k-NN(x) represents the k nearest neighbors of the
instance x. The authors design the above objective function motivated by Maximum Variance Unfolding (MVU)
 . Instead of employing a scatter matrix constraint, the
constraints and the second term of this objective function
aim to maximize the distance between instances as well
as preserve local geometry. The desired kernel matrix K
can be learned by solving a Semi-Deﬁnite Programming
(SDP) problem. After obtaining the kernel matrix,
PCA is applied to it, and then the leading eigenvectors
are selected to help construct a low-dimensional feature
representation.
• (µ = 1 and λ1 = 0) The work by Pan et al. proposes
an approach termed Transfer Component Analysis (TCA)
 , . TCA adopts MMD to measure the marginal distribution difference and enforces the scatter matrix as the
constraint. Different from MMDE that learns the kernel
matrix and then further adopts PCA, TCA is a uniﬁed
method that just needs to learn a linear mapping from an
empirical kernel feature space to a low-dimensional feature space. In this way, it avoids solving the SDP problem,
which results in relatively low computational burden. The
ﬁnal optimization problem can be easily solved via eigendecomposition. TCA can also be extended to utilize the
label information. In the extended version, the scatter
matrix constraint is replaced by a new one that balances
the label dependence (measured by HSIC) and the data
variance. Besides, a graph Laplacian regularizer is
also added to preserve the geometry of the manifold. Similarly, the ﬁnal optimization problem can also be solved by
eigen-decomposition.
• (µ = 0.5 and λ1 = 0) Long et al. proposed an approach termed Joint Distribution Adaptation (JDA) .
JDA attempts to ﬁnd a transformation matrix that maps
the instances to a low-dimensional space where both the
marginal and the conditional distribution difference are
minimized. To realize it, the MMD metric and the pseudolabel strategy are adopted. The desired transformation
matrix can be obtained by solving a trace optimization
problem via eigen-decomposition. Further, it is obvious
that the accuracy of the estimated pseudo labels affects
the performance of JDA. In order to improve the labeling
quality, the authors adopt the iterative reﬁnement operations. Speciﬁcally, in each iteration, JDA is performed,
and then a classiﬁer is trained on the instances with the
extracted features. Next, the pseudo labels are updated
based on the trained classiﬁer. After that, JDA is performed repeatedly with the updated pseudo labels. The
iteration ends when convergence occurs. Note that JDA
can be extended by utilizing the label and structure information , clustering information , various statistical
and geometrical information , etc.
• (µ ∈(0, 1) and λ1 = 0) The paper by Wang et al. proposes
an approach termed Balanced Distribution Adaptation
(BDA) , which is an extension of JDA. Different from
JDA which assumes that the marginal and the conditional
distributions have the same importance in adaptation,
BDA attempts to balance the marginal and the conditional distribution adaptation. The operations of BDA are
similar to JDA. In addition, the authors also proposed
the Weighted BDA (WBDA). In WBDA, the conditional
distribution difference is measured by a weighted version
of MMD to solve the class imbalance problem.
It is worth mentioning that some approaches transform
the features into a new feature space (usually of a high
dimension) and train an adaptive classiﬁer simultaneously.
To realize this, the mapping function of the features and the
decision function of the classiﬁer need to be associated. One
possible way is to deﬁne the following decision function:
f(x) = θ·Φ(x)+b, where θ denotes the classiﬁer parameter;
b denotes the bias. In light of the representer theorem ,
the parameter θ can be deﬁned as θ = Pn
i=1 αiΦ(xi), and
thus we have
αiΦ(xi) · Φ(x) + b =
αiκ(xi, x) + b,
where κ denotes the kernel function. By using the kernel
matrix as the bridge, the regularizers designed for the mapping function can be incorporated into the classiﬁer’s objective function. In this way, the ﬁnal optimization problem is
usually about the parameter (e.g., αi) or the kernel function.
For example, the paper by Long et al. proposes a general
framework termed Adaptation Regularization Based Transfer Learning (ARTL) . The goals of ARTL are to learn
the adaptive classiﬁer, to minimize the structural risk, to
jointly reduce the marginal and the conditional distribution
difference, and to maximize the manifold consistency between the data structure and the predictive structure. The
authors also proposed two speciﬁc algorithms under this
framework based on different loss functions. In these two
algorithms, the coefﬁcient matrix for computing MMD and
the graph Laplacian matrix for manifold regularization are
constructed at ﬁrst. Then, a kernel function is selected to
construct the kernel matrix. After that, the classiﬁer learning
problem is converted into a parameter (i.e., αi) solving
problem, and the solution formula is also given in .
In ARTL, the choice of the kernel function affects the
performance of the ﬁnal classiﬁer. In order to construct
a robust classiﬁer, some studies turn to kernel learning.
For example, the paper by Duan et al. proposes a uni-
ﬁed framework termed Domain Transfer Multiple Kernel
Learning (DTMKL) . In DTMKL, the kernel function
is assumed to be a linear combination of a group of base
kernels, i.e., κ(xi, xj) = PN
k=1 βkκk(xi, xj). DTMKL aims
to minimize the distribution difference, the classiﬁcation
error, etc., simultaneously. The general objective function of
DTMKL can be written as follows:
 MMD(XS, XT ; κ)
 + λΩL(βk, f),
where σ is any monotonically increasing function, f is the
decision function with the same deﬁnition as the one in
ARTL, and ΩL(βk, f) is a general term representing a group
of regularizers deﬁned on the labeled instances such as the
ones for minimizing the classiﬁcation error and controlling
the complexity of the resultant model. The authors developed an algorithm to learn the kernel and the decision
function simultaneously by using the reduced gradient descent method . In each iteration, the weight coefﬁcients
of base kernels are ﬁxed to update the decision function
at ﬁrst. Then, the decision function is ﬁxed to update the
weight coefﬁcients. Note that DTMKL can incorporate many
existing kernel methods. The authors proposed two speciﬁc
algorithms under this framework. The ﬁrst one implements
the framework by using hinge loss and Support Vector
Machine (SVM). The second one is an extension of the
ﬁrst one with an additional regularizer utilizing pseudolabel information, and the pseudo labels of the unlabeled
instances are generated by using base classiﬁers.
Feature Clustering
Feature clustering aims to ﬁnd a more abstract feature
representation of the original features. Although it can be
regarded as a way of feature extraction, it is different from
the above-mentioned mapping-based extraction.
For example, some transfer learning approaches implicitly reduce the features by using the co-clustering technique, i.e., simultaneously clustering both the columns and
rows of (or say, co-cluster) a contingency table based on
the information theory . The paper by Dai et al. 
proposes an algorithm termed Co-Clustering Based Classiﬁcation (CoCC), which is used for document classiﬁcation. In a document classiﬁcation problem, the transfer
learning task is to classify the target-domain documents
(represented by a document-to-word matrix) with the help
of the labeled source document-to-word data. CoCC regards the co-clustering technique as a bridge to transfer
the knowledge. In CoCC algorithm, both the source and
the target document-to-word matrices are co-clustered. The
source document-to-word matrix is co-clustered to generate
the word clusters based on the known label information,
and these word clusters are used as constraints during the
co-clustering process of the target-domain data. The coclustering criterion is to minimize the loss in mutual information, and the clustering results are obtained by iteration.
Each iteration contains the following two steps.
1. Document Clustering: Each row of the target documentto-word matrix is re-ordered based on the objective
function for updating the document clusters.
2. Word Clustering: The word clusters are adjusted to minimize the joint mutual-information loss of the source
and the target document-word matrices.
After several times of iterations, the algorithm converges,
and the classiﬁcation results are obtained. Note that, in
CoCC, the word clustering process implicitly extracts the
word features to form uniﬁed word clusters.
Dai et al. also proposed an unsupervised clustering approach, which is termed as Self-Taught Clustering (STC)
 . Similar to CoCC, this algorithm is also a co-clusteringbased one. However, STC does not need the label information. STC aims to simultaneously co-cluster the sourcedomain and the target-domain instances with the assumption that these two domains share the same feature clusters
in their common feature space. Therefore, two co-clustering
tasks are separately performed at the same time to ﬁnd
the shared feature clusters. Each iteration of STC has the
following steps.
1. Instance Clustering: The clustering results of the sourcedomain and the target domain instances are updated to
minimize their respective loss in mutual information.
2. Feature Clustering: The feature clusters are updated to
minimize the joint loss in mutual information.
When the algorithm converges, the clustering results of the
target-domain instances are obtained.
Different from the above-mentioned co-clustering-based
ones, some approaches extract the original features into concepts (or topics). In the document classiﬁcation problem, the
concepts represent the high-level abstractness of the words
(e.g., word clusters). In order to introduce the concept-based
transfer learning approaches easily, let us brieﬂy review the
Latent Semantic Analysis (LSA) , the Probabilistic LSA
(PLSA) , and the Dual-PLSA .
• LSA: LSA is an approach to mapping the document-toword matrix to a low-dimensional space (i.e., a latent semantic space) based on the SVD technique. In short, LSA
attempts to ﬁnd the true meanings of the words. To realize
this, SVD technique is used to reduce the dimensionality,
which can remove the irrelevant information and ﬁlter out
the noise information from the raw data.
• PLSA: PLSA is developed based on a statistical view of
LSA. PLSA assumes that there is a latent class variable
z, which reﬂects the concept, associating the document d
and the word w. Besides, d and w are independently conditioned on the concept z. The diagram of this graphical
model is presented as follows:
where the subscripts i, j and k represent the indexes of the
document, the word, and the concept, respectively. PLSA
constructs a Bayesian network, and the parameters are
estimated by using the Expectation-Maximization (EM)
algorithm .
• Dual-PLSA: The Dual-PLSA is an extension of PLSA. This
approach assumes there are two latent variables zd and
zw associating the documents and the words. Speciﬁcally,
the variables zd and zw reﬂect the concepts behind the
documents and the words, respectively. The diagram of
the Dual-PLSA is provided below:
←−−−−−−→zw
The parameters of the Dual-PLSA can also be obtained
based on the EM algorithm.
Some concept-based transfer learning approaches are
established based on PLSA. For example, the paper by Xue
et al. proposes a cross-domain text classiﬁcation approach
termed Topic-Bridged Probabilistic Latent Semantic Analysis (TPLSA) . TPLSA, which is an extension of PLSA,
assumes that the source-domain and the target-domain
instances share the same mixing concepts of the words.
Instead of performing two PLSAs for the source domain and
the target domain separately, the authors merge those two
PLSAs as an integrated one by using the mixing concept z as
a bridge, i.e., each concept has some probabilities to produce
the source-domain and the target-domain documents. The
diagram of TPLSA is provided below:
Note that PLSA does not require the label information. In
order to exploit the label information, the authors add the
concept constraints, which include must-link and cannotlink constraints, as the penalty terms in the objective
function of TPLSA. Finally, the objective function is iteratively optimized to obtain the classiﬁcation results (i.e.,
arg maxzP(z|dT
i )) by using the EM algorithm.
The work by Zhuang et al. proposes an approach termed
Collaborative Dual-PLSA (CD-PLSA) for multi-domain text
classiﬁcation (mS source domains and mT target domains)
 , . CD-PLSA is an extension of Dual-PLSA. Its diagram is shown below:
←−−−−−−→zw →
where 1 ≤k0 ≤mS + mT denotes the domain index.
The domain D connects both the variables d and w, but
is independent of the variables zd and zw. The label information of the source-domain instances is utilized by
initializing the value P(di|zd
k1, Dk0) (k0 = 1, · · · , mS). Due
to the lack of the target-domain label information, the
value P(di|zd
k1, Dk0) (k0 = mS + 1, · · · , mS + mT ) can
be initialized based on any supervised classiﬁer. Similarly,
the authors adopt the EM algorithm to ﬁnd the parameters. Through the iterations, all the parameters in the
Bayesian network are obtained. Thus, the class label of the
i-th document in a target domain (denoted by Dk) can
be predicted by computing the posterior probabilities, i.e.,
arg maxzdP(zd|di, Dk).
Zhuang et al. further proposed a general framework
that is termed as Homogeneous-Identical-Distinct-Concept
Model (HIDC) . This framework is also an extension of
Dual-PLSA. HIDC is composed of three generative models,
i.e., identical-concept, homogeneous-concept, and distinctconcept models. These three graphical models are presented
Identical-Concept Model:
Homogeneous-Concept Model:
Distinct-Concept Model:
The original word concept zw is divided into three types,
HC, and zw
DC. In the identical-concept model, the
word distributions only rely on the word concepts, and the
word concepts are independent of the domains. However,
in the homogeneous-concept model, the word distributions
also depend on the domains. The difference between the
identical and the homogeneous concepts is that zw
IC is directly transferable, while zw
HC is the domain-speciﬁc transferable one that may have different effects on the word distributions for different domains. In the distinct-concept model,
DC is actually the nontransferable domain-speciﬁc one,
which may only appear in a speciﬁc domain. The abovementioned three models are combined as an integrated one,
i.e., HIDC. Similar to other PLSA-related algorithms, HIDC
also uses EM algorithm to get the parameters.
Feature Selection
Feature selection is another kind of operation for feature
reduction, which is used to extract the pivot features. The
pivot features are the ones that behave in the same way
in different domains. Due to the stability of these features,
they can be used as the bridge to transfer the knowledge.
For example, Blitzer et al. proposed an approach termed
Structural Correspondence Learning (SCL) . Brieﬂy, SCL
consists of the following steps to construct a new feature
representation.
1. Feature Selection: SCL ﬁrst performs feature selection
operations to obtain the pivot features.
2. Mapping Learning: The pivot features are utilized to
ﬁnd a low-dimensional common latent feature space by
using the structural learning technique .
3. Feature Stacking: A new feature representation is constructed by feature augmentation, i.e., stacking the
original features with the obtained low-dimensional
Take the part-of-speech tagging problem as an example. The
selected pivot features should occur frequently in source
and target domains. Therefore, determiners can be included
in pivot features. Once all the pivot features are deﬁned
and selected, a number of binary linear classiﬁers whose
function is to predict the occurrence of each pivot feature are
constructed. Without losing generality, the decision function
of the i-th classiﬁer, which is used to predict the i-th pivot
feature, can be formulated as fi(x) = sign(θi·x), where x is
assumed to be a binary feature input. And the i-th classiﬁer
is trained on all the instances excluding the features derived
from the i-th pivot feature. The following formula can be
used to estimate the i-th classiﬁer’s parameters, i.e.,
θi = arg min
L (θ · xj, Rowi(xj)) + λ||θ||2,
where Rowi(xj) denotes the true value of the unlabeled
instance xj in terms of the i-th pivot feature. By stacking the
obtained parameter vectors as column elements, a matrix ˜W
is obtained. Next, based on singular value decomposition
(SVD), the top-k left singular vectors, which are the principal components of the matrix ˜W, are taken to construct
the transformation matrix W. At last, the ﬁnal classiﬁer is
trained on the labeled instances in an augmented feature
space, i.e., ([xL
Feature Encoding
In addition to feature extraction and selection, feature encoding is also an effective tool. For example, autoencoders,
which are often adopted in deep learning area, can be used
for feature encoding. An autoencoder consists of an encoder
and a decoder. The encoder tries to produce a more abstract
representation of the input, while the decoder aims to map
back that representation and to minimize the reconstruction
error. Autoencoders can be stacked to build a deep learning
architecture. Once an autoencoder completes the training
process, another autoencoder can be stacked at the top of
it. The newly added autoencoder is then trained by using
the encoded output of the upper-level autoencoder as its
input. In this way, deep learning architectures can thus be
constructed.
Some transfer learning approaches are developed based
on autoencoders. For example, the paper by Glorot et al.
proposes an approach termed Stacked Denoising Autoencoder (SDA) . The denoising autoencoder, which can
enhance the robustness, is an extension of the basic one .
This kind of autoencoder contains a randomly corrupting
mechanism that adds noise to the input before mapping. For
example, an input can be corrupted or partially destroyed
by adding a masking noise or Gaussian noise. The denoising
autoencoder is then trained to minimize the denoising reconstruction error between the original clean input and the
output. The SDA algorithm proposed in the paper mainly
encompasses the following steps.
1. Autoencoder Training: The source-domain and targetdomain instances are used to train a stack of denoising
autoencoders in a greedy layer-by-layer way.
2. Feature Encoding & Stacking: A new feature representation is constructed by stacking the encoding output of
intermediate layers, and the features of the instances
are transformed into the obtained new representation.
3. Learner Training: The target classiﬁer is trained on the
transformed labeled instances.
Although the SDA algorithm has excellent performance
for feature extraction, it still has some drawbacks such as
high computational and parameter-estimation cost. In order
to shorten the training time and to speed up traditional
SDA algorithms, Chen et al. proposed a modiﬁed version
of SDA, i.e., Marginalized Stacked Linear Denoising Autoencoder (mSLDA) , . This algorithm adopts linear
autoencoders and marginalizes the randomly corrupting
step in a closed form. It may seem that linear autoencoders
are too simple to learn complex features. However, the
authors observe that linear autoencoders are often sufﬁcient
to achieve competent performance when encountering high
dimensional data. The basic architecture of mSLDA is a
single-layer linear autoencoder. The corresponding singlelayer mapping matrix W (augmented with a bias column
for convenience) should minimize the expected squared
reconstruction loss function, i.e.,
W = arg min
EP (˜xi|x)
||xi −W ˜xi||2,
where ˜xi denotes the corrupted version of the input xi. The
solution of W is given by , :
When the corruption strategy is determined, the above formulas can be further expanded and simpliﬁed into a speciﬁc
form. Note that, in order to insert nonlinearity, a nonlinear
function is used to squash the output of each autoencoder
after we obtain the matrix W in a closed form. Then, the
next linear autoencoder is stacked to the current one in a
similar way to SDA. In order to deal with high dimensional
data, the authors also put forward an extension approach to
further reduce the computational complexity.
Feature Alignment
Note that feature augmentation and feature reduction
mainly focus on the explicit features in a feature space.
In contrast, in addition to the explicit features, feature
alignment also focuses on some implicit features such as
the statistic features and the spectral features. Therefore,
feature alignment can play various roles in the feature
transformation process. For example, the explicit features
can be aligned to generate a new feature representation, or
the implicit features can be aligned to construct a satisﬁed
feature transformation.
There are several kinds of features that can be aligned,
which includes subspace features, spectral features, and
statistic features. Take the subspace feature alignment as an
example. A typical approach mainly has the following steps.
1. Subspace Generation: In this step, the instances are used
to generate the respective subspaces for the source and
the target domains. The orthonormal bases of the source
and the target domain subspaces are then obtained,
which are denoted by MS and MT , respectively. These
bases are used to learn the shift between the subspaces.
2. Subspace Alignment: In the second step, a mapping,
which aligns the bases MS and MT of the subspaces,
is learned. And the features of the instances are projected to the aligned subspaces to generate new feature
representation.
3. Learner Training: Finally, the target learner is trained on
the transformed instances.
For example, the work by Fernando et al. proposes an
approach termed Subspace Alignment (SA) . In SA, the
subspaces are generated by performing PCA; the bases MS
and MT are obtained by selecting the leading eigenvectors.
Then, a transformation matrix W is learned to align the
subspaces, which is given by :
W = arg min
||MSW −MT ||2
where || · ||F denotes the Frobenius norm. Note that the
matrix W aligns MS with MT , or say, transforms the source
subspace coordinate system into the target subspace coordinate system. The transformed low-dimensional sourcedomain and target-domain instances are given by XSMSW
and XT MT, respectively. Finally, a learner can be trained on
the resultant transformed instances.
In light of SA, a number of transfer learning approaches
are established. For example, the paper by Sun and Saenko
proposes an approach that aligns both the subspace bases
and the distributions , which is termed as Subspace
Distribution Alignment between Two Subspaces (SDA-TS).
In SDA-TS, the transformation matrix W is formulated as
SMT Q, where Q is a matrix used to align the
distribution difference. The transformation matrix W in SA
is a special case of the one in SDA-TS by setting Q to an
identity matrix. Note that SA is a symmetrical feature-based
approach, while SDA-TS is an asymmetrical one. In SDA-
TS, the labeled source-domain instances are projected to the
source subspace, then mapped to the target subspace, and
ﬁnally mapped back to the target domain. The transformed
source-domain instances are formulated as XSMSWM T
Another representative subspace feature alignment approach is Geodesic Flow Kernel (GFK) , which is proposed by Gong et al. GFK is closely related to a previous approach termed Geodesic Flow Subspaces (GFS) . Before
introducing GFK, let us review the steps of GFS at ﬁrst. GFS
is inspired by incremental learning. Intuitively, utilizing the
information conveyed by the potential path between two
domains may be beneﬁcial to the domain adaptation. GFS
generally takes the following steps to align features.
1. Subspace Generation: GFS ﬁrst generates two subspaces
of the source and the target domains by performing
PCA, respectively.
2. Subspace Interpolation: The two obtained subspaces can
be viewed as two points on the Grassmann manifold
 . A ﬁnite number of the interpolated subspaces are
generated between these two subspaces based on the
geometric properties of the manifold.
3. Feature Projection & Stacking: The original features are
transformed by stacking the corresponding projections
from all the obtained subspaces.
Despite the usefulness and superiority of GFS, there is a
problem about how to determine the number of the interpolated subspaces. GFK resolves this problem by integrating
inﬁnite number of the subspaces located on the geodesic
curve from the source subspace to the target one. The key
of GFK is to construct an inﬁnite-dimensional feature space
that incorporating the information of all the subspaces lying
on the geodesic ﬂow. In order to compute the inner product
in the resultant inﬁnite-dimensional space, the geodesic-
ﬂow kernel is deﬁned and derived. In addition, a subspacedisagreement measure is proposed to select the optimal
dimensionality of the subspaces; a rank-of-domain metric
is also proposed to select the optimal source domain when
multi-source domains are available.
Statistic feature alignment is another kind of feature
alignment. For example, Sun et al. proposed an approach
termed Co-Relation Alignment (CORAL) . CORAL
constructs the transformation matrix of the source features
by aligning the second-order statistic features, i.e., the covariance matrices. The transformation matrix W is given by
W = arg min
||W TCSW −CT ||2
where C denotes the covariance matrix. Note that, compared to the above subspace-based approaches, CORAL
avoids subspace generation as well as projection and is very
easy to implement.
Some transfer learning approaches are established based
on spectral feature alignment. In traditional machine learning area, spectral clustering is a clustering technique based
on graph theory. The key of this technique is to utilize
the spectrum, i.e., eigenvalues, of the similarity matrix to
reduce the dimension of the features before clustering. The
similarity matrix is constructed to quantitatively assess the
relative similarity of each pair of data/vertices. On the
basis of spectral clustering and feature alignment, Spectral
Feature Alignment (SFA) is proposed by Pan et al. SFA
is an algorithm for sentiment classiﬁcation. This algorithm
tries to identify the domain-speciﬁc words and domainindependent words in different domains, and then aligns
these domain-speciﬁc word features to construct a lowdimensional feature representation. SFA generally contains
the following ﬁve steps.
1. Feature
Selection:
operations
domainindependent/pivot features. The paper presents three
strategies to select domain-independent features. These
strategies are based on the occurrence frequency of
words, the mutual information between features and
labels , and the mutual information between features and domains, respectively.
2. Similarity Matrix Construction: Once the domain-speciﬁc
and the domain-independent features are identiﬁed, a
bipartite graph is constructed. Each edge of this bipartite graph is assigned with a weight that measures the
co-occurrence relationship between a domain-speciﬁc
word and a domain-independent word. Based on the
bipartite graph, a similarity matrix is then constructed.
3. Spectral Feature Alignment: In this step, a spectral clustering algorithm is adapted and performed to align
domain-speciﬁc features , . Speciﬁcally, based
on the eigenvectors of the graph Laplacian, a feature
alignment mapping is constructed, and the domainspeciﬁc features are mapped into a low-dimensional
feature space.
4. Feature Stacking: The original features and the lowdimensional features are stacked to produce the ﬁnal
feature representation.
5. Learner Training: The target learner is trained on the
labeled instances with the ﬁnal feature representation.
There are some other spectral transfer learning approaches. For example, the work by Ling et al. proposes an
approach termed Cross-Domain Spectral Classiﬁer (CDSC)
 . The general ideas and steps of this approach are
presented as follows.
1. Similarity Matrix Construction: In the ﬁrst step, two
similarity matrices are constructed corresponding to
the whole instances and the target-domain instances,
respectively.
2. Spectral Feature Alignment: An objective function is designed with respect to a graph-partition indicator vector; a constraint matrix is constructed, which contains
pair-wise must-link information. Instead of seeking the
discrete solution of the indicator vector, the solution is
relaxed to be continuous, and the eigen-system problem
corresponding to the objective function is solved to
construct the aligned spectral features .
3. Learner Training: A traditional classiﬁer is trained on the
transformed instances.
To be more speciﬁc, the objective function has a form of
the generalized Rayleigh quotient, which aims to ﬁnd the
optimal graph partition that respects the label information
with small cut-size , to maximize the separation of
the target-domain instances, and to ﬁt the constraints of
the pair-wise property. After eigen-decomposition, the last
eigenvectors are selected and combined as a matrix, and
then the matrix is normalized. Each row of the normalized
matrix represents a transformed instance.
MODEL-BASED INTERPRETATION
Transfer learning approaches can also be interpreted from
the model perspective. Fig. 4 shows the corresponding
strategies and the objectives. The main objective of a transfer
learning model is to make accurate prediction results on the
target domain, e.g., classiﬁcation or clustering results. Note
that a transfer learning model may consist of a few submodules such as classiﬁers, extractors, or encoders. These
sub-modules may play different roles, e.g., feature adaptation or pseudo label generation. In this section, some related
Model-Based Interpretation
Domain Adaptation
Model Ensemble
Model Selection
Parameter Sharing
Prediction Making
Parameter Control
Deep Learning Technique
Parameter Restriction
Voting Strategy
Weighting Strategy
Traditional Deep Learning
Adversarial Deep Learning
Model Control
Consensus Regularizer
Domain-Dependent Regularizer
Pseudo Label Generation
Fig. 4. Strategies and objectives of the transfer learning approaches from the model perspective.
transfer learning approaches are introduced in proper order
according to the strategies shown in Fig. 4.
Model Control Strategy
From the perspective of model, a natural thought is to
directly add the model-level regularizers to the learner’s
objective function. In this way, the knowledge contained
in the pre-obtained source models can be transferred into
the target model during the training process. For example,
the paper by Duan et al. proposes a general framework
termed Domain Adaptation Machine (DAM) , ,
which is designed for multi-source transfer learning. The
goal of DAM is to construct a robust classiﬁer for the target
domain with the help of some pre-obtained base classiﬁers
that are respectively trained on multiple source domains.
The objective function is given by:
f T LT,L(f T ) + λ1ΩD(f T ) + λ2Ω(f T ),
where the ﬁrst term represents the loss function used to minimize the classiﬁcation error of the labeled target-domain instances, the second term denotes different regularizers, and
the third term is used to control the complexity of the ﬁnal
decision function f T . Different types of the loss functions
can be adopted in LT,L(f T ) such as the square error or the
cross-entropy loss. Some transfer learning approaches can
be regarded as the special cases of this framework to some
• (Consensus Regularizer) The work by Luo et al. proposes
a framework termed Consensus Regularization Framework (CRF) , . CRF is designed for multi-source
transfer learning with no labeled target-domain instances.
The framework constructs mS classiﬁers corresponding
to each source domain, and these classiﬁers are required
to reach mutual consensuses on the target domain. The
objective function of each source classiﬁer, denoted by f S
(with k = 1, · · · , mS), is similar to that of DAM, which is
presented below:
k ) + λ2Ω(f S
k denotes the decision function corresponding to
the k-th source domain, and S(x) = −x log x. The ﬁrst
term is used to quantify the classiﬁcation error of the
k-th classiﬁer on the k-th source domain, and the last
term is the consensus regularizer in the form of crossentropy. The consensus regularizer can not only enhance
the agreement of all the classiﬁers, but also reduce the
uncertainty of the predictions on the target domain. The
authors implement this framework based on the logistic
regression. A difference between DAM and CRF is that
DAM explicitly constructs the target classiﬁer, while CRF
makes the target predictions based on the reached consensus from the source classiﬁers.
• (Domain-dependent Regularizer) Fast-DAM is a speciﬁc
algorithm of DAM . In light of the manifold assumption and the graph-based regularizer , ,
Fast-DAM designs a domain-dependent regularizer. The
objective function is given by:
+ λ2Ω(f T )
k (k = 1, 2, · · · , mS) denotes the pre-obtained
source decision function for the k-th source domain and
βk represents the weighting parameter that is determined
by the relevance between the target domain and the kth source domain and can be measured based on the
MMD metric. The third term is the domain-dependent
regularizer, which transfers the knowledge contained in
the source classiﬁer motivated by domain dependence. In
 , the authors also introduce and add a new term to
the above objective function based on ε-insensitive loss
function , which makes the resultant model have
high computational efﬁciency.
• (Domain-dependent Regularizer + Universum Regularizer) Univer-DAM is an extension of the Fast-DAM .
Its objective function contains an additional regularizer,
i.e., Universum regularizer. This regularizer usually utilizes an additional dataset termed Universum where the
instances do not belong to either the positive or the
negative class . The authors treat the source-domain
instances as the Universum for the target domain, and the
objective function of Univer-DAM is presented as follows:
+ λ3Ω(f T ).
Similar to Fast-DAM, the ε-insensitive loss function can
also be utilized .
Parameter Control Strategy
The parameter control strategy focuses on the parameters of
models. For example, in the application of object categorization, the knowledge from known source categories can be
transferred into target categories via object attributes such as
shape and color . The attribute priors, i.e., probabilistic
distribution parameters of the image features corresponding
to each attribute, can be learned from the source domain
and then used to facilitate learning the target classiﬁer.
The parameters of a model actually reﬂect the knowledge
learned by the model. Therefore, it is possible to transfer the
knowledge at the parametric level.
Parameter Sharing
An intuitive way of controlling the parameters is to directly
share the parameters of the source learner to the target
learner. Parameter sharing is widely employed especially
in the network-based approaches. For example, if we have
a neural network for the source task, we can freeze (or say,
share) most of its layers and only ﬁnetune the last few layers
to produce a target network. The network-based approaches
are introduced in Section 5.4.
In addition to network-based parameter sharing, matrixfactorization-based parameter sharing is also workable. For
example, Zhuang et al. proposed an approach for text classiﬁcation, which is referred to as Matrix Tri-Factorization
Based Classiﬁcation Framework (MTrick) . The authors observe that, in different domains, different words or
phrases sometimes express the same or similar connotative
meaning. Thus, it is more effective to use the concepts behind the words rather than the words themselves as a bridge
to transfer the knowledge in source domains. Different
from PLSA-based transfer learning approaches that utilize
the concepts by constructing Bayesian networks, MTrick
attempts to ﬁnd the connections between the document
classes and the concepts conveyed by the word clusters
through matrix tri-factorization. These connections are considered to be the stable knowledge that is supposed to be
transferred. The main idea is to decompose a document-toword matrix into three matrices, i.e., document-to-cluster,
connection, and cluster-to-word matrices. Speciﬁcally, by
performing the matrix tri-factorization operations on the
source and the target document-to-word matrices respectively, a joint optimization problem is constructed, which is
Q,R,W ||XS −QSRW S||2 + λ1||XT −QT RW T ||2
+λ2||QS −˘QS||2
s.t. Normalization Constraints,
where X denotes the document-to-word matrix, Q denotes
the document-to-cluster matrix, R represents the transformation matrix from document clusters to word clusters, W
denotes the cluster-to-word matrix, nd denotes the number
of the documents, and ˘QS represents the label matrix. The
matrix ˘QS is constructed based on the class information of
the source-domain documents. If the i-th document belongs
to the k-th class, ˘QS
[i,k] = 1. In the above objective function,
the matrix R is actually the shared parameter. The ﬁrst term
aims to tri-factorize the source document-to-word matrix,
and the second term decomposes the target document-toword matrix. The last term incorporates the source-domain
label information. The optimization problem is solved based
on the alternating iteration method. Once the solution of
QT is obtained, the class index of the k-th target-domain
instance is the one with the maximum value in the k-th row
Further, Zhuang et al. extended MTrick and proposed
an approach termed Triplex Transfer Learning (TriTL) .
MTrick assumes that the domains share the similar concepts behind their word clusters. In contrast, TriTL assumes that the concepts of these domains can be further
divided into three types, i.e., domain-independent, transferable domain-speciﬁc, and nontransferable domain-speciﬁc
concepts, which is similar to HIDC. This idea is motivated
by Dual Transfer Learning (DTL), where the concepts are
assumed to be composed of the domain-independent ones
and the transferable domain-speciﬁc ones . The objective function of TriTL is provided as follows:
s.t. Normalization Constraints,
where the deﬁnitions of the symbols are similar to those of
MTrick and the subscript k denotes the index of the domains
with the assumption that the ﬁrst mS domains are the
source domains and the last mT domains are the target domains. The authors proposed an iterative algorithm to solve
the optimization problem. And in the initialization phase,
W DI and W TD
are initialized based on the clustering results
of the PLSA algorithm, while W UT
is randomly initialized;
the PLSA algorithm is performed on the combination of the
instances from all the domains.
There are some other approaches developed based on
matrix factorization. Wang et al. proposed a transfer learning framework for image classiﬁcation . Wang et al.
proposed a softly associative approach that integrates two
matrix tri-factorizations into a joint framework . Do
et al. utilized matrix tri-factorization to discover both the
implicit and the explicit similarities for cross-domain recommendation .
Parameter Restriction
Another parameter-control-type strategy is to restrict the
parameters. Different from the parameter sharing strategy
that enforces the models share some parameters, parameter restriction strategy only requires the parameters of the
source and the target models to be similar.
Take the approaches to category learning as examples.
The category-learning problem is to learn a new decision
function for predicting a new category (denoted by the
(k + 1)-th category) with only limited target-domain instances and k pre-obtained binary decision functions. The
function of these pre-obtained decision functions is to predict which of the k categories an instance belongs to. In
order to solve the category-learning problem, Tommasi et
al. proposed an approach termed Single-Model Knowledge
Transfer (SMKL) . SMKL is based on Least-Squares
SVM (LS-SVM). The advantage of LS-SVM is that LS-SVM
transforms inequality constraints to equality constraints and
has high computational efﬁciency; its optimization is equivalent to solving a linear equation system problem instead
of a quadratic programming problem. SMKL selects one of
the pre-obtained binary decision functions, and transfers
the knowledge contained in its parameters. The objective
function is given by
where f(x) = θ · Φ(x) + b, β is the weighting parameter
controlling the transfer degree, ˜θ is the parameter of a
selected pre-obtained model, and ηj is the coefﬁcient for
resolving the label imbalance problem. The kernel parameter and the tradeoff parameter are chosen based on crossvalidation. In order to ﬁnd the optimal weighting parameter,
the authors refer to an earlier work . In , Cawley
proposed a model selection mechanism for LS-SVM, which
is based on the leave-one-out cross-validation method. The
superiority of this method is that the leave-one-out error
for each instance can be obtained in a closed form without
performing the real cross-validation experiment. Motivated
by Cawley’s work, the generalization error can be easily
estimated to guide the parameter setting in SMKL.
Tommasi et al. further extended SMKL by utilizing all the
pre-obtained decision functions. In , an approach that
is referred to as Multi-Model Knowledge Transfer (MMKL)
is proposed. Its objective function is presented as follows:
where θi and βi are the model parameter and the weighting
parameter of the i-th pre-obtained decision function, respectively. The leave-one-out error can also be obtained in a
closed form, and the optimal value of βi (i = 1, 2, · · · , k)
is the one that maximizes the generalization performance.
Model Ensemble Strategy
In sentiment analysis applications related to product reviews, data or models from multiple product domains are
available and can be used as the source domains . Combining data or models directly into a single domain may
not be successful because the distributions of these domains
are different from each other. Model ensemble is another
commonly used strategy. This strategy aims to combine a
number of weak classiﬁers to make the ﬁnal predictions.
Some previously mentioned transfer learning approaches
already adopted this strategy. For example, TrAdaBoost and
MsTrAdaBoost ensemble the weak classiﬁers via voting and
weighting, respectively. In this subsection, several typical
ensemble-based transfer learning approaches are introduced
to help readers better understand the function and the
appliance of this strategy.
As mentioned in Section 4.1, TaskTrAdaBoost, which
is an extension of TrAdaBoost for handling multi-source
scenarios, is proposed in the paper . TaskTrAdaBoost
mainly has the following two stages.
1. Candidate Classiﬁer Construction: In the ﬁrst stage, a
group of candidate classiﬁers are constructed by performing AdaBoost on each source domain. Note that,
for each source domain, each iteration of AdaBoost results in a new weak classiﬁer. In order to avoid the over-
ﬁtting problem, the authors introduced a threshold to
pick the suitable classiﬁers into the candidate group.
2. Classiﬁer Selection and Ensemble: In the second stage, a
revised version of AdaBoost is performed on the targetdomain instances to construct the ﬁnal classiﬁer. In each
iteration, an optimal candidate classiﬁer which has the
lowest classiﬁcation error on the labeled target-domain
instances is picked out and assigned with a weight
based on the classiﬁcation error. Then, the weight of
each target-domain instance is updated based on the
performance of the selected classiﬁer on the target domain. After the iteration process, the selected classiﬁers
are ensembled to produce the ﬁnal predictions.
The difference between the original AdaBoost and the second stage of TaskTrAdaBoost is that, in each iteration, the
former constructs a new candidate classiﬁer on the weighted
target-domain instances, while the latter selects one preobtained candidate classiﬁer which has the minimal classiﬁcation error on the weighted target-domain instances.
The paper by Gao et al. proposes another ensemblebased framework that is referred to as Locally Weighted Ensemble (LWE) . LWE focuses on the ensemble process
of various learners; these learners could be constructed on
different source domains, or be built by performing different
learning algorithms on a single source domain. Different
from TaskTrAdaBoost that learns the global weight of each
learner, the authors adopted the local-weight strategy, i.e.,
assigning adaptive weights to the learners based on the local
manifold structure of the target-domain test set. In LWE,
a learner is usually assigned with different weights when
classifying different target-domain instances. Speciﬁcally,
the authors adopt a graph-based approach to estimate the
weights. The steps for weighting are outlined below.
1. Graph Construction: For the i-th source learner, a graph
Si is constructed by using the learner to classify the
target-domain instances in the test set; if two instances
are classiﬁed into the same class, they are connected
in the graph. Another graph GT is constructed for
the target-domain instances as well by performing a
clustering algorithm.
2. Learner Weighting: The weight of the i-th learner for the
j-th target-domain instance xT
j is proportional to the
similarity between the instance’s local structures in GT
and GT . And the similarity can be measured by the
percentage of the common neighbors of xT
j in these two
Note that this weighting scheme is based on the clusteringmanifold assumption, i.e., if two instances are close to each
other in a high-density region, they often have similar
labels. In order to check the validity of this assumption
for the task, the target task is tested on the source-domain
training set(s). Speciﬁcally, the clustering quality of the
training set(s) is quantiﬁed and checked by using a metric
such as purity or entropy. If the clustering quality is not
satisfactory, uniform weights are assigned to the learners
instead. Besides, it is intuitive that if the measured structure
similarity is particularly low for every learner, weighting
and combining these learners seems unwise. Therefore, the
authors introduce a threshold and compare it to the average
similarity. If the similarity is lower than the threshold, the
label of xT
j is determined by the voting scheme among its
reliable neighbors, where the reliable neighbors are the ones
whose label predictions are made by the combined classiﬁer.
The above-mentioned TaskTrAdaBoost and LWE approaches mainly focus on the ensemble process. In contrast, some studies focus more on the construction of weak
learners. For example, Ensemble Framework of Anchor
Adapters (ENCHOR) is a weighting ensemble framework proposed by Zhuang et al. An anchor is a speciﬁc
instance. Different from TrAdaBoost which adjusts weights
of instances to train and produce a new learner iteratively,
ENCHOR constructs a group of weak learners via using different representations of the instances produced by anchors.
The thought is that the higher similarity between a certain
instance and an anchor, the more likely the feature of that instance remains unchanged relative to the anchor, where the
similarity can be measured by using the cosine or Gaussian
distance function. ENCHOR contains the following steps.
1. Anchor Selection: In this step, a group of anchors are
selected. These anchors can be selected based on some
rules or even randomly. In order to improve the ﬁnal performance of ENCHOR, the authors proposed a
method of selecting high-quality anchors .
2. Anchor-based Representation Generation: For each anchor
and each instance, the feature vector of an instance is
directly multiplied by a coefﬁcient that measures the
distance from the instance to the anchor. In this way,
each anchor produces a new pair of anchor-adapted
source and target instance sets.
3. Learner Training and Ensemble: The obtained pairs of
instance sets can be respectively used to train learners.
Then, the resultant learners are weighted and combined
to make the ﬁnal predictions.
The framework ENCHOR is easy to be realized in a parallel
manner in that the operations performed on each anchor are
independent.
Deep Learning Technique
Deep learning methods are particularly popular in the ﬁeld
of machine learning. Many researchers utilize the deep
learning techniques to construct transfer learning models.
For example, the SDA and the mSLDA approaches mentioned in Section 4.2.6 utilize the deep learning techniques.
In this subsection, we speciﬁcally discuss the deep-learningrelated transfer learning models. The deep learning approaches introduced are divided into two types, i.e., nonadversarial (or say, traditional) ones and adversarial ones.
Traditional Deep Learning
As said earlier, autoencoders are often used in deep learning
area. In addition to SDA and mSLDA, there are some other
reconstruction-based transfer learning approaches. For example, the paper by Zhuang et al. proposes an approach
termed Transfer Learning with Deep Autoencoders (TLDA)
 , . TLDA adopts two autoencoders for the source
and the target domains, respectively. These two autoencoders share the same parameters. The encoder and the
decoder both have two layers with activation functions. The
diagram of the two autoencoders is presented as follows:
XS (W1,b1)
−−−−−−−−−−→
Softmax Regression RS ( ˆ
−−−−−→˜QS ( ˆ
−−−−−→˜XS,
KL Divergence
XT (W1,b1)
−−−−−−−−−−→
Softmax Regression RT ( ˆ
−−−−−→˜QT ( ˆ
−−−−−→˜XT .
There are several objectives of TLDA, which are listed as
1. Reconstruction Error Minimization: The output of the decoder should be extremely close to the input of encoder.
In other words, the distance between XS and ˜XS as
well as the distance between XT and ˜XT should be
minimized.
2. Distribution Adaptation: The distribution difference between QS and QT should be minimized.
3. Regression Error Minimization: The output of the encoder
on the labeled source-domain instances, i.e., RS, should
be consistent with the corresponding label information
Therefore, the objective function of TLDA is given by
LREC(X, ˜X) + λ1KL(QS||QT ) + λ2Ω(W, b, ˆW,ˆb)
+λ3LREG(RS, Y S),
where the ﬁrst term represents the reconstruction error,
KL(·) represents the KL divergence, the third term controls
the complexity, and the last term represents the regression
error. TLDA is trained by using a gradient descent method.
The ﬁnal predictions can be made in two different ways. The
ﬁrst way is to directly use the output of the encoder to make
predictions. And the second way is to treat the autoencoder
as a feature extractor, and then train the target classiﬁer
on the labeled instances with the feature representation
produced by the encoder’s ﬁrst-layer output.
In addition to the reconstruction-based domain adaptation, discrepancy-based domain adaptation is also a popular
direction. In earlier research, the shallow neural networks
are tried to learn the domain-independent feature representation . It is found that the shallow architectures
often make it difﬁcult for the resultant models to achieve
excellent performance. Therefore, many studies turn to utilize deep neural networks. Tzeng et al. added a single
adaptation layer and a discrepancy loss to the deep neural
network, which improves the performance. Further, Long
et al. performed multi-layer adaptation and utilized multikernel technique, and they proposed an architecture termed
Deep Adaptation Networks (DAN) .
For better understanding, let us review DAN in detail.
DAN is based on AlexNet and its architecture is
presented below .
Five Convolutional Layers
Three Fully Connected Layers
In the above network, the features are ﬁrst extracted by ﬁve
convolutional layers in a general-to-speciﬁc manner. Next,
the extracted features are fed into one of the two fully
connected networks switched by their original domains.
These two networks both consist of three fully connected
layers that are specialized for the source and the target
domains. DAN has the following objectives.
1. Classiﬁcation Error Minimization: The classiﬁcation error
of the labeled instances should be minimized. The
cross-entropy loss function is adopted to measure the
prediction error of the labeled instances.
2. Distribution Adaptation: Multiple layers, which include
the representation layers and the output layer, can be
jointly adapted in a layer-wise manner. Instead of using
the single-kernel MMD to measure the distribution
difference, the authors turn to MK-MMD. The authors
adopt the linear-time unbiased estimation of MK-MMD
to avoid numerous inner product operations .
3. Kernel Parameter Optimization: The weighting parameters of the multiple kernels in MK-MMD should be
optimized to maximize the test power .
The objective function of the DAN network is given by:
where l denotes the index of the layer. The above optimization is actually a minimax optimization problem. The
maximization of the objective function with respect to the
kernel function κ aims to maximize the test power. After this
step, the subtle difference between the source and the target
domains are magniﬁed. This train of thought is similar to
the Generative Adversarial Network (GAN) . In the
training process, the DAN network is initialized by a pretrained AlexNet . There are two categories of parameters that should be learned, i.e., the network parameters
and the weighting parameters of the multiple kernels. Given
that the ﬁrst three convolutional layers output the general
features and are transferable, the authors freeze them and
ﬁne-turn the last two convolutional layers and the two fully
connected layers . The last fully connected layer (or say,
the classiﬁer layer) is trained from scratch.
Long et al. further extended the above DAN approach
and proposed the DAN framework . The new characteristics are summarized as follows.
1. Regularizer Adding: The framework introduces an additional regularizer to minimize the uncertainty of the
predicted labels of the unlabeled target-domain instances, which is motivated by entropy minimization
criterion .
2. Architecture Generalizing: The DAN framework can be
applied to many other architectures such as GoogLeNet
 and ResNet .
3. Measurement Generalizing: The distribution difference
can be estimated by other metrics. For example, in
addition to MK-MMD, the authors also present the
Mean Embedding test for distribution adaptation .
The objective function of the DAN framework is given by:
P(yj|f(xT,U
where lstrt and lend denote the boundary indexes of the fully
connected layers for adapting the distributions.
There are some other impressive works. For example,
Long et al. constructed residual transfer networks for domain adaptation, which is motivated by deep residual learning . Besides, another work by Long et al. proposes
the Joint Adaptation Network (JAN) , which adapts
the joint distribution difference of multiple layers. Sun and
Saenko extended CORAL for deep domain adaptation and
proposed an approach termed Deep CORAL (DCORAL), in
which the CORAL loss is added to minimize the feature
covariance . Chen et al. realized that the instances with
the same label should be close to each other in the feature
space, and they not only add the CORAL loss but also add
an instance-based class-level discrepancy loss . Pan et
al. constructed three prototypical networks (corresponding
to DS, DT and DS ∪DT ) and incorporated the thought
of multi-model consensus. They also adopt pseudo-label
strategy and adapt both the instance-level and class-level
discrepancy . Kang et al. proposed the Contrastive
Adaptation Network (CAN), which is based on the discrepancy metric termed contrastive domain discrepancy
 . Zhu et al. aimed to adapt the extracted multiple feature representations and proposed the Multi-Representation
Adaptation Network (MRAN) .
Deep learning technique can also be used for multisource transfer learning. For example, the work by Zhu et al.
proposes a framework that is referred to as Multiple Feature
Spaces Adaptation Network (MFSAN) . The architecture of MFSAN consists of a common-feature extractor, mS
domain-speciﬁc feature extractors, and mS domain-speciﬁc
classiﬁers. The corresponding schematic diagram is shown
1 · · · XS
k · · · XS
1 · · · QS
k · · · QS
Domain-Speciﬁc
−−−−−−−−−→
Extractors
1 · · · RS
k · · · RS
1 · · · RT
k · · · RT
Domain-Speciﬁc
−−−−−−−−−→
Classiﬁers
1 · · · ˆY S
k · · · ˆY S
1 · · · ˆY T
k · · · ˆY T
In each iteration, MFSAN has the following steps.
1. Common Feature Extraction: For each source domain
(denoted by DSk with k = 1, · · · , mS), the sourcedomain instances (denoted by XS
k ) are separately input
to the common-feature extractor to produce instances in
a common latent feature space (denoted by QS
k). Similar
operations are also performed on the target-domain
instances (denoted by XT ), which produces QT .
2. Speciﬁc Feature Extraction: For each source domain,
the extracted common features QS
k is fed to the kth domain-speciﬁc feature extractor. Meanwhile, QT is
fed to all the domain-speciﬁc feature extractors, which
results in RT
k with k = 1, · · · , mS.
3. Data Classiﬁcation: The output of the k-th domainspeciﬁc feature extractor is input to the k-th classiﬁer.
In this way, mS pairs of the classiﬁcation results are
predicted in the form of probability.
4. Parameter Updating: The parameters of the network are
updated to optimize the objective function.
There are three objectives in MFSAN, i.e., classiﬁcation
error minimization, distribution adaptation, and consensus
regularization. The objective function is given by:
where the ﬁrst term represents the classiﬁcation error of the
labeled source-domain instances, the second term measures
the distribution difference, and the third term measures
the discrepancy of the predictions on the target-domain
instances.
Adversarial Deep Learning
The thought of adversarial learning can be integrated into
deep-learning-based transfer learning approaches. As mentioned above, in the DAN framework, the network Θ and
the kernel κ play a minimax game, which reﬂects the
thought of adversarial learning. However, the DAN framework is a little different from the traditional GAN-based
methods in terms of the adversarial matching. In the DAN
framework, there is only a few parameters to be optimized
in the max game, which makes the optimization easier
to achieve equilibrium. Before introducing the adversarial
transfer learning approaches, let us brieﬂy review the original GAN framework and the related work.
The original GAN , which is inspired by the twoplayer game, is composed of two models, a generator G and
a discriminator D. The generator produces the counterfeits
of the true data for the purpose of confusing the discriminator and making the discriminator produce wrong detection.
The discriminator is fed with the mixture of the true data
and the counterfeits, and it aims to detect whether a data is
the true one or the fake one. These two models actually play
a two-player minimax game, and the objective function is as
Ex∼Ptrue [log D(x)] + E˜z∼P˜z [log (1 −D(G(˜z)))],
where ˜z represents the noise instances (sampled from a
certain noise distribution) used as the input of the generator
for producing the counterfeits. The entire GAN can be
trained by using the back-propagation algorithm. When the
two-player game achieves equilibrium, the generator can
produce almost true-looking instances.
Motivated by GAN, many transfer learning approaches
are established based on the assumption that a good feature
representation contains almost no discriminative information about the instances’ original domains. For example, the
work by Ganin et al. proposes a deep architecture termed
Domain-Adversarial Neural Network (DANN) for domain
adaptation , . DANN assumes that there is no
labeled target-domain instance to work with. Its architecture consists of a feature extractor, a label predictor, and a
domain classiﬁer. The corresponding diagram is as follows.
ˆT (Domain Label)
The feature extractor acts like the generator, which aims to
produce the domain-independent feature representation for
confusing the domain classiﬁer. The domain classiﬁer plays
the role like the discriminator, which attempts to detect
whether the extracted features come from the source domain
or the target domain. Besides, the label predictor produces
the label prediction of the instances, which is trained on the
extracted features of the labeled source-domain instances,
i.e., QS,L. DANN can be trained by inserting a special gradient reversal layer (GRL). After the training of the whole
system, the feature extractor learns the deep feature of the
instances, and the output ˆY T,U is the predicted labels of the
unlabeled target-domain instances.
There are some other related impressive works. The
work by Tzeng et al. proposes a uniﬁed adversarial domain
adaptation framework . The work by Shen et al. adopts
Wasserstein distance for domain adaptation . Hoffman
et al. adopted cycle-consistency loss to ensure the structural
and semantic consistency . Long et al. proposed the
Conditional Domain Adversarial Network (CDAN), which
utilizes a conditional domain discriminator to assist adversarial adaptation . Zhang et al. adopted a symmetric
design for the source and the target classiﬁers . Zhao et
al. utilized domain adversarial networks to solve the multisource transfer learning problem . Yu et al. proposed a
dynamic adversarial adaptation network .
Some approaches are designed for some special scenarios. Take the partial transfer learning as an example. The
partial transfer learning approaches are designed for the scenario that the target-domain classes are less than the sourcedomain classes, i.e., YS ⊆YT . In this case, the sourcedomain instances with different labels may have different
importance for domain adaptation. To be more speciﬁc, the
source-domain and the target-domain instances with the
same label are more likely to be potentially associated. However, since the target-domain instances are unlabeled, how
to identify and partially transfer the important information
from the labeled source-domain instances is a critical issue.
The paper by Zhang et al. proposes an approach
for partial domain adaptation, which is called Importance Weighted Adversarial Nets-Based Domain Adaptation
(IWANDA) . The architecture of IWANDA is different
from that of DANN. DANN adopts one common feature
extractor based on the assumption that there exists a common feature space where QS,L and QT,U have the similar
distribution. However, IWANDA uses two domain-speciﬁc
feature extractors for the source and the target domains,
respectively. Speciﬁcally, IWANDA consists of two feature
extractors, two domain classiﬁers, and one label predictor.
The diagram of IWANDA is presented below.
Source Feature
Target Feature
2nd Domain
1st Domain
Before training, the source feature extractor and the label
predictor are pre-trained on the labeled source-domain instances. These two components are frozen in the training
process, which means that only the target feature extractor
and the domain classiﬁers should be optimized. In each
iteration, the above network is optimized by taking the
following steps.
1. Instance Weighting: In order to solve the partial transfer
issue, the source-domain instances are assigned with
weights based on the output of the ﬁrst domain classiﬁer. The ﬁrst domain classiﬁer is fed with QS,L and
QT,U, and then outputs the probabilistic predictions of
their domains. If a source domain instance is predicted
with a high probability of belonging to the target domain, this instance is highly likely to associate with the
target domain. Thus, this instance is assigned with a
larger weight and vice versa.
2. Prediction Making: The label predictor outputs the label
predictions of the instances. The second classiﬁer predicts which domain an instance belongs to.
3. Parameter Updating: The ﬁrst classiﬁer is optimized to
minimize the domain classiﬁcation error. The second
classiﬁer plays a minmax game with the target feature extractor. This classiﬁer aims to detect whether
a instance is the instance from the target domain or
the weighted instance from the source domain, and
to reduce the uncertainty of the label prediction ˆY T,U.
The target feature extractor aims to confuse the second
classiﬁer. These components can be optimized in a
similar way to GAN or by inserting a GRL.
In addition to IWANDA, the work by Cao et al. constructs the selective adversarial network for partial transfer
learning . There are some other studies related to
transfer learning. For example, the work by Wang et al.
proposes a minimax-based approach to select high-quality
source-domain data . Chen et al. investigated the transferability and the discriminability in the adversarial domain
adaptation, and proposed a spectral penalization approach
to boost the existing adversarial transfer learning methods
APPLICATION
In previous sections, a number of representative transfer learning approaches are introduced, which have been
applied to solving a variety of text-related/image-related
problems in their original papers. For example, MTrick 
and TriTL utilize the matrix factorization technique to
solve cross-domain text classiﬁcation problems; the deeplearning-based approaches such as DAN , DCORAL
 , and DANN , are applied to solving image
classiﬁcation problems. Instead of focusing on the general
text-related or image-related applications, in this section, we
mainly focus on the transfer learning applications in speciﬁc
areas such as medicine, bioinformatics, transportation, and
recommender systems.
Medical Application
Medical imaging plays an important role in the medical
area, which is a powerful tool for diagnosis. With the development of computer technology such as machine learning, computer-aided diagnosis has become a popular and
promising direction. Note that medical images are generated by special medical equipment, and their labeling often
relies on experienced doctors. Therefore, in many cases, it is
expensive and hard to collect sufﬁcient training data. Transfer learning technology can be utilized for medical imaging
analysis. A commonly used transfer learning approach is
to pre-train a neural network on the source domain (e.g.,
ImageNet, which is an image database containing more than
fourteen million annotated images with more than twenty
thousand categories ) and then ﬁnetune it based on the
instances from the target domain.
For example, Maqsood et al. ﬁnetuned the AlexNet 
for the detection of Alzheimer’s disease . Their approach has the following four steps. First, the MRI images
from the target domain are pre-processed by performing
contrast stretching operations. Second, the AlexNet architecture is pre-trained over ImageNet (i.e., the source
domain) as a starting point to learn the new task. Third,
the convolutional layers of AlexNet are ﬁxed, and the last
three fully connected layers are replaced by the new ones
including one softmax layer, one fully connected layer, and
one output layer. Finally, the modiﬁed AlexNet is ﬁnetuned
by training on the Alzheimer’s dataset (i.e., the target
domain). The experimental results show that the proposed
approach achieves the highest accuracy for the multi-class
classiﬁcation problem (i.e, Alzheimer’s stage detection).
Similarly, Shin et al. ﬁnetuned the pre-trained deep
neural network for solving the computer-aided detection
problems . Byra et al. utilized the transfer learning technology to help assess knee osteoarthritis . In addition to
imaging analysis, transfer learning has some other applications in the medical area. For example, the work by Tang et
al. combines the active learning and the domain adaptation
technologies for the classiﬁcation of various medical data
 . Zeng et al. utilized transfer learning for automatically
encoding ICD-9 codes that are used to describe a patient’s
diagnosis .
Bioinformatics Application
Biological sequence analysis is an important task in the
bioinformatics area. Since the understanding of some organisms can be transferred to other organisms, transfer
learning can be applied to facilitate the biological sequence
analysis. The distribution difference problem exists signiﬁcantly in this application. For example, the function of some
biological substances may remain unchanged but with the
composition changed between two organisms, which may
result in the marginal distribution difference. Besides, if
two organisms have a common ancestor but with long evolutionary distance, the conditional distribution difference
would be signiﬁcant. The work by Schweikert et al. uses
the mRNA splice site prediction problem as the example
to analyze the effectiveness of transfer learning approaches
 . In their experiments, the source domain contains the
sequence instances from a well-studied model organism, i.e.,
C. elegans, and the target organisms include two additional
nematodes (i.e., C. remanei and P. paciﬁcus), D. melanogaster,
and the plant A. thaliana. A number of transfer learning
approaches, e.g., FAM and the variant of KMM , are
compared with each other. The experimental results show
that transfer learning can help improve the classiﬁcation
performance.
Another widely encountered task in the bioinformatics
area is gene expression analysis, e.g., predicting associations
between genes and phenotypes. In this application, one
of the main challenges is the data sparsity problem, since
there is usually very little data of the known associations.
Transfer learning can be used to leverage this problem
by providing additional information and knowledge. For
example, Petegrosso et al. proposed a transfer learning approach to analyze and predict the gene-phenotype
associations based on the Label Propagation Algorithm
(LPA) . LPA utilizes the Protein-Protein Interaction
(PPI) network and the initial labeling to predict the target
associations based on the assumption that the genes that are
connected in the PPI network should have the similar labels.
The authors extended LPA by incorporating multi-task and
transfer-learning technologies. First, Human Phenotype Ontology (HPO), which provides a standardized vocabulary
of phenotypic features of human diseases, is utilized to
form the auxiliary task. In this way, the associations can be
predicted by utilizing phenotype paths and both the linkage
knowledge in HPO and in the PPI network; the interacted
genes in PPI are more likely to be associated with the same
phenotype and the connected phenotypes in HPO are more
likely to be associated with the same gene. Second, Gene
Ontology (GO), which contains the association information
between gene functions and genes, is used as the source
domain. Additional regularizers are designed, and the PPI
network and the common genes are used as the bridge
for knowledge transfer. The gene-GO term and gene-HPO
phenotype associations are constructed simultaneously for
all the genes in the PPI network. By transferring additional
knowledge, the predicted gene-phenotype associations can
be more reliable.
Transfer learning can also be applied to solving the PPI
prediction problems. Xu et al. proposed an approach
to transfer the linkage knowledge from the source PPI
network to the target one. The proposed approach is based
on the collective matrix factorization technique , where
a factor matrix is shared across domains.
Transportation Application
One application of transfer learning in the transportation
area is to understand the trafﬁc scene images. In this application, a challenge problem is that the images taken from a certain location often suffer from variations because of different
weather and light conditions. In order to solve this problem,
Di et al. proposed an approach that attempts to transfer the
information of the images that were taken from the same
location in different conditions . In the ﬁrst step, a pretrained network is ﬁnetuned to extract the feature representations of images. In the second step, the feature transformation strategy is adopted to construct a new feature representation. Speciﬁcally, the dimension reduction algorithm
(i.e., partial least squares regression ) is performed on
the extracted features to generate low-dimension features.
Then, a transformation matrix is learned to minimize the
domain discrepancy of the dimension-reduced data. Next,
the subspace alignment operations are adopted to further
reduce the domain discrepancy. Note that, although images
under different conditions often have different appearances,
they often have the similar layout structure. Therefore, in
the ﬁnal step, the cross-domain dense correspondences are
established between the test image and the retrieved best
matching image at ﬁrst, and then the annotations of the best
matching image are transferred to the test image via the
Markov random ﬁeld model , .
Transfer learning can also be applied to the task of driver
behavior modeling. In this task, sufﬁcient personalized data
of each individual driver are usually unavailable. In such
situations, transferring the knowledge contained in the historical data for the newly-involved driver is a promising
alternative. For example, Lu et al. proposed an approach to
driver model adaptation in lane-changing scenarios .
The source domain contains the sufﬁcient data describing
the behavior of the source drivers, while the target domain
has a few numbers of data about the target driver. In the
ﬁrst step, the data from both domains are pre-processed
by performing PCA to generate low-dimension features.
The authors assume that the source and the target data
are from two manifolds. Therefore, in the second step, a
manifold alignment approach is adopted for domain adaptation. Speciﬁcally, the dynamic time warping algorithm
 is applied to measuring similarity and ﬁnding the
corresponding source-domain data point of each targetdomain data point. Then, local Procrustes analysis is
adopted to align the two manifolds based on the obtained
correspondences between data points. In this way, the data
from the source domain can be transferred to the target
domain. And in the ﬁnal step, a stochastic modeling method
(e.g., Gaussian mixture regression ) is used to model
the behavior of the target driver. The experimental results
demonstrate that the transfer learning approach can help
the target driver even when few target-domain data are
available. Besides, the results also show that when the
number of target instances are very small or very large,
the superiority of their approach is not obvious. This may
because the relationship across domains cannot be found
exactly with few target-domain instances, and in the case of
sufﬁcient target-domain instances, the necessity of transfer
learning is reduced.
Besides, there are some other applications of transfer
learning in the transportation area. For example, Liu et al.
applied transfer learning to driver poses recognition .
Wang et al. adopted the regularization technique in transfer
learning for vehicle type recognition . Transfer learning
can also be utilized for anomalous activity detection ,
 , trafﬁc sign recognition , etc.
Recommender-System Application
Due to the rapid increase of the amount of information,
how to effectively recommend the personalized content
for individual users is an important issue. In the ﬁeld of
recommender systems, some traditional recommendation
methods, e.g., factorization-based collaborative ﬁltering, often rely on the factorization of the user-item interaction
matrix to obtain the predictive function. These methods
often require a large amount of training data to make
accurate recommendations. However, the necessary training
data, e.g., the historical interaction data, are often sparse
in real-world scenarios. Besides, for new registered users
or new items, traditional methods are often hard to make
effective recommendations, which is also known as the coldstart problem.
Recognizing the above-mentioned problems in recommender systems, kinds of transfer learning approaches, e.g.,
instance-based and feature-based approaches, have been
proposed. These approaches attempt to make use of the
data from other recommender systems (i.e., the source
domains) to help construct the recommender system in
the target domain. Instance-based approaches mainly focus
on transferring different types of instances, e.g., ratings,
feedbacks, and examinations, from the source domain to
the target domain. The work by Pan et al. leverages
the uncertain ratings (represented as rating distributions) of
the source domain for knowledge transfer. Speciﬁcally, the
source-domain uncertain ratings are used as constraints to
help complete the rating matrix factorization task on the
target domain. Hu et al. proposed an approach termed
transfer meeting hybrid, which extracts the knowledge from
unstructured text by using an attentive memory network
and selectively transfer the useful information.
Feature-based approaches often leverage and transfer
the information from a latent feature space. For example,
Pan et al. proposed an approach termed Coordinate System
Transfer (CST) to leverage both the user-side and the
item-side latent features. The source-domain instances come
from another recommender system, sharing common users
and items with the target domain. CST is developed based
on the assumption that the principle coordinates, which
reﬂect the tastes of users or the factors of items, characterize the domain-independent structure and are transferable
across domains. CST ﬁrst constructs two principle coordinate systems, which are actually the latent features of users
and items, by applying sparse matrix tri-factorization on
the source-domain data, and then transfer the coordinate
systems to the target domain by setting them as constraints.
The experimental results show that CST signiﬁcantly outperforms the non-transfer baselines (i.e., average ﬁlling
model and latent factorization model) in all data sparsity
levels .
There are some other studies about cross-domain recommendation , , , . For example, He et
al. proposed a transfer learning framework based on the
Bayesian neural network . Zhu et al. proposed a
deep framework, which ﬁrst generates the user and item
feature representations based on the matrix factorization
technique, and then employs a deep neural network to learn
the mapping of features across domains. Yuan et al. 
proposed a deep domain adaptation approach based on
autoencoders and a modiﬁed DANN , to extract
and transfer the instances from rating matrices.
Other Applications
Communication Application: In addition to WiFi localization tasks , , transfer learning has also been employed
in wireless-network applications. For example, Bastug et
al. proposed a caching mechanism ; the knowledge
contained in contextual information, which is extracted from
the interactions between devices, is transferred to the target
domain. Besides, some studies focus on the energy saving
problems. The work by Li et al. proposes an energy saving
scheme for cellular radio access networks, which utilizes
the transfer-learning expertise . The work by Zhao and
Grace applies transfer learning to topology management for
reducing energy consumption .
Urban-Computing Application: With a large amount of
data related to our cities, urban-computing is a promising researching track in directions of trafﬁc monitoring,
health care, social security, etc. Transfer learning has been
applied to alleviate the data scarcity problem in many
urban computing applications. For example, Guo et al. 
proposed an approach for chain store site recommendation,
which leverages the knowledge from semantically-relevant
domains (e.g., other cities with the same store and other
chain stores in the target city) to the target city. Wei et
al. proposed a ﬂexible multi-modal transfer learning
approach that transfers knowledge from a city that have
sufﬁcient multi-model data and labels to the target city to
alleviate the data sparsity problem.
Transfer learning has been applied to some recognition
tasks such as hand gesture recognition , face recognition , activity recognition , and speech emotion
recognition . Besides, transfer-learning expertise has
also been incorporated into some other areas such as sentiment analysis , , , fraud detection , social
network , and hyperspectral image analysis , .
EXPERIMENT
Transfer learning techniques have been successfully applied
in many real-world applications. In this section, we perform
experiments to evaluate the performance of some representative transfer learning models1 of different categories
on two mainstream research areas, i.e., object recognition
and text classiﬁcation. The datasets are introduced at ﬁrst.
Then, the experimental results and further analyses are
Dataset and Preprocessing
Three datasets are studied in the experiments, i.e., Ofﬁce-
31, Reuters-21578, and Amazon Reviews. For simplicity, we
focus on the classiﬁcation tasks. The statistical information
of the preprocessed datasets is listed in Table 3.
• Amazon Reviews2 is a multi-domain sentiment
dataset which contains product reviews taken from Amazon.com of four domains (Books, Kitchen, Electronics and
DVDs). Each review in the four domains has a text and a
rating from zero to ﬁve. In the experiments, the ratios that
are less than three are deﬁned as the negative ones, while
others are deﬁned as the positive ones. The frequency
of each word in all reviews is calculated. Then, the ﬁve
thousand words with the highest frequency are selected
as the attributes of each review. In this way, we ﬁnally
have 1000 positive instances, 1000 negative instances, and
about 5000 unlabeled instances in each domain. In the
experiments, every two of the four domains are selected
to generate twelve tasks.
• Reuters-215783 is a dataset for text categorization, which
has a hierarchical structure. The dataset contains 5 top
categories (Exchanges, Orgs, People, Places, Topics). In
out experiment, we use the top three big category Orgs,
People and Places to generate three classiﬁcation tasks
(Orgs vs People, Orgs vs Places and People vs Places).
In each task, the subcategories in the corresponding two
categories are separately divided into two parts. Then, the
resultant four parts are used as the components to form
two domains. Each domain has about 1000 instances, and
each instance has about 4500 features. Speciﬁcally, taking
the task Orgs vs People as an example, one part from
Orgs and one part from People and combined to form the
source domain; similarly, the rest two parts form the target
domain. Note that the instances in the three categories are
all labeled. In order to generate the unlabeled instances,
the labeled instances are selected from the dataset, and
their labels are ignored.
• Ofﬁce-31 is an object recognition dataset which
contains thirty-one categories and three domains, i.e.,
Amazon, Webcam, and DSLR. These three domains have
2817, 498, and 795 instances, respectively. The images
in Amazon are the online e-commerce pictures taken
from Amazon.com. The images in Webcam are the lowresolution pictures taken by web cameras. And the images in DSLR are the high-resolution pictures taken by
DSLR cameras. In the experiments, every two of the three
domains (with the order considered) are selected as the
source and the target domains, which results in six tasks.
1. 
2. mdredze/datasets/sentiment/
3. 
21578+Text+Categorization+Collection
Fig. 5. Comparison results on Amazon Reviews.
Experiment Setting
Experiments are conducted to compare some representative
transfer learning models. Speciﬁcally, eight algorithms are
performed on the dataset Ofﬁce-31 for solving the object
recognition problem. Besides, fourteen algorithms are performed and evaluated on the dataset Reuters-21578 for
solving the text classiﬁcation problem. In the sentiment
classiﬁcation problem, eleven algorithms are performed on
Amazon Reviews. The classiﬁcation results are evaluated by
accuracy, which is deﬁned as follows:
accuracy = |{x|xi ∈Dtest ∧f(xi) = yi}|
where Dtest denotes the test data and y denotes the truth
classiﬁcation label; f(x) represents the predicted classiﬁcation result. Note that some algorithms need the base classi-
ﬁer. In these cases, an SVM with a linear kernel is adopted
as the base classiﬁer in the experiments. Besides, the sourcedomain instances are all labeled. And for the performed algorithms (except TrAdaBoost), the target-domain instances
are unlabeled. Each algorithm was executed three times, and
the average results are adopted as our experimental results.
The evaluated transfer learning models include: HIDC
 , TriTL , CD-PLSA , , MTrick , SFA
 , mSLDA , , SDA , GFK , SCL , TCA
 , , CoCC , JDA , TrAdaBoost , DAN ,
DCORAL , MRAN , CDAN , DANN ,
 , JAN , and CAN .
Experiment Result
In this subsection, we compare over twenty algorithms on
three datasets in total. The parameters of all algorithms
are set to the default values or the recommended values
mentioned in the original papers. The experimental results
are presented in Tables 4, 5, and 6 corresponding to Amazon
Reviews, Reuters-21578, and Ofﬁce-31, respectively. In order
to allow readers to understand the experimental results
more intuitively, three radar maps, i.e., Figs. 5, 6, and 7, are
provided, which visualize the experimental results. In the
radar maps, each direction represents a task. The general
performance of an algorithm is demonstrated by a polygon
Statistical information of the preprocessed datasets.
Total Instances
Sentiment Classiﬁcation
Amazon Reviews
Text Classiﬁcation
Reuters-21578
Object Recognition
Orgs vs Places
People vs Places
Orgs vs People
Orgs vs Places
People vs Places
Orgs vs People
TrAdaBoost
Fig. 6. Comparison results on Reuters-21578.
Accuracy performance on the Amazon Reviews of four domains: Kitchen (K), Electronics (E), DVDs (D) and Books (B).
whose vertices representing the accuracy of the algorithm
for dealing with different tasks.
Table 4 shows the experimental results on Amazon Reviews. The baseline is a linear classiﬁer trained only on
the source domain (here we directly use the results from
the paper ). Fig. 5 visualizes the results. As shown in
Fig. 5, most algorithms are relatively well-performed when
the source domain is electronics or kitchen, which indicates
that these two domains may contains more transferable
information than the other two domains. In addition, it can
be observed that HIDC, SCL, SFA, MTrick and SDA perform
well and relatively stable in all the twelve tasks. Meanwhile,
other algorithms, especially mSLDA, CD-PLSA, and TriTL,
are relatively unstable; the performance of them ﬂuctuates
in a range about twenty percent. TriTL has a relatively
high accuracy on the tasks where the source domain is
kitchen, but has a relatively low accuracy on other tasks.
The algorithms TCA, mSLDA, and CD-PLSA have similar
performance on all the tasks with an accuracy about seventy
percent on average. Among the well-performed algorithms,
HIDC and MTrick are based on feature reduction (feature
clustering), while the others are based on feature encoding
(SDA), feature alignment (SFA), and feature selection (SCL).
Those strategies are currently the mainstreams of featurebased transfer learning.
Table 5 presents the comparison results on Reuter-21578
(here we directly use the results of the baseline and CoCC
from papers and ). The baseline is a regularized least
square regression model trained only on the labeled target
domain instances . Fig. 6, which has the same structure
of Fig. 5, visualizes the performance. For clarity, thirteen
algorithms are divided into two parts that correspond to
the two subﬁgures in Fig. 6. It can be observed that most
algorithms are relatively well-performed for Orgs vs Places
Fig. 7. Comparison results on Ofﬁce-31.
Accuracy performance on the Reuters-21578 of three domains: Orgs,
People, and Places.
Orgs vs Places People vs Places Orgs vs People Average
TrAdaBoost
Accuracy performance on Ofﬁce-31 of three domains: Amazon (A),
Webcam (W), and DSLR (D).
A →W D→W W→D A→D D →A W→A Average
and Orgs vs People, but poor for People vs Places. This phenomenon indicates that the discrepancy between People and
Places may be relatively large. TrAdaBoost has a relatively
good performance in this experiment because it uses the
labels of the instances in the target domain to reduce the
impact of the distribution difference. Besides, the algorithms
HIDC, SFA, and MTrick have relatively consistent performance in the three tasks. These algorithms are also wellperformed in the previous experiment on Amazon Reviews.
In addition, the top two well-performed algorithms in terms
of People vs Places are CoCC and TrAdaBoost.
In the third experiment, seven deep-learning-based
transfer learning models (i.e., DAN, DCORAL, MRAN,
CDAN, DANN, JAN, and CAN) and the baseline (i.e., the
Alexnet , pre-trained on ImageNet and then
directly trained on the target domain) are performed on the
dataset Ofﬁce-31 (here we directly use the results of CDAN,
JAN, CAN, and the baseline from the original papers ,
 , , ). The ResNet-50 is used as the backbone network for all these three models. The experimental
results are provided in Table 6 and the average performance
is visualized in Fig. 7. As shown in Fig. 7, all of these
seven algorithms have excellent performance, especially on
the tasks D →W and W →D, whose accuracy is very
close to one hundred percent. This phenomenon reﬂects the
superiority of the deep-learning based approaches, and is
consistent with the fact that the difference between Webcam
and DSLR is smaller than that between Webcam/DSLR
and Amazon. Clearly, CAN outperforms the other six algorithms. In all the six tasks, the performance of DANN is
similar to that of DAN, and is better than that of DCORAL,
which indicates the effectiveness and the practicability of
incorporating adversarial learning.
It is worth mentioning that, in the above experiments,
the performance of some algorithms is not ideal. One reason
is that we use the default parameter settings provided in the
algorithms’ original papers, which may not be suitable for
the dataset we selected. For example, GFK was originally
designed for object recognition, and we directly adopt it
into text classiﬁcation in the ﬁrst experiment, which turns
out to produce an unsatisfactory result (having about sixtytwo percent accuracy on average). The above experimental
results are just for reference. These results demonstrate that
some algorithms may not be suitable for the datasets of
certain domains. Therefore, it is important to choose the
appropriate algorithms as the baselines in the process of research. Besides, in practical applications, it is also necessary
to ﬁnd a suitable algorithm.
CONCLUSION AND FUTURE DIRECTION
In this survey paper, we have summarized the mechanisms
and the strategies of transfer learning from the perspectives
of data and model. The survey gives the clear deﬁnitions
about transfer learning and manages to use a uniﬁed symbol system to describe a large number of representative
transfer learning approaches and related works. We have
basically introduced the objectives and strategies in transfer
learning based on data-based interpretation and modelbased interpretation. Data-based interpretation introduces
the objectives, the strategies, and some transfer learning
approaches from the data perspective. Similarly, modelbased interpretation introduces the mechanisms and the
strategies of transfer learning but from the model level.
The applications of transfer learning have also been introduced. At last, experiments have been conducted to evaluate
the performance of representative transfer learning models
on two mainstream area, i.e., object recognition and text
categorization. The comparisons of the models have also
been given, which reﬂects that the selection of the transfer
learning model is an important research topic as well as a
complex issue in practical applications.
Several directions are available for future research in
the transfer learning area. First, transfer learning techniques
can be further explored and applied to a wider range of
applications. And new approaches are needed to solve the
knowledge transfer problems in more complex scenarios.
For example, in real-world scenarios, sometimes the userrelevant source-domain data comes from another company.
In this case, how to transfer the knowledge contained in the
source domain while protecting user privacy is an important
issue. Second, how to measure the transferability across domains and avoid negative transfer is also an important issue.
Although there have been some studies on negative transfer,
negative transfer still needs further systematic analyses .
Third, the interpretability of transfer learning also needs
to be investigated further . Finally, theoretical studies
can be further conducted to provide theoretical support for
the effectiveness and applicability of transfer learning. As
a popular and promising area in machine learning, transfer
learning shows some advantages over traditional machine
learning such as less data dependency and less label dependency. We hope our work can help readers have a better
understanding of the research status and the research ideas.
ACKNOWLEDGMENTS
The research work is supported by the National Key Research and Development Program of China under Grant No.
2018YFB1004300, the National Natural Science Foundation
of China under Grant No. U1836206, U1811461, 61773361,
61836013, and the Project of Youth Innovation Promotion
Association CAS under Grant No. 2017146.