Parametrized Shape Models for Clothing
Stephen Miller, Mario Fritz, Trevor Darrell, Pieter Abbeel
Abstract— We consider the problem of recognizing the con-
ﬁguration of clothing articles when crudely spread out on a
ﬂat surface, prior to and during folding. At the core of our
approach are parametrized shape models for clothing articles.
Each clothing category has its own shape model, and the variety
in shapes for a given category is achieved through variation of
the parameters. We present an efﬁcient algorithm to ﬁnd the
parameters that provide the best ﬁt when given an image of a
clothing article. The models are such that, once the parameters
have been ﬁt, they provide a basic parse of the clothing article,
allowing it to be followed by autonomous folding from category
level speciﬁcations of fold sequences. Our approach is also able
to recover the conﬁguration of a clothing article when folds are
being introduced—an important feature towards closing the
perception-action loop. Additionally, our approach provides a
reliable method of shape-based classiﬁcation, simply by examining which model yields the best ﬁt. Our experiments illustrate
the effectiveness of our approach on a large set of clothing
articles. Furthermore, we present an end-to-end system, which
starts from an unknown spread-out clothing article, performs
a parametrized model ﬁt, then follows a category-level (rather
than article speciﬁc) set of folding instructions, closing the loop
with perceptual feedback by re-ﬁtting between folds.
I. INTRODUCTION
Robotic manipulation abilities are still rather limited in
comparison to human manipulation abilities. This is largely
due to the limited perceptual understanding current algorithms are able to provide. The problem of perception is particularly challenging when considering deformable objects,
as they have very high dimensional conﬁguration spaces.
The perceptual challenges involved in the manipulation
of deformable objects are greatly reﬂected in the state of
the art in robotic automation of laundry folding. Indeed, the
current state of the art is far from enabling general purpose
manipulators to fully automate such a task.
One of the critical challenges in automating laundry folding is the ability to recognize the conﬁguration of a crudely
spread out, previously unseen clothing article. For example,
when faced with a new t-shirt, one would like for a robot
to be able to “understand” the t-shirt’s conﬁguration to the
extent of recognizing where the sleeves are, where the main
body is, how long the sleeves are, where the collar is, and
so forth. If the robot is able to acquire such a parametrized
shape representation, then it can proceed to, for example,
fold in the sleeves, or fold along “vertical” lines running
next to the collar. Moreover one would like the robot to be
able to continue to track the conﬁguration after folds have
been executed, thus enabling it to close the perception-action
University
California
{sdmiller,mfritz,trevor,pabbeel} @eecs.berkeley.edu.
In this paper, we propose parametrized shape models for
clothing categories and algorithms that enable automatic
ﬁtting of those parameters to new instances. Concretely, we
consider clothing articles that either (i) are crudely spread
out on a ﬂat surface, as might result from an initial handling
procedure which tries to maximally spread a clothing article;
or (ii) were crudely spread out initially, and have since
undergone folding manipulations.
We describe an efﬁcient algorithm to ﬁt the parameters of
our models to a new clothing instance. Our algorithm starts
by optimizing over coarse parameters, such as the position,
orientation, and scale of the article, and then gradually
introduces more detailed parameters into the model, such
as sleeve length, width, and angle. Our experiments show
our approach to be highly reliable in both determining the
category of an instance, and ﬁtting the proper model to that
We further illustrate the effectiveness of our algorithm
through implementation of an end-to-end folding system on
the Willow Garage PR2 robot. For each clothing category we
specify a parametrized folding sequence—which is deﬁned
relative to the parametrized shape model. We present the
robot with fairly spread out clothing articles. The robot ﬁts
the shape model parameters, and then executes the folds. In
between folds, the robot re-ﬁts the shape model, which then
includes additional parameters to capture the fold lines—
providing the robot feedback about the accuracy of the folds
and where to grasp next.
II. RELATED WORK
The estimation of clothing conﬁguration is a relatively new
problem, and has received scant attention in the literature.
Clothing forms follow the structure of the human body, and
thus are an instance of an articulated pose estimation task.
Classic articulated pose estimation methods iteratively ﬁt or
track an articulated model, updating the pose of individual
part segments subject to the overall body constraints. Early
methods were based on optic ﬂow and linearized exponential
map-based constraints ; subsequent approaches developed
efﬁcient sampling methods , exemplar methods , regression strategies , and subspace optimization methods
 . An early approach used an energy-optimization strategy
to match edge points between two images . Related
models for fully non-rigid shape modeling and estimation are
typically based on a learned manifold, e.g., active appearance
models . Few methods investigate clothing explicitly.
Notable exceptions to this is the recent work of , which
expands the SCAPE manifold-based model to include
a model of 3-D clothing forms, person tracking systems
2011 IEEE International Conference on Robotics and Automation
Shanghai International Conference Center
May 9-13, 2011, Shanghai, China
U.S. Government work not protected by U.S.
(a) A parametrized shape model for a t-shirt. Red indicates a skeletal parameter, blue indicates a landmark point. (b) An example instance. (c)
The result from running our approach: our model (pink) is overlayed onto the image of the clothing it is trying to ﬁt. The determined landmark points are
shown as white dots. (d) An example of a parametrized speciﬁcation of a folding sequence. All fold-lines shown are deﬁned relative to the parametrized
shape model. (e) Result from running our approach when a fold line is present.
which attempt to account for clothing variation , and
methods for estimating folds in deformable surfaces .
In this work we adopt a much simpler model, and propose
schemes for direct optimization of speciﬁc shape forms that
can be directly related to ensuing manipulation; we expect
our method to become even more robust when the above
statistical shape and observation model methods are applied
to our approach, but the results with classic methods prove
to be signiﬁcant as shown below.
From the application angle, the prior work on robotic
laundry manipulation and folding is most closely related to
our work. The current state of the art is still far removed
from having a generic robot perform end-to-end laundry, but
progress has been made on various aspects.
Paraschidis and collaborators describe the isolated
executions of grasping a layed-out material, folding a layedout material, laying out a piece of material that was already
being held, and ﬂattening wrinkles. Their perception system
relies on a library of exact, polygonal shape models of
the instances considered and then matches the sequence of
extracted edges.
There is a body of work on recognizing categories of
clothing. For example, Osawa and collaborators and
Hamajima and Kakikura present approaches to spread out
a piece of clothing using two robot arms and then classify
its category.
Yamakazi and Inaba present an algorithm that recognizes wrinkles in images, which in turn enables them to
detect clothes laying around. Kobori and collaborators 
have extended this work towards ﬂattening and spreading
clothing. Kita and collaborators ﬁt the geometry of the
silhouette of a hanging piece of clothing to the geometry
of a mass spring model of the same piece of clothing and
are able to infer some 3-D information about the piece of
clothing merely from the silhouette.
Our earlier work focused on perception algorithms for
detection of the vertices of towels. It enabled folding starting
from a crumpled towel.
Some of the prior work describes robots using tools and
the design of special purpose end-effectors as a step towards
laundry folding. For example, Osawa and collaborators 
developed a robot capable of using a “ﬂip-fold” for folding
and a plate for straightening out wrinkles. Salleh and collaborators present an inchworm gripper for tracing the
edge of a piece of clothing. A range of gripper designs is
presented by Monkman. .
In the more general context of folding, the work of
Balkcom and Mason stands out, having developed a
robot that can perform origami.
III. OVERVIEW
Our aim is to describe an arbitrarily complex article of
clothing by a simpler, parametrized model. We consider
parametrized models with which we can naturally associate
a polygon. This polygon can then be used to perform
intelligent manipulation of the clothing article.
The main components of our approach are:
• Parametrized shape models for clothing categories. For
each category of clothing, we attempt to ﬁnd the
minimal set of parameters that can describe its range
of shapes. Every (legal) setting of the parameters de-
ﬁnes a polygonal description of the shape. We call
the vertices of this polygonal description the landmark
points of the shape. To further guide the optimization
and preclude nonsensical results from consideration, we
impose legality constraints on the parameters. Fig. 1 (a)
shows a parametrized shape model for t-shirts as well
as the polygon associated with this particular model
instantiation.
• When presented with a previously unseen clothing article, we optimize over the parameters in the relevant
category model to ﬁnd the best ﬁt according to an
energy function which evaluates how well the contour
C of the perceived clothing article matches the contour
of polygons that can be generated by the parametrized
shape model. Fig. 1 (b) shows an example image,
with background and perspective effects automatically
removed. Fig. 1 (c) shows the best ﬁt of the t-shirt model
to the image as obtained by our algorithm.
• We use the resulting ﬁt polygon as input to a categorylevel parametrized folding sequence, by which the robot
is able to systematically fold the article. Fig. 1 (d) shows
an example of a parametrized folding speciﬁcation for
t-shirts. See previous work for details. 
• After completion of each fold, our approach augments
the parametrized shape model to include the location
of a fold line. It then ﬁts this augmented set of parameters to provide feedback during the folding process.
Fig. 1 (e) shows an example result.
IV. PARAMETRIZED SHAPE MODELS
We deﬁne a model M by the following components:
• A landmark generator
MLG : {P ∈Rp} →{L ∈R2×ℓ}
which takes a parameter vector P as input, and returns
the associated collection of landmark points, L.
• A contour generator
MCG : {P ∈Rp} →{C ∈R2×c}
which takes a set of scalar parameters P as input, and
returns the contour of the polygon which would arise
from the given parameters, with a ﬁxed number of
samples per side. The number of contour points c is
chosen to be much larger than the number of landmark
• A legal input set
which deﬁne set of parameters over which M is said to
be in a legal conﬁguration
• A transformation operator
MT : {P ∈Rp,T ∈R2,θ ∈R,s ∈R} →{P′ ∈Rp}
which transforms a set of parameters in such a way that
the resultant contour MCG will be translated, rotated, and
scaled by the given values of T, θ, and s.
A. Skeletal models
To capture the structure of the clothing we parametrize
a model about a set of interior (or skeletal) points, as
well as features which detail the distance from the interior
points to the contour. These may include landmark vertices,
displacements between a skeletal vertex and its nearest edge,
or scalars such as height and width.
Fig. 1 (a) shows an example skeletal model for a t-shirt;
a more detailed list of the parameters is shown in Fig. 4.
The parameters are highlighted in red, and the landmark
points are highlighted in blue. A red point with a blue outline
indicates a landmark point which is itself a parameter. The
generated contour is outlined in black. The legal input set is
detailed in Section VIII-A.3.
B. Folded Models
Once the pose of the spread-out cloth has been determined,
we wish to visually track the progress and accuracy of our
folding procedure. With an initial model M0 and associated
parameters P0, we associate a folded model such that:
Lfolded ≡R4 ×L0
where all parameters of the original model are allowed to
vary, and in addition, the parameters Θ specify a line about
which the model is to be folded. The resulting landmark
points are computed by folding the polygon speciﬁed by
M0LG(P0) about this line.1
If we are certain the clothing article did not move during a
folding operation, we may choose to optimize over the foldline, leaving the unfolded portion of the model untouched.
We therefore deﬁne a Static Folded Model, such that
Lfolded ≡R4
V. ENERGY FUNCTION
We now aim to ﬁnd the parameters which optimally ﬁt
a given image. Our approach extracts the contour of the
clothing article in the image and uses an energy function
which favors contour ﬁt. We deﬁne the energy E as follows:
E(P) = (α)× ¯d(MCG(P) →C)+(1−α)× ¯d(C →MCG(P))
where ¯d(A →B) is the average nearest-neighbor distance2
from A to B:
¯d(A →B) ≡1
The parameter α is used to adjust the way in which the
model ﬁts to the contour. If α is too low, the model will
attempt to ﬁt every point of the contour, often overﬁtting
to deviations such as wrinkles. If α is too high, the model
may cease to cover the contour at all, ﬁxating instead on a
single portion. We’ve found that setting α = 0.5 is sufﬁcient
to counter both negative tendencies.
VI. ENERGY OPTIMIZATION
Our energy optimization follows a coarse-to-ﬁne strategy,
in which the parameter space begins small and increases as
the procedure continues. It ﬁrst only considers translation,
rotation and scale, then considers all parameters but enforces
certain symmetry constraints amongst them, and ﬁnally optimizes over all parameters without the symmetry constraints.
A. Initialization
1) PCA Approach: To infer the necessary translation, rotation, and scale, we rely on a Principal Component Analysis
of the observed contour, and contour deﬁned by the model.
We ﬁrst compute the initial model contour as
Mc = MCG(P0).
1In our implementation, the folded model is always initialized with the
proper fold direction – as the direction of a fold will never be accidentally
ﬂipped in any robotic task. While the direction of the fold is speciﬁed by
Θ, it is doubtful that a continuous optimization approach would compensate
for such an error. For those interested in a general approach, we suggest
multiple optimizations: one for each fold direction.
2We additionally considered the use of Dynamic Time Warping , 
in our distance metric. The results, however, showed little improvement,
so for the sake of simplicity and computational efﬁciency, we restrict our
approach to nearest-neighbor.
We then calculate the centers of mass of the observed
contour and the model contour; co and cm respectively.
We then compute the relative translation between the two
T = co −cm.
We then perform PCA to estimate the principal axes of
each contour, denoted ao and am. We compute the relative
angle between the two axes
θ = arccos(ao ·am).
Finally, for each contour we ﬁnd the point of intersection
between the top of the contour and its principal axis, denoted
to and tm. We compute the relative scale between the two
contours as
s = ||to −co||
||tm −cm||,
which is approximately the ratio of the heights of the two
contours. The resultant contour Mc(P) will be centered about
co, and scaled and rotated such that to = tm.3
Having computed these three values, we then update our
model estimate such that
P′ ←MT(P,T,θ,s).
2) Multi-Angle Approach: We additionally consider a
second approach, in which the optimization is run with multiple initializations, attempting all possible rotations within a
granularity of δθ. Upon completion, the ﬁtted model which
yields the lowest energy function is chosen, and all others
are discarded. The method for choosing translation and scale
is the same as in the PCA approach.
B. Optimization
To ensure the best possible ﬁt, our standard approach
performs the optimization in three phases: Orientation, Symmetric, and Asymmetric.
In the Orientation Phase, all parameters are held relatively
ﬁxed, with only one external degree of freedom: θ, which
deﬁnes the net rotation of the contour points about the center
of gravity of the model. This phase is only run when using
the PCA-based initialization, and it tends to improve the
orientation estimate as it considers the entire contour, rather
than just its principal component. When using the multiangle initialization we found it better to skip the orientation
phase as it reduced the variety of orientations explored.
In the Symmetric Phase, the model is free to translate,
rotate, scale or deform within the limits determined by its
legal input set—as long as left-right symmetry is maintained.
In terms of implementation, this is done by optimizing over
a subset of the model parameters – those which describe the
left and center portions of the model – and computing the
implied values for the remaining right parameters such that
symmetry is enforced.
3Thus described, the PCA approach leaves an ambiguity in terms of
which direction is assumed to be “up” on the principal axis. To resolve
this, we attempt both upright and upside-down initializations, and choose
the minimum-cost result after the optimization is complete.
In the Asymmetric Phase, all parameters are optimized
over, and the model is free to translate, rotate, scale, or
deform within the limits determined by its legal input set.
For the numerical optimization, we use coordinate-wise
descent over the parameters—evaluating the gradients numerically (rather than analytically) and maintaining an adaptive step-size for each parameter.
To enforce legality constraints on the parameters, we
augment the energy function with a penalty for constraint
violation. We ﬁrst normalize the ﬁt such that
∀P : 0 ≤Enorm(P) < 1
To do so, we set
As a simple upper bound, Emax is is set to
h2 +w2, where h
and w denote the height and width of the image, respectively.
This corresponds to the case in which the two contours are
maximally distant given the size of the image.
We then deﬁne the structural penalty S as
The resulting energy function is then given by:
C (P) = Enorm(P)+S(P)
As the normalized energy Enorm lies between zero and
one, the optimum of the cost function will never violate a
constraint if a legal alternative exists.
VII. CLASSIFICATION
For any image and speciﬁed model, the above procedure
is able to return a set of ﬁt parameters and an associated
energy. By considering the value of the energy function as
a measure of overall model ﬁt, this provides a convenient
means of category classiﬁcation. When presented with an
image and a set of possible categories, we run the above
procedure multiple times, with one model associated with
each category. The ﬁtted model which results in the lowest
ﬁnal energy is selected, and the image is classiﬁed accordingly.
VIII. EXPERIMENTAL RESULTS
A. Parametrized Models
1) Towels: As there is little inherent structure to a towel,
its Skeletal Model is simply parametrized about the location
of its four vertices. Only one constraint was imposed, which
is common to all of our models:
• The model contour cannot have any self-intersections.
See Fig. 2 for details.
A towel model has 8 total parameters, corresponding to 4 skeletal
points. These are simply the four corners of the towel.
Fig. 3. The pants skeleton is deﬁned by 14 scalar parameters, corresponding
to 6 skeletal points and two scalar values, denoting the width of each pant
leg. The remaining landmark points are generated as follows: the right corner
is an extrapolation of the distance from the left corner to the top center; the
crotch is the top center mirrored about the axis spanning the left and right
joints; the leg corners are determined by the line perpendicular to the leg
axis, at a distance speciﬁed by the leg width.
2) Pants: A Skeletal Model of pants was devised, whose
parameters are shown in Fig. 3.4
We found it was best to give the Pants Model as much
freedom as possible. Therefore, only a small number of constraints were imposed, penalizing extreme deviations from
the norm of:5
• The length of the legs relative to the height of the pants
• The width of the legs relative to the width of the pants
• The width of the pants relative to the height
For the ﬁtting of pants two different initializations were
attempted: the ﬁrst with the legs virtually straight, and the
second with the legs widely spaced. Both models were ﬁt,
and the one with the lowest ﬁnal cost function was chosen.
3) Short-sleeved shirts: A Skeletal Model of short-sleeved
shirts was also used, detailed in Fig. 4
In order to guide the optimization, a number of constraints
were imposed, restricting:
4In all of these models, the preferred representation of parameters was in
Cartesian coordinates. We additionally explored optimizing directly over
angles and lengths. In practice, however, the optimization worked best
when all parameters were aperiodic and similarly scaled. Hence, whenever
possible, a length/angle combination was represented by a 2D point.
5For the precise numerical constraints of all of our models, see the
attached code at 
A short-sleeved shirt skeleton is deﬁned by 24 parameters,
corresponding to 11 skeletal points and 2 scalar parameters for sleeve width.
The remaining landmark points are generated as follows: the right corner
is found by extrapolating the line from the left corner to the spine bottom;
the armpit is determined by extrapolating the line from the shoulder to the
shoulder joint; the sleeve corners are determined by the line perpendicular
to the sleeve axis, at a distance speciﬁed by the sleeve width.
• The location of the collar points with respect to the neck
and shoulders
• The location of the shoulders with respect to the armpits
• The angle between the spine and horizontal axis
• The relative size and angle of the sleeves
• The width-height ratios of the sleeves and torso
Two different initializations were attempted: the ﬁrst with
medium-length sleeves, and the second with extremely short
sleeves. Both models were run, and the one with the lowest
ﬁnal cost function was chosen.
In addition to the Orientation, Symmetric, and Asymmetric
phases of optimization, a fourth Fine Tuning phase was run.
In this phase, the location of all sleeve vertices were free
to move, while the rest remained ﬁxed. This was meant to
account for the irregular shape of many t-shirt sleeves.
4) Long-sleeved shirts and sweaters: The Skeletal Model
for long-sleeved shirts is detailed in Fig. 5
A long-sleeved shirt skeleton is deﬁned by same parameters as the
short sleeved skeleton
This model is virtually identical to the Short-Sleeved
model, with a single constraint added:
• Each sleeve must be at least twice as long as it is wide
Only one initialization was used, with the arms at a
downward angle.
As long-sleeved shirts have the potential for drastic asymmetry, both the Orientation and Symmetric phases of optimization proved to be unuseful, and occasionally damaging
– the former settling on erroneous angles, and the latter on
vastly incorrect poses. In some cases, the error was so great
that the Asymmetric phase could not correct for it. For this
reason, only the Asymmetric phase of optimization was used
on this model.
5) The Polygon Model: To gauge the value of our skeletal approach, we introduce the Polygon Model, which is
parametrized about
This model has no interior structure, and no legality constraints beyond self-intersection. For every clothing category
listed above, we construct a Polygonal Model whose initial
landmark points are identical to those of the Skeletal Model
for that category. This model provides a useful baseline for
the performance of pure contour ﬁtting, beginning with the
same initialization and optimization techniques, but without
taking any prior knowledge about clothing into consideration.
B. Data Collection
To quantitatively gauge the accuracy of our approach,
our shape-ﬁtting code was run on a dataset of roughly 400
images, divided into four categories: towels, pants, shortsleeved shirts, and long-sleeved shirts. For each category,
ten representative articles of clothing were considered. These
varied greatly in size, proportion, and style. Each article was
then further placed in ten or more poses, encompassing a
variety of common spread-out conﬁgurations. (See Fig. 6.)
Each object was initially photographed on a green table.
To ensure rotational invariance, each image was transformed
to a birdseye perspective, using OpenCV’s checkerboard
detector to locate the top-down frame. The background
was then subtracted from each image. For most of these
images, hue thresholding against the green background was
sufﬁcient: however, in cases where the complex texture of the
clothing precluded hue thresholding, the Grabcut algorithm
 was used to perform the subtraction, with foreground
and background pixels manually selected by a user. Finally,
the location of each landmark point was hand-annotated, to
provide ground truth data for the model ﬁtting task. The
pipeline is illustrated in Fig. 7.
C. Implementation Details
We ran our experiments on a Lenovo Thinkpad, running
an Intel Core 2 Extreme Processor. A typical model ﬁt
took roughly 30 seconds; for more complex procedures
such as the four-phase multi-model approach for T-shirts,
convergence would occasionally take up to 2.5 minutes.
To rapidly compute nearest neighbor distances for the cost
function, the Flann library was used. The bulk of the
image processing, including transformations, thresholding,
and contour detection, was done with OpenCV .
The article of clothing is put in various poses.
The dataset pipeline. Top Left: Initially, the clothing is spread out
on a green table. Top Right: A birdseye transformation is then performed.
Bottom Left: The image is cropped, and the background is segmented
out. Bottom Right: To provide ground truth for the ﬁtting procedure, the
resulting image is hand-annotated.
D. Perception Results
Each image was ﬁrst ﬁt to the proper model according to
its known category. The Table in Fig. 8 shows the accuracy
of our approach on the 400 image dataset using both the PCA
and Multi-Angle initializations, and the performance of the
associated Polygon Model on the same set. These results are
represented pictorially in Fig. 9.
Our approach performs very well, obtaining typical accuracies of within 8 pixels per landmark point and signiﬁcantly
outperforming the Polygonal approach, the shortcomings of
which are detailed in Fig. 11.
Moreover, the relative gain of the Skeletal approach on
each category is quite telling. As the Towel Model is effectively structureless, there is no distinction between the
two models, and hence no improvement. In the case of
pants, the proximity between the two legs frequently caused
the Polygonal approach to attract to poor local minima;
whereas the Skeletal approach, with its implicit knowledge
of structure, performed quite well. Short-sleeved-shirts, being
fairly homogeneous in shape, proved extremely difﬁcult for
the Polygonal approach to ﬁt, as can be readily seen in
Fig. 9. Despite the subtlety of shoulder and collar point
locations, the longer sleeves of sweaters tend to sketch
out a very clear polygonal shape; thus the Polygon Model
performed somewhat reasonably, with most errors centered
Polygon Model
Skeletal Model (PCA)
Skeletal Model (Multi-Angle)
14.91±35.97
Short-Sleeved
89.63±44.88
23.30±11.67
Long-Sleeved
14.77±8.27
Results of ﬁtting our Skeletal Models to the dataset. Model Accuracy is measured as the average pixel distance from the predicted landmark point
to the annotated landmark point.
Comparison of individual ladmark point errors. The center of the elipses denotes mean error, and the size and skew their covariance, projected
onto a canonical version of the article. Top: Pointwise error for Skeletal Models using the PCA approach. Bottom: Pointwise error for Polygon Models.
about shoulders, collars, and sleeve edges.
The results of the Multi-Angle approach were extremely
consistent with that of PCA Initialization, suggesting that
the latter approach is sufﬁcient for most purposes. Indeed,
given the inherent ambiguity in landmark location and small
number of examples on which the two differed, any perceived
performance advantage would best be attributed to noise.
We then examined the case of unknown clothing category.
On 100% of test images, our method was able to accurately
classify the clothing category. The classiﬁcation scheme
in Section VII was used to distinguish shirts, pants, and
towels. Thresholding the sleeve length at 35% the shirt width
further dinstinguished all long-sleeved shirts from shortsleeved shirts. Therefore, the correct model is always chosen,
and the performance is identical to the known, tabulated case.
Our approach, however, was not perfect. The location of
collar points proved to be quite ambiguous, and were often
incorrectly identiﬁed. Shoulders, while signiﬁcantly localized
by structural constraints, still proved a source of difﬁculty.
Finally, the initialization was poor on a small number of
instances, and in very rare cases could not be recovered from.
E. Robotic Integration
We implemented our approach on the Willow Garage PR2.
In prior work , we demonstrated an open-loop method
for executing parametrized folds on a clothing article, given
a user-speciﬁed initial polygon. Using the methods detailed
above, we were able to improve this task in two ways:
Fig. 10. Example results of our approach on the four categories of clothing.
Failures of the Polygon Model. Left: Without more detailed
structural information, the model is unable to detect more subtly deﬁned
points, such as the shoulder (detected shoulder points in red). Right: The
unconstrained Polygon approach will generally be attracted to the nearest
edge: a poor initialization can easily ruin it.
• The initial polygon is detected automatically. This is
done by ﬁtting a Skeletal Model to the observed contour
on the table. To avoid grasping virtual points, the
generated landmark points are then relocated to their
nearest neighbor on the observed contour.
• After each fold, the robot re-examines the cloth. It then
ﬁts a Static Folded Model to the new contour, with
parameters Θ seeded by the robot’s intended fold.
The robot ﬁts a model to the initial conﬁguration, then tracks
each fold in the procedure
We found that our perception approach consistenly worked
well and had a number successful end-to-end completions on
categories of clothing. Videos of representative successful
runs as well as software implementations of our algorithm
are available at:
 
Currently the main limiting factors for end-to-end accuracy are the quality of calibration available for the PR2, and
the size of its grippers.
IX. CONCLUSIONS
We examined the problem of recognizing the pose of an
article of clothing in a crudely spread out conﬁguration,
and ﬁnding the best polygonal representation of it. We
proposed a general method for performing such recognition
with the use of parametrized shape models, and presented a
robust optimization strategy for converging upon the proper
parameters. We then detailed particular models for detecting
long-sleeved shirts, short-sleeved shirts, pants, and towels,
and illustrated the success of such models on a large dataset
of test images. Our experiments showed that the resulting
energy can also be used to recognize the clothing category.
We used this approach to close the loop on a previouslyestablished method for the motion planning aspects of laundry folding, implemented on the Willow Garage PR2.
ACKNOWLEDGMENTS
This work was supported in part by NSF under award IIS-
0904672, Willow Garage under the PR2 Beta Program, and
a Feodor Lynen Fellowship granted by the Alexander von
Humboldt Foundation.