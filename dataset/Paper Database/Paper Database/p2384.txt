MATHEMATICS
of computation
VOLUME 56, NUMBER 193
JANUARY 1991, PAGES 141-148
DEGENERATE KERNEL METHOD
FOR HAMMERSTEIN EQUATIONS
HIDEAKI KANEKO AND YUESHENG XU
The classical method of the degenerate kernel method is applied to
numerically solve the Hammerstein equations. Several numerical examples are
given to demonstrate the effectiveness of the current method. A brief discussion
of a number of methods to decompose the kernel is also included.
1. Introduction
This paper is concerned with the problem of finding numerical solutions of
the Hammerstein equation
(1.1) <p(x)- [ k(x,y)w(y,<P(y))dy = f(x), xg ,
where k, f, and y/ are given functions and <p is the solution to be determined.
Several numerical methods for approximating the solution of (1.1) are known.
The classical method of successive approximations was introduced in the 1950's
 . A variation of Nyström's method was presented in . A new collocationtype method was developed in recent papers . In this paper, we employ the
degenerate kernel method, which plays an important role in the study of numerical solutions for the Fredholm integral equations of the second kind. A unified
theory to present various degenerate kernel methods within the framework of
the projection method was recently presented in . In §2 we present the degenerate kernel method and consider the problem of existence and uniqueness of
the solution of the new Hammerstein equation associated with the degenerate
kernel. The problem of convergence of the numerical solution is also considered
in §2. Some examples are considered in §3. In §4 we approximate a given kernel
by several specific degenerate kernels and obtain convergence rates for the corresponding approximate solutions of equation (1.1). The idea of approximating
the kernel by Boolean sums is also included in this section. A comparison of
the performance of the Boolean sum approximation scheme with that of the
tensor product approximation scheme (§3, Example 4) will be given in a future
Received February 13, 1989; revised April 23, 1990.
1980 Mathematics Subject Classification . Primary 65R20, 45G10.
©1991 American Mathematical Society
0025-5718/91 11.00+ $.25 per page
HIDEAKJ KANEKO AND YUESHENG XU
In order to guarantee the existence of a unique solution to equation ( 1.1 ), we
assume throughout this paper that the following conditions (i)-(iv) be satisfied:
(i) k(x,y)GC([0,
(ii) y/(y, u) is continuous in y G[0, X] and zz G (-co, oo), and
\j\v{y,<p{y))\2dy\
<A\\<p\\2,
where || ||2 denotes the L2 norm;
(iii) y/(y,u) satisfies the Lipschitz condition \y/(y, u) - y/(y,v)\ <
B\u - v\ ;
(iv) k is bounded by \k(x, y)\ < C with BC < X .
Under these conditions there exists a unique solution in L2 for equation (1.1). This can be proved by the Banach contraction mapping principle. To
obtain a higher-order convergence rate, we need to assume higher-order smoothness conditions on k.
As the first example in §4 shows, the method of degenerate kernel described in
this paper may be applied to integral equations with multiple solutions. Hence,
conditions (i)-(iv), which guarantee the global uniqueness of the solution, are
perhaps too strong for deciding whether our method is applicable. A reader
interested in a more local property of the solution can find a related discussion
2. Degenerate
Suppose that kn(x, y) is an approximation of the kernel k(x, y), and that
it is of a degenerate kernel form,
kn(x,y) = YJBi(x)Ci(y),
where the set of functions {B^x)} is assumed to be linearly independent.
also assume that
i / / l^(x' y) ~ kn(x, y)\ dxdy\
—» 0 aszz^oo.
It is natural to expect the solutions of the following equation (2.3) associated with the degenerate kernels kn(x, y) to converge to the exact solution of
equation (1.1),
<pn(x)- [ kn(x,y)¥(y,<pn(y))dy
= f(x), xe[0,
To solve equation (2.3), substitute
kn(x, y) into (2.3) and find
(2-4) (pn(x)-j^Bi(x)fci(y)^(y,<pn(y))dy
= f(x), x€ .
degenerate
kernel method
/ Ci(y)y/(y, <pn(y))dy.
Then <p can be expressed as
9„{x) = f{x) + J2aiBi{x),
where the a('s are constants to be determined.
Once the a;'s have been obtained, (2.6) gives the solution of (2.3). Upon substitution of (2.6) into (2.5),
(2.7) aJ = ^Cp)wh,f(y)
+ J2<*iB,(y))dy
forj =X,2, ... ,n
Fj(ax,a2,...,an)=
^Cj(y)y/\y,f(y)
+ J2a¡Bi(y)\ dy .
Then (2.7) becomes a system of nonlinear algebraic equations
or, in vector notation,
Fx(ax, a2, ... ,an)
F2(ax ,a2,
where aT = (a, , a2, ... , aj
and ¥(a)T = (Fx(a),
... , Fn(a)).
We shall show that the unique solution of equation (2.10) corresponds to the
unique solution of equation (2.3) for each zz under some mild assumptions.
Equation (2.10) can be solved by a number of standard numerical methods,
such as Newton's iterative method or modified Newton's iterative method.
Now we consider the existence of a unique solution of (2.3). We recall that
assumptions (i)-(iv) are standing assumptions throughout the rest of this paper.
Theorem 1. Let kn(x, y) G C([0, l]x ) satisfy condition (2.2). Then there
exists an integer N > 0 such that, for each n > N, equation (2.3) has a unique
solution tpn G L2 .
Proof. In view of assumption (iv) and condition (2.2), there exists an integer
N such that for each n > N,
Íí7„''*"<*•'>|!
HIDEAKI KANEKO AND YUESHENG XU
For each n > N, define
Tn<p)(x)= kn(x,y)y/(y,tp(y))dy
(Tncp)(x) = (Tn<p)(x) + f(x).
It is straightforward to verify from (ii) that ||7^ç£)||2 < C4||rp||2 for all <p G
L2[0, X], Hence, Tn is a bounded nonlinear operator. Also, for <px, <p2 G
II Vi - Tn(p2\\2
= II 7>, - 7>2||2
\K^x^y)\1(ixdy
I W(y,(px(y))~w(y,(p2(y))\2dy\
< CB\\tpx - cp2\\2 by (iii) and (iv).
Since 0 < CB < X by assumption, Tn is a contraction operator. It follows
that there is a unique fixed point of Tn , which is of course the unique solution
of equation (2.3), and tpn G L2 . D
Theorem 2. Let
M = Br£J\Bi(x)\2dx\
{¿^V,(x)|2cix|
and assume M < X. Then the nonlinear algebraic equations (2.10) have a
unique solution a* = (a*, a2, ... , a*n), and
<pn(x)=f(x) + Y,a]Bi(x)
is the unique solution of equation (2.3).
Proof. Define, as usual, the discrete l2 norm by \\aWf = {23"=i lQ,|2}1/2 f°r
a = (ax,a2,...,an)T
For a(1) = (a\l) ,\..
||F(a(1))-F(Q(2))||/2<5J¿/ Wxrfdx
||a<"-a(2)||/2.
Consequently, F is a contraction operator in l2(n), since M < X. Hence, F
has a unique fixed point a*, i.e., F(a*) = a*. For this a*, it is obvious that
q>n(x) defined by (2.12) is a solution of (2.3), and by Theorem 1, (pn(x) is the
unique solution of (2.3). o
DEGENERATE KERNEL METHOD
Theorem 3. For
\\K-KJ2 = \^j\k(x,y)-kn(x,y)\2dxdy\
assume that condition (2.2) holds. Then,
||f_fj2<iÄ||j:_j:j2>
||f-fj2<Äji||j:-.*.||2.
Therefore, cpn converges to tp in L2 .
Proof. Since
(p(x)-(pn(x)=
¡ [k(x,y)-kn(x,y)]y/(y,<p(y))dy
/ k (x,y)[y(y,
q>(y))-y/(y,
<pn(y))]dy,
||? - <pj2 < A\\K - Kn\\2\\tp\\2 + CB\\<p - <pn\\2.
By virtue of the condition 0 < CB < 1,
Bf-Mla*ï%ll*-*J2.
The proof of (2.15) is quite similar. Since \\K - K\\2 -* 0 as zz -> oo,
\\<p - q>n\\2 -» 0 as zz -> oo. D
The inequalities (2.14) and (2.15) can be viewed as a priori and a posteriori
estimates, respectively, of the error of the approximate solution.
3. Examples
Example 1. First we substantiate the claim made earlier that uniqueness of the
solution is not necessary for the current method to be applicable. Consider 
xy<p (y)dy = -^x, xg[Q,X).
The actual solutions are q>x(x) = x and tp2(x) = 3x. The kernel function is
already degenerate and we obviously take Bx (x) = x and Cx (y) = y. Upon
substituting
<pn(x) = \x + ax into (2.5), we obtain a - \a + -^ = 0. Solving
this equation, the exact solutions are obtained.
Example 2. Consider
<p(x)- (X+xy)<p (y)dy = ^x-j,
Again, the kernel is degenerate. We take Bx(x) = X and B2(x) = x . The C('s
are chosen in the same way. Upon substituting <Pn = (\x - \) + ax+ a2x into
HIDEAKI KANEKO AND YUESHENG XU
(2.5) and solving the resulting equations, we obtain «1 = 3 and a2 = \ . The
exact solution <p(x) = x is obtained by substituting these values of a, and a2
in the expression <pn above.
Example 3. Consider 
tp(x) - /' exye-vhy)dy = ^-e-—=l,
x G .
The exact solution is <p(x) = ^Jx . We approximate exy by X +xy + (xy)2/2 +
An approximate solution
<pn(x) = y/x-
+ a, + a2x + a^-j= + ■ ■ ■ + a„+1 ^=
is obtained by solving (2.5). For example, for n = 2, we obtain ax = .634038 ,
a2 = .266290, q3 = .114898 . The errors en for different values of zz are listed
below. The en's are approximated by the composite Simpson's formula.
Example 4. Consider the same equation as in Example 3. Now the kernel is
approximated by J2¡=o 12¡=o eX'y'^i(x)Cj(y), where the ß('s and C 's are linear
ß-splines with knots 0 = x0 < xx < ■■ ■ < xr
= X, where xj = i/2n for
i = 0, I , ... , 2" . The approximation
tpn(x) = y/5¿-
+ £ atBt(x)
is obtained upon solving (2.5) and gives rise to errors en shown below.
4. Approximations
of the kernel
The examples in §3 are mainly concerned with the method of approximating
the kernel k(x, y) by degenerate kernels having the form of tensor products of
degenerate kernel method
univariate functions. In this section, we present another approach, a variation
of tensor products, to decompose k(x, y).
Let Lx be a projection of C( x ) onto Xn x C , where Xn
is an zz-dimensional subspace of C . Similarly, let M be a projection of
C([0, l]x ) onto C[0, l]xym,
where Ym is an zw-dimensional subspace
of C . Define
= k(x,y)-Lxk(x,y)
Ryk(x, y) = k(x, y) - Myk(x, y).
Then Lxk and Mvk provide two degenerate kernels that approximate partially k(x, y) with respect to x and y, with respective errors Rxk and Ryk .
Then LxMyk gives a complete approximation of k(x, y) in both x and y,
with error term
R(LxMy)k = Rxk + Ryk - RxRyk .
Thus, the rate of convergence depends on the approximation powers of Lx and
M . In order to enhance the speed of convergence, we define the Boolean sum
of Lx and M by
Lx®My = Lx + My-LxMy.
Then (Lx®My)k
approximates k with the error
R(Lx®My)k = RxRvk.
To see (4.5), we have by the definition of Lx®M
k-(Lx® My)k = (I- Lx)k + (I- My)k -(I-
= Rxk + Ryk - (Rxk + Ryk - RxRyk) = RxRyk .
Thus, this new approximation of k by (Lx ® My)k enhances the rate of
convergence. More specifically, let Xn be the space of spline functions of degree
zz, - 1 with knots at 0 = xQ < x, < • • • < xk < xk +1 = 1, where nx + kx =: n .
Similarly, let Ym be the space of spline functions of degree zrz, - 1 with knots
at 0 = y0 < yx < ■ ■ -yk < yk +x = X, where mx+k2=:
m . Chapters 4 and 12
of are particularly useful in relation to our current discussion.
Let Lx and Mv be the interpolator
operators onto Xn and Ym , respectively. Assuming k G C"'[0, X] x C , we have
sup\Rxk(x,y)\
< \Cx(y)\h"' < Cxh"' , C, a constant,
and similarly, when k G C x C'"' , then
sixo\Ryk(x, y)\ < \C2(x)\hy> < C2hyl, C2 a constant,
where hx = max{x( - xj_x: i = X, 2, ... , kx +X} and hy = ma\{yi-yi_i
X,2,...,k2+X}.
The following theorem is an immediate consequence of the preceding discussion.
HIDEAKI KANEKO AND YUESHENG XU
Theorem 4. (i) Let k G C"' x C , and let <pn be the solution of (23)
with kn(x, y) := Lxk(x, y). Then \\<p - (pn\\2 < Cxh"' .
(ii) Let k G C x Cm' , and let <pm be the solution of (2.3) with
:= Myk(x,y).
Then \\<p - <pj2 < C2h^ .
(iii) Let k G C' x Cm' , and let tpn be the solution of (23) with
kn(x, y) := LxMyk(x, y). Then \\<p - cpn\\2 < C3h"2, where h = ma\{hx, hy}
and n2 = min{zz,, mx} .
(iv) Let k g C"' x Cm' , and let <pn be the solution of (23) with
kn(x,y) = (Lx®My)k(x,y).
Then \\cp - <pj2 < C4h">+m< .
Proof. Proofs of (i)—(iv) of this theorem are quite obvious from the discussion
in this section and Theorem 3. We demonstrate the proof for (iv) only. By
(4.5), (4.6), and (4.7),
\\k-(Lx®My)k\\<C4hxlh^.
By Theorem 3,
h-9j2<f^C4h"x'h^<Cy^,
where C, = ^^.
There exists only a small number of papers which use the Boolean sum approximation technique. These papers are mainly in the area of approximation
of eigenvalues of certain operators (see, e.g., and references cited therein).