Long-Term Prediction of Time Series
by combining Direct and MIMO Strategies
Souhaib Ben Taieb, Gianluca Bontempi, Antti Sorjamaa and Amaury Lendasse
Abstract— Reliable and accurate prediction of time series
over large future horizons has become the new frontier of
the forecasting discipline. Current approaches to long-term
time series forecasting rely either on iterated predictors, direct predictors or, more recently, on the Multi-Input Multi-
Output (MIMO) predictors. The iterated approach suffers from
the accumulation of errors, the Direct strategy makes a conditional independence assumption, which does not necessarily
preserve the stochastic properties of the time series, while the
MIMO technique is limited by the reduced ﬂexibility of the
predictor. The paper compares the Direct and MIMO strategy
and discusses their respective limitations to the problem of longterm time series prediction. It also proposes a new methodology
that is a sort of intermediate way between the Direct and the
MIMO technique. The paper presents the results obtained with
the ESTSP 2007 competition dataset.
I. INTRODUCTION
The prediction of the future behavior of an observed time
series over a long horizon H is still an open problem in
forecasting . Currently, the most common approaches to
long-term forecasting rely either on iterated or direct
prediction techniques .
Given a time series {ϕ1, . . . , ϕt}, in the ﬁrst case, an
H-step-ahead prediction problem is tackled by iterating, H
times, a one-step-ahead predictor. Once the predictor has
estimated the future series value, this value is fed back as
an input to the following prediction. Hence, the predictor
takes as inputs estimated values, instead of actual observations with evident negative consequences in terms of error
propagation. Examples of iterated approaches are recurrent
neural networks or local learning iterated techniques ,
Another way to perform H-step-ahead forecasting consists
in estimating a set of H prediction models, each returning
a direct forecast of ϕt+h with h ∈{1, . . . , H} . Direct
methods often require higher functional complexity than
iterated ones in order to model the stochastic dependency
between two series values at two distant instants.
In computational intelligence literature, we have also examples of research works, where the two approaches have
been successfully combined .
In spite of their diversity, iterated and direct techniques for
multi-step-ahead prediction share a common feature, in the
sense that they model from data, a multi-input single-output
Gianluca Bontempi and Souhaib Ben Taieb are with the Machine Learning Group, Computer Science Department, Faculty of Sciences, Universit´e
Libre de Bruxelles (email: {gbonte, sbentaie}@ulb.ac.be).
Antti Sorjamaa and Amaury Lendasse are with the Department of
Information and Computer Science, Helsinki University of Technology,
Finland (email: {lendasse, Antti.Sorjamaa}@hut.ﬁ).
mapping, whose output is the variable ϕt+1 in the iterated
case and the variable ϕt+h in the direct case.
In , the author proposed a MIMO approach for longterm time series prediction, where the predicted value is
no more a scalar quantity but a vector of future values
{ϕt+1, . . . , ϕt+H} of the time series ϕ. This approach replaces the H models of the Direct approach with one multioutput model, which aims to preserve, between the predicted
values, the stochastic dependency characterizing the time
This paper goes one step further in that direction by
proposing a new methodology for long-term prediction,
aiming to preserve the most appealing aspects of both the
Direct and MIMO approaches. The Direct and the MIMO
approach can be indeed seen as two distinct instances of
the same prediction approach, which decomposes long-term
prediction into multi-output tasks. In the direct case, the
number of prediction tasks is equal to the size of the horizon
H and the size of the outputs is 1. In the MIMO case, the
number of prediction tasks is equal to one and the size of
the output is H. Intermediate conﬁgurations can be imagined
by transforming the original task into n =
s prediction
tasks, each with multiple outputs of size s, where s ∈
{1, . . . , H}. This approach, called Multi-Input Several Multi-
Output (MISMO), trades off the property of preserving the
stochastic dependency between future values with a greater
ﬂexibility of the predictor. For instance, the fact of having
n > 1 allows the selection of different inputs for different
horizons. In other terms, s addresses the bias/variance tradeoff of the predictor by constraining the degree of dependency
between predictions (null in the case s = 1 and maximal for
This paper introduces and assesses the MISMO methodology by implementing each prediction model with a Lazy
Learning model , . Lazy Learning (LL) is a local
modeling technique, which is query-based in the sense that
the whole learning procedure (i.e. structural and parametric
identiﬁcation) is deferred until a prediction is required. ,
 presented a LL algorithm that selects on a queryby-query basis and by means of a local cross-validation
scheme the optimal number of neighbors. Iterated versions of
Lazy Learning were successfully applied to multi-step-ahead
time series prediction , . A LL-MIMO version was
presented in . This paper presents a LL method for the
MISMO prediction of multiple and dependent outputs in the
context of long-term time series prediction.
Section II introduces the new MISMO strategy with respect to existing approaches to long-term prediction. Section III details the MISMO methodology. First, the Lazy
Learning model and the validation procedure is explained.
Next, the way to choose the parameter s of the MISMO
model is presented. Then, the input selection procedure for
the MISMO model is explained. Section IV presents the
MISMO prediction results obtained with a series proposed
by the ESTSP 2007 competition , .
II. LONG-TERM PREDICTION TECHNIQUES
This section ﬁrst introduces the Direct and the MIMO
strategies and then discusses how the original MISMO approach situates with respect to the state of the art.
Let us consider a regular and univariate time series
{ϕ1, ϕ2, . . . , ϕt} for which we intend to predict the continuation for the next H steps. Suppose that we can embed
the time series into an input-output format and that an input
selection strategy is adopted. Suppose also that the maximum
embedding order is d and that the embedding order after the
input selection is m (m ≤d).
A. Direct strategy
The Direct strategy ﬁrst embeds the original series into H
D1 = {(xi1, yi1) ∈(Rm × R)}N
DH = {(xiH, yiH) ∈(Rm × R)}N
{ϕi, . . . , ϕi+d−1},
{ϕi+d−1+h},
h ∈{1, . . . , H}.
and where x·h stands for the subset of inputs returned by the
input selection procedure
Once the time series is embedded, the Direct prediction
strategy learns H direct models fh(·) with
yih = fh(xih) + wih ,
where wih denotes the additive noise.
An attractive property of this method is that it is not prone
to the accumulation of the prediction errors . However,
the conditional independence of the H trained models does
not allow the technique to keep into consideration complex
dependency patterns existing between the variables ϕt+h .
B. MIMO Strategy
In order to remove the conditional independence assumption which is implicit in the Direct approach, a MIMO
strategy was introduced in .
Unlike the Direct strategy, MIMO considers a single
D = {(xi, yi) ∈(Rm × RH)}N
xi ⊂{ϕi, . . . , ϕi+d−1},
yi = {ϕi+d, . . . , ϕi+d+H−1}.
The MIMO strategy estimates a single multi-output model
{yi} = f(xi) + wi,
which returns a vector of H predictions. The MIMO strategy
constrains all the horizons to be predicted with the same
model structure, for instance with the same set of inputs x.
This constraint greatly reduces the ﬂexibility of the prediction
approach and can excessively bias the returned model. This
is not the case of the Direct strategy, where each model is
allowed to use a different set of input variables.
C. MISMO strategy
A solution to the shortcomings of the previously discussed
techniques comes from the adoption of an intermediate
approach, where the constraint of MIMO is relaxed by tuning
an integer parameter s, which calibrates the dimensionality
of the output on the basis of a validation criterion. For a given
s, the training set of the MISMO techniques is composed of
s portions
D1 = {(xi1, yi1) ∈(Rm × Rs)}N
Dn = {(xin, yin) ∈(Rm × Rs)}N
{ϕi, . . . , ϕi+d−1},
{ϕi+d+(p−1)s, . . . , ϕi+d+ps−1}.
and p ∈{1, . . . , n}.
The MISMO technique trains n = H
s models fp(·) with
{yip} = fp(xip) + wip,
where p ∈{1, . . . , n}. We can see that for s = 1, the
approach boils down to the direct approach, while for s = H
we have the MIMO predictor.
For instance, given an 100-steps-ahead prediction task, the
dataset of the MISMO strategy with s = 50 is composed of
D1 = {(xi1, yi1) ∈(Rm × R50)}N
D2 = {(xi2, yi2) ∈(Rm × R50)}N
and the MISMO strategy estimates 2 models, f1 and f2 with
{yi1} = f1(xi1) + wi1,
{yi2} = f2(xi2) + wi2.
Note that, throughout the paper, we assume that the value
of the parameter s is a divisor of H. If it is not the case, it
is sufﬁcient to increase the horizon H of the quantity [s −
(H mod s)] where mod stands for the modulo operation.
III. GLOBAL METHODOLOGY
The general principle underlying the MISMO strategy can
lead to distinct implementations according to the learner used
to estimate the dependencies fp and the procedure adopted
to tune the value of the parameter s. In the following, we
will detail the choices made in this paper in order to design
a long-term predictor to be used in real forecasting tasks.
A. Learning and validation procedure
The estimation of the functions fp in (14) relies on a
nearest neighbor approach, where the problem of adjusting
the size of the neighborhood is solved by a Lazy Learning
strategy , . Lazy Learning algorithms are query-based
local learning algorithms, i.e. they defer the whole learning
process until a speciﬁc query needs to be answered, and once
the prediction is returned, they discard both the answer and
the constructed model .
In this work, we use a multi-output extension of the
Lazy Learning model called LL-MIMO previously discussed
Once we have embedded the time series, the forecasting
problem boils down to n =
multi-input multi-output
supervised learning tasks
D1 = {(xi1, yi1) ∈(Rm × Rs)}N
Dn = {(xin, yin) ∈(Rm × Rs)}N
where H is the horizon of the prediction and s is the size of
the output vectors yip(see equation 11).
Given a query point xq ∈Rm and a metric on the space
Rm, we estimate the n prediction vectors yqp of xq, for each
dataset Dp as follows :
• Given k, the number of neighbors
• Order increasingly the set of vectors {xip}N
respect to the distance to xq
• Denote by [j] the index of the jth closest neighbor
j=1 y[j]p where y[j]p is the output of
the jth closest neighbor of xq in Dp
After the calculation of ˆyqp for each p ∈{1, . . . , n}, the
long term prediction is given by the concatenated vector
(ˆyq1, . . . , ˆyqn).
The adoption of local approach to solve a prediction task
requires the choice of a set of model parameters (e.g. the
number k of neighbors, the kernel function, the distance
metric). In the following, we will present two criteria to
assess and compare local models with different number
of neighbors. The ﬁrst criterion is a multi-ouput extension
of the local Leave-One-Out (LOO) and the second is a
measure of discrepancy between the training series and the
forecasted sequence, which rely either on linear or nonlinear
measures .
A computationally efﬁcient way to perform LOO crossvalidation and to assess the performance in generalization of
local linear models is the PRESS statistic, proposed in 1974
by Allen . By assessing the performance of each local
model, alternative conﬁgurations can be tested and compared
in order to select the best one in terms of expected prediction.
Let D denote a multi-input single-output dataset
D = {(xi, yi) ∈(Rm × R)}N
and suppose we want to estimate the output for a query point
xq ∈Rm. The idea consists of associating a LOO error
eLOO(k) to the estimation
returned by k neighbors. In case of constant model, the
LOO term can be derived as follows :
eLOO(k) = 1
ej(k) = y[j] −
i=1(i̸=j) y[i]
= k y[j] −ˆyk
The optimal number of neighbors is then deﬁned as the
k∗= arg min eLOO(k),
which minimizes the LOO error.
Now, in a multi-input multi-output setting with an output
of size s, where
D = {(xi, yi) ∈(Rm × Rs)}N
we can deﬁne as multi-step LOO error the quantity
ELOO(k) = 1
LOO(k) is the LOO error for the horizon h in (23).
In the following, LL-MIMO-CV will refer to a Lazy Learner
which selects the number of neighbors according to the
multiple LOO assessment. Note that, in a MISMO setting,
there are several datasets Dp and then, an optimal number
of neighbors k∗p has to be found for each dataset Dp.
The second criterion we propose, is not based on crossvalidation but rather on a measure of stochastic discrepancy
between the forecasted sequence and the training time series.
The rationale is that, the lower the discrepancy between
the descriptors of the prediction and the descriptors of the
training series, the better is the quality of the returned
forecast . Suppose, for instance, that we have a training
time series, which behaves like a sine wave and that we want
to predict H = 20 steps ahead. Suppose, that we have to
choose betwen two alternative models (e.g. two LL models
with different number of neighbors) whose predictions (in
bold on the Figures 1(a) and 1(b)) have not signiﬁcantly
different LOO errors. The question is ”which one is the
Time Series
(a) Training series (normal line) and the forecasted sequence (bold line)
Time Series
(b) Training series (normal line) and the forecasted sequence (bold line)
Training series and forecasted sequence of two models, which have
not signiﬁcantly different LOO errors.
best, knowing that they do not have signiﬁcantly different
LOO errors ?”. Intuitively, we would choose for the model
in Figure 1(a) since its predicted continuation has a ”look”
more similar to the training time series. Now, we have to
deﬁne mathematically the term ”look”.
We can deﬁne several measures of discrepancy, both linear
and non-linear . For example, we can use the autocorrelation
or the partial autocorrelation for the linear case and the
likelihood for the non-linear case. In this work, we will
restrict to consider linear measures. Let ϕ denote the training
time series and ˆyk the estimation returned by k neighbors.
The linear discrepancy measure ∆k is
1 −|cor[ρ(ϕ · ˆyk), ρ(ϕ)]|
1 −|cor[π(ϕ · ˆyk), π(ϕ)]|,
where ϕ·ˆyk is the concatenation of the training time series ϕ
and the forecasted sequence ˆyk, ρ(x) is the autocorrelation of
the series x, π(x) is the partial autocorrelation of the series x
and cor[x, y] is the correlation of the series x and the series
So, we can associate to the long-term forecasting ˆyk, a
measure of quality, which is not based on cross-validation
but rather on the preservation of the stochastic properties of
the series. The corresponding selection criterion is then
k∗= arg min ∆k,
which aims to ﬁnd the number of neighbors k for which
the predicted sequence is the closest, in terms of stochastic
properties, to the training series. In the following, LL-
MIMO-D will refer to a LL predictor where the neighbor
selection relies on such criterion.
B. Choice of the parameter s
In the MISMO model (14) the parameter s addresses the
bias/variance trade-off by constraining the degree of dependency between the predictions. The value of this parameter
s is expected to play a major role in the accuracy of the
A possible way to choose the value of this parameter,
is to analyze the performance of the MISMO model for
different values of s on the learning set, and then use the best
value obtained so far, to estimate the outputs. The following
algorithm illustrates a cross-validated strategy to choose a
good value of s.
Algorithm 1: Selection of the parameter s
Input : ϕ = {ϕ1, . . . , ϕt}, the time series
Input : m = Embedding order
Input : H = Horizon
Input : K= Max range of number of neighbors
Output: s∗, best value of the parameter s
for s in {1, . . . , H} do
= {(xi1, yi1) ∈(Rm × Rs)}N
= {(xin, yin) ∈(Rm × Rs)}N
for p in {1, . . . , n} do
= {(xip, yip) ∈(Rd × Rs)}N
learning = vector of size K
for nn in {2, . . . , K} do
learning[nn] ←Learn model
with range {2, . . . , nn}
Elearning(s) = vector of size K
for nn in {2, . . . , K} do
Elearning(s)[nn] ←1
learning[nn]
Error(s) ←1
nn=2 Elearning(s)[nn]
s∗= arg min Error(s)
The ﬁrst loop (line 1) ranges over all the values of the
parameter s. Given a value of the parameter s, the output
y is divided into n = H
s portions (y1, . . . , yn). The second
loop (line 2) processes each portions separately by measuring
the LOO error for a number nn ∈{2, . . . , K} of neighbors.
For a given s, we obtain as a result a vector E(p)
learning of
size K for each ouput yp, p ∈{1, . . . , n}. Now, we average
over p to obtain a vector Elearning(s) of length K whose k
term represents the LOO performance of the MISMO model
with the parameter s and k neighbors.
Several methods could be used to derive a global (i.e.
independent of the number of neighbors) estimate Error(s)
of the MISMO performance for a given s. For instance, we
could take the minimum or the mean value of the vector
Elearning(s).
In this work, we adopt an averaging approach and we
estimate the performance of the MISMO model by taking
the mean value of the vector Elearning(s).
C. Input Selection Procedure
The ﬂexibility of the MISMO approach allows a different
input selection for each of the n prediction tasks.
Input selection , consists of choosing a subset of
(x·1, x·2, . . . , x·d), that has the maximal predictive power
(x·i is the ith variable of the vector x). Each input selection
procedure relies on two elements: a relevance criterion and
a search procedure .
The relevance criterion is a statistical measure of the relevance of the variable selected. Several relevance criteria like
Mutual information, Gamma test,etc have been proposed
in litterature. In this work we adopted as relevance criterion
the 2-fold cross-validation of a 1-NN approximator .
Since in the MIMO technique the size of the output y can
be greater than one, the relevance criterion is adapted for
multiple outputs by taking an average over the prediction
horizon H, as shown in the following pseudo-code.
Calculation of the relevance criterion
• Given a dataset D = {(xi, yi) ∈(Rd × Rs)}N
• Given a set of variables V of size m (m ≤d), with
V ⊂{x·1, . . . , x·d}
• Given a metric on the space Rm
• Divide the N input-outputs pairs
in two parts D1 and D2
• For each point (xi, yi) in D1
– Find the nearest neighbor, say x∗
i , of xi in D2
according to the metric and the set V .
– Calculate errxi = 1
j=1(yij −y∗
ij)2 where
yij is the jth component of yi and y∗
jth component of y∗
• For each point (xi, yi) in D2
– Find the nearest neighbor, say x∗
i , of xi in D1
according to the metric and the set V .
– Calculate errxi = 1
j=1(yij −y∗
ij)2 where
yij is the jth component of yi and y∗
jth component of y∗
• Calculate C(V ) =
i=1 errxi which is the
statistical measure of the relevance of the set of
variables V .
As far as the search is concerned we adopted a Forward-
Backward Search procedure(FBS) , which is a combination of conventional Forward and Backward search. FBS
is ﬂexible in the sense that a variable is able to return to
the selected set once it has been dropped and vice versa,
a previously selected variable can be discarded later. This
method can start from any initial input variable set: empty
set, full set, custom set or randomly initialized set.
In our experiments, we use the Forward-Backward method
with four sets of initial variables, the ﬁrst one is the empty
set, and the three others are randomly initialized sets. After
calculating the value of the criterion for these four sets,
the ﬁnal set of variables is the one which minimizes the
relevance criterion. We are not starting the FBS from the
full set, because our experiments have shown that it leads to
far more selected variables and less accurate results. This is
due to the local optima problem of the search.
IV. EXPERIMENTS
In order to assess the performance of the MISMO strategy,
we tested it on the ESTSP 2007 competition dataset ,
 . The training series, composed of 875 values, is shown
in Figure 2.
Competition Data
ESTSP 2007 Competition dataset.
We set the maximum embedding order d to 55 , the
maximum number of neighbors in LL to K = 160 and we
consider prediction tasks with H = 100. For time reasons,
the selection of the s value was restricted to the ﬁve values
of the set s = {1, 5, 10, 50, 100}. Note that the value s = 1
corresponds to the Direct strategy, s = 100 to the MIMO
strategy and the values s = {5, 10, 50} to intermediate
MISMO strategies.
Figure 3 plots the vector of the LOO errors obtained for
the training series as a function of the number of neighbors
for the ﬁve values of the parameter s.
This ﬁgure suggests that the MISMO model with s = 50
is on average better than the others.
The following ﬁgures compare the predicted continuation
of the 5 MISMO models (both for LL-MIMO-CV and LL-
MIMO-D) to the real continuation of the series.
Figure 4 shows the prediction returned by the MISMO
with s = 1, i.e. by the Direct strategy. The Mean Square
Error (MSE) is 1.68 for the LL-MIMO-CV model. Note
Number of neighbors
Leave−one−out error
Performance of MISMO on the 10-fold cross validation with s = 1
(solid line), s = 5 (dashed line), s = 10 (dotted line), s = 50 (dotdashed
line) and s = 100 (large dashed line).
that the LL-MIMO-D prediction is not present here since
the too small size of the output prevents the autocorrelation
computation.
Competition Data
ESTSP Competition dataset, prediction of 100 values by using the
MISMO strategy with s = 1, which corresponds to the Direct strategy. Solid
thick line represents the real value and the solid thin line is the prediction
with the LL-MIMO-CV model.
Figure 5 shows the s = 5 predictions. The Mean Square
Error (MSE) amounts to 1.24 for the LL-MIMO-CV model
and to 1.57 for the LL-MIMO-D model.
Competition Data
ESTSP Competition dataset, prediction of 100 values by using
the MISMO strategy with s = 5. Solid thick line represents the real value,
the solid thin line is the prediction with the LL-MIMO-CV model and the
dotted one is the prediction with the LL-MIMO-D model.
The s = 10 case is illustrated by Figure 6. The accuracy
is worse than in the s = 5 case. The MSE is 1.38 for the
LL-MIMO-CV model and 1.05 for the LL-MIMO-D model.
Competition Data
ESTSP Competition dataset, prediction of 100 values by using the
MISMO strategy with s = 10. Solid thick line represents the real value,
the solid thin line is the prediction with the LL-MIMO-CV model and the
dotted one is the prediction with the LL-MIMO-D model.
As suggested by the results in cross-validation, the best
performance is attained for s = 50 (Figure 7). The MSE
drops to 0.82 for the LL-MIMO-CV model and to 0.67 for
the LL-MIMO-D model.
The MIMO case (s = 100) is ilustrated by Figure 8. The
MSE is 1.34 for the LL-MIMO-CV model and 0.95 for the
LL-MIMO-D model.
In Table I, the errors for the learning and the test set are
summarized for the different values of the parameter s.
The results of Table I and the related ﬁgures show clearly
the impact of the parameter s on the accuracy of the
prediction and justify the adoption of a MISMO strategy. The
value of s controls effectively the trade-off between bias and
Competition Data
ESTSP Competition dataset, prediction of 100 values by using the
MISMO strategy with s = 50. Solid thick line represents the real value,
the solid thin line is the prediction with the LL-MIMO-CV model and the
dotted one is the prediction with the LL-MIMO-D model.
Competition Data
ESTSP Competition dataset, prediction of 100 values by using the
MISMO strategy with s = 100. Solid thick line represents the real value,
the solid thin line is the prediction with the LL-MIMO-CV model and the
dotted one is the prediction with the LL-MIMO-D model.
LL-MIMO-CV
LOO ERROR OF THE LEARNING AND THE TEST SET, FOR DIFFERENT
VALUE OF THE PARAMETER s.
variance as made evident also by the nature of the predicted
proﬁle (strongly variant in the s = 1 case and progressively
smoother for higher values of s). A careful choice of s should
be then recommended in case of long-term forecasting.
The experimental results conﬁrm also the important role
of non cross-validated criteria in long term prediction tasks.
Indeed it appears that LL-MIMO-D is competitive and sometimes better than the conventional cross-validated selection
criterion. Once, more than a single prediction is required,
criteria which resume the global behavior of the prediction
become attractive.
Finally, it is worth adding that the MSE of the prediction
returned by MISMO (s = 50) with the LL-MIMO-D model
for an horizon H = 50 is 0.379. Note that this accuracy is
better than the one obtained by the winner of the ESTSP
2007 competition (MSE= 0.506) , .
V. CONCLUSIONS
Predictive modelling for single output tasks is known
to require careful procedures of assessment and selection.
The extension of this procedure to long-term forecasting
and consequently to multi-output modelling requires the
tuning of additional parameters and the deﬁnition of speciﬁc
calibration procedures. This paper discussed how the size
of the multiple outputs play a major role in the generalization accuracy of a long-term forecasting predictor. We
showed that Direct and MIMO strategies implicitly constrain
the size of the output target with consequent impact on
the bias/variance tradeoff and the consequent accuracy. We
proposed a new strategy called MISMO and the associated
calibration procedure which aims to decompose a longterm prediction task in the optimal number of subtasks.
Preliminary results on the ESTSP 2007 competition show
that the approach is promising.