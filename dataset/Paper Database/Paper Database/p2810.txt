Copyright © 2009 IEEE
Reprinted from
Giorgio Licciardi, Fabio Pacifici, Devis Tuia, Saurabh Prasad, Terrance West,
Ferdinando Giacco, Christian Thiel, Jordi Inglada, Emmanuel Christophe, Jocelyn
Chanussot, and Paolo Gamba. Decision Fusion for the Classification of
Hyperspectral Data: Outcome of the 2008 GRS-S Data Fusion Contest. IGARSS'08
special issue of the IEEE Transactions on Geoscience and Remote Sensing
(TGARS), 47(11):3857-3865, 2009.
This material is posted here with permission of the IEEE. Such permission of the
IEEE does not in any way imply IEEE endorsement of any of Universität Ulm's
products or services. Internal or personal use of this material is permitted.
However, permission to reprint/republish this material for advertising or
promotional purposes or for creating new collective works for resale or
redistribution must be obtained from the IEEE by writing to
 .
By choosing to view this document, you agree to all provisions of the copyright
laws protecting it.
IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 47, NO. 11, NOVEMBER 2009
Decision Fusion for the Classiﬁcation of
Hyperspectral Data: Outcome of the
2008 GRS-S Data Fusion Contest
Giorgio Licciardi, Fabio Paciﬁci, Student Member, IEEE, Devis Tuia, Student Member, IEEE,
Saurabh Prasad, Member, IEEE, Terrance West, Student Member, IEEE,
Ferdinando Giacco, Christian Thiel, Jordi Inglada, Emmanuel Christophe,
Jocelyn Chanussot, Senior Member, IEEE, and Paolo Gamba, Senior Member, IEEE
Abstract—The 2008 Data Fusion Contest organized by the IEEE
Geoscience and Remote Sensing Data Fusion Technical Committee
deals with the classiﬁcation of high-resolution hyperspectral data
from an urban area. Unlike in the previous issues of the contest, the
goal was not only to identify the best algorithm but also to provide
a collaborative effort: The decision fusion of the best individual
algorithms was aiming at further improving the classiﬁcation
performances, and the best algorithms were ranked according
to their relative contribution to the decision fusion. This paper
presents the ﬁve awarded algorithms and the conclusions of the
contest, stressing the importance of decision fusion, dimension
reduction, and supervised classiﬁcation methods, such as neural
networks and support vector machines.
Index Terms—Classiﬁcation, decision fusion, hyperspectral
I. INTRODUCTION
HE DATA Fusion Contest has been organized by the
Data Fusion Technical Committee (DFTC) of the IEEE
Geoscience and Remote Sensing Society and has been annually
proposed since 2006. It is a contest open not only to DFTC
members but also to everyone. The aim of the Data Fusion
Contest is to evaluate existing methodologies at the research
or operational level to solve remote sensing problems using
data from different sensors. The main aim of this contest is to
provide a benchmark to the researchers interested in a class of
data fusion problems, starting with a contest and then allowing
the data and results to be used as reference for the widest
community, inside and outside the DFTC. The ﬁrst issue of the
Manuscript received October 29, 2008; revised April 1, 2009. First published
October 13, 2009; current version published October 28, 2009.
G. Licciardi and F. Paciﬁci are with the Earth Observation Laboratory,
Tor Vergata University, 00133 Rome, Italy.
D. Tuia is with the University of Lausanne, 1015 Lausanne, Switzerland.
S. Prasad and T. West are with the Mississippi State University, Starkville,
MS 39762 USA.
F. Giacco is with the Department of Physics, University of Salerno, 84084
Salerno, Italy.
C. Thiel is with the University of Ulm, 89069 Ulm, Germany.
J. Inglada is with the Centre National d’Etudes Spatiales, 31401 Toulouse,
E. Christophe is with the Centre for Remote Imaging, Sensing and Processing, National University of Singapore, Singapore 119260.
J. Chanussot is with the Laboratoire Grenoblois de l’Image, de la Parole, du
Signal et de l’Automatique, Grenoble Institute of Technology, 38402 Grenoble,
P. Gamba is with the University of Pavia, 27100 Pavia, Italy.
Digital Object Identiﬁer 10.1109/TGRS.2009.2029340
contest was devoted to pansharpening . In 2007, the contest
was related to urban mapping using radar and optical data .
In 2008, the contest was dedicated to the classiﬁcation of
very high resolution hyperspectral data. A hyperspectral data
set was distributed to every participant, and the task was to
obtain a classiﬁed map as accurate as possible with respect
to the ground truth data, depicting land-cover and land-use
classes. The ground truth was kept secret, but training pixels
could be selected by the participants by photointerpretation
in order to apply supervised methods. The data set consisted
of airborne data from the reﬂective optics system imaging
spectrometer (ROSIS-03) optical sensor. The ﬂight over the
city of Pavia, Italy, was operated by the Deutschen Zentrum
fur Luft-und Raumfahrt (the German Aerospace Agency) in the
framework of the HySens project, managed and sponsored by
the European Union. According to speciﬁcations, the number of
bands of the ROSIS-03 sensor is 115 with a spectral coverage
ranging from 0.43 to 0.86 μm. Thirteen noisy bands have been
removed. The dimension of the distributed data set is hence 102.
The spatial resolution is 1.3 m per pixel. For the contest,
ﬁve classes of interest were considered, namely, buildings,
roads, shadows, vegetation, and water. Everyone could enter
the contest and download the data set. After classiﬁcation, the
participant could upload the resulting map for an automatic
evaluation of the classiﬁcation performances (confusion matrix
and average accuracy). The participating teams were allowed to
upload as many different results as they wished.
At any given time, the ﬁve best maps were combined using
majority voting (MV) and reranked according to their respective contribution to the fused result. The best seven individual
algorithms were listed in real time on the data fusion contest
website ( together with the
result of the fusion. Please note that the website is still open and
everyone can use it as a benchmark to test any new algorithm.
The contest was open for three months. At the end of the contest, 21 teams had uploaded over 2100 classiﬁcation maps! A
closer look reveals that one single team actually submitted over
1200 results (but we should underline that it did not rank in the
top ﬁve teams), while the other 1000 entries are spread over the
remaining 20 teams. The ﬁve best individual classiﬁcation maps
have been fused together. The ﬁnal corresponding teams have
been awarded with an IEEE Certiﬁcate of Recognition during
the Chapters and Technical Committees’ Dinner at the IEEE
0196-2892/$26.00 © 2009 IEEE
Authorized licensed use limited to: KIZ Abt Literaturverwaltung. Downloaded on November 12, 2009 at 10:45 from IEEE Xplore. Restrictions apply.
IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 47, NO. 11, NOVEMBER 2009
International Geoscience and Remote sensing Symposium in
Boston in July 2008.
The remainder of this paper is organized as follows. First, the
best ﬁve algorithms are detailed.
1) Section II presents the work of Giorgio Licciardi and
Fabio Paciﬁci. They use different standard classiﬁers
[three neural networks (NNs) and two maximum likelihood (ML) classiﬁers] and perform an MV between
different outputs.
2) Section III presents the work of Devis Tuia and Frederic
Ratle. They use both spectral and spatial features. The
spectral features are a six-principal-component (PC) analysis (PCA) extraction of the initial pixel’s vector value.
The spatial information is extracted using morphological
operators. These features are classiﬁed by combining
several support vector machines (SVM) using MV.
3) Section IV presents the work of Saurabh Prasad and
Terrance West.1 They use wavelet-based preprocessing
of the initial spectra followed by a linear discriminant
analysis (LDA) and an ML classiﬁer.
4) Section V presents the work of Ferdinando Giacco and
Christian Thiel. They use a PCA to reduce the dimension
of the data. Spatial information is taken into account with
some textural features. The classiﬁcation is achieved using SVM one-versus-one classiﬁers, and a spatial regularization is performed on the classiﬁcation map to eliminate
isolated pixels.
5) Section VI presents the work of Jordi Inglada and Emmanuel Christophe. They perform a Bayesian fusion
of different classiﬁers (such as SVM classiﬁers). The
weight assigned to each classiﬁer is determined by the
quantitative results it obtained. All these algorithms are
available with the ORFEO Toolbox, which is an open
source library of image processing algorithms for remote
sensing applications ( 
Finally, the decision fusion is considered in Section VII,
and the conclusions and perspectives drawn by this contest are
presented and discussed in Section VIII.
II. MV BETWEEN NN AND ML CLASSIFIERS
A. Reduction of Data Dimensionality
The analysis of hyperspectral imagery usually implicates the
reduction of data set dimensionality to decrease the complexity
of the classiﬁer and the computational time required with the
aim of preserving most of the relevant information of the
original data according to some optimal or suboptimal criteria
 , . The preprocessing procedure exploited in this section
divides the hyperspectral signatures into adjacent regions of the
spectrum and approximates their values by piecewise constant
functions. In , the authors reduced effectively the input space
using the averages of contiguous spectral bands applying piecewise constant functions instead of higher order polynomials.
This simple representation has shown to outperform most of the
feature reduction methods proposed in the literature, such as PC
1The authors would like to acknowledge the active participation of
Jeff Brantley, Jacob Bowen, and Matthew Lee to this work. They are all with
the Mississippi State University.
RESULTING SUBBANDS
TRAINING SAMPLES USED FOR THE SUPERVISED CLASSIFIERS
transform, sequential forward selection, or decision boundary
feature extraction .
Assume Sij to be the value of the ith pixel in the jth band,
with a total of N pixels. The spectral signatures of each class
extracted from ground truth pixels have been partitioned into a
ﬁxed number of contiguous intervals with constant intensities
minimizing the mean-square error
(Sij −μik)2
where a set of K breakpoints deﬁnes continuous intervals Ik,
while μik represents the mean value of each pixel’s interval between breakpoints. A number of K = 7 breakpoints were found
to be a reasonable compromise between model complexity and
computational time, and the resulting partitions are reported in
B. Classiﬁcation Phase
In the literature, NNs and SVMs have been widely used since
they do not require any speciﬁc probabilistic assumptions of the
class distribution, in opposition to parametric classiﬁers, such
as ML. The classiﬁer scheme exploited here is a combination
of single decision maps. In , it has been demonstrated that
combining the decisions of independent classiﬁers can lead
to better classiﬁcation accuracies. The combination can be
implemented using a variety of strategies, among which MV
is the simplest, and it has been found to be as effective as more
complicated schemes , .
MV was used here on ﬁve independent maps resulting from
two different methods, i.e., three NNs and two ML classiﬁers.
For each method, the input space was composed by the seven
features obtained by reducing the sensor bands, while the outputs were the ﬁve classes of interest. For training the supervised
classiﬁers, we have deﬁned three different training sets, varying
the number of samples, as reported in Table II. In the following,
we brieﬂy recall the classiﬁcation methods and the setting used.
1) NNs: The topology of a multilayer perceptron network
 has been determined through an optimization of the number of hidden layers and units, based on the results reported in
the literature, on previous experiences and on a speciﬁc numerical analysis . Two hidden layers have been found to be a
Authorized licensed use limited to: KIZ Abt Literaturverwaltung. Downloaded on November 12, 2009 at 10:45 from IEEE Xplore. Restrictions apply.
LICCIARDI et al.: DECISION FUSION FOR THE CLASSIFICATION OF HYPERSPECTRAL DATA
TRAINING SET CLASSIFICATION ACCURACIES FOR NN, ML, AND MV
CONFUSION MATRIX; TRUE CLASSES GIVEN BY ROWS
suitable choice, while the number of hidden neurons was found
using a growing method, progressively increasing the number
of elements. The variance of the classiﬁcation accuracy for
different initializations of the weights was computed to monitor the stability of the topology. The conﬁguration 7-25-25-5
maximized the accuracy and minimized the instability of the
results. Successively, three independent NNs were trained with
sets 1, 2, and 3 (see Table II), providing three different maps.
2) ML: ML is a well-known parametric classiﬁer, which
relies on the second-order statistics of a Gaussian probability
density function for the distribution of the feature vector of each
class. ML is often used as a reference for classiﬁer comparisons because it represents an optimal classiﬁer in the case of
normally distributed class probability density functions .
ML classiﬁcation was performed using sets 1 and 2 (see
Table II), providing two different maps.
The results from the ﬁve classiﬁcation maps were combined
using MV to obtain the ﬁnal map. The algorithm of MV was
implemented by following two simple rules.
1) A class is the winner if it is recognized by the majority of
the classiﬁers.
2) In the case of balance voting, the winner class is the one
with the highest Kappa (K) coefﬁcient.
The improvement derived from MV is reported in Table III,
where the K-coefﬁcients (based on training sets) obtained from
ﬁve classiﬁcations are compared with the one of the ﬁnal result.
Table IV presents the corresponding ﬁnal confusion matrix.
The score is 0.9884.
III. MORPHOLOGICAL FEATURES AND SVM CLASSIFIER
The proposed method uses both spectral and spatial information to train an SVM classiﬁer. A brief description of the
input features and of the classiﬁer exploited is discussed in this
paragraph.
A. Spectral and Spatial Features
The PCA was used to extract spectral information from the
original image. Speciﬁcally, the six ﬁrst PCs have been retained
for analysis, as shown from the component composition in
Fig. 1(b). These features count for 99.9% of the variance
contained in the original hyperspectral bands.
(a) First PC. (b) Six PCs retained.
Morphological operators , have been added to include information about the spatial neighborhood of the pixels.
Mathematical morphology is a collection of ﬁlters called operators based on set theory. Morphological operators have been
used in remote sensing to extract information about the shape
and structure of the objects in both optical , and, more
recently, hyperspectral imageries – .
An operator is applied using two ensembles: The ﬁrst is
the image to ﬁlter g, and the second is a set of known size
and shape called the structuring element B. In our setting,
and as suggested in and , the ﬁrst PC [shown in
Fig. 1(a)] has been used for the extraction of the morphological
features. Speciﬁcally, top-hat features have been considered.
These features are constructed using the three-stage ﬁltering
described as follows.
1) Erosion and dilation. For a given pixel on the input
image g, erosion ϵB(g) is the pointwise minimum ∧
between all the values of g deﬁned by B when centered on the pixel considered. On the contrary, dilation
δB(g) is the pointwise maximum ∨between these same
2) Opening and closing. Opening γB(g) is the dilation of
an eroded image and is widely used to isolate brighter
(compared to surrounding features) structures in grayscale images. On the contrary, closing φB(g) is the erosion of a dilated image and allows one to isolate darker
structures . The formulation of opening and closing
operators is given by
γB(g) = δB [ϵB(g)]
φB(g) = ϵB [δB(g)] .
Authorized licensed use limited to: KIZ Abt Literaturverwaltung. Downloaded on November 12, 2009 at 10:45 from IEEE Xplore. Restrictions apply.
IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 47, NO. 11, NOVEMBER 2009
(a) Opening and (b) closing top-hat features extracted for the Pavia
image. The size of the structuring element is increased from top (three pixels)
to the bottom (29 pixels) of the images.
LABELED PIXELS FOR THE PAVIA IMAGE
3) Top hat. Top-hat operators are the residuals of an opening
(or a closing) image, when compared to the original
TH = g −I(g).
If I = γB(g), the operator is an opening top hat and highlights bright peaks of the image. On the contrary, if I = φB(g),
the operator is closing top hat and emphasizes dark peaks of the
image, as shown in Fig. 2.
B. Experimental Setup
A total of 206 009 labeled pixels has been identiﬁed by careful visual inspection of the hyperspectral image. These samples
have been divided into a training set of about 34 000 pixels,
a validation set for model selection (about 30 000 pixels), and
a test containing the remaining 142 009 pixels, as shown in
As discussed previously, the input space takes both spectral
and spatial features into account. The six ﬁrst PCs have been
used as spectral information, while 28 spatial features have been
CONFUSION MATRIX; TRUE CLASSES GIVEN BY ROWS
extracted by applying opening and closing top-hat operators
to the ﬁrst PC using diamond-shaped structuring element with
increasing diameter size (from 3 to 29 pixels).
Each feature has been converted to standard scores and
stacked in a single 34-D input vector. The classiﬁer is a oneagainst-all SVM implemented using the Torch 3 library .
A radial basis function (RBF) kernel has been used. Model
selection has been performed by grid search to ﬁnd the optimal
kernel parameters σ and C.
C. MV of the Best Classiﬁcation Maps
During the contest, several maps have been uploaded, accounting for different training sets and optimal kernel parameters. Eventually, each classiﬁcation map improving the previous
solution has been combined using MV: A pixel received the
label of the class assigned by most of the models. In the case
where no class prevailed, the pixels receive the label of the map
showing the highest Kappa coefﬁcient.
Table VI presents the corresponding ﬁnal confusion matrix.
The score is 0.9858.
IV. GROUND-COVER MAPPING USING SUPERVISED
CLASSIFICATION AND MORPHOLOGICAL PROCESSING
In this approach, we employ discrete wavelet transform
(DWT)-based processing of the hyperspectral signatures, followed by LDA transformation and pixelwise ML classiﬁcation
for creating a ground-cover map of the satellite imagery. The
LDA transformation and ML classiﬁers are trained using the
training data extracted from the regions of interest provided
to all contest participants. The resulting ground-cover map is
then postprocessed by an appropriate morphological operation
to minimize the salt-and-pepper classiﬁcation noise introduced
because of the use of pixelwise (per-pixel) classiﬁcation. The
DWT-based preprocessing of the hyperspectral signatures provides a multiresolution information representation. The mother
wavelet employed in this approach is the Daubechies wavelet
(implemented using the Daubechies 9/7 ﬁlter bank), which
resulted in a feature vector comprising of DWT coefﬁcients per
pixel. Data from this high-dimensional space were projected
onto a reduced-dimensional space by employing the LDA algorithm. LDA seeks to ﬁnd a linear transformation, such that the
within-class scatter is minimized and the between-class scatter
is maximized. The transformation is determined by maximizing
Fisher’s ratio, which can be solved as a generalized eigenvalue
The between- and within-class scatter matrices are learned
from the training data. Since it is designed to maximize class
separation in the projected space, LDA is an appropriate dimensionality reduction approach for the land-cover classiﬁcation
task at hand.
Authorized licensed use limited to: KIZ Abt Literaturverwaltung. Downloaded on November 12, 2009 at 10:45 from IEEE Xplore. Restrictions apply.
LICCIARDI et al.: DECISION FUSION FOR THE CLASSIFICATION OF HYPERSPECTRAL DATA
CONFUSION MATRIX; TRUE CLASSES GIVEN BY ROWS
After performing an LDA transformation on the training and
test data, an ML classiﬁer is employed for classifying pixels in
the image, which assumes Gaussian class distributions for each
class. We assume equal priors for each class. The class membership function for such a classiﬁer is given in . A conventional single-classiﬁer system was sufﬁcient for the given
task because the amount of available ground truth was sufﬁcient
relative to the feature space dimensionality. Had we had an
insufﬁciently small ground-truth data set for the classiﬁcation
task, the recently developed multiclassiﬁer and decision fusion
framework could have been employed for this task . The
feature extraction, optimization, and classiﬁcation approach
outlined earlier helps in generating an initial ground-cover map.
In order to remove the salt-and-pepper classiﬁcation noise from
this map, morphological postprocessing is performed over it.
For each class i, a binary map is created with class i having
the label 1 and all other classes having the label 0. A onepixel dilation is then applied to each set of clustered pixels
in the binary map. This dilated mask is then subtracted from
the clustered pixels in the binary map which produces a cluster
ring. For a cluster smaller than a predetermined class cluster
threshold, the cluster ring is placed in the original image,
and the class with the largest sum of label pixels in the ring
deﬁnes the label of the cluster. This is done for all classes.
This operation ensures that stray mislabeling of classes (e.g.,
a building pixel in the middle of a river body) is corrected.
The normalized difference vegetation index (NDVI) is a very
good indicator of vegetation in remote sensing applications. As
the ﬁnal postprocessing, we estimated the NDVI value for each
pixel in the image. This NDVI map is used to replace the class
labels of all nonvegetation pixels in the classiﬁcation map with
vegetation pixels if the corresponding NDVI was high. This
ensures that any missed pixels of vegetation pixels using the
standard classiﬁcation approach are identiﬁed and corrected. It
is worth mentioning that, although we have performed the perpixel classiﬁcation in the wavelet domain, we obtained very
similar recognition performance (measured by the accuracy)
when we performed the classiﬁcation in the raw reﬂectance
domain. The improvement in the overall classiﬁcation by introducing wavelet-based processing was marginal.
Table VII presents the corresponding ﬁnal confusion matrix.
The score is 0.9753.
V. THREE-STAGE CLASSIFICATION BASED
ON ONE-VERSUS-ONE SVMs
The proposed method is made up of three classiﬁcation
stages with special attention to preprocessing and spatial feature
extraction.
1) Preprocessing and Feature Extraction: A PCA of the 102
ROSIS spectral bands is computed. The 26 bands with the
most signiﬁcant PCs are used as spectral input features for
the classiﬁer. In addition, we introduced some spatial information extracted from the ROSIS data set: standard deviation
calculated on the ﬁrst PC and on the near infrared/red ratio
(bands 102/66), known in remote sensing literature as a way
to emphasize the vegetation. We also computed the so-called
energy measure, extracted from the well-known gray-level cooccurrence matrix (GLCM), widely used in land-cover mapping . Starting from a pixel in a given position, the GLCM
provides a measure of the probability of occurrence of two gray
levels separated by a given distance in a given direction (among
the horizontal, vertical, left diagonal, and right diagonal). The
energy measure is computed, i.e., the summation of squared
elements in the GLCM, and the four directions are averaged to
remove directional effects; this last choice is due to the absence
of a preferred direction in the geometry of the investigated landcover classes.
Each textural measure is computed on a moving window of
3 × 3 pixels. The total number of features for the ﬁrst stage
is 29. We worked on a total number of 2133 labeled samples
to train the SVMs, which were split into two subsets for
training (882) and test (1241) during the parameter optimization
In our second classiﬁcation stage, in order to improve the
discrimination between buildings and streets, we added four
new features obtained from the HYPERUSP algorithm. This
procedure (implemented in the geographic information system
software IDRISI, Andes edition) ﬁrst makes use of an unsupervised stage in which a prearranged number of hyperspectral
signatures are identiﬁed looking at the whole ROSIS spectral
data set. Then, every pixel of the image is considered as a
combination of all the components represented in the signatures
computed in the ﬁrst stage. The coefﬁcients of the four most
representative components of the hyperspectral decomposition
were selected, adding up to a total number of 33 features for
the second classiﬁcation stage. In addition, the new class “gray
building” was introduced, summing up to 1614 labeled pixels
for this stage.
2) Classiﬁcation:
1) First stage. An SVM was used as a multiclass classi-
ﬁer, in a one-versus-one architecture with linear kernel
(C = 1; RBF or polynomial ones performed not as good),
where an SV Mi is built for each possible pair of classes.
Presented with a new sample x, each SV Mi answers with
the distance di(x) that this sample has to its hyperplane.
These distances will be converted to probabilities using
a sigmoid function with ﬁxed parameters. To incorporate information about class-pair dependences, we proposed to not simply sum up the values per class but
use an algorithm based on the statistical Bradley–Terry
model. After an iterative process, it produces probabilities that are very plausible given all pairs of classwise
comparisons.
2) Second stage. We only looked at those samples that were
classiﬁed as buildings or streets (class 1 or 2), according
to the answers of the previous stage. A one-versus-one
SVM with a linear kernel (as described before) was used.
This second step increases the overall accuracy from
96.05% to 96.41%.
3) Third stage. A simple ﬁlter was used to avoid lonely pixels which are classiﬁed differently from their neighbors.
Authorized licensed use limited to: KIZ Abt Literaturverwaltung. Downloaded on November 12, 2009 at 10:45 from IEEE Xplore. Restrictions apply.
IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, VOL. 47, NO. 11, NOVEMBER 2009
TABLE VIII
CONFUSION MATRIX; TRUE CLASSES GIVEN BY ROWS
Considering a window of 3 × 3 surrounding a selected
pixel, if the majority of the pixels belong to the same
class, the central pixel is assigned to it.
Looking at the confusion matrix (see Table VIII; the score is
0.9641) and also the ﬁnal map, one can observe that there are
very few errors, except for the classes 1 and 2 (buildings and
streets). By visual inspection of a natural color composition of
ROSIS bands, we found that our classiﬁcation procedure had
still some difﬁculties in telling gray roofs from streets. Red
roofs were classiﬁed correctly.
The rather powerful SVM with Bradley–Terry coupled output outperformed some other classiﬁers tested, and the second
stage we implemented proved to alleviate the street/building
problem. For even better results, we think that more structural
features would be needed.
VI. BAYESIAN FUSION
Given the fact that different classiﬁers have different performances for different kinds of classes, it was interesting to
perform some classiﬁer fusion. Several classiﬁcation strategies
with different reﬁnements were deﬁned to improve the shortcoming we notice during the ﬁrst tentatives. The idea is to
deﬁne several methods, each with its own strengths and weaknesses, and to combine the results. We implemented several
SVM classiﬁers using different input features and training sets
and applied Bayesian fusion with two approaches.
The ﬁrst point that we noticed was that SVM classiﬁers were
found to be very sensitive to the training sets. As no training
set was provided for the challenge, several training sets were
created with different characteristics: including border pixels
or not, exhaustive classiﬁcation of small areas, etc. Another
question was raised concerning the deﬁnition of classes: Is inner
courtyard considered as road or building? Several training sets
were created with these different strategies in mind. Finally,
four training sets were used.
The second point concerned the input data: Data provided to
the SVM are particularly critical. The ﬁrst possibility is to use
the original image. However, using many bands does not allow
one to efﬁciently differentiate classes; thus, the learning stage
is usually very costly as the SVM has to ﬁnd out the signiﬁcant
information. For hyperspectral data, several preprocessing steps
are widely used to reduce data dimensionality. PCA was used to
concentrate the information on the ﬁrst few spectral bands and
the eight bands with most energy were kept for the SVM. Similar processing was done for the maximum noise fraction (MNF)
keeping the ﬁrst eight bands. As the SVM is able to classify data
even when some features of the feature vector are irrelevant or
redundant, both PCA and MNF were also combined.
One shortcoming of the SVM classiﬁcation is that it is based
only on one pixel at a time. Pixels on the edge of classes are usually composed of several classes, and it is particularly difﬁcult
to classify these pixels without looking at their environment;
most classiﬁcation errors come from these pixels. The simplest
way to introduce a relationship between these pixels was to
use a Markov random ﬁeld to regularize the ﬁnal classiﬁcation.
A simple Potts model was introduced to reduce the noise on
these edge pixels. Such regularization usually increases the ﬁnal
score by 2% in average.
An alternative to this regularization was to apply a blur
(mean ﬁlter) to the input data. Such blur usually reduces
the differences between pixels within one class, thus greatly
speeding the learning step, without a signiﬁcant impact on false
classiﬁcation.
All these data sets, training sets, and classiﬁcation options
led to different classiﬁcation results. Given the fact that the
confusion matrix was computed on about one quarter of the
pixels, the idea was then to improve the overall results using
performances on this pixel subset. This really corresponds to
a real case where a ground truth is available for a portion of
the image, and the automatic classiﬁcation is used to speed
up the process without any more human intervention. Several
approaches were designed to combine these results.
The ﬁrst approach consisted in performing the ML fusion
(MLF) of different M classiﬁers using the confusion matrix
obtained for each of them. Thus, for a given pixel xi and for
each class Ck = 1, . . . , N, we compute likelihood
L(xi, Ck) =
j is a binary valued function which is equal to one if
classiﬁer j gives class k and zero if otherwise, and Ajk is the
diagonal term of the confusion matrix of classiﬁer j for class k.
The MLF consists in taking class k, which maximizes the
likelihood for each pixel.
The second approach consisted in performing maximum a
posteriori fusion, which is actually like MLF, but using the prior
probabilities of the different classes P(k)
L(xi, Ck) =
j · Ajk · P(k).
P(k) can easily be obtained from the output of each classi-
ﬁer, since these are good enough to assume that the proportions
of the classes are correct. One can also obtain these proportions
by computing a weighted average of the proportions of each
classiﬁer. The weights can proportional to the kappa coefﬁcient
of each classiﬁer.
Combining several classiﬁcations leads to improved results:
1% over the best classiﬁcation. This result is also more robust
as it does not need any ﬁne tuning of the SVM parameters: The
worst results will be discarded during the fusion process.
Table IX presents the corresponding ﬁnal confusion matrix.
The score is 0.9612.
VII. DECISION FUSION
The decision fusion of the ﬁve best individual results (described in the previous sections) was achieved using a simple
majority vote. Table X presents the corresponding ﬁnal confusion matrix. The score is 0.9921. Even though the ﬁnal score is
less than 1% higher than the best algorithm, it remains the best.
Authorized licensed use limited to: KIZ Abt Literaturverwaltung. Downloaded on November 12, 2009 at 10:45 from IEEE Xplore. Restrictions apply.
LICCIARDI et al.: DECISION FUSION FOR THE CLASSIFICATION OF HYPERSPECTRAL DATA
CONFUSION MATRIX; TRUE CLASSES GIVEN BY ROWS
CONFUSION MATRIX; TRUE CLASSES GIVEN BY ROWS
As a conclusion, one can clearly state that decision fusion is
indeed a promising way in order to actually solve the problem
of classiﬁcation in hyperspectral imagery. One can think of the
result of this contest as the “metaclassiﬁer” everyone has been
dreaming of, but no one ever did implement such a classiﬁer.
As a matter of fact, it requires the perfect mastering, implementation, and tuning of very different up-to-date techniques, from dimension reduction to feature extraction and
classiﬁcation. Only the joint effort by different teams, each one
specialized in its own technique, could actually make it. In that
sense, the contest was a success.
This classiﬁer, which provides the best results ever obtained
on this data set, can be considered in itself as a technical
contribution of the contest.
VIII. CONCLUSION AND PERSPECTIVES
The contest provided some interesting conclusions and perspectives. They are summarized in the following items.
1) Supervised versus unsupervised methods. It was very
interesting to see that the ﬁrst uploaded results had been
obtained with unsupervised methods. The results were
fairly good (around 75%) but were outperformed by the
supervised methods when they appeared a few weeks
later. However, seeing these methods providing very fast
and fairly good results was quite interesting.
2) Dimension reduction. Most of the proposed methods used
a dimension reduction as a preprocessing. Most of them
used the PCA, retaining various numbers of components.
However, this step, with PCA or other methods, seems to
be a must-do.
3) Spatial and spectral features. Several algorithms used
both kinds of features. While the spectral information
is easily extracted from the original spectra (directly
or after some sort of dimension reduction), the spatial
information remains a more tricky issue. Texture analysis
and mathematical morphology provide some answers.
Other ways to extract such a meaningful information are
currently investigated. Similarly, mixing the spectral and
the spatial information in the best possible way is also a
clear direction for future research works.
4) SVMs. Almost all the best methods used some SVMbased classiﬁers. SVM really appeared as extremely
suited for hyperspectral data, thus conﬁrming the results
presented in the recent abundant literature.
5) NNs. We must conclude by emphasizing that, similar to
the 2007 contest, NNs have provided the best individual
performances.
The ﬁnal comment is on decision fusion. It was a great
surprise and a very interesting point when we noticed that many
submitted results had been obtained using different algorithms,
meaning that the participants already performed a decision
fusion before uploading their classiﬁcation maps. This fusion
“to the power of two” was also a clear sign that decision fusion
is indeed a way to go for future research.
Of course, a crucial issue is the algorithm used for the fusion.
The simplest solution consists in performing a majority vote.
Some participants used it; it was also used for the ﬁnal result
of the contest. However, this is clearly suboptimal. More advanced strategies require the deﬁnition of a reliability criterion
 , . The solution used by Jordi Inglada and Emmanuel
Christophe in the frame of the contest is both very smart
and very inspiring: Using the confusion matrices automatically
provided by the system may sound like a diversion of the
contest. However, it is, as a matter of fact, absolutely reasonable
for operational applications. Combining several classiﬁcation
results based on their performances on small areas, where
a ground truth is available, corresponds to real application
situations. In crisis situation, classiﬁcation is usually performed
by hand. Using such a system enables one to limit the human
intervention only to a small portion of the image while keeping
similar performances.
As a conclusion, the actual classiﬁcation performances obtained at the end of the contest should not be considered as
absolute values. The results were obtained after a few months of
intense activity by all the participants and were obtained with
one single data set. The accurate and reliable classiﬁcation of
hyperspectral images still needs some methodological developments. However, the conclusions, as discussed in this session,
clearly point some ways for future research. Among them, decision fusion has doubtlessly demonstrated its outstanding ability.