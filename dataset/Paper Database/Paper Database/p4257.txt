Coupled Multi-Layer Attentions
for Co-Extraction of Aspect and Opinion Terms
Wenya Wang,†‡ Sinno Jialin Pan,† Daniel Dahlmeier,‡ Xiaokui Xiao†
†Nanyang Technological University, Singapore
‡SAP Innovation Center Singapore
†{wa0001ya, sinnopan, xkxiao}@ntu.edu.sg, ‡{d.dahlmeier}@sap.com
The task of aspect and opinion terms co-extraction aims to
explicitly extract aspect terms describing features of an entity
and opinion terms expressing emotions from user-generated
texts. To achieve this task, one effective approach is to exploit
relations between aspect terms and opinion terms by parsing
syntactic structure for each sentence. However, this approach
requires expensive effort for parsing and highly depends on
the quality of the parsing results. In this paper, we offer a
novel deep learning model, named coupled multi-layer attentions. The proposed model provides an end-to-end solution
and does not require any parsers or other linguistic resources
for preprocessing. Speciﬁcally, the proposed model is a multilayer attention network, where each layer consists of a couple
of attentions with tensor operators. One attention is for extracting aspect terms, while the other is for extracting opinion
terms. They are learned interactively to dually propagate information between aspect terms and opinion terms. Through
multiple layers, the model can further exploit indirect relations between terms for more precise information extraction.
Experimental results on three benchmark datasets in SemEval
Challenge 2014 and 2015 show that our model achieves stateof-the-art performances compared with several baselines.
Introduction
Aspect and opinion terms co-extraction, which aims at identifying aspect terms and opinion terms from texts, is an important task in ﬁne-grained sentiment analysis . An aspect term refers to a word or a phrase (a
sequence of words) describing an attribute or feature of an
entity, e.g., a product. An opinion term refers to the expression carrying subjective emotions. For example, in the review “This little place has a cute interior decor and affordable prices”, interior decor and prices are aspects, with cute
and affordable as their corresponding opinions.
In the literature, there exist many lines of work for aspect and/or opinion terms extraction which can be categorized as rule-based, feature-engineering-based, or deeplearning-based approaches. For rule-based approaches , the idea is to
manually design some rules based on syntactic or dependency structure of each sentence to expand the extracted
Copyright c⃝2017, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
aspect and opinion terms iteratively with a seed collection as input. For feature-engineering-based approaches, the
idea is to train a classiﬁer with rich, manual-deﬁned features based on linguistic or syntactic information from annotated corpus to predict a label (aspect, opinion, or others) on each token in a sentence . These two categories of approaches are laborintensive for constructing rules or features using linguistic
and syntactic information. To reduce the engineering effort,
deep-learning-based approaches are proposed to learn highlevel representations for each token, on which a classiﬁer
can be trained. Despite some promising results, most deeplearning approaches still require a parser analyzing the syntactic/dependency structure of the sentence to be encoded
into the deep models. Therefore, the performances of these
approaches rely on the quality of the parsing results.
In practice, the syntactic or dependency structures of
many user-generated texts may not be precise with a computational parser, which may degrade the performances of
existing deep-learning approaches. Moreover, performing
parsing on a long sentence and large dataset can be very
time-consuming. Therefore, we propose to use the attention mechanism with
tensor operators to replace the role of syntactic/dependency
parsers to capture the relations among tokens in a sentence.
Speciﬁcally, we design a couple of attentions, one for aspects extraction and the other for opinions extraction. They
are learned interactively such that label information can be
dually propagated among aspect terms and opinion terms by
exploiting their relations. Moreover, we use multiple layers of the coupled attentions to extract inconspicuous aspect/opinion terms. Our motivation is similar to for exploiting aspect-opinion relations. The difference is that our model automatically learns
these relations without any parsers or linguistic resources.
In summary, our contributions are two-fold: 1) We propose an end-to-end deep learning model for aspect and
opinion terms co-extraction without requiring any syntactic/dependency parsers or linguistic resources to generate
additional information as input. 2) We conduct extensive
experiments on three benchmark datasets to verify that our
model achieves state-of-the-art performance for aspect and
opinion terms co-extraction.
Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence (AAAI-17)
Related Work
Aspect and Opinion Terms Extraction
For extracting aspect/opinion terms from texts, Hu and
Liu proposed to use association rule mining for extracting aspect terms and synonyms/antonyms from Word-
Net for identifying opinion terms. Qiu et al. used
a dependency parser to augment a seed collection of aspect and opinion terms through double-propagation, similar
for . The above
methods are unsupervised, but depend on pre-deﬁned rules
and linguistic resources. For supervised methods, the task
is treated as a sequence labeling problem. Li et al. 
and Jin and Ho implemented CRF and HMM with
extensive human-designed features to solve the problem, respectively. Liu et al. applied a word alignment model in order to capture relations among opinion
words, which requires large amount of training data to obtain desired relations. Topic models were also applied for
aspect extraction . Recently, deep learning methods have been proposed for this task. Liu et al. applied recurrent neural network on top of pre-trained word embeddings for aspect extraction. Yin et al. proposed an unsupervised
embedding method to encode dependency path into a recurrent neural network to learn high-level features for words,
which are taken as input features for CRFs for aspect extraction. Wang et al. proposed a joint model of recursive neural networks and CRFs for aspect and opinion terms
co-extraction. The neural network is constructed from the
dependency parse tree to capture dual-propagation among
aspect and opinion terms. Note that most existing deep models require a syntactic/denpendency parser and auxiliary linguistic features to boost their extraction accuracy. As a comparison, our proposed model does not need any linguistic
features, or any pre-constructed syntactic structure as input.
Attention & Memory Network
Attentions and memory networks have recently been used
for various machine learning tasks, including image generation , machine translation , sentence summarization , document sentiment classiﬁcation , and question answering . The attention mechanism aims to select and attend
to relevant parts of the input which could be thought of as a
soft-alignment process. A memory network generally consists of multiple layers of attentions, which has shown superior performance in many NLP tasks . In this paper, we aim to develop a
multi-layer attention network to replace the role of a syntactic/dependency parser to capture the relations among words
in a sentence for information extraction.
Problem Statement & Motivation
We denote by si a review sentence from the training dataset,
which consists of a sequence of tokens si={wi1, ..., wini}.
The task aims to extract a collection of all the explicit
aspect terms Ai = {ai1, ..., aij} and opinion terms Pi =
{pi1, ..., pim} appearing in si. Note that ail or pir could
be a single word or a phrase. The task is modeled as a sequence tagging problem with the BIO encoding scheme.
Speciﬁcally, we deﬁne 5 different classes: BA (beginning
of aspect), IA (inside of aspect), BP (beginning of opinion), IP (inside of opinion), and O (others), and let L =
{BA, IA, BP, IP, O}. Each token wip ∈si is classiﬁed as
yip ∈L. Given a test review sj = {wj1, ..., wjnj}, we aim
to obtain a prediction label yjq ∈L for each wjq, where any
prediction sequence with BA (BP) at the beginning followed
by IA (IP) is extracted as a single aspect (opinion) term.
To fully exploit the syntactic relations among different tokens in a sentence, most existing methods applied a computational parser to analyze the syntactic/dependency structure of each sentence in advance. Figure 1 shows an example dependency structure of a review sentence. In this example, ﬁsh burger and tastes are ground truth aspect terms,
accompanied with best and fresh as their opinions respectively. In , several extraction rules are prede-
ﬁned based on the dependency structure. For instance, given
tastes as an aspect term, fresh could be extracted as an opinion term through the direct relation: A
−−−−→B. As another
example, given burger as an aspect term, tastes can be extracted as another aspect term through the indirection relation: A
←−−B because they both have syntactic
dependence on the same token dish. One major limitation
of this rule-based approach is that it is deterministic, and
thus may fail to handle uncertainty underlying the data. To
address this issue, Wang et al. proposed to encode
the dependency structure into a recursive neural network
plugged with a CRF to construct syntactically meaningful
and discriminative hidden representations.
Although promising results were shown in , a dependency parser is still required as a preprocessing step, and some simple feature engineering is also
needed to boost its performance. However, there may be
many grammar and syntactic errors in user-generated texts,
in which case the outputs of a dependency parser may
not be precise, and thus degrades the performance. Therefore, in this paper, we offer an end-to-end deep learning
model, which models the relations among tokens automatically without any dependency parsing or feature engineering, and achieves state-of-the-art performances for aspect
and opinion terms co-extraction.
Coupled Multi-layer Attentions
Our proposed model is named Coupled Multi-layer Attentions (CMLA) which consists of the following features:
• For each sentence, we construct a pair of attentions, one
for aspect terms extraction, and the other for opinion
terms extraction. Each attention aims to learn a prototype
vector for aspect or opinion, a high-level feature vector
for each token, and an attention score for each token in the
sentence. The feature vector and attention score measure
the extent of correlation between each input token and the
prototype using a tensor operator, which captures different contexts of a given token when measuring its corre-
Figure 1: A dependency example for sentiment analysis.
lation to the prototype. Hence, a token with high score
indicates a high chance of being an aspect or opinion.
• To capture direct relations between aspect and opinion
terms, e.g., the A
−−−−→B relation shown in Figure 1,
the pair of attentions are coupled in learning such that the
learning of each attention is affected by the other. This
helps to double-propagate information between them.
• To further capture indirect relations among aspect and
opinion terms, e.g., the A
←−−B relation shown
in Figure 1, we construct a network with multiple layers
of coupled attentions.
Attention with Tensor Operator
A basic unit of CMLA is a pair of attentions: aspect attention
and opinion attention. In most previous studies, attentions
have been used for generating sentence- or document- level
representation by computing a weighted sum of the input
sequence . The weight
of each input unit is an attention score obtained from its
composition with a prototype vector which guides the model
about where to attend. Different from previous approaches,
we use attention to identify the possibility of each token being an aspect or opinion term. Figure 2(a) shows an example
of a basic attention model for aspect extraction. We denote
by H ={h1, ..., hn} the input sequence of length n, where
hi ∈Rd is the feature representation for the i-th token wi.1
In the aspect attention, we ﬁrst generate a prototype vector ua for aspects which can be viewed as a general feature
representation for aspect terms. This aspect prototype will
guide the model to attend to the most relevant tokens.2 Given
ua and H, the model scans the input sequence and computes
an attention vector ra
i and an attention score ea
i for the i-th
token. To obtain ra
i , we ﬁrst compute a composition vector
i ∈RK that encodes the extent of correlations between hi
and prototype vector ua through a tensor operator f a:
i = f a(hi, ua) = tanh , a tensor operator could be viewed
1For initialization of hi, we ﬁrst pre-train a word embedding
xi ∈RD for wi, and then apply Gated Recurrent Unit (GRU) to obtain hi by encoding
context information.
2We randomly initialize ua from a uniform distribution: ua ∼
U[−0.2, 0.2] ∈Rd, which is then trained and updated iteratively.
as multiple bilinear terms that could model more complicated compositions between 2 units. As shown in the bottom of Figure 2(a), Ga could be decomposed into K slices,
where each slice Ga
k∈Rd×d is a bilinear term that interacts
with 2 vectors and captures one type of composition, e.g., a
speciﬁc syntactic relation. Hence h⊤
i Gaua∈RK inherits K
different kinds of compositions between hi and ua that indicates complicated correlations between each input token and
the aspect prototype. By adding a non-linear transformation
tanh(·), βa
i encodes more abstract and high-level correlation
features. Then ra
i is obtained from βa
i via a GRU network:
i = (1 −za
i = tanh(W a
i−1) + U a
i ). Here, ga
are reset and update gates respectively that control the information ﬂow from the previous timestamp. W a
z are weight matrices to be learned for transforming
i−1 and βa
i to gate units. By applying GRU on βa
i , the attention vector ra
i ∈RK becomes context-dependent with the
ability to inherit past information. For example, as shown in
Figure 2(a), if Fish has high correlations with aspect prototype, its next token burger also has high chance of being active, because ra
2 inherits information from ra
1. Indeed,
many aspect terms consist of multiple tokens, and exploiting context information helps their predictions. For simplicity, we use ra
i =GRU(f a(hi, ua), θa) to denote (2), where
An attention score ea
i for token wi is then computed as
i is a correlation feature vector, va ∈RK can be
deemed as a weight vector that weighs each feature accordingly. Hence, ea
i becomes a scalar score, where a higher
score indicates higher correlation with the prototype, and
higher chance of being attended. For example, as shown
in Figure 2(a), ua helps the model to attend to Fish and
burger which indicates their high chance of being aspect
terms. Note that the output attention vector ra
i is also used as
the ﬁnal feature representation for wi. Thus, a prediction on
each token can be generated by la
i =softmax(Cara
i ), where
Ca ∈Rc×K is a classiﬁcation matrix for converting ﬁnal
feature vectors to labels, and c is the number of classes.3
The procedure for opinion attention is similar. In the subsequent sections, we use a superscript p to denote the opinion attention. In the ﬁnal prediction, each token only belongs
to 1 of the 5 classes in L mentioned previously. After la
i are obtained for each token, we pick the largest value from
each vector. If both of them correspond to O, then the ﬁnal
prediction is O. If only one of them is O, we pick the other
one as ﬁnal prediction. When neither of them are O, the two
values are compared and the largest one is chosen.
Coupled Attentions for Dual Propagation
As discussed in previous sections, a crucial issue for coextraction of aspect and opinion terms is how to fully exploit the relations between aspect terms and opinion terms
3Here, c=3. Classes in the aspect attention are BA, IA and O,
while classes in the opinion attention are BP, IP and O.
(a) A single-layer attention model with tensor.
(b) Multi-layer Coupled attentions.
(c) Attention prototype.
Figure 2: Illustration of the proposed model.
such that the information can be propagated to each other
to assist ﬁnal predictions. However, independent learning of
the aspect or opinion attention fails to utilize their relations.
Therefore, we propose to couple the learning of the two attentions such that information of each attention can be dually propagated to the other. Speciﬁcally, as shown in Figure 2(b), solid lines and dashed lines denote aspect attention
and opinion attention, respectively. The two attentions share
the same feature vector hi for each input token wi. Different
from a single attention, the prototype to be fed into each attention module becomes a pair of vectors {ua, up}, and the
tensor operator in (1) becomes a pair of tensors {Gm, Dm}:
f m(hi, ua, up) = tanh([h⊤
i Gmum : h⊤
where [:] denotes concatenation of vectors, and m∈{a, p} is
the index of the two attentions, m = a if m = p, and m = p
if m = a. The new tensor Dm ∈RK×d×d is used to model
the correlations of hi with the prototype um from the conjugate attention, which captures the dual-propagation between
aspect terms and opinion terms. For example, if h8 for tastes
is already attended through the aspect attention and incorporated in ua, it will help to attend fresh for opinion attention
due to its strong correlation with tastes. This indicates fresh
as a possible opinion term. Similar to (2), the outputs rm
i are obtained through
i = GRU(f m(hi, ua, up), θm), and em
Multi-Layer Coupled Attentions
A couple of attentions is only able to capture the direct relations between aspect terms and opinion terms, but not the indirect relations among them, such as the A
relation shown in Figure 1. To address this issue, we propose a network with multi-layer coupled attentions. Specifically, we present an example consisting of two layers in
Figure 2(b), where each layer consists of coupled attentions
as illustrated in the previous section. For each layer t + 1
as shown in Figure 2(c), the prototype vectors um
t+1, where
m∈{a, p}, are updated based on the prototype vectors in the
previous layer um
t to incorporate more feasible representations for aspect or opinion terms through
t+1 = tanh(V mum
where V m ∈Rd×d is a recurrent transformation matrix to
be learned, and om
t is an accumulated vector computed via
ti hi, and αm
ti = exp(em
ti is a normalized attention score for em
ti . Intuitively,
is dominated by the input feature vectors {hi}’s with
higher attention scores. Therefore, om
t will approach to the
attended feature vectors of aspect or opinion tokens. As a
result, um
t+1 will capture more accurate feature representation about aspect or opinion terms, which in return is used
to guide the model about where to attend in the next layer.
We use Figure 2(b) to illustrate how the multi-layer coupled attentions model can capture indirect relations, e.g., the
←−−B relation. Suppose at layer t, ua
t incorporates h1 and h2 for Fish and burger, up
t incorporates h5 for
best. For the aspect attention, {ua
t } interact with each hi
to obtain the score ea
ti. We see that dish is attended because
h6 is highly correlated with both h2 and h5. As a result, ua
will be updated, and incorporate h6, which in turn assists
focusing attention on tastes in the next layer, because of the
strong correlation between h6 and h8. In this case, the aspect
term tastes is extracted indirectly through two layers of the
coupled attentions. This shows that the multi-layer attention
network is able to progressively attend the aspect or opinion
words that are non-obvious and have indirect relations.
Similar to the single-layer coupled attention model, the
proposed network ﬁrst accumulates high-level representations rm
ti in (5) for each token i at each layer t to generate the prediction vectors lm
i =softmax and SemEval Challenge 2015 task 12 subtask
1 . Note that the original datasets in the
challenges only contain labels for aspect terms. For S1 and
Description
SemEval-14 Restaurant
SemEval-14 Laptop
SemEval-15 Restaurant
Table 1: Dataset description with number of sentences
S2, we use the labels on opinion terms provided by , and manually label all the opinion terms for S3.
The pre-trained word embeddings are obtained using
the word2vec tool4 on two different corpora, as the three
datasets belong to two domains: restaurant and laptop. Following the setup in , for restaurant domain, we apply word2vec on Yelp Challenge dataset5 consisting of 2.2M restaurant reviews with 54K vocabulary size.
For laptop domain, we use the corpus from electronic domain in Amazon reviews , which contains 1M reviews with 590K vocabulary size. The dimensions of word embeddings are 200 for restaurant domain and
150 for laptop domain in our experiments.
For the input feature vectors to the attention network, we
convert the pre-trained word embeddings to hidden representations through GRU implemented with the Theano library.6 The size of the hidden units for each layer is 50 for
all three datasets. We use a 2-layer attention network for experiments. For each layer, the ﬁrst dimension K of tensors
is set to be 20 for S1 and S3 (15 for S2).We use a ﬁxed
learning rate for all experiments: 0.07 for S1, S3, and 0.1
for S2. To avoid overﬁtting, the network is regularized with
dropout. We follow the idea of which shows that partial dropout (only apply
dropout to non-recurrent parameters) is better than applying
dropout to all parameters for RNN. The dropout rate is set
to be 0.5 for non-recurrent parameters of GRU. Note that all
the above parameters are chosen through cross-validation.
Experimental Results
We compare CMLA with the following baseline models:
• DLIREC, IHS RD, EliXa: the top performing systems for
S1, S2 in SemEval Challenge 2014, and S3 in SemEval
Challenge 2015, respectively.
• LSTM: an LSTM network built on top of word embeddings proposed by . The settings are the same as .
• WDEmb: the model proposed by using
word and dependency path embeddings combined with
linear context embedding features, dependency context
embedding features as CRF input.7
• RNCRF: the joint model with CRF and recursive neural
network proposed by , which has been
shown to outperform CRFs with hand-crafted features.
4 
5 challenge
6 
7We report the original result from as the
source code is not available.
Table 2: Comparison results in terms of F1 scores. AS (OS)
refers to aspect (opinion) terms extraction.
• WDEmb*, RNCRF*: the corresponding models with additional human-engineered linguistic features.
The comparison results in terms of F1 scores are shown
in Table 2. We report results for both aspect terms extraction (AS) and opinion terms extraction (OP) for all the three
datasets. To make fair comparisons, we use the same corpus
as in LSTM, RNCRF, RNCRF* for training word embeddings, and same training set with both aspect and opinion
labels. Among deep-learning-based models, the models that
combine neural network with CRF (i.e., WDEmb and RN-
CRF) perform better than LSTM because of the incorporation of dependency structure. It is clear that CMLA achieves
the state-of-the-art results for most of the time without any
pre-extracted linguistic/syntactic information. Speciﬁcally,
CMLA outperforms WDEmb by 0.98%, 3.12% and 1.61%,
and RNCRF by 1.24%, 0.97% and 3.67% for aspect extraction on S1, S2 and S3, respectively. Even compared with
the deep models with additional hand-crafted features, i.e.,
WDEmb* and RNCRF*, CMLA still gets 0.32%, 2.64% and
1.00% improvement over WDEmb* for aspect extraction on
S1, S2 and S3, and 0.36% and 2.99% increase over RNCRF*
for aspect extraction on S1 and S3, respectively. Moreover,
the improvements over RNCRF and RNCRF* are all signiﬁcant (p<0.01), except for the aspects extraction on S1
and S2 over RNCRF*. Note that besides linguistic features,
WDEmb* and RNCRF* also require dependency parsers to
perform the task. Therefore, CMLA is more effective and
simpler to implement.
To show the effect of the number of layers, we present experimental results varying the number of layers in Table 4.
The best results are obtained with 2 layers. With only one
layer, the results for aspect extraction are 0.39%, 0.52% and
1.46% inferior than the best scores on S1, S2 and S3, respectively, but they are still comparable with other baselines
shown in Table 2. Similar observations can be found for the
results with 3 layers. This shows that CMLA with 2 layers is
enough to exploit most of the relations among input tokens.
We also conducted experiments to explicitly show the advantage of coupling the learning of aspect and opinion attentions. The second part in Table 4 speciﬁes different setups
of the model. ASL refers to the multi-layer network with
only aspect attention and is trained with aspect labels only.
We can see that even without opinion labels, the network
still proves comparable and even superior than deep models
best spicy tuna
great asian salad
decent menu
dessert pizza
highlyrecommend
friendly owners
Figure 3: Visualization of attention weights for different tokens within a sequence.
Prediction with CMLA
Prediction with RNCRF
also stunning “colors” and speedy
also stunning colors and speedy
Only 2 “usb ports” ... seems kind of limited
Only 2 “usb ports” ... seems kind of limited
strong “build” though which really adds to its “durability”
strong “build” though which really adds to its durability
Save room for “deserts” - they’re to die for
Save room for “deserts” - they’re to die for
You must try “Odessa stew” or “Rabbit stew”; “salads” - all good
You must try “Odessa stew or Rabbit stew”; salads - all good
Table 3: Prediction comparison between CMLA and RNCRF
ASL+OPL 84.14
Table 4: Comparisons under varying layers and setups.
without linguistic features for aspect terms extraction shown
in Table 2. This shows that multi-layer attentions with tensors is advantageous for exploiting interactions. ASL+OPL
in Table 4 trains the aspect attention and opinion attention
independently using (1) where each attention predicts one of
the three labels. The results of ASL+OPL in terms of aspect
extraction are similar to ASL, which shows that the additional opinion labels have little effect on aspect extraction if
they are not interactively trained. By coupling the aspect and
opinion attentions, CMLA achieves the best performance.
As a core component, an attention computes a score for
each token to indicate its correlation with the corresponding prototype. We visualize the actual attention scores for
the tokens of 4 sentences in Figure 3. The y-axis represents the scores before normalization which can be positive
or negative, but only the magnitude matters. Higher scores
mean larger correlations with the aspect/opinion prototype.
As the aspect and opinion attention have different sets of
parameters, the scores can correspond to different ranges of
the values. Tokens in purple (blue) are the ground-truth aspect (opinion) terms. Obviously, purple tokens correspond to
large scores for aspect extraction (purple bars with large values), and blue tokens correspond to large scores for opinion
extraction (blue bars with large values). All the other nonrelevant terms have lower scores. This shows that our model
ZRUGHPEHGGLQJGLPHQVLRQ
(a) On word embedding.
WHQVRUGLPHQVLRQ
(b) On tensor interaction.
Figure 4: Sensitivity studies for data S1.
is able to extract terms of interest.
As mentioned previously, CMLA is able to extract target
terms without any dependency parser, and hence does not
depend on the quality of the parsing results. To show that,
we pick a few example reviews from the test datasets as presented in Table 3. The left and right column show the prediction results from the proposed model and RNCRF , respectively, where predicted opinions are made
italic, and aspects are “quoted”. Obviously, the listed reviews are not formal enough to be parsed correctly. Hence,
RNCRF fails to extract some of the targets, unlike CMLA
which identiﬁes all possible target terms.
To show the robustness of CMLA, we provide two sensitivity studies on word embedding dimensions and the number of different interactions within a 3-dimensional tensor
on S1 in Figure 4. From the plot, we can see that the performances for both aspect and opinion terms extraction are
relatively stable when varying word embedding dimensions,
with the highest scores achieved at 200. For the number of
tensor interactions, the model attains the best performance
at 20 for aspect extraction and 10 for opinion extraction.
Conclusion
We present a novel end-to-end network with coupled multilayer attentions, CMLA, for aspect-opinion co-extraction,
which does not require any parsers or linguistic resources.
Different from traditional attention network, we propose
coupled attentions to exploit the correlations among input tokens, especially between aspect and opinion terms,
through tensor operators. Moreover, the multi-layer structure helps to extract non-obvious targets with indirect relations. Experimental results on 3 benchmark datasets verify
the effectiveness of CMLA.
Acknowledgements
This research is partially funded by the Economic Development Board and the National Research Foundation of
Singapore. Sinno J. Pan thanks the support from the NTU
Singapore Nanyang Assistant Professorship (NAP) grant
M4081532.020.