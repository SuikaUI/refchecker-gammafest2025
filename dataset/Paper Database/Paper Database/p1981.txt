Veriﬁcation by Abstract Interpretation
Patrick Cousot
École normale supérieure, Département d’informatique
45 rue d’Ulm, 75230 Paris cedex 05, France
 , www.di.ens.fr/~cousot
Dedicated to Zohar Manna, for his 26th birthday.
Abstract. Abstract interpretation theory formalizes the idea of abstraction of mathematical structures, in particular those involved in the speciﬁcation of properties and proof methods of computer systems. Veriﬁcation by abstract interpretation is illustrated on the particular cases of
predicate abstraction, which is revisited to handle inﬁnitary abstractions,
and on the new parametric predicate abstraction.
Introduction
Abstract interpretation theory formalizes the idea of abstraction
of mathematical structures, in particular those involved in the speciﬁcation of
properties and proof methods of computer systems.
Veriﬁcation by abstract interpretation is illustrated on the particular cases
of predicate abstraction (where the ﬁnitary program-speciﬁc ground
atomic propositional components of inductive invariants have to be provided)
which is revisited (in that it is derived by systematic approximation of the concrete semantics of a programming language using an inﬁnitary abstraction) and
on the new parametric predicate abstraction, a program-independent generalization (where parameterized inﬁnitary predicates are automatically combined by
reduction and instantiated to particular programs by approximation).
Elements of Abstract Interpretation
Let us ﬁrst recall a few elements of abstract interpretation from .
Properties and Their Abstraction. Given a set Σ of objects (such
as program states, execution traces, etc.), we represent properties P of objects
s ∈Σ as sets of objects P ∈℘(Σ) (which have the considered property). Consequently, the set of properties of objects in Σ is a complete Boolean lattice ⟨℘(Σ),
⊆, ∅, Σ, ∪, ∩, ¬⟩. More generally, and up to an encoding, the object properties
are assumed to belong to a complete lattice ⟨A, ⊑, ⊥, ⊤, ⊔, ⊓⟩.
By “abstraction”, we understand a reasoning or (mechanical) computation on
objects such that only some of the properties of these objects can be used. Let
us call concrete the general properties in A. Let A ⊆A be the set of abstract
properties that can be used in the reasoning or computation. So, abstraction
consists in approximating the concrete properties by the abstract ones. There
are two possible directions of approximation. In the approximation from above,
P ∈A is over-approximated by P ∈A such that P ⊑P. In the approximation
from below, P ∈A is under-approximated by P ∈A such that P ⊑P. Obviously
these notions are dual since an approximation from above/below for ⊑/⊒is an
inverse approximation from below/above for ⊒/⊑. Moreover, the complement
dual of an approximation from above/below for P is an approximation from
below/above for ¬P. Therefore, from a purely mathematical point of view, only
approximations from above need to be presented.
We require ⊤∈A to avoid that some concrete properties may have no
abstraction (e.g. when A = ∅). Hence any concrete property P ∈A can always
be approximated from above (by ⊤i.e. Σ, “true” or “I don’t know”). For best
precision we want to use minimal abstractions P ∈A, if any, such that P ⊑P
and @P ′ ∈A : P ⊑P ′ Ĺ P. If, for economy, we would like to avoid trying all
possible minimal approximations, we can require that any concrete property P ∈
A has a best abstraction P ∈A, that is P ⊑P and ∀P
′ ∈A : P ⊑P
(otherwise see alternatives in ). By deﬁnition of the meet ⊓, this hypothesis
is equivalent to the fact that the meet of abstract properties should be abstract
P = d{P ′ ∈A | P ⊑P ′} ∈A (since otherwise d{P ′ ∈A | P ⊑P ′} would have
no best abstraction).
Moore Family-Based Abstraction. The hypothesis that any concrete
property P ∈A has a best abstraction P ∈A implies that the set A of abstract
properties is a Moore family [11, Sec. 5.1] that is, by deﬁnition, A is closed under
meet i.e. Mc(A) = A where the Moore-closure Mc(X)
∆= {d S | S ⊆X} is the
⊆-least Moore family containing A and the set image f(X) of a set X ⊆D by
a map f ∈D 7→E is f(X)
∆= {f(x) | x ∈X}. In particular T ∅= ⊤∈A so
that any Moore family has a supremum. If the abstract domain A is a Moore
family of a complete lattice ⟨A, ⊑, ⊥, ⊤, ⊔, ⊓⟩then it is a complete meet subsemilattice ⟨A, ⊑, ⊓A, ⊤, λS· ⊓{P ∈A | ⊔S ⊆P}, ⊓⟩of A. The complete
lattice of abstractions ⟨Mc(℘(A)), ⊇, A, {⊤}, λS· Mc(∪S), ∩⟩is the set of all
abstractions i.e. of Moore families on the set A of concrete properties. T
the most concrete among the abstract domains of Mc(℘(A)) which are abstractions of all the abstract domains {Ai | i ∈I} ⊆Mc(℘(A)). Mc(S
i∈I Ai) is the
most abstract among the abstract domains of Mc(℘(A)) which are more concrete than all the Ai’s and therefore isomorphic to the reduced product [11, Sec.
10.1]. The disjunctive completion of an abstract domain A is the most abstract
domain Dc(A) = Mc({⊔X | X ⊆A}) containing all concrete disjunctions of
the abstract properties of A [11, Sec. 9.2]. A is disjunctive if and only if Dc(A)
Closure Operator-Based Abstraction. The map ρA mapping a concrete property P ∈A to its best abstraction ρA(P) in the Moore family A is
∆= d{P ∈A | P ⊆P}. It is a closure operator [11, Sec. 5.2] (which is extensive (∀P ∈A : P ⊑ρ(P)), idempotent (∀P ∈A : ρ(ρ(P)) = ρ(P)) and monotone (∀P, P ′ ∈A : P ⊑P ′ ⇒ρ(P) ⊑ρ(P ′))) such that P ∈A ⇔P = ρA(P)
hence A = ρA(A). ρA is called the closure operator induced by the abstraction
A. Closure operators are isomorphic to their ﬁxpoints hence to the Moore families. Therefore, any closure operator ρ on the set of properties A induces an
abstraction ρ(A). The abstract domain A = ρ(A) deﬁned by a closure operator
ρ on a complete lattice of concrete properties ⟨A, ⊑, ⊥, ⊤, ⊔, ⊓⟩is a complete
lattice ⟨ρ(A), ⊑, ρ(⊥), ⊤, λS· ρ(⊔S), ⊓⟩. The set uclo(A 7→A) of all abstractions, i.e. isomorphically, closure operators ρ on the set A of concrete properties
is the complete lattice of abstractions for pointwise inclusion ⟨uclo(A 7→A), ˙⊑,
λP· P, λP· ⊤, λS· ide( ˙⊔S), ˙⊓⟩where for all ρ, η ∈uclo(A 7→A), {ρi | i ∈I}
⊆uclo(A 7→A) and x ∈A, ρ ˙⊆η
∆= ∀x ∈A : ρ(x) ⊆η(x) ⇔η(A) ⊆ρ(A), the
i∈I ρi)(x)
i∈I ρi(x) is the reduced product and the lub ide( ˙F
where ide(ρ) = lfp
◦f is the ˙⊆-least idempotent operator on A ˙⊆greater than ρ satisﬁes ide( ˙F
i∈I ρi)(x) = x ⇔∀i ∈I : ρi(x) = x. The disjunctive completion of a closure operator ρ ∈uclo(A 7→A) is the most abstract
closure Dc(ρ) = ˙⊔{η ∈uclo(A 7→A) ∩A
7−→A | η ˙⊑ρ} which is more precise than ρ and is a complete join morphism (i.e. f ∈A
7−→A if and only if
∀X ⊆A : f(⊔X) = ⊔f(X)) [11, Sec. 9.2].
Galois Connection-Based Abstraction. For closure operators ρ, we
have ρ(P) ⊑ρ(P ′) ⇔P ⊑ρ(P ′) stating that ρ(P ′) is an abstraction of a
property P if and only if it ⊑-approximates its best abstraction ρ(P). This can
be written ⟨A, ⊑⟩−−→
⟨ρ(A), ⊑⟩where 1 is the identity and ⟨A, ⊑⟩−−−→
⊑⟩means that ⟨α, γ⟩is a Galois surjection, that is: ∀P ∈A, P ∈D : α(P) ⊑
P ⊑γ(P) and α is onto (equivalently α ◦γ = 1 or γ is one-to-one).
Reciprocally if ⟨A, ⊑⟩−−→
⟨ρ(A), ⊑⟩holds then ρ is a closure operator so
that this can be taken as an equivalent deﬁnition of closure operators.
We can deﬁne an abstract domain as an isomorphic representation D of the set
A ⊆A = ρ(A) of abstract properties (up to some order-isomorphism ι). Then,
with such an encoding ι, we have the Galois surjection1 ⟨A, ⊑⟩−−−−→
More generally, the correspondence between concrete and abstract properties can
be established by an arbitrary Galois surjection [11, Sec. 5.3] ⟨A, ⊑⟩−−−→
⊑⟩. This is equivalent to the deﬁnition of the abstract domain A
∆= α ◦γ(D)
by the closure operator α ◦γ so the use of a Galois surjection is equivalent to
that of a closure operator or a Moore family, up to the isomorphic representation
α ◦γ of the abstract domain A ∼= D.
Relaxing the condition that α is onto means that the same abstract property
can have diﬀerent representations. Then ⟨A, ⊑⟩−−−→
⟨D, ⊑⟩that is to say
1 Also called Galois insertion since γ is injective.
∀P ∈A, P ∈D : α(P) ⊑P
P ⊑γ(P)2 or equivalently α is monotone
(∀x, x′ ∈L : x ⊑x′ ⇒α(x) ⊑α(x′), thus α preserves concrete implication ⊑
in the abstract), γ is monotone (∀y, y′ ∈M : y ⊑y′ ⇒γ(y) ⊑γ(y′), thus γ
preserves abstract implication ⊑in the concrete), γ ◦α is extensive (∀x ∈L :
x ⊑γ(α(x)), so ρ
∆= γ ◦α and the approximation is from above) and α ◦γ is
reductive (∀y ∈M : α(γ(y)) ⊑y, so concretization can loose no information).
The composition α ◦γ is the identity if and only if α is onto or equivalently γ
is one-to-one. If α is not onto, then the reduction of the abstract domain [12,
Prop. 10] consists in considering the quotient D/≡γ by the equivalence Q ≡γ Q′
⇔γ(Q) = γ(Q′), so that ⟨A, ⊑⟩−−−−→
⟨D/≡γ, ⊑≡γ⟩is a Galois surjection
where α≡(P)
∆= [α(P)]≡γ, [Q]≡γ
∆= {Q′ ∈D | Q ≡γ Q′}, γ≡([Q]≡γ)
∆= γ(Q) and
[P]≡γ ⊑≡γ [Q]≡γ ⇔∃P ′ ∈[P]≡γ : ∃Q′ ∈[Q]≡γ : P ′ ⊑Q′.
Observe that the inverse dual of ⟨A, ⊑⟩−−−→
⟨D, ⊑⟩is ⟨D, ⊒⟩−−−→
The composition of Galois connections ⟨A, ⊑⟩−−−→
⟨D, ⊑⟩and ⟨D, ⊑⟩−−−→
⟨D, ⊑⟩is a Galois connection ⟨A, ⊑⟩−−−−−−→
Function Abstraction. Given a complete lattice ⟨A, ⊑, ⊥, ⊤, ⊔, ⊓⟩and
an abstraction ρ on A, the best abstraction of a monotone operator f ∈A
on the complete lattice A is ρ ◦f ∈ρ(A)
7−→ρ(A) [11, Sec. 7.2]. Indeed given any
other f ∈ρ(A)
7−→ρ(A) and x ∈ρ(A) the soundness requirement f(x) ⊒f(x)
implies f(x) ⊑ρ ◦f(x) since ρ is idempotent whence ρ ◦f(x) ⊑ρ ◦f(x) proving
ρ ◦f ˙⊑f so that ρ ◦f is more precise than any other sound abstraction f ∈
7−→ρ(A) of f ∈A
7−→A. In terms of Galois connections, ⟨A, ⊑⟩−−−→
⊑⟩implies ⟨A
7−→A, ˙⊑⟩−−−−−−−−−→
←−−−−−−−−−
λF· α◦F ◦γ
λF· γ◦F ◦α
7−→A, ˙⊑⟩.
Fixpoint Abstraction. Given a complete lattice ⟨A, ⊑, ⊥, ⊤, ⊔, ⊓⟩and
a monotone operator f ∈A
7−→A on the complete lattice A, its least ﬁxpoint
a f greater than a ∈A is deﬁned, if it exists, as a ⊑lfp
a f = f(lfp
∀x ∈A : a ⊑x = f(x) ⇒lfp
a f ⊑x. If a ⊑f(a) then lfp
a f does exist and is
the limit of the ultimately stationary transﬁnite sequence f η, η ∈O deﬁned by
∆= a, f η+1
∆= f(f η), for successor ordinals η + 1 and f λ
η<λ f η, for limit
ordinals λ . In particular the least ﬁxpoint of f is lfp
Given f ∈A
7−→A on the complete lattice A and an abstraction ρ, we would
like to approximate lfp
a f in ρ(A). The best abstraction ρ(lfp
a f) is in general
not computable since neither lfp
a f nor ρ are. However, following [11, Sec. 7.1], a
computable pointwise over approximation f is suﬃcient to check for an over approximation of lfp
a f in ρ(A) ∀y ∈ρ(A) :
 ρ ◦f ˙⊑f ∧ρ(a) ⊑y ∧f(y) ⊑y
2 In absence of best approximation, one can use a semi-connection, requiring only
∀P ∈A, P ∈D : α(P) ⊑P ⇒P ⊆γ(P), see .
. Moreover the ⊑-least such y is lfp
ρ(a) ρ ◦f (which does exist since
a ⊑f(a) implies ρ(a) ⊑ρ ◦f(ρ(a))) such that ρ(y) = y. This means that we can
abstract ﬁxpoints by ﬁxpoints. In terms of Galois connections, if ⟨A, ⊑⟩−−−→
7−→A and f ∈A
7−→A then f is a sound upper approximation of
f if and only if α ◦f ˙⊑f ◦α or equivalently α ◦f ◦γ ˙⊑f where α ◦f ◦γ is
the best sound upper approximation of f. This implies that α(lfp
The approximation is said to be complete if and only if α ◦f = f ◦α in which
case α(lfp
a f) = lfp
An iteration for an operator f ∈A
7−→A on the complete lattice A from
a ∈A with widening
∆= a, Xn+1
∆= (f(Xn) ⊑Xn ? Xn : Xn ` f(Xn))
 where the conditional notation is (tt ? t : f) = t, (ﬀ? t : f) = f and
(b1 ? t1 | b2 ? t2 : f) = (b1 ? t1 : (b2 ? t2 : f)). If the widening ensures
that all such iterations are stationary at a ﬁnite rank ℓ< ω and a ⊑Xℓthen
f(Xℓ) ⊑Xℓand so lfp
a f ⊑Xℓ. Widenings are also useful in absence of lubs
for ascending chains in which case one requires in addition that X ⊑X
Application to Ground Predicate Abstraction
Predicate abstraction was introduced by for computing invariants by abstract interpretation, following among others where the general idea is
that the atomic elements of the abstract domain are abstract predicates over
program variables which interpretation is a set of program states (maybe memory states attached to program points). Predicate abstraction is restricted to a
ﬁnitary abstraction . For all such ﬁnite abstract domains, the transfer functions can be computed using a theorem prover (α ◦f ◦γ(P) is overapproximated by f(P) = ⊓{Q ∈A | f ◦γ(P) ⊑γ(Q)} where the Q ∈A are
enumerated and the prover is asked for the proof f ◦γ(P) ⊑γ(Q). Q is skipped
if the prover fails which yields an overapproximation). All such ﬁnite abstract
domains can be encoded with booleans so as to reuse existing model-checkers for
ﬁxpoint computations. We revisit predicate abstraction by systematic approximation of the concrete semantics of a programming language using an inﬁnitary
abstraction to ground (as opposed to parametric) predicates.
Syntax and Concrete Reachability Semantics of the Programming Language. We consider a simple imperative programming language with
programming variables X ∈X, arithmetic expressions E ∈E (? is the random
choice), Boolean expressions B ∈B and commands C ∈C:
E ::= 1 | X | ? | E1 −E2,
B ::= E1 < E2 | ¬B1 | B1 ∧B2,
C ::= skip | X := E | C1 ; C2 | if B then C1 else C2 | whileB do C1 .
varJEK (respectively varJBK, varJCK) is the set of programming variables appearing in the (Boolean) expression E ∈E (B ∈B) or command C ∈C. Each
command C ∈C has unique labels labJCK to denote its execution points. These
labels include an entry label atJCK, an exit label afterJCK and possibly labels of
sub-commands inJCK. We assume that labJCK = {atJCK} ∪inJCK ∪{afterJCK},
atJCK ̸= afterJCK, {atJCK, afterJCK} ∩inJCK = ∅and for C1 ; C2, we have
labJC1K ∩labJC2K = {afterJC1K} = {atJC2K}.
We let D be the domain of value of the programming variables X. The semantics EJEK ∈M 7→℘(D) of expressions E ∈E is deﬁned on all memory states
∆= V 7→D where V is any set of programming variables including all such
variables appearing in E, that is varJEK ⊆V. We deﬁne EJ1Km
∆= {1}, EJ?Km
∆= {m(X)} and EJE1−E2Km
∆= {v1−v2 | v1 ∈EJE1Km∧v2 ∈EJE2Km}.
The semantics BJBK ∈℘(M) and BJBK ∈℘(M) of Boolean expressions
B ∈B is deﬁned for memory states in M
∆= V 7→D where varJBK ⊆V. BJBK
deﬁnes the set of memory states in which B may be true while BJBK deﬁnes
the set of memory states in which B may be false. We have BJBK ∪BJBK = M
but maybe BJBK ∩BJBK ̸= ∅because of non-determinism as in ? < 1. We deﬁne
BJE1 < E2K
∆= {m ∈M | ∃x1, x2 ∈D : x1 ∈EJE1Km ∧x2 ∈EJE2Km ∧x1 < x2},
∆= BJBK, BJB1∧B2K
∆= BJB1K∩BJB2K, BJE1<E2K
∆= {m ∈M | ∃x1, x2 ∈
D : x1 ∈EJE1Km ∧x2 ∈EJE2Km ∧x1 ≥x2} BJ¬B1K
∆= BJBK and BJB1 ∧B2K
BJB1K ∪BJB2K.
The reachability semantics RJCK of a command C ∈C is deﬁned on any set
of states Σ = ⟨L, M⟩such that L is a set of labels and M
∆= V 7→D is a set of
memory states on variables V chosen such that labJCK ⊆L and varJCK ⊆V. The
reachability semantics for the command C is then ⟨Σ, RJCK⟩. For a program C,
we can choose Σ = ⟨labJCK, varJCK 7→D⟩.
∆= match C with
skip →P ∪{⟨afterJCK, m⟩| ⟨atJCK, m⟩∈P}
X := E →P ∪{⟨afterJCK, m[X := v]⟩| ⟨atJCK, m⟩∈P ∧v ∈EJEKm}
C1 ; C2 →RJC1KP ∪RJC2K{⟨atJC2K, m⟩| ⟨afterJC1K, m⟩∈RJC1KP}
C = if B then C1 else C2 →P ∪P1 ∪P2 ∪Pe
∆= RJC1K{⟨atJC1K, m⟩| ⟨atJCK, m⟩∈P ∧m ∈BJBK}
∆= RJC2K{⟨atJC2K, m⟩| ⟨atJCK, m⟩∈P ∧m ∈BJBK}
∆= {⟨afterJCK, m⟩| ⟨afterJC1K, m⟩∈P1 ∨⟨afterJC2K, m⟩∈P2}
C = whileB do C1 →let
⊆λX· RJC1K({⟨atJC1K, m⟩|
(⟨atJCK, m⟩∈P ∨⟨afterJC1K, m⟩∈X) ∧m ∈BJBK})
P ∪P1 ∪{⟨afterJCK, m⟩| (⟨atJCK, m⟩∈P ∨⟨afterJC1K, m⟩∈P1) ∧m ∈BJBK}
Ground Abstract Predicates. Predicate abstraction is deﬁned by a
set P of syntactic predicates that, for simplicity, we choose to be Boolean expressions P ⊆B. We deﬁne varJPK
p∈P varJpK. The set P may be inﬁnite as e.g. in the case of Kildall’s constant propagation for which P
{tt, ﬀ} ∪S
v∈D{X = v}.
Predicate abstraction uses a prover to prove theorems t ∈T with interpretation I ∈T 7→℘(M) assigning an interpretation IJtK to all syntactic predicates
t ∈T with syntax (p ∈P):
t ::= p | tt | ﬀ| X | ¬t1 | t1 ⇒t2 |
ti | ∀X : t1
with free variables varJtK and semantics IJtK ∈℘(M) deﬁned by IJpK
∆= M, IJﬀK
∆= ∅, IJX ∈EK
∆= {m ∈M | m(X) ∈EJEKm}, IJ¬tK
{m ∈M | m ̸∈IJtK}, IJV
i∈∆IJtiK, IJt1 ⇒t2K
∆= {m ∈M | m ̸∈
IJt1K ∨m ∈IJt2K} and IJ∀X : tK
∆= {m ∈M | ∀v ∈D : m[X := v] ∈IJtK}.
Variable substitution t[X/X′] is deﬁned as usual with renaming of conﬂicting
dummy variables such that:
X ̸∈varJtK ⇒t[X/X′] = t,
EJE[X/X′]Km = EJEKm[X := m(X′)],
X ̸= Y ∧Y ̸∈varJtK ⇒IJ∀X : tK = IJ∀Y : (t[X/Y])K,
Z ̸∈varJtK ∪{X, Y} ⇒IJ(∀X : t)[Y/X]K = IJ∀Z : (t[X/Z][Y/X)]K,
IJt[X/X′]K = {m | m[X := m(X′)] ∈IJtK} .
The prover is assumed to be sound in that ∀t ∈T : proverJtK ⇒(IJtK = M).
(The inverse is not valid since provers are incomplete.)
Ground Predicate Abstraction. Given a set of states in A where Σ =
⟨L, M⟩, we can use an isomorphic representation associating sets of memory
states to labels thank to the following correspondence:
⟨℘(L × M), ⊆⟩−−−→
⟨L 7→℘(M), ˙⊆⟩
where α↓(P)
∆= λℓ·{m | ⟨ℓ, m⟩∈P}, γ↓(Q)
∆= {⟨ℓ, m⟩| ℓ∈L ∧m ∈Qℓ} and ˙⊆
is the pointwise ordering Q ˙⊆Q′ if and only if ∀ℓ∈L : Qℓ⊆Q′
A memory state property Q ∈℘(M) is approximated by the subset of predicates p of P which holds when Q holds (formally Q ⊆BJpK). This deﬁnes a
Galois connection:
⟨℘(M), ⊆⟩−−−−→
where αP(Q)
∆= {p ∈P | Q ⊆BJpK} and γP(P)
∆= T{BJpK | p ∈P} = IJV PK.
Observe that in general γP is not one-to-one (e.g. γP({X = 1, X ≥1}) = γP({X =
1}) so αP is not onto3. By pointwise extension, we have:
3 In a Galois connection ⟨L, ≤⟩−−−→
⟨M, ⊑⟩, α is onto if and only if γ is one-to-one if
and only if γ ◦α is the identity so, by duality, γ is onto if and only if α is one-to-one
if and only if α ◦γ is the identity.
⟨L 7→℘(M), ˙⊆⟩−−−−→
⟨L 7→℘(P), ˙⊇⟩
where ˙αP(Q)
∆= λℓ· αP(Qℓ), ˙γP(P)
∆= λℓ· γP(Pℓ) and P ˙⊇P ′
∆= ∀ℓ∈L : Pℓ⊇
ℓ. By composition, we get:
⟨℘(L × M), ⊆⟩−−−→
⟨L 7→℘(P), ˙⊇⟩
where α(P)
∆= ˙αP ◦α↓(P) = λℓ·{p ∈P | {m | ⟨ℓ, m⟩∈P} ⊆IJpK} and γ(Q)
γ↓◦˙γP = {⟨ℓ, m⟩| ℓ∈L∧m ∈γP(Qℓ)} = {⟨ℓ, m⟩| ℓ∈L ∧∀p ∈Qℓ: m ∈IJpK}.
If P is assumed to be ﬁnite then characteristic functions of subsets of P can
be encoded as Boolean vectors thus later allowing for the reuse of model-checker
to solve ﬁxpoint equations. However, this encoding of sets cannot be used to
encode inﬁnite sets such as Kildall’s constant propagation .
Abstract Reachability Semantics of Commands C ∈C. Given a set
of abstract predicates P, the abstract reachability semantics RJCK ∈℘(P) 7→
(labJCK 7→℘(P)) of command C ∈C is
RJCKP = α(RJCK({atJCK} × γP(P)))
that is the abstraction of the reachable states of C from its entry point atJCK in
initial memory states m ∈γP(P).
Because of undecidability, whence theorem prover incompleteness, we look
for a ˙⊇-over-approximation RJCKP such that:
α(RJCK({atJCK} × γP(P))) ˙⊇RJCKP
RJCK({atJCK} × γP(P)) ⊆γ(RJCKP)
We proceed by structural induction on the syntax of commands C ∈C. For
short, we only consider the case of assignment and iteration.
— For the assignment X := E, we have
RJX := EKP
= α(RJX := EK({atJX := EK} × γP(P)))
= let P = {atJX := EK} × γP(P) in
α(P ∪{⟨afterJCK, m[X := v]⟩| ⟨atJCK, m⟩∈P ∧v ∈EJEKm})
= let P = {atJX := EK} × γP(P) in
α(P) ˙∩α({⟨afterJCK, m[X := v]⟩| ⟨atJCK, m⟩∈P ∧v ∈EJEKm})
Hby (4), so that α is a complete join morphismI
Let us go on with the ﬁrst term α(P) of the form P = {locJCK} × γP(P)
with loc ∈{at, after}.
α({locJCK} × γP(P ))
= λℓ·{p ∈P | {m | ⟨ℓ, m⟩∈{locJCK} × γP(P )} ⊆IJpK}
= λℓ·(ℓ= locJCK ? {p ∈P | γP(P) ⊆IJpK} : {p ∈P | ∅⊆IJpK) HconditionalI
= λℓ·(ℓ= locJCK ? {p ∈P |
{BJpK | p ∈P} ⊆IJpK} : P)
Hdef. γP and ⊆I
= λℓ·(ℓ= locJCK ? {p ∈P | IJ
P ⇒pK} : P)
˙⊇λℓ·(ℓ= locJCK ? {p ∈P | proverJ
P ⇒pK} : P)
Hprover soundnessI
˙⊇λℓ·(ℓ= locJCK ? P : P)
Hless precise but avoids a call to the proverI
Given P = {atJX := EK} × γP(P), the second term is
α({⟨afterJX := EK, m[X := v]⟩| ⟨atJX := EK, m⟩∈P ∧v ∈EJEKm})
= α({⟨afterJX := EK, m[X := v]⟩| m ∈γP(P) ∧v ∈EJEKm})
= λℓ·{p ∈P | {m′ | ⟨ℓ, m′⟩∈{⟨afterJX := EK, m[X := v]⟩| m ∈γP(P) ∧v ∈
EJEKm}} ⊆IJpK}
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m[X := v] | m ∈γP(P) ∧v ∈EJEKm} ⊆
IJpK} : P)
Hdef. conditional and ⊆I
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m[X := v] | m ∈
{BJpK | p ∈P} ∧v ∈
EJEKm} ⊆IJpK} : P)
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m[X := v] | m ∈IJ
PK ∧v ∈EJEKm} ⊆
IJpK} : P)
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m[X := v′][X := v] | m[X := v′] ∈
PK ∧v ∈EJEKm[X := v′]} ⊆IJpK} : P)
Hby letting v′ = m(X) so that
m = m[X := v′]I
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m[X := v] | ∃v′ ∈D : m[X := v′] ∈
PK ∧v ∈EJEKm[X := v′]} ⊆IJpK} : P)
Hsince m[X := v′][X := v] =
m[X := v]I
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m[X := v] | m[X := m(X′)] ∈IJ
EJEKm[X := m(X′)]} ⊆IJpK} : P)
Hby letting v′ = m(X′) where X′ is
a fresh variable such that X′ ̸∈{X} ∪varJEK ∪varJPK so that X′ ̸∈varJPK and
neither IJV PK, EJEK nor IJpK depend upon the value of X′I
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m′ | m′[X := m′(X′)] ∈IJ
PK ∧m′(X) ∈
EJEKm′[X := m′(X′)]} ⊆IJpK} : P)
Hby letting m′ = m[X := v] so that
v = m′(X), m(X′) = m′(X′) and m[X := m(X′)] = m′[X := m′(X′)]I
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m ∈M | ∃v ∈D : m[X := m(X′)] ∈
P)K ∧m(X) ∈EJEKm[X := v]} ⊆IJpK} : P)
Hby letting m = m′ and
v = m′(X′)I
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m ∈M | ∃v ∈D : m[X′ := v][X :=
m(X′)] ∈IJ(
P)K ∧m(X) ∈EJEKm[X := v]} ⊆IJpK} : P)
X′ ̸∈varJPKI
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m ∈M | ∃v ∈D : m[X′ := v][X := m[X :=
v](X′)] ∈IJ(
P)K ∧m(X) ∈EJEKm[X := v]} ⊆IJpK} : P)
Hsince X ̸= X′ so
m(X′) = m[X := v](X′)I
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m ∈M | ∃v ∈D : m[X′ := v] ∈{m′ |
m′[X := m′(X′)] ∈IJ(
P)K} ∧m(X) ∈EJEKm[X := v]} ⊆IJpK} : P)
def. ∈while letting m′ = m[X := v]I
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m ∈M | ∃v ∈D : m[X′ := v] ∈
P)[X/X′]K ∧m(X) ∈EJEKm[X := v]} ⊆IJpK} : P)
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m ∈M | ∃v ∈D : m[X′ := v] ∈
P)[X/X′]K ∧m[X′ := v](X) ∈EJEKm[X := m[X′ := v](X′)]} ⊆IJpK} : P)
Hdef. m[X := v] and X ̸= X′I
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m ∈M | ∃v ∈D : m[X′ := v] ∈
P)[X/X′]K ∧m[X′ := v](X) ∈EJEKm[X′ := v][X := m[X′ := v](X′)]} ⊆
IJpK} : P)
Hsince X′ ̸∈varJEKI
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m ∈M | ∃v ∈D : m[X′ := v] ∈
P)[X/X′]K ∧m[X′ := v] ∈{m′ ∈M | m′(X) ∈EJEKm′[X := m′(X′)]}} ⊆
IJpK} : P)
Hdef. ∈while letting m′ = m[X′ := v]I
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m ∈M | ∃v ∈D : m[X′ := v] ∈
P)[X/X′]K ∩{m′ ∈M | m′(X) ∈EJEKm′[X := m′(X′)]}} ⊆IJpK} : P)
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m ∈M | ∃v ∈D : m[X′ := v] ∈
P)[X/X′]K ∩{m′ ∈M | m′(X) ∈EJE[X/X′]Km′}} ⊆IJpK} : P)
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m ∈M | ∃v ∈D : m[X′ := v] ∈
P)[X/X′]K ∩IJX ∈E[X/X′]K} ⊆IJpK} : P)
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m ∈M | ∃v ∈D : m[X′ := v] ∈
(P[X/X′])K ∩IJX ∈E[X/X′]K} ⊆IJpK} : P)
Hdef. substitutionI
= λℓ·(ℓ= afterJX := EK ? {p ∈P | {m ∈M | ∃v ∈D : m[X′ := v] ∈
P[X/X′] ∧X ∈E[X/X′]K} ⊆IJpK} : P)
= λℓ·(ℓ= afterJX := EK ? {p ∈P | IJ∃X′ :
P[X/X′] ∧X ∈E[X/X′]K ⊆IJpK} :
= λℓ·(ℓ= afterJX := EK ? {p ∈P | IJ(∃X′ :
P[X/X′] ∧X ∈E[X/X′]) ⇒pK} :
˙⊇λℓ·(ℓ= afterJX := EK ? {p ∈P | proverJ(∃X′ :
P[X/X′] ∧X ∈E[X/X′]) ⇒
Grouping both cases together, we have
RJX := EKP
= λℓ·(ℓ= atJX := EK ? {p ∈P | proverJ
P ⇒pK} : P) ˙∩λℓ·(ℓ= afterJX :=
EK ? {p ∈P | proverJ(∃X′ :
P[X/X′] ∧X ∈E[X/X′]) ⇒pK} : P)
= λℓ· (ℓ= atJCK ? {p ∈P | proverJV P ⇒pK}
| ℓ= afterJX := EK ? {p ∈P | proverJ(∃X′ : V P[X/X′] ∧X ∈E[X/X′]) ⇒pK}
Hdef. ˙∩, conditional and atJCK ̸= afterJCKI
— For tests B, we have:
γP(P ) ∩BJBK
{BJpK | (IJ
PK ∩BJBK) ⊆BJpK}
Hdef. upper boundsI
{BJpK | IJ(
P ∧B) ⇒pK = M}
{BJpK | proverJ(
P ∧B) ⇒pK}
Hprover soundnessI
⊆γP({p | proverJ(
P ∧B) ⇒pK})
Therefore we deﬁne:
∆= {p | proverJ(
P ∧B) ⇒pK}
such that:
γP(RJBKP ) ⊇γP(P ) ∩BJBK
RJBKP ⊆αP(γP(P ) ∩BJBK)
— For the iteration C = whileB do C1, given P ∈L 7→℘(P) and X ⊆Σ =
L × M, we deﬁne:
∆= RJC1K({⟨atJC1K, m⟩| (⟨atJCK, m⟩∈({atJCK} × γP(P)) ∨
⟨afterJC1K, m⟩∈X) ∧m ∈BJBK})
We can now design the abstraction F of F such that α ◦F ˙⊇F ◦α:
= α(RJC1K({atJC1K} × {m | (⟨atJCK, m⟩∈({atJCK} × γP(P)) ∨⟨afterJC1K,
m⟩∈X) ∧m ∈BJBK}))
˙⊇α(RJC1K({atJC1K} × {m | (m ∈γP(P ) ∨⟨afterJC1K, m⟩∈γ ◦α(X)) ∧m ∈
Hby (4) so that γ ◦α is extensive and monotony of RJC1K and αI
˙⊇α(RJC1K({atJC1K} × γP
◦αP({m | (m ∈γP(P) ∨⟨afterJC1K, m⟩∈γ
α(X)) ∧m ∈BJBK})))
HγP ◦αP is extensive, monotony of RJC1K and (4)
so that α is monotoneI
˙⊇α(RJC1K({atJC1K} × γP(αP(γP(P) ∩BJBK) ∩αP({m | ⟨afterJC1K, m⟩∈γ ◦
α(X) ∧m ∈BJBK}))))
HαP is a complete join morphismI
˙⊇α(RJC1K({atJC1K}×γP(αP(γP(P)∩BJBK)∩αP(γP(α(X)afterJC1K)∩BJBK))))
Hdef. of γI
˙⊇α(RJC1K({atJC1K} × γP(RJBKP ∩RJBK(α(X)afterJC1K))))
Hby (8) and
monotony I
˙⊇RJC1K(RJBKP ∩RJBK(α(X)afterJC1K))
Hby induction hypothesis (5)I
We have α(∅) = λℓ· P so that it follows that:
⊆λX· RJC1K({⟨atJC1K, m⟩| (⟨atJCK, m⟩∈P ∨⟨afterJC1K, m⟩∈X)
∧m ∈BJBK}))
λℓ· P λX· RJC1K(RJBKP ∩RJBK(XafterJC1K))
We will need to evaluate:
α({⟨ℓ1, m⟩| ⟨ℓ2, m⟩∈γ(P) ∧m ∈BJBK})
= α({⟨ℓ1, m⟩| m ∈γP(P ℓ2) ∧m ∈BJBK})
= α({ℓ1} × (γP(P ℓ2) ∩BJBK))
Hdef. ∩and ×I
˙⊇α({ℓ1} × γP(RJBKP ℓ2))
Hby (8) and (4), so that α monotoneI
˙αP ◦α↓({ℓ1} × γP(RJBKP ℓ2))
= λℓ· αP({m | ⟨ℓ, m⟩∈{ℓ1} × γP(RJBKP ℓ2))
Hdef. ˙αP and def. α↓I
˙⊇λℓ·(ℓ= ℓ1 ? RJBKP ℓ2 : P)
HαP ◦γP is reductiveI
and therefore for C = whileB do C1:
α(RJCK({atJCK} × γP(P)))
= α(({atJCK} × γP(P )) ∪P1 ∪{⟨afterJCK, m⟩| (m ∈γP(P) ∨⟨afterJC1K, m⟩∈
P1) ∧m ∈BJBK})
˙⊇α({atJCK} × γP(P)) ˙∩P 1 ˙∩α({⟨afterJCK, m⟩
BJBK}) ˙∩α({⟨afterJCK, m⟩| ⟨afterJC1K, m⟩∈P1 ∧m ∈BJBK})
Hby (9) and
(4), so that α is a complete join morphismI
˙⊇λℓ·(ℓ= atJCK ? P : P) ˙∩P 1 ˙∩λℓ·(ℓ= afterJCK ? RJ¬BKP : P) ˙∩
λℓ·(ℓ= afterJCK ? RJ¬BKP afterJC1K : P)
Hby (7), BJBK = BJ¬BK and (10)I
= P 1 ˙∩λℓ·(ℓ= atJCK ? P | ℓ= afterJCK ? RJ¬BKP ∩RJ¬BKP afterJC1K : P)
Hdef ˙∩and conditionalI
— In conclusion of these calculi, we have proved that:
RJCKP ℓ= (ℓ̸∈labJCK ? P : match C, ℓwith
_, atJCK →{p ∈P | proverJ
skip, afterJCK →{p ∈P | proverJ
X := E, afterJCK →{p ∈P | proverJ(∃X′ :
P[X/X′] ∧X ∈E[X/X′]) ⇒pK}
C1 ; C2, _ →let P 1 = RJC1KP and P 2 = RJC2KP 1(afterJC1K) in
P 1(ℓ) ∩P 2(ℓ)
if B then C1 else C2, _ →
let P t = {p ∈P | proverJ(V P ∧B) ⇒pK} and P 1 = RJC1KP t
and P f = {p ∈P | proverJ(V P ∧¬B) ⇒pK} and P 2 = RJC2KP f
in P 1(ℓ) ∩P 2(ℓ) ∩(ℓ= afterJCK ? P 1(afterJC1K) ∩P 2(afterJC2K) : P)
whileB do C1, _ →
let P 1 = gfp
λℓ· P λX· λℓ′·(ℓ′ = atJC1K ? {p ∈P | proverJ((V P ∨
X(afterJC1K)) ∧B) ⇒pK} : P) ˙∩RJC1KX(atJC1K)ℓ′
in P 1(ℓ) ∩(ℓ= afterJCK? {p ∈P | proverJ((V P ∨
P 1(afterJC1K) ∧¬B) ⇒pK} : P)
Reduced Set of Ground Abstract Predicates. Observe that because
of the normalization {p ∈P | proverJV P ⇒pK} of P ∈℘(P), the abstract
domain ⟨℘(P, ⊇⟩can be reduced [12, Prop. 10] to ⟨{{p ∈P | proverJV P ⇒
pK} | P ∈℘(P}, ⊇⟩. The abstract domain ⟨℘(P), ⊇⟩may not be Notherian while
this reduced abstract domain is Notherian. For example, in Kildall’s constant
propagation for a command C, the set of abstract predicates is P = {X =
v | X ∈varJCK ∧v ∈D}. The reduction yields the abstract predicates ∅(“I
don’t know”), P (“false”) and the {X1 = v1, . . . , Xn = vn} (where i ̸= j implies
Xi ̸= Xj). This reduced set of abstract predicates is still inﬁnite but Notherian.
The abstract semantics RJCK can be computed by induction on the structure
of C with a ﬁxpoint iteration in RJwhileB do C1K which is ﬁnite for Notherian
abstract domains (as in which corresponds to a particular chaotic iteration
strategy ). Otherwise the iterative ﬁxpoint computation may not terminate
whence may require to be over approximated by a widening.
Local Ground Abstract Predicates. Instead of choosing the set P of
abstract predicates globally, it can be chosen locally, by choosing a particular
set of abstract predicates Pℓattached to each command label ℓ∈labJCK. Then
terms of the form {p ∈P | proverJP ⇒pK} attached to program point ℓin the
deﬁnition of the abstract predicate transformer RJCK are to be simply replaced
by {p ∈Pℓ| proverJP ⇒pK.
Safety Veriﬁcation of Commands C ∈C. The veriﬁcation that a
command satisﬁes a safety speciﬁcation S ∈labJCK 7→℘(P) consists in checking
for each point ℓ∈labJCK that:
RJCK(S(atJCK))ℓ) ⇒
This is sound since:
∀ℓ∈labJCK : proverJ(
RJCK(S(atJCK))ℓ) ⇒
⇒∀ℓ∈labJCK : IJ(
RJCK(S(atJCK))ℓ) ⇒
Hprover soundnessI
⇒∀ℓ∈labJCK : IJ(
RJCK(S(atJCK))ℓ)K ⊆IJ
Hdef. of II
⇒∀ℓ∈labJCK : γP(RJCK(S(atJCK))ℓ) ⊆γP(S(ℓ))
⇒˙γP(RJCK(S(atJCK))) ˙⊆˙γP(S)
Hdef. ˙γPI
⇒γ↓◦˙γP(RJCK(S(atJCK))) ˙⊆γ↓◦˙γP(S)
Hby monotonyI
⇒γ(RJCK(S(atJCK))) ˙⊆γ(S)
⇒RJCK({atJCK} × γP(S(atJCK))) ⊆γ(S)
⇒∀ℓ∈labJCK : RJCK({atJCK} × γP(S(atJCK)))ℓ⊆γP(S(ℓ))
so that, informally, S(ℓ) holds whenever program point ℓis reached during any
execution of command C starting at point atJCK with an initial memory state
satisfying S(atJCK).
Application to Parametric Predicate Abstraction
The inconvenience of ground predicate abstractions is that the ground predicates
directly refer to the program states and control by explicitly naming program
constants, variables and maybe control points. Consequently, the abstract domain, being program-speciﬁc, has to be redesigned for each new or modiﬁed
program. This design can be partially automatized by reﬁnement techniques, including convergence acceleration by widening , but this alternation of analyzes
and reﬁnements would be costly for precise analysis of large programs. An alternative is to provide program-independent predicates by designing parametric
abstract domains. The presentation is made through a sorting example.
Parametric Abstract Domains. A parametric abstract domain is parameterized so that a particular abstract domain instantiation for a given program is obtained by binding the parameters to the constants, variables, control
points, etc. of this speciﬁc program. For a simple example, Kildall’s parametric
abstract domain for constant propagation is K(C, V ) = Q
X∈V (ℓ) L where
L is Kildall’s complete lattice ⊥⊑v ⊑⊤for all v ∈D. Given a command C,
it is instantiated to K(labJCK, varJCK) where labJCK is the set of labels of command C and varJCK(ℓ) is the set of program variables X which are visible at this
program point ℓof command C.
Parametric Comparison Abstract Domain. We let Dr(X) be a parametric relational integer abstract domain parameterized by a set X of program
and auxiliary variables. This abstract domain is assumed to have abstract operations on r, r1, r2 ∈Dr(X) such as the projection or variable elimination
∃x ∈X : r, disjunction r1 ∨r2, conjunction r1 ∧r2, abstract predicate transformers for assignments and tests, etc (see e.g. ).
Then we deﬁne the parametric comparison abstract domain:
Dlt(X) = {⟨lt(t, a, b, c, d), r⟩| t ∈X ∧a, b, c, d ̸∈X ∧
r ∈Dr(X ∪{a, b, c, d})} .
The meaning γ(⟨lt(t, a, b, c, d), r⟩) of an abstract predicate ⟨lt(t, a, b, c, d), r⟩
is informally that all elements of t between indices a and b are less than any
element of t between indices c and d and moreover r holds:
More formally, there should be a declaration t : array[ℓ, h] of int so that
γ(⟨lt(t, a, b, c, d), r⟩) deﬁnes a set of environments ρ mapping program and auxiliary variables X to their value ρ(X) for which the above concrete predicate holds:
γ(⟨lt(t, a, b, c, d), r⟩) = {ρ | ∃a, b, c, d : ρ(t).ℓ≤a ≤b ≤ρ(t).h
∧ρ(t).ℓ≤c ≤d ≤ρ(t).h
∧∀i ∈[a, b] : ∀j ∈[c, d] : ρ(t)[i] ≤ρ(t)[j] ∧ρ ∈γ(r)}
where the domain of the ρ is X ∪{a, b, c, d} and γ(r) is the concretization of the
abstract predicate r ∈Dr(X ∪{a, b, c, d}) specifying the possible values of the
variables in X and the auxiliary variables a, b, c, d.
Abstract Logical Operations of the Parametric Comparison Abstract Domain. Then the abstract domain must be equipped with abstract
operations such as the implication ⇒, conjunction ∧, disjunction ∨, etc. We
simply provided a few examples.
Abstract Implication. We have ⟨lt(t, a, b, c, d), r⟩⇒r. If r ⇒r′ and a ≤b ≤
c ≤d and e ≤f ≤g ≤h then;
⟨lt(t, a, d, e, h), r⟩⇒⟨lt(t, b, c, f, g), r′⟩
as shown below:
Abstract Conjunction. If t, i, j, k, ℓ̸∈varJrK, then:
r ∧⟨lt(t, a, c, f, h), r′⟩= ⟨lt(t, a, c, f, h), r ∧r′⟩
If a ≤b ≤c ≤d and e ≤f ≤g ≤h then we have:
⟨lt(t, a, c, f, h), r⟩∧⟨lt(t, b, d, e, g), r′⟩, = ⟨lt(t, b, c, f, g), ∃a, d, e, h : r ∧r′⟩
as shown below:
The same way, we have:
⟨lt(t, a, b, c, e), r⟩∧⟨lt(t, d, f, g, h), r′⟩= ⟨lt(t, a, b, g, h), ∃c, e, d, f : r ∧r′⟩(14)
when (r ∧r′) ⇒(c ≤d ≤e ≤f):
Abstract Disjunction. We have:
⟨lt(t, a, b, c, d), r⟩∨⟨lt(t, e, f, g, h), r′⟩= ⟨lt(t, i, j, k, ℓ), (∃a, b, c, d : i = a (15)
∧j = b ∧k = c ∧ℓ= d ∧r) ∨(∃e, f, g, h : i = e ∧j = f ∧k = g ∧ℓ= h ∧r′)⟩
In case one of the terms does not refer to the array (t ̸∈varJrK), a criterion must
be used to force the introduction of an identically true array term lt(t, i, i, i, i).
For example if the auxiliary variables d, f, g, h in r′ depend upon one selectively
chosen variable I, then we have:
r ∨⟨lt(t, d, f, g, h), r′⟩= ⟨lt(t, i, j, k, ℓ), (i = j = k = ℓ= I ∧r) ∨
(∃d, f, g, h : i = d ∧j = f ∧k = g ∧ℓ= h ∧r′)⟩
This case appears typically in loops, which can also be handled by unrolling, see
Abstract Predicate Transformers for the Parametric Comparison Abstract Domain. Then the abstract domain must be equipped with
abstract predicate transformers for tests, assignments, etc. We consider forward
strongest postconditions (although weakest preconditions, which avoid an existential quantiﬁer in assignments, may sometimes be simpler).
We depart from traditional predicate abstraction which uses a simpliﬁer
(or a theorem prover) to formally evaluate the abstract predicate transformer
α ◦F ◦γ approximating the concrete predicate transformer F. The alternative
proposed below is standard in abstract interpretation-based static program analysis and directly provides an over-approximation of the best abstract predicate
transformer α ◦
◦γ in the form of an algorithm (which correctness must
be established formally). The simpliﬁer/prover can be used to reduce the postcondition in the normal form (11) that is required for the abstract predicates
and otherwise easily handled e.g. by pattern-matching.
Abstract Strongest Postconditions for Tests.
if (t[I] > t[I + 1])
then { P1 ∧⟨lt(t, i, j, k, ℓ), i = I ∧j = I + 1 ∧k = I ∧ℓ= I⟩} . . . { P2 } (17)
else { P1 ∧⟨lt(t, i, j, k, ℓ), i = I ∧j = k = ℓ= I + 1⟩} . . . { P3 }
{ P2 ∨P3 }
Abstract Strongest Postconditions for Assignments. For assignment, we
have {t[a..I] ≤t[I] ∧t[I] > t[I + 1]} t[I] :=: t[I + 1] {t[a..I + 1] ≤t[I + 1]},
so that in the parametric abstract domain, assuming t ̸∈varJrK ∪varJr′K, r ⇒
(i ≤j = k = ℓ= I) and r′ ⇒(m = p = q = I ∧n = I + 1), we have:
{ ⟨lt(t, i, j, k, ℓ), r⟩∧⟨lt(t, m, n, p, q), r′⟩}
t[I] :=: t[I + 1]
{ ⟨lt(t, a, b, c, d), ∃i, j, k, ℓ, m, n, p, q : r ∧r′ ∧a = i ∧b = c = d = I + 1⟩} .
Similarly, if t ̸∈varJrK and r ⇒(I ∈[i, j] ∧J ∈[i, j]) ∨(J ∈[k, ℓ] ∧I ∈[k, ℓ])
{ ⟨lt(t, i, j, k, ℓ), r⟩}
t[I] :=: t[J]
{ ⟨lt(t, i, j, k, ℓ), r⟩}
since the swap of the array elements does not interfere with the assertions.
Widening for the Parametric Comparison Abstract Domain. Finally the abstract domain must be equipped with a widening to generate induction hypotheses (and optionally a narrowing to improve precision) to speed up
the convergence of iterative ﬁxpoint computations . We choose to deﬁne the
⟨lt(t, i, j, k, ℓ), r⟩
` ⟨lt(t, m, n, p, q), r′⟩
= let ⟨lt(t, r, s, t, u), r′′⟩= ⟨lt(t, i, j, k, ℓ), r⟩∨⟨lt(t, m, n, p, q), r′⟩in
⟨lt(t, r, s, t, u), r
Typically, when handling loops entry condition r, one encounters widenings of
the form r
` ⟨lt(t, m, n, p, q), r′⟩where ⟨lt(t, m, n, p, q), r′⟩appears during the
analysis of the loop body. There are several ways to handle this situation:
1. incorporate the term lt(t, i, j, k, ℓ) in the form of a tautology, as already described in (16) for the abstract disjunction;
2. use disjunctive completion to preserve the disjunction within the loop (which
may ultimately lead to inﬁnite disjunctions) or, for a less precise but cheaper
solution, allow only abstract predicates of a more restricted form, such as r ∨
⟨lt(t, m, n, p, q), r′⟩(which deﬁnitively avoids the previous potential explosion
and can be requested e.g. at widening points only);
3. unroll loops semantically (as in [5, Sec. 7.1.1]) so that the loop:
while B do C od
is handled in the abstract semantics as if written in the form:
if B then C; while B do C od ﬁ
which is equivalent in the concrete semantics. More generally, if several abstract terms of diﬀerent kinds are considered (like lt(t, i, j, k, ℓ) and s(t, m, n)
in the forthcoming Sec. 4.10), a further semantic unrolling can be performed
each time a term of a new kind does appear, while all terms of the same kind
are merged by the widening.
Reﬁned Parametric Comparison Abstract Domains. The parametric comparison abstract domain Dlt(X) of Sec. 4.2 may be imprecise since it
allows only for one term ⟨lt(t, a, b, c, d), r⟩. First we could consider several arrays, with one such term per array. Second, we could consider the conjunction
of such terms for a given array, which is more precise but may potentially lead
to inﬁnite conjunctions within loops (e.g. for which termination cannot be established). So we will consider this alternative within tests only, then applying
the above abstract domain operators term by term4.
The same way we could consider the disjunctive completion of this domain,
that is terms of the form W
j⟨lt(t, aij, bij, cij, dij), rij⟩. This would introduce
an exponential complexity factor, which we prefer to avoid. If necessary, we will
use local trace partitioning [5, Sec. 7.1.5] instead.
Parametric Comparison Static Program Analysis.
Let us consider the opposite program
(where a ≤b) which is similar to the inner loop of bubble sort . We let P i
the value of the local predicate attached
to the program point p = 1, ..., 8 at the
ith iteration. Initially, P 0
p = false for p = 2, ..., 8. We
choose the octagonal abstract domain
var t : array [a, b] of int;
while (I < b) do
if (t[I] > t[I + 1]) then
t[I] :=: t[I + 1]
I := I + 1
 as the parametric relational integer abstract domain Dr(X) parameterized
by the set X of program variables I, J,. . . and auxiliary variables i, j, etc. The
ﬁxpoint iterates are as follows:
Hinitialization to P 0
(I = a ≤b)
Hassignment (I := a)I
(I = a < b)
Hloop condition I < bI
⟨lt(t, m, n, p, q), m = p = q = I = a < b ∧n = I + 1⟩
Hby (17) for test
condition (t[I] > t[I + 1])I
4 For short we avoid to unroll loops semantically which is better adapted to automatization but would yield to lengthy handmade calculations in this section. This
technique will be illustrated anyway in the forthcoming Sec. 4.10.
⟨lt(t, a, b, c, d), ∃i, j, k, ℓ, m, n, p, q : i = j = k = ℓ= I ∧m = p = q = I =
a < b ∧n = I + 1 ∧a = i ∧b = c = d = I + 1⟩
Hby assignment (20) (with tautology lt(t, I, I, I, I)) which, by octagonal projection, simpliﬁes into:I
⟨lt(t, a, b, c, d), a = I = a < b ∧b = c = d = I + 1⟩
3 ∧⟨lt(t, i, j, k, ℓ), i = I = a < b ∧j = k = ℓ= I + 1⟩) ∨P 1
Hby (18) for test condition (t[I] > t[I + 1]) and join (19)I
(⟨lt(t, i, j, k, ℓ), i = I = a < b ∧j = k = ℓ= I + 1⟩) ∨(⟨lt(t, m, n, p, q),
m = I = a < b ∧n = p = q = I + 1⟩)
3 and (13) as well as by def. of P 1
⟨lt(t, a, b, c, d), (∃i, j, k, ℓ: a = i ∧b = j ∧c = k ∧d = ℓ∧
i = I = a < b ∧j = k = ℓ= I + 1) ∨(∃m, n, p, q : a = m ∧b = n ∧c =
p ∧d = q ∧m = I = a < b ∧n = p = q = I + 1)⟩
Hdef. (15) of the
abstract union ∨I
⟨lt(t, a, b, c, d), (a = I = a < b ∧b = c = d = I + 1)∨(a = I = a < b∧b =
c = d = I + 1⟩)
Hby octagonal projectionI
⟨lt(t, a, b, c, d), a = I = a < b ∧b = c = d = I + 1⟩
Hby octagonal
disjunctionI
⟨lt(t, a, b, c, d), a = I −1 = a < b ∧b = c = d = I⟩
Hby invertible
assignment I := I + 1I
⟨lt(t, a, b, c, d), I = a + 1 = a + 1 ≤b ∧b = c = d = I⟩
Hoctagonal
simpliﬁcationI
7 ) ∧(I < b)
Hloop condition I < b and absence of widening on
ﬁrst iterateI
((I = a ≤b) ∨(⟨lt(t, a, b, c, d), I = a + 1 = a + 1 ≤b ∧b = c = d =
I⟩)) ∧(I < b)
(⟨lt(t, i, j, k, ℓ), (i = j = k = ℓ= I = a ≤b) ∨(∃a, b, c, d : i = a ∧b =
j ∧c = k ∧d = ℓ∧I = a + 1 = a + 1 ≤b ∧b = c = d = I)⟩) ∧(I < b)
Hdef. (16) of abstract disjunction, the octagonal predicate depending only on I, a and b which leads to the selection of I,
the only of these variables which is modiﬁed within the loop
(⟨lt(t, i, j, k, ℓ), (i = j = k = ℓ= I = a ≤b) ∨(I = i + 1 = a + 1 ≤
b ∧j = k = ℓ= I)⟩) ∧(I < b)
Hby octagonal projectionI
(⟨lt(t, i, j, k, ℓ), (i = j = k = ℓ= I = a < b) ∨(I = i + 1 = a + 1 <
b ∧j = k = ℓ= I)⟩)
Hby octagonal conjunctionI
⟨lt(t, i, j, k, ℓ), i = a ≤j = k = ℓ= I ≤a + 1 ≤b⟩
Hby octagonal
disjunctionI
` ⟨lt(t, i, j, k, ℓ), i = a ≤j = k = ℓ= I ≤a + 2 ≤b⟩
absence of stabilization of the iterates, by a similar computation at the
next iterationI
⟨lt(t, i, j, k, ℓ), i = a ≤j = k = ℓ= I < b⟩Hdef. (22) of the widening
3 ∧⟨lt(t, m, n, p, q), m = p = q = I ∧n = I + 1⟩
Hby (17) for test
condition (t[I] > t[I + 1])I
⟨lt(t, i, j, k, ℓ), i = a ≤j = k = ℓ= I < b⟩∧⟨lt(t, m, n, p, q), m = p =
q = I ∧n = I + 1⟩Hdef. P 3
3 , the conjunction being left symbolic since it
cannot be simpliﬁed, see Sec. 4.6I
⟨lt(t, a, b, c, d), ∃i, j, k, ℓ, m, n, p, q : i = a ≤j = k = ℓ= I < b ∧m = p =
q = I ∧n = I + 1 ∧a = i ∧b = c = d = I + 1⟩
(20) where t ̸∈varJrK ∪varJr′K and r = (i = a ≤j = k = ℓ= I < b)
⇒(i ≤j = k = ℓ= I) and r′ = (m = p = q = I ∧n = I + 1) ⇒
(m = p = q = I ∧n = I + 1)I
⟨lt(t, a, b, c, d), a = a ≤b = c = d = I + 1 ≤b⟩
Hby octagonal
projectionI
(⟨lt(t, i, j, k, ℓ), i = a ≤j = k = ℓ= I < b⟩∧⟨lt(t, i′, j′, k′, ℓ′), i′ =
I ∧j′ = k′ = ℓ′ = I + 1⟩) ∨⟨lt(t, i′′, j′′, k′′, ℓ′′), i′′ = a ≤j′′ = k′′ = ℓ′′ =
3 ∧(t[I] ≤t[I + 1])) ∨P 3
5 and (18)I
⟨lt(t, i, j, k, ℓ), i = a ≤j = k = ℓ= I + 1 ≤b⟩∨⟨lt(t, i′′, j′′, k′′, ℓ′′),
i′′ = a ≤j′′ = k′′ = ℓ′′ = I + 1 ≤b⟩
Hdef. (14), of conjunction and
octagonal projectionI
⟨lt(t, i, j, k, ℓ), i = a ≤j = k = ℓ= I + 1 ≤b⟩
Hby P ∨P = PI
⟨lt(t, i, j, k, ℓ), i = a ≤j = k = ℓ= I ≤b⟩Hby assignment I := I + 1I
Now the iterates have stabilized since:
7 ) ∧(I < b) = (P 1
7 ) ∧(I < b)
Hsince P 3
2 is stableI
((I = a ≤b) ∨⟨lt(t, i, j, k, ℓ), i = a ≤j = k = ℓ= I ≤b⟩) ∧(I < b) Hdef.
(⟨lt(t, i, j, k, ℓ), (i = j = k = ℓ= I = a ≤b) ∨(∃a, b, c, d : i = a ∧b =
j ∧c = k ∧d = ℓ∧I = a + 1 = a + 1 ≤b ∧b = c = d = I)⟩) ∧(I < b)
Hdef. (16) of abstract disjunction with selection of I as in (23)I
(⟨lt(t, i, j, k, ℓ), (i = j = k = ℓ= I = a ≤b) ∨(j = k = ℓ= I = i + 1 =
a + 1 ≤b)⟩) ∧(I < b)
Hby octagonal projectionI
(⟨lt(t, i, j, k, ℓ), i = a ≤j = k = ℓ= I ≤b ∧a ≤b⟩) ∧(I < b)
octagonal disjunctionI
⟨lt(t, i, j, k, ℓ), i = a ≤j = k = ℓ= I < b⟩
Hby abstract conjunction
Hdef. (12) of abstract implicationI
It remains to compute the loop exit invariant:
7 ) ∧(I ≥b)
(⟨lt(t, i, j, k, ℓ), i = a ≤j = k = ℓ= I ≤b ∧a ≤b⟩) ∧(I ≥b)
octagonal disjunctionI
⟨lt(t, i, j, k, ℓ), i = a ≤j = k = ℓ= I = b⟩
Hby abstract conjunction
The static analysis has therefore discovered the following invariants:
var t : array [a, b] of int;
{I = a ≤b}
while (I < b) do
{lt(t, a, I, I, I) ∧I < b}
if (t[I] > t[I + 1]) then
{lt(t, a, I, I, I) ∧I < b ∧lt(t, I, I + 1, I, I)}
t[I] :=: t[I + 1]
{lt(t, a, I + 1, I + 1, I + 1) ∧I + 1 ≤b}
{lt(t, a, I + 1, I + 1, I + 1) ∧I + 1 ≤b}
I := I + 1
{lt(t, a, I, I, I) ∧I ≤b}
{lt(t, a, I, I, I) ∧I = b}
Parametric Sorting Abstract Domain. Then we deﬁne the parametric
sorting abstract domain:
Ds(X) = {⟨s(t, a, b), r⟩| t ∈X ∧a, b ̸∈X ∧r ∈Dr(X ∪{a, b})} .
The meaning γ(⟨s(t, a, b), r⟩) of an abstract predicate ⟨s(t, a, b), r⟩is, informally
that the elements of t between indices a and b are sorted:
γ(⟨s(t, a, b), r⟩) = ∃a, b : t.ℓ≤a ≤b ≤t.h ∧
∀i, j ∈[a, b] : (i ≤j) ⇒(t[i] ≤t[j]) ∧r .
Parametric Reduced Product of the Comparison and Sorting
Abstract Domain. The analysis of sorting algorithms involves the reduced
product of the parametric comparison abstract domain of Sec. 4.2 and sorting abstract domain of Sec. 4.8, that is triples of the form:
⟨lt(t, a, b, c, d), s(t, e, f), r⟩.
The reduction involves interactions between terms such as, e.g.:
lt(t, a, b −1, b −1, b −1) ∧lt(t, a, b, b, b)
⇒s(t, b −1, b) ∧lt(t, a, b −1, b −1, b)
s(t, b + 1, c) ∧lt(t, a, b + 1, b + 1, c) ∧lt(t, a, b, b, b)
⇒s(t, b, c) ∧lt(t, a, b, b, c)
lt(t, a, a + 1, a + 1, b) ∧s(t, a + 1, b) ⇒s(t, a, b)
The reduction also involves the reﬁnement of abstract predicate transformers
that would be performed automatically e.g. if the abstract predicate transformers
are obtained by automatic simpliﬁcation of the formula α ◦F ◦γ (where F is
the concrete semantics) by the simpliﬁer of a theorem prover.
Parametric Comparison and Sorting Static Program Analysis.
Let us consider the opposite bubble sort . The ﬁxpoint approximation below starts form:
HinitializationI
i = 2, . . . , 8
denotes the local assertion
attached to program point p at
the ith iteration and kth loop unrolling, P i
where k = 0
means that the decision to semantically unroll the loop is not yet
var t : array [a, b] of int;
while (a < J) do
while (I < J) do
if (t[I] > t[I + 1]) then
t[I] :=: t[I + 1]
I := I + 1
(a ≤b = J)
Hassignment J := bI
(a < b = J)
Htest (a < J)I
lt(t, a, I, I, I) ∧a < b = I = J5
Has in Sec. 4.7 since the inner loop
does not modify a, b or II
lt(t, a, J, J, b) ∧a < b = J
Hby elimination (octagonal projection) of
program variable I which is no longer live at program point 10I
lt(t, a, J + 1, J + 1, b) ∧a < b ∧J = b −1
Hpostcondition for
assignment J := J −1I
lt(t, a, J + 1, J + 1, b) ∧a < J = b −1
Hby semantical loop
unrolling (since a new symbolic “lt” term has appeared, see Sec. 4.5,)
and test (a < J)I
lt(t, a, J + 1, J + 1, J + 1) ∧a < J = b −1 ∧lt(t, a, I, I, I) ∧I = J
Has in Sec. 4.7 since the inner loop does not modify a, b or
I and the swap t[I] :=: t[I + 1] does not interfere with
lt(t, a, J + 1, J + 1, J + 1) according to a ≤I < I + 1 ≤
J < J + 1 so I, I + 1 ∈[a, J + 1] and (21)I
lt(t, a, J + 1, J + 1, J + 1) ∧lt(t, a, J, J, J) ∧a < J = b −1
elimination of I is dead at program point 10I
s(t, J, b) ∧lt(t, a, J, J, b) ∧a < J = b −1
Hby reduction (24)I
s(t, J + 1, b) ∧lt(t, a, J + 1, J + 1, b) ∧a ≤J = b −2
Hby assignment
J := J −1I
s(t, J+1, b)∧lt(t, a, J+1, J+1, b)∧a < J = b−2 Hby semantical loop
unrolling (since a new symbolic “s” term has appeared, see Sec. 4.5,)
and test (a < J)I
s(t, J+1, b)∧lt(t, a, J+1, J+1, b)∧a < J = b−2∧lt(t, a, I, I, I)∧I = J
Hby Sec. 4.7 and non interference, see (27)I
s(t, J + 1, b) ∧lt(t, a, J + 1, J + 1, b) ∧a < J = b −2 ∧lt(t, a, J, J, J)
Hsince I is deadI
s(t, J, b) ∧lt(t, a, J, J, b) ∧a < J = b −2
Hby reduction (25)I
s(t, J + 1, b) ∧lt(t, a, J + 1, J + 1, b) ∧a ≤J = b −3
Hby assignment
J := J −1I
11 ∧(a < J))) ∧(a < J) Hloop unrolling stops in absence of
new abstract term and widening speeds-up convergenceI
((s(t, J + 1, b) ∧lt(t, a, J + 1, J + 1, b) ∧a < J = b −2)
`(s(t, J + 1, b) ∧
lt(t, a, J + 1, J + 1, b) ∧a ≤J = b −3 ∧(a < J))) ∧(a < J) Hdef. P 1,2
s(t, J + 1, b) ∧lt(t, a, J + 1, J + 1, b) ∧((a < J = b −2)
` (a < J =
b −3)) ∧(a < J)
Hdef. wideningI
s(t, J + 1, b) ∧lt(t, a, J + 1, J + 1, b) ∧a < J ≤b −2
Hdef. octagonal
widening and conjunctionI
s(t, J+1, b)∧lt(t, a, J+1, J+1, b)∧a < J ≤b−2∧lt(t, a, I, I, I)∧I = J
Hby Sec. 4.7 and non interference, see (27)I
s(t, J + 1, b) ∧lt(t, a, J + 1, J + 1, b) ∧a < J ≤b −2 ∧lt(t, a, J, J, J)
Hby elimination of the dead variable II
s(t, J, b) ∧lt(t, a, J, J, b) ∧a < J ≤b −2
Hby reduction (25)I
s(t, J + 1, b) ∧lt(t, a, J + 1, J + 1, b) ∧a ≤J ≤b −3
Hby assignment
J := J −1I
Now (P 2,2
11 ∧a < J) ⇒P 1,2
so that the loop iterates stabilize to a post-
ﬁxpoint. On loop exit, we must collect all cases following from semantic unrolling:
Hno entry in the loopI
Hloop exit after one iterationI
Hloop exit after two iterationsI
Hloop exit after three iterations or moreI
(a = J = b) ∨(s(t, J + 1, b) ∧lt(t, a, J + 1, J + 1, b) ∧a = J ≤b −1)
Hdef. abstract disjunctionI
(a = J = b)∨(s(t, a+1, b)∧lt(t, a, a+1, a+1, b)∧a < b) Helimination
of dead variable JI
(a = b) ∨(s(t, a, b) ∧a < b)
Hby reduction (26)I
s(t, a, b) ∧a ≤b
Hdeﬁnition of abstract disjunction similar to (16)I
5 Notice that this notation is a shorthand for the more explicit notation ∃i, j, k, ℓ:
lt(t, i, j, k, ℓ) ∧i = a ∧j = I ∧k = I ∧ℓ= I) ∧a < b ∧b = J ∧I = J as used
in Sec. 4.7, so that, in particular, we freely replace i, j, k and ℓin lt(t, i, j, k, ℓ) by
equivalent expressions.
The sorting proof would proceed in the same way by proving that the ﬁnal
array is a permutation of the original one.
Observe that parametric predicate abstraction is deﬁned for a programming
language as opposed to ground predicate abstraction which is speciﬁc to a program, a usual distinction between abstract interpretation-based static program
analysis (a parametric abstraction for an inﬁnite set of programs) and abstract
model checking (an abstract model for a given program). Notice that the polymorphic predicate abstraction of is an instance of symbolic relational separate
procedural analysis [14, Sec. 7] for ground predicate abstraction. The generalization to parametric predicate abstraction is immediate since it only depends
on the way concrete predicate transformers are deﬁned (see [14, Sec. 7]).
Conclusion
In safety proofs by ground predicate abstraction, one has to provide (or compute
by reﬁnement) the ground atomic components of the inductive invariant which
is to be discovered for the proof. Then the routine work of assembling the atomic
components into a valid inductive invariant is mechanized which simpliﬁes the
proof. If the set of atomic components is ﬁnite then a Boolean encoding allows
for the reuse of model-checkers for ﬁxpoint computation. Otherwise a speciﬁc
ﬁxpoint engine has to be used, which is mandatory even in cases as simple as
constant propagation if the constants are to be discovered automatically and not
explicitly provided in the list of ground atomic predicates.
Parametric predicate abstraction provides a further abstraction step in that
hints for the proof are provided in the form of parameterized atomic predicates
(which will be instantiated automatically to program-speciﬁc ground predicates)
and reduction rules (which are hints for inductive reasoning on these parametric
predicates). This parametricity immediately leads to inﬁnite abstract domains
which means that ﬁxpoint iterations need more sophisticated inferences, which
we can provide in the simple form of widenings. Moreover, the presentation in
the form of structured abstract domains, which can be systematically composed,
reduces the need to appeal to theorem provers by reduction of the widening to
well-studied and powerful basic relational abstract domains which can be viewed
as undecidable theories with ﬁnitary extrapolation through widenings. Parametric predicate abstractions can handle large families of algorithms and data structures (as considered in ) and so is of much wider scope than ground predicate
abstraction restricted to a single program and requiring a costly reﬁnement process when ground predicates are missing.
Acknowledgements.
I thank the participants to the informal meeting on
predicate abstraction at New York University on Thursday Jan. 30th 2003 (Radhia Cousot, Dennis Dams, Kedar Namjoshi, Amir Pnueli, Lenore Zuck), in particular Amir Pnueli who proposed the bubble sort as a challenge that is handled
in Sec. 4. I thank Pavol Černý for providing a prototype implementation and
further examples (such as array initialization and Quicksort).