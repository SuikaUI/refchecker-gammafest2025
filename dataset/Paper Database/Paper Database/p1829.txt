RADAR: Robust AI-Text Detection via
Adversarial Learning
Xiaomeng Hu
The Chinese University of Hong Kong
Sha Tin, Hong Kong
 
Pin-Yu Chen
IBM Research
New York, USA
 
Tsung-Yi Ho
The Chinese University of Hong Kong
Sha Tin, Hong Kong
 
Recent advances in large language models (LLMs) and the intensifying popularity of ChatGPT-like applications have blurred the boundary of high-quality text
generation between humans and machines. However, in addition to the anticipated
revolutionary changes to our technology and society, the difficulty of distinguishing
LLM-generated texts (AI-text) from human-generated texts poses new challenges
of misuse and fairness, such as fake content generation, plagiarism, and false
accusations of innocent writers. While existing works show that current AI-text
detectors are not robust to LLM-based paraphrasing, this paper aims to bridge
this gap by proposing a new framework called RADAR, which jointly trains a
robust AI-text detector via adversarial learning. RADAR is based on adversarial
training of a paraphraser and a detector. The paraphraser’s goal is to generate
realistic content to evade AI-text detection. RADAR uses the feedback from the
detector to update the paraphraser, and vice versa. Evaluated with 8 different
LLMs (Pythia, Dolly 2.0, Palmyra, Camel, GPT-J, Dolly 1.0, LLaMA, and Vicuna)
across 4 datasets, experimental results show that RADAR significantly outperforms
existing AI-text detection methods, especially when paraphrasing is in place. We
also identify the strong transferability of RADAR from instruction-tuned LLMs to
other LLMs, and evaluate the improved capability of RADAR via GPT-3.5-Turbo.
Project Page and Demos: 
IBM demo is developed by Hendrik Strobelt and Benjamin Hoover at IBM Research
HuggingFace demo is developed by Xiaomeng Hu
Introduction
Large language models (LLMs) are high-capacity neural networks that are pretrained at web-scale
datasets. They are foundation models achieving state-of-the-art performance in a wide range of natural
language processing tasks (e.g. document completion, question answering, machine translation, and
content creation with text prompts) with advanced capabilities such as in-context learning and
reasoning (e.g. chain of thoughts). In particular, LLMs are the backbone of many ChatGPT-like
conversational bots that enable text generation with high fluency and accuracy. However, while LLMs
and their derived applications are expected to become ubiquitous in our future technology and society,
37th Conference on Neural Information Processing Systems .
 
Figure 1: Overview of RADAR. An AI-text corpus is first generated from a target (frozen) language
model from a human-text corpus. In RADAR, we introduce a paraphraser (a tunable language
model) and a detector (a separate tunable language model). In the training stage, the detector aims to
discern human-text v.s. AI-text, while the paraphraser aims to rewrite AI-text to evade detection. The
model parameters of the paraphraser and the detector are updated in an adversarial learning manner
as described in Section 3. In the evaluation stage, the trained detector is deployed to predict the
likelihood of AI-generated content for any input instance.
new risks in failing to distinguish the so-called “AI text” generated by LLMs have emerged and
gained considerable attention due to various reasons. The problem of reliable AI-text detection is
motivated by realistic socio-technological challenges such as fake content generation, AI plagiarism
(e.g. using LLMs for writing tests), and false accusations of innocent writers. According to a report
released by OpenAI1, their latest AI-text detector is admittedly not fully reliable. In the reported
evaluation of some challenging cases for English texts, their classifier only correctly identifies 26%
of AI-text (true positives) while incorrectly classifying 9% of human-written text (false positives).
Moreover, a recent study found that state-of-the-art AI-text detectors demonstrated severely
degraded performance when encountering texts written by non-native English speakers.
What can be even more challenging in AI-text detection is that existing AI-text detectors are prone
to be manipulated. The authors in showed that using LLMs as a paraphraser can easily
evade several AI-text detection methods, even in the scenario when the original AI-text had been
watermarked. These findings sparked a heated debate about whether and how we can successfully
design a reliable AI-text detector. While theoretically quantifies the best detector’s performance
with respect to the total variation distance between AI-text and human-text distributions and argues
that AI-text is difficult to detect, another work proves that it is possible to obtain a reliable AI-text
detector unless the human-text distribution is exactly the same as the AI-text distribution, based
on an information-theoretical analysis (i.e., the sample complexity of Chernoff information and
likelihood-ratio-based detectors).
To improve AI-text detection, we propose RADAR, a framework for training a robust AI-text detector
using adversarial learning. An overview of RADAR is illustrated in Figure 1. Our proposal draws
inspiration from adversarial machine learning techniques that train a high-quality generator by
introducing a discriminator to form a two-player game, such as generative adversarial networks
(GANs) . In RADAR, we introduce a paraphraser and a detector as two players with opposite
objectives. The paraphraser’s goal is to generate realistic content that can evade AI-text detection,
while the detector’s goal is to enhance AI-text detectability. In our framework, both the paraphraser
and the detector are parametrized by separate LLMs. During training, the paraphraser learns to
rewrite the text from a training corpus (generated by a target LLM from a human-text corpus) with the
1 
Figure 2: Performance evaluation (AUROC) of 8 LLMs over 4 human-text datasets. w/o paraphraser
means the evaluation with the original AI-text corpora (the yellow bin M in Figure 1). RADAR-
Unseen paraphraser means the evaluation with the paraphrased AI-text (the green bin P in Figure
1) generated from an independent paraphraser (OpenAI’s GPT-3.5-Turbo API) that is not used in
RADAR. The black error bar represents the standard deviation of the detection AUROCs across 8
LLMs. Please refer to Section 4.2 for more implementation details.
aim of decreasing the likelihood of AI-text prediction by the detector, whereas the detector aims to
enhance the detection performance by learning to compare human-text v.s. AI-text from the training
data and the paraphraser’s output. These two players iteratively update their model parameters until
their respective validation loss becomes stable. Specifically, the paraphraser treats the prediction
of the detector as a reward and uses Proximal Policy Optimization (PPO) for updates. The
detector updates its parameters based on a logistic loss function evaluated on the human-text and
AI-text corpora (including the texts generated by the paraphraser). In the evaluation phase, the trained
detector is deployed to predict the likelihood of AI-written content for any input instance. When
compared with 6 existing detectors, our experimental results on 8 different LLMs and 4 datasets show
that RADAR attains similar detection performance on the original AI-generated texts (a relatively easy
task) and simultaneously improves the AI-text detectability when facing an “unseen” paraphraser (i.e.
this paraphraser is not used in RADAR). The result is summarized in Figure 2. When facing an unseen
paraphraser (GPT-3.5-Turbo), the area under the receiver operating characteristic (AUROC) score
of RADAR is improved by 31.64% compared to the best existing detector, suggesting a significant
improvement and reliable AI-text detection power enabled by RADAR.
We summarize our main contributions as follows:
• To the best of our knowledge, RADAR is the first study that leverages the idea of adversarial
learning between a paraphraser and a detector for training a robust AI-text detector.
• The experiments on 8 different LLMs (Pythia, Dolly 2.0, Palmyra, Camel, GPT-J, Dolly 1.0,
LLaMA, and Vicuna) and 4 datasets show that unlike the six existing supervised and unsupervised
AI-text detection methods, RADAR is the only robust detector that attains consistently high
detection performance. RADAR’s detector is not weakened by paraphrasing, as shown in Figure 2.
• We also find the strong transferability of RADAR’s detection capability. The detectors of RADAR
obtained from instruction-tuned first-class LLMs (e.g., Vicuna-7B) are also effective on other LLMs,
suggesting the possibility of training a universal AI-text detector based on the state-of-the-art LLMs.
Related Work
AI-Text Detection. The research in AI-text detection can be divided into three approaches. (i)
Statistical methods: some statistics such as entropy , n-gram frequency, and perplexity are used
as a threshold to discern AI-text. A typical example is GLTR , which exploits entropy, probability,
and probability rank for detection. A more recent work is DetectGPT , which assumes that the
machine-generated text always lies in the negative curvature region of the log probability of the LLM
of interest. Based on this hypothesis, DetectGPT perturbs the input text with a mask-filling language
model, such as T5 . Then, AI-text detection is performed by comparing the log probability of the
text and its infilled variants. (ii) Classification methods: AI-text detection is formulated as a binary
classification task, and a classifier is trained for a target language model . For example,
OpenAI trains its AI-text classifier with a RoBERTa-based model .
The developers collected samples from the WebText dataset2 and labeled them as human-generated.
Then, for each target GPT-2 model, they collected the generated samples and labeled them as
machine-generated. Finally, they fine-tuned the pretrained RoBERTa-based model for AI-text
classification. More recently, with the appearance of CharGPT, OpenAI tuned a GPT model called
AI-Classifier1 using data from several sources. The human-written text comes from three sources: a
new Wikipedia dataset, the WebText dataset collected in 2019, and a set of human demonstrations
collected as part of training InstructGPT . To collect machine-generated text, for the Wikipedia
and WebText datasets, they truncated the articles sampled from the original corpus and used 34
models to generate article completion, pairing each generated text with the original article. For the
demonstrations, they used a model to generate responses for each prompt and paired them with the
corresponding human demonstrations. This detector was only accessible via a web interface since
its release in January 2023, and it has been taken down since July 2023. (iii) Watermark methods:
post-hoc watermarking techniques, such as rule-based methods and deep-learning-based
methods , can be applied to an LLM. At inference time, proposed a soft watermarking
scheme to embed a watermark in each word of the generated sentence by dividing the vocabulary
into different lists and sampling the next token in a differentiated manner. However, many existing
AI-text detectors are shown to be significantly weakened by paraphrasing in .
Adversarial Learning for Natural Language Generation. The success of GAN in the
computer vision domain has motivated many studies in natural language generation. However, since
text generation is a sequential sampling process that occurs in a discrete vocabulary space, it is difficult
to directly train a text generator using back-propagation in an end-to-end manner . There
are two common approaches to tackle this problem. The first one is to replace the discrete sampling
operation with continuous approximation techniques , such as Gumbel-Softmax .
The second one is to view text generation as a decision-making process and cast the generator as a
policy . A typical example is SeqGAN . During generation, SeqGAN considers
the generated tokens as the state and the next token to be generated as the action, and it adopts Monte
Carlo search to collect reward signals from the discriminator. Instead of using a classifier as the
discriminator, the Diversity-Promoting GAN uses a unidirectional LSTM as the discriminator
and combines both word-level and sentence-level rewards into training. TextGAIL proposed an
imitation learning paradigm in which the rewards of the human-written text are regarded as a constant
value. Then, both the rewards from human-text and AI-text are used to optimize the generator
with PPO. These works all used warm-up training for the generator with maximum likelihood
estimation (MLE) on the probability of the generated text sequence. On the other hand, trained a
language GAN from scratch. Our proposed RADAR differs from these works in that we focus on
training a robust AI-text detector with a tunable paraphraser. Another line of work, such as ,
uses paraphrasing techniques to find adversarial examples for natural language processing tasks and
for training a robust language model via adversarial training. Their focus is on the correctness of
natural language understanding, which is beyond our scope of AI-text detection.
RADAR: Methodology and Algorithms
We start this section by giving an overview and mathematical notations of our proposed RADAR
framework in Figure 1. Then, in Sections 3.1 and 3.2, we provide the details on the design and
training of the paraphraser and detector, respectively. Finally, we will summarise the entire training
process into an algorithmic procedure in Section 3.3.
High-Level Methodology. Our RADAR framework consists of three neural-network-based language
models (LMs): the target LM Tθ, the detector Dϕ and the paraphraser Gσ, parameterized with θ, ϕ
and σ, respectively. We note that Tθ is frozen (no updates on θ) in the entire process. We summarize
RADAR into three key steps:
• Step 1 (Data preparation): Before training, we build M, the corpus of AI-text, by applying
document completion based on the prefix span of text in the human-text corpus H using Tθ.
2 
• Step 2 (Paraphraser update): We collect AI-text samples xm from M and use Gϕ to do paraphrasing on xm to generate paraphrased AI-text xp to form a corpus P. Then, we use the reward of
xp returned by the detector Dθ to update the paraphraser Gϕ using PPO.
• Step 3 (Dectector update): We use the human-text samples xh from H, the original AI-text
samples xm from M, and the paraphrased AI-text samples xp from P in step 2 to update the
detector Dθ with a logistic loss function.
• Step 4 (Performance Validation and Evaluation): During training, we use the test set of WebText
as the validation dataset to estimate RADAR’s performance. For evaluation, we use Tθ to generate
AI-text for the evaluation dataset and to calculate RADAR’s detection AUROC.
Step 2 to Step 3 can be repeated until there is no improvement in the AUROC evaluated on the
validation dataset. The nature of rivalry in adversarial learning and the introduced competition helps
the detector to learn to be robust in detecting both original and paraphrased AI-text.
Training Paraphraser via Clipped PPO with Entropy Penalty
In RADAR, the goal of the paraphraser Gσ is to paraphrase the input machine-generated text xm. We
model the generation of paraphrased text as a decision-making process, taking xm as the state and
the output text xp as the action. In particular, we optimize Gσ using the reward feedback from the
detector Dϕ with PPO. The output of Dϕ(xp) is the predicted likelihood of xp being Human-text.
The reward returned by xp and the log probability of the text xp are defined in Eq. 1:
R(xp, ϕ) = Dϕ(xp) ∈ ;
log PGσ(xp|xm) =
log PGσ(xi
p|xm, x1:i−1
p means the i-th token in the sentence xp of length N and x1:i−1
represents the first i −1
tokens in xp (x1:0
means the default starting token).
We propose Clipped PPO with Entropy Penalty (cppo-ep) in RADAR to optimize Gσ. Let clip(·, a, b)
denote a value-clipping operation with a lower limit a and an upper limit b, r(σ, xm, xp) be the
importance sampling ratio between a new policy Gσ and an old policy Gσ′, and (xm, xp) ∼PGσ′ be
a state-action pair sampled from Gσ′. The loss of cppo-ep is defined as:
LG(σ) = E(xm,xp)∼PGσ′ −min{clip(r(σ, xm, xp), 1 −ϵ, 1 + ϵ), r(σ, xm, xp)} · A(xp, ϕ)
where E denotes expectation, ϵ is a parameter used in clipping to avoid the importance ratio
r from being too large, A(xp, ϕ) is the advantage item of the paraphrased text xp obtained by
applying normalization to R(xp, ϕ) across the entire PPO sample buffer B. S(σ) = E(xm,xp)∼PGσ′ −
PGσ(xp|xm) log PGσ(xp|xm), which is an entropy term introduced to encourage Gσ to explore more
diverse generation policy. γ is a coefficient to control the ratio between LA and LE, in order to make
a balance between advantage (LA) and diversity (LE) when paraphrasing.
Training Detector via Reweighted Logistic Loss
In a typical GAN training process, the discriminator receives an equal amount of positive and negative
samples in each step, assuring an in-batch sample balance. However, in RADAR, by construction,
the number of AI-text samples is twice the number of human-text samples, because each xh from the
human-text corpus H is paired with a sample xm from the original AI-text corpus M as well as a
paraphrased sample xp generated by the paraphraser Gϕ. To handle this in-batch imbalance problem,
we use a reweighted logistic loss function to optimize the detector Dϕ, as described in Eq. 3:
LD(ϕ) = −Exh∼H log Dϕ(xh)
LH: loss on human-text
+λ Exm∼M −log (1 −Dϕ(xm))
M: loss on original AI-text
+λ Exm∼M −log (1 −Dϕ(Gσ(xm)))
M: loss on paraphrased AI-text
Recall that Dϕ(x) ∈ is the predicted probability of an input instance x being Human-text. LH
is the loss to improve the correctness of predicting xh ∼H as human-written. LM = L1
M are used to avoid xm and xp from being predicted as human-text, respectively. λ
is a coefficient ranging from 0 to 1. We introduce λ to adjust the proportion of AI-text components in
the overall loss function to alleviate the effects of sample imbalance.
RADAR Algorithm
The entire training procedure of RADAR is summarized in Algorithm 1. For a given target LLM,
RADAR returns a trained paraphraser and a trained detector through the designed training steps. In
the evaluation phase, the detector is used to predict the likelihood of AI-text for any input instance.
Algorithm 1 RADAR: Robust AI-Text Detection via Adversarial Learning
1: Data initialization:
2: Collect human-written text to build human-text corpus H
3: Select a target language model Tθ to perform document completion on H to build the corresponding AI-text corpus M
4: Build a replay buffer B to store samples temporarily collected for training
5: Build a validation dataset V from H and M
6: Model initialization:
7: Detector Dϕ ←ϕpretrain (a pretrained language model)
8: Paraphraser Gσ ←σpretrain (a pretrained language model)
9: Model training:
10: for i = 1 : maximum step do
Sample xh and its corresponding xm from H and M respectively
Use Gσ to paraphrase xm and generate xp
Collect reward R(xp, ϕ) as in Eq. 1
Normalize R(xp, ϕ) to compute the advantage function A(xp, ϕ) used in Eq. 2
Fill B with (xh, xm, xp, A(xp, ϕ))
σ′ ←σ # initialize the old policy σ′ as the current policy σ
for (xh, xm, xp, A(xp, ϕ)) ∈B do
Compute the log probability log PGσ(xp|xm) and log PG′σ(xp|xm) using Eq. 1
Update Gσ using Eq. 2
for (xh, xm, xp, A(xp, ϕ)) ∈B do
Update Dϕ using Eq. 3
Evaluate AUROC of Dϕ on the validation dataset V
26: end for
27: Detector Dϕ ←ϕbest (the detector model with the best AUROC on the validation dataset)
28: Paraphraser Gσ ←σbest (the paraphraser model which pairs with ϕbest)
29: Return Dϕ and Gσ
Experiments
Experimen Setup
Datasets and Metrics. For training, we sampled 160K documents from WebText to build the
human-text corpus H. Then, we build the original AI-text corpus M from H using a target language
model Tθ, which performs text completion using the first 30 tokens as the prompt and limits the
sentence length to be 200 tokens. For evaluation, we select four human-text datasets covering different
domains. Following , we use Xsum, SQuAD, and Reddit WritingPrompts (WP) to test a detector’s
ability to detect fake news, avoid academic fraud, and identify machine-generated literature innovation,
respectively. In addition, we also use the non-native-authored TOEFL dataset (TOFEL) to
evaluate a detector’s bias when encountering non-native-authored English text. Please see Appendix A
for more details about the evaluation datasets. Following existing works, we report the area under
the receiver operating characteristic curve (AUROC) score by varying the detector’s threshold as the
performance measure (higher is better), which captures the relationship between the true positive rate
and the false positive rate.
Comparisons. We compare RADAR with various detection methods. These methods include the
OpenAI (RoBERTa) model which is fine-tuned on WebText and GPT-2 generations, as well as
the statistical approaches including log probability, rank, log rank, entropy, and DetectGPT .
Table 1: Summary of the studied large language models
Parameter Count
Model Name
Organization
Pretrain Data
Instruction Fine-tune Data
Pythia-2.8B
EleutherAI
The Pile 3
Dolly-V2-3B
Databricks
databricks-dolly-15k4
Palmyra-base
Writer’s custom dataset
70K instruction-response records by Writer Linguist team
EleutherAI
Dolly-V1-6B
Databricks
Standford Alpaca 52K instruction-following demonstrations5
Various sources6
70K conversations collected from ShareGPT 7
Specifically, we implemented DetectGPT using the trained T5-large model as the mask-filling model
and performed 10 perturbations for each sentence to be detected.
Large Language Models. For the target LLM Tθ, we select 4 pairs of LLMs and summarize them in
Table 1. Each pair contains an open-source LLM and its fine-tuned version via instruction-tuning.
Paraphrase Configurations. We consider two settings: without (w/o) paraphrasing and with
paraphrasing. To prepare the machine-generated text for evaluation, for the w/o paraphrasing setting,
we use the original AI-text corpus M generated by a target LLM based on an evaluation dataset. For
the with paraphrasing setting, we define two types of paraphrasing: seen paraphraser and unseen
paraphraser. The seen paraphraser refers to the paraphraser Gσ returned by RADAR. The unseen
paraphraser means a new paraphraser that has not participated in training the detector of RADAR. We
used the OpenAI API service of GPT-3.5-Turbo as the default unseen paraphraser. The prompt we
used for paraphrasing is “Enhance word choices to make the sentence sound more like a human”, as
inspired by .
Implementation Details. We provide the detailed setups when implementing Algorithm 1. We
build a PPO buffer B that can temporarily store 256 pairs of data for subsequent training. We use
the pre-trained T5-large and RoBERTa-large models as the initialization of Gσ and Dϕ respectively.
During training, we set the batch size to 32 and train the models until the validation loss converges.
We use AdamW as the optimizer with the initial learning rate set to 1e-5 and use linear decay for
both Gσ and Dϕ. We set λ = 0.5 for sample balancing in Eq. 3 and set γ = 0.01 in Eq. 2. We follow
the same construction principle of the training dataset to create the 4 evaluation datasets based on
Xsum, SQuAD, WP, and TOFEL. Experiments were run on 2 GPUS (NVIDIA Tesla V100 32GB).
Performance Evaluation and Comparison with Existing Methods
We run three groups of experiments (w/o paraphraser, seen paraphraser, and unseen paraphraser) and
report the overall results of RADAR and the compared methods on all 4 datasets in Table 2. The
reported AUROC scores are averaged over the 8 considered LLMs. In the relatively easy case of
without paraphrasing, most detectors attain good AUROC scores. RADAR attains a comparable
performance (0.856) to the best existing detector (log rank, 0.904). The slightly worse performance
of RADAR can be explained by the tradeoff in enhancing AI-text detection against paraphrasing.
When facing paraphrasing, all existing methods except entropy show significant performance degradation. The drop in AUROC compared to the w/o paraphrasing case ranges from 10.4% to 81.7%.
While entropy is shown to be more robust to paraphrasing, its AUROC score can be quite low. On the
contrary, RADAR demonstrates robust and superior detection power, attaining the best performance
on every dataset. As shown in Figure 2, the average AUROC score of RADAR (0.857) improves the
best existing method (entropy, 0.651) by 31.64% against the unseen paraphraser. On average, RADAR
is more robust to the seen paraphraser than the unseen paraphraser, because the seen paraphraser
is what is used to train the detector in RADAR. More importantly, the detection performance of
RADAR is stable across different paraphrasing schema, suggesting that RADAR can successfully
mitigate the performance drop in AI-text detection.
3 
4 
5 
6Collected from CCNet [67%], C4 [15%], GitHub [4.5%], Wikipedia [4.5%], Books [4.5%], ArXiv [2.5%],
Stack Exchange [2%]
7 
Table 2: AUROC score averaged over 8 target LLMs. RADAR-Seen Paraphraser means the paraphraser used in RADAR (Gσ). RADAR-Unseen Paraphraser is OpenAI’s GPT-3.5-Turbo API. The
notations { 1
⃝} denote the best/second-best method for each dataset.
Evaluation Schema
Evaluation Dataset
w/o Paraphraser
OpenAI (RoBERTa)
RADAR-Seen Paraphraser
OpenAI (RoBERTa)
RADAR-Unseen Paraphraser
OpenAI (RoBERTa)
Dolly-V1-6B
Dolly-V2-3B
Palmyra-base
Pythia-2.8B
Dolly-V1-6B
Dolly-V2-3B
Palmyra-base
Pythia-2.8B
0 1 2 3 4 5 6 7 8 9
(a) w/o paraphraser
Dolly-V1-6B
Dolly-V2-3B
Palmyra-base
Pythia-2.8B
Dolly-V1-6B
Dolly-V2-3B
Palmyra-base
Pythia-2.8B
0 1 2 3 4 5 6 7 8 9
(b) GPT-3.5-Turbo paraphraser
Figure 3: RADAR’s detection transferability between pairs of 8 LLMs in Table 1. In the matrix,
each row is the source LLM (model A) for training the detector, and each column is the target LLM
(model B) for evaluation. The reported value in the matrix represents the detection transferability
from A to B. A larger value indicates better transferability. The bar chart shows the row-wise sum of
the matrix, indicating the holistic transferability of each source LLM.
AI-Text Detection Transferability of RADAR
We explore the AI-text detection transferability of RADAR between the 8 LLMs and report the
ratio F(A,B)=AUROC(A,B)/AUROC(B,B) for each LLM pair (A,B), where AUROC(A,B) means
using the RADAR’s detector trained on model A to evaluate the AI-text generated by model B. A
larger ratio means better transferability from A to B. Figure 3 shows the matrix of pairwise detection
transferability and the bar chart of the holistic detection transferability to all the 8 LLMs in the
without and unseen paraphrasing settings. We highlight two key observations as follows.
(I) Instruction-tuned models have better detection transferability. Partitioning the LLMs into
two groups, we can find that the detector targeting an instruction-tuned LLM (top 4 rows) generally
transfers better than the detector targeting the corresponding LLM without instruction-tuning (bottom
4 rows). Take the pair (Vicuna-7B, LLaMA-7B) as an example, we can see that without paraphrasing,
F(Vicuna-7B,LLaMA) can reach up to 95.0%. On the other hand, F(LLaMA-7B,Vicuna-7B) can only
account for 68.2%. Sorting the detectors according to the holistic detection transferalbility (which is
presented in the bar chart), we can see the top-3 detectors are all trained with the instruction-tuned
LLMs. A similar conclusion can be made for the with paraphrasing setting. Moreover, there is no
obvious trend between the target LLM size and the resulting detection performance. The effect of
instruction tuning on transferability is more prominent than model size.
(II) RADAR achieves better detection transferability against paraphrasing. Another interesting finding is that RADAR’s transferability is generally improved when paraphrasing is in place.
Comparing the two bar charts in Fig. 3a and Fig. 3b, the average holistic detection transferability
(over all LLMs) is increased by 11.6%. Except for LLaMA-7B (3.8% drop) and GPT-J-6B (1.4%
drop), all other LLMs’ holistic transferability scores are improved from 2.4% (Palmyra-base) to
47.6% (Camel-5B).
Transfer detection on AI-text generated by GPT-4. We also test RADAR detectors on the texts
generated by GPT-4. The results show that 5 out of 8 RADAR models can outperform the OpenAI
(RoBERTa), and three of them can achieve more than 0.8 detection AUROC. For example, RADAR
trained on Camel-5B can achieve 0.915 detection AUROC on GPT-4 generations. The results show
that the RADAR can achieve good transfer detection for GPT-4. The details are given in Appendix K.
Ensemble detection. We also explored whether and how ensemble learning benefits detection by
combining the outputs of detectors. The results show that the detection performance can be lifted by
carefully tuning the ensemble ratio and the model to be combined. Please see Appendix G for the
exact experiment results.
To sum up, we believe our findings suggest promising results for training a universal robust AI-text
detector by leveraging state-of-the-art LLMs, and RADAR can use a smaller-sized and weaker LLM
to achieve good detection performance on texts generated from top-notching LLMs (such as GPT-4).
Variants of Paraphrasing
In addition to paraphrasing the original LLM-generated texts, we also evaluate the detection performance when paraphrasing human texts (the output is labeled as AI-text). We also allow paraphrasing
multiple times in our analysis. We conduct our experiments on the Xsum dataset using the detector
trained with Camel-5B. The paraphraser for evaluation is GPT-3.5-Turbo. As shown in Figure 4a, we
find that RADAR is the only detector robust to multi-round paraphrasing. On paraphrased AI-text,
all existing methods suffer from a notable performance drop. On paraphrased human-text, RADAR
remains effective, along with two existing methods (OpenAI (RoBERTa) and entropy). In general,
multi-round paraphrasing does not seem to increase the difficulty of AI-text detection. We also find
RADAR is robust to Dipper , another paraphrase model. Please see Appendix I for details.
(a) Paraphrased AI-text
(b) Paraphrased human-text
Figure 4: Detection AUROC of RADAR against multiple paraphrasing. The experiments are
conducted on Xsum using the detector trained for Camel-5B.
Evaluation on RADAR’s Paraphraser
Although our focus is on training a robust AI-text detector via RADAR, as a by-product, we expect
to obtain a better paraphraser through adversarial learning. To verify this hypothesis, we compare the
quality of the initial paraphraser (a pretrained LLM) and the final paraphraser returned by RADAR
using GPT-3.5-Turbo’s response. We select 100 documents from WebText and use 4 different
paraphrasers from RADAR to paraphrase the documents. Then, we ask GPT-3.5-Turbo to rate
sentences generated by these paraphrasers versus their initial version (T5-large). Figure 5a shows that
RADAR also improves the quality of paraphrasing. Figure 5b shows that the RADAR’s paraphraser
can score higher if it is trained with a larger target LLM with instruction tuning. Following , we
also evaluate RADAR’s paraphrasers on Quora Question Pairs (QQP8) and use iBLEU (α = 0.8) 
as the metric (higher is better). Figure 5c shows that the paraphrasing performance can be improved
via RADAR as all the RADAR-paraphrasers can achieve a larger iBLEU score than T5-large.
(a) GPT-3.5 assessment
(b) GPT-3.5 score
(c) iBLEU on QQP
Figure 5: Evaluation of RADAR’s paraphraser versus its initial version (T5-large).
Balancing the Detection Performance in the with and without Paraphrasing Settings
From Figure 2, we can observe that though RADAR can achieve robust detection under paraphrasing,
it is (slightly) worse than some of the existing baselines when AI-text data are unperturbed (i.e.,
w/o paraphrasing). We run a trade-off analysis on the weight coefficient λ in Equation (3) to study
whether RADAR can be further tuned to achieve competitive performance on unperturbed data
while still being robust to paraphrasing. We use Vicuna-7B as the target model to train 10 RADAR
detectors by varying λ from 0.1 to 1.0 with 0.1 increment, and then evaluate these detectors as well
as other detection baselines on the evaluation datasets. The results in Appendix J show that we can
promote RADAR’s performance on unperturbed data while still preserving high detection AUROC on
paraphrased data. Take λ = 0.6 as an example. When we change λ from 0.5 (the default value of λ)
to 0.6, the AUROC of w/o paraphrasing increases from 0.906 to 0.937, while the AUROC of unseenparaphrasing also increases from 0.892 to 0.920. The result suggests that the detection performance
of RADAR in the with and without paraphrasing settings can be simultaneously improved or better
balanced with careful tuning of the hyperparameter λ during training.
Conclusion
In this paper, we presented a robust AI-text detector training framework called RADAR, which adopts
adversarial learning to jointly train a detector and a paraphraser. RADAR addresses the shortcoming
of existing detectors when facing LLM-paraphrased texts. Our extensive experiments on 8 LLMs and
4 datasets validated the effectiveness of RADAR and demonstrated its strong transferability across
LLMs. We believe our results shed new light on improving AI-text detection.
Limitations and Ethical Considerations
While RADAR is more robust to paraphrasing than existing baselines measured on 4 datasets,
sometimes it may show degraded detection performance against native LLM-generated texts (without
paraphrasing) when compared to the best existing detection method. Moreover, like every existing
AI-text detector, we acknowledge that our detector is not perfect and will likely give incorrect
predictions in some cases. In terms of ethical considerations, we suggest users use our tool to assist
with identifying AI-written content at scale and with discretion. If the detection result is to be used as
evidence, further validation steps are necessary as RADAR cannot always make correct predictions.
8 
Acknowledgement
The authors thank James Sanders and Jonathon Hartley for providing examples that can weaken the
detection of RADAR models.