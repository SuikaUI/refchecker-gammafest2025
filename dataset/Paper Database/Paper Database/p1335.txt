astro-ph/0701113
Information criteria for astrophysical model selection
Andrew R. Liddle
Astronomy Centre, University of Sussex, Brighton BN1 9QH, United Kingdom
Institute for Astronomy, University of Hawai‘i, 2680 Woodlawn Drive, Honolulu, Hawai‘i 96822, U.S.A.
26 November 2024
Model selection is the problem of distinguishing competing models, perhaps featuring different numbers of parameters. The statistics literature contains two distinct sets of tools, those
based on information theory such as the Akaike Information Criterion (AIC), and those on
Bayesian inference such as the Bayesian evidence and Bayesian Information Criterion (BIC).
The Deviance Information Criterion combines ideas from both heritages; it is readily computed from Monte Carlo posterior samples and, unlike the AIC and BIC, allows for parameter
degeneracy. I describe the properties of the information criteria, and as an example compute
them from WMAP3 data for several cosmological models. I ﬁnd that at present the information theory and Bayesian approaches give signiﬁcantly different conclusions from that data.
Key words: cosmology: theory, methods: data analysis, methods: statistical
INTRODUCTION
Although it has been widely recognized only recently, model selection problems are ubiquitous in astrophysics and cosmology. While
parameter estimation seeks to determine the values of a parameter set chosen by hand, model selection seeks to distinguish between competing choices of parameter set. A considerable body
of statistics literature is devoted to model selection [excellent textbook accounts are given by Jeffreys 1961, Burnham & Anderson
2002, MacKay 2003, and Gregory 2005] and its use is widespread
throughout many branches of science. For a non-technical overview
of model selection as applied to cosmology, see Liddle, Mukherjee
& Parkinson , and for an overview of techniques and applications see Lasenby & Hobson .
In general, a model is a choice of parameters to be varied and
a prior probability distribution on those parameters. The goal of
model selection is to balance the quality of ﬁt to observational data
against the complexity, or predictiveness, of the model achieving
that ﬁt. This tension is achieved through model selection statistics,
which attach a number to each model enabling a rank-ordered list
to be drawn up. Typically, the best model is adopted and used for
further inference such as permitted parameter ranges, though the
statistics literature has also seen increasing interest in multi-model
inference combining a number of adequate models .
There are two main schools of thought in model selection.
Bayesian inference, particularly as developed by Jeffreys culminating in his classic textbook and by many others since, can assign probabilities to models as well as to parameter values, and manipulate these probabilities using rules such
as Bayes’ theorem. Information-theoretic methods, pioneered by
Akaike with his Akaike Information Criterion, instead focus
on the Kullback–Leibler information entropy as a measure of information lost when a particular model is
used in place of the (unknown) true model. Variants on this latter
theme include the Takeuchi Information Criterion , which extends the AIC by droppinging the assumption that
the model set considered includes the true model. Bayesian statistics include the Bayesian evidence and an approximation to it
known as the Bayesian Information Criterion ,
which, despite the name, does not have an information-theoretic
justiﬁcation.
Given the plethora of possible statistics, one might despair as
to which to use, especially if they give conﬂicting results. Cosmologists, in particular, tend to ally themselves with a Bayesian methodology, for example the use of Markov Chain Monte Carlo (MCMC)
methods to carry out parameter likelihood analyses, and are therefore tempted to adopt methods advertised as such. However, even
if one were to side automatically against frequentist approaches,
the situation does not appear that clear cut; Burnham & Anderson
 have argued that the AIC can be derived in a Bayesian way
(and the BIC in a frequentist one), and that one should not casually
dismiss a criterion soundly grounded in information theory.
Nevertheless, in my view the Bayesian evidence is the preferred tool; in Bayesian inference it is precisely the quantity which
updates the prior model probability to the posterior model probability, and has an unambiguous interpretation in these probabilistic
terms. The problem with the evidence is the difﬁculty in calculating
it to the required accuracy, though the situation there has improved
with the development of the nested sampling algorithm and its implementation for cosmology in the CosmoNest
code . This paper is principally directed at circumstances
where the evidence is not readily calculable, and a simpler model
selection technique is required.
In this article I describe and apply an additional information
c⃝0000 RAS
Andrew R. Liddle
criterion, the Deviance Information Criterion (DIC) of Spiegelhalter et al. , which combines heritage
from both Bayesian methods and information theory. It has interesting properties. Firstly, unlike the AIC and BIC it accounts for the
situation, common in astrophysics, where one or more parameters
or combination of parameters is poorly constrained by the data.
Secondly, it is readily calculable from posterior samples, such as
those generated by MCMC methods. It has already been used in
astrophysics to study quasar clustering .
MODEL SELECTION STATISTICS
Bayesian evidence
The Bayesian evidence, also known as the model likelihood and
sometimes, less accurately, as the marginal likelihood, comes from
a full implementation of Bayesian inference at the model level, and
is the probability of the data given the model. Using Bayes theorem,
it updates the prior model probability to the posterior model probability. Usually the prior model probabilities are taken as equal,
but quoted results can readily be rescaled to allow for unequal
ones if required . In many circumstances the evidence can be calculated without simplifying assumptions (though perhaps with numerical errors). It has now been quite
widely applied in cosmology; see for example Jaffe , Hobson, Bridle & Lahav , Saini, Weller & Bridle , Trotta
 , Parkinson et al. , and Lasenby & Hobson .
The evidence is given by
L(θ) P(θ) dθ ,
where θ is the vector of parameters being varied in the model and
P(θ) is the properly-normalized prior distribution of those parameters (often chosen to be ﬂat). It is the average value of the likelihood
L over the entire model parameter space that was allowed before
the data came in. It rewards a combination of data ﬁt and model
predictiveness. Models which ﬁt the data well and make narrow
predictions are likely to ﬁt well over much of their available parameter space, giving a high average. Models which ﬁt well for
particular parameter values, but were not very predictive, will ﬁt
poorly in most of their parameter space driving the average down.
Models which cannot ﬁt the data well will do poorly in any event.
The integral in equation (1) may however be difﬁcult to calculate, as it may have too many dimensions to be amenable to
evaluation by gridding, and the simplest MCMC methods such as
Metropolis–Hastings produce samples only in the part of parameter
space where the posterior probability is high rather than throughout the prior. Nevertheless, many methods exist , and the nested sampling algorithm 
has proven feasible for many cosmology applications .
A particular property of the evidence worth noting is that it
does not penalize parameters (or, more generally, degenerate parameter combinations) which are unconstrained by the data. If the
likelihood is ﬂat or nearly ﬂat in a particular direction, it simply
factorizes out of the evidence integral leaving it unchanged. This is
an appealing property, as it indicates that the model ﬁtting the data
is doing so really by varying fewer parameters than at ﬁrst seemed
to be the case, and it is the unnecessary parameters that should be
discarded, not the entire model.
AIC and BIC
Much of the literature, both in astrophysics and elsewhere, seeks a
simpler surrogate for the evidence which still encodes the tension
between ﬁt and model complexity. In Liddle , I described
two such statistics, the AIC and BIC, which have subsequently been
quite widely applied to astrophysics problems. They are relatively
simple to apply because they require only the maximum likelihood
achievable within a given model, rather than the likelihood throughout the parameter space. Of course, such simpliﬁcation comes at a
cost, the cost being that they are derived using various assumptions,
particularly gaussianity or near-gaussianity of the posterior distribution, that may be poorly respected in real-world situations.
The AIC is deﬁned as
AIC ≡−2 ln Lmax + 2k ,
where Lmax is the maximum likelihood achievable by the model
and k the number of parameters of the model . The
best model is the one which minimizes the AIC, and there is no
requirement for the models to be nested. The AIC is derived by
an approximate minimization of the Kullback–Leibler information
entropy, which measures the difference between the true data distribution and the model distribution. An explanation geared to astronomers can be found in Takeuchi , while the full statistical
justiﬁcation is given by Burnham & Anderson .
The BIC was introduced by Schwarz , and is deﬁned as
BIC ≡−2 ln Lmax + k ln N ,
where N is the number of datapoints used in the ﬁt. It comes from
approximating the evidence ratios of models, known as the Bayes
factor . The BIC assumes that
the datapoints are independent and identically distributed, which
may or may not be valid depending on the dataset under consideration (e.g. it is unlikely to be good for cosmic microwave anisotropy
data, but may well be for supernova luminosity-distance data).
Applications of these two criteria have usually shown broad
agreement in the conclusions reached, but occasional differences
in the detailed ranking of models. One should consider the extent
to which the conditions used in the derivation of the criteria are violated in real situations. A particular case in point is the existence of
parameter degeneracies; inclusion (inadvertent or otherwise) of unconstrained parameters is penalized by the AIC and BIC, but not by
the evidence. Interpretation of the BIC as an estimator of evidence
differences is therefore suspect in such cases.
Burnham & Anderson have stressed the importance of using a version of the AIC corrected for small sample sizes,
AICc. This is given by 
AICc = AIC + 2k(k + 1)
Since the correction term anyway disappears for large sample sizes,
N ≫k, there is no reason not to use it even in that case, i.e. it is
always preferable to use AICc rather than the original AIC. In typical small-sample cases, e.g. N/k being only a few, the correction
term strengthens the penalty, bringing the AICc towards the BIC
and potentially mitigating the difference between them.
The DIC was introduced by SBCL02. It has already been widely
applied outside of astrophysics. Its starting point is a deﬁnition of
an effective number of parameters pD of a model. This quantity,
c⃝0000 RAS, MNRAS 000, 000–000
Information criteria for astrophysics
known also as the Bayesian complexity, has already been introduced into astrophysics by Kunz, Trotta & Parkinson , with
focus on assessing the number of parameters that can be usefully
constrained by a particular dataset.
It is deﬁned by
pD = D(θ) −D(¯θ),
where D(θ) = −2 ln L(θ) + C .
Here C is a ‘standardizing’ constant depending only on the data
which will vanish from any derived quantity, and D is the deviance
of the likelihood. The bars indicate averages over the posterior distribution. In words, then, pD is the mean of the deviance, minus the
deviance of the mean. If we deﬁne an effective chi-squared as usual
by χ2 = −2 ln L, we can write
pD = χ2(θ) −χ2(¯θ) .
Its intent becomes clear from studying a simple onedimensional example, in which the likelihood is a gaussian of zero
mean and width σ, i.e. ln L = A −x2/2σ2, and where the prior
distribution is ﬂat with width aσ. Care is needed to properly normalize the posterior, which relates the likelihood amplitude A to
the prior width. In the limit where a ≫1, so that the posterior
is well conﬁned within the prior, one ﬁnds pD = 1 (in this case,
the averaging is just evaluating the variance of the distribution, but
in units of that variance). This corresponds to a well-measured parameter. If instead a ≪1, so that the data are unable to constrain
the parameter, then pD →0 since χ2 becomes independent of x.
Hence pD indicates the number of parameters actually constrained
by the data. Extension of the above argument to an N-dimensional
gaussian, potentially with covariance, indicates pD = N if all dimensions are well contained within the prior, and pD < N otherwise .
One issue of debate in the statistics literature is the choice of
the mean parameter value in the deﬁnition of pD. One could alternatively argue for the maximum likelihood in its place. This choice
affects the possible reparametrization dependence of the statistic
 . It may be that the best choice depends on the situation under study (e.g. the mean parameter value
will be a poor choice if the likelihood has distinct strong peaks).
The DIC is then deﬁned as
DIC ≡D(¯θ) + 2pD = D(θ) + pD .
The ﬁrst expression is motivated by the form of the AIC, replacing the maximum likelihood with the mean parameter likelihood,
and the number of parameters with the effective number. It can
therefore be justiﬁed on information/decision theory grounds, as
discussed by SBCL02. The second form is interesting because the
mean deviance can be justiﬁed in Bayesian terms, which always
deal with model-averaged quantities rather than maximum values.
The DIC has two attractive properties:
(i) It is determined by quantities readily obtained from Monte
Carlo posterior samples. One simply averages the deviances over
the samples. If the calculation is being done by whoever generated
the chains, they can obtain the deviance at the mean with a single
extra likelihood call, but even if using chains generated by others,
it should be ﬁne to use the sample closest to that mean value as the
estimator, especially bearing in mind the possibility that the mode
could have been used in place of the mean. The calculation is also
easily done with posterior samples generated by nested sampling,
which have non-integer weights .
(ii) By using the effective number of parameters, the DIC overcomes the problem of the AIC and BIC that they do not discount
parameters which are unconstrained by the data.
Note that in the case of well-constrained parameters, the DIC
approaches the AIC and not the BIC, since D(¯θ) →−2 ln Lmax
and pD →k. It is plausible to believe that it too can be corrected
for small dataset sizes using the same formula that leads to AICc,
though to my knowledge there is currently no proof of this.
Other criteria
In addition to those already mentioned, the literature contains many
other information criteria, but mostly sharing the heritage of those
above. The TIC generalizes the AIC by dropping
the assumption that the true model is in the set considered, but in
practice is hard to compute and, where computation has been carried out, tends to give results very similar to the AIC . A Bayesian version of the AIC, the Expected AIC (EAIC), where one takes its expected value over the
posterior distribution rather than evaluating at the maximum, has
been proposed (by Brooks in the comments to SBCL02) but does
not appear to have been signiﬁcantly applied.
Other information criteria, which appear to have been less
widely used, include the Network Information Criterion (NIC), the
Subspace Information Criterion (SIC, though this abbreviation is
sometimes used for Schwarz Information Criterion as another name
for the BIC), and the Generalized Information Criterion (GIC). The
DIC also comes in many variants, see e.g. Celeux et al. .
An interesting variant was proposed by Sorkin , using
a Turing machine construction to deﬁne an entropy associated with
the theory to be used as a penalty term. This was recently applied
to cosmological data by Magueijo & Sorkin . It has not been
picked up by the statistics community, but may be related to the
widely-used minimum message length paradigm . The idea of interpetting the best model as
the one offering maximal algorithmic compression of the data goes
all the way back to late 17th century writings by Leibniz.
Dimensional consistency and model selection philosophy
Dimensional consistency refers to the behaviour of the model selection statistics in the limit of arbitrarily large datasets. The BIC
and evidence are dimensionally consistent, meaning that if one of
the considered models is true, they give 100 per cent support to that
model as the dataset becomes large. As a necessary consequence,
however, they will give 100 per cent support to the best model even
if it is not true. By contrast, the AIC is dimensionally inconsistent
 , sharing its support around the models even with
inﬁnite data. As the DIC approaches the AIC in the limit of large
datasets, it too is dimensionally inconsistent (SBCL02).
Dimensional consistency does not seem to particularly bother
most statisticians, as they are typically seeking models which can
explain data and have some predictive power, rather than expecting to represent some underlying truth. Indeed, they commonly
quote statistician George Box: “All models are wrong, but some
are useful.” The problem of dimensional consistency is therefore
mitigated, because they do not expect the set of models to remain
static as the dataset evolves. Cosmologists, however, are probably
not yet willing to concede that they might be looking for something
other than absolute truth speciﬁed by a ﬁnite number of parameters. Combining this line of argument with statements above, this
implies that the Bayesian evidence indeed is the preferred choice
for cosmological model selection when it can be calculated.
c⃝0000 RAS, MNRAS 000, 000–000
Andrew R. Liddle
Table 1. Results for comparison of different models to WMAP3 data. The differences are quoted with respect to the ﬁrst model. Negative is preferred.
Parameters k
−2 ln L(¯θ)
−2 ln Lmax
Base+ASZ+nS
Base+ASZ+nS+r
Base+ASZ+nS+running
INFORMATION CRITERIA FOR WMAP3
I now apply the information criteria to WMAP3 model ﬁts as compiled by the WMAP team on LAMBDA.1 The DIC calculation is
straightforward. The 8 chains for each cosmology are concatenated,
the mean deviance found by averaging the likelihoods, and the deviance at the mean estimated by ﬁnding the MCMC point located
closest to the mean (where the distance in each parameter direction
was measured in units of the standard deviation of that parameter).
I also quote the values of the differences in AICc and BIC,
where the maximum likelihood is taken directly from the most
likely posterior sample (in principle this may slightly disadvantage
models with more parameters, for which the most likely sample
will typically be slightly further from the true maximum, though
for the WMAP3 sample sizes this effect will be small). I take N to
be the number of power spectrum datapoints, NWMAP3 = 1448
 , this choice to be discussed further below
(nothing changes signiﬁcantly if a slightly larger number ∼3000 is
used to allow for the pixel-based treatment of the low-ℓlikelihood).
With this large value, ∆AIC and ∆AICc are indistinguishable.
The available model ﬁts unfortunately do not quite cover all
cases that might be of interest. All well-ﬁtting models vary ﬁve
standard parameters, being the physical baryon density Ωbh2, the
physical cold dark matter density Ωch2, the sound horizon θ, the
perturbation amplitude ln(1010AS), and the optical depth τ (the
Hubble constant and dark energy density are derived parameters).
However ﬁts varying just these parameters, a Harrison–Zel’dovich
model suggested as the best model from ﬁrst-year WMAP data in
Liddle , are not available. Nevertheless, I will refer to this
as the Base model. Instead, there are two different six-parameter
models, one adding the spectral index nS and one adding the phenomenological Sunyaev–Zel’dovich (SZ) marginalization parameter ASZ . All further available models include
ASZ; extra parameters that I then consider are the spectral index
nS (giving the standard ΛCDM model), further addition of tensors
r to give the standard slow-roll inﬂation model, and inclusion of
spectral index running (without tensors).
The main subtlety is the inclusion of ASZ. This is poorly constrained by the data and hence is not expected to contribute fully to
pD; nevertheless the likelihood does have some dependence on it
and it must be included in the analysis that determines the deviance
at the mean. Of the parameters considered, ASZ and τ are phenomenological parameters which, at least in principle though not
yet in practice, can be determined from the others. The remaining
four are truly independent according to present understanding.
The uncertainty in the DIC may not be well estimated by analyzing subsamples, as with smaller samples the mean deviance
will be less well estimated by the nearest point. Instead I estimated
Background
 
downloaded
2006. The subsequent January 2007 update does not allow model selection
as the chains were not all generated with the same likelihood code.
the uncertainty by employing bootstrap resamples of the combined
sample list. This showed that the statistical accuracy was limited by
the accuracy with which the ln L values were stored, ±0.1 corresponding to ±0.2 in the DIC. As this is a much smaller uncertainty
than the level at which differences are signiﬁcant, the statistical uncertainty in the determination of the DIC is negligible.
The results are shown in Table 1. The pD values are in good
agreement with expectation. Kunz et al. computed pD for
several models using a compilation of microwave anisotropy data
including WMAP3, and always found pD close to the input number of parameters. However they ran their own chains and did not
include the poorly-constrained parameters ASZ and r. Models including those parameters return a pD signiﬁcantly less than k.
While only the Bayesian evidence has the full interpretation
as the model likelihood, leading to the posterior model probability,
the AIC has also been interpretted as a model likelihood by deﬁning
Akaike weights 
exp(−∆AICc,i/2)
r=1 exp(−∆AICc,r/2)
where there are R models and the differences are with respect to
any one. The same interpretation can be given to the DIC differences (SBCL02). For the BIC, insofar as it well approximates twice
the log of the Bayes factor, it too can be interpreted as a model likelihood. By convention signiﬁcance is then judged on the Jeffreys’
scale, which rates ∆IC > 5 as ‘strong’ and ∆IC > 10 as ‘decisive’ evidence against the model with higher criterion value. If
the interpretation as model likelihoods holds, these points correspond to odds ratios of approximately 13:1 and 150:1 against the
weaker model. As with the evidence, these likelihoods can be further weighted by a prior model probability if desired.
Recall that the DIC, like the AIC, is motivated from information theory, while the BIC is not. Indeed, we see that the DIC results quite closely follow the AIC results; both argue quite strongly
against the Base+ASZ model, but are then rather inconclusive
amongst the remaining models. So information theory methods are
neither for nor against inclusion of extra parameters such as r and
running at this stage. Incidentally, we can also see that if the DIC
were deﬁned using Lmax rather than L(¯θ), little difference would
have arisen in this comparison.
The information criteria indicate that WMAP3 has put the
Harrison–Zel’dovich model (with SZ marginalization) under considerable, if not yet conclusive, pressure. This is in accord with the
conclusions reached by Spergel et al. using chi-squared per
degree of freedom arguments, though the information criterion give
weaker support to this conclusion by recognizing model dimensionality. The strength of conclusion against Harrison–Zel’dovich
could also be weakened by various systematic effects in data analysis choices, e.g. inclusion of gravitational lensing ,
beam modelling , and point-source subtraction .
By contrast, Bayesian approaches do not put nS = 1 under
c⃝0000 RAS, MNRAS 000, 000–000
Information criteria for astrophysics
any kind of pressure. Parkinson et al. found that the full evidences for the Base model and Base+nS were indistinguishable
with WMAP3 alone, and still inconclusive with inclusion of other
datasets. However that analysis did not include SZ marginalization,
and so the equivalent comparison cannot be made here. However
the BIC comparison between those models each with ASZ added
does not show any strong preference, and it seems a safe bet that
had the Base model itself been supplied by WMAP3, its BIC difference compared with Base+nS, the best model in the set as judged
by the BIC, would not have been signiﬁcant.
Further, while the information theory methods are ambivalent
about r and running, the BIC argues rather strongly against, especially in the case of tensors which offer no improvement at all in
data-ﬁtting. Full evidence calculations however show that this conclusion is quite prior dependent .
That the two methods give such different answers is due to
the way that prior assumptions are treated, in particular the prior
widths of the parameter ranges. The AIC does not care about this
at all, and the DIC only cares while the data is weak enough that
some prior information on the parameter distribution remains. By
contrast, in Bayesian model comparison the prior width is a key
concept, determining the predictiveness of the model. For the evidence this is reﬂected in the domain of integration over which the
likelihood is averaged, while for the BIC it is in the dependence on
the amount of data. Cosmologists are in the fortunate position that
for many parameters the likelihood is highly compressed within
reasonable priors, forcing a discrepancy between information theory and Bayesian results. This discrepancy will be further enhanced
in the future if the data continue to improve without requiring evolution in the model dataset, i.e. the problem of dimensional inconsistency of the AIC/DIC may already be with us.
Concerning the inclusion of ASZ in models, it is clear that
Bayesian methods don’t like including it as a ﬁt parameter, since
it is poorly constrained and does not signiﬁcantly improve the ﬁt.
However the SZ effect is certainly predicted to be in the data at
some level, though it ought to be derived from the other parameters
rather than ﬁt. It is tempting to try to deal with this by using pD in
the BIC rather than k, but there is no existing justiﬁcation for doing
so. The same issue does not arise with the optical depth, also a
derived parameter, as it is well constrained by the data in all models.
In computing the BIC above, I adopted the number of datapoints literally. This may not always be the best choice: the derivation of the BIC requires the data to be independent and identically
distributed, and it may be that this can be better achieved by binning the data in some suitable way. However to do so would require
a whole new likelihood analysis for the binned data, counter to the
desire here that the methods should be applicable to pre-existing
posterior samples. In any case there does not appear to be any welldeﬁned way to judge how much binning, if any, is desirable.
Finally, I note that while here it is the BIC which appears to
behave most like the evidence, in their quasar clustering studies
Porciani & Norberg found that the DIC was the only criterion to give precisely the same model ranking order and level of
inconclusiveness as the Bayes factors, with the BIC underﬁtting.
I have described several information criteria that can be used for astrophysical model selection, representing the rival strands of information theory and Bayesian inference. In application to WMAP3
data, the DIC behaves rather similarly to the AIC, despite the presence of parameter degeneracies. The conclusions one would draw
from those statistics are rather different from those indicated by
Bayesian methods, either the full evidence as computed in Parkinson et al. or the BIC as calculated in this article.
ACKNOWLEDGMENTS
This research was supported by PPARC. Thanks to David Parkinson and Pia Mukherjee for advice on analyzing WMAP chains, and
Istvan Szapudi for discussions.