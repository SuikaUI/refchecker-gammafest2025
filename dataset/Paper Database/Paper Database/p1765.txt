Recommending POIs
based on the User’s Context and Intentions
Hernani Costa, Barbara Furtado, Durval Pires,
Luis Macedo, and Amilcar Cardoso
 , {bfurtado,durval}@student.dei.uc.pt,
{macedo,amilcar}@dei.uc.pt
CISUC, University of Coimbra, Portugal
Abstract. This
Recommender
implements a Multiagent System for making personalised context and
intention-aware recommendations of Points of Interest (POIs). A twoparted agent architecture was used, with an agent responsible for
gathering POIs from a location-based service, and a set of Personal
Assistant Agents (PAAs) collecting information about the context and
intentions of its respective user. In each PAA were embedded four
Machine Learning algorithms, with the purpose of ascertaining how wellsuited these classiﬁers are for ﬁltering irrelevant POIs, in a completely
automatic fashion. Supervised, incremental learning occurs when the
feedback on the true relevance of each recommendation is given by
the user to his PAA. To evaluate the recommendations’ accuracy, we
performed an experiment considering three types of users, using diﬀerent
contexts and intentions. As a result, all the PAA had high accuracy,
revealing in speciﬁc situations F1 scores higher than 87%.
Keywords: information overload, machine learning algorithms, multiagent
systems, personal assistant agents, recommender systems, user modelling.
Introduction
Nowadays, we are experiencing a huge growth in the quantity of information
available. This was mainly caused by the advent of communication technology
which humans cannot handle properly, and made critical the need for intelligent
assistance when browsing, searching or exploring for interesting information.
In order to cope with this superabundance, Recommender Systems (RS) are a
promising technique to be used, for instance in location-based domains .
The majority of RS’ approaches focus on either ﬁnding a match between an
item’s description and the user’s proﬁle (Content-Based ), or ﬁnding
users with similar tastes (Collaborative Filtering ). These traditional
RS consider only two types of entities, users and items, and do not put them
into a context when providing recommendations – context, in ubiquitous and
mobile context-aware systems, can be deﬁned as the location of the user, in
order to identity people and objects around him, and the changes in these
elements . However, the most relevant information for the user may not only
depend on his preferences and context, but also in his current intentions . For
example, the very same item can be relevant to a user in a particular context,
and completely irrelevant in a diﬀerent one. This is due to the fact that user’s
preferences and intentions change over time. For this reason, we believe that it
is important to have the user’s context and intentions in consideration during
the recommendation process .
In this work, our goal is to develop a RS that implements a Multiagent
System (MAS). Given the user’s context and intentions and the sources at our
disposal, it will be imperative to create a system capable of recommending POIs
in a selective fashion . Additionally, we intend to ascertain how well-suited
diﬀerent Machine Learning (ML) algorithms are to automatically ﬁlter irrelevant
POIs. After collecting a small set of POIs from a Web location-based service and
updating these manually with extra information, three diﬀerent users’ models
via stereotypes are created by using a set of rules. Our assumption is that
the system will be able to understand the diﬀerences between each user, since
each one has unique preferences, intentions and behaviours, resulting in diﬀerent
recommendations for diﬀerent users, even if their context is the same. In order
to accomplish that, a MAS was embedded with the purpose of provide selective
information to the users . The recommendations’ accuracy will be evaluated
by correlating the recommendations outputs given by these algorithms, with
nine human judges.
The remaining of the paper starts with a presentation of the system’s
architecture (section 2). Then, section 3 provides an overview of the experimental
set-up, and section 4 describes the results obtained. Finally, section 5 presents
the ﬁnal remarks.
System Architecture
In this section, we present the system’s architecture and all its components used
in this work (see ﬁgure 1). This architecture can be seen as a middleware between
the user’s needs and the information available.
More speciﬁcally, the Master Agent is responsible for starting, not only the
Web agents, but also the PAAs, described in ﬁgure 1 as PAA1 · · · PAAn. The system
is capable of retrieving POIs’ information from several location-based services.
However, for the purpose of this work it is only used the Foursquare service,
which explains why we used only one Web agent (Agentfourquare).
Agentfoursquare implements several methods available through the Foursquare
API1, allowing it to start requesting for POIs in a pre-deﬁned area (see section
3.1). During this process, it ﬁlters all the POIs that do not belong to the
categories we will use in this experiment, and stores the remaining POIs in our
system’s database (presented in ﬁgure 1 as POIs Database). This autonomous
1 
user%s&model
Master/Agent
user%s&model
Agent_foursquare
POIs' extra
information
Fig. 1. System’s Architecture.
agent is constantly searching for new information, and verifying if the data stored
in the database is up-to-date.
Due to the fact that Foursquare service did not have all the information
needed for the experiment, we decided to gather more information about the
POIs on the ﬁeld (e.g., POIs’ price, timetable, dayOﬀ, as well as some of the
attributes missing). This allowed us to have more details about each POI in
order to fulﬁl the set-up requirements of the experiment (see section 3). Thus,
this extra information was used to update the POIs’ attributes in the database.
As we can see in ﬁgure 1, each user has a PAA assigned to him. This agent
expects the user to make a request, and, based on his context and intentions
(see section 3.2), recommends a list of nearby POIs. In order to improve its
recommendations, the PAA continuously learns from the user’s experiences.
Concretely, each PAA implements a probabilistic classiﬁer to assign a probability
value to the relevance of each POI, given the current user’s context and intention.
Therefore, when the feedback of the true relevance of each recommendation is
given by the user to his PAA, the PAA updates its model (described in ﬁgure 1
as user’s model). As a result, the agent learns every time the user decides to
make a request and give his feedback.
Experiment Set-up
Our main objective is to demonstrate how we can face the information overload
problem in the location-based service domain by using a MAS architecture.
More precisely, it is our intention to take advantage of the multiple independent,
autonomous, and goal-oriented units, so called PAAs. In addition, we intend to
verify how accurate diﬀerent ML algorithms perform the task of predicting the
user’s preferences, while taking his context and intentions into account.
To achieve this goal, an eﬀectiveness evaluation of our system will be
performed in section 4. But ﬁrstly, we start by explaining the experiment setup. In detail, the area where we will perform the experimentation is presented
in section 3.1. Then, the main attributes used to deﬁne the user’s context and
intentions are presented in section 3.2. Finally, section 3.3 presents the user
stereotypes considered in this work, as well as how their models were created.
Area of Work
The experimentation was performed in Coimbra (Portugal). The number of POIs
existent in the city made it impossible to manually update all the POIs retrieved
with the extra information needed to this experiment. Thus, a smaller part of
the city that had more POIs density and diversity (Coimbra’s Downtown) was
used. Furthermore, the type of POIs used were restricted to {Food, Shopping,
Nightlife} (the categories that contain more POIs in this area). The number
of sub-categories for Food are 44, Shopping 8 and Nightlife 11, with 271, 10
and 84 diﬀerent POIs, respectively. The extra information manually gathered
from these 365 places was the POI’s price, the day oﬀand the timetable (the
possible values for each attribute is explained in the next topic).
Deﬁning Context and Intentions
Context is the key to personalise the automatic recommendations made by the
PAAs for their users. Thus, a set of attributes need to be deﬁned in order to
characterise the POI’s context, as well as the user’s context and intentions. Since
these attributes need to be combined, an interface was used to visualise current
user location, i.e., his context and intention. The main attributes used to deﬁne
the user, the POI and the information available in the interface are shown in
distanceToPOI
currentTime
Fig. 2. Main attributes used to deﬁne the context of the user, POI and the interface.
Possible values for each attribute of the POI’s context are:
⋄category = {food, shopping, nightlife},
sub-category, e.g., food = ⟨sandwichShop, vegetarian, etc.⟩,
shopping = ⟨men’sApparel, women’sApparel, etc.⟩and
nightlife = ⟨wineBar, disco, etc.⟩
⋄dayOff = {a day of the week or combinations}
⋄price = {cheap, average, expensive}, e.g., for lunch {cheap≤5e;
5e>average≤7e; expensive>7e}
⋄timetable = {morning, afternoon, night, or combinations}
Possible values provided by the interface are:
⋄distanceToPOI = {near≤200m; 200m >average≤300m; far> 300m}
⋄currentTime = {current day of the week and period of the day
(morning, afternoon or night)}
Possible values for each attribute of the user’s context are:
⋄budget = {low, medium, high}, e.g., for lunch {low≤5e;
5e>medium≤7e; high>7e}
⋄dayOfWeek = {current day of the week}
⋄goal = {coffee, lunch, dinner, party}, e.g., drink coffee
in a {bakery, coffeeShop, etc.}, have lunch and dinner in {burgers,
BBQ, etc.} and party in a {bar, disco, etc.}
⋄timeOfDay = {morning, afternoon or night)}
After deﬁning the main attributes considered in this work, we are now able
to explain how these were used to create the users’ models.
Datasets and Users Model Description
As one of the goals in this work is the study of diﬀerent user’s proﬁles, we have
created three diﬀerent types of users, which we believe to be very common in
our society:
· u1 −a user which prefers POIs that are cheap and near
· u2 −a user which prefers POIs that are near
· u3 −a user which prefers POIs that are expensive
Another objective for this work is the analysis of diﬀerent probabilistic
classiﬁers suitable for the task of ﬁltering irrelevant POIs, in a completely
automatic fashion. For this purpose, two diﬀerent Bayes classiﬁers (Na¨ıve Bayes
and BayesNet) and two versions of the C4.5 decision tree learner (J48 pruned
and unpruned), available through the Weka API2, were implemented.
However, the cold-start problem needs to be resolved. In order to
overcome this problem, a set of rules were used to create three datasets for
the three user stereotypes. In detail, the rules used (described in equation 1)
consider not only the type of user, but also his goals (i.e., intentions) when given
automatic feedback to the POIs in a speciﬁc situation. The values given by these
rules are binary, 1 if satisﬁes the user’s goal or ∅if not. To create the datasets
we simulated 420 runs, for each type of user. For the sake of clarity, a run (r)
represents a combination of the user’s context and goals with the POIs’ context
(all the POIs retrieved by the interface in the radius of 400m), i.e., a situation.
The resulted datasets, represented as d1, d2 and d3, contain:
· d 1 = 5844 instances, 1371 classiﬁed as 1 and 4473 as ∅
· d 2 = 6014 instances, 1774 classiﬁed as 1 and 4240 as ∅
2 
· d 3 = 6259 instances, 2590 classiﬁed as 1 and 3669 as ∅
The dataset number (dn) correspond to the user type (un).
R(Goal(un)) =
∀Goal(u1) if (distance ≤200m &&
price = cheap),
∀Goal(u2) if (distance ≤200m),
∀Goal(u3) if (price = expensive), R(u3) = 1
otherwise,
Our experiment can be divided into three diﬀerent evaluations. Firstly, we
made a manual evaluation and calculated the exact agreement between the
human judges (section 4.1). Then, using the feedback of the judges about the
true correctness of the recommendations, a 10 times tenfold cross-validation
was performed with purpose of evaluating the ML algorithms’ performance
(section 4.2). Finally, well-know metrics were used to compare and analyse the
recommendations given by the PAAs with manual evaluation (section 4.3).
Manual Evaluation
To test our approach, it was used a set of scenarios from real situations. More
precisely, in this experiment it were used 3 locations (the ones that had more
POI density) in 5 diﬀerent situations (i.e., considering diﬀerent user’s contexts
and intentions). These combinations were named runs (r). Next, it is presented
the ﬁrst 5 runs (location, time of day, day of the week and goal).
r 1 = [40.208934, -8.429067, Morning, Sunday, Coffee]
r 2 = [40.208934, -8.429067, Morning, Monday, Coffee]
r 3 = [40.208934, -8.429067, Afternoon, Wednesday, Lunch]
r 4 = [40.208934, -8.429067, Night, Thursday, Dinner]
r 5 = [40.208934, -8.429067, Night, Saturday, Party]
Then, these runs were manually evaluated by a set of human judges, whose
purpose was to analyse the exact agreement (EA) between them, as well as to
compare the PAAs’ recommendations with their evaluation.
In this experiment it was used 9 human judges (H), divided into three group
(G) of 3 people, to evaluate one of the 3 stereotypes (u), i.e., G1=⟨u1 →H1, H2,
H3⟩, G2=⟨u2 →H4, H5, H6⟩and G3=⟨u3 →H7, H8, H9⟩. They were asked to give
their personal opinion for a list of scenarios (15 runs), but never contradicting
the user’s proﬁle they were evaluating.
To perform this evaluation, we have created a user interface using Google
Maps3, see ﬁgure 3. The blue icon represents the current user’s location, and
the other icons represent all the POIs retrieved by the recommender system.
3 
Fig. 3. Manual evaluation example.
Clicking in each POI’s icon, the judges could see an information window
describing the context of each situation, together with the user’s intention.
With this information, the judges could perform their evaluation, clicking in
the option they prefer. The POIs’ names were omitted to avoid that the judges’
personal opinion inﬂuenced the evaluation. It was important to do this to prevent
discrepancy between the judges preferences and the user’s proﬁle that they were
evaluating. Each human judge was asked to assign one of the following values to
each POI, according to the current user’s context and POI’s context:
∅- if the POI does not satisfy the user’s context and his intention;
1 - if the POI satisﬁes the user’s context and his intention.
The EA among the judges (for the 15 runs) in the G1 (group one) resulted in
99.4%, 100% for the G2, and ﬁnally 99.4% for the G3. Despite of the small set
of judges, the EA among them, means they have very similar opinions, for all
the stereotypes evaluated, validating the data that will be used in the following
Preleminary Results
To make the evaluation test, it was chosen the 10 times tenfold cross-validation
 . This test was performed over the instances used in the training with the
recommendations given by the algorithms for the 3 types of users, for the 15 runs.
Table 1 presents the percentage of correctly and incorrectly classiﬁed instances,
and also the statistics for the classiﬁers used (BayesNet, J48 pruned, J48
unpruned and Na¨ıve Bayes, presented as BN, J48p, J48u and NB, respectively).
Table 2 shows in detail the accuracy of the classiﬁers for the user stereotype
u3. For each prediction class (Cl), it is presented the percentage of true positive
Table 1. Classiﬁers’ statistics for the three user stereotypes.
BN J48p J48u
BN J48p J48u
BN J48p J48u
Correctly classiﬁed
99.14 98.57
99.43 97.43
97.71 99.71 99.43 99.43 99.71
Kappa statistic
0.03 0.006 0.006 0.03
Root mean squared
10.93 9.45
11.09 5.92
squared error
21.18 23.05
22.60 28.43
30.53 15.98 12.60 12.60 16.73
(TP), false positive (FP), precision (P), recall (R), F1 score (F 1) and ROC
Area (ROC A.). The results shows high accuracy for the classes ∅and 1, this is
due to the fact that the number of instances in the training dataset was balanced.
Table 2. Cross-validation’s statistics for the user stereotype u3.
BN 99.50 0.49 100 99.50 99.75
100 0.00 99.33 100 99.67
J48p 98.61 0.13 99.07 98.61 98.84
98.50 0.14 99.78 98.51 98.14
J48u 98.61 0.14 99.07 98.61 98.84
98.51 0.15 97.78 98.51 98.14
NB 99.50 0.49 100 99.50 99.75
100 0.00 99.33 100 99.67
Performance Evaluation
In order to observe the relation between the manual evaluation and the output
values given by the classiﬁers, the correlation coeﬃcients between them were
computed using the Spearman’s coeﬃcient, where ρ : −100 ≤ρ ≤100 (see
equation 2).
ρ(mi, xi) =
(mi −m)(xi −x)
(mi −m)(xi −x)
Table 3. Correlation coeﬃcients’ results for the three user stereotypes.
BN J48p J48u NB
48.50 49.00 49.00 48.50 100
48.50 49.00 49.00 48.50 100
49.25 49.72 49.33 49.25 98.78
EAG1 48.50 49.00 49.00 48.50 100
48.50 49.00 49.00 48.50
49.01 48.56 48.56 47.34 100
48.67 48.21 48.21 46.99 99.39
49.01 48.56 48.56 47.34 100
EAG2 49.01 48.56 48.56 47.34 100
49.01 48.56 48.56 47.34
49.43 56.50 56.50 49.43 100
49.43 56.50 56.50 49.43 100
48.24 55.27 55.27 48.24 97.27
EAG3 49.43 56.50 56.50 49.43 100
49.43 56.50 56.50 49.43
To evaluate the predictions’ results, it was created a baseline (B) that
classiﬁes each instance based on a set of rules (the same rules used to create
the training datasets, see equation 1). This baseline acts like a trusted base of
comparison with the ML algorithms predictions. Table 3 shows the correlation
outputs for the three user stereotypes, as well as the exact agreement for each
group of judges (EAGn, where n corresponds to the user stereotype).
The high correlation (≈100) between the judges (Hn) and the baseline (B)
resulted in a perfect monotone increasing relationship, what can be seen as
an evidence of the trustiness of their feedback. Although the ML algorithms
have lower correlation compared with the baseline, as expected, all of them have
positive correlation, revealing in speciﬁc situations correlation scores higher than
56% (which can been seen as a good hint to support this approach).
To test the algorithms’ accuracy, F 1 scores were calculated for the 3 types
of users (u1, u2, u3). Table 4 presents the results with the mean (x) and the
standard deviation (σ) for the 15 runs. In order to avoid some of the ambiguity
that could arise when considering only the feedback given by one judge, F 1 was
calculated by using the EA of each group (i.e., the EAGn, where n corresponds to
user stereotype).
Again, it was used a baseline (B, see equation 1) to compare the accuracy
between the algorithms. For the sake of clarity, the runs represent diﬀerent user’s
intentions, more speciﬁcally, runs: {r 1, r 2, r 6, r 7, r 11, r 12}= goal coffee; {r 3, r 8,
r 13}= goal lunch; {r 4, r 9, r 14}= goal dinner; and {r 5, r 10, r 15}= goal party. As
we can see, higher values are obtained for the goals lunch, dinner and coffee
Table 4. F 1 results (%) for the three user stereotypes.
26.67 37.50 37.50 26.67
31.58 30.00 30.00 31.58
26.67 28.57 28.57 26.67
37.50 47.06 47.06 37.50
40.00 38.10 38.10 40.00
26.67 28.57 28.57 26.67
76.19 76.19 76.19 76.19
78.57 78.57 78.57 78.57
81.82 85.71 85.71 81.82
76.19 72.73 72.73 76.19
78.57 78.57 78.57 78.57
81.82 81.82 81.82 81.82
15.38 13.33 13.33 15.38
21.05 21.05 21.05 11.11
26.67 26.67 26.67 26.67
40.00 40.00 40.00 40.00
40.00 33.33 33.33 40.00
40.00 57.14 57.14 40.00
40.00 40.00 40.00 40.00
33.33 33.33 33.33 33.33
40.00 57.14 57.14 40.00
66.67 66.67 66.67 66.67
75.00 75.00 75.00 75.00
54.55 75.00 75.00 54.55
66.67 57.14 57.14 66.67
75.00 75.00 75.00 75.00
54.55 54.55 54.55 54.55
r 10 66.67 57.14 57.14 66.67
57.14 57.14 57.14 57.14
66.67 66.67 66.67 66.67
r 11 72.73 69.57 69.57 72.73
75.00 75.00 75.00 75.00
87.50 87.50 87.50 87.50
r 12 53.57 60.00 60.00 55.56
51.72 63.64 63.64 55.56
42.86 72.73 72.73 50.00
r 13 60.00 60.00 60.00 60.00
57.14 57.14 57.14 57.14
36.36 44.44 44.44 36.36
r 14 60.00 57.14 57.14 60.00
60.00 57.14 57.14 60.00
36.36 36.36 36.36 36.36
r 15 60.00 57.14 57.14 60.00
63.16 57.14 57.14 63.16
71.43 71.43 71.43 71.43
54.55 54.11 54.11 54.68 100 55.82 55.34 55.34 55.41 100 51.59 58.29 58.29 52.07 100
18.56 16.31 16.31 18.56 0.00 18.96 19.65 19.65 20.36 0.00 21.43 21.29 21.29 21.30 0.00
(see the underline values in the r 3, r 4 and r 11, respectively), and lower values
are obtained for the goal party (see for instance r 15). This happens because the
goal party is only valid at night and a lower number of POIs suits that goal,
which lead the classiﬁers to perform worse in these situations. Contrarily, the
goal coffee is valid in all times of day, resulting in a lot more instances and,
consequently, the classiﬁers’ improvement is faster. For example, for the r 11, u3,
all the algorithms have 87.50%.
In general, the algorithms performed similarly, however some of them had
a higher mean, for a speciﬁc user stereotype. For instance, NB had better F 1
scores for u1, for u2 →BN, and for u3 →J48p and J48u.
To sum-up, ML algorithms can be a powerful technique, in location-based
services, to predict which content will be interesting for a determined user.
Nevertheless, with more data and more usage the recommendations’ accuracy
could be improved.
Conclusions
In this paper, we discussed the combination of context and intention-awareness
with RS, applied in a location-based application. We pointed out what
advantages are earned in using, besides the context, the user’s intentions, and
how to integrate both into a location-based RS. We also presented our system’s
architecture and described its advantages. ML techniques were used to train
the classiﬁers, more precisely Na¨ıve Bayes, BayesNet and J48 (pruned and
unpruned).
Additionally, we created an experimental set-up to evaluate the algorithms’
performance, for three types of users. Firstly, a 10 times tenfold cross-validation
test was made. Secondly, in order to observe the relation between the manual
evaluation and the output values given by the PAAs, the correlation coeﬃcients
between them were computed. Finally, we performed an information retrieval
task consisting on the identiﬁcation of correct recommendations, given by the
ML algorithms. All of them had high accuracy, revealing in speciﬁc situations
F 1 scores higher than 87%.
In the future, we are planning numerous improvements to this work, such
as: the use of new information sources, as well as their aggregation; take into
account new attributes (e.g., POI’s quality by considering the number of checkins and the users’ reviews); implement and compare other ML algorithms;
analyse other users’ proﬁles; and allow the user to change what values ﬁt
in each attributes (e.g., what price is considered cheap, as well as allow the
user to select his budget). We think that with more data and more usage the
recommendations’ accuracy could improve. Furthermore, we plan to analyse
the system accuracy when applying selective attention metrics, such as surprise
 , in the recommendation outputs. Finally, we intend to make the application
available to the community in order to get more feedback and also to test our
system in other situations.
Acknowledgments
Work funded by Funda¸c˜ao para a Ciˆencia e Tecnologia — Project PTDC/EIA-
EIA/108675/2008, and by FEDER through Programa Operacional Factores de
Competitividade do QREN — COMPETE:FCOMP-01-0124-FEDER-010146.