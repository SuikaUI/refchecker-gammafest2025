Joint Geometrical and Statistical Alignment for Visual Domain Adaptation
Jing Zhang, Wanqing Li, Philip Ogunbona
Advanced Multimedia Research Lab, University of Wollongong, Australia
 , , 
This paper presents a novel unsupervised domain adaptation method for cross-domain visual recognition.
propose a uniﬁed framework that reduces the shift between domains both statistically and geometrically, referred to as Joint Geometrical and Statistical Alignment
(JGSA). Speciﬁcally, we learn two coupled projections that
project the source domain and target domain data into lowdimensional subspaces where the geometrical shift and distribution shift are reduced simultaneously. The objective
function can be solved efﬁciently in a closed form. Extensive
experiments have veriﬁed that the proposed method signiﬁcantly outperforms several state-of-the-art domain adaptation methods on a synthetic dataset and three different real
world cross-domain visual recognition tasks.
1. Introduction
A basic assumption of statistical learning theory is that
the training and test data are drawn from the same distribution. Unfortunately, this assumption does not hold in many
applications. For example, in visual recognition, the distributions between training and test can be discrepant due
to the environment, sensor type, resolution, and view angle. In video based visual recognition, more factors are involved in addition to those in image based visual recognition. For example, in action recognition, the subject, performing style, and performing speed increase the domain
shift further. Labelling data is labour intensive and expensive, thus it is impractical to relabel a large amount of data
in a new domain. Hence, a realistic strategy, domain adaptation, can be used to employ previous labeled source domain
data to boost the task in the new target domain. Based on
the availability of target labeled data, domain adaptation can
be generally divided into semi-supervised and unsupervised
domain adaptation. The semi-supervised approach requires
a certain amount of labelled training samples in the target
domain and the unsupervised one requires none labelled
data. However, in both semi-supervised and unsupervised
domain adaptation, sufﬁcient unlabeled target domain data
are required. In this paper, we focus on unsupervised domain adaptation which is considered to be more practical
and challenging.
The most commonly used domain adaptation approaches
include instance-based adaptation, feature representation
adaptation, and classiﬁer-based adaptation . In unsupervised domain adaptation, as there is no labeled data in
the target domain, the classiﬁer-based adaptation is not feasible. Alternatively, we can deal with this problem by minimizing distribution divergence between domains as well as
the empirical source error . It is generally assumed that
the distribution divergence can be compensated either by an
instance based adaptation method, such as reweighting samples in the source domain to better match the target domain
distribution, or by a feature transformation based method
that projects features of two domains into another subspace
with small distribution shift. The instance-based approach
requires the strict assumptions that 1) the conditional
distributions of source and target domain are identical, and
2) certain portion of the data in the source domain can be
reused for learning in the target domain through reweighting. While the feature transformation based approach relaxes these assumptions, and only assumes that there exists
a common space where the distributions of two domains are
similar. This paper follows the feature transformation based
Two main categories of feature transformation methods
are identiﬁed among the literature, namely data centric methods and subspace centric methods. The data centric methods seek a uniﬁed transformation that projects data
from two domains into a domain invariant space to reduce
the distributional divergence between domains while preserving data properties in original spaces, such as . The data centric methods only exploit shared feature
in two domains, which will fail when the two different domains have large discrepancy, because there may not exist
such a common space where the distributions of two domains are the same and the data properties are also maximumly preserved in the mean time. For the subspace centric methods, the domain shift is reduced by manipulating the subspaces of the two domains such that the sub-
 
space of each individual domain all contributes to the ﬁnal
mapping . Hence, the domain speciﬁc features
are exploited. For example, Gong et al. regard two
subspaces as two points on Grassmann manifold, and ﬁnd
points on a geodesic path between them as a bridge between
source and target subspaces. Fernando et al.
 align
source and target subspaces directly using a linear transformation matrix. However, the subspace centric methods only
manipulate on the subspaces of the two domains without explicitly considering the distribution shift between projected
data of two domains. The limitations of both data centric
and subspace centric methods will be illustrated on a synthetic dataset in Section 4.1.
In this paper, we propose a uniﬁed framework that reduces the distributional and geometrical divergence between domains simultaneously by exploiting both the
shared and domain speciﬁc features. Speciﬁcally, we learn
two coupled projections to map the source and target data
into respective subspaces. After the projections, 1) the variance of target domain data is maximized to preserve the
target domain data properties, 2) the discriminative information of source data is preserved to effectively transfer
the class information, 3) both the marginal and conditional
distribution divergences between source and target domains
are minimized to reduce the domain shift statistically, and 4)
the divergence of two projections is constrained to be small
to reduce domain shift geometrically.
Hence, different from data centric based methods, we
do not require the strong assumption that a uniﬁed transformation can reduce the distribution shift while preserving
the data properties. Different from subspace centric based
methods, we not only reduce the shift of subspace geometries but also reduce the distribution shifts of two domains.
In addition, our method can be easily extended to a kernelized version to deal with the situations where the shift between domains are nonlinear. The objective function can be
solved efﬁciently in a closed form. The proposed method
has been veriﬁed through comprehensive experiments on
a synthetic dataset and three different real world crossdomain visual recognition tasks: object recognition (Of-
ﬁce, Caltech-256), hand-written digit recognition (USPS,
MNIST), and RGB-D-based action recognition (MSRAction3DExt, G3D, UTD-MHAD, and MAD).
2. Related Work
2.1. Data centric approach
Pan et al. propose the transfer component analysis
(TCA) to learn some transfer components across domains
in RKHS using Maximum Mean Discrepancy (MMD) .
TCA is a typical data centric approach that ﬁnds a uniﬁed
transformation φ(·) that projects data from two domains
into a new space to reduce the discrepancy. In TCA, the
authors aim to minimize the distance between the sample
means of the source and target data in the k-dimensional
embeddings while preserving data properties in original
spaces. Joint distribution analysis (JDA) improves TCA
by considering not only the marginal distribution shift but
also the conditional distribution shift using the pseudo labels of target domain. Transfer joint matching (TJM) 
improves TCA by jointly reweighting the instances and
ﬁnding the common subspace. Scatter component analysis (SCA) takes the between and within class scatter of
source domain into consideration. However, these methods
require a strong assumption that there exist a uniﬁed transformation to map source and target domains into a shared
subspace with small distribution shift.
2.2. Subspace Centric Approach
As mentioned, subspace centric approach can address
the issue of data centric methods that only exploit common
features of two domains.
Fernando et al. proposed
a subspace centric method, namely Subspace Alignment
(SA). The key idea of SA is to align the source basis vectors
(A) with the target one (B) using a transformation matrix
M. A and B are obtained by PCA on source and target domains, respectively. Hence, they do not assume that there
exist a uniﬁed transformation to reduce the domain shifts.
However, the variance of projected source domain data will
be different from that of target domain after mapping the
source subspace using a linear map because of the domain
shift. In this case, SA fails to minimize the distributions
between domains after aligning the subspaces. In addition,
SA cannot deal with situations where the shift between two
subspaces are nonlinear. Subspace distribution alignment
(SDA) improves SA by considering the variance of the
orthogonal principal components. However, the variances
are considered based on the aligned subspaces. Hence, only
the magnitude of each eigen direction is changed which may
still fail when the domain shift is large. This has been validated by the illustration of synthetic data in Figure 2 and
the experiment results on real world datasets.
3. Joint Geometrical and Statistical Alignment
This section presents the Joint Geometrical and Statistical Alignment (JGSA) method in detail.
3.1. Problem Deﬁnition
We begin with the deﬁnitions of terminologies.
source domain data denoted as Xs ∈RD×ns are draw from
distribution Ps(Xs) and the target domain data denoted as
Xt ∈RD×nt are draw from distribution Pt(Xt), where D
is the dimension of the data instance, ns and nt are number
of samples in source and target domain respectively. We
focus on the unsupervised domain adaptation problem. In
unsupervised domain adaptation, there are sufﬁcient labeled
source domain data, Ds = {(xi, yi)}ns
i=1, xi ∈RD, and unlabeled target domain data, Dt = {(xj)}nt
j=1, xj ∈RD,
in the training stage. We assume the feature spaces and label spaces between domains are the same: Xs = Xt and
Ys = Yt. Due to the dataset shift, Ps(Xs) ̸= Pt(Xt).
Different from previous domain adaptation methods, we do
not assume that there exists a uniﬁed transformation φ(·)
such that Ps(φ(Xs)) = Pt(φ(Xt)) and Ps(Ys|φ(Xs)) =
Pt(Yt|φ(Xs)), since this assumption becomes invalid when
the dataset shift is large.
3.2. Formulation
To address limitations of both data centric and subspace
centric methods, the proposed framework (JGSA) reduces
the domain divergence both statistically and geometrically
by exploiting both shared and domain speciﬁc features of
two domains. The JGSA is formulated by ﬁnding two coupled projections (A for source domain, and B for target domain) to obtain new representations of respective domains,
such that 1) the variance of target domain is maximized,
2) the discriminative information of source domain is preserved, 3) the divergence of source and target distributions
is small, and 4) the divergence between source and target
subspaces is small.
Target Variance Maximization
To avoid projecting features into irrelevant dimensions, we
encourage the variances of target domain is maximized in
the respective subspaces. Hence, the variance maximization
can be achieved as follows
Tr(BT StB)
St = XtHtXT
is the target domain scatter matrix, Ht = It −
the centering matrix, 1t ∈Rnt is the column vector with all
Source Discriminative Information Preservation
Since the labels in the source domain are available, we can
employ the label information to constrain the new representation of source domain data to be discriminative.
A Tr(AT SbA)
A Tr(AT SwA)
where Sw is the within class scatter matrix, and Sb is the between class scatter matrix of the source domain data, which
are deﬁned as follows,
−¯ms)(m(c)
where X(c)
is the set of source samples belonging to class c, m(c)
s )T is the centering matrix of
data within class c, I(c)
is the identity matrix,
is the column vector with all ones, n(c)
number of source samples in class c.
Distribution Divergence Minimization
We employ the MMD criteria to compare the distributions between domains, which computes the distance
between the sample means of the source and target data in
the k-dimensional embeddings,
Long et al. has been proposed to utilize target pseudo labels predicted by source domain classiﬁers for representing
the class-conditional data distributions in the target domain.
Then the pseudo labels of target domain are iteratively re-
ﬁned to reduce the difference in conditional distributions
between two domains further. We follow their idea to minimize the conditional distribution shift between domains,
Hence, by combining the marginal and conditional distribution shift minimization terms, the ﬁnal distribution divergence minimization term can be rewritten as
Ms = Xs(Ls +
xi, xj ∈X(c)
Mt = Xt(Lt +
xi, xj ∈X(c)
Mst = Xs(Lst +
s , xj ∈X(c)
Mts = Xt(Lts +
s , xi ∈X(c)
Note that this is different from TCA and JDA, because we
do not use a uniﬁed subspace because there may not exist
such a common subspace where the distributions of two domains are also similar.
Subspace Divergence Minimization
Similar to SA , we also reduce the discrepancy between
domains by moving closer the source and target subspaces.
As mentioned, an additional transformation matrix M is required to map the source subspace to the target subspace in
SA. However, we do not learn an additional matrix to map
the two subspaces. Rather, we optimize A and B simultaneously, such that the source class information and the target variance can be preserved, and the two subspaces move
closer in the mean time. We use following term to move the
two subspaces close:
A,B ∥A −B∥2
By using term (14) together with (9), both shared and domain speciﬁc features are exploited such that the two domains are well aligned geometrically and statistically.
Overall Objective Function
We formulate the JGSA method by incorporating the above
ﬁve quantities ((1), (3), (4), (9), and (14)) as follows:
µ{Target Var.} + β{Between Class Var.}
{Distribution shift} + λ{Subspace shift} + β{Within Class Var.}
where λ, µ, β are trade-off parameters to balance the importance of each quantity, and Var. indicates variance.
We follow to further impose the constraint that
Tr(BT B) is small to control the scale of B. Speciﬁcally,
we aim at ﬁnding two coupled projections A and B by solving the following optimization function,
Ms + λI + βSw
Mt + (λ + µ)I
where I ∈Rd×d is the identity matrix.
Minimizing the denominator of (15) encourages small
marginal and conditional distributions shifts, and small
within class variance in the source domain. Maximizing the
numerator of (15) encourages large target domain variance,
and large between class variance in the source domain. Similar to JDA, we also iteratively update the pseudo labels of
target domain data using the learned transformations to improve the labelling quality until convergence.
3.3. Optimization
To optimize (15), we rewrite [AT
BT ] as W T . Then
the objective function and corresponding constraints can be
rewritten as:
Ms + λI + βSw
Mt + (λ + µ)I
Note that the objective function is invariant to rescaling of
W. Therefore, we rewrite objective function (16) as
Ms + λI + βSw
Mt + (λ + µ)I
The Lagrange function of (17) is
Ms + λI + βSw
Mt + (λ + µ)I
By setting the derivative ∂L
∂W = 0, we get:
Ms + λI + βSw
Mt + (λ + µ)I
where Φ = diag(λ1, ..., λk) are the k leading eigenvalues
and W = [W1, ..., Wk] contains the corresponding eigenvectors, which can be solved analytically through generalized eigenvalue decomposition. Once the transformation
matrix W is obtained, the subspaces A and B can be obtained easily. The pseudo code of JGSA is summarised in
Algorithm 1.
3.4. Kernelization Analysis
The JGSA method can be extended to nonlinear problems in a Reproducing Kernel Hilbert Space (RKHS) using
some kernel functions φ. We use the Representer Theorem
P = Φ(X)A and Q = Φ(X)B to kernelize our method,
where X = [Xs, Xt] denotes all the source and target training samples, Φ(X) = [φ(x1), ..., φ(xn)] and n is the number of all samples. Hence, the objective function becomes,
Algorithm 1: Joint Geometrical and Statistical Alignment
Input : Data and source labels: Xs, Xt, Ys; Parameters:
λ = 1, µ = 1, k, T, β.
Output: Transformation matrices: A and B; Embeddings:
Zs, Zt; Adaptive classiﬁer: f.
1 Construct St, Sb, Sw, Ms, Mt, Mst, and Mts according to
(2), (3), (4), (10), (11), (12), and (13); Initialize pseudo
labels in target domain ˆYt using a classiﬁer trained on
original source domain data;
Solve the generalized eigendecompostion problem in
Equation (19) and select the k corresponding
eigenvectors of k leading eigenvalues as the
transformation W, and obtain subspaces A and B;
Map the original data to respective subspaces to get the
embeddings: Zs = AT Xs, Zt = BT Xt;
Train a classiﬁer f on {Zs, Ys} to update pseudo labels
in target domain ˆYt = f(Zt);
Update Ms, Mt, Mst, and Mts according to (10), (11),
(12), and (13).
7 until Convergence;
8 Obtain the ﬁnal adaptive classiﬁer f on {Zs, Ys}.
Ms + λI + βSw
Mt + (λ + µ)I
where all the Xt’s are replaced by Φ(Xt) and all the Xs’s
are replaced by Φ(Xs) in St, Sw, Sb, Ms, Mt, Mst, and
Mts in the kernelized version.
We replace P and Q with Φ(X)A and Φ(X)B and obtain
the objective function as follows,
Ms + λK + βSw
Mt + (λ + µ)K
Φ(X)T Φ(X), Ks
Φ(X)T Φ(Xs), Kt
Φ(X)T Φ(Xt),
Kt −1tK −Kt1n + 1tK1n,
Rnt×n and 1n
Rn×n are matrices with all
In Sb, m(c)
Φ(X)T φ(xi).
In MMD terms, Ms
Ks(Ls + PC
s , Mt = Kt(Lt + PC
Mst = Ks(Lst + PC
t , Mts = Kt(Lts +
Once the kernelized objective function
(21) is obtained, we can simply solve it in the same way
as the original objective function to compute A and B.
4. Experiments
In this section, we ﬁrst conduct experiments on a synthetic dataset to verify the effectiveness of the JGSA methods. Then we evaluate our method for cross-domain object recognition, cross-domain digit recognition, and cross
dataset RGB-D-based action recognition.
The codes are
available online1.
We compare our method with several
state-of-the-art methods: subspace alignment (SA) ,
subspace distribution alignment (SDA) , geodesic ﬂow
kernel (GFK) , transfer component analysis (TCA) ,
joint distribution analysis (JDA) , transfer joint matching (TJM) , scatter component analysis (SCA) , optimal transport (OTGL) , and kernel manifold alignment
(KEMA) . We use the parameters recommended by the
original papers for all the baseline methods. For JGSA,
we ﬁx λ = 1, µ = 1 in all the experiments, such that
the distribution shift, subspace shift, and target variance are
treated as equally important. We empirically veriﬁed that
the ﬁxed parameters can obtained promising results on different types of tasks. Hence, the subspace dimension k,
number of iteration T, and regularization parameter β are
free parameters.
4.1. Synthetic Data
Here, we aim to synthesize samples of data to demonstrate that our method can keep the domain structures as
well as reduce the domain shift. The synthesized source
and target domain samples are both draw from a mixture of
three RBFian distributions. Each RBFian distribution represents one class. The global means, as well as the means
of the third class are shifted between domains. The original
data are 3-dimensional. We set the dimensionality of the
subspaces to 2 for all the methods.
Figure 2 illustrates the original synthetic dataset and domain adaptation results of different methods on the dataset.
It can be seen that after SA method the divergences between
domains are still large after aligning the subspaces. Hence,
the aligned subspaces are not optimal for reduce the domain
shift if the distribution divergence is not considered. The
SDA method does not demonstrate obvious improvement
over SA, since the variance shift is reduced based upon the
aligned subspaces (which may not be optimal) as in SA.
TCA method reduces the domain shift effectively. However,
two of the classes are mixed up since there may not exist a
uniﬁed subspace to reduce domain shift and preserve the
original information simultaneously. Even with conditional
distribution shift reduction (JDA) or instances reweighting
(TJM), the class-1 and class-2 still cannot be distinguished.
SCA considers the total scatter, domain scatter, and class
scatter using a uniﬁed mapping. However, there may not exist such a common subspace that satisﬁes all the constraints.
1 
Obviously, JGSA aligns the two domains well even though
the shift between source and target domains is large.
4.2. Real World Datasets
We evaluate our method on three cross-domain visual recognition tasks: object recognition (Ofﬁce, Caltech-
256), hand-written digit recognition (USPS, MNIST),
and RGB-D-based action recognition (MSRAction3DExt,
G3D, UTD-MHAD, and MAD). The sample images or
video frames are shown in Figure 1.
MSR vs. G3D
MSR vs. MAD
MSR vs. UTD
Figure 1: Sample images of object datasets, digit datasets,
and sample video frames of depth map of RGB-D-based
action datasets.
Object Recognition
We adopt the public Ofﬁce+Caltech
object datasets released by Gong et al. . This dataset
contains images from four different domains:
(images downloaded from online merchants), Webcam
(low-resolution images by a web camera), DSLR (highresolution images by a digital SLR camera), and Caltech-
256. Amazon, Webcam, and DSLR are three datasets studied in for the effects of domain shift. Caltech-256 
contains 256 object classes downloaded from Google images. Ten classes common to four datasets are selected:
backpack, bike, calculator, head-phones, keyboard, laptop,
monitor, mouse, mug, and projector. Two types of features
are considered: SURF descriptors (which are encoded with
800-bin histograms with the codebook trained from a subset of Amazon images), and Decaf6 features (which are the
activations of the 6th fully connected layer of a convolutional network trained on imageNet). As suggested by ,
1-Nearest Neighbor Classiﬁer (NN) is chosen as the base
classiﬁer. For the free parameters, we set k = 30, T = 10,
and β = 0.1.
Digit Recognition
For cross-domain hand-written digit
recognition task, we use MNIST and USPS 
datasets to evaluate our method. MNIST dataset contains
a training set of 60,000 examples, and a test set of 10,000
examples of size 28×28. USPS dataset consists of 7,291
training images and 2,007 test images of size 16×16. Ten
shared classes of the two datasets are selected. We follow
the settings of to construct a pair of cross-domain
datasets USPS →MNIST by randomly sampling 1,800 images in USPS to form the source data, and randomly sampling 2,000 images in MNIST to form the target data. Then
source and target pair are switched to form another dataset
MNIST →USPS. All images are uniformly rescaled to size
16×16, and each image is represented by a feature vector
encoding the gray-scale pixel values. For the free parameters, we set k = 100, T = 10, and β = 0.01.
RGB-D-based Action Recognition
For cross-dataset
RGB-D-based Action Recognition, four RGB-D-based Action Recognition datasets are selected, namely MSRAction3DExt , UTD-MHAD , G3D , and
All the four datasets are captured by both
RGB and depth sensors. We select the shared actions between MSRAction3DExt and other three datasets to form
6 dataset pairs.
There are 8 common actions between
MSRAction3DExt and G3D: wave, forward punch, hand
clap, forward kick, jogging, tennis swing, tennis serve, and
golf swing. There are 10 common actions between MSRAction3DExt and UTD-MHAD: wave, hand catch, right arm
high throw, draw x, draw circle, two hand front clap, jogging, tennis swing, tennis serve, and pickup and throw.
There are 7 shared actions between MSRAction3DExt and
MAD: wave, forward punch, throw, forward kick, side kick,
jogging, and tennis swing forehand. The local HON4D 
feature is used for the cross-dataset action recognition tasks.
We extract local HON4D descriptors around 15 skeleton
joints by following the process similar to . The selected
joints include head, neck, left knee, right knee, left elbow,
right elbow, left wrist, right wrist, left shoulder, right shoulder, hip, left hip, right hip, left ankle, and right ankle. We
use a patch size of 24×24×4 for depth map with resolution
of 320×240 and 48×48×4 for depth map with resolution
of 640 × 480 , then divide the patches into a 3 × 3 × 1 grid.
Since most of the real world applications of action recognition are required to recognize unseen data in the target
domain, we further divide the target domain into training
and test sets using cross-subject protocol, where half of the
subjects are used as training and the rest subjects are used as
test when a dataset is evaluated as target domain. Note that
the target training set is also unlabeled. For the free parameters, we set k = 100 and β = 0.01. To avoid overﬁtting
to the target training set, we set T = 1 in action recognition
tasks. LibLINEAR is used for action recognition by
following the original paper .
Figure 2: Comparisons of baseline domain adaptation methods and the proposed JGSA method on the synthetic data
Table 1: Accuracy(%) on cross-domain object datasets. Notation for datasets: Caltech:C; Amazon:A; Webcam:W; DSLR:D.
Table 2: Accuracy (%) on cross-domain digit datasets.
JGSA primal
MNIST→USPS
USPS→MNIST
Table 3: Accuracy (%) on cross-dataset RGB-D-based action datasets.
JGSA linear
2−152−132−11 2−9 2−7 2−5 2−3 2−1
Accuracy(%)
MSR→MADbaseline
USPS→MNIST
USPS→MNISTbaseline
W→Abaseline
(a) regularization parameter β
10 30 50 70 90 110 130 150 170 190
Accuracy(%)
MSR→MADbaseline
USPS→MNIST
USPS→MNISTbaseline
W→Abaseline
(b) dimentionality of subspace k
Accuracy(%)
MSR→MADbaseline
USPS→MNIST
USPS→MNISTbaseline
W→Abaseline
(c) number of iteration T
Figure 3: Parameter sensitivity study of JGSA on different types of datasets
Results and Discussion
The results on three types of real world cross domain
(object, digit, and action) datasets are shown in Table 1, 2,and 3. The JGSA primal represents the results of
JGSA method on original data space, while the JGSA linear and JGSA RBF represent the results with linear kernel
and RBF kernel respectively. We follow JDA to report the
results on digit datasets in the original feature space. For
the action recognition task, it is hard to do eigen decomposition in the original space due to the high dimensionality,
hence, the results are obtained using linear kernel. It can
be observed that JGSA outperforms the state-of-the-art domain adaptation methods on most of the datasets. As mentioned, the general drawback of subspace centric approach
is that the distribution shifts between domains are not explicitly reduced. The data centric methods reduce the distribution shift explicitly. However, a uniﬁed transformation
may not exist to both reduce distribution shift and preserve
the properties of original data. Hence, JGSA outperforms
both subspace centric and data centric methods on most
of the datasets. We also compare the primal and kernelized versions of the algorithm on the object recognition task
(Table 1). The results show that the primal and kernelized
versions can obtain similar results on average. To evaluate the effectiveness of pseudo labelling, we compare our
method with a semi-supervised method KEMA . We
use the same Decaf7 feature on 8 Ofﬁce-Caltech dataset
pairs as did in KEMA. Our method obtains 90.18% (linear)
and 89.91% (RBF), both of which are higher than 89.1%
reported in KEMA.
We also evaluated the runtime complexity on the crossdomain object datasets (SURF with linear kernel). The average runtime is 28.97s, which is about three times as long
as the best baseline method (JDA). This is because JGSA
learns two mappings simultaneously, the size of matrix for
eigen decomposition is doubled compared to JDA.
Parameter Sensitivity
We analyse the parameter sensitivity of JGSA on different types of datasets to validate that a wide range of parameter values can be chosen to obtain satisfactory performance. The results on different types of datasets have validated that the ﬁxing λ = 1 and µ = 1 is sufﬁcient for
all the three tasks. Hence, we only evaluate other three parameters (k, β, and T). We conduct experiments on the
USPS→MNIST, W→A (SURF descriptor with linear kernel), and MSR→MAD datasets for illustration, which are
shown in Figure 3. The solid line is the accuracy on JGSA
using different parameters, and the dashed line indicates
the results obtained by the best baseline method on each
dataset. Similar trends are observed on other datasets.
β is the trade-off parameter of within and between class
variance of source domain. If β is too small, the class information of source domain is not considered. If β is too
big, the classiﬁer would be overﬁt to the source domain.
However, it can be seen from Figure 3a, a large range of
β (β ∈[2−15, 0.5]) can be selected to obtain better results
than the best baseline method.
Figure 3b illustrates the relationship between various k
and the accuracy. We can choose k ∈ to obtain
better results than the best baseline method.
For the number of iteration T, the results on object and
digit recognition tasks can be converged to the optimum
value after several iteration. However, for the action recognition, the accuracy has no obvious change (Figure 3c).
This may be because we use a different protocol for action
recognition as mentioned in Section 4.2.1. After iterative
labelling (which is done on the target training set), the mappings may be sufﬁciently good for ﬁtting the target training
set, but it is not necessarily the case for the test set.
5. Conclusion
In this paper, we propose a novel framework for unsupervised domain adaptation, referred to as Joint Geometrical
and Statistical Alignment (JGSA). JGSA reduces the domain shifts by taking both geometrical and statistical properties of source and target domain data into consideration
and exploiting both shared and domain speciﬁc features.
Comprehensive experiments on synthetic data and three different types of real world visual recognition tasks validate
the effectiveness of JGSA compared to several state-of-theart domain adaptation methods.