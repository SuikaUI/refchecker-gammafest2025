Volume 6, Issue 2
The International Journal of
Biostatistics
CAUSAL INFERENCE
Targeted Maximum Likelihood Based Causal
Inference: Part II
Mark J. van der Laan, University of California - Berkeley
Recommended Citation:
van der Laan, Mark J. "Targeted Maximum Likelihood Based Causal Inference: Part II,"
The International Journal of Biostatistics: Vol. 6: Iss. 2, Article 3.
DOI: 10.2202/1557-4679.1241
Targeted Maximum Likelihood Based Causal
Inference: Part II
Mark J. van der Laan
In this article, we provide a template for the practical implementation of the targeted
maximum likelihood estimator for analyzing causal effects of multiple time point interventions,
for which the methodology was developed and presented in Part I. In addition, the application of
this template is demonstrated in two important estimation problems: estimation of the effect of
individualized treatment rules based on marginal structural models for treatment rules, and the
effect of a baseline treatment on survival in a randomized clinical trial in which the time till event
is subject to right censoring.
KEYWORDS: causal effect, causal graph, censored data, cross-validation, collaborative double
robust, double robust, dynamic treatment regimens, efficient influence curve, estimating function,
estimator selection, locally efficient, loss function, marginal structural models for dynamic
treatments, maximum likelihood estimation, model selection, path-wise derivative, randomized
controlled trials, sieve, super-learning, targeted maximum likelihood estimation
Introduction.
In the companion Part I article we developed targeted maximum likelihood
estimation for estimation of causal eﬀects of interventions on an outcome of
interest for general longitudinal data structures. In this article in Section 2
we start out with translating/summarizing this into a general template for
estimation of parameters of the intervention-speciﬁc counterfactual distributions, as identiﬁed by the so called G-computation formula. In Section 3, we
demonstrate the application of this template with a complex longitudinal data
structure one encounters in HIV research in order to compare mean clinical
outcomes under diﬀerent individualized rules for starting treatment. In Section 4 we apply the template to estimate a causal eﬀect of a binary treatment
on a clinical time till event outcome based on data generated by a randomized
controlled trial. We end with a discussion in Section 5.
A general template for targeted MLE of parameters of the G-computation formula.
We present a road map for the computation of the targeted MLE and corresponding statistical inference for a target parameter of the distribution of the
Code data: Represent the data on one unit as a time-ordered data structure
O = (L(0), A(0), L(1), A(1), . . . , L(K), A(K), L(K + 1)).
It is assumed that L(t) occurs before A(t), and we are interested in eﬀect
of interventions on the A-nodes of this graph.
Deﬁne target parameter: Let P0 be the probability distribution of O, and
let ψ0 = Ψ(P0) be the target parameter of interest.
The probability
distribution of O factorizes as p0 = Q0g0, where Q0 = QK+1
t=0 Q0L(t) and
t=0 g0A(t), Q0L(t) is the conditional distribution of L(t), given
Pa(L(t)) = ¯L(t −1), A(t −1), and g0A(t) is the conditional distribution
of A(t), given Pa(A(t)) = ¯L(t), ¯A(t −1). If it is known that the parent
sets of these nodes are smaller, then these smaller parent sets need to be
enforced. We will assume that each of these conditional distributions is
unspeciﬁed. Typically we will have that ψ0 = ΨF(Q0) is only a parameter of the Q-factor of density p0 of O. In causal inference most target
parameters can be deﬁned as a parameter of a distribution obtained by
van der Laan: Targeted ML Causal Inference: Part II
intervening on the A nodes in the complete system, which is thereby
only a function of Q, i.e., the G-computation formula.
Determine eﬃcient inﬂuence curve: In order to carry out the targeted
MLE to estimate ψ0 one will need to know the eﬃcient inﬂuence curve
D∗(Q, g) for any (Q, g) identifying a distribution of the data. If ψ0 only
depends on P0 through Q0, then one can ﬁnd an inﬂuence curve DIPCW
of Ψ in the model in which g0 is known. Such inﬂuence curves can often
be represented as so called inverse of probability of censoring weighted
functions of a full data eﬃcient inﬂuence curve for a formal treatment of IPCW-estimating functions). In
that case the eﬃcient inﬂuence curve can be represented as a projection
of such an IPCW-estimating function DIPCW onto the tangent space of
D∗(Q, g) = Π(DIPCW(Q, g) | TQ),
where TQ is the tangent space of the Q-factor of the density p0 of O.
Our formulas of the clever covariates in the ﬂuctuation function of the
various factors in Q will be a direct function of this DIPCW. Since for
most target parameters the IPCW-estimating function is well known
and easily constructed, this provides us with a straightforward way to
obtain the right formulas for the clever covariates needed to deﬁne the
ﬂuctuation function of the targeted MLE step.
Determine binary factorization of likelihood: Consider a L(t). Suppose
L(t) = (L(t, j) : j = 1, . . . , n(t)) consists of n(t) components, which we
denote with L(t, j) for diﬀerent j. Firstly, we determine a particular
ordering, allowing us to model
where QL(t,j) is the conditional probability distribution of L(t, j), given
Pa(L(t, j)) = ¯L(t −1), L(t, 1), . . . , L(t, j −1), A(t −1). It now remains
to further factorize QL(t,j). If L(t, j) is binary, then we do not further
factorize QL(t,j). If L(t, j) is a categorical variable with n(t, j) categories,
then assume an ordering of the categories l = 1, . . . , n(t, j), and factorize
QL(t,j) as
QL(t,j,l),
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 3
DOI: 10.2202/1557-4679.1241
where QL(t,j,l) is the conditional distribution of the indicator L(t, j, l)
of L(t, j) = l, given I(L(t, j) = m), m = 1, . . . , l −1, and Pa(L(t, j)),
where it is assumed that if one of these indicators I(L(t, j) = m) for m =
1, . . . , l −1 equals 1, then QL(t,j,l) is degenerate at 0. Let Pa(L(t, j, l))
denote the parent set for this node L(t, j, l).
If L(t, j) is an ordered variable with n(t, j) values, then we already have
an ordering, and factorize QL(t,j) as
QL(t,j,l),
where QL(t,j,l) is the conditional distribuiton of the indicator L(t, j, l) of
L(t, j) = l, given I(L(t, j) = m), m = 1, . . . , l −1, and Pa(L(t, j)),
where it is assumed that if one of these indicators I(L(t, j) = m) for
m = 1, . . . , l −1 equals 1, then QL(t,j,l) is degenerate at 0.
Note that the latter QL(t,j,l) (conditional on the previous l −1 indicators
all being zero) is identiﬁed by a so called hazard probability QL(t,j,l)(1 |
Pa(L(t, j, l)), i.e., a probability of having the random variable fall at level
l, conditional on being larger or equal than level l, and Pa(L(t, j, l)).
To conclude, we have the following factorization for QL(t),
QL(t,j,l),
and thereby the factorization for the Q-factor of the density of O,
in terms of conditional distributions of binary variables L(t, j, l), conditional on parent nodes Pa(L(t, j.l)).
Compute formulas for clever covariates: For each binary variable L(t, j, k),
Pa(L(t, j, k)) denotes the conditioning random variable:
Pa(L(t, j, k)) = ¯L(t−1), A(t−1), L(t, 1), . . . , L(t, j−1), L(t, j, 1), . . . , L(t, j, k−1),
and the following formulas have been provided for general parent sets as
well. Suppose that D = DIPCW can be represented as
D(Q) = D1 + C1(Q)
, C1(Q) is only function of O through L(0), ¯A(K),
van der Laan: Targeted ML Causal Inference: Part II
and D1 does not depend on Q (it can depend on g).
The eﬃcient inﬂuence curve can now be represented as D∗= Π(D |
TQ) = D0 + P
t≥1,j,k Dtjk, where D0 = E(D∗| L(0)), and for t ≥1,
Dtjk = Ctjk
L(t, j, k) −QL(t,j,k)(1 | Pa(L(t, j, k)))
Ctjk(Q, g) =
g(A(t−1)|X)×
{Etjk(Q)(1, Pa(L(t, j, k))) −Etjk(Q)(0, Pa(L(t, j, k)))} ,
where we deﬁned, for δ ∈{0, 1},
Etjk(Q)(δ, Pa(L(t, j, k))) = EQ
D1 | L(t, j, k) = δ, Pa(L(t, j, k))
Here we used short-hand notation for P
a(t,K) D1(A(t−1), ¯a(t, K), ¯L(K+
1)), and ¯a(t, K) = (a(t), . . . , a(K)).
Given an estimator Qn and gn, Ctjk(Qn, gn) denotes the clever covariate
deﬁning the ﬂuctuation function of the estimator QL(t,j,k),n obtained by
adding ϵCtjk(Qn, gn) on the logit scale.
Deﬁne clusters of Q-probabilities that need to considered for pooling:
We now need to deﬁne an initial estimator Q0
n of Q0. One could estimate each QL(t,j,k) separately with a machine learning algorithm for each
t, j, k. Such an estimator can be considered as one particular candidate,
but likelihood/loss function based cross-validation needs to be employed
in order to evaluate this type of estimator relative to other estimators.
Overall, smoothing in time t and/or category l is often very sensible and
will improve the overall performance of the estimator: i.e. it will typically reduce the variance signiﬁcantly at relatively minor loss in bias.
Therefore, the user should deﬁne clusters of grid points in the (t, j, k)grid for which the estimators of the corresponding QL(t,j,k) need to be
considered for being pooled: the particular machine learning algorithm
applied to this cluster might still decide to not smooth in certain timepoints or levels, but it will be guided by cross-validated risk using a
speciﬁed loss function.
Let τ1, . . . , τL be such clusters.
For example
τ1 = {(t, 1, k) : t = 1, . . . , K, k = 1, . . . , n(t, 1) −1} might indicate that
component indicated by j = 1 needs to be considered for smoothing in
both time t across all time points and in its level k. So each cluster
typically represents a particular ordered variable (e.g., CD4 count) and
it might state that the estimation procedure needs to respect the fact
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 3
DOI: 10.2202/1557-4679.1241
that the hazard of this variable at diﬀerent levels k and diﬀerent time
points might need to be smoothed across time and level. For a categorical variable, smoothing in the categories will make no sense and would
thus be made clear by the deﬁnition of the cluster for that categorical
variable, but that cluster might still suggest smoothing over time t.
Apply loss-based super learner to repeated measures data set to estimate
each cluster of Q-probabilities:
For each cluster τl, we create a pooled data set which has for each unit as
many rows as there are grid points in the cluster which will be used to ﬁt
all the conditional probabilities QL(t,j,k) with (t, j, k) ∈τl. So we create
a data set which has as columns a time stamp t, a j-stamp, and a level
stamp l, an outcome column for the binary L(t, j, k), various covariates
extracted from Pa(L(t, j, k)), across all points (t, j, k) ∈τl, each grid
point representing a line of data, thereby generating repeated measures
type data for each unit of observation. Regarding extraction of covariates
from Pa(L(t, j, k)), one needs to make sure that these covariates have
the same meaning across these diﬀerent grid points. So this step involves
deﬁning a list of extractions the histories Pa(L(t, j, k)), such as the most
recent in time measurements on the particular variable indicated by j. If
this is not possible for (say early time points), then that is an indications
that some of these (t, j, k) should not have been included in the cluster
and might thus need to be ﬁtted separately.
Given this deﬁnition of a repeated measures data set corresponding with
cluster τl, we can now apply the super learner or any other machine learning algorithm to ﬁt the regression of the binary L(t, j, k) onto (t, j, k)
and these covariate extractions from Pa(L(t, j, k)), across (t, j, k). This
requires a choice of loss function L(Q)(O). One possibility is the loglikelihood loss function −P
(t,j,k)∈τl log Qt,j,k(O). We can use a potentially more targeted loss function given by the repeated measures squared
error loss function L(Qt,j,k : (t, j, k) ∈τl)(O) deﬁned as
(t,j,k)∈τl
w(t, j, k)R(t, j, k)
L(t, j, k) −QL(t,j,k)(1 | Pa(L(t, j, k)))
for some weight function w(t, j, k). Here R(t, j, k) denotes an indicator
of L(t, j, k) being at ”risk” of changing value. If R(t, j, k) = 0, then
QL(t,j,k)(1 | Pa(L(t, j, k))) is either known to be zero or one, so that this
loss function will only evaluate the conditional probability of L(t, j, k),
given its parents and given that it is at risk of changing.
van der Laan: Targeted ML Causal Inference: Part II
As discussed previously, a particular weight function w(t, j, k) that makes
the risk of the loss function close to variance of eﬃcient inﬂuence curve,
and thereby targets the super learner ﬁt towards the parameter of interest, is given by the square of the clever covariate:
w(t, j, k) = C(t, j, k)2.
Since this weight depends on Q, g itself, this weighted super learner would
require a two stage procedure, ﬁrst an unweighted super learner (or other
machine learning algorithm) to estimate Q0, and a subsequent weighted
super-learner using the ﬁrst stage estimator to estimate the clever covariates, and thereby the weights.
Estimate treatment/censoring mechanism: The likelihood for g can also
be factorized in binary conditional probability distributions, and will
typically involve fewer binary conditional probability distributions. One
can use log-likelihood based machine learning (e.g., super-learning) to
estimate g0.
Regarding the choice of loss function for g0, one needs
to realize that the estimator of g0 is only used to estimate the clever
covariates, and that fact might guide the choice of loss function for g0
so that the resulting estimator of g0 is well suited for estimation of the
clever covariates.
Targeted MLE algorithm at given initial estimator: Suppose that we
are given an initial estimator Qn of Q0, described above, and an estimator gn of g0.
Deﬁne the ﬂuctuation of the initial estimator Qn:
logitQL(t,j,k),n(ϵ) = logitQL(t,j,k),n + ϵCtjk(Qn, gn).
We now have a variety of possibilities regarding estimation of ϵ depending
on how much we want to smooth the estimator of ϵ across (t, j, k).
Firstly, we could create a single pooled repeated measures data set in
which each unit contributes a line of data for each t, j, k. One now creates
columns for the time stamp t, the variable indicator j, the category/level
indicator k, the outcome L(t, j, k), the oﬀset QL(t,j,k),n, and the clever
covariate Ctjk. One could now ﬁt ϵ with logistic regression using the oﬀset command, regressing the binary indicator L(t, j, k) onto the clever
covariate Ctjk, thereby obtaining a single estimator ϵn for each t, j, k.
One now updates the initial estimator Q1
n(ϵn), and this process
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 3
DOI: 10.2202/1557-4679.1241
is iterated till convergence. In this way, the targeted bias reduction is
established with minimal extra ﬁtting, and therefore this might be the
preferred method relative to the alternatives considered below.
Alternatively, one could create an extra column that labels the cluster
τl, and, for each l, one runs the same iterative algorithm as above but
now only applied to the repeated measures data set corresponding with
the (t, j, k) ∈τl, i.e., for which this cluster label column equals l. In this
case, one obtains a separate estimator ϵnl for each cluster l = 1, . . . , L,
and this ϵnl is used for each (t, j, k) ∈τl. Note that in this approach one
uses the same pooling to ﬁt ϵ as was used in the initial estimator.
Finally, consider the ordering based on L(t1, j1, k1) < L(t2, j2, k2) if and
only if either t1 < t2, or, if t1 = t2, j1 < j2, or, if t1 = t2, j1 = j2, k1 < k2.
Using this ordering, deﬁne disjoint and complementary clusters of points
that represent an interval in the ordering: thus the intervals cover all
points in the (t, j, k)-grid.
So, using this ordering any (t, j, k) can now be denoted with an integer V (t, j, k) ∈{1, . . . , N}, and a cluster now has to be of the form
[a, b] representing all integers between a and b, including a, b. A typical cluster will now only run over the integers corresponding with the k
values for a particular variable indicated by t, j. For each interval one
now runs the same iterative algorithm as above but now only applied
to the repeated measures data set corresponding with the (t, j, k) with
V (t, j, k) in the interval. This iterative targeted ML algorithm thus only
updates the QL(t,j,k),n for V (t, j, k) in the interval. However, we run these
interval-speciﬁc targeted MLE algorithms sequentially starting with the
last interval in the ordering. After having run the last interval algorithm
thereby updating the QL(t,j,k),n at the end of the ordering, we update
these QL(t,j,k),n, and run the next interval (going backwards!) with the
updated Qn. In this second interval targeted ML algorithm one updates
the QL(t,j,k),n corresponding with the second interval while ﬁxing the already obtained ﬁts from the ﬁrst interval. After having run this second
interval algorithm and having updated the corresponding QL(t,j,k),n, one
runs the targeted ML algorithm for the third interval (going backwards)
updating the QL(t,j,k),n corresponding with this third interval, while ﬁxing the already obtained ﬁts of the ﬁrst and second interval. One iterates
this updating process till one arrives at the ﬁrst interval, at which time
the algorithm is ﬁnished and the updated Q∗
n is complete.
This algorithm uses the fact that the clever covariates used in an interval
van der Laan: Targeted ML Causal Inference: Part II
only depend on the QL(t,j,k),n with V (t, j, k) in the interval and to the
right of that interval. As a consequence, an update of an interval does
not aﬀect the targeted ML algorithm for the intervals to the right of that
interval. Thus, by ﬁrst updating the QL(t,j,k),n at the end of the ordering
and moving backwards in the ordering we can ﬁnish the algorithm in
one round. In other words, we exploit the monotonicity property of the
clever covariates as presented in Theorem 3 in the companiion Part I
article, that allowed a closed form backwards targeted MLE algorithm
(converging in one step) if one uses a separate ϵ for each factor QL(t,j,k),n.
The Collaborative Targeted MLE: The targeted ML update of the initial
super-learning ﬁt Qn is a function of the clever covariates and thereby
depends on the choice of treatment/censoring mechanism estimator. Different choices of treatment/censoring mechanism estimator result in different clever covariates sets (Ctjk : t, j, k) and thereby result in diﬀerent
increases in likelihood ﬁts due to targeted MLE update.
As in van der Laan and Gruber , we suggest to use log-likelihoodbased cross-validation to select among a sequence of targeted maximum
likelihood estimators using increasingly nonparametric estimators of the
treatment mechanism to estimate the clever covariates, thereby ﬁnetuning the depth of bias-reduction pursued. For details about such procedures we refer to van der Laan and Gruber , including the fact
that the resulting targeted maximum likelihood estimator is now collaborative double robust. Collaborative double robustness means that the
targeted maximum likelihood estimator is consistent if one uses an estimator gn that converges to a true censoring mechanism that correctly
adjusts the covariates that explain (i.e. increase the likelihood ﬁt relative
to Qn) the residual bias Q −Q0, where Q denotes the limit of the initial estimator Qn. That is, covariates that are not helpful in explaining
residual bias Qn −Q0 do not need to be adjusted for in the censoring
mechanism inputted in the clever covariate/least favorable model. One
particular collaborative targeted MLE algorithm presented in van der
Laan and Gruber corresponds with using a greedy forward selection building of the treatment/censoring mechanism (adding one covariate at the time) based on the penalized log-likelihood of the corresponding targeted MLE, and choosing the size of the g0-ﬁt (i.e. number of
steps in forward selection algorithm) with penalized log-likelihood based
cross-validation, using a penalty to stabilize the procedure in sparse data
situations in which clever covariates can reach large/outlier values.
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 3
DOI: 10.2202/1557-4679.1241
In order to save computer time one could decide to not cross-validate
the initial estimator and also not cross-validate the treatment mechanism estimators in this cross-validated risk of this loss function. So the
initial estimator is treated as a ﬁxed oﬀ-set, and the clever covariates indexed by diﬀerent treatment mechanism estimators are treated as given
The cross-validation thus concerns running the second stage
targeted MLE algorithm described above on a training set, while ﬁxing
the treatment mechanism estimator (and thereby the clever covariate)
and the oﬀset-initial estimator at their ﬁt based on the whole sample.
In van der Laan and Gruber we point out that using a crossvalidated initial estimator as oﬀ-set, in the sense that Oi is coupled with
an initial estimator using the training sample excluding Oi, i = 1, . . . , n,
can be important to obtain the wished bias reduction with the targeted
MLE in the case that the initial estimator is an overﬁt.
In addition, to save computer time, when carrying out this building and
selection among diﬀerent targeted maximum likelihood estimators we
suggest that one might replace the candidate targeted maximum likelihood estimators with one-step (or few steps) targeted maximum likelihood estimators only carrying out one ϵn-updating step. Once a targeted
maximum likelihood estimator is selected, it is fully iterated till convergence, and the latter true targeted maximum likelihood estimator is the
reported estimator.
Evaluation of target parameter of targeted MLE: Above we deﬁned a
template for the targeted MLE Pn →Q∗
n(Pn). One now evaluates the
target ΨF(Q∗
n(Pn)) to obtain the wished estimator of ψ0 = ΨF(Q0).
Statistical Inference: Let’s ﬁrst consider the case in which we are willing
to assume that the treatment/censoring mechanism estimator converges
to the true g0. Under this assumption, we can carry out inﬂuence curve
based inference. In order to carry out statistical inference we can use
the fact that
n(Pn), gn(Pn)) = 0,
n(Pn) is the targeted MLE. If D∗can be represented as an estimating function D∗(ψ, Q, g) in ψ, then this corresponds with stating
n) solves the estimating equation
n, gn) = 0,
and statistical inference can now be based on the double robustness of
the estimating function P0D∗(ψ0, Q, g) = 0 if either Q = Q0 or g = g0.
van der Laan: Targeted ML Causal Inference: Part II
In particular, under the assumption that gn converges to g0, asymptotically conservative ﬁrst order statistical inference can be based on
the inﬂuence curve D∗(ψ, Q, g0) and corresponding conﬁdence intervals
n ± 1.96σn/√n, where
n, gn)2(Oi)
is an estimate of the variance of the inﬂuence curve. This follows from
the fact that under regularity conditions, ψ∗
n is asymptotically linear with
inﬂuence curve D∗(ψ0, Q, g0) minus its projection on the tangent space
of the model of g∗
n, where Q is the possibly miss-speciﬁed limit of Q∗
 ).
Collaborative double robust statistical inference: If we want to
rely on double robustness, either due to high dimension of the treatment mechanism, or due to sparsity (w.r.t. target) so that the targeted
maximum likelihood step is unstable, then we recommend the use of
the collaborative targeted MLE mentioned above, which also involves
the selection among targeted maximum likelihood estimators indexed by
diﬀerent candidate estimators of gn and thereby diﬀerent targeted MLE
steps, where this choice is based on how much the clever covariates improve the ﬁt of the log-likelihood (or loss-function speciﬁc risk) of the
corresponding targeted maximum likelihood estimator. As shown in the
Appendix of van der Laan and Gruber , using this approach, one
can still use the inﬂuence curve D∗(Q, g) for statistical inference, with
Q, g denoting the limits of Q∗
n and gn, and one now relies on collaborative
double robustness stating that gn needs to converge to a true conditional
distribution g0(Q), indexed by the limit Q of Q∗
n, that adjusts correctly
for the residual bias due to misspeciﬁcation of Q∗
n w.r.t Q0. For details,
we refer to van der Laan and Gruber .
Oﬀcourse, one can also use the bootstrap for statistical inference, which
might provide better ﬁnite sample assessment of uncertainty.
Application to marginal structural model for
realistic individualized rules.
Marginal structural models for a user supplied set of dynamic treatment regimens were developed and proposed in van der Laan , van der Laan
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 3
DOI: 10.2202/1557-4679.1241
and Petersen and, simultaneously and independently, in Robins et al.
 . van der Laan and Petersen also includes a data analysis application of these models to assess the mean outcome under a rule that switches
treatment when CD4 count drops below a cut-oﬀ, and the optimal cut-oﬀis
estimated as well. Another practical illustration in sequentially randomized
trials of these marginal structural models for realistic individualized treatment rules is presented in Bembom and van der Laan . In this section
we follow the approach of non-parametrically deﬁning the causal parameters
making use of marginal structural working model, as presented and advertised
in R. Neugebauer .
For the sake of concreteness, let’s consider the ”When to start treatment”
question in HIV research. Let time 0 denote the time at which the patient
enrolls in the study. At this time, various measurements are made, including
baseline CD4 count and viral load. Subsequently each patient is monitored at
various times on a possibly ﬁne discrete time scale (e.g., the time unit might
represent a week), and followed up till end of follow up or death. Certain timedependent variables might be recorded at regularly spaced monitoring times
such as a viral load and CD4 count, or the virus might be sequenced. Other indicator variables of particular events such as life-status indicator, heart-attack
indicator, cancer occurrence indicator, infection indicator, might be observed
at irregularly spaced monotoring times. In that case, if such an event occurs,
it is recorded, and one also knows at each time, if it has already occurred (i.e.,
if it has not been recorded, then it did not happen). At such intermediate
events, certain time-dependent variables might be recorded, beyond the variables recorded at the planned monitoring times. We will refer to any such time
as a monitoring time, but one will have to specify diﬀerent types of monitoring times. Diﬀerent types of monitoring times might result in the recording of
diﬀerent variables. Beyond these diﬀerent type of monitoring times and the
corresponding data collection at these time points, there is a time till death
and time till right-censoring, both marking the end of follow up. The rightcensoring event could be indexed by diﬀerent types, such as right-censoring
by the end of study or by a medical doctor’s decision. The indicator process
which jumps at the start of treatment is also observed. We are concerned with
using n such independently and identically distributed longitudinal data structures to compare the eﬃcacy of diﬀerent treatment strategies. For the sake
of illustration we will focus on targeted maximum likelihood estimation of the
eﬀect of diﬀerent rules for when to start a patient on antiretroviral therapy.
The organization of this section is as follows. To start with we will discuss
the format of the data on one patient, and the formulation of the likelihood
of such a longitudinal data structure factorized according to the statistical
van der Laan: Targeted ML Causal Inference: Part II
graph deﬁned by chronological time ordering. Subsequently, we will deﬁne
various causal eﬀects of ”when to start rules” as parameters of interventions on
this likelihood deﬁned by the G-computation formula, including the unknown
regression parameters in a marginal structural model for a family of realistic
individualized ”when to start treatment rules”. We will then deﬁne a ﬁrst stage
super-learning maximum likelihood (or other loss-function based) estimator,
and corresponding targeted maximum likelihood estimator of these unknown
parameters.
The graph-factorized likelihood of the experimental
data structure.
The data on a subject will involve various lines of data, each line corresponding
with a monitoring time (e.g., corresponding with an intermediate event time
such as an infection/heart attack etc), as indicated by a time-stamp column,
and a ﬁnal line corresponding with the follow up time till time at analysis or till
death or another event marking end of follow up. At each monitoring time,
updates on a collection of time-dependent variables will be recorded, while
the columns coding time-independent covariates remain (obviously) constant.
The time-dependent variables that are not measured at that monitoring time
are either coded as missing or one imputes (e.g forward imputation) a value,
and one creates an imputation indicator indicating if this measurement was
imputed or an actual update. The ﬁnal line of data provides the ﬁnal time
stamp, and either the censoring indicator column might jump to the value
1, and the type of censoring is coded, or, if this ﬁnal time-stamp is time till
death, then the life-status indicator jumps to the value 1.
Formally, we could code such a data set as follows. Let Wj(t) be a timedependent variable, deﬁned as constant in between monitoring times, using
forward imputation, and missing if no previous measurement is available, j =
1, . . . , J. Let ∆j(t) be an imputation indicator corresponding to Wj(t), j =
1, . . . , J. Let Nj(t) be a counting process such as Rj(t) = I(Tj ≤t) for time
till event variables Tj, which are observed at all time points t, j = 1, . . . , J1.
Updates of the variables W(t) only occur at a time point for which at least
one of the dNj(t) = 1, i..e, at a time t at which one of the counting processes
Nj jump. For example, if there is regular monitoring at ﬁxed time points,
beyond monitoring at random times, then one of the counting processes codes
the regular monitoring times, while others code the random monitoring times.
We can now deﬁne a process O(t) = ((Wj(t), ∆j(t) : j), (Nj(t) : j)), and we
truncate this process at the minimum of end of follow up time and a maximal
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 3
DOI: 10.2202/1557-4679.1241
follow up time τ. We will suppress the missing indicators ∆j(t) in notation
below, and just refer to Wj(t). The observed data structure for one unit is
now given by ¯O = (O(t) : t ≤τ). Note that in this ﬁle ¯O, a jump of Nj results
in a new line of data.
If at a monitoring time stamp various measurements are made, then there
might be additional time ordering within the time-stamp. For example, the
time-stamp might correspond with a day, and it might be known that the
medical doctor made a treatment decision that day based on a variety of newly
recorded measures, and possibly additional measures were obtained that same
day, after the treatment had been given. This kind of additional time ordering
information is an important component of the causal graph necessary to obtain
a valid G-computation formula respecting the time-ordering. In this case, for
each t, W(t) should be accompanied with a time-ordering vector making clear
which groups of variables were measured at the same time and how these
groups are ordered in time.
The factorization of likelihood respecting the time-ordering.
likelihood of this longitudinal data structure ¯O could be written as a product
over time t starting at time 0. One starts with drawing the baseline data
at time 0. Subsequently, at each time point one draws from the conditional
intensities of Nj, given past, including the planned monitoring intensities, time
till event intensities, and end of follow up intensities such as time till death or
time till right censoring intensities. As long as none of these events occur, one
proceeds to the next time interval.
When one of these events occurs, then the possible additional random variables corresponding with that type of event are drawn, possibly sequentially
according to an additional time ordering, thus always following the known
time-ordering. One proceeds generating random variables like this, moving
along in discrete time, till either death happens, another ﬁnal event happens
which marks the end of follow up, or the end of study is reached.
Such a likelihood p0(O) = Q
t p0(O(t) | ¯O(t−)), can be factorized as
λj(t | Pa(dNj(t)))dNj(t)(1 −λj(t | Pa(dNj(t))))1−dNj(t)
P(W(t) | Pa(W(t))),
where we used an ordering for the components dNj(t) so that Pa(dNj(t)) =
O(t−), dN1(t), . . . , dNj−1(t), and Pa(W(t)) = O(t−), dN(t).
If dN(t) = 0
(i.e., each dNj(t) = 0), then no events and monitoring occurs at time t so that
P(W(t) | Pa(W(t))) is degenerate.
van der Laan: Targeted ML Causal Inference: Part II
Let W(t) = (W −(t), A(t), W +(t)), where A(t) is a treatment decision at
time t, W −(t) are variables recorded before A(t), and W +(t) are variables
recorded after t. This particular time-ordering at time t can depend on the
realization of dN(t): i.e. for diﬀerent types of events, diﬀerent variables might
be collected, and for each such group of variables that recorded, we need to
know what variables are pre-treatment and post-treatment decision at time t.
So we have, respecting the time-ordering,
P(W(t) | Pa(W(t)))
P(W −(t) | Pa(W −(t)))P(A(t) | Pa(A(t)))
P(W +(t) | Pa(W +(t))).
The conditional probability distributions PW −(t) and PW +(t) can be factorized in terms of products of conditional densities of particular variables, and
these conditional densities can be further factorized in terms of hazards of
binary events. as we did in the previous sections.
We conclude that we have the following factorization of the likelihood in
terms of conditional distribution of binary events, given the parent sets, factored according to the known time-ordering and user supplied orderings in the
case that there is no time ordering provided,
Incorporation of causal graph knowledge beyond time-ordering.
graph knowledge can be incorporated by reducing the parent set of the nodes,
and/or enforcing orderings of variables beyond the one implied by the time
ordering. The time-ordering always has to be satisﬁed by any causal graph,
so that any additional causal graph information provides additional ordering
of all measured variables, and possible reductions of parent sets.
The likelihood factored in intervention mechanism
and relevant factor.
We can refer to Q
t gA(t), with gA(t)(A(t) | Pa(A(t))), as the treatment mechanism, and it provides us also with a likelihood criterion that can be used to
generate maximum likelihood estimators of this treatment mechanism. A special case of a process A(t) is of the form A(t) = I(S ≤t), where S is the time
at which an antiretroviral therapy is started. In this case, A(t) only jumps
If dN(t) = 0, then no treatment decisions are made at time t so that
gA(t) is degenerate at such a parent set realization. If dN(t) ̸= 0, then the
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 3
DOI: 10.2202/1557-4679.1241
treatment assignment mechanism can still depend heavily on the type of event
that occurred: i.e., which dNj(t) = 1. In particular, it might be the case
that only for one type of event, treatment decisions are made, while for any
of the other events coded by the counting processes Nj(t), A(t) will not be
assigned/changed, so that it will still follow a degenerate probability distribution. Note that this treatment mechanism product over all times t reduces to
a product of treatment probabilities at the ﬁnite (but random) time points for
which dN(t) ̸= 0 and for which there is experimentation in A(t). For example,
if N1 jumps at the time point at which doctors generate measurements and
make treatment decisions, and all other events as coded by Nj, j = 2, . . . , J
do not generate treatment decisions with probability 1, then we have
t:dN1(t)=1
gA(t)(· | Pa(A(t)), dN1(t) = 1).
Interventions on treatment.
Interventions on this treatment assignment
mechanism deﬁne interesting causal eﬀects. However, it needs to be understood that such an intervention does not control the actual time points at
which these treatment decisions can be enforced: i.e.. the time points at which
A(t) changes value are kept uncontrolled under an intervention on this treatment mechanism, and, might be diﬀerential depending on the actual treatment
intervention.
Interventions on treatment and timing of treatment changes. Therefore it is also of interest to intervene on both the treatment assignment mechanism as well as the monitoring mechanism that generates the monitoring times
at which the treatment decisions can be enforced. For that purpose, suppose
that N1 is a counting process that jumps at times at which treatment decisions
are made. It would now also be of interest to both intervene on the monitoring
process N1 as well as on the treatment decisions made at the monitoring times
deﬁned by N1.
In that case the total mechanism deﬁning the ”treatment mechanism” is
λN1(t)(t)dN1(t)(1 −λN1(t)(t))1−dN1(t)gA(t).
The ﬁrst factor concerns the assignment of monitoring times of type 1 and the
second factor concerns treatment decisions at such times, but possibly also at
monitoring times of diﬀerent types. As a special case, one might have that
treatment decisions are only made at monitoring times of type 1, so that intervening on N1 and the treatment assignment mechanism at these monitoring
van der Laan: Targeted ML Causal Inference: Part II
times is an intervention on the complete treatment process. In this case, only
gA(t)(A(t) | Pa(A(t)), dN1(t) = 1) needs to be estimated, since conditioning
on other realizations of dN(t) makes gA(t) a degenerate distribution.
Right-censoring mechanism. We also deﬁne the factor that deﬁnes the likelihood for the right-censoring events. For example, if N2 is the (only) counting
process that codes right-censoring events that obstruct the complete observation of the outcome of interest Y , then we deﬁne the censoring mechanism
λdN2(t)(t)dN2(t)(1 −λdN2(t)(t))1−dN2(t).
Combined set of conditional distributions we intervene upon. We
will denote the combined treatment and censoring mechanism with g = g1 ∗g2.
Here g1 can be either the treatment mechanism or it can be both the treatment
and monitoring mechanism, depending on the scientiﬁc question we wish to
Target parameters of G-computation formula: Marginal
structural working model for intervention rules.
We will consider causal eﬀects of two interventions. Firstly, we discuss intervening on the treatment assignment process only, and subsequently, we discuss
interventions on both treatment and monitoring.
Causal eﬀect of intervention on treatment decisions at uncontrolled
monitoring times. Suppose that, in words, we wish to assess the mean outcome Y measured at a ﬁxed time K since baseline under a dynamic treatment
rule dθ that start treatment right after a measured CD4 count falls below θ.
Here Y might be deﬁned as the indicator of still being alive at time K, or an
absolute level of CD4 count, or a combination of death and CD4 count such
as an indicator of death or CD4 is below a critical value.
We now need to decide how we can formally deﬁne this parameter as an
operation on the time-ordered/causal graph factorized likelihood of the data.
Firstly, let’s consider the case in which we do not intervene on the monitoring
process N1 that generates the monitoring times at which biomarker data (e.g.,
CD4 and viral load) is generated and treatment decisions are made. In this
case we only intervene on the treatment assignment rule at the monitoring
times generated by the true intensity λ1 of N1. Such a rule might be that
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 3
DOI: 10.2202/1557-4679.1241
if the most recent measured CD4 count is below θ, then the anti-retroviral
therapy is started.
Since our outcome Y is subject to right-censoring by some of the other
intensities and we are only interested in the eﬀect of the treatment intervention on the uncensored outcome, we also need to intervene on the censoring
mechanism. Let A2 be the censoring process which jumps from zero to one
at a time point t in which a subject is right-censored by an event coded by
one or more of the counting processes. Let g = g1g2 denote the factor of the
likelihood that generates the treatment A and right-censoring A2 events.
To generate the counterfactual data under such a rule dθ, one would now
generate the data according to the likelihood as described above, but at a
monitoring time t with dN1(t) = 1 at which a treatment decision is possible,
we would now apply the dynamic rule to set the indicator A(t) of starting
treatment at time t, and at each time at which censoring can occur, we set
the relevant dNj(t) = 0 for all j that code right-censoring events. Note that
this intervention would leave the monitoring process random as it is. So, if
particular patients are badly monitored, even under a rule dθ, they might start
treatment at a much lower CD4 count than θ due to large time periods in which
the patient’s CD4 count is not observed.
Causal eﬀect of intervention on monitoring times and treatment
decisions. If one is concerned that the monitoring process heavily aﬀects
the clinical outcome and one is concerned with extrapolation of the results to
a population in which monitoring times are diﬀerently distributed, then one
might wish to assess the eﬀect of rules that intervene on both the monitoring
mechanism, as well as the treatment assignment mechanism. For example,
a rule might be that one monitors a patient every θ1 months and thereby
measures the CD4 count and viral load at these times, and that one starts antiretroviral treatment when the CD4 count measured at that time is below θ2.
To generate the data under such a rule dθ1,θ2, one would now generate the data
according to the likelihood as described above, except one would not generate
monitoring times based on λ1 till one reaches t = θ1, at which time one sets
the monitoring time at t = θ1, one draws from the conditional distribution of
time-dependent covariates at that time point, conditional on being monitored
at that time, and one assigns the when to start treatment decision according
to the rule indexed by threshold θ2. One proceeds over time following the
data generation according to the likelihood, the set monitoring times, the set
treatment starting rule, and right-censoring set at inﬁnity. It is also of interest
to consider an intervention on monitoring that corresponds with randomly
van der Laan: Targeted ML Causal Inference: Part II
will not consider this case below.
Identiﬁability of target parameter. These rules have to be realistic rules
in order to make the corresponding counterfactual probability distributions
identiﬁable from the observed data. For example, the intensity λ1 needs to have
support on these regularly spaced monitoring times kθ1, k = 1, 2, . . ., and the
lower the support the harder it will be to reliably estimate the counterfactual
distribution for that choice of θ1. If in the actual study people were regularly
followed, say every 3 months, and that variations on the monitoring times were
at most one month oﬀ, then one would expect a good support for θ ∈[3 −
δ, 3 + δ] for an appropriately chosen δ. Similarly, the when to start treatment
decision rule needs to be supported by the medical doctors that made these
decisions in the actual study. For example, if the medical community supports
the starting of the antiretroviral therapy at CD4 counts between 200 and 400,
in the sense that there is experimentation across that range, then one should
choose θ2 in that range. Finally, the right-censoring intensity should never
equal 1, whatever the history, up till the time point K at which the outcome
can be measured. Thus, if K is selected too large, then the latter assumption
might become practically violated. In addition, if there are events that imply
right-censoring at the next time point with probability 1, then one might need
to include such events in the deﬁnition of the outcome Y , so that the eﬀect
of treatment on that Y is still identiﬁable from the data, and such eﬀects will
then need to be honestly interpreted.
These counterfactuals Yθ indexed by the rule dθ for the treatment process ¯A,
either only including the treatment decisions or also including the monitoring
time process N1, are now deﬁned by its probability distribution Qθ deﬁne
above as an intervention on the the graph-factored likelihood, obtained by
excluding the factors g = g1g2 that are set by the rule, and setting the values
of treatment ¯A and right-censoring ¯A2 according to the rule dθ in any of the
conditioning events of the other factors of the likelihood.
We can now deﬁne the parameter of interest as a projection of EYθ onto
a working model, thereby creating smoothing parameters of the complete response curve θ →EYθ for which larger data support is available so that it
can be estimated using semi-parametric model eﬃciency theory and methodology. That is, EYθ is often not path-wise diﬀerentiable, while such a summary
parameter will be path-wise diﬀerentiable.
Marginal structural models for realistic individualized treatment
rules. Speciﬁcally, let mβ(θ, V ) be a working model for the conditional mean
of Yθ, under rule dθ (controlling treatment and censoring), given a baseline
drawing monitoring times from a user supplied monitoring mechanism, but we
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 3
DOI: 10.2202/1557-4679.1241
(for example) CD4 count V , such as
mβ(θ, V ) = β0 + β1θ + β2θ2 + β3θV + β4θ2V.
We now deﬁne the target parameter as
Ψ(P0) = ΨF(Q0) = arg min
h(θ, V )(Yθ −mβ(θ, V ))2,
where we remind the reader that Q0 denotes the factor of the probability
distribution of O: p0 = Q0g. Here h(θ, V ) is a user supplied weight function.
Thus Ψ is only a parameter of P0 through its Q0-factor. We refer to mβ as
a marginal structural (working) model for realistic treatment rules ).
Evaluation of target parameter. Given such an estimator Qn or its targeted MLE update Q∗
n deﬁned below, the evaluation of Ψ(Qn) can be based
on Monte-Carlo simulation. One ﬁrst samples a larger number B of observations Yθ,b, Vb, b = 1, . . . , B for each possible θ, from the corresponding Gcomputation formula of the distribution of Yθ. Then,
ΨF(Qn) = arg min
h(θ, Vb)(Yθ,b −mβ(θ, Vb))2.
In other words, we simply replace the expectation EQ0 of a function fθ,β(Yθ, V )
of Yθ, V in the deﬁnition of ΨF(Q0) by an expectation w.r.t. empirical distribution of the B draws (Yθ,b, Vb), b = 1, . . . , B.
Adaptive maximum likelihood estimation: Super
Given an estimator Qn of Q0, one obtains the estimator Ψ(Qn) of ψ0 = ΨF(Q0).
Since the likelihood factor Q factorizes in a product over conditional distributions of binary factors, we can estimate this with loss-based super-learning
methodology that can be implemented with standard software tools. Thus
one applies super learners for binary predictions, possibly pooled across many
of the binary predictions, pooling across time and or across diﬀerent levels
of ordered variables indexing the binary variables. The overall log-likelihood
or pooled weighted squared error loss function for Q0 could be employed for
ﬁne-tuning the choice and degree of pooling, only considering sensible pooling strategies. Super-learning could then be based on a library of algorithms
van der Laan: Targeted ML Causal Inference: Part II
for estimation of the complete Q0 based on this overall loss function for Q0.
Some of the candidate algorithms in the library of the super learner might involve super-learning itself of binary predictors possibly using diﬀerent pooling
strategies.
To be speciﬁc, let’s consider modeling the conditional distribution of CD4
count at time t, given its parents. We will model this in terms of conditional
binary distributions. Suppose that we can view CD4 as an ordered discrete
variable with levels l = 1, . . . , L, possibly deﬁned by the L equally spaced
quantiles of the marginal empirical distribution of CD4 counts. Let QCD4(t)
denote the conditional distribution of CD4 count at time t, conditional on
the parent nodes and that the person is monitored at time t so that the CD4
count process is at risk of changing. We write this conditional probability
distribution of CD4(t) in terms of binary conditional distributions
QCD4(t)(CD4(t))
QI(CD4(t)=j)(1)CD4(t)=jQI(CD4(t)=j)(0)CD4(t)̸=j.
If we deﬁne the discrete hazard
λCD4(t)(j) ≡P(CD4(t) = j | CD4(t) ≥j, Pa(CD4(t))
of CD4 count at time t, then it follows that
QCD4(t)(l) =
(1 −λCD4(t)(j))
λCD4(t)(l).
The likelihood for this discrete hazard is thus given by
L(λCD4(t)) =
i=1,Moni(t)=1
(1 −λCD4(t),i(l))λCD4(t),i(CD4i(t)).
The likelihood of this discrete hazard λCD4 ≡(λCD4(t)(j) : t, j) viewed as a
function in both time t and the CD4 count level j is thus given by
i=1,Moni(t)=1
(1 −λCD4(t),i(l))
λCD4(t),i(CD4i(t)).
One can now carry out estimation of this nonparametric function λCD4 based
on this log-likelihood loss function. In particular, one can apply super-learning
based on this loss function.
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 3
DOI: 10.2202/1557-4679.1241
We note that if monitoring is really random, then one will have few subjects that have a monitoring time at a given time point t within a ﬁne grid
of time points. As a consequence, in that case the t-speciﬁc likelihood for
λCD4(t) provides too little information for estimation of λCD4(t). Thus, it will
be essential to use the combined likelihood pooling across time the time points
t provided above.
Calculation of least favorable model for targeted
We now focus our attention on the deﬁnition of the ﬂuctuation function required to carry out the targeted MLE step.
Inverse probability of censoring weighted function. Let X represent
the collection of action speciﬁc counterfactuals controlling the intervention
nodes deﬁned by ¯A1, ¯A2. We will ﬁrst deﬁne an IPCW-estimating function of
O for the parameter EYθ for a given θ, before presenting the IPCW-function
of O for the MSM-parameter Ψ.
I(A1 = dθ(L), ¯A2(K) = 0)
where g = g1g2 represents the product of conditional distributions of the intervention nodes ¯A1 and ¯A2. Thus an IPCW-estimating function of EYθ is given
by )
I(A1 = dθ(L)), ¯A2(K) = 0)
(Y −EYθ) .
By a similar argument, it follows that the IPCW-estimating function of Ψ(Q0)
is given by
DIPCW(O) =
h(θ, V ) d
0(θ, V )I(
A1 = dθ(L),
A2(K) = 0)
(Y −mψ0(θ, V )).
For example, if we also intervene on the monitoring times at which treatment
can be changed, then g(A | X) involves a product over time of the likelihood
of monitoring events and a treatment event if monitoring occurred, and no
censoring event, always conditioning on the parent sets implied by the graph
implied by time ordering and possibly additional causal graph assumptions.
van der Laan: Targeted ML Causal Inference: Part II
binary factors. We ﬁrst note that the IPCW-estimating function DIPCW(O)
can be represented as
θ h(θ, V )
dψ0mψ0(θ, V )I(A1 = dθ(O), ¯A2(K) = 0)(Y −mψ0(θ, V ))
We have that the Q0-factor of the density of the data is represented as
Here we exclude the conditional distributions of the counting processes corresponding with right-censoring and or monitoring events, depending on how
A is deﬁned.
This Q0-factor identiﬁes the G-computation formula for the
distribution of the data under the individualized interventions dθ.
Let TQ be the tangent space of Q0 at PQ,g. This tangent space TQ can be
decomposed orthogonally as:
TQ = TQW (0) +
where TQW (0) is the tangent space of the marginal probability distribution of
W(0), Tλj,t is the tangent space of the j-th intensity λj(t), TQ−
tjl is the tangent
space of conditional distribution of W −
jl (t), and TQ+
tjl is the tangent space of
conditional distribution of W +
By our general Theorem, we have that the eﬃcient inﬂuence curve D∗=
Π(D | TQ) can be represented as
D∗= Π(D | TQ) = D0 +
where D0 = E(D∗| W(0)), and for each other factor, we can represent it as
Dλj,t = Ctj(dNj(t) −λj(t)), D−
jl (t) −Q−
tjl(1)), D+
tjl(1)), where these (clever covariates) Ctj, C+
tjl are deﬁned below. These
functions Dt,λj, D+
tjl and D−
tjl are zero at corresponding parent histories which
deterministically predict the value of the corresponding binary variable dNj(t),
jl (t), W −
jl (t), respectively. For example, if W −
jl (t) is only generated at a
monitoring time t generated by N1, then P
t:dN1(t)=1 D−
tjl reduces to
a sum at the random monitoring times at which dN1(t) = 1. On the other
hand, if N1 is at risk of jumping at any of the time points t, then P
remains a sum over all time points t.
The eﬃcient inﬂuence curve and corresponding clever covariates for
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 3
DOI: 10.2202/1557-4679.1241
For each binary variable dNj(t), W +
jl (t), W −
jl (t) we deﬁne ¯A(t, j), ¯A+(t, j, l),
A−(t, j, l), respectively, as the A-nodes that are included in the parent set of
that binary variable. For each binary variable dNj(t), W +
jl (t), W −
jl (t) we deﬁne
a(t, j), a+(t, j, l), a−(t, j, l) as the future path, corresponding with a complete
path ¯a, starting right after where ¯A(t, j), ¯A+(t, j, l), ¯A−(t, j, l) stops.
Suppose that the process A we control includes the monitoring process
N1. In that case, ¯A(t, j) = ¯A(t−), dN1(t), dA2(t)) includes all actions up till
and including previous time point and the censoring and monitoring event
at time t, ¯A−(t, j, l) equals ¯A(t−), dN1(t), dA2(t) as well, and ¯
A+(t, j, l) equals
A(t−), dN1(t), dA1(t), dA2(t) including now also the treatment decision at time
t. If our process A does not control monitoring N1, then exclude N1 from the
statement in the previous sentence.
The formulas for Ctj, C+
tjl, and C−
tjl can now be deﬁned as
g(A(t,j)|X) × {Ctj(1, Pa(dNj(t))) −Ctj(0, Pa(dNj(t)))}
g(A(t,j,l)+|X) × {C+
tj(1, Pa(W +
jl (t))) −C+
tj(0, Pa(W +
g(A(t,j,l)−|X) × {C−
tj(1, Pa(W −
jl (t))) −C−
tj(0, Pa(W −
jl (t)))},
where, for δ ∈{0, 1},
Ctj(δ, Pa(dNj(t))) = EQ
D1 | dNj(t) = δ, Pa(dNj(t))
and, similarly, we deﬁne the other terms C+
tj(δ, Pa(W +
jl (t))) and C−
tj(δ, Pa(W −
Here we used short-hand notation for P
a(t,j) D1(OA(t,j),
a(t,j)), and similarly
for the other two terms. If the parent set implies that there is no experimentation in the node, then this clever covariate is not deﬁned, and is also never
needed, as stated above. If one wants to extend the deﬁnition, then one could
simply deﬁne the clever covariate as zero for any parent set in which there is
no experimentation in the binary node.
For each binary node, the clever covariate can also be represented as the
diﬀerence of the conditional expectation of DIPCW = D1/g(A | X) given the
binary node equals 1, and the conditional expectation of DIPCW given the
binary node equals zero, and in both cases one also conditions on the parent
set of the binary node. In other words, it is a choice to either integrate out over
the future sample paths a so that the clever covariate factors in a g and Qfactor, or not. One can evaluate these prediction representations of the clever
covariate by Monte-Carlo simulation which involves drawing from all future
factors of the density (either from Q only, or, from both Q and g, depending
on the representation), starting at which the parent set left-oﬀ.
van der Laan: Targeted ML Causal Inference: Part II
These clever covariates provides us with the least favorable model through
Qn (at ϵ = 0) with ﬂuctuation parameter ϵ whose score at ϵ = 0 equals the
eﬃcient inﬂuence curve D∗(Qn, gn), and deﬁnes the corresponding targeted
n and Ψ(Q∗
n). We will not repeat this deﬁnition of the targeted MLE,
since it was presented in the previous section and our Part I companion paper.
Targeted maximum likelihood estimation at degenerate initial estimator of intermediate conditional
distribution.
For simplicity, let’s consider the case that our initial estimator provides deterministic predictions for any of the intermediate time-dependent covariates, so
that the clever covariates for all intermediate factors equals zero. As a consequence, the targeted MLE only involves updating the conditional distribution
of the ﬁnal node Y , given its parents.
Consider the IPCW-estimating function:
DIPCW(O) =
h(θ, V ) d
0(θ, V )I(
A1 = dθ(O),
A2(K) = 0)
(Y −mψ0(θ, V )).
Under a degenerate distribution for all intermediate variables, we only have to
project this onto the tangent space of the distribution of L(0) and the conditional distribution of Y , given ¯L(K), ¯A(K). We will now present this eﬃcient
inﬂuence curve at such a Q, and, for the sake of illustration, we will show
that it represents an unbiased estimating function of ψ at a correctly speciﬁed
g0, and arbitrarily misspeciﬁed Q. The eﬃcient inﬂuence curve has now only
two components we will denote with D∗
1(Q, g0) and D∗
2(Q, g0) respectively. We
D1(Q, ψ0) =
h(θ, V ) d
0(θ, V )(EQ(Yθ | L(0)) −mψ0(θ, V ))
and, using dθ,0 to denote both the treatment rule and the no-censoring intervention,
D2(Q, g0) =
h(θ, V ) d
0(θ, V )I( ¯
A = dθ,0(O))
(Y −EQ(Y | ¯A(K), ¯L(K))).
Thus the clever covariate we add to an initial estimator of the conditional
distribution of Y , given ¯A(K), ¯L(K), is given by
h(θ, V ) d
0(θ, V )I( ¯
A = dθ,0(O))
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 3
DOI: 10.2202/1557-4679.1241
n be the targeted MLE based on an initial estimator Qn deﬁned by the
empirical distribution Qn,L(0) of L(0) and an initial estimator Qn,Y of Y , given
A(K), ¯L(K), and degenerate distributions Qn,d for all the conditional distributions of intermediate variables/time-dependent confounders. The targeted
maximum likelihood estimator solves the eﬃcient inﬂuence curve equation
n, gn, Ψ(Q∗
We now show that indeed, as predicted by the double robustness of the
eﬃcient inﬂuence curve, P0D∗(Q, g0, Ψ(Q)) = 0 implies Ψ(Q) = Ψ(Q0), showing that the targeted MLE Ψ(Q∗
n) solves an unbiased estimating function in ψ
at a correctly speciﬁed g0. Note, by ﬁrst conditioning on X in P0D2,
P0D∗(Q, g0, Ψ(Q))
P0D1(Q, Ψ(Q)) + P0D2(Q, g0)
h(θ, V ) d
dψm (θ, V )(EQ(Yθ | L(0)) −mψ(θ, V ))
h(θ, V ) d
dψm (θ, V )(Yθ −EQ(Y | ¯
A(K) = dθ(¯L(K), ¯L(K))).
Now, note that, under the degenerate distribution Q, we have
EQ(Y | A(K) = dθ(¯L(K), ¯L(K))) = EQ(Yθ | L(0)).
Thus, we have
P0D∗(Q, g0, Ψ(Q)) = EQ0
h(θ, V ) d
dψm (θ, V )(Yθ −mΨ(Q)(θ, V )).
By deﬁnition of Ψ(Q0) we have that the latter equation equals zero at ψ0.
Thus, we can conclude that indeed, under a weak identiﬁability condition on
the working model mψ, P0D∗(Q, g0, Ψ(Q)) = 0 implies Ψ(Q) = ψ0 = Ψ(Q0).
This targeted MLE only involves adding a clever covariate to Qn,Y and
doing a single step update. This updated distribution, only updating Qn,Y ,
equals the targeted MLE at such an initial Qn.
Discussion on using degenerate ﬁts to simplify targeted MLE. Even
though the degeneracy of the initial estimator results in a simple to compute
T-MLE, it is questionable till what degree this should be an issue to consider.
Given available software, the actual practical performance will be the driving
force in such a decision over time. We can simplify the T-MLE in less dramatic
ways, by enforcing the degeneracy for most time-dependent variables, but truly
modelling the conditional probability distribution for the most important timedependent confounders. This might result in a highly eﬃcient T-MLE, while
van der Laan: Targeted ML Causal Inference: Part II
it still only involves updating the non-degenerate conditional distributions. In
particular, such a T-MLE can still be obtained in closed form by using our
backwards solving algorithm and using a separate updating step (i.e. variation
independent ﬂuctuation parameters for the conditional distributions) for these
non-degenerate conditional distributions.
Speciﬁcally, in the when to start treatment application, it is well known
that CD4 count and viral load are the most important time-dependent confounders. In addition, we consider dynamic rules for when to start the treatment responding to these time-dependent confounders. Thus, in this case, it
seems particularly appropriate to estimate the actual conditional distributions
of CD4 and viral load at the intermediate monitoring times.
The clever covariates of the CD4 count or viral load involve the evaluation of conditional expectations of the future outcome given the parent nodes.
Since these conditional expectations are calculated under a Q-ﬁt that uses a
deterministic system for all variables except viral load, CD4, and the ﬁnal outcome Y , this only involves random generation of the future CD4 counts, viral
loads, and ﬁnal Y . All other nodes are generated deterministically according
to a ﬁtted prediction function.
We also note that the degenerate conditional distributions do not need to
be factored in terms of binary conditional distributions since these will not
be updated anyway. Instead, one could simply predict the mean outcome for
any continuous or ordered categorical variable from its parent nodes, and put
probability 1 on that predicted value.
Dimension reduction.
We refer to our subsection on dimension reduction in the Part I article, which
shows that one can reduce the dimension of the time-dependent process L(t)
to a few univariate time dependent processes, beyond the time-dependent covariates used in the rule dθ, at little loss of information, while still using the
same ﬁt of the g-factor adjusting for all relevant variables.
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 3
DOI: 10.2202/1557-4679.1241
Application to causal eﬀect of point treatment, allowing for right-censoring and utilizing time-dependent covariates.
In this section, we consider a simpliﬁed version of the general data structure
covered in previous section. Suppose we observe as unit-speciﬁc data structure
O = (W, A, A2(1), L(1), . . . , A2(K), L(K), A2(K + 1), Y ),
where W is baseline covariates, A is a treatment assigned at baseline, A2(j) =
I(C ≤j) is the indicator of being right-censored at time j, C is right-censoring
time, L(j) is the biomarker (e.g., CD4 count) measured at time j, using forward imputation if C ≤j, and Y is the ﬁnal outcome of interest, but aﬀected
by right-censoring. For example, Y = I(T ≤K + 1)(1 −A2(K + 1)) is the
indicator of a time T till failure at time K + 1 and not being censored. We
assume L(j) is ordered and discrete values with values m = 1, . . . , M. The
treatment A could be randomized as in a randomized controlled trial.
Suppose that the model for the distribution P0 of O is nonparametric, and
let ψ0 = EY (1) −Y (0) be the additive causal eﬀect of the binary treatment,
where Y (a) is deﬁned as the random variable with probability distribution
deﬁned by the G-computation formula under the intervention A = a and
C = ∞(i.e., no censoring), a ∈{0, 1}.
The G-computation formula for this target parameter requires estimation
of the marginal distribution of W, the conditional distribution of L(j), given
past and not being right-censored, j = 1, . . . , K, and the conditional distribution of Y , given past and not being right-censored. The marginal distribution
is estimated with the empirical distribution of W. If Y is binary, the conditional distribution of Y , given past and not being right-censored, is estimated
with loss-based super-learning based on the log-likelihood loss function, and, if
Y is continuous, we estimate the conditional mean of Y with loss-based superlearning based on the squared error loss function: the eﬃcient inﬂuence curve
of ψ0 only depends on the conditional distribution of Y through its conditional
The conditional distribution of L(j), given past, and not being rightcensored, is also estimated with loss-based (super) learning using the loglikelihood loss function, but we will ﬁrst factorize the conditional density as
P(L(j) = l | ·) =
(1−P(L(j) = m | L(j) ≥m, ·))P(L(j) = l | L(j) ≥l, ·).
van der Laan: Targeted ML Causal Inference: Part II
In other words, we code L(j) as a a vector of binaries I(L(j) = 1), I(L(j) =
2), . . . , I(L(j) = M), and, factor the likelihood of L(j) accordingly. Thus, it remains to estimate the conditional hazard P(L(j) = m | L(j) ≥m, Pa(L(j))).
We could estimate this with super-learning smoothing in both time j and level
The G-computation formula for the counterfactual distribution of W, ¯L, Y
under intervention A = a and no-censoring ¯A2 = 0 is given by
Pa(W, L(1), . . . , L(K), Y ) =
m QL(j,m)(L(j, m) | Pa(L(j, m), A = a, ¯A2(j) = 0)
QY (Y | Pa(Y ), A = a, ¯A2(K) = 0),
where the conditional distribution of L(j, m) = I(L(j) = m), given its parents
(L(j, 1), . . . , L(j, m−1)), Pa(L(j)) is degenerate if one of the indicators L(j, l)
with l ≤m −1 is already equal to 1.
The targeted maximum likelihood step now involves adding clever covariates (on the logit-scale) to the logistic regression ﬁts of the conditional distributions of L(j, m), j = 1, . . . , K, m = 1, . . . , M, and the logistic or normal
error (i.e., least squares, if Y is continuous) regression ﬁt of Y . These clever
covariates for the conditional distribution of the binary L(j, m) are
EQ,g(DIPCW | L(j, m) = 1, Pa(L(j, m)), ¯A2(j) = 0)
−EQ,g(DIPCW | L(j, m) = 0, Pa(L(j, m)), ¯A2(j) = 0),
DIPCW(O) = Y
I(A = 1, ¯A2 = 0)
g(A, ¯A2 | X)
−I(A = 0, ¯A2 = 0)
g(A, ¯A2 | X)
So, calculation of the clever covariates requires, for each subject i, for each
time j with Ci > j, and each m with Li(j) ≥m, Monte-Carlo simulation
to evaluate the conditional mean of DIPCW, conditional on Pai(Li(j, m)) for
which Li(j) ≥m and Ci > j. This corresponds with imputing a Y (1) and
Y (0), and thereby a Y (1) −Y (0), for each subject, based on history of that
subject at time j, across j.
The clever covariate to ﬂuctuate the conditional distribution of Y is given
I(A = 1, ¯A2 = 0)
g(A, ¯A2 | X)
−I(A = 0, ¯A2 = 0)
g(A, ¯A2 | X)
If Y is binary, the ϵCY is added on the logistic scale, and if Y is continuous,
one adds ϵCY to the ﬁtted conditional mean of Y .
The iterative targeted
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 3
DOI: 10.2202/1557-4679.1241
maximum likelihood algorithm can now be applied to obtain the targeted
maximum likelihood estimator Q∗
n and corresponding Ψ(Q∗
If one assumes that gn converges to g0, faster than Q∗
n converges to Q0
n is inconsistent, or converges at slow rate), then it makes sense to use
as loss function for Q L(Q) = D∗(Q, gn)2. Thus, one would use loss-function
based cross-validation to select among diﬀerent targeted maximum likelihood
estimators Q∗
n indexed by diﬀerent initial estimators. In this manner, one is
guaranteed to asymptotically select the targeted maximum likelihood estimator that results in the most eﬃcient estimator of ψ0.
Statistical inference can be based on the norrmal distribuition approximation of √n(ψ∗
n−ψ0), given by N(0, σ2
n), where σ2
n is an estimate of the variance
Discussion.
As mentioned in our template, in van der Laan and Gruber we present
a variety of proposals for generating a sequence of targeted MLE’s Q∗
j coupled with a treatment mechanism estimator gj, each deﬁned as the result of
the targeted MLE algorithm that maps an initial estimator Qj and treatment
mechanism estimator gj into an targeted MLE update Q∗
j, indexed by treatment/censoring mechanism estimators gj that are increasingly nonparametric
in j, and ”initial” Qj that themselves might represent a targeted MLE update
of a previous initial estimator.
Such a sequence of candidate targeted MLE’s is constructed to be increasing in the empirical risk of a loss function for Q0 (e.g., log-likelihood), and
corresponds with increasing levels of targeted bias reduction (since the later
ones use an estimator of the treatment mechanism g0 that is more nonparametrically estimating g0 than estimator used in previous, and using g0 results
in the full bias reduction for the target parameter). Given such a constructed
sequence of candidate targeted MLE’s, one now selects the index of this sequence with the minimizer of the cross-validated risk of the loss function ).
The main idea of collaborative targeted MLE is that targeted maximum
likelihood estimators of ψ0 are deﬁned by an estimator Q∗
n of Q0, so that
a loss function (i.e.
empirical criterion) can be used to evaluate diﬀerent
targeted maximum likelihood estimators that only diﬀer in diﬀerent degrees
of targeted bias reduction. In this manner we can ﬁne tune the bias reduction.
For example, this adaptive selection guarantees that the targeted maximum
likelihood step (i.e., the choice of gj) is actually improving the ﬁt of Q∗
van der Laan: Targeted ML Causal Inference: Part II
the loss function, thereby dealing with the possible problem that the choice of
gj actually deteriorates the estimator relative to the initial estimator.
This selection approach for selection among candidate estimators gj is not
only theoretically grounded by oracle properties of the cross-validation selector,
but also by the collaborative double robustness of the eﬃcient inﬂuence curve
as proved in van der Laan and Gruber .
This collaborative double
robustness shows that the bias reduction for ψ0 is achieved by an estimator gn
that correctly adjusts for the covariates that are still helpful in improving the
ﬁt of Qn (i.e., the covariates that deal with the residual bias taking into account
the initial estimator), but that covariates that are not needed to remove bias
w.r.t. ψ0 can be ignored. The ﬁne-tuning of the bias reduction of the targeted
maximum likelihood estimator through the collaborative targeted maximum
likelihood estimator can, and typically should, be applied to further improve
the ﬁnite sample mean squared error of the resulting estimator of ψ0.