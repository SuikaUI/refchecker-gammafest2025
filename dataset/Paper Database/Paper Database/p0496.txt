IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. , NO. , JULY 2017
Driving Style Analysis Using Primitive Driving
Patterns With Bayesian Nonparametric
Approaches
Wenshuo Wang, Student Member, IEEE, Junqiang Xi, and Ding Zhao
Abstract—Analysis and recognition of driving styles are profoundly important to intelligent transportation and vehicle calibration. This paper presents a novel driving style analysis
framework using the primitive driving patterns learned from
naturalistic driving data. In order to achieve this, ﬁrst, a Bayesian
nonparametric learning method based on a hidden semi-Markov
model (HSMM) is introduced to extract primitive driving patterns from time series driving data without prior knowledge of
the number of these patterns. In the Bayesian nonparametric approach, we utilize a hierarchical Dirichlet process (HDP) instead
of learning the unknown number of smooth dynamical modes
of HSMM, thus generating the primitive driving patterns. Each
primitive pattern is clustered and then labeled using behavioral
semantics according to drivers’ physical and psychological perception thresholds. For each driver, 75 primitive driving patterns
in car-following scenarios are learned and semantically labeled. In
order to show the HDP-HSMM’s utility to learn primitive driving
patterns, other two Bayesian nonparametric approaches, HDP-
HMM and sticky HDP-HMM, are compared. The naturalistic
driving data of 18 drivers were collected from the University of
Michigan Safety Pilot Model Deployment (SPDM) database. The
individual driving styles are discussed according to distribution
characteristics of the learned primitive driving patterns and also
the difference in driving styles among drivers are evaluated
using the Kullback-Leibler divergence. The experiment results
demonstrate that the proposed primitive pattern-based method
can allow one to semantically understand driver behaviors and
driving styles.
Index Terms—Driving style, hidden Markov model, carfollowing behavior, Bayesian nonparametric approach, behavioral semantics.
I. INTRODUCTION
RIVING style has great impact on eco-driving , road
safety , and intelligent vehicles . Driving style,
in this paper, refers to a set of dynamic activities/steps that
a driver uses when driving, according to his/her personal
judgment, experience and skills , . Lots of previous
research has focused on characterizing and analyzing driving
styles. Most of them directly utilized the statistical metrics
of measured driving data to feature driving styles. For example, the means, standard deviations, and maximums of
This work was supported by The China Scholarship Council (CSC).
(Corresponding Author: Junqiang Xi and Ding Zhao)
W. Wang is with the Department of Mechanical Engineering, Beijing
Institute of Technology, Beijing, China, 100081, and also with Department
of Mechanical Engineering, University of California, Berkeley, Berkeley, CA,
94720, USA. e-mail: 
D. Zhao is with the Department of Mechanical Engineering, University of
Michigan, Ann Arbor, MI, 48109, USA. e-mail: 
J. Xi is with the Department of Mechanical Engineering, Beijing Institute
of Technology, Beijing, China, 100081. e-mail: 
brake pressure and throttle position were used to classify
drivers into mild, moderate, and aggressive types in – .
Vaitkus, et al. selected the mean, median, and standard
deviation of longitudinal and lateral acceleration to describe
driving styles. This kind of the above-mentioned approaches
is easy to capture the static driving habits from a statistical
perspective, but could not describe the dynamic process of
drivers’ behavioral semantics or decision making.
Decomposing complex driver behaviors into simple, smaller
and primitive patterns can facilitate identiﬁcation and analysis
of driving styles . Primitive driving pattern, as generally
deﬁned in this paper, is the primitive segments that can be
viewed as the basic composition of driver behaviors. For example, drivers’ car-following behaviors can be roughly segmented
into three primitive patterns, i.e., closing in, keeping, and
falling behind. Driving behavior segmentation enables long
sequences of observed driver behavior data to be segmented
into smaller components, to formulate and gain insight into
the driver’s dynamic decision-making process , and
driving style . Driving pattern deﬁnition is related to how
driving patterns are characterized, allowing a human or algorithmic observer to identify driving patterns from measured
data. These deﬁnitions are often subjective, application-driven,
algorithmic-dependent, and tend to group into three categories:
1) Physical Boundaries: The deﬁnition of a pattern typically refers to a physical change that occurs when a driver’s operation/decision starts or ends. These natural physical boundaries can be speciﬁed by changes of vehicle steering angle,
brake/accelerator pedal position or their combination .
These domain knowledge characteristics may be speciﬁc to
a particular operation (e.g., turn left or turn right) or could
generalize multiple operations (e.g., acceleration and lane
change). For example, MacAdam, et al. manually classiﬁed car-following behavior into ﬁve patterns (i.e., closing
in rapidly, close in, following, falling behind, and falling
behind rapidly) based on the predeﬁned thresholds of relative
speed and relative distance, and then trained a neural network
classiﬁer to evaluate drivers’ driving styles. Researchers also
segmented lane-changing behavior into two patterns (i.e.,
longitudinal control pattern and lateral control pattern), three
patterns (i.e., if, when, and how to perform lane change
maneuvers), and ﬁve patterns depending on vehicle
position in the lane as well as with respect to surrounding
vehicles. In general, the physical boundaries are empirically
set according to suit requirements, which are more subjective.
 
IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. , NO. , JULY 2017
. . . . . . . . . . .
. . . . . . . . . . .
. . . . . . . . . . .
. . . . . . . . . . .
. . . . . . . . . . .
Multiple driving
behavior data
Learned segmentations
or primitives
Labeling primitive
Driving style
Fig. 1. The proposed framework to analyze driving styles based on driving
primitive patterns.
2) Template Boundaries: Driving pattern can be deﬁned by
a user-provided template. One of the most popular templatebased algorithms is the dynamic time warping, for example,
applied to car-following behavior analysis . Deﬁning a
primitive pattern by a template or a set of template allows
maximizing ﬂexibility for users depending on special requirements. However, this approach is usually time-consuming
for preparing the templates and may miss some special and
meaningful templates.
3) Derived Metrics Boundaries: A primitive pattern can
also be deﬁned by a change in metrics (e.g., variance) or
derived signals (e.g., hidden Markov model state transitions)
based on supervised and unsupervised approaches. For example, Ma and Andreasson directly implemented a consolidated fuzzy clustering algorithm to classify different carfollowing regimes and then deﬁned ﬁve car-following patterns,
i.e., acceleration, stable following, braking, approaching, and
opening. Higgs and Abbas developed a two-step algorithm to segment drivers’ car-following behaviors based on
eight predeﬁned state-action variables (longitudinal acceleration, lateral acceleration, yaw rate, vehicle speed, lane offset,
yaw angle, range, and range rate). After that, the method
in resulted in 30 state-action clusters corresponding to
driving patterns. These aforementioned approaches, however,
require prior knowledge about the number of patterns or
Differing from previous research selecting the statistical
features (e.g., mean and standard deviations) of the measured
driving data and/or manually deﬁning the number of patterns
to characterize driving styles, in this paper, we proposed a
learning-based framework (Fig. 1) for driving style analysis
based on primitive driving patterns. The primitive driving pattern can reﬂect not only drivers’ driving preferences but also
the dynamic process of behavioral semantics and decisionmaking. In our approach, rather than subjectively relying on
hand-tuned models or predeﬁned rules to select primitive drivx1
(a) Hidden Markov model
t2 = d1 + 1
2 = d1 + d2
(b) Hidden semi-Markov model
A graphical model of HMM and HSMM. Shaded nodes are the
observable states and unshaded nodes are the latent modes.
ing patterns like in , , , we introduced a Bayesian
nonparametric approach to directly learn primitive driving
patterns from time series driving data without requiring prior
knowledge about the number of primitive patterns. For this
purpose, a hierarchical modeling structure is used to learn the
number of primitive driving patterns based on a hierarchical
Dirichlet process (HDP) and a hidden semi-Markov model
(HSMM). The primitive driving patterns are then labeled
semantically for each driver according to drivers’ physical and
psychological perception thresholds with a K-mean clustering
method. Finally, we use the distribution of primitive patterns
to semantically analyze individual’s driving styles and also use
entropy index to illustrate the differences among drivers.
The remainder of this paper is organized as follows. Section
II introduces the Bayesian nonparametric approach based on
a hidden Markov model (HMM) and its extensions. Section
III presents driving data collection and preprocessing. Section
IV shows the experimental results of primitive driving patterns
using different approaches. Section V analyzes the results of
driving styles. Lastly, the conclusions are made in Section VI.
II. BAYESIAN NONPARAMETRIC LEARNING APPROACHES
BASED ON HMM
Bayesian nonparametric learning methods have shown their
powerful ability to model and predict driver behaviors –
 in the case where the number of primitive driving patterns
is not exactly known. In this section, we illustrate a Bayesian
nonparametric approach for learning driving patterns, i.e.,
HDP-HSMM. In order to understand this approach easily, we
ﬁrst show and discuss some basic concepts, including HMM,
HSMM, HDP, HDP-HMM, and sticky HDP-HMM.
A. HMM-Based Approaches
1) Hidden Markov Model: In this work, we view the
dynamic process of primitive driving patterns in driving behaviors as a Markov process. Thus, driver behaviors can be
IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. , NO. , JULY 2017
(a) HDP-HMM
(b) sticky HDP-HMM
(c) HDP-HSMM
Fig. 3. Graphical models of three Bayesian nonparametric HMM-based approaches for an univariate time series data with a length T.
modeled based on the structure of HMM. The core of HMM
consists of two layers: a layer of hidden state and a layer
of observation or emission, as shown in Fig. 2(a), where the
shaded nodes are observations, yt, and the unshaded nodes are
latent states xt, i.e., primitive driving patterns in this work. The
hidden state sequence, x = {xt}T
t=1, is a sequence of primitive
driving patterns over a ﬁnite set X, i.e., xt ∈X. The transition
probability from primitive driving patterns i to j is noted as
πi,j = p(xt+1 = j|xt = i) and the transition matrix between
these patterns is π = {πi,j}|X|
i,j=1, where |X| indicates the size
of pattern set X. The distribution of observations or emissions
yt given current hidden states is deﬁned by p(yt|xt, θi), where
θi is the emission parameter for mode i. Thus, we can describe
xt|xt−1 ∼πxt−1
yt|xt ∼F(θxt)
where F(·) is an indexed family of distribution.
2) Hidden Semi-Markov Model: The hidden semi-Markov
model (HSMM), as an extension of HMM, is traditionally
deﬁned by allowing the underlying process to be a semi-
Markov chain, which means that each state has a variable
duration , as shown in Fig. 2(b). Several approaches can
be used to deﬁne HSMM depending on the assumptions and
applications. In this paper, we assume that each hidden state’s
duration is given over an explicit distribution, also called
explicit duration HMM . Therefore, as deﬁned in ,
we augment the generative process of a standard HMM with
a random state duration time, drawn from some state-speciﬁc
distribution when the state is entered. Here, we use the random
variable dt to denote the duration of a state that enters at time
t, and p(dt|xt = i) denotes the probability mass function for
dt. Similar to HMM, we can deﬁne HSMM by
xs|xs−1 ∼πxs−1
yt|xs, ds ∼F(θxs, ds)
where g(ωs) is a state-speciﬁc distribution over state duration
3) Hierarchical Dirichlet Process: As aforementioned in
Section I, we assume that the number of latent dynamic modes
or patterns in (1) and (2) is priorly unknown and these modes
of HMM and HSMM are subject to a speciﬁc distribution
deﬁned over a measure space.
The Dirichlet process (DP) is a measure on measures ,
denoted by DP(γ, H), and provides a distribution over discrete
probability measures with an inﬁnite collection of atoms 
νi ∼Beta(1, γ)
on a parameter space Θ that is endowed with a base measure
H. Here, the weights βi are sampled by a stick-breaking
construction and we denote β ∼GEM(γ), with β =
[β1, β2, · · · ].
According to the above discussion, a HDP is able to be
used to deﬁne a prior on the set of HMM transition probability
measures Gj
where δθ is a mass concentrated at θ. Assuming that each
discrete measure Gj is a variation on a global discrete measure
G0, thus the Bayesian hierarchical speciﬁcation takes Gj ∼
DP(α, G0), where G0 draws from a DP(γ, H), i,e.,
β|γ ∼GEM(γ)
πj|α, β ∼DP(α, β)
where πj = [πj1, πj2, · · · ].
IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. , NO. , JULY 2017
PARAMETER VALUES FOR MODELS
description
α gamma prior
γ gamma prior
κ gamma prior
IW prior degree of freedom
IW prior scale
4) Sticky HDP-HMM and HDP-HSMM: Based on the
above discussion, by applying the HDP prior to the HMM
and HSMM, we can obtain the HDP-HMM, sticky HDP-HMM
 , and HDP-HSMM , as shown in Fig. 3.
For the sticky HDP-HMM(γ, α, H), by adding an extra
parameter κ > 0 that biases the process toward self-transition
in (5b), increasing the expected probability of self-transition
by an amount proportional to κ , we can obtain
β|γ ∼GEM(γ)
πi|α, β, κ ∼DP(α + κ, αβ + κδi
), i = 1, 2, · · ·
xt|xt−1 ∼πxt−1, t = 1, 2, · · · , T
yt|xt, θxt ∼F(θxt), t = 1, 2, · · · , T
θi|H ∼H, i = 1, 2, · · · .
where T is the data length. Note that when κ = 0 in (6b), the
original HDP-HMM is obtained.
Similarly, for the HDP-HSMM(γ, α, H, G), we can describe
it using 
β|γ ∼GEM(γ)
πi|α, β ∼DP(α, β),
i = 1, 2, · · ·
(θi, ωi) ∼H × G,
i = 1, 2, · · ·
zs ∼¯πzs−1,
s = 1, 2, · · ·
ds ∼g(ωzs),
s = 1, 2, · · ·
xt1s:tds+1
yt1s:tds+1
where ¯π =
1−πii (1 −δij) is used to estimate self-transition
in the state sequence zs.
B. Observation (or Emission) Model
The observation model is determined by the type of function
F(θi), which can be Gaussian emissions or switch linear
dynamic models (SLDSs) (e.g., vector autoregressive).
One main challenge with non-parametric approaches is that
one must derive all the necessary expressions to properly
perform inference . Here, in order to make our algorithm
tractable, we assume that observations are drawn from a
Gaussian distribution like in . When observations are
assumed to be drawn from a Gaussian distribution, the θi
can be set as θi = [µi, Σi]. Therefore, if the priors for
observations and transition distributions are learned correctly,
the full-conditional posteriors can be computed using Gibbs
sampling method. Johnson and Willsky present further
details of the inference method using Gibbs sampling methods.
Fig. 4. Example of equipment for data collection. (a) Vehicle; (b) Mobileye;
and (c) Data acquisition systems.
C. Learning Procedure
We develop and test the developed models based on Johnson
and Willsky’s pyhsmm1 module and Fox’s code 2 . In
this work, the hyperparameters are determined using following
1) We place a Gamma(a, b) prior on the hyperparameters
γ, α, and κ , , as shown in Table I, where N is
the dimension of input data.
2) The Inverse-Wishart (IW) prior is conjugate to the Gaussian distributions and SLDS parameter set , thus
the hyperparameters for θi are taken to be from an IW
with a hyper-parameter γ, that is,
Σi|n0, S0 ∼IW(n0, S0)
where n0 is IW prior degree of freedom, S0 is the IW
prior scale, and S0 = 0.75¯Σ, where ¯Σ is the covariance
of the observed data.
In this work, the observation variables are generated from a
Gaussian model and we set µi = 0 according to .
III. CAR-FOLLOWING DATA COLLECTION AND
PREPROCESSING
In this work, we apply the developed methods to analyze
driving styles regarding car-following behaviors. The driving
scenarios and data collection and processing are presented as
A. Equipment and Participants
All driving data we used were extracted from the Safety
Pilot Model Deployment (SPMD) database, which recorded
the naturalistic driving of 2,842 equipment vehicles in Ann
Arbor, Michigan, for more than two years. We used 18
equipped vehicles (i.e., 18 drivers) to run experiments and
collected on-road data. The experiment vehicles were equipped
with data acquisition systems and Mobieye, as shown in Fig.
1 
2 
IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. , NO. , JULY 2017
Driving direction
∆d = x2 −x1
∆v = v2 −v1
Subject vehicle
Lead vehicle
Fig. 5. Car-following scenarios
Fig. 6. Trajectories of all car-following events.
4. The road information (e.g., lane width, lane curvature) and
the surrounding vehicle’s information (e.g., relative distance,
relative speed) were recorded by Mobileye. The subject vehicle
information such as speed, steering angle, acceleration/brake
pedal position were extracted from CAN-bus signal. All of the
data were recorded at 10 Hz.
Drivers had an opportunity to become accustomed to the
equipped vehicles. They performed casual daily trips for
several months without any restrictions on or requirements for
their trips, the duration of the trips, or their driving style. The
data processing and recording equipment were hidden from
the drivers, thus avoiding the inﬂuence of recorded data on
driver behavior.
B. Data Extraction and Preprocessing
In order to extract car-following events (Fig. 5) from the
SPMD database and capture drivers’ dynamic preference when
driving as demonstrated in , we selected the following
variables:
1) The subject vehicle acceleration ax, which can directly
reﬂect driver’s intents and driving preference.
2) The relative range between subject and lead vehicles
∆d, which is computed by ∆d = x2 −x1. It can reﬂect
driver’s preference in headway, where x1 and x2 are
the global positions of subject vehicle and lead vehicle,
respectively.
3) The relative range rate ∆v which is computed by
∆v = v2 −v1. It can capture the dynamical relationship
between two vehicles, where v1 and v2 are the velocities
of subject vehicle and lead vehicle, respectively.
Then, the car-following data consisting of the three feature
variables were extracted from the SPMD database under the
VARIABLE SEGMENTATION
Variable state
Long distance (LD)
Normal distance (ND)
[27.32, 57.33]
Close distance (CD)
[5.00, 27.32]
Range rate [m/s]
Rapidly closing in (RCI)
Closing in (CI)
[-1.17, -0.21]
Keeping (KE)
[-0.21, 0.33]
Falling behind (FB)
[0.33, 1.29]
Rapidly falling behind (RFB)
Acceleration [m/s2]
Aggressive acceleration (AA)
Gentle acceleration (GA)
[0.06, 0.23]
No acceleration (NA)
[-0.07, 0.06]
Gentle deceleration (GD)
[-0.24, -0.07]
Aggressive deceleration (AD)
following conditions: (1) There was a lead vehicle at the same
lane with the subject vehicle; (2) the lead distance was less
than 120 m; (3) the vehicle speed was large than 18 km/h (i.e.,
5 m/s); (4) if a surrounding vehicle was cutting in, then the
car-following event ended; (5) the duration of each single carfollowing event was larger than 50 s . Fig. 6 presents the
trajectories of all car-following events in the SPMD database.
When training a model, in order to reduce the scale in-
ﬂuence of different variables on the segmentation results, we
additionally normalized each variable of observation vector for
each event so that the empirical variance of the set was equal
, l = 1, 2, · · · , L, m = 1, 2, · · · , M
where x = [∆d, ∆v, ax]⊤, l is the number of event, µm and
σm are the mean and covariance of all events for mth driver,
with M = 18. Then we applied the Bayesian nonparametric
learning approaches presented in Section II to segment the
normalized time series data, thus obtaining the regimes among
primitive driving patterns.
C. Variable Segmentation and Threshold Selection
In order to easily make a semantic explanation for primitive driving patterns, we classify each variable into different
levels based on drivers’ physical and psychological perception
thresholds corresponding to their statistical feature, as shown
in Table II. More speciﬁcally, we ﬁt them using different
distributions to determine the threshold of each variable from
the statistical perspective.
Fig. 7(a) shows the ﬁtting results of the relative range (∆d),
relative range rate (∆v), and subject vehicle acceleration (a1)
using four distributions, including normal distribution (N),
Beta distribution (B), Student-t distribution (t), and Gamma
distribution (Γ) . We can see that: 1) for range rate and
acceleration, the t-distribution achieves a better ﬁtting performance than other three distributions, and 2) for the range,
the Γ-distribution and the B-distribution obtain a better ﬁtting
performance than other two distributions. Based on perceptible
characteristics of variables and driver’s comfortable thresholds,
we select the percentile value of range with the Γ-ﬁtting
IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. , NO. , JULY 2017
Range ∆d[m]
Normalized PDF
Median = (27.211, 0.022)
Range rate ∆v[m/s]
Normalized PDF
Acceleration ax[m/s2]
Normalized PDF
Percentile values
Range ∆d[m]
(0.30, 27.32)
(0.80, 57.33)
Percentile values
Range rate ∆v[m/s]
(0.15, -1.17)
(0.40, -0.21) (0.60, 0.33)
(0.85, 1.29)
Percentile values
Acceleration ax[m/s2]
(0.20, -0.24) (0.40, -0.07) (0.60, 0.06) (0.80, 0.23)
Fig. 7. (a) The statistical ﬁtting results and (b) threshold values of three variables. Four approaches are used to ﬁt the data, i.e., Normal (N) distribution,
Beta (B) distribution, Student-t (t) distribution, and Gamma (Γ) distribution.
results, and select the percentile values of range rate and
acceleration with the t-ﬁtting results, as illustrated in Fig. 7(b).
The selection procedure is discussed as follows:
• Relative range (∆d): Relative range is divided into three
levels: long distance (LD), normal distance (ND), and
close distance (CD). Note that from the top plot of Fig.
7(a), the lower threshold of 27.32 m matches the median
value 27.21 m and the upper threshold of 57.33 m is close
to the threshold 61 m which is usually used to distinguish
the free-ﬂow regime . Therefore, the threshold 30 and
85 percentile values of headway distance are selected,
corresponding to 27.32 m and 57.33 m, respectively .
• Relative range rate (∆v): From , we know that
difference
perception
|∆vthr| ∈[0.05, 0.2] m/s. Therefore, it is conservative
enough to assume that human driver hardly feel the
change of range rate when |∆v| < 0.2 m/s. From ,
we also know that driver can distinctly feel the change of
range rate when |∆v| > 1.3 m/s. Therefore, the thresholds
are selected the percentile values of 15, 40, 60, and 85
for range rate, corresponding to range rate values of -1.17
m/s, -0.21 m/s, 0.33 m/s, and 1.29 m/s, respectively, as
shown in Table II and the middle plot of Fig. 7(b). Thus,
the range rate is divided into ﬁve segments, similar to
 : rapidly closing in (RCI), closing in (CI), keeping
(KE), falling behind (FB), and rapidly falling behind
• Acceleration (ax): Acceleration is divided into ﬁve levels
based on drivers’ vestibular and kinesthetic thresholds
x | ≈0.05 m/s2 and longitudinal acceleration
comfort threshold |athr
x | ≈0.2 m/s2 . In this work, we
use the percentile values of 20, 40, 60, and 80 for acceleration as the thresholds, with -0.24 m/s2, -0.07 m/s2,
0.06 m/s2, and 0.23 m/s2, which quantitatively match
the kinesthetic perception and comfort thresholds. Thus,
the acceleration is segmented into aggressive acceleration
(AA), gentle acceleration (GA), no acceleration (NA),
gentle deceleration (GD), and aggressive deceleration
(AD), as shown in Fig. 7(b) and Table II.
Based on the aforementioned levels of each feature variable,
we can obtain 75 different primitive car-following patterns
(3 × 5 × 5 = 75) by combining the level of each feature
variable (i.e., range, range rate, and acceleration) in Table II.
This allows us to label the primitive pattern of time series
driving data in semantics, allowing one to analyze driving style
and dynamic mode characteristics from a different perspective.
IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. , NO. , JULY 2017
Iteration steps
log-likelihood
sticky HDP-HMM
predictive log-likelihood
sticky HDP-HMM
The log-likelihood of modeling the training data (left) and the
predictive log-likelihood of test data (right) for all three methods.
IV. MODEL EVALUATION AND RESULT ANALYSIS
In this section, the method utility for car-following behaviors and the learning results of the primitive driving patterns
are discussed and analyzed.
A. Method Performance Evaluation
1) Evaluation Method: One standard approach to evaluate the model performance is using the leave-one-out crossvalidation (LOO-CV) method with splitting data into training set and and test set. However, the ground truth of the
segmentation results for test dataset is difﬁcult to obtain
because we assume that the number and type of primitive
driving patterns are unknown, thus we can not directly evaluate
the learned model performance by comparing the learning
results to the ground truth. Instead, we evaluate the utility of
the developed approaches to segment different car-following
driving data sequences into primitive driving patterns based on
the ability of the learned models to predict the duration of each
primitive driving pattern for the test data. Similar to , the
predictive log-likelihood is employed to evaluate the ﬁdelity
of the learned models. For each driver and corresponding test
datasets, we apply the training data to learn parameters of all
three models, and then the learned models are used to predict
the probability distribution of durations for each primitive
driving pattern at each frame of the test data. The probability
distribution of durations of primitive driving patterns is used to
compute the predictive log-likelihood by following . For
each driver, the driving data are randomly and evenly grouped
into ten folds. Nine folds are used for model training and the
remaining one fold is used for model test. Thus we can ﬁnally
obtain ten cross-validation results for each driver. During the
training and testing procedures, the normalized car-following
on-road data, ¯x, are used to learn the three model parameters
and test these models.
2) Results: Fig. 8 shows the log-likelihood of modeling the
training data and the predictive log-likelihoods of the test data
with the LOO-CV procedure, given the training data for all
three methods. Experiment results show that the HDP-HSMM
obtains the largest log-likelihood of ﬁtting training data (Fig. 8,
left) and the largest predictive log-likelihood of test data (Fig.
8, right), indicating that the HDP-HSMM outperforms HDP-
HMM for segmenting drivers’ car-following data sequences.
Note that the HDP-HSMM only obtain a slightly higher loglikelihood value and lower stand deviations, compared to the
sticky HDP-HMM.
B. Segmentation Results and Comparisons
Here, for clarity and conciseness, we only show the results
from representative trails of driver #0. An example of segmentation results using the three approaches is shown in Fig. 9.
In order to demonstrate the advantages of HDP-HSMM, we
make a further discussion and analysis as follows.
From the top plot in Fig. 9, it can be noticed that the HDP-
HMM could not segment the driving patterns as expected. For
example, the driving data ranging from 0 s to 20 s obviously
include the positive and negtive values of range rate and
acceleration (i.e., the driver #0, at least, presents the closing
in and falling behind patterns), but the HDP-HMM does treat
the behaviors as one primitive pattern, instead of obtaining the
expected segmentations to capture the underlying patterns.
Regarding sticky HDP-HMM (Fig. 9, middle), it can segment driving data into different primitive patterns, but being
sensitive to data ﬂuctuation. For example, such patterns with
very short time duration occur frequently (e.g., a pattern only
keeps about 0.2 s starting at 8.4 s), which is not expected for
drivers’ driving states. The sticky HDP-HMM results in many
such patterns whose duration is less than 1.0 s, for example,
durations are 0.2 s, 0.8 s, 0.1 s, 0.7 s, 0.3 s, 0.6 s at time
8.6 s, 32.2 s, 55.9 s, 58.8 s, 64.3 s and 64.7 s, respectively.
In real driving cases, human drivers obviously do not adjust
their driving modes or primitive driving patterns with a high
frequency such as only keeping acceleration 0.2 s and
then taking deceleration in normal driving.
Table III presents the statistical results of the durations of
primitive driving patterns for all driving data using the three
approaches. We found that the HDP-HSMM obtains a similar
amount of the primitive driving patterns with the sticky HDP-
HMM approach, as highlighted in orange. In addition, the
HDP-HSMM approach obtains the lowest percentage (with
0.0065) of primitive driving pattern whose duration is less than
1.0 s, compared to HDP-HMM with percentage of 0.0216 and
sticky HDP-HMM with percentage of 0.0441, as shaded with
gray. It indicates that the HDP-HSMM method can segment
time series driving data into several segments and hold the
primitive driving patterns to be an expectable duration. Therefore, in the following section, driving styles will be analyzed
and evaluated based on results of HDP-HSMM.
Fig. 10 presents the statistical results including means
and standard deviations of pattern durations using the three
approaches. We can see that most driving primitive patterns
are approximately falling in 3.93 s - 7.81 s with HDP-HSMM
and in 3.30 s - 7.64 s with sticky HDP-HMM. However, the
HDP-HMM obtains a higher primitive pattern duration with
7.94 s on average, compared to the other two approaches with
5.47 s and 5.87 s on average. According to the segmentation
results using HDP-HSMM and sticky HDP-HMM, therefore,
we can conclude that human drivers usually keep a speciﬁc
IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. , NO. , JULY 2017
ax[⇥10m/s2]
ax[⇥10m/s2]
ax[⇥10m/s2]
Fig. 9. Example of experiment results of one event for driver #0 using three different methods: HDP-HMM (top) with 9 patterns, sticky HDP-HMM (middle)
with 17 patterns, and HDP-HSMM (bottom) with 14 patterns.
STATISTICAL RESULTS OF DURATIONS OF PRIMITIVE DRIVING PATTERNS USING THREE METHODS FOR ALL DRIVING DATA
Total Number
Duration of primitive driving pattern (s)
[1.0, 5.0)
[5.0, 10.0)
[10.0, 15.0)
[15.0, 20.0)
[20.0, 25.0)
[25.0, 30.0)
sticky HDP-HMM
Pattern duration (s)
sticky HDP-HMM
Fig. 10. Statistical results of primitive driving pattern durations.
following mode about 3.50 s - 10.0 s when following a lead
vehicle. In addition, note that drivers sometimes can stay in
speciﬁc but rare primitive driving patterns with durations of
more than 20.0 s when following a car.
Fig. 11 shows the scattering results of primitive segments
using all three methods. We can know that the HDP-HSMM
(Fig. 11, bottom) can segment time series data into a set
of reasonable patterns with lower frequency of switching
between driving states, compared to other two approaches. For
example, in the region A of Fig. 11, the HDP-HMM can not
recognize the underlying patterns. In addition, the sticky HDP-
HMM method is able to characterize the latent patterns, but
it generates patterns with a high changing frequency between
patterns and short time durations, which is not consistent with
that in the real driving case .
C. Labeling Behavioral Semantics
Based on the results of the learned primitive driving patterns
using HDP-HSMM, drivers’ car-following behaviors can be
described by behavioral semantics deﬁned as in Table II.
Here, in order to capture the dynamic process of behavior, we
describe each primitive driving pattern in car-following data
sequence using the following interpretation:
The driver is S∆v the lead vehicle by Sax in a S∆d
S∆v ∈{RCI, CI, KE, FB, RFB};
Sax ∈{AA, GA, NA, GD, AD};
S∆d ∈{LD, ND, CD}.
For example, regarding the region B of bottom plot in Fig.
11, the relative range rate ∆v > 1.0 m/s (i.e., {S∆v = RFB}),
the range ∆d ∈ m (i.e., S∆d = ND), and the absolute
values of the acceleration mostly fall in [0.05, 0.24] (i.e.,
Sax = GA or Sax = GD). Therefore, we can describe the
driving behavior data in region B as “The driver is rapidly
falling behind the lead vehicle by gentile accelerating or
decelerating in a normal distance.” Similarly, the driving
behavior in region C can be described as “The driver is rapidly
falling behind the lead vehicle by gentile accelerating in a
IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. , NO. , JULY 2017
Range ∆d[m]
Range rate ∆v[m/s]
32 10 1 2 3 4
Acceleration ax[m/s2]
35 40 45 50 55 60 65 70 75
Range ∆d[m]
Range rate ∆v[m/s]
Range rate ∆v[m/s]
Acceleration ax[m/s2]
35 40 45 50 55 60 65 70 75
Range ∆d[m]
Acceleration ax[m/s2]
(a) HDP-HMM
Range ∆d[m]
Range rate ∆v[m/s]
32 10 1 2 3 4
Acceleration ax[m/s2]
35 40 45 50 55 60 65 70 75
Range ∆d[m]
Range rate ∆v[m/s]
Range rate ∆v[m/s]
Acceleration ax[m/s2]
35 40 45 50 55 60 65 70 75
Range ∆d[m]
Acceleration ax[m/s2]
(b) sticky HDP-HMM
Range ∆d[m]
Range rate ∆v[m/s]
32 10 1 2 3 4
Acceleration ax[m/s2]
35 40 45 50 55 60 65 70 75
Range ∆d[m]
Range rate ∆v[m/s]
Range rate ∆v[m/s]
Acceleration ax[m/s2]
35 40 45 50 55 60 65 70 75
Range ∆d[m]
Acceleration ax[m/s2]
(c) HDP-HSMM
Fig. 11. Segment results with one event for driver #0 using three methods.
Range ∆d[m]
Range rate ∆v[m/s]
2 1 0 1 2 3
Acceleration ax[m/s2]
35 40 45 50 55 60 65 70 75
Range ∆d[m]
Range rate ∆v[m/s]
Range rate ∆v[m/s]
Acceleration ax[m/s2]
35 40 45 50 55 60 65 70 75
Range ∆d[m]
Acceleration ax[m/s2]
Fig. 12. Example of clustering results for driver #0 using K-means clustering
method based on the HDP-HSMM with K = 1, where KE-AD-LD represents
“keeping (KE) distance by aggressive deceleration (AD) in a long distance
long distance.” In the following section, to be simple, we use
a primitive pattern sequence to represent drivers’ behavioral
semantics such as [S∆v, Sax, S∆d].
Based on the learned results, some primitive driving patterns are easy to be labeled with semantic elements, but
some are not. In order to make patterns be easier labeled
and ﬁnd the commons in primitive patterns of car-following
behaviors, we cluster the driving data of each segment into
a point to represent this primitive driving pattern. The Kmeans clustering method is applied in this work because it
has been widely used to label driving patterns , , 
and shown its advantages. The clustering results allow us to
tractably translate each primitive driving pattern in semantics.
For example, Fig. 12 presents a clustering result for driver #0
based on the segmentation results of HDP-HSMM. According
to Table II, the pink point can be semantically interpreted as
[KE, AD, LD], that is, “The driver is keeping distance with the
lead vehicle by aggressive deceleration in a long distance.”,
corresponding to the pink points in the bottom plot of Fig. 11.
V. DRIVING STYLE ANALYSIS BASED ON PRIMITIVE
DRIVING PATTERNS
Understanding drivers’ behavioral semantics is able to facilitate and help driving style analysis. According to the above
discussion, we know that the HDP-HSMM provides a better
semantical way for analyzing drivers’ car-following behaviors.
Therefore, in what follows, we will discuss driving styles using
primitive driving patterns derived from HDP-HSMM.
A. Normalized Frequency Distribution of Driving Patterns
Instead of using the statistical metrics such as mean and
standard deviation, we utilize the normalized frequency distribution of primitive driving patterns to characterize driving
styles, which allows one to intuitively analyze driving habits.
IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. , NO. , JULY 2017
Close Distance
Normal Distance
Long Distance
(a) 76 events for driver #0
Close Distance
Normal Distance
Long Distance
(b) 92 events for driver #1
Close Distance
Normal Distance
Long Distance
(c) 96 events for driver #2
Close Distance
Normal Distance
Long Distance
(d) 111 events for driver #3
Fig. 13. Normalized frequency distributions of driving patterns for four drivers using the HDP-HSMM method. The dark red and dark blue indicate a higher
and lower probability of driving in this pattern, respectively. RCI = rapidly closing in, CI = closing in, KE = keeping, FB = falling behind, RFB = rapidly
falling behind, AA = aggressive acceleration, GA = gentle acceleration, NA = no acceleration, GD = gentle deceleration, AD = aggressive deceleration.
For each driver with L car-following events Xm = {x(l)
the normalized probability of each pattern is computed by
⋆= [S∆v, Sax],
where N (m)
⋆,∗is the number of occurrences for driving pattern
⋆in Xm based on the distance pattern ∗. Thus, we obtain the
normalized frequency distribution for each driver with three
distance patterns (i.e., close distance, normal distance, and
long distance). Each primitive driving pattern is clustered and
labeled according to Table II.
Fig. 13 shows examples of the normalized frequency distribution of primitive driving patterns for four drivers. Dark red
represents that the driver has a higher probability of acting
in this pattern and dark blue represents that the driver has
a lower probability (nearly equal to zero) of driving in this
pattern. For instance, when following a lead vehicle in a long
distance (Fig. 13, bottom), driver #0 (Fig. 13(a)) and driver
#1 (Fig. 13(b)) prefer to rapidly close in the lead vehicle by
no acceleration/deceleration, while driver #2 (Fig. 13(c)) and
driver #3 (Fig. 13(d)) prefer falling behind by no acceleration/deceleration and gentle deceleration, respectively. When
following the lead vehicle in a close or normal distance, our
proposed approaches can also provide an intuitive explanation
for researchers.
Fig. 14. The schematic diagram of (a) driving style patterns and (b) pattern
index (i, j) for pattern [Sax, S∆v].
In order to show which primitive pattern drivers much
prefer, we assign an unique index value to each primitive
driving pattern in car-following, as shown in Fig. 14. Acceleration and range rate with ﬁve levels are both labeled using
integers ranging from -2 to 2. A larger absolute value of the
index indicates a more aggressive driving style, represented
by dark red; conversely, a smaller absolute value of the index
represents a more gentle driving style, represented by dark
blue, as shown in Fig. 14(a). The pattern with the largest
normalized frequency probability in each distance pattern for
driver m is treated as the one this person prefers, represented
using its index i and j (Fig. 14(b)). For example, when
IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. , NO. , JULY 2017
DRIVER’S PREFERENCE IN DRIVING PRIMITIVE PATTERN (i, j) FOR ALL
PARTICIPANTS.
Driver No.
(1,2) or (0,-2)
following lead vehicles with a close distance, the primitive
driving pattern that driver #0 strongly prefers is [FB, AD],
denoted as the darkest red in the top plot of Fig. 13(a). Table
IV lists the index value (i, j) of the most preferring primitive
driving patterns for all drivers, where i and j represent the
levels of acceleration/deceleration and range rate, respectively.
According to Table IV, we can conclude:
• When following a lead vehicle in a close distance, most
drivers prefer falling behind or closing in (i.e., j = −1 or
1) the lead vehicle by taking an aggressive acceleration or
deceleration (i.e., i = −2 or 2), except driver #11 (blue
shade) who prefers to keep a constant headway distance
by no acceleration/deceleration. In addition, driver #4,
driver #6, and driver #17 (red shade) prefer to rapidly
fall behind (i.e., j = −2) the lead vehicle by accelerating
aggressively (i.e., i = −2).
• When following a lead vehicle with a normal distance,
most drivers prefer falling behind or closing in (i.e., j = 1
or 1) the lead vehicle by taking a gentle deceleration (i.e.,
i = 1), except driver #1, driver #4, and driver #17 (orange
shade) who prefer rapidly closing in the lead vehicle (i.e.,
j = −2) by taking an aggressive acceleration (i.e., i =
• When following a lead vehicle with a long distance,
most drivers prefer closing in (i.e., j = 1) with no
acceleration/deceleration (i.e., i = 0), except driver #0,
driver #2, driver #6, driver #12, and driver #15 noted
with light gray shade. For example, driver #12 prefers
falling behind by taking an aggressive deceleration.
Therefore, our proposed framework for driving styles analysis based on primitive driving patterns can semantically
analyze individual driving styles, instead of only using the
statistical metrics such as means and standard deviations.
B. Interdriver Differences in Driving Style
According to the above discussion, the normalized distribution of primitive driving pattern is able to describe and
Close distance
Normal distance
Long distance
KL divergence between two normalized distributions of primitive
driving patterns among all drivers.
analyze driving styles for individuals. In this section, we will
discuss the similarity or divergence in driving styles between
drivers. Differing previous research using statistical metrics
(e.g., mean and standard deviations) of driving data to capture
driver’s driver style, in this paper, we select the normalized
distribution of primitive driving pattern as the indicator. When
comparing the driving styles of two drivers, it is common
to assume a normal distribution for the indicators and to
compare their means and stand deviations . Here, we are
not restricted by the limitations of this assumption and we
compute the similarity of two drivers in driving styles using
the Kullback-Leibler (KL) divergence , between two
corresponding distributions to illustrate interdriver differences.
The KL divergence of the normalized distribution of primitive
driving patterns between drivers mi and mj is deﬁned as
KL(F (mi) ∥F (mj)) = −
where ⋆and ∗are deﬁned same as in (10). A larger value of KL
divergence indicates a big difference between two drivers. For
example, when mi = mj, meaning that the driver is compared
to him/herself, thus we have D(∗)
KL(F (mi) ∥F (mj)) = 0.
Fig. 15 presents the KL divergence of each pairs of drivers.
Dark red represents a great difference between two drivers and
dark blue indicates that drivers are strongly similar to each
other. From Fig. 15(a), we know that when driver follows a
lead vehicle at a close distance, driver #8 is different from
others, especially different from driver #12, i.e., the darkest
red square. According to Fig. 15(b), when following the lead
vehicle at a normal distance, driver #11 is strongly different
from others because there is a red vertical bar between driver
#11 and all other drivers. When following a long distance to
IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, VOL. , NO. , JULY 2017
the lead vehicle as shown in Fig. 15(c), driver #6, driver #11,
and driver #15 are strongly different from others. Therefore,
the KL divergence index can provide a ﬂexible way to illustrate
the similarity or divergence in driving styles between drivers
from a semantical perspective.
VI. CONCLUSION
This paper presents a new framework for driving style
analysis using primitive driving patterns with Bayesian nonparametric methods. First, a set of primitive driving patterns
are learned from normalized naturalistic driving data by assuming the number of primitive driving patterns is unknown.
To achieve this, a hierarchical structure (i.e., HDP-HSMM) is
developed by combining hierarchical Dirichlet process (HDP)
and hidden semi-Markov model (HSMM). We also compare
the HDP-HSMM method to other Bayesian nonparametric
methods such as HDP-HMM and sticky HDP-HMM, and
found that the proposed HDP-HSMM can learn a set of
expected primitive driving patterns in car-following behaviors.
To describe primitive driving pattern in semantics, this paper
divides each feature variable into different levels according
to drivers’ physical and psychological perception thresholds.
Instead of using a series of statistical results such mean and
standard deviation, we use the normalized frequency distribution of primitive driving patterns to analyze individual driving
style and also use the KL-divergence between distributions
to illustrate differences between drivers. Experimental results
demonstrate that the primitive driving pattern-based analysis
framework proposed in this paper provide an opportunity to
model and analyze driving styles semantically.