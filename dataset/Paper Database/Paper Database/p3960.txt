Ofﬂine Handwriting Recognition with
Multidimensional Recurrent Neural Networks
Alex Graves
TU Munich, Germany
 
J¨urgen Schmidhuber
IDSIA, Switzerland and TU Munich, Germany
 
Ofﬂine handwriting recognition—the transcription of images of handwritten
text—is an interesting task, in that it combines computer vision with sequence
learning. In most systems the two elements are handled separately, with sophisticated preprocessing techniques used to extract the image features and sequential
models such as HMMs used to provide the transcriptions. By combining two recent innovations in neural networks—multidimensional recurrent neural networks
and connectionist temporal classiﬁcation—this paper introduces a globally trained
ofﬂine handwriting recogniser that takes raw pixel data as input. Unlike competing
systems, it does not require any alphabet speciﬁc preprocessing, and can therefore
be used unchanged for any language. Evidence of its generality and power is provided by data from a recent international Arabic recognition competition, where it
outperformed all entries (91.4% accuracy compared to 87.2% for the competition
winner) despite the fact that neither author understands a word of Arabic.
Introduction
Ofﬂine handwriting recognition is generally observed to be harder than online handwriting recognition . In the online case, features can be extracted from both the pen trajectory and the resulting
image, whereas in the ofﬂine case only the image is available. Nonetheless, the standard recognition
process is essentially the same: a sequence of features are extracted from the data, then matched to a
sequence of labels (usually characters or sub character strokes) using either a hidden Markov model
(HMM) or an HMM-neural network hybrid .
The main drawback of this approach is that the input features must meet the stringent independence
assumptions imposed by HMMs (these assumptions are somewhat relaxed in the case of hybrid
systems, but long range input dependencies are still problematic). In practice this means the features
must be hand designed for every alphabet, and, to a lesser extent, for every language. For example
it would be impossible to use the same system to recognise both English and Arabic.
Following our recent success in transcribing raw online handwriting data with recurrent networks , we wanted to build an ofﬂine recognition system that would work on raw pixels. As
well as being alphabet independent, such a system would have the advantage of being globally
trainable, with the image features optimised along with the classiﬁer.
The online case was relatively straightforward, since the input data formed a 1D sequence that could
be fed directly to a recurrent network. The long short-term memory (LSTM) network architecture was chosen for its ability to access long range context, and the connectionist temporal
classiﬁcation output layer allowed the network to transcribe the data with no prior segmentation.
The ofﬂine case, however, is more challenging, since the input is no longer one dimensional. A
naive approach would be to present the images to the network one vertical line at a time, thereby
transforming them into 1D sequences. However such a system would be unable to handle distor-
Figure 1: Two dimensional MDRNN. The thick lines show connections to the current point (i, j).
The connections within the hidden layer plane are recurrent. The dashed lines show the scanning
strips along which previous points were visited, starting at the top left corner.
tions along the vertical axis; for example the same image shifted up by one pixel would appear
completely different. A more ﬂexible solution is offered by multidimensional recurrent neural networks (MDRNNs) . MDRNNs, which are a special case of directed acyclic graph networks ,
generalise standard RNNs by providing recurrent connections along all spatio-temporal dimensions
present in the data. These connections make MDRNNs robust to local distortions along any combination of input dimensions (e.g. image rotations and shears, which mix vertical and horizontal
displacements) and allow them to model multidimensional context in a ﬂexible way. We use multidimensional LSTM because it is able to access long range context.
The problem remains, though, of how to transform two dimensional images into one dimensional
label sequences. Our solution is to pass the data through a hierarchy of MDRNN layers, with
blocks of activations gathered together after each level. The heights of the blocks are chosen to
incrementally collapse the 2D images onto 1D sequences, which can then be labelled by the output
layer. Such hierarchical structures are common in computer vision , because they allow complex
features to be built up in stages. In particular our multilayered structure is similar to that used by
convolution networks , although it should be noted that because convolution networks are not
recurrent, they cannot be used for cursive handwriting recognition without presegmented inputs.
Our method is described in detail in Section 2, experimental results are given in Section 3, and
conclusions and directions for future work are given in Section 4.
The three components of our recognition system are: (1) multidimensional recurrent neural networks, and multidimensional LSTM in particular; (2) the connectionist temporal classiﬁcation output layer; and (3) the hierarchical structure. In what follows we describe each component in turn,
then show how they ﬁt together to form a complete system. For a more detailed description of (1)
and (2) we refer the reader to 
Multidimensional Recurrent Neural Networks
The basic idea of multidimensional recurrent neural networks (MDRNNs) is to replace the single
recurrent connection found in standard recurrent networks with as many connections as there are
spatio-temporal dimensions in the data. These connections allow the network to create a ﬂexible
internal representation of surrounding context, which is robust to localised distortions.
An MDRNN hidden layer scans through the input in 1D strips, storing its activations in a buffer. The
strips are ordered in such a way that at every point the layer has already visited the points one step
back along every dimension. The hidden activations at these previous points are fed to the current
point through recurrent connections, along with the input. The 2D case is illustrated in Fig. 1.
One such layer is sufﬁcient to give the network access to all context against the direction of scanning from the current point (e.g. to the top and left of (i, j) in Fig. 1). However we usually want
surrounding context in all directions. The same problem exists in 1D networks, where it is often
useful to have information about the future as well as the past. The canonical 1D solution is bidi-
rectional recurrent networks , where two separate hidden layers scan through the input forwards
and backwards. The generalisation of bidirectional networks to n dimensions requires 2n hidden
layers, starting in every corner of the n dimensional hypercube and scanning in opposite directions.
For example, a 2D network has four layers, one starting in the top left and scanning down and right,
one starting in the bottom left and scanning up and right, etc. All the hidden layers are connected to
a single output layer, which therefore receives information about all surrounding context.
The error gradient of an MDRNN can be calculated with an n-dimensional extension of backpropagation through time. As in the 1D case, the data is processed in the reverse order of the forward
pass, with each hidden layer receiving both the output derivatives and its own n ‘future’ derivatives
at every timestep.
j be respectively the input and activation of unit j at point p = (p1, . . . , pn) in an ndimensional input sequence x with dimensions (D1, . . . , Dn). Let p−
d = (p1, . . . , pd −1, . . . , pn)
d = (p1, . . . , pd + 1, . . . , pn). Let wij and wd
ij be respectively the weight of the feedforward
connection from unit i to unit j and the recurrent connection from i to j along dimension d. Let θh
be the activation function of hidden unit h, and for some unit j and some differentiable objective
function O let δp
j . Then the forward and backward equations for an n-dimensional MDRNN
with I input units, K output units, and H hidden summation units are as follows:
Forward Pass
Backward Pass
Multidimensional LSTM
Long Short-Term Memory (LSTM) is an RNN architecture designed for data with long range
interdependencies. An LSTM layer consists of recurrently connected ‘memory cells’. The activation
of each cell is controlled by three multiplicative gate units: the input gate, forget gate and output
gate. The gates allows the cells to store and retrieve information over long periods of time, giving
them access to long range context.
The standard formulation of LSTM is explicitly one dimensional, since each cell contains a single
self connection, whose activation is controlled by a single forget gate. However we can extend this
to n dimensions by using instead n self connections (one for each of the cell’s previous states along
every dimension) with n forget gates.
In what follows we give the forward and backward equations for an MDLSTM memory cell in a
hidden layer of H cells, connected to I input units and K output units. The subscripts c, ι, φ and ω
refer to the cell, input gate, forget gate and output gate respectively. bp
h is the output of cell h in the
hidden layer at point p in the input sequence, and sp
c is the state of cell c at p. f1 is the activation
function of the gates, and f2 and f3 are respectively the cell input and output activation functions.
The sufﬁx φ, d denotes the forget gate corresponding to recurrent connection d. The input gate ι
is connected to previous cell c along all dimensions with the same weight (wcι) whereas the forget
gates are connected to cell c with a separate weight wc(φ,d) for each dimension d.
Forward Pass
Input Gate: bp
Forget Gate: bp
i wi(φ,d) +
0 otherwise
Output Gate: bp
hω + wcωsp
Cell Output: bp
Backward Pass
Cell Output: ϵp
Output Gate: δp
φ,dwc(φ,d)
Forget Gate: δp
s if pd > 0
0 otherwise
Input Gate: δp
Connectionist Temporal Classiﬁcation
Connectionist temporal classiﬁcation (CTC) is an output layer designed for sequence labelling
with RNNs. Unlike other neural network output layers it does not require pre-segmented training
data, or postprocessing to transform its outputs into transcriptions. Instead, it trains the network to
directly estimate the conditional probabilities of the possible labellings given the input sequences.
A CTC output layer contains one more unit than there are elements in the alphabet L of labels for
the task. The output activations are normalised with the softmax activation function . At each
timestep, the ﬁrst |L| outputs are estimate the probabilities of observing the corresponding labels,
and the extra output estimates the probability of observing a ‘blank’, or no label. The combined
output sequence estimates the joint probability of all possible alignments of the input sequence with
labels and blanks. The probability of a particular labelling can then be estimated by summing over
the probabilities of all the alignments that correspond to it.
More precisely, for a length T input sequence x, the CTC outputs deﬁne a probability distribution
over the set L′T of length T sequences over the alphabet L′ = L ∪{blank}. To distinguish them
from labellings, we refer to the elements of L′T as paths. Since the probabilities of the labels at
each timestep are conditionally independent given x, the conditional probability of a path π ∈L′T
is given by p(π|x) = QT
πt. where yt
k is the activation of output unit k at time t.
Paths are mapped onto labellings l ∈L≤T by an operator B that removes ﬁrst the repeated labels,
then the blanks. For example, both B(a, −, a, b, −) and B(−, a, a, −, −, a, b, b) yield the labelling
(a, a, b). Since the paths are mutually exclusive, the conditional probability of some labelling l ∈
L≤T is the sum of the probabilities of all paths corresponding to it: p(l|x) = P
π∈B−1(l) p(π|x).
Although a naive calculation of this sum is unfeasible, it can be efﬁciently evaluated with a dynamic
programming algorithm, similar to the forward-backward algorithm for HMMs.
To allow for blanks in the output paths, for each labelling l ∈L≤T consider a modiﬁed labelling
l′ ∈L′≤T , with blanks added to the beginning and the end and inserted between every pair of labels.
The length of l′ is therefore |l′| = 2|l| + 1.
For a labelling l, deﬁne the forward variable αt(s) as the summed probability of all path beginnings
reaching index s of l′ at time t, and the backward variables βt(s) as the summed probability of all
path endings that would complete the labelling l if the path beginning had reached s at time t. Both
the forward and backward variables are calculated recursively . The label sequence probability
is given by the sum of the products of the forward and backward variables at any timestep, i.e.
p(l|x) = P|l′|
s=1 αt(s)βt(s).
The objective function O for CTC is the negative log probability of the network correctly labelling
the entire training set. Let S be a training set, consisting of pairs of input and target sequences
(x, z), where |z| ≤|x|. Then O = −P
(x,z)∈S ln p(z|x). The network can be trained with gradient
descent by ﬁrst differentiating O with respect to the outputs, then using backpropagation through
time to ﬁnd the derivatives with respect to the weights.
Note that the same label (or blank) may be repeated several times for a single labelling l. We deﬁne
the set of positions where label k occurs as lab(l, k) = {s : l′
s = k}, which may be empty.
Setting l = z and differentiating O with respect to the network outputs, we obtain:
−∂ln p(z|x)
s∈lab(z,k)
αt(s)βt(s),
k are respectively the input and output of CTC unit k at time t.
Once the network is trained, we can label some unknown input sequence x by choosing the labelling
l∗with the highest conditional probability, i.e. l∗= arg maxl p(l|x). In cases where a dictionary
is used, the labelling can be constrained to yield only sequences of complete words by using the
CTC token passing algorithm . For the experiments in this paper, the labellings were further
constrained to give single word sequences only, and the ten most probable words were recorded.
Network Hierarchy
Many computer vision systems use a hierarchical approach to feature extraction, with the features
at each level used as input to the next level . This allows complex visual properties to be built
up in stages. Typically, such systems use subsampling, with the feature resolution decreased at each
stage. They also generally have more features at the higher levels. The basic idea is to progress from
a small number of simple local features to a large number of complex global features.
We created a hierarchical structure by repeatedly composing MDLSTM layers with feedforward
layers. The basic procedure is as follows: (1) the image is divided into small pixel blocks, each of
which is presented as a single input to the ﬁrst set of MDLSTM layers (e.g. a 4x3 block is reduced
to a length 12 vector). If the image does not divide exactly into blocks, it is padded with zeros.
(2) the four MDLSTM layers scan through the pixel blocks in all directions. (3) the activations of
the MDLSTM layers are collected into blocks. (4) these blocks are given as input to a feedforward
layer. Note that all the layers have a 2D array of activations: e.g. a 10 unit feedforward layer with
input from a 5x5 array of MDLSTM blocks has a total of 250 activations.
The above process is repeated as many times as required, with the activations of the feedforward
layer taking the place of the original image. The purpose of the blocks is twofold: to collect local
contextual information, and to reduce the area of the activation arrays. In particular, we want to
reduce the vertical dimension, since the CTC output layer requires a 1D sequence as input. Note
that the blocks themselves do not reduce the overall amount of data; that is done by the layers that
process them, which are therefore analogous to the subsampling steps in other approaches (although
with trainable weights rather than a ﬁxed subsampling function).
For most tasks we ﬁnd that a hierarchy of three MDLSTM/feedforward stages gives the best results.
We use the standard ‘inverted pyramid’ structure, with small layers at the bottom and large layers at
the top. As well as allowing for more features at higher levels, this leads to efﬁcient networks, since
most of the weights are concentrated in the upper layers, which have a smaller input area.
In general we cannot assume that the input images are of ﬁxed size. Therefore it is difﬁcult to choose
block heights that ensure that the ﬁnal activation array will always be one dimensional, as required
by CTC. A simple solution is to collapse the ﬁnal array by summing over all the inputs in each
vertical line, i.e. the input at time t to CTC unit k is given by at
, where a(x,y)
uncollapsed input to unit k at point (x, y) in the ﬁnal array.
Figure 2: The complete recognition system. First the input image is collected into boxes 3 pixels
wide and 4 pixels high which are then scanned by four MDLSTM layers. The activations of the cells
in each layer are displayed separately, and the arrows in the corners indicates the scanning direction.
Next the MDLSTM activations are gathered into 4 x 3 boxes and fed to a feedforward layer of tanh
summation units. This process is repeated two more times, until the ﬁnal MDLSTM activations are
collapsed to a 1D sequence and transcribed by the CTC layer. In this case all characters are correctly
labelled except the second last one, and the correct town name is chosen from the dictionary.
Experiments
To see how our method compared to the state of the art, we applied it to data from the ICDAR
2007 Arabic handwriting recognition competition . Although we were too late to enter the
competition itself, the organisers kindly agreed to evaluate our system according to the competition
criteria. We did not receive the test data at any point, and all evaluations were carried out by them.
The goal of the competition was to identify the postcodes of Tunisian town and village names. The
names are presented individually, so this is an isolated word recognition task. However we would
like to point out that our system is equally applicable to unconstrained handwriting, and has been
successfully applied to complete lines of English text.
The competition was based on the IFN/ENIT database of handwritten Arabic words . The
publically available data consists of 32,492 images of handwritten Tunisian town names, of which
we used 30,000 for training, and 2,492 for validation. The images were extracted from artiﬁcial
Table 1: Results on the ICDAR 2007 Arabic handwriting recognition contest. All scores are
percentages of correctly identiﬁed postcodes. The systems are ordered by the ‘top 1’ results on test
set ‘f’. The best score in each column is shown in bold.
UOB-ENST-1
UOB-ENST-2
UOB-ENST-4
UOB-ENST-3
forms ﬁlled in by over 400 Tunisian people. The forms were designed to simulate writing on a
letter, and contained no lines or boxes to constrain the writing style.
Each image was supplied with a ground truth transcription for the individual characters1. There were
120 distinct characters in total. A list of 937 town names and postcodes was provided. Many of the
town names had transcription variants, giving a total of 1,518 entries in the complete dictionary.
The test data (which is not published) is divided into sets ‘f’ and ‘s’. The main competition results
were based on set ‘f’. Set ‘s’ contains data collected in the United Arab Emirates using the same
forms; its purpose was to test the robustness of the recognisers to regional writing variations. The
systems were allowed to choose up to 10 postcodes for each image, in order of preference. The test
set performance using the top 1, top 5, and top 10 answers was recorded by the organisers.
Network Parameters
The structure shown in Figure 2 was used, with each layer fully connected to the next layer in the
hierarchy, all MDLSTM layers connected to themselves, and all units connected to a bias weight.
There were 159,369 weights in total. This may sound like a lot, but as mentioned in Section 2.3, the
‘inverted pyramid’ structure greatly reduces the actual number of weight operations. In effect the
higher up networks (where the vast majority of the weights are concentrated) are processing much
smaller images than those lower down. The squashing function for the gates was the logistic sigmoid
f1(x) = 1/(1 + e−x), while tanh was used for f2 and f3. Each pass through the training set took
about an hour on a desktop computer, and the network converged after 85 passes.
The complete system was trained with online gradient descent, using a learning rate of 10−4 and
a momentum of 0.9. The character error rate was evaluated on the validation set after every pass
through the training set, and training was stopped after 50 evaluations with no improvement. The
weights giving the lowest error rate on the validation set were passed to the competition organisers
for assessment on the test sets.
Table 1 clearly shows that our system outperformed all entries in the 2007 ICDAR Arabic recognition contest. The other systems, most of which are based on HMMs, are identiﬁed by the names of
the groups that submitted them (see for more information).
1At ﬁrst we forgot that Arabic reads right to left and presented the transcriptions backwards. The system
performed surprisingly well, with a character error rate of 17.8%, compared to 10.7% for the correct targets.
Conclusions and Future Work
We have combined multidimensional LSTM with connectionist temporal classiﬁcation and a hierarchical layer structure to create a powerful ofﬂine handwriting recogniser. The system is very general,
and has been successfully applied to English as well as Arabic. Indeed, since the dimensionality of
the networks can be changed to match that of the data, it could be used for almost any supervised
sequence labelling task. We are currently investigating applications to facial expression recognition.
Acknowledgements
We would like to thank Haikal El Abed for giving us access to the ICDAR competition data, and
for persisting in the face of technical despair to install and evaluate our software. This work was
supported by the excellence cluster “Cognition for Technical Systems” (CoTeSys) from the German
Research Foundation (DFG).