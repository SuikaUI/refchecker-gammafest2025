HAL Id: hal-04306453
 
Submitted on 25 Nov 2023
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of scientific research documents, whether they are published or not.
The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Intrinsic Dimension Estimation for Robust Detection of
AI-Generated Texts
Eduard Tulchinskii, Kristian Kuznetsov, Laida Kushnareva, Daniil
Cherniavskii, Sergey Nikolenko, Evgeny Burnaev, Serguei Barannikov, Irina
Piontkovskaya
To cite this version:
Eduard Tulchinskii, Kristian Kuznetsov, Laida Kushnareva, Daniil Cherniavskii, Sergey Nikolenko, et
al.. Intrinsic Dimension Estimation for Robust Detection of AI-Generated Texts. Advances in Neural
Information Processing Systems, 2023, pp.36. ￿hal-04306453￿
Intrinsic Dimension Estimation for Robust Detection
of AI-Generated Texts
Eduard Tulchinskii1, Kristian Kuznetsov1, Laida Kushnareva2, Daniil Cherniavskii3,
Sergey Nikolenko5, Evgeny Burnaev1,3, Serguei Barannikov1,4, Irina Piontkovskaya2
1Skolkovo Institute of Science and Technology, Russia;
2AI Foundation and Algorithm Lab, Russia;
3Artificial Intelligence Research Institute (AIRI), Russia;4CNRS, Université Paris Cité, France;
5St. Petersburg Department of the Steklov Institute of Mathematics, Russia
Rapidly increasing quality of AI-generated content makes it difficult to distinguish
between human and AI-generated texts, which may lead to undesirable consequences for society. Therefore, it becomes increasingly important to study the
properties of human texts that are invariant over different text domains and varying
proficiency of human writers, can be easily calculated for any language, and can
robustly separate natural and AI-generated texts regardless of the generation model
and sampling method. In this work, we propose such an invariant for humanwritten texts, namely the intrinsic dimensionality of the manifold underlying the
set of embeddings for a given text sample. We show that the average intrinsic
dimensionality of fluent texts in a natural language is hovering around the value 9
for several alphabet-based languages and around 7 for Chinese, while the average
intrinsic dimensionality of AI-generated texts for each language is ≈1.5 lower,
with a clear statistical separation between human-generated and AI-generated distributions. This property allows us to build a score-based artificial text detector. The
proposed detector’s accuracy is stable over text domains, generator models, and
human writer proficiency levels, outperforming SOTA detectors in model-agnostic
and cross-domain scenarios by a significant margin. We release code and data1
Introduction
Modern large language models (LLMs) generate human-looking texts increasingly well, which
may also lead to worrisome consequences [Fagni et al., 2021, Adelani et al., 2020, Stokel-Walker,
2022]. Hence, the ability to detect AI-generated texts (artificial text detection, ATD) becomes
crucial for media, education, politics, creative industries and other spheres of human social activities.
A straightforward idea would be to train a classifier to detect artificial text; many such classifiers
exist [Zellers et al., 2019, Gehrmann et al., 2019, Solaiman et al., 2019], but most of them are designed
to detect samples of individual generation models, either using the model itself [Mitchell et al., 2023]
or training on a dataset of its generations. This leads to poor generalization to new models and
unknown data domains. Another idea, known as watermarking, is to inject some detectable artifacts
into model generations; for instance, Kirchenbauer et al. propose to intentionally inject a
statistical skew that can be detected in a text sample. However, later works showed that watermark
detectors can be broken by adversarial attacks, e.g., by text perturbations or paraphrasing [He et al.,
2023]. Since text generation is constantly evolving, Sadasivan et al. claim that perfect artificial
text detection is impossible; Krishna et al. address this statement and propose a retrieval-based
detector that could be implemented by text generation service providers: they should store the hash
1github.com/ArGintum/GPTID
37th Conference on Neural Information Processing Systems .
value of every text generated by their model and retrieve it by request. This approach works even
for a perfect text generator indistinguishable from human writing, but it does not apply to publicly
available models, and plenty of them already exist.
(a) AI generated
(b) human written
Figure 1: Real and artificial text have different intrinsic dimension: (a-b) idea; (c) actual results.
In this work, we show that the intrinsic dimension of text samples can serve as a helpful score
function allowing to separate artificial and generated texts in a very general setting, without additional
knowledge about the generator. The only assumption is that generation is good enough to create fluent
grammatical samples of length ≈200 words. We propose a method based on persistent homology
dimension theory, which allows to estimate the dimension of text samples with high accuracy, and
show that the proposed dimension-based classifier outperforms other artificial text detectors with a
large margin in the general-purpose setup, for a very wide class of generators.
Many works have estimated the intrinsic dimension of data representations [Pope et al., 2021,
Barannikov et al., 2021], neural network weights [Ansuini et al., 2019], or parameters needed to
adapt to some downstream task [Aghajanyan et al., 2021], but these objects are very complex. Even
if we are certain that a dataset fits into some surface in a high-dimensional feature space, it is not easy
to estimate its dimension due to various kinds of noise (natural irregularities, measurement noise,
numerical approximations) and the ambiguity of estimating a surface from a sparse set of points.
We estimate the geometry of every text sample as a separate object. Since texts generated by modern
LLMs are fluent and usually do not contain grammatical, syntactical, or local semantic inconsistencies,
we are interested in global sample geometry rather than properties that could be detected over short
text spans. We show that the persistent dimension estimator provides an excellent way to deal with
textual data: it turns out that real texts have a higher intrinsic dimension than artificial ones (Fig. 1).
We propose an efficient method to implement the estimator and evaluate its classification ability in
various settings, proving its robustness for artificial texts detection and showing that it works equally
well across a number of different languages.
Our main contributions are thus as follows: (1) we propose to estimate the intrinsic dimensionality of
natural language texts with the persistent homology dimension estimator and develop an efficient
algorithm for computing it; (2) we show that the intrinsic dimension serves as a good score for
artificial text detection for modern LLMs; in cross-domain and cross-model settings our method
outperforms other general purpose classifiers by a large margin, is robust to adversarial attacks,
and works for all considered languages; (3) we show that our text detector reduces the bias against
non-native speakers in comparison to available ATD models; (4) we release a multilingual dataset of
generations produced by GPT-3.5 and natural texts from the same domain in order to enable further
ATD research. Below, Section 2 reviews related work, Section 3 introduces instrinsic dimension and
its estimation with persistent homology, Section 4 applies it to artificial text detection, Section 5
presents our experimental evaluation, Section 6 discusses the limitations, and Section 7 concludes the
Related work
Artificial text detection (ATD) becomes increasingly important with modern LLMs. GPT-2 [Radford
et al., 2019] was accompanied by a work by Solaiman et al. on potential dangers and defences
against them; the best ATD classifier there was based on supervised fine-tuning of RoBERTa [Liu et al.,
2019]. Supervised approaches can work well for other generative models and data domains [Krishna
et al., 2023, Guo et al., 2023, He et al., 2023] but they do not generalize to other text domains,
generation models, and even sampling strategies [Bakhtin et al., 2019, Solaiman et al., 2019]. In
the zero-shot setting, Solaiman et al. threshold the average log-probability score of a sample
calculated by some pretrained language model (LM). DetectGPT [Mitchell et al., 2023] treats logprobability calculation as a function, estimates its curvature in a small neighbourhood of the text, and
shows that this curvature score is smaller for artificial texts (there are “flat” regions around them);
however, DetectGPT needs the likelihood to come from the same LM as the sample.
We focus on developing an ATD model that could generalized to unseen text generation models
and domains. Zellers et al. detect generated texts perfectly with a discriminator model built
on top of the generator, but the quality drops significantly when the generator changes, even with
supervised adaptation; a similar “model detects itself” setup was adopted by Mitchell et al. .
Solaiman et al. show that a simple score-based approach by the likelihood score works well in
the “model detects itself” setting but does not generalize to different generator and discriminator;
as for transferability, they show that a supervised classifier generalizes well when it is trained on
the output of a more complex model and transferred to a less complex one but not in the reverse
direction. Bakhtin et al. consider different types of generalization: in-domain (train and test
generators are the same), cross-corpus (train and text generators fine-tuned on different corpora), and
cross-architecture (train and test generators have different architectures but the same training corpora);
their model shows good in-domain generalization ability, handles relatively well cross-architecture
generalization, but loses quality in cross-corpus generalization. Mitchell et al. demonstrate
the stability of their method over text domains compared to supervised models, which are better on
in-domain data but lose efficiency in a cross-domain setting. Finally, Krishna et al. show all
methods failing dramatically against the DIPPER paraphrase attack . We also note a work by Liang
et al. who show the bias of artificial text detectors against non-native speakers and show that
all existing detectors can be broken by generating texts with controllable complexity.
Geometrical and topological methods have shown their usefulness for analysing the intrinsic dimensionality of data representations. Some works focus on data manifolds [Pope et al., 2021, Barannikov
et al., 2021] and others consider hidden representations and other parts of neural networks and
investigate through the lens of intrinsic dimensionality. Li et al. define the intrinsic dimension
of objective landscape by tracking the subspace dimension and performance of a neural network,
while Zhu et al. use manifold dimension directly to regularize the model. Ansuini et al.
 apply TwoNN to internal representations in CNNs and establish a connection to the model’s
generalization ability. Birdal et al. show that the generalization error of these models can be
bounded via persistent homology dimension. Vision transformers were also investigated by Xue et al.
 and Magai and Ayzenberg . Moreover, intrinsic dimensionality has been connected
to the generalization of Transformer-based LLMs [Aghajanyan et al., 2021]. Valeriani et al. 
analyze the intrinsic dimensionality of large Transformer-based models. Topological properties of the
inner representations of Transformer-based models [Vaswani et al., 2017], including BERT [Devlin
et al., 2019] and HuBERT [Hsu et al., 2021], have been successfully applied for solving a wide
variety of tasks, from artificial text detection [Kushnareva et al., 2021] and acceptability judgement
[Cherniavskii et al., 2022] to speech processing [Tulchinskii et al., 2023].
Intrinsic dimension and persistent homology dimension
Informally speaking, the intrinsic dimension of some subset S ⊂Rn is the number of degrees of
freedom that a point moving inside S has. This means that in a small neighbourhood of every point,
the set S can be described as a function of d parameters, d ≤n, and this number cannot be reduced.
This idea is formalized in the notion of a d-dimensional manifold in Rn: it is a subset M ⊂Rn such
that for every point x ∈M there exists an open neighborhood which is equivalent to an open ball in
Rd for some value d. Importantly, if M is a connected set then d should be the same for all its points,
so we can talk about the dimension of the entire manifold.
Data representations often use excessive numbers of features, some of which are highly correlated.
This overparametrization has been noticed many times [Hein and Audibert, 2005, Kuleshov et al.,
2017, Pope et al., 2021], and the idea that real data lies (approximately) on some low-dimensional
manifold in the feature space is known as the manifold hypothesis [Goodfellow et al., 2016]. However,
there are obstacles to estimating the intrinsic dimension of a dataset. First, a real dataset can be a
combination of sets of different dimensions. Second, data can be noisy and may contain outliers.
Moreover, real data can have a complicated hierarchical structure, so different approximation methods
lead to different intrinsic dimension values. For an analogy, consider the observations of a single spiral
galaxy that consists of separate points (stars, planets etc.) but forms a compact 3-dimensional manifold.
At some level of approximation the galaxy looks like a disk, which is 2-dimensional, but if we take
a closer look we discover the structure of a 3-dimensional core and basically 1-dimensional arms.
Moreover, if we add observations over time, the dataset will consist of 1-dimensional trajectories
of individual points that exactly correspond to well-defined mathematical trajectories (the noise
here comes only from measurement errors); these trajectories form an approximate 3-dimensional
cylinder in 4-dimensional space with a much higher level of noise around its borders. As a result,
the dimension of the entire object can be estimated by any number from 1 to 4 depending on the
detector’s sensitivity to noise and outliers, preference for global or local features, and the way to
average the values of the non-uniform distribution of the points.
Thus, it is natural that there exist several different methods for intrinsic dimension (ID) estimation,
and we have to choose the one most suitable for the task at hand. For example, many ID estimators
are based on constructing a global mapping of the data into a lower-dimensional linear subspace,
with either linear projection (e.g., PCA), kernel-based methods, or distance-preserving nonlinear
transformations. However, in our preliminary experiments these types of dimension estimation
seemed to be losing information that was key for artificial text detection.
We focus on the persistent homology dimension estimator (PHD) [Schweinhart, 2021], which belongs
to the class of fractal dimension approaches. Consider a ball of radius r inside a d-dimensional
manifold M. As r grows, the volume of the ball increases proportionally to rd. Let x1, ..., xN be
points uniformly sampled from M. Then the expected number of points in a ball of radius r also
changes as rd with r. Naturally, real datasets usually do not correspond to a uniform distribution
of points, but this issue can be overcome by considering the asymptotic behaviour of the number
of points in an r-ball as r →0. In this case, it suffices for the data distribution to be smooth and
therefore close to uniform in the neighbourhood of every point. Accurate straightforward estimation
of d based on the above observation is not sample-efficient but there exist several approximate
approaches, including the MLE dimension that evaluates the data likelihood [Levina and Bickel,
2004], the TwoNN dimension that uses the expected ratio of distances from a given point to its two
nearest neighbours [Facco et al., 2017], and MADA [Farahmand et al., 2007] that uses the first order
expansion of the probability mass function. We also report MLE-based results as its performance is
comparable to PHD in some tasks.
We propose to use persistence homology dimension (PHD) that has several appealing properties
compared to other fractal intrinsic dimension estimators. First, the above methods operate locally
while PHD combines local and global properties of the dataset. Second, according to our experiments,
this method is sample-efficient and redundant to noise (see below). Third, it has a solid theoretical
background that connects topological data analysis, combinatorics, and fractal geometry [Adams
et al., 2020, Birdal et al., 2021, Jaquette and Schweinhart, 2020, Schweinhart, 2021].
The formal definition of PHD is based on the concept of persistent homology for a set of points
in a metric space, which is a basic notion of topological data analysis (TDA) [Chazal and Michel,
2017, Barannikov, 1994, 2021]. TDA aims to recover the underlying continuous shape for a set of
points by filling in the gaps between them that are smaller than some threshold t and studying the
topological features of the resulting object as t increases. Each persistent homology PHi in a sequence
PH0, PH1, . . . is defined by the set of topological features of dimension i: 0-dimensional features
are connected components, 1-dimensional features are non-trivial cycles, 2-dimension features are
tunnels, etc. For each feature we calculate its “lifespan”, a pair (tbirth, tdeath), where tbirth is the
minimal threshold where the feature arises, and tdeath is the threshold where it is destroyed.
Following Adams et al. , we introduce the persistent homology dimension as follows. Consider a set of points X = {x1, . . . , xN} ⊂Rn. We define the α-weighted sum as Ei
γ∈PHi(X) |I(γ)|α, where I(γ) = tdeath(γ) −tbirth(γ) is the lifespan of feature γ. For i = 0, Ei
can be expressed in terms of the minimal spanning tree (MST) of X: its edges map to lifespans
of 0-dimensional features γ ∈PH0(X) [Bauer, 2021, Birdal et al., 2021]. Thus, the definition of
α(X) is equivalent to E0
e∈MST(X) |e|α, where |e| is the length of edge e.
Figure 2: A comparison of ID estimators with noise on artificial datasets; lower is better.
There is a classical result on the growth rate of E0
α(X) [Steele, 1988]: if xi, 0 < i < ∞are
independent random variables with a distribution having compact support in Rd then with probability
as n →∞, where equivalence means that the ratio of the terms tends to one.
It shows that E0
α tends to infinity with N if and only if α < d. Now one can define the intrinsic
dimension based on MST as the minimal value of α for which the score is bounded for finite samples
of points from M [Schweinhart, 2021]:
dimMST(M) = inf{d | ∃C such that E0
d(X) ≤C for every finite X ⊂M},
and a PH dimension as
dimPH(M) = inf{d | ∃C such that E0
d(X) ≤C for every finite X ⊂M}.
We now see that dimMST(M) = dimPH(M) for any manifold M. This fact, together with the
growth rate result above, provides a sample-efficient way to estimate dimP H(M) [Birdal et al.,
2021]: sample subsets Xni = {x1, . . . , xni} ⊂M of ni elements for a growing sequence of ni, for
every subset find its MST and calculate E0
α(Xni), and then estimate the exponent of the growth rate
of the resulting sequence by linear regression between log E0
α(Xni) and log n, since we know that
α(Xni) ∼(1 −α
d ) log ni + ˜C as ni →∞.
Next, we show empirically that our method of ID estimation via PHD approximates the real dimension
of a manifold well and is well suited for the conditions mentioned earlier: presence of noise and small
number of samples. To compare with other ID estimators, we utilize a benchmark by Campadelli
et al. designed specifically for the evaluation of ID estimation methods and used the scikitdimensions library [Bac et al., 2021] with efficient implementations of 12 different approaches to ID
estimation, popular for different tasks. We evaluated many of these approaches on artificial datasets
from Bac et al. , 1000 samples each, without noise. Choosing three “winners”—MLE, TwoNN,
and MADA,—we have evaluated their sample efficiency and noise tolerance in comparison with our
implementation of the PHD estimator. Fig. 2 shows the results: PHD is the only method tolerant
to noise, and it does not degrade when data is scarce. It outperforms all other methods in the noisy
setup for any sample size. The second-best method is MLE, which performs relatively well on small
samples (200–500) in noisy settings and has a small variance. Below we will show that as a result,
MLE is also applicable to artificial text detection, but it lags a little behind PHD on average.
Methodology
We consider consistent text samples of medium size, with length ≈300 tokens; we assume that
each text contains a complete thought or is devoted to a single topic. We estimate the dimension
of each text sample, considering it as a separate manifold. To do this, we obtain contextualized
embeddings for every token in the text by a pretrained Transfromer encoder. In our experiments, we
use RoBERTa-base [Liu et al., 2019] for English and XLM-R [Goyal et al., 2021] for other languages.
Each embedding is a numerical vector of a fixed length, so we view it as a point in the Euclidean
space. We drop the artificial first and last tokens (<CLS> and <SEP>) and evaluate the persistent
homology dimension of the resulting point cloud using the growth rate theorem (see Section 3).
Table 1: Intrinsic dimensions of English texts of different genres.
Wikipedia articles
Fiction stories
Question answering
(Stack Exchange)
9.491 ± 1.010
9.212 ± 1.288
9.594 ± 1.29
11.827 ± 0.768
11.553 ± 1.197
12.131 ± 1.004
Figure 3: Boxplots of PHD distributions for different generative models in comparison to humanwritten text on Wikipedia data. Embeddings are obtained from RoBERTa-base.
Given a set of points S, |S| = n, we first sample subsets Si ⊂S, i = 1, . . . , k whose sizes n1, . . . , nk
are uniformly distributed in [1, n]. For each Si we calculate its persistent score E1
0(Si) (just E(Si)
below); this can be done with a classical MST algorithm in linear time. Then we prepare a dataset
consisting of k pairs D = {(log ni, log E(Si))} and apply linear regression to approximate this set
by a line. Now the dimension d can be estimated as
1−κ, where κ is the slope of the fitted line.
In general, our method for PHD calculation is similar to the the computational scheme proposed by
Birdal et al. . But since we are dealing with sets that are much smaller and less uniformly
distributed, their algorithm becomes unstable, with variance up to 35% of the value from different
random seeds; moreover, if one of the subsets Si slips into a local density peak and has an unusually
low persistence score, the algorithm may even produce a meaningless answer (e.g., negative d).
To overcome this issue, we add several rounds of sampling and averaging to improve the stability of
calculation. We estimate the expectation Es⊂S,|s|=ni[E(s)] for a given ni instead of direct calculation
of E(Si) for a single sample. For that, we perform the whole process of computing d several times,
averaging the results. Details of our sampling schema can be found in the Appendix.
Finally, we construct a simple single-feature classifier for artificial text detection with PHD as the
feature, training a logistic regression on some dataset of real and generated texts.
Experiments
Datasets. Our main dataset of human texts is Wiki40b [Guo et al., 2020]. We measured intrinsic
dimension of fiction stories on the target split of the WritingPrompts dataset [Fan et al., 2018], a
collection of short texts written by Reddit users. For multilingual text detection experiments, we
generated a new WikiM dataset for 10 languages by GPT3.5-turbo (ChatGPT). We use the header and
first sentence from a Wikipedia page as the prompt and ask the model to continue. In cross-domain
and paraphrase robustness experiments, we use Wiki and Reddit datasets (3k samples each) [Krishna
et al., 2023] that use two consecutive sentences (Wiki) or the question (Reddit) as a prompt and
generate texts by GPT2-XL, OPT13b, and GPT3.5 (text-davinci-003). Following their pipeline for
Reddit, we have also generated a StackExchange dataset by GPT3.5 (text-davinci-003) as the third
domain. We select questions posted after 2019-08-01 from non-technical categories, where both
question and answer have rating more then 10, and clean them removing HTML artifacts. In order to
assess the bias in our estimator, we use the data provided by Liang et al. .
Intrinsic dimensionality of real and generated texts. First, we observe an intriguing fact: the
intrinsic dimension of natural texts is mostly concentrated between values 9 and 10, while the
dimension of generated texts is lower and is approximately equal to 8, regardless of the generator.
This is illustrated in Figure 3. Table 1 shows that this value is stable across different text genres but
slightly varies for different languages: it is approximately equal to 9±1 for most European languages,
Figure 4: Boxplots of PHD distributions in different languages on Wikipedia data. Embeddings are
obtained from XLM-RoBERTa-base (multilingual).
Figure 5: Boxplots of PHD distributions obtained by different LMs on English Wikipedia data.
slightly larger for Italian and Spanish (≈10 ± 1), and lower for Chinese and Japanese (≈7 ± 1);
details are shown in Fig. 4. But we always observe a clear difference between this distribution and
generated texts on the same language (see Appendix for more experiments).
Next, we check how the PHD estimation depends on the base model that we use for text embedding
calculation. Fig. 5 demonstrates that PHD changes slightly with the change of the base LM, decreasing
for models with fewer parameters. RoBERTa-base embeddings provide the best variance for PHD
estimation, so we use this model for all further experiments in English, and XLM-R of the same size
for multilingual experiments.
Artificial text detection. We show that intrinsic dimension can lead to a robust method of artificial
text detection. In all experiments below, we use the one-feature thresholding classifier (see Section 4).
Comparison with universal detectors. First, we show that our detector is the best among generalpurpose methods designed to detect texts of any domain, generated by any AI model, without access to
the generator itself. Such methods are needed, e.g., for plagiarism detection. To be applicable in real
life, the algorithm should provide high artificial text detection rate while avoiding false accusations
of real authors. Besides, it should be resistant to adversaries who transform the content generated by
popular AI models to reduce the chance to be caught.
Here we adopt the experimental settings by Krishna et al. and use the baseline results
presented there. We compare PHD and MLE with two general-purpose detectors: GPTZero [Tian,
2023], targeted to detect the texts generated by contemporary LLMs (GPT-3, GPT-4, ChatGPT,
BARD), and OpenAI detector [OpenAI, 2023] announced together with the ChatGPT model in order
to reduce its expected social harm. Our third baseline is DetectGPT [Mitchell et al., 2023], which
is a state of the art thresholding classifier that evaluates text samples by the probability curvature
obtained via the generator model. It works best when the base model coincides with the generator
model (“model detects itself”) but the authors claim that it can generalize to cross-model setup with
reasonable quality. RankGen [Krishna et al., 2022] is a method originally developed for ranking
hypotheses during text generation; it demonstrates a surprising ability to handle adversarial attacks.
Table 2: Artificial text detection (accuracy at 1% FPR) for open-ended generation using Wikipedia
prompts. DIPPER was run with Lex=60, Order=60.
Existing Solutions
Our methods
Following Krishna et al. , we report the detection accuracy with false positive rate (FPR) fixed
at 1%. Table 2 shows that our PHD-based classifier outperforms all baselines with a large margin:
+10% for GPT-3.5, +14% for OPT. Note that DetectGPT uses GPT-2 as the base model, which
explains its results for GPT-2. PHD is also invulnerable to the DIPPER paraphrasing attack [Krishna
et al., 2023]. When generated texts are transformed by DIPPER, they lose some characteristic features
of the generator, which causes a dramatic drop in quality for most detectors; but for the PHD classifier
the accuracy of artificial text detection even increases slightly after this perturbation. Interestingly, the
MLE dimension estimator also works quite well for this task, and even achieves 6% better detection
for GPT-3.5 generations; but its adversarial robustness is significantly worse.
Cross-domain and cross-model performance. Table 3 shows that our ID estimation is stable across
text domains; consequently, our proposed PHD text detector is robust to domain transfer. We compare
the cross-domain ability of PHD with a supervised classifier obtained by fine-tuning RoBERTabase with a linear classification head on its CLS token, a supervised classification approach used
previously for artificial texts detection with very high in-domain accuracy [Solaiman et al., 2019,
Guo et al., 2023, He et al., 2023]. We split data into train / validation / test sets in proportion
80%/10%/10%. Table 3 reports the results of the classifier’s transfer between three datasets of
different text styles—long-form answers collected from Reddit, Wikipedia-style texts, and answers
from StackExchange—using data generated by GPT-3.5 (text-davinci-003). Although supervised
classification is virtually perfect on in-domain data, it fails in cross-domain evaluation, while the PHD
classifier is not influenced by domain transfer. On average, the PHD classifier slightly outperforms
the supervised baseline, while being much more stable. Table 3 also reports cross-model transfer
ability, where the classifier is trained on the output of one generation model and tested on another.
We consider generations of GPT-2, OPT, and GPT-3.5 (text-davinci-003) in the Wikipedia domain
and observe that the PHD classifier, again, is perfectly stable. This time, RoBERTa-base supervised
classifier handles the domain shift much better and outperforms PHD on average, but it has a higher
cross-domain generalization gap. This means that we can expect the PHD classifier to be more robust
to entirely new AI models.
PHD-based classification for other languages. Table 4 presents the results of PHD-based artificial
text detection for Wikipedia-style texts generated by ChatGPT in 10 languages. Text embeddings
were obtained with XLM-RoBERTa-base, the multilingual version of RoBERTa. As quality metric
we report the area under ROC-curve (ROC-AUC). We see that both ID classifiers provide solid
results for all considered languages, with the average quality of 0.78 for PHD and 0.8 for MLE; MLE
performs better for almost all languages. The worst quality is on Chinese and Japanese (PHD 0.71
and 0.74, MLE 0.65 and 0.75 respectively), the best is for Spanish and Italian (PHD 0.83, MLE 0.85
for both). Note that the best and worst classified languages are those with the largest and smallest ID
values in Fig. 4; we leave the investigation of this phenomenon for further research.
Non-native speaker bias. Finally, we show how our model helps to mitigate the bias present in
ML-based artificial text detectors. We follow Liang et al. who demonstrate that current
artificial text detectors are often too hard on texts written by non-native speakers. We use OpenAI and
GPTZero as the baselines (see Appendix for more results) and PHD and MLE classifiers, choosing
the thresholds was chosen on data unrelated to this task, as the equal error classifier on introductions
of Wikipedia articles (real vs GPT-3.5-turbo) where it achieved EER of 26.8% for PHD and 22.5%
for MLE. On the left, Fig. 6 shows false positive rates (FPR) for three sets of student essays: TOEFL
essays by non-native speakers (red), same texts processed by GPT-4 asked to improve the text (grey),
Table 3: Cross-domain and cross-model accuracy of PHD and RoBERTa-based classifiers on data from
three different domains and three different models; classes are balanced in training and evaluation.
RoBERTa-cls
Intrinsic Dimension (PHD)
Train \ Eval
Wikipedia Reddit
StackExchange
StackExchange
StackExchange
Train \ Eval
Table 4: Quality of artificial text detection in different languages (ROC-AUC) for ChatGPT text.
Language: cn-zh
0.781 0.790
0.770 0.804
Figure 6: Comparison of GPT detectors in non-standard environment. Left: bias against non-native
English writing samples (the lower is better). Right: effect of the prompt design on performance (the
higher is better).
and native speakers (blue). First, blue bars are almost invisible for all detectors because the FPR
for a native speaker is very small (< 1%) while non-native speakers can be wrongly accused by
OpenAI and GPTZero in 58% and 52% of the cases respectively. The PHD classifier reduces this
discriminating rate by 2x, showing FPR 26% for non-native speakers. After GPT-4 polishing, this
rate further decreases to 7.7% compared to 19% for GPTZero. Interestingly, OpenAI also deals with
GPT-4 polished texts suprisingly well, its FPR drops by 15x. The MLE detector also demonstrates
less biased behaviour compared to baselines, but worse than PHD.
On the right, Fig. 6 shows the true positive rates (TPR) of these methods on essays generated by
ChatGPT. Red bars show that our classifiers greatly outperform baselines. Grey bars demonstrate
the robustness of ID detectors to changes in generation style via prompt design. If an adversary asks
ChatGPT to generate a text with some predefined level of complexity (“use simple words”, or “more
complex words”), baseline systems fail to correctly recognize such texts while both ID classifiers still
yield high detection rates.
Analysis of edge cases. We noticed an interesting tendency among the human-written passages with
the lowest ID (misclassified as AI-generated). It seems that most of these examples contain a lot of
addresses, geographical names, or proper nouns; some texts, however, are typical but very short. We
hypothesize that it can be related to an unusually high number of rare tokens or numbers in the text
and that PH dimension estimation is overall less correct on short texts. Besides, Davinci-generated
texts with the highest ID (misclassified as human-written with the most certainty) are also often quite
short. We leave a more comprehensive analysis of such failure cases for future work.
We provide examples of both types of misclassified texts in Appendix E. Moreover, we show bar plots
of the PHD of artificially created texts made from random tokens and texts composed by repeating the
same token in Figure 11. One can see that the simplest samples have the lowest ID, and the highest
values of ID correspond to completely random texts. This supports the general understanding of ID
as the number of degrees of freedom in the data.
Limitations and broader impact
We see three main limitations of our method. First, it is stochastic in nature. PH dimensions of texts
from the same generator vary widely, and the estimation algorithm is stochastic as well, which adds
noise, while rerolling the estimation several times would slow down the method. Second, “out of the
box” our method can detect only “good” (fluent) generators with a relatively small temperature of
generation. The PH dimension of “bad” or high-temperature generators is actually higher on average
than for real texts, so the detector will need to be recalibrated. Third, we have only evaluated our
approach on several relatively high-resource languages and we do not know how the method transfers
to low-resource languages; this is a direction for future work. Nevertheless, our method provides
a new tool for recognizing fake content without discriminating non-native speakers, which is also
much more robust to model change and domain change than known tools.
Conclusion
In this work, we have introduced a novel approach to estimating the intrinsic dimension of a text
sample. We find that this dimension is approximately the same for all human-written samples in a
given language, while texts produced by modern LLMs have lower dimension on average, which
allows us to construct an artificial text detector. Our comprehensive experimental study proves the
robustness of this classifier to domain shift, model shift, and adversarial attacks. We believe that we
have discovered a new interesting feature of neural text representations that warrants further study.
Acknowledgments and Disclosure of Funding
The work of Evgeny Burnaev was supported by the Russian Foundation for Basic Research grant
21-51-12005 NNIO_a.