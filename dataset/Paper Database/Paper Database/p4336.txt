The Liver Tumor Segmentation Benchmark (LiTS)
Patrick Bilic†∗a, Patrick Christ†∗a, Hongwei Bran Li∗a,b, Eugene Vorontsov†∗c, Avi Ben-Cohen†e,
Georgios Kaissis†j,l,o, Adi Szeskin†r, Colin Jacobs†d, Gabriel Efrain Humpire Mamani†d,
Gabriel Chartrand†z, Fabian Loh¨ofer†l, Julian Walter Holch†ac,ad,bq, Wieland Sommer†af,
Felix Hofmann†ae,af, Alexandre Hostettler†aj, Naama Lev-Cohain†al, Michal Drozdzal†ah, Michal Marianne
Amitai†ai, Refael Vivanti†ak, Jacob Sosna†al, Ivan Ezhova, Anjany Sekuboyinaa,b, Fernando Navarroa,bx,bz,
Florian Koﬂera,m,be,bz, Johannes C. Paetzoldo,p, Suprosanna Shita, Xiaobin Hua, Jana Lipkov´aq,
Markus Rempﬂera, Marie Piraudbe,a, Jan Kirschkem, Benedikt Wiestlerm, Zhiheng Zhangn,
Christian H¨ulsemeyera, Marcel Beetza, Florian Ettlingera, Michela Antonellii, Woong Baebu,
M´ıriam Bellveraq, Lei Bibi, Hao Chenam, Grzegorz Chlebusbj,bl, Erik B. Dambt, Qi Douao, Chi-Wing Fuao,
Bogdan Georgescubh, Xavier Gir´o-i-Nietoas, Felix Gruenab, Xu Hanby, Pheng-Ann Hengao,
J¨urgen Hesserav,aw,ax, Jan Hendrik Moltzbj, Christian Igelbt, Fabian Isenseebq,br, Paul J¨agerbq,br,
Fucang Jiabw, Krishna Chaitanya Kaluvau, Mahendra Khenedu, Ildoo Kimbu, Jae-Hun Kimba,
Sungwoong Kimbu, Simon Kohlbq, Tomasz Konopczynskiaw, Avinash Koriu, Ganapathy Krishnamurthiu,
Fan Liv, Hongchao Lik, Junbo Lih, Xiaomeng Lian, John Lowengrubbn,bo,bp, Jun Mabb,
Klaus Maier-Heinbq,br,g, Kevis-Kokitsi Maninisar, Hans Meinebj,bm, Dorit Merhofbv, Akshay Paibt, Mathias
Perslevbt, Jens Petersenbq, Jordi Pont-Tusetar, Jin Qibd, Xiaojuan Qian, Oliver Rippelbv, Karsten Rothau,
Ignacio Sarasuaay,l, Andrea Schenkbj,bk, Zengming Shenbg,bh, Jordi Torresat,aq, Christian Wachingeray,l,a,
Chunliang Wangap, Leon Weningerbv, Jianrong Wuy, Daguang Xubs, Xiaoping Yangbc, Simon Chun-Ho
Yubf, Yading Yuanaz, Miao Yuet, Liping Zhangbf, Jorge Cardosoi, Spyridon Bakass,w,x,
Rickmer Braren†f,l,ad, Volker Heinemann†ag, Christopher Pal†c, An Tang†aa, Samuel Kadoury†c,
Luc Soler†aj, Bram van Ginneken†d, Hayit Greenspan†e, Leo Joskowicz†r, Bjoern Menze†a,b
aDepartment of Informatics, Technical University of Munich, Germany.
bDepartment of Quantitative Biomedicine, University of Zurich, Switzerland.
cEcole Polytechnique de Montr´eal, Canada
dDepartment of Medical Imaging, Radboud University Medical Center, Nijmegen, the Netherlands
eDepartment of Biomedical Engineering, Tel-Aviv University, Israel
fGerman Cancer Consortium (DKTK)
gPattern Analysis and Learning Group, Department of Radiation Oncology, Heidelberg University Hospital, Heidelberg,
hPhilips Research China, Philips China Innovation Campus, Shanghai, China
iSchool of Biomedical Engineering & Imaging Sciences, King′s College London, London, UK
jInstitute for AI in Medicine, Technical University of Munich, Germany
kDepartment of Computer Science, Guangdong University of Foreign Studies, China
lInstitute for diagnostic and interventional radiology, Klinikum rechts der Isar, Technical University of Munich, Germany
mInstitute for diagnostic and interventional neuroradiology, Klinikum rechts der Isar,Technical University of Munich,
nDepartment of Hepatobiliary Surgery, the Aﬃliated Drum Tower Hospital of Nanjing University Medical School, China.
oDepartment of Computing, Imperial College London, London, United Kingdom
pInstitute for Tissue Engineering and Regenerative Medicine, Helmholtz Zentrum M¨unchen, Neuherberg, Germany
qBrigham and Women’s Hospital, Harvard Medical School, USA
rSchool of Computer Science and Engineering, the Hebrew University of Jerusalem, Israel
sCenter for Biomedical Image Computing and Analytics (CBICA), University of Pennsylvania, PA, USA
tCGG Services (Singapore) Pte. Ltd., Singapore
uMedical Imaging and Reconstruction Lab, Department of Engineering Design, Indian Institute of Technology Madras, India
vSensetime, Shanghai, China
wDepartment of Radiology, Perelman School of Medicine, University of Pennsylvania, USA
xDepartment of Pathology and Laboratory Medicine, Perelman School of Medicine, University of Pennsylvania, PA, USA
yTencent Healthcare (Shenzhen) Co., Ltd, China
zThe University of Montr´eal Hospital Research Centre (CRCHUM) Montr´eal, Qu´ebec, Canada
aaDepartment of Radiology, Radiation Oncology and Nuclear Medicine, University of Montr´eal, Canada
abInstitute of Control Engineering, Technische Universit¨at Braunschweig, Germany
† Organization team and data contributor.
∗Patrick Bilic, Patrick Christ, Hongwei Bran Li, and Eugene Vorontsov made equal contributions to this work.
 
acDepartment of Medicine III, University Hospital, LMU Munich, Munich, Germany
adComprehensive Cancer Center Munich, Munich, Germany
aeDepartment of General, Visceral and Transplantation Surgery, University Hospital, LMU Munich, Germany
afDepartment of Radiology, University Hospital, LMU Munich, Germany
agDepartment of Hematology/Oncology & Comprehensive Cancer Center Munich, LMU Klinikum Munich, Germany
ahPolytechnique Montr´eal, Mila, QC, Canada
aiDepartment of Diagnostic Radiology, Sheba Medical Center, Tel Aviv university, Israel
ajDepartment of Surgical Data Science, Institut de Recherche contre les Cancers de l’Appareil Digestif (IRCAD), France
akRafael Advanced Defense System, Israel
alDepartment of Radiology, Hadassah University Medical Center, Jerusalem, Israel
amDepartment of Computer Science and Engineering, The Hong Kong University of Science and Technology, China
anDepartment of Electrical and Electronic Engineering, The University of Hong Kong, China
aoDepartment of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China
apDepartment of Biomedical Engineering and Health Systems, KTH Royal Institute of Technology, Sweden
aqBarcelona Supercomputing Center, Barcelona, Spain
arEidgen¨ossische Technische Hochschule Zurich (ETHZ), Zurich, Switzerland
asSignal Theory and Communications Department, Universitat Politecnica de Catalunya, Catalonia/Spain
atUniversitat Politecnica de Catalunya, Catalonia/Spain
auUniversity of Tuebingen, Germany
avMannheim Institute for Intelligent Systems in Medicine, department of Medicine Mannheim, Heidelberg University
awInterdisciplinary Center for Scientiﬁc Computing (IWR), Heidelberg University
axCentral Institute for Computer Engineering (ZITI), Heidelberg University
ayDepartment of Child and Adolescent Psychiatry, Ludwig-Maximilians-Universit¨at, Munich ,Germany
azDepartment of Radiation Oncology, Icahn School of Medicine at Mount Sinai, New York, USA
baDepartment of Radiology, Samsung Medical Center, Sungkyunkwan University School of Medicine, Korea
bbDepartment of Mathematics, Nanjing University of Science and Technology, China
bcDepartment of Mathematics, Nanjing University, China
bdSchool of Information and Communication Engineering, University of Electronic Science and Technology of China, China
beHelmholtz AI, Helmholtz Zentrum M¨unchen, Neuherberg, Germany
bfDepartment of Imaging and Interventional Radiology, Chinese University of Hong Kong, Hong Kong, China
bgBeckman Institute, University of Illinois at Urbana-Champaign, USA
bhSiemens Healthineers, USA
biSchool of Computer Science, the University of Sydney
bjFraunhofer MEVIS, Bremen, Germany
bkInstitute for Diagnostic and Interventional Radiology, Hannover Medical School, Hannover, Germany
blDiagnostic Image Analysis Group, Radboud University Medical Center, Nijmegen, The Netherlands
bmMedical Image Computing Group, FB3, University of Bremen, Germany
bnDepartments of Mathematics, Biomedical Engineering, University of California, Irvine, USA
boCenter for Complex Biological Systems, University of California, Irvine, USA
bpChao Family Comprehensive Cancer Center, University of California, Irvine, USA
bqDivision of Medical Image Computing, German Cancer Research Center (DKFZ), Heidelberg, Germany
brHelmholtz Imaging, Germany
bsNVIDIA, Santa Clara, CA, USA
btDepartment of Computer Science, University of Copenhagen, Denmark
buKakao Brain, Korea
bvInstitute of Imaging & Computer Vision, RWTH Aachen University, Germany
bwShenzhen Institute of Advanced Technology, Chinese Academy of Sciences
bxDepartment of Radincology and Radiation Theraphy , Klinikum rechts der Isar, Technical University of Munich, Germany
byDepartment of computer science, UNC Chapel Hill, USA
bzTranslaTUM - Central Institute for Translational Cancer Research, Technical University of Munich, Germany
In this work, we report the set-up and results of the Liver Tumor Segmentation Benchmark (LiTS), which was
organized in conjunction with the IEEE International Symposium on Biomedical Imaging (ISBI) 2017 and
the International Conferences on Medical Image Computing and Computer-Assisted Intervention (MICCAI)
2017 and 2018. The image dataset is diverse and contains primary and secondary tumors with varied sizes
and appearances with various lesion-to-background levels (hyper-/hypo-dense), created in collaboration
with seven hospitals and research institutions. Seventy-ﬁve submitted liver and liver tumor segmentation
algorithms were trained on a set of 131 computed tomography (CT) volumes and were tested on 70 unseen
test images acquired from diﬀerent patients.
We found that not a single algorithm performed best for
both liver and liver tumors in the three events. The best liver segmentation algorithm achieved a Dice
score of 0.963, whereas, for tumor segmentation, the best algorithms achieved Dices scores of 0.674 , 0.702 , and 0.739 . Retrospectively, we performed additional analysis
on liver tumor detection and revealed that not all top-performing segmentation algorithms worked well
for tumor detection. The best liver tumor detection method achieved a lesion-wise recall of 0.458 , 0.515 , and 0.554 , indicating the need for further research. LiTS
remains an active benchmark and resource for research, e.g., contributing the liver-related segmentation
tasks in In addition, both data and online evaluation are accessible via
www.lits-challenge.com.
Segmentation, Liver, Liver tumor, Deep learning, Benchmark, CT
This is a pre-print of the journal article published in Medical Image Analysis.
If you wish to
cite this work, please cite its journal version available here: 
2022.102680. This work is available under CC-BY-NC-ND license.
1. Introduction
Background. The liver is the largest solid organ in the human body and plays an essential role in metabolism
and digestion. Worldwide, primary liver cancer is the second most common fatal cancer (Stewart & Wild,
Computed tomography (CT) is a widely used imaging tool to assess liver morphology, texture,
and focal lesions . Anomalies in the liver are essential biomarkers for initial disease
diagnosis and assessment in both primary and secondary hepatic tumor disease .
The liver is a site for primary tumors that start in the liver. In addition, cancer originating from other
abdominal organs, such as the colon, rectum, and pancreas, and distant organs, such as the breast and lung,
often metastasize to the liver during disease. Therefore, the liver and its lesions are routinely analyzed for
comprehensive tumor staging. The standard Response Evaluation Criteria in Solid Tumor (RECIST) or
modiﬁed RECIST protocols require measuring the diameter of the largest target lesion . Hence, accurate and precise segmentation of focal lesions is required for cancer diagnosis, treatment
planning, and monitoring of the treatment response. Speciﬁcally, localizing the tumor lesions in a given
image scan is a prerequisite for many treatment options such as thermal percutaneous ablation , radiotherapy, surgical resection and arterial embolization . Like many other medical imaging applications, manual delineation of the target lesion in 3D CT scans
 
November 28, 2022
Figure 1: Example from the LiTS dataset depicting a variety of shapes of on contrast-enhanced abdominal CT scans acquired.
While most exams in the dataset contain only one lesion, a large group of patients with some (2-7) or many (10-12) lesions, as
shown in the histogram calculated over the whole dataset.
is time-consuming, poorly reproducible and segmentation shows operator-dependent
Technical challenges. Fully automated segmentation of the liver and its lesions remain challenging in many
aspects. First, the variations in the lesion-to-background contrast can be caused by:
a) varied contrast agents, b) variations in contrast enhancement due to diﬀerent injection timing, and c)
diﬀerent acquisition parameters (e.g., resolution, mAs and kVp exposure, reconstruction kernels). Second,
the coexistence of diﬀerent types of focal lesions (benign vs. malignant and tumor sub-types) with varying
image appearances presents an additional challenge for automated lesion segmentation. Third, the liver
tissue background signal can vary substantially in the presence of chronic liver disease, which is a common
precursor of liver cancer.
It is observed that many algorithms struggle with disease-speciﬁc variability,
including the diﬀerences in size, shape, and the number of lesions, as well as with modiﬁcations in shape and
appearance to the liver organ itself induced by treatment . Examples of diﬀerences
in liver and tumor appearance in two patients are depicted in Figure 1, demonstrating the challenges of
generalizing to unseen test cases with varying lesions.
Contributions. In order to evaluate the state-of-the-art methods for automated liver and liver tumor segmentation, we organized the Liver Tumor Segmentation Challenge (LiTS) in three events: 1) in conjunction
with the IEEE International Symposium on Biomedical Imaging (ISBI) 2017, 2) with MICCAI 2017 and 3)
as a dedicated challenge task on liver and liver tumor segmentation in the Medical Segmentation Decathlon
2018 in MICCAI 2018 .
In this paper, we describe the three key contributions to fully automated liver and liver tumor segmentation. First, we generate a new public multi-center dataset of 201 abdominal CT Volumes and the
reference segmentations of liver and liver tumors. Second, we present the set-up and the summary of our
LiTS benchmarks in three grand challenges. Third, we review, evaluate, rank, and analyze the resulting
state-of-the-art algorithms and results. The paper is structured as follows: Section II reviews existing public
datasets and state-of-the-art automated liver and liver tumors segmentation. Next, Section III describes
the LiTS challenge setup, the released multi-center datasets, and the evaluation process. Section IV reports results, analyzes the liver tumor detection task, showcases critical cases in the LiTS Challenge results,
and discusses the technical trends and challenges in liver tumor segmentation.
Section V discusses the
limitations, summarizes this work, and points to future work.
Table 1: Overview of publicly available medical datasets of liver and liver tumor images. The LiTS dataset oﬀers a comparably
large amount of 3D scans, including liver and liver tumor annotations.
Institution
Segmentation
TCGA-LIHC 
CT, MR, PT
MIDAS 
3Dircadb-01 and 3Dircadb-02 
SLIVER’07 
LTSC’08 
ImageCLEF’15 
Bogazici Uni.
VISCERAL’16 
Uni. of Geneva
CHAOS’19 
Dokuz Eylul Uni.
2. Prior Work: Datasets & Approaches
2.1. Publicly available liver and liver tumor datasets.
Compared to other organs, available liver datasets oﬀer either a relatively small number of images and
reference segmentation or provide no reference segmentation (see Table 1). The ﬁrst grand segmentation
challenge - SLIVER07 was held in MICCAI 2007 , including the 30 CT liver images
for automated segmentation. In MICCAI 2008, the LTSC’08 segmentation challenge oﬀered 30 CT volumes
with a focus on tumor segmentation . The ImageCLEF 2015 liver CT reporting benchmark 1 made 50 volumes available for computer-aided structured reporting instead of segmentation. The
VISCERAL challenge provided 60 scans per two modalities (MRI and CT)
for anatomical structure segmentation and landmark detection. The recent CHAOS challenge provide 40 CT volumes and 120 MRI volumes for healthy abdominal organ segmentation. However,
1 
none of these datasets represents well-deﬁned cohorts of patients with lesions, and segmentation of the liver
and its lesions are absent.
2.2. Approaches for liver and liver tumour segmentation
Before 2016, most automated liver and tumor segmentation methods used traditional machine learning
methods. However, since 2016 and the ﬁrst related publications at MICCAI (Christ et al.), deep learning
methods have gradually become a methodology of choice. The following section provides an overview of
published automated liver and liver tumor segmentation methods.
2.2.1. Liver segmentation
Published work on liver segmentation methods can be grouped into three categories based on: (1) prior
shape and geometric knowledge, (2) intensity distribution and spatial context, and (3) deep learning.
Methods based on shape and geometric prior knowledge. Over the last two decades, statistical shape models
(SSMs) have been used for automated liver segmentation tasks. However, deformation
limitations prevent SSMs from capturing the high variability of the liver shapes. To overcome this issue, SSM
approaches often rely on additional steps to obtain a ﬁner segmentation contour. Therefore SSMs followed
by a deformable model performing free form deformation became a valuable method for liver segmentation
 , incorporating non-rigid template matching , initialization of SSMs utilizing an evolutionary algorithm , hierarchical SSMs
 , and deformable SSMs had been proposed to solve liver segmentation
tasks automatically. SSMs-based methods showed the best results in SLIVER07, the ﬁrst grand challenge
held in MICCAI 2007 .
Methods based on intensity distribution and spatial context. A probabilistic atlas (PA) is an anatomical atlas
with parameters that are learned from a training dataset. Park et al. proposed the ﬁrst PA utilizing 32
abdominal CT series for registration based on mutual information and thin-plate splines as warping transformations and a Markov random ﬁeld (MRF) for segmentation. Further
proposed atlas-based methods diﬀer in their computation of the PA and how the PA is incorporated into the
segmentation task. Furthermore, PA can incorporate relations between adjacent abdominal structures to
deﬁne an anatomical structure surrounding the liver . Multi-atlas methods improved liver
segmentation results by using non-rigid registration with a B-spline transformation model , dynamic atlas selection and label fusion , or liver and non-liver voxel classiﬁcation
based on k-Nearest Neighbors .
Graph cut methods oﬀer an eﬃcient way to binary segmentation problems, initialized by adaptive thresholding and supervoxel .
Methods based on deep learning. In contrast to the methods above, deep learning, especially convolutional
neural networks (CNN), is a data-driven method that can be optimized end-to-end without hand-craft
feature engineering . The U-shape CNN architecture and
its variants are widely used for biomedical
image segmentation and have already proven their eﬃciency and robustness in a wide range of segmentation
tasks. Top-performing methods share the commonality of multi-stage processes, beginning with a 3D CNN
for segmentation, and post-process the resulting probability maps with Markov random ﬁeld . Many early deep learning algorithms for liver segmentation combine neural networks with dedicated
post-processing routines: Christ et al. uses 3D fully connected neural networks combined with conditional
random ﬁelds, Hu et al. rely on a 3D CNN followed by a surface model. In contrast, Lu et al. 
use a CNN regularized by a subsequent graph-cut segmentation.
2.2.2. Liver tumor segmentation
Compared to the liver, its lesions feature a more comprehensive range of shape, size, and contrast. Liver
tumors can be found in almost any location, often with ambiguous boundaries. Diﬀerences in the uptake
of contrast agents may introduce additional variability. Therefore liver tumor segmentation is considered to
be the more challenging task. Published methods of liver tumor segmentation can be categorized into 1)
thresholding and spatial regularization, 2) local features and learning algorithms, and 3) deep learning.
Methods with thresholding and spatial regularization. Based on the assumption that gray level values of
tumor areas diﬀer from pixels/voxels belonging to regions outside the tumor, thresholding is a simple yet
eﬀective tool to automatically separate tumor from liver and background, ﬁrst shown by Soler et al. .
Since then the threshold have set by histogram analysis ,
maximum variance between classes and iterative algorithm to improve tumor segmentation results.
Spatial regulation techniques rely on (prior) information
about the image or morphologies, e.g., tumor size, shape, surface, or spatial information. This knowledge is
used to introduce constraints in the form of regularization or penalization. Adaptive thresholding methods
can be combined with model-based morphological processing for heterogeneous lesion segmentation . Active contour based tumor segmentation relies on shape and surface
information and utilize probabilistic models or histogram analysis to create segmentation maps automatically. Level set methods allow
numerical computations of tumor shapes without parametrization. Level set approaches for liver tumor
segmentation are combined with supervised pixel/voxel classiﬁcation in 2D and 3D
 .
Methods using local features and learning algorithms. Clustering methods include k-means and fuzzy c-means clustering with segmentation reﬁnement using deformable models . Among supervised classiﬁcation methods are a fuzzy classiﬁcation based level set approach , support vector machines in combination with a texture based deformable surface model for
segmentation reﬁnement , AdaBoost trained on texture features and image intensity proﬁles , logistic regression , and random forests
recursively classifying and decomposing supervoxels .
Methods based on deep learning. Before LiTS, deep learning methods have been rarely used for liver tumor
segmentation tasks. Christ et al. was the ﬁrst to use 3D U-Net for liver and liver tumor segmentation,
proposing a cascaded segmentation strategy, together with a 3D conditional random ﬁeld reﬁnement. Many
of the subsequent deep learning approaches were developed and tested in conjunction with the LiTS dataset.
Beneﬁting from the availability of the LiTS public dataset, many new deep learning solutions on liver
and liver segmentation were proposed.
U-Net-based architectures are extensively used and modiﬁed to
improve segmentation performance. For example, the nn-UNet ﬁrst presented in LiTS
at MICCAI 2018, was shown to be one of the most top-performing methods in 3D image segmentation tasks.
The related works will be discussed in the results section.
3. Methods
3.1. Challenge setup
The ﬁrst LiTS benchmark was organized in Melbourne, Australia, on April 18, 2017, in a workshop
held at the IEEE ISBI 2017 conference.
During Winter 2016/2017, participants were solicited through
private emails, public email lists, social media, and the IEEE ISBI workshop announcements. Participants
were requested to register at our online benchmarking system hosted on CodaLab and could download
annotated training data and unannotated test data.
The online benchmarking platform automatically
computed performance scores. They were asked to submit a four-page summary of their algorithm after
successful submissions to the CodaLab platform. Following the successful submission process at ISBI 2017,
the second LiTS benchmark was held on September 14, 2017, in Quebec City, Canada, as a MICCAI
workshop. The third edition of LiTS was a part of the Medical Segmentation Decathlon at MICCAI 2018
(available at 
At ISBI 2017, ﬁve out of seventeen participating teams presented their methods at the workshop. At
MICCAI 2017, the LiTS challenge introduced a new benchmark task - liver segmentation. Participants
registered a new CodaLab benchmark and were asked to describe their algorithm after the submission
deadline, resulting in 26 teams. The training and test data for the benchmark were identical to the ISBI
benchmark. The workshop at the MICCAI 2017 was organized similarly to the ISBI edition. At MICCAI
2018, LiTS was a part of a medical image segmentation decathlon organized by King’s College London in
conjunction with eleven partnerships for data donation, challenge design, and administration. The LiTS
benchmark dataset described in this paper constitutes the decathlon’s liver and liver lesion segmentation
tasks. However, the overall challenge also required the participants to address nine other tasks, including
brain tumor, heart, hippocampus, lung, pancreas, prostate, hepatic vessel, spleen, and colon segmentation.
To this end, algorithms were not necessarily optimized only for liver CT segmentation.
3.2. Dataset
Training and test cases both represented abdomen CT images. The data is licensed as CC BY-NC-SA.
Only the organizers from TUM have access to the labels of test images. The participants could download
annotated training data from the LiTS Challenge website 2.
Contributors. The image data for the LiTS challenge are collected from seven clinical sites all over the
world, including a) Rechts der Isar Hospital, the Technical University of Munich in Germany, b) Radboud
University Medical Center, the Netherlands, c) Polytechnique Montr´eal and CHUM Research Center in
Canada, d) Sheba Medical Center in Israel, e) the Hebrew University of Jerusalem in Israel, f) Hadassah
University Medical Center in Israel, and g) IRCAD in France. The distribution of the number of scans per
institution is described in Table 2. The LiTS benchmark dataset contains 201 computed tomography images
of the abdomen, of which 194 CT scans contain lesions. All data are anonymized, and the images have been
reviewed visually to preclude the presence of personal identiﬁers. The only processing applied to the images
is a transformation into a uniﬁed NIFTY format using NiBabel in Python 3. All parties agreed to make the
data publicly available; ethics approval was not required.
Data diversity. The studied cohort covers diverse types of liver tumor diseases, including primary tumor
disease (such as hepatocellular carcinoma and cholangiocarcinoma) and secondary liver tumors (such as
metastases from colorectal, breast and lung primary cancers). The tumors had varying lesion-to-background
ratios (hyper- or hypo-dense). The images represented a mixture of pre- and post-therapy abdominal CT
scans and were acquired with diﬀerent CT scanners and acquisition protocols, including imaging artifacts
(e.g., metal artifacts) commonly found in real-world clinical data. Therefore, it was considered to be very
diverse concerning resolution and image quality. The in-plane image resolution ranges from 0.56 mm to 1.0
2www.lits-challenge.com
3 
Table 2: Distribution of the number of scans per institution in the train and test in the LiTS dataset.
Institutions
Rechts der Isar Hospital, TUM, Germany
Radboud University Medical Center, the Netherlands
Polytechnique Montreal and CHUM Research Center in Canada
IRCAD, France
Sheba Medical Center
Hebrew University of Jerusalem
Hadassah University
Table 3: The characteristics of the LiTS training and test sets. The median values and the interquartile range (IQR) are
shown for each parameter. In addition, P-values were obtained by Mann-whitney u test, describing the signiﬁcance between
the training set and test set shown in the last column. An alpha level of 0.05 was chosen to determine signiﬁcance.
In-plane resolution (mm)
0.76 (0.7, 0.85)
0.74 (0.69, 0.8)
Slice thickness (mm)
1.0 (0.8, 1.5)
1.5 (0.8, 4.0)
Volume size
512×512×432
(512×512×190 , 512×512×684)
512×512×270
(512×512×125 , 512×512×622)
Number of tumors
Tumor volume (mm3)
16.11 × 103
(3.40 × 103, 107.77 × 103)
34.78 × 103
(10.41 × 103, 98.90 × 103)
Liver volume (mm3)
1586.48 × 103 ± 447.14 × 103
(1337.75 × 103, 1832.46 × 103)
1622.64 × 103 ± 546.48 × 103
 
mm, and 0.45 mm to 6.0 mm in slice thickness. Also, the number of axial slices ranges from 42 to 1026.
The number of tumors varies between 0 and 12. The size of the tumors varies between 38 mm3 and 1231
mm3. The test set shows a higher number of tumor occurrences compared to the training set. The statistical
test (p-value=0.6) shows that the liver volumes in the training and test sets do not diﬀer signiﬁcantly. The
average tumor HU value is 65 and 59 in the train and test sets, respectively. The LiTS data statistics are
summarized in Table 3. The training and test split is with a ratio of 2:1 and the training and test sets were
similar in center distribution. Generalizability to unseen centers has, hence, not been tested in LiTS.
Annotation protocol. The image datasets were annotated manually using the following strategy: A radiologist with >3 years of experience in oncologic imaging manually labelled the datasets slice-wise using the
ITK-SNAP software and assigning one of the labels ’Tumor’ or ’Healthy Liver’.
Here, the “Tumor” label included any neoplastic lesion irrespective of origin (i.e. both primary liver tumors
and metastatic lesions). Any part of the image not assigned one of the aforementioned labels was considered
’Background’. The segmentations were veriﬁed by three further readers blinded to the initial segmentation,
with the most senior reader serving as tie-breaker in cases of labelling conﬂicts. Those scans with very small
and uncertain lesion-like structures were omitted in the annotation.
3.3. Evaluation
3.3.1. Ranking strategy
The main objective of LiTS was to benchmark segmentation algorithms. We assessed the segmentation
performance of the LiTS submissions considering three aspects: a) volumetric overlap, b) surface distance,
and c) volume similarity. All the values of these metrics are released to the participating teams. Considering
that the volumetric overlap is our primary interest in liver and liver tumor segmentation, for simplicity, we
only use the Dice score to rank the submissions at ISBI-2017 and MICCAI-2017. However, the exact choice
of evaluation metric does sometimes aﬀect the ranking results, as diﬀerent metrics are sensitive to diﬀerent
types of segmentation errors. Hence, we provide a post-challenge ranking, considering three properties by
summing up three ranking scores and re-ranking by the ﬁnal scores. The evaluation codes for all metrics
can be accessed in Github 4.
3.3.2. Statistical tests
To compare the submissions from two teams in a per case manner, we used Wilcoxon signed-rank test
 . To compare the distributions of submissions from two years, we used the Mann-
Whitney U Test (unpaired) for the two groups.
3.3.3. Segmentation metrics
Dice score. The Dice score evaluates the degree of overlap between the predicted and reference segmentation
masks. For example, given two binary masks A and B, it is formulated as:
Dice(A, B) = 2|A ∩B|
The Dice score is applied per case and then averaged over all cases consistently for three benchmarks.
This way, the Dice score applies a higher penalty to prediction errors in cases with fewer actual lesions.
Average symmetric surface distance. Surface distance metrics are correlated measures of the distance between the surfaces of a reference and the predicted region. Let S(A) denote the set of surface voxels of A.
Then, the shortest distance of an arbitrary voxel v to S(A) is deﬁned as:
d(v, S(A)) =
sA∈S(A) ||v −sA||,
where ||.|| denotes the Euclidean distance. The average symmetric surface distance (ASD) is then given
ASD(A, B) =
|S(A)| + |S(B)|
d(sA, S(B)) +
d(sB, S(A))
4 
Maximum symmetric surface distance. The maximum symmetric surface distance (MSSD), also known as
the Symmetric HausdorﬀDistance, is similar to ASD except that the maximum distance is taken instead of
the average:
MSSD(A, B) = max
sA∈S(A) d(sA, S(B)),
sB∈S(B) d(sB, S(A))
Relative volume diﬀerence. The relative volume diﬀerence (RVD) directly measures the volume diﬀerence
without considering the overlap between reference A and the prediction B.
RV D(A, B) = |B| −|A|
For the other evaluation metrics, such as tumor burden estimation and the corresponding rankings,
please check the Appendix.
3.3.4. Detection metrics
Considering the clinical relevance of lesion detection, we introduce three detection metrics in the additional analysis. The metrics are calculated globally to avoid potential issues when the patient has no
tumors. There must be a known correspondence between predicted and reference lesions to evaluate the
lesion-wise metrics. Since lesions are all deﬁned as a single binary map, this correspondence must be determined between the prediction and reference masks’ connected components. Components may not necessarily
have a one-to-one correspondence between the two masks. The details of the correspondence algorithm are
presented in Appendix C.
Individual lesions are deﬁned as 3D connected components within an image.
A lesion is considered
detected if the predicted lesion has suﬃcient overlap with its corresponding reference lesion, measured
as the intersection over the union of their respective segmentation masks. It allows for a count of true
positive, false positive, and false-negative detection, from which we compute the precision and recall of
lesion detection. The metrics are deﬁned as follows:
Individual lesions are deﬁned as 3D connected components within an image.
A lesion is considered
detected if the predicted lesion has suﬃcient overlap with its corresponding reference lesion, measured
as the intersection over the union of their respective segmentation masks. It allows for a count of true
positive, false positive, and false-negative detection, from which we compute the precision and recall of
lesion detection. The metrics are deﬁned as follows:
IoU = |A ∩B|
Precision. It relates the number of true positives (TP) to false positives (FP), also known as positive
predictive value:
precision =
Recall. It relates the number of true positives (TP) to false negatives (FN), also known as sensitivity or
true positive rate:
F1 score. It measures the harmonic mean of precision and recall:
precision−1 + recall−1 .
3.3.5. Participating policy and online evaluation platform
The participants were allowed to submit three times per day in the test stage during the challenge week.
Members of the organizers’ groups could participate but were not eligible for awards. The awards were given
to the top three teams for each task. The top three performing methods gave 10-min presentations and were
announced publicly. For a fair comparison, the participating teams were only allowed to use the released
training data to optimize their methods. All participants were invited to be co-authors of the manuscript
summarizing the challenge.
A central element of LiTS was - and remains to be - its online evaluation tool hosted by CodaLab.
On Codalab, participants could download annotated training and ”blinded” test data and upload their
segmentation for the test cases.
The system automatically evaluated the uploaded segmentation maps’
performance and made the overall performance available to the participants. Average scores for the diﬀerent
liver and lesion segmentation tasks and tumor burden estimation were also reported online on a leaderboard.
Reference segmentation ﬁles for the LiTS test data were hosted on the Codalab but not accessible to
participants. Therefore, the users uploaded their segmentation results through a web interface, reviewed
the uploaded segmentation, and then started an automated evaluation process. The evaluation to assess the
segmentation quality took approximately two minutes per volume. In addition, the overall segmentation
results of the evaluation were automatically published on the Codalab leaderboard web page and could be
downloaded as a csv ﬁle for further statistical analysis.
The Codalab platform remained open for further use after the three challenges and will remain so in
the future.
As of April 2022, it has evaluated more than 3,414 valid submissions (238,980 volumetric
segmentation) and recorded over 900 registered LiTS users. The up-to-date ranking is available at Codalab
for researchers to continuously monitor new developments and streamline improvements. In addition, the
code to generate the evaluation metrics between reference and predictions is available as open-source at
5 
4. Results
4.1. Submitted algorithms and method description
The submitted methods in ISBI-2017, MICCAI-2017 and MICCAI-2018 are summarized in Table 4 and
Table 5, and the reference paper of Medical Segmentation Decathlon . In the following,
we grouped the algorithms with several properties.
Algorithms and architectures. Seventy-three submissions were fully automated approaches, while only one
was semi-supervised (
J. Ma et al.). U-Net derived architectures were overwhelmingly used in the challenge
with only two automated methods using a modiﬁed VGG-net (
J. Qi et al.) and a k-CNN (
J. Lipkova
et al.) respectively. Most submissions adopted the coarse-to-ﬁne approach in which multiple U-nets were
cascaded to perform liver and liver segmentation at diﬀerent stages. Additional residual connections and
adjusted input resolution were the most common changes to the basic U-Net architecture. Three submissions
combined individual models as an ensemble technique. In 2017, 3D methods were not directly employed
on the original image resolution by any of the submitted methods due to high computational complexity.
However, some submissions used 3D convolutional neural networks solely for tumor segmentation tasks with
small input patches. Instead of full 3D, other methods tried to capture the advantages of three-dimensionality
by using a 2.5 D model architecture, i.e., providing a stack of images as a multi-channel input to the network
and receiving the segmentation mask of the center slice of this stack as a network output.
Critical components of the segmentation methods. Data pre-processing with HU-value clipping, normalization, and standardization were the most frequent techniques in most of the methods. Data augmentation was
also widely used and mainly focused on standard geometric transformations such as ﬂipping, shifting, scaling,
or rotation. Individual submissions implemented more advanced techniques such as histogram equalization
and random contrast normalization. The most common optimizer varied between ADAM and Stochastic
gradient descent with momentum, with one approach relying on RMSProp. Multiple loss functions were
used for training, including standard and class-weighted cross-entropy, Dice loss, Jaccard loss, Tversky loss,
L2 loss, and ensemble loss techniques combining multiple individual loss functions into one.
Post-processing. Some types of post-processing methods were also used by the vast majority of the algorithm.
The common post-processing steps were to form connected tumor components and overlay the liver mask
on the tumor segmentation to discard tumors outside the liver region. More advanced methods included
a random forest classiﬁer, morphological ﬁltering, a particular shallow neural network to eliminate false
positives or custom algorithms for tumor hole ﬁlling.
Features of top-performing methods. The best-performing methods at ISBI 2017 used cascaded U-Net approaches with short and long skip connections and 2.5D input images (
X. Han et al.).
In addition,
weighted cross-entropy loss functions and a few ensemble learning techniques were employed by most of the
top-performing methods, together with some common pre- and post-processing steps such as HU-value clipping and connected component labeling, respectively. Some top-performing submissions at MICCAI 2017
J. Zou) integrated the insights from the ISBI 2017, including the idea of the ensemble, adding residual connections, and featuring more sophisticated rule-based post-processing or classical machine learning
algorithms. Therefore, the main architectural diﬀerences compared to the ISBI submissions were the higher
usage of ensemble learning methods, a higher incidence of residual connections, and an increased number
of more sophisticated post-processing steps. Another top-performing method by
X. Li et al. proposed a
hybrid insight by integrating the advantages of the 2D and 3D networks in the 3D liver tumor segmentation
task . Therefore, compared to the methods in ISBI submissions that solely rely on 2D or
3D convolutions, the main architecture diﬀerence was the hybrid usage of 2D and 3D networks. In MICCAI-
LiTS 2018, 3D deep learning models became popular and generally outperformed 2.5D or 2D without more
sophisticated pre-processing steps.
Table 4: Details of the participating teams’ methods in LiTS-ISBI-2017.
Lead Author &
Team Members
Method, Architecture &
Modiﬁcations
Data Augmentation
Loss Function
Optimizer Training
Pre-processing
Post-processing
Ensemble strategy
Residual U-Net with 2.5D
input (a stack of 5 slices)
cropping, flipping
weighted cross-entropy
SGD with momentum
Value-clipping to
[-200, 200]
Connected components with
maximum probability below
0.8 were removed
E. Vorontsov;
A. Tang, C. Pal,
S. Kadoury
Liver FCN provides pre-trained weights
for tumour FCN. Trained on 256×256,
finetuned on 512×512.
Random flips, rotations,
zooming, elastic
deformations.
largest connected
component for liver
Ensemble of three models
G. Chlebus;
J. H. Moltz,
Liver: 3 orthogonal 2D U-nets working
on four resolution levels.
Tumor: 2D U-net working on four
resolution levels
Mannual removal of cases
with flawed reference
segmentation
Liver: resampling to
isotropic 2 mm voxels.
Tumor candidate filtering
based on RF-classifier to
remove false positives
For liver: majority vote
Jinman Kim
Cascaded ResNet based on a
pre-trained FCN on 2D axial slices.
Random scaling,
crops and flips
cross-entropy
Value-clipping to
[-160, 240]
Morphological filter
to fill the holes
Multi-scale ensembling by
averaging the outputs from.
different inputs sizes.
Cascaded 2D U-Net in
three orthogonal views
Random rotation,
random translation,
and scaling
Cascaded U-Net
mirror, cropping,
additional noise
weighted cross-entropy
SGD with momentum
3D Conditional Random Field
J. Lipkova;
M. Rempfler,
J. Lowengrub,
U-Net for liver segmentation
and Cahn-Hilliard Phase field
separation for lesions
Liver:cross-entropy;
Tumor: Energy function
Y. Li, Y. Wu,
M. Zhang, X. Yang
Random Forest and
Fuzzy Clustering
Value-clipping to
[-160, 240] and intensity
normalization to 
T. Konopczynski;
K. Roth, J. Hesser
Dense 2D U-Nets (Tiramisu)
Soft Tversky-Coefficient
based Loss function
Value-clipping to
[-100, 400]
M. Bellver;
K. Maninis, J. Tuset,
X. Giro-i-Nieto,
Cascaded FCN with side outputs at
different resolutions.
Three-channel 2D input.
Weighted binary
cross entropy
Value-clipping to
[-150, 250] and intensity
normalization to 
Component analysis to
remove false positives.
A pretrained VGG with
concatenated multi-scale
feature maps
binary cross entropy
Table 5: Details of the participating teams’ methods in LiTS-MICCAI-2017.
Lead Author &
Team Members
Method, Architecture &
Modiﬁcations
Data Augmentation
Loss Function
Optimizer Training
Pre-processing
Post-processing
Ensemble strategy
Hierarchical 2.5D
FCN network
flipping, shifting, rotating,
scaling and random contrast
normalization
Jaccard distance
Clipping HU values
to [-100, 400]
ensembling 5 models
from 5-fold cross validation
A. Ben-Cohen;
VGG-16 as a backbone
and 3-channel input
softmax log loss
Clipping HU values
to [-160, 240]
Cascaded U-Nets
weighted cross-entropy
Clipping HU values
to [-75, 175]
hole filling and
noise removal
ensemble of two model
with different inputs
X. Li, H. Chen,
X. Qi, Q. Dou,
C. Fu, P. Heng
H-DenseUNet
 
rotation, flipping, scaling
Cross-entropy
Clipping HU values
to [-200, 250]
Largest connected
component; hole filling
G. Chlebus;
J. H. Moltz,
Liver: 3 orthogonal 2D U-nets working
on four resolution levels.
Tumor: 2D U-net working on four
resolution levels 
Mannual removal of cases
with flawed reference
segmentation
Liver: resampling to
isotropic 2 mm voxels.
Tumor candidate filtering
based on RF-classifier to
remove false positives
For liver: majority vote
Cascade 2D FCN
Cascade 2D U-Net in
three orthogonal views
Random rotation,
random translation,
and scaling
E. Vorontsov;
A. Tang, C. Pal,
S. Kadoury
Liver FCN provides pre-trained weights
for tumour FCN. Trained on 256×256,
finetuned on 512×512.
Random flips, rotations,
zooming, elastic
deformations.
largest connected
component for liver
Ensemble of three models
T. Konopczynski,
2D and 3D U-Net, however with
an iterative Mask Mining process
similar to model boosting
flipping, rotation,
and zooming
Mixture of smooth Dice loss
and weighted cross-entropy
Clipping HU values
to [-100, 600]
Residual U-Net with 2.5D
input (a stack of 5 slices)
cropping, flipping
weighted cross-entropy
Value-clipping to
[-200, 200]
Connected components with
maximum probability below
0.8 were removed
J. Lipkova;
M. Rempfler,
J. Lowengrub
U-Net for liver segmentation
and Cahn-Hilliard Phase field
separation for lesions
Liver:cross-entropy;
Tumor: Energy function
Jinman Kim
Cascaded ResNet based on a
pre-trained FCN on 2D axial slices.
Random scaling,
crops and flips
cross-entropy
Value-clipping to
[-160, 240]
Morphological filter
to fill the holes
Multi-scale ensembling by
averaging the outputs from.
different inputs sizes.
M. Piraud;
A. Sekuboyina,
U-Net with a double
sigmoid activation
weighted cross-entropy
Value-clipping to
[-100, 400];
intensity normalization
Y. Li, Y. Wu,
M. Zhang, X. Yang
Label propogation
(Interactive method)
Value-clipping to
[-100, 400];
intensity normalization
Context-aware PolyUNet with
zooming out/in and two-stage
strategy 
Weighted cross-entropy
Value-clipping to
[-200, 300]
largest connected component
4.2. Results of inidividual challenges
At ISBI 2017 and MICCAI 2017, the LiTS challenges received 61 valid submissions and 32 contributing
short papers as part of the two workshops. At MICCAI 2018, LiTS was held as part of the Medical Segmentation Decathlon and received 18 submissions (one of them was excluded from the analysis as requested by
the participating team). In this work, the segmentation results were evaluated based on the same metrics
described to ensure the comparability between the three events. For ISBI 2017, no liver segmentation task
was evaluated. The results of the tumor segmentation task were shown for all the events, i.e., ISBI 2017,
MICCAI 2017, and MICCAI 2018.
4.2.1. Liver segmentation
Overview. The results of the liver segmentation task showed high Dice scores; most teams achieved more
than 0.930. It indicated that solely using the Dice score could not distinguish a clear winner. When we
compared the progress with the two LiTS benchmarks, the results of MICCAI 2017 were slightly better
than the MICCAI-MSD 2018 in terms of ASD (1.104 vs. 1.342). It might be because the algorithms for
MICCAI-MSD were optimized considering their generalizability on diﬀerent organs and imaging modalities.
In contrast, the methods for MICCAI 2017 were speciﬁcally optimized for liver and CT imaging.
ranking result is shown in Table 6.
LiTS–MICCAI 2017. The evaluation of the liver segmentation task relied on the three metrics explained in
the previous chapter, with the Dice score per case acting as the primary metric used for the ﬁnal ranking.
Almost all methods except the last three achieved Dice per case values above 0.920, with the best one scoring
0.963. Ranking positions remain relatively stable when ordering submissions according to the other surface
distance metric. Most methods changed by a few spots, and the top four methods were only interchanging
positions among themselves. The position variation was more signiﬁcant than the Dice score when using
the surface distance metric ASD for the ranking, with some methods moving up to 4 positions. However, on
average, the top-2 performing Dice per case methods still achieved the lowest surface distance values, with
the winning method retaining the top spot in two rankings.
LiTS–MICCAI–MSD 2018. The performance of Decathlon methods in liver segmentation showed similar
results compared to MICCAI 2017.
In both challenges, one could observe that the diﬀerence in Dice
scores between top-performing methods was insigniﬁcant mainly because the liver is a large organ. The
comparison of ASD between MICCAI 2018 and MICCAI 2017 conﬁrmed that state-of-the-art methods
could automatically segment the liver with similar performance to manual expert annotation for most
cases. However, the methods exclusively trained for liver segmentation in MICCAI 2017 showed better
segmentations under challenging cases (1.104 vs. 1.342).
4.2.2. Liver tumor segmentation and detection
Overview. While automated liver segmentation methods showed promising results (comparable to expert
annotation), the liver tumor segmentation task remained room for improvement. To illustrate the diﬃculty
of detecting small lesions, we grouped the lesions into three categories with a clinical standard: a) small
lesions less than 10 mm in diameter, b) medium lesions between 10 mm and 20 mm in diameter, and c)
large lesion bigger than 20 mm in diameter. The ranking result is shown in Table 7.
LiTS–ISBI 2017. The highest Dice scores for liver tumor segmentation were in the middle 0.60s range,
with the winner team achieving a score of 0.674 followed by 0.652 and 0.645 for the second and third
places, respectively. However, there were no statistically signiﬁcant diﬀerences between the top three teams
in all three metrics. The ﬁnal ranking changed to some degree when considering the ASD metric. For
example, Bi et al. obtained the best ASD score but retained its order with the best methods overall. In
lesion detection, we found that detecting small lesions was very challenging in which top-performing teams
achieved only around 0.10 in F1 score. Figure 6 shows some sample results of the top-performing methods.
LiTS–MICCAI 2017. The best tumor segmentation Dice scores improved signiﬁcantly compared to ISBI,
with MICCAI’s highest average Dice (per case) of 0.702 compared to 0.674 in ISBI on the same test set.
However, the ASD metric did not improve (1.189 vs. 1.118) on the best top-performing method. In addition,
there were no statistically signiﬁcant diﬀerences between the top three teams in all three metrics. There
was an overall positive correlation of ranking positions with submissions that performed well at the liver
segmentation task concerning the liver tumor segmentation task. A weak positive correlation between the
Dice ranking and the surface distance metrics could still be observed, although a considerable portion of
methods changes positions by more than a few spots. The detection performance in MICCAI 2017 showed
improvement over ISBI 2017 in lesion recall (0.479 vs. 0.458 for the best team). Notably, the best-performing
J. Zou et al.) achieved a very low precision of 0.148, which indicated that the method generates
many false positives. Figure 7 shows some sample results of the top-performing methods.
LiTS–MICCAI–MSD 2018. The LiTS evaluation of MICCAI 2018 was integrated into MSD and attracted
much attention, receiving 18 valid submissions. Methods were ranked according to two metrics: Dice score
and ASD (in liver and liver tumor segmentation tasks). Compared to MICCAI 2017 and ISBI 2016, the two
top-performing teams signiﬁcantly improved the Dice scores (0.739 and 0.721 vs. 0.702) and ASD (0.903 and
0.896 vs. 1.189). However, there were no statistically signiﬁcant diﬀerences between the top two teams in
all three metrics. The ﬁrst place (F. Isensee et al.) statistically signiﬁcant (p-value < 0.001) outperformed
the third place (S. Chen et al.) considering Dice score. More importantly, the same team won the two tasks
using a self-adapted 3D deep learning solution, indicating a step forward in the development of segmentation
methodology. The detection performance in MICCAI 2018 showed improvement over MICCAI 2017 in lesion
recall (0.554 vs. 0.479 for the best-performing teams).
From the scatter plots shown in Figure 2, we observed that not all the top-performing methods in three
LiTS challenges achieved good scores on tumor detection. The behavior of distance- and overlap-based
metrics was similar. The detection metrics with clinical relevance could prevent the segmentation model
from tending to segment large lesions. Thus it should be considered when ranking participating teams and
performing the comprehensive assessment.
Table 6: Liver segmentation submissions of LiTS–MICCAI 2017 and LiTS–MICCAI–MSD 2018 ranked by Dice score and ASD.
Top-performing teams in liver segmentation tasks are highlighted with blue in each metric. A ranking score follows each metric
value in the bracket. Re-ranking* denotes a post-challenge ranking considering two metrics by averaging the ranking scores.
Notably only Dice and RVD are considered as the volume diﬀerence of the liver is not of interest, as opposed to the liver tumor.
Re-ranking*
LiTS–MICCAI 2017
Y. Yuan et al.
A. Ben-Cohen et al.
J. Zou et al.
X. Li et al.
L. Zhang et al.
G. Chlebus et al.
J. Wu et al.
C. Wang et al.
E. Vorontsov et al.
K. Kaluva et al.
1.880 (10)
K. Roth et al.
1.890 (11)
X. Han et al.
0.943 (10)
2.890 (12)
J. Lipkova et al.
0.938 (11)
3.540 (13)
L. Bi et al.
0.934 (12)
258.598 (15)
M. Piraud et al.
0.767 (13)
37.450 (14)
J. Ma et al.
0.041 (14)
8231.318 (15)
LiTS-MICCAI 2018
F. Isensee et al.
Z. Xu et al.
D. Xu et al.
B. Park et al.
S. Chen et al.
R. Chen et al.
M. Perslev et al.
I. Kim et al.
2.942 (12)
O. Kodym et al.
2.710 (11)
F. Jia et al.
S. Kim et al.
0.934 (10)
6.937 (14)
W. Bae et al.
0.934 (11)
2.615 (10)
Y. Wang et al.
0.926 (12)
I. Sarasua et al.
0.924 (13)
6.273 (13)
O. Rippel et al.
0.904 (14)
16.163 (16)
R. Rezaeifar et al.
0.864 (15)
9.358 (15)
J. Ma et al.
0.706 (16)
159.314 (17)
Meta Analysis
In this section, we focus on liver tumor segmentation and analyze the inter-rater variability and method
development during the last six years.
Table 7: Liver tumor segmentation results of three challenges ranked by segmentation metrics (i.e., Dice, ASD and RVD)
and detection metrics (i.e., precision, recall and separated F1 scores with three diﬀerent sizes of lesion). Each metric value is
followed by a ranking score in the bracket. Top performing teams in tumor segmentation and tumor detection are highlighted
with blue and pink colors in each metric, respectively. Re-ranking* denotes a post-challenge ranking considering three metrics
by averaging the ranking scores.
Re-ranking*
LiTS–ISBI 2017
X. Han et al.
-0.103 (7)
G. Chlebus et al.
-0.025 (2)
E. Vorontsov et al.
-0.124 (8)
L. Bi et al.
C. Wang et al.
-0.073 (5)
P. Christ et al.
J. Lipkova et al.
-0.088 (6)
J. Ma et al.
2.778 (10)
0.080 (10)
0.000 (10)
0.033 (10)
0.361 (10)
T. Konopczynski et al.
-0.150 (9)
M. Bellver et al.
-0.263 (11)
0.028 (10)
J. Qi et al.
0.188 (10)
6.118 (11)
-0.229 (10)
0.008 (11)
0.009 (11)
0.000 (10)
0.000 (11)
0.041 (11)
LiTS–MICCAI 2017
J. Zou et al.
5.921 (10)
0.148 (13)
X. Li et al.
G. Chlebus et al.
0.836 (10)
E. Vorontsov et al.
12.124 (15)
Y. Yuan et al.
J. Ma et al.
5.949 (12)
5.949 (11)
0.293 (14)
0.024 (13)
0.200 (13)
0.770 (13)
K. Kaluva et al.
0.165 (10)
X. Han et al.
0.160 (11)
0.330 (11)
C. Wang et al.
1.260 (10)
8.300 (13)
0.156 (12)
0.081 (10)
0.832 (11)
J. Wu et al.
0.624 (10)
0.373 (11)
A. Ben-Cohen et al.
0.620 (11)
1.290 (11)
0.290 (15)
0.079 (11)
0.383 (10)
L. Zhang et al.
0.620 (12)
1.388 (13)
6.420 (12)
K. Roth et al.
0.570 (13)
0.070 (14)
0.300 (13)
0.786 (12)
J. Lipkova et al.
0.480 (14)
1.330 (12)
0.060 (16)
0.190 (16)
0.014 (14)
0.206 (12)
0.755 (13)
M. Piraud et al.
0.445 (15)
1.464 (14)
10.121 (14)
0.068 (15)
0.325 (12)
0.038 (12)
0.196 (14)
0.738 (15)
LiTS–MICCAI 2018
F. Isensee et al.
-0.074 (10)
D. Xu et al.
-0.002 (1)
S. Chen et al.
1.397 (11)
-0.113 (12)
0.239 (12)
B. Park et al.
-0.067 (8)
O. Kodym et al.
-0.048 (6)
0.243 (10)
Z. Xu et al.
-0.025 (4)
0.015 (10)
0.243 (11)
R. Chen et al.
-0.188 (14)
I. Kim et al.
M. Perslev et al.
0.024 (17)
0.330 (10)
0.034 (10)
W. Bae et al.
0.517 (10)
1.650 (12)
-0.039 (5)
0.061 (14)
0.308 (11)
0.742 (11)
I. Sarasua et al.
0.486 (11)
1.374 (10)
-0.084 (11)
0.043 (16)
0.298 (12)
0.678 (12)
R. Rezaeifar et al.
0.472 (12)
1.776 (13)
-0.258 (15)
0.112 (11)
0.216 (13)
0.005 (12)
0.081 (14)
0.650 (13)
O. Rippel et al.
0.451 (13)
-0.068 (9)
0.044 (15)
0.771 (10)
S. Kim et al.
0.404 (14)
1.891 (14)
0.151 (13)
0.116 (10)
0.170 (14)
0.005 (12)
0.091 (13)
0.589 (14)
F. Jia et al.
0.316 (15)
12.762 (16)
-0.620 (16)
0.069 (12)
0.011 (17)
0.015 (10)
0.000 (16)
0.024 (17)
Y. Wang et al.
0.311 (16)
2.105 (15)
0.068 (15)
0.000 (13)
0.005 (15)
0.336 (15)
J. Ma et al.
0.142 (17)
34.527 (17)
0.685 (17)
-0.066 (13)
0.013 (16)
0.000 (13)
0.000 (16)
0.049 (16)
Figure 2: Scatter plots of methods’ performances considering: a) both segmentation and detection, b) both distance- and
overlap-based metrics for three challenge events. We observe that not all the top-performing methods in three LiTS challenges
achieved good scores on tumor detection. The behavior of distance- and overlap-based metrics is similar.
4.3.1. Inter-rater agreement
To better interpret the algorithmic variability and performance, we recruited another radiologist (Z.
Z.) with >3 years of experience in oncologic imaging to re-annotate 15 3D CT scans, and two boardcertiﬁed radiologists (J. K. and B. W.) to re-evaluate the original annotations. In Figure 3, R2 re-annotated
15 CT scans from scratch.
R3 and R4 are board-certiﬁed radiologists who checked and corrected the
annotations. Speciﬁcally, one board-certiﬁed radiologist (R3) reviewed and corrected existing annotations.
R4 re-evaluated R3’s ﬁnal annotations and corrected them. The inter-rater agreement was calculated by
the Dice score per case between the pairs of two raters. We observed high inter-rater variability (median
Dice of 70.2%)between the new annotation (R2) and the existing consensus annotation. We observed very
high agreement (median Dice of 95.2%) between the board-certiﬁed radiologist and the existing annotations.
Considering that the segmentation models were solely optimized on R1 and the best model achieved 82.5%
on the leader-board , we argue that there is still room for improvement.
4.3.2. Performance improvement
Top-performing teams over three events. First, we plotted the scores of Dice and ASD for three topperforming teams over the three events, as shown in Figure 4.
We observed incremental improvement
(e.g., the median scores) over the three events. We further performed Wilcoxon signed-rank tests on the
best teams (ranked by mean Dice) between each pair of two events. We observed that MSD’18 shows signiﬁcant improvement against ISBI’17 on both metrics (see Table 8). For MSD’18, the submitted algorithms
architectures were the same for all sub-tasks. They were trained individually for sub-tasks (e.g., liver, kidney, pancreas), focusing on the generalizability of segmentation models. The main advance was the advent
of 3D deep learning models after 2017. Tables 4 and 5 show that most of the approaches were 2D and 2.5D
Figure 3: Inter-rater agreement between the existing annotation and new annotation sets. R1 represented the rater for the
existing consensus annotation of the LiTS dataset. R2 re-annotated 15 CT scans from scratch. R3 and R4 are board-certiﬁed
radiologists who checked and corrected the annotations. Speciﬁcally, one board-certiﬁed radiologist (R3) reviewed and corrected
existing annotations. R4 re-evaluated R3’s ﬁnal annotations and corrected them. The inter-rater agreement was calculated by
the Dice score per case between the pairs of two raters.
Table 8: Results of Wilcoxon signed-rank tests between each pair of two events. MSD’18 signiﬁcantly improved over ISBI’17
on both metrics.
MICCAI’17 vs. ISBI’17
MSD’18 vs. MICCAI’17
MSD’18 vs. ISBI’17
based. The winner of MSD - the nn-Unet approach was a 3D UNet based, self-conﬁgured and adaptive for
speciﬁc tasks. We attributed the main improvement to the 3D architectures, which was in line with other
challenges and benchmark results in medical image segmentation that occurred during this time.
CodaLab submissions in the last six years. First, we separated the submissions yearly and summarized them
by individual violin plots shown in Figure 5. We observed a continuous improvement over the years, with the
best results obtained in 2022. We excluded the submissions that achieved Dice scores >10% in the analysis.
We further performed the Mann-Whitney U test on the distributions of mean Dice and ASD scores of all
teams for each year. We observed that the scores achieved in 2022 are signiﬁcantly better than in 2021,
indicating that the LiTS challenge remains active and contributes to methodology development.
Technique trend and recent advances
We have witnessed that the released LiTS dataset contributes to novel methodology development in
medical image segmentation in recent years. We reviewed sixteen papers that used the LiTS dataset for
method development and evaluation from three sources: a) Journal of Medical Image Analysis (MIA), b)
MICCAI conference proceeding, and c) IEEE Transaction on Medical Imaging (TMI), as shown in Table 10.
Figure 4: Dice and ASD scores of three top-performing teams over the three events.
Table 9: Results of Mann-Whitney U tests between the year of 2022 and the other years.
2022 vs. 2021
2022 vs. 2020
2022 vs. 2019
2022 vs. 2018
2022 vs. 2017
Figure 5: Distribution of mean Dice and ASD scores of all submissions in the CodaLab platform from the year 2017 to the
year 2022.
A signiﬁcant advance was on the 3D deep learning model besides the 2D approaches. Zhou et al. ;
Haghighi et al. proposed self-supervised pre-training frameworks to initialize 3D models for better
representation than training them from scratch. Isensee et al. proposed a self-conﬁguring pipeline to
facilitate the model training and the automated design of network architecture. Wang et al. added
a 3D attention module for 3D segmentation models. These works improved the eﬃciency of 3D models and
popularized the 3D models in many image segmentation tasks .
Ma et al. focused on the special trait of liver and liver tumor segmentation and proposed a novel
active contour-based loss function to preserve the segmentation boundary. Similarly, Tang et al. 
proposed to enhance edge information and cross-feature fusion for liver and tumor segmentation. Shirokikh
et al. considered the varying lesion sizes and proposed a loss reweighting strategy to deal with size
imbalance in tumor segmentation. Wang et al. attempted to deal with the heterogeneous image
resolution with a multi-branch decoder.
One emerging trend was leveraging available sparse labeled images to perform multi-organ segmentation.
Huang et al. attempted to perform co-training of single-organ datasets (liver, kidney, and pancreas).
Fang & Yan proposed a pyramid-input and pyramid-output network to condense multi-scale features
to reduce the semantic gaps. Finally, Yan et al. developed a universal lesion detection algorithm
to detect a variety of lesions in CT images in a multitask fashion and propose strategies to mine missing
annotations from partially-labeled datasets.
4.4.1. Remaining challenges
Segmentation performance w.r.t. lesion size. Overall, the submitted methods performed very well for large
liver tumors but struggled to segment smaller tumors (see Fig. 8). Many small tumors only have diameters
of a few voxels; further, the image resolution is relatively high with 512×512 pixels in axial slices. Therefore,
detecting such small structures is diﬃcult due to the small number of potentially diﬀering surrounding pixels,
which can indicate a potential tumor border (see Fig. 8). It is exacerbated by the considerable noise and
artifacts in medical imaging, which occur from size similarity; texture diﬀerences from the surrounding liver
tissue and their arbitrary shapes are diﬃcult to distinguish from an actual liver tumor. Overall, state-ofthe-art methods performed well on volumes with large tumors and worse on volumes with small tumors.
Worst results were achieved in exams where single small tumors (<10mm3) occur. Best results were achieved
when volumes showed less than six tumors with an overall tumor volume above 40mm3 (see Fig. 8). In the
appendix, we show the performance of all submitted methods of the three LiTS challenges, compared for
every test volume, clustered by the number of tumor appearances and tumor sizes, see Figure A.10.
Segmentation performance w.r.t. image contrast. Another important inﬂuence of the methods’ segmentation
quality was the diﬀerence in tumor and liver HU values. Current state-of-the-art methods perform best for
volumes showing higher contrast between liver and tumor. Especially in the case of focal lesions with a
density 40-60 HU higher than that of the background liver (see Fig. 8). Worst results are achieved in
Table 10: Brief summary of sixteen published work using LiTS for the development of novel segmentation methods in medical
imaging. While many of them focus on methodological contribution, they also advance the state-of-the-art in liver and liver
tumor segmentation.
Key Features
Zhou et al. 
multimodal registration, unsupervised segmentation, image-guided intervention
Wang et al. 
conjugate fully convolutional network, pairwise segmentation, proxy supervision
Zhou et al. 
3D Deep learning, self-supervised learning, transfer learning
Shirokikh et al. 
loss reweighting, lesion detection
Haghighi et al. 
self-supervised learning, transfer learning, 3D model pre-training
Huang et al. 
co-training of sparse datasets, multi-organ segmentation
Wang et al. 
volumetric attention, 3D segmentation
Tang et al. 
edge enhanced network, cross feature fusion
Nature Methods
Isensee et al. 
self-conﬁguring framework, extensive evaluation on 23 challenges
Cano-Espinosa et al. 
biomarker regression and localization
Fang & Yan 
multi-organ segmentation, multi-scale training, partially labeled data
Haghighi et al. 
self-supervised learning, anatomical visual words
Zhang et al. 
interpretable learning, probability calibration
Ma et al. 
geodesic active contours learning, boundary segmentation
Yan et al. 
training on partially-labeled dataset, lesion detection, multi-dataset learning
Wang et al. 
2.5D semantic segmentation, attention
cases where the contrast is below 20 HU (see Fig. 8), including tumors having a lower density than the
liver. An average diﬀerence in HU values eases the network’s task of distinguishing liver and tumor since a
simple threshold-derived rule could be applied as part of the decision process. Interestingly, an even more
signiﬁcant diﬀerence value did not result in an even better segmentation.
The performance of all submitted methods of three LiTS challenges was compared for every test volume,
clustered by the HU level diﬀerence between liver and tumor and the HU level diﬀerence within tumor ROIs,
shown in appendix Figure B.11.
5. Discussion
5.1. Limitations
The datasets were annotated by only one rater from each medical center. Thus it may introduce label
bias, especially for small lesion segmentation, which is only ambiguous. However, further quality control of
the annotations with consensus can reduce label noise and beneﬁt supervised training and method evaluation.
The initial rankings were conducted considering only the Dice score in which the large tissue will dominate.
We observe that solely using Dice does not distinguish the top-performing teams but combining multiple
metrics can do better. Unfortunately, imaging information (e.g., scanner type) and demographic information
are unavailable when collecting the data from multiple centers. However, they are essential for in-depth
analysis and further development of the challenge result .
The BIAS report has proven to provide a good guideline for organizing a challenge
Figure 6: Tumor segmentation results of the ISBI–LiTS 2017 challenge. The reference annotation is marked with green contour,
while the prediction is with blue contour. One could observe that the boundary of liver lesion is rather. ambiguous.
and analyzing the outcome of the challenge. Tumor detection task is of clinical relevance, and the detection
metric should be considered in future challenges.
To allow for quick evaluation of the submissions, we release the test data to the participant. Hence, we
cannot prevent potential overﬁtting behavior by multiple iterative submissions or cheating behavior (e.g.,
manual correction of the segmentation). One option to improve this is using image containers (such as
Docker 6 and Singularity 7) without releasing the test images. However, this would potentially limit the
popularity of the challenge.
6 
7 
Figure 7: Tumor segmentation results of the MICCAI–LiTS 2017 challenge. The reference annotation is marked with green
contour, while the prediction is with blue contour. One could observe that it is highly challenging to segment the liver lesion
with poor contrast.
Figure 8: Tumor segmentation results with selected cases of the tumor segmentation analysis regarding low (<20) and high
(40-60) HU value diﬀerence.
Compared are reference annotation (green), best-performing teams from ISBI 2017 (purple),
MICCAI 2017 (orange), and MICCAI 2018 (blue). We can observe that a low HU value diﬀerence (<20) between tumor and
liver tissue poses a challenge for tumor segmentation.
Figure 9: Samples of segmentation and detection results for small liver tumor. Compared are reference annotation (green),
best-performing teams from ISBI 2017 (purple), MICCAI 2017 (orange), and MICCAI 2018 (blue).
5.2. Future work
Organizing LiTS has taught us lessons relevant for future medical segmentation benchmark challenges
and their organizers. Given that many of the algorithms in this study oﬀered good liver segmentation results
compared to tumors, it seems valuable to evaluate liver tumor segmentation based on their diﬀerent size,
type, and occurrence per volume. Generating large labeled datasets is time-consuming and costly. It might
be more eﬃciently performed by advanced semi-automated methods, thereby helping to bridge the gap to
a fully automated solution.
Further, we recommend providing multiple reference annotations of liver tumors from multiple raters.
This is because the segmentation of liver tumors presents high uncertainty due to the small structure and the
ambiguous boundary . While most of the segmentation tasks in existing benchmarks
are formulated to be one-to-one mapping problems, it does not fully solve the image segmentation problem
where the data uncertainty naturally exists. Modeling the uncertainty in segmentation task is a trend 8
 and would allow the model generates not only one but various
plausible outputs. Thus, it would enhance the applicability of automated methods in clinical practice. The
released annotated dataset is not limited to benchmarking segmentation tasks but could also serve as data
for recent shape modeling methods such as implicit neural functions Considering the size and, importantly, the demographic diversity of the patient
populations from the seven institutions that contributed cases in the LiTS benchmark dataset, we think its
value and contribution to medical image analysis will be greatly appreciated across numerous directions. One
example use case is within the research direction of domain adaptation, where the LiTS dataset can be used
to account for the apparent shift of the data distribution due to the domain change (e.g., acquisition setting)
 . Another recent and intriguing use case is the research direction
of federated learning, where the multi-institutional nature of the LiTS benchmark dataset could further
contribute to federated learning simulations studies and benchmarks . It will target potential solutions to the LiTS-related tasks without sharing patient
data across institutions. We consider federated learning of particular importance, as scientiﬁc maturity in
this ﬁeld could lead to a paradigm shift for multi-institutional collaborations. Furthermore, it is overcoming
technical, legal, and cultural data sharing concerns since the patient involved in such collaboration will
always be retained within their acquiring institutions.
Acknowledgement
Bjoern Menze is supported through the DFG funding (SFB 824, subproject B12) and a Helmut-Horten-
Professorship for Biomedical Informatics by the Helmut-Horten-Foundation. Florian Koﬂer is Supported
8 
by Deutsche Forschungsgemeinschaft (DFG) through TUM International Graduate School of Science and
Engineering (IGSSE), GSC 81. An Tang was supported by the Fonds de recherche du Qu´ebec en Sant´e and
Fondation de l’association des radiologistes du Qu´ebec (FRQS-ARQ 34939 Clinical Research Scholarship –
Junior 2 Salary Award). Hongwei Bran Li is supported by Forschungskredit (Grant NO. FK-21-125) from
University of Zurich. We thank the CodaLab team, especially Eric Carmichael and Flavio Alexander for
helping us with the setup.