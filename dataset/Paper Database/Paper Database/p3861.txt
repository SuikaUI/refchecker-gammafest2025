Segmentation of Meningiomas and Low Grade
Gliomas in MRI
M. R. Kaus1,3, S. K. Warﬁeld1, A. Nabavi1,2, E. Chatzidakis1,2, P. M. Black2,
F. A. Jolesz1, and R. Kikinis1
1 Surgical Planning Laboratory, Department of Radiology
2 Department of Neurosurger
Brigham and Women’s Hospital
Harvard Medical School, 75 Francis St., Boston, MA 02115
3 Lehrstuhl Technische Elektronik
Universit¨at Erlangen-N¨urnberg, D-91058 Erlangen, Germany
{kaus,warfield,arya,manos,jolesz,kikinis}@bwh.harvard.edu
 
 
Abstract. Computer assisted surgical planning and image guided technology have become increasingly used in neurosurgery. We have developed a system based on ATmC (Adaptive Template moderated Classi-
ﬁcation) for the automated segmentation of 3D MRI brain data sets of
patients with brain tumors (meningiomas and low grade gliomas) into
the skin, the brain, the ventricles and the tumor. In a validation study
of 13 patients with brain tumors, the segmentation results of the automated method are compared to manual segmentations carried out by 4
independent trained human observers. It is shown that the automated
method segments brain and tumor with accuracy comparable to the manual method and with improved reproducibility.
Keywords: Surgical planning, Image guided neurosurgery, Magnetic
resonance (MR), segmentation, registration, brain, tumor
Introduction
Computer assisted surgical planning and image guided technology have become
increasingly used in neurosurgery . 2D images accurately describe the
size and location of anatomical objects. The process of generating 3D views
to highlight structural information and spatial relationships of the anatomy,
however, is a diﬃcult task and usually carried out in the clinician’s mind. Image
processing tools can provide the surgeon with interactively displayed 3D visual
information to facilitate the comprehension of the entire anatomy, and improve
the spatial information about relationships of critical structures (e.g. motory
and sensory cortex, vascular structures) and pathology .
Today commercially available systems usually provide the surgeon only
with 2D cross-sections of the intensity value images and a 3D model of the
C. Taylor, A. Colchester (Eds.): MICCAI’99, LNCS 1679, pp. 1–10, 1999.
⃝Springer-Verlag Berlin Heidelberg 1999
M. R. Kaus et al.
skin. The main limiting factor for the routine use of 3D models of other important structures in clinical practice is the amount of time that an operator has to
spend in the preparation of the data . The availability of automated methods will signiﬁcantly reduce the time and is necessary to make such methods
practical.
Conventional segmentation methods for tumor segmentation such as statistical classiﬁcation or mathematical morphological operations may work well in
some cases but may not diﬀerentiate between enhancing tumor, edema and normal tissue . For the separation of these tissues, the acquisition of several
tissue parameters alone has been shown to be insuﬃcient . A combination of
statistical classiﬁcation and anatomical information has been used for the segmentation of MRI images of the brain . In a recent study, an anatomical
knowledge guided fuzzy c-means method was used for automatic detection and
segmentation of glioblastoma multiforme from a combination of T1-, T2- and
Proton density (PD) MR images with promising results .
We have developed an automated segmentation method based on ATmC
(Adaptive Template moderated Classiﬁcation) that combines statistical classiﬁcation with anatomical knowledge from a digital atlas. The algorithm segments the skin surface, the brain, the ventricles and some of the most common
tumor types, meningiomas and low grade gliomas. The purpose of the current
study was to assess the accuracy and robustness of the algorithm by comparing
the automated method to manual segmentation carried out by trained medical
Materials and Methods
Patient Image Data
The MRI datasets consisted of a 3D sagittal spoiled gradient recalled (SPGR)
acquisition
slice-thickness:
256×256×124 matrix) after gadolinium-enhancement. 13 diﬀerent patients with
brain tumors of diﬀerent size, shape and location were selected, i.e. 5 meningiomas (cases No. 1–3, 11, 12), and 8 low grade gliomas (cases No. 4–10, 13).
A development database (cases No. 1–10) used for the design and validation of
the automated segmentation method was extracted from a neurosurgical image
database of approximately. 100 brain tumor cases that had been post-processed
for image guided neurosurgery (manual outlining of the structures skin-surface,
brain, ventricles, vessels and tumor). These cases provided a representative selection of meningioma and low grade glioma cases. Validation was also carried
out on the datasets of 3 patients (cases No. 11-13) were image acquisition and
processing took place after completion of the algorithm development.
Automated Segmentation of Brain and Tumor
We adapted a general algorithm intended for the automated segmentation of
anatomical objects in diﬀerent locations in the human body . The algorithm
Segmentation of Meningiomas and Low Grade Gliomas in MRI
registration
classification
& morphology
prototypes
anatomical brain atlas
pre-processed
Fig. 1. ATmC (Adaptive Template moderated Classiﬁcation) segmentation
scheme (a) and brain tumor segmentation ﬂow diagram (b).
combines two approaches to image segmentation into an iterative process: statistical classiﬁcation and segmentation by registration of an anatomical atlas
(Fig. 1). We summarize here the concept of the segmentation framework and
its application to brain tumor segmentation. For a mathematical description we
refer to .
Image Segmentation Statistical classiﬁcation (k-Nearest Neighbor rule) divides the image into diﬀerent tissue classes based on the signal intensity value .
Overlap between signal intensity distributions of diﬀerent tissue classes leads to
mis-classiﬁcations. To resolve this problem, additional information is derived
from a digital volumetric atlas of a normal brain that has been manually segmented into approximately. 250 diﬀerent structures by medical experts . By
projecting anatomical templates from the atlas onto the individual patient data,
diﬀerent structures of interest in the patient dataset can be located according to
their location in the atlas.
Comparing the images of two diﬀerent brains requires non-linear registration
for the projection of the atlas onto the patient data, capturing individual diﬀerences by allowing structures to shrink, grow, and twist, and to move or rotate
locally and independently . In our approach, the algorithm computes the spatial nonlinear transform on the basis of the segmented images, rather than the
original signal intensity values, in order that the registration be less susceptible
to image noise and intensity artifacts.
Instead of directly projecting anatomical templates onto the patient and thus
having to rely on hard boundaries, a model of anatomical localization was formulated that reﬂects lower conﬁdence in the localization towards the boundary
of structures (“soft boundaries”). This was implemented by using Euclidian distance transforms computed from the templates as additional anatomical feature
M. R. Kaus et al.
channels in the kNN classiﬁcation. The approach has the advantage that a very
precise registration is not necessary, because the method uses both the MR intensity information and the soft spatial location.
Statistical classiﬁcation and registration of the anatomical brain atlas are
iterated. The goal of the iteration is to improve the result of the registration
by providing tentative image segmentations, and to improve the result of the
classiﬁcation by providing regions of interest.
Objects of interest are deﬁned on the classiﬁed images, where every voxel
was labeled according to the assigned tissue class. For the identiﬁcation of each
structure and removement of classiﬁcation artifacts, a local segmentation strategy was used, consisting of a) a morphological erosion to “cut” classiﬁcation
artifacts such as thin connections between diﬀerent objects, b) a connectedcomponent algorithm to re-label every voxel as belonging to one object or another and c) a morphological dilation to restore previously eroded voxels on the
object boundaries .
Application to Tumor Segmentation Five tissue classes were modeled:
background, skin (fat/bone), brain, ventricles, and tumor. Due to the homogeneous tissue composition of meningiomas and low grade gliomas one tissue class
was suﬃcient for the statistical model. A simple, hierarchical model of anatomy
was used to deﬁne the order in which the diﬀerent structures were segmented. By
proceeding hierarchically from the outside to the inside of the head (Fig. 1), each
segmented structure provided additional anatomical knowledge (i.e. a reﬁned region of interest) for the next structure to be segmented. A standard normal brain
atlas contains no tumor template. This has three consequences. First, anatomical
templates from the atlas were derived only for the head, the ICC and the ventricles. Second, because the registration paradigm assumes correspondence between
every structure in atlas and patient, a compound tissue class of the normal and
pathologic brain structures was formed during ICC registration. The atlas brain
was registered to the patient brain and pathology. Third, in a ﬁrst tumor segmentation iteration, only atlas brain and ventricle templates were used. In a
second iteration, the tumor segmentation from the ﬁrst iteration was used as an
anatomical template. Although this template was approximate, the additional
information about the location of the tumor prevented the mis-classiﬁcation of
Initialization of the Automated Segmentation Method Prior to the segmentation, the image data is preprocessed with an anisotropic diﬀusion ﬁltering
method to reduce the noise in the MR images while preserving edges . The
method requires the selection of 3–4 example points for each tissue class. For the
2D display of MR slices and the selection of example tissue points using a mouse
a graphical user interface was developed. The program calculated a statistical
model for the distribution of the grey values based on these manually selected
tissue prototypes.
Segmentation of Meningiomas and Low Grade Gliomas in MRI
Validation
Since there is no “gold standard” to compare with, our deﬁnition of a segmentation “gold standard” is based upon the opinion of the medical expert, manifested in manual segmentations using interactive computer segmentation tools.
However, manual segmentation is subject to inter-rater variability and human
error. To minimize the inﬂuence of these factors while maintaining the means of
measuring the segmentation accuracy of the individual raters, the standard was
deﬁned as the area of those voxels where at least 3 out of 4 experts agreed upon
the identiﬁcation. To determine inter- and intra-variability of the segmentation
results, a ﬁfth rater manually segmented each selected 2D slice 4 times over a
period of one week, and the 4 experts carried out repeated initialization of the
automated algorithm.
The experimental setup was the following: The automated algorithm was
trained on a single MR slice containing the structures of interest and executed,
resulting in a segmentation of the entire 3D dataset into the structures skin,
brain, ventricles and tumor. A single 2D slice was randomly selected from the
subset of MR slices containing the tumor. On those slices, brain and tumor
were manually segmented by 4 trained medical experts using an interactive segmentation tool (MRX, GE Medical Systems, Schenectady, NY). The structures
were outlined slice-by-slice by pointing and clicking with a mouse. The program
connected consecutive points with lines. An anatomical object was deﬁned by a
closed contour, and the program labeled every voxel of the enclosed volume.
Statistical analysis was carried out by comparing the volumes of the automatically with the manually segmented structures. Accuracy was deﬁned as the
percentage of correctly classiﬁed voxels with respect to the total number of voxels in the image. To measure the inter- and intra-rater variation, the coeﬃcient of
variation (CV% = 100*[(SD volume)/(mean volume)], SD: standard deviation)
of the volume of the structure was calculated.
Results and Discussion
Examples for manual and automated segmentation (Fig. 2) for a meningioma
(top row) and a low grade glioma (bottom row) illustrate high similarity between
the two methods. Fig. 3 shows the accuracy for brain and tumor segmentation
achieved by the automated and the manual method. The segmentation accuracy
of the cases 11–13 is displayed in Tab. 1. The segmentation accuracy with the
automated method is above 95 % for brain and above 99 % for tumor, and
within or close (maximum diﬀerence 0.6 %) to the range of the minimum and
maximum of the accuracy with the manual method. The errors of the automated
brain segmentation are in part due to the over- and under-segmentation in the
area of the tentorium cerebelli and the area of the lateral sulcus with abundant
vessels. The algorithm tends to oversegment these areas, if voxels e.g. of the neck
close to the cerebellum are mis-classiﬁed as brain and the template ICC derived
from the atlas is mis-registered.
M. R. Kaus et al.
Fig. 2. Examples of manual and automated segmentation: Meningioma (SPGR
image (a), manual (b), and automated segmentation (c)). Low Grade Glioma
(SPGR image (d), manual (e), and automated segmentation (f).
The size of the structure aﬀects the segmentation accuracy. Potentially, the
boundaries are the areas of segmentation error. Since the comparison is based
on measuring the number of correctly classiﬁed voxels (fore- and background),
large objects tend to have a lower accuracy since there are more boundary voxels
to mis-classify with respect to the entire image.
Fig. 4 and Fig. 5 show the inter- and intra-rater variability achieved by
the manual and the automated methods. The horizontal lines mark the mean
coeﬃcient of variability over all 10 cases.
The inter- and intra-observer variability of both methods are lower for the
brain than for the tumor. This is because the methods are consistent in labeling
the “center” of an object, but vary in the determination of the boundaries. Since
the brain is a larger structure than the tumor, the disagreement on the brain
boundary with respect to the overall brain volume (not the entire image, as for
the accuracy measurement) is less signiﬁcant than for the tumor.
Segmentation of Meningiomas and Low Grade Gliomas in MRI
Table 1. Segmentation accuracy of the three cases 11–13, where image data was
acquired and segmented after completion of the algorithm development.
Brain Accuracy [%]
Tumor Accuracy [%]
Tumor Histology
min max mean ATmC
min max mean ATmC
Meningioma
96.66 99.69 99.48
97.23 99.12 99.58 99.44
Meningioma
98.75 99.62 99.15
98.69 99.25 99.89 99.72
Low Grade Glioma 96.55 99.72 98.85
99.16 99.90 99.94 99.93
Fig. 3. Segmentation accuracy of the manual (mean, minimum and maximum)
and the automated method for each of the 10 brain tumor cases (1–3 Meningiomas), (7–10 Low Grade Gliomas).
The mean inter- and intra-observer variability of the automated method is
lower than with manual outlining. While the inter-observer variability with the
automated method is consistently lower than with the manual method, the intraobserver variability of the automated method is higher for most of the low grade
glioma cases. This can be explained with the diﬀerent grey value distributions
of the meningioma and the low grade gliomas with respect to the brain. The
meningioma tissue class partially overlaps with parts of the skin, fat in the neck
and the straight and superior sagittal sinus. By restricting the region of interest
(ROI) for the meningioma to the ICC, tissues that show signal intensity overlap with the meningioma are excluded and the meningioma can be successfully
segmented. Low grade gliomas, however, are less distinguishable from brain tissue. Partial volume artifacts on the boundary of the brain and the tumor may
cause signal intensity overlap between grey matter and tumor tissue, leading to
M. R. Kaus et al.
Fig. 4. Inter-observer variability of manual and automated method (coeﬃcient
of variation, CV). The horizontal line marks the mean of the CV values.
mis-classiﬁcations, i.e. over- or under-segmentation of brain and tumor. Thus,
the classiﬁer is more sensitive to diﬀerences in the tissue prototype selection.
The mean computation time for the automated segmentation of the whole
volume was 75 minutes on a Sun ES 6000 server with 20 CPUs and 5 GB
of RAM (Sun Microsystems, Mountain View, CA). The overall operator time
was approximately. 5–10 minutes for the selection of prototypes for each of the
relevant tissue classes, while manual segmentation time for a neurosurgical case
has been reported to be in the range of 180 minutes , The reduction of
operator time makes it practical to consider the integration of computerized
segmentation into clinical routine.
Conclusion and Future Work
We have developed a method for the automated segmentation of meningiomas
and low grade gliomas without edema. Accuracy and intra-observer variability of
the automated method are comparable to the segmentation results from trained
human observers, with improved inter-observer variability.
Further investigation is required to extend the algorithm to a broader range
of brain tumors such as the glioblastoma multiforme or tumors with edema. Our
algorithm is implemented on high performance computing hardware. However,
through further algorithmic improvement and hardware speedups, we expect
that this method will become practical in a clinical setting in the near future .
Currently, our tool is used in routine surgical planning to provide the basis for a
clinical study based on a larger population to determine robustness and practical
use in a clinical setting.
Segmentation of Meningiomas and Low Grade Gliomas in MRI
Fig. 5. Intra-observer variability of manual and automated method (coeﬃcient
of variation, CV). The horizontal line marks the mean of the CV values.
Acknowledgments
This work was supported (in part) by a grant from the Deutscher Akademischer
Austauschdienst (DAAD). This investigation was supported (in part) by a Grant
from the National Multiple Sclerosis Society (SW). This work was supported (in
part) by NIH grants RO1 CA 46627-08, PO1 CA67165-01A1, PO1 AG04953-14,
NSF grant BES 9631710 and Darpa grant F41624-96-2-0001. The authors thank
Dr. Alexandra Chabrerie, Dr. Fatma Ozlen and Dr. Daniel Boll, Brigham and
Women’s Hospital, Boston for their help with the manual segmentations.