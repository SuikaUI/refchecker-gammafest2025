Adversarial Discriminative Domain Adaptation
Eric Tzeng
University of California, Berkeley
 
Judy Hoffman
Stanford University
 
Kate Saenko
Boston University
 
Trevor Darrell
University of California, Berkeley
 
Adversarial learning methods are a promising approach
to training robust deep networks, and can generate complex
samples across diverse domains. They also can improve
recognition despite the presence of domain shift or dataset
bias: several adversarial approaches to unsupervised domain adaptation have recently been introduced, which reduce the difference between the training and test domain
distributions and thus improve generalization performance.
Prior generative approaches show compelling visualizations,
but are not optimal on discriminative tasks and can be limited to smaller shifts. Prior discriminative approaches could
handle larger domain shifts, but imposed tied weights on the
model and did not exploit a GAN-based loss. We ﬁrst outline
a novel generalized framework for adversarial adaptation,
which subsumes recent state-of-the-art approaches as special cases, and we use this generalized view to better relate
the prior approaches. We propose a previously unexplored
instance of our general framework which combines discriminative modeling, untied weight sharing, and a GAN loss,
which we call Adversarial Discriminative Domain Adaptation (ADDA). We show that ADDA is more effective yet
considerably simpler than competing domain-adversarial
methods, and demonstrate the promise of our approach by
exceeding state-of-the-art unsupervised adaptation results
on standard cross-domain digit classiﬁcation tasks and a
new more difﬁcult cross-modality object classiﬁcation task.
1. Introduction
Deep convolutional networks, when trained on large-scale
datasets, can learn representations which are generically usefull across a variety of tasks and visual domains . However, due to a phenomenon known as dataset bias or domain
shift , recognition models trained along with these repsource
target*encoder
domain*discriminator
Figure 1: We propose an improved unsupervised domain
adaptation method that combines adversarial learning with
discriminative feature learning. Speciﬁcally, we learn a discriminative mapping of target images to the source feature
space (target encoder) by fooling a domain discriminator that
tries to distinguish the encoded target images from source
resentations on one large dataset do not generalize well to
novel datasets and tasks . The typical solution is to
further ﬁne-tune these networks on task-speciﬁc datasets—
however, it is often prohibitively difﬁcult and expensive to
obtain enough labeled data to properly ﬁne-tune the large
number of parameters employed by deep multilayer networks.
Domain adaptation methods attempt to mitigate the harmful effects of domain shift. Recent domain adaptation meth-
 
ods learn deep neural transformations that map both domains
into a common feature space. This is generally achieved by
optimizing the representation to minimize some measure of
domain shift such as maximum mean discrepancy or
correlation distances . An alternative is to reconstruct
the target domain from the source representation .
Adversarial adaptation methods have become an increasingly popular incarnation of this type of approach which
seeks to minimize an approximate domain discrepancy distance through an adversarial objective with respect to a domain discriminator. These methods are closely related to
generative adversarial learning , which pits two networks
against each other—a generator and a discriminator. The
generator is trained to produce images in a way that confuses
the discriminator, which in turn tries to distinguish them
from real image examples. In domain adaptation, this principle has been employed to ensure that the network cannot
distinguish between the distributions of its training and test
domain examples . However, each algorithm
makes different design choices such as whether to use a generator, which loss function to employ, or whether to share
weights across domains. For example, share weights
and learn a symmetric mapping of both source and target images to the shared feature space, while decouple some
layers thus learning a partially asymmetric mapping.
In this work, we propose a novel uniﬁed framework for
adversarial domain adaptation, allowing us to effectively
examine the different factors of variation between the existing approaches and clearly view the similarities they each
share. Our framework uniﬁes design choices such as weightsharing, base models, and adversarial losses and subsumes
previous work, while also facilitating the design of novel
instantiations that improve upon existing ones.
In particular, we observe that generative modeling of input image distributions is not necessary, as the ultimate task
is to learn a discriminative representation. On the other hand,
asymmetric mappings can better model the difference in low
level features than symmetric ones. We therefore propose
a previously unexplored unsupervised adversarial adaptation method, Adversarial Discriminative Domain Adaptation (ADDA), illustrated in Figure 1. ADDA ﬁrst learns a
discriminative representation using the labels in the source
domain and then a separate encoding that maps the target
data to the same space using an asymmetric mapping learned
through a domain-adversarial loss. Our approach is simple
yet surprisingly powerful and achieves state-of-the-art visual
adaptation results on the MNIST, USPS, and SVHN digits
datasets. We also test its potential to bridge the gap between
even more difﬁcult cross-modality shifts, without requiring
instance constraints, by transferring object classiﬁers from
RGB color images to depth observations.
2. Related work
There has been extensive prior work on domain transfer learning, see e.g., . Recent work has focused on
transferring deep neural network representations from a
labeled source datasets to a target domain where labeled
data is sparse or non-existent. In the case of unlabeled
target domains (the focus of this paper) the main strategy has been to guide feature learning by minimizing the
difference between the source and target feature distributions .
Several methods have used the Maximum Mean Discrepancy (MMD) loss for this purpose. MMD computes the
norm of the difference between two domain means. The
DDC method used MMD in addition to the regular classiﬁcation loss on the source to learn a representation that is
both discriminative and domain invariant. The Deep Adaptation Network (DAN) applied MMD to layers embedded
in a reproducing kernel Hilbert space, effectively matching
higher order statistics of the two distributions. In contrast,
the deep Correlation Alignment (CORAL) method proposed to match the mean and covariance of the two distributions.
Other methods have chosen an adversarial loss to minimize domain shift, learning a representation that is simultaneously discriminative of source labels while not being able
to distinguish between domains. proposed adding a domain classiﬁer (a single fully connected layer) that predicts
the binary domain label of the inputs and designed a domain
confusion loss to encourage its prediction to be as close as
possible to a uniform distribution over binary labels. The gradient reversal algorithm (ReverseGrad) proposed in also
treats domain invariance as a binary classiﬁcation problem,
but directly maximizes the loss of the domain classiﬁer by
reversing its gradients. DRCN takes a similar approach
but also learns to reconstruct target domain images.
In related work, adversarial learning has been explored
for generative tasks. The Generative Adversarial Network
(GAN) method is a generative deep model that pits two
networks against one another: a generative model G that
captures the data distribution and a discriminative model
D that distinguishes between samples drawn from G and
images drawn from the training data by predicting a binary
label. The networks are trained jointly using backprop on the
label prediction loss in a mini-max fashion: simultaneously
update G to minimize the loss while also updating D to
maximize the loss (fooling the discriminator). The advantage
of GAN over other generative methods is that there is no
need for complex sampling or inference during training; the
downside is that it may be difﬁcult to train. GANs have
been applied to generate natural images of objects, such as
digits and faces, and have been extended in several ways.
The BiGAN approach extends GANs to also learn the
inverse mapping from the image data back into the latent
source mapping
adversarial
objective?
target mapping
discriminator
discriminator
Generative or
discriminative
Figure 2: Our generalized architecture for adversarial domain adaptation. Existing adversarial adaptation methods
can be viewed as instantiations of our framework with different choices regarding their properties.
space, and shows that this can learn features useful for image
classiﬁcation tasks. The conditional generative adversarial
net (CGAN) is an extension of the GAN where both
networks G and D receive an additional vector of information
as input. This might contain, say, information about the
class of the training example. The authors apply CGAN to
generate a (possibly multi-modal) distribution of tag-vectors
conditional on image features.
Recently the CoGAN approach applied GANs to the
domain transfer problem by training two GANs to generate
the source and target images respectively. The approach
achieves a domain invariant feature space by tying the highlevel layer parameters of the two GANs, and shows that
the same noise input can generate a corresponding pair of
images from the two distributions. Domain adaptation was
performed by training a classiﬁer on the discriminator output
and applied to shifts between the MNIST and USPS digit
datasets. However, this approach relies on the generators
ﬁnding a mapping from the shared high-level layer feature
space to full images in both domains. This can work well
for say digits which can be difﬁcult in the case of more
distinct domains. In this paper, we observe that modeling
the image distributions is not strictly necessary to achieve
domain adaptation, as long as the latent feature space is
domain invariant, and propose a discriminative approach.
3. Generalized adversarial adaptation
We present a general framework for adversarial unsupervised adaptation methods. In unsupervised adaptation, we
assume access to source images Xs and labels Ys drawn
from a source domain distribution ps(x, y), as well as target
images Xt drawn from a target distribution pt(x, y), where
there are no label observations. Our goal is to learn a target representation, Mt and classiﬁer Ct that can correctly
classify target images into one of K categories at test time,
despite the lack of in domain annotations. Since direct supervised learning on the target is not possible, domain adaptation instead learns a source representation mapping, Ms,
along with a source classiﬁer, Cs, and then learns to adapt
that model for use in the target domain.
In adversarial adaptive methods, the main goal is to regularize the learning of the source and target mappings, Ms
and Mt, so as to minimize the distance between the empirical source and target mapping distributions: Ms(Xs) and
Mt(Xt). If this is the case then the source classiﬁcation
model, Cs, can be directly applied to the target representations, elimating the need to learn a separate target classiﬁer
and instead setting, C = Cs = Ct.
The source classiﬁcation model is then trained using the
standard supervised loss below:
Ms,C Lcls(Xs, Yt) =
E(xs,ys)∼(Xs,Yt) −
1[k=ys] log C(Ms(xs))
We are now able to describe our full general framework
view of adversarial adaptation approaches. We note that
all approaches minimize source and target representation
distances through alternating minimization between two
functions. First a domain discriminator, D, which classi-
ﬁes whether a data point is drawn from the source or the
target domain. Thus, D is optimized according to a standard
supervised loss, LadvD(Xs, Xt, Ms, Mt) where the labels
indicate the origin domain, deﬁned below:
LadvD(Xs, Xt, Ms, Mt) =
−Exs∼Xs[log D(Ms(xs))]
−Ext∼Xt[log(1 −D(Mt(xt)))]
Second, the source and target mappings are optimized according to a constrained adversarial objective, whose particular instantiation may vary across methods. Thus, we can
derive a generic formulation for domain adversarial techniques below:
LadvD(Xs, Xt, Ms, Mt)
Ms,Mt LadvM (Xs, Xt, D)
In the next sections, we demonstrate the value of our
framework by positioning recent domain adversarial approaches within our framework. We describe the potential mapping structure, mapping optimization constraints
(ψ(Ms, Mt)) choices and ﬁnally choices of adversarial mapping loss, LadvM .
Base model
Weight sharing
Adversarial loss
Gradient reversal 
discriminative
Domain confusion 
discriminative
CoGAN 
generative
ADDA (Ours)
discriminative
Table 1: Overview of adversarial domain adaption methods and their various properties. Viewing methods under a uniﬁed
framework enables us to easily propose a new adaptation method, adversarial discriminative domain adaptation (ADDA).
3.1. Source and target mappings
In the case of learning a source mapping Ms alone it is
clear that supervised training through a latent space discriminative loss using the known labels Ys results in the best
representation for ﬁnal source recognition. However, given
that our target domain is unlabeled, it remains an open question how best to minimize the distance between the source
and target mappings. Thus the ﬁrst choice to be made is in
the particular parameterization of these mappings.
Because unsupervised domain adaptation generally considers target discriminative tasks such as classiﬁcation, previous adaptation methods have generally relied on adapting
discriminative models between domains . With a
discriminative base model, input images are mapped into
a feature space that is useful for a discriminative task such
as image classiﬁcation. For example, in the case of digit
classiﬁcation this may be the standard LeNet model. However, Liu and Tuzel achieve state of the art results on unsupervised MNIST-USPS using two generative adversarial
networks . These generative models use random noise
as input to generate samples in image space—generally, an
intermediate feature of an adversarial discriminator is then
used as a feature for training a task-speciﬁc classiﬁer.
Once the mapping parameterization is determined for
the source, we must decide how to parametrize the target
mapping Mt. In general, the target mapping almost always
matches the source in terms of the speciﬁc functional layer
(architecture), but different methods have proposed various
regularization techniques. All methods initialize the target
mapping parameters with the source, but different methods
choose different constraints between the source and target
mappings, ψ(Ms, Mt). The goal is to make sure that the
target mapping is set so as to minimize the distance between
the source and target domains under their respective mappings, while crucially also maintaining a target mapping that
is category discriminative.
Consider a layered representations where each layer parameters are denoted as, M ℓ
t , for a given set of equivalent layers, {ℓ1, . . . , ℓn}. Then the space of constraints
explored in the literature can be described through layerwise
equality constraints as follows:
ψ(Ms, Mt) ≜{ψℓi(M ℓi
t )}i∈{1...n}
where each individual layer can be constrained independently. A very common form of constraint is source and
target layerwise equality:
t ) = (M ℓi
It is also common to leave layers unconstrained. These equality constraints can easily be imposed within a convolutional
network framework through weight sharing.
For many prior adversarial adaptation methods ,
all layers are constrained, thus enforcing exact source and
target mapping consistency. Learning a symmetric transformation reduces the number of parameters in the model and
ensures that the mapping used for the target is discriminative at least when applied to the source domain. However,
this may make the optimization poorly conditioned, since
the same network must handle images from two separate
An alternative approach is instead to learn an asymmetric
transformation with only a subset of the layers constrained,
thus enforcing partial alignment.
Rozantsev et al. 
showed that partially shared weights can lead to effective
adaptation in both supervised and unsupervised settings. As
a result, some recent methods have favored untying weights
(fully or partially) between the two domains, allowing models to learn parameters for each domain individually.
3.2. Adversarial losses
Once we have decided on a parametrization of Mt, we employ an adversarial loss to learn the actual mapping. There
are various different possible choices of adversarial loss functions, each of which have their own unique use cases. All
adversarial losses train the adversarial discriminator using
a standard classiﬁcation loss, LadvD, previously stated in
Equation 2. However, they differ in the loss used to train the
mapping, LadvM .
The gradient reversal layer of optimizes the mapping
to maximize the discriminator loss directly:
LadvM = −LadvD.
This optimization corresponds to the true minimax objective
for generative adversarial networks. However, this objective
can be problematic, since early on during training the discriminator converges quickly, causing the gradient to vanish.
When training GANs, rather than directly using the minimax loss, it is typical to train the generator with the standard
loss function with inverted labels . This splits the optimization into two independent objectives, one for the generator and one for the discriminator, where LadvD remains
unchanged, but LadvM becomes:
LadvM (Xs, Xt, D) = −Ext∼Xt[log D(Mt(xt))].
This objective has the same ﬁxed-point properties as the
minimax loss but provides stronger gradients to the target
mapping. We refer to this modiﬁed loss function as the
“GAN loss function” for the remainder of this paper.
Note that, in this setting, we use independent mappings
for source and target and learn only Mt adversarially. This
mimics the GAN setting, where the real image distribution
remains ﬁxed, and the generating distribution is learned to
The GAN loss function is the standard choice in the setting where the generator is attempting to mimic another
unchanging distribution. However, in the setting where
both distributions are changing, this objective will lead to
oscillation—when the mapping converges to its optimum,
the discriminator can simply ﬂip the sign of its prediction
in response. Tzeng et al. instead proposed the domain
confusion objective, under which the mapping is trained
using a cross-entropy loss function against a uniform distribution :
LadvM (Xs, Xt, D) =
2 log D(Md(xd))
2 log(1 −D(Md(xd)))
This loss ensures that the adversarial discriminator views the
two domains identically.
4. Adversarial discriminative domain adaptation
The beneﬁt of our generalized framework for domain adversarial methods is that it directly enables the development
of novel adaptive methods. In fact, designing a new method
has now been simpliﬁed to the space of making three design
choices: whether to use a generative or discriminative base
model, whether to tie or untie the weights, and which adversarial learning objective to use. In light of this view we can
summarize our method, adversarial discriminative domain
adaptation (ADDA), as well as its connection to prior work,
according to our choices (see Table 1 “ADDA”). Speciﬁcally,
we use a discriminative base model, unshared weights, and
the standard GAN loss. We illustrate our overall sequential
training procedure in Figure 3.
First, we choose a discriminative base model, as we hypothesize that much of the parameters required to generate
convincing in-domain samples are irrelevant for discriminative adaptation tasks. Most prior adversarial adaptive
methods optimize directly in a discriminative space for this
reason. One counter-example is CoGANs. However, this
method has only shown dominance in settings where the
source and target domain are very similar such as MNIST
and USPS, and in our experiments we have had difﬁculty
getting it to converge for larger distribution shifts.
Next, we choose to allow independent source and target
mappings by untying the weights. This is a more ﬂexible
learing paradigm as it allows more domain speciﬁc feature
extraction to be learned. However, note that the target domain has no label access, and thus without weight sharing
a target model may quickly learn a degenerate solution if
we do not take care with proper initialization and training
procedures. Therefore, we use the pre-trained source model
as an intitialization for the target representation space and
ﬁx the source model during adversarial training.
In doing so, we are effectively learning an asymmetric
mapping, in which we modify the target model so as to match
the source distribution. This is most similar to the original
generative adversarial learning setting, where a generated
space is updated until it is indistinguishable with a ﬁxed real
space. Therefore, we choose the inverted label GAN loss
described in the previous section.
Our proposed method, ADDA, thus corresponds to the
following unconstrained optimization:
Ms,C Lcls(Xs, Ys) =
−E(xs,ys)∼(Xs,Ys)
1[k=ys] log C(Ms(xs))
LadvD(Xs, Xt, Ms, Mt) =
−Exs∼Xs[log D(Ms(xs))]
−Ext∼Xt[log(1 −D(Mt(xt)))]
Ms,Mt LadvM (Xs, Xt, D) =
−Ext∼Xt[log D(Mt(xt))].
We choose to optimize this objective in stages. We begin
by optimizing Lcls over Ms and C by training using the
labeled source data, Xs and Ys. Because we have opted to
leave Ms ﬁxed while learning Mt, we can thus optimize
LadvD and LadvM without revisiting the ﬁrst objective term.
A summary of this entire training process is provided in
source images
Classifier
Pre-training
source images
Discriminator
Adversarial Adaptation
target images
Classifier
target image
Figure 3: An overview of our proposed Adversarial Discriminative Domain Adaptation (ADDA) approach. We ﬁrst pre-train
a source encoder CNN using labeled source image examples. Next, we perform adversarial adaptation by learning a target
encoder CNN such that a discriminator that sees encoded source and target examples cannot reliably predict their domain
label. During testing, target images are mapped with the target encoder to the shared feature space and classiﬁed by the source
classiﬁer. Dashed lines indicate ﬁxed network parameters.
We note that the uniﬁed framework presented in the previous section has enabled us to compare prior domain adversarial methods and make informed decisions about the different
factors of variation. Through this framework we are able
to motivate a novel domain adaptation method, ADDA, and
offer insight into our design decisions. In the next section
we demonstrate promising results on unsupervised adaptation benchmark tasks, studying adaptation across digits and
across modalities.
5. Experiments
We now evaluate ADDA for unsupervised classiﬁcation
adaptation across four different domain shifts. We explore
three digits datasets of varying difﬁculty: MNIST ,
USPS, and SVHN . We additionally evaluate on the
NYUD dataset to study adaptation across modalities.
Example images from all experimental datasets are provided
in Figure 4.
For the case of digit adaptation, we compare against multiple state-of-the-art unsupervised adaptation methods, all
based upon domain adversarial learning objectives. In 3 of
4 of our experimental setups, our method outperforms all
competing approaches, and in the last domain shift studied,
our approach outperforms all but one competing approach.
We also validate our model on a real-world modality
adaptation task using the NYU depth dataset. Despite a large
domain shift between the RGB and depth modalities, ADDA
learns a useful depth representation without any labeled
depth data and improves over the nonadaptive baseline by
over 50% (relative).
5.1. MNIST, USPS, and SVHN digits datasets
We experimentally validate our proposed method in an unsupervised adaptation task between the MNIST , USPS,
and SVHN digits datasets, which consist 10 classes of
digits. Example images from each dataset are visualized in
Figure 4 and Table 2. For adaptation between MNIST and
USPS, we follow the training protocol established in ,
sampling 2000 images from MNIST and 1800 from USPS.
For adaptation between SVHN and MNIST, we use the full
training sets for comparison against . All experiments
are performed in the unsupervised settings, where labels in
the target domain are withheld, and we consider adaptation
in three directions: MNIST→USPS, USPS→MNIST, and
SVHN→MNIST.
For these experiments, we use the simple modiﬁed LeNet
architecture provided in the Caffe source code .
When training with ADDA, our adversarial discriminator
consists of 3 fully connected layers: two layers with 500
hidden units followed by the ﬁnal discriminator output. Each
of the 500-unit layers uses a ReLU activation function.
Results of our experiment are provided in Table 2. On the
easier MNIST and USPS shifts ADDA achieves comparable
performance to the current state-of-the-art, CoGANs ,
despite being a considerably simpler model. This provides
compelling evidence that the machinery required to generate
images is largely irrelevant to enabling effective adaptation.
Additionally, we show convincing results on the challenging
SVHN and MNIST task in comparison to other methods,
indicating that our method has the potential to generalize
to a variety of settings. In contrast, we were unable to get
CoGANs to converge on SVHN and MNIST—because the
domains are so disparate, we were unable to train coupled
generators for them.
5.2. Modality adaptation
We use the NYU depth dataset , which contains
bounding box annotations for 19 object classes in 1449 images from indoor scenes. The dataset is split into a train (381
Digits adaptation
Cross-modality adaptation (NYUD)
Figure 4: We evaluate ADDA on unsupervised adaptation across four domain shifts in two different settings. The ﬁrst setting
is adaptation between the MNIST, USPS, and SVHN datasets (left). The second setting is a challenging cross-modality
adaptation task between RGB and depth modalities from the NYU depth dataset (right).
MNIST →USPS
USPS →MNIST
SVHN →MNIST
Source only
0.752 ± 0.016
0.571 ± 0.017
0.601 ± 0.011
Gradient reversal
0.771 ± 0.018
0.730 ± 0.020
0.739 
Domain confusion
0.791 ± 0.005
0.665 ± 0.033
0.681 ± 0.003
0.912 ± 0.008
0.891 ± 0.008
did not converge
ADDA (Ours)
0.894 ± 0.002
0.901 ± 0.008
0.760 ± 0.018
Table 2: Experimental results on unsupervised adaptation among MNIST, USPS, and SVHN.
images), val (414 images) and test (654) sets. To perform
our cross-modality adaptation, we ﬁrst crop out tight bounding boxes around instances of these 19 classes present in
the dataset and evaluate on a 19-way classiﬁcation task over
object crops. In order to ensure that the same instance is not
seen in both domains, we use the RGB images from the train
split as the source domain and the depth images from the val
split as the target domain. This corresponds to 2,186 labeled
source images and 2,401 unlabeled target images. Figure 4
visualizes samples from each of the two domains.
We consider the task of adaptation between these RGB
and HHA encoded depth images , using them as source
and target domains respectively. Because the bounding boxes
are tight and relatively low resolution, accurate classiﬁcation
is quite difﬁcult, even when evaluating in-domain. In addition, the dataset has very few examples for certain classes,
such as toilet and bathtub, which directly translates
to reduced classiﬁcation performance.
For this experiment, our base architecture is the VGG-16
architecture, initializing from weights pretrained on ImageNet . This network is then fully ﬁne-tuned on the
source domain for 20,000 iterations using a batch size of
128. When training with ADDA, the adversarial discriminator consists of three additional fully connected layers:
1024 hidden units, 2048 hidden units, then the adversarial
discriminator output. With the exception of the output, these
additionally fully connected layers use a ReLU activation
function. ADDA training then proceeds for another 20,000
iterations, again with a batch size of 128.
We ﬁnd that our method, ADDA, greatly improves classiﬁcation accuracy for this task. For certain categories, like
counter, classiﬁcation accuracy goes from 2.9% under the
source only baseline up to 44.7% after adaptation. In general,
average accuracy across all classes improves signiﬁcantly
from 13.9% to 21.1%. However, not all classes improve.
Three classes have no correctly labeled target images before
adaptation, and adaptation is unable to recover performance
on these classes. Additionally, the classes of pillow and
nightstand suffer performance loss after adaptation.
For additional insight on what effect ADDA has on classi-
ﬁcation, Figure 5 plots confusion matrices before adaptation,
after adaptation, and in the hypothetical best-case scenario
where the target labels are present. Examining the confusion
matrix for the source only baseline reveals that the domain
shift is quite large—as a result, the network is poorly conditioned and incorrectly predicts pillow for the majority of
garbage bin
night stand
television
# of instances
Source only
0.000 0.010 0.011 0.124 0.188 0.029 0.041 0.047 0.000 0.000 0.069 0.000 0.039 0.587 0.000 0.008 0.010 0.000 0.000 0.139
ADDA (Ours) 0.000 0.146 0.046 0.229 0.344 0.447 0.025 0.023 0.000 0.018 0.292 0.081 0.020 0.297 0.021 0.116 0.143 0.091 0.000 0.211
Train on target 0.105 0.531 0.494 0.295 0.619 0.573 0.057 0.636 0.120 0.291 0.576 0.189 0.235 0.630 0.362 0.248 0.357 0.303 0.647 0.468
Table 3: Adaptation results on the NYUD dataset, using RGB images from the train set as source and depth images from
the val set as target domains. We report here per class accuracy due to the large class imbalance in our target set (indicated in #
instances). Overall our method improves average per category accuracy from 13.9% to 21.1%.
garbage bin
night stand
television
Predicted label
garbage bin
night stand
television
True label
Source only
garbage bin
night stand
television
Predicted label
garbage bin
night stand
television
True label
ADDA (Ours)
garbage bin
night stand
television
Predicted label
garbage bin
night stand
television
True label
Train on target
Figure 5: Confusion matrices for source only, ADDA, and oracle supervised target models on the NYUD RGB to depth
adaptation experiment. We observe that our unsupervised adaptation algorithm results in a space more conducive to recognition
of the most prevalent class of chair.
the dataset. This tendency to output pillow also explains
why the source only model achieves such abnormally high
accuracy on the pillow class, despite poor performance
on the rest of the classes.
In contrast, the classiﬁer trained using ADDA predicts a
much wider variety of classes. This leads to decreased accuracy for the pillow class, but signiﬁcantly higher accuracies for many of the other classes. Additionally, comparison
with the “train on target” model reveals that many of the
mistakes the ADDA model makes are reasonable, such as
confusion between the chair and table classes, indicating that the ADDA model is learning a useful representation
on depth images.
6. Conclusion
We have proposed a uniﬁed framework for unsupervised
domain adaptation techniques based on adversarial learning objectives. Our framework provides a simpliﬁed and
cohesive view by which we may understand and connect
the similarities and differences between recently proposed
adaptation methods. Through this comparison, we are able
to understand the beneﬁts and key ideas from each approach
and to combine these strategies into a new adaptation method,
We present evaluation across four domain shifts for our
unsupervised adaptation approach. Our method generalizes
well across a variety of tasks, achieving strong results on
benchmark adaptation datasets as well as a challenging crossmodality adaptation task. Additional analysis indicates that
the representations learned via ADDA resemble features
learned with supervisory data in the target domain much
more closely than unadapted features, providing further evidence that ADDA is effective at partially undoing the effects
of domain shift.