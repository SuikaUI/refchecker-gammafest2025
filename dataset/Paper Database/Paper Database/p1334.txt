Diffusion Probabilistic Models for 3D Point Cloud Generation
Shitong Luo, Wei Hu *
Wangxuan Institute of Computer Technology
Peking University
{luost, forhuwei}@pku.edu.cn
We present a probabilistic model for point cloud generation, which is fundamental for various 3D vision tasks
such as shape completion, upsampling, synthesis and data
augmentation.
Inspired by the diffusion process in nonequilibrium thermodynamics, we view points in point clouds
as particles in a thermodynamic system in contact with
a heat bath, which diffuse from the original distribution to a noise distribution. Point cloud generation thus
amounts to learning the reverse diffusion process that transforms the noise distribution to the distribution of a desired
shape. Speciﬁcally, we propose to model the reverse diffusion process for point clouds as a Markov chain conditioned on certain shape latent. We derive the variational
bound in closed form for training and provide implementations of the model.
Experimental results demonstrate
that our model achieves competitive performance in point
cloud generation and auto-encoding. The code is available
at 
1. Introduction
With recent advances in depth sensing and laser scanning, point clouds have attracted increasing attention as a
popular representation for modeling 3D shapes.
Significant progress has been made in developing methods for
point cloud analysis, such as classiﬁcation and segmentation . On the other hand, learning generative
models for point clouds is powerful in unsupervised representation learning to characterize the data distribution,
which lays the foundation for various tasks such as shape
completion, upsampling, synthesis, etc.
Generative models such as variational auto-encoders
(VAEs), generative adversarial networks (GANs), normal-
*Corresponding author: Wei Hu ( ). This work
was supported by the National Key R&D project of China under contract
No. 2019YFF0302903 and National Natural Science Foundation of China
under contract No. 61972009.
Figure 1. Top: The diffusion process that converts noise to some
shape (left to right). Middle: Generated point clouds from the
proposed model. Bottom: Latent space interpolation between the
two point clouds at both ends.
izing ﬂows, etc., have shown great success in image generation . However, these powerful tools cannot be directly generalized to point clouds, due to the irregular sampling patterns of points in the 3D space in contrast to regular grid structures underlying images. Hence,
learning generative models for point clouds is quite challenging. Prior research has explored point cloud generation
via GANs , auto-regressive models , ﬂowbased models and so on. While remarkable progress
has been made, these methods have some inherent limitations for modeling point clouds. For instance, the training
procedure could be unstable for GANs due to the adversarial losses. Auto-regressive models assume a generation
ordering which is unnatural and might restrict the model’s
ﬂexibility.
In this paper, we propose a probabilistic generative
model for point clouds inspired by non-equilibrium thermodynamics, exploiting the reverse diffusion process to learn
the point distribution. As a point cloud is composed of discrete points in the 3D space, we regard these points as particles in a non-equilibrium thermodynamic system in contact
with a heat bath. Under the effect of the heat bath, the position of particles evolves stochastically in the way that they
 
diffuse and eventually spread over the space. This process
is termed the diffusion process that converts the initial distribution of the particles to a simple noise distribution by
adding noise at each time step . Analogously, we
connect the point distribution of point clouds to a noise distribution via the diffusion process. Naturally, in order to
model the point distribution for point cloud generation, we
consider the reverse diffusion process, which recovers the
target point distribution from the noise distribution.
In particular, we model this reverse diffusion process as
a Markov chain that converts the noise distribution into the
target distribution. Our goal is to learn its transition kernel such that the Markov chain can reconstruct the desired
shape. Further, as the purpose of the Markov chain is modeling the point distribution, the Markov chain alone is incapable to generate point clouds of various shapes. To this
end, we introduce a shape latent as the condition for the
transition kernel. In the setting of generation, the shape latent follows a prior distribution which we parameterize via
normalizing ﬂows for strong model expressiveness.
In the setting of auto-encoding, the shape latent is learned
end-to-end. Finally, we formulate the training objective as
maximizing the variational lower bound of the likelihood
of the point cloud conditional on the shape latent, which
is further formulated into tractable expressions in closed
form. We apply our model to point cloud generation, autoencoding and unsupervised representation learning, and results demonstrate that our model achieves competitive performance on point cloud generation and auto-encoding and
comparable results on unsupervised representation learning.
Our main contributions include:
• We propose a novel probabilistic generative model for
point clouds, inspired by the diffusion process in nonequilibrium thermodynamics.
• We derive a tractable training objective from the variational lower bound of the likelihood of point clouds
conditioned on some shape latent.
• Extensive experiments show that our model achieves
competitive performance in point cloud generation and
auto-encoding.
2. Related Works
Point Cloud Generation
Early point cloud generation
methods treat point clouds as N × 3 matrices, where
N is the ﬁxed number of points, converting the point cloud
generation problem to a matrix generation problem, so that
existing generative models are readily applicable. For example, apply variational auto-encoders to point
cloud generation. employ generative adversarial networks based on a pre-trained auto-encoder. The main
defect of these methods is that they are restricted to generating point clouds with a ﬁxed number of points, and lack
the property of permutation invariance. FoldingNet and AtlasNet mitigate this issue by learning a mapping
from 2D patches to the 3D space, which deforms the 2D
patches into the shape of point clouds. These two methods
allow generating arbitrary number of points by ﬁrst sampling some points on the patches and then applying the mapping on them. In addition, the points on the patches are
inherently invariant to permutation.
The above methods rely on heuristic set distances such as
the Chamfer distance (CD) and the Earth Mover’s distance
(EMD). As pointed out in , CD has been shown to incorrectly favor point clouds that are overly concentrated in
the mode of the marginal point distribution, and EMD is
slow to compute while approximations could lead to biased
gradients.
Alternatively, point clouds can be regarded as samples
from a point distribution. This viewpoint inspires exploration on applying likelihood-based methods to point cloud
modeling and generation. PointFlow employs continous normalizing ﬂows to model the distribution of
points. DPF-Net uses afﬁne coupling layers as the normalizing ﬂow to model the distribution. PointGrow is
an auto-regressive model with exact likelihoods. More recently, proposed a score-matching energy-based model
ShapeGF to model the distribution of points.
Our method also regards point clouds as samples from a
distribution, but differs in the probabilistic model compared
to prior works. We leverage the reverse diffusion Markov
chain to model the distribution of points, achieving both
simplicity and ﬂexibility. Speciﬁcally, the training process
of our model involves learning the Markov transition kernel, whose training objective has a simple function form.
By contrast, GAN-based models involve complex adversarial losses, continuous-ﬂow-based methods involve expensive ODE integration. In addition, our model is ﬂexible,
because it does not require invertibility in contrast to ﬂowbased models, and does not assume ordering compared to
auto-regressive models.
Diffusion Probabilistic Models
The diffusion process
considered in this work is related to the diffusion probabilistic model . Diffusion probabilistic models are
a class of latent variable models, which also use a Markov
chain to convert the noise distribution to the data distribution. Prior research on diffusion probabilistic models focuses on the unconditional generation problem for toy data
and images. In this work, we focus on point cloud generation, which is a conditional generation problem, because the
Markov chain considered in our work generates points of a
point cloud conditioned on some shape latent. This conditional adaptation leads to signiﬁcantly different training and
sampling schemes compared to prior research on diffusion
probabilistic models.
3. Diffusion Probabilistic Models for Point
In this section, we ﬁrst formulate the probabilistic model
of both the forward and the reverse diffusion processes for
point clouds. Then, we formulate the objective for training
the model. The implementation of the model will be provided in the next section.
3.1. Formulation
We regard a point cloud X(0) = {x(0)
i=1 consisting of
N points as a set of particles in an evolving thermodynamic
system. As discussed in Section 1, each point xi in the point
cloud can be treated as being sampled independently from
a point distribution, which we denote as q(x(0)
i |z). Here, z
is the shape latent that determines the distribution of points.
Physically, as time goes by, the points gradually diffuse
into a chaotic set of points. This process is termed the diffusion process, which converts the original meaningful point
distribution into a noise distribution. The forward diffusion
process is modeled as a Markov chain :
where q(x(t)
) is the Markov diffusion kernel. The
kernel adds noise to points at the previous time step and
models the distribution of points at the next time step. Following the convention of , we deﬁne the diffusion kernel as:
q(x(t)|x(t−1)) = N(x(t)|
1 −βtx(t−1), βtI), t = 1, ..., T,
where β1 . . . βT are variance schedule hyper-parameters
that control the diffusion rate of the process.
Our goal is to generate point clouds with a meaningful
shape, encoded by the latent representation z.
the generation process as the reverse of the diffusion process, where points sampled from a simple noise distribution
) that approximates q(x(T )
) are given as the input.
Then, the points are passed through the reverse Markov
chain and ﬁnally form the desired shape. Unlike the forward diffusion process that simply adds noise to the points,
the reverse process aims to recover the desired shape from
the input noise, which requires training from data. We formulate the reverse diffusion process for generation as:
pθ(x(0:T )|z) = p(x(T ))
pθ(x(t−1)|x(t), z),
pθ(x(t−1)|x(t), z) = N
µθ(x(t), t, z), βtI
where µθ is the estimated mean implemented by a neural
network parameterized by θ. z is the latent encoding the
target shape of the point cloud. The starting distribution
) is set to a standard normal distribution N(0, I).
Given a shape latent z, we obtain the point cloud with
the target shape by passing a set of points sampled from
) through the reverse Markov chain.
For the sake of brevity, in the following sections, we use
the distribution with respect to the entire point cloud X(0).
Since the points in a point cloud are independently sampled
from a distribution, the probability of the whole point cloud
is simply the product of the probability of each point:
q(X(1:T )|X0) =
pθ(X(0:T )|z) =
pθ(x(0:T )
Having formulated the forward and reverse diffusion
processes for point clouds, we will formalize the training
objective of the reverse diffusion process for point cloud
generation as follows.
3.2. Training Objective
The goal of training the reverse diffusion process
is to maximize the log-likelihood of the point cloud:
E[log pθ(X(0))]. However, since directly optimizing the
exact log-likelihood is intractable, we instead maximize its
variational lower bound:
log pθ(X(0))
pθ(X(0:T ), z)
q(X(1:T ), z|X(0))
log p(X(T ))
log pθ(X(t−1)|X(t), z)
q(X(t)|X(t−1))
−log qϕ(z|X(0))
The above variational bound can be adapted into the training objective L to be minimized (the detailed derivation is
provided in the supplementary material):
L(θ, ϕ) = Eq
 q(X(t−1)|X(t), X(0))∥
pθ(X(t−1)|X(t), z)
−log pθ(X(0)|X(1), z)
 qϕ(z|X(0))∥p(z)
Since the distributions of points are independent of each
other as described in Eq. (5), we further expand the training
Figure 2. The directed graphical model of the diffusion process for point clouds. N is the number of points in the point cloud X(0).
objective:
L(θ, ϕ) = Eq
log pθ(x(0)
 qϕ(z|X(0))
The training objective can be optimized efﬁciently since
each of the terms on the right hand side is tractable and q
is easy to sample from the forward diffusion process. Next,
we elaborate on the terms to reveal how to compute the objective.
i ) can be computed with the following closed-form Gaussian according to :
i ) = N(x(t−1)
|µt(x(t), x(0)), γtI),
where, using the notation αt = 1 −βt and ¯αt = Qt
µt(x(t), x(0)) =
√αt (1 −¯αt−1)
γt = 1 −¯αt−1
⃝pθ(x(t−1)
i , z)(t = 1, . . . , T) are trainable
Gaussians as described in Eq. (4).
⃝qϕ(z|X(0)) is the approximate posterior distribution.
Using the language of variational auto-encoders,
qϕ(z|X(0)) is an encoder that encodes the input point cloud
X(0) into the distribution of the latent code z. We assume
it as a Gaussian following the convention:
q(z|X(0)) = N
 z|µϕ(X(0)), Σϕ(X(0))
⃝The last term p(z) is the prior distribution. The most
common choice of p(z) is the isotropic Gaussian N(0, I).
In addition to a ﬁxed distribution, the prior can be a trainable parametric distribution, which is more ﬂexible. For
example, normalizing ﬂows can be employed to parameterize the prior distribution.
In the following section, we show how to optimize the
objective in Eq. (9) in order to train the model.
3.3. Training Algorithm
In principle, training the model amounts to minimizing
the objective in Eq. (9). However, evaluating Eq. (9) requires summing the expectation of the KL terms over all
the time steps, which involves sampling a full trajectory
i , . . . , x(T )
from the forward diffusion process in order
to compute the expectation.
To make the training simpler and more efﬁcient, following , instead of evaluating the expectation of the whole
summation over all the time steps in Eq. (9), we randomly
choose one term from the summation to optimize at each
training step.
Speciﬁcally, this simpliﬁed training algorithm is as follows:
Algorithm 1 Training (Simpliﬁed)
Sample X(0) ∼qdata(X(0))
Sample z ∼qϕ(z|X(0))
Sample t ∼Uniform({1, . . . , T})
Sample x(t)
1 , . . . , x(t)
N ∼q(x(t)|x(0))
Lz ←DKL(qϕ(z|X(0))∥p(z))
Compute ∇θ(Lt + 1
T Lz). Then perform gradient descent.
9: until converged
Figure 3. The illustration of the proposed model. (a) illustrates how the objective is computed during the training process. (b) illustrates
the generation process.
To efﬁciently sample from q(x(t)|x(0)) (5th statement)
and avoid iterative sampling starting from t = 1, we leverage on the result in , which shows that q(x(t)|x(0)) is a
q(x(t)|x(0)) = N(x(t)|√¯αtx(0), (1 −¯αt)I).
The gaussianity of q(x(t)|x(0)) makes further simpliﬁcation on Lt (6th statement) possible by using the reparameterization trick .
We put the detail of this simpli-
ﬁcation to the supplementary material.
Last, note that
the KL divergence in Lz is evaluated stochastically by
−Ez∼qϕ(z|X(0))
qϕ(z|X(0))
4. Model Implementations
The general training objective and algorithm in the previous section lay the foundation for the formulation of speciﬁc point cloud tasks. Next, we adapt the training objective
to point cloud generation and point cloud auto-encoding respectively.
4.1. Point Cloud Generator
Leveraging on the model in Section 3, we propose a
probabilistic model for point cloud generation by employing normalizing ﬂows to parameterize the prior distribution
p(z), which makes the model more ﬂexible .
Speciﬁcally, we use a stack of afﬁne coupling layers 
as the normalizing ﬂow. In essence, the afﬁne coupling layers provide a trainable bijector Fα that maps an isotropic
Gaussian to a complex distribution. Since the mapping is
bijective, the exact probability of the target distribution can
be computed by the change-of-variable formula:
p(z) = pw(w) ·
Here, p(z) is the prior distribution in the model, Fα is the
trainable bijector implemented by the afﬁne coupling layers, and pw(w) is the isotropic Gaussian N(0, I).
As for the encoder qϕ(z|X(0)), we adopt PointNet
 as the architecture for µϕ and Σϕ of the encoder
qϕ(z|X(0)).
Substituting Eq. (14) into Eq. (9), the training objective
for the generative model is:
LG(θ, ϕ, α) = Eq
log pθ(x(0)
qϕ(z|X(0))
The algorithm for optimizing the above objective can be
naturally derived from Algorithm 1.
To sample a point cloud, we ﬁrst draw w ∼N(0, I)
and pass it through Fα to acquire the shape latent z. Then,
with the shape latent z, we sample some points {x(T )
the noise distribution p(x(T )) and pass the points through
the reverse Markov chain pθ(x(0:T )
|z) deﬁned in Eq. (3) to
generate the point cloud X(0) = {x(0)
4.2. Point Cloud Auto-Encoder
We implement a point cloud auto-encoder based on the
probabilistic model in Section 3. We employ the PointNet
as the representation encoder, denoted as Eϕ(X(0)) with
parameters ϕ, and leverage the reverse diffusion process
Table 1. Comparison of point cloud generation performance. CD is multiplied by 103, EMD is multiplied by 101, and JSD is multiplied by
COV (%, ↑)
1-NNA (%, ↓)
PC-GAN 
GCN-GAN 
TreeGAN 
PointFlow 
ShapeGF 
PC-GAN 
GCN-GAN 
TreeGAN 
PointFlow 
ShapeGF 
presented in Section 3.1 for decoding, conditioned on the
latent code produced by the encoder.
Leveraging on Eq. (9), we train the auto-encoder by minimizing the following adapted objective:
L(θ, ϕ) = Eq
i , Eϕ(X(0)))
log pθ(x(0)
i , Eϕ(X(0)))
To decode a point cloud that is encoded as the latent code
z, we sample some points {x(T )
} from the noise distribution p(x(T )
) and pass the points through the reverse Markov
chain pθ(x(0:T )
|z) deﬁned in Eq. (3) to acquire the reconstructed point cloud X(0) = {x(0)
5. Experiments
In this section, we evaluate our model’s performance on
three tasks: point cloud generation, auto-encoding, and unsupervised representation learning.
5.1. Experimental Setup
For generation and auto-encoding tasks, we employ the ShapeNet dataset containing 51,127 shapes
Figure 4. Examples of point clouds generated by our model.
from 55 categories. The dataset is randomly split into training, testing and validation sets by the ratio 80%, 15%, 5%
respectively. For the representation learning task, we use
the training split of ShapeNet to train an encoder. Then
we adopt ModelNet10 and ModelNet40 to evaluate the
representations learned by the encoder. We sample 2048
points from each of the shape to acquire the point clouds
and normalize each of them to zero mean and unit variance.
Evaluation Metrics
Following prior works, we use the
Chamfer Distance (CD) and the Earth Mover’s Distance
Table 2. Comparison of point cloud auto-encoding performance. Atlas (S1) and Atlas (P25) denote 1-sphere and 25-square variants of
AtlasNet respectively. CD is multiplied by 103 and EMD is multiplied by 102.
Atlas (S1)
Altas (P25)
Figure 5. Examples of reconstructed point clouds from different
auto-encoders.
(EMD) to evaluate the reconstruction quality of the point
clouds .
To evaluate the generation quality, we employ the minimum matching distance (MMD), the coverage score (COV), 1-NN classiﬁer accuracy (1-NNA) and the
Jenson-Shannon divergence (JSD) . The MMD score
measures the ﬁdelity of the generated samples and the COV
score detects mode-collapse. The 1-NNA score is computed
by testing the generated samples and the reference samples
by a 1-NN classiﬁer. If the performance of the classiﬁer is
close to random guess, i.e., the accuracy is close to 50%,
the quality of generated samples can be considered better.
The JSD score measures the similarity between the point
distributions of the generated set and the reference set.
Table 3. Comparison of representation learning in linear SVM
classiﬁcation accuracy.
ModelNet10
ModelNet40
AtlasNet 
PC-GAN (CD) 
PC-GAN (EMD) 
PointFlow 
ShapeGF 
5.2. Point Cloud Generation
We quantitatively compare our method with the following state-of-the-art generative models: PC-GAN , GCN-
GAN , TreeGAN , PointFlow and ShapeGF
 using point clouds from two categories in ShapeNet:
airplane and chair. Following ShapeGF , when evaluating each of the model, we normalize both generated point
clouds and reference point clouds into a bounding box of
[−1, 1]3, so that the metrics focus on the shape of point
clouds but not the scale. We evaluate the point clouds generated by the models using the metrics in Section 5.1 and
summarize the results in Table 1. We also visualize some
generated point cloud samples from our method in Figure 4.
5.3. Point Cloud Auto-Encoding
We evaluate the reconstruction quality of the proposed auto-encoder, with comparisons against state-of-theart point cloud auto-encoders: AtlasNet , PointFlow
 and ShapeGF . Four datasets are used in the evaluation, which include three categories in ShapeNet: airplane, car, chair and the whole ShapeNet.
We also report the lower bound “oracle” of the reconstruction errors.
This bound is obtained by computing the distance between
Figure 6. Latent space interpolation and extrapolation.
Figure 7. The t-SNE clustering visualization of latent codes obtained from the encoder.
two different point clouds with the same number of points
and the identical shape. As shown in Table 2, our method
outperforms other methods when measured by EMD, and
pushes closer towards the lower bounded “oracle” performance.
The CD score of our method is comparable to
Notably, when trained and tested on the whole
ShapeNet dataset, our model outperforms others in both CD
and EMD, which suggests that our model has higher capacity to encode different shapes. Also, the visualization of
reconstructed point clouds in Figure 5 validates the effectiveness of our model.
5.4. Unsupervised Representation Learning
Further, we evaluate the representation learned by our
auto-encoder.
Firstly, we train an auto-encoder with the
whole ShapeNet dataset. During the training, we augment
point clouds by applying random rotations along the gravity axis, which follows previous works. Then, we learn the
feature representations of point clouds in ModelNet-10 and
ModelNet-40 using the trained encoder, and train a linear
SVM using the codes of point clouds in the training split and
their categories. Finally, we test the SVM using the testing
split and report the accuracy in Table 3. We run the ofﬁcial
code of AtlasNet and ShapeGF to obtain the results, since
the results are not provided in their papers. For PC-GAN
and PointFlow, we use the results reported in the papers.
The performance of our encoder is comparable to related
state-of-the-art generative models.
In addition, we project the latent codes of ModelNet-10
point clouds produced by the encoder into the 2D plane using t-SNE , and present it in Figure 7. It can be observed
that there are signiﬁcant margins between most categories,
which indicates that our model manages to learn informative representations. Further, we visualize the interpolation
and extrapolation between latent codes in Figure 6.
6. Conclusions
We propose a novel probabilistic generative model for
point clouds, taking inspiration from the diffusion process
in non-equilibrium thermodynamics. We model the reverse
diffusion process for point cloud generation as a Markov
chain conditioned on certain shape latent, and derive a
tractable training objective from the variational bound of
the likelihood of point clouds. Experimental results demonstrate that the proposed model achieves the state-of-the-art
performance in point cloud generation and auto-encoding.