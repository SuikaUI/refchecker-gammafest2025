IEEE TRANSACTIONS ON NUCLEAR SCIENCE. VOL. 39, NO. 5, OCTOBER 1992
Regularized Emission Image Reconstruction
Using Imperfect Side Information
Jeffrey A. Fesslery Neal H. Clinthorne, and W. Leslie Rogers
Division of Nuclear Medicine, University of Michigan
The inadequacy of the maximum-likelihood criterion for
emission image reconstruction has spurred the develop-
ment of several regularization methods. Despite the spatial
variance of medical images, most of the proposed meth-
penalty is analogous to the “weighted-splines” approach
described in [a] for a Gaussian noise model. This regular-
izer leads to an optimality criterion with an analytically
intractable M-step, SO we apply a variant of the GEM 
iterative method. These points are considered in detail in
Section 11.
ods are spatially invariant. This paper reports an inves-
tigation of a spatially-variant penalized-likelihood method
for tomographic image reconstruction based on a weighted
Gibbs penalty.
The penalty weights are determined
from structural side information, such as the locations of
anatomical boundaries in high-resolution magnetic reso-
nance images. Such side information will be imperfect in
practice, and a simple simulation demonstrates the impor-
tance of accounting for the errors in boundary locations.
We discuss methods for prescribing the penalty weights
when the side information is noisy. Simulation results sug-
gest that even imperfect side information is useful for guid-
ing spatially-variant regularization.
I. INTRODUCTION
Many investigators have noted the inadequacy of the
maximum-likelihood (ML) criterion for emission image re-
construction, and have proposed regularization techniques
that stabilize the emission estimate. Most such methods
are spatially invariant; however, the spatial variance typi-
cal of medical images argues for the use of spatially-variant
reconstruction methods. This paper proposes using side in-
formation, such as the locations of anatomical boundaries
obtained from magnetic resonance (MR) images, to con-
trol a spatially-variant penalized-likelihood method based
on weighted Gibbs functions. An important feature of this
method is that it can accommodate imperfect side infor-
The method described is a synthesis of three recent ad-
vances in emission image reconstruction. The measure-
ment model includes the effects of attenuation and ac-
cidental coincidences, the importance of which is shown
in [l]. The use of spatially-variant weights for a Gibbs
The approach taken here is to use the side information
to generate Gibbs penalty weights that are then held fixed
for the duration of the estimation process. A more so-
phisticated approach might allow the weights to vary with
iteration. One such method involves supplementing the
emission intensity parameters with parameters represent-
ing a “line process” [4-81. These powerful techniques have
demonstrated the capability of accommodating large reg-
istration errors in computer simulations. However, since
the number of unknown parameters is at least tripled over
the case of fixed weights, they are necessarily more com-
putationally expensive. Also, the convergence properties
of the associated algorithms are less well understood than
the weighted GEM algorithm we propose. We believe that
as MR-PET registration methods improve, there will be a
class of applications, particularly in neurological imaging,
where the simpler approach described in this paper will be
The benefits of structural side information, such as
might be derived from MR images, will clearly be task
dependent. Therefore, in this paper we depart from the
conventional global performance criteria, such as likelihood
or global mean-square error, and focus on a specific local
figure-of-merit: the accuracy of quantifying total uptake
within a small region of interest (ROI) surrounded by re-
gions of relatively higher activity. Since the results of such
a study will be context dependent, we have chosen a con-
text that has significance to clinical investigators at our
institution: quantifying tracer uptake within the globus
pallidus and the putamen for patients with Huntington’s
Disease from position emission tomographic (PET) mea-
surements of regional benzodiazepine receptor density ob-
tained by injection of [”C] flumazenil [9, lo]. These small
neurological structures (see Figure 8) are poorly quanti-
fied by conventional filtered back-projection images, due
boundaries of these structures are obtainable from MR
*This work was supported in part by NCI Training Grant 5 T32
CA 09015, a DOE Alexander Hollaender Postdoctoral Fellowship,
to spill Over from the surrounding cortex. However, the
and NIH Grant CA 54362.
0018-9499/92$03.00 0 1992 IEEE
images, so an iterative reconstruction method that can ex-
ploit such side information could be beneficial.
Section I1 describes the basic models and method, which
we have applied to both a representative one-dimensional
profile and to a realistic two-dimensional computer phan-
tom with regional activities that correspond to autoradio-
graphic data. Sections I11 and IV report the simulation
results. Section V discusses the future directions of this
11. METHOD
A. Measurement model
Accurate quantification requires the use of an accurate
measurement model. In particular, as shown in [ l ] , one
should account for the effects of attenuation and acciden-
tal coincidences in PET by including them in the mea-
surement model, rather than by precorrecting the mea-
surements. Precorrection destroys the Poisson nature of
the measurements.
For simplicity, we adopt the voxelized object model,
and denote the rate of activity in the bth voxel by A b ,
b = 1 , . . . , B. The PET system consists of D detector pairs.
Let p d b denote the point-spread function (PSF) of the PET
system, i.e., p d b is the probability that, in the absence of
attenuation, an event from the bth voxel is detected by
the dth detector pair, conditioned on it being detected.
Thus x d = l p d b = 1 . Let q b denote the overall detection
probability for an event originating in the bth voxel, in the
absence of attenuation. Let p d denote the survival prob-
ability for the dth detector pair, i.e., the probability that
both of an annihilation-produced pair of photons emitted
along the d detector pair tube are detected (not attenu-
ated). Let r d denote the rate of accidental coincidences
for the dth detector pair. Then if Y d denotes the number
of events counted by the dth detector pair, we assume the
y d ’ s have independent Poisson distributions:
POiSSOn(T ‘ (E
a d b X b + r d ) ) ,
where T is the product of the scan time and correction fac-
tors such as that for radioactive decay, and a d b = P d p d b q b .
For simplicity, we absorb T into A b and r d .
B. Regularizing Penalty Function
Although one could use ( 1 ) to define an estimation method
based on the ML criterion, the resulting estimates have ex-
cessive variance for the specific tasks we are considering,
as we show in simulations below. By considering instead
an optimality criterion that is the difference between the
log-likelihood and a penalty function that discourages ex-
cessive variation between neighboring voxels, one can sig-
nificantly reduce the variance with only a small increase
in bias, thereby reducing the total RMS error. How much
bias is tolerable is clearly task dependent, and is a subject
needing further investigation.
One’s choice for the penalty function again will be task
dependent. Our hypothesis was that the task of quanti-
fying uptake within a small cold spot would benefit from
a spatially-variant penalty function, so a weighted Gibb’s
function is a natural choice. Specifically, we consider the
following penalized-likelihood estimate:
= arg max @(A)
@(A) = -1’AX + y’log(AA + r) - aV(X),
where 1 is the column vector of ones of length D,
{ a d b } , A = [A,,. . . , A B ] , r = [ r l , . . . , r D ] , and y =
[ y l , . . . , y o ] . The weighted Gibb’s function V is defined
W j , j ( A i - Ai)?
The weights W ~ J control the influence of the penalty. If
the presence of an anatomical boundary in an MR im-
age implies that the activities in two neighboring voxels
are likely to be disparate, then the corresponding weight
should be set relatively small, so as to avoid penalizing the
discrepancy. Such a scheme reduces the “edge artifact” of
spatially-invariant regularization [I 13. It is important to
note that this weighting method does not force uniformity
within anatomical regions.
In case of perfect side information, one would set wi,j
to one for neighboring pixel pairs that do not straddle a
boundary, and all other wj,j’s to zero. In practice, side
information will be imperfect due to noise in MR images,
registration errors, and discrepancies between anatomical
and functional boundaries. As we demonstrate empirically
in Section 111, it is essential to account for such errors. The
weighted Gibbs penalty method lends itself naturally to
the following approach: we first use the side information
to generate weights that would be optimal if the bound-
aries were perfect, and then blur or dilate the weights with
a kernel whose width corresponds to the uncertainty in the
side information. Though this is not necessarily the opti-
mal method for accommodating imperfect side information
(cf ), it has yielded reasonable results in simulations.
C. Iterative Algorithm
Historically, the use of objective functions such as (a), with
its Gibbs penalty, has been hampered by the slow con-
vergence of the associated stochastic maximization proce-
dures or by the uncertain behavior of locally convergent
methods. Following the usual estimate-maximize (EM) al-
gorithm derivation, one can show that the E step for (2)
y d ( x 2 ) =
a d b x ; + r d ,
n i b = Y d a db / Yd ( x i ) ,
where Ai denotes the emission estimate after the ith itera-
tion, and nib is the conditional expectation of the number
of events in the dth detector due to the bth voxel. The M
step requires maximizing:
over Ai+'. The resulting coupled set of equations ap-
pears to have no analytical solution. We experimented
with the "one step late" (OSL) method of Green 1131,
but found the necessity of line-search operations to
be computationally prohibitive. We have adopted the gen-
eralized estimate-maximize (GEM) method of Hebert and
Leahy , which, although originally applied to SPECT,
is also applicable to the PET measurement model (1). Ze-
roing the derivative of (3) with respect to Xi+' yields:
The GEM approach is to first set Xi+' = A i for all b, then
to loop through the b's in some order and to replace Xi"
with the unique positive root of (4). After considering the
discussion in , we chose the following ordering for our
one-dimensional simulations: on even iterations, the even
voxels are updated first, and then the odd voxels are up-
dated; the opposite order holds for odd iterations. Unlike
the method in , this is guaranteed to increase the penal-
ized likelihood each iteration . For the two-dimensional
simulations, we applied the raster-scan order of .
The convergence of the GEM algorithm has been ad-
dressed in , under the assumption that the penalized
log-likelihood (2) is a strictly convex function of A. This
was established in by showing that the log-likelihood
(for a SPECT measurement model) is convex, and the
penalty term is strictly convex. In our case, it is possi-
ble that several weights could be set to zero, in which case
the penalty term may not be strictly convex (although it
would remain convex). Fortunately, the presence of acci-
dental coincidences in PET ensures that the log-likelihood
term is strictly convex, provided the matrix A has full
column rank .
111. 1D SIMULATION
To explore the possible benefits of spatially-variant regu-
larization in the presence of imperfect structural side in-
formation, we performed simulations based on the one-
dimensional profile shown in Figure 1. This profile is
representative of the flumazenil quantification task. The
nonuniform cold spot represents the putamen, which is ad-
jacent to the globus pallidus and the cortex, both of which
have significantly higher activity. For this simulation, the
diameter of the cold spot is 7 pixels. The system matrix
A corresponds to a triangular point spread function with
a FWHM of 5 pixels. A typical measurement realization
y is shown in Figure 2.
Our task is to quantify the total uptake within the cold
spot. This task requires two components: 1) reconstruct-
ing the activity distribution from the noisy measurements,
and 2) identifying the boundaries of the region of interest
(ROI) and integrating the activity within that ROI. Here
we focus only on the first task by integrating the activity
within the true ROI (pixels 33 through 39) for all simula-
We have examined the performance of the GEM recon-
struction method as a function of the regularization pa-
rameter a in four scenarios. For each scenario and for each
value of a,
50 measurement realizations were reconstructed
via 1000 iterations of the GEM algorithm.
0 Case 1: No side information was available, so all the
weights wb were set to 1. This corresponds to conven-
tional spatially-invariant regularization.
0 Case 2: Perfect side information corresponding to the
edge locations was used. Specifically, ~
= w39 = 0,
and all other weights were set to 1. Thus, the weights
for pixel pairs that straddled an edge of the cold spot
were set to 0, thereby reducing spill over.
0 Case 3: Imperfect side information was simulated. Let
bl and b, denote the left and right edges of the cold
spot as they might be determined from an MR im-
age. (These two values are the side information). For
each realization, bl was randomly selected from the
set {31,32,33}, and b, was randomly selected from
the set {38,39,40}. For Case 3, the side information
was applied "blindly," i.e., we set wbl = Wb, = 0 and
all other weights to 1, despite the fact that 61 and b,
are usually incorrect.
0 Case 4: Imperfect side information with the same er-
ror distribution as in Case 3. However, for Case 4 we
made the following heuristic attempt to account for
the errors in bl and b,: we set wb,-l = Wb, = wb1+1 =
wb,-l = Wb, = Wb,+l = 0.01, and all other weights
to 1. This small band of weights corresponds to a
dilation of the ideal weights, and allows for a rapid
activity transition in the neighborhood of edge loca-
tion specified by the noisy side information.
Figure 3 displays the percent root mean-square (RMS)
error in total uptake within the cold spot as a function of
the regularization parameter a. The optimal performance
of each method is summarized in Table I. It is useful to
compare the mean of the 50 reconstructions for each case
with the true activity distribution; these are shown in Fig-
The dotted bands around each curve represent
one standard deviation above and below the mean. The
curve for each case corresponds to the value aopt shown in
Table I that minimized the RMS error. The four cases il-
lustrate the tradeoff between bias and variance: Case l has
high variance, but additional smoothing would cause more
increase in bias than decrease in variance. Case 2 has low
variance and low bias since the edges are known perfectly.
Case 4 improves over Case 3 by significantly reducing the
bias with slight increase in variance.
Iv. 2D SIMULATION
The one-dimensional simulation results encouraged our
proceeding to evaluate the method on a realistic computer
phantom. Figure 8 shows the true emission distribution
used for this study. The anatomical boundaries in this
image were obtained by manually tracing a photographic
atlas. The regional emission intensities were assigned rel-
ative values based on autoradiographic measurements.
The simulated PET measurements included the effects
of nonuniform attenuation (due to skull), accidental co-
incidences (RZ 8%), and finite detector response (6”
FWHM). We assumed the survival probabilities and ac-
cidental coincidence rates were known.
(However, our
method has been implemented in conjunction with the
joint-likelihood method of that accounts for noise in
transmission measurements). Each PET measurement re-
alization contained approximately lo6 total counts, dis-
tributed over 100 angles by 64 bins. The reconstructed
object size was 50 x 64 pixels with 4mm sides.
For each reconstruction method shown in the figures, 30
pseudo-random Poisson distributed realizations were re-
constructed. For each realization, the total uptake within
the true region of support for the globus pallidus and
putamen were computed. The conventional filtered back-
projection reconstructions are shown in Figure 8, for both
a ramp filter, and a Hanning-windowed ramp filter with a
cutoff at the Nyquist frequency. The percent bias, stan-
dard deviation, and root mean-square (RMS) error are
summarized in Table 11. The iterative methods were ran
for 300 iterations, with the total uptake computed for every
fifth iteration. The resulting bias and variance are plotted
as trajectories in Figures 10-12. The semi-ellipses in those
figures correspond to contours of constant RMS error.
We compared three iterative methods: sieve-constrained
EM algorithm [ll], weighted Gibbs penalty GEM with per-
fect side information, and GEM with blurred weights. The
latter case corresponds to degrading the perfect side infor-
mation with a 6mm FWHM kernel-this
figure is compa-
rable to recently published MR-PET registration accura-
cies. Each method was evaluated for several values of the
regularization parameter a. The sieve-constrained EM al-
gorithm was evaluated for larger kernel sizes than 4mm
FWHM, but the resulting uptake estimates had signifi-
cantly worse RMS error. Sieve-constrained EM is a spa-
tially invariant method, and therefore does not reduce spill
over into the small ROI’s considered here. Figure 9 dis-
plays representative reconstructions for the three iterative
methods. Table I1 summarizes the error statistics for the
different methods at the 300th iteration.
V. DISCUSSION
The results summarized in Tables I and I1 demonstrate
that the use of structural side information, in conjunction
with a spatially variant reconstruction method, can signif-
icantly reduce RMS error over spatially invariant regular-
ization. In the one-dimensional case, the RMS error was
reduced by almost a factor of 3 with the use of perfect side
information. For the two-dimensional simulation, the RMS
error in uptake within the globus pallidus was reduced by
over a factor of 4. However, the one-dimensional results
clearly demonstrate that if the side information is imper-
fect, then using it “blindly” is unlikely to be significantly
beneficial for this type of quantification task. In the one-
dimensional example, we applied a simple heuristic scheme
(weight dilation) to account for the uncertainty in the side
information, and were able to recover some of the bene-
fits of the side information, despite its imperfections. The
results with blurred weights for the two-dimensional case
are less impressive, and more investigation into how to ef-
ficiently use imperfect side information is clearly needed.
VI. ACKNOWLEDGEMENT
The authors gratefully acknowledge the contributions of
G. Hutchins and R. Koeppe.