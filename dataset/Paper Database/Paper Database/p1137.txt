TECHNICAL WORKING PAPER SERIES
NONPARAMETRIC ESTIMATION OF AVERAGE
TREATMENT EFFECTS UNDER EXOGENEITY: A REVIEW
Guido Imbens
Technical Working Paper 294
 
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
October 2003
This paper was presented as an invited lecture at the Australian and European meetings of the Econometric
Society in July and August 2003. I am also grateful to Joshua Angrist, Jane Herr, Caroline Hoxby, Charles
Manski, Xiangyi Meng, Robert Moffitt, and Barbara Sianesi, and two referees for comments and to a number
of collaborators, Alberto Abadie, Joshua Angrist, Susan Athey, Gary Chamberlain, Keisuke Hirano, V.
Joseph Hotz, Charles Manski, Julie Mortimer, Jack Porter, Whitney Newey, Geert Ridder, Paul Rosenbaum,
and Donald Rubin, for many discussions on the topics of this paper. Financial support for this research was
generously provided through NSF grants SBR 9818644 and SES 0136789 and the Giannini Foundation.
Electronic correspondence: , The views
expressed in this paper are those of the authors and not necessarily those of the National Bureau of Economic
© 2003 by Guido Imbens. All rights reserved. Short sections of text, not to exceed two paragraphs, may
be quoted without explicit permission provided that full credit, including © notice, is given to the source.
Nonparametric Estimation of Average Treatment Effects under Exogeneity: A Review
Guido Imbens
NBER Technical Working Paper No. 294
October 2003
JEL No. C14, C21, C52
Recently there has been a surge in econometric work focusing on estimating average treatment effects
under various sets of assumptions. One strand of this literature has developed methods for estimating
average treatment effects for a binary treatment under assumptions variously described as exogeneity,
unconfoundedness, or selection on observables. The implication of these assumptions is that systematic
(e.g., average or distributional) differences in outcomes between treated and control units with the same
values for the covariates are attributable to the treatment. Recent analysis has considered estimation and
inference for average treatment effects under weaker assumptions than typical of the earlier literature
by avoiding distributional and functional form assumptions. Various methods of semiparametric
estimation have been proposed, including estimating the unknown regression functions, matching,
methods using the propensity score such as weighting and blocking, and combinations of these
approaches. In this paper I review the state of this literature and discuss some of its unanswered
questions, focusing in particular on the practical implementation of these methods, the plausibility of
this exogeneity assumption in economic applications, the relative performance of the various
semiparametric estimators when the key assumptions (unconfoundedness and overlap) are satisfied,
alternative estimands such as quantile treatment effects, and alternate methods such as Bayesian
inference.
Guido W. Imbens
Department of Economics
University of California at Berkeley
330 Giannini Hall
Berkeley, CA 94720-3880
 
Introduction
Since the work by Ashenfelter , Card and Sullivan , Heckman and Robb ,
Lalonde and others, there has been much interest in econometric methods for estimating
the eﬀects of active labor market programs such as job search assistance or classroom teaching
programs. This interest has led to a surge in theoretical work focusing on estimating average
treatment eﬀects under various sets of assumptions. See for general surveys of this literature
Angrist and Krueger , Heckman, Lalonde and Smith , and Blundell and Costa-Dias
One strand of this literature has developed methods for estimating the average eﬀect of
receiving or not receiving a binary treatment under the assumption that the treatment satisﬁes
some form of exogeneity. Diﬀerent versions of this assumption are referred to as unconfoundedness , selection on observables , or conditional independence .
In the remainder of this paper I will use the terms unconfoundedness and exogeneity interchangeably to denote the assumption that the receipt of treatment is independent of the potential outcomes with and without treatment once certain observable covariates are held constant.
The implication of these assumptions is that systematic (e.g., average or distributional) diﬀerences in outcomes between treated and control units with the same values for these covariates
are attributable to the treatment.
Much of the recent work, building on the statistical literature by Cochran , Cochran
and Rubin , Rubin , Rosenbaum and Rubin , Holland and others, considers estimation and inference without distributional and functional
form assumptions. Hahn derived eﬃciency bounds assuming only unconfoundedness and
some regularity conditions and proposed an eﬃcient estimator. Various alternative estimators
have been proposed given these conditions. These estimation methods can be grouped into ﬁve
categories: (i) methods based on estimating the unknown regression functions of the outcome
on the covariates , Imbens, Newey and Ridder , (ii) matching on covariates (iii) methods based on the propensity score including blocking
 and weighting , (iv) combinations of these approaches, for example weighting and regression 
or matching and regression , and (v) Bayesian methods, which have
found relatively little following since Rubin . In this paper I will review the state of this
literature – with particular emphasis on implications for empirical work – and discuss some of
the remaining questions.
The organization of the paper is as follows. In Section 2 I will introduce the notation and
the assumptions used for identiﬁcation. I will also discuss the diﬀerence between population
and sample average treatment eﬀects. The recent econometric literature has largely focused on
estimation of the population average treatment eﬀect and its counterpart for the subpopulation
of treated units.
An alternative, following the early experimental literature, , is to consider estimation of the average eﬀect of the treatment for the units in
the sample. Many of the estimators proposed can be interpreted as estimating either the average
treatment eﬀect for the sample at hand, or the average treatment eﬀect for the population.
Although the choice of estimand may not aﬀect the form of the estimator, it has implications
for the eﬃciency bounds and for the form of estimators of the asymptotic variance; the variance
of estimators for the sample average treatment eﬀect are generally smaller. In Section 2 I will
also discuss alternative estimands. Almost the entire literature has focused on average eﬀects.
However in many cases such measures may mask important distributional changes. These can
be captured more easily by focusing on quantiles of the distributions of potential outcomes, in
the presence and absence of the treatment .
In Section 3 I will discuss in more detail some of the recently proposed semiparametric
estimators for the average treatment eﬀect, including those based on regression, matching and
the propensity score. I will focus particularly on implementation, and compare the diﬀerent
decisions faced regarding smoothing parameters using the various estimators.
In Section 4 I will discuss estimation of the variances of these average treatment eﬀect
estimators. For most of the estimators introduced in the recent literature, corresponding estimators for the variance have also been proposed, typically requiring additional nonparametric
regression. In practice, however, researchers often rely on bootstrapping, although this method
has not been formally justiﬁed. In addition, if one is interested in the average treatment eﬀect
for the sample, bootstrapping is clearly inappropriate. Here I discuss in more detail a simple
estimator for the variance for matching estimators, developed by Abadie and Imbens ,
that does not require additional nonparametric estimation.
Section 5 discusses diﬀerent approaches to assessing the plausability of the two key assumptions, exogeneity or unconfoundedness and overlap in the covariate distributions. The ﬁrst of
these assumptions is in principle untestable. Nevertheless a number of approaches have been
proposed that are useful for addressing its credibility . One may also wish to assess the responsiveness of the results to this assumption using
a sensitivity analysis , or, in its extreme form, a
bounds analysis . The second assumption is that there exists appropriate overlap in the covariate distributions of the treated and control units. The assumption of
overlap in the treated and control subpopulations is eﬀectively an assumption on the joint distribution of observable variables. However, as it only involves inequality restrictions, there are
no direct tests of this null. Nevertheless, in practice it is often very important to assess whether
there is suﬃcient overlap to draw credible inferences. Lacking overlap for the full sample, one
may wish to limit inferences to the average eﬀect for the subset of the covariate space where
there exists overlap between the treated and control observations.
In Section 6 I discuss a number of implementations of average treatment eﬀect estimators.
The ﬁrst set of implementations involve comparisons of the non-experimental estimators to
results based on randomized experiments, allowing direct tests of the unconfoundedness assumption. The second set consists of simulation studies, using data created either to fulﬁll the
unconfoundedness assumption or to fail it a known way, designed to compare the applicability
of the various treatment eﬀect estimators in these diverse settings.
This survey will not address alternatives for estimating average treatment eﬀects that do not
rely on exogeneity assumptions. This includes approaches where selected observed covariates are
not adjusted for, such as instrumental variables analyses . I will also not discuss methods exploiting the
presence of additional data, such as diﬀerence-in-diﬀerences in repeated cross-sections , and regression
discontinuity where the overlap assumption is violated . I will also
limit the discussion to binary treatments, excluding models with static multi-valued treatments
as in Imbens and Lechner and models with dynamic treatment regimes as in Ham
and Lalonde , Gill and Robins and Abbring and Van Den Berg . Reviews
of many of these methods can be found in Angrist and Krueger , Heckman, Lalonde and
Smith , and Blundell and Costa-Dias .
Estimands, Identiﬁcation and Eﬃciency Bounds
Deﬁnitions
In this paper I will use the potential outcome notation that dates back to the analysis of
randomized experiments by Fisher and Neyman . After being forcefully advocated
in a series of papers by Rubin , this notation is now standard in the literature
on both experimental and non-experimental program evaluation.
We begin with N units, indexed by i = 1, . . . , N, viewed as drawn randomly from a large
population. Each unit is characterized by a pair of potential outcomes, Yi(0) for the outcome
under the control treatment and Yi(1) for the outcome under the active treatment. In addition,
each unit has a vector of characteristics, referred to as covariates, pretreatment variables or
exogenous variables, and denoted by Xi.1 It is important that these variables are not aﬀected
by the treatment. Often they take their values prior to the unit being exposed to the treatment,
although this is not suﬃcient for the conditions they need to satisfy. Importantly, this vector
of covariates can include lagged outcomes. Finally, each unit is exposed to a single treatment;
Wi = 0 if unit i receives the control treatment and Wi = 1 if unit i receives the active treatment.
We therefore observe for each unit the triple (Wi, Yi, Xi), where Yi is the realized outcome:
Yi ≡Yi(Wi) =
if Wi = 0,
if Wi = 1.
Distributions of (W, Y, X) refer to the distribution induced by the random sampling from the
superpopulation.
Several additional pieces of notation will be useful in the remainder of the paper. First,
the propensity score is deﬁned as the conditional probability
1Calling such variables exogenous is somewhat at odds with several formal deﬁnitions of exogeneity , as knowledge of their distribution can be informative about the average
treatment eﬀects. It does, however, agree with common usage. See for example, Manski, Sandefur, McLanahan,
and Powers . See also Fr¨olich and Hirano, Imbens and Ridder for additional discussion.
of receiving the treatment,
e(x) ≡Pr(W = 1|X = x) = E[W|X = x].
Also, deﬁne, for w ∈{0, 1}, the two conditional regression and variance functions:
µw(x) ≡E[Y (w)|X = x],
w(x) ≡V(Y (w)|X = x).
Finally, let ρ(x) be the conditional correlation coeﬃcient of Y (0) and Y (1) given X = x. As
one never observes Yi(0) and Yi(1) for the same unit i, the data only contain indirect and very
limited information about this correlation coeﬃcient.2
Estimands: Average Treatment Eﬀects
In this discussion I will primarily focus on a number of average treatment eﬀects (ATEs). This
is less limiting than it may seem, however, as this includes averages of arbitrary transformations
of the original outcomes. Later I will return brieﬂy to alternative estimands that can not be
written in this form.
The ﬁrst estimand, and the most commonly studied in the econometric literature, is the
population average treatment eﬀect (PATE):
τ P = E[Y (1) −Y (0)].
Alternatively we may be interested in the population average treatment eﬀect for the treated
 :
T = E[Y (1) −Y (0)|W = 1].
Heckman and Robb and Heckman, Ichimura and Todd argue that the subpopulation of treated units is often of more interest than the overall population in the context of
narrowly targeted programs. For example, if a program is speciﬁcally directed at individuals
disadvantaged in the labor market, there is often little interest in the eﬀect of such a program
on individuals with strong labor market attachment.
I will also look at sample average versions of these two population measures. These estimands focus on the average of the treatment eﬀect in the speciﬁc sample, rather than in the
population at large. These include, the sample average treatment eﬀect (SATE):
Yi(1) −Yi(0)
and the sample average treatment eﬀect for the treated (SATT):
Yi(1) −Yi(0)
2As Heckman, Smith, and Clemens point out, however, one can draw some limited inferences about
the correlation coeﬃcient from the shape of the two marginal distributions of Y (0) and Y (1).
where NT = PN
i=1 Wi is the number of treated units. The sample average treatment eﬀects have
received little attention in the recent econometric literature, although it has a long tradition in
the analysis of randomized experiments . Without further assumptions,
the sample contains no information about the population ATE beyond the sample ATE. To see
this, consider the case where we observe the sample (Yi(0), Yi(1), Wi, Xi), i = 1, . . . , N; that is,
we observe for each unit both potential outcomes. In that case the sample average treatment
eﬀect, τ S = P
i(Yi(1)−Yi(0))/N, can be estimated without error. Obviously the best estimator
for the population average eﬀect, τ P , is τ S. However, we cannot estimate τ P without error
even with a sample where all potential outcomes are observed, because we lack the potential
outcomes for those population members not included in the sample. This simple argument
has two implications. First, one can estimate the sample ATE at least as accurately as the
population ATE, and typically more so. In fact, the diﬀerence between the two variances is
the variance of the treatment eﬀect, which is zero only when the treatment eﬀect is constant.
Second, a good estimator for one average treatment eﬀect is automatically a good estimator for
the other. One can therefore interpret many of the estimators for PATE or PATT as estimators
for SATE or SATT, with lower implied standard errors as discussed in more detail in Section
A third pair of estimands combines features of the other two. These estimands, introduced
in Abadie and Imbens , focus on the average treatment eﬀect conditional on the sample
distribution of the covariates. Formally, the conditional average treatment eﬀect (CATE) is
deﬁned as:
Yi(1) −Yi(0)
and the sample average treatment eﬀect for the treated (CATT):
Yi(1) −Yi(0)
Using the same argument as in the previous paragraph, it can be shown that one can estimate
CATE and CATT more accurately than PATE and PATT.
The diﬀerence in asymptotic variances forces the researcher to take a stance on what the
quantity of interest is. For example, in a speciﬁc application one can legitimately reach the
conclusion that there is no evidence, at the 95% level, that the PATE is diﬀerent from zero,
whereas there may be compelling evidence that the SATE and CATE are positive. Typically
researchers in econometrics have focused on the PATE, but one can argue that it is of interest,
when one cannot ascertain the sign of the population-level eﬀect, to know whether one can
determine the sign of the eﬀect for the sample. Especially in cases, which are all too common,
where it is not clear whether the sample is representative of the population of interest, results
for the sample at hand may be of considerable interest.
Identiﬁcation
We make the following key assumption about the treatment assignment:
Assumption 2.1 (Unconfoundedness)
Y (0), Y (1)
This assumption was ﬁrst articulated in this form in Rosenbaum and Rubin who refer to
it as ”ignorable treatment assignment.” Lechner refers to this as the “conditional independence assumption,” Following work by Barnow, Cain and Goldberger in a regression
setting it is also referred to as “selection on observables.”
To see the link with standard exogeneity assumptions, suppose that the treatment eﬀect is
constant: τ = Yi(1) −Yi(0) for all i. Suppose also that the control outcome is linear in Xi:
Yi(0) = α + X′
with εi ⊥Xi. Then we can write
Yi = α + τ · Wi + X′
Given the constant treatment eﬀect assumption, unconfoundedness is equivalent to independence of Wi and εi conditional on Xi, which would also capture the idea that Wi is exogenous.
Without this constant treatment eﬀect assumption, however, unconfoundedness does not imply
a linear relation with (mean-)independent errors.
Next, we make a second assumption regarding the joint distribution of treatments and
covariates:
Assumption 2.2 (Overlap)
0 < Pr(W = 1|X) < 1.
For many of the formal results one will also need smoothness assumptions on the conditional
regression functions and the propensity score (µw(x) and e(x)), and moment conditions on
Y (w). I will not discuss these regularity conditions here. Details can be found in the references
for the speciﬁc estimators given below.
There has been some controversy about the plausibility of Assumptions 2.1 and 2.2 in
economic settings and thus the relevance of the econometric literature that focuses on estimation
and inference under these conditions for empirical work. In this debate it has been argued
that agents’ optimizing behavior precludes their choices being independent of the potential
outcomes, whether or not conditional on covariates. This seems an unduly narrow view. In
response I will oﬀer three arguments for considering these assumptions. The ﬁrst is a statistical,
data descriptive motivation.
A natural starting point in the evaluation of any program is
a comparison of average outcomes for treated and control units.
A logical next step is to
adjust any diﬀerence in average outcomes for diﬀerences in exogenous background characteristics
(exogenous in the sense of not being aﬀected by the treatment). Such an analysis may not lead to
the ﬁnal word on the eﬃcacy of the treatment, but its absence would seem diﬃcult to rationalize
in a serious attempt to understand the evidence regarding the eﬀect of the treatment.
A second argument is that almost any evaluation of a treatment involves comparisons of
units who received the treatment with units who did not. The question is typically not whether
such a comparison should be made, but rather which units should be compared, that is, which
units best represent the treated units had they not been treated. Economic theory can help in
classifying variables into those that need to be adjusted for versus those that do not, on the
basis of their role in the decision process (e.g., whether they enter the utility function or the
constraints). Given that, the unconfoundedness assumption merely asserts that all variables
that need to be adjusted for are observed by the researcher. This is an empirical question, and
not one that should be controversial as a general principle. It is clear that settings where some
of these covariates are not observed will require strong assumptions to allow for identiﬁcation.
Such assumptions include instrumental variables settings where some covariates are assumed
to be independent of the potential outcomes. Absent those assumptions, typically only bounds
can be identiﬁed .
A third, related, argument is that even when agents optimally choose their treatment, two
agents with the same values for observed characteristics may diﬀer in their treatment choices
without invalidating the unconfoundedness assumption if the diﬀerence in their choices is driven
by diﬀerencese in unobserved characteristics that are themselves unrelated to the outcomes of
interest. The plausability of this will depend critically on the exact nature of the optimization
process faced by the agents. In particular it may be important that the objective of the decision
maker is distinct from the outcome that is of interest to the evaluator. For example, suppose
we are interested in estimating the average eﬀect of a binary input (e.g., a new technology)
on a ﬁrm’s output.3 Assume production is a stochastic function of this input because other
inputs (e.g., weather) are not under the ﬁrm’s control, or Yi = g(W, εi). Suppose that proﬁts
are output minus costs, πi = Yi −ci · Wi, and also that a ﬁrm chooses a production level to
maximize expected proﬁts, equal to output minus costs:
Wi = arg max
E[π(w)|ci] = arg max
E[g(w, εi) −ci · w|ci],
Wi = 1{E[g(1, ε) −g(0, εi) ≥ci|ci]} = h(ci).
If unobserved marginal costs ci diﬀer between ﬁrms, and these marginal costs are independent
of the errors εi in the ﬁrms’ forecast of production given inputs, then unconfoundedness will
(g(0, ε), g(εi)) ⊥ci.
Note that under the same assumptions one cannot necessarily identify the eﬀect of the input
on proﬁts since (πi(0), π(1)) are not independent of ci. See for a related discussion, in the
3If we are interested in the average eﬀect for ﬁrms who did adopt the new technology, PATT, the following
assumptions can be weakened slightly.
context of instrumental variables, Athey and Stern .
Heckman, Lalonde and Smith
 discuss alternative models that justify unconfoundedness. In these models individuals
do attempt to optimize the same outcome that is the variable of interest to the evaluator. They
show that selection on observables assumptions can be justiﬁed by imposing restrictions on the
way individuals form their expectations about the unknown potential outcomes. In general,
therefore, a researcher may wish to, either as a ﬁnal analysis or as part of a larger investigation,
consider estimates based on the unconfoundedness assumption.
Given the two key assumptions, unconfoundedness and overlap, one can identify the average
treatment eﬀects. The key insight is that given unconfoundedness, the following equalities holds:
µw(x) = E[Y (w)|X = x] = E[Y (w)|W = w, X = x] = E[Y |W = w, X = x],
and µw(x) is identiﬁed. Thus one can estimate the average treatment eﬀect τ by ﬁrst estimating
the average treatment eﬀect for a subpopulation with covariates X = x:
τ(x) ≡E[Y (1) −Y (0)|X = x] = E[Y (1)|X = x] −E[Y (0)|X = x]
= E[Y (1)|X = x, W = 1] −E[Y (0)|X = x, W = 0]
= E[Y |X, W = 1] −E[Y |X, W = 0].
To make this feasible, one needs to be able to estimate the expectations E[Y |X = x, W = w]
for all values of w and x in the support of these variables. This is where the second assumption
enters. If the overlap assumption is violated at X = x, it would be infeasible to estimate both
E[Y |X = x, W = 1] and E[Y |X = x, W = 0] because at those values of x there would be either
only treated or only control units.
Some researchers use weaker versions of the unconfoundedness assumption . If the interest is in the population average treatment eﬀect, it is
suﬃcient to assume that
Assumption 2.3 (Mean Independence)
E[Y (w)|W, X] = E[Y (w)|X],
for w = 0, 1.
Although this assumption is unquestionably weaker, in practice it is rare that a convincing case
is made for the weaker assumption 2.3 without the case being equally strong for the stronger
version 2.1. The reason is that the weaker assumption is intrinsically tied to functional form
assumptions, and as a result one cannot identify average eﬀects on transformations of the
original outcome (e.g., logarithms) without the strong assumption.
One can weaken the unconfoundedness assumption in a diﬀerent direction if one is only
interested in the average eﬀect for the treated . In
that case one need only assume
Assumption 2.4 (Unconfoundedness for Controls)
and the weaker overlap assumption
Assumption 2.5 (Weak Overlap)
Pr(W = 1|X) < 1.
These two assumptions are suﬃcient for identiﬁcation of PATT and SATT because moments
of the distribution of Y (1) for the treated are directly estimable.
An important result building on the unconfoundedness assumption shows that one need not
condition simultaneously on all covariates. The following result shows that all biases due to
observable covariates can be removed by conditioning solely on the propensity score:
Lemma 2.1 
Suppose that Assumption 2.1 holds. Then:
Y (0), Y (1)
Proof: We will show that Pr(W = 1|Y (0), Y (1), e(X)) = Pr(W = 1|e(X)) = e(X), implying
independence of (Y (0), Y (1)) and W conditional on e(X). First, note that
Pr(W = 1|Y (0), Y (1), e(X)) = E[W = 1|Y (0), Y (1), e(X)]
E[W|Y (0), Y (1), e(X), X]
Y (0), Y (1), e(X)
E[W|Y (0), Y (1), X]
Y (0), Y (1), e(X)
Y (0), Y (1), e(X)
= E [e(X)|Y (0), Y (1), e(X)] = e(X),
where the last equality follows from unconfoundedness. The same argument shows that
Pr(W = 1|e(X)) = E[W = 1|e(X)] = E
E[W = 1|X]
= E [e(X)|e(X)] = e(X).
Extensions of this result to the multivalued treatment case are given in Imbens and
Lechner .
To provide intuition for the Rosenbaum-Rubin result, recall the textbook
formula for omitted variable bias in the linear regression model. Suppose we have a regression
model with two regressors:
Yi = β0 + β1 · Wi + β′
The bias of omitting X from the regression on the coeﬃcient on W is equal to β′
2δ, where δ is
the vector of coeﬃcients on W in regressions of the elements of X on W. By conditioning on
the propensity score we remove the correlation between X and W because X ⊥W|e(X). Hence
omitting X no longer leads to any bias (although it may still lead to some eﬃciency loss).
Distributional and Quantile Treatment Eﬀects
Most of the literature has focused on estimating average treatment eﬀects. There are, however, many cases where one may wish to estimate other features of the joint distribution of
Lehman and Doksum introduce quantile treatment eﬀects as the
diﬀerence in quantiles between the two marginal treated and control outcome distributions.4
Gelbach and Hoynes estimate these in a randomized evaluation of a social program.
In instrumental variables settings Abadie, Angrist and Imbens and Chernozhukov and
Hansen investigate estimation of diﬀerences in quantiles of the two marginal potential
outcome distributions, either for the entire population or for subpopulations.
Assumptions 2.1 and 2.2 also allow for identiﬁcation of the full marginal distributions of
Y (0) and Y (1). To see this, ﬁrst note that we can identify not just the average treatment
eﬀect τ(x), but also the averages of the two potential outcomes, µ0(x) and µ0(x). Second, by
these assumptions we can similarly identify the average of any function of the basic outcome,
E[g(Y (0))] and E[g(Y (1))]. Hence we can identify the average value of the indicator1 1{Y (0) ≤
y} and 1{Y (1) ≤y}, and thus the distribution function of the potential outcomes at y. Given
identiﬁcation of the two distribution functions, it is clear that one can also identify quantiles of
the two potential outcome distributions. Firpo develops an estimator for such quantiles
under unconfoundedness.
Eﬃciency Bounds and Asymptotic Variances for Population Average
Treatment Eﬀects
Next I review some results on the eﬃency bound for estimators of the average treatment eﬀects
τ P , and τ P
T . This requires both the assumptions of unconfoundedness and overlap (Assumption
2.1 and 2.2) and some smoothness assumptions on the conditional expectations of potential
outcomes and the treatment indicator . Formally, Hahn 
shows that for any regular estimator for τ P , denoted by ˆτ, with
N · (ˆτ −τ P )
−→N(0, V ),
we can show that
1 −e(X) + (τ(X) −τ P )2
Knowing the propensity score does not aﬀect this eﬃciency bound.
Hahn also shows that asymptotically linear estimators exist with such variance, and hence
such eﬃcient estimators can be approximated as
ˆτ = τ P + 1
ψ(Yi, Wi, Xi, τ P ) + op(N −1/2),
4In contrast, Heckman, Smith and Clemens , focus on estimation of bounds on the joint distribution
of (Y (0), Y (1)). One cannot without strong untestable assumptions identify the full joint distribution, since one
can never observe both potential outcomes simultaneously, but one can nevertheless derive bounds on functions
of the two distributions.
where ψ(·) is the eﬃcient score:
ψ(y, w, x, τ P ) =
e(x) −(1 −w)y
· (w −e(x)).
Hahn also reports the eﬃciency bound for τ P
T , both with and without knowledge of
the propensity score. For τ P
T the eﬃciency bound given knowledge of e(X) is
e(X)Var(Y (1)|X)
+ e(X)2Var(Y (0)|X)
E[e(X)]2(1 −e(X)) + (τ(X) −τ P
T )2 e(X)2
If the propensity score is not known, unlike the bound for τ P, the eﬃciency bound for τ P
aﬀected. For τ P
T the bound without knowledge of the propensity score is
e(X)Var(Y (1)|X)
+ e(X)2Var(Y (0)|X)
E[e(X)]2(1 −e(X)) + (τ(X) −τ P
which is higher by
(τ(X) −τ P
T )2 · e(X)(1 −e(X))
The intuition that knowledge of the propensity score aﬀects the eﬃciency bound for the average
eﬀect for the treated (PATT), but not for the overall average eﬀect (PATE) goes as follows.
Both are weighted averages of the treatment eﬀect conditional on the covariates, τ(x). For
PATE the weight is proportional to the density of the covariates, whereas for PATT the weight
is proportional to the produce of the density of the covariates and the propensity score . Knowledge of the propensity score implies one does not
need to estimate the weight function and thus improves precision.
Eﬃciency Bounds and Asymptotic Variances for Conditional and Sample
Average Treatment Eﬀects
Consider the leading term of the eﬃcient estimator for PATE, ˜τ = τ P + ¯ψ, where ¯ψ =
(1/N) P ψ(Yi, Wi, Xi, τ P ), and let us view this as an estimator for the sample average treatment
eﬀect, SATE, instead of as an estimator for the population average, PATE. I will show that,
ﬁrst, this estimator is unbiased, conditional on the covariates and the potential outcomes, and
second, that it has lower variance as an estimator of SATE than when viewed as an estimator
of PATE. To see that the estimator is unbiased note that with the eﬃcient score ψ(y, w, x, τ)
given in (),
E[ψ(Y, W, X, τ P |Y (0), Y (1), X)] = Y (1) −Y (0) −τ P,
E[˜τ|(Yi(0), Yi(1), Xi)N
i=1]E[ ¯ψ] + τ P = 1
(Yi(1) −Yi(0)) .
E[˜τ −τ S|(Yi(0), Yi(1), Xi)N
(Yi(1) −Yi(0)) −τ S = 0.
Next, consider the normalized variance:
V P = N · E
h ˜τ −τ S2i
h  ¯ψ + τ P −τ S2i
Note that the variance of ˜τ as an estimator of τ P is, using the fact that ψ(·) is the eﬃcient
(˜τ −τ P )2] = N · E[( ¯ψ)2
¯ψ(Y, W, X, τ P ) + (τ P −τ S) −(τ P −τ S)
¯ψ(Y, W, X, τ P ) + (τ P −τ S)
τ P −τ Si
as follows by using iterated expectations, ﬁrst conditioning on X, Y (0) and Y (1), it follows
(˜τ −τ P )2
(˜τ −τ S)2
(τ S −τ P )2
(˜τ −τ S)2
(Y (1) −Y (0) −τ P )2
Thus, the same statistic that as an estimator of the population average treatment eﬀect τ P has
a normalized variance equal to V P , as an estimator of τ S, has the property:
N(˜τ −τ S)
−→N(0, V S),
V S = V P −E[Y (1) −Y (0) −τ P )2].
As an estimator of τ S the variance of ˆτ P is lower than its variance as an estimator of τ P, with
the diﬀerence equal to the variance of the treatment eﬀect.
The same line of reasoning can be used to show that
N(˜τ −τ(X)
−→N(0, V τ(X)),
V τ(X) = V P −E[τ(X) −τ P )2],
V S = V τ(X) + E[(Y (1) −Y (0) −τ(X))2].
An example to illustrate these point may be helpful. Suppose that X ∈{0, 1}, with Pr(X =
1) = px, and Pr(W = 1|X) = 1/2. Suppose that τ(x) = 2x −1, and σ2
w(x) is very small for all
x and w. In that case the average treatment eﬀect is px · 1 + (1 −px) · (−1) = 2px −1. The
eﬃcient estimator in this case, assuming only unconfoundedness, requires separately estimating
τ(x) for x = 0 and 1, and averaging these two by the empirical distribution of X. The variance
N(ˆτ −τ S) will be small because σ2
w(x) is small, and following the math above, the variance
N(τ −τ P ) will be larger by 4px(1 −px). If px diﬀers from 1/2, and so PATE diﬀers from
zero, the conﬁdence interval for PATE in small samples will tend to include zero. In contrast,
w(x) small enough and N odd (and both N0 and N1 at least equal to 2 so that one
can estimate σ2
w(x)), the standard conﬁdence interval for τ S will exclude zero with probability
one. The intuition is that τ P is much more uncertain because it depends on the distribution
of the covariates, whereas the uncertainty about τ S depends only on the conditional outcome
variances and the propensity score.
The diﬀerence in asymptotic variances riases the issue of how to estimate the variance of
the sample average treatment eﬀect. Speciﬁc estimators for the variance will be discussed in
Section 4, but here I will introduce some general issues surrounding their estimation. Because
the two potential outcomes for the same unit are never observed simultaneously, one cannot
directy infer the variance of the treatment eﬀect. This is the same issue as the non-identiﬁcation
of the correlation coeﬃcient. One can, however, estimate a lower bound on the variance of the
treatment eﬀect, leading to an upper bound on the variance of the estimator of the SATE,
which is equal to V τ(X). Decomposing the variance as
(Y (1) −Y (0) −τ P)2
= V (E[Y (1) −Y (0) −τ|X]) + E [V(Y (1) −Y (0) −τ|X)] ,
= V (τ(X) −τ) + E
0(X) −2ρ(X)σ0(X)σ1(X)
we can consistently estimate the ﬁrst term, but generally say little about the second other than
that it is nonnegative. One can therefore bound the variance of ˜τ −τ S from above by
E[ψ(Y, W, X, τ P )2] −E[(Y (1) −Y (0)) −τ P)2]
≤E[ψ(Y, W, X, τ P )2] −E[(τ(X) −τ P )2] = E
and use this upper-bound variance estimate to construct conﬁdence intervals that are guaranteed to be conservative. Note the connection with Neyman’s discussion of conservative
conﬁdence intervals for average treatment eﬀects in experimental settings. It should be noted
that the diﬀerence between these variances is of the same order as the variance itself, and not a
small sample issue. Only when the treatment eﬀect is known to be constant can it be ignored.
Depending on the correlation between the outcomes and the covariates, this may change the
standard errors considerably. It should also be noted that bootstrapping methods in general
lead to estimation of E[(˜τ −τ P )2], rather than E[(˜τ −τ(X))2], which are generally too big.
Estimating Average Treatment Eﬀects
There have been a number of statistics proposed for estimating the average treatment eﬀects
PATE and PATT, all of which are also appropriate estimators of the sample versions SATE and
SATT and the conditional average versions CATE and CATT. (The implications of focusing
on SATE or CATE rather than PATE only arise when estimating the variance, and so I will
return to this distinction in Section 4. In the current section all discussion applies equally to all
estimands.) Here I review some of these estimators, organized into ﬁve groups. The ﬁrst set,
referred to as “regression” estimators, consists of measures that rely on consistent estimation
of the two conditional regression functions, µ0(x) and µ1(x). These estimators diﬀer in the
way that they estimate these elements, but all rely on estimators that are consistent for these
regression functions. The second set of “matching” estimators compare outcomes across pairs
of matched treated and control units, with each unit matched to a ﬁxed number of observations
with the opposite treatment. The bias of these within-pair estimates of the average treatment
eﬀect disappears as the sample size increases, although their variance does not go to zero since
the number of matches remains ﬁxed. The third set of estimators is characterized by a central
role for the propensity score. Four leading approaches in this set are weighting by the inverse
of the propensity score, blocking on the propensity score, regression on the propensity score,
and matching on the propensity score. The fourth category consists of estimators that rely
on a combination of these methods, typically combining regression with one of its alternatives.
The motivation for these combinations is that although in principle any one of these methods
can remove all of the bias associated with the covariates, combining two may lead to more
robust inference. For example, matching leads to consistent estimators for average treatment
eﬀects under weak conditions, so matching and regression can combine some of the desirable
variance properties of regression with the consistency of matching. Similarly a combination
of weighting and regression, using parametric models for both the propensity score and the
regression functions, can lead to an estimator that is consistent even if only one of the models
is correctly speciﬁed . Finally,
in the ﬁfth group I will discuss Bayesian approaches to inference for average treatment eﬀects.
Only some of the estimators discussed below achieve the semiparametric eﬃciency bound,
yet this does not mean that these should necessarily to be preferred in practice – that is, in
ﬁnite samples. More generally, the debate concerning the practical advantages of the various
estimators, and the settings in which some are more attractive than others, is still ongoing,
with no ﬁrm conclusions yet reached. Although all estimators, either implicitly or explicitly,
estimate the two unknown regression functions or the propensity score, they do so in very
diﬀerent ways. Diﬀerences in smoothness of the regression function or the propensity score, or
relative discreteness of the covariates in speciﬁc applications, may aﬀect the relative desirability
of the estimators.
In addition, even the appropriateness of the standard asymptotic distributions as a guide
towards ﬁnite sample performance is still debated . A key feature that casts doubt on the relevance of the asymptotic
distributions is that the root-N consistency is obtained by averaging a nonparametric estimator
of a regression function which itself has a slow nonparametric convergence rate over the empirical
distribution of its argument. The dimension of this argument aﬀects the rate of convergence for
the unknown function (the regression function µw(x) or the propensity score e(x)), but not the
rate of convergence for the estimator of the paramater of interest, the average treatment eﬀect.
In practice, however, the resulting approximations of the ATE can be poor if the argument is of
high dimension, in which case information about the propensity score is of particular relevance.
Although Hahn showed that, for the standard asymptotic distributions knowledge of
the propensity score is irrelevant (and conditioning only on the propensity score is in fact
less eﬃcient than conditioning on all covariates), conditioning on the propensity score involves
only one–dimensional nonparametric regression, suggesting that the asymptotic approximations
may be more accurate. In practice, knowledge of the propensity score may therefore be very
informative.
Another issue that is important in judging the various estimators is how well they account
for non– or limited-overlap in the covariate distributions of the two treatment groups. If there
are regions in the covariate space with little overlap (the propensity score close to zero or one),
average treatment eﬀect estimators should have relatively high variance. However, this is not
always the case for estimators based on tightly parametrized models for the regression functions,
where outliers in covariate values can lead to spurious precision for regression parameters.
Regions of limited overlap can also be diﬃcult to detect directly in high-dimensional covariate
spaces as it can be masked for any single variable.
Regression
The ﬁrst class of estimators relies on consistent estimation of µw(x) for w = 0, 1. Given ˆµw(x)
for these regression functions, the PATE, SATE and CATE are estimated by averaging their
diﬀerence over the empirical distribution of the covariates:
ˆµ1(Xi) −ˆµ0(Xi)
In most implementations the average of the predicted treated outcome for the treated is equal
to the average observed outcome for the treated (so that P
i Wi · ˆµ1(Xi) = P
i Wi · Yi), and
similarly for the controls, implying that ˆτreg can also be written as
Yi −ˆµ0(Xi)
+ (1 −Wi) ·
ˆµ1(Xi) −Yi
For the PATT and SATT typically only the control regression function is estimated; we only
need predict the outcome under the control treatment for the treated units. The estimator
then averages the diﬀerence between the actual outcomes for the treated and their estimated
outcomes under the control:
Wi · (Yi −ˆµ0(Xi)) .
Early estimators for µw(x) included parametric regression functions, for example linear
regression . Such parametric alternatives include least squares estimators
with the regression function speciﬁed as
µw(x) = β′x + τ · w,
in which case the average treatment eﬀect is equal to τ. In this case one can estimate τ directly
by least squares estimation using the regression function
Yi = α + β′Xi + τ · Wi + εi.
More generally, one can specify separate regression functions for the two regimes:
µw(x) = β′
In that case one estimate the two regression functions separately on the two subsamples and
then substitute the predicted values in (3.2). These simple regression estimators may be very
sensitive to diﬀerences in the covariate distributions for treated and control units. The reason
is that in that case the regression estimators rely heavily on extrapolation. To see this, note
that the regression function for the controls, µ0(x) is used to predict missing outcomes for the
treated. Hence on average one wishes to use predict the control outcome at ¯XT , the average
covariate value for the treated. With a linear regression function, the average prediction can
be written as ¯YC + ˆβ′( ¯XT −¯XC). With ¯XT and the average covariate value for the controls,
¯XC very close, the precise speciﬁcation of the regression function will not matter very much for
the average prediction. However, with the two averages very diﬀerent, the prediction based on
a linear regression function can be very sensitive to changes in the speciﬁcation.
More recently, nonparametric estimators have been proposed. Hahn recommends
estimating ﬁrst the three conditional expectations g1(x) = E[WY |X], g0(x) = E[(1 −W)Y |X],
and e(x) = E[W|X] nonparametrically using series methods. He then estimates µw(x) as
ˆµ1(x) = ˆg1(x)
and shows that the estimators for both PATE and PATT achieve the semiparametric eﬃciency
bounds discussed in Section 2.5 (the latter even when the propensity score is unkwnown).
Using this series approach, however, it is unnecessary to estimate all three of these conditional expectations (E[Y W|X], E[Y (1 −W)|X], and E[W|X]) to estimate µw(x). Instead one
can use series methods to directly estimate the two regression functions µw(x), eliminating the
need to estimate the propensity score .
Heckman, Ichimura and Todd consider kernel methods for estimating µw(x),
in particular focusing on local linear approaches. The simple kernel estimator has the form
Yi · K((Xi −x)/h)
K((Xi −x)/h),
with a kernel K(·) and bandwith h. In the local linear kernel regression the regression function
µw(x) is estimated as the intercept β0 in the minimization problem
Yi −β0 −β′
In order to control the bias of their estimators, Heckman, Ichimura and Todd require
that the order of the kernel is at least as large as the dimension of the covariates. That is, they
require the use of a kernel function K(z) such that
z zrK(z)dz = 0 for r ≤dim(X), so that
the kernel must be negative on part of the range, and the implicit averaging involves negative
weights. We shall see this role of the dimension of the covariates again for other estimators.
For the average treatment eﬀect for the treated, PATT, it is important to note that with
the propensity score known, the estimator given in (3.3) is generally not eﬃcient, irrespective
of the estimator for µ0(x). Intuitively, this is because with the propensity score known, the
average P WiYi/NT is not eﬃcient for the population expectation E[Y (1)|W = 1]. An eﬃcient
estimator can be obtained by weighting all the estimated treatment eﬀects,
ˆµ1(Xi) −ˆµ0(Xi), by the probability of receiving the treatment:
e(Xi) · (ˆµ1(Xi) −ˆµ0(Xi))
In other words, instead of estimating E[Y (1)|W = 1] as P WiYi/NT using only the treated
observations, it is estimated using all units, as P ˆµ1(Xi) · e(Xi)/ P e(Xi). Knowledge of the
propensity score improves the accuracy because it allows one to exploit the control observations
to adjust for imbalances in the sampling of the covariates.
For all of the estimators in this section an important issue is the choice of the smoothing
parameter. In Hahn’s case, after choosing the form of the series and the sequence, the smoothing
parameter is the number of terms in the series. In Heckman, Ichimura, and Todd it is the
bandwidth of the kernel chosen. The evaluation literature has been largely silent concerning the
optimal choice of the smoothing parameters, although the larger literature on nonparametric
estimation of regression functions does provide some guidance, oﬀering data-driven methods
such as cross-validation criteria. The optimality properties of these criteria, however, are for
estimation of the entire function, in this case µw(x). Typically the focus is on mean-integratedsquared-error criteria of the form
x(ˆµw(x) −µw(x))2fX(x)dx, with possibly an additional
weight function. In the current problem, however, one is interested speciﬁcally in the average
treatment eﬀect, and so such integrated mean-squared-error criteria are not necessarily optimal.
In particular, global smoothing parameters may be inappropriate because they can be driven
by the shape of the regression function and distribution of covariates in regions that are not
important for the average treatment eﬀect of interest. Lalonde’s data set is a well known
example of this where much of probability mass of the non-experimental control group is in a
region with moderate to high earnings where few of the treated group are located. There is little
evidence whether results for average treatment eﬀects are more or less sensitive to the choice
of smoothing parameter than results for estimation of the regression functions themselves.
As seen above, regression estimators impute the missing potential outcomes using the estimated
regression function.
Thus, if Wi = 1, Yi(1) is observed and Yi(0) is missing and imputed
with a consistent estimator ˆµ0(Xi) for the conditional expectation. Matching estimators also
impute the missing potential outcomes, but do so using only the outcomes of nearest neighbours
of the opposite treatment group. In that sense matching is similar to nonparametric kernel
regression methods, with the number of neighbors playing the role of the bandwidth in the
kernel regression. A formal diﬀerence is that the asymptotic distribution is derived conditional
on the implicit bandwidth, that is, the number of neighbours, which is often ﬁxed at one.
Using such asymptotics, the implicit estimate ˆµw(x) is (close to) unbiased, but not consistent
for µw(x). In contrast, the regression estimators discussed in the previous section relied on the
consistency of µw(x).
Matching estimators have the attractive feature that given the matching metric, the researcher only has to choose the number of matches. In contrast, for the regression estimators
discussed above, the researcher must choose smoothing parameters that are more diﬃcult to
interpret; either the number of terms in a series or the bandwidth in kernel regression. Within
the class of matching estimators, using only a single match leads to the most credible inference
with the least bias, at most sacriﬁcing some precision. This can make the matching estimator
easier to use than those estimators that require more complex choices of smoothing parameters,
and may explain some of its popularity.
Matching estimators have been widely studied in practice and theory . Most often they have been applied in settings
with the following two characteristics: (i) the interest is in the average treatment eﬀect for
the treated, and (ii), there is a large reservoir of potential controls. This allows the researcher
to match each treated unit to one or more distinct controls (referred to as matching without
replacement). Given the matched pairs, the treatment eﬀect within a pair is then estimated
as the diﬀerence in outcomes, with an estimator for the PATT obtained by averaging these
within-pair diﬀerences. Since the estimator is essentially the diﬀerence in two sample means,
the variance is calculated using standard methods for diﬀerences in means or methods for paired
randomized experiments. The remaining bias is typically ignored in these studies. The literature has studied fast algorithms for matching the units, as fully eﬃcient matching methods are
computationally cumbersome . Note that
in such matching schemes the order in which the units are matched is potentially important.
Abadie and Imbens study both bias and variance in a more general setting where both
treated and control units are (potentially) matched and matching is done with replacement . The Abadie-Imbens estimator is implemented in Matlab and STATA
 .5 Formally, given a sample, {(Yi, Xi, Wi)}N
let ℓm(i) be the index l that satisﬁes Wl ̸= Wi and
∥Xj −Xi∥≤∥Xl −Xi∥
where 1{·} is the indicator function, equal to one if the expression in brackets is true and zero
otherwise. In other words, ℓm(i) is the index of the unit in the opposite treatment group that
is the m-th closest to unit i in terms of the distance measure based on the norm ∥· ∥. In
particular, ℓ1(i) is the nearest match for unit i. Let JM(i) denote the set of indices for the ﬁrst
5See Becker and Ichino and Sianesi for alternative STATA implementations of matching estimators.
M matches for unit i: JM(i) = {ℓ1(i), . . . , ℓM(i)}. Deﬁne the imputed potential outcomes as:
if Wi = 0,
j∈JM(i) Yj
if Wi = 1,
j∈JM(i) Yj
if Wi = 0,
if Wi = 1.
The simple matching estimator discussed in Abadie and Imbens is then
ˆYi(1) −ˆYi(0)
They show that the bias of this estimator is of order O(N −1/K), where K is the dimension of
the covariates. Hence, if one studies the asymptotic distribution of the estimator by normalizing
N (as can be justiﬁed by the fact that the variance of the estimator is of order O(1/N)),
the bias does not disappear if the dimension of the covariates is equal to two, and will dominate
the large sample variance if K is at least three.
Let me make clear three caveats to the Abadie-Imbens result. First, it is only the continuous
covariates that should be counted in this dimension, k. With discrete covariates the matching
will be exact in large samples, therefore such covariates do not contribute to the order of the
bias. Second, if one matches only the treated, and the number of potential controls is much
larger than the number of treated units, one can justify ignoring the bias by appealling to an
asymptotic sequence where the number of potential controls increases faster than the number
of treated units. Speciﬁcally, if the number of controls, N0, and the number of treated, N1,
satisfy N1/N 4/k
→0, then the bias disappears in large samples after normalization by
Third, even though the order of the bias may be high, the actual bias may still be small if the
coeﬃcients in the leading term are small. This is possible if the biases for diﬀerent units are
at least partially oﬀsetting. For example, the leading term in the bias relies on the regression
function being nonlinear, and the density of the covariates having a nonzero slope. If one of these
two conditions is at least close to being satisﬁed, the resulting bias may be fairly limited. To
remove the bias, Abadie and Imbens suggest combining the matching process with a regression
adjustment, as I will discuss in Section 3.4.3.
Another point made by Abadie and Imbens is that matching estimators are generally not
eﬃcient. Even in the case where the bias is of low enough order to be dominated by the variance,
the estimators are not eﬃcient given a ﬁxed number of matches. To reach eﬃciency one would
need to increase the number of matches with the sample size. If M →∞, with M/N →0,
then the matching estimator is essentially like a regression estimator, with the imputed missing
potential outcomes consistent for their conditional expectations. However, the eﬃciency gain
of such estimators is of course somewhat artiﬁcial. If in a given data set one uses M matches,
one can calculate the variance as if this number of matches increases at the appropriate rate
with the sample size, in which case the estimator would be eﬃcient. Or, one could calculate
the variance conditional on the number of matches, in which case the same estimator would be
ineﬃcient. Little is yet known about the optimal number of matches, or about data-dependent
ways of choosing this number.
In the above discussion the distance metric in choosing the optimal matches was the standard
Euclidan metric:
dE(x, z) = (x −z)′(x −z).
All of the distance metrics used in practice standardize the covariates in some manner. Abadie
and Imbens use the diagonal matrix of the inverse of the covariate variances:
dAI(x, z) = (x −z)′diag(Σ−1
X )(x −z),
where ΣX is the covariance matrix of the covariates.
The most common choice is the Mahalanobis metric which uses the inverse of the covariance
matrix of the pretreatment variables:
dM(x, z) = (x −z)′Σ−1
This metric has the attractive property that it reduces diﬀerences in covariates within matched
pairs in all directions.6 See for more formal discussions Rubin and Thomas .
Zhao , in an interesting discussion of the choice of metrics, suggests some alternatives
that depend on the correlation between covariates, treatment assignment and outcomes. He
starts by assuming that the propensity score has a logistic form
1 + exp(x′γ),
and that the regression functions are linear:
µw(x) = αw + x′β.
He then considers two alternative metrics. The ﬁrsts weights absolute diﬀerences in the covariates by the coeﬃcient in the propensity score:
dZ1(x, z) =
|xk −zk| · |γk|,
6However, using the Mahalanobis metric can also have less attractive implications. Consider the case where
one matches on two highly correlated covariates, X1 and X2 with equal variances. For speciﬁcity, suppose that
the correlation coeﬃcient is 0.9 and both two variances are 1. Suppose that we wish to match a treated unit i
with Xi1 = Xi2 = 0. The two potential matches are unit j with Xj1 = Xj2 = 5 and unit k with Xk1 = 4 and
Xk2 = 0. The diﬀerence in covariates for the ﬁrst match is the vector (5, 5)′, and the diﬀerence in covariates for
the second match is (4, 0)′. Intuitively it may seem that the second match is better: it is strictly closer to the
treated unit than the ﬁrst match for both covariates. Using the Abadie-Imbens metric diag(Σ−1
X ) this is in fact
true. Under that metric the distance between the second match and the treated unit is 16, considerably smaller
than 50, the distance between the ﬁrst match and the treated unit. However, using the Mahalanobis metric the
distance for the ﬁrst match is 26 and the distance for the second match is much higher at 84. Because of the
correlation between the covariates in the sample the diﬀerence between the matches is interpreted very diﬀerently
under the two metrics. To choose between the standard and Mahalanobis metric one needs to consider what the
appropriate match would be in this case.
and the second weights them by the coeﬃcients in the regression function:
dZ2(x, z) =
|xk −zk| · |βk|,
where xk and zk are the kth elements of the K-dimensional vectors x and z respectively.
In light of this discussion, it is interesting to consider optimality of the metric. Suppose,
following Zhao , that the regression functions are linear with coeﬃcients βw. Now consider
a treated unit with covariate vector x who will be matched to a control unit with covariate vector
z. The bias resulting from such a match is (z −x)′β0. If one is interested in minimizing for
each match the squared bias, one should choose the ﬁrst match by minimizing over the control
observations (z −x)′β0β′
0(z −x). Yet typically one does not know the value of the regression
coeﬃcients, in which case one may wish to minimize expected squared bias. Using a normal
distribution for the regression errors, and a ﬂat prior on β0, the posterior distribution for β0 is
normal with mean ˆβ0 and variance Σ−1
X σ2/N. Hence the expected squared bias from a match
(z −x)′β0β′
= (z −x)′ 
In this argument the optimal metric is a combination of the sample covariance matrix plus the
outer product of the regression coeﬃcients, with the former scaled down by a factor 1/N:
d∗(z, x) = (z −x)′ 
A clear problem with this approach is that when the regression function is misspeciﬁed, matching with this particular metric may not lead to a consistent estimator. On the other hand,
when the regression function is correctly speciﬁed, it would be more eﬃcient to use the regression estimators than any matching approach. In practice one may want to use a metric that
combines some of the optimal weighting with some safeguards in case the regression function
is misspeciﬁed.
So far there is little experience with any alternative metrics beyond the Mahalanobis metric.
Zhao reports the results of some simulations using his proposed metrics, ﬁnding no clear
winner given his speciﬁc design, although his ﬁndings suggest that using the outcomes in deﬁning
the metric is a promising approach.
Propensity Score Methods
Since the work by Rosenbaum and Rubin there has been considerable interest in methods that avoid adjusting directly for all covariates, and instead focus on adjusting for diﬀerences
in the propensity score, the conditional probability of receiving the treatment. This can be implemented in a number of diﬀerent ways. One can weight the observations in terms of the
propensity score (and indirectly also in terms of the covariates) to create balance between
treated and control units in the weighted sample. Hirano, Imbens and Ridder show how such
estimators can achieve the semiparametric eﬃciency bound. Alternatively one can divide the
sample into subsamples with approximately the same value of the propensity score, a technique known as blocking. Finally, one can directly use the propensity score as a regressor in a
regression approach.
In practice there are two important cases. First, suppose the researcher knows the propensity
score. In that case all three of these methods are likely to be eﬀective in eliminating bias. Even
if the resulting estimator is not fully eﬃcient, one can easily modify it by using a parametric
estimate of the propensity score to capture most of the eﬃciency loss. Furthermore, since these
estimators do not rely on high-dimensional nonparametric regression, this suggests that their
ﬁnite sample properties are likely to be relatively attractive.
If the propensity score is not known, the advantages of the estimators discussed below are
less clear. Although they avoid the high-dimensional nonparametric regression of the two conditional expectations µw(x), they require instead the equally high-dimensional nonparametric
regression of the treatment indicator on the covariates. In practice the relative merits of these
estimators will depend on whether the propensity score is more or less smooth than the regression functions, or whether additional information is available about either the propensity score
or the regression functions.
The ﬁrst set of “propensity score” estimators use the propensity score as weights to create a
balanced sample of treated and control observations. Simply taking the diﬀerence in average
outcomes for treated and controls,
P(1 −Wi)Yi
is not unbiased for τ P = E[Y (1) −Y (0)] because, conditional on the treatment indicator, the
distributions of the covariates diﬀer. By weighting the units by the inverse of the probability
of receiving the treatment, one can undo this imbalance. Formally, weighting estimators rely
on the equalities:
e(X)Y (1)
= E[Y (1)],
and similarly
= E[Y (0)],
e(X) −(1 −W) · Y
With the propensity score known one can directly implement this estimator as
e(Xi) −(1 −Wi)Yi
In this particular form this is not necessarily an attractive estimator.
The main reason is
that, although the estimator can be written as the diﬀerence between a weighted average of
the outcomes for the treated units and a weighted average of the outcomes for the controls,
the weights do not necessarily add to one. Speciﬁcally, in (3.6), the weights for the treated
units add up to (P Wi/e(Xi))/N. In expectation this is equal to one, but since its variance is
positive, in any given sample some of the weights are likely to deviate from one. One approach
for improving this estimator is simply to normalize the weights to unity.
One can further
normalize the weights to unity within subpopulations as deﬁned by the covariates.
limit this leads to an estimator proposed by Hirano, Imbens and Ridder who suggest
using a nonparametric series estimator for e(x). More precisely, they ﬁrst specify a sequence
of functions of the covariates, e.g., a power series, hl(x), l = 1, . . . , ∞. Next, they choose a
number of terms, L(N), as a function of the sample size, and then estimate the L-dimensional
vector γL in
Pr(W = 1|X = x) =
exp((h1(x), . . . , hL(x))γL)
1 + exp((h1(x), . . . , hL(x))γL),
by maximizing the associated likelihood function. Let ˆγL be the maximum likelihood estimate.
In the third step, the estimated propensity score is calculated as:
exp((h1(x), . . . , hL(x))ˆγL)
1 + exp((h1(x), . . . , hL(x))ˆγL).
Finally they estimate the average treatment eﬀect as:
ˆτweight =
(1 −Wi) · Yi
1 −ˆe(Xi).
Hirano, Imbens and Ridder show that with a nonparametric estimator for e(x) this estimator is
eﬃcient, whereas with the true propensity score the estimator would not be fully eﬃcient (and
in fact not very attractive).
This estimator highlights one of the interesting features of the problem of eﬃciently estimating average treatment eﬀects. One solution is to estimate the two regression functions
µw(x) nonparametrically, as discussed in Section 3.1; that alternative completely ignores the
propensity score. A second approach is to estimate the propensity score nonparametrically,
ignoring entirely the two regression functions. If appropriately implemented, both approaches
lead to fully eﬃcient estimators, but clearly their ﬁnite sample properties may be very diﬀerent,
depending, for example, on the smoothness of the regression functions versus the smoothness of
the propensity score. If there is only a single binary covariate, or more generally with only discrete covariates, the weighting approach with a fully nonparametric estimator for the propensity
score is numerically identical to the regression approach with a fully nonparametric estimator
for the two regression functions.
To estimate the average treatment eﬀect for the treated rather than for the full population,
one should weight the contribution for unit i by the propensity score e(xi). If the propensity
score is known, this leads to
ˆτweight,tr =
Wi · Yi · e(Xi)
(1 −Wi) · Yi ·
1 −ˆe(Xi),
where the propensity score enters in some places as the true score (for the weights to get the
appropriate estimand) and in other cases as the estimated score (to achieve eﬃciency). In the
unknown case one always uses the estimated propensity score, leading to:
ˆτweight,tr =
One diﬃculty with the weighting estimators that are based on the estimated propensity
score is again the problem of choosing the smoothing parameters. Hirano, Imbens and Ridder use series estimators, which requires choosing the number of terms in the series.
Ichimura and Linton consider a kernel version, which involves choosing a bandwidth.
Theirs is currently one of the few studies considering optimal choices for smoothing parameters
that focuses speciﬁcally on estimating average treatment eﬀects. A departure from standard
problems in choosing smoothing parameters is that here one wants to use nonparametric regression methods even if the propensity score is known. For example, if the probability of treatment
is constant, standard optimality results would suggest using a high degree of smoothing, as this
would lead to the most accurate estimator for the propensity score. However, this would not
necessarily lead to an eﬃcient estimator for the average treatment eﬀect of interest.
Blocking on the Propensity Score
In their original propensity score paper Rosenbaum and Rubin suggest the following
“blocking propensity score” estimator. Using the (estimated) propensity score, divide the sample into M blocks of units of approximately equal probability of treatment, letting Jim be an
indicator for unit i being in block m. One way of implementing this is by dividing the unit
interval into M blocks with boundary values equal to m/M for m = 1, . . . , M −1, so that
Jim = 1{(m −1)/M < e(Xi) ≤m/M},
for m = 1, . . . , M. Within each block there are Nwm observations with treatment equal to
w, Mwm = P
i 1{Wi = w, Jim = 1}. Given these subgroups, estimate within each block the
average treatment eﬀect as if random assignment holds,
Jim(1 −Wi)Yi.
Then estimate the overall average treatment eﬀect as:
ˆτm · N1m + N0m
If one is interested in the average eﬀect for the treated, one would weight the within-block
average treatment eﬀects by the number of treated units:
ˆτT,block =
Blocking can be interpreted as a crude form of nonparametric regression where the unknown
function is approximated by a step function with ﬁxed jump points. To establish asymptotic
properties for this estimator would require establishing conditions on the rate at which the
number of blocks increases with the sample size. With the propensity score known, these are
easy to determine; no formal results have been established for the unknown case.
The question arises how many blocks to use in practice. Cochran analyses a case
with a single covariate, and, assuming normality, shows that using ﬁve blocks removes at least
95% of the bias associated with that covariate.
Since all bias, under unconfoudnedness, is
associated with the propensity score, this suggests that under normality ﬁve blocks removes
most of the bias associated with all the covariates.
This has often been the starting point
of empirical analyses using this estimator , and has been implemented in STATA by Becker and Ichino .7
however, researchers subsequently check the balance of the covariates within each block. If
the true propensity score per block is constant, the distribution of the covariates among the
treated and controls should be identical, or, in the evaluation terminology, the covariates should
be balanced. Hence one can assess the adequacy of the statistical model by comparing the
distribution of the covariates among treated and controls within blocks. If the distributions are
found to be diﬀerent, one can either split the blocks into a number of subblocks, or generalize
the speciﬁcation of the propensity score. Often some informal version of the following algorithm
is used: If within a block the propensity score itself is unbalanced, the blocks are too large and
need to be split. If, conditional on the propensity score being balanced, the covariates are
unbalanced, the speciﬁcation of the propensity score is not adequate.
No formal algorithm
exists for implementing these blocking methods.
An alternative approach to ﬁnding the optimal number of blocks is to relate this approach
to the weighting propensity score estimator discussed above. One can view the blocking estimator as identical to a weighting version, with a modiﬁed estimator for the propensity score.
Speciﬁcally, given the original estimator, ˆe(x), in the blocking approach the estimator for the
propensity score is discretized to
1{(m/M) ≤ˆe(x)}.
7Becker and Ichino also implement estimators that match on the propensity score.
Using ˜e(x) as the propensity score in the weighting estimator leads to an statistic for the
average treatment eﬀect identical to that obtained by using the blocking estimator with ˆe(x)
as the propensity score and M blocks. With suﬃciently large M, the blocking estimator is
suﬃciently close to the original weighting estimator that it shares its ﬁrst order asymptotic
properties, including its eﬃciency. This suggests that in general there is little harm in choosing
a relatively large number of blocks, at least in terms of asymptotic properties, although again
the relevance of this for ﬁnite samples has not been established.
Regression on the Propensity Score
The third method of using the propensity score is to estimate the conditional expectation of Y
given W and e(X). Deﬁne
νw(e) = E[Y (w)|e(X) = e].
By unconfoundedness this is equal to E[Y |W = w, e(X) = e]. Given an estimator ˆνw(e), one
can estimate the average treatment eﬀect as
ˆτregprop = 1
ˆν1(e(Xi)) −ˆν0(e(Xi))
Heckman, Ichimura and Todd consider a local linear version of this for estimating the
average treatment eﬀect for the treated. Hahn considers a series version and shows that
it is not as eﬃcient as the regression estimator based on adjustment for all covariates.
Matching on the Propensity Score
The Rosenbaum-Rubin result implies that it is suﬃcient to adjust solely for diﬀerences in the
propensity score between treated and control units. Since one of the ways in which one can
adjust for diﬀerences in covariates is matching, another natural way to use the propensity score
is through matching. Because the propensity score is a scalar function of the covariates, the bias
results in Abadie and Imbens imply that the bias term is of lower order than the variance
term and matching leads to a
N-consistent, asymptotically normally distributed estimator.
The variance for the case with matching on the true propensity score also follows directly from
their results. More complicated is the case with matching on the estimated propensity score. I
do not know of any results that give the variance for this case.
Mixed Methods
A number of approaches have been proposed that combine two of the three methods described
in the previous sections, typically regression with one of its alternatives. The reason for these
combinations is that, although one method alone is often suﬃcient to obtain consistent or even
eﬃcient estimates, incorporating regression may eliminate remaining bias and improve precision. This is particularly useful because neither matching nor the propensity score methods
directly address the correlation between the covariates and the outcome. The beniﬁt associated
with combining methods is made explicit in the notion developed by Robins and Ritov of
“double robustness.” They propose a combination of weighting and regression where, as long as
the parametric model for either the propensity score or the regression functions is speciﬁed correctly, the resulting estimator for the average treatment eﬀect is consistent. Similarly, matching
leads to consistency without additional assumptions, thus methods that combine matching and
regressions are robust against misspeciﬁcation of the regression function.
Weighting and Regression
One can rewrite the weighting estimator discussed above as estimating the following regression
function by weighted least squares,
Yi = α + τ · Wi + εi,
with weights equal to
Without the weights the least squares estimator would not be consistent for the average treatment eﬀect; the weights ensure that the covariates are uncorrelated with the treatment indicator
and hence the weighted estimator is consistent.
This weighted-least-squares representation suggests that one may add covariates to the
regression function to improve precision, for example as
Yi = α + β′Xi + τ · Wi + εi,
with the same weights λi. Such an estimator, using a more general semiparametric regression
model, is suggested in Robins and Rotnitzky , Robins and Ritov , and implemented
in Hirano and Imbens .
In the parametric context Robins and Ritov argue that the
estimator is consistent as long as either the regression model or the propensity score (and thus
the weights) are speciﬁed correctly. That is, in the Robins-Ritov terminology, the estimator is
doubly robust.
Blocking and Regression
Rosenbaum and Rubin suggest modifying the basic blocking estimator by using least
squares regression within the blocks. Without the additional regression adjustment the estimated treatment eﬀect within blocks can be written as a least squares estimator of τm for the
regression function
Yi = αm + τm · Wi + εi,
using only the units in block m. As above, one can also add covariates to the regression function
Yi = αm + β′
mXi + τm · Wi + εi,
again estimated on the units in block m.
Matching and Regression
Since Abadie and Imbens show that the bias of the simple matching estimator can
dominate the variance if the dimension of the covariates is too large, additional bias corrections
through regression can be particularly relevant in this case. A number of such corrections have
been proposed, ﬁrst by Rubin in a parametric setting. Following the notation of Section
3.2, let ˆYi(0) and ˆYi(1) be the observed or imputed potential outcomes for unit i; where these
estimated potential outcomes equal observed outcomes for some unit i and its match ℓ(i). The
bias in their comparison, E[ ˆYi(1)−ˆYi(0)]−(Yi(1)−Yi(0)), arises from the fact that the covariates
for units i and ℓ(i), Xi and Xℓ(i) are not equal, although close because of the matching process.
To further explore this, focusing on the single match case, deﬁne for each unit:
if Wi = 0,
if Wi = 1,
if Wi = 0,
if Wi = 1.
If the matching is exact ˆXi(0) = ˆXi(1) for each unit. If not, these discrepancies will lead to
potential bias. The diﬀerence ˆXi(1) −ˆXi(0) will therefore be used to reduce the bias of the
simple matching estimator.
Suppose unit i is a treated unit (Wi = 1), so that ˆYi(1) = Yi(1) and ˆYi(0) is an imputed value
for Yi(0). This imputed value is unbiased for µ0(Xℓ(i)) (since ˆYi(0) = Yℓ(i)), but not necessarily
for µ0(Xi).
One may therefore wish to adjust ˆYi(0) by an estimate of µ0(Xi) −µ0(Xℓ(i)).
Typically these corrections are taken to be linear in the diﬀerence in the covariates for units i
and its match, that is, of the form β′
0( ˆXi(1) −ˆXi(0) = β′
0(Xi −Xℓ(i)). Rubin proposed
three corrections which diﬀer in how β0 is estimated.
To introduce Rubin’s ﬁrst correction, note that one can write the matching estimator as the
least squares estimator for the regression function
ˆYi(1) −ˆYi(0) = τ + εi.
This representation suggests modifying the regression function to
ˆYi(1) −ˆYi(0) = τ + ( ˆXi(1) −ˆXi(0))′β + εi,
and again estimating τ by least squares.
The second correction is to estimate µ0(x) directly by taking all control units, and estimate
a linear regression of the form
Yi = α0 + β′
by least squares. (If unit i is a control unit the correction would be done using an estimator
for the regression function µ1(x) based on a linear speciﬁcation Yi = α1 + β′
1Xi estimated on
the treated units.) Abadie and Imbens show that if this correction is done nonparametrically, the resulting matching estimator is consistent and asymptotically normal, with its bias
dominated by the variance.
The third method is to estimate the same regression function for the controls, but using
only those that are used as matches for the treated units, with weights corresponding to the
number of times a control observations is used as a match .
Compared to the second method this approach is potentially less eﬃcient as it discards some
control observations and weights some more than others. It has the advantage, however, of only
using the most relevant matches. The controls that are discarded in the matching process are
likely to be outliers relative to the treated observations, and they may therefore unduly aﬀect
the least squares estimates. If the regression function is in fact linear this may be an attractive
feature, but if there is uncertainty over its functional form, one may not wish to allow these
observations such inﬂuence.
Bayesian Approaches
Little has been done using Bayesian methods to estimate average treatment eﬀects, both in
terms of methodology or application. Rubin introduces a general approach to estimating
average and distributional treatment eﬀects from a Bayesian perspective. Dehejia goes
further, studying the policy decision problem of assigning heterogenuous individuals to various
training programs with uncertain and variable eﬀects.
To my knowledge, however, there are no applications using the Bayesian approach that
focuse on estimating the average treatment eﬀect under unconfoundedness, either for the whole
population or just for the treated. Neither are there simulation studies comparing operating
characteristics of Bayesian methods to the frequentist methods discussed in the earlier sections
of this paper. Such a Bayesian approach can be easily implemented with the regression methods
discussed in Section 3.1. Interestingly, it is less clear how Bayesian methods would be used with
pairwise matching, which does not appear to have a natural likelihood interpretation.
A Bayesian approach to the regression estimators may be useful for a number of reasons.
First, one of the leading problems with regression estimators is the presence of many covariates
relative to the number of observations. Standard frequentist methods tend to either include
those covariates without any restrictions, or exclude them entirely.
In constrast, Bayesian
methods would allow researchers to include covariates with more or less informative prior distributions. For example, if the researcher has a number of lagged outcomes, one may expect
recent lags to be more important in predicting future outcomes than longer lags; this can be
reﬂected in tighter prior distributions around zero for the older information. Alternatively, with
a number of similar covariates one may wish to use hierarchical models that avoid problems
with large dimensional parameter spaces.
A second argument for considering Bayesian methods is that in an area closely related
to this process of estimated unobserved outcomes—that of missing data with the Missing At
Random (MAR) assumption—Bayesian methods have found widespread applicability. As advocated by Rubin , multiple imputation methods often rely on a Bayesian approach
for imputing the missing data, taking account of the parameter heterogeneity in a manner con-
sistent with the uncertainty in the missing data model itself. The same methods could be used
with little modiﬁcation for causal models, with the main complication that a relatively large
proportion—namely 50% of the total potential outcomes—is missing.
Estimating Variances
The variances of the estimators considered so far typically involve unknown functions. For
example, as discussed in Section 2.5 the variance of eﬃcient estimators of the population average
treatment eﬀect, PATE, is equal to
1 −e(X) + (µ1(X) −µ0(X) −τ)2
involving the two regression functions, the two conditional variances and the propensity score.
There are a number of ways we can estimate this asymptotic variance. The ﬁrst is essentially
by brute force. All ﬁve components of the variance, σ2
1(x), µ0(x), µ1(x), and e(x), are
consistently estimable using kernel methods or series, and hence the asymptotic variance can
be estimated consistently. However, if one estimates the average treatment eﬀect using only
the two regression functions, it is an additional burden to estimate the conditional variances
and the propensity score in order to estimate V P. Similarly, if one eﬃciently estimates the
average treatment eﬀect by weighting with the estimated propensity score, it is a considerable
additional burden to estimate the ﬁrst two moments of the conditional outcome distributions
just to estimate the asymptotic variance.
A second method applies to the case where either the regression functions or the propensity
score is estimated using series or sieves. In that case one can interpret the estimators, given the
number of terms in the series, as parametric estimators, and calculate the variance this way.
Under some conditions that will lead to valid standard errors and conﬁdence intervals.
A third approach is to use bootstrapping .
Although there is little formal evidence speciﬁc for these estimators, given that the estimators
are asymptotically linear, it is likely that bootstrapping will lead to valid standard errors and
conﬁdence intervals at least for the regression and propensity score methods. Bootstrapping
may be more complicated for matching estimators, as the process introduces discreteness in the
distribution that will lead to ties in the matching algorithm. Subsampling will still work in this setting.
These ﬁrst three methods provide variance estimates for estimators of τ P. As argued above,
however, one may instead wish to estimate τ S or τ(X), in which case the appropriate (conservative) variance is
As above, this variance can be estimated by estimating the conditional moments of the outcome
distributions, with the accompanying inherent diﬃculties. V S cannot, however, be estimated
by bootstrapping, since the estimand itself changes across bootstrap samples.
There is, however, an alternative method for estimating this variance that does not require
additional nonparametric estimation. The idea behind this matching variance estimator, as
developed by Abadie and Imbens , is that even though the asymptotic variance depends
on the conditional variance σ2
w(x), one need not actually estimate this variance consistently at all
values of the covariates. Rather, one needs only the average of this variance over the distribution,
weighted by the inverse of either e(x) or its complement 1−e(x). The key is therefore to obtain
a close-to-unbiased estimator for the variance σ2
w(x). More generally, suppose we can ﬁnd two
treated units with X = x, say units i and j. In that case an unbiased estimator for σ2
1(x) = (Yi −Yj)2 /2.
In general it is again diﬃcult to ﬁnd exact matches, but again, this is not necessary. Instead,
one uses the closest match within the set of units with the same treatment indicator. Let vm(i)
be the mth closest unit to i with the same treatment indicator (Wvm(i) = Wi), and
∥Xl −x∥≤∥Xvm(i) −x∥
Given a ﬁxed number of matches M, this gives us M units with the same treatment indicator
and approximately the same values for the covariates. The sample variance of the outcome
variable for these M units can then be used to estimate σ2
1(x). Doing the same for the control
variance function, σ2
0(x), we can estimate σ2
w(x) at all values of the covariates and, for w = 0, 1.
Note that these are not consistent estimators of the conditional variances. As the sample
size increases, the bias of these estimators will disappear, just as we saw that the bias of the
matching estimator for the average treatment eﬀect disappears under similar conditions. The
rate at which this bias disappears depends on the dimension of the covariates. The variance
of the estimators for σ2
w(Xi), namely at speciﬁc values of the covariates, will not go to zero;
however this is not important, as we are interested not in the variances at speciﬁc points in the
covariates distribution, but in the variance of the average treatment eﬀect, V S. Following the
process introduce above, this last step is estimated as:
Under standard regularity conditions this is consistent for the asymptotic variance of the average
treatment eﬀect estimator. For matching estimators even estimation of the propensity score
can be avoided. Abadie and Imbens show that one can estimate the variance of the matching
estimator as
where M is the number of matches and KM(i) is the number of times unit i is used as a match.
Assessing the Assumptions
Indirect Tests of the Unconfoundedness Assumption
The unconfoundedness assumption relied upon throughout this discussion is not directly testable.
As discussed above, it states that the conditional distribution of the outcome under the control
treatment, Y (0), given receipt of the active treatment and given covariates, is identical to the
distribution of the control outcome given receipt of the control treatment and given covariates.
The same is assumed for the distribution of the active treatment outcome, Y (1). Yet since the
data are completely uninformative about the distribution of Y (0) for those who received the
active treatment and of Y (1) for those receiving the control, the data cannot directly reject
the unconfoundedness assumption. Nevertheless, there are often indirect ways of assessing the
this, a number of which are developed in Heckman and Hotz and Rosenbaum .
These methods typically rely on estimating a causal eﬀect that is known to equal zero. If the
test then suggests that this causal eﬀect varies from zero, the unconfoundedness assumption is
considered less plausible. These tests can be divided into two broad groups.
The ﬁrst set of tests focuses on estimating the causal eﬀect of a treatment that is known not
to have an eﬀect, relying on the presence of multiple control groups . Suppose
one has two potential control groups, for example eligible nonparticipants and ineligibles, as
in Heckman, Ichimura and Todd . One interpretation of the test is to compare average
treatment eﬀects estimated using each of the control groups. This can also be interpreted as
estimating an “average treatment eﬀect” using only the two control groups, with the treatment
indicator now a dummy for being a member of the ﬁrst group. In that case the treatment eﬀect
is known to be zero, and statistical evidence of a non-zero eﬀect implies that at least one of the
control groups is invalid. Again, not rejecting the test does not imply the unconfoundedness
assumption is valid (as both control groups could suﬀer the same bias), but non-rejection in the
case where the two control groups are likely to have diﬀerent biases makes it more plausible that
the unconfoundness assumption holds. The key for the power of this test is to have available
control groups that are likely to have diﬀerent biases, if at all.
Comparing ineligibles and
eligible nonparticipants as in Heckman, Ichimura and Todd is a particularly attractive
comparison. Alternatively one may use diﬀerent geographic controls, for example from areas
bordering on diﬀerent sides of the treatment group.
One can formalize this test by postulating a three-valued indicator Ti ∈{−0, 1, 1} for
the groups (e.g., ineligibles, eligible nonnonparticipants and participants), with the treatment
indicator equal to Wi = 1{Ti = 1}.
If one extends the unconfoundedness assumption to
independence of the potential outcomes and the group indicator given covariates,
Yi(0), Yi(1) ⊥Ti
then a testable implication is
Yi ⊥1{Ti = 0}
Xi, Ti ≤0.
An implication of this independence condition is being tested by the tests discussed above.
Whether this test has much bearing on the unconfoundedness assumption depends on whether
the extension of the assumption is plausible given unconfoundedness itself.
The second set of tests of unconfoundedness focuses on estimating the causal eﬀect of the
treatment on a variable known to be unaﬀected by it, typically because its value is determined
prior to the treatment itself. Such a variable can be time-invariant, but the most interesting
case is in considering the treatment eﬀect on a lagged outcome. If it is not zero, this implies that
the treated observations are distinct from the controls; namely that the distribution of Y (0) for
the treated units is not comparable to the distribution of Y (0) for the controls. If the treatment
is instead zero, it is more plausible that the unconfoundedness assumption holds. Of course this
does not directly test this assumption; in this setting, being able to reject the null of no eﬀect
does not directly reﬂect on the hypothesis of interest, unconfoundedness. Nevertheless, if the
variables used in this proxy test are closely related to the outcome of interest, the test arguably
has more power. For these tests it is clearly helpful to have a number of lagged outcomes.
To formalize this, let us suppose the covariates consist of a number of lagged outcomes
Yi,−1, . . . , Yi,−T as well as time-invariant individual characteristics Zi, so that Xi = (Yi,−1, . . . , Yi,−T , Zi).
By construction only units in the treatment group after period −1 receive the treatment; all
other observed outcomes are control outcomes. Also suppose that the two potential outcomes
Yi(0) and Yi(1) correspond to outcomes in period zero. Now consider the following two assumptions. The ﬁrst is unconfoundedness given only T −1 lags of the outcome:
Yi(1), Yi(0) ⊥Wi
Yi,−1, . . . , Yi,−(T −1), Zi,
and the second assumes stationarity and exchangeability:
fYi,s(0)|Yi,s−1(0),...,Yi,s−(T −1)(0),Zi,Wi(ys|ys−1, . . . , ys−(T −1), z, w),
does not depend on i and s.
Then it follows that
Yi,−2, . . . , Yi,−T , Zi,
which is testable. This hypothesis is what the test describe above tests. Whether this test
has much bearing on unconfoundedness depends on the link between the two assumptions and
the original unconfoundedness assumption. With a suﬃcient number of lags unconfoundedness
given all lags but one appears plausible conditional on unconfoundedness given all lags, so the
relevance of the test depends largely on the plausibility of the second assumption, stationarity
and exchangeability.
Choosing the Covariates
The discussion so far has focused on the case where the covariates set is known a priori. In
practice there can be two issues with the choice of covariates. First, there may be some variables
that should not be adjusted for. Second, even with variables that should be adjusted for in
large samples, expected mean squared error may be reduced by ignoring those that have only
weak correlation with the treatment indicator and the outcomes. This second issue is essentially a statistical one. Including a covariate in the adjustment procedure, through regression,
matching or otherwise, will not lower asymptotic precision of the average treatment eﬀect if
the assumptions are correct. In ﬁnite samples, however, a covariate that is not, or only weakly,
correlated with outcomes and treatment indicators may reduce precision. There are few procedures currently available for optimally choosing the set of covariates to be included in matching
or regression adjustments, taking into account such ﬁnite sample properties.
The ﬁrst issue is a substantive one. The unconfoundedness assumption may apply with one
set of covariates but it need not apply with an expanded set. A particular concern is the inclusion
of covariates that are themselves aﬀected by the treatment such as intermediate outcomes.
Suppose, for example, that in evaluating a job training program, the primary outcome of
interest is earnings two years later.
In that case, employment status prior to the program
is unaﬀected by the treatment and thus a valid element of the set of adjustment covariates.
In contrast, employment status one year after the program is an intermediate outcome and
should not be controlled for. It could itself be an outcome of interest, and should therefore
never be a covariate in an analysis of the eﬀect of the training program. One guarantee that
a covariate is not aﬀected by the treatment is that it was measured before the treatment
was choosen. In practice, however, the covariates are often recorded at the same time as the
outcomes, subsequent to treatment.
In that case one has to assess on a case-by-case basis
whether a particular covariate should be used in adjusting outcomes. See Rosenbaum 
and Angrist and Krueger for more discussion.
Assessing the Overlap Assumption
The second of the key assumptions in estimating average treatment eﬀects requires that the
propensity score—the probability of receiving treatment—is strictly between zero and one.
Although in principle this is testable, as it restricts the joint distribution of observables, formal
tests are not necessarily the main concern. In practice, this assumption raises a number of
issues. The ﬁrst question is how to detect a lack of overlap in the covariate distributions. A
second is how to deal with it, given that such a lack exists. A third is how the individual
methods discussed in Section 3 address this lack of overlap. Ideally such a lack would result in
large standard errors for the average treatment eﬀects.
The ﬁrst method to detect lack of overlap is to plot distributions of covariates by treatment
groups. In the case with one or two covariates one can do this directly. In high dimensional
cases, however, this becomes more diﬃcult. One can inspect pairs of marginal distributions by
treatment status, but these are not necessarily informative about lack of overlap. It is possible
that for each covariate the distribution for the treatment and control groups are identical, even
though there are areas where the propensity score is zero or one.
A more useful method is therefore to inspect the distribution of the propensity score in
both treatment groups, which can directly reveal lack of overlap in the covariate distributions.
Its implementation requires nonparametric estimation of the propensity score, however, and
misspeciﬁcation may lead to failure in detecting a lack of overlap, just as inspecting various
marginal distributions may be insuﬃcient.
In practice one may wish to undersmooth the
estimation of the propensity score, either by choosing a bandwidth smaller than optimal for
nonparametric estimation or by including higher order terms in a series expansion.
A third way to detect lack of overlap is to inspect the quality of the worst matches in a
matching procedure. Given a set of matches, one can, for each component k of the vector of
covariates, inspect maxi |xi,k −xℓ1(i),k|, the maximum over all observations of the matching
discrepancy.
If this diﬀerence is large relative to the sample standard deviation of the kth
component of the covariates, there would be reason for concern. The advantage of this method
is that it does not require additional nonparametric estimation.
Once one determines that there is a lack of overlap one can either conclude that the average
treatment eﬀect of interest cannot be estimated with suﬃcient precision, and/or decide to focus
on an average treatment eﬀect that is estimable with greater accuracy. To do the latter it can be
useful to discard some of the observations on the basis of their covariates. For example one may
decide to discard control (treated) observations with propensity scores below (above) a cutoﬀ
level. The desired cutoﬀmay be sample size dependent; in a very large sample one may not be
concerned with a propensity score of 0.01, whereas in small samples such a value may make it
diﬃcult to ﬁnd reasonable comparisons. To judge such tradeoﬀs, it is useful to understand the
relationship between a unit’s propensity score and its implicit weight in the average treatment
eﬀect estimation. Using the weighting estimator the average outcome under the treatment is
estimated by summing up outcomes for the control units with weight approximately equal to
one over their propensity score (and one over one minus the propensity score for treated units).
Hence with N units, the weight of unit i is approximately 1/(N · (1 −e(Xi))) if it is a treated
unit and 1/(N · e(Xi)) if it is a control. One may wish to limit this weight to some fraction,
for example, 0.05, so that no unit will have a weight of more than 5% in the average. Under
that approach, the limit on the propensity score in a sample with 200 units is 0.1; units with a
propensity score less than 0.1 or greater than 0.9 would be discarded. In a sample with 1000
units, only units with a propensity score outside the range [0.02, 0.98] would be ignored.
In matching procedures one need not rely entirely on comparisons of the propensity score
distribution in discarding the observations with insuﬃcient match quality. Whereas Rosenbaum
and Rubin suggest accepting only matches where the diﬀerence in propensity scores is
below a cutoﬀpoint, alternatively one may wish to drop matches where individual covariates
are severely mismatched.
Finally, let us consider the three approaches to inference—regression, matching and propensity score methods—and assess how each handle lack of overlap. Suppose one is interested in
estimating the average eﬀect on the treated, and one has a data set with suﬃcient overlap.
Now suppose one adds a few treated or control observations with covariate values rarely seen
in the alternative treatment group. Adding treated observations with outlying values implies
one cannot estimate the average treatment eﬀect for the treated very precisely, because we lack
suitable controls against which to compare these additional units. Thus with methods appropriately dealing with limited overlap one would see the variance estimates increase. In contrast,
adding control observations should have little eﬀect since additional control units with outlying
covariates are irrelevant for the average treatment eﬀect for the treated. Therefore methods
appropriately dealing with limited overlap should in this case show estimates approximately
unchanged in terms of bias and precision.
Consider ﬁrst the regression approach. Conditional on a particular parametric speciﬁcation
for the regression function, adding observations with outlying values of the regressors leads
to considerably more precise parameter estimates; such observations are inﬂuential precisely
because of their outlying values. If the added observations are treated units, the precision of
the estimated control regression function at these outlying values will be lower (since few if any
control units are found in that region), thus the variance will increase as it should. One should
note, however, that the estimates in this region may be sensitive to the speciﬁcation chosen.
In contrast, by the nature of regression functions adding control observations with outlying
values will lead to a spurious increase in precision of the control regression function. Regression
methods can therefore be misleading in cases with limited overlap.
Next, consider matching. In estimating the average treatment eﬀect for the treated, adding
control observations with outlying covariate values will likely have little aﬀect on the results,
since such observations are unlikely to be used as matches. The results would, however, be
sensitive to adding treated observations with outlying covariate values, because these observations would be matched to inappropriate controls, leading to possibly biased estimates. The
standard errors would largely be unaﬀected.
Finally, consider propensity score estimates. Estimates of the probability of receiving treatment now include values close to zero and one. The values close to zero for the control observations would cause little diﬃculty because these units would get close to zero weight in the
estimation. The control observations with a propensity score close to one, however, would be
heavily weighted leading to an increase in the variance of the average treatment eﬀect estimator,
correctly infering that one cannot estimate the average treatment eﬀect very precisely. Blocking
on the propensity score would lead to similar conclusions.
Overall, propensity score and matching (and similarly kernel-based regression methods) are
better designed to cope with limited overlap in the covariate distributions than are parametric
or semiparametric (series) regression models. In all cases it is useful to inspect histograms of
the estimated propensity score in both groups to assess whether limited overlap is an issue.
Applications
There are many studies using some form of unconfoundedness or selection on observables,
ranging from simple least squares analyses to matching on the propensity score . Here I focus primarily on two sets of analyses that can help us assess the value of
the methods surveyed in this paper. First, studies attempting to assess the plausibility of the
assumptions, often using randomized experiments as a yard stick. Second, simulation studies
focusing on the performance of the various techniques in settings where the assumptions are
known to hold.
Applications: Randomized Experiments as Checks on Unconfoundedness
The basic idea behind these studies is simple: namely to use experimental results as a check on
the attempted “non-experimental” estimates. Given a randomized experiment one can obtain
unbiased estimates of the average eﬀect of a program. Then, put aside the experimental control
group, and attempt to replicate these results using a non-experimental control.
If one can
successfully replicate the experimental results, this suggests that the assumptions and methods
are plausible. Such investigations are of course not generally conclusive, but are invaluable
in assessing the plausibility of the approach.
The ﬁrst such study, and one that made an
enormous impact in the econometrics literature, was by Lalonde . Fraker and Maynard
 conducted a similar investigation, and many more have followed.
Lalonde took the National Supported Work program, a fairly small program aimed
at particularly disadvantaged people in the labor market (individuals with poor labor market
histories and skills). Using this data, he set aside the experimental control group and in its place
constructed alternative controls from the Panel Study of Income Dynamics (PSID) and Current
Population Survey (CPS), using various selection criteria depending on prior labor market experience. He then used a number of methods—ranging from a simple diﬀerence, to least squares
adjustment, a Heckman selection correction, and diﬀerence-in-diﬀerences techniques—to create
non-experimental estimates of the average treatment eﬀect. His general conclusion was that
the results were very unpredictable and that no method could consistently replicate the experimental results using any of the six non-experimental control groups constructed. A number of
researchers have subsequently tested new techniques using this same data. Heckman and Hotz
 focused on testing the various models and argued that the testing procedures they developed would have eliminated many of Lalonde’s particularly inappropriate estimates. Dehejia
and Wahba used several of the semiparametric methods based on the unconfoundedness
assumption discussed in this survey, and found that for the subsample of the Lalonde data that
they used (with two years of prior earnings), these methods replicated the experimental results
more accurately – both overall, as wellas within subpopulations. Smith and Todd analyze the same data and conclude that for other subsamples, including those for whom only one
year of prior earnings is available, the results are less robust. See Dehejia for additional
discussion of these results.
Others have used diﬀerent experiments to carry out the same or similar analyses, using
varying sets of estimators, and alternative control groups. Friedlander and Robins focus
on least squares adjustment, using data from the WIN (Work INcentive) demonstration programs conducted in a number of states, and construct control groups from other counties in the
same state, as well as from diﬀerent states. They conclude that non-experimental methods are
unable to replicate the experimental results. Hotz, Imbens and Mortimer use the same
data and consider matching methods with various sets of covariates, using single or multiple
alternative states as non-experimental control groups. They ﬁnd that for the subsample of
individuals with have positive earnings at some date prior to the program non-experimental
methods work better than for those with no known positive earnings.
Heckman, Ichimura and Todd study the national Job Training Partnership
Act (JPTA) program, using data from diﬀerent geographical locations to investigate the nature
of the biases associated with diﬀerent estimators, and the importance of overlap in the covariates, including labor market histories. Their conclusions provide the type of speciﬁc guidance
that should be the aim of such studies. They give clear and generalizable conditions that make
the assumptions of unconfoundedness and overlap—at least according to their study of a large
training program—more plausible; the need to include detailed earnings histories, and the use
of control groups that are geographically close to the treatment group, preferably groups of
ineligibles, or eligible nonparticipants from the same location. In contrast, control groups from
very diﬀerent locations are found to be poor non-experimental controls. Although such conclusions are only clearly generalizable to evaluations of social programs, they are potentially very
useful in providing analysts with concrete guidance as to the applicability of these assumptions.
Dehejia uses the Greater Avenues to INdependence (GAIN) data, using diﬀerent
counties as well as diﬀerent oﬃces within the same county as nonexperimental control groups.
Similarly, Hotz, Imbens and Klerman use the basic GAIN data set supplemented with adminstrative data of long-term quarterly earnings information (both prior and subsequent to the
randomization date), to investigate the importance of detailed earnings histories. Such detailed
histories can also provide more evidence on the plausibility of non-experimental evaluations for
long-term outcomes.
Two complications make this literature diﬃcult to evaluate. One is the diﬀerences in covariates used; it is rare that variables are measured consistently accross diﬀerent studies. For
instance, some have yearly earnings data, others quarterly, others only earnings indicators on
a monthly or quarterly basis. This makes it diﬃcult to consistently investigate the level of
detail in earnings history necessary for the unconfoundedness assumption to hold. A second
complication is that diﬀerent estimators are generally used, thus any diﬀerences in results can
be attributed to either estimators or assumptions. This is likely driven by the fact that few
of the estimators have been suﬃciently standardized that they can be implemented easily by
empirical researchers.
All of these studies just discussed took data from actual randomized experiments to test
the “true” treatment eﬀect against the estimators used on the non-experimental data. To some
extent, however, such experimental data are not required. The question of interest is whether an
alternative control group is an adequate proxy for a randomized control in a particular setting;
note that this question does not require data on the treatment group. Although these questions
have typically been studied by comparing experimental to non-experimental results, all that is
really relevant is whether the non-experimental control group can predict the average outcomes
for the experimental control. As in the Heckman, Ichimura, Smith and Todd analysis
of the JTPA data, one can take two groups, neither subject to the treatment, and ask the
question whether—using data on the covariates for the ﬁrst control group in combination with
outcome and covariate information for the second—one can predict the average outcome in the
ﬁrst. If yes, this implies that, had there been an experiment on the population from which the
ﬁrst control group was drawn, the second group would provide an acceptable non-experimental
control. From this perspective one can use data from many diﬀerent surveys. In particular,
one can more systematically investigate whether control groups from diﬀerent counties, states,
regions or even diﬀerent time periods make acceptable non-experimental controls.
Simulations
A second question that is often confounded with that of the validity of the assumptions is
that of the relative performance of the various estimators. Suppose one is willing to accept
the unconfoundedness and overlap assumptions. Which estimation method is most appropriate
in a particular setting? In many of the studies comparing non-experimental to experimental
outcomes, researchers compare results for a number of the techniques described here. Yet in
these settings we cannot be certain that the underlying assumptions hold. Thus, although it
is useful to compare these techniques in such realistic settings, it is also important to compare
them in an artiﬁcial environment where one is certain that the underlying assumptions are
There exist a few studies that speciﬁcally set out to do just this. Fr¨olich compares a
number of matching estimators and local linear regression methods, carefully formalizing fully
data-driven procedures for the estimators considered. To make these comparisons he considers a large number of data generating processes, based on eight diﬀerent regression functions
(including some highly nonlinear and multimodal ones), two diﬀerent sample sizes, and three
diﬀerent density functions for the covariate (one important limitation is that he restricts the
investigation to a single covariate).
For the matching estimator Fr¨olich considered a single
match with replacement; for the local linear regression estimators he uses data-driven optimal
bandwidth choices based on minimizing mean-squared-error of the average treatment eﬀect.
The ﬁrst local linear estimator considered is the standard one; at x the regression function µ(x)
is estimated as β0 in the minimization problem
(Yi −β0 −β1 · (Xi −x))2 · K
with an Epanechnikov kernel. He ﬁnds that this has computational problems, as well as poor
small-sample properties. He therefore also considers a modiﬁcation suggested by Seifert and
Gasser . For given x, deﬁne ¯x = P XiK((Xi −x)/h)/ P K((Xi −x)/h), so that
one can write the standard local linear estimator as
ˆµ(x) = T0
· (x −¯x),
where, for r = 0, 1, 2, Sr = P K((Xi −x)/h)(Xi −x)r and Tr = P K((Xi −x)/h)(Xi −x)rYi.
The Seifert-Gasser modiﬁcation is to use instead
ˆµ(x) = T0
S2 + R · (x −¯x),
where the recommended ridge parameter is R = |x−¯x|(5/(16h)), given the Epanechikov kernel
k(u) = (3/4)(1−u2)1{|u| < 1}. Note that with high-dimensional covariates, such a nonnegative
kernel would lead to biases that do not vanish fast enough to be dominated by the variance
 . This is not a problem in Fr¨olich’s
simulations as he considers only cases with a single covariate. Fr¨olich ﬁnds that the local linear
estimator, with the Seifert and Gassert modiﬁcation, performs better than either the matching
or standard local linear estimator.
Zhao uses simulation methods to compare matching and parametric regression estimators. He uses metrics based on the propensity score, the covariates, and estimated regression
functions. Using designs with varying numbers of covariates and linear regression functions,
Zhao ﬁnds there is no clear winner among the diﬀerent estimators, although he notes that using
the outcome data in choosing the metric appears a promising strategy.
Abadie and Imbens study their matching estimator using a data generating process
inspired by the Lalonde study to allow for substantial nonlinearity, ﬁtting a separate binary
response model to the zeros in the earnings outcome and a log linear model for the positive
observations. The regression estimators include linear and quadratic models (the latter with
a full set of interactions), with seven covariates.
This study ﬁnds that the matching estimators, and in particular the bias-adjusted alternatives, outperform the linear and quadratic
regression estimators (the former using 7 covariates, the latter 35, after dropping squares and
interactions that lead to perfect collinarity). Their simulations also suggest that with relatively
few matches—between one and four—matching estimators are not sensitive to the number of
matches use, and that their conﬁdence intervals have actual coverages rates close to the nominal
The results from these simulation studies are overall somewhat inconclusive; it is clear
that more work is required. Future simulations may usefully focus on some of the following
issues. First, it is obviously important to closely model the data generating process on actual
data sets, to ensure that the results have some relevance for practice. Ideally one would build
the simulations around a number of speciﬁc data sets through a range of data generating
processes. Second, it is important to have fully data-driven procedures that deﬁne an estimator
as a function of (Yi, Wi, Xi)N
i=1, as seen in Fr¨olich . For the matching estimators this is
relatively straightforward, but for some others this requires more care. This will allow other
researchers to consider meaningful comparisons across the various estimators.
Finally, we need to learn which features of the data generating process are important for
the properties of the various estimators. For example, do some estimators deteriorate more
rapidly than others when a dataset holds many covariates and few observations? Are some
estimators more robust against high correlations between covariates and outcomes, or high
correlations between covariates and treatment indicators? Which estimators are more likely to
give conservative answers in terms of precision? Since it is clear that no estimator is always
going to dominate all others, what is important here is to isolate salient features of the data
generating processes that lead to preferring one alternative over another.
Ideally we need
descriptive statistics summarizing the features of the data that provide guidance in choosing
the estimator that will perform best in a given situation.
Conclusion
In this paper I have attempted to review the current state of the literature on inference for
average treatment eﬀects under the assumption of unconfoundedness. This has recently been a
very active area of research where many new semi- and non-parametric econometric methods
have been applied and developed. The research has moved a long way from relying on simple
least squares methods for estimating average treatment eﬀects.
The primary estimators in the current literature include propensity score methods and
pairwise matching, as well as nonparametric regression methods. Eﬃciency bounds have been
established for a number of the average treatment eﬀects estimable with these methods, and
a variety of these estimators rely on the weakest assumptions that allow point identiﬁcation.
Researchers have suggested several ways for estimating the variance of these average treatment
eﬀect estimators. One, more cumbersome, approach requires estimating each component of
the variance non-parametrically. A more common method relies on bootstrapping. A third
alternative, developed by Abadie and Imbens for the matching estimator, requires no
non-parametric estimation. There is, as of yet, however, no consensus on which are the best
estimation methods to apply in practice. Nevertheless, the applied researcher has now a large
number of new estimators at her disposal.
Challenges remain in making the new tools more easily applicable.
Although software
is available to implement some of the estimators , many remain diﬃcult to apply. A particularly urgent
task is therefore to provide fully implementable versions of the various estimators that do not
require the applied researcher to choose bandwidths or other smoothing parameters. This is
less of a concern for matching methods and probably explains a large part of their popularity.
Another outstanding question is the relative performance of these methods in realistic settings
with large numbers of covariates and varying degrees of smoothness in the conditional means
of the potential outcomes and the propensity score.
Once these issues have been resolved, today’s applied evaluators will beneﬁt from a new set of
reliable, econometrically defendable, and robust methods for estimating the average treatment
eﬀect of current social policy programs.