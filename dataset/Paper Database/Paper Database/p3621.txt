Learning to rank in person re-identiﬁcation with metric ensembles
Sakrapee Paisitkriangkrai, Chunhua Shen∗, Anton van den Hengel
The University of Adelaide, Australia; and Australian Center for Robotic Vision
We propose an effective structured learning based approach to the problem of person re-identiﬁcation which outperforms the current state-of-the-art on most benchmark
data sets evaluated.
Our framework is built on the basis of multiple low-level hand-crafted and high-level visual features. We then formulate two optimization algorithms, which directly optimize evaluation measures commonly used in person re-identiﬁcation, also known as the
Cumulative Matching Characteristic (CMC) curve.
new approach is practical to many real-world surveillance
applications as the re-identiﬁcation performance can be
concentrated in the range of most practical importance.
The combination of these factors leads to a person reidentiﬁcation system which outperforms most existing algorithms. More importantly, we advance state-of-the-art
results on person re-identiﬁcation by improving the rank-
1 recognition rates from 40% to 50% on the iLIDS benchmark, 16% to 18% on the PRID2011 benchmark, 43% to
46% on the VIPeR benchmark, 34% to 53% on the CUHK01
benchmark and 21% to 62% on the CUHK03 benchmark.
1. Introduction
2. Our Approach
2.1. Ensemble of base metrics
. . . . . . . . . .
Relative distance based approach
(CMC triplet) . . . . . . . . . . . .
Top recognition at rank-k (CMC top)
Cutting-plane optimization . . . . .
2.2. Base metrics
. . . . . . . . . . . . . . . . .
2.3. Visual features . . . . . . . . . . . . . . . .
3. Experiments
3.1. Evaluation and analysis
. . . . . . . . . . .
3.2. Comparison with state-of-the-art results . . .
4. Conclusion
∗Corresponding author: C. Shen ( ).
1. Introduction
The task of person re-identiﬁcation (re-id) is to match
pedestrian images observed from multiple cameras. It has
recently gained popularity in research community due to its
several important applications in video surveillance. An automated re-id system could save a lot of human labour in
exhaustively searching for a person of interest from a large
amount of video sequences.
Despite several years of research in the computer vision
community, person re-id is still a very challenging task and
remains unsolved due to (a) large variation in visual appearance (person’s appearance often undergoes large variations
across different camera views); (b) signiﬁcant changes in
human poses at the time the image was captured; (c) large
amount of illumination changes and (d) background clutter
and occlusions. Moreover the problem becomes increasingly difﬁcult when persons share similar appearance, e.g.,
people wearing similar clothing style with similar color.
To address these challenges, existing research on this
topic has concentrated on the development of sophisticated
and robust features to describe the visual appearance under signiﬁcant changes.
However the system that relies
heavily on one speciﬁc type of visual cues, e.g., color, texture or shape, would not be practical and powerful enough
to discriminate individuals with similar visual appearance.
Existing studies have tried to address the above problem
by seeking a combination of robust and distinctive feature
representation of person’s appearance, ranging from color
histogram , spatial co-occurrence representation ,
LBP , color SIFT , etc.
One simple approach to exploit multiple visual features
is to build an ensemble of distance functions, in which each
distance function is learned using a single feature and the
ﬁnal distance is calculated from a weighted sum of these
distance functions . However existing works on
person re-id often pre-deﬁne these weights, which need to
be re-estimated beforehand for different data sets. Since
different re-id benchmark data sets can have very different
characteristics, i.e., variation in view angle, lighting and occlusion, combining multiple distance functions using predetermined weights is undesirable as highly discriminative
features in one environment might become irrelevant in an-
 
other environment.
In this paper, we introduce effective approaches to learn
weights of these distance functions. The ﬁrst approach optimizes the relative distance using the triplet information and
the second approach maximizes the average rank-k recognition rate, in which k is chosen to be small, e.g., k < 10.
Setting the value of k to be small is crucial for many realworld applications since most surveillance operators typically inspect only the ﬁrst ten or twenty items retrieved.
The main contributions of this paper are twofold: 1) We
propose two principled approaches to build an ensemble of
person re-id algorithms. The ﬁrst approach aims at maximizing the relative distance between images of different
individuals and images of the same individual such that the
CMC curve approaches one with a minimal number of returned candidates. The second approach directly optimizes
the probability that any of these top k matches are correct
using structured learning. Our ensemble-based approaches
are highly ﬂexible and can be combined with linear and
non-linear metrics. 2) Extensive experiments are carried out
to demonstrate that by building an ensemble of person reid algorithms learned from different visual features, notable
improvement on rank-1 recognition rate can be obtained.
Experimental results show that our approach achieves the
state-of-the-art performance on most person re-id benchmark data sets evaluated. In addition, our ensemble approach is complementary to any existing distance learning
Related work Existing person re-id systems consist of
two major components: feature representation and metric
In feature representation, robust and discriminative features are constructed such that they can be used
to describe the appearance of the same individual across
different camera views under various changes and conditions . We brieﬂy discuss some of
these work below. More feature representations, which have
been applied in person re-id, can be found in .
Bazzani et al. represent a person by a global mean color
histogram and recurrent local patterns through epitomic
analysis . Farenzena et al. propose the symmetry-driven
accumulation of local features which exploits both symmetry and asymmetry, and represents each part of a person by
a weighted color histogram, maximally stable color regions
and texture information . Gray and Tao introduce an ensemble of local features which combines three color channels with 19 texture channels . Schwartz and Davis propose a discriminative appearance based model using partial least squares, in which multiple visual features: texture, gradient and color features are combined . Zhao et
al. propose dcolorSIFT which combines SIFT features with
color histogram. The same authors also propose mid-level
ﬁlters for person re-identiﬁcation by exploring the partial
area under the ROC curve (pAUC) score .
A large number of metric learning and ranking algorithms have been proposed . Many of
these have been applied to the problem of person re-id. We
brieﬂy review some of these algorithms. Interested readers
should see . Chopra et al. propose an algorithm to learn
a similarity metric from data . The authors train a convolutional network that maps input images into a target space
such that the ℓ1-norm in the target space approximate the
semantic distance in the image space. Gray and Tao use AdaBoost to select discriminative features . Koestinger et
al. propose the large-scale metric learning from equivalence
constraint which considers a log likelihood ratio test of two
Gaussian distributions . Li et al. propose the learning
of locally adaptive decision functions, which can be viewed
as a joint model of a distance metric and a locally adapted
thresholding rule . Li et al. propose a ﬁlter pairing neural network to learn visual features for the re-identiﬁcation
task from image data . Pedagadi et al. combine color
histogram with supervised Local Fisher Discriminant Analysis . Prosser et al. use pairs of similar and dissimilar
images and train the ensemble RankSVM such that the true
match gets the highest rank . Weinberger et al. propose
the large margin nearest neighbour (LMNN) algorithm to
learn the Mahalanobis distance metric, which improves the
k-nearest neighbour classiﬁcation . LMNN is later applied to a task of person re-identiﬁcation in . Wu et al.
applies the Metric Learning to Rank (MLR) method of 
to person re-id .
Although a large number of existing algorithms have exploited state-of-the-art visual features and advanced metric learning algorithms, we observe that the best obtained
overall performance on commonly evaluated person re-id
benchmarks, e.g., iLIDS and VIPeR, is still far from the
performance needed for most real-world surveillance applications.
Notation Bold lower-case letters, e.g., w, denote column vectors and bold upper-case letters, e.g., P , denote
matrices. We assume that the provided training data is for
the task of single-shot person re-identiﬁcation, i.e., there
exist only two images of the same person – one image
taken from camera view A and another image taken from
camera view B. We represent a set of training samples by
i=1 where xi ∈RD represents a training example from one camera (i.e., camera view A), and x+
the corresponding image of the same person from a different camera (i.e., camera view B). Here m is the number
of persons in the training data.
From the given training
data, we can generate a set of triplets for each sample xi
for i = 1, · · · , m and i ̸= j. Here we
introduce x−
i where X−
i denotes a subset of images
of persons with a different identity to xi from camera view
B. We also assume that there exist a set of distance functions dt(·, ·) which calculate the distance between two given
inputs. Our goal is to learn a weighted distance function:
d(·, ·) = PT
t=1 wtdt(·, ·), such that the distance between
xi (taken from camera view A) and x+
i (taken from camera view B) is smaller than the distance between xi and any
i,j (taken from camera view B). The better the distance
function, the faster the cumulative matching characteristic
(CMC) curve approaches one.
2. Our Approach
In this section, we propose two approaches that can learn
an ensemble of base metrics. We then discuss base metrics
and visual features that will be used in our experiment.
2.1. Ensemble of base metrics
The most commonly used performance measure for evaluating person re-id is known as a cumulative matching characteristic (CMC) curve , which is analogous to the ROC
curve in detection problems. The CMC curve represents
results of an identiﬁcation task by plotting the probability
of correct identiﬁcation (y-axis) against the number of candidates returned (x-axis). The faster the CMC curve approaches one, the better the person re-id algorithm. Since
a better rank-1 recognition rate is often preferred , our
aim is to improve the recognition rate among the k best candidates, e.g., k < 20, which is crucial for many real-world
surveillance applications. Note that, in practice, the system
that achieves the best recognition rate when k is large (e.g.,
k > 100) is of little interest since most users inspect or
consider only the ﬁrst ten or twenty returned candidates.
In this section, we propose two different approaches
which learn an ensemble of base metrics (discussed in the
next section). The ﬁrst approach, CMC triplet, aims at minimizing the number of returned list of candidates in order
to achieve a perfect identiﬁcation, i.e., minimizing k such
that the rank-k recognition rate is equal to one. The second approach, CMC top, optimizes the probability that any
of these k best matches are correct.
Relative distance based approach (CMC triplet)
In order to minimize k such that the rank-k recognition
rate is equal to 100%, we consider learning an ensemble of
distance functions based on relative comparison of triplets
 . Given a set of triplets
i,j, in which xi
is taken from camera view A and {x+
i,j} are taken from
camera view B, the basic idea is to learn a distance function such that images of the same individual are closer than
any images of different individuals, i.e., xi is closer to x+
than any x−
i,j. For a triplet
i,j, the following condition must hold d(xi, x−
i,j) > d(xi, x+
i ), ∀j, i ̸= j.
Following the large margin framework with the hinge loss,
the condition d(xi, x−
i,j) ≥1 + d(xi, x+
i ) should be satisﬁed. This condition means that the distance between two
images of different individuals should be larger by at least a
unit than the distance between two images of the same individual. Since the above condition cannot be satisﬁed by all
triplets, we introduce a slack variable to enable soft margin.
By generalizing the above idea to the entire training set, the
primal problem that we want to optimize can be written as,
s.t. w⊤(d−
i ) ≥1 −ξij, ∀{i, j} , i ̸= j;
w ≥0; ξ ≥0.
Here ν > 0 is the regularization parameter and d−
[d1(xi, x−
i,j), · · · , dt(xi, x−
= [d1(xi, x+
i ), · · · ,
i )] and {d1(·, ·),· · · ,dt(·, ·)} represent a set of base
Note that we introduce the regularization term
2 to avoid the trivial solution of arbitrarily large w.
We point out here that any smooth convex loss function
can also be applied. Suppose λ(·) is a smooth convex function deﬁned in R and ω(·) is any regularization function.
The above optimization problem which enforces the relative comparison of the triplet can also be written as,
w ω(w) + ν
wtdt(xi, x−
wtdt(xi, x+
where τ being the triplet index set. In this paper, we consider the hinge loss but other convex loss functions can
be applied.
Since the number of constraints in (1) is quadratic in the
number of training examples, directly solving (1) using offthe-shelf optimization toolboxes can only solve problems
with up to a few thousand training examples. In the following, we present an equivalent reformulation of (1), which
can be efﬁciently solved in a linear runtime using cuttingplane algorithms. We ﬁrst reformulate (1) by writing it as:
m(m −1)w⊤h m
∀{i, j} , i ̸= j; w ≥0; ξ ≥0.
Note that the new formulation has a single slack variable.
Later on in this section, we show how the cutting-plane
method can be applied to solve (3).
Top recognition at rank-k (CMC top)
Our previous formulation assumes that, for any triplets, images belonging to the same individual should be closer than
images belonging to different individuals. Our second formulation is motivated by the nature of the problem, in which
person re-id users often browse only the ﬁrst few retrieved
matches. Hence we propose another approach, in which
the objective is no longer to minimize k (the number of
returned matches before achieving 100% recognition rate),
but to maximize the correct identiﬁcation among the top k
best candidates. Built upon the structured learning framework , we optimize the performance measure commonly used in the CMC curve (recognition rate at rank-k)
using structured learning. The difference between our work
and is that assumes training samples consist of
m+ positive instances and m−negative instances, while
our work assumes that there are m individuals in camera
view A and m individuals in camera view B. However there
exists ranking in both works: attempts to rank all positive samples before a subset of negative samples while our
works attempt to rank a pair of the same individual above
a pair of different individuals. Both also apply structure
learning of to solve the optimization problem.
Given the training individual xi (from camera view A)
and its correct match x+
i from camera view B, we can represent the relative ordering of all matching candidates in
camera view B via a vector p ∈Rm′, in which pj is 0 if
i (from camera view B) is ranked above x−
i,j (from camera view B) and 1 if x+
i is ranked below x−
i,j. Here m′ is
the total number of individuals from camera view B who
has a different identity to xi. Since there exists only one
image of the same individual in the camera view B, m′ is
equal to m −1 where m is the total number of individuals in the training set. We generalize this idea to the entire
training set and represent the relative ordering via a matrix
P ∈{0, 1}m×m′
as follows:
i is ranked above x−
otherwise.
The correct relative ordering of P can be deﬁned as P ∗
ij = 0, ∀i, j. The loss among the top k candidates
can then be written as,
∆(P ∗, P ) =
where (j) denotes the index of the retrieved candidates
ranked in the j-th position among all top k best candidates.
We deﬁne the joint feature map, ψ, of the form:
ψ(S, P ) =
(1 −pij)(d−
where S represent a set of triplets generated from the
training data, d−
= [d1(xi, x−
i,j), · · · , dt(xi, x−
= [d1(xi, x+
i ), · · · , dt(xi, x+
The choice of
ψ(S, P ) guarantees that the variable w, which optimizes w⊤ψ(S, P ), will also produce the distance function
d(·, ·) = PT
t=1 wtdt(·, ·) that achieves the optimal average
recognition rate among the top k candidates. The above
problem can be summarized as the following convex optimization problem:
s.t. w⊤ ψ(S, P ∗) −ψ(S, P )
≥∆(P ∗, P ) −ξ,
∀P and ξ ≥0. Here P ∗denote the correct relative ordering and P denote any arbitrary orderings. Similar to
CMC triplet, we use the cutting-plane method to solve (7).
Cutting-plane optimization
In this section, we illustrate how the cutting-plane method
can be used to solve both optimization problems: (3) and
(7). The key idea of the cutting-plane is that a small subset of the constraints are sufﬁcient to ﬁnd an ϵ-approximate
solution to the original problem. The cutting-plane algorithm begins with an empty initial constraint set and iteratively adds the most violated constraint set. At each iteration, the algorithm computes the solution over the current
working set. The algorithm then ﬁnds the most violated
constraint and add it to the working set. The cutting-plane
algorithm continues until no constraint is violated by more
than ϵ. Since the quadratic program is of constant size, the
cutting-plane method converges in a constant number of iterations. We present our proposed CMC top in Algorithm 1.
The optimization problem for ﬁnding the most violated
constraint (Algorithm 1, step y) can be written as,
∆(P ∗, P ) −w⊤ ψ(S, P ∗) −ψ(S, P )
∆(P ∗, P ) −
pi,(j)(1 −w⊤d±
pi,(j)w⊤d±
i,(j) = d−
i . Since pij in (8) is independent,
the solution to (8) can be solved by maximizing over each
element pij. Hence ¯P that most violates the constraint corresponds to,
if j ∈{1, · · · , k}
otherwise.
Algorithm 1 Cutting-plane algorithm for solving coefﬁcients of base metrics (CMC top)
1) A set of base metrics of the same individual and different
individuals {d+
2) The regularization parameter, ν;
3) The cutting-plane termination threshold, ϵ;
Output: The base metrics’ coefﬁcients w,
Initialize: The working set, C = ∅;
g(S, P , w) = ∆(P ∗, P ) −
i,j pijw⊤(d−
x Solve the primal problem using linear SVM,
s.t. g(S, P , w) ≤ξ, ∀P ∈C;
y Compute the most violated constraint,
g(S, P , w);
z C ←C ∪{ ¯P };
Until g(S, P , w) ≤ξ + ϵ ;
For CMC triplet, one replaces g(S, P , w) in Algorithm 1
with g(S, w) = 1 −
m(m−1)w⊤hP
and repeats the same procedure.
In this section we assume that the base metrics,
{d1(·, ·),· · · ,dt(·, ·)}, are provided. In the next section, we
introduce two base metrics adopted in our proposed approaches.
2.2. Base metrics
Metric learning can be divided into two categories: linear and non-linear methods . In
the linear case, the goal is to learn a linear mapping by estimating a matrix M such that the distance between images
of the same individual, (xi −x+
i )⊤M(xi −x+
i ), is less
than the distance between images of different individuals,
i,j)⊤M(xi −x−
i,j). The linear method can be easily
extended to learn non-linear mapping by kernelization .
The basic idea is to learn a linear mapping in the feature
space of some non-linear function, φ, such that the distance
(φ(xi) −φ(x+
i ))⊤M(φ(xi) −φ(x+
i )) is less than the distance (φ(xi) −φ(x−
i,j))⊤M(φ(xi) −φ(x−
Metric learning from equivalence constraints The basic idea of KISS metric learning (KISS ML) , is to learn
the Mahalanobis distance by considering a log likelihood
ratio test of two Gaussian distributions. The likelihood ratio test between dissimilar pairs and similar pairs can be
written as,
r(xi, xj) = log
where xij = xi−xj, cd =
2π|ΣD|, cs =
2π|ΣS|, ΣD
and ΣS are covariance matrices of dissimilar pairs and similar pairs, respectively. By taking log and discarding constant terms, (9) can be simpliﬁed as,
r(xi, xj) = (xi −xj)⊤(Σ−1
D )(xi −xj),
Hence the Mahalanobis distance matrix M can be written
D . The authors of clip the spectrum of
M by eigen-analysis to ensure M is positive semi-deﬁnite.
This simple algorithm has shown to perform surprisingly
well on the person re-id problem .
Kernel-based metric learning There exist several nonlinear extensions to metric learning.
In this section,
we introduce recently proposed kernel-based metric learning, known as kernel Local Fisher Discriminant Analysis
(kLFDA) , which is a non-linear extension to the previously proposed LFDA and has demonstrated the stateof-the-art performance on iLIDS, CAVIAR and 3DPeS data
sets. The basic idea of kLFDA is to ﬁnd a projection matrix M which maximizes the between-class scatter matrix
while minimizing the within-class scatter matrix using the
Fisher discriminant objective. Similar to LFDA, the projection matrix can be estimated using generalized Eigenvalues.
Unlike LFDA, kLFDA represent the projection matrix with
the data samples in the kernel space φ(·).
2.3. Visual features
We introduce visual features which have been applied in
our person re-id approaches.
SIFT/LAB patterns Scale-invariant feature transform
(SIFT) has gained a lot of research attention due to its invariance to scaling, orientation and illumination changes
 . The descriptor represents occurrences of gradient orientation in each region. In this work, we combine discriminative SIFT with color histogram extracted from the LAB
colorspace.
LBP/RGB patterns Local Binary Pattern (LBP) is another feature descriptor that has received a lot of attention
in the literature due to its effectiveness and efﬁciency .
The standard version of 8-neighbours LBP has a radius of
1 and is formed by thresholding the 3 × 3 neighbourhood
with the centre pixel’s value. To improve the classiﬁcation
accuracy of LBP, we combine LBP histograms with color
histograms extracted from the RGB colorspace.
Region covariance patterns Region covariance is another texture descriptor which has shown promising results
in texture classiﬁcation . The covariance descriptor is
extracted from the covariance of several image statistics inside a region of interest . Covariance matrix provides
a measure of the relationship between two or more set of
variates. The diagonal entries of covariance matrices represent the variance and the non-diagonal entries represent the
correlation value between low-level features.
Neural patterns Large amount of available training data
and increasing computing power have lead to a recent suc-
cess of deep convolutional neural networks (CNN) on a
large number of computer vision applications. CNN exploits the strong spatially local correlation present in natural
images by enforcing a local connectivity pattern between
neurons of adjacent layers. In the deep CNN architecture,
convolutional layers are placed alternatively between maxpooling and contrast normalization layers .
Implementation See supplementary for detailed implementation.
3. Experiments
Datasets There exist several challenging benchmark
data sets for person re-identiﬁcation.
In this experiment, we select four commonly used data sets (iLIDS,
3DPES, PRID2011, VIPeR) and two recently introduced
data sets with a large number of individuals (CUHK01 and
CUHK03). The iLIDS data set has 119 individuals captured from eight cameras with different viewpoints .
The number of images for each individual varies from 2 to
8, i.e., eight cameras are used to capture 119 individuals.
The data set consists of large occlusions caused by people
and luggages. The 3DPeS data set is designed mainly for
people tracking and person re-identiﬁcation . It contains
numerous video sequences taken from a real surveillance
environment with eight different surveillance cameras and
consists of 192 individuals. The number of images for each
individual varies from 2 to 26 images. The Person RE-ID
2011 (PRID2011) data set consists of images extracted from
multiple person trajectories recorded from two surveillance
static cameras . Camera view A contains 385 individuals, camera view B contains 749 individuals, with 200 of
them appearing in both views. Hence, there are 200 person
image pairs in the dataset.
VIPeR is one of the most popular used data sets for person re-identiﬁcation . It conntains 632 individuals taken
from two cameras with arbitrary viewpoints and varying illumination conditions. The CUHK01 data set contains 971
persons captured from two camera views in a campus environment . Camera view A captures the frontal or back
view of the individuals while camera view B captures the
proﬁle view. Finally, the CUHK03 data set consists of 1360
persons taken from six cameras The data set consists of
manually cropped pedestrian images and images cropped
from the pedestrian detector of . Due to the imperfection in the pedestrian detector, which causes some misalignments of cropped images, we use images which are manually annotated by hand.
Evaluation protocol In this paper, we adopt a singleshot experiment setting, similar to . For
all data sets except CUHK03, all the individuals in the data
set are randomly divided into two subsets so that the training
set and the test set contains half of the available individuals
with no overlap on person identities. For data set with two
cameras, we randomly select one image of the individual
taken from camera view A as the probe image and one image of the same individual taken from camera view B as the
gallery image. For multi-camera data sets, two images of
the same individual are chosen: one is used as the probe image and the other as the gallery image. For CUHK03, we set
the number of individuals in the train/test split to 1260/100
as conducted in . To be more speciﬁc, there are 59, 96,
100, 316, 485 and 100 individuals in each of the test split
for the iLIDS, 3DPeS, PRID2011, VIPeR, CUHK01 and
CUHK03 data sets, respectively. The number of probe images (test phase) is equal to the number of gallery images
in all data sets except PRID2011, in which the number of
probe images is 100 and the number of test gallery images
is 649 (all images from camera view B except the 100 training samples). This procedure is repeated 10 times and the
average of cumulative matching charateristic (CMC) curves
across 10 partitions is reported. The CMC curve provides
a ranking for every image in the gallery with respect to the
Parameters setting For the linear base metric (KISS
ML ), we apply principal component analysis (PCA)
to reduce the dimensionality and remove noise. Without
performing PCA, it is computationally infeasible to inverse
covariance matrices of both similar and dissimilar pairs as
discussed in . For each visual feature, we reduce the
feature dimension to 64 dimensional subspaces. For the
non-linear base metric (kLFDA ), we set the regularization parameter for class scatter matrix to 0.01, i.e., we add
a small identity matrix to the class scatter matrix. For both
SIFT/LAB and LBP/RGB features, we apply the RBF-χ2
kernel. For region covariance and CNN features, we apply
the Gaussian RBF kernel κ(x, x′) = exp(−∥x −x′∥/σ2).
The kernel parameter is tuned to an appropriate value for
each data set. In this experiment, we set the value of σ2 to
be the same as the ﬁrst quantile of all distances .
For CMC triplet, we choose the regularization parameter
(ν in (1)) from {103,103.1,· · · ,104} by cross-validation on
the training data. For CMC top, we choose the regularization parameter (ν in (7)) from {102,102.1,· · · ,103} by crossvalidation on the training data. We set the cutting-plane termination threshold to 10−6. The recall parameter (k in (6))
is set to be 10 for iLIDS, 3DPeS, PRID2011 and VIPeR and
40 for larger data sets (CUHK01 and CUHK03). Since the
success of metric learning algorithms often depends on the
choice of good parameters, we train multiple metric learning for each feature. Speciﬁcally, for KISS ML, we reduce
their feature dimensionality to 32, 48 and 64 dimensions
and use all three to learn the weight w for CMC triplet and
CMC top. Similarly, for kFLDA, we set the σ2 to be the
same as the 5th, the 10th and the ﬁrst quantile of all distances.
Recognition rate (%)
Ours−Top (50.34%)
Ours−Triplet (48.81%)
SIFT/LAB (43.05%)
LBP/RGB (43.73%)
Covariance (37.97%)
CNN (42.71%)
Recognition rate (%)
Ours−Top (53.33%)
Ours−Triplet (52.92%)
SIFT/LAB (45.73%)
LBP/RGB (40.42%)
Covariance (42.19%)
CNN (44.38%)
Recognition rate (%)
Ours−Top (17.90%)
Ours−Triplet (16.80%)
SIFT/LAB (11.10%)
LBP/RGB (6.50%)
Covariance (9.60%)
CNN (6.30%)
Recognition rate (%)
Ours−Top (45.89%)
Ours−Triplet (45.70%)
SIFT/LAB (34.27%)
LBP/RGB (34.05%)
Covariance (26.36%)
CNN (22.47%)
Recognition rate (%)
Ours−Top (53.40%)
Ours−Triplet (52.97%)
SIFT/LAB (37.13%)
LBP/RGB (33.20%)
Covariance (23.15%)
CNN (25.67%)
Recognition rate (%)
Ours−Top (62.10%)
Ours−Triplet (60.50%)
SIFT/LAB (39.00%)
LBP/RGB (53.60%)
Covariance (19.40%)
CNN (28.10%)
Figure 1: Performance comparison of base metrics with different visual features: SIFT/LAB, LBP/RGB, covariance descriptor and CNN features. Rank-1 recognition rates are shown in parentheses. The higher the recognition rate, the better
the performance. Ours-Top (CMC top) represents our ensemble approach which optimizes the CMC score over the top k
returned candidates. Ours-Triplet (CMC triplet) represents our ensemble approach which minimizes the number of returned
candidates such that the rank-k recognition rate is equal to one.
Recognition rate (%)
Ours (Non−lin. ML) (50.34%) .
Ours (Linear ML) (48.98%)
Recognition rate (%)
Ours (Non−lin. ML) (53.33%) .
Ours (Linear ML) (53.75%)
Recognition rate (%)
Ours (Non−lin. ML) (17.90%) .
Ours (Linear ML) (14.90%)
Recognition rate (%)
Ours (Non−lin. ML) (45.89%) .
Ours (Linear ML) (32.91%)
Recognition rate (%)
Ours (Non−lin. ML) (53.40%) .
Ours (Linear ML) (31.98%)
Recognition rate (%)
Ours (Non−lin. ML) (62.10%) .
Ours (Linear ML) (38.90%)
Figure 2: Performance comparison of CMC top with two different base metrics: linear base metric (Linear Metric Learning)
and non-linear base metric (Non-lin. Metric Learning). On VIPeR, CUHK01 and CUHK03 data sets, an ensemble of nonlinear base metrics signiﬁcantly outperforms an ensemble of linear base metrics.
3.1. Evaluation and analysis
Feature evaluation We investigate the impact of lowlevel and high-level visual features on the recognition performance of person re-identiﬁcation. Fig. 1 shows the CMC
performance of different visual features and their rank-1
recognition rates when trained with the kernel-based LFDA
(non-linear metric learning) on six benchmark data sets.
On VIPeR, CUHK01 and CUHK03 data sets, we observe
that both SIFT/LAB and LBP/RGB signiﬁcantly outperform covariance descriptor and CNN features. This result is
not surprising since SIFT/LAB combines edges and color
features while LPB/RGB combines texture and color features. We suspect the use of color helps improve the overall recognition performance of both features. We observe
that CNN features perform poorer than hand-crafted lowlevel features in our experiments. We suspect that the CNN
pre-trained model has been designed for ImageNet object
categories , in which color information might be less
important. However on many person re-id data sets, a large
number of persons wear similar types of clothing, e.g., tshirt and jeans, but with different color. Therefore color
information becomes an important cue for recognizing two
different individuals. Overall, we observe that SIFT/LAB
features perform well consistently on all data sets evaluated.
Ensemble approach with different base metrics Next
we compare the performance of our approach with two different base metrics: linear metric learning and nonlinear metric learning (introduced in Sec. 2.2). In this
experiment, we use CMC top to learn an ensemble. Experimental results are shown in Fig. 2. Two observations can be
made from the ﬁgure: 1) Both approaches perform similarly
when the number of train/test individuals is small, e.g., on
iLIDS and 3DPeS data sets; 2) Non-linear base metrics outperforms linear base metric when the number of individuals
increase. We suspect that there is less diversity when the
number of individuals is small. No further improvement
is observed when we replace linear base metrics with nonlinear base metrics.
Performance at different recall values Next we compare the performance of the proposed CMC triplet with
CMC top. Both optimization algorithms optimize the recognition rate of person re-id but with different objective criteria. We compare the performance of both algorithms with
the baseline approach, in which we simply set the value of
w to a uniform weight. Since distance functions of different features have different scales, we normalize the distance
between each probe image to all images in the gallery to be
between zero and one. In other words, we set the distance
between the probe image and the nearest gallery image to
be zero and the distance between the probe image and the
furthest gallery image to be one. The matching accuracy is
shown in Table 1. We observe that CMC top achieves the
best recognition rate performance at a small recall value.
Recognition rate (%)
VIPeR Data set
Ours (45.89%)
MidLevel+LADF (43.39%)
MidLevel (30.16%)
SalMatch (29.34%)
LADF (29.11%)
LF (26.31%)
KISSME (24.18%)
PCCA (20.66%)
aPRDC (19.87%)
PRDC (19.60%)
eSDC (19.27%)
eBiCov (16.14%)
SDALF (15.66%)
Recognition rate (%)
CUHK01 Data set
Ours (53.40%)
MidLevel (34.30%)
SalMatch (28.45%)
GenericMetric (20.00%)
ITML (19.67%)
LMNN (15.98%)
eSDC (13.45%)
SDALF (10.33%)
L2−norm (9.90%)
L1−norm (9.84%)
Figure 3: CMC performance for VIPeR and CUHK01 data
sets. The higher the recognition rate, the better the performance. Our approach outperforms all existing person re-id
algorithms.
At a large recall value (rank ≥50), both CMC top and
CMC triplet perform similarly. Interestingly, a simple averaging performs quite well on VIPeR, in which the number
of individuals in the test set is small.
3.2. Comparison with state-of-the-art results
Fig. 3 compares our results with other person re-id algorithms on two major benchmark data sets: VIPeR and
CUHK01. Our approach outperforms all existing person
re-id algorithms.
Next we compare our results with the
best reported results in the literature. The algorithm proposed in achieves state-of-the-art results on iLIDS and
3DPeS data sets (40.3% and 54.2% recognition rate at rank-
1, respectively).
Our approach outperforms on the
iLIDS (50.3%) and achieve a comparable result on 3DPeS
(53.3%). Zhao et al. propose mid-level ﬁlters for person
re-identiﬁcation , which achieve state-of-the-art results
on the VIPeR and CUHK01 data sets (43.39% and 34.30%
recognition rate at rank-1, respectively). Our approach outperforms by achieving a recognition rate of 45.89%
CMC triplet
CMC triplet
CMC triplet
Table 1: Re-id recognition rate (%) at different recall (rank). The best result is shown in boldface. Both CMC top and
CMC triplet achieve similar performance when retrieving ≥50 candidates.
and 53.40% on the VIPeR and CUHK01 data sets, respectively. Table 2 compares our results with other state-of-theart methods on other person re-identiﬁcation data sets.
4. Conclusion
In this paper, we present an effective structured learning
based approach for person re-id by combining multiple lowlevel and high-level visual features into a single framework.
Our approach is practical to real-world applications since
the performance can be concentrated in the range of most
practical importance. Moreover our proposed approach is
ﬂexible and can be applied to any metric learning algorithms. Experimental results demonstrate the effectiveness of
the proposed approach on six major person re-id data sets.