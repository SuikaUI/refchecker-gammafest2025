HAL Id: inria-00548680
 
Submitted on 20 Dec 2010
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of scientific research documents, whether they are published or not.
The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Semantic Hierarchies for Visual Object Recognition
Marcin Marszalek, Cordelia Schmid
To cite this version:
Marcin Marszalek, Cordelia Schmid. Semantic Hierarchies for Visual Object Recognition. CVPR -
IEEE Conference on Computer Vision & Pattern Recognition, Jun 2007, Minneapolis, United States.
pp.1-7, ￿10.1109/CVPR.2007.383272￿. ￿inria-00548680￿
Semantic Hierarchies for Visual Object Recognition
Marcin Marszałek
Cordelia Schmid
INRIA, LEAR - LJK
665 av de l’Europe, 38330 Montbonnot, France
 
 
In this paper we propose to use lexical semantic networks to extend the state-of-the-art object recognition techniques. We use the semantics of image labels to integrate
prior knowledge about inter-class relationships into the visual appearance learning. We show how to build and train
a semantic hierarchy of discriminative classiﬁers and how
to use it to perform object detection. We evaluate how our
approach inﬂuences the classiﬁcation accuracy and speed
on the PASCAL VOC challenge 2006 dataset, a set of challenging real-world images. We also demonstrate additional
features that become available to object recognition due to
the extension with semantic inference tools—we can classify high-level categories, such as animals, and we can train
part detectors, for example a window detector, by pure inference in the semantic network.
1. Introduction
The recognition of object categories in images is one of
the most challenging problems in computer vision, especially when the number of categories is large. Humans are
able to recognize thousands of object types, whereas most
of the existing object recognition systems are trained to recognize only a few. In this paper we address two important
limitations for constructing vision systems which deal with
a large number of categories: a) inter-class similarities and
relationships need to be modeled; b) the complexity in the
number of object categories has to be reduced.
Both points are addressed in the following by incorporating prior knowledge about object identity into the visual recognition system. Humans use this knowledge when
learning the visual appearance of the objects . For instance, when one encounters a new car model, it is not sensible to learn all the appearance details. It is enough to remember that it looks like a car as well as the discriminative
details. This can help to learn the visual appearance of new
object types and speed up the recognition process—both advantages are very desirable in object recognition. Moreover, by generalizing over object instances, humans can say
something meaningful about the appearance of each of the
terms forming a hierarchy like: Maybach →car →motor
vehicle →vehicle →artifact1 →physical object. This allows to learn new concepts by semantic inference and to
give richer answers due to possible reasoning—it is again
useful to bring those features to object recognition. The
above mentioned facts inspired us to collect the semantic
knowledge starting from the semantics encoded in the class
labels and mimic the described behavior in machine vision.
Related work.
Existing object recognition techniques
rarely consider inter-class relationships, i.e., they treat the
classes as completely separate and independent both visually and semantically. For example, the method that consecutively won the detection task of the two recent PASCAL
Visual Object Classes challenges performs multi-class
detection with a set of binary SVM classiﬁers in the oneagainst-rest setting . With the growing number of categories this is not only ineffective, but can also lead to training a “cars vs Maybachs, vehicles, all-the-possible-objects”
classiﬁer, as it ignores the semantic relationships between
classes which exist in the real world. Moreover, cars and
buses are for example more related to each other than dogs
and bicycles, which is also missed.
Knowledge can be modeled by ontologies. For example, lexical semantic networks are used to model human
psycholinguistic knowledge. One of the most popular semantic networks for English language is WordNet . It
groups words into sets of synonyms and records different
semantic relations between them. This allows to infer, for
example, that a car is a wheeled vehicle and that a motorcycle is also a wheeled vehicle, thus both should incorporate a
wheel. Querying the semantic network of WordNet, one can
determine semantic relationships between class labels that
are assigned to the observed visual object instances during
visual object recognition.
Linguistic relations between annotations have been successfully exploited in image retrieval . While we
share the idea of using WordNet to ﬁnd semantic relationships between class labels, we go beyond completing the
annotations or extending the queries. As we show in the
1By the artifact we mean a man-made object.
true positives
false positives
Figure 1. Sample PASCAL VOC’06 images classiﬁed with our semantic hierarchic classiﬁer.
experimental section, incorporating the semantics into the
knowledge representation leads to better recognition accuracy than relying only on straightforward reasoning, as it
also allows to discover additional visual cues that would be
missed otherwise. Semantic hierarchies have proved to be
useful for automatic image annotation . We use them to
combine discriminative classiﬁers and thus choose a different strategy for exploiting their structure. We will demonstrate that this introduces some additional features for object
detection, in particular it allows to give sensible answers in
situations of uncertainty and to learn new classiﬁers using
inference. We also go beyond the ISA relationships taking
advantage of PARTOF and MEMBEROF relationships.
Overview of our method.
The problem of object
recognition is often given in the form of a classiﬁcation
task, an assignment problem in which a semantic term encoding the object identity (a label) has to be assigned to
an observed visual object instance. The classiﬁcation problem can be extended to a detection problem, where instead
of questions like “Is it a car?” we answer questions like
“Is there a car?”. The detection task usually assumes not
only background clutter, but also permits co-occurrence of
multiple object instances, even representing different object
classes. Thus, unlike the classiﬁcation task, it is often multilabel. Note that we further distinguish the detection task
from the localization task, where additionally the locations
of the objects have to be given. In this paper we focus on
the detection task, but our research can be directly applied
to image classiﬁcation and also incorporated into object localization methods.
The combination of bag-of-features image representation with Support Vector Machines (SVMs) resulted in successful object recognition methods .
We take the state-of-the-art image classiﬁcation method of
Zhang et al. to implement the underlying binary classi-
ﬁer for our method. To create the semantic hierarchic classiﬁer for object detection, we query the WordNet with the
class labels and extract the knowledge in the form of a semantic hierarchy. This hierarchy is used for reasoning and
to organize and train the binary SVM detectors. The trained
hierarchic classiﬁer can be used to efﬁciently recognize a
large number of object categories. This is explained in detail in section 2. Section 3 presents the experimental results
on the natural-scene PASCAL VOC’06 dataset (see ﬁg. 1
for sample results obtained with our method). In subsection 3.1 we compare the performance of our classiﬁer to the
state-of-the-art, whereas in subsection 3.2 we discuss the
additional features of our classiﬁer. We conclude the paper
in section 4.
2. The semantic hierarchic classiﬁer
We ﬁrst describe the two key elements of our system—
the underlying binary detector (subsection 2.1) and the extracted semantic graph (subsection 2.2). Then, in subsection 2.3, we explain how to merge those elements to obtain
the semantic hierarchic classiﬁer.
2.1. Detecting the presence of a given class
In the following we describe the object detection framework of Zhang et al. . Given an image, we use two complementary scale-invariant local region detectors to extract
salient image structures: the Harris-Laplace detector 
responds to corner-like regions and the Laplacian detector extracts blob-like regions. To compute appearancebased features of the patches extracted by the detectors, we
use a combination of the SIFT descriptor and the hue
color description . The SIFT descriptor is based on a
grayscale gradient orientation histogram of dimension 128
and the color description is a hue histogram of dimension
36, i.e., the combined descriptor is of dimension 164.
We ﬁrst build a visual vocabulary by clustering the feature vectors from the training images.
Our experiments
have shown that vocabulary construction has little impact
conveyance
wheeled vehicle
motorcycle
motor vehicle
motorcycle
(a) Full hypernymy subgraph
(b) Some shared meronyms
Figure 2. WordNet 2.1 subgraphs for the VOC’06 labels. Intermediate nodes were removed for clarity. Note the obvious bus synset
(concept) misplacement.
on the ﬁnal results. We, therefore, randomly subsample a
set of 50k features and cluster them using k-means with
k = 1000. This results in a vocabulary consisting of 1000
visual words. Given a vocabulary, we can represent each
image in the dataset as a histogram of visual words .
Each feature of image i is matched with the closest word
in the vocabulary based on the Euclidean distance. Each
histogram entry hij ∈Hi is then the proportion of all descriptors in image i matched with vocabulary word j with
respect to the total number of descriptors computed for the
We use SVMs with an extended Gaussian kernel K(Hi, Hj)
A D(Hi,Hj) for classiﬁcation,
where Hi and Hj are image histograms and D(Hi, Hj) =
n=1(hin −hjn)2/(hin + hjn) is the χ2 distance. The
resulting χ2 kernel is a Mercer kernel . The parameter A
is the mean value of the distances between all training images . We combine different detector/descriptor channels by summing the corresponding distances, such that
n Dn where Dn is the χ2 distance for channel n.
2.2. Extracting the semantic graph from WordNet
WordNet 2.1 contains over 80000 noun synonym
sets called synsets. A synset is a set of words that are interchangeable in some context without changing the truth
value of the preposition in which they are embedded. If
a given word has more than one meaning, it may belong
to more than one synset, but for each sense exactly one
synset is deﬁned. Thus, synsets model concepts and are
represented with nodes in the semantic graph.
synsets semantic relationships are deﬁned. Between nouns,
antonymy (opposition in meaning), hypernymy/hyponymy
(superterm/subterm) and holonymy/meronymy (is a part
of/contains) relationships are possible. A synset can also
create a domain (a topical class), to which other synsets
are linked. Semantic relations are represented with directed
edges (links) in the semantic graph. For the detection task,
strong reasoning is possible using hypernymy (“If there is
a car then there is a vehicle”) and meronymy (“If there is
a car then then there is a wheel”). For classiﬁcation task
antonymy could be used (“If it is a man then it is not a
woman”), but this cannot be generalized to the detection
task (as there can be both a man and a woman in one image).
Domains cannot be used for strong reasoning (a presence of
a passenger does not assure the presence of a bus, nor does
the inverse hold)—they could, however, be used for weak
reasoning.
As we focus on detection and need strong reasoning
for training the hierarchic classiﬁer, we ﬁrst extract from
the WordNet the synsets that correspond to the class labels and then follow the hypernymy and meronymy links
to obtain the subgraph.
Some researchers consider only
hypernymy/hyponymy (ISA relationship) for reasoning , but we ﬁnd that incorporating holonymy/meronymy
(PARTOF and
MEMBEROF relationships) permits much
richer reasoning. When extracting the VOC’06 labels and
following only hypernymy links, the resulting subgraph
contains 42 nodes. If we also follow meronymy links, the
graph contains 1452 nodes.
Fig. 2 presents the subgraph of WordNet which corresponds to VOC’06 labels. The complete graph is shown in
the case of the hypernymy relationships (left), except the intermediate nodes which are removed for clarity. We can see
that the WordNet query results in a reasonable semantic hierarchy that mostly reﬂects visual similarities. Interestingly,
the person is not placed under the placental. This is due
to the fact that WordNet reﬂects psycholinguistic and not
strict scientiﬁc knowledge. Following the meronymy links
enriches the graph. Some meronyms shared between labels
are shown in ﬁg. 2 (right). Unfortunately, there are also
some errors and inconsistencies. The unexpected placement
of the bus synset is due to the missing hypernymy link to
motor vehicle. A meronymy link from bus to fender is also
missing. Note that for clarity of presentation we have used
only one relation for each of the graphs shown. When we
follow more types of links, the resulting graph interleaves
all relations considered. Furthermore, the resulting hypernymy graph is a binary tree, but in general more subnodes
and even many supernodes are possible and supported by
our method (we assume a DAG, which holds for WordNet).
Following meronymy links without any limitations unfortunately permits reasoning which is incorrect from the
point of view of visual appearance. For instance, a car contains fuel in its tank, which is an organic material. This,
however, does not imply similarity to living organism like
a cat. To prevent reasoning through unobservable entities
like substances, we implement a pruning process. First, a
base node is found—a “minimal” node from which all the
synsets corresponding to the queried labels can be reached
through hyponymy links. Then, after performing the full
WordNet query, the nodes that cannot be reached from the
base node through the hyponymy links are removed from
the graph. In case of our experiments, pruning reduced the
number of nodes from 1452 to 563 and assured reasonable
inference from the viewpoint of visual appearance.
It is worth noting, that we are guaranteed to ﬁnd a base
node, as any noun ISA entity.
In theory more than one
node could serve as the base node, but in practice usually
only the object2 synset satisﬁes the criterion. Another interesting feature of pruning through the base node is that
it adapts the whole graph to the domain of the queried labels. If the labels would refer to various animals, the animal
synset would be found as the base node and any non-animal
parts and members would be automatically rejected when
2.3. Constructing the semantic hierarchic classiﬁer
In order to explain the construction of the semantic hierarchic classiﬁer, we ﬁrst discuss a model framework in
which a discriminative SVM classiﬁer (cf. subsection 2.1)
is associated with each edge of the obtained semantic graph
(cf. subsection 2.2).
Let us start with looking for images (exemplars) supporting a given concept. Trivially, the exemplars that represent
the concept itself will support it. Due to the strong reasoning, however, each node of the semantic graph is addi-
2The object synset is deﬁned as a visible entity.
tionally supported by the union of the exemplars supporting
the nodes that point to it through hypernymy or meronymy
links, i.e.,
supp(Bi) ∪lbl(A)
where supp(A) is a set of exemplars supporting the A concept, Bi →A is true when Bi links to A through hypernymy
or meronymy and lbl(A) is a set of exemplars labeled with
the A concept. For instance (cf. ﬁg. 2), whenever we observe a car or a motorcycle, we observe at the same time a
wheeled vehicle, a motor vehicle, a means of transportation,
etc. Also, whenever we observe a bicycle or a motorcycle,
we observe a mudguard, a wheel, etc.
We train a given Bi|A classiﬁer associated with the
Bi →A hypernymy or meronymy edge by training a binary
SVM classiﬁer with
P = supp(Bi)
N = supp(A) −supp(Bi)
where P is the set of positive training exemplars and N is
the set of negative ones. Given a test sample and knowing that it represents the A concept, we can then consider
descending through hyponymy and holonymy links to Bi.
We do so, when the detector associated with the Bi →A
link returns a positive answer. For instance, if we know
that a test image satisﬁes the organism concept, we can
check whether it satisﬁes the person concept by running
the person|organism classiﬁer distinguishing between people and other organisms like animals.
The base node is by deﬁnition supported by all the exemplars in the dataset. Making an assumption that the training
set reﬂects the test data, we conclude that on any test image
the base concept is present. Thus, we can start our classiﬁcation at the base node and then descend the semantic hierarchy. For instance, we know that any image of the VOC’06
dataset contains an object. Then for the object node we can
have an artifact detector and an organism detector. For a
detected organism we can launch person and animal detectors. After artifact detection we can look for windows and
means of transportation, and so on.
Please note, that if supp(A) = supp(Bi) then N = ∅.
This is often the case, as there are many intermediate nodes
without their own labels3 which are linked from nodes with
exactly the same support (often there is only one linking
node). Such situation results in a trivial detector that would
for instance claim (cf. ﬁg. 2) that every animal is a placental
because it has never seen an animal that would not be a placental. Still, if the training data represents the test data, this
is a good conclusion. To avoid passing through the trivial
3Actually, in case of most object classiﬁcation datasets available nowadays, only leaf nodes are labeled. Our theory, however, fully supports
situations where classes are overlapping, labeling is incomplete, etc.
detectors, we reconstruct the originally obtained semantic
graph in a manner similar to subset construction . We
deﬁne a conset as a set of nodes (concepts) with the same
support, thus the support of a conset is equal to the support
of any of its elements. Given a conset, we can extend it
through trivial (leading to nodes with the same support) hyponymy and holonymy links. A maximally extended conset
may lead to several nodes with different supports. We group
the connected nodes with the same support into new consets
and train an SVM classiﬁer for each link to a new conset according to eq. (2). By ﬁrst extending the conset consisting
of a base node and then recursively extending the connected
consets, we create a hierarchic classiﬁer.
Given a test sample, we start at the base conset (extended from the base node) and descend to the linked consets when the classiﬁer returns a positive answer. When
reaching a conset, we can label a test image with all the
concepts (synsets) belonging to the conset. Note, however,
that usually the intermediate concepts with only trivial links
in the original semantic graph are probably less interesting
from the point of view of the user than the boundary concepts that link to the concepts with different supports. The
concepts that point through hyponymy or holonymy links
to the concepts belonging to different consets give the most
precise explanation of the sample from the point of view
of a given conset. In parallel, the concepts at the boundary
through hypernymy or meronymy links give the most abstract (still, however, limited to a given conset) explanation
of the sample. Note that given a hierarchy, the boundary
concepts determine the intermediate ones.
It is difﬁcult to give a bound on the complexity of our
semantic hierarchic classiﬁer. The total number of binary
classiﬁers evaluated depends not only on the structure of
the hierarchy which may vary signiﬁcantly from one set of
labels to another, but it also depends on the difﬁculty of the
test images which inﬂuence the number of paths considered
simultaneously. We can estimate the number of binary classiﬁers evaluated for a test sample with:
where n is the number of classes, c is the number of binary
classiﬁers evaluated at a node, a is the subproblem selection
factor (c/a deﬁnes the number of subproblems that have to
be solved) and b is the problem reduction factor (n/b de-
ﬁnes the size of the subproblem). b and c depend on the
semantic hierarchy structure, a depends on the complexity
of the test image. Thus, b and c parameters vary from node
to node and the a parameter depends on the test sample,
but we can average them for a given dataset. In the case
of the VOC’06 dataset, there were on average c = 2.85
subproblems considered (binary classiﬁers evaluated) per
node. Among those, one of every a = 1.94 subproblems
were descended while the size of the problem was reduced
b = 1.82 times. According to the master theorem , this
allows us to estimate the complexity of our classiﬁer (for
similar datasets) as:
nlogb(c/a)
when logb(c/a) > 0 ⇔c > a which is true. This is signiﬁcantly better than Θ(n) required in a one-against-rest setup
with n classiﬁers.
3. Experimental results
We evaluate our semantic hierarchic classiﬁer on the
PASCAL VOC’06 dataset . The dataset contains 1277
training images and 1341 validation images which we used
for testing. Each image contains one or more objects and
each object is annotated as belonging to one of the 10 predeﬁned classes (bicycle, bus, car, cat, cow, dog, horse, motorcycle, person, sheep). Sample images are shown in ﬁg. 1.
The detection task requires to automatically determine objects classes which are present in a test image. We train our
system providing a list of object classes which are present
in each image without indicating their locations.
The results of the different methods are evaluated with
the Equal Error Rates (EERs)4 of the Receiver Operating
Characteristic (ROC) curves on a per-class basis . To
compute the ROC curve our classiﬁer has to return conﬁdence values. In the case of the binary SVM classiﬁer, we
use the absolute value of the decision function. For hierarchic classiﬁers we combine the decision functions of the
underlying binary classiﬁers, i.e., for each concept c we de-
ﬁne a decision function hc(x):
hc(x) = max
P ∈P(s,v) min
where v is a conset (classiﬁer node) containing the concept
c, P(s, v) is the set of all possible paths from the base conset (starting node) s to conset v, P is an element of this set,
e is an edge on the path P and ge(x) is the decision function of the classiﬁer associated with the edge e. In other
words, for a given class c and sample x, the maximal decision value over all possible classiﬁcation paths is returned,
whereas for a given path the minimal decision value over its
edges is chosen.
Table 1 compares the performance of our semantic hierarchic (SH) classiﬁer with the performance of a standard one-against-rest (OAR) classiﬁer and a classiﬁer based
on an automatically constructed visual hierarchy (AVH).
AVH is a binary tree obtained through iterative merging
of the classes with the smallest average χ2 distance between their exemplars, i.e., presumably the most visually
4Precisely, the point where the recall is equal to the precision is called
break even point. For consistency with the literature we denote it as EER.
conveyance
Table 1. Comparison of the EERs achieved by the different classiﬁers. Sections A and B evaluate the performance on the PASCAL VOC
challenge 2006. Section C tests the generalization ability of the classiﬁers using an external set of images.
similar ones. In the case of both baseline classiﬁers, OAR
and AVH, the same underlying binary classiﬁers were used
as in our SH classiﬁers.
The proposed semantic hierarchic classiﬁer was evaluated in a simple form (SSH),
where only hypernymy/hyponymy relationships were used,
as well as in an extended form (ESH) that also includes
meronymy/holonymy.
3.1. Comparison with existing solutions
Section A of table 1 shows the results for the VOC’06
task of detecting ten object categories. The average over
all classes and individual results for classes for which at
least 1.5% difference between OAR and ESH classiﬁers
was observed are given. Our approach leads on average
to a slightly better performance than the methods that do
not use the semantics. This is an encouraging result, as this
means improved classiﬁer complexity and additional features (cf. section 3.2) without loss of accuracy. Note that the
visual hierarchy usually shows worse performance than the
semantic one. This means that apparent visual similarities
between images may not always generalize well to object
classes and using external semantic knowledge can help to
better discover the visual properties of object classes. Fig. 1
presents some true positives and false positives. We can see
that our classiﬁer performs well even for images with unusual object views and that it makes mistakes in situations
where a lot of context information is necessary to return the
correct answer.
It is worth adding, that our semantic hierarchic classiﬁer performs comparably to the state-of-the-art. In the
VOC’06 challenge , the average EER of the winning
method QMUL LSPCH was 86.4%. Our method achieves
an average of 82.5% with half of the training images (we
have used the validation set for testing) and including the
images marked as “difﬁcult”, skipped for the evaluation of
the submissions to the VOC’06 challenge.
Furthermore, we anticipate that the gain should further
increase for a large number of categories, as the inter-class
similarities and overlaps will cause more and more confusion of classiﬁers devoid of semantics.
3.2. Additional features of our SH classiﬁer
Adding semantic reasoning to a visual object recognition
system opens several new possibilities. Firstly, it allows to
complete the labels in the training set and permits reasoning
to enrich the answers. For instance, the images marked only
as Maybach could be used for training a car detector and
after detecting a car in a test image the image can also be
labeled as motor vehicle. Our semantic hierarchic classiﬁer
performs both types of reasoning implicitly and thus fully
supports incomplete labeling and overlapping classes (like
cars and vehicles). Secondly, the semantic hierarchic structure of our classiﬁer provides sensible answers in uncertain
situations. For instance, even when the classiﬁer does not
know whether there is a cat or a horse in the image, it may
still be certain that there is a living organism and thus provide useful information.
Section B of table 1 compares the results of detecting the
high-level concepts organisms and conveyance for training
performed with the original labels. OAR and AVH methods are not capable of reasoning, so a simple form of it (“If
there is a cat then there is an organism”, etc.) was artiﬁcially added after the object detection phase. Our hierarchic
classiﬁer directly labels the test images with those concepts
and the achieved results are signiﬁcantly better. The fact
that AVH outperforms OAR in the case of the organisms
suggests that the classiﬁers get easily confused by different
creature types. The observed 11.5% gain when comparing
ESH to OAR shows, however, that our classiﬁer goes beyond the aforementioned reasoning and is able to successfully detect a living creature without being explicitly aware
of any of the creatures known. We conclude that our classi-
ﬁer is able not only to perform reasoning (none of the training images were marked with the tested concepts), but also
to better organize the collected knowledge about the visual
appearance of the objects.
In the previous experiment all the living creatures in the
test set were corresponding to the creatures from the training set. To test the true generalization ability of our classi-
ﬁer we have collected 120 vehicle window images by querying Google Image Search with “vehicle window”, “wind-
(a) true positives
(b) false positives
Figure 3. Sample vehicle window and machine images classiﬁed by our semantic hierarchic classiﬁer as containing a window. Training
was performed on VOC’06 images with the original annotations.
screen” and “windshield” queries and manually validating
the returned images. For the negative set we have collected
120 images retrieved with the “machine” query. Section C
of table 1 shows the results for these test images; training
was performed on the VOC’06 images with the original labels. For the OAR and AVH methods post-classiﬁcation
reasoning was performed (“if there is a car or bus than there
is a window”). The SSH classiﬁer could not perform the
task as it was trained without meronymy/holonymy relationships. Our ESH classiﬁer shows signiﬁcantly better performance than the methods only extended with reasoning.
This conﬁrms that the classiﬁer was able to generalize over
the windows of cars and buses. Fig. 3 illustrates examples
for detecting individual windscreens and windows of different vehicles. Even some false positives on window-like
structures were observable, see ﬁg. 3. We conclude, that our
classiﬁer is able to learn the generalized visual appearance
of unseen object classes through inference.
4. Summary
In this paper we have proposed a semantic hierarchic
classiﬁer that uses the semantics of image labels to extract
knowledge about the inter-class relationships and that integrates it into the visual appearance learning procedure. This
allows to reduce the classiﬁer complexity in the number of
classes and, as was shown in the experimental section, helps
to learn the visual similarities. We have also demonstrated
additional features of our classiﬁer like returning valuable
information in situation of uncertainty and learning new
classiﬁers through inference. The classiﬁer’s ability to support overlapping classes and provide a complexity that is
sublinear in the number of classes makes it suitable for object recognition tasks that require recognizing a large number of categories. Future research could focus on adding
support for weak reasoning.
Acknowledgments
M. Marszałek is supported by a grant from the European Community under the Marie-Curie project VISITOR. This work was
supported by the European funded research project CLASS and
the EU network PASCAL.