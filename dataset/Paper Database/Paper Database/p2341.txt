The Roadmap to 6G – AI Empowered
Wireless Networks
Khaled B. Letaief, Wei Chen, Yuanming Shi, Jun Zhang, and Ying-Jun Angela Zhang
Abstract—The recent upsurge of diversiﬁed mobile applications, especially those supported by Artiﬁcial Intelligence (AI), is
spurring heated discussions on the future evolution of wireless
communications. While 5G is being deployed around the world,
efforts from industry and academia have started to look beyond
5G and conceptualize 6G. We envision 6G to undergo an unprecedented transformation that will make it substantially different
from the previous generations of wireless cellular systems. In
particular, 6G will go beyond mobile Internet and will be required
to support ubiquitous AI services from the core to the end
devices of the network. Meanwhile, AI will play a critical role
in designing and optimizing 6G architectures, protocols, and
operations. In this article, we discuss potential technologies for
6G to enable mobile AI applications, as well as AI-enabled
methodologies for 6G network design and optimization. Key
trends in the evolution to 6G will also be discussed.
I. INTRODUCTION
The wireless communications industry is one of the few
industry sectors that have kept a fast growing trend with
creative features for a number of decades. The current 4G LTE
networks have led to the thriving of mobile Internet, enabling
various innovative applications, such as mobile shopping and
payment, smart home/city, mobile gaming, etc. The great success of mobile Internet has in turn been a driving force behind
the evolution of wireless technologies. The upcoming 5G network will support a wide range of services, including eMBB
(enhanced mobile broadband), uRLLC (ultra-reliable and lowlatency communications), and mMTC (massive machine-type
communications) , . According to a Cisco forecast,
major operators will embark on a signiﬁcant investment in
5G networks during the next one or two years.
While 5G is still at an initial stage, to maintain the sustainability and competitiveness of wireless communication
systems, it is time for both the industry and academia to
think about what 6G will be. There are already initiatives
describing the roadmap towards 6G , , along with
the emerging trends and requirements, as well as various
enabling techniques and architectures, e.g., Terahertz band
communications .
In contrast to previous generations, 6G will be transformative and will revolutionize the wireless evolution from
Khaled B. Letaief is with Hong Kong University of Science and Technology; Wei Chen is with Tsinghua University; Yuanming Shi is with
ShanghaiTech University; Jun Zhang is with The Hong Kong Polytechnic
University; Ying-Jun Angela Zhang is with The Chinese University of Hong
This work has been submitted to the IEEE for possible publication.
Copyright may be transferred without notice, after which this version may
no longer be accessible.
“connected things” to “connected intelligence” with more
stringent requirements speciﬁed as follows.
• Very high data rates, up to 1 Tbps;
• Very high energy efﬁciency, with the ability to support
battery-free IoT devices;
• Trusted global connectivity;
• Massive low-latency control (less than 1 msec end-to-end
• Very broad frequency bands (e.g., 73GHz-140GHz and
1THz-3THz);
• Ubiquitous always-on broadband global network coverage by integrating terrestrial wireless with satellite
• Connected intelligence with machine learning capability
and AI networking hierarchy.
6G will also require the support of three new service types
beyond the eMBB, uRLLC, and mMTC services supported by
5G, as described below.
Computation Oriented Communications (COC): New
smart devices call for distributed and in-network computation
to enable the key functionalities of AI-empowered 6G, such as
federated learning and edge intelligence. Instead of targeting
classical quality of service (QoS) provisioning, CoC will
ﬂexibly choose an operating point in the rate-latency-reliability
space depending on the availability of various communications
resources to achieve a certain computational accuracy.
Contextually Agile eMBB Communications (CAeC): The
provision of 6G eMBB services is expected to be more agile
and adaptive to the network context, including communication
network context such as link congestion and network topology;
physical environment context such as surrounding location and
mobility; and social network context such as social neighborhood and sentiments.
Event Deﬁned uRLLC (EDuRLLC): In contrast to the
5G uRLLC application scenario (e.g., virtual reality and industrial automation) where redundant resources are in place
to offset many uncertainties, 6G will need to support uRLLC
in extreme or emergency events with spatially and temporally
changing device densities, trafﬁc patterns, and spectrum and
infrastructure availability.
Inspired by these trends, in this article, we attempt to
conceptualize 6G as an intelligent information system that is
both driven by and a driver of the modern AI technologies. A
roadmap for 6G is depicted in Fig. 1, which is plotted based
on the strategic plans of various standard bodies and is also
projected based on the 5G status. Key performance indicators
(KPIs) and service types are also illustrated. Meanwhile, a
potential network architecture for 6G is shown in Fig. 2.
 
Rquirement
Technology
5G Evolution(Beyond 5G)
6G Specifications
6G Product
LTE-Advanced
IMT New spectrum, Vision
Requirement
Evaluation
6G Requirements
6G Evaluation
Vision/KPI/Scope/Timeline
Collaborati
ve Research
FP9: Horizon Europe
Beyond 5G: ICT 20
5G Key technology Full 6G PoC, 5G services
HW,SW functions demos
6G testbeds
Research on spectrum
below 6GHz
Low/High-frequency candidate bands
Evaluations
Key technologies
System design
Enhanced technologies
5G Technology R&D Trial
5G Product R&D
Deployment 
Intelligence
Fig. 1. The roadmap of 6G.
We envision that AI will greatly enhance the situational
awareness of the network operators, and enable close-loop
optimization to support the new service types as mentioned
above. As such, 6G will unleash the full potential of mobile
communications, computing, and control in a host of exciting
applications, including smart cities, connected infrastructure,
wearable computers, autonomous driving, UAVs , seamless
virtual and augmented reality, Internet of Things, space-airground integrated networks , and a lot more.
This article is a humble attempt to provide a forwardlooking research roadmap for 6G. The rest of the article is
organized as follows. In Section II, a vision on 6G architecture will be presented. In Section III, we will show how
6G leverages the advent of AI to enable its key features.
Various AI applications of 6G will be given in Section IV. To
meet the expected stringent requirements of such applications,
hardware-aware communications will be embraced in 6G, as
discussed in Section V. Finally, Section VI concludes the
II. THE ARCHITECTURE OF 6G NETWORKS
In this section, we introduce a potential architecture for
6G as shown in Fig. 2, in which network intelligentization,
subnetwork evolution, and intelligent radio are embraced.
A. From Network Softwarization to Network Intelligentization
We envision that 6G will take network softwarization to a
new level, namely, towards network intelligentization. In 5G,
the “non-radio” aspect has become more and more important,
and has been the key driver behind the recent efforts on “softwarization”. More speciﬁcally, two key 5G technologies are
Software-Deﬁned Networking (SDN) and Network Functions
Virtualization (NFV), which have moved modern communications networks towards software-based virtual networks. They
also enable network slicing, which can provide a powerful
virtualization capability to allow multiple virtual networks to
be created atop a shared physical infrastructure.
Nevertheless, as the network is becoming more complex
and more heterogeneous, softwarization is not going to be
sufﬁcient for beyond 5G networks. In particular, to support
AI-based applications, the network entities have to support diverse capabilities, including communications, content caching,
computing, and even wireless power transfer. Furthermore,
6G will embrace new radio access interfaces such as THz
communications and intelligent surfaces. It will also need to
support more advanced Internet of Things (IoT) functionalities
including sensing, data collection, analytics, and storage. All
of the aforementioned challenges call for an architecture that is
ﬂexible, adaptive, and more importantly, intelligent. Existing
technologies, such as SDN, NFV, and network slicing will
need to be further improved to meet these challenges. By
enabling fast learning and adaptation, AI-based methods will
render network slicing a lot more versatile in 6G systems.
The design of the 6G architecture shall follow an “AI native”
approach where intelligentization will allow the network to
be smart, agile, and able to learn and adapt itself according
to the changing network dynamics. It will evolve into a
“network of subnetworks,” allowing more efﬁcient and ﬂexible
upgrades, and a new framework based on intelligent radio and
algorithm-hardware separation to cope with the heterogeneous
and upgradable hardware capabilities. Both of these two
features will exploit AI techniques, as further illustrated in
the following subsections.
B. A Network of Subnetworks – Local vs Global Evolution
Given its expected ultra-high heterogeneity, one key feature
of 6G will be its capability to exploit a ﬂexible subnetworkwide evolution to effectively adapt to the local environments
and user demands, thereby resulting in a “network of subnetworks”. Particularly, local subnetworks in 6G may evolve
individually to upgrade themselves. The local evolution may
happen in a few neighboring cells or even in a single cell
in order to ﬂexibly apply cutting-edge developments on new
waveforms, coding, and multi-access protocols in subnetworks
without extensive time-consuming tests. Since there is no
need to rebuild the whole system, the evolution cost can be
substantially reduced. To achieve this goal, we need to address
the following three challenges:
1) Each subnetwork should collect and analyze its local
data, which may include wireless environments, user
requests, mobility patterns, etc. and then exploit AI
methods to upgrade itself locally and dynamically.
2) When the local PHY or MAC protocols are changed, the
inter-subnetwork interaction is expected to maintain new
Modulation
Demodulation
y = hx + z
Resource Pool
y = hx + z
y = hx + z
Protocol Cooperation
Interference
AI Central
Control Node
Algorithm Domain
Preference
Supervised
Unsupervised
Semi-supervised
Reinforcement
Reinforcement
AI-OS Layer
Description
Algorithm-Hardware
Separation Architecture
Resource Block (RB) 2
Resource Block (RB) N
Resource Block (RB) 1
Distributed
Distributed
Distributed
Environment
reward, utility,
throughput
resource management,
coding, ...
Resource availability
Radio condition
Traffic characteristics
Fig. 2. The architecture of 6G.
inter-subnetwork coordination. One possible solution is
to adopt game and learning approaches in 6G, which can
assure the convergence of the subnetworks upgrades.
3) The local evolution of 6G requires a relatively stable
control plane to support the evolution in the “network
of subnetworks” level. One possible solution relies on
the “learning from scratch” method developed in Alpha
Zero . The control plane of 6G should evaluate each
upgrade of subnetworks, and then implement a networklevel learning process to identify the best strategy for
each subnetwork, accounting for its local environments
and user behaviors.
In summary, the local evolution of subnetworks substantially
speeds up the deployment of novel physical and MAC layer
protocols, and can better adapt to the spatially and temporally varying radio environments and user demands. With the
subnetwork-wide upgrades, we envision a smooth evolution
from 5G to 6G and beyond.
C. Towards Intelligent Radio (IR)
The emerging hardware revolutions, e.g., in the RF and
circuit systems, will drive 6G to track and fully exploit the fast
upgrade of the device-level and base-station level hardware.
We envision that an algorithm-hardware separation architecture will become essential in 6G. Particularly, a transceiver
algorithm will be able to automatically estimate the capability
of the transceiver hardware over which the protocol runs, then
conﬁgures itself based on the hardware capability.
This is in contrast to the systems from 1G to 5G where
the devices and transceiver algorithms are jointly designed.
Conventionally, the hardware capabilities, e.g., the number
of antennas, RF chains, and phase shifters, the resolution
and sampling rates of ADCs, as well as, the computation
abilities of decoders, etc., have remained quasi-static in the
previous cellular generations. However, the recent state-ofthe-art circuits and antennas advances are speeding up and
signiﬁcantly improving the hardware capabilities, which make
it possible for the 6G BS and handset to be diversiﬁed and
upgradable within 6G. In other words, 6G will not be operating
under the conventional joint design, which fails in allowing
agile adaptation to a diversiﬁed and upgradable hardware.
To overcome the shortcoming of joint hardware-algorithm
design and reap the beneﬁt of the algorithm-hardware separation architecture, we present an operating system (OS) between
the device hardware and the transceiver algorithms, where
we can regard a transceiver algorithm as a software running
over the OS. The OS is capable of not only estimating the
capabilities of local RF chains, phase shifters, ADCs, and
antennas, etc., but also measuring their analog parameters
automatically. Based on the hardware information and AI
methods, the OS will then be capable of conﬁguring its own
transceiver algorithms via an interface language. We shall refer
to this framework as intelligent radio (IR). In contrast to the
learning based intelligent PHY layer surveyed in subsection
III-C, IR is a much broader concept relying on the algorithmhardware separation architecture. In Table I, we compare key
features of IR, software-deﬁned radio (SDR), and cognitive
radio. Owing to Mitola’s milestone works , IR can be
regarded as a further extension, in which the cutting edge
AI techniques are deeply involved. The conventional modulation/coding modules are replaced by deep neural networks,
which can in an intelligent way adapt to the environment and
hardware. IR also takes into account the protocols over layer 3,
which are self-upgradable to support various AI applications.
By exploiting IR, 6G is expected to evaluate the contributions of various hardware components and identify their
bottlenecks. In return, the bottleneck analysis helps the device manufactures in optimizing the budget allocation of the
hardware costs. As a result, the application of IR will help 6G
enjoy a much reduced implementation time and a signiﬁcant
reduction in the cost of new algorithms and hardware in
both the PHY and MAC layers, thereby speeding up its own
THE COMPARISON OF SOFTWARE DEFINED RADIO (SDR), COGNITIVE RADIO (CR), AND INTELLIGENT RADIO (IR).
Frequency Band
Adapt to environment
Adapt to environment and hardware
Spectrum Sharing
Opportunistic
AI-enabled
Hardware Capability
Pre-claimed
Pre-claimed
Online estimated
Hardware Upgradability
PHY Tx/Rx Module
Modulation/coding/detection/estimation
Modulation/coding/detection/estimation
Deep neural networks
Multiple Access
Predetermined
Sensing Based
Distributed ML based
Protocols over Layer 3
Self-upgradable
Main Steam Apps
Voice, Data
Multimedia, Data
AI, In-network Computation
evolution.
III. AI-ENABLED TECHNOLOGIES FOR 6G
The unprecedented transformation of wireless networks will
make 6G substantially different from the previous generations,
as it will be characterized by a high degree of heterogeneity in
multiple aspects, such as network infrastructures, radio access
technologies, RF devices, computing and storage resources,
application types, etc. In addition, the wide range of new applications will mandate an intelligent use of communications,
computing, control, and storage resources from the network
edge to the core, and across multiple radio technologies
and network platforms. Last but not least, the volume and
variety of data generated in wireless networks are growing
signiﬁcantly. This opens up great opportunities for data-driven
network planning and operation to achieve real-time additivity
to dynamic network environments.
In this section, we advocate AI as an indispensable tool to
facilitate intelligent learning, reasoning, and decision making
in 6G wireless networks.
A. Big Data Analytics for 6G
The ﬁrst natural application of AI is big data analytics.
There are four types of analytics that can be applied to 6G
systems, namely descriptive analytics, diagnostic analytics,
predictive analytics, and prescriptive analytics. Descriptive
analytics mine historical data to get insights on network performance, trafﬁc proﬁle, channel conditions, user perspectives,
and etc.. It greatly enhances the situational awareness of
network operators and service providers. Diagnostic analytics
enable autonomous detection of network faults and service
impairments, identify the root causes of network anomalies,
and ultimately improve the reliability and security of 6G
wireless systems. Predictive analytics use data to predict future
events such as trafﬁc patterns, user locations, user behavior
and preference, content popularity, and resource availability. Prescriptive analytics take advantage of the predictions
to suggest decision options for resource allocation, network
slicing and virtualization, cache placement, edge computing,
autonomous driving, etc. For example, by predicting, anticipating, and inferring future user demands through big data
analytics, the notion of proactive caching has recently emerged
to signiﬁcantly relieve peak trafﬁc loads from the wireless core
B. AI-enabled Closed-loop Optimization
Traditional methodologies for wireless network optimization may not be applicable in 6G systems due to the following
reasons. First, 6G wireless systems will be extremely dynamic
and complex due to the scale, density, and heterogeneity of
the network. Modeling such systems is very hard, if not
impossible. As such, traditional optimization approaches that
rely heavily on mathematically convenient models will no
longer be adequate. Hence, the second major application of
AI in 6G wireless systems is automated and closed-loop
optimization. Problems in wireless networks are traditionally
solved by applying sets of rules derived from system analysis
with prior domain knowledge and experience. For example,
in traditional network optimization problems, the objective
functions are assumed to be available in nice algebraic forms,
allowing an optimizer to evaluate a solution by simple calculation. However, in the complex 6G network environment,
the mapping between a decision and its effect on the physical
system is cost prohibitive to deﬁne and may not be analytically available. Recent advances in AI technologies, such
as reinforcement learning and deep reinforcement learning
(DRL), can establish a feedback loop between the decision
maker and the physical system, so that the decision maker can
iteratively reﬁne its action based on the system’s feedback to
reach optimality eventually. For example, recently applied
DRL to address several emerging issues in communication and
networking, including adaptive modulation, wireless caching,
data ofﬂoading, and so on, as shown in Fig. 2.
C. Intelligent Wireless Communication
AI technologies will play a critical role in end-to-end
optimization of the full chain of the physical layer signal
processing, from the transmitter to the receiver. The end-toend communication system suffers from a wide variety of
impairments, including hardware impairments such as ampliﬁer distortion, quadrature imbalance, local oscillator and
clock harmonic leakage, and the channel impairments such as
fading and interference. Meanwhile, the number of factors and
parameters to be controlled will continue to increase. With
this level of complexity, end-to-end optimization has never
been practical in today’s wireless systems. Instead, existing
approaches divide the full chain into multiple independent
blocks, each with a simpliﬁed model that does not accurately
or holistically capture the features of real-world systems.
AI technologies open up the possibilities to learn the best
way to communicate over combinations of hardware and chan-
nel effects. We envision an “intelligent PHY layer” paradigm
in 6G, where the end-to-end system is capable of self learning
and self optimization by combining advanced sensing and
data collection, AI technologies, and domain-speciﬁc signal
processing approaches.
IV. 6G FOR AI APPLICATIONS
With the ubiquitousness of smart mobile gadgets and the
revival of artiﬁcial intelligence, various AI-empowered mobile
applications are emerging. In this section, we present how 6G
will handle mobile AI applications.
A. Trends and Challenges
AI has achieved remarkable successes in many application
domains, e.g., computer vision, natural language processing,
and autonomous driving. AI tasks are computationally intensive and mostly trained, developed, and deployed at data
centers with custom-designed servers. Given the fast growth
of smart mobile gadgets and Internet of Things devices, it is
expected that a large number of intelligent applications will
be deployed at the edge of wireless networks in the near
future. As such, the 6G wireless network will be designed
to leverage advanced wireless communications and mobile
computing technologies to support AI-enabled applications
at various edge mobile devices with limited communication,
computation, hardware and energy resources. Notably, the
capacity and latency of wireless links are the key bottlenecks
of mobile AI applications due to three reasons. First, to protect
privacy, some AI applications require data to be kept at the
mobile devices instead of being uploaded to the cloud during
the model training process. This has stimulated the recent
research interest for on-device distributed training, i.e., federated learning , where frequent communications among the
computing devices are needed for model updates. Secondly, to
overcome the resource limitation of edge devices, on-device
distributed computing provides new opportunities by pooling
the computation and storage resources of multiple mobile
devices. In this case, data shufﬂing is a key component for
exchanging the computed intermediate values among mobile
devices to enable on-device distributed inference . Last
but not least, the heterogeneous mixture of the cloud, edge
and end computing devices provides a dispersed computing
environment for both training and inference of deep neural
To enable ubiquitous and diversiﬁed mobile AI services,
6G is expected to provide ﬂexible platforms for developing advanced communication and computation technologies.
Moreover, it will provide a holistic way to optimize across
the communication, computation, and storage resources to
span the functionalities of modern AI across the end-devices,
network edges, and cloud data centers.
B. Communication for Distributed Machine Learning
Large-scale distributed machine learning is needed for mobile AI applications in 6G, for which communication becomes
the key bottleneck for scaling up distributed training and
global model
local model
Fig. 3. Over-the-air computation for on-device distributed federated learning.
learning tasks
Fig. 4. On-device distributed inference via wireless MapReduce.
distributed inference over the cloud, network edge, and enddevices.
Communication-Efﬁcient
Distributed
growing computation and storage power of devices provides
opportunities for on-device distributed training by processing
data locally. However, communicating over the volatile wireless channel becomes the signiﬁcant bottleneck for distributed
training on mobile devices. To strengthen data privacy and
security, federated learning allows the training data to
be kept at each device, thereby learning a shared global
model from distributed mobile devices. However, the limited
bandwidth becomes the main bottleneck for global model
aggregation from locally updated models computed at each
mobile device. The over-the-air computation can be exploited
to enable low-latency global model aggregation via exploiting the superposition property of a wireless multiple-access
channel, as shown in Fig. 3.
Communication-Efﬁcient Distributed Inference: In 6G,
intelligent services will span from cloud data centers to enddevices and IoT devices, e.g., self-driving cars, drones, and
auto-robots. As such, it is of prime importance to design ultralow latency, ultra-low power and low-cost inference processes.
To overcome stringent computation, bandwidth, storage, power
Fig. 5. A hardware-efﬁcient hybrid beamforming structure with ﬁxed phase
shifters. The base station and user are equipped with 144 and 16 antennas,
respectively, and 4 RF chains. The fully- and partially-connected structures
require 576 and 144 adaptive phase shifters, respectively, while the new
structure only requires 30 ﬁxed phase shifters in the ﬁrst simulation. The
second simulation shows that 15 phase shifters are already sufﬁcient for the
new structure.
and privacy constraints on individual devices, increasing research interests are moving towards leveraging the dispersed
computing resources across the cloud, network edge and enddevices of 6G networks through the lens of mobile edge
computing . For example, for a deep neural network, the
initial features can be extracted on the end devices, which are
then sent to the edge and cloud computing devices for further
processing. However, with the heterogeneity in the computing
capabilities and communication bandwidths among the computing devices, it becomes extremely challenging to allocate
the operations of the neural networks to the computing devices
so that the latency and energy are optimized. Fig. 4 demonstrates the on-device distributed inference process, where each
device locally computes the intermediate values based on the
map function using the local data. The intermediate values are
further shufﬂed across the devices assisted by a central radio
access points. The inference process will be accomplished
by collecting all the required intermediate values to construct
the prediction results. A joint optimization of the uplink and
downlink communication strategy was thus developed in 
for shufﬂing the locally computed intermediate values across
mobile devices.
V. HARDWARE-AWARE COMMUNICATIONS FOR 6G
As new radio access technologies emerge, and IoT devices become more pervasive, hardware constraints will play
critical roles when designing 6G networks. On one hand,
as radio communication is moving towards millimeter-wave
bands, and possibly Terahertz bands, the high cost and power
consumption of hardware components will signiﬁcantly affect
the transceiver architecture and algorithm design. On the other
hand, IoT devices have limited storage, energy source, and ondevice computing power. Such resource-constrained platforms
call for a holistic design of communication, sensing, and
inference. In this section, we present a new design paradigm
for 6G, namely hardware-aware communications, and discuss three promising new design principles. For performancecritical scenarios, the objective is to develop hardware-efﬁcient
transceivers that are also algorithm friendly, which calls for
hardware-algorithm co-design. For IoT-like application scenarios, application-aware communications will be essential.
Meanwhile, intelligent communications is needed to effectively adapt to heterogeneous hardware constraints.
A. Hardware-Algorithm Co-design
The desire to communicate at ever higher data rates will
never stop. To reach Terabytes per second data rates, it is
inevitable to operate at higher and higher frequency bands. The
major obstacle is from the hardware perspective. Very large
scale antenna arrays are needed to overcome the increased
pathloss and other propagation phenomena, which will bring
a large number of hardware components, including signal
mixers, ADCs/DACs, power ampliﬁers, etc. The high cost and
power consumption of these components at the mmWave and
THz band make it difﬁcult to adopt conventional transceiver
structures, which in turn will affect the design of signal
processing algorithms. To effectively design such complex
systems, collaboration among the hardware and algorithm
domains will be needed, i.e., hardware-algorithm co-design
should be advocated. The target is to develop hardwareefﬁcient transceiver structures that are also algorithm friendly:
such structures should employ few of the costly hardware
components, and they should be able to leverage existing
signal processing algorithms.
Case Study: Consider mmWave hybrid beamforming as
an example, which is a cost-effective approach for providing
effective beamforming gains. It requires a small number of
RF chains, and thus can signiﬁcantly reduce hardware cost
and power consumption. However, a large number of phase
shifters are still needed for existing hardware structure. Phase
shifters at mmWave bands are still very expensive, and thus
their number needs to be reduced. A new hardware-efﬁcient
hybrid structure was recently proposed in , as shown in
Fig. 5. It only requires a small number of phase shifters,
each with a ﬁxed phase. As such, hardware modiﬁcation
is only in the analog network, basic design principles for
hybrid beamforming can still be applied. As shown in Fig.
5, this new structure can approach the performance of the
fully digital beamforming, with much fewer phase shifters than
other hybrid beamforming structures.
B. Application-Aware Communications for IoT Devices
Thanks to the recent development of IoT technologies,
intelligent mobile applications will thrive, and many of them
are powered by specialized low-cost, low-power devices.
Such devices will handle basic sensing and simple on-device
processing tasks, while relying on proximate edge servers
or remote cloud data centers for computation-intensive processing. Thus, effective communications between devices and
servers will be essential. Rather than serving as a bit pipe
for traditional data services and focusing on maximizing data
rates, wireless communications for IoT applications should directly serve speciﬁc applications. An integrated consideration
of communication, sensing, and inference will be critical to
overcome the hardware limitations, as illustrated below.
Joint sampling, communication, and inference: IoT devices
have serious challenges. These include, 1) limited computing
power to process the collected data; 2) their limited energy
will constrain their ability to collect data samples; 3) they do
not have enough storage to store all the data; and 4) they
cannot afford to always send data to the server. By jointly
optimizing sampling, communication, and local processing,
and accounting for the state of local processors, storage,
and channel states, the overall performance can be improved.
The integration with edge computing will play an important
role, and joint edge-device processing techniques should be
developed.
C. Intelligent Communications for Heterogeneous Hardware
Constraints
Wireless networks are getting more and more heterogeneous, with various types of access points and mobile terminals, which differ signiﬁcantly in hardware settings. Such
heterogeneity has started from 4G LTE networks, and with the
deployment of advanced techniques such as massive MIMO,
the situation will further develop through 5G, and into 6G.
This trend will complicate the communication protocol and algorithm design, which may subsequently degrade the communication efﬁciency. Recently, adopting machine learning techniques to develop communication systems has demonstrated
its effectiveness, and such approaches have the potential of
leading to general purpose intelligent communications that
can adapt to heterogeneous hardware constraints. A particular
approach is illustrated as follows.
Transfer learning for different hardware constraints: One
complication brought by hardware heterogeneity is the excessive effort to redesign the system for different hardware
settings. For example, different transceiver architectures have
been proposed for mmWave systems, including analog beamforming, hybrid beamforming, and 1-bit digital beamforming.
The conventional approach relies on hand-crafted design for
each of them, which is very inefﬁcient. These different types of
transceivers will face the same problems as those in mmWave
channels, and thus an algorithm well designed for one may
also shed light on the design for another. Transfer learning is
a promising technique that can help to transfer the design of
one architecture to others.
VI. CONCLUSIONS
This article has presented an AI empowered architecture,
as well as AI-centric communication techniques, for 6G networks. New features of the 6G evolution were identiﬁed, and
enabling technologies were discussed. While a partial picture
was presented, we hope our discussion will spur interests
and further investigations on the future evolution of cellular