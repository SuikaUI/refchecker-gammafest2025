Received June 23, 2020, accepted July 6, 2020, date of publication July 21, 2020, date of current version July 31, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3010896
6G and Beyond: The Future of Wireless
Communications Systems
IAN F. AKYILDIZ
, (Fellow, IEEE), AHAN KAK
, AND SHUAI NIE
Broadband Wireless Networking Laboratory, School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332, USA
Corresponding author: Ahan Kak ( )
This work was supported in part by the U.S. National Science Foundation (NSF) under Grant ECCS-1608579 and Grant CNS-1547353,
and in part by the U.S. Army Research Ofﬁce under Grant W911NF-19-1-0043.
ABSTRACT 6G and beyond will fulﬁll the requirements of a fully connected world and provide ubiquitous
wireless connectivity for all. Transformative solutions are expected to drive the surge for accommodating a
rapidly growing number of intelligent devices and services. Major technological breakthroughs to achieve
connectivity goals within 6G include: (i) a network operating at the THz band with much wider spectrum
resources, (ii) intelligent communication environments that enable a wireless propagation environment
with active signal transmission and reception, (iii) pervasive artiﬁcial intelligence, (iv) large-scale network automation, (v) an all-spectrum reconﬁgurable front-end for dynamic spectrum access, (vi) ambient
backscatter communications for energy savings, (vii) the Internet of Space Things enabled by CubeSats
and UAVs, and (viii) cell-free massive MIMO communication networks. In this roadmap paper, use
cases for these enabling techniques as well as recent advancements on related topics are highlighted, and
open problems with possible solutions are discussed, followed by a development timeline outlining the
worldwide efforts in the realization of 6G. Going beyond 6G, promising early-stage technologies such
as the Internet of NanoThings, the Internet of BioNanoThings, and quantum communications, which are
expected to have a far-reaching impact on wireless communications, have also been discussed at length in this
INDEX TERMS 6G, wireless communications, terahertz band, intelligent communication environments,
pervasive artiﬁcial intelligence, network automation, all-spectrum reconﬁgurable transceivers, ambient
backscatter communications, cell-free massive MIMO, Internet of NanoThings, Internet of BioNanoThings,
quantum communications.
I. INTRODUCTION
Wireless communication systems have experienced substantial revolutionary progress over the past few years. Various
stakeholders, including commercial solutions providers, academic research groups, standards bodies, and end-users, have
all greatly beneﬁted from the radical changes led by the most
recent 5G developments, which include paradigm-deﬁning
techniques such as network softwarization and virtualization,
massive MIMO, ultra-densiﬁcation, and the introduction of
new frequency bands. Numerous burgeoning applications and
verticals, including virtual and augmented reality (VAR),
e-commerce,
contactless
machine-to-machine
communications, and enhanced mobile broadband, among
others, have demonstrated the vast potential of 5G, which
The associate editor coordinating the review of this manuscript and
approving it for publication was Haipeng Yao
continues to evolve and adapt to a wide variety of emerging
use cases.
However, as societal needs continue to evolve, there has
been a marked rise in a plethora of emerging use cases that
cannot be served satisfactorily with 5G. For example, the next
generation of VAR, i.e., holographic teleportation, requires
Tbps-level data rates and microsecond-level latency, which
cannot be achieved with even the millimeter wave (mmWave)
frequency bands within 5G. Further, increasing industrial
automation and the move from Industry 4.0 to the upcoming
Industry X.0 paradigm will push connectivity density well
beyond the 106 km2 metric that 5G is designed for, in addition
to requiring an overhaul of existing network management
practices. Further, an increase in the connection density will
also result in demands for improved energy efﬁciency, which
5G is not designed for. Consequently, the research community
has gravitated towards addressing the aforementioned major
VOLUME 8, 2020
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see 
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
TABLE 1. The evolution from 5G to 6G wireless systems .
challenges, and we posit that ongoing research in the domains
of terahertz band communications, intelligent surfaces and
environments, and network automation, for example, may
very well hold the key to the future of wireless.
To this end, an amalgamation of societal needs and technological breakthroughs that serve to enable those needs are the
key drivers for a generational leap beyond existing wireless
systems. Together, these factors make a strong case for a
focused discourse on the next frontier in wireless communications, i.e., 6G systems. We envision that 6G will not only
enable a pervasively intelligent, reliable, scalable, and secure
terrestrial wireless network, but will also incorporate space
communications to form an omnipresent wireless network,
in keeping with the need for true wireless ubiquity. This
paper details our vision for the future of wireless communications, highlighting emerging use cases and detailing the
key enabling technologies that are essential to the realization
We begin our discussion on 6G by formally introducing the
key performance indicators (KPIs) that are expected to guide
the design of 6G systems. While the ITU Telecommunication
Standardization Sector (ITU-T) is working on a set of ofﬁcial
recommendations for the KPI metrics, the tentative values
have appeared in the public domain recently . Table 1
presents these values and contrasts them against the metrics
associated with 5G. These KPIs serve as the fundamental
metrics to evaluate system performance. In particular, from
the table, we note the following classes of KPIs:
• System Capacity: This class of KPIs primarily deals
with metrics that are associated with system throughput.
These include peak data rate, experienced data rate,
peak spectral efﬁciency, experienced spectral efﬁciency,
maximum channel bandwidth, area trafﬁc capacity, and
connection density. Within this context, the experienced
data rate and spectral efﬁciency metrics refer to the
values that should be guaranteed to 95% of all user
locations .
• System Latency: This class of KPIs includes the endto-end latency metric, along with delay jitter. We note
that jitter is a new KPI for 6G that quantiﬁes the latency
variations in the system, and is absent from 5G.
• System Management: This class of KPIs primarily
deals with metrics related to the management and
orchestration of networks such as energy efﬁciency,
reliability, and mobility. Here too we note that while
5G does not specify a target KPI for the energy efﬁciency metric, 6G introduces a target energy efﬁciency
of 1 Tb/J.
Achieving the KPIs highlighted in Table 1 will require
revolutionary breakthroughs across all domains of wireless
communications. In particular, we identify the following
major thrusts:
• New Spectrum Usage and Radio Design Paradigms:
While 5G ensured the mainstream adoption of mmWave
spectrum, the need for higher data rates and consequently larger channel bandwidths will necessitate the
incorporation of terahertz (THz) and sub-THz spectrum
within 6G. At the same time, the opening up of new
spectrum bands will also require novel radio designs
that can simultaneously sense and communicate over the
entire EM spectrum.
• Novel Network Architectures: The classical cell-based
architecture of wireless networks cannot scale to meet
the area trafﬁc capacity and connection density requirements put forth by 6G. Instead, 6G will need to incorporate communications infrastructure into the very fabric
of the environment.
• Increasing Intelligence and Automation: The strict
spectral efﬁciency, reliability, and latency requirements
associated with 6G imply that manual conﬁguration of
the network will no longer be possible. Rather, network
intelligence and automation will occupy centre stage,
helping build an increasingly autonomous network.
• Enhancing Network Coverage Beyond the Terrestrial Domain: In order to achieve true wireless ubiquity,
6G will need to expand beyond terrestrial networks,
incorporating both near-Earth as well as deep-space
connectivity.
Towards the fulﬁllment of this grand vision, we note that
several enabling solutions have been conceived and are being
actively studied. As shown in Figure 1, these technologies
include: (i) a network operating at the THz band with abundant spectrum resources, (ii) intelligent communication environments that enable a wireless propagation environment
with active signal transmission and reception, (iii) pervasive
artiﬁcial intelligence, (iv) large-scale network automation,
(v) an all-spectrum reconﬁgurable front-end for dynamic
spectrum access, (vi) ambient backscatter communications
for energy savings, (vii) the Internet of Space Things enabled
by CubeSats and UAVs, and (viii) cell-free massive MIMO
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
FIGURE 1. The envisioned key enabling technologies for 6G and beyond wireless communications systems.
communication networks. We also make note of three very
promising technologies that are expected to shape the future
of communications, yet will not be sufﬁciently mature for 6G.
These include: (i) the Internet of NanoThings, (ii) the Internet of BioNanoThings, and (iii) quantum communications.
Further, in addition to the aforementioned key technologies,
holistic security solutions will also be vital to the success
of 6G. However, these fall outside the purview of this paper.
Further, we posit that while prior art concerning 6G wireless systems has been become increasingly commonplace
over the past year – , a majority of the past publications
in this domain focus on a select few topics, potentially hampering a comprehensive overview in terms of key aspects that
are expected to shape the future of wireless communications.
In addition, discussion concerning beyond 6G systems such
as the Internet of NanoThings, the Internet of BioNanoThings, and quantum communications is equally critical but
largely absent from existing publications.
As research on 6G wireless systems continues to evolve
and break new ground, this paper is intended to equip readers
with a targeted insight into the next generation of wireless communications. More speciﬁcally, through this paper,
we aim to deliver a holistic roadmap for 6G and beyond
wireless systems, replete with a detailed discussion surrounding the use cases and key enabling technologies. The larger
goal here is to encourage the scientiﬁc community to work
together towards tackling the critical research challenges
associated with the realization of the 6G systems.
The rest of this paper is organized as follows. In Section II,
we present a wide variety of use cases that will be enabled by
6G. Further, Sections III – VI present details concerning key
technologies that are critical to the success of 6G, along with
a discussion on the major challenges faced by each. Then,
in Section XI, we discuss promising enablers for beyond 6G
systems, followed by a timeline for the evolution of 6G in
Section XII. Finally, in Section XIII, we conclude this paper.
II. USE CASES
The lessons learned from the continued evolution of 5G
systems will serve as the backdrop for use cases that will be
best served by 6G. 5G ﬁrst introduced the targeted use cases
of enhanced mobile broadband (eMBB), ultra-reliable lowlatency communication (URLLC), and massive machine type
communications (mMTC), intended to serve a wide variety
of applications. However, as noted in Section I, there exist a
plethora of applications for which the 5G KPIs are not strict
enough. As we come to realize the performance trade-offs in
terms of throughput, latency, coverage, energy efﬁciency, and
reliability, associated with 5G systems, we can better posit the
applications that would beneﬁt the most from 6G. As shown
in Figure 2, in the following, we present a variety of critical
use cases that will be enabled by 6G.
A. MULTI-SENSORY HOLOGRAPHIC TELEPORTATION
While virtual reality (VR) and augmented reality (AR)
introduced as part of 5G, there are many applications such as
advanced healthcare including remote diagnosis and surgery,
high-resolution sensing for remote exploration, and near-real
person video conferencing that cannot be adequately served
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
FIGURE 2. Use cases best served by 6G systems.
by a combination of AR and VR. To this end, holographic
teleportation has been recognized as the natural successor
to AR and VR-based solutions. Unlike existing solutions,
holographic teleportation operates in a true three-dimensional
space and leverages all ﬁve senses– sight, hearing, touch,
smell, and taste, to provide a truly immersive experience.
At the same time, we note that holographic teleportation
requires data rates close to 5 Tbps and an end-to-end latency
of less than 1 ms , both of which are impossible to achieve
with 5G systems. Thus, 6G, with its expected Tbps-level
throughput and sub-millisecond latencies, will play a vital
role in building upon the groundwork established by eMBB
and URLLC.
B. REAL-TIME REMOTE HEALTHCARE
The success of remote healthcare solutions primarily depends
on both the quality as well as the availability of connectivity . Concerning the former, we note that through its use of
key enabling technologies such as THz band communications
and network automation solutions, 6G will usher in the highest possible wireless communications quality focusing on
very-high throughput augmented with ultra-low latency. Concerning the latter, the Internet of Space Things will play a vital
role in providing pervasive connectivity, thus enhancing the
availability of rural healthcare solutions. Further, we expect
that within the domain of healthcare, advances in 6G and
beyond will not only serve as a connectivity solution, but will
also play a vital role in the diagnosis and treatment of diseases
as detailed in Section XI-B.
C. AUTONOMOUS CYBER-PHYSICAL SYSTEMS
Autonomous vehicles and UAVs are some of the most promising cyber-physical systems in existence today , .
The operation of these autonomous systems is characterized by the exchange of large amounts of data between
the constituent nodes, i.e., both vehicles and UAVs, relating
to high-resolution real-time mapping of the terrain, route
optimization, and trafﬁc and safety information. While the
resulting large volumes of data must be delivered within
strict deadlines in an error-free manner, it also imperative to note that these nodes typically operate at speeds
in excess of 100 km/h. Therefore in addition to providing
sub-millisecond latency and very high reliability, the connectivity solution that enables autonomous cyber-physical
systems must also offer robust operation at very high speeds,
which is not possible with existing 5G systems .
D. INTELLIGENT INDUSTRIAL AUTOMATION
Over the past few years, Industry 4.0 has been the
driving force behind industrial automation based on the
concepts of supply chain optimization, autonomous equipment, additive manufacturing, data analytics, and the Internet of Things (IoT). Yet, these concepts are treated as silos
working in isolation, limiting the true potential of industrial automation. On the other hand, the upcoming Industry
X.0 paradigm seeks to realize synergies between the
various nuances of industrial automation through its use of
artiﬁcial intelligence. Vital to this vision are networked factories that serve as critical sources of big data that helps
inform decision making. To this end, the modern industrial
ﬂoor is expected to require reliable high-throughput connectivity across thousands of devices often with sub-millisecond
response times, making it the perfect use case for the next
frontier in wireless communications.
E. HIGH-PERFORMANCE PRECISION AGRICULTURE
Within the broader domain of precision agriculture, soil moisture measurements have been a mainstay in irrigation decisions for decades now. However, real-time measurements and
irrigation automation solutions still face challenges stemming
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
FIGURE 3. The THz band offers hundreds of GHz usable spectrum resources for wireless communication
links in long, medium, short, indoor, and near-field range.
from a lack of robust wireless coverage. Going beyond simple
automated irrigation solutions, high-performance precision
agriculture is largely centered around delivering data-driven
insights to address the speciﬁc needs of customers, farms,
crop, and soil. At the same time, scalable and timely access
to such data is a major challenge owing to gaps in rural
connectivity. Therefore, we expect that 6G, with its focus on
ubiquitous wireless access, will play a major role in enhancing the adoption of technology in agricultural production.
F. SPACE CONNECTIVITY
While near-Earth and deep-space connectivity are still
nascent within 5G, there are a wide variety of use cases
ranging from radio astronomy and remote sensing to navigation and backhauling that would stand to beneﬁt from
the pervasive connectivity offered by 6G. More speciﬁcally,
such applications include freight tracking, terrestrial cellular
ofﬂoading, environmental monitoring, and long-range UAV
coordination, to name a few. To this end, the Internet of
Space Things as described in Section IX, will serve as the
key enabling technology for beyond-Earth connectivity, furthering the reach of 6G systems.
G. SMART INFRASTRUCTURE AND ENVIRONMENTS
The use cases discussed thus far primarily deal with the use of
third-party systems that seek to leverage advanced telecommunications infrastructure. Simultaneously, the evolution of
such infrastructure itself is an important use case. Going
beyond network optimization strategies, there is also a need
for exercising control over the propagation of wireless signals. To this end, we note that in 5G and its predecessor systems, the wireless communication environment has always
played a passive role. However, with the ever increasing
demand for data, as evidenced by the applications presented
herein, control over the manner in which electromagnetic
waves interact with the indoor and outdoor environment will
be critical to the success of 6G. In this direction, we posit
that the intelligent communication environments described
in Section IV will play a leading role in the ubiquity and
pervasiveness of the next generation of wireless systems.
III. TERAHERTZ BAND COMMUNICATIONS
Recent years have witnessed a dramatic rise in wireless
data trafﬁc brought forth by numerous exciting technologies
in wireless communications. This exponential growth has
been accompanied by the demand for higher data rates and
better coverage . Among emerging research and development trends in wireless communications, terahertz band
(0.1 −10 THz) communications has been envisioned as one
of the key enabling technologies for the next decade. Buoyed
by the availability of ultra-wide spectrum resources, the THz
band can provide terabits per second (Tbps) links for a
plethora of applications, ranging from ultra-fast massive data
transfer among nearby devices in Terabit Wireless Personal
and Local Area Networks to high-deﬁnition videoconferencing among mobile devices in small cells.
Recently, the Federal Communications Commission (FCC)
has released the frequency bands above 95 GHz for research
purposes . While a handful of cellular operators have
adopted low millimeter wave frequencies for their 5G services with the intention of achieving a maximum data rate of
100 Gbps, the test results thus far leave much to be desired,
showing a peak data rate of around 1 Gbps.1 This gap between
the targeted and practically achievable data rates is inﬂuenced
by multiple factors, including a high complexity in realistic
communication channels, imperfections in circuitry design,
and interference from other systems operating in adjacent
frequency bands, among others. Nevertheless, even though
the THz bands have been applied in imaging and object detection, as well as for THz radiation spectroscopy in astronomical research, their use cases in wireless communications are
still under investigation. Lying between the mmWave spectrum and infrared light spectrum, as shown in Figure 3, THz
bands, with their abundant spectrum resources, have been
previously deemed as a ‘‘no-man’s land’’. However, major
progress in the domains of transceiver and antenna design
has seen THz links become a promising option for realizing
indoor communications networks. More recently, there has
been signiﬁcant progress on realizing wireless network on
chip (WNoC) using THz bands .
A. USE CASES OF THz BAND COMMUNICATIONS
Different from wireless networks at lower frequencies,
THz-band wireless communications has several unconventional application scenarios, owing to the distinct electromagnetic and photonics characteristics of this tremendously
high frequency band. In addition to the promised Tbps-level
1 
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
links for cellular systems, THz-band spectrum can also be
leveraged for the following scenarios:
• Local Area Networks: Several spectrum windows are
feasible for short-range links within ten meters, including 625 −725 GHz and 780 −910 GHz . THz band
communications is expected to form the THz-optics
bridge to enable seamless transition between ﬁber-optics
and THz-band links with zero latency.
• Personal Area Networks: THz band communications
can provide ‘‘ﬁber-like’’ data rate without the need of
wires, between multiple devices at a distance of a few
meters. Such communication scenarios can be found in
indoor ofﬁces and multimedia kiosks.
• Data Center Networks: Conventional data centers manage and maintain connectivity in wired networks using
cables, resulting in high costs in terms of both installation and reconﬁguration. On the other hand, THz links
provide promising prospects for seamless connectivity
at ultra-high-speeds in ﬁxed networks and adaptability
for hardware reconﬁguration.
• Wireless Network on Chip: As the trend in transceiver
hardware development motivates a higher level of
integration and miniaturization as well as weight reduction, the THz band links can serve as a promising
candidate to establish wireless connections among different modules within the transceiver chassis, in order
to replace the wired connections commonly found in
existing transceiver hardware products.
• Nano-networks: With its wavelength falling into the
nanometer (10−9 m) range, the THz band can operate better than any other frequencies in nano-networks.
Within this context, a nano-network is a set of interconnected nano-devices or nano-machines for information
exchange, storage, and computation. A more detailed
overview can be found in Section XI-A.
• Inter-satellite Communications: Lying largely outside
the Earth’s atmosphere, inter-satellite links are not
constrained by atmospheric attenuation, which makes
the THz band a favorable candidate for such communication links. Compared to existing spectrum resources
allocated for inter-satellite links, the THz band has a
much wider bandwidth which can accommodate more
satellites and achieve higher link performance. Unlike
the widely used optical links, the THz band does
not impose stringent requirements on beam alignment,
which can help maintain a high level of link stability as
satellites drift out of their orbits.
B. DEVICES IN THE THz BAND
The need for higher output power, lower phase noise, and
better receiving sensitivity in THz band transceivers has
driven advances in corresponding device development. Currently, three main directions are deployed in THz band signal
generation: photonics-based, electronic-based, and emerging
material-based, respectively.
In the photonics-based approach, many III-V semiconductors, including gallium arsenide (GaAs) and indium
phosphide (InP), which provide high electron mobility, are
excellent candidates especially for high frequency (i.e., above
100 GHz) applications. Such photonics-based techniques
generate time-domain pulses with lengths of femto-seconds
(10−15 s) and experimental works have demonstrated
50 Gbps data links in an indoor scenario at 300 GHz using the
uni-traveling-carrier photodiode (UTC-PD) technique .
The UTC-PDs and modiﬁed UTC-PD structures, an effective
photomixing solution which allows wider spectrum tuning
and simpler construction compared to laser pulse generators,
has pushed the output signal range from 300 GHz to 2.5 THz,
with output powers of 10 µW at 300 GHz and 1 µW at
1 THz . Additionally, a design based on slot-antennaintegrated UTC-PDs has shown superior performance in generated THz band signal strengths at 350 −850 GHz and
900 GHz −1.6 THz, compared to that of the bowtie-antenna
integrated UTC-PD . Similar photonics-based THz signal
generation at above 1 THz can be realized using quantum cascade lasers (QCLs) and other solid state lasers . However,
the operations of such devices are limited at room temperatures, requiring liquid helium cooling, which affects their
deployment in local area networks with space restrictions.
Furthermore, photoconductive antennas (PCAs) have been
utilized widely for both pulse and continuous-wave signal
generation at THz band , demonstrating a wide spectrum
(up to 4.5 THz) with a remarkable dynamic range of up to
100 dB .
In parallel to the photonics-based approach for THz band
device design which down-converts the optical frequencies,
the electronic-based THz band signal generation relies on
frequency up-conversion using multipliers , including
frequency doublers and triplers, as well as backward wave
oscillators . A recent experiment has demonstrated an allelectronics-based wireless link at 240 GHz with a throughput
of 50 Gbps and a maximum 29% error vector magnitude
using QPSK modulation . The backward wave oscillator,
which is a compact design to generate THz band signals based
on the mechanism of energy transfer from an electron beam
to an electromagnetic wave through a vacuum tube, has been
used to generate signals at 300 GHz with an output power of
1 W in plasma diagnostics .
Among the two commonly used approaches, the photonicsbased design beneﬁts from a relatively simpler transceiver
architecture based on the photomixing technique, while
the electronics-based solution relies on cascaded frequency
up-conversion of RF signals, which sets stringent requirements on linear-range operation and potentially limits the
terahertz bandwidth. On the other hand, the electronics-based
approach is less sensitive to environmental conditions, such
as temperature, humidity, among others, which makes it more
favorable for outdoor operations, whereas the link reliability
from its photonics-based counterpart is affected by scattered
particles in the channel, making the THz band link less
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
Besides these classical approaches for THz band device
development, new materials, including graphene, carbon nanotubes, and graphene nanoribbons, are gaining more attention
due to their extremely high electron mobility in the order of
8, 000 −10, 000 cm2/(V · s) at room temperature, as compared to 1, 400 cm2/(V · s) of silicon, and 8, 500 cm2/(V · s)
of GaAs, which means that the link throughput can be potentially up to ten times higher than is currently achievable
with most semiconductors . The graphene-based devices,
offering outstanding mechanical, electrical, and optical properties, have been utilized in the development of power detectors at 600 GHz and 200 GHz , as well as plasmonic
antenna arrays and transceivers , . Graphene-based
devices have the potential to break new ground in reaching
the desired level of performance at much higher frequencies
above 1 THz.
C. PHYSICAL LAYER MODELING AT THE THz BAND
The realization of wireless communications at THz frequencies requires the development of accurate channel models to
capture the impact of both channel peculiarities including the
high atmospheric attenuation and molecular absorption rates
at various transmission windows, as well as the propagation
effects including reﬂection, scattering, and diffraction, with
respect to different materials. Current research has reported
several efforts to provide fundamental understanding of such
channels. For example, an early work in demonstrates
the remarkable capacity the THz band channel can support
for short transmission distances. The model provides a detail
analysis on the effect of attenuation caused by the molecular
absorption and spreading loss, on which the performance
of channel throughput is heavily dependent. One step further, in order to extend the transmission distance at THz
bands, an idea dubbed as the ultra-massive multiple-input
multiple-output (UM MIMO) communications, enabled by
an element array size of 1024 × 1024 with plasmonic nanoantennas, can drastically boost the signal strength by steering
and focusing the transmitted beams in both space and frequency . Correspondingly, a UM MIMO channel model
has been developed in which takes into account the role
of such arrays.
Additionally, a stochastic channel model for indoor THz
band communications at 300 GHz has been reported in 
which characterizes both spatial and temporal domain channel information. More recently, based on the aforementioned applicable scenarios in the THz band, a stochastic
channel model for kiosk applications has been reported
in which ranges from 200 −340 GHz. The main takeaway from current models validated using either measurements or the ray-tracing technique is that the direct
path between the transmitter and the receiver and the
single-bounce reﬂected paths dominate the received power,
while other channel effects, including diffraction and scattering, attenuate power signiﬁcantly along propagation.
On the basis of the ultra-wideband channel characterization, THz band communications faces a critical and
challenging task of synchronization in the receiver design.
Existing pulse-based modulation schemes permit the use
of low-complexity non-coherent analogue detectors, e.g.,
energy detector and auto-correlation receiver, which involve
the multiplication of the received signal with itself, followed
by an integrator. However, a more advanced non-coherent
receiver architecture in based on a continuous time
moving average symbol detection scheme demonstrates better performance compared to previous detection schemes
for pulse-based modulations in terms of the symbol error
rate. In addition, robust frequency and timing synchronization for multi-carrier communication in the THz band is
desirable to decode multiple incoming signal streams. The
work presented in realizes both a low-rate sampling
scheme for channels with high SNR values and a maximum
likelihood-based algorithm for low SNR channels with satisfying bit-error-rate performance. More recently, a synchronization scheme based on medium access control protocols
is reported in , which shows good performance in both a
macro-scale scenario to overcome the distance limitation at
the THz band and a nano-scale scenario for nano-devices for
energy harvesting.
Similarly, given the peculiar ultra-wideband nature and
frequency selectivity of THz band communications, equalization solutions pose another relevant challenge , .
In , three equalization solutions, including the Tomlinson-
Harashima precoding, a waveform with interference management for time-reversal systems, and an iterative algorithm
with adaptive soft feedback, are reviewed and compared for
an indoor channel. Results show that the iterative algorithm
with adaptive soft feedback yields the most promising BER
performance .
D. MEDIUM ACCESS CONTROL IN THz BAND
COMMUNICATIONS
On top of physical layer channel models, the medium access
control (MAC) schemes in THz band communications should
adopt certain spatial and spectral features in order to provide solutions in resolving issues such as the deafness problem and LoS blockage, among others , . Different
from commonly used MAC solutions in RF systems that
utilize omnidirectional antennas, such as carrier sense multiple access with collision avoidance (CSMA/CA), the MAC
protocols designed for THz band rely on handshakes between
transceivers with highly directional beams. These razor-sharp
beams can provide higher power radiation gain and prolong
the transmission distance, but when misalignment happens,
the deafness problem arises. As such, the deafness avoidance
approach is required in MAC scheme design. Existing solutions utilized in IEEE 802.15.3c and others employ a
beam-training phase to estimate and steer beams towards destined devices. Recent works also propose methods based on
angular division multiplexing and a priori aided channel
tracking schemes . The results in such proposed solutions
suggest that with good beam alignment strategies the channel
throughput can be improved signiﬁcantly.
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
Moreover, the MAC protocols can also resolve the issue
of LoS blockage where the received power of a user device
may undergo deep fading due to the device being held in
a manner that blocks the LoS path. Studies have shown
that such attenuation by the human body can be as high as
20 dB at 60 GHz and up , . To mitigate the blockage
problem, researchers have proposed a multi-hop scheme at
the mmWave and THz bands to form alternative routes ,
 . A careful link-level scheduling and neighbor discovery
process is necessary to achieve high throughput while maintaining low interference.
E. OPEN PROBLEMS IN THz BAND COMMUNICATIONS
Currently, the fabrication and testing of THz band antenna
arrays remains a relevant challenge. Some techniques based
on photolithography, electro-beam lithography, among others, are able to produce the front-end with hundreds of plasmonic antenna elements. The utilization of large antenna
arrays can extend the signal coverage by forming array radiation patterns with main lobes of high directivity, thus focusing energy towards desired directions. However, such highly
directional beams limit coverage in the angular domain, causing low energy efﬁciency at the transmitter to serve each user.
A recent solution named ‘‘THzPrism’’ has been proposed
to form multiple beams with slight frequency shifts towards
different directions while maintaining good distance coverage in addition to other proposed solutions discussed
in Section III-C to solve the transmission distance problem.
This design employs true time delays for RF chains before
phase-shifters to obtain a prism-like effect, which spreads the
original beam into several beams, each with a slight frequency
shift with respect to the center frequency.
In parallel to the quest for more novel solutions in antenna
design, other remaining challenges reside in the control
and signal processing schemes associated with transceiver
designs in the THz band. On the one hand, real-time control algorithms are needed. On the other hand, communication protocols for coordination between the transmitter,
receiver, and reﬂectarrays are needed. Among others, in ,
researchers reported a smart reﬂectarray-assisted mmWave
system compatible with IEEE 802.11ad. Besides the design
of the reﬂectarray and a study on deployment strategies,
a three-way beam-searching protocol is developed, in which
the reﬂectarray coordinates with the transmitter through a
2.4 GHz control channel in order to discover the best joint
transmit and reﬂect sectors for which the signal at the receiver
is maximized. However, this work does not capture the
extended functionalities of plasmonic reﬂectarrays. Furthermore, when highly directional beams are utilized at mobile
transceivers, a relevant challenge arises from the limited
ﬁeld-of-view of antenna arrays for each transceiver to locate
the next hop to forward its data; thus, new routing solutions
are necessary for THz band communications to efﬁciently
discover and establish links. A study in reports a solution
in link discovery at THz band using a leaky-wave antenna to
sense the angular information of a user.
IV. INTELLIGENT COMMUNICATION ENVIRONMENTS
Along with the rapid growth in the number of wireless
devices, services, and applications, a corresponding demand
for higher speed wireless communications has burgeoned in
recent years. Nevertheless, the major challenge at mmWave
and THz-band frequencies is the limited communication distance because of the remarkably high path loss inherent to
small wavelengths and the limited transmission power of
mmWave and THz-band transceivers . Current solutions
primarily focus on the advancement of wireless transceiver
hardware and software, as well as network optimization
strategies. However, the wireless propagation medium has
been largely neglected. The wireless communication environments, for both indoor and outdoor scenarios, can be actively
utilized in order to become controllable for signal propagation. To control signal propagation in environments is essentially to control how electromagnetic waves interact with
scatterers, which include indoor furniture and outdoor buildings as well as other infrastructure. Typically, the controllable behaviors of electromagnetic waves include controlled
reﬂection, absorption, wave collimation, signal waveguiding,
and polarization tuning, as illustrated in Figure 4. The notion
of ‘‘Intelligent Communication Environments’’ resides in the
control algorithms where deep learning and reinforcement
learning are to be exploited to dynamically conﬁgure the
environments. In the following subsections, we elaborate on
these controllable wave behaviors, current research efforts,
as well as corresponding open issues.
A. BASICS OF INTELLIGENT COMMUNICATION
ENVIRONMENTS
The intelligent environments can be seen as a threedimensional structure with several layers, each with different functionalities. Recent research under the EU Research
Project ‘‘VisorSurf’’ has demonstrated a structure with ﬁve
main layers, which are (from top to bottom) the EM behavior
layer, the actuation and sensing layer, the shielding layer,
the computing layer, and the communication layer, respectively . Speciﬁcally, the EM behavior layer is composed
of metasurfaces, a two-dimensional representation of metamaterials, and has a tunable impedance to control directions of reﬂection of the EM waves. Some other works use
reﬂectarray antennas as the top surface , . The actuation and sensing layer consists of circuits for phase shifting and sensors for impinging signal sensing. Some options
for actuation include PIN diodes with controllable biasing
voltage as switches in reﬂectarray antennas, and complementary metal-oxide semiconductors (CMOS) transistors as well
as micro-electro-mechanical (MEMS) switches for metasurfaces. The shielding layer isolates the upper and lower parts of
the layered structure so as to minimize the possible interference. The computing layer serves to control the phase shifts
and process sensed impinging waves. To this end, another
reported solution makes use of ﬁeld-programmable gated
arrays (FPGAs) to fulﬁll such functions on metasurfaces .
Finally, the communication layer connects all upper layers
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
FIGURE 4. Conceptual design of a plasmonic reflectarray able to unconventionally manipulate EM
waves .
and serves as the gateway towards the central controller which
processes all connection requests, forwards and receives
signals, and conducts the aforementioned controlled wave
functions.
Compared to existing relays with multiple antennas which
are widely deployed in wireless networks, Intelligent Communication Environments offer the following advantages:
(i) a higher spatial diversity due to the wide coverage
of the intelligent surface with controllable antenna arrays,
(ii) a reduced processing time given that the computing and
communication layers are directly underneath the surface
layer, and (iii) a higher ﬂexibility in network routing when
impinging signals come from different directions and the
intelligent surfaces are able to collimate waves and reﬂect
them towards desired directions.
B. FUNCTIONALITIES OF INTELLIGENT ENVIRONMENTS
Bolstered by the layered structure, intelligent surfaces can
enable controlled EM wave operations. At micro- and
mmWave frequencies, metasurfaces are considered as a good
candidate. While at THz bands, graphene-based plasmonic
antenna arrays are desirable. In metasurfaces, a meta-atom is
the smallest unit, which is a conductor with a size smaller
than half the wavelength of the signal. Metasurfaces can thus
control the impinging EM waves with a very ﬁne granularity.
The meta-atoms are interconnected by a set of miniaturized
controllers that connect the switches of the metasurfaces in
the computing layer, while a gateway serves as the connectivity unit in the communication layer to provide inter-element
and external control. At THz bands, when the metasurfaces
do not yield optimal performance, the graphene-based plasmonic antenna arrays serve as a promising alternative.
Compared to metallic antenna arrays, the plasmonic
antenna arrays can have much denser element layout and
go beyond the conventional λ/2 sampling of space towards
more precise space and frequency beamforming, owing to the
physics of plasmonics. In our previous work, we have demonstrated that, graphene can be used to build nano-transceivers
and nano-antennas with a maximum dimension of λ/20
at THz frequencies, allowing them to be densely integrated
in very small footprints (1024 elements in less than 1 mm2),
as shown in Figure 4 . Therefore, by incorporating the
graphene-based plasmonic antenna arrays at THz bands and
metasurfaces operating at mmWave bands, we can expand the
operational spectrum of intelligent environments and utilize
them in transmission and reception in a controllable manner.
C. LAYERED STRUCTURE OF INTELLIGENT
COMMUNICATION ENVIRONMENTS
Based on the operating principles of the aforementioned
Intelligent Communication Environments, in this subsection,
we anatomize the layered structure and detail each layer’s
functionality.
1) METAMATERIAL PLANE
The metamaterial plane is also the surface plane, as shown
in Figure 4. In designs based on reﬂectarrays, phase shifts
are applied to each element to improve useful signals while
canceling interference , . The metasurface element
proposed in with millimeter-scale dimensions is connected to a PIN diode with a bias voltage to control operation
modes, such as altering polarizations.
In general, this layer comprises the supported EM function
of the tile as well as its operation principle. In particular,
reﬂectarray employ modiﬁable phase shifts applied over their
surface. In the far ﬁeld of radiation, reﬂected rays can be considered co-directional, and their superposition–constructive
or destructive–is controlled by the applied phase shifts .
Hence, wave scattering or controlled reﬂecting functions can
be attained. Metamaterial tiles, however, operate as surfaces
with tunable local impedance . Impinging waves create
inductive surface currents over the tile, which can be routed
by tuning the local impedance across the tile. Notice that the
Huygens Principle dictates that any EM wavefront can be
traced back to a current distribution over a surface . As a
result, in principle, metamaterials can produce any custom
EM function as a response to an impinging wave. Common
functions include wave steering, focusing, collimating (i.e.,
producing a planar wavefront as a response to an impinging
wave), polarizing, phase altering, full or partial absorption,
frequency selective ﬁltering and even modulation , .
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
2) SENSING AND ACTUATION PLANE
In order to control the EM waves per actual channel conditions, the programmable surfaces are expected to sense
the propagation environment and actuate the upper surface
plane accordingly. Such layer contains hardware elements
that can be controlled to achieve a phase shift or impedance
distribution across a tile.
antennas–such as copper patches–and multi-state switches
between them. Reﬂectarray tiles usually employ PIN diodes
with controllable biasing voltage as switches . Metamaterials have employed a wider range of choices, both
in the shape and geometry of the planar antennas and
in the nature of switches. CMOS transistors, PIN diodes,
Micro-Electro-Mechanical Switches (MEMS), micro-ﬂuidic
switches, magnetic and thermal switches are but a few of
the considered options in the literature . Notably, some
options–such as micro-ﬂuid switches–are state-preserving
in the sense that they require power only to change state
but not to maintain it (i.e., contrary to biased PIN diodes).
Sensing impinging waves are also necessary for exerting
efﬁcient control over them. While this information can be
provided by external systems , with dynamic channels
and mobile end-users, tiles capable of incorporating sensing
capabilities can be immune from the channel aging problem . The sensing can be direct, employing specialized sensors, or indirect, e.g., via deducing some impinging wave attributes from currents or voltages between tile
3) COMPUTING PLANE
The computing functionality serves the processing functionality in the controllable surface system. In the metasurface
designs in and , FPGA-based controllers are connected to the metasurfaces to implement the computing functions. This layer comprises the computing hardware that
controls the actuation and sensing elements. Its minimum
computing duties include the mapping of local phase or
impedance values to corresponding actuator states. Reﬂectarray tiles commonly implement this layer using FPGAs and
shift registers .
Metasurfaces, and speciﬁcally HyperSurfaces, can alternatively employ standard IoT devices for the same purpose.
Moreover, they can optionally include computing hardware
elements (ASICs) distributed over the tile meta-atoms ,
 . This can enable autonomous and cognitive tiles, where
meta-atoms detect the presence and state of one another, and
take local actuation decisions to meet a general functionality
objective. Nonetheless, these advanced capabilities are not
required for programmable wireless environments.
4) COMMUNICATION PLANE
The communication plane passes the signals from the processing layer to corresponding metasurface layer and collects
signals from the sensing and actuation plane. In complicated programmable surface systems, communication occurs
among planes to realize various EM wave control functions.
The command signals normally operate at much lower frequencies compared to the ones emitted from programmable
surfaces; such signals prove to be more efﬁcient in tuning the
bias voltage of the PIN diodes .
This layer comprises the communication stack and connects actuation and sensing layer as well as computing layer
with tile-external devices such as controllers. In the simplest case, this layer is implemented within the computing
hardware, acting as a gateway to the external world using
any common protocol such as the Ethernet. HyperSurface
tiles with embedded distributed computing elements additionally require inter-tile communication schemes, to handle
the information exchange between smart meta-atoms. Both
wired and wireless intra-tile communication is possible ,
 . In both cases, the ASIC hardware employs custom and
nonstandard protocols.
D. USE CASES OF INTELLIGENT ENVIRONMENTS
With the utilization of well-coordinated tiles in the Intelligent
Environments, the wireless system can be greatly improved in
terms of communication efﬁcacy.
1) ON SIGNAL PROPAGATION ENHANCEMENTS
From the perspective of multiple users and moving users,
the Intelligent Environments system is envisioned to serve
a large number of users with more realistic user patterns,
including mobile users and users in a cluster. Additionally, the Intelligent Environments system should ensure
physical layer security against jamming and eavesdropping,
an increasingly important problem that remains to be solved.
• Transmission Distance: For users in the NLoS areas
relative to the transmitter, the Intelligent Environments
system is expected to extend the transmission distance
and reach previously uncovered areas through waveguiding or reﬂection. Simulation results in demonstrate that at 60 GHz the coverage can be extended to an
entire NLoS area.
• Interference Mitigation: Due to the scenario with multiple users, there is inevitably concern of interference.
As in the envisioned scheme, each Intelligent Environment unit is dedicated to an individual user, thus
the majority of interference will reside in the wireless
section of the end-to-end link.
• Reliability: The primary efforts in terms of physical
layer reliability include using highly directional antennas to nullify jamming, forming exclusion areas, assigning secret keys to legitimate users, and so on. From the
perspective of fundamental propagation channels with
Intelligent Environments, good reliability is achieved
when the eavesdroppers do not have the knowledge of
the frequencies where packages are transmitted, or the
eavesdroppers are in the same frequency channel but
with much higher noise which makes the intercepted
data impossible to decode . Therefore, the dedicated
links in Intelligent Environments are inherently secure.
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
2) ON THE PHYSICAL LAYER SECURITY
The more frequent data exchange between users and service providers exposes a higher risk of personal and private data leakage. The 6G wireless network should not
only inherit existing network secrecy measures, but also
provide enhanced physical layer security associated with
new enabling techniques. In current 5G networks, highly
directional beams are used for mmWave communications
in spatial domain to prevent signals from being intercepted.
However, a recent study has shown that such pencil-sharp
beams are still vulnerable to agile eavesdropping . Other
physical layer encryption algorithms, including source coding approaches such as the low-density parity-check (LDPC)
code, are demonstrated with optimal performance under speciﬁc conditions . Furthermore, existing solutions in the
reconﬁgurable intelligence surface apply reﬂectarrays, which
do not have the capability to effectively distinguish target
users from malicious attackers. Hence, a solution based on
the Intelligent Environments serves the purpose of identifying
unintended recipients, creating null areas, and improving link
secrecy rate.
Essentially, the envisioned Intelligent Environments have
the capability to sense user locations and exchange such information with a system controller to verify the user’s authenticity. Only afﬁrmative users shall be served with signal streams
from the sender. On the other hand, connection requests from
unauthorized users (i.e., eavesdroppers) will be nulliﬁed from
attempting to access secure information or even trying to
establish links with the sender.
In practice, the Intelligent Environments can be conﬁgured
to tune the phases of multipath components in the channel,
such that those arrived at intended users can be coherently
combined with boosted received signal strengths, whereas
those intercepted by eavesdroppers will be scrambled or
even cancelled due to non-coherent combining . Simulation results demonstrate a 6-dB attenuation observed at the
received signal strength from the eavesdropper, validating
the proposed physical layer security solution . Hence,
the good channel secrecy is achieved when such unintended
users do not own the knowledge of equalizer to recover the
transmitted signals from noise.
E. OPEN PROBLEMS IN INTELLIGENT ENVIRONMENTS
A number of open problems need to be addressed in order
to facilitate the Intelligent Environments in becoming a
market-ready solution.
• Trade-off Between Dimensions and Energy Consumption: In terms of real-world applications, the
Intelligent Environments are expected to be coated onto
surfaces of interior walls and/or ceilings, and building
facades, which require dimensions that can both ﬁt
speciﬁc installation areas and satisfy link requirements.
Meanwhile, with more reﬂectarray elements and RF
chains built into the system, the energy consumption will
also increase, due to the advanced signal processing circuitry. Therefore, how to achieve an economic solution
to balance the overall dimension and energy consumption while serving users to its desired performance is a
nontrivial issue.
• Compatibility With Existing Solutions: Current Wi-Fi
access points have a mature protocol stack to sense
the channel and establish links with users. In order for
the Intelligent Environments to assist with improving
indoor signal coverage, it needs to be compatible with
the IEEE 802.11 series standard. For now this is still
under research and serves as a worthy problem for novel
solutions.
• Standardization: With many candidate approaches
being investigated in reﬂectarrays, metasurfaces, frequency selective surfaces, among others, there has not
been a consensus on how to standardize the device architecture, maximum emitted power, and communication
protocols. As more ideas evolve, a standardization effort
within a work group is necessary towards a solidary
framework.
• Inclusion of advanced application scenarios: as a
promising solution for future generation of wireless
systems, the Intelligent Communication Environments
should be designed to ﬁt to more advanced scenarios,
for example, in use cases with a very large quantity of
devices as in the Internet of Things, under high demands
of real-time video streaming, with devices of high mobility, among others.
• Smart resource allocation solutions: resources in the
spatial, temporal, and spectral domains should be allocated in an optimal manner to satisfy per-user demand.
• AI-driven design and optimization: in complicated
scenarios under which no closed-form solutions can
be found using conventional optimization approaches,
advanced algorithms in artiﬁcial intelligence can assist
in the deployment of Intelligent Communication Environments, especially when complex surface layout or
structures are in presence.
V. PERVASIVE ARTIFICIAL INTELLIGENCE
In the past few years, the ﬁeld of artiﬁcial intelligence (AI)
has witnessed immense growth, leading to its application in
a wide variety of ﬁelds across both academia and industry. In the realm of communications and signal processing,
AI can be readily applied to cognitive radios, remote sensing,
computer vision, and network management. More speciﬁcally, in the domain of wireless communications, AI and
its associated algorithms are also gradually proving their
utility in various emerging techniques such as massive MIMO
communications which requires efﬁcient channel estimation
and symbol detection. Such tasks often do not yield low
complexity optimal solutions in complex channels , and
thus parallel processing inherent in machine learning can be
favorably leveraged to enhance computational capacity.
Admittedly, even though current wireless communication
networks follow a layered structure, in which each layer
primarily serves several functions, applications of AI and
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
FIGURE 5. Applications of artificial intelligence at different layers of wireless systems.
relevant algorithms are gradually bridging the gap across
layers in a way that can globally optimize the performance
in the entire wireless network. However, in order to provide
a marked trail to navigate through a plethora of pervasive
AI applications, this section is organized based on the existing layers. It is worth noting that AI is a broad concept,
under which reside several branches covering interleaved
research topics, such as robotics, natural language processing, machine learning (ML), computer vision, among others.
In this section, we focus speciﬁcally on the ML algorithms
and their applications in wireless communications under the
AI umbrella. These two terms are thus used interchangeably
in this section. As shown in Figure 5, artiﬁcial intelligence
can be applied to each layer of the wireless network. At the
network layer, machine learning (ML) algorithms can be used
for trafﬁc clustering to further adapt the network resources to
various scenarios . At the physical and MAC layers, deep
learning can optimize resource allocation strategies for power
distribution, and modulation and coding schemes, among
others. Furthermore, machine learning algorithms can also
assist with channel estimation and multi-user detection.
A. AI IN THE PHYSICAL LAYER
Traditionally, physical layer modeling has been modeloriented—a practice in which mathematical models following a certain framework are proposed and optimized under
constraints to satisfy a series of pre-determined performance
requirements. For example, in order to conduct channel
estimation, a channel model is assumed along with other
parametric conﬁgurations. These model-based solutions usually perform well if the derivation of mathematical models
is relatively straightforward or there exists a closed-form
solution. The models can then be validated by ﬁeld measurements or numerical simulations. However, in real-world
scenarios, the applicability of such model-based solutions
falls short in complicated environments, due to factors such
as non-linearity inside systems and uncontrollable interference, among others. On the other hand, another approach,
which is based on statistics, or data sets, builds the model
through learning from the data. This method is particularly
useful when theoretical analysis is intractable or when a
closed-form solution is difﬁcult to obtain. For example,
in diffusion-based channels commonly found in molecular
communication, the channel characteristics depend largely on
the environment, making them challenging to model theoretically . In such cases, some data is used for training, which
can help establish a model, while other data is used for testing
in order to validate the model.
To date, artiﬁcial intelligence has demonstrated its usefulness in various physical layer techniques. For example,
in channel estimation and symbol detection, deep learning approaches reported in , have shown that the
proposed deep learning-based symbol detection algorithms
can provide robust and accurate results with reduced complexity. Furthermore, a deep learning method based on
the deep neural network architecture also demonstrates an
improved channel estimation accuracy under the effects of
non-linearities of power ampliﬁers, I/Q imbalance, and quantization errors induced by hardware impairments . An
autoencoder-based communication system is proposed to
reconstruct the transmitted signals from channel impairment
based on trained deep neural networks in an end-to-end manner . Furthermore, self-supervised learning is becoming a
trend for user localization since it has been demonstrated that
relevant methods can signiﬁcantly reduce the size of labeled
dataset for efﬁcient processing 
B. AI IN WIRELESS NETWORKS
In other essential layers of a wireless network, the existence of rich datasets lends itself to the applicability of
machine learning-based solutions. In routing protocol design
for wireless sensor networks, researchers have successfully
utilized reinforcement learning methods to achieve a more
energy-efﬁcient routing scheme for underwater sensor networks . In the vehicular industry, autonomous driving
has already been studied and become a reality in some cities
in Arizona, US.2 With respect to vehicular communication
2 
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
networks, due to the constant movement of vehicles, a predictive model based on real-time data has superiority over
traditional theoretical models in terms of accuracy. Artiﬁcial
intelligence and its plethora of algorithms can be applied in
varied ways in such networks: autoencoders for predicting
trafﬁc ﬂow , k-means clustering for trafﬁc congestion
control , and Q-learning for intelligent resource management , among others . In the Internet of Space
Things, with our envisioned multi-band communication capabilities in both inter-satellite and ground-to-satellite links,
we have proposed a deep neural network-based resource
allocation strategy to enable a ﬂexible scheme for Cube-
Sats to stay connected without human intervention from the
ground .
Apart from advancements in algorithm development,
a potential issue dwells on the location of data storage and
processing, which has largely happened in central data centers in the cloud. For devices distributed in a wide geographic
range, this undoubtedly adds signiﬁcant delays in performing
tasks which require real-time operation. Moreover, a centralized computing manner is not desired from perspectives
of data security and constraint in processing capacity .
In order to relieve such challenges, edge AI pushes local
devices to fulﬁl operation and management tasks. Admittedly, this could lead to possible overburden in local devices,
since they are not equipped with as powerful processing units
as the cloud processing center, however, research efforts in
this direction are dedicated to: (i) acceleration in boosting
the hardware’s processing capability, and (ii) leveraging the
coordination between local and central processing units to
optimization task distribution.
C. AI IN NETWORK MANAGEMENT AND ORCHESTRATION
AI, or more speciﬁcally ML, has an integral role to play
in the management of networks – . In fact, Clark
et al. introduced the concept of the Knowledge Plane 
back in 2003, describing it as a pervasive ML-based system
within the network that is geared towards providing services
and advice to other elements of the network. More recently,
with sofware-deﬁned networking (SDN) and network function virtualization (NFV) becoming mainstream, large-scale
data acquisition has become easier than ever before, making a strong case for ML-based management and orchestration primitives within 6G, ultimately leading to full network
automation as discussed in the next section.
In particular, the domain of network management presents
a wide variety of problems that can be broadly categorized
into: 
• Supervised Learning: Supervised learning is typically
applied to problems relating to trafﬁc prediction 
and classiﬁcation , as well as slice resource prediction . While the former primarily involves preemptively determining the network trafﬁc load, as well
as determining the applications, protocols and QoS
classes the trafﬁc belongs to, for ﬁne-grained trafﬁc
engineering, the latter involves predicting the resource
requirements associated with different network slices
based on the anticipated trafﬁc load.
• Reinforcement Learning: Reinforcement learning typically ﬁnds use in problems associated with resource
management , . For example, the popular virtual network embedding problem wherein the network
orchestrator performs optimal placement of virtual network functions onto the underlying physical substrate,
is highly amenable to reinforcement learning . Other
applications include elastic scaling of network infrastructure , failure prevention, and conﬁguration
rollback .
• Unsupervised Learning: While both supervised learning and reinforcement learning have shown signiﬁcant
promise in the network management domain, we note
that there exist certain use cases such as those relating to optimizing the end-users’ Quality of Experience (QoE) and network security where:
(i) labeled data for training is simply not present and
(ii) the real-time nature of the application makes it
impractical to wait for feedback. In such cases, unsupervised learning can prove to be an indispensable
tool. For example, intrusion detection systems based on
autoencoders have been shown to outperform supervised
learning-based systems .
D. OPEN PROBLEMS FOR PERVASIVE AI
During early years of 5G standardization, researchers have
discussed potentials of AI in achieving high time and
spectrum efﬁciency once incorporated in 5G. Speciﬁcally,
AI algorithms can help facilitate the following tasks which
would yield low efﬁciency with conventional solutions: identify network anomalies, allocate network resources, perform
network management, among others . However, so far
these solutions have not been ofﬁcially adopted in 5G standards worldwide. In June 2020, the ITU has initiated an
AI/ML in 5G challenge to motivate researchers to identify
and solve real-world problems using AI/ML solutions in
relevant 5G directions.3 As such, it is envisioned that such
efforts would be factored in later 5G development but will
be materialized in a more concrete and pervasive manner
While pervasive artiﬁcial intelligence in wireless communication networks will undoubtedly bring a paradigm shift
towards data-oriented approaches, there are still open problems to be resolved. First, thus far no agreement has ever been
reached on which algorithms work the best to solve a generalized problem in wireless networks, such as modulation
and coding scheme design, channel estimation, and resource
allocation, among others. Almost all published works claim
signiﬁcant accuracy or reduced complexity with either analytical theories or practical data sets . Additionally,
we note the absence of an effective method to draw a fair
3 
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
comparison among all proposed solutions, due to variations
in selected data sets, assumptions, evaluation criteria, and
so on. However, when it comes to realistic deployments,
a careful gleaning process should be performed in order to
identify algorithms without loss of general applicability. Second, the limited availability of quality datasets is detrimental
to the testing and validation of proposed classiﬁcation or
regression algorithms.
VI. NETWORK AUTOMATION
SDN and NFV have been widely recognized as the major
paradigm shifts that occurred with the advent of 5G .
In particular, SDN has paved the way for the separation of
the data and control planes, while NFV has been instrumental
in decoupling the software from the hardware. Consequently,
both wired and wireless networks have witnessed signiﬁcant beneﬁts from the adoption of SDN and NFV, including
but not limited to simpliﬁed network management and service deployment, availability of advanced trafﬁc engineering
solutions and ﬁne-grained network slicing techniques, and
reduced CAPEX and OPEX. A major contribution of network
softwarization has also been the commoditization of key
network components such as switches and base stations , , allowing for their implementation on commercial off-the-shelf (COTS) hardware. In addition, the large
open-source community supporting these projects has played
a pivotal role in engaging a wider set of stakeholders than was
previously possible.
As networks evolve further, the traditional network operations routine, rooted in manual conﬁguration and static
script-based primitives, cannot keep up with the increasing
complexity. Instead, we posit that automation will serve as the
major driving force behind building upon the improvements
brought forth by SDN and NFV. More speciﬁcally, network
automation is deﬁned as the process of automating the conﬁguration, management, testing, deployment, and operations of
physical and virtual devices within a network . Network
automation is intended to speed up the delivery of network
services while adhering to dynamic and robust service-level
agreements (SLAs), and reducing the potential for errors
through minimization of manual intervention.
Standardization efforts in this domain have led to the introduction of the Network Data Analytics Function (NWDAF)
in the control plane and the Management Data Analytics
Service (MDAS) in the management plane, for enhanced
data collection and analytics functionalities within 3GPP
Releases 15 and 16 , . Both these functions form
a critical segment of the Service-Based Architecture (SBA)
within 5G, highlighting the growing importance of network automation. To this end, we explore three key tenets
of network automation in this section– software-deﬁned
programmable data planes, automated service decomposition and orchestration, and self-driving networks. While the
ﬁrst two are primarily concerned with automating speciﬁc
aspects of the network, i.e., the data plane and the network slicing procedure, self-driving networks are the holy
grail of network automation, requiring absolutely no manual
intervention.
A. SOFTWARE-DEFINED PROGRAMMABLE DATA PLANES
Being the most popular Southbound API, OpenFlow 
is synonymous with SDN and has been featured widely
in 5G networks. Yet, the stateless match-action abstraction
implemented by OpenFlow precludes true data plane programmability since it relies largely on static header ﬁeld
matching. Within the context of this paper, we deﬁne data
plane programmability as a feature that allows data plane
devices, such as switches, to expose their packet-processing
logic to the control plane in order for it be completely recon-
ﬁgured if required. For example, the controller should be
seamlessly able to modify the packet parsing and processing
pipeline as required, add support for new protocols, and
modify existing ones. To this end, P4 is being increasingly recognized as ‘‘the programming language for the data
plane’’. P4 supports a wide variety of hardware ranging
from ASICs to commodity CPUs, and allows the controller
to specify: (i) a packet parser for extracting header ﬁelds,
and (ii) a collection of match-action tables that process these
Further, we note that the operation of many applications
depends upon the real-time state of the system, and relying
on the controller to update the forwarding state each time
introduces a signiﬁcant latency burden. Consequently, there
has been a growing body of research that seeks to develop
stateful data planes, wherein some of the stateful packet
processing and control tasks are ofﬂoaded to the data plane
switches – . For example, a stateful data plane
device may store some form of packet metadata, using it
to process new packets belonging to the same ﬂow. The
general packet forwarding rules are still set by the controller,
however, the presence of state information provides context
for rule selection at the switch level.
Programmable stateful data planes present a variety of
inter-related research challenges. First, there is a need for a
generic broad-based deﬁnition of state, along with abstractions that expose this state. Second, since packet-level state
maintenance will be done by distributed switching devices,
there is a need for a state consistency mechanism. A mechanism of this kind could potentially be enforced through the
controller, to prevent conﬂicting forwarding actions. Third,
security considerations present another important challenge.
If the data plane switches are going to perform actions based
on packet metadata, a malicious actor could easily use malformed packets to trigger state transitions for example. In this
case, ultra-lightweight mechanisms will be needed to verify
packet integrity.
B. AUTOMATED SERVICE DECOMPOSITION AND
ORCHESTRATION
Network slicing allows for the provisioning of differentiated services over the same physical infrastructure ,
and has been a major research focus in the cellular
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
FIGURE 6. Automated network slicing framework.
domain – . However, the slice instantiation and
deployment process is largely template-driven and requires
manual conﬁguration. For example, current 3GPP network
slicing speciﬁcation is primarily based on the concept of network slice templates (NSTs). An NST explicitly
deﬁnes the virtual network functions (VNFs) and associated service function chain that comprise a network service. Consequently, such network slicing primitives allow
for the deployment of a limited set of network services,
i.e., only those services for which a template has already
been deﬁned. Clearly, an approach of this kind is not
scalable because: (i) it does not provide a mechanism to
deal with new kinds of network services, and (ii) as network services increase in complexity, the effort required to
create and maintain templates will become an operational
Going beyond the traditional template-driven model,
we propose the concept of automated service decomposition
and orchestration for network slice automation, as shown
in Figure 6. To this end, and in line with 3GPP terminology, we identify three major stakeholders– the communication service customers (CSCs), the communication
service providers (CSPs), and the virtual infrastructure
service providers (VISPs). The CSCs request communications services from CSPs, who instantiate network slices and
deploy them over infrastructure owned by VISPs to deliver
the requested services. As part of the slice automation work-
ﬂow, the CSCs provide high-level requirements such as those
relating to latency, throughput, reliability, etc., along the lines
of the emerging intent-based networking paradigm .
Next, the CSC automatically decomposes the request into a
constituent VNF-forwarding graph (VNF-FG). It is important to note here that the service to VNF-FG mapping is
not a based on a template, but instead makes use of deep
learning models to extract service requirements and construct
the corresponding VNF-FG. The resulting service-speciﬁc
VNF-FG also contains the resource requirements for the
constituent VNFs, allowing for seamless deployment onto
the underlying infrastructure. Once the service has been
deployed, continuous monitoring and real-time telemetry are
used to ensure operational optimality.
C. SELF-DRIVING NETWORKS
For decades, the network operator has served as the
centerpiece of network operations. However, the increasing
complexity of communications networks coupled with the
constant state of ﬂux brought forth by an ever-increasing
number of connected devices has made the task of real-time
network management nearly impossible for human operators. Therefore, there is a strong case for transitioning from
operator-driven networks to self-driving networks. More
speciﬁcally, self-driving networks are expected to allow for
elastic utilization of resources, error-free operation, prompt
and targeted responses to security incidents, and proactive
rather than reactive service handling [126, §2].
Seeking complete automation of network management,
a self-driving network is deﬁned as a network where: (i) network measurements are task-driven and tightly integrated
with the control of the network, and (ii) large-scale data
analytics and machine learning models are used for network
control, as opposed to closed-form models of individual protocols . In a nutshell, self-driving networks should be
capable of measuring, analyzing, and controlling themselves
in an automated manner . At the outset, a self-driving
network should take a high-level goal or intent as input.
Expanding upon the concept of intents, we note that there
are broadly two types of intents– imperative and declarative.
While the former describes in explicit detail how a particular
procedure should be carried out, the latter just describes the
end-goal without specifying how the stated goal should be
achieved. For example, ‘‘reduce network congestion by shifting incoming trafﬁc originating at ingress node 1 from load
balancer 2 to load balancer 3’’ is an imperative intent since
it explicitly deﬁnes the steps that network must undertake in
order to relieve congestion.
On the other hand, ‘‘optimize network operations’’ is a
declarative intent. However, a truly declarative intent of the
kind described here would be extremely difﬁcult to implement in the near future. Instead, semi-declarative intents
that deﬁne more concrete goals would be far more helpful.
‘‘Minimize network congestion’’, is one example of such an
intent since it tasks the network with optimizing its operation by focusing on a speciﬁc objective, i.e., minimizing
congestion. Based on the intent, the network is expected to
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
FIGURE 7. High-level architecture for self-driving networks.
determine: (i) the measurements that need to be performed,
(ii) the corresponding inferences and learning that is required,
and (iii) the actions that must be undertaken in response to the
input intent. While a formal representation for self-driving
networks is yet to be realized, a high-level architecture has
been presented in Figure 7, highlighting the importance of
large-scale data acquisition, real-time analytics and inference,
and programmable data planes.
However, the realization of self-driving networks brings
forth several research challenges as described next.
• Accurate Intent Deﬁnitions: As discussed previously,
good intent deﬁnitions must toe the line between imperative and declarative. If the intent is primarily imperative,
it defeats the point of automation. On the other hand,
if the intent is purely declarative, the automation procedure becomes unnecessarily complex. Therefore, there
is a pressing need for formal guidelines that put forward
a clear framework for intent deﬁnitions. For example,
a framework of this kind could take into account customer expectations in terms of throughput and latency,
network-wide resource optimization goals, along with
other application-speciﬁc functions and services that are
required from the network.
• Automated Real-time Inference: Machine learning
is vital to the automated decision making process in
self-driving networks. However, previous work in this
domain has largely focused on applying pre-existing
learning techniques for network control, which are not
well-suited for network data, given its high-volume,
distributed nature, and rapid evolution. The major challenge here is the native integration of inference and
control algorithms with the network’s decision and control fabric. In addition, network design needs to evolve
to improve the quality of data that is input to the
designed control algorithms . Within the domain of
self-driving networks, it is widely accepted that quality
of data (QoD) is a pre-requisite for quality of service
(QoS) .
• In-band Telemetry: Research into in-band telemetry (INT) has been largely driven by the need for high
quality network monitoring data, without introducing
additional overhead. The INT approach makes use of
programmable data planes to encapsulate additional
metadata within the data packets themselves .
Examples of such metadata include switch processing
times, buffer occupancy levels, and even speciﬁc policy
rules. As packets traverses the network, they keep accumulating additional metadata, which can be extracted
as desired, thus providing highly-detailed accurate sets
of network data. To this end, there is a need to quantify the impact of INT on network performance .
In particular, metrics such as the relationship between
the amount of metadata and packet size, the additional
processing burden introduced, and the accuracy of the
measurements obtained are all important parameters that
merit careful consideration.
VII. 6G RADIO: RECONFIGURABLE TRANSCEIVER
FRONT-ENDS
The massive increase in the number of wirelessly interconnected devices, combined with the ever-growing demand
for higher wireless data rates, is leading to an overcrowded
electromagnetic (EM) spectrum. To overcome the spectrum
scarcity problem and increase the capacity of wireless networks, communication at frequencies beyond RF (i.e., from
the mmWave to the THz bands) is required. To meet the
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
data-rate, reliability, and scalability requirements from RF
to THz, transformative solutions are needed which include
the design, implementation, and optimization of frequencyagile, ultra-broadband reconﬁgurable systems. A system of
this kind is able to simultaneously sense and communicate
over the full EM spectrum (1 GHz to 10 THz), and serves
as a major contributor towards the infrastructure needed for
the next generation of wireless communications. To realize
this vision, pioneering contributions are required in terms
of: (i) new devices that surpass the limits of CMOS technology by leveraging the state-of-the-art in materials science
and nanoscale physics, (ii) heterogeneous integration of such
devices which is compatible with the electrical, thermal, and
EMI requirements for reconﬁgurability and manufacturing
scalability, and (iii) novel all-spectrum dynamic sensing and
communication algorithms, which maximize the achievable
network capacity.
The primary goal for 6G radio is to establish dynamic
all-spectrum sensing and communication from RF to THz
bands, therefore, transforming the way in which wireless
devices sense, access, and share the EM spectrum. To achieve
such a goal, key steps include: (i) intelligent all-spectrum
sensing solutions, (ii) transceiver hardware design and implementation, and (iii) spectral and energy efﬁciency optimization as well as resource management. It is worth noting
that currently reported works are fulﬁlling part of this grand
goal by achieving dynamic spectrum sensing or multi-band
communications over several frequency bands. It is our hope
to motivate advanced solutions to realize all-spectrum communications through this section.
A. DYNAMIC ALL-SPECTRUM SENSING AND ACCESS
In recent times, a concentrated research effort at the physical
and link layers has driven exciting progress at RF frequencies
for individual cognitive radios (CRs). For example, a recently
awarded research project by the Research and Innovation
Program in the United Kingdom named ‘‘6G Mitola Radio’’
aims to establish self-regulating societies for wireless communications with fairness and high efﬁciency.4 This research
will facilitate seamless convergence across heterogeneous
wireless networks with intelligent decisions made by radios
to maximize the quality of experience for end-users.
One step further, a major challenge is to develop innovative spectrum sensing and sensing-informed communication
and network optimization techniques for dynamic access to
all-spectral resources. Within this context, the targeted breakthrough would be the development of wireless network-aware
state inference using all-spectrum cartography for cognition
over the swath of frequencies from RF to the THz bands,
along with cartography-constrained algorithms for the physical and cross-layer control protocols. Artiﬁcial intelligence
and associated learning algorithms should be investigated for
dynamic spectrum sharing with a minimum cost in inter-
4 
ference. The techniques developed should wholly exploit
the capabilities of the hybrid front-ends, which include a
multi-band transceiver design and solutions for resource management.
B. MULTI-BAND TRANSCEIVER DESIGN
The optimal selection of materials and devices needed to
enable all-spectrum communications is vital to the success of any multi-band transceiver design. Existing solutions
mostly rely on CMOS for multi-band operations, but such
an approach only works well in narrowbands. Moreover,
solutions based on software-deﬁned radios (SDRs) have high
energy consumption and carbon footprint, consuming several
Watts in operation , . Instead, novel approaches
based on metamaterials, MEMS switches, and even nanoelectromechanical systems (NEMS) switches should be sought
to implement hybrid front-ends (Figure 8), which are able
to simultaneously sense the EM spectrum, identify the best
available band, and communicate over it, at frequencies anywhere from 1 GHz to 10 THz. Furthermore, fast-evolving
deep learning algorithms serve as an efﬁcient solution for
identifying available spectrum, tuning channels, and adjusting RF power levels.
To realize this vision, new techniques in materials and
devices, integration and packaging, and spectrum sensing
and communication are necessary. At the RF and microwave
frequency bands, a combination of low-risk mature CMOS
technology, with less-mature, potentially transformative technologies, including quantum cascade lasers (QCLs) and
new plasmonic technologies based on graphene and other
2D materials will be able to provide optimal tunabilities as well as a high quality factor (i.e., the Q-factor).
The heterogeneous integration of discrete devices into a
fully functional front-end will require innovation to satisfy
material compatibility, EMI shielding, thermal dissipation,
and scalability requirements. On the other hand, metamaterial and nano-materials will be deployed at sub-THz
and THz bands, based on recent advances in nano-tubes
and graphene, as well as other single-atom-thin semiconductors. Space-time-frequency coding in metasurfaces will
also allow programmable and ﬁne-tunable radio access at
mmWaves. Optimal control of the front-ends requires innovative all-spectrum sensing, utilization and sharing techniques,
new waveform and hierarchical modulation designs to maximize the capacity and distance in ultra-broadband systems,
and scalable networking solutions which are able to support
the envisioned node density in future cyber-physical systems.
The combination of several cutting-edge techniques can
help maximize: (i) spectrum utilization (toward all-spectrum
utilization), (ii) data-rates (toward terabit-per-second links)
and, (iii) network user capacity (billions of interconnected
wireless devices). The proposed technology will enable a
plethora of applications in the consumer, military, industrial and medical ﬁelds, including transformative networking
architectures designed to meet the scalability demands in
future cyber-physical systems.
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
FIGURE 8. Conceptual design of a hybrid front-end for dynamic all-spectrum sensing and communication in 6G.
C. RECONFIGURABLE FRONT-END SCHEME
Accompanying
all-spectrum
multi-band operation, agile front-ends should also be
equipped with reconﬁgurability. In terms of hardware design,
the plasmonic reﬂectarrays can be deployed in the 3D
environment, with a size ranging from 1 mm2 to 100 mm2
depending on the operating frequency (mmWave/THzband). Owing to the sub-wavelength size of their elements,
the plasmonic reﬂectarrays are able to reﬂect signals in
non-conventional ways, which include controlled reﬂections
in non-specular directions as well as reﬂections with polarization conversion . In order to adapt to dynamic frequency operation, achieve various levels of directivity, and
allocate multiple beams, the aperture of plasmonic reﬂectarray antenna can be controlled mechanically through folding, splitting, or combining in a 3D space. Existing prior
art using origami antennas works well in systems using a
single metal antenna, as reported in , . However,
to achieve reconﬁgurable continuous aperture antenna arrays,
plasmonic reﬂectarrays offer a higher degree of freedom with
the compactness of unit element distribution.
On the other hand, electronically-controlled reconﬁgurable
antenna arrays are envisioned by leveraging the tunability of
plasmonic antennas. In particular, one of the relevant properties of graphene-based plasmonic nano-antennas is the possibility to change their resonant frequency by utilizing a small
voltage to modify their Fermi energy . The possibility to
tune an antenna (or group of antennas) at different frequencies
without any mechanical modiﬁcation (as opposed to other
multi-band antenna arrays that utilize MEMS or NEMS to
create origami type structures ) enables beamforming
not only across space but also across frequencies.
D. OPEN PROBLEMS
The biggest hurdle to be overcome lies in the implementation of an integrated ultra-broadband hybrid front-end that
is capable of sensing and communication from the RF to
the THz bands, over a target distance of a few hundred
meters. Meeting this multidisciplinary challenge requires us
to: (i) close the THz gap by developing new device technologies, (ii) design and integrate re-programmable circuitry,
interconnects and antennas that can support all-spectrum
operation, (iii) develop new material integration and packaging techniques to satisfy the electrical, thermal and EMI
requirements of disparate bands, and, (iv) develop scalable
all-spectrum communication using the front-ends.
VIII. AMBIENT BACKSCATTER COMMUNICATIONS
In the realm of IoT, sensors are expected to function in various
environments with long-lasting battery life. Solutions such as
radio frequency identiﬁcation (RFID) utilize the backscatter technique to modulate and reﬂect RF signals instead
of generating them, which can achieve a signiﬁcant degree
of energy saving. However, existing modulated backscatter
solutions have stringent requirements in terms of the proximity between the backscatter transmitter and the RF source, due
to the attenuation of the signal over long distances. Besides,
the modulated backscatter transmitters are passive, which
means that they cannot transmit data without requests initiated by backscatter receivers . Furthermore, the issue
of self-interference may arise when the backscatter receiver
and RF sources are co-located. Hence, in order to achieve
better energy efﬁciency with a higher degree of ﬂexibility
and scalability, new solutions are required in the 6G IoT
Currently, with more small cells being deployed in outdoor and more access points in indoor environments, the RF
signals are covering a wide range of surroundings, and can
be considered as a resource to be utilized by secondary
radio links without requiring extra power. The system that
employs such a technique is called an ‘‘ambient backscatter
communication system’’. In an ambient backscatter communication system, transmitters can harvest the surrounding and
continuous electromagnetic waves radiated by TV towers,
base stations, as well as access points, use simple circuits
for modulation, and reﬂect them towards receivers. There
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
FIGURE 9. Illustration of backscatter communication systems.
is no need for dedicated spectrum bands for such ambient
backscatter transceivers to operate, nor complex electronic
components (e.g., analog-to-digital converters) to process
A. OPERATION PRINCIPLES OF BACKSCATTER
COMMUNICATIONS
In general, as the name suggests, backscatter communication
systems reﬂect signals impinged on a backscatter transmitter
in the direction of the signals’ origin, and since it is not a
perfect specular reﬂection, the signals are scattered within
a certain angular range of the environment. A backscatter
communication receiver within the range can thus pick up the
signals. In particular, backscatter communications have three
variations in terms of architecture, which are monostatic,
bistatic, and ambient backscatter communications, respectively. Here we brieﬂy explain the ﬁrst two types and then
focus on the last one.
As the most commonly adopted backscatter communication approach with widely-used RFID applications, monostatic backscatter communication systems have the simplest
setup, which consists of a backscatter transmitter and a reader.
The reader has both an RF signal source and a backscatter receiver embedded with a switch to change the operation mode. Once the receiver sends out a request, the RF
source activates the backscatter transmitter, which then modulates and reﬂects the EM waves impinged on it back to
the receiver, as shown in Figure 9. Such a design is mainly
used for short-range RFID applications . Nonetheless,
two drawbacks of the monostatic backscatter communication
architecture are (i) the reader cannot perform full duplex
communication due to the switch mechanism, and (ii) the
signals experience round-trip path loss being sent from
the reader to the transmitter and then reﬂected back to the
On the contrary, in the bistatic backscatter communication architecture, the RF source and receiver are separated, as shown in Figure 9, which provides higher ﬂexibility in the spatial domain. With multiple RF sources and
backscatter transmitters well placed, the serving range can be
remarkably extended compared to the monostatic backscatter
scenario. Despite this improvement, it is more costly for
bistatic backscatter communication systems to operate in real
networks, since they require RF sources and transmitters to be
well-placed so as to achieve desired performance, and most of
the times this condition can be difﬁcult to satisfy, especially in
a sophisticated network environment, such as an indoor ofﬁce
or dense urban scenarios.
B. MECHANISM OF AMBIENT BACKSCATTER
COMMUNICATIONS
Different from the monostatic backscatter device where
the transmitting and receiving components are separately
located and the RF source is co-located with the receiver,
devices of ambient backscatter communication systems consist of both the transmitter and receiver. Additionally, distinct
from bistatic backscatter communications, ambient backscatter communications do not require dedicated RF sources
to provide exclusive services, which can reduce infrastructure and maintenance expenditure signiﬁcantly. Therefore,
the ambient backscatter communications provide the most
energy-efﬁcient solution for sensors in the IoT network in 6G.
Speciﬁcally, in one proof-of-concept study for utilizing the
always-on radio signals for ambient backscatter communications reported in , TV signals serve as the RF source,
which can be amplitude and sometimes frequency-division
modulated.
In the ambient backscatter transmitter design, a simple
switch consisting of a transistor and connected to the antenna
can be used to modulate the impedance of the antenna: a
mismatch of impedance indicates a reﬂection mode of the
impinging signals, whereas a matched impedance allows for
the signal being absorbed by the antenna . The power
consumption of such 1-bit modulation of signals is minimal.
At the receiver side, by demodulating the received sequence
of ‘‘1’’ and ‘‘0’’, signals can be successfully recovered.
However, it is worth noting that since the reﬂected signals from the ambient environment already contain encoded
information from the RF source system (e.g., cellular or
TV networks), the receiver design should take into consideration how to extract the backscattered signals from the
Besides the simplicity in transceiver implementation,
ambient backscatter communications are not restricted to
a single-band operation. In fact, the ambient backscatter
transceivers can operate in the wide range of super high
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
FIGURE 10. Illustration of the IoST .
frequency (SHF) bands, covering Bluetooth, Wi-Fi, and other
bands .
C. OPEN PROBLEMS IN AMBIENT BACKSCATTER
COMMUNICATIONS
• Spectral and Energy Efﬁciency: Currently, the research
and development of ambient backscatter communications is still in its infancy. As mentioned before, careful
planning of backscatter devices is crucial for achieving
good performance. Due to the randomness in IoT device
deployment, current solutions fall behind in terms of the
targeted spectral efﬁciency. Speciﬁcally, the randomlylocated IoT devices should utilize ambient backscatter
links to achieve a satisfying throughput while maintaining an extended transmission distance. Additionally, even though individual backscatter communication
devices demonstrate good energy performance, an IoT
network comprising hundreds or even thousands of
such devices might still require optimization of energy
efﬁciency on a system level.
• Protocol Design: Existing ambient backscatter communication systems are mostly used for dedicated
application-speciﬁc purposes, and thus lack good compatibility with other wireless communication systems.
Standardization and protocol design are necessary to
formalize the key operation and management aspects
of ambient backscatter communications, such as packet
size, routing protocols, among others.
IX. INTERNET OF SPACE THINGS WITH CubeSats AND
The Internet of Space Things (IoST) is a spatial expansion
of the Internet of Things which primarily focuses on terrestrial use cases. For future communication networks, this
expansion is necessary for the following reasons: (i) the IoT
relies heavily on existing infrastructure and hence lacks ﬂexibility as well as scalability, (ii) global coverage is impossible
using traditional IoT solutions, especially in remote areas
including the North and South Poles, due to the imbalance
of construction expenditure and service revenue, and (iii)
limited heterogeneity and spectrum resources in the IoT
envisioned
ubiquitous
cyber-physical system spanning ground, air, and space, with
applications in monitoring and reconnaissance, in-space
backhauling, and holistic data integration . More specifically, as shown in Figure 10, IoST consists of the ground
station, customer premises, and on-Earth sensing devices
which form the ground segment, and the CubeSats, UAVs,
and near-Earth sensing devices that form the space segment. The ground-to-satellite links (GSLs) connect the IoST
Hubs with CubeSats to exchange requests and data, and the
inter-satellite links (ISLs) relay information to neighboring
CubeSats, in both the same orbit as well as adjacent orbits.
Further, the UAVs establish links with each other, as well as
sensors and CubeSats to form a localized data aggregation
layer. To this end, we note that UAVs are expected to feature
heavily in the upcoming 3GPP Releases 16 and 17 .
Further, since the space segment forms a vital component
of the system, research relating to the development of small
satellites, or CubeSats , for use within IoST is of critical
importance .
CubeSats are a set of miniaturized satellites with sizes
ranging from 1U to 6U (a ‘‘U’’ is 10 × 10 × 10 cm3).
Currently, CubeSats are being deployed for a variety of
applications including Earth sensing , positioning, and
IoT and machine-to-machine communications. Compared
to traditional LEO satellites, CubeSats present a number of advantages relating to (i) lower costs and shorter
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
FIGURE 11. Conceptual design of a next-generation CubeSat .
development cycles and (ii) higher ﬂexibility and scalability . Normally the development cycles range from three
to seven years for traditional LEO and GEO satellites and
the costs are extremely high. Also, since the payloads are
pre-determined in the LEO and GEO satellites from the
period of development until deployment, it is difﬁcult to
reconﬁgure any component in the middle of the process.
However, CubeSats’ development can be done in a remarkably shorter time using COTS components with much lower
costs. This also guarantees that CubeSats are easily reconﬁgurable.
next-generation
in Figure 11 . The proposed CubeSat design includes an
all-new communications subsystem for seamless operation
in a wide variety of frequency bands. More speciﬁcally,
the novelty of our design concept is characterized by the
presence of multi-band transceivers and antennas that are able
to support wireless communications at microwave, mmWave,
and THz frequencies as detailed in the following section.
Through this unique CubeSat design, we can potentially
achieve data rates in excess of 100 Gbps .
A. MULTI-BAND COMMUNICATIONS SUBSYSTEM
The primary motivation for a multi-band communications
subsystem comes from the fact that existing CubeSats
have limited communications capabilities, largely relying
on spectrum ranging from the L- (1–2 GHz) till the Ka-
(26.5–40 GHz) band. There are two major drawbacks associated with this approach. First, the traditional frequency
bands are becoming increasingly prone to congestion .
Second, the Tbps-level throughput required by IoST cannot
be achieved with existing frequency bands. To overcome
the spectrum scarcity and capacity limitations in current
satellite networks, we have proposed the use of multiple
frequency bands from RF to THz spectrum, in IoST .
The use of such frequencies has been made possible by
advances in high-frequency device development , .
More speciﬁcally, as part of the multi-band communications subsystem, we have developed both multi-frequency
transceivers as well as antenna systems, as described next.
As shown in Figure 12, in our proposed multi-band
transceiver, we use two complementary approaches, namely,
an electronic frequency up-converting chain and an optical frequency down-converting chain, to generate signals at
different frequencies. With regard to the electronics-based
approach, the primary idea is to use frequency splitters in
order to extract the intermediate frequencies for outputs. For
example, as shown in Figure 12, the signal at frequency f1 is
considered as the intermediate output when producing signals
at a higher frequency f2.
photonics-based
involves the down-conversion of optical signals. As shown
in Figure 12, multi-band signals are generated by heterodyning two input signals with a Mach-Zehnder modulator. The resulting RF signal has a frequency equal to the
difference between the two inputs. The generated signal,
along with the two input signals, serves as the ﬁnal output. Distinct from the commonly used up-conversion and
down-conversion techniques where intermediate frequency
products are abandoned, our approach harvests them and
utilizes them as part of the multi-band communication system. These multi-band frequencies can be assigned to the
GSLs and ISLs dynamically to accommodate various service
requirements. To this end, within IoST, the GSLs make use of
the more robust microwave and mmWave frequencies, while
high-capacity THz links form the ISLs.
In addition to multi-band transceivers, CubeSats in the
IoST are also equipped with multi-frequency antenna systems. In particular, as discussed in Section III, the use of THz
links allows for very large antenna arrays that serve as the
basis for massive MIMO and UM MIMO communication
schemes. More speciﬁcally, we note that there exist multiple
options when it comes to the design of multi-band antenna
arrays. The ﬁrst approach involves the use of NEMS, MEMS,
and origami structures to create physically re-conﬁgurable
antennas, wherein the size of the radiating elements can be
changed physically with a view to adjust their resonant frequency. On the other hand, the second approach proposes the
use of materials such as graphene to create electronically tunable nano-antenna arrays , . In this case, the resonant frequency can be controlled by modulating the graphene
Fermi energy or chemical potential. This allows for tuning
of the antenna to resonate at different frequencies without
physically changing its size, in contrast to the MEMS-based
B. SYSTEM CONSTELLATION DESIGN
Within the context of IoST, an ideal constellation design
is crucial to achieve true global coverage and satisfactory
link performance. However, conventional LEO constellations
are typically characterized by the presence of fewer than
a hundred satellites, for example, the CubeSat-based IoT
system, Astrocast, has a maximum of 64 satellites .
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
FIGURE 12. The proposed all-spectrum signal front-end designs .
At the outset, the coverage and connectivity offered by such
systems leaves much to be desired. Motivated by the need
for improved coverage, reliable connectivity, and increased
redundancy, mega-constellations of several hundred satellites
have gained signiﬁcant traction over the past year .
Mega-constellations provide several advantages over traditional constellations including but not limited to increased
coverage density, improved connectivity, and higher redundancy.
More speciﬁcally, constellation design typically involves
solving for several inter-related parameters such as: (i) the
apogee and perigee radii, (ii) the orbital eccentricity, (iii) the
number of CubeSats per orbital plane, (iv) the number of
orbital planes, and (v) the initial longitude of the ascending
node, argument of perigee, and true anomaly of the CubeSats.
While a fairly challenging problem in itself, the presence of
an extremely large number of satellites further serves to complicate the system design. Consequently, the existing stateof-the-art constellation design frameworks are largely geared
towards the design of systems with a few dozen satellites
at best. To this end, we have proposed a highly-scalable
and customizable constellation design framework that takes
into consideration both coverage and connectivity parameters . Through the use of novel metrics such as spherical Voronoi tessellation based coverage characterization and
ISL feasibility-based connectivity parameters, we are able to
demonstrate that the resulting IoST constellation achieves a
performance level that is similar to existing state-of-the-art
mega-constellations such as Starlink, while requiring only a
quarter, i.e., less than 500, of the satellites .
C. NETWORK MANAGEMENT
IoST encompasses a vast infrastructure spanning both the
Earth as well as space. A complex network of this kind has
much to beneﬁt from ﬁne-grained real-time control that is
well suited for tackling the peculiarities of the space environment, namely temporal topological variation and long delays.
Going beyond the traditional bent pipe nature of satellite
communications systems, IoST makes extensive use of SDN
and NFV to signiﬁcantly improve network resource utilization, simplify network management, and reduce operating
costs . In a manner similar to the infrastructure-as-aservice (IaaS) paradigm, IoST intends to deliver CubeSatsas-a-service, with promising results as shown in .
In particular, we have demonstrated that through the use of
SDN, it is possible to achieve sub-second end-to-end latencies.
More speciﬁcally with the domain of network management, IoST introduces the novel concepts of virtual
CSI (vCSI) for joint optimal physical-link layer resource allocation, and stateful segment routing (SSR) for overcoming
challenges associated with the high latency space segment.
In particular, concerning the latter, IoST extends the traditional SDN paradigm by including support for state-based
packet forwarding that takes into account the topological
conﬁguration of the network at any given instance of time,
while the use of segment routing helps in the minimization
of control trafﬁc, in addition to a higher level of demand
satisfaction and load balancing as demonstrated in . Further, IoST also employs predictive algorithms to preemptively
detect GSL outage events, which when coupled with gateway
diversity result in the realization of proactive handovers that
minimize handover interruption time. In addition, IoST proposes the use of containzeration in CubeSats for achieving lightweight hardware virtualization without signiﬁcant
overhead. Going forward, we note that the aforementioned
techniques will play a vital role in the realization of pervasive
cyber-physical systems of this kind.
X. CELL-FREE MASSIVE MIMO COMMUNICATIONS
In 5G wireless networks, massive MIMO communications
have been tested and deployed at base stations (BSs) which
are equipped with more than one hundred antenna elements
to increase the antenna array gain and take advantage of the
diversity gain. A related concept is network MIMO, which,
instead of packing more than one hundred antenna elements
at a single BS, forms a coordinated framework consisting of
multiple BSs, each with multiple antennas. A coordination
scheme of this kind can achieve spatial diversity by allowing a
single user to be served by more than one BS at the same time,
overcoming the disadvantage of bad channel conditions if
only one BS is connected to the user, and eliminates inter-cell
interference . However, a detailed comparative study has
shown that massive MIMO communication schemes outperform network MIMO with respect to end-user received signal
strength and overall costs in conﬁguration .
Going one step further, in order to effectively eliminate inter-cell interference caused by users located at cell
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
FIGURE 13. Cell-free massive MIMO in comparison with classic massive MIMO.
boundaries, based on the ideas of distributed MIMO communications and coordinated multi-point (CoMP) communications, researchers have proposed the concept of cell-free
massive MIMO communication. In a scheme of this kind,
the originally densely-packed antenna array set with a few
hundred elements at the BS is distributed in a fairly large
area in the form of smaller sets with fewer than 10 antenna
elements, while still serving a similar number of users in the
same area . As shown in Figure 13, the main difference
between cell-free and classic massive MIMO communication
systems is that instead of associating each user terminal to
a cell with a BS equipped with a large number of antenna
elements, it relaxes the restriction of cell boundaries, which
can signiﬁcantly reduce or even eliminate the inter-cell interference. Without cell boundaries, all BSs, or a subset of
BSs, can serve users simultaneously in a coordinated manner.
In coordination, the cell-free massive MIMO BSs can share
with each other the data to be sent to users through fronthaul
It has been shown that the BSs can use their local channel
state information (CSI) to achieve satisfactory performance
and avoid the excessive computation complexity associated
with sharing global channel conditions with all BSs .
The local CSI can be estimated in the uplink channel in
a time division duplex (TDD) mode. Then, precoding is
performed based on the obtained channel information at
the BSs, before data transmission in the downlink channel. The transmit power and precoding vector can be determined based on the geographic proximity of users to the
Compared to the small-cell architecture in 5G, which
consists of non-cooperative base stations that can serve up
to 100 users per cell with a smaller area (e.g., up to a
200-meter cell radius) and reduced power in signal transmission (e.g., up to 10 Watts), a cell-free massive MIMO
communication system achieves signiﬁcantly better performance, since each user can be served by a dedicated access
point. A reported study in has demonstrated that
the cell-free massive MIMO scheme improves 95%-likely
per-user throughput by ﬁve times and by ten times under
correlated shadow fading, with respect to the small-cell solution. More speciﬁcally, the same study has reported that
when considering realistic channel conditions, including pilot
contamination and imperfect CSI, cell-free massive MIMO
systems demonstrate much higher throughput compared to
small cells and, more importantly, are more robust to impacts
such as shadow fading, non-coherence interference, as well as
noise .
However, we also note the following challenges: (i) due to
the issue of aliasing, channel estimation for signals received
by different antenna elements is more complicated compared to that of ordinary massive MIMO communications,
(ii) with the signiﬁcantly increased synthesized aperture
size, the range of near-ﬁeld propagation grows larger, hence
requiring a different channel model for characterizing the
large- and small-scale channel parameters.
A. CHANNEL CHARACTERISTICS OF CELL-FREE MASSIVE
MIMO COMMUNICATION SYSTEMS
It has been theoretically proven that as the number of antenna
elements approaches inﬁnity, adversarial channel effects,
including inter-cell interference, small-scale fading, and others, will disappear . In cell-free massive MIMO communications, such effects will also have a negligible impact
on propagation channels. Speciﬁcally, channels under a coordinated scheme of this kind will satisfy the conditions of
favorable propagation . Favorable propagation conditions imply that the channel vectors between the BSs and UEs
are orthogonal, so that the sum-rate can be maximized. This
characteristic is most prominent in classic massive MIMO
communications . In cell-free massive MIMO systems,
it has been shown that favorable propagation conditions can
be achieved given that the number of APs is fairly large (with
an approximate density of 1000/km2).
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
B. OPEN PROBLEMS IN CELL-FREE MASSIVE MIMO
COMMUNICATIONS
As the domain of cell-free massive MIMO communications
is relatively new, there are several open problems that merit
further investigation. Among them, we posit that coordination
and optimization challenges will critically affect the entire
system performance and future deployments.
Scheduling:
conducted on channel characterization and capacity
analysis. However, the prior art does not take into
consideration scenarios involving networks with a large
number of users to serve. In such cases, there might
be an upper bound for the number of APs to serve a
user in order to maintain an acceptable-level of average
throughput. Current works assume that all users will
be served simultaneously under the same frequency
resource block. However, when the number of users
grows to a threshold where they can no longer be served
at the same time, a scheduling scheme that achieves
fairness should be considered.
• Location Optimization of APs: Existing works in cellular networks draw heavily upon stochastic geometry
where cell structures follow 2D Voronoi tessellation
and geographically separated BSs that serve cell-edge
users under the coordinated multipoint (CoMP) scheme
to improve overall system efﬁciency and overcome
inter-cell interference through scheduling , .
It is therefore crucial to optimize the placement of BSs
under practical link-level constraints such as signalto-interference ratio as well as success probability for
individual links to enhance network fairness .
In cell-free massive MIMO, since no cell boundaries
are assumed, system-level performance pertaining to
locations of APs, random scatterers, as well as users
should be thoroughly investigated and optimized.
XI. TECHNOLOGIES FOR BEYOND 6G
Thus far, we have presented in great detail the key drivers that
are expected to play an integral role in the next-generation of
wireless networks. However, in addition to these, we also note
the presence of several promising early-stage technologies
that are tipped to revolutionize how we perceive data communications in the near future. To this end, in this section, we discuss three such promising paradigms, namely, the Internet
of NanoThings, Internet of BioNanoThings, and quantum
communications.
A. INTERNET OF NanoThings
In addition to the need for more spectrum resources to accommodate a plethora of wireless devices and services, a variety
of transformative wireless communications scenarios are also
envisioned to become a reality in the near future. In particular, with the advent of wireless ubiquity, we note the existence of situations where electromagnetic waves do not yield
acceptable performance or lack reachability due to hardware
limitations, such as in high-salinity water or intravascular
channels where the transmission range can be extremely
short. In the aforementioned application scenarios for THz
band communications, as the frequencies of operation
increase, the wavelengths of signals fall into the nanometer
range (i.e., 10−9 to 10−7 meter in size), thereby motivating studies on nano-network communications , .
Different from those operating at lower frequencies in the
microwave range, the devices and transceivers used in the
Internet of NanoThings (IoNT) are in the scale of nanometers,
and thus behave differently from classical wireless communication systems.
Given the much smaller size, each nano-thing consumes
much less energy and is envisioned to be self-powered (e.g.,
via vibrational energy harvesting using piezoelectric nanogenerators ). Besides conducting signal transmission
tasks, the nano-things can also perform basic processing and
data storage, as well as enabling new nano-sensing capabilities with higher sensitivity. Current advancements in nanotechnologies provide several promising candidate materials
with various dimensions for creating such nano-machines,
including a thin strip of graphene named graphene nanoribbons, graphene in form of a three-dimensional (3D) roll
named carbon nanotubes, and graphene spheres.
Communications in the paradigm of nano-networks mainly
falls under two categories, which are (i) encoded signal bits being carried with molecules, which follows a
diffusion-based mechanism elaborated in Section XI-B1
and (ii) plasmonic radiation on metamaterial-based antennas including graphene and carbon nano-tubes operating in
the THz band. These plasmonic antennas , – 
leverage the physics of Surface Plasmon Polariton (SPP)
waves, i.e., conﬁned EM waves resulting from the global
oscillations of electrons at the interface of a conductor material and a dielectric material, to efﬁciently radiate at the
target resonant frequency while being much smaller than the
corresponding wavelength. This property allows them to be
integrated in very dense arrays, beyond traditional antenna
arrays. The ratio between the free-space wavelength λ and the
SPP wavelength λSPP is known as the plasmonic conﬁnement
factor, and depends on the plasmonic material properties and
the operation frequency. The higher the conﬁnement factor,
the smaller the antennas and the higher the density in which
they can be integrated.
1) ESSENTIAL COMPONENTS IN THE IoNT
Similar to traditional communication networks, several key
components are seen in IoNT :
• Nano-nodes are the basic functional units in the
nano-network, and have sizes ranging from 1 to
100 nanometers, and can form a cluster to forward
and receive signals. A typical nano-node with full
transceiving capability contains the following elements:
a nano-antenna and a plasmonic nano-tranceiver based
on graphene advancements to propagate SPP waves,
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
a nano-processer with operating frequency close to
1 THz, nano-actuators, nano-sensors which can sense
external force, gas molecules, and biological objects
such as antigens and antibodies, a nano-memory which
allows storage of a bit signal in a single atom, a nanobattery, and an energy nano-harvester which transfers
energy to power other elements . Limited by the
computation capabilities and battery life, the signals are
mostly pulse-based for the easiness of detection and
transmission.
• Nano-routers control the behavioral patterns of the
nano-nodes, aggregate information, and determine
the optimal paths for signals to be forwarded. The
nano-routers are equipped with higher energy and computational resources. When a speciﬁc query is created
from the command center, nano-routers need to select
the optimal routes that can reach the nano-nodes to
collect their data and report back. Due to the limited
transmission range, a pulse-based signaling is preferred
to assess the reachable range of nano-nodes in order to
minimize outage probability and establish the desired
• Gateways serve as the remote controller of the IoNT
and connect over the internet to service providers. The
gateways can be common smart devices such as smartphones and tablets, among others. In order to achieve
a manageable network with hundred or even thousands
of nano-nodes dissipated in sophisticated communication environments, gateways should devise a holistic
approach in disseminating commands and queries, coordinating between possible collisions, and processing
noisy data, which requires a drastically different network
framework than the conventional network architecture.
Based on the arbitrary pattern of the nano-nodes, potential solutions can be found with the assistance of artiﬁcial intelligence, which does not require pre-established
model for prediction.
It is worth noting that major device technology in the IoNT
is still under design and development. Although a few types
of individual components, such as nano-sensors, have been
made available, it is estimated that a major paradigm shift for
the IoNT is expected to occur in the second half of the 2020s.
2) APPLICATIONS OF THE IoNT
In the realm of IoNT, applications can be primarily found in
body area networks and short-distance local environments.
Three typical application scenarios are described as follows
(also illustrated in Figure 14):
• Nano-Cameras: The nano-cameras are based on
nano-photosensing and nanotechnology to sense, combine, and process light signals before transforming them into electric signals. This system includes
nano-photodectors,
nano-lens,
nano-batteries,
nano-memories in order to achieve ﬁne-resolution imaging and signal processing. The nano-cameras can be
FIGURE 14. Application scenarios of molecular communications in IoNT
and IoBNT.
applied to a wide range of scenarios including but not
limited to intravascular imaging and fracture detection
in oil pipelines .
• On-Chip Networks: With microchips getting more
compact in dimension while the complexity of functionality grows, on-chip signal transmission has become signiﬁcantly more challenging. Currently, issues relating to
CPU scalability and efﬁcient memory synchronization
have driven research trends towards wireless networkon-chip (WNoC) solutions, which can replace wired
connections on conventional chips and take advantage
of short-range communication in the nano-network at
THz-band frequencies .
• Nano-robots for IoNT: The nano-robots in nanonetworks can be deployed in environments such as
nuclear power plants and oil pipelines which might be
hazardous for humans to perform tasks but require high
precision and do not allow massive drilling or digging
over existing infrastructure. Under these circumstances,
nano-robots can be dissipated to sense and collect data
relating to chemical concentration, and ﬂuid speed,
among others. By forming ad-hoc networks, the nanorobots can aggregate and forward data packets to gateways in the IoNT. Nano-robots are also being widely
researched in biomedical engineering ﬁelds. To this end,
Section XI-B will delve into nano-robots for healthcare
applications.
3) OPEN PROBLEMS IN THE IoNT
The signiﬁcant size shrinkage brings three major challenges.
The ﬁrst one is power efﬁciency optimization. Even though
nano-devices consume power at the level of microwatts when
transmitting femtosecond long pulses, in order to cover an
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
area of a few square meters such as an ofﬁce or a meeting
room, the energy consumption factors in as a major constraint
in maintaining a satisfying overall network performance.
New designs on duty cycles for nano-transceivers should be
proposed and evaluated, as well as new clustering algorithms
in order to group nano-transceivers in close proximity for
adaptive operations.
The second open issue is interference control, which has
been extensively studied in classic wireless network scenarios. However, the conventional approaches cannot be directly
applied to the IoNT realm, due to the higher density of
nano-transceivers in space and pulse-based signal transmission schemes. Self-interference becomes the most prominent issue for nano-transceivers when full duplex mode is
deployed and hence requires novel scheduling algorithms to
mitigate this adversarial effect. Additionally, new modulation
and coding schemes should be developed to ﬁt the need of
nano-devices on spectral and power efﬁciency while maintaining a low probability of crosstalk among links.
The third challenge resides in the network protocols. Since
the IoNT will foreseeably function in a manner that is drastically different from the IoT due to differences in channel
conditions, limited scale of operation, as well as miniaturized
devices, the protocol stack design still remains an open ﬁeld
for exploration.
B. INTERNET OF BioNanoThings FOR HEALTH
APPLICATIONS
Highly relevant to IoNT, with its unique characteristics and
applications, is the concept of the Internet of BioNanoThings
(IoBNT). First introduced in 2015, the IoBNT has garnered
signiﬁcant traction in its efforts to synergistically combine
telecommunications with healthcare solutions . The
IoBNT is a network of molecules which can communicate
with each other. The types of molecular communications
include artiﬁcial cells which act as gateways to translate
between different molecule types, or a bio-cyber interface
which can convert molecular signals to electrical ones and
transmit to external devices for further processing .
In applications relating to human healthcare, the IoBNT
harbors many unique challenges and opportunities. First,
the interdisciplinary research on both communications and
data analytics can greatly facilitate the modeling of biological
processes, including cancer cell formations and Alzheimer’s
disease, and further design effective control measures for
such diseases. Second, even though expressions of genetic
codes at the cell- and organ-level can vary remarkably, in a
manner analogous to various types of data applications in
wireless networks, communication models can be developed
and exploited to conceive a generally applicable health information framework. Third, the holistic network architecture
envisioned in the IoBNT will integrate components at heterogeneous levels including within cells and among tissues,
organs, as well as systems, before eventually connecting to
the outside Internet for physicians to perform metric evaluations and propose treatment plans accordingly. However,
healthcare solutions that are to be realized in such complicated biological and molecular environments should be built
upon a solid understanding of the physics behind molecular communication and advanced statistical analysis tools in
order to unveil the principles behind the seemingly random
molecular movement.
1) ESSENTIAL COMMUNICATION MODELS IN IoBNT
Different from classic wireless communication channels
based on the propagation of electromagnetic waves, molecular communication (MC) channels rely on the mechanism
of molecular movement to transmit information. The main
difference between an MC channel and the classical wireless
channel is that the transmission medium presents different
forms, such as ﬂuids of several chemical compositions in
blood vessels, plasma membranes of neurons, and so on.
Based on the motion of molecules in such diverse mediums, end-to-end channel models have been developed to
characterize the capacity, noise, and interference in various
communication scenarios – . Particularly, in the
diffusion-based MC model, information is encoded in various
forms, for example, based on different concentration intensities and distinct release times of molecules.
The nano-device acting as a transmitter emits such encoded
molecules to the wireless molecular channel. At the receiver
side, another nano-device decodes the signals based on the
quantiﬁed received intensities or times of arrival, given that
the channel remains stationary for the duration of transmission. In such transmissions, some molecules will get dispersed in the channel and will not be received by the target
nano-devices, they are hence treated as noise, and channels
with such residual molecules are characterized as channels
with memory. For such channels, the theories of Fick’s diffusion and particle location displacement are used to characterize the channel capacity as a function of a collection of
parameters, including the diffusion coefﬁcient of the channel,
the temperature, the distance between end-transceivers, and
the bandwidth of the transmitted signal .
2) IoBNT IN PUBLIC HEALTH APPLICATIONS
Late 2019 and 2020 have seen the novel coronavirus disease
named COVID-19 spread worldwide, causing high fatalities
and a plethora of other public health issues. More generally, such outbreaks, including the severe acute respiratory
syndrome (SARS) in 2002, the middle east respiratory syndrome (MERS) in 2012, the Ebola virus disease in 2014, and
the seasonal inﬂuenza, raise questions about the manner in
which public health systems should react to such epidemics
and pandemics. The widespread havoc caused by pandemics
calls for effective means to identify new viruses, understand
their mechanisms of viral infection, and devise efﬁcient tools
for treatment and vaccination.
In order to facilitate the development of antiviral and
preventive solutions, researchers have looked into creating
biosensors that can monitor the cleavage of proteases within
infected cells . Proteases are generated as a result of the
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
cell being infected by the genome of coronavirus, which is
a type of RNA virus. Other byproducts include synthesized
polyproteins which can replicate and transcript to generate
more RNAs, and structural proteins that can construct new
virions . Two types of proteases found in the coronaviruses that cause SARS and MERS (i.e., SARS-Cov and
MERS-Cov) are papain-like protease and 3C-like protease.
The biosensor, which is based on luciferase, is used to identify
potential broad-spectrum coronavirus papain-like or 3C-like
protease inhibitors.
The SARS-CoV-2 virions that cause the COVID-19 disease have a diameter of 50–200 nanometers approximately , and infect the human respiratory system
via human-to-human spread, in the form of droplets discharged when an infected person coughs or sneezes .
COVID-19 has thus far posed unprecedented challenges
worldwide in testing, treatment, and vaccine development.
The IoBNT is envisioned to have immense potential in the
molecular diagnosis of emerging viruses of this kind. The
nanosensors, which can be ﬁreﬂy luciferase-based or other
reporter genes, can be used to examine the reverse transcription polymerase chain reaction in collected samples. Other
tests include using bio-nano-sensors to identify antibodies
from blood samples to examine if the person is infected.
In terms of treatment, although no antiviral drugs are
available for COVID-19 yet, studies on inﬂuenza treatment
can shed light on how the IoBNT could assist in future
solution development. A critical step for treatment is the
antiviral intervention, which blocks the intracellular signaling pathways to prevent inﬂuenza viruses from replication.
A reported solution preventing the virus from replication is
to use engineered bacteria (i.e., Escherichia coli) to trap the
Ebola virus . In the reported work, the blood of a patient
with the Ebola virus infection is transmitted to a microﬂuidic
chamber tube outside the body which contains the engineered
bacteria. The scattered bacteria can then achieve protein
binding with the Ebola virus using chemical bind force and
synthetic protein binding receptors .
More importantly, the IoBNT serves a unique role as a
holistic solution to not only monitor limited types of cells
(e.g., squamous epithelial cells from nasopharyngeal swabs
for COVID-19 tests), but also across different tissues and
systems. It is found that such coronaviruses can also cause
damage to digestive and neurological systems , .
Hence, a series of connected bio-nano-things consisting of
various types of engineered bacteria can operate simultaneously to improve test reliability and treatment efﬁciency.
3) ARTIFICIAL INTELLIGENCE IN IoBNT FOR HEALTH
APPLICATIONS
In the IoBNT network, different systems demonstrate a wide
variation in characteristics, thereby requiring varied analytical approaches. For example, in cardiovascular systems,
the speed of molecular transmission is determined by the
speed of blood ﬂow and heart rate, among other factors,
which may vary per person; whereas in the nervous system,
the time required to propagate information-carrying electrochemical stimuli through neurons depends on the connectivity of synapses. In order to estimate the error rate and capacity,
the existing diffusion-based MC model normally requires
several channel parameters to formulate the model for computation. The generic modeling approach provides initial
insights into the behavior of molecular signal transmission,
however, recent advances in statistical learning, that utilize
artiﬁcial intelligence, provide increasingly reﬁned solutions
for modeling sophisticated molecular information exchange
processes. For example, in , a signal detection algorithm
based on neural networks has been shown to achieve good
performance without prior knowledge of the molecular channel, thus lending support to the use of statistical inference
for characterizing molecular communication channels. Furthermore, a neural network-based nano-receiver design has
been proposed in which shows good bit error rate
performance under the effect of inter-symbol interference.
4) OPEN PROBLEMS FOR IoBNT
Currently, IoBNT primarily focuses on studies in the domains
of physical layer channel modeling, capacity analysis, modulation and coding schemes, and nano-transceiver design.
However, research gaps relating to the following aspects need
to be overcome:
• Experimental Validation: The theoretical models of
molecular communications should be validated under
realistic channel environments, which include experimental testing. Traditionally, these experimental tests
have posed high requirements on lab equipment and the
nurturing process of cells and bacteria. While the procedures for such experiments should be strictly followed
and executed, at times the cost for testing can be remarkably high. In such situations, simulations based on realistic assumptions serve as an alternative means, which
have been commonly adopted in research. The convergence between analytical and experimental approaches
should be a joint effors by researchers across ﬁelds in
telecommunications, biomedical engineering, and signal
processing.
• Data Storage and Management: The large data sets
obtained from experiments or simulations can have
many control variables which require efforts to manage
and update. Open databases have become a popular
trend for sharing raw data to beneﬁt the entire research
community for collaboration, and can be a foreseeable
direction for research in the IoBNT.
C. QUANTUM COMMUNICATIONS
As networks continue to evolve beyond 6G, they are expected
to incorporate more spectrum, a larger variety of transceiver
front-ends, higher complexity in processed signals, and
stricter requirement on reliability, and therefore, it is expected
that the computational requirements of wireless systems will
also increase . To this end, quantum computing has
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
been widely recognized as a key enabling technology for
realizing computationally complex systems . Quantum
systems are particularly useful for solving complex optimization problems. For example, in the optimal routing problem
with multiple objectives, traditional methods, including the
geographic routing algorithm, demonstrate signiﬁcant complexities to yield optimal solutions, and less complex ones
often sacriﬁce optimality . It has been demonstrated that
using quantum computing for such problems can efﬁciently
reduce complexity while achieving optimality .
However, such computationally intensive tasks often
require several hundreds of thousands or millions of interconnected quantum bits, and therefore cannot be performed
on a single quantum chip. The need for interconnecting
several chips of this kind has given rise to the concept of
quantum communications. Quantum communications is thus
indispensable for operating quantum systems at scale .
More speciﬁcally, quantum communications is deﬁned as the
exchange of information that adheres to the laws of quantum
mechanics, and offers several key advantages: (i) the capability of large-scale parallel computation, (ii) the ability to
transfer data in a tamper-proof manner, and (iii) the potential to encode and transmit a large number of multiple data
streams simultaneously.
We begin our discussion of quantum communications by
describing the following four postulates or rules that govern
the operation of such systems :
• Postulate 1 - The Quantum Bit: Within the context of
classical communications, a binary value of either 0 or
1 per bit is used to represent data. On the other hand,
in quantum communications, the quantum bit, or qubit,
contains the superposition of both logical values at the
same time, of the form
|8⟩= a0 |0⟩+ a1 |1⟩,
where |8⟩represents a two-dimensional vector, with the
coefﬁcients a0 and a1 being complex numbers, and 0 and
1 being the two logical values.
• Postulate 2 - The Quantum Register: Just like computing registers that are used to store multiple bits, quantum
registers are used for storing qubits. However, unlike
classical registers that are deterministic, the output of a
quantum register is probabilistic, i.e., when reading or
measuring the quantum register, a different value may
be returned each time, thus presenting a major challenge
in the implementation of quantum information exchange
• Postulate 3 - Exponential Speed-up: Exponential
speed-up is a key property of quantum information processing systems. We know that classical systems employ
parallelization wherein multiple computing units process parallel streams of data simultaneously. On the
other hand, in quantum systems, the entire input information is placed in a single quantum register, and a
single quantum computing unit can process multiple
register states simultaneously, thus achieving a signiﬁcant reduction in the time required for computation.
• Postulate 4 - The Q/C Conversion: Since it is far easier
to perceive information in terms of 0s and 1s, i.e., classical information, it becomes imperative to interpret the
results of any quantum operation in the classical domain.
To this end, the classical interpretation of (1) implies
that, if we were to measure such a qubit, we would
receive value 0 with probability p0 = |a0|2 and value
1 with p1 = |a1|2.
Closely related to the four postulates is the concept of
entanglement . Entanglement is a phenomenon in which
the quantum states of two or more particles are described with
reference to each other. Within this context, these particles
exist in a shared state, and are referred to as entangled pairs.
Any action on a particle within the entangled pair immediately affects all other particles within that pair, irrespective
of the physical separation between them. For example, if a
photon traveling through an optical ﬁber is entangled with
another photon outside the ﬁber, the photon inside the ﬁber
will experience the same effects as those experienced by the
photon on the outside. In this case, entanglement serves as a
source of noise in the quantum channel.
Continuing our discussion of quantum channels, we note
that classical information theory does not apply to these channels. Unlike traditional wireless communication channels
where the large- and small-scale parameters are deterministic
or can be stochastically characterized, the capacity of qubit
carrying quantum channels is deﬁned as the rate at which
classical or quantum information increases with each use of
the quantum channel .
Moreover, there exist several different types of capacities
for quantum channels, including but not limited to the classical capacity, the quantum capacity, the private capacity,
the entanglement assisted capacity, and the zero-error capacity. The classical and quantum capacities are the two most
commonly used deﬁnitions. In particular, while the classical
capacity measures classical information transmission over
a noisy quantum channel, the quantum capacity represents
the amount of quantum information, i.e., qubits, that can be
transmitted through a noisy quantum channel. We refer the
interested reader to for additional insight into each of
these channel capacity types. In the following, we discuss the
different types of channels, data routing, and open problems
within the domain of quantum communications.
1) TYPES OF CHANNELS
communications, we take into consideration the following types
of channel, the dephasing channel and the depolarizing
channel , .
• The Dephasing Channel: The dephasing channel, also
known as the phase damping or phase ﬂip channel,
applies a bit ﬂip in the conjugate basis. The impact of the
dephasing channel can be best described as equivalent
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
FIGURE 15. Physical entities associated with quantum networks .
to measuring the qubit in the computational basis and
then forgetting the result of the measurement. A more
detailed treatment of the nuances of the dephasing channel can be found in [193, §4].
• The Depolarizing Channel: The depolarizing channel is often referred to the ‘‘worst-case scenario’’ and
describes the fact that the qubit may be left unchanged
with a probability 1 −p, with p
∈ , or that
an error may occur with probability p. In this case,
the error could be one of three types, with each being
equally likely– the bit ﬂip error, the phase ﬂip error,
or both. In the event of an error, it is assumed that the
channel replaces the lost qubit with a maximally mixed
state [194, §2], i.e, all states become equally likely. For
example, the maximally mixed state with reference to (1)
implies that a0 = a1.
2) QUANTUM COMMUNICATIONS NETWORKS
Quantum networks are key to the success of distributed
quantum computing, and in turn rely on the ability to share
quantum states between different quantum devices. However,
unlike conventional networks that are based on the storeand-forward paradigm, quantum networks must adhere to
the no-cloning theorem which prohibits making copies of
an arbitrary quantum state . In order to overcome this
restriction, quantum networks rely on the concept of entanglement described earlier, along with quantum teleportation. The process of quantum teleportation leverages
entanglement to transmit unknown quantum states between
remote quantum devices, through remote entanglement distribution .
Further, as shown in Figure 15, we note the following
physical entities that constitute quantum networks :
• Quantum Nodes: These are the quantum devices that
are interconnected to each other.
• Communication Links: These include both classical as
well quantum links that interconnect the quantum nodes
in the network.
• Entanglement Generator: This device is responsible
for generating the entangled pairs that are distributed
between the quantum nodes.
• Quantum Memories: These are primarily used for storing quantum states for the purpose of communication.
• Quantum Measurement Devices: Their primary function is the assessment of the generated entangled states.
While the aforementioned entities play a vital role
in enabling quantum networks, the process of quantum
teleportation is affected by the exponential decay of communication rate with distance, which in turn is offset by the use
of quantum repeaters. The routing problem then involves the
selection of the optimal path from the source to the destination traversing one or more quantum repeaters resulting in a
high-quality entanglement distribution. Further, the routing
framework must also take cognizance of the fact that the
physical mechanisms underlying quantum entanglement are
stochastic, and that the passage of time leads to loss of
entanglement between the entangled pair . Expanding
upon this, in the following section, we delve into some of the
major challenges faced by quantum networks today.
3) OPEN PROBLEMS AND MAJOR CHALLENGES
Given the vast differences between the classical and quantum
domains, there are several fundamental research challenges,
that are vital to the success of quantum networks, as detailed
• Quantum Error Correction: There are three major
challenges faced by error correction techniques for
qubits . First, while classical error correction codes
assume that data can be duplicated freely, the no-cloning
theorem precludes the arbitrary duplication of quantum states. Second, since qubits are susceptible to both
bit-ﬂip and phase-ﬂip errors, quantum error correction
techniques need to be able to detect both error types
simultaneously, unlike classical techniques that take
only bit-ﬂips into consideration. Third, there exists the
possibility of wavefunction collapse due to measurements on the qubits performed as part of the error
correction procedure.
• Entanglement Distribution: Long distance entanglement distribution is a key challenge in the realization
of quantum networks, impacting the physical, link, and
network layers . More speciﬁcally, at the physical layer, there is a need for quantum error correction
techniques, while the no-cloning theorem necessitates a
re-design of the link layer. At the network layer, novel
quantum routing metrics are required to ensure optimal
path selection.
• Deployment Challenges: Quantum computing devices
require highly specialized data centers equipped with
ultra-high vacuum systems and ultra-low temperature
cryostats. Further, while quantum teleportation has been
proposed as a means to realize quantum networks,
it requires the integration of classical and quantum communication resources, which is a fairly complex problem
in itself.
XII. TENTATIVE TIMELINE FOR 6G
Thus far, we have described the manner in which the evolution of societal needs will guide the transition from 5G
to 6G, along with a plethora of new and upcoming use
cases that will be best served by 6G. We have also discussed the tentative KPIs associated with 6G and the key
enabling technologies that will play a vital role in achieving these next-generation KPIs, as summarized in Table 2.
As shown in Figure 16, the increasing technological readiness and worldwide deployments of 5G systems have set the
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
TABLE 2. A brief summary of the KPI impacts and open problems associated with each key enabling technology for 6G and beyond.
stage for a thoughtful discussion on the future of wireless
communications.
While 3GPP standards over the next few years, up to and
including Release 18 in 2024, are expected to primarily deal
with 5G, the ITU has recently convened the Focus Group
on Technologies for Network 2030 ,
to study the capabilities of networks for the year 2030 and
beyond. More generally, as we have seen in the preceding
VOLUME 8, 2020
I. F. Akyildiz et al.: 6G and Beyond: The Future of Wireless Communications Systems
FIGURE 16. Projected timeline for 6G and beyond systems.
sections, each of the presented key technologies has witnessed signiﬁcant traction in terms of research and development, laying the groundwork for the next generation of
wireless communications. Both the National Science Foundation (NSF) through its Platforms for Advanced Wireless
Research (PAWR) initiative and the European Commission are expected to play a major role in the development of 6G.
At the same time, going beyond academia, we expect a
signiﬁcant rise in industry involvement in the development of
these technologies over the next few years, culminating in key
hardware and software technology demos by 2025, followed
by full-scale 6G testbeds in 2026 and beyond. We envision
that these testbeds will serve as the perfect backdrop for
showcasing the potential of 6G and demonstrating its suitability for use cases such as multi-sensory holographic teleportation, real-time remote healthcare, industrial automation,
and smart infrastructure and environments, to name a few.
XIII. CONCLUSION
This paper surveys the key enabling techniques for the next
generation of wireless communication networks, outlines
their essential use cases, and provides a perspective on current
as well as future research and development efforts. We envision that 6G and beyond wireless systems will be largely
driven by a focus on wireless ubiquity, i.e., the unrestricted
availability of high quality wireless access. To this end,
we have highlighted the key enabling technologies that are
vital to the success of 6G and beyond systems. By detailing
both the operational nuances and open challenges associated
with each, we not only hope to provide a detailed insight
into the next frontier in wireless communications, but also
encourage readers to play their part in the realization of the
envisioned ubiquitous wireless future.
ACKNOWLEDGMENT
The authors would like to thank B. D. Unluturk, C. Han,
D. M. Gutierrez-Estevez, E. C. Reyes, E. Khorov, and
X. Wang for their valuable insights and suggestions that have
played a critical role in improving the quality of this paper.