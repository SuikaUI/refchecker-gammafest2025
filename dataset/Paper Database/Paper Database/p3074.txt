Practice of Epidemiology
Constructing Inverse Probability Weights for Marginal Structural Models
Stephen R. Cole1 and Miguel A. Herna´n2,3
1 Department of Epidemiology, Johns Hopkins Bloomberg School of Public Health, Baltimore, MD.
2 Department of Epidemiology, Harvard School of Public Health, Boston, MA.
3 Harvard–MIT Division of Health Sciences and Technology, Cambridge, MA.
Received for publication January 22, 2008; accepted for publication May 12, 2008.
The method of inverse probability weighting (henceforth, weighting) can be used to adjust for measured confounding and selection bias under the four assumptions of consistency, exchangeability, positivity, and no misspeciﬁcation of the model used to estimate weights. In recent years, several published estimates of the effect of
time-varying exposures have been based on weighted estimation of the parameters of marginal structural models
because, unlike standard statistical methods, weighting can appropriately adjust for measured time-varying confounders affected by prior exposure. As an example, the authors describe the last three assumptions using the
change in viral load due to initiation of antiretroviral therapy among 918 human immunodeﬁciency virus-infected US
men and women followed for a median of 5.8 years between 1996 and 2005. The authors describe possible tradeoffs that an epidemiologist may encounter when attempting to make inferences. For instance, a tradeoff between
bias and precision is illustrated as a function of the extent to which confounding is controlled. Weight truncation is
presented as an informal and easily implemented method to deal with these tradeoffs. Inverse probability weighting
provides a powerful methodological tool that may uncover causal effects of exposures that are otherwise obscured.
However, as with all methods, diagnostics and sensitivity analyses are essential for proper use.
bias (epidemiology); causality; confounding factors (epidemiology); probability weighting; regression model
Abbreviations: AIDS, acquired immunodeﬁciency syndrome; HAART, highly active antiretroviral therapy; HIV, human
immunodeﬁciency virus; HIV-1, human immunodeﬁciency virus type 1.
Inverse probability weighting (henceforth, weighting) can
be used to estimate exposure effects. Unlike standard statistical methods, weighting can appropriately adjust for confounding and selection bias due to measured time-varying
covariates affected by prior exposure (1).
Under the four assumptions of consistency, exchangeability, positivity, and no misspeciﬁcation of the model used to
estimate the weights, weighting creates a pseudo-population
in which the exposure is independent of the measured confounders (2). The pseudo-population is the result of assigning
to each participant a weight that is, informally, proportional
to the participant’s probability of receiving her own exposure history. In such a pseudo-population, one can regress
the outcome on the exposure using a conventional regression model that does not include the measured confounders
as covariates. Fitting a model in the pseudo-population is
equivalent to ﬁtting a weighted model in the study population. The parameters of such weighted regression models,
which equal the parameters of marginal structural models
(3), can be used to estimate the average causal effect of
exposure in the original study population.
In recent years, several published estimates of the effect
of time-varying exposures have been based on weighted
estimation of the parameters of marginal structural models
(4–24). Most of these articles discuss the plausibility of the
exchangeability assumption, often referred to as the
Correspondence to Dr. Stephen R. Cole, Department of Epidemiology, School of Public Health, University of North Carolina at Chapel Hill,
McGavran-Greenberg Hall, Campus Box 7435, Chapel Hill, NC 27599-7435 (e-mail: ) (present address).
Am J Epidemiol 2008;168:656–664
American Journal of Epidemiology
ª The Author 2008. Published by the Johns Hopkins Bloomberg School of Public Health.
All rights reserved. For permissions, please e-mail: .
Vol. 168, No. 6
DOI: 10.1093/aje/kwn164
Advance Access publication August 5, 2008
assumption of no unmeasured confounding, and emphasize
correctly that this assumption is not empirically veriﬁable.
These articles also implicitly assume that consistency holds,
which is a reasonable assumption when estimating the effect
of medical treatments (refer to appendix 2 for a formal definition of consistency). However, these articles do not usually include an explicit discussion of the role of the other
three assumptions stated above. Here, we describe the role
of three of the four assumptions in weighted estimation and
the interpretation of results. This paper is structured as follows. First, we describe a motivating example from our
ongoing work in human immunodeﬁciency virus (HIV) epidemiology. Second, in the context of our motivating example, we describe the assumptions of exchangeability,
positivity, and no model misspeciﬁcation, as well as the
tradeoffs that an epidemiologist may encounter when attempting to make inferences under these assumptions.
Third, we describe an informal method to deal with these
tradeoffs. We conclude with a brief discussion and some
recommendations
constructing
probability
weights (henceforth, weights).
EXAMPLE: ANTIRETROVIRAL THERAPY AND VIRAL
LOAD IN HIV-INFECTED INDIVIDUALS
To provide motivation for our discussion, we use the
analysis reported in a recent paper (19) that estimated the
effect of initiation of highly active antiretroviral therapies
(HAART) on the change in human immunodeﬁciency virus
type 1 (HIV-1) RNA viral load in HIV-infected individuals.
We suggest reading reference 19 in concert with the present
paper. In brief, 918 HIV-infected men and women not using
HAART at study entry were seen semiannually in the
Multicenter AIDS [acquired immunodeﬁciency syndrome]
Cohort Study or Women’s Interagency HIV Study for a median of 5.8 years between 1996 and 2005. We estimated the
effect of time-varying HAART initiation on change in log10
viral load.
For each subject i and visit j, we estimated a weight SWij
that was, informally, proportional to the inverse (or reciprocal) of the probability of having her own observed exposure
and censoring history through that visit. For a formal deﬁnition of the weights, refer to appendix 1. We then ﬁt
a weighted repeated measures regression model in which
an individual was assigned her estimated weight SWij at
each visit. The primary effect estimate was an immediate
and sustained 1.91 log10 decrease in viral load after HAART
initiation. Next, we describe the assumptions necessary for
valid inferences and their practical implications in the context of our example.
EXCHANGEABILITY
Exchangeability implies the well-known assumption of
no unmeasured confounding. For the assumption of no unmeasured confounding to hold, we have to measure enough
joint predictors of exposure and outcome such that, within
the levels of these predictors, associations between exposure
and outcome that are due to their common causes will disappear. For a formal deﬁnition, refer to appendix 2.
Exchangeability assumptions are not testable in observed
data, but one may explore the sensitivity of inferences from
weighted regression to this assumption by using sensitivity
analysis as described by Robins (25) and implemented by
various authors (10, 14, 26). We do not reiterate the approach
to sensitivity analysis here but, rather, assume that the most
important confounders were identiﬁed using expert knowledge (27, 28) and were then appropriately measured and
included in the analysis. Speciﬁcally, we assumed that conditioning on several baseline covariates and the most recent
values of CD4 cell count and viral load is sufﬁcient to
achieve exchangeability between those who did and did
not initiate therapy at any time during the follow-up. Later,
in table 3, we assess the impact of adding further potential
confounders. As a consequence of our assumption that therapy is continuously used after initiation, we do not need to
assume that those who did and did not discontinue were
exchangeable, and hence our estimates do not require the
assumption of exchangeability after therapy initiation. The
price we pay for this intent-to-treat assumption is, of course,
some bias toward the null that increases with the number of
participants that discontinue therapy during follow-up.
As a practical rule to help ensure approximate exchangeability, it may appear obvious that investigators need ﬁrst to
identify and measure as many potential confounders as possible. Then, investigators would include those potential confounders in the model used to estimate the denominator of
the weights. However, this strategy may not always decrease
net bias in ﬁnite samples for two reasons. First, the addition
of a nonconfounding variable may introduce selection bias
due to collider stratiﬁcation (29, 30). Second, adding too
many potential confounders in relation to the number of
observations may introduce ﬁnite-sample bias, which is related to the bias due to nonpositivity discussed below. Further, adding nonconfounding variables to the model for the
weights may decrease the statistical efﬁciency of the effect
estimate (i.e., yield wider conﬁdence intervals) (31). For
these reasons and as illustrated below, in practice one may
not always want to include as many potential confounders as
POSITIVITY
For any method that estimates the average causal effect in
the study population, one must be able to estimate the average causal effect in each subset of the population deﬁned by
the confounders. For example, to estimate the effect of
HAART in the presence of confounding by CD4 cell count,
we need to be able to estimate the effect of HAART in every
category of CD4 cell count. An effect cannot be estimated in
a subset of the study population if everyone is exposed (or
unexposed) in that subset. Positivity is the condition that
there are both exposed and unexposed individuals at every
level of the confounders. For a formal deﬁnition, refer to
appendix 2. Positivity is guaranteed (unconditionally) in experiments because, by design, there will be individuals assigned to each level of the studied treatment. The positivity
Inverse Probability Weights
Am J Epidemiol 2008;168:656–664
assumption is also called the experimental treatment assumption (32). Because the weights SWij can always be
estimated parametrically from the data, even in the presence
of violations of the positivity assumption, lack of positivity
(like lack of consistency) may go undetected unless explicitly investigated.
If somebody cannot possibly be exposed at one or more
levels of the confounders, then positivity is violated because
there is a structural zero probability of receiving the exposure. To ﬁx this idea, we provide two examples. First, in an
occupational epidemiology study to estimate the health effects of a certain chemical, being at work is a potential
confounder often used as a proxy for health status. If one
cannot be exposed to the chemical outside the workplace,
then there is a structural zero probability of exposure to the
chemical among those no longer at work. Second, in a pharmacoepidemiology study to estimate the effects of a particular
drug, an absolute contraindication for treatment (e.g., liver
disease) may be a surrogate for bad prognosis. If one cannot
possibly be treated in the presence of the contraindication,
then there is a structural zero probability of receiving the
treatment among those with the contraindication. An obvious solution is restricting the inference to the subset with
a positive probability of exposure. However, if the structural
zero occurs within levels of a time-varying confounder (e.g.,
liver disease), then restriction or censoring may lead to bias,
whether one uses weighting or other methods (30).
Even in the absence of structural zeros, random zeros
(also called practical violations of the experimental treatment assumption (33)) may occur by chance because of
small sample sizes or high dimensional (i.e., highly strati-
ﬁed or continuous) data. Even a relatively large study may
have zero proportions for particular exposure and covariate
histories as the number of covariates increases. In fact, when
modeling continuously distributed covariates, random zeros
are essentially guaranteed because of the inﬁnite number of
possible values. In such cases, the use of parametric models
smoothes over the random zeros by borrowing information
from individuals with histories similar to those that, by
chance, resulted in random zeros. For example, in table 1
we present the proportions of HAART initiation (i.e., exposure) at 25 levels of joint time-varying CD4 cell count and
viral load. At two of 25 levels, we see nonpositivity or a zero
proportion exposed. These observed zero proportions may
be structural or random. In table 1, both zero proportions
occur in person-time contributions where immunity is not
depleted (i.e., CD4 count, >749 cells/mm3) but virus is detectable. On the basis of prior substantive knowledge and
surrounding nonzero proportions, we concluded that these
two nonpositive proportions appear to be random zeros,
rather than structural zeros, and thus proceeded to model
the probability of exposure to construct weights.
There is a tradeoff between reducing confounding bias
and increasing bias and variance due to nonpositivity. Data
become sparse, and the likelihood of random zeros (and
hence bias due to nonpositivity) increases as one includes
more confounders. For example, in table 2, we progressively
expand the number of categories used to deﬁne CD4 count
and viral load in the construction of weights from one to
nine categories. Table 2 also presents the effect estimate
(i.e., the difference in log10 viral load) and its standard error
obtained by bootstrap. Estimated weights with the mean far
from one or very extreme values are indicative of nonpositivityor misspeciﬁcationof theweightmodel,and thustable2
also presents the mean, standard deviation, minimum, and
maximum estimated weights. As the number of categories increases from one to ﬁve, we observe three changes. First, the
effect estimate increases in absolute value, which (in the
present substantive setting) suggests a better control of confounding. Second, the precision of the effect estimate decreases. Third, the standard deviation and range of the
weights increase, which is the cause of the decreasing precision of the effect estimate. For seven categories of CD4
cell count and viral load, the effect estimate moves toward
the null and its standard error triples. For nine categories of
CD4 cell count and viral load, the weights become so alarmingly variable (with a mean no longer equal to one) that the
effect estimate is no longer computable.
Proportions of 286 HAART* initiators observed
in 4,778 semiannual study visits by categories of prior
time-varying CD4 and HIV-1* RNA viral load, Multicenter AIDS*
Cohort Study and Women’s Interagency HIV* Study, 1996–2005
CD4 count,
Viral load,
person-visits
Proportion
401–<4,000
4,000–10,000
10,001–35,000
401–<4,000
4,000–10,000
10,001–35,000
401–<4,000
4,000–10,000
10,001–35,000
401–<4,000
4,000–10,000
10,001–35,000
401–<4,000
4,000–10,000
10,001–35,000
* HAART, highly active antiretroviral therapy; HIV-1, human
immunodeﬁciency virus type 1; AIDS, acquired immunodeﬁciency
syndrome; HIV, human immunodeﬁciency virus.
Cole and Herna´n
Am J Epidemiol 2008;168:656–664
Contrary to the naı¨ve belief that more ﬁnely deﬁned confounders will always lead to better confounding control,
table 2 shows that bias and variance of the effect estimate
may increase with the number of categories. Similarly, one
may wish to omit control for weak confounders that cause
severe nonpositivity bias because of a strong association
with exposure. In addition, although not illustrated in table
2, the magnitude of nonpositivity bias typically increases
with the number of time points and decreases with the use
of appropriately stabilized weights.
Weighted estimates are more sensitive to random zeros
than is standard regression or stratiﬁcation estimates, which
implicitly extrapolate to levels of the covariates with a lack
of positivity. Users of weighted approaches need tools to
handle this bias-variance tradeoff. Wang et al. (33) have
proposed a computationally demanding diagnostic tool to
quantify the ﬁnite-sample bias due to random zeros in
weighted estimates. After reviewing the assumption of no
model misspeciﬁcation in the next section, we propose an
informal method to evaluate this bias-variance tradeoff.
Refer to references 32–34 for more formal methods.
CORRECT MODEL SPECIFICATION
Weighted estimation of the parameters of marginal structural models requires ﬁtting several models: 1) the structural
(i.e., weighted) model, 2) the exposure model, and 3) the
censoring model. For simplicity and because this paper focuses on constructing weights to estimate the parameters of
any marginal structural model through weighted regression,
we will assume throughout that the structural model is correctly speciﬁed. In practice, investigators will want to explore the sensitivity of their estimates to different structural
model speciﬁcations (e.g., linear vs. threshold dose-response,
long- vs. short-term effects, and so on).
To construct appropriate weights, investigators need to
correctly specify the models for exposure and censoring.
Here, we will discuss only modeling of the exposure distribution, but our comments apply equally to modeling the
censoring distribution. As stated above, a necessary condition for correct model speciﬁcation is that the stabilized
weights have a mean of one (2). In table 3, we provide
a step-by-step example of building weights for the marginal
structural model detailed previously (19) and described
above. Although the step-by-step process is a simpliﬁed
representation of the actual process, we hope that sharing
the general approach may guide future implementations of
marginal structural models.
In speciﬁcation 1, the model to estimate the denominator
of the weights was a pooled logistic model for the probability of exposure initiation at each visit. Speciﬁcally, each
person-visit was treated as an observation, and the model
was ﬁt on those person-visits for which no exposure had
occurred through the prior visit. The covariates were linear
terms for follow-up time, baseline CD4 cell count and viral
load, and time-varying CD4 cell count and viral load measured at the prior visit. This model, which is a parametric
discrete-time approximation of the Cox proportional hazards model for exposure initiation (35, 36), assumes that
the relation between the baseline covariates (and followup time) and the probability of exposure initiation is linear
on the logit scale. The model to estimate the numerator of
the weights was also a pooled logistic model for the probability of exposure initiation, except that time-varying CD4
cell count and viral load were not included as covariates.
The mean of the estimated weights was 1.07 (standard deviation, 1.47), the 1/minimum and maximum estimated
weights were 33.3 and 26.4, and the effect estimate was
1.94 (standard error, 0.17).
In speciﬁcation 2, we replace the linear terms for baseline
and time-varying CD4 and viral load with categories (i.e.,
CD4: <200, 200–500, >500 cells/mm3; and viral load detectable (at 400 copies/ml) or not) to illustrate the impact of
potential residual confounding within categories of the confounders. The estimated weights appear better behaved than
in speciﬁcation 1 (e.g., the mean moves from 1.07 to 1.05,
1/minimum and maximum notably smaller), and the standard error for the difference in log10 viral load is a striking
39 percent (1  0.104/0.170 ¼ 0.388) smaller, but the effect
estimate of 1.66 moved closer to the unadjusted value
of 1.56 (i.e., one category, table 2).
In speciﬁcation 3, the numerator and denominator are as
in speciﬁcation 1, but we add three-knot restricted cubic
splines to all linear terms. Other smoothing techniques
could be used (37). This ﬂexible parameterization of the
time-varying confounders is generally preferred, because
Effect of HAART* versus no HAART on change in
HIV-1* RNA viral load under a series of models using
increasingly ﬁne categorization of time-varying CD4 count and
viral load in construction of inverse probability weights,
Multicenter AIDS* Cohort Study and Women’s Interagency HIV*
Study, 1996–2005y
categoriesz
Estimated weights
Difference in
viral load,
log10 copies/ml
Mean (SD*)
1.01 (0.96)
1.00 (1.42)
1.03 (1.61)
0.05/1.6 3
* HAART, highly active antiretroviral therapy; HIV-1, human
immunodeﬁciency virus type 1; AIDS, acquired immunodeﬁciency
syndrome; HIV, human immunodeﬁciency virus; SD, standard deviation; SE, standard error.
y All models in this table stabilized weights by using only a threeknot spline for time.
z The nine categories of CD4 count and viral load were as follows:
25, 26–50, 51–100, 101–150, 151–<200, 200–350, 351–500, 501–
749, >749 cells/mm3 and 100, 101–1,000, 1,001–10,000, 10,001–
50,001–100,000,
100,001–200,000,
200,001–300,000,
300,001–500,000, >500,000 copies/ml, respectively; coarsened categories were obtained by collapsing adjacent outer categories.
§ The standard deviation of 500 nonparametric bootstrap sample
estimates; 500, 500, 500, and 496 converged.
{ —, not computable.
Inverse Probability Weights
Am J Epidemiol 2008;168:656–664
it liberates one from much of the residual confounding or
ﬁnite-sample bias inherent in categorical variables (e.g.,
speciﬁcation 2) and reduces the potential bias due to model
misspeciﬁcation from strong linearity assumptions (e.g.,
speciﬁcation 1). Compared with speciﬁcation 1, the estimated
weights and effect estimate are similar, but the standard error
is reduced by 18 percent (1  0.139/0.170 ¼ 0.182).
In speciﬁcation 4, we added a product term between timevarying CD4 count and follow-up time suggested by clinical
colleagues, which had p ¼ 0.03. Compared with speciﬁcation 3, there is little change in the estimated weights (although
the maximum weight increases), and the effect estimate remains unaltered, but its standard error is reduced by 5 percent.
This is essentially the model speciﬁcation used previously
(19); however, the (conservative) robust standard error reported (19) was 0.135, while the bootstrap standard error
reported here is 0.132.
In speciﬁcation 5, we explored more fully detailed covariate histories, using time-varying CD4 count and viral load
measured two visits prior to the visit at-risk for HAART
initiation in addition to values measured one visit prior.
Beyond an increase in the maximum weight, no notable
changes are apparent.
In speciﬁcation 6, we explored the addition of two more
possible time-varying confounders, namely, clinical AIDS
status and HIV-related symptoms (i.e., reports of persistent
fever, diarrhea, night sweats, or weight loss) at the visit prior
to the visit at-risk for HAART initiation. Again, no notable
changes are apparent.
WEIGHT TRUNCATION AS A MEANS TO TRADEOFF
BIAS AND VARIANCE
The process discussed above and presented in table 3
illustrates how the choice of the model used to construct
weights may impact the results of a marginal structural
model. Our decision to settle on speciﬁcation 4 of table 3
was an informal bias-variance tradeoff between the inclusion of a sufﬁcient number of ﬂexibly modeled confounders
in the weight model and the construction of well-behaved
weights (mean ¼ 1, small range) that led to a small variance
of the effect estimate. Thus, compared with the model in
speciﬁcation 4, models that included only linear terms for
the time-varying confounders (i.e., speciﬁcation 1), omitted
product terms (i.e., speciﬁcation 3), or included additional
potential confounders (i.e., speciﬁcations 5 and 6) typically
resulted in similar effect estimates with a slightly greater
variance or greater model complexity. On the other hand,
transforming the continuous confounders into categorical
variables (i.e., speciﬁcation 2) resulted in a smaller variance
but probably also in insufﬁcient confounding adjustment, as
the effect estimate moved considerably toward the unadjusted
Effect of HAART* versus no HAART on change in HIV-1* RNA viral load under a series of
models for the construction of inverse probability weights, Multicenter AIDS* Cohort Study and Women’s
Interagency HIV* Study, 1996–2005
Speciﬁcation
Description
Estimated weights
Difference in
viral load,
log10 copies/ml
Mean (SD*)
Numerator includes linear terms for baseline
CD4, RNA, and time. Denominator includes
linear terms for baseline CD4, RNA, time,
CD41, and RNA1.
1.07 (1.47)
Numerator and denominator are as in step 1
but replace linear terms for baseline and
time-varying CD4 and RNA with step
functions (i.e., categoriesz).
1.05 (0.65)
Numerator and denominator are as in step 1,
with three-knot splines to all linear terms.
1.05 (1.17)
Numerator and denominator are as in step 3,
plus a product between CD41 and time
in denominator.
1.04 (1.15)
Numerator and denominator are as in step 4,
plus three-knot splines for CD42 and
RNA2 in denominator.
1.04 (1.67)
Numerator and denominator are as in step 4,
plus indicators for AIDS-1 and presence
of HIV symptoms1 in denominator.
1.05 (1.37)
* HAART, highly active antiretroviral therapy; HIV-1, human immunodeﬁciency virus type 1; AIDS, acquired
immunodeﬁciency syndrome; HIV, human immunodeﬁciency virus; SD, standard deviation; SE, standard error.
y The standard deviation of 500 nonparametric bootstrap sample estimates; 500 always converged.
z The CD4 count categories were as follows: <200, 200–500, >500 cells/mm3; and viral load was detectable at
400 copies/ml or not.
Cole and Herna´n
Am J Epidemiol 2008;168:656–664
result. Note that the best behaved weights (by the measures
of mean and small range) would simply be a constant one.
However, such weights would completely fail to control for
time-varying confounding.
One simple way to explore this bias-variance tradeoff is to
progressively truncate (38) the weights as shown in table 4.
Speciﬁcally, the weights are progressively truncated by resetting the value of weights greater (lower) than percentile
p (100 – p) to the value of percentiles p (100 – p). The ﬁrst
row in table 4 corresponds to the standard marginal structural model (i.e., speciﬁcation 4 in table 3), while the last row
in table 4 corresponds to a baseline-adjusted model (i.e., one
category, table 2, or reference 19, p. 222). Assuming that the
marginal structural model estimate is correct, one can see
the growing bias as the weights are progressively truncated.
Simultaneously, one can see the increasing precision as the
weights are progressively truncated. In this case and under
the assumption that the marginal structural model estimate
is unbiased, the small increase in precision due to weight
truncation is outweighed by the relatively large bias induced. However, here, one could reasonably argue in favor
of reporting the result with the weights truncated at the ﬁrst
and 99th percentiles, on the basis of the centering of the
weights at one and the order of magnitude reduction in the
1/minimum and maximum weights.
The requirement of a mean of one applies to the estimated
weights at each time point, but, as a simpliﬁcation, we
pooled the estimated weights from all time points in the
study. It is therefore logically possible that the chosen
weight model results in a mean estimated weight closer to
one than an alternative weight model but that the chosen
weight model is badly misspeciﬁed for some time points,
whereas the alternative weight model is slightly misspeci-
ﬁed at all time points. Depending on the aims of analysis, we
may prefer the alternative weight model over the chosen.
CONCLUSION
The construction of inverse probability weights for marginal structural models (4–20, 22), or other uses (30, 39),
requires a thoughtful process including determination of
a proper set of covariates upon which one can tolerate the
assumptions of no unmeasured confounding and no informative censoring, exploration of positivity, and determination of a model speciﬁcation that optimizes bias reduction
and precision. Nonweighting methods are also subject to
these same assumptions. Indeed, a process similar to that
laid out here should be undertaken in any observational data
analysis. Here, we detailed some approaches to the construction of such weights using an example from a recently
published paper.
Future research is needed to formally compare competing
methods to balance bias and variance when selecting from
potential confounders and functional forms. In the meantime, we recommend the following: 1) Check positivity
for important confounders as illustrated in tables 1 and 2.
2) Explore exchangeability by using a variety of potential
confounders and functional forms as illustrated in table 3,
coupled with sensitivity analysis (14). 3) Check weight
model misspeciﬁcations by exploring the distribution of
weights. The tradeoffs implied by the need to simultaneously guarantee exchangeability, positivity, and no model
misspeciﬁcations can be explored by evaluating the sensitivity of inferences to truncating extreme weights as illustrated in table 4. In manuscripts, we encourage both
acknowledging the sensitivity of the effect estimates to the
weight model speciﬁcation and reporting an effect estimate
that is robust to different weight model speciﬁcations. Often,
this will mean selecting as the main ﬁnding an effect estimate that is less extreme than that produced by certain
weight model speciﬁcations. Inverse probability weighting
provides a powerful methodological tool that may uncover
causal effects of exposures that are otherwise obscured, but
powerful tools can be dangerous if not handled with care.
ACKNOWLEDGMENTS
Dr. Cole was supported in part by National Institute of
Allergy and Infectious Diseases grant R03-AI071763, and
Dr. Herna´n was supported in part by National Institute of
Allergy and Infectious Diseases grant R01-AI073127. The
Multicenter AIDS Cohort Study is funded by the National
Institute of Allergy and Infectious Diseases, with additional
supplemental funding from the National Cancer Institute
(grants UO1-AI-35042, 5-MO1-RR-00722 (General Clinical
Research Center), UO1-AI-35043, UO1-AI-37984, UO1-
AI-35039, UO1-AI-35040, UO1-AI-37613, and UO1-AI-
35041). The Women’s Interagency HIV Study is also
funded by the National Institute of Allergy and Infectious
Effect of HAART* versus no HAART on change in
HIV-1* RNA viral load under progressive truncation of inverse
probability weights, Multicenter AIDS* Cohort Study and
Women’s Interagency HIV* Study, 1996–2005
Truncation
percentiles
Estimated weights
Difference in
viral load,
log10 copies/ml
Mean (SD*)
1.04 (1.15)
1.00 (0.58)
0.95 (0.36)
0.92 (0.27)
0.91 (0.12)
0.95 (0.00)
* HAART, highly active antiretroviral therapy; HIV-1, human
immunodeﬁciency virus type 1; AIDS, acquired immunodeﬁciency
syndrome; HIV, human immunodeﬁciency virus; SD, standard deviation; SE, standard error.
y The standard deviation of 500 nonparametric bootstrap sample
estimates; 500 always converged.
z No truncation of weights corresponds to a standard marginal
structural model, while setting all weights to the constant 50th
percentile corresponds to the baseline adjusted model.
Inverse Probability Weights
Am J Epidemiol 2008;168:656–664
Diseases, with supplemental funding from the National
Cancer Institute, the National Institute of Child Health and
Human Development, the National Institute on Drug Abuse,
and the National Institute of Craniofacial and Dental
Research (grants U01-AI-35004, U01-AI-31834, U01-AI-
34994, AI-34989, U01-HD-32632 (National Institute of
Child Health and Human Development), U01-AI-34993,
and U01-AI-42590).
The authors thank Drs. Maya Petersen, Lisa Bodnar,
Sander Greenland, Jonathan Sterne, and James Robins for
expert advice.
Data for this article were collected through the Multicenter AIDS Cohort Study (MACS), with centers (Principal
Investigators) at the Johns Hopkins Bloomberg School of
Public Health (Drs. Joseph B. Margolick and Lisa Jacobson),
the Howard Brown Health Center and Northwestern
University Medical School (Dr. John Phair), the University
of California, Los Angeles (Drs. Roger Detels and Beth
Jamieson), and the University of Pittsburgh (Dr. Charles
Rinaldo), and the Women’s Interagency HIV Study (WIHS)
Collaborative Study Group, with centers at the New York
City/Bronx Consortium (Dr. Kathryn Anastos), Brooklyn,
New York (Dr. Howard Minkoff), the Washington, DC,
Metropolitan Consortium (Dr. Mary Young), the Connie
Wofsy Study Consortium of Northern California (Dr. Ruth
Greenblatt), the Los Angeles County/Southern California
Consortium (Dr. Alexandra Levine), the Chicago Consortium (Dr. Mardge Cohen), and the Data Coordinating
Center (Dr. Stephen Gange). World Wide Web links for
both studies are located at 
Conﬂict of interest: none declared.