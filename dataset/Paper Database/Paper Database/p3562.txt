Latent Space Autoregression for Novelty Detection
Davide Abati
Angelo Porrello
Simone Calderara
Rita Cucchiara
University of Modena and Reggio Emilia
{name.surname}@unimore.it
Novelty detection is commonly referred to as the discrimination of observations that do not conform to a learned
model of regularity. Despite its importance in different application settings, designing a novelty detector is utterly
complex due to the unpredictable nature of novelties and its
inaccessibility during the training procedure, factors which
expose the unsupervised nature of the problem. In our proposal, we design a general framework where we equip a
deep autoencoder with a parametric density estimator that
learns the probability distribution underlying its latent representations through an autoregressive procedure. We show
that a maximum likelihood objective, optimized in conjunction with the reconstruction of normal samples, effectively
acts as a regularizer for the task at hand, by minimizing
the differential entropy of the distribution spanned by latent
vectors. In addition to providing a very general formulation, extensive experiments of our model on publicly available datasets deliver on-par or superior performances if
compared to state-of-the-art methods in one-class and video
anomaly detection settings. Differently from prior works,
our proposal does not make any assumption about the nature of the novelties, making our work readily applicable to
diverse contexts.
1. Introduction
Novelty detection is deﬁned as the identiﬁcation of samples
which exhibit signiﬁcantly different traits with respect to an
underlying model of regularity, built from a collection of
normal samples. The awareness of an autonomous system
to recognize unknown events enables applications in several domains, ranging from video surveillance , to
defect detection to medical imaging . Moreover,
the surprise inducted by unseen events is emerging as a crucial aspect in reinforcement learning settings, as an enabling
factor in curiosity-driven exploration .
However, in this setting, the deﬁnition and labeling of
novel examples are not possible. Accordingly, the literature
agrees on approximating the ideal shape of the boundary
separating normal and novel samples by modeling the intrinsic characteristics of the former. Therefore, prior works
tackle such problem by following principles derived from
the unsupervised learning paradigm . Due
to the lack of a supervision signal, the process of feature extraction and the rule for their normality assessment can only
be guided by a proxy objective, assuming the latter will de-
ﬁne an appropriate boundary for the application at hand.
According to cognitive psychology , novelty can be expressed either in terms of capabilities to remember an event
or as a degree of surprisal aroused by its observation.
The latter is mathematically modeled in terms of low probability to occur under an expected model, or by lowering
a variational free energy .
In this framework, prior
models take advantage of either parametric or nonparametric density estimators. Differently, remembering an event implies the adoption of a memory represented
either by a dictionary of normal prototypes - as in sparse
coding approaches - or by a low dimensional representation of the input space, as in the self-organizing maps 
or, more recently, in deep autoencoders. Thus, in novelty
detection, the remembering capability for a given sample is
evaluated either by measuring reconstruction errors 
or by performing discriminative in-distribution tests .
Our proposal contributes to the ﬁeld by merging remembering and surprisal aspects into a unique framework: we design a generative unsupervised model (i.e., an autoencoder,
represented in Fig. 1i) that exploits end-to-end training in
order to maximize remembering effectiveness for normal
samples whilst minimizing the surprisal of their latent representation. This latter point is enabled by the maximization
of the likelihood of latent representations through an autoregressive density estimator, which is performed in conjunction with the reconstruction error minimization. We show
that, by optimizing both terms jointly, the model implicitly seeks for minimum entropy representations maintaining its remembering/reconstructive power. While entropy
minimization approaches have been adopted in deep neural
compression , to our knowledge this is the ﬁrst proposal
 
tailored for novelty detection. In memory terms, our procedure resembles the concept of prototyping the normality
using as few templates as possible. Moreover, evaluating
the output of the estimator enables the assessment of the
surprisal aroused by a given sample.
2. Related work
Reconstruction-based methods. On the one hand, many
works lean toward learning a parametric projection and
reconstruction of normal data, assuming outliers will
yield higher residuals.
Traditional sparse-coding algorithms adhere to such framework, and represent
normal patterns as a linear combination of a few basis
components, under the hypotheses that novel examples
would exhibit a non-sparse representation in the learned
subspace. In recent works, the projection step is typically
drawn from deep autoencoders . In the authors
recover sparse coding principles by imposing a sparsity
regularization over the learned representations, while a
recurrent neural network enforces their smoothness along
the time dimension.
In , instead, the authors take
advantage of an adversarial framework in which a discriminator network is employed as the actual novelty detector,
spotting anomalies by performing a discrete in-distribution
test. Oppositely, future frame prediction maximizes
the expectation of the next frame exploiting its knowledge
of the past ones; at test time, observed deviations against
the predicted content advise for abnormality. Differently
from the above-mentioned works, our proposal relies on
modeling the prior distribution of latent representations.
This choice is coherent with recent works from the density
estimation community .
However, to the best of
our knowledge, our work is the ﬁrst advocating for the
importance of such a design choice for novelty detection.
Probabilistic methods.
A complementary line of research investigates different strategies to approximate the
density function of normal appearance and motion features.
The primary issue raising in this ﬁeld concerns how to
estimate such densities in a high-dimensional and complex
feature space. In this respect, prior works involve handcrafted features such as optical ﬂow or trajectory analysis
and, on top of that, employ both non-parametric and
parametric estimators, as well as graphical
modeling .
Modern approaches rely on deep
representations (e.g., captured by autoencoders), as in
Gaussian classiﬁers and Gaussian Mixtures .
In the authors involve a Kernel Density Estimator
(KDE) modeling activations from an auxiliary object
detection network. A recent research trend considers training Generative Adversarial Networks (GANs) on normal
samples. However, as such models approximate an implicit
density function, they can be queried for new samples
but not for likelihood values.
Therefore, GAN-based
models employ different heuristics for the evaluation of
novelty. For instance, in a guided latent space search
is exploited to infer it, whereas directly queries the
discriminator for a normality score.
3. Proposed model
Maximizing the probability of latent representations is analogous to lowering the surprisal of the model for a normal
conﬁguration, deﬁned as the negative log-density of a latent
variable instance . Conversely, remembering capabilities can be evaluated by the reconstruction accuracy of a
given sample under its latent representation.
We model the aforementioned aspects in a latent variable
model setting, where the density function of training samples p(x) is modeled through an auxiliary random variable
z, describing the set of causal factors underlying all observations. By factorizing
p(x|z)p(z)dz,
where p(x|z) is the conditional likelihood of the observation given a latent representation z with prior distribution
p(z), we can explicit both the memory and surprisal contribution to novelty. We approximate the marginalization
by means of an inference model responsible for the identiﬁcation of latent space vector for which the contribution
of p(x|z) is maximal. Formally, we employ a deep autoencoder, in which the reconstruction error plays the role of
the negative logarithm of p(x|z), under the hypothesis that
p(x|z) = N(x|˜x, I) where ˜x denotes the output reconstruction. Additionally, surprisal is injected in the process by
equipping the autoencoder with an auxiliary deep parametric estimator learning the prior distribution p(z) of latent
vectors, and training it by means of Maximum Likelihood
Estimation (MLE). Our architecture is therefore composed
of three building blocks (Fig. 1i): an encoder f(x; θf), a
decoder g(z; θg) and a probabilistic model h(z; θh):
f(x; θf) : Rm →Rd,
g(z; θg) : Rd →Rm,
h(z; θh) : Rd → .
The encoder processes input x and maps it into a compressed representation z = f(x; θf), whereas the decoder
provides a reconstructed version of the input ˜x = g(z; θg).
The probabilistic model h(z; θh) estimates the density
in z via an autoregressive process, allowing to avoid
the adoption of a speciﬁc family of distributions (i.e.,
Gaussian), potentially unrewarding for the task at hand. On
this latter point, please refer to supplementary materials for
comparison w.r.t. variational autoencoders .
With such modules, at test time, we can assess the two
sources of novelty: elements whose observation is poorly
Likelihood of
latent vector
- log P(z)
Reconstruction
Input sample
Estimation
p(zd-1|z<d-1)
p(z2|z1z2)
conditionals
Reconstruction
||x – x||2
Localization
Van enters
Novelty score
Downsampling
2D tr. convolution
3D tr. convolution
Image inputs:
Video inputs:
2D convolution
3D convolution
Upsampling Ucs
Residual Rc
Figure 1: (i) The proposed novelty detection framework. The overall architecture, depicted in (a), consists of a deep autoencoder and an autoregressive estimation network operating on its latent space. The joint minimization of their respective
objective leads to a measure of novelty - (b) - obtained by assessing the remembrance of the model when looking to a new
sample, combined with its surprise aroused by causal factors. (ii) Building blocks employed in the autoencoder’s architecture.
explained by the causal factors inducted by normal samples
(i.e., high reconstruction error); elements exhibiting good
reconstructions
surprising
underlying
representations under the learned prior.
Autoregressive
estimation.
Autoregressive
models provide a general formulation for tasks involving
sequential predictions, in which each output depends on
previous observations . We adopt such a technique
to factorize a joint distribution, thus avoiding to deﬁne its
landscape a priori . Formally, p(z) is factorized as
p(zi|z<i),
so that estimating p(z) reduces to the estimation of each
single Conditional Probability Density (CPD) expressed
as p(zi|z<i), where the symbol < implies an order over
random variables.
Some prior models obey handcrafted
orderings , whereas others rely on order agnostic
training . Nevertheless, it is still not clear how to
estimate the proper order for a given set of variables. In our
model, this issue is directly tackled by the optimization.
Indeed, since we perform autoregression on learned latent
representations, the MLE objective encourages the autoencoder to impose over them a pre-deﬁned causal structure.
Empirical evidence of this phenomenon is given in the
supplementary material.
From a technical perspective, the estimator h(z; θh) outputs
parameters for d distributions p(zi|z<i). In our implementation, each CPD is modeled as a multinomial over B=100
quantization bins. To ensure a conditional estimate of each
underlying density, we design proper layers guaranteeing
that the CPD of each symbol zi is computed from inputs
{z1, . . . , zi−1} only.
Objective and connection with differential entropy.
The three components f, g and h are jointly trained to
minimize L ≡L(θf, θg, θh) as follows:
L = LREC(θf, θg) + λLLLK(θf, θh)
||x −˜x||2
reconstruction term
−λ log(h(z; θh))
log-likelihood term
where λ is a hyper-parameter controlling the weight of the
LLLK term. It is worth noting that it is possible to express
the log-likelihood term as
Ez∼p∗(z;θf )
−log h(z; θh)
= Ez∼p∗(z;θf )
−log h(z; θh) + log p∗(z; θf) −log p∗(z; θf)
= DKL(p∗(z; θf) ∥h(z; θh)) + H[p∗(z; θf)],
where p∗(z; θf) denotes the true distribution of the codes
produced by the encoder, and is therefore parametrized by
θf. This reformulation of the MLE objective yields meaningful insights about the entities involved in the optimization.
On the one hand, the Kullback-Leibler divergence
ensures that the information gap between our parametric
model h and the true distribution p∗is small. On the other
hand, this framework leads to the minimization of the differential entropy of the distribution underlying the codes produced by the encoder f. Such constraint constitutes a crucial point when learning normality. Intuitively, if we think
Estimated Differential Entropy
Figure 2: Estimated differential entropies delivered on each
MNIST class in the presence of different regularization
strategies: our, divergence w.r.t a Gaussian prior (VAE) and
input perturbation (DAE). For each class, the estimate is
computed on the training samples’ hidden representations,
whose distribution are ﬁt utilizing a Gaussian KDE in a 3Dspace. All models being equal, ours exhibits lower entropies
on all classes.
about the encoder as a source emitting symbols (namely,
the latent representations), its desired behavior, when modeling normal aspects in the data, should converge to a ‘boring’ process characterized by an intrinsic low entropy, since
surprising and novel events are unlikely to arise during the
training phase. Accordingly, among all the possible settings of the hidden representations, the objective begs the
encoder to exhibit a low differential entropy, leading to the
extraction of features that are easily predictable, therefore
common and recurrent within the training set. This kind of
features is indeed the most useful to distinguish novel samples from the normal ones, making our proposal a suitable
regularizer in the anomaly detection setting.
We report empirical evidence of the decreasing differential
entropy in Fig. 2, that compares the behavior of the same
model under different regularization strategies.
3.1. Architectural Components
Autoencoder blocks.
Encoder and decoder are respectively composed by downsampling and upsampling residual
blocks depicted in Fig. 1ii. The encoder ends with fully
connected (FC) layers. When dealing with video inputs,
we employ causal 3D convolutions within the encoder
(i.e., only accessing information from previous timesteps). Moreover, at the end of the encoder, we employ a
temporally-shared full connection (TFC, namely a linear
projection sharing parameters across the time axis on the
input feature maps) resulting in a temporal series of feature
vectors. This way, the encoding procedure does not shufﬂe
information across time-steps, ensuring temporal ordering.
Autoregressive layers.
To guarantee the autoregressive nature of each output CPD, we need to ensure proper
connectivity patterns in each layer of the estimator h.
Moreover, since latent representations exhibit different
shapes depending on the input nature (image or video), we
propose two different solutions.
When dealing with images, the encoder provides feature
vectors with dimensionality d.
The autoregressive estimator is composed by stacking multiple Masked Fully
Connections (MFC, Fig. 3-(a)).
Formally, it computes
output feature map o ∈Rd×co (where co is the number
of output channels) given the input h ∈Rd×ci (assuming
ci = 1 at the input layer). The connection between the
input element hk
i in position i, channel k and the output
element ol
j is parametrized by
if type = B
if type = A
Type A forces a strict dependence on previous elements
(and is employed only as the ﬁrst estimator layer), whereas
type B masks only succeeding elements. Assuming each
CPD modeled as a multinomial, the output of the last autoregressive layer (in Rd×B) provides probability estimates
for the B bins that compose the space quantization.
On the other hand, the compressed representation of video
clips has dimensionality t × d, being t the number of temporal time-steps and d the length of the code.
Accordingly, the estimation network is designed to capture twodimensional patterns within observed elements of the code.
However, naively plugging 2D convolutional layers would
assume translation invariance on both axes of the input map,
whereas, due to the way the compressed representation is
built, this assumption is only correct along the temporal
axis. To cope with this, we apply d different convolutional
kernels along the code axis, allowing the observation of the
whole feature vector in the previous time-step as well as
a portion of the current one. Every convolution is free to
stride along the time axis and captures temporal patterns. In
such operation, named Masked Stacked Convolution (MSC,
Fig. 3-(b)), the i-th convolution is equipped with a kernel
w(i) ∈R3×d kernel, that gets multiplied by the binary mask
M(i), deﬁned as
j,k ∈M(i) =
if j = 1 and k < i and type=A
if j = 1 and k ≤i and type=B
otherwise,
where j indexes the temporal axis and k the code axis.
Every single convolution yields a column vector, as a result
of its stride along time. The set of column vectors resulting
Figure 3: Proposed autoregressive layers, namely the Masked Fully Connection (a, Eq. 6) and the Masked Stacked Convolution (b, Eq. 7). For both layers, we represent type A structure. Different kernel colors represent different parametrizations.
from the application of the d convolutions to the input tensor
h ∈Rt×d×ci are horizontally stacked to build the output
tensor o ∈Rt×d×co, as follows:
[(M(i) ⊙w(i)) ∗h],
where || represents the horizontal concatenation operation.
4. Experiments1
We test our solution in three different settings: images,
videos, and cognitive data. In all experiments the novelty
assessment on the i-th example is carried out by summing
the reconstruction term (RECi) and the log-likelihood term
(LLKi) in Eq. 4 in a single novelty score NSi:
NSi = normS(RECi) + normS(LLKi).
Individual scores are normalized using a reference set of
examples S (different for every experiment),
normS(Li) =
Li −maxj∈S Lj
maxj∈S Lj −minj∈S Lj
Further implementation details and architectural hyperparameters are in the supplementary material.
4.1. One-class novelty detection on images
To assess the model’s performances in one class settings,
we train it on each class of either MNIST or CIFAR-10 separately. In the test phase, we present the corresponding test
set, which is composed of 10000 examples of all classes,
and expect our model to assign a lower novelty score to images sharing the label with training samples. We use standard train/test splits, and isolate 10% of training samples for
1Code to reproduce results in this section is released at https://
github.com/aimagelab/novelty-detection.
validation purposes, and employ it as the normalization set
(S in Eq. 9) for the computation of the novelty score.
As for the baselines, we consider the following:
- standard methods such as OC-SVM and Kernel
Density Estimator (KDE), employed out of features
extracted by PCA-whitening;
- a denoising autoencoder (DAE) sharing the same architecture as our proposal, but defective of the density
estimation module. The reconstruction error is employed as a measure of normality vs. novelty;
- a variational autoencoder (VAE) , also sharing the
same architecture as our model, in which the Evidence
Lower Bound (ELBO) is employed as the score;
- Pix-CNN , modeling the density by applying autoregression directly in the image space;
- the GAN-based approach illustrated in .
We report the comparison in Tab. 1 in which performances
are measured by the Area Under Receiver Operating
Characteristic (AUROC), which is the standard metric for
the task. As the table shows, our proposal outperforms all
baselines in both settings.
Considering
favorably.
Notably, Pix-CNN fails in modeling distributions
for all digits but one, possibly due to the complexity of
modeling densities directly on pixel space and following a
ﬁxed autoregression order. Such poor test performances are
registered despite good quality samples that we observed
during training: indeed, the weak correlation between sample quality and test log-likelihood of the model has been
motivated in .
Surprisingly, OC-SVM outperforms
most deep learning based models in this setting.
On the contrary, CIFAR10 represents a much more signiﬁcant challenge, as testiﬁed by the low performances of
most models, possibly due to the poor image resolution
and visual clutter between classes. Speciﬁcally, we observe
Table 1: AUROC results for novelty detection on MNIST and CIFAR10. Each row represents a different class on which
baselines and our model are trained.
that our proposal is the only model outperforming a simple
KDE baseline; however, this ﬁnding should be put into
perspective by considering the nature of non-parametric
estimators.
Indeed, non-parametric models are allowed
to access the whole training set for the evaluation of
each sample.
Consequently, despite they beneﬁt large
sample sets in terms of density modeling, they lead into an
unfeasible inference as the dataset grows in size.
The possible reasons behind the difference in performance
w.r.t. DAE are twofold. Firstly, DAE can recognize novel
samples solely based on the reconstruction error, hence
relying on its memorization capabilities, whereas our proposal also considers the likelihood of their representations
under the learned prior, thus exploiting surprisal as well.
Secondly, by minimizing the differential entropy of the
latent distribution, our proposal increases the discriminative capability of the reconstruction. Intuitively, this last
statement can be motivated observing that novelty samples
are forced to reside in a high probability region of the latent
space, the latter bounded to solely capture unsurprising
factors of variation arising from the training set. On the
other hand, the gap w.r.t. VAE suggests that, for the task at
hand, a more ﬂexible autoregressive prior should be pre-
ROC Curve - MNIST
ROC Curve - CIFAR
Figure 4: ROC curves delivered by different scoring strategies on MNIST and CIFAR-10 test sets. Each curve is an
interpolation over the ten classes.
ferred over the isotropic multivariate Gaussian. On this last
point, VAE seeks representations whose average surprisal
converges to a ﬁxed and expected value (i.e., the differential
entropy of its prior), whereas our solution minimizes such
quantity within its MLE objective. This ﬂexibility allows
modulating the richness of the latent representation vs. the
reconstructing capability of the model. On the contrary, in
VAEs, the ﬁxed prior acts as a blind regularizer, potentially
leading to over-smooth representations; this aspect is also
appreciable when sampling from the model as shown in the
supplementary material.
Fig. 4 reports an ablation study questioning the loss
functions aggregation presented in Eq. 9. The ﬁgure illustrates ROC curves under three different novelty scores: i)
the log-likelihood term, ii) the reconstruction term, and iii)
the proposed scheme that accounts for both. As highlighted
in the picture, accounting for both memorization and
surprisal aspects is advantageous in each dataset. Please
refer to the supplementary material for additional evidence.
4.2. Video anomaly detection
In video surveillance contexts, novelty is often considered
in terms of abnormal human behavior.
Thus, we evaluate our proposal against state-of-the-art anomaly detection models.
For this purpose, we considered two standard benchmarks in literature, namely UCSD Ped2 and
ShanghaiTech . Despite the differences in the number
of videos and their resolution, they both contain anomalies that typically arise in surveillance scenarios (e.g., vehicles in pedestrian walkways, pick-pocketing, brawling).
For UCSD Ped, we preprocessed input clips of 16 frames to
extract smaller patches (we refer to supplementary materials for details) and perturbed such inputs with random Gaussian noise with σ = 0.025. We compute the novelty score of
each input clip as the mean novelty score among all patches.
Concerning ShanghaiTech, we removed the dependency on
ShanghaiTech
MPPCA 
MPPC+SFA 
ConvAE 
ConvLSTM-AE 
Unmasking 
Hinami et al. 
Stacked RNN 
FFP+MC 
Figure 5: On the left, AUROC performances of our model w.r.t. state-of-the-art competitors. On the right, novelty scores
and localizations maps for samples drawn from UCSD Ped2 and ShanghaiTech. For each example, we report the trend of the
assessed score, highlighting with a different color the time range in which an anomalous subject comes into the scene.
the scenario by estimating the foreground for each frame of
a clip with a standard MOG-based approach and removing
the background. We fed the model with 16-frames clips,
but ground-truth anomalies are labeled at frame level. In
order to recover the novelty score of each frame, we compute the mean score of all clips in which it appears. We
then merge the two terms of the loss function following the
same strategy illustrated in Eq. 9, computing however normalization coefﬁcients in a per-sequence basis, following
the standard approach in the anomaly detection literature.
The scores for each sequence are then concatenated to compute the overall AUROC of the model. Additionally, we envision localization strategies for both datasets. To this aim,
for UCSD, we denote a patch exhibiting the highest novelty score in a frame as anomalous. Differently, in ShanghaiTech, we adopt a sliding-window approach : as expected, when occluding the source of the anomaly with a
rectangular patch, the novelty score drops signiﬁcantly.
Fig. 5 reports results in comparison with prior works, along
with qualitative assessments regarding the novelty score and
localization capabilities. Despite a more general formulation, our proposal scores on-par with the current state-ofthe-art solutions speciﬁcally designed for video applications
and taking advantage of optical ﬂow estimation and motion
constraints. Indeed, in the absence of such hypotheses (FFP
entry in Fig. 5), our method outperforms future frame prediction on UCSD Ped2.
4.3. Model Analysis
CIFAR-10 with semantic features.
We investigate the
behavior of our model in the presence of different assumptions regarding the expected nature of novel samples.
We expect that, as the correctness of such assumptions
increases,
performances
accordingly.
Such a trait is particularly desirable for
applications in which prior beliefs about novel examples
can be envisioned. To this end, we leverage the CIFAR-10
benchmark described in Sec. 4.1 and change the type of
information provided as input. Speciﬁcally, instead of raw
images, we feed our model with semantic representations
extracted by ResNet-50 , either pre-trained on Imagenet
(i.e., assume semantic novelty) or CIFAR-10 itself (i.e.,
assume data-speciﬁc novelty). The two models achieved
respectively 79.26 and 95.4 top-1 classiﬁcation accuracies
on the respective test sets. Even though this procedure is
to be considered unfair in novelty detection, it serves as a
sanity check delivering the upper-bound performances our
model can achieve when applied to even better features. To
deal with dense inputs, we employ a fully connected autoencoder and MFC layers within the estimation network.
Fig. 6-(a) illustrates the resulting ROC curves, where
semantic descriptors improve AUROC w.r.t.
inputs (entry “Unsupervised”). Such results suggest that
our model proﬁtably takes advantage of the separation
between normal and abnormal input representations and
scales accordingly,
even up to optimal performances
for the task under consideration.
Nevertheless, it is
interesting to note how different degrees of supervision
deliver signiﬁcantly different performances. As expected,
dataset-speciﬁc supervision increases the AUROC from
0.64 up to 0.99 (a perfect score). Surprisingly, semantic
feature vectors trained on Imagenet (which contains all
CIFAR classes) provide a much lower boost, yielding an
AUROC of 0.72.
Such result suggests that, even in the
rare cases where the semantic of novelty can be known in
advance, its contribution has a limited impact in modeling
the normality, mostly because novelty can depend on other
cues (e.g., low-level statistics).
Autoregression via recurrent layers.
To measure
the contribution of the proposed MFC and MSC layers
described in Sec. 3, we test on CIFAR-10 and UCSD
ROC Curve - CIFAR
Unsupervised
ResNet-50 (imagenet)
ResNet-50 (cifar)
LSTM 
MFC 
LSTM 
MSC 
Figure 6: (a) CIFAR-10 ROC curves with semantic input vectors. Each curve is an interpolation among the ten
classes. (b) Comparison of different architectures for the
autoregressive density estimation in feature space. We indicate with LSTM[F1,F2,...,FN] - same goes for MFC and
MSC - the output shape for each of the N layers composing
the estimator. Results are reported in terms of test AUROC.
Ped2, alternative solutions for the autoregressive density
estimator. Speciﬁcally, we investigate recurrent networks,
as they represent the most natural alternative featuring
autoregressive properties.
We benchmark the proposed
building blocks against an estimator composed of LSTM
layers, which is designed to sequentially observe latent
symbols z<i and output the CPD of zi as the hidden
state of the last layer.
We test MFC, MSC and LSTM
in single-layer and multi-layer settings, and report all
outcomes in Fig. 6-(b).
It emerges that, even though our solutions perform similarly to the recurrent baseline when employed in a shallow
setting, they signiﬁcantly take advantage of their depth
when stacked in consecutive layers.
MFC and MSC,
indeed, employ disentangled parametrizations for each
output CPD. This property is equivalent to the adoption of
a specialized estimator network for each zi, thus increasing
the proﬁciency in modeling the density of its designated
CPD. On the contrary, LSTM networks embed all the
history (i.e., the observed symbols) in their memory cells,
but manipulate each input of the sequence through the same
weight matrices. In such a regime, the recurrent module
needs to learn parameters shared among symbols, losing
specialization and eroding its modeling capabilities.
4.4. Novelty in cognitive temporal processes
As a potential application of our proposal, we investigate its
capability in modeling human attentional behavior. To this
end, we employ the DR(eye)VE dataset , introduced for
the prediction of focus of attention in driving contexts. It
features 74 driving videos where frame-wise ﬁxation maps
are provided, highlighting the region of the scene attended
by the driver. In order to capture the dynamics of attentional patterns, we purposely discard the visual content of
Novelty score
DR(eye)VE Novelty Score Distribution
Normal patterns
Attentional shifts
Figure 7: Left, the distribution of novelty scores assigned
to normal patterns against attentional shifts labeled within
the DR(eye)VE dataset. Right, DR(eye)VE clips yielding
the highest novelty score (i.e., clips in which the attentional
pattern shifts from the expected behavior). Interestingly,
they depict some peculiar situations such as waiting for the
trafﬁc light or approaching a roundabout.
the scene and optimize our model on clips of ﬁxation maps,
randomly extracted from the training set. After training, we
rely on the novelty score of each clip as a proxy for the uncommonness of an attentional pattern. Moreover, since the
dataset features annotations of peculiar and unfrequent patterns (such as distractions, recording errors), we can measure the correlation of the captured novelty w.r.t. those. In
terms of AUROC, our model scores 0.926, highlighting that
novelty can arise from unexpected behaviors of the driver,
such as distractions or other shifts in attention. Fig. 7 reports the different distribution of novelty scores for ordinary
and peculiar events.
5. Conclusions
We propose a comprehensive framework for novelty detection. We formalize our model to capture the twofold nature
of novelties, which concerns the incapability to remember
unseen data and the surprisal aroused by the observation of
their latent representations. From a technical perspective,
both terms are modeled by a deep generative autoencoder,
paired with an additional autoregressive density estimator
learning the distribution of latent vectors by maximum
likelihood principles.
To this aim, we introduce two
different masked layers suitable for image and video data.
We show that the introduction of such an auxiliary module,
operating in latent space, leads to the minimization of
the encoder’s differential entropy, which proves to be a
suitable regularizer for the task at hand.
Experimental
results show state-of-the-art performances in one-class
and anomaly detection settings, fostering the ﬂexibility
of our framework for different tasks without making any
data-related assumption.
Acknowledgements.
We gratefully acknowledge Facebook
Intelligence
Silicon Valley Lab for the donation of GPUs used for this