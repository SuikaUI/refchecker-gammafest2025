SÉMINAIRE DE PROBABILITÉS (STRASBOURG)
PIERRE DEL MORAL
LAURENT MICLO
Branching and interacting particle systems.
Approximations of Feynman-Kac formulae with
applications to non-linear ﬁltering
Séminaire de probabilités (Strasbourg), tome 34 , p. 1-145
< >
© Springer-Verlag, Berlin Heidelberg New York, 2000, tous droits réservés.
L’accès aux archives du séminaire de probabilités (Strasbourg)
( 
mathdoc.fr/SemProba/) implique l’accord avec les conditions générales d’utilisation ( Toute utilisation commerciale ou impression systématique est constitutive d’une infraction pénale. Toute copie ou impression de ce ﬁchier doit contenir la présente mention de copyright.
Article numérisé dans le cadre du programme
Numérisation de documents anciens mathématiques
 
Branching and Interacting Particle Systems
Approximations of Feynman-Kac Formulae
with Applications to Non-Linear Filtering
P. Del Moral
LSP-CNRS and Universite Toulouse III
This paper focuses on interacting particle systems methods for solving numerically a
class of Feynman-Kac formulae arising in the study of certain parabolic differential
equations, physics, biology, evolutionary computing, nonlinear filtering and elsewhere.
We have tried to give an "expose" of the mathematical theory that is useful for analyzing the convergence of such genetic-type and particle approximating models including
law of large numbers, large deviations principles, fluctuations and empirical process
theory as well as semigroup techniques and limit theorems for processes.
In addition, we investigate the delicate and probably the most important problem of
the long time behavior of such interacting measure valued processes.
We will show how to link this problem with the asymptotic stability of the corresponding limiting process in order to derive useful uniform convergence results with
respect to the time parameter.
Several variations including branching particle models with random population size
will also be presented. In the last part of this work we apply these results to continuous
time and discrete time filtering problems.
Interacting and branching particle systems, genetic algorithms, weighted sampling
Moran processes, measure valued dynamical systems defined by Feynman-Kac formulae, asymptotic stability, chaos weak propagation, large deviations principles, central
limit theorems, nonlinear filtering.
A.M.S. codes:
60G35, 60F10, 60H10, 60G57, 60K35, 60F05, 62L20, 92D25, 92D15, 93E10, 93E11.
1 Introduction
Background and Motivations ........................
1.2 Motivating Examples ............................
1.3 Description of the Models , .... , ................... 11
The Limiting Measure Valued Models ............... 13
Interacting Particle Systems Models ................ 14
Outline and Contents ............................ 17
2 The Discrete Time Case
Structural Properties of the Limiting Process............... 19
Dynamics Structure ......................... 20
2.1.2 Asymptotic Stability ...................... , . 23
2.2 Asymptotic Behavior of the Particle Systems ............... 30
Introduction............................. 30
Lp-mean errors
........................... 34
Glivenko-Cantelli Theorem ..................... 39
Central Limit Theorems ...................... 41
Large Deviations Principles
.................... 53
2.3 Branching Particle Systems Variants
................... 58
Periodic Interactions/Selections .................. 59
Conditional Mutations ....................... 62
2.3.3 BranchingSelections ........................ 65
Regularized Mutations ....................... 71
3 The Continuous Time Case
3.1 Hypotheses on the Limiting Process .................... 75
Definitions and Weak Regularity Assumption
.......... 75
Strong Regularity Assumptions
.................. 81
3.1.3 Asymptotic Stability ........................ 88
3.2 The Interacting Particle System Model .................. 92
3.3 Asymptotic Behavior ............................ 94
Weak Propagation of Chaos
.................... 95
Central Limit Theorem ....................... 104
Exponential Bounds ........................ 109
4 Applications to Non Linear Filtering
4.1 Introduction ................................. 112
Continuous Time Filtering Problems
................... 113
Description of the Models ..................... 113
4.2.2 Examples ..............................120
4.3 Time Discretization of Continuous Time Filtering Problems ...... 122
Discrete Time Filtering Problems ..................... 127
Description of the Models ..................... 127
Averaged Results .......................... 128
5 Appendix and Index of Notations
Introduction
1.1 Background and Motivations
The aim of this set of notes is the design of a branching and interacting particle system (abbreviate BIPS) approach for the numerical solving of a class of Feynman-Kac
formulae which arise in the study of certain parabolic differential equations, physics,
biology, evolutionary computing, economic modelling and nonlinear filtering problems.
Our major motivation is from advanced signal processing and particularly from
optimal nonlinear filtering problems. Recall that this consists in computing the conditional distribution of a partially observed Markov process.
In discrete time and in a rather general setting the classical nonlinear filtering
problem can be summarized as to find distributions of the form
~f ~ Bb(E), ~n ~ 0,
= 03B3n(f) 03B3n(1)
where Bb(E) is the space of real bounded measurable functions over a Polish state
space E and ~n( f ) is a Feynman-Kac formula given by
03B3n(f) =
03A0 gm(Xm-1))
where {Xn ; n > 0} is a given time inhomogeneous Markov chain taking values in E
; m > 1} is a given sequence of bounded positive functions.
In continuous time, the computation of the optimal pathwise filter can be summarized as to find the flow of distributions
~ f ~ Bb(E), ~t ~ R+,
= 03B3t(f) 03B3t(1)
where 03B3t(f) is again defined through a Feynman-Kac formula of the following form
03B3t(f) = E( f(Xt) exp (t0Us(Xs)ds))
This time {Xt ; t ~ R+} denotes an E-valued cadlag inhomogeneous Markov process
and {Ut ; t E 1~+} is a measurable collection of locally bounded (in time) and measurable nonnegative functions.
Even if equations (1) and (3) look innocent they can rarely be solved analytically
and their solving require extensive calculations. More precisely, with the notable
exception of the so-called "linear-Gaussian" situation (Kalman-Bucy’s filter ) or
wider classes of models (Benes’ filters ) optimal filters have no finitely recursive
solution . To obtain a computationally feasible solution some kind of approximation is needed.
Of course, there are many filtering algorithms that have been developed in mathematics and signal processing community. Until recently most works in this direction were
based on fixed grid approximations, conventional linearization (Extended Kalman Filters) or determining the best linear filter (in least squares sense). These various numerical methods have never really cope with large scale systems or unstable processes.
Comparisons and examples when the extended Kalman-Bucy filter fails can be found
for instance in . In addition all these deterministic schemes have to be handled
very carefully mainly because they are usually based on specific criteria and rates of
convergence are not always available.
The particle algorithms discussed in these lectures belong to the class of Monte
Carlo methods and they do not use regularity informations on the coefficients of the
models. Thus, large scale systems and nonlinear models with non sufficiently smooth
coefficients represent classes of nonlinear filtering problems to which particle methods
might be applied. These methods are in general robust and very efficient and many
convergence results are available including uniform convergence results with respect to
the time parameter. But, from a strict practical point of view, if there exists already
a good specialized method for a specific filtering problem then the BIPS approach
may not be the best tool for that application..
Let us briefly survey some distinct approaches and motivate our work.
In view of the functional representations (1) and (3) the temptation is also to
apply classical Monte-Carlo simulations based on a sequence of independent copies of
the process X. Unfortunately it is well known that the resulting particle scheme is
not efficient mainly because the deviation of the particles may be too large and the
growth of the exponential weights with respect to the time parameter is difficult to
control (see for instance ).
In we propose a way to regularize these weights and we give a natural ergodic
assumption on the signal semigroup under which the resulting Monte-Carlo particle
scheme converges in law to the optimal filter uniformly with respect to the time parameter.
In more general situations, complications occur mainly because this particle scheme
is simply based on a sequence of independent copies of the signal. This is not surprising : roughly speaking the law of signal and the desired conditional distribution may
differ considerably and they may be too few particles in the space regions with high
probability mass.
Among the most exciting developments in nonlinear filtering theory are those
centering around the recently established connections with branching and interacting
particle systems. The evolution of this rapidly developing area of research may be seen
quite directly through the following chains of papers , , , , , as well as and finally .
Instead of hand crafting algorithms, often based on the basis of had-hoc criteria,
particle systems approaches provide powerful tools for solving a large class of nonlinear filtering problems. In contrast to the first Monte-Carlo scheme the branching
and interacting particle approximating models involve the use of a system of particles
which evolve in correlation with each other and give birth to a number of offsprings
depending on the observation process. This guarantees an occupation of the probability space regions proportional to their probability mass thus providing a well behaved
adaptative and stochastic grid approximating model. Furthermore these particle algorithms also belong to the class of resampling methods and they have been made
valuable in practice by advances in computer technology . Different adaptative
locally refined but deterministic multi-grid methods can be found in . In contrast
to BIPS approaches the latter are limited to low dimensional state space examples.
It is hard to know where to start in describing contributions to BIPS approximations of Feynman-Kac formulae.
In discrete time and nonlinear filtering settings the more embryonic form of interacting particle scheme appeared in the independent works , and . The
first proof of convergence of these heuristics seems to be . The analysis of the
convergence has been further developed in .
In continuous time settings the origins of interacting particle schemes is a more
delicate problem. The first studies in continuous time settings seem to be and .
These works were developed independently of the first set of referenced papers. The
authors present a branching particle approximating model without any rates of convergence and the main difference with previous interacting particle schemes comes from
the fact that the number of particle is not fixed but random. Moreover the authors
made the crucial assumptions that we can exactly simulate random transitions according to the semigroup of the continuous time signal and stochastic integrals arising in
Girsanov exponentials are exactly known. Therefore these particle algorithms do not
applied directly to the continuous time case. On the other hand these branching particle models are based on a time discretization procedure. As a result the corresponding
nonlinear filtering problem can be reduced to a suitably defined discrete time filtering
problem. The corresponding discrete time version of such branching and interacting
particle schemes as well as the first convergence rates are described in and .
The studies and discuss several new interacting particle schemes for
solving nonlinear filtering problems where the signal is continuous but the number
of observations is finite. To get some feasible solution which can be used in practice several additional levels of approximations including time discretizations are also
analyzed. In contrast to previous referenced papers these schemes can also be used
for solving numerically filtering problems with correlated signal and observation noise
As we shall see in the further development of section 1.2 the interacting or branching particle schemes based on an additional time discretization procedure are not
really efficient for solving continuous time filtering problems. The authors presented
in a genuine continuous time genetic type particle scheme for solving the robust
optimal filter. This scheme will be discussed in section 1.3 and section 3.
The connections between this IPS model, the classical Moran IPS and the Nanbu
IPS (arising respectively in the literature of genetic algorithms and Boltzmann equations) are discussed in section 1.3.
The modelling and the analysis of such particle approximating models has matured over the past ten years in ways which make it much more complete and rather
beautiful to learn and to use. One objective of these notes is to introduce the reader to
branching and interacting particle interpretations of Feynman-Kac formulae of type
We have also tried to give an "expose" of the mathematical theory that it is useful in
analyzing the convergence of such approximating models including law of large numbers, large deviations, fluctuations and empirical process theory, as well as semigroup
techniques and functional limit theorems for stochastic processes.
Although only a selection of existing results is presented, many results appear here
for the first time and several points have been improved. The proofs of existing results
are only sketched but the methodologies are described carefully. Deeper informations
are available in the list of referenced papers.
The material for this paper has also been chosen in order to give some feel of the
variety of the theory but the development is guided by the classical interplay between
theory and detailed consideration of application to specific nonlinear filtering models.
This set of notes is very far from being exhaustive and only surveys results that are
closely related to BIPS-approximations of Feynman-Kac formulae and non linear filtering problems. Among the topics omitted are those centering around evolutionary
computing and numerical function optimization problems. Among the huge literature on evolutionary computing and genetic algorithms we refer to , ,
 , , and .
We emphasize that the so-called simple genetic algorithm is a special case of the BIPS
models presented in this work.
In this connection, the measure valued distribution flows ( 1 )-(4) and the corresponding interacting particle approximating models can be regarded as the so-called infinite
and finite population models. Therefore the methodologies presented in this work can
be used for establishing the most diverse limit theorems on the long time behavior of
these models as well as the asymptotics of the finite population model as the number
of individuals tends to infinity.
An overview of the material presented in these notes was presented in a three one
hour lectures for the Symposium/Workshop on Numerical Stochastics at
the Fields Institute for Research in Mathematical Sciences (Toronto). At the same
period they were presented at the University of Alberta Edmonton with the support of
the Canadian Mathematics of Information Technology and Complex Systems project
We would like to thank Professor M. Kouritzin from the University of Alberta for
stimulating discussions.
A part of this material presented in this set of notes results from collaborations of
one of the authors with D. Crisan and T. Lyons , with A. Guionnet ,
with J. Jacod and Ph. Protter , and with M. Ledoux .
We also heartily thank Gerard Ben Arous, Carl Graham and Sylvie Meleard for
encouraging and fruitful discussions and Michel Ledoux for inviting us to write these
notes for Le Seminaire de Probabilités.
We gratefully acknowledge CNRS research fellowship No 97N23/0019 "Modelisation et simulation numérique", European community for the CEC Contracts No
ERB-FMRX-CT96-0075 and INTAS-RFBR No 95-0091 and the Canadian Network
MITACS-Prediction In Interacting Systems.
1.2 Motivating Examples
The interacting particle interpretation of the Feynman-Kac models (1)-(4) has had
numerous applications in many nonlinear filtering problems; to name a few, radar
signal processing ( ), global positioning system ( ) and tracking problems
( ). Other numerical experiments are also given in and .
The purpose of these notes is to expose not only the theory of interacting particle
approximations of Feynman-Kac formulae but also to provide a firm basis for the
understanding and solving nonlinear filtering problems. To guide the reader and motivate this study we present here two generic models and the discrete and continuous
time Feynman-Kac formulations of the corresponding optimal filter.
The distinction between continuous and discrete time will lead to different kind
of interacting particle approximating models. Intuitively speaking continuous time
models correspond to processes of classical physics while discrete time models arise in
a rather natural way as soon as computers are part of the process. More general and
detailed models will be discussed in the further development of section 4.
In discrete time settings the state signal X = (Xn. ;
n > 0} is an Rp-valued
Markov chain usually defined through a recursion of the form
= {Wn ; n > 1 ~ is a noise sequence of independent and Revalued random
variables. For each n > 1 the function Fn
JRP is measurable and the initial
value Xo is independent of W. The above recursion contains the laws of evolution for
system states such as the laws of evolution of a target in tracking problems, an aircraft
in radar processing or inertial navigation errors in GPS signal processing. The noise
component W models the statistics of unknown control laws of an aircraft or a cruise
control in an automobile or a non cooperative target as well as uncertainties in the
choice of the stochastic mathematical model.
For future reference it is convenient to generalize the definition of the state signal
. More precisely an alternative way to define X consists in embedding the latter
random dynamical system through its transition probabilities. This approach gives
some insights into ways of thinking the evolution of the marginal laws of X and it
also allows to consider signals taking values on infinite dimensional spaces. For these
reasons we will systematically assume that the sequence X = {Xn ; n > 0~ is a
Markov process taking values in a Polish state space E with transition probabilities
{Kn ; n > 1} and initial distribution y/o- As we shall see in the further development
this formulation also allows a uniform treatment of filtering problems with continuous
time signals and discrete time observations. The signal X is not known but partially
observed. Usually we assume that the observation process Y =
> 1 ~ is a
sequence of Revalued random variables given by
where V = ~Vn ; n > 1} are independent and l~r valued random variables whose
marginal distributions possess a density
with respect to Lebesgue measure on
I~r and for each n > 1, hn
: E ~ l~r is a measurable function.
Here again the design of the disturbance sequence V depends on the class of sensors
at hand. For instance noise sources acting on sensors model thermic noise resulting
from electronic devices or atmospheric propagation delays and/or received clock bias
in GPS signal processing. For more details we refer the reader to the set of referenced
Given the stochastic nature of the pair signal/observation process and given the
observation values Yn = yn, for each n > 1, the nonlinear filtering problem consists in
computing recursively in time the one step predictor conditional probabilities qn and
the filter conditional distributions Tin given for any bounded Borel test function f by
= yla...,Yn = yn)
= E(/(X.)!~=~...~ =
As usually the n-step filter Tin is written in terms of ~n as
n(f) = Ef(x)03C6n+1(yn+1 = hn+1(x)) ~n(dx) E 03C6n+1(yn+1 - hn+1(x))
and the n-step predictor may be defined in terms of the Feynman-Kac type formula
~n(f) = 03B3n(f) 03B3n(1)
03B3n(f) = E
(f(Xn)03A003C6m(ym - hm(xm-1)))
We will return to this model with more detailed examples in section 5.
The second filtering model presented hereafter is a continuous time (signal/observation) Markov process ~(St, Y) ; t E
taking values in IRP x
It is solution of
the Ito’s stochastic differential equation
dst = A(t, St ) dt + B(t, St ) dWt + ~m C(t, St_, u)
- v(dt, du))
= h(St)dt + 03C3dVt
(V, W ) is an (q + r) dimensional standard Wiener process and is a Poisson random
measure on R+
with intensity measure v(dt, du) = dt ® F(du) and F is a positive
a-finite measure on
The mappings A : R+ x
I~p @ l~r,
C : R+ x RP x
RP, and h :
R~ are Borel functions, So is a random
variables independent of (V, W,
and Yo = 0.
Here again the first equation represents the evolution laws of the physical signal
process at hand. For instance the Poisson random measure may represent jumps
variations of a moving and non cooperative target (see for instance ).
Next we examine three situations. In the first one we assume that observations
are given only at regularly spaced times to, tl, ... , tn, ... E R+ (to = 0, Yo = 0) and we
are interested in the conditional distributions given for any bounded Borel function
f : : RP - R by
n(f) = E(f(Stn) |Yt1 = y1,...,Ytn = yn)
where y1, ... , yn E l~q is a given sequence of observations.
If we denote E = D ([0,
the Polish space of cadlag paths from [0, ti into l~p
then the discrete time sequence
~ > O ~,~ def .
stands for the usual family of time shifts), is an E-valued Markov chain.
On the other hand if H : E - R~ is the mapping defined by
H(x) = t10 h(xs) ds
then using the above notations for any n ~ 1:
Y;n-1 = H(Xn-1
This description is interesting in that it shows that the latter filtering problem is
equivalent to the previous discrete time model. In this connection it is also worth
noting that for any bounded Borel test function f : E -~ R
- - yl’ ~ . ,’ Ytn - - yn) - -
03B3n(f) = E(
f(Xn)03A003C6m(ym -
ym-1 - H(Xm-1)))
where, for any m ~ 1, 03C6m is the density of the Gaussian variable 03C3(Vtm - Vtm-1).
observation also explain why it is necessary to undertake a study of Feynman-Kac
formula of type (1) with Polish valued Markov processes X.
A more traditional question in continuous time nonlinear filtering settings is to
compute the conditional distributions {1rt ; t E
given for any bounded Borel
functions f :
R by setting
is the filtration generated by the observations up to time t. Roughly
speaking this continuous time problem is close to the previous discrete time model
when the time step At = tn - tn-i is sufficiently small and when observations are
delivered continuously in time. For instance in radar processing the measurements
derived from the return signal of a moving target can be regarded as a pulse train of
rectangular or Gaussian pulses with period 10-4 seconds.
In real applications one usually consider the discrete time signal model
{Stn ; n > 0}
as Revalued Markov chain and one replaces the continuous time observation process
by the discrete time sequence
This first level of approximation is commonly used in practice and the error caused
by the discretization of the time interval is well understood (see for instance and
references therein as well as section 4.3 in these notes).
One consequence of the previous discretizarion is that the filtering problem is now
reduced to find a way of computing the conditional distributions given for any bounded
Borel function f : l~p -~ R by
with yo = 0 and
03B30394n =
03C6m(ym - ym-1 - h(Stm-1)0394t))
One drawback of this formulation is that the corresponding IPS approximating model
is not really efficient. As we shall see in the further development of section 1.3 and
section 4.3 the evolution of this scheme is decomposed into two genetic type selection/mutation transitions. During each selection stage the system of particles takes
advantage of the current observation data in order to produce an adaptative grid.
The underlying nth step selection transition is related to the fitness functions gn defined by
but the physical noise in sensors as well as the choice of the short time step At
critically corrupt the information delivered between two dates (recall that the current
observation at time n has the form (6)). One consequence is that the resulting particle
scheme combined with the previous time discretization converges slowly to the desired
conditional distributions (5) (see for instance section 4.3 and as well as 
for a branching particle alternative scheme).
One way to improve these rates is to use a genuine continuous time and interacting
particle approximating model. In this alternative approach the information used at
each selection date is not the "increments" of the observation process but the current
observation value at that time.
The key idea presented in and further developed in this work is to study the
robust and pathwise filter defined for any y E C(R+,
(and not only on a set of
probability measure 1) and for any bounded Borel function f :
by a formula
of the form
03C0 y,t(f)
Rp f(x)eh*(x)yt ~y,t(dx) Eeh*(x)yt ~y,t(dx)
= 03B3y,t(f) 03B3y,t(1)
is again defined through a Feynman-Kac type formula
03B3y,t(f) = E(f(Xyt) exp
t0 Vs(Xys,ys)
For any s ~ R+, Vs : Rp Rq ~
R+ is a Borel measurable function which depends
on the coefficients of the filtering problem at hand and
is a Markov
process which depends on the observations. To describe precisely these mathematical
models we need to introduce several additional notations. We will return to this model
with detailed examples of signal processes which can be handled in our framework in
section 4.2.
The convergence results for the resulting interacting particle approximating model
will improve the one presented in section 4.3 and in the articles . From a
practitioner’s view point the main difference between these two approaches lies in the
fact that in the former the selection and interaction mechanism only depends on the
current observation yt and on the fitness function
yt). Moreover under
natural stability assumptions the resulting IPS scheme converges uniformly in time
to the desired optimal filter.
1.3 Description of the Models
To provide a red line in this work and to point out the connections with classical
mean-field interacting particle system theory, the models are focused around two approximating interacting particle systems (abbreviate IPS): The research literature
abounds with variation of these two IPS models. The interested reader will also find
a detailed description of several variants including branching schemes with random
population size, periodic selection schemes and conditional mutations.
Most of the terminology we have used is drawn from mean field IPS and measure
valued processes theory. We shall see that the flows of distributions (1) and (3) are
solutions of deterministic measure valued and nonlinear evolution equations. These
equations will be used to define the transition probability kernel of the corresponding
IPS approximating models. In this sense the deterministic evolution equations will
be regarded as the limiting measure valued process associated with a sequence of IPS
The resulting IPS models can also be regarded as genetic type algorithms as
those arising in numerical function optimization, biology and population analysis
(cf. ).
The range of research areas in which genetic algorithms arise is also quite board, to
name a few: machine learning , control systems , electromagnetics ,
economics and finance , aircraft landing , topological optimum design
 and identification of mechanical inclusions .
In continuous time settings the corresponding IPS can be viewed as a weighted
sampling Moran particle system model. Moran particle models arise in population
genetics. They usually model the evolution in time of the genetic structure of a large
but finite population (see for instance and references therein). In the classical
theory of measure valued processes the limiting process is random and it is called the
Fleming-Viot process. In this setting the limiting process is commonly used to predict
the collective behavior of the system with a finite but large number of particles.
In contrast to the above situation the desired distributions (1) and (3) are not random (except, in filtering settings, through the observation process). It is therefore
necessary to find a new strategy to define an IPS scheme that will approximate (1)
In time homogeneous settings and in the case where E =
> 1, the evolution
equation (11) and the corresponding IPS can also be regarded, in some sense, as a
simple generalized and spatially homogeneous Boltzmann equation and as the corresponding Nanbu type IPS (see for instance and references therein). At this
juncture many results presented in this work can be applied, but this is outside the
scope of these notes, to study the fluctuations or to prove uniform convergence results
for a class of Nanbu IPS.
Let us finally mention that the Feynman-Kac models considered in this study can
be regarded as the distributions of a random Markov particle X killed at a given
rate and conditioned by non-extinction (see for instance ). In this connection the
asymptotic stability properties of the limiting processes associated with the Feynman-
Kac models can be used to give conditions under which a killed particle conditioned
by non-extinction forgets exponentially fast its initial condition (see for instance ).
In view of the above discussion the objects on which the limiting processes (8),
(11) and the corresponding IPS schemes are sought may vary considerably. It is
therefore necessary to undertake a study of the convergence in an abstract and time
inhomogeneous setting.
For instance, in nonlinear filtering applications the time-inhomogeneous assumption
is essential since the objects depend on the observation process.
The genetic type algorithms arising in numerical function analysis or nonlinear control problems usually also depends on a specific cooling schedule parameter (see for
instance )
The Limiting Measure Valued Models
To describe precisely the limiting measure valued models, let us introduce some notations. Let (E, r) be a Polish space, ie E is a separable topological space whose
topology is given by a metric r which is supposed to be complete.
Let B(E) be the a-field of Borel subsets of E. We denote by M(E) the space of
all finite and signed Borel measures on E. Let Mi(E) C M(E) be the subset of all
probability measures. As usual, both spaces will be furnished with the weak topology.
We recall that weak topology is generated by the Banach space Cb(E) of all bounded
continuous functions, endowed with the supremum norm, defined by
~ f ~ Cb(E),
= sup|f(x)
(since M(E) can be regarded naturally as a part of the dual of Cb(E)). More generally, the norm ]] . ]] is defined in the same way on Bb(E), the set of all bounded
measurable functions, which is also a Banach space.
We denote by ~cK the measure given by
where K is
any integral operator on Bb(E),
M(E) and A E B(E). We also write
V f E Bb(E) ,
If Ki and Ki are two integral operators on Bb(E) we denote by
the composite
operator on Bb(E) defined for any f E Bb(E) by
K1K2f(x) =
EK1(x,dy)K2(y,dz)f(z)
We also denote by {Kn ; n ~ 1} the transition probability kernels (respectively
; t > 0~ the family of pregenerators) of the discrete time (resp. the continuous
time) Markov process X.
To get formally the nature of such schemes we first note that the distribution flow
~r~n ; n > 0~ defined by (1) page 3 is a solution of the following measure valued
dynamical system
1’]n = ~~(~~-y
For all n > 1, ~~, : Ml (E) --~ Mi(E) is the mapping defined by
We note that the recursion (8) involves two separate transitions:
Updating -..
Prediction
The first one is nonlinear and it will be called the updating step and the second one
is linear and it will be called the prediction transition with reference to filtering theory.
In the continuous time situation, the distributions flow {1]t ; t > 0~ defined by
(3) page 3 satisfies for any regular test function f the following nonlinear evolution
) = ~t(t,~t(f))
for t > 0 and 1] E Mi(E) fixed, is a pregenerator on E, defined on a
suitable domain by
1.3.2 Interacting Particle Systems Models
In this section we introduce the IPS approximating models of the previous evolution
equations (8) and (11). To give an initial introduction and to illustrate the idea in a
simple form we emphasize that the particle approximation approach described here
is not restricted to the particular form of mappings
> 1~ or to the nature of
the pregenerators
In discrete time, starting from a collection of mappings
M1 (E) - Ml (E),
we consider an N-IPS, ~~, = (~’~,, ... , ~’~ ), n > 0, which is a Markov chain on the
product state space EN with transition probability kernels satisfying
where dx def dxl x ... x dxN is an infinitesimal neighborhood of the point x =
(~1, ... , xN) E EN, z =
... , zN) E EN, ~d stands for the Dirac measure at a E E
~ z = (z1,
, zN) ~ EN,
The initial system go = (~o, ... , ~o ) consists in N independent particles with common
Intuitively speaking it is quite transparent from the above definition that if
sufficiently regular and if
is close to the desired distribution
expects that
is a nice approximating measure for 1]n. Therefore at the
next step the particle system 03BEn = (03BE1n,...,03BENn) looks like a sequence of independent
random variables with common law 1]n. This general and abstract IPS model first
appeared in and its analysis was further developed in .
In much the same way starting from a family of pregenerators
~ t ~ 0, rl E
we consider an interacting N-particle system
((~’t,...,~N))t», which is
a time-inhomogeneous Markov process on the product space EN, N > 1, whose
pregenerator acts on functions ~ belonging to a good domain by
V (x1, ... , xN) E EN, ~tNl(~)(x1, ... , xN)
The notation ,Ct$~ has been used instead of ,Ct,~ when it acts on the i-th variable of
... , xN). This abstract and general formulation is well known in mean field IPS
literature (the interested reader is for instance referred to and and references
In section 3.2 we will give a more detailed description of (15) when the pregenerators
are defined by (12).
In discrete time settings, a more explicit description of ( 13) in terms of a two stage
genetic type process can already been done. More precisely, using the fact that the
mappings 03A6n under study are given by (9) and
03A8n(1 N03A303B4xi) =
03A3gn(xi) 03A3Nj=1gn(xj)
we see that the resulting motion of the particles is decomposed into two separate
mechanisms
Selection/Updating
Mutation/Prediction
These mechanisms can be modelled as follows:
Selection/Updating:
= z) = N N
p=i i=l ij=1
Mutation/Prediction:
= x) == ]~[
Thus, we see that the particles move according to the following rules. In the
selection transition, one updates the positions in accordance with the fitness functions
~gn; n > 1 ~ and the current configuration. More precisely, at each time n > 1, each
particle examines the system
(~n_1, ... , ~’~ 1 ~ and chooses randomly a site
1 ! N, with a probability which depends on the entire configuration ~n-i
and given by
This mechanism is called the selection/updating transition as the particles are selected
for reproduction, the most fit individuals being more likely to be selected. In other
words, this transition allows particles to give birth to some particles at the expense
of light particles which die.
The second mechanism is called mutation/prediction since at this step each particle
evolves randomly according to a given transition probability kernel.
The preceding scheme is clearly a system of interacting particles undergoing adaptation in a time non-homogeneous environment represented by the fitness functions
{~; ~ ~ 1}. Roughly speaking the natural idea is to approximate the two step transitions (10) of the system (8) by a two step Markov chain taking values in the set of
finitely discrete probability measures with atoms of size some integer multiple of 1/N.
Namely, we have that
Selection ~ ~ 1 ~-~
= ~Z.~-120142014~-i = ~z~~20142014~=~E~-
As it will be obvious in subsequent sections the continuous time IPS model is again
a genetic type model involving selection and mutation transitions.
Another interest feature of the IPS defined by (13) and (22) is that they can be
used to approximate the Feynman-Kac formulae (2) and (4). One of the best ways for
introducing the corresponding particle approximating models is through the following
observation. In discrete time and on the basis of the definition of the distributions
> 0} we have that
~n ~ 1, ~n-1(gn) = 03B3n-1(gn) 03B3n-1(1) = 03B3n(1) 03B3n-1(1)
Therefore for any f e Bb(E) and n > 0
(with the convention fl, =1). Taking in consideration the above formula the natural
particle approximating scheme for the "unnormalized" distributions
simply given by
Similarly, in continuous time settings we have that
~t(Ut) = d dt log E [exp t0 Us(Xs)ds]
in the Radon-Nykodim sense and a.s. for t > 0. Thus, one gets
03B3t(f) = 03B3t(1)~t(f)
03B3t(1) = exp t0 ~s(Us)
Therefore the natural particle approximating model for the flow of "un-normalized"
distributions is given by
03B3Nt(f) =
03B3Nt(1) ~Nt(
03B3Nt(1) =
exp t0~Ns(Us)
where ~Nt is again the empirical measure of the system 03BEt.
Outline and Contents
These notes are essentially divided into three main parts devoted respectively to discrete time and continuous time models and applications to nonlinear filtering problems.
The first part (section 2) concerns discrete time models. Most of the material
presented in this section is taken from the papers , and .
Section 2.1 focuses on the standard properties of the limiting process needed in the
further development of section 2.2. In the preliminary subsection 2.1.1 we give a brief
exposition of basic terminologies and properties of the limiting process. In subsection
2.1.2 we discuss the delicate and important problem of the asymptotic stability of
the nonlinear semigroup associated with the limiting process. These properties are
treated under several type of hypothesis on the functions {gn ; n > 1} and on the
transition semigroup associated with the Markov process X. We will also connect in
section 2.2.3 these stability properties with the study of the long time behavior of the
IPS approximating models.
In nonlinear filtering settings these properties are also essential in order to check
whether or not the so-called nonlinear filtering equation forgets erroneous initial conditions. Applications to discrete time filtering problems are discussed in section 5.4.
Section 2.2 is concerned with the asymptotic behavior of the IPS models as the
number of particles tends to infinity. This section is essentially divided into four parts.
Each of them is devoted to a specific technique or notion to analyze the convergence of
the IPS models. This section covers 1Lp-mean error bounds and uniform convergence
results with respect to the time parameter as well as functional central limit theorems,
a Glivenko-Cantelli Theorem and large deviations principles.
The quick sketch of the contents of this section will be developed more fully in the
preliminary and introductive section 2.2.1.
In section 3 we propose to extend some of the above results to continuous time
models. This analysis involves different techniques and it is far from being complete.
Among these techniques two are of great importance: semigroup techniques and limit
theorems for processes.
In the preliminary section 3.1 we discuss the main hypothesis on the Feynman-
Kac formula needed in the further development of section 3.3. In the first subsections
3.1.1 and 3.1.2 we present several regularity assumptions on the fitness functions
~Ut ; t > 0~ and on the Markov process {Xt ; t > 0~. Section 3.1.3 is concerned
with extending the techniques presented in section 2.1.2 to derive stability properties
of the Feynman-Kac limiting process. These results will be important later to prove
uniform convergence results with respect to the time parameter.
In section 3.2 we give a rigorous mathematical model for the continuous time IPS
approximating scheme.
The asymptotic behavior of these IPS numerical schemes as the number of particles tends to infinity is discussed in section 3.3. In the first subsection 3.3.1 we
propose 1Lp-mean errors as well as uniform results. In the last subsection 3.3.2 we
prove a functional central limit theorem. Many important problems such as that of
the fluctuations and large deviations for the empirical measures on path space remain
to be answered.
In view of their kinship to discrete time models the results presented in section 3
can be seen as a good departure to develop a fairly general methodology to study the
same asymptotic properties as we did for the discrete time IPS models.
To guide the reader we give in all the development of section 2 and section 3 several comments on the assumptions needed in each specific situation. In section 5 we
give detailed and precise examples for each particular assumption.
The applications of the previous results to nonlinear filtering problems are given in
section 4. We will discuss continuous time as well as time discretizations and discrete
time filtering problems.
The study of the asymptotic stability properties of the limiting system and the
investigations of ILl-mean errors, central limit theorems and large deviation principles
will of course require quite specific tools. To each of these approaches and techniques
corresponds an appropriate set of conditions on the transition probability kernels
~K~, ; n > 1~ and on the so-called fitness functions ~g~, ; n > l~.
We have tried to present these conditions and to give results at a relevant level of
generality so that each section can be read independently of each other. The reader
only interested in IPS and BIPS approximating models is recommended to consult
section 1.3.2 and section 2.3 as well as section 3 for continuous time models.
The 1Lp-mean errors presented in section 2.2.2 as well as the central limit theorems
for processes exposed in section 3.3.2 are only related to the dynamics structure of the
limiting system studied in section 2.1.1. Section 2.2.4 and section 2.2.5 complement
previous results of section 2.2.2 and section 2.2.3 by providing asymptotic but precise
estimates of ILp-mean errors and exponential rates.
The specific conditions needed in each section are easy to interpret. Furthermore
they can be in surprisingly many circumstances be connected one each other. For all
these reasons we have no examples in these sections. The interplay and connections
between the employed conditions will be described in full details in section 5. We will
also connect them to classical examples arising in nonlinear filtering literature. We
hope that this choice of presentation will serve our reader well.
2 The Discrete Time Case
Structural Properties of the Limiting Process.
The investigations of law of large numbers, fluctuations and large deviation principles
require quite specific mathematical tools. We shall see in the forthcoming development that these properties are also strongly related to the dynamics structure of the
limiting measure valued process (8).
In this section we introduce some basic terminology and a few results on the dynamics
structure and the stability properties of (8). In our study a dynamical system is said
to be asymptotically stable when its long time behavior does not depends on its initial
condition.
In section 2.2 we will prove that the asymptotic stability of the limiting system
(8) is a sufficient condition for the uniform convergence of the density profiles of the
Asymptotic stability properties are also particularly important in filtering settings
mainly because the initial law of the signal is usually unknown. In this situation it is
therefore essential to check whether the optimal filter is asymptotic stable otherwise
all approximating numerical schemes will almost necessarily fails to describe the real
optimal filter with the exact initial data.
The genetic type scheme (13) is also used as a random search procedure in numerical function optimization. As for most of stochastic search algorithms, a related
question which is of primary interest is to check that their long time behavior does
not depend on its initial value.
The study of the long time behavior of the nonlinear filtering equation has been
started in . These papers are mainly concerned with the existence of
invariant probability measures for the nonlinear filtering equation and do not discuss
asymptotic stability properties. A first attempt in this direction was done in . The
authors use the above results to prove that the optimal filter "forgets" any erroneous
initial condition if the unknown initial law of the signal is absolutely continuous with
respect to this new starting point. In the so-called linear-Gaussian situation the optimal filter is also known to be exponentially asymptotically stable under some suitable
detectability and observability assumptions (see for instance ).
In the authors employ Lyapunov exponent and Hilbert projective techniques
to prove exponential asymptotic stability for finite state nonlinear filtering problems.
More recently an exponentially asymptotic stability property has been obtained in 
for real transient signals, linear observations and bounded observation noise. Here
again the proof entirely relies on using Hilbert’s projective metrics and showing that
the updating transition is a strict contraction with respect to this metric. As pointed
out by the authors in the drawback of this metric is its reliance on the assumption
of bounded observation noise and does not apply when the optimal filter solution has
not bounded support.
Another approach based on the use of Hilbert projective metric to control the logarithmic derivatives of Zakai’s kernel is described in .
In the authors extend their earlier Lyapunov exponent techniques to Polish-valued
signals. Here again the technique consists in evaluating the rate of contraction in the
projective Hilbert metric under a mixing type condition on the Markov process X.
In discrete time settings this assumption is that the transition probability kernel Kn
is homogeneous with respect to time (that is Kn = K) and it satisfies the following
condition.
There ezist a reference probability measure a E M1(E) and a positive
number E E (0,1] so that
A for any x E E and
Here we have chosen to present the novel approach introduced in and further developed in . It is based on the powerful tools developed by R.L. Dobrushin
to study central limit theorems for nonstationnary Markov chains . We believe
that this approach is more transparent than the previous ones and it also allows to
relax considerably the assumption (K)e. The continuous time version of this approach
will be given in section 3.1.3.
2.1.1 Dynamics Structure
Let us introduce some additional notations. Let {Qp,n
; 0 p n~ be the timeinhomogeneous semigroup defined by the relations
Qp,n = Qp+i ...
for any f E
0 p n and with the convention Qn,n = Id. It is transparent
from the definition of "un-normalized" distributions (qn ; n > 0~ that
Similarly, we denote by ~~p,n ; 0 p n} the composite mappings
with the convention
= Id. A clear backward induction on the parameter p shows
that the composite mappings
; 0 p n} have the same form as the one step
mappings ~~n ; n > 0}. This is the content of next lemma.
Lemma 2.1 ( ) For any 0 p nand f e Bb(E) we have that
Qp,n(f) Qp,n(1)
and gp,n = Qp,n(1)
The fitness functions {gp,n
; 0 ~ p ~ n) and the transition probability kernels
; 0 p n) satisfy the backward formulae
Kp-I,nf) ~
9p-1,n ~ 9p
° Kp(9p,n)
for any f e Bb(E), I p n and conventions gn,n = 1, Kn,n = Id.
Lemma 2.2 For any 0 p n, >, v e Mi(E) and f e Bb(E)
~ ’P,n(")(f)
~ +p,n (") (f) ) )
= 1 03BD(gp,n) [( (fp,n)
- 03BD(fp,n)) + 03A6p,n( )(f) (03BD(gp,n)
- (gp,n))]
. Kp,n(f).
Unless otherwise stated we will always assume that the fitness functions (gn ;
n > I) are continuous and satisfy the following condition.
(g) For any n > 1
, there exists an e [I, cxJ) with
V z e E, V n > 1,
Under this assumption and using the above notations we notice that
e For any z e E and 0 p n
1 ~ gp,n(x) ~ ap,n where ap,n = fl aq
e For any f e Bb( E) and 0 p n
llop,n(f)11 ~ ap,n
~f~ a-10,n
~ 03B3n(1) ~ a0,n
In order that our paper is both broad and has some coherence we have chosen
to concentrate on the analysis of the particle density profiles ~r~n ; n > 0~ and the
corresponding limiting system
Most of the results presented in section 2.1.2 and section 2.2 can be used to obtain
analog results for {yy~ ; ~ > 0~ and the flow
> 0~. The interested reader is
recommended to use the decompositions
03A6n( )f - 03A6n(03BD)f =
1 03BD(gn)([(gnKnf) - 03BD(gnKnf)]
+ (03A6n( )f)[03BD(gn) -
and to recall that
1 is the empirical measure associated with N conditionally independent random variables with common law
There also exists a different strategy to approximate the flow of distributions
n > 0~. This alternative approach is simply based on the observation that the dynamics structure of the latter is again defined by a recursion of the form (8). More
precisely, in view of ( 10) we have that
where n(~)
and for any f ~ Bb(E),
= ~(nf) ~(n),
f = Kn(gn+1f) Kn(gn+1),
Kn (gn+1).
Noticing that the new fitness functions {n ; n
~ 0} again satisfy () we see that the
study of (23) and its corresponding IPS approximating model is reduced to the former
by replacing the fitness functions {gn ; n > 1~ and the transitions {Kn ; n > 0~ by
~gn ; n > 0~ and ~Kn ; n > l~ and the initial data y/o by the distribution iio.
Nevertheless the above description shows that the formulation of the new fitness
functions involves integrations over the whole state space E. In practice these integrals are not known exactly and another level of approximation is therefore needed.
We also remark that we use the well known "rejection/acceptation" sampling method
to produce transitions of the IPS approximating scheme. But, when the constants
~an ; n > 1 } are too large it is well known that the former sampling technique is
"time-consuming" and not really efficient.
We have chosen to restrict our attention to the IPS approximating model
n > 0} for several reasons:
~ First of all it is defined as a two stage transition which can serve as a Markov
model for classical genetic algorithms arising in biology and nonlinear estimation
~ Secondly, some results such as the fluctuations on path space for the IPS (gn ;
n > 0} are not yet available.
w Another important reason is that the limiting system {"1n ; n > 0~ is exactly
the discrete time approximating model of the Kushner-Stratonovitch equation
(see for instance and references therein as well as section 4.3 page 122).
~ Finally the evolution equation of the distributions {7in ; n > 0~ is a special case
of (8) so that the results on (8) will also include those on (23).
2.1.2 Asymptotic Stability
In this section we discuss the asymptotic stability properties of (8). The main difficulty lies in the fact that (8) is a two stage process and it may have completely
different kinds of long time behavior.
For instance, if the fitness functions are constant functions then (8) is simply based
on prediction transitions. In this situation the recursion (8) describes the time evolution of the distributions of the Markov process {Xn ; n > 0~. In this very special
case the theory of Markov processes and stochastic stability can be applied.
On the other hand, if the transition probability kernels {Kn ; n ~ 1} are trivial,
that is Kn = Id, n > 1, then (8) is only based on updating transitions. In this
case its long time behavior is strongly related on its initial value. For instance, if
gn = exp(-U), for some U :
: E -~ R+, then for any bounded continuous function
f : E ~ R+ with compact support
~n (f) = ~0(f e-nU) ~0(e-nU)
~0(f 1U*) ~0(U*)
; U(x) = essinf~0U} (at least if "1o(U*) > 0).
If we write Mo(E) C M(E) the subset of measures such that ~u(E) = 0 then
any transition function T(x,dz) on E maps Mo(E) into Mo(E). We recall that its
norm is given by
03B2(T) sup ~ T~tv =
- 03BDT~tv
The quantity
is a measure of contraction of the total variation distance of probability measures induced by T. It can also be defined as
sup_~03B4xT
- 03B4yT~tv = 1 - 03B1(T)
The quantity a(T ) is called the Dobrushin ergodic coefficient of T defined by the
a(T ) = inf ~
min (T (x, Ai), T(z, Ai))
where the infimum is taken over all x, z E E and all resolutions of E into pairs of nonintersecting subsets {Ai; 1 i m} and m > 1 (see for instance ). Our analysis
is based on the following observation: In view of (20) the Markov transition probability
kernels (Kn,p
; 0 p n) are composite operators of time-inhomogeneous but linear
Markov operators. More precisely it can be checked directly from (20) that
_ KP(9P>n f)
The usefulness of Dobrushin ergodic coefficient in the study of the asymptotic stability
of the nonlinear dynamical system (8) can already been seen from the next theorem.
Theorem 2.3 Assume that the fitness functions (gn ;
n > I) is a sequence of
bounded and positive functions on E. For any n > p we have that
Q (KP,n) llwP>n(»
~ wP>n(")lltv
~ ~ M1(E),~f
, 03A8p,n()(f)
= (gp,n f) (gp,n)
~~P 11 +P>n(»
~ +P,n(") lltv * Q (KP,n) ~ fl (1
Assume that the transition probability kernels (Kn
; n > I) satisfy the following condition.
For any time n > 1, there exist a reference probability measure
An e Mi (E) and a positive number en e (0, 1] 80 that Kn(z, .) - An for any
~n ~ dKn(x,
.) d03BBn ~
Then, we have for any >, v e Mi (E)
03A3 ~2n = ~ ~
lim~03A60,n( )
- 03A60,n(03BD)~tv = 0
lim 1 03A3 ~2p =
~2 > 0 ~ lim sup 1 n log
~03A60,n( )
- 03A60,n(03BD) ~tv -~2 0
I%( £n ~*° e > 0 - ~- log sup 11 +p,p+T(»
- +p,p+T(v) lltv -e~
Proof: (Sketch) Since, for any > e Mi(E) we have +p,n(>) = Wp,n(>)Kp,n then,
using (24) and (26) one proves (28). Under (X§)i , the second part of the theorem is
a consequence of the fact that
> e), for any 0 p n. To prove these lower
bounds we use (25) and the definition of the transitions S(n)p. []
Remarks 2.4:
e Theorem 2.3 holds for any sequence of fitness functions
> 1}. One also
observe that the last assertion in the Theorem 2.3 holds true when the transition
probability kernels {~ ; ~ ~ 1} satisfy
In contrast to (see for instance Corollary 1 p. 706 in ) the exponential
asymptotic property (29) is valid for any time parameter and it does not depend
on the form neither on the regularity of the fitness functions.
e In time homogeneous settings (that is Kn = ~ gn = g) the mapping ~ =
~ is again time homogeneous. If there exists some fixed point ~ = ~(~) ~
Mi(E*). Theorem 2.3 gives several conditions underwhich is unique and any
; n > 0} of the time homogeneous dynamical system associated to
03A6 converges exponentially fast to as the time parameter n ~ ~. For instance
if (/C)i holds with 6~ = 6 > 0 then
e Let us consider the special case where 6~ =
with 61 > 0 and /~
Theorem 2.3 tells us that (8) is asymptotically stable but we don’t know if
exponential rates are available in this scale.
e If (/C)i is satisfied for some sequence of numbers
> 1} and a collection
of distributions {03BBn ; n ~ 1} then we also have that
~ x, z ~ E, ~ n ~ 1,
n ~ dn(x,.) dn
where ~ ~= efl and in ~ Mi(E) is the distribution on E given for any bounded
test function f by
f) 03BBn(gn+1)
This observation shows that Theorem 2.3 remains true if we replace the one
step mappings {~~ ; ~ > 1} and the numbers
> 1} by the mappings
{~ ; ~ > 1} and the numbers
> 1}. It is also worth to notice that this
results is again independent of the fitness functions.
e By definition of the one step mappings {~~ ;
; n > 1} we have the formula
Thus, by definition of the mappings
> 1}, if (~) is satisfied then one
can check that for any
~ Mi(E) and n > 1
are the composite mappings
o ... o $1
Therefore Theorem 2.3 can also be used to derive several conditions for the
asymptotic stability of (23).
In contrast to the previous remark the resulting error bound depends on the
sets of numbers
> 1} instead of {~ ; ~ > 1}.
This fact is important for instance if ~n ==
and supn an ~. In this
specific situation the estimate resulting from this approach will improve the one
we would obtain using the previous remark and it allows to conclude that (23)
is asymptotically stable even if ~~ 6~ oo.
Next condition relax
(/C)2 For any time p > 0 there exist some m > 1, Ap e Mi(E) and 6p > 0
such that for any r ~ E
~ dK(m)p(x,
.) d03BBp ~ 1 ~p
where K(m)p = Kp+1...Kp+m
Under (/C)2 and (~) one can check that for any 0 p +
(20142014201420142014Y ~~)e.(~)
We now turn to still another way to produce useful estimates.
By definition of the integral operators {5’p ; 0 p 7~} we also have for any
positive Borel test function f
: E 2014~ R+
1 a2p+2,p+m
K(m)p(gp+m,nf) K(m)p(gp+m,n
~ S(n)p+1... S(n)p+mf ~ a2p+2,p+m K(m)p(gp+m,nf) K(m)p
From (30) it is clear that for any 0 p + m n
t-~2014201420142014t S~~p+i.-Op+~~St20142014-20142014i
In contrast to (31) the estimate (32) does not depend anymore on the ergodic coefficients
Nevertheless the estimate induced by (31) may improve the one we would obtain
using (32). For instance, in time homogeneous settings (that is cp = c, ap = a,
Kp = K, for all p > 0) the bounds (32) lead to
(l-~(~...~))l-~exp-~
and (31) implies that
- 03B1 (S(n)p+1... S(n)p+m)) ~ 03A0 (1 - 03B1 (S(n)p+q)) ~ (1 - ~2 a2m03B1(K))m
and therefore
03B1(S(n)p+1
... S(n)p+m)) ~ exp - (m~2 a2m03B1(K))
One concludes that (34) improves (33) as soon as m.a(A’) > a~ and therefore
tog (l - ~
... ~)) -~
max (m.a(~), ~)
Theorem 2.5 Assume that () and (K)2 hold for some m > 1 and some sequence of
numbers {~p ; p > 0}. For any ,03BD ~ M1(E) and n
~ m we have
~03A60,n( ) - 03A60,n(03BD)~tv
~ 03A0 (1 - ~2p a2p+1,p+m03B1(Kp))/
~03A60,n( ) - 03A60,n(03BD)~tv ~
(1 - ~2pm a2pm+2,pm+m)/
/n addition, if infn ~n =
c > 0, infn 03B1(Kn) = o; > 0
a oo then for
1 a~ T > M.m
_ log sup ~p,p+T(~) -
-20142014 
where 1/M +
Next we present an easily verifiable sufficient condition for (/C)2. It also gives some
connections between (/C)i and (~0)2. It will be used in section 5 to check that some
classes of Gaussian transitions satisfy (~0)2 for m = 2. To clarify the presentation the
transition probability kernels ~
here are assumed to be time homogeneous (that is
Kn = K for all n > 0).
There exist a subset A ~ B(E), a reference probability measure
A e Mi(E) and a positive number e ~ (0,1)
that 03BB(A)
~ x ~ E, ~ z ~ a, ~
~ dK(x,.) d03BB(z) ~
In addition there exist a decomposition Ac = B1 U ... U Bm, m ~ 1 and 2m
reference probability measures 03BB1,...,03BBm,03B31,...,03B3m ~ M1(E) such that for
~ x ~ Bk, ~ z ~ E, ~
~ dK(x,.) d03BBk(z) ~ 1 ~
Under (g) and (/C)s one concludes that (/C)2 holds for m = 2 (the last condition
above is even useless for that).
Furthermore under (/C)s one can also prove the following bounds
and 03B1 (S(n)p) ~ ~4 2
Corollary 2.6 Assume that (g) and (/C)s hold. Then) for any
~ Mi(E) we have
03A3 a-2n = ~
~ lim~03A60,n( ) - 03A60,n(03BD)~tv = 0
03A3 a-2p =
a-2 ~ lim sup 1 n log ~03A60,n( ) - 03A60,n(03BD) ~tv ~ - ~4 a2
sup an = a ~ ~ T log
sup~03A6p,p+T( ) - 03A6p,p+T(03BD)~tv
A more interesting and stronger result for transition probability kernels (Kn ;
n > 1} which do not satisfy (~0)2 is given next. We will use the following condition.
There ezists some p0 ~ 0 such that
gp,n(x) gp,n(y) > 0
Let us observe that under
one has a uniform control of the fitness functions
; 0 p n) in the sense that for any n > p > po and z, y ~ ~
03B4p ~ gp,n(x) gp,n(y) ~ 1 03B4p
In contrast to previous conditions
depends on both the fitness functions {gn
n > 1} and on the transition probability kernels
> 1}. Note that
clearly satisfied when the fitness functions are constant or more generally if the fitness
functions become constant after a given step po (that is gp = 1 for any p > po). In
the same vein
is satisfied if we are allowed to choose the constants
~. In this situation we would have
Another way of viewing condition
oo is to say that the sequence of
> 1} satisfy
03A3sup|log gn(x)| ~
which clearly implies that gn tends to the unit function I as n tends to infinity.
It is also noteworthy that if (X§g) holds for po = 0 then condition (g) is directly
satisfied. More precisely in this situation we would get the bounds
~ x, y ~ E, ~ p ~ 0,
03B4p ~ gp+1(x) gp+1(y) ~ 1 03B4p
To see that (X§g) also relax (K)2 it suffices to note that (K)2 implies that for any
0 ~ p + m ~ n
gp,n(x) gp,n(y)
~ a-2p+1,p+m Kp+1... Kp+m (gp+m,n) (x) Kp+1...Kp+m(gp+m,n)(y)
~ ~2p a-2p+1,p+m > 0
Since for any p ~ n ~ p + m and x, y ~ E
we finally have the lower bounds
Under (X§g) and using (27) and the decomposition
~~~~ "(9P,n)
J-t 9P,n ) ~~ - BIt ~ ~~~~~
(03BD)(f) = 03BD(gp,n) (gp,n) [gp,n 03BD(gp,n) (f - 03A8
03BD)(f))]
we also have that
~n ~ p ~ p0,
~03A8p,n() -
03A8p,n(03BD)~tv ~ 2 03B42 ~
U sing the same lines of reasoning as before one can prove that for any Borel test
function f : E - R+ and m > I and n > p + m
~ 03B4p+1... 03B4p+(m-1)
K(m)p(gp+m,nf) K
(m)p (gp+m,n)
~ 03B4p+1... 03B4p+m K(m)p
from which one deduces the following deeper result.
Theorem 2.7 If (X§g) is satisfied for some parameter po > 0 then we have for any
n ~ p ~ p0
~03A6p,n( ) - 03A6p,n(03BD)~tv ~ 2 03B42
03B2 (Kp,n) ~
and for any m > I
sup~03A60,n( ) -
03A60,n(03BD)~tv ~
(1 - 03B4(m)p0+q.m
03B1 (K)(m)p0+q.m))
where [a] denotes the integer part of a ~ R, 03B4(m)p
03B4p+1...03B4p+m
In addition if po = 0 and inf p bp
> 0 then for m =1 (36) leads to
- - S ~ n a
Remarks 2.8:
~ The bound (36) is sharp in the sense that if the fitness functions gn are constant
then one may choose m = n, po = 0. In this situation (36) reads
... Kn - 03BDK1
... Kn~tv ~ 1-
03B1 (K1... Kn) = 03B2 (K1... Kn)
= sup ~03B4xK1
03B4yK1...Kn~tv
2022 In view of (37) and under (KG), condition
a (Kn) = oo is a sufficient
condition for the asymptotic stability of the nonlinear semigroup
~~p,~~a~pn~
This condition is a familiar necessary and sufficient condition for the temporally
inhomogeneous semigroup associated with the transitions ~ Kn ;
; n > 1 } to be
strongly ergodic (see for instance , part I, p. 76).
w In nonlinear filtering settings condition ~,~ log an oo is related to the form
of the observation noise source. An example of observation process satisfying
this condition will be given in the end of section 5. Roughly speaking the
assumptions (J~);, i = 1, 2, 3 say that the signal process is sufficiently mixing
and condition ~~ log an oo says that the observation process is sufficiently
2.2 Asymptotic Behavior of the Particle Systems
Introduction
In this section we investigate the asymptotic behavior of the IPS as the number of particles tends to infinity. In the first subsection 2.2.2 we discuss 1Lp-mean error bounds
and a uniform convergence theorem with respect to the time parameter. A Glivenko-
Cantelli Theorem is described in section 2.2.3. Subsection 2.2.4 is concerned with
fluctuations of IPS. In the last subsection 2.2.5 we present large deviation principles.
All of the above properties will of course be stated under appropriate regularity
conditions on the transition probability kernels {Kn ; n > 1~ and on the fitness functions {gn ; n > l~.
Assumption (9) is the only assumption needed on the fitness functions.
Unless otherwise stated we will always assume that (9) holds.
This condition has a clear interpretation in nonlinear filtering settings (see for
instance and section 5). It can be regarded as a technical assumption
and several results presented here can be proved without this condition. To illustrate
this remark we will give in the beginning of section 2.2.2 a very basic convergence
result that does not depend on (~). To guide the reader we now give some comments
on the assumptions needed on the transition probability kernels
The uniform convergence result presented in section 2.2.2 is based on the asymptotic stability properties of the limiting measure valued process (8) we have studied
in section 2.1.2. This part will then be related to assumptions (J~)l,(J~)2 and (K)3.
The Glivenko-Cantelli and Donsker Theorems presented in section 2.2.3 and section 2.2.4 extend the corresponding statements in the classical theory of empirical
processes. They are simply based on (~). The idea here is to consider a given random
measure J-LN as a stochastic process indexed by a collection ,~’ of measurable functions
: E - R. If J-LN is an empirical measure then, the resulting 0-indexed collection
f ); f E ,~~ is usually called the ,~’-empirical process associated with the empirical random measures
The semi-metric commonly used in such a context is the
Zolotarev semi-norm defined by
(see for instance ). In order to control the behavior of the supremum .
The Glivenko-Cantelli and Donsker Theorems are uniform versions of the law of
large numbers and the central limit theorem for empirical measures. In the classical
theory of independent random variables, these properties are usually shown to hold
under entropy conditions on the class 0. Namely, to measure the size of a given class
.~, one considers the covering numbers
defined as the minimal number
of Lp(J-L )-balls of radius 6 > 0 needed to cover 0. With respect to classical theory,
we will need assumptions on these covering numbers uniformly over all probability
measures fl. Classically also, this supremum can be taken over all discrete probability
measures. Since we are dealing with interacting particle schemes, we however need to
strengthen the assumption and take the corresponding supremum over all probability
measures. Several examples of classes of functions satisfying the foregoing uniform
entropy conditions are discussed in the book .
Denote thus by ,lV(~, ,~), ~ > 0, and by I(,~’) the uniform covering numbers and
entropy integral given by
L2(I~))s ~ E
= 10logN(~,F)d~.
which will be assumed to be finite.
The fluctuations and the large deviations principles for the particle density profiles
~~n ; n > 0} will be simply based on (?). In fact this assumption on the fitness functions will be used to check the asymptotic tightness property in Donsker’s Theorem
and an exponential tightness property in large deviation settings.
The study of fluctuations and large deviations on path space require more attention. It becomes more transparent if we introduce a more general abstract formulation.
Namely, we will assume that (gn ; n > 0~ is the IPS approximating model (13) associated with a given sequence of continuous functions ~~n ; n > l~. We will use the
following assumption.
(P)o For any time n > 1 there exists a reference probability measure
Àn E M1 (E) such that
This condition might seems difficult to check in general. In fact if the functions
~~~, ; n > l~ are given by (8) then (P)o holds if and only if the transition probability
kernels ~K~, ; n > 1~ satisfy the following condition.
(JC)o For any time n > 1 there exists a reference probability measure
An E M1(E) so that
We shall see in section 5 that this condition covers many typical examples of
nonlinear filtering problems (see also ).
The main reason for our needing to make the assumption (P)o for the analysis of
the fluctuations on path space is that we want to use a reference product probability
measure. We also notice that there is no loss of generality in choosing An =
particular choice of reference probability measure will be used for technical reasons in
the study of the fluctuations on path space. Roughly speaking this is the appropriate
and natural choice for studying the weak convergence of the resulting Hamiltonian
function under the underlying product measure (see for instance Lemma 2.24 and its
proof given on page 52).
The main simplification due to assumption (P)o is the following continuity property.
For any TEN, we denote
the law of
on the path space
~T def. ~T x ... x ~T
def. B(~T) ® ... ® B ~T
and ~T def.
Then PTNI is absolutely continuous with respect to the product
measure flJN where
~[0,T] = ~0 ~ ... ~ ~T
Next we denote by
the marginal at the time n E ~0, ... , T ~ of a measure ~ E
M1(ET) and with some obvious abusive notations by m(x) the empirical measure on
path space associated with a configuration x E
(xo,...,~T) E
Under (P)o, it is easily seen that
dP(N)T d~~N[0,T](x) = exp H(N)T(x) ~~N[0,T] - a.e.
where H(N)
: 03A3NT ~ R is the function defined by
H(N)T(x) = N 03A3 logd03A6n(mn-1(x)) d~n
In addition, if we consider the function 03A6[0,T] : M1(03A3T) ~
M1(03A3T) so that
~[O,T](~) _ ??o 0 ~1(~0) 0
then we see that H(N)T
can also be rewritten in the following form
H(N)T(x) =
logd03A6[0,T](m(x)) d~[0,T]
Therefore, the density of
only depends on the empirical measure m and we find
ourselves exactly in the setting of mean field interacting particles with regular Laplace
density. The study of the fluctuations for mean field interacting particle systems via
precise Laplace method is now extensively developed (see for instance , , ,
 and references therein).
Various methods are based on the fact that the law of mean field interacting processes can be viewed as a mean field Gibbs measure on path space (see (38)). In such
a setting, precise Laplace’s method can be developed (see for instance , , ).
In , the study of the fluctuations for mean field Gibbs measures was extended to
analytic potentials which probably includes our setting.
However the analysis of the fluctuations on the path space presented in section 2.2.4
is more related to Shiga/Tanaka’s paper . In this article, the authors restrict
themselves to dynamics with independent initial data so that the partition function
of the corresponding Gibbs measure is equal to one. This simplifies considerably the
analysis. In fact, the proof then mainly relies on a simple formula on multiple Wiener
integrals and Dynkin-Mandelbaum Theorem on symmetric statistics. Also the
pure jump McKean-Vlasov process studied in is rather close to our model.
Using the above notations and, under (P)o, if we denote by QV’) the law of the
empirical measures
~N[0,T] = m (03BE[0,T]) = 1 N 03A303B4(03BEi0,...,03BEiT) ~ M1(03A3T),
is absolutely continuous with respect to the distribution
RZ, ~F = ( F(m(x))
for any F E Cb(M1 (T)), with the convention Ao = yyo. We notice that the latter
formula can be written in the form
F(m(x))R~NT(dx)
with RT = 03BB0 ~
... ~ 03BBT
Arguing as before, it is also easily seen that
dQ(N)T dR(N)T = exp(N FT) R(N)T
where F T :
the function defined by
The above formulation will be used in section 2.2.5 to obtain large deviation principles
for the law of the empirical measures on path space.
It is worth observing immediately that
is the law of an empirical measure
associated with N independent path-valued random variables. This observation, together with the above formulation clearly shows that Varadhan’s Lemma combined
with Sanov’s Theorem and cut-off techniques are natural tools for deriving the desired
large deviation principle (see , or and references therein).
We have no examples in this section 2.2. This choice is deliberate. We will give in
section 5 a glossary of assumptions and detailed examples for each specific condition.
Lp-mean errors
As announced in the introduction we start with a very basic but reassuring convergence result which holds without assumption (9) on the fitness functions.
Proposition 2.9 For any time n > 0 and p > I, there exists some finite constant
C(p)n ~ such that
In particular, for any f E Bb(E) and n > 0,
f ; N > 1~ converges almost surely
as N tends to oo.
Proof: The proof of (41) is simply based on Marcinkiewicz-Zygmund’s inequality
(cf. p. 498). More precisely, by definition of the N-particle system (13), for any
n > 0 and f E Bb(E) we have that
where Bp is a finite constant which only depends on the parameter p > 1 and where
we have used the convention
= rto. We end up with (41~ by induction on the
time parameter. Since the result clearly holds for n = 0, we next assume that it holds
at rank (n - 1) for some constant
Using Lemma 2.2 and the induction hypothesis at rank (n - 1) on can check that
|~Nnf - 03A6
Nn-1)f|p)1 p +
1 N2~gn~~f~ ~n-1(gn) C
Consequently, in view of (42) the result holds at rank n with
C(p) = D .
The last assertion is a clear consequence of Borel-Cantelli Lemma. N
One important drawback of the above inductive proof is that it does not present
any information about the "exact values" of the LP-mean errors. For instance,
roughly of the form Bp(n + 1)nl=1
(2~gl~ ~l-1(gl)) and therefore tends to 0o as n ~ ~. In
order to get an idea of the exact values of these bounds some numerical simulations
have been done in . Precise asymptotic estimates will also be given in section 3.3.2.
When (g) holds then (41) can be proved without using an induction. This approach is based on a natural decomposition of the errors. Since this decomposition
will also be used to prove a uniform convergence result with respect to time, Glivenko-
Cantelli and Donsker’s Theorem and elsewhere we have chosen to present this alternative proof. The decomposition we will use now is the following:
V f E Bb(E) ,
f - qn f = ~
with the convention
= rto. Using Lemma 2.2 we see that each term
(~p(~p-1~) f I ~
is bounded by
a2p,n [|~Np(fp,n)
- 03A6p (~Np-1) (fp,n)| + ~f~ |~Np(gp,n)
- 03A6p (~Np-1) (gp,n)|]
gp,n Kp,n(f)
SO that )) fp,n)) )) f)) and
I. Using Marcinkiewicz-Zygmund’s inequality it
is then easy to conclude that, for any p > i , n > 0 and f e Bb( E)
1 p ~ Bp N ~f~ 03A3 a2q,n
where Bp is a finite universal constant. Here again, a clear deficiency in the preceding
result is the degeneracy of the constants when the time parameter is growing, that is
03A3nq=0 a2q,n
tends to cxJ as n - ~. To connect this problem with the stability properties
discussed in section 2.1 .2 we note that each term (44) can be rewritten as follows
|~Np ( Ng,n Np,n(f)) /~Np ( Np,n ) |
with Np,n =
gp,n 03A6p(~Np-1)(gp,n
= h’p,n (f
- +p,n (+pq§t i» f» z>
Since +p(q£ 1) (
Q(Kp,n) ]] f]] we use the same
line of arguments as before to prove that
E (|~Nnf - ~nf|p)1 p ~
|gq,n(x) gq,n(y) |2 03B2(Kq,n)
Next we would like to extend these results in two different ways. First we would
like to be able to turn this result into a statement uniform in f varying in a suitable
class of functions J’ c Bb( E). Second we would like to obtain a uniform Lp-error
bound with respect to the time parameter without any assumptions on the mutation
transition kernels Kn but only on the stability properties of the limiting system (8).
We will also use the following extension of Marcinkiewicz-Zygmund’s inequality to
empirical processes 
Lemma 2. 10 Let (X1,...,XN)
be independent E
- valued random variables with
common law
and let J’ be a countable sequence of functions f : E - R such that
. Then, for any p > I there exists a universal constant Bp such that
- p(N)IIj. Y’
Theorem 2.11 Let 0 be a countable collection of functions f such that ]] f]]
and satisfying the entropy condition 1(0) ~. Assume moreover that the limiting
dynamical system (8) is asymptotically stable in the sense that
lim sup sup~03A6p,p+T() - 03A6p,p+T(03BD)~F
When the fitness functions (gn ; n > i) satisfy (g) with supn~1
a cxJ then we
have the following uniform convergence result with respect to time
lim supE ( ))qj/ - qn )),)
In addition, let us assume that the limiting dynamical system (8) is exponentially
asymptotically stable in the sense that there exist some positive constant 03B3 > 0 and
To > 0 such that,
v >, " G Ml (E), v T ~ TO,
Then we have for any p > I, the uniform Lp-error bound given by
sup E (~~Nn - ~n~pF)1 p
~ Cpe03B3’ N03B1 2
for any N ~ 1 so that
T(N) =~~~ ) ~
2 ’f + ’f’ + - 0
where Cp is a universal constant which only depends on p > I and a and q’ are given
03B3 03B3 + 03B3’
03B3’ = 1 + 2 log a.
Proof: We use again the decomposition (43) . There is no loss of generality to assume
that I e J’. Then, by the same line of arguments as before and using the extended
version of Marcinkiewicz-Zygmund’s inequality one can prove that for any 0 q n
(~03A6q,n(~Nq)
- 03A6q,n (03A6q (~Nq-1)) iiJ i oi )1 p ~ #
where Bp is a universal constant and
0q,n ~* #q,n Kq,n(o) ~*’ l#q,n Kq>n (f)
Now, using the fact that I(J’q,n) 1(J’) (cf. Lemma 2.3, p. 9, ) and aq,n a0,n
an one concludes that
E ( 11 .q,n o§’> - +q,n (+qo§’ 1 » l12) ’ j 1°>
and therefore for any T > To
sup E(~-~!~
-~ (r+1)~ /(~)
~~~~~~ ~ ~
~~ ~ ~~ ~~~ ~~’~
Similarly, for any q > 0 and T > To we have
~ !!~+T(~)-~+T(~(~J)!~+!~~T(~)-~+T(77~
Under our assumptions, this implies that
!!~-~r!~ ~ ~~r(~)-~+T(~(~))!!~+e-~
Thus, using the same line of arguments as before, one gets for any T > To
sup E(~~Nq+T - ~q+T~pF)1 p ~ e-03B3T + Bp N (T + 1) a2T I(F)
Combining (52) and (53) leads to a uniform Lp-error bounds with respect to time in
the form of the inequality
~ T ~ T0, sup E(~~Nn - ~n~pF)1 p ~ e-03B3T + B’p N e03B3’T I(F)
where == 1 + 2 log a and B’p > 0 is a universal constant. Obviously, if we choose
~V > 1 and
where [r] denotes the integer part of r G R, we get that
sup E(~~Nn - ~n~pF)1 p ~ 1 N03B1/2(1 + e03B3’B’pI(F))
where o; = 03B3/(03B3 + 03B3’). This ends the proof of the theorem.
Remarks 2.12:
w The critical exponent resulting from the proof of Theorem 2.11 is sharp in the
following sense: if the transition probability kernels
> 1} are given by
then we see that = (~,....
is a sequence of independent random variables
with common law
In this situation the uniform upper bound (50) holds for
any choice of 03B3 ~ R+. Letting 03B3 ~ oo the critical exponent tends to 1/2 which
is the characteristic exponent of the weak law of large numbers.
w Several conditions for exponential asymptotic stability of the limiting measure
system (8) are given in section 2.1.2. The exponential stability condition (49)
can be easily related to the conditions (K)i, i = 1,2,3 discussed in section 2.1.2.
w The proof of Theorem 2.11 can be used to treat polynomial asymptotically
stable limiting dynamical systems (8). The resulting uniform Lp-error bound
has roughly the form (log N)-!3 for some p > 0.
~ The above result can also be used to obtain reliability intervals which are valid
uniformly with respect to the time parameter (cf. ).
w In nonlinear filtering settings, the fitness functions and therefore the sequence
~aq,n 0 q n~ depend on the observation process. The above result can
be used to give quenched and/or averaged uniform ILp-mean error bounds with
respect to time (cf. section 4.4 and ).
Glivenko-Cantelli Theorem
Let ,~’ be a countable collection of functions f such that
1. Upon carefully
examining the proof of Theorem 2.11, we have already proved that for any p > 1 and
for any time n ~ 0
- ~n ~pF)1 p ~ Bp N
(n + 1 ) a2o,n I(F)
Then, as an immediate consequence of Borel-Cantelli Lemma we have that
I(F) ~ ~ lim ~~Nn - ~n~F = 0
Our aim is now to show that this almost sure convergence remains true if we replace
the entropy condition
oo by a boundness condition of the covering numbers,
namely N(~,
F) ~, for any ~ > 0.
As usually we make use of the decomposition (43). There is no loss of generality
in assuming that 1 E ,~’. Then, by Lemma 2.2, we get for any 0 q n
where the class J’q,n is the class of functions defined in (51). It easily follows that, for
every 6 > 0,
P (~~~~ - ~n~~.~ > ~)
C (?2 + 1) sup P
Using (54), this implies that
P (Il~n - ~~II.~ > ~~ ~ (n + 1)
where an = 2(n +
The Glivenko-Cantelli Theorem may then be stated as follows.
Theorem 2.13 Assume that F is a countable collection of functions f such that
1 and ~,~) oo for any 6 > 0. Then, for any time n > 0,
converges almost surely to 0 as N
Theorem 2.13 is based on the following standard lemma in the theory of empirical
processes (see for instance or ).
Lemma 2.14 Let
1 z N) be independent random variables with common
and let F be a countable collection of functions f such that
for any ~ > 0 and
> 4~-1 we have that
(~1 N 03A303B4Xi - P(N)~F
Proof of Theorem 2.13: Let us fixed n throughout the argument. Using (55) and
Lemma 2.14 one easily gets that, for B/7V > 4 6~~ where ~ =
~(!!~-~!~>~) s~+i)
for each c > 0, and 0 ~ ~ (cf. Lemma 2.3, p. 9, )
one concludes that
> c) 8(n +
as soon as
> 4 6~~. The end of proof of Theorem 2.13 is an immediate consequence of the Borel-Cantelli Lemma..
The proof of Theorem 2.13 gives an exponential rate of convergence but this result
is only valid for a number of particles larger than some value depending on the time
parameter. Our aim is now to refine this exponential bound in the case of uniformly
bounded classes ~" with polynomial covering numbers. More precisely we will use the
following assumption
(Poly.) There exist some constants C and V such that
~(6,~) (-)
Several examples of classes of functions satisfying this condition are discussed
in . For instance Vapnik-Cervonenkis classes ~ of index
and envelope function F = 1 satisfy (Poly.) with V = 2(V(JF) -1) and a constant C that only depends
Theorem 2.15 Let ~" be a countable class of measurable functions f
: E 2014~ 
satisfying (Poly.) for some constants C and V. Then, for any n > 0, 03B4 > 0 and
P(N~~Nn - ~n~F > 03B403C3n) ~ (n + 1)(D 03C3 V)ve-203B42
where D is a constant that only depends on C and 03C3n = 2(n +1)
Proof: We use again the decomposition (43). Using the same notations as in the
proof of Theorem 2.13 and Theorem 2.11, we have
~ (!!~..«) -
where ~n = ~/03C3n and an = 2(n + 1)a20,n. It is also convenient to note that each class
0 ~ q n, satisfies (Poly.). Indeed, the class
is again a countable class of
functions / : E -~ and using Lemma 2.3 in we also have, for every e > 0
and 0 ~ q ~ n
N(~,Fq,n) ~ N(~,F) ~ (C ~)v.
We are now in position to apply the exponential bounds of (see also ). More
precisely, by recalling that ~
is the empirical measure associated with N conditionally
independent random variables with common law ~g(~i), we get
F(!K-~«.)!k. -. !.) ~
where D is a constant that only depends on C. The remainder of the proof is exactly
as in the proof of Theorem 2.13. Using (56), one gets finally
If we denote 6 = N~/03C3n we obtain the desired inequality and the theorem is thus
established. ’
Central Limit Theorems
The study of the fluctuations for the IPS scheme (13) is decomposed into three parts.
e In the first one we present central limit theorems (CLT) for a class of processes
arising naturally in the study of the convergence of the particle scheme.
e The second part concerns a Donsker’s Theorem for the particle density profiles.
The identification of the covariance function is based on the convergence results
presented in the first part.
e The last part of this section presents a technique for obtaining fluctuations for
the empirical distributions on path space.
CLT for Processes
One of the best approaches for obtaining fluctuations of the particle density profiles
is through a study of the convergence of some suitably chosen processes. To describe
these processes, it is convenient to introduce some additional notations. For any
valued function f = (f1,...,fd),fi ~
Bb(E), 1 z d, and for any integral operator
K on E and G Mi(E) we will slightly abuse notations and we write
> 0} be the natural filtration associated with the N-particle
system {~ ~ ; ~ ~ 0}. The first class of processes which arises naturally in our
context are the Revalued and FN-martingale {M(N)n(f) ; n ~ 0} defined by
with the usual convention ~0(~1) = ~o and where f : (p,.r) C N x E ~
is a bounded measurable function. Using the above notations, the j-th, 1 ~ d,
component of the martingale {M(N)n(f) ; n > 0} is the FN-martingale defined by
Most of the results presented here are based on the following CLT for the martingale
Lemma 2.16
For any bounded measurable function f
: (p,.r) ~ N x E e
IR d and d > 1,
and FN-martingale (Jk M(N)n(f) ; n > 0} converges in
Rd-valued and Gaussian martingale
> 0} such that for any 1 I, j ~ d
= E~((~-~))(~-~)))
Proof: The proof is based on ideas of J. Jacod (see for another presentation in
more general settings). To use the CLT for triangular arrays of Revalued random
variables (Theorem 3.33, p. 437 in ) we first rewrite the martingale Jk
in the following form
N M(N)n(f)
=03A303A31 N (fp)(03BEip) - 03A6p (~Np-1) (fp))
If we denote by [a] the integer part of a ~ R and {a} = a - [a] this yields
where for any 1 ~ (n + I)N,
~(/)=~(/~)-~(~i)(/p))
so that k = pN +i. Our aim is now to describe the limiting behavior of the martingale
in terms of the process
To this end, we denote Ff the a-algebra generated by the random variables for
any pair-index ( j, p) such that pN + j k. By definition of the IPS transitions (13)
and using the fact that [ N J
= [t] one gets that for any i, j d
= CN[t](fi,fj) +
[Nt]-N[t] N (CN[t]+1 (fi,fj
) - CN[t](fi,fj))
where, for any n ~ 0 and 1 ~ i, j ~ d
- ~ ~p(~p-1~ ( ( fp -
This implies that for any 1 i, j d
~p ( ( f p -
Ct(fi,fj) = C[t](fi,fj)
+ {t} (CM+i (/B fj) - C[t] (/B f))
Since II Uk ( f ) II
[N~ ~) for any 1 k ~Nt~ + N, the conditional Linderberg
condition is clearly satisfied and therefore one concludes that the Revalued martingale
~XN( f ) ; t E
converges in law to a continuous Gaussian martingale
such that, for any 1 i, j d
(X ( f? ) , X ( f3 ) )t
Recalling that
Nf~ ~ ~ ( f ) the proof of the lemma is completed.
A first consequence of Lemma 2.16 is another CLT for a martingale process related
to the "un-normalized" approximating measures ~~yn ; n > 0} defined in (17).
Proposition 2.17 For any T > 0 and f = ( f r, ... ,fd) E Bb(E)d, the Rd-valued
is an FN-martingale such that, for any 1 i, j d and 0 n T
- 1 n ~p (1))2
Moreover, the FN-martingale
; 0 n T) converges in law to an Rdvalued and Gaussian martingale {0393n(f) ; 0 ~ n ~ T} such that for any 1 i, j d
~p ( p,T f -
~J L "G p,T f -
Proof: For any p = (cpl, ... , cpd) E Bb( E)d we have the decomposition
with the usual convention
By definition of
n > 0} this
can also be written in the following form
~’n ~) - ~
Therefore one gets (58) by choosing p = Qn,T f and (59) is a clear consequence of
the above decomposition. We turn now to the proof of the convergence of the FNmartingale
; 0 n T}. If we put for any 0 n T
and if we denote
for any a E
then, under our assumptions,
for some finite constant CT( f) )
oo which does not depend on the parameter N.
Lemma 2.16 clearly implies that the FN-martingale {N0393Nn (f) ; 0 n T}
converges in law to the desired Gaussian martingale
(60) clearly ends the proof of the proposition.
Corollary 2.18
For any time T > 0, the sequence of random fields {W03B3,NT(
converges in law as N -~ oo, in the sense of convergence of ftnite dimensional distributions, to a centered Gaussian field ~W~,( f )
satisfying for any
E (W03B3T(f)W03B3T(h)) = 03A3 (03B3p(1))2 ~p ([Qp,Tf
- ~pQp,Tf][Qp,Th
- ~pQp,Th] )
The analysis of the fluctuations for the particle density profiles
; n > 0~ is
more delicate mainly because the limiting measure valued process (8) is not linear. In
fact many ideas work equally well when we replace the semigroup
by the "normalized" one {Q p,n ; 0 p n~ given by
n V f E B (E)
b’ 0 p n, b’ f E ,~b(E),
To see that
; 0 p n~ is indeed a semigroup we first note that for any
f = Qp,mQm,nf ~p(Qp,n1) = ~m(Qm,n1) ~p(Qp,n1)
17m (Q m n _
one concludes that for any 0 p m n
Qp,nf = ~P(Qp,m
1)Qp,mQm,nf = Qp,mQm,nf
For any 0~n~T and
f = (f1,...,fd) ~ Bb(E)d we write
Using this notation, the analog of Proposition 2.17 for the particle density profiles
; n > 0~ is the following result.
Proposition 2.19 For any T > 0 and f = ( f 1, ... fd) E
the Rd-valued
process ~W~ ( f~,,T)
; 0 n T ~ given by
converges in law to an Rd-valued Gaussian martingale
; 0 n T} such
that for any 1 i, j d and 0 n T
1 W ( f . ,T )
~p ( f p,T f p,T l
Proof: For any p _ (c~l, ... , pd) E Bb( E)d we have the decomposition
If we choose p _ ( f - r~T f with f =
... , fd) E Bb( E)d this yields
with the usual convention
= qo. Since for any 0 p T
op (fp,T) -
then (63) can also be written in the following form
B(1V) f . ,T )
Using Proposition 2.9 and Lemma 2.2 one gets after some tedious but easy calculations
sup ~B(N)n(f,x)~ ~
for some finite constant CT oo which only depends on the parameter T (we recall
for any f = ( f 1, ... , f d)). Using the same arguments as in
the proof of Proposition 2.17 we ends the proof of Proposition 2.19. More precisely,
Lemma 2.1fi implies that the FN-martingale
; ~ ~ ?2 T
converges in law to the desired Gaussian martingale ~Wn( f ,,T) ; 0 n T~ and
(65) completes the proof of the proposition.
Corollary 2.20
For any time T > 0, the sequence of random fields ~WT ( f )
; f E Bb(E)} where
converges in law as N ~ ~, in the sense of convergence of finite dimensional distributions, to a centered Gaussian field ~WT( f ) ; f E
satisfying for any
f h E Bb(E)
~ (WT(f)WT(h)) _ ~
Donsker Theorem
Before getting into the details it is useful to make a couple of remarks. In the first place
we note that the covariance functions can be formulated using the fitness functions
; 0 p T) and the transitions {hp,T
; 0 p T) defined in Lemma 2.2.
More precisely, since
Qp,T (f - ~Tf) = Qp,T(1) (Qp,T(f) Qp,T(1) - ~Tf)
(Kp,Tf - ~Tf)
for any f E Bb( E) , we have that
If the transition probability kernels ~l~n; n > l~ are trivial, in the sense that,
h’p(x, dz)
then one can readily check that y/p = J-Lp for any 0 p T and
In this particular situation {WT(f); f E
is the classical T-Brownian bridge.
Namely, WT is the centered Gaussian process with covariance
E(WT(f)WT(h)) -
The second remark is that the random fields
( f ); f E
can also be
regarded as an empirical process indexed by the collection of bounded measurable
functions. In this interpretation, Corollary 2.20 simply says that the marginals of
the Bb(E)-indexed empirical process weakly converge to the marginals of a centered Gaussian process ~WT( f ); f E
One natural question we may ask
is whether there exists a functional convergence result for an F-indexed empirical
f E ,~’} where ,~’ c Bb(E) .
We recall that weak convergence in
can be characterized as the convergence
of the marginals together with the asymptotic tightness of the process
; .f E .~~
As announced in section 2.2.1 the asymptotic tightness is related to the entropy condition
oo. The following technical lemma is proved in .
Lemma 2.21 If ,~’ is a countable collection of functions f such that
oo then, for any T > 0, the ,~’-indexed process
f E 0) is asymptotically tight.
Theorem 2.22 (Donsker Theorem) Assume that 0 is a countable class of functions such that ]] f]]
I for any f e J’ and 1(0) ~. Then, for any T > 0,
(WjY( f); f e J’) converges weakly in 1"(0) as N - cxJ to a centered Gaussian
process (WT( f); f e J’) with covariance function
E(wT(f)wT(h)) ~ § / (~ (§~ ~ ) ~ (KP>T(f)
~ oT(f))(KP>T(h)
~ oT(h))doP°
Fluctuations on Path Space
In this section we will use notations of section 2.2.I, p. 33 and the following
strengthening of (X§)o
(TC£) For any time n > I there ezist a reference probability measure
An e Mi(E) and a B(E)-measurable function 03C6n so that Kn(x,.) - 03BBn and
|logdKn(x,
.) d03BBn (z)
/ ~ wn (Z)
/ exp (P wn) dAn °°
As we already noticed the distribution
induced by gjo,Tj on path space
is absolutely continuous with respect to the product measure qg)j and
T d~~N[0,T](x) = exp H(N)T(x), ~~N[0,T] - a.e.,
where H(N) : 03A3NT ~ R is the symmetric function given by
~*~~(~~’) ~ ’~ ~ / log
To clarify the presentation, we simplify the notations suppressing the
time parameter T in our notations so that we write q, P(~), W~, H(~), £
and £N instead of
~[0,T], P(N)[0,T], WN[0,T], H(N)T,
03A3T and £lf.
In what follows we use E~~N ( . ) (resp. EpN> ( . ) ) to denote expectations with respect
to the measure q©’° (resp. Pl’°)) on £’° and, unless otherwise stated, the sequence
(z? ; I > i ) is regarded as a sequence of 03A3-valued and independent random variables
with common law q.
To get the fluctuations of the empirical measures on path space it is enough to
study the limit of
(EpN> (exp (iWN(03C6)))
where WN =
for functions p E L2(r~). Writing
Ep(N) (exp
+ H{ 1 (x)))~
one finds that the convergence of
(exp(iWN(c.p))) ;
follows from the convergence in law and the uniform integrability of
exp( iWN (c.p) +
under the product law
The last point is clearly equivalent to the uniform
integrability of exp
The proof of the uniform integrability of
then relies on a classical result (see for instance Theorem 5 p. 189 in 
or Scheffe’s Lemma 5.10 p.55 in ) which says that, if a sequence of non-negative
random variables {XN
; N > 1} converges almost surely towards some random
variable X as
oo then we have
lim E(XN) = E(X) ~ ~
{XN ; N ~ 1} is uniformly integrable
The equivalence still holds if XN only converges in distribution by Skorohod’s Theorem
(see for instance Theorem 1 p. 355 in ). Since
=1 it is clear
that the uniform integrability of
follows from the convergence in distribution of
towards a random variable H
such that E(exp H) = 1. Thus, it suffices to study the convergence in distribution of
functions cp to conclude.
To state such a result we first need to introduce some notations. Under the assumption
for any n > 1 there exists a reference probability measure An E M1(E)
such that Kn(x, .) - An . In this case we shall use the notation
dKn(x,.) d03BBn(z)
For any x = (x0, ...,xT) and z = (z0, ...,zT) ~ 03A3 set
qn(x, z) _
E gn(u)kn(u,xn)~n-1(du)
03A3 q(x’, z) ~(dx’)
One consequence of
is that the integral operator A given by
is an Hilbert-Schmidt operator on L2(E, r~).
Theorem 2.23 Assume that condition (’r~,C) is satisfied. For any T > 0 the integral
operator I - AT is invertible and the random field
converges as N - oo to a centered Gaussian field
satisfying
~(~1))~ (I - AT)-1(~Z - ~(~2)))L2 ( ~! (o,T))
in the sense of convergence of finite dimensional distributions.
The basic tools for studying the convergence in law of {~~(.r) ;
; N > l~ are the
Dynkin-Mandelbaum Theorem on symmetric statistics and Shiga-Tanaka’s formula
of Lemma 1.3 in . The detailed proof of Theorem 2.23 is given in . Here we
merely content ourselves in describing the main line of this approach. Here again we
simplify notations suppressing the time parameter T and we write A instead of AT.
Let us first recall how one can see that I - A is invertible. This is in fact classical
now (see and for instance). First one notices that, under our assumptions, An,
n > 2 and A A* are trace class operators with
TraceAn = ... ~
x2) ... a(xn, xl)
TraceAA* =
Furthermore by definition of a and the fact that yy is a product measure it is easily
checked that
TraceAn = 0
Standard spectral theory (see for instance) then shows that det2(I - A) is equal
to one and therefore that I - A is invertible.
The identification of the weak limit of {~~(.c) ;
; N > 1} relies on L2-techniques
and more precisely Dynkin-Mandelbaum construction of multiple Wiener integrals as
a limit of symmetric statistics. To state such a result, we first introduce Wiener integrals.
E L2(r~)~ be a centered Gaussian field satisfying
(~1W2)L2(rJ)
If we set, for each ~ E I~(?y) and m > 1
the multiple Wiener integrals {Im(h03C6m)
with m ~ 1, are defined by the
03A3 tm m! Im(h03C6m) =
(tI1(03C6) - t2 2~03C6~2L2(~)
The multiple Wiener integral
is then defined by a completion
argument. Theorem 2.23 is therefore a consequence of the following lemma.
Lemma 2.24 ( )
where f is given by
f(y,z) = a(y,z) + a(z,y)
- 03A3Ta(u,y)
a(u,z)~(du).
In addition, for any 03C6 ~ L2(~),
+ ih - 1 TraceAA*
Following the above observations, we get for any p E L2 (~),
+ H(N)(x)))
(exp(iI1(03C6)
+ 1 2I2(f) - 1 2TraceAA*))
Moreover, Shiga-Tanaka’s formula of Lemma 1.3 in shows that for any p E
+ 1 2 I2 (f) - 1 2 TraceAA* =
exp -1 2II( (I -
The proof of Theorem 2.23 is thus complete. The proof of Lemma 2.24 entirely relies
on a construction of multiple Wiener integrals as a limit of symmetric statistics. For
completeness and to guide the reader we present this result.
; i > l~ be a sequence of independent and identically distributed random
variables with values in an arbitrary measurable space (X, B). To every symmetric
function h(zl, ... , zm) there corresponds a statistic
h(~21,...,~i"’)
with the convention ~m - 0 for m > N. Every integrable symmetric statistic
S(~l, ... , , ~N) has a unique representation of the form
1,..., N) _ ~
where /~(~i,..., zm) are symmetric functions subject to the condition
where ~ is the probability distribution of (~.
We call such functions (hm
; m > 0} canonical. Finally we denote by 7~ the set of all
sequences h = (ho, ~i(~i),..., ~m(~i,..., ~m),...) where hm are canonical and
~~E(~(~...~))oc
As in we will use repeatedly the following
Theorem 2.25 (Dynkin-Mandelbaum )
the sequence of random variables ZN(h) =
in law, as N ~ ~, to
Proof of Lemma 2.24: (Sketched)
It is first useful to observe that for any /~ 6 Mi(E) and n > 1 we have that
~~ ~ _~M_~ = ~(~(.)~(.~)) /
d~n d03A6n(~n-1) ~n-1
(gn(.)kn(.,x)) / ~n-1(gn)
Therefore the symmetric statistics 77~(2’) can be written in the form
~E~’~)) -~ ~E~~))1
By the representation
which is valid for all z > 0 with c =
G we obtain the
decomposition
~=1 t==i B
+~E~E~)-~+~ (~
+"2 ~=1 B N
where the remainder term R(N) cancels as N tends to oo. The technical trick is to
decompose each term as in (69) in order to identify the limit by applying Theorem
2.25. For instance, the first term can readily be written as follows
with IE a(z, z)
= IE a(x, z)
= IE a(z,x)
= 0 for any x E E
and therefore a clear application of Theorem 2.25 yields that it converges in law as
2.2.5 Large Deviations Principles
The LDP presented in this section are not restricted to the situation where the functions ~~n ; n > l~ have the form (8). In what follows we undertake a more general
and abstract formulation and we assume that
> 0~ is the IPS approximating
model (13) associated with a given sequence of continuous functions ~~n ; n > l~.
The LDP for the IPS approximating model (13) for (8) will then be deduced directly
from these results.
Large Deviations on Path Space
To prove large deviations principles (LDP) for the laws
; N > 1} of the empirical measures
we will always assume that the continuous functions ~~~, ; n > l~
satisfy (P)o. As it has already seen in section 2.2.1, p. 34 the main simplification due
to this assumption is that
is absolutely continuous with respect to the distribution
of the empirical measure associated with N independent
random variables with common law
In addition, we have that
dQ(N)T dR(N)T
= exp(NFT)
where FT :
the function defined by
FT(~) _ E / iog
= log d~(D,T) !~
In a first stage for analysis it is reasonable to suppose that
(P)i For any n > 1 there exists a reference probability measure ~n E M(E)
such that for all ~ M1(E), 03A6n( ) ~ 03BBn and the function
( ,03BD) ~
logd03A6n(03BD) d03BBn
is bounded continuous.
If I( /03BD)
denotes the relative entropy of J1 with respect to v, that is the function
logd d03BD
if J1 « v and +00 otherwise, Sanov’s Theorem and Varadhan’s Lemma yields
Theorem 2.26 Assume that
n > 1~ is a sequence of continuous functions
holds. Then, for any T > 0,
N > 1~ satisfies a LDP with good
rate function
is the unique minimizer of JT.
Proof: (Sketch) Under the assumptions of the theorem, FT is bounded continuous so
N > l~ satisfies a LDP with good rate function
according to Sanov’s Theorem and Varadhan’s Lemma (see for instance). ..
Corollary 2.27 Assume that the functions ~~n ; n > l~ are given by (8) and the
transitions probability kernels ~I~n ;
; n > l~ are Feller and satisfy the following assumption
For any time n > 1, there exists a reference probability measure
~n E M1(E) such that Kn(x, .) N An and
~ the function z H log d~~d~n’’ (z) is Lipschitz, uniformly on the parameter x E E, and for any z E E the map x H dha~~’’ (z) is continuous
2022 there exists a positive number En E (0,1] such that
~n ~ dKn(x,
) d03BBn ~
Then, for any T > 0,
N > 1~ satisfies a LDP with good rate function JT.
Condition (J~)1 is stronger than condition
which has been used in section 2.1.2,
p. 24, as a mixing condition to derive exponential stability properties for the limiting
measure valued system (8). In LDP settings this hypothesis is more related to a compactness assumption.
Here we present a way to relax
based on cut-off arguments.
Let FT : : M1 (T) - R be the cut-off transformation of FT given by
FM T (l~) - ~ T /
+ sign(x) M
Next assumptions relax (~)1
(,C)o For any time n > l, there exists a reference probability measure
an E M1(E) such that for all p E M1(E),
03BBn and the function
(x, 03BD) ~ log d03A6n(03BD) d03BBn(x)
is uni f orml y continuous w. r. t. ~ (and uni f orml y w.r.t. v~ and continuous w. r. t. v.
(,C)1 There exist constants cT ~, aT > 1 such that
R(N)T(e03B1TNFT)
and, for every E > 0 there exists a function
infinity when M goes to infinity, so that
R(N)T(|FT- FMT|> ~)~e-NLT,~(M)
(,C)2 There exist constants 03B4T > 0 CT ~, DT
oo and a function ET,
ET(M) is going to zero when M is going to infinity, such that for any
Theorem 2.28 Assume conditions (,C)o, (,C)1 and (£)2 are satisfied.
Then, ~~TN~
: N > 1 } satisfies a LDP with good rate function JT.
Proof:(Sketch) Under (,C)o one first check that FT is bounded continuous. The
proof is now based on the ideas of Azencott and Varadhan and amounts to replace
the functions FT (which are a priori nor bounded nor continuous) by the functions
FT to get the LDP up to a small error E in the rate function by (,C)1 and then pass
to the limit M -~ oo by (£)2 to let finally 0.
Conditions (~C)1 and (£)2 are hard to work with. It is quite remarkable that an
exponential moment condition suffices to check (,C)1 and (,C)2.
Corollary 2.29 Suppose the functions
; n > 1} satisfy next condition
(~)i For any time 1
n T there exists a reference probability measure an E Ml(E) such that for all p E M1(E),
. For any 1 n T the function
logd03A6n(03BD) d03BBn(
is uniformly continuous w.r.t. ~ and continuous w.r.t. v.
. There exist B(E)-measurable functions c~ and ~ and constants
and E > 0 such that a + 1 03B2 1 and for any 1 n T
|log d03A6n(u) d03BBn |
~ 03C6(x) + (03C8)
: N > 1} satisfies the LDP with good rate function JT
Corollary 2.30 Assume that the functions
; n > 1~ are given by (8) and the
transitions probability kernels
; n > 1~ are Feller and satisfy the following assumption
(J~)1 For any time 1 n T there exists a reference probability measure An E M1(E) such that Kn(x, .)
2022 For any time 1 n T the function
logdKn(x,.) d03BBn
is Lipschitz, uniformly on the parameter x E E, and for any z E E
x ~ dKn(x,.) d03BBn
is continuous.
~ There exist a B(E)-measurable function ~p and constants a > 1 and
E > 0 such that for any time 1 n T
log d~ (z) p(z)
: N > 1} satisfies a LDP with good rate function JT.
Large Deviations for the Particle Density Profiles
The large deviations results on path space rely largely on the existence of a family of
reference distributions
: n > l~ satisfying condition (P)o and therefore does not
apply to some filtering problems (see section 5). To remove this assumption we shall
be dealing with the law
n > 1 ~, of the particle density profiles
; n > 1 ~.
Theorem 2.31 Assume that the continuous functions
; n > 1} satisfy the following condition
(ET ) For any n > 1, E > 0 and for any Markov transition M on E, there
exist a Markov kernel M and 0 ~ E such that
for any ~ E M1 (E) and for any compact set ACE.
Then, for any n > 0, ~P~N)
: N > l~ obeys a LDP with convex good rate function Hn given by
- log (~n(v)(ev)))
03BD~M1(E)
- I (~) ~lo)
In addition
= 0 i, f’,a =
for any n > l.
Proof:(Sketch) First we check that (~T’) insures that for any time n > 0 the
is exponentially tight (cf. Proposition 2.5 in (35~). To get the desired LDP we proceed
by induction on the time parameter. For n = 0 the result is a trivial by Sanov’s
Theorem so we assume that it holds for (n -1). Observe that the moment generating
function at rank n is given for any V E Cb(E) by
E (exp (N~ln (V )))
= ~ (~n(~l~ i)(e )~
Since Gn is bounded continuous then Varadhan’s Lemma (see for instance , Theorem 2.6 p 24) and the induction hypothesis at rank (n -1) imply that
inf (Hn-l (~) - log
Using the exponential tightness property we are now in position to apply Baldi’s
Theorem (cf. Theorem 4.5.20 p. 139 and Corollary 4.6.14 in ). More precisely, it
remains to check that An is finite valued and Gateaux differentiable. The first point
is obvious. To check that An is differentiable we introduce for v E M1 (E),
:= Hn_1(v)
After some calculations one finds that for any v E Cb(E) ,
To see that
holds if the functions ~~n ; n > l~ are given by (8) we simply
notice that, under the assumption (9), for any n ~ 1 and for any compact set A C E,
~n ~l (‘4c) ~ an
Corollary 2.32 If the functions
; n > l~ are given by (8) and the transitions
probability kernels {Iin ;
; n > l~ are Feller then for any n > 0, ~Pn : N > l~ obeys
a LDP with convex good rate function Hn.
2.3 Branching Particle Systems Variants
The research literature abounds with variations on the IPS model (13). Each of these
variants is intended to make the selection and/or the mutation transition more efficient in some sense. As a guide to their usage, this section presents a survey of what
is currently the state of the art.
The analysis of the convergence of all these alternative schemes is actually not
complete. We therefore gather together here several discussions and results which we
hope will assist in giving an illustration of how the analysis developed in section 2.2
may be applied.
The first scheme discussed in section 2.3.1 concerns a genetic type algorithm with
periodic selection times. The key idea here is to use the stability properties of the
limiting system to produce a more efficient IPS. We will show that the resulting algorithm can be reduced to the latter through a suitable state space basis. In this specific
situation all the results developed in section 2.2 may be applied. It will also be shown
that the convergence exponent in the uniform convergence result 2.11 improves the
one obtained for the generic IPS.
Section 2.3.2 presents a way to produce an IPS whose mutation transitions depends on the fitness functions. In nonlinear filtering settings this scheme is often
referred as an IPS with conditional mutations. In this situation the fitness functions
and therefore the mutation transitions depend on the observations record so that the
particles are more likely to track the signal process.
In section 2.3.3 we present "less time-consuming" selection transitions such as
the Remainder Stochastic Sampling and other BIPS alternatives including Bernoulli,
Poisson and Binomial branching distributions. These selection transitions can be related to the classical weighted bootstrap theory as well as genetic algorithms theory
(the book includes a useful survey on these two subjects).
In filtering settings the choice of the mutation transitions {Kn ; n > l~ is dictated
by the form of the signal. It may happen that these transitions are degenerated (i.e.
deterministic) and therefore the IPS approximating models will not work in practice
since after a finite number of steps we would get a single deterministic path. The last
section 2.3.4 presents a way to regularize such degenerated mutation transitions. This
regularization step has been introduced in . We shall indicate how the results of
section 2.2 are applied.
In practice the most efficient IPS approximating model is the one obtained by
combining conditional mutations and periodic selections. The choice of the best selection scheme is more an art form. There is a balance between time-consuming and
efficiency. The less time consuming selections seems to be Remainder Stochastic Sampling and Bernoulli branching selections. In the last case the size of the system is not
fixed but random and explosion is possible (cf. and 4) section 2.3.3).
The most important and unsolved problem is to understand and compare the
influence of the various selections schemes on the long time behavior of the BIPS approximating models. The interested reader will find that although we have restricted
ourselves to the relatively less complicated generic IPS model (13) most of our general
techniques apply across these more complex BIPS variants.
There are many open problems such as that of finding the appropriate analog of
the results of section 2.2 for the BIPS approximating models presented in section 2.3.3.
This study has been started in and in but many open problems such as the
fluctuations remain to be answered. A related question will be to find a criterion for
determining the "optimal branching" transition. This problem will probably lead to
difficult optimization problems since this criterion should be related to the long time
behavior of the BIPS approximating schemes.
Periodic Interactions/Selections
The IPS with periodic selections discussed here has been introduced in as a way
to combine the stability properties of the limiting system with the long time behavior
of the particle scheme.
The prediction/mutation of the former include exploration paths of a given length
T > 1 and the selection transition is used every T steps and it involves T fitness
functions. Our immediate goal is to show that the former genetic algorithm can be
reduced to the latter through a suitable state space basis. To this end we need to
introduce some additional notations.
To each p E ~l, ... , T } we associate a sequence of meshes
_ (n -1)T + p
If we write L1n = tn - tn-i for any n > 1 we clearly have that
The parameter T is called the selection period, n will denote the time step and the
parameter p will only be used to cover all the time space basis N. The construction
below will depend on the pair parameter (T, p) but to clarify the presentation we
simplify the notations suppressing the pair parameter (T, p) so that we simply note
tn instead
We also notice that the distributions given by
x Ktn+1 x ... x
are solutions of the measure valued process
= ~(P)(~n_1) n ~ 1
where ~~p) :
is the continuous function given by
~(p)(~ - ~(p)(~)~(p)
and l~{p) and ~~p) are defined as follows.
is the continuous function defined for any test
function f E
by setting
03A8(p)n( )(f) =
(g(p)n f) (g(p)n)
g(p)n(x)=gtn-1+q(xq).
2022 K(p)n is the transition probability kernel from E°n to
~~p)((xl,...,x°n)~~(zi,...,z°"+~))
The IPS associated with (75) is now defined as a Markov chain {(n ; n 2 0~ with
product state spaces ~(E°n+1 )N ; n > 0~ where N is the number of particles and
> 0~ the selection periods.
The initial particle system (o = (~~, ... ,
takes values in
is given by
and the transition of the chain is now given by
P(03B6n ~ dx|03B6n-1
= z) = 03A6(p)n
03B4z,)(dxi)
K(p)n(zi,dxi)
where dx = dxl x ... x dxN is an infinitesimal neighborhood of the point x =
)N and for any 1 i N, zi = (zi, ... ,
If we denote
~n - (~tn ) . .. ,
we see that the former algorithm is indeed a genetic type algorithm with T-periodic
selection/updating transitions. Between the dates tn and
the particles evolves
randomly according to the transition probability kernel of the signal and the selection
mechanism takes place at each time tn , n > 1.
As announced in the beginning of the section, this IPS scheme with periodic selection times is reduced to the one presented in section 1.3 through a suitable state
space basis so that the analysis given in section 2.2 applies to this situation.
The uniform results with respect to time given in Theorem 2.11 can be improved
by choosing a suitable period which depends on the stability properties of the limiting
system and on the number of particles. More precisely, if we denote by
the particle
density profiles given by
~Ntn=1 N03B403BEitn
then we have the the following theorem.
Theorem 2.33 Assume that the limiting dynamical system (8) is exponentially asymptotically stable in the sense that there exist some positive constant y > 0 such that for
any function f E Bb(E) with
If the selection period is chosen so that T = T(N) def
[1 2log N 03B3+03B3’] + 1 then for any
f E Bb(E),
l, we have the uniform bound given by
sup E(~Ntnf-~tnf|) ~
4e203B3’ N03B2/2
03B2=03B3 03B3+03B3’
03B3’ = 2log 03B1
Remarks 2.34:
. Although we have not yet checked more general LP-bounds or uniform convergence results over a suitable class of functions, the proof of Theorem 2.33
essentially follows the same arguments as in the proof of Theorem 2.11.
. It is also worth observing that the choice of the selection period depends on the
stability properties of the limiting system as well as on the number of particles.
. Another remark is that the critical exponent Q resulting from the proof of Theorem 2.33 is now sharp in the following sense: if the fitness functions are constant
then, without loss of generality, we may chose a = 1. In this specific situation
the critical exponent /3 = 1 which is again the characteristic exponent of the
weak law of large numbers.
~ Our last remark is that periodic selections are very efficient and have a specific
interpretation in nonlinear filtering settings. We recall that in this situation the
fitness functions are related to the observation process. Roughly speaking the
selection transition evaluates the population structure and allocates reproductive opportunities in such a way that these particles which better match with
the current observation are given more chance to "reproduce". This stabilizes
the particles around certain values of the real signal in accordance with its noisy
observations.
It often appears that a single observation data is not really sufficient to distinguish in a clearly manner the relative fitness of individuals. For instance this
may occurs in high noise environment. In this sense the IPS with periodic selections allows particles to learn the observation process between the selection
dates in order to produce more effective selections.
Conditional Mutations
The IPS with conditional mutations is defined in a natural way as the IPS approximating model associated to the measure valued process (23) presented in section 2.1.1,
p. 22. To clarify the presentation it is convenient here to change the time parameter
in the fitness functions {gn ; n > 1} so that we will write gn instead of gn+1. Using
these notations (23) is defined by the recursion
and for any f E Bb(E) ,
~(nf) ~(n),
Kn(gnf) Kn(gn),
As noticed in section 2.1.1 this model has the same form as (8). It is then clear
that all the results developed in section 2.1.2 and section 2.2 can be translated in
these settings.
In contrast to (8) we also note that the prediction transitions here depends on
the fitness functions and therefore the corresponding IPS approximating model will
involve mutation transitions which also depend on these functions. More precisely,
let en = ~~, ... , ~’n E EN be the N-IPS associated with (77) and defined as in (13)
by the transition probability kernels
P (en E dx
where dx def dxl x ~ ~ ~ x dxN is an infinitesimal neighborhood of the point ~ _
(zl ... xN) E EN, z =
... , zN) E EN. As before we see that the above transition
involves two mechanisms
Mutation -
201420142014201420142014~ ~ 201420142014201420142014~ ~
which can also be modelled as follows
P(n ~ dx|n-1 = z) = 03B4zi(dxp)
As we already noticed in section 2.1.1 the fitness functions {9’n ; n > 0~ and the
transitions {Kn ; n 2 1~ involve integrations over the whole state space E so that
another level of approximation is in general needed.
Nevertheless let us work out an example in which these two objects have a simple
Example 2.35 Let us suppose that E = l~ and the fitness functions ~gn ; n > 1~
and the transitions {Is’n ; n > l~ are given by
e-1 2qn(z-an(x))2
where an : IR ~ R, qn
> 0 for any n > 1 and rn > 0, cn, yn E R, for any n > 0. In
this situation one gets easily
n(x,dz) = 1 2|sn|exp(-1 2|sn|(z-[an(x)+sncnr-1n(yn-cnan(x))]
and n(x) = 1 2|qn||rn|/|sn|exp(-
1 2|qn||rn|/|sn|(yn-cn an(x))2)
One idea to approximate the transition
is to introduce an auxiliary
branching mechanism.
Selection/Mutation
201420142014201420142014201420142014201420142014201420142014). ~
The branching transition is defined inductively as follows.
At each time (n - 1) each particle ~n_1
i branches independently of each other into
M-auxiliary particles with common law Kn ~n_1, . , that is for any 1 i N,
p Branching
( ~a n’ ~ 1 ... ~ i,M)
where ~~n’1, ... , ~n~~) are (conditionally) M-independent particles with common law
~(C-i~). .
At the end of this branching step the system consists in N x M particles
~n = (~~1~, ... , ~tN~) E
x ... x EM
If the parameter M is sufficiently large then, in some sense, the empirical measures associated with each sub-group of M particles is an approximating measure of
~(~,.), that is
is the transition probability kernel from EM into E given for any x E EM
and f E Bb(E) by the formula
(K(M)nf)(x)
Using the above notations we also have, in some sense, that
~,(M}(~(~}) def. K(M}(gn)l~(n~}) --~
and for any f E Bb(E)
(M)n(f)(03B6(i)n)
K(M)n(gn f)(03B6(i)n) K(M)n(gn)(03B6(i)n)
n(f)(1n-1)
Finally if we combine (79) and (80) one gets an M-approximation of the desired
transition
N N ~M}(~(E})
The next particle system (n = ~~, ...,
simply consists in N conditionally independent particles with common law the left hand side of (81).
Our new BIPS is now defined by the following Markov Model
~n_1 ~ ~n = ~nl ~ ... ? ~n ~ ~n = ~n ~
with the following transitions
~ Branchings: The branching transition
E EN --~ ~n = ~1}, ... , {N}) E
is defined by
P (en E dx(1} x ...
~ )~®M(dx(~})
x ... x dxi,M is an infinitesimal neighborhood of the point
... , , xa’M) E EM, z = (zl, ... , zN) E EN.
~ Selection: The selection transition
(n = (~~1), ... , ~{N)) E
-~ ~~ _ ~~’}, ... ~)
is defined by
|03B6n = (x(1),... ,x(N)))
(M)n(x(p)) N
~ Mutation: The mutation transition
C~~1), ... , ~~N) E (EM)N -~ ~n E EN
is defined by
P (en E dz
= (y~l)~ ... , y~N)) =
This algorithm has been introduced in . In this work exponential rates of
convergence and LP-mean error bounds are discussed. The LDP associated with such
branching strategy and comparisons with the rates presented in section 2.2.5 are
described in .
2.3.3 Branching Selections
Roughly speaking, the selection transition is intended to improve the quality of the
system by given individuals of "higher quality" to be copied into the next generation.
In other words, selection focuses the evolution of the system on promising regions
in the state space by allocating reproductive opportunities in such a way that those
particles which have a higher fitness are given more chances to give an offspring than
those which have a poorer fitness. They are number of ways to approximate the
updating transitions but they are all based on the same natural idea. Namely, how
to approximate an updated empirical measure of the following form
gn(xi) 03A3Nj=1 gn(xj)
03B4xi (82)
by a new probability measure with atoms of size integers multiples of
In the generic IPS approximating model ( 13) this approximation is done by sampling N-independent random variables
; 1 i TV} with common law (82) and
the corresponding approximating measure is given by
(M1,...,MN)Multinomial(N,gn(x1) 03A3Nj=1 gn(xj)
gn(xN) 03A3Nj=1 gn(xj))
Using these notations the random and N-valued random variables can be regarded as
random number of offsprings created at the positions (xl, ... xN).
The above question is strongly related to weighted bootstrap and genetic algorithms theory (see for instance and references therein). In this connection the
above multinomial approximating strategy can be viewed as a weighted Efron bootstrap.
It is well known that sampling according to a multinomial may be "time consuming"
mainly because it requires a sorting of the population. As in classical bootstrap literature the other idea consists in using independent random numbers (Ml, ...
distributed according a suitably chosen branching law. In what follows we present
an abstract BIPS approximating model which enables a unified description of several
classes of branching laws that can be used in practice including Bernoulli, binomial
and Poisson distributions.
Abstract BIPS Model
The abstract BIPS model will be a two step Markov chain
Branching - - Mutation
with product state space
with the convention EO = ~0~ a cemetery if a = 0. We will note
the canonical filtration associated to (83) so that
Fn C Fn C Fn+i
The points of the set Ea, a > 0 are called particle systems and are mostly denoted
by the letters x and z. The parameter a E N represents the size of the system. The
initial number of particles No E N is a fixed non-random number which represents the
precision parameter of the BIPS algorithm.
The evolution in time of the BIPS is defined inductively as follows.
w At the time n = 0:
The initial particle system ~o = (~o, ... , ~o ° ) consists in No independent and
identically distributed particles with common law Co.
~ Evolution in time:
At the time n, the particle system consists in Nn particles.
If Nn = 0 the particle system died and we let Nn = 0 and Nn+1 = 0.
Otherwise the branching correction is defined as follows
1. Branching Correction:
When Nn > 0 we associate to ~’n = (~’n, ... , ~n n ) E ENn the weight vector
Wn = (Wn, ... , Wn n ) E RNn given by
where m(~n) _ - ~
Then, each particle ~n,1 i Nn, branches into a random number of offsprings
Mn, 1 i Nn and the mechanism is chosen so that for any f E Bb(E)
E(Minf(03BEin)|Fn = Nn03A8n+1(m(03BEn))f (84)
and there exists a finite constant C oo so that
([Minf(03BEin) -
Nn03A8n+1(m(03BEn))f]2
~ C Nn~f~2
At the end of this stage the particle system fn consists in n
= 03A3Nni=1
particles denoted by
2. Mutation transition:
If Nn = 0 the particle system dies and Nn+1 = 0.
Otherwise, each particle moves independently of each other starting off from the
parent particle branching site ~~ with law
i Nn, for any
1 i Nn . During this transition the total number of particles doesn’t change
and the mechanism can be summarized as follows, for any a > 0
and z ~ E03B1
P (03BEn+1
Kn+1(zi,dxi)
where dx = dx1 ... dx03B1 is an infinitesimal neighborhood of x ~ E03B1 with the
conventions dx = ~~~ and
1 =1 if a = 0.
The approximation of the flow of distributions
> 0~ by the particle density
03B403BEin
is guaranteed by the following theorem.
Theorem 2.36 If the branching selection law satisfy (8.~~ and (85) then, the total
mass process N = (N n )nO is a non-negative integer valued martingale with respect to
the filtration F = (Fn )nO with the following properties
In addition, for any n > 0 and f E Bb(E), ~~ f ~~ 1 we have that
- ~n(f))2]~ Bn N0
for some finite constant Bn which only depends on the time parameter n.
Branching Selections
Here we present several examples of branching laws which satisfy conditions (84)
and (85). The first one is known as the Remainder Stochastic Sampling in genetic
algorithms literature. It has been presented for the first time in .
. From a pure
practical point of view this sampling technique seems to be the more efficient since
it is extremely time saving and if the BIPS model is only based on this branching
selection scheme then the size of the system remains constant.
1) Remainder Stochastic Sampling
In what follows we denote by [a] (resp. ~a~ = a - ~a~) the integer part (resp. the
fractional part) of a E I~.
At each time n > 0, each particle ~n branches directly into a fixed number of offsprings
so that the intermediate population consists in Nn def.
~~ particles. To prevent
extinction and to keep the size of the system fixed it is convenient to introduce in this
population iifn additional particles with
One natural way to do this is to introduce the additional sequence of branching
Multinomial
More precisely, if each particle ~n again produces a number of M~ additional
offsprings, 1 i Nn, then the total size of the system is kept constant.
At the end of this stage, the particle system in again consists in Nn particles denoted
zn = 03BEkn
03A3Mln + 1~ i ~ 03A3Mln + Mkn
M~,+1~2~~M~+M~
The multinomial random numbers (88) can also be defined as follows
kn=Card {1~j~Ñn; jn=03BEk} 1~k~Nn
where (1n, ... , Ñnn) are Ñn independent random variables with common law
It is easily checked that (84) is satisfied and (85) holds for C = l.
Let us now present some classical examples of independent branching numbers
that satisfy the non bias condition (84) and the L2-condition (85).
2) Bernoulli branching numbers:
The Bernoulli branching numbers were introduced in and further developed in .
They are defined as a sequence Mn = ( Mn, 1 i Nn ) of conditionally independent random numbers with respect to Fn with distribution given for any 1 i Nn
P(Min = k|Fn
) = {NnWin}
if k = [NnWin] + 1
if k = [NnW
In addition it can be seen from the relation
= Nn that at least one
particle has one offspring (cf. for more details). Therefore using the above branching correction the particle system never dies.
It is also worth observing that the Bernoulli branching numbers are defined as in
the Remainder Stochastic Sampling by replacing the multinomial remainder branching
law (88) by a sequence of Nn independent Bernoulli random variables M,~, ... ,
3) Poisson branching numbers:
The Poisson branching numbers are defined as a sequence Mn = ( Mn, 1 i Nn )
of conditionally independent random numbers with respect to Fn with distribution
given for any 1 i N~, by
P(Min = k|Fn)
= exp (-Nn
Win) (NnWin)k k!
4) Binomial branching numbers:
These numbers are defined as a sequence Mn =
1 i Nn) of conditionally
independent random numbers with respect to Fn with distribution given for any 1
All of these models are described in full details in ~25~. In particular it is shown
that the BIPS with multinomial branching laws arises by conditioning a BIPS with
Poisson branching laws. The law of large numbers and large deviations for the BIPS
model with Bernoulli branching laws are studied in ~2~~ and ~22~.
The convergence analysis of these BIPS approximating schemes is still in progress.
They are many open problems such as that of finding the analog of the Donsker and
Glivenko-Cantelli Theorems as well as the study of their long time behavior. This last
question is maybe the most important one. The main difficulty here is that the total
size process ~Nn ;
; n > 0~ is an F-martingale with predictable quadratic variation
An = N20 + 03A3 E( |Np - Np-1
|2/Fp-1) = N20 + 03A303A3 E( (Mip-NpWip)2/Fp)
and therefore a uniform convergence result presented in section 2.2.2 will take place
- Np_1 (2) o0
The following simple example shows that even for the minimum variance Bernoulli
branching law one cannot expects to obtain the analog of the uniform convergence
results as those presented in section 2.2.2. Let us assume that the state space E =
~0,1 ~, the fitness functions ~gn ;
; n > 1 ~ and the transition kernels ~I~n ; n > 1 ~ are
time homogeneous and given by
g(1) = 3g(0) > 0
K(x, dz) = 03BD(dz)
1 203B40(dz) + 1 203B41(dz)
In this case one can check that for sufficiently large No
E ((~Nn(1)- ~n(1))2)~ n 5N0
In contrast to the situation described above in this simple case the IPS approximating model (13) will simply consist at each time in No i.i.d. particles with common
law 03BD and
~n~0, E((~Nn(f)-~n(f))2) ~ 1 N0
for any bounded test function such that
2.3.4 Regularized Mutations
The regularization of the mutation transition discussed in this section has been presented in . Hereafter we briefly indicate why it is sometimes necessary to add a
regularization step and how the previous analysis applies to this situation.
In nonlinear filtering settings the mutation transitions {Kn ; n 2 l~ are given
by the problem at hand. More precisely they are the transitions of the un-known
signal process. If E =
it may happen that some coordinates of the signal are deterministic. For instance if the signal is purely deterministic the IPS approximating
scheme (13) does not work since after a finite number of steps we would get a single
deterministic path.
As noticed in the standard regularization technique used in practice consists in
adding a "small noise" in the deterministic parts of the signal. When E = ]Rd, d 2 l,
the introduction of such a "small noise" in the signal dynamics structure consists in
replacing the transitions {Kn ; n ~ 1} by the regularized ones
where R(o) is a new transition probability kernel on E and defined for any f E Bb(E)
where 0 : IRd -~ (0, oo) is a Borel bounded function such that
The regularized limiting measure valued system is now defined by
= r~o and where !~ : : M1 (E) ~ M1 (E) is defined as in (8) by replacing the
transitions {Kn ; n > 1~ by ~Ii {a~ ; n > l~.
Let us denote by
n n’ ~’ w n
the N-IPS approximating model associated with (89) and
the empirical
measure associated with the system and defined as usual by
~(03B1),Nn=1 N
03B403BE(a),in
It is transparent from the above construction that the convergence results presented in section 2.2.2 can be applied. For instance for any bounded test function
f ~ Bb(E), !!/!! 1, and p > 1 and n > 0
E I ~n (a),N (f ) _
(n l + 1 )
where Bp is a universal constant which only depends on the parameter p.
Of course we still have to check that the flow of distributions ~~{a) ; n > 1 ~ is close
to the desired flow
> 1~ as a is close to zero. To this end we introduce some
additional notations.
We denote by Lipl the set of globally Lipschitz functions with Lipschitz norm less
than 1 that is
1. We will also use the following assumption
(R) For any time n > 1, there exist some constants Cn, C,~
9n E Cl Lipl
Lemma 2.37 Under (R), for any n > 1 there exists some constant Cn
that for any f E Lipl
Proof: For any f E Lipl and x E 1~d we clearly have
IR(a)(f)(x) - f (~)~ ~ (f (x + a y) - f (x)I 8(y) dy ~ a ~
and therefore
sup I I R(a) (~‘ ) - f I I a ~
Under our assumptions this implies that for any 1] E M1(E)
sup I ~{a}(~)(f ) - ~n(~)(f )I C a Q An
for some constant An oo. Let us prove (90) by induction on the parameter n. For
n = 0 the result is trivial with Co = 0 so we assume that it holds for (n -1). Using
Lemma 2.2 we have the decomposition
~n(~(a)1)(f ) ~n‘~n-1 )(f)
X (~{a)1 (gn K n (f))
- ~n-1 (gn K n (f))) + ~n(~~a)1 )(f ) (~n-1 (gn)
- ~Ca)1 (9n)) ]
for any f E Lip1. There is no loss of generality to assume that
> an and that
C{2) > l. Thus one gets
~n(~Ca)1)(f ~ ~n(~n-1
=C(1)n+anC(2)n
[(~(03B1)n-1(f1)
- ~n-1(f1))]
(17n-l (it) - 17n-1 (f1))
~n-1(9n) ~~n-1~f2)
1 C(1)n+anC(2)n
so that fl, f2 E Lipl. Using the induction hypothesis we arrive at
sup ~03A6n(~(03B1)n-1)(f)-03A6n(~n-1)(f)~
C(1)n + anC(2)n) ~n-1(gn) Cn-1 03C3 03B1
Therefore if we combine the above results one gets finally
sup |~(03B1)n(f) -~n(f)| ~ Cn 03C3 03B1
~in = An -f- 2(C{1) ~’ anC{2)) Cn_1.
A direct consequence of the above lemma is the following estimate
(n l + 1 )
The approximation of
; n > 0~ by the regularized IPS is now guaranteed by
the following proposition.
Proposition 2.38 Assume that the condition (R) is satisfied. Then for any n > 0
and p > 1 there exists some constant Cp,n oo such that
03B1( N) =1 /N ~
~(03B1),Nn( f)
1 p ~ Cp,n N
3 The Continuous Time Case
We will try here to retranscribe some results obtained in previous parts for discrete
time settings to continuous time models. Generally speaking, the same behaviors are
expected, but the technicalities are more involved, even only for the definitions. Furthermore, this case has been less thoroughly investigated, and it seems that a genuine
continuous time interacting particle system approximation has only recently been introduced in .
This last paper will be our reference for this part and we will keep working in the
same spirit, but in the details our approach will be different in order to obtain numerous improvements and to prove new results: weak propagation of chaos valid for all
bounded measurable functions and related upper bounds in terms of the supremum
norm, as well as uniform convergence results with respect to time and central limit
theorem and exponential upper bounds for the fluctuations.
Heuristically the main difference between the two time models is that for discrete
time, in the selection step all the particles are allowed to change, whereas for continuous time, only one particle may change at a (random) selection time, but the
length of the interval between two selection times is of order
(N being as above
the number of particles). So in some mean sense, in one unit time interval, "every
particle should have had a good chance to change" .
This is a first weak link between discrete and continuous time. But, even if this may
not be clear at first reading, there are stronger relations between the formal treatment of the discrete and continuous times, and in our way to trying to understand
the subject, they have influenced each other. In order to point out these connections,
we have tried to use the same notations in both set-ups.
To finish this opening introduction, we must precise that the main results obtained
here (the weak propagation of chaos and to some extend the central limit theorem)
can also be deduced from the approach of Graham and Meleard , valid for a more
general set-up, except they have put more restrictions on the state space, which is
assumed to be
for some d > 1 (but perhaps this point is unessential).
Nevertheless, we have preferred to introduce another method, may be more immediate
(e.g. without any reference to Boltzmann trees or Sobolev imbeddings ... ), because
we have taken into account that our models are simpler, since we are not in the need
of considering the broader situation of .
More precisely, in our case, we have a nice a priori explicit expression (3) and (4) for
the (deterministic) limiting objects, making them appear as a ratio of linear terms with
respect to
which is hidden in E as the initial distribution. This structure is more
tractable than the information one would get by merely considering the nonlinear
equation of evolution looking like (11) satisfied by the family
make use of some associated nonnegative Feynman-Kac semigroups to obtain without
difficulty the desired results.
3.1 Hypotheses on the Limiting Process
To accomplish the program described above it is first convenient to define more precisely the objects arising in formula (4). Our next objective is to introduce several
kinds of assumptions needed in the sequel and to prove some preliminary results. As
before, the metric space (E, r) is supposed to be Polish, and we denote by B(E) the
a-field of Borel subsets of E.
Definitions and Weak Regularity Assumption
Here we introduce the basic definitions and the weak hypothesis under which we will
work. It is already largely weaker than the one considered in , and we believe that
maybe it can even be removed (we have been making some recent progress in this
direction, but at the expense of readability, considering tensorized empirical measures
... ), but at least this weak assumption make clear the regularity problem one is to
encounter when following the approach presented in this paper.
The simplest object to be explained is the family (Ut)tO of non-negative functions.
We will assume that the mapping
Ut(x) E 1~+
Q9 B(E)-measurable (where B(R+) is the usual a-field of the Borel subsets
of R+) and locally bounded in the sense that for all T > 0, its restriction to [0, T] x E
is bounded.
Next we need to define the E-valued time-inhomogeneous Markov process X arising in the right hand side of (4). In our settings the more efficient and convenient way
seems to be in terms of a martingale problem (cf for a general reference), since
our method will be largely based on properties of martingales (as it was already true
for discrete time, so the set-up we are now presenting is quite a natural generalization
of the previous one):
For t > 0, let D([t,
E) be the set of all càdlàg paths from [t,
We denote by
the process of canonical coordinates on D([t,
generates on this space the a-algebra
s > t). We will also use as
customary the notation Dt,s = a(Xu
: t u s), for 0 t s.
Let A be a dense sub-algebra of Cb(E) which is supposed to contain I (that is the
function taking everywhere the value 1).
A linear operator Lo from the domain A to Cb(E) will be called a pregenerator, if
for all x E E, there exists a probability
on (D([0, +oo[, E), Ðo,+oo) such that
= ~~, the Dirac mass in x, and
. for all (/? E A, the process
(03C6(Xs)-03C6(X0)s0 L0(03C6)(Xu)
is a (D0,s)s~0-martingale
be a measurable family of pregenerators: for each t ~ 0, Lt .
Cb(E) is a pregenerator, and for each 03C6 E A fixed,
£-measurable. For the sake of simplicity, we will furthermore impose that
the above function is locally bounded.
Our first hypothesis is
For all (t, x) E l~+ x E, there exists a unique probability
(D([t, +oo[, E),
) such that
w Xt o IPt,x = 6r, and
2022 for all p E A, the process
(03C6(Xs)-03C6(Xt)-st Lu(03C6)(Xu)du)s~t
is a (Dt,s)s~t-martingale
under Pt,x.
Furthermore, it is assumed that for all A E Ðo,+oo,
, the mapping
is measurable (where
denotes the family of usual time shifts on
Combining the measurability and the uniqueness assumption (HI), one can check
is a strong Markov process (this uniqueness condition will only be needed here, so it
can be removed if we rather suppose that the previous object is a Markov process).
One can also define a probability
on (D([0, +oo[, E) Vo,+oo), for any distribution
rlo E Mi(E), by
P~0(A) = EP0,x(A)~0(dx)
which is easily seen to be the unique solution to the martingale problem associated
to (Lt)t>o whose initial law is r~o (from now on,
will stand for the expectation
relative to 1~~, the probability
Mi(E) being fixed).
The previous martingale problem can be extended to a time-space version as follows :
Let A be the set of absolutely continuous functions 9
: R+ - R with bounded
derivative in the sense that there exists a bounded measurable function g’ :
such that for all t ~ 0,
g(t) = g(0) + t0 g’(s) ds
On A ~ A, we define the operator L given on functions of the form f = g ~ 03C6,
with g ~ A and 03C6 ~ A, by
L(f)(t, x)
+ 9(t)LtU)(x)
Then we have the standard result:
Lemma 3.1 Let (t, x) E R+ x E be fixed. Under
for each f E A®,A, the process
defined by
~s~t, Ms(f) = f(s,Xs)-f(t,Xt)-st L(f)(u,Xu)du
is a square integrable martingale and its increasing process has the form
where r is the "carre du champ" bilinear operator associated to the pregenerator L
and defined by
r (f ~ 9) -
We can consider, for s > 0, the "carre du champ" bilinear operator rs associated
to the pregenerator Ls , which is naturally defined by
rs (~~ ~) -
We easily see that for all f , g E A Q9 A,
r(f ~ 9)(s~ x) - rs (f (s~ ~)~ 9(s~ )) (x)
In Lemma 3.1, the fact that A Q9 A is an algebra is crucial in order to describe the
increasing process. But the domain A Q9 A is rather too small for our purposes. We
extend it in the following way: for T > 0 fixed, we denote by ~3b(~0, T] x E) the set of
all measurable bounded functions f
: [0, T] x E -~ R and by BT the vector space of
applications f E
T] x E) for which there exists a function L(f) E
such that the process (Mt(f))0~t~T defined by
~ 0~t ~ T,
Mt(f) = f(t,Xt)-f(0,X0)t0 L(f)(s,Xs)ds
is a P~0-martingale.
In this article and unless otherwise stated, all martingales will be implicitly assumed to be cadlag (a.s.). Note that those coming from (Hl) or from Lemma 3.1 are
automatically cadlag. Let us furthermore introduce AT the subset of function f E BT
for which there exists a non-negative mapping r(f, f) E Bb( [0, T] x E) such that the
increasing process associated with (Mt(f))0~t~T has the form
Remark that L(f) and 0393(f,f) may not be uniquely defined by f E .AT (but we
will keep abusing of these notations), nevertheless this is not really important, since
for martingale problems, one can consider multi-valued operators, cf .
Next we will need some regularity conditions on the function U and the family of
probability measures
. These are expressed in the following assumption
(in the subsection 3.1.2, we will give separate and stronger hypotheses on U and
which insure that (H2) is satisfied):
For all T > 0
03C6 ~ A fixed, the application
belongs to AT
We notice that
satisfies almost surely the first assumption hidden in (H2),
To see this claim let us denote for any T > 0 and
E A fixed,
The Markov property of X implies that the process
defined by
~ 0~t ~ T,
exp(t0Us(Xs)ds)
Nt(T, 03C6)
= E~0 [exp (T0Us(Xs)ds)03C6(XT)|D0,t]
is a martingale. So we have
Nt(T,03C6)
Us(Xs)ds)t
= N0(T, 03C6) +t0
Uu(Xu) du)
-t0Us(Xs)Ns(T,03C6)ds
from which it follows that
- N0(T,03C6) +t0Us(Xs)Ns(T
is a martingale. Note that it is not necessarily cadlag, and this could be annoying for
some calculations afterwards (in (95) there was already a little difficulty, nevertheless
it is possible to consider there a cadlag modification, and end up with the fact that
is a (contingently non-cadlag) martingale). If (H2) is fulfilled, a classical
uniqueness argument for semimartingale expansion will show that
surely cadlag. Thus, we can take
V 0 t T, V x E E,
In addition if the mapping FT,~ defined in (94) belongs to AT 0 A, where AT is
the set of restrictions to [0, T] of functions from A, then we conclude that one can
(where the action of r on (AT Q9 A)2 is defined similarly as the one on (A Q9 .A)2).
But our setting is too weak to insure this property, leading us to make the assumption (H2), which will serve as an ersatz.
One way to check this condition is to follow the procedure given below:
Lemma 3.2 Let f E BT such that there exists a sequence ( fn)n~o of elements of
AT Q9 A satisfying, as n and m tend to infinity, fn ~ f and
- fm~ fn - fm) ~ O~
where ~ stands for the bounded pointwise convergence on ~O,T~ x E, and
° ) ll +°°
Then we have that f E AT.
Proof: By dominated convergence, we obtain that
lim ~o LBMBfn
in other words
It is now quite standard to deduce from this Cauchy convergence that there exists a
martingale
(that we can choose cadlag) such that
[ sup (Mt(fn)-Mt)2]
Since for any 0 t T fn(t, Xt) - fn(0, Xo) converges in L2(P~0) to f (t, Xt) f(0, X0) as n ~ ~
one concludes that
t0L(fn)(s,Xs)dst0L(f)(s,Xs)ds
converges in L2(P~0)
- Mt = f(t,Xt)
-f(0,X0)-t0L(f)(s,Xs)ds-
This shows that the latter process (for 0 ~ t ~ T) is predictable, as a limit of
predictable processes, and we already know that it is also a martingale. Furthermore,
from our hypotheses, there exists a finite constant CT > 0, such that for all n ~ N
|L(fn)(s,Xs) ds - t2t1 L(f)(s,
so in the end (considering a subsequence), (Mt(f) - Mt)t~0 will also be of bounded
variations. It is now well known that up to an evanescent set, it is the null process,
= (Mt(f ))otT.
On the other hand since Ls is a pregenerator, for any s > 0, then rs satisfies
b’ cp E ,~4, b’ x E E,
(see (98) below).
This implies that
V n, ~n > 0, V ( s, x ) E ~0, T x E,
|0393(fn,fn)(s,x)-0393(fm,fm)(s,x)
Therefore there exists a function T ( f , f )
: [0, T] x E -~ 1~+ such that
r(fn~ fn) ~
as n tends to infinity.
Again using convergence theorems (but now in
one obtains that
(M2t(f)-t0
0393(f,f)(s,Xs)ds)0~t~T
is a martingale.
Remark 3.3:
(a) In the hypothesis f E BT of the previous lemma, we don’t really need to assume
that (Mt( f ))otT is càdlàg, since the equality (Mt( f ))otT = (Mt)0~t~T insures this
(b) The result is also true if instead of assuming that f n E AT ® A, we rather
suppose that fn fn
- f m E AT, for n, m > 0, and that (97) is satisfied with r replaced
by h (the other hypotheses remaining the same, for instance ) ) L( fn)(t, ~ ) II is uniformly
bounded in 0 t T and n
Example 3.4
Assume that E is
for some n E N* and A contains at least all C2 functions
with compact support and that the Lt, t > 0, are second order differential operators
(without 0-order terms) with locally bounded coefficients (in time but uniformly in
Then Lemma 3.2 shows that AT contains at least all
functions.
This approach is a little more f lexible that the one using only stochastic calculus (to
see that at least in case there is only continuous martingales (as in a Brownian filtration~, AT is stable by composition with C2 functions, in the sense that if f 1, f 2, ~ ~ ~ , f p
belongs to AT and if F E
then F( f l, f2, ~ ~ ~ , f p) belongs to .AT~.
Using a classical embedding theorem the same results are also true for smooth separable
manifolds.
Let us observe that if f E ,AT, then the process given by
(f2(t,xt)-f2(0,X0)-t0[0393(f,f)(s,Xs)
+2f(s,Xs)L(f)(s,Xs)]
is also a martingale.
To see this claim we use the following decomposition (for 0 t T)
= f2(t,Xt) -
-2f(t, Xt)t0L(f)(s,
Xs) ds + 2f(0, X0)Mt(f)
- f2(0, X0)- 2
t0f(s,Xs)L(f)(s,
Xs) ds + 2f(0,X0)Mt(f)
t0(s0L(f)(u,Xu)du)
where the last equality comes from an integration by parts (this is also the proof of the
second part of Lemma 3.1). In other words this means that if f E ,AT, then f 2 E BT,
and we can take Z(/~) = P(/,/) + 2/Z(/).
If we look at (BT, L) as an (contingently multi-valued) linear operator, then
is also the solution to the time-space martingale problem associated with the initial
condition r~o and to (BT, L).
Finally, let us mention other properties of a pregenerator Lo which will be useful
latter on. If ro and
are respectively the "carre du champs" and solutions of
the martingale problems associated with Lo, then we have for all p E A and x E E,
03930(03C6,03C6)(x) =
limPx[(03C6(Xt)-03C6(x))2 t
It follows that if 03C6, 03C6 ~ A and f ~ AT ~ A, then we have that
~~ro(~~ ~)~~ ~
and for all x E E,
03930 (T0 f(s,.) ds,T0 f(s,.) ds) (x) ~ TT003930(f(s,.), f(s,.))(x) ds
3.1.2 Strong Regularity Assumptions
The hypotheses introduced below are not strictly necessary for the results presented
in the following sections, but they are often the shortest way to check condition (H2),
at least in abstract setting (ie not in the cases of example 3.4), so maybe this section
should be skipped at a first reading. More precisely, they allow for an understanding
of the latter hypothesis, by separating the roles of U and several aspects of regularity
for the semigroup associated to X.
To make a clear differentiation, each of them has been associated to a hypothesis
below. Thus the strong regularity assumption consists in the set of the following conditions (H4)T, (H7)T, (H8)T, (H9)T and (H10)T, the other ones are only intermediate
steps. Furthermore the considerations presented here are more or less standard in
the so-called semi group approach to the theory of Markov processes, and they will
enable us to give more tractable expressions for some norms arising in the study of
exponential bounds presented in section 3.3.3.
The time inhomogeneous semigroup associated with the Markov process (91) is
the family
of operators on Bb(E) defined by
V 0 s t, V p E
For T > 0 which will be supposed fixed in this subsection, we consider the following
set of strong hypotheses:
There exists a constant C1,T > 1 such that for all 0 t T,
in the sense that for all c~ E A and all x E E,
Let us define a norm III
(II on A by
~ 03C6 ~ A,
+ ~03930(03C6,03C6)~
For all 0 t T, we have Ut E A, and the application
] ~ t ~ Ut E A
is continuous with respect to III
s t T, A is stable by Ps,t, and for ~ E A and
0 t T fixed, the mappings
[0, t] ~ s H Ps,t(cp) E A
[t, T] ~ s ~
are continuous with respect to III
t T, A is stable by Ps,t, and there exists a
constant C2,T > 1 such that for all 0 s t T and all c~ E ~4,
s t T, ,A is stable by Ps,t, and for all c~ E ,A,
there is a fanite constant C3,T(03C6) > 0 such that for all 0 ~ s, t ~ T,
s t T, ,,4 is stable by Ps,t, and we have in the
~~~ sense, on ,~,
d dt Ps, t
= Ps, t Lt
For aII ~o E ~4, (O, T~ ~ t H
~) is differentiable (in the sense
of the norm ~) ~ ~~), and there exists a finite constant C4,T > 0 such that for
ali0tT and
(where at stands for
If ,A is stable by Lt, for a given t > 0, we can define for ~, cp E ,A,
, ( ~) - 2(
We are now in position to introduce our last assumption:
For alt 0 t T, ,A is stable by Lt, and there exists a constant
RT E I~ such that for aII cp E ,~l and x E E,
(RT will then denote the best constant possible verifying this property,
i.e. the largest one).
Before studying several links between these hypotheses and (H2)T (which corresponds to (H2) for aT> 0 fixed), let us introduce B(T, ,A) the set of f E
such that for all 0 t T, f (t, ~ ) E ,A and such that
f[0,T] def.
sup f(t,.) +~
This quantity is a norm on B(T, ,A), and we will note
the semi-norm ~~~ f (t, ~ ) ~~~,
for any 0 t T and f E B(T, ,A).
In much the same way let
- ~ f (t, ’ ) (~ and denote
~~f (~~o,T~
Our first remark is:
Lemma 3.5 Under (H3~T , (H5)T and (H7)T, for all p E A, the mapping
belongs to AT (the continuity in the first variable is only necessary in (H5)T).
Proof: For each n E N we introduce the functions f n E AT ® A defined by
’d0tT,bxEE,
(1+k-(+n)t T)
PkT 1+n,T(03C6)(x)+((1+n)t Tk)P(1+k)T 1+n
,T(03C6)(x)
where k = l(n +
Clearly, under (H5)T we have that
E B(T, A) and
lim GT,03C6- fn
By Lemma 3.2 and condition (H3)T, to prove the announced result, it remains to
To this end we first notice that for any 0 t T and x E E
L(fn)(t,x) = 1+n T(P(1+h)T 1+n,T(03C6)(x)-PkT 1+n,T(03C6)(x
+((1+n)t Tk)Lt[P(1+k)T 1+n,T(03C6)](x)
where k is defined as above. Therefore, in view of (H7)T, to see the previous affirmation, we only need to check that
P 1+k T ~~ -
To see this claim it is sufficient to write, for all x E E,
P ~ +nT,T(4~)(x) -
= EkT 1+n,x [P(1+k)T 1+n,T(03C6)(x) -P(1+k)T 1+n ,T(03C6)(X(1+k)T 1+n )]
= -EkT 1+n,
(k+1)T 1+nkT 1+n
Ls(P(1+k)T 1+n,T(03C6))(Xs)ds]
We consider next the collection
of linear operator on Bb(E) defined for
E,asfollows
Qs,t(03C6)(x) =
[exp(tsUu(Xu)du)03C6(Xt)]
It is easily seen that (Qs,t)oSt is a well defined time inhomogeneous semigroup of
non-negative operators on
(but in general non-Markovian, except in the trivial
case where U = 0, ie (Qs,t)ost = (Ps,t)oSt).
To see that Lemma 3.5 is also true for
, under the additional conditions
(H4)T and (H6)T, let us work out a relation between
and (Qs,t)ost:
Taking t = T in (9~) and integrating the above equality with respect to
obtain (in fact for all cp E
- Pa,T(SP)(x) + /
More generally and in the same way one can prove that for any 0 t T,
This identity leads us to consider, for c~ E ,A fixed, the application Z defined on
~b([0? TJ X E) bY
z(f )(t~ x)
- ~’t,T(~)(x) + /
’ ))(x) ds
Under (H4)T there exists a constant
> 0 such that
jj z( /~ )
_ z( /~ ) jj
jj /~ _ /~ jj
Z(f2)~t ~ C(1)T
Let Z’~ = Z o ... o Z (n-times) be the n-step iterate of Z. It is standard to check that
d fla f2 E ~b([a~
This implies that
.,T(cp)( ~ ) is the unique solution of the equation Z( f ) _
f , with f E ~ib([0, TJ x E).
Another useful remark is that elementary calculations show that for any f E
~b([O~ TJ X E)
(Z(f)(t,Xt)
t0Ps,T(Usf(s,
. ))(Xs) ds) 0~t~T
is a martingale (the càdlàg property comes from (H5)T). This means that one can
d 0 t T, ‘d x E E,
L(Z(f ))(ta x)
Proposition 3.6 Under conditions (H3)T, (H4)T, (H5)T,
(H6)T and (H7)T, assumption (H2)T holds, and there exists a finite constant
> 0, such that for all 03C6 E ,A,
FT,03C6[0,T]~
Proof: Let B(T, A) denote the Banach space which is the III
. [0,T]-completion
of AT 0 A. Note that if f E B(T, ,A), then we can naturally associate to it numbers
for 0 t T, and as above
III.f IIIt’ In the same way, as the
dominates (I ’
to each f E B(T, A) we associate a measurable
bounded function f
~ x E -~ R (we will occasionally abuse notation, saying that f E B(T, A), and also note that we can associate to f another measurable
bounded function which could be in an obvious way written ro( f, 1)). In view of the
Lemma 3.2 and (H3)T, if it wasn’t for the boundedness condition on the (L( fn))nEN,
such a function f would have a good chance to belong to AT. We will use this procedure here to show the belonging of
to AT, but rather taking into account the
remark after Lemma 3.2 and (100).
From now on we consider the restriction of Z to AT0A. We slight abuse notations
and still denote Z these restrictions. Using approximations techniques (as the one
presented in the proof of Lemma 3.5), the remarks at the end of section 3.1.1 and
the hypothesis (H6)T, it is easily seen that Z( f ) E B(T, A), for f E AT ® A. More
precisely, Z can be extended to B(T, A) and one can find a finite constant
depending on C2,T and IIIUIII[o,T] and such that for any f l, f 2 E B(T, A) and 0 t T
Then proceeding as above, it appears that for all n > 1,
~B(T,A), Zn(f1)-Zn(f2)2[0,T]
(C(3)TT)n n!
As a result there is a unique solution denoted by
to the equation
with f E B(T, A). Its corresponding bounded measurable function is clearly
Furthermore,
is classically shown to be the limit in B(T, A) of
for n large.
By Lemma 3.2, to be convinced that
E AT, it remains to prove that
sup~L(Zn(0))~[0,T] +~
but the remark before the proposition shows that this is a consequence of
which itself follows from the considerations above the proposition.
The last part of this proposition is now clear from the previous approximations.
Remark 3.7: In practice it may be important to know the dependence of CT2)
on U. Using the above proof we first observe that
is a finite constant which does not depend on U.
Therefore for any n E N* and
B(T, A) we have that
Zn(f1)-Zn(f2)[0,T] ~ f1
where we have use the Stirling formula to find a finite constant C > 0 such that for
makes it clear that there exist two finite constants CT5~,
> 0 such that
In the end, we have
Proposition 3.8 The conditions (H8)T., (H9)T and
implies (H3)T, (H5)T
For a proof of this result and more discussions on the curvature hypothesis (H10)T,
Remarks 3.9:
a) We believe that the hypothesis (H7)T is not natural here, and we would have
preferred to work only with closures related to functions and their carres du champs.
Nevertheless, note that if there is a finite constant C5,T > 0 such that for all 03C6 E A
~Lt(03C6)-Ls(03C6) ~ ~ C5,T03C6
(as it is the case in our applications to nonlinear filtering, cf. section 4.2), and if the
right hand side of the first equation in (H8)T is II. [[-continuous, then (H7)T is satisfied.
b) In view of the generality of our setting, the reader may wondering why we have
not only considered the time-homogeneous case, by adding the time as a coordinate
of the Markov process. The corresponding generator on the state space R+ x E is L
acting on A Q9 A. But in general U does not belong to this domain, since typically
in our applications to nonlinear filtering U will not be differentiable with respect to
time (only a regularity of Holder exponent less than 1/2 can be expected). So the
hypothesis (H4)T will not be verified in this context, giving one reason for which it
seems interesting to us to separate the role of time.
Nevertheless, note that a way to get round this particular difficulty would be to
complete A (or A Q9 A in the homogeneous case) with respect to [][ ~~~.
3.1.3 Asymptotic Stability
In this section we take up the study of the asymptotic stability of the limiting process
q = {r~t ; t > 0~ which was begun in section 2.1.2 in discrete time settings. Before
getting into the details we first need to make a few general observations and give
some definitions. We retain notations of section 2.1.2 and we denote a(H) and
the contraction and Dobrushin ergodic coefficients associated with a given transition
probability kernel H on E and given by (25) and (24).
Next we denote ~ _
; s t} the nonlinear semigroup in distribution space
associated with the dynamics structure of r~, namely
One can check that each mapping
t, has the following handy form given
for any r~ E Mi(E) and for any bounded Borel function f on E by
03A6s,t(~)(f)=~(Hs,t(f)) ~(Hs,t(1))
Hs,t(f)(x) IEs,x
(f(Xt) Zs,t)
exp (ts Ur(Xr) dr)
As in the discrete time case there is a simple trick which allows to connect the
nonlinear semigroup ~ with a family of linear semigroups.
Lemma 3.10 For any s t and u E M1 (E) we have the following decomposition
where the mapping Ws,t : M1(E) --~ M1(E) is defined by
03A8s,t( )(f)= (gs,tf) (gs,t)
gs,t Hs,t1
and for any t ~ 0, H(t)
= {H(t)s,r
; s ~ r ~ t} is a linear semigroup defined for any
f ~ Bb(E) and ~ M1(E) and s ~ r ~ t by
H(t)s,rf = E (dx)H(t)s,rf(x)
=Hs,r(gr,t f) Hs,r(gr,t
Remark 3.11 : By construction and using the Markov property of X it is easy to
see that the transition kernels
s r ~ may likewise be defined for any
bounded Borel function f by setting
~x~E, H(t)s,rf(x) = Es,x(f(Xr)Zs,t) Es,x(Zs,t)
As in discrete time settings the asymptotic stability properties of 03A6 can now be characterized in terms of the contraction coefficient of the linear semigroups {~~ ;
Lemma 3.12 For any s t we have that
where the supremum is taken over all distributions
On the basis of the definition of H it is now easy to establish that for any f ~
~ ~ and any s r ~
Recalling the definition of the ergodic coefficient a(K) of a given transition probability kernel
on E the above formula yields that for any s r ~
a (~) exp -(f
dT) a (~) a (~) exp (~
e For any t > 0, osc(Ut) ~’
(~) ~ E~}.
e For any t > 0,
r} is a collection of transition probability
functions on E and defined for any bounded Borel function f by
Using the semigroup property of ~f~, by definition of the ergodic and the contraction coefficients a(K) and
of a transition probability kernel K on E one proves
the following result.
Proposition 3.13 For
r ~ we have
where for any v > 0 and s r ~ Iv( s, r) is the subset o/R+ defined by Iv( s, r) ~=’
2014 ~)/~]} with [a] the integer part of a ~ R.
If U is chosen so that
osc*(U) def
~0 osc(Ut)
then by definition of
one gets the inequalities
t, 03B1(Ps,r)e-osc*(U)
~ 03B1(S(t)s,r)
~ 03B1(Ps,r)eosc*(U)
from which one concludes that
Theorem 3.14 If the function U satisfies (102) then for any v > 0 the following
implications hold
F lim Q (H)~/) = 0
lim sup log Q (H)~/) - "~~’~
In addition, if inf|t-s|=v a (Ps,t) def. &#x26;(v) for some v > 0 then for any p > i and
. v we have that
log~03A6t,t+T()-03A6t,t+T(03BD)
(v) q.v e-2osc*(U)
Next we examine an additional sufficient condition for the asymptotic stability of
O in terms of the mixing properties of P = (Ps,t ; s t). Assume that the semigroup
P satisfies the following condition.
(P) There exists some v > 0 such that for any t > 0
for some positive constant et(v) > 0 and some reference probability measure
The main simplification due to condition (P) is the following: for any non-negative
test function f we clearly have for any 0 s s + v t
~S(~’) wS+V,t(»(f) ~
~ 67~(~’) wS+V,t(»(f)
This implies that a
> es (v) from which one can prove the following theorem.
Theorem 3.15 Assume that the semigroup P satisfies condition (P) for some constants v > 0, et(v) > 0 and some reference probability measure pt,v e Mi(E). If the
function U is such that
[[osc(U) [[ ~%° sup osc(Ut) cxJ
then for any v > 0 the following implications hold
~nv (v) = ~ ~ lim 03B2 (H(t)0,t)
lim ~kv(v) def
~(v) ~ lim sup 1 t log03B2(H(t)0,t)
- ~(v) ve-v.~osc(U)~
In addition, if inft~0 Et(v) def. (v) for some v > 0 then for any p > 1 and T > p. v we
sup sup 1 T
log~03A6t,t+T()-03A6t,t+T(03BD)~tx
(v) q.ve-v.~osc(U)~
for any p, q > 1 such that 1/p + 1/q =1.
In time homogeneous settings several examples of semigroups P satisfying condition (~) can be found in ~9~ and in ~27~. For instance if X is a sufficiently regular
diffusion on a compact manifold then (~) holds with
Et(v) = E(v) = A exp -(Bw)
for some constants 0 A, B oo and for the uniform Riemannian measure
on the manifold. To illustrate our result let us examine the situation in which U is
also time-homogeneous, that is Ut = U.
Corollary 3.16 Assume that U is time-homogeneous and the semigroup of X satisfies condition (~) with Et(v) = E(v) given by (~03~. Then for any p > 1 and v > 0
. v we have that
,03BD~M1 (E)
B v + v. osc( U))
1 p + 1 q =1
A q v exp-(B v + v
1 p +1 q = 1
The best bound in term of the constants A, Band osc( U) is obtained for
+ 4B osc(U)
The above asymptotic stability study can be extended in a simple way, but this is
outside the scope of these notes, to study stability properties of the nonlinear filtering
equation and its robust version. The interested reader is recommended to consult ~43~.
3.2 The Interacting Particle System Model
The purpose of this section is to design an IPS
(~t)t>0 ~ (~t ~ ~t , ~ .. ~ ~N)t>0
taking values in EN, where N > 1 is the number of particles and such that for any
t > 0, the empirical measures given by
~Nt(.) = 1 N 03B403BEit(.)
are good approximations of
t > 0, for N large enough.
As announced in the introduction, the Markov process
will also be defined
by a martingale problem. At this point it is convenient to give a more detailed
description of its pregenerators which was already presented in (15). At time t > 0,
the pregenerator
of the IPS will be of genetic type in the sense that it is defined
as the sum of two pregenerators, namely
~ The first pregenerator
is called the mutation pregenerator, it denotes
the pregenerator at time t coming from N-independent processes having the same
evolution as X and it is given on A@N by
~iNl(~) - ~
denotes the action of Lt on the i-th variable x~, that is
L(i)t= Id ~
... ~~... ~ Id,
where Id is the identity operator.
~ The second one is denoted by
and it is called the selection pregenerator.
It is defined as the jump type generator defined for any 03C6 E
x = (x1, ...,xN)
(N)t(03C6)(x) = 1 N
(03C6(xi,j)
-03C6(x))Ut(xj)
where for 1 i,j N and x = (:ri,’’ -, z N) E EN,
is the element of EN given by
~1~k~N, xi,jk = xk , if k~i
, if k = i
(this is meaningful for all functions 03C6 E Bb(EN), and in fact (N)t is a bounded
generator on
Heuristically the motion of the particles (~t)t>_o is decomposed into the two following rules.
Between the jumps due to interaction between particles, each particle evolves independently from the others and randomly according to the time-inhomogeneous semigroup
At some random times, say T, we introduce a competitive interaction between the
particles, during this stage a given particle will be replaced by a new particle ~T,
1 j N, with a probability proportional to its "adaptation"
This mechanism is similar to the one of a Moran IPS, except in the form of
the intensity of replacing by ($ (which should be symmetric in these variables)
and in the total jump rate which is here "proportional" to N (instead of
fact that renormalization shows that our Moran’s type IPS can also be regarded as
a Nanbu’s type interacting particle approximating model for a simple generalized
spatially homogeneous Boltzmann equation.
There is no real difficulty to construct a probability IP (on D([0, +oo[, EN)) which
is solution to the martingale problem associated with the initial distribution
and to the time-inhomogeneous family of pregenerators
More precisely,
we proceed in two steps: we first consider the product process on EN corresponding
to the family of pregenerators
and to the initial distribution
quite immediate and the N coordinates are independent and have the same law as X
starting from r~o (cf for instance the Theorem 10.1 p. 253 of ). Then, for all t > 0,
is just seen as a bounded perturbation of
by ,C~N}. So we can apply general
results about this kind of martingale problems, see the Proposition 10.2 p. 256 of .
From now on, E will designate the expectation relative to the process = ~~t ; t >
0~ under P.
For more information about how to construct and simulate this process, see section
3 of .
In fact, the law P of the particle system ( satisfies a more extended martingale
problem, since the proofs presented by Ethier and Kurtz enable us to transpose
the whole pregenerator (BT, L) considered in the section 3.1.1:
Let us denote by BT,N the vector sub-space of
generated by the
functions f :
: [0, T x EN ~ l~ such that there exist f l, ~ ~ ~ fN E BT for which we
d t E [0, T ]a d x = (xi, ~ .. ~ xN) E EN,
If such a function f is given, we define for all (t, x) E [0, T] x E,
~~N}(.~)(t~ ~~
... f$-1(t~ x~_1)L(f~)(t~
and then we extend linearly this (contingently multi-valued) operator
We also need to consider the pregenerator
T] x EN) in the
following way:
T] x EN), V ( t, x ) E [0, T] x E,
’~(N)(f )tt~ ~) -
and next we introduce on
,C(N) _ ,C(N) + ,C(N)
This pregenerator coincides naturally with 8t +
Lemma 3.17 Under P, for all T > 0 and all f E BT,N, the process
defined by
= f(t,03BEt)-f(0,03BE0)t0 L(N)(f)(s,03B6s)ds
is a bounded martingale.
Now let AT,N be the set of all f E BT,N for which 12 E
With some obvious
notations for such functions we can define
r(N)(/, ~ ,f )
~(N)( f2) _ ~ ~’~(N)(f
Then an easy calculation we have already met several times shows that
Lemma 3.18 For any f E AT,N, the increasing process associated to the martingale
(M(N)t(f))0~t~T is given by the formula
Next we will apply this result to some special functions, for which x E EN is seen
only through its empirical measure
axi, and more precisely to
mappings f of the following type
V (t, x) E [0, T] x EN~
where f E AT, since clearly such a function f belongs to AT,N.
3.3 Asymptotic Behavior
An important role will be played here by the unnormalized Feynman-Kac stochastic
flow defined in (18). In all this section, the finite horizon T > 0 and the initial
condition r~o are fixed.
3.3.1 Weak Propagation of Chaos
Our objective is to prove the following result, which somehow gives a justification for
the interacting particle system just introduced:
Theorem 3.19 Under the assumption (H2)T, there exists a finite constant CT > 0,
such that for all p E Bb(E) and all 0 t T,
E[|~Nt(03C6)-~t(03C6)|] ~ CT~03C6~ N
The basic idea behind the proof of this result is quite simple: it consists in finding
a martingale indexed by the interval [0, T] whose terminal value at time T is precisely
for any given ~p E A. The reader may be wondering why this quantity and
not directly
The reason for this choice is that for the unnormalized Feynman-
Kac stochastic flow, we can take advantage of the underlying linear structure of the
limiting dynamical system
(ie of the relation
) _ ’ys(Qs,t( ~ )) valid for all
t > s > 0). As we will see, there is then a straight way to find such a martingale, via
the martingale problem satisfied by the law of the particle system, but naturally we
have to use the semigroup (Qs,t)ost considered above. All the calculations would be
immediate if one can use the heuristic formula
(in the usual regular cases, this is satisfied, and maybe that at a first reading one
should concentrate on these situations... ). To treat the little difficulties associated
to the general case, we consider this equation in the sense of the martingale problem.
This point of view led us to introduce the weak regularity condition (H2), insuring
that some functions constructed through the semigroup (Qs,t)ost are in the domain
of an extended pregenerator.
Another important aspect of the martingales we will consider is that they are quite
small, in the sense that their increasing process will be of order 1/N. Then taking
into account some results about iid random variables in order to estimate the initial
approximation at time 0, the expected convergence will follow easily for the unnormalized Feynman-Kac formulae (and there will be no problem with the renormalization,
so we will also end up with the convergence of the empirical measure toward the normalized Feynman-Kac formulae).
Furthermore, this approach gives at once the central limit theorem and exponential
bounds for the fluctuations.
So from now on, we will look for nice martingales, through calculations of the action
of the pregenerators on convenient functions, and (H2)T will be assumed fulfilled.
Lemma 3.20 For any p E A, the process
def.(~Nt(Qt,T(03C6))
- ~N0(Q0,T(03C6))
+t0~Ns(Us)~Ns(Qs,T(03C6))
is a martingale and its increasing process is given by
where for any 0 s T, m E M1(E) and c~ E ,A,
G(s, T, m, c~)
Proof: Applying Lemma 3.1? and Lemma 3.18 to the function
~ (t, x) H
it appears easily that
~~N~(f )(t~ x)
~~ ~(f )(t~ x) -
and the proof of the first assertion is now complete.
For the second one, calculations are a little more tedious, but in the end, we get
N),~N~(f )(t~ x) =
In view of the above lemma to find a good upper bound of
tempting to introduce the norm on ,A defined for any 03C6 E ,A by
~FT,03C6(t,. )~2
+~F(FT,03C6,FT,03C6)(t,.
(more rigorously, the infimum over all possible choices of
FT,~) of this quantities) . Using the considerations of section 3.1.2 we see that this norm is clearly related
Next result shows that the above choice is in fact far from being optimal.
Lemma 3.21 There exists a finite constant CT > 0, such that for all c~ E ,A,
Proof: Let us write that for the function f defined in (104),
d (t, x ) E ~0, T ~ x
- ~~N~(xUL(~2,T(4~))(t~
~,T(4~))(t~
- m~N~(~)LL(Q2,T(~))(t~ ’ )1 +
If we define
’ ~O, T~ x
~ (t, x) H ~n~N~(x)[~t,T(~P)~
’~~N~(9)(t~ x)
.f)(t~ x) - ~~N}(g)(t~ x) +
- ~~N}(9)(t~ x) - ~~N}(9)(t~ x) +
_ ~~N~(9)(t~ x) +
+ ~~N~(x)[~t)m~N}(x)[~t T(~)l
and finally one gets
~ .f )(t~ x)
- ~~N~(9)(t~ x) +
This implies that
# E ~~ r~N~(.f~ f)(t~ ~t) dt
- ~ ~T [~T,T(~P)~
- ~0 [’~O,T(~P)~ +
- 2~N[~t‘~t~T(~)l~N[~t~T(~)l + 2~N[Utl ~N[‘~t,T(~)~ dt
and the desired upper bound is now clear.
As announced, it is preferable to first obtain a result similar to Theorem 3.19 for
Proposition 3.22 There exists a finite constant CT > 0, such that for any cp E ,A
and 0 ~ t ~ T,
E[|03B3Nt(03C6)-03B3t(03C6)
~ T ~03C6~ N
Proof: By construction, for any 03C6 ~ A, we have that
03B3Nt(03C6)
= exp(t0~Ns(Us)
ds)~Nt(03C6)
By Lemma 3.20 it follows that for 0 t T,
Nt(03C6)= t0 exp (s0~Nu(Uu)
du) dBNs(03C6)
is a martingale. Its increasing process is clearly given for any 0 t T by
exp (2s0~Nu(Uu)du)
T,~Ns,Qs,T(03C6))ds
for a finite constant CT > 0 which does not depend on 03C6 (but it depends on U,
Recalling that
one concludes that
~‘T (~) - yT (~) - ~’~ (‘~o~T(~)) -’~~(’~~~T(~)) +
from which one gets that
~~(~YT (~P) ’- ~YT(~P))Z~ -
(‘~O,TI~P)) - ~YO(’~O~T(~P)))2~ + ~~($T )2(~P)J
Now the result follows, via a Cauchy-Schwarz inequality, from
~~(BT )2(~)~ -
and from the classical equality for iid variables:
~ exp(2T ~U~[0,T]) ~03C6~2 N
Proof of Theorem 3.19 : First let us prove that the upper bound of the previous
proposition is true for any cp E Bb(E). By density of A in Cb(E), that is at least clear
for all 03C6 ~ Cb(E). Next let 03C6 ~ Bb(E) be fixed. We have
be given with
1. Then the following formula
~Bb(E), mH() def. E[H(03B3Nt()-03B3t())]
defines a measure m H G M(E).
But a classical approximation result says that there exists a sequence
elements ofCb(E), with
for all n ~ N, such that
Putting together these facts, (106) is satisfied for all (/? ~ Bb( E).
Now it is enough to write that for all (/? ~ A,
201420142014 [~) -
+ ~)(~(!) - ~(1))]
Theorem 3.19 can be improved. As a first step in this direction, let us come back
to the martingale
for a given ~ ~ A, and study its jumps:
Lemma 3.23 There exists a finite constant C(7)T > 0 such that
sup )A~)j ~ 4~
Proof: From the definition of
we see that this upper bound would be
clear if we could show that P-a.s., the coordinates of the RN-valued process
((~(~)(~))~..~)~
never jump together.
From the construction of P (cf for more details), it is sufficient to prove this
property for the process ( which is just the product of N independent copies of X
(starting from the distribution ~o). So it is in fact enough to convince oneself that the
jumps of the martingale
(under P~) are totally
inaccessible, but this is a consequence of the continuity of its increasing process.
A similar statement holds for
Lemma 3.24 For any p > 0, there exists a finite constant C(8)T,p > 0, which does not
depend on p and such that
Nt(03C6)|p]1/p ~ C(8)T,p~03C6~ N
Proof: By Holder inequality, we only need to prove this result for p = 2q, with
q E N*, and we will proceed by an induction on q. We have already shown the case
q = 1, so let q ~ N B {0,1} be given. Applying the Itô’s formula for the mapping
we get (writing
for simplicity) for 0 ~ T,
+ q(2q - 1) /’ ~-’
+ ~ ~~ - ~ -
where B~ is the continuous martingale part of B.
But quite obviously, there exists a finite constant Cq > 0 depending only on q > 2
and such that for any 0 s T,
- 2q2q-1s-0394s
~ Cq(2q-2s
+(0394s)2q-2)0394B2s
Using the previous lemma and the general fact that
is a martingale, one can find a finite constant CT,p > 0 such that
Now the desired result follows from the bounds on (B) we have already met in the
proof of Proposition 3.22 and from the induction hypothesis (after an appropriate
application of Fatou’s Lemma).
A consequence of these preliminary results is that
Proposition 3.25 For all p > 1, there exists a finite constant Cp,T > 0 such that for
and 0 ::; t ::; T
E[|~Nt(03C6)-~t(03C6)|p]1/p ~ Cp,T~03C6~ N
Proof: Using the same arguments as in the proofs of Proposition 3.22 and Theorem
3.19, this inequality is a consequence of previous lemma and standard Marcinkiewicz-
Zygmund’s inequality, ensuring that there is a finite constant Cp > 0 such that
E[|~N0(Q0,T(03C6))-~0(Q0,T(03C6))|p]1/p ~ Cp~Q0,T(03C6)~ N
Using for instance the previous proposition with p = 4 (note that for this case,
we could have rather take into account the Lemma 3.34 p. 382 of , instead of
Lemma 3.24), we can apply the Borel-Cantelli Lemma to see that almost surely, for
a cp E Bb(E) fixed,
lim~Nt(03C6) = ~t(03C6)
In fact the Proposition 3.25 can be quantitatively improved for p = 1, if we put
the absolute value outside the expectation:
Proposition 3.26 For T > 0 given, there exists a constant CT > 0 such that for all
cp E Bb(E) and all N > l, we have
Proof: Using the equation (108) valid for all cp E A, we get
~UT (~P)~ -
But clearly this equality is then true for all cp E Bb(E), via usual arguments (ie
~yT is an estimator without biais of
Then taking into account (109), we see that
- ~I T (~P) I
- ~ ~rT 1 ( i ) ~IT N ( ~P )( ~YN T ( i - )
- ~IT (~P) ) (~YT ( i ) - ~YT ( i) ) ~
~j)~[(~(~) - ~(~))~~E[(~(I) - ~(1))~]
for a constant CT > 0, according to the Proposition 3.25 and its proof.
The proportionality to
of the upper bound we have just obtained is related
to the strong propagation of chaos. This question will not be thoroughly investigated
here, but let us give some immediate remarks about it.
First we recall the definition of this property: let X =
be the time inhomogeneous Markovian process taking values in E, whose initial law is r~o and whose
family of pregenerators is
is defined by (3) and (4) (starting
from the same
and where the pregenerator jC ~ for t > 0 and q ~ Mi(E), is given
In the generalized Boltzmann equations literature, X is called the nonlinear process (or sometimes the tarjet process) because at any time t 2 0, the law of Xt is r~t,
but at this instant its pregenerator also uses in its definition the probability 1]t. So
the evolution depends on the time marginal and this is the nonlinear aspect of X.
For T > 0 fixed, let
denote the law of (Xt)OtT. Then the strong propagation of chaos can be expressed as the existence of a constant
> 0 such that for
all N ~ 1 and 1 ~ k ~ N, we are assured of
~P(N,1,...,k)~0,[0,T]
-P~k~0,[0,T]~tv ~
where ]] .
stands for the total variation norm and where P(N,1,...,k)~0,[0,T] denotes the law
over the time interval [0, T] of the kth first particles (~’t , ~t , ’ ’ ’ ,
(cf Graham
and Meleard ).
Using on one hand a generalization of the approach presented here, but for the
tensorized empirical measures alluded to in the beginning of section
the other hand two straightforward coupling arguments, it is possible to prove such a
behavior, except we have not yet been able to get the right dependence in k.
Nevertheless, note that as a direct consequence of Proposition 3.26, we have the
simpler bound
~P(N,1)~0,T~tv
denote the law of (§ (resp. XT). This comes from the identity
= ~T and the fact that the distribution of ~T is also
by exchangeability
of the particles.
Furthermore, if we assume that the semigroup 03A6 is exponentially asymptotically
stable, in the sense (111) given below, then we obtain an uniform in time result: for
some constants C > 0 and 0 a 1,
sup~P(N,1)~0,t
More generally, to get uniform upper bounds with respect to the time parameter
(under additional stability assumptions) it is important to control the dependence of
the constant Cp,T arising in Proposition 3.25. A more cautious study shows that in
fact there exists a universal constant Ap > 0 depending on the parameter p and an
additional finite constant B > 0 (which do not depend on p) such that
Cp,T ~ Ap exp (B T0(1
We end this section with a uniform convergence result with respect to the time parameter.
Theorem 3.27 Assume that the semigroup ~ associated with the dynamics structure
of r~ and defined in (101) is asymptotically stable in the sense that
sup ~03A6t,t+T( )-03A6t,t+T(03BD)~tv
If the function U satisfies
supt>0~Ut~
oo then for any bounded Borel
function p we have the following uniform convergence result
In addition, assume that the semigroup ~ is exponentially asymptotically stable in the
sense that there exist some positive constant q > 0 and To > 0 such that for any
~c, v E M1(E) and T > To
sup ~~~t,t+T(I~~ -
Then for any p > i and for any Borel function p, ]]p[] I, we have the following
uniform LP error bound
sup E ( iq?w> - qtw> iP)
for any N > I such that
T(N) ~~~ ~
2 ’t + ’t’
where A) is a universal constant which only depends on p > I and a and q’ are given
a = ’~ and q’ = B(I + ]]U]]*)
and B is the finite constant arising in (l10).
Proof: To prove this theorem we follow the same line of arguments as in the proof of
Theorem 2. l l . Since most of the computations are similar to those made in discrete
time settings the proof will be only sketched.
The only point we have to check is that for any p, [[ p]] I , p > I , T > To and t > 0
E(|~Nt+T(03C6)-03A6t,t+T(~Nt)(03C6) |p)
~ Apexp(03B3’T) N
with 03B3’ = B(1 + ~U~*)
Subtracting the equalities (107) at times t = T and t = s (and taking into account
the definition of B given below (107)), we get that for any s T and p e A,
03B3NT(03C6) = 03B3Ns(Qs,T(03C6))+ Ts exp(0~Nu(Uu)du)dBN(03C6)
Since by definition we have
it appears by construction that
03B3Ns(Qs,T(03C6)) 03B3Ns(1)
= ~Ns(Qs,T(03C6))
so the above decomposition yields that
~Ns,T(03C6) def. 03B3NT(03C6) 03B3Ns(1)
=~Ns(Qs,T(03C6))
exp(s~Nu(Uu)
By the same reasoning as in Lemma 3.24 one can check that for any p > i , there
exists a universal constant Ap > 0 depending on the parameter p and an additional
finite constant B > 0 (which do not depend on p) such that
E(|~Ns,T(03C6)-~Ns(Qs,T(03C6))|p)1 p~
ApeB(1+~U~*)(T-s) N
Instead of (109) we now use the decomposition
~) - ~.T(~)~)
= ~(~(i)) («T(~) - ~(~.T~))) + ~(~) (~(9..T(1)) - ~(1)))
to prove that
E(j~(~) - ~T(~)(~)!’)~
The desired upper bound is now clear by replacing the pair parameter (.s,T) by
Central Limit Theorem
We now turn to fluctuactions associated with the weak propagation of chaos. We
proceed in much the same way as in discrete time settings. Let us introduce the
"normalized" semigroup
defined by
~0~s~t,~03C6~A,
Qs,t(03C6)=Qs,t(03C6) ~s(Qs,t(I))
To see that it is in fact a semigroup, we first notice that
v o ~ ~ r,
~(~,(i)) = E~
= exp(ts ~u(Uu)du)
where the latter equality correspond to the basic identity
proved at the end of section 1.3, but for the shifted dynamical system
Consequently the above semigroup can be rewritten as follows
~(~) = E~L~)exp~~(~)-~(~)~j
Therefore it is clear that
is defined as
by replacing the
mapping ~7 by the mapping
: R+xE3(~)~~r)-7~)
Theorem 3.28 For cp E ,A, define
- ~ l ‘ (~IT (S~) - ~IT (~P))
and let us denote as in (61~, for 0 t T,
Then under (H~~T, the family
converges in daw to a centered Gaussian field (WT(03C6))03C6~A
whose covariances are given by
~ 03C6, 03C6 ~ A,
E[WT (03C6)WT(03C6)] = ~0 [03C60,T03C60,T] + T0
G(s , T, ~s, 03C6, 03C6) ds
where for all0 s T, all m E M1(E) and all
G(s, T, m, ~, ~)
= m [0393(03C6.,T, 03C6 .,T)(s,.)] +
m[(03C6s,T
-m[03C6s,T])(03C6s,T
-m[03C6s,T]
)(Us + m[Us])]
First, we will only consider one function cp E ,A, for which we have the analogous
result of Lemma 3.20, whose proof is quite identical:
Lemma 3.29 For cp E ,A, the process
(BNt(03C6))0~t~T
(~Nt(03C6t,T
(~Ns(Us)-~s(Us))~Ns(03C6s,T
)ds) 0~t~T
is a martingale, whose initial value is
and whose increasing process is given by
We will examine separately each term arising in the above lemma. For the first one,
Lemma 3.30 Under (H,~~T, the random variables
NT0|(~Ns (Us)-~s(Us))~Ns(03C6s,T)|
converge in probability to D as N tends to infinity.
Proof: It is enough to show that
NT0|(~Ns(Us)
- ~s(Us))~Ns(03C6s,T)| ds]
To this end we use the following Cauchy-Schwarz upper bound of this quantity (before
going to the limit for N large)
~1 NE f /~(~))’ ~]
+oo? using the last assertion of the previous lemma and dominated
convergence, the first factor goes to zero as N tends to infinity.
For the second term, let us write that for 0 ~ ~ T,
This yields that
~Ns[03C6s,T]2
~ 2~Ns[Qs,T(1)]2 ((~Ns[Qs,T(03C6)]-~s[Qs,T(03C6)])2 ~Ns[Qs,T(1)]2
~s[Qs,T(03C6)]2 ~s[Qs,T(1)]2~Ns[Qs,T(1)]2
(~Ns[Qs,T(1)]-~s
But the proof of Theorem 3.19 shows in fact that for all (/? e A
from which one concludes that (112) holds.
The important step in this section is the following
Proposition 3.31 Under (H2)T, the martingale
converges in law (for
the Skorokhod topology in D([0,+~[,R)) for N large toward a Gaussian centered
martingale
whose increasing process is the deterministic mapping
[o,r]3~~ it
and whose initial value
~(~) ~’ ~o[(Qo,T(~ -
for variance.
Proof: Conditionning with respect to the a-algebra associated with time 0, it is not
so difficult to realize that it is sufficient to prove the two following lemmas.
Lemma 3.32 The random variables
converge in law for N large toward
a centered Gaussian law of variance
Proof: It is just the usual central limit theorem for the independent variables
i N, have the same law
We would have noticed that
~0(03C60,T)= 0.
Lemma 3.33 Consider the process
= (BNt(03C6) - BN0(03C6))0~t~T,
the law P which is constructed as l~, except that the initial distribution of ~o is a
Dirac measure
for some xo E EN. Then
converge in law toward a
Gaussian centered martingale
starting in 0 and whose increasing process
is the deterministic mapping
Proof: Since (H2)T is assumed to be satisfied for all ~0 ~ Mi(E),
again a martingale under P, and we also have that
Thanks to Theorem 3.11 p. 432 of it is now enough to prove that
lim [sup|0394Ns(03C6)|~~]
where the last limit is understood in probability (P).
But (113) is proved in quite the same way as Lemma 3.23, and (114) comes from a
dominated convergence theorem, using the weak propagation of chaos and the fact
that for all 0 s T, Us,
Putting together the previous calculations, we also see that the process
(~~(~Pt,T))0tT
converge to the same limit as the one presented in Proposition 3.31.
Now the Theorem 3.28 follows, by considering terminal values. More precisely, it
remains to replace p by (c~l, c~2, ~ ~ ~ , c~p), where
c~2, ... ,
p > 1, and to use
linear relations like
1 i ~ j p, which implies
for instance that for any 1 i ~ j p
The details are left to the reader.
The expression for the limit covariance can be simplified, in order to see that in
fact it depends continuously on ~, cp with respect to the norm ~~ ’ ~~. Furthermore, it
will confirm that it doesn’t depend on the choice of r(~.,T, cp.,T).
Lemma 3.34 More precisedy, for any ~, ~ E ,A we have
(03C6) WT(
- ~T( 03C6))] +
2T0~s[03C6s,T03C6s,TUs]
Proof: By a symmetrization procedure, it is suflicient to consider the case ~ = cp.
Then we use calculations similar to those of Lemma 3.21.
To this end we first recall that
fo ~ls~~(‘~2,T)(s~
Xs) exp ( /
Writing for all 0 s T,
03C62s,T(Xs) = 03C620,T(X0) + s0 L03C62.,T)(u, Xu) du + M(03C62.,T)sT)s
with a certain martingale (M~~2’T))$~o, we deduce that
L(03C62. ,T) (s, Xs) exp(s0
Uu(Xu)- ~u (Uu) du)]
E~0[03C62T,T(XT)
E~0[03C620,T(X0)]-
E~0[T003C62s,T(Xs)(Us(Xs)
-~s(Us))exp(s0
= ~T[03C62T,T]
-~0[03C620,T]=T0~s[03C62s,T(Us-~s(Us))]
fT ~ ~’,T )(S~
~s[L(03C62.,T)(s,
- 203C6s,T L(03C6 .,T)(s,. )] ds
= ~T[03C62T,T]
-~0[03C620,T]
-T0~s[03C62s,T(Us-
~s(Us)) + 203C6s,TL(03C6.,T)] ds
But it appears from the definition of ps,T, that
V (s, x) E [0, T] x EN,
.,T(~P))(s~ x) +
= -(Us(x)-~s(Us))03C6s,T(x)
T0 ~s[0393(03C6.,T,
03C6.,T)(s,.)] ds
= ~T[03C62T,T]-~0[03C620,T]
+T0~s[03C62s,T(Us-~s(Us))]ds
and finally the lemma follows, taking into account that
V O ~ S ~ T,
Remark 3.35: This is a first step which could lead to the conclusion that the
Theorem 3.28 is true more generally for the family
. Note also that
in the trivial case where U - 0, we find the classical covariance for independent
particles. The term
gives a measurement of the noise introduced by
interactions.
3.3.3 Exponential Bounds
We can also take advantage of the martingales we have exhibited in the previous sections to obtain exponential bounds on deviations from the limit. Here we will use
the strong regularity assumptions considered in section 3.1.2, because a.s. bounds on
the increasing processes will be needed (and not only L~ estimations, as for the weak
propagation of chaos).
Our starting point will be the following basic result from the general theory of
martingales (cf for instance the Corollary 3.3 of using calculations from the section 4.13 of ):
Proposition 3.36 Let
a martingale starting from 0, ie Mo = 0, and
such that for a constant a > 0, we have a.s.,
a. Then M is locally
square integrable and we are assured of the bounds
Now the procedure to get exponential upper bounds for the deviations
introduced in Theorem 3.28 is quite standard.
First we have to estimate the "characteristics" of the martingale B(p) defined in
the proof of Proposition 3.22, for p E A.
Lemma 3.37 For T > 0 given, there exist two constants
> 0, such that
for all 03C6 ~ A, we have almost surely,
where the norm -
was defined by the formula (105) given page 96.
Proof: Using the following relation valid for all 0 ~ T,
clearly it is enough to get these upper bounds with
replaced by the martingale
considered in Lemma 3.20. But then the required estimations are deduced at
once from Lemma 3.20 and Lemma 3.23.
Taking into account a basic result on iid random variables, we end up with
Proposition 3.38 There exists a constant C(12)T > 0 such that for all p ~ A,
V 6 > 0,P [sup |03B3Nt(Qt,T(03C6))- 03B3T(03C6)|~~]
~ 4exp( -NC(12)T~2 ~03C6~2V~~03C6~~2[0,T])
Proof: Recall that
so we can write the decomposition
It is then sufficient to prove that for all ~ > 0,
2exp ( ,~ ’ )
P[|03B3N0(Q0,T(03C6))-03B30(Q0,T(03C6))|~~/2] ~ 2exp(
-NC(14)T~2 ~03C6~2 )
for some constants C(13)T, C(14)T > 0.
For the first inequality, we note that obviously
so we only have to prove it for 0
but then, by using
the estimates of the lemma above, it comes from the Proposition 3.36 applied with
~03C6~ / Nand
The second bound is just a consequence of the Hoeffding inequality for iid random
variables (cf ), which states that for all e > 0,
2exp p -NE2 2
P [|03B3N0(Q0,T(03C6))
03B30(Q0,T(03C6))| ~ ~/2] ~ 2exp( 8~Q0,T(03C6)~2
so we can take
Now the conclusion follows easily:
Theorem 3.39 There exists a constant CT15) > 0 such that
~03C6~A,~~>0, P[|WNT(03C6)|~~]
-C(15)T~2 ~03C6~2V~~03C6~~2[0,T]
where we recall that the fluctuation are given by WT (cp)
= N(~NT(03C6)
Proof: We deduce this result from the usual decomposition (108) and the inequality
of the latter proposition, considered at time t = T. If we use the full strength of the
uniformity over the interval [0, T], then for any c~ E A and for any E > 0 we rather
end up with
P[sup|03A6t,T(~Nt)(03C6)-~T(03C6)|~~] ~
4exp(-NC(15)T~2 ~03C6~2V~~03C6~~2[0,T])
Remarks 3.40:
a) The norm ~~ ~
does not seem an easy object to manipulate, but the considerations of section 3.1.2 enables us to replace it by more convenient ones, for instance,
under hypotheses (H4)T, (H7)T, (H8)T, (H9)T and (H10)T, it appears that for a constant
> 0 depending only on T > 0, we have
b) Theorem 3.39 is a first step in the direction of a 1Lp Glivenko-Cantelli result,
since it shows that for T > 0 fixed, the process
indexed by A is sub-Gaussian with respect to the norm [[ . [[
So if for a class of functions C A, we have enough information about the packing
and covering numbers of ,~’ with respect to [] . ] V ~~~~ ’’~~~(o,T~ (or more conveniently, with
respect to ]]]
. ~~~, under the appropriate hypotheses), then we could conclude to results
similar to those presented in section 2.2.3.
c) We also notice that the Proposition 3.25 could classically be deduced from
the previous theorem (cf for instance ), except that we end up with the norm
~~ ’ ~~ V ~~~~
in the rhs of the inequality given there, instead of ]] . ~~. This leads to
the question of whether the Theorem 3.39 would not be satisfied with that norm.
4 Applications to Non Linear Filtering
Introduction
The object of this section is to apply the results obtained in previous sections to
nonlinear filtering problems. We will study continuous time as well as discrete time
filtering problems. For a detailed discussion of the filtering problem the reader is referred to the pioneering paper of Stratonovich and to the more rigorous studies
of Shiryaev and Kallianpur-Striebel . More recent developments can be found
in Ocone and Pardoux .
In continuous time settings the desired conditional distributions can be regarded
as a Markov process taking values in the space of all probability measures. The corresponding evolution equation is usually called the Kushner-Stratonovitch equation.
The most important measure of complexity is the infinite dimensionality of the state
space of this equation.
In the first section 4.2 we formulate the continuous time nonlinear filtering problem in such a way that the results of section 3 can be applied. In section 4.3 we
present an alternative approach to approximate a continuous time filtering problem.
This approach is based on a commonly used time discretization procedure (see for
instance and ).
We shall see that the resulting discrete time model has the same form as in (8) and
it also characterizes the evolution in time of the optimal filter for a suitably defined
discrete time filtering problem.
The fundamental difference between the Moran’s type IPS and the genetic type IPS
associated with this additional level of discretization lies in the fact that in the Moran
IPS competitive interactions occur randomly. The resulting scheme is therefore a
genuine continuous time and particle approximating model of the nonlinear filtering
In section 4.4 we briefly describe the discrete time filtering problem. It will be
transparent from this formulation that the desired flow of distributions have the same
form as the one considered in this work (see (8) section 1.3). We will also remark that
the fitness functions {gn ; n > 1 } and therefore the constants ~an ; n > 1 ~ defined in
condition (9) depend on the observation process so that the analysis given in previous
sections will also lead to quenched results.
For instance the covariance function in Donsker Theorem and the rates functions in
LDP will now depend on the observation record.
One natural question that one may ask if whether the averaged version of the
stability results of section 2.1.2 and the LP-error bounds given in section 2.2.2 hold.
In many practical situations the functions ~a,~ ; n > 1~ have a rather complicated
form and it is difficult to obtain an averaged version of some results such as the
exponential rates given in Theorem 2.15. Nevertheless we will see in section 4.4.2
that the averaged version of the stability results given in section 2.1.2 as well as the
averaged version of the LP-uniform bounds given in section 2.2.2 hold for a large class
of nonlinear sensors.
4.2 Continuous Time Filtering Problems
4.2.1 Description of the Models
The aim of this section is to formulate some classical nonlinear filtering problems in
such a way that the previous particles interpretations can be naturally applied to
them. Here is the heuristic model: let a signal process S = {St ; t > 0~ be given, it is
assumed to be a time-homogeneous Markov process with cadlag paths taking values
in the Polish space E. We suppose that this signal is seen through a Revalued noisy
observation process Y={Yt; t > 0} defined by
t0h(Ss)ds+Vt
where V = {Y ; t > 0} is a d-vector standard Wiener process independent of S, and
h maps somewhat smoothly the signal state space E into 1Rd.
The traditional filtering problem is concerned with estimating the conditional
distribution of St given the observational information that is available at time t,
; 0 s t), ie to evaluate for all f E Cb(E),
~ ( f(St )
More precisely, we will make the assumption that there exist an algebra A C Cb(E)
and a pregenerator Lo :
: ,A --~ Cb(E) such that for any initial distribution
there is a unique solution
to the martingales problem (we refer to the section 3.1.1
for more details) associated with r~o and Lo on
D(1~+, E), the space of all cadlag
paths from R+ to E, endowed with its natural a-algebra. Then S def. (St)t>o will denote
the canonical coordinate process on 03A91, and from now on, the initial distribution ~0
will be supposed fixed, and we will consider the Markov process Sunder
be the map from E to IRd alluded to above, we make the
hypothesis that for all 1 i d, hi E A.
Let us also introduce the canonical probability space associated with the observation process: O2 = C(1~+, 1R d), the set of all continuous functions from l~+ to
is the coordinate process on 5~2.
Let us denote 0 = Hi 03A92 a.nd !P the probability on its usual Borelian 03C3-field such
that its marginal on ~i is P~ and such that
V=(Vt)t~0 def. (Yt-t0h(Ss)ds)
is a d-vector standard Brownian motion, as previously mentionned.
In practice, this probability P is usually constructed via Girsanov’s Theorem from
another reference probability measure P on H, under which S and Y are independent,
? has law P~0 and V is a d-vector standard Brownian motion. For t ~ 0, let
~=~((~~); 0~~)
be the 03C3-algebra of events up to time t, the probabilities P and P are in fact equivalent
on ~, and their density is given by
=Zt(S,Y)def
exp (t0h*(Ss)dYs-1 2t0h*(Ss)h(Ss)ds)
where we have used standard matrix notations, for instance
Under our assumptions ( ) one can prove that
~ ~(~ ~) ~o(~)
Using Itô’s integration by part formula, in the differential sense we have that
is a d-vector
square integrable continuous martingale (relative to the natural nitration (~)oo)
with cross-variation processes given by
V 1 z’J ~,
(as usual Fo is the carré du champ associated with the pregenerator Lo). This yields
the decomposition
=h*(St)Ytt0Y*sL0(h)(Ss)dst0 Y*sdMhs-1 2t0h*(Ss)h(Ss)ds
Before going further, let us make the following remark:
As in section 3.1.1, we denote L the operator acting on A 0~4 by formula (92), where
~ is replaced by Lo. We also consider ~oo the vector space of functions / 6
for which there exists a function L( f ) E
x E) such that under
the process
(Mt(f) )OtT defined by
~0~t~T, Mt(f) = f(t,Xt) - f(0,Xp) -
t0 L(f)(s,Xs) ds
is a martingale.
We have the following stability property:
Lemma 4.1 If f E A ® A, then exp( f ) E
Proof: Using the formula exp( f ) =
and an approximation technique as
the one presented in Lemma 3.2, it is enough to show that for all T > 0 given, we
have as n, m ~ oo (and on [0, T] x E)
But these convergence results are easy to obtain, because of the general bounds
03A3fp/p!,
03A3 fp/p!)
03A3 0393(fp/p!,fp/p!)
d p >_ 1 ~
and of the upper bound on
which can be deduced by induction from
~ ~fn ~[0,T]
~L(f) ~[0,T]
+ ~f~[0,T]
+ ~0393(fn
,f) ~[0,T]
~ ~fn~[0,T]
~L(f)~[0,T]
+ ~f~[0,T]~L(fn)~[0,T]
~0393(f,f)~[0,T]~0393(fn,fn)~[0,T]
This ends the proof of the lemma.
be given. For t > 0 fixed, the map
ht : E ~ x H ~
belongs to A, so in the same way as above, we can define a function
Lo(exp(-ht)) E Bb( E).
We easily realize that the application
l~+ x E ~ (t, x)
is continuous as a locally uniform limit of continuous functions.
Then we can consider
def exp (-t0y*sdM(h)s -
t0exp(hs(Ss))L0(exp(-hs))(Ss) + L0(hs)(Ss)ds)
Note that if a sequence
of elements of C(R+,
converges uniformly on
compact subsets of R+ toward y, then uniformly for t belonging to compact subsets,
Zt(S, Yn) converges in probability towards Zt(S, y).
The interest of this quantity is that
Lemma 4.2 Let a function y E
be fixed. Under
the process (Zt(S,
is a martingale.
Proof: We will first consider the case y E
(even if this situation a.s.
never occur for Y).
Under this additional assumption, the mapping
: R+ x E3 (t, x) ~ ht(x)
clearly belongs to A ® A, and it appears that if M(h) is the martingale such that for
all t ~ 0,
Ss) ds + M
then in fact it is given by
~t~0, M(h)t
Furthermore, from Lemma 4.1, for any t > 0 we can write that
exp(-h(t, St)) = exp(-h(0, S0)) + t0 L(exp(-h))(s,Ss)ds
+ M(exp(-h))t
for a certain martingale
On the other hand it appears without difficulty that for any (s, x) E R+ x E
exp(hs(x))Lo(exp(-hs))(x) + Lo(hs)(x)
= exp(h(s, x))L(exp( -h))(s, x) + L(h)(s, x)
(ie the time derivatives cancel). As a result, for any t > 0 we have that
This may also be written in differential form
+ exp(h( t-, St-))
exp(h( t -, St-) )L( exp( -h))( t -, St-) dt)
y) exp(h(t-, St_)) dMt(exp(-h»
It follows that (Zt(S, y))t~0 is a martingale. Indeed it is more precisely the Doléans-
Dade exponential of the martingale
(t0 exp(h(s-, Ss-)) dM(exp(-h))s)t~0
Thus, we see that for all 0 ~ s ~ t and any random variables H$ which are measurable
with respect to Q(Su ; 0 u s), we have
- Z$(s, y))l
We end the proof by noting that the left hand side is continuous with respect to
if this set is endowed with the uniform convergence on compact
subsets of R+.
Let us write, for y ~ C(R+,Rd),
ln Zt(S, y)
= h*(St)yt + t0 V(Ss, ys) ds + ln Zt(S, y)
where for all (x, y) ~ E x Rd,
Together with (115) this decomposition implies that
03C0t(f) =
03A91f(03B8t)eh*(03B8t)Yt+t0 V(03B8s,Ys)ds P[Y]~0(d03B8) eh*(03B8t)Yt+t0 V(03B8s,Ys)ds P[Y]~0(d03B8)
where, for any y E C(R+,
P[y]~0 is the probability measure on 03A91 defined by its
restrictions to F(1)t = 03C3(Ss,
0 ~ s ~ t):
dP[y]~0 d~0|F(1)t = Zt(S,y)
Here is a more tractable caracterisation of
Proposition 4.3 Fix a mapping y E
and consider for t > 0 an operator
Lt given on A by
Then (Lt)t>o is a measurable family of pregenerators, and
is the unique solution
to the martingale problem associated with the initial condition rto and to this family.
We would have noticed there is no real difficulty in defining r(exp(-ht), p) for 03C6 E A.
Proof: We shall verify that for all 03C6 E A, all 0 s t and all random variable Hs
0 u s)-measurable, we have
E[y]~0 [Hs(03C6(St)
- 03C6(Ss)
- tsLu(03C6)(Xu)
where for all t > 0,
So as in Lemma 4.2, by continuity, we can assume that y E
With this assumption enforced, we have
d(zt(s, y)Nt)
- Lt(p))dt +
y)L(L~(~) -
+ exp(h(t,
we need to check that (Zt(S, y)Nt)t>_o is a martingale. To this end it is enough to see
that for any (t, x) E 1~+ x E
+ exp(h(t,
Next, since for any (t, x) E R+ x E
Lt is well defined.
The fact that, for any t > 0 Lt is a pregenerator comes from the previous considerations, taking y E C(R+, JR d) defined by
And the uniqueness property comes from the one of
since if l~ is a solution to
the martingale problem associated to (Lt)t>o, then it can be shown that the probability
P defined on ~1 by
is solution to the time-homogeneous martingale problem associated to Lo (all initial
conditions being
The above formulation of the optimal filter can be regarded as a path-wise filter
C([o,T]) -~ M1(E)
where the probability 7r y,t is given by
~ Bb(E), 03C0y,t(f)
03A91f(03B8t)eh*(03B8)tyt+t0 V(03B8s,ys)ds P[y]~0(d03B8) 03A91eh*(03B8)tyt+t0 V(03B8s,ys)ds P[y]~0(d03B8)
This gives a description of the optimal filter in terms of Feynman-Kac formulae
as those presented in (3) and (4) in the introduction. Namely,
~ f ~ Bb(E),
03C0y,t(f)
Ef(x)eh*(x)yt~y,t(dx) Eeh*(x)yt~y,t(dx)
~f ~ Bb(E),
03B3y,t(f) 03B3y,t(1)
V f E Bb(E),
Qf [f(Xt) ~’
In contrast to (115) we notice that the previous formulations do not involve
stochastic integrations and therefore it is well defined for all observation paths and
not only on a set of probability measure 1. This formulation is necessary to study the
robustness of the optimal filter (that is the continuity of the filter with respect to the
observation process), and is also essential to construct robust approximations of the
optimal filter, as our interacting particles scheme.
Remarks 4.4:
(a) Note that the condition (Hl) is automatically verified for family of pregenerators
(Lt )tO constructed as in Proposition 4.3.
(b) The change of probability presented in that proposition is rather well known
in case of diffusions (cf for instance and ), ie when the trajectories of S are
continuous.
Then we can suppose that A is stable by composition with Coo functions and we have
o( (~P)) * (SP) o(SP) + 2 SP)
ro(F(~)~ ~) - F’(~)ro(~~ ~)
So in the previous expressions, we can replace
exp(y*h(x))L0(exp(-y*h(.)))(x) by 1 2 y* 03930(h,h)(x)y
y* L0(h)(x)
where ro(h, h)(x) denote the matrix
4.2.2 Examples
Here are some classical examples that can be handled in our framework. The map h
and the function y E C(R+,
will be given as before.
~ Bounded Generators
The simplest example a pregenerator Lo is that of a bounded generator. Namely,
: E x ~ -~ R be a signed kernel such that
- for any x E E, Lo(x,. n (E B M) E M(E) and Lo(x, E) = 0
- for any A E ~*, E 5 x -~ Lo(x, A) E R is a measurable function
- there exists a constant 0 M oo such that
Then for any function f E Bb(E), we define
We can take here A = Bb(E). We calculate that the carre du champ is given for
any 03C6, 03C6 ~ A and x ~ E by
ro(~~ 4~)(x) -
- ~(x))(4~(y)
so it appears that for any t > 0, cp E A and x E E
They are again jump generators, and the rate of transition from x to y at time t > 0
has just been multiplied by exp(ht(x) - ht(y)).
For this kind of generators, all our hypotheses are trivially satisfied.
~ Riemannian Diffusions
Let E be a compact Riemannian manifold. As usual, ( ~ , ~ ), v ~ and A’ will
denote the scalar product, the gradient and the Laplacian associated with this structure. Let A be the algebra of smooth functions, i.e. A = C°°(E). Suppose that we
are given a vector field b, we denote
L0 : A ~ A
It is immediate to realize that in this example the carre du champ does not depend
on b and satisfy
(by the way, this equality gave the name "carre du champs").
The existence and uniqueness assumption for the associated martingale problem
is well known to be fulfilled. We calculate that for t > 0, Lt is obtained from Lo by a
change of drift:
This example is also a typical one where all the assumptions of section 3.1.2 are
~ Euclidean Diffusions
Except for the compactness of the state space, these processes are similar to those
of the previous example.
So here E = Rn, n > 1, and let for x E E,
and b(x) _
be respectively a symmetric nonnegative definite matrix and a n-vector. We suppose
they are uniformly Lipschitz in their dependence on x E l~’~.
Then denoting a = Q2, let us consider on A def.
the pregenerator
~ 03C6 ~ A, ~ x ~ Rn, L0(03C6)(x)
ai,j 2(x)~i,j03C6(x)
+ bi(x)~i03C6(x)
It is a classical result that the associated martingale problems are well-posed (for
further details about this problem, see ), and more precisely, for all x E
is the law of the (unique strong) solution of the stochastic differential equation
dBt + b(St) dt
is a standard n-vector Brownian motion.
Here the carre du champ is given by
so we find that
(b$(x) - ~
Let us make the hypothesis that a is uniformly elliptic: there exists a constant
~ > 0 such that for all x ~ Rn,
Under the extra assumption that a and bare Cr, we see that all the requirement
of section 3.1.2 are met (rather taking there A =
But considering the
parabolic equation satisfied by
it appears that (H2) will be verified under much
less regularity for the coefficients a and b.
4.3 Time Discretization of Continuous Time Filtering Problems
In this section we discuss a time discretization approximating model for the non linear
filtering problem associated to the previous Euclidean diffusion signal. To clarify the
presentation all processes considered in this section will be indexed on the compact
interval C R+.
The basic model for the continuous time filtering problem considered here consists
in an l~p x Revalued Markov process
E ~0,1~~, strong solution on a
probability space (H, F, P) of the Ito’s type stochastic differential equations
+ b(Xt)d03B2t
= h(Xt)dt + dVt
l~q are bounded and Lipschitz
continuous functions.
2. {(03B2t, V )
: t E } is a
x Rq)-valued standard Brownian motion.
3. Yo = 0 and Xo is a random variable independent
V ) : t E [0, l~ ~ with
law v so that
The classical filtering problem is to find the conditional distribution of the signal X
at time t with respect to the observations Y up to time t, that is
equation where
is the filtration generated by the observations Y up to time t.
The first step in this direction consists in obtaining a more tractable description
of the conditional expectations (116).
Introducing Zt > 0 such that
dt E [o,1~,
log Zt = 0
dYs - 2 1 0
it is well known that the original probability measure P is equivalent to a so called
reference probability measure Po given by
In addition, under Po, {(,st, Y;)
: t E } is a
x Rq)-valued standard Brownian
motion and, Xo is a random variable with law v, independent of (~3, Y).
The following well known result gives a, functional integral representation for the
conditional expectations (116), which is known as the Kallianpur-Striebel formula:
~f ~ Bb(Rp), ~t ~ , 03C0t
E0(f(Xt)Zt|y[0,t]) E0(Zt|y[0,t])
= EY0(f(Xt) Zt|y[0,t]) EY0(Zt|y[0,t])
( . ) to denote the integration with respect to the Brownian paths
t E [0, l~~ and the variable Xo.
In this section a program for the numerical solving of (117) by using a discrete time
IPS scheme is embarked on. As announced in the introduction such IPS approach is
obtained by first approximating the original model by a discrete time and measure
valued process. The treatment that follows is standard in nonlinear filtering literature
and it is essentially contained in and .
The former discrete time approximating model of (117) is obtained by first introducing a time discretization scheme of the basic model. To this end we introduce a
sequence a meshes ( (to, ... , t M)
: M > 1~ given by
n E {0, ... , M}.
To obtain a computationally feasible solution we will also use the following natural
assumptions:
~ For any M > 1 there exists a transition probability kernel
= 0,..., M} is the time homogeneous Markov chain with
transition probability kernel P(M) and such that
~ We can exactly simulate random variables according to the law PtM) (x, . ) for
any x E l~p.
It is worth noting that an example of an approximating Markov chain
. n = 0, ... , M~
satisfying these assumptions is given by the classical Euler scheme
= X(M)tn-1 + a( X(M)tn-1)(
c( X(M)tn-1) (03B2tn
n =1 ,..., M (118)
= Xo. This scheme is the crudest of the discretization scheme that can
be used in our settings. Other time discretization schemes for diffusive signals are
described in full detail in and . In view of (117) the optimal filters
n = 0, ... , M~ can be written as
= EY0(Ztn-1
(Htnf)(Xtn-1)
( Ht n 1 )( Xt _ n 1 ))
where Htn is the finite transition measure on l~p given by
dz) f(z) = Eo (f (Xtn)
log gtn (X, Y)
tn tn-1h*(Xs)
1 2 tntn-1|h(Xs)|2
If, for any transition measure H and any probability measure 7r on l~p we denote by
03C0H the finite measure so that for any bounded continuous function f E
(~I f )(x),
then, given the observations, the dynamics structure of the conditional distributions
= 0, ... , M~ is defined by the recursion
03C0tn(f) = 03C0tn-1Htn(f), 03C0tn-1Htn(1),
n = 1 ,...,M
with 03C0t0
To approximate the stochastic integrals (119) it is convenient to note that, in a
sense to be given,
log gtn(X,Y) ~ h*(Xtn-1)0394Ytn - 1 2|h(Xtn-1)|20394tn
. In this connection, a first step to obtain a computationally feasible solution consists in replacing Htn by the approximating multiplication operator
(H .~)(x) =
R+ is the positive and continuous function given by
Remark 4.5: The choice of the approximating function gM given above is not unique.
We can also use the functions gf! given by
The function h being bounded we can choose M large enough so that
V x E JRP,
From now on we denote by
= 0,..., M} the solution of the resulting
approximating discrete time model
= 03A6Mn(0394Ytn,
03C0Mtn-1),
n = 1, ..., M
where 03A6Mn(y,03C0)
= 03A8Mn(y,03C0)P(M)
~ f ~ Bb(E),
03A8Mtn(y,03C0)f = f(x)gMtn(y,x)03C0(dx) gMtn(y,x)03C0(dx)
for any y E 1~q and 7r E
Elementary manipulations show that the solution of the latter system is also given
by the formula
= f(xn) gMtm(0394Ytm,xm-1) P(M)(xm-1,dxm)03BDd(x0) gMtm(0394Ytm,xm-1) P(M)(xm-1,dxm)03BD(dx0)
This gives a description of a discrete time approximating model for the optimal filter in terms of Feynman-Kac formulae for measure valued systems as those presented
in section 1.1 and section 1.3.1.
The error bound caused by the discretization of the time interval ~0, l~ and the
approximation of the signal semigroup is well understood (see for instance Proposition
5.2 p. 31 , Theorem 2 in , Theorem 4.2 in and also Theorem 4.1 in ).
More precisely if for any n = 0,..., M
2014 1 and t E
we denote by 03C0Mt def.
we have the well known result.
Theorem 4.6 ( ) Let f be a bounded test function on l~p satisfying the Lipschitz
where C is some finite constant.
We shall see in section 4.4 that the discrete time approximating model (120) can
be regarded as the optimal filter of a suitably defined discrete time filtering problem.
In most of the applications we have in mind the whole path of observation process
E ~0, l~} is not completely known.
Instead of that the acquisition of the observation data is made at regularly spaced
times. In this specific situation the approximating model (120) and the sampled observation record
= l, ... , Nf ~ give a natural framework for formulating this
filtering problem and for applying the BIPS approaches developed in previous sections.
; n > 0~ we denote the N interacting particle scheme associated with the
limiting system (120) and defined as in (13) by replacing the functions ~~n ; n > 1~
by the functions
. ) ; n > l~.
The results of section 2.2 can be used to study the convergence of the random measures
def. i V-~ r
to the flow of distributions {vr~ ; ~ > 0~ as N -~ oo.
An immediate question is to know how the discrete time N-particle scheme and
the M-discretization time scheme combine? This study is still in progress. The only
known result in this direction has been obtained in .
For any n = 0, ... , M
2014 1 and t E
we denote by
the empirical
measures associated with the system 03BEtn, namely
03C0M,Nt =
03B403BEitn
Theorem 4.7 For any bounded Lipschitz test function f such that
- f(z)1 ~ _ k(f)
we have that
(|03C0tf - 03C0M,Ntf|)
~ C1 M(~f~ + k(f))
where Ci is the finite constant appeared in Theorem 4.6 and C2 =
addition, if p = q = 1 and a b, f, h are four times continuously differentiable with
bounded derivatives then we have
(|03C0tf - 03C0M,Ntf|)
1 M + M N).
4.4 Discrete Time Filtering Problems
4.4.1 Description of the Models
The discrete time filtering problem consists in a signal process X = (Xn ; n > 0)
taking values in a Polish space E and an "observation" process Y = (Yn ; n > 1)
taking values in R~ for some d > 1. We assume that the transition probability kernels
> 1~ are Feller and the initial value Xo of the signal is an E-valued random
variable with law r~o E M1(E). The observation process has the form
: E -~ R~ are bounded continuous and (Vn ; n > 0) are independent random variables with positive continuous density (pn ; n > 0) with respect to Lebesgue
measure on
It is furthermore assumed that the observation noise (Vn ; n > 0)
and the signal (Xn ; n > 0) are independent.
The filtering problem can be summarized as to find the conditional distributions
Cb(E), V n > 1,
A version of
is given by a Feynman-Kac formula as the one presented in (1),
f(xn) 03C6m(Ym-hm(xm-1)) Km(xm-1,dxm)~0(dx0) 03C6m(Ym-hm(xm-1)) Km(xm-1,dxm)~0(dx0)
It is transparent from this formulation that the discrete time approximating model
(120) given in section 4.3 can be regarded as the optimal filter associated with a discrete time nonlinear filtering problem.
Given the observations
n > l~ the flow of distributions
; n > 0~ is again
solution of a M1(E)-valued dynamical system of the form (8), that is
V n > l,’d ~Ip E M1(E),
where for any y E
M~(E) -~ M1(E) is the continuous function given by
and 03A8n(y,.) : M1(E) ~ M1(E) is the continuous function given by
~ ~ ~ M1(E), ~ f ~ Cb(E), 03A8n(y,~)(f) =
f(x)03C6n(y-hn(x))~(dx) 03C6n(y-hn(z))~(dz)
In this formulation the flow of distributions
; n > 0~ is parameterized by
a given observation record ~yn
n > 1} and it is solution of the measure valued
dynamical system having the form (8) so that the IPS and BIPS approaches introduced
in section 1.3.2 and section 2.3 can be applied.
4.4.2 Averaged Results
Our next objective is to present averaged versions of stability results given in section 2.1.2 and the averaged version of Theorem 2.11.
The only difficulty in directly applying the results of the end of section 2.1.2 stems
from the fact that in our setting the fitness functions are random in the observation
parameter. Instead of (~) we will use the following assumption
For any time n > l,
, there exist a positive function
an :1~d --~ ~l, oo)
and a nondecreasing function 8 : R ~ R such that
~x ~ E, ~y ~ Rd, 1 an(y) ~ 03C6n(y-hn(x)) 03C6n(y) ~ an(y) (127)
Theorem 4.8 Assume that (G’) holds with supn~1~hn~
~. For any ~ M1(E)
we write ~r~~ ; n > 0} the solution of the nonlinear filtering equation ~1,~6~ starting
If (J~)2 holds then for any
v E M1(E) we have the following implication
sup E(log an(Vn)) oo ~ lim
If (JC)3 holds then we also have for any p, v E M1 (E)
E(a-2n(Vn)) = ~ ~
lim E(~~ n - ~03BDn~tv = 0
E(a-2p(Vp)) > 0 ~
lim sup 1 n log E(~~ n - ~03BDn~tv)
The averaged version of Theorem 2.11 can be stated as follows
Theorem 4.9 Let F be a countable collection of functions f such that
satisfying the entropy condition I(F) ~. Assume that
holds and the following
conditions are met
sup log E(a2n(Vn))1/2
Assume moreover that the nonlinear filtering equation (~~6~ is asymptotically stable
in the sense that,
sup E(~03A6p,p+T( ) - 03A6p,p+T(03BD)~F|Y1,
... , Yp ) = 0
then we have the following uniform convergence with respect to time
lim sup E B I I ~n -
In addition, if the evolution equation (1~6~ is exponentially asymptotically stable in the
sense that there exists some positive constant ~y > 0 such that for any ~, v E M1 (E)
and T >_ 0
sup E (~ 03A6p,p+T( ) - 03A6p,p+T(03BD)
then we have for any p > 1, the uniform Lp-error bound given by
sup E ( ~ ~Nn - ~n~pF)1 p
Cp e03B3’ N03B1 2
where Cp is a universal constant which only depends on p > 1 and a and 03B3’ are given
a = ’y + ~ ’y ~
and ~y’ =1 + 2 (L + 9(M))
Remark 4.10: We now present a class of discrete time nonlinear filtering problems
for which the BIPS approaches developed in this work do not apply.
Let us assume that the pair process (X, Y) takes values in l~p x
and evolves
according to the following Itô’s differential equations
dXt = a(Xt, Yt) dt + b(Xt, Y) dWt
dY = a’(Xt, Y) dt + b’(Xt, X) dWt
where a, b, a’, b’ are known functions suitably defined and (YY’,
is a p+p’-dimensional
Wiener process. Suppose moreover that the acquisition of the observations is only
made at times n E N and we want to compute for all reasonable functions f :
This problem is clearly a discrete time nonlinear filtering problem but the BIPS
approaches developed in previous sections do not apply.
A novel BIPS strategy has been proposed in to solve this problem. In contrast
to the latter this new particle scheme consists in N-pair particles and the mutation
transition is related to the continuous semigroup of the pair process {(~, ~) ; ~ ~ 0}.
Exponential rates of convergence and L1-mean error estimates are given in 
and central limit theorems for the particle density profiles are presented in 
but many questions such as large deviations, fluctuations on path space as well as
uniform convergence results with respect to time remain unsolved.
5 Appendix and Index of Notations
Since we have tried to use similar notations for discrete and continuous time, we hope
that the following separations of the indexes for both settings will be convenient for
the reader.
Index of Symbols (discrete time)
Sets/norms
Semigroups/mappings
03B3n,~n 3
03A6n,03A8n
03A6n,03A8n
Index of Conditions for Asymptotic Theorems
(discrete time)
Fitness functions
Central limit
theorems and large deviations
(path space)
Asymptotic
Central limit theorems (path space)
Large deviation principles (path space)
Exponential rates
()0, ()1, ()2
Large deviations principles
( (density profiles) exponential tightness)
Index of Symbols
(continuous time)
Basic objects:
Martingales:
U = (Ut)t~0
((Xt)t~0, (Pt,x)(t,x)~R+E 76 M(N)(f)
76 (BNt(03C6))0~t~T
92 (BNt(03C6))0~t~T
~ _ (~t ~ ~t
~ ’ ’ ’ ~ ~t
Functions and norms:
’ ~~~~ [o,T]
Semigroups:
Pregenerators:
Qs,t)0~s~t 84
(Lt)t~0 75
03A6 = (03A6s,t)0~s~t
Hs,t,Zs,t,gs,t
L 76 (Qs,t)0~s~t
(N)t,(N)t,
,~~N), ,~~N], ~{N~
Index of Conditions for Asymptotic Theorems
(continuous time)
Weak regularity assumption
Strong regularity assumptions
(H3)T,~ ~ ~, (H10)T,
from 82 to 83
Ultra ergodicity for inhomogeneous semigroup
Despite our best eflorts, the variety of approaches to study asymptotic stability properties and limit theorems for the IPS approximating models inevitably require a set of
specific assumptions which might be confusing at a first reading. We therefore gather
together in this section a short discussion on the conditions we have defined and a
succinct series of implications. As a guide to their usage we also analyze these assumptions in two academic examples, namely the Gaussian and bi-exponential transitions
It is also worth observing immediatly that the limit theorems for the particle density profiles as the number of particles tends to infinity only depend on a boundedness
condition (~) defined on page 21. Furthermore in nonlinear filtering settings the fitness
functions ~g,~ ; n > 1 } also depend on the observation process and the appropriate
condition corresponding to (g) is the assumption (g)’ defined on page 129. It is clear
that the situation becomes more involved when dispensing with the assumption (g)
or (~)’. It turns out that several results can be proved without these conditions, see
for instance Proposition 2.9 and its proof on page 35. Furthermore these boundedness
conditions are not really restrictive and they are commonly used in nonlinear filtering
literature. We conclude this section with a short collection of fitness functions and
observation processes satisfying the former conditions.
Section 2.1.2 is concerned with the asymptotic stability properties of the limiting
measure valued systems
> 0} and ~~,~ ; n > 0}. Under appropriate mixing
conditions on the transition probability kernels
> l~ it is proven that the
resulting limiting systems forget exponentially fast their initial conditions. The mixing
type conditions we employed are (J~)E, (JC)1, (K)2, (K)3 and (JC~). Recalling their
description given respectively on pages 20, 24, 26 and 27 it is easy to establish the
following implications
(K)~ ~ (K)1
(K)2 + (G) ~ (KG)
As we said previously, the limit theorems for the IPS approximating schemes
presented in section 2.2 only require the assumption (g) on the fitness functions
{gn ; n > 1 ~ except for the central limit theorem and large deviations principles on
path space (see for instance section 2.2.1 as well as section 2.2.4 and section 2.2.5).
The weakest and preliminary condition
employed in the study the convergence
of the empirical measures on path space can be regarded as a mixing type condition.
Recalling its description on page 32 we clearly have
is also a natural and appropriate condition for using a reference product measure and express the law of the IPS as a simple mean field Gibbs measure on
path space.
The only additional restriction we place in the study of the central limit theorem
on path space is the exponential moment condition
given on page 48. As we
shall see in the further development this condition holds for many typical examples
of signal transitions. It is also worth noting that
In section 2.2.5 we analyze large deviations for the IPS approximating models for
general and abstract functions ~~n ; n > l~. We have presented a number of simple
criterion only involving these one step functions. When applied to Feynman-Kac type
systems we have seen that the large deviation principles on path space only require
the assumptions (J~)i and (l~)1 defined on page 54 and page 56. It is also easy to see
In view of the previous remarks the fluctuations and deviations on path space
rely on the existence of a reference probability measure satisfying (J~)o. One way to
remove this assumption is to study the particle density profiles.
The analysis of fluctuations of the particle density profiles is based on the dynamics structure of the limiting system given in section 2.1.1 and on limit theorems
for stochastic processes. These results only depend on the boundedness condition (~).
The same condition is used in proving large deviations for the particle density
profiles. More precisely we have employed condition (9) to check an exponential
tightness condition
(cf. page 57)
Gaussian Transitions
Let us now investigate the chain of assumptions (JC)1, (l~)2, (K)3, (~)i, (~)1, and
(7C£’) through the following Gaussian example.
Suppose that E =
m > 1 and Kn, n > 1 are given by
dz) = (( 2~ ) m ~Qn~) 1~2
exP (-2(z -
where Q is a m x m symmetric nonnegative matrix and bn l~’~ -~
is a bounded
continuous function. It is not difficult to check that
is satisfied with
- 2~ m 1 n 1~2
Indeed, we then find out that
log dKn(x,.) d03BBn(z) = const. - bn(x)’Q-1nz
which insures the Lipschitz property as well as the growth property with
From the previous observation it is also not difficult to check that condition (TCL) is
also satisfied.
Let us discuss conditions
and (~C)3 in time homogeneous settings (that is
Kn = K) and when E = R and Qn == 1 and bn = b.
: 1~ -3 R is only a bounded function, then
and (J~)2 do not hold. For
instance let us suppose that b :1~ ~ R is a bounded B(E)-measurable function such
that b(O) = 0 and b(1) _ -1. Then, hypothesis
is not satisfied. Suppose K
satisfies (1C)1. Clearly there exists an absolutely continuous probability measure with
density p such that
for some positive constant c. Using the fact that 6(1) = -1 we obtain
lim p(z)ez 2
On the other hand b(0) = 0 implies p(z)ez 2 2 ~ c-1 which is absurd.
Now we examine condition (K)3. First we note that for any |z| ~ M where M ~ 0
is chosen so that ~b~
~ dK(x,.) dl03BB(z) ~
03BB(dz) =
1 203C0 exp -z2 2 dz
log ~ = -2M2
In other words and roughly speaking
is satisfied on the compact set
Let us assume that the drift function b satisfies
= b(sign(x)M)
In this situation it is not difficult to check that (JC)3 holds with
A = [-M,M]
exp -1 2(z - M)2 dz,
03B32(dz) = 1 203C0 exp -1 2(z + M)2dz.
Let us examine a Gaussian situation where (K)"1 is not met. Again we suppose
that E = R and
R 2014~ R is a continuous function such that
It is not difficult to see that Kn is Feller. On the other hand, let us assume that
Kn satisfies (~C)~ for some function p. Since ~(~,.) is absolutely continuous with
respect to Lebesgue measure for any r (E R, the probability measure A~ described
in (~C)~ is absolutely continuous with respect to Lebesgue measure. Therefore, there
exists a probability density pn such that
~ x, z ~ R,
e-03C6(z) pn(z) ~ ~n(x) exp(-1 2~n(x)z2
) ~ e03C6(z) pn(z).
2014~ oo one gets
= 0 for any z ~ R which is absurd since we also
Our study is not restricted to nonlinear filtering problem with Gaussian transitions Kn
or with observations corrupted by Gaussian perturbations. We now present another
kind of densities that can be handled in our framework.
Bi-exponential Transitions
Suppose E = R and Kn, n > 1, are given by
This corresponds to the situation where the signal process X is given by
is a sequence of real valued and independent random variables with
bilateral exponential densities. Note that Kn may be written
It follows that (K)"1 holds since |log Kn(x,.) d03BBn(z)| has Lipschitz norm 203B1n + 03B1n~bn~.
It is also clear that (/C)i and (W~C) hold since we have in this situation
Conditions (g) and (~)’
Next we examine condition
As a typical example of nonlinear filtering problem assume the functions
1, are bounded continuous and the densities
~~=((2~!)~~~-2~~’~
where Rn is a d x d symmetric positive matrix. This correspond to the situation where
the observations are given by
is a sequence of Revalued and independent random variables with
Gaussian densities.
After some easy manipulations one gets that
holds with
1 2 ~R-1n~ ~hn~2 + ~R-1n~ ~hn~ |y|
is the spectral radius of
In addition we have
It is therefore not difficult to check that the assumptions of Theorem 4.9 is satisfied
sup(~hn~, ~R-1n~) ~
In this situation it is also clear that the conditions of Theorem 4.8 and Theorem 4.9
are met. To see this claim it suffices to note that Jensen’s inequality yields that
log E(a-2n(Vn))
~ -~R-1n~ ~hn~2 - 2~R-1n~ ~hn~ E(|Vn|)
and we also have
E(log an(Vn))
= 1 2 ~R-1n~ ~hn~2 + ~R-1n~ ~hn~ E(|Vn|)
Our result is not restricted to Gaussian noise sources. For instance, let us assume
that d == 1 and c.pn is a bilateral exponential density
03C6n(v) =
03B1n 2 exp-(03B1n|v|)
In this case one gets that
holds with
= an IIhn ~~ 1
which is independent of the observation parameter y. One concludes easily that the
conditions of Theorem 4.8 and Theorem 4.9 are satisfied as soon as
On the other hand if
then condition
is satisfied and Theorem 2.7 can be used to-study the asymptotic stability of the nonlinear filtering
equation for any strongly ergodic signal process (cf. remark 2.8).
We end this section with an example of Cauchy noise sources. Suppose that d = 1
is the density given by
In this situation one can check that
y2+03B82n y2+03B82n+~hn~2+2|y|~hn~
~ 03C6n(y-hn(x)) 03C6n(y)
~ 1 +(y 03B8n)2
Thus, (G)’
holds with