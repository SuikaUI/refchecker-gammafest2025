FakePolisher: Making DeepFakes More Detection-Evasive by
Shallow Reconstruction
Yihao Huang1, Felix Juefei-Xu2, Run Wang3,∗, Qing Guo3, Lei Ma4, Xiaofei Xie3, Jianwen Li1,
Weikai Miao1, Yang Liu3,5, Geguang Pu1,∗
1East China Normal University, China
2Alibaba Group, USA
3Nanyang Technological University, Singapore
4Kyushu University, Japan
5Zhejiang University, China
At this moment, GAN-based image generation methods are still imperfect, whose upsampling design has limitations in leaving some
certain artifact patterns in the synthesized image. Such artifact
patterns can be easily exploited (by recent methods) for difference
detection of real and GAN-synthesized images. However, the existing detection methods put much emphasis on the artifact patterns,
which can become futile if such artifact patterns were reduced.
Towards reducing the artifacts in the synthesized images, in this
paper, we devise a simple yet powerful approach termed FakePolisher that performs shallow reconstruction of fake images through
a learned linear dictionary, intending to effectively and efficiently
reduce the artifacts introduced during image synthesis. In particular, we first train a dictionary model to capture the patterns of
real images. Based on this dictionary, we seek the representation
of DeepFake images in a low dimensional subspace through linear
projection or sparse coding. Then, we are able to perform shallow
reconstruction of the ‘fake-free’ version of the DeepFake image,
which largely reduces the artifact patterns DeepFake introduces.
The comprehensive evaluation on 3 state-of-the-art DeepFake detection methods and fake images generated by 16 popular GAN-based
fake image generation techniques, demonstrates the effectiveness
of our technique. Overall, through reducing artifact patterns, our
technique significantly reduces the accuracy of the 3 state-of-theart fake image detection methods, i.e., 47% on average and up to
93% in the worst case.
Our results confirm the limitation of current fake detection methods and calls the attention of DeepFake researchers and practitioners for more general-purpose fake detection techniques.
CCS CONCEPTS
• Security and privacy →Human and societal aspects of security and privacy; • Computing methodologies →Computer
Computer vision; DeepFake; Shallow Reconstruction
INTRODUCTION
The recent advances of fake information generation draw lots of
attention and concern, with frequent and widespread media coverage and argument. Up to the present, DeepFake (e.g., fake images,
audios and videos) has become a real threat to our society due to
its realism and impact scopes. Even worse, lots of tools such as
Yihao Huang’s email: 
∗Corresponding authors. E-mail: , .
Figure 1: Before and after FakePolisher is applied: the left image is a fake
image generated from the DeepFake method . In the enlarged view, we
can easily find obvious checkerboard patterns. Corresponding to these artifacts are the bright blobs at 1/4 and 3/4 of the width/height in the spectrum
of the fake image. The artifacts are introduced by the upsampling methods
of GAN-based image generation methods. We propose a shallow reconstruction method based on dictionary learning to remove the artifacts. The right
image is the reconstructed image, which does not has obvious artifact in its
enlarged view and spectrum.
FaceApp , ZAO are available for fake image generation, further exacerbating the situation. In general, the backend techniques
of DeepFake are mostly based on generative adversarial networks
(GANs), which are used for synthesizing facial images and voices.
Many of the current state-of-the-art DeepFake techniques reach
a level that cannot be easily captured by human perceptions. For
example, it can be really hard for humans to distinguish the real
videos from faked ones only by our eyes and ears . We are
entering an era where we cannot simply trust our eyes and ears.
According to , humans detection peak accuracy reaches only
75% , where the real images are from a well-known dataset
Flicker-Faces-HQ (FFHQ) and the fake images are generated by
StyleGAN .
Although easily fooling the human, the state-of-the-art synthesized images can still be detected in many cases by current fake
detection methods. The state-of-the-art synthesized methods often
introduce artifact patterns into the image during generation, opening a chance for fake detectors . Due to the current technical
limitation, even worse, the image manipulation footprint will be
inevitably left in a synthesized image, either by partial image manipulation or full image synthesis . In particular, the
partial image manipulation methods often use convolutional and
pooling layers to transform a real image into feature maps. After
feature map modification, they have to use the upsampling method
in the decoder to amplify the feature maps into a high-resolution
fake image. Similarly, full image synthesis takes a random vector
 
Yihao Huang, et al.
Figure 2: From left to right, the original toy example and its histogram are
shown, followed by the blurred toy example and its histogram. The original
toy example contains obvious checkerboard patterns. The checkerboard patterns also exist in the blurred toy example. We can find that the blur method
can not effectively remove the checkerboard patterns.
and amplifies it with the decoder. Such inevitable manipulation
footprints leave traces for automated fake detection.
Thus far, most state-of-the-art fake image detection methods are
proposed based on convolutional neural network (CNN), which
roughly fall into three categories by their input feature types, i.e.,
image-based methods , fingerprint-based methods
 , and spectrum-based methods .
• Image-based methods adopt large and complex networks to perform fake detection, by directly working on the images as inputs.
• Fingerprint-based methods leverage both fingerprints of GAN and
images as inputs for fake detection, based on the assumption
that GANs carry certain model fingerprints, leaving stable fingerprints in their generated images. They even possibly allow us to
identify which kind of DeepFake method is used for generation.
• Spectrum-based methods find out that all GAN architectures in
the generation process leave some footprints in the frequency
domain. Therefore, they propose to leverage the spectrum information for fake detection.
These three types of methods all demonstrate their
usefulness, in achieving the state-of-the-art performance for GANsynthesized fake image detection.
We can see that the manipulation footprints during the synthesizing process open the chance for fake image detection. Existing
techniques can possibly leverage such information, from different
perspectives to different extent. Therefore, a new methodology that
reduces the footprint introduced during the synthesized process
could increase the chance of bypassing the fake detectors.
Although smoothing could be a possible way for fake footprint
reduction, we find that it is generally infeasible to effectively reduce
the footprint. For example, in Figure 2, the first image is a toy case
with checkerboard patterns, generated by the following procedures.
We first produce a checkerboard image with size 8*8. The checkerboard has two colors: white and orange. Then, we resize the image
to 64*64 by using interpolation, which simulates the operation of
upsampling. The histogram of it calculates the distribution of the
values in the gray-scale version of the toy example. The third image
is the blurred toy example. We apply a 5*5 kernel of Gaussian blur
to the toy example to obtain this image. Although the checkerboard
patterns are weakened, they still exist in the image. In the histogram
of the gray-scale blurred toy example, we can also find that the
values of peaks are regular and symmetric as that in the histogram
of the toy example. The features can be easily detected.
In this paper, we propose the FakePolisher, a shallow reconstruction method with dictionary learning to reduce such fake
footprints. In particular, we try to find the ‘closest’ representation,
free of fake patterns, of its fake image counterparts. We first train
a dictionary model to systematically capture the patterns of real
images, based on which we seek the representation of DeepFake
images in a low dimensional subspace through linear projection or
sparse coding. Then, we perform shallow reconstruction of the ‘fakefree’ version of the DeepFake image, intending to largely reduce
the manipulation footprints the DeepFake introduces. Our in-depth
evaluation on 3 state-of-the-art DeepFake detection methods and
fake images generated by 16 GAN-based methods demonstrates
that our reconstructed images successfully fool all the three types
of fake image detection methods. Although previous work does
not explicitly mention they leverage manipulation footprint for
fake image detection, our method successfully reduces the accuracy
of the 3 state-of-the-art detection techniques significantly with
an average accuracy decrease of 47%. This indicates that existing
fake detection methods highly relies on the manipulation footprint
introduced in the synthesizing phase. Our study presents a new
challenge for future fake image detection methods in the domain of
multimedia forensics, which need to look for more advanced fake
patterns beyond only the footprints introduced by the generation
The main contributions of this paper are summarized as follows.
• To reduce the footprint in GAN-synthesized fake images, we
propose a post-processing shallow reconstruction method by
using dictionary learning, which does not rely on any information
of the GAN used for generation. In other words, it can be used
as a black-box attack method to fool the fake image detectors.
• We conduct a comprehensive evaluation of our proposed approach in fooling three representative state-of-the-art of fake
image detection methods over fake images generated by 16 GANbased methods. By reducing the manipulation footprints, our
method reduces the fake detection accuracy of these methods significantly. Our reconstructed images also exhibit high similarity
to its original fake image counterpart.
• So far, it is still unknown whether existing fake detection methods
leverage the manipulation footprints and in what ways. Our
results answer this question, indicating that existing methods
can highly leverage the manipulation of footprint information
from different perspectives. Our results call for attention that
more general fake detection mechanisms should be designed.
RELATED WORK
Since its advent, GAN has been successfully applied to many
application domains, especially in the generation process for images,
natural languages, and audios, etc.
GAN-based Image Generation
Over the past several years, a lot of GAN-based image generation
methods have been proposed, largely following two categories: full
image synthesis and partial image manipulation.
Full image synthesis. Progressive growing GAN (ProGAN) is
able to synthesize high-resolution images via the incremental enhancement of the discriminator and the generator networks during
the training process. StyleGAN is an extension to the ProGAN
architecture, hovers with the ability to control over the disentangled
style properties of the generated images. StyleGAN2 fixed the
FakePolisher: Making DeepFakes More Detection-Evasive by Shallow Reconstruction
imperfection of StyleGAN to improve image quality. SNGAN 
proposes a novel weight normalization technique called spectral
normalization to stabilize the training of the discriminator. It is
capable of generating images of better or equal quality relative to
the previous training stabilization techniques. MMDGAN combines the key ideas in both generative moment matching network
(GMMN) and GAN.
Partial image manipulation. AttGAN applies an attribute classification constraint to the generated image to guarantee the correct
change of desired attributes. StarGAN simply uses a single
model to perform image-to-image translations for multiple facial
properties. STGAN simultaneously improves attribute manipulation accuracy as well as perception quality on the basis of
DeepFake Detection Methods
Tolosana et al. and Verdoliva et al. recently make comprehensive surveys on the DeepFake detection methods . Overall, they surveyed thirty-seven papers in
total, all of which are CNN-based and can be classified into three
categories depending on their feature inputs: image-based methods,
fingerprint-based methods, and spectrum-based methods. Imagebased methods directly use images as inputs with various networks
to solve the problem. Fingerprint-based methods detect DeepFake
with the features of GAN fingerprints. Spectrum-based methods
consider that DeepFake artifacts are manifested as replications of
spectra in the frequency domain. Thus they propose classifiers
based on the spectrum of fake images.
In this section, we give a more detailed discussion on the limitation
of GAN-based methods and introduce our post-processing method.
Artifact of GAN-Based Image Generation
For both partial image manipulation and full image
synthesis , the generator of GAN-based image generation
method has a decoder amplifies the random vectors or feature maps
to images. Upsampling is a significant and indispensable design in
the decoder. However, it is the upsampling design that makes the
GAN-based image generation methods limited. In general, there
are three types of upsampling methods: unpooling, transpose convolution and interpolation. It has been studied that transpose convolution results in checkerboard texture . In the amplification
procedure, unpooling operation assigns zero values to the new pixels. This regular magnification produces special textures that do
not exist in real images. For interpolation operation, at an intuitive
level, the new pixel values are calculated based on existing pixels,
which is regularity. Interpolation brings periodicity into the second derivative signal of images . Other papers also
introduced the imperfection of upsampling methods.
Shallow Reconstruction to the Rescue
In this paper, we propose FakePolisher, a post-processing method
that performs a shallow modification of fake images. Our method is
composed of three steps. First, we train a dictionary model with a
real image dataset. The learned dictionary forms a subspace that is
Figure 3: Geometric interpretation of how the shallow reconstruction works in order to bring
the DeepFake image x onto the
clean image manifold M thus
finds its ‘closest’ counterpart ˆx
on the manifold through the embedded representation y in the
embedding space L.
intrinsically low dimensional, which compactly captures the essential structures and representations of the real images. Second, we
seek the representation of a DeepFake image using the aforementioned subspace either by linear projection or sparse coding depending on the over-completeness of the learned dictionary. Third, once
such a representation is obtained, we reconstruct the ‘fake-free’
version of the DeepFake image by using the said dictionary.1
Intuitively, we are forcing the DeepFake image to find its ‘closest’
representation, on the subspace that subsequently leads to the
reconstructed version of itself free of any fake patterns. By doing
so, a shallow reconstruction can already effectively remove the fake
patterns while preserving image fidelity to the greatest extent. In
this context, deep reconstruction methods, on the contrary, can
become futile because they potentially leave traces of upsampling
artifacts as discussed above.
Geometrically, as shown in Figure 3, the learned dictionary forms
an embedding space L that could be of lower or higher dimensionality. When a DeepFake image x comes along, we seek the ‘closest’
counterpart ˆx on the clean image manifold M by first obtaining
the embedded representation y, and reconstruct back to the clean
image manifold M.
Global vs. Local Dictionary Learning
When learning the dictionary on the real images that are free of
fake patterns, one can choose to learn a local patch-based dictionary, leading to a patch-based image reconstruction; or, a global
dictionary that spans the entire image, i.e., dictionary atom is of the
same size as the image to be reconstructed. Since we can view the
global case as a local case with a large patch size, we will mainly
discuss patch-based local reconstruction in detail since it already
covers both cases. The choice between various patch sizes (local
vs. global) is largely dictated by the actual application and the type
of images that are being processed. For example, if the images are
aligned faces, it is advisable to use a global dictionary since it is
more efficient, without the need of patch-by-patch reconstruction.
On the other hand, if the images are of ImageNet type, it is more
reasonable to use a patch-based dictionary. One note is that in this
case, it is still possible to use a global dictionary, it is just we are to
foresee a drop in the reconstruction fidelity.
Next, we formulate the patch-based dictionary learning procedure. The training data (patch) matrix Y ∈Rd×n is assumed with
dimension d. All matrices have their elements arranged columnwise.
Dictionary learning methods have gained much popularity in
tackling low-level computer vision problems. One widely adopted
such an algorithm is the K-SVD . K-SVD aims to be a natural
1Throughout the paper, we use ‘clean’ to describe an image that is free of fake patterns.
‘Clean’ and ‘fake pattern-free’ are used interchangeably.
Yihao Huang, et al.
extension of K-means clustering method with the analogy that the
cluster centroids are the elements of the learned dictionary and
the cluster memberships are defined by the sparse approximations
(ℓ1 or ℓ0) of the signals in that dictionary. Formally, it provides a
solution to the problem:
subject to
∀i, ∥xi ∥0 < K (1)
where Y, D and X are the data, the learned dictionary, and the
sparse approximation matrix, respectively. Here ∥.∥0 is the pseudonorm measuring sparsity. The sparse approximations of the data
elements are allowed to have some maximum sparsity ∥x∥0 ≤K.
In addition to the K-SVD method, we also explore a ubiquitously
popular dictionary learning method: principal component analysis
(PCA) . In the original formulation of PCA, it tries to minimize
the following objective function in an ℓ2 sense. Of course, variants
of PCA such as sparse PCA or ℓ1-PCA, etc., can also fit in with ease.
Formally, PCA finds a solution to the problem:
subject to
where Y, D and X are the data, the learned dictionary (principal
components), and the dense coefficient matrix, respectively. The
regularizer in the PCA optimization ensures that the learned dictionary atoms are orthogonal, which provides maximal reconstruction
capability. The learned PCA dictionary is usually overdetermined
(or undercomplete), which provides a good complement to the
overcomplete K-SVD dictionary.
Shallow Reconstruction from Dense vs.
Sparse Representation
Once the said dictionaries are learned from real images that are
fake-pattern-free, we can project a DeepFake image patch onto the
learned subspace and obtain a new representation on the learned
manifold. The dimensionality of such a representation can be lower
or higher than the original image-domain representation depending
on the overcompleteness of the learned dictionary.
More specifically, for example, when we want to reconstruct
a single image patch y ∈Rd using learned K-SVD dictionary,
since it is overcomplete, we resort to pursuit algorithms such as
the orthogonal matching pursuit (OMP) to obtain the sparse
coefficient vector x according to the following optimization:
subject to
∀i, ∥x∥0 < τ
Note that there is a trade-off in choosing the sparsity τ while
using OMP for obtaining the sparse representation. To determine
the optimal reconstruction sparsity τ for the down-stream task, we
conduct a pilot experiment that aims at selecting a τ value that is
both relatively small (more efficient for the greedy OMP algorithm)
and provides high-quality reconstruction. Also, the sparsity τ during the OMP step is independent and different from the sparsity K
during K-SVD dictionary learning.
The shallow reconstruction is straight-forward with the learned
K-SVD dictionary D and the obtained sparse representation x. The
reconstructed image patch ˆy = Dx. The aforementioned dictionary learning and reconstruction were previously used in various
domain-domain mapping problems such as .
As a comparison, shallow reconstruction from learned PCA dictionary requires first obtaining a dense representation for the image
patch y. As discussed above, the learned PCA dictionary D is usually overdetermined, and therefore, the resulting representation
vector x on the manifold will be of lower dimensionality and dense.
The representation vector x can be obtained through a least-square
error solution in closed form which is extremely efficient:
x = (D⊤D)−1D⊤y
To further make the shallow reconstruction using PCA more
versatile, one can control what dimensions contribute more during
the reconstruction by involving a selector vector s ∈Rd that
embeds e.g., prior knowledge such as confidence or importance
of each dimension. In this case, the representation vector x can
be obtained by incorporating a diagonal selector matrix S, where
S = diag(s). The solution becomes:
ˆx = [(SD)⊤(SD)]−1(SD)⊤Sy = [D⊤S⊤SD]−1D⊤S⊤Sy
= [D⊤(S⊤S)D]−1D⊤(S⊤S)y
It can be observed that when S⊤S is close to the identity matrix I,
the ˆx is close to the original x. The same principal can be applied to
the aforementioned K-SVD sparse reconstruction. Also, the selector
vector s can be both real-numbered (dimension re-weighting) or
binary (dimension selection).
The shallow reconstruction is also straight-forward with the
learned PCA dictionary D and the obtained dense representation x,
with the reconstructed image patch ˆy = Dx.
Both K-SVD and PCA reconstructions are shallow in the sense
that they can bring back the manifold representations to the image
domain with a single-step projection. More importantly, with the
reconstruction being shallow and single-step, it does not induce
unnecessary fake patterns, as commonly found in those DeepFake
images produced or manipulated by deep generative models.
Discussion: Comparison with Denoising Autoencoder and DefenseGAN. Denoising Autoencoder (DAE) is an early attempt
for image deep reconstruction, especially for the image denoising
task. Compared to the shallow reconstruction we have discussed in
this work, DAE is usually comprised of several layers of fully connected or convolutional layers in both the encoder and the decoder,
interlaced with non-linearity.
Apart from being much deeper and non-linear, the training process of the DAE takes the noisy version of the data as input, and
the reconstructed version is then compared with the clean version,
whose discrepancy amounts to the loss that needs to be minimized
by tuning the weights in the encoder and the decoder. The model
usually works well when the input image is corrupted with the
same noise that the model has seen during the training process.
As a comparison, our shallow reconstruction method has the
following main advantages: (1) the model is shallow and linear,
which is much easier to train with little to none tuning required,
and it is much more data efficient; (2) the training only requires a
clean version of the images (as compared to the clean and noisy pairs
as in the DAE), and such reconstruction can deal with arbitrary nonclean versions of the data, be it some types of noises, or DeepFake
patterns that need to be removed.
FakePolisher: Making DeepFakes More Detection-Evasive by Shallow Reconstruction
Figure 4: The PCA dictionary
generated by us has 10,000 components. The size of each component is 224*224*3. Here we
show the images of the first ten
principal components.
Another line of recent work in the context of removing adversarial noise through deep image reconstruction is the DefenseGAN
method . The idea is to train a GAN generator based only
on clean images and any adversarially noisy image can be noiseremoved by DefenseGAN deep reconstruction. In some sense, it
seems that it can be re-purposed for reconstructing DeepFake images that are free of fake patterns. However, a major issue remains
because the deep reconstruction in the DefenseGAN also results
in fake patterns, which is something our proposed shallow reconstruction is trying hard to prevent.
EXPERIMENTS
To demonstrate the effectiveness of our shallow reconstruction,
we propose two different validation methods. One is to test the
reconstructed images on various fake image detection methods,
which indicates whether there exists some relation between these
detection methods and the artifacts (i.e., manipulation footprint).
The other is using metrics to measure the similarity between fake
images and reconstructed images, quantitatively measure our reconstructed change magnitude. These two validation methods are
able to confirm the usefulness of our method. We also give some
concrete examples to show the fake images and our reconstructed
Experimental Setup
Subject Detection Methods and Dataset: We choose three stateof-the-art fake detection methods to verify the validity of our
method, i.e., GANFingerprint (fingerprint-based method) ,
CNNDetector (image-based method) , and DCTA (spectrumbased method) . We use CelebA , LSUN , and FFHQ
 as the real image dataset. CelebA and FFHQ are the human
face dataset while LSUN includes the images of different rooms
such as classroom, bedroom, etc., which are widely used in previous work. Then, we leverage a total of 16 GAN-based methods
for fake image generation on these datasets. In particular, ProGAN
 , SNGAN , CramerGAN and MMDGAN are the
GAN-based image generation methods used by GANFingerprint
and DCTA. For each GAN-based image generation method, the
size of the testing dataset is 10,000. In CNNDetector, they choose
13 GAN-based image generation methods as the testing dataset.
The methods include ProGAN , StyleGAN , BigGAN ,
CycleGAN , StarGAN , GauGAN , CRN , IMLE ,
SITD , SAN , DeepFakes , StyleGAN2 , and Whichfaceisreal . The size of the testing dataset of these GAN-based
image generation methods range from hundreds to thousands. The
objects in the datasets of CycleGAN, ProGAN, StyleGAN and Style-
GAN2 have two or more categories. For example, in StyleGAN, it
has three different categories: bedroom, car, cat. The datasets of
other GANs have only one category.
Figure 5: The K-SVD dictionary
generated by us has 5,000 components. The size of each component is 8*8*3. The components of K-SVD dictionary are
not sequenced. Thus we randomly show images of 32 components.
Figure 6: In the first row, the images in turn are the fake image produced by
StyleGAN , PCA reconstructed image and K-SVD reconstructed image. In
the second row, the images in turn are the fake image produced by SNGAN
 , PCA reconstructed image and K-SVD reconstructed image.
Evaluation Settings: For PCA reconstruction, we use 50,000
real human images of CelebA to train the PCA dictionary model.
The component number of PCA dictionary model is 10,000. For
K-SVD reconstruction, we use 100,000 patches to train a K-SVD
model of 5,000 components. Each patch is of size 8*8, clipped from
real images of CelebA. The number of nonzero coefficients in the
training procedure is 15. In K-SVD reconstruction, we drop 10%
pixels of the fake image before reconstruction. This is an important
procedure in K-SVD reconstruction for that it can destroy the fake
textures of the fake images. What’s more, it needs a lot of time to
produce one K-SVD image. Therefore, we choose 200 of the 5,000
components of the K-SVD dictionary to reconstruct fake images.
The reconstructed images of using 200 or 5,000 components are
similar while the reconstruction time is significantly reduced. In
the reconstructing procedure, the number of nonzero coefficients is
20. The graphical representation of the PCA dictionary and K-SVD
dictionary are shown in Figure 4 and Figure 5.
Metrics: The main metric is the detection accuracy of the methods. We compare the detection accuracy of fake images and reconstructed images for each method. In addition, we also use cosine
similarity (COSS), peak signal-to-noise ratio (PSNR) and structural
similarity (SSIM) for measuring the similarity between fake image
and its corresponding reconstructed image. COSS is a common similarity metric that measures the cosine of the angle. We transform
the RGB images to vectors before calculating COSS. PSNR is the
most commonly used measurement for the reconstruction quality
of lossy compression. SSIM is one of the most popular and useful
metrics for measuring the similarity between two images. COSS,
PSNR and SSIM metrics are better if a higher value is provided. The
value ranges of COSS and SSIM are both in .
All the experiments were run on a Ubuntu 16.04 system with an
Intel(R) Xeon(R) CPU E5-2699 with 196 GB of RAM, equipped with
four Tesla V100 GPU of 32G RAM.
Yihao Huang, et al.
Figure 7: In the first row, the images in turn are a real image from CelebA, a
fake image produced by StarGAN , PCA reconstructed image and K-SVD
reconstructed image. In the second row, the images are the spectrum corresponding to the images above. As mentioned, the GAN-synthesised images have obvious artifacts in the frequency spectrum. In the spectrum of the
fake image, there are bright blobs at 1/4 and 3/4 of the width/height. In the
spectrum of reconstructed images, the artifact does not exist. This means that
our method effectively reduces fake texture from the fake image.
Examples of Reconstructed Image
Figure 6 gives the reconstructed image examples of our method,
on a cat and a human, respectively. In the second row, PCA and
K-SVD reconstruct the fake image successfully. In the first row,
we can see that the fidelity of PCA reconstructed image is not as
good as K-SVD reconstructed image. The reason is that the PCA
dictionary we used is trained by real images of humans instead of
cats. Thus, this suggests using K-SVD to reconstruct fake images if
PCA dictionary with the same category is not available.
To analyze whether the reconstructed images contain artifacts
(i.e., manipulation footprints), we analyze the spectrums of the real
image, fake image, PCA reconstructed image, K-SVD reconstructed
image (see Figure 7). We can observe that only the spectrum of the
fake image has bright blobs at 1/4 and 3/4 of the width/height. The
blobs correspond to the manipulation footprints in the fake image.
We also verified that the PCA and K-SVD reconstruction methods
can reduce artifacts on other types of images such as cat, bedroom,
GANFingerprint
In the original experiment of GANFingerprint, their method
can successfully detect whether an input image is real or fake with
high accuracy. It can even judge which GAN-based image generation method is used to produce the fake image. In our experiment,
we randomly choose 10,000 real images from CelebA. Then, for
each GAN-based image generation method (i.e., ProGAN, SNGAN,
CramerGAN, MMDGAN), we produce 10,000 fake images, resulting
in a total of 40,000. For each of PCA and K-SVD reconstruction
method, we produce 40,000 images from these 40,000 fake images.
Table 1 summarizes the detailed detection accuracy of GAN-
Fingerprint. We use ProGAN as an example to explain the data
in Table 1 (i.e., columns 2-6, rows 2-4). For ProGAN (Pro), it has
five sub-items (columns): CelebA, ProGAN (Pro), SNGAN (SN),
CramerGAN (Cramer), MMDGAN (MMD). They represent the possibility that the input ProGAN fake images be considered as one of
them. Fake, PCA-reconstructed and K-SVD-reconstructed represent the type of input images. The row of Fake shows the results
with fake images as inputs. As we can see, GANFingerprint can
accurately classify the 10,000 images generated by ProGAN into
subitem ProGAN with a detection accuracy of 99.91%. In the table,
we highlight the difference in detection accuracy between reconstructed images and fake images (e.g., by color and number). For
example, in the row PCA-reconstructed, when we put the 10,000
PCA-reconstructed images into GANFingerprint, it misclassifies
most of the images into CelebA (i.e., real images). The ratio of images classified into CelebA raises from 0.03% to 88.90%. We use blue
color and (+88.87) to highlight the difference. Similarly, the ratio
of images classified into Pro decreases from 99.91% to 6.99%. We
use red color and (-92.92) to show the difference. We can see that
most of the fake images generated by ProGAN are misclassifies to
be real images after our shallow reconstruction.
Similar conclusions could also be reached for the other three
GAN-based image generation methods. PCA reconstruction reduces
all of their classification accuracy effectively. K-SVD reconstruction
also reduces the accuracy. The attack by PCA reconstruction shows
slightly higher results compared with K-SVD reconstruction.
Table 2 shows the similarity between the fake images and reconstructed images. For both PCA and K-SVD, we use COSS, PSNR
and SSIM as the metrics for similarity measurement. In the column
of ProGAN, we can see that the values of COSS and SSIM are near
1.0, and the value of PSNR is more than 30, indicating high similarity. Likewise, for the other three GAN-based image generation
methods, the reconstructed images are also very similar to the fake
image counterparts. Compared with PCA reconstruction, images
by K-SVD show higher similarity to original fake images.
As mentioned above, DCTA has a same testing dataset as GAN-
Fingerprint. In the original experiment of DCTA, it transformed
the images into spectrum images before classification. We follow
the exact same evaluation setting, except that we use the reconstructed images to replace the fake images. Overall, the number of
testing images in our experiment is 48,000. Each category of CelebA,
ProGAN, SNGAN, CramerGAN, MMDGAN, has 9,600 images. The
PCA-reconstructed and K-SVD-reconstructed images used are the
same as that in GANFingerprint. The number of reconstructed
images is also 48,000. Table 3 summarizes detection accuracy decrease. When using PCA-reconstruction, the accuracy decreases
from 88.99% to 16.42%. Similarly, 20.44% accuracy decreases when
using K-SVD. The experimental results demonstrate the effectiveness of reconstructed images in misleading the fake detectors.
CNNDetector
In CNNDetector, it is evaluated on a large number of 13 GANbased image generation methods. In their original experiments, the
objects in the images are very different, containing animals, human
faces, road, etc. For each GAN-based image generation method, the
size of the testing dataset ranges from hundreds to thousands. They
use detection accuracy and average precision (AP) as the metrics,
on the same number of fake images and real images as the testing
dataset. We follow the same evaluation setting, except replacing
fake images with reconstructed images by our methods.
FakePolisher: Making DeepFakes More Detection-Evasive by Shallow Reconstruction
Table 1: Detection accuracy before & after reconstruction of GAN-synthesized images in GANFingerprint
Accuracy(%)
ProGAN (Pro)
SNGAN (SN)
PCA-reconstructed
88.90 (+88.87)
6.99 (-92.92)
0.21 (+0.20)
0.07 (+0.04)
3.83 (+3.81)
46.10 (+46.03)
0.12 (+0.11)
50.86 (-48.89)
0.16 (+0.11)
2.76 (+2.64)
K-SVD-reconstructed
21.50 (+21.47)
78.10 (-21.81)
0.10 (+0.09)
0.20 (+0.17)
0.10 (+0.08)
48.15 (+48.08)
4.60 (+4.59)
46.35 (-53.40)
0.60 (+0.55)
0.30 (+0.18)
Accuracy(%)
CramerGAN (Cramer)
MMDGAN (MMD)
PCA-reconstructed
54.85 (+54.85)
0.35 (+0.33)
0.93 (+0.91)
35.07 (-64.69)
8.80 (+8.60)
45.94 (+45.83)
0.13 (+0.12)
0.20 (+0.16)
0.03 (-0.24)
53.70 (-45.87)
K-SVD-reconstructed
28.70 (+28.70)
14.90 (+14.88)
0.10 (+0.08)
55.60 (-44.16)
0.70 (+0.50)
47.40 (+47.29)
14.20 (+14.19)
0.30 (+0.26)
0.70 (+0.43)
37.40 (-62.17)
Table 2: Similarity between fake image & reconstructed image of GANs in
GANFingerprint & DCTA
Table 3: Detection accuracy before & after reconstruction of GAN-synthesized
images in DCTA
Accuracy(%)
PCA-reconstructed
16.42 (-72.57)
K-SVD-reconstructed
20.44 (-68.55)
As we can see in Table 4, the two models used by CNNDetector:
blur_jpg_prob0.1 (prob0.1) and blur_jpg_prob0.5 (prob0.5) achieve
high accuracy. For convenience, we only introduce the data of using
blur_jpg_prob0.1. In the first row, Real & Fake means using real
images and fake images as the testing dataset (i.e., the same testing
dataset as used in CNNDetector).
To show the detection accuracy of real images and fake images,
we conduct extra experiments on real images and fake images
respectively. As shown in the second and third row, the testing
datasets are Real images only and Fake images only. In the second
row, we can observe that the model performs well. However, in
the third row, the performance of the model of CNNDetector is
different in various GAN-based image generation methods. It has
various performance drops on SAN and DeepFakes although it
achieves high accuracy on GANs, e.g., ProGAN, StarGAN, CRN.
For PCA reconstruction of our method, we produce a corresponding reconstructed image for each fake image in the testing dataset.
For K-SVD reconstruction, it needs a lot of time to produce one
K-SVD image. Thus for each category of each GAN-based image
generation method, we choose 100 fake images and produce 100
corresponding K-SVD reconstructed images. No matter the detection accuracy of fake images, the reconstructed images generated
by us can reduce its performance.
As we can see in the fourth and fifth row, the testing datasets
are PCA-reconstructed images and K-SVD-reconstructed images
respectively. Compared to the detection accuracy of that on fake
images, most of them are both decreased. Only the accuracy of
SAN increases slightly. In the experiment of blur_jpg_prob0.5, all
the detection accuracy decrease. The similarity of PCA/K-SVD
reconstructed images and fake images is shown in Table 5. The
images of CycleGAN, StyleGAN, StyleGAN2 and ProGAN have
quite a few different categories. For these four multi-category GANs,
they use different folders to store different categories of images.
In the other nine GANs, some of them involve only one category
(DeepFakes, IMLE, StarGAN, Whichfaceisreal, CRN). The others
combine images of different categories into one folder. We call these
GANs (BigGAN, GauGAN, SAN, SITD) uncertain-category and use
‘-’ to represent the category.
Comparison Between Partial and Full
Reconstruction
Sometimes, fake images are produced by only modifying parts of
the real images. For example, DeepFake methods may change the
hair color of a person or the color of a chair in the bedroom. For
these situations, we propose partial reconstruction.
In the GANs of GANFingerprint, DCTA and CNNDetection,
only StarGAN have partially modified fake images. Therefore, we
use StarGAN to show the comparison between partial reconstruction and full reconstruction. The numbers of real images and fake
images of StarGAN are 1,999. We produce 1,999 reconstructed images for partial and full reconstruction of PCA. We also produce
100 reconstructed images for K-SVD. Since it needs a lot of time to
produce K-SVD images, the number of K-SVD reconstructed images
is not as large as that of PCA reconstructed images.
For each of GANFingerprint and DCTA, we train a binary
classification model with real images from CelebA and partially
modified fake images from StarGAN.
Table 6 summarizes the detection accuracy of fully reconstructed
images and partially reconstructed images on three different types
of fake detectors. Compared with full reconstruction, the detection
accuracy of all the three fake detectors decrease similarly in partial reconstruction for both PCA and K-SVD. Table 7, shows the
similarity metrics between reconstructed images and the original
fake images. We can observe that the similarity of fake images and
partial reconstruction is higher than that of fake images and full
reconstruction.
To sum up, compared with fully reconstructed images, the partially reconstructed images are more similar to their original fake
counterparts. Meanwhile, in terms of degrading the performance
of fake detectors, their abilities are close, indicating the advantage
of partial reconstruction for partially modified fake images.
Yihao Huang, et al.
Table 4: Detection accuracy before & after reconstruction of GAN-synthesized images in CNNDetecion
Accuracy(%)/AP
Whichfaceisreal
Real & Fake
42.3 (-57.6)/- 3.90 (-70.3)/- 12.3 (-34.5)/- 35.8 (-43.0)/- 36.0 (-50.7)/- 14.2 (-50.6)/- 6.50 (-93.3)/- 19.4 (-80.4)/- 3.89 (-82.8)/- 3.20 (+1.37)/- 1.33 (-5.53)/- 11.9 (-56.9)/-
1.40 (-72.9)/-
94.9 (-5.0)/-
33.7 (-40.5)/- 30.0 (-16.8)/- 68.7 (-10.1)/- 48.0 (-38.7)/- 51.0 (-13.8)/- 79.0 (-20.8)/- 88.0 (-11.8)/- 45.0 (-41.7)/-
8.0 (+6.17)/-
0.00 (-6.86)/- 33.5 (-35.3)/-
50.0 (-24.3)/prob0.5
Real & Fake
71.6 (-28.4)/- 3.00 (-43.9)/- 6.45 (-12.5)/- 30.9 (-32.0)/- 42.1 (-20.6)/- 22.8 (-36.4)/- 4.36 (-71.6)/- 16.7 (-72.2)/- 1.12 (-62.8)/-
0.00 (0)/-
1.89 (-0.61)/- 6.84 (-30.1)/-
0.70 (-27.9)/-
96.7 (-3.30)/- 20.7 (-26.2)/- 9.00 (-9.90)/- 44.2 (-18.7)/- 37.0 (-25.7)/- 44.0 (-15.2)/- 22.0 (-54.0)/- 60.0 (-28.9)/- 36.0 (-27.9)/-
0.00 (0)/-
2.00 (-0.50)/- 13.0 (-23.9)/-
18.0 (-10.6)/-
Table 5: Similarity between fake image & reconstructed image of GANs in CNNDetection
BigGan DeepFakes
GauGAN IMLE
Whichfaceisreal
horse zebra winter orange apple summer bedroom
horse church
0.999 0.989 0.987
0.994 0.998 0.997
0.995 0.999
32.72 25.29 29.29
25.98 32.47 29.91
27.22 34.70
0.945 0.821 0.886
0.844 0.933 0.899
0.864 0.954
0.999 0.999 0.991
0.999 0.999 0.999
0.999 0.999
39.58 36.51 31.38
33.50 34.93 34.24
34.34 37.35
0.986 0.986 0.962
0.971 0.973 0.969
0.973 0.980
airplane motorbike tvmonitor horse
pottedplant
diningtable
sheep bottle person
0.996 0.998 0.995
0.997 0.997 0.996
0.995 0.998
27.94 29.61 27.49
30.39 29.16 27.94
26.68 31.13
0.883 0.991 0.884
0.917 0.899 0.880
0.867 0.932
0.999 0.999 0.998
0.999 0.998 0.998
0.998 0.999
32.49 32.94 32.01
33.90 32.82 31.88
31.37 37.49
0.968 0.970 0.970
0.973 0.968 0.964
0.965 0.985
Table 6: Comparison of detection accuracy between partial reconstruction
and full reconstruction
Accuracy(%)
GANFingerprint
CNNDetection(0.1) CNNDetection(0.5)
92.6 (-7.0)
65.2 (-10.9)
36.0 (-50.7)
42.1 (-20.6)
partially PCA
92.5 (-7.1)
64.7 (-11.4)
26.0 (-60.7)
36.6 (-26.1)
fully K-SVD
87.0 (-12.6)
40.0 (-36.1)
48.0 (-38.7)
37.0 (-25.7)
partially K-SVD
87.0 (-12.6)
38.9 (-37.2)
52.0 (-34.7)
35.0 (-27.7)
Table 7: Similarity comparison between partial reconstruction and full reconstruction
fully PCA-reconstructed
partially PCA-reconstructed
fully K-SVD-reconstructed
partially K-SVD-reconstructed
CONCLUSIONS
In the paper, we propose the FakePolisher, a post-processing shallow reconstruction method based on dictionary learning without knowing any information of the GAN. The reconstructed images can easily fool the existing state-of-the-art detection methods.
We also demonstrate that the existing detection methods are limited, which highly rely on the imperfection of upsampling methods. More powerful defense mechanisms for DeepFakes should be
proposed. In future work, we plan to propose new methods that
can remove the artifacts in fake images. Moreover, other shallow
methods such as the ones based on advanced correlation filters
 are also potentially viable solutions to
this problem, which we intend to explore further.