Saliency Optimization from Robust Background Detection
Wangjiang Zhu∗
Tsinghua University
 
Shuang Liang†
Tongji University
 
Yichen Wei, Jian Sun
Microsoft Research
{yichenw, jiansun}@microsoft.com
Recent progresses in salient object detection have exploited the boundary prior, or background information, to
assist other saliency cues such as contrast, achieving stateof-the-art results. However, their usage of boundary prior
is very simple, fragile, and the integration with other cues
is mostly heuristic. In this work, we present new methods
to address these issues. First, we propose a robust background measure, called boundary connectivity. It characterizes the spatial layout of image regions with respect to
image boundaries and is much more robust. It has an intuitive geometrical interpretation and presents unique beneﬁts that are absent in previous saliency measures. Second, we
propose a principled optimization framework to integrate
multiple low level cues, including our background measure,
to obtain clean and uniform saliency maps. Our formulation is intuitive, efﬁcient and achieves state-of-the-art results on several benchmark datasets.
1. Introduction
Recent years have witnessed rapidly increasing interest
in salient object detection . It is motivated by the importance of saliency detection in applications such as object
aware image retargeting , image cropping and
object segmentation . Due to the absence of high level knowledge, all bottom up methods rely on assumptions
about the properties of objects and backgrounds. The most
widely utilized assumption is that appearance contrasts between objects and their surrounding regions are high. This
is called contrast prior and is used in almost all saliency
methods .
Besides contrast prior, several recent approaches exploit boundary prior , i.e., image boundary regions are mostly backgrounds, to enhance saliency computation. Such methods achieve state-of-the-art results, suggesting that boundary prior is effective. However, we ob-
∗This work was done while Wangjiang Zhu was an intern at Microsoft
Research Asia.
†Corresponding author.
serve two drawbacks. The ﬁrst is they simply treat all image
boundary as background. This is fragile and may fail even
when the object only slightly touches the boundary. The
second is their usage of boundary prior is mostly heuristic.
It is unclear how it should be integrated with other cues for
saliency computation.
This work presents new methods to address the above two problems. Our ﬁrst contribution is a novel and reliable
background measure, called boundary connectivity. Instead
of assuming the image boundary is background , or
an image patch is background if it can easily be connected to the image boundary , the proposed measure states
that an image patch is background only when the region it
belongs to is heavily connected to the image boundary. This
measure is more robust as it characterizes the spatial layout
of image regions with respect to image boundaries. In fact, it has an intuitive geometrical interpretation and thus is
stable with respect to image content variations. This property provides unique beneﬁts that are absent in previously
used saliency measures. For instance, boundary connectivity has similar distributions of values across images and are
directly comparable. It can detect the background at a high
precision with decent recall using a single threshold. It naturally handles purely background images without objects.
Speciﬁcally, it can signiﬁcantly enhance traditional contrast
computation. We describe and discuss this in Section 3.
It is well known that the integration of multiple low level cues can produce better results. Yet, this is usually done
in heuristic ways , e.g., weighted summation
or multiplication. Our second contribution is a principled
framework that regards saliency estimation as a global optimization problem. The cost function is deﬁned to directly achieve the goal of salient object detection: object regions are constrained to take high saliency using foreground
cues; background regions are constrained to take low saliency using the proposed background measure; a smoothness
constraint ensures that the saliency map is uniform on ﬂat
All constraints are in linear form and the optimal saliency map is solved by efﬁcient least-square optimization. Our optimization framework combines low level
cues in an intuitive, straightforward and efﬁcient manner.
This makes it fundamentally different from complex CR-
F/MRF optimization methods that combine multiple saliency maps , or those adapted from other optimization
problems . Section 4 describes our optimization
In Section 5, extensive comparisons on several benchmark datasets and superior experimental results verify the
effectiveness of the proposed approach.
2. Related Work
Another research direction for visual saliency analysis aims to predict human visual attention areas. Such works are more inspired by biological
visual models and are evaluated on sparse human eye ﬁxation data instead of object/background labelings. We do not
discuss such works due to these differences. In the following we brieﬂy review previous works from the two viewpoints of interest in this paper: the usage of boundary prior
and optimization methods for salient object detection.
Some early works use the so called center prior to bias
the image center region with higher saliency. Usually, center prior is realized as a gaussian fall-off map. It is either
directly combined with other cues as weights , or
used as a feature in learning-based methods . This
makes strict assumptions about the object size and location in the image.
From an opposite perspective, recent
works introduce boundary prior and treat image
boundary regions as background. In , the contrast against
the image boundary is used as a feature in learning. In ,
saliency estimation is formulated as a ranking and retrieval
problem and the boundary patches are used as background
queries. In , an image patch’s saliency is deﬁned as
the shortest-path distance to the image boundary, observing that background regions can easily be connected to the
image boundary while foreground regions cannot. These
approaches work better for off-center objects but are still
fragile and can fail even when an object only slightly touches the boundary1. In contrast, the proposed new method
takes more spatial layout characteristics of background regions into consideration and is therefore more robust.
Most methods implement and combine low level cues
heuristically.
Recently, a few approaches have adopted
more principled global optimization.
In , multiple
saliency maps from different methods are aggregated into
a better one. Similarly, in , saliency maps computed on
multiple scales of image segmentation are combined. These
methods adopt a complex CRF/MRF formulation and the
process is usually slow. The work in treats salient objects as sparse noises and solves a low rank matrix recovery problem instead. The work in ranks the similarity
1A simple “1D-saliency” method is proposed in to alleviate this
problem, but it is highly heuristic and not robust. See for more details.
Figure 1. (Better viewed in color) An illustrative example of
boundary connectivity. The synthetic image consists of four regions with their boundary connectivity values (Eq.(1)) overlaid.
The boundary connectivity is large for background regions and small for object regions.
of image patches via graph-based manifold ranking. The
work in models salient region selection as the facility
location problem and maximizes the sub-modular objective
function. These methods adapt viewpoints and optimization techniques from other problems for saliency estimation. Unlike all the aforementioned methods, our optimization directly integrates low level cues in an intuitive and effective manner.
3. Boundary Connectivity:
a Robust Background Measure
We ﬁrst derive our new background measure from a conceptual perspective and then describe an effective computation method. We further discuss the unique beneﬁts originating from its intuitive geometrical interpretation.
3.1. Conceptual Deﬁnition
We observe that object and background regions in natural images are quite different in their spatial layout, i.e., object regions are much less connected to image boundaries
than background ones. This is exempliﬁed in Figure 1. The
synthetic image consists of four regions. From human perception, the green region is clearly a salient object as it is
large, compact and only slightly touches the image boundary. The blue and white regions are clearly backgrounds as
they signiﬁcantly touch the image boundary. Only a small
amount of the pink region touches the image boundary, but
as its size is also small it looks more like a partially cropped
object, and therefore is not salient.
We propose a measure to quantify how heavily a region
R is connected to the image boundaries, called boundary
connectivity. It is deﬁned as
BndCon(R) = |{p|p ∈R, p ∈Bnd}|
|{p|p ∈R}|
where Bnd is the set of image boundary patches and p is
an image patch. It has an intuitive geometrical interpretation: it is the ratio of a region’s perimeter on the boundary to the region’s overall perimeter, or square root of its
area. Note that we use the square root of the area to achieve
scale-invariance: the measure remains stable across different image patch resolutions. As illustrated in Figure 1, the
boundary connectivity is usually large for background regions and small for object regions.
3.2. Effective Computation
The deﬁnition in Eq.(1) is intuitive but difﬁcult to compute because image segmentation itself is a challenging and
unsolved problem. Using a hard segmentation not only involves the difﬁcult problem of algorithm/parameter selection, but also introduces undesirable discontinuous artifacts
along the region boundaries.
We point out that an accurate hard image segmentation
is unnecessary. Instead, we propose a “soft” approach. The
image is ﬁrst abstracted as a set of nearly regular superpixels using the SLIC method . Empirically, we ﬁnd 200
superpixels are enough for a typical 300∗400 resolution image. Superpixel result examples are shown in Figure 5(a).
We then construct an undirected weighted graph by connecting all adjacent superpixels (p, q) and assigning their
weight dapp(p, q) as the Euclidean distance between their
average colors in the CIE-Lab color space. The geodesic
distance between any two superpixels dgeo(p, q) is deﬁned
as the accumulated edge weights along their shortest path
on the graph
dgeo(p, q) =
p1=p,p2,...,pn=q
dapp(pi, pi+1)
For convenience we deﬁne dgeo(p, p) = 0. Then we
deﬁne the “spanning area” of each superpixel p as
geo(p, pi)
where N is the number of superpixels.
Eq.(3) computes a soft area of the region that p belongs
to. To see that, we note the operand S(p, pi) in the summation is in (0, 1] and characterizes how much superpixel pi
contributes to p’s area. When pi and p are in a ﬂat region,
dgeo(p, pi) = 0 and S(p, pi) = 1, ensuring that pi adds a
unit area to the area of p. When pi and p are in different
regions, there exists at least one strong edge (dapp(∗, ∗) ≫
3σclr) on their shortest path and S(p, pi) ≈0, ensuring that
pi does not contribute to p’s area. Experimentally, we ﬁnd
that the performance is stable when parameter σclr is within
 . We set σclr = 10 in the experiments.
Similarly, we deﬁne the length along the boundary as
Lenbnd(p) =
S(p, pi) · δ(pi ∈Bnd)
Figure 2. (Better viewed in color) Enhancement by connecting image boundaries: (a) input image; (b) boundary connectivity without linking boundary patches; (c) improved boundary connectivity
by linking boundary patches.
where δ(·) is 1 for superpixels on the image boundary and
0 otherwise.
Finally we compute the boundary connectivity in a similar spirit as in Eq.(1),
BndCon(p) = Lenbnd(p)
We further add edges between any two boundary superpixels. It enlarges the boundary connectivity values of background regions and has little effect on the object regions.
This is useful when a physically connected background region is separated due to occlusion of foreground objects, as
illustrated in Figure 2.
To compute Eq.(5), the shortest paths between all superpixel pairs are efﬁciently calculated using Johnson’s algorithm as our graph is very sparse. For 200 superpixels,
this takes less than 0.05 seconds.
3.3. Unique Beneﬁts
The clear geometrical interpretation makes boundary
connectivity robust to image appearance variations and stable across different images. To show this, we plot the distributions of this measure on four benchmarks on ground truth
object and background regions, respectively, in Figure 3.
This clearly shows that the distribution is stable across different benchmarks. The objects and backgrounds are clearly separated. Most background superpixels have values > 1
and most object superpixels have values close to 0.
This property provides unique beneﬁts that are absent in
previous works. As shown in Table 1, when using a single threshold of 2, the proposed measure can detect backgrounds with very high precision and decent recall on all
datasets. By contrast, previous saliency measures are incapable of achieving such good uniformity, since they are
usually more sensitive to image appearance variations and
vary signiﬁcantly across images. The absolute value of previous saliency measures is therefore much less meaningful.
Moreover, an interesting result is that our measure can
naturally handle pure background images, while previous
methods cannot, as exempliﬁed in Figure 4.
Boundary Connectivity
background
Boundary Connectivity
background
Boundary Connectivity
background
Boundary Connectivity
background
Figure 3. (Better viewed in color) The distribution of boundary connectivity of ground truth object and background regions on four
benchmarks. From left to right: ASD , MSRA , SED1 and SED2 . Note that we use different y-axis scales for object
and background for better visualization.
Boundary Connectivity
Geodesic Saliency
Table 1. Background precision/recall for superpixels with boundary connectivity > 2 on four benchmarks. For comparison, we
treat geodesic saliency as a background measure and show its
recall at the same precision. Note, on SED1 and SED2, we cannot
obtain the same high precision, so the max precision is given.
Background Weighted Contrast
This highly reliable
background measure provides useful information for saliency estimation. Speciﬁcally, we show that it can greatly enhance the traditional contrast computation.
Many works use the region contrast against its surroundings as a saliency cue, which is computed as the summation
of its appearance distance to all other regions, weighted by
their spatial distances . In this fashion, a
superpixel’s contrast in our notation can be written as
dapp(p, pi)wspa(p, pi)
where wspa(p, pi) = exp(−
). dspa(p, pi) is the
distance between the centers of superpixel p and pi, and
σspa = 0.25 as in .
We extend Eq. (6) by introducing a background probability wbg
as a new weighting term. The probability wbg
mapped from the boundary connectivity value of superpixel
pi. It is close to 1 when boundary connectivity is large, and
close to 0 when it is small. The deﬁnition is
= 1 −exp(−BndCon2(pi)
We empirically set σbndCon = 1. Our results are insensitive
to this parameter when σbndCon ∈[0.5, 2.5].
The enhanced contrast, called background weighted contrast, is deﬁned as
dapp(p, pi)wspa(p, pi)wbg
Figure 4. (Better viewed in color) A pure background image case.
(a) input image. (b) result of one of the state-of-the-art methods . It is hard to tell whether the detected salient regions are
really salient. (c) boundary connectivity, clearly suggesting that
there is no object as all values > 2.
According to Eq.(8), the object regions receive high wbg
from the background regions and their contrast is enhanced.
On the contrary, the background regions receive small wbg
from the object regions and the contrast is attenuated. This
asymmetrical behavior effectively enlarges the contrast difference between the object and background regions. Such
improvement is clearly observed in Figure 5. The original
contrast map (Eq.(6) and Figure 5(b)) is messy due to complex backgrounds. With the background probability map
as weights (Figure 5(c)), the enhanced contrast map clearly
separates the object from the background (Figure 5(d)). We
point out that, this is only possible with our highly reliable
background detection.
The background probability in Eq.(7) and the enhanced
contrast in Eq.(8) are complementary as they characterize
the background and the object regions, respectively. Yet,
both are still bumpy and noisy.
In the next section, we
present a principled framework to integrate these measures
and generate the ﬁnal clean saliency map, as in Figure 5(e).
4. Saliency Optimization
To combine multiple saliency cues or measures, previous works simply use weighted summation or multiplication. This is heuristic and hard for generalization. Also, although the ideal output of salient object detection is a clean
binary object/background segmentation, such as the widely
used ground truth in performance evaluation, most previous
methods were not explicitly developed towards this goal.
In this work, we propose a principled framework that intuitively integrates low level cues and directly aims for this
Figure 5. The pipeline of our method. (a) input images with superpixel boundaries overlaid. (b) contrast maps using Eq.(6). Note that
certain background regions have higher contrast than object regions. (c) background probability weight in Eq.(7); (d) background weighted
contrast using Eq.(8). The object regions are more highlighted. (e) optimized saliency maps by minimizing Eq.(9). (f) ground truth.
goal. We model the salient object detection problem as the
optimization of the saliency values of all image superpixels. The objective cost function is designed to assign the
object region value 1 and the background region value 0,
respectively. The optimal saliency map is then obtained by
minimizing the cost function.
Let the saliency values of N superpixels be {si}N
cost function is thus deﬁned as
background
i (si −1)2
foreground
wij(si −sj)2
smoothness
The three terms deﬁne costs from different constraints.
The background term encourages a superpixel pi with large
background probability wbg
(Eq. (7)) to take a small value
si (close to 0). As stated above, wbg
is of high accuracy
derived from our reliable and stable background detection.
Similarly, the foreground term encourages a superpixel pi with large foreground probability wfg
to take a large
value si (close to 1). Note that for wfg
we can essentially use any meaningful saliency measure or a combination
of them. In Figure 8, we compare several state-of-the-art
methods as well as the background weighted contrast in Eq.(8) as a simple baseline (all normalized to for each
image). Surprisingly we found out that although those measures have very different accuracies, after optimization they
all improve signiﬁcantly, and to a similar accuracy level.
This is due to our proposed background measure and the
optimization framework.
The last smoothness term encourages continuous saliency values.
For every adjacent superpixel pair (i, j), the
weight wij is deﬁned as
wij = exp(−d2
app(pi, pj)
It is large in ﬂat regions and small at region boundaries.
Note that σclr is deﬁned in Eq.(3). The parameter µ is a
small constant (empirically set to 0.1) to regularize the optimization in cluttered image regions. It is useful to erase
small noise in both background and foreground terms.
The three terms are all squared errors and the optimal
saliency map is computed by least-square. The optimization takes 3 millisecond for 200 superpixels in our tests.
This is much more efﬁcient than previous CRF/MRF based
optimization methods . Figure 5 shows the optimized results.
5. Experiments
We use the standard benchmark datasets: ASD , M-
SRA , SED1 and SED2 . ASD is widely
used in almost all methods and is relatively simple. The
other three datasets are more challenging. MSRA contains many images with complex backgrounds and low contrast objects. SED1 and SED2 contain objects of largely
different sizes and locations. Note that we obtain the pixelwise labeling of the MSRA dataset from .
For performance evaluation, we use standard precisionrecall curves (PR curves). A curve is obtained by normalizing the saliency map to , generating binary masks
with a threshold sliding from 0 to 255, and comparing the
binary masks against the ground truth. The curves are then
averaged on each dataset.
Although commonly used, PR curves are limited in that
they only consider whether the object saliency is higher than
the background saliency. Therefore, we also introduce the
mean absolute error (MAE) into the evaluation. It is the average per-pixel difference between the binary ground truth
and the saliency map, normalized to . It directly measures how close a saliency map is to the ground truth and is
more meaningful for applications such as object segmentation or cropping. This measure is also used in recent meth-
Figure 6. Comparison of PR curves (left) and MAE (right) on AS-
D dataset. Note that we use wCtr∗to denote the optimized
version of wCtr using Eq.( 9).
ods and found complementary to PR curves.
We compare with the most recent state-of-the-art
including saliency ﬁlter(SF) ,
saliency(GS-SP, short for GS) , soft image abstraction(SIA) , hierarchical saliency(HS) and manifold
ranking(MR) . Among these, SF and SIA combine low level cues in straightforward ways; GS and M-
R use boundary prior; HS and MR use global
optimization and are the best algorithms up to now. There
are many other methods, and their results are mostly inferior
to the aforementioned methods. The code for our algorithm
and other algorithms we implement is all available online.
Validation of the proposed approach To verify the effectiveness of the proposed boundary connectivity measure
and saliency optimization, we use the standard dataset AS-
D. Results in Figure 6 show that 1) boundary connectivity
already achieves decent accuracy2; 2) background weighted
contrast (Eq.(8)) is much better than the traditional one (Eq.(6)); 3) optimization signiﬁcantly improves the previous
two cues. Similar conclusions are also observed on other
datasets but omitted here for brevity.
To show the robustness of boundary connectivity, we
compare with two methods that also use boundary prior
(GS and MR ). We created a subset of 657 images
from MSRA , called MSRA-hard, where objects touch
the image boundaries. Results in Figure 7 show 1) boundary connectivity already exceeds GS ; 2) the optimized
result is signiﬁcantly better than MR .
Integration and comparison with state-of-the-art As
mentioned in Section 4, our optimization framework can
integrate any saliency measure as the foreground term. Figure 8 reports both PR curves and MAEs for various saliency
methods on four datasets, with before and after optimization
compared. Both PR curves and MAEs show that all methods are signiﬁcantly improved to a similar performance level. The big improvements clearly verify that the proposed
background measure and optimization is highly effective.
Especially, we ﬁnd that our weighted contrast (Eq.(8)) can
lead to performances comparable to using other sophisticated saliency measures, such as . This is very mean-
2We normalize and inverse the boundary connectivity map and use it as
a saliency map.
Figure 7. PR curves (left) and MAE (right) on MSRA-hard dataset.
Table 2. Comparison of running time (seconds per image)
ingful when the simplicity and efﬁciency of the weighted
contrast is considered.
Example results of previous methods (no optimization)
and our optimization using background weighted contrast
are shown in Figure 9.
Running time In Table 2, we compare average running
time on ASD with other state-of-the-art algorithms
mentioned above. We implement GS and MR on
our own, and use the authors’ code for other algorithms. For
GS , we use the same superpixel segmentation , resulting smaller time cost as reported in .
6. Conclusions
We present a novel background measure with intuitive
and clear geometrical interpretation. Its robustness makes
it especially useful for high accuracy background detection
and saliency estimation. The proposed optimization framework effectively and efﬁciently combines other saliency
cues with the proposed background cue, achieving the stateof-the-art results. It can be further generalized to incorporate more constraints, which we will consider for future
works on this subject.
Acknowledgement
This work is supported by The National Science Foundation of China (No.61305091), The Fundamental Research
Funds for the Central Universities (No.2100219038), and
Shanghai Pujiang Program (No.13PJ1408200).