Learning by tracking: Siamese CNN for robust target association
Laura Leal-Taix´e
TU M¨unchen
Munich, Germany
Cristian Canton Ferrer
Redmond (WA), USA
Konrad Schindler
ETH Zurich
Zurich, Switzerland
This paper introduces a novel approach to the task of
data association within the context of pedestrian tracking,
by introducing a two-stage learning scheme to match pairs
of detections. First, a Siamese convolutional neural network (CNN) is trained to learn descriptors encoding local spatio-temporal structures between the two input image
patches, aggregating pixel values and optical ﬂow information. Second, a set of contextual features derived from the
position and size of the compared input patches are combined with the CNN output by means of a gradient boosting
classiﬁer to generate the ﬁnal matching probability. This
learning approach is validated by using a linear programming based multi-person tracker showing that even a simple and efﬁcient tracker may outperform much more complex models when fed with our learned matching probabilities. Results on publicly available sequences show that our
method meets state-of-the-art standards in multiple people
1. Introduction
One of the big challenges of computer vision is scene understanding from video. Humans are often the center of attention of a scene, which leads to the fundamental problem
of detecting and tracking them in a video. To track multiple
people, tracking-by-detection has emerged as the preferred
method. That approach simpliﬁes the problem by dividing
it into two steps. First, ﬁnd probable pedestrian locations
independently in each frame. Second, link corresponding
detections across time to form trajectories.
The linking step, called data association is a difﬁcult
task on its own, due to missing and spurious detections, occlusions, and targets interactions in crowded environments.
To address these issues, research in this area has produced
more and more complex models: global optimization methods based on network ﬂow , minimum cliques 
or discrete-continuous CRF inference ; models of pedestrian interaction with social motion models ; integration of additional motion cues such as dense point trajectories ; and person re-identiﬁcation techniques to
Linear Programming
Siamese CNN
Gradient Boosting
Detections at
Detections at
associations
trajectories
Figure 1: Multiple object tracking with learned detection
associations.
improve appearance models . Even though the models became progressively more sophisticated, the underlying descriptors, which are used to decide whether two detections belong to the same trajectory, remained quite simple
and struggle in challenging scenarios (e.g., crowds, frequent
occlusions, strong illumination effects).
Recently, larger amounts of annotated data have become
available and, with the help of these data, convolutional
neural networks (CNNs) that learn feature representations
as part of their training have outperformed heuristic, handengineered features in several vision problems . Here,
we adapt the CNN philosophy to multi-person tracking. In
order to circumvent manual feature design for data association, we propose to learn the decision whether two detections belong to the same trajectory. Our learning framework has two stages: ﬁrst, a CNN in Siamese twin architecture is trained to assess the similarity of two equally sized
 
image regions; second, contextual features that capture the
relative geometry and position of the two patches of interest are combined with the CNN output to produce a ﬁnal
prediction, in our case using gradient boosting (GB). Given
the learned, pairwise data association score we construct a
graph that links all available detections across frames, and
solve the standard Linear Programming (LP) formulation
of multi-target tracking. We show that this simple and efﬁcient linear tracker – in some sense the “canonical baseline”
of modern multi-target tracking – outperforms much more
complex models when fed with our learned edge costs.
1.1. Contributions
This paper presents three major contributions to the
pedestrian tracking task:
• Within the context of tracking, we introduce a novel
learning perspective to the data association problem.
• We propose to use a CNN in a Siamese conﬁguration
to estimate the likelihood that two pedestrian detections belong to the same tracked entity. In the presented CNN architecture, pixel values and optical ﬂow
are combined as a multi-modal input.
• We show that formulating data association with a linear optimization model outperform complex models
when fed with accurate edge costs.
1.2. Related work
Multi-person tracking.
Multi-person tracking is the input for a number of computer vision applications, such as
surveillance, activity recognition or autonomous driving.
Despite the vast literature on the topic , it still remains
a challenging problem, especially in crowded environments
where occlusions and false detections are common. Most
modern methods use the tracking-by-detection paradigm,
which divides the task into two steps: detecting pedestrians in the scene , and linking those detections
over time to create trajectories. A common formalism is
to represent the problem as a graph, where each detection
is a node, and edges indicate a possible link. The data association can then be formulated as maximum ﬂow or,
equivalently, minimum cost problem , both
efﬁciently solved to (near-)global optimality with LP, with a
superior performance compared to frame-by-frame or
track-by-track methods. Alternative formulations typically lead to more involved optimization problems, including minimum cliques or general-purpose solvers like
MCMC . There are also models that represent trajectories in continuous space and use gradient-based optimization, sometimes alternating with discrete inference for data
association .
A recent trend is to design ever more complex models, which include further vision routines in the hope that
they beneﬁt the tracker, including reconstruction for multicamera sequences , activity recognition and
segmentation . In general, the added complexity seems
to exhibit diminishing returns, at signiﬁcantly higher computational cost.
Other works have focused on designing more robust features to discriminate pedestrians. Color-based appearance
models are common , but not always reliable, since people can wear very similar clothes, and color statistics are
often contaminated by the background pixels and illumination changes. Kuo et al. , borrow ideas from person re-identiﬁcation and adapt them to “re-identify” targets
during tracking. In , a CRF model is learned to better
distinguish pedestrians with similar appearance. A different
line of attack is to develop sophisticated motion models in
order to better predict a tracked person’s location, most notably models that include interactions between nearby people . A problem of such models is
that they hand-craft a term for each external inﬂuence (like
collision avoidance, or walking in groups). This limits their
applicability, because it is difﬁcult to anticipate all possible
interaction scenarios. The problem can be to some degree
alleviated by learning the motion model from data , although this, too, only works if all relevant motion and interaction patterns are present in the training data. Moreover,
the motion model does not seem to be an important bottleneck in present tracking frameworks. By and large, more
powerful dynamic models seem to help only in a comparatively small number of situations, while again adding complexity.
Measuring similarity with CNNs.
Convolutional architectures have become the method of choice for end-to-end
learning of image representations. In relation to our problem, they have also been remarkably successful in assessing the similarity of image patches for different tasks such
as optical ﬂow estimation , face veriﬁcation , and
depth estimation from multiple viewpoints .
In the context of tracking, CNNs have been used to
model appearance and scale variations of the target .
Recently, several authors employ them to track via online
learning, by continuously ﬁne-tuning a pre-trained CNN
model .
2. Learning to associate detections
Our tracking framework is based on the paradigm of
tracking-by-detection, i.e. ﬁrstly, we run a detector through
the sequences, and secondly, we link the detections to form
trajectories.
We propose to address the data association
problem by learning a model to predict whether two detections belong to the same trajectory or not. We use two
sets of features derived from the pedestrian detections to be
compared. First, local spatio-temporal features learnt using
(Siamese junction)
Local spatio-temporal features
Contextual features
Relative geometry &
position features
Gradient Boosting
Classifier
Final Matching
Prediction
Figure 2: Proposed two-stage learning architecture for pedestrian detection matching.
a CNN and, second, contextual features encoding the relative geometry and position variations of the two detections.
Finally, both sets of features are combined using a GB classiﬁer to produce the ﬁnal prediction (see Fig.2). Decoupling local and global features processing and ensembling them in a later stage allows understanding the contribution of each factor plus adding robustness to the prediction .
2.1. CNN for patch similarity
A common denominator when comparing two image
patches using CNNs are Siamese architectures where two
inputs are processed simultaneously by several layers with
shared weights (convolutional and/or fully connected) that
eventually merge at some point in the network. Siamese
CNN topologies can be grouped under three main categories, depending on the point where the information from
each input patch is combined (see Fig.3):
• Cost function. Input patches are processed by two
parallel branches featuring the same network structure
and weights. Finally, the top layers of each branch are
fed to a cost function that aims at learning a
manifold where different classes are easily separable.
• In-network. In this case, the top layers of the parallel
branches processing the two different inputs are concatenated and some more layers are added on top of
that . Finally, the standard softmax log-loss
function is employed.
• Joint data input. The two input patches are stacked
together forming a uniﬁed input to the CNN .
Again, the softmax log-loss function is used here.
While the two ﬁrst approaches have yield good results
in classiﬁcation applications, the best performance for tasks
involving comparison of detailed structures is obtained with
the joint data input strategy. As pointed out by and further corroborated by , jointly using information from
both patches from the ﬁrst layer tends to deliver a better
performance. In order to verify this hypothesis within the
scope of the tracking problem, we trained a Siamese network using the contrastive loss function :
(y) d + (1 −y) max (τ −d, 0) ,
where d = ||an −bn||2
2, being an and bn the L2 normalized responses of the top fully connected layer of the parallel branches processing each input image, and τ = 0.2
is the separation margin and y the label value encoded as 0
or 1. The topology of the CNN network has been the same
all through the paper and shown in Fig.2. Our early experiments, showed a relative 8% AUC increase of the joint data
input case over the best performing model from the other
two topologies, given a ﬁxed number of parameters.
Cost Function
(a) Cost function
Cost Function
(b) In-network
Cost Function
(c) Input stacking
Figure 3: Siamese CNN topologies
Architecture. The proposed CNN architecture takes as
input four sources of information: the pixel values in the
normalized LUV color format for each patch to be compared, I1 and I2, and the corresponding x and y components
of their associated optical ﬂow , O1 and O2. These four
images are resized to a ﬁxed size of 121x53 and stacked
depth-wise to form a multi-modal 10-channel data blob D
to be fed to the CNN. In order to improve robustness against
varying light conditions, for each luma channel L of both I1
and I2 we perform a histogram equalization and a plane ﬁtting, as introduced in .
The input data is processed ﬁrst by three convolutional
layers, C1,2,3, each of them followed by a PreReLU nonlinearity and a max-pooling layer that renders the net
more robust to miss alignments within the components of
D. Afterwards, four fully connected layers, F4,5,6,7, aim
at capturing correlations between features in distant parts of
the image as well as cross-modal dependencies, i.e. pixelto-motion interactions between I1,2 and O1,2. The output
of the last fully-connected layer is fed to a binary softmax which produces a distribution over the class labels
(match/no match). The output of layer F6 in the network
will be used as our raw patch matching representation feature vector to be fed to the second learning stage.
Training data generation. Pedestrian detections proposed using are generated for each frame and associations between detections are provided across frames during
the training phase. On one hand, positive examples, i.e.
pairs of detections corresponding to target m, (Im
1 ≤k < N, are directly generated from the ground truth
data, with a maximum rewind time of N = 15. On the
other hand, negative examples are generated by either pairing two true detections with belonging to different people,
a true detection with a false positive or two false positive
detections; in order to increase the variety of data presented
to the CNN, we enlarged the set of false positives by randomly selecting patches from the image of a given aspect
ratio that do not overlap with true positive detections. By
generating these random false positives, the CNN does not
overﬁt to the speciﬁc type of false positives generated by the
employed pedestrian detector thus increasing its capacity of
generalization.
We trained the proposed CNN as a binary classiﬁcation task, employing the standard backpropagation on feed-forward nets by stochastic gradient descent with momentum. The mini-batch size was set to 128,
with an equal learning rate for all layers set to 0.01, sequentially decreased every 1.5 epochs by a factor 10, ﬁnally reaching 10−4. Layer weight were initialized following and we trained our CNN on a Titan GPU X for 50
epochs. The Lasagne/Theano framework was employed to
run our experiments.
Data augmentation. Even if the available training data
is fairly large, pairs of pedestrian detections tend not to have
a large range of appearances stemming from the fact that the
number of distinct people in the training corpus is limited.
Adding variety to the input data during the training phase
is a widely employed strategy to reduce overﬁtting and improve generalization of CNNs . In our particular
case, we have randomly added geometric distortions (rotation, translation, skewing, scaling and vertical ﬂipping) as
well as image distortions (Gaussian blur, noise and gamma).
These transformations are applied independently for each of
the two input patches but only allowing small relative geometric transformations between them (with the exception of
vertical ﬂipping that is applied to both images, when chosen). Since all these transformation are performed directly
on GPU memory, the augmentation complexity cost is negligible.
2.2. Evidence aggregation with gradient boosting
The softmax output of the presented Siamese CNN
might be used directly for pedestrian detection association
but the accuracy would be low since we are not taking into
account where and when these detections originated in the
image. Therefore, the need for a set of contextual features
and a higher order classiﬁer to aggregate all this information.
Given two pedestrian detections at different time instants, It1 and It2, encoded by its position x = (x, y) and
dimensions s = (w, h), we deﬁne our contextual features
as: the relative size change, (s1 −s2)/(s1 + s2), the position change, (x1 −x2), and the relative velocity between
them, (x1 −x2)/(t2 −t1).
Combining the local and contextual sets of features is
carried out using gradient boosting (GB) . To avoid
overﬁtting on the GB, CNN predictions for each of the train
sequences are generated in a leave-one-out fashion following the stacked generalization concept introduced in .
Finally, the GB classiﬁer is trained by concatenating the
CNN and contextual features. In our case, we trained the
GB classiﬁer using 400 trees using the distributed implementation presented in .
3. Tracking with Linear Programming
In this section, we present the tracking framework where
we incorporate the score deﬁned in the previous section in
order to solve the data association problem.
i} be a set of object detections with
i = (x, y, t), where (x, y) is the 2D image position and
t deﬁnes the time stamp. A trajectory is deﬁned as a list of
ordered object detections Tk = {dt1
k2, · · · , dtN
the goal of multiple object tracking is to ﬁnd the set of trajectories T ∗= {Tk} that best explains the detections D.
This can be expressed as a Maximum A-Posteriori (MAP)
problem and directly mapped to a Linear Programming formulation, as detailed in .
The data association problem is therefore deﬁned by a
linear program with objective function:
T ∗= argmin
Cin(i)fin(i) +
Cout(i)fout(i)
Cdet(i)f(i) +
Ct(i, j)f(i, j)
subject to edge capacity constraints, ﬂow conservation at
the nodes and exclusion constraints.
The costs Cin and Cout deﬁne how probable it is for a trajectory to start or end. The detection cost Cdet(i) is linked
to the score that detection i was given by the detector. Intuitively, if the score si is very high, the cost of the edge
should be very negative, so that ﬂow will likely pass through
this edge, including the detection i in a trajectory. We normalize the costs si = for a sequence, and deﬁne the
detection cost as:
if si < Vdet
1−Vlink −1
if si ≥Vdet
If we set, for example, Vdet = 0.5, the top half conﬁdent
detections will correspond to edges with negative cost, and
will most likely be used in some trajectory. By varying this
threshold, we can adapt to different types of detectors that
have different rates of false positives.
The cost of a link edge depends only on the probability
that the two detections i and j belong to the same trajectory,
as estimated by our classiﬁer:
Ct(i, j) =
i,j < Vlink
1−Vlink −1
i,j ≥Vlink
Note in Eq. (1), that if all costs are positive, the trivial
solution will be zero ﬂow. A trajectory is only created if
its total cost is negative. We deﬁne detection costs to be
negative if we are conﬁdent that the detection is a pedestrian, while transition costs are negative if our classiﬁer is
very conﬁdent that two detections belong to the same trajectory. We control with Vdet and Vlink the percentage of
negative edges that we want in the graph. The in/out costs,
on the other hand, are positive and they are used so that the
tracker does not indiscriminately create many trajectories.
Therefore, a trajectory will only be created if there is a set
of conﬁdent detections and conﬁdent links whose negative
costs outweigh the in/out costs. Cin = Cout, Vdet and Vlink
are learned from training data as discussed in the next section.
The Linear Program in Eq. (1) can be efﬁciently solved
using Simplex or k-shortest paths . Note, that we
could use any other optimization framework, such as maximum cliques , or Kalman ﬁlter for real-time applications.
4. Experimental results
This section presents the results validating the efﬁciency
of the proposed learning approach to match pairs of pedestrian detections as well as its performance when creating
trajectories by means of the aforementioned linear programming tracker. In order to provide comparable results
with the rest of the state-of-the-art methods, we employed
the large MOTChallenge dataset, a common reference
when addressing multi-object tracking problems. It consists
of 11 sequences for training, almost 40,000 bounding boxes,
and 11 sequences for testing, over 60,000 boxes, comprising
sequences with moving and static cameras, dense scenes,
different viewpoints, etc.
4.1. Detection matching
We ﬁrst evaluate the performance of the proposed learning approach when predicting the probability of two detections belonging to the same trajectory by means of the
ROC curve computed on the training data of MOT15 ,
as shown in Fig.4. Two result groups are depicted: ﬁrst,
when only using the CNN classiﬁer (best AUC: 0.718)
and, second, when using the two stage CNN+GB classiﬁer
(best AUC: 0.954); the later yielding to a relative 41% increase in classiﬁcation performance. Oversampling the image (1,2,4 and 8 ﬁxed locations) and averaging their predictions proved to deliver a signiﬁcant improvement, specially
for the CNN part of the end-to-end system. However, the
impact of oversampling in the CNN+GB classiﬁer is less
relevant hence it may be avoided to reduce the overall computation load.
An analysis of the ROC curve on the MOT15 training
data allowed us to ﬁnd the operation point, i.e.
probability threshold Vlink within the linear programming tracking, that would maximize its accuracy. In our case, we set
Vlink = 0.35, after cross-validation.
1­CNN (area = 0.571)
2­CNN (area = 0.630)
4­CNN (area = 0.690)
8­CNN (area = 0.718)
1­GB (area = 0.944)
2­GB (area = 0.949)
4­GB (area = 0.951)
8­GB (area = 0.954)
Figure 4: Performance accuracy for the Siamese CNN and
the full two-stage learning approach (CNN+GB), when using an oversampling of 8,4,2 and 1 per pair at the input.
4.2. Multiple people tracking
Evaluation metrics. To evaluate multiple-object tracking
performance, we used CLEAR MOT metrics , tracking accuracy (TA) and precision (TP). TA incorporates
the three major error types (missing recall, false alarms
and identity switches (IDsw)) while TP is a measure
for the localization error, where 100% again reﬂects a
perfect alignment of the output tracks and the ground
truth. There are also two measures taken from which
reﬂect the temporal coverage of true trajectories by the
tracker: mostly tracked (MT, > 80% overlap) and mostly
lost (ML, < 20%). We use only publicly available detections and evaluation scripts provided in the benchmark .
Determining optimal parameters. As discussed before,
the LP parameter Vlink = 0.35 is given by the operation point of the ROC curve.
The other LP parameters,
Cin = Cout, Vdet are determined by parameter sweep with
cross-validation on the training MOT15 data in order to
obtain the maximum tracking accuracy.
Baselines. We compare to two tracking methods based on
Linear Programming. The ﬁrst is using only 2D distance
information as feature (LP2D), the second is learning
to predict the motion of a pedestrian using image features
(MotiCon). This comparison is specially interesting, since
the optimization structure for all methods is based on Linear
Linthescher
TownCentre
Table 1: Detailed result on the 11 sequences of MOTChallenge test, compared to two other methods that use also Linear Programming.
Programming, and the only factor that changes is the way
the edge costs are computed. In this way, we can see the
real contribution of our proposed learn-based costs. As it
can be seen in Table 1, the results indicate that our learned
data association costs are more accurate, and that this better
low-level evidence is the key factor driving the performance
improvement.
Finally we show the results on the test set of MOTChallenge in Table 2, where we compare to numerous stateof-the-art trackers.
Our method is among the top performing trackers, and contains less false positives than any
other method. Note, that we do not use any type of postprocessing. Again, it clearly outperforms methods based on
Linear Programming (LP2D and MotiCon), thanks to the
proposed edge costs.
MHT-DAM 
SiameseCNN (proposed)
LP-SSVM 
JPDA-m 
MotiCon 
SegTrack 
LP2D (baseline)
DCO-X 
ALExTRAC 
TC-ODAL 
DP-NMS 
Table 2: Results on the MOTChallenge test set.
5. Conclusions
In this paper we have presented a two-stage learning
based approach to associate detections within the context
of pedestrian tracking. In a ﬁrst pass, we create a multidimensional input blob stacking image and optical ﬂow information from to the two patches to be compared; these
data representation allows the following Siamese convolutional neural network to learn the relevant spatio-temporal
features that allow distinguishing whether these two pedestrian detections belong to the same tracked entity. These
local features are merged with some contextual features by
means of a gradient boosting classiﬁer yielding to a uniﬁed
prediction.
In order to highlight the efﬁciency of the proposed detection association technique, we use a modiﬁed linear programming based tracker to link the proposed correspondences and form trajectories.
The complete system
is evaluated over the standard MOTChallenge dataset ,
featuring enough data to ensure a satisfactory training of
the CNN and a thorough and fair evaluation. When comparing the proposed results with the state-of-the-art, we observe that a simple linear programming tracker fed with
accurate information reaches comparable performance than
other more complex approaches.
Future research within this ﬁeld involve applying the
proposed approach to more generic target tracking, leveraging already trained models and extending the second stage
classiﬁer to deal with more complex contextual features,
e.g. social forces . Evaluation of the proposed architecture over on datasets is currently under investigation.