ARTIFICIAL INTELLIGENCE: A MODERN
Dr. Anil Kumar
Sivasubramanian Balasubramanian
Dr. Haewon Byeon
Prof. Ganesh Vasudeo Manerkar
www.xoffencerpublication.in
Copyright © 2024 Xoffencer
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material
is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting,
reproduction on microfilms or in any other physical way, and transmission or information storage and retrieval,
electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter
developed. Exempted from this legal reservation are brief excerpts in connection with reviews or scholarly analysis
or material supplied specifically for the purpose of being entered and executed on a computer system, for exclusive
use by the purchaser of the work. Duplication of this publication or parts thereof is permitted only under the
provisions of the Copyright Law of the Publisher’s location, in its current version, and permission for use must
always be obtained from Springer. Permissions for use may be obtained through Rights Link at the Copyright
Clearance Center. Violations are liable to prosecution under the respective Copyright Law.
ISBN-13: 978-81-973708-1-6 (Paperback)
Publication Date: 18 May 2024
Trademarked names, logos, and images may appear in this book. Rather than use a trademark symbol with every
occurrence of a trademarked name, logo, or image we use the names, logos, and images only in an editorial fashion
and to the benefit of the trademark owner, with no intention of infringement of the trademark.
The use in this publication of trade names, trademarks, service marks, and similar terms, even if they are not
identified as such, is not to be taken as an expression of opinion as to whether or not they are subject to proprietary
While the advice and information in this book are believed to be true and accurate at the date of publication, neither
the authors nor the editors nor the publisher can accept any legal responsibility for any errors or omissions that may
be made. The publisher makes no warranty, express or implied, with respect to the material contained herein.
MRP: 549/-
Published by:
Xoffencer International Publication
Behind shyam vihar vatika, Laxmi colony
Dabra, Gwalior, M.P. – 475110
Cover Page Designed by:
Satyam Soni
Contact us:
Email: 
Visit us: www.xofferncerpublication.in
Copyright © 2024 Xoffencer
Author Details
Dr. Anil Kumar
Dr. Anil Kumar stands out as a remarkable figure in the realm of Chemistry, blending
16 years of teaching and research excellence with significant contributions to education
and innovation. As Head of the Department, his leadership extends beyond academia,
embracing administrative prowess and a commitment to creating a nurturing
educational environment. His creation of the ACMI model demonstrates a dedicated
effort to bridge theoretical chemistry with practical applications, particularly in the
microbial study of complexes. Through his YouTube channel, "HOTSPOT
CHEMISTRY BY DR ANIL KUMAR," he significantly expands the reach of his
expertise, democratizing education for a wider audience. Dr. Kumar's proficiency with
advanced analytical instruments and his exploration of AI and IoT signify a progressive
approach to scientific research. His prolific output includes over 80 publications,
authorship of pivotal texts in chemistry, and the guidance of numerous scholars,
highlighting his role as a beacon of knowledge and innovation. Through his active
participation in various committees and coordination roles, he has made notable
contributions to the academic community, receiving national and international
recognition. Dr. Kumar's work exemplifies a synergistic blend of leadership, research,
and a dedication to education, positioning him as a key figure in advancing the field of
chemistry and its application in solving global challenges
Sivasubramanian Balasubramanian
Sivasubramanian Balasubramanian is an esteemed scholar and innovator in the field
of artificial intelligence, whose academic and professional journey has been marked by
a deep commitment to advancing the frontiers of AI technology and ethics. After
earning an M.Sc. in Data Science from University College Cork, Siva embarked on a
career that blends rigorous academic research with impactful industry applications.
Over the past six years, he has contributed to groundbreaking projects that have shaped
the landscape of machine learning and artificial intelligence. His research has pioneered
new algorithms that enhance the capabilities of AI systems, improving their efficiency
and making them more accessible to a broader range of users. Additionally, Siva's work
on the ethical implications of AI has spurred important discussions on privacy, bias,
and the future of work in a technology-driven world.
Dr. Haewon Byeon
Dr. Haewon Byeon received the Dr Sc degree in Biomedical Science from Ajou
University School of Medicine. Haewon Byeon currently works at the Department of
Medical Big Data, Inje University. His recent interests focus on health promotion, AImedicine, and biostatistics. He is currently a member of international committee for a
Frontiers in Psychiatry, and an editorial board for World Journal of Psychiatry. Also,
He were worked on 4 projects (Principal Investigator) from the Ministry of Education,
the Korea Research Foundation, and the Ministry of Health and Welfare. Byeon has
published more than 343 articles and 19 books.
Prof. Ganesh Vasudeo Manerkar
Prof. Ganesh Vasudeo Manerkar is a young and dynamic individual with a strong
academic background in Information and Computer Science. Currently he is working
as an Assistant Professor in Information Technology, Goa College of Engineering,
Government of Goa, "Bhausaheb Bandodkar Technical Education Complex"
Farmagudi, Ponda- Goa, affiliated to Goa University. He is passionate about research,
and believes in enhancing skills through continuous learning. Currently, his research
area includes Computer Networking, Data Communication, Cloud Computing, AI,
ML, Brain Computer Interphase (BCI), E- Commerce, Computer Vision, Blockchain,
and other varied fields. His research findings are published in SCIE/SCOPUS /Googleindexed international journals. He has Patent from UK and India to his credits. He has
jointly authored and published books in different publications. In all he has got 32 +
years of experience in the academia. At present he is serving as Asst. Professor in
Information Technology.
The text has been written in simple language and style in well organized and
systematic way and utmost care has been taken to cover the entire prescribed
procedures for Science Students.
We express our sincere gratitude to the authors not only for their effort in
preparing the procedures for the present volume, but also their patience in waiting to
see their work in print. Finally, we are also thankful to our publishers Xoffencer
Publishers, Gwalior, Madhya Pradesh for taking all the efforts in bringing out this
volume in short span time.
The book "Artificial Intelligence: A Modern Approach" written by Stuart
Russell and Peter Norvig is considered to be an essential textbook in this field.
Problem-solving, knowledge representation, machine learning, natural language
processing, robotics, and a wide range of other subjects are some of the topics that are
covered in this book, which offers a complete introduction to the area of artificial
intelligence (AI). When writing the introduction, it is possible to provide a summary of
the most important aspects and goals of the book. This summary may be expressed as
follows: The book "Artificial Intelligence: A Modern Approach" provides an in-depth
analysis of AI, which is a discipline that is seeing unprecedented levels of advancement.
This foundational work, which was written by Stuart Russell and Peter Norvig, goes
into significant concepts, methodologies, and applications, so giving readers with a
profound comprehension of the fundamental principles that underlie artificial
intelligence. This book covers a wide range of subjects, including but not limited to
robotics, knowledge representation, intelligent agents, search techniques, and machine
learning. In order to do this, a combination of theoretical principles and practical
examples is used. Students, scholars, and practitioners who are interested in gaining
an understanding of the complexity and potential of artificial intelligence in the modern
world will find this book to be an indispensable resource. It places a high priority on
using cutting-edge research methodologies and processes in order to accomplish this
objective. In addition, the book explores the social and ethical implications of artificial
intelligence, prompting readers to engage in critical thinking about the ways in which
they might build and use this technology in a responsible manner. Because of its
comprehensive discussion of artificial intelligence's potential, risks, and influence on
the future of our society, "Artificial Intelligence: A Modern Approach" continues to be
a book that anybody who is interested in the topic should consult. This is due to the
book's lucid explanations with regard to the subject matter.
Chapter No.
Chapter Names
Introduction
1.1 What is AI
1.2 Artificial intelligence's bases
1.3 AI's Evolution Through Time
Associates of intelligent
2.1 Agents and environment
2.2 Good behaviour: the concept of rationality
2.3 The nature of environments
2.4 The structure of agents
Researched- based solving problem
3.1 Problems- saving agents
3.2 Examples problems
3.3 Searching for solution
3.4 Uniformed search strategies
Understanding artificial intelligence
4.1 Introduction
4.2 Definition of” understanding
4.3 What is artificial intelligence
4.4 Artificial intelligence vs robotics
4.5 Defining artificial intelligence
4.6 Types of ai and their applications
4.7 Achieving Ai
4.8 Natural language processing (NLP)
4.9 Ai's impact on industries
4.10 Why AI and why now
4.11 Industrial products leaders gain value from AI
4.12 Ethics and AI
4.13 Ethical dilemmas with artificial intelligence
4.14 The ethics and risks of developing artificial
intelligence
AI in manufacturing and automation
5.1 Introduction
5.2 Industrial sector, manufacturing
5.3 Transforming manufacturing with AI
5.4 Optimize supply chains with generative AI
5.5 Predictive maintenance and quality control
5.6 Benefits of predictive maintenance
5.7 The role of the internet of things (IOT) and industry
4.0 in qms and predictive maintenance
5.8 Smart supply chain and logistics
5.9 Smart supply chain - main characteristics
5.10 Stages of smart supply chain development
5.11 Consequently, it could be identified
5.12 Human-machine collaboration
Constraint satisfaction problem
6.1 Defining constraint satisfaction issues
6.2 Constraints transmission: deductive plants in CSPS
6.3 Investigating the ast of CSPS
6.4 Local search for CSP
Agents of logic
7.1 Agents relying on expertise
7.2 The world of Wumpus
7.4 The proposed logic: an extremely basic logic
7.5 A theorem that is supposed to prove
First order logic
8.1 Representation revisited
8.2 Syntax and semantics of first-order logic
8.3 Using first-order logic
1 | P a g e
INTRODUCTION
Here we try to define artificial intelligence (AI) and explain why we think it deserves
more attention than other worthy research topics; obviously, this is a prerequisite to
doing any kind of study in this area. We humans take great pride in our intelligence; in
fact, we call ourselves Homo sapiens, which means "man the wise." Human cognition
has long baffled scientists, who have sought to explain how a little particle of stuff like
us can see, understand, predict, and control an enormous and complex cosmos. Beyond
that, the field of artificial intelligence (AI) aims to do more than just understand; it aims
to build intelligent objects.
One of the newest innovations in engineering and science is AI. The name wasn't even
thought of until 1956, although development started in earnest almost immediately after
WWII ended. Science professionals from several disciplines often mention artificial
intelligence (AI) as the "field I would most like to be in" next to molecular biology. If
you're a physics student, you could think that all the great thinkers like Galileo, Newton,
Einstein, and others have thought of everything. Conversely, AI is still on the market
for a handful of brilliant minds to join their team full-time.
At now, AI encompasses a wide variety of subfields, from the broad (perception and
learning) to the narrow (proving mathematical theorems, writing poetry, operating a
car on a congested street, and disease detection, among many others). These are but a
few of the many activities that might be categorised as AI-related. Artificial intelligence
(AI) is a field that really covers all intellectual pursuits; it is relevant to everyone.
1.1 WHAT IS AI
Our assertion is that artificial intelligence is fascinating, but we have not specified what
it is. We may see eight different concepts of artificial intelligence set out along two
axes in Figure 1.1. While the definitions that are located at the top of the list focus on
thinking processes and reasoning, the definitions that are located at the bottom centre
on behaviour. These definitions evaluate success in terms of faithfulness to human
performance, while the ones on the right measure against an ideal performance metric
that is termed rationality. The left definitions Consider the level of human performance
2 | P a g e
while evaluating success. In order for a system to be deemed logical, it must behave in
a way that is in accordance with the information that it is aware of.
The four basic approaches to artificial intelligence have been pursued throughout
history, each by a different person using a different technique. It is necessary for a
human-centered approach to include elements of empirical research.
Table 1.1 The following are several definitions of artificial intelligence, which are
listed in four different categories.
Taking People into Account
"Cybernetic intelligence, in its broadest
definition,"
characterised as "the fascinating new effort
to make computers think."
"[The automation of] tasks typically
associated
cognition,
problem-solving,
decision-making, and."
Thinking Rationally
"The study of mental faculties through
the use of computational models." This
is a method of thinking that is
reasonable.
This article is a comprehensive review
of computing for perception, reasoning,
and action.
Source: In the year 2010, Stuart J. Russell and Peter Norvig made several
modifications to the procedures that are used in artificial intelligence for the purpose
of data collecting and processing.
exploring theories and findings about human behaviour via volving. In the rationalist1
method, mathematics and engineering are both used in conjunction with one another.
The different groups have had both positive and negative interactions with one another.
All right, let's go down the four methods one by one.
1.1.1 Putting one's humanity on display: the Turing Test method
This test, which was developed by, was intended to offer a definition of intelligence
that is adequate from an operational standpoint. If, after being presented with a series
of written questions, a human interrogator is unable to determine whether the written
replies were produced by a person or by a computer, then the computer has successfully
passed the test. examines the specifics of the examination and questions whether or not
a computer would be considered intelligent if it were to pass it. We will observe for the
time being that the programming of a computer to pass a test that is rigorously
3 | P a g e
administered gives a lot of room for improvement. The following capabilities would be
required of the computer in order for it to qualify: Machine learning enables it to adapt
to new situations and detect and extrapolate patterns; knowledge representation allows
it to store what it knows or hears; automated reasoning allows it to use the information
it has stored to answer questions and draw new conclusions; and natural language
processing enables it to communicate effectively in English.
On purpose, Turing's test did not include a direct physical link between the questioner
and the machine. This was done because it is not required for intelligence to include
the modelling of a human going through physical activity. On the other hand, the socalled entire Turing Test incorporates a visual feed, which allows the interrogator to
evaluate the subject's perceptual capabilities. Additionally, the interrogator is given the
option to pass actual things "through the hatch." In order for the computer to be able to
pass the Turing Test in its entirety, it will need computer vision in order to observe
things, as well as robotics in order to manipulate items and move about.
Turing gets credit for establishing a test that is still relevant sixty years after it was first
developed. These six fields make up for most AI systems. On the other side, AI
researchers prioritise studying the underlying concepts of intelligence over trying to
recreate an example, therefore they haven't focused much on passing the Turing Test.
It wasn't until the Wright brothers and others shifted their focus from attempting to
mimic birds to using wind tunnels and learning about aerodynamics that they finally
achieved their aim of "artificial flight." Aeronautical engineering isn't about making
"machines that fly so exactly like pigeons that they can fool even other pigeons." The
field of aeronautical engineering does not aim to achieve this.
Turing receives recognition for creating a test that remains applicable sixty years
subsequent to its development. Most artificial intelligence is based on these six
domains. On the other side, AI researchers prioritise studying the underlying concepts
of intelligence over trying to recreate an example, therefore they haven't focused much
on passing the Turing Test.
It wasn't until the Wright brothers and others shifted their focus from attempting to
mimic birds to using wind tunnels and learning about aerodynamics that they finally
achieved their aim of "artificial flight." Aeronautical engineering isn't about making
"machines that fly so exactly like pigeons that they can fool even other pigeons." The
field of aeronautical engineering does not aim to achieve this.
4 | P a g e
1.1.2 Human-centered thought: a cognitive modelling perspective
It is necessary to have some method of identifying how people think in order for us to
be able to assert that a certain programme mimics human thought processes. We have
to have a better understanding of how the human mind really functions. This may be
accomplished in three different ways: by introspection, which involves attempting to
capture our own thoughts as they pass by; through psychological studies, which include
witnessing a person in action; and through brain imaging, which involves monitoring
the processes that occur inside the brain. It will be feasible to represent the theory of
the mind as a computer programme once we have a theory of the mind that is capable
of providing adequate precision.
If the input–output behaviour of the programme is consistent with the behaviour of
people, this is indication that some of the processes that are functioning in the
programme might also be active in humans. For instance, , the creators of GPS, also
known as the "General Problem Solver," were not happy with just having their
programme answer problems in the proper manner. The comparison of the trail of its
reasoning stages to the trace of human individuals solving the identical issues was the
primary focus of their attention. Computer models from artificial intelligence (AI) and
experimental methods from psychology are brought together in the subject of cognitive
science, which is an interdisciplinary field, in order to create accurate and testable
theories of the human mind.
In and of itself, cognitive science is a fascinating area that is deserving of a number of
textbooks and at least one encyclopedia. Sometimes we will make observations on the
ways in which artificial intelligence approaches and human cognition are similar or
different. On the other hand, genuine cognitive research is always founded on the
experimental examination of real populations of either people or animals. Because we
are operating under the assumption that the reader is only able to experiment with a
computer, we will leave it for other works.
In the early days of artificial intelligence, there was sometimes a large amount of
misunderstanding between the various techniques. For example, an author can say that
an algorithm's high performance on a task makes it a good representation of human
performance, and vice versa. Research in cognitive science and AI has both been able
to advance at a faster pace as a result of the difference that modern writers have made
between the two types of assertions. The two areas continue to mutually enrich one
5 | P a g e
another, most notably in the field of computer vision, which combines findings from
neurophysiology via use of computer models.
1.1.3 Reasoning: The "laws of thought" method
Aristotle, a Greek philosopher, was among the pioneers who sought to establish rules
for what is now known as "right thinking," or ways of reasoning that are incontestable
by evidence. In other words, "Socrates is a man; all men are mortal; therefore, Socrates
is mortal." His syllogisms laid the groundwork for argument structures that, when
applied to valid premises, reliably produced valid conclusions. Other examples include
statements such as "Socrates is a mortal."
The study of these principles of thinking was the impetus for the development of the
discipline known as logic. They were assumed to control the functioning of the mind.
In the nineteenth century, logicians devised a precise notation for claims that could be
made about any and all types of things in the world as well as the relationships that
exist between them. (This is in contrast to the standard notation used in arithmetic,
which is primarily used for making claims about numerical values.)
As of the year 1965, there were programmes that were capable of solving, in theory,
any issue that could be expressed using logical notation. (However, if there is no
problem to solve, the programme could continue to run indefinitely.) Within the field
of artificial intelligence, there is a tradition known as logicist with the goal of
developing intelligent systems by using such programmes as a foundation. This
strategy has two primary challenges that must be overcome. In the first place, it is not
simple to take informal information and articulate it in the formal words that are needed
by logical notation.
This is especially true when the knowledge is less than one hundred percent absolutely
definite. Second, there is a significant gap between applying a solution to a problem
"in principle" and actually putting that solution into action. Problems that include just
a few hundred facts have the potential to exhaust the processing capabilities of any
computer, unless the machine is provided with some advice about which reasoning
processes to attempt first. In spite of the fact that each of these challenges are applicable
the logics school of thought was the first to introduce them to any effort to build
computational reasoning systems.
6 | P a g e
1.1.4 Reasoning Action: The Rational Agent Method
It is simply anything that acts (the word "agent" originates from the Latin word "agree,"
which means "to do"). It is true that every computer programme performs at least one
function, but it is anticipated of computer agents that they perform other functions, such
as operating independently, seeing their surroundings, being stable over an extended
length of time, adjusting to change, and establishing and pursuing objectives. A person
who behaves in such a way as to obtain the best possible result or, in the event that
there is ambiguity, the best possible predicted outcome is a rational agent.
Accurate conclusion-making was a major tenet of the AI "laws of thought" paradigm.
A part of being a rational agent is occasionally drawing correct conclusions, because
one way to act rationally is to reason logically to the conclusion that a given action will
achieve one's goals and then to act on that conclusion. One reason for this is because
have rational behaviour is to act rationally. On the other hand, proper inference is not
entirely based on reason; there are certain circumstances in which there is no action
that can be shown to be valid, yet it is still necessary to take some action. In addition,
there are methods of behaving rationally that cannot be mentioned as being associated
with inference. For instance, a reflex response, such as recoiling from a hot stove, is
often more effective than a delayed action that is made after extensive consideration
and consideration of the situation.
An agent is able to behave rationally if they possess all of the abilities that are required
for the Turing Test. Agents are able to arrive at sound judgements via the use of
knowledge representation and reasoning. In order for us to survive in a world that is so
complicated the ability to generate naturally occurring, intelligible phrases is essential.
Learning is necessary not only for the purpose of acquiring knowledge, but also
because it enhances our capacity to conduct ourselves in an efficient manner.
In comparison to the other techniques, there are two main advantages to using the
rational-agent method. The first advantage is that it covers more ground than the "laws
of thought" method. This is due to the fact that proper inference is simply one of
numerous alternative processes that may be used to achieve rational outcomes.
Additionally, in comparison to techniques that are based on human behaviour or human
cognition, it is more receptive to the creation of scientific knowledge. There is a
mathematically well-defined and completely universal criterion of reason. One way to
build agent designs that can be shown to do it is to "unpack" it. Conversely, human
7 | P a g e
conduct is very context dependent and may be defined as, well, everything that humans
do. As a result, the primary focus of this work is on the fundamental concepts of rational
agents as well as the components that are necessary for their construction. It will
become clear to us that, despite the seeming ease with which the problem may be
presented, there is a vast array of problems that arise when we attempt to find a solution
to it. provides a more in-depth explanation of some of these concerns.
One essential element to bear in mind is that as time goes on, we will come to see that
it is not possible to achieve complete reason, which is always acting in the appropriate
manner, in surroundings that are complex. The requirements for processing power are
just excessive. For the most of the book, on the other hand, we shall adhere to perfect
rationality is a great place to begin when doing analysis, which is the working
assumption. Not only does it make the issue easier to understand, but it also puts the
majority of the basic information in the area in the right context. The problem of limited
rationality, which refers to the process of responding correctly when there is not enough
time to do all of the calculations that one may want to, should be addressed openly.
1.2 ARTIFICIAL INTELLIGENCE'S BASES
Here we'll provide a quick rundown of all the disciplines that have informed AI with
new ideas, viewpoints, and methods. As is the case with all histories, this one is
compelled to focus on a limited number of individuals, events, and concepts while
ignoring others that were equally significant. Over the course of the history, we
organise it centred on a series of inquiries. Please do not take this as an indication that
the disciplines do not deal with other issues. nor would we want to give the impression
that all of the fields have been striving towards artificial intelligence as their pinnacle
of achievement.
1.2.1 Philosophy
 Is it possible to arrive to valid conclusions by using formal rules only?
 What is the relationship between a physical brain and the mind?
 From what source does one get knowledge?
 How does one put their knowledge into practice?
whose bust is shown on the cover of this book, was the pioneer in developing a system
of laws that govern the rational mind. Unofficial syllogism scheme for good thinking
8 | P a g e
was established by him. This method, in theory, enabled one to construct conclusions
automatically, given basic premises. After a considerable amount of time had passed,
the concept that a mechanical artefact might genuinely exercise effective thinking was
conceived. "In the privacy of our minds, we add and remove.," stated the proposition
that thinking was analogous to the process of numerical calculation. Already, the
process of automating computation itself was well on its way to completion.
A mechanical calculator was invented about the year 1500, but it was never built. New
reconstructions have shown that the plan was functional. Even though the first known
computing machine was created by a German scientist about 1623, the 1642-invented
Pascaline has greater fame. In his words, "the arithmetic machine produces effects that
appear nearer to thought than all the actions of animals." Gottfried constructed a
mechanical apparatus with the intention of performing operations on ideas rather than
numbers; nevertheless, the instrument's capabilities were somewhat restricted.
By developing a calculator that could do addition, subtraction, multiplication, and root
calculation, Leibniz was able to beat Pascal. The Pascaline, on the other hand, could
only perform addition and subtraction. Some people have hypothesised that machines
may not only be able to do computations, but they could also be able to think and
behave independently. Thomas Hobbes proposed the concept of a "artificial animal" in
his book Leviathan, which was published in 1651. Hobbes said that the heart is nothing
more than a spring, and the nerves are nothing more than a multitude of strings, and the
joints are nothing more than a multitude of wheels.
Building physical systems that mimic some of the principles of logic is a whole other
ballgame than claiming that the mind operates, at least partially, in line with such laws.
Nevertheless, claiming that the mind is a physical system is a whole other matter.
offered the first all-encompassing analysis of the distinctions between matter and
cognition and the difficulties that result from these differences. It would seem that free
choice is severely limited in a mind that is solely physical. Free will is like a boulder
'deciding' to fall towards the centre of the planet if the mind is entirely directed by
physical principles.
Herein lies one of the conceptual flaws of this mental model. Descartes was a fervent
believer in the school of thought that would later be called rationalism; it counts
Aristotle and Leibnitz among its adherents. An important tenet of the rationalist
worldview is the primacy of reason in explaining the cosmos. On the other hand,
9 | P a g e
Descartes believed in dualism and advocated for it. The component of a person's
thinking that he believed to be separate from matter and immune to the laws of nature
is called the soul or spirit. Contrarily, animals lacked this duality and could be
processed just like machines. The materialist position, which disagrees with the dualist
perspective and instead holds that mental processes are only the brain's physical
operations, is one option. To put it simply, free will is just the way in which the
decision-maker takes in all of the available alternatives.
Considering that there is a physical mind that knows how to change data, finding out
where the data came from is the next obstacle. knowledge. The maxim "Nothing is in
the understanding, which was not first in the senses" is a defining characteristic of the
empiricism movement, which began with Novum Organum 2 and continued until its
conclusion. The idea that general principles are learned by repeated exposure to
connections between their constituent parts was first stated in a treatise on human
nature. This idea is now often referred to as the principle of induction. Using the work
of the well-known Vienna Circle as a foundation, the philosophy of logical positivism
was established by.
This philosophy asserts Thus, logical positivism is a blend of rationalism and
empiricism; all knowledge may be described by logical theories that are ultimately
connected to observation sentences that match to sensory inputs.3) An attempt to study
the process of getting knowledge from experience and the confirmation theory put
forward by Carnap. "The Logical Structure of the World" was published in 1928 by
Carnap and described an explicit computational method for deriving meaning from
elementary experiences. Some say it was the first attempt to model mental processes as
computing procedures.
In the philosophical image of the mind, the relationship between knowledge and action
is the last component that brings everything together. Because intelligence includes
both thinking and action, this issue is very important to artificial intelligence. Further,
we can only comprehend how to construct an agent whose acts are reasonable (or
logical) if we have a comprehension of the manner in which actions are justified. This
book's front cover also has the last section of this piece in its original Greek form.
According to Aristotle, there must be a rational connection between goals and the
knowledge of the action's outcome for the action to be justified. The reason for this is
stated in De Motu Animalism. However, what causes the fact that thinking is
sometimes accompanied by movement and other times it is not, and that motion is
10 | P a g e
sometimes accompanied by thinking and other times it is not? From the appearance of
things, it seems that the situation is quite similar to the one that occurs while thinking
and drawing conclusions about things that do not change.
On the other hand, in that scenario, the conclusion is a proposition that is based on
speculation, but in this scenario, the conclusion that is derived an action is derived from
the two premises. A cloak provides the covering I want. Someone gives me a cloak. A
cloak is something that I require, and I have to manufacture it myself. I need to create
a cloak on my own. Furthermore, the conclusion, which states, "I need to make a cloak,"
is an activity.
Aristotle provides more elaboration on this subject in his Nicomachean Ethics, where
he proposes an optimisation algorithm:
We do not ponder about the objectives, but rather about the methods. They assume the
end They think about the process and the means by which it is accomplished, and
whether or not it appears to be easily and best produced in this way. If it is accomplished
in this way alone, then they think about the process by which it will be accomplished
in this way. This continues until they reach the first cause, and what appears to be last
in the analysis order is actually first in the becoming order. Reason being, neither a
doctor nor an orator gives any thought to whether they will cure or convince. We give
up the search if we come across an impossible, such as when we are in need of money
but it is not feasible to get it. On the other hand, if something seems to be doable, we
make an effort to accomplish it.
It wasn't until 2300 years later that Newell and Simon incorporated Aristotle's
technique into their mapping and navigation system. For the time being, we will refer
to it as software for planning regressions.
The Though useful, goal-based analysis cannot tell you what to do when you have
several options for achieving your goal or when you have no choice at all. accomplish
the goal in its entirety.
An accurate description of a quantitative method for determining what course of action
to pursue in situations such as these was provided by Antoine. contributed to the spread
of the concept of rational decision criteria throughout all aspects of human endeavours.
In the next part, we will talk about the more formal theory of choices to be explored.
11 | P a g e
1.2.2 Mathematics
For the purpose of drawing accurate conclusions, what are the formal rules?
 What is it possible to compute?
 How do we reason when we are with knowledge that is uncertain?
There are some of the essential principles of artificial intelligence that were established
by philosophers; but, in order to make the transition to a formal science, there was a
need for a degree to the formalization of mathematics in the three crucial domains of
computation, probability, and logic. Although ancient Greek philosophers laid the
groundwork for formal logic, it was the mathematicians who first attempted to unravel
the complexities of propositional logic, sometimes called Boolean logic, who laid the
groundwork for formal logic in mathematics. First order logic, which is being used
today, was established in 1879 when Boole's logic was extended to incorporate objects
and relations. shown how to connect logical objects to real-world objects by outlining
a theory of reference.
After that, Determining the limits of what might be achieved via the use of reasoning
and computation was the subsequent stage. Most people think that the first nontrivial
algorithm was something that Euclid came up with to find the greatest common
divisors. During the ninth century, the Persian mathematician al-Khowar Azmi is
credited with the invention of the term algorithm as well as the concept of studying
algorithms. It was via his works that al-Khowar Azmi brought Arabic numbers and
algebra to Europe.
In the late 19th century, Efforts were underway to formalize broad mathematical
thinking by the end of the century, when mathematicians like Boole started looking at
methods for logical deduction. In 1930 it was shown that every assertion in Frege and
Russell's first-order logic could be proved to be accurate. But it turned out that firstorder logic couldn't understand mathematical induction, which meant it couldn't handle
the natural numbers. The limits of deductions were shown in 1931.
Every strong formal theory, including Peano arithmetic, the foundational theory of
natural numbers, contains true assertions that are undecidable, as his incompleteness
theorem demonstrated. Because of this, the concept is unsupported by evidence It is
also possible to read this basic result as demonstrating These methods do not effectively
12 | P a g e
capture all of the various functions that may be performed on integers, which makes it
impossible to perform some of these functions computationally. As a result, the quest
for the collection of all functions that can be represented as a numerical expression,
also known as computable, was spurred by this. There is simply no formal definition
of a computation or an efficient approach, which is one of the reasons why this concept
is rather troublesome.
On the other hand, according to the Church-Turing thesis, the Turing machine is
capable of computing every function that can be determined by computation. widely
acknowledged as being able to provide an adequate definition. Another thing that
Turing demonstrated was that there are some functions that cannot be computed by a
Turing machine. As an example, no machine is able to determine in a general sense
whether a particular programme will deliver an answer on a certain input or continue
to run indefinitely.
In spite of the fact that it is necessary to have a grasp of decidability and computability
in order to comprehend computers; yet, the concept of tractability has been much more
prominent among the two. In the event if the amount of time necessary to resolve
instances of a problem increases at a rate that is exponentially proportional to the
number of those instances, then we generally consider the problem to be intractable.
When the distinction between exponential and polynomial increase in complexity was
first brought to light, it was in the middle of the 1960s. for the first time.
Considering that exponential growth implies that even modestly big cases cannot be
solved in any acceptable amount of time, this is a crucial point to consider. As a result,
it is strongly recommended that one make an effort to break down the overarching
challenge of producing intelligent behaviour into more manageable subproblems rather
than insurmountable ones.
What is the best way to identify an issue that cannot be solved? A solution may be
found in the notion of NP-completeness, which was first developed by. There are a
huge number of kinds of classical combinatorial search and reasoning problems that
are NP-complete. was shown by Cook and Karp. There is a high probability that any
issue class that can be reduced to the class of NP-complete problems is very difficult
to solve. (The majority of theorists are of the opinion that NP-complete problems are
inherently intractable, despite the fact that this was not shown to be the case.)
13 | P a g e
These findings are in stark contrast to the optimistic reception that the popular press
gave to the early computers, which were referred to as "Electronic Super-Brains" and
were referred to as "Faster than Einstein!" Intelligent systems will be characterised by
their judicious use of resources, despite the fact that the speed of computers is growing.
The globe, to put it in the most basic terms, is an incredibly huge issue instance! The
work that has been done in artificial intelligence has contributed to giving an
explanation for why some instances of NP-complete problems are challenging, while
others are not. simple problems. That is something that the majority of theoreticians
consider to be the case.
These findings are in stark contrast to the optimistic reception that the popular press
gave to the early computers, which were referred to as "Electronic Super-Brains" and
were referred to as "Faster than Einstein!" Intelligent systems will be characterised by
their judicious use of resources, despite the fact that the speed of computers is growing.
The globe, to put it in the most basic terms, is an incredibly huge issue instance! The
study of artificial intelligence has contributed to the explanation of why some NPcomplete issues are difficult while others are simple.
The theory of probability is the third significant contribution that mathematics has
made to artificial intelligence, after reasoning and computing. In the beginning, the
concept of probability was conceived by the Italian, who explained it by referring to
the many possibilities that may occur in gaming situations. This was shown in a letter
that was sent in 1654 and provided evidence of a strategy for forecasting the outcome
of a gambling game that has only been half played and allocating average rewards to
the players. players. The concept of probability rapidly became an important
component of the quantitative disciplines, as it assisted in the management of imprecise
observations and theories that were not fully developed. in addition to others, the theory
was developed further and new statistical approaches were presented. A rule for
revising probability in light of new evidence was suggested by the individual who is
featured on the front cover of this book. Most contemporary methods to uncertain
reasoning in artificial intelligence systems are based on Bayes' rule.
1.2.3 Economics
 In order to maximise the reward, what are some choices that we should
14 | P a g e
 How should we go with this when there is a possibility that others would
not agree with us?
 What is the best way to go with this given that the payout may not be
realised for quite some time?
"An Inquiry into the Nature and Causes of the Wealth of Nations" was released for
public use. by a Scottish philosopher in the year 1776 marked the beginning of the field
of economics as a scientific discipline. Smith was the first person to approach
economics as a science. He did this by on the basis of the concept that economies may
be seen as being composed of individuals who are attempting to optimise their own
personal financial wellbeing at all times. Even while previous economic theorists had
made contributions to economic theory before to Smith, no one had ever regarded
economics to be a scientific discipline.
The majority of people have the misconception that economics is about money;
however, economists will tell you that they are really examining how individuals make
decisions that result in results that they believe are desirable. In the event that When
you ask McDonald's why they price $1 for a hamburger, they will simply tell you that
they like $1 and are expecting that people would purchase it. John von Neumann and
Oskar Morgenstern were the first people to explicitly create the mathematical concept
of utility, which is often referred to as "preferred outcomes" . This was
accomplished in their work titled "The Theory of Games and Economic Behaviour,"
which was published in 1944. John von Neumann and Morgenstern went on to expand
upon this theory and formalize it further.
A framework that is both formal and comprehensive for decisions (economic or
otherwise) that are made in the face of uncertainty is required. provided by decision
theory, which is a combination of probability theory and utility theory. This framework
is applicable in situations where probabilistic descriptions accurately describe the
environment in which the decision maker operates. This works well for economies that
are considered to be "large," in which each agent does not have to pay keeping a careful
eye on the individual behaviour of other agents.
As compared to "big" economies, "small" ones are more like a game, with one person
may dramatically impact the utility of another player (either in a favourable or negative
way). In the process of developing game theory, Von Neumann and Morgenstern came
to the unexpected realisation that, for some games, a rational actor ought to follow
15 | P a g e
strategies that are (or at least seem to be) random. Game theory, in contrast to decision
theory, does not provide a clear and unambiguous prescription for choosing actions.
The third topic that was described above was not addressed by economists for the most
part. This question was about How is it possible for someone to make judgements that
are reasonable when the outcomes of their actions do not manifest instantly but rather
are the product of a combination of factors? succession. During World War II, the area
of operations research arose as a result of efforts made in Britain to optimise radar
systems. Subsequently, this issue was studied within the context of operations research,
which discovered civilian applications in the realm of complicated management
choices. The research conducted by formalized a category of sequential choice
problems that are referred to as Decision procedures based on Markov chains.
The areas of economics and operations research are responsible for a significant portion
of the information that we have on rational agents. considerable amount of time,
artificial intelligence research has proceeded along completely different routes. One of
the reasons was the seeming difficulty in making judgements that are made rationally.
The pioneering artificial intelligence researcher was awarded for his revolutionary
work demonstrating that models based on satisficing—making judgements that are
"good enough," rather than meticulously calculating a perfect decision—better
mirrored real human behaviour, he was awarded the Nobel Prize in economics in 1978.
This was in recognition of his groundbreaking work. Decision-theoretic paradigms had
a boom in popularity throughout the decade of the 1990s. methodologies for agent
1.2.4 Brain research
• What is the mechanism by which the brain processes information?
The field of research known as neuroscience focuses on the nervous system,
and more specifically the brain. It has been known for thousands of years that
the brain does, in fact, allow thinking, due to the fact that serious head injuries
may produce mental incapacitation. Even if it remains one of the most baffling
mysteries to scientists, the exact process by which the brain permits cognition,
this remains the case. To rub salt in the wound, the fact that human brains are
fundamentally different from animal brains has long been recognised. The
ancient Greek philosopher Aristotle said, "of all the animals, man has the largest
16 | P a g e
brain in proportion to his size." This statement was made about 335 B.C.5. On
the other hand, widespread recognition of the brain as the location where
awareness is stored. Prior to that time, the heart and the spleen were among the
potential places for the organ.
In 1861, research was conducted on individuals who had suffered brain injury
and had a speech defect known as aphasia. This study proved the presence of
localized regions various sorts of thinking are handled by various parts of the
brain. It was specifically shown by him that the areas of the left hemisphere of
the brain that are now referred to as Broca's region were responsible for the
creation of speech. Before the development of a staining method in 1873, it was
not possible to distinguish individual neurons in the brain (see to Figure 1.2 for
further information). At that point in time, it was common knowledge that
neurons, also known as nerve cells, are the building blocks of the brain. During
his groundbreaking research on the neural architecture of the brain, he used this
method. is credited as being the pioneer in studying the neurological system via
the use of mathematical models.
Figure 1.1 The components that make up a neuron or nerve cell. An individual
neuron is made up of a cell body, also known as a soma, which houses a cell
nucleus. Dendrites are a collection of fibers that extend outward from the cell
body, while the axon is a single, long fiber that extends towards the cell body.
Source: Data Processing and Artificial Intelligence: A Contemporary Approach, Stuart
J. Russell and Peter Norvig, 2010.
17 | P a g e
At this point, we have some information on the mapping that takes place between
different regions of the central nervous system and the organs and tissues that it controls
or that it receives sensory information from. It is possible for these mappings to undergo
significant transformations over the period of a few weeks, and it seems that some
species have more than one map. In addition, we do not have a complete understanding
of how other sections can carry out tasks in the event that one part is harmed. For the
most part, there is no theory that can explain how an individual's memory is stored.
The electroencephalograph (EEG) was first developed by Hans Berger in 1929,
marking the beginning of the process of measuring the activity of the brain in its
entirety. Functional magnetic resonance imaging (fMRI), which was developed
relatively recently, is providing neuroscientists with pictures of brain activity that are
unparalleled in their level of detail. This innovation enables assessments that correlate
with cognitive processes in intriguing ways now taking place. The advancements that
have been made in single-cell recording of neuron activity have contributed to this.
Electrical stimulation, chemical stimulation, or even optical stimulation may be used
to excite individual neurons, which enables the mapping of neural input–output
interactions. We have made significant progress, but we still have a long way to go
before we fully comprehend how cognitive processes truly operate.
A collection of basic cells may lead to cognition, action, and awareness, or, to put it
more succinctly, brains cause minds. This is the genuinely astounding conclusion that
can be drawn from this.
Table 1.2 The human brain is compared to the unprocessed data stored on the
IBM BLUE GENE supercomputer, which is a normal personal computer from
the year 2008, although the comparison is rudimentary.
Super computer
Computational units
transistors
transistors
Storage units
1014 bits RAM
10" bits RAM
1015 bits disk
1013 bits disk
18 | P a g e
How much time is needed for a
Security and operations department
of the department
Memories updates/sec
Source: Artificial Intelligence a Modern Approach Data Collection and Processing
Through Peter Norvig and Stuart J. Russell are the authors of this piece. 2010.
Mysticism is the sole genuine alternative explanation, which proposes that minds
conduct their operations in a mystical world that is outside the sphere of physical
Digital computers and brains have several characteristics that are distinct from one
another. According to the data shown in Figure 1.3, the cycle time of a computer is one
million times quicker than the human brain is comparable to this. In other areas, like as
storage and connections, the brain has a capacity that is greater than that of even the
most powerful home computer. This allows the brain to compensate for its less strong
processing capabilities in other areas. (However, it is important to point out that the
brain does not seem to employ all of its neurons at the same time.) The raw comparisons
are not very helpful, despite the fact that futurists make a lot of noise about these
figures, suggesting that a tipping point will soon be reached when computers achieve a
level of performance that is greater than that of humans. Even with a computer that has
a capacity that is essentially limitless, we would still not be able to figure out how to
acquire the same degree of intelligence as the brain.
1.2.5 Psychology
How do animals and humans think and behave differently?
Generally speaking, the work of the German physicist and his pupil is
considered to be the foundation upon which scientific psychology was
founded. Helmholtz used the scientific method in his investigation
Regarded as "the single most important treatise on the physics and
physiology of human vision" even today, his Handbook of Physiological
Optics remains a major work in the field of human visual science. Wundt
founded the first experimental psychology lab in the world at the University
19 | P a g e
of Leipzig. year 1879. Wundt insisted on conducting tests that were
meticulously controlled, in which his employees would carry out a task
associated with perceptual or associative thinking while simultaneously
reflecting on their own mental processes. In spite of the fact that the tight
controls contributed significantly to the transformation of psychology into
a scientific discipline, the subjective character of the data made it very
improbable that an investigator would ever disprove his or her own
hypotheses.
On the other hand, biologists who research animal behaviour did not have
access to introspective data and instead created an objective technique, as
outlined by in his important book Behaviour of the Lower Organisms.
Claiming that introspection could not provide reliable data, they rejected
any explanation that included mental processes. the behaviorism movement,
which was headed by, applied this attitude to humans and rejected any
theory that involved mental processes. When an animal was provided a
stimulus, and only then were objective measurements of that stimulus taken.
the behaviours (or reaction) that these percepts elicited from the animal
were allowed to be studied by behaviorists. While behaviorism was
successful in gaining a knowledge of rats and pigeons, it was less successful
in comprehending human beings.
At the very least, Helmholtz proposed that seeing things required an
unconscious kind of thinking, which could be traced back to his works and
the origins of cognitive psychology. This view of the brain as a machine for
processing data goes all the way back to the very first days of the discipline.
While behaviorisms largely eclipsed the cognitive approach in the US,
cognitive modelling flourished under the leadership of at Cambridge's
Applied Psychology Unit. Such "mental" concepts as beliefs and objectives
were firmly reinstated in the work of Bartlett's disciple and successor, The
Nature of Explanation.
Despite the fact that molecules in gases do not possess either of these
properties—temperature or pressure—the author maintained that these
phrases are scientifically equivalent. According to Craik, there are three
main steps to follow in order to be a knowledge-based agent: (1) converting
the stimulus into an internal representation; (2) using cognitive processes to
20 | P a g e
alter the representation and create new internal representations; and (3)
retranslating these representations into action. He went into great depth
about why this was a fantastic agent design: In every way imaginable, an
organism's ability to adapt to its environment depends on its ability to
maintain an internal "small-scale model" of both the external reality and its
own potential actions. This model allows the organism to try out different
options, pick the best one, anticipate and react to future situations, draw on
its past experiences to navigate its present and future, and much more
Donald Broadbent, who’s seminal 1958 work
Perception
Communication was among the first to conceptualize mental processes as
data processing, continued Craik's work after he passed away in a bicycle
accident in 1945. Broadbent's book was ahead of his time in using
information processing to explain psychological occurrences. During this
time, the area of cognitive science was established in the United States of
America as a result of the advent of computer modelling. One may say that
the field has its roots in a workshop that took place at MIT in September of
1956. It will be clear to us that this is just two months after the meeting that
was the occasion of the "birth" of artificial intelligence.
The Magic Number Seven was given by George Miller, Three Models of
Language was offered by Noam Chomsky, and The Logic Theory Machine
was delivered by Allen Newell and Herbert Simon. All of these
presentations took place during the workshop. These three seminal works
demonstrated the potential of computer models for studying the mental
processes involved in memory, language, and reasoning, in that order. "A
cognitive theory should be like a computer programme"–the concept put out
by Anderson in 1980 is now widely held among psychologists, despite the
fact that it is not universally accepted. This means that the theory should
explain a comprehensive information processing mechanism that might be
used to accomplish a cognitive function.
1.2.6 Computer engineering
What are some ways that we can construct a fast computer?
21 | P a g e
Intelligence and an artefact are absolutely necessary for the development of
artificial intelligence to be successful. For the most part, the computer has
become the object of choice. It was experts from three different nations who
were engaged in World War II that came up with the idea for the
contemporary digital electronic computer. These scientists worked
separately and practically concurrently. During the year 1940, Alan Turing's
team constructed the electromechanical Heath Robinson8 computer for the
sole aim of interpreting German signals. This was the first computer that
was really operational. The Colossus, a powerful general-purpose machine
that was built on vacuum tubes, was brought into existence by the same
group in the year 1943.9) The Z-3, which was invented by Konrad Zeus in
Germany in 1941, was the first programmable computer that was really
operational.
The first high-level programming language, Panchal, was also developed
by Zeus. Additionally, he was the inventor of floating-point numbers. At
Iowa State University, between the years 1940 and 1942, John Atanasoff
and Clifford Berry, who was a student of Atanasoff's, put together the ABC,
which is considered to be the first electronic computer. The ENIAC, which
was built John Eckert and John Mauchly were members of a team at the
University of Pennsylvania that developed the technology that ended up
being the most significant precursor to contemporary computers.
Atanasoff's research did not gain much backing or acknowledgment.
Computer hardware has come a long way since then, with each new
generation bringing faster processing speeds, smaller form factors, and
lower prices. capacity from the previous generation. Around the year 2005,
manufacturers began increasing the number of central processing unit
components instead of the rate of the clock in order to account for power
dissipation issues. Prior to that, performance had been doubling around
every 18 months. As of right now, it is anticipated that future improvements
in power will be the result of tremendous parallelism, which is a peculiar
convergence with the characteristics of the brain.
Calculating machines existed, without a doubt, prior to the invention of the
electronic computer. On the sixth page, we spoke about the first devices that
were automated, which dated back to the seventeenth century. In the year
22 | P a g e
1805, came up with the idea for the first programmed machine, which was
a loom. The design instructions for this loom were held on punched cards.
that was for the purpose of weaving. During the middle of the 19th century,
conceived of two different machines, two of which he did not finish
building. The Difference Engine was conceptualized with the purpose of
calculating mathematical tables for applications in the fields of engineering
and science.
Finally built and shown at London's Science Museum in 1991, it had been
a long time coming . More ambitious than previous
inventions, Babbage's Analytical Engine had addressable memory, stored
programmes, conditional jumps, and the ability to execute universal
computing. The daughter of poet Lord Byron and Babbage's partner, Ada
Lovelace, is considered to be the world's first programmer. It is in her honor
that the computer language Ada was given its name. She produced
programmes for the Analytical Engine, which was still in the process of
being completed, and she even put out the idea that the computer might
make music or play chess.
Additionally, artificial intelligence is indebted to the branch of computer
science known as software engineering for producing the languages,
operating systems, and tools needed to create modern software applications.
Nevertheless, this is one domain where the debt has been repaid:
advancements in AI have spawned several ideas that have found their way
back into traditional computer science. Timesharing, interactive
interpreters, Windows PCs, RAD environments, linked lists, automated
storage management, and the basics of symbolic, functional, declarative,
and object-oriented programming are all part of these principles.
1.2.7 Theory of control and cybernetics
 How are artefacts able to function independently of their own control?
The earliest machine that could govern itself was constructed by Kesaris of
Alexandria about the year 250 B.C. It was a water clock that included a
regulator that prevented the flow rate from fluctuating. Because of this
innovation, the capabilities of an artefact were rethought and redefined. Until
23 | P a g e
recently, only living organisms were capable of modifying their behaviour in
reaction in response to changes in their immediate physical environment. The
thermostat and governor of the steam engine are two further instances of selfregulating feedback control systems. The latter was created by the same person
who also invented the submarine. Stable feedback system theory as we know it
now emerged in the nineteenth century.
The driving force behind the creation of control theory as we know it today.
Wiener was a brilliant mathematician who worked with Bertrand Russell and
others before developing an interest in the connection between cognition and
mechanical and biological control systems. After collaborating with Russell, he
developed this passion. Wiener, together with Arturo Rosenbluth and Julian
Bigelow, cast doubt on the behaviorist’s tenets .
Another figure who challenged the behaviorists canon was Craik, who used
control systems as a paradigm for psychology. Their view is that regulatory
systems try to minimise "error," or the gap between the current and ideal states,
and that this leads to purposeful behaviour.
Wiener, Warren McCulloch, Walter Pitts, and John von Neumann were the
organizers of a number of landmark seminars at the close of the 1940s that
probed the emerging computational and mathematical theories of cognition.
These gatherings took the shape of conferences. Cybernetics, Wiener's 1948
best-selling book on artificial intelligence, roused the public to the possibility
of such robots. During this time, was an early trailblazer in the implementation
of similar ideas in the UK. To serve "those who had Wiener’s ideas before
Wiener’s book appeared," the Ratio Club was founded by Ashby, Alan Turing,
Grey Walter, and a few others with Wiener. Both in 1948 and 1952, Ashby
published "Design for a Brain," in which he laid out his ideas on how
homeostatic systems with sufficient feedback loops may achieve stable
adaptive behaviour and, by extension, intelligence.
Creating systems that continuously maximise an objective function throughout
operation is the main goal of modern control theory, especially the branch of
control called stochastic optimal control. All things considered, this is
consistent with our view of AI, which is to design optimal systems. Hence, why,
despite the close relationship between its founders, are artificial intelligence and
control theory two separate sciences? It is possible that the answer lies in the
24 | P a g e
close connection between the participants' familiar mathematical techniques
and the linked groups of issues covered in each worldview. Calculus and matrix
algebra, two tools of control theory, are especially helpful for systems that can
be characterised by fixed sets of continuous variables. Conversely, these
limitations were partly the impetus for the early development of artificial
intelligence. Thanks to early access to computation and logical inference, AI
researchers were able to investigate topics like language, vision, and planning
that control theorists could not even begin to fathom.
1.2.8 Languages
 Language and thought: what is the connection?
Verbal Behaviour was published by B. F. Skinner in 1957. Written by the
leading authority in the subject, this was an exhaustive and extensive
description of the behaviourist method of language acquisition. Curiously,
however, interest in behaviourism almost died out when a review of the book
became as famous as the book itself. The linguist Noam Chomsky wrote the
review; he had just released a book titled Syntactic Structures that outlined his
own idea. The ability of a youngster to comprehend and construct sentences
from scratch is something that Chomsky noted the behaviourist approach failed
to answer. Chomsky's theory, which he derived from syntactic models proposed
by the Indian linguist Panini (c. 350 B.C.), provided an explanation for this
phenomenon and, in contrast to other ideas, was formal enough to be, in theory,
programmed.
Computational linguistics, also known as natural language processing, is a
hybrid discipline that emerged from the confluence of modern linguistics and
artificial intelligence (AI), which were "born" at the same time. It quickly
became clear that the issue of language comprehension was much more intricate
than it had seemed in 1957. To fully grasp a language, one must be well-versed
in not just its syntax and semantics, but also its subject matter and context.
Despite how apparent it now is, this did not get widespread recognition until
the 1960s. Knowledge representation, which seeks to "represent" information
so that computers can understand and use it, owes a great deal to linguistics,
which in turn drew heavily on decades of philosophical inquiry into language.
25 | P a g e
1.3 AI's Evolution Through Time
We are now prepared to discuss the evolution of artificial intelligence itself, having
completed the background material.
1.3.1 The years between 1943 and 1955: the birth of AI
The work that accomplished is often regarded as the foundational work of what is
currently known as AI. Their three main sources of information were the theory of
computers put out by Turing, a formal study of propositional logic credited to Russell
and Whitehead, and our current knowledge of the basic anatomy and function of brain
neurons. They proposed a model of artificial neurons where each neuron is described
as "on" or "off," and a "turn on" switch occurs when enough neighboring neurons are
stimulated. The neurons may exchange information with each other in this system. The
state of a neuron was once believed to be "factually equivalent to a proposition which
proposed its adequate stimulus."
The fact that every conceivable function might be computed by a network of
interconnected neurons was one example they provided. It was also shown that basic
net topologies could implement all the logical connectives. In addition, McCulloch and
Pitts postulated that knowledge acquisition may occur in well-specified networks.
Donald Hebb introduced a simple updating mechanism for adjusting the strength of
connections between several neurons in 1949. His rule, which evolved into Hebbian
learning, remains an important paradigm to this day.
Marvin Minsky and Dean Edmonds, both of whom were undergraduate students at
Harvard, were the ones who constructed the first neural network computer in the year
1950. For the purpose of simulating a network of forty neurons, It was called the
SNARC and it used 3,000 vacuum tubes together with an automated pilot system that
had been spared from a B-24 bomber. While a student at Princeton, Minsky persisted
in studying neural networks and universal computing. Von Neumann reportedly said,
"If it isn't now, it will be someday." This was in reaction to the doubts voiced by his
Ph.D. committee on the mathematical status of his work. Future work by Minsky would
prove important theorems illuminating the limitations of neural network research.
In the beginning, there were a few instances of work that may be classified as artificial
intelligence; nevertheless, most notably, Alan Turing had one of the most important of
26 | P a g e
all of them. As early as 1947, he presented talks on the subject among the members of
the London Mathematical Society. He went on to wrote a paper titled "Computing
Machinery and Intelligence," in which he established a compelling agenda. Artificial
intelligence, Turing test, genetic techniques, algorithms, and RL were all innovations
that he presented in this passage. With the following explanation, he put out the concept
of the Child Programme: "Rather than attempting to create a programme that simulates
the mind of an adult, why not rather attempt to create one that simulates the mind of a
1.3.2 The year 1956: The beginning of AI
Another prominent figure in AI, John McCarthy, attended Princeton University. Later
acknowledged as the official birthplace of the field, Dartmouth College was
McCarthy's second stop after moving to Stanford University. In 1951, McCarthy
earned a Ph.D. from that university and spent two years teaching there. U.S. academics
interested in automata theory, neural networks, and intelligence studies were eagerly
assembled by McCarthy with the help of Claude Shannon, Nathaniel Rochester, and
Minsky. Their two-month workshop at Dartmouth was scheduled for the summer of
1956. As per the strategy, 10
At Dartmouth College in Hanover, New Hampshire, we suggest conducting research
of artificial intelligence that would last for two months and include ten individuals. The
study would take place during the summer of 1956. The hypothesis that every facet of
learning or any other component of intelligence can, in theory, be characterised with
such precision that a computer can be built to imitate it will serve as the foundation for
the research that will be carried out. There will be an effort made to discover a way to
teach computers to utilise language, to create abstractions and ideas, to solve types of
issues that are now reserved for people, and to continue to develop themselves. If a
carefully chosen group of scientists collaborate on one or more of these issues for the
duration of a summer, we believe that they will be able to make considerable progress
in addressing one or more of these issues.
In all, there were eleven people who showed there, and among them were MIT's Oliver
Selfridge and Trenchard More of Princeton University, IBM's Arthur Samuel, and Ray
Solomon off. Those who really stole the show were Carnegie Tech researchers Allen
Newell and Herbert Simon. Although other people had ideas and, in certain cases,
software tailored to particular tasks like checkers, Newell and Simon had an existing
27 | P a g e
thinking system named the Logic Theorist (LT). With this code, Simon claimed to have
solved the ancient mind-body problem: "We have invented a computer programme
capable of thinking non-numerically.""12Shortly after the workshop, the programme
proved most of the theorems included in Russell's and Whitehead's Principia
Mathematica. Rumor has it that Simon elated Russell when he showed him a computer
software had produced a shorter proof for one theorem than the one in Principia. The
editors of the Journal of Symbolic Logic were not happy with the work of Newell,
Simon, and Logic Theorist, and so rejected the paper.
Although no new findings came out of the Dartmouth workshop, it was successful in
bringing together all of the key players in the organisation. Over the next two decades,
these people—along with their pupils and coworkers at MIT, CMU, Stanford, and
IBM—would become the field's de facto leaders.
Our understanding of why AI has to emerge as its own field has been much enhanced
by perusing the Dartmouth workshop proposal. The fact that control theory, operations
research, and decision theory could have absorbed all of the AI effort is perplexing,
given that their aims are similar to AI's. Another way of looking at it is: why isn't AI a
branch of mathematics? One possibility is that AI has always been receptive to the idea
of being able to mimic human traits like creativity, self-improvement, and language
skills. No other place could have possibly addressed these problems. The alternative
response is known as methodology. Among these areas, only artificial intelligence (AI)
stands out as a separate branch of computer science; although, AI and operations
research do share a concentration on computer simulations. In addition, no other field
attempts to build computers that can function autonomously in complex and dynamic
situations like artificial intelligence (AI).
1.3.2 I was excited and full of expectations for the years 1952–1969.
In a restricted sense, the early years of artificial intelligence were very fruitful. As a
result of the crude computers and programming tools that were available at the time, as
well as the fact that computers were considered to be being limited to doing
mathematical operations alone; every hint of brilliance from a computer was greeted
with astonishment. Most members of the intellectual elite have decided that "a machine
can never do X." a lengthy list of Xs that Turing compiled may be seen here. Artificial
intelligence researchers replied in a natural way by proving one X after another. It was
28 | P a g e
around this time that John McCarthy coined the phrase "Look, Ma, no hands!" she said,
going on to describe them.
Following its first success, Newell and Simon introduced the General Problem Solver,
more often referred to as the GPS. In contrast to Logic Theorist, the goal of this
program's development was to imitate the protocols used by people to solve issues. It
discovered that the sequence in which humans dealt with the same problems matched
the sequence in which the system evaluated subgoals and possible actions. Within the
limited set of problems that the software could solve, this was true. Probably the first
software to use the "thinking humanly" approach was the Global Positioning System
As a result of the success of the Global Positioning System (GPS) and subsequent
programmes as models of cognition, the famous physical symbol system concept was
developed. Basically, it states that "a physical symbol system has the necessary and
sufficient means for general intelligent action." To rephrase, what they meant was that
any system, whether it human or digital, that demonstrates intelligence must function
by manipulating data structures that are made up of individual symbols. This idea has
been called into question from a variety of angles, as we shall see in the next section.
It was at IBM that Nathaniel Rochester and others created some of the first AI
programmes. developed the Geometry Theorem Prover, which proved theorems that
many math’s students would find difficult. In 1952, Arthur Samuel started writing a
number of checkers programmes (draughts). These algorithms mastered the art of
amateurism at last. One of the programmes was named "Checkers." In the process, he
debunked the notion that computers are only capable of doing what they are instructed
to do. His programme soon learnt to play a game that was superior to the one that it
was designed to play.
During the month of February in the year 1956, the programme was shown on
television, which left a significant influence. Similar to Turing, Samuel struggled to
find time to work on his computer. He worked at night, using devices that were still
stored in IBM's production factory. He was able to do this. Chapter 5 discusses the act
of playing games, and provides an explanation of the learning strategies that Samuel
employs. When John McCarthy transferred from Dartmouth to the Massachusetts
Institute of Technology (MIT), he produced three significant contributions in the same
year, 1958. Lisp, an advanced computer language, McCarthy created it in MIT AI Lab
29 | P a g e
Memo No. 1. Lisp would go on to become the most popular programming language for
artificial intelligence during the following thirty years. McCarthy was able to get the
tool he required by using Lisp; but, gaining access to limited and costly computer
resources was a significant challenge for him. Time sharing was a solution that as a
result of his collaboration with colleagues at MIT. Also in 1958, McCarthy put out a
paper called Programmes with Common Sense. In it, he introduced the Advice Taker,
a made-up software that may be the first complete AI system. In the article, McCarthy
explains who the Advice Taker is. Similar to the Logic Theorist and the Geometry
Theorem Prover, McCarthy's software was built to employ knowledge in order to seek
solutions to issues.
It was, nevertheless, to encapsulate broad knowledge of the world, which was different
from the other things. By way of illustration, he demonstrated how the programme
would be able to build a strategy to travel to the airport by using a few simple
assumptions. It was also built to be able to accept new axioms as part of its regular
course of operation. This made it possible for the software to become proficient in new
domains without having to be reprogrammed. Therefore, the Advice Taker exemplified
the fundamental concepts of knowledge representation and reasoning, which are that it
is advantageous to possess a formal and explicit representation of the world and the
processes that it operates, and that it is also beneficial to be able to change that
representation via the application of deductive reasoning. To this day, it is astonishing
how much of the work that was published in 1958 is still relevant.
In 1958, Marvin Minsky relocated to the Massachusetts Institute of Technology (MIT).
His first attempt at working with McCarthy did not, however, prove to be successful.
McCarthy placed a strong emphasis on representation and reasoning inside formal
logic, with Minsky's primary focus being the effectiveness of programmes, he
eventually established an anti-logic stance within the area. McCarthy founded Stanford
University's artificial intelligence lab in 1963. J. A. Robinson's 1965 discovery of the
resolution technique advanced his desire to use logic to develop the ideal Advice Taker.
As a first-order logic algorithm, the resolution technique proves theorems in their
entirety. A focus on generalizable methods of logical reasoning was central to the
Stanford research. Applications in logic include, for instance, the Shakey robots project
at the Stanford Research Institute and the question-answering and planning systems
created by Cordell Green . The second endeavour, which demonstrated
the first ever complete integration of rational reasoning and physical action, is
30 | P a g e
discussed in more depth. In the course of his supervision, Minsky oversaw a group of
students who selected restricted projects that looked to demand intellect to accomplish.
The term "microworld" developed to refer to these constrained realms. It was possible
for the SAINT programme, which was developed by James Slagle in 1963, to answer
closed-form calculus integration problems that are typical of first-year college courses.
Problems involving geometric analogies that are seen in intelligence tests were
answered by Tom Evans's analogies programme in 1968. The STUDENT programme,
which was developed by Daniel Bobrow in 1967, was able to answer algebra narrative
problems such as the following:
Find out how many consumers Tom gets in total if he runs 45 ads and gets twice the
square of 20% of those customers each time.?
Figure 1.4 From the block world comes this sight. "Find a block that is taller
than the one you are holding and put it in the box," SHRDLU orders, having
just completed the preceding sentence's instructions.
Source: AI By Stuart J. Russell and Peter Norvig , a new method for collecting
and processing data has emerged.
Among the several microworlds, the blocks world has the most name recognition. The
building blocks are solid pieces that, as shown in Figure 1.4, are placed on a tabletop
(or, more often, a tabletop simulation). Rearranging the blocks in a certain way is one
of the common activities seen in this environment, which is accomplished by utilising
31 | P a g e
a robot hand that can pick up one block at a time. Aside from housing the planner, the
blocks world was the site of the vision project for the NLU programme and the
constraint propagation work for the LT.
In addition, early work that was based McCulloch and Pitts' neural networks achieved
remarkable results. A large number of components may collectively represent, as
shown in the work done by a single notion, resulting in an improvement in both
resilience and parallelism that was proportional to the number of elements. Hebb's
learning strategies were improved by the individuals who referred to his networks as
Adaline’s, as well as by himself and his perceptrons. According to the perceptron
convergence theorem, a learning algorithm has the ability to modify the perceptron's
connection strengths to match any input data, if such match exists.
32 | P a g e
ASSOCIATES OF INTELLIGENT
We would like to provide you with a warm welcome to the world of Associates of
Intelligent, a place where intellectualism and creativity bloom. It is our community that
shines as a light of knowledge, collaboration, and development in a world that is rife
with difficulties. Associates of Intelligent is more than simply an organisation; it is a
group of people who are united by a common interest in intellectual pursuits and a
dedication to have a significant influence on the outside world. Here, we acknowledge
that intelligence may manifest itself in a variety of ways, ranging from expertise in
academics to inventiveness in artistic endeavours, from emotional intelligence to
technical innovation. To harness the power of intelligence in all of its dimensions in
order to address the most important problems that mankind is now experiencing is our
objective, which is both straightforward and deep.
Associates of Intelligent is committed to using our collective intelligence for the benefit
of society as a whole, whether it is for the purpose of furthering scientific discovery,
supporting social justice, creating economic success, or developing creative expression.
As a member of our community, you will have the opportunity to interact with people
who share your values and come from a variety of different backgrounds and fields of
study. You will also have the chance to work together on projects that push the limits
of knowledge and offer your one-of-a-kind skills to the ongoing effort to make the
world a better place. So, whether you are a scientist who is trying to solve the mysteries
of the universe, an entrepreneur who is trying to revolutionize industry, an artist who
is inspired to evoke emotion and provoke thought, or simply someone who believes in
the power of intelligence to change the world, we would like to extend a warm welcome
to you here at Associates of Intelligent. Let us go on a journey together that will be
filled with discoveries, innovations, and impacts.
2.1 AGENTS AND ENVIROMENT
One definition of an agent is "any entity that is capable of observing its surroundings
through the utilisation of sensors and acting upon those surroundings through the
utilisation of actuators." This easy idea is depicted diagrammatically in Figure 2.1 for
your convenience. A human agent is equipped with eyes, ears, and other organs for the
33 | P a g e
purpose of perceiving; for the purpose of acting, it is equipped with hands, legs, voice
tract, and other organs. A robotic agent may be outfitted with a number of different
motors for the purpose of acting as actuators, in addition to cameras and infrared range
finders for the purpose of monitoring its surroundings. There are many different types
of sensory inputs that a software agent can receive. Some examples of these are
keystrokes, the contents of files, and network packets. This agent is responsible for
displaying information on the screen, writing files, and sending network packets in
order to take action on the outside world.
For the purpose of referring to the perceptual inputs that the agent is getting at any
given moment in time, we make use of the phrase "percept." When we talk about the
percept sequence of an agent, we are referring to the whole history of everything that
the agent has ever seen. The choice of action that an agent chooses at any given instant
may, in general, be based on the whole percept sequence that it has observed up to this
point; but it is not possible for it to rely on anything that it has not noticed. Through the
process of specifying the agent's option of action for each and every probable percept
sequence, we have transmitted a significant amount of the information that was
available to us.
Figure 2.1 The ability for agents to engage with their environments is made
possible by a network of sensors and actuators.
Source: Artificial Intelligence a Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
Mentioning the agent is something that is required to be done. A mathematical
perspective allows us to assert that the conduct of an agent is described by the agent
34 | P a g e
function that maps any given percept sequence to an action. This is a statement that can
be made from the perspective of mathematics.
The idea of tabulating the agent function that is characteristic of each individual agent
is something that we are able to think of. For the most majority of agents, this would
be an extremely large table infinite, in fact unless we set a limit on the length of percept
sequences that we desire to take into consideration. In the event that one is in possession
of an agent with whom to carry out tests, it is theoretically possible to construct this
table by putting all of the potential percept sequences through their paces and
maintaining a record of the behaviours that the agent exhibits in response to each of the
sequences. One would anticipate that the table will contain an external description of
the agent, and this is exactly what is the case.
When it comes to the implementation of the agent function for an artificial agent on the
corporate level, the responsibility will fall on an agent programme. To ensure that these
two ideas are distinct from one another, it is necessary to keep them distinct. In contrast
to the agent programme, which is a concrete implementation that is carried out within
a physical system, the agent function is a mathematical description that is abstract. For
the purpose of elucidating these ideas, we will make use of a fairly straightforward
illustration, which presents the universe of hoover cleaners that can be found in Figure
2.2. We are able to describe everything that takes place in this world because it is so
basic; also, because it is a made-up world, we are able to generate a tremendous lot of
diversity in it.
Within the confines of this particular universe, the only two locations that may be
discovered are Squares A and B. A further capability of the hoover agent is the ability
to identify the square in which it is located and to ascertain whether or not the square
contains any dirt. It is able to decide whether it will move to the left, move to the right,
suck up the dirt, or do all of these things at the same time. The following is an
illustration of a fairly straightforward agent function: if the square that is now being
inspected is dirty, the agent should suck; otherwise, the agent should go to the other
You can see a partial tabulation of this agent function in Figure 2.3, and you can see an
example of an agent programme that implements it in Figure 2.8, which is located on
page 48. It is possible to locate both of these figures within the same specific chapter.
35 | P a g e
Looking at Figure 2.3, we can see that the numerous agents that are present in the
vacuum universe may be stated by simply filling in the right-hand column in a variety
of different ways. This is something that we can see when we take a look at the figure.
The question that appears to be the most obvious is, then, what is the most suitable
strategy for filling up the table? In other words, what is it that differentiates a good
agent from a terrible agent, as well as somebody who is bright from someone who is
stupid? The responses to these questions are included in the section that follows.
Figure 2.2 A planet with hoover cleaners with just two sites or locations
Source: Artificial Intelligence A Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
Table 2.1 An illustration of a partial tabulation of a straightforward agent
function specific to the hoover cleaner sector is presented below.
Percept sequence Action
[A, Clean)
[A, Dirty]
[B, Clean)
[B, Dirty]
[A, Clean), V, Clean]
[A, Clean), V, Dirty)
[A, Clean), V, Clean], [A, Clean] [A, Clean), V,
Clean], [A, Dirty]
Suck Hight
Right Suck
Source: Artificial Intelligence a Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
36 | P a g e
In order to ensure that we reach the conclusion of this section, it is essential to highlight
that the idea of an agent is meant to serve as a tool for the analysis of systems, and not
as an absolute classification that divides the entire world into agents and non-agents. It
is feasible to consider a hand-held calculator to be an agent that, when confronted with
the percept sequence "2 + 2 =," automatically picks the action of displaying the number
"4"; yet, such an analysis would not materially help to our grasp of the calculator.
Artificial intelligence works at what the authors regard to be the most intriguing end of
the spectrum. This is the end of the spectrum when the artefacts have large
computational resources and the job environment involves decision making that is not
straightforward. To a certain extent, all subfields of engineering may be seen as the
process of developing objects that engage with the environment for which they were
2.2 GOOD BEHAVIOUR: THE CONCEPT OF RATIONALITY
A rational agent is one that behaves in a manner that is compatible with common sense;
to put it another way, every item in the table that represents the agent function is filled
out properly. This is the conceptual definition of a rational agent. The fact that doing
the right thing is preferable than doing the wrong thing is not something that should
come as a surprise; but, what precisely does it mean to do the ideal thing? We provide
an answer to this age-old dilemma by employing a strategy that has been in existence
for a very long time: we take into consideration the consequences that result from the
acts executed by the agent.
When an agent is introduced in an environment, it will produce a series of activities as
a result of its presence. The perceptions that the agent has of the surrounding
environment are what dictate the behaviours that it does here. As a consequence of this
sequence of actions, the environment will progress through a number of states in a
sequential manner. In the event that the sequence is wanted, it provides evidence that
the agent has successfully performed their duties. This idea of desirability may be
included, at least to some degree, by a performance metric that is capable of analysing
any particular sequence of environmental conditions.
Please take notice that we were referring to the states of the environment rather than
the states of the agents. If we define success to be the agent's impression of its own
performance, then it is possible for an agent to achieve perfect reason by simply
deceiving itself into believing that its performance was faultless. In instance, people
37 | P a g e
are known to have "sour grapes," which is the perception that they did not truly desire
something (for example, a Nobel Prize) since they did not obtain it. This view is a result
of the fact that they did not receive it.
It is abundantly clear that there is no one performance measure that is relevant to all
tasks and agents in a universal sense; rather, in the majority of instances, a designer
would develop a metric that is acceptable for the particular circumstances. It is not as
easy as it would appear to be to understand this. Consider, for example, the hoover
cleaning agent that was covered in the section that came before this one in the
discussion. There is a possibility that we may propose that performance be judged
based on the amount of dirt that is cleaned up during a single shift that lasts for eight
hours. In the event that you are dealing with a reasonable actor, it is always the case
that you will receive precisely what you have requested. An intelligent agent may
optimise this performance parameter by first cleaning up the filth, then dumping it all
over the floor, then cleaning it up again, and so on.
This would be a cycle that would continue repeatedly. Indefinitely more iterations of
this method are possible. This would be a more acceptable performance statistic to use
in the event that the agent was to be paid for having a clean floor. Consider, for
example, the idea of awarding one point for each clean square at each time step (perhaps
with a penalty for the amount of power utilised and the amount of noise created). This
would be a good example of a possible system. It is preferable to construct performance
measurements in accordance with what one genuinely wishes in the environment,
rather than in accordance with how one feels the agent ought to behave. This is because
it is more likely that the metrics will be more accurate. The method that is being
discussed here is one that is applicable to any circumstance.
Even if the hazards that are readily evident are avoided, there are still a number of
difficult problems that need to be handled or resolved. As an illustration, the idea of a
"clean floor" in the paragraph that came before it is based on the typical degree of
cleanliness that is maintained over a period of time. When it comes to cleaning, one of
the agents consistently does a terrible job, while the other agent cleans with a lot of
Vigor but takes a lot of pauses. However, it is possible for two different agents to
achieve the same level of average cleanliness to the same degree. With that being said,
despite the fact that it could appear to be a little matter of janitorial science, the question
of which is favoured is actually a deep philosophical inquiry that has far-reaching
implications. Would you rather have a life that is full of highs and lows, full of
38 | P a g e
recklessness, or a life that is safe but boring? Which are you more interested in? Is it
more desirable to have an economy in which the majority of people live in a moderate
degree of poverty, or is it more desirable to have an economy in which some people
live in abundance while others are living in extreme poverty? We will leave these
questions as a challenge for the reader who is paying close attention to what we have
to say below.
2.2.1 Rationality
What constitutes fair behaviour at any given time is contingent upon the following four
 The requirements for success are defined by the performance metric.
 The agent's prior knowledge of its surroundings.
 The actions that the agent-human can perform.
 The agent's visual stream up to this moment.
One may therefore arrive at the following definition of a rational agent:
An action that is likely to optimise the performance measure of a rational agent should
be selected by the rational agent for each and every viable percept sequence. In light of
the evidence that is supplied by the percept sequence as well as any preceding
knowledge that the agent possesses, this endeavour ought to be carried out.
Take into consideration the uncomplicated hoover cleaner agent that cleans a square if
it is filthy and moves on to the next square if it is not dirty; this is the agent function
that is discussed in Figure 2.3, which can be found above. Is this anything that you
would regard to be a reasonable agent? Everyone depends on it! It is required to identify
the performance measure, the information that is known about the environment, as well
as the sensors and actuators that are available to the agent. This is the first step in the
process. The following should be taken into consideration:
 One point is awarded by the performance measure for each clean square that is
finished at each time step. This is done throughout the length of a "lifetime" that
is comprised of one-thousand-time steps.
 In spite of the fact that the "geography" of the environment is known in advance
(as seen in Figure 2.2), the distribution of the dirt and the first placement of the
39 | P a g e
agent are not known until much later. Areas that are already clean will continue
to be clean, and sucking will cause the square that is now being cleaned. By
moving the agent to the left and right, respectively, the Left and Right actions
move the agent to the left and right, unless the Left and Right actions would
send the agent outside of the environment, in which case the agent would
remain in the same place.
 Left, right, and sucking are the only action options that are available to be done.
 The agent has a precise awareness of its location and is able to ascertain whether
or not the location in question contains dirt.
As a result of these circumstances, we are able to say that the agent is, in fact, rational;
the level of performance that is anticipated from it is at least similar to that of any other
agent. Exercise 2.2 requires you to make this statement in order to proceed.
Taking into account the many different circumstances, it is not difficult to comprehend
how the same actor might react in an irrational manner. An illustration of this would
be the fact that once all of the dirt has been removed, the agent will move back and
forth without any apparent cause; if the performance measure includes a penalty of one
point for each movement left or right, the agent would perform poorly. If it were a more
effective agent for this circumstance, it would refrain from taking any action up until
the point where it was assured that all of the squares were clean.
In the case that clean squares have a tendency to get dirty again, the agent should make
sure to check on them on a frequent basis and re-clean them if it is deemed essential to
do so. If the geography of the environment is presently unknown, the agent will be
obliged to investigate it rather than remaining in squares A and B. This is because the
agent will be required to study the environment. You will be required to develop agents
that are appropriate for these conditions in order to complete Exercise 2.2.
2.2.2 Omniscience, learning, and autonomy
A distinction that needs to be made between rationality and omniscience is something
that needs to be done with great care. Omniscient agents are aware of the actual
outcomes of their actions and are able to take appropriate action; yet, in the real world,
omniscience is physically impossible to achieve. Taking into mind the first illustration
below: As I am taking a leisurely stroll down the Champs-Elysées, I happen to notice
an old friend standing on the opposite side of the street a few moments later. I make an
40 | P a g e
attempt to be reasonable and start crossing the street because there is no traffic in the
neighbourhoods and I am not engaged in anything else. I am also not involved in
anything else. At the same time, a cargo door from an airliner that is flying overhead at
an altitude of 33,000 feet comes crashing down on me, and before I can make it to the
opposite side of the street, I am crushed beyond recognition. Is it possible that I was
acting strangely when I crossed the street? Given the circumstances, it is highly
implausible that my obituary would contain the words "the idiot tries to cross the
The above illustration illustrates that reason is not the same thing as accomplishing
something perfectly. Rationality, on the other hand, maximizes the performance that is
predicted, in contrast to perfection, which maximizes the performance that really
occurs. This is not simply an issue of being fair to agents, but it is also a matter of
restraining oneself from the requirement of perfection. In the event that we desire an
agent to carry out what ultimately proves to be the most effective action after the
occurrence, then it will be challenging to design an agent that is capable of meeting this
objective. It is not feasible to create something that can meet this condition unless we
improve the performance of crystal balls or time machines. Until then, it will be
impossible.
Because of this, our conception of rationality does not require omniscience because the
reasonable decision is only contingent on the perceptual sequence that has been seen
up to this point in time. In addition to this, it is essential for us to verify that we have
not inadvertently made it possible for the agent to take part in activities that are notably
deficient in intelligence. For instance, if a person does not look in both directions before
crossing a busy road, then the agent's perceptual sequence will not alert it that there is
a large truck coming up behind them at a high rate of speed. This is because the person
is not communicating with the agent.
According to our understanding of what it means to be logical, is it now OK to cross
the street? In no manner, shape, or form! To begin, it would be nonsensical to cross the
street in light of this uninformative sequence of perceptions: the risk of being involved
in an accident if you do not look before crossing the street is too great. Doing so would
be a mistake. Second, a rational agent should select the "looking" action before entering
the street because seeing helps maximum the anticipated performance. This is because
seeing helps maximise expected performance. The reason for this is that gazing
provides assistance in maximising the expectation of performance.
41 | P a g e
A crucial component of rationality is the practice of engaging in activities with the
purpose of influencing future perceptions. This process, which is sometimes referred
to as knowledge gathering, is explored in great length which describes the topic in great
detail. A second example of information gathering is provided by the exploration that
must be carried out by a vacuum-cleaning agent in an area that is initially foreign to
them. This is an example of information gathering.
The rational agent must not only be able to gather information, but it must also be able
to grasp as much as it can from the information that it gets. This is necessary for the
rational agent to meet our definition. There is a possibility that the original design of
the agent will be a representation of some prior knowledge of the environment; but, as
the agent gains experience, this configuration may be modified and maybe even
improved upon. On the other hand, there are unusual situations in which the
environment is completely informed according to a priori. It is not necessary for the
agent to watch or learn in circumstances such as these; it only has to behave in the
proper manner.
It is without a doubt the case that such agents are fragile things. Consider, for instance,
the quite unassuming dung beetle. Following the completion of the excavation of its
nest and the placement of its eggs, it makes its way to a nearby waste and retrieves a
ball of faces to serve as a plug for the entrance of the nest. In the case that the beetle is
removed from the ball of dung while it is in transit, it will continue with its task and
will act as if it is sealing the nest with the dung ball that does not exist, fully ignorant
to the fact that it is absent. An assumption that has been built into the beetle by evolution
is the basis for its conduct; when this assumption is violated, the behaviour of the beetle
is rendered ineffectual. Compared to other types of wasps, Sphex wasps are a little bit
more intelligent.
When the female Sphex has finished excavating a tunnel, she will go out and sting a
caterpillar, and then she will pull the caterpillar to the hole. She will then drag the
caterpillar into the hole and lay her eggs inside. After that, she will enter the burrow
once again to make sure that everything is in order. Immediately following the hatching
of the eggs, the caterpillar will serve as a source of nourishment for the young. At this
point, everything seems to be going according to plan; nevertheless, if an entomologist
moves the caterpillar a few inches away while the Sphex is doing the check, it will
return to the "drag" stage of its plan and will continue the plan without making any
modifications, even after hundreds of interventions involving the movement of the
42 | P a g e
caterpillar. Sphex will not change its plan since it is unable to realise that its intrinsic
approach is not functioning. As a result, it will not make any adjustments to its plan.
The argument that we are making is that an agent does not possess autonomy when it
is dependent on the prior knowledge of its creator rather than on its own opinions. Due
to the fact that the designer most certainly possesses more knowledge than the agent
does, this occurred. A rational agent should be self-sufficient; it should acquire the
information it can in order to compensate for insufficient or faulty prior knowledge.
This is because rational agents are expected to be able to make educated decisions. For
instance, a vacuum cleaner that is able to educate itself to anticipate the areas and
periods at which further dirt will appear will perform far better than one that does not
have this capability.
Initially, it is not very customary to seek complete autonomy from the very beginning.
This is because of the practical challenges involved. In circumstances in which the
agent has had very little to no experience, it would be necessary for it to function in a
random fashion, unless the creator offered some guidance. Therefore, in the same way
that evolution supplies animals with adequate reflexes that allow them to live for a
sufficient length of time to learn on their own, it would be acceptable to equip an
artificially intelligent creature with some initial knowledge as well as the potential to
The conduct of a rational agent can become effectively independent of its previous
knowledge if it has had sufficient experience with its surroundings. This is feasible if
the agent has had sufficient exposure to its environment. Therefore, the incorporation
of learning makes it feasible to design a single rational agent that is capable of attaining
success in a broad variety of diverse circumstances. This is because learning makes it
possible to learn.
2.3 THE NATURE OF ENVIROMENTS
Considering that we now have a concept of rationality, we are almost at the stage where
we are prepared to contemplate the prospect of making rational creatures. As a first
step, we need to take into consideration the task settings, which are essentially the
"problems" to which rational agents are the "solutions." However, we must first take
into consideration the contexts of the tasks. From the very beginning, we will provide
a range of examples to explain the process of defining a task environment. This will
43 | P a g e
be done in order to demonstrate how to make the definition. Following that, we will
show that there are a wide variety of various sorts of task contexts. It is the taste of the
environment in which the task is carried out that has a direct impact on the design that
is appropriate for the agent programme.
2.3.1 Specifying the task environment
For the goal of our discussion about the rationality of the fundamental hoover cleaner
agent, we were needed to identify the performance measure, the surrounds, as well as
the actuators and sensors that were attached to the agent. The phrase that we use to refer
to all of these different aspects is called the task environment, which is an umbrella
term. Those individuals who are interested in acronyms may be aware that we refer to
this description as the PEAS (Performance, Environment, Actuators, and Sensors)
description. The first step that must always be taken when designing an agent is to
always characterise the task environment in as much detail as is practical. This is the
first step that must always be taken.
An easy example of this would be the world of vacuum cleaners; however, let us take
a look at a more challenging problem: an automated taxi driver. We feel it is vital to
warn the reader that a fully autonomous cab is currently a little bit beyond the
limitations of the technology that is now available. This is something that we feel is
important to bring up before the reader becomes very worried. Page 28 contains a
description of a driving robot that is now functioning. When it comes to the whole
driving duties, there is a significant amount of wiggle room available.
We made the decision to make this subject the primary focus of our discussion for a
number of reasons, one of which is because there is no limit to the creative ways in
which events may be combined. A condensed version of the PEAS description of the
working environment of the taxi fleet is presented in Figure 2.4. Immediately following
this, we will proceed to discuss each component in further detail in the following
paragraphs.
Table 2.2 PEAS details the setting in which an autonomous cab may navigate.
Evaluation
Natural Setting
44 | P a g e
comfortable
pedestrians,
various forms of
transportation,
and consumers
Controllers for
direction,
signaling,
Instruments such as
accelerometer,
engine sensors, and
a keyboard
Source: Artificial Intelligence a Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
First and foremost, what is the performance measure that we would like our automated
driver to attempt to attain within the given time frame? Getting to the correct location,
minimising the amount of fuel consumed and the amount of wear and tear, minimising
the amount of time or money spent on the journey, minimising the number of violations
of traffic regulations and disruptions to other drivers, maximising the safety and
comfort of passengers, and maximising earnings are all desirable characteristics. It
should come as no surprise that some of these goals are in direct opposition to one
another; hence, it will be required to make concessions about them. What type of
driving circumstances will the cab be subjected to? This is the second issue that has to
be answered. Each and every taxi driver is needed to handle a broad range of highways,
which may include country lanes, urban alleys, and even motorways with twelve lanes.
Everywhere you turn, you will find other vehicles on the roads, pedestrians, stray
animals, vehicles used for road construction, police cars, puddles, and potholes. In
addition to this, the taxi must have conversations with both potential passengers and
those who are currently in the vehicle. In addition, there are other choices that are not
obligatory to consider. In the event that the taxi needs to run in Southern California,
where snow is not a problem very frequently, or in Alaska, where snow is not a problem
very frequently, there is a potential that it will be necessary to do so.
It is possible that we would like it to be adaptable enough to enable us to drive on the
left when we are in Japan or Britain, but it is also possible that it only allows us to drive
on the right. The fact that the environment will be more constrained makes it very clear
that the design challenge will be easier to complete. In a taxi that operates
autonomously, a human driver has access to a variety of actuators, including control
over the engine through the accelerator, control over steering and braking, and control
45 | P a g e
over the steering and braking of the vehicle itself. In addition to this, in order for it to
communicate with the passengers, it will require output via a display screen or a voice
synthesizer. In addition, it can be necessary to have a mode of communicating with
other vehicles, whether it be polite or in some other way civilized.
The essential sensors that the taxi will be equipped with will consist of one or more
controlled video cameras. This will allow the taxi to have a view of the road. There is
the possibility that these cameras might be augmented with infrared or sonar sensors in
order to ascertain the distances to other cars and objects. It is necessary for the taxi to
be fitted with a speedometer in order to avoid incurring penalties for speeding.
Additionally, the taxi should be fitted with an accelerometer in order to ensure that it
can be managed effectively, particularly when traversing turns.
In order to arrive at a conclusion regarding the mechanical state of the car, it will be
necessary to consult the standard array of sensors that are associated with the engine,
the fuel system, and the electrical system. There is a possibility that it may benefit from
a global positioning system (GPS), similar to how many human drivers use, in order to
prevent themselves from being disoriented. In conclusion, the passenger will require
either a keyboard or a microphone in order to submit a request for a location. This is
because the passenger will be able to communicate.
In Figure 2.5, we have shown a condensed representation of the essential PEAS
components for a range of additional agent types from a number of different sources.
The exercise 2.4 has a number of other examples that can be accessed. Some readers
may be shocked to hear that our list of agent types contains some programmes that
operate in an entirely artificial environment defined by keyboard input and character
output on a screen. This is due to the fact that our list of agent types includes some
programmes that run in such an environment.
The question "Surely, this is not a real environment, is it?" might be asked by someone.
as well as they would be correct. Rather than the difference between "real" and
"artificial" settings, the intricacy of the relationship between the conduct of the agent,
the percept sequence provided by the environment, and the performance measure is
what is significant. This is because the performance meter is the most critical factor.
As a matter of fact, there are certain "real" circumstances that are quite easy to
understand. A robot that is meant to examine components as they go along a conveyor
belt, for example, might make use of a variety of simplifying assumptions in order to
46 | P a g e
accomplish its task. These assumptions include the following: that the illumination is
always exactly perfect, that the only item that will be on the conveyor belt will be pieces
of a sort that it is familiar with, and that there are only two potential actions (accept or
refuse). On the other hand, there is a possibility that some software agents, which are
often referred to as software robots or softbots, may be identified in domains that are
abundant and limitless.
Imagine a website operator that acts as a softbot and is designed to search through the
numerous news sources available on the internet in order to present the items that are
pertinent to its readers. Additionally, this website operator is able to generate revenue
by selling advertising space to its readers. In order for this operator to be effective, they
will need to possess some abilities related to natural language processing. Aside from
that, it will be necessary for it to comprehend the specific interests of each user and
advertiser, and it will be necessary for it to be able to make adjustments to its plans on
the fly. For example, it will be necessary for it to be able to modify its plans in order to
effectively deal with unforeseen circumstances, such as when the connection to a
certain news source is lost or when a new news source becomes accessible online. The
Internet is a setting that is analogous to the actual world in terms of its level of
complexity, and its inhabitants are comprised of a significant number of both artificial
and human actors.
2.3.2 Properties of task environments
When it comes to artificial intelligence, there is a vast range of different employment
settings that might potentially become available. However, we are only able to identify
a relatively small number of factors along which work situations may be classified.
This is a limitation that we face. When it comes to selecting the appropriate agent
design and the applicability of each of the key families of methodologies for agent
implementation, this particular set of factors plays a crucial role in both of these
decision-making processes. And to start,
Table 2.3 At this location, a variety of agents and the PEAS descriptions of those
agents are shown.
Agent Type
Performance
Environment
47 | P a g e
Methodology
Patients that
patients, and
the hospital
The presentation of
inquiries,
examinations,
diagnoses,
recommendations,
and treatments
the patient's
responses are
entered into
the study of
Appropriate
classification
of the picture
Through the
Presentation of the
classification
Part-picking
proportion of
components
located in the
appropriate
Components
on a conveyor
containers
Hand and arm that
are joined together
camera, and
Controller of
the refinery
Operations at
the refinery
Displays, heaters,
pumps, and control
sensors that
temperature,
pressure, and
instructor
interactive
score on test
Presentation
exercises,
recommendations,
adjustments
Source: Artificial Intelligence A Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
We begin by enumerating the dimensions, and then we proceed to investigate a variety
of diverse work environments in order to provide an explanation of the notions. The
definitions that are provided in this section are of a more informal character; following
48 | P a g e
chapters will offer statements and examples that are more particular to each type of
Fully observable, as opposed to being partially observable, is the following: When the
sensors of an agent provide it access to the whole state of the environment at each and
every point in time, we say that the task environment is totally observable. Another
way to describe this is that the environment is completely observable. For a task
environment to be regarded entirely observable, it is required for the sensors to detect
all elements that are relevant to the action that is being selected. This is the only way
that the environment may get this status. The performance metric is the determining
factor in determining whether or not the task environment is relevant. Fully visible
settings are not only advantageous but also convenient because the agent does not need
to maintain any internal state in order to keep track of the world.
This ability allows the agent to keep track of the world. Because of the existence of
noisy and incorrect sensors or because specific aspects of the state are simply omitted
from the sensor data, it is conceivable that an environment is only partially viewable.
This might be the case. For example, a hoover agent that only possesses a local dirt
sensor is unable to tell whether or not there is dirt in other squares, and an automated
taxi is unable to see what other drivers are thinking. Both of these examples lack the
ability to see what other drivers are thinking. In situations when the agent does not have
any sensors at all, the agent is unable to get information about the environment around
them. When faced with circumstances such as these, one could be tempted to conclude
that the agent's condition is hopeless. However, as we shall see in the next section, the
agent's goals may still be attainable, and one might even claim that they are definite.
A comparison of habitats with single agents and those with many agents: It would
appear to be a rather clear distinction between situations with a single agent and those
with several agents. For instance, a single-agent environment may be easily identified
by an agent that is working on a crossword puzzle by itself, but a two-agent
environment can be distinguished by an agent that is engaged in the game of chess.
Nevertheless, there are a few details that need be taken into consideration. Furthermore,
we have not yet touched on the particular entities that must be treated as agents. To
begin, we have examined the several ways in which an entity may be considered an
agent; but we have not yet completed this discussion. Is it essential for an agent A, such
a taxi driver, to consider an object B, which is another vehicle, to be an agent within
the context of the transaction? As an alternative, is it conceivable to consider it to be
49 | P a g e
nothing more than a thing that acts in accordance with the rules of physics, in a manner
that is analogous to how waves at the beach or leaves blowing in the wind are
considered to be treated? Whether or not the action of agent B can be best represented
as the maximization of a performance measure whose value is reliant on the behaviour
of agent A is one of the most crucial differences that can be made. An illustration of
this would be the game of chess, in which the opponent entity B is striving to maximum
its performance measure, which, in accordance with the rules of chess, causes the
performance measure of the agent A to be minimised. In light of this, the game of chess
may be described as a multi-agent competitive environment.
When it comes to the environment of taxi driving, on the other hand, avoiding accidents
is the most efficient approach to maximise the performance measure of all agents. This
helps to make the environment a multiagent environment that is relatively cooperative.
The fact that, for example, a parking spot may only be utilised by a single car is another
factor that contributes to the nature of competition in this industry. Examples of rational
behaviours include communication, which typically develops as a rational activity in
multiagent contexts; randomised behaviour, which avoids the problems of
predictability, is reasonable in some competitive environments. The challenges that
develop in multiagent settings are typically substantially different from those that arise
in single-agent contexts. This is because multiagent environments contain several
Both deterministic and stochastic techniques are being compared here. If the future
state of the environment is completely determined by the current state and the action
that is carried out by the agent, then we say that the environment is deterministic. If
this is not the case, then we say that the environment is stochastic as opposed to
deterministic. An agent does not need to be concerned about uncertainty if they operate
on the premise that the world is totally visible and predictable. As a consequence of
this, a game can be considered deterministic even if one of the agents is unable to
anticipate the behaviours of the other agents. Because, according to our definition, we
do not take into consideration the uncertainty that is entirely created by the behaviours
of other agents in a multiagent system, this is the reason why this is the case.
On the other hand, if the environment is only partially visible, then it could convey the
sense that it is determined by random events. In order to account for the fact that the
majority of situations that occur in the actual world are so intricate that it is difficult to
keep track of all the components that are not visible, it is important to consider them to
50 | P a g e
be stochastic for reasons that are practical. Taking a cab is a clearly stochastic activity
in this sense since it is hard to precisely foresee the behaviour of the traffic. In addition,
one's tires may suddenly blow out, and one's engine might suddenly stop operating
without any previous notice. Both of these things might happen without any prior
warning. The hoover world, in the form that we have described it, is deterministic; but
modifications may contain stochastic characteristics such as dirt that occurs at random
and a suction mechanism that is not trustworthy (Exercise 2.13). If a given environment
cannot be observed in its whole or if it cannot be predicted, then we refer to it as having
an uncertain character.
In conclusion, it is essential to emphasise that the term "stochastic" is typically
employed in a manner that implies that the degree of uncertainty regarding the
outcomes is measured in terms of probabilities. One definition of a nondeterministic
environment is one in which acts are described by the probable outcomes they will
have, but there are no probabilities connected with those actions. In the context of
performance assessments, nondeterministic environment descriptions are frequently
associated with the requirement that the agent must be successful for all of the
conceivable outcomes that occur from its activities. This is because the agent is
responsible for determining the outcomes of the activities.
The differences between sequential and episodic: While working in an environment
that is episodic, the agent's experience is split up into atomic episodes. This occurs
while the agent is operating in the environment. Following the completion of each
episode, the agent is responsible for carrying out a single action, which is then followed
by the acquisition of a percept. First and foremost, the actions that were taken in the
episodes that came before it will not have any bearing on the episode that comes after
it. Many of the challenges that arise while classifying things are of an episodic
character.
Take, for example, a representative who is entrusted with finding defective components
that are being moved down an assembly line. This agent makes each decision based on
the current component, without taking into account the decisions that have been made
in the past while making decisions. Furthermore, the decision that is being taken at this
very time does not necessarily have any bearing on whether or not the subsequent
component is flawed. On the other hand, the decision that is being made right now has
the potential to have an effect on all of the decisions that will be made in the immediate
future in sequential situations.3) Playing chess and driving a taxi are both sequential
51 | P a g e
activity; in both cases, decisions made in the near term may have consequences and
ramifications in the long run. Because the agent does not have to predict its activities,
episodic settings are far less sophisticated than sequential environments. This is
because the agent does not have to plan ahead.
When contrasted with dynamic: If an agent is able to make changes to the environment
while they are deliberating, then we say that the environment is dynamic for that agent;
otherwise, we say that the environment is constant or that it is not dynamic. Static
environments are easy to deal with, but they are challenging to manage. This is due to
the fact that the agent does not have to keep looking at the world while it is making a
decision about what action to take, and it also does not have to be concerned about the
passage of time. Dynamic environments, on the other hand, remain in a state of ongoing
inquiry into the agent's intentions; if the agent has not yet made a decision, this is seen
as a decision to do nothing. When the environment does not change over the course of
time, but the performance score of the agent does change, we refer to the environment
as being semi dynamic.
This is so because the environment itself does not change. It is abundantly clear that
the process of driving a taxi is a dynamic one: the other cars and the taxi itself continue
to move forward as the driving algorithm deliberates about what action to take next. It
is generally agreed that chess is regarded to be semi dynamic when it is played with a
clock. Puzzles that include crosswords are stationary in nature. Between discrete and
continuous: The distinction between discrete and continuous refers to the state of the
environment, the way in which time is controlled, as well as the perceptions and actions
of the agent. There is also a distinction between continuous and discrete. With the
exception of the clock, the environment of chess, for example, is made up of a set
number of distinct states that are not interchangeable with one another.
Chess is comprised of a unique collection of actions and perceptions as well as a series
of activities. Furthermore, taxi driving is a problem that must be addressed in a
continual condition and continuous time. This indicates that the taxi's speed and
location, together with those of the other vehicles, travel through a range of continuous
values in a smooth way over the course of time. This is also true for the other vehicles.
In addition, taxi driving actions, including as steering angles, are maintained unaltered
throughout the entirety of the operation. However, it is often seen as reflecting
continuously shifting intensities and locations. Although the input from digital cameras
is discrete in a formal sense, it is commonly regarded as reflecting these things.
52 | P a g e
Understanding versus not knowing: In a literal sense, this distinction does not apply to
the environment itself; rather, it refers to the amount of awareness that the agent (or
creator) possesses regarding the "laws of physics" that govern the environment. Every
action in a known environment is accompanied by the consequences (or the likelihood
of outcomes, in the event that the environment is stochastic) that are expected to occur.
In order for the agent to be able to make decisions that are in their best interests, it is
evident that they will need to gain information about the environment in order to
comprehend how it functions within the environment. Remember that the distinction
between environments that are entirely visible and environments that are partially
observable is not the same as the distinction between environments that are known and
environments that are unknown.
This is a crucial point to bear in mind. Despite the fact that I am familiar with the rules
of patience card games, for example, I am still unable to see the cards that have not yet
been turned over. This serves as an illustration of how it is entirely plausible for a
known environment to be partially observable. The second possibility is that a setting
that is foreign to you might be totally viewable. When I play a brand-new video game,
for instance, the screen may show the entire game state; yet, I won't truly comprehend
what the buttons accomplish until I actually put them to use.
The situation that is partially visible, multiagent, stochastic, sequential, dynamic,
continuous, and unknown proves to be the most challenging of all possible scenarios.
Undoubtedly, this is exactly what one would plan for. Taxi driving is difficult in all of
these regards, with the exception of the fact that the driver is, for the most part, aware
of the surroundings in which they are operating. The experience of driving a rental car
in a foreign country is far more intriguing than driving in your own country, particularly
when the topography and the regulations of the road are completely new to you.
Table 2.4 lists the features that are common to many well-liked environments.
Think about the fact that there aren't always simple, straightforward answers.
Because the robot that picks up pieces often assesses each part separately, we call
it an "episodic" robot. Still, in the event that a gigantic one does occur, then.
Deterministi
53 | P a g e
chess with a
Deterministi
Deterministi
Stochastic
Stochastic
Stochastic
Stochastic
Deterministi
Stochastic
controller
Interactive
Stochastic
Stochastic
Source: Artificial Intelligence A Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
After making several observations, the robot should be able to determine that the
distribution of defects has changed whenever it meets a batch of defective components.
Based on this new information, it should adjust its behaviour for subsequent portions.
Since this is not a characteristic exclusive to the natural world, the report does not have
a "known/unknown" column. Giving the agent full rule knowledge is a piece of cake
in some contexts, like chess and poker. Still, it's interesting to think about how an agent
might figure out how to play these games without knowing this. Several of the answers
in the table depend on the details provided about the work setting. Medical diagnosis
is a single-agent issue as it is impossible to adequately model a patient's sickness
process as an agent. Nevertheless, a medical-diagnosis system may encounter a
54 | P a g e
multiagent component in the form of dubious staff members and patients who are
resistant to therapy. Furthermore, medical diagnosis is seen as episodic when the task
is designed as selecting a diagnosis from a set of symptoms. A sequential problem, on
the other hand, is one that may include several steps, such as recommending a battery
of tests or monitoring a patient's improvement during treatment. And at scales beyond
the individual actions of the actor, many environments take on an episodic aspect. As
an example, a chess tournament consists of several games, with each game serving as
an episode.
This is because, typically, the impact of a move on the agent's overall performance is
unaffected by the moves in the game before it. On the flip side, when it comes to a
single game, the decision-making process is obviously sequential. This book's
accompanying code repository (aima.cs.berkeley.edu) includes a general-purpose
environment simulator. The goal of this simulator is to evaluate agents based on a
predefined performance metric by placing them in a simulated environment and
tracking their actions over time. The repository also includes many environments'
implementations. It is common practice to conduct these kinds of tests for several
scenarios chosen from a larger class of settings rather than a single one.
To evaluate a taxi driver in simulated traffic, for example, we'd have to do a tone of
tests under different conditions (traffic, lighting, weather, etc.). Were we to tailor the
agent's development to a specific case, we may potentially exploit situational traits;
conversely, we could fail to come up with a good design for general driving. This is
why you'll find an environment generator for every environment class in the source
code repository. This environment generator selects potential execution contexts for
the agent based on predetermined probability. The hoover environment generator,
which assigns agents and dirt patterns at random, is a fantastic example of this in action.
So, what we're interested in is the agent's average performance compared to the
environment class. Any rational agent functioning within a given class of environments
would want to maximise this average performance. The steps outlined in exercises 2.8
to 2.13 will help you build an environment class and analyse the many agents that make
2.4 THESTRUCTURE OF AGENTS
Up until now, we have been talking about agents through the definition of behaviour,
which is the activity that follows a specific perceptual sequence. We need to talk about
55 | P a g e
how the system is structured and face the reality now. Artificial intelligence is tasked
with developing agent programmes capable of performing the agent function, which
entails translating perceptions into actions. Based on our assumptions, this code is
expected to run on a computer device that has actual sensors and actuators attached to
it. Here, we talk about the architecture. Architecture plus programming equals an agent.
That the chosen programming needs to be compatible with the building's design is, of
course, obvious. The architecture has to be able to move around for the programming
to provide activities like Walk. A robotic car outfitted with many CPUs, cameras, and
other sensors may be the architecture, or it might be as simple as a regular desktop
2.4.1 Agent programs
The agent programmes that we construct during the course of this book all share the
same fundamental structure: they take the current percept as input from the sensors,
and then they send an action back to the actuators and continue the process. This is the
situation with a significant number of the agent programmes.4.
It is important to acknowledge the difference between the agent function, which takes
the entire perceptual history as input, and the agent programme, which just takes the
current percept as input. Only the present percept is taken into consideration as input
by the agent software. This is due to the fact that there is nothing further that can be
received from the environment whatsoever. In the event that the acts of the agent are
required to be dependent on the whole sequence of percepts, then the agent will be
required to recollect the percepts.
In Appendix B, we give a description of the exemplary programmes using the basic
pseudocode language that is defined in the document. It is possible to locate the
implementations in the electronic code repository. These implementations are written
in their respective programming languages. The illustration in Figure 2.7 is an
illustration of a rather straightforward agent programming. A record of the percept
sequence is kept by this programme, and it is then used to index the information into a
table of actions in order to identify which actions should be carried out. The following
sentences serve as an illustration of the table, which is supplied for the entire world:
56 | P a g e
Table 2.5— represents the agent function that the agent programme expresses in
a manner that is both obvious and consistent. Creating a rational agent who can
act in order to.
function TABLE-DRIVEN-AGENT (percept) returns an action
persistent: percepts, a sequence, initially empty
table, a table of actions, indexed by percept sequences, initially fully specified
append percept to the end of percepts
action ← LOOKUP (percepts, table)
return action
Source: Artificial Intelligence a Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
According to this point of view, it is essential for us, as designers, to create a table that
contains the appropriate action for each and every possible percept succession.
Examine the factors that contribute to the inevitability of failure for the table-driven
approach to agent construction. Taken into consideration, this is an insightful point of
view. Consider both the probable percepts, which are symbolized by the letter P, and
the lifespan of the agent, which is marked by the letter T and represents the total amount
of percepts that it will acquire during its lifetime. The lookup table will include a total
of T t = 1 |P|t entries in its entirety. Consider the case of the automated cab, for instance:
The amount of visual information that is received from a single camera is around 27
megabytes per second.
This is comparable to thirty frames per second, 640 × 480 pixels, and 24 bits of colour
information. The end result is a lookup table that contains more than
10250,000,000,000 elements that are relevant to a single hour of driving. The lookup
table for chess, which is a fairly modest and well-behaved portion of the actual world,
would have at least 10150 entries. This is because chess is a widely played game. The
daunting size of these tables (the number of atoms in the observable universe is less
than 1080) means that (a) no physical agent in this universe will have the space to store
the table, (b) the designer would not have time to create the table, (c) no agent could
ever learn all the right table entries from its experience, and (d) even if the environment
is simple enough to yield a feasible table size, the designer still has no guidance about
how to fill in the table entries.
57 | P a g e
Table-driven-agent is able to accomplish what we want it to do, which is to say that it
is able to implement the agent function that we want it to implement. When it comes to
artificial intelligence, the most essential challenge is to figure out how to construct
programmes that, to the maximum extent possible, generate sensible behaviour from a
relatively little programme rather than from a vast table. This is the most crucial task.
Additionally, there are numerous examples that illustrate that this is something that can
be achieved successfully in various environments.
As an illustration, the large tables of square roots that were utilised by engineers and
students prior to the 1970s have been replaced by a five-line programme for Newton's
approach that is carried out on electronic calculators. This programme uses electronic
calculators to perform the calculation. There is an issue that has to be answered, and
that is whether or not it is conceivable for artificial intelligence to do what Newton did
with square roots. Our point of view is that the response is in the affirmative. In the
next part, we will offer an overview of four essential types of agent programmes that
are reflective of the core notions that inform almost all intelligent systems. These four
categories of agent programmes are as follows:
There are a few different types of agents that fall under the category of simple reflex
agents. These include model-based reflex agents, goal-based agents, utility-based
agents, and simple reflex agents.
For the purpose of generating actions, every type of agent programming incorporates
particular components in a particular fashion. When it comes to transforming all of
these agents into learning agents, Section 2.4.6 offers a general overview of how to
accomplish this transformation.
function REFLEX-VACUUM-AGENT ([location, status]) returns an action
if status = Dirty then return Suck
else if location = A then return Right
else if location = B then return Lef
Source: Artificial Intelligence A Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
agents that may boost the performance of their components so as to provide superior
actions. In conclusion, Section 2.4.7 presents a description of the different manner in
58 | P a g e
which the components themselves could be represented inside the agent. Furthermore,
this diversity acts as a crucial organising force for both the field as a whole and the
book in particular with regard to the discipline.
2.4.2 Simple reflex agents
In the realm of agents, the simple reflex agent is considered to be one of the most
fundamental sorts. The current percept is the deciding factor in the actions that these
agents choose to take, and they do not consider the rest of the percept history to be
important. As an illustration of a simple reflex agent, take, for instance, the hoover
agent, the agent function of which is depicted in Figure 2.3. This is because its
judgement does not take into account anything other than the current position and
whether or not that region includes dirt. This is the reason why this is the case. A
representation of an agent programme that is utilised for this specific agent can be found
in Figure 2.8.
Taking into consideration the table that corresponds to the hoover agent programme, it
is essential to keep in mind that the programme itself is quite little in contrast to the
table. The decline that is most evident is the one that takes place when the perceptual
history is neglected, which brings the number of possibilities down from four to just
four. One further, somewhat minor reduction is brought about by the fact that the action
does not depend on the location when the square that is now being utilised is dirty. This
is a rather significant reduction.
There is still the possibility of seeing straightforward reflex behaviours, despite the
complexity of the universe. You should make an effort to put yourself in the shoes of
the person who is driving the automated cab. In the event that you see that the vehicle
in front of you is applying the brakes and the brake lights are going on, it is imperative
that you apply the brakes yourself. To put it another way, the visual information is
subjected to some processing in order to produce the condition that we talk about when
we say, "The car in front is braking."
Following that, this leads the agent programme to activate a link that was previously
made to the action "initiate braking." This link was made in the past. This type of link
is referred to as a condition–action rule, and it may be described in the following
manner: if the vehicle in front of you is applying the brakes, then you should also begin
applying the brakes. The human species also possesses a large number of such links,
59 | P a g e
some of which are reactions that are learned (such as driving), while others are reflexes
that are innate (such as blinking when something is close to the eye). We present a
variety of different techniques that may be utilised towards the acquisition and use of
such relationships during the course of the book. These approaches can be employed
in numerous different ways.
Only one specific hoover environment is compatible with the code depicted in Figure
2.8. This environment is the only one acceptable for usage. Following the development
of a general-purpose interpreter for condition–action rules, the subsequent stage is to
create rule sets that are adapted to a variety of different task contexts. In comparison to
the method that came before it, this one is more comprehensive and adaptable. For your
convenience, Figure 2.9 provides a graphical representation of the structure of this
generic programme. The condition–activity rules are shown in this image to highlight
how they make it possible for the agent to create a connection between perception and
action. Please do not be alarmed if it appears that I am
Figure 2.9 A basic reflex agent is shown in this schematic figure.
Source: Artificial Intelligence a Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
Table 2.6 A instantaneous response agent. The perceptual state determines the
governing rule, and it operates in accordance with that rule.
function SIMPLE-REFLEX-AGENT (percept) returns an action
persistent: rules, a set of condition–action rules
60 | P a g e
state ← INTERPRET-INPUT (percept)
rule ← RULE-MATCH (state, rules)
action ← rule. ACTION
return action
Source: Artificial Intelligence A Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
superfluous; it will turn into something much more intriguing very soon.) We employ
rectangles to demonstrate the internal state of the agent's decision-making process at
any given time, and ovals to represent the background information that is used in that
process. Another very simple example is the agent programme, which is illustrated in
Figure 2.10. The current state is abstracted from the percept by the INTERPRET-
INPUT function, and the first rule in the collection that meets the given state description
is returned by the RULE-MATCH function. You can describe the present condition
using any of these functions. The "rules" and "matching" description is purely notional,
so please keep that in mind. A basic set of logic gates can build a Boolean circuit on
their own, and that might be the extent of the actual implementations.
Although basic reflex agents possess the admirable trait of being simple, their
intelligence is really very low. For the agent in Figure 2.10 to work as intended, the
environment must be fully observable, meaning that the correct decision can only be
made based on the current percept. Even a little quantity of unobservability might cause
major issues. The previously demonstrated braking rule is an example of this; it uses
the current percept, which is a single frame of video, to infer that the car ahead of you
is applying the brakes. In situations where the brake light of the car ahead of you is
centrally located, this will be effective. On the other hand, it could be difficult to tell if
a car is braking from a single shot because different models had different configurations
of taillights, brake lights, and turn-signal lights. A simple reaction agent would either
brake excessively and unnecessarily or, worse, just not stop at all if they were behind
such a vehicle.
We could encounter a problem similar to this one in the vacuum domain. Consider a
simple reflex hoover agent that lacks all sensors save the dirt sensor and is lacking its
location sensor. Such an agent could only experience two possible states of mind:
[Dirty] and [Clean]. It can Suck when told "Dirty," but how will it react when told
"Clean"? Assuming you start in square A, going left will never work, and if you start
61 | P a g e
in square B, travelling right will never work either. Neither of these results will ever
disappear. Simple reflex agents operating in partially observable environments
frequently inevitably exhibits infinite loops.
It is possible to escape from infinite cycles if the agent can randomize its activities. If
the hoover agent sees the word "Clean," for example, it may toss a coin to determine
which choice is more appropriate, Left or Right. Assuming the agent takes an average
of two steps to reach the opposing square, it is easy to prove. The agent will clean the
square in question and complete the prescribed job if it is filthy. This explains why a
deterministic simple reflex agent could not be as effective as a randomised classic
reflex agent.
The suitable kind of random behaviour may be plausible in some multiagent
circumstances, as mentioned in the preceding section (2.3). When there is just one
player involved, randomization doesn't make any sense. While this approach might
work for a basic reflex agent on occasion, it usually yields far better results when
dealing with more complicated deterministic agents.
2.4.3 Model-based reflex agents
One of the most effective strategies for coping with partial observability is for the agent
to keep track of the section of the world that it is unable to witness at the present. This
practice is one of the most efficient techniques. This means that the agent should
maintain some type of internal state that is reliant on the perceptual history and, as a
result, conveys at least some of the qualities of the current state that have not been
observed. To put it another way, the agent should preserve some kind of internal state.
The internal status of the brakes is not particularly detailed; the only frame that is shown
is the one that came before it from the camera.
This pertains to the problem with the system. The agent is able to recognise situations
in which two red lights at the edge of the automobile switch on or off at the same
frequency as a result of this. In the event that it is unable to monitor all of the other cars
at the same time, the agent is required to keep track of the locations of the other vehicles
in order to perform additional driving tasks, such as changing lanes. In addition, in
order for the agent to be allowed to drive at all, it is essential for them to have a record
of the location of their keys inside their possession. There are two distinct categories
of information that must be encoded in the agent software in order to ensure that the
62 | P a g e
information on the internal state is maintained up to current as time goes on. In order
to get started, we need to have some understanding of the process by which the universe
grows beyond the influence of the agent. An automobile that is overtaking another
vehicle, for instance, will frequently be at a position that is closer to the rear of the
vehicle than it was only one minute before.
Obtaining some knowledge on the manner in which the agent's activities impact the
world is the second item that we require. In the event that the agent twists the steering
wheel in a clockwise direction, for example, the vehicle will turn to the right. In a
similar vein, if one is travelling in the northern direction on the highway for five
minutes, they will normally be around five miles north of where they were five minutes
before. A representation of this knowledge on "how the world works" is referred to as
a model of the world. This information can be written in the form of straightforward
Boolean circuits or in the form of sophisticated scientific theories. When referring to
an agent that makes use of a model of this kind, the phrase "model-based agent" is the
one that is utilised.
An illustration of the structure of the model-based reflex agent with internal state is
presented in Figure 2.11. This illustration illustrates how the current percept is
combined with the internal state that was present in the past in order to produce an
updated description of the current state. It is the agent's model of how the world
functions that serves as the foundation for this description. The agent programme that
is currently being utilised is depicted in Figure 2.12. The most exciting part of the
system is represented by a function that is referred to as update-state.
Figure 2.11 Reflex agent that is based on a model.
63 | P a g e
Source: Artificial Intelligence A Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
Table 2.7 Agent with a model-based reflex. Agent with a model-based reflex. Using
an internal model, it keeps track of the world as it is right now. After then, it
follows the reflex agent's lead when choosing an action.
function MODEL-BASED-REFLEX-AGENT (percept) returns an action
persistent: state, the agent’s current conception of the world state
model, a description of how the next state depends on current state and action
rules, a set of condition–action rules action, the most recent
action, initially none
state ← UPDATE-STATE (state, action, percept, model)
rule ← RULE-MATCH (state, rules)
action ← rule. ACTION
return action
Source: Artificial Intelligence A Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
creation of the updated description of the interior condition falls on their shoulders. The
specifics of the model and state representation may differ substantially based on the
environment under consideration and the technology employed to create the agent.
Extensive examples of models and update approaches are provided.
It is extremely challenging for the agent to provide an accurate assessment of the
current condition of a partially visible environment, regardless of the representation
chosen. Figuring out "what the world is like now" (Figure 2.11) is where the agent's
"best guess" (or best guesses) are displayed. As an example, an autonomous cab could
only have a limited field of view due to its inability to see beyond the enormous truck
that has come to a complete stop in front of it. Hence, it's conceivable that there's no
way to eliminate ambiguity regarding the current circumstance; nonetheless, the agent
must still make a decision.
Regarding the "state" that a model-based agent keeps within, it's worth noting that it
doesn't have to give a precise account of "what the world is like now." Maybe this isn't
as obvious as it seems. With respect to
64 | P a g e
Figure 2.13 An agent that depends on models and has goals. It takes stock of
where things are right now, makes a list of goals to reach, and then decides on a
strategy that will (hopefully) lead to those goals being reached in the end.
Source: Artificial Intelligence A Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
A cab going home would be subject to this rule if it is required to fill up with petrol
before it reaches its destination, even if it is 50% full. Although "driving back home"
may appear to be part of the global state, the agent's internal state really includes the
information that the cab had arrived at its destination. If this still doesn't make sense to
you, think about the fact that the cab may be at the same place right now, but it could
be heading in the opposite direction.
2.4.4 Goal-based agents
In order to make informed judgements, knowing the current state of the environment is
not always enough. When a taxi reaches a junction, for instance, it might choose to turn
left, turn right, or keep going straight ahead. The correct option depends on where the
taxi is trying to go. Another way of putting it is that the agent needs goal information
that specifies ideal situations, such being at the passenger's destination, in addition to
providing a description of the current state. Similar to how the model-based reflex agent
uses this data, the agent programme may include it into the model to determine actions
that effectively achieve the goal. Figure 2.13 depicts the building of the agent with
When a single set of activities may swiftly accomplish a goal, for example, it's easy to
see how objectives should inform action selection. Sometimes it will be harder than
65 | P a g e
other times; for example, when the agent has to come up with complex chains of logic
to complete the mission. The search and planning branches of AI are concerned with
finding the best possible sequences of actions that will allow the agent to achieve its
This form of decision-making differs significantly from the condition-action concepts
that were previously covered. Considering the future is an integral part of this process,
which is why you'll hear queries like "What will happen if I do such-and-such?" and
"Will that make me happy?" This data is not intentionally incorporated into the designs
of the reflex agents as the built-in rules translate directly from perceptions to actions.
The reflex agent will trigger the braking system the moment it senses the presence of
brake lights. A goal-based AI may theoretically deduce that the car ahead of them will
likely slow down if its brake lights are on. Braking is the only way to achieve the goal
of avoiding other cars' collisions due to the way the world usually turns out.
The goal-based agent may appear less efficient at first glance, but it really has greater
adaptability than the alternative since the data that drives its behaviours is transparent
and can be changed. In the case that it starts to rain, the agent can refresh its memory
on how well its brakes work. This will instantly trigger the modification of all the
suitable behaviours to conform to the altered conditions. However, we would have to
rewrite most of the condition-action rules if we were to use the reflex agent. Changing
the aim of a goal-based agent's behaviour to go somewhere else is as easy as defining
the new objective. This allows for the adjustment to take place. If the reflex agent wants
to go to a new place, it will have to rewrite all of its rules for determining when to turn
and when to go straight, as these rules are only applicable to one destination.
66 | P a g e
RESEARCHED BASED SOLVING PROBLEM
This is an example of how an agent may identify a series of activities that will allow it
to fulfil its objectives when there is no one action that will do just well.
The most straightforward agents that were explored in their behaviour is defined by a
straightforward mapping from states to actions; these agents are known as reflex agents.
It would be impossible for such agents to function well in contexts where the mapping
would be too extensive to retain and would need an excessive amount of time to learn.
In contrast, agents with goals think about what they want to do in the future and whether
or not that action will have desirable outcomes. brought about by those activities.
This chapter provides an explanation of a specific a problem-solving agent is a specific
kind of goal-based agent. Agents that solve problems make use of atomic
representations, as described in Section 2.4.7. This implies that the world's states are
seen as wholes, without any underlying structure, and that the algorithms used to solve
problems cannot perceive this. Using more intricate factored or structured
representations, planning agents are often known as goal-based agents. inside their
framework.
During the first part of our talk on issue solving, we will provide clear definitions of
problems and the solutions to those problems, as well as various instances to
demonstrate these definitions. In the next section, we will discuss a number of broadbased search methods that may be used to identify remedies for various problems. A
plethora of ignorant search algorithms, which are algorithms fed just their keyword(s)
and not any additional information about the problem specification, will be shown to
us. Although some of these algorithms are capable of solving each issue that may be
solved, none of them are able to do it in an efficient manner. On the other hand, guided
search algorithms have the potential to perform fairly well if they are provided with
some direction on where to hunt for answers.
We focus on the simplest possible task setting in this chapter, which is one in which
the answer to a problem is always a predetermined sequence of operations.
Consideration is given to the more general scenario, in which the agent's future
behaviours could be different based on future perceptions.
67 | P a g e
The ideas of asymptotic complexity (also known as O notation) and NP-completeness
are used in this chapter. It is recommended that readers who are not acquainted with
these ideas review Appendix A.
3.1 PROBLEMS- SAVING AGENTS
Intelligent agents are designed to achieve the highest possible performance measure;
accomplishing this objective may be made easier in certain circumstances if the agent
is able to establish a goal and work towards attaining it. First, let's take a look at the
reasons and the methods that an agent may use to achieve this.
Imagine a travel agent who is on vacation in Arad, Romania, and enjoying the sights
and sounds of the city. The performance measure of the agent takes into account a
variety of aspects, including the following: the agent wishes to develop its tan, hone his
Romanian, see the sights, and partake in the nightlife (in whatever shape it may be),
prevent hangovers, and so on. The choice dilemma is a difficult one that requires
thorough study of guidebooks and consideration of a great number of tradeoffs. Now,
let's say that the agent has a ticket that is non-refundable and is scheduled to depart
from Bucharest the following day.
Taking this into consideration, it would be reasonable for the agent to set the objective
of arriving in Bucharest. The decision-making process for the agent is substantially
simplified, and it is possible to dismiss courses of action that do not arrive in Bucharest
on time without going through any additional deliberation. As a result of restricting the
objectives that the agent is attempting to attain and, therefore, the activities that it has
to take into consideration, goals are helpful in organising behaviour. The first phase in
the process of issue solving is the development of goals, which is based on the existing
circumstances and the performance measure of the participant.
For the sake of this discussion, we shall Picture a set of world states as a goal; these are
the states that will exist after the aim is met. Every action, both immediate and longterm, must be deliberated by the agent if he or she is to achieve a goal. We need to
decide (or it needs to decide) what sorts of actions and states it should consider before
it can go on with this. Even if it were to consider commands as simple as "shift left foot
forward an inch" or "turn the wheel one degree left," the agent would likely get lost in
the parking lot and never reach Bucharest. Reason being, there is involved at that
granularity level. an excessive amount of uncertainty in the world, and there would be
68 | P a g e
an excessive number of steps involved in finding a solution. Given an objective, the
process of selecting which actions and states to take into consideration is referred to as
problem formulation. We will go into further depth about this procedure later on.
Assuming for the time being that the agent will take into consideration activities now
we will go on to the level of travelling from one big town to another. It follows that
being in a certain place correlate to being in each state.
Our representative has decided to make Bucharest their destination, and they are now
contemplating the best way to get there from Arad. Out of Arad, there are three
highways that travel to different destinations: one leads to Sibiu, one leads to
Timisoara, and one leads to Zerind. As a result of the fact that none of them leads to
the desired outcome, the agent will be unable to determine which path to take unless it
is well-versed on the topography of Romania.1. To put it another way, the agent will
not be able to determine which of its potential acts is the most advantageous since it
does not yet have sufficient knowledge on the state that ends up being the outcome of
each action. In the event that the agent does not possess any more knowledge, or if the
environment is unknown in the sense that is stated in Section 2.3, then it is compelled
to attempt one of the actions regardless of the circumstances.
But suppose the spy had a Romanian map. A map's primary function is to inform the
agent of the possible states it may enter and the actions it could do in each. The agent
may use this information to plan out a hypothetical journey that stops in each of the
three towns on the way to Buchanan. Once it finds a path on the map that goes from
Arad to Bucharest, it may complete its mission by engaging in the driving activities
that match the different phases of the journey. When faced with many uncertain-value
immediate choices, an agent may typically pick one by considering the future actions
that would bring about states of known value. Section 2.3 specifies the characteristics
of the environment that must be met before we can be clearer about what we mean
when we state that we are "examining future actions."
Here, we'll pretend that the environment is visible, so the agent knows exactly what's
going on at all times. The agent travelling in Romania is reasonable to presume that
each city on the map has a sign indicating its presence to cars entering into Romania.
Another premise we hold is that there is a finite set of activities possible in a discrete
environment. available to pick from in any given state. Due to the fact that each city in
Romania is linked to a limited number of other cities, this is the case when it comes to
exploring the country. Because we are going to assume that the environment is already
69 | P a g e
understood, the agent will be aware of the states that are reached by each action. In the
case of navigational issues, it is sufficient to possess an accurate map in order to fulfil
this criterion. Last but not least, we make the assumption that the environment is
deterministic, which means that every action has only one result. It is correct that this
is the case for the agent in Romania under perfect circumstances; this indicates that if
it decides to travel from Arad to Sibiu, it will arrive in Sibiu. Without a doubt, the
circumstances are not always perfect.
According to these presumptions, the answer to every issue is represented by a
predetermined sequence of acts. "Of course!" someone could exclaim, " Other than
that, what might it be? In a broader sense, it might be a branching strategy that, given
a set of perceptions, proposes future courses of action. For example, given less-thanideal conditions, the agent may want to go from Arad to Sibiu and then on to Remnick
Vilela. If they end up in Zerind instead of Sibiu, however, they may have to come up
with a contingency plan. The good news is that the agent knows exactly where it will
be and what it will see after the first action if it knows the starting state and the
environment is known and predictable. There can be only one potential second action
defined by the solution as there is only one possible percept that may follow the first
action, etc.
In this context, "search" means actively looking for a set of steps that, when taken
together, will bring about the desired result. A search algorithm accepts a problem
statement as input and outputs a set of instructions for fixing the problem. Once the
answer has been found, the actions it recommends may be implemented. This phase is
referred to as execution. Hence, the agent's design is simple and may be described as
"formulate, search, execute," as seen in Figure 3.1. Following the formulation of an
objective and a problem, the agent will use a search strategy to find a solution. Using
the response as a guide, it proceeds to execute the first action in the sequence (which is
usually the first step in the process) and then removes that step from the sequence. Once
the solution has been successfully implemented, the agent will go on to creating a new
objective.
Because the agent knows in advance what its perceptions will be, it chooses an action
throughout the solution sequence execution process that ignores those perceptions. If
an agent wants to be able to execute their plans blind, they need to have complete faith
in what's happening. Because it disrupts the feedback loop between the agent and its
surroundings when percepts are disregarded, control theorists call this kind of system
70 | P a g e
an open-loop system. We start by outlining the steps involved in problem formulation,
and then devote the majority of the chapter to delving into the various algorithms used
by the SEARCH system. We won't explain how the UPDATE-STATE and
FORMULATE-GOAL functions work in any more depth here.
3.1.1 Specific issues with clear resolutions
There are five components that may be used to officially characterise a problem:
• The initial condition that the agent begins in when it is released. A good
illustration of this would be the initial state of our agent in Romania, which
might be characterised as in (Arad).
Table 3.1 A straightforward agent for problem-solving. The process begins with
the formulation of a problem and a goal, followed by the search for a sequence of
activities that would have the effect of solving the issue, and finally the execution
of each action in turn. Once this is finished, it will create a new objective and begin
the process all over again.
function the result of calling SIMPLE-PROBLEM-SOLVING-AGENT on a percept
is an action sequence (seq), a problem formulation state (state), an empty state (state),
a goal (goal), and a description of the current world state (state). The statement
"UPDATE-STATE (state, percept)" is executed.
If the sequence is empty, then the following steps are executed:
goal ← FORMULATE-GOAL (state)
problem ← FORMULATE-PROBLEM (state, goal)
seq ← SEARCH (problem) if the sequence is not empty, then the result is an empty
action. action ← FIRST (seq)
seq ← REST (seq)
return action
Source: Artificial Intelligence: A Contemporary Approach to Data Gathering and
Processing by Stuart J. Russell and Peter Norvig in 2010.
We outline all the available activities for the agent to partake in. The ACTIONS(s)
function takes a state as input and returns a set of all possible actions that may be
executed in that state. We argue that each of these activities would be relevant in the
71 | P a g e
situation of s. As an example, consider the following actions that may be taken from
the state in (Arad): Go (Sibiu), Go (Timisoara), and Go (Zerind).
A function named consequence (s, a) returns the state that is formed as a consequence
of executing action an in states. This function describes what each action does; the
technical word for this is the transition model. Furthermore, every state that can be
reached from a certain state by a single action or set of actions is called a "successor"
state.2. As an example, note that the result of executing in (Arad), Go (Zerind)) equals
In (Zerind).
When the starting state, actions, and transition model are considered together, they
define the issue's state space implicitly. From the starting point, any sequence of actions
may lead to any of the states that make up this state space. The state space forms a
directed graph or network. The states serve as nodes in this network or graph, and the
actions link the nodes. (Seeing as how each road in Figure 3.2 represents two distinct
driving actions, one in each direction, we may interpret it as a state-space graph
depicting Romania.) A route in state space is a collection of states connected by a chain
of operations.
To determine whether a given state qualifies as a target state, one might use the goal
test. It is common practice to have a list of possible target states beforehand, and the
test's only purpose is to identify if the state under consideration is one of those states.
Reaching the empty set {In(Bucharest)} is one of the goals of the Romanian agent.
Figure 3.1 A simplified mapping of a portion of Romania's roadways
72 | P a g e
Source: Artificial Intelligence: A Contemporary Approach to Data Gathering and
Processing by Stuart J. Russell and Peter Norvig in 2010.
However, there are situations when the objective is stated by an abstract attribute rather
than by a collection of states that are explicitly named. For instance, the objective in
the game of chess is to achieve a situation known as "checkmate," which occurs when
the king of the opponent is the target of an assault and cannot escape.
This is a route cost function that gives each path a numeric cost that is assigned to it.
By selecting a cost function that is reflective of its own performance measure, the
problem-solving agent makes its selection. Due to the fact that time is of the importance
for the agent who is attempting to reach Bucharest, the cost of a way might be the length
of the path, measured in kilometers. Assuming that the cost of a route can be
represented as the total of the prices of the various acts that occur along the path, we
will proceed towards the conclusion of this chapter. In order to get to states, the step
cost of performing action an in states is represented by the symbol c(s, a, s). On display
in Figure 3.2 are the step costs for Romania, which are represented as route distances.
The assumption that we make is that step costs are positive.
A issue is defined by the components that have come before it, and these elements may
be compiled creating a unified data format that may be fed into a problem-solving
algorithm. When we speak about a solution to an issue, what we really mean is the set
of steps that leads from the initial condition to the final, desired one. In order to
determine which option is best, we utilise the route cost function. The solution with the
lowest path cost is considered optimal.
3.1.2 Creating issues
A formulation of the issue of travelling to Bucharest was presented in the part that came
before this one. This formulation was based on the beginning situation, steps, change
model, objective evaluation, and travel expense. Despite appearances, this formulation
is still only a model—an abstract mathematical description—and not the actual thing.
Compare the straightforward description of the state that we have selected, in (Arad),
to the actual experience of travelling across the country, where the state of the world
encompasses a wide range of factors, such as the people with whom you are travelling,
the radio programme that is currently playing, the scenery that can be seen through
scenario, procedures, change paradigm, objective assessment, and trip cost. In spite of
73 | P a g e
what you would think, this formulation is nothing more than a model, a mathematically
abstract description, and not. Due to the fact that they are not pertinent to the issue of
locating a route to Bucharest, all of these factors are not included in our descriptions of
the states. Abstraction refers to the process of eliminating details from a representation
from a representation. It is necessary to abstract not just the state description but also
the actions themselves. A driving action may produce several outcomes. As the old
adage goes, "travel is spreading," but it also alters the agent, requires fuel, produces
pollution, and takes time. The car and its occupants are also shifted in their positions
as a result. The change in location is the only factor that our model accounts for.
Additionally, there are other activities that we refrain from doing, such as listening to
the radio, looking out the window, and reducing our speed to accommodate law
enforcement officers, among many others. Note that we do not provide steps as simple
as "turn the steering wheel to the left by one degree." in addition.
Could we become more precise if we determined the appropriate level of abstraction?
The chosen abstract states and actions are like a huge database of specific world states
and action sequences, in a way. Now come up with a solution to the problem that is
more theoretical in character. Think about the path that starts in Arad and ends in
Bucharest; it passes via Sibiu, Remnick Vilela, Pitesti, and back again. This generalised
answer is associated with a plethora of specific paths. We could, for instance, listen to
the radio between Sibiu and Remnick Vilela, and then silence it for the rest of the way.
It is essential that for every detailed state "in Arad," there exists a detailed path to some
detailed state "in Sibiu," and so on.
One may argue that an abstraction is valid if it can be extended into a solution in the
more complex reality.5. An abstraction is useful if solving the issue using its constituent
parts is easier than the original problem itself. Here, the steps are simple enough that a
typical driving agent with enough understanding may do them without having to do
any further research or preparation. Eliminating as much detail as feasible while
maintaining the validity of the abstract actions and ensuring their simplicity is essential
for selecting an acceptable abstraction. Natural phenomena would utterly overwhelm
sentient beings if they had the capacity to generate useful abstractions.
3.2 EXAMPLES PROBLEMS
A wide variety of different job contexts have been used to put the problem-solving
technique into practice. To differentiate between toy difficulties and real-world issues,
74 | P a g e
we provide a list of some of the more well-known ones below. The purpose of a toy
problem is to demonstrate or practise a variety of approaches to problem-solving for
children. As a result of the fact that it is possible to provide a clear and precise
explanation, it may be used by a variety of researchers in order to evaluate the
effectiveness of algorithms. In the real world, an issue is considered to be one whose
solutions are of genuine concern to people. Generally speaking, such issues do not have
a single definition that is universally accepted; yet, we are able to provide an overall
flavor of their formulations.
Figure 3.2 The state spaces of the planet vacuum are these. "Suck" means "suck
out," "right" means "right," and "left" means "left.".
Source: Artificial Intelligence: A Contemporary Approach to Data Gathering and
Processing by Stuart J. Russell and Peter Norvig in 2010.
3.2.1 Toy problems
The vacuum world, which was first conceptualised in (See Figure 2.2), is the first case
that we will investigate. One possible formulation of this issue as a problem is as
• States: The determining factors for the state are the agent location as well as
the dirt locations. A dirt-filled environment may or may not be present in either
of the two sites where the agent is now located. As a result, there are a total of
75 | P a g e
eight potential world states, which is equal to two times twenty-two. n · 2n
states are present in a wider environment that consists of n places.
• Initial state: The initial state might be any state that is chosen to be labelled as
• The actions: In this straightforward setting, there are just Right, Left, and Suck
are the three actions that may be performed for each state. Additionally, Up and
Down may be present in situations that are larger.
• Transition model: The activities have the results that were anticipated, with
the exception of travelling to the left side of the square, travelling to the right
side of the square, and sucking in a clean square.
See Figure 3.3 for a representation of the whole state space.
To find out whether every square is clean, this is the end goal test.
There is a one-to-one relationship between the number of steps and the overall cost of
the journey since each step has an associated cost.
This toy issue, in contrast to the actual world, has defined places, discrete filth,
consistent cleaning, and it never becomes much dirtier than it already is.
An example of the 8-puzzle may be seen in Figure 3.4. This puzzle is comprised of a
board that is 3×3 in size and has eight tiles that are numbered, as well as a blank spot.
It is possible for a tile that is next to the empty area to slide into the space. To achieve
a certain target state, such as the one shown on the right side of the picture, is the
objective of this endeavour. A typical formulation might look something like this:
Figure 3.3 An example of the 8-puzzle in its normal form
76 | P a g e
Source: Artificial Intelligence: A Contemporary Approach to Data Gathering and
Processing by Stuart J. Russell and Peter Norvig in 2010.
States: The eight tiles and one empty square may be located using a state description.
This information is provided in the state description.
• Initial state: The initial state might be any state that is chosen to be labelled as
such. It is important to keep in mind that every particular objective may be
accomplished by starting from precisely half of the potential places (Exercise
• Actions: The most straightforward definition of actions describes them as
motions of the blank space to the left, right, in the upward direction, or
downward. There are a variety of subsets of these that may be created based on
the location of the blank.
• If we take the initial state in Figure 3.4 and perform the Left operation, the
resultant state will have the blank and the 5 rearranged. This is an example of a
transition model, which produces the next state when given an action and a
As illustrated in Figure 3.4, the goal test checks to see whether the present state matches
the target configuration. (Alternative goal combinations are not out of the question.)
There is a one-to-one relationship between the number of steps and the overall cost of
the journey since each step has an associated cost.
Please tell me how we have used abstractions in this. As a result of activities being
reduced to their beginning and ending phases, the sliding locations of the block are
ignored. If pieces get stuck on the board, we can't do things like shake the board or use
a knife to remove and reposition them; none of those options are left. When it comes
to the problem, all that is left for us to do is read a description of its regulations, ignoring
any specifics about the actual movements.
There is a family of sliding-block puzzles that includes the 8-puzzle. These puzzles are
often used as test problems for new search methods used in artificial intelligence.
Because it is well known that this family is NP-complete, it is not reasonable to
anticipate discovering techniques that are much superior than the search algorithms that
are presented in this chapter and the next one under the worst-case scenario. It is not
77 | P a g e
difficult to solve the 8-puzzle, which has 9! /2 = 181, 440 states that may be reached.
There are about 1.3 trillion states in the 15-puzzle, which is shown on a 4×4 board. The
ideal solution for random occurrences may be achieved in a matter of milliseconds by
the most advanced search engines. There are about 1025 states in the 24-puzzle, which
is shown on a board that is 5 by 5. Solving random occurrences of the problem takes
many hours. Arranging eight queens on a chessboard in a manner that no queen can
attack is the goal of the 8-queens problem. (A queen may easily attack any piece in the
same row, column, or diagonal.) A failed attempt at a solution is shown in Figure 3.5,
which shows the queen in the upper left column attacking the queen in the rightmost
Figure 3.4 It's almost like a solution to the dilemma of eight queens. As an
exercise, the solution is left unresolved.
Source: Artificial Intelligence: A Contemporary Approach to Data Gathering and
Processing by Peter Norvig and Stuart J. Russell 2010.
There are efficient special-purpose algorithms for this problem and the full n-queens
family, however this problem is still useful for testing search techniques. There are two
main types of formulations. In terms of the 8-queens problem, this means that the state
gains one queen for every action. The state description is enhanced in an incremental
formulation by operators, which starts with an empty state. Starting with all eight
queens on the board and then moving them is a full formulation. about. Regardless of
the circumstances, the cost of the journey is irrelevant since the only state that matters
are the ultimate one. The following is an example of the first incremental formulation
that one may investigate:
78 | P a g e
The term "state" refers to any configuration on the board that has between 0 and 8
• At the beginning, there are board has no queens.
• As an action, you may put a queen on an empty square.
• After the transition model finishes, the board is returned to you squared with a
queen. that was specified before to the transition.
• There are eight queens on the board, and none of them have been attacked.
• •According to this approach, we have about 1.8 × 1014 potential sequences to
analyse, which is 64 · 63 ··· 57. A more effective version can't place a queen in
a square that is currently on the receiving end of an attack:
All potential configurations of n queens, with n ranging from 0 to 8, are considered
states. Each queen is placed No queen may attack another queen in the n columns on
It is possible to do things like add a queen on any empty square in the far left most
column in a manner that prevents other queens from attacking that tile.
This formulation reduces the state space of eight queens from 1.8 × 1014 to only 2,057,
thus finding solutions to this issue is not difficult. On the other side, the reduction for
100 queens is a considerable improvement, going from around 10400 states to about
1052 states (Exercise 3.5), but it is still insufficient to make the issue manageable. The
complete-state formulation is discussed in Section 4.1, and provides a straightforward
method that can easily solve even the million-queens issue.
Our last toy problem was conceived of by Donald Knuth in 1964, and it serves as an
example of how limitless state spaces might come into existence. Knuth hypothesised
that if one begins with the number 4, a series of operations using the factorial, the square
root, and the floor would eventually arrive at any positive integer that one desires. For
instance, we can get to five from four by doing the following:
79 | P a g e
The definition of the issue is quite straightforward:
• Identifies numbers that are positive.
The starting point is a 4.
Operations: Perform the operation that takes the square root of an integer, the floor, or
the factorial of an integer.
The described model is the transition model, according to the mathematical
specifications of the operations.
In order to pass the objective exam, the state must be a positive integer.
As far as we are aware, there is no limit to the size of a number that may be built
throughout the process of obtaining a certain objective. For instance, the equation for
5 generates the number 620,448,401,733,239,439,360,000. As a result, the state space
for this issue is limitless. These kinds of state spaces are commonly encountered in
activities that involve the development of recursively described items, including
mathematical statements, circuits, proofs, and software.
3.2.2 Issues with a real impact
Previous work has taught us how to define the route-finding problem in terms of known
locations and the transitions between them along their links. Numerous applications
make use of the methods used to find routes. Websites and in-car systems that provide
driving directions are two examples that are very simplified versions of the Romanian
model. Trip planning systems, military operations planning, and computer network
video stream routing are a few more examples of possible uses. used by airlines, include
specifications that are far more complicated. Consider the following issues that must
be resolved by a travel-planning website in order to accommodate aircraft travel:
States: It goes without saying that with each state comes a place (like an airport, for
example) and the current time. Additionally, since the cost of an activity (The state
must keep track of extra details on these "historical" flights since they can rely on
previous segments, their price bases, and whether they are local or international.
80 | P a g e
At the outset, the user's query establishes this point.
It is advised that you board any flight leaving from this airport, regardless of seat class,
after the current time, and allow enough time for any airport transfers that may be
required. Transition model: In the state that is created when a flight is taken, the present
location is the target destination of the flight, and the anticipated arrival time is the
current time. Is this the final destination the user has indicated? If so, then we have
passed the aim test. The journey's expense depends on a multitude of variables, such as
the total amount paid, the duration of the trip, the time spent waiting, the procedures at
customs and immigration, the seat quality, the time of day, the type of aircraft, frequent
flyer miles awards, and so on.
Commercial travel advising systems use this kind of problem formulation—which
introduces a plethora of additional challenges—to address the complicated price
structures imposed by airlines. However, every seasoned traveler knows that plane trips
don't always go as to plan. If the cost of the original plan justifies it, a really outstanding
system should include backup plans, such booking on alternate aircraft, in case of
contingencies. and the risk that it will fail.
The issues of touring are closely connected to the problems of route-finding, although
there is a significant distinction between the two. Take for instance the challenge that
requires you to go to each of the cities shown in Figure 3.2 at least once, beginning and
finishing in Bucharest. Similar to the process of route discovery, the activities
correspond to journeys between cities that are not far apart. Nevertheless, the state
space is fairly distinct from the other. It is necessary for each state to provide not only
the present location of the agent in addition to the list of cities they have been to. So, it
would start with in (Bucharest), Visited (Bucharest), go on to In (Vasuki), Visited
(Bucharest, Urziceni, Vasuki), and finally, the target test would verify that the agent is
still in Bucharest and that all twenty cities have been visited.
As a touring issue, the travelling salesman problem (TSP) states that each city must be
visited exactly once. The objective is to find the shortest route. A lot of effort has gone
into improving the performance of TSP algorithms, even though it is recognised that
the problem is NP-hard. Among the many applications of these algorithms are the
organisation of shop floor inventory and automated circuit-board drills, as well as the
scheduling of routes for mobile salesmen.
81 | P a g e
Maximising manufacturing yield, minimising stray capacitances, minimising circuit
delays, and minimising space needed for the designing of a very large-scale integrated
circuit (VLSI) requires packing millions of components and connections into a chip.
There are often two components to the layout problem: cell layout and channel routing.
It usually shows up after the rational design stage is over. The basic building blocks of
a circuit are organised into smaller units called "cells" in a cell architecture, and each
cell is assigned a specific function. The size and shape of each cell are defined in
advance, and there must be a certain minimum number of connections between all cells.
Ensuring that the cells do not overlap and that there is enough room for the connecting
wires to be positioned between them is crucial when arranging them on the chip. The
channel routing method finds a specific route for each wire via the intercellular gaps.
Problems with these searches include exceedingly difficult to solve, but they are
unquestionably worth the effort. In a later section of this chapter, we will discuss
several algorithms that are able to solve these problems. Additionally, the issue of
route-finding that was discussed before may be generalised to include robot navigation.
It is feasible for a robot to navigate across an uninterrupted realm where, in principle,
there is an infinite variety of possible deeds and states, rather than adhering to a linear
series of routes. Space is essentially two-dimensional as it pertains to a spherical robot
moving on a flat surface. With the addition of controllable limbs or wheels, the search
space grows exponentially in terms of the number of dimensions. All that is necessary
to make the search space limited is the use of sophisticated procedures. In Chapter 25,
we get a look at a few of these different approaches. In addition to the difficulty of the
task, actual robots have to contend with inaccuracies in the readings that their sensors
provide and in the controls that they use for their motors.
Freddy was the first robot to exhibit the ability to automatically
sequence the construction of complicated things for the first time. Since that time, there
has been steady but modest progress, which has led to the point where it is now possible
to inexpensively assemble complex devices such as electric motors without breaking
the bank. When solving assembly issues, the objective is to determine the sequence in
which the components of a given item should be assembled. It will be impossible to
add a component later in the sequence if the incorrect order is selected since doing so
would require redoing some of the work that has already been completed.
The process of determining whether or not a certain step in the sequence is feasible is
a challenging geometrical search issue that is strongly connected to robot navigation.
82 | P a g e
Therefore, the costliest aspect of assembly sequencing is the formation of legal lawsuits
because of this. In order to be practical, an algorithm must avoid exploring the entire
space with the exception of a very small portion of it. The design of proteins is still
another major obstacle to assembly. Finding an amino acid sequence that can fold into
a three-dimensional protein with the right properties to cure a certain disease or
infection is the goal of this task.
3.3 SEARCHING FOR SOLUTION
After identifying a few issues, the next step is to find solutions to problems, then you
need to figure out how to fix them. Since an action sequence is what makes a solution,
search algorithms work by considering all the possible action sequences. A search tree
is formed by the different action sequences that start at the starting state; the initial state
is at the root of the tree. Each node in the search tree represents a state in the issue's
state space, and each branch represents an action. In Figure 3.6, we can see the first
steps of creating the search tree to find a route from Arad to Bucharest.
The initial condition, in (Arad), is symbolized as the tree's root node. First things first:
we need to know whether this is a goal state. (The answer to trick questions like
"beginning in Arad, get to Arad." requires verification, even if it's clear that it isn't.)
After that, we should consider engaging in a wide range of pursuits. In particular, we
do this by adding new states to the existing ones via the process of "extension," which
entails applying each legal action to the current state. In particular, we will establish a
parent node In (Arad) and three child nodes by use of three branches. Specifically, these
offspring nodes will be located in Sibu, Timisoara, and Zerind. Now is the time to
choose which of these three suggestions will get more research time.
To search effectively, one must focus on one possibility at a time while putting the rest
on wait. This is carried out when the first choice fails to provide an answer. Assume
for the moment that Sibiu is our first choice. We expand it to get in (Arad), In
(Foggaras), In (Oradea), and in (Rimnicu Vilcea) after confirming that it is not a target
state. To achieve this, we first verified that it is a target state. We may then choose one
of these four options, or we can go back to the first screen and choose Timisoara or
Zerind. These six nodes in the tree are all leaf nodes, meaning they do not produce any
new branches. At any one time, the "frontier" consists of all the leaf nodes that are
viable for development. The phrase "open list" is used by many publications, although
it is inaccurate and fails to convey any geographical information.
83 | P a g e
The reason for this is because there are more suitable data structures than just a simple
list. In Figure 3.6, the nodes that form the boundary of each tree are the ones with robust
outlines. Until either a solution is found or no more states can be expanded, the process
of expanding nodes on the frontier will continue. Figure 3.7 provides an informal
representation of the TREE-SEARCH algorithm in its general form. This basic
structure is shared by all search algorithms; what differentiates them mostly is the
search strategy, which determines which state to grow too next.
Those readers with excellent observational skills may notice something peculiar about
the search tree in Figure 3.6: it includes the path that goes from Arad to Sibiu and then
back to Arad! In this specific case, a looping route produces what is known as In(Arad),
a recurring state inside the search tree. It turns out that the search tree for Romania is
limitless when loopy routes are included. This is because it is possible to go around a
loop an infinite number of times.
The state space, shown by Figure 3.2's map, however, consists of a mere twenty states.
In Section 3.4, we discussed how loops may make certain methods useless, which in
turn can make problems that might be solved otherwise unsolvable. In a stroke of good
fortune, looping paths are completely unnecessary. The reason why a looping method
to any state is always worse than the same technique without the loop is because route
costs are cumulative and step costs are nonnegative. There are other resources than gut
feelings that might help us with this.
84 | P a g e
Figure 3.5 A partial search tree was constructed to find a route from Arad to
Bucharest. Enhanced nodes are colored, newly created nodes are bold, and
weakly dashed lines reflect nodes that have not yet been established. Bold nodes
have not been extended yet.
Source: Data Processing and Artificial Intelligence: A Contemporary Approach, Stuart
J. Russell and Peter Norvig, 2010.
When there is more than one possible route from one state to another, we say that there
are redundant pathways; loopy routes are a subset of this concept. Redundant pathways
may take many forms, one of which being loopy paths. The 140-kilometer Arad-Sibiu
Road and the 297-kilometer Arad-Zerind-Oradea-Sibiu route are two examples. Taking
the second, more difficult path to the same place is obviously superfluous. No matter
how concerned you are about reaching your objective, you should never remember
more than one way to get to any particular condition. This is because, as a general rule,
if you can achieve a desired state by expanding one path, you can also reach the same
state by expanding the opposite direction.
In some cases, it is possible to define the problem itself, which will enable the removal
of superfluous paths. There is no! possible pathways to any state with n queens if the
8-queens problem (page 71) is rewritten so that a queen may be put in any column.
85 | P a g e
However, if we rephrase the issue so that each new queen goes into the first vacant
column on the left, then there is only one method to get to any state.
Table 3.2 The generic tree-search and graph-search algorithms are described in
an informal manner here. All of the modifications that are required to handle
repeated states are represented by the sections of GRAPH-SEARCH that are bold
and italicized.
A solution or failure is returned by the function TREE-SEARCH (problem).
start using the problem's starting state to initialize the border; if the frontier is empty,
return failure. remove a leaf node from the frontier if it has a target state; return the
matching solution; expand the node that was selected; add the nodes that were
expanded to the frontier.
A solution or failure is returned by the GRAPH-SEARCH function when provided a
set up the boundary by starting with the current issue state.
start with an empty explored set loop do
if the frontier is empty then return failure
choose a leaf node and remove it from the frontier
if the node contains a goal state, then return the corresponding solution
add the node to the explored set
expand the chosen node, adding the resulting nodes to the frontier
only if not in the frontier or explored set
Source: Artificial Intelligence A Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
In certain instances, it is impossible to avoid taking repeated pathways. All problems
in which the actions may be reversed are included in this category. Some examples of
such problems are sliding-block puzzles and route-finding difficulties. One example
that is especially significant in the realm of computer games is the process of locating
a route on a rectangular grid, such as the one that will be utilised later for Figure 3.9.
Because of this, a search tree with d levels and repeated states has 4d leaves, yet there
are only around 2d2 distinct states within d steps of any one state. This is because each
state in such a grid has four successors. When d is equal to 20, this indicates that there
are around 800 unique states but close to a trillion nodes. Therefore, pursuing repeated
pathways might result in an issue that was before manageable becoming unmanageable.
86 | P a g e
Even algorithms that are aware of how to prevent endless loops are not immune to this
phenomenon.
There is a proverb that states algorithms that forget their past are destined to bring it
back to them. Remembering where one has been in the past is the best approach to
avoid going down pathways that have already taken. In order to do this, we integrate
the explored set, often called the closed lies, is a data structure, into the TREE-
SEARCH algorithm. This structure is responsible for remembering each enlarged node.
When newly created nodes are found to be identical to previously generated nodes,
whether they are in the explored set or the frontier, it is possible to reject them rather
than adding them to the frontier. The new approach, which is referred to as GRAPH-
SEARCH, is shown in a more casual manner see Figure 3.7. In this chapter, we cover
a number of algorithms that use this general framework.
Figure 3.6 A graph search was conducted on the Romania problem, as
illustrated in Figure 3.2, and a series of search trees were generated as a
consequence. With every level we've finished, the journey has been extended by
Source: AI Stuart J. Russell and Peter Norvig's 2010 work presents a contemporary
method for gathering and processing data.
It is evident that the search tree that is produced by the graph-search algorithm has no
more than one copy of each state. Therefore, we may consider it to be the process of
developing Figure 3.8 shows a tree superimposed on the state-space graph. The
method's ability to split the state-space graph into an examined area and an
undiscovered zone is another one of its many useful features. This guarantees that the
investigated area is the starting point for all routes.
87 | P a g e
Figure 3.7 A rectangular grid is used to demonstrate the separation feature of
GRAPH-SEARCH.
Source: AI By Stuart J. Russell and Peter Norvig , a new method for collecting
and processing data has emerged.
In order to reach an unknown state, the original state must first go via a state that is
located on the border. (Exercise 3.13 should be performed right now if this was entirely
evident to you.) Figure 3.9 provides a visual representation of this characteristic. The
algorithm is solving the problem by systematically examining each state in the state
space. This is shown by the fact that as the process progresses, certain states are moved
from the undiscovered zone to the frontier, and vice versa.
3.3.1 Framework for algorithmic search
In order to maintain a record of the search tree that is being formed, search algorithms
need to be designed using a data structure. Our structure consists of the following four
parts, one for each node n in the tree:
• Nodes' corresponding states in the state space are denoted by state.
• The node in the search tree that created this node is represented by parent.
• The action that was taken to the parent node to produce this node is action.
• The cost of the route from the starting state to the node, as shown by the parent
pointers, is route-COST, usually represented by g(n).
88 | P a g e
Figure 3.8 The search tree is generated using nodes, which are data structures
that are created from the tree. Every single one of them has a parent, a state,
and a variety of accounting topics. The arrows point from the kid to the parent.
Source: Artificial Intelligence: A Contemporary Approach to Data Gathering and
Processing by Stuart J. Russell and Peter Norvig in 2010.
The components needed to construct a child node may be easily calculated when the
components for a parent node are known. Invoking the CHILD-NODE function with a
parent node and an action causes it to return the child node that was created:
function CHILD-NODE (issue, guardian, course of action) produces the expected
result—a node whose STATE is wrong. ACTION = parent's state, PATH-COST =
parent, and the result is returned by the function RESULT (parent. STATE, action).
PATH-COST plus issue. Procedure STEP-COST (parent. STATE, input)
Source: Artificial Intelligence: A Contemporary Approach to Data Gathering and
Processing by Stuart J. Russell and Peter Norvig in 2010.
A representation of Figure 3.10 displays the node data structure. Be careful to see how
the PARENT pointers join the nodes into a tree structure. These pointers also allow for
the extraction of the solution path upon discovery of a target node. After obtaining an
action sequence by tracking parent pointers back to the root, we utilise the SOLUTION
function to get it.
There has not been a great deal of attention paid to distinguishing between nodes and
states up to this point; nonetheless, when it comes to designing precise algorithms, it is
essential to achieve this separation. For the purpose of representing a data structure
known as a node in the search tree that is utilised in accounting. Within the context of
89 | P a g e
the world, a state is equivalent to a configuration. On the other hand, states are not on
specific pathways, but nodes are on specific paths that are determined by PARENT
pointers. Additionally, if the world state is formed by two distinct search pathways,
then it is possible for an identical world state to be included inside two distinct nodes.
Given that we now have nodes, we are in need of a location to store them. In order for
the search algorithm can easily choose the next node to expand based on its selected
strategy, the frontier information has to be kept in such a manner that it is easily
accessible. A queue is the data structure that is most suitable for this situation. These
are the operations that may be performed on a queue:
In the event that there are no more items in the queue, the EMPTY? (queue) function
will only return true.
• The POP (queue) function takes the first item in the queue and extracts it before
returning it.
• With the Using the INSERT (element, queue) method, we may insert an
element and get back the resulting queue.
What sets queues apart from other kinds of queues is the order in which they store the
inserted nodes. Common types of queues include the first-in, first-out (FIFO) queue,
which removes the oldest item from the queue; the last-in, first-out (LIFO) queue,
which removes the most recent item from the queue (also called a stack); and the
priority queue, which removes the item from the queue with the highest priority
according to some ordering function.
Through the use of a hash table, the explored set may be built in order to facilitate the
efficient testing of repeated states. It is possible to do insertion and lookup in a time
that is nearly constant, regardless of the number of states that are saved, if the
implementation is efficient. Putting Care must be used while putting the hash table into
action in accordance with the suitable notion of equality between states. As an example,
the hash table needs to know that the set of visited cities {Bucharest,Urziceni,Vaslui}
is the same as the set of visited cities {Urziceni,Vaslui,Bucharest} in the case of the
travelling salesman (page 74). Enforcing canonical form for state data structures may
be the easiest way to do this in some cases. Therefore, the same data structure should
correspond to states that are semantically equivalent. When it comes to sets
90 | P a g e
representing states, for example, a bit-vector representation or a sorted list free of
repetition would be deemed canonical, while an unsorted list would not.
3.3.2 Assessing the ability to solve problems
It is necessary for us to take into consideration the criteria that might be utilised to
choose individual search algorithms before we proceed with the construction of
particular search algorithms. We are able to assess the performance of an algorithm in
four different ways:
• Completeness: Does the method ensure that it will locate a solution whenever
there is one on the table?
• Optimality: In accordance with the definition provided on page 68, does the
technique locate the optimum solution?
• The amount of time investment required to discover a solution: how long does
• The intricacy of the space situation: What much of RAM is needed to run the
When attempting to quantify the difficulty of a problem, the interplay between time
and space is always a factor. The state space graph size, which is the standard metric
in theoretical computer science, is equal to the sum of the sets V and E. Here, V stands
for the set of graph vertices (nodes) and E for the set of graph edges (links). This is the
correct thing to do when the graph is a data structure that is explicitly inserted into the
search software. This is shown, for instance, by the Romanian map. In artificial
intelligence, the network is often infinite and is implicitly represented by the beginning
state, actions, and transition model.
These considerations lead to the following three measures of complexity: b, the
branching factor or maximum number of successors of any node; d, the depth of the
shallowest destination node (i.e., the number of steps along the route from the root);
and m, the maximum length of any path in the state space. A common metric for
measuring efficiency in both space and time is the greatest number of nodes that may
be stored in memory. The number of nodes produced during the search is a common
metric for measuring time. Time and space complexity of tree search is the main topic
of our talk. The answer in the context of a graph depends on how "redundant" the paths
in the state space are.
91 | P a g e
The search cost, which is often defined by the time complexity but may also include a
word for memory utilisation, is one metric that may be used to assess the efficiency of
a search algorithm. Another option is to use the total cost, which is equal to the sum of
the search cost and the route cost of the found solution. Both the search cost and the
solution cost are measured in terms of the total length of the journey in kilometers. The
search cost represents the time spent looking for a route from Arad to Bucharest. The
difficulty of determining a direct path between Arad and Bucharest is the source of both
of these expenses. Consequently, we need to include milliseconds and miles in the
overall cost. Even if there isn't a "official exchange rate" between the two, it's
reasonable to use an estimate of the typical speed of the car to translate kilometers into
milliseconds (because the agent is concerned with time). Therefore, the agent may find
the optimal tradeoff point, when doing additional work to find a quicker path becomes
unproductive.
3.4 UNIFORMED SEARCH STRATEGIES
This section discusses a number of different search tactics that fall under the category
of uninformed search, which is frequently used interchangeably with the term blind
search. The word indicates that the strategies do not include any more information
about states except for the information that is supplied in the specification of the issue.
All they are able to do is create successors and differentiate between a target state and
a state that does not have a goal. Every search strategy may be differentiated from one
another based on the sequence in which nodes are enlarged. Search techniques that are
able to determine which of the non-target states are "more promising" than competing
ones referred to as heuristic search strategies or informed search strategies.
3.4.1 search with a wide focus
An easy way to implement this strategy is to start by extending the root node, then all
of its descendants, then those descendants again, and so on. The breadth-first search
strategy describes this. Typically, while building a search tree, all the nodes are
expanded to a specific depth before moving on to the next level.
Figure 3.7 shows that one example of a general graph-search algorithm is the breadthfirst search method. The strategy involves picking the deepest, unenlarged node and
expanding it. Using a First-In, First-Out (FIFO) queue for the border makes this task
reasonably easy to perform. The outcome is that older nodes, which are shallower than
92 | P a g e
the new ones, get extended before the new ones, and new nodes, which are inherently
deeper than their parents, are pushed to the back of the queue. The goal test is applied
to each node during production instead of expansion selection in the generic graphsearch technique, which is a little change.
To achieve this, the test is applied during generation. The decision is dissected later
down the page when we discuss the time complexity. It should be mentioned that the
approach disallows any further paths to states that are already in the explored or frontier
sets, since it adheres to the fundamental graph search pattern. The previously known
route must be at least as deep as any such path, and this is a very obvious fact.
Consequently, the breadth-first search strategy guarantees that for any node on the
frontier, there is a minimum-depth route.
The pseudocode may be seen in Figure 3.11. Figure 3.12 shows the search's
advancement using a basic binary tree.
How does the breadth-first search performance differ using the four criteria mentioned
earlier? If the branching factor b is finite and the shallowest target node is at a finite
depth d, then breadth-first search will find it after generating all the shallower nodes.
This is something that stands out as being true. Keep in mind that the moment a goal
node is created, we know it is the goal node with the least depth as all the shallower
nodes must have been made and failed the goal test before. Now, it's not always the
case that the target node with the lowest depth is the best;
Table 3.3 A search on a graph that prioritizes breadth
A node with the status "problem" is returned by the function
BREADTH-FIRST-SEARCH, which may either be a solution or a failure. If there is
INITIAL-STATE, PATH-COST will be 0.
GOAL-TEST (node. STATE) returns the current state of the node; frontier indicates
FIFO queue with node as the sole element; explored indicates an empty set;
if EMPTY? (frontier) returns failure, node indicates that the node is empty;
POP (frontier) selects the node with the lowest depth; add node. Proceed with each
step of the problem-solving process. If child is an element of the node, then perform
CHILD-NODE (problem, node, action) using
93 | P a g e
ACTIONS (node. STATE). The state is not yet on the border, thus there may be
issues. After running the goal test on the child's state, the code will return the solution
and insert the child's border.
Source: Artificial Intelligence: A Contemporary Approach to Data Gathering and
Processing by Stuart J. Russell and Peter Norvig in 2010.
From a technical standpoint in cases when the route cost is not a function that decreases
as the depth of the node increases, breadth-first search is the optimal choice. When all
actions have the same cost, this sort of situation occurs most often.
Up to this point, the breadth-first search has only had good news. There is some
discouraging data on space and time. Consider a uniform tree where each state has b
successors; it should be easy to see. As a result of the search tree's root producing b
nodes at the first level and those nodes in turn producing b more nodes, the second level
has a total of b2 nodes. Each of these generates b new nodes, which in turn generates
b3 nodes at the subsequent level, and the cycle continues indefinitely. Just pretend for
a second that depth d is where the solution lies. In the worst-case scenario, it is the very
last node to develop at that level. The total number of nodes generated is O(bd) as it is
equal to b plus b2 plus b3 plus bd.
Figure 3.9 Using a basic binary tree in a breadth-first search. At the conclusion
of each stage, you can see the node that will be enlarged next thanks to the
Source: AI Stuart J. Russell and Peter Norvig's 2010 work presents a contemporary
method for gathering and processing data.
(The temporal complexity would be O(bd+1) if the expansion of the whole layer of
nodes at depth d was to occur before the goal was detected; this would happen if the
94 | P a g e
goal test were applied to nodes at the time of selection for expansion instead of
formation.)
Regardless of the kind of graph search, the space complexity will always be less than
or equal to b times the time complexity for any set that is being studied. Regardless of
the kind of graph search, this remains true. Keep in mind that, especially for breadthfirst graph search, each newly generated node remains in memory. The explored set
will have a number of nodes with an O(bd−1) complexity, while the frontier will have
a number of nodes with an O(bd) complexity.
The complexity of the space is thus O(bd), which means that it is mostly determined
by how wide the boundary is. Switching to a tree search won't help in a state space with
plenty of redundant paths. a significant amount of space, and switching may also cost
a significant amount of time.
It is unsettling to see is limited by an exponential complexity, such O(bd). See Figure
3.13 for the explanation. The table gives the memory and time requirements for a
breadth-first search with a branching factor of b= 10 for a range of solution depth d
values. Assuming that one million nodes can be formed in a single second and that each
node takes one thousand bytes of storage space, the table is constructed. The majority
of search tasks, when executed on a contemporary personal computer, are generally
able to be accommodated within these assumptions (give or take a factor of 100).
Table 3.4 The requirements for time and memory for breadth-first operations
11 milliseconds
107 kilobytes
II milliseconds
10.6 megabytes
1.1 seconds
103 gigabytes
10 terabytes
I petabyte
99 petabytes
10 exabytes
Source: Artificial Intelligence: A Contemporary Approach to Data Gathering and
Processing by Stuart J. Russell and Peter Norvig in 2010.
95 | P a g e
The analysis of Figure 3.13 reveals two important takeaways. To begin, the memory
needs for breadth-first search are a more significant challenge than the execution time.
If one were to wait thirteen days for the answer to a significant issue using search depth
12, it would be impossible to do so since no home computer had the petabyte of
memory that would be required. On the bright side, there are alternate ways that use
less memory. The second thing that I've learned is that time is still a significant element.
If there is a solution to your issue Using our assumptions, a breadth-first search (or any
other uninformed search) would take about 350 years to find it at depth 16. of the
exception of the most basic instances, uninformed methods are usually unable to handle
search problems of exponential complexity.
96 | P a g e
UNDERSTANDING ARTIFICIAL INTELLIGENCE
4.1 INTRODUCTION
Numerous fields have benefited greatly from recent developments in deep learning,
including computer vision, speech processing, natural language comprehension, and
many more. Improvements in processing capabilities, particularly graphics processing
units (GPUs), and greater data sets are primarily responsible for this increase, rather
than the creation of substantially new algorithmic frameworks or knowledge
representations. The bulk of modern AI systems still adhere to the fundamental
principles of Stochastic Gradient Descent and Artificial Neural Networks, two
breakthroughs in the 1980s. The 1980s saw the development of both networks.
Although it is highly beneficial for many applications, especially in the realm of vision,
the deep learning-only approach has many major flaws. For example, CNNs struggle
with same-different relations, their models aren't interpretable, they can't be
deconstructed, they don't properly include symbolic information, and they can't fulfil
the requirements for long-chained reasoning.
In terms of input processing, many of the current technologies just compute higherorder statistics over basic components like pixels, phonemes, letters, or words. These
methods, however, fail to provide an easily (de)composable and interpretable
representation of the components and their interconnections. The use of symbols to
represent information, formal logic, and reasoning, however, is not new. This has really
been around for a while. The problem is that these methods struggle when faced with
inconsistent, incomplete, or unclear data. Instead of limiting ourselves to deep learning
and symbolic approaches, we want to provide up-to-date benchmarks and research
streams that cover a wider range of topics.
Here we detail how different research streams and standards express and use data to try
to comprehend things on a human level. Compositional, hierarchically structured
knowledge representations that integrate several modes of expression are the focus of
these studies. Part one of this debate will include some introductory information about
the term "understanding" and its significance in relation to AI, as covered in Section 2.
One way to evaluate comprehension abilities is to compare results to those of other
97 | P a g e
systems or people; this is known as benchmarking. This strategy will be covered in
greater depth later on in the text.
4.2 DEFINITION OF” UNDERSTANDING”
According to the Cambridge Dictionary, "understanding" is being able to explain
something by describing its causes and mechanisms. There are available definitions
that are quite similar to one another in a lot of disciplines, including computer science,
philosophy, and psychology. It is now widely accepted that understanding is a crucial
component of AI. The development of autonomous, intelligent robots relies heavily on
the design of computer programmes with environmental perception capabilities. Many
competing hypotheses have been advanced in an attempt to provide light on the nature
and development of AI. Many diverse approaches have been used in proposing these
ideas. To this day, we still don't fully grasp the challenges faced by cutting-edge AI
systems, even if these approaches can occasionally outperform humans. Machines that
can learn to play AlphaGo and other Atari games require a large quantity of training
data in the form of sample games so that they may change the basic game model. If you
want the machine to learn the game, you have to do this.
Unfortunately, no matter how much training is done, there is still no way to create a
model that can be used for jobs that are very similar to the original one. Not only that,
but there is no way to create a model that can be used for games either. We may look
at one more example in the field of image analytics. Deep neural networks are at the
pinnacle of technological achievement in many different fields of application. Medical
image diagnosis, face recognition, and the control of autonomous vehicles are just a
few examples of these fields. When neural networks are subjected to so-called
"adversarial attacks," they have a good chance of making a very confident mistake in
object identification. What we call these kinds of assaults are "adversarial attacks." This
form of attack modifies images by really small amounts that are nearly hard for humans
to notice.
This proves that neural networks use distributions of higher-order pixels for
categorization instead of possessing actual image information. Also, cutting-edge
algorithms for natural language processing are quite picky about the exact wording of
inputted text, even down to the smallest of adjustments, yet humans are immune to this.
Providing a formal description and an accurate assessment of a system's capacity to
understand particular information may prove to be problematic. The results produced
98 | P a g e
by a system can be evaluated by humans in a manner analogous to the Turing test, a
method that has been suggested for determining if a system is intelligent. The idea of
"understanding" might be quantified in this manner. The difficulty and openness to
interpretation of such a measurement is, however, a major downside. Another approach
to finding out how well a system understands data is to compare its performance to that
of other systems on certain data sets and tasks. When evaluating machine learning
systems, one typical approach is to utilise benchmarks. The use of these standards
allows for a repeatable and objective examination.
To test whether algorithms can handle more challenging issues, it is feasible to create
benchmarks that include tasks that are progressively more complicated. Eventually, we
hope to have a system that reliably exhibits very intelligent conduct. It is crucial not to
commit everything to memory in a manner analogous to testing human intellect. The
word "memorization" as used here means to get good scores on a test by committing
the questions and answers to memory. Furthermore, it is important to consider whether
or not the benchmark data set has biases. It becomes more challenging to assess one's
grasping ability when these biases might be used for personal gain. Modern
benchmarks like CLEVR have found ways around these problems by supplying
synthetic data with well controlled distributions, which completely removes the
possibility of bias. Because of this, they have been able to avoid the issues. However,
there are frequently constraints on the capacities to understand synthetic data. This is
because, in contrast to real-life circumstances, the depth and complexity of simulations
are far lower.
For the CLEVR benchmark, for instance, your system has to be able to isolate and
locate a limited set of objects that share a specific set of properties. One effective
strategy for dealing with it, which goes beyond what humans are capable of, is the
employment of neuro-symbolic techniques. It is necessary to create and use
benchmarks that represent a growing level of complexity in order to advance towards
ever more complicated comprehension capacities. To move forward, this is essential.
Composing ability is another crucial comprehension attribute; this quality has received
a lot of attention in relation to visual tasks and understanding natural language. In a
broader sense, it's the capacity of a system to break down an object or issue into its
constituent parts and then reassemble those parts in novel ways to carry out related but
separate tasks more efficiently, whether that's through the use of less data or higher
processing speeds. That is to say, it dissects the object or issue into its component parts.
99 | P a g e
As our knowledge of the system grows, we will investigate the feasibility of combining
previously collected data into ontologies and knowledge graphs. The quantity of data
stored in the system may be quickly and readily expanded in this way. A knack for
immediately integrating information could facilitate the transfer of abilities across
domains or activities. This would help AI systems become more adaptable so they can
understand and solve new problems.
4.3 WHAT IS ARTIFICIAL INTELLIGENCE?
In the context of AI, what function do robots perform? Will AI and robots ever be able
to live side by side? How exactly do you think these two claims differ from one
another? The different uses for AI and robotics are somewhat distinct. Saying so, many
people confuse the two of them. The question of whether robotics falls under artificial
intelligence or if the two terms may be used interchangeably is one that many people
find difficult to resolve.
Figure 4.1 AI Part Of Robotics
Source: data collection by Artificial Intelligence in Manufacturing Companies and
Broader: Buch meister, B 
4.4 ARTIFICAL INTELLIGENCE VS ROBOTICS
Computer scientists have the option of delving further into the topic of computer
science by investigating artificial intelligence (AI). An essential part of this process is
developing computer programmes to perform tasks that, in other contexts, would need
human cognitive abilities. A few examples of the many possible tasks that AI systems
may do include learning, perception, problem solving, language understanding, and
logical reasoning. Artificial intelligence (AI) has many potentials uses in today's
100 | P a g e
society. These applications cover a wide spectrum, from self-driving cars to virtual
assistants. In terms of future growth, artificial intelligence (AI) is making enormous
strides. In science fiction, robots designed to seem as human as possible are a common
representation of artificial intelligence (AI). Robotics, on the other hand, is a subfield
of computer science concerned with robotics. One branch of computer science is
robotics. Autonomous or semi-autonomous robots can often follow a set of
predetermined instructions and complete a sequence of tasks without human
intervention. Robots may be programmed to interact with their physical surroundings.
Robots can operate independently or with limited human oversight. The three main and
most important components of a robot are these.
Since certain robots lack the capability to function alone, we use the word "usually"
self-sufficient to describe them. It is still considered a subfield of robotics even though
human operators have complete command over telerobots and other forms of
telerobotics. In the distant future, AI-powered robots will serve as a binding tie between
AI and robotics. What this means is that these robots can be guided by AI-powered
computer software. There is a staggeringly large proportion of robots that are
completely devoid of AI. Up until very recently, the only thing that industrial robots
could be taught to perform was to repeat a predetermined pattern of operations. In order
to do repetitious tasks, artificial intelligence is unnecessary, as was already said.
Intelligent machines have limitless potential, which non-intelligent robots may only
dream of matching. These days, AI algorithms are very much a need for any robot that
wants to take on more difficult jobs.
4.5 DEFINING ARTIFICIAL INTELLIGENCE
4.5.1 Traits of an AI
Using algorithms that are able to extract patterns from enormous amounts of data,
artificial intelligence is able to demonstrate both the ability to forecast and adapt to new
circumstances.
Artificial intelligence, which is capable of making judgements on its own, has the
potential to improve human intelligence, generate insights, and boost productivity.
In addition to continuous learning, the analytical models that artificial intelligence
employs are built with the help of algorithms. Artificial intelligence technology will
101 | P a g e
find out how to carry out duties by participating in an unlimited number of rounds of
trial and error. This will be accomplished with the assistance of these algorithms.
Artificial intelligence (AI) is a technology that allows humans to rethink how they
analyse data and integrate knowledge, and then use these new insights to make better
decisions. AI makes it possible for individuals to gaze into the future.
4.6 TYPES OF AI AND THEIR APPLICATIONS
A more precise description of AI as it is now would be restricted AI, sometimes called
weak AI. For example, a restricted artificial intelligence system may be programmed
to do nothing more than browse the internet, drive a car, or recognise faces; it lacks
sentience and is hence limited in its usefulness. In contrast, many scientists are aiming
to develop AGI, which is often called strong AI in some areas, as their ultimate goal.
This usually means that computers are "at least as smart as a typical human." A
computer with artificial general intelligence (AGI) can work its brains out of every
given situation, not just a single one.
Figure 4.2: Future of AI
Source: data collection by Artificial Intelligence in Manufacturing Companies And
Broader: Buch meister, B 
Narrow AI has the potential to surpass humans in a single task if designed only for that
task, such as solving complex mathematical problems or playing chess. However, in
102 | P a g e
almost every cognitive task, global artificial general intelligence (AGI) would
accomplish better results than humans.
The realisation of super intelligence (ASI), a level of mental capacity that exceeds that
of the most brilliant and talented humans, is the end aim of this made-up endeavour. In
a very short period of time, the development of artificial general intelligence is
expected to lead to the production of super intelligence, as a result of recursive selfimprovement.
Type 2 (Based on functionalities)
Purely Reactive
The most fundamental type of machine is a reactive machine, which cannot use its past
experiences or store "memories" to guide its future decisions. Being alert and
responding to what they perceive is their sole activity. One of IBM's reactive systems
is Deep Blue. It has the ability to observe and respond to chess pieces. It was possible
to beat chess grandmaster Kasparov with this strategy. The system is unable to learn
from its mistakes or build upon its prior successes. It is not feasible to do either of these
Limited Memory
Data can only be stored for a certain length of time by machines with limited memory.
They have a limited window of opportunity to put this data to good use, but they can't
compile it into a book about their experiences. Many autonomous vehicles make use of
Limited Memory technology. Vehicles equipped with this technology can save data
that could be useful for navigating roads, such as the current speed of other cars, the
distance between them, the speed limit, and other pertinent information.
Theory of Mind
Individuals are described as being driven by their thoughts, feelings, memories, and
mental models, which in turn shape their behaviour, according to the discipline of
psychology. The objective of researchers that investigate theory of mind is to produce
computers that are capable of imitating human mental models. This is accomplished by
generating representations about the environment, as well as about other agents and
items that are present in it. The development of computers that are able to relate to
103 | P a g e
humans and recognise human intelligence, as well as having the ability to comprehend
how the environment and events impact people's sentiments, is one of the goals that
these academics have set for themselves. In spite of the fact that there are a vast number
of computers that use models, there is not yet a computer that possesses a "mind." C-
3PO R2-D2 from the Star Wars Universe and Sonny from the film I, Robot, which was
released in 2004, are two instances of robots that have been used in this way.
Self-Awareness
In spite of the fact that they are the stuff of science fiction, a significant number of
individuals who are enthusiastic about artificial intelligence believe that the ultimate
goal of AI research is to create robots that are self-aware. The question of whether or
whether a machine can become really self-aware, sometimes known as "conscious," is
one that should be left to the experts from the field of philosophy. Even if a machine
were to be able to function in the same manner as a human being, for example by
conserving itself, anticipating its own wants and desires, and connecting to others as an
equal, the issue would still not be addressed. This is the reason why this is the case. In
the film Ex Machina , for instance, Eva made an appearance, while Synths made
an appearance in the television series Humans .
4.7 ACHIEVING AI
The development of artificial intelligence may be accomplished in a variety of methods,
some of which are as follows:
Figure 4.3: AI Branches
104 | P a g e
Source: data collection by Artificial Intelligence in Manufacturing Companies and
Broader: Buch Meister, B 
On the other hand, we shall be talking about the most significant of them all.
4.8 NATURAL LANGUAGE PROCESSING (NLP)
In addition to making, it easier for computers and people to communicate with one
another in their native language, natural language processing also makes it easier to
scale up tasks that are connected to language. Natural language processing (NLP), for
example, enables computers to read text, hear speech, evaluate it, quantify ideas and
emotions, and determine which portions are relevant. Natural language processing also
enables computers to identify which sections are significant. The computers of today
are able to analyse more information based on language than humans are now capable
of doing, and they can do it without being weary and in a consistent and objective
Figure 4.4: AI Perception Action Cycle in Autonomous Cars
Source: data collection by Artificial Intelligence in Manufacturing Companies and
Broader: Buch meister, B 
4.8.1Vision
Over the course of the past several years, there has been a decrease in the costs that are
involved with the collecting and recognition of huge data sets. The Industrial Internet
of Things (IIoT) has seen significant advancements, which has led to this immediate
105 | P a g e
consequence. As a direct result of this specific advancement, machine learning is now
more readily available for use in inspection applications than it has ever been before.
The second important use of this technology is the incorporation of artificial
intelligence into vision systems with the objective of accomplishing the ongoing
enhancement of recognition applications.
4.8.2 Autonomous Vehicles
A loop that is repeated and is referred to as a perceptual activity cycle is produced as a
consequence of the process by which autonomous automobiles receive data from their
surroundings and then input that data into an intelligent agent. This process results in
the formation of a loop. An intelligent agent will then make decisions, which will, in
turn, make it possible for an autonomous vehicle to carry out certain tasks in an
environment that is nearly identical to the one in which it was formed after it was
developed. Take a look at the following image, which provides an illustration of the
flow of data that takes place within autonomous vehicles:
4.9 AI'S IMPACT ON INDUSTRIES
In this era of tremendous technological advancement, artificial intelligence (AI) has
arisen as a potent force with the potential to radically alter the civilization in which we
now reside. It might cause major shifts in how we live, work, and communicate, and
its effects are already seen in many different areas. Various industries, such as
healthcare, banking, education, and entertainment, are seeing the introduction of
exciting new prospects brought about by AI, which is also changing established
practises. In this blog, we will examine the effects of AI on various businesses, with a
particular emphasis on the ways in which AI has influenced student views within the
realm of education.
As a result of using AI, substantial progress has been made in the field of education.
Adaptive learning platforms and intelligence-based tutoring systems both utilise AI
algorithms. One way to ensure that every student has a personalised learning experience
is to adapt the course material to their specific strengths and areas of weakness. By
answering student questions and expanding access to educational materials, chatbots
powered by AI might revolutionize the way students receive support in the classroom.
Another factor that helps to speed up the grading process is the emergence of AI-based
assessment tools, which offer faster and more objective evaluations.
106 | P a g e
Artificial intelligence (AI) has recently arisen as a potent tool with potential
applications in healthcare, including patient diagnosis, drug discovery, and treatment.
Algorithms trained with machine learning can sift through mountains of medical data
in search of clues about potential diseases and treatments. It is possible that this will be
very helpful. Artificial intelligence (AI)-powered robotic help has allowed surgeons to
perform intricate surgical procedures with more accuracy and less room for error.
Virtual nurses and health monitoring systems powered by AI algorithms may now
provide remote patient monitoring and personalised medical assistance. Plus, these
technologies can keep tabs on patients from afar. Economic Sector Having regard to
the financial industry has seen a dramatic transition as a consequence of artificial
intelligence's impact on automation, fraud detection, and predictive analytics.
Intelligent algorithms can sift through massive databases, spot trends, and provide
reliable predictions for investing strategies. Utilising chatbots powered by AI allows
for the automation of repetitive financial tasks and the provision of customer service.
Consumers get a better experience and productivity rises as a result. Artificial
intelligence (AI) technologies may also help detect fraudulent activity, which lessens
risks and ensures the security of financial transactions altogether.
The media and entertainment industries have been quick to embrace AI as a means to
better serve their customers and make it easier to create personalised content. Machine
learning algorithms take into account the user's tastes, habits, and past activities to
recommend films, TV shows, songs, and other types of entertainment. In the fields of
gaming and storytelling, the combination of artificial intelligence (AI) with VR and AR
technology has led to the development of immersive experiences. A defining feature of
this sector is the use of AI to the creation of content, be it computer-generated artwork
or automated news reporting.
The Transportation and Logistics Industry: The complete upheaval that AI has caused
in the logistics and transportation industry has ushered in a new age of driverless cars,
smart traffic control, and highly efficient supply chain management systems.
Transportation might become safer and more efficient with the help of autonomous cars
and trucks driven by AI algorithms. Application of AI-based optimisation techniques
allows for the simplification of logistical procedures. As a result, this contributes to
better delivery times and lower costs. Improved customer happiness and overall
productivity may be the outcomes of using AI-powered predictive maintenance and
route planning.
107 | P a g e
More personalised shopping experiences, better inventory management, and enhanced
customer care are all outcomes of the retail industry's rapid use of artificial intelligence
(AI). Even better for the e-commerce sector is this trend. In order to provide shoppers
with suitable product recommendations, recommendation systems that use AI-powered
algorithms examine shoppers' tastes and online habits. Artificial intelligence (AI)
chatbots not only make it easier for customers to make purchases and get product
recommendations, but they also answer customer questions. Retailers may also benefit
from AI-powered inventory management systems when it comes to forecasting
customer demand, keeping track of inventory, and cutting down on waste.
Modern manufacturing and industrial automation systems would be lacking something
essential without AI, which is helping to streamline production procedures and boost
overall productivity. Artificial intelligence-enabled industrial robots can accomplish
repetitive jobs quickly and accurately. By lowering the potential room for human
mistake, this feature enhances output. It is critical to have quality control systems that
are able to detect errors and abnormalities in real time, powered by artificial
intelligence. This will help preserve high product standards. Predictive maintenance
using artificial intelligence algorithms helps keep equipment online for as little time as
possible. In the long run, this maintenance helps save money by optimising
maintenance schedules.
Farming & Agriculture: AI is reshaping the agricultural industry by increasing harvest
yields, tracking soil health, and optimising resource utilisation. Unmanned aerial
vehicles (UAVs) outfitted with AI and satellite imagery are being used to track crop
health. Because of this, farmers might catch illnesses, pests, or malnutrition in their
crops early. More accurate production forecasts may be generated with the use of
machine learning algorithms, which can more precisely determine when to sow and
harvest crops. Water usage can be optimised with the use of AI-driven intelligent
irrigation systems, leading to resource savings and cost reductions.
The energy sector can benefit from AI due to its ability to optimise energy production,
improve grid management, and increase resource efficiency. For this reason, AI is
becoming useful in the energy sector. Smart meters and other sensors collect data,
which artificial intelligence systems then use to predict how much energy will be used
in the future. Because of this, utility firms have more say over energy generation and
delivery. Artificial intelligence-driven predictive maintenance solutions aid in the
oversight of energy infrastructure by identifying potential issues before they escalate.
108 | P a g e
There will be less downtime and better maintenance results because of this. Artificial
intelligence also aids in assessing the feasibility of reducing energy use and integrating
renewable energy sources. This is a major advancement that AI achieves. The use of
artificial intelligence is causing a number of changes in the HR and recruitment
processes. These changes include the automation of laborious tasks, the enhancement
of candidate selection, and the enhancement of employee engagement. Applicant
tracking systems that are powered by artificial intelligence are responsible for analysing
resumes. These systems also evaluate prospects and identify which candidates are the
best fit for certain jobs. In addition to chatbots and virtual assistants, employees may
get support with issues about HR rules and benefits.
Additional assistance may be provided. organisations are able to evaluate the degree of
engagement and happiness of their staff with the use of tools powered by artificial
intelligence (AI) that analyse sentiment. This allows these organisations to take
preventive measures for the growth and retention of their employees. Artificial
intelligence is continuing to have an influence across a broad variety of business
domains, bringing with it both new opportunities and new challenges. This impact is
continuing to be noticed.
Because it helps students to have a more well-rounded perspective and the ability to
adapt to the needs of future employment, having awareness of the effect that artificial
intelligence is having in a range of sectors is beneficial to students. The use of artificial
intelligence technology in a responsible way and the acquisition of the required skills
will be absolutely necessary for success in a future that will be driven by artificial
intelligence. By harnessing the power of artificial intelligence, industries have the
potential to achieve higher levels of innovation, efficiency, and sustainability in their
operations.
WHY AI AND WHY NOW?
Businesses can now integrate massive amounts of organised and unstructured data with
the help of artificial intelligence. They can also use natural language queries to get
results and use machine learning techniques to data analysis. When put together, these
abilities may significantly boost speed, efficiency, and insight. The use of artificial
intelligence by companies producing industrial goods is currently at a crossroads. Half
or more of the executives surveyed think their companies and industries are ready to
adopt the technology, and they also agree that it's ready to sell.
109 | P a g e
• How much money do you think industrial products manufacturers will put into
AI? When all three of these objectives are met at once, there is a tremendous
opportunity to improve efficiency and decision-making.
• Data from raw materials, production lines, finished goods, maintenance
records, and consumer complaints may be analysed by artificial intelligence
systems to determine the factors that caused quality concerns. We do this to
make sure the product is up to par.
• Data pertaining to processes and the activities performed by top-line operators
in manufacturing operations may be continuously fed into artificial intelligence
systems, allowing them to learn. Also, it's useful for predicting and identifying
outcomes and suggesting ways to boost productivity.
• The application of artificial intelligence in machine maintenance offers several
benefits, including the capacity to detect irregularities, assess their severity,
identify their root cause, and aid maintenance professionals in doing fixes
correctly the first time.
4.11 INDUSTRIAL PRODUCTS LEADERS GAIN VALUE FROM AI
In what ways may companies benefit from the most recent advancements in AI
technology? We looked through the survey responses and identified a handful of
industrial products that worked very effectively to find a solution to this problem.
Twelve percent of our study was devoted to this group. The self-reported data shows
that this organisation has been far more efficient and profitable than its competitors
over the past three years, and it has also surpassed them in terms of revenue.
What was it that made these successful people different from the rest? With the data
they have, they can make educated guesses about how their companies will do in the
AI future. When compared to the other replies, where just 2% of executives are fully
in agreement that their business is ready to deploy AI, this 7% figure is rather high.
Many high-performing industrial products have begun to include artificial intelligence
(AI), which is not surprising. Only 32% of the other products we looked at had
employed AI before, whereas 64% of them had. Looking at these companies' top
executives can help other groups understand what they need to do to adapt to the AI
era. Afterwards, they could begin to:
• Construct a foundation for artificial intelligence data
• Concentrate on developing new talents
110 | P a g e
• Develop a new degree of intelligence
4.12 ETHICS AND AI
A trustworthy artificial intelligence system should be in conformity with all applicable
laws and regulations, as well as a set of standards; special lists of evaluations are
developed to aid in confirming the application of each of the major criteria.
Robustness and Safety: In order to create artificial intelligence that can be relied upon,
it is vital to have algorithms that are secure, trustworthy, and resilient. These algorithms
need to be able to deal with any faults or inconsistencies that may arise over the whole
life cycle of the artificial intelligence systems themselves.
Privacy and data governance: Individuals should have complete control over their
own personal data, and their data should not be used in a way that causes them damage
or discriminates against them.
Transparency: It is imperative that artificial intelligence systems be provided with a
guarantee of tractability.
Accessibility, as well as the whole range of human abilities, skills, and requirements,
have to be taken into consideration and ensured by artificial intelligence systems.
Additionally essential are the principles of diversity, non-discrimination, and fairness.
Artificial intelligence systems should be utilised to inspire positive social change and
to enhance environmental sustainability. This brings us to the sixth point, which is the
well-being of society and the environment.
Accountability: To ensure accountability and responsibility for artificial intelligence
systems and the products they generate, it is vital to design processes that will guarantee
accountability and responsibility.
4.13 ETHICAL DILEMMAS WITH ARTIFICIAL INTELLIGENCE
In spite of the fact that artificial intelligence provides an infinite number of possibilities,
we must not lose sight of the fact that, in many respects, this is just a new frontier for
ethics and risk assessment in addition to being a new frontier for the technology that is
being created. This is something that we must not overlook. Not only does artificial
111 | P a g e
intelligence have a tremendous influence on our economy, but it also has a significant
influence on our culture. The effects of this may be observed in the form of supply
chain optimisation, as well as conversations with "Alexa" from Amazon and "Siri"
from Apple among other things.
These two technologies are quite well-liked by people. There has been a significant
increase in the demand for ethics and standards as a consequence of the tremendous
growth of technology over the course of many years. Recent events have resulted in the
formation of this need, which has since evolved. It is possible that the development of
artificial intelligence will put us in a lot of difficult ethical situations. According to
Bossman , the World Economic Forum has identified nine potential ethical
challenges that will be posed to human beings during the process of developing and
deploying artificial intelligence. These challenges will be posed during the
development and deployment of AI. As a result of the development and implementation
of artificial intelligence, many issues will ensue. After this, we will have a brief
conversation on the topics that are going to be covered in the next sections.
4.13.1 Unemployment
Is it conceivable that the technological advancement of artificial intelligence might
result in the elimination of jobs for human beings? In the event that people start talking
about artificial intelligence and robots, it is unavoidable that this worry will be brought
up again and again. In spite of the fact that we have already made tremendous progress
in automating labour, we have still made room for individuals to perform activities that
are more difficult. During this move away from the physical labour that was dominant
in the pre-industrial market, working approaches that are more cognitively demanding
and strategic in nature are becoming more widespread.
This is a result of the fact that the pre-industrial market prioritized physical labour. The
trucking industry is one of the job sectors that is most likely to be automated through
the implementation of technologies that are now available. According to statements
made by Elon Musk, his self-driving vehicles will be ready for usage in commercial
settings over the next 10 years.
Assuming that he keeps his word, what are the consequences that will follow? This is
the time when mankind is at a crossroads, the time when we need to decide how we are
going to spend our time and what we are going to do with it. This is the moment when
112 | P a g e
we need to make a decision. In spite of the fact that the majority of people in today's
society are reliant on their income to fulfil their financial obligations and provide for
their families, we can only hope that the advent of artificial intelligence will inspire
people to pursue hobbies that are not related to their jobs. People may enhance their
life by doing a variety of things, like taking care of their families, being more involved
in their communities, learning how to be more proactive, and making a contribution to
human civilization. These are just some examples. Who knows, maybe one day we may
look back on history and see that it was foolish of us to waste your precious and brief
years on earth working hard just for the sake of preserving our way of life. Who knows?
Nevertheless, who's to say?
4.13.2 Wealth Inequality
The subject of how we will distribute the wealth that is created by computers is another
challenge that Bossman addresses in his presentation that he gave at the World
Economic Forum in the year 2016. This implies that we are compensated for the
contributions that we make to the economy, which is the cornerstone of the global
economy, which is a compensation system. The vast majority of firms in the current
day continue to pay their employees on an hourly basis; however, wealthy organisations
that are able to use artificial intelligence will see a significant reduction in the amount
of money they spend on salaries. Because of this, they will generate at least the same
amount of profit, but they will divide it to a smaller number of persons.
This is the effect of this. As a consequence of this, those who manage businesses that
are powered by artificial intelligence will be the ones to earn all of the money. This will
result in a far bigger gap between the wealthy and the less fortunate than it is in some
countries at the present time. Therefore, it is of the utmost importance that governments
and huge businesses start thinking about the ways in which we can distribute that
wealth in order to guarantee that everyone will have the chance to take part in our future
4.13.3 Humanity
How will the development of new technology impact human conduct and social
interactions? More and more, computers are able to hold their own in a discussion with
a human being, thanks to a dramatic rise in their intelligence over the past several years.
"Siri" from Apple and "Alexa" from Amazon are two digital assistants that come to
113 | P a g e
mind. Depending on the data given to them, these two virtual assistants may converse
with humans to a certain extent, answering questions and carrying out tasks. Machines
will play an increasingly larger role in our lives in the future, especially in sales and
customer service. Unlike humans, who have a finite amount of time and energy to
devote to developing meaningful connections, robots can pour an infinite amount of
resources into this process. Thus, it is possible for robots to build relationships. When
designing an ideal society, perfect communication and cooperation between people and
robots are of the highest significance. Of all the things to think about, this is the most
crucial. the most crucial reason being that our ability to form bonds with one another is
an essential part of what it is to be human, and without it, we would be severely lacking.
4.13. 4 Artificial Stupidity
Furthermore, as said before, robots gain intelligence through learning. Through
practice, kids learn to detect relevant patterns and act properly in response to new
information. To be sure, there's no way to train a computer to handle every single
possible scenario that may arise in the real world. A higher probability of success exists
for fooling robots in this way as compared to humans. For example, robots could be
tricked into perceiving imaginary objects if their dot patterns aren't predictable. It is
crucial that we trust AI and ensure that it cannot be exploited for selfish purposes if we
believe it will bring about a new age of work, economy, and efficiency.
4.13.5 Bias
Additionally, another major ethical dilemma has emerged with the exposure of AI's
intrinsic biases. Do you think AI upholds justice? Is it possible to prevent AI systems
from being biassed? Though technology outperforms people in terms of speed,
efficiency, and accuracy, it is reasonable to say that robots aren't perfect and aren't
always impartial. Even if robots can outperform humans in terms of accuracy, this
remains the case. The AI will internalize the prejudices of the datasets it uses for
When given the opportunity, a computer trained on biassed data—including biases
based on gender, colour, education, and socioeconomic status—will inevitably exhibit
such biases. To illustrate the point, a piece of AI software developed in the US with the
goal of identifying potential offenders recommended harsher punishments for Black
individuals and assigned them higher risk ratings. This was due to the fact that racial
114 | P a g e
bias was present in the statistics about criminal incarceration in the US. Because of this,
remembering that even AI is created by humans and affected by their tastes is crucial.
Furthermore, another objection arises from the fact that no dataset is perfect. A time
without difficulties is impossible to come by, and neither is it feasible to overcome all
difficulties in the time allotted. Making AI more sustainable and ethically compliant
requires addressing prejudice, which is among the most crucial challenges. Among the
most pressing problems that require fixing, this ranks high. Perhaps this can be
achieved if machines are taught the importance of equality throughout their training.
4.13.6 Security
A greater degree of responsibility is invariably associated with a greater degree of
intelligence and power. The necessity for security measures will grow in tandem with
the development of artificial intelligence (AI), since this technology has the potential
to be utilised for both positive and negative ends. In addition to autonomous weapons
and robots built for combat, this also applies to AI systems that, if misused or operated
by untrained people, might do huge damage.
There have been many casualties due to the brutality and brutality of the events that
have taken place during the conflict. Conflicts will not only occur on battlefields in this
and future centuries, thanks to the new digital war platform that has emerged as a
consequence of information digitalization. There has never been a time when cyber
security was more important than now due to the increased risk of sensitive information
and personal data breaches.
4.13.7 Evil Geniuses
The threats we face now are more complex than in the past. Is there anything we can
do to protect ourselves against AI in case it decides to become wicked overnight? In
our minds, when we hear the word "evil," we don't picture computers that have
voluntarily turned wicked; rather, we picture machines that have done terrible things in
ways nobody could have foreseen.
But it's quite unlikely that machines will ever do something bad. Untrained individuals
will be unpredictable and perhaps dangerous because they refuse to learn to understand
the full context of some situations. Think about what would happen if computers were
programmed to find a cure for cancer, but in the process, they ended up killing every
115 | P a g e
single human on Earth. That the machines have achieved their goal is obvious, but it
was not how humans had envisioned.
4.13.8 Singularity
Is there anything we can do to ensure that we will be able to keep this highly advanced
technology within our control? Humans do not occupy the highest rung of the food
chain due to our superior strength or the sharpness of our incisors and claws compared
to other animals. This is why our species is unparalleled in intelligence compared to all
others. We are the most intelligent species because of our large brains and creative
abilities. The fact that we have created means to subdue and govern them makes us
appear to be larger and more powerful beings.
This has caused us to get really angry. This occurrence raises concerns about AI and
the possibility that robots could one day be able to replicate human cognitive abilities.
Will we, too, reap the benefits of technological advancements in the future? We won't
be able to turn machines and AI off just by turning the power off when they reach the
stage where they can operate well and satisfy themselves. Reason being, they will
probably think of this coming and make plans to defend themselves. This is what the
World Economic Forum calls the "Singularity Problem," a catchall phrase for the
inevitable day when human intelligence is surpassed by all other forms of life on Earth.
4.13.9 Robot Rights
How can we categorise the exchanges that occur between humans and AI? The debate
over whether or not machines should have legal protections is mostly an intellectual
one. It is safe to presume that they lack emotion since, in most instances, they are only
computer codes. It would be reasonable to assume this. Considering the provided
output is negative, may we really say that a system is suffering? Currently, these
systems are not complicated at all. However, when we have created fully autonomous
beings with senses, emotions, and the ability to act, it will not be inappropriate to
discuss their legal status, regardless of how simple they are now.
For example, you can yell at Alexa or Siri without ever hurting their feelings or giving
them mental anguish. One of the greatest ethical dilemmas that may arise is coming up
with ways to alleviate suffering while still accepting a certain level of danger. The fact
that AI is improving in intelligence makes it quite clear that we would like AI to support
116 | P a g e
us and that we would like to establish a positive, respectful relationship with it.
Consequently, it's possible that codifying humane behaviour of robots is a crucial
component in that. We must proceed with prudence because, ultimately, we would want
them to be our friends rather than our enemies.
DEVELOPING
ARTIFICIAL
INTELLIGENCE
We should also consider whether we should build AI, even though our current focus is
on our ability to do so. It would be the right thing to do for researchers in the field of
artificial intelligence to shift their attention if it turns out that the technology's effects
would be more negative than positive. Many new technologies have introduced
undesirable side effects that were not anticipated. The Chernobyl accident and the
possibility of a global calamity were both caused by nuclear fission. We owe the
pollution of the air, the acceleration of global warming, and the demise of paradise to
internal combustion engines. You might say that automobiles are like robots; they've
conquered the globe and become indispensable.
Ethical questions about proper workplace conduct, the completion or non-completion
of projects, and the administration of such endeavours affect all professionals in the
scientific and technical disciplines. Berners and Brunstein’s 2001 handbook on
computer ethics is a good resource to peruse. AI, however, seems to bring a slew of
additional difficulties that extend well beyond the problem of building bridges that
don't fall down. Here are some of the difficulties:
• There are two potential outcomes of automation: first, people may lose their
employment.
• Second, people could have too much free time on their hands.
• People could start to feel like they don't belong.
• AI systems have the potential to be utilised for undesirable ends.
• A lack of accountability may result from the introduction of AI technologies.
Also, AI may end up
• Wiping humans off the face of the earth if it were to become widely used.
• We will analyse each issue separately.
People might lose their jobs to automation: In today's industrial economy, computers
and in particular some AI software are becoming more and more important. The
117 | P a g e
availability of consumer credit options, for instance, is crucial to a large segment of the
economy, especially in the US. Credit card applications, charge approvals, and fraud
detection are now handled by AI programmes. Some may claim that thousands of jobs
have been lost due to AI programmes, but in fact, those employment would be
eliminated if AI projects were to be removed. The addition of human work would cause
the transaction costs to skyrocket, which is obviously unacceptable. Thus far,
automation brought about by IT and AI in particular has created more jobs than it has
eliminated, and those jobs are better paid and more interesting. Jobs are less of a
concern given because the standard AI software is a "intelligent agent" designed to help
humans. This is different from the past, when artificial intelligence focused on "expert
systems" that attempted to supplant humans.
To counter this, there are academics who think AI should aim to undertake the entire
task. He proposed creating AI on par with humans, with the ability to pass the
employment test instead of the Turing test, in a reflection on the AAAI's 25th
anniversary. This hypothetical robot has the potential to acquire the skills necessary to
carry out a wide range of tasks. In a dystopian future where many people are out of
work, it's plausible that the unemployed would manage their own team of robotic
Laborers. There could be too much (or too little) free time for people. As per "Since
the turn of the century, the work week has been reduced by fifty percent." Some have
even speculated that it would be halved again by the turn of the millennium. The people
of 2001 could be "faced with a future of utter boredom," as stated in an article.
If this were to happen, picking a TV station from among hundreds would be the biggest
obstacle someone could face. With the exception of the amount of television channels,
none of these predictions have proven to be true. Working people in knowledgeintensive industries have instead found that they are part of a computerised system that
runs around the clock; hence, they have had to work more hours to stay up with the
system's demands. In a typical industrial economy, putting in 10% more hours would
normally lead to a 10% increase in income. Put simply, the time invested usually
directly correlates to the advantages.
In the "Winner-Take-All Society" (an information economy defined by high-bandwidth
transmission and cheap copying of intellectual property), being somewhat better than
the competitors can lead to a substantial payoff. If one were to labour 10% extra, their
income would rise by 100%. As a result, everyone is feeling the heat to put in more
effort. This broader tendency is furthered by artificial intelligence, which increases the
118 | P a g e
pace of technical progress. On the other side, AI holds the potential to free us from our
daily tasks and let our automated agents to take charge for a little. According to Tim
Ferriss , one way to achieve a four-hour work week is via utilising automation
and outsourcing.
People may begin to feel less special. In his book Computer Power and Human Reason,
the creator of the ELIZA software, examines the potential risks that artificial
intelligence (AI) might pose to many parts of society. According to Weinbaum, one of
the main arguments is that we risk losing our autonomy and humanity if we begin to
view humans as automata, a concept made possible by AI advancements. The idea has
been around from at least L'Homme Machine, which is a lot longer ago than artificial
intelligence today. We humans have triumphed against other obstacles to our
uniqueness, such as the fact that De Revolutionists Erbium Celestial moved Earth from
its solar system centre and Descent of Man lowered Homo sapiens to the level of other
animals. If AI becomes widely used, it might challenge our moral ideas in the same
way that Darwin's theory of evolution challenged nineteenth-century views on natural
selection.
It is possible to misuse AI systems. People in charge have frequently utilised state-ofthe-art technologies to defeat their rivals. According to Hardy, a number theorist, "a
science is said to be useful if its development tends to accentuate the existing
inequalities in the distribution of wealth, or more directly promotes the destruction of
human life." This claim is grounded in the reality that scientific progress often leads to
this or that outcome. Artificial intelligence is no different; this is true across all
scientific disciplines. At this very moment, autonomous AI systems are spreading like
wildfire over the battlefield. U.S. military deployments in Iraq include over 12,000
autonomous ground vehicles and 5,000 autonomous aircraft . A moral
theory has been taken to its logical conclusion, claiming that military robots are
analogous to mediaeval armor.
Based on this logic, there should be no moral objections to a soldier choose to wear a
helmet while facing massive, angry, axe-wielding enemies, as a teleoperated robot is
essentially a very safe form of protection. However, there are a plethora of additional
risks posed by robotic weaponry. There is a risk that robots may make decisions that
lead to the killing of innocent people if human decision-making is eliminated from the
firing loop. An overinflated sense of self-confidence might cause a nation to participate
in battles with more recklessness than necessary if it has powerful robots, such as tough
119 | P a g e
helmets. The dispute might have been resolved differently if one of the combatants
hadn't had an exaggerated belief in their own military might.
The potential for broad eavesdropping enabled by speech recognition technology was
also raised, which might lead to the erosion of people's civil liberties. He correctly
recognised that AI may produce vast surveillance, but he failed to foresee a future when
terrorist threats would upset the balance of the amount of monitoring that people are
willing to endure. The United Kingdom already has an extensive system of surveillance
cameras, and other countries routinely track internet and phone traffic, so some of his
predictions have come true.
Some have admitted that privacy is being lost due to the use of computers. For instance,
Sun Microsystems CEO Scott McNealy has reportedly stated, "You have zero privacy
anyway." So, just forget about it. maintains that everyone will inevitably lose some
privacy and that universal surveillance is the only way to balance the power imbalance
between the state and its citizens. underlines the need of finding a middle ground
between personal freedoms and the needs of one's community, solitude and safety.
The potential for accountability to be compromised by AI systems is a real concern. In
the United States, where litigation is commonplace, questions of legal responsibility
take on paramount importance. Who pays the price if a doctor’s diagnosis is wrong
because it was based on an inaccurate opinion from a medical expert system?
Fortunately, the concept that a doctor cannot be sued for carelessness in performing
medical procedures with high expected benefit has been widely accepted, even if the
patient has a terrible consequence. This is mainly because decision-theoretic techniques
are becoming more influential in the medical industry.
In light of this, the question that must be addressed is, "Who is responsible if the
patient's diagnosis is irrational?" Up to this point, the courts have established that
medical expert systems perform the same function as academic medical reference
materials. As a result, clinicians should exercise their best judgement in deciding
whether to follow the system's suggestions or not, and they should understand the
reasoning behind any conclusion. Building medical expert systems as agents
necessitates shifting focus from the patient to the physician's conduct rather of the other
way around. In the event that expert systems routinely outperform human
diagnosticians, medical personnel might face legal consequences if they disregard the
recommendations of these systems.
120 | P a g e
Similar problems are beginning to emerge on the Internet as a result of intelligent
agents' usage. inform that efforts to constrain intelligent beings have had some results.
These limitations make sure the agents can't do things like damage other people's files.
Things take a dramatic turn when funds are moved from one account to another. Can
an intelligent agent be held liable for a person's obligations if the person has let the
agent conduct financial transactions "on their behalf"? Is it feasible for an intelligent
agent to handle its own electronic transactions and hold its own assets? It seems that
these questions have not been fully understood thus far.
Given the existing state of affairs, it seems illogical to provide any programme the legal
standing of a person so that it may engage in financial transactions. Furthermore,
programmes are not considered "drivers" in the traditional sense when it comes to
enforcing traffic regulations on real highways. It would appear that there are no legal
consequences that would prevent an autonomous vehicle from going over the speed
limit, at least in California. But if an accident were to occur, the person responsible
would be the one who designed the vehicle's control system. Just as the law has lagged
behind reproductive technology, it has failed to keep pace with new developments in
technology.
We may all perish if AI manages to achieve its full potential. Most technologies, when
misused, might do harm; but a new threat has emerged with the advent of machine
learning and artificial intelligence: the technology itself could cause harm if it falls into
the wrong hands. Apocalyptic robots or robot-human cyborgs have been the subject of
several science fiction tales. Historical examples include Mary Shelley's Frankenstein
and the play that followed, in which the world was overrun by robots. Such films like
The Terminator and others like it merge the clichés of machines taking over the
world with time travel and brain-in-a-vat elements.
Because they represent the unknown, robots appear to be the heroes of many myths
about taking over the world. This is reminiscent of the Martians in Orson Scott Card's
The War of the Worlds or the witches and specters in classic tales. The question at hand
is whether AI systems pose a bigger danger than regular software. We will look into
three distinct possible threats.
The first is that the AI system could behave inappropriately because its assessment of
its current state is erroneous. For example, if a self-driving car were to mistakenly
believe that another vehicle was in the adjacent lane, it may cause an accident that could
121 | P a g e
kill everyone in the car. More terrifying is the idea that a missile defense system may
falsely detect an assault and launch a counterattack, killing billions of people. Neither
of these problems is intrinsic to AI systems; in fact, a human being might just as easily
make the same mistake as an AI unit. Constructing a system with checks and balances
is essential for efficiently limiting these hazards. This checks that the system as a whole
is not affected by a single incorrect state estimate.
To continue, defining the optimal utility function for an AI system to maximise is far
from an easy subject. Consider a utility function that aims to alleviate human suffering;
it would be expressed as an additive reward function over time, just like the one we've
been discussing. However, because we humans are inherently cruel, we would find a
method to endure agony even in an ideal world; thus, the AI system would be wise to
eradicate humanity as soon as possible, guaranteeing that there would be no humans
and, by extension, no pain. People may easily grasp that the proposed utility function
cannot be taken literally, but AI systems require us to be very careful with our requests.
But the irrational habits we've been talking about don't always have to hurt computers.
People sometimes utilise their brains in an aggressive manner because, as a product of
evolution, we all have certain aggressive tendencies.
And that's only because these characteristics are so common in the human race. Our
built machines don't have to be inherently hostile unless we explicitly specify that we
want them to be (or whether their design encourages aggressive tendencies). Luckily,
we can use techniques like apprenticeship learning to build an example and define a
utility function that way. You would think that a robot with the brainpower to figure
out how to exterminate all humans would also be smart enough to know that this wasn't
its original, utilitarian purpose. Thirdly, the AI system's learning function has the
potential to shape it into a system that displays unintended conduct.
Since this is the most perilous situation and it concerns AI systems in particular, we
will go into it more. According on what I. J. Good said in 1965, math professor and
science fiction writer Vernor Vinge has also called the "intelligence explosion" the
technological singularity. The end of the human era will be announced "within thirty
years, we will have the technological means to create superhuman intelligence with the
help of technology." Vinge made this prediction in 1993. Countless people, including
Good and Vinge, have correctly noted that, when taking Moore's Law into account, the
curve of technological progress is now growing exponentially, among other measures.
However, it may be seen as a leap of faith to assume that the curve will eventually reach
122 | P a g e
a point of practically infinite development. At this juncture, the exponential growth of
technology starts to level out, and all preceding technologies have followed a curving
S-shaped trajectory. On sometimes we hit our limits, and other times we hit a point
where we can't go any more. Predicting events hundreds of years from now is
challenging since the history of high technology spans just over a century.
It must be emphasised that the concept of ultra intelligent robots’ rests on the premise
that intellect is a very important attribute, and that an excess of it may resolve any
problem. Still, we're cognizant of the fact that the calculations' computability and
complexity are limited. Also, if there are no heuristic shortcuts and the challenge of
defining ultra intelligent machines (or even approximations to them) falls into the
category of NEXPTIME-complete problems, then exponential technological
advancement will not assist. Computing power is severely limited by the speed of light;
issues beyond this limit will remain unsolved. Where exactly those upper bounds are
remaining a mystery to this day.
While Vinge is worried about the approaching singularity, some computer scientists
and futurists are enthusiastic about it. Our "mind children," or the robots we create,
may surpass human intelligence in the future, so it's wise to provide them all the tools
they need. The social movement that is eagerly looking forward to a future when
breakthroughs in robots and information technology either integrate or replace humans
has a new name: transhumanism. Protecting human life and our species is something
most moral theorists see as a good thing, therefore it's fair to say that these kinds of
worries give them trouble. The most well-known proponent of the singularity concept,
Ray Kurzweil, wrote the following in his 2005 book "The Singularity is Near":
Because of the Singularity, we will be able to transcend these limitations that our
physical and mental selves impose on us. More and more, we shall be able to shape our
own fates. It is up to us to decide whether or not we live or die. The claim that we will
live eternally differs slightly from the claim that we will have the freedom to live for
an unlimited amount of time. Once we fully comprehend the nature of human cognition,
we will also be able to greatly enhance and broaden its application. At the end of this
century, our intellect's nonbiological component will be billions of trillions of times
stronger than humans' intelligence in the absence of intervention. Kurzweil
acknowledges the potential dangers in his work as well, saying, "But the Singularity
will also amplify the ability to act on our destructive inclinations, so its full story has
not yet been written."
123 | P a g e
It would be in our best interest as humans to make sure that the machines that come
before ultra intelligent ones are built to treat us with respect if it's possible to construct
such robots. The following are the three laws of robotics proposed by science fiction
writer Isaac Asimov in 1942 as an initial response to this issue:
1. No robot may ever intentionally hurt a human being or allow another human
being to suffer damage because it does nothing.
2. Robots must obey human commands unless doing so would violate the First
3. Assuming it doesn't break the First or Second Law in doing so, a robot must
take reasonable precautions to protect itself from harm.
These regulations appear reasonable from our human perspective.6. Figuring out how
to implement these guidelines is the real issue. In the short story "Roundabout" by Isaac
Asimov, a robot is dispatched to retrieve selenium. Then it appears as though the robot
is circling the selenium source. The third rule dictates that it must always turn away
from the source if it feels a hazard as it approaches it. Still, every time it ducks its head,
the danger fades, and the second rule takes over, making it veer back towards the
selenium so it may keep on its path. The set of points that characterise the midpoint
between the two laws is what makes up the circle.
This suggests that the laws are not hard and fast rules of logic but are instead considered
relative, with the older laws carrying more weight than their more recent counterparts.
A control-theory-based design, maybe including a linear combination of parameters,
was probably what Asimov had in mind. Today, nevertheless, a probabilistic reasoning
agent that maximizes utility according to the three laws of probability would be the
most probable design. Such an agent would reason over distributions of outcomes'
probabilities. Given the potential dangers that may arise, it is understandable that we
would prefer that our robots not physically block a person from crossing the street.
Consequently, harming a human person must have a far greater negative value than
disobedience, albeit it should be remembered that both utilities have limits and cannot
be limitless.
124 | P a g e
AI IN MANUFACTURING AND AUTOMATION
5.1 INTRODUCTION
The invention of artificial intelligence (AI), which is often referred to as computerised
intelligence, is frequently considered to be one of the most important advancements in
the history of contemporary humanity. Since the beginning of time, the actions of
people have been the single most essential force in influencing the way our global
biosphere is structured. The pace of development has increased to a frantic speed,
rapidly increasing, ever since the invention of the steam engine and the following
commencement of the first industrial revolution, which occurred 250 years ago. Now,
we are on the verge of a new revolution, which will be driven by the transformative
potential of new technologies that are now being created. This revolution will
revolutionize the way we live our lives.
The way in which we live our lives will undergo substantial transformations in the nottoo-distant future as a result of developments in technology such as artificial
intelligence, genetic engineering, virtual reality, robotics, and 3D printing. These
technologies are not only far more powerful than any technology that has gone before
them, but they are also developing at a much faster pace. Our living conditions have
significantly improved over the last few hundred years as a direct result of the
substantial contributions that technology and invention have made over the course of
this time period.
Although it is indisputable that technological advancement and innovation will play a
significant part in the process of moving towards a more sustainable future, it is also
inescapable that technology will be one of the key contributors to many of the
difficulties that we are now confronted with. Turing was already aware of the
possibilities of machine or artificial intelligence by the middle of the 1940s, and he was
conducting discussions about these possibilities. Temari , a technology
enthusiast and an AI researcher, examines the prospects given by AI. He is sure that
we can expand the wealth of the world via automation without leaving people without
money or purpose. Temari’s article may be found here.
125 | P a g e
As far as Temari is concerned, there is no reason for mankind to be concerned about
participating in an arms race when artificial intelligence is employed in this way. Rather
than worrying about the possibility of existential threats that are unlikely to materialise,
it is more crucial to concentrate on the ways in which artificial intelligence will enhance
the quality of human life. Intelligent machines may fail in ways that are unique from
the error patterns of people, ways that we do not foresee or are prepared for, and ways
that need humans to cling even more strongly to their values and ethics. These are all
examples of ways in which intelligent robots risk failing.
A significant worry that arises in the context of an examination of the impact of
technology is the connection that exists between artificial intelligence (AI) and
sustainability, as well as the concept of sustainable development. As a part of our study,
which is related to and bound by reports that already exist, we give an overview of the
key future changes that will be induced by the use of artificial intelligence in the
industrial sector (and more widely in the social sense). These changes will be generated
when artificial intelligence is used in the industrial sector. In addition to this, we discuss
the most significant elements, opportunities, and risks that are associated with the
prospective changes that are brought about by developing technologies.
5.2 INDUSTRIAL SECTOR, MANUFACTURING
Approximately fifty percent of the world's energy consumption and one third of the
world's gross domestic product (GDP) may be attributed to the industrial sector. It is a
large consumer of freshwater and other natural resources, in addition to being a big
contributor to the development of trash and pollution. In addition, it is a significant
contributor to the generation of garbage. Increasing the efficiency of industrial
processes is crucial to maintaining a sustainable future for the planet, as stated by
Zervamicin . This is due to the substantial effect that these activities have on the
environment that surrounds them. For those who are in the business of producing
goods, the potential for profit is great.
Nevertheless, in order to make this a reality, we will need to make use of newly
developing information technologies such as social networking, mobile computing,
data analytics, and cloud computing, in conjunction with newly developing operational
technologies such as sensors, machine-to-machine communication, additive
manufacturing, and robots. The development of brand-new technologies that make use
of renewable energy sources as well as a variety of other "green" manufacturing tactics
126 | P a g e
has received a substantial share of the attention that has been paid to this topic. The
idea that things might be implemented in such a short period of time anyplace in the
world is just implausible and cannot even be considered a possibility. In particular,
when you take into consideration the fact that the heavy industries, which are
accountable for the biggest amount of waste and resource consumption, are a part of an
industry that has a poor profit margin and is struggling to maintain its competitiveness.
On the other side, businesses are focusing their efforts on ensuring that they continue
to exist rather than making investments in a future that is more environmentally
Fig.5.1. AI solutions are revolutionizing manufacturing .
Source: Artificial Intelligence in Manufacturing Companies and Broader: Buch
meister, B 
The enterprise resource planning (ERP) system of a corporation will be intrinsically
linked to the growth of a manufacturer's business in an environment that is
characterised by Industry 4.0. Enterprise resource planning (ERP) and manufacturing
execution systems (MES) need to come together to form a unified whole in order for
businesses to be able to take advantage of the expansion opportunities that are presented
by the new age of intelligent manufacturing (Fig. 1). Without a doubt, the lines that
divide production from management need to be eliminated immediately. These three
components—intelligent goods, intelligent manufacturing processes, and intelligent
services—are included in the concept of intelligent manufacturing (Figure 1).
5.3 TRANSFORMING MANUFACTURING WITH AI
For the purpose of enhancing safety, building simulation datasets, examining how a
component might be manufactured or machined more quickly, and bringing their goods
to market more quickly, engineers may utilise generative artificial intelligence to study
127 | P a g e
large data sets. Not only does generative AI provide a vast range of design options, but
this feature is also available. These data sets have the potential to become the source
information, also known as FMs, upon which a generative artificial intelligence
strategy for a manufacturer may be developed. During this time, the data may continue
to be protected from unauthorised access and kept secret, and the organisation may
continue to reap the benefits of these technological advancements.
The Amazon Web Services (AWS) company launched a brand-new managed service
known as Amazon Bedrock in April of 2023. Through the use of an application
programming interface, it is intended to make FMs from such companies as AI21 Labs,
Anthropic, Stability AI, and Amazon accessible to everyone. Through the use of FMs,
Amazon Bedrock is intended to make it as easy as possible for customers to develop
and evolve applications that are built on generative artificial intelligence. This will
result in access being made more accessible to all builders. One of the most helpful
aspects that Amazon Bedrock provides is the simplicity with which a model may be
customised. This is one of the available options.
The only thing that customers need to do is point Bedrock to the labelled examples that
are stored in Amazon Simple Storage Service (S3). This will allow the service to finetune the model for a particular task without the need to annotate a large quantity of data
(as little as twenty examples are adequate). Just for a moment, put yourself in the
position of managing content marketing for a trendy clothing store. Your job is to come
up with fresh, targeted advertising content and campaign language for a new line of
handbags that is going to be released in the near future. They provide Bedrock with a
few tagged examples of the taglines that have worked the best for them in prior
campaigns, along with the product descriptions that go along with those taglines. This
is done in order to accomplish the aforementioned goal.
In order to train this private copy of the model, Bedrock will first generate a separate
copy of the client's base basic model. The client is the only one who will have access
to this copy. Following the conclusion of the training, Bedrock will immediately begin
the process of automatically producing interesting material for the new handbags; this
includes content for social media platforms, display advertisements, and the website.
There is not a single instance in which the data of the client is used in the process of
training the first base models. Additionally, customers have the option to encrypt their
data and configure their Amazon Virtual Private Cloud (Amazon VPC) settings in order
to have access to Bedrock APIs and provide data for model fine-tuning in a secure
128 | P a g e
manner. The data that pertains to clients is always protected, both while it is in transit
(using TLS1.2) and while it is being stored, using keys that are held by the service
A great number of manufacturers are hesitant to embrace and use new technologies in
production settings since there is such a significant danger of output loss and the
expenditures that are associated with it. Despite the fact that it is still early days for use
cases of generative artificial intelligence in industrial production, executives from
factories have already begun talking to us about how generative AI may help optimise
overall equipment effectiveness (OEE). Before manufacturers can begin their journey
with generative AI, they must first overcome the particular industrial hurdle of getting
access to their manufacturing data and placing it into the cloud. This is due to the fact
that generative AI depends on enormous amounts of data in order to develop functional
models (FMs).
The implementation of an industrial data strategy has to be the first step for a wide
variety of various kinds of businesses. It is vital to have an industrial data strategy in
place in order to enable business teams to easily and efficiently harness that data in
order to handle a variety of use cases inside an organisation. This is why it is essential
to have such a strategy in place. Data serves as the foundation for every single activity
that is conducted in the realm of digital transformation. How come? When it comes to
FMs, the difficulty of acquiring economical, secure, organised, and rapid access to
high-quality information is made more difficult by the fact that manufacturers often
deal with data sources that are walled and disconnected, and that were not intended to
work together. The solutions that Amazon Web Services (AWS) provides for Industrial
Data Fabric are able to resolve a considerable number of these challenges.
Artificial intelligence (AI) and machine learning (ML) have been utilised by
organisations such as Georgia Pacific (GP) for a considerable amount of time in order
to enhance the quality of paper manufacture, for instance. By employing the data
analysis technology offered by Amazon Web Services (AWS), GP was able to
maximise their plant resources and boost their profits. This was accomplished by
determining the best pace at which their conversion lines should work in order to reduce
the quantity of paper that was ripped throughout the manufacturing process. To what
extent, however, may generative artificial intelligence be of use to businesses in terms
of production?
129 | P a g e
The truth that attrition continues to erode the knowledge and experience that is present
on their factory floors is one of the concerns that comes up again and again when I have
meetings with individuals who are in charge of business and production. This is one of
the topics that I bring up in several occasions. The workforce is losing workers with
decades of experience, and these workers are often taking their decades' worth of
knowledge with them when they go. These are the sorts of persons who are able to
determine, via the use of either sound or touch, if a machine bearing need lubrication
or whether it is vibrating excessively and whether it is not functioning appropriately.
The problem that needs to be solved is figuring out how to provide less experienced
operators with the information that is necessary to keep intricate production processes
operating properly.
Additionally, the problem needs to be solved by figuring out how to maximise
productivity while simultaneously improving quality and the availability of machines.
In the event that manufacturers are willing to digitised and record historical data on
machine maintenance, repair data, equipment manuals, production data, and maybe
even data from other manufacturers in order to improve an efficient FM in order to
bring about true change, then this could be a real option. For example, a piece of
equipment that is prone to malfunctioning and causing unplanned downtime is an
example of something that may be considered. What would happen if production
engineers had the capacity to utilise generative artificial intelligence to investigate the
most probable causes of failure and acquire high-probability suggestions on how to
modify the inputs of equipment, carry out the required maintenance, or even purchase
new components in order to reduce downtime? When it comes to production scenarios,
generative artificial intelligence has a significant amount of promise to maximise
overall equipment effectiveness (OEE) in the absence of expert engineers and
operators.
5.4 OPTIMIZE SUPPLY CHAINS WITH GENERATIVE AI
Amazon Web Services (AWS) offers a wide variety of services that may be used to
fulfil a variety of supply chain use cases. AWS Supply Chain is an application that
provides assistance to businesses in expanding the visibility of their supply chains. This
enables the businesses to make decisions that are more quickly informed, which
ultimately results in a reduction in risks, along with a reduction in costs and an
improvement in customer experiences. The ability of Amazon Web Services Supply
Chain to automatically gather and analyse data from a wide variety of supply chain
130 | P a g e
systems allows businesses to monitor their operations in real time, find trends more
quickly, and generate demand estimates that are more accurate. This enables companies
to ensure that they have sufficient inventory to meet the requirements of their clients
and so satisfy their obligations. A number of features, including a single data lake,
insights driven by machine learning, recommended actions, and in-application
collaboration capabilities, are one of the ways that Amazon Web Services Supply Chain
contributes to the enhancement of supply chain resilience. Amazon.com has acquired
almost thirty years of expertise in the management of its logistics network, which has
enabled the company to develop these skills.
The supply networks of manufacturers continue to be a cause of stress, if not outright
fear, as a consequence of the unpredictability that has been brought into supply chains
as a result of the pandemic, regional conflicts, raw material shortages, and even natural
disasters. Other factors that have contributed to this unpredictability include natural
disasters. The function of sourcing is a fertile ground for the use of generative artificial
intelligence, which has the potential to bring about value. Imagine for a moment that a
manufacturer has exhausted their existing supply of custom machined components and
is now looking for other suppliers that can do some custom machining work. This is
because the firm has run out of custom machined components.
It is possible that alternative providers may be equipped with the abilities necessary to
effectively do the particular work that is required via the use of generative artificial
intelligence. The use of generative artificial intelligence in circumstances where it is
possible to substitute typical human interactions is yet another potential use of this
technology. This would make it possible to provide answers to questions that, in the
past, would have needed a significant amount of time—typically hours or even days—
to get the relevant data and then to make sense of it. Generative artificial intelligence
has the ability to serve as a control tower for the supply chain. This might be
accomplished by proactively analysing risks related with shipping concerns, natural
disasters, strikes, and other forms of geopolitical events. This would make it feasible
for the function of the supply chain to properly allocate limited resources in order to
lessen the risk of disruptions occurring.
5.5 PREDICTIVE MAINTENANCE AND QUALITY CONTROL
In today's modern manufacturing processes, both quality control and predictive
maintenance are essential components that carry out their respective functions. It is the
131 | P a g e
purpose of these components to enhance the overall dependability of the product and
the process, as well as to maximise efficiency and reduce unnecessary expenditures.
For the sake of this discussion, let's consider each of them in turn:
Indicators of Predictive Action: Using data analysis, machine learning, and advanced
sensors, predictive maintenance is a proactive maintenance strategy that forecasts when
equipment or machinery is likely to break down. This method is also known as
preventative maintenance. Predictive maintenance is sometimes referred to as
condition-based maintenance in certain circles. Instead of depending on fixed timebased maintenance schedules or waiting for the equipment to break down suddenly,
this system analyses the status of assets in real-time in order to arrange repair activities
precisely when they are necessary. This eliminates the need to wait for the equipment
to break down unexpectedly. Establishing a timetable for maintenance tasks at the exact
moment when they are required is the objective.
5.6 BENEFITS OF PREDICTIVE MAINTENANCE:
Unexpected downtime is reduced as a result of early identification of possible faults,
which enables prompt maintenance and further reduces unexpected downtime.
The reduction of operating expenses may be accomplished by eliminating maintenance
that is not essential and by making the most efficient use of available resources.
Extended Asset Lifespan: Performing routine maintenance on machinery at the
appropriate intervals may help to prolong the asset's operating life.
An increase in safety is achieved by ensuring the dependability of equipment, which
lowers the likelihood of accidents or failures that might cause damage to humans or the
environment.
5.6.1 Quality Control:
An approach that is process-oriented and is known as quality control is used in order to
ensure that a product or service exceeds both the quality standards that have been set
in the past and the expectations of the market that is being targeted. As part of this
process, commodities are monitored and tested at various stages of production in order
to identify defects and deviations from the specifications. This allows corrective actions
to be made prior to the release of the final product.
132 | P a g e
5.6.2 Key components of quality control:
Inspection: During the various stages of manufacturing, there are regular inspections
carried out in order to discover any variances, non-conformities, or faults that may
become apparent.
The methods of statistical process control (SPC) are used in order to monitor and
regulate the quality of production processes. This is done in order to guarantee that the
processes continue to be stable and fall within acceptable bounds.
Quality Assurance (QA): QA is composed of the deployment of systems, processes,
and policies with the purpose of ensuring that goods consistently fulfil certain quality
requirements.
Root Cause Analysis: When problems or flaws emerge, root cause analysis is carried
out in order to determine the causes that lie under the surface and to avoid similar
problems from occurring in the future.
5.6.3 Benefits of quality control:
The key to reaching both delighted consumers and loyal brand supporters is to maintain
a consistent quality standard throughout the whole process.
When issues are discovered at an early stage, it is possible to reduce the quantity of
resources and materials that are wasted.
When the quality of a product is enhanced, there is a reduction in the requirement for
rework, returns, or warranty claims, which ultimately results in cost savings.
An organisation is able to avoid penalties and other legal issues by complying with
regulatory and industry standards. Compliance is the process of fulfilling these
requirements.
The combination of quality control and predictive maintenance has the potential to
provide a remarkable synergy. This is due to the fact that predictive maintenance helps
to ensure that the equipment continues to be reliable, which in turn contributes to the
product's quality being consistent throughout. A competitive advantage in the market
may be achieved by the use of these approaches inside industries, which may lead to
133 | P a g e
greater productivity, less downtime, and the manufacturing of high-quality items. All
of these factors contribute to the overall competitive advantage.
5.6.4 Integration of Predictive Maintenance and Quality Control:
It is possible that the combination of quality control and predictive maintenance might
result in an approach to overall industrial operations that is not only more
comprehensive but also more effective. If businesses combine these two strategies, they
have the ability to achieve a bigger number of additional benefits than they would
otherwise.
As a result of an enhancement in product quality: The use of predictive maintenance
allows for the identification and resolution of issues with machinery that may have an
effect on the quality of the product. It is feasible to greatly reduce the amount of things
that have flaws simply by ensuring that all of the equipment is in good operating
condition. This approach may be used to achieve this goal.
Continuous Quality Assurance in Real Time: There is a possibility that the data
collected during the operations of predictive maintenance will also provide valuable
insights into the quality of the things that are actually being manufactured. It is possible
to conduct an analysis of these data in combination with the data obtained from the
production process in order to discover links between the state of the equipment and
the quality of the result.
As a result of the predictive nature of maintenance, any issues that might have an effect
on product quality can be anticipated and resolved before they can result in substantial
deviations from specifications or serious faults. This is an example of proactive quality
management.
Resource Optimisation: When businesses are able to correctly predict their
maintenance needs, they are in a better position to optimise the allocation of resources
like spare parts, manpower, and maintenance staff, which ultimately results in cost
The feedback loop that is generated as a consequence of the combination of quality
control and predictive maintenance helps to nurture an atmosphere that is devoted to
continuous improvement. This in turn serves to ensure that the environment is
conducive to continuous improvement. Using insights that are gained from data on
134 | P a g e
maintenance and quality, it is possible to achieve a number of goals, including the
optimisation of processes, the removal of root causes of problems, and an overall
increase in efficiency. Enhancement of Safety Creating a safer environment for workers
to do their tasks is a goal that may be accomplished via the use of both predictive
maintenance and quality control. The potential of accidents or malfunctions that might
put people or property in danger is considerably enhanced when equipment is not
properly maintained. This situation could put people or property in danger.
Utilising Predictive Analytics for Quality Control: Many of the same methods that
are commonly used for maintenance may also be utilised for quality control if
predictive analytics are utilised. It is possible for algorithms that learn from machine
data to identify patterns in quality data, to generate accurate predictions about product
problems, and to give suggestions for improving product quality.
Data-Driven Decision Making: Integrating data from predictive maintenance and
quality control may make it possible for a business to realise the benefits of data-driven
decision making throughout the whole organisation. It is possible to make decisions
that need to be made about production schedules, maintenance plans, and quality
improvement programmes by using real-time data and insights that can be acted upon.
These decisions may be made based on the information that is available.
It is generally accepted that the combination of quality control and predictive
maintenance leads to the development of an industrial ecosystem that is more
intelligent, efficient, and resilient. It provides assistance to businesses in making the
shift from a reactive and time-based approach to maintenance to a proactive and datadriven strategy, which eventually leads to an improvement in product quality, a
reduction in downtime, and an increase in customer satisfaction. With the continued
advancement of technology, it is predicted that the synergy between these two
approaches will play a crucial part in defining the future of manufacturing as well as
other industries. This is the case to the degree that technological progress continues to
THE ROLE OF THE INTERNET OF THINGS (IOT) AND INDUSTRY
4.0 IN QMS AND PREDICTIVE MAINTENANCE:
Both predictive maintenance and quality control have been brought to a new level of
efficiency and effectiveness as a consequence of the integration of technologies from
135 | P a g e
Industry 4.0 and the Internet of Things. This has resulted in a revolution in both of these
Sensors and Connectivity for the Internet of Things: Devices and sensors that are
connected to the Internet of Things are currently being integrated into a wide range of
industrial processes and pieces of machinery. These integrated Internet of Things
devices and sensors are constantly collecting data in real time on factors like as
temperature, pressure, vibration, and other important performance indicators. With the
help of these sensors, remote monitoring and data transmission are made possible,
which eventually leads to a more comprehensive picture of how effectively the
equipment is performing in general.
Predictive Analytics and Machine Learning: The data that is produced by the IoT is
processed through advanced analytics and machine learning algorithms so that patterns,
irregularities, and potential failure causes may be recognised. Due to the fact that
machine learning models acquire knowledge from vast amounts of data over the course
of time, their accuracy increases, which ultimately leads to more accurate predictions
and recommendations for preventive maintenance.
Edge computing capabilities allow for data processing and analysis to take place closer
to the data source (for example, on the equipment itself or at neighboring gateways).
This enables predictive maintenance to take place on the edge. The performance of
predictive maintenance is made possible as a result of this. In circumstances when rapid
action is required to prevent malfunctions in a piece of equipment, this method reduces
the amount of latency that occurs and makes it feasible to make choices in real time.
This is a crucial strategy under certain circumstances.
Data Management via the Use of the Cloud computing makes it feasible to centralize
data storage and provides a scalable and secure environment for the management of
vast amounts of data generated by Internet of Things (IoT) devices. Data management
may be accomplished via the use of cloud computing. On account of the fact that these
data are easily available and can be evaluated from any place, they make it possible to
conduct a monitoring effort that is more thorough and collaborative across a large
number of sites or even globally distant facilities.
Digital Twins: A digital twin is a virtual clone of a real object that is created by
combining data from Internet of Things devices with simulation models. This process
136 | P a g e
is known as creation of a digital twin. By doing so, they make it possible to carry out
continuous monitoring and modelling of the behaviour of the equipment, which, in turn,
makes it possible to have a better understanding of, optimise, and anticipate the
requirements for maintenance.
Augmented Reality (AR) and Virtual Reality (VR): The technologies that are
responsible for AR and VR have been included into the procedures that are used for
quality control and maintenance. This gives personnel the ability to view data and
visualizations in real time while they are doing inspections or maintenance tasks. This
will result in their labour being more precise and efficient, which is a positive outcome.
Automated Quality Control: During the production process, hardware that is
integrated with the Internet of Things is able to do automated inspections and quality
control checks. The use of computer vision and image processing techniques assists in
the detection of defects or deviations from quality standards, which ultimately results
in a quality evaluation that is not only more expedient but also more consistent.
The Management of a Predictive Supply Chain: Predictive maintenance and quality
control are not confined to the factory floor; rather, they extend to the supply chain as
well. Businesses have the ability to proactively address any disruptions and keep a
smooth flow of materials and products if they monitor the state of essential equipment
along the supply chain and document any faults that they detect; this allows them to
maintain a smooth flow of materials and commodities.
The Internet of Things (IoT) and Industry 4.0 technologies have been incorporated into
predictive maintenance and quality management, which has resulted in the creation of
new potential for organisations to achieve levels of productivity, reliability, and quality
that were previously unreachable. In light of the fact that these technologies are still in
the process of being developed, the manufacturing and industrial sectors are in an
excellent position to become even more data-driven, adaptable, and resilient in the face
of opportunities and difficulties.
5.8 SMART SUPPLY CHAIN AND LOGISTICS
At each and every stage of production and distribution, the supply chain is comprised
of a collection of organisations, individuals, processes, information, technologies, and
resources that are involved in the creation of the product value. This includes the
137 | P a g e
sources of raw materials, production, and the end user, all of whom are connected to
the supply chain through the flow of information, physical distribution, and monetary
transactions. Terminological dictionaries are the source of this particular definition of
the supply chain structure. The concept of the supply chain, which was first introduced
by K. Oliver in 1982, has seen substantial changes over the course of the almost four
decades that have progressed since that time.
Fig. 5.2. Supply chain evolution
Source: Logistics of smart supply chains St. Petersburg 
Figure 5.2 illustrates how the current generation of supply chains evolved from the
previous generation of supply chains, which consisted of linear models, uncomplicated
network configurations, and individual desynchronized economic interactions, into
partner networks that are connected, scalable, adaptable, and harmonized.
In the direct supply chain, sometimes referred to as supply chain version 1.0, there is a
focal (central) business, which is often an industrial organisation or a trading company,
a supplier, and a client or consumer. This kind of supply chain is also known as the
supply chain. Under these circumstances, the company that serves as the hub is the one
that makes the decisions about the construction of the chain as well as the management
of the connections between the many business partners. In addition to including secondlevel suppliers and users, the advanced supply chain, which is sometimes referred to as
Supply Chain 2.0, serves as the basis for the development of the SCOR model, which
is a reference model of operations in supply chains.
The Supply Chain Council (SCC) is responsible for the development of this model,
which is today recognised as an international standard. The SCC's primary objective
138 | P a g e
was to analyse, successfully plan, and construct supply networks. The maximum supply
chain, often referred to as Supply chain 3.0, is comprised of a focal corporation and all
of the contractors that come under its umbrella. The providers of raw materials and
natural resources that decide the resources of the focal firm are included in this group
of contractors. Additionally, the distribution network that extends all the way to the end
users, as well as logistical, institutional, and other intermediates, are also provided by
these contractors. The expansion of managerial duties occurred concurrently with the
establishment of genuine supply chains, which was the root cause of this transition
inside the organisation.
In the past, the job of supply chain management (SCM) was just operational logistics,
with the primary focus being on meeting the requirements of production and delivering
items to customers. However, as time has progressed, this position has evolved into a
full-fledged supply chain management concept. Increasing complexity in
contemporary company processes was the primary cause of this development, which
took place as a direct outcome of that complexity. Due to the fact that it is the most
common concept for establishing connections between contractors, the SCM need aid
from scientific methodologies in order to be successful. This provides an explanation
for why there is an increasing amount of work being done in this direction. Throughout
the course of history, the major emphasis of researchers has been placed on finding
answers to challenges such as how to make supply chain management more efficient
and how to make supply chain management more adaptable.
The first plan calls for the reduction of production and operating costs, particularly via
the reduction of inventories and the active use of "just-in-time" supply practices.
Additionally, the plan calls for integrated planning, the reallocation of resources, and
the sharing of duties and risks. In addition to that, this technique requires the
distribution of duties and risks among the participants. The second approach focuses
on establishing an operational reaction to altering conditions of need and demand, as
well as situations of rivalry and cooperation. This reaction is intended to be a response
to operational circumstances. The effectiveness of each of these techniques has been
shown in the sectors of effort in which they have been implemented.
The traditional supply chains of the first and third generations, on the other hand,
continued to be largely a sequence of discrete, independent processes in the marketing,
manufacturing, distribution, and delivery of products. This was the case despite the fact
that there were significant changes in the content, structure, and organisation of the
139 | P a g e
supply chains. The situation remained the same despite the fact that there were
significant shifts in these regions. A procedure that is extremely regimented is an
approach that is used by the overwhelming majority of organisations in order to
guarantee that their clients are delighted. In order to make an effort at forecasting
consumer demand for the subsequent time period, the marketing department begins by
conducting an analysis of client demand. On the basis of these forecasts, the
development of orders for materials and components, as well as the accurate planning
of facilities and production, are both actions that are carried out.
It is the responsibility of distribution to communicate with clients about the estimated
delivery time of products, taking into mind that projections and plans are being taken
into consideration. Users will be able to purchase the products they want at the proper
area and at the suitable time if the events that take place are in accordance with the
plans that have been established; nevertheless, this does not occur as often as we would
like it to. The methods that are used for forecasting continue to be very inaccurate, and
the data that are used to support these methods are often unsuitable, inconsistent, and
lacking in completeness. Despite the fact that there is a lack of suitable coordination
with marketing, the capabilities of suppliers, and other partners, there are times when
manufacturing is successful.
There is a lack of transparency across the chain, which results in situations in which
some chain nodes do not have a comprehensive understanding of what is going in other
chain nodes. This, in turn, leads to actions that are not coordinated with one another.
The ever-increasing demands of consumers, in addition to the changing logic of the
connection between contractors, were the driving forces for the transition of traditional
supply chains into modern networks, which is also referred to as Supply chains 4.0 or
smart supply chains. At the very least, there are two tendencies that are connected with
one another, and both of these developments are likely to be responsible for the
emergence of a new stage in the development of supply chains and their transition to
model 4.0.
There is a wide range of possible customer expectations. When consumers have more
precise and individualised expectations of what they should give, businesses are
motivated to develop supply networks that are customer-oriented, trustworthy, and
transparent. Businesses are also driven to establish supply chains that are transparent.
Moreover, it is possible that the beginnings of these transformations are already visible.
Over thirty percent of respondents have indicated that they have already started the
140 | P a g e
process of network transformation, and in general, more than seventy percent of
respondents want to carry out this transformation during the next five years, as stated
by research that was carried out by the consulting company PwC and was based on a
survey that included more than two thousand respondents. Because of the development
and revolutionary transformation of technologies, these respondents estimate that their
efficiency will grow by 4.1% on an annual basis, and they will also see an increase in
revenue of 2.9% on an annual basis.
Generally speaking, the development of business theory is lagging behind the practice
of business. This is due to the fact that innovative management choices and tools are
pushing the limits of paradigms that have been created in the past. It is necessary to
have a solid understanding of the theory in order to provide an explanation for the
advances that have taken place, which is what defines the significance of this work.
When viewed from a strictly practical perspective, the research of intelligent supply
chains will be of assistance in defining the needed formation tools and suitable
management tactics.
5.9 SMART SUPPLY CHAIN - MAIN CHARACTERISTICS
There is a concept that is only partly defined, and the phrase "smart supply chain" (SSC)
relates to that concept. It is described by some authors as a modern business system
that is networked and grows from applications that are autonomous, local, and confined
to a single firm to implementations that are ubiquitous and systematic in supply chain.
According to the definitions of other writers, it is a supply chain management system.
During the course of the study, characteristics of intelligent supply chains have been
identified more accurately. However, Butner argues in favor of smart supply chains,
which he describes as supply networks that are intelligent, networked, and instrumented
and that are connected to one another. It is instrumented, it is networked, it is intelligent,
it is automated, it is integrated, and it is imaginative.
These are the six characteristics that define a supply chain that is considered to be smart.
In addition, a smart supply chain may be distinguished by the use of the three
characteristics listed below: connection, collaboration, and customisation. An
intelligent Everything in the supply chain is interconnected because of the integration
of all entities, assets, IT systems, and items. "Unprecedented levels of interaction with
customers, suppliers, and information technology systems in general, but also among
objects that are monitoring or even flowing through the supply chain" is another
141 | P a g e
characteristic that distinguishes a smart supply chain from a traditional supply chain.
The use of a multitude of cutting-edge information and communication technologies
(ICT) is the distinguishing feature of a smart supply chain. These technologies are
sometimes referred to as information, communication, and production technologies
(ICP) if the focus is put on the link to the industrial environment. It is possible to
increase the flow of information across different items, information technology
systems, and enterprises by using these technologies. Making use of ICT is of critical
importance since it substantially facilitates the sharing of information and knowledge
at both the organisational and supply-chain levels.
Connectivity enables the collection of data and communication in real time across all
stages of the supply chain, which enables intelligent decision making as well as more
information, better decisions, better procedures, and an even better product would be
the output of a smart supply chain, which aims to improve customer service via efficient
and responsive operations. " . The System Support Centre (SSC) is a hybrid system that
brings together the digital and analogue worlds. This is a phrase that is used to define
the utilisation of cyber-physical systems (CPS) in combination with the utilisation of
smart products and services on a daily basis. "Physical and engineered system, that
operations can be kept an eye on, coordinated, managed, and integrated by a network
of computers and system"; it contains many components such as sensors, actuators,
control processing units, and communication devices.
A system that utilizes cyber-physical technology is "physical and engineered system,
that operations can be monitored, coordinated, controlled, and integrated by a
computing and communication system." When embedded computers and networks are
linked to physical processes, they monitor and manage those processes. This is because
the physical processes have an effect on the computing, and the computation is
influenced by the physical processes. Cyber-physical systems make it possible to
strengthen the control, transparency, and efficiency of the production process.
Additionally, they encourage the connection between machines and human people,
which opens up the option of being flexible and responding to altering needs. Cyberphysical systems are becoming increasingly popular. Internet of Things (IoT), which is
described as "set of physical devices (machines, products, etc.) connected through
network with capacity to share data on one's own environment and physical location,"
is an integral component of Cyber-Physical Systems (CPS). An intelligent supply chain
might be described as automated due to the fact that its process flows are automated
142 | P a g e
and intelligent. This is because it is able to make judgements on a large scale that are
relevant to the viewpoint of the whole supply chain. The ability to learn and make
certain judgements on its own, without the intervention of humans, as well as the ability
to foresee future events, are especially impressive features of this system.
According to K. Butner, in order for contemporary supply chains to effectively manage
risk and achieve their economic objectives, they need to become much more intelligent.
He believes this to be the case. The cornerstone of intelligent supply chain management
is the use of data received from various parts of the supply chain, including production
lines, warehouses, and logistic centres. It is necessary to have Internet of Things
Technology, sensors, indications, and the Internet of Things (IoT) Global Positioning
Systems (GPS) in order to collect, store, and analyse the data in real time. Even data
obtained from social media sites might be subjected to analysis.
The term "big data analytics" refers to the process of analysing enormous amounts of
data in real time using a variable processing method. In the framework of the Internet
of Things (IoT), one of the topics of debate is the enormous potential that is made
available by mobile technology, mobile devices, and the services that are linked with
them. Augmented reality applications, wearables (such as smart watches and glasses),
and autonomous vehicles (drones) are some of the other key technologies that are being
developed for the fourth generation of logistics. Both the transportation and
warehousing industries may benefit tremendously from the use of these technologies.
A "full of sensors, RFID tags, meters, GPSs, and other devices and systems" are the
components that make up the smart supply chain, and "information is being machinegenerated" is another component.
A smart supply chain is built on the basis of intelligent production and value chains
that are integrated together. Customers and partners in the supply chain are able to
communicate with one another and engage with one another as a result of the existence
of information systems. The newly developed solutions are built on a cloud-based
system, which serves as a platform for the sharing and collaboration of resources and
can be accessible regardless of the user's physical location. Communication has a direct
influence on a variety of topics, including the formation of relationships, the resolution
of disputes, the creation of trust, and the mutual understanding of one another.
Furthermore, according to Li and Lin, the distribution of information makes it simpler
to coordinate and integrate activities that are a part of the supply chain. This, in turn,
leads to an improvement in the outcomes that are created by the supply chain as a
143 | P a g e
whole. As a consequence of this, a smart supply chain may be characterised as being
more integrated (on the basis of the integration of processes and the collaboration
among partners in the supply chain), and as a consequence of this, it can be
characterised as being more imaginative, providing new innovative solutions and
meeting new requirements.
Using intelligent supply chain management has as its major goal the fulfilment of the
customised needs of each individual customer and the transportation of personalised
products in the most efficient and cost-effective way that is feasible. When enormous
volumes of data are processed and improvements are made to the management of
production and logistical operations based on the demand that is expressed by
customers, the outcome will be the creation of value via the ongoing introduction of
new goods and services to the market. This will also result in the development of items
that are developed according to the preferences of each and every unique consumer.
The intelligent supply chain, on the other hand, not only makes it possible to
personalise items, but it also makes it possible to differentiate them in large quantities.
"Mass individualization" refers to the process by which consumers are "involved in
designing the options of their product to fit their exact individual needs and desires."
In contrast, mass customisation refers to the process by which a manufacturer provides
clients with a selection of product alternatives that are optional. In this scenario, the
customer has the impression that they are creating the product, but they are merely
picking a few of the available possibilities. The difference between mass customisation
and mass individualization is that consumers are "involved in designing the options of
their product to fit their exact individual needs and desires." Mass individualization
does not entail bulk customisation. For the purpose of providing a concise summary of
what constitutes a smart supply chain, its components include being networked,
automated, intelligent, instrumented, integrated, imaginative, and focused on the
particular needs of individual clients.
5.10 STAGES OF SMART SUPPLY CHAIN DEVELOPMENT
In order to get a comprehensive understanding of the concept of a smart supply chain,
it is essential to first recognise the phases that the chain has gone through in its
development. An intelligent supply chain is a modern linked business system that may
vary from supply chain solutions that are large and methodical to those that are small
and focused on a single organisation. In general, a smart supply chain is characterised
144 | P a g e
as a business system that is connected to other business systems. Within the scope of
this specification, a wide variety of supply chain implementations are included.
As a result, the phases of SSC development that are listed below might be considered
to represent the key stages: the early phase, which involves the local implementation
of some intelligent applications; the intermediate phase, which involves the
implementation of some isolated system, such as an intelligent factory or service; and
the advanced phase, which is characterised by the implementation of smart solutions
that integrate processes throughout the entire supply chain. The implementation of Big
Data, which includes Internet of Things (IoT) infrastructure, an adequate information
system, sophisticated analytics, data mining, BI, process automation, and optimisation,
supply chain collaboration, supply chain integration, and product and process
innovations are the fundamental elements that are necessary for the development of a
smart supply chain.
The use of contemporary technology, the exchange of information, and genuine
cooperation amongst different organisations are the foundations of a smart supply
chain. When it comes to facilitating cooperation among players in a supply chain, trust
is a vital component that is often overlooked. It has an impact on the efficiency of
supply chains and leads to an improvement in communication across the supply chain.
When it comes to the supply chain, not only should there be a high level of trust
between the various players, but there should also be a high level of trust between the
information systems and the information technologies. There is a new issue that has to
be taken into consideration in SSC, and that is trust in technical systems. It is essential
because human-to-human connections are gradually being replaced by human-totechnology connections, which is why it is vital. There will be a rise in the degree to
which supply chains are integrated, and the scope of the data that is used for sharing
will extend even more.
In the year 2025, it is anticipated that the value of the Internet of Things market
throughout the whole world would reach between 4 and 11 trillion Americans dollars.
The McKinsey Global Institute has released its report for the year 2015. Building,
implementing, and enhancing a smart supply chain is neither a straightforward or
speedy process. It is neither easy nor fast. Putting in a lot of time and work is required.
It is necessary to take a comprehensive strategy that is aimed at determining the
resources of the chain in terms of their interoperability, and followed by the
development of intelligent applications for the most effective utilisation of those
145 | P a g e
resources. It is essential that information be seen as a strategic asset in order for supply
chains to achieve success. SSC is characterised by a number of qualities, one of which
is the overwhelming presence of an infinite number of possibilities for the
administration of information that is both effective and efficient. Intelligent supply
chains are characterised by the following characteristics: they automatically optimise
production of products and services; they quickly and intelligently respond to
disruptions that are created both internally and externally; they automatically balance
supply and demand based on historical projections and predictive algorithms; and they
automatically optimise output.
Smart supply chains, on the other hand, will be more intelligent in the future. They will
be more digital, self-managed, and capable of finding solutions to issues. They will
also be able to adapt to new circumstances and tasks, adjust their behaviour, and learn
on their own. In the future, the architecture of intelligent supply chains will be more
fluid and transient. A reduction in the number of entities involved in the process of
producing value for goods will occur as a result of the use of 3D printing and the
potential of printing things by consumers. Supply chains will become more localized
and smaller as a result of these developments.
5.11 CONSEQUENTLY, IT COULD BE IDENTIFIED:
• Initial phase - with local applications such as e-sourcing or RFID tags
implementation;
• Early phase - with the implementation of isolated system for example an
intelligent factory or service;
• Intermediate phase - characterised by the implementation of smart
solutions integrating processes in whole supply chain (integrated, based on
high scope of the data exchange and high level of trust);
• Advanced phase - characterised by digitality, dynamic Ness and
temporariness, with ability to adapt to the needs of the market and resources
As a result of the potential of connecting to any network, the amount of information
that is acquired and processed will further increase in both volume and scale. This
includes the possibility of connecting to large multinational corporations, tiny local
supply, power grids, and even the transportation systems that are the least accessible.
146 | P a g e
5.12 HUMAN-MACHINE COLLABORATION
Machines and intelligent devices that are equipped with a broad array of sensing
capabilities as well as artificial intelligence (AI) have become more commonplace as a
result of ongoing technical breakthroughs thanks to the widespread deployment of these
devices. In addition to permeating every aspect of our daily lives, this phenomenon has
also invaded almost every industrial area. The collection of observations, the
processing of raw data, and the computation of numerical values are only some of the
activities and processes that are currently carried out by machines.
In the past, individuals were responsible for carrying out these activities and processes.
Having said that, machines are typically purpose-built and are taught using a limited
quantity of data, they lack the generalizability and flexibility that are required to be
adapted to new conditions. This is because of the fact that machines are typically
constructed for specific uses. The incorporation of the cognitive powers and knowledge
of humans into the decision-making process is very necessary in high-pressure, highstakes situations in which people's lives as well as their assets are at risk. This is done
in order to enhance the quality of choices and to raise situational awareness.
A significant amount of research has been conducted in the area of signal processing
on collaborative decision making, which is a process in which the only individuals
involved in the decision-making process are machines or electronic equipment, such as
sensors. Examples of contexts where this form of decision-making has been studied
include distributed and centralised systems. Although there have been considerable
gains due to recent theoretical developments The performance of sensor networks,
scattered detection, and information fusion are all areas where decision-making
systems face the challenge of interacting with end users, or how to include humans into
control and decision-making processes.
Establishing mission-oriented networks that include both humans and sensors is
increasingly crucial for completing challenging tasks in unpredictable environments.
Semiautonomous systems that allow these networks to interact with one other are
necessary for their construction. These networks are also known as human-machine
teams. The capacity to think inductively, use judgement, improvise, and use flexible
tactics are all areas where humans excel above machines, according to. The reason for
this is because people may be very adaptable. On the other hand, computers are better
than humans when it comes to responding swiftly, executing things that are routine and
147 | P a g e
repetitive, and capable of deducing reasoning and computation. Our growing
understanding of human-machine inference teams aims to bridge the gap between
humans' complementary cognitive strengths and computers' computational prowess in
a way that that is intelligent.
Fig. 5.3. Architecture for the notional cooperation of humans and machines.
Source: data collection by AI in Computer Science Matthew N. O. Sadiku 
This is done with the intention of achieving more performance than either humans or
computers could do on their own. Presented in Figure 5.3 is a typical architecture that
is used for the purpose of producing intelligent judgements. In this configuration,
networks consisting of both humans and robots are used to monitor the same
phenomenon of interest (Poi) from a number of distinct perspectives.
It is possible for individuals to perform a wide range of roles inside an inference
network of this sort. It is possible, for instance, that they will take on the role of global
decision makers, in which they would base their judgements on the outcomes of
machine measures. People may also operate as "sensors" themselves, for example by
acting as scouts to gather information. This is an alternative mode of operation.
The assessments that people make at the local level are then conveyed to a decision
maker at the global level. This ability allows humans to make decisions at the local
level. There are two things that need to be taken into mind throughout the development
148 | P a g e
of the system in order for people to have a more productive relationship with the
machines. The following is a list of these aspects: a) the outputs of the machine have
an effect on the actions, choices, and behaviours of people; and (b) the deployments
and optimal algorithm design of the computers are impacted by human characteristics
and behavioural attributes.
There has been a lot of effort by cognitive psychologists to model human decisionmaking, both in terms of individual and collective decisions. Furthermore, this article
aims to summarise the research on human machine cooperation and decision making
from a signal processing and information fusion standpoint. The focus of this piece is
on the studies that have examined these questions. Applying ideas from cognitive
psychology and statistical signal processing to the field of the sake of inference and
intelligent decision making is something that we are especially interested in,
particularly within the scope of multi-agent systems and distributed detection.
The phrase "human-machine collaboration" refers to the seamless integration and
cooperation between humans and machines for the aim of providing solutions to
problems, carrying out operations, or accomplishing objectives. An idea that places a
focus on the combination of human intelligence, creativity, and emotional
understanding with the processing power, efficiency, and accuracy of machines is
called the notion of artificial intelligence. In particular, it is centred on the concept of
artificial general intelligence, sometimes known as AGI. In order to maximise
productivity, decision-making, and overall performance across a wide range of
domains, the objective of this attempt is to make the most of the advantages that both
businesses possess in their respective areas of expertise.
149 | P a g e
CONSTRAINT SATISFACTION PROBLEM
6.1 DEFINING CONSTRAINT SATISFACTION ISSUES
X, D, and C are the three components that make up, respectively, a constraint
satisfaction issue.
X is a collection of variables, denoted by the notation {X1,,Xn}.
D represents a collection of domains, denoted as {D1, Dn}, with each domain
representing a different variable.
In this context, the letter C stands for a collection of constraints that determine the value
combinations that are permitted.
There is a set of permissible values for the variable Xi, which may be expressed as {v1,
vk}, and this set is applicable to any domain Di. There are two components that make
up each constraint Ci: the scope and the rel. A relation reel is a tuple of variables that
are included in the constraint, and it determines the values that are permitted for the
variables that are defined by the scope variables. A relation may be defined in a number
of different ways. One of these ways is by using an explicit list of all value tuples that
meet the constraint. Another method is to use an abstract relation that allows for two
operations: enumerating the members of the relation and testing to see whether or not
a tuple also belongs to the relation. The set {A, B} is considered to have a single
instance when both X1 and X2 are components of the set. In this context, the condition
that the two variables must be unique might be expressed using the formulas (X1, X2),
[(A, B),(B,A)] or (X1, X2), X1 = X2.
Before it is possible to solve a CSP, it is necessary to first establish a state space and
the concept of a solution. There is the possibility of establishing the meaning of each
state in a CSP by assigning values to any or all of the variables. For instance, Xi can be
assigned the value vi, while Xj can be assigned the value vj. An assignment is
considered legal and consistent if it does not breach any of the constraints that have
been highlighted in the previous paragraphs. One definition of a full assignment is one
that has all of the variables that are assigned to it. The only way to solve a CSP is to
150 | P a g e
have an assignment that is both consistent and complete. It is possible to give values to
some variables in a partial fashion rather than setting values to all of them.
6.1.1 Issue with coloring a map
Therefore, let us imagine that we have had enough of Romania and are now looking at
a map of Australia that depicts all of the states and territories (Figure 6.1(a)). We are
the ones who are responsible for determining whether each zone should be red, green,
or blue because it is forbidden for two neighboring zones to share the same hue. The
objective here is to make certain that no two places are identical to one another. We are
going to use different areas as the variables in order to construct this as a customs
service provider.
Every variable has the set Di as its domain, which is composed of the color’s red, green,
and blue. When it comes to the limitations, neighboring areas are required to have
different colour. The nine limitations are as follows:
This is due to the fact that there are nine sites where regions border.
In this context, A lot of acronyms are being used; SA = WA is a shorthand equivalent
to (SA, WA), SA = WA, where SA = WA may be properly enumerated in turn as {(red,
green),(red, blue),(green, red),(green, blue),(blue, red),(blue, green)}.
There are several potential answers to this issue, including the following: {WA = red,
NT = green, Q = red, NSW = green, V = red, SA = blue, T = red}.
As shown in Figure 6.1(b), thinking of a constraint scalar product (CSP) as a constraint
graph might be helpful in terms of comprehension. A link is a relationship that can exist
between any two variables that are contained within a constraint. The nodes in the graph
are the representations of the variables that are associated with the issue.
When an issue is expressed as a CSP, what does it imply to do so? It is possible that
this is due to the fact that CSPs provide a natural representation for a wide variety of
various kinds of issues. Instead of coming up with a bespoke solution by employing a
151 | P a g e
different search strategy, it is typically simpler to use a system that solves issues by
utilising CSPs to solve new problems. This is because the system already has the
capability to solve problems. In addition, CSP solvers are superior than state-space
searchers because they are able to rapidly reject significant areas of the search region.
When they are in states-space, the searchers proceed at a slower rate. As an illustration,
when it comes to the Australia problem, we can get to the conclusion that none of the
five variables that are close to each other can have the value blue. This is because we
have already selected the value {SA = blue}. In the event that constraint propagation
did not exist, there would need to be a search strategy that took into consideration 35,
which is equivalent to 243 assignments for the five variables that are located close. This
brings the total number of assignments down to 25, or 32, despite the fact that blue is
never a value that should be taken into consideration when restrict propagation is being
used. There has been a decrease consisting of 87%.
The sole question that may be asked during a standard state-space search is, "Is this
particular state a goal?" Oh, no! That brings us to this one. Once it is determined that a
partial assignment is not a solution, we are able to use CSPs to identify a solution.
Figure 6.1 (a) Those states and territories that make up the majority of
Australia. Another way to look at coloring this map is as a constraint satisfaction
problem, sometimes known as a CSP.
Source: Artificial Intelligence a Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
152 | P a g e
Immediately throw out any further improvements that were made to the partial
assignment. In addition, we are able to understand why the assignment is not a solution;
we are able to determine which variables break a constraint, which allows us to
concentrate our attention on the variables that are significant. As a consequence of this,
a great number of issues that are insurmountable for conventional state-space search
may be resolved in a short amount of time when phrased as a CSP.
6.1.2 The job-shop scheduling example issue
There are a number of limits that factories must adhere to when arranging a day's worth
of work, which presents a challenge. In actuality, a significant many of these issues
may be resolved by using CSP strategies. Take for example the challenge of
determining the best time to put together an automobile. We may represent each job as
a variable whose value is the start time of the job expressed as an integer of minutes.
Every part of the work is a task, and we may treat each task like a variable in our model.
It is possible for constraints to declare that one job must take place before another, such
as the installation of a wheel must take place before the hubcap is placed on, and that
there is a limit to the number of activities that may be performed simultaneously. It is
also possible for constraints to stipulate that a job must be completed within a certain
length of time.
We take into consideration a tiny portion of the automobile assembly, which consists
of fifteen tasks: installing axles (both front and rear), attaching all four wheels (front
and rear), nut tightening, hubcap attachment, and final assembly inspection. The fifteen
factors that follow may be used to represent the tasks:
The time at which the activity begins is the value that is assigned to each variable.
Following that, we will illustrate the limitations of priority between the distinct jobs.
Whenever a job T1 is required to take place before task T2, and task T1 requires a
period of d1 to complete, we include an arithmetic constraint of the type T1 + d1 < T2
into the equation.
153 | P a g e
In our illustration, the axles have to be installed before the wheels are placed on, and
the process of installing an axle takes ten minutes, therefore we write that it takes ten
Following that, we state that, for every wheel, we are required to first connect the
wheel, which requires one minute of your time, and then secure the bolts, which takes
two minutes, and lastly, we must attach the hubcap, which takes one minute but is not
yet represented:
Imagine that we have four personnel involved in the installation of wheels, but they are
required to share one tool that assists in the placement of the axle. In order to ensure
that Axle F and Axle B do not overlap in time, we need a disjunctive constraint. This
means that either one of them must come first or the other must arrive first:
In light of the fact that this constraint combines arithmetic and logic, it seems to be
more complex. In spite of this, it may still be reduced to a collection of pairs of values
that Axle F and Axle F are able to assume.
In addition, we need to make it clear that the inspection is the last step and takes three
minutes. A constraint of the type X + dX <= Inspect is added to each variable, with the
exception of Inspect, to ensure equality. Consider the following scenario: there is a
requirement that the whole assembly must be completed within thirty minutes. It is
possible for us to do this by restricting the scope of all variables:
154 | P a g e
It is not difficult to find a solution to this specific issue; nonetheless, CSPs have been
used to tackle job-shop scheduling difficulties that include hundreds of variables much
like this one. In some circumstances, there exist complex restrictions that are difficult
to define using the CSP formalism, and the need for more advanced planning is also
6.1.3 Variations on the CSP formalism
Variables that have discrete and finite domains are the ones that are involved in the
most basic form of CSP. Problems of this nature include those involving the coloring
of maps and scheduling with time constraints. The 8-queens problem that is discussed
in Chapter 3 may alternatively be interpreted as a finite-domain CSP. In this case, the
variables Q1, Q8 represent the locations of each queen in columns 1, 8, and the domain
Di is equal to the set of numbers 1, 2, 3, 4, 5, 6, 7, 8.
Any discrete domain, such as the set of strings or numbers, may have an endless number
of elements. (If we did not impose a time limit on the issue of work scheduling, there
would be an endless number of possible start times for each variable.) It is no longer
viable to define restrictions by enumerating all of the conceivable combinations of
values when the domains are infinite. In its place, it is necessary to use a constraint
language that is capable of comprehending constraints like T1 + d1 ≤ T2 in a
straightforward manner, without the need to enumerate the set of pairs of values that
are permissible for (T1, T2). For linear constraints on integer variables, there are special
solution techniques that are available. These algorithms are not going to be discussed
here. Linear constraints are constraints, such as the one that was just shown, in which
each variable only occurs in linear form. It has been shown that there is no method that
can solve universal nonlinear restrictions on integer variables currently in existence.
In fact, constraint fulfilment issues with continuous domains are fairly prevalent, and
operations research places a significant amount of emphasis on these kinds of problems.
As an illustration, the Hubble Space Telescope requires the correct observing time in
order to schedule experiments. Every single observation and movement must begin and
end with continuous-valued variables that are required to adhere to a set of principles
pertaining to power, precedence, and astronomy. Linear programming issues are the
most well-known type of continuous-domain generalised problems (CSPs). Limitations
that are linear, either in terms of equality or disparity, are the only ones that we consider
under these circumstances. It is possible to solve issues involving linear programming
155 | P a g e
in a certain amount of time that is polynomial with respect to the number of variables.
There have also been studies conducted on problems that involve a broad variety of
constraints and objective functions. These problems include second-order conic
programming, quadratic programming, and a great deal of other problems.
While it is beneficial to investigate the many kinds of variables that may be found in
CSPs, it is also beneficial to investigate the different kinds of constraints. Restricting
the value of a single variable is the unary constraint, which is the kind that is the most
straightforward. In the case of the map-coloring issue, for instance, it is possible that
South Australians would not accept the colour green. We are able to express this using
the unary constraint (SA), which is equal to green.
A binary constraint is a relationship between two variables. One example of a binary
constraint is the expression SA = NSW. Those CSPs that only have binary constraints
are referred to as binary CSPs. This kind of CSP may be represented as a limitation
diagram, as seen in Figure 6.1(b).” Through the use of the ternary constraint Between
(X, Y, Z), we are also able to specify higher-order restrictions. For example, we may
declare that the value of Y does not fall outside of the range of X and Z.
One kind of constraint is referred to be a global constraint, and it takes into account an
unlimited number of variables. It is a classic moniker, but it is also confusing since it
does not always incorporate all of the variables that are involved in a situation. The
Alldiff constraint is one of the most frequent global constraints. This constraint requires
that all of the variables that are a part of the constraint have values that are distinct from
one another.
In Sudoku puzzles (for further information, see Section 6.2.6), it is necessary for every
variable in a row or column to fulfil an Alldiff criterion. Puzzles that include
cryptarithmetic calculations are yet another such. It is shown in Figure 6.2(a). In
cryptarithmetic, each letter represents a different alphabetic character. In Figure 6.2(a),
this is illustrated as the global constraint Alldiff (F, T, U, W, R, O). In order to express
the addition constraints that are placed on the four columns of the problem, the
following n-ray constraints may be written:
156 | P a g e
where the auxiliary variables C10, C100, and C1000 each represent the digit that was
carried over into the ten’s column, the hundreds column, and the thousands column,
respectively. One possible method for representing these restrictions is to make use of
a constraint hypergraph, such as the one shown in Figure 6.2(b). There are two different
kinds of nodes that make up a hypergraph: regular nodes, which are represented by
circles in the figure, and hypernodes, which are squares and reflect n-ARY restrictions.
On the other hand, you are required to demonstrate in Exercise 6.6 that each finitedomain constraint may be reduced to a collection of binary constraints if there are
sufficient auxiliary variables. To put it another way, we might decrease the complexity
of the algorithms by transforming any CSP into one that only possesses binary
constraints. A second method for transforming n-ARY CSPs to binary ones is the dual
graph transformation, which consists of the following steps: Following the generation
of the new graph, each constraint from the old graph will be assigned its own variable
in the new graph.
Figure 6.2 (a) There is a difficulty with cryptography. The intention is to
discover a replacement of numbers for letters in such a way that the resultant
total is arithmetically valid, with the additional limitation that there are no
leading zeroes permitted. Each letter represents a different digit.
Source: Artificial Intelligence a Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
It is necessary for there to be a single binary constraint in the initial graph for every
pair of constraints that share variables. The original C1 and C2 relation specifies the
157 | P a g e
variables that are shared (X and Y), and the new relation R1 indicates the constraint
that exists between the two variables. By applying the binary constraint (X, Y) on the
variables {C1, C2} in the dual graph, the binary constraint is imposed. If we assume
that the initial network had variables {X, Y, Z} with constraints (X, Y, Z), C1 and (X,
Y), C2, then the dual graph would consist of variables {C1, C2} with the binary
constraint (X, Y), R1.
On the other hand, we would choose for a global restriction such as Aldi rather than a
series of binary constraints there are two reasons for this. Using Aldi to produce the
problem description is a simpler and less error-prone initial step than using any other
methodology. This brings us to the conclusion that it is theoretically conceivable to
construct inference techniques that have universally applicable limitations that are
designed specifically for that purpose, but these methods are not accessible for a
collection of more basic constraints.
All of the constraints that we have discussed up to this point have been absolute
constraints, which means that any violation of them eliminates any possibility of a
solution. A great number of CSPs that are used in the real world have preference
constraints that specify which solutions are favoured. As an example, when it comes to
the scheduling of courses at a university, there are absolute limits that restrict the ability
of any professor to teach two sessions at the same time. On the other hand, we may also
permit preference constraints: There is a possibility that Professor R takes pleasure in
teaching in the morning, whilst Professor N favors Instruction in the afternoon is
delivered. In spite of the fact that it would not be ideal, a timetable that includes
Professor R giving a lecture at two o'clock in the afternoon would still be feasible
(unless, of course, he is the chair of the department).
One frequent method of expressing preference restrictions is through the expression of
the costs that are involved with assigning various variables. When the complete
objective function is taken into consideration, for instance, assigning Professor R a
morning slot costs one point, whilst assigning him a position in the afternoon costs two
points is comparable. This formulation allows for the use of optimisation search
techniques, which may be used to solve CSPs that integrate preferences, which may be
either path-based or local. This kind of issue is referred to as a constraint optimisation
problem, or COP for short. There is a kind of optimisation that is performed via linear
programming issues.
158 | P a g e
6.2 CONSTRAINTS TRANSMISSION: DEDUCTIVE PLANTS IN CSPs
An algorithm is only capable of doing one thing when it is used in standard state-space
search: try to find. Search, which involves selecting a new variable assignment from a
set of possibilities, and constraint propagation, which is a type of inference in which
constraints are used to decrease the number of legal values for a variable, which in turn
reduces the number of legal values for another variable, and so on, are the two options
that are available to algorithms in CSPs.
Depending on the circumstances, either the search process or the constraint propagation
process may be involved, or the former might be performed as preprocessing prior to
the search beginning. If this preprocessing manages to totally eradicate the issue, then
there will be no need for any search to be conducted.
Local homogeneity is a notion that is really necessary. The elimination of incorrect
values from the graph as a whole is accomplished by the implementation of consistency
checks at the node level. The reason for this is that if we consider all variables to be
nodes in a graph (refer to Figure 6.1(b)) and all binary constraints to be arcs, we will
be able to eliminate values that are inconsistent across the board. In this section, we
will discuss the many forms of local consistency, which will be discussed in turn.
6.2.1 The stability of nodes
If every value in the domain of a single variable (representing a node in the CSP
network) satisfies the unary constraints linked to that variable, we say that the variable
is node-consistent. The variable SA starts with the domain {red, green, blue} in Figure
6.1, which shows a variant of the Australia map-coloring dilemma where South
Australians strongly dislike the colour green. Leave SA with the smaller domain {red,
blue} if we want to achieve node consistency by excluding green. When all of a
network's variables match the nodes, we say that the network is node-consistent.
Through the use of node consistency, it is always feasible to get rid of all of the unary
restrictions that are present in a CSP. The transformation of all n-ary restrictions into
binary ones is another possibility (for an example, see Exercise 6.6). It is usual practice
to construct CSP solvers that operate with just binary constraints; we will assume this
assumption throughout the remainder of this chapter, with the exception of the places
where it is specifically stated.
159 | P a g e
6.2.2 Arc stability
For a CSP variable to be termed arc-consistent, it must possess a domain in which every
single value satisfies the binary requirement that is associated with the variable. When
it comes to another variable Xj, it is necessary for every value in domain Di to fulfil
the binary constraint on the arc (Xi, Xj) in order for Xi to be arc-consistent. This is only
the case if there is a value in domain Dj that fulfils this particular requirement.
A more elucidating explanation of the idea is provided in this section. According to our
definition, a network is said to be arc-consistent if and only if each and every variable
in the network is consistent with each and every other variable. As an illustration, take
into consideration the equation Y = X2, in which the domain for both variables is the
set of integers where the equation is written. This constraint is something that we are
able to declare openly as
We restrict the domain of X to the set of numbers 0 through 3 in order to make it arcconsistent with respect to Y. If we additionally make Y arc-consistent with regard to
X, then the domain of Y will be as follows: {0, 1, 4, 9}, and the whole CSP will be arcconsistent. When it comes to the issue of coloring the map of Australia, arc consistency,
on the other hand, is completely ineffective. Please take into consideration the
inequality restriction that follows on (SA, WA):
There is a legitimate value for the other variable, regardless of the value that you choose
for SA (or for WA at that point of time). Therefore, the application of arc consistency
does not have any impact on the categories of either variable.
Please refer to Figure 6.3 for further information about the most often used method for
arc consistency. In order to ensure that every variable arc is consistent, the AC-3
algorithm keeps a queue of arcs that it must take into consideration. According to
160 | P a g e
conventional wisdom, the data structure is really a set, although it is often referred to
as a queue. This is because the order of consideration is not significant. In the
beginning, the queue is comprised of all of the arcs that are included inside the CSP.
AC-3 then removes an arbitrary arc from the queue, which is denoted by the coordinates
Xi and Xj, and ensures that Xi is arc-consistent with regard to Xj. In the event that this
does not affect Di in any way, the algorithm will proceed to the subsequent arc.
Table 6.1 The approach to ensure arc coherence known as AC-3. Following the
application of AC-3, either every arc is consistent with the arc. Alternatively,
certain variables have an empty domain, which indicates that The CSP is
intractable
Source: Artificial Intelligence A Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
However, if this causes Di to be revised (that is, if it reduces the size of the domain),
then we will add to the queue those arcs (Xk, Xi) in which Xk is a neighbor of Xi. This
is something that has to be done since the modification to Di might potentially allow
for more reductions in the domains of Dk, even if we have already taken into
consideration Xk. In the event that Di is reduced to zero, we will be aware that the
whole CSP does not possess a consistent solution, and AC-3 will be able to promptly
return failure. In the event that this is not the case, we continue to verify and attempt to
remove values from variable domains until there are no more arcs in the queue. After
161 | P a g e
that, we have a CSP that is similar to the CSP that was first created; we may use either
one to discover the solution; however, the arc-consistent CSP will often be easier to
search for due to the fact that its variables have smaller domains.
The complexity of AC-3 may be broken down into the following categories. Take into
consideration a CSP that has n variables, each of which has a domain size of no more
than d, and c binary constraints (arcs). It is only possible to add each arc (Xk, Xi) to
the queue a maximum of d times due to the fact that Xi can only remove a maximum
of d values. Performing a check on the consistency of an arc may be accomplished in
O(d2) time, which means that the total worst-case time is O(cd3).
It is possible to expand the concept of arc consistency such that it may accommodate
n-ARY constraints as opposed to only binary constraints. This is referred to as
generalised the writer is responsible for determining if the hyperarc or arc consistency
is appropriate for the situation. Additionally, there is a tuple of values that is a member
of the constraint, has all of its values taken from the domains of the variables that
correspond to it, and has its Xi component equal to v. This tuple of values is present
for every value v that is included inside the domain of Xi. According to the n-ary
requirement, this tuple is defined as a generalised arc that is compatible with the
specification. Take the following example into consideration: One, two, three, and zero
are the domains of all variables. Example: In order to determine whether or not the
variable X is compatible with the constraint X.
6.2.3 Consistency of the path
Arc consistency may go a long way towards decreasing the domains of variables,
sometimes finding a solution (by reducing every domain to size 1) and sometimes
indicating that the CSP cannot be solved (by reducing some domain to size 0). Arc
consistency may also be used to detect problems that cannot be solved. Arc consistency
can be used to do both of these things extremely well. When it comes to other networks,
however, arc consistency does not provide sufficient conclusions.
Take for example the difficulty of coloring a map of Australia, but with just two colour
permitted: red and blue to choose from. Due to the fact that every variable is already
arc consistent, arc consistency is unable to do anything. For example, any variable may
be red with blue at the opposite end of the arc (or vice versa). However, it is abundantly
evident that there is no solution to the issue. Due to the fact that South Australia,
162 | P a g e
Western Australia, and the Northern Territory all touch each other, we need at least
three colour for each of these three states alone.
Through the use of the arcs, which are binary constraints, arc consistency is able to
reduce the domains, which are unary constraints. Our understanding of consistency has
to be strengthened if we are going to make any forward on issues such as coloring maps.
from the use of implicit constraints, which are deduced from the examination of triples
of variables, path consistency increases the stringency of the binary constraints.
For any given set of two variables {Xi, Xj} that satisfies the constraints on {Xi, Xj},
there must be an assignment to Xm that satisfies the constraints on both {Xi, Xm} and
{Xm, Xj} in order for the set to be path-consistent with respect to a third variable Xm.
It is possible to think of path consistency as a route that goes from Xi to Xj, with Xm
in the middle, and this idea comes from there.
In order to evaluate the effectiveness of route consistency, let's colour the map of
Australia with two different colour. We are going to ensure that the route that is
established {WA, SA} is consistent with regard to NT. To begin, we will list all of the
consistent assignments that have been made to the set. Here, there are just two: {WA =
red, SA = blue} and {WA = blue, SA = red}. Both of these combinations are possible.
Given both of these assignments, it is clear that NT cannot be either red or blue (due to
the fact that doing so would be in contradiction with either WA or SA).
Considering that there is no legitimate option for NT, we delete both assignments,
resulting in a situation where we do not have any valid assignments for {WA, SA}
either. It is for this reason that we are aware that there is no possible solution to this
situation. PC-2, which was developed by Mackworth in 1977, is able to achieve route
consistency in a manner that is comparable to how AC-3 is able to achieve arc
consistency. Due to the fact that it is so comparable, we will not include it here.
6.2.4 K-consistency
Through the use of the concept of k-consistency, more robust types of propagation may
be identified. For every collection of k − 1 characteristics, and for the consistent
assignment of those characteristics to, a CSP is said to be k-consistent if it is possible
to assign a consistent value to any kth variable across the whole set of variables. Based
on the concept of 1-consistency, it is possible to make any set of one variable consistent,
163 | P a g e
provided that the set is empty. This concept is referred to as node consistency. There is
no difference between arc consistency and 2-consistency. The concept of 3-consistency
is equivalent to the concept of route consistency in binary constraint networks.
When a CSP is consistent with k, it is considered extremely k-consistent if it is also
consistent with (k − 1)-consistency, (k − 2)-consistency, and so on, all the way down
to 1-consistency. Assume for a moment that we have a CSP that has n nodes and that
we make it strongly n-consistent (that is, strongly k-consistent for k equal to n). This is
how we may then find a solution to the problem: We begin by selecting a value that is
consistent for X1. This ensures that we will be able to choose a value for X2 due to the
fact that the graph is consistent with two values, for X3 due to the fact that it is
consistent with three values, and so on.
If we want to get a value that is compatible with X1, Xi-1, all we have to do is search
through the d values that are present in the domain for each variable Xi. Within the
time constraint of O(n2d), we are certain to discover a cure. Obviously, there is no such
thing as a free lunch: any method that is intended to produce n-consistency must, in the
worst-case scenario, need a duration that is exponential in n. In addition, n-consistency
necessitates the utilisation of space that is exponential in n. The memory problem is far
more serious than the problems with the time. When it comes to actual practice,
establishing the proper amount of consistency checking is mostly an empirical science.
It is possible to say that practitioners typically calculate two-consistency, whereas
three-consistency is computed less often.
6.2.5 Worldwide limitations
Keep in mind that even while a global constraint can make use of any number of
variables, this does not necessarily guarantee that it will have an effect on each and
every one of them. Through the use of specialised algorithms that outperform the
general-purpose approaches that have been demonstrated up until this point, it is
feasible to address global restrictions, which are frequent in situations that occur in the
real world. For instance, the Ayliff constraint stipulates that all variables must have
values that are different from one another, as demonstrated in the cryptarithmetic
problem that came before it and the Sudoku puzzles that are presented below. The
constraint cannot be satisfied if there are m variables involved, each of which can take
on one of n potential values, and the number of variables is greater than or equal to n.
In this case, the restriction cannot be satisfied. An illustration of a method for
164 | P a g e
identifying discrepancies in Ayliff constraints is shown here in its most fundamental
The straightforward strategy that is followed as a result of this is as follows: It is
necessary to locate and remove any constraint variables that have a singleton domain
to get started. After that, delete the value of each variable that is still present from the
domain it belongs to. In the event that any of the variables are singletons, please execute
the code once again. If the domain is empty at any point in time or if there are more
variables than domain values remaining, then there is inconsistency.
With the utilisation of this particular strategy, Figure 6.1 has the capability to identify
the distinction in the assignment {WA = red, NSW = red}. It is important to keep in
mind that SA, NT, and Q are fundamentally connected by an Ayliff constraint. This is
due to the fact that every pair of variables must incorporate two distinct colour. The
domain of each variable is reduced to a combination of green and blue when AC-3 is
used in conjunction with partial assignment. There are three variables, but the data only
represents two colour; hence, the Ayliff criterion is not satisfied. In essence, there are
three variables. Because of this, it may be more beneficial to utilise a straightforward
consistency process for a higher-order constraint rather than applying arc consistency
to a group of binary requirements that are similar to one another. When looking for
more complex Ayliff inference techniques, van Hoeve and Katriel are the ones
to consult. These approaches need a greater amount of processing resources to operate,
but they transfer a greater number of limits.
Another significant higher-order constraint is the resource constraint, which is
sometimes referred to as the at most constraint in certain contexts. To illustrate this
point, let us assume that there is a scheduling issue and that the number of workers
allocated to each of the four jobs is denoted by the letters P1, P2, P3, and P4. For the
purpose of expressing the constraint that no more than ten individuals can be allocated
in total, the notation at most (10, P1, P2, P3, P4) is utilised. When we gather all of the
minimum values of the current domains and combine them together, we are able to
readily identify any inconsistencies. Take into consideration the scenario in which the
Atmost constraint is not met since every variable inside the domain {3, 4, 5, 6} is
present. In addition, if the lowest value of a domain does not correspond to the
minimum values of the other domains, we have the ability to delete the maximum value
of that domain in order to guarantee consistency. For a more straightforward
165 | P a g e
explanation, if the domains of the variables in our example are {2, 3, 4, 5, 6}, then it is
possible to remove the numbers 5 and 6 from each of them.
In most cases, it is not possible to first represent the domain of each variable as a
massive collection of integers and then gradually reduce that set by employing
procedures that verify for consistency. There are many instances of resource-limited
situations with integer values, such as the logistics challenges that include the transfer
of thousands of people in hundreds of cars. Bounds propagation is responsible for
managing domains, and using lower and upper limits to identify domains is one way to
accomplish so. Let's imagine, for the purpose of argument, that there are two flights,
F1 and F2, and that the aircraft has the capacity to accommodate 165 and 385
passengers, respectively, in the context of a scheduling challenge for an airline. The
following is a list of the first domains for the total number of passengers that each
aircraft is able to service:
A further limitation that we must take into account is that the combined capacity of the
two aircraft must be 420 passengers: F1 plus F2 equals 420. Through the use of
propagating limits restrictions, we narrow the domains down to
What we mean Bounds consistency in a CSP is defined as the presence of a value of Y
satisfying the constraint between X and Y for any value of Y, regardless of the lowerbound or upper-bound of X. This is the case when the CSP is bounds consistent. Bounds
propagation of this kind is utilised quite frequently in the context of practical constraint
6.2.6 Solving a sudoku puzzle
It is possible that millions of people have been exposed to constraint satisfaction
problems through the popular puzzle known as Sudoku, even though they may not be
aware of this fact. There are eighty-one spaces on a Sudoku board, and part of them are
originally filled with numbers from one to nine. Every square is assigned a distinct
number. For an illustration of the puzzle, see to Figure 6.4. To avoid any duplicate
166 | P a g e
digits in any row, column, or 3 × 3 box, the goal is to fill in all the remaining squares.
A "unit" in a table may be anything from a row to a column to a box.
One defining feature of Sudoku problems found in print media and puzzle books is the
inherent unicity of each problem's solution. Even the most difficult Sudoku puzzles can
be solved by a computer-based solver in less than 0.1 second, despite the fact that some
of them can be difficult to solve manually and take tens of minutes to complete.
It is possible to think of a Sudoku puzzle as a CSP because it contains 81 variables, one
assigned to each square. For the top row (left to right), we use the variable names A1
through A9, and for the bottom row, we use the names I1 through I9 in that order. The
domain of the empty squares is expressed as {1, 2, 3, 4, 5, 6, 7, 8, 9}, whereas the
domain of the prefilled squares is comprised of a single value. To add insult to injury,
there are 27 distinct
Table 6.2 (a) A Sudoku problem and (b) its solution
Let us see how far we can accomplish while maintaining arc uniformity. For the sake
of immediately using the AC-3 method, what if, to make things easier, the Alief
167 | P a g e
constraints have been expanded into binary constraints? For instance, A1 = A2. Figure
6.4(a) displays the variable E6; observe it, which is the empty square that is located in
the middle box between the two and the eight. It is possible for us to remove not only
the numbers 2 and 8 from E6's domain, but also the numbers 1 and 7 from the
restrictions in the box. It is possible to delete the numbers 5, 6, 2, 8, 9, and 3 based on
the limitations in its column.
That leaves E6 with a domain of {4}; to put it another way, we are completely aware
of the solution for E6. Consider now the variable I6, which is the square in the centre
bottom box that is bordered by the numbers 1, 3, and 3. By using the principle of arc
consistency in its column, we remove the numbers 5, 6, 2, 4, 8, 9, and 3 (given that we
now know that E6 must be 4). The value 1 is eliminated via the use of arc consistency
with I5, and the only value that remains in the domain of I6 is the number 7. Since there
are now eight values that are known to exist in column 6, It may be inferred from arc
consistency that A6 is equal to 1. Following this line of reasoning, the inference process
keeps on, and AC-3 will finally be able to solve the whole thing. Figure 6.4(b) shows
that the domains of all the variables will be reduced to one value.
If AC-3 could be mechanically applied to address every problem, it is certain that
Sudoku would quickly lose its attraction. In fact, AC-3 is only effective for solving the
most straightforward Sudoku puzzles. PC-2 is capable of solving somewhat more
difficult puzzles, but doing so requires a significant amount of processing effort. For
example, a Sudoku problem has 255,960 possible route restrictions to take into
consideration. For us to be able to tackle the most difficult challenges and make
progress in an effective manner, we will need to be more intelligent.
As a matter of fact, the human solver finds the attractiveness of Sudoku puzzles in the
fact that individuals rely on their ability to think creatively while using ever-morecomplex inference processes. Their many devoted followers have bestowed upon them
amusing moniker, such as "naked triples." The steps to execute this approach are as
follows: Discover three squares in every given unit (row, column, or box) whose
domain includes at least three integers. An example of this would be the three domains
being {1, 8}, {3, 8}, and {1, 3, 8} respectively. We are unable to determine whether
square includes the numbers 1, 3, or 8 based on this information; yet, we are certain
that the three numbers must be spread among the three squares. Because of this, we are
able to eliminate the numbers 1, 3, and 8 from the domains of every other square in the
168 | P a g e
The fact that we can get thus far without mentioning a lot of things that are unique to
Sudoku is a noteworthy observation to make. It goes without saying that we are
required to mention that there are 81 variables, that their domains consist of the
numbers 1 through 9, and that there are 27 Ayliff constraints being applied. Beyond
that, however, all of the methods, such as arc consistency, path consistency, and so on,
are applicable to all CSPs in general, and not only to Sudoku puzzles specifically. There
is no connection between naked triples and Sudoku in and of itself; rather, they are a
mechanism for ensuring that Ayliff restrictions are adhered to consistently. The
strength of the CSP formalism lies in the fact that it just requires us to specify the issue
in terms of constraints for each new problem area. After that, the general constraintsolving mechanisms are able to take over.
6.3 INVESTIGATING THE PAST OF CSPS
Problems in the Sudoku puzzle are intended to be solved by drawing conclusions based
on the limitations. However, there are a great number of additional CSPs that cannot
be handled just via the use of inference; that is when we will need to look for a solution.
In this section, we will examine backtracking search algorithms that are effective on
partial assignments. In the next section, we will examine local search algorithms that
are effective on whole assignments.
It is possible for us to do a conventional depth-limited search. A partial assignment
would be an example of a state, and adding the string var = value to the assignment
would be an example of an action. However, when we consider a CSP that has n
variables and a domain size of d, we rapidly become aware of a dreadful truth: nd is
the branching factor at the highest level. Reason being, each one of the n variables can
take on any value from the d-value range. This indicates that the branching factor at the
subsequent level is (n − 1) d, and the process continues indefinitely for n levels.
Regardless of the fact that there are only dn possible complete assignments, we
nonetheless manage to create a tree with n! dn leaves.
Commutativity, a critical trait that is shared by all CSPs, is ignored by our formulation,
which seems to be sensible but is really rather stupid. If the sequence in which a certain
set of actions is applied does not have any impact on the final result, then the issue is
said to be commutative. Commutative functions are commutative because, regardless
of the sequence in which we assign values to variables, we always end up with the same
partial assignment outcome. It is thus sufficient for us to take into consideration simply
169 | P a g e
every branch of the search tree has one variable. If we were to colour the map of
Australia, for example, we could choose between SA = red, SA = green, and SA = blue
at the root node of a search tree. Having said that, we would never choose between SA=
red and WA= blue. As we would have hoped, the number of leaves is reduced to dn as
a result of this limitation.
Table 6.3 An approach for constraint fulfilment issues that is straightforward and
uses backtracking. The recursive depth-first search serves as the source of
inspiration for the method.
Source: Artificial Intelligence A Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
Backtracking search is a kind of depth-first search that selects values for one variable
at a time and then backtracks when a variable has no more legal values to assign.
Backtracking search is a phrase that is used to describe this type of search. Figure 6.5
depicts the algorithm that might be used. When it is attempting to discover a solution,
it continually selects a variable that has not been given a value, and then it attempts
each value that falls inside the domain of that variable in turn. In the event that an
inconsistency is identified, the backtrack function will return failure, which will cause
the preceding call to attempt a different value.
Figure 6.6 is a portion of the search tree that we have made for the Australia problem.
In this particular search tree, Various variables have been assigned in the following
order: WA, NT, Q, etc. Your domain-specific starting state, action function, transition
170 | P a g e
model, and goal test are not required to be provided to BACKTRACKING-SEARCH.
The uniform representation of CSPs is the reason behind this.
Be aware that, contrary to what is said above, BACKTRACKING-SEARCH does not
create new representations of states but rather alters the ones that already exist.
Using our knowledge of the scenario to build domain-specific heuristic functions, we
improved the underwhelming performance of naive search algorithms. We have
learned that such domain-specific knowledge is unnecessary for solving CSPs
efficiently. In order to solve these problems, we might alternatively make the functions
not shown in Figure 6.5 more complicated and apply them to the following questions:
1. Which variable would you want to assign next using the select-unassignedvariable command? Then, in what sequence should we evaluate its values using
the ORDER-domain-values command?
Figure 6.2 depicts a portion of the search tree that was used to solve the mapcoloring issue.
Source: Artificial Intelligence a Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
2. When doing the search, what kinds of inferences need to be carried out at each
stage (INFERENCE)?
3. If the search finds an assignment that violates a constraint, is it possible for the
search to avoid making the same mistake again for the same reason? All of
these concerns are addressed in the subsequent subsections, which are listed
171 | P a g e
6.3.1 Variable and value ordering
In the backtracking process, the line is included with the
choose-UNASSIGNED-VARIABLE
straightforward approach is in order to select the next unassigned variable from the set
of {X1, X2, using this static ordering of variables to conduct the most efficient search
is highly unlikely. Take Figure 6.6 as an example. After WA and NT are assigned red
and green, the only possible value for SA is blue. Instead of allocating Q next, it makes
more sense to assign SA = blue. This is due to the fact that SA can only take on a single
value. The truth is that once SA is assigned, the choices for Q, NSW, and V are fixed
and cannot be altered.
This gut feeling tells us to pick the variable with the fewest "legal" values; this heuristic
is called the minimum-remaining-values (MRV) heuristic. Also known as the "failfirst" or "most constrained variable" heuristic, it has seen some use. The second part of
the name is that it narrows the search tree by picking a variable that would most likely
fail soon, thereby lowering its size. If a certain variable X does not have any valid
values left, the MRV heuristic will select X, and failure will be immediately apparent.
Doing so will avoid the needless exploration of additional factors. Typically, the MRV
heuristic outperforms static or random ordering by a factor of a thousand or more.
Nonetheless, depending on the specifics of the situation, the outcomes might be
substantially different.
When it comes to selecting the first area to colour in Australia, the MRV heuristic is of
no use at all. This is due to the fact that initially, each region has three colour that are
legal. It is helpful to have the degree heuristic available in this scenario. It does this by
picking the variable that is involved in the greatest number of constraints on other
variables that have not yet been assigned. This is done in an effort to lower the
branching factor that affects future selections.
With the exception of T, which has a degree of zero, the remaining variables in Figure
6.1 have degrees of two or three, with the exception of SA, which has the greatest
degree, which is five. In point of fact, once SA has been selected, the issue can be
solved by using the degree heuristic without any false steps being taken. This means
172 | P a g e
that you may choose any colour that is consistent at each decision point and yet arrive
at a solution without having to go backwards. Although the minimum-remainingvalues heuristic is often a more effective guide, the degree heuristic might be helpful
in situations when there is a tie between two options.
Whenever a variable has been chosen, the algorithm is required to make a decision
about the sequence in which its values will be examined. For this purpose, In certain
cases, the least-constraining-value heuristic might prove to be beneficial. In the context
of the constraint graph, it favors the value that precludes the fewest alternatives for the
adjacent variables. Think about this situation: We have made the partial assignment in
Figure 6.1 with WA = red and NT = green; now we may go on to Q. The scenario's
partial assignment has been produced. It would be a poor decision to go with blue since
it would remove the final remaining lawful value for Q's neighbours, SA.
Therefore, the heuristic with the least limiting value indicates that red is preferable than
blue. To put it another way, the heuristic is attempting to allow as much room for
flexibility as possible for following variable assignments. In the event that we are not
just looking for the first answer to a problem, but rather all of the solutions to the issue,
then the ordering does not matter since we are required to take into account every value
regardless. In the event that there are no answers to the issue, the same remains true.
Why should the selection of variables be the first to fail, but the selection of values be
the last to fail? When applied to a broad range of issues, it has been discovered that by
pruning larger parts of the tree sooner, the number of nodes in the search tree can be
reduced using an ordering of variables that chooses a variable with the fewest
remaining values. We only need one answer for value ordering; thus, it makes logical
to look for the most likely values first as they are the ones most likely to be correct.
Using value ordering would be pointless if our goal was to find all viable answers
instead of just one.
6.3.2 Integrating inference and search
We have already seen that AC-3 and similar algorithms may deduce domain-ofvariables reductions prior to beginning the search. Everything up to this point has been
covered in our discussions. While doing a search, inference may prove to be
significantly more effective: with each variable value selection, we are presented with
a fresh opportunity to infer additional domain reductions on the adjacent variables.
173 | P a g e
One of the simplest forms of inference, it is known as forward checking. The forwardchecking process ensures that X always has arc consistency whenever it is allocated.
The procedure is as follows: for each constraint-related unassigned variable Y, subtract
from its domain any value that contradicts the value chosen for X. Given that forward
checking can only draw conclusions on arc consistency, it would be pointless to execute
it after performing arc consistency as a preprocessing step.
Figure 6.7 shows the backtracking search progression for the Australia CSP, which also
incorporates forward checking. It is important to highlight two key points about this
case. To begin, take note of the fact that after WA = red and Q = green are assigned,
the domains of NT and SA are reduced to a single value. This means that we have
completely eliminated branching on these variables by propagating information from
WA and Q. There is a second thing to take note of, and that is the fact that the domain
of SA is empty after V = blue. Because of this, forward checking has determined that
the partial assignment {WA = red, Q = green, V = blue} does not conform to the
constraints of the issue. As a result, the algorithm will instantly revert to its previous
Combining the MRV heuristic with forward checking will make the search more
efficient for a great deal of the issues that we are trying to solve. If you have a look at
Figure 6.7 after you have assigned {WA = red}. It would seem, based on our intuition,
that this assignment places constraints on its neighbors, NT and SA, and hence we need
to deal with them.
Table 6.4 What is the current status of a map-coloring search that includes
forward checking? The first step is to set the value of WA = red. After that,
forward checking removes red from the domains of the variables NT and SA that
are next to it.
Source: Artificial Intelligence A Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
174 | P a g e
variables after that, and after that, all of Everything else will work out as it should.
However, this is exactly what happens with MRV: first, we choose the first value from
NT and SA (both of which have two options), then we choose the second value, and so
on for Q, NSW, and V. Finally, T retains its three possible values; any one of them can
be employed. To help the MRV heuristic carry out its tasks, forward checking can be
seen as a viable option for progressively calculating the data it needs.
There are certain inconsistencies that forward checking misses, even though it finds
almost all of them. Unfortunately, it only takes care of making the current variable arcconsistent and doesn't check to see if all the other variables will be arc-consistent as
well. Look at Figure 6.7's third row as an example. This proves that NT and SA must
be blue when WA is red and Q is green. This remains true in every situation. Forward
checking fails to detect inconsistencies because it does not look far enough forward.
There can be no equality in value between NT and SA because they are adjacent.
This pattern of inconsistency is identified via a method known as MAC, which stands
for Maintaining Arc Consistency (MAC). The INFERENCE function invokes AC-3
after a value has been assigned to a variable Xi. However, rather than starting with to
start with, for each Xj that is an unassigned variable and Xi's neighbours, we just need
the arcs (Xj, Xi) from the CSP queue. Next, AC-3 follows the standard procedure for
constraint propagation. The call to AC-3 fails if the domain of any variable is reduced
to the empty set, and we know we need to go back to the beginning if this happens. It
is clear that MAC is superior than forward checking because both methods get the same
result on the initial arcs in MAC's queue. While MAC recursively transmits limitations
whenever variables' domains are modified, forward checking does not. This proves
beyond a reasonable doubt that MAC has superior power over forward checking.
6.3.3 Smart retracement: Looking in the other direction
When a search branch fails, the BACKTRACKING-SEARCH algorithm (shown in
Figure 6.5) follows a pretty simple protocol. This strategy involves going back to the
previous variable and trying to figure out what it may be instead of its current value.
This approach is called chronological retracing since it involves reviewing the most
recent decision point. This paragraph takes into account better choices.
In Figure 6.1, we can observe the results of simple backtracking applied to the variables
Q, NSW, V, T, SA, WA, and NT in a fixed variable ordering. The partial assignment,
175 | P a g e
which we have made, looks like this: Q= red, NSW= green, V= blue, and T= red. When
we test out the next variable, SA, we find that every single value breaks a rule.
Returning to the letter T, we try out a different shade of blue for Tasmania! Changing
the colour of Tasmania won't fix the problem with South Australia, thus it's clear this
is a bad idea.
Returning to a variable that may have supplied the solution is a reasonable first step in
the retracing procedure. An example of a variable that may make some SA values
impossible is this one. In order to do this, we will keep track of a set of assignments
that go against a specific value for SA. The set that is called the conflict set for SA in
this case is {Q = red, NSW = green, V = blue}. In order to complete the most current
assignment in the conflict set, one might use the back jumping approach. In this case,
attempting a new value for V would involve back hopping over Tasmania. By
modifying the BACKTRACK function, this method may be easily created to
accumulate the conflict set while also checking for an acceptable value to assign. If the
method cannot find a legal value, it should display the failure flag and the most recent
member of the conflict set.
If the reader is paying close enough, they will have seen that forward checking may
provide the conflict set information automatically. This is due to the fact that for every
instance when X = x is used for forward checking and Y's domain is updated, X = x
should be added to Y's conflict set. If the last value is removed from Y's domain, the
assignments in the conflict set of Y are also added to the conflict set of X. We know
exactly where to turn around if we need to when we get to Y because of this.
Any reader with keen eyes would have seen something peculiar: back hopping happens
when every value in a domain is in conflict with the assignment that is currently being
used. However, forward checking is able to identify this occurrence and prevent the
search from ever reaching a node that is in conflict with the assignment. One may
demonstrate that any branch that is trimmed by back leaping is likewise pruned by
forward checking. This is a truth that can be shown. When doing a search that involves
forward-checking or, more specifically, when conducting a search that makes use of
greater consistency checking, such as MAC, simple back leaping is thus unnecessary.
In spite of the observations made in the paragraph before this one, the concept of back
jumping continues to be a sound one: to retrace one's steps, taking into account the
factors that led to failure. Back jumping is able to detect failure when the domain of a
176 | P a g e
variable becomes empty; however, in many instances, a branch is doomed long before
this happens. Again, let us take into consideration the partial assignment {WA = red,
NSW = red}, which, as we discussed before, is an inconsistent assignment. The next
step would be to allocate NT, Q, V, and SA after checking that T equals red. As a result
of the fact that we are aware that no assignment can be successful for these last four
variables, we will finally run out of values to attempt at NT.
Right now, the issue is, where should we go backwards? Due to the fact that NT does
contain values that are compatible with the variables that were assigned before it, back
jumping is not possible does not contain a comprehensive conflict set of previous
variables that led to its failure before it was implemented. We are aware, on the other
hand, that the four variables NT, Q, V, and SA, when taken together, ended up failing
due to a set of preceding variables. These preceding variables must be those factors that
are in direct opposition to the four variables. When this is taken into consideration, a
more profound understanding of the conflict set for a variable like NT emerges: it is
the set of variables that came before it that led to NT, along with any variables that
came after it, not having a solution that is consistent. Given that the set consists of
Western Australia and New South Wales, the algorithm ought to return to New South
Wales and ignore Tasmania. This kind of back jumping algorithm is referred to as
conflict-directed back jumping. It makes use of conflict sets that are constructed in this
The computation of these new conflict sets is something that has to be explained today.
This strategy is really fairly easy to understand. In every instance, when a variable's
domain becomes empty and a standard conflict is set, the "terminal" failure of that
branch of the search occurs. For our situation, SA fails and produces a conflict set like
{WA, NT, Q}. If we go back to Q, we'll see that it takes the SA conflict set and adds it
to its own direct conflict set, called {NT, NSW}; the resultant conflict set is as follows
{WA, NT, NSW}.
That is to say, there is no solution from Q forward, especially in light of the assignment
that came before it to {WA, NT, NSW}. It is for this reason that we return to NT, which
is the most current of them. NT incorporates {WA, NT, NSW} −{NT} into its own
direct conflict set {WA}, resulting in the formation of {WA, NSW} (as has been
mentioned in the preceding paragraph). Now, the algorithm leaps back to New South
Wales, as we had hoped it would. Let's say that the current variable is denoted by Xj,
and the conflict set associated with it is denoted by conf (Xj). Make a backwards leap
177 | P a g e
to the most recent variable Xi in the configuration file (Xj) and set it if every
conceivable value for Xj is unsuccessful.
When we come into a contradiction, back jumping may provide us with information on
how far to go backwards. This allows us to avoid wasting time by altering variables
that will not resolve the issue. We would, however, wish to avoid encountering the
same difficulty once again if at all possible. In the event that the search yields a
contradiction, we are aware that the issue is caused by a particular segment of the
collection of conflicts. Finding the minimal collection of conflicting variables that
contribute to the current problem is what constraint learning is all about. A "no-good"
collection is one that has all of these variables and the values that go along with them.
Afterwards, we make note of the bad by either incorporating a new restriction into the
CSP or by keeping a distinct cache of bads. Here we will go over both of these
approaches.
Consider the state {WA = red, NT = green, Q = blue} in the bottom row of Figure 6.6
as an example. Since SA does not have a valid assignment, we can tell that this state is
bad via forward checking. In this case, recording the no-good would serve no use
because we would never see this combination again after removing this branch from
the search tree. However, let's pretend that Figure 6.6's search tree was actually a part
of a larger search tree that started by giving values to the V and T places beforehand.
Since we will face the same problem for all possible combinations of V and T
assignments, it might be wise to mark {WA = red, NT = green, Q = blue} as a no-good.
We will encounter the same issue once more; therefore, this is necessary. Forward
checking and back jumping are two great ways to make effective use of no-goods.
Constraint learning is one of the most important tactics used by modern CSP solvers to
improve performance while dealing with complex problems.
6.4 LOCAL SEARCH FOR CSP
It turns out that local search algorithms, which are discussed in Section 4.1, are
successful in solving a lot of CSPs. They use a formulation known as a complete-state
formulation, in which the starting state gives a value to each and every variable, and
the search process alters the value of one variable at a time. An example of this would
178 | P a g e
be the 8-queens issue, which is shown in Figure 4.3. In this scenario, the starting state
may be a random arrangement of eight queens in eight columns, and each step would
involve moving a single queen to a new location inside its column. Most of the time,
the first estimate violates a number of different criteria. When using local search, the
goal is to get rid of the limitations that have been violated.
The most apparent heuristic to use when selecting a new value for a variable is to
choose the value that will result in the fewest number of conflicts with other variables.
This is referred to as the min-conflicts.
Table 6.5 CSPs may be solved using the MIN-CONFLICTS method, which is a
local search algorithm. Random selection or a greedy assignment procedure that
selects a minimum conflict value for each variable in turn may be used to choose
the starting state. Both of these methods are viable options.
Figure 6.3 For a problem with eight queens, a two-step solution that makes use
of minimum conflicts. At every level, a queen is selected to be reassigned in the
column that corresponds to it.
Source: Artificial Intelligence a Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
179 | P a g e
A heuristic approach. This procedure is shown in Figure 6.8, and Figure 6.9 is a
diagrammatic representation of how it might be used to a situation involving eight
queens. The success rate of min-conflicts in CSPs is unexpected. The interesting thing
about the n-queens problem is that, if the initial placement of queens is ignored, the run
time of min-conflicts is almost unrelated of the size of the problem. It can solve the
problem of a million queens in around fifty steps on average (after the initial
assignment).
As we'll see in this groundbreaking realisation sparked a flurry of activity in the 1990s
about local search and the categorization of scenarios as either easy or hard. Since the
solutions are scattered all throughout the state space, n-queens is easy to use for local
search. A further useful option for challenging situations is min-conflicts. One example
is its usage in scheduling observations for the Hubble Space Telescope; thanks to this,
the time needed to schedule a week's worth of observations is now a mere 10 minutes,
down from three weeks (!).
Each of the local search strategies described in Section 4.1 is a potential candidate for
application to CSPs, and a few of those strategies have shown to be particularly
successful. In accordance with the mi conflicts heuristic, the landscape of a CSP often
consists of a number of plateau instances. A solution could be found for each of the
Countless variable assignments that are awaiting resolution, with just a single dispute
remaining. To get off this plateau, local search can use plateau search, which lets you
go sideways to another state with the same score. It is possible to direct this plateau
meandering with the tabu search method. This search method involves maintaining a
tiny list of states that have been visited lately and preventing the programme from
returning to those places. Escape from plateau may also be accomplished via the use of
simulated annealing.
One further method, which is known as constraint weighting, may assist in focusing
the search on the most significant constraints. At the outset, each constraint is assigned
a numeric weight, denoted by Wi, which is all 1. The method selects a variable/value
pair to modify at each stage of the search process. This is done with the intention of
achieving the lowest possible total weight of all constraints that have been violated.
The weights are then modified by increasing the weight of each constraint that is
violated by the present assignment. This takes place after the weights have been
changed. There are two advantages to this: first, it adds topography to plateau, which
180 | P a g e
ensures that it is feasible to improve from the present condition; second, it gives weight
to the limitations that are proving to be tough to address over time.
In the event that the issue is altered, local search may also be used in an internet
environment, which is yet another benefit related to it. The significance of this cannot
be overstated when it comes to timing issues. It is possible for a plane to operate
hundreds of flights and assign tens of thousands of employees this week; but, if there
is extreme weather at a single airport, the timetable may become impossible to follow.
In order to fix the timetable, we would want to make any necessary adjustments as little
as possible. With the help of a local search algorithm, this may be accomplished with
relative ease, beginning with the present timetable. In most cases, searching in reverse
using the updated set of restrictions will need a significant amount of additional time,
and it may yield a solution that involves a significant amount of deviation from the
present timetable.
181 | P a g e
AGENTS OF LOGIC
7.1 AGENTS RELYING ON EXPERTISE
A knowledge-based agent's knowledge base, often known as KB, is the most important
aspects of the agent. An assortment of phrases constitutes a knowledge foundation.
 .
184 | P a g e
The chance of discovering a lump of gold is the only thing that can be considered a
positive aspect of this desolate setting. Despite the fact that the world of the Wumpus
is quite simple when compared to the worlds of contemporary computer games, it
demonstrates a number of significant aspects of intelligence.
The Wumpus planet that is depicted in Figure 7.2 is an example. Following the
recommendation made in Section 2.3, the PEAS description provides the detailed
description of the work setting, which reads:
• Performance measure: One point is deducted for each action done, ten points
are deducted for using up the arrow, and one point is deducted in order to get
the treasure from the cave. One point is deducted for falling into a hole or
getting devoured by the Wumpus. When the agent either passes away or climbs
out of the cave, the game is over. Both of these outcomes are possible.
Environment: A four-by-four room layout. The square designated "right" on
the board is where the agent will always start. Locations of the Wumpus and
gold are chosen at random from the squares, following a regular distribution,
with the exception of the initial square. that are found in the game. Additionally,
with a probability of 0.2, any square that is not the starting point has the
potential to be a pit.
Actuators: The agent has the ability to go forward, turn left 180 degrees, or
turn right 90 degrees. In the event that the agent approaches a square that
contains either a pit or a living Wumpus, it will suffer a painful end. " You may
enter a square with a dead Wumpus without fear of odour, even if it will be
unpleasant. Whenever an agent encounters a wall while trying to progress, they
are rendered unable to go beyond that point. If the agent and the gold are in the
same square, the agent may grab the gold by performing the Grab action.
A straight arrow pointed in the direction of the agent's face may be fired by
using the action Shoot can be implemented. The trajectory of the arrow will
continue until it either strikes the Wumpus, causing it to die, or it strikes a wall.
There is only one arrow available to the agent, therefore the first Shoot action
is the only one that has any impact. Climb is the final action that may be used
to climb out of the cave; however, it can only be utilised after starting from
185 | P a g e
• Sensors: A single piece of information is provided by each of the five sensors
that are a part of the agent:
• A Stench will be perceived by the agent in the square that contains the Wumpus
as well as in the squares that are directly adjacent to it (the diagonally adjacent
• It is possible for the agent to detect a breeze in the squares that are immediately
near to a pit.
• A Glitter will be seen by the agent in the square where the gold is located.
• A Bump will be felt when the agent walks into a wall.
• The death of a Wumpus causes it to let out a sad scream that can be heard throughout
The agent software will be given a list of five symbols that represent the percepts. For
example, if there is a wind and a scent but no sparkle, bump, or scream, the agent
programme will understand that there is a breeze but no glitter. programme will obtain
the percepts. It is possible for us to characterise the surroundings of the Wumpus along
the many aspects that are presented in Chapter 2. Evidently, it is a single-agent system
that is discrete and static. (To our excellent fortune, the Wumpus does not move.) It is
sequential due to the fact that benefits could not appear till after performing a great deal
Figure 7.2 The world of a normal Wumpus. In the bottom left corner, facing right,
is where you will find the agent.
Source: Artificial Intelligence: A Contemporary Approach to Data Gathering and
Processing by Stuart J. Russell and Peter Norvig in 2010.
186 | P a g e
There are some characteristics of the condition that cannot be directly perceived, such
as the position of the agent, how well the Wumpus is doing right now, and whether or
not an arrow is available. On the other hand, you can see it to a point. The locations of
the pits and Wumpus, on the other hand, may be thought of as unseen parts of the state
that are unchangeable. If this is the case, then the transition model for the environment
would be entirely different. known; alternatively, one might argue in this case, the
agent's understanding of the transition model is uncertain since they do not know which
Forward actions are fatal. transition model is completed when the locations of pits and
Wumpus are discovered.
The most significant obstacle that an agent's initial ignorance about the environment's
setup is a significant obstacle it must overcome.; it appears that logical thinking is
required in order to overcome this lack of knowledge. It is feasible for the agent to
collect the gold in a secure manner in the majority of situations that occur in the
Wumpus universe. On occasion, the agent is forced to make a decision between
returning home without any gold and taking the danger of dying so that the gold may
be found. About 21% of the sceneries are totally unfair since the gold is in a pit or
surrounded by pits.
The environment depicted in Figure 7.2 is being explored by a Wumpus agent that is
based on previously acquired information. As shown in Figures 7.3 and 7.4, we make
use of a language that is used for the informal representation of knowledge. This
language consists of jotting down symbols in Grids.
The rules of the environment are stored in the initial knowledge base of the agent, as
was previously explained. In particular, the agent is aware that the item is in and that
the square in question is secure; we denote these things with a "A" and a "OK,"
respectively, in the square.
According to the initial perception, which is [None, None, None, None, none], the agent
is able to draw the conclusion that the squares that are adjacent to it are risk-free and
that they are in good condition. A representation of the agent's current level of
knowledge may be found in Figure 7.3(a). The only square that a cautious agent will
walk into is one that it is aware of as being safe. Now, let us assume that the agent has
made the decision to go to A light wind (the letter "B") is detected by the agent. in,
which indicates that there must be a pit in a square that is adjacent to it. According to
the regulations of the game, the pit cannot be in the point hence there must be a pit in
187 | P a g e
one or both of those places. In Figure 7.3(b), the notation "P?" serves as an indication
that there is a potential pit in those squares. At this time, there is just one square that is
known to be safe and that has not yet been visited by anyone.
Figure 7.3 The initial action conducted by the agent within the realm of the
Wumpus. (a) The first circumstance, after the perception of (b) Following a
single movement, with percept.
Source: The data collection and processing methods used in artificial intelligence were
updated in 2010 by Stuart J. Russell and Peter Norvig.
The wise agent will thus do a U-turn, return to, and then proceed to as follows: Figure
7.4(a) depicts the state of knowledge that occurs as a result of the agent detecting a
stink in the environment. Because of the smell, it is apparent that there is a Wumpus in
the vicinity. However, the
Figure 7.4 Two further phases of the agent's development. (a) Along after the
third step, with percept [Stench, None, None, None, None]. (a) After the sixth
motion, with the percept at [Stench, Breeze, Glitter, None, None].
188 | P a g e
Source: The data collection and processing methods used in artificial intelligence were
updated in 2010 by Stuart J. Russell and Peter Norvig.
Wumpus is not allowed to be in the game since the laws of the game prohibit it, and if
it were, the agent would have detected a stink when it was already present. As a result,
the agent is able to draw the conclusion that the Wumpus is in. Clearly, this conclusion
is shown by the notation W! Furthermore, the absence of a wind in suggests that there
is no pit in the aforementioned on the other hand, the agent has already deduced that
there must be a hole in one of the two, which indicates that it must be because This is
a pretty challenging inference to make since it integrates information that was acquired
at separate times and in different locations, and it depends on the absence of a firsthand experience to make a single critical step.
It has been demonstrated to the agent that there is neither a pit nor a Wumpus in the
area, and as a result You may move there without any problems. Instead of proving the
agent's present degree of comprehension, we're assuming it will turn and move to give
us Figure 7.4(b). The agent must promptly return to its dwelling after obtaining the
gold from any sparkle it discovers.
It is important to keep in mind that in every instance in it is ensured that the agent's
conclusion, if formed with the supplied knowledge, would be valid so long as the
information that is provided is accurate. This is a key characteristic of thinking that is
based on logic. The remainder of this chapter will be devoted to describing how to
construct logical agents that are capable of representing information and drawing
conclusions similar to those that were discussed in the paragraphs that came before this
This section provides a concise yet comprehensive overview of the essential ideas of
reasoning based on logical representations. All of the particular shapes that reasoning
may take are irrelevant to these fantastic ideas. So, we will use the famous example of
ordinary mathematics and put off discussing the technical details of those forms until
the next part.
The idea that sentences serve as the foundation of knowledge bases was discussed in
Section 7.1. The representation language's syntax defines all correctly built sentences,
189 | P a g e
and all of these assertions are represented in line with it. While "x + y = 4" is a wellformed statement in the domain of conventional mathematics, "x4y+ =" is not. This
demonstrates that the idea of syntax is sufficiently apparent.
Determining the semantics, or meaning, of sentences is another requirement for a logic.
The semantics determines the truth of each phrase in relation to all of the different
worlds that might exist. For instance, according to the semantics of arithmetic, the
statement "x + y = 4" is correct in a universe in which x is equal to two and y is equal
to two, but it is incorrect in a world in which x is equal to one and y is equal to one.
According to the traditional Each statement must have an absolute truth value in logic.
in every conceivable universe; there is no "in between" in this approach.
Instead of using the phrase "possible world," we use the term "model" when we need
to be completely exact. All models do is find out if every relevant assertion is true or
untrue; they are mathematical abstractions. On the other side, possible worlds may be
seen as environments where the agent might or might not be present. As an example of
a more casual manner of considering a possible world, let's say that x men and y women
are sitting at a table playing bridge, and that the equation x + y = 4 holds true when
there are four people in total. All the possible values of x and y, expressed as real
numbers, are the potential models.
Figure 7.5 Several hypotheses that might explain the existence of pits in squares
the solid line is the KB that corresponds to the observations of their being nothing
in and a wind in. Models of α1 (no pit) are shown by the dot-line in (a). Dotted
lines are used to represent models of α2.
Source: Artificial Intelligence: A Contemporary Approach to Data Gathering and
Processing by Stuart J. Russell and Peter Norvig in 2010.
190 | P a g e
In its most conventional use, this is the word. Any mathematical expression with x and
y as variables may have its validity corrected by any of these assignments. This
sentence is true in model m if and only if model m meets assertion α. One might also
argue that m is a model of α in some cases. In order to denote the collection of all
models of α, we employ the notation M(α).
The topic of logical thinking is ready to be discussed now that we have a concept of
what constitutes the truth. In this context, the concept of logical entailment refers to the
relationship between sentences, which is the idea that one statement ought to flow
inferentially from a different phrase. This statement is expressed as α |= β in
mathematical notation.
The idea that the statement α includes the sentence β is what I'm trying to convey. This
is one way to put entailment into formal definition: Can we state that α is identical to β
if (and only if) in every model where α is true, β is also true? The notation that was just
given allows us to write
(Take note of the direction of the ⊆ in this context: if α is equal to β, then α is a more
robust claim than β, since it eliminates a greater number of potential worlds.) We are
satisfied with the idea that x= 0 implies xy= 0 since we are also acquainted with the
mathematical relation of entailment. In every model where x is zero, it is guaranteed
that xy is zero, independent of y's value. It makes no difference what the situation is.
When it comes to the Wumpus-world reasoning example that was presented in the part
before this one, we are able to use the same sort of analysis. Take a look at the scenario
depicted in Figure 7.3(b): In addition to a wind, the agent has not found anything in the
area. It is the combination of these perceptions and the agent's familiarity with the laws
that govern the Wumpus universe that makes up the KB.
The agent is interested in a number of things, one of which is whether or not the squares
that are near to each other have pits. In this case, there are three possible squares, each
of which may or may not include a pit. Consequently, there are a total of 23 models,
which is equal to eight different possibilities. Figure 7.5 depicts these eight different
models. Look at it!
191 | P a g e
One might think of the KB as a collection of phrases or as an assertion including all
phrases that are included in the collection. The knowledge base is incorrect in models
that are in direct opposition to what the agent is aware of; for instance, the knowledge
base is incorrect in any model that includes a pit because there is no breeze in the pit.
In point of fact, there are only Three models are shown in Figure 7.5, where the KB is
exact. being encircled by another solid line. Now, let us take into consideration two
different perspectives:
Through the use of dotted lines, the models of α1 and α2 are outlined in Figures 7.5(a)
and 7.5(b), respectively. Following is what we observe upon closer inspection:
In each and every model where KB is true, α1 is likewise true by definition.
Because of this, KB is equal to α1, which indicates that there is no pit in Another thing
that we may see is that in certain models, while KB is true, α2 is not true.
Since KB is equal to α2, it follows that the agent cannot reach the conclusion that there
is no pit, nor can it reach the conclusion that there is a pit.
In addition to demonstrating entailment, the example that came before it also
demonstrates what logical inference is and how it may be used to the notion of
entailment in order to draw conclusions. Figure 7.5 depicts an inference approach
known as model checking. This method is called model checking because it lists all
possible models to check whether α is true in every model where KB is true or if M(KB)
is a subset of M(α).
If one wants to understand entailment and inference more clearly, it might help to think
of all the implications of KB as a haystack and α as a needle. Entailment is like the
needle already being there, as contrast to inference, which is like trying to locate a
needle in a haystack. A formal notation may be used to represent this difference: if an
inference method i can derive α from KB, then we can write
192 | P a g e
The phrase " either "i derives α from KB" or "α is derived from KB by i." " is the
pronunciation of this phrase.
The term "sound" or "truth preserving" refers to an inference method that only
generates sentences that contain essential elements. A property that is very valued is
one that is sound. The announcement of the finding of needles that do not exist is an
example of an unsound inference technique, which basically simply makes stuff up as
it goes along. It should come as no surprise that model checking is a reliable method,
provided that it is necessary to do so.
Another desired attribute is completeness. An inference technique is said to be
complete if it can create every sentence that is involved in the inference process. The
reality that the presence or absence of a needle in a haystack can always be ascertained
with a methodical examination is something that appears to be clear when dealing with
genuine haystacks, which have a limited extent. However, the haystack of
repercussions is limitless for many knowledge bases, and completeness becomes a
crucial issue as a result of this.5. The good news is that there exist comprehensive
inference processes for logics that are sufficiently expressive to deal with a wide variety
of knowledge bases.
The method of reasoning that we have described is one in which the In any possible
world where the premises hold, the conclusions will also hold. To be more specific,
any phrase α that is derived from KB using a sound inference approach is also true in
the real world if KB is true in the actual world. Inference procedures revolve on
"syntax," which denotes the fundamental physical arrangements of a system, such the
patterns of electrical blips in the brain or the bits in a register. Still, the procedure lines
up with the grammar.
Figure 7.6 When an agent uses reasoning, they are creating new physical
configurations from existing ones; sentences are the agent's physical
configurations.
193 | P a g e
Source: The data collection and processing methods used in artificial intelligence were
updated in 2010 by Stuart J. Russell and Peter Norvig.
to the connection that exists in the actual world, in which one feature of Because other
aspects of the actual world are true, the real world is true overall. This illustration
illustrates the relationship that exists between the world and representation.
The last thing to take into consideration is grounding, which refers to the relationship
that exists between the processes of logical thinking and the actual world in which the
agent resides. Specifically, how can we be certain that KB is accurate when applied to
the actual world? (Knowledge, after all, is nothing more than "syntax" in the mind of
the actor.) The answer to this philosophical dilemma has been the subject of a great
number of works on the subject. (For further information, see Chapter 26.) An easy
explanation would be that the link is established by the sensors of the agent. As an
illustration, our agent from the Wumpus planet has a smell detector. The agent software
will provide a situationally relevant comment the moment it senses an Oduor.
Whenever a statement is added to the knowledge base, it automatically becomes true
in the real world. Accordingly, the significance and veracity of these expressions are
decided by the sensory and sentence-forming systems that generate perceptual
sentences. However, what happens to the rest of the agent's data, such its belief that
nearby squares' Oduors originate from Wampuses? Although it may be based on past
perceptual experience, this is not an exact depiction of any one percept; rather, it is a
rule of thumb that has been developed from such observations. This and similar basic
concepts are the result of a method of sentence creation called learning, which is
covered in Part V. There are certain problems with learning. Except on February 29th
in leap years, when Wumpus bathe, it's possible that Wumpus are to blame for
unpleasant smells. Consequently, KB may not be applicable in the real world; yet, there
is reason to be hopeful when one uses efficient learning methods.
7.4 THE PROPOSED LOGIC: AN EXTREMELY BASIC LOGIC
An easy-to-understand yet very effective mode of reasoning, propositional logic will
be covered here. Here we'll go over the grammar and semantics of propositional logic,
the language used to describe assertions' truth values. After that, we'll take a look at
entailment—the connection between a phrase and the sentence that follows it—and
how it contributes to the development of a simple procedure for logical inference. The
Wumpus world is obviously the setting for all of this.
194 | P a g e
7.4.1 Language Structure
For propositional logic, the rules of syntax specify which statements are valid. Each
atomic phrase is composed of a single symbol that stands for that idea. On both cases,
each of these symbols stands for a notion that could or might not be true. A few
examples of the symbols we employ include North, W1, R, Q, and P. Every one of
these symbols starts with an uppercase letter and could have subscripts or more letters
after it. To represent the proposition that the Wumpus is in, we use the symbols W1,3.
Keep in mind that symbols like these are atomic, thus the parts of the symbol that are
not relevant are W, 1, and 3.
The names are selected arbitrarily, but they are frequently chosen to have some
mnemonic significance. Both True and False are proposition symbols that have definite
meanings. True represents the proposition that is always true, while False represents
the proposition that is always false. The use of brackets and logical connectives as
building blocks allows for the construction of more complex statements from smaller
phrases. The following are the five connectives that are typical:
Figure 7.7 A Backus-Naur Form (BNF) grammar of propositional logic
sentences, with operator precedence’s listed from most significant to least.
Source: Computing with AI: A Contemporary Perspective on Gathering and Analysing
Data by Stuart J. Russell and Peter Norvig in 2010.
offers a formal framework for reasoning based on propositions; If the BNF notation is
foreign to you, please go to page 1060. When taken by itself, the BNF grammar is
ambiguous; a phrase that contains numerous operators can be processed by the
195 | P a g e
grammar in a number of different patterns. For the purpose of removing any
misunderstanding, we have established a priority for every operator. In the equation
¬A ∧ B, the ¬ binds the most firmly since the "not" operator (¬) is the most important.
Therefore, the correct form is (¬A) ∧B instead of ¬(A∧B). −2+4 is written as 2, not –
6. This is because the notation for simple arithmetic is the same. When you are unsure
of how to interpret anything, use brackets to ensure that you are correct. There is no
difference between the meaning of square brackets and that of brackets; the primary
purpose of using either square brackets or brackets should be to make it simpler for a
human being to interpret a phrase.
7.4.2 Definitions of Terms
Following the specification of the syntax of propositional logic, the semantics of this
logic will now be described. The criteria that are used to determine whether or not a
statement is true in relation to a certain model are defined by the principles of
semantics. Within the realm of propositional logic, a model only establishes the truth
value, which pertains to whether a proposition symbol is true or false. As an illustration,
given that the phrases included inside the database use the proposition symbols P1,2,
P2,2, and P3,1, among others, one suitable model is
Figure 7.5 depicts the precise set of possible models, out of a total of 23= 8. These
models are based on three proposition symbols. However, it is important to note that
the models are essentially mathematical objects, and they do not necessarily have any
link to Wumpus habitats. Aside from being a sign, the term "P1,2" might mean anything
from "there is a pit in " to "I'm in Paris today and tomorrow."
Given a model, the semantics of a propositional logic statement must specify how to
determine the truth value of that statement. No matter the phrase, this is correct. Yes,
this works in a recursive way. Because all sentences consist of atomic sentences and
the five connectives, we must provide instructions on how to determine the truth of
atomic sentences and how to determine the truth of sentences formed using each of the
five connectives. Atomic sentences have a basic structure:
True and False are always true and false in all models. It makes no difference whatever
model this is applied to. •Every other proposition symbol must have its absolute truth
196 | P a g e
value stated within the model. P1,2 does not hold when using the previously shown
model m1 as an example. There are five general rules for complex sentences that hold
for each pair of subsentences P and Q in any model m (where "if" means "if and only
 If P is not true in m, then ¬P is true.
 P ∧ Q holds if and only if P and Q are true in the set m.
 P ∨ Q holds true if and only if P or Q is true in m.
 Unless both P and Q are true in m, the statement P ⇒ Q is true.
 P ⇔ Q is valid if and only if P and Q are either true or false in m.
It is also feasible to represent the rules through the use of truth tables, which are tables
that define the truth value of a complicated phrase for each conceivable assignment of
truth values to the components of the sentence. Figure 7.8 provides truth tables for each
of the five connectives that are examined. The truth value of each sentence s may be
determined with regard to any model m using a straightforward recursive evaluation,
which can be derived from these tables. Just one example:
Figure 7.8 All five logical connectives have truth tables. First, locate the row to
use the table to determine, for example, the value of P ∨ Q when P is true and Q
is false, it must be placed on the left (the third row) when P is true and Q is false.
Look at that row beneath the P ∨ Q column to discover the real result.
Source: Artificial Intelligence: A Contemporary Approach to Data Gathering and
Processing by Stuart J. Russell and Peter Norvig in 2010.
the sentence
performed in m1 yields the result that Being true plus
false plus true equals being true plus true. To get the truth value of propositional logic,
you are to write the PL-TRUE algorithm in Exercise 7.3.(s, m). It interacts with models
m. sentences s.
197 | P a g e
As far as the English words "and," "or," and "not" closely match our gut feelings about
them. P plus Q is true if either P or Q is true, or both. is true, which is the major point
that might be confused. "Exclusive or" (or "xor" for short) is an alternative connective
that returns false when both disjuncts are true.7 The sign for exclusive or is not
universally agreed upon; alternatives include ∨˙, =, or ⊕.
A person's intuitive grasp from the statements "P implies Q" or "if P then Q"." may not
be fully compatible with the truth table for ⇒. First of all, there needs to be no
connection or causality between P and Q for propositional logic to work. Despite its
somewhat unusual English construction, the statement " makes little sense unless you
consider Tokyo to be Japan's capital. according to the conventional view, a valid
propositional logic phrase. The idea that an inference is true if and only if its antecedent
is untrue is another source of misunderstanding. Take the statement "5 is even implies
Sam is smart" as an example. It is true irrespective of Sam's intelligence. If you interpret
"P ⇒ Q" signifies that "If P is true, then I am claiming that Q is true," then the seemingly
strange statement starts to make sense. Aside from that, I am not claiming anything. If
P is true but Q is untrue, then this phrase can only be false.
Any time both P ⇒ Q and Q ⇒ P are true, the biconditional, P ⇔ Q, is true. "P if and
only if Q." is a common way to express this in English. The Wumpus world's laws are
most effectively expressed using the symbol ⇔. The presence of a pit in a neighboring
square is a necessary condition for a square to be breezy, but it is not sufficient on its
own. Thus, a biconditional is required.
where B1,1 indicates the presence of a wind.
7.4.3 A basic database of information
As soon as After completing the definition of propositional logic's semantics, we will
be able to build a knowledge base for the world of Wumpus. In the beginning, we will
concentrate on the parts of the Wumpus universe that are unchangeable, and we will
save the malleable portions to be covered in a subsequent section. The following
symbols are needed for each location at [x, y] at the moment:
The existence of a pit in the interval [x, y] guarantees that Px,y is true.
198 | P a g e
If [x, y] contains a Wumpus, whether living or dead, then Wx, y is true.
If the agent detects a breeze in the interval [x, y], then Bx,y is true.
Given that the agent detects an Oduor in [x, y], Sx, y is true.
In order to deduce ¬P1,2 (there is no pit in), the sentences that we write will be
sufficient. This is similar to what was done informally in Section 7.3. For the sake of
referring to each phrase, we name it with the letter Ri:
Pits do not exist in:
If there is a depression in one square that borders another, then the square is
said to be breezy. it. The following must be provided for each square; for the
time being, we will only add the squares that are pertinent:
In every Wumpus universe, the statements that came before this one are
accurate. Now, we are going to incorporate the wind perceptions for the first
two squares that the agent has visited in the particular environment that they are
in, which will ultimately lead to the condition depicted in Figure 7.3(b).
7.4.4 A basic method for drawing conclusions
For a certain phrase α, we want to know whether KB is equivalent to α. Did ¬P1,2 play
a role in our KB, for example? Our first inference method is based on a model-checking
strategy that uses the idea of entailment directly. In this method, we list all the models
and check that KB holds in each one to make sure that is true. Every proposition symbol
has a model that indicates whether it is true or untrue. Keeping with our Wumpus-
199 | P a g e
related example, the relevant proposition symbols are B1,1, B2,1, P1,1, P1,2, P2,1,
P2,2, and P3,1. Figure 7.9 shows that out of 128 possible models, 27 are correct. There
are a total of 128 potential models, with seven symbols. Since ¬P1,2 holds true in all
three models, we may conclude that there is no pit in P2,2. However, P2,2 is true in
two models and false in one; so, we cannot tell whether there is a pit in at the moment.
Figure 7.9 is a more direct reproduction of the reasoning shown in Figure 7.5. Figure
7.10 shows the procedure that may be used to determine entailment in propositional
logic in a general way. This approach, TT-ENTAILS, is essentially similar to the
BACKTRACKING-SEARCH algorithm mentioned on page 215, and it recursively
enumerates a limited space of symbols' assignments. Since it puts the idea of entailment
into practice immediately, this method is solid. Additionally, it is comprehensive since
it consistently concludes, regardless of KB and α, and there is a limited amount of
models to examine.
Figure 7.9 For the purpose of the knowledge base described in the book, a truth
table was developed. It is only in three of the 128 rows (the ones that are
highlighted in the right-hand column) where the condition R1 through R5 is
true, which means that KB is true.
Source: Artificial Intelligence: A Contemporary Approach to Data Gathering and
Processing by Stuart J. Russell and Peter Norvig in 2010.
"Few" is not necessarily synonymous with "finitely many," as is true in several
situations. It may be concluded that there are 2n models if both KB and α contain a
total of n symbols. This leads us to believe that the method's temporal complexity is
200 | P a g e
O(2n). Due to the depth-first enumeration, the space complexity is only O(n).), which
is the only possible value. We will demonstrate algorithms that are significantly more
effective in a variety of situations later on in this chapter. Unfortunately, propositional
entailment is co-NP-complete, which means that it is almost as difficult as NP-complete
(for details, see Appendix A). The worst-case complexity of all known propositional
logic inference methods is hence exponential with respect to the input size.
Figure 7.10 In order to determine propositional entailment, a truth-table
enumeration procedure is presented. is legitimate, then α is equal to β. This is true for every sentence
including α and β.
202 | P a g e
Exercise 7.5 requires a proof to be provided. Therefore, in order to determine if α is
equal to β, we may either verify that the statement The inference process shown in
Figure 7.10 accomplishes the truth of (α ⇒ β) in all models, or we may show that it is
equal to True. On the other hand, the deduction theorem states that every statement that
may be deemed an implication sentence has the ability to explain a valid conclusion.
In the end, we will only need the final concept, which is satisfaction. If a given assertion
is true in a certain model or can be fulfilled by that model, we say that the statement is
satisfiable. Figure 7.9 shows that the knowledge base previously exhibited, which is
represented as (R1 ∧ R2 ∧ R3 ∧ R4 ∧ R5), is satisfiable since it is true in three models.
It is feasible to determine whether or not a statement is satisfied by counting all of the
potential models until one is discovered that meets the sentence. Concerning the
challenge of establishing whether or not sentences are "satisfiable" The SAT issue,
which is a case of propositional logic, was the first problem that was demonstrated to
be NP-complete. Numerous issues that arise in the field of computer science are, in
reality, satisfiability issues. As an illustration, each and every constraint satisfaction
issue that is presented in Chapter 6 inquires as to whether or not the constraints can be
pleased by some assignment.
There exists a connection between validity and satisfiability. In other words, if α is
valid, then ¬α is not satisfiable. Conversely, if ¬α is not valid, then α is satisfiable rather
than valid. Also, we have the following result, which is really helpful:
Demonstrating the existence of β from α through the verification of (α ∧ ¬β) being
unsatisfiable is the same as the standard mathematical proving method called reductio
ad absurdum, which means "reduction to an absurd thing." This kind of proof is also
known as proof by refutation or proof by contradiction. One presupposes that a
statement β is false and then proves that this results in a clash with unknown axioms α.
This contradiction is precisely what is meant by the assertion that the sentence (α ∧ ¬β)
is unsatisfiable.
7.5.1 Deduction and demonstration
This part of the article discusses the rules of inference in such a way that it is possible
to draw a proof, which is comprised of a series of inferences that ultimately lead to the
203 | P a g e
desired outcome. outcome. Modus Ponens, which literally translates to "mode that
affirms," is the most well-known rule, and it is written as follows:
Through the use of this notation, it is possible to infer the sentence β Each and every
situation in which statements of the form α ⇒ β and α are identified and present
presented. By way of illustration, if the pairs (Wumpus Ahead ∧Wumpus Alive) and
(Wumpus Ahead ∧ Wumpus Alive) are provided, then it is possible to infer the value
Another helpful rule for inference is the And-Elimination rule, which states that any of
the conjuncts can be inferred from a conjunction with the following conditions:
Take Wumpus Alive as an example; it may be deduced from (Wumpus Ahead ∧
Wumpus Alive).
It is easily shown that Modus Ponens and And-Elimination are mathematically sound
once and for all by considering the probable truth values of α and β. Then, you may get
valid conclusions without having to list models by applying these principles to every
particular case where they apply.
Figure 7.11 shows a set of logical equivalences that may be used as guidelines for
making inferences. As an illustration, the two inference rules can be obtained by
making use of the equivalence for biconditional elimination.
Not every rule of inference can be applied in this way on both ends. To illustrate the
point, we can't use Modus Ponens backwards to get α from β and α from β.
204 | P a g e
Our goal is to find out how Wumpus may make use of these equivalences and inference
rules. To begin, we take the knowledge base that includes R1 through R5 and
demonstrate the steps to establish that ¬P1,2, i.e., that there is no pit. As a first step, we
get R2 by using biconditional elimination to
Next, we get what we need by applying And-Elimination to R6:
In the case of contrapositives, logical equivalence yields
Modus Ponens may be used with R8 and the percept R4 (i.e., ¬B1,1) to get what we
Finally, we apply De Morgan’s rule, giving the conclusion
There is no pit in either or .
Even though this proof has to be found by hand, we can find a proof's stages by using
any of the search strategies discussed in Chapter 3. The following is a basic explanation
of what a proof issue is:
INITIAL STATE: the foundational body of information.
ACTIONS: The collection of actions includes all the inference rules that are
applied to every sentence that meets the criteria given in the first half of that
205 | P a g e
RESULT: The addition of the sentence to the bottom part of the inference rule
is the consequence of an action.
GOAL: We are attempting to prove a sentence, and the objective is to fulfil a
condition that includes the phrase.
Enumerating models is one choice; therefore, seeking for proofs is another alternative.
Finding a proof can be more efficient in many practical situations because the proof
can disregard unimportant propositions, regardless of how many of them there are. This
is true regardless of the number of propositions. To illustrate, the evidence that was
shown previously, which led to the conclusion that the equation ¬P1,2 ∧ ¬P2,1 omitted
the statements B2,1, P1,1, P2,2, and P3,1. Since the goal proposition (P1,2) is unique
to sentence R2, these propositions are irrelevant. Furthermore, only R2 and R4 include
the remaining proposals in R2. Consequently, the proof is unaffected by R1, R3, and
R5. This holds true regardless of how many words are added to the knowledge base;
nevertheless, the simple truth-table method would struggle to handle the exponential
increase in the number of models.
As a final characteristic of logical systems, monotonicity asserts that the quantity of
concerned sentences can only increase with the addition of new information to the
knowledge base.8. For each pair of words α and Η, if KB is equal to α, then KB plus β
is also equal to α.
Consider the following scenario: the knowledge base has an extra claim denoted by the
letter β, which states that there are precisely eight pits in the entire universe. The agent
may be able to draw additional conclusions with the assistance of this knowledge;
nevertheless, it lacks the ability to render unfounded any inferred conclusion α, as the
one that states there is no pit. When suitable premises are found in the knowledge base,
inference rules may be used, which is the idea of monotonicity. So, it doesn't matter
what else is in the knowledge base; the conclusion of the rule still has to be reached.
206 | P a g e
FIRST ORDER LOGIC
8.1 REPRESENTATION REISITED
The features of representation languages will be discussed in the following paragraphs.
Our discussion inspired the development of first-order logic, a language with far greater
expressiveness than the previously offered propositional logic. Our research on
propositional logic and other languages aims to shed light on what works and what
doesn't. Because of the constraints of time and space, we will have to distil thousands
of years of research into just a few phrases.
The second most popular group of formal languages nowadays are programming
languages like C++, Java, or Lisp. When you look at programming, the only things you
can see are computer-related tasks. As an example, the Wumpus world may be
represented by a four-by-four array in a code. This is an excellent illustration of how
important data may be represented using programme data structures. Using the
computer language expression World ← Pit to state that there is a pit at square is
a rather clear way to convey this specific claim.
(These representations may be considered ad hoc; database systems were created to
provide a more generic and domain-agnostic way to store and retrieve data.)
Unfortunately, computer languages do not provide a standard mechanism for creating
new facts from existing ones. Rather, the programmer uses their expertise in the subject
to define the details of a domain-specific method that updates data structures as needed.
The declarative character of propositional logic stands in stark contrast to this
procedural approach; it is defined by the division between knowledge and inference
and by the fact that inference is domain-specific.
If the Wumpus is in, then he is not in; there is no straightforward way to explain things
like that. This is an additional drawback of programmatic data structures (and databases
more generally). The reason behind this is that putting these ideas into words is not
easy. There are systems that allow variables to have no value at all, or even "unknown,"
but these systems don't have the expressiveness to handle partial information well.
Propositional logic is a declarative language by definition since its semantics is based
207 | P a g e
on a truth connection between words and alternative worlds. Furthermore, it has
sufficient expressive capacity to handle partial information via disjunction and
Compositionality is a third and very desired property of propositional logic within the
domain of representation languages. The meaning of a phrase in a language that is partof-something is dependent on the meaning of the pieces that comprise the sentence.
Take, for example, how the phrases "S1,4 ∧ S1,2" are related to the meanings of "S1,4"
and "S1,2." It would be an extremely strange occurrence if the expression "S1,4" meant
that square stinks and "S1,2" meant that square stinks even more, but "S1,4 ∧S1,2"
meant that the ice hockey qualifying match between France and Poland last week ended
in a 1-all draw. Noncom positionality greatly complicates the reasoning system's life,
which is not surprising.
But as we have seen, propositional logic lacks the expressive power to compactly
describe an environment with many objects. For example, we had to write a separate
rule for each square describing breezes and pits, using examples like:
However, it appears simple enough to state unequivocally in English, "Squares adjacent
to pits are breezy." Concise environmental descriptions are somehow attainable thanks
to English's syntax and semantics.
8.1.1 The language of thought
The expressiveness of natural languages, like English and Spanish, cannot be denied.
With the exception of a few rare situations where logic, mathematics, and the language
of diagrams are used, we managed to write almost the whole book in ordinary English.
It has long been held in linguistics and philosophy of language that natural language is
primarily a language for representing declarative knowledge. If we could deduce the
laws that regulate natural language, we could put the billions of pages written in that
language to good use. Because of this, we may use NLP in our reasoning and
representation systems.
Modern thinkers have shifted our focus from natural language's representational role to
that of a medium for communication. If a speaker wants to tell their audience, "Look!"
208 | P a g e
that Superman has finally shown outside on the rooftops, for instance, they may just
point and say it. But we don't want to say that "Look!" represents that reality. To the
contrary, context plays an important role in determining the meaning of a statement,
alongside the sentence itself. A statement like "Look!" cannot be stored in a knowledge
base and its meaning can only be retrieved along with its context, which should be
readily apparent. Because of this, we have to wonder how the context may be depicted.
One problem with natural languages is ambiguity; this is also an issue with
representation languages. Taken from Pinker's book, the following is an excerpt:
"When people think about spring, surely they are not confused as to whether they are
thinking about a season or something that goes boing—and if one word can correspond
to two thoughts, then thoughts cannot be words."
A popular theory called the Sapir-Whorf hypothesis states that our language greatly
influences our perception of the world. Whorf asserts that "We cut nature up,
organise it into concepts, and ascribe significances as we do, largely because we are
parties to an agreement to organise it this way—an agreement that holds throughout
our speech community and is codified in the patterns of our language." Whorf asserts
that "We cut nature up, organise it into concepts, and ascribe significances as we do."
The fact that different language groups conceptualize the cosmos in different ways is
an indisputable fact. While the English language uses a one word, "chair," the French
employ two words, "chaise" and "fauteuil," to describe the same thing. But the Englishspeaking world has a word for the fauteuil category that is quite similar to "open-arm
chair." Is there a true difference in language? We now have tangible proof from
anthropological, psychological, and neurological studies, whereas Whorf depended
mostly on his intuition and theory in the past.
As an illustration, are you able to recall which of the two phrases that can be seen below
served as the introduction to Section 8.1?
For the purpose of this section, we will be discussing the characteristics of
representation languages.
A discussion on the subject of knowledge representation languages is
presented in this section.
In a very similar experiment, Wagner found that participants not only recalled
over 90% of the text they read, but also made the correct selection at the chance level
around 50% of the time. This suggests that people interpret the words in a way that
209 | P a g e
resembles nonverbal communication. An even more intriguing scenario is when a
notion disappears entirely from a language. The indigenous Australians who speak
Guugu Yimithirr do not have any words for relative directions like front, behind, right,
or left. Alternatively, they speak in absolute terms, such when they say "I have a pain
in my north arm." Because of this linguistic gap, individuals act differently: native
Guugu Yimithirr speakers are more adept at finding their way across wide landscapes,
whereas native English speakers know just where to put the fork on the plate. Gender
of nouns and other seeming random grammatical aspects are another way language
seems to impact thinking.
Words like "bridge" have a masculine connotation in Spanish but a feminine one in
German. Boroditsky had participants choose English adjectives that they
thought best described a picture of a specific bridge. German speakers chose beautiful,
exquisite, delicate, and thin, whereas Spanish speakers chose big, dangerous, powerful,
and towering. Words have the power to provide us with a foundational understanding
of the world. Loftus and Palmer screened a film of a vehicle accident to the subjects of
the 1974 study. Respondents to the question, "How fast were the cars going when they
contacted each other?" averaged out 36 mph. Meanwhile, respondents who were asked
the identical question but were asked to use the word "smashed" instead of "contacted"
came up with a speed of 41 mph for the identical cars in the same film.
In a first-order logic reasoning system that uses CNF, we can see that the linguistic
forms "¬(A ∨ B)" and "¬A ∧ ¬B" are identical. Reason being, when we peek inside the
system, we can see that the two phrases are saved in the identical canonical CNF form.
Is it possible that our brains will not let us do it? Their reaction used to be "no," but
now it's more like "maybe." Patients' brains were scanned while they were positioned
in a functional magnetic resonance imaging (fMRI) scanner, according to Mitchell et
al. . They presented the participants words like "celery." Following this, a
computer software may be trained by the researchers to identify the spoken word using
a picture of the subject's brain.
This method achieves a prediction accuracy of 77% in cases when there are two
possible answers (such "celery" or "aero plane"). By considering the images of related
terms, the system can make above-chance predictions for words it has never seen an
fMRI image of before. It can also make predictions for people it has never seen before,
demonstrating that fMRI reveals some level of shared representation among people of
different backgrounds. Functional magnetic resonance imaging (fMRI) and other
210 | P a g e
imaging technologies, like intracranial electrophysiology , may yet
give us considerably more precise descriptions of the representation of human
knowledge, even though this area of study is still in its early stages.
Formal logic maintains that there is no difference between two representations of the
same information; the same facts may be deduced from either representation. But in
reality, it could take less steps to get to a decision using one representation. This implies
that although one representation may not be available to a reasoner with restricted
resources, they may still be able to reach the conclusion. Noneducative activities, like
learning from experience, rely on the shape of the representations employed to
determine the results. We show in Chapter 18 that the shortest theory is usually chosen
to break a tie when a learning programme considers two competing but equally
plausible universe hypotheses that are compatible with all the evidence. The language
chosen to communicate theories determines this option. This means that the impact of
language on cognition cannot be disregarded by any actor involved in the learning
8.1.2 Combining the best of formal and natural languages
Building upon the foundation of propositional logic—a context-independent,
unambiguous declarative compositional semantics—we may create a more expressive
logic. Doing so allows us to sidestep propositional logic's drawbacks while capitalising
on representational conceptions found in natural language. Noun phrases pertaining to
objects (squares, pits, Wampuses) and verb phrases pertaining to interactions among
objects (is breezy, is near to, shoots) are the most obvious components when we analyse
the grammar of natural language. Some of these connections are functions, which are
defined as relationships where each "input" may have just one possible "value." Simple
objects, relations, and functions can be illustrated by the following examples:
Things that fall within this category include homes, numbers, theories, Ronald
McDonald, colour, baseball games, wars, and centuries.
Red, spherical, fake, prime, multi-story, etc. are examples of unary relations; n-ary
relations such as "brother of," "bigger than," "within," "part of," "has colour," "occurred
after," "owns," "comes between," etc. are examples of more general relations.
211 | P a g e
As an actor, he has several characters to play, including those of father, best friend,
third baseman, batting opener, and more. Truthfully, it's easy to see how almost every
claim alludes to things, their attributes, or the connections between them. Here are a
couple of instances:
In mathematics, the statement "one plus two equals three" The objects are 1, 2, 3, and
1 + 2, and the relation is equals. The function is plus. ("One plus two" is the name of
the object generated by applying the function "plus" on the objects "one" and "two."
The production of the item follows from this. It goes by more than just "three" here.
"The squares that are adjacent to the Wumpus have a foul Oduor." Objects include the
Wumpus and squares, whereas the property itself is the stinky one.
King John, the villain, governed England in 1200. John, England, 1200; controlled;
bad, monarch; properties.
The first-order logic language is built using objects and relations. Here we shall define
the syntax and semantics of this language. Its impact on mathematics, philosophy, and
AI is largely attributable to the fact that these disciplines—and a large chunk of human
experience—can be reasonably viewed as addressing things and the relationships
between them. Truths regarding some or all things in the universe's universe can be
stated using first-order logic as well. For example, "Squares that are adjacent to the
Wumpus are smelly." This enables the transmission of general rules or standards.
Propositional logic and first-order logic differ primarily in their ontological
commitments, or the assumptions they make on the nature of reality. The main
distinction between the two schools of thought is this. This dedication is conveyed in
mathematics via the features of the formal models that prove assertions to be true. As
an example, consider the premise of propositional logic: that all facts in the universe
are either true or false. Every fact can be in either the true or false condition, and every
proposition symbol can be assigned a true or false value depending on the model (for
more information, see Section 7.4.2).
2. First-order logic also presupposes that there are some interactions between items in
the universe that are either true or false. The formal models are thought to be far more
complex than the models for propositional logic. Moreover, special-purpose logics
212 | P a g e
make additional ontological claims. For example, according to temporal logic, truths
are true at certain ordered moments, which might be points or intervals. So, instead of
merely defining some objects in the knowledge base, special-purpose logics provide
them "first class" status within the logic along with the axioms that relate to them. In
higher-order logic, the relations and functions that are mentioned in first-order logic
are seen as independent entities. Because of this, claims may be made regarding any
relation. Asking what it means for a relation to be transitive is one such example. Unlike
most special-purpose logics, higher-order logic is more expressive than first-order logic
in a strict sense. Reason being, there's no limit to the amount of first-order logic phrases
that can express some sentences of higher-order reasoning.
Another way to define a logic is by looking at its epistemological commitments, or the
several ways of knowing that it allows for each fact. In both first-order and
propositional logic, a sentence represents a fact, and the agent's judgement on the truth
or falsity of the statement depends on the context. This means that any statement in
these logics can be linked to one of three distinct levels of knowledge. However,
systems grounded on probability theory may support any level of belief, from utter
skepticism (0=) to full faith (1=).For example, a probabilistic Wumpus-world agent
might think there's a 0.75 percent chance that the Wumpus is there. Five different logics
are linked to different ontological and epistemological commitments, which are
summarised in Figure 8.1.
Figure 8.1 The tenets of formal languages with regard to knowledge and
Source: Artificial Intelligence a Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
In what follows, we will go deeply into the details of first-order logic. Similar to how
a physics student needs a basic understanding of mathematics, an AI researcher has to
213 | P a g e
be comfortable with logical notation. Conversely, there are hundreds of different kinds
of logical notation, so it's important not to get bogged down in the nitty-gritty. The most
crucial aspects to consider are the language's facilitation of clear information portrayal
and the ways in which its semantics lead to logical reasoning.
8.2 SYNTAX AND SEMANTICS OF FIRST-ORDER LOGIC
In the first part of this section, we will begin by providing a more detailed explanation
of the manner in which the potential worlds of first-order logic represent the ontological
commitment associated with objects and relations. After that, we will present the
various components of the language, elaborating on their semantics as we progress
through the process.
8.2.1 Models for first-order logic
Keep in mind from Chapter 7 that the formal structures comprising the several worlds
under consideration are the models of a logical language. One may determine the
veracity of any assertion by comparing it to the language of logical claims and the
components of the potential universe, which each model does. This leads to
propositional logic models associating proposition symbols with fixed truth values.
Even more intriguing from a curiosity standpoint are models for first-order logic.
Before everything else, look inside of them! The set of things or domain components
that are represented by a model is called its domain. In order for the do main to be
nonempty, there must be something in every possible universe. Look to Exercise 8.7 if
you want to know more about empty worlds. We will use a concrete example for
pedagogical reasons, even though it is mathematically unimportant what these things
are; the only thing that matters is the number of instances included within each given
model. Figure 8.2 is a model that includes five objects: the left legs of Richard the
Lionheart (who ruled England from 1189 to 1199), John, Richard's younger brother
(who reigned from 1199 until 1215), a crown, and the other two figures.
Many potential relationships exist between the model's components. The picture shows
Richard and John as brothers. To put it simply, a relation is just a set of related object
tuples in a formal sense. Data items organised in a specific order are called tuples. The
collection's elements are encapsulated in angle brackets to represent tuples. Because of
this, the set is a metaphor for the bond between brothers. King John, Richard the
Lionheart, King John II, and King John III are the four protagonists of this narrative.
214 | P a g e
Here we've supplied the English names of the items, but you may freely replace the
pictures with their corresponding titles in your head if you choose. The "on head" link
is just a single tuple consisting of the crown and King John since the crown is put on
King John's head. The "brother" and "on head" relationships are both examples of
binary relations; they link two distinct things. Unitary relations, also called properties,
are also a part of the model. Take Richard and John as an example; they both possess
the "person" attribute. Contrarily, the "king" property is valid just for John (likely due
to Richard's death by this point) while the "crown" property is valid only for the crown.
Some types of relationships are better described in terms of functions. This is because
this is the only way to connect a certain thing with another object. For instance, the
model has a unary "left leg" function that combines the following mappings, as every
individual has one left leg:
(Richard the Lionheart) → Richard’s left leg
(King John) → John’s left leg.
Each input tuple must include a value in order for first-order logic models to possess
complete functions. In its most literal sense, this describes the phrase. Consequently,
the crown needs a left leg, and every left leg needs a left leg as well. This frustrating
but theoretically solvable problem requires an additional "invisible" component.
Figure 8.2 One set of labels for the left-leg function, three sets for the binary
relations, two sets for the objects that indicate unary relations, and five objects
total make up this model.
215 | P a g e
Source: Artificial Intelligence a Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
an entity that serves as the auxiliary limb for all things lacking a corresponding limb,
including itself. The bright side is that these nitpicks don't matter if you don't criticize
things for having no legs at all. So far, we have covered the basics of what goes into
first-order logic model populating. As we'll see in the following sentence, the language
of the logical assertions is another crucial part of a model. The link between these parts
is also important.
8.2.2 Symbols and interpretations
We have reached the section on first-order logic syntax. If the reader is in a rush, they
can get all the information they need by looking at the formal grammar in Figure 8.3.
All objects, relations, and functions in first-order logic are represented by symbols,
which are the building blocks of first-order logic. Consequently, there are three types
of symbols: those representing things (constant symbols), relations (predicate
symbols), and functions (function symbols). Further explanation of each of these
groups follows. The convention that these symbols must begin with capital letters has
been accepted, and we will follow it. Richard and John are examples of constant
symbols; Brother, On Head, Person, King, and Crown are examples of predicate
symbols; and Left Leg is an example of a function symbol. A user's choice of names is
fully customizable, much like with proposal symbols. The number of arguments is
determined by the arity that is attached to a predicate and function symbol.
Every model, much like propositional logic, must provide the information required to
determine the truth or falsity of a statement. Hence, the constant, predicate, and
function symbols denote certain objects, relations, and functions, and each model has
an interpretation that specifies this. The model's objects, relations, and functions are all
part of this interpretation. This is an illustration of one possible reading of our situation
that a logician would call the ideal reading from their perspective:
• John alludes to the notoriously evil King John, and Richard to Richard the
Lionheart.
For the brotherhood relation, see Equation (8.1); for the "on head" connection
between the crown and King John.,
216 | P a g e
• see On Head; for the sets of objects representing individuals, kings, and crowns,
respectively, see Person, King, and Crown; and for the sets of objects
representing other relations, see On Head. To be more precise, Left Leg is the
abbreviation for the "left leg" function, which is the mapping given in Equation
I mean, come on, there are a tone of potential accurate readings. The fact that Richard
is mapped to the crown and John to King John's left leg is a solid example of this. There
are twenty-five possible ways to look at the constant symbols Richard and John,
because the model has five distinct objects. Keep in mind that naming isn't necessary
for every item; for example, the intended reading doesn't give the crown or the legs
names. Something else that may happen is that the same thing could have many names.
From what I can see, Richard and John are both thinking of the crown as the thing in
issue.4. If this choice makes no sense to you, remember that propositional logic says
it's possible to have a model where both Cloudy and Sunny are true. If a model is
determined to be at odds with what we know, the knowledge base should reject it.
Figure 8.3 Backus-Naur notation is defined on page 1060 for people who are not
familiar with the syntax of first-order logic with equality. From most significant
to least, the operator precedence’s are displayed in this sequence.
217 | P a g e
Source: Artificial Intelligence A Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
Figure 8.4 A subset of all feasible models exists for a language that has the
binary relation symbol as a single unit and the letters R and J as constants.
Source: Artificial Intelligence a Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
A first-order logic model, in brief, is an assembly of objects and an interpretation that
assigns symbols to them based on their properties, relations to those properties, and
functions to the operations carried out on those properties. Concepts like entailment
and validity are defined in terms of all the possible models, just as propositional logic.
Get a feel for how the set of all possible models looks by looking at Figure 8.4. It proves
that models vary in how the constant symbols are translated into objects and in the
number of objects they include, which can be anything from one to an infinite number.
When there is just one item and two constant symbols, they must both relate to the same
thing. But this is still a possibility even when dealing with a number of things. When
there are more items than constant symbols, it's likely that some of them will go
unnamed. When compared to propositional logic, first-order logic cannot verify
entailment by listing all possible models. Since there is an infinite number of alternative
models, this is the result. Even if there are just a small number of components, the
number of conceivable combinations might be rather significant. (Refer to Exercise 8.5
for further details.) Figure 8.4 shows that out of all the models, 137,506,194,466 have
six attributes or fewer.
8.2.3 Terms
A word is a phrase that is related to an item and has a logical quality. Consequently,
words are constant symbols; nonetheless, it is not necessarily practical to have a distinct
218 | P a g e
sign for identifying every single thing. To avoid identifying him, we might say, "King
John's left leg" when speaking English. The reason behind this is because his leg
remains unnamed. Function symbols are used for this reason; for instance, instead of
using a constant symbol, we use Left Leg (John). After a function symbol, a set of
phrases is surrounded in brackets and passed to the function as arguments. When a
complicated phrase is formed, this is the typical scenario. You must always bear in
mind that a complex term is only a more elaborate form of name. This "subroutine call"
does not comply with the assertion that it "returns a value."
There is no method in the Left Leg subroutine that takes a person as an argument and
returns a leg. It is possible to reason about left legs (e.g., by stating that everyone has
one and then assuming that John must have one) without ever defining Left Leg. The
use of subroutines in computer programming languages precludes the execution of this
specific scenario. When expressed formally, the semantics of ideas are straightforward.
Here we are debating a word f (t1, Tn). Everything that the function F applies to the
values of d1, dn represents is an object, and the phrase "absolute" describes it. A model
function, denoted by the letter f, is going to be called F from here on out. We shall call
the things in the domain d1, dn, and the words in the argument corresponding to those
items. Assume, for the sake of argument, that King John is represented by the left Leg
function symbol and that Equation (8.2) represents the function. Here, the sign for King
John's left leg would be Left Leg (John). This allows the interpretation to identify the
phrase's referent.
8.2.4 Atomic sentences
Now that we have nouns to describe objects and predicate symbols to describe
relations, we may mix the two kinds of symbols to form atomic sentences that state
facts. Atoms, short for "atomic E sentences," consist of a predicate symbol and a list of
words in brackets, depending on the sentence. "Brother (Richard, John)" is an example
of a phrase like this.
This proves, as was previously thought, that Richard the Lionheart is indeed the brother
of King John. Atomic sentences allow for the use of more complex language in their
arguments. Richard the Lionheart's father is said to be married to King John's mother
in the book "Married" (Father (Richard), Mother (John)). This is again taken at face
value, of course. For a given model to include an atomic sentence, it is necessary that
219 | P a g e
the relation to which the predicate symbol refers holds true among the objects to which
the arguments pertain.
8.2.5 Complex sentences
Using logical connectives, we may construct more complex assertions, and the syntax
and semantics of these sentences are the same as in propositional calculus. According
to our intended interpretation, the following four statements pertain to the model shown
in Figure 8.2:
 Brother (Left Leg (Richard), John)
 Brother (Richard, John) ∧ Brother (John, Richard)
 King (Richard) ∨ King (John)
 King (Richard) ⇒ King (John).
8.2.6 Quantifiers
Rather of listing each item individually, it is more efficient to describe the properties
of a big collection of objects once we have a logic that allows objects. For the simple
reason that doing so will serve our interests best. Quantifiers allow this to happen.
There are two common quantifiers in first-order logic, and they are called universal and
existential, respectively.
Universal quantification (∀)
Keep in mind the difficulty we had in Chapter 7 with representing general concepts in
propositional logic. Rules like "Squares neighboring the Wumpus are smelly" and "All
kings are persons" are hallmarks of first-order logic. These regulations provide the
basis of the subject area. The initial rule will be covered in the section that follows.
As for the second rule, "All kings are persons," it is expressed in first-order logic as
∀ x King(x) ⇒ Person(x).
The standard way to pronounce Ↄ is as "For all...". (It must be remembered that the
upside-down A stands for "all.") As one reading of the verse goes, "For all x, if x is a
king, then x is a person." In this situation, X is called a variable. Standard practice
dictates that variables be expressed using lowercase letters. Being a word in and of
220 | P a g e
itself, a variable can serve as an argument to a function. As an example of a variable,
consider Left Leg(x). A "ground term" is one that does not have any variables.
Any logical phrase P, where ∀ x P, implies that for every object x, P is true. I think this
is a reasonable claim. If P holds in every possible extended interpretation of the model's
interpretation, where each extended interpretation identifies a domain element to which
x connects, then P is true in the given model. More precisely, according to a model, P
is true if and only if x P is true in that model.
Despite how challenging it seems; this is really just a method of precisely expressing
the intuitive meaning of universal quantification. Take into consideration both the
model and its accompanying interpretation presented in Figure 8.2. We have five
options for expanding the interpretation:
 x → The Lionheart, Richard
 x → King John,
 x → Richard’s left leg,
 x → John’s left leg,
 x → the crown
According to the original model, if the statement King(x) ⇒ Person(x) is true under
each of the five expanded interpretations, then the universally quantified phrase ∀ x
King(x) ⇒ Person(x) is assumed to be true. What this means is that the globally
quantified sentence is the same as confirming the five statements that are given below.
Richard the Lionheart is a king ⇒ Richard the Lionheart is a person.
 King John is a king ⇒ King John is a person.
 Richard’s left leg is a king ⇒ Richard’s left leg is a person.
 John’s left leg is a king ⇒ John’s left leg is a person.
 The crown is a king ⇒ the crown is a person.
Let us examine these assumptions in detail first. It is to be expected that the second
sentence asserts that monarch John is a person, given that he is the only monarch in our
paradigm. However, how about the final four sentences, which appear to make claims
regarding legs and crowns? Is this one of the many interpretations of the sentence "All
kings are persons"? The other four assertions in the model are true; nonetheless, they
do not assert in any way that legs, crowns, or Richard possess personhood. This is
because none of these things can be considered kings in and of themselves.
221 | P a g e
By looking at the truth table for the implication (on page 246, Figure 7.8), we can prove
that the implication is true whenever its premise is false, independent of the validity of
the conclusion. The result is that we state the conclusion of the rule only for objects for
which the premise is true and nothing about those individuals for whom the premise is
false when we state the universally quantified sentence, which is the same as saying a
whole list of individual implications. Thus, the truth-table interpretation of ⇒ is fully
enough for the goal of developing generic rules that include universal quantifiers.
Readers who pay close attention and have read the material several times still make the
same mistake: using conjunctions instead of implication. According to this declaration
 ∀ x King(x) ∧ Person(x)
 It would be the same as saying
 Richard the Lionheart is both a person and a ruler.
 King John is both a monarch and an individual.
 Richard's left leg may be both a person and a king.
 The list goes on and on. Clearly, this falls short of our expectations
Existential quantification (∃)
In accordance with the principle of universal quantification, claims can be made about
any and all things. In a similar spirit, we are able to make a statement about a specific
entity in the universe by utilising an existential quantifier. This allows us to do so
without really naming the thing in question. In order to convey this idea, for example,
we may write that King John is adorned with a crown on his head.
 ∃ x Crown(x) ∧ On Head (x, John).
 ∃x is pronounced “There exists an x such that ...” or “For some x...”
Given the sentence ∃ x P, it is possible to draw the conclusion that the assertion P is
true for at least one of the objects x according to the sentence. If there is at least one
extended interpretation that assigns x to a domain element, then P is believed to be true
in the model that is being considered. More specifically, to assert that the statement ∃
x P is true inside a certain model. In order to make this point clear, at least one of the
following assertions is correct:
 A crown represents Richard the Lionheart, and John wears him on his head.
222 | P a g e
 John is wearing the crown of King John.
 Richard's left leg rests on John's head, resembling a crown.
 A crown rests on John's head, which is supported by John's left leg.
 John is wearing a crown, which is a symbol of royalty.
Since the fifth statement holds water in the paradigm, the first-stated existentially
quantified sentence also holds water. Be careful to remember that our definition holds
that the expression would be accurate even if King John sported two crowns. "King
John is wearing a crown on his head." with there's no inconsistency between that with
the original text. Similarly to how ⇏ is the correct choice for connecting ∀, ∧ is the
correct choice for connecting ∃. In the previous part, the statement was made far too
powerful due to the usage of ∧ as the main connective with ∀. However, a statement
that is rather weak is usually the outcome of using ⇒ with ∃. Take a look at the
following sentence:
∃ x Crown(x) ⇒ On Head (x, John).
At first glance, this may appear to be a logical interpretation of the text that we have
provided. When we apply the semantics, we find that the phrase asserts that at least one
of the statements that are listed below is absolutely correct:
 Richard the Lionheart is a crown ⇒ Richard the Lionheart is on John’s head;
 King John is a crown ⇒ King John is on John’s head;
 Richard’s left leg is a crown ⇒ Richard’s left leg is on John’s head;
as well as other things. Therefore, an implication is considered to be legitimate if both
the premise and the conclusion are true, or if the premise of the implication is not true.
Therefore, if Richard the Lionheart is not a crown, then the first assumption is right,
and the existential criterion is satisfied that the first assumption is accurate. Therefore,
an existentially quantified implication statement is true anytime any object fails to
match the premise; hence, statements of this sort do not truly communicate very much
Nested quantifiers
In many cases, we will wish to express more complicated statements by utilising a
number of different quantifiers. When all of the quantifiers are of the same type, this is
223 | P a g e
the simplest possible scenario. "Brothers are siblings" is one example of a phrase that
may be written as
∀ x ∀ y Brother (x, y) ⇒ Sibling (x, y).
In some cases, it is possible to write consecutive quantifiers of the same type as a single
quantifier that contains several variables. We can state, for instance, that the connection
between siblings is one that is symmetric at the same time.
∀ x, y Sibling (x, y) ⇔ Sibling (y, x).
In certain instances, we will be dealing with mixes. When someone says, "Everybody
loves somebody," they are referring to the fact that there is someone who every single
person loves:
∀ x ∃ y Loves (x, y).
At the same time, in order to express the idea that "There is someone who is loved by
everyone," we write
∃ y ∀ x Loves (x, y).
Consequently, the order in which quantification is carried out is of the highest
importance. Incorporating brackets into the sentence will make it easier to comprehend.
As stated in the assertion that ∀ x (∃ y Loves (x, y)), it is said that every individual
possesses a particular trait, namely the attribute that they love someone. Another
alternative is the sentence ∃ y (∀ x Loves (x, y)), which proves that there is a particular
individual in the world who possesses a certain characteristic, namely the property of
being loved by all individuals.
When there are two quantifiers that are used with the same variable name, there is a
risk that there will be some confusion that arises. This sentence should be taken into
consideration.
∀ x (Crown(x) ∨ (∃ x Brother (Richard, x))) .
Within this context, the x in Brother (Richard, x) is quantified in an existential sense.
As a general rule, the variable is considered to be a member of the quantifier that is the
224 | P a g e
most internal to the one that references it. After that, it will not be susceptible to any
further quantification. There is another way to think about it, which is as follows: the
line "∃ x Brother (Richard, x)" is about Richard, not about x; hence, inserting a ∀ x
outside of it does not have any impact. In addition, it is possible that the sentence may
have been phrased as "Richard, z Brother." Because this can lead to misunderstanding,
we will always use separate variable names with nested quantifiers. This is because this
can bring about confusion.
Connections between ∀ and ∃
Negation is the means by which the two quantifiers are in fact closely associated with
one another inside the system. In the same way as stating that everyone dislikes
parsnips is the same as asserting that there is no one who like them, and vice versa,
∀ x ¬Likes (x, Parsnips) is equivalent to ¬∃ x Likes(parsnips).
To take this a step further, we may clarify that the statement "everyone likes ice cream"
implies that there is no one who does not enjoy eating ice cream:
∀ x Likes(ice-cream) is equivalent to ¬∃ x ¬Likes(ice-cream).
It should not come as a surprise that they adhere to De Morgan's norms, given that ∀ is
actually a conjunction over the universe of objects and ∃ is a disjunction by definition.
Both quantified and unquantified statements are subject to the following De Morgan
Therefore, it is not necessary for us to have both ∀ and ∃, just as it is not necessary for
us to have both ∧ and ∨. For the time being, we shall continue to use both of the
quantifiers because readability is more essential than parsimony.
8.2.7 Equality
One further method for constructing atomic sentences is included in first-order logic.
This method is in addition to the use of a predicate and words, which was discussed
225 | P a g e
before. When two words relate to the same thing, we may use the equality symbol to
indicate that they are the same thing. Just one example:
Father (John) = Henry
asserts that the thing that Father (John) is referring to and the object that Henry is
referring to are identical to one another. The truth of an equality sentence may be
determined by only observing that the referents of the two words are the same object.
This is due to the fact that an interpretation can fix the referent of any term.
In the same way that we just did with the Father sign, the equality symbol serves the
purpose of stating information about a certain function. It is also possible to use it in
conjunction with negation to emphasise that two terms do not refer to the same thing.
We would write that Richard has at least two brothers in order to make this statement.
∃ x, y Brother (x, Richard) ∧ Brother (y, Richard) ∧ ¬(x = y) .
The sentence
∃ x, y Brother (x, Richard) ∧ Brother (y, Richard)
does not have the intended meaning. In particular, it is true in the model of Figure 8.2,
where Richard has only one brother. To see this, consider the extended interpretation
in which both x and y are assigned to King John. The addition of ¬(x = y) rules out
such models. The notation x = y is sometimes used as an abbreviation for ¬(x = y)..
8.2.8 An alternative semantics?
As a continuation of the scenario presented in the last section, let us assume that we
have the belief that Richard has two brothers named John and Geoffrey.8. If we make
the assertion that Brother (John, Richard) ∧ Brother (Geoffrey, Richard), is it possible
for us to capture this state of affairs? No, not exactly. To begin, this assumption is
correct under a scenario in which Richard has just one sibling; nevertheless, we must
ensure that John is equal to Geoffrey. In the second place, the statement does not
exclude the possibility that Richard has a great number of additional brothers in
addition to John and Geoffrey. The phrase "Richard's brothers are John and Geoffrey"
can be translated as follows, which is the right translation:
226 | P a g e
Brother (John, Richard) ∧ Brother (Geoffrey, Richard) ∧ John = Geoffrey
∧∀ x Brother (x, Richard) ⇒ (x = John ∨ x = Geoffrey)
In many contexts, this appears to be a far more laborious phrase than the natural
language term that corresponds to it. As a consequence of this, it is possible for people
to make errors while translating their knowledge into first-order logic, which eventually
leads to behaviours that are not intuitive from logical reasoning systems that make use
of the information. Is it possible for us to come up with a semantics that enables
expressions of logic that are less complicated?
The following is an explanation of how one suggestion that is often used in database
systems operates. The first thing that we do is make the so-called unique-names
assumption, which states that we require every constant sign to refer to a different thing.
As a second assumption, we make the closed-world assumption, which states that
atomic statements that are not known to be true are, in reality, untrue.
Figure 8.5 Some members of the set of all models for a language with two
constant symbols, R and J, and one binary relation symbol, under database
semantics.
Source: Artificial Intelligence a Modern Approach Data Collection and Processing
Through by Stuart J. Russell and Peter Norvig 2010.
Last but not least, we finally call domain closure, which means that every model does
not include any more domain elements beyond those that are named by the constant
symbols. In accordance with the resultant semantics, which we refer to as database
semantics in order to differentiate it from the conventional semantics of first-order
logic, the statement Equation (8.3) does, in fact, say that Richard's two brothers are
John and Geoffrey. One other use of database semantics is in logic programming
systems, as was previously stated.
227 | P a g e
As seen in Figure 8.4, it is useful to take into consideration the collection of all potential
models that fall within the category of database semantics for the same scenario. There
are a few models that are displayed in Figure 8.5. These models range from the model
that does not have any tuples that fulfil the relation to the model that has all of the tuples
that meet the relation. There are four distinct two-element tuples that may be created
using two objects, which means that there are 24 = 16 different subsets of tuples that
can fulfil the relation being discussed. There are therefore a total of sixteen potential
models, which is a significant reduction from the unlimited number of models that are
used for the normal first-order semantics. The database semantics, on the other hand,
necessitates having a clear understanding of the things that are contained in the world.
It is crucial to note that there is no one "correct" semantics for logic, and this example
brings up an important issue. The utility of any suggested semantics is contingent on
the degree to which it simplifies and simplifies intuition in the representation of the
types of information that we wish to record, as well as the ease with which and the
naturalness with which the rules of inference that correspond to that knowledge are
developed. When we are positive about the identification of all the objects specified in
the knowledge base and when we have all the information at our disposal, database
semantics is at its most beneficial. In other circumstances, however, it may be
extremely unpleasant. While we will be assuming the normal semantics for the
remainder of this chapter, we will be highlighting cases in which this decision results
in formulations that are difficult to understand.
8.3 USING FIRST-ORDER LOGIC
Now that we have established what an expressive logical language is, it is time to
master the skills necessary to use it. Using examples is the most effective approach to
do this. In this part, we will offer more systematic representations of several basic
domains. Previously, we have seen some simple phrases that illustrate the many
components of logical syntax. Within the realm of knowledge representation, a domain
is nothing more than a specific region of the world that we intend to communicate some
knowledge about.
When it comes to first-order knowledge bases, we will start out by providing a concise
explanation of the TELL/ASK interface. The next thing that we do is investigate the
realms of familial ties, numbers, sets, and lists, as well as the world of Wumpus. A
228 | P a g e
more important example, which is electrical circuits, is shown in the next section,
which also encompasses everything that exists in the universe.
8.3.1 Assertions and queries in first-order logic
A knowledge base is expanded with the addition of sentences by the use of TELL,
much like in propositional logic. This type of language is referred to as an assertion. It
is possible, for instance, to say that John is a king, that Richard is a person, and that all
kings are people:
 TELL (KB, King (John)).
 TELL (KB, Person (Richard)).
 TELL (KB, ∀ x King(x) ⇒ Person(x)).
 We can ask questions of the knowledge base using ASK. For example,
 ASK (KB, King (John))
true is returned. Queries or objectives are the names given to questions that are posed
using ASK. In general, the answer to any question that is logically implied by the
knowledge base ought to be presented in the positive. Given the two claims that came
before it, for instance, the question is as follows:
 ASK (KB, Person (John))
 Should also return true. We can ask quantified queries, such as
 ASK (KB, ∃ x Person(x)).
The response is correct; nevertheless, it is possible that this is not as useful as we would
like it to be. It is comparable to responding to the question "Can you tell me the time?"
with the word "Yes." For the purpose of determining the value of x that will result in
the statement being true, we will require a new function known as ASKVARS, which
we will call with
ASKVARS (KB, Person(x))
and it results in a steady stream of responses. For this particular scenario, there will be
two possible responses: {x/John} and {x/Richard}. The answer to this question is
referred to as a substitute or binding list. ASKVARS is often reserved for knowledge
bases that are made up entirely of Horn clauses. This is due to the fact that in such
229 | P a g e
knowledge bases, any method of making the query true will tie the variables to
particular values. In the realm of first-order logic, this is not the case. If KB is informed
that King (John) ∨ King (Richard), then the question ∃ x King(x) does not have any
binding to x, despite the fact that the inquiry is true.
8.3.2 The kinship domain
The realm of familial bonds, also known as kinship, is the first example that we take
into consideration. Facts such as "Charles is the father of William" and "Elizabeth is
the mother of Charles" are examples of the kind of information that fall under this
category. Rules such as "One's grandmother is the mother of one's parent" are also
Clearly, the objects that fall under our purview are individuals. Male and female are
the two unary predicates that we have today. Predicates that are binary in nature are
used to describe kinship relationships such as parentage, brotherhood, marriage, and
other similar relationships. These predicates include: parent, sibling, brother, sister,
child, daughter, son, spouse, wife, husband, grandparent, grandchild, cousin, aunt, and
uncle. Due to the fact that every individual possesses precisely one of each of them (at
least according to the design of nature), we make use of functions for Mother and
We are able to list everything that we are aware of in relation to the other symbols as
we proceed through each function and predicate. In this context, the term "mother"
refers to a person's female parent.
∀ m, c Mother (c) = m ⇔ Female(m) ∧ Parent (m, c).
One’s husband is one’s male spouse:
∀ w, h Husband (h, w) ⇔ Male(h) ∧ Spouse (h, w).
Male and female are disjoint categories:
∀ x Male(x) ⇔ ¬Female(x).
Parent and child are inverse relations:
∀ p, c Parent (p, c) ⇔ Child (c, p).
A grandparent is a parent of one’s parent:
∀ g, c Grandparent (g, c) ⇔∃ p Parent (g, p) ∧ Parent (p, c).
A sibling is another child of one’s parents:
∀ x, y Sibling (x, y) ⇔ x = y ∧∃ p Parent (p, x) ∧ Parent (p, y).
230 | P a g e
As an example, we could continue on for a number of additional pages like this, and
Exercise 8.14 invites you to do exactly that. In accordance with the explanation
provided in Section 7.1, each of these phrases can be interpreted as an axiom of the
kinship domain. Axioms are typically linked with domains that are solely concerned
with mathematics; in a moment, we shall examine some axioms on the subject of
numbers; yet, they are essential in every domain. In doing so, they supply the
fundamental factual knowledge that may be used to draw conclusions that are
meaningful.
The axioms that we use to define kinship are also definitions; they are expressed in the
form ∀ x, y P (x, y) ⇔.... A number of predicates, including the mother function, the
Husband, Male, Parent, Grandparent, and Sibling predicates, are defined by the axioms
in relation to other predicates. Our definitions "bottom out" at a fundamental set of
predicates, which are Child, Spouse, and Female. As a result, the other predicates are
eventually defined in terms of these three predicates.
It is a natural approach to construct the representation of a domain, and it is comparable
to the way that software packages are constructed by successively defining subroutines
from primitive library functions. This is a natural way to construct the representation
of a domain. It is important to take note that there is not necessary a singular collection
of basic predicates; on the other hand, we may have utilised Parent, Spouse, and Male
on equal footing. According to our findings, there is no fundamental set that can be
easily identified in some areas.
It is not true that every logical proposition concerning a domain is an axiom. There are
several that are theorems, which means that they are implied by the axioms. Consider,
for instance, the claim that the relationship between siblings is symmetric:
∀ x, y Sibling (x, y) ⇔ Sibling (y, x).
If this is a theorem, then it is an axiom. In point of fact, it is a theorem that can be
deduced from the axiom that defines siblinghood in a very rational manner. We should
get a positive response from the knowledge base if we ask it about this statement.
A knowledge base is required to contain just axioms and no theorems alone from a
strictly logical standpoint. This is due to the fact that the theorems do not contribute to
the expansion of the set of conclusions that are derived from the knowledge base. For
231 | P a g e
the purpose of lowering the amount of computer resources required to generate new
phrases, theorems are imperative from a pragmatic standpoint. Without them, a
reasoning system is required to begin from the very beginning each and every time.
This is analogous to the situation in which a physicist is required to rederive the laws
of calculus for each and every new problem.
Axioms are not always definitions of things. Some of them include more broad
information about certain predicates, but they do not constitute a comprehensive
definition. In point of fact, there are certain predicates that do not have a complete
definition because we do not have sufficient information to completely characterise
them. Take, for instance, the fact that there is no apparent and definite way to finish the
∀ x Person(x) ⇔ ...
We are fortunate because first-order logic enables us to make use of the Person
predicate without having to initially define it in its entirety. In its place, we may
construct partial descriptions of the characteristics that are shared by all individuals as
well as the characteristics that distinguish something as a person:
∀ x Person(x) ⇒ ...
∀ x ... ⇒ Person(x).
There is also the possibility that axioms are "just plain facts," such as "male" (Jim) and
"spouse" (Jim, Laura). These facts are what constitute the descriptions of particular
instances of the problem, which in turn enables specific questions to be addressed.
These issues will subsequently be answered by theorems, which are conclusions that
may be drawn from the axioms.
There are times when one discovers that the answers that are anticipated do not
materialise. For instance, based on the phrase "spouse" (Jim, Laura), one anticipates
(according to the legal systems of numerous nations) to be able to deduce "spouse"
(George, Laura). However, this does not follow from the axioms that were presented
earlier, even after we include the phrase "Jim = George" as suggested in Section 8.2.8.
A lack of an axiom is indicated by this particular symbol. With Exercise 8.8, the reader
is tasked with providing it.
232 | P a g e
8.3.3 Numbers, sets, and lists
A huge theory may be constructed from a small nucleus of axioms, and numbers are
possibly the most vivid example of how this can be put into practice. A description of
the theory of natural numbers, often known as non-negative integers, is provided here.
It is necessary for us to have a predicate called Nat Num that is applicable to natural
numbers; we must have one constant symbol, which is 0; and we must have one
function symbol, which is S (successor). The natural numbers and addition are both
defined by the Peano axioms.9) In a recursive manner, natural numbers are defined
Nat Num (0).
∀ n Nat Num(n) ⇒ Nat Num(S(n)).
To clarify, the number 0 is considered a natural number, and if the number n is also a
natural number, then the function S(n) is also considered a natural number. The natural
numbers are therefore 0 (S (0)), S (S (0)), and so on and so forth. As you read Section
8.2.8, you will see that these axioms permit the existence of natural numbers different
than the ones that are typically considered natural; for more information, see Exercise
8.12. Furthermore, in order to limit the successor function, we require axioms:
 ∀ n 0 = S(n).
 ∀ m, n m = n ⇒ S(m) = S(n).
 Now we can define addition in terms of the successor function:
 ∀ m NatNum(m) ⇒ + (0, m) = m .
 ∀ m, n Nat Num(m) ∧ Nat Num(n) ⇒ + (S(m), n) = S (+ (m, n)).
According to the first of these axioms, the addition of 0 to any natural number m results
in the generation of m itself. It is important to take note of the fact that the symbol "+"
is used in the expression "+(m, 0);" in the context of conventional mathematics, the
expression would be represented as "m + 0" using infix notation. Prefix is the name of
the notation that we make use of while dealing with first-order logic. We allow the use
of infix notation in our statements that are about numbers because we want to make
them easier to read. In addition, we may define S(n) as n plus 1, which means that the
second axiom is now
233 | P a g e
∀ m, n Nat Num(m) ∧ Nat Num(n) ⇒ (m + 1) + n = (m + n) +1.
By reducing addition to the repetitive application of the successor function, this axiom
achieves better results.
The usage of infix notation is an example of syntactic sugar, which may be defined as
an extension or shortening of the conventional syntax that does not alter the meaning
of the sentence. The term "desugared" refers to the process of producing an equivalent
statement using conventional first-order logic from any sentence that contains sugar.
The definition of multiplication as repeated addition, exponentiation as repeated
multiplication, integer division and remainders, prime numbers, and so on is easy after
we have established the concept of addition. Since this is the case, the entirety of
number theory, which encompasses cryptography as well, can be constructed using just
one constant, one function, one predicate, and four axioms.
Furthermore, the domain of sets is crucial not just to mathematics but also to reasoning
that is grounded in common sense. (In point of fact, it is feasible to understand the
concept of number theory by referring to set theory.) To be able to represent individual
sets, including the empty set, is something that we want possible. In order to construct
sets, we require a method that allows us to add an element to an existing set, as well as
to take the union or intersection of two sets. It will be necessary for us to determine
whether or not a certain element is a member of a set, and we will also need to
differentiate between sets and things that are not sets.
For the purpose of syntactic sugar, we shall make use of the standard language of set
theory. This constant, denoted by the symbol { }, is the empty set. Set is the only unary
predicate that operates on sets, and it is true of sets. The binary predicates are x ∈ s,
which means that x is a member of set s, and s1 ⊆ s2, which means that set s1 is a
subset of set s2, which does not necessarily mean that it is a legitimate subset of set s2.
There are three binary functions: s1 ∩ s2 (which represents the intersection of two sets),
s1 ∧ s2 (which represents the union of two sets), and {Xs} (which represents the set
that is produced by connecting element x to set s). The following is an example of a
potential collection of axioms:
1. The only sets are the empty set and those made by adjoining something to a set:
∀ s Set(s) ⇔ (s = { }) ∨ (∃ x, s2 Set(s2) ∧ s = {x|s2}) .
234 | P a g e
2. The empty set has no elements adjoined into it. In other words, there is no way
to decompose { } into a smaller set and an element:
¬∃ x, s {Xs} = { } .
3. Adjoining an element already in the set has no effect:
∀ x, s x∈ s ⇔ s = {Xs} .
4. The only members of a set are the elements that were adjoined into it. We
express this recursively, saying that x is a member of s if and only if s is equal
to some set s2 adjoined with some element y, where either y is the same as x or
x is a member of s2:
∀ x, s x∈ s ⇔∃ y, s2 (s = {y|s2} ∧ (x = y ∨ x∈ s2)).
5. A set is a subset of another set if and only if all of the first set’s members are
members of the second set:
∀ s1, s2 s1 ⊆ s2 ⇔ (∀ x x∈ s1 ⇒ x∈ s2).
6. Two sets are equal if and only if each is a subset of the other:
∀ s1, s2 (s1 = s2) ⇔ (s1 ⊆ s2 ∧ s2 ⊆ s1).
7. An object is in the intersection of two sets if and only if it is a member of both
∀ x, s1, s2 x∈ (s1 ∩ s2) ⇔ (x∈ s1 ∧ x∈s2).
8. An object is in the union of two sets if and only if it is a member of either set:
∀ x, s1, s2 x∈ (s1 ∪ s2) ⇔ (x∈ s1 ∨ x∈s2).
Compare and contrast lists and sets. There are two key distinctions: first, lists
are arranged in a certain order, and second, elements can appear in a list more
than once. By using the vocabulary of Lisp, we are able to make use of lists. Nil
is the constant list that does not include any items; Cons, Append, First, and
Rest are functions; and find is the predicate that performs the same job for lists
235 | P a g e
that Member does for sets. The only thing that can be true for the predicate
"List?" is a list. Similar to the usage of syntactic sugar in sets, it is usual practice
to employ it in logical formulations that involve lists. There is nothing on the
list. It is expressed as [x|y] when the word Cons (x, y) is used, where y is a list
that is not empty. The notation [x] is used to represent the word Cons (x, Nil),
which refers to the list that contains the member x. There is a correspondence
between the nested term Cons (A, Cons (B, Cons (C, Nil)) and a list that has
several entries, such as [A, B, C]. In Exercise 8.16, you will be asked to express
the axioms that pertain to lists.