The Evolution of Boosting Algorithms
From Machine Learning to Statistical Modelling∗
Andreas Mayr†1, Harald Binder2, Olaf Gefeller1,
Matthias Schmid1,3
1 Institut f¨ur Medizininformatik, Biometrie und Epidemiologie,
Friedrich-Alexander-Universit¨at Erlangen-N¨urnberg, Germany
2 Institut f¨ur Medizinische Biometrie, Epidemiologie und Informatik,
Johannes Gutenberg-Universit¨at Mainz, Germany
3 Institut f¨ur Medizinische Biometrie, Informatik und Epidemiologie,
Rheinische Friedrich-Wilhelms-Universit¨at Bonn, Germany
Background: The concept of boosting emerged from the ﬁeld of machine learning.
The basic idea is to boost the accuracy of a weak classifying tool by combining various
instances into a more accurate prediction. This general concept was later adapted to
the ﬁeld of statistical modelling. Nowadays, boosting algorithms are often applied to
estimate and select predictor eﬀects in statistical regression models.
Objectives: This review article attempts to highlight the evolution of boosting algorithms from machine learning to statistical modelling.
Methods: We describe the AdaBoost algorithm for classiﬁcation as well as the two
most prominent statistical boosting approaches, gradient boosting and likelihood-based
boosting for statistical modelling. We highlight the methodological background and
present the most common software implementations.
Although gradient boosting and likelihood-based boosting are typically
treated separately in the literature, they share the same methodological roots and
follow the same fundamental concepts. Compared to the initial machine learning algorithms, which must be seen as black-box prediction schemes, they result in statistical
models with a straight-forward interpretation.
Conclusions: Statistical boosting algorithms have gained substantial interest during
the last decade and oﬀer a variety of options to address important research questions
in modern biomedicine.
∗This article is not an exact copy of the original published article in Methods of Information in Medicine.
The deﬁnitive publisher-authenticated version is available online (together with the companion review and
an invited discussion) at: 
If citing, please refer to the original article:
Mayr A, Binder H, Gefeller O, Schmid M. The Evolution of Boosting Algorithms – From Machine Learning
to Statistical Modelling. Methods Inf Med 2014; 53(6): 419–427.
†Address for correspondence: Andreas Mayr, Institut f¨ur Medizininformatik, Biometrie und Epidemiologie, Friedrich-Alexander Universit¨at Erlangen-N¨urnberg, Waldstr. 6, 91054 Erlangen, Germany.
 
Introduction
Boosting algorithms represent one of the most promising methodological approaches for
data analysis developed in the last two decades. The original algorithm emerged from
the ﬁeld of machine learning, where it gained much interest and was soon considered as a
powerful instrument to predict binary outcomes. The basic idea is to iteratively apply simple
classiﬁers and to combine their solutions to obtain a better prediction result. The concept of
boosting was later adapted to the ﬁeld of statistical modelling, where it can be used to select
and estimate the eﬀect of predictors on a univariate response variable in diﬀerent types of
regression settings .
Following a recent focus theme on boosting algorithms in Methods of Information in Medicine
 , the ﬁrst aim of this review is to highlight the evolution of boosting from a black-box
machine learning algorithm to a ﬂexible tool to estimate and select interpretable statistical
models. We will refer to this type of boosting algorithms as statistical boosting algorithms.
The second aim is to bridge the methodological gap between two diﬀerent statistical boosting approaches which are typically treated separately in the literature, but share the same
historical roots: gradient boosting and likelihood-based boosting . Both are increasingly applied in biomedical settings for diﬀerent kind of regression and prediction analysis
 .
The reasons for the success of statistical boosting algorithms are (i) their ability to incorporate automated variable selection and model choice in the ﬁtting process, (ii) their ﬂexibility
regarding the type of predictor eﬀects that can be included in the ﬁnal model and (iii) their
stability in the case of high-dimensional data with possibly far more candidate variables
than observations – a setting where most conventional estimation algorithms for regression
settings collapse. The application of boosting algorithms thus oﬀers an attractive option
for biomedical researchers: many modern biomedical settings like genome-wide association
studies and research using other ’omics’ technologies are speciﬁcally challenging regarding
all three points mentioned above .
This review is structured as follows: In Section 2, we introduce the machine-learning concept
of boosting which led to the famous AdaBoost algorithm for classiﬁcation. In Section 3
we present the statistical view on boosting which paved the way for the development of
statistical boosting algorithms that are suitable for general regression settings. We describe
the generic algorithms for gradient boosting and likelihood-based boosting and present the
most common software packages.
In the concluding Section 4, we summarize the main
ﬁndings and highlight the diﬀerences between AdaBoost and statistical boosting.
In a companion article , we additionally document the signiﬁcant progress in the methodological research on statistical boosting algorithms over the last few years.
Boosting in machine learning
The concept of boosting emerged from the ﬁeld of supervised learning, which is the automated learning of an algorithm based on labelled data with observed outcome in order
to make valid predictions for unlabelled future or unobserved data. Supervised learning
is a subdiscipline of machine learning, which also comprises unsupervised learning based
on unlabelled data and semi-supervised learning which is a combination of supervised and
unsupervised learning . A supervised learning machine typically yields a generalization
function ˆh(·) that provides the solution to a classiﬁcation problem. The main goal of classiﬁcation is to categorize objects into a pre-deﬁned set of classes. For the remainder of this
section we will consider the most common classiﬁcation problem, where the outcome variable
Y has two classes, coded as {−1, 1}. Note that this coding diﬀers from the standard {0, 1}
which is typically used in statistics for dichotomous outcomes.
The machine should learn from a training sample (y1, x1), ..., (yn, xn) with known class labels
how to predict the class of a new observation xnew. The predictors x1, ..., xn are realizations
of X, and n is the sample size. The task for the machine is to develop a prediction rule ˆh(·)
to correctly classify a new observation:
(y1, x1), ..., (yn, xn)
supervised learning
−−−−−−−−−−→ˆh(xnew) = ˆynew
The concept of boosting
The success story of boosting began with a question, not with an algorithm. The theoretical
discussion was if any weak learning tool for classiﬁcation could be transformed to become
also a strong learner . In binary classiﬁcation, a weak learner is deﬁned to yield a correct
classiﬁcation rate at least slightly better than random guessing (> 50%). A strong learner,
on the other hand, should be able to be trained to a nearly perfect classiﬁcation (e.g., 99%
accuracy). This theoretical question is of high practical relevance as it is typically easy to
construct a weak learner, but diﬃcult to get a strong one . The answer, which laid
the ground for the concept of boosting, is that any weak base-learner can be potentially
iteratively improved (boosted) to become also a strong learner. To provide evidence for this
concept, Schapire and Freund developed the ﬁrst boosting algorithms.
Schapire and Freund later compared the general concept of boosting with “garnering wisdom
from a council of fools” . The “fools” in this case are the solutions of the simple baselearner: It classiﬁes only slightly better than the ﬂip of a coin. A simple base-learner is by
no means a practical classiﬁcation rule, but even the simple base-learner must contain some
valid information about the underlying structure of the problem. The task of a boosting
algorithm is hence to learn from the iterative application of a weak learner and to use this
information to combine it to an accurate classiﬁcation.
However, just calling the weak learner multiple times on the same training sample would
not change anything in its performance. The concept of boosting is not really to manipulate
the base-learner itself to improve its performance but to manipulate the underlying training
data by iteratively re-weighting the observations . As a result, the base-learner in every
iteration m will ﬁnd a new solution ˆh[m](·) from the data.
Via repeated application of the weak base-learner on observations that are weighted based
on the base-learner’s success in the previous rounds, the algorithm is forced to concentrate
on objects that are hard to classify – as observations that were misclassiﬁed before get higher
weights. Boosting the accuracy is achieved by increasing the importance of “diﬃcult” observations. In each iteration m = 1, ..., mstop, the weight vector w[m] = (w[m]
1 , ..., w[m]
n ) contains
the individual weights of all observations depending on the success of their classiﬁcation in
previous iterations. During the iteration cycle, the focus is shifted towards observations that
were misclassiﬁed up to the current iteration m.
In a ﬁnal step, all previous results of the base-learner are combined into a more accurate
prediction: The weights of better performing solutions of the base-learner are increased via
an iteration-speciﬁc coeﬃcient, which depends on the corresponding misclassiﬁcation rate.
The resulting weighted majority vote chooses the class most often selected by the baselearner while taking the error rate in each iteration into account (see point (5) in Box 1).
This combination of forcing the algorithm to develop new strategies for problematic observations and rewarding the base-learner in the ﬁnal aggregation for accurate solutions is the
main idea of boosting. Following this concept, it can be shown that all weak learners can
potentially be boosted to become also strong learners .
The early boosting algorithms by Schapire and Freund were rather theoretical
constructs for proving the idea of boosting than being suitable algorithms for practical
usage. However, they paved the way for the ﬁrst concrete and – still today – most important
boosting algorithm AdaBoost . AdaBoost was the ﬁrst adaptive boosting algorithm as
it automatically adjusts its parameters to the data based on the actual performance in the
current iteration: both the weights wi for re-weighting the data as well as the weights αm
for the ﬁnal aggregation are re-computed iteratively. For a schematic overview, see Box 1 –
for worked out examples, we refer to .
The introduction of AdaBoost gained much attention in the machine learning community.
In practice, it is often used with simple classiﬁcation trees or stumps as base-learners and
typically results in a dramatically improved performance compared to the classiﬁcation by
one tree or any other single base-learner . For example, Bauer and Kohavi report
an average 27% relative improvement in the misclassiﬁcation error for AdaBoost compared
with a single decision tree. The authors additionally compared the accuracy of AdaBoost
with the one of Bagging in various settings. Bagging, in contrast to boosting, uses
bootstrap generated samples to modify the training data and hence does not rely on the
misclassiﬁcation rate of earlier iterations.
After their large-scale comparison, Bauer and
Kohavi concluded that boosting algorithms, in contrast to Bagging, are able to reduce not
only the variation in the base-learner’s prediction error resulting from the use of diﬀerent
training data sets (variance), but also the average diﬀerence between predicted and true
classes (bias). This view is also essentially supported by an analysis of Breiman . The
success of AdaBoost allegedly led Breiman, who was a pioneer and leading expert in machine
learning, to the statement : Boosting is the best oﬀ-the-shelf classiﬁer in the world.
Overﬁtting
A long-lasting discussion in the context of AdaBoost is its overﬁtting behavior. Overﬁtting
describes the common phenomenon that when a prediction rule concentrates too much on
peculiarities of the speciﬁc sample of training observations it was optimized on, it will often
perform poorly on a new data set . To avoid overﬁtting, the task for the algorithm
therefore should not be to ﬁnd the best possible classiﬁer for the underlying training sample,
but rather to ﬁnd the best prediction rule for a set of new observations.
The main control instrument to avoid overﬁtting in boosting algorithms is the stopping
iteration mstop. Very late stopping of AdaBoost may favor overﬁtting, as the complexity of
Initialization
(1) Set the iteration counter m = 0 and the individual weights wi for observations
i = 1, ..., n to w 
Base-learner
(2) Set m := m + 1 and compute the base-learner for the weighted data set:
re-weight observations with w[m−1]
, ..., w[m−1]
base-learner
−−−−−−→ˆh[m](·)
Update weights
(3) Compute error rate and update the iteration-speciﬁc coeﬃcient αm →high values
for small error rates. Update individual weights w[m]
→higher values if observation was misclassiﬁed.
(4) Iterate steps 2 and 3 until m = mstop.
Final aggregation
(5) Compute the ﬁnal classiﬁer for a new observation xnew:
ˆfAdaboost(xnew) = sign
αmˆh[m](xnew)
Box 1: Schematic overview of the AdaBoost algorithm.
the ﬁnal solution increases. On the other hand, stopping the algorithm too early does not
only inevitably lead to higher error on the training data but could as well result in a poorer
prediction on new data (underﬁtting). In the context of AdaBoost, it is nowadays consensus
that although the algorithm may overﬁt , it often is quite resistent to overﬁtting
 .
In their initial article, Freund and Schapire showed that the generalization error on a
test data set of AdaBoost’s ﬁnal solution is bounded by the training error plus a term which
increases with the number of boosting iterations and the complexity of the base-learner. This
ﬁnding was apparently supported by the widely acknowledged principle known as Occam’s
Razor , which roughly states that for predictions, more complex classiﬁers should be
outperformed by less complex ones if both carry the same amount of information. However,
this theoretical result is not supported by the observation that AdaBoost, in practice, is often
resistent to overﬁtting. As the complexity of the ﬁnal AdaBoost solution depends mainly
on the stopping iteration mstop, following Occam’s Razor, later stopping of the algorithm
should yield poorer predictions .
One way to explain AdaBoost’s overﬁtting behavior is based on the margin interpretation
 : The margin of the ﬁnal boosting solution, in brief, can be interpreted as the
conﬁdence in the prediction. With higher values of mstop, this margin may still increase and
lead to better predictions on the test data even if the training error is already zero . This
theory was early questioned by results of Breiman , who developed the arc-gv algorithm
which should yield a higher margin than AdaBoost, but clearly failed to outperform it in
practice with respect to prediction accuracy. Later, Reyzin and Schapire explained these
ﬁndings with other factors like the complexity of the base-learner. For more on the margin
interpretation see the corresponding chapters in .
Another explanation of the – seemingly contradictory – results on the overﬁtting behavior
of boosting is the use of the wrong performance criteria for evaluation (e.g., ).
performance of AdaBoost has often been measured by evaluating the correct classiﬁcation
rate, and the resistance to overﬁtting has usually been demonstrated by focusing on this
speciﬁc criterion only. However, the criterion that is optimized by AdaBoost is in fact not
the correct classiﬁcation rate but the so-called exponential loss function, and it can be shown
that the two criteria are not necessarily optimized by the same predictions. For this reason
some authors have argued that the overﬁtting behavior of AdaBoost should be analyzed by
solely focusing on the exponential loss function . For example, B¨uhlmann and Yu 
have provided empirical evidence that too large mstop can lead to overﬁtting regarding the
exponential loss without aﬀecting the misclassiﬁcation rate.
Statistical boosting
Up to this point, we focused on the classical supervised learning problem where the task of
boosting is to predict dichotomous outcomes. Nowadays, boosting algorithms are more often
used to estimate the unknown quantities in general statistical models (statistical boosting).
In the remainder of this section, we will therefore broaden the scope and consider general
regression settings where the outcome variable Y can also be continuous or represent count
data. The most important interpretation of boosting in this context is the statistical view of
boosting by Friedman et al. . It provided the basis for understanding the boosting concept
in general and the success of AdaBoost in particular from a statistical point of view by
showing that AdaBoost in fact ﬁts an additive model.
Most solutions of machine-learning algorithms, including AdaBoost, must be seen as blackbox prediction schemes. They might yield very accurate predictions for future or unobserved
data, but the way those results are produced and which role single predictors play are hardly
interpretable. A statistical model, in contrast, aims at quantifying the relation between one
or more observed predictor variables x and the expectation of the response E(Y ) via an
interpretable function E(Y |X = x) = f(x).
In cases of more than one predictor, the
diﬀerent eﬀects of the single predictors are typically added, forming an additive model
f(x) = β0 + h1(x1) + · · · + hp(xp)
where β0 is an intercept and h1(·),...,hp(·) incorporate the eﬀects of predictors x1, ..., xp,
which are components of X. The corresponding model class is called generalized additive
models (’GAM’, ) and the aim is to model the expected value of the response variable,
given the observed predictors via a link-function g(·):
g(E(Y |X = x)) = β0 +
GAMs are by deﬁnition no black boxes but contain interpretable additive predictors: The
partial eﬀect of predictor x1, for example, is represented by h1(·). The direction, the size and
the shape of the eﬀect can be visualized and interpreted – this is a main diﬀerence towards
many tree-based machine learning approaches.
The core message delivered with the statistical view of boosting is that the original AdaBoost
algorithm with regression-type base-learners (e.g., linear models, smoothing splines), in fact,
ﬁts a GAM for dichotomous outcomes via the exponential loss in a stage-wise manner. The
work by Friedman et al. therefore provided the link between a successful machine-learning
approach and the world of statistical modelling .
Gradient boosting
The concept of the statistical view of boosting was further elaborated by Friedman who
presented a boosting algorithm optimizing the empirical risk via steepest gradient descent in
function space. Generally, the optimization problem for estimating the regression function
f(·) of a statistical model, relating the predictor variables X with the outcome Y , can be
expressed as
ˆf(·) = argmin
ρ(Y, f(X))
where ρ(·) denotes a loss function. The most common loss function is the L2 loss ρ(y, f(·)) =
(y −f(·))2, leading to classical least squares regression of the mean: f(x) = E(Y |X = x).
In practice, with a learning sample of observations (y1, x1), ..., (yn, xn) we minimize the
empirical risk:
ˆf(·) = argmin
ρ(yi, f(xi))
The fundamental idea of gradient boosting is to ﬁt the base-learner not to re-weighted
observations, as in AdaBoost, but to the negative gradient vector u[m] of the loss function
ρ(y, ˆf(x)) evaluated at the previous iteration m −1:
i=1,...,n =
∂f ρ(yi, f)
f= ˆf[m−1](·)
In case of the L2 loss, ρ(y, f(·)) = 1
2(y−f(·))2 leads simply to re-ﬁtting the residuals y−f(·).
In every boosting iteration m, the base-learner is hence directly ﬁtting the errors made in
the previous iteration y −f(·)[m−1]. Keeping this principle in mind, it becomes obvious that
both AdaBoost and gradient boosting follow the same fundamental idea: Both algorithms
boost the performance of a simple base-learner by iteratively shifting the focus towards
problematic observations that are ‘diﬃcult’ to predict. With AdaBoost, this shift is done
by up-weighting observations that were misclassiﬁed before. Gradient boosting identiﬁes
diﬃcult observations by large residuals computed in the previous iterations.
Initialization
(1) Set the iteration counter m = 0. Initialize the additive predictor ˆf with a starting value, e.g. ˆf := (0)i=1,...,n. Specify a set of base-learners h1(x1), ..., hp(xp).
Fit the negative gradient
(2) Set m := m + 1.
(3) Compute the negative gradient vector u of the loss function evaluated at the
previous iteration:
i=1,...,n =
∂f ρ(yi, f)
f= ˆf[m−1](·)
(4) Fit the negative gradient vector u[m] separately to every base-learner:
base−learner
−−−−−−−→ˆh[m]
for j = 1, ..., p.
Update one component
(5) Select the component j∗that best ﬁts the negative gradient vector:
j∗= argmin
j (xj))2 .
(6) Update the additive predictor ˆf with this component
ˆf [m](·) = ˆf [m−1](·) + sl · ˆh[m]
where sl is a small step length (0 < sl ≪1). A typical value in practice is 0.1.
Iterate steps (2) to (6) until m = mstop.
Box 2: Component-wise gradient boosting algorithm
Generally, the underlying base-learner can be any regression technique; the most simple baselearner is a classical linear least-squares model with h(x) = x⊤β. If x is assumed to have a
non-linear eﬀect on the response, smoothing splines could be used . B¨uhlmann and Yu 
further developed the gradient boosting approach by applying component-wise smoothing
splines as base-learners.
The fundamental idea is that diﬀerent predictors are ﬁtted by
separate base-learners hj(·), j = 1, ..., p. Typically, each base-learner hj(·) corresponds to one
component xj of X and in every boosting iteration (as proposed in ) only a small amount
of the ﬁt of the best-performing base-learner is added to the current additive predictor.
The authors demonstrated that the resulting algorithm in combination with the L2 loss
outperforms classical additive modelling in terms of prediction accuracy. This approach was
further developed by B¨uhlmann who specially focused on high-dimensional data settings.
B¨uhlmann and Hothorn gave an overview of gradient boosting algorithms from a statistical perspective presenting a generic functional gradient descent algorithm (see Box 2).
As in , base-learners are used to ﬁt the negative gradient vector of the corresponding loss
function. The algorithm descends the empirical risk via steepest gradient descent in function
space, where the function space is provided by the base-learners. Each base-learner typically
includes one predictor and in every boosting iteration only the best-performing base-learner
and hence the best performing component of X is included in the ﬁnal model. This procedure eﬀectively leads to data-driven variable selection during the model estimation. The
base-learners h1(x1), ..., hp(xp) reﬂect the type of eﬀect the corresponding components will
contribute to the ﬁnal additive model, which oﬀers the same interpretability as any other
additive modelling approach. Examples for base-learners can be trees as in classical boosting
algorithms, but commonly simple regression tools like linear models or splines are used to
include linear as well as non-linear eﬀects on the response. Generally, it is consensus in the
literature that base-learners should be weak in the sense that they do not oﬀer too complex
solutions in a single iteration (e.g., penalized splines with small degrees of freedom ).
In contrast to standard estimation methods, component-wise gradient boosting also works
for high dimensional data where the number of predictors exceeds the number of observations
(p > n). Furthermore, it is relatively robust in cases of multicollinearity. Due to the small
step length in the update step (a typical value is 0.1 ) in combination with early stopping
(Section 3.3), gradient boosting incorporates shrinkage of eﬀect estimates in the estimation
process: The absolute size of the estimated coeﬃcients is intentionally reduced – this is a
similarity to penalized regression approaches as the Lasso . Shrinkage of eﬀect estimates
leads to a reduced variance of estimates and should therefore increase the stability and
accuracy of predictions .
The gradient boosting approach can be used to optimize any loss function that is at least
convex and diﬀerentiable: The framework is speciﬁcally not restricted to statistical distributions that are members of the exponential family as in classical GAMs. For example, Ma
and Huang applied gradient boosting with an adapted ROC (receiver operating characteristics) approach, optimizing the area under the ROC curve for biomarker selection from
high-dimensional microarray data.
Likelihood-based boosting
When considering statistical models, estimation in low-dimensional settings typically is performed by maximizing a likelihood. While such a likelihood can also be used to deﬁne a loss
function in gradient boosting, a boosting approach could also be built on base-learners that
directly maximize an overall likelihood in each boosting step. This is the underlying idea
Initialization
(1) Set the iteration counter m = 0.
Initialize the additive predictor ˆf with a
starting value, e.g. ˆf := (0)i=1,...,n or the maximum likelihood estimate ˆβ0 from
an intercept model (if the overall regression model includes an intercept term).
Candidate models
(2) Set m := m + 1.
(3) For each predictor xj, j = 1, ..., p estimate the corresponding functional term ˆhj(·),
as determined by parameter γj, by attaching a penalty term to the log-likelihood
l(γj), which includes ˆf [m−1](·) as an oﬀset.
Update one component
(4) Select the component j∗that results in the candidate model with the largest
log-likelihood l(ˆγj∗):
j∗= argmax
(5) Update ˆf [m] to
ˆf [m](·) = ˆf [m−1](·) + ˆh[m]
potentially adding an intercept term from maximum likelihood estimation.
Iterate steps (2) to (5) until m = mstop.
Box 3: Component-wise likelihood-based boosting algorithm
of likelihood-based boosting, introduced by Tutz and Binder . When the eﬀects of the
predictors x1, . . . , xp can be speciﬁed by a joint parameter vector β, the task is to maximize
the overall log-likelihood l(β). Given a starting value or estimate from a previous boosting
step ˆβ, likelihood-based boosting approaches use base-learners for estimating parameters γ
in a log-likelihood l(γ) that contains the eﬀect of ˆβ as a ﬁxed oﬀset. For obtaining small
updates, similar to gradient boosting, a penalty term is attached to l(γ). The estimates ˆγ
are subsequently used to update the overall estimate ˆβ. For continuous response regression
models, including an oﬀset is the same as ﬁtting a model to the residuals from the previous
boosting step, and maximization of l(γ) by a base-learner becomes standard least-squares
estimation with respect to these residuals. In this special case, likelihood-based boosting
thus coincides with gradient boosting for L2 loss .
Component-wise likelihood-based boosting performs variable selection in each step, i.e. there
is a separate base-learner for ﬁtting a candidate model for each predictor xj by maximizing
a log-likelihood l(γj).
The overall parameter estimate ˆβ then only is updated for that
predictor xj∗which results in the candidate model with the largest log-likelihood l(ˆγj). In
linear models, γj is a scalar value, and the penalized log-likelihood takes the form l(γj)−λγ2
where λ is a penalty parameter that determines the size of the updates. Component-wise
likelihood-based boosting then generalizes stagewise regression .
For a schematic overview of component-wise likelihood-based boosting see Box 3. Tutz and
Binder applied this principle to generalized additive models with B-spline base-learners.
Likelihood-based boosting for generalized linear models was introduced in another article by
Tutz and Binder and an approach for generalized additive mixed models was described
by Groll and Tutz . In these approaches, the best component for an update is selected
according to the deviance in each boosting step. To decrease the computational demand with
a large number of covariates, the likelihood-based boosting approach for the Cox proportional
hazards model instead uses a score statistic.
While component-wise likelihood-based boosting often provides results similar to gradient
boosting (e.g., ), the use of standard regression models in the boosting steps allows
for adaptation of techniques developed for the standard regression setting. For example,
unpenalized covariates can be incorporated in a straightforward way by not incorporating
these into the penalty term attached to l(γ) , but estimating their parameters together
with a potential intercept term in steps (1) and (5). Approximate conﬁdence intervals for the
estimated covariate eﬀects can be obtained by combining hat matrices from the individual
boosting steps .
Early stopping of statistical boosting algorithms
Although there are diﬀerent inﬂuential factors for the performance of boosting algorithms,
the stopping iteration mstop is considered to be the main tuning parameter . Stopping
the algorithm before its convergence (early stopping) prevents overﬁtting (Section 2.3) and
typically improves prediction accuracy. In case of statistical boosting, mstop controls both
shrinkage of eﬀect estimates and variable selection. The selection of mstop hence reﬂects the
common bias-variance trade-oﬀin statistical modelling: Large values of mstop lead to more
complex models with higher variance and small bias. Smaller values of mstop lead to sparser
models with less selected variables, more shrinkage and reduced variance .
To prevent overﬁtting, it is crucial not to consider the stopping iteration mstop that leads to
the best model on the training data but to evaluate the eﬀect of mstop on separate test data.
If no additional data are available, two general approaches are commonly applied:
The ﬁrst is to use information criteria (AIC, BIC or gMDL ) which evaluate the likelihood
on training data but additionally penalize too complex models by adding a multiple of their
degrees of freedom. There are two problems with this approach: (i) for component-wise
boosting algorithms these information criteria rely on an estimation of the degrees of freedom
that is known to underestimate the true values ; (ii) they are only available for a limited
number of loss functions.
The second, more general approach is to apply resampling or cross-validation techniques to
subsequently divide the data into test and training sets and choose mstop by evaluating the
models on the test data. For the evaluation, it is crucial to use the same loss function the
algorithm aims to optimize. If the algorithm in a binary classiﬁcation setting optimizes the
exponential loss, one should use the exponential loss and not the misclassiﬁcation rate to
select mstop. The optimal mstop is hence the one which leads to the smallest average empirical
loss on the out-of-sample test data.
Implementation and computational complexity
Most implementations of statistical boosting algorithms are included in freely available addon packages for the open source programming environment R . Worked out examples
and R-code for applying the most important implementations are provided in the Appendix
of this article.
Gradient boosting is implemented in the add-on package mboost (model-based boosting,
The package provides a large variety of pre-implemented loss functions and baselearners yielding wide-ranging possibilities for almost any statistical setting where regression
models can be applied. For an overview of how mboost can be used in biomedical practice,
see Hofner et al. . An alternative implementation of gradient boosting is provided with
the gbm package which focuses on trees as base-learners. Likelihood-based boosting
for generalized linear and additive regression models is provided by the add-on package
GAMBoost and an implementation of the Cox model is contained in the package
CoxBoost .
One of the main advantages of statistical boosting approaches compared to standard estimation schemes is that they are computationally feasible in p > n situations. The computational complexity of statistical boosting approaches depends mainly on the number of
separate base-learners. In case of component-wise boosting, the complexity increases linearly
with p . The computationally most burdensome part of applying statistical boosting in
practice is the selection of the stopping iteration mstop. In case of applying information
criteria (as the AIC), this involves multiplication of n × n matrixes for each boosting iteration, which becomes computationally problematic for data settings with large n. The
computing-time to select mstop via resampling procedures depends mainly on mstop itself,
the number of resamples B and p . In practice, selecting mstop via resampling can be
drastically fastened by applying parallel computing, which is implemented in all R packages
for statistical boosting.
Conclusion
One reason for the success of statistical boosting algorithms is their straight-forward interpretation. While competing machine learning approaches (including AdaBoost) may also
yield accurate predictions in case of complex data settings, they must be seen as black boxes:
The structure of the underlying data is considered irrelevant and the way diﬀerent predictors contribute to the ﬁnal solution remains unknown. Statistical boosting algorithms, in
contrast, are typically applied with simple regression-type functions as base-learners and
therefore yield classical statistical models, reﬂecting the contribution of diﬀerent predictors
on an outcome variable of interest. As a result, their solution oﬀers the same interpretation
as any other model in classical regression analysis – only that it was derived by applying one
of the most powerful prediction frameworks available in the toolbox of a modern statistician.
We presented two speciﬁc frameworks for statistical boosting: gradient boosting and likelihoodbased boosting. Although both algorithms are typically treated separately in the literature,
both follow the same structure and share the same historical roots. In some special cases
like the L2 loss and Gaussian response they coincide. While gradient boosting is a more
general approach and also allows for distribution-free regression settings like optimizing a
ROC curve or boosting quantile regression , likelihood-based boosting carries the
advantage that it delivers the Hessian matrix, which can be used to compute approximate
conﬁdence intervals for the estimated predictor eﬀects.
It is by no means an exaggeration to forecast that the application of statistical boosting
algorithms in biomedical research will increase in the years to come. One of the main reasons
for this development is that the number of candidate variables and predictors for modern
biomedical research has continuously been increasing in recent years. In this type of settings,
statistical boosting algorithms can demonstrate their full strengths via automated variable
selection and model choice while still providing the same interpretability most biomedical
research relies on.
Acknowledgements
The work on this article was supported by the Deutsche Forschungsgemeinschaft (DFG)
(www.dfg.de), grant SCHM 2966/1-1.
Discussion
An invited discussion on this article and its companion review can be found in the same
issue of Methods of Information in Medicine as the original article:
B¨uhlmann P, Gertheiss J, Hieke S, Kneib T, Ma S, Schumacher M, Tutz G, Wang CY,
Wang Z, Ziegler A. Discussion of “The Evolution of Boosting Algorithms” and “Extending
Statistical Boosting”. Methods Inf Med 2014; 53: XX-XX.