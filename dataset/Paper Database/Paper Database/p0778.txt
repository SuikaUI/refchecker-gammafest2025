Active Learning via Transductive Experimental Design
 
Siemens, Corporate Technology, Otto-Hahn-Ring 6, Munich 81739, Germany
 
Siemens, Medical Solutions, 51 Valley Stream Parkway, Malvern PA 19355, USA
Volker Tresp
 
Siemens, Corporate Technology, Otto-Hahn-Ring 6, Munich 81739, Germany
This paper considers the problem of selecting the most informative experiments x
to get measurements y for learning a regression model y = f(x).
We propose a
novel and simple concept for active learning, transductive experimental design, that
explores available unmeasured experiments
(i.e.,unlabeled data) and has a better scalability in comparison with classic experimental design methods.
Our in-depth analysis
shows that the new method tends to favor
experiments that are on the one side hardto-predict and on the other side representative for the rest of the experiments.
Eﬃcient optimization of the new design problem is achieved through alternating optimization and sequential greedy search. Extensive
experimental results on synthetic problems
and three real-world tasks, including questionnaire design for preference learning, active learning for text categorization, and spatial sensor placement, highlight the advantages of the proposed approaches.
1. Introduction
Recent years have seen considerable interests in learning with labeled and unlabeled data ,
since labels are often expensive to obtain whereas vast
amount of unlabeled data are easily available. Semisupervised learning 
solves the problem by exploring additional information
given by unlabeled data. Active learning reduces the
Appearing in Proceedings of the 23 rd International Conference on Machine Learning, Pittsburgh, PA, 2006. Copyright 2006 by the author(s)/owner(s).
labeling costs in a diﬀerent but complementary way,
which chooses the most informative data to label.
There has been a long tradition of research on active
learning in the machine learning community. Typically
discriminant models prefer to choosing uncertain or
hard-to-predict data, and generative models tend to
select typical data.
Uncertain data can be atypical
and even outliers. It is thus essential to unify these two
diﬀerent views. Active learning is also referred to as
experimental design in statistics , or choose the
most informative data that optimize some expected
gain . The latter typically requires expensive retraining of models when evaluating each candidate. Some other approaches assume generative models and explore the dependency between inputs and
outputs .
learning methods for support vector machines and Gaussian processes 
have also been suggested.
2.2. Experimental design
Classic experiment design considers learning a linear
function f(x) = w⊤x, w ∈Rd, from measurements
yi = w⊤xi + ϵi, i = 1, . . . , m, where ϵi ∼N(0, σ2)
is measurement noise, and x1, . . . , xm are experiments
chosen from n candidates v1, . . . , vn ∈Rd, n > m.
The goal of experimental design is to ﬁnd a set of experiments xi that together are maximally informative.
Following the convention in the machine learning literature, we call experiments x as data, and measurements y as labels.
In the rest of this paper, we use X to represent both
the matrix [x1, . . . , xm]⊤∈Rm×d and the set {xi},
and V to represent both [v1, . . . , vn]⊤∈Rn×d and the
set {vi}. The meanings will be clear in the contexts.
|X| = m and |V| = n respectively denote the sizes of
The maximum-likelihood estimate of w is obtained by
ˆw = arg min
It is known that the estimation error e = w −ˆw has
zero mean and a covariance matrix given by σ2Cw,
where Cw is the inverted Hessian of J(w)
and σ is a constant. The matrix Cw characterizes the
conﬁdence of the estimation, or the informativeness of
the selected data. Let mj denote the number of times
for which vj is chosen in X, so we have m1+· · ·+mn =
m. Then an optimization problem can be formulated
as minimization of some measurement of estimation
error derived from Cw. For example, the so-called Aoptimal design minimizes the trace of Cw
subject to
mj ≥0, m1 + · · · + mn = m, mi ∈Z
where Tr(·) is the trace. To relax the integer constraint
mj ∈Z, we set τj = mj/m and ignore mτj ∈Z, then
A-optimal design becomes
subject to
τ ⪰0, 1⊤τ = 1
where τ is the vector of τj’s, and 1 a column vector of
ones. This has been shown to be a convex semideﬁnite
programming (SDP) problem was applied to
biological experiments.
3. Transductive Experimental Design
3.1. Motivations
The classic experimental design methods described in
Sec. 2.2 have the following shortcomings.
• The optimization criteria based on Cw does not
directly characterize the quality of predictions on
test data. If the test data are given beforehand,
it is more sensible to directly assess the quality of
predictions y = f(x) on the test data.
• Standard experimental design only considers linear functions and is thus restrictive in applications.
• Very importantly, classic experimental design has
to solve a SDP problem, which is often very slow
when dealing with hundreds of data points.
To overcome these problems, this paper proposes experimental design in a transductive setting, where the
focus is on the predictive performance on known test
data, as well as the development of eﬃcient solutions.
Active Learning via Transductive Experimental Design
3.2. Formulations
A general setting may consider a diﬀerent set T of test
data points besides candidates in V. Here for simpli-
ﬁcation we assume that the two sets are the same. In
this section we will ﬁrst focus on linear functions and
then generalize it to the nonlinear case by applying
reproducing kernels. The scalability issue will be addressed in Sec. 4.
Let us consider a regularized linear regression problem
2 + µ∥w∥2
where µ > 0 and ∥· ∥is the vector 2-norm. Similar as
before, the inverted Hessian is computed as
= (X⊤X + µI)−1
Compared with Eq. (2), the newly introduced regularization improves numerical stability since X⊤X+µI is
full-rank. Let f = [f(v1), . . . , f(vn)]⊤be the function
values on all the available data V, then the predictive
error f −ˆf has the covariance matrix σ2Cf with
Cf = VCwV⊤= V(X⊤X + µI)−1V⊤
VV⊤−VX⊤(XX⊤+ µI)−1XV⊤i
where the Woodbury inversion identity is applied. In
contrast to Cw, Cf directly characterizes the quality
of predictions on the target data V. The average predictive variance on V is given by σ2
n Tr(Cf). A sensible design objective is to select m data points X from
V such that a high conﬁdence of predictions on the
available test data V is ensured.
Therefore we formulate the transductive experimental design problem
as a minimization of the predictive variance on test
data V. Since n, µ, σ and Tr(VV⊤) are constants, we
deﬁne the problem as
Deﬁnition 3.1. Transductive experimental design:
VX⊤(XX⊤+ µI)−1XV⊤i
subject to
X ⊂V, |X| = m
Since Tr(Cf) = Tr(CwV⊤V), the classical A-optimal
design can be seen as a subcase of transductive design,
however with a restrictive assumption V⊤V ∝I.
3.3. Interpretations
The following theorem helps to understand the behaviors of the proposed transductive experimental design.
Theorem 3.2. Transductive experimental design is
equivalent to
∥vi −X⊤ai∥2 + µ∥ai∥2
subject to
X ⊂V, |X| = m,
A = [a1, . . . , an]⊤∈Rn×m
Proof. We rewrite the cost function as L(X, A) =
F +µTr(AA⊤), where ∥·∥F is the Frobenius
norm for matrices. Then
L(X, A) = Tr
(V −AX)(V −AX)⊤i
+ µTr(AA⊤)
VV⊤−AXV⊤−VX⊤A⊤+ AXX⊤A⊤+ µAA⊤i
= Tr(VV⊤) −Tr
AXV⊤+ VX⊤A⊤−A(XX⊤+ µI)A⊤i
By taking the partial derivatives of L(X, A) with respect to A, it is easy to see that given X, the optimum
of A to minimize L(X, A) has the form
A∗= VX⊤(XX⊤+ µI)−1
Plugging this result into the loss function, we can get
min∥V −AX∥2
F + µTr(AA⊤)
=Tr(VV⊤) −Tr
VX⊤(XX⊤+ µI)−1XV⊤i
Given Tr(VV⊤) is a constant,
the minimization
problem with respect to X becomes the maximization of VX⊤(XX⊤+ µI)−1XV, which completes the
Theorem 3.2 transforms the problem into a regularized least squares formalism. Interestingly, it demonstrates an equivalence to ﬁnding the optimal set of
basis vectors X to approximate the whole set of vectors V ≡{vi} by ˆvi = X⊤ai. Based on the projection
theorem of least squares estimator, the approximations
can be seen as (regularized) projections of V onto the
linear subspace spanned by X. Therefore, transductive
experimental design has a clear geometric interpretation: it tends to ﬁnd representative data samples X
that span a linear space to retain most of the information of V. In contrast, standard experimental design
methods do not pursue this property.
On the other hand, the minimization in (9) encourages to particularly “focus on” those vi with large
norms, or even to directly include them into X. Intuitively, it is hard to obtain stable predictions for those
vi with big norms, because a small disturbance to w
can cause a big variation of f(vi) = w⊤vi. Therefore, Theorem 3.2 indicates that the selected X tends
Active Learning via Transductive Experimental Design
to well represent those hard-to-predict test cases in V.
Furthermore, in the context of sequential design (see
Sec. 4.1), vi are actually residuals of data after being approximated by previously selected data, which
means that vi with a larger norm correspond to data
that are under-represented by previously chosen data.
Therefore, transductive experimental design tends to
select data representative to those yet unexplored data
in a sequential design.
Like other experimental design methods, despite the
fact that we consider a supervised learning problem,
the data selection itself is independent of measurements y ≡{yi}. The reason is that the least squares
cost has only a linear dependency between w and y,
which makes the Hessian of J(w) independent of y.
Note that for classiﬁcation, not the focus of this paper, the situation is diﬀerent.
3.4. Kernel Transductive Experimental Design
Now we are ready to handle nonlinear functions. Let
H be a reproducing kernel Hilbert space (RKHS) with
a kernel function
k(x, v) = ⟨φ(x), φ(v)⟩, x, v ∈Rd
where φ : Rd →H is a feature mapping, then f ∈H
has the form f(x) = w⊤φ(x). Plugging it into (5),
we obtain a regularized linear regression in the feature space.
It is well-known that the solution has
the form f(x) = Pm
i=1 αik(xi, x), with coeﬃcients
α = [α1, . . . , αm]⊤estimated via a kernel regression
αjk(xj, xi) −yi
αiαjk(xi, xj)
Let’s denote the data in the transformed feature
[φ(x1), . . . , φ(xm)]⊤
[φ(v1), . . . , φ(vn)]⊤, and plug them into (8), we directly obtain the kernelized transductive experimental
Kvx(Kxx + µI)−1Kxv
subject to
X ⊂V, |X| = m
where (K)ij = k(vi, vj), (Kvx)ij = k(vi, xj) and
(Kxx)ij = k(xi, xj).
In the new kernelized version
we can directly work with a kernel function, like RBF
kernel, without explicitly referring to the feature mapping φ(·). f(x) can be nonlinear if a nonlinear kernel
is adopted. In the case of linear kernels, the kernel
regression and kernel transductive experimental design are equivalent to their counterparts introduced
in Sec. 3.2. In the rest of this paper, we will mainly
consider the kernel version.
4. Optimization Approaches
Although the transductive design has a simple interpretation, the involved optimization problem is a
diﬃcult combinatorial optimization problem, as indicated by the following theorem. We have to resort to
tractable approximations.
Theorem 4.1. Transductive experimental design is
Proof. Based on theorem 3.2, a special case of the
problem is to select m < n basis vectors from n candidates to approximate a single vector in the least
squares criterion. The case is known as a sparse linear regression problem with a cardinality constraint,
which has been proven to be NP-hard in (Natarajan,
The transductive design is NP-hard since it
approximates multiple vectors using sparse basis.
4.1. Sequential Optimization
In this subsection, we develop a very simple sequential greedy optimization approach. We ﬁrst formulate
transductive experimental design as a sequential optimization problem.
Given previously selected data
X1, a sequential transductive design seeks m new data
X2 ⊂V in the following way
Kvx(Kxx + µI)−1Kxv
subject to
X = X1 ∪X2, X2 ⊂V, |X2| = m
Problem (12) can be written as a canonical form of
transductive experimental design
˜Kvx2( ˜Kx2x2 + µI)−1 ˜Kx2v
subject to
X2 ⊂V, |X2| = m
where the kernel matrix ˜K is obtained by deﬂating the
original kernel matrix K by X1:
˜K = K −Kvx1(Kx1x1 + µI)−1Kx1v
Problem (13) can be understood as a kernel version
of the following procedure: after approximating V by
X1, the approximation residuals ˜V form a new kernel
matrix ˜K = ˜V ˜V
⊤, and a set of m vectors from ˜V are
selected to further approximate ˜V. As pointed out in
Sec. 3.3, the algorithm tends to select data that are
typical among those under-represented by X1.
Since it is very simple to select just one data point,
we propose an easy-to-implement algorithm that iteratively performs the following two steps until m data
points have been selected. Note that there is no need
for matrix inverse.
Active Learning via Transductive Experimental Design
Algorithm 1: Sequential Design
• Select x ∈V with the highest ∥Kx∥2/(k(x, x) +
µ), and add x into X, where Kx and k(x, x) are
x’s corresponding column and diagonal entry in
current K;
• Update K ←K −
(k(x,x)+µ);
4.2. Alternating Optimization
Sequential optimization is a greedy process that can be
suboptimal. In this subsection we ﬁrst transform the
problem into an equivalent regression-like formalism,
which makes it possible to relax the discrete nature of
the problem and then design non-greedy mathematical
programming solutions.
Theorem 4.2. Let Q = [q1, . . . , qn]⊤and π1 ≥. . . ≥
πn be the eigenvectors and eigenvalues of K = VV⊤.
Then transductive experimental design is equivalent to
∥√πiqi −Kvxci∥2 + µπi∥ci∥2
subject to
X ⊂V, |X| = m,
C = [c1, . . . , cn]⊤∈Rn×m
Proof. Let V has the singular value decomposition
V = QΠ1/2P⊤. Then based on Theorem 3.2, given
X, at the minimum of ∥V−AX∥2
F +µTr(AA⊤) there
F = ∥V −VX⊤(XX⊤+ µI)−1X∥2
= ∥VP −VX⊤(XX⊤+ µI)−1XP∥2
= ∥QΠ1/2 −VX⊤(XX⊤+ µI)−1XP∥2
µTr(A∗A∗⊤)
VX⊤(XX⊤+ µI)−2XV⊤i
QΠ1/2P⊤X⊤(XX⊤+ µI)−2XPΠ1/2Q⊤i
Π1/2P⊤X⊤(XX⊤+ µI)−2XPΠ1/2i
Let C = P⊤X⊤(XX⊤+ µI)−1, then the minimum of
F + µTr(AA⊤) must have the form
∥QΠ1/2 −K⊤
F + µTr[C⊤ΠC].
Tr[Π1/2CC⊤Π1/2]
Tr[C⊤ΠC]. Obviously, minimizing the above new cost
function with respect to C ∈Rn×m is a variational formalism of minimization in problem (15) with respect
to w. The proof is ﬁnished.
Theorem 4.2 shows that the transductive design is
equivalent to choosing m columns in K that can be
used to best approximate eigenvectors of K. Due to
the weighting by eigenvalues πi in (15), a better eﬃciency can be achieved by considering only those leading eigenvectors q of K. Note that X is a subset of V
assuming that all available data are given in V as its
rows. Denote a matrix B as an n × n diagonal matrix
with its j-th diagonal element equal to βj ∈{0, 1}. We
call B an indicator matrix indicating whether or not
an according data point will appear in X. If βj = 1, vj
is included in X. Then Kvxci = KBαi where αi is an
n vector with its subset of m components (indicated
in B) equal to ci correspondingly.
Then the transductive design problem is equivalent to the following
integer program:
∥√πiqi −KBαi∥2 + µπi∥Bαi∥2
subject to B = diag(β),
Card(β) = m,
βj ∈{0, 1},
j = 1, · · · , n.
Problem (16) is often computationally intractable
since it requires branch-and-bound procedure to optimize integer variables β. We relax constraints on integer variables β to allow them to take real numbers.
Then βj corresponds to a scaling factor indicating how
signiﬁcantly the corresponding data in V contributes
to the minimization of (16). We then enforce the sparsity of β. Sparsity can be enforced by employing regularization conditions on β, such as the 0-norm penalty
which controls the cardinality of β, ), or
the 1-norm penalty which is less stringent than the 0norm penalty. To derive computationally eﬃcient and
scalable formulations, we relax the problem to use 1norm penalty on β instead of restricting its cardinality.
Problem (16) becomes
∥√πiqi −KBαi∥2 + µπi∥Bαi∥2 + γ∥β∥1
subject to
B = diag(β),
j = 1, · · · , n.
The residual term √πiqi−KBαi in problem (17) is bilinear with respect to β and αi. Taking the 2-norm of
the residual introduces polynomial terms of high order
in terms of its variables and thus the problem is still
arduous to solve. We propose an alternating optimization approach to problem
(17) by repeating steps depicted in Algorithm 2, which
is similar, in spirit, to the principle of Expectation-
Maximization (EM) algorithms. Moreover, note that
∥β∥1 = P βj due to the nonnegativity of βj.
Active Learning via Transductive Experimental Design
Algorithm 2: Alternating Design
• Fix B to the current solution (initially to the identity matrix I), convert ˜K ←KB, solve the following problem for optimal αi,
i=1 ∥√πiqi −˜Kαi∥2 + µπi∥Bαi∥2
• Fix αi to the solution obtained at the above step,
convert Ki ←K · diag(αi), solve the following
problem for optimal ˆβ,
i=1 ∥√πiqi −Kiβ∥2 + µπi∥β ⊗αi∥2
• B ←B ⊗diag(ˆβ)
where ⊗denotes the component-wise multiplication
between two matrices. The algorithm takes a greedy
scheme in the third step of the iterations, assuring data
samples receiving small scaling factors in early iterations will continue receiving small weights.
The ﬁrst step of Algorithm 2 solves a simple ridge
regression problem which can be de-coupled to minimize ∥√πiqi −˜Kαi∥2 + µπi∥Bαi∥2 for each individual αi.
Thus, problem (18) actually has a closedform solution, which is to solve B (KK + µπiI) Bαi =
√πiBKqi where the diagonal matrix B may not be
full rank. The solution ˆαi = B−1 (KK + µπiI)−1 Kqi
where B−1 denotes the diagonal matrix whose nonzero diagonal elements equal the inverse of nonzero
diagonal components of B. Note that the matrix inversion (KK + µπiI)−1 only needs to be calculated in
the ﬁrst iteration and can then be reused in later iterations, thus gaining computational eﬃciency.
The second step of Algorithm 2 solves a quadratic programming problem. Denote Λi = diag(αi). The problem (19) can be rewritten in the following canonical
form of a quadratic program:
i (Λi(KK + µπiI)Λi) β
5. Experiments
In this section we test the kernel transductive experimental design in a number of settings. To the best of
our knowledge, there is no kernel A-optimal design in
the literature. For a fair comparison to our approach,
we ﬁrst use kernel PCA to map data points into an ndimensional linear space, and then apply the standard
A-optimal design solved by the SeDuMi optimization
(a) Data set
(b) A-optimal design
(c) Sequential design
(d) Alternating design
Figure 1. Experimental design (m = 4) on synthetic I. Selected data are marked by red triangles, gray levels and
contours indicate the predictive variance of the learned
function in the input space (darker means lower variance).
package1. For those methods that compute nonnegative coeﬃcients for each candidate data points, like
alternating transductive design and A-optimal design,
we choose those m data points having the biggest coeﬃcients. In all the investigated problems, µ is ﬁxed
Synthetic problem I: We generate a mixture of four
Gaussian components in a 2-D space, as shown in
Fig. 1-(a). An RBF kernel with length scale 1.8 is used.
Classical experimental design, such as A-optimal design, attempts to choose data on the border of data
set as shown Fig. 1-(b), where the low predictive variance area covers a space without many data samples
present. In contrast, as shown in Fig. 1-(c) and (d),
the two variants of transductive design both select representative data regarding the whole distribution.
Synthetic problem II: In this case we show that sequential design can sometimes obtain suboptimal solutions while the alternating approach is superior. As
shown in Fig. 2-(a), the data set consisted of two major Gaussians in the left and right sides and a minor Gaussian in the middle. An RBF kernel with the
length scale 2.5 is applied. The sequential transductive design ﬁrst picked up a point near the center of
the data and then picked another point close to the
right border, as shown in Fig. 2-(c). This result is less
optimal than that of non-sequential solutions shown in
Fig. 2-(d).
1 
Active Learning via Transductive Experimental Design
(a) Questionnaire Design
(b) Text Categorization
(c) Sensor Placement
Figure 3. Experimental design in various applications
(a) Data set
(b) A-optimal design
(c) Sequential design
(d) Alternating design
Figure 2. Experimental design (m = 2) on synthetic problem II. The sequential transductive design is suboptimal
compared with the non-sequential solution.
Questionnaire Design for Recommender Systems: The so-called “cold-start problem” of recommender systems refers to the diﬃculty of providing accurate recommendations if the system does not know
a user’s preferences on any products.
To solve the
problem, the system usually requires the user to rate
a set of products.
In this experiment we consider
questionnaire design to select informative products.
Our study is based on the well-known Eachmovie data
set, which contains 74,424 users’ numerical ratings
{1, 2, 3, 4, 5, 6} on 1648 movies. We follow the same
setting as , which chose 5000 users’
ratings as training data and a diﬀerent set of 5000 users
for test. Then each movie is seen as being represented
by a 5000-dimensional feature vector formed by 5000
training users’ ratings on it. In forming feature vectors, we estimate each training user’s mean rating and
use it to centralize this user’s ratings. Given a test
user’s ratings on a set of movies, we apply regularized linear regression (or equivalently, kernel regression with linear kernels) to predict this user’s ratings
on other unrated movies. Mean absolute error (MAE)
is the most common accuracy metric in the literature. We use experimental design methods to choose
m = 5, 10, 15, . . . , 45, 50 movies. Since each test user
only watched a subset of movies, given a particular
questionnaire, some test users may have no ratings on
the chosen movies. In this case we use each movie’s
mean ratings as predictions. To alleviate the sparsity
problem, we restrict the question candidates to those
100 most popular movies, regarding to their numbers
of received ratings in the training set. MAE is evaluated on test users’ ratings on movies outside of the
questionnaire. The results are shown in Fig. 3-(a). As
a baseline, “Random Design” chooses m movies randomly, repeated by 10 times. The mean and standard
deviation are plotted.
The second baseline, “Most
Popular Movies”, chooses the m most frequently rated
movies. A bit surprisingly, choosing the most popular
movies does not bring advantages over random guessing. This is because that the most popular movies are
rated highly by nearly all the users and thus give no
information about user tastes. MAE is even increased
as m going over 25, because less popular movies and
relatively more hard movies are left for accuracy evaluation.
Very positively, all the experimental design
methods outperform the two baselines. In this task
transductive design shows results comparable to that
of A-optimality.
Text Categorization: We validate experimental design methods on text categorization based on a subset of Newsgroup corpus, which contains 8014 dimensional TFIDF features and 3970 documents, covering
four categories autos, motorcycles, baseball, hockey.
We conduct one-against-all scheme for each category
and thus treat the problem as binary classiﬁcation
(y = {−1, 1}). Due to the unbalance of two classes,
AUC score is used to evaluate the accuracy, averaged
over the 4 topics. We apply kernel regression with linear kernels, which has shown the state-of-art for text
categorization compared to SVMs is also examined, which chooses data
closest to the classiﬁcation boundary.
For each run
of this method we initialize with a SVM trained on a
pair of randomly chosen positive and negative examples. With 10 random initializations, mean and errorbar are computed. As the baseline, random design is
also repeated 10 times to produce the errorbars. The
results are shown in Fig. 3-(b). Transductive design
methods signiﬁcantly outperform the competitors. For
example, AUC based on just 10 selected training examples achieves 90.2%, in contrast to 77.0% with random sampling. Interestingly, SVM active learning and
A-optimal design perform much worse than random
sampling. This is because that Newsgroup data has a
very clear clustering structure (like synthetic problem
I). As illustrated in the synthetic problem I, A-optimal
design does not explore this structure.
SVM active
learning tends to select untypical data and thus does
not either. Since SDP by SeDuMi aﬀords A-optimal
design with up to 400 candidates, we have to restrict
the candidates of A-optimality to a random set of 397
documents. To make the comparison fair, we also apply sequential transductive design based on the same
candidate set (shown as “Sequential Design (L)”) and
still produce much better results.
Sensor Placement: The application is to measure indoor temperature based on optimal placement of sensors.
The data was previously applied in , consist of snapshots of measurements
from 54 sensors in a hall within two days. We apply
experimental design to select sensors such that remaining sensors’ measurements can be optimally predicted.
In this case we employ nonlinear kernels between locations, oﬀered by the authors of .
Fig. 3-(c) shows the results measured by MAE, averaged over 10,000 snapshots. Tansductive design generally outperforms random selection. A-optimal design
does not show much advantages, largely because all the
sensors are not uniformed distributed in the space.
6. Conclusions
In this paper we proposed transductive experimental
design for active learning of regression models. As a
key advantage over classical methods, it fully explores
the available unlabeled data and demonstrates sensible data selection properties. Eﬃcient solutions were
developed. The achieved experimental results suggest
its wide applicability to real-world applications. In the
near future it would be interesting to develop a similar
idea for classiﬁcation models.