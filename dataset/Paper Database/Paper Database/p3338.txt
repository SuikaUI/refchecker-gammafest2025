Swinburne University of Technology | CRICOS Provider 00111D | swinburne.edu.au
Swinburne Research Bank
 
Lin, M., Wierman, A., Andrew, L. L. H., & Thereska, E. . Dynamic rightsizing for power-proportional data centers.
Originally published in Proceedings of the 30th IEEE International Conference on
Computer Communications , Shanghai, China, 10–15 April
2011 (pp. 1098-1106). Piscataway, NJ: IEEE.
Available from: 
Copyright © 2011 IEEE.
This is the author’s version of the work, posted here with the permission of the
publisher for your personal use. No further distribution is permitted. You may also be
able to access the published version from your library. The definitive version is
available at 
Dynamic right-sizing for power-proportional data centers
Minghong Lin and Adam Wierman
California Institute of Technology
Lachlan L. H. Andrew
Swinburne University of Technology
Eno Thereska
Microsoft Research
Abstract—Power consumption imposes a signiﬁcant cost for
data centers implementing cloud services, yet much of that power
is used to maintain excess service capacity during periods of
predictably low load. This paper investigates how much can be
saved by dynamically ‘right-sizing’ the data center by turning off
servers during such periods, and how to achieve that saving via
an online algorithm. We prove that the optimal ofﬂine algorithm
for dynamic right-sizing has a simple structure when viewed in
reverse time, and this structure is exploited to develop a new
‘lazy’ online algorithm, which is proven to be 3-competitive. We
validate the algorithm using traces from two real data center
workloads and show that signiﬁcant cost-savings are possible.
I. INTRODUCTION
Energy costs represent a signiﬁcant fraction of a data
center’s budget and this fraction is expected to grow as
the price of energy increases in coming years. Hence, there
is a growing push to improve the energy efﬁciency of the
data centers behind cloud computing. A guiding focus for
research into ‘green’ data centers is the goal of designing
data centers that are ‘power-proportional’, i.e., use power only
in proportion to the load. However, current data centers are
far from this goal – even today’s energy-efﬁcient data centers
consume almost half of their peak power when nearly idle .
A promising approach for making data centers more powerproportional is using software to dynamically adapt the number
of active servers to match the current workload, i.e., to
dynamically ‘right-size’ the data center. Speciﬁcally, dynamic
right-sizing refers to adapting the way requests are dispatched
to servers in the data center so that, during periods of low
load, servers that are not needed do not have jobs routed to
them and thus are allowed to enter a power-saving mode (e.g.,
go to sleep or shut down).
Technologies that implement dynamic right-sizing are still
far from standard in data centers due to a number of challenges. First, servers must be able to seamlessly transition into
and out of power saving modes while not losing their state.
There has been a growing amount of research into enabling this
in recent years, dealing with virtual machine state , network
state and storage state , . Second, such techniques
must prove to be reliable, since administrators we talk to worry
about wear-and-tear consequences of such technologies. Third,
and the challenge that this paper addresses, it is unclear how
to determine how many servers to toggle into power-saving
mode and how to control servers and requests.
A goal of this paper is to provide a new algorithm to address
this third challenge. To this end, we develop a simple but
general model that captures the major issues that affect the
design of a right-sizing algorithm, including: the cost (lost
revenue) associated with the increased delay from using fewer
servers, the energy cost of maintaining an active server with
a particular load, and the cost incurred from toggling a server
into and out of a power-saving mode (including the delay,
energy, and wear-and-tear costs).
This paper makes three contributions: First, we analytically
characterize the optimal ofﬂine solution (Section III). We prove
that it exhibits a simple, ‘lazy’ structure when viewed in
reverse time.
Second, we introduce and analyze a novel, practical online
algorithm motivated by this structure (Section IV). The algorithm, named Lazy Capacity Provisioning (LCP(w)), uses a
prediction window of length w of future arrivals and mimics
the ‘lazy’ structure of the optimal algorithm, but proceeding
forward instead of backwards in time. We prove that LCP(w)
is 3-competitive: its cost is at most 3 times that of the optimal
ofﬂine solution. This is regardless of the workload and for
very general energy and delay cost models, even when no
information is used about arrivals beyond the current time
period (w = 0). Further, in practice, LCP(w) is far better than
3-competitive, incurring nearly the optimal cost.
Third, we validate our algorithm using two load traces
(from Hotmail and a Microsoft Research data center) to
evaluate the cost savings achieved via dynamic right-sizing
in practice (Section V). We show that signiﬁcant savings
are possible under a wide range of settings and that savings
become dramatic when the workload is predictable over an
interval proportional to the toggling cost. The magnitude of the
potential savings depend primarily on the peak-to-mean ratio
(PMR) of the workload, with a PMR of 5 being enough to give
50% energy saving and 40% total cost saving even for quite
bursty workloads. In the context of these real traces, we also
discuss when it does and when it does not make sense to use
dynamic right-sizing versus the alternative of ‘valley-ﬁlling’,
i.e., using periods of low load to run background/maintenance
tasks. We ﬁnd that dynamic right-sizing provides more than
15% cost savings even when the background work makes up
> 40% of the workload when the PMR is larger than 3.
II. MODEL FORMULATION
We now describe the model we use to explore the cost
savings possible via dynamic right-sizing of data centers. The
assumptions used in the model are minimal and capture many
properties of current data centers and traces we have obtained.
A. The workload model
We consider a discrete-time model where the timeslot length
matches the timescale at which the data center can adjust its
capacity. There is a (possibly long) time-interval of interest
t ∈{0, 1, . . . , T}. The mean arrival rate for slot t is denoted
by λt. For convenience, we enforce that λt = 0 for all t ≤0
and all t ≥T. We assume that the job interarrival times are
much shorter than the timeslot, so that provisioning can be
based on the average arrival rate during a slot. In practice, T
could be a year and a slot t could be 10 minutes.
The analytic results of Sections III and IV assume that the
workload has a ﬁnite duration, i.e. T < ∞, but make no
other assumptions about λt, i.e., λt can be arbitrary. Thus,
the analytic results provide worst-case guarantees. However,
to provide realistic cost estimates, we consider case-studies in
Section V where λt is deﬁned using real-world traces.
B. The data center cost model
We model a data center as a collection of homogeneous
servers.1 We focus on two important decisions for the data
center: (i) determining xt, the number of active servers during
each time slot t, and (ii) assigning arriving jobs to servers, i.e.,
determining λi,t, the arrival rate to server i at time t. (Note
i=1 λi,t = λt.) The data center wants to choose xt and
λi,t to minimize the cost during [1, T]. Our model for the cost
focuses on the server costs of the data center.2
We model the cost of a server by (i) the operating costs
incurred by an active server and (ii) the switching costs to
toggle a server into and out of a power-saving mode (e.g.,
off/on or sleeping/waking). Both components include energy
and delay costs.
The operating costs are modeled by a convex function
f(λi,t), which is the same for all servers. The convexity
assumption is quite general and captures many common server
models. One example of a convex cost model is a weighted
sum of delay costs and energy costs: r(λi,t, d)+e(λi,t), where
r(λi,t, d) is the revenue lost given delay d and arrival rate λi,t,
and e(λi,t) is the energy cost of an active server handling
arrival rate λi,t. One common model of the energy cost for
typical servers is an afﬁne function e(λi,t) = e0 + e1λi,t
where e0 and e1 are constants; e.g., see . The lost revenue is more difﬁcult to model. One natural model for it
is r(λi,t, d) = d1λi,t(d −d0)+ where d0 is the minimum
delay users can detect and d1 is a constant. This measures the
perceived delay weighted by the fraction of users experiencing
that delay. Further, the average delay can be modeled using
standard queuing theory results. For example, if the server
happens to be modeled by an M/GI/1 Processor Sharing
queue then d = 1/(1 −λi,t), where the service rate of the
server is assumed to be 1 without loss of generality . The
combination of these models gives
f(λi,t) = d1λi,t
+ (e0 + e1λi,t)
The above is one example that convex f(·) can capture, but
the results hold for any convex model of operating costs. Other
examples include, for instance, using the 99th percentile of
delay instead of the mean. In fact, if the server happens to be
modeled by an M/M/1 Processor Sharing queue then the 99th
percentile is log(100)/(1 −λ), and so the form of (1) does
not change . Similarly, when servers use dynamic speed
scaling, if the energy cost is modeled as polynomial in speed
as in , then the aggregate cost f(·) remains convex ,
 . Note that, in practice, f(·) can be empirically measured
by observing the system over time.
The switching cost, β, models the cost of toggling a server
back-and-forth between active and power-saving modes. The
constant β includes the costs of (i) the energy used toggling
1Multiple classes of servers can easily be incorporated at the cost of added
notational complexity.
2Minimizing server energy consumption also reduces cooling and power
distribution costs .
a server, (ii) the delay in migrating connections/data/etc. (e.g.,
via VM techniques) when toggling a server, (iii) increased
wear-and-tear on the servers toggling, and (iv) the risk associated with server toggling. If only (i) and (ii) matter, then β
is on the order of the cost to run a server for a few seconds
(waking from suspend-to-RAM) or migrating network state 
or storage state , to several minutes (to migrate a large
VM ). However, if (iii) is included, then β becomes on the
order of the cost to run a server for an hour . Finally, if
(iv) is considered then our conversations with operators suggest
that their perceived risk that servers will not turn on properly
when toggled is high, so β may be many hours’ server costs.
Note that this model ignores many issues surrounding reliability and availability, which are key components of data
center service level agreements (SLAs). In practice, a solution
that toggles servers must still maintain the reliability and
availability guarantees. For example, if data is replicated three
times and two copies fail while the third is asleep, the third
copy must immediately be woken. Modeling such failures is
beyond the scope of this paper, however previous work shows
that solutions are possible .
C. The data center optimization problem
Given the cost models above, the goal of the data center is
to choose the number of active servers xt and the dispatching
rule λi,t to minimize the total cost during [1, T], which is
captured by the following optimization:
f(λi,t) + β
(xt −xt−1)+
subject to
0 ≤λi,t ≤1 and
λi,t = λt,
where the constraint λi,t ≤1 is a result of normalizing the
arrival rate, without loss of generality, such that an arrival rate
of 1 is the largest that a server can stabilize. Note that we
model the cost β of toggling a server as being incurred when
the server is returned to an active state. Though the data center
seeks to solve (2), it must do so in an online manner, i.e, at
time τ, it does not have full information about λt for t > τ.
In the remainder of this section we simplify the form of (2)
by noting that, if xt is ﬁxed, then the remaining optimization
for λi,t is convex. Thus, we can use the KKT conditions to
determine the optimal dispatching rule λ∗
i,t. This yields that
2t = · · · = λt/xt, which implies that once xt is ﬁxed
the optimal dispatching rule is to “load balance” across the
servers. Given that load balancing is always optimal, we can
decouple dispatching (λi,t) from capacity planning (xt), and
simplify (2) into purely a capacity planning optimization:
xtf(λt/xt) + β
(xt −xt−1)+
subject to
It is this formulation of the data center optimization that we
focus on for the remainder of the paper. Note that xtf(λt/xt)
is the perspective function of the convex function f(·), thus
it is also convex. Therefore, (3) is a convex optimization
problem for xt. Throughout, denote the operating cost of a
vector X = (x1, . . . , xT ) by costo(X) = PT
t=1 xtf(λt/xt),
costs(X) = β PT
t=1(xt−xt−1)+, and cost(X) = costo(X)+
Formulation (3) makes two important simpliﬁcations. First,
it does not enforce that xt be integer valued. This is acceptable
since the number of servers in a typical data center is large.
Second, it does not enforce an upper bound on the number
of servers active at time t. However, numerical results suggest
that the optimal solution with the additional constraint xt < K
is simply the minimum of K and the solution to (3).
III. THE OPTIMAL OFFLINE SOLUTION
Given the data center optimization problem, the ﬁrst natural
task is to characterize the optimal ofﬂine solution, i.e., the
optimal solution given access to the the full vector of λt. The
insight provided by the characterization of the ofﬂine optimum
motivates the formulation of our online algorithm.
It turns out that there is a simple characterization of the
optimal ofﬂine solution to the data center optimization problem, X∗in terms of two bounds on the optimal solution
which correspond to charging β cost either when a server goes
into power-saving mode or when comes out. The optimal x∗
can be viewed as ‘lazily’ staying within these bounds going
backwards in time.
More formally, let us ﬁrst describe upper and lower bounds
τ, denoted xU
τ , respectively. Let (xL
τ,1, . . . , xL
be the solution vector to the following optimization problem
xtf(λt/xt) + β
(xt −xt−1)+
subject to
Then, deﬁne xL
τ,τ. Similarly, let (xU
τ,1, . . . , xU
τ,τ) be the
solution vector to the following optimization problem
xtf(λt/xt) + β
(xt−1 −xt)+
subject to
Then, deﬁne xU
Notice that in each case, the optimization problem includes
only times 1 ≤t ≤τ, and so ignores the arrival information
for t > τ. In the case of the lower bound, β cost is incurred
for each server toggled on, while in the upper bound, β cost
is incurred for each server toggled into power-saving mode.
Lemma 1. For all τ, xL
Given Lemma 1, we now characterize the optimal solution
τ. Deﬁne (x)b
a = max(min(x, b), a) as the projection of x
into [a, b]. Then, we have:
Theorem 1. The optimal solution X∗= (x∗
0, . . . , x∗
T ) of the
data center optimization problem (3) satisﬁes the following
backward recurrence relation
Theorem 1 and Lemma 1 are proven in Appendix A.
An example of the optimal x∗
t can be seen in Figure 1(a).
Many more numeric examples of the performance of the
optimal ofﬂine algorithm are provided in Section V.
time t (hours)
(a) Ofﬂine optimal
time t (hours)
(b) LCP(0)
Illustrations of (a) the ofﬂine optimal solution and (b) LCP(0) for
the ﬁrst day of the MSR workload described in Section V with a sampling
period of 20 minutes. The operating cost is deﬁned by (1) with d0 = 1.5,
d1 = 1, µ = 1, e0 = 1 and e1 = 0 and the switching cost has β = 8.
Theorem 1 and Figure 1(a) highlight that the optimal algorithm can be interpreted as moving backwards in time, starting
T = 0 and keeping x∗
τ+1 unless the bounds
prohibit this, in which case it makes the smallest possible
change. An important point highlighted by this interpretation
is that it is impossible for an online algorithm to compute x∗
since, without knowledge of the future, an online algorithm
cannot know whether to keep xτ constant or to follow the
upper/lower bound.
IV. LAZY CAPACITY PROVISIONING
A major contribution of this paper is the presentation and
analysis of a novel online algorithm, Lazy Capacity Provisioning (LCP(w)). At time τ, LCP(w) knows only λt for t ≤τ+w,
for some prediction window w. Here, we assume that these are
known perfectly, but we show in Section V that the algorithm
is robust to this assumption in practice. The design of LCP(w)
is motivated by the structure of the optimal ofﬂine solution
described in Section III. Like the optimal solution, it “lazily”
stays within upper and lower bounds. However, it does this
moving forward in time instead of backwards in time.
Before deﬁning LCP(w) formally, recall that the bounds
τ do not use knowledge the loads in the prediction
window of LCP(w). To use it, deﬁne reﬁned bounds xU,w
such that that xU,w
τ+w,τ in the solution of (5)
τ+w,τ in the that of (4). Note that xU,0
τ . The following generalization of Lemma 1 is
proven in Appendix B.
Lemma 2. xL
τ for all w ≥0.
Now, we are ready to deﬁne LCP(w) using xU,w
Algorithm 1. Lazy Capacity Provisioning, LCP(w).
Let XLCP (w) = (xLCP (w)
, . . . , xLCP (w)
) denote the vector
of active servers under LCP(w). This vector can be calculated
using the following forward recurrence relation
Figure 1(b) illustrates the behavior of LCP(0). Note its
similarity with Figure 1(a), but with the laziness in forward
time instead of reverse time.
The computational demands of LCP(w) may initially seem
prohibitive as τ grows, since calculating xU,w
requires solving convex optimizations of size τ +w. However,
it is possible to calculate xU,w
without using the
full history. Lemma 9 in Appendix B implies that it is enough
to use only the history since the most recent point when the
time (hours)
(a) Hotmail
time (hours)
Illustration of the traces used for numerical experiments.
solutions of (4) and (5) are either both increasing or both
decreasing, if such a point exists. In practice, this period is
typically less than a day due to diurnal trafﬁc patterns, and so
the convex optimization, and hence LCP(w), remains tractable
even as τ grows.
Next, consider the cost incurred by LCP(w). Section V
discusses the cost in realistic settings, while in this section
we focus on worst-case bounds. In particular, we derive a
competitive ratio. We say that an algorithm is C-competitive if
for all problem instances (all convex cost functions and ﬁnite
arrival rate vectors), the cost of the algorithm is less than C
times the cost of the optimal ofﬂine solution. The following
theorem is proven in Appendix B.
Theorem 2. cost(XLCP (w)) ≤cost(X∗)+2costs(X∗). Thus,
LCP(w) is 3-competitive for optimization (3). Further, for any
ﬁnite w and ϵ > 0 there exists an instance such that LCP(w)
attains a cost greater than 3 −ϵ times the optimal cost.
Note that Theorem 2 says that the competitive ratio is independent of any parameters of the model, e.g., the prediction
window size w, the switching cost β, and the form of the
operating cost function f(λ). Surprisingly, this means that even
the “myopic” LCP(0) is 3-competitive, regardless of the arrival
vector, despite having no information about arrivals beyond the
current timeslot. It is also surprising that the competitive ratio
is tight regardless of w. Seemingly, for large w, LCP(w) should
provide reduced costs. Indeed, for any particular workload,
as w grows the cost decreases and eventually matches the
optimal. However, for any ﬁxed w, there is a worst-case arrival
sequence and cost function such that the competitive ratio is
arbitrarily close to 3.
Finally, though 3-competitive may seem like a large gap, the
fact that cost(XLCP (w)) ≤cost(X∗)+2costs(X∗) highlights
that the gap will tend to be much smaller in practice, where
the switching costs make up a small fraction of the total costs
since dynamic right-sizing would tend to toggle servers once
a day due to the diurnal trafﬁc.
V. CASE STUDIES
In this section our goal is two-fold: First, we seek to evaluate
the cost incurred by LCP(w) relative to the optimal solution
in the context of realistic workloads. Second, more generally,
we seek to illustrate the cost savings and energy savings that
come from dynamic right-sizing in data centers. To accomplish
these goals, we experiment using two real-world traces.
A. Experimental setup
Throughout the experimental setup, our aim is to choose
parameters that provide conservative estimates of the cost
savings from LCP(w) and right-sizing in general.
% of load due to spike
% cost reduction
Impact of overnight peak in
the Hotmail workload.
Mean prediction error (% mean load)
% cost reduction
Impact of prediction error on
LCP(w) under Hotmail workload.
Cost benchmark: Current data centers typically do not use
dynamic right-sizing and so to provide a benchmark against
which LCP(w) is judged, we consider the cost incurred by
a ‘static’ right-sizing scheme for capacity provisioning. This
chooses a constant number of servers that minimizes the costs
incurred based on full knowledge of the entire workload. This
policy is clearly not possible in practice, but it provides a very
conservative estimate of the savings from right-sizing since it
uses perfect knowledge of all peaks and eliminates the need
for overprovisioning in order to handle the possibility of ﬂash
crowds or other trafﬁc bursts.
Cost function parameters: The cost is characterized by the
four parameters of (1), d0, d1, e0 and e1, and the switching
cost β. We choose units such that the ﬁxed energy cost is
e0 = 1. The load-dependent energy consumption is set to
e1 = 0, because the energy consumption of current servers
is dominated by the ﬁxed costs .
The delay cost d1 reﬂects revenue lost due to customers
being deterred by delay, or to violation of SLAs. We set
d1/e0 = 1 for most experiments but consider a wide range
of settings in Figure 7. The minimum perceptible delay is set
to d0 = 1.5 times the time to serve a single job. The value 1.5
is realistic or even conservative, since “valley ﬁlling” experiments similar to those of Section V-B show that a smaller value
would result in a signiﬁcant added cost when valley ﬁlling,
which operators now do with minimal incremental cost.
The normalized switching cost β/e0 measures the duration a
server must be powered down to outweigh the switching cost.
We use β = 6, which corresponds to the energy consumption
for one hour (six samples). This was chosen as an estimate
of the time a server should sleep so that the wear-and-tear of
power cycling matches that of operating .
Workload information: The workloads for these experiments
are drawn from two real-world data center traces. The ﬁrst set
of traces is from Hotmail, a large email service running on
tens of thousands of servers. We used I/O traces from 8 such
servers over a 48-hour period, starting at midnight (PDT) on
Monday August 4 2008. The second set of I/O traces is taken
from 6 RAID volumes at MSR Cambridge. The traced period
was 1 week starting from 5PM GMT on the 22nd February
2007. Thus, these activity traces represent a service used by
millions of users and a small service used by hundreds of users.
The traces are normalized to the peak load. Both sets of traces
show strong diurnal properties and have peak-to-mean ratios
(PMRs) of 1.64 and 4.64 for Hotmail and MSR respectively.
Loads were averaged over disjoint 10 minute intervals.
The Hotmail trace contains signiﬁcant nightly activity due
to maintenance processes (backup, index creation etc). The
data center, however, is provisioned for the peak foreground
activity. This creates a dilemma: should our experiments
prediction window, w
% cost reduction
(a) Hotmail
prediction window, w
% cost reduction
Impact of prediction window size on cost incurred by LCP(w).
include the maintenance activity or to remove it? Figure 3
illustrates the impact of this decision. If the spike is retained,
it makes up nearly 12% of the total load and forces the static
provisioning to use a much larger number of servers than if
it were removed, making savings from dynamic right-sizing
much more dramatic. To provide conservative estimates of the
savings from right-sizing, we chose to trim the size of the
spike to minimize the savings from right-sizing.
Prediction error: The LCP(w) algorithm depends on having
estimates for the arrival rate during the current timeslot as
well as for w timeslots into the future. Our analysis in Section
IV assumes that these estimates are perfect, but of course in
practice there are prediction errors. However, Figure 4 shows
that LCP(w) is fairly robust to prediction errors, and so this
assumption is not problematic. In particular, the cost reduction
on the Hotmail trace, relative to a static scheme with full,
perfect, knowledge of the workload is still signiﬁcant when
additive white Gaussian noise of increasing variance is added
to predictions used by LCP(w). The plot for the MSR trace
is qualitatively the same, however the cost savings is actually
signiﬁcantly larger. Given that prediction errors for real data
sets tend to be small , , based on these plots, to
simplify our experiments we allow LCP(w) perfect predictions.
B. When is right-sizing beneﬁcial?
Our experiments are organized in order to illustrate the
impact of a wide variety of parameters on the cost-savings
provided by dynamic right-sizing via LCP(w). The goal is
to better understand when dynamic right-sizing can provide
large enough cost-savings to warrant the extra implementation
complexity. Remember that throughout, we have attempted to
choose experimental settings so that the beneﬁt of dynamic
right-sizing is conservatively estimated.
Impact of prediction window size: The ﬁrst parameter we
study is the impact of the predictability of the workload. In
particular, depending on the workload, the prediction window
w for which accurate estimates can be made could be on the
order of tens of minutes or on the order of hours. Figure 5
illustrates the impact this has on the cost savings of LCP(w),
where the unit of w is one timeslot which is 10 minutes.
The ﬁrst observation from Figure 5 is that the savings
possible in the MSR trace are dramatically larger than in the
Hotmail trace. However, in both cases, a signiﬁcant fraction
of the optimal cost savings is achieved by LCP(0), which
uses only workload predictions about the current timeslot (10
minutes). The fact that this myopic algorithm provides significant gain over static provisioning is encouraging. Further, a
prediction window that is approximately the size of β = 6 (i.e.
one hour) gives nearly the optimal cost savings.
peak/mean ratio
% cost saving
(a) Total cost
peak/mean ratio
% energy cost saving
(b) Energy cost
Impact of the peak-to-mean ratio of the workload on the total cost
and energy cost incurred by LCP(w) in the Hotmail workload.
Impact of peak-to-mean ratio (PMR): Dynamic right-sizing
inherently exploits the gap between the peaks and valleys of
the workload, and intuitively provides larger savings as that
gap grows. Figure 6 illustrates that this intuition holds for
both cost savings and energy savings. The gain grows quickly
from zero at PMR=1, to 5–10% at PMR≈2 which is common
in large data centers, to very large values for the higher
PMRs common in small to medium sized data centers. This
shows that, even for small data centers where the overhead
of implementing right-sizing is amortized over fewer servers,
there is a signiﬁcant beneﬁt in doing so. To provide some
context for the monetary value of these savings, consider that
a typical 50,000 server data center has an electricity bill of
around $1 million/month .
The workload for the ﬁgure is generated from the Hotmail
workload by scaling λt as ˆλt = k(λt)α, varying α and
adjusting k to keep the mean constant. Note that though
Figure 6 includes only the results for Hotmail, the resulting
plot for the MSR trace is nearly identical. This highlights that
the difference in cost savings observed between the two traces
is primarily due to the fact that the PMR of the MSR trace is
so much larger than that of the Hotmail trace.
Impact of energy costs: Clearly the beneﬁt of dynamic
right-sizing is highly dependent on the cost of energy. As the
economy is forced to move towards more expensive renewable
energy sources, this cost will inevitably increase and Figure 7
shows how this increasing cost will affect the cost savings
possible from dynamic right-sizing. Note that the cost savings
from dynamic right-sizing grow quickly as energy costs rise.
However, even when energy costs are quite small relative to
delay costs, we see improvement in the case of the MSR
workload due to its large PMR.
Impact of switching costs: One of the main worries when
considering right-sizing is the switching cost of toggling
servers, β, which includes the delay costs, energy costs, costs
of wear-and-tear, and other risks involved. Thus, an important
question to address is: “How large must switching costs be
before the cost savings from right-sizing disappears?”
Figure 8 shows that signiﬁcant gains are possible provided
β is smaller than the duration of the valleys. Given that the
energy costs, delay costs, and wear-and-tear costs are likely
to be on the order of an hour, this implies that unless the
risks associated with toggling a server are perceived to be
extreme, the beneﬁts from dynamic right-sizing are dramatic
in the MSR trace (high PMR case). Though the gains are
smaller in the Hotmail case for large β, this is because the
spike of background work splits an 8 hour valley into two
short 4 hour valleys. If these tasks were shifted or balanced
across the valley, the Hotmail trace would show signiﬁcant
cost reduction for much larger β, similarly to the MSR trace.
energy cost / delay cost
% cost reduction
(a) Hotmail
energy cost / delay cost
% cost reduction
Impact of increasing energy costs.
Impact of valley ﬁlling: A common alternative to dynamic
right-sizing that is often suggested is to run very delayinsensitive maintenance/background processes during the periods of low load, a.k.a., ‘valley ﬁlling’. Some applications
have a huge amount of such background work, e.g., search
engines tuning their ranking algorithms. If there is enough
such background work, the idea is that the valleys can be
entirely ﬁlled and so the PMR≈1 and thus dynamic rightsizing is unnecessary. Thus, an important question is: “How
much background work is enough to eliminate the cost savings
from dynamic right-sizing?”
Figure 9 shows that, in fact, dynamic right-sizing provides
cost savings even when background work makes up a signiﬁcant fraction of the total load. For the Hotmail trace,
signiﬁcant savings are still possible when background load
makes upwards of 10% of the total load, while for the MSR
trace this threshold becomes nearly 60%. Note that Figure 9
results from considering ‘ideal’ valley ﬁlling, which results
in a perfectly ﬂat load during the valleys, but does not give
background processes lower queueing priority.
VI. RELATED WORK
This paper is not alone in approaching the task of developing
algorithms for dynamic right-sizing. Interest in right-sizing
has been growing since and appeared at the start
of the decade. Approaches range from very “analytic” work
focusing on developing algorithms with provable guarantees
to “systems” work focusing purely on implementation. Early
systems work such as achieved substantial savings despite
ignored switching costs in their design. Other designs have
focused on decentralized frameworks, e.g., and ,
as opposed to the centralized framework considered here. A
recent survey is .
Related analytic work focusing on dynamic right-sizing
includes , which reallocates resources between tasks within
a data center, and , which considers sleep of individual
components, among others. Typically, approaches have applied
optimization using queueing theoretic models, e.g., , or
control theoretic approaches, e.g., – . A recent survey
of analytic work focusing on energy efﬁciency in general is
 . Our work is differentiated from this literature by the
generality of the model considered, which subsumes most
common energy and delay cost models used by analytic
researchers, and the fact that we provide worst-case guarantees
for the cost of the algorithm, which is typically not possible for
queueing or control theoretic based algorithms. For example,
using ‘model predictive control’ has often been suggested
for dynamic right-sizing, but has an unbounded competitive
ratio for the model considered here.
The model and algorithm introduced in this paper most
closely ties to the online algorithms literature, speciﬁcally
% cost reduction
(a) Hotmail
% cost reduction
Impact of switching cost, against time on a logarithmic scale.
the classic rent-or-buy (or “ski rental”) problem . The
optimal deterministic strategy for deciding when to turn off
a single idle server (i.e., to stop ‘renting’ and ‘buy’) is the 2competitive . Additionally, there is a randomized algorithm
which is asymptotically e/(e −1)-competitive . Both of
these competitive ratios extend to the more general setting of
putting a server in one of several sleep modes, with different
power consumption and transition costs . An important
difference between these simple models and the current paper
is that the cost of the ‘buy’ and ‘rent’ actions may change
arbitrarily over time in the data center optimization problem.
Problems with this sort of dynamics typically have competitive
ratios greater than 2. For example, when rental prices vary in
time, the competitive ratio is unbounded in general . Further, for “metrical task systems” – , which generalize
rent-or-buy problems and the data center optimization problem,
there are many algorithms available, but they typically have
competitive ratios that are poly-logarithmic in the number
of servers. Perhaps the most closely related prior work from
this area is the page-placement problem (deciding on which
server to store a ﬁle), which has competitive ratio 3 . The
page replacement-problem is nearly a discrete version of the
data center optimization problem where the cost function is
restricted to f(x) = |x −1|. Finally, it is important to note
that LCP(w) is quite different than the classical algorithms
applied for rent-or-buy problems.
VII. SUMMARY AND CONCLUDING REMARKS
This paper has provided a new online algorithm, LCP(w),
for dynamic right-sizing in data centers. The algorithm is
motivated by the structure of the optimal ofﬂine solution and
guarantees cost no larger than 3 times the optimal cost, under
very general settings – arbitrary workloads, general delay cost
models, and general energy cost models. Further, in realistic
settings the cost of LCP(w) is nearly optimal. Additionally,
LCP(w) is simple to implement in practice and does not
require signiﬁcant computational overhead.
Additionally, the case studies used to evaluate LCP(w)
highlight that the cost and energy savings achievable via
dynamic right-sizing are signiﬁcant and, often, dramatic. The
case studies highlight that if a data center has PMR larger than
3, a cost of toggling a server of less than a few hours of server
costs, and less than 40% background load then the cost savings
from dynamic right-sizing can be conservatively estimated
at larger than 15%. Thus, even if a data center is currently
performing valley ﬁlling, it can still achieve signiﬁcant cost
savings via dynamic right-sizing.