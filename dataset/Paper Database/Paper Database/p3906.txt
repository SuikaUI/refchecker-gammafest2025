Received March 26, 2020, accepted April 10, 2020, date of publication April 22, 2020, date of current version May 7, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.2989443
Spatiotemporal Data Fusion in Graph
Convolutional Networks for
Traffic Prediction
BAOXIN ZHAO
1,2, (Student Member, IEEE), XITONG GAO2, (Member, IEEE),
JIANQI LIU
3, (Member, IEEE), JUANJUAN ZHAO
AND CHENGZHONG XU4, (Fellow, IEEE)
1Shenzhen College of Advanced Technology, University of Chinese Academy of Sciences, Shenzhen 518055, China
2Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen 518055, China
3School of Automation, Guangdong University of Technology, Guangzhou 510006, China
4State Key Laboratory of IoTSC, Faculty of Science and Technology, University of Macau, Macao, China
Corresponding author: Xitong Gao ( )
This work was supported in part by the National Key Research and Development Program of China under Grant 2019YFB2102100, in part
by the National Natural Science Foundation of China under Grant 61701122, Grant 61806192, and Grant 61802387, in part by the Science
and Technology Development Fund of Macao (FDCT) under Grant 0015/2019/AKP, in part by the Shenzhen Engineering Research Center
for Beidou Positioning Service Improvement Technology under Grant XMHT20190101035, in part by the Shenzhen Discipline
Construction Project for Urban Computing and Data Intelligence, in part by the Basic Research Program of Shenzhen under
Grant JCYJ20180302145731531 and Grant JCYJ20190812160003719, and in part by the Research Center for Ecology and Environment
of Central Asia, Chinese Academy of Sciences.
ABSTRACT A plethora of information is now readily available for trafﬁc prediction, making an effective
use of them enables better trafﬁc planning. With data coming from multiple sources, and their features
spanning spatial and temporal dimensions, there is an increasing demand to exploit them for accurate trafﬁc
prediction. Existing methods, however, do not provide a solution for this, as they tend to require expertise
feature engineering. In this paper, we propose a general architecture for SpatioTemporal Data Fusion (STDF)
with parameter efﬁciency. To make heterogeneous multi-source data fusion effectiveness, we separate all data
into trafﬁc directly related data and trafﬁc indirectly related data. With trafﬁc indirectly related data as the
input to Spatial Embedding by Temporal convolutiON (SETON) that simultaneously encodes each feature
in both space and time dimensions and trafﬁc directly related data as the input to the graph convolutional
network(GCN), we designed a ﬁne-grained feature transformer to match the ones generated by GCN. This
is then followed by a fusion module to combine all features to make ﬁnal prediction. Compared to using
GCNs training with only trafﬁc directly related data, experimental results show that our model can achieve
a 6.1% improvement in prediction accuracy measured by Root Mean Squared Error.
INDEX TERMS Data fusion, graph convolutional networks, multi-source data, trafﬁc prediction.
I. INTRODUCTION
The trafﬁc is playing a vital role of human life and signiﬁcantly inﬂuenced every aspect of life. With the rapid
increase of vehicles, the trafﬁc jam has attracted a national
concern for urban management. Smart city is considered as
a potential solution, which uses intelligent technologies to
predict the trafﬁc ﬂow, and smooth the peaks and valleys
by offering residents travel guidance . Trafﬁc prediction
is of great importance for smart cities and has attracted
The associate editor coordinating the review of this manuscript and
approving it for publication was Keli Xiao
attention from research to industry for many years. Accurate
real-time road trafﬁc prediction is critical for the realization
of intelligent cities , . Trafﬁc authorities require reliable
prediction to facilitate the related process of policy-making,
regulatory, and implementation. With the development of
sensors, the trafﬁc data is collected by sensors equipped
within vehicles or installed along the roads. Examples of
trafﬁc data include license number of vehicles, GPS data
of vehicles, video or image records of surveillance devices,
temperature, wind speed and level of sunlight data of weather
sensors . These multi-source data converge to the data
center by vehicle ad hoc networks (VANET), or the upcoming
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see 
VOLUME 8, 2020
B. Zhao et al.: STDF in GCNs for Traffic Prediction
5G cellular network . Many trafﬁc prediction algorithms
have proposed to guide convenient travel for citizens based
on these mass trafﬁc data, and there have been some works
showing the advantages of multi-source data fusion in the
spatio-temporal data prediction tasks .
Unlike traditional data fusion methods, multi-source trafﬁc
data includes not only trafﬁc directly related data, e.g., vehicle speed, vehicle density, trafﬁc ﬂow, but also indirectly
related data, e.g., weather, points of interests (PoIs), etc.. All
these data span both spatial and temporal dimensions ,
 . As shown in Figure 1, our goal is to predict trafﬁc
condition at each road segment. The residence areas in the
morning tend to have many people going out for fun or work,
while in the evening many people go home, or to a place of
entertainment. These information therefore must be incorporated in the model for accurate trafﬁc prediction. However,
merging all these data straightforwardly could not explore the
semantics changing of trafﬁc indirectly related data over time.
To tackle this, in this paper we propose a SpatioTemporal
Data Fusion (STDF) framework, which is a general architecture to improve trafﬁc prediction performance in metro-city
scales by using data fusion.
Trafﬁc prediction using data fusion needs to consider both
spatial and temporal features from multi-source data. It is
notable that the distribution of urban trafﬁc exhibit high
variability both in spatial and temporal domain. Trafﬁc prediction in urban cities is challenging because of their complex
environment. It is thus essential to ﬁnd an efﬁcient and effective way to make trafﬁc prediction more accurate by using
them jointly. There have been many works on data fusion.
According to the model parameters size, the work in trafﬁc
prediction by data fusion can be classiﬁed into two categories,
i.e., traditional machine learning method and deep neural networks. Many effective methods have been proposed, such as
XGBOOST , random forest , LightGBM , embedding learning . Although these methods can ﬁnd the
relationship between trafﬁc prediction and trafﬁc indirectly
related data, they require signiﬁcant human effort because
the features extracted from multi-source data play a vital
role in the prediction accuracy. Meanwhile, it is computation consuming if we apply these methods into large scale
data fusion for urban cities. To overcome it, an end-to-end
learning method is thus a desirable alternative at the cost
of computation power. For example, some works use deep
neural networks
 – to automate the processing of
multi-source data fusion and extraction of useful features.
They merge multi-source data straightforwardly into a vector
and treat trafﬁc directly related and indirectly related data
equally. As a result, they ignore the semantics changing of
trafﬁc indirectly related data. In this paper, we explore an
effective and efﬁcient way to fuse multi-domain data considering both the spatial and temporal properties based on
Multi-source data fusion with the consideration of its spatial and temporal properties is challenging for the following reasons. The ﬁrst challenge is the large scale feature
representation. It is infeasible to encode each node at different time into a uniﬁed vector in metro-city scales. For
example, the parameter size is over 10G for a Small city
containing 10,000 road segment and 100 external factors
for each node on average if each factor is represented by a
10-tuple vector at one time interval, which will easily result in
an over-parameterized model and over-ﬁtting when training.
Second, an automated but efﬁcient facility is urgently needed
to ﬁnd the spatio-temporal representation for all multi-source
data. Third, fusing trafﬁc indirectly related data into trafﬁc
prediction may cause negative effect on prediction accuracy.
Besides, there are practical concern when applied into the real
trafﬁc prediction in metro city scales.
To tackle the aforementioned challenges, we proposed
a general STDF framework. STDF adopts branchingtransfer-fuse strategy. STDF ﬁrst separates the prediction
model into two branches with each branch processing trafﬁc
directly related data and trafﬁc indirectly related data correspondingly. The trafﬁc directly realted data is processed
by GCN to get the spatio-temporal representation from the
middle layer of GCN. While the trafﬁc indirectly related
data is process by two parts successively. The ﬁrst part is
called static Spatial Embedding by Temporal convolutiON
(SETON). SETON ﬁrst encodes each feature in both space
and time dimensions simultaneously, followed by an convolutional operation with spatial embeddings as input and
temporal embeddings as convolutional kernel to get the
spatio-temporal representation. Meanwhile, all nodes share
the same spatial and temporal embeddings, which are traninable in the model as well as to avoid the overparameterized
problem. The second part is a feature transform module which
is to map the spatio-temporal representation generated by
SETON to the feature map space generated by GCN. At last,
the feature map generated by GCN and feature transform
module are fused together followed by several full connection output layers. In summary, this paper has the following
contributions.
• Generic Architectures for Deep Spatio-temporal Data
The STDF framework is a general neural network architectures, which can efﬁciently fuse
multi-source data both in spatial domain and temporal
domain in large scales.
• Deep Spatio-temporal Data Fusion Operator-
designed a new type of deep spatio-temporal data fusion
operator i.e.SETON. The operator has the ability to
capture both the spatial representation and temporal representation simultaneously.
• Computation Efﬁciency and Practical - Both the components in the STDF framework have the parameter sharing strategy to avoid model over-parameterized, which
is applicable in the complex urban computing with high
computation efﬁciency.
• Performance Improvement in Spatiotemporal Data Prediction - We apply our method into real trafﬁc speed
prediction and human ﬂow prediction in metro. Experimental results demonstrate that our spatiotemporal data
VOLUME 8, 2020
B. Zhao et al.: STDF in GCNs for Traffic Prediction
FIGURE 1. Semantics changing over time. Multi-source data fusion will benefit the traffic prediction accuracy.
At the same time, the representation of different factors is changing over time. Traffic prediction using data fusion
needs to consider both the spatial and temporal representation simultaneously.
fusion method performs signiﬁcantly better than the one
without data fusion or only spatial data fusion.
The rest of this paper is organized as follows. Section II gives
a brief literature review of related work from trafﬁc prediction
and data fusion perspective. Section III formulates the trafﬁc
prediction problem and an overview of the architecture of
solution. Section IV details the process of spatiotemporal representation with parameter efﬁciency. With the extracted features, a feature transformer module and data fusion method
are introduced at Section V. We conduct comprehensive
experiments in section VI and give a discussion of our model.
Section VII offers the conclusion of our work and outlines our
future work.
II. RELATED WORK
In this section, we review the recent studies that are relevant to
trafﬁc prediction and data fusion. We ﬁrst introduce the trafﬁc
prediction methods from mathematical model perspective.
Then data fusion methods are detailed both in feature level
and semantic level.
A. TRAFFIC PREDICTION
There are many achievements made in trafﬁc prediction, including trafﬁc ﬂow, vehicle speed, vehicle density, etc. Trafﬁc prediction can be models as a time series
data prediction. The statistical modes including history
average (HA), Autoregressive Integrated Moving Average
(ARIMA) , Seasonal Autoregressive Integrated Moving Average (SARIMA) and spatiotemporal correlations are widely used in real trafﬁc condition prediction
for its computation efﬁciency. However, all these methods
require the input data to meet a certain condition, which
consequently perform poorly in the complex urban trafﬁc
prediction.
To make trafﬁc prediction model have the ability to deal
with complex data, there are continuous applying trying
machine learning methods into the urban trafﬁc prediction,
such as XGBOOST , random forest , LightGBM ,
embedding learning . Although these methods have the
inherent advantage to deal with multi-source data, they need
a lot of domain knowledge and careful feature engineering,
which is not only computation consuming but also has some
scalability issues.
Because of the strong self-adapting and self-learning ability of artiﬁcial neural network, deep learning has been used in
different domains, such as computer vision , natural language processing and auto driving, and brings many signiﬁcant breakthroughs. At the same time, a great deal of studies
have been done on improving trafﬁc prediction performance
by using different types of neural network architectures, such
as multi-layers perception , long short-term memory 
and auto encoders . Although these works can effectively
extract the local patterns of data, they can only be applied
for the standard structure data and are lack of awareness
of the global prediction. With the ability of processing data
of graph structures, the graph convolutional networks are
widely used to deal with complex graph data in a global
perspective. Yu proposed a Spatio-Temporal Graph Convolutional Networks (STGCN) with the ability to capture comprehensive spatial and temporal dependencies for long-term
trafﬁc prediction . Guo applies attention strategy into
GCN to predict trafﬁc ﬂow with considering the dynamic
spatial-temporal correlations of trafﬁc data . Li proposed
a diffusion convolutional recurrent neural network (DCRNN)
to model the trafﬁc ﬂow as a diffusion process . Different from our work, these models did not deal with the
multi-source data problem.
B. DATA FUSION
Data fusion in trafﬁc scenario often implies the combination of trafﬁc related data sets that present an enormous diversity on the basis of location, weather, points of
interests, trafﬁc ﬂow, density and speed. These data sets
are differently represented in different perspective, but they
represent the same real world object and complement each
other. A straightforward method , in the feature level
is that all the object-related features are extracted equally and
all features are concatenated sequentially into a equal-sized
VOLUME 8, 2020
B. Zhao et al.: STDF in GCNs for Traffic Prediction
or unequal-sized vector to be injected into the kernel task.
The low-level representation might exist redundancies and
the sampled data may be not independent, it is easy to lead
to model instability.
Feature engineering is an especially good idea that makes
machine learning algorithms work. Lakhinaet analyzed the
distributions of packet features in ﬂow traces in details, which
showed signiﬁcant advantages for anomalies detection .
Samant and Adeli extracted trafﬁc incident related features
by using wavelet transform and linear discriminant analysis . The two-stage feature extraction algorithm made
the trafﬁc incidents detection model more robust. Although a
good feature engineering can get better performance, it needs
a deep understanding of domain knowledge. Besides, it is
time consuming and computation consuming for large scale
data fusion. An end-to-end learning technology with better
ﬂexibility provides a consistent alternative for the ability of
auto feature extraction.
Deep neural networks (DNN) is an excellent solution for
end-to-end learning when geta uniﬁed feature representation from disparate data sets. An end-to-end structure of
ST-ResNet was proposed to predict citywide crowd
ﬂows, where the input with unique properties of spatiotemporal data is feed into ST-ResNet simultaneously. Bojarski
trained a convolutional neural network (CNN) to map raw
pixels from three cameras directly to steering commands .
The system automatically learns internal representations of
the necessary processing steps such as detecting useful road
features. With the ability to self-learn feature representation,
these end-to-end based data fusion methods need lots of computation cost. At the same time, the feature representations
are extracted in a grid scale, but not in the road segments level.
Different from them, we are more interested in the graph
structure data.
Feature based data fusion approaches take all the feature
equally and ignore the semantic meaning of each feature.
On the contrary, semantics based data fusion methods try to
understand the meaning of each feature and ﬁnd the relationships between features by mining the insight of each
data. For example, many works tried to ﬁnd the relationship
between emotion and audio signals in the emotion recognition – . The fusion results combining the acoustic
and facial emotion recognition were achieved in the semantic
level. DeepFM is an end-to-end deep learning framework
for click-through rate prediction, where data representation is
realized by feature embedding. DeepFM fuses the feature by a
factorization-machine with a deep neural network. However,
all these feature representation are static and only related to
its input data correspondingly. In this paper, we will tackle
the spatiotemporal data fusion problem in trafﬁc prediction
scenarios because the spatial features in semantics level are
dynamically changing with time.
III. PRELIMINARIES
Deﬁnition 1: (Spatial Network): The trafﬁc network G is
a weighted directed graph G = (V, E, A), where set |V| = N
is a set of nodes that can represent road segments or metro
stations, N is the number of nodes, and E denotes the set
of edges, A ∈RN×N is the weighted adjacent matrix of
network G.
Deﬁnition 2: (Multi-Source Data): The multi-source data
includes two types of data, trafﬁc directly related data and
trafﬁc indirectly related data. The trafﬁc directly related data
means the graph signal matrix Xt
G ∈RN×C, where C is the
number of trafﬁc condition of interests (e.g., trafﬁc speed,
trafﬁc ﬂow, trafﬁc density, etc.). The trafﬁc indirectly related
data represents external factors that can inﬂuence trafﬁc condition indirectly, which is denoted by FG ∈RN×M, where M
is the number of ﬁelds including categorical ﬁelds (e.g., residential area, hi-tech zones, entertainment place, rain, etc.)
and continuous ﬁelds (e.g., PoI density, PoI number).
A. PROBLEM STUDIED
The problem of trafﬁc prediction by data fusion can be
described as: given the observations at N nodes of historical
P time steps X = (Xt−P+1
, · · · , Xt
G) ∈RP×N×C
and the external factors FG collected from other domain,
we aim to learn a mapping function f which can map the
input data into the future observation of trafﬁc condition
, · · · , Xt+Q
), i.e., Y = f (X, FG), where Q
denotes the length of the target of trafﬁc condition to predict.
Figure 2 illustrates the architecture of STDF framework to
solve the problem. As the studies about GCN have gotten
state-of-the-art performance in spatio-temporal data prediction and there have been many completed GCN architectures
widely used in time series data prediction, we select one type
of GCN to demonstrate the framework of STDF.
FIGURE 2. STDF architecture. The SETON operator aims to getting the
low-level spatio-temporal features from the input including spatial
features and temporal factors. The feature transformer component is to
map the low-level features to a high level feature that has the same size
with the high-level features generated by GCN. The ST-Conv Block is the
basic block for GCN.
B. GRAPH CONVOLUTIONAL NETWORK
Graph convolutional network (GCN) is a neural network
that operates on graphs, which is able to extract local features with different reception ﬁelds from translation variant
VOLUME 8, 2020
B. Zhao et al.: STDF in GCNs for Traffic Prediction
non-Euclidean structure . As depicted in , GCN is
designed to solve the time-series prediction problem, i.e., predicting the future trafﬁc measurements under given input with
a ﬁxed temporal length, which is written as
bY = GCN(Xt−P+1
, · · · , Xt
The feature map FMg generated by the second ST-Conv
Block in GCN as demonstrated in Figure 2 is denoted by
FMg = fg(Xt−P+1
, · · · , St
However, there are many external factors that have inﬂuence on trafﬁc pattern. For each node v, the external factors
are written as a vector Fv. Spatio-temporal data fusion is not
a simple data integration process. STDF is designed to ﬁnd
an efﬁcient and effective data fusion strategy that is one kind
of practical methods for large scale trafﬁc data prediction
in real world. STDF consists of three parts: SETON and
Feature Matching. The SETON is to ﬁnd a computation
efﬁcient spatio-temporal representation for external trafﬁc
related variables. Feature transformer maps spatio-temporal
representation to a feature space that has the same feature
shape with the feature map FMg for each node. Then a fusion
module is followed to combine the two features into one
tensor. We introduce the three parts in details as follows.
The STEON consists of three components: spatial feature
embedding layer, temporal feature embedding layer and
embedding vector fusion layer. The spatial feature embedding
layer maps the external factors to a ﬁxed sized embedding
vector. The vector length k is determined in advance. Similarly, the temporal feature embedding layer maps the time
interval to a 3-D tensor, with the length of the ﬁrst and second
dimension equal to k and the length of the third dimension
equal to the number of time slots, and embedding vector
fusion layer is to get the spatio-temporal embedding vectors
using the output of the aforementioned two components as
input, which is the spatio-temporal representation of traf-
ﬁc indirect related data in low level. At the same time, all
vectors in SETON can be self-learned without any feature
engineering.
A. SPATIAL FEATURE EMBEDDING
Because the trafﬁc network is complex and the environment
around each node is different from each other, the size of
external data related to trafﬁc prediction is too large if we
give each factor a spatiotemporal representation in neural networks, which may cause over-parameterized and overﬁtting
when training. To overcome the over-parameterized problem,
we proposed a data sharing strategy for all nodes.
We ﬁrst classify the indirect trafﬁc data into an m-ﬁelds
data according to the way how the PoI will inﬂuence
people travel pattern. They may include categorical ﬁelds
(e.g., residential area, hi-tech zones, entertainment place) and
continuous ﬁelds (e.g., PoI density, PoI number). Different
categorical ﬁelds may contains different size of data denoted
by an one hot encoding. The continuous ﬁelds are represented
FIGURE 3. SETON architecture. The STEON consists of spatial feature
embedding layer, temporal feature embedding layer and spatiotemporal
feature product layer. SETON is designed to get the feature representation
of indirect traffic data both in spatial and temporal dimension
simultaneously with parameter efficiency.
by the value itself. The instance for node v is written as
Fv = {fﬁeld1, fﬁeld2, · · · , fﬁeldm}, where fﬁeldj stands for the
j-th ﬁeld of Fv. Then the instance for all node V is F =
{F1, F2, · · · , Fn}. The task for spatial feature embedding is to
ﬁnd a parameter efﬁcient method to allocate each value in F
to a equal sized embedding vector. The length of embedding
vector is a predeﬁned as k.
FIGURE 4. Spatial feature embedding. All nodes share a same latent
feature vectors W . The tensor W serves as network weights which are
trainable and acts as a role in mapping the input data to fixed sized
embedding vectors, which makes our model salable when appled into
large urban computing.
Figure 4 highlights the detail of spatial feature embedding
from the input layer F to the embedding layer for all nodes,
VOLUME 8, 2020
B. Zhao et al.: STDF in GCNs for Traffic Prediction
where the length of embedding vector is set to 5. The left
part stands for the embedding process for node 1 and the
right part stands for the same process for node n. All nodes
share a same latent feature vectors W. By the way, there is
no need of pre-training for the latent feature vectors W. The
tensor W serves as network weights, which can be learned
by the network itself. Besides, the tensor W acts as a role
in mapping the input data to ﬁxed sized embedding vectors,
which denoted as:
ai = [ei,1, ei,2, · · · , ei,m],
where ei,j stands for the embedding vector of j-th ﬁeld for
node i and m is the number of ﬁelds. More speciﬁcally,
the embedding output for each node is a k × m tensor. The
parameter that needs to be learned is of a size of M × k,
where M is equal to Pm
j=1 |fﬁeldj|. The parameter size has no
relationship with the node number, which is the foundation
for large scale data fusion in urban cities.
B. TEMPORAL FEATURE EMBEDDING
In the application of trafﬁc prediction, time factor plays an
important role in understanding people travel patterns .
For example, people would like to go out in the morning
and get back home in the evening. So the embedding vector
for residential area is different at different time. Meanwhile,
the spatial semantics changing is also needed for other kinds
of categories. Because the characteristics of trafﬁc data has
a property of cyclical, we divide the time in one day into
T time intervals. As we all know, urban trafﬁc has different
patterns and people travel patterns also differs from each
other at different time. So each time interval has a distinct
transmission matrix in our model, which is used to transfer
the spatial embedding vector to a corresponding vector.
We use a tensor W to represent the temporal embeddings
for all time intervals. At the same time, W serves as network
weights which can be learned by the network itself. To make
the temporal embeddings matching with the spatial embeddings, the tensor W is of a 3-D shape T × k × k.
Taking k = 5 as an example, we highlight the temporal feature embedding process from the input layer to the
embedding layer as shown in Figure 5. For the time factor t,
we encode it to a one hot vector after discretization, where
the vector length is equal to T. Similarly, the latent feature
vectors W for temporal embedding process serves as network
weights which can be learned by the network itself. After the
embedding process, we get the temporal embedding matrix
αt corresponding to the time interval t.
αt = f (W, t) = W[t, :, :],
where f is a look up function to get its corresponding vector.
And the output matrix αt has a shape of k × k, which stands
for how the spatial meaning of each categories changes over
its corresponding time t. The size of parameters W has
relationship only with time intervals and embedding size but
not determined by node number n, which beneﬁts large scale
data fusion in urban cities. Therefore, the spatial embeddings
FIGURE 5. Temporal feature embedding. The temporal embeddings
serves as network weights with a size of T × k × k. Each time interval t
has its own temporal embedding.
and temporal embeddings make our model scalable without
the inﬂuence from graph size.
C. SPATIO-TEMPORAL FEATURE REPRESENTATION
IN LOW LEVEL
To get both the spatial and temporal feature representation,
we apply temporal embedding matrix αt to every ﬁeld of spatial embedding vector for all nodes. For a node i at time t, its
spatiotemporal feature embedding vectors is calculated by:
i = [αt ∗ei,1, αt ∗ei,2, · · · , αt ∗ei,m]
i,2, · · · , et
where ∗means the convolutional operator.
In summary, the number of parameters learned by the
network itself is only M × k + T × k × k. And the output
spatiotemporal feature embedding vectors A0
t after SETON
operation is of a shape of n×k ×m. As similar to the concept
in convolutional neural network for computer vision task, this
feature representation is in low level.
V. FEATURE TRANSFORMER AND DATA FUSION
This section introduces a feature transformer method that is
to get the representation in high level and match the feature
map FMg calculated by GCN.
A. EXTRACT SPATIOTEMPORAL REPRESENTATION
IN HIGH LEVEL
As illustrated in Figure 2, the feature transformer component
is a bridge between SETON and the feature map FMg, which
achieves shape alignment between the two layers. The feature
transformer part stacks q convolutional layers. Each convolutional layer contains a 1-D convolutional kernel which
enables all nodes in graph G share the same convolutional
VOLUME 8, 2020
B. Zhao et al.: STDF in GCNs for Traffic Prediction
kernel, rectiﬁed linear units and batch normalization except
the last layer containing only convolutional operation.
t = bn(relu(conv(Al−1
where kl is a 1-D vector that can be learned by network itself,
l ∈{1, 2, · · · , q} stands for the layer number. All nodes share
the same convolutional kernel kl at layer l, which not only
makes parameters efﬁcient but also avoid overﬁtting when
training. What’s more, the padding operation, incidentally,
depends on whether up-sampling is necessary. For example,
the feature map FMg ∈Rn×kg×cg with cg channels generated
by GCN is regarded as a representation for the objective
trafﬁc data in high level. If k < kg, up-sampling is necessary and experimental results tell us will cause performance
degradation sharply. So it is better to keep the value of kg
is less than k. After the node-wised convolutional operation,
the output feature map Aq
t is denoted by FMst, which has the
same size with FMg.
B. FEATURE MAP FUSION
There are many feature map fusion methods widely used in
neural networks. But in the large urban cities computing,
we prefer to directly merge the feature map FMst generated
by STDF with that of GCN as shown in Figure 2, which is
denoted by FM followed by rectiﬁed linear units and batch
normalization and written as:
FM = FMg + FMst.
This type of feature map fusion method has two beneﬁts used
in large scale data fusion. The ﬁrst is to reduce the computation overload when add more data into trafﬁc prediction.
Besides it would not bring more parameters into our model,
thus it can avoid overﬁtting problem.
To get the predicted value, several full connected layers are
stacked to map the feature map to the object value.
C. LOSS FUNCTION
In the training process, the goal is to minimize the gap
between the real trafﬁc conditionY and the predicted valuebY.
Different from other tasks, trafﬁc prediction has data incomplete and data bias problem. In statistics, the Huber loss is a
loss function used in robust regression, that is less sensitive to
outliers in data than the squared error loss. To minimize the
inﬂuence of trafﬁc outliers, we select Huber loss as the loss
for |Y −bY| ≤δ
otherwise.
where δ is a threshold parameter which controls the range of
squared error loss.
VI. EXPERIMENTS
In this section, we present the experiment and comparison
results. We ﬁrst present the experiment settings with baseline algorithms and datasets introduced, then demonstrate the
overall performance of STDF with its components analysis.
Finally we detail the training process, testing performance
and hyperparameters selection.
FIGURE 6. Physical map in Shenzhen: (a) metro station; (b) road network.
A. EXPERIMENT SETUPS
1) DATESETS
Metro: The dataset used in this study is the smart card
transaction records and train operation logs in Shenzhen,
China. The metro system has 5 metro lines by 2015 as
shown in Figure 6(a). The whole data collected from
around 4 million smart cards have more than 300 million
smart card transaction records, covering 184 consecutive
days from January 1, 2015 to July 30, 2015. We use
144 days of data to train the network and 20 days for
cross validation and 20 days for testing. The standard
time interval is set to 30-minutes. The prediction task for
Metro is to forecast the passenger number at each metro
• TaxiSZ: We collect the data from City Trafﬁc Bureau
of Shenzhen (China) for as long as one year from
January 1, 2015 to December 31, 2015. There are about
15,000 taxis equipped with high-resolution GPS devices
reporting 32,205,000 records per day on average. There
are 341 days of valid data, where 281 days of data is used
for training, 30 days for cross validation and 30 days for
testing. The standard time interval is set to 15 minutes.
We use this data to predict the trafﬁc speed at every road
segment as shown in Figure 6(b).
VOLUME 8, 2020
B. Zhao et al.: STDF in GCNs for Traffic Prediction
TABLE 1. Statistics on datasets.
Trafﬁc indirectly related data: We collect the trafﬁc
indirectly related data at Shenzhen. It includes weather
conditions and PoIs. The weather conditions consist
of 16 types, such as sunny, rainy, etc. The PoIs has
659,494 records. Each record includes name, longitude, latitude, primary category, secondary category and
address. The primary category has 20 types, such as
incorporated business, real estate, ﬁnancial area, education zone, etc. Each primary category includes different
number of secondary category. For example, there are
three secondary categories for real estate and twelve secondary categories for education zone. There are 135 secondary categories all together.
2) BASELINES
For evaluation, we use the Root Mean Squared Error (RMSE)
and Mean Absolute Errors (MAE). We compare our model
with the following baselines:
• HA: We predict trafﬁc condition by the average value of
history value in the corresponding periods, e.g., 6:00am-
6:15am on Monday, its corresponding time spans are all
historical time intervals from 6:00am to 6:15am on all
historical Monday.
• ARIMA: Auto-Regressive Integrated Average is ﬁtted to
time series data either to better understand the data or to
predict future points in the series 
• SARIMA: The SARIMA is an extension of ARIMA that
explicitly supports univariate time series data with a
seasonal component .
• GCN: We use STGCN as an example. The channels
of three layers in STGCN are 64, 32, 128 respectively.
To evaluate each component of our model, we also compare it the difference of fusion layers.
• GCN-SDF-logits: GCN-SDF-logits only considers data
fusion in spatial domain and the fusion layer is located
at the logits layer.
GCN-SDF-FM:
GCN-SDF-FM only considers data
fusion in spatial domain and the fusion operation is
located at the middle layer as depicted in Section III-B.
GCN-STDF-logits: GCN-STDF-logits considers data
fusion both in spatial domain and temporal domain. But
the fusion layer is located at the logits layer.
GCN-STDF-FM:
GCN-STDF-FM considers data
fusion both in spatial domain and temporal domain.
The fusion layer is located at the middle layer as depicted
in Section III-B.
All above methods are evaluated and compared using
datasets: Metro and TaxiSZ. All GCN-based networks are
trained using ﬁne-tuned hyper-parameters. We use ﬁve-fold
cross validation for calculating its average performance. All
networks have been trained using 50 epochs under the same
settings with TensorFlow implementations. We use Adam
optimizer to train all networks. For each node, the traf-
ﬁc indirectly related data contains all the features within
one-kilometer radius.
TABLE 2. Overall performance.
B. OVERALL COMPARISONS
Table 2 demonstrates the results of STDF and the baselines on the datasets Metro and TaxiSZ. ARIMA gets
the worst results because of its low capacity in handling
spatio-temporal data prediction. GCN get a better performance than ARIMA. However, GCN-SDF-logits gets a worse
results compared with GCN only. Although data fusion is
believed to be more effective than the one without data fusion,
we can see that data fusion by putting more data into one
model may bring negative effects on the model performance.
GCN-SDF-FM and GCN-SDF-logits, which only consider
the spatial property but ignore the temporal dependency,
have much higher RMSE. We call this phenomenon as negative fusion. GCN-SDF-FM and GCN-STDF-FM get a better
performance than GCN-SDF-logits and GCN-STDF-logits,
which suggests it is better to locate the fusion layer at the
middle layer but not at the logits layer. Our proposed model
GCN-STDF-FM consistently achieves the best performance
on the datasets Metro and TaxiSZ, which shows the effectiveness of using spatial property and temporal property simultaneously. The intuition is that STDF gives the model the ability
to capture the dynamic trafﬁc demands and relationships
between the node and its surroundings.
C. TRAINING EFFICIENCY AND GENERALIZATION
In order to further investigate the overload caused by adding
more data when predicting, we calculate the parameters size
and training time consumption (second per epoch) as shown
in Table 3. For TaxiSZ dataset, the GCN only model has
1,090,824 parameters and consumes 21.950s seconds per
epoch on the training process. Meanwhile, our model only
consume 64,640 more parameters, i.e., it cause only 5.59%
VOLUME 8, 2020
B. Zhao et al.: STDF in GCNs for Traffic Prediction
TABLE 3. Training efficiency.
of parameters increasing. And the training time of our model
only cause 0.909 seconds longer than GCN per epoch, which
is practical for the real trafﬁc prediction. Similar observations
have been also obtained for Metro dataset. GCN has been
improved with 6.1% lower testing error by using the method
D. CASE STUDIES
To understand the performance of STDF, we conduct the
following case studies.
FIGURE 7. Training process.
1) FITTING CAPACITY
Figure 7 demonstrates the comparison of training process of
GCN, GCN-STDF-FM, GCN-STDF-logits, GCN-SDF-FM
and GCN-SDF-logits. We randomly select one of ﬁve-fold
cross validation to show the training process. Each network
is trained for 50 epoches. The X axis stands for the epoch
number. and the Y axis is the loss value. Taking the metro
data as an example, we can see that GCN-STDF-FM achieves
the lowest training loss and GCN-SDF-logits with the highest
training loss. Similar phenomenon can be seen at the testing performance demonstrated at Figure 8 corresponding to
Figure 7. It can be clearly observed that STDF provides GCN
both (1) enhanced capacity to ﬁt training data as well as
(2) the generalizability to adapt testing samples.
2) LEARNING RATE
Conﬁguring the learning rate is challenging and timeconsuming. We use ﬁve-fold cross validation for searching the best conﬁgurations of the learning rate for each
experiment by grid search. We set the learning rate to be
0.00001, 0.0001, 0.001, 0.01, 0.1. As observed from Figure 9,
the test RMSE reaches to the best performance 68.49 when
the learning rate is set to 0.001. The learning rate is ﬁxed to
0.001 in all experiments for STDF.
FIGURE 8. Testing performance.
FIGURE 9. Learning rate curve.
VII. CONCLUSION
In this paper, we propose a novel framework STDF for traf-
ﬁc prediction to handle multi-source data fusion. A splittransform-merge strategy is used in STDF. We ﬁrst separate
multi-source data into directly related data and indirectly
related data, which are input to GCN and SETON, correspondingly. The feature transformer module is designed to
extract spatiotemporal representation for trafﬁc indirectly
related data. We get the spatiotemporal representation for
trafﬁc directly related data from the middle layer of GCN.
This is then followed by a fusion module to combine all
features to make ﬁnal prediction. By using a data sharing
strategy, our model is scalable and the overload caused by
fusing trafﬁc indirectly related data is acceptable in the real
trafﬁc prediction. Experimental results show that our model
achieves the best performance compared with other stateof-the-art methods on two real world datasets. In summary,
STDF can successfully capture the spatial features changing
over time from multi-domain data, which not only can be
used into trafﬁc prediction, but also can be applied into other
spatiotemporal data prediction. In the future, we will predict
the trafﬁc congestion diffusion via representation learning,
where the representation vectors are extracted from the fusion
layer of STDF. A trafﬁc congestion control policy will be
made according to the trafﬁc congestion diffusion model.