HAL Id: hal-01569447
 
Submitted on 26 Jul 2017
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of scientific research documents, whether they are published or not.
The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Robust non-rigid registration through agent-based
action learning
Julian Krebs, Tommaso Mansi, Hervé Delingette, Li Zhang, Florin C Ghesu,
Shun Miao, Andreas Maier, Nicholas Ayache, Rui Liao, Ali Kamen
To cite this version:
Julian Krebs, Tommaso Mansi, Hervé Delingette, Li Zhang, Florin C Ghesu, et al.. Robust non-rigid
registration through agent-based action learning. Medical Image Computing and Computer Assisted
Interventions (MICCAI), Sep 2017, Quebec, Canada. pp.344-352, ￿10.1007/978-3-319-66182-7_40￿.
￿hal-01569447￿
Robust non-rigid registration through
agent-based action learning
Julian Krebs123, Tommaso Mansi1, Herv´e Delingette2, Li Zhang1, Florin C.
Ghesu1,3, Shun Miao1, Andreas Maier3, Nicholas Ayache2, Rui Liao1, and
Ali Kamen1
1 Siemens Healthineers, Medical Imaging Technologies, Princeton, New Jersey, USA
2 Universit´e Cˆote d’Azur, Inria, Asclepios Team, Sophia Antipolis, France
 
3 Friedrich-Alexander-Universit¨at, Pattern Recognition Lab, Erlangen, Germany
Abstract. Robust image registration in medical imaging is essential
for comparison or fusion of images, acquired from various perspectives,
modalities or at diﬀerent times. Typically, an objective function needs
to be minimized assuming speciﬁc a priori deformation models and predeﬁned or learned similarity measures. However, these approaches have
diﬃculties to cope with large deformations or a large variability in appearance. Using modern deep learning (DL) methods with automated
feature design, these limitations could be resolved by learning the intrinsic mapping solely from experience. We investigate in this paper how DL
could help organ-speciﬁc (ROI-speciﬁc) deformable registration, to solve
motion compensation or atlas-based segmentation problems for instance
in prostate diagnosis. An artiﬁcial agent is trained to solve the task of
non-rigid registration by exploring the parametric space of a statistical
deformation model built from training data. Since it is diﬃcult to extract trustworthy ground-truth deformation ﬁelds, we present a training
scheme with a large number of synthetically deformed image pairs requiring only a small number of real inter-subject pairs. Our approach was
tested on inter-subject registration of prostate MR data and reached
a median DICE score of .88 in 2-D and .76 in 3-D, therefore showing
improved results compared to state-of-the-art registration algorithms.
Introduction
Registration of images with focus on the ROI is essential in fusion and atlasbased segmentation (e.g. ). Traditional algorithms try to compute the dense
mapping between two images by minimizing an objective function with regard
to some similarity criterion. However, besides challenges of solving the ill-posed
and non-convex problem many approaches have diﬃculties in handling large
deformations or large variability in appearance. Recently, promising results using
deep representation learning have been presented for learning similarity metrics
 , predicting the optical ﬂow or the large deformation diﬀeomorphic metric
mapping-momentum . These approaches either only partially remove the
above-mentioned limitations as they stick to an energy minimization framework
(cf. ) or rely on a large number of training samples derived from existing
registration results (cf. ).
Inspired by the recent works in reinforcement learning , we propose a
reformulation of the non-rigid registration problem following a similar methodology as in 3-D rigid registration of : in order to optimize the parameters of a
deformation model we apply an artiﬁcial agent – solely learned from experience
– that does not require explicitly designed similarity measures, regularization
and optimization strategy. Trained in a supervised way the agent explores the
space of deformations by choosing from a set of actions that update the parameters. By iteratively selecting actions, the agent moves on a trajectory towards
the ﬁnal deformation parameters. To decide which action to take we present
a deep dual-stream neural network for implicit image correspondence learning.
This work generalizes to non-rigid registration problems by using a larger
number of actions with a low-dimensional parametric deformation model. Since
ground-truth (GT) deformation ﬁelds are typically not available for deformable
registration and training based on landmark-aligned images as in rigid registration (cf. ) is not applicable, we propose a novel GT generator combining
synthetically deformed and real image pairs. The GT deformation parameters of
the real training pairs were extracted by constraining existing registration algorithms with known correspondences in the ROI in order to get the best possible
organ-focused results. Thus, the main contributions of this work are: (1) The
creation and use of a low-dimensional parametric statistical deformation model
for organ-focused deep learning-based non-rigid registration. (2) A ground truth
generator which allows generating millions of synthetically deformed training
samples requiring only a few (<1000) real deformation estimations. (3) A novel
way of fuzzy action control.
Training Artiﬁcial Agents
Image registration consists in ﬁnding a spatial transformation Tθ, parameterized
by θ ∈Rd which best warps the moving image M as to match the ﬁxed image
F. Traditionally, this is done by minimizing an objective function of the form:
arg minθ F(θ, M, F) = D (F, M ◦Tθ) + R(Tθ) with the image similarity metric
D and a regularizer R. In many cases, an iterative scheme is applied where
at each iteration t the current parameter value θt is updated through gradient
descent: θt+1 = θt + λ∇F(θt, Mt, F) where Mt is the deformed moving image
at time step t: M ◦Tθt.
Inspired by , we propose an alternative approach to optimize θ based on
an artiﬁcial agent which decides to perform a simple action at at each iteration
t consisting in applying a ﬁxed increment δθat: θt+1 = θt + δθat. If θ is a ddimensional vector of parameters, we deﬁne 2d possible actions a ∈A such that
δθ2i[j] = ϵiδj
i and δθ2i+1[j] = −ϵiδj
i with i ∈{0..d −1}. In other words the
application of an action at increases or decreases a speciﬁc parameter within θt
by a ﬁxed amount where δj
i is an additional scaling factor per dimension that
is set to 1 in our experiments but could be used e.g. to allow larger magnitudes
ﬁrst and smaller in later iterations for ﬁne-tuning the registration.
The diﬃculty in this approach lies into selecting the action at as function of the current state st consisting of the ﬁxed and current moving image:
st = (F, Mt). To this end, the framework models a Markov decision process
(MDP), where the agent interacts with an environment getting feedbacks for
each action. In reinforcement learning (RL) the best action is selected based
on the maximization of the quality function at = arg maxa∈A Q⋆(st, a). In the
most general setting, this optimal action-value function is computed based on
the reward function deﬁned between two states R(s1, a, s2) which serves as the
feed-back signal for the agent to quantify the improvement or worsening when
applying a certain action. Thus, Q⋆(st, a) may take into account the immediate
but also future rewards starting from state st, as to evaluate the performance of
an action a.
Recently, in RL powerful deep neural networks have been presented that
approximate the optimal Q⋆ . Ghesu et al. used deep reinforcement learning
(DRL) for landmark detection in 2-D medical images. In the rigid registration
approach by Liao et al. the agent’s actions are deﬁned as translation and
rotation movements of the moving image in order to match the ﬁxed image.
In this work, the quality function ya(st) ≈Q⋆(st, a) is learned in a supervised manner through a deep regression network. More precisely, we adopt a
single-stage MDP for which Q⋆(st, a) = R(st, a, st+1), implying that only the
immediate reward, i.e. the next best action, is accounted for. During training, a
batch of random states, pairs of F and M, is considered with known transformation TθGT (with F ≈M ◦TθGT ). The target quality is deﬁned such that actions
that bring the parameters closer to its ground truth value are rewarded:
Q⋆(st, a) = R(st, a, st+1) = ∥θGT −θst∥2 −∥θGT −θa
The training loss function consists of the sum of L2-norms between the explicitly computed Q-values (Eq. 1) for all actions a ∈A and the network’s quality
predictions ya(st) per action. Having a training batch B with random states sb
the loss is deﬁned as: L = P
a∈A ∥ya(sb) −Q⋆(sb, a)∥2 .
In testing, the agent iteratively selects the best action, updates the parameter
θt and warps the moving image Mt as to converge to a ﬁnal parameter set
representing the best mapping from moving to ﬁxed image (see Fig. 1b).
Statistical Deformation Model
One challenge of the proposed framework is to ﬁnd a low dimensional representation of non-rigid transformations to minimize the number of possible actions
(equal to 2d), while keeping enough degrees of freedom to correctly match images. In this work, we base our registration method on statistical deformation
models (SDM) deﬁned from Free Form Deformations (FFD). Other parametrizations could work as well. Typically, the dense displacement ﬁeld is deﬁned as the
Intra-Subj.
Inter-Subj.
Neural Network
Convolutional + Pooling
Fully-Connected
deformation
Fig. 1: (a) Training Data Generation: Synthetic deformations (blue arrows) and intersubject GT deformations (black) are used for intra- (green) and inter-subject (red) image pairs for training. (b) Dual-stream network used for Q-value prediction ya including
complete single-stage Markov Decision Process for testing (blue background).
summation of tensor products of cubic B-splines on a rectangular grid. Rueckert
et al. proposed to further reduce the dimensionality by constructing an SDM
through a principal component analysis (PCA) on the B-spline displacements.
We propose to use the modes of the PCA as the parameter vector θ describing the transformation Tθ that the agent aims to optimize. The agent’s basic
increment per action ϵi is normalized according to the mean value of each mode
estimated in training. To have a stochastic exploration of the parameter space,
predicted actions at are selected given ﬁxed probabilities (see ).
Fuzzy Action Control. Since parameters θ are the amplitudes of principal
components, the deviation of θ2m and θ2m+1 from the mean µm should stay
within k-times the standard deviation σm in testing. In order to keep θ inside this
reasonable parametric space of the SDM, we propose fuzzy action controlling.
Thus, actions that push parameter values of θ outside that space, are stochastically penalized – after being predicted by the network. Inspired by rejection
sampling, if an action a moves parameter θm to a value fm, then this move
is accepted if a random number generated between is less than the ratio
N(fm; µm, σm)/N(h; µm, σm) where hm = µm + kσm, and N is the Gaussian
distribution function. Therefore, if |fm −µm| ≤kσm, the ratio is greater than
1 and the action is accepted. If |fm −µm| > kσm then the action is randomly
accepted, but with a decreased likelihood as fm moves far away from µm. This
stochastic thresholding is performed for all actions at each iteration and rejection is translated into adding a large negative value to the quality function ya.
The factor k controls the tightness of the parametric space and is empirically
chosen as 1.5. By introducing fuzzy action control, the MDP gets more robust
since the agent’s access to the less known subspace of the SDM is restricted.
Training Data Generation
Since it is diﬃcult to get trustworthy ground-truth (GT) deformation parameters θGT for training, we propose to generate two diﬀerent kinds of training
pairs: Inter- and intra-subject pairs where in both moving and ﬁxed images are
synthetically deformed. The latter pairs serve as a data augmentation method
to improve the generalization of the neural network.
In order to produce the ground truth deformations of the available training
images, one possibility would be to apply existing registration algorithms with
optimally tuned parameters. However, this would imply that the trained artiﬁcial agent would only be as good as those already available algorithms. Instead,
we make use of manually segmented regions of interest (ROI) available for both
pairs of images. By constraining the registration algorithms to enforce the correspondence between the 2 ROIs (for instance by artiﬁcially outlining the ROIs
in images as brighter voxels or using point correspondences in the ROI), the estimated registration improves signiﬁcantly around the ROI. From the resulting
deformations represented on an FFD grid, the d principal components are extracted. Finally, these modes are used to generate the synthetic training samples
by warping the original training images based on randomly drawn deformation
samples according to the SDM. Amplitudes of the modes are bounded to not
exceed the variations experienced in the real image pairs, similar to .
Intra-subject training pairs can be all combinations of synthetically deformed
images of the same subject. Since the ground-truth deformation parameters are
exactly known, it is guaranteed that the agent learns correct deformations. In the
case of inter-patient pairs a synthetic deformed image imb of one subject Im is
allowed to be paired with any synthetic deformed image inc of any other subject
In with b, c denoting random synthetic deformations (see Fig. 1a). Thereby, the
GT parameters θGT for image pair (imb, inc) are extracted via composition of
the diﬀerent known deformations such that ((imb ◦T imb,Im
) ◦T Im,In
) ◦T In,inc
Note the ﬁrst deformation would require the inverse of a known deformation
that we approximate by its opposite parameters for reasons of computational
eﬃciency. The additional error due to this approximation, computed on a few
pairs, remained below 2% in terms of the DICE score.
Mini-batches are created online – during training – via random image pairing
where intra- and inter-subject pairs are selected with the same probabilities.
Through online random pairing the experience of new pairs is enforced since
the number of possible image combinations can be extremely high (e.g. 1012)
depending on the number of synthetic deformations.
Experiments
We focused on organ-centered registration of MR prostate images in 2-D and
3-D with the use case of image fusion and atlas-based segmentation . The
task is very challenging since texture and anatomical appearance can vary a
lot. 25 volumes were selected from the MICCAI challenge PROMISE12 4 and 16
from the Prostate-3T database5 including segmentations. Same images and the
cases with rectal probes were excluded. Randomly 8 cases were chosen for testing
(56 pairs), 33 for training. As preprocessing, translation-based registration for all
pairs was carried out in 3-D using the elastix-framework with standard parameters followed by cropping and down sampling the images (to 100x100/75x75x20
pixels in 2-D/3-D respectively). For the 2-D experiments, the middle slice of each
volume has been taken. For the purpose of GT generation mutual information
as similarity metric and a bending energy metric was used. The optimization
function was further constrained by a Euclidean point correspondence metric.
Therefore, equally distributed points were extracted from the given mask surfaces. elastix was used to retrieve the solution with the weights 1, 3 and 0.2
for the above-mentioned metrics and a B-spline spacing of 16x16(x8) voxels. As
a surrogate measure of registration performance we used the DICE score and
Hausdorﬀdistance (HD) on the prostate region. The extracted GT resulted in
median DICE coeﬃcients of .96 in 2-D and .88 in 3-D. Given the B-spline displacements, the PCA was trained with d = 15 modes in 2-D, d = 25 in 3-D
(leading to 30 respectively 50 actions with a reconstruction error < 5% (DICE
score) as a compromise to keep the number of modes relatively small.
The network’s two independent processing streams contained 3 convolutional
(with 32, 64, 64 ﬁlters and kernel size 3) and 2 max-pooling layers for feature
extraction. The concatenated outputs of the two streams were processed in 3
fully-connected layers (with 128, 128, 64 knots) resulting in an output with
size 2d (equals the number of actions). Batch normalization and ReLu units
were used in all layers. The mini-batch size was 65/30 (2-D/3-D). For updating
the network weights, we used the adaptive learning rate gradient-based method
RMSprop. The learning rate was 0.001 with a decay factor of 0.8 every 10k
mini-batch back-propagations. Training took about 12 hours/ 1 day for 2-D and
3-D respectively. All experiments were implemented in Python using the deep
learning library Theano including Lasagne6. DL tasks ran on GPUs (NVIDIA
GeForce GTX TITAN X ). During testing 200 MDP iterations (incl. resampling
of the moving image) took 10 seconds (GPU) in 2-D and 90 seconds in 3-D
(GPU). The number of testing steps was set empirically since registration results
only change marginally when increasing the number of steps. In empirical 2-D
experiments with 1000 steps the agent’s convergence was observable.
For testing, the initial translation registration was done with elastix by registering each of the test images to an arbitrarily chosen template from the training base. Table 1 shows that our method reaches a median DICE coeﬃcient of
.88/.76 in 2-D/3-D and therefore shows similar performance as in with the
best reported median DICE of .76 on a diﬀerent data set. However, on our challenging test data our method outperformed the LCC-Demons algorithm with
4 
5 
6 
Table 1: Results of prostate MR registration on the 56 testing pairs. 2-D and 3-D
results in comparison to elastix with B-spline spacing of 8 (e8) or 16 (e16) as proposed
in and the LCC-Demons algorithm (dem). T are the initial scores after translation
registration with elastix. 3-D* are results with perfect rigid alignment T*. nfc are our
results with no fuzzy action control (HD in mm).
e8 dem our
e8 dem nfc our
.79 .79 .80
.80 .79 .81
.07 .05 .04
11.6 15.2 14.5 7.7 16.1 21.2 25.3 15.9 11.8
9.2 13.4 14.5 10.4 8.9 8.0
11.7 13.2 13.0 7.2 15.2 18.0 21.7 15.8 11.2
9.0 11.6 13.5 10.8 8.8 7.9
3.9 10.7 10.9
2.5 2.2 1.9
manually tuned parameters and elastix, using similar parameters as proposed
for prostate registration using B-spline spacing of 8 and 16 pixels. We found
that better rigid registration can signiﬁcantly improve the algorithm’s performance as shown in the experiments with perfect rigid alignment according to
the segmentation (3-D*). Extreme results are shown visually in Fig. 2.
Regarding the results of elastix and LCC-Demons, a rising DICE score was
observed while HD increased due to local spikes introduced in the masks (visible
in Fig. 2b) as we focused on the DICE scores during optimization for fair comparisons. In the 3-D* setting, DICE scores and HDs improved when applying
fuzzy action control compared to not applying any constraints (see Table 1).
Conclusion
In this work, we presented a generic learning-based framework using an artiﬁcial
agent for approaching organ-focused non-rigid registration tasks appearing in
image fusion and atlas-based segmentation. The proposed method overcomes
limitations of traditional algorithms by learning optimal features for decisionmaking. Therefore, segmentation or handcrafted features are not required for
the registration during testing. Additionally, we propose a novel ground-truth
generator to learn from synthetically deformed and inter-subject image pairs.
In conclusion, we evaluated our approach on inter-subject registration of
prostate MR images showing ﬁrst promising results in 2-D and 3-D. In future
work, the deformation parametrization needs to be further evaluated. Rigid registration as in could be included in the network or applied as preprocessing
to improve results as shown in the experiments. Besides, the extension to multimodal registration is desirable.
Disclaimer This feature is based on research and is not commercially available.
Due to regulatory reasons its future availability cannot be guaranteed.
(a) 2-D: Moving, Fixed, elastix-e8 (.84), elastix-e16 (.70), ours (.94).
(b) 3-D: Moving, Fixed, elastix-e8 (.49), elastix-e16 (.59), LCC-Demons (.67), ours
Fig. 2: 2-D and 3-D registration results of extreme cases with segmentation masks
overlays (ﬁxed: green, moving: orange) and DICE scores in parenthesis.