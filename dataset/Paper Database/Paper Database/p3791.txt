Learning Bayesian Networks: The Combination of
Knowledge and Statistical Data
David Heckerman
Dan Geiger∗
Microsoft Research, Bldg 9S
Redmond, WA 98052-6399
 , , 
David M. Chickering
We describe scoring metrics for learning
Bayesian networks from a combination of
user knowledge and statistical data.
identify two important properties of metrics,
which we call event equivalence and parameter modularity. These properties have been
mostly ignored, but when combined, greatly
simplify the encoding of a user’s prior knowledge.
In particular, a user can express his
knowledge—for the most part—as a single
prior Bayesian network for the domain.
Introduction
The ﬁelds of Artiﬁcial Intelligence and Statistics share
a common goal of modeling real-world phenomena.
Whereas AI researchers have emphasized a knowledgebased approach to achieving this goal, statisticians
have traditionally emphasized a data-based approach.
In this paper, we present a uniﬁcation of the two approaches. In particular, we develop algorithms based
on Bayesian principles that take as input (1) a user’s
prior knowledge expressed—for the most part—as a
prior Bayesian network and (2) statistical data, and
returns one or more improved Bayesian networks.
Several researchers have examined methods for learning Bayesian networks from data, including Cooper
and Herskovits , Buntine ,
Spiegelhalter et al. (herein referred to as CH,
Buntine, and SDLC, respectively). These methods all
have the same basic components: a scoring metric and
a search procedure. The metric computes a score that
is proportional to the posterior probability of a network structure, given data and a user’s prior knowledge.
The search procedure generates networks for
∗Author’s primary aﬃliation:
Computer Science Department, Technion, Haifa 32000, Israel.
evaluation by the scoring metric. These methods use
the two components to identify a network or set of
networks with high posterior probabilities, and these
networks are then used to predict future events.
In this paper, we concentrate on scoring metrics. Although we restrict ourselves to domains containing
only discrete variables, as we show in Geiger and Heckerman , our metrics can be extended to domains
containing continuous variables. A major contribution
of this paper is that we develop our metrics from a
set of consistent properties and assumptions. Two of
these, called parameter modularity and event equivalence, have been ignored for the most part, and their
combined ramiﬁcations have not been explored. The
assumption of parameter modularity, which has been
made implicitly by CH, Buntine, and SDLC, addresses
the relationship among prior distributions of parameters for diﬀerent Bayesian-network structures. The
property of event equivalence says that two Bayesiannetwork structures that represent the same set of independence assertions should correspond to the same
event and therefore receive the same score. We provide justiﬁcations for these assumptions, and show
that when combined with assumptions about learning Bayesian networks made previously, we obtain a
straightforward method for combining user knowledge
and statistical data that makes use of a prior network.
Our approach is to be contrasted with those of CH
and Buntine who do not make use of a prior network,
and to those of CH and SDLC who do not satisfy the
property of event equivalence.
Our identiﬁcation of the principle of event equivalence
arises from a subtle distinction between two types of
Bayesian networks. The ﬁrst type, called belief networks, represents only assertions of conditional independence.
The second type, called causal networks,
represents assertions of cause and eﬀect as well as assertions of independence. In this paper, we argue that
metrics for belief networks should satisfy event equivalence, whereas metrics for causal networks need not.
Our score-equivalent metric for belief networks is similar to metrics described by York , Dawid and
Lauritzen and Madigan and Raferty , except that our metric scores directed networks, whereas
their metrics score undirected networks. In this paper, we concentrate on directed models rather than on
undirected models, because we believe that users ﬁnd
the former easier to build and interpret.
Belief Networks and Notation
Consider a domain U of n discrete variables x1, . . . , xn.
We use lower-case letters to refer to variables and
upper-case letters to refer to sets of variables.
write xi = k when we observe that variable xi is in
state k. We use p(x = i|y = j, ξ) to denote the probability of a person with background knowledge ξ for the
observation x = i, given the observation y = j. When
we observe the state for every variable in set X, we
call this set of observations an instance of X. We use
p(X|Y, ξ) to denote the set of probabilities for all possible observations of X, given all possible observations
of Y . The joint space of U is the set of all instances
of U. The joint probability distribution over U is the
probability distribution over the joint space of U.
A belief network—the ﬁrst of the two types of Bayesian
networks that we consider—represents a joint probability distribution over U by encoding assertions of
conditional independence as well as a collection of
probability distributions. From the chain rule of probability, we know
p(x1, . . . , xn|ξ) =
p(xi|x1, . . . , xi−1, ξ)
For each variable xi, let Πi ⊆{x1, . . . , xi−1} be a set
of variables that renders xi and {x1, . . . , xi−1} conditionally independent. That is,
p(xi|x1, . . . , xi−1, ξ) = p(xi|Πi, ξ)
A belief network is a pair (BS, BP ), where BS is a
belief-network structure that encodes the assertions of
conditional independence in Equation 2, and BP is a
set of probability distributions corresponding to that
structure. In particular, BS is a directed acyclic graph
such that (1) each variable in U corresponds to a node
in BS, and (2) the parents of the node corresponding
to xi are the nodes corresponding to the variables in
Πi. (In the remainder of this paper, we use xi to refer
to both the variable and its corresponding node in a
graph.) Associated with node xi in BS are the probability distributions p(xi|Πi, ξ).
BP is the union of
these distributions. Combining Equations 1 and 2, we
see that any belief network for U uniquely determines
a joint probability distribution for U. That is,
p(x1, . . . , xn|ξ) =
p(xi|Πi, ξ)
A minimal belief network is a belief network where
Equation 2 is violated if any arc is removed. Thus,
a minimal belief network represents both assertions of
independence and assertions of dependence.
Metrics for Belief Networks:
Previous Work
presented—for example—in CH, Buntine, and SDLC
on the computation of a score for a belief-network
structure BS, given a set of cases D = {C1, . . . , Cm}.
Each case Ci is the observation of one or more variables in U. We sometimes refer to D as a database.
A Bayesian measure of the goodness of a belief-network
structure is its posterior probability given a database:
p(BS|D, ξ) = c p(BS|ξ) p(D|BS, ξ)
where c = 1/p(D|ξ) = 1/ P
BS p(BS|ξ) p(D|BS, ξ) is a
normalization constant. For even small domains, however, there are too many network structures to sum
over in order to determine the constant. Therefore researchers have used p(BS|ξ) p(D|BS, ξ) = p(D, BS|ξ)
as a network-structure score. We note that this metric
treats all variables as being equally important, but can
be generalized [Spiegelhalter et al., 1993].
To compute p(D, BS|ξ) in closed form, researchers typically have made ﬁve assumptions, which we explicate
Assumption 1 The database D is a multinomial
sample from some belief network (BS, BP ).
There are several assumptions implicit in Assumption 1. One is that all variables in U are discrete. We
modify this assumption in another paper in this proceedings [Geiger and Heckerman, 1994]. Another assumption is that the user may be uncertain as to which
belief-network structure is generating the data. This
uncertainty is encoded in the prior probabilities for
network structure p(BS|ξ). Also implicit is that, given
the data comes from a particular network structure,
the user may be uncertain about the probabilities for
that structure. These probabilities actually should be
thought of as being long-run fractions that we would
see in a very large database, and are called parameters
in the statistical literature. Finally, we note that Assumption 1 implies that the processes generating the
data do not change in time.
Figure 1: Illustration of Assumptions 1 and 2 for the
network structure x →y, where x and y are binary.
Assumption 1 can be represented in a belief network.
Figure 1 illustrates the assumption for the network
structure x →y where x and y are binary variables.
(We shall use this two-variable domain to illustrate
many of the points in this paper.) The parameter θx
represents the long-run fraction of cases where x is
observed to be true. Given θx, the observations of x
in each case are independent.
The parameters θy|x
and θy|¯x represent the long-run fraction of cases where
y is observed to be true, in those cases where x is
observed to be true and false, respectively. If these
two parameters are known, then the observations of y
in any two cases are independent, provided x is also
observed for at least one of those cases.
In general, given a belief-network structure BS for
U = {x1, . . . , xn}, we use ri to denote the number
of states of variable xi, and qi = Q
xl∈Πi rl to denote
the number of instances of Πi. We use the integer j
to index these instances. That is, we write Πi = j to
denote the observation of the jth instance of the parents of xi. We use θijk to denote the long-run fraction
of cases where xi = k, in those cases where Πi = j.
We use Θij to denote the union of θijk over k, and
ΘBS to denote the union of Θij for all instances j of
all variables xi. Thus, the set ΘBS corresponds to the
parameter set BP for belief-network structure BS, as
deﬁned in Section 2.
Here, however, these parameters are long-run fractions whose values are uncertain.
Also, we use ρ(·|ξ) to denote the probability density
for a continuous variable or set of variables. For example, ρ(Θij|BS, ξ) denotes the probability density for
the set of parameters Θij, given BS and ξ.
The next assumption, which we call parameter independence, says that the parameters associated with a
given belief-network structure are independent, except
for the obvious dependence among the parameters for
a given variable (which must sum to one).
Assumption 2 (Parameter Independence) For
all belief-network structures BS,
ρ(ΘBS|BS, ξ) =
ρ(Θij|BS, ξ)
This assumption is illustrated in Figure 1 for the network structure x →y.
If all variables in a case are observed, we say that the
case is complete. If all cases in a database are complete, we say that the database is complete.
Assumption 3 All databases are complete.
We note that Spiegelhalter et al. provide an excellent survey of approximations that circumvent this
assumption.
A general metric now follows. Applying the chain rule,
p(D|BS, ξ) =
p(Cl|C1, . . . , Cl−1, BS, ξ)
where Ci is the ith case in the database. Given Assumption 3, it follows that parameters remain independent when cases are observed. This conclusion is easily seen in the simple example of Figure 1.1 Therefore,
conditioning on the parameters of the belief-network
structure BS, we have
p(Cl|C1, . . . , Cl−1, BS, ξ) =
p(Cl|ΘBS , BS, ξ)
ρ(Θij|C1, . . . , Cl−1, BS, ξ)
Also, because each case in D is complete, we have
p(Cl|ΘBS, BS, ξ) =
where αlijk is 1 if and only if xi = k and Πi = j in
case Cl, and 0 otherwise. Plugging Equation 6 into
Equation 5 and the result into Equation 4 yields
p(D, BS|ξ) = p(BS|ξ)
< θijk|C1, . . . , Cl−1, BS, ξ >αlijk
where < θijk|ξ > denotes the expectation of θijk with
respect to ρ(Θij|ξ).
One diﬃculty in applying Equation 7 is that, a user
must provide prior distributions for every parameter
set Θij associated with every structure BS. To reduce
the number of prior distributions, we make the following assumption.
1In general, if a variable is observed in a belief network,
we may delete all arcs emanating from it and retain a valid
belief network.
Assumption 4 (Parameter Modularity)
If xi has the same parents in any two belief-network
structures BS1 and BS2, then for j = 1, . . . , qi,
ρ(Θij|BS1, ξ) = ρ(Θij|BS2, ξ)
We call this property parameter modularity, because it
says that the densities for parameters Θij depend only
on the structure of the belief network that is local to
variable xi—namely, Θij only depends on the parents
of xi. For example, in our two-variable domain, let
BS1 be the network with an arc pointing from x to y,
and BS2 be the network with no arc between x and
y. Then ρ(θx|BS1, ξ) = ρ(θx|BS2, ξ) because x has the
same parents (namely, none) in both belief networks.
We note that CH, Buntine, and SDLC implicitly make
the assumption of parameter modularity . Also, in
the context of causal networks, the assumption has a
compelling justiﬁcation (see Section 7). To our knowledge, however, we are the ﬁrst researchers to make this
assumption explicit. As we see in the following section,
this assumption has important ramiﬁcations.
Given Assumption 3, parameter modularity holds even
after cases have been observed. Consequently, we can
drop the conditioning event BS in Equation 7, to yield
p(D, BS|ξ) = p(BS|ξ)
< θijk|C1, . . . , Cl−1, ξ >αlijk
In Heckerman et al.
 , we provide greater detail about this general metric. Here, we concentrate
on a special case where each parameter set Θij has a
Dirichlet distribution.
An important concept to be used in much of the remaining presentation is that of a complete belief network. A complete belief-network is one with no missing edges—that is, one that represents no assertions of
conditional independence.
Assumption 5 For
belief-network
structure BSC, and for all Θij ⊆ΘBSC , ρ(Θij|BSC, ξ)
has a Dirichlet distribution. Namely, there exists exponents N ′
ijk > 0, such that
ρ(Θij|BSC, ξ) ∝
From this assumption and our assumption of parameter modularity, it follows that for every belief-network
structure BS, and for all Θij ⊆ΘBS, ρ(Θij|BS, ξ) has
a Dirichlet distribution.2
When every such parameter set of BS has this distribution, we simply say that
ρ(ΘBS|BS, ξ) is Dirichlet.
Combining our previous assumptions with this consequence of Assumption 5, we obtain
ρ(Θij|D, BS, ξ) ∝
ijk+Nijk−1
where Nijk is the number of cases in D where xi = k
and Πi = j. Thus, if the prior distribution for Θij
has a Dirichlet distribution, then so does the posterior distribution for Θij.
We say that the Dirichlet
distribution is closed under multinomial sampling, or
that the Dirichlet distribution is a conjugate family
of distributions for multinomial sampling. Given this
< θijk|D, ξ >=
ijk + Nijk
where Nij = Pri
k=1 Nijk, and N ′
ijk. Substituting Equation 9 into each term of Equation 8, and
performing the sum over l, we obtain
ijk + Nijk)
where Γ is the Gamma function, which satisﬁes Γ(x +
1) = xΓ(x).
We shall refer to Equation 10 as the
BD metric (Bayesian metric with Dirichlet priors), although we emphasize that this metric is not new.
Even with the inclusion of the assumption of parameter modularity, the application of this metric is diﬃcult, because it requires that a user specify the Dirichlet exponents N ′
ijk for every complete belief network
structure.
In the following section, we introduce a
property of belief-network metrics called event equivalence. In the subsequent section, we show how this
property leads to a dramatic simpliﬁcation of the assessment of these Dirichlet exponents.
Event Equivalence and Score
Equivalence
In the previous section, we used BS as an argument of
probabilities and probability densities. However, BS
is a belief-network structure, not an event. Thus, we
should have used Be
S in these situations, where Be
the event that corresponds to structure BS (the superscript “e” stands for event). In this section, we provide
2CH, Buntine, and SDLC express Assumption 5 in this
a deﬁnition of Be
S and explicate an important property
of this deﬁnition.
A simple deﬁnition of Be
S is implicit in Assumption 1.
In particular, this assumption says that (1)
the database is a multinomial sample from the joint
space of U, and (2) Be
S holds true iﬀthe multinomial parameters for U satisfy the independence assertions of BS. For example, in our two-variable domain, Condition 1 corresponds to the assertion that
a given database is a multinomial sample from the
joint space {xy, x¯y, ¯xy, ¯x¯y}. Given BS is the network
structure with no arc between x and y, Condition 2
says that the event Be
S corresponds to the assertion
θxy + θ¯xy = θxy/(θxy + θx¯y)—that is, θy = θy|x.
This deﬁnition has the following desirable property.
When two belief-network structures represent the
same assertions of conditional independence, we say
that they are isomorphic. For example, in the three
variable domain {x, y, z}, the network structures x →
y →z and x ←y →z represent the same assertion: x
and z are independent given y. Given the deﬁnition of
S, it follows that events Be
S2 are equivalent
if and only if the structures BS1 and BS2 are isomorphic. That is, the relation of isomorphism induces an
equivalence class on the set of events Be
S. We call this
property event equivalence.
There is a problem with the deﬁnition, however. In
particular, events corresponding to non-isomorphic
network structures are not mutually exclusive.
example, the event corresponding to a complete beliefnetwork structure always holds true, and therefore implies the event corresponding to any other structure.
In this case, and in general, the scores p(D, Be
S) associated with these network structures are useless for
comparison.
A seemingly reasonable repair would be to say that
S holds true iﬀthe multinomial parameters for U
satisfy the independence and dependence assertions of
BS, where BS is now interpreted as a minimal beliefnetwork structure. Under this revised deﬁnition, each
event is a set of equalities (as before), and also a set
of inequalities. For example, given BS1 is the beliefnetwork structure x →y in our two-variable domain,
S1 is the event θy|x ̸= θy; and given BS2 is
the belief-network structure with no arc, then Be
the event θy|x = θy. These two events are mutually
exclusive. Furthermore, the events corresponding to
x →y and y →x are equal.
This repair is still not suﬃcient for larger domains,
however. First, the property of score equivalence may
be violated.
For example, in the three-variable domain {x, y, z}, the events corresponding to complete
belief-network structures for diﬀerent orderings are not
equal. We may recover this property by including in
the event corresponding to a set of isomorphic network
structures E the union of inequalities associated with
each such structure in E. Second, events corresponding to some non-isomorphic structures are not mutually exclusive. For example, the events corresponding
to the structures x →y ←z and x →y →z both
include the situation where θz|x = θz. In general, however, such overlaps will be of measure zero with respect
to the events that create the overlap. Thus, given a set
of overlapping events, we may exclude the intersection
from all but one of the events without aﬀecting our
mathematical results or the intuitive understanding of
events by the user.
This revised deﬁnition of the event Be
S guarantees that
the set of events corresponding to the set of all possible network structures for a given domain is mutually exclusive. Furthermore, the deﬁnition retains the
property of event equivalence.
Proposition 1 (Event Equivalence)
Belief-network structures BS1 and BS2 are isomorphic
if and only if Be
S|ξ), an immediate consequence of the property
of event equivalence is score equivalence3:
Proposition 2 (Score Equivalence) The scores of
two isomorphic belief-network structures must be equal.
We note that, given the property of event equivalence, we technically should score each belief-networkstructure equivalence class, rather than each beliefnetwork structure. Nonetheless, users ﬁnd it intuitive
to work with (i.e., construct and interpret) belief networks.
Consequently, we continue our presentation
in terms of belief networks, keeping Proposition 2 in
It is easy to show that the BD metric given by Equation 10 does not exhibit the property of score equivalence for most choices of the Dirichlet exponents N ′
Thus, the property of event equivalence must induce
constraints on the parameters N ′
3In making the assumptions of parameter independence
and parameter modularity, we have—in eﬀect—speciﬁed
the prior densities for the multinomial parameters in terms
of the structure of a belief network. Consequently, there is
the possibility that this speciﬁcation violates the property
of score equivalence. In Heckerman et al. , however,
we show that our assumptions and score equivalence are
consistent.
The Prior Belief Network
In this section, we show how the property of event
equivalence and Assumptions 1 through 5 lead to constraints on the exponents N ′
ijk. We see that the constraints are so strong, that all exponents may be constructed from (1) a belief network reﬂecting the user’s
current knowledge about the next case, and (2) and
equivalent sample size for the domain as a whole.
To begin, let us see how the property of event equivalence and Assumptions 1 through 4 constrain the prior
densities ρ(ΘBS|Be
S, ξ). That is, for the moment, let
us ignore the assumption that densities are Dirichlet.
First, consider only complete belief-network structures.
From the property of event equivalence, we
know that the event associated with any complete
belief-network structure for a given domain U is the
same; and we use Be
SC to denote this event. So, suppose that we know the density of the multinomial parameters for the joint space of U conditioned on Be
Then, we may determine the density of the parameters
for any complete network structure, simply by performing a change-of-variable operation. For example,
consider the complete belief-network structure x →y
for our two-variable domain. A parameter set for the
joint space is {θxy, θ¯xy, θx¯y}; and a parameter set for
the network structure is {θx, θy|x, θy|¯x}. These sets are
related by the following relations:
θxy = θxθy|x
θ¯xy = (1 −θx)(θy|¯x)
θx¯y = θx(1 −θy|x)
Thus, given the density ρ(θxy, θ¯xy, θx¯y|Be
SC, ξ) for
ρ(θx, θy|x, θy|¯x|Be
SC, ξ) using the relation
ρ(θx, θy|x, θy|¯x|Be
SC, ξ) = J · ρ ,
we show that, given the density of the multinomial
parameters for the joint space of U conditioned on
SC, we may determine the density of the parameters for any network structure.
To understand this
result, consider the incomplete network structure containing no arc between x and y for our two variable domain. The method for determining the density for the parameters of BS is illustrated in Figure 2. Given the assumption of parameter indepen-
modularity
Figure 2: A method for obtaining the density for the
parameters of BS from the density of the joint space
of the domain.
dence, we may obtain the densities for θx and θy separately. To obtain the density for θx, we identify a
complete network structure BSC1 such that x has the
same parents (namely, none) in both BS and BSC1.
Next, using the change-of-variable procedure described
in the previous paragraph, we determine the density
SC1, ξ) from ρ(θxy, θ¯xy, θx¯y|Be
use the assumption of parameter modularity to obtain ρ(θx|Be
S, ξ) = ρ(θx|Be
SC1, ξ). In a similar manner, as illustrated in the ﬁgure, we obtain the density
Next, let us consider Assumption 5. By a similar argument to that given in the ﬁrst part of this discussion, we know that given any two complete network
structures BSC1 and BSC2, we may obtain the density ρ(ΘBSC1|Be
SC, ξ) from ρ(ΘBSC2|Be
SC, ξ), and vice
versa, through a change of variable. If we assume that
the densities for BSC1 are Dirichlet, however, it may
not be the case that the densities for BSC2 will be
Dirichlet. For example, in our two-variable domain,
suppose ρ(θx, θy|x, θy|¯x|Be
SC, ξ) is equal to a constant
(all Dirichlet exponents equal to 1). After a change of
variable, from Equation 11 we have
ρ(θy, θx|y, θx|¯y|Be
SC, ξ) ∝· θy(1−θy)
(θyθx|y+(1−θy)θx|¯
y)(1−(θyθx|y+(1−θy)θx|¯
which is not Dirichlet. Consequently, the Dirichlet exponents must be constrained.
In Heckerman et al.
 , we show
that if ρ(ΘBSC |Be
SC, ξ) is Dirichlet for every complete
belief-network structure BSC, then the density of the
parameters for the joint space (also conditioned on
SC) must also have a Dirichlet distribution. Combining this result with our previous discussion, we see
that we may obtain all exponents N ′
ijk for all beliefnetwork structures, simply by assessing the Dirichlet
density for the joint space of U conditioned on Be
For domains containing a small number of variables,
the user may assess this density directly.
domains, however, we can use an assessment method
based on the notion of an equivalent sample size,
described by Winkler .
To understand this
method, let Θx1,...,xn denote the set of parameters
for the joint space of U = {x1, . . . , xn}. Denote the
Dirichlet density for these parameters as follows:
ρ(Θx1,...,xn|Be
[θx1,...,xn](N ′
x1,...,xn−1)
Now, the expectation of Θx1,...,xn with respect to
ρ(Θx1,...,xn|Be
SC, ξ) is equal to the user’s prior probability p(x1, . . . , xn|Be
SC, ξ) for the next instance of the
domain to be observed. Thus, using the formula for
the expectation of Θx1,...,xn given the Dirichlet density
in Equation 12, we obtain
p(x1, . . . , xn|Be
SC, ξ) = N ′
Thus, we can determine all needed exponents by having a user assess p(x1, . . . , xn|Be
SC, ξ) and N ′.
The user can assess the joint probability distribution
p(x1, . . . , xn|Be
SC, ξ) by constructing a belief network
for U, given Be
SC. We call this network the user’s prior
belief network.4
The constant N ′ has a simple interpretation as the
equivalent number of cases that the user has seen since
he was completely ignorant about the domain. Winkler shows how a user may be trained to assess
The BDe Metric
Given a prior belief network and the constant N ′, it
is not diﬃcult to show that the exponents N ′
determined by the relation
ijk + 1 = N ′ · p . This constraint has a simple interpretation in terms of equivalent sample sizes. Namely, N ′
ijk is the
equivalent sample size for the parameter set Θij—the
4At ﬁrst glance, there seems to be a contradiction in
asking the user to construct such a belief network—which
may contain assertions of independence—under the assertion that Be
SC is true. The assertions of independence in
the prior network, however, refer to independencies in the
next case to be observed. In contrast, the assertion of full
dependence Be
SC refers to long-run fractions.
parameters for xi, given that we have observed the jth
instance of Πi. From Equation 15, we see that
ij = N ′ · p(Πi = j|Be
That is, the equivalent sample size for Θij is just the
overall equivalent sample size N ′ times the probability
that we see Πi = j.
Substituting Equation 15 into the BD metric (Equation 10), we obtain the BDe metric, a score equivalent
metric for belief networks. We note that N ′ acts as a
gain control for learning—the smaller the value of N ′,
the more quickly the BDe metric will favor network
structures that diﬀer from the prior belief-network
structure.
As an example, let Bx→y and By→x denote the beliefnetwork structures where x points to y and y points
to x, respectively, in our two-variable domain. Suppose that N ′ = 12 and that the user’s prior network gives the joint distribution p(x, y|Be
1/4, p(x, ¯y|Be
x→y, ξ) = 1/4, p(¯x, y|Be
x→y, ξ) = 1/6, and
p(¯x, ¯y|Be
x→y, ξ) = 1/3. Using the BDe metric, if we
observe database D containing a single case with both
x and y true, we obatin
x→y|ξ) = p(Be
x→y|ξ) · 11!
y→x|ξ) = p(Be
y→x|ξ) · 11!
Thus, as required, the BDe metric exhibits the property of score equivalence.5
Causal Networks
People often have knowledge about the causal relationships among variables in addition to knowledge about
conditional independence. Such causal knowledge is
stronger than is conditional-independence knowledge,
because it allows us to derive beliefs about a domain
after we intervene. For example, most of us believe
that smoking causes lung cancer. From this belief, we
infer that if we stop smoking, then we decrease our
chances of getting lung cancer. In contrast, if we were
to believe that there is only a statistical correlation between smoking and lung cancer, perhaps because there
is a gene that causes both our desire to smoke and lung
5We note that Buntine presented without derivation
the special case of the BDe metric obtained by letting
SC, ξ) be uniform, and noted the property of score
equivalence.
Also, CH presented a special case of the
BD metric wherein each N ′
ijk is set to 1, yielding a uniform Dirichlet distribution on each density ρ , Pearl and Verma , and Heckerman
and Shachter represent such causal relationships among variables. In particular, a causal network
for U is a belief network for U, wherein it is asserted
that each nonroot node x is caused by its parents. The
precise meaning of cause and eﬀect is not important for
our discussion. The interested reader should consult
the previous references.
More formally, we deﬁne a causal network to be a pair
(CS, CP ), where CS is a causal-network structure and
CP is a set of probability distributions corresponding
to that structure. The event Ce
S is the same as that for
a belief-network structure, except that we also include
in the event the assertion that each nonroot node is
caused by its parents.
In contrast to the case of belief networks, it is not appropriate to require the properties of event equivalence
or score equivalence. For example, in our two-variable
domain, both the causal network CS1 where x points to
y and the causal network CS2 where y points to x represent the assertion that x and y are dependent. The
network CS1, however, in addition represents the assertion that x causes y, whereas the network CS2 represents the assertion that y causes x. Thus, the events
S2 are not equal. Indeed, it is reasonable to
assume that these events—and the events associated
with any two diﬀerent causal-network structures—are
mutually exclusive.
Therefore, the consequences of event equivalence discussed in Section 5 do not apply to causal networks.
In particular, the exponents N ′
ijk have no theoretical
constraints, and we may use the BD metric to score
causal networks.
Nonetheless, for practical reasons,
it is useful to constrain the parameters N ′
describe one such approach.
First, as we do, they
asses a prior network. Then, for each variable xi and
each instance j of Πi in the prior network, they allow the user to specify an equivalent sample size N ′
From these assessments, SDLC compute equivalent
sample sizes N ′
ij for other network structures using
an expansion–contraction procedure. This method has
several appealing theoretical properties, but is computationally expensive.
CH’s specialization of the BD
metric, wherein they set each N ′
ijk to one is eﬃcient,
but ignores the prior network.
We have explored a
simple approach, wherein each Nij is equal to N ′′, a
We call this metric the BDu metric (“u”
stands for uniform equivalent sample sizes). Of course,
the BDe metric may also be used to score causal networks.
Note that, in the context of causal networks, the assumption of parameter modularity (Assumption 4) has
an appealing justiﬁcation.
Namely, we can imagine
that a causal mechanism is responsible for the interaction between each node and its parents.
The assumption of parameter modularity then follows from
the assumption that the causal mechanisms are independent.
Limitations of the BDe Metric
Let us again consider the scoring of belief networks.
Although our method for determining the exponents
ijk is simple, it is—in a sense—too simple. Namely,
it may be the case that a user has more knowledge
about some variables than others, and would like to
assess diﬀerent equivalent sample sizes N ′
ij for diﬀerent values of i and j. If the network is causal, doing so
represents no problem. As we have seen in Section 5,
however, doing so in the case of belief networks requires that we abandon at least one of (1) score equivalence, (2) Dirichlet priors, or (3) the ability to score
all possible network structures.
We believe it is important to retain score equivalence
if at all possible. Furthermore, it is computationally
expensive to abandon the Dirichlet assumption. There
is promise, however, in avoiding the third assumption.
Namely, given a non-score-isomorphic metric that accommodates variable dependent sample sizes, we could
use it to score only one element from each equivalence
class of isomorphic network structures. To do so, we
need a method for designating exactly one network
structure from each equivalence class as the network
to be scored. A simple approach would be to ask the
user to specify a complete ordering over the domain
variables. For example, given the ordering (x, y, z) for
our three-variable domain, the equivalence class corresponding to the conditional independence of x and z
given y would be represented by the network structure
x →y →z; and we would score only this structure.
As a more subtle example, given the same ordering,
the equivalence class corresponding to the conditional
independence of x and y given z would be represented
by x →z →y, because among those network structures in this equivalence class, x occurs ﬁrst only in
this network structure.
Priors for Network Structures
To complete the information needed to compute our
metrics, the user must assess the prior probabilities
for the network structures. These assessments are logically independent of the assessment of the prior network, except in the limit as equivalent sample size(s)
approach inﬁnity, when the prior network structure
must receive a prior probability of one. Nonetheless,
structures that closely resemble the prior network tend
to have higher prior probabilities.
Here, we propose the following parametric formula for
S|ξ) that makes use of the prior network. Given
a network structure BS, let δi denote the number of
nodes in the symmetric diﬀerence of the parents of
xi in BS and the parents of xi in the prior network
structure. Then, BS and the prior network diﬀer by
i=1 δi arcs; and we penalize BS by a constant
factor 0 < κ ≤1 for each such arc. That is, we set
S|ξ) = c κδ
where c is a normalization constant. This formula is
simple, as it requires only the assessment of a single
constant κ. Nonetheless, we can imagine generalizing
the formula by punishing diﬀerent arc diﬀerences with
diﬀerent weights, as suggested by Buntine. Although
this parametric form does not satisfy score equivalence,
we may recover this property, as described in the previous section, by designating within each event equivalence class the network structure to be scored.
Evaluation
In this section, we evaluate the BDe metric using the
36-node Alarm network for the domain of ICU ventilator management [Beinlich et al., 1989]. In our evaluations we start with the given network, which we
call the gold-standard network. Next, we generate a
database from the given network, using a Monte-Carlo
technique. Then, we use one of the scoring metrics and
a local search procedure similar to the one described in
Lam and Bacchus to identify a high-scoring network structure. Next, we use the database and prior
knowledge to populate the probabilities in the new network, called the learned network. In particular, we set
each probability p(xi = k|Πi = j) to be the posterior
mean of θijk, given the database.
Finally, we compare the joint distributions of the gold-standard and
learned networks.
In this paper, we use the cross-entropy measure
for comparison.
In particular, let q(xi, . . . , xn) and
p(xi, . . . , xn) denote the probability of an instance of
U obtained from the gold-standard and learned networks, respectively. Then we measure the accuracy of
a learning algorithm using the cross entropy H(q, p),
q(xi, . . . , xn) log q(xi, . . . , xn)
p(xi, . . . , xn)
The lower the value of the cross entropy, the more accurate the algorithm. In Heckerman et al. , we
describe a method for computing the cross entropy of
two networks that makes use of the network structures.
In our experiments, we construct prior networks by
adding noise to the gold-standard network. We control the amount of noise with a parameter η. When
η = 0, the prior network is identical to the goldstandard network, and as η increases, the prior network diverges from the gold-standard network. When
η is large enough, the prior network and gold-standard
networks are unrelated. To generate the prior network,
we ﬁrst add 2η arcs to the gold-standard network, creating network structure BS1. When we add an arc,
we copy the probabilities in BP 1 so as to maintain
the same joint probability distribution for U. Next,
we perturb each conditional probability in BP 1 with
In particular, we convert each probability to
log odds, add to it a sample from a normal distribution with mean zero and standard deviation η, convert
the result back to a probability, and renormalize the
probabilities. Then, we create another network structure BS2 by deleting η arcs and reversing up to 2η
arcs (a reversal may create a directed cycle, in which
case, the reversal is not done). Next, we perform inference using the joint distribution determined by network (BS1, BP 1) to populate the conditional probabilities for network (BS2, BP 2), which we return as the
prior network.
Figure 3 shows the cross entropy of learned networks
with respect to the Alarm network (inverse learning
accuracy) as a function of the deviation of the priornetwork from the gold- standard network (η) and the
user’s equivalent sample size (N ′) for the BDe metric.
In this experiment, we used 100-case databases generated from the Alarm network. For each value of η and
N ′, the cross-entropy values shown in the ﬁgure represent an average over ten learning instances, where in
each instance we used a diﬀerent database and prior
network. The databases and prior networks generated
for a given value of η were used for all values of N ′. We
made the prior parameter κ a function of N ′—namely,
κ = 1/(N ′ + 1)—so that it would take on reasonable
values at the extremes of N ′. (When N ′ = 0, reﬂecting complete ignorance, all network structures receive
the same prior probability. Whereas, in the limit as
N ′ approaches inﬁnity, reﬂecting complete conﬁdence,
the prior network structure receives a prior probability
The qualitative behavior of the curve is reasonable.
Namely, when η = 0—that is, when the prior network was identical to the Alarm network—learning
accuracy increased as the equivalent sample size N ′
increased.
Also, learning accuracy decreased as the
Cross Entropy
BDe Metric
Figure 3: Evaluation results.
prior network deviated further from the gold-standard
network, demonstrating the expected result that prior
knowledge is useful. In addition, when η ̸= 0, there
was a value of N ′ associated with optimal accuracy.
This result is not surprising. If N ′ is too large, then
the deviation between the true values of the parameters and their priors degrade performance. On the
other hand, if N ′ is too small, the metric is ignoring
useful prior knowledge. We speculate that results of
this kind can be used to calibrate users in the assessment of N ′.
Also, the quantitative results are encouraging. To provide a scale for cross entropy in the Alarm domain,
note that the cross entropy of the Alarm network with
an empty network for the domain (i.e., a network
where all variables are independent) whose marginal
probabilities are determined from the Alarm network
is 13.6. Using only a 100 case database, and a prior
network with a signiﬁcant amount of noise—η = 2,
the cross entropy for the BDe metric, at the optimum
value of N ′ (= 16), is only 1.6.
Acknowledgments
We thank Jack Breese, Wray Buntine, Greg Cooper,
Steﬀen Lauritzen, and anonymous reviewers for useful
suggestions.