Relational Learning via Collective
Matrix Factorization
Ajit P. Singh Geoffrey J. Gordon
CMU-ML-08-109
Relational Learning via Collective Matrix
Factorization
Ajit P. Singh
Geoﬀrey J. Gordon
CMU-ML-08-109
School of Computer Science
Carnegie Mellon University
Pittsburgh, PA 15213
Relational learning is concerned with predicting unknown values of a relation, given a database of entities
and observed relations among entities. An example of relational learning is movie rating prediction, where
entities could include users, movies, genres, and actors. Relations would then encode users’ ratings of movies,
movies’ genres, and actors’ roles in movies. A common prediction technique given one pairwise relation, for
example a #users × #movies ratings matrix, is low-rank matrix factorization. In domains with multiple
relations, represented as multiple matrices, we may improve predictive accuracy by exploiting information
from one relation while predicting another. To this end, we propose a collective matrix factorization model:
we simultaneously factor several matrices, sharing parameters among factors when an entity participates in
multiple relations. Each relation can have a diﬀerent value type and error distribution; so, we allow nonlinear
relationships between the parameters and outputs, using Bregman divergences to measure error. We extend
standard alternating projection algorithms to our model, and derive an eﬃcient Newton update for the
projection. Furthermore, we propose stochastic optimization methods to deal with large, sparse matrices.
Our model generalizes several existing matrix factorization methods, and therefore yields new large-scale
optimization algorithms for these problems. Our model can handle any pairwise relational schema and a
wide variety of error models. We demonstrate its eﬃciency, as well as the beneﬁt of sharing parameters
among relations.
This research is supported by DARPA grant NBCHD030010 (RADAR Project).
Keywords: Matrix factorization, relational learning, stochastic approximation
Introduction
Relational data consists of entities and relations between them. In many cases, such as relational databases,
the number of entity types and relation types are ﬁxed. Two important tasks in such domains are link
prediction, determining whether a relation exists between two entities, and link regression, determining the
value of a relation between two entities given that the relation exists.
Many relational domains involve only one or two entity types: documents and words; users and items;
or academic papers where attributed links between entities represent counts, ratings, or citations. In such
domains, we can represent the links as an m × n matrix X: rows of X correspond to entities of one type,
columns of X correspond to entities of the other type, and the element Xij indicates either whether a
relation exists between entities i and j. A low-rank factorization of X has the form X ≈f(UV T ), with
factors U ∈Rm×k and V ∈Rn×k. Here k > 0 is the rank, and f is a possibly-nonlinear link function.
Diﬀerent choices of f and diﬀerent deﬁnitions of ≈lead to diﬀerent models: minimizing squared error with
an identity link yields the singular value decomposition (corresponding to a Gaussian error model), while
other choices extend generalized linear models to matrices and lead to error models such as
Poisson, Gamma, or Bernoulli distributions.
In domains with more than one relation matrix, one could ﬁt each relation separately; however, this
approach would not take advantage of any correlations between relations. For example, a domain with users,
movies, and genres might have two relations: an integer matrix representing users’ ratings of movies on a
scale of 1–5, and a binary matrix representing the genres each movie belongs to. If users tend to rate dramas
higher than comedies, we would like to exploit this correlation to improve prediction.
To do so, we extend generalized linear models to arbitrary relational domains. We factor each relation
matrix with a generalized-linear link function, but whenever an entity type is involved in more than one
relationship, we tie factors of diﬀerent models together.
We refer to this approach as collective matrix
factorization.
We demonstrate that a general approach to collective matrix factorization can work eﬃciently on large,
sparse data sets with relational schemas and nonlinear link functions. Moreover, we show that, when relations
are correlated, collective matrix factorization can achieve higher prediction accuracy than factoring each
matrix separately. Our code is available under an open license.1
A Uniﬁed View of Factorization
The building block of collective factorization is single-matrix factorization, which models a single relation
between two entity types E1 and E2. If there are m entities of type E1 and n of type E2, we write X ∈Rm×n
for our matrix of observations, and U ∈Rm×k and V ∈Rn×k for the low-rank factors. A factorization
algorithm can be deﬁned by the following choices, which are suﬃcient to include most existing approaches
(see Sec. 2.2 for examples):
1. Prediction link f : Rm×n →Rm×n.
2. Loss function D(X, f(UV T )) ≥0, a measure of the error in predicting f(UV T ) when the answer is X.
3. Optional data weights W ∈Rm×n
, which if used must be an argument of the loss.
4. Hard constraints on factors, (U, V ) ∈C.
5. Regularization penalty, R(U, V ) ≥0.
For the model X ≈f(UV T ), we solve:
[D(X, f(UV T )) + R(U, V )].
1Source code is available at This paper is a longer version of Singh et al. .
The loss D(·, ·) quantiﬁes ≈in the model. It is typically convex in its second argument, and often decomposes
into a weighted sum over the elements of X. For example, the loss for weighted SVD is
DW (X, UV T ) = ||W ⊙(X −UV T )||2
where ⊙denotes the element-wise product of matrices.
Prediction links f allow nonlinear relationships between UV T and the data X. The choices of f and
D are closely related to distributional assumptions on X; see Section 2.1. Common regularizers for linear
models, such as ℓp-norms, are easily adapted to matrix factorization. Other regularizers have been proposed
speciﬁcally for factorization; for example, the trace norm of UV T , the sum of its singular values, has been
proposed as a continuous proxy for rank .
For clarity, we treat hard constraints C separately from
regularizers. Examples of hard constraints include orthogonality; stochasticity of rows, columns, or blocks
(e.g., in some formulations of matrix co-clustering each row of U and V sums to 1); non-negativity; and
sparsity or cardinality.
Bregman Divergences
A large class of matrix factorization algorithms restrict D to generalized Bregman divergences: e.g., singular
value decomposition and non-negative matrix factorization .
Deﬁnition 1 ( ). For a closed, proper, convex function F : Rm×n →R, the generalized Bregman divergence between matrices Z and Y is
DF (Z || Y ) = F(Z) + F ∗(Y ) −Y ◦Z,
where A ◦B is the matrix dot product tr(AT B) = P
ij AijBij and F ∗is the convex dual (Fenchel-Legendre
conjugate): F ∗(µ) = supθ∈dom F [⟨θ, µ⟩−F(θ)].
If F ∗is diﬀerentiable, this is equivalent to the standard deﬁnition , except that the standard
deﬁnition uses arguments Z and ∇F ∗(Y ) instead of Z and Y . If F decomposes into a sum over components
of Z, we can deﬁne a weighted divergence. Overloading F to denote a single component of the sum,
DF (Z || Y, W) =
Wij (F(Zij) + F ∗(Yij) −YijZij) .
Examples include weighted versions of squared loss, F(x) = x2, and I-divergence, F(x) = x log x −x. Our
primary focus is on decomposable regular Bregman divergences , which correspond to maximum likelihood
in exponential families:
Deﬁnition 2. A parametric family of distributions ψF = {pF(x|θ) : θ} is a regular exponential family if
each density has the form
log pF (x|θ) = log p0(x) + θT x −F(θ)
where θ is the vector of natural parameters for the distribution, x is the vector of minimal suﬃcient statistics,
and F(θ) is the log-partition function
F(θ) = log
p0(x) · exp(θT x) dx.
A distribution in ψF is uniquely identiﬁed by its natural parameters. For regular exponential families
log pF (x|θ) = log p0(x) + F ∗(x) −DF ∗(x || f(θ))
where the matching prediction link is f(θ) = ∇F(θ) . Minimizing a Bregman divergence under
a matching link is equivalent to maximum likelihood for the corresponding exponential family distribution.
The relationship between matrix factorization and exponential families is seen by treating the data matrix
X as a collection of samples, X = {X11, . . . , Xmn}. Modeling X = f(UV T ), we have that Xij is drawn from
the distribution in ψF with natural parameter (UV T )ij.
Decomposable losses, which can be expressed as the sum of losses over elements, follows from matrix
exchangeability . A matrix X is row-and-column exchangeable if permuting the rows and columns of X
does not change the distribution of X. For example, if X is a document-word matrix of counts, the relative
position of two documents in the matrix is unimportant: the rows are exchangeable (likewise for words). A
surprising consequence of matrix exchangeability is that the distribution of X can be described by a function
of a global matrix mean, row and column eﬀects (e.g., row biases, column biases), and a per-element eﬀect
(e.g., the natural parameters UV T above). The per-element eﬀect leads naturally to decomposable losses. An
example where decomposability is not a legitimate assumption is when one dimension indexes a time-varying
The simplest case of matrix factorization is the singular value decomposition: the data weights are constant,
the prediction link is the identity function, the divergence is the sum of squared errors, and the factors are
unregularized. A hard constraint that one factor is orthogonal and the other orthonormal ensures uniqueness
of the global optimum (up to permutations and sign changes), which can be found using Gaussian elimination
or the Power method .
Variations of matrix factorization change one or more of the above choices. Non-negative matrix factorization maximizes the objective
X ◦log(UV T ) −1 ◦UV T
where 1 is a matrix with all elements equal to 1. Maximizing Equation 2 is equivalent to minimizing the
I-divergence DH(X || log(UV T )) under the constraints U, V ≥0. Here H(x) = x log(x) −x. The prediction
link is f(θ) = log(θ).
The scope of matrix factorizations we consider is broader than , but the same alternating Newtonprojections approach (see Sections 4-5) can be generalized to all the following scenarios, as well as to collective
matrix factorization: (i) constraints on the factors, which are not typically considered in Bregman matrix
factorization as the resulting loss is no longer a regular Bregman divergence. Constraints allow us to place
methods like non-negative matrix factorization or matrix co-clustering into our framework. (ii) non-
Bregman matrix factorizations, such as max-margin matrix factorization , which can immediately take
advantage of the large scale optimization techniques in Sections 4-5; (iii) row and column biases, where a
column of U is paired with a ﬁxed, constant column in V (and vice-versa). If the prediction link and loss
correspond to a Bernoulli distribution, then margin losses are special cases of biases; (iv) methods based
on plate models, such as pLSI , can be placed in our framework just as well as methods that factor
data matrices. While these features can be added to collective matrix factorization, we focus primarily on
relational issues herein.
Relational schemas
A relational schema contains t entity types, E1 . . . Et. There are ni entities of type i, denoted {x(i)
relation between two types is Ei ∼u Ej; index u ∈N allows us to distinguish multiple relations between the
same types, and is omitted when no ambiguity results. In this paper, we only consider binary relations. The
matrix for Ei ∼u Ej has ni rows, nj columns, and is denoted X(ij,u). If we have not observed the values
of all possible relations, we ﬁll in unobserved entries with 0 (so that X(ij,u) is a sparse matrix), and assign
them zero weight when learning parameters. By convention, we assume i ≤j. Without loss of generality, we
assume that it is possible to traverse links from any entity type to any other; if not, we can ﬁt each connected
component in the schema separately. This corresponds to a fully connected entity-relationship model .
We ﬁt each relation matrix as the product of latent factors, X(ij) ≈f (ij)(U (i)(U (j))T ), where U (i) ∈
Rni×kij and U (j) ∈Rnj×kij for kij ∈{1, 2, . . .}. Unless otherwise noted, the prediction link f (ij) is an
element-wise function on matrices. If Ej participates in more than one relation, we allow our model to use
only a subset of the columns of U (j) for each one. This ﬂexibility allows us, for example, to have relations with
diﬀerent latent dimensions, or to have more than one relation between Ei and Ej without forcing ourselves
to predict the same value for each one. In an implementation, we would store a list of participating column
indices from each factor for each relation; but to avoid clutter, we ignore this possibility in our notation.
Collective Factorization
For concision, we introduce collective matrix factorization on the three-entity-type schema E1 ∼E2 ∼E3, and
use simpliﬁed notation: the two data matrices are X = X(12) and Y = X(23), of dimensions m = n1, n = n2,
and r = n3. The factors are U = U (1), V = U (2), and Z = U (3). The latent dimension is k = k12 = k23.
The weight matrix for X is W, and the weight matrix for Y is ˜W. Since E2 participates in both relations,
we use the factor V in both reconstructions: X ≈f1(UV T ) and Y ≈f2(V ZT ).
An example of this schema is collaborative ﬁltering: E1 are users, E2 are movies, and E3 are genres. X is
a matrix of observed ratings, and Y indicates which genres a movie belongs to (each column corresponds to
a genre, and movies can belong to multiple genres).
One model of Bregman matrix factorization proposes the following decomposable loss function for
X ≈f1(UV T ):
L1(U, V |W) = DF1(UV T || X, W) + DG(0 || U) + DH(0 || V ),
where G(u) = λu2/2 and H(v) = γv2/2 for λ, γ > 0 corresponds to ℓ2 regularization. Ignoring terms that
do not vary with the factors the loss2 is
L1(U, V |W) =
 W ◦F(UV T ) −(W ⊙X) ◦UV T 
+ G∗(U) + H∗(V ).
Similarly, if Y were factored alone, the loss would be
L2(V, Z| ˜W) = DF2(V ZT || Y, ˜W) + DH(0 || V ) + DI(0 || Z).
Since V is a shared factor we average the losses:
L(U, V, Z|W, ˜W) = αL1(U, V |W) + (1 −α)L2(V, Z| ˜W),
where α ∈ weights the relative importance of relations.
Each term in the loss, L1 and L2, is decomposable and twice-diﬀerentiable, which is all that is required
for the alternating projections technique described in Section 4.1. Despite the simplicity of Equation 3,
it has some interesting implications. The distribution of Xij given x(1)
j , and the distribution of
Yjk given x(2)
k , need not agree on the marginal distribution of x(2)
j . Extending the notion of rowcolumn exchangeability, each entity x(2)
corresponds to a record whose features are the possible relations
with entities of types E1 and E3. Let F2,1 denote the features corresponding to relations involving entities of
E1, and F2,3 the features corresponding to relations involving entities of E3. If the features are binary, they
indicate whether or not an entity participates in a relation with x(2)
j . The latent representation of x(2)
Vj·, where UV T
j· and Vj·ZT determines the distribution over F2,1 and F2,3 respectively.
2The conference version of the paper contains an erroneous deﬁnition of L1(U, V |W ), which is corrected here.
Parameter Estimation
Equation 3 is convex in any one of its arguments. We extend the alternating projection algorithm for matrix
factorization, ﬁxing all but one argument of L = L(U, V, Z|W, ˜W) and updating the free factor using a
Newton-Raphson step. Diﬀerentiating the loss with respect to each factor:
 f1(UV T ) −X
V + ∇G∗(U),
 f1(UV T ) −X
 f2(V ZT ) −Y
Z + ∇H∗(V ),
∇ZL = (1 −α)
 f2(V ZT ) −Y
V + ∇I∗(Z).
Setting the gradients equal to zero yields update equations for U, V , and Z. Note that the gradient step
does not require the divergence to be decomposable, nor does it require that that the matching losses
be diﬀerentiable; simply replace gradients with subgradients in the prequel. For ℓ2 regularization on U,
G(U) = λ||U||2/2, ∇G∗(U) = U/λ. The gradient for a factor is a linear combination of the gradients with
respect to the individual matrix reconstructions the factor participates in.
A cursory inspection of Equations 4-6 suggests that an Newton step is infeasible. The Hessian with
respect to U would involve nk parameters. However, if L1 and L2 are each decomposable functions, then we
can show that almost all the second derivatives of L with respect to a single factor U are zero. Moreover,
the Newton update for the factors reduces to row-wise optimization of U, V , and Z. For the subclass of
models where Equations 4-6 are diﬀerentiable and the loss is decomposable, deﬁne
q(Ui·) = α
 f1(Ui·V T ) −Xi·
V + ∇G∗(Ui·),
q(Vi·) = α
 f2(Vi·ZT ) −Yi·
Z + ∇H∗(Vi·),
q(Zi·) = (1 −α)
V + ∇I∗(Zi·).
Since all but one factor is ﬁxed, consider the derivatives of q(Ui·) with respect to any scalar parameter in U:
∇Ujsq(Ui·). Because Ujs only appears in q(Ui·) when j = i, the derivative equals zero when j ̸= i. Therefore
the Hessian ∇2
UL is block-diagonal, where each non-zero block corresponds to a row of U. The inverse of a
block-diagonal matrix is the inverse of each block, and so the Newton direction for U, [∇UL][∇2
UL]−1, can
be reduced to updating each row Ui· using the direction [q(Ui·)][q′(Ui·)]−1. The above argument applies to
V and Z as well, since the loss is a sum of per-matrix losses and the derivative is a linear operator.
Any (local) optima of the loss L corresponds to roots of the equations {q(Ui·)}m
i=1, {q(Vi·)}n
i=1. We derive the Newton step for Ui·,
= Ui· −η · q(Ui·)[q′(Ui·)]−1,
where we suggest using the Armijo criterion to set η. To concisely describe the Hessian we introduce
terms for the contribution of the regularizer,
Gi ≡diag(∇2G∗(Ui·)),
Hi ≡diag(∇2H∗(Vi·)),
Ii ≡diag(∇2I∗(Zi·)),
and terms for the contribution of the reconstruction error,
D1,i ≡diag(Wi· ⊙f ′
1(Ui·V T )),
D2,i ≡diag(W·i ⊙f ′
D3,i ≡diag( ˜
D4,i ≡diag( ˜
The Hessians with respect to the loss L are
q′(Ui·) ≡∇q(Ui·) = αV T D1,iV + Gi
q′(Zi·) ≡∇q(Zi·) = (1 −α)V T D4,iV + Ii
q′(Vi·) ≡∇q(Vi·) = αU T D2,iU + (1 −α)ZT D3,iZ + Hi
Each update of U, V , and Z reduces at least one term in Equation 3. Iteratively cycling through the update
leads to a local optima. In practice, we simplify the update by taking one Newton step instead of running
to convergence.
In addition to weighing the importance of reconstructing diﬀerent parts of a matrix, W and ˜W serve other
purposes. First, the data weights can be used to turn the objective into a per-element loss by scaling each
element of X by (nm)−1 and each element of Y by (nr)−1. This ensures that larger matrices do not dominate
the model simply because they are larger. Second, weights can be used to correct for diﬀerences in the scale of
L1(U, V ) and L2(V, Z). If the Bregman divergences are regular, we can use the corresponding log-likelihoods
as a consistent scale. If the Bregman divergences are not regular, computing
DF1(UV T || X, W)/DF2(V ZT || Y, ˜W),
averaged over uniform random parameters U, V , and Z, provides an adequate estimate of the relative scale
of the two losses. A third use of data weights is missing values. If the value of a relation is unobserved, the
corresponding weight is set to zero.
Generalizing to Arbitrary Schemas
The three-factor model generalizes to any pairwise relational schema, where binary relations are represented
as a set of edges: E = {(i, j) : Ei ∼Ej ∧i < j}. Let [U] denote the set of latent factors and [W] the weight
matrices. The loss of the model is
L([U] | [W]) =
DF (ij)(U (i)(U (j))T || X(ij), W (ij))
DG(i)(0 || U (i)),
where F (ij) deﬁnes the loss for a particular reconstruction, and G(i) deﬁnes the loss for a regularizer. The
relative weights α(ij) ≥0 measure the importance of each matrix in the reconstruction. Since the loss is a
linear function of individual losses, and the diﬀerential operator is linear, both gradient and Newton updates
can be derived in a manner analogous to Section 4.1, taking care to distinguish when U (i) acts as a column
factor as opposed to a row factor.
Stochastic Approximation
In optimizing a collective factorization model, we are in the unusual situation that our primary concern is
not the cost of computing the Hessian, but rather the cost of computing the gradient itself: if k is the largest
embedding dimension, then the cost of a gradient update for a row U (i)
j:Ei∼Ej nj), while the cost of
a Newton update for the same row is O(k3 + k2 P
j:Ei∼Ej nj). Typically k is much smaller than the number
of entities, and so the Newton update costs only a factor of k more. (The above calculations assume dense
matrices; for sparsely-observed relations, we can replace nj by the number of entities of type Ej which are
related to entity x(i)
r , but the conclusion remains the same.)
The expensive part of the gradient calculation for U (i)
is to compute the predicted value for each observed
relation that entity x(i)
participates in, so that we can sum all of the weighted prediction errors.
approach to reducing this cost is to compute errors only on a subset of observed relations, picked randomly
at each iteration.
This technique is known as stochastic approximation .
The best-known stochastic
approximation algorithm is stochastic gradient descent; but, since inverting the Hessian is not a signiﬁcant
part of our computational cost, we will recommend a stochastic Newton’s method instead.
Consider the update for Ui· in the three factor model. This update can be viewed as a regression where
the data are Xi· and the features are the columns of V . If we denote a sample of the data as s ⊆{1, . . . , n},
then the sample gradient at iteration τ is
ˆqτ(Ui·) = α
Vs· + ∇G∗(Ui·),
Similarly, given subsets p ⊆{1, . . ., n} and q ⊆{1, . . ., r}, the sample gradients for the other factors are
ˆqτ(Vi·) = α
Zq· + ∇H∗(Vi·),
ˆqτ(Zi·) = (1 −α)
Vs· + ∇I∗(Zi·).
The stochastic gradient update for U at iteration τ is
i· −τ −1ˆqτ(Ui·).
and similarly for the other factors. Note that we use a ﬁxed, decaying sequence of learning rates instead of a
line search: sample estimates of the gradient are not always descent directions. An added advantage of the
ﬁxed schedule over line search is that the latter is computationally expensive.
We sample data non-uniformly, without replacement, from the distribution induced by the data weights.
That is, for a row Ui·, the probability of drawing Xij is Wij/ P
j Wij. This sampling distribution provides a
compelling relational interpretation: to update the latent factors of x(i)
r , we sample only observed relations
involving x(i)
r . For example, to update a user’s latent factors, we sample only movies that the user rated. We
use a separate sample for each row of U: this way, errors are independent from row to row, and their eﬀects
tend to cancel. In practice, this means that our actual training loss decreases at almost every iteration.
With sampling, the cost of the gradient update no longer grows linearly in the number of entities related
r , but only in the number of entities sampled. Another advantage of this approach is that when we
sample one entity at a time, |s| = |p| = |q| = 1, stochastic gradient yields an online algorithm, which need
not store all the data in memory.
As mentioned above, we can often improve the rate of convergence by moving from stochastic gradient
descent to stochastic Newton-Raphson updates . For the three-factor model the stochastic Hessians are
τ(Ui·) = αV T
s· ˆD1,iVs· + Gi,
τ(Zi·) = (1 −α)V T
s· ˆD4,iVs· + Ii,
τ(Vi·) = αU T
p· ˆD2,iUp· + (1 −α)ZT
q· ˆD3,iZq· + Hi.
ˆD1,i ≡diag(Wis ⊙f ′
ˆD2,i ≡diag(Wpi ⊙f ′
ˆD3,i ≡diag( ˜Wiq ⊙f ′
ˆD4,i ≡diag( ˜
To satisfy convergence conditions, which will be discussed in Section 5.1, we use an exponentially weighted
moving average of the Hessian:
¯qτ+1(·) =
When the sample at each step is small compared to the embedding dimension, the Sherman-Morrison-
Woodbury lemma (e.g., ) can be used for eﬃciency.
The stochastic Newton update is analogous to
Equation 7, except that η = 1/τ, the gradient is replaced by its sample estimate ˆq, and the Hessian is
replaced by its sample estimate ¯q.
Convergence
We consider three properties of stochastic Newton, which together are suﬃcient conditions for convergence
to a local optimum of the empirical loss L . These conditions are also satisﬁed by setting the Hessian to
the identity, ¯q(·) = Ik — i.e., stochastic gradient.
Local Convexity: The loss must be locally convex around its minimum, which must be contained in its domain.
In alternating projections the loss is convex for any Bregman divergence; and, for regular divergences, has
R as its domain. The non-regular divergences we consider, such as Hinge loss, also satisfy this property.
Uniformly Bounded Hessian: The eigenvalues of the sample Hessians are bounded in some interval [−c, c]
with probability 1.
This condition is satisﬁed by testing whether the condition number of the sample
Hessian is below a large ﬁxed value, i.e., the Hessian is invertible. Using the ℓ2 regularizer always yields an
instantaneous Hessian ˆq that is full rank. The eigenvalue condition implies that the elements of ¯q and its
inverse are uniformly bounded.
Convergence of the Hessian: There are two choices of convergence criteria for the Hessian. Either one suﬃces
for proving convergence of stochastic Newton. (i) The sequence of inverses of the sample Hessian converges
in probability to the true Hessian: limτ→∞(¯qτ)−1 = (q′)−1. Alternately, (ii) the perturbation of the sample
Hessian from its mean is bounded. Let Pτ−1 consist of the history of the stochastic Newton iterations: the
data samples and the parameters for the ﬁrst τ −1 iterations. Let gτ = os(fτ) denote an almost uniformly
bounded stochastic order of magnitude. The stochastic o-notation is similar to regular o-notation, except
that we are allowed to ignore measure-zero events and E[os(fτ)] = fτ. The alternate convergence criteria is
a concentration of measure statement:
E[¯qτ|Pτ−1] = ¯qτ + os(1/τ).
For Equation 8 this condition is easy to verify:
E[¯qτ|Pτ−1] =
since Pτ−1 contains ¯qτ−1. Any perturbation from the mean is due to the second term. If ˆq is invertible then
its elements are uniformly bounded, and so are the elements of E[ˆqτ|Pτ−1]; since this term has bounded
elements and is scaled by 2/τ, the perturbation is os(1/τ). One may fold in an instantaneous Hessian that
is not invertible, so long as the moving average ¯q remains invertible. The above proves the convergence of a
factor to the value which minimizes the expected loss, assuming the other factors are ﬁxed. With respect to
the alternating projection, we only have convergence to a local optima of the empirical loss L.
Related Work
Collective matrix factorization provides a uniﬁed view of matrix factorization for relational data: diﬀerent
methods correspond to diﬀerent distributional assumptions on individual matrices, diﬀerent schemas tying
factors together, and diﬀerent optimization procedures. We distinguish our work from prior methods on
three points: (i) competing methods often impose a clustering constraint, whereas we cover both cluster and
factor analysis (although our experiments focus on factor analysis); (ii) our stochastic Newton method lets
us handle large, sparsely observed relations by taking advantage of decomposability of the loss; and (iii) our
presentation is more general, covering a wider variety of models, schemas, and losses. In particular, for (iii),
our model emphasizes that there is little diﬀerence between factoring two matrices versus three or more;
and, our optimization procedure can use any twice diﬀerentiable decomposable loss, including the important
class of Bregman divergences. For example, if we restrict our model to a single relation E1 ∼E2, we can
recover all of the single-matrix models mentioned in Sec. 2.2. While our alternating projections approach is
conceptually simple, and allows one to take advantage of decomposability, there is a panoply of alternatives
for factoring a single matrix. The more popular ones includes majorization , which iteratively minimize
a sequence of convex upper bounding functions tangent to the objective, including the multiplicative update
for NMF and the EM algorithm, which is used both for pLSI and weighted SVD .
optimization solves the non-convex problem with respect to (U, V ) using gradient or second-order methods,
such as the fast variant of max-margin matrix factorization .
The next level of generality is a three-entity-type model E1 ∼E2 ∼E3.
A well-known example of
such a schema is pLSI-pHITS , which models document-word counts and document-document citations:
E1 = words and E2 = E3 = documents, but it is trivial to allow E2 ̸= E3. Given relations E1 ∼E2 and E2 ∼E3,
with corresponding integer relationship matrices X(12) and X(23), the likelihood is
L = αX(12) ◦log
+ (1 −α)X(23) ◦log
where the parameters U, V , and Z correspond to probabilities uik = p(x(1)
| hk), vik = p(hk | x(2)
zik = p(x(3)
| hk) for clusters {h1, . . . , hK}. Probability constraints require that each column of U, V T ,
and Z must sum to one, which induces a clustering of entities. Since diﬀerent entities can participate in
diﬀerent numbers of relations (e.g., some words are more common than others) the data matrices X(12)
and X(23) are usually normalized; we can encode this normalization using weight matrices. The objective,
Equation 9, is the weighted average of two probabilistic LSI models with shared latent factors hk. Since
each pLSI model is a one-matrix example of our general model, the two-matrix version can be placed within
our framework.
Matrix co-clustering techniques have a stochastic constraint: if an entity increases its membership in
one cluster, it must decrease its membership in others clusters.
Examples of matrix and relational coclustering include pLSI, pLSI-pHITS, the symmetric block models of Long et. al. , and Bregman
tensor clustering (which can handle higher arity relations). Matrix analogues of factor analysis place no
stochastic constraint on the parameters. Collective matrix factorization has been presented using matrix
factor analyzers, but the stochastic constraint, that each row of U (r) sums to 1, distributes over the alternating
projection to an equality constraint on each update of U (r)
i· . This additional equality constraint can be folded
into the Newton step using a Lagrange multiplier, yielding an unconstrained optimization (c.f., ch. 10 ).
Comparing the extension of collective matrix factorization to the alternatives above is a topic for future
work. It should be noted that our choice of X = UV T is not the only one for matrix factorization. Long
et. al. proposes a symmetric block model X ≈C1ACT
2 , where C1 ∈{0, 1}n1×k and C2 ∈{0, 1}n2×k are
cluster indicator matrices, and A ∈Rk×k contains the predicted output for each combination of row and
column clusters. Early work on this model uses a spectral relaxation speciﬁc to squared loss , while later
generalizations to regular exponential families use EM. An equivalent formulation in terms of regular
Bregman divergences uses iterative majorization as the inner loop of alternating projection. An
improvement on Bregman co-clustering accounts for systematic biases, block eﬀects, in the matrix .
The three-factor schema E1 ∼E2 ∼E3 also includes supervised matrix factorization. In this problem,
the goal is to classify entities of type E2: matrix X(12) contains class labels according to one or more related
concepts (one concept per row), while X(23) lists the features of each entity. An example of a supervised
matrix factorization algorithm is the support vector decomposition machine : in SVDMs, the features
X(23) are factored under squared loss, while the labels X(12) are factored under Hinge loss. A similar model
was proposed by Zhu et al. , using a once-diﬀerentiable variant of the Hinge loss. Another example is
supervised LSI , which factors both the data and label matrices under squared loss, with an orthogonality
constraint on the shared factors. Principal components analysis, which factors a doubly centered matrix
under squared loss, has also been extended to the three-factor schema .
Another interesting type of schema contains multiple parallel relations between two entity types. An
example of this sort of schema is max-margin matrix factorization (MMMF) . In MMMF, the goal is
to predict ordinal values, such as a user’s rating of movies on a scale of {1, . . ., R}. We can reduce this
prediction task to a set of binary threshold problems, namely, predicting r ≥1, r ≥2, . . . , r ≥R. If we
use a Hinge loss for each of these binary predictions and add the losses together, the result is equivalent
to a collective matrix factorization where E1 are users, E2 are movies, and E1 ∼u E2 for u = 1 . . . R are the
binary rating prediction tasks. In order to predict diﬀerent values for the R diﬀerent relations, we need to
allow the latent factors U (1) and U (2) to contain some untied columns, i.e., columns which are not shared
among relations. For example, the MMMF authors have suggested adding a bias term for each rating level
or for each (user, rating level) pair. To get a bias for each (user, rating level) pair, we can append R untied
columns to U (1), and have each of these columns multiply a ﬁxed column of ones in U (2). To get a shared
bias for each rating level, we can do the same, but constrain each of the untied columns in U (1) to be a
multiple of the all-ones vector.
Experiments
Movie Rating Prediction
Our experiments focus on two tasks: (i) predicting whether a user rated a particular movie: israted; and
(ii) predicting the value of a rating for a particular movie: rating. User ratings are sampled from the Netﬂix
Prize data : a rating can be viewed as a relation taking on ﬁve ordinal values (1-5 stars), i.e., Rating(user,
movie). We augment these ratings with two additional sources of movie information, from the Internet Movie
Database : genres for each movie, encoded as a binary relation, i.e., HasGenre(movie, genre); and a list
of actors in each movie, encoded as a binary relation, i.e., HasRole(actor, movie). In schema notation E1
corresponds to users, E2 corresponds to movies, E3 corresponds to genres, and E4 corresponds to actors.
Ordinal ratings are denoted E1 ∼1 E2; for the israted task the binarized version of the ratings is denoted
E1 ∼2 E2. Genre membership is denoted E2 ∼E3. The role relation is E2 ∼E4.
There is a signiﬁcant diﬀerence in the amount of data for the two tasks. In the israted problem we know
whether or not a user rated a movie for all combinations of users and movies, so the ratings matrix has no
missing values. In the rating problem we observe the relation only when a user rated a movie—unobserved
combinations of users and movies have their data weight set to zero.
Model and Optimization Parameters
For consistency, we control many of the model and optimization parameters across the experiments. In the
israted task all the relations are binary, so we use a logistic model: sigmoid link with the matching log-loss.
To evaluate test error we use mean absolute error (MAE) for both tasks, which is the average zero-one loss
for binary predictions. Since the data for israted is highly imbalanced in favour of movies not being rated,
we scale the weight of those entries down by the fraction of observed relations where the relation is true.
We use ℓ2 regularization throughout. Unless otherwise stated the regularizers are all G(U) = 105||U||2
In Newton steps, we use an Armijo line search, rejecting updates with step length smaller than η = 2−4.
In Newton steps, we run till the change in training loss falls below 5% of the objective. Using stochastic
Newton, we run for a ﬁxed number of iterations.
Relations Improve Predictions
Our claim regarding relational data is that collective factorization yields better predictions than using a
single matrix. We consider the israted task on two relatively small data sets, to allow for repeated trials.
Since this task involves a three factor model there is a single mixing factor, α in Equation 3. We learn a
model for several values of α, starting from the same initial random parameters, using full Newton steps.
The performance on a test set, entries sampled from the matrices according to the test weights, is measured
at each α. Each trial is repeated ten times to provide 1-standard deviation error bars.
Two scenarios are considered. First, where the users and movies were sampled uniformly at random;
all genres that occur in more than 1% of the movies are retained. We only use the users’ ratings on the
Test Loss −− X
(a) Ratings
Test Loss −− Y
(b) Genres
Figure 1: Test errors (MAE) for predicting whether a movie was rated, and the genre, on the dense rating
sampled movies. Second, where we only sample users that rated at most 40 movies, which greatly reduces
the number of ratings for each user and each movie. In the ﬁrst case, the median number of ratings per user
is 60 (the mean, 127); in the second case, the median number of ratings per user is 9 (the mean, 10). In
the ﬁrst case, the median number of ratings per movie is 9 (the mean, 21); in the second case, the median
number of ratings per movie is 2 (the mean, 8). In the ﬁrst case we have n1 = 500 users and n2 = 3000
movies and in the second case we have n1 = 750 users and n2 = 1000 movies. We use a k = 20 embedding
dimension for both matrices.
The dense rating scenario, Figure 1, shows that collective matrix factorization improves both prediction
tasks: whether a user rated a movie, and which genres a movie belongs to. When α = 1 the model uses only
rating information; when α = 0 it uses only genre information.
In the sparse rating scenario, Figure 2, there is far less information in the ratings matrix.
movies are rated by only one or two users. Because there is so little information between users, the extra
genre information is more valuable. However, since few users rate the same movies there is no signiﬁcant
improvement in genre prediction.
We hypothesized that adding in the roles of popular actors, in addition to genres, would further improve
performance. By symmetry the update equation for the actor factor is analogous to the update for the genre
factor. Since there are over 100,000 actors in our data, most of which appear in only one or two movies, we
selected 500 popular actors (those that appeared in more than ten movies). Under a wide variety of settings
for the mixing parameters {α(12), α(23), α(24)} there was no statistically signiﬁcant improvement on either
the israted or rating task.
Stochastic Approximation
Our claim regarding stochastic optimization is that it provides an eﬃcient alternative to Newton updates
in the alternating projections algorithm. Since our interest is in the case with a large number of observed
relations we use the israted task with genres. There are n1 = 10000 users, n2 = 2000 movies, and n3 = 22
of the most common genres in the data set. The mixing coeﬃcient is α = 0.5. We set the embedding
dimension of both factorizations to k = 30.
On this three factor problem we learn a collective matrix factorization using both Newton and stochastic
Newton methods with batch sizes of 25, 75, and 100 samples per row. The batch size is larger than the
Test Loss −− X
(a) Ratings
Test Loss −− Y
(b) Genres
Figure 2: Test errors (MAE) for predicting whether a movie was rated, and the genre, on sparse rating
number of genres, and so they are all used. Our primary concern is sampling the larger user-movie matrix.
Using Newton steps ten cycles of alternating projection are used; using stochastic Newton steps thirty cycles
are used. After each cycle, we measure the training loss (log-loss) and the test error (mean absolute error),
which are plotted against the CPU time required to reach the given cycle in Figure 3. This experiment was
repeated ﬁve times, yielding 2-standard deviation error bars.
Using only a small fraction of the data we achieve results comparable to full Newton after ﬁve iterations.
At batch size 100, we are sampling 1% of the users and 5% of the movies; yet its performance on test data
is the same as a full Newton step given 8x longer to run. Diminishing returns with respect to batch size
suggests that using very large batches is unnecessary. Even if the batch size were equal to max{n1, n2, n3}
stochastic Newton would not return the same result as full Newton due to the 1/τ damping factor on the
sample Hessian.
It should be noted that rating is a computationally simpler problem. On a three factor problem with
n1 = 100000 users, n2 = 5000 movies, and n3 = 21 genres, with over 1.3M observed ratings, alternating
projection with full Newton steps runs to convergence in 32 minutes on a single 1.6 GHz CPU. We use a
small embedding dimension, k = 20, but one can exploit common tricks for large Hessians. We used the
Poisson link for ratings, and the logistic for genres; convergence is typically faster under the identity link.
Comparison to pLSI-pHITS
In this section we provide an example where the additional ﬂexibility of collective matrix factorization leads
to better results; and another where a co-clustering model, pLSI-pHITS, has the advantage.
We sample two instances of israted, controlling for the number of ratings each movie has. In the dense
data set, the median number of ratings per movie (user) is 11 (76); in the sparse data set, the median number
of ratings per movie (user) is 2 (4). In both cases there are 1000 randomly selected users, and 4975 randomly
selected movies, all the movies in the dense data set.
Since pLSI-pHITS is a co-clustering method, and our collective matrix factorization model is a link
prediction method, we choose a measure that favours neither inherently: ranking. We induce a ranking of
movies for each user, measuring the quality of the ranking using mean average precision (MAP) : queries
correspond to user’s requests for ratings, “relevant” items are the movies of the held-out links, we use only
CPU Time (s)
Training Error
Stochastic Newton (batch = 25)
Stochastic Newton (batch = 75)
Stochastic Newton (batch = 100)
(a) Training Loss (Log-loss)
CPU Time (s)
Test Error
Stochastic Newton (batch = 25)
Stochastic Newton (batch = 75)
Stochastic Newton (batch = 100)
(b) Test Error (MAE)
Figure 3: Behaviour of Newton vs. Stochastic Newton on a three-factor model.
the top 200 movies in each ranking3, and the averaging is over users. Most movies are unrated by any given
user, and so relevance is available only for a fraction of the items: the absolute MAP values will be small,
but relative diﬀerences are meaningful. We compare four diﬀerent models for generating rankings of movies
for users:
CMF-Identity: Collective matrix factorization using identity prediction links, f1(θ) = f2(θ) = θ and
squared loss. Full Newton steps are used. The regularization and optimization parameters are the same as
those described in Section 7.1.1, except that the smallest step length is η = 2−5. The ranking of movies for
user i is induced by f(Ui·V T ).
CMF-Logistic: Like CMF-Identity, except that the matching link and loss correspond to a Bernoulli
distribution, as in logistic regression: f1(θ) = f2(θ) = 1/(1 + exp−θ).
pLSI-pHITS: Makes a multinomial assumption on each matrix, which is somewhat unnatural for the
rating task—a rating of 5 stars does not mean that a user and movie participated in the rating relation
ﬁve times. Hence our use of israted. We give the regularization advantage to pLSI-pHITS. The amount of
regularization β ∈ is chosen at each iteration using tempered EM. The smaller β is, the stronger the
parameter smoothing towards the uniform distribution. We are also more careful about setting β than Cohn
et. al. , using a decay rate of 0.95 and minimum β of 0.7. To have a consistent interpretation of iterations
between this method and CMF, we use tempering to choose the amount of regularization, and then ﬁt the
parameters from a random starting point with the best choice of β. Movie rankings are generated using
p(movie|user).
Pop: A baseline method that ignores the genre information. It generates a single ranking of movies, in order
of how frequently they are rated, for all users.
In each case the models, save popularity ranking, have embedding dimension k = 30 and run for at most
10 iterations.
We compare on a variety of values of α, but we make no claim that mixing information
improves the quality of rankings. Since α is a free parameter we want to conﬁrm the relative performance
of these methods at several values. In Figure 4, collective matrix factorization signiﬁcantly outperforms
pLSI-pHITS on the dense data set; the converse is true on the sparse data set. Ratings do not beneﬁt from
mixing information in any of the approaches, on either data set. While the ﬂexibility of collective matrix
factorization has its advantages, especially computational ones, we do not claim unequivocal superiority over
3The relations between the curves in Figure 4 are the same if the rankings are not truncated.
Mean Average Precision
CMF−Identity
CMF−Logistic
pLSI−pHITS
Mean Average Precision
CMF−Identity
CMF−Logistic
pLSI−pHITS
(b) Sparse
Figure 4: Ranking movies for users on a data set where each movie has many ratings (dense) or only a
handful (sparse). The methods are described in Section 7.4. Errors bars are 1-standard deviation.
relational models based on matrix co-clustering.
Contributions
We present a uniﬁed view of matrix factorization, building on it to provide collective matrix factorization as
a model of pairwise relational data. Experimental evidence suggests that mixing information from multiple
relations leads to better predictions in our approach, which complements the same observation made in
relational co-clustering . Under the common assumption of a decomposable, twice diﬀerentiable loss, we
derive a full Newton step in an alternating projection framework. This is practical on relational domains
with hundreds of thousands of entities and millions of observations.
We present a novel application of
stochastic approximation to collective matrix factorization, which allows one handle even larger matrices
using a sampled approximation to the gradient and Hessian, with provable convergence and a fast rate of
convergence in practice.
Acknowledgements
The authors thank Jon Ostlund for his assistance in merging the Netﬂix and IMDB data. This research was
funded in part by a grant from DARPA’s RADAR program (NBCHD030010). The opinions and conclusions
are the authors’ alone.