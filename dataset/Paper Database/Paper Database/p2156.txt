Steel Defect Classiﬁcation with
Max-Pooling Convolutional Neural Networks
Jonathan Masci, Ueli Meier, Dan Ciresan,
J¨urgen Schmidhuber
IDSIA, USI and SUPSI
Galleria 2, 6928 Manno-Lugano,
Switzerland
{jonathan, ueli, dan, juergen}@idsia.ch
Gabriel Fricout
Arcelor Mittal
Maizi`eres Research SA,
{ }
Abstract—We present a Max-Pooling Convolutional Neural
Network approach for supervised steel defect classiﬁcation. On a
classiﬁcation task with 7 defects, collected from a real production
line, an error rate of 7% is obtained. Compared to SVM
classiﬁers trained on commonly used feature descriptors our best
net performs at least two times better. Not only we do obtain
much better results, but the proposed method also works directly
on raw pixel intensities of detected and segmented steel defects,
avoiding further time consuming and hard to optimize ad-hoc
preprocessing.
I. INTRODUCTION
Machine vision based surface inspection technologies have
gained a lot of interest from various industries to automate inspection systems, and to signiﬁcantly improve overall product
quality. A typical industry adopting these reﬁned inspection
tools is the rolled steel strip market. Real-time visual inspection of production lines is crucial to provide a product with
ever fewer surface defects. Manual inspection, even though
really accurate in case of few samples, is slow and prone
to fatigue induced errors in high speed modern setups. This
results in many additional costs which make this approach not
only too expensive but also inapplicable. Automated machine
vision inspection, one of the most investigated areas in the ﬁeld
of quality control, is fast and reliable achieving satisfactory
results in many cases.
Combined developments in camera technologies, acquisition
hardware and machine learning algorithms offer the required
tools to meet speed, resolution and classiﬁcation demands of
current production lines. Even with the proper equipment and
most advanced algorithms the problem of steel defect detection
and classiﬁcation remains non-trivial. Further improvements
based on expert knowledge encoded in geometrical and shapebased features are difﬁcult to achieve. A successful inspection
algorithm should adaptively learn according to the changing
data distribution, especially in modern dynamic processes
where the production shifts from a product to another very
quickly. On the other hand, all the expert knowledge and effort
put in hand-crafted feature extraction is valuable and should
complement any novel inspection algorithm.
A standard inspection system is coarsely divided in three
main stages: image acquisition, feature extraction, and classiﬁcation. The system is usually based on a set of handwired pipelines with partial or no self-adjustable parameters
which makes the ﬁne-tuning process of this industrial systems
cumbersome, requiring much more human intervention than
desired. In this work we focus on the two last pipeline stages
and propose an approach based on Max-Pooling Convolutional
Neural Networks (MPCNN) , , , , , that learn
the features directly from labeled images using supervised
learning. We show that the proposed method achieves stateof-the-art results on real world data and compare our approach
to classiﬁers trained on classic feature descriptors.
There is not much literature about steel defect detection
 . However, in a broader context the problem can be
viewed as defect detection in textured material which has
received considerable attention in computer vision , ,
 . In classical approaches, feature extraction is performed
using the ﬁlter-bank paradigm, resulting in an architecture
very similar to a MPCNN. Each image is convolved with
a set of two-dimensional ﬁlters, whose structure and support
come from prior knowledge about the task, and the result of
the convolutions (ﬁlter responses) is later used by standard
classiﬁers. A popular choice for the two-dimensional ﬁlters
are Gabor-Wavelets that offer many interesting properties
and have been successfully applied for defect detection in
textured materials in general , for textile ﬂaw detection
 and face recognition in particular. While being a
very powerful technique, it has many drawbacks. First of all
it is inherently a single layer architecture whereas deep multilayer architectures are capable of extracting more powerful
features . Furthermore, the ﬁlter response vector after the
ﬁrst layer is high dimensional and requires further processing
to be handled in real time/memory bounded systems.
The rest of the paper is organized as follows. We ﬁrst review
classical feature extraction methods and introduce the neural
network framework. We then describe the data set and show
results from the various experiments we performed.
II. RELATED WORK
When it comes to texture related descriptors the amount of
available techniques is quite large, to say the least, making
the selection process cumbersome and not easy to optimize
U.S. Government work not protected by U.S. copyright
WCCI 2012 IEEE World Congress on Computational Intelligence
June, 10-15, 2012 - Brisbane, Australia
for various products. Here we summarize the most notable
descriptors which have been used in a similar context and
compare them later on with our MPCNN approach.
• Local Binary Patterns (LBP) : is an operator that
focuses on the spatial structure of grey-level texture. For
each pixel, the method takes a surrounding neighborhood
and creates a binary descriptor which is intensity and rotation invariant based on the signs of differences between
neighboring pixels.
• Local Binary Pattern Histogram Fourier (LBP-HF) :
is a rotation invariant descriptor computed from discrete
Fourier transforms of LBP. The rotation invariance is
computed on the histogram of non-invariant LBP, hence
the rotation invariance is attained globally. The resulting
features are invariant to rotations of the whole input signal
but still retain information about the relative distribution
of different orientations of uniform local binary patterns.
• Monogenic-LBP : integrates the traditional Local
Binary Pattern (LBP) operator with the other two rotation
invariant measures, the local phase and the local surface
type are computed by the 1st- and 2nd-order Riesz
transforms.
• Rotation invariant measure of local variance (VAR) :
is a descriptor which is not gray-scale invariant as LBP
but incorporates information about the contrast of local
image texture. VAR in conjunction with LBP makes a
very powerful rotation invariant descriptor of local image
• Histogram of Oriented Gradients (HOG) : is a
method based on evaluating normalized local histograms
of image gradient orientations in a dense grid. The basic
idea is that local object appearance and shape can often
be characterized rather well by the distribution of local
intensity gradients or edge directions.
Histograms
Orientation
(PHOG) : is an extension of the HOG descriptor
that also considers the spatial locality of the descriptor’s
constituents.
III. MAX-POOLING CONVOLUTIONAL NEURAL
NETWORKS (MPCNN)
Convolutional Neural Networks (CNN) are hierarchical
models alternating two basic operations, convolution and subsampling, reminiscent of simple and complex cells in the
primary visual cortex . As CNN share weights, the number
of free parameters does not grow proportionally with the input
dimensions as in standard multi-layer networks. Therefore
CNN scale well to real-sized images and excel in many object
recognition benchmarks , , . A CNN as depicted
in Figure 1, consists of several basic building blocks brieﬂy
explained here:
• Convolutional Layer: performs a 2D ﬁltering between
input images x and a bank of ﬁlters w, producing
another set of images h. A connection table CT indicates
the input-output correspondences, ﬁlter responses from
inputs connected to the same output image are linearly
combined. Each row in CT is a connection and has the
following semantic: (inputImage, ﬁlterId, outputImage).
This layer performs following mapping
i,k∈CTi,k,j
where ∗indicates the 2D valid convolution. Each ﬁlter
wk of a particular layer has the same size and deﬁnes,
together with the size of the input, the size of the output
images hj. Then, a non-linear activation function (e.g.
tanh, logistic, etc.) is applied to h just as for standard
multi-layer networks.
• Pooling Layer: reduces the dimensionality of the input
by a constant factor. The scope of this layer is not
only to reduce the computational burden, but also to
perform feature selection. The input images are tiled in
non overlapping subregions from which only one output
value is extracted. Common choices are maxima or average, usually shortened as Max-Pooling and Avg-Pooling.
MaxPooling is generally favorable as it introduces small
invariance to translation and distortion, leads to faster
convergence and better generalization . In this paper
we will use only this kind of subsampling layer and hence
the name MPCNN.
• Fully Connected Layer: this is the standard layer of
a multi-layer network. Performs a linear combination
of the input vector with a weight matrix. Either the
network alternates convolutional and max-pooling layers
such that at some stage a 1D feature vector is obtained
(images of 1×1), or the resulting images are rearranged
to have 1D shape. The output layer is always a fully
connected layer with as many neurons as classes in the
classiﬁcation task. The outputs are normalized with a
softmax activation function and therefore approximate
posterior class probabilities.
A schematic representation of a Max-Pooling Convolutional Neural
Network. Convolutional layers and max-pooling layers are stacked until the
fully connected layers used for classiﬁcation start.
A. Training Procedure
As for any supervised architecture the network is trained to
predict the correct label for a given input pattern, minimizing
the misclassiﬁcation error over a set of labeled examples (i.e.
the training set). Using the back-propagation algorithm 
the gradient of the error function with respect to the adjustable
parameters of the MPCNN is efﬁciently obtained, and any
gradient based optimization algorithm can then be used. In
general however, due to the highly non-linear nature of the
error surface, a stochastic gradient descent procedure is preferred as it usually avoids being stuck in poor local minima.
For all experiments we anneal the learning rate and update the
weights after each sample. A learning epoch is complete when
all the samples of the training set have been visited once. Note
that random permutation of the samples prior to each epoch
is very important to obtain i.i.d patterns.
The error back-propagation for a convolutional layer is
k,j∈CTi,k,j
where ∗indicates the 2D full correlation, equivalent to a
convolution with a kernel ﬂipped along both axes. The gradient
is computed as
∇wk = xi ∗δj
where in this case ∗indicates the 2D valid convolution. In
equation 3 there is no summation as each kernel is only used
once, there are no multiple images sharing the same kernel.
IV. DATASET
The experiments are performed on data collected on an
actual production line. The dataset is composed of a subset of 7
defects, chosen because of their intra-class variabilities which
makes learning difﬁcult. In ﬁgure 2 two instances of the same
defect are shown to illustrate the intraclass variability of this
data. The images come in big patches with the detected region
of interest that the segmentation stage produces. This stage can
obviously miss the defect and create false alarms. In this study
we do not consider errors from the detection/segmentation
pipeline and consider each segmented region of interest as
a correctly labeled sample. This implies that in addition to
high intraclass variability the classiﬁcation algorithm also has
to deal with false positives in the training set.
Two instances of the same defect class.
Contrary to classical machine vision approaches where there
are no constraints on the input dimensions for the feature
extraction stage, MPCNNs need a constant sized input as
they perform feature extraction and classiﬁcation jointly. We
therefore resize all the defects, preserving the aspect ratio and
minimizing the overall down/up-sampling rate according to the
distribution of image dimension over the training set (ﬁgure 3).
Dimension distribution on the training set
Each point corresponds to the width and height of an image from the
training set, histograms of the width and height distribution are also shown.
We decide to resize the images to 150×150 pixels, padding
with surrounding pixels in the smaller patch whenever necessary. If the region of interest is smaller than the target size
we take surrounding pixels with no rescaling; otherwise we
downsample the bigger patches. In ﬁgure 4 a sample from
each of the 7 defects detected on the superior (ﬁrst row) as
well as on the inferior (second row) part of the steel strip is
shown. There is no correspondence between defects from the
superior and inferior part, and no additional information can
be extracted as each image is considered as an independent
sample of a particular defect. In total the training set consists
of 2281 images and the test set consists of 646 images.
In classical approaches, a histogram of the features is
created in order to obtain a constant sized feature vector used
for classiﬁcation. For all experiments using classical feature
extraction techniques we adopt this approach. We keep the
original images avoiding artifacts that might ruin the quality
of the features. For example, if a defect covered only 10% of
the image and we zero-padded, the resulting histogram would
almost be ﬂat and the actual information regarding the defect
would be lost.
V. RESULTS
A. Standard Features
For each of the standard features we tested, the code
provided by the respective authors was used, so a margin of
improvement might be achieved by ﬁne tuning the parameters.
For LBP we combine rotation invariant and non rotation invariant features by simple concatenation the two feature vectors.
As always, prior knowledge and experience are important, but
ﬁne tuning the parameters of the feature extraction is usually
harder than for MPCNNs, especially for LBP which depends
on many parameters and is available in many variants.
A sample from each of the seven defects in the dataset. First row: superior part of the strip; second row: inferior part of the strip. There is no
correspondence between the two images for a given instance of the defect.
The extracted features, which are histograms, are locally
normalized between 0 and 1 and then fed to a classiﬁer.
We opt for a multi-layer perceptron (MLP) just as for the
MPCNN, where the last to layers are an MLP. It is also easier
to extract values that can afterwards be interpreted as posterior
probabilities (see section V-C). We used a single layer architecture with 100 hidden nodes 1, number of inputs given by
the dimensionality of a given feature representation and tanh
activation function; training is performed for a total of 300
epochs. The output layer has 7 neurons, one for each defect
class, that are normalized with a softmax activation function.
We also tested a SVM with RBF-kernel, whose kernel parameter γ and penalty term C are optimized over following grid:
γ = [2−15, 2−13, ..., 23] and C = [2−5, 2−3, ..., 215] by a 5fold cross-validation. Results for both classiﬁers are shown in
CLASSIFICATION ERRORS FOR A MLP/SVM TRAINED ON THE
HISTOGRAMS GENERATED BY CLASSICAL FEATURES.
Feature (#Dims)
LBP-HF (76)
MONO-LBP (540)
VAR (10000)
PHOG (680)
We train two different architectures with stochastic gradient
descent and annealed learning rate. We perform experiments
with and without random translation of max. ±15% of the
image size. Since no padding region is used, border effects
arise. In order to minimize these we opt for the simplest
solution, and assign to each unknown pixel the intensity of
the closest pixel with respect to the euclidean distance. This
may introduce problems when a defect is close to the border
1We also tested MLPs with more hidden units and an additional hidden
layer with no considerable improvement.
as it might possibly disappear due to the translation factor.
Training stops when either the validation error becomes 0, the
learning rate reaches its predeﬁned minimum or there is no
improvement on the validation set for 50 consecutive epochs.
The undistorted, original training set is used as validation set
to cope with the limited amount of valuable labeled training
data. A GPU implementation of a MPCNN is used to speed
up training, on a GeForce GTX 460 one training epoch takes
about 90s, a speed-up of 20-40 (depending on the network
topology) with respect to an optimized CPU implementation.
The ﬁrst architecture has 5 hidden layers, a convolutional
layer with 50 maps and ﬁlters of size 19×19, a max-pooling
layer of size 4×4, a convolutional layer with 100 maps and
ﬁlters of size 13×13, a max-pooling layer of size 3×3, a fully
connected layer with 100 neurons, a fully connected layer with
7 output classes (5HL-MPCNN). The second architecture has 7
hidden layers, a convolutional layer with 50 maps and ﬁlters of
size 11×11, a max-pooling layer of size 4×4, a convolutional
layer with 100 maps and ﬁlters of size 6×6, a max-pooling
layer of size 3×3, a convolutional layer with 150 maps and
ﬁlters of size 5×5, a max-pooling layer of size 3×3, a fully
connected layer with 100 neurons, a fully connected layer with
7 output classes (7HL-MPCNN).
Classiﬁcation error for training and test set are shown for
both architectures trained for 50 epochs with and without
translation. All layers of the nets in Tab. II have been trained
whereas the ﬁrst layer for the nets in Tab. III was kept ﬁxed
during the learning process. That is the ﬁrst convolutional layer
performs random ﬁltering, reducing number of free parameters and hence training time without degrading classiﬁcation
performance. As a matter of fact it even improves generalization when no translations are used . Each experiment is
repeated ﬁve times with different random initializations, since
any iterative gradient based optimization technique depends
on the starting model. The deeper net yields better results and
translating images prior to training by a maximal amount of
15% further increases performance. The additional translations
serve as a regularizer and improve generalization capabilities
of the trained nets to the unseen test data (i.e. a translated
image of a particular defect, still belongs the same defect)
especially when the amount of training data is scarce. All
the MPCNN yield lower error rates than any of the feature
based classiﬁers (Tab. I). The best 7HL-MPCNN with an error
rate of 6.97% with and 8.20% without translations clearly
outperforms the best feature based classiﬁer, PHOG with an
error of 15.48%. This illustrates the power and potential of
the proposed architecture, for defect classiﬁcation in textured
materials.
CLASSIFICATION RESULTS FOR TWO DIFFERENT MPCNN
ARCHITECTURES TRAINED FOR 5 INDEPENDENT INITIALIZATIONS
(RUN1-5) WITH AND WITHOUT 15% TRANSLATION, ALL LAYERS ARE
15% Trans.
15% Trans.
CLASSIFICATION RESULTS FOR TWO DIFFERENT MPCNN
ARCHITECTURES TRAINED FOR 5 INDEPENDENT INITIALIZATIONS
(RUN1-5) WITH AND WITHOUT 15% TRANSLATION, FIRST
CONVOLUTIONAL LAYER IS NOT TRAINED.
15% Trans.
15% Trans.
In Figure 5-left the confusion matrix of the best MPCNN
from Tab. III is shown, where the rows represent the true
classes and the columns the predicted classes. On the diagonal
the per class percentage of correctly classiﬁed samples is
shown, all off-diagonal entries in each row correspond to the
wrongly classiﬁed samples for a particular class. For example,
14% (ﬁrst entry in row 6) of samples from defect class 6 are
wrongly classiﬁed as class 0.
DETAILED NETWORKS STRUCTURE. THE TIME PER SAMPLE REFERS TO
THE TIME REQUIRED FOR A TRAINED NETWORK TO PRODUCE THE CLASS
PREDICTION.
#parameters
#connections
time per sample
C. Committee of classiﬁers
Combining the output of several classiﬁers is an easy and
effective way of boosting the performance. If the errors of
different classiﬁers have zero mean and are uncorrelated with
each other, then the average error might be reduced by a factor
of M simply by averaging the output of the M models .
In practice, error of models trained on similar data tends to
be highly correlated. To avoid this problem predictions of
various classiﬁers trained on differently normalized data can
be combined . Along similar lines the same classiﬁer can
be trained on random subsets of the training set (bootstrap aggregation technique ), or different types of classiﬁers can
be trained on the same data . Here we combine classiﬁers
trained on different features, harnessing the complementary
information content of the various feature descriptors.
In Table V the results of the three best committees out
of all possible committees with at least 2 out of the 6
classiﬁers trained on the 6 different feature descriptors. The
best committee decreased the error rate by 5% with respect
to the best single classiﬁer. Note, however, that even the three
best committees have a much bigger error rate compared to the
MPCNN (Tabs. II, III). In Figure 5 we clearly see that using
a committee of classiﬁers considerably boosts the recognition
rate (compare middle and right matrices). We can also see
that a simple MPCNN performs always better in the per-class
evaluation (diagonal values) except for defect number 2 where
a committee reaches almost perfect accuracy.
CLASSIFICATION RESULTS FOR THE TOP-3 COMMITTEES OF MLPS
TRAINED ON THE HISTOGRAM GENERATED BY CLASSICAL FEATURES. WE
TAKE THE BEST COMBINATION EVALUATED ON THE TRAINING SET. NOTE
THE CONSIDERABLE IMPROVEMENT OVER A CONVENTIONAL SINGLE
CLASSIFIER APPROACH (SEE TABLE I)
Best Combination
HOG, PHOG, LBP-HF
LBP, HOG, PHOG
PHOG, MONO-LBP
ALL FEATURES
VI. CONCLUSIONS
We presented a steel defect classiﬁcation approach based on
Max-Pooling Convolutional Neural Networks which is able to
perform supervised feature extraction directly from the pixel
representation of the steel defect images. We showed that
without any prior knowledge excellent results are achieved,
outperforming any classiﬁer trained on feature descriptors
commonly used for defect detection in textured materials. The
best MPCNN with an error rate of 7% clearly outperforms
the best classiﬁer trained on PHOG features with an error
rate of 15%. We conclude that for defect classiﬁcation in
textured materials, the proposed method is a viable alternative
to standard feature descriptors.
It also scales well to multivariate images (i.e. color, hyperspectral) where the input will map to more than one channel
as in gray-scale. This is a great advantage over hand-crafted
features which are hard to be extended to such domains where
even prior knowledge is still not well consolidated.
ACKNOWLEDGMENTS
This work was ﬁnanced by ArcelorMittal.
Confusion matrices for the best classiﬁers. Left: MPCNN, middle: PHOG, right: PHOG + MONO-LBP committee. Only on defect number 2 the
classical features obtained a better result than our MPCNN. Also note the non marginal improvement of a committee w.r.t. the single best classiﬁer.