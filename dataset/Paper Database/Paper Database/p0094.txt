Data Augmentation Approaches in Natural Language
Processing: A Survey
Bohan Li, Yutai Hou, Wanxiang Che∗
Harbin Institute of Technology, Harbin, China
As an eﬀective strategy, data augmentation (DA) alleviates data scarcity scenarios where deep learning techniques may fail. It is widely applied in computer
vision then introduced to natural language processing and achieves improvements in many tasks. One of the main focuses of the DA methods is to improve
the diversity of training data, thereby helping the model to better generalize to
unseen testing data. In this survey, we frame DA methods into three categories
based on the diversity of augmented data, including paraphrasing, noising, and
sampling. Our paper sets out to analyze DA methods in detail according to the
above categories. Further, we also introduce their applications in NLP tasks as
well as the challenges. Some useful resources are provided in Appendix A.
Data Augmentation, Natural Language Processing
2010 MSC: 00-01, 99-00
A person in white clothes and
jeans is standing there.
A person in white sweater and jeans is standing there.
Paraphrasing
A person people in white sweater and jeans is standing there.
There stands a girl wearing white sweater and jeans.
∗Corresponding author
Email addresses: (Bohan Li), (Yutai Hou),
 (Wanxiang Che)
 
June 28, 2022
 
Introduction
Data Augmentation Methods in NLP
Paraphrasing-based Methods . . . . . . . . . . . . . . . . . . .
Thesauruses . . . . . . . . . . . . . . . . . . . . . . . . . .
Semantic Embeddings . . . . . . . . . . . . . . . . . . . .
Language Models . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Machine Translation . . . . . . . . . . . . . . . . . . . . .
Model Generation
. . . . . . . . . . . . . . . . . . . . . .
Noising-based Methods . . . . . . . . . . . . . . . . . . . . . .
Swapping . . . . . . . . . . . . . . . . . . . . . . . . . . .
Deletion . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Insertion . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Substitution . . . . . . . . . . . . . . . . . . . . . . . . . .
Sampling-based Methods . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Non-pretrained Models . . . . . . . . . . . . . . . . . . . .
Pretrained Models . . . . . . . . . . . . . . . . . . . . . .
Self-training . . . . . . . . . . . . . . . . . . . . . . . . . .
Mixup . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Strategies and Tricks
Method Stacking . . . . . . . . . . . . . . . . . . . . . . . . . . .
Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
The Use of Augmented Data
. . . . . . . . . . . . . . . .
Hyperparameters . . . . . . . . . . . . . . . . . . . . . . .
Training Strategies . . . . . . . . . . . . . . . . . . . . . .
Training Objects . . . . . . . . . . . . . . . . . . . . . . .
Filtering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Applications on NLP Tasks
Related Topics
Pretrained Language Models
. . . . . . . . . . . . . . . . . . . .
Contrastive Learning . . . . . . . . . . . . . . . . . . . . . . . . .
Other Data Manipulation Methods . . . . . . . . . . . . . . . . .
Generative Adversarial Networks . . . . . . . . . . . . . . . . . .
Adversarial Attacks . . . . . . . . . . . . . . . . . . . . . . . . . .
Challenges and Opportunities
Conclusion
Appendix A
Related Resources
1. Introduction
Data augmentation refers to methods used to increase the amount of data
by adding slightly modiﬁed copies of already existing data or newly created synthetic data from existing data. Such methods alleviate data scarcity scenarios
where deep learning techniques may fail, so DA has received active interest and
demand recently. Data augmentation is widely applied in the ﬁeld of computer
vision , such as ﬂipping and rotation, then introduced to natural language processing (NLP). Diﬀerent to images, natural language is discrete, which makes
the adoption of DA methods more diﬃcult and underexplored in NLP.
Large numbers of DA methods have been proposed recently, and a survey of
existing methods is beneﬁcial so that researchers could keep up with the speed
of innovation. Liu et al. and Feng et al. both present surveys that give a
bird’s eye view of DA for NLP. They directly divide the categories according to
the methods. These categories thus tend to be too limited or general, e.g., backtranslation and model-based techniques. Bayer et al. post a survey on DA
for text classiﬁcation only. In this survey, we will provide an inclusive overview
of DA methods in NLP. One of our main goals is to show the nature of DA,
i.e., why data augmentation works. To facilitate this, we category DA methods
according to the diversity of augmented data, since improving training data
diversity is one of the main thrusts of DA eﬀectiveness. We frame DA methods
into three categories, including paraphrasing, noising, and sampling.1
Speciﬁcally, paraphrasing-based methods generate the paraphrases of the
original data as the augmented data.
This category brings limited changes
compared with the original data. Noising-based methods add more continuous
or discrete noises to the original data and involve more changes.
Samplingbased methods master the distribution of the original data to sample new data
as augmented data. With the help of artiﬁcial heuristics and trained models,
such methods can sample brand new data rather than changing existing data
and therefore generate even more diverse data.
Our paper sets out to analyze DA methods in detail according to the above
categories. In addition, we also introduce their applications in NLP tasks as
well as the challenges. The rest of the paper is structured as follows:
• Section 2 presents a comprehensive review of the three categories and
analyzes every single method in those categories. We also introduce the
characteristics of the methods, e.g., the granularity and the level.
• Section 3 refers to a summary of common strategies and tricks to improve
the quality of augmented data, including method stacking, optimization,
and ﬁltering strategies.
1This survey has been accepted by AI OPEN: 
 
NLP-DA-Papers
• Section 4 analyzes the application of the above methods in NLP tasks.
We also show the development of DA methods through a timeline.
• Section 5 introduces some related topics of data augmentation, including
pre-trained language models, contrastive learning, similar data manipulation methods, generative adversarial networks, and adversarial attacks.
We aim to connect data augmentation with other topics and show their
diﬀerence at the same time.
• Section 6 lists some challenges we observe in NLP data augmentation,
including theoretical narrative and generalized methods.
These points
also reveal the future development direction of data augmentation.
• Section 7 concludes the paper.
Paraphrasing
Thesauruses
Zhang et al. , Wei et al. , Coulombe et al. 
Embeddings
Wang et al. 
Jiao et al. 
Coulombe et al. , Regina et al. , Louvan et al. 
Translation
Back-translation
Xie et al. , Zhang et al. 
Unidirectional
Translation
Nishikawa et al. , Bornea et al. 
Generation
Hou et al. , Li et al. , Liu et al. 
Wei et al. , Luque et al. , Yan et al. 
Wei et al. , Peng et al. , Yu et al. 
Wei et al. , Peng et al. , Yan et al. 
Substitution
Coulombe et al. , Xie et al. , Louvan et al. 
Min et al. , Liu et al. 
Nonpretrained
Kang et al. , Zhang et al. , Raille et al.
Pretrained
Tavor et al. , Kumar et al. , Ng et al. 
Thakur et al. , Quteineh et al. 
Du et al. , Montella et al. 
Guo et al. , Cheng et al. 
Figure 1: Taxonomy of NLP DA methods.
A person in white clothes and
jeans is standing there.
A person in white sweater and jeans is standing there.
Paraphrasing
A person people in white sweater and jeans is standing there.
There stands a girl wearing white sweater and jeans.
Figure 2: Data augmentation techniques include three categories. The examples of the original
data and augmented data are on the left and right, respectively. As we can see, the diversity
of paraphrasing, noising, and sampling increases in turn compared to the original input.
2. Data Augmentation Methods in NLP
Data Augmentation aims at generating additional, synthetic training data in
insuﬃcient data scenes. Data augmentation ranges from simple techniques like
rule-based methods to learnable generation-based methods, and all the above
methods essentially guarantee the validity of the augmented data . That
is to say, DA methods need to make sure that the augmented data is valid for
the task, i.e., be considered to be part of the same distribution of the original
data . For example, similar semantics in machine translation and the same
label in text classiﬁcation as the original data.
On the basis of validity, augmented data is also expected to be diverse to
improve model generalization on downstream tasks. This involves the diversity
of augmented data. In this survey, we novelly divide DA methods into three
categories according to the diversity of their augmented data: paraphrasing,
noising, and sampling.
• The paraphrasing-based methods generate augmented data that has limited semantic diﬀerence from the original data, based on proper and restrained changes to sentences. The augmented data convey very similar
information as the original form.
• The noising-based methods add discrete or continuous noise under the
premise of guaranteeing validity. The point of such methods is to improve
the robustness of the model.
• The sampling-based methods master the data distributions and sample
novel data within them.
Such methods output more diverse data and
satisfy more needs of downstream tasks based on artiﬁcial heuristics and
trained models.
2. Semantic Embeddings
1. Thesaurus
5. Machine Translation
6. Model Generation
Sentence-level
Phrase-level
Word-level
Figure 3: Data augmentation techniques by paraphrasing include three levels: word-level,
phrase-level, and sentence-level.
Figure 4: Paraphrasing by using thesauruses.
As shown in the examples and diagrams in Figure 2, the paraphrasing, noising, and sampling-based methods provide more diversity in turn. In this section,
we will introduce and analyze them in detail.2
Paraphrasing-based Methods
As common phenomena in natural language, paraphrases are alternative
ways to convey the same information as the original form . Naturally,
the generation of paraphrases is a suitable scheme for data augmentation. Paraphrasing consists of several levels, including lexical paraphrasing, phrase paraphrase, and sentence paraphrase (Figure 3). Therefore, the paraphrasing-based
DA techniques introduced below can also be included into these three levels.
2.1.1. Thesauruses
Some works replace words in the original text with their synonyms and
hypernyms,3 so as to obtain a new way of expression while keeping the semantics
of the original text as unchanged as possible. As shown in Figure 4, thesauruses
like WordNet contain such lexical triplets of words and are often used as
external resources.
Zhang et al. are the ﬁrst to apply thesaurus in data augmentation. They
use a thesaurus derived from WordNet,4 which sorts the synonyms of words
according to their similarity. For each sentence, they retrieve all replaceable
words and randomly choose r of them to be replaced. The probability of number
2The speciﬁc classiﬁcation is shown in Figure 12
3Replacing a word with an antonym or a hyponym (more speciﬁc word) is usually not a
semantically invariant transformation. 
4The thesaurus is obtained from the Mytheas component used in LibreOﬃce project.
Being late is terrible. Being late is bad .
Figure 5: Paraphrasing by using semantic embeddings.
r is determined by a geometric distribution with parameter p in which P[r] ∼pr.
Given a word, the index s of its chosen synonym is also determined by a another
geometric distribution in which P[s] ∼ps. The method ensures that synonyms
that are more similar to the original word are selected with greater probability.
Some methods apply a similar method.
A widely used text augmentation method called EDA (Easy Data Augmentation Techniques) also replaces the original words with their synonyms
using WordNet: they randomly choose n words, which are not stop words, from
the original sentence.5 Each of these words is replaced with a random synonym.
Zhang et al. apply a similar method in extreme multi-label classiﬁcation.
In addition to synonyms, Coulombe et al. propose to use hypernyms to
replace the original words. They also recommend the parts of speech of the
augmented word in order of increasing diﬃculty: adverbs, adjectives, nouns,
and verbs. Zuo et al. use WordNet and VerbNet to retrieve synonyms,
hypernyms, and words of the same category.
Thesauruses
Advantage(s):
1. Easy to use.
Limitation(s):
1. The scope and part of speech of augmented words are limited.
2. This method cannot resolve the ambiguity problem.
3. Sentence semantics may be aﬀected if there are too many substitutions.
2.1.2. Semantic Embeddings
This method overcomes the limitations of replacement range and parts of
speech in the thesaurus-based method. It uses pre-trained word embeddings,
such as Glove, Word2Vec, FastText, etc., and replaces the original word in the
sentence with its closest neighbor in embedding space, as shown in Figure 5.
In the Twitter message classiﬁcation task, Wang et al. pioneer to use
both word embeddings and frame embeddings instead of discrete words.6 As
for word embeddings, each original word in the tweet is replaced with one of
its k-nearest-neighbor words using cosine similarity. For example, “Being late is
terrible” becomes “Being behind are bad”. As for frame semantic embeddings,
5n is proportional to the length of the sentence.
6The frame embeddings refer to the continuous embeddings of semantic frames .
Figure 6: Paraphrasing by using language models.
the authors semantically parse 3.8 million tweets and build a continuous bag-offrame model to represent each semantic frame using Word2Vec . The same
data augmentation approach as words is then applied to semantic frames.
Compared to Wang et al. , Liu et al. only use word embeddings to
retrieve synonyms.
In the meanwhile, they edit the retrieving result with a
thesaurus for balance. RamirezEchavarria et al. create the dictionary of
embeddings for selection.
Semantic Embeddings
Advantage(s):
1. Easy to use.
Higher replacement hit rate and more comprehensive replacement
Limitation(s):
1. This method cannot resolve the ambiguity problem.7
2. Sentence semantics may be aﬀected if there are too many substitutions.
2.1.3. Language Models
Pretrained language models have become mainstream models in recent years
due to their excellent performance. Masked language models (MLMs) such as
BERT and RoBERTa can predict masked words in text based on context, which
can be used for text data augmentation (as shown in Figure 6).
this approach alleviates the ambiguity problem since MLMs consider the whole
Wu et al. ﬁne-tune on pre-trained BERT to perform conditional MLM
task. They alter the segmentation embeddings to label embeddings, which are
learned corresponding to the annotated labels on labeled datasets. They use this
ﬁne-tuned conditional BERT to augment sentences. Speciﬁcally, a few words in
a labeled sentence are randomly mask then ﬁlled by the conditional BERT.
Jiao et al. use both word embeddings and masked language models to
obtain augmented data. They apply the tokenizer of BERT to tokenize words
into multiple word pieces. Each word piece is replaced with probability 0.4. If
a word piece is not a complete word (“est” for example), it is replaced by its
K-nearest-neighbor words in the Glove embedding space. If the word piece is
a complete word, the authors replace it with [MASK] and employ BERT to
predict K Words to ﬁll in the blank. Regina et al. , Tapia-Téllez et al. ,
Lowell et al. , and Palomino et al. apply methods that are similar to Jiao
et al. . They mask multiple words in a sentence and generate new sentences
by ﬁlling these masks to generate more varied sentences. In addition, RNNs are
She is not overly optimistic. She isn’t overly optimistic.
Figure 7: Paraphrasing by using rules.
also used for replacing the original word based on the context ( ).
Language Models
Advantage(s):
1. This approach alleviates the ambiguity problem.
2. This method considers context semantics.
Limitation(s):
1. Still limited to the word level.
2. Sentence semantics may be aﬀected if there are too many substitutions.
2.1.4. Rules
This method requires some heuristics about natural language to ensure the
maintaining of sentence semantics, as shown in Figure 7.
On the one hand, some works rely on existing dictionaries or ﬁxed heuristics
to generate word-level and phrase-level paraphrases. Coulombe et al. introduce the use of regular expressions to transform the form without changing
sentence semantics, such as the abbreviations and prototypes of verbs, modal
verbs, and negation. For example, replace “is not” with “isn’t”. Similarly, Regina
et al. use word-pair dictionaries to perform replacements between the expanded form and the abbreviated form.
On the other hand, some works generate sentence-level paraphrases for original sentences with some rules, e.g. dependency trees. Coulombe et al. use a
syntactic parser to build a dependency tree for the original sentence. Then the
dependency tree is used for syntax transformation. For example, replace “Sally
embraced Peter excitedly.” with “Peter was embraced excitedly by Sally.”. Dehouck et al. apply a similar method.
Louvan et al. crop particular
fragments on the dependency tree to create a smaller sentence. They also rotate the target fragment around the root of the dependency parse structure,
without harming the original semantics.
Advantage(s):
1. Easy to use.
2. This method preserves the original sentence semantics.
Limitation(s):
1. This method requires artiﬁcial heuristics.
2. Low coverage and limited variation.
It‘s so kind of you. 你真好。
You are so nice.
Figure 8: Paraphrasing by machine translation.
2.1.5. Machine Translation
Translation is a natural means of paraphrasing. With the development of
machine translation models and the availability of online APIs, machine translation is popular as an augmentation method in many tasks, as shown in Figure 8.
Back-translation. This method means that the original text is translated into
other languages, and then translated back to obtain the augmented text in the
original language. Diﬀerent from word-level methods, back-translation does not
directly replace individual words but rewrites the whole sentence in a generated
Xie et al. , Yu et al. , and Fabbri et al. use English-French
translation models (in both directions) to perform back-translation on each
sentence and obtain their paraphrases. Lowell et al. also introduce this
method as one of the unsupervised data augmentation methods. Zhang et al. 
leverage back-translation to obtain the formal expression of the original data in
the style transfer task.
In addition to some trained machine translation models, some cloud translation API services like Google and DeepL are common tools for back-translation
and are applied by some works like .8
Some works add additional features based on vanilla back-translation. Nugent et al. propose a range of softmax temperature settings to ensure diversity while preserving semantic meaning. Qu et al. combine back-translation
with adversarial training, to synthesize diverse and informative augmented examples by organically integrating multiple transformations. Zhang et al. 
employ a discriminator to ﬁlter the sentences in the back-translation results.
This method greatly improves the quality of the augmented data as a threshold.
Unidirectional Translation. Diﬀerent from back-translation, the unidirectional translation method directly translates the original text into other languages once, without translating it back to the original language. This method
usually occurs in a multilingual scene.
In the task of unsupervised cross-lingual word embeddings (CLWEs), Nishikawa
et al. build pseudo-parallel corpus with an unsupervised machine translation model. The authors ﬁrst train unsupervised machine translation (UMT)
models using the source/target training corpora and then translate the corpora
8The links of the above Cloud Translation API services are: 
translate/docs/apis (Google) and (DeepL).
Figure 9: Paraphrasing by model generation.
using the UMT models. The machine-translated corpus is used together with
the original corpus to learn monolingual word embeddings for each language
independently. Finally, the learned monolingual word embeddings are mapped
to a shared CLWE space. This method both facilitates the structural similarity
of two monolingual embedding spaces and improves the quality of CLWEs in
the unsupervised mapping method.
Bornea et al. , Barrire et al. , and Aleksandr et al. translate the
original English corpus into several other languages and obtain multiplied data.
Correspondingly, they use multilingual models.
Machine Translation
Advantage(s):
1. Easy to use.
2. Wide range of applications.
3. This approach guarantees correct syntax and unchanged semantics.
Limitation(s):
1. Poor controllability and limited diversity because of the ﬁxed machine
translation models.
2.1.6. Model Generation
Some methods employ Seq2Seq models to generate paraphrases directly.
Such models output more diverse sentences given proper training objects, as
shown in Figure 9.
Hou et al. propose a Seq2Seq data augmentation model for the language understanding module of task-based dialogue systems.
They feed the
delexicalized input utterance and the speciﬁed diverse rank k (e.g.
into the Seq2Seq model as the input to generate a new utterance. Similarly,
Hou et al. encodes the concatenated multiple input utterances by an Llayer transformer. The proposed model uses duplication-aware attention and
diverse-oriented regularization to generate more diverse sentences.
In the task of aspect term extraction, Li et al. adopt Transformer as the
basic structure. The masked original sentences as well as their label sequences
are used to train a model M that reconstructs the masked fragment as the
augmented data.9
Kober et al. use GAN to generate samples that are
9Half of the words in original sentences whose sequence labels are not ‘O’ are masked.
very similar to the original data. Liu et al. employ a pre-trained model to
provide prior information to the proposed Transformer-based model. Then the
proposed model could generate both context-relevant answerable questions and
unanswerable questions.
Model Generation
Advantage(s):
1. Wide range of applications.
2. Strong application.
Limitation(s):
1. Require for training data.
2. High training diﬃculty.
Noising-based Methods
The focus of paraphrasing is to make the semantics of the augmented data as
similar to the original data as possible. In contrast, the noising-based methods
add faint noise that does not seriously aﬀect the semantics, so as to make it
appropriately deviate from the original data. Humans greatly reduce the impact of weak noise on semantic understanding through their grasp of linguistic
phenomena and prior knowledge, but this noise can pose challenges for models. Thus, this method not only expands the amount of training data but also
improves model robustness.
2.2.1. Swapping
The semantics of natural language are sensitive to text order, while slight
order change is still readable for humans . Therefore, the random swapping
between words even sentences within a reasonable range can be used as a data
augmentation method.
Wei et al. randomly choose two words in the sentence and swap their
positions. This process is repeated n times, in which n is proportional to the
sentence length l. Longpre et al. , Rastogi et al. , and Zhang et al. 
also apply the same method. Dai et al. split the token sequence into segments according to labels, then randomly choose some segments to shuﬄe the
order of the tokens inside, with the label order unchanged.
In addition to word-level swapping, some works also propose sentence-level
even instance-level swapping. In the task of tweet sentiment analysis, Luque
et al. divide tweets into two halves. They randomly sample and combine
ﬁrst halves with second halves that have the same label. Although the data
generated in this way may be ungrammatical and semantically unsound, it still
carries relatively complete semantics and emotional polarity compared to individual words. Yan et al. perform sentence-level random swapping on legal
documents classiﬁcation. Since sentences independently contain relatively complete semantics comparing to words, the sentence order in the legal document
has little eﬀect on the meaning of the original text. Consequently, the authors
shuﬄe the sentences to obtain the augmented text.
Figure 10: The example of ﬁve noising-based methods.
2.2.2. Deletion
This method means randomly deleting words in a sentence or deleting sentences in a document.
As for word-level deletion, Wei et al. randomly remove each word in
the sentence with probability p. Longpre et al. , Rastogi et al. , and
Zhang et al. also apply the same method. In the task of spoken language
understanding, Peng et al. augment input dialogue acts by deleting slot
values to obtain more combinations.
As for sentence-level deletion, Yan et al. randomly delete each sentence
in a legal document according to a certain probability. They do this because
there exist many irrelevant statements and deleting them will not aﬀect the
understanding of the legal case. Yu et al. employ the attention mechanism to
determine the objective of both word-level and sentence-level random deletion.
2.2.3. Insertion
This method means randomly inserting words into a sentence or inserting
sentences into a document.
As for word-level insertion, Wei et al. select a random synonym of a
random word in a sentence that is not a stop word, then insert that synonym
into a random position in the sentence. This process is repeated n times. In the
task of spoken language understanding, Peng et al. augment input dialogue
acts by inserting slot values to obtain more combinations.
In legal documents classiﬁcation, since documents with the same label may
have similar sentences, Yan et al. employ sentence-level random insertion.
They randomly select sentences from other legal documents with the same label
to get augmented data.
Random insertion introduces new noisy information that may change the
original label. Tips to avoid this problem:
1. Word level: use label-independent external resources.
2. Sentence level: use other samples with the same labels as the original
2.2.4. Substitution
This method means randomly replacing words or sentences with other strings.
Diﬀerent from the above paraphrasing methods, this method usually avoids using strings that are semantically similar to the original data.
Some works implement substitution through existing outer resources. Coulombe
et al. and Regina et al. introduce a list of the most common misspellings
in English to generate augmented texts containing common misspellings.10 For
example, “across” is easily misspelled as “accross”. Xie et al. borrow from
the idea of “word-dropout” and improve generalization by reducing the information in the sentence. This work uses “_” as a placeholder to replace random
words, indicating that the information at that position is empty.
Some works use task-related resources or generate random strings for substitution. Xie et al. and Xie et al. replace the original words with other
words in the vocabulary, and they use the TF-IDF value and the unigram frequency to choose words from the vocabulary, respectively. Lowell et al. and
Daval et al. also explore this method as one of unsupervised data augmentation methods. Wang et al. propose a method that randomly replaces words
in the input and target sentences with other words in the vocabulary. In NER,
Dai et al. replace the original token with a random token in the training
set with the same label. Qin et al. propose a multi-lingual code-switching
method that replaces original words in the source language with words of other
languages. In the task of task-oriented dialogue, random substitution is a useful
way to generate augmented data. Peng et al. augment input dialogue acts
by replacing slot values to obtain more combinations in spoken language understanding. In slot ﬁlling, Louvan et al. do slot substitution according to the
slot label. Song et al. augment the training data for dialogue state tracking
by copying user utterances and replace the corresponding real slot values with
generated random strings.
10A list of common spelling errors in English can be obtained from the online resources of
Oxford Dictionaries: 
Random substitution introduces new noisy information that may change
the original label. Tips to avoid this problem:
1. Word level: use label-independent external resources.
2. Sentence level: use other samples with the same labels as the original
Advantage(s):
1. Noising-based methods improve model robustness.
Disadvantage(s):
1. Poor interpretability.
2. Limited diversity for every single method.
Sampling-based Methods
Sampling-based methods grasp the data distribution and sample new data
within it. Similar to paraphrasing-based models, they also involve rules and
trained models to generate augmented data. The diﬀerence is that the samplingbased methods are task-speciﬁc and require task information like labels and data
Such methods not only ensure validity but also increase diversity.
They satisfy more needs of downstream tasks based on artiﬁcial heuristics and
trained models, and can be designed according to speciﬁc task requirements.
Thus, they are usually more ﬂexible and diﬃcult than the former two categories.
2.3.1. Rules
This method uses some rules to directly generate new augmented data.
Heuristics about natural language and the corresponding labels are sometimes
required to ensure the validity of the augmented data. The model structure
is as shown in Figure 11(a). Diﬀerent from the above rule-based paraphrasing
method, this method constructs valid but not guaranteed to be similar to the
original data (even diﬀerent labels).
Min et al. swap the subject and object of the original sentence, and
convert predicate verbs into passive form.
For example, inverse “This small
collection contains 16 El Grecos.”
into “16 El Grecos contain this small collection.”. The labels of new samples are determined by rules. Liu et al. 
apply data augmentation methods in the task of solving math word problems
(MWPs). They ﬁlter out some irrelevant numbers. Then some rules are used
to construct new data based on the idea of double-checking, e.g., constructing
augmented data describing distance = time × speed by reusing the original
data describing time = distance/speed. The output equations of this method
are computationally right. Given the training set of Audio-Video Scene-Aware
11Recall that paraphrasing-based methods are task-independent and only require the original sentence as input.
(e) Mixup.
(d) Self-training.
(c) Pretrained Models.
(b) Non-pretrained Models.
(a) Rules.
Figure 11: Sampling-based models.
Dialogue that provides 10 question-answer pairs for each video, Mou et al. 
shuﬄe the ﬁrst n pairs as dialogue history and take the n + 1-th question as
what needs to be answered.
In natural language inference, Kang et al. 
apply external resources like PPDB and artiﬁcial heuristics to construct new
sentences.
Then they combine the new sentences with original sentences as
augmented pairs according to rules, for example, if A entails B and B entails
C, then A entails C. Kober et al. deﬁne some rules to construct positive
and negative pairs using adjective-noun (AN) and noun-noun (NN) compounds.
For example, given < car, car >, they construct < fastcar, car > as a positive
sample and < fastcar, redcar > as a negative sample. Shakeel et al. construct both paraphrase annotations and non-paraphrase annotations through
three properties including reﬂexivity, symmetry, and transitive extension. Yin
et al. use two kinds of rules including symmetric consistency and transitive
consistency, as well as logic-guided DA methods to generate DA samples.
Advantage(s):
1. Easy to use.
Limitation(s):
1. Require for artiﬁcial heuristics.
2. Low coverage and limited variation.
2.3.2. Non-pretrained Models
Some methods use non-pretrained models to generate augmented data. Such
methods usually entail the idea of back translation (BT) ,12 which is to
train a target-to-source Seq2Seq model and use the model to generate source
12Note that the idea of back translation here is DIFFERENT from the above paraphrasing
method called “back-translation” in Section 2.1.5.
sentences from target sentences, i.e., constructing pseudo-parallel sentences .
Such Seq2Seq model learns the internal mapping between the distributions of
the target and the source, as shown in Figure 11(b). This is diﬀerent from the
model generation based paraphrasing method because the augmented data of
the paraphrasing method shares similar semantics with the original data.
Sennrich et al. train an English-to-Chinese NMT model using existing
parallel corpus, and use the target English monolingual corpus to generate Chinese corpus through the above English-to-Chinese model. Kang et al. train
a Seq2Seq model for each label (entailment, contradiction, and neutral) and
then generate new data using the Seq2Seq model given a sentence and a speciﬁc
label. Chen et al. adopt the Tranformer architecture and map the “rewrite
utterance →request utterance” to the machine translation process. Moreover,
they enforce the optimization process of the Seq2Seq generation with a policy
gradient technique for controllable rewarding. Zhang et al. use Transformer
as the encoder and transfer the knowledge from Grammatical Error Correction
to Formality Style Transfer. Raille et al. create the Edit-transformer, a
Transformer-based model works cross-domain. Yoo et al. propose a novel
VAE model to output the semantic slot sequence and the intent label given an
utterance.
Non-pretrained Models
Advantage(s):
1. Strong diversity.
2. Strong application.
Limitation(s):
1. Require training data.
2. High training diﬃculty.
2.3.3. Pretrained Models
In recent years, large-scale language models (LM) have achieved great success by acquiring rich linguistic knowledge through pretraining. Thus, they are
naturally used as augmentation tools, as shown in Figure 11(c).
Tavor et al. propose a data augmentation method named LAMBDA.
They generate labeled augmented sentences with GPT-2, which is ﬁne-tuned
on the training set in advance. Then the augmented sentences are ﬁltered by a
classiﬁer to ensure the data quality. Kumar et al. applies a similar method
without the classiﬁer for ﬁltering.
Some works adopt masked language models to obtain augmented data. Ng
et al. use the masked language model to construct a corruption model and a
reconstruction model. Given the input data points, they initially generate data
far away from the original data manifold with the corruption model. Then the
reconstruction model is used to pull the data point back to the original data
manifold as the ﬁnal augmented data.
Some works adopt auto-regressive models to obtain augmented data. Peng
et al. use the pre-trained SC-GPT and SC-GPT-NLU to generate utterances and dialogue acts respectively. The results are ﬁltered to ensure the data
quality. Abonizio et al. ﬁne-tune DistilBERT on original sentences to
generate synthetic sentences. Especially, GPT-2 is a popular model used for
generating augmented data. Quteineh et al. use label-conditioned GPT-2
to generate augmented data. Tarján et al. generate augmented data with
GPT-2 and retokenize them into statistically derived subwords to avoid the vocabulary explosion in a morphologically rich language. Zhang et al. use
GPT-2 to generate substantially diversiﬁed augmented data in extreme multilabel classiﬁcation.
Pretrained Models
Advantage(s):
1. Strong diversity.
2. Strong application.
Limitation(s):
1. Require training data.
2.3.4. Self-training
In some scenarios, unlabeled raw data is easy to obtain. Thus, converting
such data into valid data would greatly increase the amount of data, as shown
in Figure 11(d).
Thakur et al. ﬁrst ﬁne-tune BERT on the original data, then use the
ﬁne-tuned BERT to label unlabeled sentence pairs. Such augmented data, as
well as the gold data, are used to train SBERT together. Miao et al. further
introduce data distillation into the self-training process. They output the label
of unlabeled data by the iteratively updated teacher model. Yang et al. 
apply a similar self-training method in question answering; a cross-attentionbased teacher model is used to determine the label of each QA pair. Du et
al. introduce SentAugment, a data augmentation method that computes
task-speciﬁc query embeddings from labeled data to retrieve sentences from a
bank of billions of unlabeled sentences crawled from the web.
Some methods directly transfer exsiting models from other tasks to generate pseudo-parallel corpus.
Montella et al. make use of Wikipedia to
leverage a massive sentences.
Then they use Stanford OpenIE package to
extract the triplets given Wikipedia sentences.
For example, given “Barack
Obama was born in Hawaii.”, the returned triples by Stanford OpenIE are
< BarackObama; was; born > and < BarackObama; wasbornin; Hawaii >
Such mappings are ﬂipped as the augmented data of RDF-to-text tasks. Aleksandr et al. apply a similar method.
Since BERT does well on objectproperty (OP) relationship prediction and object-aﬀordance (OA) relationship
prediction, Zhao et al. directly use a ﬁne-tuned BERT to predict the label
of OP and OA samples.
Self-training
Advantage(s):
1. Easier than generative models.
2. Suitable for data-sparse scenarios.
Disadvantage(s):
1. Require for unlabeled data.
2.3.5. Mixup
This method uses virtual embeddings instead of generated natural language
form text as augmented samples.
The existing data is used as the basis to
sample in the virtual vector space, and the sampled data may have diﬀerent
labels than the original data.
The idea of Mixup ﬁrst appears in the image ﬁeld by Zhang et al. . Inspired by this work, Guo et al. propose two variants of Mixup for sentence
classiﬁcation. The ﬁrst one called wordMixup conducts sample interpolation in
the word embedding space, and the second one called senMixup interpolates the
hidden states of sentence encoders. The interpolated new sample through word-
Mixup as well as senMixup, and their common interpolated label are obtained
as follows:
t + (1 −λ)Bj
{k} = λf(Bi){k} + (1 −λ)f(Bj){k},
˜yij = λyi + (1 −λ)yj,
in which Bi
t ∈RN×d denote the t-th word in two original sentences, and
f(Bi), f(Bj) denote the hidden layer sentence representation. Moreover, yi, yj
are the corresponding original labels.
Mixup is widely applied in many works recently. Given the original samples,
Cheng et al. ﬁrstly construct their adversarial samples following , and
then apply two Mixup strategies named Padv and Paut: The former interpolates
between adversarial samples, and the latter interpolates between the two corresponding original samples. Similarly, Sun et al. , Bari et al. , and Si
et al. both apply such Mixup method for text classiﬁcation. Sun et al. 
propose Mixup-Transformer which combines Mixup with transformer-based pretrained architecture. They test its performance on text classiﬁcation datasets.
Chen et al. introduce Mixup into NER, proposing both Intra-LADA and
InterLADA.
Advantage(s):
1. Generating augmented data between diﬀerent labels.
Disadvantage(s):
1. Poor interpretability.
Table 1: Characteristics of diﬀerent DA methods. Learnable denotes whether the methods
involve model training; online and oﬄine denote whether the DA process is during or after model training. Ext.Know denotes to whether the methods require external knowledge
resources to generate augmented data. Pretrain denotes whether the methods require a pretrained model.
Task-related denotes whether the methods consider the label information,
task format, and task requirements to generate augmented data. Level denotes the depth and
extent to which elements of the instance/data are modiﬁed by the DA; t, e, and l denote text,
embedding, and label, respectively. Granularity indicates the extent to which the method
could augment; w, p, and s denote word, phrase, and sentence, respectively.
Learnable Ext.Know Pretrain Task-related Level Granularity
Paraphrasing
Thesauruses
Semantic Embeddings
Language Models
Machine Translation
Model Generation
Substitution
Non-pretrained
Pretrained
Self-training
2.4. Analysis
As shown in Table 1, we compare the above DA methods by various aspects.
• It is easy to ﬁnd that nearly all paraphrasing-based and noising-based
methods are not learnable, except for Seq2Seq and Mixup. However, most
sampling-based methods are learnable except for the rule-based ones.
Learnable methods are usually more complex than non-learnable ones,
thus sampling-based methods generate more diverse and ﬂuent data than
the former two.
• Among all learnable methods, Mixup is the only online one. That is to
say, the DA process is during model training. Thus, Mixup is the only one
that outputs cross-label and discrete embedding from augmented data.
• Comparing Learnable and Resource, we could see that most non-learnable
methods require external knowledge resources which go beyond the original dataset and task deﬁnition.
Commonly used resources include semantic thesauruses like WordNet and PPDB, handmade resources like
misspelling dictionary in , and artiﬁcial heuristics like the ones in 
• Through Learnable, Ext.Know and Pretrain, it can be seen that in addition to artiﬁcial heuristics, DA requires other external interventions to
generate valid new data. This includes model training objectives, external knowledge resources, and knowledge implicit in pretrained language
• Comparing Learnable and Task-related, we could see that all paraphrasingbased and noising-based methods except model generation are not taskrelated. They generate augmented data given only original data without
labels or task deﬁnition. However, all sampling-based methods are taskrelated because heuristics and model training are adopted to satisfy the
needs of speciﬁc tasks.
• Comparing Level and Task-related, we could see that they are relevant.
The paraphrasing-based methods are at the text level. The same is true
for noising-based methods, except for Mixup, which augments both embeddings and labels. All sampling-based methods are at the text and label
level since the labels are also considered and constructed during augmentation.
• Comparing Learnable and Granularity, we could see that almost all nonlearnable methods could be used for word-level and phrase-level DA, but
all learnable methods could only be applied for sentence-level DA. Although learnable methods generate high-quality augmented sentences, unfortunately, they do not work for document augmentation because of their
weaker processing ability for documents. Thus, document augmentation
still relies on simple non-learnable methods, which is also a current situation we have observed in our research.
3. Strategies and Tricks
The three types of DA methods including paraphrasing, noising, and sampling, as well as their characteristics, have been introduced above. In practical
applications, the eﬀect of the DA method is inﬂuenced by many factors. In this
chapter, we present these factors to inspire our readers to use some strategies
and tricks for selecting and constructing suitable DA methods.
3.1. Method Stacking
The methods in Section 2 are not mandatory to be applied alone. They
could be combined for better performance. Common combinations include:
The Same Type of Methods. Some works combine diﬀerent paraphrasingbased methods and obtain diﬀerent paraphrases, to increase the richness of augmented data. For example, Liu et al. use both thesauruses and semantic
embeddings, and Jiao et al. use both semantic embeddings and MLMs. As for
noising-based methods, the former unlearnable ways are usually used together
 . It is because these methods are simple, eﬀective, and complementary. Some methods also adopt diﬀerent sources of noising or paraphrasing like
 . The combination of diﬀerent resources could also improve the
robustness of the model.
Unsupervised Methods. In some scenarios, the simple and task-independent
unsupervised DA methods could meet the demand. Naturally, they are grouped
together and widely used. Wei et al. introduce a DA toolkit called EDA that
consists of synonym replacement, random insertion, random swap, and random
deletion. EDA is very popular and used for many tasks ( ). UDA by Xie
et al includes back-translation and unsupervised noising-based methods; it
is also used in many tasks like .
Multi-granularity. Some works apply the same method at diﬀerent levels to
enrich the augmented data with changes of diﬀerent granularities and improve
the robustness of the model.
For example, Wang et al. train both word
embeddings and frame embeddings by Word2Vec; Guo et al. apply Mixup
at the word and sentence level, and Yu et al. use a series of noising-based
methods at both the word and the sentence level.
3.2. Optimization
The optimization process of DA methods directly inﬂuences the quality of
augmented data. We introduce it through four angles: the use of augmented
data, hyperparameters, training strategies, and training objects.
3.2.1. The Use of Augmented Data
The way of using augmented data directly inﬂuences the ﬁnal eﬀect. From
the perspective of data quality, the augmented data could be used to pre-train
a model if it is not of high quality; otherwise, it could be used to train a
model directly.
From the perspective of data amount, if the amount of the
augmented data is much higher than the original data, they are usually not
directly used together for model training.
Instead, some common practices
include (1) oversampling the original data before training the model (2) pretraining the model with the augmented data and ﬁne-tuning it on the original
3.2.2. Hyperparameters
All the above methods involve hyperparameters that largely aﬀect the augmentation eﬀect. We list some common hyperparameters in Figure 12:
3.2.3. Training Strategies
Some works apply training strategies based on the basic data augmentation
methods. For example, Qu et al. combine back-translation with adversarial
training. Similarly, Quteineh et al. transform the basic pre-trained model
into an optimization problem 13 to maximize the usefulness of the generated
output. Hu et al. and Liu et al. use pre-trained language models to
generate augmented data, and transfer such progress into reinforcement learning. Some works ( ) take the idea of Generative Adversarial Networks to
generate challenging augmented data.
13Monte Carlo Tree Search.
Paraphrasing
1. Thesauruses
2. Semantic
Embeddings
3. Language
(1) Number of replacements
(2) Probability of replacement
5. Machine
Translation
(1) Number of (intermediate) languages
(2) Types of (intermediate) languages
Generation
(1) Parameters in the neural network
1. Swapping
2. Deletion
3. Insertion
4. Substitution
(1) Number of operations
(2) Probability of operations
(1) Number of replacements
-Pretrained
3. Pretrained
4. Self-training
(1) Parameters in the neural network
Figure 12: Hyperparameters that aﬀect the augmentation eﬀect in each DA method.
3.2.4. Training Objects
Training objects are essential for model training, especially for the learnable
DA methods. Nugent et al. propose a range of softmax temperature settings
to ensure diversity while preserving semantic meaning.
Hou et al. use
duplication-aware attention and diverse-oriented regularization to generate more
diverse sentences. Cheng et al. employ curriculum learning to encourage
the model to focus on the diﬃcult training examples.
3.3. Filtering
Sometimes the progress of data augmentation inevitably introduces some
noise even errors, thus ﬁltering mechanisms are introduced to avoid this problem.
Some works ﬁlter input data in the initial stage to avoid inappropriate input
aﬀecting the augmentation eﬀect. A typical example is sentence length, i.e.,
ﬁlter sentences that are too short ( ).
Liu et al. ﬁlter out irrelevant
numbers without augmenting them in solving Math Word Problems, to ensure
the generated data is computationally right.
In addition, some works ﬁlter the synthetic augmented data at the end-stage.
This is usually achieved through a model. For example, Zhang et al. employ
a discriminator to ﬁlter the back-translation results. Tavor et al. and Peng
et al. both apply a classiﬁer to ﬁlter the augmented sentences generated by
pre-trained models to ensure the data quality.
Table 2: The application of DA methods in NLP tasks. Note that if a paper involves multiple
methods, we count it multiple times.
Classiﬁcation
Generation
Prediction
Paraphrasing
Thesauruses
 , , , ,
 , , , ,
 , 
 , 
Embeddings
 , , 
Language Models
 , , , ,
 , , 
 , 
Machine Translation
 , , , ,
 , , , ,
 , , ,
 , 
 , 
 , , ,
Model Generation
 , , ,
 , 
 , , ,
 , , ,
 , , 
 , , , ,
 , , ,
 , , , ,
 , , 
 , , , ,
Substitution
 , , , ,
 , , 
 , , ,
 , , , ,
 , , ,
 , , ,
Non-Pretrained
 , , ,
 , 
 , , ,
 , 
 , 
Pretrained
 , , , ,
 , , ,
 , 
 , , 
 , 
Self-training
 , , , 
 , 
 , , ,
4. Applications on NLP Tasks
Although a variety of data augmentation methods have emerged in the ﬁeld
of NLP in recent years, it is diﬃcult to directly compare their performance. This
is because diﬀerent tasks, evaluation metrics, datasets, model architectures,
and experimental settings make direct comparisons meaningless.
Therefore,
based on the work introduced above, we analyze the data augmentation methods
from the perspective of diﬀerent NLP tasks including text classiﬁcation, text
generation, and structured prediction .
• Text classiﬁcation is the simplest and most basic natural language processing problem. That is, for a piece of text input, output the category to
which the text belongs, where the category is a pre-deﬁned closed set.14
• Text generation, as the name implies, is to generate the corresponding text
given the input data. The most classic example is machine translation.
• The structured prediction problem is usually unique to NLP. Diﬀerent
from the text classiﬁcation, there are strong correlation and format requirements between the output categories in the structured prediction
In this section, we try to analyze the features as well as the development status
of DA in these tasks. Some statistical results are shown in Table 2 and Table 3.
DA methods are applied more widely in text classiﬁcation than other NLP
tasks in general and in each category. Moreover, each individual DA method
could be applied to text classiﬁcation. Such application advantage is because of
the simple form of text classiﬁcation: given the input text, it directly investigates
the model’s understanding of semantics by label prediction.
Therefore, it is
relatively simple for data augmentation to only consider retaining the semantics
of words that are important for classiﬁcation.
As for text generation, it prefers sampling-based methods to bring more semantic diversity. And structured prediction prefers paraphrasing-based methods
because it is sensitive to data format. Thus, it has higher requirements for data
By comparing each DA method, we can see that simple and eﬀective unsupervised methods, including machine translation, thesaurus-based paraphrasing, and random substitution, are quite popular. In addition, learnable methods
like paraphrasing-based model generation and sampling-based pretrained models, also gain a lot of attention because of their diversity and eﬀectiveness.
We also show the development process of the DA method on three types of
tasks through a timeline (Table 3). On the whole, the number of applications
of DA in these tasks has increased these years. Text classiﬁcation is the ﬁrst
task to use DA, and the number of corresponding papers is also larger than
the other two tasks.
In terms of text generation and structured prediction,
DA is receiving increasing attention. Paraphrasing-based methods have always
been a popular method. In recent years, sampling-based methods show clear
momentum in text classiﬁcation and text generation, because they bring more
gains to powerful pretrained language models than paraphrasing-based methods.
However, people still tend to use paraphrasing and noising-based methods in
structured prediction.
14Text matching tasks such as Natural Language Inference can also be transformed into
text classiﬁcation.
Timeline of DA methods applied in three kinds of NLP tasks. The time for each
paper is based on its ﬁrst arXiv version (if exists) or estimated submission time. P denotes
paraphrasing-based methods; N denotes noising-based methods; S denotes sampling-based
Text Classiﬁcation
Text Generation
Structured Prediction
Zhang et al. P
Wang et al. P
Sennrich et al. S
Xu et al. S
Xie et al. N
Fadaee et al. P
Yu et al. P
Kang et al. S
Kobayashi et al. P
Hou et al. P
Aroyehun et al. P
Wang et al. N
Risch et al. P
Yoo et al. S
Yoo et al. S
Du et al. N
Sahin et al. P
Coulombe et al. P, N
Wu et al. P
Wei et al. P, N
Xie et al. P, N
Guo et al. S
Gao et al. N
Xia et al. S
Bergmanis et al. S
Kumar et al. P
Yu et al. N
Li et al. P
Zmigrod et al. S
Yin et al. P
Luque et al. P, N
Yan et al. N
Text Classiﬁcation
Text Generation
Structured Prediction
Anaby et al. S
Longpre et al. P
Malandrakis et al. P
Niu et al. S
Zhao et al. P
Shakeel et al. S
Yoo et al. P
Kumar et al. S
Raille et al. S
Lun et al. P, N, S
Peng et al. N, S
Li et al. P
Peng et al. S
Kober et al. P, S
Zhang et al. P, S
Cao et al. S
Liu et al. P
Cheng et al. S
Qin et al. N
Qin et al. N
Min et al. S
Chen et al. S
Andreas et al. P
Rastogi et al. P, N
Tarjan et al. S
Regina et al. P, N
Mou et al. S
Asai et al. S
Ng et al. S
Ng et al. S
Yang et al. S
Zhang et al. P,N, S
Zhang et al. S
Barrire et al. P
Fabbri et al. P
Liu et al. P
Louvan et al. P
Louvan et al. N
Tapia-Téllez et al. P
Chen et al. S
Sun et al. S
Dai et al. P, N
Abonizio et al. S
Riabi et al. S
Zuo et al. P
Longpre et al. P, N
Quteineh et al. S
Miao et al. S
Wan et al. P
Bornea et al. P
Daval et al. P ,N
Yao et al. 
Hou et al. P
Liu et al. S
Montella et al. S S
Daval et al. P ,N
Aleksandr et al. S
Chen et al. S
Si et al. S
Xu et al. P
Liu et al. P
Guo et al. P
Si et al. S
Shi et al. N
Shi et al. N
Staliunaite et al. S
Dong et al. S
Chen et al. S
Xu et al. S
Chen et al. N
Jiang et al. S
Kovatchev et al. P, N
Bari et al. P
Liu et al. S
5. Related Topics
How does data augmentation relate to other learning methods?
section, we connect data augmentation with other similar topics.
5.1. Pretrained Language Models
The training of most pre-trained language models (PLMs) is based on selfsupervised learning. Self-supervised learning mainly uses auxiliary tasks to mine
its supervised information from large-scale unsupervised data, and trains the
network through this constructed supervised information, so that it can learn
valuable representations for downstream tasks. From this perspective, PLMs
also introduce more training data into downstream tasks, in an implicit way.
On the other hand, the general large-scale unsupervised data of PLMs may be
out-of-domain for speciﬁc tasks. Diﬀerently, the task-related data augmentation
methods essentially focus on speciﬁc tasks.
5.2. Contrastive Learning
Contrastive learning is to learn an embedding space in which similar samples
are close to each other while dissimilar ones are far apart. It focuses on learning
the common features between similar samples and distinguishing the diﬀerences
between dissimilar ones. The ﬁrst step of contrastive learning is applying data
augmentation to construct similar samples with the same label, and the second
step is to randomly choose instances as the negative samples. Thus, contrastive
learning is one of the applications of data augmentation.
5.3. Other Data Manipulation Methods
In addition to DA, there are some other data manipulation methods to improve model generalization . Oversampling is usually used in data imbalance scenarios. It simply samples original data from the minority group as
new samples, instead of generating augmented data. Data cleaning is additionally applied to the original data to improve data quality and reduce data noise.
It usually includes lowercasing, stemming, lemmatization, etc.
Data weighting assigns diﬀerent weights to diﬀerent samples according to their importance
during training, without generating new data. Data synthesis provides entire
labeled artiﬁcial examples instead of augmented data generated by models or
5.4. Generative Adversarial Networks
Generative Adversarial Networks (GANs) are ﬁrst introduced by Goodfellow
et al. . As a type of semi-supervised method, GANs include the generative
model, which is mainly used to challenge the discriminator of GANs, while the
generative models in some DA methods are directly used to augment training
data. Moreover, the generative model of GANS is applied as a DA method
in some scenes like , and have demonstrated to be
eﬀective for data augmentation purposes.
5.5. Adversarial Attacks
Adversarial attacks are techniques to generate adversarial examples attacking a machine learning model, i.e., causing the model to make a mistake. Some
works use DA methods like code-switch substitution to generate adversarial
examples as consistency regularization .
6. Challenges and Opportunities
Data augmentation has seen a great process over the last few years, and it
has provided a great contribution to large-scale model training as well as the
development of downstream tasks. Despite the process, there are still challenges
to be addressed. In this section, we discuss some of these challenges and future
directions that could help advance the ﬁeld.
Theoretical Narrative. At this stage, there appears to be a lack of systematic probing work and theoretical analysis of DA methods in NLP. The few
related works are of DA in the image domain, considering data augmentation
as encoding a priori knowledge about data or task invariance , variance
reduction or regularization methods . In NLP, Most previous works
propose new methods or prove the eﬀectiveness of the DA method on downstream tasks, but do not explore the reasons and laws behind it, e.g., from
the perspective of mathematics. The discrete nature of natural language makes
theoretical narrative essential since narrative helps us understand the nature of
DA, without being limited to determining eﬀectiveness through experiments.
More Exploration on Pretrained Language Models. In recent years, pretrained language models have been widely applied in NLP, which contain rich
knowledge through self-supervision on a huge scale of corpora.
works using pre-trained language models for DA, but most of them are limited to [MASK] completion , direct generation after ﬁne-tuning , or selftraining . Is DA still helpful in the era of pre-trained language models? Or,
how to further use the information in pre-trained models to generate more diverse and high-quality data with less cost? There are some initial explorations
in these directions , while we still look forward to more works in the
Few-shot Scenarios. In few-shot scenarios, models are required to achieve
performance which rivals that of traditional machine learning models, yet the
amount of training data is extremely limited. DA methods provide a direct
solution to the problem. However, most current works in few-shot scenarios
are paraphrasing-based methods . Such methods ensure the validity of the
augmented data, but also lead to insuﬃcient semantic diversity. Mainstream
pretrained language models obtain rich semantic knowledge by language modeling.
Such knowledge even covers to some extent the semantic information
introduced by traditional paraphrasing-based DA methods. In other words, the
improvement space that traditional DA methods bring to pretrained language
models has been greatly compressed. Therefore, it is an interesting question
how to provide models with fast generalization and problem solving capability
by generating high quality augmented data in few-shot scenarios.
Retrieval Augmentation. Retrieval-augmented language models integrate
retrieval into pre-training and downstream usage .15 Retrieval augmentation makes models much more parameter-eﬃcient, as they need to store
less knowledge in their parameters and can instead retrieve it. It also enables
eﬃcient domain adaptation by simply updating the data used for retrieval .
Recently, the size of the retrieval corpora has achieved explosive growth 
and models have been equipped with the ability to query the web for answering
questions . In the future, there may be diﬀerent forms of retrieval to
leverage diﬀerent kinds of information such as common sense knowledge, factual relations, linguistic information, etc. Retrieval augmentation could also be
combined with more structured forms of knowledge retrieval, such as methods
from knowledge base population and open information extraction.
More Generalized Methods for NLP. Natural language is most diﬀerent
from image or sound in that its representation is discrete. At the same time,
NLP includes speciﬁc tasks such as structured prediction that are not available
in other modalities. Therefore, unlike general methods such as clipping for image
augmentation or speed perturbation for audio augmentation, there is currently
no DA method that can be eﬀective for all NLP tasks. This means that there is
still a gap for DA methods between diﬀerent NLP tasks. With the development
of pre-trained models, this seems to have some possibilities.
Especially the
proposal of T5 and GPT3 , as well as the emergence of prompting
learning further verify that the formalization of tasks in natural language can be
independent of the traditional categories, and a more generalized model could
be obtained by unifying task deﬁnitions.
Working with Long Texts and Low Resources Languages. The existing
methods have made signiﬁcant progress in short texts and common languages.
However, limited by model capabilities, DA methods on long texts still struggle
with the simplest methods of paraphrasing and noising (as shown in
Table 1). At the same time, limited by data resources, augmentation methods
of low resource languages are scarce , although they have more demand
for data augmentation. Obviously, exploration in these two directions is still
limited, and they could be promising directions.
7. Conclusion
In this paper, we presented a comprehensive and structured survey of data
augmentation for natural language processing. In order to inspect the nature
15See for further information.
of DA, we framed DA methods into three categories according to the diversity of augmented data, including paraphrasing, noising, and sampling. Such
categories help to understand and develop DA methods. We also introduced
the characteristics of DA methods and their applications in NLP tasks, then
analyzed them through a timeline. In addition, we introduced some tricks and
strategies so that researchers and practitioners can refer to obtain better model
performance. Finally, we distinguish DA with some related topics and outlined
current challenges as well as opportunities for future research.