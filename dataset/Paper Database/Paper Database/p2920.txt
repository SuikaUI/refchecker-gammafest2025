Volume 6, Issue 2
The International Journal of
Biostatistics
CAUSAL INFERENCE
Targeted Maximum Likelihood Based Causal
Inference: Part I
Mark J. van der Laan, University of California - Berkeley
Recommended Citation:
van der Laan, Mark J. "Targeted Maximum Likelihood Based Causal Inference: Part I,"
The International Journal of Biostatistics: Vol. 6: Iss. 2, Article 2.
DOI: 10.2202/1557-4679.1211
Targeted Maximum Likelihood Based Causal
Inference: Part I
Mark J. van der Laan
Given causal graph assumptions, intervention-specific counterfactual distributions of the data
can be defined by the so called G-computation formula, which is obtained by carrying out these
interventions on the likelihood of the data factorized according to the causal graph. The obtained
G-computation formula represents the counterfactual distribution the data would have had if this
intervention would have been enforced on the system generating the data. A causal effect of
interest can now be defined as some difference between these counterfactual distributions indexed
by different interventions. For example, the interventions can represent static treatment regimens
or individualized treatment rules that assign treatment in response to time-dependent covariates,
and the causal effects could be defined in terms of features of the mean of the treatment-regimen
specific counterfactual outcome of interest as a function of the corresponding treatment regimens.
Such features could be defined nonparametrically in terms of so called (nonparametric) marginal
structural models for static or individualized treatment rules, whose parameters can be thought of
as (smooth) summary measures of differences between the treatment regimen specific
counterfactual distributions.
In this article, we develop a particular targeted maximum likelihood estimator of causal
effects of multiple time point interventions. This involves the use of loss-based super-learning to
obtain an initial estimate of the unknown factors of the G-computation formula, and subsequently,
applying a target-parameter specific optimal fluctuation function (least favorable parametric
submodel) to each estimated factor, estimating the fluctuation parameter(s) with maximum
likelihood estimation, and iterating this updating step of the initial factor till convergence. This
iterative targeted maximum likelihood updating step makes the resulting estimator of the causal
effect double robust in the sense that it is consistent if either the initial estimator is consistent, or
the estimator of the optimal fluctuation function is consistent. The optimal fluctuation function is
correctly specified if the conditional distributions of the nodes in the causal graph one intervenes
upon are correctly specified. The latter conditional distributions often comprise the so called
treatment and censoring mechanism. Selection among different targeted maximum likelihood
estimators (e.g., indexed by different initial estimators) can be based on loss-based crossvalidation such as likelihood based cross-validation or cross-validation based on another
appropriate loss function for the distribution of the data. Some specific loss functions are
mentioned in this article.
Subsequently, a variety of interesting observations about this targeted maximum likelihood
estimation procedure are made. This article provides the basis for the subsequent companion Part
II-article in which concrete demonstrations for the implementation of the targeted MLE in
complex causal effect estimation problems are provided.
KEYWORDS: causal effect, causal graph, censored data, cross-validation, collaborative double
robust, double robust, dynamic treatment regimens, efficient influence curve, estimating function,
estimator selection, locally efficient, loss function, marginal structural models for dynamic
treatments, maximum likelihood estimation, model selection, pathwise derivative, randomized
controlled trials, sieve, super-learning, targeted maximum likelihood estimation
Introduction.
The data structure on the experimental unit can often be viewed as a timeseries in discrete time, possibly on a ﬁne scale. At many time points nothing
might be observed and at possibly irregular spaced time-points events occur
and are measured, where some of these events occur at the same time. A
speciﬁed ordering of all measured variables which respects this time-ordering
and possibly additional knowledge about the ordering in which variables were
realized, implies a graph in the sense that for each observed variable we can
identify a set of parent nodes of that observed variable, deﬁned as the set of
variables occurring before the observed variable in the ordering. The likelihood of this unit speciﬁc data structure can be factorized accordingly in terms
of the conditional distribution of a node in the graph, given the parents of
that node, across all nodes.
This particular factorization of the likelihood
puts no restriction on the possible set of data generating distribution, but
the ordering aﬀects the so called G-computation formula for counterfactual
distributions of the data under certain interventions implied by this ordering.
Beyond the factorization of the likelihood in terms of a product of conditional
distributions, the G-computation formula involves specifying a set of nodes in
the time-series/graph as the variables to intervene upon, and specifying the
intervention for these nodes. These interventions could be rules that assign the
value for the intervention node (possibly) in response to the observed data on
the (observed) parents of the intervention node. The G-computation formula
is now deﬁned as the product, across all nodes, excluding the intervention
nodes, of the conditional distribution of a node, given the parent nodes with
the intervention nodes in the parent set following their assigned values.
If it is known that the conditional distribution of a node only depends on a
subset of the parents that were implied by the ordering, then that knowledge
should be incorporated by reducing the parent set to its correct set. This
kind of knowledge does reduce the size of the model for the data generating
distribution (and such assumptions can indeed be tested from the data).
The G-computation formula provides a probability distribution of the intervention speciﬁc data structure. Under certain causal graph conditions on a
causal graph on an augmented set of nodes which includes unobserved nodes
beyond the observed nodes ), such as no unblocked back-door
path from intervention node to future/downstream nodes, for each intervention node, this G-computation formula equals the counterfactual distribution
of the data structure if one would have enforced the speciﬁed intervention on
the system described by the causal graph.
We remind the reader that a causal graph on a set of nodes states that
van der Laan: Targeted ML Causal Inference: Part I
each node is a deterministic function of its parents. It typically represents
a set of so called causal assumptions that cannot be learned from the data.
Given a declared causal graph on a set of nodes, one can formally state what
assumptions on this causal graph are needed in order to claim that a speci-
ﬁed G-computation formula for the observed nodes corresponds with the Gcomputation formula for the causal graph on the full set of nodes (that includes
the unobserved nodes), where the latter G-computation formula is then viewed
as the gold-standard representing the causal eﬀect of interest ).
Either way, the time-ordering and possible known additional known ordering does provide a statistical graph for the data as explained above, and a
corresponding G-computation formula.
In this article we are concerned with (semi-parametric) eﬃcient estimation
of the ”causal” eﬀects viewed as parameters of this G-computation formula
based on observing n independent and identically observations O1, . . . , On of
O. Speciﬁcally, we are concerned with estimation of parameters of the Gcomputation formula implied by a particular statistical graph on the observed
data structure O, in the semiparametric model that makes no assumptions
about each node-speciﬁc conditional distribution in the graph, given its parents.
Formally, the density of O is modeled as
P(N(j) | Pa(N(j))
where N(j) denote the nodes in the graph representing the observed variables,
Pa(N(j)) denote the parents of N(j), and we make no assumptions on each
conditional distribution of N(j), beyond that N(j) only depends on Pa(N(j)).
Note, however, as remarked above, if the parent sets induce more structure
than parent sets implied by an ordering of all observed variables, then this statistical graph of p0 might implies a real (i.e., not just nonparametric) semiparametric model on p0, corresponding with a variety of conditional independence
assumptions.
Even if the (non-testable) causal assumptions required to interpret the Gcomputation formula as a counterfactual distribution on a system fail to hold,
assuming that the ordering of the likelihood respects the ordering w.r.t. the
intervention nodes (i.e., it correctly states what variables are pre or post intervention for each intervention node), the target parameters often still represent
eﬀects of interest aiming to get as close to a causal eﬀect as the data allows. In
particular, one can simply interpret the G-computation parameters for what
they are, namely well deﬁned eﬀects of interventions on the distribution of
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 2
DOI: 10.2202/1557-4679.1211
the data: see van der Laan for more discussion of the role of causal
parameters in variable importance analysis.
It is important to note that the probability density p0 of the observed data
structure O, factored by the statistical graph, can be represented as a product
of two factors, the ﬁrst factor Q0 that identiﬁes the G-computation formulas for interventions, and the second factor g0 representing product over the
intervention nodes of the conditional distribution of the intervention nodes:
p0 = Q0g0. We often refer to the second factor as the censoring and/or treatment mechanism in case the intervention nodes correspond with censoring
variables and/or treatment assignments. We will denote the true probability
distribution of the data-structure on the experimental unit with P0, and its
probability density with p0.
A variety of estimators of causal eﬀects of multiple time-point interventions,
including handling censored data (by, enforcing no-censoring as part of the intervention) have been proposed: Inverse Probability of Censoring Weighted
(IPCW) estimators, Augmented IPCW-estimators (which are double robust),
maximum likelihood based estimators, and targeted Maximum Likelihood Estimators (which are double robust). The IPCW and augmented-IPCW estimators fall in the category of estimating equation methodology ). The augmented-IPCW estimator is deﬁned as a solution of an
estimating equation in the target parameter implied by the so called eﬃcient
inﬂuence curve. Maximum likelihood based estimators involve estimation of
the distribution of the data and subsequent evaluation of the target parameter. Traditional maximum likelihood estimators are not targeted towards the
target parameter, and are thereby, in particular, not double robust.
Targeted maximum likelihood estimators (T-MLE) are two stage estimators, the ﬁrst stage applies regularized maximum likelihood based estimation,
where we advocate the use of loss-based super-learning to maximize adaptivity
to the true distribution/G-computation formula of data ), and the second stage targets the obtained ﬁt from the ﬁrst stage towards the target parameter of interest through a targeted maximum likelihood
step. This targeted maximum likelihood step removes bias for the target parameter if the censoring/treatment mechanism used in the targeted MLE step
is estimated consistently. In this targeted maximum likelihood step the initial
(ﬁrst stage) estimator is treated as an oﬀ-set, and it involves the application of
a ﬂuctuation function to the oﬀset, where the set of possible ﬂuctuations represents a parametric model consisting of ﬂuctuated versions of the oﬀset. This
parametric model is a so called least favorable parametric model in the sense
that its maximum likelihood estimator listens as much to the data w.r.t. ﬁtting
the target parameter as a semiparametric model eﬃcient estimator. Formally,
van der Laan: Targeted ML Causal Inference: Part I
it is the parametric submodel through the ﬁrst stage estimator with the worst
Cramer-Rao lower bound for estimation of the target parameter (at zero ﬂuctuation), among all parametric submodels. (This worst case Cramer-Rao lower
bound as achieved by this least favorable model is actually the semiparametric information bound deﬁned as the variance of the eﬃcient inﬂuence curve.)
Given this least-favorable submodel, maximum likelihood estimation is used
to ﬁt the ﬁnite dimensional ﬂuctuation parameter. Due to this parametric
targeted maximum likelihood step the targeted maximum likelihood estimator is also double robust: the estimator is consistent if the initial ﬁrst-stage
estimator of the G-computation factor of the likelihood is consistent, or if the
conditional distributions of the intervention nodes (i.e., censoring/treatment
mechanism) are estimated consistently (as required to identify the ﬂuctuation
function used in targeted maximum likelihood step). In addition, under regularity conditions, the targeted MLE is (semiparametric) eﬃcient if the initial
estimator is consistent, and consistent and asymptotically linear if either the
initial estimator or the treatment/censoring mechanism estimator is consistent.
Even though the augmented IPCW-estimator is also tailored to be double
robust and locally eﬃcient, targeted maximum likelihood estimation has the
following important advantages relative to estimating equation methods such
as the augmented-IPCW estimator: 1) the T-MLE is a substitution estimator and thereby, contrary to the augmented IPCW-estimator, respects global
constraints of the model such as that one might be estimating a probability
in , 2) since, given an initial estimator, the targeted MLE step involves
maximizing the likelihood along a smooth parametric submodel, contrary to
the augmented IPCW-estimator, it does not suﬀer from multiple solutions of
a (possibly non-smooth in the parameter) estimating equation, 3) contrary to
the augmented IPCW-estimator, the T-MLE does not require that the eﬃcient
inﬂuence curve can be represented as an estimating function in the target parameter, and thereby applies to all path-wise diﬀerentiable parameters, 4) it
can use the cross-validated log-likelihood (of the targeted maximum likelihood
estimator), or any other cross-validated risk of an appropriate loss function
for the relevant factor Q0 of the density (i.e., the G-computation formula)
of the data, as principle criterion to select among diﬀerent targeted maximum likelihood estimators indexed by diﬀerent initial estimators or diﬀerent
choices of ﬂuctuation models. The latter allows ﬁne tuning of the initial estimator of Q0 as well as the ﬁne tuning of the estimation of the unknowns (e.g.,
censoring/treatment mechanism g0) of the ﬂuctuation function applied in the
targeted maximum likelihood step, thereby utilizing the excellent theoretical
and practical properties of the loss-function speciﬁc cross-validation selector.
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 2
DOI: 10.2202/1557-4679.1211
On the other hand, the augmented-IPCW estimator cannot be evaluated based
on a loss function for Q0 alone, but also requires a choice of loss function for
g0. The latter point 4) also allows the targeted MLE to be generalized to lossbased estimation of inﬁnite dimensional parameters that can be approximated
by pathwise diﬀerentiable parameters.
These important theoretical advantages have a substantial practical impact, by allowing one to construct estimators in a wider variety of applications, and with better ﬁnite sample and asymptotic mean squared error w.r.t.
the target. This inspired us to implement targeted maximum likelihood estimation of causal eﬀects of single time point treatment in a variety of data
analyses, allowing for right-censoring of the time-till-event clinical outcome,
and missingness of the clinical outcome. Even though we discussed the overall
targeted maximum likelihood estimator for causal eﬀect estimation of multiple
time point interventions in technical reports ), in this
article we aim to dive deeper into this challenge. In particular, our goal is to
present templates that can be implemented with standard statistical software,
and aim to understand the choices to be made. In future papers we will be implementing these methods on real and simulated data sets and use this paper
as guidance.
The organization of this paper is as follows. Firstly, in Section 2 we start
out with presenting the targeted MLE for sequentially randomized controlled
trials. A speciﬁc targeted loss function is proposed to select among diﬀerent targeted MLE indexed by diﬀerent initial estimators, which results in
maximally asymptotically eﬃcient targeted MLE’s ). Due to the double robustness of the targeted MLE this estimator is
guaranteed to estimate the causal eﬀect of interest consistently, so that conﬁdence intervals and type-I error control are asymptotically valid. In addition,
the T-MLE utilizes all the data (including time-dependent biomarkers) and
thereby has great potential for large eﬃciency gains and bias reductions in
these sequentially randomized controlled trials.
In Section 3 we develop and present a general targeted MLE for any timeseries data structure, applicable to sequentially randomized controlled trials
with censoring and missingness, as well as longitudinal observational studies. The integration of loss-based (super) learning to build and select among
targeted MLE’s is made explicit again, and targeted loss functions are proposed for that purpose. In addition, a variety of interesting observations are
made about the targeted MLE, relevant to the practical implementation of
this estimator in complex longitudinal observational studies and randomized
controlled trials. We end with a discussion in Section 4. Our companion Part
II article will present demonstrations of the targeted MLE.
van der Laan: Targeted ML Causal Inference: Part I
Some overview of relevant literature
The construction of eﬃcient estimators of path-wise diﬀerentiable parameters
in semi-parametric models requires utilizing the so called eﬃcient inﬂuence
curve deﬁned as the canonical gradient of the path-wise derivative of the parameter. This is no surprise since a fundamental result of the eﬃciency theory
is that a regular estimator is eﬃcient if and only if it is asymptotically linear
with inﬂuence curve equal to the eﬃcient inﬂuence curve. We refer to Bickel
et al. , and Andersen et al. . There are two distinct approaches for
construction of eﬃcient (or locally eﬃcient) estimators: the estimating equation approach that uses the eﬃcient inﬂuence curve as an estimating equation
 ), and the targeted MLE that uses the eﬃcient inﬂuence curve to
deﬁne a targeted ﬂuctuation function of an initial estimator, and maximizes
the likelihood in that targeted direction.
The construction of locally eﬃcient estimators in censored data models in
which the censoring mechanism satisﬁes the so called coarsening at random
assumption , Jacobsen and Keiding , Gill
et al. ) has been a particular focus area. This includes also the theory
for locally eﬃcient estimation of causal eﬀects, since the causal inference data
structure can be viewed as a missing data structure on the intervention-speciﬁc
counterfactuals, and the sequential randomization assumption (SRA) implies
the coarsening at random assumption on the missingness mechanism, while
SRA still does not imply any restriction on the data generating distribution.
A particular construction of counterfactuals from the observed data structure,
so that the observed data structure augmented with the counterfactuals satisﬁes the consistency (missing data structure) and sequential randomization
assumption, is provided in Yu and van der Laan , providing an alternative to the implicit construction presented earlier in Gill and Robins ,
thereby showing that, without loss of generality, one can view causal inference
as a missing data structure estimation problem: the importance of the causal
graph is that it makes explicit the deﬁnition of the counterfactuals of interest
(i.e., full data in the censored data model).
The theory for inverse probability of censoring weighted estimation and
the augmented locally eﬃcient IPCW estimator based on estimating functions deﬁned in terms of the orthogonal complement of the nuisance tangent
space in CAR-censored data models (including the optimal estimating function implied by eﬃcient inﬂuence curve) was originally developed in Robins
 , Robins and Rotnitzky . Many papers have been building on
this framework for a uniﬁed treatment
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 2
DOI: 10.2202/1557-4679.1211
of this estimating equation methodology and references). In particular, double robust locally eﬃcient augmented IPCW-estimators have been developed
 , Robins and Rotnitzky , Robins et al.
 , Robins , van der Laan and Robins , Neugebauer and
van der Laan , Yu and van der Laan ).
Causal inference for multiple time-point interventions under sequential randomization started out with papers by Robins in the eighties: e.g. Robins
 , Robins . The popular propensity score methods to assess causal
eﬀects of single time point interventions ,
Sekhon , Rubin ) are not double robust (i.e., rely on correct speciﬁcation of propensity score), have no natural generalization to multiple timepoint interventions, and are also ineﬃcient estimators for single time point interventions ), relative to the locally eﬃcient double
robust estimators such as the augmented IPCW estimator, and the targeted
Structural nested models and marginal structural models for static treatments were proposed by Robins as well: Robins , Robins ,
Robins . Many application papers on marginal structural models exist, involving the application of estimating equation methodology (IPCW and
DR-IPCW): e.g., Hernan et al. , Robins et al. , Bryan et al.
 , Yu and van der Laan . In van der Laan et al. history
adjusted marginal structural models were proposed as a natural extension of
marginal structural models, and it was shown that the latter also imply an
individualized treatment rule of interest (a so called history adjusted statically
optimal treatment regimen): see Petersen et al. for an application to
the when to switch question in HIV research.
Murphy et al. present a nonparametric estimator for a mean under a dynamic treatment in an observational study. Structural nested models
for modeling and estimating an optimal dynamic treatment were proposed by
Murphy , Robins , Robins , Robins . Marginal
structural models for a user supplied set of dynamic treatment regimens were
developed and proposed in van der Laan , van der Laan and Petersen
 and, simultaneously and independently, in Robins et al. . van der
Laan and Petersen also includes a data analysis application of these
models to assess the mean outcome under a rule that switches treatment
when CD4 count drops below a cut-oﬀ, and the optimal cut-oﬀis estimated
Another practical illustration in sequentially randomized trials of
these marginal structural models for realistic individualized treatment rules is
presented in Bembom and van der Laan .
Uniﬁed loss-based learning based on cross-validation was developed in-
van der Laan: Targeted ML Causal Inference: Part I
van der Laan and Dudoit , including construction of adaptive minimax
estimators for inﬁnite dimensional parameters of the full data distribution in
CAR-censored data and causal inference models: see also van der Laan et al.
 , van der Vaart et al. , van der Laan et al. , Dudoit and
van der Laan , Kele¸s et al. , Sinisi and van der Laan . This
research establishes, in particular, ﬁnite sample oracle inequalities, which state
that the expectation of the loss-function speciﬁc dissimilarity between the the
cross-validated selected estimator among the library of candidate estimators
(trained on training samples) and the truth is smaller or equal than the expectation of the loss-function speciﬁc dissimilarity between the best possible
selected estimator and the truth plus a term that is bounded by a constant
times the logarithm of the number of candidate estimators in the library divided by the sample size. The only assumption this oracle inequality relies
upon is that the loss function is uniformly bounded.
These oracle results
for the cross-validation selector inspired a uniﬁed super-learning methodology.
This methodology ﬁrst constructs a set of candidate estimators, proposes a
family of weighted combinations of these candidate estimators indexed by a
weight vector, and uses cross-validation to determine a weighted combination
with optimal cross-validated risk. Under the assumption that the loss function
is uniformly bounded, and the number of estimators is polynomial in sample
size, the resulting estimator (super learner) is either asymptotically equivalent
with the oracle selected estimator among the library of weighted combinations
of the estimators, or it achieves the optimal parametric rate of convergence
(i.e. one of estimators corresponds with correctly speciﬁed parametric model)
up till (worst case) log-n-factor. We refer to van der Laan et al. , Polley
and van der Laan .
The super-learning methodology applied to a loss function for the Gcomputation formula factor, Q0, of the observed data distribution, provides
substitution estimators of ψ0. However, although these super learners of Q0
are optimal w.r.t.
the dissimilarity with Q0 implied by the loss function,
the corresponding substitution estimators will be overly biased for a smooth
parameter mapping Ψ. This is due to the fact that cross-validation makes
optimal choices w.r.t. the (global) loss-function speciﬁc dissimilarity, but the
variance of Ψ(Qn) is of smaller order than the variance of Qn itself.
van der Laan and Rubin integrates the loss-based learning of Q0
into the locally eﬃcient estimation of pathwise diﬀerentiable parameters, by
enforcing the restriction in the loss-based learning that each candidate estimator of Q0 needs to be a targeted maximum likelihood estimator (thereby, in
particular, enforcing each candidate estimator of Q0 to solve the eﬃcient inﬂuence curve estimating equation). Another way to think about this is that each
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 2
DOI: 10.2202/1557-4679.1211
loss function L(Q) for Q0 has a corresponding targeted loss function L(Q∗),
Q∗representing the targeted maximum likelihood estimator applied to initial
Q, and we apply the loss-based learning to the latter targeted version of the
loss function L(Q). Rubin and van der Laan propose the square of
eﬃcient inﬂuence curve as a valid and sensible loss function L(Q) for selection
and estimation of Q0 in models in which g0 can be estimated consistently, such
as in randomized controlled trials.
The implications of this targeted loss-based learning are that Q0 is estimated optimally (maximally adaptive to the true Q0) w.r.t. the targeted
loss function L(Q∗) using the super-learning methodology, and due to the
targeted MLE step the resulting substitution estimator of ψ0 is now asymptotically linear as well if the targeted ﬂuctuation function is estimated at a
good enough rate (and only requiring adjustment by confounders not yet accounted for by initial estimator: see collaborative targeted MLE): either way,
asymptotic bias reduction for the target parameter will occur as long as the
censoring/treatment mechanism is estimated consistently. In addition, since
the targeted maximum likelihood step involves additional maximum likelihood
ﬁtting, generally speaking, no loss in bias will occur, even if the wished ﬂuctuation function is heavily misspeciﬁed.
Targeted MLE have been applied in a variety of estimation problems: Bembom et al. , Bembom et al. (physical activity), Tuglus and van der
Laan (biomarker analysis), Rosenblum et al. (AIDS), van der
Laan (case control studies), Rose and van der Laan (case control
studies), Rose and van der Laan (matched case control studies), Moore
and van der Laan (causal eﬀect on time till event, allowing for rightcensoring), van der Laan (adaptive designs, and multiple time point
interventions), Moore and van der Laan (randomized trials with binary
outcome). We refer to van der Laan et al. for collective
readings on targeted maximum likelihood estimation.
In van der Laan and Gruber we use the loss-based cross-validation
to not only select among diﬀerent initial estimators for the targeted maximum
likelihood estimators, but it is also used to select the ﬁt of the ﬂuctuation
function applied to the initial estimator (and thus the ﬁt of the censoring and
treatment mechanism). This results in a so called collaborative double robust
targeted maximum likelihood estimator, which utilizes the collaborative double
robustness of the eﬃcient inﬂuence curve, which is stronger robustness result
than the regular double robustness of the eﬃcient inﬂuence curve the double
robust estimators rely upon.
These collaborative double robust estimators
select confounders for the censoring and treatment mechanism in response
to the outcome and the initial estimator of Q0, thereby allowing for more
van der Laan: Targeted ML Causal Inference: Part I
eﬀective bias reductions by the resulting ﬂuctuation functions (as predicted by
theory and observed in practice). Simulations and data analysis illustrating the
excellent performance of the collaborative double robust T-MLE are presented
in van der Laan and Gruber .
The T-MLE in multi-stage sequentially randomized controlled trials
Consider a sequentially randomized trial in which one randomly samples a
patient from a population, one collects at baseline covariates L(0), and one
randomizes the patient to a ﬁrst line treatment A(0). Subsequently, one collects an intermediate biomarker L(1), and based on this intermediate clinical
response one randomizes the patient to a second line treatment A(1). Finally,
one collects the clinical outcome Y of interest at a ﬁxed point in time. This is
experiment is carried out for n patients.
We ﬁrst discuss two of such sequentially randomized cancer trials.
Anderson Cancer Center Prostate Cancer Two Stage Trial: Thall
et al. present an analysis of the ﬁrst clinical trial in oncology that makes
use of sequential randomization. During this trial, prostate cancer patients
who were found to be responding poorly to their initially randomly assigned
regimen (among four treatments) were re-randomized to the remaining three
candidate regimens. The clinical outcomes of interest was response to treatment at a particular point in time or time till death. In contrast to conventional
trials based on a single randomization, this design allows the investigator to
study adaptive treatment strategies that adjust a patients treatment in response to the observed course of the illness. Such adaptive strategies, also
referred to as dynamic or individualized treatment rules, form the basis of
common medical practice in cancer chemotherapy, with physicians typically
facing the following questions: Which regimen should be used to initially treat
a patient? Which regimen should the patient be switched to if the front-line
regimen fails? Given an observed intermediate outcome such as a change in
tumor size or PSA level, what threshold should be used to decide that the
current regimen is failing?
In recent years, sequentially randomized trials
have been recognized as being uniquely suited to the study of these exciting
questions , Lavori and Dawson , Lavori and Dawson
 , Murphy ), with researchers in other clinical areas also beginning
to implement this design , Schneider et al. , Swartz
et al. ). The original results of Thall et al. focus on ﬁtting logistic
regression models for the diﬀerent stage-speciﬁc factors of the likelihood. We
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 2
DOI: 10.2202/1557-4679.1211
can apply the T-MLE to estimate the mean outcomes under the 12 dynamic
treatment rules indexed by ﬁrst line therapy and the second line switching
therapy, and also incorporate the handling of the right-censoring.
E4494 Eastern Oncology Trial: Another example is the cancer trial
E4494, a lymphoma study of rituximab therapy that had both induction and
maintenance rituximab randomizations, where the second randomization of
maintenance versus observation was based on intermediate response to the
initial treatment. The clinical outcome of interest was time till death.
Let’s denote the observed data structure on a randomly sampled patient
from the target population with O = (L(0), A(0), L(1), A(1), Y = L(2)). For
simplicity and the sake of presentation, we will assume that A(0), L(1) and
A(1) are binary.
The likelihood can be factorized as
P(L(j) | ¯L(j −1), ¯A(j −1))
P(A(j) | ¯A(j −1), ¯L(j)),
where the ﬁrst factors will be denoted with QL(j), j = 0, 1, 2, and the latter
factors denote the treatment mechanism and are denoted with gA(j), j = 0, 1.
We make the convention that for j = 0, ¯A(j −1) and ¯L(j −1) are empty. In
a sequentially randomized controlled trial, the treatment assignment mechanisms gA(j), j = 0, 1, are known.
Suppose our parameter of interest is the treatment speciﬁc mean EYd for a
certain treatment rule d that assigns treatment d0(L(0)) at time 0 and treatment d1(¯L(1), A(0)) at time 1. For example, d0(L(0)) = 1 is a static treatment
assignment, and d1(¯L(1), A(0)) = I(L(1) = 1)1 + I(L(1) = 0)0 assigns treatment 1 if the patients responds well to the ﬁrst line treatment 1, and treatment
0 if the patients does not respond well to the ﬁrst line treatment 1. We note
that any treatment rule can be viewed as a function of ¯L = (L(0), L(1)) only,
and therefore we will use the shorter notation d(¯L) = (d0(L(0)), d1(¯L)) for the
two rules at times 0 and 1.
Note that EYd = Ψ(Q) for a well deﬁned mapping Ψ. Speciﬁcally, we have
Ψ(Q) = EPdY , where the intervened distribution Pd of (L(0), L(1), L(2)) is
deﬁned by the G-computation formula:
QL(j),d(¯L(j)),
where, for notational convenience, especially in view of our representation for
general data structures, we used the notation QL(j),d(¯L(j)) = QL(j)(L(j) |
¯L(j −1), A(j −1) = d(¯L(j −1))).
van der Laan: Targeted ML Causal Inference: Part I
Instead of computing an analytic mean under Pd, this mean can also be
approximated by simulating a large number of observations from this distribution and taking the mean of its last component L(2).
Note that Pd
corresponds with simulating sequentially from the conditional distributions
QL(0),d, QL(1),d, QL(2),d, for L(0), L(1), L(2), respectively. Alternatively, this
mean is calculated analytically as follows:
l(0),l(1),y
yPd(l(0), l(1), y)
Pd(l(0), l(1), y)
QL(0)(l(0))QL(1),d(l(0), l(1))QY,d(l(0), l(1), y).
If QL(0) is replaced by the empirical distribution, then this reduces to
QL(1),d(Li(0), l(1))QY,d(Li(0), l(1), y).
From this analytic expression it also follows that, even if Y is continuous,
Ψ(Q) only depends on the conditional distribution of Y through its mean.
In this case of a 2-stage sequentially randomized controlled trial, the analytic
evaluation of Ψ(Q) seems preferable since it will be very fast to compute.
With this precise deﬁnition of the parameter as a mapping from the conditional distributions QL(j), j = 0, 1, 2, to the real line, given an estimator Qn,
we obtain a substitution estimator Ψ(Qn) of ψ.
The targeted maximum likelihood estimator involves ﬁrst deﬁning an initial estimator of Q, and then a subsequent targeted maximum likelihood step
according to a ﬂuctuation function applied to this initial estimator, where this
step is tailored to remove bias from the initial estimator for the purpose of
estimating the parameter of interest ψ. The ﬂuctuation function equals the
least favorable parametric model through Q which is deﬁned as the parametric submodel through Q which makes estimation of Ψ(Q) hardest in the sense
that the parametric Cramer-Rao Lower bound for the variance of an unbiased
estimator is maximal among all parametric submodels. Intuitively, this is the
parametric submodel for which the maximum likelihood estimator listens as
much to the data w.r.t. ﬁtting the target parameter as an eﬃcient estimator
in the large semiparametric model, and thereby can expected to provide important bias reduction. This deﬁnition of least favorable model implies that
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 2
DOI: 10.2202/1557-4679.1211
a least favorable parametric model is a model that has a score at zero ﬂuctuation equal to the eﬃcient inﬂuence curve/canonical gradient of the pathwise
derivative of the target parameter Ψ.
We use the following Theorem that provides the representation of the eﬃcient inﬂuence curve which is needed to deﬁne the ﬂuctuation function. This
Theorem also provides the formula for the eﬃcient inﬂuence curve for other
parameters and for higher (than two) stage RCT’s.
Theorem 1 The eﬃcient inﬂuence curve for ψ = EYd at the true distribution
P0 of O can be represented as
D∗= Π(DIPCW | TQ),
DIPWC(O) = I( ¯A = d(¯L))
g(d(¯L) | X) Y −ψ,
TQ is the tangent space of Q in the nonparametric model, and Π denotes the
projection operator onto TQ in the Hilbert space L2
0(P0) of square P0-integrable
functions of O, endowed with inner product ⟨h1, h2⟩= EP0h1h2(O).
We have that this subspace
is the orthogonal sum of the tangent spaces TQL(j) of the QL(j)-factors, which
consists of functions of L(j), Pa(L(j)) with conditional mean zero, given the
parents Pa(L(j)) of L(j), j = 0, 1, 2. Recall that we also denote L(2) with Y .
j = Π(D∗| TQL(j)), j = 0, 1, 2.
E(Yd | L(0)) −ψ
I(A(0) = d0(L(0))
g(d0(L(0)) | X)
CL(1)(Q0)(1) −CL(1)(Q0)(0)
{L(1) −E(L(1) | L(0), A(0))}
L(2) −E(L(2) | ¯L(1), ¯A(2))
where, for δ ∈{0, 1},
CL(1)(Q0)(δ) = E(Yd | L(0), A(0), L(1) = δ).
van der Laan: Targeted ML Causal Inference: Part I
We note that
E(Yd | L(0), A(0) = d0(L(0)), L(1)) = E(Y |
¯L(1), ¯A = d(¯L)).
For general data structure O = L(0), A(0), . . . , L(K), A(K), Y = L(K +1),
and DIPCW = D1(O)/g(A | X) for some D1, we have
Π(DIPCW | TQL(j)) =
g(A(j−1)|X)
¯a(j,K) D1(¯a(j, K)) | ¯L(j), ¯A(j −1))
¯a(j,K) D1(¯a(j, K)) | ¯L(j −1), ¯A(j −1))
g(A(j−1)|X)CL(j)(¯L(j −1), ¯A(j −1))(L(j) −E(L(j) | ¯L(j −1), ¯A(j −1)),
D1(¯a(j, K)) | L(j) = 1, ¯L(j −1), ¯A(j −1))
D1(¯a(j, K)) | L(j) = 0, ¯L(j −1), ¯A(j −1))
Here we use the short-hand notation ¯a(j, K) ≡(a(j), . . . , a(K)) and D1(¯a(j, K)) =
D1(A(j −1), ¯a(j, K), ¯L¯a(j,K)(K + 1)).
This Theorem allows us now to specify the targeted maximum likelihood
estimator.
The targeted maximum likelihood estimator: Consider now an initial estimator QL(j)n of each QL(j), j = 0, 1, 2.
We will estimate the ﬁrst
marginal probability distribution QL(0) of L(0) with the empirical distribution
of Li(0), i = 1, . . . , n. We can estimate the conditional distributions of the
binary L(1) and the conditional mean of Y = L(2) with machine learning algorithms (using logistic link for QL(1), and, if Y is binary, also for QY ) such as
the super learner represented by a data adaptively (based on cross-validation)
determined weighted combination of a user supplied set of candidate machine learning algorithms estimating the particular conditional probability.
We will now deﬁne ﬂuctuations of this initial estimator QL(1)n = QL(1)n(Pn)
and QL(2)n = QL(2)(Pn) which are particular functions of the empirical probability distribution Pn. We will use notation Qn = (QL(1)n, QL(2)n). Firstly,
LogitQL(1)n(ϵ) = LogitQL(1)n + ϵCL(1)(Qn, gn)
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 2
DOI: 10.2202/1557-4679.1211
be the ﬂuctuation function of QL(1)n with ﬂuctuation parameter ϵ, where we
added the covariate CL(1)(Q, g) deﬁned as
I(A(0) = d0(L(0))
gA(0(d0(L(0)) | X){CL(1)(Q)(1) −CL(1)(Q)(0)},
where CL(1)(Q)(δ) = EQ(Yd | L(0), A(0), L(1) = δ). We refer to these covariate choices as clever covariates, since they represent a covariate choice that
identiﬁes a least favorable ﬂuctuation model, thereby providing the wished
targeted bias reduction. Similarly, if Y = L(2) is binary, then let
LogitQL(2)n(ϵ) = LogitQL(2)n + ϵCL(2)(Qn, gn),
where the added the clever covariate
CL(2)(Q, g)(¯L(1), ¯A(1)) = I( ¯
g(A | X) .
If Y is continuous, then we use as ﬂuctuation model the normal densities with
mean EQY n(Y | Pa(Y ))+ϵCL(2)(Qn, gn), and constant variance σ2, so that the
MLE of ϵ is the linear least squares estimator, and the score of ϵ at ϵ = 0 is
CL(2)(Y −EQ(Y | Pa(Y ))), as required. We note that the above ﬂuctuation
function indeed satisﬁes that the score of ϵ at ϵ = 0 equals the eﬃcient inﬂuence
curve D∗(Qn, gn) as presented in the Theorem above.
One now estimates ϵ with the MLE.
ϵn = arg max
QL(j)n(ϵ)(Oi).
One could also obtain a separate MLE of ϵ for each factor j = 1, 2. This process
is now iterated till convergence, which deﬁnes the targeted MLE (Q∗
starting at initial estimator (Qn, gn), which does not involve updating of gn.
We note that the ϵn for each factor separately can be estimated with standard logistic regression or linear regression software using as oﬀ-set the logit of
the initial estimator and having a single clever covariate CL(j)(Q, g), j = 1, 2.
If Y is also binary, the single/common ϵn deﬁned above requires applying a
single logistic regression applied to repeated measures data set with one line of
data for each of two factors, creating a clever covariate column that alternates
the clever covariates CL(1) and CL(2), and using the corresponding oﬀ-sets. So
in both cases (separate or common ϵ), the update step can be carried out with
a simple univariate logistic regression maximum likelihood estimator. Computing a common ϵ in the case that we use linear regression for Y and logistic
regression for L(1) requires some programming.
van der Laan: Targeted ML Causal Inference: Part I
We note that the clever covariate changes at each update step since the
estimator of Q is updated at each step and the clever covariate is deﬁned by
the current Q-ﬁt. Let Q∗
L(j)n, j = 1, 2, and Q∗
n denote the ﬁnal update (at
convergence of the MLE of ϵ to zero) of QL(j)n, j = 1, 2, and Qn, respectively.
The T-MLE of ψ is now given by Ψ(Q∗
A one-step T-MLE: Interestingly, if we use a separate ϵL(j) for j = 1, 2,
ﬁrst carry out the tmle update for QL(2)n, and use this updated Q∗
L(2)n in the
targeted MLE update for QL(1)n, then we obtain a targeted MLE-algorithm
that converges in two simple steps, representing a single step update of Qn.
Below, we will generalize this one-step targeted MLE algorithm for updating
an initial Qn for general longitudinal data structures.
Statistical inference for T-MLE: Let D∗(Q, g) be the eﬃcient inﬂuence
curve at pQ,g = Q∗g, as deﬁned in the above Theorem.
Under regularity
conditions, the T-MLE is consistent and asymptotically linear with inﬂuence
curve D∗(Q∗, g0), where Q∗denotes the limit of Q∗
n, and g0 is the true treatment
mechanism. As a consequence, for construction of conﬁdence intervals and
testing one can use as working model ψ∗
n ∼N(ψ0, Σ0), where Σ0 = ED∗(Q, g0)2
is the variance of the eﬃcient inﬂuence curve at (Q∗, g0). Here Σ0 can be
estimated with the empirical covariance matrix of D∗(Q∗
n, g0)(Oi), i = 1, . . . , n.
Targeted Loss-based selection among T-MLE’s indexed by different initial estimators: Sequentially randomized trials allow us to select a targeted loss function for selection among diﬀerent targeted maximum
likelihood estimators indexed by diﬀerent initial estimators. For the sake of
illustration, we assume ψ0 is one-dimensional.
Suppose a collection of initial estimators is available for Q0. Let Q∗
k(Pn) be the corresponding
targeted maximum likelihood estimators, k = 1, . . . , K. One of these initial estimators might correspond with a super learner based on the log-likelihood loss
function. We can select among these targeted maximum likelihood estimators
based on cross-validated risk of the loss function
L(Q) ≡D∗(Q, g0)2,
which is indeed a valid loss function since it satisﬁes Q0 = arg minQ E0L(Q)(O)
among all Q with Ψ(Q) = ψ0. The latter loss function is now a loss function
for the whole Q and is very targeted towards ψ0 since it corresponds exactly
with the asymptotic variance of the targeted MLE. Thus, we would select k
with the cross-validation selector:
kn = ˆk(Pn) = arg min
n,Bn), g0)2,
where Bn ∈{0, 1}n denotes a random vector of binaries indicating a split
in training sample {i : Bn(i) = 0} and validation sample {i : Bn(i) = 1},
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 2
DOI: 10.2202/1557-4679.1211
n,Bn, are the corresponding empirical distributions of the training and
validation sample. Here we used the notation Pf ≡
f(o)dP(o). The selected
targeted maximum likelihood estimator is then Q∗
kn(Pn), and ψ0 is now
estimated with the substitution estimator Ψ(Q∗
Assuming a uniformly bounded loss function (i.e., a uniform bound on the
eﬃcient inﬂuence curve), due to oracle results of the cross-validation selector,
the resulting targeted maximum likelihood estimator Ψ(Q∗
n) will be at least
as eﬃcient as any of the candidate targeted maximum likelihood estimators
kn), k = 1, . . . , K.
Construction of Targeted Initial estimators: Above we showed that
the projection of the eﬃcient inﬂuence curve on the tangent space of the conditional distribution of L(1) can be written as CL(1)(L(1) −QL(1)), and for
Y = L(2), as CL(2)(L(2) −QL(2)), where we use short-hand notation. For
the purpose of constructing an initial estimator of QL(1), we can use lossbased learning based on the weighted squared-error loss function L1(QL(1)) =
L(1)(L(1) −QL(1))2, and, similarly, for the purpose of constructing of an initial estimator of QL(2), we can use loss-based learning based on the weighted
squared-error loss function L2(QL(2)) = C2
L(2)(Y −QL(2))2. These are targeted
loss functions since they correspond with the components of the variance of
the eﬃcient inﬂuence curve. Since the clever covariate CL(2) only depends on
g0, the required weights C2
L(2) for loss-based learning of QL(2) are completely
known. Therefore, we ﬁrst apply the loss-based learning of the true QL(2)0.
Let, QL(2)n be the resulting estimator. Now, we plug such an estimator into
the weight-function CL(1), and we use the resulting weights C2
L(1) to apply lossbased learning of QL(1). In this way, using this backwards sequential loss-based
learning, we can generate initial candidate estimators of QL(1), QL(2) that are
themselves already targeted by being based on these weighted squared-error
loss functions (e.g. using diﬀerent regression algorithms but using the weight
option). We can now select among the targeted MLE indexed by these diﬀerent
targeted initial estimators, by using cross-validation with the above mentioned
loss function L(Q) = D∗(Q, g0)2.
As might already be apparent, and certainly becomes apparent in the next
section, this powerful approach combining loss-based learning with targeted
MLE for the analysis of the simple two-stage sequentially randomized controlled trial generalizes to all sequentially randomized controlled trials for any
target parameter, any number of stages, and higher dimensional intermediate
time-dependent covariates.
We remark that the above targeted maximum likelihood estimator can also
be applied to the data structure L(0), A(0), L(1), ∆, L(2) = ∆Y , where A(0) is
a treatment assigned at baseline (e.g, RCT), L(1) represents the data collected
van der Laan: Targeted ML Causal Inference: Part I
between baseline and the time point at which the outcome Y is measured, and
∆is a missing indicator for Y . One simply applies the above data structure
with A(2) = ∆. Oﬀcourse, if L(1) is not binary, then the above estimator
needs to be generalized as carried out in the next section, and, the missingness
mechanism might need to be estimated from the data.
Targeted MLE of parameters of the
G-computation formula.
We will now present the general approach to obtain a targeted maximum likelihood estimator, including the selection among diﬀerent targeted maximum
likelihood estimators indexed by diﬀerent initial estimators. The choice of loss
function we will use for the latter will depend on if one is willing to assume
that the treatment/censoring mechanism is correctly estimated (or known, as
in a S-RCT), or that one wishes to rely on double robustness, and we will
provide appropriate loss functions for both purposes. This will generalize the
above targeted maximum likelihood estimator for a two-stage sequentially randomized controlled trial to arbitrary sequentially randomized controlled trials,
including S-RCT’s that are subject to right-censoring or missingness and for
which one is willing to assume that censoring/missingness is well understood.
In addition, it will present the double robust T-MLE for observational studies.
Organization: Firstly, we will present the likelihood using binary coding of the data structure O. Second, we will present a representation of the
eﬃcient inﬂuence curve based on this binary factorization of the likelihood.
Third, we present the ﬂuctuation/least favorable model of the initial estimate
and the corresponding targeted maximum likelihood estimator. Fourth, we
present a closed form one-step version of this targeted maximum likelihood
estimator that applies if one is willing to ﬁt a separate ﬂuctuation parameter for each factor of the G-computation formula factor of the likelihood.
Fifth, we present a targeted loss function that can be used to select among
diﬀerent targeted maximum likelihood estimators indexed by diﬀerent initial
estimators. We also present a particular type of targeted maximum likelihood
estimator that uses a degenerate initial estimator for the intermediate factors
of the G-computation formula, so that the targeted MLE algorithm only requires updating the ﬁnal outcome conditional distribution. Finally, we make
some observations regarding the pursuit of targeted dimension reductions simplifying the G-computation formula, which can form an important ingredient
for generating diﬀerent candidate targeted MLE’s, and control complexity.
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 2
DOI: 10.2202/1557-4679.1211
A factorization of likelihood of data in terms of binary variables.
Suppose the data structure O = (L(0), A(0), . . . , L(K), A(K), L(K + 1)) for
one unit involves collection of treatment and censoring actions coded with
A(t) at times t = 0, . . . , K, and time-dependent covariate and outcome data
at times t = 0, . . . , K + 1. We note that L(t) can become degenerate after
censoring and or after a terminal event like death, so that this data structure O
also allows for longitudinal data structures that are truncated by the minimum
of right-censoring and death. By choosing a ﬁne enough discretization in time
this data structure also approximates treatment and censoring processes A(t)
that evolve in continuous time.
For the sake of presentation, we will assume that A(t) and L(t) are discrete
valued for all t so that the likelihood of O can be expressed in terms of probabilities, thereby avoiding technical diﬃculties regarding choice of dominating
measure, without aﬀecting the realm of practical applications.
The time ordering implies a graph with observed nodes L(t), t = 0, . . . , K+
1, and A(t), t = 0, . . . , K, and a corresponding factorization of the observed
data likelihood of O, given by
where QL(t) and gA(t) denote the conditional probability distributions of L(t),
given parents Pa(L(t)), and A(t), given parents Pa(A(t)), respectively. The
parent sets could be known to be subsets of the parent set implied by the time
ordering of data structure, as discussed in introduction.
This factorized likelihood can be subjected to static and dynamic interventions on the A() process mapping the probability distribution of O into
probability distributions of Od corresponding with a static or dynamic intervention d, often referred to as the G-computation formula. These interventions
could involve all A-nodes as well as a subset of these nodes. The corresponding probability distributions of Od are obtained by removing the gA(t)’s corresponding with the A(t) nodes on which an intervention is carried out under
rule d, and substituting for A(t) in the conditioning events (i.e., parents) of
the QL(l)-factors with l > t the corresponding intervened values.
In many applications A(t) = (A1(t), A2(t)) involves two types of actions
A1(t) and A2(t), both relevant for deﬁning the parameter of interest of the
probability distribution of O.
For example, A1(t) might be the treatment
assigned at time t, A2(t) might be an indicator of being right-censored at time t,
van der Laan: Targeted ML Causal Inference: Part I
and the scientiﬁc parameter of interest, Ψ(P0), might be deﬁned as a parameter
of the distribution of O under the intervention on A deﬁned by no-censoring
at any time point, and a certain treatment intervention. In many cases, one
deﬁnes the scientiﬁc parameter of interest in terms of changes of the latter
distribution under diﬀerent treatment regimens, and always no censoring: for
example, marginal structural models for static or realistic dynamic treatment
regimens provide such parameters, as we demonstrate in Section 5.
We will consider the case that for each node, the model for the conditional
distributions of a nodes, given the parents, is nonparametric. Let Ψ be the
parameter mapping so that ψ0 = Ψ(P0) denotes the parameter of interest.
Without loss of generality, we assume that, for each t ∈{1 . . . , K + 1},
L(t) can be coded in terms of n(t) binary variables {L(t, j) : j = 1, . . . , nt}, so
that QL(t) can be further factorized as
where we deﬁne QL(t,j) as the conditional distribution of L(t, j), given its
parents Pa(L(t, j)) deﬁned as the parents of L(t) augmented with the ﬁrst j−1
variables L(t, 1), . . . , L(t, j −1), l = 1, . . . , j −1. Note that this factorizations
depends on a user-supplied ordering of the binary variables. For example, this
particular coding and ordering might be implied by what is considered natural.
The choice of coding and ordering does not aﬀect the theoretical properties
of the resulting targeted MLE, but it does imply the binary predictors QL(t,j)
one will need to estimate from the data.
This now provides the following likelihood factorization for the probability
distribution of O:
p0 = QL(0)
where QL(0) denotes the marginal distribution of the baseline covariates L(0).
General representation of eﬃcient inﬂuence curve
of target parameter.
We will now work out a general representation of the eﬃcient inﬂuence curve we
can apply to implement the targeted maximum likelihood estimator for general
longitudinal data structures.
These results provide us with a template for
implementing the targeted maximum likelihood estimator for nonparametric
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 2
DOI: 10.2202/1557-4679.1211
models and essentially any type of longitudinal data structure that includes
time dependent treatments and censoring actions that are realized in response
to previously collected data.
Recall that in our model for P0, for each node in the statistical graph, the
conditional distribution is unspeciﬁed. Let Ψ be the parameter mapping so
that ψ0 = Ψ(P0) denotes the parameter of interest. If Ψ(P0) = ΨF(Q0) is only
a parameter of the Q0, then we can present the eﬃcient inﬂuence curve of Ψ
as the projection of any inﬂuence curve (i.e., gradient of path-wise derivative)
in the model in which g is known onto the tangent space of Q ):
D∗= Π(D | TQ) for a certain gradient D.
Such an estimating function D is often called an IPCW-estimating function
 ). We will now be concerned with ﬁnding
a representation of this eﬃcient inﬂuence curve in terms of an orthogonal
sum of scores of certain ﬂuctuations Q(ϵ) of Q at ϵ = 0, thereby implying a
corresponding implementation of the targeted MLE.
The factorization (1) of the distribution P0 implies an orthogonal decomposition of the tangent space at P0 in our model, where this tangent
space is a subspace of the Hilbert space L2
0(P0) endowed with inner product ⟨h1, h2⟩= EP0h1(O)h2(O). This orthogonal decomposition of the tangent
space T(P0) ⊂L2
0(P0 is given by
T(P0) = TL(0) +
TL(t,j) + TCAR,
where TL(0) is the tangent space of QL(0) consisting of the functions of L(0)
with mean zero, TL(t,j) is the tangent space of the conditional probability
distribution QL(t,j),
V (L(t, j) | Pa(L(t, j))) −EQL(t,j)V : V
{V (1 | Pa(L(t, j))) −V (0 | Pa(L(t, j))} (L(t, j) −QL(t,j)(1)) : V
and TCAR is the tangent space of g. TCAR can also be orthogonally decomposed
t=0 TA(t) with TA(t) the tangent space of gA(t). Here we used the notation
EQL(t,j)V = E(V | Pa(L(t, j))) for the conditional expectation w.r.t. QL(t,j). If
the parent sets are all implied by a speciﬁed ordering of all measured variables,
then the model for P0 is actually the nonparametric model so that the tangent
space is saturated: T(P0) = L2
van der Laan: Targeted ML Causal Inference: Part I
In the case that Ψ(P0) is a parameter of both Q0 and g0, the eﬃcient in-
ﬂuence curve D∗will also have components in TCAR. An example of such a
target parameter is E(Y (1) −Y (0) | A = 1), the eﬀect among the treated,
based on observed data (W, A, Y ) and the causal graph implied by time ordering W, A, Y . In that case the targeted MLE will also need to ﬂuctuate an initial
ﬁt of g0 with a ﬂuctuation having a score that coincides with the eﬃcient inﬂuence curve. For that purpose, let’s also code A(t) in terms of binary variables.
Let A(t) be coded in terms of binary variables {A(t, j) : j = 1, . . . , m(t)}, and
consider the factorization
where an ordering needs to be speciﬁed so that the parents of A(t, j) are given
by the parents of A(t) augmented with A(t, 1), . . . , A(t, j −1).
The corresponding orthogonal decomposition of the tangent space of g is
TA(t,j) = {V (A(t, j) | Pa(A(t, j))) −E(V | Pa(A(t, j))) : V }
= {{¯V (Pa(A(t, j))(A(t, j) −gA(t,j)(1 | Pa(A(t, j))) : V },
where we used the notation ¯V (Pa(A(t, j)) = V (1 | Pa(A(t, j))) −V (0 |
Pa(A(t, j)), which thereby can represent any function of Pa(A(t, j)).
This factorization p(O) = Q
j gA(t,j) yields the orthogonal
decomposition of the tangent space T(P0) given by
T(P0) = TL(0) +
We can now state the corresponding Theorem for both a representation of a
given eﬃcient inﬂuence curve D∗as well as a projection of a function D, (e.g.)
representing an ineﬃcient inﬂuence curve for a parameter Ψ(P) = ΨF(Q) in
a model with g known, onto the tangent space TQ of Q.
Theorem 2 Consider the Hilbert space L2
0(P0) and the factorization (1) of
P0. A function D ∈L2
0(P0) which is also an element of the tangent space
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 2
DOI: 10.2202/1557-4679.1211
T(P0) can be represented as
D = DL(0) +
E(D | L(0)) −ED
Π(D | TL(t,j))
CL(t,j){L(t, j) −QL(t,j)(1)},
CL(t,j) = E(D | L(t, j) = 1, Pa(L(t, j))) −E(D | L(t, j) = 0, Pa(L(t, j))),
for t = 1, . . . , K + 1, and, for each t, j = 1, . . . , n(t). In addition,
Π(D | TA(t,j))
CA(t,j){A(t, j) −gA(t,j)(1)},
CA(t,j) = E(D | A(t, j) = 1, Pa(A(t, j))) −E(D | A(t, j) = 0, Pa(A(t, j))).
In particular, the projection of D onto the tangent space TQ of Q can be
represented as
Π(D | TQ) = D0 +
If we represent D as D(O) = D1(A, L(A))/g(A | X) for some D1, X =
(L(a) : a), La(t) = L¯a(t−1)(t), assume that Pa(L(t, j)) = (
A(t−1), Pa ¯A(t−1)(L(t, j))
includes ¯A(t −1), then the above representation of Π(D | TQ) applies with
g(A(t−1)|Pa(L(t))) ×
CL(t,j)(Q)(1) −CL(t,j)(Q)(0)
where, for δ ∈{0, 1},
CL(t,j)(Q)(δ) = EQ
D1 | L¯a(t−1)(t, j) = δ, Pa¯a(t−1)(L(t, j))
¯a(t−1)= ¯
Above, we used short-hand notation for P
¯a(t,K) D1(
a(t, K), LA(t−1)
and ¯a(t, K) = (a(t), . . . , a(K)). Here g(¯a(t −1) | Pa(L(t))) denotes the conditional probability of ¯A(t−1) = ¯a(t−1), given Pa¯a(t−1)(L(t)), and it also equals
the conditional probability of ¯A(t −1) = ¯a(t −1), given La(t, j), Paa(L(t, j)).
van der Laan: Targeted ML Causal Inference: Part I
Proof of Theorem. We only need to prove the latter representation of CL(t,j).
We have D(A, L(A)) = D1(A, L(A))/g(A | X), and we consider the case
that Pa(L(t, j)) includes ¯A(t −1). For the sake of this proof we exclude the
treatment nodes ¯A(t −1) from Pa(L(t, j)). Setting A(t −1) = ¯a(t −1), gives
us the following conditional expectation to consider
E(D1(A)/g(A | X) | L(t, j), Pa(L(t, j)), A(t −1) = ¯a(t −1)).
We ﬁrst condition on X and ¯A(t−1). This corresponds with taking an expectation w.r.t. QK
s=t g(A(s) | Pa(A(s))). This gives us
D1(¯a)/g(¯a(t −1) | X) | L¯a(t, j), Pa¯a(L(t, j)), ¯A(t −1) = ¯a(t −1)).
This conditional expectation for each ¯a(t, K)-speciﬁc term is a sum over La
compatible with La(t, j), Paa(L(t, j)). Speciﬁcally,
g(¯a(t−1)|X)P(La | La(t, j), Paa(L(t, j)), ¯A(t −1) = ¯a(t −1))
g(¯a(t−1)|X)
P(La,La(t,j),Paa(L(t,j)),A(t−1)=¯a(t−1))
P(La(t,j),Paa(L(t,j)),A(t−1)=¯a(t−1))
{La:La(t,j),Paa(L(t,j))} D1(¯a)
P(La(t,j),Paa(L(t,j)),A(t−1)=¯a(t−1))
g(¯a(t−1)|La(t,j),Paa(L(t,j))
{La:La(t,j),Paa(L(t,j))} D1(¯a)
P(La(t,j),Paa(L(t,j)))
g(¯a(t−1)|La(t,j),Paa(L(t,j))EQ(D1(¯a) | La(t, j), Paa(L(t, j)).
We will now prove that, by conditional independence assumptions of the statistical graph, g(¯a(t −1) | La(t, j), Paa(L(t, j))) = g(¯a(t −1) | Paa(L(t))). To
see this we ﬁrst note that g(¯a(t −1) | La(t, j), Paa(L(t, j))) equals
g(¯a(t −1) | ¯La(t −1))P(¯La(t −1) | La(t, j), Paa(L(t, j))).
Since Paa(L(t, j)) are the parents of La(t, j), we have
P(¯La(t −1) | La(t, j), Paa(L(t, j))) = P(¯La(t −1) | Paa(L(t, j))). Thus, this
g(¯a(t −1) | La(t, j), Paa(L(t, j))) = g(¯a(t −1) | Paa(L(t, j))).
More general, recall La(t, j), Paa(L(t, j)) = La(t, 1), . . . , La(t, j), Paa(L(t)),
and note that Paa(L(t)) is included in ¯La(t−1) (recall, that we excluded A(t−
1) from Pa(L(t, j)) in this proof). We have La(t, 1), . . . , La(t, j) is independent
of ¯La(t −1), given Paa(L(t)). So we obtain
P(¯La(t −1) | La(t, j), Paa(L(t, j)))
= P(¯La(t −1) | La(t, 1), . . . , La(t, j), Paa(L(t)))
= P(¯La(t −1) | Paa(L(t))).
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 2
DOI: 10.2202/1557-4679.1211
This shows
g(¯a(t −1) | La(t, j), Paa(L(t, j))) = g(¯a(t −1) | Paa(L(t))).
To conclude, we have shown
¯a(t,K) D1(¯a)
g(¯a(t−1)|X) | L¯a(t, j) = 1, Pa¯a(L(t, j)), ¯A(t −1) = ¯a(t −1)
g(¯a(t−1)|Paa(L(t)))E(P
¯a(t,K) D1(¯a) | L¯a(t−1)(t, j) = 1, Pa¯a(t−1)(L(t, j))),
which completes the proof. 2
Remark about double robustness of eﬃcient inﬂuence curve for general statistical graph:
The eﬃcient inﬂuence curve D∗at P depends on
the Q-factor as well as a g representing conditional distributions of A(t) nodes,
possibly conditioning on subsets of the actual parents of A(t). It is immediate that P0D∗(Q0, g) = 0 at possibly miss-speciﬁed g.
To understand the
possible additional robustness P0D∗(Q, g0) for Q with Ψ(Q) = Ψ(Q0) and
correctly speciﬁed g0, and thereby the so called double robustness of the eﬃcient inﬂuence curve ), we make the following
observation. By our latter representation in the above theorem, we have
D∗(Q, g) = P
t 1/g(A(t −1) | (Paa(L(t)) : a))
¯a(t,K) D1(¯a(t −1), ¯a(t, K)) | La(t) = L(t), Pa¯a(t−1)(L(t)) = Pa(L(t)))
¯a(t,K) D1(¯a(t −1), ¯a(t, K)) | Pa¯a(t−1)(L(t)))
¯a(t−1)= ¯
where we also have that g(
1) | (Paa(L(t)) : a)) = g(
1) | (La(t), Paa(L(t)) :
a)), as we showed in the proof above. If we now take the conditional mean,
given (La(t), Paa(L(t)) : a), within the P
t-summation, then this corresponds
with integration over g0(A(t −1) | (Paa(L(t)) : a)).
Thus at a correctly
speciﬁed g0, we obtain that P0D∗(Q, g0) equals
{EQ(D1(¯a) | La(t), Paa(L(t))) −EQ(D1(¯a) | Paa(L(t)))} ,
thereby giving us an expression that does only depend on the Q0-factor of
the distribution of the data (thus nothing to do anymore with the conditional
treatment probabilities).
Some additional structure is now needed on the
statistical graph to have that the latter equals zero at miss-speciﬁed Q. In
particular, if Pa(L(t)) = ¯A(t −1), ¯L(t −1) represents the history according
to the time-ordered sequence representing the longitudinal data structure O,
it follows, through cancelation of terms, that the latter equals EQ0
¯a D1(¯a),
thereby giving the wished result for nonparametric full data models).
van der Laan: Targeted ML Causal Inference: Part I
Using normal error regression to model and ﬂuctuate conditional
ﬁnal outcome distribution.
Consider the case that Ψ(Q0) only depends on
the conditional distribution of a ﬁnal outcome Y = L(K +1), given its parents
Pa(Y ) through its conditional mean, and that the projection of the eﬃcient
inﬂuence curve (or any other gradient in model with g known) onto the tangent
space of this conditional distribution QY can be written as CY (Y −EQ(Y |
Pa(Y )) for some function CY of its parents Pa(Y ). Then it follows that there
is no need to factorize the conditional distribution of Y in binary conditional
distributions, but one could model the conditional distribution of Y with a
normal error mean regression, and ﬂuctuate the mean by adding the clevercovariate extension ϵCY . This was explicitly illustrated in Section 2 for the
targeted MLE of EYd.
The targeted MLE based on the binary representation of density
In this subsection we will deﬁne the targeted MLE based on the representation
(1) of the density of O in terms of the binary predictors QL(t,j), and, for the sake
of presentation, we assume that our target parameter is only a parameter of
Q0. Consider an initial estimator QL(t,j)n of each QL(t,j), t = 1, . . . , K + 1, j =
1, . . . , n(t). We will estimate the ﬁrst marginal probability distribution QL(0)
of L(0) with the empirical distribution of Li(0), i = 1, . . . , n. Let Qn denote
the combined set of QL(t,j)n across all nodes L(t, j).
The conditional distributions of L(t, j) are binary distributions which we
can estimate with machine learning algorithms (using logistic link) such as the
super learner represented by a data adaptively (based on cross-validation) determined weighted combination of a user supplied library of machine learning
algorithms estimating the particular conditional probability. These estimates
could be obtained separately for each t, j or smoothing across time points t
and or j could be employed if appropriate, by applying such machine learning algorithms to an appropriately constructed repeated measures data set.
In particular, candidate estimators could be based on (guessed) subsets of
Pa(L(t, j)).
In addition, let gn be an estimator of g0. We will now deﬁne the following
ﬂuctuations of the initial estimator QL(t,j)n = QL(t,j)(Pn) of QL(t,j):
LogitQL(t,j)n(ϵ) = LogitQL(t,j)n + ϵCL(t,j)(Qn, gn),
where we added the clever covariate CL(t,j)n obtained by substitution of the
initial estimator Qn and gn of the true Q0 and g0.
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 2
DOI: 10.2202/1557-4679.1211
One can now estimate ϵ with the MLE.
ϵn = arg max
QL(t,j)n(ϵ)(Oi).
One could also obtain a separate MLE of ϵ for each factor indexed by (t, j):
ϵL(t,j)n = arg max
QL(t,j)n(ϵ).
One can now set Q1
n = Qn(ϵn) to update Qn. This updating process Qm
n ), m = 1, . . . , is now iterated till convergence, which deﬁnes the
targeted MLE starting Q∗
n at initial estimator (Qn, gn).
We note that the ϵL(t,j)n for each factor separately can be estimated with
standard logistic regression software using as oﬀ-set the logit of the initial
estimator and having a single clever covariate CL(t,j)(Qn, gn). The single ϵn
(uniform across t, j) deﬁned above requires applying a single univariate logistic
regression applied to repeated measures data set with one line of data for each
factor indexed by (t, j), creating a clever covariate column that stacks (CL(t,j) :
t, j) for each unit, and using the corresponding oﬀ-set covariate logitQL(t,j)n.
So in both cases, the update step can be carried out with a simple univariate
logistic regression maximum likelihood estimator using the oﬀ-set command
(applied to a possibly repeated measures data set).
We note that the clever covariate changes at each update step since the
estimator of Q is updated at each step and the clever covariate is deﬁned by
the current Q-ﬁt in the iterative algorithm. Let Q∗
L(t,j)n and Q∗
n denote the
ﬁnal update (at convergence of the MLE of ϵ to zero) of QL(t,j)n, and Qn. The
targeted MLE of ψ0 is now given by Ψ(Q∗
A targeted MLE based on the binary predictor representation of density that converges in one step
In this section we will deﬁne a fast targeted MLE based on the representation
(1) of the density of O in terms of the binary predictors QL(t,j).
Consider an initial estimator QL(t,j)n of each QL(t,j), t = 1, . . . , K + 1, j =
1, . . . , n(t). We will estimate the ﬁrst marginal probability distribution QL(0)
of L(0) with the empirical distribution of Li(0), i = 1, . . . , n. Let Qn denote
the combined set of QL(t,j)n across t, j.
In addition, let gn be an estimator of g0. As above, we deﬁne the following
ﬂuctuations of the initial estimator QL(t,j)n of QL(t,j):
LogitQL(t,j)n(ϵ) = LogitQL(t,j)n + ϵCL(t,j)(Qn, gn),
van der Laan: Targeted ML Causal Inference: Part I
where we added the clever covariate CL(t,j)n obtained by substitution of the
initial estimator Qn and gn of the true Q0 and g0.
Monotone dependence on Q-property of the clever covariates:
Consider the clever covariate representations of CL(t,j) presented in the above
Theorem 2 for QL(t,j) for the case that D = D1/g with D1 not indexed by
Q, g. Then the conditional expectations in the deﬁnition of the clever covariate
CL(t,j) only depends on Q through {QL(s,l) : s > t, l} ∪{QL(t,l) : l > j}.
Let’s enumerate all terms QL(t,j) for t ≥1 by moving row-wise: thus Q1 =
Q11, Q2 = Q12, . . ., Qn(1) = Q1n(1), Qn(1)+1 = Q21, and so on till QN =
QK+1,n(K+1), where N = PK+1
t=1 n(t). Here we used temporarily the notation
Q12 = QL(1,2) and so on. Recall that QL(0), the marginal distribution of L(0),
does not need to be ﬂuctuated, and is thus not considered here: we will always
estimate QL(0) with the empirical distribution, so that no ﬂuctuation is needed.
Under this ordering, the k-th clever covariate Ck only depends on Q through
Qk+1, . . . , QN, k = 1, . . . , N. In particular, CN does not depend on Q at all,
while CN−1 depends on QN only, CN−1 depends on QN−1, QN, and so on. We
refer to this property of the clever covariates as the monotone dependence (on
Q) property, which will have an immediate implication for the corresponding
iterative T-MLE algorithm.
We denote this monotonicity property with Ck(Q) = Ck(Qk+1, . . . , QN),
where we suppress the dependence on g since in the targeted MLE algorithm
presented below g will not be updated.
We obtain a separate MLE of ϵ for each factor, but we start with last factor
ﬁrst, and use the update of last factor in clever covariate of N −1-th factor,
carry out update of N −1-th factor, use the update of N −1-th factor in
clever covariate of N −2-th factor, and so on till we update the ﬁrst factor
based on ﬁrst clever covariate including all previously obtained updates. One
could now start over, since Qn got updated during this particular round of
updating steps, and apply the same round of updating steps to the update of
Qn, and iterate this till convergence. The below Theorem states that this is
not necessary, since the algorithm has converged after one round.
We state here the one step convergence of this targeted MLE algorithm.
Theorem 3 Consider the targeted MLE algorithm above applied to an initial estimator Qn, gn, using a separate ϵL(t,j)n for each factor QL(t,j)n, t ≥1,
carrying out the updating steps one at the time, starting with ﬁnal factor in
likelihood, and going backwards till ﬁrst term always incorporating the latest
updates on Qn, and Q0n is the empirical distribution of Li(0), i = 1, . . . , n. We
can refer to one round of updating starting at ﬁnal factor and ending at ﬁrst
factor as one step. This process can be iterated thereby deﬁning an iterative
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 2
DOI: 10.2202/1557-4679.1211
algorithm.
Suppose that for each t ≥1, j the clever covariate in this algorithm, CL(t,j)(Q),
only depends on Q through Qsl = QL(s,l) for s > t and for s = t, l > j. In that
case, the above iterative targeted MLE algorithm converges in one step/round,
and thus in exactly N = PK+1
t=1 n(t) updating steps.
We recall from the previous Theorem, if D(O) = D1(O)/g(A | X), and
the probability distribution of O is factored in binary predictors as in (1), then
D∗= Π(D | TQ) = D0 + P
tj Dtj, where Dtj = CL(t,j)(L(t, j) −QL(t,j)(1)), and
g(A(t−1)|Pa(L(t))) ×
CL(t,j)(Q)(1) −CL(t,j)(Q)(0)
where, for δ ∈{0, 1},
CL(t,j)(Q)(δ) = EQ
D1 | L¯a(t−1)(t, j) = δ, Pa¯a(t−1)(L(t, j))
¯a(t−1)= ¯
This monotonicity property of the clever covariate holds if D1 does not depend
on Q itself. More generally, it holds if
D(Q) = D1 + C1(Q)
, C1(Q) is only function of O through L(0), ¯A(K),
(so that C1(Q) will cancel out in the representation of CL(t,j)) and D1 does not
depend on Q (it can depend on g).
This Theorem allows us to deﬁne closed form targeted MLE algorithms
for a large class of parameters in our semiparametric model deﬁned by no
constraints on any of the conditional node speciﬁc distribution, given their
speciﬁed parent nodes. To utilize this closed form one-step targeted MLE, one
is forced to carry out a separate update step for each factor (only once), but
one can still use smoothing across many factors for the initial estimator.
Targeted loss-based selection among targeted MLE.
The basic idea is as follows. All our candidate estimators of Q0 are targeted
maximum likelihood estimators, indexed by diﬀerent initial estimators of Q0,
and using same gn of g0. Due to fact that these targeted MLE’s solve the eﬃcient inﬂuence curve equation, it follows that the bias for ψ0 involves a product
n −Q0 and gn −g0: see asymptotic linearity Theorems in van der Laan
and Robins and van der Laan and Gruber . The goal is clearly to
van der Laan: Targeted ML Causal Inference: Part I
estimate Q0 as accurately as possible, which will maximize eﬃciency and minimize bias for ψ0. Therefore, we want to use cross-validation to select among
diﬀerent targeted maximum likelihood estimators, using a loss function whose
risk is minimized at Q0. However, there are many choices for the loss-based
dissimilarity, E0L(Q) −L(Q0), between a candidate Q and Q0 possible, and
one will be more targeted towards ψ0 than another. For example, we can use
the log-likelihood loss function, a penalized log-likelihood loss function presented in ), and other loss functions inspired
by the eﬃcient inﬂuence curve of ψ0, as presented here ).
Here we present two loss functions for Q0 that are identiﬁed by the eﬃcient
inﬂuence curve of Ψ. Firstly, if g0 is known , then we can use
L1(Q) = {D∗(Q, g0)}2.
If D∗(Q, g0) = D(Q, g0) −Ψ(Q), then it follows that indeed
Q0 = arg minQ E0L1(Q), since the variance under P0 of D∗(Q, g0, ψ0) is minimized at Q = Q0 ). For more general eﬃcient
inﬂuence curves, the latter property has to be explicitly veriﬁed: at minimal,
if D∗(Q, g) = D(Q, g, Ψ(Q)), then one can replace Ψ(Q) by a consistent estimator of ψ0, and use the loss function D2(Q, g0, ψn). By the argument above,
the loss function is still valid if one is willing to assume a consistent and good
estimator of g0 (an estimator that will converge faster to true g0 than the
estimators of Q0 will converge to Q0).
To explain the rationale of this loss function, ﬁrst consider the case that g0
is known. If g0 is known, a targeted MLE for which Q∗
n converges to Q with
Ψ(Q) = ψ0 is asymptotically linear with inﬂuence curve D∗(Q, g0) ) and it is well known that the variance of D∗(Q, g0)
for a Q with Ψ(Q) = ψ0 is minimal at Q = Q0, which then corresponds with
the semiparametric information bound. Thus, E0L1(Q) equals the asymptotic
variance of the inﬂuence curve of the targeted MLE. Under the assumption that
L1(Q) is uniformly bounded in all candidate Q’s, we can apply the Theorems
on the cross-validation selector ), which
proves that either the cross-validation selector is asymptotically equivalent
with the oracle selector, or it achieves the parametric rate of convergence. As
a consequence, loss-function based cross-validation based on this loss function
will, for large enough sample size, select the targeted maximum likelihood
estimator with the smallest asymptotic variance of its resulting substitution
estimator of ψ0 (excluding the case that there are ties). If g0 is unknown,
but estimated at a fast rate relative to the rate at which one estimates Q0,
then the above argument for the cross-validation selector still applies in ﬁrst
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 2
DOI: 10.2202/1557-4679.1211
order: see van der Laan and Dudoit for oracle results for the crossvalidation selector based on loss functions with nuisance parameters. If g0 is
estimated, and Q ̸= Q0, then the inﬂuence curve of the targeted MLE involves
another contribution, reducing the variance relative to the variance of the
inﬂuence curve for g0 known. In this case, L1(Q) is not exactly the asymptotic
variance of the targeted MLE, but it is still minimized at the optimal Q0, and
it represents a large component of the true asymptotic variance of the targeted
Consider now the case that we are not willing to assume that estimation
of g0 is easy relative to estimation of Q0. In that case, the above loss function
is not appropriate. Recall the representation of the eﬃcient inﬂuence curve
L(t,j) with DL(t,j) = CL(t,j)(L(t, j)−QL(t,j)(1)). We make the
following observation (using short-hand notation):
VAR(D∗(Q0, g0))
L(t,j)(L(t, j) −QL(t,j)(1))2,
This suggests to use as loss function for QL(t,j), t ≥1, the weighted squarederror loss function:
L(t,j)(L(t, j) −QL(t,j)(1))2,
which is indexed by a weight function C2
L(t,j). One would need to obtain an
initial estimator of these weights which depend on both Q0 and g0. However,
note that even if we estimate these weights inconsistently, then this loss function L2(Q) remains a valid loss function for Q0, thereby preserving the double
robustness of the resulting targeted maximum likelihood estimator of Q0.
In van der Laan and Gruber other loss functions implied by the eﬃcient inﬂuence curve are proposed, including the variance of eﬃcient inﬂuence
curve at a collaborative estimator of g0.
The targeted-MLE at a degenerate initial estimator
for intermediate time-dependent covarariate factors.
Consider the likelihood factorization as used to deﬁne the G-computation formula, and assume that the IPCW estimating function is of the form stated in
the above Theorem 3. If one of the node-speciﬁc conditional distribution is
van der Laan: Targeted ML Causal Inference: Part I
estimated with a degenerate conditional distribution, given the data generated
by previous node-speciﬁc conditional distributions, then Theorem 3 implies
that the projection of a function of O on the tangent space generated by that
factor equals zero.
For example, suppose the likelihood is factored according to the ordering
L(0), A(0), L(1), A(1), Y . The projection of a function D(O) onto the tangent space of QL(1) is zero at a degenerate QL(1), even if the true conditional
distribution of L(1) is not degenerate.
This insight suggests a simple-to-compute version of targeted MLE. Suppose we obtain an initial estimator Q0
n that is degenerate for all factors except
the last one, and we use the empirical distribution for the marginal distribution
of the baseline covariates. In that case, only the last factor, say QY =L(K+1),
needs to be updated in the targeted MLE algorithm. As a consequence, the
targeted MLE requires only one update, and thus converges in one single updating step.
Thus, in this case one estimates most of the system with a deterministic
system, and only the last factor is estimated with a non-degenerate conditional
probability distribution that is updated with a clever covariate depending on
the treatment mechanism. Due to the double robustness of the targeted MLE,
the resulting targeted MLE will be consistent and asymptotically linear if
the treatment mechanism is correctly speciﬁed, and will still gain eﬃciency if
the degenerate distributions are doing a reasonable job: since the degenerate
distribution will be misspeciﬁed it is not reasonable anymore to rely on correct
speciﬁcation of the initial estimator Q0
n of Q0 for consistency. Note also that
this simpliﬁed targeted ML estimator still allows us to apply the collaborative
targeted MLE approach for selection among diﬀerent treatment mechanism
estimators based on the log-likelihood of the targeted estimator Q1
by the treatment mechanism estimator: see van der Laan and Gruber .
We can view this particular simple targeted maximum likelihood estimator
as one particular candidate among a set of candidate targeted maximum likelihood estimators, and use loss-based cross-validation to select among these
candidate targeted maximum likelihood estimators. One would use one of our
proposed (eﬃcient-inﬂuence curve based) loss functions, such as the weighted
squared error loss function, since the log-likelihood loss function will become
undeﬁned as a degenerate distribution.
Dimension reduction for time-dependent covariates.
One could use a loss function on the Q-factor of the binary coded complete data
structure, and use loss-function based cross-validation to select among diﬀerent
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 2
DOI: 10.2202/1557-4679.1211
ﬁts, thereby implicitly carrying out a dimension reduction. For example, by
not including a node in the graph in parent sets of other nodes it will be
equivalent to removing the node from the data structure, and such moves
can be scored based on the loss function. In this manner one might build an
initial estimator Qn whose G-computation formula for parameter of interest
is only aﬀected by conditional distribution of subset of all nodes, thereby also
simplifying the targeted MLE update.
Here we wish to investigate alternative targeted dimension reductions that
would, in particular, reduce the computational complexity of the targeted maximum likelihood estimator which is driven by the number of binary variables
coding the data structure. This reduced complexity/dimension can also imply
that the loss function for the Q0 of the reduced data structure implies a more
targeted dissimilarity for the purpose of ﬁtting Ψ(Q0).
If a multivariate L(t) is reduced to a one dimensional time-dependent covariate, then the targeted maximum likelihood estimator is simpler, but if this
reduction means that A(t) now depends on measured variables beyond the
one dimensional reduced time-dependent covariate, then this reduction will
also have caused bias. In addition, much information might have been lost,
thereby causing variance. So care is needed.
Let’s revisit the two-stage sequentially randomized controlled trial with
data structure O = L(0), A(0), L(1), A(1), Y = L(2), but let’s now consider
the more general case that L(1) can be a multivariate vector with discrete
and/or continuous components. Suppose that we wish to estimate EY (1, 1).
Inspection of the eﬃcient inﬂuence curve of EY (1, 1) shows that it only depends on the conditional distribution of Y through its mean E(Y | A(0) =
1, A(1) = 1, ¯L(1)). This suggest that LQ(1) = E(Y | A(0), A(1) = 1, ¯L(1))
denotes a targeted dimension reduction: below we provide a general approach
which implies this precise dimension reduction. In addition, let Lg(1) be de-
ﬁned as the propensity score P(A(1) = 1 | L(0), A(0), L(1)).
A targeted
dimension reduction of the observed O is now given by
(L(0), A(0), LQ(1), Lg(1), A(1), Y ). We can ﬁt both LQ(1) and Lg(1) from the
data using super-learning, thereby obtaining an estimated dimension reduction Or. A targeted MLE for this (estimated) reduced data structure now
involves ﬁtting QLQ(1), QLg(1), and QY , where only the conditional mean of
Y is needed. However, by deﬁnition of LQ(1), the conditional mean of QY at
A(1) = 1 equals LQ(1), suggesting that we can exclude Lg(1) from the parent
set of Y without meaningful loss of information. Then, the conditional distribution QLg(1) does not aﬀect the G-computation formula of the distribution
of Y (1, 1) or, more general, the joint distribution of Y (1, 1) and L(0). As a
consequence, in this case we do not even need to ﬁt QLg(1).
van der Laan: Targeted ML Causal Inference: Part I
To summarize, in this manner we have succeeded in dramatically reducing
the complexity of a targeted MLE by replacing the ﬁtting of a conditional
distribution of a multivariate random variable L(1) into ﬁtting of a univariate
conditional distribution of LQ(1).
Let’s now generalize this type of targeted dimension reduction procedure.
Consider a general longitudinal data structure L(0), A(0), . . . , L(K), A(K), Y =
L(K + 1), and let’s consider the case that A(j) is binary, j = 0, . . . , K. The
dimension reduction can be guided by the actual form of the eﬃcient inﬂuence
curve for the target parameter. To demonstrate this, we ﬁrst note that the eﬃcient inﬂuence curve can often be represented as DIPCW(g0, ψ0)(L(0), A, Y ) −
j=0 E(DIPCW | A(j), Pa(A(j))) −E(DIPCW | Pa(A(j))) for some IPCWestimating function ). The latter differences of two conditional expectations can also be written as C(j)(A(j) −
P(A(j) = 1 | Pa(A(j)), where
C(j) = E(DIPCW | A(j) = 1, Pa(A(j))) −E(DIPCW
| A(j) = 0, Pa(A(j))).
For example, if ψ0 = EY (1), then DIPCW(O) = {I(A = 1)/g(A | X)}Y −ψ0.
As we did before, we can factorize this diﬀerence of conditional expectations in
terms of a factor only depending on Q0 and a factor only depending on g0. We
can deﬁne LQ(j) as the Q0-factor only, thereby preserving double robustness
of the resulting targeted MLE. In addition, we deﬁne
Lg(j) = P(A(j) = 1 | Pa(A(j)).
If the target parameter is EY (a) for a static regimen a, it follows that the
eﬃcient inﬂuence curve depends on O through the reduction
Or = (L(0), A(0), LQ(1), Lg(1), A(1), . . . , LQ(K), Lg(K), A(K), Y.
If the target parameter is EY (d) for a dynamic treatment rule d, then, one
also needs to include the time-dependent covariate the rule d uses to assign
treatments. To summarize, inspection of the eﬃcient inﬂuence curve of the
target parameter deﬁnes a reduction Or in terms of two time-dependent covariate processes, one representing the treatment asssignment probabilities as
functions of the past, and one based on the Q0-functions making up the ef-
ﬁcient inﬂuence curve. These time-dependent covariates depend on unknown
Q0 and g0. We will estimate these time-dependent covariates, by estimating
the treatment mechanism, and the required LQ(j). We can now apply the
targeted MLE to this reduced data structure.
As in our previous example, suppose that for each of the conditional distributions of Y and LQ(j), j = 1, . . . , K, we do not include any of the Lg(j) in the
The International Journal of Biostatistics, Vol. 6 , Iss. 2, Art. 2
DOI: 10.2202/1557-4679.1211
parent sets. We suggest that this comes at little cost in eﬃciency. Under this
condition, the conditional distributions QLg(j) do not aﬀect the G-computation
formula of the distribution of Y (d) or, more general, the joint distribution of
Y (d) and L(0). As a consequence, in that case we do not even need to ﬁt QLg(j),
j = 1, . . . , K. To summarize, in this manner we can dramatically reduce the
complexity of a targeted MLE by replacing the ﬁtting of a conditional distribution of a multivariate random variable L(j) into only ﬁtting the univariate
conditional distributions of LQ(j) and possibly the conditional distribution of
another time-dependent covariate that is used to deﬁne the target parameter
(e.g., treatment rule based on time dependent biomarker). Note that we will
still ﬁt the treatment mechanisms of A(j) conditional on its parents (under
Or) including Lg(j), and thus just ﬁt P(A(j) = 1 | Pa(A(j))) with Lg(j) itself.
This dimension reduction still allows for the construction of a collaborative
estimator gn of g0, given an estimator Qn of Qr
0, representing the conditional
distributions of LQ(j), Lg(j) and Y . This just requires applying the C-T-MLE
algorithm as presented in van der Laan and Gruber to the log-likelihood
0, thereby scoring a ﬁt of g0 with the log-likelihood (or other loss function)
of the targeted MLE of Qr
0 corresponding with the ﬂuctuation function implied
by the candidate g0-ﬁt.
By using as loss function the variance of the inﬂuence curve of the targeted
MLE we can still select among diﬀerent targeted maximum likelihood estimators indexed by diﬀerent dimension reductions of the type presented above,
assuming that each of them puts the maximal eﬀort in obtaining an unbiased
estimator.
Discussion
Targeted maximum likelihood estimation, combined with loss based super
learning fully utilizing the power of cross-validation for bounded loss functions, provides an exceptional powerful framework for assessing causal eﬀects,
with distinct advantages relative to other proposed methodology. The current
paper lays the ground work for the implementation of targeted maximum likelihood estimators that also incorporate time-dependent covariates and outcome
processes. Time dependent covariates and outcome processes allow reasonably
accurate imputations of the clinical outcome based on recent history, thereby
allowing for signiﬁcant potential gains in both eﬃciency and bias (see formula
of eﬀcicient inﬂuence curve/clever covariates). Even though almost all current
clinical trials collect time dependent data, these important sources of information have been ignored in the assessment of the causal eﬀect of a drug or
van der Laan: Targeted ML Causal Inference: Part I
treatment strategy. Clinical trials provide just one important application of
the targeted maximum likelihood estimator. Other important applications are
the assessment of causal eﬀects of treatment rules in sequentially randomized
controlled trials, and observational studies.