Volume 2, Issue 1
Article 11
The International Journal of
Biostatistics
Targeted Maximum Likelihood Learning
Mark J. van der Laan, Division of Biostatistics, School of
Public Health, University of California, Berkeley
Daniel Rubin, University of California, Berkeley
Recommended Citation:
van der Laan, Mark J. and Rubin, Daniel "Targeted Maximum Likelihood Learning," The
International Journal of Biostatistics: Vol. 2: Iss. 1, Article 11.
DOI: 10.2202/1557-4679.1043
Targeted Maximum Likelihood Learning
Mark J. van der Laan and Daniel Rubin
Suppose one observes a sample of independent and identically distributed observations from
a particular data generating distribution. Suppose that one is concerned with estimation of a
particular pathwise differentiable Euclidean parameter. A substitution estimator evaluating the
parameter of a given likelihood based density estimator is typically too biased and might not even
converge at the parametric rate: that is, the density estimator was targeted to be a good estimator
of the density and might therefore result in a poor estimator of a particular smooth functional of
the density. In this article we propose a one step (and, by iteration, k-th step) targeted maximum
likelihood density estimator which involves 1) creating a hardest parametric submodel with
parameter epsilon through the given density estimator with score equal to the efficient influence
curve of the pathwise differentiable parameter at the density estimator, 2) estimating epsilon with
the maximum likelihood estimator, and 3) defining a new density estimator as the corresponding
update of the original density estimator. We show that iteration of this algorithm results in a
targeted maximum likelihood density estimator which solves the efficient influence curve
estimating equation and thereby yields a locally efficient estimator of the parameter of interest,
under regularity conditions. In particular, we show that, if the parameter is linear and the model is
convex, then the targeted maximum likelihood estimator is often achieved in the first step, and it
results in a locally efficient estimator at an arbitrary (e.g., heavily misspecified) starting density.
We also show that the targeted maximum likelihood estimators are now in full agreement
with the locally efficient estimating function methodology as presented in Robins and Rotnitzky
 and van der Laan and Robins , creating, in particular, algebraic equivalence between
the double robust locally efficient estimators using the targeted maximum likelihood estimators as
an estimate of its nuisance parameters, and targeted maximum likelihood estimators. In addition, it
is argued that the targeted MLE has various advantages relative to the current estimating function
based approach. We proceed by providing data driven methodologies to select the initial density
estimator for the targeted MLE, thereby providing data adaptive targeted maximum likelihood
estimation methodology. We illustrate the method with various worked out examples.
KEYWORDS: causal effect, cross-validation, efficient influence curve, estimating function,
locally efficient estimation, loss function, maximum likelihood estimation, sieve, targeted
maximum likelihood estimation, variable importance
Author Notes: This research was supported by NIH grant R01 GM071397.
Introduction
Let O1, . . . , On be n independent and identically distributed (i.i.d.) observations of an experimental unit O with probability distribution P0 ∈M, where
M is the statistical model. For the sake of presentation, we will assume that
M is dominated by a common measure µ so that we can identify each possible
probability measure P ∈M by its density p = dP/dµ. In the discussion we
point out that our methods are not restricted to models dominated by a single
measure. Let Pn be the empirical probability distribution of O1, . . . , On which
puts mass 1/n on each of the n observations. Let p0 = dP0
dµ be the density of
p0 with respect to a dominating measure µ, and let pn be a density estimator
of p0. For example, pn ≡Φ(Pn) could be the maximum likelihood estimator
deﬁned by the following mapping Φ
pn = Φ(Pn) ≡arg max
Alternatively, if the model M is too large in the sense that the maximum
likelihood estimator is too variable or even inconsistent, then one typically
proposes a sieve Ms ⊂M, indexed by indices s, approximating M, and
computes candidate maximum likelihood estimators
pns = Φs(Pn) ≡arg max
In such a setting it remains to data adaptively select s. For example, one could
use likelihood based cross-validation to select s:
sn = arg max
log Φs(P 0
n,Bn)(Oi),
where Bn ∈{0, 1}n is a random vector of binary variables deﬁning a random
split in a training sample {i : Bn(i) = 0} and validation sample {i : Bn(i) = 1},
n,Bn denote the empirical probability distributions of the training
and validation sample, respectively. Now, one would deﬁne the estimator of
p0 as the cross-validated maximum likelihood estimator given by
pn = Φ(Pn) ≡pnsn = Φsn(Pn).
It is common practice to evaluate one or many Euclidean valued smooth
functionals Ψ(pn) of the density estimator pn and view them as estimators of
the parameter Ψ(p0) for given parameter mappings Ψ : M →IRd. Although
van der Laan and Rubin: Targeted Maximum Likelihood Learning
this method is known to result in eﬃcient estimators of Ψ(p0) in parametric models (i.e., M in the above deﬁnition of pn is a parametric model), in
general, such substitution estimators are not correctly trading oﬀbias and
variance with respect to the parameter of interest ψ0 = Ψ(p0). For example,
a univariate (standard) kernel density estimator optimizing the mean squared
error with respect to p0, assuming a continuous second derivative, can have
bias of the order n−2/5 based on an optimal bandwidth of the order n−1/5. The
corresponding substitution estimator of the cumulative distribution function
at a point can have bias which converges to zero at the same rate n−2/5, but
a variance of O(1/n), so that the substitution estimator has a variance (1/n)
which is smaller than the square bias (n−4/5) by an order of magnitude. In
particular, the smoothed empirical cumulative distribution functions would
not even converge at root-n rate due to the fact that √n times the bias n−2/5
does not converge to zero: that is, in this kernel density estimator example
√nn−2.5 →∞, so that the relative eﬃciency of the empirical cumulative distribution function and this smooth cumulative distribution function converges
to zero. This shows that substitution estimators based on optimal (for the
purpose of the density itself) density estimators of the cumulative distribution
function are typically theoretically inferior to other more targeted estimators
of the parameter of interest. In general, substitution estimators based on density estimators might simply not be very good estimators, and, in particular,
likelihood based substitution estimators will often fail to be asymptotically ef-
ﬁcient due to the bias caused by the curse of dimensionality: the kernel density
example already shows the failure of likelihood based learning of smooth parameters of a density of a univariate random variable, and it gets much worse
for densities of multivariate random variables. This issue has been stressed
repeatly by Robins and co-authors and
van der Laan and Robins ). This article proposes a method which, given
a particular pathwise diﬀerentiable parameter of interest, allows one to map a
density estimator (such as pn or pns for each s) into a targeted maximum likelihood density estimator so that the corresponding substitution estimator of ψ0
is locally eﬃcient, under reasonable conditions: that is, if the starting density
estimator is consistent, it will typically be eﬃcient, and otherwise in certain
classes of problems it might still be consistent and asymptotically linear.
Speciﬁcally, in this article we propose a one step maximum likelihood density estimator which involves 1) creating a parametric model with Euclidean
parameter ϵ (e.g., the same dimension d as the parameter ψ0) through a given
density estimator p0
n (e.g., s-speciﬁc MLE pns) at ϵ = 0 whose scores include
the components of the eﬃcient inﬂuence curve of the pathwise diﬀerentiable
parameter at the density estimator p0
n, 2) estimating ϵ with the maximum
The International Journal of Biostatistics, Vol. 2 , Iss. 1, Art. 11
DOI: 10.2202/1557-4679.1043
likelihood estimator of this parametric model, and 3) deﬁning a new density
estimator p1
n as the corresponding ﬂuctuation of the original density estimator
In addition, iterating this process results in a sequence of pk
n with increasing log-likelihood converging to a solution of the eﬃcient inﬂuence curve
estimating equation, and thereby typically results in a locally eﬃcient substitution estimator of ψ0. We refer to this solution as the targeted maximum
likelihood estimator based on the initial p0
n. We provide various examples in
which this targeted maximum likelihood estimator is achieved at the ﬁrst step
of the algorithm.
In particular, one can map each model based MLE pns into a targeted MLE
ns (targeted towards ψ0). We suggest that it is appropriate to select among
this collection of targeted MLEs p∗
ns with likelihood based cross-validation, as
explained heuristically in our accompanying technical report: targeted MLE’s
are comparable w.r.t. to being fully trained w.r.t. estimation of the parameter
of interest, which makes the log-likelihood an appropriate criteria to select
among them. That is, let p∗
s(Pn) be the s-speciﬁc targeted MLE applied
to the initial density estimator pns. Let
sn = arg max
n,Bn)(Oi),
where Bn ∈{0, 1}n is a random vector of binary variables deﬁning a random
split in a training sample {i : Bn(i) = 0} and validation sample {i : Bn(i) = 1},
n,Bn denote the empirical probability distributions of the training
and validation sample, respectively, as above. Now, likelihood cross-validated
targeted MLE is deﬁned as:
n = ˆΦ(Pn) ≡p∗
We also note that the candidate models indexed by s can be chosen to represent
a sieve in a possibly misspeciﬁed (big) model M, as long as this model M
is still such that the Kullback-Leibler projection of the true density p0 on
this model identiﬁes the parameter of interest Ψ(p0) correctly: for example,
if the parameter of interest is a parameter of a regression of an outcome Y
on covariates W, then one might select as big model the normal densities
with unspeciﬁed conditional mean, given W, and certain possibly misspeciﬁed
conditional variance, even though the true density p0 is not a member of this
Organization of article.
In Section 2, given an initial density estimator p0
n (e.g., pns) of p0, we formally
deﬁne the k-th order targeted maximum likelihood density estimator pk
van der Laan and Rubin: Targeted Maximum Likelihood Learning
corresponding targeted maximum likelihood estimator Ψ(pk
n) of ψ0. We illustrate the targeted MLE of the cumulative distribution function at a point in a
nonparametric model. In this case, it appears that the ﬁrst step targeted MLE
of ψ0 algebraically equals the empirical cumulative distribution function, for
any given initial density estimator p0
n. Thus, while the original substitution
estimator of the cumulative distribution function would not converge at the
parametric rate 1/√n due to it being too biased, the ﬁrst order targeted bias
corrected density estimator estimates the cumulative distribution function ef-
ﬁciently. In Section 3 we establish that the targeted MLE solves the eﬃcient
inﬂuence curve estimating equation, which provides the basis of its asymptotic
eﬃciency for ψ0. In Section 4 we present general templates for establishing
consistency, asymptotic linearity and eﬃciency of the targeted MLE of ψ0,
which provides a particular powerful theorem for convex models and linear
pathwise diﬀerentiable parameters stating that the targeted MLE will be consistent and asymptotically linear for an arbitrary starting density, and it will
be eﬃcient if the starting (or its targeted MLE version) density consistently
estimates the eﬃcient inﬂuence curve. We illustrate the latter result with two
examples. In Section 5 we discuss the relation, and in particular, the algebraic
equivalence, between targeted maximum likelihood estimation and estimating
function based estimation if one estimates the nuisance parameters in the estimating functions with the targeted MLE. We point out that targeted MLE
is more widely applicable by not relying on being able to map the eﬃcient
inﬂuence curve in a corresponding estimating function, and it deals naturally
with the issue of multiple solutions of estimating equations. In Subsection 5.1
we focus on censored data models to make the comparison with the estimating function methodology in van der Laan and Robins . In particular,
we present the targeted MLE approach which results in algebraic equivalence
between the Inverse Probability of Censoring Weighted estimator, the double robust IPCW estimator, and the targeted MLE of a parameter of the full
data distribution based on observing n i.i.d. observations of a censored data
structure under coarsening at random (CAR). These results show that the
targeted MLE does not only provide a boost for likelihood based estimation,
but it also provides an improvement relative to the current implementation of
locally eﬃcient estimation based on estimating function methodology. In Section 6 we present important examples illustrating the power and computational
simplicity of this new targeted maximum likelihood estimator: estimation of
a marginal causal eﬀect, and the parametric component in a semiparametric regression model, and we present a simulation to illustrate the targeted
MLE. In Section 7 we present a loss based approach of targeted MLE learning
based on the uniﬁed loss function based approach in van der Laan and Dudoit
The International Journal of Biostatistics, Vol. 2 , Iss. 1, Art. 11
DOI: 10.2202/1557-4679.1043
 . We end this article with a discussion in Section 8. In our accompanying technical report we show generalizations of the targeted MLE of pathwise
diﬀerentiable parameters to targeted MLE of general parameters.
Some relevant literature overview.
There exist various methods for construction of an eﬃcient estimator of a parameter based on parametric models. In particular, Fisher’s method of maximum likelihood estimation can be applied, or closely related M-estimate (i.e.,
estimators deﬁned as solutions of estimating equations) methods which work
under minimal conditions. Maximum likelihood estimation in semiparametric
models has been an extensive research area of interest. Here we suﬃce with
a referral to van der Vaart and Wellner for a partial overview of the
theory for the analysis of maximum likelihood. There are plenty of examples in
which the straightforward semiparametric MLE even fails to be consistent, but
often an appropriate regularization can be applied to repair the consistency
of the semiparametric MLE: e.g., see van der Laan for such examples
based on censored data. However, as argued above in the kernel density estimator example, maximum likelihood based smoothing/model selection will
often provide the wrong trade-oﬀof bias and variance for speciﬁc smooth parameters. The literature (notably Robins and co-authors) has recognized this
problem with likelihood based estimation. For example, smoothing survival
functions or smoothing the nonparametric components in a semiparametric regression model requires so called “under-smoothing” in order to obtain root-n
consistency for the parameter of interest: see e.g., Cosslett .
For an overview of the literature on eﬃcient estimation of pathwise diﬀerentiable parameters in semiparametric models we refer to Bickel et al. .
In particular, the latter presents the general one step estimator based on an
estimate of the eﬃcient inﬂuence curve: see e.g. Klaassen .
overview of the literature on locally eﬃcient estimating function based estimation of pathwise diﬀerentiable parameters based on censored longitudinal
data ),
we refer to van der Laan and Robins .
A uniﬁed loss function approach based methodology for estimation and
estimator selection, and concrete illustration of this method in various examples is presented in van der Laan and Dudoit . This methodology is
general by allowing the loss function to be an unknown function of the experimental unit and the parameter values. van der Laan and Rubin 
and van der Laan and Rubin present an alternative uniﬁed estimating
function methodology for both estimation and estimator selection. The latter
van der Laan and Rubin: Targeted Maximum Likelihood Learning
two methodologies provide two general strategies for data adaptive estimation
of any parameter in any model.
We note that these (uniﬁed) loss function and (uniﬁed) estimating function based approaches give up on using the log-likelihood as loss function for
the purpose of estimator selection and estimation when the parameter of interest is not the actual density of the data, but a particular parameter of
it: these methods replace the log-likelihood loss function by a loss function
or an estimating function targeted at the parameter of interest. From that
point of view, the current article shows that it is not necessary to replace the
log-likelihood loss function by a targeted loss function, but that one can also
target the directions in which one maximizes the log-likelihood.
Targeted maximum likelihood estimators.
Let Ψ : M →IRd be a pathwise diﬀerentiable parameter at any density p ∈M,
where M denotes the statistical model consisting of the possible densities
p = dP/dµ of O with respect to some dominating measure µ. That is, given a
suﬃciently rich class of one-dimensional regular parametric submodels {pδ : δ}
with parameter δ of M through the density p at δ = 0, we have for each of
these submodels pδ with score s at δ = 0 and pδ=0 = p
dδ Ψ(pδ)|δ=0 = EpS(p)(O)s(O)
for some S(p) ∈(L2
0(p))d, where L2
0(p) denotes the Hilbert space of functions
of O with mean 0 and ﬁnite variance under P, endowed with inner product
⟨h1, h2⟩P = Eph1(O)h2(O). This random variable S(p) ∈(L2
0(p))d is called a
gradient of the pathwise derivative at p. Let T(p) ⊂L2
0(p) be the tangent space
at p which is deﬁned as the closure of the linear span of the scores s of this
class of submodels through p. If the model is not locally saturated in the sense
that T(p) = L2
0(p), then there can be many gradients. Let T ⊥
nuis(p) ⊂L2
the orthogonal complement of the so called nuisance tangent space, where the
latter is deﬁned as the closure of the linear span of all scores of pδ for which
the pathwise derivative equals 0 , Chapter
1). As in van der Laan and Robins , we denote the set of gradients at
p with T ⊥∗
nuis(p) ⊂(T ⊥
nuis(p))d. Let S∗(p) be the so called canonical gradient
which is the unique gradient whose d components S∗(p)j, j = 1, . . . , d, are
elements of the tangent space T(P). A submodel {pϵ : ϵ} with score S∗(p) at
ϵ = 0 is often referred to as a hardest submodel ), as we
will also do in this article.
The International Journal of Biostatistics, Vol. 2 , Iss. 1, Art. 11
DOI: 10.2202/1557-4679.1043
Let (O, p) →D(p)(O) be a point-wise well deﬁned class of functions on
the Cartesian product of the support of O and the model M, which satisﬁes
D(p) = S∗(p) P0-a.e. for all p ∈M.
As an example, consider letting O be a Euclidean valued d-variate random
variable with density p0. Let M be the class of all continuous densities with
respect to Lebesgue measure µ, and let Ψ(p) =
0 p(o)dµ(o) be the cumulative
distribution function at a point t ∈IR corresponding with density p. In this
case Ψ : M →IR is pathwise diﬀerentiable parameter at p with eﬃcient
inﬂuence curve S(p)(O) = I(O ≤t) −Ψ(p), and, because the model is locally
saturated, it is also the only inﬂuence curve/gradient. So D(p) = I(O ≤t) −
Ψ(p). Similarly, given a set of user supplied points {t1, . . ., td}, we could deﬁne
the d-dimensional Euclidean parameter Ψ(p) = (Ψ(p)(tj) ≡
0 p(o)dµ(o) : j =
1, . . . , d) representing the cumulative distribution function at d points. In this
case, D(p) = (I(O ≤tj) −Ψ(p)(tj) : j = 1, . . . , d) has d components.
A general methodology for construction of functions Dh(p) indexed by an
h ∈H so that {Dh(p) : h ∈H} ⊂T ⊥
nuis(p) (or equality) is presented in
van der Laan and Robins .
In van der Laan and Robins the
class of functions {Dh(p) : h ∈H} is referred to as a representation of the
orthogonal complement of the nuisance tangent space, which is then used
to map into a class of corresponding estimating functions for the pathwise
diﬀerentiable parameter p →Ψ(p) of the form p →Dh(Ψ(p), Υ(p)) with Υ
representing a nuisance parameter. In van der Laan and Robins , for a
variety of general classes of models and censored data structures O, explicit
representations of the orthogonal complement of the nuisance tangent space,
nuis(p), corresponding gradients, T ⊥∗
nuis(p), and canonical gradient S∗(p), have
been provided.
n = Φ(Pn) ∈M be a density estimator of p0 = dP0/dµ. Deﬁne now
a parametric submodel {p0
n(ϵ) : ϵ ∈IRk} ⊂M through p0
n at ϵ = 0 whose
linear span of scores of ϵ at ϵ = 0 includes all d components of D(pn). One
possibility is to choose ϵ ∈IRd of the same dimension as D(p) and arrange
that the score of ϵj at ϵ = 0 equals Dj(p), j = 1, . . ., d. For example, if the
model M is convex then the following model typically applies
n(ϵ) ≡(1 + ϵ⊤D(p0
where ϵ ∈IRd denotes the parameter ranging over all values for which p0
is a proper density. Note that indeed p0
n(ϵ) is a density (positive
valued and integrates till 1) for ϵ small enough, and
ϵ=0 = D(p0
van der Laan and Rubin: Targeted Maximum Likelihood Learning
One can also use an exponential family
n(ϵ) ≡C(ϵ, p0
n) exp(ϵ⊤D(p0
for C(ϵ, p0
n) be a normalizing constant. In general, one can choose a parameterization ϵ →p0
n(ϵ) ∈M which is smooth in ϵ at ϵ = 0 and whose score at
ϵ = 0 equals D(p0
n). However, we will also consider submodels p0
n(ϵ) with additional scores in order to arrange that the targeted MLE will be fully targeted
towards estimation of D(p0).
ϵn = ϵ(Pn | p0
{ϵ:p0n(ϵ)∈M}
be the maximum likelihood estimator of ϵ treating the density estimator p0
given and ﬁxed. We will assume that the maximum is attained in the interior
of M so that ϵn solves the estimating equation:
Here we use the common notation Pf ≡
R f(o)dP(o). For example, if p0
(1 + ϵ⊤D(p0
n, as one might choose in convex models, then we have that ϵn
is the solution of
This deﬁnes now an updated density estimator
n(ϵn) = p0
n(ϵ(Pn | p0
Note that this simply deﬁnes a method for mapping an initial density estimator
n ∈M in a new density estimator p1
n ∈M, which we call the ﬁrst step
targeted maximum likelihood estimator. By iterating this process one obtains
the k-step targeted maximum likelihood estimator pk
n, k = 1, . . .
Deﬁnition 1 Given an initial density estimator p0
n = ˆΦ0(Pn) based on the
empirical probability distribution Pn, a parametric ﬂuctuation {p0
n(ϵ) : ϵ} ⊂M
satisfying p0
ϵ=0 = D∗(p0
n), where the linear span of
the components of D∗(p0
n) include all d components of a canonical gradient
n) of the parameter of interest Ψ : M →IRd at p0
n, a maximum likelihood
n) ≡arg max
The International Journal of Biostatistics, Vol. 2 , Iss. 1, Art. 11
DOI: 10.2202/1557-4679.1043
of ϵ, we deﬁne the ﬁrst step targeted maximum likelihood density estimator as
n = ˆΦ1(Pn) ≡p0
n(ϵ(Pn | p0
This process can be iterated to deﬁne the k-step targeted maximum likelihood
density estimator as
= ˆΦk+1(Pn) ≡pk
n(ϵ(Pn | pk
n)), k = 0, 1, . . ..
The corresponding k-step targeted maximum likelihood estimator of ψ0 is
ˆΨk(Pn) = Ψ(pk
The targeted maximum likelihood estimator is deﬁned as
n = ˆΦ∗(Pn) ≡lim
assuming this limit exists.
Example: Estimating the CDF.
Consider an initial data generating density p0 = f, let F(t) =
denote the associated CDF at some ﬁxed point t ∈IR, and consider the parametric model
fϵ(o) = (1 + ϵ[I(o ≤t) −F(t)])f(o) : −
1 −F(t) ≤ϵ ≤
where one can check that the range restraint on ϵ serves merely to ensure that
the family is indeed a proper class of densities. Consider estimating ϵ from
maximum likelihood based on an i.i.d. sample {Oi}n
i=1. The log likelihood is,
log(1 + ϵ[I(Oi ≤t) −F(t)]) +
log f(Oi).
Its derivative is,
I(Oi ≤t) −F(t)
1 + ϵ[I(Oi ≤t) −F(t)].
Its second derivative is easily seen to be,
l′′(ϵ) = −
I(Oi ≤t) −F(t)
1 + ϵ[I(Oi ≤t) −F(t)]
van der Laan and Rubin: Targeted Maximum Likelihood Learning
Because the log likelihood is concave, we know that the maximum is achieved
if l′(ϵ) = 0 has a solution. Letting Fn(·) denote the empirical distribution
function, note that we can decompose the terms in l′(ϵ) into two parts (those
for which I(Oi ≤t) are 0 or 1), and the MLE of ϵ can be seen to solve,
I(Oi ≤t) −F(t)
1 + ϵ[I(Oi ≤t) −F(t)]
1 + ϵ[1 −F(t)] + n(1 −Fn(t)) −F(t)
Moving the second term on the right to the other side of the equation, dividing
both sides by n, and multiplying both sides by (1 + ϵ[1 −F(t)])(1 −ϵF(t)),
the equation reduces to,
Fn(t)(1 −F(t))(1 −ϵF(t)) = (1 −Fn(t))F(t)(1 + ϵ(1 −F(t))).
This is linear in ϵ, and one can check that the solution is
Fn(t)(1 −F(t)) −(1 −Fn(t))F(t)
F(t)(1 −F(t))
Fn(t) −Fn(t)F(t) −F(t) + Fn(t)F(t)
F(t)(1 −F(t))
Fn(t) −F(t)
F(t)(1 −F(t)).
Because 0 ≤Fn(t) ≤1, one can check that indeed
1 −F(t) = −
F(t)(1 −F(t) ≤ϵn ≤
F(t)(1 −F(t)) =
so the range restraint on ϵ for the family (2) always holds for the maximum
likelihood estimator, meaning that fϵn(·) is a proper density. Now, the resulting CDF at t for this density is then,
−∞fϵn(o)do
−∞(1 + ϵn[I(o ≤t) −F(t)])f(o)do
−∞f(o)do + ϵn
−∞I(o ≤t)f(o)do −ϵ1F(t)
The International Journal of Biostatistics, Vol. 2 , Iss. 1, Art. 11
DOI: 10.2202/1557-4679.1043
F(t) + ϵnF(t) −ϵnF(t)2 = F(t) + ϵ1F(t)(1 −F(t))
F(t) + Fn(t) −F(t)
F(t)(1 −F(t))F(t)(1 −F(t)) from (7)
F(t) + Fn(t) −F(t) = Fn(t).
Therefore, for any initial density f(·) and any time point t, the targeted likelihood maximum likelihood estimator of the CDF reduces to the empirical
distribution estimator in a single step. This result immediately generalizes to
A p(o)dµ(o) for any measurable set A.
Solving the eﬃcient estimating equation.
We have the following trivial, but useful result. It states that if the MLE’s
n) at step k of the targeted MLE algorithm converge to zero for k →∞
(as one expects to hold if the log likelihood of the data is uniformly bounded
in the model M), then the algorithm converges to a solution of the eﬃcient
inﬂuence curve equation PnD(p) = 0 in the sense that PnD(pk
Result 1 Let Pn be given. Assume that
ϵ→0 lim sup
that for each k there exist a constant matrix Ak so that Ak
pkn = D(pk
lim supk→∞∥Ak ∥< ∞, where ∥A ∥denotes a matrix norm.
If ϵ(Pn | pk
n) solves Pn
pkn(ϵ) = 0 for all k, and ϵ(Pn | pk
n) →0 for k →∞,
then we have
n) →0 for k →∞.
The condition (9) holds if the score of the one-dimensional submodel p(ϵ)
at ϵ converges to the score at ϵ = 0 for ϵ →0 uniformly in a set containing
the k-step targeted MLE’s pk
n, k = 1, 2, . . ., and that for each p ∈M, the
linear span of the components p′(0)
p(0) includes the components of D(p). Since
the likelihood increases at each step one might indeed expect that typically the
targeted MLE algorithm will converge and thereby that ϵ(Pn | pk
n) →0. That
is, Result 1 essentially states that, if the targeted MLE algorithm converges,
then the algorithm will converge to a solution of the eﬃcient inﬂuence curve
equation in the sense that by choosing k large enough PnD(pk
n) ≈0 with
van der Laan and Rubin: Targeted Maximum Likelihood Learning
arbitrary small deviation from 0.
Proof. Let ϵk = ϵ(Pn | pk
n), k = 0, . . .. If ϵk →0 for k →∞, then
for k →∞. Let Ak be such that Ak
pkn(0) = D(pk
n). By assumption, the matrix
has a norm bounded uniformly in k. Thus, we also have
for k →∞. However, Pn
n(ϵk) = 0 (and thus Ak applied to this
equals 0 as well), which shows that PnD(pk
Eﬃciency of targeted likelihood estimation.
In this section we provide templates for proving consistency, asymptotic linearity and eﬃciency of the targeted maximum likelihood estimator of a path-wise
diﬀerentiable parameter. Since convexity of the model and linearity of the
parameter allows a particular strong result, we separate this situation from
the general case.
Linear parameters in convex models.
n denote the limit of our algorithm if it exists as a density with respect
to µ in M, and otherwise it represents a pk
n ∈M for a large enough k. If
the condition of the above Result 1 holds, then p∞
n ∈M, and for all practical
purposes, we have PnD(p∞
n ) = 0. If this is true, then this result can be used
to establish eﬃciency of the substitution estimator Ψ(p∞
n ) as an estimator
of ψ0 under the assumption that the parameter Ψ : M →IRd is linear and
M is convex, under weak regularity conditions. Speciﬁcally, by the identity
for convex models and linear parameters in van der Laan we have
Ψ(p) −Ψ(p0) = −P0D(p) for any p, p0 ∈M for which p0/p < ∞. Thus, if
n ∈M and it is bounded away from 0 on the support of p0, then combining
n ) = 0 with the latter identity gives us
n ) −Ψ(p0) = (Pn −P0)D(p∞
Even if p∞
n does not satisfy p0/p∞
n < ∞, then the identity Ψ(p∞
n ) −Ψ(p0) =
n ) can still be established under a continuity condition on p →P0D(p)
The International Journal of Biostatistics, Vol. 2 , Iss. 1, Art. 11
DOI: 10.2202/1557-4679.1043
 ), so that (10) can even be established for density
estimators not satisfying this support condition.
Applying empirical process theory ) now
proves that Ψ(p∞
n ) is root-n consistent if D(p∞
n ) falls in a P0 Donsker class with
probability tending to 1. If one can now also establish that P0(D(p∞
n )−D(p1))2
converges to zero in probability for a certain p1 ∈M, then it follows that
n ) is asymptotically linear with inﬂuence curve D0(p1) ≡D(p1)−P0D(p1):
n ) −Ψ(p0) = (Pn −P0)D0(p1) + oP (1/√n),
where we note that p1 can be an arbitrary limit (i.e., p1 ̸ =p0 is allowed). In
particular, if the limit p1 is such that D(p1) = D(p0), then Ψ(p∞
n ) is asymptotically linear with inﬂuence curve D(p0). Thus, if D(p0) is the eﬃcient inﬂuence
curve, then Ψ(p∞
n ) is asymptotically eﬃcient.
Theorem 1 Suppose the conclusion of Result 1 holds, and K = K(n) is
chosen large enough so that the targeted MLE pn = pK
n satisﬁes PnD(pn) =
R(n, K(n)) = oP (1/√n) (where limK→∞R(n, K) = 0). Assume that pn ∈M,
p0/pn < ∞uniformly over a support of p0, M is convex, and Ψ : M →IRd is
linear. Then
Ψ(pn) −Ψ(p0) = (Pn −P0)D(pn) + R(n, K(n)).
If D(pn) falls in a P0 Donsker class with probability tending to 1, then
Ψ(pn) −ψ0 = OP (1/√n).
If it is also shown that P0(D(pn) −D(p1))2 →0 in probability for n →∞for
some p1 ∈M, then it follows that Ψ(pn) is asymptotically linear with inﬂuence
curve D(p1) −P0D(p1):
Ψ(pn) −Ψ(p0) = (Pn −P0)D(p1) + oP (1/√n).
In particular, if D(p1) = D(p0), and D(p0) is the eﬃcient inﬂuence curve of
Ψ at p0, then Ψ(pn) is asymptotically eﬃcient.
This shows that the targeted MLE of a linear parameter in a convex model
is typically consistent and asymptotically linear for arbitrary starting density
n, and if the targeted MLE p∞
n is consistent in the sense that P0(D(p∞
D(p0))2 →0 with probability tending to 1 for n converging to inﬁnity (e.g.,
the initial starting density p0
n would already yield a consistent estimator D(pn
of D(p0)), then the targeted MLE will also be eﬃcient. We will now provide
van der Laan and Rubin: Targeted Maximum Likelihood Learning
two examples illustrating this theorem. The ﬁrst example represents a case
in which the targeted MLE is eﬃcient for arbitrary starting density p0
second example represents the case that the targeted MLE is consistent and
asymptotically linear for arbitrary starting density p0
n, and is eﬃcient if the
starting density consistently estimates D(p0).
Example 1 ((Eﬃciency of a smooth cumulative distribution function) In this example we have D(p)(O) = I(O ≤t) −
0 p(o)dµ(o). A targeted MLE pn solving PnD(pn) = 0 satisﬁes that Ψ(pn) = PnI(· ≤t) equals
the empirical cumulative distribution function at t and is therefore asymptotically eﬃcient, for arbitrary starting density p0. Thus in this example the
initial density does not need to be consistent in order to make the targeted
MLE asymptotically eﬃcient. Suppose that p0
nh is indexed by a bandwidth
or model choice h, and let p∗
nh be the targeted MLE density estimator using
as starting density p0
nh. Each of the targeted MLE’s p∗
nh results in the same
estimator of the cumulative distribution function Ψ(p0) at time t. If one uses
likelihood cross-validation to select h, then one selects among all of these targeted MLE’s the one which is supposedly closest to the true density p0 with
respect to Kullback-Leibler divergence, which now provides a valid and reasonable criteria since all the candidates density estimators already map into
eﬃcient (and algebraically equivalent) estimators of ψ0.
Example 2 ((Local eﬃciency of targeted MLE based on censored
data) We consider a particular example of a censored data structure to illustrate that Theorem 1 yields local eﬃciency of the targeted MLE based on
CAR censored data structures based on any starting density p0
n, under very
weak conditions.
Suppose that the full data structure X = (W, Y (a) : a ∈{0, 1}) on the
experimental unit consists of a set of baseline covariates W, and treatment
speciﬁc outcomes Y (a), indexed by treatment values a ∈{0, 1}. Suppose that
the observed data structure O = (W, A, Y = Y (A)) ∼p0, and it is assumed
that the conditional probability distribution g0(· | X) of A, given X, satisﬁes
g0(A | X) = g0(A | W): that is, A is independent of X, given W. Suppose
that this conditional probability distribution of g0(A | W) of A, given W, is
known, and satisﬁes 0 < g0(1 | W) < 1, as it would be in a randomized trial
aiming to establish the causal eﬀect of A on Y . Let M be the class of all
densities of O with respect to an appropriate dominating measure. We have
M = {p(O) = QXA(W, Y )g0(A | X) : QX0, QX1},
where the full data sub-distributions QXa(w, y) = PW,Y (a)(w, y) are joint densities of (W, Y (a)), a ∈{0, 1}, and are unspeciﬁed. As a consequence, M is
The International Journal of Biostatistics, Vol. 2 , Iss. 1, Art. 11
DOI: 10.2202/1557-4679.1043
a convex model. Let Ψ : M →IR be deﬁned as Ψ(p) = Ep(Y (1) −Y (0)) =
Ep(Ep(Y | A = 1, W) −Ep(Y | A = 0, W)), which is often called the marginal
causal eﬀect of treatment A on the outcome Y . In this case, Ψ(p) is pathwise
diﬀerentiable at p with eﬃcient inﬂuence curve S(p) deﬁned by
S(p) = (Y −Q(p)(A, W))(A −(1 −A))
g(p)(A | W)
+ Q(p)(1, W) −Q(p)(0, W) −Ψ(p),
where g(p)(· | W) = Prp(A = · | W) = g0(· | W), and Q(p)(A, W) =
Ep(Y | A, W). Note that Ψ(p) depends on p through Q(p) and its marginal
distribution pW of W. Due to the factorization of the density of O in a QXfactor and g0 factor, this is also the eﬃcient inﬂuence curve if g0 is unknown
or modelled. The class of all gradients at p ∈M is given by:
(Y −Q(A, W))(I(A = 1) −I(A = 0))
+ Q(1, W) −Q(0, W) −Ψ(p) : Q
where Q can be an arbitrary function of A, W.
So we could deﬁne
DQ(p)(O) ≡(Y −Q(A, W))(A −(1 −A))
+ Q(1, W) −Q(0, W) −Ψ(p),
and D(p) = DQ(p)(p) represents the eﬃcient inﬂuence curve. We are now ready
to deﬁne the targeted MLE of p0 with respect to the parameter ψ0.
n be an initial density estimator of p0. For example, p0
n could correspond with the empirical distribution of W, and a normal distribution for
the conditional density of Y , given A, W, with mean Q0
n(A, W) and variance
n(A, W), where Q0
n is an estimate of Q(p0)(A, W) = E0(Y | A, W). Let p∗
a targeted MLE, as we explicitly deﬁne in the later Section 6 in detail, solving
n) = 0. In Section 6, we show for a particular hardest submodel pk
consisting of normal densities of Y , conditional on A, W, with ϵ corresponding
with a ﬂuctuation of current regression Qk
n(A, W), that the targeted MLE is
achieved in the ﬁrst step (i.e., p∗
n), and indeed solves the score equation
n) = 0. Let’s consider this particular targeted MLE for illustration, but
the following arguments apply to any targeted MLE solving PnD(p∗
Application of the theorem teaches us that
n) −ψ0 = (Pn −P0)DQ(p∗n).
Since g0 is bounded away from zero, if Q1
n is a nice smooth function ), it follows that DQ(p∗n) falls in a P0-Donsker class, and thus that
n) −ψ0 = OP (1/√n).
If the initial regression estimator Q0
converges to a possibly misspeciﬁed Q1 = Q(p1), then it follows that Ψ(p∗
is asymptotically linear with inﬂuence curve DQ(p1)(O), where p1 is the possibly misspeciﬁed limit of p1
n. Finally, if Q0
n is actually consistent for Q(p0),
then the targeted MLE of ψ0 is asymptotically eﬃcient. We can use likelihood
based cross-validation to select among targeted MLE’s indexed by diﬀerent
candidate initial estimators Q0
n, thereby improving the eﬃciency relative to
a targeted MLE with a ﬁxed initial Q0
n. Thus this example teaches us that
the targeted MLE Ψ(p∗
n) of ψ0, which typically equals the ﬁrst step targeted
MLE, is consistent and asymptotically linear for arbitrary initial regression
estimator Q0
n, and it is eﬃcient if Q0
n happens to be consistent, where the
latter can potentially be achieved by using a machine learning type algorithm
and selecting the ﬁne tuning parameters with likelihood based cross-validation.
These results still carry through if g0 is unknown but is known to belong to a
parametric model.
Local eﬃciency for general smooth parameters.
The remarkable robustness with respect to the starting density p0
n as observed
in the previous subsection is a consequence of the convexity of the model and
linearity of the parameter Ψ. In general, such results cannot be expected to
hold. In this subsection we present a more general approach for establishing
the wished asymptotic linearity and eﬃciency of the targeted MLE of any
pathwise diﬀerentiable parameter.
n ∈M denote the limit of the targeted MLE algorithm if it exists
and otherwise it represents a pk
n for a large k. If the targeted MLE solves
the eﬃcient inﬂuence curve equation, then for all practical purposes, we have
n ) = 0. Let R(p, p0) be deﬁned by
Ψ(p) −Ψ(p0) = −P0D(p) + R(p, p0)
for any p ∈M. We note that by pathwise diﬀerentiability of Ψ at p, R(p, p0)
represents a second order term in the diﬀerence p−p0. Combining PnD(p∞
0 with the latter identity gives us
n ) −Ψ(p0) = (Pn −P0)D(p∞
n ) + R(p∞
Applying empirical process theory now proves that Ψ(p∞
n ) is root-n consistent if D(p∞
n ) falls in a P0 Donsker class with probability tending to 1, and
n , p0) = oP (1/√n). If one can now also establish that P0(D(p∞
n )−D(p1))2
The International Journal of Biostatistics, Vol. 2 , Iss. 1, Art. 11
DOI: 10.2202/1557-4679.1043
converges to zero in probability for a possibly misspeciﬁed p1 ∈M, then it follows that Ψ(p∞
n ) is asymptotically linear with inﬂuence curve D(p1)−P0D(p1):
n ) −Ψ(p0) = (Pn −P0)D(p1) + oP (1/√n).
In particular, if D(p1) = D(p0), then the targeted MLE is asymptotically eﬃcient. Note that the asymptotic linearity requires that R(p∞
n , p0) = oP (1/√n),
while the convexity of the model and linearity of the parameter as assumed in
the previous subsection allowed us to avoid such a condition: i.e. in that case
we had R(p, p0) = 0 for arbitrary p ∈M with p0/p < ∞.
Fusion of MLE and estimating equations
In this section we show that the targeted MLE can be viewed as a solution of
an optimal estimating equation for the parameter of interest, if one estimates
the nuisance parameters with the targeted MLE itself. This comparison can
only be made by making the assumption that the eﬃcient inﬂuence curve can
be viewed as an estimating function of the parameter of interest, which is
needed for the estimating function methodology ), but not for targeted MLE.
As previously argued, a sieve-based maximum likelihood estimator of a
pathwise diﬀerentiable parameter is based on choices such as the sieve and
the criteria for trading oﬀvariance and bias, which is completely unrelated to
the actual parameter Ψ. As a consequence, such likelihood based estimators
suﬀer, in principle, from serious bias for the parameter of interest ψ0. Let p0
be such a likelihood based estimator of p0 and Ψ(p0
n) be the corresponding
substitution estimator of ψ0.
On the other hand, estimating function methodology ) constructs estimating functions Dh(ψ, υ)(O) for the parameter
of interest ψ indexed by a choice h, based on a representation of the orthogonal
complement of the nuisance tangent space p →T ⊥
nuis(p) (i.e., Dh(Ψ(p), Υ(p)) ∈
nuis(p) for all h), which typically also depend on an unknown nuisance parameter Υ satisfying EpDh(Ψ(p), Υ(p)) = 0 for all p ∈M.
The current
recommendation in estimating function methodology ) proposes to use an external estimator υn of nuisance parameters and estimate ψ0 with the solution of 0 = PnDhn(ψ, υn) = 0 in ψ. For
example, one could use the maximum likelihood estimator p0
n and estimate ψ0
with the solution ψn0 of 0 = PnDh(p0n)(ψ, Υ(p0
n)). This estimator ψn0 is not
necessarily, and in fact, will typically not be equal to Ψ(p0
n). Thus, even if
the nuisance parameters are based on a maximum likelihood estimator p0
van der Laan and Rubin: Targeted Maximum Likelihood Learning
resulting estimating function based estimators of ψ0 are intrinsically diﬀerent
from (and less biased than) the likelihood based estimator Ψ(p0
However, let pn be the targeted maximum likelihood estimator based on
hardest submodels at p with eﬃcient inﬂuence curve D(p) = Dh(p)(Ψ(p), Υ(p))
and starting with the initial density estimator p0
n, so that pn solves PnD(pn) =
Dh(pn)(Ψ(pn), Υ(pn)) = 0. Again, we consider the (now targeted) maximum
likelihood estimator Ψ(pn) versus the estimating function based estimator
described in the previous paragraph.
The estimating function based estimator ψn of ψ0 is deﬁned as the solution of the estimating equation 0 =
PnDh(pn)(ψ, Υ(pn)), which diﬀers from above by now using the targeted MLE
pn (based on p0
n) to estimate the index and nuisance parameters (instead of
likelihood based p0
n). Because PnDh(pn)(Ψ(pn), Υ(pn)) = 0, it follows that the
estimating function based estimator ψn now equals Ψ(pn), assuming that this
solution is unique. That is, if one estimates the nuisance parameters and index
in the estimating function methodology with a targeted maximum likelihood
estimator pn, then the (or, at least, one of the) estimating function based estimator ψn and the targeted maximum likelihood estimator Ψ(pn) are identical.
Note that the targeted MLE is more general than the estimating function
based methodology since it does not require the representation of an estimating
function as a function of the parameter of interest and a variation independent nuisance parameter, thereby making it more widely applicable. Another
advantage of targeted MLE relative to estimating function based estimation
that it is invariant to monotone transformations of the parameter of interest.
CAR-censored data models
This targeted MLE approach has a particular nice application in estimation of
pathwise diﬀerentiable parameters based on censored data under the coarsening at random assumption , Jacobsen and Keiding
 , Gill et al. , van der Laan and Robins ).
That is, let
O = Φ(C, X) ∼p0 for some known many to one mapping Φ, X ∼FX0 is
the full data structure one wishes to observe on a randomly sampled experimental unit, and assume that the conditional distribution of the censoring
variable C, given X, i.e., the censoring mechanism, satisﬁes coarsening at
random (CAR). In this case it is known that the density of O factorizes as:
p0(0) = g(p0)(O | X)Q(p0)(O), where g(p0)(O | X) (which is only a function
of O by CAR) is the conditional density of O, given X, which thus only depends on the conditional distribution of C, given X. The Q(p0) factor only
depends on the distribution FX0 of the full data structure X ).
Thus given a model M for O obtained by modelling
The International Journal of Biostatistics, Vol. 2 , Iss. 1, Art. 11
DOI: 10.2202/1557-4679.1043
FX0 and or the censoring mechanism g0(O | X), each p ∈M is identiﬁed
by (g(p), Q(p)). Let Ψ(p) = Ψ(Q(p)) be a pathwise diﬀerentiable parameter of the Q(p)-part of the density p of O: i.e., it represents an identiﬁable
parameter of FX. In this case, it is known that the eﬃcient inﬂuence curve
D(p) = D(g(p), Q(p)) at p ∈M is orthogonal to the tangent space TCAR(p)
of the censoring mechanism g at p only assuming CAR (i.e., the Hilbert space
0(P) spanned by all scores of parametric submodels through g(p) at p),
where TCAR(p) = {h(O) : Ep(h(O) | X) = 0} consists of all functions of O
with conditional mean, given X, equal to zero. As a consequence, given an
initial estimator Q0 of Q(p0) and g0 of g(p0), a hardest parametric model for
0 can be chosen to be of the form p0(ϵ) ≈(1 + ϵD(p0))p0 = g0Q0(ϵ), where
Q0(ϵ) ≈(1 + ϵD(Q0, g0))Q0. That is, the hardest parametric model only corresponds with changing Q0, but it leaves g0 untouched. The targeted MLE
approach proceeds now as deﬁned above.
Targeting the censoring mechanism.
In this subsection we propose a targeted maximum likelihood methodology
for estimation of ψ0 which involves updating of estimators of both g0 and Q0.
As shown in van der Laan and Robins (Theorem 1.3), we have that
any gradient D(p) can be decomposed as D(p) = DIP CW (p) −DCAR(p) with
DIP CW being a so called Inverse Probability of Censoring Weighted (IPCW)
function, and DCAR(p) = Π(DIP CW (p) | TCAR(p)) is the projection of the
IPCW function DIP CW (p) onto TCAR(p) in the Hilbert space L2
0(p). In order
to relate these functions to estimating functions for ψ0 ) we will also sometimes use DIP CW (p) = DIP CW (g(p), Ψ(p))
and D(p) = D(g(p), Q(p), Ψ(p)) in the case that these functions can be represented as an estimating function in ψ indexed by nuisance parameters being functions of g(p) and Q(p): we note that the IPCW estimating function
typically only depends on p through g(p) and Ψ(p).
Given an initial estimator p0
n), in the censored data literature one deﬁnes the IPCWestimator and DR-IPCW estimator as the solutions of the estimating equations PnDIP CW (g0
n, ψ) = 0 and PnD(g0
n, ψ) = 0, respectively, and Ψ(Q0
is called the likelihood based estimator (making the assumption that Q0
likelihood based).
We will now describe the targeted MLE algorithm also involving the updating of g0
n. At step k it now involves also a parametric submodel g(pk
through g(pk
n) with score DCAR(gk
n) at ϵ2 = 0.
It can be shown that
DCAR(g(p), Q(p)) corresponds with the eﬃcient inﬂuence curve of the parameter Φ(g) = EpDIP CW (g, Q(p)) at g = g(p), so that this parametric submodel
van der Laan and Rubin: Targeted Maximum Likelihood Learning
makes the estimator of g0 targeted for estimation of the mean of the IPCWcomponent of the eﬃcient inﬂuence curve. In particular, it is also the parametric submodel which makes the IPCW estimator ψn,IP CW , deﬁned as the
solution of the IPCW estimating equation 0 = PnDIP CW (gn, ψ), eﬃcient if
the submodel is correctly speciﬁed, under regularity conditions. As above, let
n(ϵ1) be a parametric submodel through Qk
n with score D(gk
n) at ϵ1 = 0.
Targeted MLE algorithm:
• Set k = 0.
• Let ϵ1nk = arg maxϵ1 Pn log Qk
n(ϵ1), and ϵ2nk = arg maxϵ2 Pn log gk
• Set gk+1
n(ϵ2n) and Qk+1
n(ϵ1n). Set pk+1
• Set k = k + 1, and iterate this process utill convergence.
If ϵ1nk and ϵ2nk converge to zero for k →∞(which can be expected because
both factors g and Q of the likelihood are increasing at each step), then the
targeted MLE algorithm will converge to a simultaneous solution of
k PnDCAR(gk, Qk) = 0 and lim
k PnD(gk, Qk) = 0.
Equivalence of IPCW, DR-IPCW, and targeted MLE: As a consequence of the decomposition D(p) = DIP CW (p) −DCAR(p), this implies also
limk DIP CW (gk, Ψ(Qk)) = 0. Note that the double robust IPCW estimator
deﬁned as the solution in ψ of PnD(gk
n, ψ) = 0, the targeted maximum
likelihood estimator Ψ(Qk
n), and the IPCW estimator deﬁned as the solution
n, ψ) = 0, all based on these targeted MLE’s gk
n are identical
up to an arbitrarily small error decreasing in k (assuming uniqueness of the
DR-IPCW and IPCW solution).
Examples of targeted maximum likelihood.
In this section we provide some important examples of the targeted MLE
to illustrate its remarkable simplicity and good properties.
For additional
examples we refer to our accompanying technical report.
The International Journal of Biostatistics, Vol. 2 , Iss. 1, Art. 11
DOI: 10.2202/1557-4679.1043
Estimation of a mean in a nonparametric model.
Consider an initial data generating density p0
n (with respect to a dominating
measure µ) of a possibly multivariate random variable O, a given function
w(·), and deﬁne the parameter of interest as
Ψ(p) = Ep[w(O)] =
w(o)p(o)dµ(o).
For the exponential family
exp(ϵ(w(x) −ψ0
R exp(ϵ(w(x) −ψ0
n(x)dµ(x) : ϵ
consider attempting to estimate ϵ with maximum likelihood based on an i.i.d.
sample {Oi}n
i=1. Here ψ0
n). The log likelihood is then,
n(Oi))+ϵ(w(Oi)−ψ0
exp(ϵ(w(x) −ψ0
In our accompanying technical report we show that (for each initial p0
n) the onestep targeted maximum likelihood estimator Ψ(p1
n(ϵn) of the mean of
w(O) equals the sample mean ¯Wn = 1
i=1 w(Oi). For the detailed proof we
refer to our technical report.
Estimation of a marginal causal eﬀect.
Double robust locally eﬃcient estimation of the causal eﬀect of a point treatment assuming a marginal structural model has been provided in Robins
 , Robins and Rotnitzky , and Robins et al. : see also van der
Laan and Robins .
Let O = (W, A, Y ), W be a vector of baseline covariates, A be a binary
treatment variable, and Y an outcome of interest. Let M be the class of all
densities of O with respect to an appropriate dominating measure: so M is
nonparametric up to possible smoothness conditions. Let Ψ : M →IR be
deﬁned as Ψ(p) = Ep(Ep(Y | A = 1, W) −Ep(Y | A = 0, W)), where it is
assumed 0 < P(A = 1 | W) < 1 with probability one so that this parameter
is well deﬁned. This parameter corresponds with the marginal causal eﬀect of
A on Y if one assumes the usual consistency assumption, temporal ordering
assumption, and randomization assumption required for causal inference. In
order to acknowledge that this parameter is of interest in general, van der
Laan refers to this parameter as the variable importance of variable
van der Laan and Rubin: Targeted Maximum Likelihood Learning
A. This parameter Ψ(p) is pathwise diﬀerentiable at p with eﬃcient inﬂuence
curve S(p) deﬁned by
(Y −Q(p)(A, W))(I(A = 1) −I(A = 0))
g(p)(A | W)
+Q(p)(1, W) −Q(p)(0, W) −Ψ(p),
where g(p)(· | W) = Prp(A = · | W), and Q(p)(A, W) = Ep(Y | A, W)
 , van der Laan ). Note that Ψ(p) depends on
p through Q(p) and its marginal distribution pW of W. Because the model
is locally saturated, it is also the only inﬂuence curve/gradient ). So we set D(p) = S(p).
We can decompose this eﬃcient score D(p) into three subcomponents as
D(p) −Ep(D(p) | A, W) + Ep(D(p) | A, W) −Ep(D(p) | W)
+Ep(D(p) | W) −EpD(p),
which corresponds with scores for p(Y | A, W), p(A|W) and p(W), respectively. We have
D(p) −Ep(D(p) | A, W)
(Y −Q(p)(A, W))A −(1 −A)
g(p)(A | W)
Ep(D(p) | A, W) −Ep(D(p) | W)
Ep(D(p) | W) −Ep(D(p))
Q(p)(1, W) −Q(p)(0, W) −Ψ(p).
Consider an initial density estimator p0
n of the density p0 of (W, A, Y )
with marginal distribution of W being the empirical probability distribution
of W1, . . ., Wn. We have that D(p0
n) = D1(p0
n) + D2(p0
n) and thus that a onedimensional p0
n(ϵ) with score D(p0
n) at ϵ = 0 corresponds with a zero score for
n). In addition, we have that PnD2(p0
n) = 0 (i.e., the empirical distribution
of W is a nonparametric maximum likelihood estimator) so that p0
n(ϵ) can be
selected to only vary p0
n(Y | A, W) with a score D1(pn) at ϵ = 0.
We now propose an easily implemented targeted maximum likelihood estimator of the marginal causal eﬀect by using a normal regression model as
hardest submodel. Speciﬁcally, consider an initial density estimator p0
marginal distribution of W equal to the empirical probability distribution
of W1, . . ., Wn, and let the conditional probability density p0
n(Y | A, W) =
The International Journal of Biostatistics, Vol. 2 , Iss. 1, Art. 11
DOI: 10.2202/1557-4679.1043
σ(Q0n)(A,W )f0({Y −Q0
n(A, W)}/σ(Q0
n)(A, W)) be a normal density with mean
n(A, W) and variance σ(Q0
n)2(A, W). Here f0 denotes the N(0, 1) density.
In addition, g(pn
0)(A | W) is a particular ﬁt of the conditional density of A,
given W. We now consider as possible submodels p0
n(ϵ)(Y | A, W) =
σ(Q0n(A, W)f0
n(A, W) −ϵh(p0
σ(Q0n)(A, W)
where the function h will be speciﬁed so that the score of p0
n at ϵ = 0 equals
the eﬃcient inﬂuence curve at p0
n. The maximum likelihood estimator of ϵ is
simply given by the weighted least squares estimator for a univariate linear
regression model:
ϵn = arg min
n(Ai, Wi) −ϵh(p0
n)(Ai, Wi))2
σ(Q0n)2(Ai, Wi).
The score of p0
n(ϵ)(Y | A, W) at a value ϵ is given by:
S(ϵ) = −Y −Q0
n(A, W) −ϵh(p0
σ(Q0n)2(A, W)
and ϵn solves indeed PnS(ϵn) = 0. If we set
n)(A, W) ≡
n(1 | W) −I(A = 0)
n)2(A, W),
then the score S(0) = D1(p0
n) = (Y −Q0
n(A, W))(I(A = 1)/g0
n(1 | W) −I(A =
n(0 | W)) of p0
n(ϵ)(Y | A, W) at ϵ = 0 corresponds with the eﬃcient
inﬂuence curve at p0
n. As in our previous subsection, since p0
n(W) equals the
empirical distribution of W the MLE of ϵ1 →Pn log p0(ϵ1)(W) equals ϵ = 0,
n(A | W) will not be varied by p0
n(ϵ): that is, the marginal distribution
of W and the treatment mechanism g0(A | W) will not be updated in the
algorithm for calculating the targeted maximum likelihood estimator.
n(ϵn) whose conditional distribution of Y , given A, W, is a
normal density with mean Q1
n(A, W) and variance σ2(Q1
n)(A, W), where
n(A, W) = Q(p1
n)(A, W) = Q0
n(A, W) + ϵnh(p0
The corresponding estimate of ψ0 is given by
n(1, Wi) −Q1
van der Laan and Rubin: Targeted Maximum Likelihood Learning
It is straightforward to show that PnD(p1
n) = 0 in the case that σ0
is constant in the model {p0
n(ϵ) : ϵ}, but is simply set at an initial estimate.
Thus in this case the targeted maximum likelihood is achieved at the ﬁrst step.
For arbitrary ﬁxed values of σ(A, W), the targeted MLE is locally eﬃcient in
the sense that if g(p0
n) is consistent at some rate, then it is consistent and
asymptotically linear for arbitrary Q0
n, and it is eﬃcient if Q0
n is consistent for
Q0(A, W). Likewise, a consistent Q1
n(A, W) will lead to a consistent estimator
of the parameter of interest ψ0, even with an arbitrary ﬁt of the treatment
mechanism g(A|W). Iterative estimation of σ provides no (asymptotic) reward, and could simply be omitted by setting (e.g.) σ at an initial estimate,
so that the targeted MLE is achieved in a single step.
Targeting the treatment mechanism as well.
We will now proceed with this example, but also use for g0 a targeted maximum
likelihood estimator. Our goal is to make the IPTW estimator ψn,IP T W =
I(Ai=1)−I(Ai=0)
corresponding wiht the targeted MLE gn an eﬃcient
estimator. Let g(p0
n)(A | W) be an initial estimator and represent it as a
logistic function:
n)(1 | W) =
1 + exp(−m0n(W)).
Consider as parametric submodel
n)(ϵ2)(1 | W) =
1 + exp(−m0
n(W) −ϵ2h(p0
Let ϵ2n = arg max Pn log g(p0
n)(ϵ). In practice this can be done by ﬁtting a
logistic regression in the covariates m0
n(W) and h(p0
n)(W), setting the intercept equal to zero, and setting the coeﬃcient in front of m0
n(W) equal to 1,
and set ϵ2n equal to ﬁtted coeﬃcient in front of h(p0
n)(W). It is also ﬁne to
reﬁt the intercept and coeﬃcient in front of m0
n(W), since choosing additional
parameters still guarantees that the linear span of scores includes the score of
n)(W). We have
(O) = h(p0
n)(W)(A −g(p0
n)(1 | W)).
Solving for h so that
h(W)(A −g(p0
n)(1 | W))
The International Journal of Biostatistics, Vol. 2 , Iss. 1, Art. 11
DOI: 10.2202/1557-4679.1043
{I(A = 1) −I(A = 0)}
n)(1, W) −Q(p0
yields the solution
n)(W) = Q(p0
g(p0n)(1 | W) + Q(p0
g(p0n)(0 | W).
We are now ready to present the proposed targeted MLE which also targets
the treatment mechanism ﬁt.
The algorithm for targeted maximum likelihood estimation of a
marginal causal eﬀect, including the targeting of the treatment mechanism.
Thus the algorithm for targeted maximum likelihood estimation of
0 can be described as follows. Let k = 0, and let g0(A | W) and the regression
ﬁt Q0(A, W) of E0(Y | A, W) be given. Let
1 = h1(gk, Qk)(A, W) ≡
gk(1 | W) −I(A = 0)
σ(Qk)2(A, W)
2 = h2(gk, Qk)(W) = Qk(1, W)
gk(1 | W) + Qk(0, W)
gk(0 | W).
Let mk(W) = log(gk(1 | W)/gk(0 | W)) so that gk(1 | W) = 1/(1 +
exp(−mk(W)). Consider the logistic regression model
gk(ϵ2)(1 | W) =
1 + exp(−mk(W) −ϵ2hk
Let ϵ2n(k) = arg maxϵ2 Pn log gk(ϵ2) be the maximum likelihood estimator of
this univariate logistic regression model, and let
ϵ1n(k) = arg min
(Yi −Qk(Ai, Wi) −ϵ1hk
1(Ai, Wi))2
σ(Qk)2(Ai, Wi),
the univariate least squares estimator of ϵ1.
Now, update gk and Qk as follows:
Qk+1(A, W)
Qk(A, W) + ϵ1n(k)hk
mk+1(A, W)
mk(W) + ϵ2n(k)hk
gk+1(A | W)
1 + exp(−mk+1(W))
Set k = k + 1 and iterate this algorithm.
van der Laan and Rubin: Targeted Maximum Likelihood Learning
Equivalence of IPTW, DR-IPTW, and targeted maximum likelihood estimators.
Recall that the eﬃcient inﬂuence curve function is decomposed as D(g, Q)(O) = DIP T W(g, Q)−DCAR(g, Q), where DIP T W (g, Q) =
g(A|W )(I(A = 1) −I(A = 0)) −Ψ(Q), and DCAR(g, Q) =
g(A|W ) (I(A =
1) −I(A = 0)) −(Q(1, W) −Q(0, W)).
For k converging to inﬁnity the
targeted MLE yields a ﬁnal estimator gn of the treatment mechanism and a
regression ﬁt Qn(A, W) so that the score equations of the two submodels in ϵ1
and ϵ2 are solved at ϵ1 = ϵ2 = 0:
PnD(gn, Qn) = 0 and PnDCAR(gn, Qn) = 0.
This implies also that
PnDIP T W(gn, Qn) = 0.
Thus, we can conclude that the three estimators
gn(Ai | Wi)(I(Ai = 1) −I(Ai = 0))
Ψn,DR−IP T W
gn(Ai | Wi)(I(Ai = 1) −I(Ai = 0))
DCAR(gn, Qn)(Ai, Wi)
Qn(1, Wi) −Qn(0, Wi)
are algebraically identical: Ψn,IP TW = Ψn,DR−IP T W = Ψn,MLE. That is, the
targeted MLE Ψ(Qn) equals the IPTW and DR-IPTW estimator based on the
targeted MLE (gn, Qn) as estimators of the nuisance parameters (g0, Q0) in the
corresponding estimating equations. Preliminary results suggest that consistency of the resulting targeted likelihood algorithm depends on the consistency
of either the g0 or Q0 component of the initial density estimator.
Simulation for marginal variable importance.
Simulated data can be used to illustrate the beneﬁts of the targeted likelihood
procedure. We simulated replicates of the data structure O = (W, A, Y ) ∼p0
representing baseline covariates, a binary treatment, and a response measurement on a subject, and attempted to estimate the causal eﬀect of treatment
A on response Y . We generated 1000 datasets of size n = 200 according to
the following mechanism:
The International Journal of Biostatistics, Vol. 2 , Iss. 1, Art. 11
DOI: 10.2202/1557-4679.1043
P(A = 1|W) =
1 + exp(−8W2 + 8W −1)
AQ(1, W) + (1 −A)Q(0, W) + ϵ
3, Q(1, W) = −(8W 2 −8W + 1)
Here O represented a censored data structure. The unavailable counterfactual data was given by,
X = (W, Y0, Y1) = (W, Q(0, W) + ϵ, Q(1, W) + ϵ).
It could be be veriﬁed that the coarsening at random assumption held, or that,
as well as the experimental treatment assignment assumption, implied by,
0 < 0.26 < g(1|W) < .74 < 1 with probability one.
Together these assumptions made it possible to estimate the parameter,
Ψ(p0) = E[Y1] −E[Y0] = 1,
representing the counterfactual mean diﬀerence between the treatment group
(A = 1) and the control group (A = 0).
The standard estimators for this problem are the inverse probability of
treatment (IPTW), maximum likelihood (G-computation), and doubly robust
(eﬃcient) estimators. These respectively depend on ﬁtting either the censoring
mechanism g or the nuisance parameter Q(A, W) = E[Y |W], and are given as
follows, where hg(A, W) =
Ψn,IPTW(g)
Yihg(Ai, Wi)
[Q(1, Wi) −Q(0, Wi)]
Ψn,DR-IPTW(g, Q)
Ψn,IPTW + Ψn,MLE −1
hg(Ai, Wi)Q(Ai, Wi)
Typically estimation is based on forming external estimates of at least one
of the two nuisance parameters g or Q, and then applying one of the IPTW,
van der Laan and Rubin: Targeted Maximum Likelihood Learning
maximum likelihood, or double robust estimators. The three estimators can
potentially be very diﬀerent from one another, leading to diﬃculties when
interpreting the data. Targeted likelihood resolves this problem, by estimating
both nuisance parameters g and Q accurately with maximum likelihood, but in
a way so that the IPTW, maximum likelihood, and doubly robust estimators
are algebraically equivalent.
As our initial ﬁt to p0 prescribed that {Y |A, W} followed a Gaussian distribution with ﬁxed variance, the hardest one-dimensional submodel ϵ →pϵ
for estimation of Ψ(p0) could be given by,
{Y |A, W} ∼N(Q(0)
n (A, W) + ϵhg(A, W), σ2),
while the laws of {W} and {A|W} were left unchanged. The maximum likelihood estimator of ϵ became,
i=1 hg(Ai, Wi)(Yi −Q(0)
n (Ai, Wi))
i=1 hg(Ai, Wi)
leading to the updated estimate of Q(A, W) = E[Y |A, W],
n (A, W) = Q(0)
n (A, W) + ϵnhg(A, W).
When the treatment mechanism g was not updated, the targeted likelihood
algorithm converged in a single iteration. Note that the update did not depend in any way on the choice of variance σ2 for the law of {Y |A, W}, so
long as it was a constant.
The parameter Ψ(p0) was then estimated with
Ψ(p(ϵn)), which was equal to Ψn,MLE(Q(1)
n ) and Ψn,DR-IPTW(g, Q(1)
treatment mechanism g could also be updated with targeted likelihood, to
make the IPTW estimator equivalent with the maximum likelihood and double robust estimators.
This was done by making a one-dimensional model
gϵ(1|W) through g(1|W) at ϵ = 0, whose score at ϵ = 0 was the projection of
the IPTW estimator’s inﬂuence curve on TCAR. Such a submodel could be
formed by taking,
logit(gϵ(1|W)) = g(1|W) + ϵ[Q(1, W)
g(1|W) + Q(0, W)
Because this was simply a logistic model for {A|W}, we could estimate ϵ
through logistic regression. After iterating the targeted likelihood procedure
to update both of the Q and g nuisance parameters until convergence, the
IPTW, maximum likelihood, and double robust estimators of Ψ(p0) became
equivalent.
The International Journal of Biostatistics, Vol. 2 , Iss. 1, Art. 11
DOI: 10.2202/1557-4679.1043
For this data structure, Ψn,DR-IPTW(g, Q) was asymptotically eﬃcient,
meaning that its asymptotic performance was superior to any other regular
estimator.
This eﬃcient estimator could not be used directly on observed
data, due to its dependence on the unknown nuisance paramters g and Q. We
assessed the quality of an estimator Ψn through the ratio
Ep0[n|Ψn −Ψ(p0)|2]
Ep0[n|Ψn,DR-IPTW(g, Q) −Ψ(p0)|2]
For large enough sample size n, and consistent and asymptotically linear Ψn,
this approximated the asymptotic relative eﬃciency of Ψn to the eﬃcient estimator, and necessarily exceeded one. We approximated R(Ψn) after forming
Ψn on 1000 simulated datasets of size n = 200.
In our simulations, we considered known censoring mechanism g, as could
occur in a randomized clinical trial. We misspeciﬁed the nuisance parameter
Q, by estimating E[Y |W] in the A = 0 and A = 1 strata with linear regression, while quadratic regression would have been appropriate. This ﬁrst-order
approximation to Q lead to an inaccurate maximum likelihood estimator, having R(Ψn) = 2.63. Conﬁdence intervals for R(Ψn) were negligible, due to the
number of simulations. The misspeciﬁed nuisance parameter Q did not aﬀect
the performance of the IPTW estimator, or the consistency of the double robust estimator, which respectively had asymptotic relative eﬃciencies R(Ψn)
of 1.18 and 1.15. Note that the IPTW estimator was unbiased, but was less
accurate than the double robust estimator with misspeciﬁed Q. After updating Q with a single targeted likelihood iteration, R(Ψn) decreased to 1.10.
The resulting estimator was then a maximum likelihood estimator (and double robust estimator) with updated Q, and the update greatly increased of
the accuracy of the parameter estimate. When also updating the censoring
mechanism g, the asymptotic relative eﬃciency dropped even further to 1.07,
making the estimator almost equivalent with the eﬃcient estimator. In spite
of the fact that the censoring mechanism g was already known, estimating it
from the data was nevertheless beneﬁcial, as could be surmised from Chapter
2.3.7 of ).
Thus, the targeted likelihood algorithm allowed us to estimate the nuisance
parameters g and Q with maximum likelihood in a manner such that three
standard estimators become identical, and led to better performance than
was achieved by the initial IPTW, maximum likelihood, and double robust
estimators.
van der Laan and Rubin: Targeted Maximum Likelihood Learning
Semiparametric regression example.
Let O = (W, A, Y ) ∼p0 and consider the semiparametric regression model
M = {p : Ep(Y | A, W) −Ep(Y | A = 0, W) = m(A, W | β(p))} for some
parametrization β →m(A, W | β) satisfying m(0, W | β) = 0 for all β ∈IRd.
This is equivalent with assuming E0(Y | A, W) = m(A, W | β0) + θ0(W)
with θ0 unspeciﬁed and m(0, W | β) = 0, and can therefore also be viewed
as a semiparametric regression model. It has been recognized that a maximum likelihood ﬁt (e.g., generalized additive models) of the semiparametric
regression suﬀers from bias for the parametric part, so that one needs to undersmooth the nonparametric components in the semiparametric regression
model. However, the literature does not provide practical guidance about how
to undersmooth. Therefore, the targeted MLE approach presented here provides an importance practical improvement. Let Ψ(p) = β(p) ∈IRd be the
parameter of interest.
This type of semiparametric regression models has been considered by
various authors ; Rosenbaum and Rubin ; Robins
et al. ; Robins and Rotnitzky; Yu and van der Laan ). The latter three articles derive the orthogonal complement of the nuisance tangent
space (i.e., the set of all gradients of the pathwise derivative), the eﬃcient in-
ﬂuence curve/canonical gradient, and establish the wished double robustness
of the corresponding estimating functions. In particular, for our purpose we
refer to Theorem 2.1 and 2.2 in Yu and van der Laan for the following
statements.
The orthogonal complement of the nuisance tangent space is given by:
nuis(p) = {Dh(p) : h} ⊂L2
where Dh(p)(O) ≡(h(A, W) −Ep(h(A, W) | W))(Y −m(A, W | β(p)) −
Ep(Y | A = 0, W)).
The orthogonal complement of the nuisance tangent
space corresponds with the set of gradients for Ψ at p given by:
−c(p)(h)−1Dh(p)(O) : h = (h1, . . ., hd)
where c(p)(h) =
dβEpDh(p, β)
β=β(p), and Dh now represents a vector function
(Dh1, . . . , Dhd). The eﬃcient inﬂuence curve is identiﬁed by a closed form index
h(p) ), which is provided below (12). Let
D(p) = Dh(p)(p) be this eﬃcient inﬂuence curve at p as identiﬁed by this index
Let g(p) be the conditional density of A, given W, under p, let Q(p) be
the conditional distribution of Y , given A, W, under p.
We note that the
The International Journal of Biostatistics, Vol. 2 , Iss. 1, Art. 11
DOI: 10.2202/1557-4679.1043
parameter Ψ(p) is only a function of Q(p), and the density factorizes as p(O) =
p(W)g(p)(A | W)Q(p)(Y | A, W).
As a consequence, the elements Dh(p)
are orthogonal to the tangent spaces of the nuisance parameter g(p) and the
nuisance parameter p(W). That is, we can decompose the eﬃcient score D(p)
into three subcomponents as follows:
D(p) −Ep(D(p) | A, W) + Ep(D(p) | A, W) −Ep(D(p) | W)
+Ep(D(p) | W) −EpD(p),
which corresponds with scores for p(Y
| A, W), p(A|W) and p(W) at p,
respectively, but Ep(D(p) | A, W) −Ep(D(p) | W) = 0 and Ep(D(p) |
W) −E(D(p)) = 0. Thus the eﬃcient inﬂuence curve D(p) represents only a
score for Q(p)(Y | A, W), and indeed satisﬁes Ep(D(p)(O) | A, W) = 0.
Consider an initial density estimator p0
n)) of (W, A, Y )
with marginal distribution of W being the empirical probability distribution
of W1, . . ., Wn. Above we showed that a submodel p0
n(ϵ) through p0
n with score
n) at ϵ = 0 can be selected to only vary the conditional density Q(p0
Y , given A, W, with a score D(p0
n) at ϵ = 0. Such a submodel will now be
presented.
Suppose that Q(p0
n) is a normal distribution with mean
n)(A, W) = Ep0n(Y | A, W) and variance σ2(A, W) = σ2(Q0
n)(A, W). Recall
n) = (h(p0
n)(A, W) −Ep0n(h(p0
n) | W))(Y −m(A, W | β(p0)) −Ep0n(Y |
A = 0, W)). For notational convenience, we will represent this function as
n)(A, W)(Y −Ep0n(Y | A, W)) with now h(p0
n) so that Ep0n(h(p0
n)(A, W) |
Consider the parametric submodel of M deﬁned as the normal
density with conditional variance σ2(A, W) and conditional mean m(A, W |
n(ϵ)) + θ0
n(ϵ). That is,
n(ϵ)(Y | A, W) =
Y −m(A, W | β0
n(0) = β(Q0
n(0) = θ(Q0
n) = EQ0n(Y | A = 0, W), and f0 is the
standard normal density. We note that this is a valid submodel through Q0
at ϵ = 0. Let β(ϵ) ≡β(Q0
n) + ϵ and θ0
n(ϵ) = θ(Q0
n) + ϵ⊤r. It remains to ﬁnd a
function r(W) so that the score of Q0
n(ϵ) at ϵ = 0 equals the eﬃcient inﬂuence
curve D(p0
We have that the score S(ϵ) at ϵ is given by (note that f ′
0(x)/f0(x) = 2x/σ2)
S(ϵ)σ2(A, W)
(Y −m(A, W | β0
dϵm(A, W | β0
van der Laan and Rubin: Targeted Maximum Likelihood Learning
n(ϵ)m(A, W | β0
n(ϵ)) −r(W))
(Y −m(A, W | β0
Solving for r so that S(0) = D(p0) yields the equation
n)(A, W)(Y −EQ0(Y | A, W)) =
dβ(Q0n)m(A, W | β(Q0
(Y −EQ0n(Y | A, W)).
In order to have that the score equals Dh for a particular h(A, W) with
Ep0n(h(A, W) | W) = 0, we need
nm(A,W |β0
σ2(A,W ) | W
This yields the following score for our submodel p0
n(ϵ) at ϵ = 0:
S(0) = h(p0
n)(A, W)(Y −m(A, W | β(Q0
dβ(Q0n)m(A, W | β(Q0
dβ(Q0n)m(A, W | β(Q0
n))/σ2(A, W) | W
Ep0n(1/σ2(A, W) | W)
This choice h(p0
n) gives a score S(0) equal to the eﬃcient inﬂuence curve ). So we succeeded in ﬁnding a submodel
n(ϵ) with a score at ϵ = 0 equal to the eﬃcient inﬂuence curve at p0
we are now ready to deﬁne the targeted MLE.
Consider the log-likelihood for p0
n(ϵ) in ϵ:
Yi −m(Ai, Wi | β0
n + ϵ) −(θ0
n(W) + ϵ⊤r(p0
Let ϵn be the maximizer, which can thus be computed with standard weighted
least squares regression:
ϵn = arg min
σ2(Ai, Wi)
Yi −m(Ai, Wi | β0
n + ϵ) −θ0
n(Wi) −ϵr(p0
The score equation 0 = d/dϵl(ϵ) = PnS(ϵ) for ϵn is given by
dβ0n(ϵ)m(β0
n(ϵ)) −r(p0
The International Journal of Biostatistics, Vol. 2 , Iss. 1, Art. 11
DOI: 10.2202/1557-4679.1043
In the sequel we consider the case that m(A, W | β) = β⊤m1(A, W) is linear in β for some speciﬁed covariate vector m1(A, W). In this case we have
d/dβm(A, W | β) = m1(A, W) so that the score equation PnS(ϵ) = 0 reduces
n)} (Y −(β0
n + ϵn)m1 −θ0
Firstly, we note that ϵn exist in closed form:
n)} (Y −β0⊤
where the d × d matrix An is given by
σ2(Ai, Wi)
m1(Ai, Wi) −r(p0
(m1(Ai, Wi) + r(p0
n(ϵn) be the new density estimator. Recall that the distribution of
(A, W) under p0
n(ϵn) is still the same as under p0
n, because p0
n(ϵ) only updates
the conditional distribution of Y , given A, W. We now wish to investigate
if the ﬁrst step targeted MLE p1
n(ϵn) already solves the eﬃcient score
equation: PnD(p1
n) = PnD(p0
n(ϵn)) = 0. We have that PnD(p0
n(ϵn)) is given by
n(ϵn))} (Y −(β0
n + ϵn)m1 −θ0
n −ϵnr(p0(ϵn)))
Because r(p0
n(ϵ)) = r(p0
n), it follows that PnD(p0(ϵn)) is given by
n)} (Y −(β0
n + ϵn)m1 −θ0
but the latter equals zero by the fact that PnS(ϵn) = 0 (12). This proves that,
if m(A, W | β) is linear in β, then the targeted maximum likelihood estimator
is achieved in the ﬁrst step of the algorithm and solves the eﬃcient inﬂuence
curve estimating equation PnD(p) = 0. If one would also update σ2(A, W)
in the submodel p0
n(ϵ), then the algorithm would have to be iterated in order
to converge to a targeted MLE solving PnD(p) = 0. Similarly, for nonlinear
models m(A, W | β) the targeted MLE algorithm will also need to be iterated
till convergence.
Targeted MLE as loss based estimation.
In the previous sections we deﬁned a targeted MLE in terms of an initial
density estimator and the targeted MLE algorithm applied to this initial density estimator. In order to provide a general data adaptive likelihood based
van der Laan and Rubin: Targeted Maximum Likelihood Learning
approach for construction of targeted MLE’s (also allowing for an integrated
data adaptive approach for searching over the initial densities, just as in sieve
based MLE), we now note that the targeted MLE approach corresponds with
a particular modiﬁed log-likelihood loss function. Speciﬁcally, let
L(p | P0) ≡−log p∗(p),
where p∗(p) is deﬁned as the limit for k →∞of the targeted MLE applied to
P0 and starting at p:
pk+1 = arg
p∈{pk(ϵ):ϵ} P0 log p.
Note that L(p | P0) is a loss function for densities p of the data indexed by unknown nuisance parameters, since the ϵk
0 ≡arg maxϵ P0 log pk(ϵ) are unknown.
However, estimation of the unknown nuisance parameter corresponds simply
with applying the targeted MLE algorithm to the data starting at p. The loss
function satisﬁes
p0 = arg min
p∈M P0L(p | P0),
because p∗(p0) = p0 and p0 = arg minp∈M −P0 log p. Therefore, we can apply
the uniﬁed loss based learning approach presented in van der Laan and Dudoit
 based on this new loss function L(p | P0) for a candidate density p.
Succinctly, this loss based learning approach works as follows. Let Ms ⊂M
be a sieve of M indexed by ﬁne tuning parameters s. Let
psn = ˆΦs(Pn) ≡arg min
p∈Ms PnL(p | Pn) = arg max
p∈Ms Pn log p∗
n(p) represents the limit density of the targeted MLE algorithm starting at p applied to the data Pn. Note that this maximization corresponds
with maximizing the log likelihood over solutions of PnD(p∗) = 0, where the
p∗= p∗(p) is restricted by the constraints on the initial p. We can select s
with likelihood based cross-validation:
sn = ˆS(Pn) ≡arg min
n,BnL(ˆΦs(P 0
n,Bn) | P 0
resulting in the targeted ML density estimator
pn ≡psnn =
ˆΦS(Pn)(Pn)
and targeted ML estimator of ψ0 given by ψn = Ψ(pn).
The International Journal of Biostatistics, Vol. 2 , Iss. 1, Art. 11
DOI: 10.2202/1557-4679.1043
Discussion.
In this article we assumed a model in terms of densities with respect to a
known dominating measure, and our targeted MLE density estimators are
assumed to be dominated by this dominating measure. This allowed us to
simplify the presentation of the method. However, we also wish to stress that
the presented targeted maximum likelihood estimation methodology can easily
be generalized to targeted maximum likelihood estimation in models in terms
of probability distributions including (say) discrete as well as continuous distributions, just as this is common practice in maximum likelihood estimation
in semiparametric models. The targeted MLE algorithm takes as input an
initial density with respect to a speciﬁed dominating measure, and is based on
a hardest submodel in terms of densities with respect to this same dominating
measure. Thus, the targeted MLE algorithm can be applied to discrete distributions as well as continuous distributions, and as a consequence, the (loss
based) targeted MLE learning as presented in Section 7 applies to models that
are not necessarily dominated by a single dominating measure.
As a further generalization, the iterative principle underlying this work can
be applied to loss functions other than the negative log likelihood. Given a
loss function deﬁned on the data and parameter space (and possibly a nuisance parameter η), we can make a one-dimensional ϵ-extension through a
space containing both the parameter Ψ and nuisance parameter η, initialize
the parameter estimate at Ψ(0), and then update the parameter estimate by
choosing ϵ to minimize the empirical risk
i=1 L(Oi, Ψ(ϵ)|η(ϵ)).
The requirement underlying the procedure is that
dϵL(O, Ψ(ϵ)|η(ϵ))|ϵ=0 is equal to
an estimating equation for the parameter Ψ. If this condition is met, then
solving this estimating equation should correspond to convergence of the iterative empirical risk minimization algorithm. Hence, applying the algorithm
with such a loss function L(O, Ψ|η) leads to a fusion of general loss based
estimation and estimating function methodology.
Given a density estimator we deﬁned a targeted density estimator through
an iterative maximum likelihood algorithm along hardest submodels with a
score equal to the eﬃcient inﬂuence curve of the parameter of interest. This
tool allows us to map any candidate density p into its targeted version p∗
We now showed that by using the minus log density as loss function and
thereby use the log-likelihood criteria in combination with the cross-validated
log-likelihood criteria, but restricted to targeted density estimators only, we can
build data adaptive sieve based algorithms for generating a ﬁnal targeted ML
density estimator and corresponding substitution estimator of the parameter
of interest.
van der Laan and Rubin: Targeted Maximum Likelihood Learning
By restricting the log-likelihood criteria and cross-validated log-likelihood
criteria to targeted densities only, targeted maximum likelihood estimation
provides now a purely likelihood based methodology for estimation of any
kind of parameter such as pathwise diﬀerentiable parameters and inﬁnite dimensional parameters: see our accompanying technical report.
In particular, we showed that targeted maximum likelihood estimation
completely uniﬁes maximum likelihood estimation and estimating function
based estimation, and results in important improvements in both. Targeted
MLE also deals naturally with the issue of multiple solutions of estimating
equations by using the log-likelihood as the criteria to be maximized. Another
nice feature of targeted MLE is that it always improves on the initial density
estimator by increasing the log-likelihood ﬁt. As a consequence, when targeted
MLE is applied to estimate pathwise diﬀerentiable parameters of a full data
distribution FX in CAR censored data models as in ), if one applies the targeted MLE to an initial p0
n being ﬁts of the censoring mechanism g0 and the FX-factor Q0
of the density p0, then it provides an estimator which is guaranteed to be
more eﬃcient than the double robust IPCW estimator based on estimating
the nuisance parameters (g0, Q0) with p0
n. So the targeted MLE algorithm
provides a natural way to always improve on any initial double robust IPCW
locally eﬃcient estimator as presented in van der Laan and Robins .