The Thirty-Third AAAI Conference on Artiﬁcial Intelligence (AAAI-19)
Explainable Reasoning over Knowledge Graphs for Recommendation
Xiang Wang,1∗Dingxian Wang,2† Canran Xu,2 Xiangnan He,3 Yixin Cao,1 Tat-Seng Chua1
1School of Computing, National University of Singapore, 2eBay
3School of Information Science and Technology, University of Science and Technology of China
 , {diwang, canxu}@ebay.com, {xiangnanhe, caoyixin2011}@gmail.com, 
Incorporating knowledge graph into recommender systems
has attracted increasing attention in recent years. By exploring the interlinks within a knowledge graph, the connectivity
between users and items can be discovered as paths, which
provide rich and complementary information to user-item interactions. Such connectivity not only reveals the semantics
of entities and relations, but also helps to comprehend a user’s
interest. However, existing efforts have not fully explored this
connectivity to infer user preferences, especially in terms of
modeling the sequential dependencies within and holistic semantics of a path.
In this paper, we contribute a new model named Knowledgeaware Path Recurrent Network (KPRN) to exploit knowledge
graph for recommendation. KPRN can generate path representations by composing the semantics of both entities and
relations. By leveraging the sequential dependencies within
a path, we allow effective reasoning on paths to infer the
underlying rationale of a user-item interaction. Furthermore,
we design a new weighted pooling operation to discriminate
the strengths of different paths in connecting a user with an
item, endowing our model with a certain level of explainability. We conduct extensive experiments on two datasets about
movie and music, demonstrating signiﬁcant improvements
over state-of-the-art solutions Collaborative Knowledge Base
Embedding and Neural Factorization Machine.
Introduction
Prior efforts have shown the importance of incorporating
auxiliary data into recommender systems, such as user pro-
ﬁles and item attributes . Recently, knowledge graphs
(KGs) have attracted increasing attention , due to its comprehensive auxiliary data: background knowledge of items and
their relations amongst them. It usually organizes the facts
of items in the form of triplets like (Ed Sheeran, IsSingerOf,
Shape of You), which can be seamlessly integrated with useritem interactions . More important, by exploring the interlinks
∗The ﬁrst three authors have equal contribution.
†Dingxian Wang is the corresponding author.
Copyright c⃝2019, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
Figure 1: Illustration of KG-aware recommendation in the
music domain. The dashed lines between entities are the corresponding relations, while the sold lines are the user-item
interactions.
within a KG, the connectivity between users and items re-
ﬂects their underlying relationships, which are complementary to user-item interaction data.
Extra user-item connectivity information derived from
KG endows recommender systems the ability of reasoning
and explainability. Taking music recommendation as an example (Figure 1), a user is connected to I See Fire since she
likes Shape of You sung by the same singer Ed Sheeran. Such
connectivity helps to reason about unseen user-item interactions (i.e., a potential recommendation) by synthesizing
information from paths.
Running Example: (Alice, Interact, Shape of You)∧(Shape
of You, SungBy, Ed Sheeran)∧(Ed Sheeran, IsSingerOf, I See
Fire)⇒(Alice, Interact, I See Fire).
Clearly, the reasoning unveils the possible user intents behind an interaction, offering explanations behind a recommendation. How to model such connectivity in KGs, hence,
is of critical importance to inject knowledge into a recommender systems.
Prior efforts on knowledge-aware recommendation are
roughly categorized into path and embedding fashion. Pathbased methods introduce meta-paths to reﬁne the similarities between users and
items. However, we argue that meta-path is inefﬁcient in reasoning over KGs, owing to the following limitations: 1) As
relations are usually excluded from meta-paths, they hardly
specify the holistic semantics of paths, especially when similar entities but different relations are involved in a metapath; and 2) They fail to automatically uncover and reason
on unseen connectivity patterns, since meta-paths requires
domain knowledge to be predeﬁned.
Another line of research leverages knowledge graph embedding (KGE) techniques, such as TransE and TransR , to regularize the representations of items. As a result, items with similar connected
entities have similar representations, which facilitate the collaborative learning of user interests. Despite performance
improvements, we argue that KGE regularization lacks the
reasoning ability. Specially, it only considers direct relations
between entities, rather than the multi-hop relation paths as
the Running Example shows. Moreover, the characterization
of user-item connectivity is achieved in a rather implicit way,
that is, to guide the representation learning, but not to infer
a user’s preference.
In this work, we aim to ﬁll the research gap by developing a solution that reasons on paths to infer user preferences
on items. In terms of reasoning, we expect our method to
model the sequential dependencies of entities and sophisticated relations of a path connecting a user-item pair. In terms
of explainability, we would like our method to discriminate
the different contributions of different paths, when inferring
user interests.
Towards this end, we propose a new solution, named
Knowledge-aware Path Recurrent Network (KPRN), which
not only generates representations for paths by accounting
for both entities and relations, but also performs reasoning based on paths to infer user preference. Speciﬁcally,
we ﬁrst extract qualiﬁed paths between a user-item pair
from the KG, each of which consists of the related entities and relations. We then adopt a Long Short-Term Memory (LSTM) network to model the sequential dependencies
of entities and relations. Thereafter, a pooling operation is
performed to aggregate the representations of paths to obtain prediction signal for the user-item pair. More importantly, the pooling operation is capable of discriminating
the contributions of different paths for a prediction, which
functions as the attention mechanism . Owing to such attentive effect, our model can offer path-wise explanations
such as Castle on the Hill is recommended since you have
listened to Shape of You sung and written by Ed Sheeran.
We conduct extensive experiments on two datasets to verify
our method.
The contributions of this work are threefold:
• We highlight the importance of performing explicit reasoning on KG to better reveal the reasons behind a recommendation.
• We propose an end-to-end neural network model to learn
path semantics and integrate them into recommendation.
• We contribute a dataset to study KG for recommendation
by aligning a MovieLens benchmark with IMDB. We verify our method on the data, and release the data and the
codes to facilitate the community working on emerging
ﬁeld of KG-enhanced recommendation.
Knowledge-aware Path Recurrent Network
In this section, we elaborate our proposed method, as illustrated in Figure 2. Before introducing our proposed method,
we ﬁrst formally deﬁne Knowledge Graph, user-item data
and describe how to combine them in an enriched knowledge graph as the inputs of our model.
Background
A knowledge Graph (KG) is a directed graph whose nodes
are entities E and edges R denote their relations. Formally,
we deﬁne KG as KG = {(h, r, t)|h, t ∈E, r ∈R}, where
each triplet (h, r, t) indicates a fact that there is a relationship r from head entity h to tail entity t.
The user-item interaction data is usually presented as a
bipartite graph. In particular, we use U = {ut}M
t=1 to separately denote the user set and the item
set, where M and N are the number of users and items,
respectively. Following , we represent the interaction between a user and an
item with a triplet τ =(u, interact, i), if there is an observed
interaction (e.g., rate, click, and view feedbacks), where interact is a pre-deﬁned relation.
We merge the item set and the entity set through
string matching: I ⊆E, so that the two structural data
are integrated into an enriched knowledge graph G
{(h, r, t)|h, r ∈E′, r ∈R′}, where E′ = E ∪U and
R′ = R∪{interact}. For consistency, the Knowledge Graph
(KG) in the rest paper denotes the combined graph G including both original KG and user-item data, otherwise noted.
Preference Inference via Paths
The triplets in the KG clearly describe direct or indirect
(i.e. multiple-step) relational properties of items, which shall
constitute one or several paths between the given user and
item pair. We explore these paths in order to achieve comprehensively reasoning and understanding for recommendation.
Within G, we formally deﬁne the path from the user u to
the item i as a sequence of entities and relations: p = [e1
−−−→eL], where e1 = u, eL = i; (el, rl, el+1) is
the l-th triplet in p, and L −1 denotes the number of triplets
in the path. The construction of paths will be elaborated in
the section of Section Path Extraction.
Next, we will use a realistic example to show the sophisticated relations (i.e. paths) between a user and an item behind their possible interactions, which inspires us to model
the high-level semantics of path compositionally by considering both entities and (multiple-step) relations.
Examples: Consider the music recommendation shown in
Figure 1, where the “listen to Castle on the Hill” behavior of
user Alice can be referred by the following paths:
• p1 = [Alice
−−−−→Shape of You
ContainSong
Castle on the Hill];
Shape of You
Ed Sheeran
IsSingerOf
−−−−−→Castle on the Hill].
Figure 2: Schematic overview of our model architecture. The embedding layer contains 3 individual layers for entity, entity
type, and relation type, respectively. The concatenation of the 3 embedding vectors is the input of LSTM for each path.
Shape of You
InteractedBy
−−−−→Castle on the Hill];
These paths from the same user Alice to the same item Castle on the Hill obviously express their different multiple-step
relations, and implies various compositional semantics and
possible explanations of the listen behavior. In particular, p1
and p2 infer that Alice may prefer songs that belonging to
the album ÷ and the songs sung by Ed Sheeran, while p3
reﬂects the collaborative ﬁltering (CF) effect: similar users
tend to have similar preferences. Therefore, from the view
of reasoning, we consume the connectivity along all paths to
learn compositional relation representations, and weighted
pool them together for predicting the interact relation between the user and the target item.
Task Deﬁnition: Our task can be formulated as follows:
given a user u, a target item i, and a set of paths P(u, i) =
{p1, p2, · · · , pK} connecting u and i, the holistic goal is to
estimate the interaction by:
ˆyui = fΘ(u, i|P(u, i)),
where f denotes the underlying model with parameters Θ,
and ˆyui presents the predicted score for the user-item interaction. Distinct from embedding-based methods, we can
explain ˆyui as the plausibility score of the triplet τ
(u, interact, i) inferred by the connectivity P(u, i).
KPRN takes a set of paths of each user-item pair as input,
and outputs a score indicating how possible the user will interact the target item. As illustrated in Figure 2, there are
three key components: (1) embedding layer to project three
types of IDs information: the entity, entity type, and the relation pointing to the next node into a latent space, (2) LSTM
layer that encodes the elements sequentially with the goal
of capturing the compositional semantics of entities conditioned on relations, and (3) pooling layer to combine multiple paths and output the ﬁnal score of the given user interacting the target item.
Embedding Layer
Given a path pk, we project the type
(e.g., person or movie) and speciﬁc value (e.g., Peter Jackson
or The Hobbit II) of each entity into two separate embedding
vectors, el ∈Rd and e′
l ∈Rd, where d is the embedding
In real-world scenarios, it is common that the same entityentity pairs may have different semantics due to different
relations connecting them. Such differences may reveal the
diverse intents about why a user selected the item. As an
example, let (Ed Sheeran, IsSingerOf, Shape of You) and
(Ed Sheeran, IsSongwriterOf, Shape of You) be the triplets
in two paths referring a user’s preferences. Without specifying the relations, these paths will be represented as the
same embeddings, regardless of the possibility that the user
only prefers songs sung by Ed Sheeran, rather than that
written by Ed Sheeran. We hence believe that it is important to explicitly incorporate the semantics of relations into
path representation learning. Towards this end, each relation
rl in pk is represented as an embedding vector rl ∈Rd.
As a result, we obtain a set of embeddings for path pk,
[e1, r1, e2, · · · , rL−1, eL], where each element denotes an
entity or a relation.
LSTM Layer
With the embedding sequence to describe
a path, we can employ RNN models to explore the sequential information, and generate a single representation for encoding its holistic semantics. Among various RNN methods , we adopt LSTM since it is capable
of memorizing long-term dependency in a sequence. Such
long-term sequential pattern is crucial to reason on paths
connecting a user and item entities to estimate the conﬁdence of the “interact” relation.
At the path-step l −1, the LSTM layer outputs a
hidden state vector hl−1, consuming the subsequence
[e1, r1, · · · , el−1, r1−1]. Simultaneously, we concatenate the
embedding of current entity el−1 and relation rl−1 as the input vector:
xl−1 = el−1 ⊕e′
l−1 ⊕rl−1,
where ⊕is the concatenation operation. Noted that, for the
last entity eL, a null relation rL is padded to the end of path.
As such, the input vector contains not only the sequential
information, but also the semantic information of the entity
and its relation to the next entity. Consequently, hl−1 and
xl−1 are used to learn the hidden state of the next path-step
l, which is deﬁned via the following equations:
zl = tanh(Wzxl + Whhl−1 + bz)
fl = σ(Wfxl + Whhl−1 + bf)
il = σ(Wixl + Whhl−1 + bi)
ol = σ(Woxl + Whhl−1 + bo)
cl = fl ⊙cl−1 + il ⊙zl
hl = ol ⊙tanh(cl)
where cl ∈Rd′, z ∈Rd′ denote the cell (memory) state
vector and information transform module, respectively, and
d′ is the number of hidden units; il, ol, and fl separately represents the input, output, and forget gate. Wz, Wi, Wf, and
Wo ∈Rd′×3d, and Wh ∈Rd′×d′ are mapping coefﬁcient
matrices, while bz, bi, bf, and Wo are bias vectors. σ(·) is
the activation function set as sigmoid, and ⊙stands for the
element-wise product of two vectors. Taking advantages of
the memory state, the last state hL is capable of representing
the whole path pk.
Having established the representation of path pk, we aim
to predict the plausibility of τ = (u, interact, i). Towards
this end, two fully-connected layers are adopted to project
the ﬁnal state into the predictive score for output, given by:
s(τ|pk) = W⊤
where W1 and W2 are the coefﬁcient weights of the ﬁrst
and second layers respectively, bias vectors are omitted form
simplicity, and the rectiﬁer is adopted as the activation function.
Weighted Pooling Layer
A user-item entity pair usually has a set of paths connecting them in a KG. Let
S = {s1, s2, · · · , sK} be the predictive scores for K paths,
P(u, i) = {p1, p2, · · · , pK}, connecting a user-item pair
(u, i), where each element is calculated based on Equation (4). The ﬁnal prediction could be the average of the
scores of all paths, which is formulated as,
ˆyui = σ suggest that different paths have varying contributions
to model user preferences, while Equation (5) fails to specify importance of each path. Inspired by previous work , we design a weighted
pooling operation to aggregate scores of all paths. Here the
pooling function is deﬁned as follows,
g(s1, s2, · · · , sK) = log
and the ﬁnal prediction score is given by,
ˆyui = σ(g(s1, s2, · · · , sK)),
where γ is the hyper-parameter to control each exponential
weight. Such pooling is capable of distinguishing the path
importance, which is attributed by the gradient:
k′ exp(sk′/γ),
which is proportional to the score of each path during the
back-propagation step. Moreover, the pooling function endows the ﬁnal prediction more ﬂexibility. In particular, when
setting γ →0, the pooling function can degenerate to maxpooling; whereas, it can degrade to mean-pooling by setting
γ →∞. We conduct a case study on exploring the utility of
the weighted pooling operation in Section Case Studies.
Similar to the spirit in recent work , we treat the recommender learning task
as a binary classiﬁcation problem, where an observed useritem interaction is assigned a target value 1, otherwise 0.
We use the pointwise learning methods to learn the parameters of our model. In particular, the negative log-likelihood
is adopted as the objective function, which is deﬁned as follows,
log ˆyui +
log(1 −ˆyuj),
where O+ = {(u, i)|yui = 1} and O−= {(u, j)|yuj =
0} are the positive and negative user-item interaction pairs,
respectively. We conduct L2 regularization on the trainable
parameters Θ, which is omitted here for simplicity, to avoid
overﬁtting. We elaborate the implementation details in the
section of Experimental Settings.
Experiments
In this section, we perform experiments on two real-world
datasets to evaluate our proposed method. We aim to answer
the following research questions:
• RQ1: Compared with the state-of-the-art KG-enhanced
methods, how does our method perform?
• RQ2: How does the multi-step path modeling (e.g., the
incorporation of both entity and relation types) affect
• RQ3: Can our proposed method reason on paths to infer
user preferences towards items?
Dataset Description
We consider two scenarios: movie recommendation and music recommendation. For movie domain, we use the combination of MovieLens-1M and IMDb datasets, named MI,
which are linked by the titles and release dates of movies.
In particular, MovieLens-1M offers the user-item interaction data, while IMDb serves as the KG part that contains
auxiliary information on movies, such as genre, actor, director, and writer. For music domain, we use the benchmark dataset, KKBox, which is adopted from the WSDM
cup 2018 Challenge and is provided by the music streaming
service KKBox. Beyond the user-item interaction data, this
dataset contains the descriptions of music like singer, songwriter, and genre. The statistics of two datasets are summarized in Table 1.
Following previous efforts , we process the datasets as: if a user rates
a movie or has an interaction record with a song, we set the
Table 1: Statistics of our datasets.
Interaction
#Interactions
#Entity Types
#Relation Types
11,182,682
55,573,556
38,192,484
Avg Path Length
user-movie or user-song pair as the observed positive feedback with the target value of 1, and 0 otherwise.
For each dataset, we holdout the 80% and 20% interaction
history of each user randomly to construct the training and
test sets. For each positive user-item interaction pair in the
training set, we conducted the negative sampling strategy to
pair it with four negative items that the user has not interacted with. During the test stage, the ratio between positive
and negative interactions is set as 1 : 100, namely, 100 negative items are randomly sampled and pair with one positive
item in the testing set.
Path Extraction
In practice, it is labor intensive and infeasible to fully exploring all connected paths over the KG. Especially, the number of paths grows exponentially w.r.t. the length of path,
where millions of interlinks will be generated. As suggested
in prior efforts , truncating
all paths at a certain length and disregarding remote connections are sufﬁcient to model the connectivity between a
user-item pair. Moreover, as pointed out by ,
paths with length greater than six will introduce noisy entities. Therefore, we extract all qualiﬁed paths, each with
length up to six, that connect all user-item pairs.
Experimental Settings
Evaluation Metrics
We adopt two evaluation protocols
to evaluate the performance of top-K recommendation and
preference ranking, respectively, given by:
• hit@K considers whether the relevant items are retrieved
within the top K positions of the recommendation list.
• ndcg@K measures the relative orders among positive and
negative items within the top K of the ranking list.
We report the average metrics at K = {1, 2, · · · , 15} of all
instances in the test set.
We compare our proposed method with the following methods:
• MF : This is matrix factorization with
Bayesian personalized ranking (BPR) loss, which solely
utilizes user-item interaction.
• NFM : The method is a state-of-theart factorization model which treats historical items as
the features of users. Specially, we employed one hidden
layer as suggested in .
• CKE : Such embedding-based method
is tailored for KG-enhanced recommendation, which
integrates the representations from Matrix Factorization and TransR to
enhance the recommendation.
• FMG : This is a state-of-the-art metapath based method, which predeﬁnes various types of
meta-graphs and employs Matrix Factorization on each
meta-graph similarity matrix to make recommendation.
Parameter Settings
For fair comparison, we learn all
models from scratch without any pretrained parameters.
We optimize all models with Adaptive Moment Estimation (Adam) and apply a grid search to ﬁnd out the best
settings of hyperparameters. The learning rate is searched
in {0.001, 0.002, 0.01, 0.02}, while the coefﬁcient of L2
regularization is tuned amongst {10−5, 10−4, 10−3, 10−2}.
Other hypermeters of our proposed model are empirically
set as follows: the batch size is 256, the embedding size of
relation and entity type is 32, the embedding size of entity
value is 64, and the unit number of LSTM is 256. The dimensions of latent factors for MF, NFM, and CKE are empirically set to be 64. For FMG, we set the rank used to
factorize meta-graph similarity matrices to be 10, and the
factor size of the second-order weights as 10, as suggested
by . Moreover, the early stopping strategy
is performed, i.e., premature stopping if hit@15 on the test
data does not increase for ﬁve successive epochs.
Performance Comparison (RQ1)
Figure 3 reports our experimental results on two datasets
w.r.t. hit@K and ndcg@K. We have the following ﬁndings:
• FMG gives poor performance in both datasets. This indicates that meta-graph based methods, which rely heavily
on the predeﬁned meta-graph patterns, may introduce remote entities and fail to fully explore the user-item connectivity.
• NFM achieves better performance than MF. It makes
sense since by treating the rated items as the user features, NFM essentially enhances the second-order useritem proximity, while MF only considers the ﬁrst-order
user-item connections.
• Compared to CF-based methods (MF and NFM), the performance of CKE indicates that incorporating KG can
solve the data sparsity issue effectively. In particular, CKE
shows consistent improvement over KKBox dataset that is
extremely sparse, while only achieving comparable performance to NFM on MI dataset which has denser interaction data.
• KPRN substantially outperforms CKE w.r.t. hit@K and
ndcg@K, achieving the best performance. By leveraging paths to infer user preference, KPRN is capable of
exploring the user-item connectivity in an explicit way,
while the embedding-based method (CKE) only utilizes
KG to guide the representation learning of items. This
veriﬁes the importance of leveraging both entities and relations of KG. Further analyzing Figures 3b and 3d reveal
(a) hit@K on MI
(b) ndcg@K on MI
(c) hit@K on KKBox
(d) ndcg@K on KKBox
Figure 3: Top-K recommendation performance between all the methods on MI and KKBox datasets w.r.t. hit@K and ndcg@K.
Table 2: Performance comparison of KPRN and KPRN-r and their effects on relation modeling.
(a) hit@K on MI
(b) ndcg@K on MI
Figure 4: Performance comparison w.r.t. γ on the MI dataset.
that KPRN outperforms other baselines by a larger margin w.r.t. ndcg@K, demonstrating the strong capacity of
preference ranking.
Study of KPRN (RQ2)
To investigate the role of path modeling, we start by explore
the inﬂuence of relation in paths. We then study how the
weighted pooling operation affects the performance.
Effects of Relation Modeling
We consider one variant of
KPRN without the relation modeling, termed as KPRN-r.
In particular, the relation embedding rl−1 in Equation (2)
is discarded to generate the input vector xl−1. In Table 2,
we compare KPRN with KPRN-r in terms of hit@K and
ndcg@K, where K is selected from {5, 10, 15}. We have
the following observations:
• Without considering relations in paths, the performance of
KPRN-r decreases on both datasets. This justiﬁes our intuition that specifying different relations is of importance
to capture the path semantics, especially when the same
entities are involved.
• We ﬁnd that KPRN improves KPRN-r by 6.45% w.r.t.
hit@5 on MI, while only 0.70% on KKBox. One reason
may be that as MI is much denser than KKBox and it is
common that, in MI, multiple paths connect a user-item
pair with similar entities but different relations, whereas
fewer paths are offered in KKBox. This demonstrates that,
given strong connectivity between users and items, specifying relations of paths is of more importance to explore
the ﬁne-grained interests of users.
Effects of Weighted Pooling
To integrate the prediction
scores of multiple paths between a user-item pair, a weighted
pooling operation is carefully designed. To analyze its effect, we set the value γ as {0.01, 0.1, 1, 10} and report the
performance on MI in Figure 4. We ﬁnd that,
• When γ decrease from 1 to 0.1, the weighted pooling operation degrades the performance, since it is similar to
max-pooling and selects only the most important paths as
the user-item connectivity.
• The performance w.r.t. hit@K and ndcg@K becomes
poorer, when increasing γ from 1 to 10. It makes sense
since it tends to aggregate contributions from more paths,
rather than the most informative ones.
Case Studies (RQ3)
Another desirable property of KPRN is to reason on paths to
infer the user preferences towards target items and generate
reasonable explanations. This is because our model capture
the higher-level semantics from these key factors: entity, entity type, and relation. To demonstrate this, we show an example drawn from KPRN on movie recommendation task.
We randomly select a user, whose ID is u4825 in
MovieLens-1M, and select the movie Shakespeare in Love
from her interaction record. We then extract all the qualiﬁed
paths connecting the user-item pair and present the subgraph
in Figure 5. We have several observations.
• Collaborative ﬁltering effect plays a pivotal rule to recommend the movie Shakespeare in Love to the user, since
the interaction behaviors from other users (e.g., u940 and
u5448) are involved in two paths. In particular, the path
containing u5448 offers the high contribution score of
0.356 to infer the user’s interest.
Figure 5: Visualization of three paths with prediction scores
for the user of u4825 in MI dataset. The prediction scores
are normalized for illustration.
• The target item is connected to what u4825 has watched
before (e.g., Rush Hour, Titanic, and Fantasia) by the
shared knowledge entities, such as actor (Tom Wilkinson)
and director (James Algar). This shows that KPRN is capable of extending user interests along KG paths.
• Analyzing these three paths jointly, we ﬁnd that different paths describe the user-item connectivity from dissimilar angles, which can be treated as the evidence why the
item is suitable for the user. Specially, we can offer pathwise explanations such as Shakespeare in Love is recommended since you have watched Rush Hour acted by the
same actor Tom Wilkinson or since it is similar to Titanic
that you watched before. This case demonstrates KPRN’s
capacity of providing informative explanations.
Related Work
Previous solutions on integrating KG into recommendation
can be roughly categorized into embedding-based and pathbased methods.
Embedding-based Methods
Prior efforts leverage
knowledge graph embedding techniques to guide the representation learning of items. For example, for each item,
Zhang et al. generated the representation by combining its latent factor from MF and its semantic embedding from TransR. When performing news recommendation,
Wang et al. generated the news representation by
integrating the knowledge-aware embeddings and word embedding of each word entity within the news content. More
recently, Huang et al. adopted TransE to generate representations for entities and items, and
employed memory networks to update the user representations based on her preferences on speciﬁc entities. By exploiting the KG to guide the representation learning, such
methods achieve signiﬁcant improvement in performance.
However, we argue that KGE regularization has not fully
explored the connectivity between users and items. One reason is that the characterization of user-item connectivity is
achieved in a rather implicit way. Moreover, they lack the
reasoning ability to infer why a item is recommended for a
Path-based Methods
In the literature of path-based methods, some prior studies
introduce the connectivity patterns, termed as meta-paths,
to explicitly guide the recommender leaning . Meta-path is de-
ﬁned as a sequence of entity type, such as user-movie-directmovie, to capture the user-item afﬁnities carried in KG. For
instance, Yu et al. conducted MF framework over
meta-path similarity matrices to perform recommendation.
Such methods, however, use the user-item connectivity to
update user-item similarity, but not reason on paths. Moreover, the performance rely heavily on the quality of metapaths, which requires domain knowledge.
Several researchers exploit programming models to infer
a user preference along paths . Nevertheless, these
methods fail to learn representations of users and items, thus
hardly generalize to unseen interactions. To solve the issues,
recent studies learn the representation for each path . Hu et al. 
employed CNN over the embeddings of entities to get a
single representation for a path, while recurrent networks
are adopted in . As such, these methods
can combine the strengths of embedding-based and pathbased approaches, achieving better performance. However,
the work ignores the sequential dependencies of entities and relations within a path; moreover, only
entity embeddings are involved in the path modeling . Such limitations may hurt the reasoning ability of
models. Towards this end, we propose a model to consider
the sequential dependencies, as well as relation semantics,
to reason a user-item interaction.
Conclusions
In this work, we exploit knowledge graph to construct paths
as extra user-item connectivity, which is complementary to
user-item interactions. We propose a knowledge-aware path
recurrent network to generate representation for each path
by composing semantics of entities and relations. By adopting LSTM on paths, we can capture the sequential dependencies of elements and reason on paths to infer user preference. Extensive experiments are performed to show the effectiveness and explainability of our model.
In future, we will extend our work in two directions. First,
we attempt to mimic the propagation process of user preferences within KGs via Graph Neural Networks, since extracting qualiﬁed paths is labor-intensive. Second, as KG links
multiple domains (e.g., movie and book) together with overlapped entities, we plan to adopt zero-shot learning to solve
the cold start issues in the target domain.
Acknowledgement This work is supported by NExT, by the
National Research Foundation Singapore under its AI Singapore Programme, Linksure Network Holding Pte Ltd and the
Asia Big Data Association . Assistance provided by eBay, Search Science Shanghai Director Hua Yang, Manager Xiaoyuan Wu, and intern
Mohan Zhang was greatly appreciated.