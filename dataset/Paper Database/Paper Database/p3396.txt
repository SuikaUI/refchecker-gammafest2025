Latent Semantic Models
for Collaborative Filtering
THOMAS HOFMANN
Brown University
Collaborative Ô¨Åltering aims at learning predictive models of user preferences, interests or behavior
from community data, that is, a database of available user preferences. In this article, we describe a
new family of model-based algorithms designed for this task. These algorithms rely on a statistical
modelling technique that introduces latent class variables in a mixture model setting to discover
user communities and prototypical interest proÔ¨Åles. We investigate several variations to deal with
discrete and continuous response variables as well as with different objective functions. The main
advantages of this technique over standard memory-based methods are higher accuracy, constant
time prediction, and an explicit and compact model representation. The latter can also be used to
mine for user communitites. The experimental evaluation shows that substantial improvements
in accucracy over existing methods and published results can be obtained.
Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information
Search and Retrieval‚Äîinformation Ô¨Åltering; I.5.3 [Pattern Recognition]: Clustering‚Äîalgorithms
General Terms: Collaborative Ô¨Åltering, recommender systems, machine learning, mixture models,
latent semantic analysis
1. INTRODUCTION
Content-based Ô¨Åltering and retrieval builds on the fundamental assumption
that users are able to formulate queries that express their interests or information needs in term of intrinsic features of the items sought. In some cases,
however, it may be difÔ¨Åcult to identify suitable descriptors such as keywords,
topics, genres, etc. that can be used to accurately describe interests. Yet in other
cases, for example, in electronic commerce, users may be unaware or at least
inattentive of their interest. In both cases, one would like to predict user preferences and recommend items without requiring the user to explicitly formulate
Collaborative Ô¨Åltering is a technology that is complementray to contentbased Ô¨Åltering and that aims at learning predictive models of user preferences,
This work was sponsored by NSF-ITR grants, award numbers IIS-0085836 and IIS-0085940.
Author‚Äôs address: Department of Computer Science, Box 1910, Brown University, Providence, RI
Permission to make digital or hard copies of part or all of this work for personal or classroom use is
granted without fee provided that copies are not made or distributed for proÔ¨Åt or direct commercial
advantage and that copies show this notice on the Ô¨Årst page or initial screen of a display along
with the full citation. Copyrights for components of this work owned by others than ACM must be
honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers,
to redistribute to lists, or to use any component of this work in other works requires prior speciÔ¨Åc
permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 1515
Broadway, New York, NY 10036 USA, fax: +1 (212) 869-0481, or .
‚Éù2004 ACM 1046-8188/04/0100-0089 $5.00
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004, Pages 89‚Äì115.
Thomas Hofmann
interests or behavior from community data, that is, a database of available user
preferences. Ideally, additional user input or interaction beyond the proÔ¨Åle generated from previous interactions and observations is not necessary. Up to now,
the dominant paradigm for performing collaborative Ô¨Åltering in recommender
systems has been based on nearest neighbor regression or memory-based techniques. Virtually all Ô¨Årst generation recommender systems have used the same
fundamental two-step approach of Ô¨Årst identifying users that are similar to
some active user for which a recommendation has to be made, and then computing predictions and recommendations based on the preferences and judgments
of these similar or like-minded users. The latter includes [Goldberg et al. 1992],
the GroupLens (and MovieLens) project [Resnik et al. 1994; Konstan et al.
1997], Ringo [Shardanand and Maes 1995] as well as a number of commercial
systems, most notably the systems deployed at Amazon.com and CDNow.com.
Memory-based methods have reached this level of popularity, because they
are simple and intuitive on a conceptual level while avoiding the complications of a potentially expensive model-building stage. At the same time, they
are deemed sufÔ¨Åcient for many real-world problems. Yet there are a number of
shortcomings, four of which we would like to point out here: (i) The accuracy
obtained by memory-based methods may be suboptimal. Since recommendation
accuracy is perhaps the most crucial factor from a user‚Äôs perspective, improving accuracy is very important for most recommendation systems. (ii) Since no
explicit statistical model is constructed, nothing is actually learned form the
available user proÔ¨Åles and no general insight is gained. Hence, memory-based
methods are only of limited use as data mining tools. (iii) Memory-based methods do not scale well in terms of their resource requirements (memory and
computer time), unless further approximations‚Äîlike subsampling‚Äîare made.
(iv) It is difÔ¨Åcult to systematically tailor memory-based algorithms to maximize
the objective associated with a specÔ¨Åc task.
This article deals with a model-based approach that addresses the above
shortcomings and (i) achieves higher prediction accuracies, (ii) compresses the
data into a compact statistical model that automatically identiÔ¨Åes user communities, (iii) enables to compute preference predictions in constant time, and
(iv) gives the system designer more Ô¨Çexibility in speciÔ¨Ång the objectives of the
application.
Model-based techniques have been investigated before, most notably
Bayesian and non-Bayesian clustering techniques [Breese et al. 1998; Ungar
and Foster 1998; Basu et al. 1998; Chien and George 1999], Bayesian networks
[Breese et al. 1998], and dependency networks [Heckerman et al. 2000]. The
approach proposed in this paper is a generalization of a statistical technique
called probabilistic Latent Semantic Analysis (pLSA) [Hofmann 2001a] which
was originally developped in the context of information retrieval [Hofmann
1999]. It bears some similarity with clustering methods such as distributional
clustering [Pereira et al. 1993] in that latent variables for user communities are
introduced, yet the communities can be overlapping and users are not partitioned into groups, not even probabilistically (cf. Hofmann and Puzicha ).
In fact, the probabilistic latent semantic models are in many ways closer related
to dimension reduction methods and matrix decomposition techniques such as
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Latent Semantic Models for Collaborative Filtering
Singular Value Decomposition (SVD) and Principal Component Analysis (PCA),
which have been applied in information retrieval [Deerwester et al. 1990] as
well as in the context of recommender systems [Sarwar et al. 2000; Goldberg
et al. 2001; Canny 2002].
The main difference between our work and Bayesian or dependency networks
is the fact that the latter learn a dependency structure directly on the observables, while our approach is based on a latent cause model that introduces the
notion of user communities or groups of items. The main difference compared to
PCA and SVD-based dimension reduction methods is that pLSA offers a probabilistic semantics and can build on statistical techniques for inference and
model selection. However, our approach shares with all of the above techniques
the assumption that predictions are computed in a ‚Äúuser-centric‚Äù view, whereas
some more recent work has investigated item-based recommendation methods
[Sarwar et al. 2001].
2. MODEL-BASED COLLABORATIVE FILTERING
2.1 Implicit and Explicit Ratings
The domains we consider consist of a set of persons or users U = {u1, . . . , un},
a set of items Y = { y1, . . . , ym} and a set of possible ratings V. We assume
observations are available for person/object pairs (u, y), where u ‚ààU and y ‚ààY.
In the most basic case, an observation will just be the co-occurrence of u and y,
representing events like ‚Äúperson u buys product y‚Äù or ‚Äúperson u clicks on link
y‚Äù, which is also sometimes called implicit preference data. Other cases may
also provide an explicit rating v ‚ààV as part of an observation. In the simplest
case, this will be a binary response variable v ‚àà{‚àí1, 1}, modeling events like
‚Äúperson x likes/dislikes object y‚Äù. In general, V may be discrete or continuous,
equipped with an ordinal or numerical (absolute) scale. For example, a Ô¨Åve- or
six-star rating scale as commonly used in movie recommendation systems such
as MovieLens or EachMovie.
Rating data can be concisely summarized in table format as a n by m matrix
A, where each row will correspond to a user and each column to an item. In the
case of implicit ratings, each entry aij represents a count variable of how often
user ui has selected item item yj or, more generally, how many pairs (ui, yj)
have been observed. In the case of explicit ratings, each entry aij ‚ààV ‚à™{‚àÖ} will
either correspond to a rating, aij ‚ààV or will be unobserved, aij = ‚àÖ. Notice that
the data matrix A will typically be sparse in the sense that only a small fraction
of pairs (u, y) are actually ever observed. Hence, the vast majority of entries aij
will be 0 (implicit ratings) or ‚àÖ(explicit ratings).
2.2 Prediction Problems
We will consider two type of prediction problems. The Ô¨Årst setting that we
call forced prediction involves predicting a preference value for a particular
item given the identity of the user, that is, one would like to learn a mapping g : U √ó Y ‚ÜíV. More generally, one may be interested in the conditional probability P(v|u, y) that user u will rate item y with v. Based on the
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Thomas Hofmann
conditional probability one may also deÔ¨Åne a deterministic prediction function
by g(u, y) = arg maxv P(v|u, y). If v possesses a numerical scale, then it is more
appropriate to deÔ¨Åne g via the expected rating, g(u, y) = 
v‚ààV vP(v|u, y) or
V v P(v|u, y) dv.1 We call this setting forced prediction, because it
mimics an experimental setup in which a user response is solicited for a particular item and the user has no choice on which item to vote. This is the relevant
prediction mode in scenarios in which an item is presented to a user as a recommendation and one is interested in anticipating the user‚Äôs response.
In the second setting, which we call free prediction, the item selection process is part of the predictive model and the goal is to learn probabilities
P(v, y|u) in order to predict both, the selected item y and (optionally) the
associated rating v. By virtue of the chain rule, this can be rewritten as
P(v, y|u) = P(v| y, u)P( y|u), thus decomposing the problem into the prediction of the selected item (irrespective of the rating) and a prediction of the
rating conditioned on the (hypothetically) selected item. This mimics a scenario in which the user is free to select an item of her or his choice and‚Äîin the
case of explicit ratings‚Äîalso provides a rating for it. The free prediction case
is a generalization of what is commonly referred to as the ‚Äúrecommend‚Äù task.
i.e. selecting a set of items to present to the user.
In the forced prediction case, the user is presented with a particular item
and provides a rating for it. Here the selection of the item on which a user
vote or response is solicitated is part of the experimental design. In the free
prediction case, the user is in control of the item selection and one is interested
in prediciting both, what a user will select and (optionally) how s/he will rate
2.3 Loss and Risk Functions
Since we are pursuing a model-based approach to collaborative Ô¨Åltering, we
will assume the availability of an adequate loss function. A loss function L is a
function that quantiÔ¨Åes how good or bad the predicition of a model is compared
to a true outcome. We will denote the (parameterized) model space by H and use
a generic parameter Œ∏ to refer to a particular model in H. Then, a loss function
can be formally deÔ¨Åned as a function L : X √óH ‚Üí‚Ñúwhere X = U √óV √óY. Here
V is treated as void in the case of implicit ratings. Hence, for a given observation (u, v, y), a loss function L will assign a score to every hypothesis Œ∏ under
consideration. The smaller L((u, v, y), Œ∏), the more compatible Œ∏ is believed to
be with the observation.
In statistical inference, one often uses the (log-)likelihood as a criterion corresponding to a (negative) logarithmic loss
lg1((u, v, y), Œ∏) = ‚àílog P(v|u, y; Œ∏), or L
lg2((u, v, y), Œ∏) = ‚àílog P(v, y|u; Œ∏). (1)
The Ô¨Årst loss function in Eq. (1) is appropriate for the forced prediction scenario,
since it conditions on the selected item y, while the second one corresponds to
the free prediction mode in which y is part of the prediction.
1For notational convenience, P(v|u, y) denotes a probability mass function (discrete case) or a
conditional probability density function (continuous case) dependent on the context.
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Latent Semantic Models for Collaborative Filtering
Another popular choice for the case of discrete response variables and for
models that make deterministic predictions is the zero-one loss,
zo((u, v, y), Œ∏) = 1 ‚àí[[v = g(u, y; Œ∏)]],
where [[¬∑]] denotes the indicator function of the enclosed predicate. If the prediction is correct, no loss is incurred, otherwise the loss is one. This loss function is
also commonly used in supervised classiÔ¨Åcation or pattern recognition. It can
be generalized to the case of probabilistic models where one may deÔ¨Åne a loss
via the probability of making an incorrect prediction, that is, the probability of
pe((u, v, y), Œ∏) =
P(v‚Ä≤|u, y; Œ∏) = 1 ‚àíP(v|u, y; Œ∏)
The logarithmic loss provides an upper bound on the probability of error, since
pe((u, y, v), Œ∏) = 1 ‚àíP(v|u, y; Œ∏) ‚â§1 ‚àílog P(v|u, y; Œ∏)
lg1((u, y, v), Œ∏).
The zero‚Äìone loss is sometimes difÔ¨Åcult to optimize directly, because it is a
non-differentiable function of Œ∏, in which case the use of the logarithmic loss
can be advantageous for computational reasons. In fact, in this article, we focus exclusively on the use of logarithmic loss functions, which can be optimized
(in approximation) with the well-known Expectation‚ÄìMaximization (EM) algorithm for the proposed latent class models.
For numeric response variables, it is more common to use a metric-based loss
function, for example, the absolute loss
abs((u, v, y), Œ∏) = |v ‚àíg(u, y; Œ∏)|
or the squared loss
sqr((u, v, y), Œ∏) = (v ‚àíg(u, y; Œ∏))2 .
These loss functions have been used extensively for evaluating the accuracy
of collaborative Ô¨Åltering methods, in particular memory-based methods, and
we will also use them in our experiments. For completeness, we would like to
mention the RankBoost method [Freund et al. 1998] which aims at minimizing
an upper bound on the ranking loss. The latter uses a purely ordinal scale for
the ratings and can be deÔ¨Åned via the number of misordered item pairs.
A loss function scores models based on a single observation; however, we need
to specify how to combine data consisting of several observations. Put differently, we need a sampling model to specify under which distribution P(u, v, y)
we would like to minimize the loss. This is usually called a risk function or
functional, R(Œ∏) ‚â°
u,v, y P(u, v, y)L((u, v, y); Œ∏), where part of the sum has to
be replaced by an integral in the case of continuous response variables v. A
typical choice is to minimize the empirical loss, that is,
emp(Œ∏) = 1
L((u, v, y), Œ∏),
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Thomas Hofmann
where angular brackets under a summation symbol are used as a shorthand
notation to refer to all observation triplets and N denotes the total number
of observed triplets. However, in collaborative Ô¨Åltering, it is a conceivable alternative to give the same weight to every user, irrespective of the number of
implicit or explicit ratings available for that user. If we denote by nu the number
of observation triplets for user u, then this would correspond to the normalized
empirical risk function
emp(Œ∏) = 1
‚ü®u‚Ä≤,v, y‚ü©:u‚Ä≤=u
L((u, v, y), Œ∏).
The choice of a normalized vs. nonnormalized risk function depends on the
application. If we assume that users for which more data is available are more
important, in the sense that it is more likely that we will have to make predictions for them again, then the unnormalized risk function in Eq. (7) may
be more appropriate. Notice also that ÀúRemp may put a lot of weight on individual
observations, just because the data for some users may be sparse. Hence, we
expect the normalized risk function to be more susceptible to overÔ¨Åtting, which
has turned out to be disadvantageous in our experiments (cf. Section 5).
3. CO-OCCURRENCE LATENT SEMANTIC MODEL
3.1 Model DeÔ¨Ånition
We would like to discuss a simple model for co-occurrence data Ô¨Årst, which
is known as probabilistic latent semantic analysis (pLSA) [Hofmann 2001a;
Hofmann 1999]. This can be thought of as a special case of collaborative Ô¨Åltering with implicit preference data [Hofmann and Puzicha 1999]. The data thus
consists of a set of user-item pairs (u, y) which are assumed to be generated
independently. The key idea of our approach is to introduce hidden variables Z
with states z for every user-item pair, so that user u and item y are rendered
conditionally independent. The possible set of states z is assumed to be Ô¨Ånite
and of size k. The resulting model is a mixture model that can be written in the
following way
P(u, y; Œ∏) =
P(u, y, z) =
P( y|z)P(z|u)P(u),
where sums over z run over all possible k states. By applying Bayes‚Äô rule,
one can alternatively use the equivalent parameterizations P(u, y; Œ∏‚Ä≤)
z P(z)P(u|z)P( y|z) and P(u, y; Œ∏‚Ä≤‚Ä≤) = 
z P(u|z)P(z| y)P( y). Since the more
typical situation in collaborative Ô¨Åltering is to make personalized, that is, userspeciÔ¨Åc recommendations, we will mainly work with the conditional model
P( y|u; Œ∏) =
P( y|z)P(z|u).
In this model, the parameter vector Œ∏ summarizes the probabilities P(z|u)
which can be described by (k ‚àí1)√ón independent parameters as well as P( y|z)
which requires (m‚àí1)√ók independent parameters, where again k denotes the
number of possible states of the hidden variable.
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Latent Semantic Models for Collaborative Filtering
Notice that if k = 1, then the model simply assumes that the selection of an
item y does not depend on the identity of the user, P( y|u) = P( y), resulting
in non-personalized predictions. The user identity and the item identity are
assumed to be marginally independent in this case. As the number of hidden
states increases, the set of representable joint distribution over user‚Äìitem pairs
becomes less and less constrained until a fully saturated model is obtained,
which can represent any probability mass function over user‚Äìitem pairs. In
practice, k has to be chosen in a way that adjusts model complexity in the
light of the amount and sparseness of available data. Standard model selection
techniques like cross-validation are available to that extend.
While we have not associated any a priori meaning with the states of the
hidden variables, the hope though is to recover interesting structure in the data
about user communities and groups of related items. Intuitively, the state z of a
hidden variable Z associated with an observation (u, y) is supposed to model a
hidden cause, that is, the fact that a person u selects item y ‚Äúbecause of‚Äù z. Each
z is intended to offer a hypothetical explanation for an implicit rating that is
itself not directly observable. Since the number of possible states k is typically
much smaller than the number of items and users, the model encourages to
group users into user communities and items into groups of related items.
3.2 Expectation Maximization Algorithm
Following the maximum likelihood approach to statistical inference, we propose
to Ô¨Åt the model parameters Œ∏ by maximizing the (conditional) log-likelihood, or
equivalently, by minimizing the empirical logarithmic loss
log P( y|u; Œ∏) = ‚àí1
aij log P( yj|ui; Œ∏)
where aij counts the number of times each pair (ui, yj) has been observed. Notice
that for user‚Äìitems pairs that have never been observed one gets aij = 0 and
hence the number of terms in the double sum in Eq. (11) depends on the number
of nonzero entries in the data matrix A which is upper bounded by N and which
can be far less than n √ó m.
The Expectation Maximization (EM) algorithm [Dempster et al. 1977] is a
standard method for statistical inference that can be used to (approximately)
maximize the log-likelihood in mixture models like pLSA [Hofmann 2001a].
The Ô¨Årst step in deriving an EM algorithm is to specify a complete data model.
A complete data model treats the hidden variables as if they were actually observed, which in our case amounts to the assumption that for every observed
pair (u, y), we would in fact observe a triplet (u, y, z). The complete data model
corresponding to Eq. (10) is given by P( y, z|u) = P( y|z)P(z|u) and the corresponding (negative) log-likelihood function can be written as
Rc(Œ∏) = ‚àí1
log P( y|z) + log P(z|u)
Since the states of the latent variables are not known, we introduce a so-called
variational probability distribution Q(z; u, y) [Neal and Hinton 1998] for every
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Thomas Hofmann
observed user item pair. Intuitively, the Q distribution will model our best
knowledge about the states of the latent variables given the current parameters.
If we identify the latter with user communities, then Q(z; u, y) will denote the
probability that the co-occurrence of (u, y), that is, the selection of item y by
user u, will be attributed to the fact that u is a member of community z.
Using Q one can deÔ¨Åne a family of risk functions (one risk function for every
choice of Q)
¬ØR(Œ∏, Q) = ‚àí1
Q(z; u, y)
log P( y|z) + log P(z|u)
Exploiting the concavity of the logarithm and using Jensen‚Äôs inequality
(cf. Cover and Thomas ), it can be shown that every ¬ØR(¬∑, Q) deÔ¨Ånes an
upper bound on R(¬∑) (up to a constant that only depends on Q),
Q(z; u, y) P( y|z)P(z|u)
Q(z; u, y)
Q(z; u, y) log P( y|z)P(z|u)
Q(z; u, y)
= ¬ØR(Œ∏, Q) ‚àí1
H(Q(¬∑; u, y)) ,
where H(Q) refers to the entropy of a probability distribution Q.
The EM algorithm now consists of two steps that are performed in alternation: (i) computing the tightest bound for given parameters ÀÜŒ∏ and (ii) optimizing
this bound with respect to Œ∏. The Ô¨Årst step consists of minimizing Eq. (14c) with
respect to the variational distribution Q. This is called the E-step and amounts
to computing the posterior probabilities of the hidden variables. Thus, for given
parameters ÀÜŒ∏, the optimal Q‚Äîdenoted by Q‚àó‚Äîis given by
Q‚àó(z; u, y; ÀÜŒ∏) = P(z|u, y; ÀÜŒ∏) =
ÀÜP( y|z) ÀÜP(z|u)
z‚Ä≤ ÀÜP( y|z‚Ä≤) ÀÜP(z‚Ä≤|u) .
A formal derivation using the technique of Lagrange multipliers is included in
the appendix. The hat on probabilities in Eq. (15) denotes quantities parameterized by ÀÜŒ∏. Obviously, the posterior probabilities need only to be computed
for user‚Äìitem pairs (u, y) that have actually been observed. Averaging Rc with
respect to the posterior distribution calculated from Eq. (15) then yields the
following upper bound on the negative log-likelihood function
¬ØR(Œ∏, ÀÜŒ∏) ‚â°
¬ØR(Œ∏, Q‚àó) = ‚àí1
Q‚àó(z; u, y, ÀÜŒ∏)
log P( y|z) + log P(z|u)
ÀÜP( y|z) ÀÜP(z|u)
z‚Ä≤ ÀÜP( y|z‚Ä≤) ÀÜP(z‚Ä≤|u)
log P( y|z) + log P(z|u)
which needs to be optimized with respect to the parameters Œ∏ in the Maximization (M) step of EM. The M-step requires to solve a constrained optimization
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Latent Semantic Models for Collaborative Filtering
problem (cf. appendix for details) leading to the set of equations
‚ü®u, y‚Ä≤‚ü©: y‚Ä≤= y Q‚àó(z; u, y, ÀÜŒ∏)
‚ü®u, y‚ü©Q‚àó(z; u, y, ÀÜŒ∏)
‚ü®u‚Ä≤, y‚ü©:u‚Ä≤=u Q‚àó(z; u, y, ÀÜŒ∏)
‚ü®u‚Ä≤, y‚ü©:u‚Ä≤=u Q‚àó(z‚Ä≤; u, y, ÀÜŒ∏) =
‚ü®u‚Ä≤, y‚ü©:u‚Ä≤=u Q‚àó(z; u, y, ÀÜŒ∏)
|{‚ü®u‚Ä≤, y‚ü©: u‚Ä≤ = u}|
The complete EM algorithm now proceeds by alternating the E-step in Eq. (15)
with the M-step in Eq. (17).
3.3 Regularized Risk Functions
Learning statistical models with many parameters from a limited amount of
data bears the risk of overÔ¨Åtting. Traditional model selection techniques would
Ô¨Åt models by maximum likelihood and then determine the generalization performance of the model either analytically (typically in an asymptotic approximation) or via empirical evaluation using hold-out data or cross-validation.
As an alternative approach we have proposed a technique called tempered EM
[Hofmann 2001a] which minimizes a regularized risk function instead of the
empirical risk (i.e. the negative log-likelihood in the case of maximum likelihood
estimation). Formally, a Œ≤-parameterized family of regularized risk functions
can be obtained by generalizing the upper bound in Eq. (14c)
ÀúRŒ≤(Œ∏, Q) ‚â°¬ØR(Œ∏, Q) ‚àí1
H(Q(¬∑; u, y))
Notice that for Œ≤ = 1 this reduces to maximum likelihood estimation via EM.
For Œ≤ < 1 more weight is put on the entropy of Q which avoids ‚Äúover-conÔ¨Ådence‚Äù
in computing the posterior probabilities as can be seen from the solution of the
generalized E-step (cf. appendix)
Q‚àó(z; u, y, ÀÜŒ∏) ‚àù
 ÀÜP(z|u) ÀÜP( y|z)
As a result, the optimal Q-distributions will be more smeared-out or fuzzy
which counteracts overÔ¨Åtting as we will demonstrate in the experiments. Similar ‚Äútricks‚Äù have been used in speech recognition and other applications involving high-dimensional statistical models, in particular to compensate for
simplifying assumptions about statistical independence. Notice that one of the
advantages of tempered EM is the fact that the M-step is unaffected by the
choice of Œ≤, hence one only has to modify the E-step.
A more rigorous framework is offered by the framework of Bayesian learning.
As has been proposed in Blei et al. one can put Dirichlet priors on the
multinomial distributions P(z|u) and integrate them out, resulting in a model
that has been called latent Dirichlet allocation (LDA) model. However, inference
is signiÔ¨Åcantly harder in this setting and further approximation are necessary
to derive a tractable algorithm [Blei et al. 2002; Minka and Lafferty 2002].
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Thomas Hofmann
3.4 Mixture Models, Clustering, and Dimension Reduction
It is important not to confuse the pLSA model with probabilistic or Bayesian
clustering models [Breese et al. 1998; Chien and George 1999] in which it is
assumed that each user belongs to exactly one user group. In a standard user
clustering model, one introduces a single latent cluster membership variable
for every user u, while the pLSA model associates a latent variable with every observation triplet (u, v, y). Hence, different ratings of the same user can
be explained by different latent causes in pLSA, whereas a user clustering
model assumes that all ratings involving the same user are linked to the same
underlying community. This can be stated more formally by computing and
comparing the probability of a set of observations involving a particular user.
The clustering model yields the following probability for the ratings of a Ô¨Åxed
P((v1, y1), . . . , (vl, yl)) =
P(vi, yi|z) .
In contrast, in the pLSA model each user is characterized by a distribution
P(z|u) and one gets a user-speciÔ¨Åc expression
Pu((v1, y1), . . . , (vl, yl)) =
P(z|u)P(vi, yi|z) .
By integrating out the mixture proportions P(z|u) in a Bayesian manner, one
can also deÔ¨Åne a generative model that does not have any reference to a speciÔ¨Åc
P((v1, y1), . . . , (vl, yl)) =
Œ∏z P(vi, yi|z)
Here, Œ∏z with Œ∏z ‚â•0 and 
z Œ∏z = 1 takes the role of a latent parameter, which
is averaged over using a prior probability density function p(Œ∏). If the latter
is chosen to be a Dirichlet distribution, one gets the LDA model of Blei et al.
 . In this article, we have focused on maximum likelihood estimation of
P(z|u), because statistical inference turns out to be signiÔ¨Åcantly easier than in
the fully Bayesian model.
4. LATENT SEMANTIC MODELS WITH RATINGS
4.1 Model DeÔ¨Ånition and Dependency Structures
Since many applications of collaborative Ô¨Åltering involve explicit user ratings,
the pLSA model needs to be extended appropriately. We will focus Ô¨Årst on the
case, where ratings are predicted for Ô¨Åxed items (forced prediction). There are
two different ways to augment the pLSA model with an additional random
variable v for explicit ratings, as shown in Figures 1(e) and 1(f). The predicted
rating will depend on the latent variable z and it will either depend directly on
the item (variant (e)) or the user (variant (f)). The augmented pLSA model is
hence no longer symmetric in the sense that both types of entities, users and
items, are treated differently. We call the Ô¨Årst variant the community version,
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Latent Semantic Models for Collaborative Filtering
Graphical model representation of possible extensions of the pLSA model to include a rating
variable v. (a) Depicts the co-occurrence pLSA model. In (b), the rating only depends on the latent
variable. (c) and (d) correspond to the free prediction mode with users and items interchanging
their roles. (e) and (f) are derived from (c) and (d), respectively, by removing one arc, which is the
manipulation corresponding to forced prediction.
since the user only inÔ¨Çuences the prediction mediated by z, but not directly.
Correspondingly, the second variant will be called the categorized version, since
items only impact the prediction through z which is supposed to model item
categories or types. Similarly, two models can be derived for the free prediction
mode. They are depicted in Figures 1(c) and 1(d). The model in Figure 1(b) is
too restrictive to be useful for collaborative Ô¨Åltering.
4.2 Class Conditional Distributions
The proposed model has two ingredients, mixture coefÔ¨Åcients‚Äîwhich in the
community variant correspond to probabilities P(z|u)‚Äîand class-conditional
probability distributions P(v| y, z). While the variables u and y are naturally
assumed to be categorical, one of the key questions is how to take possible
scales of the response variable v into account and how to parameterize the
class-conditional distributions. In what follows, we will for concreteness focus
on the community model, but the same argumentation applies to the categorized
model variant.
If v is itself a categorical variable, for example, only taking binary values,
v ‚àà{‚àí1, 1}, then one can simply introduce success probability parameters
œÄ y,z ‚àà[0; 1] and deÔ¨Åne P(v| y, z) ‚â°œÄ y,z. More generally, one can parameterize the conditional probability for categorical variables in the following manner
 
P(v| y, z) = œÄv
In working with numerical (absolute) scales, we propose to introduce a location parameter ¬µ y,z ‚àà‚Ñúand a scale parameter œÉ y,z ‚àà‚Ñú+ for every community
z and every item y which deÔ¨Ånes a Gaussian mixture model with user-speciÔ¨Åc
mixing weights
P(v|u, y) =
P(z|u) P(v; ¬µ y,z, œÉ y,z),
P(v; ¬µ, œÉ) =
The assumption is that within each community the rating for each item possesses a typical value ¬µ y,z, but that the observed ratings for individual users
are noisy versions corrupted by normally distributed noise with variance œÉ 2
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Thomas Hofmann
Finally, notice that the expected response can be computed as
E[v|u, y] =
v P(v|u, y) dv =
v P(v| y, z) dv
P(z|u)¬µ y,z .
It may be helpful to point out that Eq. (24) reduces to a standard Gaussian
mixture model, in the degenerate case of a single user. In general, mixture proportions are user-speciÔ¨Åc though and the Gaussian pLSA model is very different
from a standard Gaussian mixture model.
4.3 User Normalization
The models presented so far assume that all users express their ratings on a
common scale. However, it is known that different users may associate subjectively different meanings with ratings and, for instance, a Ô¨Åve-star rating
may mean different things for different people. In memory-based methods, this
is taken into account by similarity measures such as the Pearson or Spearman correlation coefÔ¨Åcient [Herlocker et al. 1999]. One way to accommodate
this in model-based approaches with numerical ratings is to normalize the raw
user ratings appropriately. To that extend, we propose to transform ratings
by (i) subtracting the user-speciÔ¨Åc mean rating ¬µu and by (ii) normalizing the
variance of ratings for each user to one. The Ô¨Årst step accounts for individual
differences in the overall ‚Äúenthusiasm‚Äù of users and calibrates what should be
considered as the neutral vote for every user. The second step makes the ratings
more comparable across users by adjusting their dynamic range.
Formally, this is accomplished by performing the user-speciÔ¨Åc transformation of ratings
(u, v, y) ‚Üí(u, v‚Ä≤, y),
v‚Ä≤ = v ‚àí¬µu
¬µu = E[v|u],
(v ‚àí¬µu)2|u
For users with a small number of ratings, one has to be careful to perform
appropriate smoothing in estimating the standard deviations (and to a lesser
extend the means), since the empirical estimates derived from sample averages
may be very unreliable due to sampling noise. We have thus used the following
scheme to smooth the estimates of the variances,
‚ü®u,v, y‚ü©(v ‚àí¬µu)2 + q ¬ØœÉ 2
where ¬ØœÉ 2 denotes the overall variance of ratings, nu is the number of ratings
available for user u and q is a free parameter controlling the smoothing strength
(set to q = 5 in our experiments).
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Latent Semantic Models for Collaborative Filtering
4.4 Maximum Likelihood Estimation: Discrete Case
Let us Ô¨Årst discuss model Ô¨Åtting in the simplest case of the community or categorized models with a categorical response variable. Performing (approximate)
maximum likelihood estimation can again be performed via the EM algorithm
along exactly the same lines as outlined in Section 3. The only difference is
that P( y|z) is replaced by P(v| y, z)P( y|z) (free prediction) or P(v| y, z) (forced
prediction), respectively. One thus arrives at the following E-step for the forced
prediction case
Q‚àó(z; u, v, y, ÀÜŒ∏) =
ÀÜP(z|u) ÀÜP(v| y, z)
z‚Ä≤ ÀÜP(z‚Ä≤|u) ÀÜP(v| y, z‚Ä≤)
and similarly for the free prediction case
Q‚àó(z; u, v, y, ÀÜŒ∏) =
ÀÜP(z|u) ÀÜP(v| y, z) ÀÜP( y|z)
z‚Ä≤ ÀÜP(z‚Ä≤|u) ÀÜP(v| y, z‚Ä≤) ÀÜP(z|z‚Ä≤) .
The resulting M-step equations are Eq. (17) and
P(v| y, z) ‚àù
‚ü®u,v‚Ä≤, y‚Ä≤‚ü©:
v‚Ä≤=v, y‚Ä≤= y
Q‚àó(z; u, v, y, ÀÜŒ∏) .
The details of the derivation can be found in the appendix. Comparing these
equations with the standard pLSA equations in Section 3 shows little differences on a qualitative level.
4.5 Maximum Likelihood Estimation: Continuous Case
In the continuous case with Gaussian distributions, both the E-step and M-step
need to be modiÔ¨Åed. The E-step equation can be obtained by replacing P(v| y, z)
with a Gaussian probability density function P(v; ¬µ y,z, œÉ y,z). The M-step update equations can be obtained by differentiating Eq. (16) with respect to the
parameters ¬µ y,z and œÉ 2
¬µ,z (cf. appendix) which results in
‚ü®u,v, y‚Ä≤‚ü©: y‚Ä≤= y v Q‚àó(z; u, v, y, ÀÜŒ∏)
‚ü®u,v, y‚Ä≤‚ü©: y‚Ä≤= y Q‚àó(z; u, v, y, ÀÜŒ∏)
‚ü®u,v, y‚Ä≤‚ü©: y‚Ä≤= y(v ‚àí¬µ y,z)2 Q‚àó(z; u, v, y, ÀÜŒ∏)
‚ü®u,v, y‚Ä≤‚ü©: y‚Ä≤= y Q‚àó(z; u, v, y, ÀÜŒ∏)
These are essentially the standard M-step equations of a Gaussian mixture
model. The fact that mixing proportions are user-speciÔ¨Åc only enters in the
computation of the posterior probabilities in the E-step. On an intuitive level,
the community means ¬µ y,z and variances œÉ 2
y,z are obtained by averaging over
votes available for item y. The relative weight of the vote cast by user u though
depends on the posterior probability of the latent ‚Äúcommunity‚Äù variable z.
4.6 Computational Complexity
The amount of data available in many practical applications of recommender systems can be enormous and the scalability of collaborative Ô¨Åltering
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Thomas Hofmann
algorithms is a crucial factor for a successful system deployment. One has to
distinguish between the ofÔ¨Çine and online computational complexity of an algorithm. The former accounts for computations that can be performed beforehand, that is, before actual predictions or recommendations for speciÔ¨Åc users
have to be made. The latter deals with those computations that can only be performed in real-time during the interaction with a speciÔ¨Åc user, either because
it is intractable to precompute all possible predictions or recommendations in
advance, or because user proÔ¨Åles are changing dynamically in the course of an
on-line session.
OfÔ¨Çine Complexity.
Analyzing the ofÔ¨Çine complexity of the proposed
EM algorithm requires Ô¨Årst of all to calculate the complexity of the E-step and
M-step respectively. In the E-step, one needs to compute the optimal variational
probability Q‚àófor each of the N observed user ratings. Each such Q‚àóconsists
of k numbers and requires a constant number of arithmetic operations to be
computed, resulting in O(k ¬∑ N) operations for a single E-step. In the M-step,
the posterior probabilities for each rating are accumulated to form the new estimates for P(z|u), P(v| y, z) and (in the free prediction model) P( y|z). Notice
that each Q‚àó(z; u, v, y) is added to the accumulators for exactly one P(z|u) and
P( y|z) as well as one of the accumulators for P(v| y, z) (multinomial model) or
¬µ y,z and œÉ 2
y,z (Gaussian model). Thus, the M-step also requires O(k ¬∑ N) operations. Typical values of k in our experiments have been in the range between 20
and 200. As far as memory requirements are concerned, we would like to point
out that the E-steps and M-steps can be interleaved so that at any point we
need to store the old value of the parameters, summarized in ÀÜŒ∏, as well as the
same number of accumulator variables which are used internally to compute
the new estimate of Œ∏.
The number of EM-iterations that need to be performed cannot be easily
estimated a priori, since it depends on properties of the speciÔ¨Åc data set. In
the experiments, we have found that between 30‚Äì100 iterations are usually
sufÔ¨Åcient.
Online Complexity.
More important for many applications is the
online complexity of computing predictions in a dynamic environment. First of
all, let us analyze the computational effort for computing a prediction g(u, y),
focusing on the Gaussian pLSA case for concreteness. From Eq. (25), we have
that g(u, y) = 
z P(z|u)¬µ y,z. Since ¬µ y,z and P(z|u) are assumed to be explicitly available as part of the statistical model, this requires 2k arithmetic
operations. Moreover, since the number of communities k does not depend on
the number of users n nor the number of items m, this amounts to a constant
time prediction algorithm which has a computational complexity of O(k).
For new users u, we also have to compute P(z|u) in the Ô¨Årst place. Similarly,
if additional ratings for user u become available, we would like to update the parameters P(z|u) accordingly. We propose to ignore the effect on the communityspeciÔ¨Åc parameters, since we expect the notion of a community to change on a
much smaller time-scale. These changes can be taken into account by regular
ofÔ¨Çine incremental EM updates or model retraining. From Eq. (17b), one sees
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Latent Semantic Models for Collaborative Filtering
that computing P(z|u) only involves posterior probabilities P(v|u, y) for ratings of the same user u. Hence we propose to perform a limited EM iteration in
which the E-step computes the posterior probabilities for all nu ratings of the
active user, which can be done in O(nu ¬∑ k) operations and the M-step updates
are restricted to the P(z|u) parameters, which can also be carried out in time
O(nu ¬∑ k). This operation has also been called fold-in [Hofmann 2001a]. Typically, 20‚Äì40 restricted EM iterations are sufÔ¨Åcient to compute P(z|u). Notice
that the computational complexity is independent of the number of users and
items, but depends on the number of items that have been rated by the active
5. EXPERIMENTS
5.1 Data Set
The data we have used in our experiments is the EachMovie data set
[EachMovie]. The data has been collected by Digital Equipment Research Center from 1995 through 1997. There are 1,623 items (movies) in this data set
and 61,265 user proÔ¨Åles with a total of over 2.1 million ratings. Consequently,
the average number of ratings per user is about 35. The rating scale is discrete,
taking values from 0 (no star) to 5 (Ô¨Åve stars),2 with 5 being the highest rating
and 0 being the lowest rating. The average rating over all observed votes is
‚âà3.03 and the overall rating variance is ‚âà1.48.
The EachMovie data set is to our knowledge the largest publicly available
data set for collaborative Ô¨Åltering and possesses the advantage of offering explicit user ratings. The latter fact allows us to study both, item selection and
rating prediction.
5.2 Evaluation Metric
A thorough empirical analysis of collaborative Ô¨Åltering algorithms has been
presented in Breese et al. and we have adapted most of the proposed
evaluation metrics. The effectiveness of collaborative Ô¨Åltering techniques can
be measured in various ways dependent on how the recommender system is
used and how results are presented to the user.
The Ô¨Årst setting we have investigated assumes that the goal of the system
is to predict user ratings. Hence, we assume that an item y is presented to
a user u and the goal is to predict the rating ÀÜv = g(u, y). We have used two
loss functions to measure the deviation between the predicted rating ÀÜv and the
observed rating v: the absolute deviation |ÀÜv ‚àív| and the squared error (ÀÜv ‚àív)2.
Empirical risks based on these loss functions are summarized as the mean
absolute error (MAE) and the rooted mean square (RMS) error. In addition we
have also measured the zero-one loss, in which case the predictions have been
quantized by rounding ÀÜv to the closest integer.
In the second setting, the goal is to predict both, the selected item and the
corresponding rating. Here we have used the score for ranked lists proposed
2The original ratings have been multiplied by a factor of 5.
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Thomas Hofmann
in Breese et al. . Let us denote a permutation of the items by œÑ and
the rank of an item y with respect to œÑ by œÑ( y). The top ranked item y will
have œÑ( y) = 1, the second item œÑ( y) = 2, and so forth. Items whose ratings
have been used for training are not included in the ranking. We then use the
following rank score for œÑ,
‚ü®u‚Ä≤,v, y‚ü©:u=u‚Ä≤
Œ±‚àí1 max(v ‚àí¬Øv, 0),
with ¬Øv denoting the overall mean vote. The rationale behind this score is that
when presented with a ranked list of items, users will sift through the list starting at the top, until they Ô¨Ånd a relevant item or simply give up. The probability
that a user will ever take notice of an item at rank r is modeled as an exponential distribution with a half-life constant Œ± (set to 4 in our experiments). The
total score for a population of users is then measured by (cf. Breese et al. )
u R(u, œÑu)
u maxœÑ ‚Ä≤ R(u, œÑ ‚Ä≤) .
This normalizes the sum of the achieved score with what could have optimally
achieved, if for every user all relevant items would appear at the very top of
the ranked list.
5.3 Evaluation Protocols
We have used the leave-one-out protocol to evaluate the obtained prediction
accuracies. This means we randomly leave out exactly one rating for every
user possessing at least a minimal number M ‚â•2 of observed ratings and
then average the loss function over this set of users to obtain an estimate of
the risk. This protocol has been called AllBut1 in Breese et al. . More
precisely, we have eliminated one vote for every user from the training set and
trained models on this reduced set. Notice that this uses somewhat less data
than required, but allows us to use a single model to evaluate the leave-oneout performance averaged over all users. We have varied M to investigate the
prediction accuracy for users for which a minimal number of M ratings are
available. In order to establish statistical signiÔ¨Åcance of the Ô¨Åndings, we have
repeated the leave-one-out procedure 20 times with different random seeds.
The reported numbers are the mean performance averaged over these 20 runs.
5.4 Results: Prediction Scenario
Table I summarizes experimental results obtained by different variants of the
proposed method (multinomial, Gaussian, Gaussian with normalized votes),
a memory-based method using the Pearson correlation coefÔ¨Åcient, and results
 
Bayesian networks = BN, correlation = CR). The baseline is simply deÔ¨Åned by
the overall mean vote for each item. The test votes have been selected by leaveone-out with M = 2.
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Latent Semantic Models for Collaborative Filtering
Table I. Prediction Accuracy of Various Methods in forced Prediction Mode Averaged
Over 20 Runs
Relative improvement
Pearson correlation
Multinomial
Gaussian, normalized
CR [Breese et al. 1998]
BC [Breese et al. 1998]
BN [Breese et al. 1998]
As far as different sampling models for the ratings are concerned, one can
make the following observations: First of all, the multinomial sampling model is
quite competitive, yielding an improvement over the correlation-based method
for all three loss functions and achieving the best overall performance for the
zero-one loss. Second, the Gaussian model without user-speciÔ¨Åc normalization
does much worse and is clearly not competitive. Third, performing the userspeciÔ¨Åc scale transformation in the Gaussian rating model leads to a substantial
gain in prediction accuracy, yielding the best achieved results with respect to
MAE and RMS error. It is also quite remarkable that this result is obtained with
a model involving a much smaller number of communities (k = 40) compared
to the multinomial model (k = 200). We conclude from this that the assumption
of user-speciÔ¨Åc rating scales encodes useful prior knowledge.
As can be seen, the proposed Gaussian pLSA outperforms the memory-based
method in terms of MAE and achieves a relative accuracy gain over the baseline of 17.8% as opposed to 12.9% for the Pearson correlation. This corresponds
to a relative performance gain of approximately 6% when taking the Pearson
correlation method as the baseline. In absolute terms, the MAE difference between the memory-based method based on the Pearson correlation coefÔ¨Åcient
and the normalized Gaussian pLSA model with k = 40 has a mean of 0.053
and a standard deviation of 0.0036. This is statistically highly signiÔ¨Åcant, for
example, using a paired t-test on the differences this corresponds to a t-value
of ‚âà50, which means that Gaussian pLSA outperforms the Pearson correlation
method with conÔ¨Ådence approaching certainty.
Notice that the results are overall better than the results published in Breese
et al. . With respect to the latter results one has to acknowledge a somewhat different setup though, which has lead to overall better performance results in our experiments. However, an approximate comparison seems to be possible by identifying our implementation of a correlation-based Ô¨Åltering method
with the one implemented in Breese et al. .
We have further investigated the effect of M on the prediction accuracy
obtained by the correlation-based method and the Gaussian pLSA approach. It
has to be expected that the prediction accuracy improves with growing M for all
methods, since predictions should be more reliable for users for which a larger
number of ratings is available. Figure 2 shows the result in terms of MAE for
M = 2, 5, 10, 20, 50, 100, 200. It shows that the relative advantage of pLSA over
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Thomas Hofmann
MAE for the Pearson correlation method and Gaussian pLSA for different values of M
(corresponding to the minimal number of ratings required for test users).
Predictive performance in terms of MAE and RMS for the multinomial pLSA model as a
function of the number of user communities k.
the correlation-based method increases for larger M. Gaussian pLSA seems to
be capable of using additional ratings more effectively in order to improve the
average prediction accuracy, whereas the correlation-based methods shows only
a small improvement for larger M compared to the M = 2 case. At M = 200
the relative improvement of Gaussian pLSA over the correlation-based method
is more than 10% and the relative improvement over the baseline popularity
prediction approach is 23%.
We have also investigated the prediction accuracy obtained by models with
varying number of user communities. Figure 3 shows the results obtained for
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Latent Semantic Models for Collaborative Filtering
Predictive performance in terms of MAE and RMS for the Gaussian pLSA model as a
function of the number of user communities k.
the multinomial model. It can be seen that the performance improves steadily
with the number of communities, but levels off towards the end. This is not
true however in the case of models with Gaussian distributions for community
ratings. Figure 4 shows a clear optimum around k = 40 communities, after
which the performance slowly degrades with model size. This seems to indicate that the multinomial rating model needs to introduce a larger number
of communities to account for the user-speciÔ¨Åc shift in the rating scale, which
is incorporated a priori in the Gaussian model. The latter therefore requires
fewer communities to model the correlations between the normalized user
Our next comparison (Figure 5) evaluates the effectiveness and importance
of the tempered regularization with early stopping. We have used 10% hold-out
data to determine the optimal stopping point and Œ≤-value, respectively. In the
case of early stopping, one more EM training iterations using all data (training
plus hold-out) is performed after stopping. Since the results are comparable
for different sampling models, we only report and discuss the results for the
multinomial case using the MAE criterion. As can be seen from the graph, the
models obtained via tempered EM consistently outperform the ones trained by
plain EM with early stopping. It is important to notice though that the number
of EM iterations performed in early stopping EM is much smaller, typically
between 30 and 40, compared to approximately 100‚Äì120 in the tempered version. On the other hand, for the same performance level, the tempered models
need fewer parameters and are hence more compact. Tempering also requires
to determine the optimal inverse temperature Œ≤ which further increases the
computational burden. In practice, the scalability-accuracy tradeoff may be decided with regard to the speciÔ¨Åc application and the available computational
resources.
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Thomas Hofmann
Predictive performance in terms of MAE for tempered EM (TEM) vs. early stopping EM
Table II. Performance of Different Methods in Free Prediction Mode
According to Ranking Criterion
rel. improv.
Pearson correlation
Multinomial
Gaussian, normalized
5.5 Results: Ranking Scenario
The second scenario we have experimentally investigated is the free prediction
mode. Since the prediction accuracy in predicting votes is no longer adequate,
we have used the ranking loss in Eq. (34) to benchmark different algorithms.
Again, we have used the leave-one-out protocol. The results are summarized in
The best ranking scores are obtained by the multinomial and the normalized
Gaussian pLSA model. The difference between these two models is not statistically signiÔ¨Åcant, while the performance gain relative to the Pearson correlation
method is signiÔ¨Åcant. The relative performance gain with respect to the popularity baseline is overall higher than in the forced prediction mode‚Äìmore than
40% relative improvement are achieved. Notice however that the actual prediction error of these models is higher than for the models that have been trained
in forced mode. In fact the absolute error of the Gaussian pLSA model is slightly
higher than with the correlation-based approach, although the difference is not
statistically signiÔ¨Åcant.
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Latent Semantic Models for Collaborative Filtering
5.6 Runtime
We have implemented the Gaussian and multinomial pLSA algorithms in C++
and ran our experiments on a standard PC with a 2GHZ CPU. The computer
time needed to perform a single EM step using all 61,265 users for a Gaussian
model with k = 40 is about 30 seconds. The number of iterations required
when using early stopping is around 30‚Äì40 while up to 100‚Äì120 iterations are
required when using tempered EM. In the latter case, the off-line training of the
model takes thus slightly less than 1 hour, while off-line training using earlystopping takes less than 20 minutes. For models with larger k, the training
time grows proportionally in k.
5.7 Miscellaneous
In the above experiments, we have always used the community variant of the
latent class models, that is, models involving P(v| y, z) instead of P(v|u, z). We
have also run experiments with the latter though, which has consistently led
to worse results. For example, the best MAE obtained in forced prediction was
0.971 compared to an absolute error of 0.927 for the multinomial community
We have also not been able to obtain competitive results using the normalized
risk function of Eq. (8) for training. In fact, we have even experimented with
various interpolated versions of the risk functions in Eq. (7) and Eq. (8) without
much success. It thus seems that a uniform weighting of each rating is the best
5.8 Mining User Communities
Finally, we would like to illustrate that the decomposition of user ratings may
lead to the discovery of interesting patterns and regularities that describe user
interests as well as disinterest. To that extent, we have to Ô¨Ånd a mapping
of a quantitative pLSA model into a more qualitative description suitable for
visualization. We propose to summarize and visualize each user community,
corresponding to one of the k possible states of the latent variable Z, in the
following way. We sort items within each community or interest group according to their popularity within the community as measured by the probability
P( y|z). The most popular items are used to characterize a community and we
expect these items to be descriptive for the types of items that are relevant
to the user community. Figures 6 and 7 display the interest groups extracted
by a multinomial pLSA model with k = 40, ordered according to the average
‚Äúpositiveness‚Äù of each group, computed as g( y, z) = 
y,v vP(v| y, z)P( y|z). For
example, in Figure 6, interest group 6 has romantic movies like ‚ÄúThe Remains
of the Day‚Äù, ‚ÄúThe Piano‚Äù, ‚ÄúLike Water for Chocolate‚Äù and ‚ÄúMuch Ado About
Nothing‚Äù top ranked. Interest group 18 seems to be formed around musicals
like ‚ÄúMary Poppins‚Äù, ‚ÄúCinderella‚Äù, ‚ÄúThe Sound of Music‚Äù and ‚ÄúDumbo‚Äù. With
each top-ranked item, we also suggest to display the average rating the item
receives in the community, computed as ¬Øv = 
v vP(v| y, z). These numbers
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Thomas Hofmann
User communities 1‚Äì20 (of 40) extracted from the EachMovie data set with a multinomial
pLSA model.
are displayed in rectangular brackets and enclosed by stars in Figures 6 and 7.
Looking at the average ratings obtained by the top movies in each of the interest
groups extracted from the EachMovie data set, it is interesting to see that communities seem to constitute themselves around items of either common interest
or disinterest. This is indicated by the fact that movies with highest selection
probabilities P( y|z) within a community z seem to have similar ratings. Notice
that the latter fact is nowhere enforced by any means in the model and is a
property that emerges from the data.
While some of the dis-interest groups like the one formed around the movies
‚ÄúMighty Morphin Power Rangers‚Äù and ‚ÄúThe Brady Bunch Movie‚Äù are certainly
not useful to derive recommendations, they are however important to model and
predict negative ratings and to prevent that certain items end up as recommendations where they should not. Some of the extracted ‚Äúcommunities‚Äù may thus
not correspond to interest groups in the usual sense, which are formed around
a common interest. Rather, communities are characterized by a commonality
that can also be a shared depreciation for certain items.
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Latent Semantic Models for Collaborative Filtering
User communities 21‚Äì40 (of 40) extracted from the EachMovie data set with a multinomial
pLSA model.
Overall, we believe that patterns and regularities extracted with pLSA models can be helpful in understanding shared interests of users and correlations
among ratings for different items. The ability to automatically discover communities as part of the collaborative Ô¨Åltering process is a trait which pLSA shares
with only few other methods such as clustering approaches, but which is absent
in all memory-based techniques.
6. CONCLUSION
We have presented a powerful method for collaborative Ô¨Åltering and mining
of user data based on a statistical latent class model. The method achieves
competitive recommendation and prediction accuracies, is highly scalable, and
extremely Ô¨Çexible. Conceptionally, the decomposition of user preferences using
overlapping user communities is a novel idea that clearly distinguishes this
approach from traditional memory-based approaches as well as previous modelbased methods.
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Thomas Hofmann
A.1 Derivation of the Generalized E-step
We derive the solution of minimizing the following objective function
FŒ≤(Q) = ¬ØR(Œ∏, Q) ‚àí1
H(Q(¬∑; u, v, y))
with respect to the variational distribution Q.
Notice Ô¨Årst that FŒ≤ can be rewritten as a sum over contributions from all
(u, v, y) pairs,
FŒ≤(u, v, y, Q),
FŒ≤(u, v, y, Q) = ‚àí
Q(z; u, v, y)
log S(u, v, y, z) ‚àílog Q(z; u, v, y)
Here S(u, v, y, z)
P( y|z)P(z|u) in the co-occurrence model, whereas
S(u, v, y, z)
P(v| y, z)P( y|z)P(z|u) in the free prediction case and
S(u, v, y, z) = P(v| y, z)P(z|u) for forced prediction.
Hence, one can minimize every FŒ≤(u, v, y, Q) separately. Introducing a Lagrange multiplier Œª to enforce the normalization constraint 
z Q(z; u, v, y) = 1,
one forms the Lagrangian function
LŒ≤(Q, Œª) = FŒ≤(u, v, y, Q) + Œª
Q(z; u, v, y) ‚àí1
Computing the partial derivative of LŒ≤ with respect to Q(z; u, v, y) and setting
to zero results in the necessary conditions
Œ≤ log Q‚àó(z; u, v, y) = log S(u, v, y, z) ‚àíŒª + 1
Exponentiating both sides of the equality yields
Q‚àó(z; u, v, y) = S(u, v, y, z)Œ≤
Apparently, Œª needs to be chosen such that
S(u, v, y, z)Œ≤ ‚áê‚áíŒª = 1
S(u, v, y, z)Œ≤
Plugging this value for the Lagrange multiplier Œª back into the Lagrangian
function results in the general optimality condition for Q which leads to the special cases of Eq. (15) and the tempered version in Eq. (19) for the co-occurrence
model and Eq. (29) and Eq. (30) for the model including rating variables.
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Latent Semantic Models for Collaborative Filtering
A.2 Derivation of the M-step
The most general case is the free prediction case, where one has to minimize
¬ØR(Œ∏, ÀÜŒ∏)=‚àí1
Q‚àó(z; u, v, y, ÀÜŒ∏)
log P(v| y, z) + log P( y|z) + log P(z|u)
with respect to the parameters P( y|z), P(z|u) and the parameters representing
P(v| y, z), respectively. In order to ensure the normalization 
y P( y|z) = 1 for
all z and 
z P(z|u) = 1 for all u, we introduce Lagrange multipliers Œªz and Œªu
and form the Lagrangian
L(Œ∏) = ¬ØR(Œ∏, ÀÜŒ∏) +
P( y|z) ‚àí1
Taking derivatives with respect to P( y|z) and setting to zero results in
Q‚àó(z; u, v, y, ÀÜŒ∏) ‚àíŒªz = 0 ‚áê‚áíP( y|z) = 1
Q‚àó(z; u, v, y, ÀÜŒ∏)
Similarly one obtains for P(z|u)
Q‚àó(z; u, v, y, ÀÜŒ∏) ‚àíŒªu = 0 ‚áê‚áíP(z|u) = 1
Q‚àó(z; u, v, y, ÀÜŒ∏)
Plugging these results back into Eq. (43) yields the following expressions for
the Lagrange multipliers
Q‚àó(z; u, v, y, ÀÜŒ∏)
Q‚àó(z; u, v, y, ÀÜŒ∏) =
which in turn lead to the M-step equations in Eq. (17).
In the multinomial pLSA model, one uses the same approach for P(v| y, z), introducing additional Lagrange multipliers Œª y,z to ensure that 
v P(v| y, z) = 1.
Augmenting the Lagrangian function by a term 
v P(v| y, z) ‚àí1
and solving as before leads to equation Eq. (31). Notice that the M-step equations for the co-occurrence model and the forced prediction case can be obtained
by dropping the equations for P(v| y, z) and P( y|z), respectively.
In the Gaussian pLSA model, one has to compute derivatives
‚àÇ¬ØR(Œ∏, ÀÜŒ∏)
‚ü®u,v, y‚Ä≤‚ü©, y= y‚Ä≤
Q‚àó(z; u, v, y, ÀÜŒ∏)v ‚àí¬µ y,z
‚ü®u,v, y‚Ä≤‚ü©, y= y‚Ä≤ Q‚àó(z; u, v, y, ÀÜŒ∏)v
‚ü®u,v, y‚Ä≤‚ü©, y= y‚Ä≤ Q‚àó(z; u, v, y, ÀÜŒ∏)
and a similar equation for œÉ 2
ACM Transactions on Information Systems, Vol. 22, No. 1, January 2004.
Thomas Hofmann
ACKNOWLEDGMENTS
The EachMovie data set is by courtesy of Digital Equipment Corporation and
was generously provided by Paul McJones.