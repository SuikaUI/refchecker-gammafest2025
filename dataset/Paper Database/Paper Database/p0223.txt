Received December 1, 2018, accepted December 13, 2018, date of publication December 19, 2018,
date of current version January 23, 2019.
Digital Object Identifier 10.1109/ACCESS.2018.2888585
A Novel Data-Driven Model for Real-Time
Influenza Forecasting
SIVA R. VENNA
1,2, AMIRHOSSEIN TAVANAEI1,2, RAJU N. GOTTUMUKKALA2,
VIJAY V. RAGHAVAN1,2, (Life Senior Member, IEEE), ANTHONY S. MAIDA1,
AND STEPHEN NICHOLS3
1School of Computing and Informatics, University of Louisiana at Lafayette, Lafayette, LA 70503, USA
2NSF Center for Visual and Decision Informatics, University of Louisiana at Lafayette, Lafayette, LA 70506, USA
3Schumacher Clinical Partners, Lafayette, LA 70508, USA
Corresponding author: Raju N. Gottumukkala ( )
This work was supported in part by the Division of Computer and Network Systems under Grant 1650551 and in part by Oak Ridge
Associated Universities under Grant 370270.
ABSTRACT We propose a novel data-driven machine learning method using long short-term memory
(LSTM)-based multi-stage forecasting for inﬂuenza forecasting. The novel aspects of the method include
the following: 1) the introduction of LSTM method to capture the temporal dynamics of seasonal ﬂu and
2) a technique to capture the inﬂuence of external variables that includes the geographical proximity and
climatic variables such as humidity, temperature, precipitation, and sun exposure. The proposed model
is compared against two state-of-the-art techniques using two publicly available datasets. Our proposed
method performs better than the existing well-known inﬂuenza forecasting methods. The results offer a
promising direction in terms of both using the data-driven forecasting methods and capturing the inﬂuence
of spatio-temporal and environmental factors to improve inﬂuenza forecasting.
INDEX TERMS Inﬂuenza forecasting, LSTM, recurrent neural networks, spatio-temporal data, time series
forecasting.
I. INTRODUCTION
Seasonal inﬂuenza is a major global health epidemic. According to the Center for Disease Control (CDC) reports in the
United States alone, there were 9.2 million to 35.6 million
reported illnesses since 2010. Inﬂuenza can cause severe
illnesses and even deaths for high-risk populations. Prevention and control of inﬂuenza spread can be a huge challenge
especially without adequate tools to monitor and estimate
the intensity of outbreaks in various populations. Predicting
inﬂuenza is a very difﬁcult task given the stochastic nature
of the inﬂuenza strain and environmental conditions that
affect the severity of the spread. Given the importance of this
problem, many researchers have tried different approaches
 – to model various aspects of inﬂuenza outbreaks.
Data-driven forecasting models offer a promising direction,
especially with availability of real-time data on affected
populations, and environmental conditions that contribute
to these outbreaks. CDC – and Defense Advanced
Research Projects Agency (DARPA) , have launched
several competitions to solve the problem of real-time forecasting of inﬂuenza and other infectious diseases.
Inﬂuenza forecasting research may be broadly classiﬁed
categories.
traditional
compartment
Susceptible-Infected-Recovered (SIR) , , Susceptible-
Infected-Recovered-Susceptible
Susceptible-Exposed-Infected-Recovered (SEIR) , .
The compartmental models are intuitive in terms of capturing the different states of infected populations. These
models are deterministic and lack ﬂexibility to be recalibrated in terms of capturing the dynamics of inﬂuenza
spread. The models in the second category employ statistical
and time-series based methodologies such as Box-Jenkins
applying some variant of Auto-Regression Integrated Moving Average (ARIMA) and Generalized Autoregressive
Moving Average (GARMA) . The Box-Jenkins based
time-series methods are ﬂexible in terms of capturing the
trending behavior of affected populations, but suffer from
poor accuracy as the inﬂuence of external factors is not
well captured in existing forecasting models. The third category models are machine learning methods that have gained
prominence in recent years. Some popular machine learning
VOLUME 7, 2019
2018 IEEE. Translations and content mining are permitted for academic research only.
Personal use is also permitted, but republication/redistribution requires IEEE permission.
See for more information.
S. R. Venna et al.: Novel Data-Driven Model for Real-Time Influenza Forecasting
methods include Stacked linear regression , Support Vector Regression , Binomial Chain , Classiﬁcation and
Regression Trees . Machine learning based approaches
are data-driven approaches that offer more ﬂexibility in terms
of capturing the inﬂuence of multiple external variables, but
are computationally expensive compared to statistical models. The use of machine learning methods in understanding
inﬂuenza dynamics are discussed in – . Additionally,
a review of existing inﬂuenza forecasting methods is provided
in – .
Recurrent Neural Networks (RNNs), a class of machine
learning methods, have the ability to model sequential (temporal) data prediction . However, the conventional RNNs
have shown practical difﬁculties in training the networks
faced with long temporal contingencies of input/output
sequences . Most recently, a gradient-based method
called Long Short Term Memory (LSTM) was introduced to
develop a stable recurrent architecture . This new technology supersedes RNNs for time series forecasting. RNNs solve
the vanishing/exploding gradient problem and gives much
more ﬂexibility to the learning algorithm on when to forget
the past or ignore the current input. The deep network architecture of the LSTM cells can provide a powerful model in
temporal data processing. Recently, LSTM and deep LSTM
have attracted much interest in temporal data prediction such
as trafﬁc speed prediction and classiﬁcation of the diagnoses given intensive care unit time series . One of the
key contributions of the paper is the application of a deep
LSTM neural network for the ﬂu prediction problem. The deep
architecture can be fulﬁlled by unrolling the LSTM cells in
which the input of the successor cell is provided by the output
of the predecessor cell.
Researchers have attempted to improve the forecasting accuracy of inﬂuenza prediction methods by capturing
the inﬂuence of external environmental variables. Previous
studies have clearly identiﬁed direct inﬂuence of weather
variables such as temperature, humidity, precipitation etc.
on inﬂuenza virus transmission and survival
 – .
As presented in , low relative humidity aids in faster evaporation of expelled droplets or particles and longer survival
of the airborne virus. Also, geographical regions that are in
close proximity to infected regions have high risk of getting
infected due to population movements and high-likelihood
of social interactions
 – . The impact of environmental factors has to be integrated effectively into the ﬂu
forecasting model to achieve better accuracy with inﬂuenza
prediction models. Recent work from tried to capture
the inﬂuence of environmental conditions for ﬂu forecasting
using GARMA(3,0) model. Prior experimental studies in 
and , however, demonstrated that temperature and humidity are not linearly correlated with inﬂuenza spread. Some of
the recent work also includes social media interactions such
as Twitter messages , Google searches involving ﬂu
related words , travel patterns to estimate ﬂu risk
in a particular region. However, these models, speciﬁcally
the Google Flu Trends (GFT) were criticized due to
lack of reliability that prompted Google to discontinue the
model for real-time forecasting. This highlights the gaps in
both gathering reliable data and forecasting methods. While
both statistical and machine learning methods have been
successfully applied for inﬂuenza forecasting, one of the
known limitations is that they have not been able to capture
the inﬂuence of external environmental variables to improve
inﬂuenza forecasting.
We propose a novel LSTM based multi-stage forecasting
method that integrates the inﬂuence of various external variables into state-of-the-art machine learning models. The ﬁrst
stage of the model employs a time-series forecasting model.
During subsequent stages the situational time-lag between the
ﬂu occurrence and weather variables, and spatial proximity
of different geographical regions are captured to adjust the
error introduced by the original forecasting model to further improve the performance of the model. There are two
important contributions of the paper. First, is the use of LSTM
model to forecast inﬂuenza counts. Second, is the introduction of a novel method to capture the inﬂuence of external
environmental variables. The proposed method is compared
with existing state-of-the-art models on both GFT and CDC
data. The LSTM model is further improved in terms of its
ability to forecast inﬂuenza counts at multiple spatial and
temporal scales by capturing both the inﬂuence of geographical proximity, and the impacts from environmental factors
in future stage. The proposed model performs better than the
existing baseline time series based ARIMA model and the
EAKF (Ensembled Adjustment Kalman Filter) model. EAKF
is a data assimilation method and a recursive ﬁltering technique that combines observations with a temporally-evolving
ensemble of model simulations to generate a posterior estimate of the model state . The notations and symbols used
in this paper are summarized in Table. 1.
II. METHOD
The proposed model consists of two stages. In the ﬁrst stage,
a deep learning model based on the LSTM neural network
approach is used to estimate an initial forecast. In the second stage the error from the initial forecast is reduced by
incorporating two different factors: (1) An impact factor
is obtained from the weather variables (humidity, precipitation, temperature, sun exposure) by extracting situational
time lags using symbolic time series approach, and (2) a
spatio-temporal adjustment factor obtained by capturing the
inﬂuence of ﬂu spread from neighboring regions within geographical proximity.
The proposed multi-stage forecasting approach includes
two following steps. In the ﬁrst stage, the LSTM neural
network is trained on the ﬂu time series of nodes to forecast
the initial ﬂu counts. A node refers to a geographical region,
which could be a HHS region or a GFT city. In the second
stage, the impact of climatic variables and spatio-temporal
adjustment factor are added to the ﬂu counts estimated by
the LSTM model to reduce the error. The impact component
from climatic variables is computed using the time delayed
VOLUME 7, 2019
S. R. Venna et al.: Novel Data-Driven Model for Real-Time Influenza Forecasting
TABLE 1. Notations and symbols used in this paper.
association analysis between each symbolic time series of
weather and ﬂu counts. The spatio-temporal adjustment factor is calculated by averaging over the ﬂu variations at
nearby data nodes. The proposed model is compared against
our baseline LSTM model and two state-of-the-art models
namely ARIMA(3,0,3) and Ensembled Adjustment Kalman
Filter (EAKF).
A. DEEP LONG SHORT TERM MEMORY NETWORK
1) LSTM CELL
RNN computes an output sequence (y1, y2, . . . , yT ) based
on its input sequence (x1, x2, . . . , xT ) and its previous state
(h1, h2, . . . , hT ) as shown in Eq. 1 and Fig. 1.
ht = σ(Wi · xt + Wh · ht−1 + bh)
yt = θ(Wo · ht + by)
FIGURE 1. Recurrent neural network.
Here σ and θ are the hidden and output activation functions.
W and b determine the adaptive weight and bias vectors of
LSTM is a variation of RNNs preserving back-propagated
error through time and layers. Furthermore, the LSTM learning algorithm is local in both space and time, with computational complexity of O(1) per time step and weight ,
which is faster than the popular RNN learning algorithms (e.g. real-time recurrent learning (RTRL) and
back-propagation through time (BPTT) ). An LSTM cell
performs as a memory to write, read, and erase information
according to the decisions speciﬁed by the input, output, and
forget gates, respectively. The weights associated with the
gates are trained (adapted) by a recurrent learning process.
FIGURE 2. An LSTM cell containing the input gate, the forget gate, and the
output gate. Each gate receives two vectors as input, xt , and previous
output, ot−1.
The memory cell shown in Fig. 2 is implemented as
It = σ(Wxixt + Wmiot−1 + bi)
Ft = σ(Wxf xt + Wmf ot−1 + bf)
Yt = σ(Wxoxt + Wmoot−1 + bo)
At = Wxcxt + Wmcot−1 + bc
Bt = Ft ⊙Bt−1 + It ⊙θ(At)
ot = Yt ⊙θ(Bt)
where Wx and Wm are the adaptive weights, initialized randomly in the range (0,1). xt and ot−1 denote the current input
and previous output vectors, respectively. b parameters are
bias vectors that are not shown in Fig. 2. The cell state,
Bt, is updated by the forget gate, the input gate, and the
current input value (At). The functions σ and θ determine
the Sigmoid and Tanh activations respectively.
2) DEEP LSTM ARCHITECTURE
A number of approaches for developing the deep architectures
in , , , and . In this investigation, we construct
an LSTM network by unrolling the LSTM cells in time. This
model provides a suitable architecture for the time series
prediction problems due to its sequential framework. Fig. 3
shows the network architecture consisting of the unrolled
VOLUME 7, 2019
S. R. Venna et al.: Novel Data-Driven Model for Real-Time Influenza Forecasting
FIGURE 3. LSTM neural network consisting of the unrolled LSTM cells. The red backward arrows show
the backpropagation algorithm and are not part of the network architecture.
LSTM cells that are trained by the back-propagation algorithm based on the mean-square-error cost function (training
criterion). The corresponding LSTM cell at time t −i receives
the ﬂu count calculated by the predecessor cell (ot−i−1) and
the input, xt−i, to calculate the ﬂu count at t −i, ot−i. This
process is repeated for all LSTM cells in the model. The
number of LSTM cells denotes the number of time steps,
T, before the current time. To calculate the ﬂu count at the
current state, t, the data points from T previous time steps are
used. After different experimental setups, we selected T = 20
time steps.
B. CLIMATIC VARIABLE IMPACT
There is strong evidence from prior literature that the dynamics of ﬂu spread and intensity is inﬂuenced by various climatic conditions
 – . Humidity, sun exposure, precipitation, temperature all have different levels of impact
on the ﬂu counts. For example, in Fig. 4, one can observe
the strong correlation between the maximum and minimum
temperatures with ﬂu counts from CDC data in one of the
geographical regions. While the impact of these climatic
variables is evident, a linear relationship between a climatic
variable and ﬂu count may not be effective. This is because
the dynamics of ﬂu spread is not linearly correlated with
climatic variables – . One way to capture these nonlinear relationships between the composite climatic variables
(i.e. temperature, sun exposure and precipitation) with the
ﬂu counts is through a symbolic time series approach. With
FIGURE 4. A plot showing correlation between minimum and maximum
temperatures with flu counts.
the symbolic time series approach, the numerical time series
is converted to a sequence of symbols
 – . These
symbols can be based on the characteristics of the original
time series that include magnitude, change over time, etc. The
situational time lag represents the time lag between a climatic
variable and ﬂu count.
Approach to Compute Situational Time Lags (STL):
1) Convert each of numeric time series (i.e. ﬂu counts,
temperature, sun exposure, precipitation) into symbolic
time series, where the numerical value at each time step
is converted to a symbol represented by a tuple (XY),
where X ∈{high, medium, low} and Y ∈{increasing,
decreasing, stable}.
2) Identify frequent symbol associations at different time
lags between the climatic variable and the ﬂu counts
using the Apriori algorithm . In this context, symbols represent items.
3) From the frequent symbol associations identiﬁed in
the earlier step, pick the symbol pairs that have high
conﬁdence. The conﬁdent frequent associated symbol
pairs at any time lag represent the situational correlation between the climatic variables and the ﬂu counts.
4) If symbol pairs are conﬁdent at multiple time lags,
then an average of these time lags is assigned to that
particular pair. Also, for symbol pairs missing from the
ﬁnal conﬁdent pair list, an overall average time lag is
assigned to them by default.
5) Create Situational-Time Lag STLv table (from step
3&4) for each climatic variable v that includes a symbol
pair (XY) and its appropriate situational time-lag.
Once the time lags between ﬂu counts and each weather
variable are computed for all the data nodes, total impact, Itot,
inﬂicted at time step t from the weather variables for data
node n is estimated using the formula shown in Eq. 8.
where Itot
n,t is the total impact from all the D climate variables
on the node n at time t, Ii
n,t is the individual impact from
climatic variable i on the node n at time t calculated as
shown in Eq. 9 and Wn,i is the impact weight associated
with the node n and climate variable i. The weights, Wn,i are
trained using Widrow-Hoff learning with mean square
error (MSE) criterion as the cost function on the training
data with target function as shown in Eq. 8. The target of
VOLUME 7, 2019
S. R. Venna et al.: Novel Data-Driven Model for Real-Time Influenza Forecasting
this Widrow-Hoff learning is to reduce the MSE to obtain
the optimum weights (Wn,i). These weights are exclusive and
trained separately for each data node.
n,t−lag −V i
n,t−lag, V i
The impact value at node n coming from ith climatic
variable at time t is the ratio of change happening before
the appropriate situational time-lag (lag) retrieved from the
situational time lag table STLi at time t and symbolic representation of ﬂu count Fn,t−1 at node n and time t −1. V i
the numeric time series (not the symbolic data) of ith weather
variable at node n.
C. SPATIO-TEMPORAL ADJUSTMENT FACTOR
Geographical proximity, in general, strongly affects inﬂuenza
outbreak in a particular region. One can observe similar ﬂu
trends between data nodes within spatial proximity as shown
in Fig. 5 for both GTF and CDC data. This impact is captured
by computing an adjustment factor from the nearby data
nodes. Similar to the weather variables, each neighboring
data node impacts this data node independently from the
other neighboring data nodes. Thus, a weighted summation
of individual adjustment factors is used. Here, Widrow-Hoff
learning is used to train those weights. Similar to the
impact weights, the mean square error (MSE) training criterion is used as the cost function. Adjustment factor coming
FIGURE 5. A plot showing similar trends in flu counts in 2015 for different
CDC regions (top). A map showing the CDC-HHS regions (bottom).
FIGURE 6. Comparison of MAPE, RMSE and RMSPE of the flu prediction
models for 1 to 5 weeks ahead forecasts with the CDC-ILI dataset.
from each neighboring node is the average of ﬂu variation
difference during the previous three time stamps at that node.
The adjustment factor, γ , to be applied at data node n on
the initial forecast at time step t is the weighted average of
changes in the ﬂu counts obtained at other nearby data nodes
at time step t −1.
Wn,i × γ i
(Fi,t−j −Fi,t−j−1)
Total adjustment γ tot
n,t at data node n and time t is the
average weighted summation of the individual adjustments
n,t coming from all its neighbors that are in geographical
proximity of n. Similar to the impact weights, adjustment
weights(Wn,i) are also trained using the Widrow-Hoff algorithm on the historical data from this node as well as its
neighbors. Here Fi,t−j is the actual ﬂu count at neighbor i
to n at time t −j. In our experiments we selected y to be 3 as
it gave us optimum results.
VOLUME 7, 2019
S. R. Venna et al.: Novel Data-Driven Model for Real-Time Influenza Forecasting
FIGURE 7. Comparison of Actual and predicted ILI counts for CDC-HHS Regions 1, 6, and 9 while forecasting 1 to 5 weeks ahead for an entire
flu-season.
D. FORECAST VALUE ESTIMATION
Final forecast after applying impact factor Itot
n,t from weather
variables and adjustment factor γn,t from spatio-temporal
neighbors as computed in Eq. 8 and 10, Fﬁnal
n,t , of data node n
at time t is computed as shown in the Eq. 12.
III. EXPERIMENTS AND RESULTS
The baseline LSTM model and the new proposed model are
compared against two state of the art models ARIMA and
EAKF on two different publicly available data sets related to
inﬂuenza counts, namely the CDC and GFT data sets. Both
data sets represent a broad sample in terms of spatio-temporal
granularity. The model was evaluated on three widely
accepted evaluation metrics, namely Mean Absolute Percentage Error (MAPE), Root Mean Square Error (RMSE) and
Root Mean Square Percentage Error (RMSPE) used in 
and . Each of the models were implemented in R .
The LSTM model was implemented using the Tensorﬂow
library . Computational complexity of BPTT and LSTM
are both O(W) where W is the number of adaptive weights.
However, LSTM, unlike the BPTT, is local in time and space
and does not need to store unlimited activation values .
The computational complexity of both the Widrow-Hoff
models trained for Eq. 8 and 10 is dependent on the size of
VOLUME 7, 2019
S. R. Venna et al.: Novel Data-Driven Model for Real-Time Influenza Forecasting
the weight vector W and the number of iterations required for
their convergence. The equations in Eq. 9, 11 and 12 are computed in linear time O(1) as they are simple additions and subtractions. A personal computer with Intel I7-6700k processor,
16 gigabytes of RAM and an NVIDIA 1070 GTX GPU was
used for the experiments. The LSTM model for each training
dataset takes 18-20 minutes to converge, and the overall
model takes approximately 24 to 25 minutes to train. The
prediction takes less than 2 seconds on the same hardware.
A. DATA DESCRIPTION
For inﬂuenza activity, two different real-world data sets were
chosen. The CDC-reported Inﬂuenza Like Illness (ILI) data
from CDC for all ten HHS regions between 2002-2016 is
the only national level dataset available for the United States.
Google Flu Trends (GFT) data is a weekly estimate of inﬂuenza activity derived from
aggregated search query data. A subset of the GFT dataset
including the ﬂu count trends reported for 6 cities from
Texas and Louisiana (Austin, Dallas, Houston, San Antonio,
Baton Rouge and New Orleans) is selected as a sample for
our experiments. The weather data is downloaded from Climate Data Online (CDO) that provides free access to
National Climatic Data Center (NCDC) archive of historical
weather and climate data. The weather variables that were
used include precipitation, maximum temperature, minimum
temperature, and sun exposure. For each city from the GFT
dataset, all available stations from the CDO within that city’s
geographical limits are downloaded. For the CDC dataset, all
the stations within each HHS region boundaries are downloaded from the CDO. The data collected from the CDO for
the both datasets are then aggregated for each city or region
by averaging into single weekly summarized time-series with
respect to each climatic variable. This aggregated data is
then cleaned to treat any further missing values using simple moving average based smoothing. At this time all collected datasets ILI, GFT and respective weather variables
are weekly summarized time series. For each experiment a
combination of training (80%) and testing set (20%) is used,
where training and testing sets are in sequence and mutually
exclusive. For LSTM the dataset is divided into training
(60%), validation (20%) and testing (20%) sets. During each
of the training exercises approximately 560 samples are used
for training and/or validation and the last 140 samples are
used for testing with respect to CDC dataset. At the same time
for GFT dataset the training and/or validation, testing sample
sizes are approximately 480 and 120 respectively.
B. EVALUATION CRITERIA
The prediction performance of the proposed system is evaluated using the following three metrics:
Mean absolute percentage error (MAPE) measures the
average percent of absolute deviation between actual and
forecasted values.
FIGURE 8. Comparison of MAPE, RMSE and RMSPE of the flu prediction
models for 1 to 5 weeks ahead forecasts with the GFT dataset.
Root mean squared error (RMSE) captures the square root
of average of squares of the difference between actual and
forecasted values.
Root mean squared percentage error (RMSPE) captures
percentage of square root of average of squares of the deviation between actual and forecated values.
where, N is the number of test samples, A is the actual ﬂu
count, and F is its respective forecasted value.
We compared our results with two state-of-the-art models
namely ARIMA and EAKF. The four models compared in the
results section are as follows:
• EAKF (Flu count estimated using the state-of-art
Ensembled Adjustment Kalman Filter)
• LSTM (The value predicted by LSTM (FLSTM) alone,
that is without the variable impact and adjustment factor
applied to it)
VOLUME 7, 2019
S. R. Venna et al.: Novel Data-Driven Model for Real-Time Influenza Forecasting
FIGURE 9. Comparison of Actual and predicted GFT counts for cities of Baton Rouge, Dallas and New Orleans while forecasting 1 to 5 weeks
ahead for an entire flu-season.
• ARIMA (Flu count estimated using the state-of-art
• Proposed (This is the ﬁnal forecast value (Fﬁnal
n,t ) after
both climatic variable impact factor and spatio-temporal
adjustment factor are added to LSTM as computed in
Eq. 12. This is the proposed approach)
C. RESULTS
Plots from Fig. 6 and Fig. 8 show the errors for various models for both CDC and GFT for weekly forecasting ranging
from 1 week to 5-weeks. The prediction error presented in
the ﬁgures is the average forecast across all the geographical
regions. From both tables, one can observe that for both CDC
and GFT data, the error increases with increase in forecast
length (i.e. 1 week to 5 weeks in advance) for all four models
(i.e. EAKF, LSTM, ARIMA model and the proposed model).
The charts in Fig. 7 and Fig. 9 show the ﬂu distribution
and forecasts over a one-year time period for three regions
from CDC data and three cities from GFT data respectively.
One can observe that the error in the forecast is typically
high when there is a sudden increase or decrease in ﬂu observations. The prediction errors for both LSTM and EAKF
models are less compared to the baseline ARIMA model for
VOLUME 7, 2019
S. R. Venna et al.: Novel Data-Driven Model for Real-Time Influenza Forecasting
both datasets. ARIMA has been extensively used in the past
because the data sample was not too large. We now have a
sizable dataset of 14 years of ﬂu data from CDC for 10 HHS
regions, and 11 years of data from GFT. Given the large
sample size, we observe that both LSTM and EAKF models
outperform the baseline ARIMA model. We were also able to
reliably quantify the impact of weather on inﬂuenza spread,
the impact of neighboring regions at a regional and city scale.
This enabled us to further improve the baseline LSTM model
by adjusting the error of the baseline forecast by incorporating the impact of climatic inﬂuence and spatio-temporal
ﬂu patterns. This error adjustment leads to a better forecast
compared to the baseline LSTM model and the EAKF model.
The primary limitation of the model is the requirement of
sufﬁcient training data both for capturing the inﬂuence of
external variables and training the baseline forecast model.
So, this model may not be effective when sample sizes are
The plots in Fig. 7 compares the predicted values from the
four models with actual data for 1 to 5 week-ahead forecasts
and HHS-CDC regions 1, 6 and 9 separately. For regions
1 and 9, all four models are successful in predicting the peak
ﬂu season for 1-week and 2-week ahead forecasts; however
ARIMA fails to identify peak for 4-week and 5-week ahead
forecasts. The other 3 models could identify peaks up to
5-week ahead forecasts. The proposed model’s prediction is
closest to the actual observed peak. In Region-6, there are
two different peaks during the ﬂu season. ARIMA failed to
identify the second peak after 1-week ahead forecast, whereas
the other 3 models identiﬁed both peaks up to 3 weekahead forecasts, with the proposed approach being the most
The plots in Fig. 9 compare the predicted values from
the four models with actual data for 1 to 5 week-ahead forecasts and GFT cities Baton Rouge, Dallas and New Orleans
separately. For Baton Rouge ARIMA fails to identify peaks
after 2-weeks ahead forecasts, while the other 3 could predict
the peaks up to 5-weeks ahead forecasts with the proposed
approach being the most accurate.
IV. CONCLUSION
In this paper, we proposed a new data-driven approach for
inﬂuenza forecasting. The ﬁrst key contribution is the applicability of the LSTM based deep-learning method which
is shown to perform well compared to existing time series
forecasting methods. We further reduced the error of the
deep learning based forecasting method by introducing an
approach to integrate the impact from climatic variables and
spatio-temporal factors. We evaluated the proposed approach
on publicly available CDC-HHS ILI and GFT datasets. The
proposed method offers a promising direction to improve the
performance of real-time inﬂuenza forecasting models.
In this paper, we have implemented separate learning components for the climatic variables and for the geospatially
proximal variables. Our future study seeks to develop an
end-to-end learning model incorporating all the modules.
This could be done by using a convolutional LSTM to
learn spatio-temporal patterns.