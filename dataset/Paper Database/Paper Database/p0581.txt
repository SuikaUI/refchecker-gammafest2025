BREGMAN MONOTONE OPTIMIZATION ALGORITHMSâˆ—
HEINZ H. BAUSCHKEâ€ , JONATHAN M. BORWEINâ€¡, AND PATRICK L. COMBETTESÂ§
SIAM J. CONTROL OPTIM.
âƒ2003 Society for Industrial and Applied Mathematics
Vol. 42, No. 2, pp. 596â€“636
A broad class of optimization algorithms based on Bregman distances in Banach
spaces is uniï¬ed around the notion of Bregman monotonicity.
A systematic investigation of this
notion leads to a simpliï¬ed analysis of numerous algorithms and to the development of a new class
of parallel block-iterative surrogate Bregman projection schemes. Another key contribution is the
introduction of a class of operators that is shown to be intrinsically tied to the notion of Bregman
monotonicity and to include the operators commonly found in Bregman optimization methods. Special emphasis is placed on the viability of the algorithms and the importance of Legendre functions
in this regard. Various applications are discussed.
Key words.
Banach space, block-iterative method, Bregman distance, Bregman monotone,
Bregman projection, B-class operator, convex feasibility problem, essentially smooth function, essentially strict convex function, FejÂ´er monotone, Legendre function, monotone operator, proximal
mapping, proximal point algorithm, resolvent, subgradient projection
AMS subject classiï¬cations. 90C25, 90C48, 47H05
PII. S0363012902407120
1. Introduction. A sequence (xn)nâˆˆN in a Banach space X is FejÂ´er monotone
with respect to a set S âŠ‚X if
(âˆ€x âˆˆS)(âˆ€n âˆˆN)
âˆ¥xn+1 âˆ’xâˆ¥â‰¤âˆ¥xn âˆ’xâˆ¥.
In Hilbert spaces, this notion has proven to be remarkably useful and successful in
attempts to unify and harmonize the convergence proofs of a large number of optimization algorithms; see, e.g., . A classical example is the
method of cyclic projections for ï¬nding a point in the intersection S Ì¸= Ã˜ of a ï¬nite
family of closed convex sets (Si)1â‰¤iâ‰¤m. In 1965, Bregman [14, Thm. 1] showed that
for every initial point x0 âˆˆX the sequence (xn)nâˆˆN generated by the cyclic projections
xn+1 = Pn (mod m)+1xn,
where Pi denotes the metric projector onto Si and where the mod m function takes
values in {0, . . . , mâˆ’1}, is FejÂ´er monotone with respect to S and converges weakly to
a point in that set. Two years later , the same author investigated the convergence
of this method in a general topological vector space X. To this end, he introduced
a distance-like function D: E Ã— E â†’R, where E is a convex subset of X such that
i=1 Si Ì¸= Ã˜. The conditions deï¬ning D require, in particular, that for
âˆ—Received by the editors May 6, 2002; accepted for publication (in revised form) January 8, 2003;
published electronically May 29, 2003.
 
â€ Department of Mathematics and Statistics, University of Guelph, Guelph, Ontario N1G 2W1,
Canada ( ). This authorâ€™s research was supported by the Natural Sciences and
Engineering Research Council of Canada.
â€¡Centre for Experimental & Constructive Mathematics, Simon Fraser University, Burnaby, British
Columbia V5A 1S6, Canada ( ). This authorâ€™s research was supported by the
Natural Sciences and Engineering Research Council of Canada and the Canada Research Chair
Programme.
Â§Laboratoire Jacques-Louis Lions, UniversitÂ´e Pierre et Marie Curie â€“ Paris 6, 75005 Paris, France
( ).
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
every i âˆˆ{1, . . . , m} and every y âˆˆE, there exists a point Piy âˆˆE âˆ©Si such that
D(Piy, y) = min D(Eâˆ©Si, y). In this broader context, Bregman showed that for every
initial point x0 âˆˆE the cyclic projections algorithm (1.2) produces a sequence that
satisï¬es the monotonicity property
(âˆ€x âˆˆS)(âˆ€n âˆˆN)
D(x, xn+1) â‰¤D(x, xn)
and whose cluster points are in S [15, eq. (1.2) and Thm. 1]. If X is a Hilbert space,
an example of a D-function satisfying the required conditions relative to the weak
topology is D: X 2 â†’R: (x, y) â†’âˆ¥x âˆ’yâˆ¥2/2. In this case, we recover the previous
convergence result [15, Example 1] and observe that (1.3) reduces to (1.1). If X is
the Euclidean space RN, another example of a suitable D-function is
D: E Ã— E â†’R: (x, y) â†’f(x) âˆ’f(y) âˆ’âŸ¨x âˆ’y, âˆ‡f(y)âŸ©,
where f : E âŠ‚RN â†’R is a convex function which is diï¬€erentiable on E and satisï¬es a
set of auxiliary properties [15, Example 2]. Due to its importance in applications, this
particular type of D-function was further studied in and has since been known as
a Bregman distance (see for an historical account). In RN, various investigations
have focused on the use of Bregman distances in projection, proximal point, and ï¬xed
point algorithms; see . (See also , where extensions of
(1.4) to nondiï¬€erentiable functions were studied.) Extensions to Hilbert 
and Banach spaces have also been considered
more recently. In the present paper, we adopt the following deï¬nition for Bregman
distances.
Definition 1.1. Let X be a real Banach space and let f : X â†’]âˆ’âˆ, +âˆ] be a
lower semicontinuous convex function which is GË†ateaux-diï¬€erentiable on int dom f Ì¸=
Ã˜. The Bregman distance (for brevity D-distance) associated with f is the function
D: X Ã— X â†’[0, +âˆ],
f(x) âˆ’f(y) âˆ’âŸ¨x âˆ’y, âˆ‡f(y)âŸ©
if y âˆˆint dom f,
otherwise.
In addition, the Bregman distance to a set C âŠ‚X is the function
DC : X â†’[0, +âˆ],
y â†’inf D(C, y).
In Hilbert spaces, one recovers D: (x, y) â†’âˆ¥x âˆ’yâˆ¥2/2 by setting f = âˆ¥Â· âˆ¥2/2.
This observation suggests that the following natural variant of the notion of FejÂ´er
monotonicity suits the environment described in Deï¬nition 1.1.
Definition 1.2. A sequence (xn)nâˆˆN in X is Bregman monotone (for brevity
D-monotone) with respect to a set S âŠ‚X if the following conditions hold:
(i) S âˆ©dom f Ì¸= Ã˜.
(ii) (xn)nâˆˆN lies in int dom f.
(iii) (âˆ€x âˆˆS âˆ©dom f)(âˆ€n âˆˆN) D(x, xn+1) â‰¤D(x, xn).
Let us note that item (ii) is stated only for the sake of clarity and that it could be
replaced by x0 âˆˆint dom f since, in view of (1.5), (iii) then forces the whole sequence
(xn)nâˆˆN to lie in int dom f.
The importance of the notion of Bregman monotonicity is implicit in . In the
Euclidean space setting of (see also [33, page 55]), Bregman monotone sequences
were called â€œDf FejÂ´er monotoneâ€ by analogy with (1.1).
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
H. H. BAUSCHKE, J. M. BORWEIN, AND P. L. COMBETTES
The goal of this paper is to provide a broad framework for the design and the analysis of algorithms based on Bregman distances around the notion of D-monotonicity.
This framework not only will lead to a uniï¬ed convergence analysis for existing algorithms, but also will serve as a basis for the development of a new class of parallel,
block-iterative, surrogate Bregman projection methods for solving convex feasibility problems involving variational inequalities, convex inequalities, equilibrium constraints, and ï¬xed point constraints. The tools developed in this paper also provide
the main building blocks for the algorithms proposed in to ï¬nd best Bregman
approximations from intersections of closed convex sets in reï¬‚exive Banach spaces.
Guide to the paper. We proceed towards our goal of constructing a broad
framework for Bregman distance-based algorithms in several steps.
We collect assumptions, notation, and basic results in section 2. The standing
assumptions on the underlying space X and the function f that generates the Bregman
distance are stated in section 2.1. In sections 2.2â€“2.6, we introduce basic notation and
terminology, including D-viable operators and Legendre functions. Useful identities
for the Bregman distance are provided in section 2.7.
A general and powerful class of operators based on Bregman distances is introduced and analyzed in section 3. This so-called B-class includes types of operators
fundamental in Bregman optimization such as D-ï¬rm operators, D-resolvents, D-prox
operators, and (subgradient) D-projections, which correspond to their classical counterparts when X is a Hilbert space and f = âˆ¥Â· âˆ¥2/2. For example, it is shown that if
X is reï¬‚exive and f is Legendre, then D-prox operators belong to B (Corollary 3.25).
This result underscores the importance of Legendreness. Moreover, B-class operators
are stable under a certain type of parallel combination, which will be crucial in the
formulation of a new block-iterative algorithmic framework in section 5.
Section 4 is devoted to D-monotonicity.
This is a central notion in the analysis of Bregman optimization methods because it describes the behavior of a wide
class of algorithms based on Bregman distances. Assumptions are given under which
simple characterizations can be established for the weak and strong convergence of
D-monotone sequences. In conjunction with the results of section 3, D-monotonicity
provides a global framework for the development and analysis of algorithms. Indeed,
we show that D-monotone sequences can be generated systematically via the iterative
x0 âˆˆint dom f and (âˆ€n âˆˆN) xn+1 âˆˆTnxn, where Tn âˆˆB.
A detailed convergence analysis of this unifying model is carried out which, in turn,
covers and extends known convergence results.
Finally, in section 5, we are in a position to construct a new block-iterative algorithmic framework. Results obtained in sections 3 and 4 are combined to construct
and investigate new classes of parallel, block-iterative methods for solving convex feasibility problems. The main result, Theorem 5.7, provides conditions suï¬ƒcient for the
weak and strong convergence of sequences generated by the new algorithm. Section 5.4
presents several scenarios in which these suï¬ƒcient conditions are satisï¬ed, including
the frequently encountered situation when f is a separable Legendre function on RN
such that dom f âˆ—is open (Example 5.14). The concluding sections, sections 5.5 and
5.6, discuss how the main result can be applied to speciï¬c optimization problems such
as solving convex inequalities, ï¬nding common zeros of maximal monotone operators,
ï¬nding common minimizers of convex function, and ï¬nding common ï¬xed points of
D-ï¬rm operators.
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
2. Notation, assumptions, and basic facts.
2.1. Standing assumptions. We assume throughout the paper that X is a real
Banach space and that f : X â†’]âˆ’âˆ, +âˆ] is a lower semicontinuous convex function
which is GË†ateaux-diï¬€erentiable on int dom f Ì¸= Ã˜.
2.2. Basic notation. Throughout, N is the set of nonnegative integers. The
norm of X and that of its topological dual X âˆ—is denoted by âˆ¥Â·âˆ¥, the associated metric
distance by d, and the canonical bilinear form on X Ã— X âˆ—by âŸ¨Â·, Â·âŸ©. (If X is a Hilbert
space, âŸ¨Â·, Â·âŸ©denotes also its scalar (or inner) product.) The metric distance function
to a set C âŠ‚X is dC : X â†’[0, +âˆ] : y â†’infxâˆˆC âˆ¥x âˆ’yâˆ¥where, by convention,
inf Ã˜ = +âˆ. For every y âˆˆint dom f, we set fy = f âˆ’âˆ‡f(y). The symbols â‡€,
âˆ—â‡€, and â†’denote, respectively, weak, weakâˆ—, and strong convergence. S(xn)nâˆˆN and
W(xn)nâˆˆN are, respectively, the sets of strong and weak cluster points of a sequence
(xn)nâˆˆN in X. bdry C denotes the boundary of a set C âŠ‚X, int C its interior, and
C its closure. The closed ball of center x and radius Ï is denoted by B(x; Ï). The
normalized duality mapping J of X is deï¬ned by
xâˆ—âˆˆX âˆ—| âˆ¥xâˆ¥2 = âŸ¨x, xâˆ—âŸ©= âˆ¥xâˆ—âˆ¥2
RN is the standard N-dimensional Euclidean space.
2.3. Set-valued operators. Let Y be a Banach space and 2Y the family of
all subsets of Y. A set-valued operator from X to Y is an operator A: X â†’2Y.
It is characterized by its graph gr A = {(x, u) âˆˆX Ã— Y | u âˆˆAx}; its domain is
dom A = {x âˆˆX | Ax Ì¸= Ã˜} (with closure dom A); its range is ran A = 
xâˆˆX Ax (with
closure ran A); and, if Y = X, its ï¬xed point set is Fix A = {x âˆˆX | x âˆˆAx} (with
closure Fix A). The graph of the inverse Aâˆ’1 of A is {(u, x) âˆˆY Ã— X | (x, u) âˆˆgr A}.
If B : X â†’2Y and Î± âˆˆR, then gr(Î±A + B) = {(x, Î±u + v) âˆˆX Ã— Y | (x, u) âˆˆ
gr A, (x, v) âˆˆgr B}. As is customary, if x âˆˆdom A and A is single-valued on dom A,
we shall denote the unique element in Ax by Ax. Finally, A is locally bounded at
x âˆˆX if there exists Ï âˆˆ]0, +âˆ[ such that A
is bounded. (We adopt the
same deï¬nition as in [79, section 17]; it diï¬€ers slightly from Phelpsâ€™ deï¬nition [71,
Chap. 2] which requires x âˆˆdom A.)
2.4. Orbits and suborbits of algorithms. In section 4 and subsequent sections, we shall discuss various algorithms. Sequences generated by algorithms are
called orbits, and their subsequences are referred to as suborbits.
2.5. Functions. The domain of a function g: X â†’]âˆ’âˆ, +âˆ] is dom g = {x âˆˆ
X | g(x) < +âˆ} (with closure dom g), and g is proper if dom g Ì¸= Ã˜. Moreover, g is
subdiï¬€erentiable at x âˆˆdom g if its subdiï¬€erential at this point,
xâˆ—âˆˆX âˆ—| (âˆ€y âˆˆX) âŸ¨y âˆ’x, xâˆ—âŸ©+ g(x) â‰¤g(y)
is not empty; a subgradient of g at x is an element of âˆ‚g(x). The domain of continuity
x âˆˆX | |g(x)| < +âˆand g is continuous at x
and its lower level set at height Î· âˆˆR is levâ‰¤Î· g = {x âˆˆX | g(x) â‰¤Î·}. Recall that
the value of gâˆ—, the conjugate of g, at point xâˆ—âˆˆX âˆ—is deï¬ned by
gâˆ—(xâˆ—) = sup
âŸ¨x, xâˆ—âŸ©âˆ’g(x);
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
H. H. BAUSCHKE, J. M. BORWEIN, AND P. L. COMBETTES
g is coï¬nite if dom gâˆ—= X âˆ—. Furthermore, g is coercive if limâˆ¥xâˆ¥â†’+âˆg(x) = +âˆ,
supercoercive if limâˆ¥xâˆ¥â†’+âˆg(x)/âˆ¥xâˆ¥= +âˆ, (weak) lower semicontinuous if its lower
level sets
Î·âˆˆR are (weakly) closed, and (weak) inf-compact if they are (weakly)
compact. If X is reï¬‚exive, the notions of weak inf-compactness and coercivity coincide
for weak lower semicontinuous functions. The set of minimizing sequences of g is
denoted by
(xn)nâˆˆN in dom g | g(xn) â†’inf g(X)
and the set of global minimizers of g by Argmin g. (If it is a singleton, its unique
element is denoted by argmin g.) The inf-convolution of two functions g1, g2 : X â†’
]âˆ’âˆ, +âˆ] is g1 â–¡g2 : X â†’[âˆ’âˆ, +âˆ] : x â†’infyâˆˆX g1(y) + g2(x âˆ’y).
The indicator function of a set C âŠ‚X is the function Î¹C : X â†’{0, +âˆ} that
takes value 0 on C and +âˆon its complement, and its normal cone is
NC = âˆ‚Î¹C : X â†’2X âˆ—: x â†’
xâˆ—âˆˆX âˆ—| (âˆ€y âˆˆC) âŸ¨y âˆ’x, xâˆ—âŸ©â‰¤0
otherwise.
2.6. D-viability and Legendre functions. Operators based on Bregman distances are not deï¬ned outside of int dom f. Thus, using the terminology of , for an
algorithm such as (1.7) to be viable in the sense that its iterates remain in int dom f,
the operators involved must satisfy the following viability condition.
Definition 2.1.
An operator T : X â†’2X is D-viable if ran T âŠ‚dom T =
int dom f.
It was shown in that a suï¬ƒcient condition for Bregman projection operators
onto closed convex sets in Euclidean spaces to be D-viable is that f be a Legendre
function. (In this context, â€œD-viabilityâ€ was called â€œzone consistencyâ€ after .)
The classical ï¬nite-dimensional deï¬nition of a Legendre function, as introduced by
Rockafellar in [77, section 26], is of limited use in general Banach spaces since the
resulting class of functions loses some of its remarkable ï¬nite-dimensional properties.
In the context of Banach spaces, we introduced in the following notion a Legendre
function. It not only generalizes Rockafellarâ€™s classical deï¬nition but also preserves its
salient properties in reï¬‚exive spaces. (For results on Legendre functions in nonreï¬‚exive
spaces, see .)
Definition 2.2 ([8, Def. 5.2]). The function f is
(i) essentially smooth if âˆ‚f is both locally bounded and single-valued on its domain;
(ii) essentially strictly convex if (âˆ‚f)âˆ’1 is locally bounded on its domain and f is
strictly convex on every convex subset of dom âˆ‚f;
(iii) Legendre if it is both essentially smooth and essentially strictly convex.
Such functions will be of prime importance in our analysis as they will be shown to
provide a simple and convenient suï¬ƒcient condition for the D-viability of the operators
commonly encountered in Bregman optimization methods in Banach spaces.
2.7. Basic properties of Bregman distances. The following properties follow
directly from (1.5).
Proposition 2.3. Let {x, y} âŠ‚X and {u, v} âŠ‚int dom f. Then
(i) D(u, v) + D(v, u) = âŸ¨u âˆ’v, âˆ‡f(u) âˆ’âˆ‡f(v)âŸ©;
(ii) D(x, u) = D(x, v) + D(v, u) + âŸ¨x âˆ’v, âˆ‡f(v) âˆ’âˆ‡f(u)âŸ©;
(iii) D(x, v) + D(y, u) = D(x, u) + D(y, v) + âŸ¨x âˆ’y, âˆ‡f(u) âˆ’âˆ‡f(v)âŸ©.
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
Fig. 1. If T âˆˆB, x âˆˆint dom f, and u âˆˆTx, the half-space H(x, u) contains Fix T.
3. Operators associated with Bregman distances. In Hilbert spaces, various nonlinear operators are involved in the design of algorithms, including projection
operators, proximal operators, resolvents, subgradient projection operators, ï¬rmly
nonexpansive operators, and combinations of these. Such operators arise in convex
feasibility problems, in equilibrium theory, in systems of convex inequalities, in variational inequalities, as well as in numerous ï¬xed point problems . Intrinsically tied to the very deï¬nition of these operators is the use of the
standard notion of metric distance to measure the proximity between two points. In
the context of Bregman distances, it is therefore natural to attempt to deï¬ne variants
of these operators. This eï¬€ort has been undertaken by several authors at various levels
of generality. In this section, we systematically study nonlinear operators associated
with Bregman distances in order to bring together and extend a collection of results
disseminated in the literature. Speciï¬cally, we investigate when D-ï¬rm operators,
D-resolvents, D-prox operators, D-projectors, and subgradient D-projectors belong
to class B. (For relationships among these operators in the classical case, i.e., when X
is a Hilbert space and f = âˆ¥Â·âˆ¥2/2, see [9, Prop. 2.3].) Moreover, the class B is shown
to be closed under a certain type of relaxed parallel combination. The discussion is
not limited to convex problems as nonconvex extensions of standard algorithms have
been found to be quite useful in a number of applications; see .
3.1. The class B. Ultimately, our goal is to deï¬ne a class of operators for
which (1.7) systematically generates D-monotone sequences. In this perspective, the
operators employed in (1.7) must be D-viable (see Deï¬nition 2.1) and induce a certain
monotonicity property (see Deï¬nition 1.2). These requirements lead to the following
class of operators (see Figure 1).
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
H. H. BAUSCHKE, J. M. BORWEIN, AND P. L. COMBETTES
Definition 3.1. For every x and u in int dom f, set
y âˆˆX | âŸ¨y âˆ’u, âˆ‡f(x) âˆ’âˆ‡f(u)âŸ©â‰¤0
T : X â†’2X | ran T âŠ‚dom T = int dom f, (âˆ€(x, u) âˆˆgr T) Fix T âŠ‚H(x, u)
If X is Hilbertian, f = âˆ¥Â· âˆ¥2/2, and only single-valued operators are considered,
then B reverts to the class T of operators introduced in and further investigated
in this context in . In these studies, T was shown to play a central role in the
analysis of FejÂ´er monotone algorithms. Because of Proposition 3.3(i) below, there is
some overlap between the â€œparacontractionsâ€ introduced in (see also )
and operators in B.
Furthermore, if f satisï¬es certain conditions and T âˆˆB is
single-valued with Fix T Ì¸= Ã˜, then T is â€œtotally nonexpansiveâ€ in the sense of .
Lemma 3.2. Let C1 and C2 be two convex subsets of X such that C1 is closed
and C1 âˆ©int C2 Ì¸= Ã˜. Then C1 âˆ©int C2 = C1 âˆ©C2.
Proof. Since C2 is convex with nonempty interior, C1 âˆ©int C2 âŠ‚C1 âˆ©int C2 =
To show the reverse inclusion, ï¬x x0 âˆˆC1 âˆ©int C2 and x1 âˆˆC1 âˆ©C2.
By convexity, [x0, x1] âŠ‚C1 and [x0, x1[ âŠ‚int C2.
Therefore, (âˆ€Î± âˆˆ[0, 1[) xÎ± =
(1 âˆ’Î±)x0 + Î±x1 âˆˆC1 âˆ©int C2. Consequently x1 = limÎ±â†‘1âˆ’xÎ± âˆˆC1 âˆ©int C2, and we
conclude C1 âˆ©C2 âŠ‚C1 âˆ©int C2.
Proposition 3.3. Let T be an operator in B and let F = 
(x,u)âˆˆgr T H(x, u).
(i) (âˆ€(x, u) âˆˆgr T)(âˆ€y âˆˆFix T) D(y, u) â‰¤D(y, x) âˆ’D(u, x);
(ii) (âˆ€(x, u) âˆˆgr T) D(u, x) â‰¤DFix T (x);
(iii) (âˆ€(x, u) âˆˆgr T)(âˆ€y âˆˆFix T) D(x, u) + D(u, x) â‰¤âŸ¨y âˆ’x, âˆ‡f(u) âˆ’âˆ‡f(x)âŸ©.
Now suppose that f|int dom f is strictly convex; then
(iv) Fix T = F âˆ©int dom f;
(v) Fix T is convex;
(vi) T is single-valued on Fix T.
If, in addition, Fix T Ì¸= Ã˜, then
(vii) Fix T = F âˆ©dom f;
(viii) (âˆ€(x, u) âˆˆgr T)(âˆ€y âˆˆFix T) D(y, u) â‰¤D(y, x) âˆ’D(u, x).
Proof. (i) Take (x, u) âˆˆgr T and y âˆˆFix T. Then Proposition 2.3(ii) and the
inclusion y âˆˆH(x, u) yield D(y, u) = D(y, x) âˆ’D(u, x) + âŸ¨y âˆ’u, âˆ‡f(x) âˆ’âˆ‡f(u)âŸ©â‰¤
D(y, x) âˆ’D(u, x).
(ii) By (i), (âˆ€(x, u) âˆˆgr T)(âˆ€y âˆˆFix T) D(u, x) â‰¤D(y, x).
(iii) Take (x, u) âˆˆgr T and y âˆˆFix T, and suppose yn â†’y for some sequence (yn)nâˆˆN
in Fix T. Then it follows from Proposition 2.3(i) that
(âˆ€n âˆˆN) D(x, u) + D(u, x) = âŸ¨x âˆ’u, âˆ‡f(x) âˆ’âˆ‡f(u)âŸ©
= âŸ¨x âˆ’yn, âˆ‡f(x) âˆ’âˆ‡f(u)âŸ©+ âŸ¨yn âˆ’u, âˆ‡f(x) âˆ’âˆ‡f(u)âŸ©
â‰¤âŸ¨x âˆ’yn, âˆ‡f(x) âˆ’âˆ‡f(u)âŸ©.
Since âŸ¨x âˆ’yn, âˆ‡f(x) âˆ’âˆ‡f(u)âŸ©â†’âŸ¨x âˆ’y, âˆ‡f(x) âˆ’âˆ‡f(u)âŸ©, the proof is complete.
(iv) Take y âˆˆF âˆ©int dom f. Then y âˆˆ
uâˆˆT y H(y, u) and, in turn,
(âˆ€u âˆˆTy) âŸ¨y âˆ’u, âˆ‡f(y) âˆ’âˆ‡f(u)âŸ©â‰¤0.
However, {y} âˆªTy âŠ‚int dom f and, since f|int dom f is strictly convex, âˆ‡f is strictly
monotone on int dom f. Therefore Ty = {y} and y âˆˆFix T. Thus, F âˆ©int dom f âŠ‚
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
Since T âˆˆB, the reverse inclusion is clear.
(iv) â‡’(v) Since the sets
(x,u)âˆˆgr T and int dom f are convex, so is their intersection Fix T.
was proved in the proof of (iv). (iv) â‡’(vii) Observe that F is closed and apply
Lemma 3.2. (viii) Take (x, u) âˆˆgr T, y0 âˆˆFix T, and y âˆˆFix T. By (iv) and (vii),
Fix T = F âˆ©int dom f and Fix T = F âˆ©dom f.
Since F and dom f are convex,
[y0, y] âŠ‚F and [y0, y[ âŠ‚int dom f. Therefore,
(âˆ€Î± âˆˆ[0, 1[) yÎ± = (1 âˆ’Î±)y0 + Î±y âˆˆFix T.
Invoking the lower semicontinuity and convexity of f, we get
f(y) â‰¤lim Î±â†‘1âˆ’f(yÎ±) â‰¤lim Î±â†‘1âˆ’f(yÎ±) â‰¤lim Î±â†‘1âˆ’(1 âˆ’Î±)f(y0) + Î±f(y) = f(y).
Hence limÎ±â†‘1âˆ’f(yÎ±) = f(y) and, in turn,
(âˆ€z âˆˆint dom f)
Î±â†‘1âˆ’D(yÎ±, z) = D(y, z).
On the other hand, since u âˆˆTx and T âˆˆB, (3.4) and (i) yield
(âˆ€Î± âˆˆ[0, 1[) D(yÎ±, u) â‰¤D(yÎ±, x) âˆ’D(u, x).
Consequently, D(y, u) â‰¤D(y, x) âˆ’D(u, x).
3.2. D-ï¬rm operators. An operator T : X â†’X is said to be ï¬rmly nonexpansive if for all x and y in dom T one has 
(âˆ€Î± âˆˆ]0, +âˆ[) âˆ¥Tx âˆ’Tyâˆ¥â‰¤âˆ¥Î±(x âˆ’y) + (1 âˆ’Î±)(Tx âˆ’Ty)âˆ¥.
For the sake of notational simplicity, let us now suppose that X is smooth. Then its
normalized duality map J is single-valued and, upon invoking the equivalence (âˆ€Î± âˆˆ
]0, +âˆ[) âˆ¥uâˆ¥â‰¤âˆ¥u + Î±vâˆ¥â‡”0 â‰¤âŸ¨v, JuâŸ© , we observe that (3.8) is equivalent to
âŸ¨Tx âˆ’Ty, J(Tx âˆ’Ty)âŸ©â‰¤âŸ¨x âˆ’y, J(Tx âˆ’Ty)âŸ©.
If X is not a Hilbert space, then J is not linear and this type of inequality may be
diï¬ƒcult to manipulate. In Hilbert spaces, J = Id = âˆ‡f for f = âˆ¥Â· âˆ¥2/2, and (3.9)
can therefore be written
âŸ¨Tx âˆ’Ty, âˆ‡f(Tx) âˆ’âˆ‡f(Ty)âŸ©â‰¤âŸ¨Tx âˆ’Ty, âˆ‡f(x) âˆ’âˆ‡f(y)âŸ©.
In the framework of Bregman distances, this inequality suggests the following deï¬nition.
Definition 3.4. An operator T : X â†’2X with dom T âˆªran T âŠ‚int dom f is
(âˆ€(x, u) âˆˆgr T)(âˆ€(y, v) âˆˆgr T) âŸ¨u âˆ’v, âˆ‡f(u) âˆ’âˆ‡f(v)âŸ©â‰¤âŸ¨u âˆ’v, âˆ‡f(x) âˆ’âˆ‡f(y)âŸ©.
Proposition 3.5. Let T : X â†’2X be a D-ï¬rm operator. Then
(i) (âˆ€(x, u) âˆˆgr T) Fix T âŠ‚H(x, u);
(ii) T âˆˆB if int dom f = dom T;
(iii) T is single-valued on its domain if f|int dom f is strictly convex;
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
H. H. BAUSCHKE, J. M. BORWEIN, AND P. L. COMBETTES
(iv) (âˆ€(x, u) âˆˆgr T)(âˆ€(y, v) âˆˆgr T)
D(u, v) + D(v, u) â‰¤D(u, y) + D(v, x) âˆ’
D(u, x) âˆ’D(v, y).
Proof. (i) Suppose y âˆˆTy. Then (3.11) implies that
(âˆ€(x, u) âˆˆgr T) âŸ¨y âˆ’u, âˆ‡f(x) âˆ’âˆ‡f(u)âŸ©â‰¤0.
(i) â‡’(ii) is clear. (iii) Fix x âˆˆdom T and {u, v} âŠ‚Tx. Then (3.11) implies that
âŸ¨u âˆ’v, âˆ‡f(u) âˆ’âˆ‡f(v)âŸ©â‰¤0.
Since âˆ‡f is strictly monotone on int dom f âŠƒ{u, v}, we obtain u = v. (iv) follows
from Proposition 2.3(i), (3.11), and Proposition 2.3(iii).
Remark 3.6. For single-valued operators in Hilbert spaces and f strongly convex
(i.e., f âˆ’Î²âˆ¥Â· âˆ¥2/2 is convex for some Î² âˆˆ]0, +âˆ[), item (iv) above was used to deï¬ne
D-ï¬rmness in .
3.3. D-resolvents. The resolvent of an operator A: X â†’2X is (Id +A)âˆ’1. It
is known that an operator T : X â†’X is ï¬rmly nonexpansive if and only if it is the
resolvent of an accretive operator A: X â†’2X .
Now let A: X â†’2X âˆ—be a nontrivial operator, i.e., gr A Ì¸= Ã˜.
Then, in the
context of Bregman distances, it is reasonable to introduce the following variant of
the notion of a resolvent to obtain an operator from X to X (this deï¬nition appears
to have ï¬rst been proposed in RN in ).
Definition 3.7. The D-resolvent associated with A: X â†’2X âˆ—is the operator
RA = (âˆ‡f + A)âˆ’1 â—¦âˆ‡f : X â†’2X .
An a posteriori motivation for (3.14) is that it preserves the usual ï¬xed point
characterization of the zeros of A, namely,
(âˆ€x âˆˆX)(âˆ€Î³ âˆˆ]0, +âˆ[)
x âˆˆFix RÎ³A,
as 0 âˆˆAx â‡”âˆ‡f(x) âˆˆâˆ‡f(x)+Î³A(x) = (âˆ‡f+Î³A)(x) â‡”x âˆˆ(âˆ‡f+Î³A)âˆ’1 
is also consistent with previous attempts to deï¬ne resolvents for monotone operators:
â€¢ Let X be smooth and set f = âˆ¥Â·âˆ¥2/2. Then âˆ‡f = J and RA = (J +A)âˆ’1 â—¦J.
This type of resolvent was used in .
â€¢ If X is Hilbertian and f : x â†’âˆ¥Î xâˆ¥2/2, where Î  is the metric projector onto
a closed vector subspace of X, then âˆ‡f = Î  and RA = (Î  + A)âˆ’1 â—¦Î . This
generalized resolvent was used in .
Proposition 3.8. RA satisï¬es the following properties:
(i) dom RA âŠ‚int dom f.
(ii) ran RA âŠ‚int dom f.
(iii) Fix RA = (int dom f) âˆ©Aâˆ’10.
(iv) Suppose A is monotone. Then the following conditions hold:
(a) RA is D-ï¬rm.
(b) RA is single-valued on its domain if f|int dom f is strictly convex.
(c) Suppose ran âˆ‡f âŠ‚ran(âˆ‡f + A).
Then RA âˆˆB.
If, in addition,
f|int dom f is strictly convex, then Fix RA is convex.
Proof. (i) is clear. (ii) We have
ran RA âŠ‚ran(âˆ‡f + A)âˆ’1 = dom(âˆ‡f + A) = dom âˆ‡f âˆ©dom A âŠ‚dom âˆ‡f
= int dom f.
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
(iii) Fix RA âŠ‚int dom f by (i) and (âˆ€x âˆˆint dom f) 0 âˆˆAx â‡”x âˆˆRAx by (3.15).
Hence, Aâˆ’10 âˆ©int dom f = Fix RA âˆ©int dom f = Fix RA. (iv) Suppose that A is
monotone. (a) In view of (i) and (ii), let us show that (3.11) is satisï¬ed. Fix (x, u) and
(y, v) in gr RA. Then âˆ‡f(x) âˆ’âˆ‡f(u) âˆˆAu and âˆ‡f(y) âˆ’âˆ‡f(v) âˆˆAv. Consequently,
since A is monotone, we get âŸ¨uâˆ’v, âˆ‡f(x)âˆ’âˆ‡f(u)âˆ’(âˆ‡f(y)âˆ’âˆ‡f(v))âŸ©â‰¥0. (b) follows
from (a) and Proposition 3.5(iii). (c) ran âˆ‡f âŠ‚ran(âˆ‡f + A) â‡”ran âˆ‡f âŠ‚dom(âˆ‡f +
A)âˆ’1 â‡”dom RA = dom âˆ‡f = int dom f.
In view of (a) and Proposition 3.5(ii),
RA âˆˆB. Proposition 3.3(v) implies the convexity of Fix RA.
Definition 3.9 (see [86, sections 32.14 and 32.21]). A is
(i) weakly coercive if limâˆ¥xâˆ¥â†’+âˆinf âˆ¥Axâˆ¥= +âˆ;
(ii) strongly coercive if
(âˆ€x âˆˆdom A)
âˆ¥yâˆ¥â†’+âˆinf âŸ¨y âˆ’x, AxâŸ©
(iii) 3-monotone if
(x, xâˆ—), (y, yâˆ—), (z, zâˆ—)
âŸ¨x âˆ’y, xâˆ—âŸ©+ âŸ¨y âˆ’z, yâˆ—âŸ©+ âŸ¨z âˆ’x, zâˆ—âŸ©â‰¥0;
(iv) 3âˆ—-monotone if it is monotone and
(âˆ€(x, xâˆ—) âˆˆdom A Ã— ran A) sup
âŸ¨x âˆ’y, yâˆ—âˆ’xâˆ—âŸ©| (y, yâˆ—) âˆˆgr A
Lemma 3.10 (see [86, section 32.21], ). Suppose that X is reï¬‚exive and that
A is monotone and satisï¬es one of the following properties:
(i) A is 3-monotone.
(ii) A is strongly coercive.
(iii) ran A is bounded.
(iv) A = âˆ‚Ï•, where Ï•: X â†’]âˆ’âˆ, +âˆ] is a proper function.
Then A is 3âˆ—-monotone.
The following lemma is Reichâ€™s extension to a reï¬‚exive Banach space setting of
the BrÂ´ezisâ€“Haraux theorem on the range of the sum of two monotone operators.
Lemma 3.11 (see [74, Thm. 2.2]). Suppose that X is reï¬‚exive and let A1, A2 : X â†’
2X âˆ—be two monotone operators such that A1 + A2 is maximal monotone and A1 is
3âˆ—-monotone. In addition, suppose that dom A2 âŠ‚dom A1 or A2 is 3âˆ—-monotone.
Then int ran(A1 + A2) = int(ran A1 + ran A2) and ran (A1 + A2) = ran A1 + ran A2.
Proposition 3.12. Let Î³ âˆˆ]0, +âˆ[. Suppose that X is reï¬‚exive and that A is
maximal monotone with (int dom f) âˆ©dom A = dom âˆ‚f âˆ©dom A Ì¸= Ã˜. Then âˆ‡f + Î³A
is maximal monotone. Moreover, the inclusions
int(ran âˆ‡f + Î³ ran A) âŠ‚ran(âˆ‡f + Î³A)
ran âˆ‡f + Î³ ran A âŠ‚ran (âˆ‡f + Î³A)
are satisï¬ed if one of the following conditions holds:
(i) dom A âŠ‚int dom f.
(ii) A is 3âˆ—-monotone.
Proof. Since f is proper, lower semicontinuous, and convex, âˆ‚f is maximal monotone [79, Thm. 30.3] and int dom f = cont f âŠ‚dom âˆ‚f âŠ‚dom f [48, Chap. I]. Since
(int dom f) âˆ©dom A = dom âˆ‚f âˆ©dom A Ì¸= Ã˜, we have (int dom âˆ‚f) âˆ©dom Î³A =
(int dom f) âˆ©dom A Ì¸= Ã˜, and it follows from Rockafellarâ€™s sum theorem [79, section 23] that âˆ‚f + Î³A is maximal monotone. However, the above assumption implies
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
H. H. BAUSCHKE, J. M. BORWEIN, AND P. L. COMBETTES
that dom(âˆ‡f + Î³A) = dom(âˆ‚f + Î³A) and, in turn, that âˆ‡f + Î³A = âˆ‚f + Î³A
since {âˆ‡f} = âˆ‚f|int dom f. Thus, âˆ‡f + Î³A is maximal monotone. The second assertion is an application of Lemma 3.11 with A1 = âˆ‡f and A2 = Î³A.
dom âˆ‡f = int dom f and, by Lemma 3.10(iv), âˆ‚f is 3âˆ—-monotone and so is, therefore,
âˆ‡f since gr âˆ‡f âŠ‚gr âˆ‚f.
Theorem 3.13. Let Î³ âˆˆ]0, +âˆ[. Suppose that X is reï¬‚exive, that A is maximal
monotone with (int dom f) âˆ©dom A = dom âˆ‚f âˆ©dom A Ì¸= Ã˜, and that one of the
following conditions holds:
(i) X is smooth and f = âˆ¥Â· âˆ¥2/2.
(ii) (âˆ‡f + Î³A)âˆ’1 is locally bounded at every point in X âˆ—.
(iii) âˆ‡f + Î³A is weakly coercive.
(iv) dom A âŠ‚int dom f or A is 3âˆ—-monotone, and one of the following conditions
(a) ran âˆ‡f + Î³ ran A = X âˆ—.
(b) f is Legendre and coï¬nite.
(c) ran(âˆ‡f + Î³A) is closed and 0 âˆˆran A.
(d) ran âˆ‡f is open and 0 âˆˆran A.
Then RÎ³A âˆˆB.
In view of Proposition 3.8(iv)(c), it suï¬ƒces to show that ran âˆ‡f âŠ‚
ran(âˆ‡f + Î³A). (i) Since X is smooth, âˆ‡f = J [34, Corollary I.4.5] and Rockafellarâ€™s surjectivity theorem [79, Thm. 10.7] yields ran(âˆ‡f + Î³A) = X âˆ—. (ii) Proposition 3.12 asserts that âˆ‡f + Î³A is maximal monotone.
It therefore follows from
the BrÂ´ezisâ€“Browder surjectivity theorem (see [34, Thm. V.3.8] or [86, Thm. 32.G])
that ran(âˆ‡f + Î³A) = X âˆ—. (iii) â‡’(ii) follows from [86, Cor. 32.35] since âˆ‡f + Î³A
is maximal monotone. (iv) By Proposition 3.12, (3.17) holds. (a) By (3.17), X âˆ—=
int(ran âˆ‡f + Î³ ran A) âŠ‚ran(âˆ‡f + Î³A). (b) â‡’(a) By [8, Thm. 5.10], Legendreness
guarantees ran âˆ‡f = int dom f âˆ—while coï¬niteness gives int dom f âˆ—= X âˆ—. Consequently, ran âˆ‡f + Î³ ran A = X âˆ—. (c) By (3.17), ran âˆ‡f = ran âˆ‡f + {0} âŠ‚ran âˆ‡f +
Î³ ran A âŠ‚ran (âˆ‡f+Î³A) = ran(âˆ‡f+Î³A). (d) By (3.17), ran âˆ‡f = int(ran âˆ‡f+{0}) âŠ‚
int(ran âˆ‡f + Î³ ran A) âŠ‚ran(âˆ‡f + Î³A).
In connection with the problem of ï¬nding zeros of maximal monotone operators,
the following corollary is particularly useful.
Corollary 3.14.
Let Î³ âˆˆ]0, +âˆ[.
Suppose that X is reï¬‚exive, that A is
maximal monotone with 0 âˆˆran A, and that one of the following conditions holds:
(i) ran âˆ‡f is open and dom A âŠ‚int dom f.
(ii) f is Legendre and dom A âŠ‚int dom f.
(iii) f is Legendre, A is 3âˆ—-monotone, and dom A âˆ©int dom f Ì¸= Ã˜.
Then RÎ³A âˆˆB.
Proof. The assertions follow from Theorem 3.13(iv)(d). Indeed, in (i), dom A âŠ‚
int dom f = cont f âŠ‚dom âˆ‚f â‡’(int dom f) âˆ©dom A = dom âˆ‚f âˆ©dom A = dom A Ì¸=
Ã˜. On the other hand, in (ii) and (iii), ran âˆ‡f is open since Legendreness yields
ran âˆ‡f = int dom f âˆ—[8, Thm. 5.10]. Consequently, if dom A âŠ‚int dom f, then (ii) is a
consequence of (i). Otherwise, if A is 3âˆ—-monotone and (int dom f)âˆ©dom A Ì¸= Ã˜, then
it suï¬ƒces to note that essential smoothness yields dom âˆ‚f = int dom f [8, Thm. 5.6],
whence (int dom f) âˆ©dom A = dom âˆ‚f âˆ©dom A Ì¸= Ã˜.
Remark 3.15. In RN, Corollary 3.14(i) corresponds to [46, Thm. 4].
3.4. D-prox operators. The classical notion of a proximal operator was introduced by Moreau in Hilbert spaces. The proximal operator associated
with a function Ï•: X â†’]âˆ’âˆ, +âˆ] is proxÏ• : y â†’argmin Ï• + âˆ¥Â· âˆ’yâˆ¥2/2. Outside of
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
Hilbert spaces, this notion is of less interest since Fermatâ€™s rule for the minimization
of Ï• + âˆ¥Â· âˆ’yâˆ¥2/2 becomes a nonseparable inclusion, namely, 0 âˆˆâˆ‚Ï•(x) + J(x âˆ’y).
In RN, the idea of deï¬ning proximal operators based on D-distanceâ€”rather than
quadraticâ€”penalizations was introduced in . In our setting, they will be deï¬ned
as follows.
Definition 3.16. Let Ï•: X â†’]âˆ’âˆ, +âˆ]. The D-prox operator of index Î³ âˆˆ
]0, +âˆ[ associated with Ï• is the operator
Î³ : X â†’2X ,
x âˆˆdom f âˆ©dom Ï• | Ï•(x) + 1
Î³ D(x, y) = min
It follows from this deï¬nition that
Î³ âŠ‚int dom f
Î³ âŠ‚dom f âˆ©dom Ï•.
Recall (see section 2.5) that a function is weak inf-compact if all its lower level
sets are weakly compact.
Lemma 3.17. Suppose that g1 : X â†’]âˆ’âˆ, +âˆ] is weak lower semicontinuous
and bounded from below and that g2 : X â†’]âˆ’âˆ, +âˆ] is weak inf-compact. Then
g1 + g2 is weak inf-compact.
Proof. Set Î² = inf g1(X) and let Î· âˆˆR. Since g1 and g2 are weak lower semicontinuous, so is their sum, and therefore levâ‰¤Î· (g1 + g2) is weakly closed. On the other
hand, levâ‰¤Î· (g1 +g2) is contained in the weakly compact set levâ‰¤Î·âˆ’Î² g2. We conclude
that levâ‰¤Î· (g1 + g2) is weakly compact.
The following result concerns the domain requirement for the D-viability of Dprox operators. Recall (see sections 2.5 and 2.2) that M denotes the set of minimizing
sequences of a function and that W is the set of weak cluster points of a sequence.
Theorem 3.18. Let Î³ âˆˆ]0, +âˆ[, let Ï•: X â†’]âˆ’âˆ, +âˆ] be such that dom f âˆ©
dom Ï• Ì¸= Ã˜, and assume that one of the following conditions holds:
(i) (âˆ€y âˆˆint dom f)(âˆƒ(xn)nâˆˆN âˆˆM(fy + Î³Ï•))(âˆƒx âˆˆW(xn)nâˆˆN) f + Î³Ï• is weak
lower semicontinuous at x.
(ii) (âˆ€y âˆˆint dom f) fy + Î³Ï• is weak inf-compact.
(iii) Ï• is weak lower semicontinuous and bounded from below, and, for every y âˆˆ
int dom f, fy is weak inf-compact.
(iv) Ï• is weak inf-compact.
Then dom proxÏ•
Î³ = int dom f.
Proof. Fix y âˆˆint dom f and set g = fy + Î³Ï•. (i) Pick (xn)nâˆˆN âˆˆM(g) such that
xkn â‡€x and g is weak lower semicontinuous at x. It follows that g(x) â‰¤lim g(xkn) =
inf g(X) and hence g(x) = inf g(X). Therefore, g achieves its inï¬mum and the result
holds since proxÏ•
Î³ y = Argmin(fy+Î³Ï•) = Argmin(g). (ii) â‡’(i) Take (xn)nâˆˆN âˆˆM(g).
Then it follows from weak inf-compactness of g that (xn)nâˆˆN lies in a weakly compact
set and therefore that W(xn)nâˆˆN Ì¸= Ã˜. On the other hand, as g is weak inf-compact,
it is weak lower semicontinuous and so is f + Î³Ï• = fy + Î³Ï• + âˆ‡f(y) = g + âˆ‡f(y).
(iii) â‡’(ii) follows from Lemma 3.17. (iv) â‡’(ii) It is clear that fy is weak lower
semicontinuous.
On the other hand, it follows from the convexity of f that, for
every x âˆˆX, âŸ¨x âˆ’y, âˆ‡f(y)âŸ©+ f(y) â‰¤f(x) and, therefore, fy(x) â‰¥fy(y). Hence
inf fy(X) â‰¥fy(y) > âˆ’âˆand, by Lemma 3.17, g is weak inf-compact.
The following fundamental result is due to Moreau and Rockafellar .
Lemma 3.19. Let yâˆ—âˆˆX âˆ—. Then fâˆ’yâˆ—is coercive if and only if yâˆ—âˆˆint dom f âˆ—.
Lemma 3.20. Let g1, g2 : X â†’]âˆ’âˆ, +âˆ] be two convex functions. Then
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
H. H. BAUSCHKE, J. M. BORWEIN, AND P. L. COMBETTES
(i) if g1 and g2 are lower semicontinuous and 0 âˆˆint
dom g1 âˆ’dom g2
(g1 + g2)âˆ—= gâˆ—
(ii) if cont g1 âˆ©dom g2 Ì¸= Ã˜, then âˆ‚(g1 + g2) = âˆ‚g1 + âˆ‚g2 [79, Thm. 28.2].
Proposition 3.21. Let Ï•: X â†’]âˆ’âˆ, +âˆ] be a lower semicontinuous convex
function such that dom f âˆ©dom Ï• Ì¸= Ã˜ and let Î³ âˆˆ]0, +âˆ[. Suppose that X is reï¬‚exive
and that one of the following conditions holds:
(i) (âˆ€y âˆˆint dom f)(âˆƒ(xn)nâˆˆN âˆˆM(fy + Î³Ï•)) supnâˆˆN âˆ¥xnâˆ¥< +âˆ.
(ii) (âˆ€y âˆˆint dom f) fy + Î³Ï• is coercive.
(iii) ran âˆ‡f âŠ‚int dom (f + Î³Ï•)âˆ—.
(iv) f + Î³Ï• is coï¬nite.
(v) 0 âˆˆint(dom f âˆ’dom Ï•) and dom f âˆ—+ Î³ dom Ï•âˆ—= X âˆ—.
(vi) Ï• is bounded from below and f is essentially strictly convex.
(vii) f + Î³Ï• is supercoercive.
(viii) Ï• is bounded from below and f is supercoercive.
(ix) Ï• is coercive.
Then dom proxÏ•
Î³ = int dom f.
Proof. Let y be an arbitrary point in int dom f. Note that, since Ï• is weak lower
semicontinuous, so are f + Î³Ï• and fy + Î³Ï• and that, since X is reï¬‚exive, coercive
weak lower semicontinuous functions are weak inf-compact. (i) is a consequence of
Theorem 3.18(i). Indeed, take a bounded sequence (xn)nâˆˆN âˆˆM(fy + Î³Ï•). Then
it follows from the reï¬‚exivity of X that W(xn)nâˆˆN Ì¸= Ã˜. (ii) follows at once from
Theorem 3.18(ii). (iii) â‡”(ii) âˆ‡f(y) âˆˆint dom (f +Î³Ï•)âˆ—â‡”f +Î³Ï•âˆ’âˆ‡f(y) is coercive
by Lemma 3.19. (iv) â‡’(iii) is clear. (v) â‡’(iv) Lemma 3.20(i) yields
dom f âˆ—+ Î³ dom Ï•âˆ—= dom f âˆ—+ dom Î³Ï•âˆ—(Â·/Î³) = dom f âˆ—+ dom(Î³Ï•)âˆ—
f âˆ—â–¡(Î³Ï•)âˆ—
0 âˆˆint(dom f âˆ’dom Ï•)
f âˆ—â–¡(Î³Ï•)âˆ—= (f + Î³Ï•)âˆ—.
Hence dom f âˆ—+ Î³ dom Ï•âˆ—= X âˆ—â‡’dom(f + Î³Ï•)âˆ—= X âˆ—. (vi) is a consequence of
Theorem 3.18(iii): indeed, by [8, Thm. 5.9(ii)], âˆ‡f(y) âˆˆint dom f âˆ—and fy is therefore
coercive by Lemma 3.19. (vii) â‡’(iv) See [8, Thm. 3.4]. (viii) â‡’(vii) is clear. (ix) is
a consequence of Theorem 3.18(iv).
The next result gathers some facts concerning D-prox operators for convex functions.
Proposition 3.22. Let Ï•: X â†’]âˆ’âˆ, +âˆ] be convex and let Î³ âˆˆ]0, +âˆ[. Then
the following hold:
(ii) If, in addition, ran proxÏ•
Î³ âŠ‚int dom f, then
(b) Fix proxÏ•
Î³ = (int dom f) âˆ©Argmin Ï•;
Î³ is D-ï¬rm;
Î³ is single-valued on its domain if f|int dom f is strictly convex.
Proof. Fix y âˆˆint dom f. (i) By (3.18), ran proxÏ•
Î³ âŠ‚dom f âˆ©dom Ï•. If dom f âˆ©
dom Ï• = Ã˜, both sides of the desired identity reduce to the trivial operator z â†’
Ã˜. If not, take x âˆˆdom f âˆ©dom Ï•. Since cont âˆ‡f(y) = X, Lemma 3.20(ii) yields
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
âˆ‚(fy + Î³Ï•)(x) = âˆ‚(f + Î³Ï•)(x) âˆ’âˆ‡f(y). Consequently,
Î³ y â‡”0 âˆˆâˆ‚(fy + Î³Ï•)(x)
â‡”âˆ‡f(y) âˆˆâˆ‚(f + Î³Ï•)(x)
(ii) Suppose ran proxÏ•
Î³ âŠ‚int dom f. (a) On the one hand, it follows from (3.18) that
Î³ âŠ‚(int dom f) âˆ©dom Ï•. On the other hand, ran RÎ³âˆ‚Ï• âŠ‚dom(âˆ‡f + Î³âˆ‚Ï•) âŠ‚
(int dom f) âˆ©dom Ï•. Therefore, if (int dom f) âˆ©dom Ï• = Ã˜, both sides of the desired
identity reduce to the trivial operator z â†’Ã˜. If not, take x âˆˆ(int dom f) âˆ©dom Ï• =
cont f âˆ©dom Ï•. Lemma 3.20(ii) now yields âˆ‚(f +Î³Ï•)(x) = âˆ‡f(x)+Î³âˆ‚Ï•(x) and (3.21)
Î³ y â‡”âˆ‡f(y) âˆˆâˆ‡f(x) + Î³âˆ‚Ï•(x) â‡”x âˆˆRÎ³âˆ‚Ï•y.
(a) â‡’(b) follows from Proposition 3.8(iii). (a) â‡’(c) Since âˆ‚Ï• is monotone, RÎ³âˆ‚Ï• is
D-ï¬rm by Proposition 3.8(iv)(a). (a) â‡’(d) follows from Proposition 3.8(iv)(b).
We now turn our attention to the range requirement for the D-viability of D-prox
operators.
Proposition 3.23. Let Ï•: X â†’]âˆ’âˆ, +âˆ] be convex such that dom f âˆ©dom Ï• Ì¸=
Ã˜, and let Î³ âˆˆ]0, +âˆ[. Assume that one of the following conditions holds:
(i) dom âˆ‚(f + Î³Ï•) âŠ‚int dom f.
(ii) dom f âˆ©dom Ï• âŠ‚int dom f.
(iii) dom f is open.
(iv) dom Ï• âŠ‚int dom f.
(v) (int dom f) âˆ©dom Ï• Ì¸= Ã˜ and one of the following conditions holds:
(a) dom âˆ‚f âˆ©dom âˆ‚Ï• âŠ‚int dom f.
(b) f is essentially smooth.
(c) dom âˆ‚Ï• âŠ‚int dom f.
Then ran proxÏ•
Î³ âŠ‚int dom f.
Proof. (i) By Proposition 3.22(i),
âˆ’1 = dom âˆ‚(f + Î³Ï•) âŠ‚int dom f.
(ii) â‡’(i) dom âˆ‚(f + Î³Ï•) âŠ‚dom(f + Î³Ï•) = dom f âˆ©dom Ï• âŠ‚int dom f. (iii) â‡’(ii)
and (iv) â‡’(ii) are clear. (v) â‡’(i) It results from Lemma 3.20(ii) that âˆ‚(f + Î³Ï•) =
âˆ‚f +Î³âˆ‚Ï•. Whence, (a) â‡’(i). (b) â‡’(a) Essential smoothness â‡’dom âˆ‚f = int dom f
[8, Thm. 5.6(iii)]. (c) â‡’(a) is clear.
Upon combining Propositions 3.23, 3.22(ii)(c), 3.21, and 3.5(ii), we obtain the
following theorem.
Theorem 3.24. Let Ï•: X â†’]âˆ’âˆ, +âˆ] be a lower semicontinuous convex function such that dom f âˆ©dom Ï• Ì¸= Ã˜, and let Î³ âˆˆ]0, +âˆ[. Suppose that X is reï¬‚exive
and that one of conditions (i)â€“(ix) in Proposition 3.21 holds together with one of
conditions (i)â€“(v) in Proposition 3.23. Then proxÏ•
The following special case underscores the importance of the notion of Legendreness.
Corollary 3.25.
Let Ï•: X â†’]âˆ’âˆ, +âˆ] be a lower semicontinuous convex
function such that (int dom f) âˆ©dom Ï• Ì¸= Ã˜, and let Î³ âˆˆ]0, +âˆ[. Suppose that X is
reï¬‚exive, that f is Legendre, and that Ï• is bounded below. Then
Î³ is single-valued on its domain and proxÏ•
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
H. H. BAUSCHKE, J. M. BORWEIN, AND P. L. COMBETTES
(ii) for every x and y in int dom f,
Î³ y â‡”(âˆ€z âˆˆdom Ï•) âŸ¨z âˆ’x, âˆ‡f(y) âˆ’âˆ‡f(x)âŸ©/Î³ + Ï•(x) â‰¤Ï•(z).
Proof. (i) Combine Propositions 3.23(v)(b), 3.22(ii)(c) and (d), 3.21(vi), and 3.5(ii).
(ii) By (3.22), x = proxÏ•
Î³ y â‡”âˆ‡f(y) âˆ’âˆ‡f(x) âˆˆÎ³âˆ‚Ï•(x).
Remark 3.26. A special case of Theorem 3.18(iii) in RN can be found in [32,
Prop. 3.1].
In RN, assertions (iv) and (v)(b) of Proposition 3.23 appear in [58,
Lemma 3.3]. In the case when X is Hilbertian and f = âˆ¥Â· âˆ¥2/2, the characterization
supplied by Corollary 3.25(ii) is well known; see, e.g., [48, section II.2].
3.5. D-projections. The following concept goes back to Bregmanâ€™s original
paper .
Definition 3.27. The D-projector onto a set C âŠ‚X is the operator
PC : X â†’2X ,
x âˆˆC âˆ©dom f | D(x, y) = DC(y) < +âˆ
It is clear that, for any Î³ âˆˆ]0, +âˆ[, PC = proxÎ¹C
Î³ . Hence, the results of section 3.4
will automatically yield results on D-projections when specialized to Ï• = Î¹C. Before
we proceed in this direction, let us introduce a couple of deï¬nitions, which are natural
adaptations of standard ones in metric approximation theory .
Definition 3.28.
A set C âŠ‚X is D-proximinal if dom PC = int dom f and
D-semi-Chebyshev if PC is single-valued on its domain. C is D-Chebyshev if it is
D-proximinal and D-semi-Chebyshev.
Definition 3.29. A set C âŠ‚X is D-approximately weakly compact if
(âˆ€y âˆˆint dom f)(âˆ€(xn)nâˆˆN in C âˆ©dom f) D(xn, y) â†’DC(y) â‡’W(xn)nâˆˆN âˆ©C Ì¸= Ã˜.
Theorem 3.30. Let C be a subset of X such that C âˆ©dom f Ì¸= Ã˜ and assume
that one of the following conditions holds:
(i) C is D-approximately weakly compact.
(ii) (âˆ€y âˆˆint dom f)(âˆƒÎ· âˆˆR) C âˆ©levâ‰¤Î· fy is nonempty and weakly compact.
(iii) C is weakly closed and, for every y âˆˆint dom f, fy is weak inf-compact.
(iv) C is weakly compact.
Then C is D-proximinal.
Proof. (i) Since f is weak lower semicontinuous, f + Î¹C is weak lower semicontinuous at every point in C.
Now ï¬x y âˆˆint dom f and (xn)nâˆˆN âˆˆM(fy + Î¹C).
Then D(xn, y) â†’DC(y) and Deï¬nition 3.29 yields W(xn)nâˆˆN âˆ©C Ì¸= Ã˜. Now take
x âˆˆW(xn)nâˆˆN âˆ©C. Since f + Î¹C is weak lower semicontinuous at x, the claims follow
from Theorem 3.18(i) with Ï• = Î¹C. (ii) Fix y âˆˆint dom f. As minimizing D(Â·, y) over
C is equivalent to minimizing the weak lower semicontinuous function fy over the
weakly compact set C âˆ©levâ‰¤Î· fy, the result follows. Assertions (iii) and (iv) follow,
respectively, from assertions (iii) and (iv) in Theorem 3.18 with Ï• = Î¹C.
Upon setting Ï• = Î¹C, Proposition 3.21 becomes the following.
Proposition 3.31.
Let C be a closed and convex subset of X such that C âˆ©
dom f Ì¸= Ã˜.
Suppose that X is reï¬‚exive and that one of the following conditions
(i) (âˆ€y âˆˆint dom f)(âˆ€(xn)nâˆˆN âˆˆM(fy + Î¹C)) supnâˆˆN âˆ¥xnâˆ¥< +âˆ.
(ii) (âˆ€y âˆˆint dom f) fy + Î¹C is coercive.
(iii) ran âˆ‡f âŠ‚int dom (f + Î¹C)âˆ—.
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
(iv) f + Î¹C is coï¬nite.
(v) 0 âˆˆint(dom f âˆ’C) and dom f âˆ—+ dom Î¹âˆ—
(vi) f is essentially strictly convex.
(vii) f + Î¹C is supercoercive.
(viii) f is supercoercive.
(ix) C is bounded.
Then C is D-proximinal.
Likewise, Proposition 3.22 with Ï• = Î¹C yields the following.
Proposition 3.32. Let C be a convex subset of X. Then the following hold:
(ii) If, in addition, ran PC âŠ‚int dom f, then
(a) PC = RNC.
(b) Fix PC = C âˆ©int dom f.
(c) PC is D-ï¬rm.
(d) C is D-semi-Chebyshev if f|int dom f is strictly convex.
The D-viability requirements for the range of PC are obtained by setting Ï• = Î¹C
in Proposition 3.23.
Proposition 3.33. Let C âŠ‚X be convex such that C âˆ©dom f Ì¸= Ã˜. Assume
that one of the following conditions holds:
(i) dom âˆ‚(f + Î¹C) âŠ‚int dom f.
(ii) C âˆ©dom f âŠ‚int dom f.
(iii) dom f is open.
(iv) C âŠ‚int dom f.
(v) C âˆ©int dom f Ì¸= Ã˜ and one of the following conditions holds:
(a) C âˆ©dom âˆ‚f âŠ‚int dom f;
(b) f is essentially smooth.
Then ran PC âŠ‚int dom f.
Theorem 3.34. Let C âŠ‚X be a closed convex set such that C âˆ©dom f Ì¸= Ã˜.
Suppose that X is reï¬‚exive and that one of conditions (i)â€“(ix) in Proposition 3.31
holds together with one of conditions (i)â€“(v) in Proposition 3.33. Then PC âˆˆB.
Since Proposition 3.31 parallels Proposition 3.21 and Proposition 3.33
parallels Proposition 3.23, it suï¬ƒces to set Ï• = Î¹C in Theorem 3.24.
We conclude this section with the following result.
Corollary 3.35. Suppose that X is reï¬‚exive, that f is Legendre, and that C is
a closed convex subset of X such that C âˆ©int dom f Ì¸= Ã˜. Then
(i) C is D-Chebyshev and PC âˆˆB;
(ii) for every x and y in int dom f,
C âŠ‚H(y, x).
Proof. Take Ï• = Î¹C in Corollary 3.25.
Remark 3.36. Proposition 3.31(vii)â€“(ix) can be found in [1, Prop. 2.1]. Corollary 3.35(i) covers [8, Cor. 7.9] (see also [7, section 3] in the special case of Euclidean spaces), which was obtained via diï¬€erent arguments. If X is Hilbertian and
f = âˆ¥Â· âˆ¥2/2, Corollary 3.35(ii) reduces to the classical characterization of metric
projections onto closed convex sets.
3.6. Subgradient D-projections. The D-projection onto a closed convex set
may be hard to compute. If the set is speciï¬ed as a lower level set, it can be approximated by the D-projection onto a separating hyperplane, which is much easier
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
H. H. BAUSCHKE, J. M. BORWEIN, AND P. L. COMBETTES
to compute. In the traditional case when X is Hilbertian and f = âˆ¥Â· âˆ¥2/2, this is
a standard approach which goes back to (see also ). In the context
of Bregman distances, we shall deï¬ne subgradient D-projections as follows (see also
 for special instances).
Definition 3.37. Suppose that
X is reï¬‚exive and f is Legendre,
g: X â†’]âˆ’âˆ, +âˆ] is lower semicontinuous and convex,
levâ‰¤0 g âˆ©int dom f Ì¸= Ã˜ and dom f âŠ‚dom g.
For every x âˆˆint dom f and xâˆ—âˆˆâˆ‚g(x), set
G(x, xâˆ—) =
y âˆˆX | âŸ¨x âˆ’y, xâˆ—âŸ©â‰¥g(x)
The operator
Qg : int dom f â†’X : x â†’
PG(x,xâˆ—)x | xâˆ—âˆˆâˆ‚g(x)
is the subgradient D-projector onto levâ‰¤0 g.
Note that G(x, xâˆ—) is a proper closed half-space if xâˆ—Ì¸= 0 and the whole space X
otherwise; the latter may occur only when x âˆˆArgmin g.
Proposition 3.38. Suppose that (3.26) is in force and let Qg be the subgradient
D-projector onto levâ‰¤0 g. Then
(i) Fix Qg = levâ‰¤0 g âˆ©int dom f;
(ii) Qg âˆˆB.
Proof. Fix x âˆˆint dom f and xâˆ—âˆˆâˆ‚g(x). Since int dom f âŠ‚int dom g âŠ‚dom âˆ‚g,
âˆ‚g(x) Ì¸= Ã˜ and the closed convex set G(x, xâˆ—) is well deï¬ned. Moreover, (2.2) yields
(âˆ€y âˆˆlevâ‰¤0 g) âŸ¨y âˆ’x, xâˆ—âŸ©â‰¤g(y) âˆ’g(x) â‰¤âˆ’g(x).
Therefore, levâ‰¤0 g âŠ‚G(x, xâˆ—) and, in turn, G(x, xâˆ—) âˆ©int dom f Ì¸= Ã˜. Hence, Corollary 3.35(i) asserts that PG(x,xâˆ—) is single-valued with ran PG(x,xâˆ—) âŠ‚int dom f =
dom PG(x,xâˆ—), whence ran Qg âŠ‚int dom f = dom Qg. (i) Take y âˆˆX. Then it follows
from Proposition 3.32(ii)(b) that
y âˆˆFix Qg â‡”(âˆƒyâˆ—âˆˆâˆ‚g(y)) y = PG(y,yâˆ—)y
â‡”(âˆƒyâˆ—âˆˆâˆ‚g(y)) y âˆˆG(y, yâˆ—) âˆ©int dom f
â‡”(âˆƒyâˆ—âˆˆâˆ‚g(y)) 0 = âŸ¨y âˆ’y, yâˆ—âŸ©â‰¥g(y) and y âˆˆint dom f
â‡”y âˆˆlevâ‰¤0 g âˆ©int dom f.
Thus, Fix Qg = levâ‰¤0 g âˆ©int dom f. (ii) To show that Qg âˆˆB observe that Corollary 3.35(ii) implies that G(x, xâˆ—) âŠ‚H(x, PG(x,xâˆ—)x). Consequently, Fix Qg âŠ‚levâ‰¤0g âŠ‚
G(x, xâˆ—) âŠ‚H(x, PG(x,xâˆ—)x), where (x, PG(x,xâˆ—)x) is an arbitrary point in gr Qg. Altogether, Qg âˆˆB.
3.7. Relaxed parallel combination of B-class operators. The following
proposition describes a scheme to aggregate B-class operators in order to create a
new B-class operator.
Proposition 3.39.
Suppose that X is reï¬‚exive and that f is Legendre.
(Ti)iâˆˆI be a ï¬nite family of operators in B such that 
iâˆˆI Fix Ti Ì¸= Ã˜, let (Ï‰i)iâˆˆI be
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
weights in ]0, 1] such that 
iâˆˆI Ï‰i = 1, and let Î» be a relaxation parameter in ]0, 1].
For every x âˆˆint dom f, select (ui)iâˆˆI âˆˆÃ—iâˆˆITix, put
y âˆˆX | âŸ¨y, xâˆ—âŸ©â‰¤Î·(x)
xâˆ—= âˆ‡f(x) âˆ’
iâˆˆI Ï‰iâˆ‡f(ui),
iâˆˆI Ï‰i âŸ¨x + Î»(ui âˆ’x), âˆ‡f(x) âˆ’âˆ‡f(ui)âŸ©,
and deï¬ne T : int dom f â†’X : x â†’PH(x)x. Then the following hold:
(i) T is single-valued on dom T = int dom f âŠƒran T.
(ii) For every x âˆˆint dom f, the following statements are equivalent:
iâˆˆI Fix Ti.
(b) xâˆ—= 0.
(c) H(x) = X.
(d) x âˆˆH(x).
(e) x âˆˆFix T.
(iii) Fix T = 
iâˆˆI Fix Ti.
(iv) Fix T = 
iâˆˆI Fix Ti.
(v) (âˆ€x âˆˆint dom f) H(x) = H(x, Tx).
(vi) T âˆˆB.
Proof. Fix x âˆˆint dom f. (i) We ï¬rst observe that the operator T is well deï¬ned.
Indeed, since (Ti)iâˆˆI lies in B, xâˆ—and Î·(x) are well deï¬ned and we have
âŠ‚(int dom f) âˆ©
âŠ‚(int dom f) âˆ©
y âˆˆX | âŸ¨y âˆ’ui, âˆ‡f(x) âˆ’âˆ‡f(ui)âŸ©
â‰¤(1 âˆ’Î») âŸ¨x âˆ’ui, âˆ‡f(x) âˆ’âˆ‡f(ui)âŸ©
âŠ‚(int dom f) âˆ©
Ï‰i âŸ¨y âˆ’ui, âˆ‡f(x) âˆ’âˆ‡f(ui)âŸ©
Ï‰i âŸ¨x âˆ’ui, âˆ‡f(x) âˆ’âˆ‡f(ui)âŸ©
= (int dom f) âˆ©H(x),
where the second inclusion follows from the inequality Î» â‰¤1 and the monotonicity
of âˆ‡f. Whence, (int dom f) âˆ©H(x) Ì¸= Ã˜, and it follows from Corollary 3.35(i) that
PH(x)x is a well-deï¬ned point in int dom f. (ii) Since f is essentially strictly convex,
it is strictly convex on int dom f and it follows from Proposition 3.3(vi) that (a) â‡’
(âˆ€i âˆˆI) ui = x â‡’(b). (b) â‡’(c) Suppose xâˆ—= 0 and ï¬x y âˆˆ
iâˆˆI Fix Ti. Then,
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
H. H. BAUSCHKE, J. M. BORWEIN, AND P. L. COMBETTES
since (Ti)iâˆˆI lies in B,
Ï‰i âŸ¨ui âˆ’y, âˆ‡f(x) âˆ’âˆ‡f(ui)âŸ©
= Î·(x) âˆ’âŸ¨y, xâˆ—âŸ©âˆ’(1 âˆ’Î»)
Ï‰i âŸ¨x âˆ’ui, âˆ‡f(x) âˆ’âˆ‡f(ui)âŸ©
Accordingly, H(x) = X. The implications (c) â‡’(d) â‡’x = PH(x)x â‡’(e) are clear
in view of Proposition 3.32(ii)(b). (e) â‡’(a) We have
x âˆˆFix T â‡”x = PH(x)x
â‡”âŸ¨x, xâˆ—âŸ©â‰¤Î·(x)
Ï‰i âŸ¨x âˆ’ui, âˆ‡f(x) âˆ’âˆ‡f(ui)âŸ©â‰¤0
â‡”(âˆ€i âˆˆI) x = ui âˆˆTix
where the next to last equivalence follows from the strict monotonicity of âˆ‡f on
int dom f (f is strictly convex on int dom f) and the inequalities Î» > 0 and miniâˆˆI Ï‰i >
0. (iii) (i) and (ii) yield Fix T = (int dom f) âˆ©Fix T = 
iâˆˆI(Fix Ti âˆ©int dom f) =
iâˆˆI Fix Ti.
(iv) Set (âˆ€i âˆˆI) Fi = 
(x,u)âˆˆgr Ti H(x, u).
Then (iii) and Proposition 3.3(iv) yield Fix T = (int dom f)âˆ©
iâˆˆI Fi. Therefore, by Lemma 3.2 and Proposition 3.3(vii),
Fix T = dom f âˆ©
(Fi âˆ©dom f) =
(v) By Corollary 3.35(ii), we always have H(x) âŠ‚H(x, PH(x)x) = H(x, Tx). Now
suppose x âˆˆH(x). Then (ii) yields H(x) = X = H(x, x) = H(x, PH(x)x) = H(x, Tx).
Next, suppose x /âˆˆH(x). Then (ii) yields xâˆ—Ì¸= 0 and H(x) is therefore a proper
closed half-space in X.
On the other hand, x Ì¸= PH(x)x = Tx and, since âˆ‡f is
injective [8, Thm. 5.10], âˆ‡f(x) Ì¸= âˆ‡f(Tx). Consequently, H(x, Tx) is also a proper
closed half-space in X. Since Tx âˆˆH(x) âˆ©bdry H(x, Tx) and H(x) âŠ‚H(x, Tx), we
conclude H(x) = H(x, Tx). (vi) It follows successively from (iii), (3.32), and (v) that
iâˆˆI Fix Ti âŠ‚H(x) = H(x, Tx). In view of (i), the proof is complete.
4. Bregman monotonicity.
4.1. Properties. D-monotonicity was introduced in Deï¬nition 1.2.
collect some elementary properties.
Proposition 4.1. Let (xn)nâˆˆN be a sequence in X which is D-monotone with
respect to a set S âŠ‚X. Then the following hold:
(i) (âˆ€x âˆˆS âˆ©dom f)
nâˆˆN converges.
(ii) (âˆ€n âˆˆN) DS(xn+1) â‰¤DS(xn).
nâˆˆN converges.
(iv) (âˆ€(x, xâ€²) âˆˆ(S âˆ©dom f)2)
âŸ¨x âˆ’xâ€², âˆ‡f(xn)âŸ©
nâˆˆN converges.
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
(v) (xn)nâˆˆN is bounded if, for some z âˆˆS âˆ©dom f, the set levâ‰¤D(z,x0) D(z, Â·) is
bounded. This is true in particular if S âˆ©int dom f Ì¸= Ã˜, X is reï¬‚exive, and
one of the following properties is satisï¬ed:
(a) f is supercoercive;
(b) dim X < +âˆand dom f âˆ—is open.
Proof. (i) and (ii) are immediate consequences of Deï¬nition 1.2, and (iii) follows from (ii). (iv) Take x and xâ€² in S âˆ©dom f. By (i), the sequences
âŸ¨x âˆ’xn, âˆ‡f(xn)âŸ©
f(xn)+âŸ¨xâ€² âˆ’xn, âˆ‡f(xn)âŸ©
nâˆˆN converge and so does their
âŸ¨x âˆ’xâ€², âˆ‡f(xn)âŸ©
nâˆˆN. (v) By deï¬nition, for every x âˆˆS âˆ©dom f, (xn)nâˆˆN
lies in levâ‰¤D(z,x0) D(z, Â·).
The second assertion follows from [8, Lemma 7.3(viii)
and (ix)], which asserts that D(z, Â·) is coercive under the stated assumptions if
z âˆˆint dom f.
The following example shows that the conclusion of Proposition 4.1(v) may hold
even though the properties (a) and (b) are not satisï¬ed.
Example 4.2. Let X = â„“2(N) and deï¬ne
f : X â†’]âˆ’âˆ, +âˆ] : x = (Î¾k)kâˆˆN â†’
kâˆˆN Î¾k âˆ’ln(1 + Î¾k)
if (âˆ€k âˆˆN) Î¾k > âˆ’1,
otherwise.
Then f is Legendre and dom f is open. Moreover, levâ‰¤Î· D(0, Â·) is bounded for Î· > 0
suï¬ƒciently small.
Proof. We only sketch the arguments, as the example is not utilized elsewhere.
Observe that f is separable: (âˆ€x âˆˆX) f(x) = 
kâˆˆN h(Î¾k), where
(âˆ€Î¾ âˆˆR) h(Î¾) =
Î¾ âˆ’ln(1 + Î¾)
if Î¾ > âˆ’1,
otherwise.
Using calculus, one veriï¬es that dom f =
x âˆˆX | (âˆ€k âˆˆN)
, which is
open. Also, f is GË†ateaux-diï¬€erentiable on its domain with âˆ‡f(x) =
Hence f is essentially smooth. Now (âˆ€x âˆˆX) f âˆ—(x) = f(âˆ’x). Thus f âˆ—is essentially
smooth as well.
By [8, Thm. 5.4], f is essentially strictly convex.
Altogether, f
is Legendre. Let Î± = ln(2) âˆ’1/2. A careful analysis of the Bregman distance Dh
associated with h reveals that Dh(0, Î¾) < Î± â‡’|Î¾| < 1 â‡’Dh(0, Î¾) â‰¥Î±|Î¾|2.
passing, we point out that Dh(0, Â·) is convex precisely on ]âˆ’1, +1[.) Fix Î· âˆˆ[0, Î±[ and
x âˆˆX such that D(0, x) â‰¤Î·. Then (âˆ€k âˆˆN) Dh(0, Î¾k) â‰¥Î±|Î¾k|2. Summing yields
Î· â‰¥D(0, x) â‰¥Î±âˆ¥xâˆ¥2, whence x âˆˆB(0;
The next two assumptions will be quite helpful in the analysis of the convergence
of D-monotone sequences.
Condition 4.3. Given S âŠ‚X, for every bounded sequence (xn)nâˆˆN in int dom f,
x âˆˆW(xn)nâˆˆN âˆ©S,
xâ€² âˆˆW(xn)nâˆˆN âˆ©S,
(xn)nâˆˆN is D-monotone with respect to S
Condition 4.4. For all bounded sequences (xn)nâˆˆN and (yn)nâˆˆN in int dom f,
D(xn, yn) â†’0
xn âˆ’yn â†’0.
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
H. H. BAUSCHKE, J. M. BORWEIN, AND P. L. COMBETTES
These two assumptions cover familiar situations, as the following examples show.
Example 4.5. Suppose that S is a subset of X such that S âˆ©dom f is a singleton.
Then Condition 4.3 is satisï¬ed.
Take (xn)nâˆˆN in int dom f.
Then W(xn)nâˆˆN âŠ‚dom f and, therefore,
W(xn)nâˆˆN âˆ©S is at most a singleton.
Example 4.6. Suppose that S âŠ‚int dom f is convex, f|S is strictly convex, and
âˆ‡f is sequentially weak-to-weakâˆ—continuous at every point in S. Then Condition 4.3
is satisï¬ed.
Proof. Let (xn)nâˆˆN be a bounded sequence which is D-monotone with respect to
S. Then xkn â‡€x âˆˆS and xln â‡€xâ€² âˆˆS imply âˆ‡f(xkn)
âˆ—â‡€âˆ‡f(x) and âˆ‡f(xln)
âˆ‡f(xâ€²). Proposition 4.1(iv) therefore forces âŸ¨x âˆ’xâ€², âˆ‡f(x)âŸ©= âŸ¨x âˆ’xâ€², âˆ‡f(xâ€²)âŸ©; hence
âŸ¨x âˆ’xâ€², âˆ‡f(x) âˆ’âˆ‡f(xâ€²)âŸ©= 0.
Since âˆ‡f is strictly monotone on S, we get x =
Our next example requires the following lemma.
Lemma 4.7. Suppose that Îµ âˆˆ]0, +âˆ[, x âˆˆdom f, and y âˆˆint dom f. Then
there exists z âˆˆint dom f such that âˆ¥x âˆ’zâˆ¥â‰¤Îµ and |D(x, y) âˆ’D(z, y)| â‰¤Îµ.
Proof. Put (âˆ€Î± âˆˆ[0, 1[) xÎ± = (1 âˆ’Î±)y + Î±x. Then (xÎ±)Î±âˆˆ[0,1[ lies in int dom f,
limÎ±â†‘1âˆ’xÎ± = x and, by (3.6), limÎ±â†‘1âˆ’D(xÎ±, y) = D(x, y). Thus, for Î± suï¬ƒciently
close to 1, we can take z = xÎ±.
We now recall the notion of a Bregman/Legendre function in RN, which covers
numerous functions of importance in convex optimization . This notion will allow
us to describe a ï¬nite-dimensional setting in which Condition 4.3 holds.
Definition 4.8. Suppose that X = RN and f is Legendre. Then f is Bregman/
Legendre, if each of the following conditions is satisï¬ed:
(i) dom f âˆ—is open.
(ii) (âˆ€x âˆˆdom f âˆ–int dom f) D(x, Â·) is coercive.
x âˆˆdom f âˆ–int dom f,
(yn)nâˆˆN in int dom f,
yn â†’y âˆˆbdry dom f,
nâˆˆN bounded
D(y, yn) â†’0.
(xn)nâˆˆN in int dom f,
(yn)nâˆˆN in int dom f,
xn â†’x âˆˆdom f âˆ–int dom f,
yn â†’y âˆˆdom f âˆ–int dom f,
D(xn, yn) â†’0
Example 4.9. Suppose that X = RN, f is Bregman/Legendre, and S is a subset
of X such that S âˆ©dom f Ì¸= Ã˜. Then Condition 4.3 is satisï¬ed.
Proof. Let us start with two useful facts, namely
(yn)nâˆˆN in int dom f,
nâˆˆN bounded
D(y, yn) â†’0,
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
(yn)nâˆˆN in int dom f,
yn â†’y âˆˆdom f,
D(x, yn) â†’0
If x âˆˆint dom f, (4.5) follows from [7, Thm. 3.8(ii)].
On the other hand, if x âˆˆ
dom f âˆ–int dom f, (4.5) follows from [7, Prop. 3.3] if y âˆˆint dom f and from [7,
Def. 5.2.BL2] if y âˆˆbdry dom f. We now turn to (4.6). If x or y belongs to int dom f,
it suï¬ƒces to apply [7, Thm. 3.9(iii)].
Otherwise, {x, y} âŠ‚dom f âˆ–int dom f and
Lemma 4.7 ensures that, for every n â‰¥1, we can ï¬nd a point xn âˆˆint dom f such
that âˆ¥x âˆ’xnâˆ¥â‰¤1/n and |D(x, yn) âˆ’D(xn, yn)| â‰¤1/n. Therefore, xn â†’x and, since
D(x, yn) â†’0 by assumption, D(xn, yn) â†’0. It then follows from [7, Def. 5.2.BL3]
that x = y.
Now let (xn)nâˆˆN be a bounded sequence which is D-monotone with
respect to S and let z âˆˆS âˆ©dom f. Suppose xkn â†’x âˆˆS and xln â†’xâ€² âˆˆS. Since by
D-monotonicity the sequences
nâˆˆN are bounded, (4.5)
yields D(x, xkn) â†’0, D(xâ€², xln) â†’0, and {x, xâ€²} âŠ‚S âˆ©dom f. However, it follows
from Proposition 4.1(i) that D(x, xkn) â†’0 â‡’D(x, xn) â†’0 â‡’D(x, xln) â†’0. In
view of (4.6), we conclude x = xâ€², as required.
Following , we say that f is uniformly convex on bounded sets if, for every
bounded set B âŠ‚X, one has
(âˆ€t âˆˆ]0, +âˆ[) inf Âµ
B âˆ©dom f, t
Âµ: dom f Ã— [0, +âˆ[ â†’[0, +âˆ] : (x, t) â†’
f(x) + f(y)
Examples of such functions are given in .
The next result gives suï¬ƒcient conditions for Condition 4.4 to hold. (See also 
and for item (ii).)
Example 4.10. Condition 4.4 is satisï¬ed whenever one of the following is true:
(i) f is uniformly convex on bounded sets.
(ii) X = RN, dom f is closed, and f|dom f is strictly convex and continuous.
(iii) X = R and f|dom f is strictly convex.
Proof. (i) is a direct consequence of [25, Prop. 4.2]. (ii) and (iii) are special cases
of (i) by [85, Prop. 3.6.6(i)].
In passing, we note that it follows from [85, Thm. 3.5.13] that item (i) of Example 4.10 forces the underlying space X to be reï¬‚exive.
The above assumptions lead to remarkably simple weak and strong convergence
criteria for D-monotone sequences. In the case when X is Hilbertian and f = âˆ¥Â·âˆ¥2/2,
Conditions 4.3 and 4.4 are satisï¬ed and these criteria can essentially be found in 
(see also and ). Recall (see section 2) that S denotes the set of strong cluster
points of a sequence.
Theorem 4.11. Let (xn)nâˆˆN be a bounded sequence in X which is D-monotone
with respect to a set S âŠ‚X. Suppose that X is reï¬‚exive and Condition 4.3 is satisï¬ed.
(i) (xn)nâˆˆN converges weakly to a point in Sâˆ©dom f if and only if W(xn)nâˆˆN âŠ‚S;
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
H. H. BAUSCHKE, J. M. BORWEIN, AND P. L. COMBETTES
(ii) supposing that xn â‡€x âˆˆS âˆ©int dom f and Condition 4.4 is satisï¬ed, then
xn â†’x if and only if S(xn)nâˆˆN Ì¸= Ã˜.
Proof. (i) Necessity is clear. To prove suï¬ƒciency, suppose that W(xn)nâˆˆN âŠ‚S
and take x and xâ€² in W(xn)nâˆˆN, say xkn â‡€x and xln â‡€xâ€². Then x and xâ€² lie in
S and (4.3) forces x = xâ€². Since X is reï¬‚exive and (xn)nâˆˆN is bounded, we conclude
xn â‡€x. Furthermore, since dom f âˆ‹xn â‡€x and dom f is weakly closed, x âˆˆdom f.
(ii) Necessity is clear. To prove suï¬ƒciency, suppose that Condition 4.4 is satisï¬ed,
x âˆˆS âˆ©int dom f, and S(xn)nâˆˆN Ì¸= Ã˜, i.e., some subsequence (xkn)nâˆˆN converges
strongly. Since xn â‡€x, we must have xkn â†’x. In turn, [8, Lemma 7.3(x)] yields
D(x, xkn) â†’0 and it follows from Proposition 4.1(i) that D(x, xn) â†’0. In view of
(4.4), we conclude xn â†’x.
4.2. Construction.
Algorithm 4.12. Starting with x0 âˆˆint dom f, at every iteration n âˆˆN, select
ï¬rst Tn âˆˆB and then xn+1 âˆˆTnxn.
Proposition 4.13. Let (xn)nâˆˆN be an arbitrary orbit of Algorithm 4.12. Suppose
Fix Tn Ì¸= Ã˜, S âŠ‚
Fix Tn, and
S âˆ©dom f Ì¸= Ã˜.
(i) if f|int dom f is strictly convex, (xn)nâˆˆN is D-monotone with respect to S;
nâˆˆN D(xn+1, xn) < +âˆ.
(i) Proposition 3.3(viii) yields (âˆ€n âˆˆN)(âˆ€y âˆˆFix Tn) D(y, xn+1) â‰¤
(ii) Fix y âˆˆ
nâˆˆN Fix Tn.
Then Proposition 3.3(i) yields the stronger
(âˆ€n âˆˆN) D(y, xn+1) â‰¤D(y, xn) âˆ’D(xn+1, xn).
Therefore 
nâˆˆN D(xn+1, xn) â‰¤D(y, x0).
Theorem 4.14. Let (xn)nâˆˆN be an arbitrary bounded orbit of Algorithm 4.12.
Suppose that X is reï¬‚exive, that f|int dom f is strictly convex, and that (4.9) is satisï¬ed.
Suppose in addition that Condition 4.3 is satisï¬ed and that
D(xn+1, xn) < +âˆ
W(xn)nâˆˆN âŠ‚S.
(i) (xn)nâˆˆN converges weakly to a point x âˆˆS;
(ii) the convergence is strong in (i) if x âˆˆint dom f, Condition 4.4 is satisï¬ed,
D(xn+1, xn) < +âˆ
S(xn)nâˆˆN Ì¸= Ã˜.
Proof. Combine Theorem 4.11 and Proposition 4.13.
5. Parallel block-iterative D-monotone algorithm.
5.1. Objective. For the remainder of this paper, we assume that
X is reï¬‚exive and f is Legendre,
(Si)iâˆˆI is a countable family of closed convex subsets of X,
(int dom f) âˆ©
iâˆˆI Si Ì¸= Ã˜,
S = dom f âˆ©
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
The purpose of this section is to develop a relaxed, parallel, block-iterative algorithm
to solve the convex feasibility problem
Find x âˆˆS.
5.2. Algorithm.
Algorithm 5.1. Starting with x0 âˆˆint dom f, take at every iteration n
â€a nonempty ï¬nite index set In âŠ‚I,
âoperators (Ti,n)iâˆˆIn in B such that (âˆ€i âˆˆIn) Si âˆ©int dom f âŠ‚Fix Ti,n,
â‚points (ui,n)iâˆˆIn âˆˆÃ—iâˆˆInTi,nxn,
âƒweights (Ï‰i,n)iâˆˆIn in such that 
iâˆˆIn Ï‰i,n = 1,
â„a relaxation parameter Î»n âˆˆ]0, 1]
n = âˆ‡f(xn) âˆ’
iâˆˆIn Ï‰i,nâˆ‡f(ui,n),
xn, âˆ‡f(xn) âˆ’
Ï‰i,nâˆ‡f(ui,n)
Ï‰i,n âŸ¨ui,n âˆ’xn, âˆ‡f(ui,n) âˆ’âˆ‡f(xn)âŸ©,
y âˆˆX | âŸ¨y, xâˆ—
Then set xn+1 = PHnxn.
We now motivate this algorithm geometrically. At iteration n, xn is given and
a ï¬nite block of indices In is retained. Set I+
i âˆˆIn | Ï‰i,n > 0
. Then, using
Lemma 3.2 for the ï¬rst and last equality, step âfor the third inclusion, and (3.32)
for the fourth inclusion,
S = (int dom f) âˆ©
Si âŠ‚(int dom f) âˆ©
Si âŠ‚(int dom f) âˆ©
Fix Ti,n âŠ‚(int dom f) âˆ©Hn = dom f âˆ©Hn âŠ‚Hn.
Thus, Hn acts as an outer approximation to the intersection of the block of constraint
sets (dom f âˆ©Si)iâˆˆIn and, therefore, to S. More precisely, the block constraint y âˆˆ
iâˆˆIn Si is replaced by the surrogate aï¬ƒne constraint âŸ¨y, xâˆ—
nâŸ©â‰¤Î·n. The
update xn+1 is then the D-projection of xn onto Hn, i.e., the D-closest point to xn
which satisï¬es the surrogate constraint. (xn+1 is well deï¬ned by virtue of (5.1) and
Corollary 3.35(i).) Naturally, such a point is considerably simpler to ï¬nd than a point
in dom f âˆ©
iâˆˆIn Si. In spirit, this type of surrogate constraint construction can be
foundâ€”explicitly or implicitlyâ€”in several places in the literature, although not in the
context of Bregman distances. (See, for instance, and the references therein.)
The parallel nature of the algorithm stems from the fact that the points (ui,n)iâˆˆIn
at step â‚can be computed independently on concurrent processors. In addition, the
algorithm has the ability to process variable blocks of constraints, which makes it
possible to match closely the computational load of each iteration to the parallel
processing architecture at hand. A discussion on the importance of block-processing
for task scheduling on parallel architectures can be found in .
To shed more light on Algorithm 5.1, we ï¬rst consider the case when X is Hilbertian and f = âˆ¥Â· âˆ¥2/2. Then, steps â…and â†become
iâˆˆIn Ï‰i,nui,n,
iâˆˆIn Ï‰i,nui,n
iâˆˆIn Ï‰i,nâˆ¥ui,n âˆ’xnâˆ¥2.
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
H. H. BAUSCHKE, J. M. BORWEIN, AND P. L. COMBETTES
Furthermore, the updating step is explicitly given as
xn+1 = PHnxn = xn + Î·n âˆ’âŸ¨xn, xâˆ—
n = xn + Î»nLn
Ï‰i,n(ui,n âˆ’xn)
iâˆˆIn Ï‰i,nâˆ¥ui,n âˆ’xnâˆ¥2
iâˆˆIn Ï‰i,n(ui,n âˆ’xn)âˆ¥2
otherwise.
This is essentially the algorithm proposed in [41, section 6] (in this setting, the range
of Î»n can be extended to ]0, 2[), which itself contains those of 
as special cases. In particular, if I is ï¬nite, In â‰¡I, Ï‰i,n = Ï‰i, and ui,n = Pixn,
where Pi is the metric projector onto Si, then (5.5)â€“(5.6) reduces to Pierraâ€™s classic
extrapolated parallel projection method , which in turn can be traced back to Merzlyakovâ€™s method for solving systems of linear inequalities in RN. Since Ln â‰¥1
in (5.6), large extrapolations are possible in this algorithm by selecting Î»n â‰ˆ1. It is
known that these extrapolations yield signiï¬cantly accelerated convergence in numerical experiments in comparison with purely averaged iterations, i.e.,
which can be derived from (5.5) by setting Î»n = 1/Ln.
Returning to the standing assumptions, let us now consider the parallel blockiterative update rule
âˆ‡f(xn+1) =
Ï‰i,nâˆ‡f(ui,n).
This alternative method for solving (5.2) was recently proposed by Censor and Herman
in (see also ) for the special case when X = RN, I is ï¬nite, and ui,n is the
D-projection of xn onto Si. If we assume that X is a Hilbert space and f = âˆ¥Â· âˆ¥2/2,
then (5.8) reduces to (5.7) which, as noted above, is itself a special case of (5.5)â€“(5.6),
hence of Algorithm 5.1. In general, however, we do not know whether (5.8) is always
a particularization of Algorithm 5.1.
We now turn to Butnariu and Iusemâ€™s algorithmic framework for solving
(5.2). (In fact, they study the so-called stochastic convex feasibility problem, which is
similar to (5.2) but allows for an uncountable index set I. Their framework requires
measure theory for a precise formulation and their assumptions on the underlying
function f are diï¬€erent from the ones made here. The reader is referred to for
further details.) Let (Ri)iâˆˆI be a family of totally nonexpansive operators in the sense
of . (See also the paragraph following Deï¬nition 3.1.) Specialized to the case when
I is ï¬nite, the update step in this algorithm is
This resembles (5.8), except for notably absent gradients on both sides of the equation and for weights that do not depend on n. (If the Riâ€™s are D-projectors, then
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
(5.9) can also be interpreted as a sequential algorithm in the product space XI; see
 .) Note that if X is a Hilbert space and f = âˆ¥Â· âˆ¥2/2, then (5.9) once again corresponds to a parallel Cimmino-type algorithm, which is genuinely more restrictive
than Algorithm 5.1 for this set-up.
While a detailed numerical and theoretical comparison of these algorithms lies
beyond the scope of this paper, we remark that preliminary experiments suggest
that Algorithm 5.1 is more ï¬‚exible and faster than the one given by (5.8) and that
Algorithm 5.1 is genuinely diï¬€erent from the method given by (5.9).
5.3. Convergence. The following notions were introduced in [6, Def. 3.7] and
[41, Def. 6.5], respectively, to study the asymptotic behavior of FejÂ´er monotone algorithms in Hilbert spaces. The former can be interpreted as an extension of the
notion of demiclosedness at 0 and the latter as an extension of the notion of
demicompactness at 0 .
Definition 5.2. Algorithm 5.1 is
â€¢ focusing if for every bounded suborbit (xkn)nâˆˆN it generates and every index
ui,kn âˆ’xkn â†’0
â€¢ demicompactly regular if there exists i âˆˆI, called an index of demicompact
regularity, such that for every bounded suborbit (xkn)nâˆˆN it generates,
ui,kn âˆ’xkn â†’0
S(xkn)nâˆˆN Ì¸= Ã˜.
We now describe the context in which the convergence of Algorithm 5.1 will be
investigated.
Condition 5.3.
(i) For some z âˆˆdom f âˆ©
iâˆˆI Si, C = levâ‰¤D(z,x0) D(z, Â·) is bounded.
(ii) For all sequences (un)nâˆˆN and (vn)nâˆˆN in C such that (âˆ€n âˆˆN) un Ì¸= vn, one
âŸ¨un âˆ’vn, âˆ‡f(un) âˆ’âˆ‡f(vn)âŸ©
âˆ¥âˆ‡f(un) âˆ’âˆ‡f(vn)âˆ¥
âˆ‡f(un) âˆ’âˆ‡f(vn) â†’0.
Condition 5.4.
(i) (âˆƒÎ´1 âˆˆ]0, 1[)(âˆ€n âˆˆN)(âˆƒj âˆˆIn)
âˆ¥âˆ‡f(uj,n) âˆ’âˆ‡f(xn)âˆ¥= max
iâˆˆIn âˆ¥âˆ‡f(ui,n) âˆ’âˆ‡f(xn)âˆ¥and Ï‰j,n â‰¥Î´1.
(ii) (âˆƒÎ´2 âˆˆ]0, 1[)(âˆ€n âˆˆN) Î»n â‰¥Î´2.
(iii) (âˆ€i âˆˆI)(âˆƒMi âˆˆN âˆ–{0})(âˆ€n âˆˆN) i âˆˆn+Miâˆ’1
As will be seen subsequently, the above set of assumptions deï¬nes a broad framework which covers numerous practical situations. Note that, by virtue of (5.1), the
quotient in (5.12) is well deï¬ned since âˆ‡f is injective on int dom f [8, Thm. 5.10].
Situations in which Condition 5.3(ii) is satisï¬ed are detailed below. Note also that
Condition 5.4(iii) imposes that every index i be activated at least once within any
Mi consecutive iterations. This control rule, which has already been used in metric
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
H. H. BAUSCHKE, J. M. BORWEIN, AND P. L. COMBETTES
projection algorithms in Hilbert spaces , provides great ï¬‚exibility in
the management of the constraints and the implementation of the algorithm. Condition 5.4(i) provides added ï¬‚exibility by oï¬€ering the possibility of setting Ï‰i,n = 0
if the corresponding step size âˆ¥âˆ‡f(ui,n) âˆ’âˆ‡f(xn)âˆ¥is not maximal. It is thereby
possible to meet the control condition Condition 5.4(iii) without actually using the
ith constraint in the construction of xn+1.
Recall that an operator T from a Banach space Y to its dual Yâˆ—is said to be
uniformly monotone on U âŠ‚dom T with modulus c if [86, section 25.3]
(âˆ€x âˆˆU)(âˆ€y âˆˆU) âŸ¨x âˆ’y, Tx âˆ’TyâŸ©â‰¥âˆ¥x âˆ’yâˆ¥Â· c(âˆ¥x âˆ’yâˆ¥),
where c: [0, +âˆ[ â†’[0, +âˆ[ is a strictly increasing function such that c(0) = 0. In
particular, T is said to be strongly monotone on U with constant Î± âˆˆ]0, +âˆ[ if it is
uniformly monotone on U with modulus c: t â†’Î±t.
Proposition 5.5. Let z and C be as in Condition 5.3(i). Then Condition 5.3(ii)
is satisï¬ed in each of the following cases:
(i) âˆ‡f âˆ—is uniformly monotone on âˆ‡f(C).
(ii) âˆ‡f is Lipschitz-continuous on dom f = X.
(iii) X = RN and C âŠ‚int dom f.
(iv) X = RN and z âˆˆint dom f.
Let (un)nâˆˆN and (vn)nâˆˆN be two sequences in C such that (âˆ€n âˆˆN)
(i) Let c be the modulus of uniform monotonicity of âˆ‡f âˆ—on âˆ‡f(C).
Since âˆ‡f is a bijection from int dom f to int dom f âˆ—with inverse âˆ‡f âˆ—[8, Thm. 5.10]
and since C âŠ‚int dom f, we have (âˆ€u âˆˆC)(âˆ€v âˆˆC) âŸ¨u âˆ’v, âˆ‡f(u) âˆ’âˆ‡f(v)âŸ©â‰¥
âˆ¥âˆ‡f(u) âˆ’âˆ‡f(v)âˆ¥Â· c (âˆ¥âˆ‡f(u) âˆ’âˆ‡f(v)âˆ¥). Hence, since c is strictly increasing and
âŸ¨un âˆ’vn, âˆ‡f(un) âˆ’âˆ‡f(vn)âŸ©
âˆ¥âˆ‡f(un) âˆ’âˆ‡f(vn)âˆ¥
âˆ¥âˆ‡f(un) âˆ’âˆ‡f(vn)âˆ¥
â‡’âˆ‡f(un) âˆ’âˆ‡f(vn) â†’0.
(ii) â‡’(i) If âˆ‡f is Îº-Lipschitz-continuous on X, then it follows from the Baillonâ€“
Haddad theorem [4, Cor. 10] that (âˆ€x âˆˆX)(âˆ€y âˆˆX) âŸ¨x âˆ’y, âˆ‡f(x) âˆ’âˆ‡f(y)âŸ©â‰¥
âˆ¥âˆ‡f(x)âˆ’âˆ‡f(y)âˆ¥2/Îº, i.e., âˆ‡f âˆ—is strongly monotone with constant 1/Îº. Consequently,
âˆ‡f âˆ—is uniformly monotone on âˆ‡f(C). (iii) Suppose
âŸ¨un âˆ’vn, âˆ‡f(un) âˆ’âˆ‡f(vn)âŸ©
âˆ¥âˆ‡f(un) âˆ’âˆ‡f(vn)âˆ¥
âˆ‡f(un) âˆ’âˆ‡f(vn) Ì¸â†’0.
Then there exists a strictly increasing sequence (kn)nâˆˆN in N and Îµ âˆˆ]0, +âˆ[ such
that infnâˆˆN âˆ¥âˆ‡f(ukn) âˆ’âˆ‡f(vkn)âˆ¥â‰¥Îµ. Since (ukn)nâˆˆN lies in C, it is bounded and
therefore possesses a convergent subsequence, say ukln â†’u. As (vkln)nâˆˆN is also
bounded, we can assume (passing to a subsequence if necessary) that it converges,
say vkln â†’v. Since {u, v} âŠ‚C âŠ‚int dom f and âˆ‡f is continuous at every point in
int dom f by [77, Thm. 25.5], taking the limit yields âˆ¥âˆ‡f(u) âˆ’âˆ‡f(v)âˆ¥â‰¥Îµ and, by
injectivity of âˆ‡f on int dom f [8, Thm. 5.10], u Ì¸= v. On the other hand, (5.15) yields
ukln âˆ’vkln, âˆ‡f(ukln) âˆ’âˆ‡f(vkln)
âˆ¥âˆ‡f(ukln) âˆ’âˆ‡f(vkln)âˆ¥
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
and, since âˆ¥âˆ‡f(u) âˆ’âˆ‡f(v)âˆ¥Ì¸= 0, taking the limit yields âŸ¨u âˆ’v, âˆ‡f(u) âˆ’âˆ‡f(v)âŸ©=
0. However, f|int dom f is strictly convex and therefore âˆ‡f is strictly monotone on
int dom f âŠƒ{u, v}. This forces u = v and we reach a contradiction. (iv) In view of
(iii), it is enough to show that C âŠ‚int dom f. If the inclusion does not hold, then we
can ï¬nd y âˆˆbdry dom f and (yn)nâˆˆN in C such that yn â†’y. Thus supnâˆˆN D(z, yn) â‰¤
D(z, x0) < +âˆ, and, at the same time, since f is essentially smooth, [7, Thm. 3.8(i)]
yields D(z, yn) â†’+âˆ, which is absurd.
Remark 5.6. A careful analysis of [85, Corollary 3.4.4â€œ(iii)â‡”(iv)â€], [85, Proposition 3.5.1], and [85, Proposition 3.6.2] shows that Proposition 5.5(i) holds as soon as
âˆ‡f is Lipschitz on bounded sets. In turn, this condition is satisï¬ed in Lp spaces for
p, where {p, s} âŠ‚[2, +âˆ[. (The proof relies on the case when s = 2; see also
Example 5.11 below.)
Examples of Legendre functions f which satisfy Conditions 4.3, 4.4, and 5.3(i)â€“
(ii) will be supplied in section 5.4. Our main convergence result can now be stated
and proved.
Theorem 5.7. Suppose that Conditions 4.3, 4.4, 5.3, and 5.4 are satisï¬ed, and
let (xn)nâˆˆN be an arbitrary orbit of Algorithm 5.1. Then, for every n âˆˆN, xn and
(ui,n)iâˆˆIn lie in the bounded set C. If, in addition, Algorithm 5.1 is focusing, then the
following statements hold true:
(i) (xn)nâˆˆN converges weakly to a point x âˆˆS.
(ii) If the weak limit x from (i) belongs to int dom f and the algorithm is demicompactly regular, then (xn)nâˆˆN converges strongly.
Proof . For every n âˆˆN, set Tn = PHn and I+
i âˆˆIn | Ï‰i,n > 0
x0 âˆˆint dom f and, by Proposition 3.39(vi), Tn âˆˆB, we recognize that
Algorithm 5.1 is a special case of Algorithm 4.12.
Our goal is to apply Theorem 4.14 and we must start by verifying (4.9).
considering (5.1), Algorithm 5.1â, and Proposition 3.39(iii), we obtain
(âˆ€n âˆˆN) Ã˜ Ì¸= (int dom f) âˆ©
(Si âˆ©int dom f) âŠ‚
Fix Ti,n = Fix Tn.
nâˆˆN Fix Tn Ì¸= Ã˜. In addition, (5.1), Lemma 3.2, and (5.18) yield
(âˆ€n âˆˆN) S = dom f âˆ©
Si âŠ‚Fix Tn.
Consequently, S âŠ‚
nâˆˆN Fix Tn. Next, we derive from (5.1) that
Ã˜ Ì¸= (int dom f) âˆ©
Si âŠ‚dom f âˆ©dom f âˆ©
Si = dom f âˆ©S.
Thus, (4.9) holds. Now, let z and C be as in Condition 5.3(i). It follows from (5.17)
and Proposition 4.13(i) that the sequences (xn)nâˆˆN and (Tnxn)nâˆˆN are contained in C,
which is bounded. In order to verify (4.11), some key facts must be established. Let us
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
H. H. BAUSCHKE, J. M. BORWEIN, AND P. L. COMBETTES
temporarily ï¬x n âˆˆN. The ï¬rst fact is supplied by the inclusion xn+1 = PHnxn âˆˆHn,
which yields
âˆ¥xn+1 âˆ’xnâˆ¥â‰¥dHn(xn).
Next, it follows from Condition 5.3(i), (5.1), Lemma 3.2, and Algorithm 5.1âthat
(âˆ€i âˆˆIn) z âˆˆSi âˆ©dom f = Si âˆ©int dom f âŠ‚Fix Ti,n.
Hence, for every i âˆˆIn, Algorithm 5.1â‚and Proposition 3.3(viii) yield D(z, ui,n) â‰¤
D(z, xn) âˆ’D(ui,n, xn) â‰¤D(z, xn). Therefore,
(âˆ€i âˆˆIn) ui,n âˆˆC.
Now, per Condition 5.4(ii), pick jn âˆˆIn such that
âˆ¥âˆ‡f(ujn,n) âˆ’âˆ‡f(xn)âˆ¥= max
iâˆˆIn âˆ¥âˆ‡f(ui,n) âˆ’âˆ‡f(xn)âˆ¥
Ï‰jn,n â‰¥Î´1.
We claim that
n Fix Ti,n
ujn,n = xn
âˆ¥âˆ‡f(ujn,n) âˆ’âˆ‡f(xn)âˆ¥= 0,
n Fix Ti,n
dHn(xn) â‰¥Î´1Î´2
âŸ¨ujn,n âˆ’xn, âˆ‡f(ujn,n) âˆ’âˆ‡f(xn)âŸ©
âˆ¥âˆ‡f(ujn,n) âˆ’âˆ‡f(xn)âˆ¥
On the one hand, using Proposition 3.3(vi) and the injectivity of âˆ‡f on int dom f
[8, Thm. 5.10], since (5.24) forces jn âˆˆI+
n , we get xn âˆˆ
n Fix Ti,n â‡”(âˆ€i âˆˆI+
ui,n = xn â‡’ujn,n = xn â‡’âˆ¥âˆ‡f(ujn,n) âˆ’âˆ‡f(xn)âˆ¥= 0 â‡’(âˆ€i âˆˆIn) âˆ¥âˆ‡f(ui,n) âˆ’
âˆ‡f(xn)âˆ¥= 0 â‡”(âˆ€i âˆˆIn) ui,n = xn â‡’(âˆ€i âˆˆI+
n ) ui,n = xn. On the other hand, if
n Fix Ti,n, then Proposition 3.39(ii) asserts that xn /âˆˆHn and xâˆ—
n Ì¸= 0, so
dHn(xn) = âŸ¨xn, xâˆ—
iâˆˆIn Ï‰i,n âŸ¨ui,n âˆ’xn, âˆ‡f(ui,n) âˆ’âˆ‡f(xn)âŸ©
âˆ‡f(ui,n) âˆ’âˆ‡f(xn)
iâˆˆIn Ï‰i,n âŸ¨ui,n âˆ’xn, âˆ‡f(ui,n) âˆ’âˆ‡f(xn)âŸ©
iâˆˆIn Ï‰i,nâˆ¥âˆ‡f(ui,n) âˆ’âˆ‡f(xn)âˆ¥
âŸ¨ujn,n âˆ’xn, âˆ‡f(ujn,n) âˆ’âˆ‡f(xn)âŸ©
âˆ¥âˆ‡f(ujn,n) âˆ’âˆ‡f(xn)âˆ¥
where (5.26) follows from [80, Lemma I.1.2] and (5.27) from Condition 5.4(ii). Altogether, (5.25) is veriï¬ed. The third key fact is derived from (5.23) and Proposition 2.3(i) as follows:
(âˆ€i âˆˆIn) diam(C)âˆ¥âˆ‡f(ui,n) âˆ’âˆ‡f(xn)âˆ¥â‰¥âŸ¨ui,n âˆ’xn, âˆ‡f(ui,n) âˆ’âˆ‡f(xn)âŸ©
= D(ui,n, xn) + D(xn, ui,n)
â‰¥D(ui,n, xn).
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
Let us now verify (4.11). To this end, let us ï¬x i âˆˆI and x âˆˆW(xn)nâˆˆN, say xkn â‡€x.
Because x âˆˆdom f, it is suï¬ƒcient to show
D(xn+1, xn) â†’0
Let Mi be as in Condition 5.4(iii). After passing to a subsequence of (xkn)nâˆˆN if
necessary, we assume that, for every n âˆˆN, kn+1 â‰¥kn + Mi. This guarantees the
existence of a sequence (pn)nâˆˆN in N such that
(âˆ€n âˆˆN) kn â‰¤pn â‰¤kn + Mi âˆ’1 < kn+1 â‰¤pn+1
Now consider the subsequence (xpn)nâˆˆN of (xn)nâˆˆN. The triangle inequality yields
(âˆ€n âˆˆN) âˆ¥xpn âˆ’xknâˆ¥â‰¤
âˆ¥xl+1 âˆ’xlâˆ¥â‰¤(Mi âˆ’1)
knâ‰¤lâ‰¤kn+Miâˆ’2 âˆ¥xl+1 âˆ’xlâˆ¥.
Now suppose D(xn+1, xn) â†’0. Then (4.4) yields
xn+1 âˆ’xn â†’0
and it follows from (5.21) that dHn(xn) â†’0. Consequently, we derive from (5.25),
(5.23), and Condition 5.3(ii) that maxjâˆˆIn âˆ¥âˆ‡f(uj,n) âˆ’âˆ‡f(xn)âˆ¥â†’0. In turn, (5.29)
implies that D(ui,pn, xpn) â†’0 and, invoking (4.4) again, we obtain
ui,pn âˆ’xpn â†’0.
We also derive from (5.32) and (5.33) that xpn âˆ’xkn â†’0, whence xpn â‡€x. However, since the algorithm is focusing, (5.10) yields x âˆˆSi. Thus (5.30) holds and,
consequently, the following conclusions can be drawn:
(i) Theorem 4.14(i) asserts that (xn)nâˆˆN converges weakly to x âˆˆS.
(ii) Suppose that x âˆˆint dom f, i âˆˆI is an index of demicompact regularity, and
D(xn+1, xn) â†’0. Then it results from (5.34) and (5.11) that (4.12) holds.
In view of Condition 4.4, the strong convergence claim therefore follows from
Theorem 4.14(ii).
5.4. When all the assumptions hold. In this subsection, we describe scenarios in which all the assumptions required in Theorem 5.7 on f and on the constraint
sets (Si)iâˆˆI are satisï¬ed.
As a preamble to our ï¬rst example, recall that if X is a Hilbert space, the Moreauâ€“
Yosida regularization of a proper lower semicontinuous convex function Ï•: X â†’
]âˆ’âˆ, +âˆ] with parameter Î³ âˆˆ]0, +âˆ[ is the ï¬nite continuous convex function
âˆ¥Â· âˆ¥2/(2Î³)
Moreover, Moreauâ€™s classic proximal operator associated
with Ï• and Î³ is given by Deï¬nition 3.16 for f = âˆ¥Â· âˆ¥2/2 and will be denoted by
Î³ . It follows from Proposition 3.21(v) that ProxÏ•
Î³ is deï¬ned everywhere and,
from Proposition 3.22(ii)(d) and (c), that it is single-valued and ï¬rmly nonexpansive.
Moreover [67, Prop. 7.d],
âˆ‡Î³Ï• = Id âˆ’ProxÏ•
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
H. H. BAUSCHKE, J. M. BORWEIN, AND P. L. COMBETTES
Example 5.8 (Moreauâ€“Yosida regularization).
Let X be a Hilbert space, set
w = âˆ¥Â· âˆ¥2/2, and deï¬ne f : X â†’R by
f = (1 + Î³)w âˆ’1Ï•,
where Ï•: X â†’]âˆ’âˆ, +âˆ] is a proper lower semicontinuous convex function and Î³ âˆˆ
]0, +âˆ[. Then
D: (x, y) â†’Î³w(x âˆ’y) + w(x âˆ’ProxÏ•
1 y) + Ï•(ProxÏ•
w(x âˆ’ProxÏ•
1 x) + Ï•(ProxÏ•
and Conditions 4.4 and 5.3 are satisï¬ed. If ProxÏ•
1+Î³ is aï¬ƒne or S is a singleton, then
Condition 4.3 is also satisï¬ed.
Proof. The expression (5.37) is derived from (1.5) by simple algebra. Now set
Ïˆ = w âˆ’1Ï•. Then
xâˆˆdom Ï• Ï•(x) + w(Â· âˆ’x) =
âŸ¨x, Â·âŸ©âˆ’Ï•(x) âˆ’w(x) = (Ï• + w)âˆ—.
Hence, Ïˆ is a proper lower semicontinuous convex function as the conjugate of one
such function. Since Ïˆ is convex, f = Ïˆ+Î³w is strongly (hence uniformly) convex and,
in view of Example 4.10(i), Condition 4.4 is therefore satisï¬ed. On the other hand,
(5.35) yields dom âˆ‡f = X and âˆ‡f = ProxÏ•
1 +Î³ Id. Hence f is essentially smooth
by [8, Thm. 5.6]. Furthermore, since ProxÏ•
1 is ï¬rmly nonexpansive, it is 1-Lipschitz
and therefore âˆ‡f is (1 + Î³)-Lipschitz. Accordingly, Proposition 5.5(ii) asserts that
Condition 5.3(ii) is satisï¬ed. Next, using standard Hilbertian convex calculus, we
âˆ—= Ïˆâˆ—â–¡(w/Î³) = (Ï• + w) â–¡(w/Î³) = Î³
Â· /(1 + Î³)
+ w/(1 + Î³).
It therefore follows from (5.35) that
dom âˆ‡f âˆ—= X
Â· /(1 + Î³)
Consequently, f âˆ—is also essentially smooth and it follows from [8, Thm. 5.4] that f
is Legendre. Moreover, since X is a Hilbert space, it is reï¬‚exive. We also derive from
(5.40) that, since Id âˆ’ProxÏ•
Î³/(1+Î³) is (ï¬rmly) nonexpansive, âˆ‡f âˆ—is 1/Î³-Lipschitz and,
thereby, maps bounded sets to bounded sets. It then follows from [8, Thm. 3.3] that
f is supercoercive, and Proposition 4.1(v)(a) asserts that Condition 5.3(i) is satisï¬ed.
Finally, since âˆ‡f is continuous, it will be weakly continuous when it is aï¬ƒne, i.e.,
when ProxÏ•
Î³/(1+Î³) is. In turn, Example 4.6 implies that Condition 4.3 is satisï¬ed. On
the other hand, if S is a singleton, the claim follows from Example 4.5.
If we let Ï• be the indicator function of a nonempty closed convex set in (5.36),
then we obtain the Legendre function studied in [8, Example 7.2]. Specializing even
further, we obtain the following examples.
Example 5.9 (distance).
In the previous example, set Ï• = Î¹M, where M is
a closed aï¬ƒne subspace of X, and let PM be the metric projector onto M. Then
Conditions 4.3, 4.4, and 5.3 are satisï¬ed, f = (1 + Î³)w âˆ’d2
2, and D: (x, y) â†’
Î³w(x âˆ’y) + w(x âˆ’PMy) âˆ’w(x âˆ’PMx).
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
Example 5.10 (energy).
In the previous example, set M = {0} and Î³ = 1.
Then f = âˆ¥Â· âˆ¥2/2, âˆ‡f = Id, D: (x, y) â†’âˆ¥x âˆ’yâˆ¥2/2, and we recover the usual FejÂ´er
monotonicity framework.
The next example shows that the function f = âˆ¥Â· âˆ¥2/2 can also be used outside
Hilbert spaces.
Example 5.11 (Lp spaces). Let (â„¦, F, Âµ) be a positive measure space and let p âˆˆ
[2, +âˆ[. Let X = Lp(â„¦, F, Âµ), equipped with its canonical norm, and set f = âˆ¥Â· âˆ¥2/2.
Then Conditions 4.4 and 5.3 are satisï¬ed. If S is a singleton, then Condition 4.3 is
also satisï¬ed.
Proof. By [8, Example 6.5], f is Legendre and uniformly convex on closed balls.
Hence Condition 4.4 holds by Example 4.10(i).
Since f is supercoercive, Condition 5.3(i) follows from [8, Lemma 7.3(viii)]. We now establish Condition 5.3(ii). As
p âˆˆ[2, +âˆ[, [45, Corollary V.1.2] implies that Ïâˆ¥Â·âˆ¥, the modulus of smoothness of X,
is of power type 2. We thus obtain Îº âˆˆ]0, +âˆ[ so that (see [45, section IV.4])
(âˆ€t âˆˆ[0, +âˆ[)
Ïâˆ¥Â·âˆ¥(t) â‰¤Îºt2.
Recall that âˆ‡f = J and deï¬ne j(x) = J(x)/âˆ¥xâˆ¥= âˆ‡âˆ¥xâˆ¥for all nonzero x âˆˆX. Now
(5.41) and [45, Lemma IV.5.1] yield
(âˆ€u âˆˆSX )(âˆ€v âˆˆSX )
âˆ¥j(u) âˆ’j(v)âˆ¥â‰¤Îºâˆ¥u âˆ’vâˆ¥.
Fix two nonzero points x and y in X and assume, without loss of generality, that
âˆ¥xâˆ¥â‰¥âˆ¥yâˆ¥. Then, using the triangle inequality,
+ âˆ¥yâˆ¥Â· y âˆ’âˆ¥xâˆ¥Â· y
âˆ¥xâˆ¥âˆ¥x âˆ’yâˆ¥.
âˆ¥j(x) âˆ’j(y)âˆ¥=
âˆ¥xâˆ¥âˆ¥x âˆ’yâˆ¥,
where we have used the deï¬nition of j for the equality, (5.42) for the ï¬rst inequality,
and (5.43) for the second. Furthermore,
âˆ¥J(x) âˆ’J(y)âˆ¥=
âˆ¥xâˆ¥Â· j(x) âˆ’âˆ¥yâˆ¥Â· j(y)
âˆ¥xâˆ¥Â· j(x) âˆ’âˆ¥xâˆ¥Â· j(y)
âˆ¥xâˆ¥Â· j(y) âˆ’âˆ¥yâˆ¥Â· j(y)
â‰¤âˆ¥xâˆ¥Â· âˆ¥j(x) âˆ’j(y)âˆ¥+ âˆ¥j(y)âˆ¥Â·
â‰¤(2Îº + 1) Â· âˆ¥x âˆ’yâˆ¥,
where the last inequality follows from (5.44) and the fact that âˆ¥j(y)âˆ¥= 1. Now (5.45)
implies that J = âˆ‡f is Lipschitz-continuous on dom f = X, with constant 2Îº + 1
(for x = 0 or y = 0, argue directly). We apply Proposition 5.5(ii) and conclude that
Condition 5.3(ii) is satisï¬ed. Finally, if S is a singleton, we employ Example 4.5.
Guaranteeing Condition 4.3 requires some care.
Remark 5.12. As already discussed in Remark 5.6, Proposition 5.5(i) holds as
soon as âˆ‡f is Lipschitz on bounded sets.
Thus, the assertions of Example 5.11
remain true for f = âˆ¥Â· âˆ¥s/s, where s âˆˆ[2, +âˆ[. The case when s = p is particularly
interesting because then âˆ‡f becomes JÏ•, the duality mapping corresponding to the
weight Ï•: t â†’tpâˆ’1 (see ). If we specialize this further to the space â„“p(N), then
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
H. H. BAUSCHKE, J. M. BORWEIN, AND P. L. COMBETTES
JÏ• is known to be sequentially weakly continuous (see [34, Prop. II.4.14]) and thus
Example 4.6 is applicable. To sum up,
let X = â„“p(N) and f = âˆ¥Â· âˆ¥p/p, for p âˆˆ[2, +âˆ[ ;
then Conditions 4.3, 4.4, and 5.3 are satisï¬ed.
Additional examples can be generated in suitable product spaces such as â„“p1(N) Ã—
â„“p2(N), equipped with the Euclidean product norm and with {p1, p2} âŠ‚[2, +âˆ[, or in
certain spaces of power type 2. (See for further information about such spaces.)
Example 5.13 (closed domain Bregman/Legendre functions). Let X = RN and
let f be a Bregman/Legendre function with closed domain. Then Conditions 4.3, 4.4,
and 5.3 are satisï¬ed.
Proof. Example 4.9 implies that Condition 4.3 holds. Condition 4.4 follows from
[7, Def. 5.2.BL3 and Thm. 3.9(iii)]. It remains to check items (i) and (ii) in Condition 5.3: since D(z, Â·) is coercive for every z âˆˆdom f [7, Remark 5.3], (i) holds,
whereas (ii) follows from Proposition 5.5(iv).
The class of Bregman/Legendre functions (see Deï¬nition 4.8) is large enough to
contain many functions important in convex optimization and it is related to the
Bregman functions of , which require closed domains. We refer the reader to
 for further information. The following example gives conditions that are easy to
verify in practice.
Example 5.14 (separable Bregman/Legendre functions). Let (Ï•k)1â‰¤kâ‰¤N : R â†’
]âˆ’âˆ, +âˆ] be a family of Legendre functions such that (dom Ï•âˆ—
k)1â‰¤kâ‰¤N are open. Let
X = RN, and let f : (Î¾k)1â‰¤kâ‰¤N â†’N
k=1 Ï•k(Î¾k). Then Conditions 4.3, 4.4, and 5.3
are satisï¬ed.
Proof. By [7, Corollary 5.13], f is Bregman/Legendre. Mimicking the proof of
the previous example, we note that it remains to check Condition 4.4.
k âˆˆ{1, . . . , m}, since Ï•k|int dom Ï•k is strictly convex by Legendreness and Ï•k|dom Ï•k
is continuous by (3.5), Ï•k|dom Ï•k is strictly convex. Hence, it follows from Example 4.10(iii) that the Bregman distance Dk induced by Ï•k on R satisï¬es Condition 4.4
and, in turn, so does D:
(Î¾k)1â‰¤kâ‰¤N, (Ï‡k)1â‰¤kâ‰¤N
k=1 Dk(Î¾k, Ï‡k).
Unlike the previous examples, the following example does not require that X be
ï¬nite-dimensional or that f have full domain.
Example 5.15. Let X be the Hilbert space â„“2(N) Ã— R and deï¬ne
f : X â†’]âˆ’âˆ, +âˆ] : (x, Î¾) â†’
2âˆ¥xâˆ¥2 + Î¾ ln(Î¾) âˆ’Î¾
Let (âˆ€i âˆˆI) Si = S = â„“2(N) Ã— [1, +âˆ[.
Fix (z, Î¶) âˆˆS, Î· > 0, and set C =
. Then Conditions 4.3, 4.4, and 5.3 are satisï¬ed.
Proof. Let g = f(Â·, 0) and h = f(0, Â·). Hence, (âˆ€(x, Î¾) âˆˆX) f(x, Î¾) = g(x) + h(Î¾).
Note that g and h are Legendre, and so is f, with dom f = â„“2(N) Ã— [0, +âˆ[. Now,
let Dg and Dh be the Bregman distances induced by g on â„“2(N) and h on R, respectively.
Take (y, Ï‡) âˆˆX with D
(z, Î¶), (y, Ï‡)
= Dg(z, y) + Dh(Î¶, Ï‡) â‰¤Î·.
particular, Dg(z, y) â‰¤Î· and Dh(Î¶, Ï‡) â‰¤Î·. Since Dg(z, Â·) and Dh(Î¶, Â·) are coercive
by Proposition 4.1(v)(a) and (b), C is bounded. Condition 4.3 is a consequence of
Example 4.6. Since D: (x, Î¾) â†’Dg(x) + Dh(Î¾), Condition 4.4 is immediate by Examples 5.10 and 5.13. Applying [7, Thm. 3.8.(i)] to h and Î¶ âˆˆint dom h, we obtain
Îµ âˆˆ]0, +âˆ[ such that (âˆ€(y, Ï‡) âˆˆC) Ï‡ â‰¥Îµ. A straightforward computation shows
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
that âˆ‡f âˆ—is strongly monotone with constant min{1, Îµ}. Therefore, using Proposition 5.5(iv), Condition 5.3(ii) holds as well and the proof is complete.
5.5. Applications. A broad class of problems in convex optimization and nonlinear analysis are captured by the mixed convex feasibility problem
Find x âˆˆdom f such that
(âˆ€i âˆˆI(1))
(âˆ€i âˆˆI(2))
(âˆ€i âˆˆI(3))
Ï•i(x) = inf Ï•i(X),
(âˆ€i âˆˆI(4))
where (gi)iâˆˆI(1) and (Ï•i)iâˆˆI(3) are families of proper lower semicontinuous convex
functions from X into ]âˆ’âˆ, +âˆ], (Ai)iâˆˆI(2) is a family of maximal monotone operators
from X into 2X âˆ—, and (Ti)iâˆˆI(4) is a family of D-ï¬rm operators from X into X. Here,
I(1), I(2), I(3), and I(4) are pairwise disjoint, possibly empty, countable index sets
such that I = 4
k=1 I(k) Ì¸= Ã˜. Now let us deï¬ne
(âˆ€i âˆˆI) Si =
if i âˆˆI(1),
if i âˆˆI(2),
if i âˆˆI(3),
if i âˆˆI(4).
Throughout this section, the following set of assumptions will be made.
Condition 5.16.
(i) Conditions 4.3, 4.4, 5.3, and 5.4 are satisï¬ed.
(ii) For every i âˆˆI(1), âˆ‚gi(C) is bounded and dom f âŠ‚dom gi.
(iii) For every i âˆˆI(2), one of the following conditions holds:
(a) dom Ai âŠ‚int dom f,
(b) Ai is 3âˆ—-monotone.
(iv) For every i âˆˆI(4), dom Ti = int dom f and Ti âˆ’Id is demiclosed at 0 in the
sense that for every sequence (yn)nâˆˆN in dom Ti
(âˆ€n âˆˆN) un âˆˆTiyn,
y âˆˆFix Ti.
Let us observe that the sets (Si)iâˆˆI are closed and convex. For i âˆˆI(1)âˆªI(2)âˆªI(3),
this follows from well-known facts; for i âˆˆI(4), this follows from Condition 5.16(iv),
Propositions 3.5(ii), the essential strict convexity of f, and Proposition 3.3(v). Accordingly, (5.47) is a special case of the convex feasibility problem (5.2) and it can
therefore be solved by Algorithm 5.1.
Algorithm 5.17 (speciï¬c implementation of Algorithm 5.1). Fix (Îµi)iâˆˆI(2) and
(Îµi)iâˆˆI(3) in ]0, +âˆ[. Implement Algorithm 5.1âby choosing for every i âˆˆIn
if i âˆˆI(1) (see Deï¬nition 3.37),
RÎ³i,nAi, where Î³i,n âˆˆ[Îµi, +âˆ[
if i âˆˆI(2) (see Deï¬nition 3.7),
Î³i,n, where Î³i,n âˆˆ[Îµi, +âˆ[
if i âˆˆI(3) (see Deï¬nition 3.16),
if i âˆˆI(4) (see Deï¬nition 3.4).
Thanks to Condition 5.16, (5.50) meets the requirements of Algorithm 5.1âsince
in each case we have the following:
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
H. H. BAUSCHKE, J. M. BORWEIN, AND P. L. COMBETTES
â€¢ Ti,n âˆˆB.
This follows from Proposition 3.38(ii) if i âˆˆI(1), from Corollary 3.14(ii) and (iii) if i âˆˆI(2) (since Aâˆ’1
i 0 âˆ©int dom f Ì¸= Ã˜, dom Ai âˆ©
int dom f Ì¸= Ã˜), from Corollary 3.25(i) if i âˆˆI(3) (since Ï•i is proper and
Argmin Ï•iâˆ©int dom f Ì¸= Ã˜, Ï•i is bounded below and dom Ï•iâˆ©int dom f Ì¸= Ã˜),
and from Proposition 3.5(ii) if i âˆˆI(4).
â€¢ Siâˆ©int dom f âŠ‚Fix Ti,n. (See Proposition 3.38(i), Proposition 3.8(iii), Proposition 3.22(ii)(b), and Proposition 3.3(iv) and (vii), respectively.)
Theorem 5.18. Suppose that Condition 5.16 is in force and let (xn)nâˆˆN be an
arbitrary orbit of Algorithm 5.17. Then (xn)nâˆˆN converges weakly to a point x âˆˆS.
The convergence is strong if x âˆˆint dom f and any of the following assumptions is
(i) For some i âˆˆI(1) and some Î· âˆˆ]0, +âˆ[, C âˆ©levâ‰¤Î· gi is relatively compact.
(ii) For some i âˆˆI(2), C âˆ©dom Ai is relatively compact.
(iii) For some i âˆˆI(3), C âˆ©dom âˆ‚Ï•i is relatively compact.
(iv) For some i âˆˆI(4), Ti is demicompact at 0 in the sense that for every sequence
(yn)nâˆˆN in dom Ti
(yn)nâˆˆN bounded,
(âˆ€n âˆˆN) un âˆˆTiyn,
S(yn)nâˆˆN Ì¸= Ã˜.
Proof. As seen above, (5.47) is a special case of (5.2), whereas Algorithm 5.17
is a special case of Algorithm 5.1. Invoking Theorem 5.7, we shall prove that Algorithm 5.17 is focusing to establish the weak convergence claim and then that it is
demicompactly regular to establish the strong convergence claim. It is recalled that
Theorem 5.7 asserts that (xn)nâˆˆN and
(ui,n)iâˆˆIn
nâˆˆN lie in the bounded set C.
To show that Algorithm 5.17 is focusing, let us ï¬x i âˆˆI and a suborbit (xkn)nâˆˆN
such that i âˆˆ
nâˆˆN Ikn, xkn â‡€x, and ui,kn âˆ’xkn â†’0. According to (5.10), we must
show x âˆˆSi. Four cases will be considered:
(1) i âˆˆI(1). We must show gi(x) â‰¤0. In view of (5.50), for every n âˆˆN, ui,kn is
the D-projection of xn onto Gi(xkn, xâˆ—
y âˆˆX | âŸ¨xkn âˆ’y, xâˆ—
nâŸ©â‰¥gi(xkn)
for some xâˆ—
n âˆˆâˆ‚gi(xkn). Since ui,kn âˆˆGi(xkn, xâˆ—
n), we have
âˆ¥ui,kn âˆ’xknâˆ¥â‰¥dGi(xkn,xâˆ—
i (xkn)/âˆ¥xâˆ—
otherwise,
i = max{0, gi} and the last equality follows from [80, Lemma I.1.2].
Since (xkn)nâˆˆN lies in C, (xâˆ—
n)nâˆˆN is bounded by Condition 5.16(ii). Therefore, ui,kn âˆ’xkn â†’0 implies g+
i (xkn) â†’0. However, as g+
is convex and
lower semicontinuous, it is weak lower semicontinuous and thus g+
i (xkn) = 0. We conclude gi(x) â‰¤0.
(2) i âˆˆI(2).
We must show (x, 0) âˆˆgr Ai.
For every n âˆˆN, (5.50) yields
ui,kn âˆˆ(âˆ‡f + Î³i,knAi)âˆ’1
and we deï¬ne
n = âˆ‡f(xkn) âˆ’âˆ‡f(ui,kn)
(ui,kn, uâˆ—
nâˆˆN lies in gr Ai and ui,kn âˆ’xkn â†’0 â‡’ui,kn â‡€x. If
for all n suï¬ƒciently large we have xkn = ui,kn, then by Proposition 3.8(iii) the
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
tail of (xkn)nâˆˆN is in the weakly closed set Aâˆ’1
i 0 and therefore (x, 0) âˆˆgr Ai.
Otherwise, we can extract a subsequence (xkln)nâˆˆN such that, for all n âˆˆN,
xkln Ì¸= ui,kln. Since, on the one hand, (xkln)nâˆˆN and (ui,kln)nâˆˆN lie in C and,
on the other hand,
(âˆ€n âˆˆN) âˆ¥ui,kln âˆ’xklnâˆ¥â‰¥
ui,kln âˆ’xkln, âˆ‡f(ui,kln) âˆ’âˆ‡f(xkln)
âˆ¥âˆ‡f(ui,kln) âˆ’âˆ‡f(xkln)âˆ¥
it follows from Condition 5.3(ii), (5.53), and the inequality infnâˆˆN Î³i,kln â‰¥Îµi
that ui,kln âˆ’xkln â†’0 â‡’âˆ‡f(ui,kln) âˆ’âˆ‡f(xkln) â†’0 â‡’uâˆ—
ln â†’0. Finally,
since Ai is maximal monotone, gr Ai is sequentially closed in the weak Ã—
strong topology of X Ã— X âˆ—and we conclude that (x, 0) âˆˆgr Ai, as required.
(3) i âˆˆI(3).
We must show Ï•i(x) = inf Ï•i(X), i.e., (x, 0) âˆˆgr âˆ‚Ï•i.
Ï• is a proper lower semicontinuous convex function, Ai = âˆ‚Ï•i is maximal
monotone [79, section 29] and 3âˆ—-monotone by Lemma 3.10(iv), and, in view
of Propositions 3.22(ii)(a) and 3.23(v)(b), the claim follows from case (2).
(4) i âˆˆI(4). We must show x âˆˆFix Ti. This follows at once from (5.49).
It remains to show that in each instance (i)â€“(iv), i is an index of demicompact regularity. Henceforth, (xkn)nâˆˆN is a suborbit such that i âˆˆ
nâˆˆN Ikn and ui,kn âˆ’xkn â†’0.
By (5.11), we must show S(xkn)nâˆˆN Ì¸= Ã˜.
(i) Arguing as in case (1), we obtain
lim gi(xkn) â‰¤0. Therefore, the tail of (xkn)nâˆˆN lies in the compact set C âˆ©levâ‰¤Î· gi,
whence S(xkn)nâˆˆN Ì¸= Ã˜. (ii) It follows from (3.16) that for every n âˆˆN
ui,kn âˆˆC âŠ‚int dom f,
ui,kn âˆˆran(âˆ‡f + Î³i,knAi)âˆ’1 â—¦âˆ‡f âŠ‚dom âˆ‡f âˆ©dom Ai = int dom f âˆ©dom Ai.
Therefore, (ui,kn)nâˆˆN lies in the compact set C âˆ©dom Ai, whence S(ui,kn)nâˆˆN Ì¸= Ã˜.
Since ui,kn âˆ’xkn â†’0, we conclude S(xkn)nâˆˆN Ì¸= Ã˜. (iii) As in case (3), this is a
special case of (ii). (iv) This is clear from (5.51).
Theorem 5.18 produces convergence results for various new block-iterative parallel schemes for solving problems, including solving convex inequalities (I(2) = I(3) =
I(4) = Ã˜), ï¬nding common zeros (I(1) = I(3) = I(4) = Ã˜), solving systems of variational inequalities (I(1) = I(2) = I(4) = Ã˜), ï¬nding common ï¬xed points (I(1) =
I(2) = I(3) = Ã˜), and combinations of these. Note that D-projection methods are
also captured by Theorem 5.18 since, in view of Proposition 3.32(ii)(c), one can take,
for instance, Ti to be the D-projector onto Si if i âˆˆI(4) in (5.50).
Naturally, our framework also encompasses relaxed sequential algorithms, which
are obtained by taking (In)nâˆˆN to be a sequence of singletons, as in the following
Example 5.19. Suppose X = RN, (Si)1â‰¤iâ‰¤m is a (ï¬nite) family of half-spaces
with D-projectors (Pi)1â‰¤iâ‰¤m, and, for every n âˆˆN, In = {n (mod m) + 1} and
Ti,n = Pi. Then Algorithm 5.1 reduces to the relaxed D-projection method of .
In the case of unrelaxed sequential algorithms, our working assumptions can be
loosened. This is discussed next.
5.6. Unrelaxed sequential algorithms. Algorithm 5.1 can be specialized to
an unrelaxed sequential algorithm for solving the convex feasibility problem (5.2).
Indeed, suppose that at each iteration n only one index, say i(n), is retained and
Î»n = 1. Then Algorithm 5.1â‡becomes
y âˆˆX | âŸ¨y âˆ’un, âˆ‡f(xn) âˆ’âˆ‡f(un)âŸ©â‰¤0
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
H. H. BAUSCHKE, J. M. BORWEIN, AND P. L. COMBETTES
where un âˆˆTnxn for some Tn âˆˆB such that Si(n)âˆ©int dom f âŠ‚Fix Tn. Consequently,
since by Corollary 3.35(ii) PHnxn = un, Algorithm 5.1 can be rewritten as follows.
Algorithm 5.20. Starting with x0 âˆˆint dom f, take at every iteration n
â€an index i(n) âˆˆI,
âan operator Tn in B such that Si(n) âˆ©int dom f âŠ‚Fix Tn.
Then select xn+1 âˆˆTnxn.
In this context, Deï¬nition 5.2 takes the following form.
Definition 5.21. Algorithm 5.20 is
â€¢ focusing if for every bounded suborbit (xkn)nâˆˆN it generates and every index
(âˆ€n âˆˆN) i = i(kn),
xkn+1 âˆ’xkn â†’0
â€¢ demicompactly regular if there exists i âˆˆI, called an index of demicompact
regularity, such that for every bounded suborbit (xkn)nâˆˆN it generates,
(âˆ€n âˆˆN) i = i(kn),
xkn+1 âˆ’xkn â†’0
S(xkn)nâˆˆN Ì¸= Ã˜.
Removing item (ii) from Condition 5.3 yields the following set of assumptions for
the unrelaxed sequential case.
Condition 5.22.
For some z âˆˆdom f âˆ©
iâˆˆI Si, C = levâ‰¤D(z,x0) D(z, Â·) is
Condition 5.23. (âˆ€i âˆˆI)(âˆƒMi âˆˆNâˆ–{0})(âˆ€n âˆˆN) i âˆˆ
i(n), . . . , i(n+Miâˆ’1)
We now show that Algorithm 5.20 converges under this reduced set of assumptions.
Theorem 5.24. Suppose that Conditions 4.3, 4.4, 5.22, and 5.23 are satisï¬ed
and that Algorithm 5.20 is focusing. Then the following statements hold true for every
orbit (xn)nâˆˆN generated by Algorithm 5.20:
(i) (xn)nâˆˆN converges weakly to a point x âˆˆS.
(ii) If the weak limit x from (i) belongs to int dom f and the algorithm is demicompactly regular, then (xn)nâˆˆN converges strongly.
Proof. In the proof of Theorem 5.7, note that Condition 5.3(ii) is used only to
obtain (5.34), i.e., in the present context, xpn+1 âˆ’xpn â†’0. However, this property
follows directly from(5.33).
As an example, we revisit Bregmanâ€™s original cyclic projection method (1.2). (See
[1, Thm. 3.1] for a special case.)
Corollary 5.25. Suppose that Conditions 4.3 and 4.4 are satisï¬ed, that I =
{1, . . . , m}, and that C = levâ‰¤D(z,x0) D(z, Â·) is bounded for some z âˆˆdom f âˆ©
Let (Pi)1â‰¤iâ‰¤m be the D-projectors of (Si)1â‰¤iâ‰¤m.
Then the following
statements hold true for every orbit (xn)nâˆˆN generated by (1.2):
(i) (xn)nâˆˆN converges weakly to a point x âˆˆdom f âˆ©
(ii) If the weak limit x from (i) belongs to int dom f and C âˆ©Si is relatively compact (e.g., Si is boundedly compact) for some i âˆˆ{1, . . . , m}, then (xn)nâˆˆN
converges strongly.
Proof. In view of Corollary 3.35(i), (1.2) is a special realization of Algorithm 5.20
with (âˆ€n âˆˆN) Tn = Pn (mod m)+1 (single-valued) and Î»n = 1. In addition, the index
Downloaded 06/03/13 to 134.148.10.13. Redistribution subject to SIAM license or copyright; see 
BREGMAN MONOTONE OPTIMIZATION ALGORITHMS
control rule i: n â†’n (mod m) + 1 complies with Condition 5.23. On the other hand,
algorithm (1.2) is focusing, as a direct consequence of the weak closedness of the sets
(Sj)1â‰¤jâ‰¤m. Finally, i is an index of demicompact regularity since (xnm+i)nâˆˆN lies in
C âˆ©Si. The announced results therefore follow from Theorem 5.24.
Remark 5.26. Throughout section 5, Legendreness has been imposed on f. This
property has been shown to provide a rich and convenient framework in which our
results could be derived in a uniï¬ed manner.
Further results can nonetheless be
obtained from the analysis of sections 3 and 4 for functions which are not Legendre
at the expense of more technical assumptions.
Acknowledgments. We wish to thank Dan Butnariu and Yair Censor for sending us , Constantin ZË˜alinescu for sending us , and especially Jon
Vanderwerï¬€for his help in the derivation of Example 5.11. Two anonymous referees
made several helpful comments and suggestions, which led to improvements over the
originally submitted version.