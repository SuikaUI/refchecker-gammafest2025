Spectral Segmentation with Multiscale Graph Decomposition
Timoth´ee Cour1
Florence B´en´ezit2
Jianbo Shi3
1,3Computer and Information Science
2Applied Mathematics Department
University of Pennsylvania
Ecole Polytechnique
Philadelphia, PA 19104
91128 Palaiseau Cedex, FRANCE
 
 
We present a multiscale spectral image segmentation algorithm. In contrast to most multiscale image processing,
this algorithm works on multiple scales of the image in parallel, without iteration, to capture both coarse and ﬁne level
details. The algorithm is computationally efﬁcient, allowing
to segment large images. We use the Normalized Cut graph
partitioning framework of image segmentation. We construct a graph encoding pairwise pixel afﬁnity, and partition the graph for image segmentation. We demonstrate that
large image graphs can be compressed into multiple scales
capturing image structure at increasingly large neighborhood. We show that the decomposition of the image segmentation graph into different scales can be determined by
ecological statistics on the image grouping cues. Our segmentation algorithm works simultaneously across the graph
scales, with an inter-scale constraint to ensure communication and consistency between the segmentations at each
scale. As the results show, we incorporate long-range connections with linear-time complexity, providing high-quality
segmentations efﬁciently. Images that previously could not
be processed because of their size have been accurately segmented thanks to this method.
1. Introduction
There are two things you could do to make image segmentation difﬁcult: 1) camouﬂage the object by making its
boundary edges faint, and 2) increase clutter by making
background edges highly contrasting, particularly those in
textured regions. In fact, such situations arise often in natural images, as animals have often evolved to blend into their
environment.
Several recent works have demonstrated that multiscale
image segmentation can produce impressive segmentation
results under these difﬁcult conditions. Sharon, et. al. 
uses an algebraic multi-grid method for solving the normalized cut criterion efﬁciently, and uses recursive graph coarsening to produce irregular pyramid encoding region based
grouping cues. Yu constructs a multiple level graph encoding edge cues at different image scales, and optimizes
the average Ncut cost across all graph levels. Zhu et. al. 
explicitly controls the Markov chain transitions in the space
of graph partitions by splitting, merging and re-grouping
segmentation graph nodes.
We argue that there are in fact three orthogonal issues
in multiscale image segmentation: 1) multiscale signal processing to enhance faint contours ; 2) image region
similarity cues at multiple scales provides texture/shape
cues for larger regions; 3) propagation of local grouping
cues across multiple ranges of spatial connections allows us
to detect coherent regions with faint boundary.
Sharon , Zhu ’s approaches focus on the last two issues, and Yu focuses on the ﬁrst and third. The primary
motivation underlying all these approaches is that local information propagates faster with long range connections
across image regions, and computation converges faster
both in graph partitioning and MRF probabilistic formulation. Both Sharon and Zhu advocated data driven adaptive coarsening of an image region/segmentation graph as
an essential step in multiscale segmentation. This conclusion is partly justiﬁed by the failure of most multiscale segmentation algorithms which use simple geometric
coarsening of images: typically ﬁne level details along object boundaries are lost due to coarsening error.
We focus on the third issue of multiscale propagation of
grouping cues in isolation. We show that simple geometric coarsening of the image region/segmentation graph can
work for multiscale segmentation. The key principle is that
segmentation across different spatial scales should be processed in parallel. We specify the constraint that segmentation must be self-consistent across the scales. This constraint forces the system to seek an “average” segmentation
across all scales. We show our multiscale segmentation algorithm can precisely segment objects with both ﬁne and
coarse level object details.
The advantage of graphs with long connections comes
with a great computational cost. If implemented naively,
segmentation on a fully connected graph G of size N would
require at least O(N 2) operations. This paper develops an
efﬁcient computation method of multiscale image segmentation in a constrained Normalized cuts framework. We
show that multiscale Normalized cuts can be computed in
linear time.
This paper is organized as follows. In section 2, we review the basics of graph based image segmentation. In section 3 and 4, we show how to compress a large fully connected graph into a multiscale graph with O(N) total graph
weights. In section 5, 6, we demonstrate efﬁcient optimization of multiscale spectral graph partitioning with O(N)
running time. We conclude with experiments in section 7.
2. Graph based image segmentation
Given an image I, we construct a graph G = (V, E, W),
with the pixels as graph nodes V , and pixels within distance ≤Gr are connected by a graph edge in E. A weight
value W(i, j) measures the likelihood of pixel i and j belonging to the same image region. Partitioning on this graph
provides image regions segmentation.
2.1. Encoding Graph Edges
The overall quality of segmentation depends on the pairwise pixel afﬁnity graph. Two simple but effective local
grouping cues are: intensity and contours.
Intensity Close-by pixels with similar intensity value are
likely to belong to one object:
WI(i, j) = e−||Xi−Xj||2/σx−||Ii−Ij||2/σI
where Xi and Ii denote pixel location and intensity. Connecting pixels by intensity is useful to link disjoint object
parts. But because of texture clutter, the intensity cue alone
often gives poor segmentations.
Intervening Contours Image edges signal a potential object
boundary. It is particularly useful when background clutter has similar intensity value with object body. We evaluate the afﬁnity between two pixels by measuring the magnitude of image edges between them:
WC(i, j) = e−maxx∈line(i,j)||Edge(x)||2/σC
where line(i, j) is a straight line joining pixels i and j, and
Edge(x) is the edge strength at location x. Fig. 1 shows
graph weights W(i, :) for a ﬁxed pixel i. At coarse image
scales, texture edges tend to be blurred out and suppressed,
while at ﬁne image scales faint elongated edges are more
likely to be detected, together with texture edges. To de-
ﬁne the afﬁnity between two pixels i and j we look at the
edges across multiple scales.
We can combine the two cues with WMixed(i, j) =
WI(i, j) × WC(i, j) + αWC(i, j).
Figure 1: Column 1 and 2: image and image edges. Column 3
and 4: segmentation graph encoding intervening contour grouping cue. Two pixels have high afﬁnity if the straight line connecting them does not cross an image edge. Column 3 displays one
row WC(i, :) of the graph connection matrix reshaped as an image, for the central pixel i. The row corresponds to the red line on
2.2. Computing Optimal Normalized Cuts
bipartition
Normalized
Ncut(A, B) =
V olume(A)×V olume(B). We can rewrite it
using binary group indicator function Xl
with Xl(i)
1 iff pixel i belongs to segment l.
[X1, X2], D be a diagonal matrix where
D(i, i) = P
j W(i, j). The segmentation criterion amounts
to the following:
maximize ϵ(X) = 1
subject to X ∈{0, 1}N×2 and X12 = 1N (1N is a vector
of N ones). A generalized K-way Ncut cost function can be
similarly deﬁned using X = [X1, . . . , XK]. Finding the optimal Ncut graph partitioning is NP hard. A spectral graph
partitioning technique allows us to solve this problem using a continuous space solution by computing the K eigenvectors corresponding to the K largest eigenvalues in:
To discretize V into X, we ﬁrst normalize the rows of V
into V ′, and then search for the rotation R that brings V ′
the closest possible to a binary indicator vector X.
3. How large of a graph connection radius?
The construction of our image segmentation graph thus
far has focused on encoding grouping cues to compute the
graph weights W(i, j). We turn our attention to the graph
topology. Recall that two pixels are connected in a graph if
they are within distance Gr. How big should the graph connection radius Gr be ?
A larger graph radius Gr generally makes segmentation
better. Long range graph connections facilitate propagation
of local grouping cues across larger image regions. This effect allows us to better detect objects with faint contours in
a cluttered background, as shown in ﬁg. 2.
Figure 2: The Ncut segmentation eigenvector of the left image for
increasingly large graph connection radius Gr. With larger Gr, the
squirrel with faint contours pops out more clearly, but the graph
afﬁnity matrix becomes denser. The bottom row shows zoomed
out versions of the afﬁnity matrices.
Smaller Gr generally makes segmentation faster. The
graph weight matrix grows rapidly with rate of O(G2
computing the Ncut eigenvectors, the overall running time
is dominated by two factors: 1) the cost of matrix-vector
multiplication y := Wx (which can be thought of as a local anisotropic diffusion on partitioning function x), and 2)
the number of iterations, or number of matrix-vector multiplications until convergence. For faster computation, we
want to minimize the number of iterations and make each iteration faster. However, as the following experiment (ﬁg. 3)
shows, setting Gr small does not necessarily make the overall Ncut optimization faster. As we see in ﬁg. 3, there is a
tradeoff between the number of eigensolver iterations, and
the size of Gr. It appears there is a minimum required connection radius. A graph with a too small connection radius
requires a lot of diffusion operations y := Wx to propagate local grouping cues across larger neighborhood.
4. Compression of long range connection
The ideal graph connection radius Gr is a tradeoff between the computation cost, and segmentation result. We
will show that we can alleviate this tradeoff by providing an
efﬁcient segmentation algorithm which can effectively have
a very large Gr. We do so by decomposing the long range
connection graph into independent subgraphs.
Figure 3: We compute Ncut segmentation eigenvectors for graphs
with increasing connection radius Gr for the squirrel image in
Fig. 2. The number of eigensolver iterations and total running
time (sec) as a function of graph radius Gr. The number of eigensolver iterations is high for small Gr, and decreases steadily until
Gr = 7. The total running time remains constant until Gr = 5 despite rapid increase in the cost of y := Wx.
4.1. Statistics of Segmentation Graph Weights
Consider the following experiment. We extract 60 × 60
patches from 200 randomly selected images. For each image patch Pk, we use the intervening contour cue to compute W Pk(i, j) = W Pk
C (i, j) for the central pixel i and all
possible j. We estimate the following statistical measures:
Ave[W(i, j)] =
k=1 W Pk(i, j), shown in Fig. 4(a).
As expected, the average afﬁnity between two pixels i
and j at distance rij = ||Xi −Xj|| decreases exponentially fast as a function of rij. This can be explained.
If pedge is the probability that an edge does not fall between two adjacent pixels, the probably that i and j are not
separated by an image edge is theoretically prij
V ar[W(i, j)] =
k=1 |W Pk(i, j) −Ave[W(i, j)]|2,
shown in Fig. 4(b). Overall, as a function of rij, the graph
variance approximates a Laplacian. For short range connections (rij ≤3), the pair-wise afﬁnity has low variance
across image patches. As pair-wise pixel separation rij increases, the variance in graph afﬁnity increases quickly
= 13. For long range connections, the variance drops back to zero. This implies that for very short
and very long range connections, the W(i, j) are more predictable between the images, than those of mid-range
connections. Therefore, the mid-range connections contain most information of the image structure.
3) Variance of graph weights across small neighborhood.
For a pair of pixels i, j with r pixels apart, we take two
balls of radius R, Bi and Bj around i and j. We measure
the variance of graph weights W Pk(i′, j′) for all (i′, j′) ∈
Bi × Bj, denoted as V arW Pk(Bi, Bj), and average it
across all image patches and all i, j with r pixels apart:
V arW(r) =
k=1 Avei,j:rij=rV arW Pk(Bi, Bj), as
W(icenter,j)
(a) Ave[W(i,j)]
(b) Var[W(i,j)]
(c) VarW(r)
(e) Graph Coarsing
W(icenter,j)
(d) Log(VarW(r))
W(icenter,j)
Figure 4: Statistics of graph weights on natural images. Top row: we use intervening contour cue to compute graph weights for randomly
selected image patches across 200 images. For a ﬁxed pixel i, we estimate average graph weight W(i, j) in (a), variance of W(i, j) across
images in (b), and variance of each graph edge W(i, j) across a small neighborhood R of the edge as a function of spatial separation
r = rij, in (c), (d). Distant pixels are more likely to be disconnected by an image contour far from both pixels. Together, these facts allow
us to create a multiscale decomposition of large radius graph connections by “condensing” close-by edge weights (i, j) and (i′, j′), (e).
shown in Fig. 4(c,d). V arW(r) decreases exponentially fast
as a function of spatial separation r! For short range graph
edges, it is hard to predict neighboring afﬁnities around
graph edge (i, j) from a particular afﬁnity W(i, j). As
spatial separation increases, the afﬁnity variations decrease
quickly, indicating one can potentially predict graph edge
weights in its neighborhood using one representative edge
connection.
In summary, statistical measurements of the intervening contour image segmentation graph reveal three facts: 1)
graph edge weights decrease exponentially fast with pairwise pixel separation; 2) across the images, the mid-range
graph edges are most un-predictable, therefore contain most
relevant grouping information; 3) the variations in graph
weights across a small neighborhood of graph edge (i, j)
decrease exponentially fast with the pixel separation rij,
implying that longer range graph connections have more redundant information with their nearby connections, therefore can be compressed.
4.2. Decomposition of graph into multiple scales
Our empirical estimation of Graph mean and Graph
variance indicates that at different ranges of spatial separations rij, the graph afﬁnity W(i, j) exhibits very different
characteristics. Therefore, we can separate the graph links
into different scales according to their underlying spatial
separation:
W = W1 + W2 + ... + WS,
where Ws contains afﬁnity between pixels with certain spatial separation range: Ws(i, j) ̸= 0 only if Gr,s−1 < rij ≤
Gr,s. This decomposition allows us to study behaviors of
graph afﬁnities at different spatial separations.
Furthermore, afﬁnity variation V arW(r) decreases
quickly, implying that, at a given scale, one can potentially “condense” pixels in a small neighborhood into
representative pixels, and store only the afﬁnity between those pixels. More importantly, the exponential decay of V arW(r) implies we can condense pixels very aggressively, at exponential rate, as we increase the graph
connection radius. Therefore even though the non-zero elements in Ws grow quadratically with s, we can represent
Ws more efﬁciently with fewer representative connections.
How do we determine representative pixels at graph
scale Ws? For the ﬁrst graph scale W1, we take every pixel
as graph node, and connect pixels within r distance apart
by a graph edge. For the second graph scale W2, there are
no short graph connections, we can sample pixels at distance 2r + 1 apart in the original image grid as representative nodes. Applying this procedure recursively, at scale
s, we sample representative pixels at (2r + 1)s−1 distance
apart on the original image grid, as shown in Fig. 5. We will
denote the representative pixels in each scale by Is, and denote W c
s as a compressed afﬁnity matrix with connections
between the representative pixels in Is. The different scales
of the graph are deﬁned on different layers of the image
pyramid, each a sub-sample of the original image.
Note we create W c
s by simply sub-sampling the original graph Ws which encodes combined interveningcontour/brightness cues. There are several alternatives:
one can average the graph connections within the sampled image region, or use region based grouping cues to
deﬁne the graph weights between the representative pixels. We choose not to use these alternatives, and focus on
purely the effect of multiscale graph decomposition itself.
Figure 5: 1D view of multiple-scale graph decomposition with
r = 1. Large radius graphs can be decomposed into different
scales, each containing connections with speciﬁc range of spatial
separation: W = W1 +W2 +...+WS. At larger scales, the graph
weights vary slowly in a neighborhood, we can sample them using representative pixels at (2 · r + 1)s−1 distance apart.
Figure 6: Multiscale graph compression. With a maximal graph
connection radius Gr, the afﬁnity matrix WF ull probably doesn’t
ﬁt in memory. We can decompose it into short-range and longrange connections: WF ull = W1 + W2, and compress W2 with
a low-rank approximation: W2 ≈CT
2 C1,2. W c
2 can be computed either directly on a sub-sampled image, or by sampling values from W1. The interpolation matrix C1,2 from scale 2 to scale
1 will be introduced later on to couple segmentations at each scale.
Computational saving. Using the above mentioned multiscale graph decomposition and compression, at compressed graph scale s we have N/ρ2(s−1) nodes, where
N is the number of pixels, and ρ is the sampling factor, in our case ρ = 2r + 1. Summing across all the
scales, we have a total of N/(1 −
ρ2 ) nodes. Since at
each scale nodes are connected with only (2r + 1)2 nearest neighbors, we can compress a fully connected graph
with N(2r + 1)2/(1 −
ρ2 ) graph weights. Take a typical value of ρ = 3, r = 1, the total number of multiscale
graph connections is about 10N which is a very small fraction of the original N 2 connections. As Fig. 6 illustrates,
such a small number of connections can have virtually the same effect as a large fully connected graph.
In summary, we have proposed a decomposition of a segmentation graph W into disjoint scales: (Ws)s=1..S, where
each Ws can be compressed using a recursive sub-sampling
of the image pixels. This compression of W is not perfect,
compared to more accurate data-driven graph compression
schemes such as algebraic multi-grid. However, as we will
explain in the following section, we can still achieve precise and efﬁcient graph partitioning using this simple multiscale graph decomposition.
5. Multiscale Graph Segmentation
Principle We process the multiscale graph in parallel so
that information propagates from one scale to another. We
achieve this by specifying constraints on the multiscale
graph partitioning criterion. This is in contrast to most existing multiscale segmentation algorithms where the different scales are processed sequentially. The main difﬁculty is
in specifying information ﬂow across scales, which is the
topic of the next section.
5.1. Parallel segmentation across scales
Let Xs ∈{0, 1}Ns×K be the partitioning matrix at scale
s, Xs(i, k) = 1 iff graph node i ∈Is belongs to partition k.
We form the multiscale partitioning matrix X and the bloc
diagonal multiscale afﬁnity matrix W as follows:
We seek a multiscale segmentation optimizing the Ncut
criterion on W deﬁned in Sec. 2.2.
Direct partitioning of graph W gives the trivial segmentation, grouping all the nodes in a given scale as one
segment. For multiscale segmentation, we need segmentation costs to propagate across the different scales. At the
ﬁnest graph scale, the segmentation should take into account graph links at all coarser levels. We need to seek one
consistent segmentation across all scales. The cross-scale
consistency we seek is simple: the coarse-scale segmentation (Xs+1) should be locally an average of the ﬁne-scale
segmentation (Xs). This is done by constraining the multiscale partitioning vector X to verify: for all node i in layer
Is+1, Xs+1(i) =
j∈Ni Xs(j). The neighborhood Ni
Figure 7: Left: 2D view of a three-layer graph with connection radius r = 1. The three scales communicate through cross-scale interpolation matrices C1,2 and C2,3. Middle: cross-scale constraint
between scale 1 and scale 2 for partitioning vector X. X2(i) is the
average of X1(j) for nodes j below i. Stacking those equations
together, we get the cross-scale constraint CX = 0, here for two
scales. We see the upper triangular structure of C = [C1,2, −I2].
speciﬁes the projection of i ∈Is+1 on the ﬁner layer Is,
and is simply deﬁned on a regularly spaced grid of size ρ,
the sampling factor.
Deﬁne matrix Cs,s+1 (of size Ns+1 × Ns) as the crossscale interpolation matrix between nodes in layer Is and
those in coarser layer Is+1, as shown in Fig. 7:
Cs,s+1(i, j) =
|Ni| if j ∈Ni,
We deﬁne the cross-scale constraint matrix C:
and the cross-scale segmentation constraint equation:
As illustrated in Fig.7, the cross-scale constraint is a key
concept in our multiscale segmentation algorithm. With this
constraint, the segmentation cost is forced to propagate
across the scales to reach a consistent segmentation at all
Multiscale segmentation criterion
The segmentation
criterion we will use is the constrained multiscale Normalize Cut:
maximize ε(X) = 1
subject to CX = 0, X ∈{0, 1}N∗×K, X1K = 1N∗, (11)
where N ∗= P
s Ns. The problem being set, we will now
show how to handle it in an efﬁcient way.
6. Computational solution and running time
We transform this NP-complete combinatorial problem
into its counter part in a continuous space. After some algebra, the problem becomes:
maximize ε(Z) = 1
K tr(ZT WZ)
subject to CZ = 0, ZT DZ = IK,
This constrained optimization problem has been addressed in , we adapt the main result below. Let
be the normalized afﬁnity matrix, and Q be the projector onto the feasible solution
Q = I −D−1
2 CT (CD−1CT )−1CD−1
Let V = (V1, ..., VK) be the ﬁrst K eigenvectors of matrix
QPQ. Then the solutions to (12) are given by scaling any
rotation of the K eigenvectors V = (V1, ..., VK):
ε(Z) = {D−1
2 V R : R ∈O(K)}.
The proof, given in , uses Lagrange multipliers to
get rid of the constraint. The optimal solution is a subspace spanned by the K largest eigenvectors, but this time
the matrix is QD−1
2 Q instead of D−1
The ﬁnal algorithm is summarized in the box below.
1. Given a p×q image I, for s = 1..S (S=# scales):
(a) sample p
ρ pixels i ∈Is from Is−1 on
a regular grid, where ρ is the sampling factor.
(b) compute constraint Cs−1,s(i, j) =
∀j ∈Ni sampling neighborhood of i.
(c) compute afﬁnity W c
s on Is with small radius r, using image edges at scale s.
2. compute W, C from (W c
s , Cs,s+1)s as in (6),(8)
3. Compute Q using (14), compute V , the ﬁrst K
eigenvectors of QD−1
2 Q. Compute V =
2 V and discretize.
6.1. Running time analysis
We show that the complexity of this algorithm is linear in the number of pixels. Fix the sampling factor ρ between the scales, and the connection radius r to compute
Ws at each scale s. Suppose we use all possible scales, i.e.
S = logρ(max(p, q)) for a N = p × q image. Denoting
nnz(A) the number of non-zero elements of a matrix A, we
have nnz(W) = P
s nnz(Ws) = P
ρ2(s−1) (2r + 1)2 =
We show the constrained multiscale Ncut can also be
computed in O(N) time. The complexity of the eigensolver is dominated by the running time of the matrixvector multiplication y := QPQx, where Q deﬁned in
(14) could be full. Instead of computing Q explicitly, we
expand out the terms in Q, and apply a chain of smaller
matrix-vector operations. The only time consuming term is
computation of y := (CD−1CT )−1x, which has O(N 3)
running time. However, because we chose non-overlapping
grid neighborhoods, we can order the graph nodes to make
C (and hence CD−1
2 ) upper triangular. We then compute
y := (CD−1CT )−1x by solving 2 triangular systems with
nnz(C) = O(N) elements. Overall, the complexity of
y := QPQx is O(N). We veriﬁed empirically this linear
running time bound, and the results in Fig. 8 show a dramatic improvement over state of the art implementations.
Original Ncut
Multiscale Ncut
Original Ncut
Multiscale Ncut
Figure 8: Running time in seconds of original Ncut vs. Multiscale Ncut as a function of image pixels N. In original Ncut, we
scale connection radius with image size:Gr =
20 , and running
time is ≥O(NG2
r) = O(N 2). In Multiscale Ncut, we construct
a multiscale graph with same effective connection radius. Its running time is O(N).
6.2. Comparison with other multi-level graph cuts
It is important to contrast this method to two other successful multilevel graph partitioning algorithms: METIS 
and Nystrom approximation . In both cases, one adaptively coarsens the graph into a small set of nodes, and compute segmentation on the coarsened graph. The ﬁne level
segmentation is obtained by interpolation. Both algorithms
require correct initial graph coarsening . Nystrom works
quite well for grouping cues such as color. However for intervening contour grouping cues, graph weights have abrupt
variations making such precise graph coarsening infeasible.
7. Results
Sanity check. We verify Multiscale Ncut segmentation with
a simple “tree” image shown in Fig. 9. We create two scales,
with sampling rate = 3. The ﬁrst level graph has radius =1,
the second level has radius = 9. We test whether Multiscale Ncut is able to segment coarse and ﬁne structures at
the same time: the large trunk as well as the thin branches.
For comparison, we computed Ncut eigenvectors of coarse
and ﬁne level graphs in isolation. As we see in Fig.9, multiscale segmentation performs correctly, combining beneﬁts
of both scales.
Figure 9: Top middle: ﬁne level segmentation fails in cluttered region; Bottom left, coarse level segmentation alone fails to provide
detailed boundary; Bottom middle multiscale segmentation provides correct global segmentation with detailed boundary. Right:
zoom portion of the segmentation in ﬁne level (a), coarse level (b),
and multiscale (c).
Effect of sampling error in coarse graph construction. We
purposely kept construction of multiscale graph extremely
simple with geometric sampling. This sampling could have
a bad effect on pixels near an object boundary. We study if
Multiscale Ncut can overcome this sampling error. Fig. 10
shows the ﬁnal segmentation can overcome errors in coarse
grid quantization, with a small decrease in boundary sharpness (deﬁned as eigenvector gap across the object boundary) in worst case.
Effect of image clutter and faint contours We argue multiscale segmentation can handle image clutter and detect objects with faint contours. Such a problem is particularly important for segmenting large images. Fig. 11 provides one
such example with a 800 × 700 image. The segmentation is
both accurate (in ﬁnding details), robust (in detecting faint
but elongated object boundary), and fast.
We have experimented with the multiscale Ncut on a
variety of natural images, shown in Fig. 12. We observed
that compressed long range graph connections signiﬁcantly
improve running time and quality of segmentation. More
quantitative measurement is currently underway.