Graph Neural Network-Based Anomaly Detection in Multivariate Time Series
Ailin Deng, Bryan Hooi
National University of Singapore
 , 
Given high-dimensional time series data (e.g., sensor data),
how can we detect anomalous events, such as system faults
and attacks? More challengingly, how can we do this in a
way that captures complex inter-sensor relationships, and detects and explains anomalies which deviate from these relationships? Recently, deep learning approaches have enabled
improvements in anomaly detection in high-dimensional
datasets; however, existing methods do not explicitly learn
the structure of existing relationships between variables, or
use them to predict the expected behavior of time series. Our
approach combines a structure learning approach with graph
neural networks, additionally using attention weights to provide explainability for the detected anomalies. Experiments
on two real-world sensor datasets with ground truth anomalies show that our method detects anomalies more accurately
than baseline approaches, accurately captures correlations between sensors, and allows users to deduce the root cause of a
detected anomaly.
Introduction
With the rapid growth in interconnected devices and sensors
in Cyber-Physical Systems (CPS) such as vehicles, industrial systems and data centres, there is an increasing need to
monitor these devices to secure them against attacks. This is
particularly the case for critical infrastructures such as power
grids, water treatment plants, transportation, and communication networks.
Many such real-world systems involve large numbers of
interconnected sensors which generate substantial amounts
of time series data. For instance, in a water treatment plant,
there can be numerous sensors measuring water level, ﬂow
rates, water quality, valve status, and so on, in each of their
many components. Data from these sensors can be related in
complex, nonlinear ways: for example, opening a valve results in changes in pressure and ﬂow rate, leading to further
changes as automated mechanisms respond to the change.
As the complexity and dimensionality of such sensor data
grow, humans are increasingly less able to manually monitor this data. This necessitates automated anomaly detection approaches which can rapidly detect anomalies in highdimensional data, and explain them to human operators to
Copyright © 2021, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
allow them to diagnose and respond to the anomaly as
quickly as possible.
Due to the inherent lack of labeled anomalies in historical data, and the unpredictable and highly varied nature of anomalies, the anomaly detection problem is typically treated as an unsupervised learning problem. In past
years, many classical unsupervised approaches have been
developed, including linear model-based approaches , distance-based methods , and one-class methods based on support vector machines . However, such approaches
generally model inter-relationships between sensors in relatively simple ways: for example, capturing only linear relationships, which is insufﬁcient for complex, highly nonlinear relationships in many real-world settings.
Recently, deep learning-based techniques have enabled
improvements in anomaly detection in high-dimensional
datasets. For instance, Autoencoders (AE) 
are a popular approach for anomaly detection which uses
reconstruction error as an outlier score. More recently, Generative Adversarial Networks (GANs) and
LSTM-based approaches have also reported promising performance for multivariate anomaly detection. However, most methods do not explicitly learn
which sensors are related to one another, thus facing difﬁculties in modelling sensor data with many potential interrelationships. This limits their ability to detect and explain
deviations from such relationships when anomalous events
How do we take full advantage of the complex relationships between sensors in multivariate time series? Recently, graph neural networks (GNNs) have shown success in modelling
graph-structured data. These include graph convolution networks (GCNs) , graph attention networks (GATs) and multi-relational
approaches . However, applying
them to time series anomaly detection requires overcoming two main challenges. Firstly, different sensors have very
different behaviors: e.g. one may measure water pressure,
while another measures ﬂow rate. However, typical GNNs
use the same model parameters to model the behavior of
each node. Secondly, in our setting, the graph edges (i.e. relationships between sensors) are initially unknown, and have
The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)
to be learned along with our model, while GNNs typically
treat the graph as an input.
Hence, in this work, we propose our novel Graph Deviation Network (GDN) approach, which learns a graph of
relationships between sensors, and detects deviations from
these patterns1. Our method involves four main components:
1) Sensor Embedding, which uses embedding vectors to
ﬂexibly capture the unique characteristics of each sensor;
2) Graph Structure Learning learns the relationships between pairs of sensors, and encodes them as edges in a
graph; 3) Graph Attention-Based Forecasting learns to
predict the future behavior of a sensor based on an attention function over its neighboring sensors in the graph; 4)
Graph Deviation Scoring identiﬁes and explains deviations
from the learned sensor relationships in the graph.
To summarize, the main contributions of our work are:
• We propose GDN, a novel attention-based graph neural
network approach which learns a graph of the dependence
relationships between sensors, and identiﬁes and explains
deviations from these relationships.
• We conduct experiments on two water treatment plant
datasets with ground truth anomalies. Our results demonstrate that GDN detects anomalies more accurately than
baseline approaches.
• We show using case studies that GDN provides an explainable model through its embeddings and its learned
graph. We show that it helps to explain an anomaly, based
on the subgraph over which a deviation is detected, attention weights, and by comparing the predicted and actual
behavior on these sensors.
Related Work
We ﬁrst review methods for anomaly detection, and methods for multivariate time series data, including graph-based
approaches. Since our approach relies on graph neural networks, we summarize related work in this topic as well.
Anomaly Detection
Anomaly detection aims to detect unusual samples which deviate from the majority of the data.
Classical methods include density-based approaches , linear-model based approaches , distance-based methods ,
classiﬁcation models , detector ensembles and many others.
More recently, deep learning methods have achieved
improvements in anomaly detection in high-dimensional
datasets. These include approaches such as autoencoders
(AE) , which use reconstruction error as an
anomaly score, and related variants such as variational autoencoders (VAEs) , which develop a probabilistic approach, and autoencoders combining
with Gaussian mixture modelling .
However, our goal is to develop speciﬁc approaches for
multivariate time series data, explicitly capturing the graph
of relationships between sensors.
1The code is available at 
Multivariate Time Series Modelling
These approaches
generally model the behavior of a multivariate time series
based on its past behavior. A comprehensive summary is
given in .
Classical methods include auto-regressive models and the auto-regressive
integrated moving average (ARIMA) models , based on a linear model given
the past values of the series. However, their linearity makes
them unable to model complex nonlinear characteristics in
time series, which we are interested in.
To learn representations for nonlinear high-dimensional
time series and predict time series data, deep learningbased time series methods have attracted interest. These
techniques, such as Convolutional Neural Network (CNN)
based models , Long Short Term Memory
(LSTM) and Generative Adversarial Networks (GAN) models , have found success in practical time
series tasks. However, they do not explicitly learn the relationships between different time series, which are meaningful for anomaly detection: for example, they can be used to
diagnose anomalies by identifying deviations from these relationships.
Graph-based methods provide a way to model the relationships between sensors by representing the interdependencies with edges. Such methods include probabilistic graphical models, which encode joint probability distributions, as described in . However, most existing methods are designed to handle stationary time series, and have difﬁculty
modelling more complex and highly non-stationary time series arising from sensor settings.
Graph Neural Networks
In recent years, graph neural
networks (GNNs) have emerged as successful approaches
for modelling complex patterns in graph-structured data. In
general, GNNs assume that the state of a node is inﬂuenced
by the states of its neighbors. Graph Convolution Networks
(GCNs) model a node’s feature representation by aggregating the representations of its one-step
neighbors. Building on this approach, graph attention networks (GATs) use an attention function to compute different weights for different neighbors
during this aggregation. Related variants have shown success in time-dependent problems: for example, GNN-based
models can perform well in trafﬁc prediction tasks . Applications in recommendation systems 
and relative applications verify the effectiveness of GNN to model large-scale multi-relational data.
However, these approaches use the same model parameters to model the behavior of each node, and hence face
limitations in representing very different behaviors of different sensors. Moreover, GNNs typically require the graph
structure as an input, whereas the graph structure is initially
unknown in our setting, and needs to be learned from data.
2. Graph Structure Learning
1. Sensor Embedding
4. Graph Deviation Scoring
Prediction
Observation
Learned Relations
3. Graph Attention-Based Forecasting
Attention-Based Features
Figure 1: Overview of our proposed framework.
Proposed Framework
Problem Statement
In this paper, our training data consists of sensor (i.e. multivariate time series) data from N sensors over Ttrain time
ticks: the sensor data is denoted strain =
train, · · · , s(Ttrain)
which is used to train our approach. In each time tick t, the
sensor values s(t)
train ∈RN form an N dimensional vector representing the values of our N sensors. Following the usual
unsupervised anomaly detection formulation, the training
data is assumed to consist of only normal data.
Our goal is to detect anomalies in testing data, which
comes from the same N sensors but over a separate
set of Ttest time ticks: the test data is denoted stest
test, · · · , s(Ttest)
The output of our algorithm is a set of Ttest binary labels
indicating whether each test time tick is an anomaly or not,
i.e. a(t) ∈{0, 1}, where a(t) = 1 indicates that time t is
anomalous.
Our GDN method aims to learn relationships between sensors as a graph, and then identiﬁes and explains deviations
from the learned patterns. It involves four main components:
1. Sensor Embedding: uses embedding vectors to capture
the unique characteristics of each sensor;
2. Graph Structure Learning: learns a graph structure representing dependence relationships between sensors;
3. Graph Attention-Based Forecasting: forecasts future
values of each sensor based on a graph attention function
over its neighbors;
4. Graph Deviation Scoring: identiﬁes deviations from the
learned relationships, and localizes and explains these deviations.
Figure 1 provides an overview of our framework.
Sensor Embedding
In many sensor data settings, different sensors can have very
different characteristics, and these characteristics can be related in complex ways. For example, imagine we have two
water tanks, each containing a sensor measuring the water
level in the tank, and a sensor measuring the water quality
in the tank. Then, it is plausible that the two water level sensors would behave similarly, and the two water quality sensors would behave similarly. However, it is equally plausible
that sensors within the same tank would exhibit strong correlations. Hence, ideally, we would want to represent each
sensor in a ﬂexible way that captures the different ‘factors’
underlying its behavior in a multidimensional way.
Hence, we do this by introducing an embedding vector
for each sensor, representing its characteristics:
vi ∈Rd, for i ∈{1, 2, · · · , N}
These embeddings are initialized randomly and then trained
along with the rest of the model.
Similarity between these embeddings vi indicates similarity of behaviors: hence, sensors with similar embedding
values should have a high tendency to be related to one another. In our model, these embeddings will be used in two
ways: 1) for structure learning, to determine which sensors
are related to one another, and 2) in our attention mechanism, to perform attention over neighbors in a way that allows heterogeneous effects for different types of sensors.
Graph Structure Learning
A major goal of our framework is to learn the relationships
between sensors in the form of a graph structure. To do this,
we will use a directed graph, whose nodes represent sensors, and whose edges represent dependency relationships
between them. An edge from one sensor to another indicates
that the ﬁrst sensor is used for modelling the behavior of the
second sensor. We use a directed graph because the dependency patterns between sensors need not be symmetric. We
use an adjacency matrix A to represent this directed graph,
where Aij represents the presence of a directed edge from
node i to node j.
We design a ﬂexible framework which can be applied either to 1) the usual case where we have no prior information
about the graph structure, or 2) the case where we have some
prior information about which edges are plausible (e.g. the
sensor system may be divided into parts, where sensors in
different parts have minimal interaction).
This prior information can be ﬂexibly represented as a set
of candidate relations Ci for each sensor i, i.e. the sensors
it could be dependent on:
Ci ⊆{1, 2, · · · , N} \ {i}
In the case without prior information, the candidate relations
of sensor i is simply all sensors, other than itself.
To select the dependencies of sensor i among these candidates, we compute the similarity between node i’s embedding vector, and the embeddings of its candidates j ∈Ci:
∥vi∥· ∥vj∥for j ∈Ci
Aji = 1{j ∈TopK({eki : k ∈Ci})}
That is, we ﬁrst compute eji, the normalized dot product between the embedding vectors of sensor i, and the candidate
relation j ∈Ci. Then, we select the top k such normalized
dot products: here TopK denotes the indices of top-k values among its input (i.e. the normalized dot products). The
value of k can be chosen by the user according to the desired
sparsity level. Next, we will deﬁne our graph attention-based
model which makes use of this learned adjacency matrix A.
Graph Attention-Based Forecasting
In order to provide useful explanations for anomalies, we
would like our model to tell us:
• Which sensors are deviating from normal behavior?
• In what ways are they deviating from normal behavior?
To achieve these goals, we use a forecasting-based approach, where we forecast the expected behavior of each
sensor at each time based on the past. This allows the user to
easily identify the sensors which deviate greatly from their
expected behavior. Moreover, the user can compare the expected and observed behavior of each sensor, to understand
why the model regards a sensor as anomalous.
Thus, at time t, we deﬁne our model input x(t) ∈RN×w
based on a sliding window of size w over the historical time
series data (whether training or testing data):
s(t−w), s(t−w+1), · · · , s(t−1)i
The target output that our model needs to predict is the sensor data at the current time tick, i.e. s(t).
Feature Extractor
To capture the relationships between
sensors, we introduce a graph attention-based feature extractor to fuse a node’s information with its neighbors based on
the learned graph structure. Unlike existing graph attention
mechanisms, our feature extractor incorporates the sensor
embedding vectors vi, which characterize the different behaviors of different types of sensors. To do this, we compute
node i’s aggregated representation zi as follows:
αi,iWx(t)
where x(t)
Rw is node i’s input feature, N(i)
{j | Aji > 0} is the set of neighbors of node i obtained from
the learned adjacency matrix A, W ∈Rd×w is a trainable
weight matrix which applies a shared linear transformation
to every node, and the attention coefﬁcients αi,j are computed as:
= vi ⊕Wx(t)
π (i, j) = LeakyReLU
exp (π (i, j))
k∈N (i)∪{i} exp (π (i, k)),
where ⊕denotes concatenation; thus g(t)
concatenates the
sensor embedding vi and the corresponding transformed
feature Wx(t)
i , and a is a vector of learned coefﬁcients for
the attention mechanism. We use LeakyReLU as the nonlinear activation to compute the attention coefﬁcient, and
normalize the attention coefﬁcents using the softmax function in Eq. (8).
Output Layer
From the above feature extractor, we obtain
representations for all N nodes, namely {z(t)
1 , · · · , z(t)
For each z(t)
i , we element-wise multiply (denoted ◦) it with
the corresponding time series embedding vi, and use the results across all nodes as the input of stacked fully-connected
layers with output dimensionality N, to predict the vector of
sensor values at time step t, i.e. s(t):
ˆs(t) = fθ
1 , · · · , vN ◦z(t)
The model’s predicted output is denoted as ˆs(t). We use
the Mean Squared Error between the predicted output ˆs(t)
and the observed data, s(t), as the loss function for minimization:
ˆs(t) −s(t)
Graph Deviation Scoring
Given the learned relationships, we want to detect and explain anomalies which deviate from these relationships.
To do this, our model computes individual anomalousness
scores for each sensor, and also combines them into a single anomalousness score for each time tick, thus allowing
the user to localize which sensors are anomalous, as we will
show in our experiments.
The anomalousness score compares the expected behavior
at time t to the observed behavior, computing an error value
Err at time t and sensor i:
Erri (t) = |s(t)
As different sensors can have very different characteristics,
their deviation values may also have very different scales.
To prevent the deviations arising from any one sensor from
being overly dominant over the other sensors, we perform a
robust normalization of the error values of each sensor:
ai (t) = Erri (t) −eµi
where eµi and eσi are the median and inter-quartile range
(IQR2) across time ticks of the Erri (t) values respectively.
We use median and IQR instead of mean and standard deviation as they are more robust against anomalies.
Then, to compute the overall anomalousness at time tick
t, we aggregate over sensors using the max function (we use
max as it is plausible for anomalies to affect only a small
subset of sensors, or even a single sensor) :
A (t) = max
2IQR is deﬁned as the difference between the 1st and 3rd quartiles of a distribution or set of values, and is a robust measure of the
distribution’s spread.
To dampen abrupt changes in values are often not perfectly predicted and result in sharp spikes in error values
even when this behavior is normal, similar with , we use a simple moving average(SMA) to generate the smoothed scores As (t).
Finally, a time tick t is labelled as an anomaly if As(t)
exceeds a ﬁxed threshold. While different approaches could
be employed to set the threshold such as extreme value theory , to avoid introducing additional hyperparameters, we use in our experiments a simple approach
of setting the threshold as the max of As(t) over the validation data.
Experiments
In this section, we conduct experiments to answer the following research questions:
• RQ1 (Accuracy): Does our method outperform baseline
methods in accuracy of anomaly detection in multivariate
time series, based on ground truth labelled anomalies?
• RQ2 (Ablation): How do the various components of the
method contribute to its performance?
• RQ3 (Interpretability of Model): How can we understand our model based on its embeddings and its learned
graph structure?
• RQ4 (Localizing Anomalies): Can our method localize
anomalies and help users to identify the affected sensors,
as well as to understand how the anomaly deviates from
the expected behavior?
As real-world datasets with labeled ground-truth anomalies
are scarce, especially for large-scale plants and factories,
we use two sensor datasets based on water treatment physical test-bed systems: SWaT and WADI, where operators
have simulated attack scenarios of real-world water treatment plants, recording these as the ground truth anomalies.
The Secure Water Treatment (SWaT) dataset comes from
a water treatment test-bed coordinated by Singapore’s Public
Utility Board . It represents
a small-scale version of a realistic modern Cyber-Physical
system, integrating digital and physical elements to control
and monitor system behaviors. As an extension of SWaT,
Water Distribution (WADI) is a distribution system comprising a larger number of water distribution pipelines . Thus WADI forms a more complete and realistic water treatment, storage and distribution
network. The datasets contain two weeks of data from normal operations, which are used as training data for the respective models. A number of controlled, physical attacks
are conducted at different intervals in the following days,
which correspond to the anomalies in the test set.
Table 1 summarises the statistics of the two datasets. In order to speed up training, the original data samples are downsampled to one measurement every 10 seconds by taking the
median values. The resulting label is the most common label
during the 10 seconds. Since the systems took 5-6 hours to
reach stabilization when ﬁrst turned on ,
we eliminate the ﬁrst 2160 samples for both datasets.
Table 1: Statistics of the two datasets used in experiments
We compare the performance of our proposed method with
ﬁve popular anomaly detection methods, including:
• PCA: Principal Component Analysis 
ﬁnds a low-dimensional projection that captures most of
the variance in the data. The anomaly score is the reconstruction error of this projection.
• KNN: K Nearest Neighbors uses each point’s distance
to its kth nearest neighbor as an anomaly score .
• FB: A Feature Bagging detector is a meta-estimator that
ﬁts a number of detectors on various sub-samples of the
dataset, then aggregates their scores .
• AE: Autoencoders consist of an encoder and decoder
which reconstruct data samples . It uses
the reconstruction error as the anomaly score.
• DAGMM: Deep Autoencoding Gaussian Model joints
deep Autoencoders and Gaussian Mixture Model to generate a low-dimensional representation and reconstruction
error for each observation .
• LSTM-VAE: LSTM-VAE replaces the feed-forward network in a VAE with
LSTM to combine LSTM and VAE. It can measure reconstruction error with the anomaly score.
• MAD-GAN: A GAN model is trained on normal
data, and the LSTM-RNN discriminator along with
a reconstruction-based approach is used to compute
anomaly scores for each sample .
Evaluation Metrics
We use precision (Prec), recall (Rec) and F1-Score (F1)
over the test dataset and its ground truth values to evaluate the performance of our method and baseline models:
F1 = 2×Prec×Rec
Prec+Rec , where Prec =
TP+FP and Rec =
and TP, TN, FP, FN are the numbers of true positives, true
negatives, false positives, and false negatives. Note that our
datasets are unbalanced, which justiﬁes the choice of these
metrics, which are suitable for unbalanced data. To detect
anomalies, we use the maximum anomaly score over the validation dataset to set the threshold. At test time, any time
step with an anomaly score over the threshold will be regarded as an anomaly.
Experimental Setup
We implement our method and its variants in Py-
Torch version 1.5.1 with CUDA 10.2
and PyTorch Geometric Library 
Table 2: Anomaly detection accuracy in terms of precision(%), recall(%), and F1-score, on two datasets with
ground-truth labelled anomalies. Part of the results are from
 .
version 1.5.0, and train them on a server with Intel(R)
Xeon(R) CPU E5-2690 v4 @ 2.60GHz and 4 NVIDIA RTX
2080Ti graphics cards. The models are trained using the
Adam optimizer with learning rate 1 × 10−3 and (β1, β2) =
(0.9, 0.99). We train models for up to 50 epochs and use
early stopping with patience of 10. We use embedding vectors with length of 128(64), k with 30(15) and hidden layers of 128(64) neurons for the WADI (SWaT) dataset, corresponding to their difference in input dimensionality. We set
the sliding window size w as 5 for both datasets.
RQ1. Accuracy
In Table 2, we show the anomaly detection accuracy in terms
of precision, recall and F1-score, of our GDN method and
the baselines, on the SWaT and WADI datasets. The results
show that GDN outperforms the baselines in both datasets,
with high precision in both datasets of 0.99 on SWaT and
0.98 on WADI. In terms of F-measure, GDN outperforms the
baselines on SWaT; on WADI, it has 54% higher F-measure
than the next best baseline. WADI is more unbalanced than
SWaT and has higher dimensionality than SWaT as shown in
Table 1. Thus, our method shows effectiveness even in unbalanced and high-dimensional attack scenarios, which are
of high importance in real-world applications.
RQ2. Ablation
To study the necessity of each component of our method, we
gradually exclude the components to observe how the model
performance degrades. First, we study the importance of the
learned graph by substituting it with a static complete graph,
where each node is linked to all the other nodes. Second,
to study the importance of the sensor embeddings, we use
an attention mechanism without sensor embeddings: that is,
gi = Wxi in Eq. (6). Finally, we disable the attention mechanism, instead aggregating using equal weights assigned to
all neighbors. The results are summarized in Table 3 and
provide the following ﬁndings:
• Replacing the learned graph structure with a complete
graph degrades performance in both datasets. The effect
on the WADI dataset is more obvious. This indicates that
Table 3: Anomaly detection accuracy in term of percision(%), recall(%), and F1-score of GDN and its variants.
2_FIC_101_C
2_FIC_201_C
2_FIC_301_C
2_FIC_101_CO
2_FIC_201_CO
2_FIC_301_CO
Figure 2: A t-SNE plot of the sensor embeddings of our
trained model on the WADI dataset. Node colors denote
classes. Speciﬁcally, the dashed circled region shows localized clustering of 2 FIC x01 CO sensors. These sensors are
measuring similar indicators in WADI.
the graph structure learner enhances performance, especially for large-scale datasets.
• The variant which removes the sensor embedding from
the attention mechanism underperforms the original
model in both datasets. This implies that the embedding
feature improves the learning of weight coefﬁcients in the
graph attention mechanism.
• Removing the attention mechanism degrades the model’s
performance most in our experiments. Since sensors have
very different behaviors, treating all neighbors equally introduces noise and misleads the model. This veriﬁes the
importance of the graph attention mechanism.
These ﬁndings suggest that GDN’s use of a learned graph
structure, sensor embedding, and attention mechanisms all
contribute to its accuracy, which provides an explanation for
its better performance over the baseline methods.
RQ3. Interpretability of Model
Interpretability via Sensor Embeddings
To explain the
learned model, we can visualize its sensor embedding vectors, e.g. using t-SNE , shown on
the WADI dataset in Figure 2. Similarity in this embedding
space indicate similarity between the sensors’ behaviors, so
inspecting this plot allows the user to deduce groups of sensors which behave in similar ways.
1_FIT_001_PV
1_MV_001_STATUS
1_AIT_005_PV
1_LT_001_PV
1_MV_001_STATUS
1_FIT_001_PV
Figure 3: Left: Force-directed graph layout with attention weights as edge weights, showing an attack in WADI. The red triangle
denotes the central sensor identiﬁed by our approach, with highest anomaly score. Red circles indicate nodes with edge weights
larger than 0.1 to the central node. Right: Comparing expected and observed data helps to explain the anomaly. The attack
period is shaded in red.
To validate this, we color the nodes using 7 colors corresponding to 7 classes of sensors in WADI systems. The
representation exhibits localized clustering in the projected
2D space, which veriﬁes the effectiveness of the learned feature representations to reﬂect the localized sensors’ behavior
similarity. Moreover, we observe a group of sensors forming
a localized cluster, shown in the dashed circled region. Inspecting the data, we ﬁnd that these sensors measure similar
indicators in water tanks that perform similar functions in
the WADI water distribution network, explaining the similarity between these sensors.
Interpretability via Graph Edges and Attention Weights
Edges in our learned graph provide interpretability by indicating which sensors are related to one another. Moreover, the attention weights further indicate the importance of
each of a node’s neighbors in modelling the node’s behavior. Figure 3 (left) shows an example of this learned graph on
the WADI dataset. The following subsection further shows a
case study of using this graph to localize and understand an
RQ4. Localizing Anomalies
How well can our model help users to localize and understand an anomaly? Figure 3 (left) shows the learned graph
of sensors, with edges weighted by their attention weights,
and plotted using a force-directed layout .
We conduct a case study involving an anomaly with
a known cause: as recorded in the documentation of the
WADI dataset, this anomaly arises from a ﬂow sensor,
1 FIT 001 PV, being attacked via false readings. These false
readings are within the normal range of this sensor, so detecting this anomaly is nontrivial.
1 MV 001 STATUS as the deviating sensor with the
highest anomaly score, as indicated by the red triangle in
Figure 3 (left). The large deviation at this sensor indicates
that 1 MV 001 STATUS could be the attacked sensor, or
closely related to the attacked sensor.
GDN indicates (in red circles) the sensors with highest attention weights to the deviating sensor. Indeed, these neighbors are closely related sensors: the 1 FIT 001 PV neighbor is normally highly correlated with 1 MV 001 STATUS,
as the latter shows the valve status for a valve which controls the ﬂow measured by the former. However, the attack caused a deviation from this relationship, as the attack gave false readings only to 1 FIT 001 PV. GDN further allows understanding of this anomaly by comparing the
predicted and observed sensor values in Figure 3 (right):
for 1 MV 001 STATUS, our model predicted an increase (as
1 FIT 001 PV increased, and our model has learned that the
sensors increase together). Due to the attack, however, no
change was observed in 1 MV 001 STATUS, leading to a
large error which was detected as an anomaly by GDN.
In summary: 1) our model’s individual anomaly scores
help to localize anomalies; 2) its attention weights help to
ﬁnd closely related sensors; 3) its predictions of expected
behavior of each sensor allows us to understand how anomalies deviate from expectations.
Conclusion
In this work, we proposed our Graph Deviation Network
(GDN) approach, which learns a graph of relationships between sensors, and detects deviations from these patterns,
while incorporating sensor embeddings. Experiments on two
real-world sensor datasets showed that GDN outperformed
baselines in accuracy, provides an interpretable model, and
helps users to localize and understand anomalies. Future
work can consider additional architectures and online training methods, to further improve the practicality of the approach.
Acknowledgments
This work was supported in part by NUS ODPRT Grant
R252-000-A81-133. The datasets are provided by iTrust,
Centre for Research in Cyber Security, Singapore University of Technology and Design.