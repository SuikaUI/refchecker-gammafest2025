Analyzing Evolutionary Optimization in Noisy Environments
Chao Qian, Yang Yu∗, Zhi-Hua Zhou
National Key Laboratory for Novel Software Technology
Nanjing University, Nanjing 210023, China
Many optimization tasks have to be handled in noisy environments, where we cannot
obtain the exact evaluation of a solution but only a noisy one. For noisy optimization
tasks, evolutionary algorithms (EAs), a kind of stochastic metaheuristic search algorithm,
have been widely and successfully applied. Previous work mainly focuses on empirical
studying and designing EAs for noisy optimization, while, the theoretical counterpart
has been little investigated. In this paper, we investigate a largely ignored question, i.e.,
whether an optimization problem will always become harder for EAs in a noisy environment. We prove that the answer is negative, with respect to the measurement of the
expected running time. The result implies that, for optimization tasks that have already
been quite hard to solve, the noise may not have a negative effect, and the easier a task
the more negatively affected by the noise. On a representative problem where the noise
has a strong negative effect, we examine two commonly employed mechanisms in EAs
dealing with noise, the re-evaluation and the threshold selection strategies. The analysis
discloses that the two strategies, however, both are not effective, i.e., they do not make
the EA more noise tolerant. We then ﬁnd that a small modiﬁcation of the threshold selection allows it to be proven as an effective strategy for dealing with the noise in the
Key words: Noisy optimization, evolutionary algorithms, re-evaluation, threshold selection,
running time, computational complexity
∗Corresponding author
Email addresses: (Chao Qian), (Yang Yu), have been widely and successfully
adopted for noisy optimization tasks .
EAs are a kind of randomized metaheuristic optimization algorithms, inspired by natural phenomena including evolution of species, swarm cooperation, immune system, etc. EAs typically involve a
cycle of three stages: reproduction stage produces new solutions based on the currently maintained
solutions; evaluation stage evaluates the newly generated solutions; selection stage wipes out bad
solutions. An inspiration of using EAs for noisy optimization is that the corresponding natural phenomena have been processed successfully in noisy environments, and hence the algorithmic simulations are also likely to be able to handle noise. Besides, improved mechanisms have been invented
for better handling noise. Two representative strategies are re-evaluation and threshold selection: by
the re-evaluation strategy , whenever the ﬁtness (also called cost or objective value) of a
solution is required, EAs make an independent evaluation of the solution despite of whether the
solution has been evaluated before, such that the ﬁtness is smoothed; by the threshold selection
strategy , in the selection stage EAs accept a newly generated solution only if its ﬁtness is
larger than the ﬁtness of the old solution by at least a threshold, such that the risk of accepting a bad
solution due to noise is reduced.
An assumption implied by using a noise handling mechanism in EAs is that the noise makes the
optimization harder, so that a better handling mechanism can reduce the negative effect by the
noise . This paper ﬁrstly investigates if this assumption is true. We start by presenting an
experimental evidence using (1+1)-EA optimizing the hardest case in the pseudo-Boolean function
class . Experiment results indicate that the noise, however, makes the optimization easier rather
than harder, under the measurement of expected running time.
Following the experiment evidence, we then derive sufﬁcient theoretical conditions, under which
the noise will make the optimization easier or harder. By ﬁlling the conditions, we present proofs
that, for the (1+λ)-EA (a class of EAs employing offspring population size λ), the noise will make the
optimization easier on the hardest case in the pseudo-Boolean function class, while harder on the
easiest case. The proofs imply that we need to take care of the noise only when the optimization is
moderately or less complex, and ignore this issue when the optimization task itself is quite hard.
For the situations where the noise needs to be cared, this paper examines the re-evaluation and the
threshold selection strategies for their polynomial noise tolerance (PNT). For a kind of noise, the PNT
of an EA is the maximum noise level such that the expected running time of the algorithm is polynomial. The closer the PNT is to 1, the better the noise tolerance is. Taking the easiest pseudo-Boolean
function case as the representative problem, we analyze the PNT for different conﬁgurations of the
(1+1)-EA with respect to the one-bit noise, whose level is characterized by the noise probability.
For the (1+1)-EA (without any noise handling strategy), we prove that the PNT has a lower bound
Ω(poly(n)) and an upper bound 1 −
O(2npoly(n)). Since the (1+1)-EA with re-evaluation has the
PNT Θ( log n
n ) , it is surprisingly that the re-evaluation makes the PNT much worse. We further
prove that for the (1+1)-EA with re-evaluation using threshold selection, when the threshold is 1,
the PNT is not less than
2e, and when the threshold is 2, the PNT has a lower bound 1 −
Ω(poly(n))
and an upper bound 1 −
O(2npoly(n)). The PNT bounds indicate that threshold selection improves
the re-evaluation strategy, however, no improvements from the (1+1)-EA are found. We then introduce a small modiﬁcation into the threshold selection strategy to turn the original hard threshold
to be a smooth threshold. We prove that with the smooth threshold selection strategy the PNT is 1,
i.e., the (1+1)-EA is always a polynomial algorithm disregard the probability of one-bit noise on the
The rest of this paper is organized as follows. Section 2 introduces some background. Section 3
shows that the noise may not always be bad, and presents a sufﬁcient condition for that. Section 4
analyzes noise handling strategies. Section 5 concludes.
2. Background
2.1. Noisy Optimization
A general optimization problem can be represented as arg maxx f(x), where the objective f is also
called ﬁtness in the context of evolutionary computation. In real-world optimization tasks, the ﬁtness evaluation for a solution is usually disturbed by noise, and consequently we can not obtain the
exact ﬁtness value but only a noisy one. In this paper, we will involve the following kinds of noise,
and we will always denote f N(x) and f(x) as the noisy and true ﬁtness of a solution x, respectively.
additive noise f N(x) = f(x) + δ, where δ is uniformly selected from [δ1, δ2] at random.
multiplicative noise f N(x) = f(x) · δ, where δ is uniformly selected from [δ1, δ2] at random.
one-bit noise f N(x) = f(x) with probability (1 −pn) (0 ≤pn ≤1); otherwise, f N(x) = f(x′), where
x′ is generated by ﬂipping a uniformly randomly chosen bit of x ∈{0, 1}n. This noise is for
problems where solutions are represented in binary strings.
Additive and multiplicative noise has been often used for analyzing the effect of noise . Onebit noise is speciﬁcally for optimizing pseudo-Boolean problems over {0, 1}n, and also the investigated noise in the only previous work for analyzing running time of EAs in noisy optimization .
For one-bit noise, pn controls the noise level. In this paper we assume that the parameters of the
environment (i.e., pn, δ1 and δ2) do not change over time.
It is possible that a large noise could make an optimization problem extremely hard for particular
algorithms. We are interested in the noise level, under which an algorithm could be “tolerant” to
have polynomial running time. We deﬁne the polynomial noise tolerance (PNT) as Deﬁnition 1,
which characterizes the maximum noise level for allowing a polynomial expected running time.
Note that, the noise level can be measured by the adjusting parameter, e.g., δ1, δ2 for the additive
and multiplicative noise, and pn for the one-bit noise. We will study the PNT of EAs for analyzing
the effectiveness of noise handling strategies.
Deﬁnition 1 (Polynomial Noise Tolerance (PNT))
The polynomial noise tolerance of an algorithm on a problem, with respect to a kind of noise, is the
maximum noise level such that the algorithm has expected running time polynomial to the problem
2.2. Evolutionary Algorithms
Evolutionary algorithms (EAs) are a kind of population-based metaheuristic optimization algorithms. Although there exist many variants, the common procedure of EAs can be described as
Generate an initial set of solutions (called population);
Reproduce new solutions from the current population;
Evaluate the newly generated solutions;
Update the population by removing bad solutions;
Repeat steps 2-5 until some criterion is met.
The (1+1)-EA, as in Algorithm 1, is a simple EA for maximizing pseudo-Boolean problems over
{0, 1}n, which reﬂects the common structure of EAs. It maintains only one solution, and repeatedly improves the current solution by using bit-wise mutation (i.e., the 3rd step of Algorithm 1). It
has been widely used for the running time analysis of EAs, e.g., .
Algorithm 1 ((1+1)-EA)
Given pseudo-Boolean function f with solution length n, it consists of the following steps:
x := randomly selected from {0, 1}n.
Repeat until the termination condition is met
x′ := ﬂip each bit of x with probability p.
if f(x′) ≥f(x)
where p ∈(0, 0.5) is the mutation probability.
The (1+λ)-EA, as in Algorithm 2, applies an offspring population size λ. In each iteration, it ﬁrst
generates λ offspring solutions by independently mutating the current solution λ times, and then
selects the best solution from the current solution and the offspring solutions as the next solution.
It has been used to disclose the effect of offspring population size by running time analysis .
Note that, (1+1)-EA is a special case of (1+λ)-EA with λ = 1.
Algorithm 2 ((1+λ)-EA)
Given pseudo-Boolean function f with solution length n, it consists of the following steps:
x := randomly selected from {0, 1}n.
Repeat until the termination condition is met
Repeat until i > λ.
xi := ﬂip each bit of x with probability p.
i := i + 1.
x = arg maxx′∈{x,x1,...,xλ} f(x′).
where p ∈(0, 0.5) is the mutation probability.
The running time of EAs is usually deﬁned as the number of ﬁtness evaluations (i.e., computing f(·))
until an optimal solution is found for the ﬁrst time, since the ﬁtness evaluation is the computational
process with the highest cost of the algorithm .
2.3. Markov Chain Modeling
We will analyze EAs by modeling them as Markov chains in this paper. Here, we ﬁrst give some
preliminaries.
EAs generate solutions only based on their currently maintained solutions, thus, they can be modeled and analyzed as Markov chains, e.g., . A Markov chain {ξt}+∞
t=0 modeling an EA is constructed by taking the EA’s population space X as the chain’s state space, i.e. ξt ∈X. Let X ∗⊂X
denote the set of all optimal populations, which contains at least one optimal solution. The goal
of the EA is to reach X ∗from an initial population. Thus, the process of an EA seeking X ∗can be
analyzed by studying the corresponding Markov chain.
A Markov chain {ξt}+∞
t=0 (ξt ∈X) is a random process, where ∀t ≥0, ξt+1 depends only on ξt. A
Markov chain {ξt}+∞
t=0 is said to be homogeneous, if ∀t ≥0, ∀x, y ∈X:
P(ξt+1 = y|ξt = x) = P(ξ1 = y|ξ0 = x).
In this paper, we always denote X and X ∗as the state space and the optimal state space of a Markov
chain, respectively.
Given a Markov chain {ξt}+∞
t=0 and ξˆt = x, we deﬁne the ﬁrst hitting time (FHT) of the chain as a
random variable τ such that τ = min{t|ξˆt+t ∈X ∗, t ≥0}. That is, τ is the number of steps needed to
reach the optimal state space for the ﬁrst time starting from ξˆt = x. The mathematical expectation
of τ, E[[τ|ξˆt = x]] = P∞
i=0 iP(τ = i), is called the expected ﬁrst hitting time (EFHT) of this chain
starting from ξˆt = x. If ξ0 is drawn from a distribution π0, E[[τ|ξ0 ∼π0]] = P
x∈X π0(x)E[[τ|ξ0 = x]] is
called the expected ﬁrst hitting time of the Markov chain over the initial distribution π0.
For the corresponding EA, the running time is the numbers of calls to the ﬁtness function until
meeting an optimal solution for the ﬁrst time. Thus, the expected running time starting from ξ0 and
that starting from ξ0 ∼π0 are respectively equal to
N1 + N2 · E[[τ|ξ0]]
N1 + N2 · E[[τ|ξ0 ∼π0]],
where N1 and N2 are the number of ﬁtness evaluations for the initial population and each iteration,
respectively. For example, for (1+1)-EA, N1 = 1 and N2 = 1; for (1+λ)-EA, N1 = 1 and N2 = λ.
Note that, when involving the expected running time of an EA on a problem in this paper, if the
initial population is not speciﬁed, it is the expected running time starting from a uniform initial
distribution πu, i.e., N1 + N2 · E[[τ|ξ0 ∼πu]] = N1 + N2 · P
|X|E[[τ|ξ0 = x]].
The following two lemmas on the EFHT of Markov chains will be used in this paper.
Given a Markov chain {ξt}+∞
t=0, we have
∀x ∈X ∗: E[[τ|ξt = x]] = 0;
∀x /∈X ∗: E[[τ|ξt = x]] = 1 +
y∈X P(ξt+1 = y|ξt = x)E[[τ|ξt+1 = y]].
Given a homogeneous Markov chain {ξt}+∞
t=0, it holds
∀t1, t2 ≥0, x ∈X : E[[τ|ξt1 = x]] = E[[τ|ξt2 = x]].
For analyzing the EFHT of Markov chains, drift analysis is a commonly used tool, which will
also be used in this paper. To use drift analysis, it needs to construct a function V (x) (x ∈X) to
measure the distance of a state x to the optimal state space X ∗. The distance function V (x) satisﬁes
that V (x ∈X ∗) = 0 and V (x /∈X ∗) > 0. Then, by investigating the progress on the distance to X ∗
in each step, i.e., E[[V (ξt) −V (ξt+1)|ξt]], an upper (lower) bound of the EFHT can be derived through
dividing the initial distance by a lower (upper) bound of the progress.
Lemma 3 (Drift Analysis )
Given a Markov chain {ξt}+∞
t=0 and a distance function V (x), if it satisﬁes that for any t ≥0 and any
ξt with V (ξt) > 0,
0 < cl ≤E[[V (ξt) −V (ξt+1)|ξt]] ≤cu,
then the EFHT of this chain satisﬁes that
V (ξ0)/cu ≤E[[τ|ξ0]] ≤V (ξ0)/cl,
where cl, cu are constants.
2.4. Pseudo-Boolean Functions
The pseudo-Boolean function class in Deﬁnition 2 is a large function class which only requires the
solution space to be {0, 1}n and the objective space to be R. Many well-known NP-hard problems
(e.g., the vertex cover problem and the 0-1 knapsack problem) belong to this class. Diverse pseudo-
Boolean problems with different structures and difﬁculties have been used for analyzing the running time of EAs, and then to disclose properties of EAs, e.g., . Note that, we consider
only maximization problems in this paper since minimizing f is equivalent to maximizing −f.
Deﬁnition 2 (Pseudo-Boolean Function)
A function in the pseudo-Boolean function class has the form: f : {0, 1}n →R.
Ihardest (or called Trap) problem in Deﬁnition 3 is a special instance in this class, which is to maximize the number of 0 bits of a solution except the global optimum 11 . . . 1 (brieﬂy denoted as 1n).
Its optimal function value is 2n, and the function value for any non-optimal solution is not larger
than 0. It has been widely used in the theoretical analysis of EAs, and the expected running time of
(1+1)-EA with mutation probability 1
n has been proved to be Θ(nn) . It has also been recognized
as the hardest instance in the pseudo-Boolean function class with a unique global optimum for the
(1+1)-EA .
Deﬁnition 3 (Ihardest Problem)
Ihardest Problem of size n is to ﬁnd an n bits binary string x∗such that
x∗= arg maxx∈{0,1}n
 f(x) = 3n
where xi is the i-th bit of a solution x ∈{0, 1}n.
Ieasiest (or called OneMax) problem in Deﬁnition 4 is to maximize the number of 1 bits of a solution.
The optimal solution is 1n, which has the maximal function value n. The running time of EAs has
been well studied on this problem . Particularly, the expected running time of (1+1)-EA
with mutation probability 1
n on it has been proved to be Θ(n log n) . It has also been recognized
as the easiest instance in the pseudo-Boolean function class with a unique global optimum for the
(1+1)-EA .
Deﬁnition 4 (Ieasiest Problem)
Ieasiest Problem of size n is to ﬁnd an n bits binary string x∗such that
x∗= arg maxx∈{0,1}n
where xi is the i-th bit of a solution x ∈{0, 1}n.
3. Noise is Not Always Bad
3.1. Empirical Evidence
It has been observed that noisy ﬁtness evaluation can make an optimization harder for EAs, since
it may make a bad solution have a “better” ﬁtness, and then mislead the search direction of EAs.
Droste proved that the running time of (1+1)-EA can increase from polynomial to exponential
due to the presence of noise. However, when studying the running time of (1+1)-EA solving the
hardest case Ihardest in the pseudo-Boolean function class, we have observed oppositely that noise
can also make an optimization easier for EAs, which means that the presence of the noise decreases
the running time of EAs for ﬁnding the optimal solution.
For Ihardest problem over {0, 1}n, there are 2n possible solutions, which are denoted by their corresponding integer values 0, 1, . . . , 2n−1, respectively. Then, we estimate the expected running time of
(1+1)-EA maximizing Ihardest when starting from every solution. For each initial solution, we repeat
independent runs for 1000 times, and then the average running time is recorded as an estimation
of the expected running time (brieﬂy called as ERT). We run (1+1)-EA without noise, with additive
noise and with multiplicative noise, respectively. For the mutation probability of (1+1)-EA, we use
the common setting p =
n. For additive noise, δ1 = −n and δ2 = n, and for multiplicative noise,
δ1 = 0.1 and δ2 = 10. The results for n = 3, 4, 5 are plotted in Figure 1. We can observe that the curves
by these two kinds of noise are always under the curve without noise, which shows that Ihardest problem becomes easier for (1+1)-EA in a noisy environment. Note that, the three curves meet at the last
point, since the initial solution 2n −1 is the optimal solution and then ERT = 1.
Initial solution
Estimated ERT
without noise
multiplicative
Initial solution
Estimated ERT
without noise
multiplicative
Initial solution
Estimated ERT
without noise
multiplicative
Figure 1: Estimated ERT comparison for (1+1)-EA solving Ihardest problem with or without noise.
3.2. A Sufﬁcient Condition
In this section, by comparing the expected running time of EAs with and without noise, we derive a
sufﬁcient condition under which the noise will make an optimization easier for EAs.
Most practical EAs employ time-invariant operators, thus we can model an EA without noise by a
homogeneous Markov chain. While for an EA with noise, since noise may change over time, we can
just model it by a Markov chain. Note that, the two EAs with and without noise are different only
on whether the ﬁtness evaluation is disturbed by noise, thus, they must have the same values on N1
and N2 for their running time Eq.2. Then, comparing their expected running time is equivalent to
comparing the EFHT of their corresponding Markov chains.
We ﬁrst deﬁne a partition of the state space of a homogeneous Markov chain based on the EFHT,
and then deﬁne a jumping probability of a Markov chain from one state to one state space in one
step. It is easy to see that X0 in Deﬁnition 5 is just X ∗, since E[[τ|ξ0 ∈X ∗]] = 0.
Deﬁnition 5 (EFHT-Partition)
For a homogeneous Markov chain {ξt}+∞
t=0, the EFHT-Partition is a partition of X into non-empty
subspaces {X0, X1, . . . , Xm} such that
∀x, y ∈Xi, E[[τ|ξ0 = x]] = E[[τ|ξ0 = y]];
E[[τ|ξ0 ∈X0]] < E[[τ|ξ0 ∈X1]] < . . . < E[[τ|ξ0 ∈Xm]].
Deﬁnition 6
For a Markov chain {ξt}+∞
ξ(x, X ′) = P
y∈X ′ P(ξt+1 = y|ξt = x) is the probability of jumping from
state x to state space X ′ ⊆X in one step at time t.
Given an EA A and a problem f, let a Markov chain {ξt}+∞
t=0 and a homogeneous Markov chain
t=0 model A running on f with noise and without noise respectively, and denote {X0, X1, . . . , Xm}
as the EFHT-Partition of {ξ′
t=0, if for all t ≥0, x ∈X −X0, and for all integers i ∈[0, m −1],
ξ(x, Xj) ≥
ξ′(x, Xj),
then noise makes f easier for A, i.e., for all x ∈X,
E[[τ|ξ0 = x]] ≤E[[τ ′|ξ′
The condition of this theorem (i.e., Eq.3) intuitively means that the presence of noise leads to a
larger probability of jumping into good states (i.e., Xj with small j values), starting from which the
EA needs less time for ﬁnding the optimal solution. For the proof, we need the following lemma,
which is proved in the appendix.
Let m (m ≥1) be an integer. If it satisﬁes that
∀0 ≤i ≤m, Pi, Qi ≥0, and
i=0 Qi = 1;
0 ≤E0 < E1 < . . . < Em;
∀0 ≤k ≤m −1,
then it holds that
i=0 Pi · Ei ≥
i=0 Qi · Ei.
Proof of Theorem 1. We use Lemma 3 to derive a bound on E[[τ|ξ0]], based on which this theorem
For using Lemma 3 to analyze E[[τ|ξ0]], we ﬁrst construct a distance function V (x) as
∀x ∈X, V (x) = E[[τ ′|ξ′
which satisﬁes that V (x ∈X ∗) = 0 and V (x /∈X ∗) > 0 by Lemma 1.
Then, we investigate E[[V (ξt) −V (ξt+1)|ξt = x]] for any x with V (x) > 0 (i.e., x /∈X ∗).
E[[V (ξt) −V (ξt+1)|ξt = x]] = V (x) −E[[V (ξt+1)|ξt = x]]
y∈X P(ξt+1 = y|ξt = x)V (y)
= E[[τ ′|ξ′
y∈X P(ξt+1 = y|ξt = x)E[[τ ′|ξ′
0 = x)E[[τ ′|ξ′
y∈X P(ξt+1 = y|ξt = x)E[[τ ′|ξ′
(by Lemma 1)
t+1 = y|ξ′
t = x)E[[τ ′|ξ′
y∈X P(ξt+1 = y|ξt = x)E[[τ ′|ξ′
(by Eq.1 and Lemma 2, since {ξ′
t=0 is homogeneous.)
ξ′(x, Xj) −P t
ξ(x, Xj))E[[τ ′|ξ′
(by Deﬁnitions 5 and 6)
ξ(x, Xj) = Pm
ξ′(x, Xj) = 1, E[[τ ′|ξ′
0 ∈Xj]] increases with j and Eq.3 holds, by
Lemma 4, we have
ξ′(x, Xj)E[[τ ′|ξ′
ξ(x, Xj)E[[τ ′|ξ′
Thus, we have, for all t ≥0, all x /∈X ∗,
E[[V (ξt) −V (ξt+1)|ξt = x]] ≥1.
Thus, by Lemma 3, we get for all x ∈X,
E[[τ|ξ0 = x]] ≤V (x) = E[[τ ′|ξ′
(the ‘=’ is by Eq.4)
which implies that noise leads to less time for ﬁnding the optimal solution, i.e., noise makes optimization easier.
We prove below that the experimental example satisﬁes this sufﬁcient condition. We consider (1+λ)-
EA, which covers (1+1)-EA and is much more general. Let {ξt}+∞
t=0 and {ξ′
t=0 model (1+λ)-EA with
and without noise for maximizing Ihardest problem, respectively. For Ihardest problem, it is to maximize the number of 0 bits except the optimal solution 1n. It is not hard to see that the EFHT
0 = x]] only depends on |x|0 (i.e., the number of 0 bits). We denote E1(j) as E[[τ ′|ξ′
with |x|0 = j. The order of E1(j) is showed in Lemma 5, the proof of which is in the Appendix.
For any mutation probability 0 < p < 0.5, it holds that E1(0) < E1(1) < E1(2) < . . . < E1(n).
Either additive noise with δ2 −δ1 ≤2n or multiplicative noise with δ2 > δ1 > 0 makes Ihardest
problem easier for (1+λ)-EA with mutation probability less than 0.5.
Proof. The proof is by showing that the condition of Theorem 1 (i.e., Eq.3) holds here. By Lemma 5,
the EFHT-Partition of {ξ′
t=0 is Xi = {x ∈{0, 1}n||x|0 = i} (0 ≤i ≤n) and m in Theorem 1 equals
to n here. Let f N(x) and f(x) denote the noisy and true ﬁtness, respectively.
For any x ∈Xk (k ≥1), we denote P(0) and P(j) (1 ≤j ≤n) as the probability that for the λ
offspring solutions x1, . . . , xλ generated by bit-wise mutation on x, min{|x1|0, . . . , |xλ|0} = 0 (i.e.,
the least number of 0 bits is 0), and min{|x1|0, . . . , |xλ|0} > 0 ∧max{|x1|0, . . . , |xλ|0} = j (i.e., the
largest number of 0 bits is j while the least number of 0 bits is larger than 0), respectively. Then,
we analyze one-step transition probabilities from x for both {ξ′
t=0 (i.e., without noise) and {ξt}+∞
(i.e., with noise).
t=0, because only the optimal solution or the solution with the largest number of 0 bit among
the parent solution and λ offspring solutions will be accepted, we have
ξ′(x, X0) = P(0);
∀1 ≤j ≤k −1 : P t
ξ′(x, Xj) = 0;
ξ′(x, Xk) =
∀k + 1 ≤j ≤n : P t
ξ′(x, Xj) = P(j).
For {ξt}+∞
t=0 with additive noise, since δ2 −δ1 ≤2n, we have
f N(1n) ≥f(1n) + δ1 ≥2n + δ2 −2n = δ2;
∀y ̸= 1n, f N(y) ≤f(y) + δ2 ≤δ2.
For multiplicative noise, since δ2 > δ1 > 0, then
f N(1n) > 0;
∀y ̸= 1n, f N(y) ≤0.
Thus, for these two noises, we have ∀y ̸= 1n, f N(1n) ≥f N(y), which implies that if the optimal
solution 1n is generated, it will always be accepted. Thus, we have, note that X0 = {1n},
ξ(x, X0) = P(0).
Due to the ﬁtness evaluation disturbed by noise, the solution with the largest number of 0 bit among
the parent solution and λ offspring solutions may be rejected. Thus, we have
∀k + 1 ≤i ≤n :
ξ(x, Xj) ≤
By combining Eq.5, Eq.6 and Eq.7, we have
∀1 ≤i ≤n :
ξ(x, Xj) ≤
ξ′(x, Xj).
ξ(x, Xj) = Pn
ξ′(x, Xj) = 1, the above inequality is equivalent to
∀0 ≤i ≤n −1 :
ξ(x, Xj) ≥
ξ′(x, Xj),
which implies that the condition Eq.3 of Theorem 1 holds. Thus, we can get that Ihardest problem
becomes easier for (1+λ)-EA under these two kinds of noise.
Theorem 1 gives a sufﬁcient condition for that noise makes optimization easier. If its condition Eq.3
changes the inequality direction, which implies that noise leads to a smaller probability of jumping
to good states, it obviously becomes a sufﬁcient condition for that noise makes optimization harder.
We show it in Theorem 3, the proof of which is as similar as that of Theorem 1, except that the
inequality direction needs to be changed.
Given an EA A and a problem f, let a Markov chain {ξt}+∞
t=0 and a homogeneous Markov chain
t=0 model A running on f with noise and without noise respectively, and denote {X0, X1, . . . , Xm}
as the EFHT-Partition of {ξ′
t=0, if for all t ≥0, x ∈X −X0, and for all integers i ∈[0, m −1],
ξ(x, Xj) ≤
ξ′(x, Xj),
then noise makes f harder for A, i.e., for all x ∈X,
E[[τ|ξ0 = x]] ≥E[[τ ′|ξ′
Then we apply this condition to the case that (1+λ)-EA is used for optimizing the easiest case Ieasiest
in the pseudo-Boolean function class. Let {ξt}+∞
t=0 and {ξ′
t=0 model (1+λ)-EA with and without
noise for maximizing Ieasiest problem, respectively. It is not hard to see that the EFHT E[[τ ′|ξ′
only depends on |x|0. We denote E2(j) as E[[τ ′|ξ′
0 = x]] with |x|0 = j. The order of E2(j) is showed in
Lemma 6, the proof of which is in the Appendix.
For any mutation probability 0 < p < 0.5, it holds that E2(0) < E2(1) < E2(2) < . . . < E2(n).
Any noise makes Ieasiest problem harder for (1+λ)-EA with mutation probability less than 0.5.
Proof. We use Theorem 3 to prove it. By Lemma 6, the EFHT-Partition of {ξ′
t=0 is Xi = {x ∈
{0, 1}n||x|0 = i} (0 ≤i ≤n).
For any non-optimal solution x ∈Xk (k > 0), we denote P(j) (0 ≤j ≤n) as the probability that
the least number of 0 bits for the λ offspring solutions generated by bit-wise mutation on x is j.
t=0, because the solution with the least number of 0 bits among the parent solution and λ
offspring solutions will be accepted, we have
∀0 ≤j ≤k −1 : P t
ξ′(x, Xj) = P(j);
ξ′(x, Xk) =
∀k + 1 ≤j ≤n : P t
ξ′(x, Xj) = 0.
For {ξt}+∞
t=0, due to the ﬁtness evaluation disturbed by noise, the solution with the least number of 0
bits among the parent solution and λ offspring solutions may be rejected. Thus, we have
0 ≤i ≤k −1 :
ξ(x, Xj) ≤
Then, we can get
∀0 ≤i ≤n −1 :
ξ(x, Xj) ≤
ξ′(x, Xj).
This implies that the condition Eq.8 of Theorem 3 holds. Thus, by Theorem 3, we can get that noise
makes Ieasiest problem harder for (1+λ)-EA.
3.3. Discussion
We have shown that noise makes Ihardest and Ieasiest problems easier and harder, respectively, for
(1+λ)-EA. These two problems are known to be the hardest and the easiest instance respectively in
the pseudo-Boolean function class with a unique global optimum for the (1+1)-EA . We can intuitively interpret the discovered effect of noise for EAs on these two problems. For Ihardest problem,
the EA searches along the deceptive direction while noise can add some randomness to make the EA
have some possibility to run along the right direction; for Ieasiest problem, the EA searches along the
right direction while noise can only harm the optimization process. We thus hypothesize that we
need to take care of the noise only when the optimization problem is moderately or less complex.
To further verify our hypothesis, we employ the Jumpm,n problem, which is a problem with adjustable difﬁculty and can be conﬁgured as Ieaisest when m = 1 and Ihardest when m = n.
Deﬁnition 7 (Jumpm,n Problem)
Jumpm,n Problem of size n with 1 ≤m ≤n is to ﬁnd an n bits binary string x∗such that
x∗= arg maxx∈{0,1}n
Jumpm,n(x) =
i=1 xi ≤n −m or Pn
i=1 xi = n
where xi is the i-th bit of a solution x ∈{0, 1}n.
We test (1+1)-EA with mutation probability 1
n on Jumpm,n. It is known that the expected running
time of the (1+1)-EA on Jumpm,n is Θ(nm + n log n) , which implies that Jumpm,n with larger
value of m is harder. In the experiment, we set n = 5, and for noise, we use the additive noise with
δ1 = −0.5n ∧δ2 = 0.5n, the multiplicative noise with δ1 = 1 ∧δ2 = 2, and the one-bit noise with
pn = 0.5, respectively. We record the expected running time gap starting from each initial solution
gap = (E[[τ]] −E[[τ ′]])/E[[τ ′]],
where E[[τ]] and E[[τ ′]] denote the expected running time of the EA optimizing the problem with and
without noise, respectively. The larger the gap means that the noise has a more negative effect, while
the smaller the gap means that the noise has a less negative effect. For each initial solution and each
conﬁguration of noise, we repeat the running of the (1+1)-EA 1000 times, and estimate the expected
running time by the average running time, and thus estimate the gap. The results are plotted in
We can observe that the gaps for larger m are lower (i.e., the negative effect by noise decreases as the
problem hardness increases), and the gaps for large m tend to be 0 or negative values (i.e., noise can
have no or positive effect when the optimization is quite hard). These empirical observations give
support to our hypothesis that the noise should be handled carefully only when the optimization is
moderately or less complex.
Initial solution
Estimated gap
Initial solution
Estimated gap
Initial solution
Estimated gap
(a) additive noise
(b) multiplicative noise
(c) one-bit noise
Figure 2: Estimated ERT gap for (1+1)-EA solving Jumpm,5 problem with or without noise.
4. On the Usefulness of Noise Handling Strategies
4.1. Re-evaluation
There are naturally two ﬁtness evaluation options for EAs :
• single-evaluation we evaluate a solution once, and use the evaluated ﬁtness for this solution
in the future.
• re-evaluation every time we access the ﬁtness of a solution by evaluation.
For example, for (1+1)-EA in Algorithm 1, if using re-evaluation, both f(x′) and f(x) will be calculated and recalculated in each iteration; if using single-evaluation, only f(x′) will be calculated and
the previous obtained ﬁtness f(x) will be reused. Intuitively, re-evaluation can smooth noise and
thus could be better for noisy optimizations, but it also increases the ﬁtness evaluation cost and thus
increases the running time. Its usefulness was not yet clear. Note that, the analysis in the previous
section assumes single-evaluation.
In this section, we take the Ieasiest problem, where noise has been proved to have a strong negative
effect in the previous section, as the representative problem, and compare these two options for
(1+1)-EA with mutation probability 1
n solving this problem under one-bit noise to show whether reevaluation is useful. Note that for one-bit noise, pn controls the noise level, that is, noise becomes
stronger as pn gets larger, and it is also the variable of the PNT.
The PNT of (1+1)-EA using single-evaluation with mutation probability 1
n on Ieasiest problem is lower
bounded by 1−1/Ω(poly(n)) and upper bounded by 1−1/O(2npoly(n)), where poly(n) indicates any
polynomial of n, with respect to one-bit noise.
The theorem is straightforwardly derived from the following lemma.
For (1+1)-EA using single-evaluation with mutation probability 1
n on Ieasiest problem under one-bit
noise, the expected running time is O(n2 + n/(1 −pn)) and Ω(npn/(2n(1 −pn))).
Proof. Let L denote the noisy ﬁtness value f N(x) of the current solution x. Because (1+1)-EA does
not accept a solution with a smaller ﬁtness (i.e., the 4th step of Algorithm 1) and it doesn’t re-evaluate
the ﬁtness of the current solution x, L (0 ≤L ≤n) will never decrease. We ﬁrst analyze the expected
steps until L increases when starting from L = i (denoted by E[[i]]), and then sum up them to get an
upper bound Pn−1
i=0 E[[i]] for the expected steps until L reaches the maximum value n. For E[[i]], we
analyze the probability P that L increases in two steps when L = i, then E[[i]] = 2 · 1
P . Note that,
one-bit noise can make L be |x|1 −1, |x|1 or |x|1 + 1, where |x|1 = Pn
i=1 xi is the number of 1 bits.
When analyzing the noisy ﬁtness f N(x′) of the offspring x′ in each step, we need to ﬁrst consider
bit-wise mutation on x and then one random bit ﬂip for noise.
When 0 < L < n −1, |x|1 = L −1, L or L + 1.
(1) For |x|1 = L−1, P ≥n−L+1
n)(n−1)pn n−L
n)(n−1)(1−pn) n−L
n)(n−1)(1−pn),
since it is sufﬁcient to ﬂip one 0 bit for mutation and one 0 bit for noise in the ﬁrst step, or ﬂip one
0 bit for mutation and no bit for noise in the ﬁrst step and ﬂip one 0 bit for mutation and no bit for
noise in the second step.
(2) For |x|1 = L, P ≥(1 −1
n)n−1(1 −pn), since it is sufﬁcient to ﬂip no bit for
mutation and one 0 bit for noise, or ﬂip one 0 bit for mutation and no bit for noise in the ﬁrst step.
(3) For |x|1 = L + 1, P ≥(1 −1
n)n(1 −pn + pn n−L−1
), since it is sufﬁcient to ﬂip no bit for mutation
and no bit or one 0 bit for noise in the ﬁrst step.
Thus, for these three cases, we have
P ≥pn(1 −1
n)(n−1) n −L
n)2(n−1)(1 −pn)2 n −L
≥1 (pn + (1 −pn)2)(n −L)(n −L −1)
≥2 3(n −L)(n −L −1)
where the ‘≥1’ is by (1 −1
e and the ‘≥2’ is by 0 ≤pn ≤1.
When L = 0, |x|1 = 0 or 1. By considering case (2) and (3), we can get the same lower bound for P.
When L = n−1 and the optimal solution 1n has not been found, |x|1 = n−2 or n−1. By considering
case (1) and (2), we can get P ≥3/(2e2n2).
Based on the above analysis, we can get that the expected steps until L = n is at most
i=0 E[[i]] ≤2 · (
3(n −L)(n −L −1) + 2e2n2
), i.e., O(n2).
When L = n, |x|1 = n −1 or n (i.e., the optimal solution has been found). If |x|1 = n −1, the optimal
solution will be generated and accepted in one step with probability 1
n)n−1(1 −pn) ≥(1−pn)
because it needs to ﬂip the unique 0 bit for mutation and no bit for noise. This implies that the
expected steps for ﬁnding the optimal solution is at most
Thus, we can get the upper bound O(n2 +
1−pn ) for the expected running time of the whole process.
Then, we are to analyze the lower bound. Assume that the initial solution xinit has n −1 number of
1 bits, i.e., |xinit|1 = n −1. If the ﬁtness of xinit is evaluated as n, which happens with probability
n, before ﬁnding the optimal solution, the solution will always have n −1 number of 1 bits and its
ﬁtness will always be n. From the above analysis, we know that in such a situation, the probability
of generating and accepting the optimal solution in one step is 1
n)n−1(1 −pn) ≤(1−pn)
the expected running time for ﬁnding the optimal solution when starting from |xinit|1 = n −1 is
at least pn 1
(1−pn). Because the initial solution is uniformly distributed over {0, 1}n, the
probability that the algorithm starts from |xinit|1 = n −1 is n/2n. Thus, we can get the lower bound
2n(1−pn)) for the expected running time of the whole process.
The PNT of (1+1)-EA using re-evaluation with mutation probability 1
n on Ieasiest problem is Θ( log(n)
with respect to one-bit noise.
The theorem is straightforwardly derived from the following lemma.
Lemma 8 ( )
For (1+1)-EA using re-evaluation with mutation probability 1
n on Ieasiest problem under one-bit
noise, the expected running time is polynomial when pn ∈O(log(n)/n), and the running time is
polynomial with super-polynomially small probability when pn ∈ω(log(n)/n).
4.2. Threshold Selection
During the process of evolutionary optimization, most of the improvements in one generation are
small. When using re-evaluation, due to noisy ﬁtness evaluation, a considerable portion of these
improvements are not real, where a worse solution appears to have a “better” ﬁtness and then survives to replace the true better solution which has a “worse” ﬁtness. This may mislead the search
direction of EAs, and then slow down the efﬁciency of EAs or make EAs get trapped in the local optimal solution, as observed in Section 4.1. To deal with this problem, a selection strategy for EAs
handling noise was proposed .
• threshold selection an offspring solution will be accepted only if its ﬁtness is larger than the
parent solution by at least a predeﬁned threshold τ ≥0.
For example, for (1+1)-EA with threshold selection as in Algorithm 3, its 4th step changes to be “if
f(x′) ≥f(x) + τ” rather than “if f(x′) ≥f(x)” in Algorithm 1. Such a strategy can reduce the risk
of accepting a bad solution due to noise. Although the good local performance (i.e., the progress of
one step) of EAs with threshold selection has been shown on some problems , its usefulness
for the global performance (i.e., the running time until ﬁnding the optimal solution) of EAs under
noise is not yet clear.
Algorithm 3 ((1+1)-EA with threshold selection)
Given pseudo-Boolean function f with solution length n, and a predeﬁned threshold τ ≥0, it consists of the following steps:
x := randomly selected from {0, 1}n.
Repeat until the termination condition is met
x′ := ﬂip each bit of x with probability p.
if f(x′) ≥f(x) + τ
where p ∈(0, 0.5) is the mutation probability.
In this section, we compare the running time of (1+1)-EA with and without threshold selection solving Ieasiest problem under one-bit noise to show whether threshold selection will be useful. Note
that, the analysis here assumes re-evaluation.
Algorithm 4 shows a random walk on a graph. Lemma 9 gives an upper bound on the expected steps
for a random walk to visit each vertex of a graph at least once, which will be used in the following
Algorithm 4 (Random Walk)
Given an undirected connected graph G = (V, E) with vertex set V and edge set E, it consists of the
following steps:
start at a vertex v ∈V .
Repeat until the termination condition is met
choose a neighbor u of v in G uniformly at random.
set v := u.
Lemma 9 ( )
Given an undirected connected graph G = (V, E), the expected cover time of a random walk on G is
upper bounded by 2|E|(|V | −1), where the cover time of a random walk on G is the number of steps
until each vertex v ∈V has been visited at least once.
The PNT of (1+1)-EA using re-evaluation with threshold selection τ = 1 and mutation probability 1
on Ieasiest problem is not less than 1
2e, with respect to one-bit noise.
The theorem can be directly derived from the following lemma.
For (1+1)-EA using re-evaluation with threshold selection τ = 1 and mutation probability 1
Ieasiest problem under one-bit noise, the expected running time is O(n3) when pn ≤
Proof. We denote the number of one bits of the current solution x by L (0 ≤L ≤n). Let Pd denote
the probability that the offspring solution x′ by bit-wise mutation on x has L + d (−L ≤d ≤n −L)
number of one bits, and let P ′
d denote the probability that the next solution after bit-wise mutation
and selection has L + d number of one bits.
Then, we analyze P ′
d. We consider 0 ≤L ≤n−1. Note that one-bit noise can change the true ﬁtness
of a solution by at most 1, i.e., |f N(x) −f(x)| ≤1.
(1) When d ≤−2, f N(x′) ≤L+d+1 ≤L−1 ≤f N(x). Because an offspring solution will be accepted
only if f N(x′) ≥f N(x)+1, the offspring solution x′ will be discarded in this case, which implies that
∀d ≤−2 : P ′
(2) When d = −1, the offspring solution x′ will be accepted only if f N(x′) = L ∧f N(x) = L −1,
the probability of which is pn n−L+1
n, since it needs to ﬂip one 0 bit of x′ and ﬂip one 1 bit of x.
−1 = P−1 · (pn L
(3) When d = 1, if f N(x) = L −1, the probability of which is pn L
n, the offspring solution x′ will be
accepted, since f N(x′) ≥L + 1 −1 = L > f N(x); if f N(x) = L ∧f N(x′) ≥L + 1, the probability of
which is (1 −pn) · (1 −pn + pn n−L−1
), x′ will be accepted; if f N(x) = L + 1 ∧f N(x′) = L + 2, the
probability of which is pn n−L
· pn n−L−1
, x′ will be accepted; otherwise, x′ will be discarded. Thus,
1 = P1 · (pn L
n + (1 −pn)(1 −pn + pn n−L−1
) + pn n−L
n pn n−L−1
(4) When d ≥2, it is easy to see that P ′
Because we are to get the upper bound of the expected running time for ﬁnding the optimal solution
1n for the ﬁrst time, we pessimistically assume that ∀d ≥2 : P ′
d = 0. Then, we compare P ′
1 with P ′
where the second inequality is by P1 ≥n−L
n)n−1 since it is sufﬁcient to ﬂip just one 0 bit, and
the last inequality is by (1 −1
−1 = P−1(pn
en2 · L(n −L + 1)
where the ﬁrst inequality is by P−1 ≤
n since it is necessary to ﬂip at least one 1 bit, the second
inequality is by pn ≤
2e, and the last inequality is by L(n−L+1)
Thus, we have for all 0 ≤L ≤n−1, P ′
−1. Because we are to get the upper bound of the expected
running time for ﬁnding 1n, we can pessimistically assume that P ′
−1. Then, we can view the
evolutionary process as a random walk on the path {0, 1, 2, . . . , n}. We call a step that jumps to the
neighbor state a relevant step. Thus, by Lemma 9, it needs at most 2n2 expected relevant steps to ﬁnd
1n. Because the probability of a relevant step is at least P ′
1 ≥P1(1−pn)2 ≥n−L
2e)2/en, the expected running time for a relevant step is O(n). Thus, the expected running time
of (1+1)-EA with τ = 1 on Ieasiest problem with pn ≤
2e is upper bounded by O(n3).
The PNT of (1+1)-EA using re-evaluation with threshold selection τ = 2 and mutation probability 1
on Ieasiest problem is lower bounded by1 −1/Ω(poly(n)) and upper bounded by 1 −1/O(2npoly(n)),
where poly(n) indicates any polynomial of n, with respect to one-bit noise.
The theorem can be directly derived from the following lemma.
For (1+1)-EA using re-evaluation with threshold selection τ = 2 and mutation probability 1
Ieasiest problem under one-bit noise, the expected running time is O(n log n/(pn(1 −pn))) and
Ω(n2/(2npn(1 −pn))).
Proof. Let L (0 ≤L ≤n) denote the number of one bits of the current solution x. Here, an offspring
solution x′ will be accepted only if f N(x′) −f N(x) ≥2. As in the proof of Lemma 10, we can derive
∀d ≤−1 : P ′
n ((1 −pn) + pn
) + (1 −pn)(pn
∀d ≥2 : P ′
Thus, L will never decrease in the evolution process, and it can increase in one step with probability
n)(n−1)((1 −pn)pn(1 −1
L(n −L −1)
2e(1 −pn)pn
Then, we can get that the expected steps until L = n (i.e., the optimal solution is found) is at most
(1 −pn)pn(n −L), i.e., O(
pn(1 −pn)).
Then, we are to analyze the lower bound. Assume that the initial solution xinit has n −1 number
of 1 bits. Before ﬁnding the optimal solution, the solution x in the population will always satisfy
|x|1 = n −1 because ∀d ≤−1 : P ′
d = 0. The optimal solution (i.e., |x|1 = n) will be found in one step
with probability P ′
1 = P1pn(1 −pn)(1 −1
n)(n−1)pn(1 −pn)(1 −1
n) ≤pn(1−pn)
. Thus, the
expected steps for ﬁnding the optimal solution when starting from |xinit|1 = n−1 is at least
By the uniform distribution of the initial solution, the probability that |xinit|1 = n −1 is n/2n. Thus,
we can get the lower bound Ω(
2npn(1−pn)) for the expected running time of the whole process.
4.3. Smooth Threshold Selection
We propose the smooth threshold selection as in Deﬁnition 8, which modiﬁes the original threshold
selection by changing the hard threshold value to a smooth one. We are to show that, by such a
small modiﬁcation, the PNT of (1+1)-EA on Ieasiest problem is improved to 1, which means that the
expected running time of (1+1)-EA is always polynomial disregard the one-bit noise level.
Deﬁnition 8 (Smooth Threshold Selection)
Let δ be the gap between the ﬁtness of the offspring solution x′ and the parent solution x, i.e., δ =
f(x′) −f(x). Then, the selection process will behave as follows:
(1) if δ ≤0, x′ will be rejected;
(2) if δ = 1, x′ will be accepted with probability
(3) if δ > 1, x′ will be accepted.
The PNT of (1+1)-EA using re-evaluation with smooth threshold selection and mutation probability
n on Ieasiest problem is 1, with respect to one-bit noise.
Proof. We ﬁrst analyze P ′
d as that analyzed in the proof of Lemma 10. The only difference is that
when the ﬁtness gap between the offspring and the parent solution is 1, the offspring solution will
be accepted with probability
5n here, while it will be always accepted in the proof of Lemma 10.
Thus, for smooth threshold selection, we can similarly derive
∀d ≤−2 : P ′
−1 = P−1(pn
5n + (1 −pn) + pn
) + (1 −pn)((1 −pn) · 1
∀d ≥2 : P ′
Note that L (0 ≤L ≤n) denotes the number of one bits of the current solution x. Our goal is to
reach L = n. If starting from L = n −1, L will reach n in one step with probability
5n + (1 −pn)(1 −pn) · 1
5n + (1 −pn)(1 −pn) · 1
5en2 (n −1
n + (1 −pn)2)
(by L = n −1 and (1 −1
5en2 · n −1
2n −1 ∈Ω( 1
(by 0 ≤pn ≤1)
Thus, for reaching L = n, we need to reach L = n −1 for O(n2) times in expectation.
Then, we analyze the expected running time until L = n −1. In this process, we can pessimistically
assume that L = n will never be reached, because our ﬁnal goal is to get the upper bound on the
expected running time for reaching L = n. For 0 ≤L ≤n −2, we have
P1 · (pn L
P−1 · (pn L
n)n−1 · (pn L
≥5n(n −L)(n −L −1)
eL(n −L + 1)
n−L−1) > 1.
Again, we can pessimistically assume that P ′
−1 and ∀d ≥2, P ′
d = 0, because we are to get the
upper bound on the expected running time until L = n −1. Then, we can view the evolutionary
process for reaching L = n −1 as a random walk on the path {0, 1, 2, . . . , n −1}. We call a step that
jumps to the neighbor state a relevant step. Thus, by Lemma 9, it needs at most 2(n −1)2 expected
relevant steps to reach L = n −1. Because the probability of a relevant step is at least
1 ≥P1((1 −pn)(1 −pn) · 1
5en2 ((1 −pn)2 + p2
(n −L)(n −L −1)
5en2 ((1 −pn)2 + 2
the expected running time for a relevant step is O(n4). Then, the expected running time for reaching
L = n −1 is O(n6).
Thus, the expected running time of the whole optimization process is O(n8) for any pn ∈ , and
then this theorem holds.
We draw an intuitive understanding from the proof of Theorem 9 that why the smooth threshold
selection can be better than the original threshold selections. By changing the hard threshold to be
a smooth threshold, it can not only make the probability of accepting a false better solution in one
step small enough, i.e. P ′
−1, but also make the probability of producing progress in one step
large enough, i.e., P ′
1 is not small.
5. Discussions and Conclusions
This paper studies theoretical issues of noisy optimization by evolutionary algorithms.
First, we discover that an optimization problem may become easier instead of harder in a noisy environment. We then derive a sufﬁcient condition under which noise makes optimization easier or
harder. By ﬁlling this condition, we have shown that for (1+λ)-EA, noise makes the optimization
on the hardest and the easiest case in the pseudo-Boolean function class easier and harder, respectively. We also hypothesize that we need to take care of noise only when the optimization problem
is moderately or less complex. Experiments on the Jumpm,n problem, which has an adjustable dif-
ﬁculty parameter, supported our hypothesis.
In problems where the noise has a negative effect, we then study the usefulness of two commonly
employed noise-handling strategies, re-evaluation and threshold selection. The study takes the easiest case in the pseudo-Boolean function class as the representative problem, where the noise signiﬁcantly harms the expected running time of the (1+1)-EA. We use the polynomial noise tolerance
(PNT) level as the performance measure, and analyzed the PNT of each EA.
The re-evaluation strategy seems to be a reasonable method for reducing random noise. However,
we derive that the (1+1)-EA with single-evaluation has a PNT lower bound 1 −1/Ω(poly(n)) from
Theorem 5 which is close to 1, whilst the (1+1)-EA with re-evaluation has the PNT Θ(log(n)/n) which
can be quite close to zero as n is large. It is surprise to see that the re-evaluation strategy leads to a
much worse noise tolerance than that without any noise handling method.
The re-evaluation with threshold selection strategy has a better PNT comparing with the re-evaluation
alone. When the threshold is 1, we derive a PNT lower bound
2e from Theorem 7, and when the
threshold is 2, we obtain 1 −1/Ω(poly(n)) from Theorem 8. The improvement from re-evaluation
alone could be explained as that the threshold selection ﬁlters out fake progresses that caused by
the noise. However, it still showed no improvements from the (1+1)-EA without any noise handling
We then proposed the smooth threshold selection, which acts like the threshold selection with
threshold 2 but accepts progresses 1 with a probability. We proved that the (1+1)-EA with the smooth
threshold selection has the PNT 1 from Theorem 9, which exceeds that of (1+1)-EA without any noise
handling method. Our explanation is that, like the original threshold selection, the proposed one
ﬁlters out fake progresses, while it also keep some chances to accept real progresses.
Although the investigated EAs and problems in this paper are simple and speciﬁcally used for the
theoretical analysis of EAs, the analysis still disclosed counter-intuitive results and, particularly,
demonstrated that theoretical investigation is essential in designing better noise handling strategies. We are optimistic that our ﬁndings may be helpful for practical uses of EAs, which will be
studied in the future.
6. Acknowledgements
to be added ...