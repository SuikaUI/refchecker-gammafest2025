Information & Management 58 103434
Available online 24 January 2021
0378-7206/© 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license ( 
Artificial intelligence capability: Conceptualization, measurement
calibration, and empirical study on its impact on organizational creativity
and firm performance
Patrick Mikalef a,*, Manjul Gupta b
a Department of Computer Science, Norwegian University of Science and Technology, Sem Sælandsvei 9, 7491, Trondheim, Norway
b Department of Information Systems and Business Analytics, College of Business Florida International University, Miami, FL, USA
A R T I C L E I N F O
Artificial intelligence
Firm performance
Organizational creativity
Capability
Resource-based theory
Instrument development
A B S T R A C T
Artificial intelligence (AI) has been heralded by many as the next source of business value. Grounded on the
resource-based theory of the firm and on recent work on AI at the organizational context, this study (1) identifies
the AI-specific resources that jointly create an AI capability and provides a definition, (2) develops an instrument
to capture the AI capability of the firms, and (3) examines the relationship between an AI capability and
organizational creativity and performance. Findings empirically support the suggested theoretical framework
and corresponding instrument and provide evidence that an AI capability results in increased organizational
creativity and performance.
1. Introduction
Artificial intelligence (AI) has emerged as a top technological pri­
ority of organizations over the past few years, largely fueled by the
availability of big data and the emergence of sophisticated techniques
and infrastructure . A recent report by Gartner indicated that the
number of organizations implementing AI grew 270 % in the past four
years and has tripled in the last year . While there is much excitement
about the potential business value that AI can deliver, organizations that
are beginning to adopt AI solutions are facing numerous challenges
which prevent them from realizing performance gains . In a 2019
global executive study published in the MIT Sloan Management Review,
seven out of 10 companies reported that AI has delivered minimal to no
business impact so far . Despite the large potential that AI technol­
ogies hold, Brynjolfsson et al. highlight that we are dealing with a
modern productivity paradox. According to the authors, one of the main
reasons AI has yet to deliver expected outcomes is due to implementa­
tion and restructuring lags. Organizations, therefore, need to invest in
complementary resources to be able to leverage their AI investments.
Understanding what complementary resources need to be developed
and implementing them is imperative in the quest of realizing perfor­
mance gains from AI. In other words, it is time to examine how orga­
nizations build an AI capability.
Within the IS literature we know that firms achieve competitive
performance gains by building unique, and hard to imitate capabilities,
which emerge by combining and deploying several complementary firm-
level resources . Building on this stream of research, this study
considers AI technologies as one such resource, which is necessary, but
not sufficient to develop an AI capability. Essentially this means that AI
techniques alone will be unlikely to deliver any competitive gains by
their own right, as they are easily acquired in the market and are subject
to replication. In addition, the data used to fuel these techniques alone
will be insufficient to create distinct AI capabilities. Early reports from
leading firms in terms of AI adoption highlight that organizations
require a unique blend of physical, human, and organizational resources
to create an AI capability, which can deliver value by differentiating it
from that of competitors . Despite a growing number of popular
press articles—most of which are written by technology consultants and
vendors—underscoring the importance of some key aspects organiza­
tions must consider, there is little theoretically grounded knowledge
about how to build AI capabilities.
This study draws on the resource-based theory (RBT) of the firm and
seeks to examine the resources that are required to build an AI capa­
bility. Findings from past studies have shown that the RBT is an
appropriate theoretical lens for dynamic and turbulent environments,
particularly when resource complementarity is fostered, and
* Corresponding author.
E-mail address: (P. Mikalef).
Contents lists available at ScienceDirect
Information & Management
journal homepage: www.elsevier.com/locate/im
 
Received 8 May 2020; Received in revised form 6 January 2021; Accepted 21 January 2021
Information & Management 58 103434
organizations develop distinctive capabilities around their respective
resources . We therefore provide the following definition:
“An AI capability is the ability of a firm to select, orchestrate, and
leverage its AI-specific resources.”
In developing the notion of an AI capability, we draw on past IT
capability literature, and on recent studies on AI in the organizational
context. The IS research is rich in understanding the enablers and effects
of different types of IT capabilities, such as social media capabilities
 , social commerce capabilities , and business analytics capa­
bilities . Nevertheless, as with any new technology, such as
that of AI, organizations need to develop a unique set of resources to
effectively leverage their investments to generate business value. By
building on these past studies and on recent research on AI in the
organizational context, we identify several key types of resources and
then categorize them into tangible, human skills, and intangibles re­
sources. In addition, this study develops a survey instrument to quantify
these resources and measure an organization’s AI capability. To do so,
we adhere to established guidelines for scale development in the man­
agement information systems (MIS) literature . Thus, we used an
expert panel to establish the content validity of the measures, and in
sequence, through a large-scale survey study using a sample of 143 se­
nior technology managers with knowledge of AI initiatives in their or­
ganizations, examined the psychometric properties of all measures. We
also examined the nomological validity of the AI capability scale by
testing its relationship with organizational creativity and organizational
performance.
The rest of the paper is organized as follows. In the next section we
briefly introduce the relevant literature around the RBT of the firm, as
well as that on AI. Next, in Section 3 we describe the different resources
that create an AI capability. In Section 4, we introduce the process by
which we arrive at the AI capability instrument, as well as the methods
used to validate it. The paper then discusses the theoretical and practical
implications of this research, as well as some important limitations.
2. Background
2.1. The RBT of the firm
The RBT of the firm has become one of the most widely applied
theoretical perspectives in explaining how the resources that an orga­
nization owns or has under its control can lead to differences in per­
formance in the same industry . Grounded in strategic management
literature, the RBT posits that firms compete based on the resources that
they have under their control, which providing are valuable, rare,
difficult to imitate, and non-substitutable can generate performance
gains . Later work on the RBT makes a distinction between
resource-picking and capability building, two distinct central facets of
the theory. Amit and Schoemaker define resources as tradable and
non-specific firm assets, and capabilities as non-tradable firm-specific
abilities to integrate, deploy, and utilize resources within the firm. As
such, resources represent the input of the production process, while a
capability is the potential to deploy these resources to improve pro­
ductivity and generate rents . By adopting this perspective, there
is an inherent assumption that firms’ capabilities are dependent and
developed based on the available set of organizational resources .
Therefore, the strength of a firm’s capabilities is determined by the re­
sources on which they are developed .
The RBT has been a central theoretical perspective in understanding
how information technology (IT) investments produce value and enable
firms to attain performance gains . This theoretical perspective is
also highly relevant in the context of our study since knowing which AI
resources firms must develop is crucial in generating rents from in­
vestments. Past studies applying the RBT have highlighted the fact that
apart from the technology itself, other human and complementary
organizational resources are required to leverage investments .
Empirical evidence from these and other past studies consistently
demonstrate the strength of the RBT in explaining the relationship be­
tween organizational resources and firm performance. Within the MIS
field, numerous studies have applied the RBT to examine if, and what
combination of IT and other complementary resources drive perfor­
mance gains .Melville et al. argue that the RBT allows re­
searchers to develop empirically testable propositions, an assessment of
which will enable us to advance our understanding of the value of
different IT resources and their role in affecting organizational perfor­
mance. Similarly, Wade and Hulland advocate that the RBT pro­
vides a cogent framework to evaluate the strategic value of information
system resources.
The value of the RBT in explaining organizational-level phenomena
is evident by the fact that it is a well-accepted theory in other business
disciplines including those of operations management , supply
chain management , and marketing among others. More than
three decades of empirical testing have thus established the RBT as a
prevailing paradigm for developing theoretical arguments and empiri­
cally examining the effect that organizational resources have on firm
performance . The RBT has also been suggested as an appropriate
theoretical lens in turbulent and frequently changing business environ­
ments, as resource complementarity, and developing distinctive and
hard-to-imitate capabilities has been long linked to competitive success
Since the aim of this study is to identify the necessary organizational
resources that will enable firms to develop their AI capabilities, which in
turn are argued to result in performance gains, the choice of the RBT as
the underlying theoretical framework of this study is deemed as
appropriate. Doing that through the RBT lens, we are not only able to
theorize about the strategic importance of organizational resources, but
also to develop associations about the effect of these resources, as in­
dependent variables, on firm performance as a dependent variable. The
central premise which studies that adopt the RBT build on is that the
bundling of resources facilitates the formation of organizational capa­
bilities, which, in turn, drive performance gains .
Several studies have put forth the different types of resources that are
required for the development of organizational capabilities that drive
performance . One of the most widely used classifications is that
proposed by Grant , who makes a distinction between tangible (e.g.,
physical and financial resources), human skills (e.g., knowledge and
skills of employees), and intangible (e.g., synergy, coordination, and
strategic orientation). This categorization of resources into tangible,
human skills, and intangible has been used extensively in the IS litera­
ture . Following this stream of literature, we adhere to the same
classification to categorize resources that form an AI capability. We
discuss these in the following sections.
2.2. Artificial intelligence
Despite the fact that AI has been a topic of interest for several de­
cades, there is still a lack of a universally accepted definition throughout
the literature. This lack of a definition to ground empirical studies on AI
has led to a fundamental problem of understanding AI in its entirety
 . In order to build a coherent understanding of AI, it is necessary to
first explore the notion of "intelligence", before ascribing this concept to
machines and defining the compound term "artificial intelligence". To
measure the intelligence of diverse technologies, such as those encom­
passed under the umbrella term AI, we must take a step back from the
specifics of systems and establish the underlying fundamentals of what it
is we are attempting to capture through the term "intelligence".
Grounded on a series of prior definitions, Legg and Hutter develop
an integrated definition of intelligence, explicating it as "the ability to
interact, learn, adopt, and resort to information from experiences, as
well as to deal with uncertainty". In combination with the above, the
notion "artificial" pertains to the idea of something being made by
P. Mikalef and M. Gupta
Information & Management 58 103434
humans, which is a copy or replica of something natural . Building
on the meaning of these two core notions, it is crucial that we develop a
more sophisticated understanding of the term AI. To enable a more
holistic and comprehensive understanding of what AI is, we identified
and selected five definitions of AI from relevant articles, which are
presented in Table 1.
From these definitions, all address the issue of human-like behavior
being replicated or enacted by machines. The underlying theme in all is
the attempt of AI to reproduce human cognitive processes in order to
address different situations. An emphasis on all definitions is the focus of
AI on emulating human learning mechanisms, processing information,
as well as dealing with states that require problem-solving. The only
exception is the definition provided by Poole and Mackworth who
describe the properties of the agents without attributing any charac­
teristics to human-like characteristics. Building on these definitions, as
well as on the delineation of the two comprising terms that form the
overall notion, we provide an integrative definition of AI that is used
throughout this article. Our goal in doing so is not to provide yet another
definition of AI, but one that is relevant in the context of information
systems research. Providing such a definition is in response to several
calls by editorials and recent studies on the role of AI in the organiza­
tional setting . Hence, we provide the following definition:
AI is the ability of a system to identify, interpret, make inferences, and
learn from data to achieve predetermined organizational and societal
In line with this definition, our understanding of an AI application is
that of any form of manufactured system that can autonomously
generate insights and/or take action based on these, to reach a set of
objectives. These objectives are narrowed to those that are directly or
indirectly relevant to the directions set out by organizations and soci­
eties. We purposefully avoid making any inference to human-like abil­
ities, as many AI applications that are used in the organizational setting
exhibit complementary characteristics to those of humans . Also, we
avoid describing AI as emerging directly from human programming,
since many AI applications are developed and tuned by other AI appli­
cations . As such, our definition diverges slightly from those pre­
sented in Table 1 and is limited in scope toward the study of
management and information systems–related phenomena. By devel­
oping this definition, it is thus easier to identify what does and what does
not constitute an AI within the organizational setting.
2.3. The business value of artificial intelligence
AI has been hailed by many academics and practitioners as a revo­
lutionary and game-changing set of technologies in the business world
 . Nevertheless, there are to date very few empirical studies
examining the effects that structured adoption of AI has on key perfor­
mance indicators. In addition, there is a large discussion about how AI
can fuel creativity in organizations . The reasoning in such claims is
that by automating many manual tasks, humans will have more time on
their hands to engage in creative activities. Also, through certain ap­
plications of AI, human capabilities can be augmented, through what is
termed augmented intelligence . The main idea is that specific AI
techniques can use large data-sets to assist professionals in creative
tasks, such as engineering, design, and the arts, by enhancing their input
information, and provide suggestions that would otherwise be hard to
develop . An example of such applications of AI can be found in the
latest designs of Philippe Starck, who in early 2020 introduced a new
series of chairs that were designed with the aid of AI. Through special­
ized software provided by Autodesk, in their Fusion 360 software
package, the designer was able to overcome his biases developed over
the years and come up with new creative concepts . Similar cases
are gradually emerging in different professions, documenting some of
the potential benefits that AI may have on the creativity of individuals,
and as an extension, on organizations.
Apart from enhancements in creativity, AI has also been suggested to
lead to improvements in various key performance indicators at an
organizational level. For example, applications that enable better
customer segmentation and facilitate better knowledge and interaction
with profitable segments, are suggested to improve market share and
customer retainment . Other applications of AI have been argued to
increase the speed of processing data, thus reducing bottlenecks and
improving overall operational efficiency . In their recent article,
Davenport and R. Ronanki . provide several examples of areas where
AI can be applied to automate processes, ranging from “reading” legal
and contractual documents to extract provisions, to replacing lost credit
or ATM cards and handling customer communications. Finally, by
enabling access to insight that would be impossible to uncover other­
wise, AI is argued to facilitate better decision-making by expanding the
range of insight top-management and other key decision-makers usually
have access to. Such insight can have significant effects on key perfor­
mance outcomes enabling organizations to slice-costs, expand their
products and/or services, and provide more personalized offerings to
customers .
3. Conceptualizing an AI capability
Although the published research on the business value and use of AI
in the organizational setting is still quite limited, there are some studies
that have identified obstacles when it comes to successful deployments
of AI projects . A large proportion of these studies have been from
practice-based press, which nevertheless draws on samples from leading
organizations in terms of AI adoption and use. For instance, a study by
Ransbotham et al. finds that a lack of technology competence is one
of the biggest inhibitors of deriving value from AI. Specifically, their
findings highlighted the fact that almost one in five organizations do not
understand the data requirements when it comes to AI, and the corre­
sponding technological infrastructure required to store and transport it.
Another recent study by Davenport and Ronanki noted that the
difficulty in integrating AI projects with existing processes and systems
was the main issue for derailing AI initiatives. In the context of the
public sector, Mikalef et al. find that the primary issue is the
inability to integrate systems and data, as well as to ensure that quality
data are utilized to train AI. Evidently, novel technological solutions are
required to address the new challenges that are caused by characteristics
of data needed for AI. Nevertheless, there have been great strides in the
progress of AI-related technologies in the last few years.
Although the AI-specific technology required to support initiatives is
forecasted to mature very fast, it is equally as important to focus on other
organizations resources that need to be fostered besides the technology.
These complementary organizational resources are what is needed to
Sample definitions of Artificial Intelligence.
Definition
Kaplan and Haenlein
A system’s ability to correctly interpret external data, to
learn from such data, and to use those learnings to achieve
specific goals and tasks through flexible adaptation
Russel and Norvig
Systems that mimic cognitive functions generally associated
with human attributes such as learning, speech, and problem
Dwivedi et al. 
The increasing capability of machines to perform specific
roles and tasks currently performed by humans within the
workplace and society in general
Knowles 
The theory and development of computer systems able to
perform tasks normally requiring human intelligence, such
as visual perception, speech recognition, decision-making,
and translation between languages
McCarthy 
The science and engineering of making intelligent machines
Mackworth 
Computational agents that act intelligently and perceive
their environments in order to take actions that maximize
chances of success
P. Mikalef and M. Gupta
Information & Management 58 103434
build firm-specific, and hard-to-imitate AI capabilities . We define
AI capability as the ability of a firm to select, orchestrate, and leverage its
AI-specific resources. An indicative example of the complementary or­
ganizations resources that are required in order to realize business value
from AI investments is that provided in the study of Ransbotham et al.
 . The authors of the study who note that one of most important
barriers in realizing value is the lack of leadership to support AI, while
Davenport and Ronanki highlight that in more than a third of the
surveyed organizations, managers do not understand AI technologies
and how they work. Several practice-based studies have emphasized the
importance of such complementary resources. For instance, Fountaine
et al. underscore the importance of fostering inter-departmental
coordination, developing cross-functional teams with a mix of skills
and perspectives. By having analytics experts work together with busi­
ness and operational people, organizations can ensure that AI initiatives
address broad organizational priorities, and not just isolated business
issues. Doing so will also ensure that the developed AI applications are
better aligned with regard to operational needs. Another challenge
noted by several studies relates to the AI-specific skills that companies
need to develop, as working with AI requires a completely new type of
skill-set for both technical and managerial personnel .
The studies discussed so far, as well as several other academic pub­
lications and business reports highlight the diversity of resources that
organizations need to foster in order to derive business value from their
AI investments. Nevertheless, there is a lack of theoretically grounded
research about how organizations can create an AI capability. This is an
important gap for both research and practice, as it can indicate the core
areas that organizations should steer their focus toward when deploying
AI initiatives and provide a notion upon which to gauge the potential
business value and mechanisms of value creation. Building on the
theoretical underpinnings of the RBT , on empirical work
adopting the RBT in the IS domain , as well as on recent studies
that outline the challenges related to AI adoption and value generation
 , we propose eight resources which we argue jointly
constitute an AI capability (Fig. 1). These resources can either be directly
owned by the focal firm or be acquired through service agreements. The
theoretical framing of the RBT allows for such types of resource
“ownership” as it essentially underscores the importance of controlling
resources. In the context of IT-related resources this is very important as
many companies use the support of external IT vendors for solutions that
cannot be developed in-house .
The previously mentioned resources were identified by surveying
existing academic studies, analyzing practitioner reports and through a
series of unstructured interviews with academics and practitioners
through a deductive approach. The identified resources were then
grouped into three categories based on the framework of Grant .
Tangible resources comprise data, technology, and basic resources,
while human resources consist of business and technical skills.
Inter-departmental coordination, an organizational change capacity,
and risk proclivity are included as three critical intangible resources that
are required to build an AI capability. In the sub-sections that follow we
discuss each of these resources in detail. The RBT and the identification
of important resources in the formation of a capability are also a relevant
perspective for practice, as managers and practitioners can develop
specific benchmark criteria and quantify their readiness in each of the
dimensions. By doing so, they can reveal potential weaknesses that can
be addressed through targeted actions.
3.1. Tangible resources
Following the literature on the RBT, tangible resources are consid­
ered those that can be sold or bought in a market . For instance,
physical assets, such as equipment or facilities, and financial assets, such
as debt and equity, are different types of tangible resources. As tangible
resources, are to a large extent available in the market for all firms, these
resources are not likely to provide a competitive advantage per se.
Nevertheless, tangible resources are necessary, but not sufficient by
themselves to create capabilities
3.1.1. Data
Based on a recently published study by the MIT Sloan Management
Review, data are considered by managers as one of the key enablers in
leveraging the potential of AI . While organizations have traditionally
focused on structured data in order to guide business decisions, today’s
organizations capture a large diversity of data stemming from multiple
sources and in different formats . In fact, the availability of
high-quality data is considered critical, as it is used to train the AI al­
gorithms. A recent study by Ransbotham et al. found that pioneering
organizations in AI follow a common understanding within their man­
agement teams which regards data as a corporate asset. The conver­
gence of big data with AI has emerged as one of the most important
developments, and is shaping how firms drive business value from their
data resources . When it comes to developing AI applications that
can deliver value, the quality of the data that are fed into such algo­
rithms are of great importance. Since AI systems require massive
training data-sets, and applications effectively “learn” from available
information in a manner similar to the way humans do, there is a high
requirement on large amounts of high-quality data. In addition to the
issues of quality, many AI applications are developed in a supervised
way, which places a heavy focus on appropriate labeling of data .
Adding to this issue, skewed data during labeling and training can
potentially result in biased AI applications . These alone pose some
significant challenges to practitioners in leveraging their data assets into
AI applications. Over the past few years a lot has been written about the
opportunities of utilizing big data , with a multitude of papers
specifying its defining characteristics, or the sources from which firms
can source data with high value potential . The significance of
the data resource was even noted in an article in The Economist, refer­
ring to data as the new oil which when refined can be a source of
competitive advantage .
The data that organizations have access to can be broadly catego­
rized into two types, internal and external data . Internal data
include all that are created by the organization’s internal operations
such as accounting, sales, human resource management, and manu­
facturing/production. Traditionally, internal data represented a large
proportion of the overall data organizations were utilizing to base de­
cisions on. Yet, relying on such data to base business decisions on is
unlikely to result in a competitive edge. External data refer to that which
is not directly related to the firm’s operations but can provide novel and
deeper insights about the competitive landscape in which contemporary
organizations operate. The large volumes of inflowing external and in­
ternal data while providing unprecedented opportunities for organiza­
tions also pose a great challenge, that of filtering out noisy data and
reducing their size into manageable and meaningful sets . However,
there needs to be an equilibrium when reducing data through cleansing,
as summarized data may obscure some key insights, relationships, and
patterns, so that a right degree of granularity is achieved toward desired
Fig. 1. AI capability and categorization of resources.
P. Mikalef and M. Gupta
Information & Management 58 103434
objectives. Thus, firms interested in leveraging data to enable AI must
integrate internal and external data sources, while at the same time
manage to cleanse, process, and distribute data throughout organiza­
tional boundaries as needed.
3.1.2. Technology
One of the main challenges in leveraging these large, unstructured,
fast-moving and complex data sources to build AI applications, concerns
the underlying technological infrastructure required to bring them to
life. Such novel forms of data call for radically new technologies to store,
process, transfer, and secure data through all the stages from acquisi­
tion, insight generation, and to training AI applications. Data storage
requirements for AI vary significantly according to the application and
source material. In addition, the data requirements fluctuate depending
on the stage of AI application development and use, which puts a
requirement on firms to invest in storage infrastructures that can support
the volume and different formats, as well as be scalable depending on
the demand . Apart from the flexible data storage, AI technologies
also put pressure on organizations to invest in technologies that can
quickly process data and run complex algorithms. Common approaches
include the use of GPU-intensive clusters and using parallel computing
techniques to deal with the processing power required . Many or­
ganizations are also adopting cloud-based solutions to deal with the
large cost associated with AI infrastructure, while a new market for in­
tegrated cloud services that allow complex AI methods to be applied
through simple API calls has gained prevalence over the last years .
A recent report published by McKinsey highlights that a lack of
technological infrastructure is one of the main barriers in adopting AI in
organizations . As AI technologies require infrastructure in­
vestments at multiple levels, this proves to be a major obstacle for many
organizations, particularly those with less slack resources . For
instance, deep learning systems, with their ability to retrain themselves
as they operate, require a constant feed of updated data. This essentially
translates to infrastructure investments being made through the whole
pipeline from ingest to inference, from storage, transfer through high
bandwidth networks, to processing power. The technological infra­
structure is also highly dependent on the type of techniques that are
used, which means that organizations can end up having to invest in
several different supporting technologies. For instance, applications of
computer vision require devices with built-in cameras able to capture
images at a high frame-rate, high-bandwidth networks, and hardware
designed specifically for handling the processing complexity of image
segmentation, object detection, pattern detection, and feature matching
3.1.3. Basic resources
Apart from the investments in data and the technological infra­
structure to support AI, organizations need to be able to provide time
and financial resources to allow such initiatives to deliver expected
outcomes. As most organizations are just now experimenting with AI,
the vast majority of initiatives will need some time to mature before
being released and yielding value . Adding to time requirements,
another important aspect that organizations must invest in is providing
adequate financial resources to allow AI applications to develop. In a
2017 study by McKinsey, the majority of respondents reported that less
than one-tenth of their digital technology spending was on AI initiatives
 . However, allocating financial resources for AI projects is essential,
as internal budgeting for such initiatives requires that technical and
non-technical employees can utilize some of their working hours in
developing AI applications and have the necessary technological infra­
structure to do so. In fact, the experimentation with proof-of-concept
pilots is regarded as a best practice when it comes to AI initiatives,
where the organization can test different technologies and methods .
For example, the multinational pharmaceutical company Pfizer has over
60 AI projects currently, many of which are just at a pilot stage .
Based on these reports on industry, and consistent with prior IS business
value research , we argue that investments and time are a
group of basic resources which are required to create an AI capability.
Schryen in his review paper on IS business value refers to time and
financial investments as required resources to realize value. To distin­
guish these resources from the other resources introduced in this study,
we use the label “basic resources”.
3.2. Human resources
The human capital of an organization is often measured by assessing
the knowledge, skills, experience, leadership qualities, vision, commu­
nication and collaboration competencies, and problem-solving abilities
of its employees. Past research on digital capabilities has identified
technical and business skills as critical pillars of human resources .
Following this line of reasoning this study suggests that AI-specific
technical and business skills are two important components of a firm’s
human AI resources.
3.2.1. Technical skills
When referring to technical AI skills, we mean those that are
necessary in order to deal with the implementation and realization of AI
algorithms, managing the infrastructure to support such initiatives, as
well as those to introduce and ensure AI applications adhere to goals.
More specifically, algorithm developers are necessary in order to utilize
latest AI research and transform it into repeatable processes through
mathematical formulas that can be implemented through hardware and
software . It has been suggested that most careers in technical as­
pects of AI will require individuals with a strong background in statis­
tics, probability, predictions, calculus, algebra, Bayesian algorithms,
and logic. In addition, a good background in programming, logic, data
structures, language processing, and cognitive learning theory has been
highlighted as an essential technical AI skill . A recent article in the
MIT Sloan Management Review presents three key roles that will emerge
as technical profiles in the age of AI: trainers, explainers, and sustainers
 . Trainers are concerned with teaching AI systems how they should
perform, and include tasks of helping service chatbots, for instance,
identify the complexities and subtleties of human communication. Ex­
plainers bridge the gap between the technologists and the business
managers by providing clarity regarding the inner workings of AI sys­
tems to non-technical audiences. Finally, sustainers ensure that AI sys­
tems are operating as expected and that any unanticipated consequences
are addressed with appropriately. Each of these three roles includes a list
of more detailed job functions that are already becoming critical for
contemporary organizations. While these skills are currently scarce in
the market, it is argued that they will gradually become more common,
as higher-education and online training courses are emerging, making
this resource a commodity across firms over time .
3.2.2. Business skills
One of the most commonly cited barriers in adopting and leveraging
AI technologies in the organizational setting is the lack of knowledge of
managers regarding how and where to apply such technologies . In
fact, in a recent survey published in the MIT Sloan Management Review,
a lack of leadership support for AI initiatives was ranked as one of the
top hindrances in adopting AI . Realizing business value for AI in­
vestments requires a real understanding and commitment on the part of
the leaders to drive a large-scale change. In addition, managers need to
understand the potential application areas of AI, and how to handle the
transition to AI-enabled activities. A striking finding by Davenport and
R. Ronanki noted that one in three managers do not understand how
AI technologies work. It is therefore imperative that managers become
acquainted with the types of AI technologies and their potential uses
within different functions of the organization. Another important aspect
is the ability of managers to initiate and plan AI deployments . This
is particularly important when considering the strong forces that exist
within organizations against change, and the threat that AI may replace
P. Mikalef and M. Gupta
Information & Management 58 103434
many of the jobs that are currently held by employees. Thus, it is
important that managers develop good working relationships between
the technical employees and staff of the line function to minimize fric­
tions and potential forces of inertia, which could delay the adoption of
AI and impede business value . Being able to capture the opportu­
nities of the different AI technologies and managing the organizational
change that are entailed with AI deployments will likely be a resource
that will be difficult to imitate by other firms.
3.3. Intangible resources
From the three main types of organizational resources that have been
identified in the RBT , intangible resources are regarded as those
that are more difficult to replicate by other firms and are of heightened
importance in uncertain and volatile markets . Unlike the other two
categories of resources, intangibles are much more elusive and difficult
to identify within organizations . Nevertheless, despite being diffi­
cult to measure, they are also the type of resources that meet the VRIN
status of the RBT . This means that no two resources are the same
across firms as they are highly heterogeneous and unique. The hetero­
geneity and non-replicability of intangible resources owe themselves to
the fact that they are developed through the unique mixture of organi­
zational history, people, processes, and conditions that characterize
organizations. Early reports on the drivers of AI success ) as well
as a long history of empirical IS research , highlight the
importance of intangible resources in reaping business benefits from
adopted technologies. In the context of AI, the resources we have
identified are inter-departmental coordination, organizational change
capacity, and risk proclivity.
3.3.1. Inter-departmental coordination
The ability to coordinate tasks and share a mutual vision among the
different departments of an organization is regarded as a cornerstone of
cross-disciplinary
inter-departmental coordination has long been noted as a key enabler of
innovation and creativity in organizations . Inter-departmental co­
ordination has been defined as “a state of high degrees of shared values,
mutual goal commitments, and collaborative behaviors” . Based on this
perspective, what is important are continuous relationships between
departments rather than simple transactions between departments .
On the same lines, recent studies in AI and business value argue that to
unleash the value of AI technologies, organizations must foster a culture
of teamwork, collective goals, and shared resources .
Fountaine et al. note that AI has the biggest impact when it is
developed by cross-functional teams with a mix of skills. By doing so,
organizations will ensure that AI initiatives address broad organiza­
tional priorities and not just isolated business issues. By fostering
inter-disciplinary teams, organizations are also suggested to be able to
think through the operational challenges new applications may require,
thus improving the overall performance of deployed AI solutions.
Finally, enhancing inter-departmental coordination is likely to make
organizations more agile and adaptable in deploying AI applications, as
a shared language and a common understanding of employees between
different departments will lead to reduced times in deploying new AI
applications or adapting existing ones when the need arises . The
importance of inter-departmental coordination is also noted in a recent
study, which highlights that functional silos are one of the most
important barriers in deriving business value from AI investments as
they constrain end-to-end solutions being developed .
3.3.2. Organizational change capacity
The ability of organizations to initiate and follow through execution
of plans has long been regarded as a key success factor in digital
transformation . Organizational change capacity focuses on the
potential problems that may arise due to failure to transition from an old
process to a new one. In both management literature and IS studies,
developing a capacity that minimizes frictions and inertia associated
with change is considered as a key resource of digital transformation
capabilities and overall business value . Grover et al. note
that organizational change capacity entails the ability of breaking the
organizational status quo and introducing new practices, new values,
and new structures. AI applications introduce significant changes to how
organizations perform their key activities, either by replacing tradi­
tionally human-executed tasks, or by augmenting existing processes
 . Being able to plan for and manage such change, at multiple levels
within the organization, is suggested to be an important component of
realizing value from AI investments .
In a recently published article in the Harvard Business Review, one of
the main findings on how to make AI deliver business included the
ability to overcome unique barriers to change . Each organization
will present a unique set of inhibiting factors that delay, or even obstruct
change. It is therefore important that managers foster a capacity to
anticipate, plan, and execute change at an organizational level. In
Appian’s Future of Work survey of 500 senior level IT managers ,
the most important barriers in leveraging AI investments were according
to respondents, changing the existing IT and business cultures. Similar
results were noted in a large-scale study conducted by the MIT Sloan
Management Review, which indicated that more than 40 % of re­
spondents faced challenges of cultural resistance to AI approaches,
which greatly hindered adoption and business value of AI investments
 . An organization that is unable to overcome these forces of resistance
is unlikely to be able to derive value from AI investments. Even with vast
amounts of data, highly skilled technical personnel, and state-of-the-art
AI infrastructure, an organization that is unable to leverage these and
change its existing way of doing business to incorporate AI advance­
ments will not be able to realize performance gains.
3.3.3. Risk proclivity
In their recent survey of top-level executives in 29 industries and
located in 126 countries, Ransbotham et al. found that the organi­
zations that adopt a more risk-oriented approach to new ventures such
as AI, reap the benefits much before their competitors or new entrants
do. This strategic orientation toward risk-taking has been highlighted in
management under different terms (e.g., risk proclivity, entrepreneurial
orientation, proactive stance) , and is associated with typologies
that reflect proactive and aggressive initiatives to alter the competitive
scene (e.g., prospectors) . This body of research underscores the
impact of adopting such a risk-taking and proactive stance, which is
commonly associated with higher levels of innovation output and mar­
ket leadership . When it comes to AI adoption, Ransbotham
et al. highlight that organizations that embrace risk proclivity
deepen their commitments to AI, and in doing so establish their position,
which makes it harder for others to catch up. The CIO of Chevron, Bill
Braun, notes that AI is one of the most exciting-value-added, and
competitive parts of business in the future , indicating that risk-takers
perceive AI as an opportunity that they must capitalize on before com­
petitors do. The shift of orientation that is required to derive value from
AI is also highlighted by Fountaine et al. who argue that organiza­
tions must depart from risk-averse strategic orientation and become
agile, experimental, and adaptable. The main idea is that companies that
are willing to move out of standard practices and adopt new and more
ambitious targets are also more likely to see the formation of strong AI
capabilities compared to those that adopt a more conservative approach.
Based on the above, it is safe to suggest that organizations with a high
proclivity toward risky projects are likely to be the first to embrace AI
and gain the first-mover advantage. By doing so, they are able to
consolidate their position long after, and be within the group of pioneers
that enjoys a competitive advantage from leveraging their AI resources
toward strategic objectives.
P. Mikalef and M. Gupta
Information & Management 58 103434
3.4. Impact on organizational creativity and performance
Through the previous argumentation on the role of AI in business, it
is clear that a lot of emphasis has been placed on the role that such
technologies may play in making organizations more creative and
improving their performance. We develop our argumentation on this
relationship through the conceptual research model presented in Fig. 2.
In fact, there have been several documented cases in different industries
where developing an AI capability has resulted in organizational crea­
tivity gains . While these cases tend to be rather narrow in scope,
they do signal that AI has an impact on the creative process within or­
ganizations. Apart from direct effects by augmenting human intelli­
gence, such as in the example of the designer we described earlier, AI
can also automate many manual processes that require considerable
time and human capital. By freeing up human resources that have the
potential to engage in creative processes, firms will be more likely to
innovate. Both cases, however, require that AI be deployed beyond an
experimental stage, so that it is viable to free up human resources on the
long term. As such, local experimental applications of AI need to be
scaled up to an organizational-wide AI capability. Adding to the above,
when AI technologies are deployed and used toward organizational
goals they can enable managers to gain insight that was previously
unobtainable by making sense of vast amounts of data and uncovering
patterns and relationships . Several such applications of AI have
been described in recent articles, where new insight essentially results in
new creative solutions within organizational boundaries .
Yet, enhancing the creative process is not the only way in which AI
can deliver value to organizations. Improving operational inefficiencies
and automating tasks through AI have direct effects on different per­
formance indicators, such as reducing costs, improving time-to-respond,
slicing down production times and costs, and improving customer
relationship management . Being able to derive such value, how­
ever, necessitates that AI solutions are deployed as part of organizational
efforts and there is a shared vision and understanding of their objective.
Early studies have documented that such a structured approach in
deploying AI solutions can result in performance gains for firms in a
range of industries . Applications such as chat-bots, intelligent
agents, and even process automating methods of AI have the potential to
generate performance gains for organizations. Based on the foregoing
argumentation, we can hypothesize the following:
An AI capability will have a positive effect on organizational
creativity
An AI capability will have a positive effect on organizational
performance
Recent literature in the domain of IT-enabled organizational capa­
bilities posits that the use and deployment of different IT solutions can
lead to the generation of certain meta-capabilities . In essence,
such deployments of IT often have indirect effects on key performance
indicators, by enabling certain key organizational capabilities. For
example, Mikalef and Pateli indicate that leveraging IT to enable
dynamic capabilities allows firms to attain market capitalizing and
operational adjustment agility, which are key components of a
competitive advantage. Other studies have documented similar findings,
with IT being the driver of increased business flexibility , ampli­
fiers of an intrapreneurship culture , and as a tool to mitigate
tradeoffs . Following the same logic, we argue that an AI capability
can have indirect effects on organizational performance, through its
effect on organizational creativity. Several performance indicators are
contingent on the creative solutions that emerge within the organiza­
tion. Similar to the notion of IT wisdom, as described by Liu et al. ,
we suggested that an AI capability can help generate knowledge within
the organizations boundaries, which then can be harnessed to improve
performance. Thus, we hypothesize the following:
Organizational creativity will have a positive effect on organiza­
tional performance
4. The AI capability instrument
4.1. Conceptualization and measurement of constructs
As introduced earlier, this study defines an AI capability as a firm’s
ability to structure, bundle, and leverage its AI-based resources. In line with
this definition, the AI capability construct is conceptualized as a multi­
dimensional third-order formative construct, which is comprised of the
following AI-specific dimensions: tangible resources, human skills, and
intangible resources. These dimensions are, in turn, conceptualized as
second-order formative constructs comprising eight first-order con­
structs (Table 2).
The measures used to develop the first-order constructs were either
adapted or created from existing literature on digital capabilities, while
some were based on business reports and expert interviews. As such, the
AI capability construct differs significantly from other digital capability
constructs such as IT capability as the resources that comprise it are AI-
specific. Digital technologies correspond to IT-related resources that
support core organizational activities such as computer-supported
collaborative work, supply chain management, and human resource
management . When such digital technologies are combined
with other organizational-level resources, they allow the creation of
digital capabilities . Despite the fact the AI and the data used to
develop such applications can be considered digital resources, it is the
combination with other AI and organizational-related resources that
collectively lead to the emergence of an AI capability. This idea is re­
flected in the proposed theoretical framework (Fig. 1) and in the items
used to capture the first-order constructs, which are related specifically
to AI use within organizations (Table 3).
For example, the data construct and the corresponding items capture
the degree to which an organization has access to data at the rights level
of granularity, and whether the organization can integrate and effec­
tively cleanse data to be suitable for AI applications. Similarly, the
technology construct indicates whether an organization has invested in
the necessary hardware and software AI technologies to enable flexible
data storage (e.g., cloud-based services), analysis (e.g., Microsoft
Cognitive Services, Google Cloud Vision), processing (e.g., Parallel
computing, CPUs, GPUs), and transfer within and beyond firm bound­
aries. Through the technical and business skills constructs, we capture
the level to which the technical and business staff have AI-specific skills.
The inter-departmental coordination construct identifies the extent to
which there is a culture of open communication and collaboration be­
tween departments, and the degree to which they have a shared vision.
Organizational change capacity captures the level to which the organi­
zation can agilely adapt to evolving conditions, while risk proclivity
measures the degree to which an organization has an attitude of
engaging in high-risk projects that can potentially yield high returns.
The three later constructs correspond to the intangible organizational
resources that firms must possess in order to be successful in the age of
Fig. 2. Conceptual research model.
P. Mikalef and M. Gupta
Information & Management 58 103434
4.2. Artificial intelligence capability as a higher-order formative construct
In this study, we develop the construct of an AI capability as a higher-
order formative construct. Benitez et al. identify two types of
formative constructs, composite, and causal-formative constructs. The
former is explained nicely through a brewery analogy, where different
recipes exist to produce beer, denoting the idiosyncratic nature of ca­
pabilities. In essence, this model can be understood as a recipe for how
ingredients (the components) should be coalesced to build the artifact
 . Causal-formative constructs, however, assume that the observed
indicators cause the latent variable. In this study we develop the AI
capability construct as a composite type as we assume that every orga­
nization develops its own unique version of an AI capability through its
idiosyncratic means of orchestrating and leveraging the corresponding
resources. Based on this emerging stream of research, we proceed to
describe the formative nature of the AI capability construct.
Following the IT capability and big data analytics capability litera­
ture , which grounds conceptualizations on the RBT, this study
conceptualizes the AI capability construct through three main di­
mensions: tangible resources, human skills, and intangible resources. As
this study extend significantly from prior studies that are based on the IT
capability literature, we start by examining whether the IT capability
construct has been developed as a reflective or formative construct.
Within this body of research there is considerable variation, with some
studies such as those of Lu and Ramamurthy and Kim et al. ,
developing their conceptualization of IT capability as a higher-order
reflective construct, whereas others such as Wang et al. and
Ravichandran and Lertwongsatien conceptualizing IT capability as
a higher-order formative construct. This divergence in notions that
attempt to capture the same underlying concept is an important one to
resolve, as the choice of measuring a construct reflectively versus
formatively may result in a different overall construct .
Adding to the above, although the measure may have the same
naming, the indicators that are used to compose a construct will
significantly differ if the construct is formative versus reflective .
By surveying the existing body of literature in terms of how they develop
the notions of IT capability, this difference in measurement and its ef­
fects becomes evident. This difference in how similar concepts have
been conceptualized and measured essentially has to do with how the
researchers have defined the concept at hand and on the theoretical and
research objectives of the study . Based on the provided definition
of the AI capability notion, and the nature of the underlying dimensions
as described in the conceptualization section, we applied four widely
accepted decision rules to conceptually assess whether the construct
should be developed as a higher-order formative or reflective one [119,
First, from the proposed underlying dimensions (tangible resources,
human skills, and intangible resources), there is no single one that can
adequately explain the notion of an AI capability. This observation is a
strong criterion that tangible, human skills, and intangible resources are
core characteristics, rather than manifestations of the AI capability.
Extending on this logic, Chen et al. argue that due to the fact that
IT capability constructs are quite broad, it is preferable to model capa­
bility constructs as formative. This is true also in the case of an AI
capability, as the three main dimensions that comprise the construct
cover complementary facts of the overall capability.
Second, the three dimensions that comprise the AI capability
construct capture very distinct aspects of an organization’s AI capability.
There is also a minimal degree of overlap between the dimensions. This
essentially means that removing one dimension would have a significant
impact on the completeness of the overall construct, as the dimensions
are not interchangeable. If we were to adopt a reflective conceptuali­
zation of the construct, dropping one dimension to satisfy reliability
criteria would mean removing a large essential facet of the AI capability
construct. In contrast with reflective conceptualizations where items or
dimensions are interchangeable, a formative conceptualization dictates
that all items or dimensions are essential parts of the whole. In our case,
if, for example, we dropped the dimension of human skills, it would be
unlikely that the dimensions of tangible or intangible resources would
be able to compensate and capture the lost dimension.
Third, in the case of formative constructs there is no requirement of
covariation, something which is essential in the case of reflective con­
structs. Based on the theoretical grounding of the AI capability
construct, the three dimensions of tangible, human, and intangible re­
sources do not need to covary . For instance, having developed the
tangible dimension does not necessarily entail that an organization has
fostered its intangible resources. As an ex-post method to ensure that
there is no covariation (or multicollinearity) between the dimensions of
a formative construct, it is possible to calculate the variance inflation
factor (VIF) . As part of our empirical analysis, VIF values
were calculated to examine if collinearity was an issue for each forma­
tive construct. The outcomes of our analysis are presented further in the
Fourth, the underlying three dimensions of an AI capability have
very different antecedents. For example, tangible resources (i.e., data,
technology, and basic resources), human skills (i.e., technical and
business skills), and intangible (i.e., inter-departmental coordination,
organizational change capacity, and risk proclivity) are developed and
dependent on a different set of predictors. Furthermore, the sub-
dimensions from which they are composed are very distinct from each
other. Therefore, the higher-order AI capability construct satisfies the
four decision rules in accordance to the formative methodological
literature . We used the same approach to determine the
underlying sub-dimensions (e.g., the conceptualization and measure­
ment approach for data, technology, and basic resources toward their
higher-order construct of tangible resources).
4.3. Hierarchical model specification
In specifying our model we used the two-step approach as described
by Benitez et al. . To formally specify the hierarchical model, we
followed a step-by-step approach in order to represent the relationships
between the indicators, sub-dimensions, and the higher-order constructs
 (Fig. 1). We used the latent variables scores in each step of the
estimation after the first. We started by associating the indicators to
their corresponding firs-order latent constructs. Data, technology, and
basic resources were modeled as mode B “formative”, while the
remaining first-order constructs were modeled as mode A “reflective”.
Latent constructs and sub-dimensions.
Third-order
Second-order (sub-dimensions)
First-order (sub-dimensions)
AI Capability
Tangible Resources
Technology
Basic Resources
Human Resources
Technical Skills
Reflective
Business skills
Reflective
Intangible Resources
Inter-departmental Coordination
Reflective
Organizational Change Capacity
Reflective
Risk Proclivity
Reflective
P. Mikalef and M. Gupta
Information & Management 58 103434
The estimation of reflective constructs was performed using the
consistent PLS mode A as it provides a correction for estimates .
During the second step, the latent variable scores of the first-order
constructs were used to form the second-order corresponding variable.
As a result, the latent variable scores of data, technology, and basic re­
sources were used to develop the second-order variable of tangible re­
sources. Similarly, the human skills second-order construct was
developed through the latent variable scores of the corresponding
first-order dimensions of technical skills and business skills. The intan­
gible resource second-order construct was formed from the latent vari­
able scored of the constructs of inter-departmental coordination,
organizational change capacity, and risk proclivity. Finally, the
third-order variable, AI capability, was developed by the latent variable
scored of the second-order constructs after being re-analyzed.
4.4. Data collection
To ensure that the developed survey instrument was valid and
robust, we followed the guidelines suggested by MacKenzie et al. .
In accordance with these guidelines, after specifying the measurement
model, we proceeded to obtain data in order to examine the psycho­
metric properties of the scale and to evaluate its convergent, discrimi­
nant, and nomological validity. As the indicators for the first-order
constructs were either adopted or adapted, we assessed their content
Constructs and measures of AI Capability.
We have access to very large, unstructured,
or fast-moving data for analysis
We integrate data from multiple internal
sources into a data warehouse or mart for
easy access
We integrate external data with internal to
facilitate high-value analysis of our
business environment
We have the capacity to share our data
across business units and organizational
boundaries
We are able to prepare and cleanse AI data
efficiently and assess data for errors
We are able to obtain data at the right level
of granularity to produce meaningful
Technology
We have explored or adopted cloud-based
services for processing data and performing
AI and machine learning
We have the necessary processing power to
support AI applications (e.g., CPUs, GPUs)
We have invested in networking
infrastructure (e.g., enterprise networks)
that supports efficiency and scale of
applications (scalability, high bandwidth,
and low-latency)
We have explored or adopted parallel
computing approaches for AI data
processing
We have invested in advanced cloud
services to allow complex AI abilities on
simple API calls (e.g., Microsoft Cognitive
Services, Google Cloud Vision)
We have invested in scalable data storage
infrastructures
We have explored AI infrastructure to
ensure that data is secured from to end to
end with state-of-the-art technology
Basic Resources
The AI initiatives are adequately funded
The AI project has enough team members to
get the work done
The AI project is given enough time for
completion
Technical Skills
The organization has access to internal and
external talent with the right technical
skills to support AI work
Our data scientists are very capable of using
AI technologies (e.g., machine learning,
natural language processing, deep learning)
Our data scientists have the right skills to
accomplish their jobs successfully
Our data scientists are effective in data
analysis, processing, and security
Our data scientists are provided with the
required training to deal with AI
applications
We hire data scientists that have the AI
skills we are looking for
Our data scientists have suitable work
experience to fulfill their jobs
Business Skills
Our managers are able to understand
business problems and to direct AI
initiatives to solve them
Our managers are able to work with data
scientists, other employees and customers
to determine opportunities that AI might
bring to our organization
Our managers have a good sense of where
to apply AI
The executive manager of our AI function
has strong leadership skills
Our managers are able to anticipate future
business needs of functional managers,
Table 3 (continued)
suppliers and customers and proactively
design AI solutions to support these needs
Our managers are capable of coordinating
AI-related activities in ways that support
the organization, suppliers and customers
We have strong leadership to support AI
initiatives and managers demonstrate
ownership of and commitment to AI
Intangible
Inter-Departmental
Coordination
Please indicate to what extent do departments
(e.g., marketing, R&D, manufacturing,
information technology, and sales) within
your organization engage in the following
activities:
Collaboration
Collective goals
Same vision
Mutual understanding
Shared information
Shared resources
Organizational
Change Capacity
OCC1. We are able to anticipate and plan
for the organizational resistance to change
OCC2. We consider politics of the business
reengineering efforts
OCC3. We recognize the need for managing
OCC4. We are capable of communicating
the reasons for change to the members of
our organization
OCC5. We are able to make the necessary
changes in human resource policies for
process re-engineering
OCC6. Senior management commits to new
Risk Proclivity
RP1. In our organization we have a strong
proclivity for high risk projects (with
chances of very high returns)
RP2. In our organization we take bold and
wide-ranging acts to achieve firm
objectives
RP3. We typically adopt a bold aggressive
posture in order to maximize the
probability of exploiting potential
opportunities
P. Mikalef and M. Gupta
Information & Management 58 103434
validity through a group of experts that were required to provide their
recommendation as to which questions correspond to each construct.
For this step, we used a group of nine experts who had substantial ac­
ademic and practical experience in the domain of AI. Of the nine experts,
six had a background in industry with over 20 years of experience each
in the domains of data science and AI, while the three were senior ac­
ademics whose work was focused on IS in organizations. We provided
definitions of each and asked them to map the items onto the corre­
sponding constructs, which they believed they belonged to. Further­
more, we asked them to provide recommendations of questions that
were not comprehensive or aspects of questions that could be improved.
The feedback provided resulted in some minor modifications and
including some examples particularly in the use of technologies. This
feedback coupled with the high correct hit ratio of items on their cor­
responding constructs was a strong indicator that the content validity for
the instrument was established.
To ensure that the instrument satisfied convergent, discriminant, and
nomological validity, the revised survey instrument was sent out to a
sample of C-level technology managers working in firms in the USA. The
respondents were members of the Artificial Intelligence and Business An­
alytics group on LinkedIn1 . We contacted selected respondents through
email and asked them to participate only if they were in a high-level
technology management position within their organizations. After an
initial invitation and three reminders, with a one-week interval between
each, a total of 143 responses were received. The responses represented
a range of industries (e.g., financial services, manufacturing, high-tech
companies), and the job titles of the respondents were primarily chief
information officers, chief technology officer, director of IT, IT manager,
and chief digital officer. Since we collected data that corresponded to 46
indicators, the first step of our analysis was to conduct an exploratory
factor analysis using principal component analysis and varimax rotation.
Through this analysis, eight factors emerged (eigenvalues > 1). In
addition, all the items loaded to their corresponding factors in accor­
dance to how we had developed them (Tables 4 7 and 9).
To reduce the probability of informant bias, we compared early and
late responses to ensure that responses did not differ significantly. We
developed two groups of responses, those that replied within the first
two weeks, and those that answered during the last two weeks of the
data-collection process. For each of the questions used in this study and
for corresponding constructs they were used to capture, we run Man­
n–Whitney U-tests. We did not identify any significant difference in the
items and constructs, so late-response bias was not an issue within our
sample. Furthermore, from the population of firms that were contacted,
no significant differences were observed between responding and non-
responding firms in terms of their industry, size-class, and age. Since
the collected data were perceptual and came from a single source at one
point in time, we also controlled for the common method bias in
accordance with the suggestions of Chang et al. . During the
invitation email we sent out to the respondents, we assured them that
the data collected would remain anonymous and that it would only be
analyzed for research purposes. In addition, we made clear that there
would be complete confidentiality during the entire process . After
the data collection was finalized, we performed Harman’s one-factor
tests, and entered the study variables into a principal component fac­
tor analysis. The outcomes of this analysis revealed that one construct
did not account for the majority of variance .
4.5. Instrument assessment (validity and reliability)
Since the assessment criteria for formative and reflective constructs
are different, we used several different criteria to examine their validity
and reliability. For the formative measures, we examined the weights of
the items and their significance levels. For the data construct two
indicators were found to be non-significant (D2 and D4), for the tech­
nology construct two indicators were marked as non-significant (T1 and
T5), and for the basic resources construct there was one item that was
non-significant (BR2). Nevertheless, Cenfetelli and Bassellier 
highlight that any formative construct with many indicators is likely to
have several indicators with non-significant weights. They recommend
that non-significant indicators be kept in the model as long as there is a
strong theoretical justification for the inclusion, which contrasts the way
of approaching reflective indicators. Since the dimensions that are
proposed and the corresponding items used to measure them capture
different, critical facets, we believe that it was necessary to retain
non-significant indicators in the model. This was based on the fact that
the expert panel insisted that they are important facets, as well as on
several reports and studies documenting their importance toward an AI
capability. We therefore deemed it as necessary not to remove any items
as each made a distinct contribution to the overall construct it was
assigned to.
Next, we followed the recommendations of MacKenzie et al. and
Schmiedel et al. and evaluated the validity of the items for the
formative constructs by using Edwards’ adequacy coefficient
a). We calculated the R2
a values by summing the squared correlations
between the construct and its dimensions (i.e., indicators) and dividing
by the number of dimensions (i.e., indicators). All R2
a values exceeded
the lower threshold of 0.50 (Table 5) suggesting that the majority of
variance in the items is shared with the formative construct and are thus
valid. We then proceeded to evaluate the higher order constructs with
their respective indicators (dimensions) through the same way. All
weights from lower-order dimensions to higher-order constructs were
positive and significant. We calculated the adequacy coefficient via the
same way, and all R2
a were greater than the 0.50 threshold.
Finally, we assessed whether multicollinearity was an issue between
indicators of the formative constructs. Although the presence of
Sample Characteristics.
Percentage
Technology
Bank & Financials
ICT and Telecommunications
Consulting Services
Consumer Services
Health Care
Consumer Goods
Others (Oil & Gas, Transport, Industrials, Basic Materials,
Total AI experience
Less than one year
More than 4 years
Size-class of the organization
Micro (1−9 employees)
Small (10−49 employees)
Medium (50−249 employees)
Large (250+ employees)
Respondent position
Chief Information/Technology/Digital Officer
IT Director
Head of IT Department
Chief Executive Officer
IT Project Manager
Business Analyst
Other (Lead data scientist, Enterprise architect, Operations
manager, etc.)
1 
P. Mikalef and M. Gupta
Information & Management 58 103434
multicollinearity is desirable among indicators that are modeled as
reflective, it is problematic in the case of formative measurements. The
thresholds for multicollinearity are typically set at below values of 10
 , however, Petter et al. recommend a more restrictive cutoff
value of 3.3. We examined VIF values for first-order, second-order, and
third-order constructs, with all values being below the most conserva­
tive cutoff point of 3.3, which demonstrated that multicollinearity was
not a concern in this study .
To assess the reliability and validity of the reflective constructs we
used several analyses at both the item and construct level. For the first-
order reflective latent constructs, we assessed their reliability, conver­
gent validity, and discriminant validity. Reliability was gauged at both
the construct and item levels. At the construct level, we looked at
composite reliability (CR) and Cronbach’s alpha (CA) values, and made
sure that their values were above the threshold of 0.70 . We
determined indicator reliability by examining if construct-to-item
loadings were above the threshold of 0.70 (Appendix B). To assess
convergent validity, we examined if average variance extracted (AVE)
values were above the lower limit of 0.50, with the lowest observed
value being 0.58, which exceeds this threshold. To determine if
discriminant validity was established we employed two means. First, we
tested whether each indicator’s outer loading was greater that its
cross-loadings with other constructs . Second, we calculated the
heterotrait–monotrait ratio (HTMT), which Henseler et al. argue
is a more robust criterion to assess discriminant validity. The HTMT is
calculated based on the average of the correlations of indicators across
constructs measuring different aspects of the model, relative to the
average of the correlations of indicators within the same construct
 . The values we got from the analysis were all below the threshold
of 0.85, which is an indication of sufficient discriminant validity (Ap­
pendix D). The abovementioned results (Table 6) suggest that first-order
reflective measures are valid to work with and support the appropri­
ateness of all items as good indicators for their respective constructs.
For formative constructs, there are, to the best of our knowledge, no
established tests to assess the discriminant validity of constructs.
Nevertheless, MacKenzie et al. ; Benitez et al. ; Benitez et al.
 have put forward some recommendations for formative con­
structs. Specifically, they highlight that it is important to test for mul­
ticollinearity, and examine weights, loadings, and significance levels.
We tested for multicollinearity by checking whether the VIF at all levels
was below 3.3 (Table 5). The values ranged from 1.300 to 3.109 at the
first-order level and from 1.445 to 2.395 at the second-order level, while
the range at the third-order level was between 1.645 and 2.568, which is
below the stricter threshold. We followed the suggestions of Benitez,
et al. who argue that composite indicator and dimensions should
be retained irrespective of whether their weight is significant or not.
However, loadings are important . The analysis showed that
five indicators were non-significant. Nevertheless, all first-, second-, and
third- order loadings were significant at the 0.001 level. As with
reflective constructs, the indicators of formative constructs should load
highly on their corresponding constructs in comparison to other con­
structs . By examining cross-loadings and correlations (Appendix C
and Table 5) we can confirm that all reflective and formative constructs
satisfy both conditions. Overall, all formative and reflective items
demonstrated good psychometric properties, and hence, we proceed to
examine the nomological validity by examining the relationship be­
tween AI capability and different firm performance measures.
4.6. Nomological validity
4.6.1. Confirmatory composite analysis
The confirmatory composite analysis aims at examining the overall
fit of the measurement (saturated) model . In other words, a
confirmatory composite analysis helps determine whether it makes
sense to create the proposed formative construct and identifies any
model misspecifications . Based on the guidelines of Benitez
et al. , the confirmatory composite analysis checks the adequacy of
the composite model (i.e., higher-order model) by comparing the
empirical correlation matrix with the model-implied correlation matrix.
This is done by examining the standardized root means square residual
(SRMR), unweighted least squares (ULS) discrepancy (dULS), and
Formative construct validation.
Significance
Technology
Technology
Basic Resources
Technical Skills
Business skills
Intangibles
Inter-departmental
Coordination
Organizational
Change Capacity
Risk Proclivity
AI Capability
Intangibles
Assessment of reliability, convergent and discriminant validity of reflective constructs.
Technology
Basic Resources
Technical Skills
Business skills
Inter-departmental Coordination
Organizational Change Capacity
Risk Proclivity
Standard Deviation
Cronbach’s Alpha
Composite Reliability
P. Mikalef and M. Gupta
Information & Management 58 103434
geodesic discrepancy (dG) to evaluate the goodness of saturated model
fit . In sum, the indicators provide empirical support to answer the
question if the latent variables exist, or do the indicators form a
higher-order construct. To obtain these values, we used the latent var­
iable scores obtained in SmartPLS in the software package ADANCO
2.2.0 Professional for Windows ( 
com/) . The SRMR determines the average magnitude of the dis­
crepancies between observed and expected correlations as an absolute
measure of model fit criterion. The value of the SRMR was 0.037, which
is lower than the threshold of 0.080 . In addition, all discrepancy
measures (i.e., dULS and dG) were below the 95 % quantile of their
corresponding reference distribution (HI95) (Table 7). The results
demonstrate that the measurement structure of the composite construct
is correct.
4.6.2. Measurement model
As part of examining the nomological validity of the proposed
construct, we introduced two performance metrics to capture the sug­
gested effect that an AI capability has at an organizational level. We
therefore included organizational creativity (ORC) and organizational
performance (ORP), in addition to the existing constructs of the AI
capability scale as introduced earlier. The size-class of firms and the
industry that they belonged to were also used as controls. Organizational
creativity was captured based on the adopted measures from the study of
Scheibe and Gupta , while organizational performance was oper­
ationalized based on the items proposed by Lee and Choi . Both
constructs are validated in past empirical studies and reflect different
outcomes that have been associated with adoption and use of AI tech­
nologies in the organizational boundary. We repeated the same tests to
establish that the psychometric properties of the scale are not influenced
by the inclusion of outcome variables. We therefore once again exam­
ined reliability and validity at the construct level and examined
inter-correlations between the latent variables for first-order constructs
(Table 8).
4.6.3. Structural model
Having established the psychometric properties of the AI capability
scale, we then proceeded to examine the nomological validity of the AI
capability construct by assessing its relationship with organizational
creative and organizational performance. Consistent with past empirical
studies, we define organizational creativity as the degree to which an
organization is able to generate new and constructive ideas (or products)
in the complex organizational setting . The literature on the value
of AI has argued that by automating repetitive processes, or by replacing
humans in tasks that do not require creativity, complexity, and dealing
with new and unfamiliar situations, human capital can be used in tasks
that make use of their creativity and innovation capacities . Adding
to this, there are many examples where AI technologies can expand the
abilities of human, by amplifying cognitive strengths, embodying
human skills to extend physical abilities, and by interacting with cus­
tomers and employees to free personnel for higher-level tasks .
Similarly, following prior literature we define organizational perfor­
mance as the degree to which organizations achieve their business ob­
jectives . As AI has been argued to deliver effects at several
different levels within organizational activities , it is suggested that
it will have an impact on the attainment of key business objectives. For
instance , highlighted in a recent study that AI can enable firms to
pursue multiple objectives, such as enhancing the features, functions,
and performance of products, help managers make better decisions,
optimize internal business operations, and facilitate external processes
such as marketing and sales. As in other studies that examine IT-business
value, it is advocated that it is important to make inter-firm comparisons
as an appropriate measure for organizational performance . We
therefore deem the relative organizational performance measures as
appropriate to examine the effect of AI capabilities.
In order to examine the two hypothesized relationships, we used a
PLS-SEM analysis and specifically the software SmartPLS 3.0 . The
structural model from the PLS analysis is depicted in Fig. 3, where the
explained variance of endogenous variables (R2) and the standardized
path coefficients (β) are presented. We verify the structural model by
examining the coefficient of determination (R2) values, effect size of
predictor variables (f2), and the effect size of path coefficients. To obtain
the significance of estimates (t-values) we performed a bootstrap
Results of the confirmatory composite analysis.
Discrepancy
Overall saturated model fit evaluation
Conclusion
Inter-correlations of the latent variables for first-order constructs.
Technology
Basic Resources
Technical Skills
Business skills
Inter-departmental Coordination
Organizational Change Capacity
Risk Proclivity
Organizational Creativity
Organizational Performance
Standard Deviation
Cronbach’s Alpha
Composite Reliability
Fig. 3. Results of structural model.
P. Mikalef and M. Gupta
Information & Management 58 103434
analysis using 500 resamples. As shown in Fig. 3, we found a significant
positive effect of AI capability on both organizational creativity
(β = 0.573, t = 15.213, p < 0.001) and organizational performance
(β = 0.561, t = 12.569, p < 0.001). In addition, we found a significant
effect of organizational creativity on organizational performance
(β = 0.294, t = 6.946, p < 0.001). We also controlled for firm size and
industry; however, only firm size had an impact on organizational per­
formance (β = 0.141, t = 2.069, p < 0.05). The model accounted for
49.2 % of variance with regard to organizational creativity
(R2 = 0.492), and 51.3 % of variance for organizational performance
(R2 = 0.513).
In addition to examining the R2, the model is evaluated by assessing
the effect size f2. The effect size f2 enables us to determine the contri­
bution of an exogenous construct to an endogenous latent variable R2.
All direct values are greater than the thresholds of 0.15 and 0.35, so we
can thus conclude that they have moderate to high effect sizes .
Moreover, the model fit indicators were established by using ADANCO.
Examining model fit in such settings allows us to assess whether we have
incorrectly omitted an important effect in the model . The SRMR of
the model was 0.036, dULS = 0.237, dG = 0.051, which is an indication of
a good model fit. The results from the nomological model provide evi­
dence for a strong, positive relationship between an AI capability and
organizational creativity and organizational performance, as well as a
highly significant positive effect of organizational creativity on organi­
zational performance.
4.7. Comparative test for higher-order factors
Having two paths from our proposed AI capability construct to the
organizational creativity (ORC) and organizational performance (ORP)
constructs, our model as depicted in Fig. 3 represents a multiple indi­
cator multiple cause (MIMIC) model and therefore satisfies the 2+
emitted paths rule. As such, the formative model presented above is
highly unlikely to present interpretational confounding . Never­
theless, to empirically exclude the potential of interpretational con­
founding in our model, we followed the recommendations of and
created two models. Model 1-ORC included organizational creativity as
the sole dependent variable, while in Model 2-ORP, organizational
performance was the only dependent variable. The weights of the three
formative measures that comprise the AI capability construct remained
consistent and statistically significant across the two models (see Fig. 4).
These results suggest that interpretational confounding was not an issue
in this study. Several recent studies including those of Wu et al. 
and Gupta and George have used this method to empirically validate
the formative constructs in their study.
In the next step, we examine the external consistence of the AI
capability construct. Based on the guidelines of Kim et al. , we
developed a test model (TModel) which comprised the three formative
indicators of the AI capability construct (tangibles, human skills, and
intangibles) and the two endogenous constructs (organizational crea­
tivity and organizational performance). The two previously described
models—Model 1 and Model 2 were used as the baseline models.
External consistency is achieved when the formative measures of a
construct have consistent correlation with the measures of the depen­
dent variable in proportion to their correlation with the other construct
 . Therefore, we proceeded by examining two things, 1)
comparing the correlations of the three measures of the AI capability
construct and the five measures of organizational creativity across
Model 1 and the TModel, and 2) comparing the correlations of the three
measures of the AI capability construct and the five measures of orga­
nizational performance across Model 2 and the TModel. By looking at
the differences in correlations between the AI capability measures (i.e.,
tangibles, human skills, and intangibles) and the measures of organi­
zational creativity and organizational performance across the baseline
models and the TModel, we found scores that were close to zero as
depicted in Table 9. As such, the issue of weakened external consistency
can be excluded in this study.
5. Discussion
Although the interest around the business potential of AI is contin­
uously growing, reports and empirical studies from early adopters
indicate that many organizations are struggling to realize business value
from their AI investments . These findings are quite striking when
considering the large number of articles that highlight the business value
that can be derived by utilizing AI in core organizational operations . This clash of expectations versus reality is nicely described by
Brynjolfsson et al. who argue that a lot of the attention AI has gained
is from vendors and popular press, which is a cause for false hope. In
many occasions AI is put forward as a panacea that can remedy all
business-related issues, overinflating expectations about what it can
deliver. In addition, many of the reports about the business value of AI
have been documented by technology and business consultants, which
lack the theoretical basis to consolidate findings.
Fig. 4. Test for interpretational confounding.
Test for external consistency (change in correlations).
Formative Indicators
Model 1—TModel
Model 2—TModel
Human Skills
Intangibles
P. Mikalef and M. Gupta
Information & Management 58 103434
5.1. Research implications
In this study, we attempted to understand the use of AI in the orga­
nizational setting by adopting the theoretical lens of the RBT, a well-
established theory in strategic management which has a long tradition
of providing useful insights on IT-business value research . The
objective of adopting this theoretical perspective was to understand the
resources that need to effectively leverage AI technologies and to realize
performance gains. While there have been many practitioner-based
publications to date highlighting the potential value that AI can
deliver, the majority of these do not adopt a theoretical lens that can
explain how organizations need to be set up in order to utilize these
novel technologies toward organizational goals. In addition, the aca­
demic literature that exists to date primarily focuses on the technical
elements pertaining to AI, often disregarding the challenges associated
with deploying such solutions and aligning them with business objec­
tives. This has led to several commentaries and research studies arguing
that it is important to understand the necessary resources that organi­
zations should foster in order to be ready to deploy AI technologies to
support their core activities .
This study makes an important contribution in the business value of
AI literature in three main ways. First, we present a theoretical frame­
work of an AI capability which consists of several technical and
nontechnical resources categorized into three categories. Past research
has shown that it is important to examine the specific capabilities that
are associated with emerging technologies as each creates a unique set of
requirements for organizations . We used the RBT to identify
and categorize the different resources that are relevant in the organi­
zational setting of AI, therefore guaranteeing that a holistic perspective
is adopted. Further, the identification of resources was performed in a
systematic manner that utilized a plethora of approaches to ensure an
exhaustive and complete set of AI-related resources that jointly comprise
a capability. This was done by surveying business reports,
practitioner-based press, research publications, and new releases
regarding AI adoption at the organizational level. By performing this
review, a large list of important factors emerged, which was then
grouped based on the underlying themes and categories as defined in the
RBT. After this initial process, a group of practitioners and academics
which formed our expert group was asked to evaluate these and high­
light if there were any important aspects that were missing. This process
was also aided by providing them the definition of AI and AI capabilities
upon which we based this study. By doing so we then concluded the
main resource categories that jointly comprise an AI capability.
Second, by building on the above-mentioned theoretical framework,
this study develops a construct that can be empirically applied to assess
the AI capabilities of organizations. We argue that theoretically, the AI
capability construct is distinct from other digital capability constructs,
such as IT capabilities, and proceed to define based on the extracted
dimensions the measures required to capture the concept. By following a
rigorous process based on the guidelines of MacKenzie et al. we
develop an instrument that captures the AI-specific resources that or­
ganizations need to foster. Unlike other constructs and corresponding
instruments on different digital capabilities, the questions used to cap­
ture the main dimensions are based on the specific AI technologies,
skills, and intangible resources. As such, we opted not to focus solely on
adapting previous measurements but also to include new ones based on
the existing body of research regarding the use of AI and the important
elements pertaining to its utilization in organizations. Through our
empirical study we demonstrated the reliability and validity of the AI
capability construct overall, as well as the underlying dimensions and
items. By doing so, we address the recent calls in the IS community
concerning the need to define and conceptualize an organizational ca­
pacity to leverage AI toward business objectives .
Third, we demonstrated impact that developing an AI capability has
on key organizational performance indicators. Specifically, we assessed
the extent to which it impacts organizational creativity and
organizational performance. These outcome variables have been sug­
gested to be influenced by the use and deployment of AI in the organi­
zational setting in several practice-based publications , as well
as in research commentaries and editorials . Nevertheless, there
is to the best of our knowledge, no empirical large-scale study linking a
theoretically grounded conceptualization of AI with key business in­
dicators. We empirically demonstrate that by developing an AI capa­
bility, organizations can realize gains in both creativity and
performance. This finding underscores the importance of approaching
AI through a holistic manner when deploying in within the organization,
as simply focusing on the required data and the technology is insuffi­
cient to deliver any substantial business results. The findings also indi­
cate that AI can be of significant value for organizations in achieving and
sustain competitive performance gains, as it has an impact on key per­
formance outcomes. From a theoretical standpoint, the outcomes also
reveal the strategic potential of AI, as we find support for the idea that AI
capabilities can contribute to the creative processes, and perhaps even to
the knowledge base and innovation outcomes of firms. These association
demonstrate that AI can allow organizations to pursue ambidextrous
strategies depending on the type of solutions that are deployed. In
addition, we find that organizational creativity, which is directly asso­
ciated with a firms AI capability, leads to organizational performance
gains. These findings combines provide support for the domain of
IT-enabled organizational capabilities, whereby strategically leveraging
IT organizations can enhance and even develop new organizational
capabilities.
Summarizing, following the established theoretical framework pro­
vided by the RBT, this study extends the existing body of research in the
IS community by adopting it within the context of AI to explain what
resources organizations need to develop to realize business value from
their AI investments. We follow the reasoning and argumentation of
Wade and Hulland who suggest that the RBT can provide benefits to
the IS community as, 1) the RBT provides the foundation for specifying
firm-level
resources,
distinctions
cross-functional, as well as technical and nontechnical firm-level re­
sources, and 3) it enables researchers to systematically test the rela­
tionship between the aggregate of resources into capabilities, with key
performance outcomes. By building on these strengths of the RBT we
have been able to further the explanatory power and generalizability of
the RBT to the emerging field of AI.
5.2. Practical implications
By including in our conceptualization of an AI capability aspects that
have to do with human skills and other intangible resources, we high­
light the importance of expanding the view to incorporate more “soft”
factors when designing AI deployment strategies. While to date data, the
infrastructure and the techniques used to bring to life AI solutions have
mostly dominated practice-based literature, in this study we underscore
the significance of more elusive but equally important aspects related to
AI success. In fact, we show that making such technically oriented in­
vestments alone will most likely not result in substantial performance
gains. Rather, managers must develop the structures and culture that
enable value generation from their AI investments. For example, inter-
departmental coordination if found to be a necessary condition to
enable flow of information and data, as well as a means to develop AI
solutions that correspond to the business requirements. Unlike many IT
solutions, AI applications require lengthy procedures for training, cali­
brating, and refining, taking into account new sources of data and
adapting the models upon which they are developed. Doing so requires
that there is a culture of coordination, mutual understanding, and
cooperation between the different departments within an organization.
In other words, developing an AI orientation within the firm is a
necessary precondition for successful deployments.
On a similar note, we highlight the role that skills have in facilitating
the mobilization and orchestration of AI within organizations. Our
P. Mikalef and M. Gupta
Information & Management 58 103434
results indicate that practitioners should focus not only on purely
technical skills associated with AI, but also on the managerial compe­
tencies to direct AI initiatives toward priority areas that generate busi­
ness value. These findings stress the importance of training technical and
business staff with regards to emerging AI techniques and their appli­
cations. As AI requires a substantially different skillset compared to
other IT solutions, it is critical that organizations are prepared to
accommodate their existing employees with the necessary training and
educational material to become acquainted with AI tools and tech­
niques. Online resources can be a viable solution as they provide up-to-
date knowledge in an environment that facilitates asynchronous
learning. In addition, it also serves to highlight what skills would be
required in the case of newly hired employees.
Through the intangible dimension of risk proclivity, we also explain
the importance of adopting an organizational culture that embraces risk
taking and making bold and radical actions. This is a necessary mind-set
when it comes to AI projects, as in many successful business cases using
AI, going forward with uncertain initiatives that can possibly yield high
returns has proven to be instrumental . A lot of organizations are
risk averse when it comes to implementing new IT solutions and
deploying them in operations. However, findings from our study as well
as other reports show that it is important to embrace a logic of “high risk
high gains” when it comes to AI.
Adding to the above, an important component of becoming an AI-
ready organization is being able to self-assess the organizations’
strengths and weaknesses. The survey instrument we developed as part
of this study can be used by managers in organizations to identify what
resources need to be enhanced and which ones are developed to a
satisfactory level. For example, the instrument can be applied at local
business units, exposing areas such as technical skills, or basic resources
such as financing that require further development locally. By distrib­
uting it to sub-units, it is also possible to identify which business units
are not well connected or have been under-emphasized. This could show
imbalances within the organization and units that are not on par with
the others or have major weaknesses that could potentially inhibit
overall attainment of goals. Given that AI adoption in organizations is
still an inaugurating state, such benchmarking attempts could help
direct financing and resource allocation more efficiently and help
generate business value with fewer uncured costs.
Finally, while the AI capability construct may highlight areas within
the organization that practitioners should develop in order to maximize
the likelihood of attaining performance outcomes, it must be noted that
the value-generating mechanisms are likely to be produced in very
dissimilar ways. This has to do both with the types of AI applications that
can be developed, as well as on the context in which they are applied.
For instance, certain forms of AI can lead to substantial performance
gains by automating manual and repetitive tasks, whereas others could
be applied to enhance creativity of skilled labor. Since AI applications
encompass a broad type of technologies and techniques, it is likely that
value will depend on the technologies used, but also on how they are
5.3. Limitations and future research
As with any research, our study is not without limitations. First,
while we outline the main types of resources firms should consider when
designing and deploying their AI initiatives, it cannot be considered as a
universal model, completely applicable to all organizations. As we are in
an initial stage of understanding AI in the business context, providing an
exhaustive list of resources driving an AI capability is not easy. It is
probable that some organizations may require additional resources to be
able to leverage their AI investments based on several contingent as­
pects, such as industry, size-class, type of AI application, or country of
operation. Furthermore, the AI capability construct is by no means
exhaustive, so there may be additional important dimensions that we
did not manage to capture that future research could examine.
Second, while we identify and describe the main pillars of an AI
capability through the tangible, human skills, and intangible di­
mensions, we do not delve into a process-based perspective of how AI
initiatives unfold and what dynamics shape final outcomes. It is highly
probable that organizations follow different trajectories when it comes
to how they plan and deploy AI solutions, and in doing so face a different
set of challenges and hindrances. By adopting an interpretivist
approach, it would be possible to uncover the forces that influence
choices around AI deployments, the tensions that unfold between
involved stakeholders, as well as what the influences of frameworks and
governance choices are in impacting the attainment of set goals .
Third, our study used respondents that worked in companies based in
the United States. It is likely that organizations from different regions, or
the ones that are laggards in adopting AI technologies may do so in a
different manner. For instance, organizations that have less slack
financial resources to invest in developing AI solutions may opt to
selecting applications from vendors that just require minimum config­
urations to be operational. In this case, outsourcing solutions would
mean a lower need for mobilizing and developing internal resources.
Surveying companies from different geographical areas and at different
stages of AI deployments could uncover new, equally effective patterns
of utilizing AI for organizational purposes.
Finally, while we relied on senior technology professionals within
firms, the choice of a single respondent could potentially include some
bias in results. A way to remedy this would be to opt for survey designs
that collect data from multiple respondents within firms. Another way in
which business value can be assessed would be to use objective, rather
than subjective performance indicators, time-lagged based on when AI
solutions were first deployed.
6. Conclusion
This study has been motivated by the surge of interest in the AI
phenomenon by practitioners and academics, particularly over the past
five years. Although there has been considerable contribution in litera­
ture from practitioners , within the academic community only
within the last couple of years has the topic gained some traction. As a
result, there has been much discussion about the business potential of
AI, without clearly defining what AI means in the IS context, and with an
absence of a concrete definition of an organization’s AI capability. In
this study, we took insight from the RBT, prior IT studies, and recently
published work on using AI in the organizational setting. Through this
approach and grounded on input from a group of experts and a
large-scale survey-based study, we developed and validated a concep­
tualization of an AI capability. We argue that eight types of comple­
mentary resources must be developed, and which jointly contribute to
the emergence of an overall AI capability. Specifically, the tangible re­
sources comprise of data, technology, and basic resources, human skills
consist of technical and business skills, while intangible resources that
are critical include the presence of inter-department coordination, an
organizational change capacity, and risk proclivity. Finally, this study
developed a survey instrument to measure an organization’s AI capa­
bility, which was empirically validated, demonstrating that by fostering
an AI capability firms can realize gains in terms of organizational
creativity and performance.
CRediT authorship contribution statement
Patrick Mikalef: Conceptualization, Methodology, Software,
Writing - original draft, Writing - review & editing. Manjul Gupta:
Conceptualization, Methodology, Investigation, Methodology, Project
administration, Writing - original draft, Writing - review & editing.
P. Mikalef and M. Gupta
Information & Management 58 103434
Appendix A. AI Capability Instrument
AI Capability
D1. We have access to very large, unstructured, or fast-moving data for analysis
D2. We integrate data from multiple internal sources into a data warehouse or mart for easy access
D3. We integrate external data with internal to facilitate high-value analysis of our business environment
D4. We have the capacity to share our data across business units and organizational boundaries
D5. We are able to prepare and cleanse AI data efficiently and assess data for errors
D6. We are able to obtain data at the right level of granularity to produce meaningful insights
- Technology
T1. We have explored or adopted cloud-based services for processing data and performing AI and machine learning
T2. We have the necessary processing power to support AI applications (e.g. CPUs, GPUs)
T3. We have invested in networking infrastructure (e.g. enterprise networks) that supports efficiency and scale of applications (scalability, high
bandwidth, and low-latency)
T4. We have explored or adopted parallel computing approaches for AI data processing
T5. We have invested in advanced cloud services to allow complex AI abilities on simple API calls (e.g. Microsoft Cognitive Services, Google Cloud
T6. We have invested in scalable data storage infrastructures
T7. We have explored AI infrastructure to ensure that data is secured from to end to end with state-of-the-art technology
- Basic Resources
BR1. The AI initiatives are adequately funded
BR2. The AI project has enough team members to get the work done
BR3. The AI project is given enough time for completion
Human Skills
- Technical Skills
TS1. The organization has access to internal and external talent with the right technical skills to support AI work
TS2. Our data scientists are very capable of using AI technologies (e.g. machine learning, natural language processing, deep learning)
TS3. Our data scientists have the right skills to accomplish their jobs successfully
TS4. Our data scientists are effective in data analysis, processing, and security
TS5. Our data scientists are provided with the required training to deal with AI applications
TS6. We hire data scientists that have the AI skills we are looking for
TS7. Our data scientists have suitable work experience to fulfill their jobs
- Business skills
BS1. Our managers are able to understand business problems and to direct AI initiatives to solve them
BS2. Our managers are able to work with data scientists, other employees and customers to determine opportunities that AI might bring to our
organization
BS3. Our managers have a good sense of where to apply AI
BS4. The executive manager of our AI function has strong leadership skills
BS5. Our managers are able to anticipate future business needs of functional managers, suppliers and customers and proactively design AI solutions
to support these needs
BS6. Our managers are capable of coordinating AI-related activities in ways that support the organization, suppliers and customers
BS7. We have strong leadership to support AI initiatives and managers demonstrate ownership of and commitment to AI projects
Intangible
- Inter-Departmental
Coordination
Please indicate to what extent do departments (e.g., marketing, R&D, manufacturing, information technology, and sales) within your organization engage in
the following activities:
IC1. Collaboration
IC2. Collective goals
IC3. Teamwork
IC4. Same vision
IC5. Mutual understanding
IC6. Shared information
IC7. Shared resources
- Organizational Change
OCC1. We are able to anticipate and plan for the organizational resistance to change
OCC2. We consider politics of the business reengineering efforts
OCC3. We recognize the need for managing change
OCC4. We are capable of communicating the reasons for change to the members of our organization
OCC5. We are able to make the necessary changes in human resource policies for process re-engineering
OCC6. Senior management commits to new values
- Risk Proclivity
RP1. In our organization we have a strong proclivity for high risk projects (with chances of very high returns)
RP2. In our organization we take bold and wide-ranging acts to achieve firm objectives
RP3. We typically adopt a bold aggressive posture in order to maximize the probability of exploiting potential opportunities
Appendix B. Performance Measures
Organizational Creativity
ORC1. Our organization has produced many novel and useful ideas (services/products).
ORC2. Our organization fosters an environment that is conductive to our own ability to produce novel and useful ideas (services/products).
ORC3. Our organization spends much time for producing novel and useful ideas (services/products).
ORC4. Our organization considers producing novel and useful ideas (services/products) as important activities.
ORC5. Our organization actively produces novel and useful ideas (services/products).
Organizational Performance
ORP1. Compared to our key competitors our organization is more successful.
ORP2. Compared to our key competitors our organization has a greater market share.
ORP3. Compared to our key competitors our organization is growing faster.
ORP4. Compared to our key competitors our organization is more profitable.
ORP5. Compared to our key competitors our organization is more innovative
P. Mikalef and M. Gupta
Information & Management 58 103434
Appendix C. Cross-Loadings
D – Data, T – Technology, BR – Basic Resources, TS – Technical Skills, BS – Business skills, IC – Inter-Departmental Coordination, OCC – Orga­
nizational Change Capacity, RP – Risk Proclivity
Appendix D. Heterotrait-Monotrait Ratio (HMTM)
(4) Technical Skills
(5) Business skills
(6) Inter-Departmental Coordination
(7) Organizational Change Capacity
(8) Risk Proclivity