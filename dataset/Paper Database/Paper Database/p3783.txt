Fireﬂy Algorithm, Stochastic Test Functions and Design
Optimisation
Xin-She Yang
Department of Engineering, University of Cambridge,
Trumpington Street, Cambridge CB2 1PZ, UK
Email: 
November 26, 2024
Modern optimisation algorithms are often metaheuristic, and they are very promising in solving NP-hard optimization problems. In this paper, we show how to use the recently developed
Fireﬂy Algorithm to solve nonlinear design problems. For the standard pressure vessel design
optimisation, the optimal solution found by FA is far better than the best solution obtained
previously in literature. In addition, we also propose a few new test functions with either singularity or stochastic components but with known global optimality, and thus they can be used
to validate new optimisation algorithms. Possible topics for further research are also discussed.
To cite this paper as follows: Yang, X. S., ‘Fireﬂy Algorithm, Stochastic Test Functions
and Design Optimisation’, Int. J. Bio-Inspired Computation, Vol. 2, No. 2, pp.78–84.
Introduction
Most optimization problems in engineering are nonlinear with many constraints. Consequently, to
ﬁnd optimal solutions to such nonlinear problems requires eﬃcient optimisation algorithms . In general, optimisation algorithms can be classiﬁed into two
main categories: deterministic and stochastic. Deterministic algorithms such as hill-climbing will
produce the same set of solutions if the iterations start with the same initial guess. On the other
hand, stochastic algorithms often produce diﬀerent solutions even with the same initial starting
point. However, the ﬁnal results, though slightly diﬀerent, will usually converge to the same optimal
solutions within a given accuracy.
Deterministic algorithms are almost all local search algorithms, and they are quite eﬃcient in
ﬁnding local optima. However, there is a risk for the algorithms to be trapped at local optima, while
the global optima are out of reach. A common practice is to introduce some stochastic component
to an algorithm so that it becomes possible to jump out of such locality. In this case, algorithms
become stochastic.
Stochastic algorithms often have a deterministic component and a random component.
stochastic component can take many forms such as simple randomization by randomly sampling the
search space or by random walks. Most stochastic algorithms can be considered as metaheuristic,
and good examples are genetic algorithms (GA) and particle swarm
optimisation (PSO) . Many modern metaheuristic
algorithms were developed based on the swarm intelligence in nature . New modern metaheuristic algorithms are being developed and begin to
show their power and eﬃciency. For example, the Fireﬂy Algorithm developed by the author shows
its superiority over some traditional algorithms .
The paper is organized as follows: we will ﬁrst brieﬂy outline the main idea of the Fireﬂy
Algorithm in Section 2, and we then describe a few new test functions with singularity and/or
randomness in Section 3. In Section 4, we will use FA to ﬁnd the optimal solution of a pressure
vessel design problem. Finally, we will discuss the topics for further studies.
Fireﬂy Algorithm and its Implementation
Fireﬂy Algorithm
The Fireﬂy Algorithm was developed by the author , and it was based on
the idealized behaviour of the ﬂashing characteristics of ﬁreﬂies. For simplicity, we can idealize these
ﬂashing characteristics as the following three rules
• all ﬁreﬂies are unisex so that one ﬁreﬂy is attracted to other ﬁreﬂies regardless of their sex;
• Attractiveness is proportional to their brightness, thus for any two ﬂashing ﬁreﬂies, the less
brighter one will move towards the brighter one. The attractiveness is proportional to the
brightness and they both decrease as their distance increases. If no one is brighter than a
particular ﬁreﬂy, it moves randomly;
• The brightness or light intensity of a ﬁreﬂy is aﬀected or determined by the landscape of the
objective function to be optimised.
For a maximization problem, the brightness can simply be proportional to the objective function.
Other forms of brightness can be deﬁned in a similar way to the ﬁtness function in genetic algorithms
or the bacterial foraging algorithm (BFA) .
In the FA, there are two important issues: the variation of light intensity and formulation of the
attractiveness. For simplicity, we can always assume that the attractiveness of a ﬁreﬂy is determined
by its brightness or light intensity which in turn is associated with the encoded objective function.
In the simplest case for maximum optimization problems, the brightness I of a ﬁreﬂy at a particular
location x can be chosen as I(x) ∝f(x). However, the attractiveness β is relative, it should be seen
in the eyes of the beholder or judged by the other ﬁreﬂies. Thus, it should vary with the distance
rij between ﬁreﬂy i and ﬁreﬂy j. As light intensity decreases with the distance from its source, and
light is also absorbed in the media, so we should allow the attractiveness to vary with the degree of
absorption.
In the simplest form, the light intensity I(r) varies with the distance r monotonically and exponentially. That is
I = I0e−γr,
where I0 is the original light intensity and γ is the light absorption coeﬃcient. As a ﬁreﬂy’s attractiveness is proportional to the light intensity seen by adjacent ﬁreﬂies, we can now deﬁne the
attractiveness β of a ﬁreﬂy by
β = β0e−γr2,
where β0 is the attractiveness at r = 0. It is worth pointing out that the exponent γr can be
replaced by other functions such as γrm when m > 0. Schematically, the Fireﬂy Algorithm (FA)
can be summarised as the pseudo code.
Fireﬂy Algorithm
Objective function f(x),
x = (x1, ..., xd)T
Initialize a population of ﬁreﬂies xi (i = 1, 2, ..., n)
Deﬁne light absorption coeﬃcient γ
while (t <MaxGeneration)
for i = 1 : n all n ﬁreﬂies
for j = 1 : i all n ﬁreﬂies
Light intensity Ii at xi is determined by f(xi)
if (Ij > Ii)
Move ﬁreﬂy i towards j in all d dimensions
Attractiveness varies with distance r via exp[−γr]
Evaluate new solutions and update light intensity
Rank the ﬁreﬂies and ﬁnd the current best
Postprocess results and visualization
The distance between any two ﬁreﬂies i and j at xi and xj can be the Cartesian distance
rij = ||xi −xj||2 or the ℓ2-norm. For other applications such as scheduling, the distance can be time
delay or any suitable forms, not necessarily the Cartesian distance.
The movement of a ﬁreﬂy i is attracted to another more attractive (brighter) ﬁreﬂy j is determined by
xi = xi + β0e−γr2
ij(xj −xi) + αǫi,
where the second term is due to the attraction, while the third term is randomization with the vector
of random variables ǫi being drawn from a Gaussian distribution.
For most cases in our implementation, we can take β0 = 1, α ∈ , and γ = 1. In addition,
if the scales vary signiﬁcantly in diﬀerent dimensions such as −105 to 105 in one dimension while,
say, −10−3 to 103 along others, it is a good idea to replace α by αSk where the scaling parameters
Sk(k = 1, ..., d) in the d dimensions should be determined by the actual scales of the problem of
In essence, the parameter γ characterizes the variation of the attractiveness, and its value is
crucially important in determining the speed of the convergence and how the FA algorithm behaves.
In theory, γ ∈[0, ∞), but in practice, γ = O(1) is determined by the characteristic/mean length Sk
of the system to be optimized. In one extreme when γ →0, the attractiveness is constant β = β0.
This is equivalent to saying that the light intensity does not decrease in an idealized sky. Thus, a
ﬂashing ﬁreﬂy can be seen anywhere in the domain. Thus, a single (usually global) optimum can
easily be reached. This corresponds to a special case of particle swarm optimization (PSO). In fact,
if the inner loop for j is removed and Ij is replaced by the current global best g∗, FA essentially
becomes the standard PSO, and, subsequently, the eﬃciency of this special case is the same as that
of PSO. On the other hand, if γ →∞, we have β(r) →δ(r), which is a Dirac δ-function. This means
that the attractiveness is almost zero in the sight of other ﬁreﬂies, or the ﬁreﬂies are short-sighted.
This is equivalent to the case where the ﬁreﬂies ﬂy in a very foggy region randomly. No other
ﬁreﬂies can be seen, and each ﬁreﬂy roams in a completely random way. Therefore, this corresponds
to the completely random search method. So γ partly controls how the algorithm behaves. It is also
possible to adjust γ so that multiple optima can be found at the same during iterations.
Numerical Examples
From the pseudo code, it is relatively straightforward to implement the Fireﬂy Algorithm using a
popular programming language such as Matlab. We have tested it against more than a dozen test
Figure 1: Four global maxima at (±1/2, ±1/2).
functions such as the Ackley function
f(x) = −20 exp
cos(2πxi)] + 20 + e,
which has a unique global minimum f∗= 0 at (0, 0, ..., 0). From a simple parameter studies, we
concluded that, in our simulations, we can use the following values of parameters α = 0.2, γ = 1,
and β0 = 1. As an example, we now use the FA to ﬁnd the global maxima of the following function
with the domain −10 ≤xi ≤10 for all (i = 1, 2, ..., d) where d is the number of dimensions. This
function has multiple global optima. In the case of d = 2, we have 4 equal maxima f∗= 1/√e ≈
0.6065 at (1/2, 1/2), (1/2, −1/2), (−1/2, 1/2) and (−1/2, −1/2) and a unique global minimum at
The four peaks are shown in Fig. 1, and these global maxima can be found using the implemented
Fireﬂy Algorithms after about 500 function evaluations. This corresponds to 25 ﬁreﬂies evolving
for 20 generations or iterations. The initial locations of 25 ﬁreﬂies are shown Fig.
2 and their
ﬁnal locations after 20 iterations are shown in Fig. 3.
We can see that the Fireﬂy Algorithm is
very eﬃcient. Recently studies also conﬁrmed its promising power in solving nonlinear constrained
optimization tasks .
New Test Functions
The literature about test functions is vast, often with diﬀerent collections of test functions for
validating new optimisation algorithms. Test functions such as Rosenbrock’s banana function and
Ackley’s function mentioned earlier are well-known in the optimisation literature. Almost all these
Figure 2: Initial locations of 25 ﬁreﬂies.
Figure 3: Final locations after 20 iterations.
test functions are deterministic and smooth. In the rest of this paper, we ﬁrst propose a few new
test functions which have some singularity and/or stochastic components. Some of the formulated
functions have stochastic components but their global optima are deterministic. Then, we will use
the Fireﬂy Algorithm to ﬁnd the optimal solutions of some of these new functions.
The ﬁrst test function we have designed is a multimodal nonlinear function
i=1(xi/β)2m −2e−Pd
i=1(xi−π)2i
which looks like a standing-wave function with a defect (see Fig. 4). It has many local minima
and the unique global minimum f∗= −1 at x∗= (π, π, ..., π) for β = 15 within the domain
−20 ≤xi ≤20 for i = 1, 2, ..., d. By using the Fireﬂy Algorithm with 20 ﬁreﬂies, it is easy to ﬁnd
the global minimum in just about 15 iterations. The results are shown in Fig. 5 and Fig. 6.
As most test functions are smooth, the next function we have formulated is also multimodal but
it has a singularity
which has a unique global minimum f∗= 0 at x∗= (0, 0, ..., 0) in the domain −2π ≤xi ≤2π where
i = 1, 2, ..., d. At a ﬁrst look, this function has some similarity with function (5) discussed earlier.
However, this function is not smooth, and its derivatives are not well deﬁned at the optimum
(0, 0, ..., 0).
The landscape of this forest-like function is shown in Fig.
7 and its 2D contour is
displayed in Fig. 8.
Almost all existing test functions are deterministic.
Now let us design a test function with
stochastic components
f(x, y) = −5e−β[(x−π)2+(y−π)2]
ǫije−α[(x−i)2+(y−j)2],
where α, β > 0 are scaling parameters, which can often be taken as α = β = 1. Here the random
variables ǫij (i, j = 1, ..., K) obey a uniform distribution ǫij ∼Unif . The domain is 0 ≤x, y ≤K
and K = 10. This function has K2 local valleys at grid locations and the ﬁxed global minimum at
x∗= (π, π). It is worth pointing that the minimum fmin is random, rather than a ﬁxed value; it
may vary from −(K2 + 5) to −5, depending α and β as well as the random numbers drawn.
For stochastic test functions, most deterministic algorithms such as hill-climbing would simply
fail due to the fact that the landscape is constantly changing. However, metaheuristic algorithms
could still be robust in dealing with such functions. The landscape of a realization of this stochastic
function is shown in Fig. 9.
Using the Fireﬂy Algorithm, we can ﬁnd the global minimum in about 15 iterations for n = 20
ﬁreﬂies. That is, the total number of function evaluations is just 300. This is indeed very eﬃcient
and robust. The initial locations of the ﬁreﬂies are shown in Fig. 10 and the ﬁnal results are shown
Furthermore, we can also design a relative generic stochastic function which is both stochastic
and non-smooth
−5 ≤xi ≤5,
where ǫi (i = 1, 2, ..., d) are random variables which are uniformly distributed in . That is,
ǫi ∼Unif . This function has the unique minimum f∗= 0 at x∗= (0, 0, ..., 0) which is also
We found that for most problems n = 15 to 50 would be suﬃcient. For tougher problems, larger
n can be used, though excessively large n should not be used unless there is no better alternative,
as it is more computationally extensive for large n.
Figure 4: The standing wave function for two independent variables with the global minimum
f∗= −1 at (π, π).
Figure 5: The initial locations of 20 ﬁreﬂies.
Figure 6: Final locations after 15 iterations.
Figure 7: The landscape of function (7).
Figure 8: Contour of function (7).
Figure 9: The 2D Stochastic function for K = 10 with a unique global minimum at (π, π), though
the value of this global minimum is somewhat stochastic.
Figure 10: The initial locations of 20 ﬁreﬂies.
Figure 11: The ﬁnal locations of 20 ﬁreﬂies after 15 iterations, converging into (π, π).
Engineering Applications
Now we can apply the Fireﬂy Algorithm to carry out various design optimisation tasks. In principle,
any optimization problems that can be solved by genetic algorithms and particle swarm optimisation
can also be solved by the Fireﬂy Algorithm. For simplicity to demonstrate its eﬀectiveness in realworld optimisation, we use the FA to ﬁnd the optimal solution of the standard but quite diﬃcult
pressure design optimisation problem.
Pressure vessels are literally everywhere such as champagne bottles and gas tanks. For a given
volume and working pressure, the basic aim of designing a cylindrical vessel is to minimize the total
cost. Typically, the design variables are the thickness d1 of the head, the thickness d2 of the body,
the inner radius r, and the length L of the cylindrical section .
This is a well-known test problem for optimization and it can be written as
minimize f(x) = 0.6224d1rL + 1.7781d2r2
1L + 19.84d2
subject to the following constraints
g1(x) = −d1 + 0.0193r ≤0
g2(x) = −d2 + 0.00954r ≤0
g3(x) = −πr2L −4π
3 r3 + 1296000 ≤0
g4(x) = L −240 ≤0.
The simple bounds are
0.0625 ≤d1, d2 ≤99 × 0.0625,
Recently, Cagnina et al used an eﬃcient particle swarm optimiser to solve this problem
and they found the best solution
f∗≈6059.714,
x∗≈(0.8125, 0.4375, 42.0984, 176.6366).
This means the lowest price is about $6059.71.
Using the Fireﬂy Algorithm, we have found an even better solution with 40 ﬁreﬂies after 20
iterations, and we have obtained
x∗≈(0.7782, 0.3846, 40.3196, 200.0000)T,
fmin ≈5885.33,
which is signiﬁcantly lower or cheaper than the solution f∗≈6059.714 obtained by Cagnina et al
This clearly shows how eﬃcient and eﬀective the Fireﬂy Algorithm could be. Obviously, further
applications are highly needed to see how it may behave for solving various tough engineering
optimistion problems.
Conclusions
We have successfully used the Fireﬂy Algorithm to carry out nonlinear design optimisation. We ﬁrst
validated the algorithms using some standard test functions. After designing some new test functions
with singularity and stochastic components, we then used the FA to solve these unconstrained
stochastic functions. We also applied it to ﬁnd a better global solution to the pressure vessel design
optimisation. The optimisation results imply that the Fireﬂy Algorithm is potentially more powerful
than other existing algorithms such as particle swarm optimisation.
The convergence analysis of metaheuristic algorithms still requires some theoretical framework.
At the moment, it still lacks of a general framework for such analysis. Fortunately, various studies
started to propose a feasible measure for comparing algorithm performance. For example, Shilane et
al suggested a framework for evaluating statistical performance of evolutionary algorithms.
Obviously, more comparison studies are highly needed so as to identify the strength and weakness
of current metaheuristic algorithms. Ultimately, even better optimisation algorithms may emerge.