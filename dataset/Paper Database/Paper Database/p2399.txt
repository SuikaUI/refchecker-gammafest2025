Anomaly Detection With Multiple-Hypotheses Predictions
Duc Tam Nguyen 1 2 Zhongyu Lou 2 Michael Klar 2 Thomas Brox 1
In one-class-learning tasks, only the normal case
(foreground) can be modeled with data, whereas
the variation of all possible anomalies is too erratic to be described by samples. Thus, due to the
lack of representative data, the wide-spread discriminative approaches cannot cover such learning tasks, and rather generative models, which
attempt to learn the input density of the foreground, are used. However, generative models
suffer from a large input dimensionality (as in
images) and are typically inefﬁcient learners. We
propose to learn the data distribution of the foreground more efﬁciently with a multi-hypotheses
autoencoder. Moreover, the model is criticized
by a discriminator, which prevents artiﬁcial data
modes not supported by data, and enforces diversity across hypotheses. Our multiple-hypothesesbased anomaly detection framework allows the reliable identiﬁcation of out-of-distribution samples.
For anomaly detection on CIFAR-10, it yields up
to 3.9% points improvement over previously reported results. On a real anomaly detection task,
the approach reduces the error of the baseline
models from 6.8% to 1.5%.
1. Introduction
Anomaly detection classiﬁes a sample as normal or abnormal. In many applications, however, it must be treated as a
one-class-learning problem, since the abnormal class cannot
be deﬁned sufﬁciently by samples. Samples of the abnormal
class can be extremely rare, or they do not cover the full
space of possible anomalies. For instance, in an autonomous
driving system, we may have a test case with a bear or a
kangaroo on the road. For defect detection in manufacturing,
University
2Corporate Research,
Robert Bosch
GmbH, Renningen, Germany.
Correspondence to:
< >,
< >,
< >,
< >.
new, unknown production anomalies due to critical changes
in the production environment can appear. In medical data
analysis, there can be unknown deviations from the healthy
state. In all these cases, the well-studied discriminative
models, where decision boundaries of classiﬁers are learned
from training samples of all classes, cannot be applied. The
decision boundary learning of discriminative models will
be dominated by the normal class, which will negatively
inﬂuence the classiﬁcation performance.
Anomaly detection as one-class learning is typically approached by generative, reconstruction-based methods
 . They approximate the input distribution of the normal cases by parametric models, which allow
them to reconstruct input samples from this distribution.
At test time, the data negative log-likelihood serves as an
anomaly-score. In the case of high-dimensional inputs, such
as images, learning a representative distribution model of
the normal class is hard and requires many samples.
Autoencoder-based approaches, such as the variational autoencoder ,
mitigate the problem by learning a mapping to a lowerdimensional representation, where the actual distribution
is modeled. In principle, the nonlinear mappings in the
encoder and decoder allow the model to cover multi-modal
distributions in the input space. However, in practice, autoencoders tend to yield blurry reconstructions, since they
regress mostly the conditional mean rather than the actual
multi-modal distribution (see Fig. 1 for an example on a
metal anomaly dataset). Due to multiple modes in the actual
distribution, the approximation with the mean predicts high
probabilities in areas not supported by samples. The blurry
reconstructions in Fig. 1 should have a low probability and
be classiﬁed as anomalies, but instead they have the highest
likelihood under the learned autoencoder. This is fatal for
anomaly detection.
Alternatively, mixture density networks learn
a conditional Gaussian mixture distribution. They directly
estimate local densities that are coupled to a global density estimate via mixing coefﬁcients. Anomaly scores for
new points can be estimated using the data likelihood (see
Appendix). However, global, multi-modal distribution estimation is a hard learning problem with many problems
in practice. In particular, mixture density networks tend to
 
Anomaly Detection With Multiple-Hypotheses Predictions
(a) Test images
(b) Autonencoder reconstructions
(c) ConAD reconstructions
Figure 1. Detection of anomalies on a Metal Anomaly dataset. (a) Test images showing anomalies (black spots). (b) An Autoencoder-based
approach produces blurry reconstructions to express model uncertainty. The blurriness falsiﬁes reconstruction errors (and hence anomaly
scores)(c) Our model: Consistency-based anomaly detection (ConAD) gives the network more expressive power with a multi-headed
decoder (also known as multiple-hypotheses networks). The resulting anomaly scores are hence much clearer in our framework ConAD.
(a) Cond. space
(b) Autoencoder
(e) Our model
Figure 2. Illustration of the different anomaly detection strategies. (a) In this example, two dimensions with details that are hard to capture
in the conditional space are shown. The red dot is a new point. Dark blue indicates high likelihood, black indicates the neighborhood
considered. The autoencoder (b) cannot deal with the multi-modal distribution. The mixture density network (c) in principle can do so, but
recognition of the sample as a normal case is very brittle and will fail in case of mode collapse. Local-Outlier-Factor (d) makes a decision
based on the data samples closest to the input sample. Our model (e) learns multiple local distributions and uses the data likelihood of the
closest one as the anomaly score.
suffer from mode collapse in high-dimensional data spaces,
i.e., the relevant data modes needed to distinguish rare but
normal data from anomalies will be missed.
Simple nearest neighbor analysis, such as the Local-outlierfactor , operates in image-space directly without training. While this is a simple and sometimes
effective baseline, such local analysis is inefﬁcient in very
high-dimensional spaces and is slow at test time. Fig. 2 illustrates these different strategies in a simple, two-dimensional
In this work, we propose the use of multiple-hypotheses
networks for anomaly
detection to provide a more ﬁne-grained description of the
data distribution than with a single-headed network. In
conjunction with a variational autoencoder, the multiple
hypotheses can be realized with a multi-headed decoder.
Concretely, each network head may predict a Gaussian
density estimate. Hypotheses form clusters in the data space
and can capture model uncertainty not encoded by the latent
Multiple-hypotheses networks have not yet been applied
to anomaly detection due to several difﬁculties in training
these networks to produce a multi-modal distribution consistent with the training distribution. The loosely coupled
hypotheses branches are typically learned with a winnertakes-all loss, where all learning signal is transferred to one
single best branch. Hence, bad hypotheses branches are not
penalized and may support non-existing data regions. These
artiﬁcial data modes cannot be distinguished from normal
data. This is an undesired property for anomaly detection
and becomes more severe with an increasing number of
hypotheses.
We mitigate the problem of artiﬁcial data modes by combining multiple-hypotheses learning with a discriminator
D as a critic. The discriminator ensures the consistency of
Anomaly Detection With Multiple-Hypotheses Predictions
estimated data modes with the real data distribution. Fig. 3
shows the scheme of the framework.
This approach combines ideas from all three previous
paradigms: the latent code of a variational autoencoder
yields a way to efﬁciently realize a generative model that
can act in a rather low-dimensional space; the multiple hypotheses are related to the mixture density of mixture density
networks, yet without the global component, which leads to
mode collapse.
We evaluate the anomaly detection performance of our approach on CIFAR-10 and a real anomaly image dataset,
the Metal Anomaly dataset with images showing a structured metal surface, where anomalies in the form of
scratches, dents or texture differences are to be detected.
We show that anomaly detection performance with multiplehypotheses networks is signiﬁcantly better compared to
single-hypotheses networks. On CIFAR-10, our proposed
ConAD framework (consistency-based anomaly detection)
improves on previously published results. Furthermore, we
show a large performance gap between ConAD and mixture
density networks. This indicates that anomaly score estimation based on the global neighborhood (or data likelihood)
is inferior to local neighborhood consideration.
2. Anomaly detection with multi-hypotheses
variational autoencoders
2.1. Training and testing for anomaly detection
Fig. 3 shows the training and testing within our framework.
The multiple-hypothesis variational autoencoder (Fig. 4)
uses the data from the normal case for distribution learning.
The learning is performed with the maximum likelihood and
critics minimizing objectives (Fig. 5).
At test time (Fig 3b), the test set is contaminated with
samples from other classes (anomalies). For each sample,
the data negative log-likelihood under the learned multihypothesis model is used as an anomaly score. The discriminator only acts as a critic during training and is not required
at test time.
2.2. Multiple-hypotheses variational autoencoder
For ﬁne-grained data description, we learn a distribution
with a multiple-hypotheses autoencoder. Figure 4 shows our
multiple-hypotheses variational autoencoder. The last layer
(head) of the decoder is split into H branches to provide H
different hypotheses. The outputs of each branch are the
parameters of an independent Gaussian for each pixel.
In the basic training procedure without discriminator training, the multiple-hypotheses autoencoder is trained with the
winner-takes-all (WTA) loss:
Figure 3. Training and testing overview of the proposed anomaly
detection framework. (a) shows training the model to capture
the normal data distribution. For the distribution learning, we
use a multiple-hypotheses variational autoencoder (Fig. 4) with
discriminator training (Fig. 5). During training, only data from
the normal case are used. (b) At test time, the data likelihood
is used for detecting anomalies. A low likelihood indicates an
out-of-distribution sample, i.e., an anomaly.
LW T A(xi|θh) = Ezk∼qφ(z|x) [log pθh(xi|zk)]
s.t. h = arg max
Ezk∼qφ(z|x)
log pθj(xi|zk)
whereby θj is the parameter set of hypothesis branch j, θh
the best hypothesis w.r.t. the data likelihood of sample xi,
zk is the noise and qφ the distribution after the encoder.
Only the network head with the best-matching hypothesis
concerning the training sample receives the learning signal.
2.3. Training with discriminator as a critic
When learning with the winner-takes-all loss, the nonoptimal hypotheses are not penalized. Thus, they can support any artiﬁcial data regions without being informed via
the learning signal; for a more formal discussion see the
Appendix. We refer to this problem as the inconsistency of
the model regarding the real underlying data distribution.
As a new alternative, we propose adding a discriminator D as
a critic when training the multiple-hypotheses autoencoder
G; see Fig. 5. D and G are optimized together on the
Anomaly Detection With Multiple-Hypotheses Predictions
Figure 4. Multi-headed variational autoencoder. All heads share
the same encoder, the same latent code, and large parts of the
decoder, but the last layers create different hypotheses.
Figure 5. Discriminator training in the context of the multiplehypotheses autoencoder. As in usual discriminator training, an
image from the training set and a randomly sampled image are
labeled as real and fake respectively. Additional fake samples are
generated by the autoencoder.
minimax loss
G LD(x, z) = min
G −log(pD(xreal))
+Lfake(x, z)
with Lfake(x, z) = log(pD(ˆxz∼N(0,1)))
+ log(pD(ˆxz∼N(µz|x,Σz|x))) + log(pD(ˆxbest−guess))
Figure 5 illustrates how samples are fed into the discriminator. In contrast to a standard GAN, samples labeled as
fake come from three different sources: randomly-sampled
images ˆxz∼N(0,1), data reconstruction deﬁned by individual hypotheses ˆxz∼N(µz|x,Σz|x), the best combination of
hypotheses according to the winner-takes-all loss ˆxbest guess.
Accordingly, the learning objective for the VAE generator
G LG = min
G LW T A + KL(qφ(z|x)||N(0, 1)) −LD,
where KL denotes the symmetrized Kullback-Leibler divergence (Jensen-Shannon divergence). Intuitively, the discriminator enforces the generated hypotheses to remain in
realistic data regions. The model is trained until the WTAloss is minimized on the validation set.
Figure 6. (a) Modeling task with one extremely dominant data
mode (dense region) and one under-represented mode. (b) shows
how multiple-hypotheses predictions are used to cover data modes.
Hypotheses tend to concentrate on the dominant mode, which
leads to over-ﬁtting in this region. (c) Increasing diversity across
hypotheses (similar to maximizing inter-class variance) leads to
better coverage of the underlying data.
2.4. Avoiding mode collapse
To avoid mode collapse of the discriminator training and
hypotheses, we propose to employ hypotheses discrimination. This is inspired by minibatch discrimination . Concretely, in each batch, the discriminator
receives the pair-wise features-distance of generated hypotheses. Since batches of real images have large pair-wise
distances, the generator has to generate diverse outputs to
avoid being detected too easily. Training with hypotheses
discrimination naturally leads to more diversity among hypotheses.
Fig. 6 shows a simple example of why more diversity among
hypotheses is beneﬁcial. The hypotheses correspond to
cluster centers in the image-conditional space. Maximizing diversity among hypotheses is, hence, similar to the
maximization of inter-class-variance in typical clustering
algorithm such as Linear Discriminant Analysis (Mika et al.,
2.5. Anomaly score estimation based on local
neighborhood
Hypotheses are spread out to cover the data modes seen
during training. Due to the loose coupling between hypotheses, the probability mass of each hypothesis is only
distributed within the respective cluster. Compared to traditional likelihood learning, the conditional probability mass
only sums up to 1 within each hypothesis branch, i.e., the
combination of all hypotheses does not yield a proper density function as in mixture density networks. However, we
can use the winner-takes-all loss as the pixel-wise sample
anomaly score. Hence, each pixel likelihood is only evaluated based on the best-matching conditional hypothesis. We
refer to this as anomaly detection based on local likelihood
estimation.
Anomaly Detection With Multiple-Hypotheses Predictions
Local likelihood is more effective for anomaly score estimation
Fig. 2 provides an intuition, why the local neighborhood is more effective in anomaly detection. The red
point represents a new normal point which is very close to
one less dominant data mode. By using the global likelihood
function (Fig. 2c), the anomaly score depends on all other
However, samples further away intuitively do not affect
the anomaly score estimation. In Local-outlier-factor , outlier score estimation only depends on
samples close to the new point (ﬁg. 2d). Similarly, our
multi-hypotheses model considers only the next cluster (ﬁg.
2e) and provides a more accurate anomaly score.
Further, learning local likelihood estimations is easier and
more sample-efﬁcient than learning from a global likelihood
function, since the local model need not learn the global
dependencies. During training, it is sufﬁcient if samples are
covered by at least one hypothesis.
In summary, we estimate the anomaly scores based on the
consistency of new samples regarding the closest hypotheses. Accordingly, we refer to our framework as consistencybased anomaly detection (ConAD).
3. Related works
In high-dimensional input domains such as images, modern
generative models are typically used to learn the data distribution
for the normal data . In many cases, anomaly detection
might improve the models behavior in out-of-distribution
cases .
For learning in uncertain tasks, Chen & Koltun ;
Bhattacharyya et al. ; Rupprecht et al. ; Ilg
et al. independently proposed multiple-hypothesespredictions (MHP) networks. More details about theses
works can be found in the Appendix.
In contrast to previous MHP-networks, we propose to utilize
these networks for anomaly detection for the ﬁrst time. To
this end, we introduce a strategy to avoid the support of
artiﬁcial data modes, namely via a discriminator as a critic.
 suggested a soft WTA-loss, where
the non-optimal hypotheses receive a small fraction of the
learning signal. Depending on the softening parameter ϵ, the
model training results in a state between mean-regression
(i.e., uni-modal learning) and large support of non-existing
data modes (more details in the Appendix). Therefore, the
soft-WTA-loss is a compromise of contradicting concepts
and, thus, requires a good choice of the corresponding hyperparameter. In the case of anomaly detection, the hyperparameter search cannot be formalized, since there are not
enough anomalous data points available.
Compared to previous reconstruction-based anomaly detection methods ; Bishop
 ), our framework evaluates anomaly score only based
on the local instead of the global neighborhood. Further, the
model learns from a relaxed version of likelihood maximizing, which results in better sample efﬁciency.
4. Experiments
In this section, we compare the proposed approach to previous deep learning and non-deep learning techniques for oneclass learning tasks. Since true anomaly detection benchmarks are rare, we ﬁrst tested on CIFAR-10, where one class
is used as the normal case to be modeled, and the other 9
classes are considered as anomalies and are only available
at test time. Besides, we tested on a true anomaly detection
task on a metal anomaly dataset, where arbitrary deviations
from the normal case can appear in the data.
4.1. Network architecture
The networks are following DCGAN 
but were scaled down to support the low-resolution of
CIFAR-10. Concretely, the decoder only uses a sequence
of Dense-Deconv.-Conv.-Deconv. layers and on top, 2 ∗n
Deconv. layer for n hypotheses branches. Each branch requires two layers since for each pixel position, the network
predicts a µ andσ for the conditional distribution. Further,
throughout the network, leaky-relu units are employed.
Hypotheses branches are represented as decoder networks
heads. Each hypothesis predicts one Gaussian distribution
with diagonal co-variance Σ and means µ. The winner-takesall loss operates on the pixel-level, i.e., for each predicted
pixel, there is a single winner across hypotheses. The bestcombined-reconstructions is the combination of the winning
hypotheses on pixel-level.
4.2. Training
For training with the discriminator in Fig. 5, samples are
forwarded separately through the network. The batch-size n
was set to 64 each on CIFAR-10, 32 on the Metal Anomaly
dataset. Adam was used for training
with a learning rate of 0.001. Per discriminator training,
the generator is trained at most ﬁve epochs to balance both
players. We use the validation set of samples from the
normal class to early stop the training if no better model
regarding the corresponding loss could be found.
4.3. Evaluation
Experiments details
Quantitative evaluation is done on
CIFAR-10 and the Metal Anomaly dataset (Tab.1). The typ-
Anomaly Detection With Multiple-Hypotheses Predictions
Table 1. Dataset description. CIFAR-10 is transformed into 10
anomaly detection tasks, where one class is used as the normal
class, and the remaining classes are treated as anomalies. The train
& validation datasets contain only samples from the normal class.
This scenario resembles the typical situation where anomalies are
extremely rare and not available at training time, as in the Metal
Anomaly dataset.
METAL ANOMALY
RESOLUTION
NORMAL DATA
ical 10-way classiﬁcation task in CIFAR-10 is transformed
into 10 one vs. nine anomaly detection tasks. Each class
is used as the normal class once; all remaining classes are
treated as anomalies. During model training, only data
from the normal data class is used, data from anomalous
classes are abandoned. At test time, anomaly detection
performance is measured in Area-Under-Curve of Receiver
Operating Curve (AUROC) based on normalized negative
log-likelihood scores given by the training objective.
2, we evaluated on CIFAR-10 variants of our
multiple-hypotheses approaches including the following energy formulations: MDN , MHP-WTA , MHP , ConAD, and
MDN+GAN. We compare our methods against vanilla VAE
 , VAEGAN
 , AnoGAN
 , AdGAN Deecke et al., 2018, OC-
Deep-SVDD . Traditional approaches
considered are: Isolation Forest ,
OCSVM . The performance of traditional methods suffers due to the curse of dimensionality
 .
Furthermore, on the high-dimensional Metal Anomaly
dataset, we focus only on the evaluation of deep learning
techniques. The GAN-techniques proposed by previous
work AdGAN & AnoGAN heavily suffer from instability
due to pure GAN-training on a small dataset. Hence, their
training leads to random anomaly detection performance.
Therefore, we only evaluate MHP-based approaches against
their uni-modal counterparts (VAE, VAEGAN).
Anomaly detection on CIFAR-10
Tab. 7 and Tab. 4
show an extensive evaluation of different traditional and
deep learning techniques. Results are adopted from in which the training and testing scenarios
were similar. The average performance overall 10 anomaly
detection tasks are summarized in Tab. 2. Traditional,
Table 2. Anomaly detection on CIFAR-10, performance measured
in AUROC. Each class is considered as the normal class once
with all other classes being considered as anomalies, resulting in
10 one-vs-nine classiﬁcation tasks. Performance is averaged for
all ten tasks and over three runs each (see Appendix for detailed
performance). Our approach signiﬁcantly outperforms previous
non-Deep Learning and Deep Learning methods.
NON-DL. KDE-PCA
ADGAN CONAD
non-deep-learning methods only succeed to capture classes
with a dominant homogeneous background such as ships,
planes, frogs (backgrounds are water, sky, green nature
respectively). This issue occurs due to preceding feature
projection with PCA, which focuses on dominant axes with
large variance. reported that even features from a pretrained AlexNet have no positive effect on
anomaly detection performance.
Our approach ConAD outperforms previously reported
results by 3.9% absolute improvement.
Furthermore,
compared to other multiple-hypotheses-approaches (MHP,
MDN, MHP+WTA), our model could beneﬁt from the increased capacity given by the additional hypotheses. The
combination of discriminator training and a high number
of hypotheses is crucial for high detection performance as
indicated in our ablation study (Tab. 5).
Anomaly detection on Metal Anomaly dataset
shows a qualitative analysis of uni-modal learning with VAE
 compared to our framework
ConAD. Due to the ﬁne-grained learning with multiplehypotheses, our maximum-likelihood reconstructions of
samples are signiﬁcantly closer to the input. Contrary, VAE
training results in blurry reconstructions and hence falsiﬁed
anomaly heatmaps, hence cannot separate possible anomaly
from dataset details.
Tab. 6 shows an evaluation of MHP-methods against multimodal density-learning methods such as MDN , VAEGAN . Note that the VAE-GAN model corresponds to our
ConAD with a single hypothesis. The VAE corresponds to
a single hypothesis variant of MHP, MHP-WTA, and MDN.
Anomaly Detection With Multiple-Hypotheses Predictions
Table 3. CIFAR-10 anomaly detection: AUROC-performance of different approaches. The column indicates which class was used as
in-class data for distribution learning. Note that random performance is at 50% and higher scores are better. Top-2-methods are marked.
Our ConAD approach outperforms traditional methods and vanilla MHP-approaches signiﬁcantly and can beneﬁt from an increasing
number of hypotheses.
MHP-WTA-16
MDN+GAN-16
CONAD - 2 (OURS)
CONAD - 4 (OURS)
CONAD - 8 (OURS)
CONAD - 16 (OURS)
Table 4. Anomaly detection performance on CIFAR-10 dependent
on multiple-hypotheses-predictions models and hypotheses number. Performance averaged over tasks and in multiple runs each.
HYPOTHESES
61.7 =VAEGAN 61.6
The signiﬁcant improvement of up to 4.2% AUROC-score
comes from the loose coupling of hypotheses in combination
with a discriminator D as quality assurance. In a highdimensional domain such as images, anomaly detection with
MDN is worse than MHP approaches. This result from (1)
typical mode collapse in MDN and (2) global neighborhood
consideration for anomaly score estimation.
Using the MHP-technique, better performance is already
achieved with two hypotheses. However, without the discriminator D, an increasing number of hypotheses rapidly
leads to performance breakdown, due to the inconsistency
property of generated hypotheses. Intuitively, additional
Table 5. Ablation study of our approach ConAD on CIFAR-10,
meausured in anomaly detection performance (AUROC-scores on
unseen contaminated dataset).
CONFIGURATION
CONAD (8-HYPOTHESES)
- FEWER HYPOTHESES (2)
- DISCRIMINATOR
- WINNER-TAKES-ALL-LOSS (WTA)
- WTA & LOOSE HYP. COUPLING
- MULTIPLE-HYPOTHESES
- MULTIPLE-HYPOTHESES & DISCRIMINATOR
non-optimal hypotheses are not strongly penalized during
training, if they support artiﬁcial data regions.
With our framework ConAD, anomaly detection performance remains competitive or better even with an increasing
number of hypotheses available. The discriminator D makes
the framework adaptable to the new dataset and less sensitive to the number of hypotheses to be used.
When more hypotheses are used (8), the anomaly detection performance in all multiple-hypotheses models rapidly
breaks down. The standard variance of performance of standard approaches remains high (up to ± 3.5). The reason
might be the beneﬁcial start for some hypotheses branches,
which adversely affect non-optimal branches.
Anomaly Detection With Multiple-Hypotheses Predictions
Figure 7. (a) anomalous samples on Metal Anomaly data-set. Anomalies are highlighted. (b) shows maximum-likelihood reconstructions
under a Variational Autoencoder and the corresponding anomaly heatmaps based on negative-log-likelihood. (c) shows the reconstructions
and anomaly maps for ConAD. In all cases, the maximum-likelihood expectation under the unimodal model is blurry and should itself be
seen as an anomaly. Contrary, under our model, the maximum-likelihood expectation of the input is much closer to the input and more
realistic. Due to the ﬁne-grained learning, the anomaly heatmaps could reliably identify the location and strength of possible anomalies.
Table 6. Anomaly detection performance and their standard variance on the Metal Anomaly dataset. To reduce noisy residuals
due to the high-dimensional input domain, only 10% of maximally
abnormal pixels with the highest residuals are summed to form the
total anomaly score. AUROC is computed on an unseen test set, a
combination of normal and anomaly data. For more detailed results
see Appendix. The anomaly detection performance of plain MHP
rapidly breaks down with an increasing number of hypotheses.
HYPOTHESES
98.0 (0.5)
97.0 (1.0)
95.0 (0.2)
98.0 (0.9)
98.0 (0.1)
94.6 (3.3)
90.0 (1.1)
91.0 (1.9)
91.6 (3.5)
94.2 (1.6)
91.3 (1.9)
94.3 (1.1)
98.5 (0.1)
97.7 (0.5)
96.5 (0.2)
This effect is less severe in our framework ConAD. The
standard variance of our approaches is also signiﬁcantly
lower. We suggest that the noise is then learned too easily.
Consider the extreme case when there are 255 hypotheses
available. The winner-takes-all loss will encourage each
hypothesis branch to predict a constant image with one value
from . In our framework, the discriminator as a critic
attempts to alleviate this effect. That might be a reason why
our ConAD has less severe performance breakdown. Our
model ConAD is less sensitive to the choice of the hyperparameter for the number of hypotheses. It enables better
exploitation of the additional expressive power provided by
the MHP-technique for new anomaly detection tasks.
Our method can detect more subtle anomalies due to the focus on extremely similar samples in the local neighborhood.
However, the added capacity by the hypotheses branches
makes the network more sensitive to large label noise in the
datasets. Hence, robust anomaly detection under label noise
is a possible future research direction.
5. Conclusion
In this work, we propose to employ multiple-hypotheses
networks for learning data distributions for anomaly detection tasks. Hypotheses are meant to form clusters in the
data space and can easily capture model uncertainty not encoded by the latent code. Multiple-hypotheses networks can
provide a more ﬁne-grained description of the data distribution and therefore enable also a more ﬁne-grained anomaly
detection. Furthermore, to reduce support of artiﬁcial data
modes by hypotheses learning, we propose using a discriminator D as a critic. The combination of multiple-hypotheses
learning with D aims to retain the consistency of estimated
data modes w.r.t. the real data distribution. Further, D
encourages diversity across hypotheses with hypotheses discrimination. Our framework allows the model to identify
out-of-distribution samples reliably.
For the anomaly detection task on CIFAR-10, our proposed
model results in up to 3.9% points improvement over previously reported results. On a real anomaly detection task,
the approach reduces the error of the baseline models from
6.8% to 1.5%.
Anomaly Detection With Multiple-Hypotheses Predictions
Acknowledgements
This research was supported by Robert Bosch GmbH. We
thank our colleagues Oezguen Cicek, Thi-Hoai-Phuong
Nguyen and the four anonymous reviewers who provided
great feedback and their expertise to improve our work.