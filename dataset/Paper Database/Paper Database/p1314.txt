Received May 24, 2020, accepted June 17, 2020, date of publication June 29, 2020, date of current version July 13, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3005540
Advanced Techniques for Predicting the Future
Progression of Type 2 Diabetes
MD. SHAFIQUL ISLAM
1, MARWA K. QARAQE
1, (Member, IEEE),
SAMIR BRAHIM BELHAOUARI
1, (Senior Member, IEEE),
AND MUHAMMAD A. ABDUL-GHANI2
1College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar
2UT Health San Antonio, San Antonio, TX 78229, USA
Corresponding author: Md. Shaﬁqul Islam ( )
This work was supported in part by a scholarship from Hamad Bin Khalifa University (HBKU), and in part by a member of Qatar
Foundation for Education, Science, and Community Development.
Diabetes is a costly and burdensome metabolic disorder that occurs due to the elevation
of glucose levels in the bloodstream. If it goes unchecked for an extended period, it can lead to the damage of
different body organs and develop life-threatening health complications. Studies show that the progression of
diabetes can be stopped or delayed, provided a person follows a healthy lifestyle and takes proper medication.
Prevention of diabetes or the delayed onset of diabetes is crucial, and it can be achieved if there exists a
screening process that identiﬁes individuals who are at risk of developing diabetes in the future. Although
machine learning techniques have been applied for disease diagnosis, there is little work done on long
term prediction of disease, type 2 diabetes in particular. Moreover, ﬁnding discriminative features or riskfactors responsible for the future development of diabetes plays a signiﬁcant role. In this study, we propose
two novel feature extraction approaches for ﬁnding the best risk-factors, followed by applying a machine
learning pipeline for the long term prediction of type 2 diabetes. The proposed methods have been evaluated
using data from a longitudinal clinical study, known as the San Antonio Heart Study. Our proposed model
managed to achieve 95.94% accuracy in predicting whether a person will develop type 2 diabetes within the
next 7–8 years or not.
INDEX TERMS Feature extraction, fractional derivative, wavelet transform, machine learning, and diabetes
prediction.
I. INTRODUCTION
Diabetes mellitus (DM) is a chronic metabolic disorder
requiring continuous glycemic control for associated risk
reduction. Insulin, a hormone generated in the pancreas gland
of the body, carries glucose from the bloodstream into the
body cells . The lack of insulin leads to the rise of
blood glucose levels and thus progresses the development
of diabetes. According to the World Health Organization
(WHO), diabetes is diagnosed if fasting plasma glucose
(PG0) value is ≥126 mg/dL or two-hour plasma glucose
(PG120) is ≥200 mg/dL after 75g of oral glucose intake .
The consequence of diabetes affects national health-care budgets, slows down economic growth, and increases healthcare expenditure . According to the International Diabetes
The associate editor coordinating the review of this manuscript and
approving it for publication was Khalid Aamir.
Federation (IDF), in 2015, there were about 415 million
diabetic people worldwide . IDF also forecasts that, if the
present trends continue, then by the year 2045, 629 million
people will have diabetes.
Early detection of diabetes is vital so that patients can
take necessary actions at an early stage and potentially prevent or delay health complications such as cardiovascular
disease, neuropathy, nephropathy, and eye disease arise from
diabetes. Studies show that the progression of diabetes can
be stopped, provided a person adheres to a strict dietary and
medication regimen. Certain people, who are overweight,
age over 45 years, have a family history of diabetes, and
physically less active, are at high risk of developing diabetes in their lifetime than others. A recent study found that
early detection of type 2 diabetes mellitus (T2DM) can bring
substantial health beneﬁts . Early screening, followed by
treatment, reduced cardiovascular risk factors for the groups
VOLUME 8, 2020
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see 
M. S. Islam et al.: Advanced Techniques for Predicting the Future Progression of Type 2 Diabetes
TABLE 1. List of socio-demographic and physiological data collected in the SAHS study.
as compared to the subjects who had no screening within the
ﬁve-year follow-up period.
In the recent past, we have seen researchers applying
machine learning techniques to detect and predict diabetes at
an early stage – . Heikes et al. used the physiological data from the National Health and Nutrition Examination Survey (NHANES) for detecting undiagnosed diabetes
and pre-diabetes by applying logistic regression (LR) and
decision tree (DT) classiﬁers. The authors achieved a sensitivity of 88% and 75% in the detection of diabetes and
pre-diabetes, respectively. Casanova et al. investigated
the relative performance of the machine learning models for
detecting diabetes incident. The random forest (RF) and LR
models were evaluated on Jackson Heart Study (JHS) data
and achieved an AUC score of 82%. Alghamdi et al. also
investigated the relative performance of different machine
learning approaches such as the DT, naive Bayes (NB), LR,
and RF for predicting the future development of diabetes.
They utilized physical exercise data from the Henry Ford
exercise testing (FIT) study, which involved 32,555 nondiabetic subjects, 5,099 of them developed diabetes during
the 5-year follow-up. Their method achieved an AUC score
of 92%. Zhang et al. used the support vector machine
(SVM) to investigate the texture patterns of the tongue
for diabetes detection. Tongue images were collected from
296 diabetics and 531 non-diabetic subjects. Such approach
achieved an accuracy of 78.77%. Pradhan et al. used the
artiﬁcial neural network (ANN) on the Pima Indian diabetes
dataset and obtained detection accuracy of 85.09%.
In an attempt to further the limited research done in the
prediction of T2DM, we propose a novel approach that a)
incorporates two new feature extraction schemes, b) selects
features/risk-factors that are highly correlated with the future
development of T2DM, and c) ﬁnally implements a machine
learning model to predict the future progression of T2DM.
This work offers three major contributions:
1) Two new methods to extract features from the oral glucose tolerance test (OGTT) data have been introduced.
2) The second signiﬁcant contribution of this work is the
identiﬁcation of the best features/risk-factors responsible for the future development of T2DM.
3) A machine learning framework is proposed and
optimized in the context of T2DM prediction.
II. DATA MODEL
The San Antonio Heart Study (SAHS) is a clinical study
that was conducted from 1979 to 1988 among the population of Mexican American (MA) and non-Hispanic White
(NHW) ethnicity . The study aimed to ﬁnd the prevalence of T2DM after 7–8 years. Different socio-demographic
and physiological data, as outlined in Table 1, were collected at baseline between 1979–1988 and during a followup from 1987–1996. For the baseline study, a total number
of 5,158 participants, aged 25–64 years, were recruited for the
OGTT data collection. Only 3226 subjects showed-up during
the follow-up. Plasma glucose (PG) and serum insulin (I)
levels at 0, 30, 60, and 120 min. were measured in two time
periods: at baseline and during the follow-up.
Previously, the SAHS and other similar datasets were used
for the prediction of T2DM prevalence. Among them are
Stern et al. , who proposed the San Antonio Diabetes
Prediction Model (SADPM) to identify the person at risk
of developing T2DM. The model was evaluated by randomly selecting 1791 MA and 1112 NHW subjects from
the SAHS data. Abdul-Ghani et al. randomly sampled
1397 subjects from the SAHS data to ﬁnd the best predictor
responsible for the future development of T2DM. In another
study, Abdul-Ghani et al. introduced two-step criteria
for predicting T2DM progression. The study implemented the
SADPM model to calculate a risk score for 1397 individuals
of the SAHS data. In addition, Bozorgmanesh et al. 
investigated the applicability of the SADPM model for the
Middle Eastern population. They selected 3242 subjects from
Tehran glucose and lipid study (TGLS) who were without
diabetes as a baseline and predicted T2DM progression with
a follow up of 6.3 years.
A. DATA PREPARATION
In the present study, we analyzed 1368 randomly selected
subjects from the SAHS data. There were 904 and 466 participants from MA and NHW ethnicity, respectively. A total
of 171 subjects developed diabetes during the follow-up.
The data have a reasonable number of subjects, and they are
well representative of the total study population. However,
the dataset is highly imbalanced as only 11% of the instances
were in positive class (diabetic) as compared to 89% of
the cases for negative (healthy) class. Machine learning
VOLUME 8, 2020
M. S. Islam et al.: Advanced Techniques for Predicting the Future Progression of Type 2 Diabetes
TABLE 2. Data groups with their corresponding patient IDs.
classiﬁers work best when the data are balanced .
To manage the imbalance, the dataset was split into seven
groups, G1–G7, as outlined in Table 2, with an equal number
of instances for both positive and negative classes. The
patient group, G1, consists of 171 healthy subjects with
patient id from H1 to H171, and 171 diabetic subjects
with patient id from D1 to D171. In the subsequent patient
group, the same diabetic subjects were maintained. However,
a new dataset was used for healthy patients. All patients’
data consisted of 1197 healthy and 171 diabetic subjects,
respectively. The low-risk group comprised of 1026 healthy
(IDs D1-D171, while, the high-risk group had 171 healthy
subjects (IDs H1027-H1197) and 171 diabetic subjects
(IDs D1-D171).
FIGURE 1. Bar graph showing the values of PG60 (mg/dL) for all the
patient groups from G1 to G7.
B. STATISTICAL ANALYSIS OF SAHS DATA
The statistical summary of the collected SASH data for all
the patient groups is shown in the bar graph (Fig. 1). The
difference in plasma glucose values at 1h (PG60) between
the healthy and diabetic subjects during baseline is significant (p < 0.05) for patients groups G1–G6. In particular, for group G1, the mean of PG60 for the patients who
remained healthy during follow-up was 74.32 mg/dL. In contrast, the mean of PG60 for the participants who developed
diabetes was 180.8 mg/dL. Similarly, signiﬁcant difference
in PG60 values was observed between healthy and diabetic
subjects for the patient groups G2-G6. However, no signiﬁcant difference in PG60 values was observed between healthy
(179.19 mg/dL) and diabetic (180.08 mg/dL) subjects for
the patient group G7. From the statistical analysis in Fig. 1,
we can conclude that, patient groups G1–G6 are separable
from each other but the same cannot be said of the patient
group G7. Therefore, the groups G1–G6 are referred to as a
low-risk group, while group G7 as a high-risk group.
III. PROPOSED MACHINE LEARNING FRAMEWORK
This section presents the proposed machine learning framework that incorporates two novel feature extraction methods
to predict future development of T2DM. A summary of the
work-ﬂow followed in this proposed framework is shown
in Fig. 2. The SAHS OGTT data have been used in this
study. The dataset was already covered in Section II. Two
new feature extraction techniques, utilizing the concept of
fractional derivative and wavelet decomposition, have been
introduced. Then all the extracted features were fused. Statistical test was performed on the extracted features to ﬁnd
important features. Finally, a machine learning framework
was implemented to predict the incidence of T2DM.
FIGURE 2. Proposed machine learning methodology for T2DM prediction.
A. PRE-PROCESSING
The raw OGTT data were pre-processed by ﬁlling missing
values using the arithmetical mean of the corresponding
variable. The data variables were analyzed for any extreme
values, and no such outliers were found for the variable
without missing values as outlined in Table 1. Moreover,
there were only ﬁve and eight missing values for the variable I120 and PG0, respectively, which is a small fraction
(0.36% and 0.58%) of the total subjects. It was also observed
VOLUME 8, 2020
M. S. Islam et al.: Advanced Techniques for Predicting the Future Progression of Type 2 Diabetes
that the values for the variable without missing values are
around the mean, such as for BMI (min-15.21, mean-27.55,
max-58.58). Therefore, to preserve the mean of the corresponding variable, the arithmetical mean was used to
replace missing values. Furthermore, the ethnicity feature
was encoded with a numerical representation as 0 for MA,
and 1 for NHW, respectively.
B. FEATURE EXTRACTION
Feature extraction refers to the transformation of raw data
into a set of discriminative predictors, which facilitates better model performance . Extracting relevant features is
considered the most critical and signiﬁcant task in machine
learning-based classiﬁcation. In literature, there was limited
work done on ﬁnding a set of highly correlated features
responsible for the future development of diabetes. In this
study, two novel feature extraction methods have been introduced. A detailed description of each approach is provided in
the subsequent subsections.
1) GLUCOSE AND INSULIN INDEX FEATURE
The way a person reacts to glucose intake over time dictates
how capable their body is at metabolizing glucose. The poor
glucose absorption capability of a person indicates that more
glucose will remain in the bloodstream over time . The
same holds for the person whose pancreas has an inadequate
insulin production capacity. The body’s glucose absorption
index (BGAI) and insulin production index (BIPI) have been
calculated using the concept of the fractional derivative .
The fractional derivative of f(x) with respect to x is the
function f′(x) and is deﬁned as,
f′(x) = f(x + h) −f(x)
f(k)(x) ≈lim
f(x) −kf(x −h) + k(k−1)
f(x −2h) + · · ·
where f(x + h) is h hours’ time delayed form of f(x). The
classical derivative can be extended for any order k in R,
i.e., the derivative of order k does not only have to be a noninteger, but also a negative order. We can simplify the above
expression by taking the ﬁrst two terms only and considering
time difference at denominator such as:
f(k)(x) = f(x + h) −kf(x)
(t(x + h) −t(x))k
For the proposed feature extraction scheme, different
BGAI and BIPI features are derived based on:
BGAI[k]i = PGj −kPGl
BIPI[k]i =
where PG and I are plasma glucose and insulin, respectively.
t1 and t2 are the time intervals such as 0, 30, 60, and 120 min.
at which the glucose and insulin values are measured during the OGTT. For different values of k (=0.5, 1, 1.5, 2),
i (=1, 2, 3, . . . 6), j (=30, 60, 120), and l (=0, 30, 60), a total
of 48 BGAI and BIPI features have been extracted.
2) STATISTICAL WAVELET FEATURE
In the literature, the features related to the area under the glucose and insulin curve were extracted from raw OGTT data
for T2DM prediction . Wavelet-based statistical features
such as mean, median, and standard deviation are widely used
for biomedical signal analysis and application . Wavelet
transformation is ideal for spectral analysis of the signals.
However, the discrete wavelet transformation appears to be
less efﬁcient for pure stationary signals. Also, due to the
redundancy of wavelet basis functions, it is computationally
intensive to choose the right mother wavelet . This paper
presents a new type of feature extraction scheme, which is
inspired by the Haar wavelet transformation. Haar basis is
the simplest yet the most widely used wavelet basis .
In this transformation approach, coefﬁcients are calculated
by taking the pairwise mean of the raw data and then subtracting the mean from the ﬁrst element of the pair. The
procedures are repeated for calculating means, and differences are kept unchanged in subsequent steps. An example
with 4 data samples is shown in the Fig. 3 for illustrative
FIGURE 3. A numerical example of the proposed feature extraction
scheme inspired from wavelet transformation (Haar Basis).
The rationale behind using wavelet decomposition for feature extraction was that the inadequate glucose metabolizing
capability of a person leads to accumulating more glucose in
the blood over time. Thus, the averages and differences of glucose values for different time intervals (0, 30, 60, 120 min.)
are higher for those subjects as compared to the healthy
subjects. The same holds for the averages and differences in
insulin values. In this study, the same strategies of addition
and subtraction of Haar wavelet were adapted to extract a new
set of features from the OGTT data. A total of 8 new wavelet
features were derived based on
Wavelet1 =
Wavelet2 =
Wavelet3 =
Wavelet4 =
Wavelet5 = X1 −X2
VOLUME 8, 2020
M. S. Islam et al.: Advanced Techniques for Predicting the Future Progression of Type 2 Diabetes
Wavelet6 = X3 −X4
Wavelet7 = X5 −X6
Wavelet8 = X7 −X8
where Xn is a data vector of size 8 which consists of eight raw
features from the OGTT data; namely, X1 = PG0, X2 = PG30,
X3 = PG60, X4 = PG120, X5 = I0, X6 = I30, X7 = I60,
and X8 = I120.
3) FEATURE ADAPTATION
This study adapted the area under the glucose and insulinbased characteristic features, as outlined in Table 3. Those
features have shown to be effective in discriminating between
the two classes: healthy and diabetic . The trapezoidal
rule was used to calculate the area under the glucose curve
(AuG0−120) and area under the insulin curve (AuI0−120)
values, for 0-120 min. Matsuda index (M) refers to insulin
sensitivity calculated from PG0 and I0 . Insulin secretion
(1I/1G0−30) was calculated by dividing the increment of
I30 with the increment of PG30 for 0–30 min during the
OGTT. Insulin secretion or resistance indices were derived by
multiplying Matsuda index and insulin secretion for 0-30 min
(1I/1G0−30 × M) or 0-120 min (1I/1G0−120 × M),
respectively.
TABLE 3. Feature adapted from the study of Abdul-Ghani et al. .
C. STATISTICAL ANALYSIS, FEATURE FUSION
AND SELECTION
1) STATISTICAL ANALYSIS
The features derived from raw data play a crucial role
in machine learning-based classiﬁcation task. This work
attempts to extract the features that are most discriminatory between healthy and diabetic subjects. Inferential statistics provide inference about data, whether they occur in
real or just by chance. One such statistical test is t-statistics,
also known as student t-test proposed by William Sealy
Gosset . A paired t-test was implemented to gain insight
about the distribution of the data and to conﬁrm if there is any
difference between healthy subjects and diabetic subjects’
means and variances of the extracted features. The t-test
justiﬁes the null hypothesis that two features have equal
mean and equal but unknown variance. T-test returns two
results 1 or 0, which implies reject or accept the null hypothesis, respectively.
2) FEATURE FUSION
Feature fusion is the consolidation of features extracted from
multiple approaches into a single feature set. It facilitates
to have a compact set of salient features that can improve
classiﬁcation accuracy . In this study, the extracted and
adapted features have been fused. The ﬁnal feature vector
consists of raw features, glucose and insulin index features,
statistical wavelet features, and adapted features. The size of
the ﬁnal feature vector is 78, and consequently, the size of the
ﬁnal dataset with all patients is 1368 × 78.
3) FEATURE SELECTION
In the literature, there was limited work done on ﬁnding signiﬁcant features correlated with the future progression of diabetes. We implemented different feature selection techniques
to ﬁnd a set of best features that are highly correlated with
the future development of T2DM. To ﬁnd an optimal feature
set, three feature selection approaches; namely, ﬁlter, wrapper, and embedded methods were implemented. Ultimately,
the best performing features were chosen for model development. Pearson correlation was used while performing the
ﬁlter method. This method yielded a rank for each feature that
ranged from 1 (best feature) to -1 (least signiﬁcant feature).
Then the wrapper method was applied by developing an RF
model with greedy forward feature selection, which evaluates
the performance of a feature set by estimating the accuracy.
To calculate the accuracy of the RF model for a set of features,
10-folds cross-validation (CV) was used. In the embedded
method, features were selected based on their highest level
of contribution to the outcome. The least absolute shrinkage and selection operator (LASSO) penalty was used while
incorporating the LR model for feature selection. LASSO
(L1 penalty) can shrink some features coefﬁcients values to
zero, which facilitates the removal of those features .
D. MODEL DEVELOPMENT
Different machine learning models were proposed for the
long term T2DM prediction. The ﬁnal output of the model is a
binary decision (0/1 - no/yes) for the future forecast of T2DM.
A 10-fold CV technique was implemented for training and
testing of the proposed models. The SAHS dataset was split
into ten folds during the model development. In the ﬁrst
iteration, nine folds were used for training, and the remaining
fold was used for testing. The training and testing process
was repeated ten times with a different train and test samples
in each time. Final results were calculated by averaging outcomes from test samples over ten iterations. The developed
models were optimized by tuning different hyperparameters.
1) SUPPORT VECTOR MACHINE
The SVM, a popular supervised machine learning model,
ﬁnds the best separating hyperplane by maximizing the margin between the classes using the Lagrangian optimization
technique . In the case of a non-linear distribution of the
data, where a hyperplane cannot separate the classes, SVM
VOLUME 8, 2020
M. S. Islam et al.: Advanced Techniques for Predicting the Future Progression of Type 2 Diabetes
uses a technique known as the kernel. The kernel trick transforms the data into a higher dimensional feature space so that
a linear separation of the data is ensured. The pseudocodes of
developed polynomial SVM can be summarized as:
Pseudocode Polynomial SVM
Input: Dataset D
Output: Accuracy, Sensitivity, Speciﬁcity, AUC
CV: 10-folds Cross-Validation
PolynomialSVM (Input, N_iteration,CV):
X_train: Split[D, 0.9]
X_test: Split[D, 0.1]
y_train, y_test: Labels, y in {0,1}
M:Polynomial SVM Classiﬁers
for each n in 1 to CV:
construct M using X_train, y_train
ﬁnd C and Gamma
apply M on X_test to get labels y_pred
calculate Accuracy, Sensitivity, Speciﬁcity, AUC
The proposed SVM model with a polynomial kernel was
optimized in the context of T2DM prediction. Two hyperparameters of SVM, namely C and gamma, were tuned to get
the optimized model. The hyper-parameter C is considered as
a regularization parameter that allows ﬂexibility in deﬁning
margin, while the gamma value determines the curvature of
the decision boundary.
2) ENSEMBLING OF Naïve BAYES
The NB is one of the benchmarked algorithm used for the
classiﬁcation task. It calculates the posterior probability of
a class label given a particular data record based on Bayes
theorem . The conditional probability p(y|x) of a class y
is calculated as:
p(y | x) = p(y) p(x | y)
where p(y) is the prior probability of a class y, p(x|y) is the
conditional probability of a feature given a particular class,
and p(x) is the evidence or probability of data x regardless of
it’s class.
In this study, NB and its two variants, such as averaged one-dependence estimators (A1DE) and averaged
two-dependence estimators (A2DE) were ensembled for
T2DM prediction. An assumption of weaker feature independence facilitates A1DE and A2DE to have high classiﬁcation
accuracy as compared to NB . In the A1DE technique,
classiﬁers were developed for every single feature, and the
ﬁnal prediction was calculated by averaging over all classi-
ﬁers’ decisions. The ensembling steps were as follows:
1) Step-1: Split the data, D, into ten folds
2) Step-2: Train three classiﬁers (NB, A1DE, A2DE) on
the nine (one–nine) folds and test on the tenth fold
3) Step-3: Repeat Step-2 ten times for different combinations of train and test data
4) Step-4: Take the product of probability from the individual classiﬁers’ decision to make the ﬁnal decision
over all three classiﬁers
3) BOOSTING AND BAGGING ALGORITHMS
The Boosting technique is useful for reducing bias and variance. In boosting, multiple weak learners’ decisions combine
to make a strong decision. The misclassiﬁed samples are
given more priority in the next step with an increased weight.
Conversely, bagging or bootstrap aggregating improves the
stability and accuracy of the model by building trees using
randomly sampled data and, thus, avoids over-ﬁtting. One
such bagging method is the RF algorithm , which adds
more randomness in selecting a subset of the features.
In this study, tree-based models such as RF, AdaBoost, and
bagging models were proposed for T2DM prediction. Three
hyperparameters of the RF model; namely, the maximum
number of features, the number of trees, and the minimum
sample leaf size have been tuned. The square root of the
total number of features, 500 trees, and minimum leaf size
of 50 were found to be optimal values of hyperparameters
that achieved the highest accuracy. For the AdaBoost model,
the optimum values of hyperparameters are- number of learners (100), learning rate (0.01), and depth of the tree (10).
For the bagging approach, a decision tree is developed and
optimized with a maximum depth of 20, a minimum sample
split of 10, and a maximum feature of 30. The pseudocode of
the developed RF can be summarized as:
Pseudocode Random Forest
Generate n classiﬁers:
for i = 1 to n do
Randomly sample the data D with replacement to
produce Di
Create a root nodeNi with data Di
Call BuildTree (Ni)
BuildTree(N):
Randomly select x% of features in N
Select the feature with highest information gain
Create N1..Nf child nodes, where F = F1..Ff
for i = 1 to f do
Call BuildTree(Ni)
E. PERFORMANCE EVALUATION
To evaluate the performance of the proposed T2DM prediction models, the following metrics are used:
Accuracy =
TP + TN + FP + FN
Sensitivity =
Speciﬁcity =
AUC = p(Score(TP) > Score(TN))
VOLUME 8, 2020
M. S. Islam et al.: Advanced Techniques for Predicting the Future Progression of Type 2 Diabetes
where TP, TN, FP, FN refer to true positive, true negative,
false positive, and false negative instances respectively. Area
under curve (AUC) of a classiﬁer is the probability that
a randomly chosen TP case will be ranked higher than a
randomly chosen TN case.
IV. RESULTS AND DISCUSSIONS
In this section, the t-test results of the derived features are
provided. Details result on feature selection is analyzed. The
10-folds CV performance of the proposed T2DM prediction
models is presented and benchmarked with the literature.
TABLE 4. Result of statistical t-test between the healthy and diabetic
subjects of groups G1, G4 and G7.
A. STATISTICAL ANALYSIS OF THE DERIVED FEATURES
Statistical t-test values for the patient groups G1, G4, and G7,
are summarized in Table 4. The test rejected the null hypothesis for all features, except BIPI3, Wavelet2, Wavelet8,
AuI30−120, and 1I/1G0−30 for the patient group G1. This
ﬁnding indicates that the mean and the variance were not
equal among the healthy and diabetic subjects of G1. As the
distribution of the data between healthy and diabetic subjects
differs for most of the extracted features of G1, the healthy
subjects can be easily separable from diabetic subjects. The
similar t-test results were obtained for patient group G4, and
the null hypothesis can be accepted only for four features.
However, for the patient group G7, the null hypotheses was
true for 14 of the extracted features. Therefore, the means
and the variances of those 14 features were equal among
the healthy and diabetic subjects of G7. Some important
features for which null hypotheses was rejected among the
subjects of G7 are: BGAI3, BGAI5, Wavelet2, AuG0−120, and
1I/1G0−30 × M. These features appear as discriminating
features for separating healthy subjects from diabetes subjects of G7, which was inseparable while using only the raw
data, as shown in Section II.
B. FEATURE SELECTION RESULTS
The top–30 features selected by the ﬁlter, wrapper, and
embedded methods are summarized in Table 5 with their
corresponding rank. In the ﬁlter method, the Pearson correlation coefﬁcient was used as a ranking criterion for feature
selection. Top ﬁve features selected by the ﬁlter method
are: PG120, AuG0−120, AuG60−120, BGAI[k = 0.5]6, and
AuG0−120. In the wrapper method, the RF classiﬁer was
combined with a forward feature selection approach. PG120,
AuG0−120, and AuG60−120 remained the top three features.
The embedded method, in which LR model with Lasso
penalty was used for features selection, ranks AuG0−120
as the top feature, followed by BGAI[k = 0.5]6, and
BGAI[k = 1]6. It was observed that our extracted fractional
derivative and wavelet features, as well as the area under
glucose-based features, remain the top features for all the
three methods. The raw OGTT features such as PG120, PG60,
and PG30 were also appeared in the top–30 features list.
TABLE 5. Selected top-30 features by the filter, wrapper, and embedded
C. T2DM PREDICTION RESULTS
The classiﬁcation performance of the proposed ensemble
model on different feature combinations is summarized
in Table 6. For the top–5 features, the model achieved 82.02%
accuracy, 79.8% sensitivity, 82.46% speciﬁcity, and 86.7%
AUC score. The best performance was obtained for the
top–30 features with an accuracy of 95.94%, a sensitivity
of 100%, a speciﬁcity of 91.5%, and an AUC score of 96.3%.
The accuracy dropped to 84.46% while evaluating the model
with all the features. We found top–25, top–30, and top–35
are the optimal features set that displayed the best performances. Using only the top–1, top–5 or all the features
appeared to be not useful for the proposed classiﬁcation task
as those combinations come with low sensitivities of 78.2%,
79.8%, and 84.8% as well as moderate accuracies of 81.78%,
82.02%, and 84.46%, respectively. It was observed that using
VOLUME 8, 2020
M. S. Islam et al.: Advanced Techniques for Predicting the Future Progression of Type 2 Diabetes
TABLE 6. Performance comparison of selected different feature
combinations used in this study.
the same ensemble model performances differ from one feature combination to another. Therefore, feature selection was
a crucial step, along with the optimized model for achieving
the best performance.
TABLE 7. The 10-folds CV performance comparison of T2DM prediction
models proposed in this study.
The 10-folds CV performances of the developed models are summarized in Table 7. All the proposed machine
learning models utilized the best performing top–30 features
during model development and evaluation. The best result
was achieved for the ensembling of NB and its two variants
A1DE and A2DE, with an accuracy of 95.94%, a sensitivity
of 100%, a speciﬁcity of 91.5%, and an AUC score of 96.3%.
Although NB, A1DE, and A2DE separately achieved a sensitivity of 81.9%, 84.8%, and 93.4%, respectively, sensitivity
reached to 100% when all the three classiﬁers are ensembled. The sensitivity result was signiﬁcantly improved for the
ensembling model as compared to other proposed models.
All the other proposed classiﬁers displayed similar performance, which comprises high speciﬁcity and low sensitivity.
This work aims to improve the classiﬁers’ sensitivity over the
speciﬁcity, as missing a progressor of T2DM has more severe
consequences than missing a healthy outcome. Although a
perfect sensitivity score has been achieved, the speciﬁcity
score was affected; that is, 8.5% healthy subjects were misclassiﬁed. As obtaining high sensitivity was the priority,
we accepted the 91.5% speciﬁcity result.
TABLE 8. Group-wise 10-folds CV performance comparison of T2DM
prediction models proposed in this study.
The group-wise performance comparison of T2DM prediction is summarized in Table 8. The best performing ensemble
model with the selected top–30 features were used to produce
Table 8. For the patient group G1, an accuracy of 98.83%,
a sensitivity of 97.7%, a speciﬁcity of 100%, and an AUC
score of 97.7% have been achieved. Similar performances
were observed, i.e., high accuracies coupled with high sensitivities, speciﬁcities, and AUC scores for the patient groups
G2–G6. But for the patient group G7, the accuracy decreased
to 86.84%, sensitivity to 82.3%, speciﬁcity to 91.2%, and
AUC scores to 91.9%. The poor performance in terms of
sensitivity by the patient group G7 was expected as it was
shown through statistical analyses that the distribution of
both healthy and diabetic subjects for G7 is similar. This
similarity and high overlapping made classiﬁcation task challenging for the patient group G7. The averaging over all the
groups (G1–G7) provided an accuracy of 95.23%, a sensitivity of 92.2%, a speciﬁcity of 98.24%, and an AUC score
of 97.04%.
The poor performance of the patient group G7 was affecting the overall performance of the model. To justify this
rationale, another two models, namely, low-risk and high-risk
models, have been proposed based on data similarity and dissimilarity. The low-risk model was developed using the data
from patient groups G1-G6 as these groups showed dissimilar
statistical behavior between healthy and diabetic subjects.
On the other hand, the high-risk model was developed using
the data from the patient group G7. This group named as a
high-risk group because it was challenging for the classiﬁers
to distinguish between healthy and diabetic subjects due to
their similar statistics, as shown in the bar graph (Fig. 1) and
in Table 4. For the low-risk model, an accuracy of 94.15%,
a sensitivity of 95.3%, a speciﬁcity of 93%, and an AUC score
of 96.7% were achieved. Conversely, performance dropped
to 86.84% accuracy, 82.3% sensitivity, 91.2% speciﬁcity,
and 91.9% AUC score for the high-risk model. An attempt
was also taken to develop a generalized model so that it
can perform equally well for all the patients. The proposed
VOLUME 8, 2020
M. S. Islam et al.: Advanced Techniques for Predicting the Future Progression of Type 2 Diabetes
TABLE 9. Performance comparison with literature on T2DM prediction.
generalized model, developed by ensembling of NB, and it’s
two variants, A1DE and A2DE, utilized all patients’ data and
achieved 95.94% accuracy, 100% sensitivity, 91.5% speci-
ﬁcity, and 96.3% AUC score.
D. RESULTS BENCHMARKING
Performance comparison between the proposed models and
other similar existing works addressing T2DM prediction is
summarized in Table 9. Studies – , predict future
progression of diabetes in advance of 5–7 years time-frame.
The SAHS dataset was used for both model development
and evaluation in the studies , . The SADPM was
implemented for the long term prediction of diabetes progression in the studies – . Most of the studies, as outlined
in Table 9, utilized only raw data as features. There were
limited works done on feature extraction from OGTT data.
The study extracted the area under the glucose and
insulin curve features, as well as insulin secretion and resistance features. They selected insulin secretion and resistance
features as the best features and achieved 82% sensitivity.
The color and texture of the tongue images were extracted for
T2DM prediction in the study . The principal component
VOLUME 8, 2020
M. S. Islam et al.: Advanced Techniques for Predicting the Future Progression of Type 2 Diabetes
analysis (PCA) was applied for dimensionality reduction of
the images. An accuracy of 78.77% was achieved for their
image-based approach. Another study included a total
of 62 raw features from demographic, disease, and medical
history of the subjects. Clinical importance criteria was used
to select 13 features where age, heart rate, blood pressure,
obesity, and family history were found as optimal features
that provided an AUC score of 92%. In our study, we devised
a machine learning framework to predict T2DM progression
in 7–8 years advance. The main goal of this work was to
extract discriminative features from OGTT data and to investigate whether a machine learning model can outperform the
regression model (SADPM) for this particular SAHS dataset.
Our proposed ensemble model achieved an average accuracy
of 95.94%, a sensitivity of 100%, a speciﬁcity of 91.5%,
and an AUC score of 96.3%. Our feature extraction, coupled
with the model ensembling outperforms the existing works
in terms of accuracy, sensitivity, AUC; and overall serves as
an optimal prediction model compared to similar work in the
literature.
The signiﬁcance of this work is crucial in that it allows
subjects to be given a fair warning of whether they are susceptible to develop T2DM in the future. This early warning of
diabetes development can aid in the prevention of the disorder
by taking appropriate measures and, at minimum, to reduce
the severity of the disease and prolong its onset.
V. CONCLUSION
The early prediction of diabetes is a critical task that can
equip people with the advantage of early knowledge and
intervention. It helps people to enhance their health status
and possibly prevent the onset of the disorder. Also, such an
accurate prediction of the disease can signiﬁcantly reduce
national healthcare expenditure, particularly in the area of
diabetes and its complications. This paper aimed to extract
novel features from OGTT data, to select the best riskfactor responsible for type 2 diabetes development, and to
implement a machine learning pipeline for early prediction
of type 2 diabetes. Two novel feature extraction techniques
have been introduced, which is then followed by features
selection. Several supervised learning models have been presented and demonstrated that the best results were achieved
for the ensemble of classiﬁers. This study also compared
the performance improvement over the existing works in
terms of accuracy, sensitivity, speciﬁcity, and AUC scores.
The proposed machine learning framework is the pioneer in
the ﬁeld that is capable of predicting whether a person will
develop T2DM within the next 7-8 years with an accuracy
of 95.94%.
We faced several challenges while developing and evaluating the proposed machine learning framework. There is
no other OGTT dataset publicly available to test further
the applicability of our extracted features for T2DM prediction. In the future, other OGTT datasets can be used upon
availability to evaluate our proposed framework. Another
potential research direction can be to extract more fractional
derivative-based glucose and insulin index features by a varying number of higher-order terms and investigate the classi-
ﬁcation performance. In the future, we also plan to extract
features from the OGTT data using deep learning approaches.