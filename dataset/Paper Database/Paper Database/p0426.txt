Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing pages 1003 1013
Structural Representations for Learning Relations between Pairs of Texts
Simone Filice and Giovanni Da San Martino and Alessandro Moschitti
ALT, Qatar Computing Research Institute, Hamad Bin Khalifa University
{sfilice,gmartino,amoschitti}@qf.org.qa
This paper studies the use of structural
representations for learning relations between pairs of short texts (e.g., sentences
or paragraphs) of the kind: the second
text answers to, or conveys exactly the
same information of, or is implied by, the
ﬁrst text.
Engineering effective features
that can capture syntactic and semantic relations between the constituents composing the target text pairs is rather complex.
Thus, we deﬁne syntactic and semantic
structures representing the text pairs and
then apply graph and tree kernels to them
for automatically engineering features in
Support Vector Machines. We carry out
an extensive comparative analysis of stateof-the-art models for this type of relational
learning. Our ﬁndings allow for achieving the highest accuracy in two different and important related tasks, i.e., Paraphrasing Identiﬁcation and Textual Entailment Recognition.
Introduction
Advanced NLP systems, e.g., IBM Watson system
 , are the result of effective
use of syntactic/semantic information along with
relational learning (RL) methods. This research
area is rather vast including, extraction of syntactic relations, e.g., , predicate
relations, e.g., Semantic Role Labeling or FrameNet parsing and relation extraction between named entities, e.g., .
Although extremely interesting,
methods target relations only between text constituents whereas the ﬁnal goal of an intelligent
system would be to interpret the semantics of
larger pieces of text, e.g., sentences or paragraphs.
This line of research relates to three
broad ﬁelds, namely, Question Answering (QA)
 , Paraphrasing Identiﬁcation (PI) and Recognition
of Textual Entailments (RTE) . More generally, RL from text can be denied
as follows: given two text fragments, the main
goal is to derive relations between them, e.g., either if the second fragment answers the question,
or conveys exactly the same information or is implied by the ﬁrst text fragment. For example, the
following two sentences:
- License revenue slid 21 percent, however, to
$107.6 million.
- License sales, a key measure of demand, fell 21
percent to $107.6 million.
express exactly the same meaning, whereas the
- She was transferred again to Navy when the
American Civil War began, 1861.
- The American Civil War started in 1861.
Automatic learning a model for deriving the relations above is rather complex as any of the text
constituents, e.g., License revenue, a key measure
of demand, in the two sentences plays an important
role. Therefore, a suitable approach should exploit representations that can structure the two sentences and put their constituents in relation. Since
the dependencies between constituents can be an
exponential number and representing structures in
learning algorithms is rather challenging, automatic feature engineering through kernel methods
 can be a promising direction.
In particular, in ,
we represented the two evaluating sentences for
the RTE task with syntactic structures and then applied tree kernels to them. The resulting system
was very accurate but, unfortunately, it could not
scale to large datasets as it is based on a compu-
tationally exponential algorithm. This prevents its
application to PI tasks, which typically require a
large dataset to train the related systems.
In this paper, we carry out an extensive experimentation using different kernels based on trees
and graphs and their combinations with the aim of
assessing the best model for relation learning between two entire sentences (or even paragraphs).
More in detail, (i) we design many models for RL
combining state-of-the-art tree kernels and graph
kernels and apply them to innovative computational structures. These innovative combinations
use for the ﬁst time semantic/syntactic tree kernels and graph kernels for the tackled tasks. (ii)
Our kernels provide effective and efﬁcient solutions, which solve the previous scalability problem
and, at the same time, exceed the state of the art
on both RTE and PI. Finally, our study suggests
research directions for designing effective graph
kernels for RL.
Related Work
In this paper, we apply kernel methods, which enable an efﬁcient comparison of structures in huge,
possibly inﬁnite, feature spaces. While for trees, a
comparison using all possible subtrees is possible,
designing kernel functions for graphs with such
property is an NP-Hard problem (i.e., it shows the
same complexity of the graph isomorphism problem) .
Thus most kernels
for graphs only associate speciﬁc types of substructures with features, such as paths , walks
 
and tree structures .
We exploit structural kernels for PI, whose task
is to evaluate whether a given pair of sentences is
in the paraphrase class or not, ). Paraphrases can be seen as
a restatement of a text in another form that preserves the original meaning. This task has a primary importance in many other NLP and IR tasks
such as Machine Translation, Plagiarism Detection and QA. Several approaches have been proposed, e.g., apply a recursive
auto encoder with dynamic pooling, and use eight machine translation metrics
to achieve the state of the art. To our knowledge no
previous model based on kernel methods has been
applied before: with such methods, we outperform
the state of the art in PI.
A description of RTE can be found in : it is deﬁned as a directional
relation extraction between two text fragments,
called text and hypothesis. The implication is supposed to be detectable only based on the text content. Its applications are in QA, Information Extraction, Summarization and Machine translation.
One of the most performing approaches of RTE 3
was , which
largely relies on external resources (i.e., WordNet,
Wikipedia, acronyms dictionaries) and a base of
knowledge developed ad hoc for the dataset. In
 , we designed an
interesting but computationally expensive model
using simple syntactic tree kernels.
In this paper, we develop models that do not use external
resources but, at the same time, are efﬁcient and
approach the state of the art in RTE.
Structural kernels
Kernel Machines carry out learning and classiﬁcation by only relying on the inner product between instances. This can be efﬁciently and implicitly computed by kernel functions by exploiting the following dual formulation of the model
(hyperplane): P
i=1..l yi↵iφ(oi) · φ(o) + b = 0,
where yi are the example labels, ↵i the support
vector coefﬁcients, oi and o are two objects, φ is
a mapping from the objects to feature vectors ~xi
and φ(oi) · φ(o) = K(oi, o) is the kernel function implicitly deﬁning such mapping.
of structural kernels, K maps objects in substructures, thus determining their size and shape. Given
two structures S1 and S2, our general deﬁnition of
structural kernels is the following:
K(S1, S2) =
s1✓S1,s2✓S2,si2S
kiso(s1, s2),
where si are substructures of Si, S is the set of admissible substructures, and kiso determines if the
two substructures are isomorphic, i.e., it outputs 1
if s1 and s2 are isomorphic and 0 otherwise.
In the following, we also provide a more
computational-oriented deﬁnition of structural
kernels to more easily describe those we use in our
Let the set S = {s1, s2, . . . , s|S|} be the substructure space and χi(n) be an indicator function,
equal to 1 if the target si is rooted at node n and
equal to 0 otherwise. A structural-kernel function
over S1 and S2 is
K(S1, S2) =
∆(n1, n2),
where NS1 and NS2 are the sets of the S1’s and
S2’s nodes, respectively and
∆(n1, n2) =
χi(n1)χi(n2).
The latter is equal to the number of common
substructures rooted in the n1 and n2 nodes.
In order to have a similarity score between 0
and 1, a normalization in the kernel space, i.e.,
K(S1,S1)⇥K(S2,S2) is usually applied.
practical computation viewpoint, it is convenient
to divide structural kernels in two classes of algorithms working either on trees or graphs.
The Partial Tree Kernel (PTK)
PTK generalizes a large class
of tree kernels as it computes one of the most
general tree substructure spaces. Given two trees
S1 and S2, PTK considers any connected subset
of nodes as possible feature of the substructure
space, and counts how many of them are shared
by S1 and S2. Its computation is carried out by
Eq. 2 using the following ∆PTK function:
∆PTK(n1, n2) = 0; else ∆PTK(n1, n2) =
~I1,~I2,l(~I1)=l(~I2)
λd(~I1)+d(~I2)
∆P T K(cn1(~I1j), cn2(~I2j))
where µ, λ 2 are two decay factors, ~I1 and
~I2 are two sequences of indices, which index subsequences of children u, ~I = (i1, ..., i|u|), in sequences of children s, 1 i1 < ... < i|u| |s|,
i.e., such that u = si1..si|u|, and d(~I) = i|u| −
i1 + 1 is the distance between the ﬁrst and last
The PTK computational complexity is
O(p⇢2|NS1||NS2|) , where p is
the largest subsequence of children that we want
to consider and ⇢is the maximal outdegree observed in the two trees. However the average running time tends to be linear for natural language
syntactic trees .
Smoothed Partial Tree Kernel (SPTK)
Constraining the application of lexical similarity to words embedded in similar structures
provides clear advantages over all-vs-all words
similarity,
semantically
Indeed, syntax provides the necessary
restrictions to compute an effective semantic
similarity.
SPTK generalizes
similarity
during substructure matching.
More formally,
SPTK is computed by Eq. 2 using the following
∆SPTK(n1, n2) = P|S|
i,j=1 χi(n1)χj(n2)⌃(si, sj),
where ⌃is a similarity between structures1. The
recursive deﬁnition of ∆SPTK is the following:
1. if n1 and n2 are leaves ∆SPTK(n1, n2) =
µλσ(n1, n2);
2. else ∆SPTK(n1, n2) = µσ(n1, n2) ⇥
~I1,~I2,l(~I1)=l(~I2)
λd(~I1)+d(~I2)
∆σ(cn1(~I1j), cn2(~I2j))
where σ is any similarity between nodes, e.g., between their lexical labels, and the other variables
are the same of PTK. The worst case complexity
of SPTK is identical to PTK and in practice is
not higher than O(|NS1||NS2|).
Neighborhood Subgraph Pairwise
Distance Kernel (NSPDK)
When general subgraphs are used as features in a
kernel computation, eq. 1 and 2 become computationally intractable . To solve
this problem, we need to restrict the set of considered substructures S. 
deﬁned NSPDK such that the feature space is
only constituted by pairs of subgraphs (substructures) that are (i) centered in two nodes n1 and n2
such that their distance is not more than D; and
(ii) constituted by all nodes (and their edges) at
an exact distance h from n1 or n2, where the distance between two nodes is deﬁned as the number of edges in the shortest path connecting them.
More formally, let G, NG and EG be a graph and
its set of nodes and edges, respectively, the substructure space S = SG(H, D) used by NSPDK
in eqs 2 and 3 is:
{(γh(n), γh(n0)) : 1 h H, n, n0 2 NG,
d(n, n0) D},
where γh(n) returns the subgraph obtained by executing h steps of a breadth-ﬁrst visit of G starting
from node n and d(n, n0) is the distance between
two nodes in the graph. Note that (i) any feature
1Note that this generalizes Eq. 3.
of the space is basically a pair of substructures;
and (ii) there is currently no efﬁcient (implicit) formulation for computing such kernel. In contrast,
when H and D are limited, it is simple to compute
the space SG(H, D) explicitly. In such case, the
complexity of the kernel is given by the substructure extraction step, which is O(|NG| ⇥h⇢log ⇢).
Kernel Combinations
Previous sections have shown three different kernels. Among them, NSPDK is actually an explicit kernel, where the features are automatically
extracted with a procedure. In NLP, features are
often manually deﬁned by domain experts, who
know the linguistic phenomena involved in the
task. When available, such features are important
as they encode some of the background knowledge
on the task. Therefore, combining different feature
spaces is typically very useful. Fortunately, kernel methods enable an easy integration of different
kernels or feature spaces, i.e., the kernel sum produces the joint feature space and it is still a valid
kernel. In the next section, we show representations of text, i.e., structures and features, speciﬁc
to PI and RTE.
Representations for RL from text
The kernels described in the previous section can
be applied to generic trees and graphs.
Automatic feature engineering using structural kernels
requires the design of structures for representing
data examples that are speciﬁc to the learning task
we want to tackle. In our case, we focus on RL,
which consists in deriving the semantic relation
between two entire pieces of text. We focus on
two well-understood relations, namely, paraphrasing and textual implications. The tasks are simply
deﬁned as: given two texts a1 and a2, automatically classify if (i) a1 is a paraphrase of a2 and/or
(ii) a1 implies a2. Although the two tasks are linguistically and conceptually rather different, they
can be modeled in a similar way from a shallow
representation viewpoint. This is exactly the perspective we would like to keep for showing the advantage of using kernel methods. Therefore, in the
following, we deﬁne sentence representations that
can be suitably used for both tasks and then we
rely on structural kernels and the adopted learning
algorithm for exploring the substructures relevant
to the different tasks.
Tree Representations
An intuitive understanding of our target tasks
suggests that syntactic information is essential to
achieve high accuracy.
Therefore, we consider
the syntactic parse trees of the pair of sentences
involved in the evaluation. For example, Fig. 1
shows the syntactic constituency trees of the
sentences reported in the introduction (these
do not include the green label REL and the
dashed edges).
Given two pairs of sentences,
pa = ha1, a2i and pb = hb1, b2i, an initial kernel
for learning the tasks, can be the simple tree
kernel sum, e.g., PTK(a1, b1) + PTK(a2, b2)
as was deﬁned in . This kernel
works in the space of the union of the sets of all
subtrees from the upper and lower trees, e.g.:
[PP [TO [to::t]][NP [QP [$
[$::$]][QP [CD [107.6::c]]]]]], [PP
[TO][NP [QP [$][QP [CD ]]]]], [PP
[TO][NP [QP [QP [CD]]]]], [PP [NP [QP
[QP]]]], ...
[NP [NP [DT [a::d]] [JJ [key::j]
NN]][PP]], [NP [NP [DT] [JJ NN]][PP]], [NP
[NP [JJ NN]][PP]], [NP [NP [NN]][PP]],
[NP [NP [JJ]][PP]], ...
However, such features cannot capture the relations between the constituents (or semantic lexical
units) from the two trees. In contrast, these are essential to learn the relation between the two entire
sentences2.
To overcome this problem, in , we proposed the use of placeholders for RTE: the main idea was to annotate the
matches between the constituents of the two sentences, e.g., 107.6 millions, on both trees. This
way the tree fragments in the generated kernel
space contained an index capturing the correspondences between a1 and a2. The critical drawback
of this approach is that other pairs, e.g., pb, will
have in general different indices, making the representation very sparse. Alternatively, we experimented with models that select the best match between all possible placeholder assignments across
the two pairs. Although we obtained a good improvement, such solution required an exponential
computational time and the selection of the max
2Of course assuming that text meaning is compositional.
license::j
revenue::n
slide::vNP-REL
percent::n
however::r
million::c
license::j
measure::n
percent::n
million::c
Figure 1: Text representations for PI and RTE: (i) pair of trees, a1 (upper) and a2 (lower), (ii) combined
in a graph with dashed edges, and (iii) labelled with the tag REL (in green). The nodes highlighted in
yellow constitute a feature for the NSPDK kernel (h = 1, D = 3) centered at the nodes ADVB and
assignment made our similarity function a nonvalid kernel.
Thus, for this paper, we prefer to rely on a more
recent solution we proposed for passage reranking
in the QA domain , and
for Answer Selection (Severyn and Moschitti,
It consists in simply labeling matching
nodes with a special tag, e.g., REL, which
indicates the correspondences between words.
REL is attached to the father and grandfather
nodes of the matching words.
Fig. 1 shows
several green REL tags attached to the usual
POS-tag and constituent node labels of the parse
trees. For example, the lemma license is matched
by the two sentences, thus both its father, JJ,
and its grandfather, NP, nodes are marked with
Thanks to such relational labeling the
simple kernel, PTK(a1, b1) + PTK(a2, b2), can
generate relational features from a1, e.g.,
[NP-REL [JJ-REL] NN]][PP]], [NP
[NN]][PP]],
[NP [NP-REL [JJ-REL]][PP]],...
If such features are matched in b1, they provide
the fuzzy information: there should be a match
similar to [NP [NP-REL [JJ-REL]] also between
a2 and b2. This kind of matches establishes a sort
of relational pair features.
It should be noted that we proposed more
complex REL tagging policies for Passage Reranking, exploiting additional resources such as
Linked Open Data or WordNet . Another interesting application of this
RL framework is the Machine Translation Evaluation . Finally, we used a similar model for translating questions to SQL queries
in .
Graph Representations
The relational tree representation can capture relational features but the use of the same REL
tag for any match between the two trees prevents
to deterministically establish the correspondences
between nodes.
For exactly representing such
matches (without incurring in non-valid kernels
or sparsity problems), a graph representation is
needed. If we connect matching nodes (or also
nodes labelled as REL) in Fig. 1 (see dashed
lines), we obtain a relational graph. Substructures
of such graph clearly indicate how constituents,
e.g., NPs, VPs, PPs, from one sentence map into
the other sentence.
If such mappings observed
in a pair of paraphrase sentences are matched
in another sentence pair, there may be evidence
that also the second pair contains paraphrase sen-
Unfortunately, the kernel computing the space
of all substructures of a graph (even if only considering connected nodes) is an intractable problem as mentioned in Sec. 3.3. Thus, we opt for the
use of NSPDK, which generates speciﬁc pairs
of structures. Intuitively, the latter can capture relational features between constituents of the two
trees. Figure 1 shows an example of features generated by the NSPDK with parameters H =
1, D = 3 (the substructures are highlighted in
yellow), i.e., [ADVB [VP] [RB]], [NP-REL [VP]
[CD-REL] [NN-REL]].
Basic Features
In addition to structural representations, we also
use typical features for capturing the degrees of
similarity between two sentences.
In contrast,
with the previous kernels these similarities are
computed intra-pair, e.g., between a1 and a2. Note
that any similarity measure generates only one feature. Their description follows:
– Syntactic similarities, which apply the cosine
function to vectors of n-grams (with n = 1, 2, 3, 4)
of word lemmas and part-of-speech tags.
– Kernel similarities, which use PTK or SPTK
applied to the sentences within the pair.
We also used similarity features from the
DKPro of the UKP Lab , tested
in the Semantic Textual Similarity (STS) task:
– Longest common substring measure and Longest
common subsequence measure, which determine
the length of the longest substring shared by two
text segments.
– Running-Karp-Rabin Greedy String Tiling provides a similarity between two sentences by counting the number of shufﬂes in their subparts.
– Resnik similarity based on the WordNet hierarchy.
– Explicit Semantic Analysis (ESA) similarity represents documents as weighted vectors of concepts learned from Wikipedia, WordNet and Wiktionary.
– Lexical Substitution :
a supervised word sense disambiguation system
is used to substitute a wide selection of highfrequency English nouns with generalizations,
then Resnik and ESA features are computed on the
transformed text.
Combined representations
As mentioned in Sec. 3.4, we can combine kernels for engineering new features. Let K be PTK
or SPTK, given two pairs of sentences pa =
ha1, a2i and pb = hb1, b2i, we build the following
kernel combinations for the RTE task:
(i) K+(pa, pb) = K(a1, b1) + K(a2, b2), which
simply sums the similarities between the ﬁrst
two sentences and the second two sentences
whose implication has to be derived.
(ii) An alternative kernel combines the two
similarity scores above with the product:
K⇥(pa, pb) = K(a1, b1) · K(a2, b2).
(iii) The symmetry of the PI task requires different kernels.
The most intuitive applies K
between all member combinations and sum
all contributions: all+
K(pa, pb)=K(a1, b1) +
K(a2, b2) + K(a1, b2) + K(a2, b1).
(iv) It is also possible to combine pairs of
corresponding kernels with the product:
K(a1, b1)K(a2, b2)
K(a1, b2)K(a2, b1).
(v) An alternative kernel selects only the best between the two products above: MK(pa, pb) =
max(K(a1, b1)K(a2, b2), K(a1, b2)K(a2, b1)).
This is motivated by the observation that
before measuring the similarity between
two pairs,
we need to establish which
ai is more similar to bj.
However, the
max operator causes MK
not to be a
substitute it with a softmax function,
is a valid kernel, i.e., SMK(pa, pb) = softmax(K(a1, b1)K(a2, b2), K(a1, b2)K(a2, b1)),
where softmax(x1, x2) = 1
clog(ecx1 + ecx2)
(c=100 was accurate enough).
The linear kernel (LK) over the basic features
(described previously) and/or NSPDK can be of
course added to all the above kernels.
Experiments
MSR Paraphrasing: we used the Microsoft Research Paraphrase Corpus consisting of 4,076 sentence pairs in the training set
and 1,725 sentence pairs in test set, with a distribution of about 66% between positive and negative
5 Fold Cross Validation
without REL tagging
75.54 ± 0.45
0.786 ± 0.009
0.876 ± 0.019
0.828 ± 0.004
72.49 ± 1.22
0.723 ± 0.014
0.957 ± 0.011
0.824 ± 0.008
72.04 ± 1.08
0.725 ± 0.009
0.940 ± 0.017
0.819 ± 0.009
SMSP T KLSA
72.56 ± 1.10
0.731 ± 0.010
0.937 ± 0.017
0.821 ± 0.009
SMSP T KW 2V
72.23 ± 1.07
0.727 ± 0.009
0.938 ± 0.017
0.820 ± 0.009
71.57 ± 0.86
0.724 ± 0.007
0.933 ± 0.015
0.815 ± 0.008
72.06 ± 0.62
0.730 ± 0.007
0.928 ± 0.014
0.817 ± 0.006
SP T KW 2V
71.61 ± 0.76
0.725 ± 0.008
0.931 ± 0.013
0.815 ± 0.007
70.76 ± 0.91
0.720 ± 0.008
0.924 ± 0.017
0.809 ± 0.009
71.42 ± 0.91
0.727 ± 0.008
0.920 ± 0.020
0.812 ± 0.009
SP T KW 2V
71.19 ± 1.22
0.723 ± 0.010
0.927 ± 0.018
0.812 ± 0.011
72.31 ± 0.67
0.731 ± 0.007
0.930 ± 0.015
0.819 ± 0.007
MSP T KLSA
72.32 ± 0.44
0.732 ± 0.006
0.927 ± 0.014
0.818 ± 0.005
MSP T KW 2V
71.99 ± 0.96
0.730 ± 0.008
0.926 ± 0.016
0.816 ± 0.008
with REL tagging
74.69 ± 2.52
0.749 ± 0.029
0.940 ± 0.008
0.834 ± 0.018
75.42 ± 0.86
0.771 ± 0.007
0.903 ± 0.012
0.832 ± 0.008
SMSP T KLSA
75.62 ± 0.90
0.772 ± 0.007
0.905 ± 0.013
0.833 ± 0.007
SMSP T KW 2V
75.64 ± 0.77
0.771 ± 0.004
0.907 ± 0.012
0.833 ± 0.007
74.76 ± 0.71
0.769 ± 0.006
0.892 ± 0.016
0.826 ± 0.008
74.83 ± 0.92
0.771 ± 0.009
0.891 ± 0.011
0.826 ± 0.008
SP T KW 2V
75.26 ± 0.81
0.771 ± 0.008
0.898 ± 0.011
0.830 ± 0.008
73.99 ± 1.04
0.767 ± 0.010
0.880 ± 0.013
0.820 ± 0.009
73.87 ± 0.85
0.766 ± 0.009
0.880 ± 0.010
0.819 ± 0.007
SP T KW 2V
74.16 ± 0.75
0.768 ± 0.008
0.882 ± 0.012
0.821 ± 0.007
GK+SMSP T KW 2V
76.12 ± 0.96
0.787 ± 0.008
0.885 ± 0.015
0.833 ± 0.009
77.85 ± 1.00
0.804 ± 0.008
0.886 ± 0.015
0.843 ± 0.009
LK+SMSP T KW 2V
77.52 ± 1.41
0.802 ± 0.011
0.885 ± 0.016
0.841 ± 0.011
LK+GK+SMSP T KW 2V
78.11 ± 0.94
0.811 ± 0.005
0.879 ± 0.016
0.844 ± 0.009
 
 
Table 1: Results on Paraphrasing Identiﬁcation
examples. These pairs were extracted from topically similar Web news articles, applying some
heuristics that select potential paraphrases to be
annotated by human experts.
RTE-3. We adopted the RTE-3 dataset , which is composed by 800 texthypothesis pairs in both the training and test sets,
collected by human annotators. The distribution
of the examples among the positive and negative
classes is balanced.
Models and Parameterization
We train our classiﬁers with the C-SVM learning
algorithm within KeLP3, a
Kernel-based Machine Learning platform that implements tree kernels. In both tasks, we applied
the kernels described in Sec. 4, where the trees are
generated with the Stanford parser4.
similarity
σ(n1, n2) implemented as follows: if n1 and n2
are two identical syntactic nodes σ = 1. If n1
and n2 are two lexical nodes with the same POS
tag, their similarity is evaluated computing the
cosine similarity of their corresponding vectors in
a wordspace. In all the other cases σ = 0. We
generated two different wordspaces. The ﬁrst is
3 
4 
a co-occurrence LSA embedding as described in
 . The second space is
derived by applying a skip-gram model with the word2vec tool5.
using the LSA will be referred to as SPTKLSA,
while when adopting word2vec it will be indicated
with SPTKW2V .
We used default parameters
both for PTK and SPTK whereas we selected
h and D parameters of NSPDK that obtained
the best average accuracy using a 5-fold cross
validation on the training set.
Performance measures
The two considered tasks are binary classiﬁcation
problems thus we used Accuracy, Precision, Recall and F1. The adopted corpora have a prede-
ﬁned split between training and test sets thus we
tested our models according to such settings for
exactly comparing with previous work. Additionally, to better assess our results, we performed a 5fold cross validation on the complete datasets. In
case of PI, the same sentence can appear in multiple pairs thus we distributed the pairs such that
the same sentence can only appear in one fold at a
5 
5 Fold Cross Validation
without REL tagging
62.94 ± 5.68
0.635 ± 0.057
0.679 ± 0.083
0.652 ± 0.049
55.63 ± 1.81
0.564 ± 0.022
0.612 ± 0.087
0.584 ± 0.032
54.13 ± 3.26
0.547 ± 0.024
0.637 ± 0.051
0.587 ± 0.027
53.63 ± 2.50
0.543 ± 0.024
0.622 ± 0.060
0.578 ± 0.027
54.06 ± 2.34
0.546 ± 0.022
0.634 ± 0.060
0.585 ± 0.026
52.81 ± 1.99
0.535 ± 0.025
0.623 ± 0.055
0.574 ± 0.028
53.56 ± 2.09
0.543 ± 0.022
0.616 ± 0.065
0.576 ± 0.026
52.50 ± 1.77
0.533 ± 0.027
0.619 ± 0.071
0.571 ± 0.034
with REL tagging
59.81 ± 3.84
0.599 ± 0.037
0.678 ± 0.071
0.634 ± 0.026
67.75 ± 7.17
0.655 ± 0.067
0.817 ± 0.038
0.725 ± 0.046
67.81 ± 7.30
0.656 ± 0.069
0.816 ± 0.036
0.725 ± 0.047
68.00 ± 7.15
0.658 ± 0.068
0.816 ± 0.039
0.726 ± 0.046
67.75 ± 7.37
0.658 ± 0.071
0.804 ± 0.038
0.722 ± 0.049
68.00 ± 7.62
0.661 ± 0.074
0.808 ± 0.039
0.725 ± 0.049
67.69 ± 6.95
0.658 ± 0.069
0.804 ± 0.040
0.722 ± 0.043
GK+SP T K⇥
66.00 ± 6.79
0.648 ± 0.069
0.769 ± 0.034
0.701 ± 0.044
62.06 ± 5.49
0.620 ± 0.051
0.702 ± 0.053
0.656 ± 0.036
LK+SP T K⇥
68.25 ± 7.54
0.663 ± 0.076
0.816 ± 0.032
0.728 ± 0.047
LK+GK+SP T K⇥
66.31 ± 7.35
0.652 ± 0.075
0.770 ± 0.053
0.703 ± 0.052
 
 
Table 2: Results on Textual Entailment Recognition
Results on PI
The results are reported in Table 1. The ﬁrst column shows the use of the relational tag REL in
the structures (discussed in Sec. 4.1). The second
column indicates the kernel models described in
sections 3 and 4 as well as the combination of the
best models. Columns 3-6 report Accuracy, Precision, Recall and F1 derived on the ﬁxed test set,
whereas the remaining columns regard the results
obtained with cross validation. We note that:
First, when REL information is not used in the
structures, the linear kernel (LK) on basic features outperforms all the structural kernels, which
all perform similarly. The best structural kernel is
the graph kernel, NSPDK (GK in short). This
is not surprising as without REL, GK is the only
kernel that can express relational features.
Second, SPTK is only slightly better than
The reason is mainly due to the approach used for building the dataset: potential
paraphrases are retrieved applying some heuristics
mostly based on the lexical overlap between sentences. Thus, in most cases, the lexical similarity
used in SPTK is not needed as hard matches occur between the words of the sentences.
Third, when REL is used on the structures, all
kernels reach or outperform the F1 (ofﬁcial measure of the challenge) of LK. The relational structures seem to drastically reduce the inconsistent
matching between positive and negative examples,
reﬂecting in remarkable increasing in Precision. In
particular, SMSPTKLSA achieves the state of the
art6, i.e., 84.1 .
Next, combining our best models produces a
signiﬁcant improvement of the state of the art, e.g.,
LK +GK +SMSPTKW 2V outperforms the result
in by 1.7% in accuracy and
1.1 points in F1.
Finally, the cross-validation experiments con-
ﬁrm the system behavior observed on the ﬁxed
test set. The Std. Dev. (speciﬁed after the ± sign)
shows that in most cases the system differences are
signiﬁcant.
Results on RTE
We used the same experimental settings performed
for PI to carry out the experiments on RTE. The
results are shown in Table 2 structured in the same
way as the previous table. We note that:
(i) Findings similar to PI are obtained.
(ii) Again the relational structures (using REL)
provide a remarkable improvement in Accuracy (RTE challenge measure), allowing
tree kernels to compete with the state of the
This is an impressive result considering that our models do not use any external resource, e.g., as in .
(iii) This time, SPTK⇥
W2V improves on PTK by
1 absolute percent point.
6The performance of the several best systems improved
by our models are nicely summarized at 
org/aclwiki/index.php?title=Paraphrase_
Identification_(State_of_the_art)
(iv) The kernel combinations are not more effective than SPTK alone.
Finally, the cross-fold validation experiments con-
ﬁrm the ﬁxed-test set results.
Discussion and Conclusions
In this paper, we have engineered and studied
several models for relation learning. We utilized
state-of-the-art kernels for structures and created
new ones by combining kernels together. Additionally, we provide a novel deﬁnition of effective
and computationally feasible structural kernels.
Most importantly, we have designed novel computational structures for trees and graphs, which
are for the ﬁrst time tested in NLP tasks. Our kernels are computationally efﬁcient thus solving one
of the most important problems of previous work.
We empirically tested our kernels on two of the
most representative tasks of RL from text, namely,
PI and RTE. The extensive experimentation using many kernel models also combined with traditional feature vector approaches sheds some light
on how engineering effective graph and tree kernels for learning from pairs of entire text fragments. In particular, our best models signiﬁcantly
outperform the state of the art in PI and the best
kernel model for RTE 3, with Accuracy close to
the one of the best system of RTE 3.
It should be stressed that the design of previous
state-of-the-art models involved the use of several
resources, annotation and heavy manually engineering of speciﬁc rules and features: this makes
the portability of such systems on other domains
and tasks extremely difﬁcult. Moreover the unavailability of the used resources and the opacity
of the used rules have also made such systems very
difﬁcult to replicate.
On the contrary, the models we propose enable
researchers to:
(i) build their system without the use of speciﬁc resources. We use a standard syntactic
parser, and for some models we use wellknown and available corpora for automatically learning similarities with word embedding algorithms; and
(ii) reuse our work for different (similar) tasks
(see paraphrasing) and data.
The simplicity and portability of our system is a
signiﬁcant contribution to a very complex research
area such as RL from two entire pieces of text.
Our study has indeed shown that our kernel
models, which are very simple to be implemented,
reach the state of the art and can be used with large
Furthermore, it should be noted that our models outperform the best tree kernel approach of the
RTE challenges 
and also its extension that we proposed in . These systems are also adaptable and easy to replicate, but they are subject to
an exponential computational complexity and can
thus only be used on very small datasets (e.g., they
cannot be applied to the MSR Paraphrase corpus).
In contrast, the model we proposed in this paper
can be used on large datasets, because its kernel
complexity is about linear (on average).
We believe that disseminating these ﬁndings
to the research community is very important, as
it will foster research on RL, e.g., on RTE, using structural kernel methods. Such research has
had a sudden stop as the RTE data in the latest
challenges increased from 800 instances to several thousands and no tree kernel model has been
enough accurate to replace our computational expensive models .
In the future, it would be interesting deﬁning
graph kernels that can combine more than two substructures. Another possible extension regards the
use of node similarity in graph kernels. Additionally, we would like to test our models on other
RTE challenges and on several QA datasets, which
for space constraints we could not do in this work.
Acknowledgments
This research is part of the Interactive sYstems
for Answer Search (IYAS) project, conducted by
the Arabic Language Technologies (ALT) group
at Qatar Computing Research Institute (QCRI)
within the Hamad Bin Khalifa University and
Qatar Foundation.