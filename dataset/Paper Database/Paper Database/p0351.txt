When Will AI Exceed Human Performance?
Evidence from AI Experts
Katja Grace1,2, John Salvatier2, Allan Dafoe1,3, Baobao Zhang3, and Owain Evans1
1Future of Humanity Institute, Oxford University
2AI Impacts
3Department of Political Science, Yale University
Advances in artiﬁcial intelligence (AI) will transform modern life by reshaping transportation,
health, science, ﬁnance, and the military . To adapt public policy, we need to better
anticipate these advances . Here we report the results from a large survey of machine
learning researchers on their beliefs about progress in AI. Researchers predict AI will outperform humans in many activities in the next ten years, such as translating languages ,
writing high-school essays , driving a truck , working in retail ,
writing a bestselling book , and working as a surgeon . Researchers believe
there is a 50% chance of AI outperforming humans in all tasks in 45 years and of automating
all human jobs in 120 years, with Asian respondents expecting these dates much sooner than
North Americans. These results will inform discussion amongst researchers and policymakers
about anticipating and managing trends in AI.
Introduction
Advances in artiﬁcial intelligence (AI) will have massive social consequences. Self-driving technology might replace millions of driving jobs over the coming decade.
In addition to possible
unemployment, the transition will bring new challenges, such as rebuilding infrastructure, protecting vehicle cyber-security, and adapting laws and regulations . New challenges, both for AI
developers and policy-makers, will also arise from applications in law enforcement, military technology, and marketing . To prepare for these challenges, accurate forecasting of transformative
AI would be invaluable.
Several sources provide objective evidence about future AI advances: trends in computing
hardware , task performance , and the automation of labor . The predictions of AI experts
provide crucial additional information . We survey a large, representative sample of AI
experts. Our questions cover the timing of AI advances (including both practical applications of
AI and the automation of various human jobs), as well as the social and ethical impacts of AI.
Survey Method
Our survey population was all researchers who published at the 2015 NIPS and ICML conferences (two of the premier venues for peer-reviewed research in machine learning). A total of 352
researchers responded to our survey invitation (21% of the 1634 authors we contacted). Our questions concerned the timing of speciﬁc AI capabilities (e.g. folding laundry, language translation),
superiority at speciﬁc occupations (e.g. truck driver, surgeon), superiority over humans at all tasks,
and the social impacts of advanced AI. See Survey Content for details.
Time Until Machines Outperform Humans
AI would have profound social consequences if all tasks were more cost eﬀectively accomplished by
machines. Our survey used the following deﬁnition:
“High-level machine intelligence” (HLMI) is achieved when unaided machines can accomplish every task better and more cheaply than human workers.
 
Each individual respondent estimated the probability of HLMI arriving in future years. Taking the
mean over each individual, the aggregate forecast gave a 50% chance of HLMI occurring within
45 years and a 10% chance of it occurring within 9 years.
Figure 1 displays the probabilistic
predictions for a random subset of individuals, as well as the mean predictions. There is large
inter-subject variation: Figure 3 shows that Asian respondents expect HLMI in 30 years, whereas
North Americans expect it in 74 years.
Years from 2016
Probability of HLMI
Aggregate Forecast (with 95% Confidence Interval)
Random Subset of Individual Forecasts
Aggregate subjective probability of ‘high-level machine intelligence’ arrival by
future years. Each respondent provided three data points for their forecast and these were ﬁt to the
Gamma CDF by least squares to produce the grey CDFs. The “Aggregate Forecast” is the mean distribution
over all individual CDFs (also called the “mixture” distribution). The conﬁdence interval was generated
by bootstrapping (clustering on respondents) and plotting the 95% interval for estimated probabilities at
each year. The LOESS curve is a non-parametric regression on all data points.
While most participants were asked about HLMI, a subset were asked a logically similar question
that emphasized consequences for employment. The question deﬁned full automation of labor as:
when all occupations are fully automatable. That is, when for any occupation, machines
could be built to carry out the task better and more cheaply than human workers.
Forecasts for full automation of labor were much later than for HLMI: the mean of the individual
beliefs assigned a 50% probability in 122 years from now and a 10% probability in 20 years.
Figure 2: Timeline of Median Estimates (with 50% intervals) for AI Achieving Human Performance. Timelines showing 50% probability intervals for achieving selected AI milestones. Speciﬁcally,
intervals represent the date range from the 25% to 75% probability of the event occurring, calculated from
the mean of individual CDFs as in Fig. 1. Circles denote the 50%-probability year. Each milestone is for
AI to achieve or surpass human expert/professional performance (full descriptions in Table S5). Note that
these intervals represent the uncertainty of survey respondents, not estimation uncertainty.
Respondents were also asked when 32 “milestones” for AI would become feasible. The full descriptions of the milestone are in Table S5. Each milestone was considered by a random subset of
respondents (n≥24). Respondents expected (mean probability of 50%) 20 of the 32 AI milestones
to be reached within ten years. Fig. 2 displays timelines for a subset of milestones.
Intelligence Explosion, Outcomes, AI Safety
The prospect of advances in AI raises important questions. Will progress in AI become explosively
fast once AI research and development itself can be automated? How will high-level machine intelligence (HLMI) aﬀect economic growth? What are the chances this will lead to extreme outcomes
(either positive or negative)? What should be done to help ensure AI progress is beneﬁcial? Table
S4 displays results for questions we asked on these topics. Here are some key ﬁndings:
1. Researchers believe the ﬁeld of machine learning has accelerated in recent years.
We asked researchers whether the rate of progress in machine learning was faster in the
ﬁrst or second half of their career. Sixty-seven percent (67%) said progress was faster in the
second half of their career and only 10% said progress was faster in the ﬁrst half. The median
career length among respondents was 6 years.
2. Explosive progress in AI after HLMI is seen as possible but improbable. Some
authors have argued that once HLMI is achieved, AI systems will quickly become vastly
superior to humans in all tasks . This acceleration has been called the “intelligence
explosion.” We asked respondents for the probability that AI would perform vastly better
than humans in all tasks two years after HLMI is achieved. The median probability was
10% (interquartile range: 1-25%). We also asked respondents for the probability of explosive
global technological improvement two years after HLMI. Here the median probability was
20% (interquartile range 5-50%).
3. HLMI is seen as likely to have positive outcomes but catastrophic risks are
possible. Respondents were asked whether HLMI would have a positive or negative impact
on humanity over the long run.
They assigned probabilities to outcomes on a ﬁve-point
scale. The median probability was 25% for a “good” outcome and 20% for an “extremely
good” outcome. By contrast, the probability was 10% for a bad outcome and 5% for an
outcome described as “Extremely Bad (e.g., human extinction).”
4. Society should prioritize research aimed at minimizing the potential risks of AI.
Forty-eight percent of respondents think that research on minimizing the risks of AI should
be prioritized by society more than the status quo (with only 12% wishing for less).
Asia (n=68)
Europe (n=58)
North America (n=64)
Other Regions (n=21)
Years from 2016
Probability of HLMI
Figure 3: Aggregate Forecast (computed as in Figure 1) for HLMI, grouped by region in
which respondent was an undergraduate.
Additional regions (Middle East, S. America, Africa,
Oceania) had much smaller numbers and are grouped as “Other Regions.”
Asians expect HLMI 44 years before North Americans
Figure 3 shows big diﬀerences between individual respondents in when they predict HLMI will
arrive. Both citation count and seniority were not predictive of HLMI timelines (see Fig. S1 and
the results of a regression in Table S2). However, respondents from diﬀerent regions had striking
diﬀerences in HLMI predictions. Fig. 3 shows an aggregate prediction for HLMI of 30 years for
Asian respondents and 74 years for North Americans. Fig. S1 displays a similar gap between the
two countries with the most respondents in the survey: China (median 28 years) and USA (median
76 years). Similarly, the aggregate year for a 50% probability for automation of each job we asked
about (including truck driver and surgeon) was predicted to be earlier by Asians than by North
Americans (Table S2). Note that we used respondents’ undergraduate institution as a proxy for
country of origin and that many Asian respondents now study or work outside Asia.
Was our sample representative?
One concern with any kind of survey is non-response bias; in particular, researchers with strong
views may be more likely to ﬁll out a survey.
We tried to mitigate this eﬀect by making the
survey short (12 minutes) and conﬁdential, and by not mentioning the survey’s content or goals
in our invitation email. Our response rate was 21%. To investigate possible non-response bias,
we collected demographic data for both our respondents (n=406) and a random sample (n=399)
of NIPS/ICML researchers who did not respond.
Results are shown in Table S3.
Diﬀerences
between the groups in citation count, seniority, gender, and country of origin are small. While we
cannot rule out non-response biases due to unmeasured variables, we can rule out large bias due to
the demographic variables we measured. Our demographic data also shows that our respondents
included many highly-cited researchers (mostly in machine learning but also in statistics, computer
science theory, and neuroscience) and came from 43 countries (vs. a total of 52 for everyone we
sampled). A majority work in academia (82%), while 21% work in industry.
A second concern is that NIPS and ICML authors are representative of machine learning but
not of the ﬁeld of artiﬁcial intelligence as a whole. This concern could be addressed in future
work by surveying a broader range of experts across computer science, robotics, and the cognitive
sciences. In fact, a 2017 survey by Walsh asked a broad range of AI and robotics experts a
question about HLMI almost identical to ours. For a 50% chance of HLMI, the median prediction
in this survey was 2065 for robiticists and 2061 for AI experts. Our machine learning experts
predicted 2057. This is very close Walsh’s results and suggests that our conclusions about expert
views on HLMI are robust to surveying experts outside machine learning.1 It’s still possible that
groups of experts diﬀer on topics other than HLMI timelines.
Discussion
Why think AI experts have any ability to foresee AI progress? In the domain of political science, a
long-term study found that experts were worse than crude statistical extrapolations at predicting
political outcomes . AI progress, which relies on scientiﬁc breakthroughs, may appear intrinsically harder to predict. Yet there are reasons for optimism. While individual breakthroughs are
unpredictable, longer term progress in R&D for many domains (including computer hardware, genomics, solar energy) has been impressively regular . Such regularity is also displayed by trends
 in AI performance in SAT problem solving, games-playing, and computer vision and could be
exploited by AI experts in their predictions. Finally, it is well established that aggregating individual predictions can lead to big improvements over the predictions of a random individual .
Further work could use our data to make optimized forecasts. Moreover, many of the AI milestones
(Fig. 2) were forecast to be achieved in the next decade, providing ground-truth evidence about
the reliability of individual experts.
1The diﬀerence in medians between us and Walsh is tiny compared to diﬀerences between Asians and North
Americans in our study and does not provide evidence of a substantial diﬀerence between groups of experts.