Multiple Component Learning
for Object Detection
Piotr Doll´ar1,2 Boris Babenko2 Serge Belongie1,2 Pietro Perona1 Zhuowen Tu3
1 Electrical Engineering
2 Comp. Science & Eng.
3 Lab of Neuro Imaging
California Inst. of Tech.
Univ. of CA, San Diego
Univ. of CA, Los Angeles
{pdollar,perona}@caltech.edu
{bbabenko,sjb}@cs.ucsd.edu
 
Abstract. Object detection is one of the key problems in computer vision. In the last decade, discriminative learning approaches have proven
eﬀective in detecting rigid objects, achieving very low false positives
rates. The ﬁeld has also seen a resurgence of part-based recognition
methods, with impressive results on highly articulated, diverse object
categories. In this paper we propose a discriminative learning approach
for detection that is inspired by part-based recognition approaches. Our
method, Multiple Component Learning (mcl), automatically learns individual component classiﬁers and combines these into an overall classiﬁer.
Unlike previous methods, which rely on either fairly restricted part models or labeled part data, mcl learns powerful component classiﬁers in a
weakly supervised manner, where object labels are provided but part labels are not. The basis of mcl lies in learning a set classiﬁer; we achieve
this by combining boosting with weakly supervised learning, speciﬁcally
the Multiple Instance Learning framework (mil). mcl is general, and
we demonstrate results on a range of data from computer audition and
computer vision. In particular, mcl outperforms all existing methods on
the challenging INRIA pedestrian detection dataset, and unlike methods
that are not part-based, mcl is quite robust to occlusions.
Introduction
Computer vision has recently witnessed rapid development in the areas of category detection (detection and localization) and recognition (categorization).
In detection, approaches that learn classiﬁers from simple low-level features
and large amounts of data can achieve low false positive rates for quasi-rigid
objects . In recognition, part-based methods, particularly patches-as-parts
approaches , have proven eﬀective at diﬀerentiating highly articulated categories. In this paper we propose a detection algorithm that is inspired by both
lines of work. Through this combination, our system learns a robust, componentbased classiﬁer that achieves low false positive rates on articulated objects.
Our approach is based on training a discriminative set classiﬁer through a
combination of boosting and weakly supervised learning, speciﬁcally Multiple
Instance Learning (mil). The resulting method, Multiple Component Learning
(mcl), learns individual component classiﬁers and combines these into an overall
P. Doll´ar, B. Babenko, S. Belongie, P. Perona, Z. Tu
Fig. 1. Response of ﬁrst 5 learned components classiﬁers on randomly selected INRIA
pedestrian test images (best viewed in color). At most one box is displayed per component after non-maximal suppression and thresholding. Three components correspond
to semantically meaningful parts (head-magenta, left foot-red, right foot-yellow); 2 correspond to the region between between the legs. The components were learned with no
component labels provided during training. See Sec. 4.3 for details.
object classiﬁer. Object labels in the form of bounding boxes are provided, but
component labels are not. The approach is general, and we demonstrate results
on a range of data from computer audition and computer vision, including state
of the art results on the challenging INRIA pedestrian detection dataset.
We begin with a review of related work below, followed by a thorough description of our method in Sec. 2. Next we present a theoretical justiﬁcation of
our approach in Sec. 3, where we also review related work from the machine
learning literature. Finally, we present experimental results in Sec. 4.
Related Work
A number of discriminative detection systems that learn from simple low-level
features and large amounts of data have been proposed; typically their focus is
either on the learning aspect or the design of appropriate features . These
methods require large amounts of labeled data to learn invariance to articulation,
occlusion and intra-class variations. As mentioned, they have proven particularly
successful for detecting rigid objects, achieving low false positive rates. mcl is
similar to these methods in some regards, the key diﬀerence being that built
into mcl is the domain knowledge that objects are composed of parts, that the
mutual position of parts is somewhat variable and that parts may not all be
visible. mcl is therefore much better suited for detecting articulated objects,
e.g. pedestrians, and remains robust in the presence of occlusion.
Part-based approaches have a rich history; one of the earliest approaches
dates back to 1973 . A number of diﬀerent ways of extracting parts from images have since been proposed. One approach involves designing part detectors
by hand or providing a system with labeled part examples . Other than
the obvious disadvantage of being labor intensive, these methods are restricted
to using a limited number of possibly sub-optimal parts. An alternative approach
involves searching for repeatedly occurring elements using diﬀerent criteria such
as frequency of appearance in the training data , lowering an empirical risk
function , or increasing mutual information . Unlike in mcl, the recurring elements in these methods are fairly simple, including edge fragments ,
Gaussian models , or image fragments .
Multiple Component Learning for Object Detection
A simple but eﬀective method of extracting parts is to crop small image
patches, either using an interest point operator or by dense sampling .
The patches can be vector quantized to form ‘codebooks’ , and an image can
then be represented using a ‘bag of words’ model . Spatial information can
be encoded using pairwise relationships or with a spatial voting scheme
 . Alternatively, a generative model can be used to model the object, e.g. the
constellation model and its variants have proven robust and capable of
operating with little training data. Though eﬀective in recognition tasks, these
patch-based methods are limited by simple or ﬁxed part appearance models,
often relying on a patch distance measure in a predeﬁned feature space, e.g.
using normalized correlation or other patch descriptors. In mcl the component
classiﬁers are learned from low level features, and although mcl requires more
training data, the approach can lead to higher accuracy models.
Most closely related to our work is , which uses a formalism called latent
SVMs to simultaneously learn part and object models. The resulting system is
eﬀective, though very diﬀerent from our own. We emphasize that, as far as we
are aware, aside from mcl is the ﬁrst part-based method that uses rich part
appearance models without relying on part labels during training.
Multiple Component Learning
There are three primary challenges that we address in order to come up with
our discriminative component-based object model. The ﬁrst of these is how to
learn a component classiﬁer when only an object label is given. The second is
how to learn diverse component classiﬁers given a method for learning a single
component classiﬁer. Finally, given multiple diverse component classiﬁers, we
must combine these properly into an overall classiﬁer for the object of interest.
In this work we present a uniﬁed and eﬀective solution to these challenges.
In order to learn component classiﬁers we turn to weakly supervised learning
methods developed for object detection, where positive training images contain
the object of interest, but, unlike the fully supervised case, the object location in
each image is unknown . Observe that learning a component classiﬁer
from images of objects where the components are in unspeciﬁed locations is an
analogous problem. Thus, we can use weakly supervised learning to learn a single
component classiﬁer; speciﬁcally we use multiple instance learning (mil) .
To learn a diverse collection of component classiﬁers we turn to boosting .
In boosting, multiple weak learners, each of which may have fairly high error, are
combined into a single strong classiﬁer with a low overall error. Weak classiﬁers
are trained sequentially with the weights of the training samples adjusted so that
incorrectly classiﬁed examples receive more weight. Boosting is ideally suited
both for learning diverse classiﬁers and combining them into an overall classiﬁer.
The key to our approach is that we use component classiﬁers, trained using
weakly supervised learning, as the weak classiﬁers in a boosting framework.
We refer to the individual constituent classiﬁers learned with weakly supervised learning as components rather than parts, as they need not always
P. Doll´ar, B. Babenko, S. Belongie, P. Perona, Z. Tu
Fig. 2. We model an image as a set or sequence of sets of patches. Left: A pedestrian
represented as a set of m densely sampled patches. A feature vector xij is computed
for each patch, forming a set Xi = {xi1, . . . , xim}. Right: Pedestrians have limited
articulation, so each component appears in a limited region of the image. Prior to
training, p overlapping regions are randomly generated (details in Sec. 4). For each
region we extract patches, generating an ordered sequence of sets Xi = [X1
i , . . . , Xp
correspond to semantically meaningful object parts (see Fig. 1). We name our
approach Multiple Component Learning (mcl) to emphasize that we learn a
classiﬁer composed of a number of constituent classiﬁers.
We begin by laying out the problem formulation and introducing some notation, followed by an overview of mil in Sec. 2.2. The foundation of our work
is in the development of a practical set classiﬁcation algorithm in Sec. 2.3.
Problem Formulation & Notation
We assume that the image of an object is composed of multiple components,
each of limited spatial extent, arranged in a particular pattern. For a given
object, only some of its components will be visible, and their position, scale,
rotation, etc. may vary. If a component is present and visible, there will be an
image patch that contains it; the challenge is that, a priori, it isn’t known which
patches contain relevant components.
We model an object as a collection of patches, or more formally as a set of
patches. To model spatial relationships, alongside the appearance of each patch
we keep track of its location (details discussed in Sec. 4). For objects with limited
articulation, each component can appear in a limited region of the image, and
it becomes useful to model the image as an ordered sequence of sets, one set for
each ﬁxed image region. See Fig. 2 for an illustration.
We now review the framework for standard discriminative learning, then
move on to discriminative learning for sets and sequences of sets. Formally, in
supervised learning data samples are represented by feature vectors from some
data space X, e.g. X = Rd. The goal is to learn a function f : X →Y, where
Y = {0, 1} in binary classiﬁcation. The learner is given a training data set
{(x1, y1) . . . , (xn, yn)}, where xi ∈X and yi ∈Y, and outputs a function f that
predicts the labels of novel data points.
Supervised learning for sets can be deﬁned in an analogous way. The training
data has the form {(X1, y1), . . . , (Xn, yn)}, where each Xi = {xi1, . . . , xim},
Multiple Component Learning for Object Detection
xij ∈X and yi ∈{0, 1}. We emphasize that the Xi are sets, i.e. the elements
of Xi are unordered, and we denote this by Xi ∈X m. Although mcl allows
for sets of varying cardinality, for notational simplicity we assume a ﬁxed size
m. The goal is to learn a function F : X m →{0, 1} that generalizes well to
unseen data. Technically speaking, set learning is a special case of supervised
learning with the data space being X m. For the case of sequences of sets, each
training instance Xi represents an ordered sequence of p (possibly overlapping)
sets Xi = [X1
i , . . . , Xp
i ], where Xk
i ∈X mk represents a set like before. The goal
is to learn a function F : [X m1, . . . , X mp] →{0, 1} that generalizes well.
Multiple Instance Learning
Here we give an overview of multiple instance learning (mil), which will serve
as the basis for learning a single component classiﬁer. In mil, training data is
given in sets, just as in mcl (in mil terminology ‘bag/instance’ are used in place
of ‘set/element’). Labels are deﬁned for instances, and a set is labeled positive
if any instance in the set is positive and negative otherwise. Using the notation
from above, a mil classiﬁer has the following form:
1 if ∃j s.t. f(xij) = 1
0 otherwise
The goal is to minimize the error of F on the training data. Note that F depends
entirely on the instance classiﬁer f : X →{0, 1}. Thus, although the training
data is given in sets X, the goal of mil is to learn a classiﬁer f that operates
on instances. F(Xi) is essentially the maximum of f(xij) over j. If f outputs a
probability or conﬁdence in , then we can deﬁne a ‘soft’ version of F:
ˆF(Xi) = softmaxj(f(xij)),
where ‘softmax’ is some diﬀerentiable real-valued approximation of the max over
 . We use the model of mil deﬁned in Equation (2) throughout this paper.
Note that mil can be considered a special case of set learning where the form
of F is restricted to the form given in Equation (1). We summarize the diﬀerence
between standard classiﬁcation, mil and mcl in Fig. 3.
The term mil was originally coined by Dietterich et al. in their study
of drug activity prediction, and in earlier work, Keeler et al. trained a
digit recognition system using unaligned image data. More recently, Viola et al.
 introduced a boosting variant of mil called mil-boost which is eﬀective
and robust. Throughout this work we use an extended version of mil-boost
described in . Some of these extensions are necessary for mcl, e.g. weighted
sets, others improve performance, e.g. the generalized mean softmax model.
MCL Derivation
We are now ready to present the details of mcl. Again, the idea is to use component classiﬁers, trained using mil, as the weak learners in a boosting framework.
P. Doll´ar, B. Babenko, S. Belongie, P. Perona, Z. Tu
Fig. 3. Three learning paradigms, and how each applies to object detection. Left:
Ground truth in supervised learning includes a label for each training instance. Middle: For mil, labels are given only for sets, where a set is positive if it contains at least
one positive instance, e.g. an image is labeled positive if the target object is present.
Like in the standard case, the goal is to learn a function f that classiﬁes instances.
Right: In mcl data is likewise given in sets, but the goal is to learn a set classiﬁer F.
Note that in this case X m represents a set of candidate component patches.
We begin with a brief review of AdaBoost . Given N labeled training
examples (xi, yi) with xi ∈X and yi ∈Y, and an initial distribution D1(i),
AdaBoost combines a number of weak classiﬁers ht to learn a strong classiﬁer
H(x) = sign(PT
t=1 αtht(x)). Here Y = {−1, 1}. Boosting has excellent generalization abilities and a strong theoretical foundation.
A close inspection of AdaBoost reveals that it makes no assumption about
the form of the input space X. The only requirement is that there exists a routine
for training a weak classiﬁer ht : X →{−1, 1} that has error less than 1
arbitrary weighing Dt of the training data. Therefore AdaBoost can be trained
on sets as long as the weak classiﬁers are suited for set classiﬁcation.
We use mil to train each weak classiﬁer, or component, inside the boosting
framework. Recall that mil, given input data organized in sets Xi ∈X m, learns
a function ˆF : X m → of the form ˆF(Xi) = softmaxj(f(xij)). It is possible,
using the extended version of mil-boost, to train ˆF using an arbitrary distribution over the training data . Inserting ˆF for h in AdaBoost, and adjusting
the form of the input data to be in sets, along with some other details, gives rise
to mcl-AdaBoost; see Fig. 4 for details.
Note that mil is asymmetric and only learns components from the positive
class; to also learn components from the negative class we can train mil with the
positive/negative labels swapped, and keep the better of the two components.
Derivation of mcl with other boosting algorithms, such as RealBoost or Gentle-
Boost , are similar to the derivation for mcl-AdaBoost. These require mil to
return real valued outputs, which is the case for mil-boost. In our experiments
Multiple Component Learning for Object Detection
Given: N labeled training examples (Xi, yi) with yi ∈{−1, 1} and Xi =
{xi1, . . . , xim}, and initial distr. of weights D1(i) =
N over the examples.
For t = 1, . . . , T:
• Train a mil classiﬁer ˆFt : X m → using distribution Dt. Let ˆF ′
(2 × 1[ ˆFt(Xi) > th] −1), where th = .5 or is chosen to minimize ϵt.
• Calculate error of ˆF ′
t : ϵt = PN
i=1 Dt(i)1(yi ̸= ˆF ′
• Set αt = −1
2 log (ϵt/(1 −ϵt)).
• Set Dt+1(i) = Dt(i) exp
−αtyi ˆF ′
where Zt = 2
ϵt(1 −ϵt) is a normalization factor.
Output the mcl classiﬁer:
F(X) = sign
Fig. 4. mcl-AdaBoost
mcl-RealBoost slightly outperforms mcl-AdaBoost; however, for simplicity we
chose to use mcl-AdaBoost (which we abbreviate to mcl).
If each input is a sequence of sets, a simple variation of mcl proves eﬀective.
The training examples have the form Xi = [X1
i , . . . , Xp
i ], where each Xk
set. During each phase of boosting, for each value of k < p, we train mil using
i . Of the p candidates trained this way, we keep the one with lowest error
and discard the rest. To make training more eﬃcient, T1 < p classiﬁers can be
selected instead. If T1 = T, the diversity of the components comes from training
each on diﬀerent data as opposed to the reweighing step of boosting; however,
boosting is still used to combine them. Details are omitted for space.
In the description of mcl given here, we assume that the input data has been
organized into sets or sequences of sets and that mil-boost is essentially a black
box. Given this, mcl, like AdaBoost, only requires one parameter, the number of
components T. In practice, we must also specify how to convert input data into
sets, and the parameters to use when training mil-boost, the most important
being the feature space to use and the number of weak classiﬁers for mil-boost.
Moreover, the features used to capture spatial relations must be speciﬁed. These
considerations are domain dependent, and we shall discuss them in more detail
in the experiments sections.
Theoretical Foundations of MCL
Set learning can be approached as classifying distributions, where the elements
of the set are observations sampled independently from an unknown density
function. Examples include using statistical tests on histograms of quantized
feature vectors to determine if two sets belong to the same distribution and
methods in computer audition that ﬁt Gaussian Mixture Models (GMM) to the
P. Doll´ar, B. Babenko, S. Belongie, P. Perona, Z. Tu
set distributions . Alternatively, sets can be viewed as collections of elements
where the order of the elements is unknown; however, an ordering is assumed to
exist and part of the challenge is to recover it. A good example of this style of approach is kernel methods that implicitly or explicitly try to ﬁnd correspondences
between elements .
Like many existing set learning algorithms, mcl assumes that an ordering of
the elements in a set exists but is not known. If the ordering was given during
training of mcl, the components could be learned using supervised learning as
opposed to weakly supervised learning (see Fig. 4). However, unlike existing set
learning algorithms, mcl does not require a distance measure between elements,
nor does it assume the elements are generated from a simple model. Instead,
learning occurs both at the instance level and at the set level. In this sense mcl
is fundamentally diﬀerent from existing work.
Here we give a more formal derivation of mcl. We begin by deﬁning the
problem of discriminative set classiﬁcation in a way that does not rely on any
assumptions at the instance level. The resulting formulation is intractable; however, imposing additional constraints leads to a more tractable approximation,
resulting in mcl. This derivation will make explicit the assumptions made by
mcl. It will help put mcl into context, and ﬁnally, it will allow us to explore
how at least some of these assumptions could be lifted in the future.
A note on notation: the uppercase script letters F, G refer to classiﬁers that
operate on sets X ∈X m and lowercase letters f, g refer to classiﬁers over instances x ∈X, where typically X = Rd. There exist multiple approaches to
learning instance classiﬁers, e.g. boosting, support vector machines, neural networks, etc. Here we describe set classiﬁers in terms of instance classiﬁers.
A set Xi = {xi1, . . . , xim} is unordered, so a set classiﬁer F(Xi) should not
depend on the indexing of the elements xij. Let [xij1, . . . , xijk] denote the object
obtained by stacking k elements in the set Xi in ﬁxed order j1, . . . , jk (with
possible repetitions and omissions). A general form for a set classiﬁer is:
1 if ∃j1, . . . , jk s.t. f([xij1, . . . , xijk]) = 1
0 otherwise
In other words Fk is deﬁned in terms of some instance classiﬁer f, such that
Fk(Xi) = 1 iﬀthere exists some ordering of the elements in Xi that satisﬁes
f([xij1, . . . , xijk]) = 1. Although fairly general, this form of Fk is not tractable
for large k as computing Fk(Xi) involves a search. In the worst case, evaluating
Fk(Xi) requires computing f over all mk orderings of Xi of length k.
A crucial observation is that training Fk reduces to training a mil classiﬁer.
For the case of k = 1 this reduction is direct since F1(X) ≡F(X), where
F(X) is the standard mil formulation given in Equation (1). Thus we can use
existing mil approaches to learn the instance classiﬁer f. The reduction to mil
for k > 1 is slightly more complex. Given a set X, we can exhaustively generate
a set X∗, where each element in X∗is created by concatenating k elements
xj1, . . . , xjk ∈X into the vector [xj1, . . . , xjk]. Close inspection of Equations (1)
and (3) shows that Fk(X) ≡F(X∗). Unfortunately this reduction is exponential
in k, since by construction X∗contains mk elements.
Multiple Component Learning for Object Detection
The smaller the value of k the more tractable learning and computing Fk
becomes, but also the less information Fk(Xi) can use about Xi. To compensate
for the loss of information from using small k, T diﬀerent classiﬁers Fk
combined using an instance classiﬁer g. Deﬁne Gk as follows:
1 (X), . . . , Fk
The formulation of set learning given in Equation (3) is strictly more general
than the form given in Equation (4); however, a potentially intractable search
has been replaced with T smaller ones. Computing Gk(X) is O(Tmk), which is
tractable for small k, and Gk can still depend on all elements in X regardless of
k. Equation (4) thus represents a reasonable model for a set classiﬁer.
mcl learns G1, with g being an additive model. Speciﬁcally, mil and AdaBoost are used to sequentially learn and combine F1
1, . . . , F1
T into an overall
set classiﬁer. We now consider the approximations used to operationalize Fk
into mcl. First, G is used as a tractable alternative to F. Additive models have
been shown to be robust and general , so their use for g is reasonable. With
appropriate choice of a mil training procedure, the components F1
i are chosen
from a rich hypothesis class and can thus be quite general. Perhaps the most
severe approximation is use of k = 1 since each component F1
i is limited to
depend on a single instance. Further experiments could reveal if this is limiting
in practice, e.g. for object detection. Assuming that m is not too large, deriving
mcl using k = 2 or 3 would be straightforward given the reduction of Fk to mil
described above; however, it is outside the scope of this work.
Experiments
We experiment with data coming from three domains: (1) handwriting identiﬁcation, (2) speaker identiﬁcation and (3) pedestrian detection. We compile
datasets for the ﬁrst two domains; for the third we use the INRIA pedestrian
dataset . Finally, we discuss the role of data alignment in Sec. 4.4.
The ﬁrst two experiments are meant to show the generality and power of
mcl. We compare to two representative approaches. The ﬁrst is AdaBoost 
applied to a standard, not set-based, representation of the data. AdaBoost has
access to identical features as mcl. We also compare to a simple bag of features
(bof) method: ﬁrst we use k-means to quantize the feature space (k chosen via
cross-validation), next we compute a k-bin histogram for each set, ﬁnally these
histograms are input into AdaBoost. Learning occurs at the set level but not at
the instance level (since the distances used for clustering are ﬁxed).
Handwriting Identiﬁcation
In the ﬁrst experiment we apply mcl to the oﬄine, text-independent handwriting identiﬁcation problem (recognizing the author by his/her handwriting) .
Intuitively, a person’s handwriting has a number of distinct features which are
independent of the actual text, hence a set representation is appropriate.
P. Doll´ar, B. Babenko, S. Belongie, P. Perona, Z. Tu
False Positive Rate
True Positive Rate
MCL−NOR (eer=0.060)
MCL−ISR (eer=0.107)
MCL−GM (eer=0.080)
BoF (eer=0.293)
Boost (eer=0.313)
# of components
Equal Error Rate (eer)
Fig. 5. Results for writer identiﬁcation, see text for details.
Our data consists of images of 4 pages of text handwritten by 2 people. Each
training example is a randomly sampled 70x50 window of text. For AdaBoost
and mcl we used Haar features ; for bof we use Euclidean distance on pixels
to perform clustering. For each training example, 25x25 patches were randomly
sampled to generate the sets. We trained mcl with three versions of mil-boost,
altering the softmax model (see Equation 2 and for details). mcl signiﬁcantly
outperforms both AdaBoost and bof. Results are shown in Fig. 5; the last plot
shows performance as a function of number of components T.
Speaker Identiﬁcation
False Positive Rate
True Positive Rate
MCL−NOR (eer=0.020)
MCL−ISR (eer=0.066)
MCL−GM (eer=0.014)
BoF (eer=0.046)
Boost (eer=0.343)
# of components
Equal Error Rate (eer)
Fig. 6. Results for speaker identiﬁcation, see text for details.
In this experiment our goal was to discriminate between the voices of John
Kerry and George W. Bush (speaker identiﬁcation is analogous to writer identi-
ﬁcation). We retrieved audio from a 2004 presidential debate1 and cropped out
roughly 6 minutes of each person speaking. The audio for each candidate was
parsed into 360 second length clips, a quarter of which were used for training.
We used MFCC features which are commonly used in speaker recognition
 . For AdaBoost one feature vector was generated per clip. For mcl and
bof, we generated a set representation of each clip by randomly sampling 78
1 Available publicly at 
Multiple Component Learning for Object Detection
short windows, and computed 30-dimensional MFCC features for each window.
AdaBoost performed very poorly (ROC curve is outside range of plot), while
mcl with two variations of mil-boost signiﬁcantly outperformed bof when
trained with enough components T. Results are shown in Fig. 6.
Pedestrian Detection
false positive per window (FPPW)
INRIA Results
Dalal&Triggs Ker. SVM
Dalal&Triggs Lin. SVM
Tuzel et. al.
false positive per window (FPPW)
Occlusion Results
SoftCasc Occ=NONE
SoftCasc Occ=30x30
SoftCasc Occ=45x45
MCL Occ=NONE
MCL Occ=30x30
MCL Occ=45x45
Fig. 7. Results on pedestrian detection. Left: mcl outperforms all reported results. At a
false positive per window rate (FPPW) of 10−4, a commonly used reference point, mcl
has a miss rate of ∼4%, compared to ∼7% for and ∼10% for . For comparison we
also implemented the SoftCascade approach described in , using the same candidate
Haar features we use in mcl. Consistent with previously reported results, a cascade of
Haars performs poorly. Right: Results on artiﬁcially generated occlusion. We overlaid
random 30x30 or 45x45 patches into random locations in the pedestrian test images.
We then regenerated the ROC curves for mcl as well as SoftCascade (which, like , is not part-based). mcl on data with 30x30 performs similarly to SoftCascade on
unoccluded data, and as the amount of occlusion increases, the gap between mcl and
SoftCascade further increases.
We now present results on the INRIA pedestrian dataset . A number of
recent methods have targeted this data , We compare our results to each,
using the training and evaluation methodology presented in , except to 
as it appears the results reported in that work are inaccurate2.
Here we provide details for training mcl on this dataset. Training windows
are 128x64, and for each of these we extract ∼4K overlapping patches. We compute ∼10K random Haar features per patch, using the original grayscale
image, as well as gradient magnitude and 6 channels of gradient quantized by
orientation. We use mil-boost with the generalized mean softmax model to select 256 stump classiﬁers. All 2416 positive sets and ∼10K negative sets are used
for training each mil. We use the sequence of sets version of mcl (see Fig. 2).
2 See 
P. Doll´ar, B. Babenko, S. Belongie, P. Perona, Z. Tu
Initially 50 binary masks in the shape of ellipses are randomly generated, and
one mil classiﬁer is trained per mask, using sets generated from patches only in
the masked region. The original binary masks are random and likely suboptimal;
after training each mil, we compute a new mask based on the mil probability
response images on the training positives and then retrain. This mask reﬁnement
step improves results. From among the 50 mil candidate classiﬁers, AdaBoost is
used to select the 20 best components. Next, we bootstrap ∼10K new negative
windows from the training images from the false positives reported by mcl. The
entire process is repeated 4 times to form a cascade. Our ﬁnal mcl classiﬁer is
composed of 80 components (selected from 200 candidates).
We present a simple yet powerful method of incorporating spatial information into our mcl classiﬁer. First, we compute the responses of the component
classiﬁer on the training images, giving one 128x64 probability map per training
image for each component. Then, instead of using F (the max response over the
set) as the weak classiﬁer to AdaBoost, we use Haar features computed over these
probability maps. Intuitively, single rectangle Haars capture absolute component
location, multiple rectangle Haars capture relative component locations. Using
these features, AdaBoost automatically learns the spatial relationships governing the components; no parameters need to be set in an ad-hoc manner. Using
spatial information instead of the max was important for obtaining good results.
Training takes 2 weeks on a modern PC (majority of time is spent in milboost training). Our classiﬁer is composed of ∼20K Haar features (256 per mil),
compared to ∼6K in the Viola & Jones real-time face detector ; however, they
are organized into multiple shallow cascades as opposed to a single deep cascade,
so evaluation is slower. Simple feature sharing strategies should increase speed
by an order of magnitude, reducing evaluation time to a few seconds per image.
The ﬁrst ﬁve learned components are shown in Fig. 1. ROC curves comparing
our method with Dalal and Triggs and Tuzel et al. are shown in Fig. 7, left.
Part-based approaches have a natural advantage when occlusions are present.
We show the robustness of mcl to occlusions in Fig. 7, right.
Role of Data Alignment
false positive per window (FPPW)
foot detector
false positive per window (FPPW)
head detector
Fig. 8. Eﬀects of alignment on training part classiﬁers, see text for details.
Multiple Component Learning for Object Detection
We perform a ﬁnal experiment to show that using aligned data results in
higher accuracy (part) classiﬁers. Note that simultaneous alignment of articulated objects is often impossible without relying on a part-based model.
We labeled the head and feet in the 2416 INRIA training pedestrians. For
each part, we trained a classiﬁer using patches sampled from each pedestrian in 1
of 3 ways: at the labeled part location, at the mean part location, and in a region
around the mean part location (mil). We used AdaBoost for the ﬁrst two cases
and the extended version of mil-boost for the third, using 256 Haars selected
from an identical pool in each case. During testing, we applied each classiﬁer to
a region around the mean part location and recorded the maximum probability.
Results against bootstrapped negatives are shown in Fig. 8. Not surprisingly,
labeled outperformed mean, showing alignment is beneﬁcial. Additionally, mean
performed better when we took the max probability over the region during testing rather than rely on the probability at the mean part location (mean*). Also,
consistent with the ﬁndings of , mil outperformed labeled even though it was
trained in a weakly supervised manner (presumably our labeling is imperfect).
Together, these results make a strong case that data alignment is highly
beneﬁcial. As articulated objects typically cannot be fully aligned everywhere,
mcl has an inherent advantage over methods that are not part-based.
Conclusion & Future Work
In this paper we presented a part-based object detection system called Multiple
Component Learning (mcl). mcl combines elements of patch-based recognition
and discriminative detection techniques to produce a high accuracy object detector that works well for articulated objects and is robust to occlusion. Unlike
previous approaches, mcl learns powerful component classiﬁers without labeled
part data. We showed results on data from computer vision and computer audition, including state of the art results in pedestrian detection.
In future work we plan on speeding up mcl, and seeing if tradeoﬀs in accuracy
are necessary to achieve near real-time speeds. Additionally, results could be
further improved by adapting mil-boost to better suit the needs of mcl.
Acknowledgments
PD and BB were funded by NSF IGERT Grant DGE-0333451. SB was funded by NSF
Career Grant #0448615 and the Alfred P. Sloan Research Fellowship. ZT was funded
by NIH Grant U54RR021813 entitled Center for Computational Biology.