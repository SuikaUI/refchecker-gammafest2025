Model Selection and Multimodel Inference
Second Edition
Heidelberg
Kenneth P. Burnham
David R. Anderson
Model Selection and
Multimodel Inference
A Practical Information-Theoretic Approach
Second Edition
With 31 Illustrations
Kenneth P. Burnham
David R. Anderson
Colorado Cooperative Fish
and Wildlife Research Unit
Colorado State University
Fort Collins, CO 80523-1484
Cover Illustration: The cover was assembled from photos of the yellow-bellied toad (Bombina variegata) taken by Jonas Barandum as part of his Ph.D. program at the University of Zurich. These toads
have individually identiﬁable patterns on their abdomen from a few weeks following metamorphosis
that remain unchanged until death. Two pairs are duplicates—but which two?
Cover photographs by Dr. Jonas Barandum, St. Gallen, Switzerland. Cover design by Kenton Allred.
Library of Congress Cataloging-in-Publication Data
Burnham, Kenneth P.
Model selection and multimodel inference : a practical information-theoretic approach
/ Kenneth P. Burnham, David R. Anderson.—2nd ed.
Rev. ed. of: Model selection and inference. © 1998.
Includes bibliographical references (p. ).
ISBN 0-387-95364-7 (alk. paper)
1. Biology—Mathematical models.
2. Mathematical statistics.
I. Burnham, Kenneth P.
Model selection and inference.
II. Title.
570′.1′51—dc21
2001057677
ISBN 0-387-95364-7
Printed on acid-free paper.
© 2002, 1998 Springer-Verlag New York, Inc.
All rights reserved. This work may not be translated or copied in whole or in part without the written
permission of the publisher (Springer-Verlag New York, Inc., 175 Fifth Avenue, New York, NY 10010,
USA), except for brief excerpts in connection with reviews or scholarly analysis. Use in connection
with any form of information storage and retrieval, electronic adaptation, computer software, or by
similar or dissimilar methodology now known or hereafter developed is forbidden.
The use in this publication of trade names, trademarks, service marks, and similar terms, even if they
are not identiﬁed as such, is not to be taken as an expression of opinion as to whether or not they are
subject to proprietary rights.
Printed in the United States of America.
9 8 7 6 5 4 3 2
SPIN 10853081
www.springer-ny.com
Springer-Verlag
New York Berlin Heidelberg
A member of BertelsmannSpringer Science+Business Media GmbH
To my mother and father, Lucille R. (deceased) and J. Calvin Burnham
(deceased), and my son and daughter, Shawn P. and Sally A. Burnham
To my parents, Charles R. (deceased) and Leta M. Anderson; my wife,
Dalene F. Anderson; and my daughters, Tamara E. and
Adrienne M. Anderson
We wrote this book to introduce graduate students and research workers in
various scientiﬁc disciplines to the use of information-theoretic approaches in
the analysis of empirical data. These methods allow the data-based selection
of a “best” model and a ranking and weighting of the remaining models in
a pre-deﬁned set. Traditional statistical inference can then be based on this
selected best model. However, we now emphasize that information-theoretic
approaches allow formal inference to be based on more than one model (multimodel inference). Such procedures lead to more robust inferences in many
cases, and we advocate these approaches throughout the book.
The second edition was prepared with three goals in mind. First, we have
tried to improve the presentation of the material. Boxes now highlight essential expressions and points. Some reorganization has been done to improve the
ﬂow of concepts, and a new chapter has been added. Chapters 2 and 4 have
been streamlined in view of the detailed theory provided in Chapter 7. Second, concepts related to making formal inferences from more than one model
(multimodel inference) have been emphasized throughout the book, but particularly in Chapters 4, 5, and 6. Third, new technical material has been added
to Chapters 5 and 6. Well over 100 new references to the technical literature
are given. These changes result primarily from our experiences while giving
several seminars, workshops, and graduate courses on material in the ﬁrst edition. In addition, we have done substantially more thinking about the issue and
reading the literature since writing the ﬁrst edition, and these activities have
led to further insights.
Information theory includes the celebrated Kullback–Leibler “distance” between two models (actually, probability distributions), and this represents a
fundamental quantity in science. In 1973, Hirotugu Akaike derived an estimator of the (relative) expectation of Kullback–Leibler distance based on Fisher’s
maximized log-likelihood. His measure, now called Akaike’s information criterion (AIC), provided a new paradigm for model selection in the analysis of
empirical data. His approach, with a fundamental link to information theory,
is relatively simple and easy to use in practice, but little taught in statistics
classes and far less understood in the applied sciences than should be the case.
We do not accept the notion that there is a simple “true model” in the biological sciences. Instead, we view modeling as an exercise in the approximation
of the explainable information in the empirical data, in the context of the data
being a sample from some well-deﬁned population or process. Rexstad 
views modeling as a fabric in the tapestry of science. Selection of a best approximating model represents the inference from the data and tells us what
“effects” (represented by parameters) can be supported by the data. We focus
on Akaike’s information criterion (and various extensions) for selection of a
parsimonious model as a basis for statistical inference. Model selection based
on information theory represents a quite different approach in the statistical
sciences, and the resulting selected model may differ substantially from model
selection based on some form of statistical null hypothesis testing.
We recommend the information-theoretic approach for the analysis of data
from observational studies. In this broad class of studies, we ﬁnd that all the various hypothesis-testing approaches have no theoretical justiﬁcation and may
often perform poorly. For classic experiments (control–treatment, with randomization and replication) we generally support the traditional approaches
(e.g., analysis of variance); there is a very large literature on this classic subject.
However, for complex experiments we suggest consideration of ﬁtting explanatory models, hence on estimation of the size and precision of the treatment
effects and on parsimony, with far less emphasis on “tests” of null hypotheses, leading to the arbitrary classiﬁcation “signiﬁcant” versus “not signiﬁcant.”
Instead, a strength of evidence approach is advocated.
We do not claim that the information-theoretic methods are always the very
best for a particular situation. They do represent a uniﬁed and rigorous theory,
an extension of likelihood theory, an important application of information
theory,andtheyareobjectiveandpracticaltoemployacrossaverywideclassof
empiricalproblems.Inferencefrommultiplemodels,ortheselectionofasingle
“best” model, by methods based on the Kullback–Leibler distance are almost
certainly better than other methods commonly in use now (e.g., null hypothesis
testing of various sorts, the use of R2, or merely the use of just one available
model). In particular, subjective data dredging leads to overﬁtted models and
the attendant problems in inference, and is to be strongly discouraged, at least
in more conﬁrmatory studies.
Parameter estimation has been viewed as an optimization problem for at
least eight decades (e.g., maximize the log-likelihood or minimize the residual
sum of squared deviations). Akaike viewed his AIC and model selection as
“. . . a natural extension of the classical maximum likelihood principle.” This
extension brings model selection and parameter estimation under a common
framework—optimization. However, the paradigm described in this book goes
beyond merely the computation and interpretation of AIC to select a parsimonious model for inference from empirical data; it refocuses increased attention
on a variety of considerations and modeling prior to the actual analysis of data.
Model selection, under the information-theoretic approach presented here, attempts to identify the (likely) best model, orders the models from best to
worst, and produces a weight of evidence that each model is really the best as
an inference.
Several methods are given that allow model selection uncertainty to be incorporated into estimates of precision (i.e., multimodel inference). Our intention
is to present and illustrate a consistent methodology that treats model formulation, model selection, estimation of model parameters and their uncertainty
in a uniﬁed manner, under a compelling common framework. We review and
explain other information criteria (e.g., AICc, QAICc, and TIC) and present
several examples to illustrate various technical issues, including some comparisons with BIC, a type of dimension consistent criterion. In addition, we
provide many references to the technical literature for those wishing to read
further on these topics.
This is an applied book written primarily for biologists and statisticians
using models for making inferences from empirical data. This is primarily a
science book; we say relatively little about decision making in management or
management science. Research biologists working either in the ﬁeld or in the
laboratory will ﬁnd simple methods that are likely to be useful in their investigations. Researchers in other life sciences, econometrics, the social sciences,
and medicine might also ﬁnd the material useful but will have to deal with
examples that have been taken largely from ecological studies of free-ranging
vertebrates, as these are our interests. Applied statisticians might consider the
information-theoretic methods presented here quite useful and a superior alternative to the null hypothesis testing approach that has become so tortuous and
uninformative. We hope material such as this will ﬁnd its way into classrooms
where applied data analysis and associated science philosophy are taught. This
book might be useful as a text for a course for students with substantial experience and education in statistics and applied data analysis. A second primary
audience includes honors or graduate students in the biological, medical, or
statistical sciences. Those interested in the empirical sciences will ﬁnd this material useful because it offers an effective alternative to (1) the widely taught,
yet often both complex and uninformative, null hypothesis testing approaches
and (2) the far less taught, but potentially very useful, Bayesian approaches.
Readers should ideally have some maturity in the quantitative sciences and
experience in data analysis. Several courses in contemporary statistical theory
and methods as well as some philosophy of science would be particularly useful in understanding the material. Some exposure to likelihood theory is nearly
essential, but those with experience only in least squares regression modeling
will gain some useful insights. Biologists working in a team situation with
someone in the quantitative sciences might also ﬁnd the material to be useful. The book is meant to be relatively easy to read and understand, but the
conceptual issues may preclude beginners. Chapters 1–4 are recommended for
all readers because they provide the essential material, including concepts of
multimodel inference. Chapters 5 and 6 present more difﬁcult material and
some new research results. Few readers will be able to absorb the concepts
presented here after just one reading of the material; some rereading and additional consideration will often be necessary to understand the deeper points.
Underlying theory is presented in Chapter 7, and this material is much deeper
and more mathematical. A high-level summary of the main points of the book
is provided in Chapter 8.
We intend to remain active in this subject area after this second edition has
been published, and we invite comments from colleagues as an ideal way to
learn more and understand differing points of view. We hope that the text does
not appear too dogmatic or idealized. We have tried to synthesize concepts that
we believe are important and incorporate these as recommendations or advice
in several of the chapters. This book is an effort to explore the K-L–based
multimodel inference in some depth. We realize that there are other approaches,
and that some people may still wish to test null hypotheses as the basis for
building models of empirical data, and that others may have a more lenient
attitude toward data dredging than we advocate here. We do not want to deny
other model selection methods, such as cross-validation, nor deny the value
of Bayesian methods. Indeed, we just learned that AIC can be
derived as a Bayesian result and have added a note on this issue while reviewing
the ﬁnal page proofs (see Section 6.4.5). However, in the context of objective
science,wearecompelledbytheaprioriapproachofbuildingcandidatemodels
to represent research hypotheses, the use of information-theoretic criteria as
a basis for selecting a best approximating model; model averaging, or other
multimodel inference methods, when truth is surely very complex; the use of
likelihood theory for deriving parameter estimators; and incorporating model
selection uncertainty into statistical inferences. In particular, we recommend
moving beyond mere selection of a single best model by using concepts and
methods of multimodel inference.
Several people have helped us as we prepared the two editions of this book.
In particular, we acknowledge C. Chatﬁeld, C. Hurvich, B. Morgan, D. Otis,
J. Rotella, R. Shibata, and K. Wilson for comments on earlier drafts of the
original manuscript. We are grateful to three anonymous reviewers for comments that allowed us to improve the ﬁrst edition. D. Otis and W. Thompson
served as the reviewers for the second edition and offered many suggestions
that were helpful; we greatly appreciate their excellent suggestions. Early discussions with S. Buckland, R. Davis, R. Shibata, and G. White were very
useful. S. Beck, K. Bestgen, D. Beyers, L. Ellison, A. Franklin, W. Gasaway,
B. Lubow, C. McCarty, M. Miller, and T. Shenk provided comments and insights as part of a graduate course on model selection methods that they took
from the authors. C. Flather allowed us to use his data on species accumu-
lation curves as our ﬁrst example, and we thank C. Braun and the Colorado
Division of Wildlife for the data on sage grouse; these data were analyzed
by M. Zablan under the supervision of G. White. C. Southwell allowed us to
use his kangaroo data from Wallaby Creek. P. Lukacs conducted the bootstrap
analysis and some of the Monte Carlo studies of the body fat data in Chapter 5.
J. Kullback allowed us to use a photo of his father, and H. Akaike, R. Leibler,
R. Shibata, and K. Takeuchi kindly sent us photos and biographical material
that appear in the book. Chelsea Publishing Company allowed our use of the
photo of L. Boltzmann from the book Wissenschaftliche Abhandlungen von
Ludwig Boltzmann, and the International Biometric Society authorized our
use of a photo of R. Fisher . J. Barandun provided the toad photos for the cover, K. Allred provided
the cover design, and B. Schmidt helped in coordination. C. Dion, R. Fulton,
S. Kane, B. Klein, A. Lyman, and T. Sundlov helped obtain library materials.
J. Kimmel and L. Farkas helped in countless ways as we prepared both editions
of this book.
We are happy to acknowledge the long-term cooperators of the Colorado Cooperative Fish and Wildlife Research Unit: the Colorado Division of Wildlife,
Colorado State University, the Biological Resources Division of the U.S. Geological Survey, and the Wildlife Management Institute. Graduate students and
faculty within the Department of Fisheries and Wildlife Biology at Colorado
State University provided a forum for our interests in the analysis of empirical data. We extend our appreciation to several federal agencies within the
Department of the Interior, particularly the U.S. Geological Survey, for their
support of our long-term research interests.
Fort Collins, Colorado
Kenneth P. Burnham
David R. Anderson
January 2002
About the Authors
Introduction
Objectives of the Book
. . . . . . . . . . . . . . . . . . .
Background Material
. . . . . . . . . . . . . . . . . . . .
Inference from Data, Given a Model . . . . . . . .
Likelihood and Least Squares Theory
. . . . . . .
The Critical Issue: “What Is the Best Model
to Use?” . . . . . . . . . . . . . . . . . . . . . . .
Science Inputs: Formulation of the Set of
Candidate Models . . . . . . . . . . . . . . . . . .
Models Versus Full Reality . . . . . . . . . . . . .
An Ideal Approximating Model . . . . . . . . . . .
Model Fundamentals and Notation . . . . . . . . . . . . .
Truth or Full Reality f
. . . . . . . . . . . . . . .
Approximating Models gi(x|θ) . . . . . . . . . . .
The Kullback–Leibler Best Model gi(x|θ0) . . . . .
Estimated Models gi(x| ˆθ) . . . . . . . . . . . . . .
Generating Models
. . . . . . . . . . . . . . . . .
Global Model . . . . . . . . . . . . . . . . . . . .
Overview of Stochastic Models in the
Biological Sciences . . . . . . . . . . . . . . . . .
Inference and the Principle of Parsimony . . . . . . . . . .
Avoid Overﬁtting to Achieve a Good Model Fit . .
The Principle of Parsimony . . . . . . . . . . . . .
Model Selection Methods . . . . . . . . . . . . . .
Data Dredging, Overanalysis of Data, and
Spurious Effects . . . . . . . . . . . . . . . . . . . . . . .
Overanalysis of Data
. . . . . . . . . . . . . . . .
Some Trends
. . . . . . . . . . . . . . . . . . . .
Model Selection Bias
. . . . . . . . . . . . . . . . . . . .
Model Selection Uncertainty
. . . . . . . . . . . . . . . .
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . .
Information and Likelihood Theory: A Basis for Model
Selection and Inference
Kullback–Leibler Information or Distance Between
Two Models . . . . . . . . . . . . . . . . . . . . . . . . .
Examples of Kullback–Leibler Distance . . . . . .
Truth, f , Drops Out as a Constant
. . . . . . . . .
Akaike’s Information Criterion: 1973 . . . . . . . . . . . .
Takeuchi’s Information Criterion: 1976 . . . . . . . . . . .
Second-Order Information Criterion: 1978 . . . . . . . . .
Modiﬁcation of Information Criterion for Overdispersed
Count Data . . . . . . . . . . . . . . . . . . . . . . . . . .
AIC Differences, i . . . . . . . . . . . . . . . . . . . . .
A Useful Analogy . . . . . . . . . . . . . . . . . . . . . .
Likelihood of a Model, L(gi|data)
. . . . . . . . . . . . .
Akaike Weights, wi
. . . . . . . . . . . . . . . . . . . . .
Basic Formula . . . . . . . . . . . . . . . . . . . .
An Extension . . . . . . . . . . . . . . . . . . . .
Evidence Ratios . . . . . . . . . . . . . . . . . . . . . . .
Important Analysis Details
. . . . . . . . . . . . . . . . .
2.11.1 AIC Cannot Be Used to Compare Models of
Different Data Sets
. . . . . . . . . . . . . . . . .
2.11.2 Order Not Important in Computing AIC Values
2.11.3 Transformations of the Response Variable . . . . .
2.11.4 Regression Models with Differing
Error Structures . . . . . . . . . . . . . . . . . . .
2.11.5 Do Not Mix Null Hypothesis Testing with
Information-Theoretic Criteria . . . . . . . . . . .
2.11.6 Null Hypothesis Testing Is Still Important in
Strict Experiments . . . . . . . . . . . . . . . . . .
2.11.7 Information-Theoretic Criteria Are Not a “Test” . .
2.11.8 Exploratory Data Analysis
. . . . . . . . . . . . .
Some History and Further Insights
. . . . . . . . . . . . .
2.12.1 Entropy . . . . . . . . . . . . . . . . . . . . . . .
2.12.2 A Heuristic Interpretation . . . . . . . . . . . . . .
2.12.3 More on Interpreting Information-
Theoretic Criteria . . . . . . . . . . . . . . . . . .
2.12.4 Nonnested Models
. . . . . . . . . . . . . . . . .
2.12.5 Further Insights . . . . . . . . . . . . . . . . . . .
Bootstrap Methods and Model Selection Frequencies πi . .
2.13.1 Introduction . . . . . . . . . . . . . . . . . . . . .
2.13.2 The Bootstrap in Model Selection:
The Basic Idea . . . . . . . . . . . . . . . . . . . .
Return to Flather’s Models
. . . . . . . . . . . . . . . . .
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . .
Basic Use of the Information-Theoretic Approach
Introduction . . . . . . . . . . . . . . . . . . . . . . . . .
Example 1: Cement Hardening Data
. . . . . . . . . . . .
Set of Candidate Models
. . . . . . . . . . . . . .
Some Results and Comparisons . . . . . . . . . . .
A Summary . . . . . . . . . . . . . . . . . . . . .
Example 2: Time Distribution of an Insecticide Added to a
Simulated Ecosystem
. . . . . . . . . . . . . . . . . . . .
Set of Candidate Models
. . . . . . . . . . . . . .
Some Results . . . . . . . . . . . . . . . . . . . .
Example 3: Nestling Starlings . . . . . . . . . . . . . . . .
Experimental Scenario
. . . . . . . . . . . . . . .
Monte Carlo Data . . . . . . . . . . . . . . . . . .
Set of Candidate Models
. . . . . . . . . . . . . .
Data Analysis Results . . . . . . . . . . . . . . . .
Further Insights into the First Fourteen
Nested Models
. . . . . . . . . . . . . . . . . . .
Hypothesis Testing and Information-Theoretic
Approaches Have Different
Selection Frequencies . . . . . . . . . . . . . . . .
Further Insights Following Final
Model Selection . . . . . . . . . . . . . . . . . . .
Why Not Always Use the Global Model
for Inference? . . . . . . . . . . . . . . . . . . . .
Example 4: Sage Grouse Survival . . . . . . . . . . . . . .
Introduction . . . . . . . . . . . . . . . . . . . . .
Set of Candidate Models
. . . . . . . . . . . . . .
Model Selection . . . . . . . . . . . . . . . . . . .
Hypothesis Tests for Year-Dependent
Survival Probabilities . . . . . . . . . . . . . . . .
Hypothesis Testing Versus AIC in
Model Selection . . . . . . . . . . . . . . . . . . .
A Class of Intermediate Models
. . . . . . . . . .
Example 5: Resource Utilization of Anolis Lizards . . . . .
Set of Candidate Models
. . . . . . . . . . . . . .
Comments on Analytic Method . . . . . . . . . . .
Some Tentative Results . . . . . . . . . . . . . . .
Example 6: Sakamoto et al.’s Simulated Data . . . .
Example 7: Models of Fish Growth . . . . . . . . . . . . .
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . .
Formal Inference From More Than One Model:
Multimodel Inference (MMI)
Introduction to Multimodel Inference . . . . . . . . . . . .
Model Averaging
. . . . . . . . . . . . . . . . . . . . . .
Prediction . . . . . . . . . . . . . . . . . . . . . .
Averaging Across Model Parameters . . . . . . . .
Model Selection Uncertainty
. . . . . . . . . . . . . . . .
Concepts of Parameter Estimation and
Model Selection Uncertainty . . . . . . . . . . . .
Including Model Selection Uncertainty in
Estimator Sampling Variance . . . . . . . . . . . .
Unconditional Conﬁdence Intervals
. . . . . . . .
Estimating the Relative Importance of Variables . . . . . .
Conﬁdence Set for the K-L Best Model . . . . . . . . . . .
Introduction . . . . . . . . . . . . . . . . . . . . .
i, Model Selection Probabilities,
and the Bootstrap . . . . . . . . . . . . . . . . . .
Model Redundancy
. . . . . . . . . . . . . . . . . . . . .
Recommendations . . . . . . . . . . . . . . . . . . . . . .
Cement Data . . . . . . . . . . . . . . . . . . . . . . . . .
Pine Wood Data . . . . . . . . . . . . . . . . . . . . . . .
The Durban Storm Data . . . . . . . . . . . . . . . . . . .
4.10.1 Models Considered . . . . . . . . . . . . . . . . .
4.10.2 Consideration of Model Fit . . . . . . . . . . . . .
4.10.3 Conﬁdence Intervals on Predicted
Storm Probability . . . . . . . . . . . . . . . . . .
4.10.4 Comparisons of Estimator Precision . . . . . . . .
Flour Beetle Mortality: A Logistic Regression Example . .
Publication of Research Results . . . . . . . . . . . . . . .
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . .
Monte Carlo Insights and Extended Examples
Introduction . . . . . . . . . . . . . . . . . . . . . . . . .
Survival Models . . . . . . . . . . . . . . . . . . . . . . .
A Chain Binomial Survival Model . . . . . . . . .
An Example . . . . . . . . . . . . . . . . . . . . .
An Extended Survival Model . . . . . . . . . . . .
Model Selection if Sample Size Is Huge,
or Truth Known . . . . . . . . . . . . . . . . . . .
A Further Chain Binomial Model . . . . . . . . . .
Examples and Ideas Illustrated with Linear Regression . . .
All-Subsets Selection: A GPA Example
. . . . . .
A Monte Carlo Extension of the GPA Example
An Improved Set of GPA Prediction Models . . . .
More Monte Carlo Results
. . . . . . . . . . . . .
Linear Regression and Variable Selection
Discussion . . . . . . . . . . . . . . . . . . . . . .
Estimation of Density from Line Transect Sampling . . . .
Density Estimation Background
. . . . . . . . . .
Line Transect Sampling of Kangaroos at
Wallaby Creek . . . . . . . . . . . . . . . . . . . .
Analysis of Wallaby Creek Data
. . . . . . . . . .
Bootstrap Analysis
. . . . . . . . . . . . . . . . .
Conﬁdence Interval on D . . . . . . . . . . . . . .
Bootstrap Samples: 1,000 Versus 10,000 . . . . . .
Bootstrap Versus Akaike Weights: A Lesson
on QAICc . . . . . . . . . . . . . . . . . . . . . .
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . .
Advanced Issues and Deeper Insights
Introduction . . . . . . . . . . . . . . . . . . . . . . . . .
An Example with 13 Predictor Variables and
8,191 Models
. . . . . . . . . . . . . . . . . . . . . . . .
Body Fat Data . . . . . . . . . . . . . . . . . . . .
The Global Model . . . . . . . . . . . . . . . . . .
Classical Stepwise Selection
. . . . . . . . . . . .
Model Selection Uncertainty for AICc and BIC
An A Priori Approach . . . . . . . . . . . . . . . .
Bootstrap Evaluation of Model Uncertainty
Monte Carlo Simulations . . . . . . . . . . . . . .
Summary Messages . . . . . . . . . . . . . . . . .
Overview of Model Selection Criteria . . . . . . . . . . . .
Criteria That Are Estimates of K-L Information . .
Criteria That Are Consistent for K . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . .
Consistent Selection in Practice:
Quasi-true Models . . . . . . . . . . . . . . . . . .
Contrasting AIC and BIC . . . . . . . . . . . . . . . . . .
A Heuristic Derivation of BIC
. . . . . . . . . . .
A K-L-Based Conceptual Comparison of
AIC and BIC
. . . . . . . . . . . . . . . . . . . .
Performance Comparison . . . . . . . . . . . . . .
Exact Bayesian Model Selection Formulas . . . . .
Akaike Weights as Bayesian Posterior
Model Probabilities . . . . . . . . . . . . . . . . .
Goodness-of-Fit and Overdispersion Revisited . . . . . . .
Overdispersion ˆc and Goodness-of-Fit:
A General Strategy . . . . . . . . . . . . . . . . .
Overdispersion Modeling: More Than One ˆc . . . .
Model Goodness-of-Fit After Selection . . . . . . .
AIC and Random Coefﬁcient Models . . . . . . . . . . . .
Basic Concepts and Marginal
Likelihood Approach . . . . . . . . . . . . . . . .
A Shrinkage Approach to AIC and
Random Effects . . . . . . . . . . . . . . . . . . .
On Extensions . . . . . . . . . . . . . . . . . . . .
Selection When Probability Distributions Differ
by Model . . . . . . . . . . . . . . . . . . . . . . . . . . .
Keep All the Parts . . . . . . . . . . . . . . . . . .
A Normal Versus Log-Normal Example . . . . . .
Comparing Across Several Distributions:
An Example . . . . . . . . . . . . . . . . . . . . .
Lessons from the Literature and Other Matters . . . . . . .
Use AICc, Not AIC, with Small Sample Sizes . . .
Use AICc, Not AIC, When K Is Large . . . . . . .
When Is AICc Suitable: A Gamma
Distribution Example . . . . . . . . . . . . . . . .
Inference from a Less Than Best Model
. . . . . .
Are Parameters Real? . . . . . . . . . . . . . . . .
Sample Size Is Often Not a Simple Issue . . . . . .
Judgment Has a Role . . . . . . . . . . . . . . . .
Tidbits About AIC . . . . . . . . . . . . . . . . . . . . . .
Irrelevance of Between-Sample Variation
of AIC . . . . . . . . . . . . . . . . . . . . . . . .
The G-Statistic and K-L Information . . . . . . . .
AIC Versus Hypothesis Testing: Results Can Be
Very Different . . . . . . . . . . . . . . . . . . . .
A Subtle Model Selection Bias Issue . . . . . . . .
The Dimensional Unit of AIC . . . . . . . . . . . .
AIC and Finite Mixture Models . . . . . . . . . . .
Unconditional Variance . . . . . . . . . . . . . . .
A Baseline for w+(i)
. . . . . . . . . . . . . . . .
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . .
Statistical Theory and Numerical Results
Useful Preliminaries . . . . . . . . . . . . . . . . . . . . .
A General Derivation of AIC . . . . . . . . . . . . . . . .
General K-L–Based Model Selection: TIC . . . . . . . . .
Analytical Computation of TIC . . . . . . . . . . .
Bootstrap Estimation of TIC
. . . . . . . . . . . .
AICc: A Second-Order Improvement . . . . . . . . . . . .
Derivation of AICc
. . . . . . . . . . . . . . . . .
Lack of Uniqueness of AICc
. . . . . . . . . . . .
Derivation of AIC for the Exponential Family
of Distributions
. . . . . . . . . . . . . . . . . . . . . . .
Evaluation of tr(J(θ o)[I(θ o)]−1) and Its Estimator . . . . .
Comparison of AIC Versus TIC in a
Very Simple Setting . . . . . . . . . . . . . . . . .
Evaluation Under Logistic Regression . . . . . . .
Evaluation Under Multinomially Distributed
Count Data
. . . . . . . . . . . . . . . . . . . . .
Evaluation Under Poisson-Distributed Data
Evaluation for Fixed-Effects Normality-Based
Linear Models . . . . . . . . . . . . . . . . . . . .
Additional Results and Considerations . . . . . . . . . . .
Selection Simulation for Nested Models . . . . . .
Simulation of the Distribution of p . . . . . . . .
Does AIC Overﬁt?
. . . . . . . . . . . . . . . . .
Can Selection Be Improved Based on
All the i?
. . . . . . . . . . . . . . . . . . . . .
Linear Regression, AIC, and Mean Square Error . .
AICc and Models for Multivariate Data . . . . . . .
There Is No True TICc
. . . . . . . . . . . . . . .
Kullback–Leibler Information Relationship to the
Fisher Information Matrix . . . . . . . . . . . . . .
Entropy and Jaynes Maxent Principle . . . . . . . .
7.7.10 Akaike Weights wi Versus Selection
Probabilities πi
. . . . . . . . . . . . . . . . . . .
Kullback–Leibler Information Is Always ≥0 . . . . . . . .
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . .
The Scientiﬁc Question and the Collection of Data . . . . .
Actual Thinking and A Priori Modeling . . . . . . . . . . .
The Basis for Objective Model Selection . . . . . . . . . .
The Principle of Parsimony . . . . . . . . . . . . . . . . .
Information Criteria as Estimates of Expected Relative
Kullback–Leibler Information . . . . . . . . . . . . . . . .
Ranking Alternative Models . . . . . . . . . . . . . . . . .
Scaling Alternative Models . . . . . . . . . . . . . . . . .
MMI: Inference Based on Model Averaging
. . . . . . . .
MMI: Model Selection Uncertainty . . . . . . . . . . . . .
MMI: Relative Importance of Predictor Variables
More on Inferences
. . . . . . . . . . . . . . . . . . . . .
Final Thoughts . . . . . . . . . . . . . . . . . . . . . . . .