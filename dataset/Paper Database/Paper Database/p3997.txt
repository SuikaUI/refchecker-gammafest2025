Towards Using Unlabeled Data in a Sparse-coding
Framework for Human Activity Recognition
Sourav Bhattacharyaa, Petteri Nurmia, Nils Hammerlab, and Thomas Plötzb
aHelsinki Institute for Information Technology HIIT, Department of Computer
Science, University of Helsinki, Finland
bCulture Lab, School of Computing Science, Newcastle University, UK
“NOTICE: this is the author’s version of a work that was accepted for publication in
Pervasive and Mobile Computing. Changes resulting from the publishing process,
such as peer review, editing, corrections, structural formatting, and other quality
control mechanisms may not be reflected in this document. Changes may have been
made to this work since it was submitted for publication.
DOI: 10.1016/j.pmcj.2014.05.006”
 
Towards Using Unlabeled Data in a Sparse-coding Framework for Human Activity
Recognition
Sourav Bhattacharyaa, Petteri Nurmia, Nils Hammerlab, Thomas Pl¨otzb
aHelsinki Institute for Information Technology HIIT
Department of Computer Science, University of Helsinki, Finland
bCulture Lab, School of Computing Science, Newcastle University, UK
We propose a sparse-coding framework for activity recognition in ubiquitous and mobile computing that alleviates two
fundamental problems of current supervised learning approaches. (i) It automatically derives a compact, sparse and
meaningful feature representation of sensor data that does not rely on prior expert knowledge and generalizes well
across domain boundaries. (ii) It exploits unlabeled sample data for bootstrapping effective activity recognizers, i.e.,
substantially reduces the amount of ground truth annotation required for model estimation. Such unlabeled data is easy
to obtain, e.g., through contemporary smartphones carried by users as they go about their everyday activities.
Based on the self-taught learning paradigm we automatically derive an over-complete set of basis vectors from unlabeled data that captures inherent patterns present within activity data. Through projecting raw sensor data onto the
feature space deﬁned by such over-complete sets of basis vectors effective feature extraction is pursued. Given these
learned feature representations, classiﬁcation backends are then trained using small amounts of labeled training data.
We study the new approach in detail using two datasets which differ in terms of the recognition tasks and sensor
modalities. Primarily we focus on a transportation mode analysis task, a popular task in mobile-phone based sensing. The sparse-coding framework demonstrates better performance than the state-of-the-art in supervised learning
approaches. More importantly, we show the practical potential of the new approach by successfully evaluating its generalization capabilities across both domain and sensor modalities by considering the popular Opportunity dataset. Our
feature learning approach outperforms state-of-the-art approaches to analyzing activities of daily living.
Keywords: Activity Recognition, Sparse-coding, Machine Learning, Unsupervised Learning.
1. Introduction
Activity recognition represents a major research area
within mobile and pervasive/ubiquitous computing .
Prominent examples of domains where activity recognition has been investigated include smart homes ,
situated support , automatic monitoring of mental and
physical wellbeing , and general health care . Modern smartphones with their advanced sensing
capabilities provide a particularly attractive platform for
activity recognition as they are carried around by many
people while going about their everyday activities.
The vast majority of activity recognition research relies on supervised learning techniques where handcrafted
features, e.g., heuristically chosen statistical measures,
are extracted from raw sensor recordings, which are then
combined with activity labels for effective classiﬁer training.
While this approach is in line with the standard
procedures in many application domains of general pattern recognition and machine learning techniques , it
is often too costly or simply not applicable for ubiquitous/pervasive computing applications. The reasons for
this are twofold. Firstly, the performance of supervised
learning approaches is highly sensitive to the type of feature extraction, where often the optimal set of features
varies across different activities . Secondly,
and more crucially, obtaining reliable ground truth annotation for bootstrapping and training activity recognizers
poses a challenge for system developers who target realworld deployments. People typically carry their mobile
device while going about their everyday activities, thereby
not paying much attention to the phone itself in terms of
location of the device (in the pocket, in the backpack, etc.)
and only sporadically interacting with it . Consequently, active support from users to
provide labels for data collected in real-life scenarios cannot be considered feasible for many settings as prompting
mobile phone users to annotate their activities while they
are pursuing them has its limitations. Apart from these
limitations, privacy and ethical considerations typically
render direct observation and annotation impracticable in
realistic scenarios.
Possible alternatives to such direct observation and annotation include: (i) self-reporting of activities by the
users, e.g., using a diary ; (ii) the use of experience
sampling, i.e., prompting the user and asking for the current or previous activity label ; and (iii) a combination of these methods. While such techniques somewhat
alleviate the aforementioned problem by providing annotation for at least smaller subsets of unlabeled data, they
still remain prone to errors and typically cannot replace
expert ground truth annotation.
Whereas obtaining reliable ground truth annotation is
hard to achieve, the collection of, even large amounts of,
unlabeled sample data is typically straightforward. People’s smartphones can simply record activity data in an
opportunistic way, without requiring the user to follow a
certain protocol or scripted activity patterns. This is especially attractive since it allows for capturing sensor data
while users perform their natural activities without necessarily being conscious about the actual data collection.
In this paper we introduce a novel framework for activity recognition. Our approach mitigates the requirement
of large amounts of ground truth annotation by explicitly exploiting unlabeled sensor data for bootstrapping our
recognition framework. Based on the self-taught learning paradigm , we develop a sparse-coding framework for unsupervised estimation of sensor data representations with the help of a codebook of basis vectors
(see Section 3.2). As these representations are learned
in an unsupervised manner, our approach also overcomes
the need to perform feature-engineering. While the original framework of self-taught learning has been developed
mainly for the analysis of non-sequential data, i.e., images
and stationary audio signals , we extend the approach
towards time-series data such as continuous sensor data
streams. We also develop a basis selection method that
builds on information theory to generate a codebook of
basis vectors that covers characteristic movement patterns
in human physical activities. Using activations of these
basis vectors (see Section 3.3) we then compute features
of the raw sensor data streams, which are the basis for
subsequent classiﬁer training. The latter requires only relatively small amounts of labeled data, which alleviates the
ground truth annotation challenge of mobile computing
applications.
We demonstrate the beneﬁts of our approach using data
from two diverse activity recognition tasks, namely transportation mode analysis and classiﬁcation of activities of
daily living (the Opportunity challenge ).
Our experiments demonstrate that the proposed approach provides better results than the state-of-the-art, namely PCAbased feature learning, semi-supervised En-Co-Training,
and feature-engineering based (supervised) algorithms,
while requiring smaller amounts of training data and not
relying on prior domain knowledge for feature crafting.
Apart from successful generalization across recognition
tasks, we also demonstrate easy applicability of our proposed framework beyond modality boundaries covering
not only accelerometer data but also other commonly
available sensors on the mobile platform, such as the gyroscopes, or magnetometers.
2. Learning From Unlabeled Data
The focus of our work is on developing an effective
framework that exploits unlabeled data to derive robust
activity recognizers for mobile applications. The key idea
is to use vast amounts of easy to record unlabeled sample data for unsupervised feature learning. These features
shall cover general characteristics of human movements,
which guarantees both robustness and generalizability.
Only very little related work exists that focus on incorporating unlabeled data for training mobile activity recognizers. A notable exception is the work by Amft who
explored self-taught learning in a very preliminary study
for activity spotting using on-body motion sensors .
However, that work does not take into account the properties of the learned codebook which play an important role
in the recognition task.
The idea of incorporating unlabeled data and related
feature learning techniques into recognizer training is a
well researched area in the general machine learning and
pattern recognition community. In the following, we will
summarize relevant related work from these ﬁelds and link
them to the mobile and ubiquitous computing domain.
2.1. Non-supervised Learning Paradigms
A number of general learning paradigms have been developed that focus on deriving statistical models and recognizers by incorporating unlabeled data. Although differing in their particular approaches, all related techniques
share the objective of alleviating the dependence on a
large amount of annotated training data for parameter estimation.
Learning from a combination of labeled and unlabeled
datasets is commonly known as semi-supervised learning . The most common approach to semi-supervised
learning is generative models, where the unknown data
distribution p(x) is modeled as a mixture of class conditional distributions p(x|y), where y is the (unobserved)
class variable.
The mixture components are estimated
from a large amount of unlabeled and small amount of
labeled data by applying the Expectation Maximization
(EM) algorithm.
The predictive estimate of p(y|x) is
then computed using Bayes’ formula. Other approaches
to semi-supervised learning include self-training, cotraining, transductive SVM (TSVM), graphical models
and multiview learning.
Semi-supervised learning techniques have also been applied to activity recognition, e.g., for recognizing locomotion related activities , and in smart homes . In
order to be effective, semi-supervised learning approaches
need to satisfy certain, rather strict assumptions .
Probably the strongest constraint imposed by these techniques is that they assume that the unlabeled and labeled datasets are drawn from the same distribution, i.e.,
Du = Dl. In other words, the unlabeled dataset has to
be collected with strict focus on the set of activities the
recognizer shall cover. This limits generalization capability and renders the learning error-prone for real-world settings where the user might perform extraneous activities,
or no activity at all . Our approach provides improved
generalization capability by relaxing the equality condition for the distributions of unlabeled and labeled datasets,
i.e., Du ̸= Dl.
An alternative approach to dealing with unlabeled data
is active learning. Techniques for active learning aim to
make the most economic use of annotations by identifying
those unlabeled samples that are most uncertain and thus
their annotation would provide most information for the
training process. Such samples are automatically identiﬁed using information theoretic criteria and then manual annotation is requested. Active learning approaches
have become very popular in a number of application
domains including activity recognition using body-worn
sensors . Active learning operates on pre-deﬁned
sets of features, which stands in contrast to our approach
that automatically learns feature representations. In doing so, active learning becomes sensitive to the particular
features that have been extracted, hence limiting its generalizability.
Explicitly focusing on generalizability of recognition
frameworks, transfer learning techniques have been developed to bridge, e.g., application domains with differing classes or sensing modalities . In this approach,
knowledge acquired in a speciﬁc domain can be transferred to another, if a systematic transformation is either
provided or learned automatically. Transfer learning has
been applied to ubiquitous computing problems, for example, for adapting models learned with data from one
smart home to work within another smart home ,
or to adapt activity classiﬁers learned with data from one
user to work with other users . In these approaches
the need for annotated training data is not directly reduced
but shifted to other domains or modalities, which can be
beneﬁcial if such data are easier to obtain.
As an alternative approach to alleviating the demands
of ground truth annotation so-called multi-instance learning techniques have been developed. These techniques
assign labels to sets of instances instead of individual data
points . Multi-instance learning has also been applied
for activity recognition tasks in ubiquitous computing settings . To apply multi-instance learning, labels of
the individual instances were considered as hidden variables and a support vector machine was trained to minimize the expected loss of the classiﬁcation of instances
using the labels of the instance sets. Multi-instance learning also operates on a predeﬁned set of features and therefore has limited generalizability.
2.2. Feature Learning
Exploiting unlabeled data can also be applied at the feature level to derive a compact and meaningful representation of raw input data. In fact, feature learning, i.e., unsupervised estimation of suitable data representations, has
been actively researched in the machine learning community . The goal of feature learning is to identify and
model interesting regularities in the sensor data without
being driven by class information. The majority of methods rely on a process similar to generative models but employ efﬁcient, approximative learning algorithms instead
of EM .
Data representations for activity recognition in the
ubiquitous or mobile computing domain typically correspond to some sort of “engineered” feature sets, e.g., statistical values calculated over analysis windows that are
extracted using a sliding window procedure . Such
predeﬁned features often do not generalize across domain
boundaries, which requires system developers to optimize
their data representation virtually from scratch for every
new application domain.
Only recently, concepts of feature learning have been
successfully applied for activity recognition tasks. For
example, M¨antyj¨arvi et al. compared the use of Principal Component Analysis (PCA) and Independent Component Analysis (ICA) for extracting features from sensor
data. In their approach, either PCA or ICA was applied on
raw sensor values. A sliding window was then applied on
the transformed data and a Wavelet-based feature extraction method was used in combination with a multilayer
perceptron.
Similarly, Pl¨otz et al. employed principal component
analysis to derive features from tri-axial accelerometer
data using a sliding window approach . However, instead of applying the PCA on the raw sensor values, they
used the empirical cumulative distribution of a data frame
to represent the signals before applying PCA . Moreover, they investigated the use of Restricted Boltzmann
Machines , to train an autoencoder network for feature learning.
Minnen et al. considered activities as sparse motifs
in multidimensional time series and proposed an unsupervised algorithm for automatically extracting such motifs
from data. A related approach was proposed by Frank et
al. who used time-delay embeddings to extract features from windowed data and fed these features to a subsequent classiﬁer.
Contrary to the popular Fourier and Wavelet representations, which suffer from non-adaptability to the particular
dataset , we employ a data-adaptive approach of representing accelerometer measurements. The data-adaptive
representation is tailored to the statistics of the data and
is directly learned from the recorded measurements. Examples of data-adaptive methods include PCA, ICA and
Matrix Factorization. Our approach differs from common
data-adaptive methods by employing an over-complete
and sparse feature representation technique. Here, overcompleteness indicates that the dimension of the feature
space is much higher than the original input data dimension, and sparsity indicates that the majority of the elements in a feature vector is zero.
3. A Sparse-Coding Framework for Activity
Recognition
We propose a sparse-coding framework for activity
recognition that uses a codebook of basis vectors that capture characteristic and latent patterns in the sensor data.
As the codebook learning is unsupervised and operates on
unlabeled data, our approach effectively reduces the need
for annotated ground truth data and overcomes the need
to use predeﬁned feature representations, rendering our
approach well suited for continuous activity recognition
tasks under naturalistic settings.
3.1. Method Overview
Figure 1 gives an overview of our approach to learning activity recognizers. We ﬁrst collect unlabeled data,
which in our experiments consists mainly of tri-axial accelerometer measurements (upper part of Figure 1(a)). We
then solve an optimization problem (see Section 3.2) to
learn a set of basis vectors — the codebook — that capture characteristic patterns of human movements as they
can be observed from the raw sensor data (lower part of
Figure 1(a)).
Once the codebook has been learned, we use a small set
of labeled data to train an activity classiﬁer (Figure 1(b)).
The features that are used for training the classiﬁer correspond to so-called activations, which are vectors that
enable transferring sensor readings to the feature space
spanned by the basis vectors in the codebook.
model training, the activity label for new sensor readings
can be determined by transferring the corresponding measurements into the same feature space and applying the
learned classiﬁer.
3.2. Codebook Learning from Unlabeled Data
We consider sequential, multidimensional sensor data,
which in our experiments correspond to measurements
from a tri-axial accelerometer or a gyroscope. We apply a sliding window procedure on the measurements to
extract overlapping, ﬁxed length frames. Speciﬁcally, we
consider measurements of the form xi ∈Rn, where xi is
a vector containing all measurements within the ith frame
and n is the length of the frame, i.e., the unlabeled measurements are represented as the set
{x1, x2, . . . , xK}, xi ∈Rn.
In the ﬁrst step of our approach, we use the unlabeled
data X to learn a codebook B that captures latent and
characteristic patterns in the sensor measurements. The
codebook consists of S basis vectors {βj}S
j=1, where each
basis vector βj ∈Rn represents a particular pattern in the
data. Once the codebook has been learned, any frame of
sensor measurements can be represented as a linear superposition of the basis vectors, i.e.,
Unlabeled data
Codebook of basis vectors
Unsupervised
(a) The ﬁrst phase of sparse-coding based estimation of activity
recognizers consists of codebook learning from unlabeled data
that results in a codebook of basis vectors that cover characteristic patterns of human movements.
Labeled data
Sparse activations
Training a classifier
(a1, y1) (a2, y2)
Ground-truths
(b) The second phase of our modeling approach extracts feature
vectors from small amounts of labeled dataset using the codebook of basis vectors extracted in the ﬁrst phase. Based on
these features standard classiﬁer training is performed.
Figure 1: Overview of the sparse-coding framework for activity recognition incorporating unlabeled training data.
j is the activation for jth basis vector when representing the measurement vector xi; see Figure 4(a) for an
illustration.
The task of learning the codebook B = {βj}S
unlabeled data X can be formulated as a regularized optimization problem (see, e.g., ). Speciﬁcally,
we obtain the codebook as the optimal solution to the following minimization problem:
2 + α||ai||1
||βj||2 ≤1, ∀j ∈{1, . . . , S}.
Equation 3 contains two optimization variables:
activations
{a1, a2, . . . , aK}. The regularization parameter α controls the trade-off between reconstruction quality and
sparseness of the basis vectors. Smaller values of α lead to
the ﬁrst term, i.e., the quadratic term in Equation 3, dominating, thereby generating basis vectors whose weighted
combination can represent input signals accurately.
contrast, large values (e.g., α ≈1) shift the importance towards the regularization term, thereby encouraging sparse
solutions where the activations have small L1-norm, i.e.,
the input signal is represented using only a few basis vectors.
The constraint on the norm of each basis vector βj is
essential to avoid trivial solutions, e.g., very large βj and
very small activations ai . Note that Equation 3 does
not pose any restrictions on the number of basis vectors
S that can be learned. In fact, the codebook can be overcomplete, i.e., containing more basis vectors than the input data dimension (i.e., S ≫n). Over-completeness
reduces sensitivity to noise, whereas the application of
sparse-coding enables deviating from a purely linear relationship between the input and output, enabling the codebook to capture complex and high-order patterns in the
data .
The minimization problem speciﬁed in Equation 3 is
not convex on both B and a simultaneously. However,
it can easily be divided into two convex sub-problems,
which allows for iterative optimization of both B and a,
thereby keeping one variable constant while optimizing
the other. Effectively this corresponds to solving a L2constrained least squares problem while optimizing for
B keeping a constant, followed by optimizing a whilst
keeping B constant, i.e., solving an L1-regularized least
square problem .
The solution to the optimization
problem, speciﬁcally in the case of a large dataset and
highly over-complete representation, is computationally
expensive . Following Lee et al. , we use a fast
iterative algorithm to codebook learning.
Algorithm 1
summarizes the procedure, where the FeatureSignSearch
algorithm (line 12) solves the L1-regularized least square
problem (for details see ). The codebook is derived
by using standard least square optimization (line 13). The
convergence of the algorithm is detected when the drop in
the objective function given in Equation 3 is insigniﬁcant
between two successive iterations.
Algorithm 1 Fast Codebook Learning
1: Input: Unlabeled dataset X = {xi}K
2: Output: Codebook B = {βj}S
3: Algorithm:
4: for j ∈{1, . . . , S} do
▷Initializing basis vectors
βj ∼U(−0.5, 0.5)
βj = MeanNormalize(βj)
βj = MakeNormUnity(βj)
8: end for
q=1 = Partition(X)
partition data into M batches
for q ∈{1, . . . , M} do
aBatchq = FeatureSignSearch(Batchq, B)
B = LeastSquareSolve(Batchq, aBatchq)
15: until convergence
16: return: B
Codebook Selection
When sparse-coding is applied on sequential data
streams, the solution to the optimization problem speciﬁed by Equation 3 has been shown to produce redundant basis vectors that are structurally similar, but shifted
in time . Grosse et al. have proposed a convolution
technique that helps to overcome redundancy by allowing
the basis vectors βj to be used at all possible time shifts
within the signal xi. Speciﬁcally, in this approach the optimization equation is modiﬁed into the following form:
2 + α||ai||1
subject to
||βj||2 ≤c, ∀j ∈{1, . . . , S},
where xi ∈Rn and βj ∈Rp with p ≤n. The activations
are now n−p+1 dimensional vectors, i.e., ai
j ∈Rn−p+1,
and the measurements are represented using a convolution
of activations and basis vectors, i.e., xi = βi ∗ai
j. However, this approach is computationally intensive, rendering
it unsuitable to mobile devices. Instead of modifying the
optimization equation itself, we have developed a basis
vector selection technique based on an information theoretic criterion. The selection procedure reduces redundancy by removing speciﬁc basis vectors that are structurally similar.
In the ﬁrst step of our codebook selection technique,
we employ a hierarchical clustering of the basis vectors.
More speciﬁcally, we use the complete linkage clustering
algorithm with maximal cross-correlation as the sim-
Cutoff threshold
Basis vectors
Cross-correlation
Figure 2: Dendrogram showing the hierarchical relationship, with respect to cross-correlation, present within a
codebook of 512 basis vectors. The plot also indicates the
cutoff threshold used to generate 52 clusters.
ilarity measure between two basis vectors:
sim(β, β′) =
τ=max(1,t−n+1)
β(τ)β′(n + τ −t).
The clustering returns a hierarchical representation of the
similarity relationships between the basis vectors. From
this hierarchy, we then select a subset of basis vectors that
contains most of the information. In order to do so, we
ﬁrst apply an adaptive cutoff threshold on the hierarchy
to divide the basis vectors into ⌈S/10⌉clusters. For illustration, Figure 2 shows the dendrogram plot of the hierarchical relationships found within a codebook of 512
basis vectors. The red line in the ﬁgure indicates the cutoff threshold (0.34) used to divide the basis vectors into
52 clusters. Next, we remove from each cluster those basis vectors that are not sufﬁciently informative. Speciﬁcally, we order the basis vectors within a cluster by their
empirical entropy1 and discard the lowest 10-percentile of
vectors. The basis vectors that remain after this step constitute the ﬁnal codebook B∗used by our approach.
3.3. Feature Representations and Classiﬁer Training
Once the codebook has been learned, we use a small
set of labeled data to train a classiﬁer that can be used
to determine the appropriate activity label for new sensor
readings. Let X′ = {x′
1, . . . , x′
M} denote the set of measurement frames for which ground truth labels are available and let y = (y1, . . . , yM) denote the corresponding
activity labels. To train the classiﬁer, we ﬁrst map the
measurements in the labeled dataset to the feature space
spanned by the basis vectors. Speciﬁcally, we need to derive the optimal activation vector bai for the measurement
1To calculate the empirical entropy, we construct a histogram of
the basis vector values. The empirical entropy is then computed by
q pq · log pq, where pq is the probability of the qth histogram bin.
i, which corresponds to solving the following optimization equation:
bai = arg min
2 + α||ai||1.
Once the activation vectors bai have been calculated, a supervised classiﬁer is learned using the activation vectors
as features and the labels yi as the class information, i.e.,
the training data consists of tuples (bai, yi). The classiﬁer
is learned using standard supervised learning techniques.
In our experiments we consider decision trees, nearestneighbor, and support vector machines (SVM) as the classiﬁers; however, our approach is generic and any other
classiﬁcation technique can be used.
To determine the activity label for a new measurement
frame xq, we ﬁrst map the measurement onto the feature
space speciﬁed by the basis vectors in the codebook, i.e.,
we use Equation 6 to obtain the activation vector baq for
xq. The current activity label can then be determined by
giving the activation vector baq as input to the previously
trained classiﬁer.
The codebook selection procedure based on hierarchical clustering also helps to improve the running time of
above optimization problem while extracting feature vectors and therefore suits well for mobile platforms. The
overall procedure of our sparse-coding based framework
for activity recognition is summarized in Algorithm 2.
4. Case Study: Transportation Mode Analysis
In order to study the effectiveness of the proposed
sparse-coding framework for activity recognition, we conducted an extensive case study on transportation mode
We utilized smartphones and their onboard
sensing capabilities (tri-axial accelerometers) as mobile
recording platform to capture people’s movement patterns
and then use our new activity recognition method to detect the transportation modes of the participants in their
everyday life, e.g., walking, taking the metro and riding
Knowledge of transportation mode has relevance to numerous ﬁelds, including human mobility modeling ,
inferring transportation routines and predicting future
movements , urban planning , and emergency response, to name but a few . It is considered as a representative example of mobile computing applications .
Gathering accurate annotations for transportation mode
detection is difﬁcult as the activities take place in everyday
situations where environmental factors, such as crowding,
Algorithm 2 Sparse-code Based Activity Recognition
1: Input: Unlabeled dataset X = {xi}K
Labeled dataset X′ = {(x′
3: Output: Classiﬁer C
4: Algorithm:
5: B = Fast Codebook Learning(X)
▷Learning a
codebook from unlabeled data using Algorithm 1
6: Identify clusters {Ki}C
i=1 within learned codebook B
based on structural similarities.
▷Initialization of optimized codebook
8: for j ∈{1, . . . , C} do
B∗= B∗∪Select(Kj)
▷selection of most
informative basis vectors from a cluster
10: end for
▷Initialization of feature set
12: for i ∈{1, . . . , M} do
bai = arg minai ||x′
2 + α||ai||1 ▷
Here, βj ∈B∗, ∀j and S∗= |B∗|
F = F ∪(bai, yi)
15: end for
16: C = ClassiﬁerTrain(F)
17: return: C
can rapidly inﬂuence a person’s behavior.
Transportation activities are also often interleaved and difﬁcult to
distinguish (e.g., a person walking in a moving bus on
a bumpy road). Furthermore, people often interact with
their phones while moving, which adds another level of
interference and noise to the recorded signals.
The state-of-the-art in transportation mode detection
largely corresponds to feature-engineering based approaches , which we will use as a baseline
for our evaluation.
4.1. Dataset
For the case study we have collected a dataset that consists of approximately 6 hours of consecutive accelerometer recordings.
Three participants, graduate students
in Computer Science who had prior experience in using
touch screen phones, carried three Samsung Galaxy S II
each while going about everyday life activities. The participants were asked to travel between a predeﬁned set of
places with a speciﬁc means of transportation. The data
collected by each participant included still, walking and
traveling by tram, metro, bus and train. The phones were
placed at three different locations: (i) jacket’s pocket; (ii)
pants’ pocket; and (iii) backpack.
Accelerometer data were recorded with a sampling frequency of 100 Hz. For ground truth annotation partici-
1, 827, 710
1, 694, 413
1, 825, 868
Table 1: Summary of the dataset used for the case study
on transportation mode analysis. The ﬁrst three columns
contain the number of samples recorded from each phone
location, and the ﬁnal column shows the overall duration
of the corresponding measurements (in hours).
pants were given another mobile phone that was synchronized with the recording devices and provided a simple
annotation GUI. The dataset is summarized in Table 1.
4.2. Pre-processing
Before applying our sparse-coding based activity
recognition framework, the recorded raw sensor data have
to undergo certain standard pre-processing steps.
Orientation Normalization
Since tri-axial accelerometer readings are sensitive to
the orientation of the particular sensor, we consider magnitudes of the recordings, which effectively normalizes
the measurements with respect to the phone’s spatial orientation.
Formally, this normalization corresponds to
aggregating the tri-axial sensor readings using the L2norm, i.e., we consider measurements of the form d =
d2x + d2y + d2z where dx, dy and dz are the different acceleration components at a time instant. Magnitude-based
normalization corresponds to the state-of-the-art approach
for achieving rotation invariance in smartphone-based activity recognition .
Frame Extraction
For continuous sensor data analysis we extract small
analysis frames, i.e., windows of consecutive sensor readings, from the continuous sensor data stream. We use a
sliding window procedure that circumvents the need
for explicit segmentation of the sensor data stream, which
in itself is a non-trivial problem. We employ a window
size of one second, corresponding to 100 sensor readings. Using a short window length enables near real-time
information about the user’s current transportation mode
and ensures the detection can rapidly adapt to changes in
transportation modalities .
Consecutive frames
overlap by 50% and the activity label of every frame is
then determined using majority voting. For example, in
(a) Examples of basis vectors learned from accelerometer data.
(b) Examples of basis vectors from one cluster, showing the timeshifting property.
Figure 3: Examples of basis vectors as learned from
the transportation mode dataset and example of the timeshifting property observed within a codebook.
our analysis two successive frames have exactly 50 contiguous measurements in common and the label of a frame
is determined by taking the most frequent ground-truth label of the 100 measurements present within it. In (rare)
cases of a tie, the frame label is determined by selecting
randomly among the labels with the highest occurrence
frequency.
4.3. Codebook Learning
According to the general idea of our sparse-coding
based activity recognition framework, we derive a userspeciﬁc codebook of basis vectors from unlabeled frames
of accelerometer data (magnitudes) by applying the fast
codebook learning algorithm as described in the previous
section (see Algorithm 1). With a sampling rate of 100
Hz and a frame length of 1s, the dimensionality of both
input xi and the resulting basis vectors βj is 100, i.e.,
xi ∈R100 and βj ∈R100.
Figure 3(a) illustrates the results of the codebook learning process by means of 49 exemplary basis vectors as
they have been derived from one arbitrarily chosen participant (User 1).
The shown basis vectors were randomly picked from the generated codebook. For illustration purposes Figure 3(b) additionally shows examples of
the time-shifted property observed within the learned set
of basis vectors.
By analyzing the basis vectors it becomes clear that:
(i) the automatic codebook selection procedure covers a
large variability of input signals; and (ii) that basis vectors
assigned to the same cluster often are time-shifted variants
of each other.
When representing an input vector, the activations of
basis vectors are sparse, i.e., only a small subset of the
over-complete codebook has non-zero weights that originate from different pattern classes. The sparseness property improves the discrimination capabilities of the framework. For example, Figure 4(a) illustrates the reconstruction of an acceleration measurement frame with 54 out of
512 basis vectors present in a codebook. Moreover, Figure 4(b) illustrates the histograms of the number of basis
vectors activated to reconstruct the measurement frames,
speciﬁc to different transportation modes, for the dataset
collected by User 1. The ﬁgure indicates that a small fraction of the basis vectors from the learned codebook (i.e.,
≪512) are activated to accurately reconstruct most of the
measurement frames.
The quality of the codebook can be further assessed by
computing the average reconstruction error on the unlabeled dataset. Figure 5(a) shows the histogram of the reconstruction error computed using a codebook of 512 basis vectors for the dataset collected by User 1. The ﬁgure
indicates that the learned codebook can represent the unlabeled data very well with most of the reconstructions
resulting in a small error.
The reconstruction error on the unlabeled data can also
be used to determine the size of the codebook to use. To
illustrate this, Figure 5(b) shows the average reconstruction error while learning codebooks of varying size from
the data collected by User 2. Note that the reconstruction
error does not necessarily decrease with increased size of
the codebook since large over-complete bases can be dif-
ﬁcult to learn. The ﬁgure shows that the codebook with
512 basis vectors failed to reduce the average reconstruction error, compared to the codebook with 256 basis vectors. In order to ﬁnd a good codebook size, we next use a
greedy binary search strategy and learn a codebook whose
size is halfway in between 256 and 512, i.e., 384. If the
new codebook achieves the lowest average reconstruction
error, we stop the back tracking (as in this case). Otherwise, we continue searching for a codebook size by taking
Measurement vector dimensions
Reconstruction
(a) Reconstruction of a measurement frame
using 54 basis vectors from a codebook
containing 512 basis vectors.
No. of activations
Still, µ = 13.2
No. of activations
Walking, µ = 46.3
No. of activations
Bus, µ = 22.9
No. of activations
Train, µ = 15.2
No. of activations
Metro, µ = 15.2
No. of activations
Tram, µ = 16.1
(b) Histograms of number of basis vector activations.
Figure 4: (a) Example of reconstruction of a frame of accelerometer measurements (after normalization). (b) Histograms showing the frequency distributions of the number of basis vectors activated for the reconstruction of accelerometer measurement frames for different transportation modes present in one dataset (User 1). The ﬁgure
also indicates the average number of basis vector activations per transportation mode.
the mid point between the codebook size with lowest reconstruction error found so far (e.g., 256) and the latest
codebook size tried (e.g., 384). Figure 5(b) also indicates
that an over-complete codebook (i.e., S ≥100), generally
improves the accuracy of the data reconstruction.
4.4. Feature Extraction
Examples of features extracted from accelerometer
readings collected during different modes of transportation using the optimized codebook B∗are given in Figure 6. In the ﬁgure we have separated activations of basis
vectors in different clusters with red vertical lines and the
basis vectors within a cluster are sorted based on their empirical entropy. Among all transportation modes, ‘walking’, which represents the only kinematic activity in our
Feature vector dimensions
Figure 6: Examples of feature vectors derived for different transportation modes using the optimized codebook B∗.
Vertical lines separate different clusters of basis vectors, which remained after the codebook selection process.
Reconstruction Error (RMSE)
64 128 256 320 384 512
Average reconstruction error (RMSE)
Size of learned codebook
(a) Histogram of the reconstruction error
(RMSE) of accelerometer data collected by User 1 using
a codebook of 512 basis vectors. (b) Variation of average
reconstruction error with varying codebook size.
dataset, is found to be totally different from other activities. The ﬁgure indicates the presence of a large cluster of
basis vectors with structural similarities, which can also
be observed from Figure 2. The basis vectors belonging
to the large cluster are responsible mostly for capturing inherent patterns present in ‘static’ and ‘motorized’ modes
of transportation.
4.5. Baseline Algorithms
We compare the effectiveness of the proposed sparsecoding framework with three standard analysis approaches as they have been deployed in a number of stateof-the-art activity recognition applications. In the following, we summarize the technical details of the latter. Note
that the focus of our work is on feature extraction. The
classiﬁcation backend is principally the same for all experiments (see Section 5).
4.5.1. Principal Component Analysis
Principal Component Analysis (PCA, ) is a popular dimensionality reduction method, which has also been
used for feature extraction in activity recognition community . We use PCA based feature learning as a baseline
in our evaluation experiments, and in this section we outline the main differences of PCA compared to the sparsecoding based approach.
PCA projects data onto an orthogonal lower dimensional linear space such that the variance of the projected
data is maximized. The optimization criterion for extracting principal components, i.e., the basis vectors can be
written as:
subject to βj ⊥βk, ∀j, k s.t. j ̸= k
where d is the dimensionality of the subspace. Feature
vectors ai can be derived by projecting the input data xi ∈
Rn on the principal components {βj}d
j=1, where d ≤n.
PCA has two main differences to sparse-coding. First,
PCA extracts only linear features, i.e., the extracted features ai are a linear combination of the input data. This results in the inability of PCA to extract non-linear features
and restricts its capability for accurately capturing complex activities. Second, PCA constraints the basis vectors
to be mutually orthogonal, which restricts the maximum
number of features that can be extracted to the dimensionality of the input data, i.e., in our case to the frame-length
n. Hence, PCA cannot extract over-complete and sparse
We follow the argumentation in and normalize the
accelerometer data before applying PCA using an (inverse) ECDF approach. The inverse of the empirical cumulative distribution function (ECDF) is estimated for
training frames at ﬁxed numbers of points. These frame
representations are then projected onto the subspace retaining at least 99% of the variance resulting in the ﬁnal
feature representation that is then fed into classiﬁer training. During the inference, frames from the test dataset are
projected onto the same principal subspace as estimated
during the training.
Figure 7 illustrates PCA features as they have been extracted from the same transportation mode data frames as
it was used for the sparse-coding approach, which makes
Figures 6 and 7 directly comparable. Input frames of accelerometer readings are projected onto the linear PCA
subspace that retains at least 99% variance of the data,
which in our case results in d = 30-dimensional data vectors. Figure 7 indicates that the PCA features are, in general, non-sparse and measurements collected during different motorized transportations are projected to a similar
region in the subspace.
4.5.2. Feature-Engineering
Aiming for a performance comparison of the proposed sparse-coding framework with state-of-the-art approaches to activity recognition, our second baseline experiment covers feature-engineering, i.e., manual selections of heuristic features. For transportation mode analysis Wang et al. have developed a standard set of features that comprises statistical moments of the considered
frames and spectral features, namely FFT frequency components in the range 0 ∼4 Hz . The details of the
extracted features are summarized in Table 2.
4.5.3. Semi-supervised Learning
As our ﬁnal baseline we consider En-Co-Training, a
semi-supervised learning algorithm proposed by Guan et
al. . This algorithm ﬁrst generates a pool of unlabeled
Feature vector dimensions
Figure 7: Example of feature vectors obtained using PCA
based approach for different transportation modes.
2) Variance,
3) Mean zero crossing rate,
4) Third quartile,
5) Sum of frequency components between 0∼2 Hz,
6) Standard deviation of frequency components
between 0∼2 Hz,
7) Ratio of frequency components between 0∼2 Hz to all
frequencies,
8) Sum of frequency components between 2∼4 Hz,
9) Standard deviation of frequency components between
10) Ratio of frequency components between 2∼4 Hz to
all frequencies, and
11) spectrum peak position.
Table 2: Features used for feature-engineering experiments .
data by randomly sampling measurements from the unlabeled dataset. The algorithm then uses an iterative approach to train three classiﬁers, a decision tree, a Na¨ıve-
Bayes classiﬁer, and a 3-nearest neighbor classiﬁer, using
the labeled data. For training these classiﬁers, we use the
same features as with our feature-engineering baseline.
Next, the three classiﬁers are used to predict the labels
of the samples that are in the pool. Samples for which
all classiﬁers agree are then added to the labeled dataset
and the pool is replenished by sampling new data from the
unlabeled dataset. This procedure is repeated for a prede-
ﬁned number of times (see for details), and the ﬁnal
predictions can be obtained by employing majority voting
on the output of the three classiﬁers.
5. Results
We will now report and discuss the results of the transportation mode case study (described in the previous section), thereby aiming to understand to what extent our approach can effectively alleviate the ground truth annotation problem activity recognition systems for ubiquitous/
pervasive computing typically face.
Serving as performance metric for the recognizers analyzed, we compute the F1-score for individual classes of
the test dataset:
F1-score = 2 · precision · recall
precision + recall,
where precision and recall are calculated in percentages.
Moreover, in order to mitigate the non-uniform class distribution in the test dataset, we employ the multi-class F1score :
1 -score =
i=1 wi · F i
1-score represents the F1-score of the ith class
(out of c different classes of test dataset) and wi corresponds to the number of samples belonging to the ith
5.1. Classiﬁcation Performance
The focus of the ﬁrst part of our experimental evaluation is on the classiﬁcation accuracies that can be achieved
on real-world recognition tasks using the proposed sparsecoding activity recognition approach and comparing it to
the results achieved using state-of-the-art techniques (see
Section 4.5). Classiﬁcation experiments on the transportation mode dataset were carried out by means of a six-fold
cross validation procedure. Sensor readings from one participants (∼2 hr) were used as the unlabeled dataset (e.g.,
for codebook estimation in the sparse-coding based approach, see Section 4.4), those from the second participant (∼2 hr) were used as the labeled dataset for classiﬁer training, and the derived classiﬁer is then tested on
the remaining set of recordings as collected by the third
participant (∼2 hr) of our case study. This procedure is
then repeated six times, thereby considering all possible
permutations of assigning recordings to the three aforementioned datasets. The ﬁnal results are obtained by aggregating over the six folds.
For our sparse-coding approach we analyzed the effectiveness of codebooks of different sizes. For practicality
and also to put a limit on the redundancy (see Section 3.2),
we set an upper bound on the codebook size to 512. Based
on the reconstruction quality (evaluated on the unlabeled
dataset, see Section 4.3), we derived participant-speciﬁc
codebooks. In our experiments, the suitable sizes of the
codebooks are found to be 512, 384, and 512 respectively. We then construct the optimized codebooks employing the hierarchical clustering followed by the pruning method (see Section 3.2). After codebook learning
and optimization, the classiﬁcation backend is trained using the labeled dataset as mentioned before. Recognizers based on En-Co-Training and PCA (Section 4.5) are
trained analogously.
To ensure the amount of training
data does not have an effect on the results, the featureengineering baseline is trained using solely the labeled
We use a SVM classiﬁer with all of the algorithms (except En-Co-Training; see Sec. 4.5.3) in a one-versus-all
setting, i.e., we train one SVM classiﬁer for each transportation mode present in the training data.
We consider the common choice of radial basis functions (RBF)
(exp(−γ||x −y||2
2)) as the Kernel function of the SVM
classiﬁers, and optimize relevant parameters (cost coefﬁcient C and Kernel width γ) using a standard grid search
procedure on the parameter space with nested two-fold
cross validation. During the prediction phase, we compute the probabilities p(yc|f) of each class yc, given an
input feature vector f. The ﬁnal prediction is then the
class with the highest estimated probability, i.e., y =
arg maxc p(yc|f).
Classiﬁcation results are reported in Table 3. It can
be seen that the novel sparse-coding based analysis approach achieves the best overall performance with a F M
1 score of 79.9%. In comparison to the three baseline methods, our sparse-coding framework achieves superior performance with all transportation modes. The confusion
matrix shown in Table 4 provides a more detailed picture
of the classiﬁcation performance of our approach.
Verifying the state-of-the-art in transportation mode detection, all considered approaches achieve good performance on walking and stationary modalities. However,
their classiﬁcation accuracies substantially drop on more
complex modalities, i.e., those exhibiting more intraclass variance such as ‘motorized’ ones like riding a bus.
In fact, the state-of-the-art approaches to transportation
mode detection use GPS, GSM and/or WiFi for aiding the
detection of motorized transportation modalities, as it has
been shown that these are the most difﬁcult modalities to
detect solely based on accelerometer measurements .
The semi-supervised En-Co-Training algorithm has the
second best performance overall, with a F M
1 -score of
69.6%. The feature-engineering approach of Wang et al.
Algorithms
Sparse-coding (this work)
En-Co-Training
Feature-engineering (Wang et al.)
Table 3: Classiﬁcation performance of sparse-coding and baseline algorithms using SVM.
Predictions
Weighted average:
Table 4: Confusion matrix for classiﬁcation experiments using the sparse-coding framework.
achieves the next best performance, with a F M
1 -score of
67.9%, and the PCA-based approach has the worst performance with a F M
1 -score of 65.5%. Signiﬁcance tests,
carried out using McNemar χ2-tests with Yates’ correction , indicate the performance of our sparse-coding
approach to be signiﬁcantly better than the performances
of all the baselines (p < 0.01). Also the differences between En-Co-Training and Wang et al., and Wang et al.
and PCA were found statistically signiﬁcant (p < 0.01).
To obtain a strong upper bound on the performance
of the feature-engineering based baseline, we ran a separate cross-validation experiment where the corresponding
SVM classiﬁer was trained with data from two users and
tested on the remaining user. This situation clearly gives
an unfair advantage to the approach of Wang et al. as it can
access twice the amount of training data. With increased
availability of labeled training data, the performance of
the feature-engineering approach improves to F M
of 74.3% (from 67.9%). However, the performance remains below our sparse-coding approach (79.9%), further
demonstrating the effectiveness of our approach, despite
using signiﬁcantly smaller amount (half) of labeled data.
Analyzing the details of the transportation mode dataset
unveils the structural problem PCA-based approaches
have. More than 99% of the frame variance corresponds to
the ‘walking’ activity, which results in a severely skewed
class distribution. While this is not unusual for real-world
problems it renders pure variance-based techniques —
such as PCA — virtually useless for this kind of applica-
Vector dimensions
First three principal components indicating
dominance by a single class with a high variance.
tions. In our case, the derived PCA feature space captures
‘walking’ very well but disregards the other, more sparse,
classes. The reason for this is that the optimization criterion of PCA aims for maximizing the coverage of the
variance of the data – not those of the classes. In principle, this learning paradigm is similar for any unsupervised
approach. However, “blind” optimization as performed
by PCA techniques suffer substantially from skewed class
distributions, whereas our sparse-coding framework is
able to neutralize such biases to some extent.
In order to illustrate the shortcoming of PCA, Figure 8
illustrates the ﬁrst three principal components as derived
for the transportation mode task. Solid blue lines represent the component identiﬁed from only ‘walking’ data
and the black dashed lines show the case when data from
different modes of transportation is used as well for PCA
estimation. A close structural similarity indicates that the
linear features extracted by PCA are highly inﬂuenced by
one class with high variance, thereby affecting the quality
of features for other classes.
For completeness, we have repeated the same six fold
cross-validation experiment using C4.5 decision trees
(see, e.g., [59, Chap. 4]) as the classiﬁers. Similarly to
the previous results, the best performance is achieved by
the sparse-coding algorithm 75.8%. The second best performance, 70.8%, is shown by the feature-engineering algorithm of Wang et al., signiﬁcantly lower than the sparsecoding (p < 0.01).
The performance of the En-Co-
Training remained the same (69.6%) and no signiﬁcant
difference was found compared to the feature-engineering
approach. As before, the PCA-based algorithm showed
the worst performance (64.9%).
5.2. Exploiting Unlabeled Data
The effectiveness of sparse coding depends on the quality of the basis vectors, i.e., how well they capture patterns
that accurately characterize the input data. One of the
main factors inﬂuencing the quality of the basis vectors
is the amount of unlabeled data that is available for learning. As the next step in our evaluation we demonstrate
that even small amounts of additional unlabeled data can
effectively be exploited to signiﬁcantly improve activity
recognition performance.
We use an evaluation protocol, where we keep a small
amount of labeled data (∼15 min) and a test dataset
(∼2 hr) ﬁxed. We only increase the size of the unlabeled
dataset. In this experiment, the training dataset consists
of a stratiﬁed sample of accelerometer readings from one
participant (User 1) only, amounting to roughly 15 minutes of transportation activities. As the test data we use
all recordings from User 2. We then generate an increasing amount of unlabeled data X(t) by taking the ﬁrst t
minutes of accelerometer recordings collected by User 3,
where t is varied from 0 minutes to 90 minutes with a
step of 10 minutes. This procedure corresponds to the envisioned application case where users would carry their
mobile sensing device while going about their everyday
business, i.e., not worrying about the phone itself, their
activities and their annotations. Similarly to the previous
section, we use SVM as the classiﬁer.
Figure 9 illustrates the results of this experiment and
compares sparse-coding against the baseline algorithms.
In addition to the classiﬁcation accuracies achieved using the particular methods (upper part of the diagram), the
ﬁgure also shows the transportation mode ground truth for
the additional unlabeled data (lower part). Note that this
ground truth annotation is for illustration purposes only
and we do not use the additional labels for anything else.
supervised
featureengineering based approach by Wang et al., thereby
effectively neglecting all unlabeled data. This baseline
is represented by the dashed (red) line, which achieves
1 -score of 68.2%.
Since the supervised approach
does not exploit unlabeled data at all, its classiﬁcation
performance remains constant for the whole experiment.
All other methods, including our sparse-coding
framework, make use of the additional unlabeled data,
which is indicated by actual changes in the classiﬁcation accuracy depending on the amount of additional
unlabeled data used.
However, only the sparse-coding
framework actually beneﬁts from the additional data (see
The performance improvement by the PCAbased approach over the feature-engineering algorithm
is marginal. Whereas, the improvements are signiﬁcant
by the En-Co-Training and our sparse-coding framework.
The more additional data is available, the more drastic
this difference becomes for the sparse-coding.
Our sparse-coding framework starts with an F M
of 71.8% when the amount of unlabeled data is small
(t = 10 minutes). The unlabeled data at t = 10 minutes only contains measurements from ‘still’, ‘walking’
and ‘tram’ classes and the algorithm is unable to detect
the ‘train’ and ‘metro’ activities in the test dataset. At
t = 30 minutes, when more measurements from ‘tram’
have become available, the F1-score for that class improves by approximately 18% absolute (not shown in the
Additionally, sparse-coding begins to successfully detect ‘train’ and ‘metro’ transportation modes due
to its good reconstruction property, even though no samples from either of the classes are present in the unlabeled data. With a further increase of the amount of unlabeled data, the performance of sparse-coding improves
and achieves its maximum of 84.6% at t = 50 minutes. The performance of sparse-coding remains at this
level (saturation), which is signiﬁcantly better classiﬁcation performance (p < 0.01) compared to all other methods. It is worth noting again that this additional training
data can easily be collected by simply carrying the mobile
sensing device while going about everyday activities and
not requiring any manual annotations.
Analyzing the remaining two curves in Figure 9 it
becomes clear that both En-Co-Training (black curve)
and PCA-based recognizers (blue curve) do not outperform our sparse-coding framework.
The plot indicates
that these techniques cannot use the additional unlabeled
dataset to improve the overall recognition performance.
Time (minute)
Sparse-coding
En-Co-Training
Supervised learning
Figure 9: Classiﬁcation accuracies for varying amounts of unlabeled data used (training and test datasets kept ﬁxed).
The unlabeled dataset begins with the walking activity
(see ground-truth annotations in Figure 9) and the ﬁrst
10 minutes of the unlabeled dataset contains a major portion of the high variance activity data. Thus, the principal components learned from the unlabeled data do not
change signiﬁcantly (see Figure 8) as more and more low
variance data from motorized transportations are added.
As the labeled training data is kept constant, the feature
set remains almost invariant, which explains almost constant performance shown by the PCA-based feature learning approach when tested on a ﬁxed dataset.
The En-Co-Training algorithm employs the same feature representation as the supervised learning approach
and uses a random selection procedure from the unlabeled data to generate a set on which the classiﬁcation ensemble is applied. The random selection process suffers
from over representation by the large transportation activity as it completely ignores the underlying class distribution. The bias toward the large classes limits the En-Co-
Train algorithm to utilize the entire available unlabeled
dataset well, especially for activities that are performed
sporadically. To mitigate the effect of the random selection, we repeat the En-Co-Train algorithm ﬁve times and
only report the average performance for different values of
t. Apart from noise effects no signiﬁcant changes in classiﬁcation accuracy can be seen and the classiﬁcation accuracies remain almost constant throughout the complete
experiment.
5.3. Inﬂuence of Training Data Size
As the next step in our evaluation, we show that the
sparse-coding alleviates the ground-truth collection problem and achieves a superior recognition performance even
when a small amount of ground-truth data is available.
Percentage (%) of Training Data
Sparse-coding
En-Co-Training
Supervised learning
Figure 10: Classiﬁcation accuracies for varying amounts
of labeled data used (unlabeled and test datasets kept
To study the inﬂuence of the amount of labeled training
data on the overall recognition performance, we conduct
an experiment where we systematically vary the amount
of labeled data and measure the recognition performances
of all algorithms using SVM, while keeping the unlabeled
and the test datasets ﬁxed. More speciﬁcally, 24 training
datasets with increasing size are constructed from the data
collected by User 1 by selecting the ﬁrst (chronological)
p% of all the transportation modes (stratiﬁcation), where
p is varied from 1 to 4 with unit step and then 5 to 100,
with a step of 5. This approach also suits well for the
practical use-case, where a small amount of target class
speciﬁc training data is collected to train an activity recognizer. As the test dataset we use the entire data of User 2
and use the data of User 3 as the unlabeled dataset. Note
that the experimental setting differs from that in Section
5.1 and hence the results of these sections are not directly
comparable.
The results of the experiment are shown in Figure 10.
Our sparse-coding based approach clearly outperforms
Algorithms
Sparse-coding
Feature-engineering (Wang)
En-Co-Training
Table 5: Classiﬁcation performance in presence of extraneous activities (‘run’ and ‘bike’) in the test dataset.
Predictions
Weighted average:
Table 6: Confusion matrix for classiﬁcation experiments using the sparse-coding framework in presence of extraneous
activities (‘run’ and ‘bike’).
all baseline algorithms, achieving the best F M
1 -score for
all training data sizes from p ≥2% onwards.
using only 2% of the training data (∼3 minutes), the
sparse-coding achieves a F M
1 -score of 75.1%, which is
signiﬁcantly better (p < 0.01) than all other algorithms,
irrespective of the amount of training data they used.
This indicates superior feature learning capability of the
proposed sparse-coding based activity recognition framework. As more training data is provided, the performance
of the sparse-coding, in general, improves and the highest
1 -score of 86.3% is achieved when 95% of the training
data is available.
The state-of-the-art supervised learning approach performs poorly when very little training data (e.g., ≤5%)
is available and achieves the lowest F M
1 -score of 59.5%.
Additional ground-truth data, e.g., till 40%, continue to
improve the performance of the algorithm to 72.2%. Further increases in training data, however, fail to improve the
performance, with the ﬁnal performance dipping slightly
1 -score of around 70%.
Similarly to our approach, the semi-supervised En-Co-
Training algorithm is capable of utilizing unlabeled data,
achieving a F M
score of 67.4% when 5% of the training
data is available. With 5 −10% training data, En-Co-
Training achieves signiﬁcantly better performance than
the feature-engineering and the PCA-based approaches
(p < 0.01). The performance of the algorithm slightly
improves with additional training data, staying at a level
of 69% until 40% of training data is used. Further increases to the amount of training data start to make the
algorithm sensitive to small scale ﬂuctuations in measurements, causing a slight dip in performance (66%).
These ﬂuctuations are due to the inherent random selection process employed by the algorithm (see Sec. 4.5.3).
When more training data becomes available, the featureengineering approach surpasses the performance of the
En-Co-Training despite relying on the same feature set.
Despite the ability of En-Co-Training to utilize unlabeled
data, its performance remains below sparse-coding, and
also below the feature-engineering for larger training set
sizes, indicating poor generalization capability for the ensemble learning employed by the algorithm.
The PCA-based feature learning approach shows a low
recognition performance of 59.5%, when training data is
With additional training data (e.g., 20%) the
algorithm shows improved performance (67.6%), however, the improvement diminishes as more training data
is added. As described before, the PCA-based approach
learns a set of principal components based on the variance
present in the dataset, without considering the class information. When a large amount of training data is provided,
the orientation of the principal components, biased by the
‘walking’ activity, generates similar features among the
kinematic and motorized activities and makes the classiﬁcation task difﬁcult, resulting in a drop in overall performance.
5.4. Coping with Extraneous Activities
In the ﬁnal part of the transportation mode case study,
we now focus on a more detailed analysis of how the
recognition systems cope with sensor data that were
recorded during extraneous activities, i.e., those that were
not originally targeted by the recognition system. While
going about everyday business, such extraneous activities
can occur and any activity recognition approach needs to
cope with such “open” test sets.
We study the reconstruction errors as they occur when
accelerometer data from extraneous activities are derived
using codebooks that previously had been learned in absence of these extraneous activities. For this evaluation,
we collected additional data from ‘running’ and ‘biking’
activities and then extracted features using the sparsecoding framework as described in Section 4.4.
Figure 11 shows the box-and-whisker diagram, highlighting the quartiles and the outliers of the reconstruction
errors, for different activities using the same codebook
that was used in the experiments of Section 5.1. It can be
seen that the learned codebook effectively generalizes beyond the sample activities seen during training. Although
no sensor readings for ‘running’ or ‘biking’ activities were
used for learning the codebook, the derived basis vectors
can effectively be used to represent these unseen activities
with a reconstruction error that is comparable to those activities that were present during codebook training. Note
that the differences in reconstruction errors reﬂect actual
differences in measurement variance between the activities , and that generally the higher the variance in
measurements, the higher the reconstruction error as more
basis vectors are needed to reconstruct the signal (see Figure 4(b)).
For completeness we also repeated the classiﬁcation
experiments as described in Section 5.1 (six-fold cross
validation using SVM). We extended the labeled training
set by adding approximately 1 minute of ‘running’ (60
frames) and ‘biking’ data (60 frames), and added around
10 minutes of ‘biking’ and 15 minutes of ‘running’ data
to the test set. The results of this cross validation experiment are summarized in Table 5. Even in the presence of
novel activities, the sparse-coding based activity recognition approach achieves the highest overall F M
of 79.3%, which is signiﬁcantly better than all other approaches (p < 0.01 for all). The second best performance
Reconstruction error (RMSE)
Figure 11: Box plot of the reconstruction errors for codebook evaluation on test dataset including previously unseen activities (‘running’ and ‘biking’).
is achieved by the feature-engineering approach (72.2%),
followed by the En-Co-Training approach (71.2%). Similarly to the earlier experiments, PCA results in the lowest
performance at 70.7%.
The addition of more high variance kinematic activities, decreases the accuracy of ‘walking’ (previously the
only high variance activity) detection for all algorithms,
as the underlying classiﬁers confuse ‘walking’ with ‘running’ and ‘biking’ activities. The confusion matrix for
the sparse-coding algorithm is given in Table 6, which
shows that the SVM classiﬁer confuses, mainly among
the ‘walking’, ‘running’, and ‘biking’ activities. Additionally, some degree of confusion is also observed among
the motorized transportation modes and the extraneous activities. Hence, in case of the sparse-coding algorithm,
the F1-scores for all the activities degrade and the overall performance is observed to drop slightly, nevertheless
signiﬁcantly better than all other baseline algorithms. The
results given in Table 5 suggest that the recognition performance of activities using a sub-optimal codebook may
suffer as the extraneous activities are not represented in
the unlabeled dataset. Note that this issue is unlikely to
occur in practice as small amounts of the training data
(e.g., 1 minute) could be included as part of the unlabeled data and the codebook could be learned from the
expanded unlabeled set. As demonstrated in the previous sections, our approach can effectively generalize even
from small amounts of unlabeled data.
6. Generalization: Sparse Coding for Analysis of
Activities of Daily Living (Opportunity)
In order to demonstrate the general applicability of the
proposed sparse-coding approach beyond the transportation mode analysis domain, we now report results on an
additional activity recognition dataset that covers domestic activities as they were recorded in the Opportunity
dataset .
Opportunity represents the de-facto standard dataset for
activity recognition research in the wearable and ubiquitous computing community. It captures human activities within an intelligent environment, thereby combining
measurements from 72 sensors with 10 different modalities. These sensors are: (i) embedded in the environment; (ii) placed in objects; and (iii) attached to the human body to capture complex human activity traits. To
study the performance of our sparse-coding framework,
we use the publicly available challenge dataset2 and focus on the task B2, i.e., gesture recognition3. The task involves identifying gestures performed with the right-arm
from unsegmented sensor data streams. For the purpose
of gesture recognition, in this paper we only consider the
inertial measuring unit (IMU) attached to the right lower
arm (RLA) which was conﬁgured to record measurements
approximately at a rate of 30 Hz for all the inbuilt sensors
(e.g., accelerometer, gyroscope and magnetometer).
We deploy the sparse-coding based recognition framework as described in the transportation mode case study
(Section 4). Task speciﬁc modiﬁcations are minimal and
only of technical nature in order to cope with the collected
data. Contrary to the task of transportation mode detection, sensor orientation information is important for separating the different gestures as they have been performed
in Opportunity (e.g., opening a door, moving a cup and
cleaning table) . Instead of aggregating sensor
readings, our sliding window procedure extracts frames
by concatenating one second of samples from each axis,
i.e., the recordings are of the form:
1, . . . , dx
1, . . . , dy
1, . . . , dz
k correspond to the different axes of
a sensor in the kth sample within a frame, and w is the
length of the sliding window (here 30). Accordingly, each
analysis window contains 90 samples. In line with the reference implementation, subsequent frames have an overlap of 50%.
In order to systematically evaluate the sparse-coding
framework on Opportunity, we ﬁrst construct the unlabeled dataset by combining the ‘Drill’, ‘ADL 1’, ‘ADL 2’
and ‘ADL 3’ datasets of the three subjects (S1, S2 and S3).
We also demonstrate the generalizability of our sparsecoding framework to other modalities, i.e., gyroscope.
Accordingly, we construct the unlabeled datasets from ac-
2 
challengeDataset [Accessed: July 24, 2014].
3 
#TASK-B2 [Accessed: July 24, 2014].
celerometer and gyroscope measurements and learn sensor speciﬁc codebooks comprising of 512 basis vectors
each and then apply the optimization procedure as described in Section 3.2. For performance evaluation we
construct the cross-validation dataset by combining ‘ADL
4’ and ‘ADL 5’ datasets of the same three subjects and run
a six-fold cross validation using C4.5 decision tree classiﬁer. Table 7 summarizes the performance of the sparsecoding when features are considered from accelerometer
only, gyroscope only and from both the sensors. For comparison we also include the same cross-validation results
as obtained using PCA based feature learning with ECDF
normalization (Section 4.5.1). Additionally we include
the performance of a feature-engineering method using
the feature set proposed by Pl¨otz et at. . The feature
set captures cross-axial relations and previously has been
used successfully on the Opportunity dataset .
Table 7 shows that our sparse-coding framework significantly outperforms the state-of-the-art on the task of analyzing activities of daily living. Sparse-coding achieves
1 -scores of 65.9%, 67.2% and 66.6% respectively
while using features from accelerometer, gyroscope and
both sensors together. The feature-engineering approach
results in scores of 65.0%, 66.0%, and 64.9%, and the
PCA based approach achieves 63.7%, 65.3%, and 63.3%
respectively.
The McNemar tests prove that improvements by sparse-coding are statistically signiﬁcant (p ≪
0.01, each) for all three sensor conﬁgurations.
7. Practical Considerations
When focusing on ubiquitous computing applications
(especially using mobile devices), computational requirements play a non-negligible role in system design. Consequently, we now discuss some practical aspects of our
sparse-coding framework for activity recognition.
The most time-consuming part of our approach is the
construction of the codebook, i.e., the extraction of the
basis vectors. The time that is needed for constructing
the codebook depends, among other things, on the size
of the unlabeled dataset, the number of basis vectors, the
sparsity requirement, and the dimensionality of data, i.e.,
the length of the data windows. The second most timeconsuming task is the training of the supervised classi-
ﬁer using the labeled dataset. However, there is no need
to perform either of these tasks on the mobile device as
online recognition of activities is possible as long as the
codebook and the trained classiﬁer are transferred to the
mobile device from remote servers or cloud.
Accelerometer
Accelerometer + Gyroscope
Sparse-coding
Feature-Engineering (Pl¨otz et al.)
Table 7: Classiﬁcation performance of sparse-coding and baseline algorithms on Opportunity dataset.
No. of basis vector
Time (mili Second)
Un-pruned code-book
Pruned code-book
Figure 12: Runtime requirements for feature extraction
with different codebook sizes, i.e., varying numbers of basis vectors.
The most computationally intensive task that needs to
be performed on the mobile device during online recognition is the mapping of measurements onto the basis vectors, i.e., the optimization task speciﬁed by Equation 6.
To demonstrate the feasibility of using our framework on
mobile devices, we have carried out an experiment where
we measured the runtime of the feature extraction using a
dataset consisting of 1, 000 frames and with varying codebook sizes. The results of this evaluation are shown in
Figure 12. As expected, the runtime increases as the size
of the codebook increases. This increase is linear in the
number of basis vectors, with the pruning of basis vectors
further reducing the runtime. The total time that is needed
to run the feature extraction for 1, 000 frames is under 187
milliseconds (evaluated on a standard desktop PC, solely
for the sake of standardized validation experiments) for a
codebook consisting of 350 basis vectors. With the computational power of contemporary smartphones (such as
the Samsung Galaxy SII, which was used for data collection in the transportation mode task) the sparse-coding
based approach is feasible for recognition rates of up to
5 Hz with moderately large codebooks and frame lengths
(1s). This performance is sufﬁcient for typical activity
analysis tasks .
8. Summary
Ubiquitous computing opens up many possibilities for
activity recognition using miniaturized sensing and smart
data analysis. However, especially for real-world deployments the acquisition of ground truth annotation of activities of interest can be challenging, as activities might be
sporadic and not accessible to well controlled, protocol
driven studies in a naturalistic and hence representable
The acquisition of ground truth annotation in
these problem settings is resource consuming and therefore often limited. This limited access to labeled data renders typical supervised approaches to automatic recognition challenging and often ineffective.
In contrast, the acquisition of unlabeled data is not limited by such constraints. For example, it is straightforward
to equip people with recording devices — most prominently smartphones — without the need for them to follow
any particular protocol beyond very basic instructions.
However, typical heuristic, i.e. hand-crafted, approaches
to recognition common in this ﬁeld are unable to exploit
this vast pool of data and are therefore inherently limited.
We have presented a sparse-coding based framework
for human activity recognition with speciﬁc but not exclusive focus on mobile computing applications. In a case
study on transportation mode analysis we detailed the effectiveness of the proposed approach. Our sparse-coding
technique outperformed state-of-the-art approaches to activity recognition. We effectively demonstrated that even
with limited availability of labeled data, recognition performance of the proposed system massively beneﬁts from
unlabeled resources, far beyond its impact on comparable
approaches such as PCA.
Furthermore, we demonstrated the generalizability of
the proposed approach by evaluating it on a different domain and sensor modalities, namely the analysis of activities of daily living. Our approach outperforms the analyzed state-of-the-art in the Opportunity challenge.
With a view on mobile computing applications we have
shown that — even if computationally intensive — inference is feasible on modern, hand-held devices, thus opening this type of approach for mobile applications.
9. Acknowledgement
The authors would like to thank Dr. P. Hoyer for insightful discussions and comments on early versions of
this work. The authors also acknowledge Samuli Hemminki for providing help and insights with the transportation mode data.
S. Bhattacharya received funding from Future Internet Graduate School (FIGS) and the Foundation of Nokia
Corporation.
Parts of this work have been funded by
the RCUK Research Hub on Social Inclusion through the
Digital Economy (SiDE; EP/G066019/1), and by a grant
from the EPSRC (EP/K004689/1).