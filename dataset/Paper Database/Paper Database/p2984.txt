Evolutionary Computation for Dynamic
Optimization Problems
Shengxiang Yang
Centre for Computational Intelligence
School of Computer Science and Informatics
De Montfort University, United Kingdom
Email: 
 
 
Copyright is held by the author/owner(s).
GECCO’13 Companion, July 6-10, 2013, Amsterdam, The Netherlands.
ACM 978-1-4503-1964-5/13/07.
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Instructor/Presenter — Shengxiang Yang
Education and career history:
PhD, Northeastern University, China, 1999
Worked at King’s College London, University of Leicester, and Brunel
University, 1999-2012
Joined De Montfort University as Professor in Computational Intelligence
(CI) in July 2012
Director of Centre for Computational Intelligence (CCI)
Research interests:
Evolutionary computation (EC) and nature-inspired computation
Dynamic optimisation and multi-objective optimisation
Relevant real-world applications
Over 160 publications and over £1M funding as the PI
Editor, Evolutionary Computation and 3 other journals
Chair of two IEEE CIS Task Forces
EC in Dynamic and Uncertain Environments
Intelligent Network Systems
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Centre for CI (CCI), De Montfort University
CCI (www.cci.dmu.ac.uk):
Mission: Developing fundamental theoretical and practical solutions to real
world problems using a variety of CI paradigms
Members: 15 staff, 4 research fellows, 30+ PhDs, visiting researchers
Components: 3 Labs (Robotics, Gaze, Game Programming) & Bio-Health
Informatics Research Group
Research Councils: EPSRC, TSB, Royal Academy of Engineering, Royal
Society, KTP, Innovation Fellowships, HOPE foundation
Government: Leicester City Council, DTI
Industries: Lachesis, EMDA, RSSB, Network Rail, etc.
Collaborations:
Universities: UK, USA, Spain, and China
Industries and local governments
Teaching/Training:
DTP-IS: University Doctor Training Programme in Intelligent Systems
MSc Intelligent Systems, MSc Intelligent Systems & Robotics
BSc Artiﬁcial Intelligence with Robotics
YouTube page: 
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Outline of the Tutorial
Part I: Set up the stage
Introduction to evolutionary computation (EC)
EC for dynamic optimization problems (DOPs): Concept and motivation
Benchmark and test problems
Performance measures
Part II: Play the game
EC approaches for DOPs
Case studies
Relevant issues
Future work
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
What Is Evolutionary Computation (EC)?
EC encapsulates a class of stochastic optimization algorithms, dubbed
Evolutionary Algorithms (EAs)
An EA is an optimisation algorithm that is
Generic: a black-box tool for many problems
Population-based: evolves a population of candidate solutions
Stochastic: uses probabilistic rules
Bio-inspired: uses principles inspired from biological evolution
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Design and Framework of an EA
Given a problem to solve, ﬁrst consider two key things:
Representation of solution into individual
Evaluation or ﬁtness function
Then, design the framework of an EA:
Initialization of population
Evolve the population
Selection of parents
Variation operators (recombination &
Selection of offspring into next
generation
Termination condition: a given number
of generations
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
EC Applications
EAs are easy-to-use: No strict requirements to problems
Widely used for optimisation and search problems
Financial and economical systems
Transportation and logistics systems
Industry engineering
Automatic programming, art and music design
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
EC for Optimisation Problems
Traditionally, research on EAs has focused on static problems
Aim to ﬁnd the optimum quickly and precisely
But, many real-world problems are dynamic optimization problems
(DOPs), where changes occur over time
In transport networks, travel time between nodes may change
In logistics, customer demands may change
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
What Are DOPs?
In general terms, “optimization problems that change over time” are
called dynamic problems/time-dependent problems
F = f(⃗x, ⃗φ, t)
– ⃗x: decision variable(s); ⃗φ: parameter(s); t: time
DOPs: special class of dynamic problems that are solved online by an
algorithm as time goes by
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Why DOPs Challenge EC?
For DOPs, optima may move over time in the search space
Challenge: need to track the moving optima over time
DOPs challenge traditional EAs
Once converged, hard to escape from an old optimum
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Why EC for DOPs?
Many real-world problems are DOPs
EAs, once properly enhanced, are good choice
Inspired by natural/biological evolution, always in dynamic environments
Intrinsically, should be ﬁne to deal with DOPs
Many events on EC for DOPs recently
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Relevant Events
Books (Monograph or Edited):
Yang & Yao, 2013; Yang et al., 2007; Morrison, 2004; Weicker, 2003;
Branke, 2002
PhD Theses:
Mavrovouniotis, 2013; du Plessis, 2012; Li, 2011; Nguyen, 2011; Simoes,
Journal special issues:
Neri & Yang, 2010; Yang et al., 2006; Jin & Branke, 2006; Branke, 2005
Workshops and conference special sessions:
EvoSTOC : part of Evo*
ECiDUE : part of IEEE CEC
EvoDOP (’99, ’01, ’03, ’05, ’07, ’09): part of GECCO
IEEE Symposium on CIDUE 
IEEE Competitions: within IEEE CEC 2009 & CEC 2012
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Benchmark and Test DOPs
Basic idea: change base static problem(s) to create DOPs
Real space:
Switch between different functions
Move/reshape peaks in the ﬁtness landscape
Binary space:
Switch between ≥2 states of a problem: knapsack
Use binary masks: XOR DOP generator (Yang & Yao’05)
Combinatorial space:
Change decision variables: item weights/proﬁts in knapsack problems
Add/delete decision variables: new jobs in scheduling, nodes
added/deleted in network routing problems
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
The DF1 Generator
Proposed by Morrison & De Jong 
The base landscape in the D-dimensional real space:
f(⃗x) = max
(xj −Xij)2
– ⃗x = (x1, · · · , xD): a point in the landscape; p: number of peaks
– Hi, Ri, Xi = (Xi1, · · · , XiD): height, slope, center of peak i
The dynamics is controlled by a logistics function:
∆t = A · ∆t−1 · (1 −∆t−1)
– A ∈[1.0, 4.0]: a constant; ∆t: step size of changing a parameter
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Moving Peaks Benchmark (MPB) Problem
Proposed by Branke 
The MPB problem in the D-dimensional space:
F(⃗x, t) = max
1 + Wi(t) PD
j=1 (xj(t) −Xij(t))2
– Wi(t), Hi(t), Xi(t) = {Xi1 · · · XiD}: height, width, location of peak i at t
The dynamics:
Hi(t) = Hi(t −1) + height_severity ∗σ
Wi(t) = Wi(t −1) + width_severity ∗σ
⃗r + ⃗vi(t −1)
((1 −λ)⃗r + λ⃗vi(t −1))
⃗Xi(t) = ⃗Xi(t)(t −1) + ⃗vi(t)
– σ ∼N(0, 1); λ: correlated parameter
– ⃗vi(t): shift vector, which combines random vector ⃗r and ⃗vi(t −1) and is
normalized to the shift length s
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Dynamic Knapsack Problems (DKPs)
Static knapsack problem:
Given n items, each with a weight and a proﬁt, and a knapsack with
a ﬁxed capacity, select items to ﬁll up the knapsack to maximize the
proﬁt while satisfying the knapsack capacity constraint
Constructed by changing weights and proﬁts of items, and/or knapsack
capacity over time as:
Max f(⃗x(t), t) =
pi(t) · xi(t), s. t. :
wi(t) · xi(t) ≤C(t)
– ⃗x(t) ∈{0, 1}n: a solution at time t
– xi(t) ∈{0, 1}: indicates whether item i is included or not
– pi(t) and wi(t): proﬁt and weight of item i at t
– C(t): knapsack capacity at t
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
The XOR DOP Generator
The XOR DOP generator can create DOPs from any binary f(⃗x) by an
XOR operator “⊕” 
Suppose the environment changes every τ generations
For each environmental period k = ⌊t/τ⌋, do:
M(0)=0000000000
M(2)=0111010011
M(3)=1101000101
M(1)=1001011010
State 0 (Initial State)
T(0)=1001011010
T(1)=1110001001
T(2)=1010010110
Create a template Tk with ρ ∗l ones
Create a mask ⃗M(k) incrementally
⃗M(0) = ⃗0 (the initial state)
⃗M(k + 1) = ⃗M(k) ⊕⃗T(k)
Evaluate an individual:
f(⃗x, t) = f(⃗x ⊕⃗M(k))
τ and ρ controls the speed and severity of change respectively
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Constructing Cyclic Dynamic Environments
Can extend the XOR DOP generator to create cyclic environments:
M(2)=1111111111
M(1)=1001011010
(Initial State)
Base State 0
Base State 1
M(3)=0110100101
Base State 3
M(0)=0000000000
Base State 2
T(0)=1001011010
Partition Templates:
T(1)=0110100101
Construct K templates ⃗T(0),· · · ,⃗T(K −1)
Form a partition of the search space
Each contains ρ × l = l/K ones
Create 2K masks ⃗M(i) as base states
⃗M(0) = ⃗0 (the initial state)
⃗M(i + 1) = ⃗M(i) ⊕⃗T(i%K), i = 0,· · · , 2K −1
Cycle among ⃗M(i)’s every τ generations
f(⃗x, t) = f(⃗x ⊕⃗M(It )) = f(⃗x ⊕⃗M(k%(2K)))
– k = ⌊t/τ⌋: environmental index
– It = k%(2K): mask index
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Constructing Cyclic Environments with Noise
We can also construct cyclic environments with noise:
Each time before a base state is entered, it is bitwise changed with a
small probability
M(2)=0111111111
Base State 2
M(1)=1001011011
(Initial State)
Base State 0
Base State 1
M(0)=0000000000
M(3)=0110110101
Base State 3
Bit 1 changed
Bit 10 changed
Bit 6 changed
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Dynamic Traveling Salesman Problems
Stationary traveling salesman problem (TSP):
Given a set of cities, ﬁnd the shortest route that visits each city once and
Dynamic TSP (DTSP):
May involve dynamic cost (distance) matrix
D(t) = {dij(t)}n∗n
– dij(t): cost from city i to j; n: the number of cities
The aim is to ﬁnd a minimum-cost route containing all cities at time t
DTSP can be deﬁned as f(x, t):
f(x, t) = Min(
dxi ,xi+1(t))
where xi ∈1, · · · , n. If i ̸= j, xi ̸= xj, and xn+1 = x1
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Dynamic Permutation Benchmark Generator
The dynamic benchmark generator for permutation-encoded problems
(DBGP) can create a DOP from any stationary TSP/VRP by swapping
Generate a random vector ⃗r(T) that
contains all objects every f iterations
Generate another randomly re-order vector
⃗r ′(T) that contains only the ﬁrst m × n
objects of ⃗r(T)
Modify the encoding of the problem instance
with m × n pairwise swaps
More details: M. Mavrovouniotis, S. Yang, & X. Yao . PPSN XII, Part II,
LNCS 7492, pp. 508–517
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Effect on Algorithms
Similar with the XOR DOP generator, DBGP shifts the
population of an alg. to new location in the ﬁtness landscape
The individual with the same encoding as before a change will have a
different cost after the change
Can extend for cyclic and cyclic with noise environments
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Generalized DOP Benchmark Generator (GDBG)
Proposed by Li & Yang , GDBG uses the model below:
.... .....
.... .....
Instance k
Instance k
Instance 2
Instance 2
Instance 1
Instance 1
Instance 1
Instance k
Instance 2
Generalized DBG
Binary Space
Real Space
Combinatory Space
.... .....
In GDBG, DOPs are deﬁned as:
F = f(x, φ, t),
– φ: system control parameter
Dynamism results from tuning φ of the current environment
φ(t + 1) = φ(t) ⊕∆φ
– ∆φ: deviation from the current control parameter(s)
The new environment at t + 1 is as follows:
f(x, φ, t + 1) = f(x, φ(t) ⊕∆φ, t)
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
GDBG: Dynamic Change Types
Change types:
Small step: ∆φ = α · ∥φ∥· rand()
Large step: ∆φ = ∥φ∥· (α + (1 −α)rand())
Random: ∆φ = ∥φ∥· rand()
Chaotic: φ(t + 1) = A · φ(t) · (1 −φ(t)/∥φ∥)
Recurrent: φ(t + 1) = φ(t%P)
Recurrent with nosy: φ(t + 1) = φ(t%P) + α · ∥φ∥· rand()
More details:
C. Li & S. Yang . SEAL’08, LNCS 5361, pp. 391–400
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
DOPs: Classiﬁcation
Classiﬁcation criteria:
Time-linkage: Does the future behaviour of the problem depend on the
current solution?
Predictability: Are changes predictable?
Visibility: Are changes visible or detectable
Cyclicity: Are changes cyclic/recurrent in the search space?
Factors that change: objective, domain/number of variables, constraints,
and/or other parameters
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
DOPs: Common Characteristics
Common characteristics of DOPs in the literature:
Most DOPs are non time-linkage problems
For most DOPs, changes are assumed to be detectable
In most cases, the objective function is changed
Many DOPs have unpredictable changes
Most DOPs have cyclic/recurrent changes
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Performance Measures
For EC for stationary problems, 2 key performance measures
Convergence speed
Success rate of reaching optimality
For EC for DOPs, over 20 measures 
Optimality-based performance measures
Collective mean ﬁtness or mean best-of-generation
Adaptation
Ofﬂine error and ofﬂine performance
Mean distance to optimum at each generation
Behaviour-based performance measures
Reactivity
Robustness
Satisﬁcability
Diversity measures
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Performance Measures: Examples
Collective mean ﬁtness (mean best-of-generation):
j=1 FBOGij )
– G and N: number of generations and runs, resp.
– FBOGij : best-of-generation ﬁtness of generation i of run j
Adaptation performance 
(fbest(t)/fopt(t))
Accuracy 
(fbest(i) −fopt(i))
– fbest(i): best ﬁtness for environment i (best before change)
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Part II: Play the Game
EC approaches for DOPs
Case studies
Relevant issues
Future work
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
EC for DOPs: First Thinking
Recap: traditional EAs are not good for DOPs
Goal: to track the changing optimum
How about restarting an EA after a change?
Natural and easy choice
But, not good choice because:
It may be inefﬁcient, wasting computational resources
It may lead to very different solutions before and after a change.
For real-world problems, we may expect solutions to remain similar
Extra approaches are needed to enhance EAs for DOPs
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
EC for DOPs: General Approaches
Many approaches developed to enhance EAs for DOPs
Typical approaches:
Memory: store and reuse useful information
Diversity: handle convergence directly
Multi-population: co-operate sub-populations
Adaptive: adapt generators and parameters
Prediction: predict changes and take actions in advance
They have been applied to different EAs for DOPs
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Memory Approaches
Cyclic DOPs: change cyclically among a ﬁxed set of states
Memory works by storing and reusing useful information
Two classes regarding how to store information
Implicit memory: uses redundant representations
Multiploidy and dominance 
Dualism mechanisms 
Explicit memory: uses extra space to store information
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Implicit Memory: Diploid Genetic Algorithm
Dominance Scheme
Chromosome 1
Chromosome 2
External Environment
Evaluating
Same Phenotypic
Genotype−to−Phenotype
Genotypic Alleles:
Phenotypic Alleles:
Dominance Scheme
Ng & Wong 
Lewis et al. 
Each individual has a pair of chromosomes
Dominance scheme maps genotype to phenotype
Dominance scheme may change or be adaptive (Uyar & Harmanci,
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Explicit Memory Approaches
Basic idea: use extra memory
With time, store useful information of the pop into memory
When a change occurs, use memory to track new optimum
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Explicit Memory: Direct vs Associative
Direct memory: store good solutions 
Associative memory: store environmental information + good solutions
 
memory solution
2. Replace one
1. Select best
pop member
Main Population
Retrieve memory
Update memory
Environment information
Main Population
3. Replace
1. Extract
1. Associate
2. Associate
3. Replace
Retrieve memory
Update memory
Direct Memory
Associative Memory
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Associative Memory Based Genetic Algorithm
Idea: Use allele distribution (AD) ⃗D to represent environmental info.
Allele distribution vector
Main Population
3. Replace
3. Replace
2. Associate
1. Extract allele
distribution vector
Update memory
1. Associate
Retrieve memory
Use memory to store <⃗D, S> pairs
Update memory by similarity policy
Re-evaluate memory every generation. If
change detected
Extract best memory AD: ⃗DM
Create solutions by sampling ⃗DM
Replace them into the pop randomly
S. Yang . EvoWorkshops’06, pp. 788–799
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Diversity Approaches: Random Immigrants
Convergence is the key problem in metaheuristics for DOPs
Random immigrants:
Each generation, insert some random individuals (called random
immigrants) into the population to maintain diversity
When optimum moves, random immigrants nearby take action to draw the
pop to the new optimum
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Memory-Based Immigrants
Random immigrants maintain the diversity while memory adapts an
algorithm directly to new environments
Memory-based immigrants: uses memory to guide immigrants
towards current environment
Re-evaluate the memory every generation
Retrieve the best memory point BM(t) as the base
Generate immigrants by mutating BM(t) with a prob.
Replace worst members in the population by these immigrants
memory−based immigrants
memory points
Search Space
current best memory point
random immigrants
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Experimental Results: Immigrants Based GAs
Cyclic Dynamic OneMax Function, τ = 25, ρ = 0.1
Random Dynamic OneMax Function, τ = 25, ρ = 0.1
Best-Of-Generation Fitness
Generation
Best-Of-Generation Fitness
Generation
Memory-based immigrants GA (MIGA) signiﬁcantly beats other GAs
More details:
S. Yang . Evol. Comput., 16(3): 385–416
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Hybrid Immigrants Approach
Combines elitism, dualism and random immigrants ideas
Dualism: Given ⃗x = (x1, · · · , xl) ∈{0, 1}l, its dual is deﬁned as
⃗xd = dual(⃗x) = (xd
1 , · · · , xd
l ) ∈{0, 1}l
Each generation t, select the best individual from previous generation,
E(t −1), to generate immigrants
Elitism-based immigrants: Generate a set of individuals by mutating
E(t −1) to address slight changes
Dualism-based immigrants: Generate a set of individuals by mutating the
dual of E(t −1) to address signiﬁcant changes
Random immigrants: Generate a set of random individuals to address
medium changes
Replace these immigrants into the population
More details:
S. Yang & R. Tinos . Int. J. of Autom. & Comp., 4(3): 243–254
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Experimental Results: Hybrid Immigrants GA
Offline Performance
OneMax, τ = 10
Offline Performance
Royal Road, τ = 10
Offline Performance
Deceptive, τ = 10
Offline Performance
Knapsack, τ = 10
Offline Performance
OneMax, τ = 100
Offline Performance
Royal Road, τ = 100
Offline Performance
Deceptive, τ = 100
Offline Performance
Knapsack, τ = 100
Hybrid immigrants improve GA’s performance for DOPs efﬁciently
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Multi-Populations: Shifting Balance
Multi-population scheme uses co-operating sub-populations
Shifting Balance GA :
A core population exploits the promising area
Several colonies explore the search space
Population
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Multi-Populations: Self-Organizing Scouts
Self-organizing scouts (SOS) GA 
The parent population explores the search space
A child population is split under certain conditions
Child populations search limited promising areas
Population
Population
Population
population 2
population 1
population 1
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Multi-Populations: Clustering PSO
Particle Swarm Optimisation (PSO):
Motivated by the social behaviour of swarm of animals, e.g., bird ﬂocking
and ﬁsh schooling
PSO has been used to address DOPs
Recently, we developed a Clustering PSO (CPSO) for DOPs
Use a clustering technique to construct sub-swarms
Each sub-swarm will search among one peak quickly
Overlapping and convergence check
Strategies to response to changes
More details:
S. Yang & C. Li . IEEE Trans Evol Comput, 14(6): 93–106
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Demo: Clustering PSO for DOPs
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Adaptive Approaches
Aim: Adapt operators/parameters, usually after a change
Hypermutation : raise the mutation rate
temporarily
Hyper-selection : raise the selection pressure
temporarily
Hyper-learning : raise the learning rate for
Population-Based Incremental Learning (PBIL) temporarily
Combined: Hyper-selection and hyper-learning with re-start or
hypermutation
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Prediction Approaches
For some DOPs, changes exhibit predictable patterns
Techniques (forecasting, Kalman ﬁlter, etc.) can be used to predict
The location of the next optimum after a change
When the next change will occur and which environment may appear
Some relevant work: see Simões & Costa 
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Remarks on Enhancing Approaches
No clear winner among the approaches
Memory is efﬁcient for cyclic environments
Multi-population is good for tracking competing peaks
The search ability will decrease if too many sub-populations
Diversity schemes are usually useful
Guided immigrants may be more efﬁcient
Different interaction exists among the approaches
Golden rule: balancing exploration & exploitation over time
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Case Study: Dynamic Routing in MANETs – 1
Shortest path routing problem (SPRP) in a ﬁxed network:
Find the shortest path between source and destination in a ﬁxed topology
More and more mobile ad hoc networks (MANETs) appear where the
topology keeps changing
Dynamic SPRP (DSPRP)in MANETs:
Find a series of shortest paths in a series of highly-related network
topologies
We model the network dynamics as follows:
For each change, a number of nodes are randomly selected to sleep or
wake up based on their current status
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Case Study: Dynamic Routing in MANETs – 2
A specialized GA for the DSPRP:
Path-oriented encoding
Tournament selection
Path-oriented crossover and mutation with repair
Enhancements: Immigrants and memory approaches
Experimental results:
Both immigrants and memory enhance GA’s performance for the DSPRP
in MANETs.
Immigrants schemes show their power in acyclic environments
Memory related schemes work well in cyclic environments
More details:
S. Yang, H. Cheng, & F. Wang . IEEE Trans SMC Part C: Appl. &
Rev., 40(1): 52–63
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Case Study: Dynamic Vehicle Routing – 1
The basic Vehicle Routing Problem (VRP):
A number of vehicles with a ﬁxed capacity need to satisfy the demand of all
customers, starting from and ﬁnishing to the depot
Dynamic extensions of VRP that model real-world scenarios:
Dynamic demands
Trafﬁc factors
Dynamic test cases can be generated using the DBGP generator
 
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Case Study: Dynamic Vehicle Routing – 2
ACO algorithms with immigrants schemes are used to address the
dynamic VRP with trafﬁc factors
Each ant constructs a solution that contains all the routes of the vehicles
Diversity is maintained using immigrant ants
Experimental results:
ACO with elitism-based immigrants outperforms other ACO algorithms
ACO with random immigrants is outperformed by other ACO algorithms
Usually, ACO with guided diversity performs well for DOPs
More details:
M. Mavrovouniotis & S. Yang . EvoApplications’12, LNCS 7248,
pp. 519–528
M. Mavrovouniotis & S. Yang . CEC’12
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Case Study: GA for Dynamic TSP
Dynamic TSP:
144 Chinese cities, 1 geo-stationary saterllite, and 3 mobile satellites
Find the path that cycles each city and satellite once with the minimum
length over time
Solver: A GA with memory and other schemes
More details:
C. Li, M. Yang, & L. Kang . SEAL’06, LNCS 4247, pp. 236–243
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Theoretical Development
So far, mainly empirical studies
Theoretical analysis has just appeared
Runtime analysis:
Stanhope & Daida ﬁrst analyzed a (1+1) EA on the dynamic bit
matching problem (DBMP)
Droste analyzed the ﬁrst hitting time of a (1+1) ES on the DBMP
Rohlfshagen et al. analyzed how the magnitude and speed of
change may affect the performance of the (1+1) EA on two functions
constructed from the XOR DOP generator
Analysis of dynamic ﬁtness landscape:
Branke et al. analyzed the changes of ﬁtness landscape due to
changes of the underlying problem instance
Richter analyzed the properties of spatio-temporal ﬁtness
landscapes constructed from Coupled Map Lattices (CML)
Tinos and Yang analyzed the properties of the XOR DOP generator
based on the dynamical system approach of the GA
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
EC for Dynamic Multi-objective Optimization
So far, mainly dynamic single-objective optimization
Dynamic multi-objective optimization problems (DMOPs): even more
challenging
A few studies have addressed EC for DMOPs
Farina et al. classiﬁed DMOPs based on the changes on the Pareto
optimal solutions
Goh & Tan proposed a competitive-cooperative coevolutionary
algorithm for DMOPs
Zeng et al. proposed a dynamic orthogonal multi-objective EA
(DOMOEA) to solve a DMOP with continuous decision variables
Zhang & Qian proposed an artiﬁcial immune system to solve
constrained DMOPs
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Challenging Issues
Detecting changes:
Most studies assume that changes are easy to detect or visible to an
algorithm whenever occurred
In fact, changes are difﬁcult to detect for many DOPs
Understanding the characteristics of DOPs:
What characteristics make DOPs easy or difﬁcult?
The work has started, but needs much more effort
Analysing the behaviour of EAs for DOPs:
Requiring more theoretical analysis tools
Addressing more challenging DOPs and EC methods
Big question: Which EC methods for what DOPs?
Real world applications:
How to model real-world DOPs?
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Future Work
The domain has attracted a growing interest recently
But, far from well-studied
New approaches needed: esp. hybrid approaches
Theoretical analysis: greatly needed
EC for DMOPs: deserves much more effort
Real world applications: also greatly needed
Fields: logistics, transport, MANETs, data streams, social networks, ...
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
EC for DOPs: challenging but important
The domain is still young and active:
More challenges to be taken regarding approaches, theory, and
applications
More young researchers are greatly welcome!
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Acknowledgements
Two EPSRC funded projects on EC for DOPs
“EAs for DOPs: Design, Analysis and Applications”
Linked project among Brunel Univ. ,
Univ. of Birmingham, BT, and Honda
Funding/Duration: over £600K / 3.5 years 
 
“EC for Dynamic Optimisation in Network Environments”
Linked project among DMU, Univ. of Birmingham, RSSB, and Network Rail
Funding/Duration: ∼£1M / 4 years 
 
Research team members:
Research Fellows: Dr. Hui Cheng, Dr. Crina Grosan, Dr. Changhe Li,
Dr. Michalis Mavrovouniotis
PhD students: Changhe Li, Michalis Mavrovouniotis, Lili Liu, Hongfeng
Wang, Yang Yan
Research cooperators:
Prof. Xin Yao, Prof. Juergen Branke, Dr. Renato Tinos, Dr. Hendrik Richter,
Dr. Trung Thanh Nguyen, etc.
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
Relevant Information
IEEE CIS Task Force on EC in Dynamic and Uncertain Environments
 
Maintained by Shengxiang Yang
Source codes:
 
IEEE Competitions:
2009 Competition on EC in Dynamic & Uncertain Environments:
 
2012 Competition on EC for DOPs:
 
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
References – 1
J. Branke . Memory enhanced evolutionary algorithms for changing
optimization problems. CEC’99, pp. 1875–1882
J. Branke . Evolutionary Optimization in Dynamic Environments. Kluwer Academic
Publishers
J. Branke, E. Salihoglu & S. Uyar . Towards an analysis of dynamic environments.
GECCO’05, pp. 1433–1439
H.G. Cobb & J.J. Grefenstette . Genetic algorithms for tracking changing
environments. Proc. ICGA, pp. 523–530
C. Cruz, J. Gonzanlez, & D. Pelta . Optimization in dynamic environments: A survey
on problems, methods and measures. Soft Comput., 15: 1427–1448
S. Droste Analysis of the (1+1) ea for a dynamically changing onemax-variant.
CEC’02, pp. 55–60
M. Farina, K. Deb, & P. Amato . Dynamic multiobjective optimization problems: test
cases, approximations, and applications. IEEE Trans. Evol. Comput., 8(5): 425–442
C. Goh & K.C. Tan . A competitive-cooperative coevolutionary paradigm for dynamic
multiobjective optimization. IEEE Trans. Evol. Comput., 13(1): 103–127
Y. Jin & J. Branke . Evolutionary optimization in uncertain environments–A survey.
IEEE Trans. Evol. Comput., 9(3): 303–317
10 R.W. Morrison . Designing Evolutionary Algorithms for Dynamic Environments.
11 E.H.J. Lewis & G. Ritchie . A comparison of dominance mechanisms and simple
mutation on non-stationary problems. PPSN V, pp. 139–148.
12 R.W. Morrison & K.A. De Jong . A test problem generator for
non-stationary environments. CEC’99, pp. 2047–2053
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
References – 2
13 K.P. Ng & K.C. Wong . A new diploid scheme and dominance change
mechanism for non-stationary function optimisation. ICGA 6, pp. 159–166
14 T.T. Nguyen, S. Yang, & J. Branke . Evolutionary dynamic optimization: A survey of
the state of the art. Swarm & Evol. Comput., 6: 1–24
15 F. Oppacher & M. Wineberg . The Shifting balance genetic algorithm: Improving the
GA in a dynamic environment. GECCO’99, vol. 1, pp. 504–510
16 H. Richter . Evolutionary optimization and dynamic ﬁtness landscapes: From
reaction-diffusion systems to chaotic cml. Evolutionary Algorithms and Chaotic Systems,
Springer, pp. 409–446.
17 P. Rohlfshagen, P.K. Lehre, & X. Yao . Dynamic evolutionary optimisation: An
analysis of frequency and magnitude of change. GECCO’09, pp. 1713–1720
18 S.A. Stanhope & J.M. Daida . (1+1) genetic algorithm ﬁtness dynamics in a
changing environments. CEC’99, vol. 3, pp. 1851–1858
19 R. Tinos & S. Yang An analysis of the XOR dynamic problem generator based on
the dynamical system. PPSN XI, LNCS 6238, Part I, pp. 274–283
20 A. Simões & E. Costa . Improving prediction in evolutionary algorithms for dynamic
environments. GECCO’09, pp. 875–882
21 K. Trojanowski & Z. Michalewicz . Searching for optima in non-stationary
environments. CEC’99, vol. 3, pp. 1843–1850
22 A.S. Uyar & A.E. Harmanci . A new population based adaptive domination change
mechanism for diploid genetic algorithms in dynamic environments. Soft Comput., 9:
23 S. Yang . Non-stationary problem optimization using the primal-dual
genetic algorithm. CEC’03, pp. 2246–2253
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013
References – 3
24 S. Yang, Y. Jiang, & T.T. Nguyen . Metaheuristics for dynamic combinatorial
optimization problems. IMA J of Management Math., in press
25 S. Yang, Y.-S. Ong & Y. Jin . Evolutionary Computation in Dynamic and Uncertain
Environments. Springer
26 S. Yang & H. Richter . Hyper-learning for population-based incremental learning in
dynamic environments. CEC’09, pp. 682–689
27 S. Yang & R. Tinos . Hyper-selection in dynamic environments. CEC’08,
pp. 3185-3192
28 S. Yang & X. Yao . Experimental study on population-based incremental learning
algorithms for dynamic optimization problems. Soft Comput., 9: 815–834
29 S. Yang & X. Yao . Population-based incremental learning with associative memory
for dynamic environments. IEEE Trans Evol Comput, 12: 542–561
30 S. Yang & X. Yao . Evolutionary Computation for Dynamic Optimization Problems.
31 K. Weicker . Evolutionary Algorithms and Dynamic Optimization Problems. Der
Andere Verlag
32 S. Zeng et al. . A dynamic multi-objective evolutionary algorithm based on an
orthogonal design. CEC’06, pp. 573–580
33 Z. Zhang & S. Qian . Artiﬁcial immune system in dynamic environments solving
time-varying non-linear constrained multi-objective problems. Soft Comput., 15(7):
Shengxiang Yang (De Montfort University)
Tutorial: EC for DOPs
GECCO’13, 7/7/2013