Human pose estimation via Convolutional Part
Heatmap Regression
Adrian Bulat and Georgios Tzimiropoulos
Computer Vision Laboratory, University of Nottingham
{adrian.bulat,yorgos.tzimiropoulos}@nottingham.ac.uk
Abstract. This paper is on human pose estimation using Convolutional
Neural Networks. Our main contribution is a CNN cascaded architecture
speciﬁcally designed for learning part relationships and spatial context,
and robustly inferring pose even for the case of severe part occlusions.
To this end, we propose a detection-followed-by-regression CNN cascade. The ﬁrst part of our cascade outputs part detection heatmaps
and the second part performs regression on these heatmaps. The bene-
ﬁts of the proposed architecture are multi-fold: It guides the network
where to focus in the image and eﬀectively encodes part constraints
and context. More importantly, it can eﬀectively cope with occlusions
because part detection heatmaps for occluded parts provide low conﬁdence scores which subsequently guide the regression part of our network to rely on contextual information in order to predict the location
of these parts. Additionally, we show that the proposed cascade is ﬂexible enough to readily allow the integration of various CNN architectures
for both detection and regression, including recent ones based on residual learning. Finally, we illustrate that our cascade achieves top performance on the MPII and LSP data sets. Code can be downloaded from
 
Keywords: Human pose estimation, part heatmap regression, Convolutional Neural Networks
Introduction
Articulated human pose estimation from images is a Computer Vision problem
of extraordinary diﬃculty. Algorithms have to deal with the very large number
of feasible human poses, large changes in human appearance (e.g. foreshortening,
clothing), part occlusions (including self-occlusions) and the presence of multiple
people within close proximity to each other. A key question for addressing these
problems is how to extract strong low and mid-level appearance features capturing discriminative as well as relevant contextual information and how to model
complex part relationships allowing for eﬀective yet eﬃcient pose inference. Being capable of performing these tasks in an end-to-end fashion, Convolutional
Neural Networks (CNNs) have been recently shown to feature remarkably robust
 
Adrian Bulat, Georgios Tzimiropoulos
part detection network
regression network
part heatmaps
regression
Fig. 1: Proposed architecture: Our CNN cascade consists of two connected
deep subnetworks. The ﬁrst one (upper part in the ﬁgure) is a part detection
network trained to detect the individual body parts using a per-pixel sigmoid
loss. Its output is a set of N part heatmaps. The second one is a regression
subnetwork that jointly regresses the part heatmaps stacked along with the input
image to conﬁdence maps representing the location of the body parts.
Fig. 2: Paper’s main idea: The ﬁrst row shows the produced part detection
heatmaps for both visible (neck, head, left knee) and occluded (ankle, wrist,
right knee) parts (drawn with a dashed line). Observe that the conﬁdence for
the occluded parts is much lower than that of the non-occluded parts but still
higher than that of the background providing useful context about their rough
location. The second row shows the output of our regression subnetwork. Observe
that the conﬁdence for the visible parts is higher and more localized and clearly
the network is able to provide high conﬁdence for the correct location of the
occluded parts. Note: image taken from LSP test set.
Human pose estimation via Convolutional Part Heatmap Regression
performance and high part localization accuracy. Yet, the accurate estimation of
the locations of occluded body parts is still considered a diﬃcult open problem.
The main contribution of this paper is a CNN cascaded architecture speciﬁcally
designed to alleviate this problem.
There is a very large amount of work on the problem of human pose estimation. Prior to the advent of neural networks most prior work was primarily
based on pictorial structures which model the human body as a collection of
rigid templates and a set of pairwise potentials taking the form of a tree structure, thus allowing for eﬃcient and exact inference at test time. Recent work includes sophisticated extensions like mixture, hierarchical, multimodal and strong
appearance models , non-tree models as well as cascaded/sequential
prediction models like pose machines .
More recently methods based on Convolutional Neural Networks have been
shown to produce remarkable performance for a variety of diﬃcult Computer
Vision tasks including recognition , detection and semantic segmentation outperforming prior work by a large margin. A key feature of these
approaches is that they integrate non-linear hierarchical feature extraction with
the classiﬁcation or regression task in hand being also able to capitalize on
very large data sets that are now readily available. In the context of human
pose estimation, it is natural to formulate the problem as a regression one in
which CNN features are regressed in order to provide joint prediction of the
body parts . For the case of non-visible parts though, learning the complex mapping from occluded part appearances to part locations is hard and the
network has to rely on contextual information (provided from the other visible parts) to infer the occluded parts’ location. In this paper, we show how to
circumvent this problem by proposing a detection-followed-by-regression CNN
cascade for articulated human pose estimation.
Main Contribution
The proposed architecture is a CNN cascade consisting of two components (see
Fig. 1): the ﬁrst component (part detection network) is a deep network for part
detection that produces detection heatmaps, one for each part of the human
body. We train part detectors jointly using pixelwise sigmoid cross entropy loss
function . The second component is a deep regression subnetwork that jointly
regresses the location of all parts (both visible and occluded), trained via con-
ﬁdence map regression . Besides the two subnetworks, the key feature of
the proposed architecture is the input to the regression subnetwork: we propose
to use a stacked representation comprising the part heatmaps produced by the
detection network. The proposed representation guides the network where to
focus and encodes structural part relationships. Additionally, our cascade does
not suﬀer from the problem of regressing occluded part appearances: because
the part heatmaps for the occluded parts provide low conﬁdence scores, they
subsequently guide the regression part of our network to rely on contextual information (provided by the remaining parts) in order to predict the location of
these parts. See Fig. 2 for a graphical representation of our paper’s main idea.
Adrian Bulat, Georgios Tzimiropoulos
The proposed cascade is very simple, can be trained end-to-end, and is ﬂexible enough to readily allow the integration of various CNN architectures for
both our detection and regression subnetworks. To this end, we illustrate two
instances of our cascade, one based on the more traditional VGG converted to
fully convolutional (FCN) and one based on residual learning .
Both architectures achieve top performance on both MPII and LSP 
data sets.
Closely Related Work
Overview of prior work. Recently proposed methods for articulated human
pose estimation using CNNs can be classiﬁed as detection-based or
regression-based . Detection-based methods are relying on powerful CNN-based part detectors which are then combined using a graphical
model or reﬁned using regression . Regression-based methods try to
learn a mapping from image and CNN features to part locations. A notable development has been the replacement of the standard L2 loss between the predicted
and ground truth part locations with the so-called conﬁdence map regression
which deﬁnes an L2 loss between predicted and ground truth conﬁdence maps
encoded as 2D Gaussians centered at the part locations (these regression
conﬁdence maps are not to be confused with the part detection heatmaps proposed in our work). As a mapping from CNN features to part locations might
be diﬃcult to learn in one shot, regression-based methods can be also applied
sequentially (i.e. in a cascaded manner) . Our CNN cascade is based on
a two-step detection-followed-by-regression approach (see Fig. 1) and as such is
related to both detection-based and regression-based methods .
Relation to regression-based methods. Our detection-followed-by-regression
cascade is related to which can be seen as a two-step regression-followedby-regression approach. As a ﬁrst step performs conﬁdence map regression
(based on an L2 loss) as opposed to our part detection step which is learnt
via pixelwise sigmoid cross entropy loss. Then, in pre-conﬁdence maps are
used as input to a subsequent regression network. We empirically found that
such maps are too localised providing small spatial support. In contrast, our
part heatmaps can provide large spatial context for regression. For comparison
purposes, we implemented the idea of using two diﬀerent architectures, one
based on VGG-FCN and one on residual learning, and show that the proposed
detection-followed-by-regression cascade outperforms it for both cases (see section 4.2). In order to improve performance, regression methods applied in a
sequential, cascaded fashion have been recently proposed in . In particular, has recently reported outstanding results on both LSP and MPII 
data sets using a six-stage CNN cascade.
Relation to detection-based methods. Regarding detection-based methods, has produced state-of-the-art results on both MPII and LSP data sets
using a VGG-FCN network to detect the body parts along with an L2 loss
for regression that reﬁnes the part prediction. Hence, does not include a sub-
Human pose estimation via Convolutional Part Heatmap Regression
sequent part heatmap regression network as our method does. The work of 
uses a part detection network as a ﬁrst step in order to provide crude estimates
for the part locations. Subsequently, CNN features are cropped around these
estimates and used for reﬁnement using regression. Hence, does not include
a subsequent part heatmap regression network as our method does, and hence
does not account for contextual information but allows only for local reﬁnement.
Residual learning. Notably, all the aforementioned methods were developed prior to the advent of residual learning . Very recently, residual learning
was applied for the problem of human pose estimation in and . Residual
learning was used for part detection in the system of . The “stacked hourglass
network” of elegantly extends FCN and deconvolution nets within
residual learning, also allowing for a more sophisticated and heavy processing
during top-down processing. We explore residual learning within the proposed
CNN cascade; notably for our residual regression subnetwork, we used a single
“hourglass network” .
The proposed part heatmap regression is a CNN cascade illustrated in Fig. 1. Our
cascade consists of two connected subnetworks. The ﬁrst subnetwork is a part
detection network trained to detect the individual body parts using a per-pixel
softmax loss. The output of this network is a set of N part detection heatmaps.
The second subnetwork is a regression subnetwork that jointly regresses the part
detection heatmaps stacked with the image/CNN features to conﬁdence maps
representing the location of the body parts.
We implemented two instances of part heatmap regression: in the ﬁrst one,
both subnetworks are based on VGG-FCN and in the second one, on
residual learning . For both cases, the subnetworks and their training
are described in detail in the following subsections. The following paragraphs
outline important details about the training of the cascade, and are actually
independent of the architecture used (VGG-FCN or residual).
Part detection subnetwork. While uses a per-pixel softmax loss encoding diﬀerent classes with diﬀerent numeric levels, in practice, for the human
body this is suboptimal because the parts are usually within close proximity to
each other, having high chance of overlapping. Therefore, we follow an approach
similar to and encode part label information as a set of N binary maps, one
for each part, in which the values within a certain radius around the provided
ground truth location are set to 1 and the values for the remaining background
are set to 0. This way, we thus tackle the problem of having multiple parts in
the very same region. Note that the detection network is trained using visible
parts only, which is fundamentally diﬀerent from the previous regression-based
approaches .
The radius deﬁning “correct location” was selected so that the targeted body
part is fully included inside. Empirically, we determined that a value of 10px to
be optimal for a body size of 200px of an upright standing person.
Adrian Bulat, Georgios Tzimiropoulos
We train our body part detectors jointly using pixelwise sigmoid cross entropy
loss function:
ij + (1 −pn
ij) log(1 −ˆ
ij denotes the ground truth map of the nth part at pixel location (i, j)
(constructed as described above) and ˆ
ij is the corresponding sigmoid output at
the same location.
Regression subnetwork. While the detectors alone provide good performance, they lack a strong relationship model that is required to improve (a)
accuracy and (b) robustness particularly required in situations where speciﬁc
parts are occluded. To this end, we propose an additional subnetwork that
jointly regresses the location of all parts (both visible and occluded). The input of this subnetwork is a multi-channel representation produced by stacking
the N heatmaps produced by the part detection subnetwork, along with the
input image. (see Fig. 1). This multichannel representation guides the network
where to focus and encodes structural part relationships. Additionally, it ensures
that our network does not suﬀer from the problem of regressing occluded part
appearances: because the part detection heatmaps for the occluded parts provide low conﬁdence scores, they subsequently guide the regression part of our
network to rely on contextual information (provided by the remaining parts) in
order to predict the location of these parts.
The goal of our regression subnetwork is to predict the points’ location via
regression. However, direct regression of the points is a diﬃcult and highly nonlinear problem caused mainly by the fact that only one single correct value needs
to be predicted. We address this by following a simpler alternative route ,
regressing a set of conﬁdence maps located in the immediate vicinity of the
correct location (instead of regressing a single value). The ground truth consists
of a set of N layers, one for each part, in which the correct location of each part,
be it visible or not is represented by Gaussian with a standard deviation of 5px.
We train our subnetwork to regress the location of all parts jointly using the
following L2 loss:
Mn(i, j) −Mn(i, j)
Mn(i, j) and Mn(i, j) represent the predicted and the ground truth con-
ﬁdence maps at pixel location (i, j) for the nth part, respectively.
VGG-FCN part heatmap regression
Part detection subnetwork. We based our part detection network architecture on the VGG-16 network converted to fully convolutional by replacing
the fully connected layers with convolutional layers of kernel size of 1 . Because the localization accuracy oﬀered by the 32px stride is insuﬃcient, we make
Human pose estimation via Convolutional Part Heatmap Regression
use of the entire algorithm as in by combining the earlier level CNN features,
thus reducing the stride to 8px. For convenience, the network is shown in Fig. 3
and Table 1.
Fig. 3: The VGG-FCN subnetwork used for body part detection. The blocks
A1-A9 are deﬁned in Table 1.
Table 1: Block speciﬁcation for the VGG-FCN part detection subnetwork. Torch
notations (channels, kernel, stride) and (kernel, stride) are used to deﬁne the
conv and pooling layers.
layer (64,
3x3, 1x1),
layer (128,
3x3, 1x1),
layer (256,
3x3, 1x1),
layer (512,
3x3, 1x1),
layer(512,
1x1, 1x1),
conv layer
conv layer
Regression subnetwork. We have chosen a very simple architecture for
our regression sub-network, consisting of 7 convolutional layers. The network is
shown in Fig. 4 and Table 2. The ﬁrst 4 of these layers use a large kernel size that
varies from 7 to 15, in order to capture a suﬃcient local context and to increase
the receptive ﬁeld size which is crucial for learning long-term relationships. The
last 3 layers have a kernel size equal to 1.
Training. For training on MPII, all images were cropped after centering on
the person and then scaled such that a standing-up human has height 300px.
All images were resized to a resolution of 380x380px. To avoid overﬁtting, we
performed image ﬂipping, scaling (between 0.7 and 1.3) and rotation (between
-40 and 40 degrees). Both rotation and scaling were applied using a set of prede-
ﬁned step sizes. Training the network is a straightforward process. We started by
Adrian Bulat, Georgios Tzimiropoulos
ﬁrst training the body part detection network, ﬁne-tuning from VGG-16 
pre-trained on ImageNet . The detectors were then trained for about 20
epochs using a learning rate progressively decreasing from 1e −8 to 1e −9. For
the regression subnetwork, all layers were initialized with a Gaussian distribution (std=0.01). To accelerate the training and avoid early divergence we froze
the training of the detector layers, training only the subnetwork. We let this
train for 20 epochs with a learning rate of 0.00001 and then 0.000001. We then
trained jointly both networks for 10 epochs. We found that one can train both
the part detection network and the regression subnetwork jointly, right from the
beginning, however, the aforementioned approach results in faster training.
For LSP, we ﬁne-tuned the network for 10 epochs on the 1000 images of the
training set. Because LSP provides the ground truth for only 14 key points, during ﬁne-tuning we experimented with two diﬀerent strategies: (i) generating the
points artiﬁcially and (ii) stopping the backpropagation for the missing points.
The later approach produced better results overall. The training was done using
the caﬀe bindings for Torch7 .
Fig. 4: The VGG-based subnetwork used for regression. The blocks C1-C8 are
deﬁned in Table 2.
Table 2: Block speciﬁcation for the VGG-based regression subnetwork. Torch
notations (channels, kernel, stride) and (kernel, stride) are used to deﬁne the
conv and pooling layers.
13x13, 1x1)
layer(128,
13x13, 1x1)
layer(256,
15x15, 1x1)
layer(512,
layer(512,
layer (16,
Residual part heatmap regression
Part detection subnetwork. Motivated by recent developments in image
recognition , we used ResNet-152 as a base network for part detection.
Doing so requires making the network able to make predictions at pixel level
which is a relative straightforward process (similar ways to do this are described
Human pose estimation via Convolutional Part Heatmap Regression
in ). The network is shown in Fig. 5 and Table 3. Blocks B1-B4 are
the same as the ones in the original ResNet, and B5 was slightly modiﬁed. We
ﬁrstly removed both the fully connected layer after B5 and then the preceding
average pooling layer. Then, we added a scoring convolutional layer B6 with N
outputs, one for each part. Next, to address the extremely low output resolution,
we ﬁrstly modiﬁed B5 by changing the stride of its convolutional layers from 2px
to 1px and then added (after B6) a deconvolution layer B7 with a kernel
size and stride of 4, that upsamples the output layers to match the resolution of
the input. We argue that for our detection subnetwork, knowing the exact part
location is not needed. All added layers were initialized with 0 and trained using
rmsprop .
Fig. 5: The architecture of the residual part detection subnetwork. The network
is based on ResNet-152 and its composing blocks. The blocks B1-B7 are deﬁned
in Table 3. See also text.
Table 3: Block speciﬁcation for the residual part detection network. Torch notations (channels, kernel, stride) and (kernel, stride) are used to deﬁne the conv
and pooling layers. The bottleneck modules are deﬁned as in .
1x conv layer
(64,7x7,2x2)
1x pooling
(3x3, 2x2)
3x bottleneck
[(64,1x1),
(256,1x1)]
8x bottleneck
[(128,1x1),
(128,3x3),
(512,1x1)]
bottleneck
[(256,1x1),
(256,3x3),
(1024,1x1)]
3x bottleneck
[(512,1x1),
(512,3x3),
 ]
1x conv layer
(16,1x1,1x1)
(16,4x4,4x4)
Regression subnetwork. For the residual regression subnetwork, we used a
(slightly) modiﬁed “hourglass network” , which is a recently proposed stateof-the-art architecture for bottom-up, top-down inference. The network is shown
in Fig. 6 and Table 4. Brieﬂy, the network builds on top of the concepts described
in , improving a few fundamental aspects. The ﬁrst one is that extends 
within residual learning. The second one is that instead of passing the lower level
futures through a convolution layer with the same number of channels as the ﬁnal
scoring layer, the network passes the features through a set of 3 convolutional
blocks that allow the network to reanalyse and learn how to combine features
Adrian Bulat, Georgios Tzimiropoulos
Fig. 6: The “hourglass network” used as the residual regression network. The
Blocks D1-D7 are deﬁned in Table 4. See also text.
extracted at diﬀerent resolutions. See for more details. Our modiﬁcation
was in the introduction of deconvolution layers D5 for recovering the lost spatial
resolution (as opposed to nearest neighbour upsampling used in ). Also, as
in the detection network, the output is brought back to the input’s resolution
using another trained deconvolutional layer D5.
Table 4: Block speciﬁcation for the “hourglass network”. Torch notations (channels, kernel, stride) and (kernel, stride) are used to deﬁne the conv and pooling
layers. The bottleneck modules are deﬁned as in .
layer(64, 7x7,
2x2), 1x pooling(2x2,2x2)
3x bottleneck
maxpooling
(2x2, 2x2),
3x bottleneck
3x bottleneck
1x deconv.
layer (256,
1x conv layer
(512, 1x1,
scoring layer
(16, 1x1, 1x1)
Training. For training on MPII, we applied similar augmentations as before,
with the diﬀerence being that augmentations were applied randomly. Also, due to
memory issues, the input image was rescaled to 256x256px. Again, we started by
ﬁrst training the body part detection network, ﬁne-tuning from ResNet-152 
pre-trained on ImageNet . The detectors were then trained for about 50
epochs using a learning rate progressively decreasing from 1e −3 to 2.5e −5.
For the regression “hourglass” subnetwork, we froze the learning for the detector
layers, training only the regression subnetwork. We let this train for 40 epochs
using a learning rate of 1e −4 and then 2.5e −5. In the end, the networks
were trained jointly for 50 more epochs. While we experimented with diﬀerent
Human pose estimation via Convolutional Part Heatmap Regression
initialization strategies, all of them seemed to produce similar results. For the
ﬁnal model, all layers from the regression subnetwork were zero-initialized, except
for the deconvolution layers, which were initialized using bilinear upsampling
ﬁlters, as in . The network made use of batch normalization, and was trained
with a batch size of 8. For LSP, we follow the same procedure as the one for VGG-
FCN, changing only the number of epochs to 30. The network was implemented
and trained using Torch7 . The code, along with the pretrained models will
be published on our webpage.
We report results for two sets of experiments on the two most challenging data
sets for human pose estimation, namely LSP and MPII . A summary of
our results is as follows:
– We show the beneﬁt of the proposed detection-followed-by-regression cascade
over a two-step regression approach, similar to the idea described in ,
when implemented with both VGG-FCN and residual architectures.
– We provide an analysis of the diﬀerent components of our network illustrating their importance on overall performance. We show that stacking the
part heatmaps as proposed in our work is necessary for achieving high performance, and that this performance is signiﬁcantly better than that of the
part detection network alone.
– We show the beneﬁt of using a residual architecture over VGG-FCN.
– We compare the performance of our method with that of recently published
methods illustrating that both versions of our cascade achieve top performance on both the MPII and LSP data sets.
We carried out a series of experiments in order to investigate the impact of the
various components of our architecture on performance. In all cases, training and
testing was done on MPII training and validation set, respectively. The results
are summarized in Table 5. In particular, we report the performance of
i the overall part heatmap regression (which is equivalent to “Detection+regression”)
for both residual and VGG-FCN architectures.
ii the residual part detection network alone (Detection only).
iii the residual detection network but trained to perform direct regression (Regression only).
iv a two-step regression approach as in (Regression+regression), but implemented with both residual and VGG-FCN architectures.
Adrian Bulat, Georgios Tzimiropoulos
We ﬁrst observe that there is a large performance gap between residual part
heatmap regression and the same cascade but implemented with a VGG-FCN.
Residual detection alone works well, but the regression subnetwork provides a
large boost in performance, showing that using the stacked part heatmaps as
input to residual regression is necessary for achieving high performance.
Furthermore, we observe that direct regression alone (case iii above) performs
better than detection alone, but overall our detection-followed-by-regression cascade signiﬁcantly outperforms the two-step regression approach. Notably, we
found that the proposed part heatmap regression is also considerably easier to
train. Not surprisingly, the gap between detection-followed-by-regression and
two-step regression when both are implemented with VGG-FCN is much bigger.
Overall, these results clearly verify the importance of using (a) part detection
heatmaps to guide the regression subnetwork and (b) a residual architecture.
Table 5: Comparison between diﬀerent variants of the proposed residual architecture on MPII validation set, using PCKh metric. The overall residual part
heatmap regression architecture is equivalent to “Detection+regression”.
Head Shoulder Elbow Wrist Hip
Knee Ankle Total
Part heatmap regression(Res)
89.4 85.7 81.9
Part heatmap regression(VGG) 95.6
Detection only(Res)
Regression only(Res)
Regression+regression(Res)
Regression+regression(VGG)
Table 6: PCKh-based comparison with state-of-the-art on MPII
Head Shoulder Elbow Wrist Hip
Knee Ankle Total
Part heatmap regression(Res)
89.4 85.7 81.9
Part heatmap regression(VGG)
Newell et al., arXiv’16 
Wei et al., CVPR’16 
Insafutdinov et al., arXiv’16 96.6
Gkioxary et al., arXiv’16 
Lifshitz et al., arXiv’16 
Pishchulin et. al., CVPR’16 94.1
Hu&Ramanan., CVPR’16 
81.9 74.25 69.5
Carreira et al., CVPR’16 
Tompson et al., NIPS’14 
Tompson et al., CVPR’15 
Human pose estimation via Convolutional Part Heatmap Regression
Comparison with state-of-the-art
In this section, we compare the performance of our method with that of published methods currently representing the state-of-the-art. Tables 6 and 7 summarize our results on MPII and LSP, respectively. Our results show that both
VGG-based and residual part heatmap regression are very competitive with the
latter, along with the other two residual-based architectures , being top
performers on both datasets. Notably, very close in performance is the method
of which is not based on residual learning but performs a sequence of 6 CNN
regressions, being also much more challenging to train . Examples of ﬁtting
results from MPII and LSP for the case of residual part heatmap regression can
be seen in Fig. 7.
Table 7: PCK-based comparison with the state-of-the-art on LSP
Head Shoulder Elbow Wrist Hip
Knee Ankle Total
Part heatmap regression(Res)
92.2 91.5 88.6
Part heatmap regression(VGG)
Wei et al., CVPR’16 
Insafutdinov et al., arXiv’16 97.4
Pishchulin et al.CVPR’16 
Lifshitz et al., arXiv’16 
Yang et al., CVPR’16 
Carreira et al., CVPR’16 
Tompson et al., NIPS’14 
Fan et al., CVPR’15 
Chen&Yuille, NIPS’14 
Acknowledgement
We would like to thank Leonid Pishchulin for graciously producing our results
on MPII with unprecedented quickness.
Conclusions
We proposed a CNN cascaded architecture for human pose estimation particularly suitable for learning part relationships and spatial context, and robustly
inferring pose even for the case of severe part occlusions. Key feature of our
network is the joint regression of part detection heatmaps. The proposed architecture is very simple and can be trained end-to-end, achieving top performance
on the MPII and LSP data sets.
Adrian Bulat, Georgios Tzimiropoulos
Fig. 7: Examples of poses obtained using our method on MPII (ﬁrst 3 rows), and
LSP (4th and 5th row). Observe that our method copes well with both occlusions
and diﬃcult poses. The last row shows some fail cases caused by combinations
of extreme occlusion and rare poses.
Human pose estimation via Convolutional Part Heatmap Regression