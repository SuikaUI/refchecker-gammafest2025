The age of secrecy and unfairness in recidivism
prediction
Cynthia Rudin∗, Caroline Wang† Beau Coker†
Departments of Computer Science, Electrical and Computer Engineering, and Statistical Science,
Duke University,
LSRC Building, Durham, NC 27708, USA
1 In our current society, secret algorithms make important decisions about
individuals. There has been substantial discussion about whether these algorithms are unfair to groups of individuals. While noble, this pursuit is complex
and ultimately stagnating because there is no clear deﬁnition of fairness and
competing deﬁnitions are largely incompatible. We argue that the focus on the
question of fairness is misplaced, as these algorithms fail to meet a more important and yet readily obtainable goal: transparency. As a result, creators of secret algorithms can provide incomplete or misleading descriptions about how
their models work, and various other kinds of errors can easily go unnoticed.
By trying to partially reconstruct the COMPAS model — a recidivism-risk
scoring model used throughout the criminal justice system — we show that it
does not seem to depend linearly on the defendant’s age, despite statements to
the contrary by the model’s creator. This observation has not been made before despite many recently published papers on this algorithm. Furthermore,
by subtracting from COMPAS its (hypothesized) nonlinear age component,
we show that COMPAS does not necessarily depend on race, contradicting
ProPublica’s analysis, which assumed linearity in age. In other words, faulty
assumptions about a proprietary algorithm lead to faulty conclusions that go
unchecked. Were the algorithm transparent in the ﬁrst place, this likely would
1∗To whom correspondence should be addressed; E-mail: . Symbol † denotes equal contribution
 
not have occurred. We demonstrate other issues with deﬁnitions of fairness
and lack of transparency in the context of COMPAS, including that a simple model based entirely on a defendant’s age is as ‘unfair’ as COMPAS by
ProPublica’s chosen deﬁnition. We ﬁnd that there are many defendants with
low risk score but long criminal histories, suggesting that data inconsistencies
occur frequently in criminal justice databases. We argue that transparency
satisﬁes a different notion of procedural fairness by providing both the defendants and the public with the opportunity to scrutinize the methodology and
calculations behind risk scores for recidivism.
Introduction
Secret algorithms control important decisions about individuals, such as judicial bail, parole,
sentencing, lending decisions, credit scoring, marketing, and access to social services. These
algorithms may not do what we think they do, and they may not do what we want.
There have been numerous debates about fairness in the literature, mainly stemming from
a ﬂawed analysis by the ProPublica group (1, 2) of data from Broward County FL, claiming
that the proprietary prediction model COMPAS (Correctional Offender Management Proﬁling
for Alternative Sanctions) (3) is racially biased. COMPAS is used throughout the criminal
justice system in the U.S., and its predictions have serious consequences in the lives of many
people (4–14). The bottom line from these debates is that there is not a single correct deﬁnition
of fairness and the fact that multiple types of fairness are incompatible. We put aside typical
fairness considerations for a moment to focus on more pressing issues.
One issue with COMPAS is that it is complicated. It is based on 137 variables (15) that
are collected from a questionnaire. This is a serious problem because typographical or data entry errors, data integration errors, missing data, and other types of errors abound when relying
on manually-entered data. Individuals with long criminal histories are sometimes given low
COMPAS scores (which labels them as low risk), and vice versa. In the past, there have been
documented cases where individuals have received incorrect COMPAS scores based on incorrect criminal history data (16,17) and have had no mechanism to correct it after a decision was
made based on that incorrect score. This problem has inadvertently occurred with other (even
transparent) scoring systems, at least in one case leading to the release of a dangerous individual
who committed a murder while on bail (18,19). An error in a complicated model is much harder
to ﬁnd than an error in a simple model, and it not clear how many times typographical errors
in complicated models have led to inappropriate releases that resulted in crimes, after decades
of widespread use of these models. The question of whether calculation errors occur often in
these models is of central importance to the present work.
A separate issue with COMPAS is that it is proprietary, which means its calculations cannot
be double-checked for individual cases, and its methodology cannot be veriﬁed. Furthermore, it
is unclear how the data COMPAS collects contribute to its automated assessments. For instance,
while some of the questions on the COMPAS questionnaire are the same as those in almost every
risk score — age, and number of past crimes committed — other questions seem to be direct
proxies for socioeconomic status, such as “How hard is it for you to ﬁnd a job ABOVE minimum
wage compared to others?” It is not clear that such data should be collected or permitted for the
purposes in which these risk scores are used.
Though creators of proprietary algorithms often provide descriptions of how their models
work, by nature, it is difﬁcult for third-parties to verify these descriptions. This may allow errors in documentation to propagate unchecked for years. By partially reconstructing COMPAS
in Broward County, we show in Section 2.2 that COMPAS may depend nonlinearly on age,
contradicting its stated methodology. As a result, ProPublica’s conclusion that being African-
American leads to a higher COMPAS score, even controlling for criminal history and sex, based
on a logistic regression would be invalid because the linearity assumption is violated. While
adding a nonlinear age term to the regression could mitigate the impact of this particular issue, it misses the larger point. Without transparency, incorrect high-level statements about a
model (e.g., its dependence on age is linear) go unchecked, and this can have downstream consequences for independent analyses of a model.
While COMPAS depends heavily on age, we show in Sections 2.3 through 2.6 that it does
not seem to depend in such a strong way on either criminal history or proxies for race. We discuss several possible reasons, but it is possible that COMPAS depends less on criminal history
than we might expect. This leads to the possibility that COMPAS depends heavily on variables
that we may not want it to depend on.
In Section 3 we pinpoint many individuals whose COMPAS scores seem unusually low
given their criminal histories. Since COMPAS is proprietary, we cannot fully determine whether
these low scores are due to errors in calculation, data entry errors or errors from some other
source (or even if they are errors at all).
COMPAS’ creator Northpointe disagreed with each of ProPublica’s claims on racial bias
(20) based on their deﬁnition of fairness. Their rebuttal did not include arguments as to the type
of fairness we consider here, and in particular, why it beneﬁts the justice system to use a model
that is complicated or proprietary.
Work in machine learning has shown that complicated, black-box, proprietary models are
not necessary for recidivism risk assessment. Researchers have shown (on several datasets, including the data from Broward County) that interpretable models are just as accurate as black
box machine learning models for predicting recidivism (21–26). These simple models involve
age and counts of past crimes, and indicate that younger people, and those with longer criminal histories, are more likely to reoffend. A judge could easily memorize the models within
these works, and compute the risk assessments without even a calculator (23,24). Despite this
knowledge, complicated models are still being used.
Given that we do not need proprietary models, why we should allow proprietary models
at all? The answer is the same as it is in any other application: by protecting intellectual
property, we incentivize companies to perform research and development. Since COMPAS has
been at the forefront of the fairness debate about modern machine learning methods, it is easy
to forget that COMPAS is not one of these methods. It is a product of years of painstaking
theoretical and empirical sociological study. For a company like Northpointe to invest the time
and effort into creating such a model, it seems reasonable to afford the company intellectual
property protections. However, as we discussed, machine learning methods — either standard
black-box or, better yet, recently-developed interpretable ones — can predict equally well or
better than bespoke models like COMPAS (21–24). For important applications like criminal
justice, academics have always been willing to devote their time and energy. High-performing
predictive models can therefore be created with no cost to the criminal justice system. Allowing
proprietary models to incentivize model development is not necessary in the ﬁrst place.
Neglecting to use transparent models has consequences. We provide two arguments for why
transparency should be prioritized over other forms of fairness. First, no matter which technical
deﬁnition of fairness one chooses, it is easier to debate the fairness of a transparent model than
a proprietary model. Transparent algorithms provide defendants and the public with imperative
information about tools used for safety and justice, allowing a wider audience to participate in
the discussion of fairness. Second, transparency constitutes its own type of procedural fairness
that should be seriously considered (see (27) for a discussion). We argue that it is not fair that
life-changing decisions are made with an error-prone system, without entitlement to a clear,
veriﬁable, explanation.
In Section 2, we try to partially reconstruct COMPAS for Broward County and show how it
is likely to be inconsistent with its ofﬁcial documentation; in Section 3, we identify a number
of individuals with long criminal histories but low risk scores; and in Section 4, we describe
transparency as a form of fairness. We consider the most transparent non-trivial predictive
model we could ﬁnd: age. Younger people tend to be at higher risk of recidivism. Our goal in
this section is to modify the discussion of fairness to be through the lens of transparency.
Reconstructing COMPAS
Even with our limited data, we may have been able to partially reconstruct parts of the COMPAS
model as it is implemented in Broward County. We will next describe these attempts. Note that
other groups besides ProPublica have attempted to explain COMPAS (28,29). One attempt (29)
uses only linear models (and our evidence suggests that COMPAS’ dependence on age is nonlinear). Another attempt (28) modeled COMPAS with a generalized additive model, and we
hypothesize that they had the correct model form, based on COMPAS’ documentation. However, their analysis has similar issues to that of ProPublica or (29): all of these groups attempted
to explain COMPAS scores using ProPublica’s limited set of features, but this type of analysis
is not valid because there are many unmeasured features. COMPAS’s actual dependence on the
observable features may be totally different than what they report. For instance, if age is correlated with unmeasured survey data, their model would exploit this correlation to compensate
for the missing survey data, leading to an incorrect estimate of how COMPAS depends on age.
Our approach instead attempts to isolate and subtract off the parts of COMPAS that we think
can be explained from our data, using COMPAS’ documentation to guide us. If our stated assumptions are correct, our analysis is valid even in the presence of many unmeasured features.
The analysis still holds even if the measured and unmeasured features are correlated. Of course,
ground truth cannot be made available (except to the designers of COMPAS), so our hypotheses
cannot be veriﬁed.
COMPAS as described by its creator
There are two COMPAS recidivism risk assessments of interest: the general score and the
violence score. These scores assess the risk that a defendant will commit a general or violent
crime, and we use them to predict crime within the next two years. Each score is given as an
integer between 1 and 10 but is based on a raw score that can take any value. Higher scores
indicate higher risk. The raw score is computed by a formula and the ﬁnal integer score is
normalized based on a local population. We will therefore attempt to reconstruct the raw scores.
To compute the COMPAS raw scores, Northpointe collects 137 variables from a questionnaire, computes a variety of subscales, and ﬁnally linearly combines the subscales and two age
variables — the defendant’s age at the time of the current offense and age at the time of the ﬁrst
offense — to compute the raw risk scores. For example, using the equation exactly as written
in the COMPAS documentation, the violent recidivism raw score is given by:
Violent Recidivism Risk Score
(age∗−w)+(age-at-ﬁrst-arrest∗−w)+(history of violence ∗w)
+(vocation education ∗w) + (history of noncompliance ∗w),
where the variables not related to age are subscales and the weights “w” may be different for
each variable. The notation “age∗−w” would commonly indicate “age times the negative of w.”
We have little knowledge of how the subscales depend on the questionnaire; the documentation
states only which questionnaire items are used for which subscales. Table 1 shows for each
subscale the recidivism score(s) to which it relates and the number of underlying questionnaire
items we can compute using our data. We use the data made available by ProPublica2; the Propublica dataset is missing features needed to compute the COMPAS score, and so we supplement
this dataset with probation data from the Broward Clerk’s Ofﬁce. However, there remain missing items often related to subjective survey questions that cannot be computed without access
to Northpointe’s data, which are not publicly available. Notes on our data processing can be
found in the supplement.
According to our understanding of the COMPAS documentation, the general and violent
COMPAS scores are both linear models, where age and age-at-ﬁrst-arrest are the only factors
that can have negative contributions to the COMPAS scores.
COMPAS seems to depend nonlinearly on age, contradicting its documentation
Let us consider if the linear model given by COMPAS is supported by our data. We make the
following assumption:
2 
Table 1: COMPAS subcales are inputs to the recidivism scores. We have some but not all of the
questionnaire features that determine each subscale. For one of the History of Noncompliance
features, “Was this person on probation or parole at the time of the current offense?”, we can
compute only whether the person was on probation.
# Features we have
Recidivism Score
Criminal Involvement
History of Noncompliance
History of Violence
Vocational/Educational
Substance Abuse
Data Assumption: For most values of age, there is at least one person in our
dataset with age-at-ﬁrst-arrest equal to their age and the lowest possible risk score
for each subscale.
First, note that age and age-at-ﬁrst-arrest are the only COMPAS score inputs that have negative contribution to the COMPAS scores. Next, note that the least-risky value for age-at-ﬁrstarrest occurs when it is equal to current age (this implies that the individual has committed
only one arrestable offense). Thus, individuals satisfying the Data Assumption should have the
lowest COMPAS raw score for their age, which is key for the rest of our age analysis. In what
follows, we describe attempts to conﬁrm that these individuals are present in the data.
First, and most importantly, we used our data to check directly that for most values of age,
there is at least one person in our dataset who has age-at-ﬁrst-arrest equal to their age and
who does not have criminal history. For the COMPAS general score, we can check if the Data
Assumption holds for the Criminal Involvement subscale because we have all the inputs to it.
We can only approximately check this assumption for the History of Violence and History of
Noncompliance subscales because we do not have all the inputs. However, the Data Assumption
seems plausible given that (1) the inputs to the subscales can take only a few integer values3
and (2) their typical content (e.g., “Do you have a job?” or “How many times has this person
been sentenced to jail for 30 days or more?”) suggests the least-risky input values are fairly
likely. We cannot check the Data Assumption for the subscales for which we do not have data.
3In all but one case, the subscale inputs are binary or count variables that take up to only 6 values. The exception
is the Criminal Involvement Subscale, which takes the total number of prior arrests, and for which we have data to
directly validate.
However, the Data Assumption seems to hold for the subscales for which we do have data (see
Figure 12 in the appendix), leading us to believe it might hold generally.
If the COMPAS documentation were correct in that COMPAS is a linear function of age,
then, as long as the Data Assumption holds, if we plot the COMPAS raw score against age for all
people, the lower bound should be a line with slope equal to the sum of the coefﬁcients on age
and age-at-ﬁrst-arrest, since age equals age-at-ﬁrst-arrest. Figure 1 shows this is not the case.
Also, the people near the lower bound of Figure 1 often have no criminal history, and have ageat-ﬁrst-arrest equal to age (see the appendix for more analysis). Thus, our evidence indicates
the COMPAS model is not the linear model given above within the documentation. Recall that
except for some typos, there should be no noise in the COMPAS scores. The COMPAS scores
we observe should be the direct output of a computer program.
Despite the lack of agreement of the data with the documentation, we would still like to
reconstruct as much of the COMPAS black box as possible, so we make several weaker hypotheses about its form, none of which contradict the COMPAS documentation:
Model Assumption 1: The COMPAS raw score is an additive model with respect
to each input (age, age-at-ﬁrst-arrest, and the subscales).
Model Assumption 2: The additive terms corresponding to each input except age
and age-at-ﬁrst-arrest are never negative.
Model Assumption 3: For the lowest risk score, (a) the additive term corresponding to age-at-ﬁrst-arrest is lowest when age-at-ﬁrst-arrest is as large as possible
(i.e., equal to age) and (b) the additive terms corresponding to the subscales are
We believe Model Assumption 2 should hold because all of the inputs except age and ageat-ﬁrst-arrest (e.g. number of violent felonies, number of times on probation) should lead to a
higher risk of violence or recidivism, and therefore a higher COMPAS score. Should Model Assumption 3 not hold, people with nonzero criminal history would have lower COMPAS scores
than those with none, which is not intuitive. With these Model Assumptions and under the Data
Assumption, the lower bound observed in Figure 1 is exactly the additive term corresponding
Reconstructing COMPAS’s dependence on age is important because we know that COM-
PAS, if it is like other scoring systems, should depend heavily on age in order to predict well.
If we could isolate and subtract off its dependence on age, we could more easily determine its
dependence on protected attributes such as criminal history and race. Based on the lower bound
of the COMPAS score with respect to age, we present a conjecture of approximately how the
COMPAS score may depend on age, at least in Broward County, and we have a similar conjecture for the violence recidivism counterpart:
Conjecture: The COMPAS general recidivism model is a nonlinear additive model. Its dependence on age in Broward County is approximately a linear spline, deﬁned as follows:
for ages ≤33.26, fage(age) = −0.056 × age −0.179
for ages between 33.26 and 50.02, fage(age) = −0.032 × age −0.963
for ages ≥50.02, fage(age) = −0.021 × age −1.541.
Similarly, the COMPAS violence recidivism model is a nonlinear additive model, with a
dependence on age that is approximately a linear spline, deﬁned by:
for ages ≤21.77, fviol age(age) = −0.205 × age + 1.815
for ages between 21.77 and 34.58, fviol age(age) = −0.070 × age −1.113
for ages between 34.58 and 48.36, fviol age(age) = −0.040 × age −2.166
for ages ≥48.36, fviol age(age) = −0.025 × age −2.882.
We used a two-stage procedure to ﬁt the functions fage and fviol age, with the goal of obtaining
the closest approximation to the true functional relationship between age and the COMPAS raw
scores as possible. First, we ﬁt quadratic and quartic polynomials respectively to the lower
bounds of the scatter plots of individuals’ COMPAS general recidivism scores and the COMPAS
violent recidivism scores. Points more than c = .05 below these age polynomials were deemed
“age outliers” (a handful of individuals whose age seems to be incorrect) and removed from
the analysis. Less than ten individuals (for each score) were removed due to this reason. The
age splines were ﬁt using the lower bound of the subsets of individuals whom we hypothesize
to satisfy the data assumption (individuals with age equal to age-at-ﬁrst-arrest and no known
contribution to any subscale), shown in Figure 2. In the left ﬁgure, several of the age outliers
appear as if they were in a line, but if we add in the age outliers from the full population (not
just those with no criminal history) the apparent line is no longer a lower bound.
As discussed above, COMPAS’ documentation claims a linear dependence on age. Even if
COMPAS constructed the model to only take age as a linear argument, its predictions, as applied
Age at COMPAS screening date
General score
Age at COMPAS screening date
Violence score
(b) fviol age
Scatter plot of COMPAS general recidivism score versus age and scatter plot of
COMPAS violence recidivism score versus age. Age splines used to approximate the lower
bound of the scatter plots are shown in red; age outliers that were removed from the analysis
are also in red.
Age at COMPAS screening date
General Score
Below age polynomial
Used to construct linear splines
Age at COMPAS screening date
Violence Score
Below age polynomial
Used to construct linear splines
(b) fviol age
Figure 2: Fitting fage and fviol age to the data. The data are represented by the black dots and the
ﬁtting is shown as the multicolored line. Points which we deemed as age outliers are shown in
red. 92 individuals were used to ﬁt fviol age and 100 individuals were used to ﬁt fage.
to a sample with representative covariate information, apparently induce nonlinear dependence
on it. For the COMPAS documentation to claim such linear dependence can thus be misleading.
It is possible that age’s only contribution to the COMPAS general recidivism score is fage
(similarly, fviol sage for the violence score). Let us describe why this seems to be true. The
remainders of general COMPAS minus fage and violent COMPAS minus fviol age do not seem
to depend on age. After subtracting out the age polynomials, we employed machine learning
methods along with linear models (Table 2) to model the remainder (COMPAS score minus the
age polynomial). We ran each of these algorithms on the data, once using criminal history and
age features only (with-age models), and once using just criminal history (without-age models).
Machine learning methods are powerful, nonparametric models that are capable of modeling
nonlinear functions very closely, given the right features. Thus, if the remainder depends on
age coupled with criminal history, it is likely the accuracy will vary between the with-age and
without-age models. However, instead, Tables 2 and 3 (for the general and violence scores,
respectively) show the accuracy of the machine learning models was almost identical between
the with-age and without-age models.
Importantly, if the dependence on age is additive, COMPAS does not use features that couple
age and criminal history, such as the rate of crimes committed over time, despite the potential
usefulness of this type of feature (see, e.g., (30)).
Dec. Trees
Without Age
Table 2: Root mean square error for several machine learning algorithms for predicting COM-
PAS score minus age polynomial (fage), with age included as a feature (bottom row), and without
age (top row). We are trying to determine whether the COMPAS remainder (general COMPAS
after subtracting the main age terms) still depends on age. The numbers for “with age” look
very similar to the numbers “without age.” Thus, age does not seem to participate in the remainder term because accuracy does not change between the two rows. Race and age at ﬁrst
arrest are included as predictors for both “with age” and “without age” predictions.
The fact that the lower bounds fage and fviol age seem to vary smoothly and uniformly with
age, with only few outliers, indicates that the data entering into the COMPAS scores is high
quality with respect to age. This has implications for our later analysis.
Now that we have hypothesized the dependence of COMPAS on age, we wish to explain its
Dec. Trees
Without Age
Table 3: Analogous to Table 2 but for the COMPAS violence recidivism score, predicting COM-
PAS violence score minus fviol age. Again, age does not seem to participate in this remainder.
dependence on criminal history variables. We do this separately for the general and violence
scores in Sections 2.3 and 2.4, respectively.
Criminal history and the COMPAS general recidivism score
Unlike the dependence on age, the COMPAS general score does not seem to display a clear dependence on criminal history. Figure 3 shows a scatter plot of COMPAS general score remainder (which we deﬁne as the COMPAS score minus the age spline fage) against the total number
of prior charges, which is one of the variables determining the Criminal Involvement Subscale
(left panel), and the unweighted sum of the variables in the Criminal Involvement Subscale
(right panel). Note that we would ideally plot the remainder against the Criminal Involvement
Subscale itself, but we do not know how the inputs are combined to form the subscale. Even
excluding the age outliers (highlighted in green), there is no smooth lower bound as seen in Figure 1. Therefore we transition from searching for simple dependence of the COMPAS general
score on its subscale items to searching for more complex dependencies.
To then investigate whether the COMPAS general score depends in a more complex way
on the Criminal Involvement Subscale items listed in the Appendix in Table 12, we ran several
machine learning algorithms (random forests (31), boosted decision trees (32), and support
vector machines with a radial basis kernel function) on the subscale items our data has, to see
if the COMPAS general recidivism score could be explained (either linearly or nonlinearly) by
the subscale components. We tried predicting both the general score itself and the general score
after subtracting fage. Figure 4 shows a scatter plot of predictions versus the actual values for
the two prediction problems. We make two observations from this ﬁgure. By comparing the
two panels, we can see that the COMPAS general score seems to depend heavily on age, as the
predictions of the COMPAS score remainder (right panel) are much worse than the predictions
of the COMPAS score itself (left panel); this is because criminal history is correlated with age.
Number of prior charges
General score − fage
Above fage
Below fage
(a) COMPAS −fage vs. number of priors. The
green points are age outliers.
Sum of Criminal Involvement Components
General score − fage
Above fage
Below fage
(b) COMPAS −fage vs. unweighted sum of Criminal Involvement Subscale components. The green
points are age outliers.
Figure 3: We do not ﬁnd a clear relationship between the COMPAS general score after subtracting the age spline and criminal history. Note that in each plot there are a few observations
with a large number of prior charges that are outside of the plot range. Left: COMPAS −fage
vs. number of priors. The green points are age outliers. Right: COMPAS −fage vs. unweighted
sum of Criminal Involvement Subscale components.
After subtracting our reconstructed dependence on age (right panel), we see the ability of the
criminal history variables to predict the COMPAS score remainder is surprisingly unsuccessful.
Thus the dependence of the COMPAS general score on criminal history, as captured by the
components of the Criminal Involvement Subscale, seems to be weak.
Criminal history and the COMPAS violent recidivism score
We gained more traction reconstructing the COMPAS violent recidivism score than the general score. Figure 5 shows the COMPAS violence score after subtracting the age spline fviol age
against the unweighted sum of the Violence History Subscale components. Excluding the age
outliers, this subtraction produced a crisp lower bound on the remainder, unlike the bounds we
obtained trying various individual components and weighted sums of the components. We estimate the dependency on the Violence History Subscale as a piecewise linear function, which we
call gviol hist. Next, in Figure 6, we plot the remainder after also subtracting this dependency on
Violence History (that is, the remainder of the COMPAS violence score after subtracting both
fviol age and gviol hist) against the unweighted sum of the components of the History of Noncompliance Subscale, on which the violence score should also depend. There is not a sharp lower
General score
XGBoost prediction
(a) Predictions of COMPAS vs. actual values.
General score − fage
XGBoost prediction
(b) Predictions of COMPAS −fage vs. actual values.
Figure 4: Predicting general remainder. Left: Predictions of COMPAS vs. actual values. Right:
Predictions of COMPAS −fage vs. actual values.
bound that is consistent across the horizontal axis, which means this sum, by itself, is not likely
to be an additive term within COMPAS. Therefore, we do not estimate a dependency on the
unweighted sum of items in the History of Noncompliance Subscale.
As with the COMPAS general score, we investigate if the COMPAS violence score depends
on its subscale components in a more complex way. Figure 7 shows the results of three separate
prediction problems using all of the components in the History of Violence and History of Noncompliance subscales. From left to right, we use gradient boosted trees to predict the COMPAS
violence score, the COMPAS violence score after subtracting fviol age, and the COMPAS violence score after subtracting fviol age and gviol hist. Comparing the panels in Figure 7 from left to
right, we see that the predictions degrade, emphasizing the importance of fviol age and gviol hist,
respectively, to the COMPAS violence score. That is, after subtracting these components, the
input variables are much less able to predict the remaining COMPAS contribution. Thus, the
dependence of the COMPAS violence score on criminal history, as captured by the Violence
History and History of Noncompliance subscales, seems to be weak.
Sum of History of Violence Components
Violent score − fviol age
Above fviol age
Below fviol age
gviol hist
Figure 5: COMPAS −fage vs. sum of History of Violence components. Green points are age
Sum of History of Noncompliance Components
Violent score − fviol age − gviol hist
Above fviol age
Below fviol age
Figure 6: COMPAS −fage −gviol hist vs. sum of History of Noncompliance components. Green
points are age outliers.
Violent score
XGBoost prediction
(a) Predictions of COMPAS vs.
actual values.
Violent score − fviol age
XGBoost prediction
(b) Predictions of COMPAS −
fviol age vs. actual values.
Violent score − fviol age − gviol hist
XGBoost prediction
(c) Predictions of COMPAS −
fviol age−gviol hist vs. actual values.
Figure 7: Predicting violent remainder. Left: Predictions of COMPAS vs. actual values. Center:
Predictions of COMPAS−fviol age vs. actual values. Right: Predictions of COMPAS−fviol age −
gviol hist vs. actual values.
For both the general and violent COMPAS scores, we were unable to capture the remainder
of the COMPAS score (i.e., after subtracting the reconstructed dependency on age) using the
various criminal history variables that constitute the subscales. There could be several reasons
for this, including the following, among other things:
• It is possible that our data are ﬂawed. We obtained these data from a combination of
ProPublica, the Broward County Sheriff, as well as the Broward County Clerk’s ofﬁce.
We believe most of these data should be approximately the same as the data entered into
the general COMPAS score. Furthermore, based on the analysis above, our age data on
individuals seems to be high quality, so there is no a priori reason that the criminal history
data would be substantially lower quality.
It is also possible that the way we calculated the criminal history subscale items for COM-
PAS differs from the way the Broward County Sheriff’s Ofﬁce calculates them. Our data
processing is discussed in the appendix.
• It is possible that we did not hypothesize the correct model form used in COMPAS; that
is, our machine learning models may not have been able to express the nonlinearities
present in COMPAS. While this could be true, we used very ﬂexible models that should
be able to ﬁt (or even overﬁt) the COMPAS scores. Thus, we believe this is not a likely
explanation.
• It is possible that our data are incomplete. We know this is true, as COMPAS depends on
factors other than criminal history. However, this leads to questions of what COMPAS can
reasonably depend heavily on. Criminal history data are less noisy and less susceptible to
manipulation than other survey questions; criminal history features do not depend on the
survey-taker telling the truth about the answers. If COMPAS depended more heavily on
survey questions than on criminal history, it could lead precisely to a kind of bias that we
might want to avoid. For instance, if COMPAS did not depend heavily on the number of
prior crimes, it might depend more heavily on socioeconomic proxies (e.g., “How hard
is it for you to ﬁnd a job ABOVE minimum wage compared to others?” which is one of
several questions on the COMPAS questionnaire that directly relates to socioeconomic
• There is something in the procedure of calculating the COMPAS score that causes it to
be calculated inconsistently. Since we do not know COMPAS, we cannot check this
possibility. In the past, there have been documented cases where individuals have received incorrect COMPAS scores based on incorrect criminal history data (16, 17), and
no mechanism to correct it after a decision was made based on that incorrect score. We
do not know whether this happens often enough to inﬂuence the scatter plot in a visible
way. However, this type of miscalculation is one of the biggest dangers in the use of
proprietary models. As we know from the calculations of other scoring systems besides
COMPAS, if the number of crimes is not taken into account properly, or if the scoring
system is calculated improperly in other ways, it could lead (and has led in the past) to
unfair denial of parole, and dangerous criminals being released pre-trial.
Data quality issues, either for us or for the COMPAS score itself, are not just a problem for
our analysis, but a problem that is likely to plague almost every jurisdiction that uses COMPAS
or any other secret algorithm. This is discussed more in the next section.
Linear Model
Random Forest
Without Race
Table 4: RMSE of machine learning methods for predicting COMPAS general recidivism raw
score after subtracting fage with and without race as a feature. There is little difference with and
without race. The differences between algorithms are due to differences in model form. Age at
COMPAS screening date and age-at-ﬁrst-arrest are included as features.
Linear Model
Random Forest
Without Race
Table 5: RMSE of machine learning methods for predicting COMPAS violence recidivism raw
score after subtracting fviol age with and without race as a feature. Age at COMPAS screening
date and age-at-ﬁrst-arrest are included as features.
Propublica seems to be incorrect in its claims of how COMPAS depends on race
If age and the components we have of the Criminal Involvement, History of Noncompliance,
and History of Violence subscales can only explain COMPAS scores to a limited extent, then
either the few components of these subscales that we are missing, or the remaining subscales,
Substance Abuse for the violence score and Vocational/Educational for both scores, must be a
large component of the scores. Reasoning these two subscales are highly correlated with race,
we then tried to model the COMPAS remainders (i.e., after subtracting the age splines) with race
as a feature, in addition to the available subscale components. Tables 4 and 5, respectively, show
the results of several machine learning methods for predicting the general and violence score
remainders. We see that these features cannot explain the COMPAS violence score remainders
very well. Thus, to conclude, we hypothesize that COMPAS has at most weak dependence on
race after conditioning on age and criminal history.
We replicated ProPublica’s ﬁnding that a model with race predicts COMPAS well, but disagree with their conclusions. We repeated ProPublica’s linear logistic regression on our slightly
modiﬁed dataset, leading to a model, provided in the supplementary materials in Table 9, whose
race coefﬁcient is large and signiﬁcantly different from zero. Coefﬁcients both for age and race
are both large.
There are several ﬂaws in this analysis. First, the linearity assumption is likely to be wrong,
as we know from considering the age analysis above. Second, the existence of an accurate
model that depends on race is not sufﬁcient to prove that COMPAS depends on race. Race
is correlated with both criminal history and with age in this dataset. Because the linearity
assumption is probably wrong, it is easily possible that race would appear to be signiﬁcant,
regardless of whether COMPAS is actually using race or its proxies (aside from criminal history
and age) as important variables. As shown in Tables 4 and 5, including race as a variable
to predict COMPAS does not improve prediction accuracy. That is, for each model we created
that uses race, we found another almost equally accurate model that does not use race. Thus, it is
not clear that race or its proxies (aside from criminal history and age) are necessarily important
factors in COMPAS.
In a separate analysis, Fisher et al. (33) consider all models that approximate COMPAS with
low loss, and among these, ﬁnd models that depend the most and the least on race.
COMPAS sometimes labels individuals with long or serious criminal histories as low-risk
We examine whether COMPAS scores can be low for individuals who pose a serious threat.
Recently in California (18, 19), a defendant with a long criminal history was released pre-trial
after a criminal history variable was inadvertently mistyped into a scoring system as being much
lower than its true value. The defendant murdered a bystander before his trial.
Typographical (data-entry) errors are extremely common (34), which means risk-score errors occur regularly. For instance, if each person’s COMPAS questionnaire contains 100+ questions, even a 1% error rate could cause multiple wrong entries on almost every person’s questionnaire. Data entry errors are a serious problem for medical records (35), and in numerous
other applications. The threat of typographical errors magniﬁes as the complexity of the scoring system increases; California had a very simple scoring system, and still typographical errors
have caused serious events discussed above.
In what follows, we use real names and public records found easily on the Internet, following ProPublica, which is a news organization that compiled this public database and published
real names and pictures of individuals within their report. It has been long debated whether this
kind of information should be public, with citizen protection being a main argument (e.g., background checks for potential employees in sensitive jobs). There is an irony of this information
being public, in contrast to the information actually used to make high-stakes decisions about
these individuals being secret. However, this public information may allow us to determine that
the secret information is potentially sometimes incorrect.
Consider the case of Desmond Rolle, whose criminal history included trafﬁcking cocaine
and aggravated battery of a pregnant woman, (felony battery — domestic battery by strangulation). He was given a COMPAS score of 1 (the lowest possible risk). A similar problem
occurs for several individuals in the database. Table 6 shows several such individuals who have
COMPAS scores that appear to have been calculated with incorrect inputs, or whose criminal
history information somehow has not been considered within the COMPAS formula. None of
these individuals has scores below the age spline (none are age outliers).
While it is possible that COMPAS includes mitigating factors (employment, education, drug
treatment) that reduce its score, it seems unlikely that they would reduce the score all the way
to the lowest possible value, but since the model is not published, we cannot actually determine
this. According to (36), the only negatively weighted factors in COMPAS are age and age at
ﬁrst arrest, but according to our analysis above, these variables remain essentially constant with
age for older individuals. This indicates there is no way to reduce a high score that might arise
from a lengthy criminal history. Thus, what we are observing (long criminal histories with a
low COMPAS violence score) should be impossible unless inputs have been entered incorrectly
or omitted from the COMPAS score altogether.
COMPAS general or violence scores do not include the current charges. Thus, in the case
of Martin Owens in the ProPublica database, charged with a serious crime (kidnapping) but no
prior crimes, he still receives the lowest-risk COMPAS score of 1.
There are many individuals in the database whose COMPAS scores appear to be unreasonably high; however, it is possible that for those individuals, there are extra risk factors that cause
them to be labeled high risk that are not in our database (e.g., incomplete criminal history information). Missing information would be able to explain COMPAS scores that seem too high,
but it cannot explain COMPAS scores that are too low, such as the ones we presented above in
Table 6. Figure 8 shows the predictions of a machine learning model versus COMPAS score.
There are a huge number of individuals whose COMPAS score is much larger than the machine
learning predictions, and also, there are many individuals for whom the machine learning model
(a boosted decision tree) indicates high risk of recidivism, but the COMPAS score indicates a
lower risk.
In cases like that of prisoner Glenn Rodr¨ıguez whose parole was denied because of a miscalculated COMPAS score (16,17), he did not notice the error on his COMPAS form until after his
Predicted probabilty of violent recidivism
COMPAS violent decile
Berry Sanders
Steven Glover
Richard Campbell
Oscar Pope
Travis Spencer
Martin Owens
Shandedra Hardy
Jesse Bernstein
Rufus Jackson
Anthony Hawthorne
John Coleman
Figure 8: Predicted probability of violent recidivism vs. COMPAS violence decile score. Individuals listed in Table 6 are highlighted.
parole was denied. Complicated forms, even if one is asked to check them over, lead to human
error. We are certain, for instance, that there are still errors in this paper, no matter how many
times we have checked it over – and the longer the paper, the more errors it probably contains.
Glenn Rodr¨ıguez is a proven example of a data input error, but his case further demonstrates that data input transparency alone is insufﬁcient to help wronged defendants, the scoring
mechanism must also be transparent. Mr. Rodr¨ıguez was unable to change his parole sentence
because he was unable to demonstrate that the data error impacted his COMPAS score.
Is age unfair? Fairness through the lens of transparent
Differences in true/false positive rates do not consider other factors like age and criminal history.
In ProPublica’s regression analysis of the COMPAS score, ProPublica conditioned on age and
criminal history among other factors, indicating they thought COMPAS would hold to some
notion of fairness had it depended only on age and criminal history. (Otherwise, why condition
on those two factors explicitly?). They used the signiﬁcance of the coefﬁcient on race to support
their conclusion of bias against blacks. However, they used a linear term for age and did not
handle unmeasured confounding, so this analysis was faulty. The faulty regression analysis
leaves the differences in true/positive rates as their only remaining evidence of bias. However,
the true/false positive rates are not conditioned on age and criminal history; that was why they
performed the regression analysis, suggesting the regression could mitigate bias. In other words,
Propublica’s second analysis (the regression model) was invalid because it assumed a linear
dependence on age. Their ﬁrst analysis (the true/false positive rate analysis) would also then
have been invalid for exactly the reasons why they conducted the second analysis (which is that
they would consider the model fair if COMPAS did not depend on race when conditioned on
age and criminal history).
Age is a well-known determining risk factor for recidivism. Many recidivism scoring systems depend on age (21, 37–44) since it has no direct causal relationship with race (race does
not cause age, age does not cause race), and it is a good predictor of future crime. For adults,
the risk of recidivism decreases with age.4
On the other hand, in the Broward County data, African-American people tend to be disproportionately represented at younger ages than Caucasians; the median age of a COMPAS
assessment on an African-American person is 27 years whereas the median age of a Caucasian
is 33 years.5 This means that more African-Americans will be labeled as high risk than Caucasians. This also means that more African-Americans will be mistakenly labeled as high risk
than caucasians. It also means that more Caucasians will be mistakenly labeled as low risk than
African-Americans. Because of the difference in ages between blacks and whites in the dataset,
even models that consider only age and criminal history can be as “unfair” as COMPAS by
ProPublica’s true/false positive rate analysis.
Figure 9 shows the true positive rate (TPR), false positive rate (FPR), true negative rate
(TNR) and false negative rates (FNR) for the model age, which is deﬁned to be “If age ≤24,
then predict arrest within 2 years, otherwise predict no arrest.” The ﬁgure also shows the rates
for the COMPAS general recidivism score. The data were divided into 10 randomly chosen
folds, and the rates are plotted for all folds, showing a consistent pattern across folds. Indeed,
we observe higher false positive rates for African-Americans, and higher false negative rates for
Caucasians. There is an elevated ≈10% higher FPR for African-Americans than for Caucasians
for age, and a ≈10% higher FNR for Caucasians than African-Americans for age. These differ-
4Figure 10 in the appendix plots the probability of 2-year recidivism (deﬁned by arrest within 2 years) as a
function of age for individuals in Broward County, Florida, showing how it decreases as a function of age.
5see the supplementary materials for full distributions
Figure 9: Rates for the simple age model and for the COMPAS score. Age appears also to be
ing levels constitute one of the accusations of unfairness by ProPublica, which means that age
is an unfair risk prediction model by this deﬁnition. COMPAS seems to be more “unfair” than
age, but as we have seen, it may be possible to explain this unfairness by a combination of age
and other features that differ between the distributions of African-Americans and Caucasians
and have little to do with the COMPAS score itself. In fact, we also know from (24) that a
very simple model involving age and the number of priors is just as unfair as COMPAS by this
deﬁnition.
The many deﬁnitions of fairness often contradict with each other. Had ProPublica considered just the transparent model age (instead of analyzing COMPAS), it would have been easy to
see that the difference in age populations between African-Americans and Caucasians caused
their two notions of fairness to disagree. In that case, would they still have written an article
claiming that the difference in true and false positive rates meant that COMPAS was unfair?
Or would they have claimed that the use of age was unfair rather than conditioning on it? Or
would they have claimed the data collection process was unfair? Using a transparent model can
sometimes enlighten an understanding of the debate on fairness.
The consequences of using age in criminal risk assessments are explained nicely by (45),
however, the use of criminal history to assess fairness is confusing for additional reasons. If we
do use criminal history in risk prediction, since African-Americans tend to have longer criminal
histories, their scores will be worse. On the other hand, if we do not use criminal history, our
risk predictions would be worse. In that case, we could be releasing dangerous criminals based
on poor pre-trial risk assessments, which leads to poor decisions for the public.
Of course, if we eliminate the most important predictors of recidivism (age and criminal
history) on grounds of leading to unfair models, it is not clear that any useful predictors of
criminal recidivism remain. In that case, we could be stuck in the situation where a human
decision-maker provides non-transparent, potentially biased decisions.
The point of this exercise is not to determine whether the age model is fair by any given
deﬁnition – the age model is transparent, which makes it much easier to debate, and useful for
explaining different possible deﬁnitions of fairness and how they may never intersect. ProPublica’s regression analysis seems to assume that using age in a risk prediction model is reasonable. But is age unfair? If we cannot decide on whether the age model is fair, we certainly
cannot decide on whether COMPAS is unfair. However, it is certainly much easier to debate
about the transparent and simple age model than about a black-box scoring system. While a
review of the numerous deﬁnitions of fairness (46, 47) is outside the scope of this work, a potentially easy way to alter the deﬁnition of fairness is to control for non-protected covariates
such as age. In that case, as long as predictions for African-Americans and Caucasians have
equal true/false positive rates for each age group, then the model would be considered fair. Of
course, a problem with this deﬁnition is that any policy that targets young people disproportionately affects African-Americans.
Discussion
After attempting to isolate COMPAS’ dependence on age, we were able to investigate how much
COMPAS can depend on criminal history and proxies for race. We found that it is unlikely
that COMPAS depends heavily on either of them. Machine learning methods for predicting
COMPAS scores performed equally well with or without direct knowledge of race. This seems
to contradict ProPublica’s claims, but ProPublica’s methodological assumptions (at least about
COMPAS depending linearly with age) were wrong, which caused their conclusions to be faulty.
Northpointe claims the current charge is not helpful for prediction of future violent offenses (36). (Oddly, they have a separate “Current Violence” scale that includes the current
charges, but which is not claimed to be predictive.) How much should one weigh the current
charges with the COMPAS scores? This is not clear. Because COMPAS is a black box, it is
difﬁcult for practitioners to combine the current charge (or any other outside information) with
the COMPAS scores. Because the current charges are separate, COMPAS scores are not single
numbers that represents risk. Instead their interpretation has a large degree of freedom. Could
decision-makers fail to realize that the COMPAS score does not include the current charge?
Perhaps this alone could lead to faulty decision-making.
We showed examples where COMPAS scores can label individuals with long criminal histories as low-risk. This could easily stem from a lack of transparency in COMPAS and could
lead to dangerous situations for the public. Even if COMPAS were completely fair, by some
reasonable deﬁnition of fairness, this would not stop it from being miscalculated, leading to a
form of procedural unfairness. Since it is known that COMPAS is no more useful for predicting
recidivism than simple, interpretable models, there is no good reason to continue using complicated, expensive, error-prone proprietary models for this purpose. There is a mystique behind
the use of black box models for prediction. However, just because a model is a proprietary does
not mean it is any better than a publicly available model (48).
Interestingly, a system that relies only on judges – and does not use machine learning at all
– has similar disadvantages to COMPAS; the thought processes of judges is (like COMPAS)
a black box that provides inconsistent error-prone decisions. Removing COMPAS from the
criminal justice system, without a transparent alternative, would still leave us with a black box.
Privacy of data should be more of a concern than it presently is. If COMPAS does not
depend heavily on most of the 137 variables, including the proxies for socioeconomic status, it is
not clear if Northpointe is justiﬁed in collecting such private information. COMPAS is a risk and
needs assessment, but is that private information necessary to assess an individual’s needs? All
evidence suggests it does not seem to be necessary for estimating risk. Determination of needs
seems to be a complicated causal question about who beneﬁts from what types of treatments.
This issue is beyond the scope of this article, but is important. Northpointe’s control over
criminal risk scores is analogous to Equifax’s control over credit scores, and leads to inherent
privacy risks.
Thus, our ﬁndings indicate that some form of unfairness caused by COMPAS can affect almost everyone involved in the justice system: 1) lack of transparency makes it difﬁcult to assess
any of the myriad forms of fairness, leading to faulty arguments like those of ProPublica. Lack
of transparency can hide bias towards underrepresented groups, or conversely, it can make fair
models seem biased. 2) The unnecessary complexity of COMPAS could cause injustice to those
who had typos in the COMPAS computation, and as a result, were given extra long sentences
or denial of parole. (This is procedural unfairness.) 3) It is possibly unfair to the taxpayers and
judicial system to pay for the collection of long COMPAS surveys and COMPAS predictions
when simpler, transparent, options are available. (Poor designation of public resources is unfair
to everyone.) 4) The subgroup of people who provided very private personal information (e.g.,
about their family history of crime or poverty) to Northpointe has potentially been wronged.
(There is a form of privacy unfairness in being forced to provide personal information to an
entity when it is unnecessary to do so.)
The problems with COMPAS pertain to many industries. Without community standards or
policy requirements for transparency, business considerations disincentivize creators of models
to disclose their formulas. However, this lack of transparency is precisely what allows error to
propagate and results in damage to society (48). Merely being able to explain black box models
is not sufﬁcient to resolve this – the models need to be fully transparent, and in criminal justice,
there is no loss in predictive accuracy for using a transparent model.
Our code is here: