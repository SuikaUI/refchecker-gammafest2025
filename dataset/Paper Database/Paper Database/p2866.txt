SPARSE REPRESENTATION FOR COLOR IMAGE RESTORATION
Julien Mairal
Michael Elad
Guillermo Sapiro
IMA Preprint Series # 2139
 
INSTITUTE FOR MATHEMATICS AND ITS APPLICATIONS
UNIVERSITY OF MINNESOTA
400 Lind Hall
207 Church Street S.E.
Minneapolis, Minnesota 55455–0436
Phone: 612/624-6066
Fax: 612/626-7370
URL: 
Sparse Representation for Color Image
Restoration
Julien Mairal,1∗
Michael Elad,2
and Guillermo Sapiro3
Sparse representations of signals have drawn considerable interest in recent years. The assumption
that natural signals, such as images, admit a sparse decomposition over a redundant dictionary leads
to efﬁcient algorithms for handling such sources of data. In particular, the design of well adapted
dictionaries for images has been a major challenge. The K-SVD has been recently proposed for this
task , and shown to perform very well for various gray-scale image processing tasks. In this paper
we address the problem of learning dictionaries for color images and extend the K-SVD-based grayscale image denoising algorithm that appears in . This work puts forward ways for handling nonhomogeneous noise and missing information, paving the way to state-of-the-art results in applications
such as color image denoising, demosaicing, and inpainting, as demonstrated in this paper.
EDICS Category: COL-COLR (Color processing)
I. INTRODUCTION
In signal and image processing we often impose an arbitrary model to describe the data source.
Such a model becomes paramount when developing algorithms for processing these signals. In
this context, Markov-Random-Field (MRF), Principal-Component-Analysis (PCA), and other
related techniques are popular and often used.
Work partially supported by NSF, ONR, NGA, DARPA, and the McKnight Foundation.
1. Department of Electrical and Computer Engineering, University of Minnesota, 200 Union Street SE Minneapolis, MN
55455 USA, Email: . Phone: +1-612-6251343. Fax: +1-612-6254583.
2. Department of Computer Science, The Technion – Israel Institute of Technology, Haifa 32000 Israel, Email:
 . Phone: +972-4-829-4169. Fax: +972-4-829-4353.
3.Department of Electrical and Computer Engineering, University of Minnesota, 200 Union Street SE Minneapolis, MN 55455
USA, E-mail: . Phone: +1-612-6251343. Fax: +1-612-6254583.
The Sparseland model is an emerging and powerful method to describe signals based on the
sparsity and redundancy of their representations , . For signals from a class Γ ⊂Rn, this
model suggests the existence of a speciﬁc dictionary (i.e., a matrix) D ∈Rn×k which contains
k prototype signals, also referred to as atoms. The model assumes that for any signal x ∈Γ,
there exists a sparse linear combination of atoms from D that approximates it well. Put more
formally, this reads
∀x ∈Γ, ∃α ∈Rk
x ≈Dα and ∥α∥0 ≪n.
The notation ∥· ∥0 is the ℓ0-norm which counts the number of non-zero elements in a vector.
We typically assume that k > n, implying that the dictionary D is redundant in describing x.
If we consider the case where Γ is the set of natural images, dictionaries such as wavelets
of various sorts , curvelets , , contourlets , , wedgelets , bandlets , ,
and steerable wavelets , , are all attempts to design dictionaries that fulﬁll the above
model assumption. Indeed, these various transforms have led to highly effective algorithms in
many applications in image processing, such as compression , denoising , , ,
 , inpainting , and more. Common to all these pre-deﬁned dictionaries is their analytical
nature, and their reliance on the geometrical nature of natural images, especially piece-wise
smooth ones.
In , the authors introduce the K-SVD algorithm, a way to learn a dictionary, instead of
exploiting pre-deﬁned ones as described above, that leads to sparse representations on training
signals drawn from Γ. This algorithm uses either Orthogonal Matching Pursuit (OMP) , ,
 , or Basis Pursuit (BP), , as part of its iterative procedure for learning the dictionary.
The follow-up work reported in , proposes a novel and highly effective image denoising
algorithm for the removal of additive white Gaussian noise with gray-scale images. Their proposed method includes the use of the K-SVD for learning the dictionary from the noisy image
In this paper, our main aim is to extend the algorithm reported in to color images (and
to vector-valued images in general), and then show the applicability of this extension to other
inverse problems in color image processing. The extension to color can be easily performed by a
simple concatenation of the RGB values to a single vector and training on those directly, which
gives already better results than denoising each channel separately. However, such a process
produces false colors and artifacts, which are typically encountered in color image processing.
The ﬁrst part of this work presents a method to overcome these artifacts, by adapting the OMP
inner-product (metric) deﬁnition.
This paper also describes an extension of the denoising algorithm to the proper handling of
non-homogeneous noise. This development is crucial in cases of missing values, such as in the
color image demosaicing and the inpainting problems. Treating the missing values as corrupted
by a strong (impulse) noise, our general setting ﬁts both problems. We demonstrate the success
of the proposed scheme in demosaicing and inpainting, as well as color denoising applications,
exhibiting in all cases state-of-the-art results. We also show that interacting between the learning
and the restoration further improves the color image processing results.
This paper is organized as follows – In Section 2 we describe prior art on example-based image
denoising (and general image processing) methods. Section 3 is devoted to a brief description of
the K-SVD-based gray-scale image denoising algorithm as proposed in . Section 4 describes
the novelties offered in this paper – the extension to color images, the handling of color artifacts,
and ﬁnally the treatment of non-homogeneous noise, along with its relation to demosaicing and
inpainting. In Section 5 we provide various experiments that demonstrate the effectiveness of the
proposed algorithms. Section 6 concludes this paper with a brief description of its contributions
and a list of open questions for future work, including preliminary discussion and results on
how to extend the above to a multiscale algorithm.
II. PRIOR ART
Many problems in image processing and computer vision are in a dire need for prior models
of the images they handle. This is especially true whenever information is missing, damaged, or
modiﬁed. Armed with a good generic image prior, restoration algorithms become very effective.
The research activity on the topic of image priors is too wide to be compacted into this paper, and
as our interest is primarily in learned priors, such general survey is beyond its scope anyhow.
We therefore restrict our discussion to recent methods that lean on image examples in their
construction of the prior.
When basing the learned prior on image examples, the ﬁrst junction to cross is the one which
splits between parametric and non-parametric prior models. The parametric path suggests an
analytical expression for the prior, and directs the learning process to tune the prior parameters
based on examples. Such is the case with the MRF prior learned in and later in ,
 ; the wavelet based image prior as appears in ; the Tikhonov regularization proposed by
Haber and Tenorio ; the super-resolution approach adopted by Baker and Kanade ; and
the recent K-SVD denoising as described in , .
The alternative path, a non-parametric learning, use image examples directly within the reconstruction process, as practiced by Efros and Leung for texture synthesis ; by Freeman
et. al. for super-resolution , ; and by several follow-up works , , , for
super-resolution and inpainting. Interestingly, most of the above direct methods avoid the prior
and target instead the posterior density, from which reconstruction is easily obtained.
The second major junction to cross in exploiting examples refers to the question of the origin
of these examples. Many of the above described works use a separate corpus of training images
for learning the prior (or its parameters). The alternative option is to use examples from the
corrupted image itself. This surprising idea has been proposed in as a universal denoiser of
images, which learns the posterior from the given image in a way inspired by the Lempel-Ziv
universal compression algorithm. Another path of such works is the Non-Local-Means , 
and related works , . Interestingly, the work in belongs to this family as well, as the
dictionary can be based on the noisy image itself.
Most of the above methods deploy processing of small image patches, a theme that characterizes our method as well. In this paper we present a framework for learning a sparsifying
dictionary for color image patches taken from natural images. As such, the approach we adopt
is the parametric one. The learning we propose leans on both external data-set, as well as on
the damaged image directly. The novelty of this paper is in the way of introducing the color to
the K-SVD algorithm such that it avoids typical artifacts, and its extension to non homogeneous
noise, which enables the handling of color inpainting and demosaicing.
The only work we are aware of, which handles color images within the framework of parametric learned models, is the one reported in . This work builds on the Field of Experts, as
developed in , to learn an MRF model for color images, and uses it successfully for image
denoising. The main theme of this paper is an attempt to circumvent the high-dimensionality of
the training space by several simpliﬁcations over the original method in . Color artifacts are
not mentioned, and indeed, the shown results demonstrate a phenomenon we have experienced
too, of a tendency to wash-out the color content of the image. We address this in this paper
by proposing a new metric in the sparsity representation. We will return to this work in the
experimental results section, and show comparisons of performance favorable to our framework.
III. THE GRAY-SCALE K-SVD DENOISING ALGORITHM
In , , Aharon and Elad present a K-SVD-based algorithm for denoising of gray-scale
images with additive homogeneous white Gaussian noise. We now brieﬂy review the main
mathematical framework of this approach, as our work builds upon it. First, let x0 be a clean
image written as a column vector of length N. Then one considers its noisy version,
y = x0 + w,
where w is a white Gaussian noise with a spatially uniform deviation σ, which is assumed to be
known. Given ﬁxed-size patches √n×√n, one assumes that all such patches in the clean image
x0 admit a sparse representation. Addressing the denoising problem as a sparse decomposition
technique per each patch leads to the following energy minimization problem:
αij, ˆD, ˆx
D,αij,x λ||x −y||2
µij||αij||0 +
||Dαij −Rijx||2
In this equation, ˆx is the estimator of x0, and the dictionary ˆD ∈Rn×k is an estimator of the
optimal dictionary which leads to the sparsest representation of the patches in the recovered
image. The indices [i, j] mark the location of the patch in the image (representing it’s top-left
corner). The vectors ˆαij ∈Rk are the sparse representations for the [i, j]-th patch in ˆx using the
dictionary ˆD. The operator Rij is a binary n × N matrix which extracts the square √n × √n
patch of coordinates [i, j] from the image written as a column vector of size N.
The ﬁrst term in Equation (1) introduces the likelihood force that demands a proximity between
ˆx and y. The second and the third terms together pose the image prior. This regularization term
assumes that good-behaved natural images are to exhibit a sparse representation for every patch,
and from every location in the image, over the learned dictionary ˆD. The second term provides
the sparsest representation, and the third term ensures the consistency of the decomposition.
The choice of the norm L2 is relatively arbitrary, and could be changed in this formulation, as
later proposed in this paper for color images. Note that norms different than L2 might lead to
difﬁculties in the minimization.
To approximate a solution for this complex minimization task, the authors of , put
forward an iterative method that incorporates the K-SVD algorithm, as presented in . Figure
1 presents this image denoising algorithm in details.
Parameters: λ (Lagrange multiplier); C (noise gain); J (the number of iterations); k
(size of the dictionary); n (size of the patches and the atoms).
Initialization: Set ˆx = y; Let ˆD = (ˆdl)l∈1...k be some initial dictionary.
Loop: Repeat J times
• Sparse Coding: Fix ˆD and use OMP to compute ˆαij per each patch by solving
ˆαij = arg min
α ||α||0 subject to ||Rijˆx −ˆDα||2
2 ≤n(Cσ)2.
• Dictionary Update: Fix all ˆαij, and for each atom l ∈1, 2, . . ., k in ˆD,
– Select the set of patches which use this atom, ωl = {[i, j]|ˆαij(l) ̸= 0}.
– For each patch [i, j] ∈ωl, compute its residual, el
ij = Rijˆx−ˆDˆαij + ˆdlˆαij(l).
– Set El as the matrix whose columns are the el
ij, and ˆαl the row vector whose
elements are the ˆαij(l).
– Update ˆdl and the ˆαij(l) by minimizing:
(ˆdl, ˆαl) = arg
α,||d||2=1 ||El −dα||2
This one-rank approximation is performed by a truncated Singular Value
Decomposition (SVD) of the matrix El.
Averaging: Perform a weighted average:
The K-SVD-based image denoising algorithm as proposed in .
One can notice that different steps in this algorithm reject the noise. First, the Matching Pursuit
(OMP) stops when the approximation reaches a sphere of radius √nCσ in the patches’ space
in order not to reconstruct the noise. Then, the SVD selects an “average” new direction for
each atom, which rejects noise from the dictionary. Finally, the last formula performs an average
between the representation of overlapping patches.
Here, the choice of the parameter C is very important and depends on the dimension of
the patches: If w′ is a n-dimensional Gaussian vector, ||w′||2 is distributed by the generalized
Rayleigh law which leads to the following result:
P(||w′||2 ≤√nCσ) =
2 −1e−zdz.
In , C was tuned empirically to C = 1.15 for n = 8 × 8 = 64. Here we choose the rule
P(||w′||2 ≤√nCσ) = 0.93,
which provides a good parameter C for any dimension n.
This approach leads to state-of-the-art gray-scale image denoising performance as shown in
 , . The main challenge to extend this work to color images is to make it able to capture
some correlation between the channels and to reconstruct the image without adding artifacts. Both
simple methods, such as denoising each channel separately and denoising directly each patch
as a long concatenated RGB vector, fail respectively in one of these two challenges. Moreover,
for classical color image processing applications such as demosaicing, denoising, and image
inpainting, , spatial and/or spectral non-uniform noise has to be handled. These challenges
are addressed next.
IV. SPARSE COLOR IMAGE REPRESENTATION
We now turn to detail the proposed fundamental extensions to the above gray-scale framework,
and put forward algorithms addressing several different tasks, such as denoising of color images,
denoising with non-uniform noise, inpainting small holes of color images, and demosaicing.
A. Denoising of color images
The simplest way to extend the K-SVD algorithm to the denoising of color images is to denoise
each single channel using a separate algorithm with possibly different dictionaries. However,
our goal is to take advantage of the learning capabilities of the K-SVD algorithm to capture the
correlation between the different color channels. We will show in our experimental results that
a joint method outperforms this trivial plane-by-plane denoising. Recall that although in this
paper we concentrate on color images, the key extension components here introduced are valid
for other modalities of vector-valued images, where the correlation between the planes might be
even stronger.
The problem we address is the denoising of RGB color images, represented by a column
vector y, contaminated by some white Gaussian noise w with a known deviation σ, which
has been added to each channel. (As we show below, the noise does not have to be uniform
across the channels or across the image.) Color-spaces such as YCbCr, Lab, and other Luminance/Chrominance separations are often used in image denoising because it is natural to handle
the chroma and luma layers differently, and also because the L2-norm in these spaces is more
reliable and better reﬂects the human visual system’s perception. However, in this work we
choose to stay with the original RGB space, as any color conversion changes the structure of
the noise. Since the OMP step in the algorithm uses an intrinsic hypothesis of a noise with a
sphere structure in the patches’ space, such assumption remains valid only in the RGB domain.
Other noise geometries do not necessarily guarantee the performance of the OMP.
In order to keep a reasonable computational complexity for the color extensions presented in
this work, we use dictionaries that are not particularly larger than those practiced in the gray-scale
version of the algorithm. More speciﬁcally, in the authors use dictionaries with 256 atoms
and patches of size 8×8. Applying directly the K-SVD algorithm on (three dimensional) patches
of size 8 × 8 × 3 (containing the RGB layers) with 256 atoms, leads already to substantially
better results than denoising each channel separately. However, this direct approach produces
artifacts – especially a tendency to reduce the color saturation in the reconstruction. We observe
that during the algorithm, the OMP is likely to follow the “gray” axis, which is the axis deﬁned
by r = g = b in the RGB color space.
Before proceeding to explain the proposed solution to this color bias and washing effect, let
us explain why it happens. As mentioned before, this effect can be seen in the results in ,
although it has not been explicitly addressed there.
First, at the intuitive level, relatively small dictionaries within the order of 256 atoms, for
example, are not rich enough to represent the diversity of colors in natural images. Therefore,
training a dictionary on a generic database leads to many gray or low chrominance atoms which
represent the basic spatial structures of the images. This behavior can be observed in Figure
2. This result is not unexpected since this global dictionary is aiming at being generic. This
predominance of gray atoms in the dictionary encourages the image patches approximation to
“follow” the gray axis by picking some gray atoms (via the OMP step, see below), and this
introduces a bias and color washing in the reconstruction. Examples of such color artifacts
resulting from global dictionaries are presented in Figure 3. Using an adaptive dictionary tends
to reduce but not eliminate these artifacts. A look at the dictionary in Figure 4, learned on a
speciﬁc image instead of a database (global dictionary), shows that the atoms are usually more
colored. Our experiments showed that these color artifacts are still present on some image details
even with adaptive dictionaries. One might be tempted to solve the above problem by increasing
k and thus adding redundancy to the dictionary. This, however, is counter productive in two
important ways - the obtained algorithm becomes computationally more demanding, and as the
images we handle are getting close in size to the dictionary, over-ﬁtting in the learning process
in unavoidable.
(a) 5 × 5 × 3 patches
(b) 8 × 8 × 3 patches
Dictionaries with 256 atoms learned on a generic database of natural images, with two different sizes of patches. Note
the large number of color-less atoms. Since the atoms can have negative values, the vectors are presented scaled and shifted to
the range per channel.
We address this color problem by changing the metric of the OMP as it will be explained
shortly. The OMP is a greedy algorithm that aims to approximate a solution of Equation (2). It
consists of selecting at each iteration the best atom from the dictionary, which is the one that
maximizes its inner product with the residual (minimizing the error metric), and then updating
the residual by performing an orthogonal projection of the signal one wants to approximate
(a) Original
(b) Original algorithm, γ = 0,
PSNR=28.78 dB
(c) Proposed algorithm, γ =
5.25, PSNR=30.04 dB
Examples of color artifacts while reconstructing a damaged version of the image 3(a) without the improvement here
proposed (γ = 0 in the new metric). Color artifacts are reduced with our proposed technique (γ = 5.25 in our proposed new
metric). Both images have been denoised with the same global dictionary. In 3(b), one observes a bias effect in the color from
the castle and in some part of the water. What is more, the color of the sky is piecewise constant when γ = 0 (false contours),
which is another artifact our approach corrected.
onto the vectorial space generated by the previously selected atoms. This orthogonalization is
important since it gives more stability and a faster convergence for this greedy algorithm. For
details, the reader should refer to , , .
An additional, more formal way to explain the lack of colors and the color bias in the
reconstruction is to note that the OMP does not guarantee that the reconstructed patch will
maintain the average color of the original one. Therefore, the following relationship for the
patch ij, E(Rijy) = E(Rijx0 + Rijw) = E(Rijˆx), does not necessarily hold. If the diversity
of colors is not important enough in the dictionary, the pursuit is likely to follow some other
direction in the patches’ space. But with color images and the corresponding increase in the
dimensionality, our experiments show that this is clearly the case. To address this, we add a
force during the OMP which tends to minimize also the bias between the input image and the
reconstruction on each channel. Considering that y and x are two patches written as column
vectors (R, G, B)T, we deﬁne a new inner product to be used in the OMP step:
< y, x >γ= yTx + γ
n2yTKTKx = yT(I + γ
(a) Training Image
(b) Resulting dictionary
Figure 4(b) is the dictionary learned on the image 4(a). The dictionary is more colored than the global one.
Here, Jn is a n × n matrix ﬁlled with ones, and γ is a new parameter which can be tuned
to increase or discard this correction. We empirically ﬁxed this parameter to γ = 5.25. The
ﬁrst term in this equation is the ordinary Euclidean inner product. The second term with the
matrix K computes an estimator of E(y) and E(x) on each channel and multiplies them, thereby
forcing the selected atoms to take into account the average colors. Examples of results from our
algorithm are presented on Figure 3, with different values for this parameter γ, illustrating the
efﬁciency of our approach in reducing the color artifacts. This correction proved to be crucial
in our process, especially for global dictionaries which have a lot of gray atoms as mentioned
A simple implementation of the above ideas follows from the simple fact that I + γ
nK)T(I + a
nK), with γ = 2a + a2. Thereby, scaling each patch and each atom of the
dictionary by multiplying them by I+ a
nK, and taking into account a normalization factor, leads
to a straightforward implementation of the OMP with the new inner product. This approach
effectively changes the metric in Equation (2). We chose not to change the stopping criterion
in the OMP to prevent any blurring effect due to the increase in low frequency caused by this
scaling. One could wonder why we chose not to change the metric as well in equations (3) and
(4), and thereby in Equation (1) (this could effectively be achieved by keeping the scaled image
and dictionaries all across the algorithm). In fact, this metric (inner product) modiﬁcation is here
simply to correct a defect of the OMP when a dictionary can not provide enough diversity in
the choice of colors and does not aim at changing the global formulation.
To conclude, the basic color denoising algorithm follows the original K-SVD, applied to
√n×√n×3 patches, with a new metric in the OMP step that explicitly addresses critical color
artifacts.
B. Extension to non-homogeneous noise
We now extend the K-SVD algorithm to non-uniform noise. This problem is very important
as non-uniform noise across color channels is very common in digital cameras. Spatially nonuniform noise also becomes very important for color demosaicing and inpainting.
To simplify the presentation, we ﬁrst consider the case of gray-scale images. We denote by
σp > 0 the deviation of the noise at the pixel p. We assume that this vector σ is known (this
assumption is natural for demosaicing, inpainting, and color dependent noise). In order to be
able to use a consistent OMP, we need to have a sphere structure for the noise in the patches’
space. This can be explained by the fact that this greedy algorithm aims at ﬁnding the sparsest
path from the null vector to the vector to approximate in the space generated by the dictionary,
by selecting iteratively atoms and reducing the norm of the residual. To prevent the algorithm
to retrieve the noise, one has to stop the pursuit when it reaches a high probability of ﬁnding
the value of the non-noisy patch. As the only aim of the algorithm is to reduce the norm of the
residual, the algorithm will provide a maximum efﬁciency if the stopping criterion is based on a
threshold for this norm, thereby it imposes a sphere structure for the noise in the norm’s metric.
The ﬁrst natural idea would be to scale the data so that the deviation of the noise becomes
uniform. Scaling the data and then approximating the scaled models leads to loose the image
natural structure, which is exactly what we are trying to learn and exploit. Therefore, we need to
approximate the non-scaled data using a different metric for each patch where the noise would
have a sphere structure. Introducing a vector β composed of weights for each pixel:
βp = minp′∈Image σp′
It leads us to deﬁne a weighted K-SVD algorithm based on a different metric for each patch.
Denoting by ⊗the element-wise multiplication between two vectors, we aim at solving the
following problem, which replaces Equation (1):
αij, ˆD, ˆx
D,αij,x λ||β⊗(x−y)||2
µij||αij||0+
||(Rijβ)⊗(Dαij−Rijx)||2
The OMP step then aims at solving the following equation for the patch ij, instead of (2):
∀ij, ˆαij = arg min
α ||α||0 subject to ||(Rijβ) ⊗(Rijˆx −ˆDα)||2
2 ≤||Rijβ||0(C min
The term ||Rijβ||0 here counts the number of pixels in the patch ij without a coefﬁcient β equal
to zero which should therefore be taken into account. The new inner product (metric) associated
with our problem for any vector x and y becomes:
< x, y >ij
((Rijβ) ⊗x)T((Rijβ) ⊗y).
Concerning the learning step, the natural approach consists of minimizing for each atom l the
following energy, instead of Equation (3):
(ˆdl, ˆαl) = arg
α,||d||2=1 ||βl ⊗(El −dα)||2
where βl is the matrix whose size is the same as El and where each column corresponding to
an index [i, j] is Rijβ. This problem is known as a weighted one-rank approximation matrix, is
not simple and has not an unique solution. In , Srebro and Jaakkola put forward a simple
iterative algorithm which gives an approximated solution of a local minimum. Nevertheless, this
algorithm requires a SVD for each of its iterations, being relatively complex. We chose instead
for each atom l to perform a one-rank approximation with a single truncated SVD of the most
consistent term, which is composed of the contribution of one atom in the reconstruction plus
its weighted residual:
(ˆdl, ˆαl) = arg
α,||d||2=1 ||Eβ
l is the matrix whose columns are
l (ij) = (Rijβ) ⊗(Rijˆx −ˆDˆαij)
weighted residual
+ ˆdl ˆαij(l)
contribution
Note that we can rewrite this expression as
l (ij) = (Rijβ) ⊗(Rijˆx −ˆDˆαij + ˆdl ˆαij(l)) + (1n −Rijβ) ⊗ˆdl ˆαij(l),
where 1n denotes a column vector ﬁlled with ones. This is actually the ﬁrst iteration of the
algorithm put forward by Srebro and Jaakkola in . One can interpret the ﬁrst term (Rijβ) ⊗
(Rijˆx −ˆDˆαij + ˆdl ˆαij(l)) as the relevant information we dispose to make the atoms evolve,
whereas (1n −Rijβ)⊗ˆdl ˆαij(l) can be viewed as a balancing term, completing the equation and
permitting to perform the SVD.
Finally, note that the averaging expression, Equation (4), remains the same (modulo the I and
y in the average, which are weighted by β), since all has been taken into consideration in the
previous stages of the algorithm.
Let us now present the model that combines this non-uniform noise handling with the one
developed to deal with color artifacts introduced in the previous section. Mixing these two new
metrics for each patch ij, we use then the following new inner product (metric) during the OMP
step only:
< x, y >ij
((Rijβ) ⊗x)T(I + γ
nK)((Rijβ) ⊗y)
Concerning the learning step, it remains identical to Equation (9), since it does not need any
color/bias correction.
To conclude, we have now introduced a new metric that addresses possible color artifacts as
well as non-uniform noise. This paves the way for applications beyond color image denoising,
and these are described next.
C. Color image inpainting
Image inpainting is the art of modifying an image in an undetectable form, and it often refers
to the ﬁlling-in of holes of missing information in the image . Although sparsity, as practiced
here with localized patches, is not necessarily an efﬁcient model for ﬁlling large holes, since it
would intrinsically lead to a lack of details, one can still use it for ﬁlling small holes, as long
as their sizes are smaller than the size of the atoms. For larger holes, iterative and/or multiscale
or texture synthesis methods like in are needed.
The idea for extending the previously described work for inpainting is quite simple. If one
considers holes as areas with inﬁnite power noise, this leads to some βij coefﬁcients equal to
0. To make the model consistent we also ﬁxed σ = ǫ > 0 in the known areas to prevent inﬁnite
β-coefﬁcients. Finally, we consider two possibilities:
• If we have both noise and missing information (holes), we use the model exactly as described
above for color image restoration with non-uniform noise.
• If we only have missing information, we change the OMP so that it runs for not more
than a ﬁxed number of iterations (this replaces the error-based stopping criteria). Then we
use the information of the reconstructed image to ﬁll-in the holes. This approach is faster
because it does not force the OMP to ﬁt exactly the known areas and gives similar visual
Note also that within the limit of our model, some β-coefﬁcients equal to zero can mask parts
of some unnatural atoms, which could end-up being used. Therefore, we initialize the algorithm
with a global dictionary learned on a large dataset of clean and hole-free images, preventing
the use of non natural patterns like the atoms in the 3D-DCT dictionary, which proved to be
inefﬁcient in our experiments for inpainting.
Another possible problem can occur when the matrix of the coefﬁcients β follows a regular
pattern. This can lead our algorithm to learn this pattern, absorb it into the dictionary, and thus
overﬁt. A successful strategy for preventing this is presented in the demosaicing section next,
where the holes do form a repetitive pattern (this is much more unusual in ordinary inpainting
applications). Note also that with inpainting, we do not have the problem of color artifacts
anymore because the constraints of reconstruction are hard (meaning they tend to have a perfect
reconstruction on some parts of the image), thereby preventing any bias problem. That is why
we chose γ = 0 in this case.
To conclude, the model for non-uniform noise can be readily exploited for color image
inpainting, and examples on this are presented in the experimental section.
D. Color image demosaicing
The problem of color demosaicing consists of reconstructing a full resolution image from
the raw data produced by a common colored-ﬁltered sensor. Most digital cameras use CCD or
CMOS sensors, which are composed of a grid of sensors. One sensor is associated to one pixel
and is able to measure the light energy it receives during a short time. Combined with a color
ﬁlter (R (red), G (green), or B (blue)), it retrieves the color information of one speciﬁc channel.
Therefore, often only one color for each pixel is obtained and interpolation of the the missing
values is necessary. The most used pattern for this is the Bayer pattern, GRGRGR. . . on odd
lines and BGBGBG. . . on even ones.
Several algorithms have been developed in recent years to produce high quality full color
images from the mosaic sensor, e.g., , , , . Although color demosaicing is becoming less relevant with the on-going development of sensor and camera technology, addressing
it remains a challenging task that helps to test the effectiveness of different image models and
image processing algorithms. We thereby chose to address this problem as a proof of the relevance
of our model, helping to show the generality of our framework. The fact that our general model
performs as well or even better than state-of-the-art algorithms exclusively developed for image
demosaicing, shows the correctness of our approach, and the generality of the sparsity and
redundancy concepts, along with the appropriateness of the K-SVD algorithm for learning the
dictionary.
We opt to deﬁne the problem of demosaicing as an inpainting problem with very small holes
which consist of two missing channels per pixel. Considering that we do not need any smoothing
effects to get rid of some noise (assuming for the sake of simplicity that the available colors
are noise free), neither we need to inpaint large holes, we chose to restrain the algorithm to use
small patches well adapted for retrieving details. We chose thus 5 × 5 × 3 patches.
One drawback of our modiﬁed K-SVD algorithm with β coefﬁcients is that the presence of
a (hole) pattern in the matrix β can lead the algorithm to learn it (the pattern would appear
in the dictionary atoms). A simple way of addressing this problem is to use a globally learned
dictionary with no-mosaic images. This gives already quite good results, and as we shall show
next, can be further improved.
We introduce the idea of learning the dictionary on a likely image with some artifacts but
with a low number of steps during the OMP (low number of atoms will be used to represent
the patch), in order to prevent any learning of these artifacts (over-ﬁtting). We deﬁne then the
patch-sparsity L of the decomposition as this number of steps. The stopping criteria in Equation
(2) becomes the number of atoms used instead of the reconstruction error. Using a small L
during the OMP permits to learn a dictionary specialized in providing a coarse approximation.
Our assumption is that (pattern) artifacts are less present in coarse approximations, preventing
the dictionary from learning them. We propose then the algorithm described in Figure 5. We
typically used L = 2 to prevent the learning of artifacts and found out that two outer iterations
in the scheme in Figure 5 are sufﬁcient to give satisfactory results, while within the K-SVD,
10-20 iterations are required.
Input: ym (mosaiced image); Dg (one pre-learned global dictionary).
Demosaic with a global dictionary: ym using Dg. This gives ˆx.
Demosaicing improvement: Apply Iter times:
• Dictionary Learning: Learn the dictionary on x using a low L patch-sparsity factor
starting from Dg. This gives an adaptive dictionary Da.
• Demosaicing using joint dictionary: Demosaic ym (with the new inner product,
derived from non-uniform noise considerations, as deﬁned in the previous section)
using the joint dictionary Da ∪Dg. This gives an update of ˆx.
Fig. 5. Modiﬁed K-SVD algorithm for color image demosaicing. This algorithm combine global dictionaries with data dependent
ones learned with a low patch-sparsity factor.
To conclude, in order to address the demosaicing problem, we use the modiﬁed K-SVD
algorithm that deals with non-uniform noise, as described in previous section, and add to it an
adaptive dictionary that has been learned with low patch-sparsity in order to avoid over-ﬁtting the
mosaic pattern. The same technique can be applied to generic color inpainting as demonstrated
in the next section.
V. EXPERIMENTAL RESULTS
We are now ready to present the color image denoising, inpainting, and demosaicing results
that are obtained with the proposed framework.
A. Denoising color images
The state-of-the-art performance of the algorithm on gray-scale images has already been
studied in . We now evaluate our extension for color images. We trained some dictionaries
with different sizes of atoms 5 × 5 × 3, 6 × 6 × 3, 7 × 7 × 3 and 8 × 8 × 3, on 200000 patches
taken from a database of 15000 images with the patch-sparsity parameter L = 6 (6 atoms in the
representations). We used the database LabelMe, , to build our image database. Then we
trained each dictionary with 600 iterations. This provided us a set of generic dictionaries that we
used as initial dictionaries in our denoising algorithm. Comparing the results obtained with the
global approach and the adaptive one permits to see the improvements in the learning process.
We chose to evaluate our algorithm on some images from the Berkeley Segmentation database,
 , presented in Figure 6. This data selection allows us to compare our results with the relevant
work on color image denoising reported in , which as mentioned before, is an extension of
 . As the raw performance of the algorithm can vary with the different noise realization, the
results presented in Table I and Table II are averaged over 5 experiments for each image and each
σ. Note that the parameter C has been tuned using Equation (5). Some visual results are also
presented on Figure 7 on the “castle” image. First of all, one can observe that working on the
whole RGB space provides an important improvement when compared to applying gray-scale
K-SVD, , on each channel separately, both in terms of PSNR and visually. Concerning the
different sizes of patches, small patches are better at retrieving the color of some details whereas
large patches are better in ﬂat areas. For example, taking the example of Figure 7, the sky on
the 10 × 10 × 3 image is smoother than on the 5 × 5 × 3, whereas the color of the red curtain
behind the windows of the center tower is slightly washed out on the 10 × 10 × 3 image. This
motivates in part the learning of multiscale dictionaries as discussed in the conclusion of this
paper. Another visual result is presented Figure 8 on the “mushroom” image. Besides this, we
present an example of denoising a non uniform noise on Figure 9, where a white Gaussian noise
has been added to each data, but with a different known standard deviation.
Data set used for evaluating denoising experiments
The results show that our approach is well adapted to color images. The quality of the results
obtained by applying the extended color K-SVD algorithm to the RGB space are signiﬁcantly
better than when denoising each RGB channel separately. Moreover, the algorithm outperforms
the most recent work on learning color images reported in .
The K-SVD algorithm is relatively fast for denoising. The complexity depends on the number
Results obtained on the castle image. Bottom left image is the noisy image with σ = 25, top left image is the original
one. Then, from left to right are respectively presented: the results obtained with patches 5 × 5 × 3, 7 × 7 × 3, 10 × 10 × 3,
and the result obtained applying directly the gray-scale K-SVD algorithm, , on each channel separately using patches 8 × 8.
The bottom row shows a zoomed-in region for each one of the top row images.
(a) Original
(c) Denoised Image
Result obtained by applying our algorithm with 7 × 7 × 3 patches on the mushroom image where a white Gaussian
noise of standard deviation σ = 25 has been added.
PSNR results of our denoising algorithm with 256 atoms of size 7 × 7 × 3 for σ > 10 and 6 × 6 × 3 for σ ≤10. Each case is
divided in four parts: The top-left results are those given by McAuley and al with their “3 × 3 model.” The top-right
results are those obtained by applying the gray-scale K-SVD algorithm, , on each channel separately with 8 × 8 atoms. The
bottom-left are our results obtained with a globally trained dictionary. The bottom-right are the improvements obtained with
the adaptive approach with 20 iterations. Bold indicates the best results for each group. As can be seen, our proposed
technique consistently produces the best results.
of patches, the sparsity of the decomposition (which depends on σ as well), and the size of the
patches. With our experimental implementation in C++, it took approximatively 4.4s to remove
noise with standard deviation σ = 25 from a 256 × 256 × 3 color image with patches of size
5 × 5 × 3 with a global dictionary (one iteration), and about 1 min. 40 sec. when we performed
20 iterations of the algorithm on a Pentium-M 1.73GHz processor.
B. Inpainting color images
We now present results for inpainting small holes in images. The ﬁrst example shows the
behavior of our algorithm when removing data from the castle image. It is presented on Figure
10. The second example, Figure 11, is a classical example of text removal, , and was used in
 in order to evaluate their model compared to the pioneer work from . In , the Field
of Experts model achieves 32.23 dB using their algorithm on the YCbCr space and 32.39 dB on
the RGB space. With our model, using 9 × 9 × 3 patches which are large enough to ﬁll in the
holes and a dictionary with 512 atoms to ensure the over-completeness, a patch-sparsity of 20,
and 20 learning iterations, we obtained 32.45 dB. The results from these two models are very
Comparison of the PSNR results on the image “castle” between and what we obtained with 256 6 × 6 × 3 and 7 × 7 × 3
patches. For the adaptive approach, 20 iterations have been performed. Bold indicates the best result, indicating once again
the consistent improvement obtained with our proposed technique.
(a) Original
(c) Denoised Image
Example of non-spatially-uniform white Gaussian noise. For each image pixel, σ takes a random value from a uniform
distribution in [1; 101]. The σ values are assumed to be known by the algorithm. Here, the denoising has been performed with
7 × 7 × 3 patches and 20 learning iterations. The initial PSNR was 12.77 dB, the resulting PSNR is 29.87 dB.
similar and both achieve better results than those presented in the original inpainting algorithm
C. Demosaicing
We now present results for demosaicing images. We ran our experiments on the images in
Figure 12, which are taken from the Kodak image database. The size of the images is 512×768,
encoded in RGB with 8 bits per channel. We simulated the mosaic effects using the Bayer pattern,
present in Table III the results in terms of PSNR using a globally trained dictionary with atoms
(a) Original Image
(b) Damaged Image
(c) Restored Image
From left to right : The original image, the image with 80% of data removed, the result of our inpainting using
7 × 7 × 3 patches. The restored image PSNR is 29.36 dB.
(a) Original image
(b) Image with text
(c) Restored image
Inpainting for text removal.
of size 5 × 5 × 3, with a patch-sparsity factor L = 20, and compare to bilinear interpolation, the
results given by Kimmel’s algorithm , three very recent methods and state-of-the-art results
presented in .
For some very difﬁcult regions of some images, our generic color image restoration method,
when applied to demosaicing, does not give better results than the best interpolation-based
methods, which are tuned to track the classical artifacts from the demosaicing problem. On the
other hand, on average, our algorithm performs as well and sometimes better than state-of-theart, improving by 0.11 dB the average result on this standard dataset when compared to the best
demosaicing algorithm so far reported. The fact that we did not introduce any special procedure
Comparison of the PSNR, in dB, for different demosaicing algorithms on the Kodak data set. Some results are taken from the
paper . BI refers to a simple bilinear interpolation, then, K, AP, OR, SA, CC refer to the algorithms respectively from
 , , , , . D1 refers to the results obtained with a globally trained dictionary (200 iterations with L = 6 on
200000 different 5 × 5 × 3 patches), D2 refers to a better trained dictionary (600 iterations with L = 6 on 200000 different
5 × 5 × 3 patches). Then, D1L and D2L refer to the result obtained with these dictionaries and the learning process we
already described, with two times 20 learning iterations with a patch-sparsity equal to 15. Bold indicates the best results for
each image, and these are mostly shared between our algorithm and the one recently reported in , which was explicitly
designed for handling demosaicing problems.
Kodak image database, images 1 to 24 from left to right and top to bottom, so that the upper left image is n1, and
the upper right image is n6
to address the classical demosaicing artifacts and still achieve state-of-the-art results, clearly
indicates the power of our framework. Some visual results are presented in Figure 13.
VI. DISCUSSION AND CONCLUDING REMARKS
In this paper we introduced a framework for color image restoration, and presented results for
color image denoising, inpainting, and demosaicing. The framework is based on learning models
for sparse color image representation. The gray-scale K-SVD algorithm introduced in , 
proved to be robust toward the dimensionality increase resulting from the use of color. Following
the extensions here introduced, this algorithm learns some correlation between the different R,G,B
channels and provides noticeably better results than when modeling each channel separately.
Although we already obtain state-of-the-art results with the framework presented here, there is
still room for future improvement. The artifacts found in images modeled with small patches are
often different from those we observed on images modeled with larger patches. Large patches
introduce a smoothing effect, giving very good results on ﬂat areas, whereas some details could
be blurred. On the other hand, small patches are very good at retrieving details, whereas they
might introduce artifacts in ﬂat areas. This motivates us to consider a multiscale version of the
K-SVD, and a multiscale learning for image modeling in general.
We present here a preliminary result in this multiscale direction, working with just two different
patch sizes. The idea consists of performing a weighted average between the result obtained with
(a) Image 19 restored
(b) Zoomed region
(c) Image 17 restored
(d) Zoomed region
(e) Image 7 restored
(f) Zoomed region
(g) Image 14 restored
(h) Zoomed region
Examples of demosaicing results. The image 13(a) is one where we do not perform (visually) as well as the best
interpolation-based algorithm. On the other ones, Figures 13(e), 13(g) and 13(c), we outperform these algorithms.
these sizes. The weights are derived from the sparsity of each pixel in the reconstructed images.
We deﬁne the pixel-sparsity of one pixel in the reconstructed image as the average sparsity of
each patch which contains this pixel.
We consider now gray-scale images to simplify the notations. Assume we denoise the image
y = x + w, following our proposed framework, with one patch size s, obtaining ˆxs, and then
with another patch size b, obtaining ˆxb. We want to ﬁnd the optimal set of weights λij for each
pixel ij, without knowing the original image x, such that
λij = arg min
0≤λ≤1 |xij −(λˆxs
ij + (1 −λ)ˆxb
In order to learn the relationship between the pixel-sparsity and the optimal weights, we use a
Support Vector Regression algorithm with a linear kernel . The basic algorithm is presented
on Figure 14. We observed some improvements with this two-scale dictionary, as presented in
Table IV, encouraging our ongoing research on learning multiscale image models and multiscale
sparsity frameworks.
Input: y (noisy image); σ (deviation of the noise); Γ (generic data-set of different
Initialization of the database:
• Creation of the noisy database: Create ˜Γ, the noisy version of Γ, where one adds
a noise of deviation σ to each image of Γ in order to create the learning database.
Denoising the learning database with small patches: Denoise ˜Γ using patches of
size s × s. This gives the reconstructed images ˆΓs and the sparsity of each pixel,
• Denoising the learning database with large patches: Denoise ˜Γ using patches of
size b × b. This gives the reconstructed images ˆΓb and Lb
• Computation of the optimal weights: For each pixel (i, j) of each image m of Γ,
denoted by Γijm, compute the optimal weight:
λijm = arg min
0≤λ≤1 |Γijm −(λˆΓs
ijm + (1 −λ)ˆΓb
Learning the rule between sparsity and optimal weights: Train a Support Vector
Regression using Ls
Γ as inputs and the λijm as outputs, or eventually one part
of this training set.
Denoising process:
• With small patches: Denoise y using patches of size s × s. This gives the
reconstructed images ˆxs and the sparsity of each pixel, Ls.
• With large patches: Denoise y using patches of size b × b. This gives the
reconstructed images ˆxb and Lb.
• Estimation of the optimal weights: Use the Support Vector Regression to estimate
the optimal weights for x using Ls and Lb as inputs. This gives a matrix ˆλ.
• Weighted averaging: The output of the algorithm is then the weighted average
between ˆxs and ˆxb, with ˆλ providing the weights.
K-SVD algorithm for denoising with two sizes of patches.
Training Image
Noisy image
Small size/PSNR
Big size/PSNR
Result with SVR
5 × 5 × 3 / 30.74
8 × 8 × 3 / 31.11
5 × 5 × 3 / 28.04
8 × 8 × 3 / 28.06
5 × 5 × 3 / 30.65
8 × 8 × 3 / 31.12
5 × 5 × 3 / 30.10
8 × 8 × 3 / 30.30
5 × 5 × 1 / 28.42
10 × 10 × 1 / 29.37
5 × 5 × 1 / 29.28
10 × 10 × 1 / 31.40
Preliminary results when working with two sizes of patches. The SVR is trained on the image of the ﬁrst column, then it is
used to denoise the image on the second column, which has been noised with a white Gaussian noise of standard deviation
σ = 25. Third and fourth columns indicate, respectively, the PSNR result when denoising with 5 × 5 × 3 and 8 × 8 × 3 atoms.
The last column presents the PSNR result for the joint two-patches reconstruction.
Concerning the computational complexity, the trade-off between speed and quality can be
chosen by the user. Using global dictionaries provides fast results. Inpainting/demosaicing can
be performed with a few step in the OMP (parameter L). One great advantage of the K-SVD
algorithm which will be more and more important in the future is that it can easily be parallelized.
Nowadays processors are not progressing a lot in the number of sequential operations per second
but are multiplying the number of cores inside each chip. Therefore, it has become very important
to design algorithms which can be parallelized. In our case, the OMP can be performed with one
patch per processor with maximal efﬁciency. For the learning step, some libraries like ARPACK
provide incomplete Singular Value Decomposition for parallel machines and it is possible to
perform the learning of two atoms in parallel if the sets of patches which use them are not
overlapping. One strategy to further improve complexity consists of reducing the overlapping of
the patches and using only one portion of the patches when working with large images. With
patches of size 8 × 8 and gray-scale images 512 × 512, a one fourth reduction proved not to
affect the quality of the reconstruction . In our examples, we chose to always use a complete
set of overlapping patches, but if one wants to use high deﬁnition images with more than one
million of pixels, this would be problematic. This is an additional motivation for our current
efforts on multiscale frameworks.
We chose to work with natural color images because of their practical relevance and because
it is a very convenient data source in order to compare our algorithm with other results available
in the literature. One main characteristic we have not discussed in this paper is the capability of
this algorithm to be adapted to other types of vectorial data. Future work will consist of testing
the algorithm on multi-channels images such as LANDSAT. Another interesting future direction
consists of learning dictionaries for speciﬁc classes of images such as MRI and astronomical
data. We strongly believe that this framework could provide cutting edge results in modeling
this kind of data as well.