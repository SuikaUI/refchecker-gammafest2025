,/97874(-278-898-32%06)437-836=
'ST]VMKLX
8LMWZIVWMSRMWEZEMPEFPIEX,/97874 -based recommender systems, contentbased recommender systems, and hybrid recommender systems . CF-based recommendation models user preference
based on the similarity of users or items from the interaction
data, while content-based recommendation utilizes item’s
Qingyu Guo, Fuzhen Zhuang, Qing He are with Key Lab of Intelligent
Information Processing of Chinese Academy of Sciences (CAS), Institute
of Computing Technology, CAS, Beijing 100190, China. Qingyu Guo is
also with Hong Kong University of Science and Technology, Clearwater
Bay, Kowloon, Hong Kong. Fuzhen Zhuang and Qing He are also with
University of Chinese Academy of Sciences, Beijing 100049, China.
E-mail: , {zhuangfuzhen, heqing}@ict.ac.cn.
Fuzhen Zhuang is the corresponding author. Qingyu Guo is an intern
student under the supervision by Fuzhen Zhuang.
University
Technology
Intelligence
 .
Hengshu Zhu is with Baidu Talent Intelligence Center, Baidu Inc. E-mail:
 .
Xing Xie is with Microsoft Research Asia, Beijing, China. E-mail:
 .
Hui Xiong is with Rutgers, the State University of New Jersey. E-mail:
 .
content features. CF-based recommender systems have been
widely applied because they are effective to capture the
user preference and can be easily implemented in multiple scenarios, without the efforts of extracting features in
content-based recommender systems , . However, CFbased recommendation suffers from the data sparsity and
cold start problems . To address these issues, hybrid
recommender systems have been proposed to unify the
interaction-level similarity and content-level similarity. In
this process, multiple types of side information have been
explored, such as item attributes , , item reviews ,
 , and users’ social networks , .
In recent years, introducing a knowledge graph (KG)
into the recommender system as side information has attracted the attention of researchers. A KG is a heterogeneous
graph, where nodes denote entities, and edges represent
relations between entities. Items and their attributes can be
mapped into the KG to understand the mutual relations between items . Moreover, users and user side information
can also be integrated into the KG, which makes relations
between users and items, as well as the user preference, can
be captured more accurately . Figure 1 is an example of
KG-based recommendation, where the movie “Avatar” and
“Blood Diamond” are recommended to Bob. This KG contains users, movies, actors, directors, and genres as entities,
while interaction, belonging, acting, directing, and friendship are relations between entities. With the KG, movies
and users are connected with different latent relations,
which helps to improve the precision of recommendation.
Another beneﬁt of the KG-based recommender system is the
explainability of recommendation results . In the same
example, reasons for recommending these two movies to
Bob can be known by following the relation sequences in the
user-item graph. For instance, one reason for recommending
“Avatar” is that “Avatar” is the same genre as “Interstellar”,

Fig. 1. An illustration of KG-based recommendation.
which was watched by Bob before. Recently, multiple KGs
have been proposed, such as Freebase , DBpedia ,
YAGO , and Google’s Knowledge Graph , which
makes it convenient to build KGs for recommendation.
Our paper is related to the surveys in the ﬁeld of graphbased recommendation and applications of KG. On the one
hand, Shi et al. presented traditional recommendation
methods based on the heterogeneous information network,
however, latest developed deep learning based models are
not covered. Liu et al. discussed how to introduce the
KG embedding into recommender systems, nevertheless,
this is only one implementation of KG-based recommendation. Sun et al. reviewed how KGs serve as a type of
side information for recommender systems, however, some
representative works are missing and the categorization
of recommendation approaches are not ﬁne-grained. On
the other hand, Zhang and Chen illustrated how KGs
bring interpretability to recommender systems, and Wang et
al. listed some representative methods, however, only
a few works are investigated and the inherent relations
between algorithms are not mentioned.
Compared with previous works, our survey goes deeper
to algorithms and provides a more ﬁne-grained, hierarchical
taxonomy. In the ﬁrst level, we classify these works into
three categories, including the embedding-based method,
the connection-based method, and the propagation-based
method, from the perspective of the leveraged KG-related
information. In the second level, we split these three categories into several groups based on their characteristics.
Speciﬁcally, for embedding-based methods, we group them
on the basis of how the KG embedding is learned; while for
connection-based methods, we differentiate them according
to how to model the connection pattern in the KG; and
ﬁnally, for propagation-based methods, we distinguish them
based on which type of entity is reﬁned in the propagation
process. The second contribution is that we elaborate on
how different works utilize the KG for explainable recommendation, and summarize common techniques used for
explainable recommendation in different methods. In addition, we ﬁnd that KGs serve as side information in multiple
scenarios, including the recommendation for movies, books,
news, products, points of interest (POIs), music, and social
platform. We gather recent works, categorize them by the
application, and collect datasets evaluated in these works.
The organization of this survey is as follows: in Section 2, we present notations and concepts used in this
paper, as well as foundations of KGs and recommender
Notations used in this paper.
Descriptions
Entity k in the knowledge graph
Relation between two entities
(ei, ej) in the knowledge graph
Predicted user ui’s preference
for item vj
Latent vector of user ui
Latent vector of item vj
Latent vector of entity ek in the
Latent vector of relation rk in
U = {u1, u2, · · · , um}
V = {v1, v2, · · · , vn}
Latent vector of the user set
Latent vector of the item set
User-Item Interaction matrix
One path k to connect two entities (ei, ej) in the knowledge
Nonlinear Transformation
Element-wise Product
Vector concatenation
systems; in Section 3 and Section 4, we review KG-based
recommender systems from the aspect of approaches and
evaluated datasets, respectively; in Section 5, we provide
some potential research directions in this ﬁeld; ﬁnally, we
conclude this survey in Section 6.
BACKGROUNDS
In this section, we introduce the fundamental knowledge
and summarize related work in the domain of KG-based
recommendation, including KGs and recommender systems. Moreover, before delving into the state-of-the-art approaches exploiting KGs as side information for recommendation, we ﬁrst present notations and concepts used in the
paper to eliminate misunderstanding. For convenience, we
list some symbols and their descriptions in Table 1.
• Recommender Systems. The recommendation task is
to recommend one or a series of unobserved items to a
given user, and it can be formulated into the following
steps. First, the system learns the representation ui and
vj for the target user ui and candidate item vj. Then, it
learns a scoring function f : ui × vj →ˆyi,j, which models
the preference of ui for vj. Finally, the recommendation
can be generated by sorting the preference scores for
Recommender
many domains, such as POIs , , news , ,
transportation , and education , . There have
been quite a number of surveys related to recommender
recommender
systems can be classiﬁed into content-based recommender
systems, CF-based recommender systems, and hybrid
recommender systems , Lops et al. , Su et al. , and
Burke summarized the characteristics of each approach,
respectively. Among these three categories, the CF-based
recommendation is the most popular strategy, and Shi et
al. introduced the latest progress in this direction.
Moreover, with the development of deep learning methods,
the recommendation architectures have been revolutionized
dramatically, therefore, Zhang et al. investigated how
different deep learning techniques are adopted in recent
recommender systems. Readers can check these surveys to
learn more fundamental knowledge in this ﬁeld.
• Heterogeneous Information Network (HIN). A HIN is
a directed graph G = (V, E) with an entity type mapping
function φ : V →A and a link type mapping function
: E →R. Each entity v ∈V belongs to an entity type
φ(v) ∈A, and each link e ∈E belongs to a relation type
ψ(e) ∈R. In addition, the number of entity types |A| > 1
or the number of relation types |R| > 1.
• Knowledge Graph (KG). A KG G = (V, E) is a directed
graph whose nodes are entities and edges are subjectproperty-object triple facts. Each edge of the form (head
entity, relation, tail entity) (denoted as < eh, r, et >) indicates
a relationship of r from entity eh to entity et. A KG can be
regarded as an instance of a HIN.
The KG is a practical approach to represent large-scale
information from multiple domains . A common way
to describe a KG is to follow the Resource Description
Framework (RDF) standard , in which nodes represent
entities, while edges imply the speciﬁc relationship between
the head entity and tail entity. For example, (Donald Trump,
president of, America) indicates the fact that Donald Trump
is the president of America. A KG is a heterogeneous network since it contains multiple types of nodes and relations
in the graph. Such a graph has strong representation ability
as multiple attributes of an entity can be obtained by following different edges in the graph, and high-level relations
of entities can be discovered through these relational links.
To date, KGs have been created and applied in multiple
scenarios, including search engines, recommender systems,
Question Answering system , etc. In our collected papers, three open KGs, Freebase , DBpedia , as well
as CN-DBPedia , and an enterprise KG, Satori , are
adopted to provide external knowledge. These KGs contain
facts from multiple domains, offering diverse entities and
relations for recommender systems. For a more comprehensive review of KGs, we refer readers to , . In addition,
literature provides practical advice on choosing the KG
under different conditions.
In our collected papers, there are two types of KGs, as
illustrated below.
• Item Knowledge Graph. In the item KG, items and item
associated entities, for example, item attributes, serve as
nodes. Edges can either stand for item’s attribute-level
relations, such as brand, category, or user-related relations,
such as “co-view”, “co-buy”.
• User-Item Knowledge Graph. In the user-item KG, users,
items, and their associated entities serve as nodes. Despite
item-related relations in the item KG, relations between the
user and the item are also included in the user-item KG,
such as “buy”, “click”, and “mention”.
• Meta-path. A meta-path P = A0
is a path deﬁned on the graph of network schema GT =
(A, R), which deﬁnes a new composite relation R1R2 · · · Rk
between type A0 and Ak, where Ai ∈A and Ri ∈R for
i = 0, · · · , k. It is a relation sequence connecting object pairs
in a HIN, which can be used to extract connectivity features
in the graph.
• Meta-graph. Similar to a meta-path, a meta-graph is
another meta-structure that connects two entities in a HIN.
The difference is that a meta-path only deﬁnes one relation
sequence, while a meta-graph is a combination of different
meta-paths . Compared with a meta-path, a meta-graph
can contain more expressive structural information between
entities in the graph.
• Knowledge Graph Embedding (KGE). KGE is to embed
a KG G = (V, E) into a low dimensional space . After
the embedding procedure, each graph component, including the entity and the relation, is represented with a ddimensional vector. The low dimensional embedding still
preserves the inherent property of the graph, which can be
quantiﬁed by semantic meaning or high-order proximity in
the graph. For a more comprehensive understanding of KGE
algorithms, we recommend reference , to readers.
• H-hop Neighbor. Nodes in the graph can be connected
with a multi-hop relation path: e0
in this case, eH is the H-hop neighbor of e0, which can be
represented as eH ∈N H
e0 . Note that N 0
e0 denotes e0 itself.
• Entity Triplet Set. The triplet set of an entity e ∈G is
(eh, r, et)|(eh, r, et) ∈G and eh ∈N k−1
k = 1, 2, · · · , H.
It can be regarded as multiple layers of triplets containing
entities from 1-hop neighbors to H-hop neighbors.
METHODS OF RECOMMENDER SYSTEMS WITH
KNOWLEDGE GRAPHS
In this section, we collect papers related to KG-based
recommender systems. Based on how these works utilize
the KG information, we group them into three categories,
embedding-based methods, connection-based methods, and
propagation-based methods. We further subdivide each category according to the characteristics of these approaches.
Generally, the ﬁrst step in these methods is to build
a KG, either the item KG or the user-item KG. Take the
construction of an item KG as an example, items are ﬁrstly
mapped to the external KG to ﬁnd their associated entities,
then multi-hop neighbors of associated entities are extracted
from the KG and form a subgraph for the recommendation
system. The graph can also be built from the side information within the provided data, without the assistant of
external KGs. The other steps vary in different methods,
which will be elaborated in this section.
The explainable recommendation has been another hot
research topic in recent years. On the one hand, it is
helpful for users to adopt the suggestions generated by
the recommender system if appropriate explanations can
be provided to them. On the other hand, researchers can
Table of collected papers. In the table, “Emb.” stands for embedding-based method, “Conn.” stands for connection-based method, “Prop.” stands
for propagation-based method, “TSL.” stands for two-stage learning method, “JL.” stands for joint learning method, “MTL.” stands for multi-task
learning method, “MSB.” stands for meta-structure based method, “PEB.” stands for path-embedding based method, “RU.” stands for reﬁnement of
the user, “RI.” stands for reﬁnement of the item, “RUI.” stands for reﬁnement of the user and item, “⋆” stands for the recommendation model is
explainable, “KG Embed.” stands for KGE method, “IKG” stands for item KG, “UIKG” stands for user-item KG, “−” stands for no KGE method is
adopted in this model, or no issue of this category is solved by this model.
Issue Solved
entity2rec 
explainability
KTGAN 
Metapath2Vec
improper embedding
improper embedding
improper embedding
SHINE 
IKG & UIKG
Autoencoder
improper embedding
improper embedding
ECFKG⋆ 
improper embdding, explainability
end-to-end
improper embedding
improper embedding, explainability
improper embedding, explainability
Hete-MF⋆ 
Hete-CF⋆ 
HeteRec⋆ 
HeteRec p⋆ 
personalization
ProPPR⋆ 
SemRec⋆ 
HeRec⋆ 
limited semantics of the meta-path
end-to-end
meta-path modeling
end-to-end
handcrafted meta-paths
end-to-end
handcrafted meta-paths
end-to-end
handcrafted meta-paths
RuleRec⋆ 
end-to-end
handcrafted meta-paths
end-to-end
handcrafted meta-paths, post-hoc explanation
handcrafted meta-paths, post-hoc explanation
RippleNet⋆ 
end-to-end
AKUPM⋆ 
RCoLM⋆ 
end-to-end
scalability
KGCN-LS⋆ 
end-to-end
scalability, generalization
scalability
end-to-end
early summarization
IntentGC 
end-to-end
scalability
noise in the entire KG
gain a deeper understanding of the recommendation algorithm . Compared with traditional recommender systems, KG-based recommender systems bring a variety of
entities and relations connecting users and items, and are
capable of illustrating the reasoning process. In this section,
we will also show how different works leverage KGs for
explainable recommendation.
To facilitate readers checking the literature, we summarize and organize these papers in Table 2, which lists the
approaches to utilize a KG for recommendation, whether
the model is explainable, how the model builds the KG, and
what issues are solved in each model.
Embedding-based Method
Embedding-based methods leverage fruitful facts in the KG
to enrich the representation of items or users. There are two
basic modules in these works, one is the graph embedding
module to learn representations of entities and relations in
the KG; and the other one is the recommendation module,
which is used to estimate user ui’s preference for item vj
with learned features. Based on how these two modules
are associated in the framework, we categorize embeddingbased methods into the two-stage learning method, the joint
learning method, and the multi-task learning method. The
challenges of this method include: 1) how to obtain the
entity embedding with the proper KGE method; 2) how to
integrate the learned entity embedding in the recommendation module.
Two-stage Learning Method
The two-stage learning method stands for training the graph
embedding module and the recommendation module one
by one. In the ﬁrst step, representations of entities and
relations are learned with KGE algorithms. Then, the pretrained graph related embeddings are fed into the recommendation module along with other user features and item
features to make predictions.
Wang et al. proposed DKN for news recommendation. In the ﬁrst stage, entities in news titles are extracted
and mapped into the Satori KG to mine the knowledgelevel relations between news. DKN models the news vj
by combining the textual embedding of sentences learned
with Kim CNN and the knowledge-level embedding
of entities in news content via TransD , and the ﬁnal
news representation is vj. In order to capture the user’s
dynamic interest in news, the representation of ui is learned
by aggregating the embedding of historical clicked news
{v1, v2, · · · , vN} with an attention mechanism,
svk,vj vk,
where svk,vj measures the similarity between the candidate
news vj and the clicked news vk. In the second stage, user’s
preference for candidate news vj can be calculated via ˆyi,j =
MLP (ui, vj).
Huang et al. proposed the KSR framework for
sequential recommendation. KSR utilizes a GRU network
to capture the user’s sequential preference, and a KV-MV
module to model the user’s attribute-level preference with
knowledge base information. In detail, given the interaction
sequence {v1, v2, · · · , vT }, the GRU network models the
user representation at time t as the hidden state vector
i is the item embedding pre-trained with BPR
model . For the KV-MN module, it ﬁrst learns the
entity embedding e and relation embedding r with the
TransE model . The relation embedding are taken as
the attribute key, and the user’s attribute level preference
i is modeled with attention mechanism on vectors of item
attributes. The ﬁnal representation of the user and the candidate item consist of embeddings from the above-mentioned
KG and interaction related modules, which can be written
i and vj = qj ⊕ej · ut
i, respectively. After
transforming ut
i and vj to the same dimension, the user’s
preference for items can be estimated via inner product
T · MLP (vj) .
The KSR framework is interpretable by checking user’s
attention weight over explicit attributes. For example, the
“singer” attribute dominating the attention weight for a recommended song indicates the recommendation is generated
based on that feature. Therefore, such feature-level attention
weight can reﬂect the user’s explicit preference.
Yang et al. introduced a GAN-based recommendation model, KTGAN, with external knowledge learned from
item KG. In the ﬁrst phase, KTGAN learns the knowledge
embedding vk
j for movie vj by incorporating the Metapath2Vec model on the movie’s KG, and the tag embedding vt
j with the Word2Vec model on movie’s attributes.
The initial latent vector of movie vj is represented as
j. Similarly, the initial latent vector of user ui
is represented as uinitial
i, where uk
i is the average
of knowledge embeddings of ui’s favored movies, and ut
ui’s tag embedding. In the second stage, it learns a generator
G and a discriminator D to reﬁne initial representations of
users and items. The generator G tries to generate relevant
movies for user ui according the score function pθ(vj|ui, r),
where r denotes the relevance between ui and vj. During
the training process, G aims to let pθ(vj|ui, r) approximate
ui’s true favorite movie distribution ptrue(vj|ui, r), so that
G can select relevant user-movie pairs. The discriminator D
is a binary classiﬁer to distinguish relevant user-movie pairs
and irrelevant pairs according to the learned score function
fφ(ui, vj). The objective function of the GAN module is
written as,
{Evj∼ptrue (vj|ui,r) [log P (vj|ui)]
+Evj∼pθ(vj|ui,r) [log (1 −P (vj|ui))]},
P(vj|ui) =
−fφ(ui, vj)
where P(vj|ui) stands for the probability of movie vj being
preferred by user ui. After the adversarial training, optimal
representations of ui and vj are learned. Recommendation
can be generated for the target user ui by ranking movies
according to the generator’s score function pθ(vj|ui, r). Experiments show that the pre-trained KG embedding can
improve the model performance compared with randomly
initialized embeddings.
Ye et al. proposed BEM, which uses information from
two item KGs, one with item-attribute level knowledge,
and the other one is named as behavior graph, containing
user-related relations, such as “co-view”, “co-buy”. BEM
ﬁrst learns the initial embeddings from two KGs with the
TransE model and the GraphSAGE model , respectively. Next, they designed a Bayesian generative model
to mutually reﬁne these two representations and preserve
item’s structural information in each graph. Finally, the
recommendation can be generated by ﬁnding closest items
of the interacted items in the behavior graph under the
relation of “co-buy” or “co-click”.
The two-stage learning method is easy to implement,
where the KG embeddings are generally treated as extra features for the following recommendation module. Another
beneﬁt is that KG embeddings can be learned without the
interaction data, therefore, large-scale interaction datasets
will not increase the computational complexity. Moreover,
since the KG is usually stable, it is unnecessary to update
embeddings frequently once they are learned. However, the
entity embedding optimized by KGE models is more suitable for in-graph applications, like KG completion. Since the
KGE module and the recommendation module are loosely
coupled, the learned embeddings may not be suitable for
recommendation tasks.
Joint Learning Method
Another trend is to jointly learn the graph embedding
module and the recommendation module in the end-to-end
training fashion. In this way, the recommendation module
can guide the feature learning process in the graph embedding module.
Zhang et al. proposed CKE, which uniﬁes various
types of side information in the CF framework, including
item’s attribute-level feature, textual feature, and visual
feature. The attribute-level feature xj is encoded with the
TransR to learn structural knowledge from KG, while
the textual feature zt,j and the visual feature zv,j are
extracted with the autoencoder. The objective function of
these three feature learning modules are added with the
recommendation module to learn parameters jointly,
L = LRec + λ1Latt + λ2Ltext + λ3Lvis + λ4Lreg,
where LRec, Latt, Ltext, Lvis, and Lreg are the objective
function of the recommendation module, the attribute-level
feature learning module, textual feature learning module,
visual feature learning module, and the regularization term,
respectively. The ﬁnal representation of item vj is obtained
by aggregating the item feature from each part along with
the offset vector ηj extracted from the user-item interaction
matrix through vj = ηj + xj + zt,j + zv,j. After obtaining
the latent vector ui of the user ui, the preference score is
estimated via the inner product ˆyi,j = uT
i vj. Experiments
show that incorporating structural knowledge can boost the
performance of recommendation.
Wang et al. proposed SHINE, which formulates
the user recommendation task as the sentiment link prediction task between entities in the graph. SHINE utilizes
information from multiple sources, including the sentiment
network Gs which represents attitude among users, the
social network Gr which contains user relations, and the
proﬁle network Gp with user attribute-level knowledge.
User features us
i are learned from Gs, Gr, Gp with
the autoencoder model, respectively, then are aggregated
for the ﬁnal user representation ui. The preference between
user ui and uj can be modeled from their corresponding
representations in the prediction model,
ˆyi,j = f(ui, uj),
where AGG(·) is the aggregation operator. This model is
also optimized end-to-end by adding loss terms together.
Zhang et al. proposed CFKG, which constructs a
user-item KG for recommendation. CFKG adopts the TransE
model to encode the graph, and learns the embedding
of entities and relations in the graph with a hinge loss
(eh,r,et)∈G
γ + ∥eh + r −et∥2 −∥eh + r −et′∥2
h,r,et)∈Gh
γ + ∥eh + r −et∥2 −∥eh′ + r −et∥2
where γ is the margin, Gt and Gh are triplets obtained by
replacing the tail entity and the head entity in correct triplets
(eh, r, et) ∈G, respectively. In the recommendation phase,
the system ranks candidate items according to the Euclidean
distance between ui and vj measured by the “buy” relation,
ui + rbuy −vj
where rbuy is the learned embedding for the relation type
“buy”. A smaller distance between ui and vj measured by
the “buy” relation refers to a higher preference score ˆyi,j.
In the follow-up work ECFKG proposed by Ai et al. ,
they illustrated that explanations for the recommendation
can be provided by extracting relation paths between the
target user and the candidate item.
The joint learning method can be trained end-to-end, and
it can use the KG structure to regularize the recommender
system. Nevertheless, the combination of different objective
functions needs to be ﬁne-tuned.
Multi-task Learning Method
A recent research direction is to adopt the strategy of multitask learning, to train the recommendation task with the
guidance of the KG-related task. The motivation is that
items in the user-item interaction bipartite graph and their
associated entities in the KG are likely to share similar
structures. Therefore, the transferring of low-level features
between items and entities is helpful for facilitating the
improvement of recommender system.
Wang et al. proposed MKR, which consists of a
recommendation module and a KGE module. Instead of
feeding KG embeddings into the recommendation module,
these two modules are independent and are connected with
a cross & compress unit to share knowledge. The recommendation module is trained to estimate user’s preference
for candidate items, while the KGE module is trained to
estimate the tail entity representation given the head entity
and the relation in a triplet (eh, r, et). In detail, the recommendation module feeds initial user representation u into
L-layer MLP to obtain ﬁnal user representation uL. The
ﬁnal item representation vL is reﬁned by L-layer cross &
compress unit with their associated entities e ∈Sv in the
KG. The user preference for the candidate item is estimated
with a nonlinear function,
vL = Ee∈Sv
CL (v, e) [v]
Similarly, the KGE module learns ﬁnal relation representation rL with the L-layer MLP, and the head entity representation is reﬁned through the L-layer cross & compress
unit with their associated items v ∈Seh. Then, the model
predicts tail entity embedding ˆet by concatenating these
two embeddings, followed by a K-layer MLP. The similarity
between ˆet and the real tail entity embedding et is measured
by a score function,
h = Ev∈Seh
CL (v, eh) [e]
s(eh, r, et) = Φ
These two modules share low-level features in each part,
and are trained alternatively. The ﬁnal objective function is
L =LRec + λ1LKG + λ2Lreg
J (ˆyu,v, yuv)
(eh,r,et)∈G
s(eh, r, et) −
where J is the cross-entropy function, and W is the trainable parameters, LRec, LKG, and Lreg are the objective
function of the recommendation task, the KGE task, and the
regularization term, respectively.
Cao et al. proposed KTUP to jointly learn the task of
recommendation and knowledge graph completion. They
further considered the user’s preference can be reﬂected
by relations among items in the KG. Since some facts are
missed in the KG, by transferring low-level features of items
and relations from the recommendation task, better representation of entities and relations in the KG can be learned
in the KG completion task, which mutually improves performance in two tasks. KTUP adopts the TransH to learn
the entity and relation embedding via
h = eh −wT
t = et −wT
s(eh, r, et) =
In the recommendation module, KTUP ﬁrst induces user
preferences from the interaction history. Then, it projects
representations of the user and the item to the preference
hyperplane, and adopts a score function similar to the
TransH. The representation of the item is enhanced by
related entities in the KG, while the preference vector is
enriched by predeﬁned relation mapping in the KG,
i = ui −wT
ˆp = p + r,
ˆvj = vj + e,
ˆwp = wp + wr,
j = ˆvj −ˆwT
p ˆvj ˆwp,
i + ˆp −ˆv⊥
These two modules are jointly trained, and the objective
function is
L = LRec + λLKG
ˆyi,j −ˆyi,j′
(eh,r,et)∈G
s(eh, r, eh) + γ −s(e′
where (i, j) and (i, j′) are positive samples and negative
samples in the user-item interaction matrix, respectively;
[·]+ is the hinge loss function, γ is the margin, LRec denotes
the objective function of the recommendation task, and LKG
represents the objective function of the KG completion task.
Representations of items and preferences can be enriched
by transferring knowledge of entities, relations and preferences in each module under the framework of KTUP. By
extracting the attention weight of the explicitly modeled
user preference, relations that the user concern most are
available in the system, which forms the preference-level
explanation. Moreover, the model can detect items in the
interaction history and entities in the KG that satisfy those
salient relations to offer more solid explanations.
By applying the multi-task learning strategy, it is helpful
to prevent the recommendation system from overﬁtting, and
improve the generalization ability of the model. However,
similar to the joint learning method, it requires efforts to
integrate different tasks under one framework.
Summary for Embedding-based Method
In this section, we summarize the advantages and shortcomings of each type of the embedding-based method, which
are listed in Table 3.
Comparisons between embedding-based methods. In the table, “TSL.”
stands for the two-stage learning method, “JL.” stands for the joint
learning method, and “MTL.” stands for the multi-task learning method.
Main advantages
Main shortcomings
∗easy to implement
∗scalability
∗improper embedding
∗end-to-end training
∗ﬁne-tune weight of different objective functions
∗end-to-end training
∗generalization
∗ﬁne-tune weight of different objective functions
Although the two-stage learning method is easy to implement, the learned entity embedding may not be suitable for the recommendation task. To solve this issue,
initial entity embeddings are reﬁned by the GAN model
in KTGAN , and the Bayesian generative model in
BEM . The joint learning method learns optimized entity
embedding through end-to-end training, and the multitask learning method further improves the generalization
of the model by transferring knowledge from KG-related
tasks. However, it requires plenty of experiments to ﬁnd the
optimal combination of different objective functions.
Connection-based Method
Connection-based method utilizes the connection patterns
in the graph to guide the recommendation. Most works in
this group utilize the user-item KG to mine the relationships
among entities in the graph. There are two main approaches
in exploring the connective information in the KG. The
ﬁrst direction is to utilize the meta-structure in the graph,
including meta-path and the meta-graph, to calculate the
similarity between entities. The meta-structure based similarity can serve as the constraint for the representations of
users and items, or can be used to predict users’ interests
from similar users or similar items in the interaction history.
The second solution is to encode the connection pattern
between user-item pair or item-item pair into vectors, which
can be integrated into the recommendation framework. We
call such a method as the path-embedding based method.
The challenges of this method include: 1) how to design
proper meta-paths for different tasks; 2) how to model the
connection patterns between entities.
Meta-structure Based Method
One implementation of the meta-structure based method
is to utilize the connective similarities of entities in different meta-paths as the graph regularization to constrain
the representation of users and items. The motivation is
that entities with high meta-path based similarity should
be close in the latent space. The objective function can be
written as
L = LRec + λLSim,
where LRec represents the objective function of recommendation, and the common selection is the Matrix Factorization
i Vj −Ri,j
2. The similarity constraint LSim
guides the learning of the user embedding and the item
embedding. To measure the connectivity similarity between
entities in the graph, PathSim is commonly used. It is
2 × |{px⇝y : px⇝y ∈P}|
|{px⇝x : px⇝x ∈P}| + |{py⇝y : py⇝y ∈P}| ,
where pm⇝n is a path between the entity m and n. Three
types of entity similarities are commonly utilized,
• User-User Similarity. The objective function becomes
i,j ∥ui −uj∥2
where ∥· ∥F denotes the matrix Frobenius norm, Θ =
[θ1, θ2, · · · , θL] denotes the weight for each meta-path, U =
[u1, u2, · · · , um] denotes latent vectors of all users, and sl
denotes the similarity score of user i and j in meta-path l.
The user-user similarity forces the embeddings of users to
be close in the latent space if users share high meta-pathbased similarity.
• Item-Item Similarity. The objective function is
i,j ∥vi −vj∥2
where V = [v1, v2, · · · , vn] denotes latent vectors of all
items. Similar to the user-user similarity, the low-rank representations of items should be close if their meta-path-based
similarity is high.
• User-Item Similarity. The objective function of this term
can be written as
The user-item similarity term will force the latent vector of
users and items to be close to each other if their meta-pathbased similarity is high.
Yu et al. proposed the Hete-MF, which extracts L
different meta-paths and calculates item-item similarity in
each path. The item-item regularization is integrated with
the matrix factorization method to reﬁne low-rank representation of users and items for better recommendation.
Later, Luo et al. proposed Hete-CF to ﬁnd the user’s
afﬁnity to unrated items by taking the user-user similarity,
item-item similarity, and user-item similarity together as
regularization terms. Therefore, the Hete-CF outperforms
the Hete-MF model.
Another type of meta-structure based methods utilize
the entity similarity to predict users interests for unrated
items, which can be regarded as preference fusion in the
KG. Yu et al. proposed HeteRec, which leverages the
meta-path similarities to enrich representations of users and
items. The motivation is that users history interaction can
reﬂect user’s preference, and recommendations to this user
can be made by ﬁnding similar items to the ones that
the target user has interacted before. HeteRec ﬁrst deﬁnes
L different types of meta-paths that connect items in the
graph, which further forms L item-item similarity matrices
S(l) ∈Rn×n(l = 1, 2, · · · , L), where S(l)
i,j is the similarity
between item i and j under the relation deﬁned by the lth meta-path. The target user’s preference matrix under l-th
type of meta-path relation can be obtained via ˜R(l) = RS(l),
where R is the user-item interaction matrix. By applying
non-negative matrix factorization technique on these L
user preference matrices, a series of reﬁned latent vectors of
users and items can be obtained:
= argminU,V
 ˜R(l) −UT V
F s.t. U ≥0,
Finally, the recommendation can be generated by linear
combination of user’s preference on each path, with the
scoring function
θl · ˆu(l)T
where θl is the weight for the user-item latent vector pair in
the l-th path. One limitation for HeteRec is that the learned
weight θl for each path is the same for all users, which
impedes the degree of personalized recommendation.
Later, Yu et al. proposed HeteRec-p, which further
considers the importance of different meta-paths should
vary for different users. HeteRec-p ﬁrst clusters users into
c groups based on their past behaviors, then generates personalized recommendation with the clustering information,
instead of applying a global preference model. The modiﬁed
scoring function becomes
sim (Ck, ui)
l · ˆu(l)T
where sim (Ck, ui) denotes the cosine similarity between
user ui and the target user group Ck, and θk
l denotes the
importance of meta-path l for the user group k. Therefore,
recommendations for target users are more personalized
compared with HeteRec.
The aforementioned methods ﬁrst learn latent vectors of
users and items from the interaction matrix and their mutual
meta-structure based similarities, then make predictions
based on enhanced representations. Another approach is to
predict the preference for unrated items with the weighted
ensemble of similar user’s ratings directly. Shi et al. proposed the SemRec which considers the explicit rating scores
in the range of 0 to N, instead of implicit interaction records.
Ratings for candidate items are predicted by the weighted
ensemble of similar user’s rating, where user similarities
are learned from different meta-paths. In each meta-path,
SemRec deﬁnes rating intensity matrix Q(l) ∈R|U|×|I|×N,
where Q(l)
u′ Eu′,v,n × S(l)
u,u′, Eu′,v,n is an indicator
function that shows whether user u′ has rated the item v
with score n or not, and S(l)
u,u′ is the similarity between target
user u and user u′ along the meta-path l. The target user’s
score for item v along the meta-path l can be calculated via
The ﬁnal estimated score ˆRu,v can be obtained by considering the importance of different path for the user,
where W (l)
is the preference weight on the l-th meta-path.
One limitation of previous methods is that meta-path
is not able to characterize rich semantics. For example,
the relation of “two users both buy and review the same
product” cannot be depicted by a meta-path. Zhao et al. 
designed FMG by replacing the meta-path with the metagraph to capture complicated relations between entities in
the heterogeneous graph. Similar to HeteRec, by designing
L meta-graphs, they got L different user-item similarity
matrices, which are further decomposed to L latent vectors
of user-item pairs, denoted as
, l = 1, 2, · · · , L.
Next, the factorization machine (FM) is applied to fuse the
features of users i and items j across different meta-graphs
for computing preference score ˆyi,j. The FM considers the
interaction of entities along different meta-graphs, which
can further exploit connectivity patterns.
Meta-structure based methods are explainable since
these manually designed meta-structures provide the reference for the recommendation by matching the metastructure between the candidate item and the interacted
item or the target user. For example, if the recommended
item shares connectivity pattern User
←−−−−−−Item2 with an item in the interaction
history, it can be indicated that the item is recommended
because it is similar to historical interactions.
The meta-structure based method is easy to implement,
and most works are based on MF techniques with relatively
low model complexity. However, the selection of metapath or meta-graph requires domain knowledge, and these
meta-structures may vary signiﬁcantly for different datasets.
Moreover, it may not be suitable to apply the meta-structure
based method under some speciﬁc scenarios. For example,
in the news recommendation task, entities that belong to
one news may belong to different domains, which makes it
difﬁcult to design meta-paths.
Path-embedding Based methods
One issue in the meta-structure based method is that the
connection pattern is not explicitly modeled, which makes
it hard to learn the mutual effect between the user-item pair
and the connection pattern. Recently, the path-embedding
based method has been proposed to explicitly learn the embedding of connection patterns. Some frameworks learn the
explicit embedding of paths that connect user-item pairs in
the user-item KG, or item-item pairs in the item KG, in order
to directly model the user-item or item-item relations. Take
the relation modeling in the user-item KG as an example,
assume there are K paths that connect ui and vj in the KG,
the embedding of path p is represented as hp. Then, the ﬁnal
representation of the interaction between ui and vj can be
obtained via
h = g(hp), p = 1, 2, · · · , K,
where g(·) is the function to summarize the information
from each path embedding, and the common choice is a
max-pooling operation or weighted sum operation. Then,
ui’s preference for the vj can be modeled via
ˆyi,j = f(ui, vj, h),
where f(·) is the function to map the representation of
the interaction between the user-item pair as well as the
embedding of the user-item pair to a preference score.
For instance, Hu et al. proposed MCRec, which learns
the explicit representations of meta-paths to depict the interaction context of user-item pairs. For each ui and vj,
MCRec deﬁnes L meta-paths that connects ui and vj and
samples K path instances for each meta-path, where each
path instance Xp ∈RL×d consists of L entities ei ∈Rd. It
ﬁrst learns the embedding for each path instance with CNN,
then calculates the meta-path embedding by applying the
max-pooling operation on embeddings of K path instances
that belong to its class. Next, the interaction embedding h
between the user and item is obtained with the weighted
average of these meta-path embeddings. Another novelty of
MCRec is that the user embedding and the item embedding
are updated with the interaction embedding:
βui = ReLU (W1ui + W2h + bui) ,
˜ui = βui ⊙ui,
βvj = ReLU
˜vj = βvj ⊙vj.
Finally, the preference score is calculated by following
ˆyi,j = MLP (˜ui ⊕˜vj ⊕h). The recommendations can be
interpreted by checking the weight of each meta-path. A
higher meta-path weight means such a relation between
the target user and the candidate item is more important
in making the decision. However, MCRec still needs to
manually deﬁne the type and number of meta-paths, which
is tedious and requires domain knowledge.
Sun et al. proposed a recurrent knowledge graph
embedding (RKGE) approach that mines the path relation
between user ui and item vj automatically, without prede-
ﬁned meta-paths. Speciﬁcally, RKGE ﬁrst enumerates userto-item paths P(ui, vj) that connects ui and vj with different
semantic relations under a sequence length constraint. They
designed a recurrent network which takes as input the path
instance p consists of entity embeddings, and used the ﬁnal
hidden state hp as the representation of the entire path.
Next, following Equation 25, ﬁnal hidden states hp of all
these paths are aggregated via the average-pooling operation to model the semantic relation h between ui and vj.
Finally, the preference of ui for vj is estimated with h, and
Equation 26 becomes ˆyi,j = σ (Whh + b), where σ(·) is the
sigmoid function. After the training stage, better representations of users and items can be achieved. In the prediction
stage, they used the inner product of the user embedding
and the item embedding, since the inner product is more
efﬁcient. Entities in the KG serve as the bridge connecting
items in the recommendation list and the interaction history,
which can provide explanations for recommendation from
different angles.
Similarly, Wang et al. proposed a
knowledge-aware path recurrent network (KPRN) solution.
The major difference is that KPRN constructs the path
sequence with both the entity embedding and the relation
embedding. Moreover, they ﬁrst calculated the preference
score based on each path, then aggregated these scores for
ﬁnal preference estimation. The preference score on each
path can reﬂect the relative importance of each path that
connects the target user and the candidate item. Therefore,
it can provide the precise relation-path-level explanation for
each item.
Besides the relation modeling between the user-item
pair, the relation embedding between the item-item pair
can also be utilized. Ma et al. proposed RuleRec to
model connection patterns of associated items (co-buy, coview, etc.) in an external item KG into rule features. RuleRec
jointly trains a rule learning module and an item recommendation module. The rule learning module ﬁrst links
items with associated entities in an external KG, which
forms an item KG. Then this module summarizes common
connection patterns that connect associated items, which
are represented as several rules. The corresponding weight
for each rule is further learned with the recommendation
module jointly, which forms a feature vector where each
entry is the rule value given two items in the KG. The
ﬁnal recommendation is obtained by considering the user
representation, the candidate item representation, and the
rule feature vector between the candidate item and interacted items. The explanation can be offered from the humanunderstandable rules and corresponding rule weights.
Xian et al. proposed Policy-Guided Path Reasoning (PGPR) to use reinforcement learning (RL) to search
for reasonable paths between user-item pairs automatically.
They formulated the recommendation problem as a Markov
decision process to ﬁnd a reasonable path connecting the
user-item pair in the KG. They trained an agent to walk from
users to items by designing the path searching algorithm,
the transition strategy, terminal conditions, and RL rewards,
so that high rewards will be given to the correct user-item
pairs. The beneﬁt of adopting RL is that the actual path that
connects the user and the recommended item is available,
which makes the system more transparent.
The path-embedding based method encodes the connection pattern of user-item pair or item-item pair into latent
vectors, which makes it possible to consider the mutual
effect of the target user, the candidate item, and the connection pattern. In addition, most models are able to mine the
connection patterns automatically by numerating qualiﬁed
paths and selecting salient ones, without the assistance of
predeﬁned meta-structures. Therefore, it is likely to capture
expressive connection patterns. However, the number of
possible paths in the graph can grow to a large number if
relations in the graph are complex. In reality, it is impossible
to exploit all the paths for each entity pair in large-scale
KGs, which may hinder the performance of the model.
Summary for Connection-based Method
In this section, we compare the meta-structure based
method and the path-embedding based method, as shown
in Table 4. The connection-based method relies heavily
on the connection patterns. However, the representation
ability of the meta-path is limited, which hinders the
performance of traditional meta-structure based methods.
FMG solves this issue by replacing the meta-path
with the meta-graph to capture richer semantics in the
graph. Path-embedding based methods further overcome
another shortcoming of meta-structure based methods that
domain knowledge and handcrafted paths are required.
Comparisons between connection-based methods. In the table, “MSB.”
stands for the meta-structure based method, and “PEB.” stands for the
path-embedding based method.
Main advantages
Main shortcomings
∗easy to implement
∗scalability
handcrafted
metapaths with limited semantics
∗richer semantics
∗mutual effect of path
and user-item pair involved
∗scalability
These methods enumerate possible paths and explicitly
model the relation between user-item pairs or item-item
pairs. However, the scalability is sacriﬁced to some extent
in the path-embedding based method, since these models
are relatively complex, and more computations are required
in enumerating paths and learning representations.
Propagation-based Method
Embedding-based methods leverage the semantic relations
in the KG to enrich the representations of users and items,
or to regularize the recommendation, but it is difﬁcult to
capture high-order relations between entities. Connectionbased methods use the connectivity information in the
graph to guide recommendation, however, it is unavoidable to lose information by decomposing the sophisticated
user-item connection pattern into separate linear paths. To
fully exploit the information in the KG, propagation-based
methods have been proposed to integrate both the representation of entities and relations, and the high-order connection patterns for a more personalized recommendation.
The propagation-based method is based on the idea of embedding propagation, where the common implementation
is based on the GNN technique. These methods reﬁne the
entity representation by aggregating embeddings of multihop neighbors in the KG. Then, the user’s preference can be
predicted with the enriched representations of user ui and
the potential item vj. We subdivide this category according
to which type of entity is reﬁned in the message propagation
procedure. The challenges of this method include: 1) how
to assign proper weights to different neighbors; 2) how to
propagate messages on different relation edges; 3) how to
improve the scalability of models.
Reﬁnement of User Representation
The ﬁrst group of works reﬁne the user representation
based on their interaction history. These works build the
item KG that connects both interacted items and candidate
items with multiple relations. The motivation is that users
can be represented as the combination of their interacted
items as well as multi-hop neighbors of these items. In
detail, items in the interaction history are selected as seeds
of the propagation process. Then, multi-hop triplet sets
ui(k = 1, 2, · · · , H) are extracted along links in the graph,
ui is the triplet set (eh, r, et) with the head entities
being the user ui’s engaged items. The process of learning
user representation ui can be formulated as
Calculate the user representation ok
u by aggregating
entities in each layer of the triplet set Sk
1, 2, · · · , H).
Combine ok
u(k = 1, 2, · · · , H) for ﬁnal user representation ou.
Since the propagation starts from the user’s engaged items
and ends with distant neighbors, this process can be regarded as propagating the user’s preference layer by layer
outwardly in the item KG. Therefore, these methods can
be interpreted as propagating the user’s preference from
historical interests along paths in the KG.
Wang et al. proposed RippleNet that ﬁrst introduces
the preference propagation mechanism in the KG. It trains a
relation matrix Ri ∈Rd×d to assign weights for neighbors
in the graph. In each layer of the triplet set, the aggregation
process can be illustrated as follows. Firstly, representations
of the head entity ehi ∈Rd, the relation matrix Ri, and the
candidate item vj ∈Rd are used to calculate the weight
pi for tail entity in the corresponding triplet by following
Equation 28. During this process, the similarities of the
candidate item vj and multi-hop neighbors of interacted
items are calculated in the relation space. Secondly, user’s
representation oh
ui ∈Rd in the h-th layer of triplet set
can be calculated with the weighted average of tail entity
embeddings eti ∈Rd via Equation 29,
(ehk ,rk,etk )∈Sh
ehi ,ri,eti
where the candidate item embedding is initialized with
in the ﬁrst layer of the triplet set, and is replaced
with the oh−1
in the h-th layer of the triplet set. By repeating
the process in Equation 28-29 from h = 1, 2, · · · , H iteratively, user’s preference is propagated from interacted item
to distant neighbors in the graph. The ﬁnal representation of
ui is the combination of user representations in each layer
of triplet set with the equation of ui = o1
ui +· · ·+oH
Finally, the preference score can be generated via
i vinitial
where σ(x) is the sigmoid function. However, the preference
matrix Ri is hard to train. As a consequence, the recommendation results suffer from unrelated entities. Moreover,
the size of triplet sets can be extremely large as the layer
increases, which hinders the scalability.
Tang et al. proposed AKUPM with a similar preference propagation mechanism in the RippleNet. The difference is that AKUPM models entities with TransR to
assign entities with different representations under various
relations. In addition, AKUPM applies the self-attention
mechanism to assign weights for entities in the aggregation process, and to concatenate the user representation
obtained in each layer. In the entity aggregation process,
the Query Qh
ui, Key Kh
ui, Value Vh
ui are combined with
the representation of the head entity and the corresponding
relation, then the user representations oh
ui in h-th layer is
calculated via Equation 31,
h2, · · · , Rh
where d is applied to scale the matrix for stability. To
improve the efﬁciency, the maximum number of entities to
be aggregated in each layer is set to N. Finally, user ui’s
representation in each layer are concatenated with different
importance and forms the ﬁnal user representation u via
Equation 32,
Vui = Kui =
ui, · · · , oH
where d is applied to scale the matrix for stability, vj is
the representation of the candidate item vj. Then it follows
Equation 30 to predict the user preference. With the selfattention mechanism, AKUPM can ﬁgure out related items
for the user and capture the user’s interest better.
In these methods, the edge weight is explicit in the item
KG. Therefore, the salient path that connects the candidate
item and the interacted item can be selected and serve as
the explanation for the recommendation results. Although
these works utilize both the entity embedding and the high
order connection information, only the user representation
gets updated during the propagation process.
Reﬁnement of Item Representation
The above-mentioned works reﬁne user representation by
aggregating entities outwardly in the graph. Another solution is to learn high order representation of the candidate
item vj by aggregating embeddings of item vj’s multi-hop
neighbors N k
v (k = 1, 2, · · · , H) inwardly in the item KG.
During the inward propagation process, the graph attention
mechanism is adopted, where the weight of different neighbors is user-speciﬁc and relation-speciﬁc. The motivation
is that a user will have distinct preferences for different
relations, which can guide the information ﬂow in the KG.
Each round of the propagation procedure can be illustrated
as follows:
Aggregate neighbors of an entity ei:
= AGG (eh−1
), ∀m ∈Ni, h = 1, 2, · · · , H.
Update the h-order representation of the entity with
h−1-order neighbor embedding and self embedding:
i = g(eh−1
), h = 1, 2, · · · , H.
Note that e0
i stands for the initial representation of the entity,
i stands for the h-order representation of entity ei,
which is a mixture of entity initial representation and representations from h-hop neighbors. The aggregation function
maps N neighbors to a vector ∈Rd, and the update function
g(·) is a non-linear function: Rd × Rd →Rd. By repeating
this process for H times iteratively, the representation of the
candidate item contains information from H-hop neighbors.
Wang et al. proposed KGCN, in which the weight of
each neighbor m ∈Ni is user-speciﬁc. It is calculated with
the user representation u and the entity relation r, which are
all trainable parameters,
wm = uT r.
Then, the weight of each neighbor is normalized, and forms
the h −1-order representation for entity ei’s neighbors via
m∈N (i) exp (wm) ,
As for the entity representation update part, it designs different update functions to concatenate neighbors. In the h-th
round of the propagation process, entities within H −h + 1
hops of the candidate items are updated by following the
Equation 33, 34. In each round of update, the candidate item
embedding evi mixes with neighbors one hop further, and
ﬁnally receives the information from H-hop neighbors. For
computational efﬁciency, KGCN uniformly samples a ﬁxedsize of neighbors for each entity in the constructed item KG,
which is favorable for large-scale datasets and KGs.
However, KGCN is prone to overﬁtting, since the useritem interaction is the only supervised signal for the whole
framework. Later, Wang et al. proposed a follow-up
approach, KGCN-LS, which further adds a label smoothness (LS) regularization on the KGCN model. If the user
u interacts with item v in the extracted entities, v should
have a label lu(v) = 1, otherwise lu(v) = 0. In this work,
they mapped the user preference for each entity pair in
the extracted entity sets ε into a preference matrix Au,
where Au[i, j] = su(rei,ej), the user preference score for
entity ei and ej connected with the relation rei,ej. Then, the
framework tries to minimize the following energy function
with the assumption that adjacent entities in the KG may
have similar labels,
E (lu, Au) = 1
Au[i, j] (lu (ei) −lu (ej))2 .
Next, it propagates the interaction labels in the KG and
estimates the label ˆlu(v) for the candidate item v. The loss
function for the label propagation part is
yuv, ˆlu(v)
where J(·) is the cross-entropy loss function, yuv is the true
label for user-item pair. The label propagation module and
the preference propagation module are jointly trained, and
further improve the recommendation results.
Based on the item KG, these papers reﬁne the item
representation with inward propagation in the item KG.
However, similar to user reﬁnement with outward aggregation in the KG, only one type of entity is reﬁned.
Reﬁnement of both User and Item Representation
Recently, some papers have explored the propagation mechanism in the user-item KG. Both users, items and their
associated entities are connected in one graph, and the
interaction between user-item pairs serves as one type of
relation. The user embedding and the item embedding can
be reﬁned with their corresponding neighbors during the
propagation process, as illustrated in Equation 33, 34.
Wang et al. proposed KGAT, which directly models
the high order relations between users and items with
embedding propagation. KGAT ﬁrst applies TransR to
obtain the initial representation for entities. The neighbor
aggregation process is similar to KGCN, though it utilizes
the following nonlinear activation equation for each triplet
(h, r, t) ∈G to calculate the weight for aggregation:
w(h, r, t) = (Wret)T tanh(Wreh + er).
After H-layer-propagation, different order representations
of the user e(0)
u , · · · , e(H)
will be obtained. These representations are concatenated and forms the ﬁnal user representation e∗
u. The ﬁnal representation of the candidate item
v can be calculated in a similar approach. Finally, the user
preference can be calculated via ˆyu,v = e∗T
Qu et al. proposed KNI, which further considers
the interaction between item-side neighbors and user-side
neighbors. After obtaining high-order representation e(H)
of entities in the KG, instead of using the enhanced user
and item embedding to predict the user preference, KNI
leverages the enhanced representation of user neighbors
Nu and item neighbors Nv for preference estimation. The
motivation is that items i ∈Nu and entities j ∈Nv share
interactive patterns. They designed an attention network to
assign a proper weight for each neighbor pair to model the
user preference ˆyu,v:
αi,j = softmaxi,j
Zhao et al. proposed IntentGC, a scalable recommendation framework. To improve efﬁciency, IntentGC translates the original user-item KG into two user-user and
item-item multi-relational graphs. IntentGC calculates the
second-order proximity of two users and items under each
type of auxiliary entity in the original graph, and converts it
to a relation in the translated graph. The user representation
and the item representation are reﬁned in the user graph
and item graph separately with the propagation mechanism
as illustrated in Equation 33, 34. Moreover, they designed a
faster graph convolution function to update high-order entity representation, with the assumption that the interaction
between features in different dimensions of the entity and
its neighbors are meaningless. Take the user side update as
an example, the update function 34 becomes:
(i, 1) · eh−1
(i, r) · eh−1
where r is the r-th type of relation, wh−1
(i, j) is the weight
for the feature in the i-th dimension, N r
u is the neighbor
with the r-th type of relation, θh−1
is the importance for the
i-th feature vector.
One limitation of previous methods is that they may
introduce irrelevant neighbors in the propagation process.
To overcome this issue, Sha et al. proposed AKGE,
which learns enhanced representation of user ui and candidate item vj by propagating information in a subgraph of
this user-item pair. AKGE ﬁrst pre-trains the embeddings of
entities in the graph with TransR , then samples several
salient paths connecting ui and vj based on the pairwise
distance in these paths, which forms a subgraph for ui and
vj. Next, AKGE updates high-order entity representation
with a gating mechanism that is similar to the gated recurrent units to better control the information ﬂow in
the graph. The construction of the subgraph ﬁlters out less
related entities in the graph, facilitating mining high-order
user-item relations for recommendation.
Similar to propagation in the item graph, the weight of
edges in the user-item graph is also user-speciﬁc. Therefore,
these models can offer explanations for recommendation
results by checking the salient paths that connect the target
user and the candidate item. As the user is incorporated as
one type of node, the explanation is more intuitive, since the
contribution of each interacted item is available.
By incorporating users into the KG, the high-order connection pattern can be explored to a greater extent. The
downside is that more relations in the graph will bring
irrelevant entities, which may mislead the user’s preference
in the aggregation process.
Summary for Propagation-based Method
In Table 5, we list the main advantages and shortcomings of
different implementation of propagation-based methods.
Comparisons between propagation-based methods. In the table, “RU.”
stands for reﬁnement of the user, “RI.” stands for reﬁnement of the item,
“RUI.” stands for reﬁnement of the user and item, and “−” stands for
this method has no comparative advantage.
Main advantages
Main shortcomings
∗only one type of entity
gets reﬁned
∗scalability
∗only one type of entity
gets reﬁned
∗reﬁne both user and
item representations
∗more irrelevant entities
Propgation-based methods are usually computational
costly. As the graph grows large, it becomes difﬁcult for the
model to converge. To improve the efﬁciency, faster graph
convolutional operation has been proposed in , and it is
common to apply neighbor sampling in each layer , ,
 , . However, the random sampling will inevitably
lead to loss of information, failing to fully explore the
knowledge in the graph.
In this section, we provide qualitative comparisons for
methods across categories and necessary explanations to
illustrate their advantages and shortcomings in Table 6.
Moreover, we summarize common techniques for the explainable recommendation and compare the performance
of popular KGE methods, so as to provide readers with
practical suggestions.
The embedding-based method is the most ﬂexible approach. On the one hand, it is relatively easy to encode
the KG with the KGE module, and the learned embedding
Comparisons for methods across categories. In the table, “Emb.” stands
for embedding-based method, “Conn.” stands for connection-based
method, and “Prop.” stands for propagation-based method.
Main advantages
Main shortcomings
∗ignore high-order
relation between entities
∗hard to interpret
∗interpretable
∗data-sparsity issue
information
in decomposing connection
meta-structure
∗interpretable
∗fully exploit information
∗scalability
can be naturally incorporated into the user representation or
item representation. While in the connection-based method,
it can be tedious to deﬁne meta-path or meta-graph in the
graph; as for the propagation-based method, the aggregation and update part need to be carefully designed. On
the other hand, the embedding-based method is suitable for
most application scenarios, due to the external knowledge
is usually available in different tasks. On the contrary, in
the meta-structure based method, meta-paths are usually
diverse for different application scenarios and cannot generalize to new datasets. Also, for speciﬁc scenarios, like
news recommendation, it is hard to deﬁne meta-path and
apply the meta-structure based method. Meanwhile, both
the path-embedding based method and the propagationbased method are impropriate for the recommendation
scenarios with large-scale datasets, since the computational
complexity may grow large in enumerating paths and
neighbors. Moreover, the quality and the quantity of paths
are crucial for connection-based methods, therefore, sparse
datasets may not provide enough paths to mine relations
and model interests for this type of method. Nevertheless,
both the embedding-based method and the connectionbased method fail to fully explore information in the KG.
With the development of GNN techniques, the propagationbased method has become a new research trend in recent years. In addition, both the connection-based method
and the propagation-based method can be interpreted with
paths in the KG, while the embedding-based method is less
intuitive to interpret.
To facilitate readers understanding how to leverage KG
for the explainable recommendation, we summarize common techniques in our collected papers.
• Attention mechanism on relation embedding. This approach is adopted in embedding-based methods , ,
 . The attention mechanism is applied to the embedding
of relations between entities in the KG. From the attention
weight of different relations, the signiﬁcance of each type of
item attribute for the target user is available. Therefore, this
technique could provide the preference-level explanation for
the recommendation.
• Deﬁning meta-path/meta-graph. The relation between the
selected item and the target user or interacted items can be
decomposed into the combination of several meta-paths or
meta-graphs. By translating the meta-path or meta-graph
into understandable rules, the explanation can be offered by
the system , , , , , , , .
• Attention mechanism on path embedding. For pathembedding methods, the weight of a speciﬁc path that
connects the target user and candidate item is available
with the attention mechanism. The weight of each path can
represent the relative importance of each path for the user.
Therefore, explanations can be provided based on salient
paths in the graph , , , .
• Reinforcement learning in User-Item KG. By training an
agent in the user-item KG with the reinforcement learning
technique, the actual path that connects the uer-item pair
can be mined , . It can directly show the reasoning
process in the KG instead of ﬁnding a post-hoc explanation
for the already chosen recommendations. Thus, the reasoning process is precise and trustworthy for the target user.
• Extracting edge weight. The propagation-based method
requires assigning the user-speciﬁc weight for each type
of neighbor in the aggregation process. The edge weight
controls the information ﬂow between entities in the graph,
and can reﬂect the importance of each type of relation in the
KG. Moreover, edge weights between entities in the KG are
also available from the attention weight or learned relation
matrix. Therefore, it is possible to generate explanations
by ﬁnding salient paths that connect the candidate item
and the target user, or the interacted items in multi-hop
neighbors , , , , , , .
The KGE method is required in most works to encode
the semantic relations between entities in the KG. Distinct
KGE methods will lead to different performances in models,
thus, we summarize and compare various KGE strategies.
In the two-stage learning method, the entity embedding
is learned in the KGE module separately. While in other
categories of works, the entity embedding can be randomly
initialized and jointly trained with the recommendation
module. However, it has been reported that replacing the
randomly initialized vector with pre-trained KG embedding
learned from the KGE model can improve the recommendation performance . Here, we collect empirical analysis
of the effect of different KGE methods on recommendation
results. The most commonly used methods are translational distance models, including TransE , TransH ,
TransR , and TransD . TransE provides the most
strict constraint of entity representations. Given a triplet
(eh, r, et) ∈G, TransE assumes the entity embedding and
the relation embedding have the relation eh + r ≈et.
Although TransE is simple and efﬁcient, it has ﬂaws in
capturing the many-to-many relation. TransH overcomes
the issue by allowing the head entity and tail entity to have
different representations under various relations. TransR
relaxes the entity relation by modeling the entity embedding
and the relation embedding in separate spaces connected
with a projection matrix. TransD further allows the projection matrix to consider both the relation type and entity
type. Based on the empirical results in , , , ﬂexible
models such as TransD, TransR, and TransH outperform
the TransE model. However, a higher degree of ﬂexibility
in KGE methods not necessarily bring improvement ,
 . The optimal KGE method may be related to speciﬁc
datasets and recommendation frameworks. Moreover, these
translational distance models are only suitable for a direct
graph. For an undirected KG, there may exist the relation
(movie1, share director, movie2). To learn the embedding
for an undirected graph, semantic matching models are
commonly used. For example, RCF adopts DistMult to
learn the graph embedding.
DATASETS OF RECOMMENDER SYSTEMS WITH
KNOWLEDGE GRAPH
Besides the beneﬁt of accuracy and interpretability, another advantage of KG-based recommendation is that this
type of side information can be naturally incorporated into
recommender systems for different applications. To show
the effectiveness of the KG as side information, KG-based
recommender systems have been evaluated on datasets
under different scenarios. In this section, we categorize these
works based on the dataset and illustrate the difference
among these scenarios. The contributions of this section are
two-fold. First, we provide an overview of datasets used
in various scenarios. Second, we illustrate how knowledge
graphs are constructed for different recommendation tasks.
This section can help researchers ﬁnd suitable datasets to
test their recommender systems.
We collect datasets used in investigated papers, and
summarize the basic statistical information of the dataset
(the number of users, the number of items, the density of
the dataset), how papers construct the KG, as well as the
commonly selected knowledge base to supplement external
knowledge for each dataset in Table 7. For the statistical
information of the dataset, we list the information in its original description if it is available. In practice, it is common to
select a subset of the large dataset, and ﬁlter out users and
items with less than k records for higher data quality, thus,
the statistical information of the dataset in different works
might be slightly different. Eventually, these works can be
categorized into seven application scenarios, and we will
illustrate the characteristics of each scenario.
• Movie. The advantage of movie recommendation is that
there are multiple external knowledge bases contain knowledge in the movie domain. Moreover, it is easy to map the
movie title into the external knowledge base, from which
extracts subgraphs with the movie’s extra knowledge, such
as the genre, the actor, the director, and the country. The
most commonly used datasets are the MovieLens benchmark datasets which are collected from the MovieLens
website , including MovieLens-100K, MovieLens-1M,
and MovieLens-20M with a different number of ratings.
Each dataset contains ratings, the movie’s attributes, and the
user’s proﬁle. Besides the MovieLens dataset, there is also
the DoubanMovie dataset crawled from Douban ,
a popular Chinese social media network. DoubanMovie
maintains the movie tag, and can link the movie title with
the entity in the Chines KG, CN-DBPedia, to enrich the
representation of items. Among these datasets, MovieLens-
100K is the smallest one, which is generally evaluated
by some early works and works with high computational
complexity. MovieLens-1M is the most popular one with a
A collection of datasets for different application scenarios and corresponding papers, where “⋆” stands for the dataset is public available, “# U”
stands for the number of user, “# I” stands for the number of item, “IKG” stands for item KG, “UIKG” stands for user-item KG, “Exernal KB” stands
for the external knowledge base, “−” stands for the speciﬁc number is not public, and the blank entries stand for no paper in the survey belongs to
this category, or no external knowledge base has been used for this dataset in our collected papers.
External KB
MovieLens-100K ⋆
 , 
 , , , 
MovieLens-1M ⋆
 , , ,
 , , , 
 , , ,
 , , 
MovieLens-20M ⋆
 , , 
 , 
DoubanMovie ⋆
CN-DBPedia
Book-Crossing ⋆
 , , ,
 , , 
Amazon-Book ⋆
 , 
DBbook2014
IntentBooks
DoubanBook
Last.FM-a ⋆
 , , 
Last.FM-b ⋆
 , 
 , , 
Amazon Review ⋆
 , , ,
 , 
Alibaba Taobao
Yelp Challenge ⋆
 , , ,
 , , ,
 , , 
Dianping-Food
balanced rating number and density, while the MovieLens-
20M is the largest one, which is suitable for verifying the
scalability of the model. Note that the movie recommendation datasets are much denser than other scenarios.
• Book. The book recommendation is another popular task.
Similar to the movie scenario, external knowledge of books
is also abundant. Two public available datasets are commonly used, including Book-Crossing and Amazon-
Book . Book-Crossing contains the user’s demographic
information and the book’s attributes, such as the author,
the publisher, the year of publication. The Amazon-Book
dataset is the largest subset of the Amazon Review dataset.
Compared with the Book-Crossing dataset, the user’s review and user’s behavior relations, such as “also view”,
“view and buy”, “also buy”, and “buy together” are available. Therefore, more relations can be included in the constructed KG. Moreover, the Amazon-Book dataset is much
larger. Some papers also adopt the dataset of DoubanBook,
DBbook2014, and IntentBooks.
• Music. Similar to the movie and book scenario, external
knowledge of music tracks and artists can be obtained.
There are two datasets extracted from the Last.fm online
music system . Last.FM-a is a small dataset, which
provides the user’s social relation, tags of tracks and artists,
and listening records. While Last.FM-b contains demographic information of users, tags of tracks, and user’s
listening records. Another popular dataset is the KKBox
dataset, which was released by the WSDM Cup 2018 Challenge . This dataset contains the listening records and
the description of the track, including the genre, artist,
composer, and lyricist. These datasets vary by the size, and
the KKBox is the most sparse one.
• News. Compared with other scenarios, news recommendation is heavily dependent on the textual information,
which requires incorporating natural language processing
(NLP) techniques. Moreover, news recommendation is challenging because the news itself is time-sensitive, and
the content is highly condensed, which requires commonsense to understand. Besides, people are topic-sensitive in
choosing news to read and may prefer news from various
domains. Traditional news recommendation models fail to
discover the high-level connection among the news. Therefore, KGs are introduced into this scenario , , to
ﬁnd the logical relations between different news for more
personalized recommendation. To build the KG for news
recommendation, the ﬁrst step is to recognize entities in the
content, then map these extracted entities to the external
knowledge base. The most popular dataset is Bing-News,
which contains the user click information, news title, etc,
however, this dataset is private. While MIND is a
recently released large-scale news dataset, containing a title,
an abstract, a category label, and a body for each news
article, as well as interaction records for each user. Moreover,
entities in each news article are recognized and mapped
into the Wikidata knowledge base. The entities, their
corresponding triplets in Wikidata, as well as entity and
relation embeddings learned with the TransE model are
all included in the dataset, which makes it convenient for
the research of KG-based news recommendation.
• Product. Compared with datasets in other scenarios,
datasets in this domain are quite large and sparse. The most
popular dataset is the Amazon Review dataset . There
are multiple subsets of different sizes in the Amazon Review dataset, including books, cell phones, clothing, music,
electronics, etc, here we list the statistics of data in total.
Except for the user and item attributes, user reviews and
user behavior relations are also included. Although external
knowledge of products is also available, most works ,
 , , , build the user-item KG directly with multiple types of relations within the recommendation dataset,
while build the item KG with the assistance of the
Freebase to mine rules between associated items. Some
papers , also use the data from Alibaba Taobao.
• POI. Point of Interest (POI) recommendation is the recommendation of new businesses and activities (restaurants,
museums, parks, cities, etc.) to users based on their historical check-in data. The most popular dataset is the Yelp Challenge , which contains the attributes of businesses and
users, check-ins, and reviews. There are multiple versions
of the Yelp Challenge dataset, here we present the dataset
released in 2013. Similar to the product recommendation,
the Yelp Challenge dataset contains rich POI side information and user-related relations, therefore, the user-item
KG can be constructed with knowledge within the dataset.
There is also paper that utilizes the CEM dataset1 to
recommend next trip, and work that uses the Dianping-
Food dataset, which is provided by Dianping.com for
restaurant recommendation.
• Social Platform. This task is to recommend potentially
interested people or meetings to users in the community.
Since all the data are crawled by themselves, it is hard to
map the user or item to external knowledge bases in some
datasets. Therefore, most works build KGs with available
relations in the crawled data. One application is to recommend unfollowed users to the target user on the social platform Weibo with the collected Weibo tweets data ,
where an item KG is constructed to map celebrities to Satori.
Another application is to recommend ofﬂine meetings for
users on a social website, MeetUp . The last application
lies in the academic domain, to recommend conferences to
researchers with the DBLP data .
FUTURE DIRECTIONS
In the above sections, we have demonstrated the advantage of KG-based recommender systems from the aspects
of more accurate recommendation and explainability. Although many novel models have been proposed to utilize
1. an Amadeus database containing bookings over a dozen of airlines
the KG as side information for recommendation, some further opportunities still exist. In this section, we outline and
discuss some prospective research directions.
• Dynamic Recommendation. Although KG-based recommender systems with GNN or GCN architectures have
achieved good performance, the training process is timeconsuming. Thus such models can be regarded as static
preference recommendation. However, in some scenarios,
such as online shopping, news recommendation, Twitter,
and forums, a user’s interest can be inﬂuenced by social
events or friends very quickly. In this case, recommendation with a static preference modeling may not be enough
to understand real-time interests. In order to capture dynamic preference, leveraging the dynamic graph network
can be a solution. Recently, Song et al. designed
a dynamic-graph-attention network to capture the user’s
rapidly-changing interests by incorporating long term and
short term interests from friends. It is natural to integrate
other types of side information and build a KG for dynamic
recommendation by following such an approach.
• Multi-task Learning. KG-based recommender systems
can be naturally regarded as link prediction in the graph.
Therefore, it is potential to improve the performance of
graph-based recommendation by considering the nature of
the KG. For example, there may exist missing facts in the
KG, which leads to missing relations or entities. However,
the user’s preference may be ignored because these facts are
missing, which can deteriorate the recommendation results.
Papers , have shown it is effective to jointly train the
KG completion module and recommendation module for
better recommendation. Other works have utilized multitask learning by jointly training the recommendation module with the KGE task and item relation regulation
task . It would be interesting to exploit transferring
knowledge from other KG-related tasks, such as entity
classiﬁcation and resolution, for better recommendation performance.
• Cross-Domain Recommendation. Recently, works on
cross-domain recommendation have appeared. The motivation is that interaction data is unbalanced across domains.
For example, on the Amazon platform, the book subset
is larger than other domains. With the transfer learning
technique, interaction data from the source domain with
relatively rich data can be shared for better recommendation in the target domains. Zhang et al. proposed
a matrix-based method for cross-domain recommendation.
Later, Zhao et al. introduced PPGN, which puts users
and products from different domains in one graph, and
leverages the user-item interaction graph for cross-domain
recommendation. Although PPGN outperforms SOTA signiﬁcantly, the user-item graph contains only interaction
relations, and does not consider other relationships among
users and items. It could be promising to follow works in
this survey, by incorporating different types of user and item
side information in the graph to improve the performance
of cross-domain recommendation.
• Knowledge Enhanced Language Representation. To improve the performance of various NLP tasks, there is a
trend to integrate external knowledge into the language
representation model, so that the knowledge representation
and the text representation can be reﬁned mutually. For
instance, Chen et al. proposed the STCKA for short
text classiﬁcation, which utilizes the prior knowledge from
KGs to enrich the semantic representation of short texts.
Zhang et al. proposed the ERNIE, which incorporates
knowledge from Wikidata to enhance the language representation, and such an approach has proven to be effective
in the task of relation classiﬁcation. Although the DKN
model utilizes both the text embedding and the entity
embedding in the news, these two types of embeddings are
simply concatenated to obtain the ﬁnal representation of
news, instead of considering the information fusion between
two vectors. Therefore, it is promising to apply the strategy
of knowledge-enhanced text representation in the news
recommendation task and other text-based recommendation
tasks for better representation learning, facilitating more
accurate recommendation.
CONCLUSION
In this survey paper, we investigate KG-based recommender
systems and summarize the recent efforts in this domain.
This survey illustrates how different approaches utilize the
KG as side information to improve the recommendation
result as well as providing interpretability in the recommendation process. Moreover, an introduction to datasets used
in different scenarios is provided. Finally, future research
directions are identiﬁed, hoping to promote development
in this ﬁeld. KG-based recommender systems are promising
for accurate recommendation and explainable recommendation, beneﬁtting from the fruitful information contained in
the KGs. We hope this survey paper can help readers better
understand works in this area.
ACKNOWLEDGMENTS
The research work is supported by the National Key Research and Development Program of China under Grant No.
2018YFB1004300, the National Natural Science Foundation
of China under Grant No. U1836206, U1811461, 61773361,
61836013, 71531001, the Project of Youth Innovation Promotion Association CAS under Grant No. 2017146.