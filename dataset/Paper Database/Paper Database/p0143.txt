NBER TECHNICAL WORKING PAPER SERIES
BOOTSTRAP-BASED IMPROVEMENTS FOR INFERENCE WITH CLUSTERED
A. Colin Cameron
Jonah B. Gelbach
Douglas L. Miller
Technical Working Paper 344
 
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
September 2007
We thank an anonymous referee and participants at The Australian National University, UC Berkeley,
UC Riverside, Dartmouth College, Florida State University, Indiana University, and MIT for useful
comments. Miller acknowledges funding from the National Institute on Aging, through Grant Number
T32-AG00186 to the NBER. The views expressed herein are those of the author(s) and do not necessarily
reflect the views of the National Bureau of Economic Research.
© 2007 by A. Colin Cameron, Jonah B. Gelbach, and Douglas L. Miller. All rights reserved. Short
sections of text, not to exceed two paragraphs, may be quoted without explicit permission provided
that full credit, including © notice, is given to the source.
Bootstrap-Based Improvements for Inference with Clustered Errors
A. Colin Cameron, Jonah B. Gelbach, and Douglas L. Miller
NBER Technical Working Paper No. 344
September 2007
JEL No. C12,C15,C21
Researchers have increasingly realized the need to account for within-group dependence in estimating
standard errors of regression parameter estimates. The usual solution is to calculate cluster-robust
standard errors that permit heteroskedasticity and within-cluster error correlation, but presume that
the number of clusters is large. Standard asymptotic tests can over-reject, however, with few (5-30)
clusters. We investigate inference using cluster bootstrap-t procedures that provide asymptotic refinement.
These procedures are evaluated using Monte Carlos, including the example of Bertrand, Duflo and
Mullainathan . Rejection rates of ten percent using standard methods can be reduced to the nominal
size of five percent using our methods.
A. Colin Cameron
Department of Economics
One Shields Avenue
Davis, CA 95616
 
Jonah B. Gelbach
Department of Economics
University of Arizona
1130 E. Helen Street
Tucson, AZ 85721-0108
 
Douglas L. Miller
Department of Economics
One Shields Avenue
davis, CA 95616-8578
 
Introduction
Microeconometrics researchers have increasingly realized the essential need
to account for any within-group dependence in estimating standard errors of
regression parameter estimates. In many settings the default OLS standard
errors that ignore such clustering can greatly underestimate the true OLS
standard errors, as emphasized by Moulton .
A common correction is to compute cluster-robust standard errors that
generalize the White heteroskedastic-consistent estimate of OLS standard errors to the clustered setting. This permits both error heteroskedasticity and quite ﬂexible error correlation within cluster, unlike a much more
restrictive random eﬀects or error components model. In econometrics this
adjustment was proposed by White and Arellano , and it is implemented in STATA, for example, using the cluster option. In the statistics
literature these are called sandwich standard errors, proposed by Liang and
Zeger for generalized estimating equations, and they are implemented
in SAS, for example, within the GENMOD procedure. A recent brief survey
is given in Wooldridge .
Not all empirical studies use appropriate corrections for clustering. In
particular, for ﬁxed eﬀects panel models the errors are usually correlated
even after control for ﬁxed eﬀects, yet many studies either provide no control
for serial correlation or erroneously cluster at too ﬁne a level. Kézdi 
demonstrated the usefulness of cluster robust standard errors in this setting
and contrasted these with other standard errors based on stronger distributional assumptions. Bertrand, Duﬂo, and Mullainathan , henceforth
BDM , focused on implications for diﬀerence-in-diﬀerence (DID) studies using variation across states and years. Then the regressor of interest is
an indicator variable that is highly correlated within cluster (state) so there
is great need to correct standard errors for clustering. The clustering should
be on state, rather than on state-year.
A practical limitation of inference with cluster-robust standard errors is
that the asymptotic justiﬁcation assumes that the number of clusters goes
to inﬁnity. Yet in some applications there may be few clusters. For example,
this happens if clustering is on region and there are few regions. With a
small number of clusters the cluster-robust standard errors are downwards
biased. Bias corrections have been proposed in the statistics literature; see
Kauermann and Carroll , Mancl and DeRouen , and Bell and
McCaﬀrey . Angrist and Lavy in an applied study ﬁnd that bias
adjustment of cluster-robust standard errors can make quite a diﬀerence. But
even after appropriate bias correction, with few clusters the usual Wald statistics for hypothesis testing with asymptotic standard normal or chi-square
critical values over-reject. BDM demonstrate through a Monte Carlo
experiment that the Wald test based on (unadjusted) cluster-robust standard
errors over-rejects if standard normal critical values are used. Donald and
Lang also demonstrate this and propose, for DID studies with policy
invariant within state, an alternative two-step GLS estimator that leads to Tdistributed Wald tests in some special circumstances. Ibragimov and Muller
 propose an alternate approach based on separate estimation within
each group. They separate the data into independent groups, estimate the
model within each group, average the separate estimates and divide by the
sample standard deviation of these estimates, and then compare against critical values from a T-distribution. This approach holds promise for settings
with few groups and where model identiﬁcation and a central limit theorem
holds within each group. Our proposed method does not require the latter
two conditions, can be used to test multiple hypotheses, and is based on the
parameter estimator commonly used in practice.
In this paper we investigate whether bootstrapping to obtain asymptotic reﬁnement leads to improved inference for OLS estimation with cluster-
robust standard errors when there are few clusters.
We focus on cluster
bootstrap-t procedures that are generalizations of those proposed for regression with heteroskedastic errors in the nonclustered case.
Several features of our bootstraps are worth emphasizing. First, the bootstraps involve resampling entire clusters. Second, our goal is to use variants
of the bootstrap that provide asymptotic reﬁnement, whereas many empirical studies use the bootstrap only to obtain consistent estimates of standard
errors. Third, we consider several diﬀerent cluster resampling schemes: pairs
bootstrap, residuals bootstrap and wild bootstrap. Fourth, we consider examples with as few as ﬁve clusters. Fifth, we evaluate our bootstrap procedures in a number of settings including examples of others that were used to
demonstrate the deﬁciencies of standard cluster-robust methods.
The paper is organized as follows.
Section 2 provides a summary of
standard asymptotic methods of inference for OLS with clustered data, and
presents small-sample corrections to cluster-robust standard errors that have
been recently proposed in the statistics literature. Section 3 presents various
possible bootstraps for clustered data, with additional details relegated to
an Appendix. Sections 4 to 6 present, respectively, a Monte Carlo experiment using generated data, a Monte Carlo experiment using data from BDM
 , and an application using data from Gruber and Poterba .
The primary contribution of this paper is to oﬀer methods for more accurate cluster-robust inference. These methods are fairly simple to implement
and matter substantively in both our Monte Carlo experiments and our replications.
A second important contribution of this paper is to oﬀer a careful and
precise description of the various bootstraps a researcher might perform, and
the similarities and diﬀerences between our proposed methods and several
commonly-applied methods. Our primary motivation for presenting this description is to be precise about our methods. It also oﬀers empiricists a clearer
understanding of the menu of bootstrap choices and their consequences.
Cluster-Robust Inference
Before considering the bootstrap we present results on inference with clustered errors.1
OLS with Clustered Errors
The model we consider is one with G clusters (subscripted by g), and with Ng
observations (subscripted by i) within each cluster. Errors are independent
1For this and subsequent sections, additional details and explanation are provided in
 .
across clusters but correlated within clusters. The model can be written at
various levels of aggregation as
igβ + uig,
i = 1, ..., Ng, g = 1, ..., G,
= Xgβ + ug,
g = 1, ..., G,
where β is k × 1, xig is k × 1, Xg is Ng × k, X is N × k, N = P
g Ng, yig and
uig are scalar, yg and ug are Ng × 1 vectors and y and u are N × 1 vectors.
Interest lies in inference for the OLS estimator bβ = (X0X)−1X0y. Under
the assumptions that data are independent over g but errors are correlated
within cluster, with E[ug] = 0, E[ugu0
g] = Σg, and E[ugu0
h] = 0 for cluster
h 6= g, we have
a∼N[0, N V[bβ]] where
V[bβ] = (X0X)−1 ³XG
g=1 XgΣgX0
This diﬀers from and is usually larger than the specialization V[bβ] =
u(X0X)−1 that is based on the assumption of iid errors and leads to the
default OLS variance estimate when σ2
u is estimated by s2 = bu0bu/(N −k).
The underestimation bias is typically increasing in (1) cluster size; (2) withincluster correlation of the regressor; and (3) within-cluster correlation of the
error; see Kloek . The bias can be very large .
One approach to correcting this bias is to model Σg to depend on unknown
parameters, say Σg = Σg(γ), and then use estimate bΣg = Σg(bγ).
random eﬀects (RE) model assumes that there are cluster-speciﬁc iid random
eﬀects, estimates the variance of these eﬀects and of the iid individual shocks,
and uses these for bΣg. We call the resulting standard errors Moulton-type
standard errors.
Cluster-Robust Variance Estimates
The RE model places restrictions of homoskedasticity and equicorrelation
within cluster, and assumes knowledge of the functional form Σg(γ).
less parametrically restrictive approach is to use the cluster-robust variance
estimator (CRVE)
bVCR[bβ] = (X0X)−1 ³XG
g=1 Xgeugeu0
In the simplest case OLS residuals are used, so eug = bug = yg −Xgbβ.
The CRVE controls for both error heteroskedasticity across clusters and
quite general correlation and heteroskedasticity within cluster, at the expense
of requiring that the number of clusters G →∞. It is implemented for many
STATA regression commands using the cluster option (which uses eug = √cbug
G−1 with large N), and is used in SAS in the GENMOD
procedure (which uses eug = bug).
A weakness of the standard CRVE with eug = bug is that it is biased,
since E[bugbu0
g] 6= Σg = E[ugu0
g]. The bias depends on the form of Σg but
will usually be downwards.2 Several corrected residuals eug for (3) have been
proposed by Kauermann and Carroll and Bell and McCaﬀrey .
In our simulations we examine a correction proposed by Bell and McCaﬀrey
 which is equivalent to the jackknife estimate of the variance of the
OLS estimator.
This correction generalizes the HC3 measure (jackknife)
of MacKinnon and White , and so we refer to this correction as the
CR3 variance estimator.3 For a more detailed discussion of the computation
of this estimator, see Cameron, Gelbach, and Miller, . Angrist and
Lavy apply a related (but distinct) correction ) in an
application with G = 30 to 40 and ﬁnd that the correction increases clusterrobust standard errors by between 10 and 50 percent.
2For example, Kezdi uses eug = bug and ﬁnds in his simulations that with G = 10
the donwards bias is between 9 and 16 percent.
3The jackknife drops in turn each observation, here a cluster, computes the leave-oneout estimate bβ(g), g = 1, ..., G, and then uses variance estimate G−1
g(bβ(g) −bβ). The
CR3 measure for OLS is a multiple of the related measure proposed by Mancl and DeRouen
 in the more general setting of GEE.
Cluster-Robust Wald Tests
We consider two-sided Wald tests of H0 : β1 = β0
1 against Ha : β1 6= β0
β1 is a scalar component of β.4 We use the Wald test statistic
where sbβ1 is the square root of the appropriate diagonal entry in bVCR[bβ].
This “t” test statistic is asymptotically normal under H0, and we reject H0
at signiﬁcance level α if |w| > zα/2, where zα/2 is a standard normal critical
Under standard assumptions the Wald test is of correct size as the number of clusters G →∞. The problem we focus on in this paper is that with
few clusters the asymptotic normal critical values can provide a poor approximation to the correct, ﬁnite-G critical values for w, even if an unbiased
variance matrix estimator is used in calculating sbβ.
General small sample results are not possible even if the (clustered) errors
are normally distributed. In practice, as a small sample correction some programs use a T distribution to form critical values and p-values. STATA uses
4The generalization to single hypothesis c0β −r = 0 where c is a k × 1 vector is trivial.
For multiple hypotheses Cβ −r = 0 the Wald asympototic chisquare test would be used.
the T(G −1) distribution, which may be better than the standard normal,
but may still not be conservative enough to avoid over-rejection. Bell and
McCaﬀrey and Pan and Wall propose instead using a T distribution with degrees of freedom determined using an approximation method
due to Satterthwaite . Rather than use OLS, Donald and Lang 
propose an alternative two-step estimator that leads to a Wald test that in
some special cases is T(G−k1) distributed where k1 is the number of regressors that are invariant within cluster and often k1 = 2 (the intercept and the
clustered regressor of interest).
We instead continue to use the standard OLS estimator with CRVE,
and bootstrap to obtain bootstrap critical values that provide an asymptotic
reﬁnement and may work better than other inference methods for OLS when
there are few clusters.
Cluster Bootstraps
Bootstrap methods generate a number of pseudo-samples from the original
sample, for each pseudo-sample calculate the statistic of interest, and use the
distribution of this statistic across pseudo-samples to infer the distribution
of the original sample statistic.5
There is no single bootstrap as there are diﬀerent statistics that we may
be interested in, diﬀerent ways to form pseudo-samples, and diﬀerent ways to
use results for statistical inference. In this section we discuss several diﬀerent
bootstraps that are examined in our simulations. We provide greater detail
on the bootstrap algorithms in Appendix A.2, and in .
Choices that need to be made when bootstrapping include the following:
what observational units to sample (individual observations or clusters); what
objects to sample in generating bootstrap samples ((y, X) pairs, residuals
drawn from the sample residuals, or residuals based on transformations of
sample residuals); what statistics to calculate in each bootstrap replication;
how to use the resulting bootstrap distribution of the statistics; and whether
or not to impose the null hypothesis in generating the bootstrap samples.
Some combinations of these choices provide asymptotic reﬁnement; others
do not. Some choices in principle provide valid tests, but in fact perform
poorly with few clusters and commonly occuring empirical settings.
5The bootstrap was introduced by Efron . Standard book treatments are Hall
 , Efron and Tibsharani , and Davison and Hinkley . In econometrics see
Horowitz , MacKinnon , and the texts by Davidson and MacKinnon 
and Cameron and Trivedi .
The statistic considered is the Wald test statistic w deﬁned above. The
data are clustered into G independent groups, so the resampling method
should be one that assumes independence across clusters but preserves correlation within clusters.
Pairs Cluster Bootstrap-se and Bootstrap-t
The obvious method is to resample the clusters with replacement from the
original sample {(y1, X1), ..., (yG, XG)}. This resampling method is called
a pairs cluster bootstrap6. A commonly used bootstrap in the empirical literature is to use a pairs bootstrap with the bootstrap-se procedure.
bootstrap-se procedure uses the bootstrap estimates of bβ1, denoted bβ
form the bootstrap estimate of standard error
1b. This estimated standard error is then used in a
typical wald test. This is popular in the applied literature as it enables an
estimate of the standard error when the analytic formula for the standard
error is diﬃcult to compute. However, in contrast to the bootstrap-t procedure, it does not oﬀer asymptotic reﬁnement, and so may perform worse
6Alternative names used in the literature include cluster bootstrap, case bootstrap, nonparametric bootstrap, and nonoverlapping block bootstrap.
with few clusters.
The bootstrap-t procedure, proposed by Efron for conﬁdence intervals, computes the following Wald statistic for each bootstrap replication
1,b −bβ1)/sbβ
b = 1, ..., B,
1,b is a cluster-robust standard error for bβ
1,b. Note that w∗
b is centered
on bβ1. This centering is changed to β0
1 if the resampling method imposes H0.
The resulting distribution of w∗
1, ..., w∗
B is then used to form inference on the
original Wald statistic in (4).7 We oﬀer more details in the appendix A.2.
Both bootstrap-se and bootstrap-t procedures are asymptotically valid.
For small number of clusters G, however, the true size will diﬀer from the
nominal signiﬁcance level α. Furthermore, the true size will also diﬀer across
the two procedures. An asymptotic approximation yields an actual rejection
rate or true size α + O(G−j/2). Then the true size goes to α as G →∞,
provided j > 0. Larger j is preferred, however, as then convergence to α
is faster. A bootstrap provides asymptotic reﬁnement if it leads to j larger
than that for conventional (ﬁrst-order) asymptotic methods.
Bootstrap-t
7The bootstrap-t procedure is also called a percentile-t procedure, because the “t” test
statistic w is bootstrapped, and a studentized bootstrap, since the Wald test statistic is a
studentized statistic.
procedures provide an asymptotic reﬁnement, while bootstrap-se procedures
do not. Further, as we show in our simulations below, this can matter in
actual data settings with few clusters.
Asymptotic reﬁnement is more likely to occur if the bootstrap is applied
to an asymptotically pivotal statistic, meaning one with asymptotic distribution that does not depend on unknown parameters; see Appendix A.1 for a
more complete discussion. The bootstrap-t procedure directly bootstraps w
which is asymptotically pivotal since the standard normal has no unknown
parameters.
An alternative method with asymptotic reﬁnement is the bias-corrected
accelerated (BCA) procedure, deﬁned in Efron , Hall , and in .
This bootstraps bβ1
which is asymptotically nonpivotal as its asymptotic distribution depends on
unknown σ2
bβ1, but then provides adjustment for bias and asymmetry. This
is a popular method for conﬁdence intervals — STATA reports BCA rather
than percentile-t conﬁdence intervals. We adapt BCA to testing by rejecting
H0 if w is outside the conﬁdence interval, and include a cluster version of
BCA in our simulations.
There are just a few studies that we are aware of that consider asymptotic
reﬁnement. Sherman and le Cessie conduct simulations for OLS with
as few as ten clusters. For 90 percent conﬁdence intervals, they ﬁnd that the
pairs cluster bootstrap-t undercovers by considerably less than conﬁdence intervals based on CRVE. Flynn and Peters consider cluster randomized
trials where a pairs cluster bootstrap draws G clusters by separately resampling from the G/2 treatment clusters and the G/2 control clusters. For
skewed data and few clusters they ﬁnd that pairs cluster BCA conﬁdence intervals have considerable undercoverage, even more than conventional robust
conﬁdence intervals, though in their Monte Carlo design the robust intervals
do remarkably well. The authors also consider a second-stage of resampling
within each cluster, using a method for hierarchical data given in Davison
and Hinkley that is applicable if the random eﬀects model is assumed.
In the econometrics literature, BDM apply a pairs cluster bootstrap using the bootstrap-t procedure. BDM use default OLS standard errors, however, rather than cluster-robust standard errors, in computing both
the original data and the resampled data Wald statistics. Because of this their
method may not yield asymptotic reﬁnement. The authors ﬁnd that their
bootstrap does better than using default OLS standard errors and standard
normal critical values, yet surprisingly does worse than using cluster robust
standard errors with standard normal critical values.
Residual and Wild Cluster Bootstrap-t
For a regression model with additive error, resampling methods other than
pairs cluster can be used. In particular, one can hold regressors X constant
throughout the pseudo-samples, while resampling the residuals which can be
then used to construct new values of the dependent variable y.
The obvious method is a residual cluster bootstrap that resamples with replacement from the original sample residual vectors to give residuals {bu∗
1, ..., bu∗
and hence pseudo-sample {(by∗
1, X1), ..., (by∗
G, Xg)} where by∗
This resampling scheme has two weaknesses. First, it assumes that the
regression error vectors ug are iid, whereas in Section 2 we were speciﬁcally
concerned that the variance matrix Σg will diﬀer across clusters. Second, it
presumes a balanced data set where all clusters are the same size.
The wild bootstrap relaxes both these restrictions. This procedure creates pseudo-samples based on bu∗
g = bug with probability 0.5 and bu∗
with probability 0.5, with this assignment at the cluster level. The wild bootstrap was proposed for regression in the nonclustered case (and with diﬀerent
weights) by Wu . Its asymptotic validity and asymptotic reﬁnement
were proven by Liu and Mammen . Horowitz pro-
vides a Monte Carlo demonstrating good size properties. The weights we use
(+1 with probability 0.5 and −1 with probability 0.5) are called Rademacher
weights8. Here we have extended the wild bootstrap to the clustered setting.
The only other study to do so that we are aware of is the brief application
by Brownstone and Valletta .
Several authors, particularly Davidson and MacKinnon , advocate
use of bootstrap resampling methods that impose the null hypothesis. This
is possible using both residual and Wild bootstraps. Thus we present results
based on bootstraps that impose the null, in which case the bootstrap Wald
statistics are centered on β0
1 rather than bβ1, and the residuals bootstrapped
are those from the restricted OLS estimator eβ that imposes H0 : β1 = β0
For details see Appendix A.2.
Bootstraps with Few Clusters
With few clusters the bootstrap resampling methods produce a distinctly ﬁnite number of possible pseudo-samples, so the bootstrap distribution w∗
1, ..., w∗
will not be smooth even with many bootstrap replications. Furthermore, in
8These weights lead to asymptotic reﬁnement if bβ is symmetrically distributed, which
is the case if errors are symmetric. If bβ is asymmetrically distributed, our version is still
asymptotically valid, but diﬀerent weights provide asymptotic reﬁnement. Davidson and
Flachaire provide theory and simulation to nonetheless support using Rademacher
weights even in the asymmetric case.
some pseudo-samples bβ1 or sbβ1 may be inestimable. This is likely to be a
problem with pairs cluster bootstrap when there is a binary regressor that
is invariant within cluster (so always 0 or always 1 for given g). Then if
there are few clusters some bootstrap resamples may have all clusters with
the regressor taking only value 0 (or value 1), so that bβk is inestimable.
This issue does not arise when regressors and dependent variables take several diﬀerent values, such as in the Section 4 Monte Carlos. But it does
arise in our application to the BDM and Gruber and Poterba 
diﬀerences-in-diﬀerences examples, because the regressors of interest in those
cases are indicator variables. The residual or wild cluster bootstraps do not
encounter these problems, as we are not resampling the regressors. In our
BDM simulations below we see this issue is problematic for G ≤10.
Test Methods used in this Paper
In the remainder of the paper we implement the Wald test using nine bootstrap procedures, as well as four non-bootstrap procedures. Table 1 provides
a summary.
Our ﬁrst four methods do not use the bootstrap and diﬀer only in the
method from section 2 used to calculate bV[bβ]. They use, respectively, the
default variance estimate, the Moulton-type estimate, the cluster-robust es-
timate (3), and the cluster-robust estimate with jackknife corrected residuals. Method 1 is invalid if there is clustering, method 2 is invalid unless
the clustering follows a random eﬀects model, while methods 3 and 4 are
asymptotically valid provided clusters are independent.
Methods 5 to 7 use the bootstrap-se procedure. We use three diﬀerent
cluster bootstrap resampling methods, respectively, the pairs cluster bootstrap, the residual clusters bootstrap with H0 imposed, and the wild bootstrap with H0 imposed. For details see Appendix A.2.3. Methods 5-7 do not
provide asymptotic reﬁnement, and method 6 is valid only if cluster error
vectors are iid.
Method 8 uses the BCA bootstrap with pairs cluster resampling.
Methods 9 to 13 use the bootstrap-t procedure. The ﬁrst three of these
methods use pairs cluster resampling with diﬀerent standard error estimates.
Method 9 is the already discussed method of BDM that uses default standard
errors rather than CRVE standard errors. Methods 10 and 11 use diﬀerent
variants of the CRVE deﬁned in (3), respectively, the standard CRVE and the
CR3 correction. In each case the same variance matrix estimation method is
used for both the original sample and bootstrap resamples. Methods 12 and
13 use, respectively, residual and wild bootstraps, and both use the standard
CRVE estimate and impose H0.
Method 12 is valid only if cluster error
vectors are iid. For details see Appendix A.2.1.
Monte Carlo Simulations
To examine the ﬁnite-sample properties of our methods we conducted several Monte Carlo exercises for dgp a linear model with intercept and single
regressor. The error is clustered according to a random eﬀects model, with
either constant correlation within cluster or departures from this induced by
heteroskedasticity. This design is relevant to a cross-section study of individuals with clustering at the state level, for example. The regressor and
dependent variable are continuous and take distinct values across clusters
and (usually) within clusters, so that even with few clusters it is unlikely
that a pairs cluster bootstrap sample will be inestimable.
yig = β0 + β1xig + uig,
with diﬀerent generating processes for xig and uig used in subsequent subsections. Since β1 = 1 in the dgp, the Wald test statistic is w = (bβ1 −1)/sbβ1.
We perform R replications, where each replication yields a new draw of
data from the dgp, and leads to rejection or nonrejection of H0. In each repli-
cation there are G groups (g = 1, ..., G), with NG individuals (i = 1, ..., NG)
in each group. We varied the number of groups G from 5 to 30 and usually
set NG = 30. The various methods given in each row of Tables 2-4 are then
applied to the same generated data. For bootstraps we used B = 399 bootstraps rather than the recommended B = 999 or higher. This lower value
is ﬁne for a Monte Carlo exercise, since the bootstrap simulation error will
cancel out across Monte Carlo replications.
We estimate the actual rejection rate a, by ba, the fraction of the R replications for which H0 is rejected. This is an estimate of the true size of the test.
With a ﬁnite number of replications a may be diﬀer from the true size due to
simulation error. The simulation standard error is sba =
ba(1 −ba)/(R −1).
For example, sba = 0.007 for ba = 0.05 and R = 1000.
Simulations with Homoskedastic Clustered Errors
In the ﬁrst simulation exercise both regressors and errors are correlated
within group, with errors homoskedastic.
Data were generated according
yig = β0 + β1xig + uig = β0 + β1 (zg + zig) + (εg + εig),
with zg, zig, εg, and εig each an independent N draw, and β0 = 0 and
β1 = 1. Here the components zg and εg that are common to individuals
within a group induce within group correlation of both regressors and errors.
The simulation is based on R = 1000 Monte Carlo replications.
Our ﬁrst results appear in Table 2. Each column gives results for the
various number of groups (G = 5, 10, 15, 20, 25, 30) and throughout NG =
30. The ﬁrst entry is the estimated true size of the test. The Monte Carlo
standard error is given in parentheses. Each row presents a diﬀerent method,
detailed in section 3.4. For comparison, we also show the rejection rate that
would hold if we used the asymptotic normal critical value of 1.96, but the
Wald statistic actually had a T distribution with G −2 degrees of freedom,
Pr[|T| > 1.96|T ∼TG−2].
We begin with conventional (nonbootstrap) Wald tests using diﬀerent
estimators of standard errors.
The default OLS standard errors that assume iid errors do poorly here, with rejection rates given in row 1 of 0.43 to
0.50. This illustrates the need to correct standard errors for clustering. The
Moulton-type estimate for standard errors should work well here since this
takes advantage of correct knowledge of the dgp. The rejection rates in row 2
are considerably higher than 0.05, especially for low G, though are similar to
those expected if the Wald test statistic is actually T(G−2) distributed. The
CRVE is much better than default standard errors, though still over-rejects
compared to Moulton-type standard errors. The CR3 correction leads to
rejection rates much closer to (but signiﬁcantly diﬀerent from) 0.05.
The pairs cluster bootstrap-se method yields rejection rates in row 5
that are very similar to the CRVE, except for G = 5. The residual cluster
bootstrap-se method leads to rejection rates in row 6 that are close to 0.05.
From row 7, the wild cluster bootstrap-se method under-rejects for G ≤10,
and rejects at level close to 0.05 for G > 10. The closeness to 0.05 of the
latter two bootstrap methods is surprising given that they do not oﬀer an
asymptotic reﬁnement. The BCA bootstrap with pairs cluster resampling
should provide an asymptotic reﬁnement, yet from row 8 it has rejection
rates similar to those using CRVE.
The remainder of Table 2 uses the theoretically preferred bootstrap-t
procedure with various resampling methods. Even though it uses default
standard errors, the BDM bootstrap (row 9) does better than CRVE and
is a great improvement compared to not bootstrapping (row 1). The pairs
cluster bootstrap-t has rejection rates in row 10 of 0.08 that are much closer
to (but signiﬁcantly diﬀerent from) 0.05. The CR3 correction makes little
diﬀerence. Both the residual cluster bootstrap-t and wild cluster bootstrap-t
rejection rates are not statistically diﬀerent from 0.05 (with the exception of
the residual bootstrap with G = 5).
In summary, Table 2 demonstrates that all the bootstrap-t methods are
an improvement on the usual cluster-robust method with standard normal
critical values; the BCA method provides no improvement on CRVE; and
the residual cluster bootstrap-se also performs well.
Simulations with Heteroskedastic Clustered Errors
The second simulation brings in the additional complication of heteroskedastic errors. Then the Moulton-type correction and the residual bootstrap are
no longer valid theoretically.
We generated data according to the process:
yig = β0 + β1xig + uig = β0 + β1 (zg + zig) + (εg + εig),
with zg, zig, and εg again independent N draws, but now εig ∼N[0, 9 ∗
(zg + zig)2]. The dgp sets β0 = 1 and β1 = 1.
Results appear in Table 3. Default OLS standard errors again do poorly,
with rejection rates around 0.30. The Moulton-type correction breaks down
given the heteroskedasticity, as expected. The cluster-robust methods do a
little better than in the preceding table, but rejection rates in rows 3 and
4 still generally exceed 0.05. The residual cluster bootstrap-se method now
breaks down due to heteroskedasticity, with rejection rates in row 6 in excess
of 0.15. The pairs cluster bootstrap-se and wild cluster bootstrap-se methods
(rows 5 and 7) perform similarly to Table 2. The BCA bootstrap again has
rejection rates in row 8 similar to those using CRVE (row 3).
The results for the bootstrap-t methods in rows 9 to 13 are similar to
those in Table 2. The BDM bootstrap-t (row 9) has similar high rejection
rates to those in Table 2, aside from marked deterioration for G = 5. The
remaining bootstrap-t methods all yield rejection rates less than 0.08, with
the residual cluster bootstrap-t and wild cluster bootstrap-t doing best. The
good performance of the residual cluster bootstrap-t is surprising given that
errors are heteroskedastic.
In summary, the Table 3 results for inference with heteroskedastic clustered errors are similar to those for homoskedastic clustered errors except
that, as expected, the Moulton-type correction and residual cluster bootstrapse methods now perform very poorly. The bootstrap-t methods are an improvement on the usual cluster-robust method with standard normal critical
values, while the BCA method provides no improvement.
Alternative Critical Values, Cluster Sizes and Regressor Design
We perform a third set of Monte Carlo experiments to examine how the
diﬀerent estimators perform under varying assumptions. These simulations
are presented in Table 4 with each simulation based on G = 10 groups.
Column 1 of Table 4 provides a baseline against which the other results
are compared. It uses the same dgp as that of Table 2. In column 2 for tests
without asymptotic reﬁnement we use critical values from a T distribution
with 8 degrees of freedom, an ad hoc ﬁnite sample correction, so that we
reject H0 if |w| > 2.306 rather than |w| > 1.960. Then the Moulton-type
estimator and the CR3 correction lead to rejection rates not statistically
signiﬁcant from 0.05. The CRVE and pairs cluster bootstrap-se still lead to
over-rejection, though by not as much. And the residual cluster bootstrap-se
and wild cluster bootstrap-se, which seem to do very well when asymptotic
normal critical values are used, now lead to great under-rejection.
In columns 3 to 5 of Table 4 we consider alternative cluster sizes of,
respectively, 2, 10 and 100 observations. For method 1, the rejection rates
increase with cluster size. Once clustering is accounted for, by any of methods
2-13, rejection rates do not vary signiﬁcantly with cluster size.
In column 6 of Table 3 we examine the performance of the various testing methods when there are there are three additional regressors, each with
no clustering component, and we continue to test the ﬁrst regressor. The
four regressors are scaled down by a factor of 1/2, so that the sum of their
variances will equal the variance of the single regressor used in the dgp of
column 1. The only signiﬁcant change in rejection rates is an increase in the
already high rejection rate for method 1 which neglects clustering.
All preceding regression designs set the intraclass correlation, ρx, of the
regressor of interest to be 0.5. In column 7 we increase ρx to ρx = 1 (clusterinvariant regressor with xig = zg) and in column 8 we decrease to ρx = 0 in
column 8 (iid regressor with xig = zig). In both cases the regressor is scaled
2 to keep V[xig] unchanged.
With cluster-invariant regressor (column 7) the failure to control for clustering is magniﬁed and the row 1 to 3 rejection rates are larger than in
the benchmark column 1. For bootstrap-se and bootstrap-t there is little
change in rejection rates, except that for reasons unknown the pairs cluster
bootstraps (both bootstrap-se and bootstrap-t) now have rejection rates not
statistically signiﬁcantly diﬀerent from 0.05.
With iid regressor (column 8) the default OLS standard errors are consis-
tent and the rejection rate in row 1 is close to 0.05. The Moulton-type and
CRVE also have rejection rates much closer to 0.05. The various bootstrap
procedures lead to rejection rates that are all close to those in column 1.
Finally, in column 9 we change the dgp to examine an unbalanced setting,
so that one half of the clusters are small (with group size NG = 10) and half
of the clusters are large (with group size NG = 50). The residual cluster
bootstrap requires equal cluster sizes, so it cannot be used in this design.
The remaining methods yield results qualitatively similar to those in column
1, with the main change being that the standard CRVE leads to much larger
over-rejection in row 3.
In summary, all the bootstrap-t methods are an improvement on the usual
cluster-robust method with standard normal critical values; the BCA method
provides no improvement; and the residual cluster bootstrap-se also performs
well. Table 4 also indicates that when non-bootstrap methods are used to
control for clustering, it is better to use critical values from a T (G −2)
distribution than from a standard normal.
Bertrand, Duﬂo and Mullainathan 
Simulations
To enable a more practically familiar application of our methods, we now
consider the diﬀerences-in-diﬀerences setup explored in Bertrand, Duﬂo, and
Mullainathan . The main results of this section are that the residual
and wild cluster bootstrap methods perform well in cases with as few as 6
clusters. These results stand in contrast to the more pessimistic conclusion
about cluster bootstrapping in BDM .
The data set is of U.S. states over time. The dependent variable is the
state-by-year average log wage level (after partialling out certain individual
characteristics). For such a variable, the error term within cluster is serially
correlated, even if state and year ﬁxed eﬀects are included as regressors. The
regressor of interest is a state policy dummy variable.
The original data is CPS data on many individuals over time and states.
Most of the BDM study uses a smaller data set that aggregates individual observations to the state-year level. We begin with these data, which
have the advantage of being balanced and relatively small, before moving to
the individual data.9
9We extracted individual-level data from the relevant CPS data sets and, when appropriate, aggregated these data using the method presented in BDM . This gave data
Aggregated State-year Data
Using our choice of subscripts, the igth observation is for the ith year in the
gth state. There are ﬁfty states and twenty-one years. The aggregate model
estimated is
yig = αg + γi + β1Iig + uig,
where yig is a year-state measure of excess earnings, the regressors are state
dummies, year dummies, and a policy change indicator Iig.10
If a policy change occurs in state g at time i∗, then Iig = 0 for i < i∗and
Iig = 1 for i ≥i∗. BDM’s experiments randomly assign a policy change to
occur in half the states, and when it does occur it occurs somewhere between
the sixth and ﬁfteenth year. In each simulation a diﬀerent draw of G states
with replacement is made from the original 50 states.
The Wald statistic studied is w = bβ1/sbβ1. BDM investigate size properties
by letting the policy change be a “placebo” regressor that has no eﬀect on
yig. They also investigate the power against the alternative Ha : β1 = 0.02
similar to that in BDM . We thank these authors for sharing some of their data
with us, enabling this comparison.
10We retain our notation for consistency with the rest of our discussion.
more obvious subscripts for this problem are i for individual, s for state and t for year.
The underlying model is yist = αs + γt + x0
istδ + βIst + uist, where yist is individual
log-earnings for women aged 25-50 years, and xist is age and education.
two-step OLS procedure: (1) regress yist on xist yielding OLS residual buist; (2) regress
bust = N −1
i buist on state dummies, year dummies, and Ist. Thus our yig is their bust.
by actually increasing yig by 0.02 when Iig = 1. They ﬁnd that (1) default
standard errors do poorly; (2) cluster-robust standard errors do well for all
but G = 6; and (3) their bootstrap, which we discuss in our section 3.1, does
poorly for low numbers of clusters, with actual rejection rates 0.44, 0.23 and
0.13 for G = 6, 10 and 20, respectively.
The ﬁrst two rows of Table 5 show that the default standard errors and
Moulton-type estimator lead to high rejection rates. The third row uses the
cluster-robust variance estimator, and gives results very close to those in
BDM’s Table 8.
Rows 4 to 6 of our Table 5 give rejection rates when the Wald statistic
is calculated using bootstrap standard error estimates. These generally lead
to tests with actual size between 0.04 and 0.09. The one notable exception
is that the cluster-pairs standard error bootstrap (row 4) produces severe
under-rejection (0.001) with G = 6. Informal experimentation suggests to
us that this is because many bootstrap replications (with only a couple of
states sampled) sample only one “treatment” or “control” state. For these
replications, the treatment dummy (or constant) is ﬁt perfectly, and so has
zero estimated residuals. When these “zero” residuals are plugged into the
CRVE formula (3) the resulting bVCR[bβ
1] is unreasonably small, leading to
Wald statistics in some bootstrap resamples that are too large to consistently
represent the Wald statistic’s true distribution. This in turn results in the
severe under-rejection.11
The BCA method with pairs cluster resampling in general leads to greater
over-rejection than when CRVE is used.
The remaining rows 8 to 11 of Table 5 give rejection rates for various
bootstrap-t procedures. From row 8 we ﬁnd that the BDM bootstrap performs similarly to cluster-robust standard errors. For reasons we cannot explain, the rejection rates we obtain are considerably lower than those given
in BDM Table 5. The pairs cluster bootstrap-t under-rejects appreciably
for both G = 6 and G = 10 for reasons discussed above. The residual and
wild cluster bootstrap-t methods (rows 9 and 10) do very well with actual
rejection rates approximately equal to 0.05, even for G = 6.
The discussion so far has focused on size. The last 4 columns in Table
5 report power against a ﬁxed alternative.
As expected, power increases
as the number of clusters increases, since there is then greater precision in
estimation.
11We thank Doug Staiger for suggesting this mechanism to us.
Individual-Level Data
For completeness we additionally consider regression using individual-level
Recall that we are using g to denote the clustering unit and i to
denote year, so we use n to denote individual. Then the model is
ynig = αg + γi + x0
nigδ + β1Iig + unig,
where the individual-level regressors xnig are a quartic in age and three education dummies. Iig is generated as before.
Table 6 reports the results of R = 250 simulations with B = 199 replications used for the bootstrap. We consider cases G = 6 and G = 10. The
ﬁrst row reports high rejection rates when we use the CRVE but erroneously
cluster on state-year combinations. In the second row of Table 6 we see that
using the CRVE and correctly clustering on state considerably reduces the
rejection rates, but they are still much too high. The third row of Table
6 shows that the bootstrap-t procedure using wild cluster resampling (with
clustering on the state) leads to rejection rates not statistically signiﬁcantly
diﬀerent from 0.05. Because the individual level data are unbalanced we
cannot use the residual cluster bootstrap.
In summary, using both aggregate and micro data, the wild cluster bootstrap-
t leads to rejection rates of 0.05. The pairs cluster bootstrap-t works ﬁne
for G ≥20, but for G ≤10 can fail due to problems posed by the binary
regressor.
Gruber and Poterba Application
Gruber and Poterba examine the impact of tax incentives on the decision to purchase health insurance. They analyze diﬀerential
changes for self-employed and business-employed in the after-tax price of
health insurance due to the Tax Reform Act of 1986 (TRA86). The TRA86
extended the tax subsidy for health insurance to self-employed individuals;
individuals employed by a business had a tax subsidy both before and after
TRA86, and so can serve as a comparison group.
The dependent variable y is whether or not an employed person has private health insurance. Like GP we focus on individuals 25-54 years of age.
The model can be written as
yijt = α1 + α2SELFijt + α3POSTijt + β1SELFijt × POSTijt + ujt,
where i denotes individual, j denotes employer type, t denotes year, SELFijt =
1 if individual i is self-employed at time t, and POSTijt = 1 if the year is
1987, 1988 or 1999.
We perform diﬀerence-in-diﬀerence analysis, controlling for potential clustering of errors of a form considered by Donald and Lang . Like Donald
and Lang, we ignore additional regressors (GP examine subtle interactions
between pre-tax income, employment status, and the TRA86).
In their preliminary analysis, GP report in their Table IV average insurance rates by year and employer-type for March CPS data on eight years (ﬁve
before the TRA86 and three after), leading to an aggregated data set with
sixteen observations. Our simple diﬀerence-in-diﬀerence estimate is 0.055,
with a standard error of 0.0044.
We next follow Donald and Lang , and treat years as clusters, so
that there are G = 8 clusters in our analysis. When we cluster on year, the
cluster-robust standard error obtained using (3) is 0.0074. The regressor is
highly statistically signiﬁcant, with bβ1/sbβ1 = 7.46 and very low p-value.
To enable more meaningful analysis we test H0 : β1 = 0.040 against
Ha : β1 6= 0.040. Then w = (0.055 −0.040)/0.0074 = 2.02 with p-value of
0.043 using standard normal critical values and 0.090 using the T distribution
with G −2 = 6 degrees of freedom.
If we instead bootstrap this Wald statistic with B = 999 replications, the
pairs cluster bootstrap-t yields p = 0.209, the residual cluster bootstrap-t
gives p = 0.112, and the wild cluster bootstrap-t gives a p-value of 0.070.12
We believe that the p-value for the pairs cluster bootstrap is implausibly
large, for reasons discussed in the BDM replication, while the other two
bootstraps lead to plausible p-values that, as expected, are larger than those
obtained by using asymptotic normal critical values.
We have also estimated this model on individual-level data , with results very similar to those reported here.
Conclusion
Many microeconometrics studies use clustered data, with regression errors
correlated within cluster and regressors correlated within cluster. Then it
is essential that one control for clustering. A good starting point is to use
Wald tests (or “t” tests) that use cluster-robust standard errors, provided
the appropriate level of clustering is chosen. As made clear in section 2 of
BDM , too many studies fail to do even this much.
In this paper we are concerned with the additional complication of having few clusters. Then the use of appropriate cluster-robust standard errors
still leads to nontrivial over-rejection by Wald tests. Our Monte Carlo sim-
12The results reported use Mammen weights and do not impose the null hypothesis.
Similar results were obtained using Rademacher weights and imposing the null hypothesis.
ulations reveal that at the very least one should provide some small sample
correction of standard errors, such as magnifying the residuals in (3) by a
G/(G −1) and using a T distribution with G or fewer degrees of
freedom (we arbitrarily used G −2 in Table 3).
The primary contribution of this paper is to use bootstrap procedures
to obtain more accurate cluster-robust inference when there are few clusters.
Our discussion and implementations of the bootstrap make it clear that there
are many possible variations on a bootstrap. The usual way that the bootstrap is used, to obtain an estimate of the standard error, does not lead to
improved inference with few clusters as it does not provide an asymptotic
reﬁnement.
We focus on the bootstrap-t procedure, the method most emphasized by
theoretical econometricians and statisticians, and which provides asymptotic
reﬁnement. We ﬁnd that the bootstrap-t procedure can lead to considerable
improvement, provided the same method is used in calculating the Wald
statistic in the original sample and in the bootstrap resamples.
But these improvements depend on the resampling method used and on
the discreteness of the data being resampled.
The standard method for
resampling that preserves the within-cluster features of the error is a pairs
cluster bootstrap that resamples at the cluster level, so that if the gth cluster
is selected then all data (dependent and regressor variables) in that cluster
appear in the resample. This bootstrap can lead to inestimable models or
nearly inestimable models in some bootstrap pseudo-samples when there are
few clusters and regressors take a very limited range of values. While not
all applications will encounter this problem, it does arise when interest lies
in a binary policy variable that is invariant (conditional on other regressors)
within cluster.
We ﬁnd that an alternative cluster bootstrap, the wild cluster bootstrap
does especially well. This bootstrap is a cluster generalization of the wild
bootstrap for heteroskedastic models. Even when analysis is restricted to a
wild cluster bootstrap, several diﬀerent variations are possible. The variation
we use is one that uses equal weights and probability, and uses residuals from
OLS estimation that imposes the null hypothesis. This bootstrap works well
in our own simulation exercise and when applied to the data of BDM .
The BDM study is one of the highest proﬁle papers highlighting the importance of cluster robust inference. One important conclusion of
BDM is that for few (six) clusters the cluster-robust estimator performs poorly, and for moderate (ten and twenty) number of clusters their
bootstrap based method also does poorly. We perform a re-analysis of their
exercise, and come to much more optimistic conclusions.
Using the wild
cluster bootstrap-t method our empirical rejection rates are extremely close
to the theoretical values, even with as few as six clusters, and there is no
noticeable loss of power after accounting for size. Our results oﬀer not only
theoretical improvements, but practical ones as well. We hope researchers
will take advantage of these improvements in the plentiful cases when clustering among a relatively small number of groups is a real concern.
Appendix A.1 presents a general discussion of the bootstrap and why it is asymptotically better to bootstrap an asymptotically pivotal statistic (bootstrapt method). Appendix A.2 details the various bootstraps summarized in Table
Asymptotic Reﬁnement for Bootstrap-t
The theory draws heavily on Hall and Horowitz . Cameron and
Trivedi provide a more introductory discussion.
General Bootstrap Procedure
We use the generic notation TN = TN(SN) to denote the statistic of interest,
calculated on the basis of a sample SN of size N. We focus on inference
for a single regression coeﬃcient β1 from multivariate OLS regression. Then
leading examples are TN = bβ1, and TN = (bβ1 −β0
1)/sbβ1, where we recall that
1 is given by the null hypothesis.
We wish to approximate the ﬁnite sample cdf of TN, HN(t) = Pr[TN ≤t].
The bootstrap does this by obtaining B resamples of the original sample
SN, using methods given in the subsequent subsection. The bth resample is
denoted S∗
Nb and is used to form a statistic T ∗
Nb). The empirical
distribution of T ∗
Nb, b = 1, .., B, is used to estimate the distribution of TN, so
Pr[TN ≤t] is estimated by the fraction of the realized values of T ∗
N1, ..., T ∗
that are less than t, denoted
bHN(t) = B−1
where 1 (·) is the indicator function. This distribution can be used to compute
moments such as variance, and also to compute test critical values and pvalues.
General Bootstrap Procedure for a Statistic TN
1. Do B iterations of this step. On the bth iteration:
(a) Re-sample the data from SN using one of the procedures presented
in Appendix A.2. Call the resulting re-sample S∗
(b) Use the bootstrap re-sample form T ∗
Nb), where in some
but not all cases T ∗
N(·) = TN(·).
2. Conduct inference using bHN(t). See Appendix A.2 for further details.
The bootstrap-t method directly approximates the distribution of TN =
1)/sbβ1. If the bootstrap resampling method imposes H0 then T ∗
1b, where bβ
1b is the estimator of β1 and sbβ
1b is the standard error
from re-sample S∗
Nb. Note that we center T ∗
1 since the resampling dgp
has β1 = β0
1. If instead the bootstrap resampling method does not impose
H0, the case necessarily for pairs cluster, then T ∗
1b −bβ1)/sbβ
centering is on bβ1 and the bootstrap views the original sample as the population. That is, implicitly we impose β1 = bβ1, and the bootstrap resamples
are viewed as B samples from a population with β1 = bβ1.
By contrast the bootstrap-se, percentile and BCA methods bootstrap
TN = bβ1. Then T ∗
1b, where bβ
1b is the estimator of β1 from re-sample
Asymptotic Reﬁnement
For notational simplicity drop the subscript N, so TN(SN) = T has smallsample cdf denoted H(t|F) = Pr[T ≤t|F] where F is the true cdf generating
the underlying data in sample SN. The distribution H usually is analytically
intractable.
The usual ﬁrst-order asymptotic theory replaces it with the
asymptotic distribution of the test-statistic. The bootstrap instead replaces
H with bH(t| bF) = Pr[T ∗≤t| bF] where bF denotes the cdf used to obtain
bootstrap resamples. We are concerned with how good an estimate bH(t| bF)
is of H(t|F).
The bootstrap leads to consistent estimates and hypothesis tests under
relatively weak assumptions. Because the bootstrap should be based on a
distribution bF that is consistent for F, one must take care to choose the
resampling method so as to mimic the properties of F.
For consistency,
the bootstrap requires smoothness and continuity in F and in bH. These
assumptions are satisﬁed for our application for the OLS estimator with
clustered errors.
A consistent bootstrap need not have asymptotic reﬁnement, however. A
key requirement is that we work with an asymptotically pivotal statistic, as
now explained.
To begin with assume that T is standardized to have mean 0 and variance
1. The usual asymptotic approximation T
a∼N is
Pr[T ≤t|F] = Φ(t) + O(N−1/2),
where Φ(·) is the standard normal cdf and N is sample size. When one uses
the standard normal critical values with a “t” statistic, this is the approximation on which one relies. The Edgeworth expansion gives a better asymptotic
approximation
Pr[T ≤t|F] = Φ(t) + N−1/2a(t)φ(t) + O(N−1),
where φ(·) is the standard normal density and a(·) is an even quadratic
polynomial with coeﬃcients that depend on the low-order cumulants (or moments) of the underlying data. One can directly use the preceding result, but
computation of the polynomial coeﬃcients in a(t) is theoretically demanding.
The bootstrap provides an alternative.
The bootstrap version of T is the statistic T ∗, which has Edgeworth
Pr[T ∗≤t| bF] = Φ(t) + N−1/2ba(t)φ(t) + Op(N−1),
where bF is the empirical distribution function of the sample.
If ba(t) =
a(t) + Op(N−1/2), which is often the case, then
Pr[T ≤t|F] = Pr[T ∗≤t| bF] + Op(N−1).
This statement means that the bootstrap cdf Pr[T ∗≤t| bF] is within Op(N−1)
of the unknown true cdf Pr[T ≤t|F], which is a better approximation than
one gets using Φ(t), since the standard normal cdf is within O(N−1/2) and
Pr[O(N−1/2) −Op(N−1) > 0] gets arbitrarily close to 1 for suﬃciently large
What if we use a nonpivotal statistic T? Suppose T
a∼N[0, σ2] so that
a∼N where s is a consistent estimate of the standard error. Then
Edgeworth expansions still apply, but now
Pr[T ≤t|F] = Φ(t/σ) + N−1/2b(t/σ)φ(t/σ) + O(N−1),
for some quadratic function b(·) 6= a(·), and similarly for the bootstrap estimates
Pr[T ∗≤t| bF] = Φ(t/s) + N−1/2bb(t/s)φ(t/s) + Op(N−1).
Now, even if bb(·) = b(·) + Op(N−1/2), these functions are evaluated at t/s
where usually s = σ + Op(N−1/2). It follows for nonpivotal T that
Pr[T ≤t|F] = Pr[T ∗≤t| bF] + Op(N−1/2),
so there is no asymptotic reﬁnement. Thus nonpivotal statistics bring no
improvement in the convergence rate relative to using ﬁrst-order asymptotic
The main requirement for the asymptotic reﬁnement (10) is that an asymptotically pivotal statistic is the object being bootstrapped. The bootstrapt procedure does this.
The preceding analysis shows that for tests of nominal size α the true
size is α + O(N−j/2) where j = 2 using the bootstrap-t procedure, while
j = 1 using the usual asymptotic normal approximation and the percentile
and bootstrap-se procedures. These results for are for a one-sided test or a
nonsymmetric two-sided test. For a two-sided symmetric test, cancellation
occurs because a(t) is an even function, so one further term in the Edgeworth
expansion can be used. Then j = 3 using the bootstrap-t procedure and j = 2
using the other procedures.
Bootstrap Procedures
Bootstrap-t Procedures
We begin with the preferred bootstrap-t procedures using three bootstrap
sampling schemes - pairs cluster, residual cluster and wild cluster - that are
generalizations of pairs, residual and wild resampling for nonclustered data.
Pairs Cluster Bootstrap-t
1. From the original sample form w = (bβ1−β0)/sbβ1, where sbβ1 is obtained
using the CRVE in (3) with eug = (G/(G −1))bug.
2. Do B iterations of this step. On the bth iteration:
(a) Form a sample of G clusters {(y∗
1), ..., (y∗
G)} by resampling
with replacement G times from the original sample of clusters.
(b) Calculate the Wald test statistic w∗
1,b −bβ1)/sbβ
1,b, where bβ
and its standard error sbβ
1,b are obtained from OLS estimation us-
ing the bth pseudo-sample, sbβ
1,b is obtained using the same method
as that in step 1, and bβ1 is the original OLS estimate.
3. Reject H0 at level α if and only if w < w∗
[α/2] or w > w∗
[1−α/2], where
[q] denotes the qth quantile of w∗
1, ..., w∗
We consider two variations of this procedure that use alternative estimators of sbβ in both step 1 and in step 2b. First, the pairs cluster CR3
bootstrap-t uses the CRVE in (3) with eug calculated using the CR3 correction. Second, the pairs cluster BDM bootstrap-T uses default OLS standard
errors and is a symmetric version of the Wald test, following BDM .
The remaining bootstrap-t procedures use residual cluster and wild cluster resampling schemes that take advantage of the ability to resample with
the null hypothesis β1 = β0
1 imposed.
Cluster Residual Bootstrap-t with H0 imposed
1. From OLS estimation on the original sample form w = (bβ1 −β0)/sbβ1,
where sbβ1 is obtained using the CRVE in (3) with eug = (G/(G−1))bug.
Also obtain the restricted OLS estimator bβ
R that imposes H0 : β1 = β0
and the associated restricted OLS residuals {buR
1 , ..., buR
13The restricted estimator can be obtained by regressing yig −β0
1x1,ig on a constant and
all regressors other than x1,ig.
2. Do B iterations of this step. On the bth iteration:
(a) Form a sample of G clusters {(by∗
1, X1), ..., (by∗
G, XG)} by resampling
with replacement G times from {buR
1 , ..., buR
G} to give {buR∗
1 , ..., buR∗
and then forming by∗
g , g = 1, ..., G.
(b) Calculate the Wald test statistic w∗
1,b, where
1,b and its standard error sbβ
1,b are obtained from unrestricted
OLS estimation using the bth pseudo-sample, with sbβ
1,b computed
using the same method as that in step 1.
3. Reject H0 at level α if and only if w < w∗
[α/2] or w > w∗
[1−α/2], where
[q] denotes the qth quantile of w∗
1, ..., w∗
Hall provides theoretical justiﬁcation for the residual
bootstrap for clustered errors. This bootstrap is used as a benchmark in
Monte Carlo simulations for the other bootstraps. In practice it is too restrictive as it assumes that ug are iid, ruling out heteroskedasticity across
clusters, and that clusters are balanced.
Wild Cluster bootstrap-t with H0 imposed
The wild cluster bootstrap-t with H0 imposed follows the same steps
as the cluster residual bootstrap-t with H0 imposed, except that step 2a is
replaced as follows:
2a Form a sample of G clusters {(by∗
1, X1), ..., (by∗
G, XG)} by the following
For each cluster g = 1, ..., G, form either buR∗
probability 0.5 or buR∗
g with probability 0.5 and then form by∗
g , g = 1, ..., G.
A variety of weights ag have been proposed for the wild bootstrap. The
ones we use, with ag = 1 with probability 0.5 and ag = −1 with probability
0.5 are called Rademacher weights. Mammen actually proposed an
alternative set of weights: ag = (1 −
5)/2 ' −0.6180 with probability
5 ' 0.7236 and ag = 1 −(1 −
5)/2 with probability 1 −(1 +
5. These weights are the only two-point distribution that satisfy the
constraints E[ag] = 0 and E[a2
g] = 1 and the additional constraint E[a3
which is necessary to achieve asymptotic reﬁnement if bβ is asymmetrically
distributed.
Bootstrap-se Methods
We present the bootstrap-se for pairs cluster resampling.
Pairs Cluster Bootstrap-se
1. From the original sample form bβ1.
2. Do B iterations of this step. On the bth iteration:
(a) Form a sample of G clusters {(y∗
1), ..., (y∗
G)} by resampling
with replacement G times from the original sample.
(b) Calculate the OLS estimate bβ
3. Reject H0 at level α if and only if |wBSE| > zα/2, where
sbβ1,B is the bootstrap estimate of the standard error
This method is easily adapted to the other resampling schemes by appropriately amending steps 1 and 2a.