IEEE TRANSACTIONS ON AUDIO, SPEECH AND LANGUAGUE PROCESSING
Application of Deep Belief Networks for Natural
Language Understanding
Ruhi Sarikaya, Geoffrey E. Hinton, Anoop Deoras
Abstract—Applications of deep belief nets (DBN) to various
problems have been the subject of a number of recent studies
ranging from image classiﬁcation and speech recognition to
audio classiﬁcation. In this study we apply DBNs to a natural
language understanding problem. The recent surge of activity in
this area was largely spurred by the development of a greedy
layer–wise pretraining method that uses an efﬁcient learning
algorithm called contrastive divergence (CD). CD allows DBNs
to learn a multi-layer generative model from unlabeled data
and the features discovered by this model are then used to
initialize a feed-forward neural network which is ﬁne-tuned
with backpropagation. We compare a DBN-initialized neural
network to three widely used text classiﬁcation algorithms:
support vector machines (SVM), boosting and maximum entropy
(MaxEnt). The plain DBN-based model gives a call–routing
classiﬁcation accuracy that is equal to the best of the other
models. However, using additional unlabeled data for DBN pre–
training and combining DBN–based learned features with the
original features provides signiﬁcant gains over SVMs, which, in
turn, performed better than both MaxEnt and Boosting.
Index Terms—Natural language Understanding, Call–Routing,
Deep Learning, Deep Neural Nets, DBN, RBM.
I. INTRODUCTION
The goal of spoken language understanding (SLU) systems
is to enable communication between a human and machine.
SLU systems automatically identify a user’s intent from natural language by extracting the information bearing words and
issuing queries to back–end databases to satisfy the user’s
requests. Ground-breaking advances in speech recognition
technology from early 1980’s to early 1990’s opened the way
for spoken language understanding. An early SLU task was
the DARPA (Defense Advanced Research Program Agency)
Airline Travel Information System (ATIS) project in 1990.
This project focused on building spoken understanding systems in the travel domain. These systems handled spoken
queries related to ﬂight-related information including ﬂight
booking and hotel reservation. An example utterance from
this domain is I want to ﬂy from Seattle to Miami tomorrow
morning. Language understanding was reduced to the problem
of extracting task-speciﬁc slots, such as DestinationLocation,
DepartureLocation and DepartureDate, where the intent is
FindFlight.
The conditional random ﬁelds (CRFs) is one of the
most widely used discriminative modeling technique for slot
ﬁlling , in spoken language understanding. Slot ﬁlling
Corporation,
(Ruhi.Sarikaya,Anoop.Deoras)@microsoft.com.
University of Toronto ( .)
is cast as a sequence classiﬁcation problem to obtain the most
probable slot sequence:
C∗= argmax
where W = w1, ..., wT is the input word sequence and C =
c1, ..., cT , ct ∈C is the sequence of associated class labels
Motivated by the success of early commercial interactive
voice response (IVR) applications used in call centers, a new
SLU task evolved: that of determining the user intent. This
new SLU task was framed as classifying users’ utterances
into predeﬁned categories (called intents or call-types) .
For example, if the user said something related to a billing
statement in an IVR setting, the automatic call routing system
should direct the call to the billing department. For intent
determination (for call routing or other tasks), early work on
discriminative classiﬁcation algorithms for the AT&T HMIHY
system used Boosting . In this paper, we focus on the
intent determination task, speciﬁcally focusing on call routing
applications. We frame the problem in a probabilistic setting.
More formally, given the sequence of words, W, the most
likely user intent (class label), U ∗is given by:
U ∗= argmax
where W = w1, ..., wT is the input word sequence and U ∈
U is the user intent among the possible set of intents ∈U.
We refer interested readers to for a detailed history and
overview on SLU.
Today, natural language call routing is one of the most
widely adopted NLP technologies in the world, and there are
hardly any large companies that do not use it for dealing
with customers. The main advantage of call routing is the
automation it provides for customer care, largely eliminating
customer/agent interaction. As such, every small improvement
in call routing accuracy matters since users whose goal is
not identiﬁed by the system require a human agent to resolve
their problems. A typical call routing system is composed of
two statistical components: a speech recognition system and
an action classiﬁer. The speech recognition system transcribes
the speaker’s speech and sends the transcription to the action
classiﬁer, which extracts the speaker’s intent embodied in
different call–types. Each call–type triggers a different action
in the system back–end. There are numerous machine learning
techniques such as Boosting , Maximum Entropy Modeling
(MaxEnt) , and Support Vector Machines (SVM) ,
 , which are used as action classiﬁers. All of these techniques
require labeled data to train a model. Quantity and quality
IEEE TRANSACTIONS ON AUDIO, SPEECH AND LANGUAGUE PROCESSING
of labeled data are the determining factors in building and
deploying such systems. The complexity of the call routing
task largely determines how much labeled data is needed to
achieve a reasonable performance level. As the complexity of
the task increases the amount of training data required for
a reasonable performance level can become large. Therefore,
there are several key areas for technology improvement: 1)
minimizing the amount of labeled data to achieve a given
performance level, 2) improving the machine learning algorithms to achieve the best performance for a given amount
of labeled data, and 3) exploiting unlabeled data, which are
typically available in much larger quantities than labeled data,
to improve the performance for a given amount of labeled
Neural Networks (NNets) are not new to the speech and language processing ﬁeld. There have been numerous applications
of NNets to speech recognition and natural language processing problems during the past two decades. Even though NNets,
particularly deep nets with many hidden layers, appeared
capable of modeling complex structures and dependencies in
the data, they failed to live up to the expectations because
of the lack of effective training algorithms for training such
networks. Consequently, until very recently, NNets lost the
battle against GMMs/HMMs for speech recognition due to
larger computational demands and difﬁculty in parallelizing
the model training compared to the GMM/HMM approach.
In the NLP area, where the primary problems can be cast
as classiﬁcation problems, NNets fared better, but they still
were not the preferred modeling approach compared to maximum entropy models, support vector machines, and boosting
techniques partly due to the difﬁculty in training deep networks. Moreover, SVM and boosting have maximum margin
properties with faster training algorithms. Recently, however,
there has been increasing interest in Deep Belief Networks
(DBNs) because of the invention of an efﬁcient layer-bylayer learning technique. The building block of a DBN is a
probabilistic model called a Restricted Boltzmann Machine
(RBM), which is used to discover one layer of features at a
time. To learn a DBN, RBMs are applied recursively with the
feature activations produced by one RBM acting as the data
for training the next RBM in the stack. DBNs have been used
as generative models of many different forms of data in such
diverse areas as image classiﬁcation, speech recognition and
information retrieval , , . Deep networks typically
have higher modeling capacity than shallow networks with the
same number of parameters, but they are harder to train, both
as stochastic top-down generative models and as deterministic
bottom-up discriminative models. For generative training, it
is generally very difﬁcult to infer the posterior distribution
over the multiple layers of latent (hidden) variables. For
discriminative training using backpropagation, learning can be
very slow with multiple hidden layers and overﬁtting can also
be a serious problem. The recursive training method for DBNs
solves the inference problem. The use of features found by the
DBN to initialize a multilayer feed-forward neural network
signiﬁcantly decreases both the time taken for discriminative
training and the amount of overﬁtting .
RBMs can be trained using unlabeled data and they can
learn stochastic binary features which are good for modeling the higher-order statistical structure of a dataset. Even
though these features are discovered without considering the
discriminative task for which they will be used, some of
them are typically very useful for classiﬁcation as well as
for generation. A subsequent stage of discriminative ﬁnetuning can then slightly change the feature weights to make
the network even more useful for discrimination with much
less overﬁtting, which otherwise can be a serious problem
with purely discriminative training. This is particularly helpful
when the number of labeled training examples is relatively
small. In this regime, it has been shown that classiﬁers based
on generative models can outperform discriminative classiﬁers,
even without making use of additional unlabeled data .
Part of the work in this paper is presented in . In this
paper we pursue two lines of research suggested as future work
in : a) investigating the effect of using unlabeled data to
train RBMs, and b) treating the DBN as a feature generator
and using a separate classiﬁer such as an SVM to perform
the actual classiﬁcation task. These techniques lead to clear
performance improvements both over the baseline DBN and
SVM, which are largely equivalent in terms of the performance
The rest of the manuscript is organized as follows: Section
2 provides a brief introduction to RBMs. Section 3 describes
how to train a stack of RBMs recursively and how to use the
resulting DBN to initialize a feed-forward neural network that
can be discriminatively ﬁne-tuned to optimize classiﬁcation.
Section 4 summarizes the other widely used discriminative
classiﬁers. Section 5 presents the experimental results and
discussion followed by the conclusions in Section 6.
II. RESTRICTED BOLTZMANN MACHINES
A restricted Boltzmann machine is a two-layer, undirected, bipartite graphical model where the ﬁrst layer consists
of observed data variables (or visible units), and the second
layer consists of latent variables (or hidden units). The visible
and hidden layers are fully connected via symmetric undirected weights, and there are no intra–layer connections within
either the visible or the hidden layer. A typical RBM model
topology is shown in Fig. II.
The weights and biases of an RBM determine the energy of
a joint conﬁguration of the hidden and visible units E(v, h),
E(v, h; θ) = −
with model parameters θ = {W, b, a} and vi, hj ∈{0, 1}. W
are the symmetric weight parameters with V ×H dimensions,
b are the visible unit bias parameters, a are the hidden unit
bias parameters. The network assigns a probability to every
possible visible-hidden vector pair via the the energy function,
p(v, h) = 1
Z e−E(v,h)
The normalization term or partition function, Z, is obtained by
summing over all possible pairs of visible and hidden vectors.
IEEE TRANSACTIONS ON AUDIO, SPEECH AND LANGUAGUE PROCESSING
The probability that the model assigns to a visible vector, v,
is obtained by marginalizing over the space of hidden vectors,
The simplest RBMs use Bernouilli-distributed units (i. e.
stochastic binary units), but they can be generalized to any
distribution in the exponential family . However, some
combinations of distributions for the visible and hidden units
are very hard to train (see for more details). In this paper,
we restrict ourselves to binary units for all of the experiments.
The derivative of the log probability of a visible vector, v
with respect to the weights is given by:
= ⟨vihj⟩v −⟨vihj⟩model
where the angle bracket denotes the expectation with respect
to the distribution speciﬁed in the subscript. Following the
gradient of the log likelihood we obtain the update rule for
the weights as,
∆wij = ϵ(⟨vihj⟩data −⟨vihj⟩model)
where ϵ is the learning rate. The lack of hidden–hidden
connections makes the ﬁrst expectation easy to compute.
Given a visible vector, v, the hidden units are conditionally
independent and the conditional distribution of hidden unit j
is given by:
p(hj = 1 | v) = σ(aj +
where σ is the logistic sigmoid function σ(x) = 1/(1 +
exp(−x)). It is therefore easy to get an unbiased sample of
⟨vihj⟩data . Similarly, because there are no visible–visible
connections, we can easily get an unbiased sample of the state
of a visible unit, i, given a hidden vector, h:
p(vi = 1 | h) = σ(bi +
Unfortunately, it is exponentially expensive to compute
⟨vihj⟩model exactly so the contrastive divergence (CD) approximation to the gradient is used by replacing ⟨vihj⟩model
with ⟨vihj⟩recon, which is a lot easier and faster to compute . ⟨vihj⟩recon is computed by setting the visible
units to a random training vector. Then the binary states of
the hidden units are computed using Eqn. 7, followed by
computing the binary states of the visible units using Eqn. 8.
The computed visible states are a ‘reconstruction’ of the
original visible vector. Finally, Eqn. 7 is used once more to
compute the states of the hidden units from the reconstruction.
The new learning rule is a crude approximation to following
the gradient of the log probability of the training data, but it
works well in practice and is adequate for discovering good
Fig. 1. RBM Architecture.
III. LEARNING AND USING DEEP BELIEF NETWORKS
After training the network consisting of the visible layer and
the ﬁrst hidden layer, which we will refer to as RBM1 , its
learned parameters, θ1, deﬁne p(v, h|θ1), p(v|θ1), p(v|h, θ1),
and p(h|v, θ1) via Eqns. 7 and 8. The parameters of RBM1
also deﬁne a prior distribution over hidden vectors, p(h|θ1),
which is obtained by marginalizing over the space of visible
vectors. This allows p(v|θ1) to be written as:
p(h|θ1)p(v|h, θ1)
The idea behind training a DBN by training a stack of RBMs
is to keep the p(v|h, θ1) deﬁned by RBM1, but to improve
p(v) by replacing p(h|θ1) by a better prior over the hidden
vectors. To improve p(v), this better prior must have a smaller
KL divergence than p(h|θ1) from the “aggregated posterior”,
which is the equally weighted mixture of the posterior distributions over the hidden vectors of RBM1 on all N of the
training cases:
p(h|v, θ1)
The analogous statement for Gaussian mixture models is that
the updated mixing proportion of a component should be
closer to the average posterior probability of that component
over all training cases.
Now consider training RBM2, which is the network formed
by using the samples from the aggregated posterior of RBM1
as training data. It is easy to ensure that the distribution which
RBM2 deﬁnes over its visible units is identical to p(h|θ1):
we simply initialize RBM2 to be an upside-down version of
RBM1 in which the roles of visible and hidden units have
been swapped. So RBM2 has h as a visible vector and h2 as
a hidden vector. Then we train RBM2 which makes p(h|θ2)
be a better model of the aggregated posterior than p(h|θ1).
After training RBM2, we can combine the two RBMs to
create a hybrid of a directed and an undirected model. p(h|θ2)
is deﬁned by the undirected RBM2, but p(v|h, θ1) is deﬁned
by directed connections from the ﬁrst hidden layer to the
visible units. In this hybrid model, which we call a deep belief
net, exact inference of p(h|v, θ1, θ2) is no longer easy because
the prior over the hidden vectors is no longer deﬁned by θ1.
However, it is proved in that if we perform approximate
inference for the ﬁrst hidden layer by using Eqn. 7, there is a
variational lower bound on the log probability of the training
data that is improved every time we add another layer to the
DBN, provided we add it in the appropriate way.
IEEE TRANSACTIONS ON AUDIO, SPEECH AND LANGUAGUE PROCESSING
Fig. 2. Stacking RBMs to create a deep network. This architecture is used
in our experiments.
After training a stack of RBMs, the bottom up recognition
weights of the resulting DBN can be used to initialize the
weights of a multi-layer feed-forward neural network, which
can then be discriminatively ﬁne-tuned by backpropagating
error derivatives. The feed-forward network is given a ﬁnal
“softmax” layer that computes a probability distribution over
class labels and the derivative of the log probability of the
correct class is backpropagated to train the incoming weights
of the ﬁnal layer and to discriminatively ﬁne-tune the weights
in all lower layers.
Deep belief networks (DBNs) have yielded impressive
classiﬁcation performance on several benchmark classiﬁcation
tasks, beating the state-of-the-art in several cases . In principle, adding more layers improves modeling power, unless the
DBN already perfectly models the data. In practice, however,
little is gained by using more than about 3 hidden layers. We
use the architecture shown in Fig. III. It has three hidden layers
that are pre-trained, one at a time, as the hidden layers in a
stack of three RBMs without making any use of the class
It is worth mentioning that the softmax output layer of a
neural network is the same as a MaxEnt classiﬁer: in other
words, a neural network is a MaxEnt classiﬁer in which the
feature functions are learned.
IV. TRADITIONAL CLASSIFIERS
A. Maximum Entropy
The Maximum Entropy (MaxEnt) method is a ﬂexible
statistical modeling framework that has been widely used
in many areas of natural language processing . MaxEnt
based classiﬁers do not assume statistical independence of the
features that are used as predictors. As such, they allow the
combination of multiple overlapping information sources ,
 . The information sources are combined as follows:
i λifi(C,W )
j λjfj(C′,W ) ,
which describes the probability of a particular class C (e.g.
call-types) given the word sequence W spoken by the caller.
Notice that the denominator includes a sum over all classes
C′, which is essentially a normalization factor for probabilities
to sum to 1. The fi are indicator functions, or features,
which are “activated” based on computable features on the
word sequence, for example if a particular word or word pair
appears, or if the parse tree contains a particular tag, etc.
The MaxEnt models are trained using the improved iterative
scaling algorithm with Gaussian prior smoothing 
using a single universal variance parameter of 2.0.
B. Boosting
Boosting is a method that can be used in conjunction with
many learning algorithms to improve the accuracy of the
learning algorithm. The idea of Boosting is to produce an accurate prediction rule by combining many moderately inaccurate
(weak) rules into a single classiﬁer. At each iteration, boosing
adds a new (weak) prediction rule that focuses on samples that
are incorrectly classiﬁed by the current combined predictor.
Even though Boosting is known to be sensitive to noisy
data and outliers, in some problems, it is less susceptible to
overﬁtting than most machine learning algorithms. We used a
speciﬁc implementation of Boosting, AdaBoost using decision
stumps, which is described in . Boosting has been applied to
a number of natural language processing tasks in the past .
C. Support Vector Machines
Support vector machines (SVMs) are supervised learning
methods used for classiﬁcation. The basic SVM takes a set
of input data and predicts, for each given input, which of two
possible classes forms the output, making it a non-probabilistic
binary classiﬁer.
SVMs are derived from the theory of structural risk minimization . SVMs learn the boundaries between samples of
the two classes by mapping these sample points into a higher
dimensional space. SVMs construct a hyperplane or a set of
hyperplanes in a high-dimensional space, which can be used
for classiﬁcation. Intuitively, a good separation is achieved
by the hyperplane that has the largest distance to the nearest
training data point of any class (the ”functional margin”), since
in general the larger the margin the lower the generalization error of the classiﬁer. The hyperplane separating these
regions is found by maximizing the margin between closest
sample points belonging to competing classes. In addition to
performing linear classiﬁcation, SVMs can efﬁciently perform
non-linear classiﬁcation using what is called the kernel trick,
implicitly mapping their inputs into high-dimensional feature
spaces. Much of the ﬂexibility and classiﬁcation power of
SVMs resides in the choice of kernel. Some of the commonly
used kernels are linear, polynomial and radial basis functions.
In this work, we chose linear kernels to train the SVM since
computationally it is faster compared to other kernels, yet
there is no signiﬁcant difference in performance for the current
task. This is a fairly standard result for applying SVMs in
natural language processing since we are already using a high–
dimensional feature vector.
V. EXPERIMENTAL RESULTS AND DISCUSSION
The call–routing task considered in this paper is from a
call–center customer hotline that gives technical assistance for
IEEE TRANSACTIONS ON AUDIO, SPEECH AND LANGUAGUE PROCESSING
a Fortune–500 company . The call–routing system selects
one of 35 call–types. The training data has 27K automatically
transcribed utterances amounting to 178K words. This data is
split into sets containing {1K, 2K, 3K, 4K, 5K, 6K, 7K, 8K,
9K, 10K} and 27K utterances respectively. These sets will
be referred to in a similar fashion. The purpose of this split
is to investigate various training data sizes and their effects
on the learning methods. We also have two separate datasets
containing about 3.2K and 5.6K sentences that are used as
development and test data, respectively. All of these datasets
are hand–labeled with call–types. In all the classiﬁcation
methods employed here we used vectors of individual word
counts as the inputs to the models. For the DBNs, the counts
were clipped at 1 to allow them to be modeled by binary units.
In our experiments with the development data we found
that hidden layers of 500 →500 →500 provided slightly
better results than the other hidden layer sizes that we tried.
The model architecture is shown in Fig. III. The individual
RBM models were trained in an unsupervised fashion using
contrastive divergence learning with 1 step of Gibbs sampling
(CD-1). The training phase made 100 passes (epochs) through
the training dataset. The weights of each RBM were initialized
with small random values sampled from a zero-mean normal
distribution with standard deviation 0.01 and updated using
a learning rate of 0.01/batch-size, momentum of 0.9, and a
weight decay of 0.001.
For the discriminative ﬁne-tuning, we use stochastic gradient descent (SGD) and we also set the number of iterations
by using early stopping according to the validation set classi-
ﬁcation error. To reduce computation time, we select the SGD
learning rate, momentum parameter and other parameters by
maximizing the accuracy on the development set.
In Table I, we present the results on the test data for
SVMs, MaxEnt, Boosting and DBNs. Various classiﬁer parameters (e.g. smoothing priors for MaxEnt learning, and
kernel selection for SVMs) are tuned on the development
data. Each classiﬁer is trained using the amount of labeled
data given in the ﬁrst column. Looking ﬁrst at the traditional
classiﬁers, we notice that the SVM classiﬁer obtained 77.8%
accuracy using 1K labeled data. The corresponding ﬁgures
for the MaxEnt classiﬁer and the Boosting based classiﬁer
are 76.0% and 79.6% respectively. Not only for 1K labeled
data but also for 2K and 3K data, Boosting provides the
best performance. However, for larger amounts of training
data, the SVM consistently outperformed both MaxEnt and
Boosting, which is in agreement with other studies . The
DBN (4th column) performed as well as or slightly better than
SVMs for all sizes of training set. When trained on all of the
training data, they had identical performance, achieving 90.3%
In this paper we pursued two of the three future research
directions suggested in . The ﬁrst extension was using
additional unlabeled data to train the RBMs, since typically
there is a lot more unlabeled data available than labeled data.
In our experiments, for smaller chunks of labeled data, the
entire 27K labeled data is treated as unlabeled data to train the
DBN. For example, when 1K labeled data is used to train the
DBN, we used 27K to train the corresponding RBMs. We have
Fig. 3. Stacked RBMs (see Fig. 2) are ﬁrst trained using labeled and unlabeled
data and then the learned parameters are used to obtain higher level features.
These higher level features in conjunction with original input feature vector are
used to train a SVM classiﬁer. This classiﬁer is then used during evaluation.
repeated the same steps with different amounts of labeled data
given in Table I. The second direction of research was to treat
the DBN as a feature extractor and use these features as input
to a separate classiﬁer. We ﬁrst trained a DBN and then for
each utterance, we generated the activity at the top layer. This
activity along with the original features were concatenated and
used as input to an SVM classiﬁer. Fig. 3 shows the schematics
of the setup.
We provided additional experimental results for three scenarios: a) using additional unlabeled data to train the RBMs
(DBN-1) , b) using DBN learned features as input additional
features to SVM classiﬁer (DBN-2), and c) combining the
previous two scenarios (DBN-3). Using additional unlabeled
data provided large gains when the ratio of unlabeled to
labeled data size is large, as shown in the column of DBN-1
column in Table I. For example, when we have 27K unlabeled
data to train RBMs but only 2K labeled data to ﬁne tune the
DBNs the gain is 1.1%. Likewise, when the labeled data is
3K the gain is 0.9%. However, as the ratio of the labeled
data to unlabeled data gets larger we do not observe gains
from using additional unlabeled data. We note that the amount
of unlabeled data considered here is fairly small. In many
applications however, the amount of unlabeled data can be
substantially larger than the labeled data. It is one of our future
research work directions to investigate using substantially
larger amounts of unlabeled data to train RBMs in a separate
application.
In the table we also show feature combination results where
DBN learned features are combined with the original features
(DBN-2) as input to an SVM classiﬁer. The results indicate
that we get consistent gains when DBN based features are
combined with the original features across all labeled data
sizes. Finally, we combine DBN based features where RBMs
are trained with large (relative to the labeled data) collection
IEEE TRANSACTIONS ON AUDIO, SPEECH AND LANGUAGUE PROCESSING
Action Classiﬁcation Accuracy (%)
Labeled Data
PACKAGE SHIPMENT TASK: ACCURACY FOR TRADITIONAL AND DBN BASED CLASSIFIERS.
of unlabeled data with the original features using an SVM
classiﬁer. This set-up is called DBN-3 and the results are given
in the last column of Table I. The results show that DBN-
3 improves the call routing performance consistently across
all data sizes with the exception of the 1K data size where
Boosting performs better. For smaller amounts of labeled
data the performance improvements over SVM are signiﬁcant.
For example, 0.8%, 1.9% , 1.2%, 1.3% and 1.2% absolute
improvements are obtained for 1K through 5K labeled data
amounts. The improvements were smaller but consistent all
the way to 27K labeled data. The performance gains are
coming largely from using unlabeled data, which is used to
train RBMs, when the labeled data size is small. The results
indicate that gains for DBN-1 and DBN-2 are approximately
We also investigate whether binarization of the features
for DBNs give them an advantage by also testing the SVM
classiﬁer with binarized word count features. The n–gram
features are formed based on the existence of these features
regardless of the actual counts that they are observed in the
sentence. There are about 15% of the sentences that had n–
gram features of count two or more. However, classiﬁcation
results across all data sizes show that the feature binarization
did not change the SVM performance (the changes were in
the second decimal).
VI. CONCLUSION AND FUTURE WORK
This work presented a successful application of Deep Belief
Nets (DBNs) to a natural language call–routing task. DBNs
use unsupervised learning to discover multiple layers of features that are then used in a feed–forward neural network
and ﬁne–tuned to optimize discrimination. When the amount
of training data is limited, unsupervised feature discovery
makes DBNs less prone to overﬁtting than feedforward neural
networks initialized with random weights, and it also makes
it easier to train neural networks with many hidden layers.
DBNs produce better classiﬁcation results than several other
widely used learning techniques, outperforming Maximum
Entropy and Boosting based classiﬁers. Their performance is
almost identical to SVMs, which are the best of the other
techniques that we investigated.
We further extended our initial work by treating DBNs
as feature generators to capture and model the underlying
structure in the input data. The learned features are used
in conjunction with the original inputs to do classiﬁcation
using an SVM. We also leveraged additional unlabeled data to
improve the modeling performance. Both of these extensions
resulted in additional improvement in call–routing classiﬁcation performance. In the future, we plan to consider DBNs
for sequence tagging for slot detection and entity tagging in
spoken language understanding.