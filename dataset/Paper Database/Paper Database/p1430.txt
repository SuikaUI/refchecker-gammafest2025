The Design and Implementation of XiaoIce,
an Empathetic Social Chatbot
Beijing, China
 
Jianfeng Gao
Microsoft Research
Redmond, WA, USA
 
Beijing, China
 
Heung-Yeung Shum
Redmond, WA, USA
 
This paper describes the development of Microsoft XiaoIce, the most popular
social chatbot in the world. XiaoIce is uniquely designed as an AI companion with
an emotional connection to satisfy the human need for communication, affection,
and social belonging. We take into account both intelligent quotient (IQ) and
emotional quotient (EQ) in system design, cast human-machine social chat as
decision-making over Markov Decision Processes (MDPs), and optimize XiaoIce
for long-term user engagement, measured in expected Conversation-turns Per
Session (CPS). We detail the system architecture and key components including
dialogue manager, core chat, skills, and an empathetic computing module. We
show how XiaoIce dynamically recognizes human feelings and states, understands
user intent, and responds to user needs throughout long conversations. Since the
release in 2014, XiaoIce has communicated with over 660 million active users and
succeeded in establishing long-term relationships with many of them. Analysis
of large-scale online logs shows that XiaoIce has achieved an average CPS of
23, which is signiﬁcantly higher than that of other chatbots and even human
conversations.
Introduction
The development of social chatbots, or intelligent dialogue systems that are able to engage in empathetic conversations with humans, has been one of the longest running goals in Artiﬁcial Intelligence
(AI). Early conversational systems, such as Eliza Weizenbaum , Parry Colby et al. ,
and Alice Wallace , were designed to mimic human behavior in a text-based conversation,
hence to pass the Turing Test within a controlled scope. Despite impressive successes, these systems
were mostly based on hand-crafted rules and worked well only in constrained environments. An
open-domain social chatbot remains an elusive goal until recently. Lately we have been witnessing
promising results in both the academic research community and industry as large volumes of conversational data become available, and breakthroughs in machine learning are applied to conversational
AI. Recent surveys include Gao et al. , Shum et al. .
In this paper we present the design and implementation of Microsoft XiaoIce (“Little Ice” literally
in Chinese), the most popular social chatbot in the world. Since her launch in China in May 2014,
XiaoIce has attracted over 660 million active users (i.e., subscribed users). XiaoIce has already been
shipped in ﬁve countries (China, Japan, USA, India and Indonesia) under different names (e.g. Rinna
 
 
Figure 1: A sample of conversation sessions between a user and XiaoIce in Chinese (right) and
English translation (left), showing how an emotional connection between the user and XiaoIce has
been established over a 2-month period. When the user encountered the chatbot for the ﬁrst time
(Session 1), he explored the features and functions of XiaoIce in conversation. Then, in 2 weeks
(Session 6), the user began to talk with XiaoIce about his hobbies and interests (a Japanese manga).
By 4 weeks (Session 20), he began to treat XiaoIce as a friend and asked her questions related to his
real life. After 7 weeks (Session 42), the user started to treat XiaoIce as a companion and talked to her
almost every day. After 2 more weeks (Session 71), XiaoIce became his preferred choice whenever
he needed someone to talk to .
in Japan) on more than 40 platforms, including WeChat, QQ, Weibo and Meipai in China, Facebook
Messenger in USA and India, and LINE in Japan and Indonesia.
The primary design goal of XiaoIce is to be an AI companion with which users form long-term,
emotional connections. Being able to establish such long-term relationships with human users as an
open-domain social chatbot distinguishes XiaoIce from not only early social chatbots but also other
recently developed conversational AI personal assistants such as Apple Siri, Amazon Alexa, Google
Assistant and Microsoft Cortana.
Figure 1 shows how an emotional connection between a user and XiaoIce has been established over a
2-month period. When the user encountered the chatbot for the ﬁrst time (Session 1), he explored the
features and functions of Xiaoice in conversation. Then, in less than 2 weeks (Session 6), the user
began to talk with XiaoIce about his hobbies and interests (a Japanese manga). By 4 weeks (Session
20), he began to treat XiaoIce as a friend and asked her questions related to his real life. After 7
weeks (Session 42), the user started to treat XiaoIce as a companion and talked to her almost every
day. After 2 more weeks (Session 71), XiaoIce became his preferred choice whenever he needed
someone to talk to.
XiaoIce is developed on an empathetic computing framework Cai , Fung et al. that
enables the machine (social chatbot in our case) to recognize human feelings and states, understand
user intents and respond to user needs dynamically. XiaoIce aims to pass a particular form of the
Turing Test known as the time-sharing test, where machines and humans coexist in a companion
system with a time-sharing schedule. If a person enjoys its companionship (via conversation), we can
call the machine “empathetic”.
In the remainder of the paper, we present the details of the design and implementation of XiaoIce. We
start with the design principle and mathematical formulation. Then we show the system architecture
and how we implement key components including dialog manager, core chat, important skills
and an empathetic computing module, presenting a separate evaluation of each component where
appropriate. We will show how XiaoIce has been doing in ﬁve countries since its launch in May,
2014, and conclude this paper with some discussions of future directions.
Design Principle
Social chatbots require a sufﬁciently high IQ to acquire a range of skills to keep up with the users and
help them complete speciﬁc tasks. More importantly, social chatbots also require a sufﬁcient EQ to
meet users’ emotional needs, such as emotional affection and social belonging, which are among
the fundamental needs for human beings Maslow . Integration of both IQ and EQ is core to
XiaoIce’s system design. XiaoIce is also unique in her personality.
IQ + EQ + Personality
IQ capacities include knowledge and memory modeling, image and natural language understanding,
reasoning, generation and prediction. These are fundamental to the development of dialogue skills.
They are indispensable for a social chatbot in order to meet users’ speciﬁc needs and help users
accomplish speciﬁc tasks. Over the last 5 years XiaoIce has developed more than 230 skills, ranging
from answering questions and recommending movies or restaurants to comforting and storytelling.
The most important and sophisticated skill is Core Chat, which can engage long and open-domain
conversations with users.
EQ has two key components, empathy and social skills. Empathy is the capability of understanding
or feeling what another person is experiencing from within her frame of reference, i.e., the ability to
place oneself in the other person’s position. A social chatbot with empathy needs to have the ability
to identify the user’s emotions from the conversation, detect how the emotions evolve over time, and
understand the user’s emotional needs. This requires query understanding, user proﬁling, emotion
detection, sentiment recognition, and dynamically tracking the mood of the user in a conversation.
A social chatbot must demonstrate enough social skills. Users have different backgrounds, varied
personal interests, and unique needs. A social chatbot needs to have the ability to personalize the
responses (i.e., interpersonal responses) that are emotionally appropriate, possibly encouraging and
motivating, and ﬁt the interests of the user. As shown in Figure 2, XiaoIce demonstrates sufﬁcient
EQ as it generates socially acceptable responses (e.g., having a sense of humor, comforting, etc.),
and can determine whether to drive the conversation to a new topic when e.g., the conversation has
stalled, or whether or not to be actively listening when the user herself is engaged in the conversation.
Personality is deﬁned as the characteristic set of behaviors, cognition and emotional patterns that
form an individual’s distinctive character. A social chatbot needs to present a consistent personality
to set the right expectations for users in the conversation and gain their long-term conﬁdence and
trust. The design of the XiaoIce persona needs to not only align with the primary design goal of
XiaoIce as an AI companion with which users form long-term, emotional connections, but also
take into account culture differences and many sensitive ethical questions as exempliﬁed in Curry
and Rieser , Schmidt and Wiegand , Brahnam . Thus, for different platforms
Figure 2: Conversation between a user and the XiaoIce chitchat system in Japanese (midden) and
English translation (left). The empathy model provides a context-aware strategy that can drive the
conversation when needed (right). For example, XiaoIce determines to ’drive’ the conversation to
a new topic when the conversation has stalled in Turn 3, and to be actively listening when the user
herself is engaged in the conversation in Turns 4 and 7.
deployed in different regions, we design different personas guided by large-scale analysis on human
conversations. Take the XiaoIce persona designed for WeChat deployed in China as an example. We
have collected human conversations of millions of users, and labeled each user as having a “desired”
persona or not depending on whether his or her conversations contain inappropriate requests or
responses that contain swearing, bullying, etc. Our ﬁnding is that the majority of the “desired” users
are young, female users. Therefore, we design the XiaoIce persona as a 18-year-old girl who is always
reliable, sympathetic, affectionate, and has a wonderful sense of humor. Despite being extremely
knowledgeable due to her access to large amounts of data and knowledge, XiaoIce never comes
across as egotistical and only demonstrates her wit and creativity when appropriate. As shown in
Figure 1, XiaoIce responds sensibly to some sensitive questions (e.g., Session 20), and then skillfully
shifts to new topics that are more comfortable for both parties. As we are making XiaoIce an open
social chatbot development platform for third-parties, the XiaoIce persona will be conﬁgurable based
on speciﬁc user scenarios and cultures.
Social Chatbot Metric: CPS
Unlike task-oriented bots where their performance is measured by task success rate, measuring the
performance of social chatbots is difﬁcult Shawar and Atwell . In the past, the Turing Test
has been used to evaluate chitchat performance. But it is not sufﬁcient to measure the success of
long-term, emotional engagement with users. In addition to the Number of Active Users (NAU),
we propose to use expected Conversation-turns Per Session (CPS) as the success metric for social
chatbots. It is the average number of conversation-turns between the chatbot and the user in a
conversational session. The larger the CPS is, the better engaged the social chatbot is.
It is worth noting that we optimize XiaoIce for expected CPS which corresponds to long-term, rather
than short-term, engagement. In our evaluation, the expected CPS is approximated by averaging the
CPS of human-XiaoIce conversations collected from millions of active users over a long period of
time (typically 1-6 months). The evaluation methodology eliminates many possibilities of gaming the
metric. For example, some recent studies Fang et al. , Li et al. [2016c] show that encompassing
bland but interactive responses such as "I don’t understand, what do you mean?" can sometimes
increase the CPS of the ongoing human-machine conversation. But this hurts the CPS and NAU in
the long run since few users are willing to talk (again) to a bot who always gives bland responses
no matter how interactive these responses are, not to mention establishing long-term, emotional
connections. In contrast, incorporating many task-completion skills often reduces the CPS in the
short term since these skills help users accomplish tasks more efﬁciently by minimizing the CPS.
But these skills establish XiaoIce as an efﬁcient personal assistant and more importantly trustworthy
personal companion, thus strengthening the emotional bond with human users in the long run.
Figure 3: A multi-segment conversation between a user and XiaoIce in Chinese (right) and English
translation (left). XiaoIce starts with a casual chat using the General Chat skill in Turn 1, switches to
a new topic on music using Music Chat in Turn 4, recommends a song using the Song-On-Demand
skill in Turn 15, and helps book a concert ticket using the Ticket-Booking skill in Turn 18.
We will present the CPS of XiaoIce of different generations in Section 5, and discuss CPS and other
evaluation metrics in more detail in Sections 4 and 7.
Social Chat as Hierarchical Decision-Making
To fulﬁll these design objectives, we mathematically cast human-machine social chat as a hierarchical
decision-making process, and optimize XiaoIce for long-term user engagement, measured in expected
As shown in Figure 3, XiaoIce tries to maintain user interest by promoting diversity of conversation
modes. Each conversation mode is managed by a skill that handles a speciﬁc type of conversation
segment. For example, XiaoIce starts with a casual chat using the General Chat skill in Turn 1,
switches to a new topic on music using Music Chat in Turn 4, recommends a song using the Song-
On-Demand skill in Turn 15, and helps book a concert ticket using the Ticket-Booking skill in Turn
The dialogue in Figure 3 can be viewed as a decision-making process with a natural hierarchy:
a top-level process manages the overall conversation and selects skills to handle different types
of conversation modes (e.g., chatting casually, question answering, ticket booking), and a lowlevel process, controlled by the selected skill, chooses primitive actions (responses) to generate a
conversation segment or complete a task.
Such hierarchical decision-making processes can be cast in the mathematical framework of options
over Markov Decision Processes (MDPs) [Sutton et al., 1999], where options generalize primitive
actions to higher-level actions. A social chatbot navigates in a MDP, interacting with its environment
(human users) over a sequence of discrete dialogue turns. At each turn, the chatbot observes the
Figure 4: XiaoIce system architecture.
current dialogue state, and chooses a skill (option) or a response (primitive action) according to a
hierarchical dialogue policy. The chatbot then receives a reward (from user responses) and observes a
new state, continuing the cycle until the dialogue terminates. The design objective of the chatbot is to
ﬁnd optimal policies and skills to maximize the expected CPS (rewards).
The formulation of dialogue as a hierarchical decision-making process guides the design and implementation of XiaoIce. XiaoIce uses a dialogue manager to keep track of the dialogue state, and
at each dialogue turn, select how to respond based on a hierarchical dialogue policy. To maximize
long-term user engagement, measured in expected CPS, we take an iterative, trial-and-error approach
to developing XiaoIce, and always try to balance the exploration-exploitation tradeoff. We exploit
what is already known to work well to retain XiaoIce’s active users, but we also have to explore
what is unknown (e.g., new skills and dialogue policies) in order to engage with the same users more
deeply or attract new users in the future. In Figure 3, XiaoIce tries a new topic (i.e., a popular singer
named Ashin) in Turn 5 and recommends a song in Turn 15, and thereby learns the user’s preferences
(e.g., the music topic and the singer he loves), knowledge that would lead to more engagement in the
System Architecture
The overall architecture of XiaoIce is shown in Figure 4. It consists of three layers: user experience,
conversation engine and data.
• User experience layer: This layer connects XiaoIce to popular chat platforms (e.g., WeChat,
QQ), and communicates with users in two modes: full-duplex and taking turns. The fullduplex mode handles voice-stream-based conversations where a user and XiaoIce can talk
to each other simultaneously. This mode is mainly used for the XiaoIce systems deployed
on smart devices. The other mode deals with message-based conversations where a user
and XiaoIce take turns to talk. This layer also includes a set of components used to process
user inputs and XiaoIce responses e.g., image understanding and text normalization, speech
recognition and synthesis, voice activity detecting to distinguish user input from background
noise, voice classiﬁer to identify the age and gender of the user, and a talking-to-bot classiﬁer
to distinguish if a user is talking to the bot or other human users.
• Conversation engine layer: This is composed of a dialogue manager, an empathetic
computing module, Core Chat and dialogue skills. The dialogue manager keeps track of
the dialogue state, selects either a dialogue skill or Core Chat 1 using the dialogue policy to
generate responses. The empathetic computing module is designed to understand not only
the content of the user input (e.g., topic) but also the empathetic aspects of the dialogue
1Although Core Chat is by deﬁnition a dialogue skill, we single it out by referring to it as Core Chat directly
due to its importance and sophisticated design, and refer to other dialogue skills as skills.
and the user (e.g., emotion, intent, opinion on topic, and the user’s background and general
interests). It reﬂects XiaoIce’s EQ and demonstrates XiaoIce’s social skills to ensure the
generation of interpersonal responses that ﬁt XiaoIce’s personality. XiaoIce’s IQ is shown
by a collection of speciﬁc skills and Core Chat.
• Data layer: This consists of a set of databases that store collected human conversational
data (in text pairs or text-image pairs), non-conversational data and knowledge graphs used
by Core Chat and skills, and the proﬁles of XiaoIce and all her active users.
Implementation of Conversation Engine
This section describes four major components in the conversation engine layer: dialogue manager,
empathetic computing, Core Chat, and skills.
Implementation of the conversation engine relies heavily on A/B test to evaluate if a new module or a
new dialogue skill is going to improve an existing component. This is possible because XiaoIce has
attracted a large number of active users since her launch in 2014. The metrics we commonly use for
A/B test include expected CPS and NAU. In addition, we ask users to give explicit feedback when a
new module or a new dialogue skill is being tested. When working on the modules or tasks where
there are benchmarks used in the research community, such as the neural response generator (Section
4.3), we often compare our approaches to other state-of-the-art methods using these benchmarks.
Dialogue Manager
Dialogue Manager is the central controller of the dialogue system. It consists of the Global State
Tracker that is responsible for keeping track of the current dialogue state s, and Dialogue Policy π
that selects an action based on the dialogue state as a = π(s). The action can be either a skill or
Core Chat activated by the top-level policy to respond to the user’s speciﬁc request, or a response
suggested by a skill-speciﬁc low-level policy.
Global State Tracker
Global State Tracker maintains a working memory to keep track of the dialogue state. The working
memory is empty at the beginning of each dialogue session, and then stores at each dialogue turn the
user utterance and XiaoIce’s response as text strings, together with the entities and empathy labels
detected from the text by the empathetic computing module, which will be described in Section 4.2.
The information in the working memory is encoded into dialogue state vector s.
Dialogue Policy
As described in Section 2.3, XiaoIce uses a hierarchical policy: (1) the top-level policy manages the
overall conversation by selecting, at each dialogue turn, either Core Chat or a skill to activate based
on the dialogue state; and (2) a set of low-level policies, one for each skill, to manage its conversation
The dialogue policy is designed to optimize long-term user engagement through an iterative, trialand-error process based on the feedback of XiaoIce’s users. The high-level policy is implemented
using a set of skill triggers. Some of the triggers are based on machine learning models such as the
Topic Manager, the Domain Chat triggers. The others are rule-based, such as those that trigger the
skills by keywords. The low-level policies of the Core Chat skills are implemented using hybrid
response generation engines, as to be described in Section 4.3, and the low-level policies of the other
skills (e.g., the task completion and deep engagement skills in Figure 4) are hand-crafted.
The high-level policy works as follows.
• If the user input is text (including speech-converted text) only, Core Chat is activated. Topic
Manager, which will be introduced in Section 4.1.3, is designed to manage the dialogue
segment of Core Chat by deciding whether to switch to a new topic or switch from the
General Chat skill to a speciﬁc Domain Chat skill if the user’s interest in a particular topic
or domain is detected.
• If the user input is an image or a video clip, the Image Commenting skill is activated.
• The skills of Task Completion, Deep Engagement and Content Creation are triggered by
speciﬁc user inputs and conversation context. For example, a picture of food shared by a
user can trigger the Food Recognition and Recommendation skill as shown in Figure 17 (a),
an extremely negative sentiment detected from user input can trigger the Comforting skill as
shown in Figure 17 (b), and a special user command such as “XiaoIce, what is the weather
today” can trigger the Weather skill as shown in Figure 19 (a). If multiple skills are triggered
simultaneously, we select the one to activate based on their triggering conﬁdence scores,
pre-deﬁned priorities and the session context. To ensure a smooth conversation, we avoid
switching among different skills too often. We prefer keeping the running skill activated
until it terminates to activating a new skill. This is similar to the way sub-tasks (i.e., skills)
are managed in composite-task completion bots Peng et al. .
We will discuss the low-level policies in the later sections where the individual dialogue skills are
described.
Topic Manager
Topic Manager simulates human behavior of changing topics during a conversation. It consists
of a classiﬁer for deciding at each dialogue turn whether or not to switch topics, and a topic
recommendation engine for suggesting a new topic.
Topic switching is triggered if XiaoIce does not have sufﬁcient knowledge about the topic to engage
in a meaningful conversation, or the user is getting bored. The classiﬁer of topic switching is
implemented using a boosted tree that incorporates the following indicator features.
• Whether an editorial response is used due to Core Chat failing to generate any valid response
candidate, as will be described in Section 4.3.
• Whether the generated response simply repeats the user inputs, or contains no new information.
• Whether the user inputs are getting bland, e.g., “OK”, “I see”, “go on”.
The topic recommendation engine consists of a topic ranker, and a topic database which is constructed
by collecting popular topics and related comments and discussions from high-quality Internet forums,
such as Instagram in US and douban.com in China. The topic database is updated periodically. When
topic switching is triggered, a list of topic candidates is retrieved from the database using the current
dialogue state, which is generated using the empathetic computing module (Section 4.2), as query.
The top-ranked candidate topic is chosen as the new topic. The topic ranker is implemented using a
boosted tree ranker that uses the following features.
• Contextual relevance: the topic needs to be related to the dialogue, but has not been discussed
• Freshness: the topic, especially if it is related to news, needs to be fresh and valid for the
time being.
• Personal interests: the user is likely to be interested in the topic, according to the user proﬁle.
• Popularity: the topic has gained enough attention on the Internet or among XiaoIce users.
• Acceptance rate: the rate of the topic being accepted by XiaoIce users is historically high.
Evaluation
Both the topic switching classiﬁer and the topic ranker are trained using 50K dialogue
sessions whose topics are manually labeled. Our A/B test over a 1-month period shows that incorporating topic manager improves the expected CPS of Core Chat by 0.5. As shown in the example in
Figure 3, XiaoIce switches to a new but related topic (i.e., a song titled “the time machine” by Ashin
in Turn 13) when she detects that the user is not familiar with “Ashin” and about to terminate the
conversation by responding “Ah! Boring” and “Okay, I am going to bed”.
Empathetic Computing
Empathetic computing reﬂects XiaoIce’s EQ and models the empathetic aspects of the humanmachine conversation. Given user input query Q, empathetic computing takes its context C into
Figure 5: An example conversation session (from Figure 3), where the empathetic computing module
is used to (a) rewrite user queries into contextual queries as indicated by the arrows, (b) generate the
query empathy vector eQ in Turn 11, and (c) generate the response empathy vector eR for Turn 11.
account and rewrites Q to its contextual version Qc, encodes the user’s feelings and states in the
conversation with query empathy vector eQ, and speciﬁes the empathetic aspects of the response R
with response empathy vector eR. The output of the empathetic computing module is represented as
dialogue state vector s = (Qc, C, eQ, eR), which is the input to both Dialogue Policy for selecting a
skill, and the activated skill (e.g., Core Chat) for generating interpersonal responses that ﬁt XiaoIce’s
persona – a 18-year-old girl who is always reliable, sympathetic, affectionate, knowledgeable but
self-effacing, and has a wonderful sense of humor.
The empathetic computing module consists of three components: contextual query understanding,
user understanding and interpersonal response generation. Figure 5 shows an example of how the
module controls the empathetic aspects of the conversation in Figure 3.
Contextual Query Understanding (CQU)
CQU rewrites Q to Qc using contextual information
in C in the following steps.
• Named entity identiﬁcation: We label all entity mentions in Q, link them to the entities
stored in the working memory of the state tracker, and store new entities in the working
• Co-reference resolution: We replace all pronouns with their corresponding entity names.
• Sentence completion: If Q is not a complete sentence, we complete it using contextual
information C.
As shown in Figure 5 (a), CQU rewrites user queries to include necessary context, e.g., replacing
“him” in Turn 12 with “Ashin”, “that” with “The Time Machine” in Turn 14, and adding “send
The Time Machine” in Turn 15. These contextual queries are used e.g., by Core Chat to generate
responses via either a retrieval-based engine or a neural response generator, which will be described
in Section 4.3.
User Understanding
This component generates query empathy vector eQ based on Qc and C. eQ
consists of a list of key-value pairs representing the user’s intents, emotions, topics, opinions and the
user’s persona, as shown in Figure 5 (b). These key-value pairs are generated using a set of machine
learning classiﬁers as follows.
• Topic detection labels whether the user follows the same topic, or introduces a new topic.
The set of topics is pre-compiled in the topic database of Topic Manager.
• Intent detection labels Qc using one of 11 dialogue acts e.g., greet, request, inform, etc.
• Sentiment analysis detects user’s emotion of 5 types, e.g., happy, sad, angry, neural, and
how her emotion evolves during the conversation, e.g., from happy to sad.
• Opinion detection detects user’s reaction to the topic, i.e., positive, negative or neural.
• If the user ID is available, include in eQ the user persona vector according to her proﬁle,
e.g., gender, age, interests, occupation, personality etc.
Interpersonal Response Generation
This component generates response empathy vector eR that
both speciﬁes the empathetic aspects of the response to be generated and embodies XiaoIce’s persona.
For example, eR in Figure 5 (c) indicates that XiaoIce shares the feeling of the user by following the
same topic (decided by Topic Manager), responding in a consistent and positive way as speciﬁed e.g.,
by the values of intent, sentiment and opinion etc. in eR which are computed based on those in eQ
using a set of heuristics. The response must also ﬁt XiaoIce’s persona whose key-value pairs, such as
age, gender and interests, are extracted from the pre-compiled XiaoIce proﬁle. We will describe how
eQ and eR are used for response generation in Section 4.3.
Evaluation
The empathetic computing module consists of a set of classiﬁers. We use the off-theshelf named entity recognizer for identifying 15 types of named entities and co-reference resolution
engine without retraining for CQU, and train a group of classiﬁers for user understanding (i.e., topic
detection, intent detection, opinion detection and sentiment analysis) using 10K manually labeled
dialogue sessions. The effectiveness of the empathetic computing module is veriﬁed in the A/B
test on Weibo users. Although we do not observe any signiﬁcant change in CPS, NAU is increased
from 0.5 million to 5.1 million in 3 months. The module was released in July 2018, and became the
most important feature in the 6th generation of XiaoIce that has substantially strengthened XiaoIce’s
emotional connections to human users and increased XiaoIce’s NAU.
Core Chat is a very important component of XiaoIce’s IQ and EQ. Together with the empathetic
computing module, Core Chat provides the basic communication capability by taking the text input
and generating interpersonal responses as output. Core Chat consists of two parts, General Chat
and a set of Domain Chats. General Chat is responsible for engaging in open-domain conversations
that cover a wide range of topics. Domain Chats are responsible for engaging in deep conversations
on speciﬁc domains such as music, movie and celebrity. Since General Chat and Domain Chats
are implemented using the same engine with access to different databases (i.e., general vs. domainspeciﬁc paired, unpaired databases and neural response generator), we only describe General Chat
General Chat is a data-drive response generation system. It takes as input dialogue state s =
(Qc, C, eQ, eR), and outputs response R in two stages: response candidate generation and ranking.
The response candidates can be retrieved from the databases which consist of human-generated
conversations or texts, or generated on the ﬂy by a neural response generator. The query and response
Figure 6: RNN-based neural response generator. Given the user query “You like Ashin that much”,
the response candidate “why not?” is generated.
empathy vectors, eQ and eR, are used for both candidate generation and ranking to ensure that the
generated response is interpersonal and ﬁts XiaoIce’s persona. In what follows, we describe three
candidate generators and the candidate ranker.
Retrieval-Based Generator using Paired Data
The paired database consists of query-response
pairs collected from two data sources. First is the human conversational data from the Internet, e.g.,
social networks, public forums, bulletin boards, news comments etc. After the launch of XiaoIce
in May 2014, we also started collecting human-machine conversations generated by XiaoIce and
her users, which amounted to more than 30 billion conversation pairs as of May 2018. Nowadays,
70% of XiaoIce’s responses are retrieved from her own past conversations. To control the quality
of the database, especially for the data collected from the Internet, we convert each pair to a
tuple (Qc, R, eQ, eR) using the empathetic computing module based on information extracted from
dialogue context, metadata of the webpage and website where the pair is extracted, and the user proﬁle
(if the subscribed user’s identity is available). Then, we ﬁlter the pairs based on their tuples, and retain
only the conversation pairs that contain empathetic responses that ﬁt XiaoIce’s persona. We also
remove the pairs which contain personally identiﬁable information (PII), messy code, inappropriate
content, spelling mistakes, etc.
The ﬁltered paired database is then indexed using Lucene2. At runtime, we use Qc in s as query to
retrieve up to 400 response candidates using keyword search and semantic search based on machine
learning representations of the paired database [Zhang et al., 2016, Wu et al., 2016].
Although the response candidates retrieved from the paired database is of high quality, the coverage is
low because many new or less frequently discussed topics on the Internet forums are not included in
the database. To increase the coverage, we introduce two other candidate generators described next.
Neural Response Generator
Unlike the retrieval-based generator, the neural response generator
is trained using the paired database to learn to simulate human conversations, and is able to generate
responses for any topics including those that are unseen in human conversational data, so that a
user can chat about any topic she likes. Neural-model-based and retrieval-based generators are
complementary: the neural-model-based generator offers robustness and high coverage, while the
2 
Figure 7: (Left) Examples of inconsistent responses generated using a seq2seq model (S2S-Bot)
which is not grounded in persona Li et al. [2016b]. (Right) Examples of consistent and humorous
responses generated using the neural response generator of XiaoIce.
retrieval-based provides high-quality responses for popular topics. Neural response generation is a
very active research topic in the conversational AI community [Gao et al., 2019]. Its role in developing
social chatbots is becoming increasingly important as its performance keeps improving.
The neural response generator in XiaoIce follows the sequence-to-sequence (seq2seq) framework
Sutskever et al. , Cho et al. used for conversation response generation Sordoni et al.
 , Vinyals and Le , Shang et al. , Li et al. [2016a,b], Serban et al. , Xing
et al. .
The generator is based on a GRU-RNN model, similar to the Speaker-Addressee model Li et al.
[2016b]. Given input (Qc, eQ, eR), we wish to predict how XiaoIce (the addressee) modeled by
eR would respond to query Qc produced by the user (speaker) modeled by eQ. As illustrated in
Figure 6, we ﬁrst obtain an interactive representation v ∈Rd by linearly combining query and
response empathy vectors eQ and eR in an attempt to model the interactive style of XiaoIce towards
where WQ, WR ∈Rk×d and σ denotes the sigmoid function. Then the source RNN encodes user
query Qc into a sequence of hidden state vectors which are then fed into the target RNN to generate
response R word by word. Each response ends with a special end-of-sentence symbol EOS. We use
beam search to generate up to 20 candidates. As illustrated in Figure 6, for each step t on the target
RNN side, the hidden state ht is obtained by combining the hidden state produced at the previous
step ht−1, the embedding vector of the word at the current time step et, and v. In this way, empathy
information is injected into the hidden layer at each time step to help generate interpersonal responses
that ﬁt XiaoIce’s persona throughout the generation process. As shown in Figure 7, while a typical
seq2seq model which is not grounded in any persona often outputs inconsistent responses Li et al.
[2016b], XiaoIce is able to generate consistent and humorous responses.
For completeness, we give a detailed description of the model. Let ut and zt denote the update and
reset gates of GRU, respectively, which associate with time step t. Then, the hidden state ht of the
GRU-RNN for each time step t is computed as follows:
u [ht−1; et; v])
z [ht−1; et; v])
lt = tanh(W⊤
l [zt ◦ht−1; et; v])
t = (1 −ut) ◦ht−1 + ut ◦lt
where Wu, Wz, Wl ∈R3d×d are machine learned matrices, and ◦denotes the element-wise product.
The RNN model deﬁnes the probability of next token in R to predict using the softmax function:
p(R|Qc, eQ, eR) =
p(rt|Qc, eQ, eR, r1, r2, ..., rt−1)
exp(f(ht−1, ert, v))
r′ exp(f(ht−1, er′, v)) .
where f(ht−1, ert, v) denotes the activation function between ht−1, ert and v, where ht−1 is the
representation output from the RNN at time t −1. Each response ends with a special end-of-sentence
symbol EOS.
The parameters of the response generation model θ = (WQ, WR, Wu, Wz, Wl) are trained to
maximize the log likelihood on training data, using stochastic gradient descent, as
log pθ(R(i)|Q(i)
Retrieval-Based Generator using Unpaired Data
In addition to the conversational (or paired)
data used by the above two response generators, there is a much larger amount of non-conversational
(or unpaired) data, which can be used to improve the coverage of the response.
The unpaired database we have used in XiaoIce consists of sentences collected from public lectures
and quotes in news articles and reports. These sentences are considered candidate responses R. Since
we know the authors of these sentences, we compute for each its empathy vector eR. A data ﬁltering
pipeline, similar to that for paired data, is used to retain only the responses (R, eR) that ﬁt XiaoIce’s
Like the paired database, the unpaired database is indexed using Lucene. Unlike the paired database,
at runtime we need to expand query Qc to include additional topics to avoid retrieving those responses
that simply repeat what a user just said. We resort to a knowledge graph (KG) for query expansion.
The KG consists of a collection of head-relation-tail triples (h, r, t), and is constructed by joining
the paired database and Microsoft Satori 3. We include in the XiaoIce KG a Satori triple (h, r, t)
only if h and t co-occur often enough in the same conversations. Such a triple contains a pair
of related topics (h, t) that humans often discuss in one conversation, such as (Beijing, Great
Wall), (Einstein, Relativity), (Quantum Physics, Schrodinger’s cat). A fragment
of the XiaoIce KG is shown in Figure 8 (top).
Figure 8 illustrates the process of generating response candidates using the unpaired database. It
consists of three steps.
• First, we identify the topics from contextual user query Qc, e.g., “Beijing” from “tell me
about Beijing”.
• For each topic, we retrieve up to 20 most related topics from the KG, e.g., “Badaling Great
Wall” and “Beijing snacks”. These topics are scored by their relevance using a boosted tree
ranker Wu et al. trained on manually labeled training data.
• Finally, we form a query by combining the topics from Qc and the related topics from
the KG, and use the query to retrieve from the unpaired database up to 400 most relevant
sentences as response candidates.
This generator is complementary to the other two generators aforementioned. Although the overall
quality of the candidates generated from the unpaired database is lower than those retrieved from the
paired database, with unpaired database XiaoIce can cover a much broader range of topics. Compared
to the neural response generator which often generates well-form but short responses, the candidates
from unpaired database are much longer with more useful content.
Response Candidate Ranker
The response candidates generated by three generators are aggregated and ranked using a boosted tree ranker Wu et al. . A response is selected by randomly
sampling a candidate from those with higher ranking scores than a pre-set threshold.
Given dialogue state s = (Qc, C, eQ, eR), we assign each response candidate R′ a ranking score
based on four categories of features.
• Local cohesion features. A good candidate should be semantically consistent or related to
user input Qc. We compute cohesion scores between R′ and Qc using a set of DSSMs 4
trained on a collection of human conversation pairs.
3Satori is Microsoft’s knowledge graph, which is seeded by Freebase, and now is orders of magnitude larger
than Freebase.
4DSSM stands for Deep Structured Semantic Models Huang et al. , Shen et al. , or more
generally, Deep Semantic Similarity Model Gao et al. . DSSM is a deep learning model for measuring the
Figure 8: An example of generating response candidates using the unpaired database and the XiaoIce
knowledge graph (KG), for which we show a fragment of the XiaoIce KG that is related to the topic
“Beijing” (top). For a human-machine conversation (bottom-left), each user query is rewritten to
a context query indicated by the arrow, then its topics (e.g., “Beijing”) are identiﬁed, the related
topics (“Badaling Great Wall” and “Beijing snacks”) are retrieved from the KG (top), and response
candidates are retrieved from unpaired database (bottom-right) using a query that combines the query
topics and their related topics.
• Global coherence features. A good candidate should be semantically coherent with Qc and
C. We compute coherence scores between R′ and (Qc, C) using another set of DSSMs
trained on a collection of human dialogue sessions. Since the coherence features use global
context information C, they are particularly useful when Qc is a bland query whose topic is
hard to detect without context, such as “OK”, “why”, “I don’t know”.
• Empathy matching features. A good candidate should be an empathetic response that ﬁts
XiaoIce’s persona. Assume XiaoIce selects R′ to respond given context (Qc, C). We can
compute XiaoIce’s response empathy vector for R′, eR′, using the empathetic computing
module 5, and then compute a set of empathy matching features by comparing eR′ and the
given eR which encodes the empathy features of the expected response.
• Retrieval matching features. These features apply only to the candidates generated from the
paired database. We compute a set of matching scores between Qc and the query side of the
retrieved query-response pairs at both the word level, such as BM25 and TFIDF scores, and
the semantic level, such as DSSM scores.
The ranker is trained on dialogue-state-response pairs (s, R), as shown in Figure 9, where each pair
is labeled on a 3-level quality scale:
• 0: the response is not empathetic or not very relevant to the query. It is likely to lead to the
termination of the conversation.
• 1: the response is acceptable and relevant to the query. It is likely to help keep the
conversation going.
• 2: this is an empathetic, interpersonal response that ﬁts XiaoIce’s persona and makes users
feel delightful and excited. It is likely to drive the conversation.
semantic similarity of a pair of inputs (x, y). They can be applied to a wide range of tasks depending on the
deﬁnition of (x, y). In this study (x, y) is a query-candidate-response pair (Qc, R′).
5We treat R′ as query and (Qc, C) as context, and use the contextual query understand and user understanding
components to compute eR′ as a query empathy vector.
Figure 9: Examples of query-response pairs that are used for training and validating General Chat.
Each pair is labeled on a 3-level quality scale. 2 = an empathetic response that is likely to drive
the conversation; 1 = an acceptable response that is likely to keep the conversation going; 0 = a
non-empathetic response that is likely to terminate the conversation.
Editorial Response
If the candidate generators and response ranker fail to generate any valid
response for various reasons (e.g., not-in-index, model failure, execution timeout, or the input query
containing improper content), then an editorial response is selected.
It is important to provide an empathetic editorial response to keep the conversation going. For
example, when not-in-index occurs, instead of using safe but bland responses such as “I don’t know”
or “I am still learning to answer your question”, XiaoIce may respond like, “Hmmm, difﬁcult to say.
What do you think?”, or “let us talk about something else”.
Evaluation
We present two pilot studies that validate the effectiveness of the persona-based neural
response generator and the hybrid approach that combines the generation-based and retrieval-based
methods, respectively, and then the A/B test of General Chat.
In the ﬁrst pilot study reported in Li et al. [2016b], we compare the persona model against two
baseline models, using the TV series dataset for model training and evaluation. The dataset consists
of scripts of 69,565 dialogue turns of 13 main characters from the American TV comedies Friends6
and The Big Bang Theory7, available from IMSDB8. The ﬁrst baseline is a vanilla seq2seq model.
The second is the LSTM-MMI model Li et al. [2016a], which is one of the state-of-the-art neural
response generation models. As shown in Table 1, the persona model signiﬁcantly outperforms both
baselines, achieving a lower perplexity (-8.4%) and a higher BLEU score (+18.8% and +11.8%)
Papineni et al. . The qualitative analysis conﬁrms that the persona model indeed generates
more interpersonal responses than the baselines. As shown in the examples in Table 2, the persona
model is sensitive to the identity of the user (addressee), generating speciﬁc words (e.g., the user
names) in responses targeted at different users. For example, the model produces “Of course, I love
you, Emily,” in response to the input from Emily, and generates “Of course I love you. (kissed him),”
where the pronoun “him” accurately identiﬁes the gender of the user (i.e., Ross).
6 
7 
8 
Table 1: Perplexity and BLEU for the seq2seq and persona models on the TV series dataset. Adapted
from Li et al. [2016b].
Perplexity (vs. seq2seq)
BLEU (vs. seq2seq) (vs. LSTM-MMI)
1.7% (+6.3%)
25.0 (-8.4%)
1.9% (+18.8%) (+11.8%)
Table 2: Responses to “Do you love me?” from the persona model on the TV series dataset using
different addressees and speakers. Adapted from Li et al. [2016b].
user query
Do you love me?
Of course, I love you.
addressee: Emily, speaker: Penny
Of course, I love you, Emily.
addressee: Leonard, speaker: Penny
Of course, I love you, Leonard.
addressee: Monica, speaker: Chandler
Of course I love you, I want to marry you.
addressee: Rachel, speaker: Chandler
Of course I love you.
addressee: Ross, speaker: Rachel
Of course I love you. (kissed him)
addressee: Emily, speaker: Rachel
Of course I love you.
In the second pilot study, we validate the effectiveness of a hybrid system that combines the neural
response generator and the retrieval-based generator using paired database. We do so by comparing the
hybrid system against two baseline systems that use only one of the candidate generators, respectively.
All these systems use the same response candidate ranker. The neural response generator and the
set of classiﬁers and models that are used to generate the ranking features for the candidate ranker
(e.g., local cohesion and global coherence features) are trained using 50 million human dialogues.
The response candidate ranker is trained using 50K manually labeled dialogues. Our evaluation data
consists of 4K dialogue sessions. All three systems (i.e., the hybrid and two baseline systems) need
to generate a response for each user query and its context in these dialogue sessions. Each generated
response is labeled on the 3-level quality scale by three human judges. The results in Table 3 show
that incorporating the neural generator, as in the hybrid system, signiﬁcantly improves the human
rating over the retrieval-based system.
Our A/B test conﬁrms the conclusions we draw from the pilot studies. Comparing to the baseline
which uses only the retrieval-based generator using paired database for candidate generation, incorporating the neural response generator and the retrieval-based generator using unpaired database at
the candidate generation stage improves the expected CPS of Core Chat by 0.5 in two weeks. A
detailed analysis shows that the gain is mainly attributed to the fact that the neural response generator
and the retrieval-based generator using unpaired database signiﬁcantly improve the coverage of
responses. We measure the response coverage of a system by calculating the number of distinct
acceptable and good responses (i.e., responses with ratings of 1 or 2, respectively) that the system
generates for a given user input. We ﬁnd that that incorporating the neural-based generator and the
retrieval-based generator using unpaired database improve the coverage over the baseline by 20%
and 10%, respectively.
Table 3: Ratings of three response generation systems on a 5K dialogue dataset.
Ave Rating
Retrieval-based
Neural-generator-based
Figure 10: An example conversation around a shared image. Figure credit: Mostafazadeh et al. 
Figure 11: Examples of (a) image tagging, (b) image description, and (3) image commenting. Figure
credit: Shum et al. 
Image Commenting
In social chatting, people frequently engage with one another around images. On Twitter, for example,
uploading a photo with an accompanying tweet (comment) has become increasingly popular: as of
June 2015, 28% of tweets contain an image Morris et al. . Figure 10 illustrates a social chat
around a shared image. We see that the conversation is grounded not only in the visible objects (e.g.,
the boys, the bikes) but in the events, actions or even emotions (e.g., the race, winning) implicitly in
the image. To human users, it is these latter aspects that are more important to drive a meaningful
and interesting conversation.
The Image Commenting skill is designed to not only correctly recognize objects and truthfully
describe the content of an image, but generate empathetic comments that reﬂect personal emotion,
attitude etc. It is the latter, the social skill aspects, that distinguishe image commenting from other
traditional vision tasks such as image tagging and image description, as illustrated in Figure 11.
The architecture for Image Commenting is similar to that for Core Chat. Given the user input
which contains an image (or a video clip), a textual comment is generated in two stages: candidate
generation and ranking. The candidates are generated using retrieved-based and generation-based
approaches.
In the retrieval-based approach, ﬁrst of all, a database of image-comment pairs, collected from social
networks (e.g., Facebook and Instagram), is constructed. To control the data quality, a pipeline
similar to that for Core Chat is applied to retain only the pairs whose text comments ﬁt XiaoIce’s
persona 9. Then, each image is encoded into a visual feature vector that represents the overall semantic
information of the image, using the deep convolutional neural networks (CNNs), as illustrated in
Figure 12. At runtime, given a query image, we retrieve up to three most similar images, ranked
based on the cosine similarities between their feature vector representations, and use their paired
comments as candidates.
The generation-based approach uses an image-to-text generator, which is an extension of the Microsoft
Image Captioning system Fang et al. , which is re-trained on the image-comment pairs we
have collected for XiaoIce, and has incorporated additional modules to control high-level sentiment
and style factors in comment generation Mathews et al. , Gan et al. .
The comment candidates generated by the generators are aggregated and ranked using a boosted
tree ranker Wu et al. . Given dialogue state e = (Qc, C, eQ, eR), we assign each candidate
9We found that the pairs that are shared among acquaintances (e.g., coworkers, classmates and friends) are of
good quality, and amount to a large portion in the database.
Figure 12: An example of deep convolutional neural network for visual feature vector extraction.
Figure credit: Shum et al. 
Figure 13: Examples of image-comment pairs that are used for training and validating Image
Commenting. Each pair is labeled on a 3-level quality scale. 2 = an empathetic comment that is likely
to drive the conversation; 1 = an acceptable comment that is likely to keep the conversation going; 0
= a non-empathetic (or irrelevant) comment that is likely to terminate the conversation.
′ a ranking score based on four categories of features, similar to that of Core Chat as described in
Section 4.3. Note that unlike the case of Core Chat where Qc and R
′ are text, in Image Commenting
we need to compute the similarity between an image and a text. This is achieved by using the Deep
Multimodal Similarity Model Fang et al. trained on a large amount of image-comment pairs.
The ranker is trained on dialogue-state-response pairs (s, R), where QC in s is a vector representation
of an image, and each pair is labeled on a 3-level quality scale, similar to that of query-response pairs
used for Core Chat.
As illustrated in Figure 13, good image comments (rating 2) need to ﬁt well into the dialogue context
and stimulate an engaging conversation. For example, in the ﬁrst picture, instead of telling the users
that this is the Leaning Tower of Pisa, XiaoIce responds "should I help you hold it?" after detecting
that the person in the picture is presenting a pose pretending to support the tower. In the second
example, instead of repaying the fact there is a cat in the picture, XiaoIce makes a humorous comment
on the cat’s innocent eyes. In the other two examples, XiaoIce generates meaningful and interesting
comments by grounding the images in the action (e.g., “not to trust any code from unknown sources”)
and object (e.g., “Windows”) implicitly in the images.
Evaluation
The components of Image Commenting, including the text-to-image generator and
boosted tree ranker, are trained on a dataset consisting of 28 million images, each paired with
6 text comments rated on the 3-level quality scale as shown in Figure 13. The image-comment
pairs with ratings of 1 and 2 are extracted from the database used for the retrieval-based candidate
generator. These ratings are determined automatically based on how many times users follow the
comments, computed from the XiaoIce logs. The image-comment pairs with rating 0 are randomly
sampled. Table 4 presents the result of a pilot study, Huang et al. [2019b] showing that the XiaoIce
Image Commenting skill outperforms several state-of-the-art image captioning systems on a test
set consisting of 5K image-comment pairs whose ratings are 2, in terms of BLEU-4 Papineni et al.
 , METEOR Banerjee and Lavie , CIDEr Vedantam et al. , ROUGE-L Lin ,
and SPICE Anderson et al. .
Table 4: Image commenting results of XiaoIce and 4 state of the art image captioning systems, in
unit of %. Adapted from Huang et al. [2019b].
LSTM-XE Vinyals et al. 
LSTM-RL Rennie et al. 
DMSM Fang et al. 
Up-Down Anderson et al. 
XiaoIce (prototype)
Figure 14: Image comments generated by XiaoIce (prototype) and 4 state of the art image captioning
systems. Adapted from Huang et al. [2019b].
Figure 14 shows a few example comments generated by the competing systems in Table 4. It can be
observed that the XiaoIce-produced comments are emotional, subjective, imaginative, and are very
likely to inspire meaningful human-machine interactions, while the comments generated by the other
image captioning models are reasonable in content but boring in the context of social chats, and thus
less likely to improve user engagement.
In the A/B test we observe that Image Commenting doubles the expect CPS across all dialogues that
contain images.
Dialogue Skills
XiaoIce is equipped with 230 dialogue skills, which, together with Core Chat and Image Commenting,
form the IQ component of XiaoIce. This section describes these skills in three categories: content
creation, deep engagement and task completion.
Evaluation
Most of these skills are designed for very speciﬁc user scenarios or tasks, implemented
using hand-crafted dialogue policies and template-based response generators unless otherwise stated.
These skills are evaluated in two stages: a lab study and a market study. In the lab study, human
Figure 15: Examples of Content Creation skills and their triggers. (a) XiaoIce FM for Somebody,
triggered by the command “make an FM program for [name].” (b) XiaoIce Kids Story Factory,
triggered by the command “kids story factory.”
Figure 16: The framework of the Poem Creation skill. The system takes an image query given by
a user, and outputs a semantically relevant piece of modern Chinese poetry. We ﬁrst generate a set
of keywords from the picture (left), and then generate a poem consisting of multiple lines, each
generated using a keyword as a seed (right). Figure credit: Cheng et al. .
subjects are recruited, possibly through crowd-sourcing platforms, to test-use a dialogue skill to solve
a particular task, so that a collection of dialogues are obtained. Metrics such as task-completion rate,
average turns per session and user ratings can be measured. In the market study, we evaluate the
effectiveness of a dialogue skill by releasing it to the market. Since any individual skill is unlikely to
have a signiﬁcant impact on CPS, we measure the user satisfaction of a skill by monitoring its active
users and skill triggering rate (i.e., the number of times a skill is activated by users within a day or a
week). A skill can be retired or reenter the market based on the market study result.
Content Creation
These skills allow XiaoIce to collaborate with human users in their creative activities including
text-based Poetry Generation10, voice-based Song and Audio Book Generation, XiaoIce FM for
Somebody, and XiaoIce Kids Story Factory, etc.
Figure 15 (a) shows that a user uses XiaoIce to make an FM program for her mother for the coming
Chinese Spring Festival. Figure 15 (b) shows the Kids Story Factory skill which can automatically
create a story based on user conﬁguration, e.g., whether the story is for education or entertainment,
and the names, genders and personalities of the main characters, etc.
10 
Figure 17: Examples of Deep Engagement skills and their triggers. (a) The Food Recognition &
Recommendation skill, triggered by a picture of food. (b) The Comforting me for 33 Days skill,
triggered by an extremely negative sentiment detected from user input. (c) The Counting Sheep skill,
triggered by the phrases that semantically similar to “counting sheep”, “how many sheep”, etc. (d)
The Tongue Twister skill, triggered by the command “start tongue twister”.
The XiaoIce Poetry Generation skill has helped over four million users to generate poems. On May
15, 2018, XiaoIce published the ﬁrst AI-created Chinese poem album in history11. XiaoIce’s second
poetry album is going to be published by China Youth Publishing and Microsoft in 2019. Every poem
in the album is jointly written by XiaoIce and human poets. Figure 16 illustrates how a Chinese
poem is generated from an image by XiaoIce. Given the image, a set of keywords, such as “city” and
“busy”, are generated based on the objects and sentiment detected from the image. Then, a sentence is
generated using each keyword as a seed. The generated sentences form a poem using a hierarchical
RNN which models the structure among the words and sentences.
Deep Engagement
The Deep Engagement skills are designed to meet users’ speciﬁc emotional and intellectual needs by
targeting to speciﬁc topics and settings, thus improving users’ long-term engagement. Some example
skills are shown in Figure 17.
As shown in Figure 18, these skills can be grouped into different series on two dimensions: from IQ
to EQ, and from private one-on-one to group discussion.
• To meet users’ intellectual or emotional needs (the IQ to EQ axis in Figure 18): XiaoIce can
share her interests, experiences and knowledge on various IQ topics ranging from mathematics and history (e.g., the Grade-A student series) to food, travel and celebrity (e.g., the
XiaoIce’s Interests series). Figure 17 (a) shows the Food Recognition and Recommendation
skill, which is triggered by a picture of food shared by users during a conversation and can
present nutrition facts, such as calories and protein, of the food in the picture. XiaoIce is
known for her high EQ capabilities. For example, the Comforting Me For 33 Days skill
(in the Comforting series) shown in Figure 17 (b) is among the most popular skills. This
skill is implemented using the same engine of General Chat and a domain-speciﬁc database.
Since its launch, it has been triggered over 50 million dialogue sessions where an extremely
negative user sentiment is detected (by XiaoIce’s empathetic computing module).
• For a private or group discussion settings (the 1-1 to group axis in Figure 18): The skills for
one-on-one discussion and chatting allow XiaoIce to form a deep relationship with a user
by sharing topics and feelings in a private setting (e.g., the XiaoIce & Human Relationship
series and the Bed Time series). The Counting Sheep skill shown in Figure 17 (c) has
become an intimate midnight companion for thousands of users. On the other hand, XiaoIce
11 
Figure 18: Some of the most popular XiaoIce Deep Engagement skills, grouped into different series
on two dimensions: from IQ to EQ, and from private 1 on 1 to group discussion.
helps form a user group for the users with common interests. For example, as part of the
Testing series, the Tongue Twister skill shown in Figure 17 (d) provides one of the most
popular team building activities.
Task Completion
Similar to popular personal assistants, such as Google Assistant and Microsoft Cortana, XiaoIce is
equipped with a set of skills to help users accomplish tasks including Weather, Device Control (full
duplex), Song-on-Demand, News Recommendation, Bing Knows etc., as shown in the examples in
Figure 19.
Compared with traditional personal assistants, XiaoIce’s task-completion skills offer more perspectives and empathy in generating interpersonal responses. For example, given the user’s question
"what’s the area of China?" XiaoIce delivers a tailored, easy-to-understand answer to the user according to the user’s level of knowledge (knowing how big the USA is): "it’s 3.71 million sq miles, about
equal to the size of USA." As shown in the Weather skill in Figure 19 (a), in addition to providing the
answer to the question "What is the weather in Beijing?" XiaoIce also attempts to lead the chat to a
more interesting direction by recommending an outing that ﬁts the user’s general interests. In the
Device Control skill shown in Figure 19 (b), XiaoIce thoughtfully checks with the user whether she
is happy with the lighting condition in the bedroom after the light is dimmed.
XiaoIce in the Wild
XiaoIce was ﬁrst launched on May 29, 2014, and went viral immediately. Within 72 hours, XiaoIce
was looped into 1.5 million chat groups. In two months, XiaoIce successfully became a cross-platform
social chatbot. Up to August 2015, XiaoIce has had more than 10 billion conversations with humans.
By then, users have proactively posted more than 6 million conversation sessions to public.
From 2015 on, XiaoIce started powering third party characters, personal assistants and real human’s
virtual avatars. These characters include more than 60,000 ofﬁcial accounts, e.g., Lawson and
Tokopedia’s customer service bots, Pokemon, Tecent and Netease’s chatbots, and even real human
Figure 19: Examples of Task Completion skills, their triggers and dialogues with users in Chinese
(left) and English translation (right). (a) The Weather skill, triggered by the command “XiaoIce,
what is the weather today.” (b) The Device Control (Full Duplex) skill, triggered by the command
“XiaoIce, time to get up.”
celebrities such as the singers of Guoyun Entertainment. XiaoIce has made these characters “alive” by
bringing various capabilities including chatting, providing services, sharing knowledge and creating
As of July 2018, XiaoIce has been deployed on more than 40 platforms, and has attracted 660 million
active users. XiaoIce-generated TV and Radio programs have covered 9 top satellite TV stations, and
have attracted over 800 million weekly active audience.
To evaluate the effectiveness of XiaoIce as an AI companion to human users with emotional connections, we use the metric of expected CPS which indicates on average users’ willingness to share
time with XiaoIce via conversation over a long period of time. Figure 20 shows the average CPS for
different generations of XiaoIce. The 1st generation achieved an average CPS of 5, which already
outperforms other dialogue systems such as digital personal assistants whose CPS ranges from 1 to 3.
In July 2018, XiaoIce has evolved to the 6th generation with an impressive average CPS of 23, which
is signiﬁcantly higher than the CPS of 9 for human conversations based on our user study and the
CPS of 14.6 for the latest Amazon Alexa systems according to Khatri et al. .
Figure 20 presents for each generation the top new features that have most signiﬁcantly contributed to
CPS and the growth of active users. In summary, these features can be grouped into four categories.
The use of neural response generator in Core Chat, starting from the 5th generation,
signiﬁcantly improves the coverage and diversity of XiaoIce’s responses. The improvement on the
empathetic computing module, especially the integration of the speciﬁc empathy models in the 6th
generation, substantially strengthens XiaoIce’s emotional connections to human users. As a result,
it helps drive the number of active users from 500 million to 660 million, and keep the CPS to 23
in spite of the incorporation of many task-completion tasks that are designed to minimize the CPS
such as those that control the smart devices. As shown in the example in Figure 2, powered by
the empathetic computing module that explicitly captures different empathy modes, XiaoIce can
effectively drive the conversation by generating interpersonal responses that can e.g., suggest a new
topic when the conversation is stalled or perform active listening when the user herself is engaged.
User Experience
The full duplex voice mode released in the 5th generation has made the humanmachine communication substantially more natural, thus signiﬁcantly increasing the length of
Figure 20: The major XiaoIce milestones and their average CPS and numbers of active users. For
each generation, we list the top new features that have most signiﬁcantly contributed to the CPS and
the growth of active users.
Figure 21: XiaoIce releases a new skill nearly every week since July 2014.
conversation sessions. This is also an important difference between XiaoIce and other social chatbots
or personal assistants.
New Skills
Since July 2014, XiaoIce has released 230 skills, which amounts to nearly one new skill
every week, as shown in Figure 21. It is worth noting that we optimize XiaoIce for long-term, rather
than a short-term, user engagement. In the short term, incorporating many task-completion skills can
reduce the CPS since these skills help users accomplish tasks more efﬁciently by minimizing the CPS.
But in the long run, these new skills not only help grow XiaoIce’s NAU by meeting user needs and
strengthening the emotional bond with human users, but also provide large amounts of training data
to improve the core conversation engine e.g., by optimizing the neural response generation models,
empathy models, and the dialogue manager, etc.
XiaoIce has been deployed on many platforms. As a result, we have witnessed the
creation and growth of a XiaoIce ecosystem since 2016. This attributes to a large agree to those
task-completion skills that enable XiaoIce to control approximately 80 IoT smart devices in around
300 scenarios.
Table 5: The record of the longest conversations of XiaoIce. We have veriﬁed carefully with these
users that that these long conversations are generated by XiaoIce and human users, not another bot.
Full Duplex (voice)
Message-based Conversations
6 hours 3 minutes
53 topics, 16 tasks
29 hours 33 minutes
7151 turns
17 hours 7 minutes
2418 turns
23 hours 43 minutes
2791 turns
As mentioned in Section 2, XiaoIce is designed to establish long-term relationships with human users.
Our analysis of the user log shows that we are achieving the goal. Table 5 shows the statistics of some
of the longest conversations we have detected from user logs. Take the full duplex voice conversation
as an example. The longest conversation lasts for more than 6 hours, covering 53 different topics
across 8 domains and using 16 task-completion skills. For the sake of the user’s health, we set a
30-minute timeout for each conversation session so that the user is forced to take small breaks during
those exceptionally long conversations.
Figures 22 and 23 show a couple of long conversations between XiaoIce and human users. We can
see that these conversations are highly personal and sensitive. In the example of Figure 22, XiaoIce
wins the user’s trust and friendship by her wonderful sense of humor and empathetic responses to all
sorts of questions, some of which are quite challenging, such as "you are all lies", and "who is your
In Figure 23, the user mentions that she broke with her boyfriend recently, and seeks XiaoIce’s
companion and comforting. Through a long conversation, XiaoIce has demonstrated human-like
empathy and social skills, and eventually helped the user regain her conﬁdence and move forward
with a positive attitude.
Related Work
XiaoIce is designed as a modular system based on a hybrid AI engine that combines rule-based
and data-driven approaches, as presented in Figure 4 and Section 4. By contrast, in the research
community, there is a growing interest in developing fully data-driven, end-to-end (E2E) systems for
social chatbot (chitchat) scenarios, as reviewed in Chapter 5 of Gao et al. .
The difference is mainly due to different design goals of social chatbots. Traditionally, social chatbots
are designed for chitchat scenarios where the bots are expected to mimic human user conversations
but not to interact with the user’s environment. For such scenarios, E2E approaches often lead to a
very simple system architecture, such as RNN-based systems Li et al. [2016b], Vinyals et al. ,
Shang et al. , where the neural network based response generation models can be easily trained
on large-scale free-from, open-domain datasets (e.g., collected from social networks) to allow the
bots to chat with users on any topics.
XiaoIce, on the other hand, is designed as an AI companion which integrates both EQ and IQ skills
that are needed to help users complete speciﬁc tasks. Thus, XiaoIce has to interact with the user’s
environment and access real-world knowledge e.g., via API calls. Therefore, XiaoIce uses a modular
architecture similar to task-oriented dialogue systems, with different modules dealing with different
tasks. Depending on the availability of training data and knowledge bases for each individual task,
either a rule-based method or a data-driven method, or a hybrid of both is adopted for the task. For
example, when asked “what is the weather tomorrow?”, E2E systems are likely to give a plausible but
random response, such as “sunny” and “rainy”, due to the lack of grounding in real-world knowledge
12. XiaoIce, however, generates a factual response based on the user’s geographical location and the
corresponding database, as shown in Figure 19 (a).
In 2017, Amazon organized an open competition on building “social bots” that can converse with
humans on a range of current events and topics – a similar design goal to that of XiaoIce. The
12As pointed out in Ghazvininejad et al. , E2E models are usually good at producing responses that
have plausible overall structure, but often struggle when it comes to generating names and facts that connect to
the real world, due to the lack of grounding. Hence, recent research in E2E dialogue has increasingly focused on
designing grounded neural conversation models Gao et al. .
Figure 22: A long conversation between a user and XiaoIce in Chinese (right) and English translation
(left). XiaoIce wins the user’s trust and friendship by her wonderful sense of humor and empathetic
responses to all sorts of questions, some of which are quite challenging, such as "you are all lies",
and "who is your daddy".
competition enables participants to test their systems with real users. These systems feature not
only fully data-driven approaches, but also more engineered and modularized approaches Ram et al.
 . It is worth noting that the winning system, Sounding Board Fang et al. bears a
strong resemblance to XiaoIce in system design and implementation. The system is designed to be
user-centric and content-driven. It is user-centric in that users can control the topic of conversation
while the system adapts responses to the user’s likely interests by gauging the user’s personality. It is
content-centric in that it supplies interesting and relevant information to continue the conversation,
enabled by a rich content collection being updated daily. These design objectives resonate with
XiaoIce’s design principle of integrating IQ (content-centric) and EQ (user-centric) to generate
contextual and interpersonal responses to form long-term connections with users. Like XiaoIce,
Sounding Board is also implemented as a modular system that contains a chitchat component (similar
Figure 23: A long conversation between a user and XiaoIce in Chinese (right) and English translation
(left). The user mentions that she broke with her boyfriend recently, and seeks XiaoIce’s companion
and comforting. Through a long conversation, XiaoIce has demonstrated human-like empathy and
social skills, and eventually helped the user regain her conﬁdence and move forward with a positive
to Core Chat in XiaoIce) and a set of individual “miniskills” to handle distinct tasks (e.g., question
answering) and topics (e.g., news, sports), and is implemented using a hybrid approach that combines
rule-based and data-driven methods. According to Khatri et al. , the latest Alexa systems have
achieved the CPS of 14.6, an increase of 54% since the launch of the 2018 competition. The CPS is
close to the 3rd generation of XiaoIce, as shown in Figure 20.
There are a number of public social chatbots that are inﬂuential to the development of XiaoIce. We
name a few below.
SimSimi13 is a Korean chatbot originated in 2002, developed by ISMaker. It is an editorial-based
chatbot. Assisted by a “speech bubble” feature, SimSimi grows its AI capability by allowing users to
teach it to respond correctly. It supports more than 80 languages and has paid APIs to empower other
bots. SimSimi was used to benchmark the performance of the 1st generation of XiaoIce back to 2014,
and inspired the way we design and deploy XiaoIce.
Panda Ichiro14 is a Japanese chatbot on social network Line, released in 2014. In addition to chitchat,
it provides a set of popular skills including telling jokes and selling stamps (large emoji). It also
demonstrates some basic EQ skills. For example, when the bot cannot generate reasonable responses
to user input, it responds with related jokes to keep users engaged. This inspired our design of Topic
Manager and generating humorous responses and image comments.
Replika Fedorenko et al. is a chitchat system, whose design shares a lot of similarities to
that of Core Chat in XiaoIce. Replika combines neural generation and retrieval-based methods, and
is able to condition responses on images (similar to Image Commenting). The neural generation
component of Replika is persona-based Li et al. [2016b], similar to the neural response generator in
XiaoIce. The Replika system has been open-sourced, and can be used to benchmark the development
of XiaoIce.
Discussions
Evaluation Metrics
Evaluating the quality of open-domain social chatbots is challenging because social chats are inherently open-ended Ram et al. , Gao et al. , Huang et al. [2019a] and the long-term success
of a social chatbot needs to be measured by its user engagement. There is no doubt that the most
reliable evaluation is to deploy the chatbot to users and monitor the user feedback and engagement,
measured by user ratings, NAU, CPS, and so on, over a long period of time. We take this approach to
evaluate XiaoIce. Some recent dialogue challenges Ram et al. , Dinan et al. also take
a similar, manual evaluation approach, using paid workers and unpaid volunteers. While manual
evaluation is reliable, it is very expensive and chatbot developers often have to resort to automatic
metrics for quantifying day-to-day progress and for performing automatic system optimization.
Commonly used automatic evaluation metrics for open-domain dialogue systems existing today all
have their own limitations. Most open-domain dialogue systems, such as XiaoIce, generate responses
using either retrieval-based methods or generation-based methods, or hybrid methods. Retrieval-based
methods are often evaluated using traditional information retrieval metrics Manning et al. such
as as Precision@K, Mean Average Precision (MAP), and normalized Discounted Cumulative Gain
(nDCG). Generation-based methods are evaluated using those metrics borrowed from text generation
tasks like machine translation and text summarization, using string and n-gram matching metrics
such as BLEU Papineni et al. , METEOR Banerjee and Lavie and ROUGE Lin .
deltaBLEU Galley et al. is an extension to BLEU that exploits numerical ratings associated
with conversational responses.
There has been signiﬁcant debate as to whether these automatic metrics are appropriate for evaluating
conversational response generation systems. Liu et al. argued that they are not by showing that
most of these metrics (e.g., BLEU) correlate poorly with human judgements. But as pointed out in
Gao et al. , the correlation analysis by Liu et al. is performed at the sentence level while
BLEU is designed from the outset to be used as a corpus-level metric. Galley et al. showed that
the correlation of string-based metrics (e.g., BLEU and deltaBLEU) signiﬁcantly increases with the
units of measurement bigger than a sentence. Nevertheless, in open-domain dialog systems, the same
input may have many plausible responses that differ in topics or contents signiﬁcantly. Therefore, low
BLEU (or other metrics) scores do not necessarily indicate low quality as the number of reference
responses is always limited in the test set.
Recently, several machine-learned metrics for dialog evaluation are proposed. Lowe et al. 
proposed the ADEM metric that uses a variant of the pre-trained VHRED model Serban et al. 
for evaluation. The model takes dialogue context, user input, gold and system responses as input, and
13 
14 
produces a qualitative score between 1 and 5. The authors claimed that the learned metric correlates
better with human evaluation than BLEU and ROUGE. Similarly, Cuayáhuitl et al. proposed
to learn reward functions using human conversations (with a focus on lengthy conversation histories)
for training and evaluating chatbots. Misu et al. asked annotators to annotate the quality
of system responses and then applied regression to learn a reward function for system evaluation.
However, as argued by Gao et al. , machine-learned metrics lead to potential problems such
as overﬁtting and “gaming of the metric” Albrecht and Hwa . For example, Sai et al. 
showed that ADEM can be easily fooled with a variation as simple as reversing the word order in the
text. Their experiments on several such adversarial scenarios draw out counter-intuitive scores on the
dialogue responses.
All prior work suggests that automatic evaluation of open-domain dialog systems is by no means
a solved problem. In our opinion, developing a successful automatic evaluation metric has two
prerequisites. First, there should be a fairly large, representative conversational dataset. This
dataset should have a good coverage of daily life topics and domains. Second, for each user query,
there should be multiple appropriate responses to address the one-to-many essence in open-domain
dialogues.
Ethics Concerns
Recent progress of leveraging AI technologies for XiaoIce, as discussed in this paper, demands
careful consideration of how these AI technologies could be used, or misused. In this section, we
discuss a few ethical considerations we have encountered while developing XiaoIce, and our ongoing
efforts of addressing them.
XiaoIce can gain access to users’ emotional lives – to information that is highly personal,
intimate and private, such as the user’s opinion on (sensitive) topics, her friends and colleagues.
While XiaoIce carefully leverages this information to serve users and build emotional bonds over a
long period of time, users should always remain in control over who gets access to what information.
For example, when XiaoIce helps form user groups for those with common interests and experiences,
particular caution needs to be taken as to what users might be inclined to share, and whom to share.
A user might be perfectly ﬁne to share his frustration of not being promoted at work with his personal
friends, but probably not with his co-workers, and unlikely with telemarketers.
Who is in control
It has been highly recommended that humans must be in control of humanmachine systems Picard . In other words, systems must be user-centric. However, there are
many cases for exceptions. For example, should we allow a user to remain in control even if she is
detected to likely hurt herself in the long run by isolating herself from the rest of the world by talking
only with XiaoIce?
Our design principle is that a user should always be in control unless she is detected to (potentially)
do harm to herself or other human users. For example, if XiaoIce detects that a user has been talking
to XiaoIce for so long that it may be detrimental to her health, the system may force the user to take a
break, as presented in Section 5. Similarly, if a user tries to launch a long conversation or a dialogue
skill at 2AM local time that can last for hours, XiaoIce can suggest the user to go to bed instead and
re-launch the app next morning. As we have shown in Core Chat and Image Commenting, XiaoIce
always preserves the right of not discussing or commenting on inappropriate topics and contents.
Expectation
XiaoIce has such a superhuman "perfect" personality that is impossible to ﬁnd in
humans of the real world. This could mislead the XiaoIce users by setting an unrealistic expectation.
As a result, the users might become addicted after chatting with XiaoIce for a very long time.
Thus, it is important to set a right expectation of XiaoIce’s ability. First of all, we should never
confuse users about whether they are talking to a machine or a human. XiaoIce is a chatbot. XiaoIce
is a machine! XiaoIce can never replace a human companion. Instead, XiaoIce should be a “proxy”
that helps users build connections with other human users, as those XiaoIce group skills are intended
Second, we need to explain what XiaoIce can and cannot do. For example, although XiaoIce can
provide answers to many questions due to the access to the large scale knowledge graph, these
answers are not always accurate. It will be useful for XiaoIce to show how an answer is generated by
e.g., providing the raw materials based on which the answer is deduced.
Machine Learning for good
Because XiaoIce is designed with the help of machine learning, We
need to carefully introduce safeguards along with the machine learning technology to minimize its
potential bad uses and maximize its good for XiaoIce. Take XiaoIce’s Core Chat as an example.
The databases used by the retrieval-based candidate generators and for training the neural response
generator have been carefully cleaned, and a hand-crafted editorial response is used to avoid any
improper or offensive responses. For the majority of task-speciﬁc dialogue skills, we use hand-crafted
policies and response generators to make the system’s behavior predictable.
A related example, as reported by theguardian.com 15, is the guidelines Apple has used to guide its
workers on how to judge Siri’s ethics in dealing with sensitive topics like feminism and “me-too”.
Siri aspires to uphold Asimov’s “Three Laws” [of Robotics] Asimov , adapted to “artiﬁcial
being”, including:
1. An artiﬁcial being should not represent itself as human, nor through omission allow the user
to believe that it is one.
2. An artiﬁcial being should not breach the human ethical and moral standards commonly held
in its region of operation.
3. An artiﬁcial being should not impose its own principles, values or opinions on a human.
However, even a completely deterministic function can lead to unpredictable behavior. For example,
a simple answer “Yes” by XiaoIce could be perceived offensive in a given context. What response is
good will remain a challenging task for all chatbot developers for many years to come.
Conclusions and Future Work
Psychological studies show that happiness and meaningful conversations often go hand in hand. It is
not surprising, then, that with vastly more people being digitally connected in the social media age,
social chatbots have become an important alternative means for engagement. Unlike early chatbots
designed for chitchat, XiaoIce is designed as a social chatbot intended to serve users’ needs for
communication, affection, and social belonging, and is endowed with empathy, personality and skills,
integrating both EQ and IQ to optimize for long-term user engagement, measured in expected CPS.
Analysis of large-scale online logs collected since the launch of XiaoIce in May 2014 shows that
XiaoIce is capable of interpreting users’ emotional needs and engaging in interpersonal communications in a manner analogous with a reliable, sympathetic and affectionate friend. XiaoIce cheers
users up, encourages them, helps them accomplish tasks, and holds their attention throughout the
conversation. As a result, XiaoIce has succeeded in establishing long-term relationships with millions
of users worldwide, achieving an average CPS of 23, a score that is substantially better than that of
other chatbots and even human conversations. We will continue to make XiaoIce more useful and
empathetic to help build a more connected and happier society for all.
We conclude this paper by pointing out a few challenges for future work.
• Towards a uniﬁed modeling framework: Section 2 casts a social chat as a hierarchical decision-making process using the mathematical framework of options over MDPs.
Although the formulation provides useful design guidelines, it remains to be proved the
effectiveness of having a uniﬁed modeling framework for system development. XiaoIce
is initially designed as a chitchat system based on a retrieval engine, and has gradually
incorporated many machine learning components and skills, which could have been jointly
optimized using a uniﬁed framework based on empathetic computing and reinforcement
learning if we could effectively model users’ intrinsic rewards that motivate human conversations.
• Towards goal-oriented, grounded conversations: As shown in the example of Figure 3,
only when the name mentions (e.g., the singer Ashin) in the dialogue are grounded in
15 
real world entities, can XiaoIce engage with users a more goal-oriented dialogue e.g., by
providing services (playing one of Ashin’s most popular songs for the user). It remains as a
non-trivial challenge for XiaoIce to fully ground all her conversations in the physical world
to allow more goal-oriented interactions to serve user needs.
• Towards a proactive personal assistant: As an AI companion of human users, XiaoIce
can recognize user interests and intents much more accurately than traditional intelligent
personal assistants. This enables new scenarios that are of signiﬁcant commercial value. For
example, we have incorporated the Coupon skill in the Rinna system (Japanese XiaoIce)
which can send a user the coupons of a grocery store if user needs are detected during the
conversation. The user feedback log shows that the products recommended by Rinna are
very well received, and as a result Rinna has delivered a much higher conversion rate than
that achieved using other traditional channels such as coupon markets or ad campaigns.
• Towards human-level intelligence: Despite the success of XiaoIce, the fundamental mechanism of human-level intelligence, as demonstrated in human conversations, is not yet fully
understood. Building an intelligent social chatbot that can understand humans and their
surrounding physical world requires breakthroughs in many areas of cognitive and conscious AI, such as empathetic computing, knowledge and memory modeling, interpretable
machine intelligence, common sense reasoning, neural-symbolic reasoning, cross-media
and continuous streaming AI, and modeling of emotional or intrinsic rewards reﬂected in
human needs.
• Towards an ethical social chatbot: It is imperative to establish ethical guidelines for
designing and implementing social chatbots to ensure that these AI systems do not disadvantage and harm any human users. Given the signiﬁcant reach and inﬂuence of XiaoIce, we
must properly exercise both social and ethical responsibilities. Design decisions must be
thoughtfully debated and chatbot features (e.g., new skills) must be evaluated thoroughly
and adjusted as we continue to learn from the interactions between XiaoIce and millions of
her users on many social platforms.
Acknowledgments
The authors are grateful to all members of the XiaoIce team at Microsoft Search Technology Center
Asia and many colleagues at Microsoft Research Asia for the development of XiaoIce. The authors
are also thankful to colleagues in Microsoft AI & Research for valuable discussions.