The Modeling and Seasonal Adjustment of Weekly Observations
Author(s): Andrew Harvey, Siem Jan Koopman, Marco Riani
Source: Journal of Business & Economic Statistics, Vol. 15, No. 3 , pp. 354-368
Published by: American Statistical Association
Stable URL: 
Accessed: 14/11/2008 05:11
Your use of the JSTOR archive indicates your acceptance of JSTOR's Terms and Conditions of Use, available at
 JSTOR's Terms and Conditions of Use provides, in part, that unless
you have obtained prior permission, you may not download an entire issue of a journal or multiple copies of articles, and you
may use content in the JSTOR archive only for your personal, non-commercial use.
Please contact the publisher regarding any further use of this work. Publisher contact information may be obtained at
 
Each copy of any part of a JSTOR transmission must contain the same copyright notice that appears on the screen or printed
page of such transmission.
JSTOR is a not-for-profit organization founded in 1995 to build trusted digital archives for scholarship. We work with the
scholarly community to preserve their work and the materials they rely upon, and to build a common research platform that
promotes the discovery and use of these resources. For more information about JSTOR, please contact .
American Statistical Association is collaborating with JSTOR to digitize, preserve and extend access to Journal
of Business & Economic Statistics.
 
Adjustment
Observations
Andrew HARVEY
Faculty of Economics and Politics, University of Cambridge, Cambridge CB3 9DD, United Kingdom
Siem Jan KOOPMAN
Department of Statistics, London School of Economics, Houghton Street, London WC2A 2AE, United Kingdom
Marco RIANI
Dipartimento Statistico, Universita di Firenze, Viale Morgagni 59, 50139 Firenze, Italy
Several important economic time series are recorded on a particular day every week. Seasonal
adjustment of such series is difficult because the number of weeks varies between 52 and 53 and
the position of the recording day changes from year to year. In addition certain festivals, most
notably Easter, take place at different times according to the year. This article presents a solution
to problems of this kind by setting up a structural time series model that allows the seasonal
pattern to evolve over time and enables trend extraction and seasonal adjustment to be carried out
by means of state-space filtering and smoothing algorithms. The method is illustrated with a Bank
of England series on the money supply.
KEY WORDS: Calendar effects; Irregularly spaced observations; Kalman filter; Money supply;
Moving festival; Periodic spline; Stochastic seasonality; Structural time
series model.
The weekly figures on the U.K. money supply are eagerly
anticipated in the City of London because they are believed
to be an important economic indicator. One of the key series
is the value of the Bank of England notes and coins in
circulation, plus cash deposits of commercial banks with the
Bank of England. This basically corresponds to the measure
known as MO, and we will refer to it in this way hereafter.
These figures display considerable seasonal fluctuations and
are particularly high just before Christmas. As a result there
is a need for the Bank of England to produce a seasonally
adjusted series for ease of interpretation.
Figure 1 shows a plot of the logarithms of the obser-
vations on MO starting on May 28, 1969. Taking loga-
rithms yields a series with a more stable seasonal pattern.
The figures are recorded every Wednesday, except when
the Wednesday falls on a public holiday, in which case
the figure is recorded on the previous Tuesday (or Mon-
day if Tuesday is also a holiday). The Christmas peak can
be clearly seen and, as with many economic time series, it
is apparent that the seasonal pattern has evolved over time
due to changing institutional and social factors. An excel-
lent discussion of the changing nature of Christmas and its
consequent economic impact is that of Scott .
Modeling a changing seasonal component is relatively
easy for quarterly and monthly observations, the seasonal
component normally being combined with a stochastic
trend and an irregular term. This is either done explicitly,
as in the structural time series modeling approach, or im-
plicitly, as in the autoregressive integrated moving average
(ARIMA) approach. In the latter case, the seasonal compo-
nent is specified by means of a "canonical decomposition"
as shown by Hillmer and Tiao . The seasonal compo-
nent can be extracted by a state-space smoothing algorithm;
see, for example, Kitagawa and Gersch or Harvey
 . Carrying out such model-based seasonal adjustment,
using either approach, has considerable attractions because
the procedure adapts to the particular characteristics of the
series involved. The relationship between the model-based
procedures and the widely used Bureau of the Census X-11
program was discussed by Maravall .
Seasonal adjustment of weekly data is not an easy task.
The first problem is that, because the observations are nor-
mally recorded on a particular day of the week rather than
on predetermined dates, the fact that there is not an inte-
gral number of weeks in the year means that the number
of observations in the year varies between 52 and 53. Thus,
even if the seasonal pattern were deterministic, it could not
be modeled by a set of dummy variables. Furthermore, the
position of the dates of the observation days changes with
each year so that even with an integral number of weeks
in the year the seasonal pattern would change from year to
year. It makes a big difference, for example, if the money-
supply figure is recorded on the day before Christmas or six
days before Christmas. (The former case arises if Christmas
is on a Thursday, the latter if it is on a Tuesday.) To make
matters worse, these differing seasonal patterns do not even
recur every seven years because of leap years.
The other major problem is that the position of Easter
changes from year to year. Furthermore, its effect can be
different depending on when it occurs. If it is late, its ef-
fects can overlap, and possibly interact with, those asso-
ciated with the May Day public holiday. Of course, the
I 1997 American Statistical Association
Journal of Business & Economic Statistics
July 1997, Vol. 15, No. 3
Harvey, Koopman, and Riani: Modeling and Seasonal Adjustment of Weekly Observations
. . . . ..
. . . . . . . . . . . . . . .
. ..........
. . . . . . . . . . . . . . . . .
. . . . . . . .. .
? ? ? ? ? ?
. . . . . . . . . . . . . . . . . ...
.. . ? ? ? ? ? ? ? ? - ? ? ?
. . . . . . . . . . . . . . - ? ? ? ? ? ?
...........
Figure~.. ?????????
..........
... ?........... ......'~''~'`
. . . . . . . . . . . . . .
. . . . . . .
. . . . . . ~ '~"
........... ..u
............- ??
-f................... ,... ~ .......~~-
~~~~~~~~~~.
Observatins
on the UKMoney
?-???-????-?????I??
a,..'.''''
'-~'~'~'`'``~-'
?~~`''``~~'''
ct3~~~~~~~~~~~~~~.
.........~
010873...... 0397
030692?????
... .II.,.
Figure. 1.. Weekly Observations on th UK Moe
position of Easter also affects models for monthly observa-
tions, but in this case it is more easily handled, and there
is a considerable literature on its treatment; see Bell and
Hillmer .
The ARIMA-based procedure does not easily generalize
to weekly data. One of the few published articles on weekly
model-based seasonal adjustment, that by Pierce, Grupe,
and Cleveland , got around some of the problems by
using regression to model some of the seasonal effects in
a deterministic way and then grafting on stochastic effects
using an ARIMA model. Our approach is to attack the prob-
lem using structural time series models. Such models can
be interpreted as regressions on functions of time in which
the parameters are time-varying. This makes them a natu-
ral vehicle for handling changing seasonality of a complex
form. Once a suitable model has been fitted, the seasonal
component can be extracted by a smoothing algorithm.
The plan of the article is as follows. Section 1 briefly
reviews the basic structural model as it is typically used for
quarterly and monthly data and explains why it cannot be
directly applied to weekly data. Sections 2 and 3 describe
the two seasonal components that we propose introducing
into a structural model to allow it to cope with weekly data,
and Section 4 explains how the model is handled statisti-
cally. The model is applied to the Bank of England money-
supply data in Section 5. Section 6 presents the conclusions.
1. THE BASIC STRUCTURAL
TIME SERIES MODEL
The basic structural model (BSM) is formulated in terms
of trend, seasonal, and irregular components. All are as-
sumed to be stochastic and driven by serially independent
Gaussian disturbances that are mutually independent. If
there are s seasons in the year, the model is
Yt = At + 't + Et,
NID(0, cr),
where the trend, seasonal, and irregular are denoted by
/it, yt, and et, respectively.
The trend is specified in the following way:
It = At--1 + t-1 + ?It,
r-d NID(O, cr2),
Ct . NID(0,a( ),
where [t is the level and Ot is the slope. The disturbances
,qt and -Observations on December 16, 23, and 30 and January 6 for 1970.--; 19810
1987,.; and 19.902
(b) Observations on December 15, 22, and 229 and January 5 for 1971,-; 1976,-;
1982,.; and 1993,
models of the form (1.1) with s seasons in the year is
7t= Eyj,t,
t= 1,..., T,
where each Yj,t is generated by
- sin Aj cos Aj
where Aj = 27rj/s is frequency, in radians, for j =
1,..., [s/2] and wt and w* are two mutually uncorrelated
white-noise disturbances with zero means and common
variance acr. For s even, [s/2] = s/2, but for s odd,
[s/2] = (s - 1)/2. Note that -y,t is redundant for j = s/2.
The BSM consisting of the stochastic trend in (1.2)
combined with trigonometric seasonality is easily put in
state-space form by defining the (s + 1) x 1 state vector
at = (i-i 1t,
. . .)'. The measurement equa-
tion is then
Yt = (1, 0, zt)at + Et,
where z' = (1, 0, 1, 0....). If the Kalman filter is initiated
with a diffuse prior, as shown by De Jong , an estima-
tor of the state with a proper prior is effectively constructed
from the first s + 1 observations.
1.2 Dummy-Variable
Seasonality
The form of dummy-variable seasonality relevant to the
development later in the article is one in which each ele-
ment in an s x 1 vector yt represents the effect of a partic-
ular month and these effects sum to 0; see Harvey for a discussion of different types of dummy-
variable seasonality. The effects evolve over time according
to a multivariate random walk
t-1i + Xt,
where Xt is an s x 1 vector of serially uncorrelated random
disturbances with zero mean. The zero sum over the year
constraint implies restrictions on the covariance matrix of
disturbances. Specifically
var(Xt) = or(I - (1/s)ii'),
where c2 is the variance parameter that governs the speed
with which the seasonal pattern can change and i is an s x 1
vector of ones. This covariance matrix enforces the con-
straint that i'Xt = 0 by making its variance 0. Thus, if
i'/t_ = 0, then i'yt = 0.
One of the elements of 7t can be dropped from Equation
(1.6); it can always be recovered as minus the sum of the
elements remaining. The state-space form of a BSM with
this kind of seasonality is such that s - 1 elements of yt
appear in the state vector and the measurement equation is
Harvey, Koopman, and Riani: Modeling and Seasonal Adjustment of Weekly Observations
l l | , , , l
l , ' ~ l t J
. . . . . . ...' ' '. . . .. . . ..
, ,. . . . . . . . . ....'..
. . . . . . . . . ..
. . ' ' ' |
Figure 3. Prediction Errors Over the Last Five Years (broken line is when periodic variance not doubled at Christmas).
as in (1.5) with zt being an (s - 1) x 1 vector that yields
the effect of the current month. Thus if the sth element
of yt has been dropped from the state vector, zt has a 1 in
position j for month j, j = 1,..., s-1, and zeros elsewhere,
and all elements equal to -1 for month s.
1.3 Weekly Data
The features of weekly data noted in the first section
mean that the preceding approach cannot be applied di-
rectly. Our solution, like that of Pierce et al. , is to
model the seasonal pattern using two components. The first
component is a function of the date in the year--that is,
the number of days that have passed in the year. Thus, for
example, it takes a particular value on day 358 (which hap-
pens to be Christmas Eve). The second component is a col-
lection of effects associated with public holidays, such as
Easter, that take place on different dates in different years
but always fall on the same day of the week. Once these
components have been specified as deterministic effects so
that they could be handled by regression, it is straightfor-
ward to allow them to evolve stochastically over time by
casting the whole model in state-space form. This is a con-
Table 1. Estimates of Hyperparameters
Constant periodic variance
947 x 10-8
Doubled at Christmas
794 x 10-8
siderable advantage over the approach adopted by Pierce
et al. in which a stochastic ARIMA component is
added to a regression component with no clear connection
between the two.
In what follows, we will refer to the first seasonal ef-
fect, 7t, as the periodic component and to the second, Ot,
as the moving festival component. It is possible to include
an additional periodic component if there is a significant
intramonthly effect.
Although our model is formulated on a daily basis, we
could go further and set up the evolution of the parameters
in continuous time. This is quite natural because the pe-
riodic component is a continuous function. Although con-
tinuous time is an elegant approach, it makes little or no
difference to the form of the implied weekly models, how-
ever, and its use in the present context should be clear from
the general discussion of Harvey .
2. PERIODIC EFFECTS
We wish to model the yearly pattern on a daily basis. For
the moment, we will assume that there are no leap years,
so each year has 365 days.
The periodic component will be modeled as a linear func-
tion of a set of parameters contained in a g x 1 vector y.
If these parameters are fixed, the periodic pattern is fixed,
and we may write the periodic effect for the dth day in the
d = 1,...,365,
Journal of Business & Economic Statistics, July 1997
Table 2. Final State Vector
Description
Level slope
Moving-festival dummies
Coefficients of knots
Silver Jubilee
where Zd is a g x 1 vector of known values. The idea is to
specify (2.1) so as to have g reasonably small-one hopes
much less than 52. There are essentially two options. The
first is to let Yd be a mixture of trigonometric functions. The
second is to model it by a periodic spline. In our application
the second option seems to offer more scope for a parsimo-
nious parameterization,
mainly because of the need to cap-
ture the sharp peak at Christmas. The important point, how-
ever, is that both approaches can be generalized to allow the
seasonal pattern to evolve over time by letting ' be stochas-
tic. Stochastic trigonometric seasonals have long been a part
of structural time series modeling methods. Stochastic, or
time-varying, periodic splines were first used by Harvey and
Koopman to model intraweekly patterns of hourly
electricity demand.
Further scope for cutting down on the number of param-
eters may be afforded if there is an intramonthly pattern.
Again either trigonometric terms or splines may be used.
2.1 Trigonometric Seasonality
A fixed annual pattern may be represented by a trigono-
metric model as follows:
(yj cosAjd+ y sinAjd),
d= 1,...,365,
where Aj = 27rj/365. To include the full set of trigono-
metric terms, as is normally the case with a monthly or
quarterly model, would mean setting k = 182. Pierce et
al. found, however, that setting k = 8 is perfectly
adequate when combined with intramonthly effects.
Now suppose that the periodic pattern changes over time
on a daily basis, irrespective of whether there has been an
observation. Each trigonometric component now evolves as
in (1.3) and (1.4) with the AXj's
specified as in (2.2) and the
subscript t denoting the seasonal effect on the tth day from
the beginning of the sample. Thus the model is modified to
t = 1, 2, ..., Td,
where Td denotes the number of days covered by the sample
period. When a2 = 0, the deterministic model is obtained.
2.2 Periodic Time-Varying Splines
To set up a spline we need to choose h knots in the range
 . Then
d = 1, ..., 365,
where Wd is an h x 1 vector that depends on the position of
the knots and is defined in such a way as to ensure conti-
nuity of the spline from one year to the next-that is, make
it periodic; see the Appendix and Poirier .
To have the periodic seasonal effects summing to 0 over the
year, one of the elements in yt, say the last one, is dropped.
Then, in terms of the formulation in (2.1), -y consists of the
first g = h - 1 elements of -yt, and the ith element in Zd is
Zdi = Wdi - WdhW*i/W*h,
i=1,...,g,
d=1,...,365,
where wj is the ith element of the vector
Note that it is the effects summed over all the days in the
year that come to 0 rather than the effects summed over the
particular days when there are observations. (If we want to
regard d as continuous, then w, is an integral; this can be
evaluated in practice by summing over many points or by
using the formula at the end of Appendix A.)
The splines can be allowed to evolve over time by letting
the parameters follow random walks. If we assume that the
parameters change every day, irrespective of whether or not
there is an observation, we may write
t = 1, 2,...,
where Xt is an h x 1 vector of serially uncorrelated random
disturbances with zero mean and covariance matrix
2 (I - (1/w w,)w
where a2 is the variance parameter that governs the speed
with which the spline can change. This covariance matrix
Harvey, Koopman, and Riani: Modeling and Seasonal Adjustment of Weekly Observations
200121 911010 0711109
I11.1.1I.1.1.11.1.1.
lI.III.II.
.'.'..I.'.
..I.I........
. . . . . . . . . . . . . . . I . . . . . . .
enforces the constraint that wxt
= 0. Note that, if there
is a knot for each day, the seasonal dummy model of (1.6)
is obtained with h = s and w, = i.
As before, one of the elements of ^lt can be dropped to
give a g x 1 vector "yt. The effect in the tth day from the
beginning of the sample is then
where the notation t(d) for the subscript of z stresses de-
pendence on the day of the year.
In some circumstances, a part of the periodic pattern may
change more rapidly than the rest of the pattern. For money
demand, this seems to be the case with the Christmas effect.
This phenomenon can be modeled by letting the parameters
at the knots close to the points at which rapid changes take
place be subject to relatively larger disturbances. Thus, sup-
pose that the first m elements in 7vy have associated with
them a variance of a , and the second n = h - m have a
larger variance, an. The covariance matrix of Xt then be-
where Wm consists of the first m elements of w, and w,
contains the last n; that is, w, = (w', w')'. This additional
flexibility is an attractive feature of the spline formulation.
Again, w'xt = 0.
2.3 Intramonthly
Pierce et al. observed significant intramonthly ef-
fects in U.S. monetary aggregates, primarily due to the
higher money supply toward the end of the month when
wages are paid. Such effects were captured by the inclu-
sion of trigonometric terms as in (2.2) but with d denoting
the day of the month and 365 replaced by the number of
days in the month. An intramonthly pattern of this form
can be made time-varying exactly as in Subsection 2.1.
An additional hyperparameter
is needed to fulfil the role
It is only worth using intramonthly effects if most of
the months display a similar pattern. This may well be a
reasonable assumption for monetary aggregates, although
December may be different if people tend to be paid before
the Christmas break.
Intramonthly effects can also be modeled by a time-
varying periodic spline. A trigonometric intramonthly com-
ponent can be used together with an intrayearly spline and
vice versa.
2.4 Leap Years
There are two ways to handle leap years. The first is
to set the periodic effect for February 29 the same as for
Journal of Business & Economic Statistics, July 1997
Co . . . . . . ..
llA.........
... ... ....
................
Figure 5. Smoothed Periodic Component Over the Last Four Years, Starting in February 1990, With Position of Knots (e).
February 28--that is, to regard day 59 as occurring twice.
By proceeding in this way we ensure that Christmas falls
at exactly the same point every year--that is, day 359.
Note that day 59 must be counted twice in the summation
A slightly different approach is to let the leap-year effect
be spread throughout the whole year. For the trigonometric
model, this is easily accomplished by replacing 365 by 366
in the Ai's. For the spline, we modify Wd, and hence Zt(d),
by multiplying the knot positions by 366/365.
3. MOVING FESTIVALS:
VARIABLE-DUMMY
The effect of each public holiday may be modeled by a
set of dummy variables that are assigned to the surrounding
weeks. The day of the year on which the holiday falls, and
hence the days on which the surrounding observations fall,
depends on the calendar.
Suppose that m dummy variables are used to pick up
public-holiday effects. Each effect takes up seven days.
Thus the number of days remaining is, averaging over four
km+l = 365.25 - 7m.
These days must be allocated an effect to counterbalance
effect of the public holidays, thereby making the component
sum to 0. Averaging over four years avoids a slight end-
of-year discontinuity associated with leap years. Thus, if
01,..., 0m denote the holiday effects, the nonholiday factor
0m+1 = -(81
+ Om)7/km+l.
To allow the dummy-variable
effects to evolve over time,
we let them follow constrained random walks as in Subsec-
tion 2.4. There is no need to include 0m+1 because it may
be inferred from (3.2). Thus, following the treatment of the
daily-effects model as set out by Harvey ,
Ojt = Oj,t-1- + vjt,j = 1,..., m,
t = 1,..., Td,
where vjt is a zero mean, serially uncorrelated disturbance
with variance
2 (1 - 49/K),
j = 1, .. ,m,
where K = 49m + km+12 The covariances between distur-
bances are given by
cov(vjvt) = -ov49/K,
j, 1= 1,...,
The model may be generalized to allow some effects to
change more rapidly by giving them a larger variance.
STATISTICAL TREATMENT OF THE MODEL
The full daily model is
Yt = At + --t
+ Ot $+ Et,
t = 1, 2,..., Td,
Harvey, Koopman, and Riani: Modeling and Seasonal Adjustment of Weekly Observations
....I..,.,II,.,I,.'I
'I...................I.I
Figure 6. Smoothed Moving-Festival
Component Over the Last Four Years, Starting in July 1989.
with the trend defined as in (1.2) and 7t and Ot denoting
the periodic and moving-festival effects. The irregular term,
et, is assumed to be white noise, and the disturbances in
the different components are uncorrelated with each other.
The model is easily put into state-space form by letting the
state vector be at = (pt, /t, 7It, 0')'. The transition equation
is made up of (1.2), (2.6), and (3.3), and the measurement
equation is
Yt = (1, 0, t(d), x(c))at
t = 1, ...,Td,
where Zt(d) depends on the number of days that have passed
in the year and xt(c) depends on the calendar. The role of
xt(c) is to pick out from the variable dummy vector, O6, the
appropriate element or elements if there is no direct holiday
effect and (3.2) is relevant.
The preceding formulation is independent of the observa-
tions. These can be weekly, which is the focus of attention
here, or they can arrive on various days with no particular
pattern. When there is no observation on a particular day,
the Kalman filter simply treats it as a missing observation:
There is no difficulty in carrying out prediction, smoothing,
and estimation. The hyperparameters-that is, the variances
of the disturbances--can be estimated by maximizing the
(exact) log-likelihood function computed via the Kalman fil-
ter using the prediction error decomposition; see Appendix
B. The use of a "square root" filter is recommended because
it appears to be much more stable for weekly data. Numer-
ical optimization needs to be carried out with respect to the
hyperparameters
relative to the variance of the irregular,
which can be concentrated out of the likelihood function.
With weekly data, the observations are, for the most part,
equally spaced. It is therefore more efficient to convert the
model to a weekly basis. If y, denotes the observation in
week 7 of the sample, we can write y, = wT, + Y, + 0-, +
Er, 7- = 1,2,... ,T, and the transition equation is modified
appropriately.
For parameters evolving according to random
walks, as in (2.6) and (3.3), all that needs to be done is
to observe that the variance for a weekly model will be
seven times the variance for a daily model. For the local
linear trend, the modification to the covariance matrix of the
trend disturbances, ri and (t in (1.2), was given by Harvey
 . In the case of the trigonometric formulation,
the frequencies must be multiplied by 7, and if there is an
intramonthly effect, it is necessary to take account of the
fact that different months may have different numbers of
days. There are occasions in which a figure is not recorded
on the usual day of the week due to a holiday. In such cases
it is straightforward
to modify the state-space formulation
to make allowance for the different time intervals involved.
This generally involves multiplying disturbance variances
(and frequencies, if relevant) by a factor of p/7, where p is
the number of days since the last observation.
Estimates of the various components in the model us-
ing all the observations can be computed by smoothing.
The algorithm devised by Koopman allows smooth-
ing to be carried out with computational efficiency without
Journal of Business & Economic Statistics, July 1997
Figure 7. Smoothed Estimates of the Effect of Easter: Wednesday
Before (solid line); Wednesday After (dashed line).
excessive storage requirements; see Appendix B. Smooth-
ing forms the basis for seasonal adjustment because all that
needs to be done is to remove the periodic and moving-
festival smoothed seasonal components. Note that the best
estimate of the seasonal effect at the end of the series is
given by filtering, so a seasonally adjusted figure can be
provided as each new observation becomes available. This
figure can subsequently be revised as further observations
become available.
U.K. MONEY SUPPLY
To get some idea of the seasonal pattern in the MO series
shown in Figure 1, it was subject to simple detrending using
the Hodrick-Prescott filter. This filter can be obtained very
easily as the smoother for a local linear-trend model-that
is, (1.1) and (1.2) without the seasonal-in which 0r2 =
and C /a, = .000625. A plot of the observations in each
year shows clear and permanent changes in the seasonal
pattern. This is particularly marked at Christmas. Figure 2,
page 356, shows the pattern of detrended observations over
the Christmas period when Christmas falls on a Friday and
on a Saturday. At the beginning of the sample, the peak is
about 5% above the trend, whereas at the end it is about
10% . The same features appear when Christmas falls on
other days of the week.
The periodic component was modeled using a time-
varying spline. A good deal of experimentation was car-
ried out in positioning the knots and dummy variables. To
capture the peaks at times such as Christmas, a relatively
large number of knots are needed in a short period. At
other times, the seasonal pattern changes quite slowly and
only a few knots are needed. Similar considerations ap-
plied in modeling the intradaily electricity demand of Har-
vey and Koopman . Here the situation is more com-
plicated because the interaction between the positioning of
the dummy variables needed to capture the moving festivals
and the knots used to pick up the rest of the seasonal pat-
tern. The final specification had 19 knots and was decided
by factors such as the "t ratios" of the knot coordinates
and dummies, diagnostics and residual plots, goodness-of-
fit statistics, and forecasting performance. Increasing the
Table 3. Diagnostics: Residual Autocorrelations
Constant periodic variance
Doubled at Christmas
number of knots gives a better fit and reduces the residual
serial correlation at lags 1 and 2 and at the annual lag of 52
(and 53). The less smooth the pattern is and the more knots
are included, however, the less easy it is to distinguish the
periodic pattern from the moving-festival pattern.
All moving public holidays fall on Mondays, except for
Good Friday, and the moving-festival dummy variables
were specified as follows:
1. Easter-the two weeks before and the week after
2. May Day-the week before and the week after . When we doubled the variance
of the Christmas knots, we found that the residuals close to
Christmas were much more akin to residuals in other parts
of the year. Furthermore, the unstandardized
prediction er-
rors were also smaller around Christmas; see Figure 3, page
357. (It could be argued that one of the reasons the Christ-
mas effect changes so rapidly is because it is different for
Christmas falling on different days of the week. We were
unable to capture such an effect by additional dummies; in-
deed, given that each day occurs only three or four times in
our sample, this may be impossible to do. An examination
of Fig. 2 and the plots for other days, however, indicates
that the evolution over time far outweighs any possible day-
of-the-week effect.)
Table 4. Diagnostics: Box-Ljung Statistics
Constant periodic variance
Doubled at Christmas
NOTE: Q(P) is based on first P residual autocorrelations.
Harvey, Koopman, and Riani: Modeling and Seasonal Adjustment of Weekly Observations
Table 5. Diagnostics: Normality Test Statistics
Constant periodic variance
Doubled at Christmas
Table 1, page 357, shows the estimated hyperparameters
for the specification with and without the doubling of the
periodic variance at Christmas. The q's denote hyperparam-
eters relative to the variance of the irregular. Because of the
sharp change in the trend in the late 1970s, it turned out
to be more satisfactory to drop the first 400 observations
in estimating the hyperparameters.
They were retained for
all other purposes, however. For the reasons given in the
previous paragraph and confirmed in the following discus-
sion, the doubled variance model is our preferred specifica-
tion. Table 2, page 358, shows the estimates of the state for
this model at the end of the sample, together with their t
ratios-that is, the estimates divided by the corresponding
root mean squared errors. In assessing the relative impor-
tance of the various estimates from their t ratios, it must be
remembered that they are liable to change over time. Thus,
although some knots are not significant at the end of the
sample, they may have been in the past.
Figure 4, page 359, graphs the smoothed trend. Its rela-
tively slow changes seem to be quite suitable for this series.
Figure 5, page 360, shows the smoothed pattern of the pe-
riodic component over the last four years, and Figure 6,
page 361, shows the moving-festival component. Note that
there are very few knots in periods when there are public
holidays-for example, in April and May. Small changes
in both periodic and moving-festival patterns are apparent
even over a short period of time. Figure 7 illustrates the
much more dramatic changes that can take place over a
longer period. It shows the evolution of the dummies in
the weeks before and after Easter over the full sample. As
with the Christmas effect, there is a doubling effect, with
a movement from around 1.5% of the underlying level to
The equation standard error, s, which is the square root
of the one-step-ahead prediction-error
variance, is normally
used as a measure of goodness of fit, but here there is
a problem because the nature of the model means that it
changes over time and never goes to a steady state. A rough
idea of the size of s can be gauged from Figure 3.
Residual serial correlation can be assessed by the autocor-
relations at lag 7, denoted r(7), and the Box-Ljung statis-
tics, Q(P), based on the first P autocorrelation. Tables 3
and 4 report these statistics for the last five years. It seems
to be diftficult to eliminate serial correlation completely un-
less many knots are used, and our preference is to keep the
number of knots reasonably small. The model with constant
periodic variance shows quite strong serial correlation at lag
52, and the plot of the residual correlogram in Figure 8(a)
confirms the impression of some residual seasonal effects.
Figure 8(b) indicates that this feature is eliminated in the
model with the periodic variance doubled around Christ-
mas. There is now more serial correlation, however, at lags
1 and 2. If this were felt to be of any practical importance,
it could be removed by letting the disturbance follow a low-
order autoregressive moving average process.
Table 5 reports the skewness and kurtosis moment test
statistics and the Bowman-Shenton normality test statistic.
When the model is correctly specified with Gaussian distur-
bances, the skewness and kurtosis statistics are asymptoti-
cally distributed as chi squares with 1 df, whereas Bowman-
Shenton has a chi-squared distribution with 2 df; see Har-
vey . The extremely high kurtosis is due to
the Christmas effect, but it is reduced to a reasonable level
when the periodic variance is doubled around Christmas.
The fact that the model is successful comes out in the
predictions over the last few years. Figure 9 shows the one-
step-ahead predictions obtained by filtering. This effectively
gives the same information as the prediction-error
Figure 3, but it brings home more clearly how accurate the
predictions are, being less than .5% of the level most of
the time. Even more impressive is Figure 10, which shows
the multistep predictions made from September 9, 1992.
Overall the model is successful in providing a relatively
parsimonious representation of the data.
1219I26I33
eiulCreorm
a osatProi
Journal of Business & Economic Statistics, July 1997
2480612 0502
290411 1006
141205 241306 0408
081206 1901
Figure 9. One-Step-Ahead Predictions (- -) and Actual Values that approximates an unknown function
f(x). Periodic cubic splines are subjected to special end-
conditions. The cubic spline is defined as a set of polyno-
mial functions differentiable up to order 3 with the first two
derivatives continuous. The set of coordinates (4x, y ), with
i = 0, 1,..., k, will be referred to as the set of knot points
associated with the mesh (x0, ... , k). In this appendix, the
knot coordinates are treated as fixed and known. Section
2.2 describes how the
's are estimated when they are al-
lowed to change over time. It will be shown that the cubic
spline function is derived as a set of linear equations; see
also Poirier .
Let us assume that the mesh is in ascending order,
Xto < x <-... < x .
Let h, = x3 -xj_,j
= 1,...,k,
and let dj(x) and dj(x)
denote the first and second derivatives, respectively, of the
spline function g(x) calculated in the interval [x•_, xt]. The
cubic spline function is a mixture of polynomials of order
3, so its second derivative within [x_-, x] will be linear;
j = 1,..., k.
The scalar aj is the second derivative of the spline func-
tion at the knot point x; that is, aj = d2(x ). Starting from
(A.2), the cubic spline and the periodic spline are easily
derived by the following steps:
1. Expressions for the first derivative function and the
cubic spline function g(x) are obtained via standard rules
of integration. The spline function is forced to cross the
knots; that is, g(x)
= y and g(x>_l) = yj_. This leads
[(x4 x) )2 - hj]
- x _1 -1)
6 aj (A.4)
with x_1 < x < x,j = 1, 2, .. ., k.
2. The spline function (A.3) can be expressed in vector
notation via
gj(x) = r yt + s a,
where a= (ao,..., ak)',yt
t)', and the vectors
rj and sj are equal to 0 except for their jth and (j + 1)th
elements, which correspond to the appropriate weights
3. The continuity restriction also applies to the first
derivative (A.4), dc (xr) = dj+1(x ). After some minor ma-
nipulations, we obtain a set of k - 1 linear restrictions
aj_1 + 2aj +
hj(h3 + h+1)
hj+l(hj + h+1)'
j=1,2,...,k-1.
4. A system of k-1 linear equations with k+1 unknowns
aj cannot be solved unless two linear restrictions are added.
Poirier suggested setting ao = ak = O, which he
defined as a natural condition for a spline. With these two
additional constraints the system of equations (A.6) can be
represented in matrix notation as
Journal of Business & Economic Statistics, July 1997
h3 (h3+h4)
hk(hk-1+hk)
5. The matrices P and Q have dimension (k + 1) x
(k + 1). Note that the first and the last rows of P and Q
represent the natural constraints a0o = ak = 0. The solution
a = P-1Qyt
so that (A.5) becomes
gj(x) = w yt,
w/ = r/ + sP
This shows that, given a set of k knots with a particular
vector yt, the natural spline g(x) can be calculated for any
t < x < xtk. Note that if x equals
, O i j ? k, vector
wj is 0 except for its jth element, which equals unity and
hence g(xj) = ty.
6. The cubic spline becomes periodic when the first and
the last knots are restricted to be the same. The continuity
is enforced by letting the corresponding first and second
derivatives to be the same as well; that is,
t = ytk, di(xo) = dk (Xtk), d 2xto) = d2(Xtk). (A.13)
The second restriction of (A.13) implies
- k-1 + 2ak +
hk(hl + hk)
hl(hl + hk)'
which can be added to the set of linear restrictions (A.6).
The last restriction of (A.13) sets ao = ak. Therefore, the
natural constraints are no longer required because we now
have a system of k linear restrictions and k unknowns. The
(k x k) matrices PP and Q, for a periodic spline become
Harvey, Koopman, and Riani: Modeling and Seasonal Adjustment of Weekly Observations
h2(h2+h3 )
h3(h2+h3 )
hk(hk-l+hk)
Furthermore, the (k x 1) vectors a, y, rj, and sj,j
1, ..., k, are adjusted appropriately, also with respect to the
first restriction of (A.13).
In the main body of the article vector w. is defined in
where wj, j= 1,..., k, must be computed even if the eval-
uation of the spline at position j is not required. Therefore,
when k is large, the calculation of w, may become a com-
putational burden. An alternative expression for w, is
where r, =
=1 rj and s =
j=1 sj can be analytically
derived as
t t h3 - h3
t - t -3 h3
h(1 - h) + hk(1-
APPENDIX B: STATE-SPACE
METHODS AND
SEASONAL ADJUSTMENT
The full model (4.1) can be put in state-space form; that
Ztat + Gtut,
NID(O, I),
= Ttat + Htut,
t = 1,..., T,
where Zt is given in (4.2) and the matrices Tt, Gt, and Ht
are constructed straightforwardly.
Note that the matrices Gt
and Tt are time-invariant, but matrix Ht is time-varying
because the variances of the periodic effect are forced to
increase around the Christmas period. The disturbance vec-
tor ut is the stack of all disturbances associated with the
unobserved components of the model including the irreg-
ular et. The initial state a1 is treated as a random vector
generated from a diffuse distribution.
The Kalman filter, or its more stable counterpart the
"square root" Kalman filter, is used for the evaluation of the
likelihood and for the calculation of one-step-ahead predic-
tion errors. The Kalman filter is given by
vt = yt - Ztatit-1,
ZtPtlt-lZ't
Kt = TtPtlt_lZtft-1,
Ttatit-1 + Ktvt,
Pt+l1t = TtPtt-T
with the initializations allo = 0 and P110 = ,Ii, where
n is a suitably chosen large number. The vector atlt-1 is
the one-step-ahead prediction of the state at with its mean
squared error matrix Ptlt-1. The one-step-ahead prediction
error and its variance are given by vt and ft, respectively.
The vector Kt is referred to as the Kalman gain. Usually,
the Kalman filter is computationally not very demanding
but Model (4.1) requires a large state vector that leads to a
computational effort with respect to Ptlt-1. Of course, the
computations take longer as the number of observations in-
A state smoothing algorithm is designed to compute
full-sample estimates of the state vector. The estimated
trend and periodic components can be extracted from the
smoothed state vector, and they can be graphically repro-
duced as part of a validation procedure of the estimated
model. Seasonal adjustment procedures remove seasonal
and periodic variation from the observed series and, there-
fore, in the context of state-space models, they require a
Table B1. Computational Performance of Smoothing
Multiplications
De Jong 
Koopman 
Journal of Business & Economic Statistics, July 1997
state smoother. Smoothing algorithms are computationally
expensive, especially when the state vector is large, and they
require much storage space because a selection of Kalman
filter quantities needs to be stored for t = 1,... , T.
We consider two different state smoothers, proposed by
De Jong and Koopman . Table B.1 reports the
number of multiplications for each time index t, the num-
ber of values to be stored for each time index t, and to-
tal computer time required for smoothing a series of 1,500
observations on a Pentium processor with clock speed 90
MHz. The model considered is (4.1) with 20 knots for
the periodic spline and 10 stochastic dummy variables for
the moving-festival effects. The results show dramatically
that the smoothing algorithm of Koopman outper-
forms the algorithm of De Jong with respect to all
indicators. Koopman's algorithm does not give the mean
squared errors of the smoothed estimators of the state
vector, but for many applications this is not necessary.
Koopman's smoothing algorithm is a two-step approach.
First, a backward disturbance smoother is applied; that is,
et = vt/ft - K rt, rt-1 = Z'et + T rt, t = T, ..., 1, with
initialization rT = 0. The Kalman filter only needs to
store the scalar vt/ft and the vector Kt, t = 1,... ,T.
The storage space can be overwritten to store the vector
nt = HtHIrt. Second, the forward recursion at+llT
TtatT+nt, t = 1, ... , T-1, must be used with initialization
a IT = all0 + Pll0ro. The storage space can be overwritten
by the smoothed state vector atlT.
[Received May 1995. Revised March 1996.]