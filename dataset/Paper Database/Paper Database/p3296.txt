Recommender Systems
Linyuan L¨ua,b,c, Mat´uˇs Medob, Chi Ho Yeungb,d, Yi-Cheng Zhanga,b,c,∗, Zi-Ke Zhanga,b,c,
Tao Zhoua,b,c,e
aInstitute of Information Economy, Hangzhou Normal University, Hangzhou, 310036, PR China
bDepartment of Physics, University of Fribourg, Fribourg, CH-1700, Switzerland
cWeb Sciences Center, University of Electronic Science and Technology of China, Chengdu, 610054, PR
dThe Nonlinearity and Complexity Research Group, Aston University, Birmingham B4 7ET, United
eBeijing Computational Science Research Center, Beijing, 100084, PR China
The ongoing rapid expansion of the Internet greatly increases the necessity of eﬀective
recommender systems for ﬁltering the abundant information. Extensive research for recommender systems is conducted by a broad range of communities including social and
computer scientists, physicists, and interdisciplinary researchers. Despite substantial theoretical and practical achievements, uniﬁcation and comparison of diﬀerent approaches are
lacking, which impedes further advances. In this article, we review recent developments in
recommender systems and discuss the major challenges. We compare and evaluate available
algorithms and examine their roles in the future developments. In addition to algorithms,
physical aspects are described to illustrate macroscopic behavior of recommender systems.
Potential impacts and future directions are discussed. We emphasize that recommendation
has a great scientiﬁc depth and combines diverse research ﬁelds which makes it of interests
for physicists as well as interdisciplinary researchers.
recommender systems, information ﬁltering, networks
∗Corresponding author
Email address: (Yi-Cheng Zhang)
 
November 27, 2024
 
Introduction
Real Applications of Recommender Systems
Netﬂix Prize . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Major challenges
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Deﬁnitions of Subjects and Problems
Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Bipartite Networks and Hypergraphs . . . . . . . . . . . . . . . . . . . . .
Recommender Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Evaluation Metrics for Recommendation . . . . . . . . . . . . . . . . . . .
Accuracy Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Rank-weighted Indexes . . . . . . . . . . . . . . . . . . . . . . . . .
Diversity and Novelty . . . . . . . . . . . . . . . . . . . . . . . . . .
Coverage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Similarity-based methods
Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
User similarity
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Item similarity
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Slope One predictor . . . . . . . . . . . . . . . . . . . . . . . . . . .
How to deﬁne similarity
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
Rating-based similarity . . . . . . . . . . . . . . . . . . . . . . . . .
Structural similarity
. . . . . . . . . . . . . . . . . . . . . . . . . .
Similarity involving external information . . . . . . . . . . . . . . .
Dimensionality Reduction Techniques
Singular Value Decomposition (SVD) . . . . . . . . . . . . . . . . . . . . .
Bayesian Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Probabilistic Latent Semantic Analysis (pLSA) . . . . . . . . . . . . . . . .
Latent Dirichlet Allocation (LDA) . . . . . . . . . . . . . . . . . . . . . . .
Diﬀusion-based methods
Heat diﬀusion algorithm (HDiﬀ) . . . . . . . . . . . . . . . . . . . . . . . .
Multilevel spreading algorithm (MultiS)
. . . . . . . . . . . . . . . . . . .
Probabilistic spreading algorithm (ProbS)
. . . . . . . . . . . . . . . . . .
Hybrid spreading-relevant algorithms . . . . . . . . . . . . . . . . . . . . .
Social ﬁltering
Social Inﬂuences on Recommendations
. . . . . . . . . . . . . . . . . . . .
Trust-Aware Recommender Algorithms . . . . . . . . . . . . . . . . . . . .
Adaptive Social Recommendation Models . . . . . . . . . . . . . . . . . . .
Meta approaches
Tag-aware methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Time-aware methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Iterative reﬁnement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Hybrid algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Performance evaluation
10 Outlook
References
1. Introduction
Thanks to computers and computer networks, our society is undergoing rapid transformation in almost all aspects. We buy online, gather information by search engines and live
a signiﬁcant part of our social life on the Internet. The fact that many of our actions and
interactions are nowadays stored electronically gives researchers the opportunity to study
socio-economical and techno-social systems at much better level of detail. Traditional “soft
sciences”, such as sociology or economics, have their fast-growing branches relying on the
study of these newly available massive data sets . Physicists, with their long experience with data-driven research, have joined this trend and contributed to many ﬁelds such
as ﬁnance , network theory and social dynamics which are outside
their traditional realm. The study of recommender systems and information ﬁltering in
general is no exception with the interest of physicists steadily increasing over the past
decade. The task of recommender systems is to turn data on users and their preferences
into predictions of users’ possible future likes and interests. The study of recommender
systems is at crossroads of science and socio-economic life and its huge potential was ﬁrst
noticed by web entrepreneurs in the forefront of the information revolution. While being
originally a ﬁeld dominated by computer scientists, recommendation calls for contributions
from various directions and is now a topic of interest also for mathematicians, physicists,
and psychologists. For instance, it is not a coincidence that an approach based on what
psychologists know about human behavior scored high in a recent recommendation contest
organized by the commercial company Netﬂix .
When computing recommendations for a particular user, the very basic approach is
to select the objects favored by other users that are similar to the target user.
this simple approach can be realized in a multitude of ways—this is because the ﬁeld of
recommendation lacks general “ﬁrst principles” from which one could deduce the right way
to recommend. For example, how best to measure user similarity and assess its uncertainty?
How to aggregate divergent opinions from various users? How to handle users for whom
little information is available? Should all data be trusted equally or can one detect reckless
or intentionally misleading opinions? These and similar issues arise also when methods
more sophisticated than those based on user similarity are used. Fortunately, there exist
a number of real data sets that can be used to measure and compare performance of
individual methods. In consequence, similarly to physics, it is the experiment what decides
which recommendation approach is good and which is not.
It would be very misleading to think that recommender systems are studied only because
suitable data sets are available. While the availability of data is important for empirical
evaluation of recommendation methods, the main driving force comes from practice: electronic systems give us too much choice to handle by ourselves. The interest from industry
is hardly surprising—an early book on the nascent ﬁeld of recommendation, Net Worth by
John Hagel III and Marc Singer , clearly pointed out the enormous economic impact of
“info-mediaries” who can greatly enhance individual consumers’ information capabilities.
Most e-commerce web sites now oﬀer various forms of recommendation—ranging from simply showing the most popular items or suggesting other products by the same producer to
complicated data mining techniques. People soon realized that there is no unique best recommendation method. Rather, depending on the context and density of the available data,
diﬀerent methods adapting to particular applications are most likely to succeed. Hence
there is no panacea, and the best one can do is to understand the underlying premises and
recommender mechanisms, then one can tackle many diverse application problems from
the real life examples. This is also reﬂected in this review where we do not try to highlight
any ultimate approach to recommendation. Instead, we review the basic ideas, methods
and tools with particular emphasis on physics-rooted approaches.
The motivation for writing this review is multifold. Firstly, while extensive reviews
of recommender systems by computer scientists already exists , the view of
physicists is diﬀerent from that of computer scientists by using more the complex networks
approach and adapting various classical physics processes (such as diﬀusion) for information
ﬁltering. We thus believe that this review with its structure and emphasis on respective
topics can provide a novel point of view. Secondly, the past decade has already seen a
growing interest of physicists in recommender systems and we hope that this review can
be a useful source for them by describing the state of the art in language which is more
familiar to the physics community. Finally, the interdisciplinary approach presented here
might provide new insights and solutions for open problems and challenges in the active
ﬁeld of information ﬁltering.
This review is organized as follows. To better motivate the problem, In Section 2 we
begin with a discussion of real applications of recommender systems. Next, in Section 3 we
introduce basic concepts—such as complex networks, recommender systems, and metrics
for their evaluation—that form a basis for all subsequent exposition. Then we proceed to
description of recommendation algorithms where traditional approaches (similarity-based
methods in Section 4 and dimensionality reduction techniques in Section 5) are followed by
network-based approaches which have their origin in the random walk process well known
to all physicists (in Section 6). Methods based on external information, such as social
relationships (in Section 7), keywords or time stamps (in Section 8), are also included. We
conclude with a brief evaluation of methods’ performance in Section 9 and a discussion on
the outlook of the ﬁeld in Section 10.
2. Real Applications of Recommender Systems
Thanks to the ever-decreasing costs of data storage and processing, recommender systems gradually spread to most areas of our lives. Sellers carefully watch our purchases to
recommend us other goods and enhance their sales, social web sites analyze our contacts
to help us connect with new friends and get hooked with the site, and online radio stations
remember skipped songs to serve us better in the future (see more examples in Table 1).
In general, whenever there is plenty of diverse products and customers are not alike, personalized recommendation may help to deliver the right content to the right person. This
is particularly the case for those Internet-based companies that try to make use of the
so-called long-tail of goods which are rarely purchased yet due to their multitude they
can yield considerable proﬁts (sometimes they are referred to as “worst-sellers”). For ex-
ample on Amazon, between 20 to 40 percent of sales is due to products that do not belong
to the shop’s 100 000 most saled products . A recommender system may hence have
signiﬁcant impact on a company’s revenues: for example, 60% of DVDs rented by Netﬂix
are selected based on personalized recommendations.1
As discussed in , recommender systems not only help decide which products to
oﬀer to an individual customer, they also increase cross-sell by suggesting additional products to the customers and improve consumer loyalty because consumers tend to return to
the sites that best serve their needs (see for an empirical analysis of the impact of
recommendations and consumer feedback on sales at Amazon.com).
Since no recommendation method serves best all customers, major sites are usually
equipped with several distinct recommendation techniques ranging from simple popularitybased recommendations to sophisticated techniques many of which we shall encounter in
the following sections.
Further, new companies emerge (see, for example, string.com)
which aim at collecting all sorts of user behavior (ranging from pages visited on the web
and music listened on a personal player to “liking” or purchasing items) and using it to
provide personalized recommendations of diﬀerent goods or services.
2.1. Netﬂix Prize
In October 2006, the online DVD rental company Netﬂix released a dataset containing
approximately 100 million anonymous movie ratings and challenged researchers and practitioners to develop recommender systems that could beat the accuracy of the company’s
recommendation system, Cinematch . Atlhough the released data set represented only
a small fraction of the company’s rating data, thanks to its size and quality it fast became
a standard in the data mining and machine learning community. The data set contained
ratings in the integer scale from 1 to 5 which were accompanied by dates. For each movie,
title and year of release were provided. No information about users was given. Submitted
predictions were evaluated by their root mean squared error (RMSE) on a qualifying data
set containing over 2,817,131 unknown ratings. Out of 20,000 registered teams, 2,000 teams
submitted at least one answer set. On 21 September 2009, the grand prize of $1,000,000
was awarded to a team that overperformed the Cinematch’s accuracy by 10%. At the
time when the contest was closed, there were two teams that achieved the same precision.
The prize was awarded to the team that submitted their results 20 minutes earlier than
the other one. (See for a popular account on how the participants struggled with the
challenge.)
There are several lessons that we have learned in this competition . Firstly, the
company gained publicity and a superior recommendation system that is supposed to
improve user satisfaction. Secondly, ensemble methods showed their potential of improving
accuracy of the predictions.2 Thirdly, we saw that accuracy improvements are increasingly
1As presented by Jon Sanders (Recommendation Systems Engineering, Netﬂix) during the talk “Research Challenges in Recommenders” at the 3rd ACM Conference on Recommender Systems .
2The ensemble methods deal with the selection and organization of many individual algorithms to
achieve better prediction accuracy. In fact, the winning team, called BellKor’s Pragmatic Chaos, was a
What is recommended
books/other products
Perfectmatch
CareerBuilder
StumbleUpon
Popular sites using recommender systems.
Besides, there are also some companies devoting themselves to recommendation techniques, such as Baifendian (www.baifendian.com), Baynote
(www.baynote.com), ChoiceStream (www.choicestream.com), Goodrec (www.goodrec.com), and others.
demanding when RMSE drops below a certain level. Finally, despite the company’s eﬀort,
anonymity of its users was not suﬃciently ensured . As a result, Netﬂix was sued by
one of its users and decided to cancel a planned second competition.
2.2. Major challenges
Researchers in the ﬁeld of recommender systems face several challenges which pose
danger for the use and performance of their algorithms. Here we mention only the major
1. Data sparsity. Since the pool of available items is often exceedingly large (major online bookstores oﬀer several millions of books, for example), overlap between two users
is often very small or none. Further, even when the average number of evaluations
per user/item are high, they are distributed among the users/items very unevenly
(usually they follow a power-law distribution ) and hence majority of users/items
may have expressed/received only a few ratings. Hence, an eﬀective recommender
algorithm must take the data sparsity into account .
2. Scalability. While the data is mostly sparse, for major sites it includes millions of
users and items. It is therefore essential to consider the computational cost issues
and search for recommender algorithms that are either little demanding or easy to
parallelize (or both). Another possible solution is based on using incremental versions
of the algorithms where, as the data grows, recommendations are not recomputed
globally (using the whole data) but incrementally (by slightly adjusting previous
recommendations according to the newly arrived data) . This incremental
approach is similar to perturbation techniques that are widely used in physics and
mathematics .
3. Cold start. When new users enter the system, there is usually insuﬃcient information
to produce recommendation for them. The usual solutions of this problem are based
on using hybrid recommender techniques (see Section 8.4) combining content and
collaborative data and sometimes they are accompanied by asking for some
base information (such as age, location and preferred genres) from the users. Another
way is to identify individual users in diﬀerent web services. For example, Baifendian
developped a technique that could track individual users’ activities in several ecommerce sites, so that for a cold-start user in site A, we could make recommendation
according to her records in sites B, C, D, etc.
4. Diversity vs. accuracy. When the task is to recommend items which are likely to be
appreciated by a particular user, it is usually most eﬀective to recommend popular
and highly rated items. Such recommendation, however, has very little value for the
users because popular objects are easy to ﬁnd (often they are even hard to avoid)
without a recommender system. A good list of recommended items hence should
combined team of BellKor , Pragmatic Theory and BigChaos (of course, it was not a simple
combination but a sophisticated design), and each of them consists of many individual algorithms. For
example, the Pragmatic Theory solution considered 453 individual algorithms.
contain also less obvious items that are unlikely to be reached by the users themselves
 . Approaches to this problem include direct enhancement of the recommendation
list’s diversity and the use of hybrid recommendation methods .
5. Vulnerability to attacks. Due to their importance in e-commerce applications, recommender systems are likely targets of malicious attacks trying to unjustly promote
or inhibit some items . There is a wide scale of tools preventing this kind of behavior, ranging from blocking the malicious evaluations from entering the system to
sophisticated resistant recommendation techniques . However, this is not a easy
task since the strategies of attackers also get more and more advanced as the developing of preventing tools. As an example, Burke et al. introduced eight attacking
strategies, which are further divided into four classes: basic attack, low-acknowledge
attack, nuke attack and informed attack.
6. The value of time. While real users have interests with widely diverse time scales (for
example, short term interests related to a planned trip and long term interests related to the place of living or political preferences), most recommendation algorithms
neglect the time stamps of evaluations. It is an ongoing line of research whether and
how value of old opinions should decay with time and what are the typical temporary
patterns in user evaluations and item relevance .
7. Evaluation of recommendations. While we have plenty of distinct metrics (see Section
3.4), how to choose the ones best corresponding to the given situation and task is still
an open question. Comparisons of diﬀerent recommender algorithms are also problematic because diﬀerent algorithms may simply solve diﬀerent tasks. Finally, the
overall user experience with a given recommendation system—which includes user’s
satisfaction with the recommendations and user’s trust in the system—is diﬃcult to
measure in “oﬄine” evaluation. Empirical user studies thus still represent a welcome
source of feedback on recommender systems.
8. User interface. It has been shown that to facilitate users’ acceptance of recommendations, the recommendations need to be transparent : users appreciate when
it is clear why a particular item has been recommended to them. Another issue is
that since the list of potentially interesting items may be very long, it needs to be
presented in a simple way and it should be easy to navigate through it to browse
diﬀerent recommendations which are often obtained by distinct approaches.
Besides the above long-standing challenges, many novel issues appear recently. Thanks
to the development of methodlogy in related branches of science, especially the new tools
in network analysis, scientists started to consider the eﬀecrs of network structure on recommendation and how to make use of known structural features to improve recommendation.
For example, Huang et al. analyzed the consumer-product networks and proposed
an improved recommendation algorithm preferring edges that enhance the local clustering property, and Sahebi et al. designed an improved algorithm making use of the
community structure. Progress and propagation of new techniques also bring new challenges. For example, the GPS equipped mobile phones have become mainstream and the
Internet access is ubiquitous, hence the location-based recommendation is now fesaible and
increasingly signiﬁcant.3 Accurate recommendation asks for both the high predictability
of human movements and quantitative way to deﬁne similarities between locations
and people . Lastly, intelligent recommender systems should take into account the
diﬀerent behavioral patterns of diﬀerent people. For example, new users tend to visit very
popular items and select similar items, while old users usually have more speciﬁc interests
 , and users behave much diﬀerently between low-risk (e.g., collecting bookmarks,
downloading music, etc.) and high-risk (e.g., buying a computer, renting a house, etc.)
activities .
3. Deﬁnitions of Subjects and Problems
We brieﬂy review in this chapter basic concepts that are useful in the study of recommender systems.
3.1. Networks
Network analysis is a versatile tool in uncovering the organization principles of many
complex systems . A network is a set of elements (called nodes or vertices) with
connections (called edges or links) between them. Many social, biological, technological
and information systems can be described as networks with nodes representing individuals
or organizations and edges capturing their interactions. The study of networks, referred to
as graph theory in mathematical literature, has a long history that begins with the classical
K¨onigsberg bridge problem solved by Euler in 18th century . Mathematically speaking,
a network G is an ordered pair of disjoint sets (V, E) where V is the set of nodes and the
set of edges, E, is a subset of V × V . In an undirected network, an edge joining nodes
x and y is denoted by x ↔y, and x ↔y and y ↔x mean exactly the same edge. In a
directed network, edges are ordered pairs of nodes and an edge from x to y is denoted by
x →y. Edges x →y and y →x are distinct and may be present simultaneously. Unless
stated otherwise, we assume that a network does not contain a self-loop (an “edge” joining
a node to itself) or a multi-edge (several “edges” joining the same pair of nodes). In a
multinetwork both loops and multi-edges are allowed.
In an undirected network G(V, E), two nodes x and y are said to be adjacent to each
other if x ↔y ∈E. The set of nodes adjacent to a node x, the neighborhood of x, is
denoted by Γx. Degree of node x is deﬁned as kx = |Γx|. The degree distribution, P(k),
is deﬁned as the probability that a randomly selected node is of degree k. In a regular
network, every node has the same degree k0 and thus P(k) = δk,k0. In the classical Erd¨os-
R´enyi random network where each pair of nodes is connected by an edge with a given
probability p, the degree distribution follows a binomial form 
pk(1 −p)N−1−k,
3Websites like Foursquare, Gowalla, Google Latitude, Facebook, Jiapang, and others already provide
location-based services and show that many people want to share their location information and get
location-based recommendations.
Figure 1: A simple undirected network with 6 nodes and 7 edges. The node degrees are k1 = 1, k2 = k5 = 3
and k3 = k4 = k6 = 2, corresponding to the distribution P(1) = 1/6, P(2) = 1/2 and P(3) = 1/3. The
diameter and average distance of this network are dmax = 3 and ¯d = 1.6, respectively. The clustering
coeﬃcients are c2 = 1
6, c3 = c4 = 0, c5 = 1
3 and c6 = 1, and the average clustering coeﬃcient is C = 0.3.
where N = |V | is the number of nodes in the network. This distribution has a characterized
scale represented by the average degree ¯k = p(N −1). At the end of the last century,
researchers turned to investigation of large-scale real networks where it turned out that
their degree distributions often span several orders of magnitude and approximately follow
a power-law form
P(k) ∼k−γ,
with γ being a positive exponent usually lying between 2 and 3 . Such networks are called
scale-free networks as they lack a characteristic scale of degree and the power-law function
P(k) is scale-invariant . Note that detection of power-law distributions in empirical
data requires solid statistical tools . For a directed network, the out-degree of a
node x, denoted by kout, is the number of edges starting at x, and the in-degree kin is the
number of edges ending at x. The in- and out-degree distribution of a directed network in
general diﬀer from each other.
Generally speaking, a network is said to be assortative if its high-degree nodes tend
to connect with high-degree nodes and the low-degree nodes tend to connect with lowdegree nodes (it is said to be disassortative if the situation is opposite). This degree-degree
correlation can be characterized by the average degree of the nearest neighbors or
a variant of Pearson coeﬃcient called assortativity coeﬃcient . The assortativity
coeﬃcient r lies in the range −1 ≤r ≤1. If r > 0 the network is assortative; if r < 0,
the network is disassortative. Note that this coeﬃcient is sensitive to degree heterogeneity.
For example, r will be negative in a network with very heterogeneous degree distribution
(e.g., the Internet) regardless to the network’s connecting patterns .
The number of edges in a path connecting two nodes is called length of the path, and
distance between two nodes is deﬁned as the length of the shortest path that connects
them. The diameter of a network is the maximal distance among all node pairs and the
average distance is the mean distance averaged over all node pairs as
where dxy is the distance between x and y.4 Many real networks display a so-called smallworld phenomenon: their average distance does not grow faster than the logarithm of the
network size .
The importance of triadic clustering in social interaction systems has been realized for
more than 100 years . In social network analysis , this kind of clustering is called
transitivity, deﬁned as three times the ratio of the total number of triangles in a network
to the total number of connected node triples. In 1998, Watts and Strogatz proposed
a similar index to quantify the triadic clustering, called clustering coeﬃcient. For a given
node x, this coeﬃcient is deﬁned as the ratio of the number of existing edges between x’s
neighbors to the number of neighbor pairs,
2kx(kx −1)
where ex denotes the number of edges between kx neighbors of node x (this deﬁnition is
meaningful only if kx > 1). The network clustering coeﬃcient is deﬁned as the average of
cx over all x with kx > 1. It is also possible to deﬁne the clustering coeﬃcient as the ratio
of 3 × number of triangles in the network to the number of connected triples of vertices,
which is sometimes referred to as “fraction of transitive triples” . Note that the two
deﬁnitions can give substantially diﬀerent results.
Figure 1 illustrates the above deﬁnitions for a simple undirected network. For more
information about network measurements, readers are encouraged to refer an extensive
review article on characterization of networks.
3.2. Bipartite Networks and Hypergraphs
A network G(V, E) is a bipartite network if there exists a partition (V1, V2) such that
V1 ∪V2 = V , V1 ∩V2 = ∅, and every edge connects a node of V1 and a node of V2.
Many real systems are naturally modeled as bipartite networks: the metabolic network
 consists of chemical substances and chemical reactions, the collaboration network 
consists of acts and actors, the Internet telephone network consists of personal computers
and phone numbers , etc. We focus on a particular class of bipartite networks, called
web-based user-object networks , which represent interactions between users and objects
in online service sites, such as collections of bookmarks in delicious.com and purchases of
books in amazon.com.
As we shall see later, these networks describe the fundamental
structure of recommender systems. Web-based user-object networks are speciﬁc by their
4When no path exists between two nodes, we say that their distance is inﬁnite which makes the average
distance automatically inﬁnite too. This problem can be avoided either by excluding such node pairs from
averaging or by using the harmonic mean .
Figure 2: An illustration of the one-to-one correspondence between a hypergraph (a) and a bipartite
network (b). There are three hyperedges, X = {1, 2, 4}, Y = {4, 5, 6} and Z = {2, 3, 5, 6}.
gradual evolution where both nodes and links are added gradually. By contrast, this cannot
happen in, for example, act-actor networks (e.g., one can not add authors to a scientiﬁc
paper after its publication).
Most web-based user-object networks share some structural properties. Their objectdegree distributions obey a power-law-like form P(k) ∼k−γ, with γ ≈1.6 for the Internet
Movie Database (IMDb) , γ ≈1.8 for the music-sharing site audioscrobbler.com ,
γ ≈2.3 for the e-commerce site amazon.com , and γ ≈2.5 for the bookmark-sharing
site delicious.com . The form of the user-degree distribution is usually between an
exponential and a power law , and can be well ﬁtted by the Weibull distribution 
P(k) ∼kµ−1 exp
where k0 is a constant and µ is the stretching exponent. Connections between users and
objects exhibit a disassortative mixing pattern .
A straightforward extension of the deﬁnition of bipartite network is the so-called multipartite network. For an r-partite network G(V, E), there is an r-partition V1, V2, · · · , Vr
such that V = V1 ∪V2 ∪· · · ∪Vr, Vi ∩Vj = ∅whenever i ̸= j, and no edge joins two
nodes in the same set Vi for all 1 ≤i ≤r. The tripartite network representation has
found its application in collaborative tagging systems (also called folksonomies in the literature) , where users assign tags to online resources, such as photographs
in ﬂickr.com, references in CiteULike.com and bookmarks in delicious.com.
Note that some information is lost in the tripartite representation. For example, given
an edge connecting a resource and a tag, we do not know which user (or users) contributed
to this edge. To resolve this, hypergraph can be used to give an exact representation
of the full structure of a collaborative tagging system.
In a hypergraph H(V, E), the
hyperedge set E is a subset of the power set of V , that is the set of all subsets of V .
Link e can therefore connect multiple nodes.
Analogously to ordinary networks, node
degree in a hypergraph is deﬁned as the number of hyperedges adjacent to a node and the
distance between two nodes is deﬁned as the minimal number of hyperedges connecting
these nodes. The clustering coeﬃcient and community structure can also
Figure 3: A hypergraph illustration of collaborative tagging networks. (left) A triangle-like hyperedge ,
which contains three types of vertices, depicted by one red circle, one green rectangle and one blue triangle
which respectively represent a user, a resource and a tag. (right) A descriptive hypergraph consists of two
users, four resources and three tags. Take user U2 and resource R1 for example, the measurements are
denoted as: (i) U2 has participated in six hyperedges, which means its hyperdegree is 6; (ii) U2 has directly
connected to three resources and three tags. As deﬁned by Eq. (6), it suggests it possibly has 3×3=9
hyperedges in maximal.
Thus its clustering coeﬃcient equals 6/9≈0.667 , where 6 is its hyperdegree;
Comparatively, as deﬁned by Eq. (7), its clustering coeﬃcient Dh(U2) = 12−6
12−4=0.75; (iii) the shortest path
from U2 to R1 is U2 −T1 −R1, which indicates the distance between U2 and R1 is 2.
be deﬁned and quantiﬁed following the deﬁnitions in ordinary networks. Notice that there
is a one-to-one correspondence between a hypergraph and a bipartite network. Given a
hypergraph H(V, E), the corresponding bipartite network G(V ′, E′) contains two node sets,
as V ′ = V ∪E, and x ∈V is connected with Y ∈E if and only if x ∈Y (see Figure 2 for
an illustration).
Hypergraph representation has already found applications in ferromagnetic dynamics
 , population stratiﬁcation , cellular networks , academic team formation ,
and many other areas. Here we are concerned more about the hypergraph representation
of collaborative tagging systems where each hyperedge joins three nodes (represented by a triangle-like in Figure 3), user u, resource r and tag t, indicating that u
has given t to r. A resource can be collected by many users and given several tags by
a user, and a tag can be associated with many resources, resulting in small-world hypergraphs (Figure 3 shows both the basic unit and extensive description). Moreover,
hypergraphs for collaborative tagging systems have been shown to be highly clustered,
with heavy-tailed degree distribution5 and of community structure . A model for
5The degrees of users, resources and tags are usually investigated separately. For ﬂickr.com and CiteU-
Like.com, the user and tag degree distributions are power-law-like, while the resource degree distributions
are much narrower because in ﬂickr.com, a photograph is only collected by a single user and in CiteU-
Like.com, a reference is rarely collected by many users .
By contrast, in delicious.com, a popular
bookmark can be collected by thousands of users and thus the resource degree distribution is of a powerlaw kind .
evolving hypergraphs can be found in .
Generally, to evaluate a hypergraph from the perspective of complexity science, the following quantities (Figure 3 gives a detailed description of these quantities) can be applied:
(i) hyperdegree: The degree of a node in a hypergraph can be naturally deﬁned as the
number of hyperedges adjacent to it.
(ii) hyperdegree distribution: deﬁned as the proportion that each hyperdegree occupies,
where hyperdegree is deﬁned as the number of hyperedges that a regular node participates
(iii) clustering coeﬃcients: deﬁned as the proportion of real number of hyperedges to all
the possible number of hyperedges that a regular node could have . e.g., the clustering
coeﬃcient for a user, Cu, is deﬁned as
where ku is the hyperdegree of user u, Ru is the number of resources that u collects and
Tu is the number of tags that u possesses. The above deﬁnition measures the fraction
of possible pairs present in the neighborhood of u.
A larger Cu indicates that u has
more similar topic of resources, which might also show that u has more concentrated on
personalized or special topics, while smaller Cu might suggest that s/he has more diverse
interests. Similar deﬁnitions can also be deﬁned for measuring the clustering coeﬃcient of
resources and tags.
An alternative metric, named hyperedge density, is proposed by Zlati´c et al . Taking
a user node u again as an example, they deﬁne the coordination number of u as z(u) =
Ru + Tu. Given k(u), the maximal coordination number is zmax(u) = 2k(u), while the
minimal coordination number is zmin(u) = 2n for n(n−1) < k(u) ≤n2 and zmin(u) = 2n+1
for n2 < k(u) ≤n(n + 1), with n some integer. Obviously, a local tree structure leads
to maximal coordination number, while the maximum overlap corresponds to the minimal
coordination number. Therefore, they deﬁne the hyperedge density as :
zmax(u) −z(u)
zmax(u) −zmin(u), 0 ≤Dh(u) ≤1.
The deﬁnition of hyperedge density for resources and tags is similar. Empirical analysis
indicates a high clustering behavior under both metrics . The study of hypregraph
for the collaborative tagging networks has just been unfolding, and how to properly quantify
the clustering behavior, the correlations and similarities between nodes, and the community
structure is still an open problem.
(iv) average distance: deﬁned as the average shortest path length between two random
nodes in the whole network.
3.3. Recommender Systems
A recommender system uses the input data to predict potential further likes and interests of its users. Users’ past evaluations are typically an important part of the input
Nationality
Attributes
Harry is a
very special
I dislike it
I dislike it
Figure 4: Illustration of a recommender system consisted of ﬁve users and four books. The basic information contained by every recommender system is the relations between users and objects that can be
represented by a bipartite graph. This illustration also exhibits some additional information frequently
exploited in the design of recommendation algorithms, including user proﬁles, object attributes and object
data. Let M be the number of users and let N be the number of all objects that can
be evaluated and recommended. Note that object is simply as a generic term which can
represent books, movies, or any other kind of consumed content. To stay in line with
standard terminology, we sometimes use item which has the same meaning. To make the
notation more clear, we restrict to Latin indices i and j when enumerating the users and
to Greek indices α and β when enumerating the objects. Evaluation/rating of object α
by user i is denoted as riα. This evaluation is often numerical in an integer rating scale
(think of Amazon’s ﬁve stars)—in this case we speak of explicit ratings. Note that the
common case of binary ratings (like/dislike or good/bad) also belongs to this category.
When objects are only collected (as in bookmark sharing systems) or simply consumed
(as in online newspaper or magazine without rating systems) or when “like” is the only
possible expression (as on Facebook), we are left with unary ratings. In this case, riα = 1
represents a collected/consumed/liked object and riα = 0 represents a non-existing evaluation (See Fig. 4). Inferring users’ conﬁdence levels of ratings is not a trival task, especially
from the binary or unary ratings. Accessorial information about users’ behavior may be
helpful, for example, the users’ conﬁdence levels can be estimated by their watching time
of television shows and with the help of this information, the quality of recommendation
can be improved . Even if we have explict ratings, it does not mean we know how and
why people vote with these ratings–Do they have standards of numerical ratings or they
just use ratings to present orders? Recent evidence to some extent supports the latter
2001: A Space Odyssey
Casablanca
Table 2: Recommendation process in a nutshell: to estimate the potential favorable opinion of Carol about
Casablanca, one can use the similarity of her with those of Alice. Alternatively, one can note that ratings
of Titanic and Casablanca follow a similar pattern, suggesting that people who liked the former might also
like the latter.
The goal of a recommender system is to deliver lists of personalized “recommended”
objects to its users. To this end, evaluations can be predicted or, alternatively, recommendation scores can be assigned to objects yet unknown to a given user. Objects with the
highest predicted ratings or the highest recommendation scores then constitue the recommendation list that is presented to the target user. There is an extensive set of performance
metrics that can be used to evaluate the resulting recommendation lists (see Sec. 3.4). The
usual classiﬁcations of recommender systems is as follows :
1. Content-based recommendations: Recommended objects are those with content similar to the content of previously preferred objects of a target user. We present them
in Sec. 4.2.3.
2. Collaborative recommendations: Recommended objects are selected on the basis of
past evaluations of a large group of users. They can be divided into:
(a) Memory-based collaborative ﬁltering: Recommended objects are those that were
preferred by users who share similar preferences as the target user, or, those that
are similar to the other objects preferred by the target user. We present them
in Sec. 4 (Standard similarity-based methods) and Sec. 7 (methods employing
social ﬁltering).
(b) Model-based collaborative ﬁltering: Recommended objects are selected on models that are trained to identify patterns in the input data. We present them in
Sections 5 (dimensionality reduction methods) and 6 (diﬀusion-based methods).
3. Hybrid approaches: These methods combine collaborative with content-based methods or with diﬀerent variants of other collaborative methods. We present them in
3.4. Evaluation Metrics for Recommendation
Given a target user i, a recommender system will sort all i’s uncollected objects and
recommend the top-ranked objects. To evaluate recommendation algorithms, the data is
usually divided into two parts: The training set ET and the probe set EP. The training
set is treated as known information, while no information from the probe set is allowed
to be used for recommendation. In this section we brieﬂy review basic metrics that are
used to measure the quality of recommendations. How to choose a particular metric (or
metrics) to evaluate recommendation performance depends on the goals that the system is
supposed to fulﬁll. Of course, the ultimate evaluation of any recommender system is given
by the judgement of its users.
3.4.1. Accuracy Metrics
Rating Accuracy Metrics. The main purpose of recommender systems is to predict users’
future likes and interests.
A multitude of metrics exist to measure various aspects of
recommendation performance. Two notable metrics, Mean Absolute Error (MAE) and
Root Mean Squared Error (RMSE), are used to measure the closeness of predicted ratings
to the true ratings. If ruα is the true rating on object α by user i, ˜riα is the predicted
rating and EP is the set of hidden user-object ratings, MAE and RMSE are deﬁned as
|riα −˜riα|,
(riα −˜riα)21/2
Lower MAE and RMSE correspond to higher prediction accuracy. Since RMSE squares the
error before summing it, it tends to penalize large errors more heavily. As these metrics
treat all ratings equally no matter what their positions are in the recommendation list,
they are not optimal for some common tasks such as ﬁnding a small number of objects
that are likely to be appreciated by a given user (Finding Good Objects). Yet, due to their
simplicity, RMSE and MAE are widely used in the evaluation of recommender systems.
Rating and Ranking Correlations. Another way to evaluate the prediction accuracy is to
calculate the correlation between the predicted and the true ratings. There are three wellknown correlation measures, namely the Pearson product-moment correlation , the
Spearman correlation and Kendall’s Tau . The Pearson correlation measures the
extent to which a linear relationship is present between the two sets of ratings. It is deﬁned
α(˜rα −¯˜r)(rα −¯r)
α(˜rα −¯˜r)2pP
α(rα −¯r)2,
where rα and ˜rα are the true and predicted ratings, respectively. The Spearman correlation
coeﬀcient ρ is deﬁned in the same manner as the Pearson correlation, except that rα and ˜rα
are replaced by the ranks of the respective objects. Similarly to the Spearman correlation,
Kendall’s Tau also measures the extent to which the two rankings agree on the exact values
of ratings. It is deﬁned as τ = (C −D)/(C + D) where C is the number of concordant
pairs—pairs of objects that the system predicts in the correct ranked order and D is the
number of discordant pairs—pairs that the system predicts in the wrong order. τ = 1
when the true and predicted ranking are identical and τ = −1 when they are exactly
opposite. For the case when objects with equal true or predicted ratings exist, a variation
of Kendall’s Tau was proposed in 
(C + D + ST)(C + D + SP)
where ST is the number of object pairs for which the true ratings are the same, and SP
is the number of object pairs for which the predicted ratings are the same. Kendall’s Tau
metric applies equal weight to any interchange of successively ranked objects, no matter
where it occurs. However, interchanges at diﬀerent places, for example between top 1 and
2, and between 100 and 101, may have diﬀerent impacts. Thus a possible improved metric
could give more weight to object pairs at the top of the true ranking.
Similar to Kendall’s Tau, the normalized distance-based performance measure (NDPM)
was originally proposed by Yao to compare two diﬀerent weakly ordered rankings. It
is based on counting the number of contradictory pairs C−(for which the two rankings
disagree) and compatible pairs Cu (for which one ranking reports a tie while the other
reports strict preference of one object over the other). Denoting the total number of strict
preference relationships in the true ranking as C, NDPM is deﬁned as
NDPM = 2C−+ Cu
Since this metric does not punish the situation where the true ranks are tied, it is more
appropriate than correlation metrics for domains where users are interested in objects that
are good-enough.
Classiﬁcation Accuracy Metrics. Classiﬁcation metrics are appropriate for tasks such as
“Finding Good Objects”, especially when only implicit ratings are available (i.e., we know
which objects were favored by a user but not how much they were favored).
ranked list of objects is given, the threshold for recommendations is ambiguous or variable.
To evaluate this kind of systems, one popular metric is AUC (Area Under ROC Curve),
where ROC stands for the receiver operating characteristic (for how to draw a ROC
curve see ). AUC attempts to measure how a recommender system can successfully
distinguish the relevant objects (those appreciated by a user) from the irrelevant objects (all
the others). The simplest way to calculate AUC is by comparing the probability that the
relevant objects will be recommended with that of the irrelevant objects. For n independent
comparisons (each comparison refers to choosing one relevant and one irrelevant object),
if there are n′ times when the relevant object has higher score than the irrelevant and n′′
times when the scores are equal, then according to 
AUC = n′ + 0.5n′′
Clearly, if all relevant objects have higher score than irrelevant objects, AUC = 1 which
means a perfect recommendation list. For a randomly ranked recommendation list, AUC =
0.5. Therefore, the degree of which AUC exceeds 0.5 indicates the ability of a recommendation algorithm to identify relevant objects. Similar to AUC is a so-called Ranking Score
proposed in . For a given user, we measure the relative ranking of a relevant object in
this user’s recommendation list: when there are o objects to be recommended, a relevant
object with ranking r has the relative ranking r/o. By averaging over all users and their
relevant objects, we obtain the mean ranking score RS—the smaller the ranking score, the
higher the algorithm’s accuracy, and vice versa.
Since real users are usually concerned only with the top part of the recommendation
list, a more practical approach is to consider the number of a user’s relevant objects ranked
in the top-L places. Precision and recall are the most popular metrics based on this. For
a target user i, precision and recall of recommendation, Pi(L) and Ri(L), are deﬁned as
Pi(L) = di(L)
Ri(L) = di(L)
where di(L) indicates the number of relevant objects (objects collected by i that are present
in the probe set) in the top-L places of the recommendation list, and Di is the total number
of i’s relevant objects. Averaging the individual precision and recall over all users with
at least one relevant object, we obtain the mean precision and recall, P(L) and R(L),
respectively. These values can be compared with precision and recall resulting from random
recommendation, leading to precision and recall enhancements as deﬁned in 
eP(L) = P(L) MN
eR(L) = R(L) N
where M and N are the number of users and objects, respectively, and D is the total
number of relevant objects. While precision usually decreases with L, recall always grows
with L. One may combine them into a less L-dependent metric 
F1(L) = 2PR
which is called F1-score. Many other measurements which combine precision and recall are
used to evaluate the eﬀectiveness of information retrieval, but rarely applied to evaluate
recommendation algorithms: Average Precision, Precision-at-Depth, R-Precision, Reciprocal Rank , Binary Preference Measure . A detailed introduction and discussion
of each combination index can be found in .
3.4.2. Rank-weighted Indexes
Since users have limited patience on inspecting individual objects in the recommended
lists, user satisfaction is best measured by taking into account the position of each relevant
object and assign weights to them accordingly. Here we introduce three representative indexes that follow this approach. For a detailed discussion of their strengths and weaknesses
Half-life Utility. The half-life utility metric attempts to evaluate the utility of a recommendation list to a user. It is based on the assumption that the likelihood that a user examines
a recommended object decays exponentially with the object’s ranking. The expected utility
of recommendations given to user i hence becomes 
max(riα −d, 0)
2(oiα−1)/(h−1) ,
where objects are sorted by their recommendation score ˜riα in descending order, oiα represents the predicted ranking of object α in the recommendation list of user i, d is the
default rating (for example, the average rating), and the “half-life” h is the rank of the
object on the list for which there is a 50% chance that the user will eventually examine
it. This utility can be further normalized by the maximum utility (which is achieved when
the user’s all known ratings appear at the top of the recommendation list). When HLi is
averaged over all users, we obtain an overall utility of the whole system.
Discounted Cumulative Gain. For a recommendation list of length L, DCG is deﬁned as
where rn indicates the relevance of the n-th ranked object (rn = 1 for a relevant object
and zero otherwise) and b is a persistence parameter which was suggested to be 2. The
intention of DCG is that highly ranked relevant objects give more satisfaction and utility
than badly ranked ones.
Rank-biased Precision. This metric assumes that users always check the ﬁrst object and
progress from one object to the next one with certain (persistence) probability p (with a
complementary probability 1 −p, the examination of the recommendation list ends). For
a list of length L, the rank-biased precision metric is deﬁned as 
RBP = (1 −p)
where rn is the same as in DCG. RBP is similar to DCG, the diﬀerence is that RBP
discounts relevance via a geometric sequence, while DCG does so using a log-harmonic
3.4.3. Diversity and Novelty
Even a successfully recommended relevant object has little value to a user when it
is notorious. To complement the above accuracy-probing metrics, several diversity- and
novelty-probing metrics have been proposed recently and we introduce them
Diversity. Diversity in recommender systems refers to how diﬀerent the recommended
objects are with respect to each other. There are two levels to interpret diversity: one
refers to the ability of an algorithm to return diﬀerent results to diﬀerent users—we call
it Inter-user diversity (i.e., the diversity between recommendation lists). The other one
measures the extent to which an algorithm can provide diverse objects to each individual
user—we call it Intra-user diversity (i.e., the diversity within a recommendation list).
Inter-user diversity is deﬁned by considering the variety of users’ recommendation
lists. Given users i and j, the diﬀerence between the top L places of their recommendation
lists can be measured by the Hamming distance
Hij(L) = 1 −Qij(L)
where Qij(L) is the number of common objects in the top-L places of the lists of users i
and j. If the lists are identical, Hij(L) = 0, while if their lists are completely diﬀerent,
Hij(L) = 1. Averaging Hij(L) over all user pairs, we obtain the mean Hamming distance
The greater its value, the more diverse (more personalized) recommendation is
given to the users.
Denoting the recommended objects for user i as {o1, o2, · · · , oL}, similarity of these
objects s(oα, oβ) can be used to measure the intra-user diversity (this similarity can be
obtained either directly from the input ratings or from object metadata) . The average
similarity of objects recommended to user i,
s(oα, oβ),
can be further averaged over all users to obtain the mean intra-similarity of the recommendation lists, I(L). The lower is this quantity, the more diverse objects are recommended
to the users. Notably, intra-list diversity can be used to enhance improve recommendation
lists by avoiding recommendation of excessively similar objects . The rank-sensetive
version can be obtained by introducing a discount function of the object’s rank in recommendation list .
Novelty and Surprisal. The novelty in recommender systems refers to how diﬀerent the
recommended objects are with respect to what the users have already seen before. The
simplest way to quantify the ability of an algorithm to generate novel and unexpected
results is to measure the average popularity of the recommended objects
R is the recommendation list of user i and kα denotes the degree of object α
(i.e., the popularity of object α). Lower popularity indicates higher novelty of the results.
Another possibility to measure the unexpectedness is using the self-information (surprisal)
 of recommended objects. Given an object α, the chance that a randomly-selected
user has collected it is kα/M and thus its self-information is
Uα = log2(M/kα).
A user-relative novelty variant can be deﬁned by restricting the observations to the target
user, namely caculating the mean self-information of target user’s top-L objects. Averaging
over all users we obtain the mean top-L surprisal U(L). With a similar resulting formula,
a discovery-based novelty was proposed in by considering the propability that an
object is known or familiar to a random user.
3.4.4. Coverage
Coverage measures the percentage of objects that an algorithm is able to recommend
to users in the system. Denoting the total number of distinct objects in top L places of all
recommendation lists as Nd, the L-dependent coverage is deﬁned as
COV (L) = Nd/N.
Low coverage indicates that the algorithm can access and recommend only a small number
of distinct objects (usually the most popular ones) which often results in little diverse recommendations. On the contrary, algorithms with high coverage are more likely to provide
diverse recommendations . From this viewpoint, coverage can be also considered as
a diversity metric. In addition, coverage is helpful to better evaluate results of accuracy
metrics : recommending popular objects is likely to be of high accuracy but of low
coverage. A good recommendation method is expected to be of both high accuracy and
The choice of a particular metric (or metrics) to evaluate a recommender system depends on the goals that the system is supposed to fulﬁll. In practice, one may specify
diﬀerent goals for new and experienced users which further complicates the evaluation process. For a better overview, Table 3 summarizes the described metrics for evaluation of
recommender systems.
4. Similarity-based methods
Similarity-based methods represent one of the most successful approaches to recommendation. They have been studied extensively and found various applications in e-commerce
 . This class of algorithms can be further divided into methods employing user
and item similarity, respectively. The basic assumption of a method based on user similarity is that people who agree in their past evaluationes tend to agree again in their
future evaluations. Thus, for a target user, the potential evaluation of an object is estimated according to the ratings from users (“taste mates”) who are similar to the target
user (see Fig. 5 for a schematic illustration). Diﬀerent from user similarity, an algorithm
based on item similarity recommends a user the objects that are similar to what this user
has collected before. Note that, sometimes the opinions from dissimilar users or the
negative ratings can play a signiﬁcant (even positive) role in determining the recommendation, especially when the data set is very sparse and thus the information about
relevance is more important than that about correlation . For additional information
see the recent review articles , and is a nice survey that contains a number
of similarity indices.
4.1. Algorithms
Here we brieﬂy introduce the conventional similarity-based algorithms which are often
referred to as memory-based collaborative ﬁltering techniques. The term “collaborative
ﬁltering” was introduced by creators of the ﬁrst commercial recommender system, Tapestry
Table 3: Summary of the presented recommendation metrics. The third column represents the preference
of the metric (e.g., smaller MAE means higher rating accuracy). The fourth column describes the scope
of the metric. The last two columns show whether the metric is obtained from a ranking and whether it
depends of the length of the recommendation list L.
Preference
rating accuracy
rating accuracy
rating correlation
rating correlation
Kendall’s Tau
rating correlation
ranking correlation
classiﬁcation accuracy
classiﬁcation accuracy
classiﬁcation accuracy
classiﬁcation accuracy
Ranking score
ranking accuracy
Half-life utility
satisfaction
Discounted Cumulative Gain
satisfaction and precision
Rank-biased Precision
satisfaction and precision
Hamming distance
inter-diversity
Intra-similarity
intra-diversity
Popularity
surprisal and novelty
Self-information
unexpectedness
coverage and diversity
input data
(25) or (27)
Predictions
˜r1, . . . , ˜rM
Recommendations
(top objects for user i)
output data
Figure 5: A schematic representation of collaborative-ﬁltering (CF) recommendation method: rating prediction for a given user-object pair is based on the user’s and object’s past ratings.
 , derives from the fact that it requires collaboration of multiple agents who share
their data to obtain better recommendation. In the following sections, we describe basic
algorithms as well as main approaches to the computation of similarity which is a critical
component of the recommendation process.
4.1.1. User similarity
The goal is to make automated prediction of user preferences by collecting evaluation
data from many other users, especially those whose evaluations are similar to evaluations
from the target user. Denote the rating from user u on object α as ruα and let Γu be the set
of objects that user u has evaluated. The average rating given by u is ¯ru =
According to the standard collaborative ﬁltering, the predicted rating of user u on object
˜ruα = ¯ru + κ
suv(rvα −¯rv)
where ˆUu denotes the set of users that are most similar to user u, suv denotes the similarity
between user u and user v and κ =
v |suv| is a normalization factor. If instead of explicit
ratings, only the sets of objects collected by individual users are known (implicit ratings),
we aim at predicting the objects which are most likely to be collected by a user in the
future. According to , Eq. (25) should be replaced with
where puα is the recommendation score of object α for user u and avα is an element of
the adjacency matrix of the user-object bipartite network (avα = 1 if user v has collected
object α and avα = 0 otherwise).
As has already been made explicit by Eq. (25) and Eq. (26), only users most similar to
given user u are usually considered. To obtain ˆUu, two neighborhood selection strategies
are usually applied: (i) correlation threshold is based on selecting all users v whose
similarity suv surpasses a given threshold, (ii) maximum number of neighbors consists
of selecting those k users that are most similar to u (here k is a parameter of the algorithm).
Restricting computation to the most similar users is not only computationally advantageous
but in general it leads to superior results .
4.1.2. Item similarity
In this case, item-item similarity sαβ is employed instead of user-user similarity suv.
The simplest way is to estimate unknown ratings using the weighted average 
β∈Γu sαβruβ
where Γu is the set of items evaluated by user u. Techniques limiting the computation of
˜ruα to items that are most similar to α can be applied similarly as described above for user
similarity. One of the advantages of this approach is that similarity between items tends to
be more static than similarity between users, allowing its values and neighborhoods to be
computed oﬄine (i.e., before recommendation for a particular user is requested—this allows
to shorten the time needed to obtain the recommendation). Hybrid collaborative ﬁltering
algorithms combining user-, item- or attribute-based similarity were proposed .
Their results show that this approach not only improves the prediction accuracy but it is
also more robust to data sparsity.
4.1.3. Slope One predictor
Slope One predictor with the form f(x) = x + b, where b is a constant and x is a
variable representing the rating values, is the simplest form of item-based collaborative
ﬁltering based on ratings . It subtracts the average ratings of two items to measure
how much more, on average, one item is liked than another. This diﬀerence is used to
predict another user’s rating of one of these two items, given his rating of the other. For
example, consider a case where user i gave score 1 to item α and score 1.5 to item β while
user j gave score 2 to item α. Slope One then predicts that user j will rate item β with
2 + (1.5 −1) = 2.5 (see Fig. 6 for an illustration).
Figure 6: In the depicted case, the Slope One prediction would be x = 2 + (1.5 −1) = 2.5.
The Slope One scheme takes into account both information from other users who rated
the same item and from the other items rated by the same user. In particular, only ratings
by users who have rated some common items with the target user and only ratings of items
that the target user has also rated are involved in the prediction process. Denoting the set
of users who rated items α and β as S(α, β), the average deviation of item β with respect
to item α is deﬁned as
i∈S(α,β) riβ −riα
Given a known rating ruα, Slope One predicts u’s rating on item β as ruα + devβα. By
varying α in Eq. 28, we obtain diﬀerent predictions. A reasonable overall predictor is their
average value
(ruβ + devαβ),
where R(u, α) is the set of items that have been both rated by u and co-rated with item
β. Note that predictions obtained from diﬀerent items α have equal weight no matter how
many users have co-rated α with β. To take into account the fact that the credibility of
devαβ depends crucially on |S(α, β)| (the larger the overlap, the more trustful the value),
one can introduce a Weighted Slope One prediction as
α|S(α, β)|(ruβ + devαβ)
α|S(α, β)|
Another improvement of the basic Slope One algorithm is based on dividing the set of all
items into items liked and disliked by a given user (a straightforward criterion to identify
liked and disliked items is to check whether their rating were higher or lower than the
average rating awarded by the given user).
From these liked and disliked items, two
separate predictions are then derived which are combined into one prediction at the very
end. Denote by S+1(α, β) and S−1(α, β) the sets of users who like and dislike, respectively,
both α and β. The deviations for liked and disliked items are
|S+1(β, α)|
i∈S+1(β,α)
(riβ −riα),
|S−1(β, α)|
i∈S−1(β,α)
(riβ −riα).
The prediction for the rating of item β based on the rating of item α is either rjα + dev+1
or rjα + dev−1
βα depending on whether the target user j likes or dislikes item α respectively.
The Bi-Polar Slope One is thus given by
α|S+1(β, α)|(rjα + dev+1
α|S−1(β, α)|(rjα + dev−1
α|S+1(β, α)| + P
α|S−1(β, α)|
where the weights are chosen similarly as for Weighted Slope One.
It was shown that Slope One can outperform linear regression (i.e., estimation by
f(x) = ax+b) while having half the number of regressors . This simple approach
also reduces storage requirements and latency of the recommender system. Slope One has
been used as a building block to improve other algorithms . For instance,
it can be combined with user-based collaborative ﬁltering to address the data sparsity
problem via ﬁlling the vacant ratings of the user-item matrix by the Slope One scheme,
and thus improving the prediction accuracy .
4.2. How to deﬁne similarity
The key problem of similarity-based algorithms is how to deﬁne similarity between
users or objects. When explicit ratings are available, similarity is usually deﬁned using
a correlation metric such as Pearson, for example (two users are considered as similar
when they tend to give similar ratings to the objects they rate). When there is no rating
information available, similarity can be inferred from the structural properties of the input
data (two users are considered as similar when they liked/bought many objects in common).
Besides, external information such as users’ attributes, tags and objects’ content meta
information can be utilized to estimate similarity better.
4.2.1. Rating-based similarity
In many online e-commerce services, users are allowed to evaluate the consumed objects
by ratings.
For example, in Yahoo Music, users vote each song with one to ﬁve stars
representing ”Never play again”(⋆), ”It is ok”(⋆⋆), ”Like it” (⋆⋆⋆), ”Love it”(⋆⋆⋆⋆)
and ”Can’t get enough”(⋆⋆⋆⋆⋆). With explicit rating information we can measure the
similarity between two users or between two objects by Cosine index which is
xy = rx · ry
For quantifying the similarity between users, rx, ry are rating vectors in the N-dimensional
object space while for similarity between objects, rx, ry are vectors in M-dimensional user
space. Note that, in the calculation of rating-based similarity, it is necessary to eliminate
the rating tendencies of users and/or on items, otherwise the similarity is less meaningful.
Actually, according to a recently reported smart method, in some rating systems, via
proper usage of rating tendencies, one could predict the unknown ratings with remarkably
higher accuracy than the simply similarity-based methods .
The rating correlation can also be measured by Pearson coeﬃcient (PC) . To
quantify similarity between users u and v, it reads
α∈Ouv(ruα −¯ru)(rvα −¯rv)
α∈Ouv(ruα −¯ru)2
α∈Ouv(rvα −¯rv)2,
where Ouv = Γu ∩Γv indicates the set of objects rated by both u and v. A constrained
Pearson coeﬃcient proposed by Shardanand and Maes consists of substituting the
user mean in Eq. 34 with a “central” rating (for example, in the scale from 1 to 5, one
can set the central rating to be 3). The idea is to take into account the diﬀerence between
positive (above the central rating) and negative ratings (below the central rating).
weighted Pearson coeﬃcient is based on the idea of capturing the conﬁdence that can be
placed on similarity values (when two users evaluated only a few objects in common, their
potentially high similarity should not be trusted as much as for a pair of users with many
overlapping objects). It was proposed to weight the Pearson coeﬃcient as
for |Ouv| ≤H,
where H is a threshold, determined experimentally, beyond which the correlation measure
can be trusted.
Analogically, Pearson similarity between objects α and β reads
u∈Uαβ(ruα −¯rα)(ruβ −¯rβ)
u∈Uαβ(ruα −¯rα)2qP
u∈Uαβ(ruβ −¯rβ)2,
where Uαβ is the set of users who rated both α and β, and ¯rα is the average rating of object
α. Experiments have shown that the Pearson coeﬃcient performs better than the cosine
vector index . When only binary ratings are available (like or dislike, purchase or no
purchase, click or no click, etc.), the cosine and Pearson coeﬃcient can still be applied to
quantify the similarity of vectors with binary elements. For example, Amazon’s patented
algorithm computes the cosine similarity between binary vectors representing users’
purchases and use it in item-based collaborative ﬁltering.
4.2.2. Structural similarity
As we have mentioned above, similarity can be deﬁned using the external attributes
such as tag and content information. However, the required data is usually very diﬃcult
to collect. Another simple and eﬀective way to quantify the similarity, structural similarity , is based solely on the network structure of the data. Recent research shows
that the structural-based similarity can produce better recommendations that the Pearson
correlation coeﬃcient, especially when the input data is very sparse .
To calculate the structural similarity between users or objects, we generally project the
user-object bipartite network which contains the complete information about the system
into a monopartite user-user or object-object network (for more information on this aspect
of similarity see ). In the simplest case, two users are considered similar if they have
voted at least one common object (analogically, two objects are considered similar if they
have been co-voted by at least one user).
More reﬁned similarity metrics that can be
roughly categorized as node-dependent vs. path-dependent, local vs. global, parameterfree vs. parameter-dependent, and so on—here we review some of them.
Table 4: Mathematical deﬁnitions of the described node-dependent similarity indices. Γx denotes the set
of neighbors of node x (which can be either a user or an object node) and kx is the degree of node x.
sxy = |Γx ∩Γy|
sxy = |Γx ∩Γy|/
sxy = |Γx ∩Γy|/|Γx ∪Γy|
sxy = 2|Γx ∩Γy|/(kx + ky)
sxy = |Γx ∩Γy|/ min{kx, ky}
sxy = |Γx ∩Γy|/ max{kx, ky}
sxy = |Γx ∩Γy|/(kxky)
z∈Γx∩Γy 1/ ln kz
z∈Γx∩Γy 1/kz
sxy = kxky
(i) Node-dependent similarity.
The simplest weighted similarity index is Common
Neighbors (CN) where the similarity of two nodes is directly given by the number of
common neighbors (think of the number of users who bought both objects α and β or the
number of objects shared by users u and v). By considering degrees of the two target nodes,
six variations of CN were derived: Salton Index , Jaccard Index , Sørensen Index
 , Hub Promoted Index (HPI) , Hub Depressed Index (HDI) and Leicht-Holme-
Newman Index (LHN16) . One can further take into account degrees of respective
common neighbors to reward less-connected neighbors with a higher weight as in Adamic-
Adar Index (AA) and Resource Allocation Index (RA) . Note that since AA uses
a logarithmic weighting, it penalizes high-degree common neighbors less than RA. Finally,
Preferential Attachment Index (PA) builds on the classical preferential attachment rule in
network science . This index has been used to quantify the functional signiﬁcance of
links subject to various network-based dynamics, such as percolation , synchronization
 and transportation . Note that these similarity can be computed also for a bipartite network where common neighbors are objects and users when considering user and
object similarity, respectively. A summary of mathematical deﬁnitions of these similarity
indices is shown in Table 4.
(ii) Path-dependent similarity. The basic assumption here is that two nodes are similar
if they are connected by many paths. Since elements of an n-th power of the adjacency
matrix, An, are equal to the number of distinct paths between respective pairs of nodes,
path-dependent similarity metrics can be usually written in a compact form such as
xy = (A2)xy + ϵ(A3)xy
for the Local Path Index where only paths of length two and three count and ϵ is a
6We use the abbreviation LHN1 to distinguish this index to another index named as LHN2 also proposed
by Leicht, Holme and Newman.
damping parameter. (Note that in a bipartite network, only paths of an even length can
exist between nodes of the same kind.) By including paths of all lengths, we obtain the
classical Katz similarity which is deﬁned as
= βAxy + β2(A2)xy + β3(A3)xy + . . . ,
where β is a damping factor controlling the path weights. This can be written as sKatz =
(I −βA)−1 −I. A variant of the Katz index, Leicht-Holme-Newman Index (LHN2) ,
was proposed where the term (Al)xy is replaced with (Al)xy/E[(Al)xy] where E[X] is the
expected value of X.
(iii) Random-walk-based similarity.
Another group of methods is based on random
walks on networks.
Average Commute Time: The average commute time between nodes x and y is
deﬁned as the average number of steps required by a random walker starting from node x
to reach node y plus that from y to x. It can be obtained in terms of the pseudoinverse of
the network’s Laplacian matrix, L+, as 
 (L+)xx + (L+)yy −2(L+)xy
where E is the number of edges in the network. Assuming that two nodes are similar if
they have small average commute time, similarity between nodes x and y can be deﬁned
as the reciprocal of their average commute time
(L+)xx + (L+)yy −2(L+)xy
where the constant factor E has been removed.
Cosine-based on L+: This index is an inner-product-based measure. In the Euclidean
space spanned by vx = Λ
2UTex where U is an orthonormal matrix composed of the eigenvectors of L+ ordered in a decreasing order of their eigenvalues λx, Λ = diag(λx), ex is a
column base vector ((ex)y) = δxy) and T is matrix transposition, elements of the pseudoinverse of the Laplacian matrix are the inner products of the node vectors, (L+)xy = vT
Consequently, cosine similarity is deﬁned as 
|vx||vy| =
(L+)xx(L+)yy
Random Walk with Restart: This index is a direct application of the PageRank
algorithm . Consider a random walker starting from node x recursively moves to a
random neighbor with probability c and returns to node x with probability 1−c. Denoting
by qxy the resulting stationary probability that the walker is located at node y, we can
qx = cPTqx + (1 −c)ex
where P is the transition matrix with elements Pxy = 1/kx if x and y are connected and
Pxy = 0 otherwise. The solution to this equation is
qx = (1 −c)(I −cPT)−1 ⃗ex.
Finally, the similarity index is deﬁned as
= qxy + qyx.
A fast algorithm to calculate this index was proposed and the application to recommender systems was studied in where it was found that this similarity performs
better than the Pearson correlation coeﬃcient.
SimRank: This index is deﬁned based on the assumption that two nodes are similar if
they are connected to similar nodes. This allows us to deﬁne SimRank in a self-consistent
way as
z′∈Γy sSimRank
where sxx = 1 and C ∈ is a free parameter.
SimRank can also be interpreted
by the random-walk process: sSimRank
measures how fast are two random walkers, who
respectively start at nodes x and y, expected to meet at a certain node.
Matrix Forest Index: This index introduces similarity between x and y as the ratio
of the number of spanning rooted forests such that nodes x and y belong to the same
tree rooted at x to all spanning rooted forests of the network (for details see ). Its
mathematical deﬁnition
sMFI = (I + L)−1.
can be further parametrized to obtain a variant of MFI
sPMFI = (I + αL)−1,
According to the authors, α > 0 determines the proportion of accounting for long connections between vertices of the graph versus short ones.
Local Random Walk: To measure similarity between nodes x and y, a random walker
is introduced in node x and thus the initial occupancy vector is πx(0) = ex. This vector
evolves as πx(t + 1) = PTπx(t) for t ≥0. The LRW index at time step t is deﬁned as
(t) = qxπxy(t) + qyπyx(t)
where q is the initial conﬁguration function and t denotes the time step. In it was
suggested to use a simple approach where q is determined by node degree: qx = kx/M. Note
that in bipartite networks, an even time step must be used to obtain similarity between
nodes of the same kind.
Superposed Random Walk: Similar to the RWR index, in they proposed another index where the random walker is continuously released at the starting point, resulting in a higher similarity between the target node and its nearby nodes. The mathematical
expression reads
[qxπxy(τ) + qyπyx(τ)].
In , several random-walk-based similarity indices, such as ACT, cos + and MFI,
were applied in collaborative ﬁltering. Their experimental results show that in general,
Laplacian-based similarities perform well.
4.2.3. Similarity involving external information
Besides the fundamental user-object relations and the ratings, additional information
can be exploited to deﬁne or improve the node similarity.
(i) Attributes.
The dimension and elements of the attribute vectors are deﬁned in
advance by some domain experts, and is identical to all users (objects) in the system. The
similarity between two users (objects) is obtained by calculating the correlation of their
corresponding attributes vectors. For example, user proﬁles, usually including age, sex,
nationality, location, career, etc., can be simply applied to quantify the similarity between
users based on the assumption that two users are similar when they have many common
features. In , a hybrid method considering both attributes of objects and the ratings
was shown to provide better recommendations than when these two sources of information
are used independently. However, the application of attributes represents some risks to user
privacy—as shown by a recent work on de-anonymization of large datasets , collection
and utilization of attribute data poses several sensitive issues. For more information on
the issues of user privacy see .
(ii) Contents. Modern information retrieval techniques allow us to automatically extract
content and meta information of the available objects. Object similarity can hence be
calculated based on the content comparison of the given objects. This is usually referred
as content-based recommendation in literature .
Unlike collaborative ﬁltering, in
a content-based algorithm, recommendations are made based solely on the proﬁle built
up by analyzing the content of objects that the target user has rated in the past. The
recommendation problem hence becomes a search for objects whose content is most similar
to the content of objects already preferred by the target user. The classical method to
weigh content is TF-IDF (term frequency - inverse document frequency) , which is a
weighing metric often used in information retrieval and text mining. A term, t, in a given
document, d, is weighted as,
Wt,d = tf(t, d) × log
|d : t ⊆d|,
where tf(t, d) is the frequency of t in document d, |D| is number of all observed documents.
Then Wt,d can be used to measure the similarly of objects deﬁned in Sec. 4.2.2. In addition,
if two users have collected objects with similar content, we may assume that these two users
are similar.
Since both content-based method and collaborative ﬁltering have their individual limitations, such as CF systems do not explicitly incorporate feature information and face
the sparsity and cold-start problems, while content-based systems do not necessarily incorporate the information in preference similarity across individuals (see summaries and
discussions in Refs.
 ), many hybrid algorithms are proposed to avoid certain
weaknesses in each approach and thereby improve the recommendation performance. The
combination methods can be classiﬁed into four categories: (i) implement separate collaborative and content-based methods and then combine their predictions ; (ii) add
content-based characteristics to collaborative models ; (iii) add collabora-
tive characteristics to content-based models and (iv) develop a general uniﬁed model
that integrate both content-based and collaborative characteristics .
However, these methods are only eﬀective if the objects contain rich content information
that can be automatically extracted. This is the case for recommendation of books, articles
and bookmarks, but not for videos, music tracks or pictures
(iii) Tags.
Collaborative tagging systems emerged with the advent of Web2.0 .
Diﬀerent from traditional taxonomy with hierarchical structure, tagging systems allow
users to freely assign keywords (which are usually referred to as tags) to manage their
own collections without the limitation of a preset vocabulary. Tags provide a rich source
of information for recommendation purposes. With the tagging information, algorithms
can be easily designed to calculate user similarity and object similarity by considering
tag vectors in user and object space, respectively. To alleviate the eﬀects of spam and
magnify personalized user preferences, weighting techniques are often applied to measure
the importance of each element in a given tag vector.
5. Dimensionality Reduction Techniques
Dimensionality reduction aims at downsizing the amount of relevant data while preserving the major information content. It is often applied in areas such as data mining,
machine learning and cluster analysis. Most techniques of dimensionality reduction involve feature extraction which makes use of hidden variables, or so called latent variables,
to describe the underlying causes of co-occurrence data. In the context of movie selection,
potential viewers may consider genres such as action, romance or comendy features in a
movie, which consititute the latent variables. These latent variables are usually represented by multi-dimensional vectors. A simpliﬁed picture of two-dimensional vectors of
action and romance is shown in Fig. 7, which shows that user Peter has a preference in
action movies, while user Mary prefers romantic content. Given these vectors and the
corresponding vectors of movies, we can deﬁne the expected rating of a user on a move as
the scalar product of their vectors. For instance, we expect Peter prefers movie β rather
than α, while the opposite is true for Mary. Recommendations can thus be made once the
vectors are computed. If K hidden variables are used, the latent vectors are K-dimensional
and dimensionality reduction is achieved if K(N +M) < NM, since the number of relevant
variables is reduced. In practise, these techniques are particularly suitable for large data
sets which are costly to store and manipulate.
Instead of introducing latent variables which describe interests and genres, users and objects can also be assigned to individual classes which leads to reduction of data dimension.
In this case, the co-ocurrence of a user-object pair is explained by the relation between the
classes to which the user and the object belong to. Though the original intention for such
classiﬁcation is not to reduce the data dimension, the number of classes used is usually
signiﬁcantly smaller than the number of users and objects, which then results in reduction
of dimensionality.
Dimensionality reduction is in particular well applicable in collaborative ﬁltering (it is
sometimes referred to as model-based collaborative ﬁltering), as for most applications only
a small fraction of user-object pairs are observed such that the number of relevant variables can be signiﬁcantly reduced. Reductions in dimensionality eﬀectively preserve the
information content while drastically decreasing the computation complexity and memory
requirements for making recommendations. In this section, several techniques of dimensionality reduction with implementation to recommender systems are discussed, including
singular value decomposition (SVD) , Bayesian clustering , probabilistic latent
semantic analysis (pLSA) and latent dirichlet allocation (LDA) .
5.1. Singular Value Decomposition (SVD)
We start with a N × M matrix R whose element riα corresponds to the rating of user i
to object α (if the rating has not yet been given, the corresponding element of R is zero).
In the case without numeric ratings, R becomes the adjacency matrix as riα = 0, 1 for
connected and unconnected user-object pair, respectively. Recommendation process then
aims to determine which presently zero entries of R have high chance to be non-zero in the
Figure 7: An example of a user’s movie selection process with hidden variables.
future. Note that R is a sparse matrix for most applications because only a small fraction
of all its elements are diﬀerent from zero.
Dimensionality reduction is achieved by introducing K hidden variables which categorize tastes of users and attributes of objects. The original R is approximated as the
product of two matrices
where W and V are respectively matrices with dimension N ×K and K ×M. They contain
the taste information for users and content information for objects, respectively, expressing
them in terms of K hidden variables. Because of these hidden variables, SVD belongs to a
broad class of latent semantic analysis (LSA) techniques. From the product of W and V
in Eq. (51), we see that objects are selected by users based on the overlap between a user’s
tastes and a movie’s attributes. When the number of hidden variables is smaller than N
and M, the number of parameters needed to describe the system reduces from NM for
the original R to NK + KM for the product WV . This approach is also known as matrix
factorization (MF) as R is factorized into a product of matrices.
To obtain W and V , singular value decompostion (SVD) is a common algebraic tool
in LSA which results in downsizing of relevant variables and, at the same time, ﬁnding a
good approximation of R. In SVD, R is factorized as
where Σ is a K × K diagonal matrix, and equality in the above factorization holds with
K = min(N, M). The matrix Σ contains the so-called singular values of R, which are
indeed the square root of the eigenvalues of RR∗(or R∗R). To beneﬁt from dimensionality
reduction, we put K < min(N, M) which corresponds to the K-rank approximation in
SVD and include only the K largest singular values in Σ and replace the others by zero.
Equality in Eq. (52) no longer holds and R is approximated with ˜R given by
R ≈˜R = W ˜ΣV
where ˜Σ is the K-rank approximation of Σ.
It can be shown that ˜R can be found by minimizing the Frobenius norm of the matrix
R −˜R, that is
˜R = argmin
with the rank of ˜R′ restricted to be K. The Frobenius norm is given by
(riα −˜riα)2,
which corresponds to the root square error of ˜R with respect to R, with ˜riα denoting the
element (i, α) in ˜R. SVD thus provides a simple cost function for measuring the agreement
between R and ˜R. To obtain ˜R explicitly for a particular R, an simple iterative approach
 based on gradient descent can be employed. Σ in Eq. (53) is ﬁrst absorbed into either
W or V to obtain ˜R = WV as in Eq. (51). Our task is to obtain the optimal W and V
for which ˜R = WV minimizes the norm in Eq. (55). We now express ˜riα as
After substitution of the above expression, we minimize the diﬀerence between riα and ˜riα
by diﬀerientiation of (riα −˜riα)2, namely
(riα −˜riα)2 = −2wik
(riα −˜riα)2 = −2vkα
Since the norm is non-negative by deﬁnition, we minimize the norm square which leads
to the same result while encountering simpler expressions in the process. The obtained
gradients can be used to write a gradient descent-based updating procedure for wik and
vkα in the form
wik(t + 1) = wik(t) + 2ηwik(t)eiα(t),
vkα(t + 1) = vkα(t) + 2ηvkα(t)eiα(t),
where t denotes the iteration step and
eiα(t) = riα −
wik(t)vkα(t).
The learning rate η > 0 should be small to avoid big jumps in the solution space. With
random initial conditions on wik and vkα, these equations are iterated until the squared
norm shows no further decrease.
Other procedures such as the variants of stochastic
gradient descent may be applied to improve computational eﬃciency . As suggested
by , substracting a small term from the gradient can prevent large resulting weights
of wik and vkα (this is equivalent to minimizing ∥R −˜R∥2 + λ
2∥V ∥2, or similar to
using the Tikhonov regularization which gives preference to solutions with small norms in
ill-posed problems), which leads to the following update rule
wik(t + 1) = wik(t) + η
 2wik(t)eiα(t) −λwik(t)
vkα(t + 1) = vkα(t) + η
 2vkα(t)eiα(t) −λvik(t)
where a new parameter λ ≥0 is introduced to this end; λ > 0 usually leads to better
accuracy of the results. Using the resulting wik and vkα, we can compute ˜R = WV which
has non-zero values on entries where the input matrix R are zero (representing unexpressed
evaluations)—element ˜riα then predicts the possible rating given by user i to object α.
Note that while ∥R −˜R∥measures the “error” of ˜R with respect to R, it is usually
very diﬀerent from (greater than) the error of the ultimate rating estimates. The reason
for this, of course, lies in the fact that ∥R −˜R∥is minimized while knowing R, and the
K(N + M) free parameters usually allow us to achieve very low value of ∥R −˜R∥. To
measure performance of this method correctly, the available data must be divided into a
training set (which is used to “learn” W and V ) and a test set (see Sec. 3.3 for details).
Increasing K does not automatically improve the results: over-ﬁtting the data (providing
too many free parameters) can lead to inferior accuracy. The use of this and other machinelearning methods hence requires a certain amount of tests and/or experience.
In addition to a simple iteration procedure, SVD also enjoys a ﬂexibility in dealing
with additional data. For instance, one can easily include the inﬂuence of individual rating
bias in the framework. Suppose user i tends to give an average of bi more score for all his
items when compared to other users, while object α tends to receive bα more scores when
compared to other items, the predicted scores can be expressed as 
˜riα = µ + bi + bα +
where µ is the average value among all user-object pairs. In this case, ∥R−˜R∥is minimized
with respect to bi, bα, wik and vkα for all i, k and α. Other than individual bias, there
are other variants of SVD which utilizes the relations between users in social network, for
instance the similarity in taste between friends, to improve the recommendation accuracy
by the factorized matrices .
Apart from the case with user-object ratings as the only input data, the above-described
procedure can be generalized to incorporate additional information . Suppose diα is the
additional information (e.g.date) associated with a given user-object pair. Transforming
diα into positive integers l with 1 ≤l ≤L, the elements ykl in the K × L matrix Y contain
the relation between each of these additional data and the hidden variables. For example,
a large number of movies with romantic content are reviewed on the Valentine day, leading
to a large value in the corresponding entries of romance and Valentine day in Y . With the
additional information, the matrix ˜R can be expressed as
wikvkαykdiα.
Similar derivations based on gradient descent provide updating procedures for wik, vkα and
yk,diα which can then be used to obtain ˜R with the smallest error with respect to R.
5.2. Bayesian Clustering
Before describing a probabilistic version of LSA, we ﬁrst introduce the Bayesian clustering method which is also probabilistic but simpler in formulation. In Bayesian networks,
the value of a variable depends only on the value of its parent variables. For example,
the probability of a variable x is described by the conditional probability P(x|pax) where
pax is the parent variable of x. The joint probability of several independent variables can
be factorized as P(x1, . . . , xN) = QN
i=1 P(xi|paxi) which represents the dependency structure of the variables. However, obtaining the most relevant dependency structure, i.e.the
dependency relation between diﬀerent nodes in the Bayesian network, is not a trivial task.
For the purpose of personalized recommendation, we describe a two-sided clustering
 which is easy to implement. To obtain the rating for an unobserved user-object
pair, one classiﬁes users and objects respectively into Kuser and Kobject classes. The values
of Kuser and Kobject are parameters on the algorithm, similarly to K which was a parameter
of SVD. We assume that there is a simple Bayesian network that underlies the input data—
the simplest assumption is that riα depends only on the user’s class ci and the object’s
class cα. The probability of riα can then be written as
P(riα|ci, cα)P(ci)P(cα),
To obtain an estimate of riα, we need to ﬁnd P(ci), P(cα) and P(riα|ci, cα), which is
eﬀectively P(r|x, y) as the rating r is dependent merely on the user class x and the object
This can be done by applying the inference methods including the marginal
estimation by belief propagation and likelihood maximization by expectation
maximization . Here we describe another simple scheme, known as the Gibbs sampling
method , which is similar to the heat bath algorithm in statistical physics .
Gibbs sampling is useful when the joint distribution of all variables is diﬃcult to sample (in
our case, P({r|(x, y)}, {ci}, {cα})), while sampling the conditional probability of individual
variables given all other variable is comparatively easy (e.g., P(ci′|{r|(x, y)}, {ci}−i′, {cα})).
It is similar to the heat bath algorithm as it models the state of a system moving in a phase
space and samples at certain time intervals the required (physical) quantities.
Here we describe the Gibbs sampling scheme suggested in to sample the state
({r|(x, y)}, {ci}, {cα}) of the system which allows us to evaluate the predicted ratings for
any unobserved user-object pair. This scheme was developed to sample binary ratings so
we assume that riα = 1 when user i has collected α or rated object by a score above a
certain threshold; riα = 0 otherwise. In this case, one can represent P(r|x, y) by a single
value variable Pxy corresponding to the probability that a user from category x likes an
object from category y.
We start the algorithm with a random latent class assignment for all users and objects
and evaluate Nx, Ny and Nxy, respectively correspond to the number of users in class x, the
number of objects in class y, and the number of observed user-object pairs (i.e., riα = 1) for
all pairs of classes. We then draw values of Pxy from the beta distribution with parameters
(Nxy + 1, NxNy −Nxy + 1), or simply approximate Pxy by its mean Pxy = Nxy/NxNy.
Similary, the variables Px and Py, respectively deﬁned as the probability that a random
user or object is classiﬁed in class x or y, are drawn from Dirichlet distributions or simply
approximated by Px = Nx/N and Py = Ny/M. All these values of Pxy, Px and Py are used
to evalulate the transition probability of the system from the present state to another state
in the phase space. We then successively pick either a random user or a random object
and update its latent class as 
P(ci = x) ∝Px
α riαδcα,y
α(1−riα)δcα,y,
for users, and
P(cα = y) ∝Py
i riαδci,x
i(1−riα)δci,x.
for objects.
These equations involve large powers of probability values and may lead
to inaccurate numerics during the computation. Instead of computating the probability
direcly, one can ﬁrst compute the powers and convert them to probability during the update
of latent classes. The values of Nx, Ny and Nxy, and thus of Px, Py and Pxy, are updated
after each update of user class or object class. After a suﬃcient number of iterations, we can
start sampling estimated ratings of unobserved user-object pairs at regular time intervals
which should be long enough to ensure low correlation between consecutive sampled states.
For instance, the predicted rating for user i on object α can be obtained by
Pxy(tc + tT)δx,ci(tc+tT)δu,cα(tc+tT),
where tc and T are respectively the convergence time and the sampling time interval.
We can also store the state ({Pxy}, {ci}, {cα}) at each sampling time and use the above
equation to obtain the predictions afterwards.
We remark that the above two-sided Bayesian network corresponds to the simplest
dependency structure which relates ratings to merely user and object classes. More comprehensive Bayesian relation can be derived, for instance, to include the individual rating
preference for objects or to model the possibility of mixed membership . Another class of extensions is to build a probabilistic relational model (PRM) to predict
ratings by utilizing other meta-data including age, occupation and gender of users, or
category, price and origin of objects. Although this comprehensive information generally
improves recommendation results, to determine a valid dependency structure of meta-data
is a non-trivial task in PRM.
5.3. Probabilistic Latent Semantic Analysis (pLSA)
Probabilistic latent semantic analysis (pLSA) is similar to LSA in the sense that hidden
variables are introduced in to explain the co-occurrence pairs of data. Unlike the algebraic
SVD employed in LSA, pLSA is a statistical technique based on a probabilistic model. Well
developed inference methods including likehood maximization and Gibbs sampling
 can thus be employed in pLSA. pLSA models the relations between users and objects
through the implicit overlap of genres, as compared to the two-sided Bayesian clustering
where each user and object belong to a single speciﬁc category. In pLSA, the co-occurrence
probability P(i, α) of user i and object α is expressed using the conditional probability given
a hidden variable k
P(i|k)P(α|k)P(k).
Since P(i|k)P(k) = P(k|i)P(i), this can be written as
P(i, α) = P(i)
P(α|k)P(k|i)
which leads to the condititonal probability P(α|i) of an object α to be collected given the
P(α|k)P(k|i),
which is already a quantity useful for personalized recommendation. Unlike the Bayesian
clustering approach where the co-ocurrences of users and objects are characterized by the
coupled probability Pxy between the classes, users and objects are rendered independent
in pLSA given the hidden variables—the co-ocurrence probabilities are factorized. Our
task is to obtain suitable forms of P(α|k) and P(k|i) which provide accurate predictions
of collected and recommended objects through P(α|i). We note that instead of P(α|i),
P(i, α) can also be expressed as
P(i, α) = P(α)
P(i|k)P(k|α)
to obtain P(i|α) which can be of interest for some purposes.
To obtain P(α|k) and P(k|i), one can adopt a variational approch described in 
to maximize the per-link log-likelihood of the observed dataset which is given by
L(φ, θ) = 1
log P(α|i) = 1
P(α|k)P(k|i)
with respect to vectors φ and θ which parametrize P(α|k) and P(k|i) by P(α|k) = φ(k)
and P(k|i) = θ(i)
k . Here E is the total number of user-object links. We remark that the sum
over (i, α) includes only the observed user-object pairs. We then employ the expectation
maximization (EM) algorithms to ﬁnd the value of θ that maximize L(φ, θ). To
achieve the goal, one can introduce the variational probability distribution Q(k|i, α) in
Eq. (73) for each observed pair (i, α), with the constraint PK
k=1 Q(k|i, α) = 1, which allows
us to rewrite L(φ, θ) as
L(φ, θ) = 1
Q(k|i, α)P(α|k)P(k|i)
Q(k|i, α) log P(α|k)P(k|i)
:= F(Q, φ, θ)
with the inequality is justiﬁed by Jensens’ inequality. F(Q, φ, θ) can be written as
F(Q, φ, θ) = 1
Q(k|i, α) log[P(α|k)P(k|i)] + Siα(Q)
with Siα(Q) being the entropy of the probability distribution Q for the pair (i, α) which is
Siα(Q) = −
Q(k|i, α) log Q(k|i, α).
Since F serves as the lower bound of likelihood function L(φ, θ), we maximize F with respect to Q, φ and θ. The expectation maximization algorithm thus maximizes F by ﬁnding
the optimal Q, φ, θ alternatively. We ﬁrst obtain the distribution Q which maximizes F
by assuming a particular form of P(α|k) and P(k|i), i.e.holding φ and θ constant. Maximization of F in this step is subject to the normalization of Q(k|i, α) for every observed
user-object pair which leads us to the Lagrangian
L(Q, φt, θt) = F(Q, φt, θt) +
Q(k|i, α) −1
where φt and θt denotes respectively φ and θ after t iteration steps, or equivalently,
Pt(α|k) and Pt(k|i). L(Q, φt, θt) can then be diﬀerentiated to obtain the optimal Q for
every observed user-object pair in the form
Qt(k|i, α) =
Pt(α|k)Pt(k|i)
k′=1 Pt(α|k′)Pt(k′|i)
k′=1 φ(k′)
This optimal Q is obtained from θt and φt, thus we label it as Qt.
We then proceed to obtain the distributions P(α|k) and P(k|i), i.e.the value of φ(k)
k , by assuming Q is held ﬁxed at Q = Qt obtained from Eq. (79). Due to the
normalization of P(α|k) for all α and P(k|i) = 1 for all i, the corresponding Lagrangian
has the form
L(Qt, θ) = F(Qt, θ) +
After diﬀerentiation, the optimal P(α|k) and P(k|i) can be found
Pt+1(α|k) = φ(k)
i Qt(k|i, α)
i Qt(k|i, α′),
Pt+1(k|i) = θ(i)
α Qt(k|i, α)
α Qt(k′|i, α)
where the summation involving i and α runs only over the observed user-object pairs. The
optimal P(α|k) and P(k|i) are obtained from Q = Qt. We label them as Pt+1(α|k) and
Pt+1(k|i), respectively, because they constitute the basis for the next iteration step where
Qt+1 is found. After stationary values of Qt, φt and θt are found, Eq. (71) is used to obtain
personalized recommendations.
As the above pLSA model considers a multinomial distribution φ(k)
which can be used
to model only binary preferences, one may consider the generlized pLSA which allows
for numeric ratings. The fast increasing number of independent variables used by pLSA
(there are K(N +M) of them) and the cold-start problem for new objects can be alleviated
by asssuming prior distributions on φ(k) and θ(i), such as Dirichlet priors discussed in the
following section .
5.4. Latent Dirichlet Allocation (LDA)
Latent Dirichlet Allocation (LDA) is similar to pLSA in the sense that hidden
variables are present in a probabilistic way. While pLSA does not assume a speciﬁc prior
distribution over P(k|i), LDA assumes that priors that have the form of the Dirichlet
distribution. LDA was applied to predict review scores based on the content of reviews
 and to uncover implicit community structures in a social network . It can be
also extended to include general meta-data of users and objects .
For each user i there is a distribution P(k|θ(i)) where θ(i) is a K-dimensional multinomial
distribution with θ(i)
k is the probability of user i belonging to the latent class k, i.e.P(k|i) =
k . Unlike pLSA, the variable θ(i) in LDA has a Dirichlet prior distribution with a Kdimensional parameter a. The probability of observing user i with the collected object set
P({α}i|a, φ) =
dθ(i)P(θ(i)|a)
P(αi,µ|k)P(k|θ(i))
Figure 8: A so-called plate notation representing the LDA recommendation model: a and b represent the
model’s parameters at the system level, which characterize respectively the Dirichlet distribution of θ(i)
α , where P(k|i) = θ(i)
and P(α|k) = φ(k)
where ki is the number of objects collected by user i and αi,µ is the µ-th object collected
by i. The Dirichlet prior distribution P(θ(i)|a) is
P(θ(i)|a) = Γ
where Γ(x) is the Gamma function, the constraint PK
k = 1 holds and θi,k > 0 for all
i and k. Prior distributions for all θ(i) share the same parameter a. The LDA model can
be represented by a so-called plate notation which is shown Fig. 8. The probability of the
observed data {(i, α)},
P({(i, α)}|a, φ) =
dθ(i)P(θ(i)|a)
P(αi,µ|k)P(k|θ(i))
depends on the parameter vectors a and b.
In the original formulation of LDA , P(α|k) is given by a multinomial distribution
parametrized by φ such that P(α|k) = φ(k)
as in the case of pLSA. Some variants of LDA
consider P(α|k) following a Dirchlet prior distribution, which is known as a smoothed version of LDA . In this case, b which characterizes the prior distribution of P(α|k) = φ(k)
in Eq. (83) corresponds to a M-dimensional parameter of the Dirichlet prior distribution
P(φ(k)|b) = Γ
Prior distributions for all φ(k) share the same parameter b.
In order to obtain rating predictions for unobserved user-object pairs, one has to ﬁnd
P({φ(k)}, {θ(i)}|{(iα)}, a, b) and use {φ(k)} and {θ(i)} to make personalized predictions
for user i.
For instance, the predicted score for an unobserved pair (i, α) is given by
k . Since the distribution of {φ(k)}, {θ(i)} is in general intractable, one can
follow and adopt a variational approach to maximize likelihood—similarly as we did
in the case of pLSA. Here we describe the Gibbs sampling for the smoothed LDA as an
alternative inference method . The procedures are similar to the Gibbs sampling in
Bayesian networks, except that one assigns a latent class for each user-object pair, instead
of classes for individual users and objects.
To derive an equation for Gibbs sampling in LDA, we ﬁrst assign an index µ for each
observed user-object pair (i, α) so that kµ is a latent variable drawn from the multinomial
distribution θ(iµ) and αµ is an object drawn from the multinomial distribution φ(kµ). As
shown in , the inference method is much simpliﬁed by assuming a symmetry
Dirichlet prior with homogeneous a and b, i.e.a1 = · · · = aK := a and b1 = · · · = bM := b.
Then one can show that the conditional probability for an observed user-object pair µ′
characterized by kµ′ is given by
P (kµ′ = k|{kµ}−µ′, {(iµ, αµ)}) ∝P (αµ′|kµ′ = k, {kµ}−µ′, {(iµ, αµ)}−µ′) P (kµ′ = k|{kµ}−µ′)
−µ′,αµ′ + b
where all n−µ′’s are evaluated in the absence of pair µ′: n(k)
−µ′ is the number of observed
pairs charaterized by latent class k, n(k)
−µ′,α is the number of observed pairs of object α
charaterized by latent class k, n(i)
−µ′ is the number of observed pairs of user i (degree of i)
−µ′,k is the number of observed pairs with user i characterized by latent class k.
The Gibbs sampling process runs as follows. We ﬁrst start with a random assignment
of latent class to each observed user-object pair and successively pick a random user-object
pair to update its latent class according to Eq. (87). This corresponds to a shift of the
system state from one to another; n(k), n(k)
αµ′, n(iµ′) and n
are updated after each new
assignment of the latent class. After a suﬃcient number of iterations, one can sample φ(k)
and θ(i) at a regular time interval
n(k) + Mb,
n(i) + Ka.
With these samples of φ(k) and θ(i), the predicted score for an unobserved user-object pair
can be computed as
α (tc + tT)θ(i)
k (tc + tT),
where tc and T are respectively the convergence time and the sampling time interval. As
in the Gibbs sampling of Bayesian clustering, states of φ(k) and θ(i) can be stored and use
to compute the predicted scores later. When the input data is large, one can distribute
the Gibbs sampling to several processors to shorten the computation time .
6. Diﬀusion-based methods
Similarly as the classical PageRank algorithm brought the order to the Internet
by analyzing the directed network of links among web pages, one could aim to obtain
recommendations using a network representation of the input data with user preferences.
The algorithms presented in this section are all based on speciﬁc transformations (projections) of the input data to object-object networks. Personalized recommendations for an
individual user are then obtained by using this user’s past preferences as “sources” in a
given network and propagating them to yet unevaluated objects.
6.1. Heat diﬀusion algorithm (HDiﬀ)
This algorithm is based on projecting the input data on a simple object network characterized by a symmetric adjacency matrix A with elements either one (for similar objects)
or zero (for dissimilar objects). It recommends objects to an individual user by a process
motivated by heat diﬀusion: objects liked and disliked by this user are represented as hot
and cold spots respectively, and recommendation is made according to the equilibrium
“temperature” of the nodes in the networks . The discrete Laplace operator of the
network has the form L = 1N −D−1A where D is the network’s diagonal degree matrix with
elements Dαβ = kαδαβ. This operator is a discrete analog of the heat diﬀusion operator
−∇2 which is well-known in physics. The resulting temperature vector for user i, hi, is
the solution of the heat diﬀusion equation
and has both variable part (which we seek) and ﬁxed part. Fixed elements of hi correspond
to objects already evaluated by user i; they are set to 1 (objects liked by the user—they act
as heat sources) or 0 (objects disliked by the user—they act as heat sinks). Mathematically
this corresponds to the Dirichlet boundary condition. The external ﬂux vector f i is nonzero only for objects evaluated by user i and allows for ﬁxed values attributed to sources
and sinks. Eq. (90) can be solved using the Green’s function method and the involved
computational cost can be lowered by utilizing various algebraical properties of L . At
the same time, it is straightforward to ﬁnd the equilibrium hi iteratively by setting the
initial temperature vector h(0)
to contain only the ﬁxed heat sources and sinks and iterate
i is the same as the Laplace operator above except that it keeps elements in hi
corresponding to i’s evaluated objects unchanged.
Given this mathematical framework, it is still an open question how exactly to apply it
to a given rating matrix R. The procedure adopted in is that the Pearson’s correlation
coeﬃcient for ratings of objects α and β, Cαβ, is compared with a speciﬁed threshold Ct
and Aαβ = 1 when Cαβ ≥Ct and it is zero otherwise. The threshold Ct is set so that the
resulting number of links is the same as the number of non-zero entries in RTR (which is
equivalent to the number of object pairs co-evaluated by at least one user). The boundary
Figure 9: Graphical representation of the links created by a user who has rated only objects 1 (rating 5),
2 (rating 3) and 3 (rating 4).
condition for user i is composed of the ratings given by this user to diﬀerent objects (note
that the heat diﬀusion equations above are not constrained to the binary case like/dislikehot/cold and can be used to arbitrary-valued ratings).
6.2. Multilevel spreading algorithm (MultiS)
This algorithm can be applied when ratings riα are given in a discrete scale.7
example, Amazon.com employs a ﬁve-star scale where one and ﬁve stars correspond to
the worst and best rating, respectively. For the sake of simplicity, we assume a ﬁve-level
rating scale in the rest of this subsection (generalization to a diﬀerent number of levels
is straightforward).
As in other diﬀusion-based methods, the recommendation process
starts with the preparation of a particular object-object projection of the rating data. To
eliminate the loss of information in the projection, instead of merely creating a link between
two objects, in this multilevel spreading algorithms, links are created between ratings given
to a pair of objects . As a result we obtain 52 = 25 separate connections (channels) for
each object pair. This is illustrated in ﬁg. 9 on an example of a user who has rated three
movies; as a result, three links are created between the given movies. When all data are
processed, contributions from all users accumulate and a weighted object-object network
is created. Note that splitting the connection between two objects into multiple separate
channels aggravates the data sparsity problem and can lead to inferior performance of this
algorithm in some cases.
Between a given pair of objects we create multiple links which are conveniently stored
in a 5×5 matrix. By representing integer ratings riα with column vectors in 5 dimensional
space (unknown rating with viα = (0, 0, 0, 0, 0)T, rating riα = 1 with viα = (1, 0, 0, 0, 0)T,
rating riα = 2 with viα = (0, 1, 0, 0, 0)T, etc.), connection matrix for objects α and β has
7It is also possible to apply a binning procedure to continuous-valued ratings and hence transform them
into an integer scale but that has not been used in practice yet.
Weights of individual users are inversely proportional to their number of evaluations—this
aims to compensate the quadratically growing number of links created by an individual
user, ki(ki −1)/2, hence in total we get a linear relation between user’s number of evaluations and the cumulative weight of user’s ratings.8
Matrices Wαβ form a symmetric matrix W with dimensions 5N × 5N. By the column
normalization of W we obtain an asymmetric matrix Ωwhich describes a diﬀusion process
on the underlying network with the outgoing weights from any node in the graph normalized
to unity (if one chooses the row normalization instead, the resulting process is equivalent to
heat conduction in the network; for a mathematically-oriented review of ﬂows in networks
see ).
Elements with large weights in Ωrepresent strong patterns in user ratings
(e.g., most of those who rated movie X with 5 gave 3 to movie Y). Similarly as for other
diﬀusion-based methods, we obtain personal recommendations for user i by combining the
aggregate matrix Ωwith opinions already expressed by i. This opinions are stored in a
5N-dimensional vector h(0)
(the ﬁrst 5 elements correspond to object 1, next 5 elements
to object 2, etc.). As in Sec. 6.1, we seek the stationary solution of the equation
Ωihi = hi,
where Ωi is the same as Ωexcept it keeps the elements corresponding to the objects
evaluated by user i unchanged. Resulting vectors h(n)
contain information about objects
unrated by user i.
This information can be used to obtain rating predictions by the
standard weighted average.
For example, if for a given object in hi we obtain the 5tuple (0.0, 0.2, 0.4, 0.4, 0.0)T, the rating prediction is 0.2 × 2 + 0.4 × 3 + 0.4 × 4 = 3.2.
Numeric tests presented in suggest that h(1)
is a good enough predictor. Sophisticated
techniques to avoid multiple iterations in Eq. (93) are hence not fundamental for
practical applications of this algorithm. An alterative way is to map each object to several
channels with the number of channels being equal to the number of diﬀerent ratings. So
that if a user i has collected an object α with rating 2, her will only connect to α(2). After
that, one can directly apply the probabilistic spreading process (see the next subsection)
to obtain the similarity and then integrate it into the collaborative ﬁltering framework to
obtain better recommendation .
6.3. Probabilistic spreading algorithm (ProbS)
This algorithm is suitable for data without explicit ratings, i.e. only the sets of object
collected/visited by each user is known. Elements of the rating matrix R are hence riα = 1
(when user i has collected/visited object α) or riα = 0 (otherwise). More explicit preference
8Since the users who have evaluated only one object add no links to the object-object network, the
divergence of the weight 1/(ki −1) at ki = 1 is not an obstacle.
Figure 10: Illustration of the ProbS’s resource-allocation process in a simple bipartite network.
assigned resources ﬁrst ﬂow from object-nodes (circles) to user-nodes (squares) and then return back to
object-nodes.
indicators can be easily mapped to this form, albeit losing information in the process,
whereas the converse is not so.
The spreading recommendation algorithm proposed in is based on a projection
of the input data (which can be represented by an unweighted user-object network) to
an object-object network. In this projection, the weight Wαβ can be considered as the
importance of node α with respect to node β and in general it diﬀers from Wβα. A suitable
form of Wαβ can be obtained by studying the original bipartite network where a certain
amount of a resource (a scalar quantity which reﬂects, for example, social inﬂuence in a
recommender system) is assigned to each object node. Since the network is unweighted,
the unbiased allocation of the initial resource is split equally among all its neighboring
user-nodes. Consequently, resources collected by user-nodes are equally redistributed back
to their neighboring object-nodes.
This is equivalent to random walk from the initial
source nodes to a distance of two in the user-object bipartite graph. An illustration of this
resource-allocation process for a simple bipartite network is shown in Fig. 10.
Denoting the initial object resource values as xα, the two resource-distribution steps
can be merged to one and the ﬁnal resource values read ˜xα = PN
αβxβ where
The superscript P stands for “probabilistic” and serves to distinguish the current spreading
process from its modiﬁcations that we shall discuss later. Note that the resulting N × N
transition matrix is column normalized with W P
αβ representing the fraction of the initial
β’s resource transferred to α. Recommendations for a given user i are obtained by setting
the initial resource vector hi in accordance with the objects the user has already collected,
that is, by setting hi
β = riβ. Recommendation scores of objects are then obtained by
Objects recommended to user i are then selected according to ˜hi
α (the higher the value,
the better).
The original ProbS algorithm has been later improved in various directions. In , the
authors suggested a heterogeneous distribution of the initial resources among the nodes,
hα = aiαkθ
α, and showed that when the parameter θ is tuned appropriately, it can help
increase the accuracy of recommendations and it also makes the recommendations more
personalized. The optimal value of θ is close to -1 (e.g., -0.8 to -1.0 for MovieLens, depending on the size of the selected data set ), indicating that each item should be
assigned more or less the same amount of total initial resource. In , it was proposed
to construct the transition matrix as W + ηW2 where W is deﬁned by Eq. (94) and η is
a free parameter. By eﬀectively removing redundant correlations (the optimal value of
η is usually negative), this method succeeded in outperforming ProbS and other derived
methods in terms of accuracy and diversity of recommendations. Similar method can also
be applied in designing more accurate similarity index for collaborative ﬁltering and
link prediction . In , they proposed to increase the method’s accuracy by giving preference to objects with degree similar to the average degree of objects collected by
a given user. In addition, the degree correlation , users’ tastes , user behavior
patterns can also be accounted to improve the recommendation accuracy.
Finally, we introduce a preferential diﬀusion method, which was proposed to enhance
the algorithm’s ability to ﬁnd unpopular and niche objects . The basic idea is that at
the last step (i.e., diﬀusion from users to objects), the amount of resource that object α
receives is proportional to kε
α where ε ≤0 is a free parameter. When ε = 0, this method
is identical to ProbS. It was shown that PD not only provides more accurate recommendations than ProbS but it also generates more diverse and novel recommendations by recommending relevant unpopular items. The authors further compared the intra-similarity
of recommended items with that of the whole system. As shown in Fig. 11, they draw a
line that divides the parameter space into two phases: In the left region, especially the
Figure 11: (Color online) Intra-similarity I(L) (see Eq. 21) for MovieLens and Netﬂix. With the parameter
combination (ε, L) along this line, the intra-similarity equals the value of the system.
area corresponding to smaller ε and larger L, PD is like a concave lens that broadens the
user’s vision, while in the right region, corresponding to larger ε and smaller L, PD likes
a convex lens that narrows the user’s vision. Of course, we prefer the former case since it
embodies the merit of personalization.
Note that the resource-allocation process can also be applied in unipartite networks.
Considering a pair of nodes i and j, i can send some resource to j with their common
neighbors playing the role of transmitters.
In the simplest case, we assume that each
transmitter has a unit of resource, and will equally distribute it to all neighbors. This
deﬁnes a similarity index (called resource allocation index ) between nodes:
where Γi denotes the set of i’s neighboring nodes. Recent works showed that despite its
simplicity, this index performs better than many known local similarity indices in link
prediction , community detection , and the characterization of weighted transportation networks .
6.4. Hybrid spreading-relevant algorithms
To answer the need of diversity in algorithm-based recommendation (see Section 2.2
for a discussion of this problem and possible solutions), a hybrid algorithm was proposed
in which combines accuracy-focused ProbS with diversity-favoring heat spreading. As
in probabilistic spreading, heat spreading works by assigning objects an initial level of
“resource” denoted by the vector h, and then redistributing it via the transformation
˜h = WHh. The transition matrix of heat spreading reads
Figure 12: (Color online) Comparison of ProbS and HeatS, where the target user is marked by a star and
the collected objects are of initial resource 1. The ﬁnal scores after ProbS and HeatS are listed in the right
sides of plots (c) and (e).
which, in contrast to WP obtained with Eq. (94), is row-normalized and corresponds to a
heat diﬀusion process (thus named HeatS) on the given user-object network.
Figure 12 illustrates the procedures of ProbS and HeatS. According to the ﬁnal scores,
ProbS will recommend the third object to the target user, while HeatS will recommend the
second. Generally speaking, HeatS is able to ﬁnd out unpopular (i.e., of low degree) objects,
yet ProbS tends to recommend popular objects and thus lacks diversity and novelty. On
the other hand, recommendations obtained by HeatS are too peculiar to be useful9. To
integrate the advantages from both two algorithms, in they proposed an elegant hybrid
of WH and WP (named HybridS) in the form
where λ = 0 gives pure heat spreading and λ = 1 gives pure probabilistic spreading. As before, the resulting recommendation scores for user i are computed as ˜hi
where the initial resource values are set as hi
β = riβ. Results shown in show that
this combination of two diﬀerent algorithms allows us not merely to compromise between
diversity and accuracy but to simultaneously improve both aspects. By tuning the degree
9Compared with the similarity-based methods and ProbS, the AUC value and precision of HeatS are
considerably lower. Therefore, using HeatS alone seems not proper. Recent works indicate that
some weighted version of HeatS could also give highly accurate recommendation.
of hybridization, represented by the parameter λ, the algorithms can be tailored to many
custom situations and requirements. Note that, the parameter λ is not necessarily to be
the same for diﬀerent users and objects, namely each user i can have her own parameter λi
or each object α can have its own parameter λα, in this way, the algorithmic performance
can be further improved . And the initial resource distribution is not necessarily to
be homogeneous, and by introducing the heterogeneity, the algorithmic performance can
be improved .
Similar to the Hybrid spreading algorithm, B-Rank combines a random walk process
with heat diﬀusion but it does so for data containing explicit ratings . The transition
matrix is introduced in the form
Pαβ = 1 −δαβ
where xiα = 1 if user i has rated object α and xiα = 0 otherwise, wi is the weight of user
i and nα is a term which makes the matrix P row-normalized. User weights wi are set
all identical but can be potentially set heterogeneous, for example, to give more weight to
reliable users or suppress spammers (these possibilities have not been studied yet). Due to
the term 1−δαβ, Pαα = 0 and the corresponding random walk on the weighted object-object
network is thus non-lazy (there is no possibility to return to the initial node after one step).
Using the vector with ratings of user i, hi
α = riα, object scores corresponding to the forward
and backward propagation of hi are computed as F i = PThi and Bi = Phi (forward and
backward propagation correspond to random walk and heat diﬀusion, respectively—for
details see ).
The ﬁnal score of object α is obtained as f i
α (the higher,
the better). Note that this algorithm does not aim at predicting missing scores (hence
the traditional measures of recommender systems, MAE and RMSE cannot be applied to
evaluate it). Instead, it provides a personalized ranking (hence the name, ’B-Rank’) of
objects for each user.
The above-mentioned diﬀusion processes can be applied in computing the similarity
between users or items, and then integrated into the similarity-based methods. Liu et al.
 deﬁned the similarity between users according to ProbS10, and showed that based
on the routine collaborative ﬁltering algorithm, the proposed similarity index improved
the algorithmic performance compared with the Pearson similarity index. Pan et al. 
applied the HybridS process to deﬁne similarity, which outperforms the cosine similarity
under the framework of collaborative ﬁltering.
10Similar to Eq. 94, but the spreading process starts from user side and ends at user sides.
7. Social ﬁltering
Recommendations made by a recommender system are often less appreciated than those
coming from our friends and social inﬂuences may play a more important role than
similarity of past activities . In addition, accuracy of recommendation can be
improved by analyzing social relationships, such as coauthorships in academic literature
recommendation and friendships and memberships in product recommendation .
Many real systems, such as Delicious.com and Facebook.com, allow users to recommend
objects to their friends. Similarly, users can subscribe to articles from selected bloggers in
blogging sites (Twitter.com and others) as well as to news alerts from information dissemination systems (Elesvier.com and others). In this chapter, we will ﬁrst present empirical
evidences that demonstrate the presence of social inﬂuence on information ﬁltering. Then
we will introduce two basic ways social ﬁltering are employed in recommendation: by
quantifying and utilizing trust relationships between users and by using the opinion “taste
mates” to select the content to be recommended.
7.1. Social Inﬂuences on Recommendations
Social inﬂuences, also called the word-of-mouth eﬀect in the literatures, are known to
be crucial to many sociometric processes, such as decisions making, opinions spreading and
the propagation of innovation and fashion . Scientists have been aware of
the commercial values of social inﬂuences for a long time , yet large-scale applications
for commercial purpose only emerged when the Internet era began. Besides, the availability
and the great variety of data provide us good opportunities to quantitatively understand
social inﬂuences . This section focuses on the social recommendations, whose eﬀects
can be roughly divided into two classes: one is on users’ prior expectations, leading to the
increase of sales; another is on users’ posterior evaluations, resulting in the enhancement
of the user loyalty.
Positive eﬀects of social recommendations on prior expectation have already been
demonstrated in a number of real examples. They are found in a wide range of systems,
including product reviews , e-mails , blogs and microblogs . In
 , the authors studied the eﬀects of social inﬂuences on purchase preference: users of an
e-commerce system were given the option to recommend an item to their friends through
e-mails after purchase. The ﬁrst person to purchase the same item through a referral link
from e-mails got a 10% discount, and when this happens, the recommender will receive a
10% credit. As shown in Fig. 13, the purchase probability for a DVD grows remarkably
with the increasing number of received recommendations from friends on this DVD. There
is a saturation at about 10 recommendations, after which the purchase probability does not
increase any more. In other examples, social inﬂuences can be much more complicated. In
 , they reported a similar experiment with book sales where in contrast to the common
sense, recommendations had little or even negative eﬀect on the purchase probability. Social inﬂuences may also vary across topics and items: showed that diﬀerent tags and
topics spread on Twitter diﬀerently and found that strength and direction of social
inﬂuence are topic-dependent. A recent work shows that the mutual interaction between
Incoming Recommendations
Probability of Buying
Figure 13: Probability of buying a DVD given a number of incoming recommendations (taken from ).
opinions of past viewers and potential future viewers leads to a complex dynamics that
agrees qualitatively with movie popularity behavior seen in real systems .
In comparison, the issue about how social recommendations aﬀect users’ posterior evaluation received less attention. empirically analyzed two web sites, Douban.com and
Goodreads.com, where millions of users rate books, music and movies, and share their
ratings and reviews with friends and followers. On these social network sites, the phenomenon that users recommend favorites to friends and followers plays an important role
in shaping users’ behaviors and collections. Fig. 14 compares the probability distribution
of ratings on items in Douban with and without recommendations (the result is very similar in Goodreads). This demonstrates that an individual is more likely to give a high
rating to an item with word-of-mouth recommendations, compared with items without
recommendations.
There are also indirect evidences about the positive social inﬂuences, for example, in
Twitter, statistically a tweet will spread to about 103 users if it gets retweeted , and in
Taobao11, the communication between buyers is a fundamental driving force for purchasing
activity .
Many ingredients could result in positive social inﬂuences in online recommendation.
Firstly, the word-of-mouth inﬂuences and role-model eﬀects from social mates are very
strong in oﬄine society, for example, an experiment in Nepal shows that on average
the probability of a woman to use a novel menstrual cup Take-Up will increase by 18.6% if
one more of her friends has used Take-Up. Secondly, the friendship network and interestbased network are strongly correlated with each other , and friends tend to visit the
same items and vote them with similar ratings .
11Taobao.com is a Chinese consumer marketplace that is the world’s largest e-commerce website.
User rating
Probability density
Ratings with recommendation
Ratings without recommendation
Figure 14: The probability distributions of ratings, posted with (solid line) or without (dashed line) a
word-of-mouth recommendation in Douban (taken from ).
7.2. Trust-Aware Recommender Algorithms
It is the basic paradigm of recommender systems that when computing recommendations for an individual user, evaluations of the others are not weighed equally and preference
is given to those who have similar rating patterns as the given user. This approach neglects
an important facet of the evaluation process: it is not only personal tastes but also social
relationships and the quality of evaluations that diﬀers from one user to another. To make
a better use of social relationships, various recommendation algorithms relying explicitly
on trust or user reputation have been developed and applied by many commercial web sites such as eBay.com . Trust can be used instead of user similarity ,
in combination with collaborative ﬁltering to help deal with data sparsity and the cold
start problem , or it can help to further ﬁlter recommendations by prioritizing those approved by trusted sources (see for a review). The use of reputation
in recommendation is further supported by the evidence that trust correlates with user
similarity , meaning that by introducing trust we are unlikely to conﬂict with users’
interests and preferences. As noted in , even an imperfect reputation system may be
beneﬁcial as (i) it provides an incentive for good behaviors, (ii) imposes costs on participants to get established, and (iii) swiftly reacts to bad behavior. The use of trust and
reputation has also its drawbacks, which includes: (i) time consuming computation, (ii) low
incentives for users to provide the required feedback, (iii) privacy concern for data of trust
relationship, and (iv) low availability of trust datasets for tests of algorithms. However,
without algorithms for trust and reputation, online transactions would be dramatically
aﬀected, if not halted.
The diﬀerence between reputation and trust is that while the former characterizes
general beliefs about a user’s trustworthiness, the latter concept is personal and relates
to a user’s willingness to rely on the actions of a given user. The terms local and global
trust metric are sometimes used instead of trust and reputation, respectively. To establish
trust or reputation, one may let the involved participants to rate each other and use these
evaluations to derive trust or reputation scores . When mutual user evaluations are
given, an initial seed of trusted users can be used to ﬁnd all the trustworthy users as
in the classical Advogato trust metric (see 
html). Other popular trust metrics, such as PageRank and Eigentrust , use the
spreading activation approach by which nodes are intially loaded and then propagate their
load within the network (diﬀusion-based recommendation methods are presented in
Section 6 also use this approach). When trust relations between the users are weighted
(with trust values 1 and 0 representing total trust and distrust, respectively), the plain
trust propagation can be shown to be insuﬃcient—the Appleseed algorithm solves this
problem by creating virtual trust edges for backward propagation .
It is a great disadvantage of reputation-aware recommender systems that they usually
require substantial input on the the user side to evaluate trust and reputation.
trust-aware reputation algorithms hence tried not to rely on explicit evaluations of other
users. In , they propose to detect noisy ratings by comparing the actual ratings with
the predicted ratings obtained by a recommendation algorithm, with data only from a
set of implicitly trusted users. This “reputation of ratings” can in turn be used to build
reputation of users . A diﬀerent approach was proposed by where the authors
use the information contained in social relationships between the users (which may stem
from users’ family or friendship relations), the transitivity of trust (as in ), and the
propagation of users’ queries in social networks. When computing recommendations for
a speciﬁc user i, the greatest weight is hence given to the users who can be connected
with user i in the social network by a short path with high trust values along its edges.
The proposed system is shown to assign correctly trust values and self-organizes to a
state producing highly accurate recommendations (when compared to a simple benchmark
strategy when one of the recommendations from peers is chosen at random).
7.3. Adaptive Social Recommendation Models
While the above described trust-aware systems make use of existing social relationships,
adaptive social recommendation models build a network of users based on their evaluations. In , the authors proposed a model where the recommended items spread over
the network similarly as an epidemics or rumor spreads in a society.
Simultaneously with this spreading, the network of users evolves and adapts to best capture users’ similarities. This epidemic-like spreading of a successful item is of particular
importance in the case when individual items swiftly loose their relevance —as it is
the case for news stories, for example—because it combines personalization with the speed
of access. It is very diﬀerent from the currently popular services such as digg.com and
reddit.com which still rely on centralized distribution of items where only those of very
Figure 15: Illustration of the news propagation in an adaptive network model . User i added a new
news, which is automatically considered as approved (A) and sent to users j1, j2, j3 who are i’s followers.
While user j2 dislikes (D) the news, users j1 and j3 approve it and pass it further to their followers k1, . . . , k5
who have not evaluated the news yet (which is denoted with question marks). User k4 receives the news
from the authorities j1 and j3, yielding the news’s recommendation score sj1k4 + sj3k4. At the same time,
user k5 receives the news only from the authority j3 and hence for this user, the recommendation score is
only sj3k5.
general interest can become popular and be accessed by many. For a recent review of
approaches to news recommendation see .
Here we describe brieﬂy the model introduced in . In this model, users either
“approve” or “disapprove” the consumed items. Each user i has S sources (i.e., S other
users from whom i receives news) and thus the system can be described by a directed
network with a constrained node in-degree S. When a news is approved by user i, it is
added to the recommendation lists to all i’s followers (i.e., all users who have i as one of
their sources). This spreading process is illustrated in Fig. 15. Similarity between users i
and j is deﬁned according to the agreement of their past evaluations,
where nA and nD denote the number of news for which evaluations of i and j agree and
disagee evaluations, respectively. The term 1/√nA + nD aims at penalizing user pairs with
little overlap of evaluated news as they may seem to be a great match for each other simply
because agreeing in evaluations of a few news. To summarize, items at the top of a user’s
recommendation list are probably recommended by multiple sources of this user or, at
least, by a source whose similarity with this user is high.
Apart from using user similarity in the recommendation process (the recommendation
score of item α for user i is given by the similarity between i and the sources of i who
approved this news), it is also crucial for updating the source-follower network.
updating aims at maximizing the similarity of each user with their sources. As shown in
 by agent-based simulations, the system can evolve from a random initial state to a
highly organized state where taste mates are connected and news spread eﬀectively. The
original network can be improved by rewiring, through ineﬀective random replacements
or computationally demanding global optimization. One can also combine simple greedy
optimization with random assignment , repeated trials or exploration of the
directed user network both in the direction of followers and sources . Robustness of
this recommendation approach can be enhanced by introducing the user reputation .
This adaptive evolution of the network of user-user interactions can be used to explain
the widely observed scale-free leadership structure in social recommender systems ,
and recent analysis suggested that users could get better information by selecting proper
leaders in social sharing websites .
8. Meta approaches
Input data for recommendation can be extended far behind the traditional user-itemrating scheme.
In this section, we brieﬂy review the so-called meta approaches where
additional information of various kind (tags assigned to items by users or time stamps of
past evaluations) enters the recommendation process or simply several recommendation
methods are combined together (either in an iterative self-evaluating way or by forming a
hybrid algorithm). As possibilities for extensions are relatively easy to ﬁnd, this direction
has seen high activity over the past years.
8.1. Tag-aware methods
In the past decade, the advent of Web 2.0 and its aﬃliated applications brought us
a new paradigm to facilitate the user-generated creation on the Internet. One such example are user-driven platforms that allow users to store resources (bookmarks, images,
documents, and others) and to associate them with personalized words, so-called tags.
The resulting ternary user-object-tags structure, so-called folksonomy, represents a rich
data structure that is of interest for computer scientists, sociologists, linguists, and also
physicists . When viewed from the perspective of an individual user, these tags constitute a personalized folksonomy where tags, although only simple words, contain
highly abstracted yet personalized information. Diﬀerent from other kinds of metadata
(such as proﬁle, attributes, and content), tags are not predeﬁned by domain experts or
administrators. This approach has the advantage of being scalable and requiring no speciﬁc skills, hence allowing every individual to participate and contribute. Despite the lack
of imposed organization, shared vocabularies were shown to emerge in folksonomies ,
making them increasingly accessibile to advanced information ﬁltering techniques. Tags
therefore represent a simple yet promising tool to provide reasonable recommendations and
solve some outstanding problems in recommender systems, e.g.the cold-start problem .
The social impact and dynamical properties of folksonomies are expected
to be applied to obtain trustworthy and real-time recommendations in tagging systems.
In addition, the hypergraph theory is considered to fully utilize the complete network
structure of tagging platforms without using any hybrid methods and losing any information, which gives promises for generally more reliable recommendations. At the same
time, there are also drawbacks caused by the freedom of tags: e.g.polysemy, synonymy, and
ambiguity . To alleviate these problems, advanced methods such as tag hierarchical
clustering , introduction of ontologies and recommendation of tags were
Unlike being used as a traditional ﬁlter, researches tend to apply more sophisticated
theories and methods (e.g., social impact) in designing tag-aware recommendation algorithms. The FolkRank , a modiﬁed PageRank algorithm, was proposed to rank tags
in folksonomies by assuming that important tags are given by important users. Due to
the success of collaborative ﬁltering, many works were devoted to using tags to measure
similarity among users or objects, and then fuse with the standard memory-based collaborative ﬁltering framework . In , the present tag-aware algorithms are
Figure 16: (Color online) Illustration of a user-item-tag tripartite graph consists of three users, ﬁve items
and four tags, as well as the recommendation process described in . The tripartite graph is decomposed
to user-item (black links) and item-tag (red links) bipartite graphs connected by items. This is how the
scoring process works for a given target user U1. (a) Firstly, highlight the items, I1, I3, I5, collected by
the target user U1 and mark them with unit resource. In the depicted case we have: fI1 = fI3 = fI5 = 1,
and fI2 = fI4 = 0. (b) Secondly, distribute the resources from items to their corresponding users and tags,
respectively: fU3 = fI1 × 1
2 +fI2 × 1
2 +fI5 × 1
2 = 1 and fT4 = fI1 × 1
3 +fI3 × 1
2 +fI4 × 1
6; (c) Finally, redistribute the resources from users and tags to their neighboring items:
I4 = fU2 × 1
3 + fU3 × 1
12 and f pt
I4 = fT3 × 1
3 + fT4 × 1
classiﬁed as follows:
1. Topic-based models. They implement probability-based methods such as pLSA and
LDA (see Sections 5.3 and 5.4) to extract latent topics from the available tags in the
user or object space and then produce recommendations using classical probabilitybased models .
2. Network-based models. They implement graph theory-based methods such as ProbS
(see Sec. 6.3) to represent tags as nodes in a tripartite user-object-tag network and
apply a diﬀusion process to generate recommendations (see Fig. 16).
3. Tensor-based models. They implement tensor factorization to reduce the ternary
relation into low-rank feature matrices, alleviate the sparsity problem in large-scale
datasets and ultimately provide personalized recommendations .
8.2. Time-aware methods
Nowadays, huge quantities of information emerge every second. We receive news from
various media, such as newspapers, TV programs, websites, etc. Due to its timeliness and
in particular its convenience, more and more people prefer to read news online (e.g., using
RSS feeds) instead of from traditional media like newspapers. However, given the enormous
amount of online news, one challenging issue is the novelty of news recommendation, i.e.,
how to appropriately and eﬃciently recommend news to readers, matching their reading
preferences as much as possible. The analysis of data from a popular platform for sharing
news stories, Digg.com, by Wu and Huberman shows that the novelty of news half
there decays in a very short period. Another typical instance is the communication system
to predict
Figure 17: (Color online) Illustration of time based recommendation where the target user has collected
three items, I1, I2 and I3, which are then used to predict the newest item I4. f is the decay function to
weight the time diﬀerence between I4 and other items that were collected before.
of e-commerce websites, which require real-time feedback among various agents . Such
information updates so frequently that it is impossible for individuals to evaluate each, or
even read them in time. Consequently, an urgent question emerges: how to automatically
ﬁlter out the irrelevant information, receive timely news and perform immediate yet appropriate response? One promising solution lies in time-aware recommender systems, which
can hopefully help to address aforementioned issues. Collaborative ﬁltering (see Sec. 4), as
the most widely adopted method in recommender systems, is the ﬁrst one to be considered.
Following the classical collaborative ﬁltering framework, most of the related work focuses
on designing time factors to suppress old evaluations or objects. Generally, such kind of
weight is expressed by various decay functions (see Fig. 17), which suggests that user
interests in a single topic would decay with time (see Fig. 18). Ding and Li weighed
diﬀerent items by putting smaller weights on older ones. Similar methods used the time
factor to adaptively choose temporal neighborhoods and then obtain recommendations via
the reﬁned neighbors . Another kind of attempts consider decaying time
to weigh user-item binary edges in bipartite networks. Liu and Deng hypothesized
the time eﬀect decayed in a exponential manner, which could also been found in other
empirical studies and models . A broad picture of collaborative ﬁltering with
time can be found in a recent Ph.D. thesis .
Another important issue in recommender systems is that of novelty.
Although an
item with the highest recommendation score is the most possible candidate for a target
user, it may fail to be picked due to the diversity of human tastes. In such cases, these
items should not always occupy the recommendation list and be recommended over and
over again. Therefore, temporal diversity becomes crucial in designing time-based
algorithms. Xiang et al. divided user interests into two general categories: longer-term
and short-term . Longer-term interests govern the essential preferences of users and
would not easily change over time. By contrast, short-term interests are more likely to be
eﬀected by social environment (Fig. 18 shows such diﬀerence). By identifying and making
use of the diﬀerences between them using a time factor, in they successfully provided
o v i e l e n s
Figure 18: (Color online) Illustration of users’ interests changing with time in the MovieLens data. Shifts
of user interests are represented by the average similarity among item pairs of the target user within an
observed time t (shown with gray circles). The dashed line represents the average similarity of all users.
more reliable yet interesting recommendations, which can also be found in relative works
Besides recommendation, time also plays an important role in various ﬁelds, such as
network growth , identiﬁcation of original scientiﬁc contributions , selecting the backbone structure of citation networks , and aging eﬀects in synchronization . However, how to appropriately use the time information to discover the
underlying dynamics of user preferences and help us master the current information era
still remains an important research challenge.
8.3. Iterative reﬁnement
Iteratively solved self-consistent equations are widely applied in characterizing structural and functional features of nodes and/or edges in networked systems. Their solution
is usually used to describe a stable distribution of a certain quantity in a system consisting
of many interacting individuals, where the amount of this quantity assigned to individual i
is aﬀected by both the interacting rules and the amounts of this quantity assigned to other
individuals interacting with i. In a directed network, the signiﬁcance of a node is not only
determined by its attributes (if applicable), but also contributed by the signiﬁcance of its
downstream nodes. For example, the classical set of self-consistent equations for PageRank
value G(i) of the web page i has the form 
G(i) = c + (1 −c)
where j runs over all the web pages that point to i, c is the return probability accounting
for the random browsing, and kout
is j’s out-degree.
This set of equations represents
a particular Markovian process on a network and can be successfully solved using an
iterative approach thanks to the fast convergence to a stationary solution observed in
most cases . Besides web pages, similar self-consistent equations are also successfully
applied in ranking people , genes , and so on. If instead of referring to nodes, the
individuals refer to pairs of nodes, this approach can be used to quantify node similarity
 . In more complicated situations, the individuals can be users and items, or
scientists and publications, and similar iterative equations embodied in bipartite networks
can be applied in building quantitative reputation systems, namely simultaneously estimate
people’s reputation and objects’ quality .
Besides the above-mentioned iterative equations, a closely related framework is that of
the so-called self-consistent reﬁnement . In the link prediction and personalized
recommendation, the known information is the adjacency matrix representing a unipartite
or a bipartite network and the task is to estimate the likelihoods of link existence for
currently zero elements of the adjacency matrix. For recommender systems with ratings,
the algorithms need to predict unknown ratings according to the rating matrix. Denoting
R the known matrix and ˜R the predicted matrix (i.e., output), the procedure of many
algorithms can be written in a generic form
˜R = D(R),
where D is a matrix operator.12 Denoting the initial conﬁguration as R(0) and the initial
time step k = 0, a generic framework of self-consistent reﬁnement reads : (i) Implement
the operation D(R(k)); (ii) Set the elements of R(k+1) as
Then, set k = k + 1. (iii) Repeat (i) and (ii) until the diﬀerence between R(k) and R(k−1)
is smaller than a given terminating threshold.
Considering the matrix series R(0), R(1), · · · , R(T) (T denotes the last time step) as a
certain dynamics driven by the operator D, all the elements corresponding to the known
items (i.e., R(0)
iα ̸= 0) can be treated as the boundary conditions expressing to the known
and ﬁxed information.13 If ˜R is an ideal prediction, it should satisfy the self-consistent
12See on how to use this generic form to represent the well-known similarity-based and spectrumbased algorithms for rating prediction.
13This is the essential diﬀerence between the self-consistent reﬁnement and the above-mentioned iterative
equations like PageRank, since in the latter case, every matrix element is free to be changed.
Figure 19: Prediction error (MAE) versus iterative step for MovieLens data. We use the MovieLens data
that consists of N = 3020 users, M = 1809 movies, and 2.24 × 105 discrete ratings from 1 to 5. All the
ratings are sorted according to their time stamps with 90% earlier ratings as the training set, and the
remaining ratings (with later time stamps) as the testing set.
condition ˜R = D(˜R). However, this equation is not hold for most known algorithms. In
contrast, the convergent matrix R(T) is self-consistent.
As shown in , applying the self-consistent framework can lead to great improvements compared with non-iterative methods employing Eq. (101). We next show a simple
example for similarity-based recommendation. Taking into account the diﬀerent evaluation scales of diﬀerent users , we subtract the corresponding user average from each
evaluated entry in the rating matrix R and get a new matrix R′. The predicted rating is
calculated by using a weighted average, as:
β Ωαβ · R′
where the similarity between items α and β is deﬁned by Eq. (34). As shown in Fig. 19,
experiment on MovieLens veriﬁes the advantages of the iterative reﬁnement, where the
original similarity-based algorithm corresponds to the ﬁrst iteration step.
8.4. Hybrid algorithms
Even for a good recommender algorithms it is diﬃcult to address diverse needs of its
heterogenous users. Hybrid methods overcome this problem by aptly combining recommendations obtained by diﬀerent methods . Hybridization is hence often used
in practical implementations of recommender systems, even in very early ones . One
of the most important applications of hybrid recommendation algorithms is to solve the
cold-start problem, by combining collaborative and content data in such a way that even
a new object that has never been rated before can be recommended (similarly, a new
user who has never rated anything can receive some recommendations). Since hybrid algorithms combine diﬀerent approaches to recommendation, they also have the potential to
improve the diversity of recommendations . The following classiﬁcation of hybridization
methods is taken from :
1. implement collaborative and content-based methods separately and combine their
predictions,
2. incorporate some content-based characteristics into a collaborative approach,
3. incorporate some collaborative characteristics into a content-based approach, and
4. construct a general unifying model that incorporates both content-based and collaborative characteristics.
Now we can extend class 4 to include also unifying models that incorporate two or more
collaborative methods (see Sec. 6.4).
Hybrid methods range from simple, such as using a linear combination of ratings obtained by diﬀerent methods , to very complex, such as employing Markov chain Monte
Carlo methods to model combined collaborative and content data. Recent Netﬂix
prize (see Sec. 2.1) has provoked interest in sophisticated methods for combined predictions (also called ensemble learning or blending) which were shown to be very successful
in lowering the error of predictions . The main idea of blending is that the prediction
vectors of F distinct recommendation methods, denoted as x1, . . . , xF, are combined by a
function Ω: RF →R so that the prediction error on a test set (evaluated by RMSE, for
example) is minimized. The optimal weighting function Ωis obtained by linear regression,
neural networks, or bagging predictors . For details and evaluation of diﬀerent
blending schemes on the extensive dataset provided by Netﬂix for the competition see .
Some challenges can also be partially solved by hybridization, for example, the link prediction algorithm can be used to generate artiﬁcal links that could eventually improve the
recommendation in very sparse data .
Table 5: Data sets used for evaluation of recommendation methods. Data density is deﬁned as the ratio
of the available ratings to the maximum possible number of ratings; kU and kO denote the average user
and object degree, respectively.
9. Performance evaluation
In this section we brieﬂy compare performance of individual algorithms presented in
this review. To test the algorithms, we use two standard data sets: Movielens 1M14 and
Netﬂix15. The Movielens data set, which contains ratings from 6,040 users to 3706 movies
(corresponding to the rating density of 4.5 · 10−2), is used in its original form. Our subset
of the original Netﬂix data set was created by randomly selecting 8,000 users from the
original data set released by Netﬂix for the Netﬂix Prize and keeping all their evaluations
(see 2.1 for details on the competition). In this way, a data set with 17,148 objects (DVDs
rented by the company to its users) and 1,632,172 ratings in the integer scale from one
to ﬁve (corresponding to the rating density of 1.2 · 10−2) was created. Both data sets use
the integer rating scale from one to ﬁve. For methods requiring no explicit ratings (binary
data), we assume that all ratings greater or equal than three represent objects liked by
the users and hence constitute a corresponding user-object link (if the rating is less than
three, no link is formed). As a result, there are 1,387,039 and 836,478 links in the Netﬂix
and Movielens data set, respectively. Table 5 summarizes basic properties of the data sets.
Our two data sets diﬀer not only by their density and user/object ratio—histograms
of user and object degrees in Fig. 20 reveal further diﬀerences. Firstly, Movielens data
were originally prepared in such a way that all users rated at least twenty movies. This
constraint has not been applied to the Netﬂix data set, resulting in a considerable number
of users with only little data on their past preferences available. Secondly, Netﬂix data also
contains a large portion of movies that have been rated only a few times (this probably
reﬂects the fact that the company rents a wide variety of DVDs, many of which are of
interest for only a small part of the customers). Unsurprisingly, all degree distributions
are broad and right-skewed, as similar to many other social systems .
To test a recommendation method, we employ the standard approach. First, a randomly
selected small part of the input data is moved into a so-called probe. In our case, the probe
contains 10% of ratings present in the input data set. The remaining 90% of the data is then
given to the recommendation method and are used to estimate the missing ratings. The
estimated missing ratings are then compared with the true ratings present in the probe set.
This comparison is done by means of root mean square error (RMSE) and mean absolute
14This data set can be obtained at 
15This data set can be obtained at www.netflixprize.com.
user degree
number of users
object degree
number of objects
Figure 20: User and object degree distribution for the two data sets used to evaluate recommendation
overall average
object average
user average
multilevel spreading
user similarity
object similarity
slope one weighted
Table 6: Performance of algorithms for data with explicit ratings (averaged over 10 realizations).
error (MAE) in the case of data with explicit ratings and by means of precision, recall and
the average relative rank in the case of data without explicit ratings (see Section 3.4 for a
detailed description of these performance metrics). For precision and recall, we take into
account top 100 places of each user’s recommendation list. To eliminate possible eﬀects of
the probe selection, we repeat the procedure for ten independent randomly selected probe
sets and present the averaged results.
Method overall average is used only as a benchmark; it uses the average rating in
the input data as estimate for every user-object pair. For similarity-based methods, we
employ the Pearson correlation coeﬃcient which slightly outperforms cosine similarity in
terms of RMSE and MAE. For SVD, we used parameter values D = 20, η = 0.001 and
λ = 0.1 that result in favorable performance (see Section sec:SVD for the meaning of these
parameters). Note that a better founded approach would be to learn “optimal” values of
these parameters from the data itself. This can be achieved by choosing {D, η, λ} based
global rank
Bayesian clustering
ProbS+HeatS, λ = 0.2
Table 7: Performance of algorithms for data without explicit ratings (averaged over 10 realizations).
on RMSE or MAE computed for a small test set of predictions (which could again be
created by taking 10% of the input data) and only then reporting the resulting method’s
performance computed for the probe. However, with only three free parameters to tune,
the results are likely to diﬀer little from the results obtained by our naive approach where
{D, η, λ} are chosen directly from performance observed for the probe.
While numerical performance values may seem very close to each other across all the
methods (perhaps with the exception of overall average), diﬀerences between the methods
from the user’s point of view are much greater than one would expect from RMSE varying
at the second decimal place. For example, user average outperforms object average for the
Netﬂix data set, yet in fact it has zero ﬁltering ability. For a given user, estimated rating
of all unrated objects is the same (equal to this user’s average rating), this user is thus
provided no useful information as to which object to select in the future. Further, the
performance of object average may seem appealing with respect to the method’s simplicity,
yet one can easily check that objects with the highest estimated score are likely those that
received only a few ratings. This is because while a rarely viewed object may easily receive
the highest possible average rating of ﬁve, a popular object inevitable receives some worse
marks which result in a lower average rating. For example, top-rated movies in both tested
data sets have all received less than ﬁve ratings and scored 5.0 on average. This analysis
shows that RMSE and MAE, while useful and easy to understand, give only a very limited
information about a method’s performance.
Table 7 summarizes performance of methods requiring data without explicit ratings
(binary data). As performance metrics we use precision P, recall R and the relative rank
(marked as rank in the table) of probe objects (if probe object α belonging to user i appears
on place x of this user’s recommendation list and this user has collected ki objects, the
relative rank of α is x/(M −ki)). Method global rank corresponds to recommendation
of the most popular items that have not yet been collected by a given user. The results
of pLSA and LDA are obtained from K = 50, while a slight increase in performance
is observed when K increases further. Results of Bayesian clustering are obtained with
(Kuser, Kitem) = (70, 35) for Movielens and (Kuser, Kitem) = (70, 140) for Netﬂix, where
Kuser/Kitems is in a rough proportion to the corresponding ratio of users to items. Note
that global rank and Bayesian clustering are able to yield low relative rank but they fail to
score in precision and recall.
10. Outlook
After reviewing extensively the past work in the ﬁeld of recommender systems, we
describe here a few challenges that the ﬁeld of recommendation needs to tackle in the
To begin with, let us take the conceptual question of the possibility of eﬀective recommendation. For a long time, we all thought that we know ourselves better than anyone
else does. Without much fanfare and fuss about philosophical implications, IT experts and
online businesses continue in their exploration of the part of our knowledge that resides
not on in our minds, but at crossroads of communities. This in eﬀect has violated both
our self-knowledge belief and an implicit, long cherished notion: individuals are masters of
themselves. Conceptually, this admitting is nothing short of a revolution. The potential
of the new approach is huge: the “extra-body” knowledge about our preferences manifests
itself in communication data and is thus much easier to analyze and decipher than the part
hiding among our neurons and synapses. What Amazon or Netﬂix does is just scratching
on the surface of the huge potential, as they only take into account a tiny fraction of
information about us. Google’s Gmail gains more insight about what its users do in the
hope that emails reveal more than what can be obtained from data about searching, bookbuying, and movie-rating, thereby matching ads more closely to our preferences and hence
increasing their eﬃciency. Some recent online communities go even a step further than
Gmail. For example, Facebook.com lets its members to create trusted relationships and
keeps track of members’ activities and conversations, obtaining the opportunity to infer
intimate details about users’ preferences. Though most of this information is implicit and
not yet ready for recommendation, the huge data basis in principle can yield much more
insight than hitherto seen. By letting the users to reveal more and more, the potential
for inferring their future wants grows and we are still to know what the consequences will
be. The induced danger of privacy violation calls for new, privacy preserving recommender
systems where no sensitive data leave users’ computers, yet users can enjoy the beneﬁt of
collaborative ﬁltering.
IMDB (Internet Movie Database) and similar web sites aggregate millions of votes for
a wide range of movies, and online sellers of movies use some degree of collaborative ﬁltering to make recommendations given one’s past purchasing history. However, an open
reputation-sharing mechanism remains to become widespread. One can project forward
to imagine innovative applications, such as “Movies Wanted”: a system where plot descriptions are collaboratively developed and voted on, to highlight movies desired by a
constituency. The net eﬀect of reputation ﬁltering will be to bring more old, foreign, and
niche movies to light, with similar eﬀects for music and other culture. Cultural opportunities that languish for want of attention due to high search costs will reach audiences
that did not know what they were missing. Many recommender systems provide suggestions based on expressed or observed preferences. But reputations could also encode other
properties of media, such as “ethicalness” of lyrics (and indeed of the performers’ lives and
aims if one desires), or speciﬁc legal or reproduction rights. Licensing schemes like Creative
Commons certify an artistic work as having particular legal properties; it is then feasible
to provide both recommendations and direct access just within the set of freely available
Beyond music and movies, numerous cultural areas and experience goods are ripe for
recommendation services provided by reputations. Book ratings and suggestions provide
a navigation tool through humanity’s ever-growing literary output—most notably from
Amazon, but also from a variety of small-scale services and personal lists. Travel guidebooks aid in getting the insider view of an unfamiliar locale, but interpreted experiences
of natives and previous travelers could be even better. Whether for festivals, museums,
opera, or the thousands of other shared activities which enrich our social landscape, the
cultural sector is fertile ground for development.
In the age of Internet and World Wide Web, ICT tools allows information to spread
faster and wider than ever before, and dominates the way we form our opinions and knowledge. While there has been an undeniable progress in the information availability, a fundamental question remains elusive: do we get more diverse information than in the past?
Although the ICT Revolution was expected to allow people to access ever more diversiﬁed
information sources and products, one often sees that this is not the case. Popular viral
videos copy the strategy of blockbuster ﬁlms and target the tastes of the general audience,
giving rise to global hits. On the Internet, a few sites attire a huge part of web traﬃc. A
similar process is in action in science where disproportional attention is given to a small
fraction of all new and exciting works . The problem is that search engines and recommender systems fall prey to a self-reinforcing rich-get-richer phenomenon: items that
were popular in the past tend to be served to even more users in the future. The natural outcomes of such defective dynamics are the narrowing of people tastes and opinions
together with a general cultural ﬂattening. To address this issue, we need to consider the
long-term impacts of information ﬁltering systems on the information ecology and study
information ﬁltering tools that favor diversity without sacriﬁcing their overall performance
Another interesting facet of the mentioned diversity challenge is related to a concept
of “crowd-avoidance”. There are situations where the generated data naturally ﬁts the
paradigm of recommender systems, yet using a standard recommender system may result
in poor outcomes. For example, when given data of user preferences for restaurants, it
is natural to recommend a user a new place to eat.
However, if too many users are
recommended the same place, it gets crowded and nobody enjoys their meal. Similarly,
when given data of industrial sectors active in various countries (which can be eﬀectively
represented by a bipartite network , so much discussed and utilized in this review), one
may recommend a country a new sector on the basis of its similarity with already active
sectors. However, if the country faces a strong competition from its neighbors, it may do
better by choosing a less similar sector where the competition is weaker. The same happens
on a smaller scale where companies routinely compete with products of other companies,
yet avoiding a direct clash may be very beneﬁcial. The concept of crowd avoidance in
recommender systems could yield beneﬁts in situations similar to those described above,
where resources cannot be shared by an arbitrary number of parties due to constraints of
geographic space or limited interest of customers.
The crowd avoidance phenomenon ranges from practically non-existing (in the case of
e-book distribution, for example) to very strong (no two customers can share an item)
where it approaches the classical assignment problem . The most challenging seems
to be the moderate case where recommending an item to a small number of consumers
does not create a problem yet (which ﬁts well the above-described product and restaurant
recommendation, for example). Note that this whole problem is in principle similar to
quantum physics systems where occupation numbers are conﬁned by constraints (such as
the Pauli exclusion principle which says that two identical fermions cannot simultaneously
occupy the same quantum state) or where mutual repulsion among particles sharing the
same site exists. Analogies with physics can thus prove useful in studying this kind of
The science of recommendation is just starting—despite impressive progresses, much
remains to be understood. For further advances intuition alone is no longer enough and
a multidisciplinary approach will surely bring powerful tools that may help innovative
matchmakers to turn the immense potential of recommendations into real life applications.
Acknowledgments
This work was partially supported by the EU FET-Open Grant 231200 (project QLectives) and National Natural Science Foundation of China (Grant Nos. 11075031, 11105024,
61103109 and 60973069). CHY is partially supported by EU FET FP7 project STAMINA
(FP7-265496). TZ is supported by the Research Funds for the Central Universities (UESTC).