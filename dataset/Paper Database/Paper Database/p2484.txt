Published online 17 February 2003
Computational approaches to motor learning
by imitation
Stefan Schaal1,2*, Auke Ijspeert1,3 and Aude Billard1,4
1Computer Science & Neuroscience, University of Southern California, 3641 Watt Way, Los Angeles, CA 90089-2520, USA
2ATR Human Information Sciences, 2-2 Hikaridai, Seika-cho, Soraku-gun, Kyoto 619-0218, Japan
3School of Computer and Communication Sciences, and 4School of Engineering, Swiss Federal Institute of Technology,
Lausanne, CH 1015 Lausanne, Switzerland
Movement imitation requires a complex set of mechanisms that map an observed movement of a teacher
onto one’s own movement apparatus. Relevant problems include movement recognition, pose estimation,
pose tracking, body correspondence, coordinate transformation from external to egocentric space, matching of observed against previously learned movement, resolution of redundant degrees-of-freedom that
are unconstrained by the observation, suitable movement representations for imitation, modularization of
motor control, etc. All of these topics by themselves are active research problems in computational and
neurobiological sciences, such that their combination into a complete imitation system remains a daunting
undertaking—indeed, one could argue that we need to understand the complete perception–action loop.
As a strategy to untangle the complexity of imitation, this paper will examine imitation purely from a
computational point of view, i.e. we will review statistical and mathematical approaches that have been
suggested for tackling parts of the imitation problem, and discuss their merits, disadvantages and underlying principles. Given the focus on action recognition of other contributions in this special issue, this paper
will primarily emphasize the motor side of imitation, assuming that a perceptual system has already identified important features of a demonstrated movement and created their corresponding spatial information.
Based on the formalization of motor control in terms of control policies and their associated performance
criteria, useful taxonomies of imitation learning can be generated that clarify different approaches and
future research directions.
Keywords: imitation; motor control; duality of movement generation and movement recognition;
motor primitives
1. INTRODUCTION
Movement imitation is familiar to everybody from daily
experience: a teacher demonstrates1 a movement, and
immediately the student is capable of approximately
repeating it. In addition to a variety of social, cultural and
cognitive implications that the ability to imitate entails , from the viewpoint
of learning, a teacher’s demonstration as the starting point
of one’s own learning can significantly speed up the learning process, as imitation usually drastically reduces the
amount of trial-and-error that is needed to accomplish the
movement goal by providing a good example of a successful movement . Thus, from a computational
point of view, it is important to understand the detailed
principles, algorithms and metrics that subserve imitation,
starting from the visual perception of the teacher up to
issuing motor commands that move the limbs of the student.
* Author for correspondence ( ).
One contribution of 15 to a Theme Issue ‘Decoding, imitating and
influencing the actions of others: the mechanisms of social interaction’.
Phil. Trans. R. Soc. Lond. B 358, 537–547
2003 The Royal Society
DOI 10.1098/rstb.2002.1258
Figure 1 sketches the major ingredients of a conceptual
imitation learning system . Visual sensory
information needs to be parsed into information about
objects and their spatial location in an internal or external
coordinate system; the depicted organization is largely
inspired by the dorsal (what) and ventral (where) stream
as discovered in neuroscientific research . As a result, some form of postural information of the movement of the teacher and/or 3D object
information about the manipulated object (if an object is
involved) should become available. Subsequently, one of
the major questions revolves around how such information can be converted into action. For this purpose,
figure 1 alludes to the concept of movement primitives,
also called ‘movement schemas’, ‘basis behaviours’,
‘units of action’, ‘macro actions’, etc. , such
low-level representations do not scale well to learning in
systems with many degrees of freedom. Thus, it is useful
for a movement primitive to code complete temporal
behaviours, like ‘grasping a cup’, ‘walking’, ‘a tennis ser-
S. Schaal and others
Computational approaches to motor learning by imitation
motor command
generation
primitive 1
primitive 2
primitive 3
primitive 4
primitive n–2
primitive n–1
primitive n
perceptual
3D information
of manipulated
posture and
movement of
information
recognition
performance
evaluation
recurrent connections
(efference copy)
Figure 1. Conceptual sketch of an imitation learning system. The right-hand side contains primarily perceptual elements and
indicates how visual information is transformed into spatial and object information. The left-hand side focuses on motor
elements, illustrating how a set of movement primitives competes for a demonstrated behaviour. Motor commands are
generated from input of the most appropriate primitive. Learning can adjust both movement primitives and the motorcommand generator.
ve’, etc. Figure 1 assumes that the perceived action of
the teacher is mapped onto a set of existing primitives in
an assimilation phase, also suggested in Demiris & Hayes
 and Wolpert et al. . This mapping process
also needs to resolve the correspondence problem concerning a mismatch between the teacher’s body and the
student’s body . Subsequently, the most appropriate primitive is adjusted by
learning to improve the performance in an accommodation phase. Figure 1 indicates such a process by highlighting the better-matching primitives with increasing
linewidths. If no existing primitive is a good match for
the observed behaviour, a new primitive must be generated. After an initial imitation phase, self-improvement,
e.g. with the help of a reinforcement-based performance
evaluation criterion , can refine
both movement primitives and an assumed stage of
motor-command generation (see § 2b) until a desired
level of motor performance is achieved.
In §§ 2 and 3, we will attempt to formalize the conceptual picture of figure 1 in the context of previous work on
computational
approaches
imitation.
Rittscher & Blake already concentrate on the perceptual part of imitation in this issue, our review will focus
on the motor side in figure 1.
Phil. Trans. R. Soc. Lond. B 
2. COMPUTATIONAL IMITATION LEARNING
Initially, at the beginning of the 1980s, computational
imitation learning found the strongest research interest in
the field of manipulator robotics, as it seemed to be a
promising route to automate the tedious manual programming of these machines. Inspired by the ideas of artificial
intelligence, symbolic reasoning was the common choice
to approach imitation, mostly by parsing a demonstrated
movement into some form of ‘if–then’ rules that, when
chained together, created a finite state machine controller
Lozano-Pe´rez
Levas & Selfridge 1984; Segre & DeJong 1985; Segre
1988). Given the reduced computational power available
at this time, a demonstration normally consisted of manually ‘pushing’ the robot through a movement sequence
and using the proprioceptive information that the robot
sensed during this guided movement as basis to extract
the if–then rules. In essence, many recent robotics
approaches to imitation learning have remained closely
related to this strategy. New elements include the use of
visual input from the teacher and movement segmentation
derived from computer vision algorithms . Other projects used data
gloves or marker-based observation systems as input for
imitation learning .
Computational approaches to motor learning by imitation
S. Schaal and others
More recently, research on imitation learning has been
influenced increasingly by non-symbolic learning tools, for
instance artificial neural networks, fuzzy logic, statistical
learning, etc. . An even more recent trend takes
inspiration of the known behavioural and neuroscientific
processes of animal imitation to develop algorithms for
robot programming by demonstration with the goal
of developing a more general and less task-specific theory
of imitation learning. It is these neural computation techniques that we will focus on in this review, as they offer
the most to both biologically inspired modelling of imitation and technological realizations of imitation in artificial intelligence systems.
(a) A computational formalization of imitation
Successful motor control requires issuing motor commands for all the actuators of a movement system at the
right time and of correct magnitude in response to internal
and external sensations and a given behavioural goal.
Thus, the problem of motor control can generally be formalized as finding a task-specific control policy 
u(t) = (z(t),t,),
where u denotes the vector of motor commands, z the
vector of all relevant internal states of the movement system and external states of the environment, t represents
the time parameter, and  stands for the vector of open
parameters that need to be adjusted during learning, e.g.
the weights of a neural network . We will denote a policy that explicitly uses a
dependence on time as a nonautonomous policy, whereas a
dependence,
u(t) = (z(t),), will be called autonomous. The formulation in equation (2.1) is very general and can be applied
to any level of analysis, like a detailed neuronal level or a
more abstract joint angular level. If the function  were
known, the task goal could be achieved from every state
z of the movement system. This theoretical view allows us
to reformulate imitation learning in terms of the more formal question of how control policies, which we also call
movement primitives, can be learned (or bootstrapped) by
watching a demonstration.
Crucial to the issue of imitation is a second formal
element, an evaluation criterion that creates a metric of
the level of success of imitation
J = g(z(t),u(t),t).
Without any loss of generality, we will assume that the
cost J should be minimized; particular instantiations of J
will be discussed in the following paragraphs. In general,
J can be any kind of cost function, defined as an accumulative cost over a longer time horizon as is needed for minimizing energy, or only over one instant of time, e.g. as
needed when trying to reach a particular goal state. Moreover, J can be defined on variables based in any coordinate
system, e.g. external, internal or a mixed set of coordinates. The different ways of creating control policies and
metrics will prove to be a useful taxonomy of previous
approaches to imitation learning and the problem of imitation in general.
Phil. Trans. R. Soc. Lond. B 
Defining the cost J for an imitation task is a complex
problem. In an ideal scenario, J should capture the task
goal and the quality of imitation in achieving the task goal.
For instance, the task goal could be to reach for a cup,
which could be formalized as a cost that penalizes the
squared distance between the hand and the cup. The teacher’s demonstration, however, may have chosen a particular form of reaching for the cup, e.g. in a strangely
curved hand trajectory. Thus, faithful imitation may
require adding an additional term to the cost J that penalizes deviations from the trajectory the teacher demonstrated, depending on whether the objective of imitation
is solely focused on the task or also on how to move to
perform the task. Hence, the cost J quickly becomes a
complex, hybrid criterion defined over various objectives.
In biological research, it is often difficult to discover what
 Imitation by direct policy learning
The demonstrated behaviour can be used to learn the
appropriate control policy directly by supervised learning
of the parameters  of the policy (cf. equation (2.1)), i.e.
a nonlinear map z →u, employing an autonomous policy
and using as evaluation criterion (cf. equation (2.2)) simply the squared error of reproducing u in a given state z.
For this purpose, the state z and the action u of the
teacher need to be observable and identifiable, and they
must be meaningful for the student, i.e. match the student’s kinematic and dynamic structure . This prerequisite of observability, shared
by all forms of imitation learning, imposes a serious constraint since, normally, motor commands, i.e. kinetic variables, and internal variables of the teacher are hidden from
the observer. Although statistical learning has methods to
uncover hidden states, e.g. by Hidden Markov Models,
Kalman filters or more advanced methods , we are not aware that such techniques have
been applied to imitation yet.
Thus, to instantiate a movement primitive from a demonstration, the primitive needs to be defined in variables
that can be perceived, leaving only kinematic variables as
potential candidates, e.g. positions, velocities and accelerations. Given that the output of a movement primitive has
to be interpreted as some form of a command to the motor
system, usually implying a desired change of state, movement primitives that output a desired velocity or acceleration can be useful, i.e. a ‘desired time-derivative’ of the
state information2 that is used to represent the teacher’s
movement. Our generic formulation of a policy in equation (2.1) can, therefore, be written more suitably as
z˙(t) = (z(t),t,).
From a control theoretical point of view, this line of
reasoning requires that motor control be modular, i.e. has
at least separate processes for movement planning (i.e.
generating the right kinematics) and execution (i.e. generating the right dynamics) .
Figure 2 illustrates two classical examples of modular control in the context of imitation learning and motor primitives. In figure 2a, the demonstrated
S. Schaal and others
Computational approaches to motor learning by imitation
feed-forward
controller
controller
coordinate
transformation
controller
feed-forward
controller
demonstrated
demonstrated
Figure 2. Modular motor control with movement primitives, using (a) a movement primitive defined in internal coordinates,
and (b) a movement primitive defined in external coordinates.
behaviour is mapped onto a movement primitive that is
defined in internal coordinates of the student: joint angular coordinates  are a good candidate as they can be
extracted from visual information, a problem addressed
under the name of pose estimation in computer vision
 . Such
internal coordinates can directly serve as desired input to
a motor-command execution stage (cf. figure 1), here
assumed to be composed of a feedback and a feed-forward
control block .
Alternatively,
illustrates
important change when movement primitives are represented in external coordinates, i.e. a task-level representation . For
instance, the acceleration of the fingertip in the task of
pole balancing would be interpreted as a task-level command issued by the movement primitive in external coordinates, by contrast to joint angular accelerations of the
entire arm and body that would be issued by a movement
primitive in internal coordinates. Most often, task-level
representations are easier to extract from a demonstration,
and have a more compact representation. Task-level representations can also cope with a mismatch in dynamic
and/or kinematic structure between the teacher and the
student—only the task state is represented, not the state of
motor system that performs the task. Task-level imitation
requires prior knowledge of how a task-level command
can be converted into a command in internal coordinates,
a classic problem in control theory treated under the name
of inverse kinematics , but which
has found several elegant solutions in neural computation
in the recent years .
In summary, movement primitives for imitation learning seem to be the most useful if expressed in kinematic
coordinates, either in internal (e.g. joint, muscle) space
˙(t) = (z(t),t,)
or in external (task) space
x˙(t) = (z(t),t,).
Phil. Trans. R. Soc. Lond. B 
Note that the formulations in equations (2.4) and (2.5)
intentionally use z, the variable that represents all possible
state information about the movement system and the
environment as input, but only output a variable that is
the desired change of state of the student in the selected
coordinate system, i.e., x˙ in external space, and ˙ in
internal space. By dropping the explicit time dependence
on the right-hand sides of equations (2.4) and (2.5), both
policy formulations can be made to be autonomous.
Direct policy learning from imitation can now be
reviewed more precisely in the context of the discussions
of the previous paragraphs and figure 2. Direct policy
learning in task space was conducted for the task of pole
balancing with a computer-simulated pole . For this purpose, a
supervised neural network was trained on task-level data
recorded from a human demonstration. Similarly, several
mobile robotics groups adopted imitation by direct policy
learning using a ‘robot teacher’ . For example, the ‘robot student’ followed the
‘robot teacher’s’ movements in a specific environment,
mimicked its kinematic, task-oriented actions, and learned
to associate which action to choose in which state. Afterwards, the robot student had the same competence as the
teacher in this environment. An impressive application of
direct policy learning in a rather complex control system,
a flight simulator, was demonstrated by Sammut et al.
 . Kinematic control actions from several human
subjects were recorded and an inductive machine learning
algorithm was trained to represent the control with
decision trees. Subsequently, the system was able to
autonomously perform various flight manoeuvres.
In all these direct policy-learning approaches, there is
no need for the student to know the task goal of the
teacher, i.e. equation (2.2) has only imitation-specific criteria, but no task-specific criteria. Imitation learning is
greatly simplified in this manner. However, the student
will not be able to undergo self-improvement unless an
explicit reward signal, usually generated from a task-
Computational approaches to motor learning by imitation
S. Schaal and others
specific optimization criterion, is provided to the student,
as in approaches discussed in the following section.
Another problem with direct policy learning is that there
is no guarantee that the imitated behaviour is stable, i.e.
can reach the (implicit) behavioural goal from all start
configurations. Lastly, imitation by direct policy learning
usually generates policies that cannot be re-used for a
slightly modified behavioural goal. For instance, if reaching for a specific target was learned by direct policy learning, and the target location changes, the commands issued
by the learned policy are wrong for the new target
location. Such a form of imitation of is often called ‘indiscriminate imitation’ or ‘mimicking’ as it just repeats an
observed action pattern without knowledge about how to
modify it for a new behavioural context.
(c) Imitation by learning policies from
demonstrated trajectories
A teacher’s demonstration usually provides a rather limited amount of data, best described as ‘sample trajectories’. Various projects investigated how a stable policy can
be instantiated from such small amount of information. As
a crucial difference with respect to direct policy learning, it
is now assumed that the task goal is known (see the following examples), and the demonstrated movement is only
used as a seed for an initial policy, to be optimized by
a self-improvement process. This self-learning adjusts the
imitated movement to kinematic and dynamic discrepancies between the student and the teacher, and additionally ensures behavioural stability.
The idea of learning from trajectories was explored with
an anthropomorphic robot arm for dynamic manipulation
tasks, for instance learning a tennis forehand and the game
of kendama (‘ball-in-the-cup’) . At the outset, a human demonstrated the task, and his/her movement trajectory was
recorded with marker-based optical recording equipment
(OptoTrack). This process resulted in spatio-temporal
data about the movement of the manipulated object in
Cartesian coordinates, as well as the movement of the
actuator (arm) in terms of joint angle coordinates. For
imitation learning, a hybrid internal/external evaluation
criterion was chosen. Initially, the robot aimed at indiscriminate imitation of the demonstrated trajectory in task
space based on position data of the endeffector, while trying to use an arm posture as similar as possible to the
demonstrated posture of the teacher . This approximation process corrected for kinematic differences between the teacher and the robot and
resulted in a desired trajectory for the robot’s motion—a
desired trajectory can also be conceived of as a nonautonomous policy . Afterwards, using
manually provided knowledge of the task goal in form of
optimization
criterion,
performance
improved by trial and error learning until the task was
accomplished. For this purpose, the desired endeffector
trajectory of the robot was approximated by splines, and
the spline nodes, called via-points, were adjusted in space
and time by optimization techniques until the task was fulfilled. Using this method,
the robot learned to manipulate a stochastic, dynamic
environment within a few trials.
A spline-based encoding of a control policy is nonauton-
Phil. Trans. R. Soc. Lond. B 
omous, because the via-points defining the splines are
parameterized explicitly in time. There are two drawbacks
in using such nonautonomous movement primitives. First,
modifying the policy for a different behavioural context,
e.g. a change of target in reaching or a change of timing
and amplitude in a locomotion pattern, requires more
complex computations in terms of scaling laws of the viapoints . Second, and more
severely, nonautonomous policies are not very robust in
coping with unforeseen perturbations of the movement.
For instance, when abruptly holding the arm of a tennis
player during a forehand swing, a nonautonomous policy
would continue creating desired values for the movement
system, and, owing to the explicit time dependency, these
desired values would increasingly more open a large gap
between the current position and the desired position.
This gap can potentially cause huge motor commands that
fight the advert perturbation, and, if the arm were
released, it would ‘jump’ to catch up with the target trajectory; a behaviour that is undesirable in any motor system
autonomous movement primitives can avoid this behaviour as the output of the policy is solely state and not time
dependent, and perturbations can create inhibitive terms
in the policy that ensure that the planned movement of
the policy will never deviate too much from the actual position. In this vein, Ijspeert et al. suggested the
use of autonomous dynamical systems as an alternative
to spline-based imitation learning, realizing that equations
(2.4) and (2.5) are nothing but nonlinear differential
equations. In their approach, a demonstrated trajectory is
encoded by learning the transformation from a simple
canonical attractor system to a new nonlinear attractor
landscape that has the demonstrated trajectory as its
unique attractor. Both limit cycle or point attractors could
be realized, corresponding to rhythmic or discrete movement primitives. The evaluation criterion for imitation was
the deviation of the reproduced trajectory from the demonstrated one, either in internal or external space—reaching the target of the movement, i.e. either a point or a limit
cycle, is automatically guaranteed by shaping the attractor
landscape appropriately. The dynamic systems policies
were designed to provide a spatial and temporal invariant,
i.e. a qualitatively similar movement will always lead to a
similarly parameterized movement primitive, irrespective
of the timing of the movement and the target to which the
movement was executed. Coupling terms to the differential equations allowed natural robustness towards external
perturbations ). The effectiveness of imitation learning with these dynamic systems
primitives was successfully demonstrated on a humanoid
robot that learned a series of movements such as tennis
forehand, tennis backhand and drumming sequences from
a human teacher (figure 3), and that was subsequently
able to re-use the learned movement in modified behavioural contexts.
Another, more biologically inspired, dynamic systems
approach to imitation was pursued by Billard and colleagues . Joint angular trajectories, recorded from
human demonstrations, were segmented using zero velocity points. The policy approximated the segment for each
joint movement by a second-order differential equation
S. Schaal and others
Computational approaches to motor learning by imitation
Figure 3. Four frames of a tennis swing over time, progressing from the top downwards. (a) Teacher demonstration of a
tennis swing; (b) imitated movement by the humanoid robot.
that activated a pair of antagonistic muscles, modelled as
spring–damper systems .
Owing to the dynamic properties of muscles, this policy
generates joint angle trajectories with a bell-shaped velocity profile similarly to human motion; the initial flexion
or extension force determines entirely the trajectory and
is computed using the initial acceleration of the demonstrated trajectory segment. After acquiring this movement,
primitive imitation learning is used to combine joint trajectory segments to produce whole body motion. For this
purpose, a time-delay recurrent neural network is trained
to reproduce the sequential activation of each joint, similar
to methods of associative memory . Both speed and amplitude of movement that can
be modulated by adjusting appropriate parameters in the
network. This imitation system can generate complex
Phil. Trans. R. Soc. Lond. B 
movement sequences (figure 4) and even ‘improvise’
movement by randomly activating nodes in the associative memory.
(d) Imitation by model-based policy learning
A third approach to learning a policy from imitation
employs model-based learning . From the demonstrated behaviour, not the
policy but a predictive model of the task dynamics is
approximated . Given knowledge
of the task goal, the task-level policy of the movement
primitive can be computed with reinforcement learning
procedures based on the learned model. For example,
Atkeson & Schaal showed how the model-based approach allowed an
anthropomorphic robot arm to learn the task of pole-
Computational approaches to motor learning by imitation
S. Schaal and others
Figure 4. Learning of movement sequences by imitation. (a) Teacher demonstrates movement sequence; (b) imitated
movement by the humanoid robot.
balancing in just a single trial, and the task of a ‘pendulum
swing-up’ in only three to four trials. These authors also
demonstrated that task-level imitation based on direct policy learning, augmented with subsequent self-learning, can
be rather fragile and does not necessarily provide significant learning speed improvement over pure trial-and-error
learning without a demonstration.
(e) Matching of demonstrated behaviour against
existing movement primitives
The approaches discussed in the previous sections illustrated some computational ideas for how novel behaviours
can be learned by imitation. Interesting insights into these
methods can be gained by analysing the process of how
a perceived behaviour is mapped onto a set of existing
primitives. Two major questions are: what is the matching criterion for recognizing
a behaviour; and in which coordinate frame does matching
take place?
(i) Matching based on policies with kinetic outputs
If only a kinetic control policy of the movement primitive exists (cf. equation (2.1)), finding a matching criterion
becomes difficult because kinetic outputs such as forces
or torques cannot be observed from demonstrations. One
solution would be to execute a primitive, observe its outcome in either internal or external kinematic space, and
generate in the chosen coordinate frame a performance
criterion based on the similarity between the executed and
the teacher’s behaviour, e.g. the squared difference of state
variables over time or distance to a goal at the end of the
movement. This procedure needs to be repeated for every
primitive in the repertoire and is thus quite inefficient.
Given that kinetic policies are also not very useful for
learning novel movements by imitation (cf. § 2b), kinetic
policies seem to be of little use in imitation learning.
Phil. Trans. R. Soc. Lond. B 
(ii) Matching based on policies with kinematic outputs
If the primitive outputs observable variables, e.g. kinematic commands as in equations (2.4) and (2.5), matching
is highly simplified because the output of the primitive can
be compared directly with the teacher’s performance.
execution stage of figure 2 creates motor commands that
faithfully realize the kinematic plans of the primitive, i.e.
that motor-command generation approximately inverts
the dynamics of the movement system . At
least two forms of matching mechanisms are possible.
One matching mechanism simply treats the demonstrated movement as a candidate for a new movement
primitive and fits the parameterization of this primitive.
The parameters are subsequently compared with the parameters of all previously learned primitives, and the best
matching one in memory is chosen as the winner. For this
method to work, the parameterization of the movement
primitive should have suitable invariances towards variations of a movement, e.g. temporal and spatial scale
invariance. The via-point method of Miyamoto et al.
 can easily be adapted for such movement recognition, as via-points represent a parsimonious parameterization of a movement that
classification algorithms, e.g. nearest neighbour methods
 . Similarly, the dynamic systems
approach to motor primitives of Ijspeert et al. creates a movement parameterization that affords classification in parameter space—indeed, the in-built scale and
time invariances of this technique adds significant robustness to movement recognition in comparison to methods.
The second matching paradigm is based on the idea of
predictive forward models . While observing the teacher, each
movement primitive can try to predict the temporal evol-
S. Schaal and others
Computational approaches to motor learning by imitation
ution of the observed movement based on the current
state z of the teacher. The primitive with the best
prediction abilities will be selected as the best match. If, as
mentioned above, the motor execution stage of the control
circuit (figure 2) faithfully realizes the movement plan
issued by a movement primitive, the primitive can act
itself as a forward model, i.e. it can predict a change in
state z of the teacher (cf. equations (2.4) and (2.5)). Alternatively, it is also possible to include prediction over the
entire dynamics of the movement system. For this purpose, the output of the movement primitive is fed to the
motor-command execution stage, whose output is subsequently passed through a predictive forward model of
the dynamics of the student’s movement system , thus predicting the change of state of movement without actually
performing it. This technique will work even when the
motor execution stage is less accurate in realizing desired
movement kinematics, but it comes at the cost of two
more levels of signal processing, i.e. the simulated motorcommand generation and the need for a forward model
of the motor system. Demiris & Hayes realized
such an imitation system in a simulated humanoid.
What is particularly noteworthy in these approaches to
movement recognition is the suggested bi-directional
interaction between perception and action: movement recognition is directly accomplished with the movementgenerating mechanism. This concept is compatible with
the concept of mirror neurons in neurobiology , with the simulation
theory of mind reading , and
it also ties into other research projects that emphasize the
bi-directional interaction of generative and recognition
models in unsupervised
learning. Such bi-directional theories enjoy an increasing
popularity in theoretical models to perception and action
as they provide useful constraints for explaining the autonomous development of such system.
(iii) Matching based on other criteria
Exploiting the literature on computer vision and statistical classification, a large variety of alternative approaches
to movement recognition can be developed, mostly without taking into account mutuality criteria between movement generation and movement recognition. Rittscher &
Bake provide an overview of techniques in this
(f ) The correspondence problem
An important topic of imitation learning concerns how
to map the external and internal space of the teacher to
the student, often called the ‘correspondence problem’
 . Solving correspondence in external space is usually simplified, as external
coordinates
coordinates)
independent of the kinematic and dynamic structure of
the teacher. For instance, if pole balancing could be demonstrated by a dolphin, a human student could imitate
despite the mismatch in body structure if only task-level
imitation is attempted—the only transformation needed is
a mapping from the teacher’s body-centred external space
to the student’s body-centred external space, which is just
a linear transformation. Correspondence in internal space
Phil. Trans. R. Soc. Lond. B 
is a more complex problem. Even when teacher and student have the same degrees of freedom, as it is the case
with human-to-human or human-to-humanoid-robot imitation, the bodies of student and teacher are bound to
differ in many ways, including in their ranges of motion,
in their exact kinematics, and their dynamics. The mapping is even more difficult when the teacher and student
have dissimilar bodies. In that case, the student can only
imitate approximately, reproducing only sub-goals or substates of the demonstrated motion. The correspondence
problem consists of defining which sub-states of the
motion can and/or should be reproduced. Dautenhahn &
Nehaniv proposed a general mathematical framework to express such a mapping function in terms of transfer functions across different spaces. Alissandrakis et al.
 implement this framework to solve the correspondence problem in a chess game case study. The movement
of two chess pieces (e.g. queen and knight) are directed by
very different rules such that the two pieces cannot replicate
each other’s move in just one time step. For the knight to
replicate the trajectory followed by the queen, it must
define several sub-goals (positions on the chessboard)
through which the queen has travelled and that the knight
can reach using its own movement capacities. The best
strategy to define the sub-goals depends on the metric
applied to measure the imitation performance. The authors
compare metrics that minimize either the total number of
moves required for the reproduction, or the space covered
during the reproduction by the motion.
(g) Imitation of complex movement sequences
One final issue concerns the imitation of complex motor
acts that involve learning a sequence of primitives and
when to switch between them. In this context, Fagg &
Arbib provided a model of reaching and grasping
based on the known anatomy of the fronto-parietal circuits, including the mirror neuron system. Essentially,
their model employed a recurrent neural network that
sequenced and switched between motor schemas based on
sensory cues. The work of Billard and colleagues follows a similar vein, just at a higher level of biological abstraction and more suitable for the control of real,
complex robotic systems. In a robotic study, Pook &
Ballard used hidden Markov models to learn
appropriate sequencing from demonstrated behaviour for
a dexterous manipulation task. There is also large body of
literature
time-series
segmentation
 that employed competitive learning and
forward models for recognition and sequencing in a way
that is easily adapted for imitation learning as illustrated
in figure 1.
3. SUMMARY
Using the formalization of motor control in terms of
generating control policies under a chosen performance
criterion, we discussed computational imitation learning
as methodology to bootstrap a student’s control policy
from a teacher’s demonstration. Different methods of imitation were classified according to which variables were
assumed observable for the student, whether variables
Computational approaches to motor learning by imitation
S. Schaal and others
were of kinetic or kinematic nature, whether internal,
external coordinates, or both were used during demonstration, and whether the task goal was explicitly known
to the student or not. Additional insights could be
obtained by discussing how a demonstrated movement
can be mapped onto a set of existing movement primitives.
Important topics in computational imitation concerned
the formation of motor primitives, their representation,
their sequencing, the reciprocal interaction of movement
recognition and movement generation, and the correspondence problem. At the current stage of research, all these
issues have been modelled in various ways, demonstrating
an increasingly growing formal understanding of how imitation learning can be accomplished. Among the most crucial missing points to be addressed in imitation is
presumably a formalization of extracting the intent of a
demonstrated movement. Billard & Schaal suggested some initial ideas towards this goal by modelling
the probability distribution over manipulated objects by
the teacher, which triggered appropriate imitation behaviour in a humanoid robot. However, a more abstract representation of task goals, perhaps as a set of generic goal
taxonomies, is needed to make further progress in this
This work was made possible by awards, nos. 9710312/
0010312 and 0082995, of the National Science Foundation,
award AC no. 98-516 by NASA, an AFOSR grant on Intelligent Control, the ERATO Kawato Dynamic Brain Project
funded by the Japanese Science and Technology Agency, and
the ATR Human Information Processing Research Laboratories.
1For this paper, only visually mediated imitation will be considered,
although, at least in humans, verbal communication can supply important
additional information.
2Note that instead of a formulation as a differential equation, we would
also choose a difference equation, i.e. where a desired ‘next state’ is the
output of the policy, not a desired change of state.