Domain-adversarial neural networks
to address the appearance variability of
histopathology images
Maxime W. Lafarge, Josien P.W. Pluim, Koen A.J. Eppenhof, Pim Moeskops,
and Mitko Veta
Medical Image Analysis Group, Department of Biomedical Engineering,
Eindhoven University of Technology, The Netherlands
Abstract. Preparing and scanning histopathology slides consists of several steps, each with a multitude of parameters. The parameters can vary
between pathology labs and within the same lab over time, resulting in
signiﬁcant variability of the tissue appearance that hampers the generalization of automatic image analysis methods. Typically, this is addressed
with ad-hoc approaches such as staining normalization that aim to reduce the appearance variability. In this paper, we propose a systematic
solution based on domain-adversarial neural networks. We hypothesize
that removing the domain information from the model representation
leads to better generalization. We tested our hypothesis for the problem
of mitosis detection in breast cancer histopathology images and made
a comparative analysis with two other approaches. We show that combining color augmentation with domain-adversarial training is a better
alternative than standard approaches to improve the generalization of
deep learning methods.
Keywords: Domain-adversarial training, histopathology image analysis
Introduction
Histopathology image analysis aims at automating tasks that are diﬃcult, expensive and time-consuming for pathologists to perform. The high variability of the
appearance of histopathological images, which is the result of the inconsistency
of the tissue preparation process, is a well-known observation. This hampers the
generalization of image analysis methods, particularly to datasets from external
pathology labs.
The appearance variability of histopathology images is commonly addressed
by standardizing the images before analysis, for example by performing staining
normalization . These methods are eﬃcient at standardizing colors while
keeping structures intact, but are not equipped to handle other sources of variability, for instance due to diﬀerences in tissue ﬁxation.
We hypothesize that a more general and eﬃcient approach in the context
of deep convolutional neural networks (CNNs) is to impose constraints that
 
M.W. Lafarge et al.
disregard non-relevant appearance variability with domain-adversarial training
 . We trained CNN models for mitosis detection in breast cancer histopathology images on a limited amount of data from one pathology lab and evaluated
them on a test dataset from diﬀerent, external pathology labs. In addition to
domain-adversarial training, we investigated two additional approaches (color
augmentation and staining normalization) and made a comparative analysis. As
a main contribution, we show that domain-adversarial neural networks are a
new alternative for improving the generalization of deep learning methods for
histopathology image analysis.
Materials and Methods
This study was performed with the TUPAC16 dataset that includes 73 breast
cancer cases annotated for mitotic ﬁgures. The density of mitotic ﬁgures can be
directly related to the tumor proliferation activity, and is an important biomarker
for breast cancer prognostication.
The cases come from three diﬀerent pathology labs (23, 25 and 25 cases per
lab) and were scanned with two diﬀerent whole-slide image scanners (the images
from the second two pathology labs were scanned with the same scanner). All
CNN models were trained with eight cases (458 mitoses) from the ﬁrst pathology
lab. Four cases were used as a validation set (92 mitoses). The remaining 12
cases (533 mitoses) from the ﬁrst pathology lab were used as an internal test
set1 and the 50 cases from the two other pathology labs (469 mitoses) were used
to evaluate inter-lab generalization performance.
The Underlying CNN Architecture
The most successful methods for mitosis detection in breast cancer histopathology images are based on convolutional neural networks (CNN). These methods
train models to classify image patches based on mitosis annotations resulting
from the agreement of several expert pathologists .
The baseline architecture that is used in all experiments of this study is a
6-layer neural network with four convolutional and two fully connected layers
that takes a 63 × 63 image patch as an input and produces a probability that
there is a mitotic ﬁgure in the center of the patch as an output. The ﬁrst convolutional layer has 4 × 4 kernels and the remaining three convolutional layers
have 3 × 3 kernels. All convolutional layers have 16 feature maps. The ﬁrst fully
connected layer has 64 neurons and the second layer serves as the output layer
with softmax activation. Batch normalization, max-pooling and ReLU nonlinearities are used throughout. This architecture is similar to the one proposed in
 . The neural network can be densely applied to images in order to produce a
mitosis probability map for detection.
1 This test set is identical to the one used in the AMIDA13 challenge .
DANNs to address the appearance variability of histopathology images
Three Approaches to Handling Appearance Variability
Poor generalization occurs when there is a discrepancy between the distribution
of the training and testing data. Increasing the amount of training data can be
of help, however, annotation of histology images is a time-consuming process
that requires scarce expertise. More feasible solutions are needed, therefore we
chose to investigate three approaches.
One straightforward alternative is to artiﬁcially produce new training samples. Standard data augmentation methods include random spatial and intensity/color transformation (e.g. rotation, mirroring and scaling, and color shifts).
In this study, we use spatial data augmentation (arbitrary rotation, mirroring
and ±20% scaling) during the training of all models. Since the most prominent
source of variability in histopathology images is the staining color appearance,
the contribution of color augmentation (CA) during training is evaluated separately.
The opposite strategy is to reduce the appearance variability of all the images
as a pre-processing step before training and evaluating a CNN model. For hematoxylin and eosin (H&E) stained slides, staining normalization (SN) methods
can be used .
A more direct strategy is to constrain the weights of the model to encourage learning of mitosis-related features that are consistent for any input image
appearance. We observed that the features extracted by a baseline CNN mitosis
classiﬁer carry information about the origin of the input patch (see Section 3).
We expect that better generalization can be achieved by eliminating this information from the learned representation with domain-adversarial training .
Finally, in addition to the three individual approaches, we also investigate
all possible combinations.
Color Augmentation. Color variability can be increased by applying random
color transformations to original training samples. We perform color augmentation by transforming every color channels Ic ←ac · Ic + bc, where ac and bc are
drawn from uniform distributions ac ∼U [0.9, 1.1] and bc ∼U [−10, +10].
Staining Normalization. The RBG pixel intensities of H&E-stained histopathology images can be modeled with the Beer-Lambert law of light absorption:
Ic = I0 exp (−Ac,∗· C). In this expression c = 1, 2, 3 is the color-channel index,
A ∈[0, +∞]3×2 is the matrix of absorbance coeﬃcients and C ∈[0, +∞]2 are
the stain concentrations . We perform staining normalization with the method
described in . This is an unsupervised method that decomposes any image with
estimates of its underlying A and C. The appearance variability over the dataset
can then be reduced by recomposing all the images using some ﬁxed absorbance
coeﬃcients.
Domain Adversarial Neural-Network. Since every digital slide results from
a unique combination of preparation parameters, we assume that all the image
M.W. Lafarge et al.
Fig. 1. Illustration of the variability of histological images with 8 patches from diﬀerent
slides (ﬁrst row), and their transformed version after staining normalization (second
row). The third row illustrates the range of color variation induced by color augmentation.
patches extracted from the same slide come from the same unique data distribution and thus constitute a domain. Domain-adversarial neural networks (DANN)
allow to learn a classiﬁcation task, while ensuring that the domain of origin of
any sample of the training data cannot be recovered from the learned feature
representation . Such a domain-agnostic representation improves the crossdomain generalization of the trained models.
Any image patch x extracted from the training data can be given two labels:
its class label y (assigned to “1” if the patch is centered at a mitotic ﬁgure, “0”
otherwise) and its domain label d (a unique identiﬁer of the slide that is the
origin of the patch).
probability
probability
Fig. 2. Architecture of the domain-adversarial neural network. The domain classiﬁcation (red) bifurcates from the baseline network (blue) at the second and forth layers.
The training of the mitosis classiﬁer introduced in Sect. 2.2 is performed by
minimizing the cross-entropy loss LM(x, y; θM), where θM are the parameters
of the network.
The DANN is made of a second CNN that takes as input the activations of
the second and fourth layers of the mitosis classiﬁer and predicts the domain
DANNs to address the appearance variability of histopathology images
identiﬁer d. This network is constructed in parallel to the mitosis classiﬁer, with
the same corresponding architecture (Fig. 2). Multiple bifurcations are used to
make domain classiﬁcation possible from diﬀerent levels of abstraction and to
improve training stability as in . The cross-entropy loss of the domain classiﬁer
is LD(x, d; θM, θD), where θD are the parameters of the bifurcated network (note
however that the loss is also a function of θM).
The weights of the whole network are optimized via gradient back-propagation
during an iterative training process that consists of three successive update rules:
Optimization of the mitosis classiﬁer
with learning rate λM:
θM ←θM −λM
Optimization of the domain classiﬁer
with learning rate λD:
θD ←θD −λD
Adversarial update of the mitosis classiﬁer:
θM ←θM + αλD
The update rules (1) and (3) work in an adversarial way: with (1), the parameters θM are updated for the mitosis detection task (by minimizing LM), and
with (3), the same parameters are updated to prevent the domain of origin to be
recovered from the learned representation (by maximizing LD). The parameter
α ∈ controls the strength of the adversarial component.
Evaluation
The performances of the mitosis detection models were evaluated with the F1score as described in . We used the trained classiﬁers to produce dense
mitosis probability maps for all test images. All local maxima above an operating point were considered detected mitotic ﬁgures. The operating point was
determined as the threshold that maximizes the F1-score over the validation set.
We used the t-distributed stochastic neighbor embedding (t-SNE) method
for low-dimensional feature embedding, to qualitatively compare the domain
overlap of the learned feature representation for the diﬀerent methods.
Experiments and Results
For every possible combination of the three approaches developed in Section 2.3,
we trained three convolutional neural networks with the same baseline architecture, under the same training procedure, but with random initialization seeds to
assess the consistency of the approaches.
Baseline Training. Training was performed with stochastic gradient descent
with momentum and with the following parameters: batch size of 64 (with balanced class distribution), learning rate λM of 0.01 with a decay factor of 0.9 every
M.W. Lafarge et al.
5000 iterations, weight decay of 0.0005 and momentum of 0.9. The training was
stopped after 40000 iterations.
Because the training set has a high class imbalance, hard negative mining
was performed as previously described . To this purpose, an initial classiﬁer
was trained with the baseline CNN model. A set of hard negative patches was
then obtained by probabilistically sampling the probability maps produced by
this ﬁrst classiﬁer (excluding ground truth locations). We use the same set of
hard-negative samples for all experiments.
Domain-Adversarial Training. Every training iteration of the DANN models
involves two passes. The ﬁrst pass is performed in the same manner as the
baseline training procedure and it involves the update (1). The second pass uses
batches balanced over the domains of the training set, and is used for updates
(2) and (3). Given that the training set includes eight domains, the batches for
the second pass are therefore made of 8 random patches from each training case.
The learning rate λD for these updates was ﬁxed at 0.0025.
As remarked in , domain-adversarial training is an unstable process.
Therefore we use a cyclic scheduling of the parameter α involved in the adversarial update (3). This allows alternating between phases in which both branches
learn their respective tasks without interfering, and phases in which domainadversarial training occurs. In order to avoid getting stuck in local maxima and
to ensure that domain information is not recovered over iterations in the main
branch, the weights of the domain classiﬁer θD are reinitialized at the beginning
of every cycle.
Performance. The F1-scores for all three approaches and their combinations
are given in Table 1. t-SNE embeddings of the feature representations learned
by the baseline model and the three investigated approaches are given in Fig.
3. Although the t-SNE embeddings of the ﬁrst row only show two domains for
clarity, the same observations can be made for almost all pairs of domains.
Table 1. Mean and standard deviation of the F1-score over the three repeated experiments. Every column of the table represents the performance of one method on the
internal test set (ITS; from the same pathology lab) and the external test sets (ETS;
from diﬀerent pathology labs). The squares indicate the diﬀerent investigated methods.
Multiple squares indicate a combination of methods.
.62 ± .02 .61 ± .01
.62 ± .00 .51 ± .02
DANNs to address the appearance variability of histopathology images
t-SNE embeddings of 80 patches represented by the learned features at the
fourth layer of the mitosis classiﬁer. First row: patches are balanced across classes
(mitosis: disk, non-mitosis: circle) and are equally sampled from two diﬀerent slides of
the training set (red/blue). Second row: patches of mitotic ﬁgures sampled from slides
of the internal (orange) and external test set (green). Each column corresponds to one
approach: (a) baseline, (b) SN, (c) CA, (d) DANN.
Discussion and Conclusions
On the internal test set, all methods and combinations have good performance
in line with previously reported results . The combination of color augmentation and domain-adversarial training has the best performance (F1-score
of 0.62±0.02). The staining normalization method and combinations of staining
normalization with other methods have the worst performance (F1-scores lower
than the baseline method).
As with the internal test set, the best performance on the external test set
is achieved by the combination of color augmentation and domain-adversarial
training (F1-score of 0.62 ± 0.00). On the external test set, all three investigated
methods show improvement since the baseline method has the worst performance
(F1-score of 0.33 ± 0.08).
The intra-lab t-SNE embeddings presented in the ﬁrst row of Fig. 3 show that
the baseline model learns a feature representation informative of the domain, as
shown by the presence of well-deﬁned clusters corresponding to the domains of
the embedded image patches. In contrast, each of the three approaches produces
some domain confusion in the model representation, since such domain clusters
are not produced by t-SNE under the same conditions.
While staining normalization improves the generalization of the models to
data from an external pathology lab, it clearly has a general adverse eﬀect when
combined to other methods, compared to combinations without it. A possible
reason for this eﬀect could be that by performing staining normalization, the
M.W. Lafarge et al.
variability of the training dataset is reduced to a point that makes overﬁtting
more likely.
For both test datasets, the best individual method is color augmentation.
The t-SNE embeddings in the second row of Fig. 3 show that the models trained
with CA produce a feature representation more independent of the lab than the
baseline, SN or DANN. This is in line with the observation that the appearance
variability in histopathology images is mostly manifested as staining variability.
The best performance for both datasets is achieved by the combination of
color augmentation and domain-adversarial training. This complementary eﬀect
indicates the ability of domain-adversarial training to account for sources of
variability other than color.
In conclusion, we investigated DANNs as an alternative to standard augmentation and normalization approaches, and made a comparative analysis. The
combination of color augmentation and DANNs had the best performance, con-
ﬁrming the relevance of domain-adversarial approaches in histopathology image
analysis. This study is based on the performances for a single histopathology
image analysis problem and only one staining normalization method was investigated. These are limiting factors, and further conﬁrmation of the conclusions
we make is warranted.