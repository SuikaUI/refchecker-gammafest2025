Bridging the Gap Between Anchor-based and Anchor-free Detection via
Adaptive Training Sample Selection
Shifeng Zhang1,2, Cheng Chi3, Yongqiang Yao4, Zhen Lei1,2*, Stan Z. Li5
1 CBSR, NLPR, CASIA
2 SAI, UCAS
3 AIR, CAS
5 Westlake University
{shifeng.zhang,zlei,szli}@nlpr.ia.ac.cn, , yao 
Object detection has been dominated by anchor-based
detectors for several years. Recently, anchor-free detectors have become popular due to the proposal of FPN and
Focal Loss. In this paper, we ﬁrst point out that the essential difference between anchor-based and anchor-free
detection is actually how to deﬁne positive and negative
training samples, which leads to the performance gap between them. If they adopt the same deﬁnition of positive
and negative samples during training, there is no obvious difference in the ﬁnal performance, no matter regressing from a box or a point.
This shows that how to select positive and negative training samples is important
for current object detectors. Then, we propose an Adaptive Training Sample Selection (ATSS) to automatically select positive and negative samples according to statistical
characteristics of object. It signiﬁcantly improves the performance of anchor-based and anchor-free detectors and
bridges the gap between them. Finally, we discuss the necessity of tiling multiple anchors per location on the image
to detect objects. Extensive experiments conducted on MS
COCO support our aforementioned analysis and conclusions. With the newly introduced ATSS, we improve stateof-the-art detectors by a large margin to 50.7% AP without introducing any overhead.
The code is available at
 
1. Introduction
Object detection is a long-standing topic in the ﬁeld of
computer vision, aiming to detect objects of predeﬁned categories. Accurate object detection would have far reaching
impact on various applications including image recognition
and video surveillance. In recent years, with the development of convolutional neural network (CNN), object detection has been dominated by anchor-based detectors, which
can be generally divided into one-stage methods 
*Corresponding author
and two-stage methods . Both of them ﬁrst tile a large
number of preset anchors on the image, then predict the category and reﬁne the coordinates of these anchors by one or
several times, ﬁnally output these reﬁned anchors as detection results. Because two-stage methods reﬁne anchors several times more than one-stage methods, the former one has
more accurate results while the latter one has higher computational efﬁciency. State-of-the-art results on common detection benchmarks are still held by anchor-based detectors.
Recent academic attention has been geared toward
anchor-free detectors due to the emergence of FPN and
Focal Loss . Anchor-free detectors directly ﬁnd objects
without preset anchors in two different ways. One way is to
ﬁrst locate several pre-deﬁned or self-learned keypoints and
then bound the spatial extent of objects. We call this type of
anchor-free detectors as keypoint-based methods .
Another way is to use the center point or region of objects to deﬁne positives and then predict the four distances
from positives to the object boundary. We call this kind
of anchor-free detectors as center-based methods .
These anchor-free detectors are able to eliminate those hyperparameters related to anchors and have achieved similar performance with anchor-based detectors, making them
more potential in terms of generalization ability.
Among these two types of anchor-free detectors,
keypoint-based methods follow the standard keypoint estimation pipeline that is different from anchor-based detectors. However, center-based detectors are similar to anchorbased detectors, which treat points as preset samples instead
of anchor boxes. Take the one-stage anchor-based detector RetinaNet and the center-based anchor-free detector FCOS as an example, there are three main differences between them: (1) The number of anchors tiled per
location. RetinaNet tiles several anchor boxes per location,
while FCOS tiles one anchor point1 per location. (2) The
deﬁnition of positive and negative samples. RetinaNet resorts to the Intersection over Union (IoU) for positives and
1A point in FCOS is equal to the center of an anchor box in RetinaNet,
thus we call it as the anchor point. A pair of anchor point and box is associated to the same location of feature map to be classiﬁed and regressed.
 
negatives, while FCOS utilizes spatial and scale constraints
to select samples. (3) The regression starting status. RetinaNet regresses the object bounding box from the preset
anchor box, while FCOS locates the object from the anchor
point. As reported in , the anchor-free FCOS achieves
much better performance than the anchor-based RetinaNet,
it is worth studying which of these three differences are essential factors for the performance gap.
In this paper, we investigate the differences between
anchor-based and anchor-free methods in a fair way by
strictly ruling out all the implementation inconsistencies
between them. It can be concluded from experiment results that the essential difference between these two kind
of methods is the deﬁnition of positive and negative training samples, which results in the performance gap between
them. If they select the same positive and negative samples during training, there is no obvious gap in the ﬁnal
performance, no matter regressing from a box or a point.
Therefore, how to select positive and negative training samples deserves further study. Inspired by that, we propose
a new Adaptive Training Sample Selection (ATSS) to automatically select positive and negative samples based on
object characteristics. It bridges the gap between anchorbased and anchor-free detectors. Besides, through a series
of experiments, a conclusion can be drawn that tiling multiple anchors per location on the image to detect objects is not
necessary. Extensive experiments on the MS COCO 
dataset support our analysis and conclusions. State-of-theart AP 50.7% is achieved by applying the newly introduced
ATSS without introducing any overhead. The main contributions of this work can be summarized as:
• Indicating the essential difference between anchorbased and anchor-free detectors is actually how to de-
ﬁne positive and negative training samples.
• Proposing an adaptive training sample selection to automatically select positive and negative training samples according to statistical characteristics of object.
• Demonstrating that tiling multiple anchors per location
on the image to detect objects is a useless operation.
• Achieving state-of-the-art performance on MS COCO
without introducing any additional overhead.
2. Related Work
Current CNN-based object detection consists of anchorbased and anchor-free detectors. The former one can be divided into two-stage and one-stage methods, while the latter
one falls into keypoint-based and center-based methods.
2.1. Anchor-based Detector
Two-stage method.
The emergence of Faster R-CNN
 establishes the dominant position of two-stage anchorbased detectors. Faster R-CNN consists of a separate region
proposal network (RPN) and a region-wise prediction network (R-CNN) to detect objects. After that, lots
of algorithms are proposed to improve its performance, including architecture redesign and reform ,
context and attention mechanism , multiscale training and testing , training strategy and loss
function , feature fusion and enhancement
 , better proposal and balance . Nowadays,
state-of-the-art results are still held by two-stage anchorbased methods on standard detection benchmarks.
One-stage method.
With the advent of SSD , onestage anchor-based detectors have attracted much attention because of their high computational efﬁciency. SSD
spreads out anchor boxes on multi-scale layers within a
ConvNet to directly predict object category and anchor box
offsets. Thereafter, plenty of works are presented to boost
its performance in different aspects, such as fusing context information from different layers , training from scratch , introducing new loss function
 , anchor reﬁnement and matching , architecture redesign , feature enrichment and alignment
 . At present, one-stage anchor-based
methods can achieve very close performance with two-stage
anchor-based methods at a faster inference speed.
2.2. Anchor-free Detector
Keypoint-based method. This type of anchor-free method
ﬁrst locates several pre-deﬁned or self-learned keypoints,
and then generates bounding boxes to detect objects. CornerNet detects an object bounding box as a pair of
keypoints (top-left corner and bottom-right corner) and
CornerNet-Lite introduces CornerNet-Saccade and
CornerNet-Squeeze to improve its speed. The second stage
of Grid R-CNN locates objects via predicting grid
points with the position sensitive merits of FCN and then
determining the bounding box guided by the grid.
ExtremeNet detects four extreme points (top-most, leftmost, bottom-most, right-most) and one center point to generate the object bounding box. Zhu et al. use keypoint
estimation to ﬁnd center point of objects and regress to all
other properties including size, 3D location, orientation and
pose. CenterNet extends CornetNet as a triplet rather
than a pair of keypoints to improve both precision and recall. RepPoints represents objects as a set of sample
points and learns to arrange themselves in a manner that
bounds the spatial extent of an object and indicates semantically signiﬁcant local areas.
Center-based method. This kind of anchor-free method
regards the center (e.g., the center point or part) of object
as foreground to deﬁne positives, and then predicts the distances from positives to the four sides of the object bounding box for detection. YOLO divides the image into
an S × S grid, and the grid cell that contains the center of
an object is responsible for detecting this object. DenseBox
 uses a ﬁlled circle located in the center of the object
to deﬁne positives and then predicts the four distances from
positives to the bound of the object bounding box for location. GA-RPN deﬁnes the pixels in the center region
of the object as positives to predict the location, width and
height of object proposals for Faster R-CNN. FSAF attaches an anchor-free branch with online feature selection to
RetinaNet. The newly added branch deﬁnes the center region of the object as positives to locate it via predicting four
distances to its bounds. FCOS regards all the locations
inside the object bounding box as positives with four distances and a novel centerness score to detect objects. CSP
 only deﬁnes the center point of the object box as positives to detect pedestrians with ﬁxed aspect ratio. FoveaBox regards the locations in the middle part of object
as positives with four distances to perform detection.
3. Difference Analysis of Anchor-based and
Anchor-free Detection
Without loss of generality, the representative anchorbased RetinaNet and anchor-free FCOS are
adopted to dissect their differences. In this section, we focus on the last two differences: the positive/negative sample
deﬁnition and the regression starting status. The remaining
one difference: the number of anchors tiled per location,
will be discussed in subsequent section. Thus, we just tile
one square anchor per location for RetinaNet, which is quite
similar to FCOS. In the remaining part, we ﬁrst introduce
the experiment settings, then rule out all the implementation
inconsistencies, ﬁnally point out the essential difference between anchor-based and anchor-free detectors.
3.1. Experiment Setting
Dataset. All experiments are conducted on the challenging MS COCO dataset that includes 80 object classes.
Following the common practice , all 115K images
in the trainval35k split is used for training, and all 5K
images in the minival split is used as validation for analysis study. We also submit our main results to the evaluation
server for the ﬁnal performance on the test-dev split.
Training Detail.
We use the ImageNet pretrained
ResNet-50 with 5-level feature pyramid structure as
the backbone. The newly added layers are initialized in the
same way as in . For RetinaNet, each layer in the 5-level
feature pyramid is associated with one square anchor with
8S scale, where S is the total stride size. During training,
we resize the input images to keep their shorter side being
800 and their longer side less or equal to 1, 333. The whole
network is trained using the Stochastic Gradient Descent
(SGD) algorithm for 90K iterations with 0.9 momentum,
0.0001 weight decay and 16 batch size. We set the initial
learning rate as 0.01 and decay it by 0.1 at iteration 60K
Table 1: Analysis of implementation inconsistencies between RetinaNet and FCOS on MS COCO minival set.
“#A=1” means there is one square anchor box per location.
Inconsistency FCOS
RetinaNet (#A=1)
Centerness
32.5 33.4 34.9 35.3 36.8 37.0
and 80K, respectively. Unless otherwise stated, the aforementioned training details are used in the experiments.
Inference Detail. During the inference phase, we resize the
input image in the same way as in the training phase, and
then forward it through the whole network to output the predicted bounding boxes with a predicted class. After that, we
use the preset score 0.05 to ﬁlter out plenty of background
bounding boxes, and then output the top 1000 detections
per feature pyramid. Finally, the Non-Maximum Suppression (NMS) is applied with the IoU threshold 0.6 per class
to generate ﬁnal top 100 conﬁdent detections per image.
3.2. Inconsistency Removal
We mark the anchor-based detector RetinaNet with only
one square anchor box per location as RetinaNet (#A=1),
which is almost the same as the anchor-free detector FCOS.
However, as reported in , FCOS outperforms RetinaNet
(#A=1) by a large margin in AP performance on the MS
COCO minival subset, i.e., 37.1% vs. 32.5%. Furthermore, some new improvements have been made for FCOS
including moving centerness to regression branch, using
GIoU loss function and normalizing regression targets by
corresponding strides. These improvements boost the AP
performance of FCOS from 37.1% to 37.8% 2, making the
gap even bigger. However, part of the AP gap between the
anchor-based detector (32.5%) and the anchor-free detector (37.8%) results from some universal improvements that
are proposed or used in FCOS, such as adding GroupNorm
 in heads, using the GIoU regression loss function,
limiting positive samples in the ground-truth box , introducing the centerness branch and adding a trainable
scalar for each level feature pyramid. These improvements can also be applied to anchor-based detectors, therefore they are not the essential differences between anchorbased and anchor-free methods. We apply them to RetinaNet (#A=1) one by one so as to rule out these implementation inconsistencies. As listed in Table 1, these irrelevant
2This 37.8% AP result does not include the center sample improvement, which is our contribution that has been merged into FCOS and will
be introduced in Sec. 4.2.
Figure 1: Deﬁnition of positives ( 1 ) and negatives ( 0 ).
Blue box, red box and red point are ground-truth, anchor
box and anchor point. (a) RetinaNet uses IoU to select positives ( 1 ) in spatial and scale dimension simultaneously. (b)
FCOS ﬁrst ﬁnds candidate positives ( ? ) in spatial dimension, then selects ﬁnal positives ( 1 ) in scale dimension.
differences improve the anchor-based RetinaNet to 37.0%,
which still has a gap of 0.8% to the anchor-free FCOS. By
now, after removing all the irrelevant differences, we can
explore the essential differences between anchor-based and
anchor-free detectors in a quite fair way.
3.3. Essential Difference
After applying those universal improvements, these are
only two differences between the anchor-based RetinaNet
(#A=1) and the anchor-free FCOS. One is about the classi-
ﬁcation sub-task in detection, i.e., the way to deﬁne positive
and negative samples. Another one is about the regression
sub-task, i.e., the regression starting from an anchor box or
an anchor point.
Classiﬁcation. As shown in Figure 1(a), RetinaNet utilizes
IoU to divide the anchor boxes from different pyramid levels into positives and negatives. It ﬁrst labels the best anchor
box of each object and the anchor boxes with IoU > θp
as positives, then regards the anchor boxes with IoU < θn
as negatives, ﬁnally other anchor boxes are ignored during
training. As shown in Figure 1(b), FCOS uses spatial and
scale constraints to divide the anchor points from different
pyramid levels. It ﬁrst considers the anchor points within
the ground-truth box as candidate positive samples, then selects the ﬁnal positive samples from candidates based on the
scale range deﬁned for each pyramid level3, ﬁnally those
unselected anchor points are negative samples.
As shown in Figure 1, FCOS ﬁrst uses the spatial constraint to ﬁnd candidate positives in the spatial dimension,
then uses the scale constraint to select ﬁnal positives in the
scale dimension. In contrast, RetinaNet utilizes IoU to directly select the ﬁnal positives in the spatial and scale dimension simultaneously. These two different sample selec-
3There are several preset hyperparameters in FCOS to deﬁne the scale
range for ﬁve pyramid levels: [m2, m3] for P3, [m3, m4] for P4, [m4,
m5] for P5, [m5, m6] for P6 and [m6, m7] for P7.
(a) Positive sample
(b) RetinaNet
Figure 2: (a) Blue point and box are the center and bound of
object, red point and box are the center and bound of anchor.
(b) RetinaNet regresses from anchor box with four offsets.
(c) FCOS regresses from anchor point with four distances.
Table 2: Analysis of differences (%) between RetinaNet and
FCOS on the MS COCO minival set.
Classiﬁcation
Regression
Intersection over Union
Spatial and Scale Constraint
tion strategies produce different positive and negative samples. As listed in the ﬁrst column of Table 2 for RetinaNet
(#A=1), using the spatial and scale constraint strategy instead of the IoU strategy improves the AP performance
from 37.0% to 37.8%. As for FCOS, if it uses the IoU
strategy to select positive samples, the AP performance decreases from 37.8% to 36.9% as listed in the second column
of Table 2. These results demonstrate that the deﬁnition of
positive and negative samples is an essential difference between anchor-based and anchor-free detectors.
Regression. After positive and negative samples are determined, the location of object is regressed from positive samples as shown in Figure 2(a). RetinaNet regresses from the
anchor box with four offsets between the anchor box and the
object box as shown in Figure 2(b), while FCOS regresses
from the anchor point with four distances to the bound of
object as shown in Figure 2(c). It means that for a positive
sample, the regression starting status of RetinaNet is a box
while FCOS is a point. However, as shown in the ﬁrst and
second rows of Table 2, when RetinaNet and FCOS adopt
the same sample selection strategy to have consistent positive/negative samples, there is no obvious difference in ﬁnal
performance, no matter regressing starting from a point or
a box, i.e., 37.0% vs. 36.9% and 37.8% vs. 37.8%. These
results indicate that the regression starting status is an irrelevant difference rather than an essential difference.
Conclusion. According to these experiments conducted in
a fair way, we indicate that the essential difference between
one-stage anchor-based detectors and center-based anchorfree detectors is actually how to deﬁne positive and negative
training samples, which is important for current object detection and deserves further study.
4. Adaptive Training Sample Selection
When training an object detector, we ﬁrst need to deﬁne
positive and negative samples for classiﬁcation, and then
use positive samples for regression. According to the previous analysis, the former one is crucial and the anchorfree detector FCOS improves this step. It introduces a new
way to deﬁne positives and negatives, which achieves better performance than the traditional IoU-based strategy. Inspired by this, we delve into the most basic issue in object detection: how to deﬁne positive and negative training
samples, and propose an Adaptive Training Sample Selection (ATSS). Compared with these traditional strategies, our
method almost has no hyperparameters and is robust to different settings.
4.1. Description
Previous sample selection strategies have some sensitive
hyperparameters, such as IoU thresholds in anchor-based
detectors and scale ranges in anchor-free detectors. After
these hyperparameters are set, all ground-truth boxes must
select their positive samples based on the ﬁxed rules, which
are suitable for most objects, but some outer objects will be
neglected. Thus, different settings of these hyperparameters
will have very different results.
To this end, we propose the ATSS method that automatically divides positive and negative samples according to statistical characteristics of object almost without any hyperparameter. Algorithm 1 describes how the proposed method
works for an input image. For each ground-truth box g on
the image, we ﬁrst ﬁnd out its candidate positive samples.
As described in Line 3 to 6, on each pyramid level, we select k anchor boxes whose center are closest to the center
of g based on L2 distance. Supposing there are L feature
pyramid levels, the ground-truth box g will have k × L candidate positive samples. After that, we compute the IoU between these candidates and the ground-truth g as Dg in Line
7, whose mean and standard deviation are computed as mg
and vg in Line 8 and Line 9. With these statistics, the IoU
threshold for this ground-truth g is obtained as tg = mg+vg
in Line 10. Finally, we select these candidates whose IoU
are greater than or equal to the threshold tg as ﬁnal positive samples in Line 11 to 15. Notably, we also limit the
positive samples’ center to the ground-truth box as shown
in Line 12. Besides, if an anchor box is assigned to multiple ground-truth boxes, the one with the highest IoU will be
selected. The rest are negative samples. Some motivations
behind our method are explained as follows.
Selecting candidates based on the center distance between anchor box and object. For RetinaNet, the IoU is
larger when the center of anchor box is closer to the center
of object. For FCOS, the closer anchor point to the center
of object will produce higher-quality detections. Thus, the
closer anchor to the center of object is the better candidate.
Algorithm 1 Adaptive Training Sample Selection (ATSS)
G is a set of ground-truth boxes on the image
L is the number of feature pyramid levels
Ai is a set of anchor boxes from the ith pyramid levels
A is a set of all anchor boxes
k is a quite robust hyperparameter with a default value of 9
P is a set of positive samples
N is a set of negative samples
1: for each ground-truth g ∈G do
build an empty set for candidate positive samples of the
ground-truth g: Cg ←∅;
for each level i ∈[1, L] do
Si ←select k anchors from Ai whose center are closest
to the center of ground-truth g based on L2 distance;
Cg = Cg ∪Si;
compute IoU between Cg and g: Dg = IoU(Cg, g);
compute mean of Dg: mg = Mean(Dg);
compute standard deviation of Dg: vg = Std(Dg);
compute IoU threshold for ground-truth g: tg = mg + vg;
for each candidate c ∈Cg do
if IoU(c, g) ≥tg and center of c in g then
16: end for
17: N = A −P;
18: return P, N;
Using the sum of mean and standard deviation as the
IoU threshold. The IoU mean mg of an object is a measure
of the suitability of the preset anchors for this object. A high
mg as shown in Figure 3(a) indicates it has high-quality
candidates and the IoU threshold is supposed to be high.
A low mg as shown in Figure 3(b) indicates that most of its
candidates are low-quality and the IoU threshold should be
low. Besides, the IoU standard deviation vg of an object is
a measure of which layers are suitable to detect this object.
A high vg as shown in Figure 3(a) means there is a pyramid
level speciﬁcally suitable for this object, adding vg to mg
obtains a high threshold to select positives only from that
level. A low vg as shown in Figure 3(b) means that there
are several pyramid levels suitable for this object, adding vg
to mg obtains a low threshold to select appropriate positives
from these levels. Using the sum of mean mg and standard
deviation vg as the IoU threshold tg can adaptively select
enough positives for each object from appropriate pyramid
levels in accordance of statistical characteristics of object.
Limiting the positive samples’ center to object. The anchor with a center outside object is a poor candidate and
will be predicted by the features outside the object, which
is not conducive to training and should be excluded.
Figure 3: Illustration of ATSS. Each level has one candidate
with its IoU. (a) A ground-truth with a high mg and a high
vg. (b) A ground-truth with a low mg and a low vg.
Maintaining fairness between different objects. According to the statistical theory4, about 16% of samples are in
the conﬁdence interval [mg + vg, 1] in theory. Although the
IoU of candidates is not a standard normal distribution, the
statistical results show that each object has about 0.2 ∗kL
positive samples, which is invariant to its scale, aspect ratio
and location. In contrast, strategies of RetinaNet and FCOS
tend to have much more positive samples for larger objects,
leading to unfairness between different objects.
Keeping almost hyperparameter-free. Our method only
has one hyperparameter k. Subsequent experiments prove
that it is quite insensitive to the variations of k and the proposed ATSS can be considered almost hyperparameter-free.
4.2. Veriﬁcation
Anchor-based RetinaNet. To verify the effectiveness of
our adaptive training sample selection for anchor-based detectors, we use it to replace the traditional strategy in the
improved RetinaNet (#A=1). As shown in Table 3, it consistently boosts the performance by 2.3% on AP, 2.4% on
AP50, 2.9% for AP75, 2.9% for APS, 2.1% for APM and
2.7% for APL. These improvements are mainly due to the
adaptive selection of positive samples for each ground-truth
based on its statistical characteristics. Since our method
only redeﬁnes positive and negative samples without incurring any additional overhead, these improvements can be
considered cost-free.
Anchor-free FCOS. The proposed method can also be applied to the anchor-free FCOS in two different versions: the
lite and full version. For the lite version, we apply some
ideas of the proposed ATSS to FCOS, i.e., replacing its way
to select candidate positives with the way in our method.
FCOS considers anchor points in the object box as candidates, which results in plenty of low-quality positives. In
contrast, our method selects top k = 9 candidates per pyramid level for each ground-truth. The lite version of our
method has been merged to the ofﬁcial code of FCOS as
the center sampling, which improves FCOS from 37.8% to
4 
Table 3: Veriﬁcation of the proposed method (%) on the
MS COCO minival set. ATSS and center sampling are
the full version and the lite version of our proposed method.
RetinaNet (#A=1)
RetinaNet (#A=1) + ATSS
FCOS + Center sampling
FCOS + ATSS
38.6% on AP as listed in Table 3. However, the hyperparameters of scale ranges still exist in the lite version.
For the full version, we let the anchor point in FCOS
become the anchor box with 8S scale to deﬁne positive and
negative samples, then still regress these positive samples to
objects from the anchor point like FCOS. As shown in Table
3, it signiﬁcantly increases the performance by 1.4% for AP,
by 1.7% for AP50, by 1.7% for AP75, by 0.6% for APS,
by 1.3% for APM and by 2.7% for APL. Notably, these
two versions have the same candidates selected in the spatial
dimension, but different ways to select ﬁnal positives from
candidates along the scale dimension. As listed in the last
two rows of Table 3, the full version (ATSS) outperforms
the lite version (center sampling) across different metrics
by a large margin. These results indicate that the adaptive
way in our method is better than the ﬁxed way in FCOS to
select positives from candidates along the scale dimension.
4.3. Analysis
Training an object detector with the proposed adaptive
training sample selection only involves one hyperparameter
k and one related setting of anchor boxes. This subsection
analyzes them one after another.
Hyperparameter k. We conduct several experiments to
study the robustness of the hyperparameter k, which is used
to select the candidate positive samples from each pyramid level. As shown in Table 4, different values of k in
 are used to train the detector.
We observe that the proposed method is quite insensitive
to the variations of k from 7 to 17. Too large k (e.g., 19)
will result in too many low-quality candidates that slightly
decreases the performance. Too small k (e.g., 3) causes
a noticeable drop in accuracy, because too few candidate
positive samples will cause statistical instability. Overall,
the only hyperparameter k is quite robust and the proposed
ATSS can be nearly regarded as hyperparameter-free.
Table 4: Analysis of different values of hyperparameter k
on the MS COCO minival set.
Table 5: Analysis (%) of different anchor scales with ﬁxed
aspect ratio 1 : 1 on the MS COCO minival set.
Table 6: Analysis (%) of different anchor aspect ratios with
ﬁxed scale 8S on the MS COCO minival set.
Aspect Ratio
Anchor Size. The introduced method resorts to the anchor
boxes to deﬁne positives and we also study the effect of the
anchor size. In the previous experiments, one square anchor with 8S (S indicates the total stride size of the pyramid
level) is tiled per location. As shown in Table 5, we conduct
some experiments with different scales of the square anchor
in and the performances are quite stable. Besides, several experiments with different aspect ratios of the
8S anchor box are performed as shown in Table 6. The performances are also insensitive to this variation. These results indicate that the proposed method is robust to different
anchor settings.
4.4. Comparison
We compare our ﬁnal models on the MS COCO
test-dev subset in Table 8 with other state-of-the-art object detectors. Following previous works , the multiscale training strategy is adopted for these experiments, i.e.,
randomly selecting a scale between 640 to 800 to resize the
shorter side of images during training. Besides, we double
the total number of iterations to 180K and the learning rate
reduction points to 120K and 160K correspondingly. Other
settings are consistent with those mentioned before.
As shown in Table 8, our method with ResNet-101
achieves 43.6% AP without any bells and whistles, which
is better than all the methods with the same backbone including Cascade R-CNN (42.8% AP), C-Mask RCNN
 (42.0% AP), RetinaNet (39.1% AP) and ReﬁneDet
 (36.4% AP). We can further improve the AP accuracy of the proposed method to 45.1% and 45.6% by
using larger backbone networks ResNeXt-32x8d-101 and
ResNeXt-64x4d-101 , respectively.
The 45.6% AP
result surpasses all the anchor-free and anchor-based detectors except only 0.1% lower than SNIP (45.7%
AP), which introduces the improved multi-scale training
Table 7: Results (%) with different multiple anchors per
location on the MS COCO minival set.
RetinaNet (#A=9)
+Imprs.+ATSS
+Imprs.+ATSS
+Imprs.+ATSS
+Imprs.+ATSS
and testing strategy. Since our method is about the definition of positive and negative samples, it is compatible
and complementary to most of current technologies. We
further use the Deformable Convolutional Networks (DCN)
 to the ResNet and ResNeXt backbones as well as the
last layer of detector towers. DCN consistently improves
the AP performances to 46.3% for ResNet-101, 47.7% for
ResNeXt-32x8d-101 and 47.7% for ResNeXt-64x4d-101,
respectively. The best result 47.7% is achieved with singlemodel and single-scale testing, outperforming all the previous detectors by a large margin. Finally, with the multiscale testing strategy, our best model achieves 50.7% AP.
4.5. Discussion
Previous experiments are based on RetinaNet with only
one anchor per location. There is still a difference between
anchor-based and anchor-free detectors that is not explored:
the number of anchors tiled per location. Actually, the original RetinaNet tiles 9 anchors (3 scales × 3 aspect ratios)
per location (marked as RetinaNet (#A=9)) that achieves
36.3% AP as listed in the ﬁrst row of Table 7. In addition,
those universal improvements in Table 1 can also be used
to RetinaNet (#A=9), boosting the AP performance from
36.3% to 38.4%. Without using the proposed ATSS, the improved RetinaNet (#A=9) has better performance than RetinaNet (#A=1), i.e., 38.4% in Table 7 vs. 37.0% in Table 1.
These results indicate that under the traditional IoU-based
sample selection strategy, tiling more anchor boxer per location is effective.
However, after using our proposed method, the opposite conclusion will be drawn. To be speciﬁc, the proposed
ATSS also improves RetinaNet (#A=9) by 0.8% on AP,
1.4% on AP50 and 1.1% on AP75, achieving similar performances to RetinaNet (#A=1) as listed in the third and
sixth rows of Table 7. Besides, when we change the number of anchor scales or aspect ratios from 3 to 1, the results
are almost unchanged as listed in the fourth and ﬁfth rows
of Table 7. In other words, as long as the positive samples
are selected appropriately, no matter how many anchors are
tiled at each location, the results are the same. We argue
that tiling multiple anchors per location is a useless operation under our proposed method and it needs further study
to discover its right role.
Table 8: Detection results (%) on MS COCO test-dev set. Bold fonts indicate the best performance.
anchor-based two-stage:
trainval35
ResNet-101
ResNet-101
CoupleNet 
ResNet-101
Inception-ResNet-v2-TDM
Hu et al. 
trainval35k
ResNet-101
DeepRegionlets 
trainval35k
ResNet-101
FitnessNMS 
Gu et al. 
trainval35k
ResNet-101
DetNet 
trainval35k
Soft-NMS 
ResNet-101
SOD-MTGAN 
trainval35k
ResNet-101
G-RMI 
trainval35k
Ensemble of Five Models
C-Mask RCNN 
trainval35k
ResNet-101
Cascade R-CNN 
trainval35k
ResNet-101
Revisiting RCNN 
trainval35k
ResNet-101+ResNet-152
trainval35k
anchor-based one-stage:
YOLOv2 
trainval35k
DarkNet-19
SSD512∗ 
trainval35k
STDN513 
DenseNet-169
DES512 
trainval35k
DSSD513 
trainval35k
ResNet-101
RFB512-E 
trainval35k
PFPNet-R512 
trainval35k
ReﬁneDet512 
trainval35k
ResNet-101
RetinaNet 
trainval35k
ResNet-101
anchor-free keypoint-based:
ExtremeNet 
trainval35k
Hourglass-104
CornerNet 
trainval35k
Hourglass-104
CenterNet-HG 
trainval35k
Hourglass-104
Grid R-CNN 
trainval35k
ResNeXt-101
CornerNet-Lite 
trainval35k
Hourglass-54
CenterNet 
trainval35k
Hourglass-104
RepPoints 
trainval35k
ResNet-101-DCN
anchor-free center-based:
GA-RPN 
trainval35k
FoveaBox 
trainval35k
ResNeXt-101
trainval35k
ResNeXt-64x4d-101
trainval35k
ResNeXt-64x4d-101
trainval35k
ResNet-101
trainval35k
ResNeXt-32x8d-101
trainval35k
ResNeXt-64x4d-101
trainval35k
ResNet-101-DCN
trainval35k
ResNeXt-32x8d-101-DCN
trainval35k
ResNeXt-64x4d-101-DCN
ATSS (Multi-scale testing)
trainval35k
ResNeXt-32x8d-101-DCN
ATSS (Multi-scale testing)
trainval35k
ResNeXt-64x4d-101-DCN
5. Conclusion
In this work, we point out that the essential difference between one-stage anchor-based and center-based anchor-free
detectors is actually the deﬁnition of positive and negative
training samples. It indicates that how to select positive and
negative samples during object detection training is critical.
Inspired by that, we delve into this basic issue and propose
the adaptive training sample selection, which automatically
divides positive and negative training samples according to
statistical characteristics of object, hence bridging the gap
between anchor-based and anchor-free detectors. We also
discuss the necessity of tiling multiple anchors per location
and show that it may not be a so useful operation under current situations. Extensive experiments on the challenging
benchmarks MS COCO illustrate that the proposed method
can achieve state-of-the-art performances without introducing any additional overhead.
Acknowledgments
This work has been partially supported by the Chinese
National Natural Science Foundation Projects #61872367,
#61876178, #61806196, #61806203, #61976229.