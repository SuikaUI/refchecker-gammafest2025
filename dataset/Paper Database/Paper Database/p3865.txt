InfoMax-GAN: Improved Adversarial Image Generation via
Information Maximization and Contrastive Learning
Kwot Sin Lee1,2
Ngoc-Trung Tran3
Ngai-Man Cheung3
1University of Cambridge
2Snap Inc.
3Singapore University of Technology and Design
While Generative Adversarial Networks (GANs) are fundamental to many generative modelling applications, they
suffer from numerous issues. In this work, we propose a principled framework to simultaneously mitigate two fundamental issues in GANs: catastrophic forgetting of the discriminator and mode collapse of the generator. We achieve this by
employing for GANs a contrastive learning and mutual information maximization approach, and perform extensive analyses to understand sources of improvements. Our approach
signiï¬cantly stabilizes GAN training and improves GAN performance for image synthesis across ï¬ve datasets under the
same training and evaluation conditions against state-of-theart works. In particular, compared to the state-of-the-art SS-
GAN, our approach does not suffer from poorer performance
on image domains such as faces, and instead improves performance signiï¬cantly. Our approach is simple to implement
and practical: it involves only one auxiliary objective, has a
low computational cost, and performs robustly across a wide
range of training settings and datasets without any hyperparameter tuning. For reproducibility, our code is available in
Mimicry : 
1. Introduction
The ï¬eld of generative modelling has witnessed incredible successes since the advent of Generative Adversarial Networks (GANs) , a form of generative model known for
its sampling efï¬ciency in generating high-ï¬delity data .
In its original formulation, a GAN is composed of two models - a generator and a discriminator - which together play
an adversarial minimax game that enables the generator to
model the true data distribution of some empirical data. This
adversarial game is encapsulated by the following equation:
D V (D, G) = Exâˆ¼pr(x)[log D(x)]
+ Ezâˆ¼p(z)[log(1 âˆ’D(G(z)))]
where V is the value function, p(z) is a prior noise distribution, pr(x) is the real data distribution, and G(z) is the
generated data from sampling some random noise z.
In this formulation, training the discriminator and generator with their respective minimax loss functions aims
to minimize the Jensen-Shannon (JS) divergence between
the real and generated data distributions pr and pg respectively. However, GAN training is notoriously difï¬cult.
Firstly, such theoretical guarantees only come under the
assumption of the discriminator being trained to optimality , which may lead to saturating gradients in practice.
Even so, there is no guarantee for convergence in this minimax game as both generator and discriminator are simultaneously and independently ï¬nding a Nash equilibrium in a
high-dimensional space. Finally, GANs face the perennial
problem of mode collapse, where pg collapses to only cover
a few modes of pr, resulting in generated samples of limited
diversity. Consequently, recent years have seen concerted
efforts to mitigate these issues.
A primary cause of GAN training instability is the nonstationary nature of the training environment: as the generator learns, the modeled distribution pg the discriminator
faces is ever changing. As our GAN models are neural
networks, the discriminator is susceptible to catastrophic forgetting , a situation where the network learns
ad-hoc representations and forgets about prior tasks to focus
on the current one as the weights of the network updates,
which contributes to training instability. The state-of-the-art
Self-supervised GAN (SSGAN) is the ï¬rst to demonstrate that a representation learning approach could mitigate
discriminator catastrophic forgetting, thus improving training stability. However, the approach still does not explicitly
mitigate mode collapse, and has a failure mode in image domains such as faces . Furthermore, shows that while
SSGANâ€™s approach is helpful for discriminator forgetting, it
in fact promotes mode collapse for the generator.
To overcome these problems, we present an approach
to simultaneously mitigate both catastrophic forgetting and
mode collapse. On the discriminator side, we apply mutual
information maximization to improve long-term representation learning, thereby reducing catastrophic forgetting in the
non-stationary training environment. On the generator side,
 
we employ contrastive learning to incentivize the generator
to produce diverse images that give easily distinguishable
positive/negative samples, hence reducing mode collapse.
Through mitigating both issues, we show a wide range of
practical improvements on natural image synthesis using
GANs. We summarize our contributions below:
â€¢ We present a GAN framework to improve natural image synthesis through simultaneously mitigating two
key GAN issues using just one objective: catastrophic
forgetting of the discriminator (via information maximization) and mode collapse of the generator (via contrastive learning). Our approach mitigates issues in both
discriminator and generator, rather than either alone.
â€¢ With this multi-faceted approach, we signiï¬cantly
improve GAN image synthesis across ï¬ve different
datasets against state-of-the-art works under the same
training and evaluation conditions.
â€¢ Our framework is lightweight and practical: it introduces just one auxiliary objective, has a low computational cost, and is robust against a wide range of training
settings without any tuning required.
â€¢ Our work is the ï¬rst to demonstrate the effectiveness of
contrastive learning for signiï¬cantly improving GAN
performance, and also the ï¬rst to apply the InfoMax
principle in a GAN setting, which we hope would open
a new research direction in these areas.
2. Background
Mutual information and representation learning
Mutual information has deep connections with representation
learning , where we aim to learn an encoder function E
that ideally captures the most important features of the input data X, often at a lower dimensional latent space. This
concept is encapsulated by the InfoMax objective :
EâˆˆE I(X; E(X))
where E is some function class, and the objective is to ï¬nd
some E that maximizes the mutual information between the
input data and its encoded representations E(X). To maximize on the InfoMax objective, one could alternatively maximize I(CÏˆ(X); EÏˆ(X)), where CÏˆ and EÏˆ are encoders
part of the same architecture parameterised by Ïˆ. It is shown
in maximizing I(CÏˆ(X); EÏˆ(X)) is maximizing on a
lower bound of the InfoMax objective:
I(CÏˆ(X); EÏˆ(X)) â‰¤I(X; (CÏˆ(X), EÏˆ(X)))
In practice, maximizing I(CÏˆ(X); EÏˆ(X)) has several
advantages: (a) Using different feature encodings allow us
to capture different views and modalities of the data for
ï¬‚exibility of modelling ; (b) The encoded data lies in a
much lower dimensional latent space than that of the original
data, thus reducing computational constraints .
Contrastive learning
Recently, state-of-the-art works in
unsupervised representation learning 
lies in taking a contrastive approach to maximizing the mutual information between encoded local and global features.
Yet, since directly maximizing mutual information is often
intractable in practice , these works often maximize on
the InfoNCE lower bound instead, which involves a
contrastive loss minimized through having a critic ï¬nd positive samples in contrast to a set of negative samples. Such
positive/negative samples are arbitrarily created by pairing
features , augmentation , or a combination of both .
Our work similarly maximizes on this InfoNCE bound, and
most closely follows the Deep InfoMax approach of
obtaining local and global features for the maximization.
3. InfoMax-GAN
3.1. Approach
Figure 1 illustrates the InfoMax-GAN framework. Firstly,
to maximize on the lower bound of the InfoMax objective,
I(CÏˆ(X); EÏˆ(X)), we set EÏˆ to represent layers of the discriminator leading to the global features, and CÏˆ as layers
leading to the local features. Here, CÏˆ = CÏˆ,1 â—¦... â—¦CÏˆ,n is
a series of n intermediate discriminator layers leading to the
last local feature map CÏˆ(x) and fÏˆ is the subsequent layer
transforming CÏˆ(x) to a global feature vector EÏˆ(x), which
is ultimately used for computing the GAN objective Lgan.
We set the local and global feature as the penultimate and ï¬nal feature outputs of the discriminator encoder respectively,
and we study its ablation impact in Appendix A.5.
Next, the local/global features CÏˆ(x) and EÏˆ(x) extracted from the discriminator are passed to the critic networks Ï†Î¸ and Ï†Ï‰ to be projected to a higher dimension
Reproducing Kernel Hilbert Space (RKHS) , which exploits the value of linear evaluation in capturing similarities
between the global and local features. These projected features then undergo a Contrastive Pairing phase to create positive/negative samples, where given some image x, a positive
sample is created by pairing the (projected) global feature
vector Ï†Ï‰(EÏˆ(x)) with a (projected) local spatial vector
Ïˆ (x)) from the imageâ€™s own (projected) local feature
map Ï†Î¸(CÏˆ(x)), where i âˆˆA = {0, 1, ..., M 2 âˆ’1} is an
index to the M Ã— M local feature map. Doing so, we represent a positive sample as the pair (Ï†Î¸(C(i)
Ïˆ (x)), Ï†Ï‰(EÏˆ(x)))
for some i. For each of such positive sample, negative
samples are obtained by sampling local spatial vectors
from the projected local feature map of another image xâ€²
in the same mini-batch, and are represented as the pairs
Ïˆ (xâ€²)), Ï†Ï‰(EÏˆ(x))). Intuitively, this step constrains
the discriminator to produce global features of some image
that maximizes mutual information with the local features
of the same image, rather than those from other images.
Taking this further, consider for each positive sample, the
ContrastivePairing
LocalFeatures
ğœ™ğœƒ(CÏˆ(ğ‘¥â€²))
LocalFeatures
GlobalFeatures
Discriminator
PositiveSample
NegativeSample
Figure 1: Illustration of the InfoMax-GAN framework. An image x is sampled from the real data distribution pr or fake
data distribution pg as modeled by the generator G. Image x passes through a discriminator encoder EÏˆ = fÏˆ â—¦CÏˆ, where
CÏˆ = CÏˆ,1 â—¦... â—¦CÏˆ,n is a series of n intermediate discriminator layers leading to the last local feature map CÏˆ(x) and fÏˆ
transforms CÏˆ(x) to a global feature vector EÏˆ(x), which is subsequently used to compute the GAN objective Lgan. The local
and global features CÏˆ(x) and EÏˆ(x) are then projected to a higher dimension by the spectral normalized critic networks Ï†Î¸
and Ï†Ï‰ respectively. Finally, the resulting features undergo a Contrastive Pairing phase involving local features from another
image xâ€², to produce positive and negative samples for computing the contrastive loss Lnce.
pairs (Ï†Î¸(C(j)
Ïˆ (x)), Ï†Ï‰(EÏˆ(x))), j âˆˆA, j Ì¸= i as negative
samples. That is, using spatial vectors from the same local
feature map to create negative samples. Doing so, we regularize the learnt representations to avoid trivial solutions
to the mutual information maximization objective, since the
global features are constrained to have consistently high
mutual information with all spatial vectors of its own local
feature map, rather than from only some. This effectively
aggregates all local information of the image to represent it.
Thus, for N images in a mini-batch, we produce positive/negative samples to perform an NM 2 way classiï¬cation for each positive sample. Through this approach, it is
shown in one maximizes the InfoNCE lower bound
of the mutual information I(CÏˆ(X); EÏˆ(X)). Formally,
for a set of N random images X = {x1, ..., xN} and set
A = {0, 1, ..., M 2 âˆ’1} representing indices of a M Ã— M
spatial sized local feature map, the contrastive loss is:
Lnce(X) = âˆ’ExâˆˆXEiâˆˆA
log p(C(i)
Ïˆ (x), EÏˆ(x) | X)
= âˆ’ExâˆˆXEiâˆˆA [âˆ†]
exp(gÎ¸,Ï‰(C(i)
Ïˆ (x), EÏˆ(x)))
(xâ€²,i)âˆˆXÃ—A exp(gÎ¸,Ï‰(C(i)
Ïˆ (xâ€²), EÏˆ(x)))
where gÎ¸,Ï‰ : R1Ã—1Ã—K Ã— R1Ã—1Ã—K â†’R is a critic mapping
the local/global features with K dimensions to a scalar score.
Formally, we deï¬ne gÎ¸,Ï‰ to be:
Ïˆ (x), EÏˆ(x)) = Ï†Î¸(C(i)
Ïˆ (x))T Ï†Ï‰(EÏˆ(x))
where Ï†Î¸ : RMÃ—MÃ—K â†’RMÃ—MÃ—R and Ï†Ï‰ : R1Ã—1Ã—K â†’
R1Ã—1Ã—R are the critic networks parameterized by Î¸ and Ï‰
respectively, projecting the local and global features to the
higher RKHS. In practice, Ï†Î¸ and Ï†Ï‰ are deï¬ned as shallow
networks with only 1 hidden layer following , but with
spectral normalized weights as well. These shallow networks
serve to only project the feature dimensions of the input
features, and preserve their original spatial sizes.
To stabilize training, we constrain the discriminator to
learn from only the contrastive loss of real image features,
and similarly for the generator, from only the contrastive
loss of fake image features. We formulate the losses for
discriminator and generator LD and LG as such:
LG = Lgan( Ë†D, G) + Î±Lnce(Xg)
LD = Lgan(D, Ë†G) + Î²Lnce(Xr)
where Î± and Î² are hyperparameters; Ë†D and Ë†G represent a
ï¬xed discriminator and generator respectively; Xr and Xg
Iterations
Figure 2: Accuracy of a classiï¬er when trained on the onevs-all CIFAR-10 classiï¬cation task. Regularized with the
InfoMax objective by minimizing (4), the classiï¬er successfully predicts classes trained from previous iterations even
when the underlying class distribution changes.
represent sets of real and generated images respectively; and
Lgan is the hinge loss for GANs :
Lgan(D, Ë†G) = Exâˆ¼pr[min(0, 1 âˆ’D(x))]
+ Ezâˆ¼pz[min(0, 1 + D( Ë†G(z)))]
Lgan( Ë†D, G) = âˆ’Ezâˆ¼pz[ Ë†D(G(z))]
In practice, we set Î± = Î² = 0.2 for all experiments for
simplicity, with ablation studies to show our approach is
robust across a wide range of Î± and Î² values.
3.2. Mitigating Catastrophic Forgetting
Our approach mitigates a key issue in GANs: catastrophic
forgetting of the discriminator, a situation where due to the
non-stationary GAN training environment, the discriminator
learns only ad-hoc representations and forget about prior
tasks it was trained on. For instance, while the discriminator
may learn to penalize ï¬‚aws in global structures early in GAN
training , it may later forget these relevant representations in order to learn those for ï¬nding detailed ï¬‚aws in local
structures, which overall contributes to training instability.
Inspired by , we examine the ability of our approach
in mitigating catastrophic forgetting: we train a discriminator classiï¬er on the one-vs-all CIFAR-10 classiï¬cation task
where the underlying class distribution changes every 1K iterations, and the cycle repeats every 10K iterations. As seen
in Figure 2, without the InfoMax objective, the classiï¬er
overï¬ts to a certain class distribution and produces very low
accuracy when the class distribution is changed. When training is regularized with the InfoMax objective, the classiï¬er
successfully remembers all prior classes it was trained on.
Thus, the InfoMax objective helps the discriminator to reduce catastrophic forgetting and adapt to the non-stationary
nature of the generated image distribution, which ultimately
stabilizes GAN training.
Iterations
InfoNCE Accuracy
No Mode Collapse
Partial Mode Collapse
Total Mode Collapse
Iterations
InfoNCE Accuracy
No Mode Collapse
Figure 3: Contrastive task accuracy when simulating generators exhibiting a range of mode collapse behaviours using
CIFAR-10 data. (a) We show that the less mode collapsed
a generator is, the better the accuracy for contrastive task.
(b) The contrastive task accuracy is consistently lower when
the generator has partially mode collapsed to any individual
class, compared to when there is no mode collapse.
3.3. Mitigating Mode Collapse
Our approach also mitigates a persistent problem of the
generator: mode collapse. For a fully mode collapsed generator, we have x = xâ€² âˆ€x, xâ€² âˆ¼Xg, where Xg is a set
of randomly generated images, such that CÏˆ(x) = CÏˆ(xâ€²).
This means the term p(C(i)
Ïˆ (x), EÏˆ(x) | Xg) approaches 0
in the limit, rather than the optimal value 1, as the critics
cannot distinguish apart the multiple identical feature pairs
from individual images.
To validate this, we show there is a direct correlation
between the diversity of generated images and the contrastive
learning task accuracy p(C(i)
Ïˆ (x), EÏˆ(x) | X). We train the
discriminator to solve the contrastive task using CIFAR-10
training data, and simulate 3 different kinds of generators
using CIFAR-10 test data: (a) a perfect generator with no
mode collapse that generates all classes of images; (b) a
partially mode collapsed generator that only generates one
class of images and (c) a totally mode collapsed generator
that only generates one image.
From Figure 3a, we observe a perfect generator with no
mode collapse best solves the contrastive task, and a partially mode collapsed generator has a consistently poorer
accuracy in the contrastive task than the perfect generator.
This concurs with our expectation: images from only one
class exhibit a much lower diversity than images from all
classes, and so distinguishing positive samples amongst similar and harder negative samples makes the contrastive task
much harder. Furthermore, for a totally mode collapsed
generator which only generates one image, the accuracy is
near zero, which conï¬rms our initial hypothesis. For any N
images, there are NM 2 samples to classify in the contrastive
task, with NM 2 âˆ’1 negative samples for each positive sample. However, if all N images are identical due to total mode
collapse, then there exists N âˆ’1 negative samples identical
to each positive sample, which makes the contrastive task
nearly impossible to solve. Thus, to solve the contrastive
task well, the generator is highly encouraged to generate
images with greater diversity, which reduces mode collapse.
Furthermore, in Figure 3b, the performance of any class
demonstrating partial mode collapse is consistently worse
than the case of no mode collapse, where all classes of images are used. Thus, the generator is incentivized to not
collapse to producing just any one class that fools the discriminator easily, since producing all classes of images naturally leads to the best performance in the contrastive task.
4. Experiments
4.1. Experimental Settings
GAN architectures
We compare our model with the baseline Spectral Normalization GAN (SNGAN) and the
state-of-the-art Self-supervised GAN (SSGAN) . For
clarity, we highlight InfoMax-GAN is equivalent to SNGAN
with our proposed objective, and SSGAN is equivalent to
SNGAN with the rotation task objective. We show InfoMax-
GAN alone performs highly competitively, with signiï¬cant
improvements over SSGAN. We detail the exact architectures used for all models and datasets in Appendix C.
We experiment on ï¬ve different datasets at multiple resolutions: ImageNet (128 Ã— 128) , CelebA
(128Ã—128) , CIFAR-10 (32Ã—32) , STL-10 (48Ã—48)
 , and CIFAR-100 (32 Ã— 32) . The details for these
datasets can be found in Appendix A.1.
We train all models using the same Residual
Network backbone, under the exact same settings for
each dataset, and using the same code base, for fairness
in comparisons. For details, refer to Appendix A.2. For
all models and datasets, we set Î± = Î² = 0.2, to balance
the contrastive loss to be on the same scale as the GAN loss
initially. This scaling principle is similar to what is applied in
 , and we later show in our ablation study our framework
is highly robust to changes in these hyperparameters.
Evaluation
To assess the generated images quality, we
employ three different metrics: FrÃ©chet Inception Distance
(FID) , Kernel Inception Distance (KID) , and Inception Score (IS) . In general, FID and KID measure the
diversity of generated images, and IS measures the quality
of generated images. Here, we emphasize we use the exact
same number of real and fake samples for evaluation, so
that we can compare the scores fairly. This is crucial, especially since metrics like FID can produce highly biased
estimates , where using a larger sample size leads to a
signiï¬cantly lower score. Finally, for all our scores, we
compute them using 3 different random seeds to report their
mean and standard deviation. A detailed explanation of all
three metrics and the sample sizes used can be found in
Appendix A.3
4.2. Results
Improved image synthesis
As seen in Table 1, InfoMax-
GAN improves FID consistently and signiï¬cantly across
many datasets over SNGAN and SSGAN. On the challenging
high resolution ImageNet dataset, InfoMax-GAN improves
by 6.8 points over SNGAN, and 3.6 points over SSGAN.
On the high resolution CelebA, while SSGAN could not
improve over the baseline SNGAN, as similarly noted in
 , InfoMax-GAN improves by 3.4 points over SNGAN,
and 5.8 points over SSGAN. This suggests our approach is
versatile and can generalise across multiple data domains.
On STL-10, InfoMax-GAN achieves an improvement
of 3.0 points over SNGAN and 1.5 points over SSGAN.
Interestingly, while InfoMax-GAN performs similarly as
SSGAN on CIFAR-10 with around 0.5 points difference, it
improves FID by 3.4 points on CIFAR-100 when the number
of classes increase. We conjecture this is due to the tendency
for SSGAN to generate easily rotated images , which
sacriï¬ces diversity and reduces FID when there are more
classes. This observation also supports InfoMax-GANâ€™s
larger improvements on ImageNet, which has 1000 classes.
Similarly, for alternative metrics like KID and IS,
InfoMax-GAN achieves a highly competitive performance
and improves over the state-of-the-art works.
InfoMax-GAN improves from 0.2 to 0.4 points over SS-
GAN for all datasets except CIFAR-10, where the margin is
less than 0.1 points and within the standard deviation, indicating a similar performance. Similar to its FID performance
on CelebA, SSGAN also performs worse in terms of IS compared to the baseline SNGAN, suggesting its failure mode
on faces is not just due to a limited diversity, but also due to
poorer quality. In contrast, InfoMax-GAN improves on IS
over SNGAN and SSGAN signiï¬cantly. Finally, on KID, we
conï¬rm our result on FID: where FID is better, KID is also
Resolution
InfoMax-GAN
65.74 Â± 0.31
62.48 Â± 0.31
58.91 Â± 0.14
14.04 Â± 0.02
16.39 Â± 0.09
10.63 Â± 0.04
40.48 Â± 0.07
38.97 Â± 0.23
37.49 Â± 0.05
24.76 Â± 0.16
24.64 Â± 0.16
21.22 Â± 0.26
18.63 Â± 0.22
16.59 Â± 0.13
17.14 Â± 0.20
0.0663 Â± 0.0004
0.0616 Â± 0.0004
0.0579 Â± 0.0004
0.0076 Â± 0.0001
0.0101 Â± 0.0001
0.0063 Â± 0.0001
0.0369 Â± 0.0002
0.0332 Â± 0.0004
0.0326 Â± 0.0002
0.0156 Â± 0.0003
0.0161 Â± 0.0002
0.0135 Â± 0.0004
0.0125 Â± 0.0001
0.0101 Â± 0.0002
0.0112 Â± 0.0001
13.05 Â± 0.05
13.30 Â± 0.03
13.68 Â± 0.06
2.72 Â± 0.01
2.63 Â± 0.01
2.84 Â± 0.01
8.04 Â± 0.07
8.25 Â± 0.06
8.54 Â± 0.12
7.57 Â± 0.11
7.56 Â± 0.07
7.86 Â± 0.10
7.97 Â± 0.06
8.17 Â± 0.06
8.08 Â± 0.08
Table 1: Mean FID, KID and IS scores of all models across different datasets, computed across 3 different seeds. FID and
KID: lower is better. IS: higher is better.
Resolution
SSGAN + IM
62.48 Â± 0.31
56.45 Â± 0.29
16.39 Â± 0.09
11.93 Â± 0.14
38.97 Â± 0.23
37.73 Â± 0.06
24.64 Â± 0.16
21.40 Â± 0.20
16.59 Â± 0.13
15.42 Â± 0.08
Table 2: Mean FID scores (lower is better) of SSGAN before
and after applying our method: â€œ+ IMâ€ refers to adding our
proposed InfoMax-GAN objective.
better. This further substantiates our FID results and how
InfoMax-GAN generates more diverse images across these
datasets, with no obvious failure modes unlike in SSGAN.
Orthogonal improvements
In Table 2, we show our improvements are orthogonal to those in SSGAN: when adding
our objective into SSGAN, FID improves across all datasets
signiï¬cantly, achieving even larger improvements of approximately 2.5 points for the challenging ImageNet dataset.
Thus, our method is ï¬‚exible and can be easily integrated into
existing state-of-the-art works like SSGAN.
Improved training stability
Similar to , we test training stability through evaluating the sensitivity of model performance when hyperparameters are varied across a range
of popular settings for training GANs, such as the Adam
parameters (Î²1, Î²2) and number of discriminator steps per
generator step, ndis, all chosen from well-tested settings in
seminal GAN works . As seen in Table 3,
in comparison to SNGAN at the same architectural capacity, InfoMax-GAN consistently improves FID for different
datasets even in instances where GAN training does not
converge (e.g. when ndis = 1). The FID score variability
for InfoMax-GAN is much lower than SNGAN, showing
its robustness to changes in training hyperparameters. Finally, while different sets of (Î²1, Î²2) work better for each
dataset, our method stabilizes training and obtain signiï¬cant
improvements in all these settings, without any hyperparameter tuning. This can be useful in practice when training new
GANs or on novel datasets, where training can be highly
unstable when other hyperparameters are not well-tuned.
In Figure 4, we show our method stabilizes GAN training
by allowing GAN training to converge faster and consistently
improve performance throughout training. We attribute this
to an additional constraint where the global features are constrained to have high mutual information with all their local
features , thereby constraining the space of generated
data distribution and causing pg to change less radically and
ultimately stabilizing the GAN training environment. This
is a practical beneï¬t when training GANs given a ï¬xed computational budget, since signiï¬cant improvements can be
gained early during training.
Low computational cost
In practice, our method takes
only a fraction of the training time. Similar to , we
proï¬le the training time for 100 generator update steps. In
Figure 5, we see our approach takes minimal time at less
than 0.1% of training time per update, across all ndis for
both CIFAR-10 and STL-10. This is since in practice, only
InfoMax-GAN
InfoMax-GAN
164.74 Â± 0.42
24.42 Â± 0.18
267.10 Â± 0.20
54.29 Â± 0.13
20.87 Â± 0.19
18.08 Â± 0.27
46.65 Â± 0.18
38.96 Â± 0.31
18.63 Â± 0.22
17.14 Â± 0.20
40.48 Â± 0.07
37.49 Â± 0.05
73.07 Â± 0.20
20.58 Â± 0.10
134.51 Â± 0.37
62.28 Â± 0.07
18.74 Â± 0.24
17.19 Â± 0.32
40.67 Â± 0.29
40.54 Â± 0.20
21.10 Â± 0.89
18.39 Â± 0.04
84.20 Â± 0.67
75.72 Â± 0.19
Table 3: Mean FID scores (lower is better) across a range of hyperparameter settings. (Î²1, Î²2) represents the hyperparameters
of the Adam optimizer, and ndis represents the number of discriminator steps per generator step. Our method performs robustly
in a wide range of training settings without any tuning.
Iterations
InfoMax-GAN
Iterations
InfoMax-GAN
Iterations
InfoMax-GAN
Iterations
InfoMax-GAN
Iterations
InfoMax-GAN
Figure 4: Our approach stabilizes GAN training signiï¬cantly, converges faster and consistently improves FID for all models
across all datasets. Left to right: ImageNet, CelebA, CIFAR-10, CIFAR-100, STL-10.
InfoMax-GAN
(a) CIFAR-10
InfoMax-GAN
(b) STL-10
Figure 5: Training time for 100 generator update steps across
different ndis values for CIFAR-10 and STL-10, using the
same hardware. In general, our proposed framework incurs
signiï¬cantly less time than the overall training cost.
2 shallow (1 hidden layer) MLP networks are needed to
compute the contrastive loss. Furthermore, from Table 3,
at ndis = 2, InfoMax-GAN has a consistently better FID
than SNGAN at ndis = 5 at approximately half the training
time, since a large ndis is a signiï¬cant bottleneck in training
time. Thus, our approach is practical for training GANs at a
ï¬xed computational budget, and has minimal computational
Improved mode recovery
In Appendix A.4, we demonstrate our approach helps to signiï¬cantly recover more modes
in the Stacked MNIST dataset .
Relative Size
17.07 Â± 0.25
17.21 Â± 0.15
17.14 Â± 0.20
17.80 Â± 0.05
17.38 Â± 0.11
Table 4: Mean FID scores (lower is better) for InfoMax-
GAN on CIFAR-10 when the RKHS dimension R is varied.
Relative size here refers to how much larger R is relative
to the discriminator feature map depth of 128, in terms of
multiplicative factor.
Qualitative comparisons
In Appendix A.6, we show generated images with improved image quality against those
from other models for all datasets.
4.3. Ablation Studies
RKHS dimensions
As seen in Table 4, our proposed
framework is robust to the choice of R, with the FID remaining consistent in their range of values. We attribute
this to how the InfoMax critics are simple MLP networks
with only 1 hidden layer, which is sufï¬cient for achieving
good representations in practice . We note for all our
experiments in Tables 1, 2, and 3, we used R = 1024.
Sensitivity of Î± and Î² hyperparameters
In Figure 6a,
we performed a large sweep of Î± and Î² from 0.0 to 1.0,
Iterations
Iterations
= 0.0, = 0.2
= 0.1, = 0.2
= 0.2, = 0.0
= 0.2, = 0.1
Figure 6: (a) CIFAR-10 FID curves for InfoMax-GAN
across a large sweep of Î± and Î² hyperparameters, showing Î± = Î² = 0.2 performs the best. (b) We perform a small
sweep around the chosen hyperparameters Î± = Î² = 0.2.
and see Î± = Î² = 0.2 obtains the best performance for our
method. From Figure 6b, we see our InfoMax objective for
the discriminator is important for improving GAN performance: as Î² is decreased, keeping Î± = 0.2, FID deteriorates.
Interestingly, when Î± = 0 and Î² = 0.2, having the InfoMax
objective for the discriminator alone is sufï¬cient in gaining
FID improvements. This conï¬rms our intuition of the role of
information maximization in mitigating discriminator catastrophic forgetting to stabilize the GAN training environment
and improve FID. However, the performance improves when
the generator is also trained on the InfoMax objective, at
Î± âˆˆ{0.1, 0.2} and Î² = 0.2, which afï¬rms our prior intuition that the contrastive nature of the objective helps the
generator reduce mode collapse and improve FID. We note
apart from this ablation study, we used Î± = Î² = 0.2 for all
experiments reported in this paper.
Further studies
We include three further ablation studies
on our design choices in Appendix A.5 to demonstrate the
strength of our approach and justify our design choices.
5. Related Work
Mode collapse and catastrophic forgetting
Early works
in reducing mode collapse include Unrolled GAN ,
which restructures the generator objective with respect to
unrolled discriminator optimization updates. These works
often focused on assessing the number of modes recovered
by a GAN based on synthetic datasets . Subsequent
works include MSGAN , which introduces a regularization encouraging conditional GANs to seek out minor modes
often missed when training. These works instead focus on
direct metrics for assessing the diversity
and quality of generated images. In our work, we utilized
both types of metrics for assessment. Previous approaches to
mitigate catastrophic forgetting in GANs include using forms
of memory , such as checkpoint averaging. 
demonstrates the mitigation of catastrophic forgetting using
a representation learning approach, which we built upon.
Representation learning and GANs
To the best of our
knowledge, the closest work in methodology to ours is the
state-of-the-art SSGAN, which demonstrates the use of a
representation learning approach of predicting rotations 
to mitigate GAN forgetting and hence improve GAN performance. In contrast to SSGAN, our work uses a contrastive
learning and information maximization task instead, which
we demonstrate to simultaneously mitigate both GAN forgetting and mode collapse. Furthermore, our work overcomes
failure modes demonstrated in SSGAN, such as in datasets
involving faces . For fair and accurate comparisons, our
work compared with SSGAN using the exact same architectural capacity, training and evaluation settings.
Information theory and GANs
The most prominent
work in utilizing mutual information maximization for
GANs is InfoGAN, but we emphasize here that our work
has a different focus: while InfoGAN focuses on learning
disentangled representations, our goal is to improve image
synthesis. For clarity, we illustrate the speciï¬c differences
with InfoGAN in Appendix B. Other approaches employing
information-theoretic principles include Variational GAN
(VGAN) , which uses an information bottleneck to
regularize the discriminator representations; with 
extending to minimise divergences apart from the original JS
divergence. In contrast to these works, our work employs the
InfoMax principle to improve discriminator learning and provides a clear connection to how this improves GAN training
via the mitigation of catastrophic forgetting.
6. Conclusion and Future Work
In this paper, we presented the InfoMax-GAN framework
for improving natural image synthesis through simultaneously alleviating two key issues in GANs: catastrophic forgetting of the discriminator (via information maximization),
and mode collapse of the generator (via contrastive learning).
Our approach signiï¬cantly improves on the natural image
synthesis task for ï¬ve widely used datasets, and further overcome failure modes in state-of-the-art models like SSGAN.
Our approach is simple and practical: it has only one auxiliary objective, performs robustly in a wide range of training
settings without any hyperparameter tuning, has a low computational cost, and demonstrated improvements even when
integrated to existing state-of-the-art models like SSGAN.
As future work, it would be interesting to explore this framework for different tasks, such as in 3D view synthesis, where
one could formulate objectives involving mutual information
and adjacent views. To the best of our knowledge, our work
is the ï¬rst to investigate using information maximization and
contrastive learning to improve GAN image synthesis performance, and we hope our work opens up new possibilities
in this direction.