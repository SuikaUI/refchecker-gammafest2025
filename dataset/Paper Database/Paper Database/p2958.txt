Growing Self-Organizing Maps for Data
Soledad Delgado
Technical University of Madrid, Spain
Consuelo Gonzalo
Technical University of Madrid, Spain
Estíbaliz Martínez
Technical University of Madrid, Spain
Águeda Arquero
Technical University of Madrid, Spain
INTRODUCTION
Currently, there exist many research áreas that produce
large multivariable datasets that are difficultto visualize
in order to extract useful information. Kohonen selforganizing maps have been used successfully in the
visualization and analysis of multidimensional data.
In this work, a projection technique that compresses
multidimensional datasets into two dimensional space
using growing self-organizing maps is described. With
this embedding scheme, traditional Kohonen visualization methods have been implemented using growing
cell structures networks. New graphical map displays
have been compared with Kohonen graphs using two
groups of simulated data and one group of real multidimensional data selected firom a satellite scene.
BACKGROUND
Data mining first stage usually consist of building
simplified global overviews of data sets, generally in
graphical form . At present, the huge
amount of information and its multidimensional
nature complicates the possibility to employ direct
graphic representation techniques. Self-Organizing
Maps fit well in the exploratory data
analysis since its principal purpose is the visualization
and the analysis of nonlinear relations between multidimensional data . In this sense, a great
variety of Kohonen's SOM visualization techniques
 , and some automatic
map analysis (Franzmeier, Witkowski &Rückert2005)
have been proposed.
In Kohonen's SOM the network structure has to
be specified in advance and remains static during the
training process. The choice of an inappropriate network
structure can degrade the performance of the network.
Some growing self-organizing maps have been implemented to avoidthis disadvantage. In ,
Fritzke proposed the Growing Cell Structures (GCS)
model, with a fixed dimensionality associated to the
output map. In , the Growing Neural
Gas is exposed, a new SOM model that learns topology
relations. Eventhoughthe GNG networks getbest grade
of topology preservationthan GCS networks, due to the
multidimensional nature of the output map it cannot be
used to genérate graphical map displays in the plañe.
However, using the GCS model it is possible to créate
networks with a fixed dimensionality lower or equal
than 3 that can be projected in a plañe .
GCS model, without removal of cells, has been used to
compress biomedical multidimensional data sets to be
displayed as two-dimensional colour images .
GROWING CELL STRUCTURES
VISUALIZATION
This work studies the GCS networks to obtain an embedding method to project the bi-dimensional output
map, with the aim of generating several graphic map
displays for the exploratory data analysis during and
after the self-organization process.
Growing Cell Structures
The visualization methods presented in this work are
based on self-organizing map architecture and learning
process of Fritzke's Growing Cell Structures (GCS)
network . GCS network architecture
consists of connected units forming k-dimensional
hypertetrahedron structures linked between them.
The interconnection scheme defines the neighbourhood relationships. During the learning process, new
units are added and superfluous ones are removed, but
these modifications are performed in such way thatthe
original architecture structure is maintained.
The training algorithm is an iterative process that
performs a non-linear projection of the input data over
the output map, trying to preserve the topology of the
original data distribution. The self-organization process of the GCS networks is similar that in Kohonen's
model. For each input signal the best matching unit
{bmu) is determined, and bmu and its direct neighbour's
synaptic vectors are modified. In GCS networks each
neuron has associated a resource, which can represent
the number of input signáis received by the neuron, or
the summed quantization error caused by the neuron.
In every adaptation step the resource of the bmu is
conveniently modified. A new neuron is inserted between the unit with highest resource, q, and its direct
neighbour with the most different reference vector,/
after a fixed number of adaptation steps. The new unit
synaptic vector is interpolated firom the synaptic vectors of q and/ and the resources valúes of q and/are
redistributed too. In addition, neighbouring connections
are modified in order to ensure the output architecture
structure. Once all the training vectors have been processed a fixed number of times (epoch), the neurons
whose reference vectors fall into regions with a very
low probability density are removed. To guarantee the
architecture structure some neighbouring connections
are modified too. Relative normalized probability
density estimation valué proposed in 
has been used in this work to determine the units to
be removed. This valué provides better interpretation
of some training parameters, improving the removal
of cells and the topology preserving of the network.
Several separated meshes could appear in the output
map when superfluous units are removed.
When the growing self-organization process finishes, the synaptic vectors of the output units along with
the neighbouring connections can be used to analyze
different input space properties visually.
Network Visualization: Constructing the
Topographic Map
The ability to project high-dimensional input data
onto a low-dimensional grid is an important property
of Kohonen feature maps. By drawing the output map
over a plañe it will be possible to visualize complex
data and discover properties or relations of the input
vector space not expected in advance. Output layer of
Kohonen feature maps can be printed on a plañe easily,
painting a rectangular grid, where each cell represents
an output neuron and neighbour cells correspond to
neighbour output units.
GCS networks have less regular output unit connections than Kohonen ones. When k=2 architecture factor
is used, the GCS output layer is organized in groups
of interconnectedtriangles. In spite ofbi-dimensional
nature of these meshes, it is not obvious how to embed
this structure into the plañe in order to visualize it. In
 , Fritzke proposed a physical model to
construct the bi-dimensional embedding during the
self-organization process of the GCS network. Each
output neuron is modelled by a disc, with diameter d,
made of elastic material. Two discs with distance d
between centres touch each other, and two discs with
distance smaller than d repeal each other. Each neighbourhood connection is modelled as an elastic string.
Two discs connected but not touching are pulled each
other. Finally, all discs are positively charged and repeal each other. Using this model, the bi-dimensional
topographic coordinates of each output neuron can be
obtained, and thus, the bi-dimensional output meshes
can be printed on a plañe.
In order to obtain the output units bi-dimensional
coordinates of the topographic map (for k=2), a slightly
modified versión of this physical model has been used
in this contribution. At the beginning of the training
process, the initial three output neurons are placed in
the plañe in a triangle form. Each time a new neuron
is inserted, its position in the plañe is located exactly
halfway of the position of the two neighbouring neurons
between whichithas been inserted. Afterthis, attraction
and repulsión forces are calculated for every output
neuron and its positions are consequently moved. The
attraction forcé of a unit is calculated as the sum of
individual attraction forces that all neighbouring connections exercise over it. Attraction forcé between two
neighbouring neurons i andj, with/? and/? coordinates
in the plañe, and Euclidean distance e, is calculated as
(e-d)!2 iíe>d, and 0 otherwise. The repelling forcé of
a unit is calculated as the sum of individual repulsión
forces that all no-neighbouring outputneurons exercise
over it. Repelling forcé between two no-neighbouring
neurons i and j is calculated as di5 if2d<e<3d, d/2 if
d<e<2d,dií0<e<d, and 0 otherwise. There existthree
basic differences between the embedding model used
inthis work and the Fritzke's one. First, repelling forcé
is only calculated with no-neighbouring units. Second,
attracting forcé between two neurons i and 7 is multiplied by the distance normalization ((p.-p)/e) and by
the attraction factor 0.1 (instead of 1). Last, repelling
forcé between two neurons i and 7 is multiplied by the
distance normalization {(p-p)le) and by the repulsión
factor 0.05 (instead of 0.2). '
The result of applying this projection method is
showed in Fig. 1. When removal of cells is performed,
different meshes are showed unconnectedly. Without
any other additional information, this proj ection method
makes possible cluster detection.
Visualization Methods
Using the projection method exposed, traditional Kohonen visualization methods can be implemented using
GCS networks with k=2. Each output neuron is painted
as a circle in a colour determined by a maj or parameter.
When greyscale is used, normally dark and clear tones
are associated with high and low valúes respectively.
The grey scales are relative to the máximum and minimum valúes taken by the parameter. The nature of the
data used to calcúlate the parameter determines three
general types of methods for performing visual analysis
of self-organizing maps: distances between synaptic
vectors, training patterns projection over the neurons,
and individual information about synaptic vectors.
All the experiments have been performed using
two groups of simulated data and one group of real
multidimensional data (Fig. 2) selected firom a scene
registered by the ETM+ sensor (Landsat 7). The input
signáis are defined by the six ETM+ spectral bands with
Figure 1. Output mesh projection during different self-organization process stages ofa GCS network trained
with bi-dimensional vectors distributed on eleven sepárate regions.
Figure 2. (a) Eleven sepárate regions in the bi-dimensional plañe, (b) Two three dimensional chain-link. (c)
Projection of multidimensional data ofsatellite image.
^SE';:/ .'|3fe
the same spatial resolution: TM1 to TM5, and TM7.
The input data set has a total number of 1800 pixels.
1500 carefully chosen from the original scene and 300
randomly selected. The input vectors are associated to
six land cover categories.
Displaying Distances
The adaptation process of GCS networks places the
synaptic vectors in regions with high probability density, removing units positioned into regions with a very
low probability density. A graphical representation of
distances between the synaptic vectors will be auseful
tool to detect clusters over the input space. Distance
map, unified distance map (U-map), and distance addition map have been implemented to represent distance
map information with GCS networks.
In distance map, the mean distance between the
synaptic vector of each neuron and the synaptic vectors of all its direct neighbours is calculated. U-map
represents the same information than distance map
but, in addition it includes the distance between all the
neighbouring neurons (painted in a circle form between
each pair of neighbour units). Finally, the sum of the
distance between the synaptic vector of a neuron and
the synaptic vectors of the rest of units is calculated,
when distance addition map is generated. In distance
map and U-map, dark zones represent clusters and clear
zones boundaries along with them. In distance addition map, neurons with near synaptic vectors appear
with similar colour, and boundaries can be detected
analyzing the regions where a considerable colour
variationexists. Using GCS networks, separatedmeshes
represent different input clusters, usually. Fig. 3 shows
an example of these three graphs, compared with the
traditional Kohonen's maps, when an eleven sepárate
regions distribution data set is used. GCS network
represents eleven clusters in the three graphs, clearly.
Distance map and U-map in Kohonen's network show
the eleven clusters too, but in distance addition map it
is not possible to distinguish them.
Displaying Projections
This technique takes into account the input distribution patterns to genérate different valúes to assign to
each neuron. For GCS networks, data histograms and
quantization error maps have been implemented.
Generating the histogram, the number of training
patterns associated to each neuron is obtained. However,
when quantization error graph has to be produced, the
sum of the distances between the synaptic vector of a
neuron and the input vectors that lies in its Voronoi región is calculated. In both graphs, dark and clear zones
correspond with high and low probability density áreas,
respectively, so it can be used in cluster analysis. Fig. 4
shows an example of these two methods compared with
those obtained using Kohonen's model when chain-link
distribution data set is used. Using Kohonen's model is
difficult to distinguish the number of clusters present
in the input space. On the other hand, GCS model has
generated three output meshes, two of them representing one ring.
Figure 3. From left to right: distance map, U-map (unified distance map), and distance addition map when an
eleven sepárate regions distribution data set is used. (a) Kohonen feature map with 10x10 grid of neurons. (b)
GCS network with 100 output neurons. The right column shows the input data and the networkprojection using
the two component valúes ofthe synaptic vectors.
Displaying Components
The displaying components technique analyzes each
synaptic vector or reference vector component in an
individual manner. This kind of graphs offers a visual
analysis of the topology preserving of the network, and
a possible detection of correlations and dependences
betweentraining data components. Direct visualization
of synaptic vectors and component planes graphs have
been implemented for GCS networks.
Direct visualization map represents each neuron
in a circle form within its synaptic vector inside in a
graphical manner. This graph can be complementedwith
anyone of described in the previous sections, enriching
its interpretation. A component plañe map visualizes an
individual component of all the synaptic vectors.
When all the component planes are generated, relations between weights can be appreciated if similar
structures appear in identical places of two different
componentplanes. Fig. 5 shows anexampleof mese two
displaying methods when multi-band data of satellite
image is used. The direct visualization map shows the
similarity between neighbouring units synaptic vectors,
and, it is interesting distinguish the fact that all the
neurons in a cluster have similar synaptic shapes. Furthermore, the integratedinformationaboutthe distance
addition map shows that there is no significant colour
variation inside the same cluster. The six component
Figure 4. From left to right: Unified distance map, data histograms and quantization error maps when chain-link
distribution data set is used. (a) Kohonen feature map with 10x10 grid of neurons. (b) GCS network with 100
output neurons. The right column shows the input data and the network projection using the three component
valúes ofthe synaptic vectors.
Figure 5. GCS network trainedwith multidimensional data of satellite image, 54 output neurons. Graphs from
(a) to (f) show the component planes for the six elements ofthe synaptic vectors. (g) Direct visualization map
using distance addition map additional information.
plañe graphs exhibit possible dependences involving
TM1, TM2 and TM3 input vector components and.
TM5 and TM7 components too.
Several Kohonen and GCS networks have beentrained
in order to evalúate and compare the resulting visualization graphs. For the sake of space only a few of these
maps have been includedhere. Fig. 3 and Fig. 4 compare
Kohonen and GCS visualizations using distance map,
U-map, distance addition map, data histograms and
quantization error map. It can be observed that GCS
model offers much better graphical results in clusters
analysis than Kohonen networks. The removal of
units and connections inside low probability distribution áreas causes that GCS network presents within a
particular cluster the same quality of information that
Kohonen network in relation to the entire map. Since
it has already been mentioned, the grey scale used in
all the maps is relative to the máximum and minimum
valúes taken by the studied parameter. In all the cases
the range of valúes taken by the calculated factor using
GCS is minor than using Kohonen maps.
The exposed visualization methods applied to the
visual analysis of multidimensional satellite data has
given very satisfactory results (Fig 5). All trained GCS
networks have been able to genérate six sub maps in
the output layer (in some case they have arrived up to
eight) that identify the six land cover classes present
in the sample of data. The direct visualization map
and the component plañe graphs have demonstrated
to be a useful tool for the extraction of knowledge of
the multisensorial data.
FUTURE TRENDS
The proposed knowledge visualization method based
on GCS networks has results a useful tool for multidimensional data analysis. In order to evalúate the
quality of the trained networks we consider necessary
to develop some measure techniques (qualitative and
quantitative in numerical and graphical format) to
analyze the topology preservation obtained. In this way
we will be able to validate the information visualized
by the methods presented in this paper.
Also it would be interesting to validate these methods of visualisation with new data sets of very high
dimensional nature. We need to study the viability of
cluster analysis with this projection technique when
this class of data samples is used.
CONCLUSIÓN
The exposed embedding method allows multidimensional data to be displayed as two-dimensional grey
images. The visual-spatial abilities of human observers
can explore these graphical maps to extract interrelations and characteristics in the dataset.
In GCS model the networks size does not have to
be specified in advance. During the training process,
the size of the network grows and decreases adapting
its architecture to the particular characteristics of the
training dataset.
Although in GCS networks it is necessary to determine a greatnumber of training factorsthan in Kohonen
model, using the learning modified model the tuning of
the training factors valúes is simplified. In fact, several
experiments have been made on datasets of diverse
nature using the same valúes for all the training factors
and giving excellent results in all the cases.
Especially notable isthe clusterdetection during the
self-organization process without any other additional
information.