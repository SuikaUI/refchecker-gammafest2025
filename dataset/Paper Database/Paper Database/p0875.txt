HAL Id: hal-01142656
 
Submitted on 15 Apr 2015
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of scientific research documents, whether they are published or not.
The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
EpicFlow: Edge-Preserving Interpolation of
Correspondences for Optical Flow
Jerome Revaud, Philippe Weinzaepfel, Zaid Harchaoui, Cordelia Schmid
To cite this version:
Jerome Revaud, Philippe Weinzaepfel, Zaid Harchaoui, Cordelia Schmid. EpicFlow: Edge-Preserving
Interpolation of Correspondences for Optical Flow. CVPR - IEEE Conference on Computer Vision &
Pattern Recognition, Jun 2015, Boston, United States. pp.1164-1172, ￿10.1109/CVPR.2015.7298720￿.
￿hal-01142656￿
EpicFlow: Edge-Preserving Interpolation of Correspondences for Optical Flow
Jerome Revauda
Philippe Weinzaepfela
Zaid Harchaouia,b
Cordelia Schmida
 
We propose a novel approach for optical ﬂow estimation, targeted at large displacements with signiﬁcant occlusions. It consists of two steps: i) dense matching by
edge-preserving interpolation from a sparse set of matches;
ii) variational energy minimization initialized with the
dense matches.
The sparse-to-dense interpolation relies
on an appropriate choice of the distance, namely an edgeaware geodesic distance. This distance is tailored to handle occlusions and motion boundaries – two common and
difﬁcult issues for optical ﬂow computation. We also propose an approximation scheme for the geodesic distance to
allow fast computation without loss of performance. Subsequent to the dense interpolation step, standard one-level
variational energy minimization is carried out on the dense
matches to obtain the ﬁnal ﬂow estimation. The proposed
approach, called Edge-Preserving Interpolation of Correspondences (EpicFlow) is fast and robust to large displacements. It signiﬁcantly outperforms the state of the art on
MPI-Sintel and performs on par on Kitti and Middlebury.
1. Introduction
Accurate estimation of optical ﬂow from real-world
videos remains a challenging problem , despite the
abundant literature on the topic. The main remaining challenges are occlusions, motion discontinuities and large displacements, all present in real-world videos.
Effective approaches were previously proposed for handling the case of small displacements (i.e., less than a few
pixels) .
These approaches cast the optical
ﬂow problem into an energy minimization framework, often solved using efﬁcient coarse-to-ﬁne algorithms .
However, due to the complexity of the minimization, such
methods get stuck in local minima and may fail to estimate large displacements, which often occur due to fast
motion. This problem has recently received signiﬁcant attention. State-of-the-art approaches use descriptor
matching between adjacent frames together with the inte-
∗LEAR team, Inria Grenoble Rhone-Alpes, Laboratoire Jean Kuntzmann, CNRS, Univ. Grenoble Alpes, France.
Figure 1. Image edges detected with SED and ground-truth
optical ﬂow. Motion discontinuities appear most of the time at
image edges.
gration of these matches in a variational approach. Indeed,
matching operators are robust to large displacements and
motion discontinuities . Energy minimization is carried out in a coarse-to-ﬁne scheme in order to obtain a fullscale dense ﬂow ﬁeld guided by the matches. A major drawback of coarse-to-ﬁne schemes is error-propagation, i.e.,
errors at coarser levels, where different motion layers can
overlap, can propagate across scales. Even if coarse-to-ﬁne
techniques work well in most cases, we are not aware of a
theoretical guarantee or proof of convergence.
Instead, we propose to simply interpolate a sparse set of
matches in a dense manner to initiate the optical ﬂow estimation. We then use this estimate to initialize a one-level
energy minimization, and obtain the ﬁnal optical ﬂow estimation. This enables us to leverage recent advances in
matching algorithms, which can now output quasi-dense
correspondence ﬁelds . In the same spirit as ,
we perform a sparse-to-dense interpolation by ﬁtting a local
afﬁne model at each pixel based on nearby matches. A major issue arises for the preservation of motion boundaries.
We make the following observation: motion boundaries often tend to appear at image edges, see Figure 1.
Consequently, we propose to exchange the Euclidean distance
with a better, i.e., edge-aware, distance and show that this
offers a natural way to handle motion discontinuities. Moreover, we show how an approximation of the edge-aware distance allows to ﬁt only one afﬁne model per input match (instead of one per pixel). This leads to an important speed-up
of the interpolation scheme without loss in performance.
The obtained interpolated ﬁeld of correspondences is
sufﬁciently accurate to be used as initialization of a
one-level energy minimization.
Our work suggests that
there may be better initialization strategies than the well-
Coarsest level
Coarsest level
Flow estimate at coarsest level
Flow estimate at coarsest level
Original frame
Original frame
Flow estimate after coarse-to-fine
Flow estimate after coarse-to-fine
Ground-truth flow
Ground-truth flow
Figure 2. Comparison of coarse-to-ﬁne ﬂow estimation and
EpicFlow. Errors at the coarsest level of estimation, due to a low
resolution, often get propagated to the ﬁnest level (right, top and
middle). In contrast, our interpolation scheme beneﬁts from an
edge prior at the ﬁnest level (right, bottom).
established coarse-to-ﬁne scheme, see Figure 2. In particular, our approach, EpicFlow (edge-preserving interpolation
of correspondences) performs best on the challenging MPI-
Sintel dataset and is competitive on Kitti and Middlebury . An overview of EpicFlow is given in Figure 3.
To summarize, we make three main contributions:
• We propose EpicFlow, a novel sparse-to-dense interpolation scheme of matches based on an edge-aware distance.
We show that it is robust to motion boundaries, occlusions
and large displacements.
• We propose an approximation scheme for the edge-aware
distance, leading to a signiﬁcant speed-up without loss of
• We show empirically that the proposed optical ﬂow estimation scheme is more accurate than estimations based on
coarse-to-ﬁne minimization.
This paper is organized as follows. In Section 2, we
review related work on large displacement optical ﬂow.
We then present the sparse-to-dense interpolation in Section 3 and the energy minimization for optical ﬂow computation in Section 4. Finally, Section 5 presents experimental results. Source code is available online at http:
//lear.inrialpes.fr/software.
2. Related Work
Most optical ﬂow approaches are based on a variational
formulation and a related energy minimization problem . The minimization is carried out using a coarse-to-
ﬁne scheme . While such schemes are attractive from
a computational point of view, the minimization often gets
stuck in local minima and leads to error accumulation across
scales, especially in the case of large displacements .
To tackle this issue, the addition of descriptor/matching
was recently investigated in several papers. A penalization
Minimization
First Image
Second Image
Interpolation
Figure 3. Overview of EpicFlow. Given two images, we compute
matches using DeepMatching and the edges of the ﬁrst image
using SED . We combine these two cues to densely interpolate
matches and obtain a dense correspondence ﬁeld. This is used as
initialization of a one-level energy minimization framework.
of the difference between ﬂow and HOG matches was added
to the energy by Brox and Malik . Weinzaepfel et al. 
replaced the HOG matches by an approach based on similarities of non-rigid patches: DeepMatching. Xu et al. 
merged the estimated ﬂow with matching candidates at each
level of the coarse-to-ﬁne scheme. Braux-Zin et al. used
segment features in addition to keypoints. However, these
methods rely on a coarse-to-ﬁne scheme, that suffers from
intrinsic ﬂaws. Namely, details are lost at coarse scales, and
thin objects with substantially different motions cannot be
detected. Those errors correspond to local minima, hence
they cannot be recovered and are propagated across levels,
see Figure 2.
In contrast, our approach is conceptually closer to recent
work that rely mainly on descriptor matching . Lu et al. propose a variant of Patch-
Match , which uses SLIC superpixels as basic blocks
in order to better respect image boundaries. The purpose
is to produce a nearest-neighbor-ﬁeld (NNF) which is later
translated into a ﬂow. However, SLIC superpixels are only
locally aware of image edges, whereas our edge-aware distance is able to capture regions at the image scale. Similarly, Chen et al. propose to compute an approximate
NNF, and then estimate the dominant motion patterns using RANSAC. They, then, use a multi-label graph-cut to
solve the assignment of each pixel to a motion pattern candidate. Their multi-label optimization can be interpreted as
a motion segmentation problem or as a layered model .
These problems are hard and a small error in the assignment
can lead to large errors in the resulting ﬂow.
In the same spirit as our approach, Ren proposes
to use edge-based afﬁnities to group pixels and estimate
a piece-wise afﬁne ﬂow.
Nevertheless, this work relies
on a discretization of the optical ﬂow constraint, which
is valid only for small displacements. Closely related to
EpicFlow, Leordeanu et al. also investigate sparseto-dense interpolation. Their initial matching is obtained
through the costly minimization of a global non-convex
matching energy. In contrast, we directly use state-of-theart matches as input. Furthermore, during their
sparse-to-dense interpolation, they compute an afﬁne transformation independently for each pixel based on its neighborhood matches, which are found in a Euclidean ball and
weighted by an estimation of occluded areas that involves
learning a binary classiﬁer. In contrast, we propose to use an
edge-preserving distance that naturally handles occlusions,
and can be very efﬁciently computed.
3. Sparse-to-dense interpolation
3.1. Interpolation method
We propose to estimate a dense correspondence ﬁeld F :
I →I′ between two images I and I′ by interpolating a
given set of inputs matches M = {(pm, p′
m)}. Each match
m) ∈M deﬁnes a correspondence between a pixel
pm ∈I and a pixel p′
m ∈I′. The interpolation requires a
distance D : I × I →R+ between pixels, see Section 3.2.
We consider here two options for the interpolation.
• Nadaraya-Watson (NW) estimation .
The correspondence ﬁeld FNW (p) is interpolated using the
Nadaraya-Watson estimator at a pixel p ∈I and is expressed by a sum of matches weighted by their proximity
(pm,p′m)∈M
kD(pm, p)p′
(pm,p′m)∈M
where kD(pm, p) = exp (−aD(pm, p)) is a Gaussian kernel for a distance D with a parameter a.
• Locally-weighted afﬁne (LA) estimation . The second estimator is based on ﬁtting a local afﬁne transformation. The correspondence ﬁeld FLA(p) is interpolated using a locally-weighted afﬁne estimator at a pixel p ∈I as
FLA(p) = App + t⊤
p , where Ap and tp are the parameters of an afﬁne transformation estimated for pixel p. These
parameters are computed as the least-square solution of an
overdetermined system obtained by writing two equations
for each match (pm, p′
m) ∈M weighted as previously:
 Appm + t⊤
Local interpolation.
Note that the inﬂuence of remote
matches is either negligible, or could harm the interpolation, for example when objects move differently. Therefore,
we restrict the set of matches used in the interpolation at a
pixel p to its K nearest neighbors according to the distance
D, which we denote as NK(p). In other words, we replace
the summation over M in the NW operator by a summation
over NK(p), and likewise for building the overdetermined
system to ﬁt the afﬁne transformation for FLA.
3.2. Edge-preserving distance
Using the Euclidean distance for the interpolation presented above is possible. However, in this case the interpolation is simply based on the position of the input matches
and does not respect motion boundaries. Suppose for a moment that the motion boundaries are known. We can, then,
use a geodesic distance DG based on these motion boundaries. The geodesic distance between two pixels p and q is
deﬁned as the shortest distance with respect to a cost map
DG(p, q) =
C(ps)dps ,
where Pp,q denotes the set of all possible paths between p
and q, and C(ps) the cost of crossing pixel ps (the viscosity in physics). In our settings, C corresponds to the motion
boundaries. Hence, a pixel belonging to a motion layer is
close to all other pixels from the same layer according to
DG, but far from everything beyond the boundaries. Since
each pixel is interpolated based on its neighbors, the interpolation will respect the motion boundaries.
In practice, we use an alternative to true motion boundaries, making the plausible assumption that image edges are
a superset of motion boundaries. This way, the distance between pixels belonging to the same region will be low. It ensures a proper edge-respecting interpolation as long as the
number of matches in each region is sufﬁcient. Similarly,
Criminisi et al. showed that geodesic distances are a
natural tool for edge-preserving image editing operations
(denoising, texture ﬂattening, etc.) and it was also used recently to generate object proposals . In practice, we set
the cost map C using a recent state-of-the-art edge detector,
namely the “structured edge detector” (SED) 1. Figure 4 shows an example of a SED map, as well as examples
of geodesic distances and neighbor sets NK(p) for different pixels p. Notice how neighbors are found on the same
objects/parts of the image with DG, in contrast to Euclidean
distance (see also Figure 6).
3.3. Fast approximation
The geodesic distance can be rapidly computed from a
point to all other pixels. For instance, Weber et al. propose parallel algorithms that simulate an advancing wavefront. Nevertheless, the computational cost for computing
the geodesic distance between all pixels and all matches (as
required by our interpolation scheme) is high. We now propose an efﬁcient approximation ˜DG.
A key observation is that neighboring pixels are often interpolated similarly, suggesting a strategy that would leverage such local information. In this section we employ the
term “match” to refer to pm instead of (pm, p′
Geodesic Voronoi diagram. We ﬁrst deﬁne a clustering
L, such that L(p) assigns a pixel p to its closest match
according to the geodesic distance, i.e., we have L(p) =
argminpm DG(p, pm). L deﬁnes geodesic Voronoi cells,
as shown in Figure 5(c).
1 
Figure 4. (a-b) two consecutive frames; (c) contour response C from SED (the darker, the higher); (d) match positions {pm} from
DeepMatching ; (e-f) geodesic distance from a pixel p (marked in blue) to all others DG(p, .) (the brighter, the closer). (g-h) 100
nearest matches, i.e., N100(p) (red) using geodesic distance DG from the pixel p in blue.
Figure 5. For the region shown in (a), (b) shows the image edges
C and white crosses representing the match positions {pm}. (c)
displays the assignment L, i.e., geodesic Voronoi cells. We build a
graph G from L (see text). (d) shows the shortest path between two
neighbor matches, which can go through the edge that connects
them (3-4) or a shorter path found by Dijkstra’s algorithm (1-2).
Approximated geodesic distance. We then approximate
the distance between a pixel p and any match pm as the
distance to the closest match L(p) plus an approximate distance between matches:
˜DG(p, pm) = DG(p, L(p)) + DG
G(L(p), pm)
G is a graph-based approximation of the geodesic
distance between two matches.
To deﬁne DG
a neighborhood graph G whose nodes are {pm}.
matches pm and pn are connected by an edge if they are
neighbors in L. The edge weight is then deﬁned as the
geodesic distance between pm and pn, where the geodesic
distance calculation is restricted to the Voronoi cells of pm
and pn. We, then, calculate the approximate geodesic distance between any two matches pm, pn using Dijkstra’s algorithm on G, see Figure 5(d).
Piecewise ﬁeld. So far, we have built an approximation of
the distance between pixels and match points. We now show
that our interpolation model results in a piece-wise correspondence ﬁeld (either constant for the Nadaraya-Watson
estimator, or piece-wise afﬁne for LA). This property is
crucial to obtain a fast interpolation scheme, and experiments shows that it does not impact the accuracy. Let us
consider a pixel p such that L(p) = pm. The distance between p and any match pn is the same as the one between
pm and pn up to a constant independent from pn (Equation 4). As a consequence, we have NK(p) = NK(pm)
DG(p, pn) = kDG(p, pm) × kDG
G(pm, pn). For the
Nadaraya-Watson estimator, we thus obtain:
(pn,p′n) k ˜
DG(p,pn)p′
(pn,p′n) k ˜
kDG(p,pm) P
(pn,p′n) kDG
kDG(p,pm) P
(pn,p′n) kDG
= FNW (pm)
where all the sums are for (pn, p′
n) ∈NK(p) = NK(pm).
The same reasoning holds for the weighted afﬁne interpolator, which is invariant to a multiplication of the weights
by a constant factor. As a consequence, it sufﬁces to compute |M| estimations (one per match) and to propagate it
to the pixel assigned to this match. This is orders of magnitude faster than an independent estimation for each pixel,
e.g. as done in . We summarize the approach in Algorithm 1 for Nadaraya-Watson estimator. The algorithm is
similar for LA interpolator (e.g. line 6 becomes “Estimate
afﬁne parameters Apm, tpm” and line 8 “Set WLA(p) =
AL(p)p + t⊤
Algorithm 1 Interpolation with Nadaraya-Watson
Input: a pair of images I, I′, a set M of matches
Output: dense correspondence ﬁeld FNW
Compute the cost C for I using SED 
Compute the assignment map L
Build the graph G from L
For (pm, p′
Compute NK(pm) from G using Dijkstra’s algorithm
Compute FNW (pm) from NK(pm) using Eq. 1
For each pixel p
Set FNW (p) = FNW (L(p))
4. Optical Flow Estimation
Coarse-to-ﬁne vs. EpicFlow. The output of the sparse-todense interpolation is a dense correspondence ﬁeld. This
ﬁeld is used as initialization of a variational energy minimization method.
In contrast to our approach, state-ofthe-art methods usually rely on a coarse-to-ﬁne scheme to
compute the full-scale correspondence ﬁeld. To the best of
our knowledge, there exists no theoretical proof or guarantee that a coarse-to-ﬁne minimization leads to a consistent
estimation that accurately minimizes the full-scale energy.
Thus, the coarse-to-ﬁne scheme should be considered as a
heuristic to provide an initialization for the full-scale ﬂow.
Our approach can be thought of as an alternative to the
above strategy, by offering a smart heuristic to accurately
initialize the optical ﬂow before performing energy minimization at the full-scale. This offers several advantages
over the coarse-to-ﬁne scheme. First, the cost map C in
our method acts as a prior on boundary location.
a prior could also be incorporated by a local smoothness
weight in the coarse-to-ﬁne minimization, but would then
be difﬁcult to interpret at coarse scales where boundaries
might strongly overlap. In addition, since our method directly works at the full image resolution, it avoids possible
issues related to the presence of thin objects that could be
oversmoothed at coarse scales. Such errors at coarse scales
are propagated to ﬁner scales as the coarse-to-ﬁne approach
proceeds, see Figure 2.
Variational Energy Minimization. We minimize an energy deﬁned as a sum of a data term and a smoothness term.
We use the same data term as , based on a classical
color-constancy and gradient-constancy assumption with a
normalization factor. For the smoothness term, we penalize
the ﬂow gradient norm, with a local smoothness weight α
as in : α(x) = exp
 −κ∥∇2I(x)∥
with κ = 5.
We have also experimented using SED instead and obtained
similar performance.
For minimization, we initialize the solution with the output of our sparse-to-dense interpolation and use the approach of without the coarse-to-ﬁne scheme. More precisely, we perform 5 ﬁxed point iterations, i.e., compute
the non-linear weights (that appear when applying Euler-
Lagrange equations ) and the ﬂow updates 5 times iteratively. The ﬂow updates are computed by solving linear
systems using 30 iterations of the successive over relaxation
method .
5. Experiments
In this section, we evaluate EpicFlow on three state-ofthe-art datasets:
• MPI-Sintel dataset is a challenging evaluation benchmark obtained from an animated movie. It contains multiple
sequences including large/rapid motions. We only use the
“ﬁnal” version that features realistic rendering effects such
as motion, defocus blur and atmospheric effects.
• The Kitti dataset contains photos shot in city streets
from a driving platform. It features large displacements,
different materials (complex 3D objects like trees), a large
variety of lighting conditions and non-lambertian surfaces.
• The Middlebury dataset has been extensively used for
evaluating optical ﬂow methods. It contains complex motions, but displacements are limited to a few pixels.
As in , we optimize the parameters on a subset (20%)
of the MPI-Sintel training set. We then report average endpoint error (AEE) on the remaining MPI-Sintel training set
(80%), the Kitti training set and the Middlebury training
set. This allows us to evaluate the impact of parameters on
different datasets and avoid overﬁtting. The parameters are
typically a ≃1 for the coefﬁcient in the kernel kD, the
number of neighbors is K ≃25 for NW interpolation and
K ≃100 when using LA. In Section 5.4, we compare to
the state of the art on the test sets. In this case, the parameters are optimized on the training set of the corresponding
dataset. Timing is reported for one CPU-core at 3.6GHz.
In the following, we ﬁrst describe two types of input
matches in Section 5.1. Section 5.2 then studies the different parameters of our approach. In Section 5.3, we compare
our method to a variational approach with a coarse-to-ﬁne
scheme. Finally, we show that EpicFlow outperforms current methods on challenging datasets in Section 5.4.
5.1. Input matches
To generate input matches, we use and compare two recent matching algorithms. They each produce about 5000
matches per image.
• The ﬁrst one is DeepMatching (DM), used in Deep-
Flow , which has shown excellent performance for optical ﬂow. It builds correspondences by computing similarities of non-rigid patches, allowing for some deformations.
We use the online code2 on images downscaled by a factor 2. A reciprocal veriﬁcation is included in DM. As a
consequence, the majority of matches in occluded areas are
pruned, see matches in Figure 6 (left).
• The second one is a recent variant of PatchMatch that
relies on kd-trees and local propagation to compute a dense
correspondence ﬁeld (KPM). We use the online code
to extract the dense correspondence ﬁeld3. It is noisy, as
it is based on small patches without global regularization,
as well as often incorrect in case of occlusion. Thus, we
perform a two-way matching and eliminate non-reciprocal
matches to remove incorrect correspondences. We also subsample these pruned correspondences to speed-up the interpolation. We have experimentally veriﬁed on several image
pairs that this does not result in a loss of performance.
Pruning of matches. In both cases, matches are extracted
locally and might be incorrect in regions with low texture.
Thus, we remove matches corresponding to patches with
low saliency, which are determined by the eigenvalues of
autocorrelation matrix. Furthermore, we perform a consistency check to remove outliers. We run the sparse-to-dense
interpolation once with the Nadaraya-Watson estimator and
2 
3 
Figure 6. Left: Match positions returned by are shown in
blue. Red denotes occluded areas. Right: Yellow (resp. blue)
squares correspond to the 100 nearest matches with a Euclidean
(resp. edge-aware geodesic) distance for the occluded pixel shown
Interpolator
MPI-Sintel
Middlebury
Interpolation
Table 1. Comparison of average endpoint error (AEE) for different
sparse matches (DM, KPM) and interpolators (NW, LA) as well
as for sparse-to-dense interpolation (top) and EpicFlow (bottom).
The approximated geodesic distance ˜DG is used.
remove matches for which the difference to the initial estimate is over 5 pixels.
We also experiment with synthetic sparse matches of various densities and noise levels in Section 5.3, in order to
evaluate the sensitivity of EpicFlow to the quality of the
matching approach.
5.2. Impact of the different parameters
In this section, we evaluate the impact of the matches
and the interpolator. We also compare the quality of the
sparse-to-dense interpolation and EpicFlow. Furthermore,
we examime the impact of the geodesic distance, of its approximation and of the quality of the contour detector.
Matches and interpolators. Table 1 compares the result of
our sparse-to-dense interpolation, i.e., before energy minimization, and EpicFlow for different matches (DM and
KPM) and for the two interpolation schemes: Nadaraya-
Watson (NW) and locally-weighted afﬁne (LA). The approximated geodesic distance is used in the interpolation,
see Section 3.3.
We can observe that KPM is consistently outperformed
by DeepMatching (DM) on MPI-Sintel and Kitti datasets,
with a gap of 2 and 8 pixels respectively. Kitti contains
many repetitive textures like trees or roads, which are often
mismatched by KPM. Note that DM is signiﬁcantly more
robust to repetitive textures than KPM, as it uses a multiscale scoring scheme. The results on Middlebury are comparable and below 1 pixel.
We also observe that LA performs better than NW on
Kitti, while the results are comparable on MPI-Sintel and
Middlebury.
This is due to the speciﬁcity of the Kitti
Ground-Truth
Interpolation
DeepFlow 
Figure 7. From top to bottom: ground-truth ﬂow, result of sparseto-dense interpolation (Interpolation), full method (EpicFlow),
and DeepFlow , one of the top performers on MPI-Sintel.
dataset, where the scene consists of planar surfaces and,
thus, afﬁne transformations are more suitable than translations to approximate the ﬂow. Based on these results, we
use DM matches and LA interpolation in the remainder of
the experimental section.
The interpolation is robust to the neighborhood size K
with for instance an AEE of 4.082, 4.053, 4.068 and 4.076
for K = 50, 100, 160 (optimal value on the training set),
200 respectively, on MPI-Sintel with the LA estimator and
before variational minimization. We also implemented a
variant where we use all matches closer than a threshold
and obtained similar performance.
Sparse-to-dense interpolation versus EpicFlow. We also
evaluate the gain due to the variational minimization using
the interpolation as initialization. We can see in Table 1 that
this step clearly improves the performance in all cases. The
improvement is around 0.5 pixel. Figure 7 presents results
for two image pairs with the initialization only and the ﬁnal result of EpicFlow (second and third rows). While the
ﬂow images look similar overall, the minimization allows
to further smooth and reﬁne the ﬂow, explaining the gain in
performance. Yet, it preserves discontinuities and small details, such as the legs in the right column. In the following,
results are reported for EpicFlow, i.e., after the variational
minimization step.
Edge-aware versus Euclidean distances. We now study
the impact of different distances. First, we examine the effect of approximating the geodesic distance (Section 3.3).
Table 2 shows that our approximation has a negligible impact when compared to the exact geodesic distance. Note
that the exact version performs distance computation as well
as local estimation per pixel and is, thus, an order of magnitude slower to compute, see last column of Table 2.
MPI-Sintel
Middlebury
Geodesic (approx.)
Geodesic (exact)
Geodesic (approx.)
Canny 
Geodesic (approx.)
Geodesic (approx.)
GT boundaries
Geodesic (approx.)
Table 2. Comparison of the AEE of EpicFlow (with DM and LA)
for different distances and different contour extractors. The time
(right column) is reported for a MPI-Sintel image pair.
Next, we compare the geodesic distance and Euclidean
distances. Table 2 shows that using a Euclidean distance
leads to a signiﬁcant drop in performance, in particular for
the MPI-Sintel dataset, the drop is 1 pixel. This conﬁrms
the importance of our edge-preserving distance. Note that
the result with the Euclidean distance is reported with an
exact version, i.e., the interpolation is computed pixelwise.
We also compare to a mixed approach, in which the
neighbor list NK is constructed using the Euclidean distance, but weights k ˜
D(pm, p) are set according to the approximate geodesic distance. Table 2 shows that this leads
to a drop of performance by around 0.3 pixels for MPI-
Sintel and Kitti. Figure 6 illustrates the reason: none of the
Euclidean neighbor matches (yellow) belong to the region
corresponding to the selected pixel (red), but all of geodesic
neighbor matches (blue) belong to it. This demonstrates the
importance of using an edge-preserving geodesic distance
throughout the whole pipeline, in contrast to who interpolates matches found in a Euclidean neighborhood.
Impact of contour detector. We also evaluate the impact of
the contour detector in Table 2, i.e., the SED detector 
is replaced by the Berkeley gPb detector or the Canny
edge detector . Using gPb leads to a small drop in performance (around 0.1 pixel on Kitti and 0.5 on MPI-Sintel)
and signiﬁcantly increases the computation time. Canny
edges perform similar to the Euclidean distance. This can
be explained by the insufﬁcient quality of the Canny contours. Using the norm of image’s gradient improves slightly
over gPb. We found that this is due to the presence of holes
when estimating contours with gPb. Finally, we perform experiments using ground-truth motion boundaries, computed
from the norm of ground-truth ﬂow gradient, and obtain an
improvement of 0.1 on MPI-Sintel (0.2 before the variational part). The ground-truth ﬂow is not dense enough on
Middlebury and Kitti datasets to estimate GT boundaries.
5.3. EpicFlow versus coarse-to-ﬁne scheme
To show the beneﬁt of our approach, we have carried
out a comparison with a coarse-to-ﬁne scheme. Our implementation of the variational approach is the same as in
Section 4, with a coarse-to-ﬁne scheme and DeepMatching
integrated in the energy through a penalization of the difference between ﬂow and matches . Table 3 compares
EpicFlow to the variational approach with coarse-to-ﬁne
Flow method
MPI-Sintel
Middlebury
DM+coarse-to-ﬁne
DM+EpicFlow
Table 3. Comparison of AEE for EpicFlow (with DM + LA) and a
coarse-to-ﬁne scheme (with DM).
Matching noise
Matching density
AEE for EpicFlow
Matching noise
Matching density
AEE for coarse-to-fine
Figure 8. Comparison of AEE between EpicFlow (left) and a
coarse-to-ﬁne scheme (right) for various synthetic input matches
with different densities and error levels. For positions above the
red line, EpicFlow performs better.
scheme, using exactly the same matches as input. EpicFlow
performs better and is also faster. The gain is around 0.4
pixel on MPI-Sintel and over 1 pixel on Kitti. The important gain on Kitti might be explained by the afﬁne model
used for interpolation, which ﬁts well the piecewise planar
structure of the scene. On Middlebury, the variational approach achieves slightly better results, as this dataset does
not contain large displacements.
Figure 7 shows a comparison to the state-of-the-art
method, built upon a coarse-to-ﬁne scheme. Note how motion boundaries are preserved by EpicFlow. Even small details, like the limbs in the right column, are captured.
Sensitivity to the matching quality. In order to get a better understanding of why EpicFlow performs better than
a coarse-to-ﬁne scheme, we have evaluated and compared
their performances for different densities and error rates
of the input matches. To that aim, we generated synthetic
matches by taking the ground-truth ﬂow, removing points in
the occluded areas, subsampling to obtain the desired density and corrupting the matches to the desired percentage
of incorrect matches. For each set of matches with a given
density and quality, we have carefully determined the parameters of EpicFlow and the coarse-to-ﬁne method on the
MPI-Sintel training subset, and then evaluated them on the
remaining training images.
Results in term of AEE are given in Figure 8, where density is represented vertically as the ratio of #matches / #nonoccluded pixels and matching error is represented horizontally as the ratio of #false matches / #matches. We can observe that EpicFlow yields better results provided that the
matching is sufﬁciently dense for a given error rate. For
low-density or strongly corrupted matches, EpicFlow yields
unsatisfactory performance (Figure 8 left), while the coarseto-ﬁne method remains relatively robust (Figure 8 right).
This shows that our interpolation-based heuristic for initial-
TF+OFM 
DeepFlow 
S2D-Matching 
Classic+NLP 
MDP-Flow2 
NLTGV-SC 
Table 4. Results on MPI-Sintel test set (ﬁnal version). AEE-occ
is the AEE on occluded areas. s0-10 is the AEE for pixels whose
motions is between 0 and 10 px and similarly for s10-40 and s40+.
NLTGV-SC 
BTF-ILLUM 
TGV2ADCSIFT 
Data-Flow 
DeepFlow 
TF+OFM 
Table 5. Results on Kitti test set.
AEE-noc is the AEE over
non-occluded areas.
Out-Noc 3 (resp. Out-all 3) refers to the
percentage of pixels where ﬂow estimation has an error above 3
pixels in non-occluded areas (resp. all pixels).
izing the ﬂow takes better advantage of the input matches
than a coarse-to-ﬁne schemes for sufﬁciently dense matches
and is able to recover from matching failures. We have indicated the position of DeepMatching and KPM in terms of
density and quality on the plots: they lie inside the area in
which EpicFlow outperforms a coarse-to-ﬁne scheme.
5.4. Comparison with the state of the art
Results on MPI-Sintel test set are given in Table 4.
Parameters are optimized on the MPI-Sintel training set.
EpicFlow outperforms the state of the art with a gap of
0.5 pixel in AEE compared to the second best performing method, TF+OFM , and 1 pixel compared to the
third one, DeepFlow . In particular, we improve for
both AEE on occluded areas and AEE over all pixels and
for all displacement ranges. In addition, our approach is
signiﬁcantly faster than most of the methods, e.g. an order
of magnitude faster than the second best.
Table 5 reports the results on the Kitti test set for methods that do not use epipolar geometry or stereo vision. Parameters are optimized on the Kitti training set. We can
see that EpicFlow performs best in terms of AEE on nonoccluded areas. In term of percentage of erroneous pixels,
our method is competitive with the other algorithms. When
comparing the methods on both Kitti and MPI-Sintel, we
outperform TF+OFM and DeepFlow (second and
third on MPI-Sintel) on the Kitti dataset, in particular for
occluded areas. We perform on par with NLTGV-SC 
on Kitti that we outperform by 2.5 pixels on MPI-Sintel.
On the Middlebury test set, we obtain an AEE below 0.4
pixel. This is competitive with the state of the art. In this
dataset, there are no large displacements, and consequently,
Figure 9. Failure cases of EpicFlow due to missing matches on
spear and horns of the dragon (left column) and missing contours
on the arm (right column).
the beneﬁts of a matching-based approach are limited. Note
that we have slightly increased the number of ﬁxed point
iterations to 25 in the variational method for this dataset
(still using one level) in order to get an additional smoothing effect. This leads to a gain of 0.1 pixels (measured on
the Middlebury training set when setting the parameters on
MPI-Sintel training set).
Timings. EpicFlow runs in 16.4 seconds for a MPI-Sintel
image pair (1024×436 pixels) on one CPU-core at 3.6Ghz.
In detail, computing DeepMatching takes 15s, extracting
SED edges 0.15s, dense interpolation 0.25s, and variational
minimization 1s.
Failure cases. EpicFlow can be incorrect due to errors in
the sparse matches or errors in the contour extraction. Figure 9 (left column) shows an example where matches are
missing on thin elements (spear and horns of the dragon).
Thus, the optical ﬂow takes the value of the surrounding
region for these elements. An example for incorrect contour extraction is presented in Figure 9 (right column). The
contour of the character’s left arm is poorly detected. As a
result, the motion of the arm spreads into the background.
6. Conclusion
This paper introduces EpicFlow, a novel state-of-theart optical ﬂow estimation method.
EpicFlow computes
a dense correspondence ﬁeld by performing a sparse-todense interpolation from an initial sparse set of matches,
leveraging contour cues using an edge-aware geodesic distance. The approach builds upon the assumption that contours often coincide with motion discontinuities. The resulting dense correspondence ﬁeld is fed as an initial optical
ﬂow estimate to a one-level variational energy minimization. Experimental results show that EpicFlow outperforms
current coarse-to-ﬁne approaches. Both the sparse set of
matches and the contour estimates are key to our approach.
Future work will focus on improving these two components
separately as well as in an interleaved manner.
Acknowledgments. This work was supported by the European integrated project AXES, the MSR-Inria joint centre, the LabEx Persyval-Lab (ANR-11-LABX-0025), the
Moore-Sloan Data Science Environment at NYU, and the
ERC advanced grant ALLEGRO.