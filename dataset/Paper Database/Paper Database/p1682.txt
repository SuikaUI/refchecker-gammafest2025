Going Deeper with Contextual CNN for
Hyperspectral Image Classiﬁcation
Hyungtae Lee, Member, IEEE, and Heesung Kwon, Senior Member, IEEE
Abstract—In this paper, we describe a novel deep convolutional
neural network (CNN) that is deeper and wider than other
existing deep networks for hyperspectral image classiﬁcation.
Unlike current state-of-the-art approaches in CNN-based hyperspectral image classiﬁcation, the proposed network, called
contextual deep CNN, can optimally explore local contextual interactions by jointly exploiting local spatio-spectral relationships
of neighboring individual pixel vectors. The joint exploitation
of the spatio-spectral information is achieved by a multi-scale
convolutional ﬁlter bank used as an initial component of the
proposed CNN pipeline. The initial spatial and spectral feature
maps obtained from the multi-scale ﬁlter bank are then combined
together to form a joint spatio-spectral feature map. The joint
feature map representing rich spectral and spatial properties of
the hyperspectral image is then fed through a fully convolutional
network that eventually predicts the corresponding label of each
pixel vector. The proposed approach is tested on three benchmark
datasets: the Indian Pines dataset, the Salinas dataset and the
University of Pavia dataset. Performance comparison shows
enhanced classiﬁcation performance of the proposed approach
over the current state-of-the-art on the three datasets.
Index Terms—Convolutional neural network (CNN), hyperspectral image classiﬁcation, residual learning, multi-scale ﬁlter
bank, fully convolutional network (FCN)
I. INTRODUCTION
ECENTLY, deep convolutional neural networks (DCNN)
have been extensively used for a wide range of visual
perception tasks, such as object detection/classiﬁcation, action/activity recognition, etc. Behind the remarkable success
of DCNN on image/video anlaytics are its unique capabilities
of extracting underlying nonlinear structures of image data as
well as discerning the categories of semantic data contents by
jointly optimizing parameters of multiple layers together.
Lately, there have been increasing efforts to use deep learning based approaches for hyperspectral image (HSI) classiﬁcation – . However, in reality, large scale HSI datasets are
not currently commonly available, which leads to sub-optimal
learning of DCNN with large numbers of parameters due to the
lack of enough training samples. The limited access to large
scale hyperspectral data has been preventing existing CNNbased approaches for HSI classiﬁcation – from leveraging deeper and wider networks that can potentially better
exploit very rich spectral and spatial information contained in
hypersepctral images. Therefore, current state-of-the-art CNNbased approaches mostly focus on using small-scale networks
Manuscript received October 05, 2016; revised April 13, 2017.
Hyungtae Lee is with Booz Allen Hamilton Inc., McLean, VA, 22102 USA
(e-mail: lee ).
Heesung Kwon is with the Image processing branch, the Sensors &
Electron Devices Directorate (SEDD), Army Research Laboratory, Adalphi,
MD, 20783 USA (e-mail: ).
(a) Residual learning
(b) Multi-scale ﬁlter bank
(c) Fully Convolutional Network (FCN)
Fig. 1. Key components of the proposed network.
with relatively fewer numbers of layers and nodes in each
layer at the expense of a decrease in performance. Deeper and
wider mean using relatively larger numbers of layers (depth)
and nodes in each layer (width), respectively. Accordingly,
the reduction of the spectral dimension of the hyperspectral
images is in general initially performed to ﬁt the input data into
the small-scale networks by using techniques, such as principal
component analysis (PCA) , balanced local discriminant
embedding (BLDE) , pairwise constraint discriminant analysis and nonnegative sparse divergence (PCDA-NSD) ,
etc. However, leveraging large-scale networks is still desirable
to jointly exploit underlying nonlinear spectral and spatial
structures of hyperspectral data residing in a high dimensional
feature space. In the proposed work, we aim to build a deeper
and wider network given limited amounts of hypersectral
data that can jointly exploit spectral and spatial information
together. To tackle issues associated with training a large
scale network on limited amounts of data, we leverage a
recently introduced concept of “residual learning”, which has
demonstrated the ability to signiﬁcantly enhance the train
efﬁciency of large scale networks. The residual learning 
basically reformulates the learning of subgroups of layers
called modules in such a way that each module is optimized
by the residual signal, which is the difference between the
desired output and the module input, as shown in Figure 1a.
It is shown that the residual structure of the networks allows
 
for considerable increase in depth and width of the network
leading to enhanced learning and eventually improved generation performance. Therefore, the proposed network does not
require pre-processing of dimensionality reduction of the input
data as opposed to the current state-of-the art techiniques.
To achieve the state-of-the art performance for HSI classi-
ﬁcation, it is essential that spectral and spatial features are
jointly exploited. As can be seen in – , , , the
current state-of-the-art approaches for deep learning based HSI
classiﬁcation fall short of fully exploiting spectral and spatial
information together. The two different types of information,
spectral and spatial, are more or less acquired separately
from pre-processing and then processed together for feature
extraction and classiﬁcation in , . Hu et al. also failed
to jointly process the spectral and spatial information by only
using individual spectral pixel vectors as input to the CNN. In
this paper, inspired by , we propose a novel deep learning
based approach that uses fully convolutional layers (FCN) 
to better exploit spectral and spatial information from hyperspectral data. At the initial stage of the proposed deep CNN,
a multi-scale convolutional ﬁlter bank conceptually similar
to the “inception module” in is simultaneously scanned
through local regions of hyperspectral images generating initial
spatial and spectral feature maps. The multi-scale ﬁlter bank
is basically used to exploit various local spatial structures
as well as local spectral correlations. The initial spatial and
spectral feature maps generated by applying the ﬁlter bank
are then combined together to form a joint spatio-spectral
feature map, which contains rich spatio-spectral characteristics
of hyperspectral pixel vectors. The joint feature map is in turn
used as input to subsequent layers that ﬁnally predict the labels
of the corresponding hyperspectral pixel vectors.
The proposed network1 is an end-to-end network, which is
optimized and tested all together without additional pre- and
post-processing. The proposed network is a fully convolutional
network (FCN) (Figure 1c) to take input hyperspectral
images of arbitrary size and does not use any subsampling
(pooling) layers that would otherwise result in the output
with different size than the input; this means that the network
can process hyperspectral images with arbitrary sizes. In this
work, we evaluate the proposed network on three benchmark
datasets with different sizes (145×145 pixels for the Indian
Pines dataset, 610×340 pixels for the University of Pavia
dataset, and 512×217 for the Salinas dataset). The proposed
network is composed of three key components; a novel fully
convolutional network, a multi-scale ﬁlter bank, and residual
learning as illustrated in Figure 1. Performance comparison
shows enhanced classiﬁcation performance of the proposed
network over the current state-of-the-art on the three datasets.
The main contributions of this paper are as follows:
• We introduce the deeper and wider network with the
help of “residual learning” to overcome sub-optimality
in network performance caused primarily by limited
amounts of training samples.
1A preliminary version of this paper was presented at the 2016 IEEE
International Geoscience and Remote Sensing Symposium .
• We present a novel deep CNN architecture that can
jointly optimize the spectral and spatial information of
hyperspectral images.
• The proposed work is one of the ﬁrst attempts to successfully use a very deep fully convolutional neural network
for hyperspectral classiﬁcation.
The remainder of this paper is organized as follows. In
Section II, related works are described. Details of the proposed
network are explained in Section III. Performance comparisons
among the proposed network and current sate-of-the-art approaches are described in Section IV. The paper is concluded
in Section V.
II. RELATED WORKS
detection/classiﬁcation
LeCun, et al. introduced the ﬁrst deep CNN called LeNet-
5 consisting of two convolutional layers, two fully
connected layers, and one Gaussian connection layer with
additional several layers for pooling. With the recent advent
of large scale image databases and advanced computational
technology, relatively deeper and wider networks, such as
AlexNet , began to be constructed on large scale image
datasets, such as ImageNet . AlexNet used ﬁve convolutional layers with three subsequent fully connected layers.
Simonyan and Zisserman signiﬁcantly increased the depth
of Deep CNN, called VGG-16, with 16 convolutional layers.
Szegedy et al. introduced a 22 layer deep network called
GoogLeNet, by using multi-scale processing, which is realized
by using a concept of “inception module.” He et al. built
a network substantially deeper than those used previously by
using a novel learning approach called “residual learning”,
which can signiﬁcantly improve training efﬁciency of deep
B. Deep CNN for Hyperspectral Image Classiﬁcation
A large number of approaches have been developed to tackle
HSI classiﬁcation problems , – . Recently, kernel
methods, such as multiple kernel learning – , have been
widely used primarily because they can enable a classiﬁer to
learn a complex decision boundary with only a few parameters.
This boundary is built by projecting the data onto a highdimensional reproducing kernel Hilbert space . This makes
it suitable for exploiting dataset with limited training samples.
However, recent advance of deep learning-based approaches
has shown drastic performance improvements because of its
capabilities that can exploit complex local nonlinear structures
of images using many layers of convolutional ﬁlters. To
date, several deep learning-based approaches – have
been developed for HSI classiﬁcation. But few have achieved
breakthrough performance due mainly to sub-optimal learning
caused by the lack of enough training samples and the use of
relatively small scale networks.
Deep learning approaches normally require large scale
datasets whose size should be proportional to the number
of parameters used by the network to avoid overﬁtting in
Fig. 2. AlexNet . The network consists of ﬁve convolutional layers and three fully connected layers. In the illustration, cubes and boxes indicate data
blobs. Several non-linear functions are also used in the network. Non-linear functions are listed beside the output blobs of each layer in order.
learning the network. Chen et al. used stacked autoencoders
(SAE) to learn deep features of hyperspectral signatures in
an unsupervised fashion followed by logistic regression used
to classify extracted deep features into their appropriate material categories. Both a representative spectral pixel vector
and the corresponding spatial vector obtained from applying
principle component analysis (PCA) to hyperspectral data over
the spectral dimension are acquired separately from a local
region and then jointly used as an input to the SAE. In ,
Chen et al. replaced SAE by a deep belief network (DBN),
which is similar to the deep convolutional neural network
for HSI classiﬁcation. Li et al. also used a two-layer
DBN but did not use initial dimensionality reduction, which
would inevitably cause the loss of critical information of
hyperspectral images. Hu et al. fed individual spectral
pixel vectors independently through simple CNN, in which
local convolutional ﬁlters are applied to the spectral vectors
extracting local spectral features. Convolutional feature maps
generated after max pooling are then used as the input to the
fully connected classiﬁcation stage for material classiﬁcation.
Chen et al. also used deep convolutional neural network
adopting ﬁve convolutional layers and one fully connected
layer for hyperspectral classiﬁcation.
Unlike these deep learning-based approaches, we ﬁrst attempt to build much deeper and wider network using relatively small amounts of training samples. Once the network
is effectively optimized, it is expected to provide enhanced
performance over relatively shallow and narrow networks.
III. THE CONTEXTUAL DEEP CONVOLUTIONAL NEURAL
In this section, we ﬁrst describe the widely used CNN
model referred to as AlexNet and then discuss the overall
architecture of the proposed network. We elaborate on the
two key components of the proposed network, “multi-scale
convolutional ﬁlter bank” and “residual learning.” The learning
process of the network is discussed at the end of the section.
A. Deep Convolutional Neural Network
A widely used deep CNN model includes multiple layers of
neurons, each of which extracts a different level of non-linear
features from the input ranging from low to high level features.
Non-linearity in each layer is achieved by applying a nonlinear
activation function to the output of local convoultional ﬁlters in
each layer. The proposed network is basically a convolutional
neural network with a nonlinear activation function used
In this section, we ﬁrst describe the architecture of AlexNet,
a widely used deep CNN model, as shown in Figure 2,
to provide the basis for understanding the architecture of
the proposed network. AlexNet consists of ﬁve convolutional
layers and three fully connected layers. Each fully connected
layer contains linear weights WF C connecting the relationship
between input x and output y:
y = WF C · x,
where x and y represent the input and output vectors. A
convolutional layer with N local ﬁlters, WC,i, i = 1, 2, ..., N,
extracts local nonlinear features from the input and is expressed as:
y = {WC,i ∗x}i=1,2,...,N,
where ∗denotes a convolution. The ﬁlter size of all
{WC,i}i=1,2,...,N is carefully determined to be much smaller
than the size of WF C.
In , several non-linear components, such as the local response normalization (LRN), max pooling, the rectiﬁed linear
unit (ReLU), dropout, and softmax are used. LRN normalizes
each activation ai over local activations of n adjacent ﬁlters
centered on the position (px, py), which aims to generalize
ﬁlter responses,
i (px, py) = ai(px, py)/
aj(px, py)
where k, n, α, and β are hyper-parameters. Max pooling downsamples the output of layers by replacing a sub-region of the
output with the maximum value, which is commonly used
for dimensionality reduction in CNN. ReLU rectiﬁes negative
An illustration of the architecture of the proposed network. The ﬁrst row illustrates input and output blobs of convolutional layers and their
connections. The number of ﬁlters of each convolutional layer is indicated under its output blob. The second row shows a ﬂow chart of the network.
values to zero and is used for the network to learn parameters
with positive activations only. ReLU basically replaces the
sigmoid function commonly used for other neural networks
mainly because learning deep CNN with ReLU is several
times faster than the network with other nonlinear activation
functions such as tanh. Dropout is a function that forces the
output of individual nodes of each layer to be zero with a
probability under a certain threshold, which takes any value
within (0, 1). In this work, we used a threshold of 0.5.
Dropout reduces overﬁtting by preventing multiple adaptations
of training data simultaneously (referred to as “complex coadaptions”). Softmax is a generalization of the logistic function, which is deﬁned as the gradient-log-normalizer of the
categorical probability distribution:
P(y = j|x, {fk}k=1,2,···,K) =
k=1 efk(x) ,
where fj is a classiﬁcation function for a jth class, whose
input and output are x and y, respectively. Therefore, softmax
is useful for probabilistic multiclass classiﬁcation including
HSI classiﬁcation.
B. Architecture of the Proposed Network
We propose a novel fully convolutional network (FCN) 
with a number of convolutional layers for HSI classiﬁcation, as
show in Figure 3. The ﬁrst part of the network is a “multi-scale
ﬁlter bank” followed by two blocks of convolutional layers
associated with residual learning. The last three convolutional
layers function in a similar manner to the fully conected layers
for classiﬁcation of the AlexNet, which performs classiﬁcation
using local features. Similar to AlexNet, the 7th and 8th
convolutional layers have dropout in training. The ReLU is
used after the multi-scale ﬁlter bank, the 2th, 3rd, 5th, 7th,
8th convolutional layers, and two residual learning modules.
vector product
Input (dim: 1x1xd)
Output (dim: 1x1xl)
l Convolutional filters (dim: 1x1xd)
Convolutional layer
Output (dim: 1x1xl)
Input (dim: 1x1xd)
Fully connected layer
Convolutionalized model. For pixel classiﬁcation, a convolutional
layer can achieve the same effect as the fully connected layer with the same
number of weights. In the above illustration, the convolutional layer uses
l convolutional ﬁlters whose dimension is 1 × 1 × d and weights of the
fully connected layer is {wi,j}i=1,···,d,j=1,···,l. Both convolutional layer
and fully connected layer use d × l weights.
The output of the ﬁrst two convolutional layers is normalized
by LRN. Note that the height and width of all data blobs in
the architecture are the same and only their depth changes.
No dimensionality reduction is performed throughout the FCN
processing.
Note that convolving a 1 × 1 × d blob with l ﬁlters
whose size is 1 × 1 × d can achieve the same effect as fully
connecting the 1 × 1 × d input blob to l output nodes, as
illustrated in Figure 4. Due to this “convolutionalized model”,
FCN can be used for pixel classiﬁcation, such as semantic
segmentation, HSI classiﬁcation, etc. Since our network is
based on FCN, the proposed network learns on 5 × 5 pixels
centered on individual pixel vectors and is applied to the
whole image in test.
How Much Deeper Does the Proposed Network Go? The
proposed network contains a total of 9 layers, which is much
deeper than other CNNs for HSI classiﬁcation trained on the
COMPARISON OF NETWORK VARIABLES OF VARIOUS CNNS FOR BOTH
IMAGE AND HSI CLASSIFICATION.
# of Layer
param/data
AlexNet 
VGG16 
GoogLeNet 
ResNet152 
 -Indian Pines
 -Salinas
 -U. of Pavia
The Proposed-Indian Pines
The Proposed-Salinas
The Proposed-U. of Pavia
same datasets . However, the depth of 9 still does not seem
to be large enough, especially when compared to the current
state-of-the-art CNNs for image classiﬁcation, such as ResNet
 . This is mainly because HSI-based CNNs have to be
trained on much smaller amounts of training samples than that
of the image classiﬁcation CNNs primarily trained on large
scale databases, such as ImageNet (1.2 M) . Constrained
by highly limited HSI training data, the proposed going deeper
strategy opts not to use a very large number of layers to
avoid overﬁtting. However, it still uses a much greater number
of layers than that of any other HSI-based CNNs. Table I
shows a comparison of various CNNs for both image and HSI
classiﬁcation with regards to network variables, such as the
number of layers and parameters, training data size, and a
ratio between the number of the parameters and data size.
Similar to data augmentation used in image classiﬁcation
CNNs, the proposed network also uses a data augmentation
strategy described in Section III-E. As shown Table I, the
proposed network provides much larger ratios between the
number of parameters and training data size than those of
the baseline for the same training dataset. Also, the
parameter vs. data ratios of the proposed networks are at
least approximately eight times larger than that of any image
classiﬁcation CNNs. This indicates that the architecture of
the proposed network is designed to ensure that it provides
sufﬁcient depth of layers to fully exploit training data.
C. Multi-scale Filter Bank
The ﬁrst convolutional layer applied to the input hyperspectral image uses a multi-scale ﬁlter bank that locally convolves
the input image with three convolutional ﬁlters with different
sizes (1 × 1 × B, 3 × 3 × B, and 5 × 5 × B where B is the
number of spectral bands). The 3 × 3 × B and 5 × 5 × B
ﬁlters are used to exploit local spatial correlations of the input
image while the 1 × 1 × B ﬁlters are used to address spectral
correlations. The output of the ﬁrst convolutional layer, the
three convolutional feature maps, as shown in Figure 3, are
combined together to form a joint spatio-spectral feature map
used as input to the subsequent convolutional layers.
However, since the size of the feature maps from the three
convolutional ﬁlters is different from each other, a strategy to
adjust the size of the feature maps to be same to combine them
into a joint feature map is needed. First, a space of two-pixel
width ﬁlled with zeros is padded around the input image such
that the size of the feature maps from the 1×1, 3×3, and 5×5
ﬁlters becomes (H +4, W +4), (H +2, W +2), and (H, W),
respectively. H and W are the height and width of the input
image, respectively. The size of all the feature maps becomes
(H, W) after 5 × 5 and 3 × 3 max poolings are applied to the
feature maps from the 1 × 1 and 3 × 3 ﬁlters, respectively.
3 × 3 and 5 × 5 convolutions with a large number of
spectral bands can be expensive and merging of the output
of the convolutional ﬁlter bank causes the size of the
network to increase, which also inevitably leads to high
computational complexity. As the network size is increased,
optimizing the network with a small number of training
samples will face overﬁtting and divergence. Therefore, a
strategy to address the above issues needs to be used. To
tackle the issues, we use training data augmentation and
residual learning modules described in Section III-D and III-E.
Functionality of the Multi-scale Filter Bank. The multi-scale
ﬁlter bank conceptually similar to the inception module in 
is used to optimally exploit diverse local structures of the input
image. demonstrates the effectiveness of the inception
module that enables the network to get deeper as well as to
exploit local structures of the input image achieving state-ofthe-art performance in image classiﬁcation. The multi-scale
ﬁlter bank in the proposed network is used in a somewhat
different manner that aims to jointly exploit local spatial
structures in conjunction with local spectral correlations at the
initial stage of the proposed structure.
D. Residual Learning
The subsequent convolutional layers use 1×1×B ﬁlters to
extract nonlinear features from the joint spatio-spectral feature
map. We use two modules of “residual learning” , which
is shown to help signiﬁcantly improve training efﬁciency of
deep networks. The residual learning is to learn layers with
reference to the layer input using the following formula:
y = F(x, {Wi}) + x,
where x and y are the input and output vectors of the layers
considered, respectively. The function F := y −x is the
residual mapping of the input to the residual output y −x
using convolutional ﬁlters Wi. proved that it is easier
to optimize Wi with the residual mapping than to optimize
those weights with the unreferenced mapping. In the proposed
network, two convolutional layers are used for the residual
mapping, which is called “shortcut connections”. The residual
learning is very effective in practice, which is also proven
in . ReLU is the function that makes the ﬁrst layer in the
module nonlinear. Note that both the multi-scale ﬁlter bank
and the residual learning are effective in increasing the depth
and width of the network while keeping the computational
Training data augmentation
Contextual Deep CNN
Groundtruth
Hyperspectral Image
Fig. 5. The learning process of the proposed network. In the hyperspectral image, 1×1 training pixel and its neighboring 5×5 pixels are indicated by a
red and white rectangle, respectively. In the red box representing augmented training data, 5×5v, 5×5h, and 5×5d are the training samples mirrored across
across the horizontal, vertical, and diagonal axes, respectively.
budget constrained , . This helps to effectively learn
the deep network with a small number of training samples.
E. Learning the Proposed Network
We randomly sample a certain number of pixels from the
hyperspectral image for training and use the rest to evaluate the
performance of the proposed network. For each training pixel,
we crop surrounding 5×5 neighboring pixels for learning
convolutional layers. The proposed network contains approximately 1000K parameters, which are learned from several hundreds of training pixels from each material category. To avoid
overﬁtting, we augment the number of training samples four
times by mirroring the training samples across the horizontal,
vertical, and diagonal axes. Figure 5 illustrates the learning
process of the proposed network.
For learning the proposed network, stochastic gradient
descent (SGD) with a batch size of 10 samples is used
with 100K iterations, a momentum of 0.9, a weight decay
of 0.0005 and a gamma of 0.1. We initially set a base
learning rate as 0.001. The base learning rate is decreased
to 0.0001 after 33,333 iterations and is further reduced to
0.00001 after 66,666 iterations. To learn the network, the last
argmax layer is replaced by a softmax layer commonly used
for learning convolutional layers. The ﬁrst, second, and ninth
convolutional layers are initialized from a zero-mean Gaussian
distribution with standard deviation of 0.01 and the remaining
convolutional layers are initialized with standard deviation of
0.005. Biases of all convolutional layers except the last layer
are initialized to one and the last layer is initialized to zero.
Indian Pines
University of Pavia
Fig. 6. Three HSI datasets. Indian pines, Salinas, and University of Pavia
datasets. For each dataset, three-band color composite image is given on the
left and ground truth is shown on the right. In groundtruth, pixels belonged
to the same class are depicted with the same color.
SELECTED CLASSES FOR EVALUATION AND THE NUMBERS OF TRAINING
AND TEST SAMPLES USED FROM THE INDIAN PINES DATASET
Corn-notill
Corn-mintill
Grass-pasture
Hay-windrowed
Soybean-notill
Soybean-mintill
Soybean-clean
IV. EXPERIMENTAL RESULTS
A. Dataset and Baselines
The performance of HSI classiﬁcation of the proposed
network is evaluated on three datasets: the Indian Pines dataset,
the Salinas dataset, and the University of Pavia dataset, as
shown in Figure 6. The Indian Pines dataset consists of
Corn-notill
Corn-mintill
Grass-pasture
Hay-windrowed
Soybean-notill
Soybean-mintill
Soybean-clean
(a) Indian Pines
Broccoli green weeds 1
Broccoli green weeds 2
Fallow rough plow
Fallow smooth
Corn senesced green weeds
Lettuce romaine, 4 wk
Lettuce romaine, 5 wk
Lettuce romaine, 6 wk
Lettuce romaine, 7 wk
Vineyard vertical trellis
Grapes untrained
Soil vineyard develop
Vineyard untrained
(b) Salinas
(c) University of Pavia
Fig. 7. RGB composition maps of groundtruth (left) of each dataset and the classiﬁcation results (center) from the proposed network for the dataset.
SELECTED CLASSES FOR EVALUATION AND THE NUMBERS OF TRAINING
AND TEST SAMPLES USED FROM THE SALINAS DATASET
Broccoli green weeds 1
Broccoli green weeds 2
Fallow rough plow
Fallow smooth
Grapes untrained
Soil vineyard develop
Corn senesced green weeds
Lettuce romaines, 4 wk
Lettuce romaines, 5 wk
Lettuce romaines, 6 wk
Lettuce romaines, 7 wk
Vineyard untrained
Vineyard vertical trellis
145×145 pixels and 220 spectral reﬂectance bands covering
the range from 0.4 to 2.5 µm with a spatial resolution of 20 m.
The Indian Pines dataset originally has 16 classes but we only
use 8 classes with relatively large numbers of samples. The
Salinas dataset consists of 512×217 pixels and 224 spectral
bands. It contains 16 classes and is characterized by a high
spatial resolution of 3.7 m. The University of Pavia dataset
contains 610×340 pixels with 103 spectral bands covering the
spectral range from 0.43 to 0.86 µm with a spatial resolution
of 1.3 m. 9 classes are in the dataset. For the Salinas dataset
and the University of Pavia dataset, we use all classes because
both datasets do not contain classes with a relatively small
number of samples.
We compare the performance of the proposed network to
the one reported in that used a different deep CNN architecture and RBF kernel-based SVM on the three hyperspectral
datasets. The deep CNN used in consists of two convolutional layers and two fully connected layers, which is much
shallower than our proposed network with nine convolutional
layers. Currently, for the Indian Pines and University of Pavia
SELECTED CLASSES FOR EVALUATION AND THE NUMBERS OF TRAINING
AND TEST SAMPLES USED FROM THE UNIVERSITY OF PAVIA DATASET
Bare soils
datasets, an approach using diversiﬁed Deep Belief Networks
(D-DBN) provides higher HSI classiﬁcation accuracy than
that of the network in . We also use D-DBN as a baseline
in this work. For the Indian Pines dataset, we also use three
types of neural networks evaluated in : a two layer fully
connected neural network (Two-layer NN), a fully connected
neural network with one hidden layer (Three-layer NN), and
the classic LeNet-5 .
For a fair comparison, we randomly select 200 samples from
each class and use them as training samples as in . The rest
are used for testing the proposed network. The selected classes
and the numbers of training and test samples of the three
datasets are listed in Tables II, III, and IV. In the literature
on HSI classiﬁcation, different train/test dataset partitions are
used to evaluate their approaches. Among them, our dataset
partition using 200 training samples has two advantages in
evaluating the proposed network; i) evaluation with this partition can verify our contribution, which is building a deeper
and wider network with a relatively small number of training
samples and ii) using this partition can provide reasonable
performance of relatively good baselines, such as RBF-SVM
and the shallower CNN. For all experiments, we perform the
random train/test partition 20 times and report mean and stand
deviation of overall classiﬁcation accuracy (OA). We have
carried out all the experiments on Caffe framework with
a Titan X GPU.
COMPARISON OF HYPERSPECTRAL CLASSIFICATION PERFORMANCE AMONG THE PROPOSED NETWORK AND THE BASELINES ON THREE DATASETS (IN
PERCEPTAGE). THE BEST PERFORMANCE AMONG 20 TRAIN/TEST PARTITIONS IS SHOWN IN PARENTHESES. THE BEST PERFORMANCE AMONG ALL
METHODS IS INDICATED IN BOLD FONT.
Performance
Indian Pines
University of Pavia
Two-layer NN 
RBF-SVM 
Three-layer NN , 
LeNet-5 , 
Shallower CNN 
91.03 ± 0.12
93.11 ± 0.06
The proposed network
93.61 ± 0.56 (94.24)
95.07 ± 0.23 (95.42)
95.97 ± 0.46 (96.73)
PERFORMANCE COMPARISON OF THE PROPOSED NETWORK IN PERCENTAGE W.R.T. VARYING WIDTHS (NUMBER OF KERNELS IN EACH LAYER).
Indian Pines
80.38 ± 14.20
93.61 ± 0.56
93.47 ± 0.41
92.79 ± 0.81
91.35 ± 3.62
93.60 ± 0.58
95.07 ± 0.23
94.10 ± 0.55
University of Pavia
94.77 ± 0.83
95.97 ± 0.46
95.86 ± 0.50
95.78 ± 0.52
TRAINING TIME (IN SECOND) OF THE PROPOSED NETWORK W.R.T.
VARYING WIDTHS (NUMBER OF KERNELS IN EACH LAYER).
Indian Pines
University of Pavia
B. HSI Classiﬁcation
Table V shows a performance comparison among the proposed network and baselines on the datasets. Hu et al. only
reports a single instance of classiﬁcation performance without
indicating if the value is the best or mean accuracy of multiple evaluations. The proposed network provided improved
performance over all the baselines on all datasets. The mean
of classiﬁcation performance of the proposed network is better
than the best baseline classiﬁcation performance by 2.58 %,
2.47 %, and 2.86 % for the Indian Pines dataset, the Salinas
dataset, and the University of Pavia dataset, respectively. This
performance enhancement was achieved mainly by building
a deeper and wider network as well as jointly exploiting the
spatio-spectral information of the hyperspectral data. Residual
learning also helped improve the performance by optimizing
training efﬁciency on a relatively small number of samples.
The groundtruth map (left) and the classiﬁcation map (right)
obtained by the proposed network for all datasets are also
shown in Figure 7. The classiﬁcation map is drawn from one
arbitrary train/test partition among 20.
TABLE VIII
PERFORMANCE COMPARISON OF THE PROPOSED NETWORK IN
PERCENTAGE W.R.T. VARYING DEPTHS (NUMBER OF RESIDUAL LEARNING
Indian Pines
92.74 ± 0.69
93.61 ± 0.56
92.63 ± 0.84
94.06 ± 0.26
95.07 ± 0.23
94.01 ± 0.47
University of Pavia
95.63 ± 0.50
95.97 ± 0.46
95.66 ± 0.59
TRAINING TIME (IN SECOND) OF THE PROPOSED NETWORK W.R.T.
VARYING DEPTHS (NUMBER OF RESIDUAL LEARNING MODULES).
Indian Pines
University of Pavia
C. Finding the Optimal Depth and Width of the Network
To ﬁnd the optimal width of the proposed network, we
evaluate the network by varying the number of convolutional
ﬁlters (i.e., the number of kernels): 64, 128, 192, and 256
for all three datasets. Table VI shows the performance of
the proposed network with the varying numbers of kernels
(network width) while Table VII shows training time for all
cases. For the Indian Pines dataset and the University of Pavia
dataset, 128 is the optimal width for the best performance
while 192 is the best one for the Salinas dataset. Since the
Salinas dataset contains more training samples from the larger
number of classes than other datasets, more weights seem to
be necessary to achieve optimal performance. As shown in
1x1 convolutions
1x1 output
1x1 convolutions
1x1 output
3x3 convolutions
3x3 max pooling
concatenation
1x1 convolutions
1x1 output
3x3 convolutions
5x5 max pooling
concatenation
5x5 convolutions
3x3 max pooling
1x1 convolutions
1x1 output
3x3 convolutions
7x7 max pooling
concatenation
5x5 convolutions
5x5 max pooling
3x3 max pooling
7x7 convolutions
Fig. 8. Architecture of various multi-scale ﬁlter banks.
PERFORMANCE COMPARISON OF THE PROPOSED NETWORK (IN PERCENTAGE) W.R.T. MULTI-SCALE FILTER BANKS WITH DIFFERENT CONFIGURATIONS.
∼7 × 7 MEANS THE MULTI-SCALE FILTER BANK CONSISTING OF 1×1, 3×3, 5×5, AND 7×7 CONVOLUTION FILTERS.
Indian Pines
53.67 ± 16.63
87.37 ± 4.12
93.61 ± 0.56
93.47 ± 0.77
50.62 ± 30.87
92.08 ± 0.77
95.07 ± 0.23
94.20 ± 0.43
University of Pavia
65.62 ± 8.18
93.59 ± 1.35
95.97 ± 0.46
95.91 ± 0.50
Table VI and VII, adding more ﬁlters to the optimal network
not only causes reduction in performance but also results in
an increase in computational cost.
We also evaluate the proposed network with various depths
in order to ﬁnd the optimal depth. Depth can be varied
by using different numbers of residual learning modules.
Performance comparison of the proposed network with varying
numbers of residual learning modules is shown in Table VIII.
Table IX shows training time for all cases. For all the three
datasets, using two residual learning modules achieves the
best performance among all variations. Using three residual
learning modules may face an overﬁtting issue, which results
in performance degradation. It is also shown in Table IX
that using three residual learning modules turns out to be
computationally very expensive.
On the basis of these evaluations, we choose the network
with two residual learning modules and the width of 128 for
each layer for both the Indian Pines dataset and the University
of Pavia dataset. For the Salinas dataset, the network with two
residual learning modules and the width of 192 for each layer
is selected.
D. Effectiveness of the Multi-scale Filter Bank
To verify the effectiveness of the multi-scale ﬁlter bank used
to jointly exploit the spatio-temporal information together, we
compare the proposed network to the network without the
multi-scale ﬁlter bank, which use only a 1×1 ﬁlter in the
ﬁrst layer. We also compare to the network with the multiscale ﬁlter bank with a different conﬁguration: 1×1, 3×3,
5×5, and 7×7. Figure 8 shows architectures of all various
multi-scale ﬁlter banks. As shown in Table XII, the multiscale ﬁlter bank signiﬁcantly outperforms the network without
it (1x1 only) for all the three datasets (by 39.94 % for the
Indian Pines dataset, 44.45 % for the Salinas dataset, and
30.35 % for the University of Pavia in mean classiﬁcation
performance). The drastic performance degradation is mainly
caused by two reasons; i) no joint exploitation of the spatiospectral information is performed and ii) data augmentation
by mirroring local regions cannot be used due to the nonexistence of spatial ﬁltering.
We also compare the proposed network to the one multiscale ﬁlter banks with different conﬁgurations. As shown in
Table XII, The performance degradation from using the multiscale ﬁlter bank with all the ﬁlters up to 7×7 denoted by
∼7×7 is caused by ’spillover’ near class boundaries resulted
from using the spatial ﬁlter of 7×7. Therefore, we choose to
use a multi-scale ﬁlter bank with 1×1, 3×3, and 5×5 for the
proposed network.
E. Effectiveness of Residual Learning
To verify the effectiveness of the “residual learning”, we
also compare the performance of the proposed network to a
similar network with the ﬁrst residual module replaced with
regular two convolutional layers, as shown in Table XI. Both
the networks are built on the same number of convolutional
layers, which is 9. It was found that the network without
using residual learning modules at all failed to converge
in training due mainly to the small size training data. The
loss (in log)
w/ residual learning
w/o residual learning
Accuracy (%)
w/ residual learning
w/o residual learning
(a) Indian Pines
loss (in log)
w/ residual learning
w/o residual learning
Accuracy (%)
w/ residual learning
w/o residual learning
(b) Salinas
loss (in log)
w/ residual learning
w/o residual learning
Accuracy (%)
w/ residual learning
w/o residual learning
(c) University of Pavia
Fig. 9. Evaluation of effectiveness of residual learning. Training loss (top) and classiﬁcation accuracy (bottom) on three datasets with the proposed network
and the network with the ﬁrst residual learning module replaced with two convolutional layers are provided as a function of training iterations. Note that
‘w/ residual learning’ is the proposed architecture and ‘w/o residual learning’ is the modiﬁed architecture replacing the ﬁrst residual learning modules with
regular two nonlinear layers as two sequential convolutional layers with the same nonlinear layers.
network with the ﬁrst residual learning module replaced with
two convolutional layers also failed to optimize the network
parameters resulting in sub-optimal performance, as shown in
Table XI. Figure 9 shows the comparison of training loss and
classiﬁcation accuracy as a function of training iterations for
the two networks, which are calculated from one arbitrary
train/test partition. From the training loss in the plots of the
ﬁrst row of Figure 9, we observe that the proposed network
achieves lower loss both during learning and at the end
of the iterations than the other network. The second row
of the Figure 9 also shows that lower loss during learning
leads to improved classiﬁcation accuracy. These observations
support that residual learning greatly improves overall learning
efﬁciency resulting in both lower training loss and higher
classiﬁcation accuracy.
F. Performance Changes according to Training Set Size
To analyze the effects of training dataset size in learning
the proposed network, we compare the performance of the
proposed network as the size of training dataset is changed: 50,
100, 200, 400, or 800 examples per a class. Table XII presents
classiﬁcation accuracy of the proposed network w.r.t. training
dataset size. For the Indian Pines dataset, we do not perform
CLASSIFICATION PERFORMANCE COMPARISON OF THE PROPOSED
NETWORK AND THE NETWORK WITH THE FIRST RESIDUAL LEARNING
MODULE REPLACED WITH REGULAR CONVOLUTIONAL LAYERS (IN
PERCENTAGE).
w/ conv. layer
w/ residual learning
Indian Pines
49.73 ± 24.58
93.61 ± 0.56
46.75 ± 25.98
95.07 ± 0.23
University of Pavia
50.23 ± 27.78
95.97 ± 0.46
learning with 800 examples per a class because several classes
have insufﬁcient examples (e.g. 483 for Grass-pasture, 478 for
Hay-windrowed, 593 for Soybean-clean).
As expected, the classiﬁcation accuracy of the proposed
network monotonically increases as training dataset size increases. We also note that even for smaller training dataset
size, such as 50 and 100, the proposed network provides
higher accuracy than multiple kernel learning (MKL)-based
HSI classiﬁcation , as shown in Table XII.
PERFORMANCE COMPARISON OF THE PROPOSED NETWORK (IN PERCENTAGE) W.R.T. THE NUMBER OF TRAINING EXAMPLES PER A CLASS.
Indian Pines
77.40 ± 1.78
80.63 ± 0.99
The proposed network
80.50 ± 3.93
87.39 ± 0.88
93.61 ± 0.56
94.68 ± 0.47
89.33 ± 0.44
90.60 ± 0.43
The proposed network
91.36 ± 1.11
93.15 ± 0.43
95.07 ± 0.23
96.55 ± 0.29
97.14 ± 0.53
University of Pavia
91.52 ± 0.98
92.72 ± 0.33
The proposed network
91.39 ± 0.80
93.10 ± 0.45
95.97 ± 0.46
96.81 ± 0.25
97.31 ± 0.26
G. False Positives Analysis
Table XIII shows confusion matrices for three datasets,
which are calculated from one arbitrary train/test partition.
For the Indian Pines dataset, the proposed network presents
the performance below 95 % in only two classes that are
corn-notill and soybean-mintill, among the eight classes. As
shown in the Table II, the two classes are the ones with
much larger numbers of samples than others. The network
learning with relatively small training data seems to fail
to represent overall spectral characteristics of the classes.
Similarly, approximately 5% of false positives of each of
the two classes are labeled as the other class because the
spectral distributions of the two classes are more widespread
than others. Similar tendency is shown for the Salinas dataset.
The proposed network performed worst for the two classes
with more test data, which are grapes untrained and vineyard
untrained, as shown in Table III: 83.4 % for grapes untrained
and 89.4 % for vineyard untrained. Most false positives from
each of the two classes are the ones misclassiﬁed as the other
class of the two classes. For the University of Pavia dataset,
the classiﬁcation performance of the bricks class is noticeably
worse, which is less than 90 %. Most false positives of the
bricks class are classiﬁed as gravels.
To evaluate how the proposed network performs for pixels
near boundaries between different classes, we categorized all
the pixels according to the pixel distance to the boundary.
Pixels on the boundary are labelled as zero. Similarly, pixels
near boundary with one pixel apart are labelled as one. The rest
are labelled as ≥2. Note that we use neighboring 5×5 pixels
for exploiting spatial information of each pixel. For pixels
labelled as ≥2, their 5×5 neighboring pixels are from the
same class. Table XIV shows the number of false positives
versus all the test data within each pixel category for all
the three datasets. For all datasets, it is observed that larger
portions of false positives are generated near boundaries as
expected. The false positives close to class boundaries are one
of major factors for performance degradation of the proposed
network. The pixels far from the boundaries by more than one
pixel distance are not affected by ‘spillover’ and therefore less
prone to misclassiﬁcation.
V. CONCLUSION
In the proposed work, we have built a fully convolutional
neural network with a total of 9 layers, which is much deeper
than other existing convolutional networks for HSI classiﬁcation. It is well known that a suitably optimized deeper network
can in general lead to improved performance over shallower
networks. To enhance the learning efﬁciency of the proposed
network trained on a relatively sparse training samples a newly
introduced learning approach called residual learning has been
used. To leverage both spectral and spatial information embedded in hyperspectral images, the proposed network jointly
exploits local spatio-spectral interactions by using a multiscale ﬁlter bank at the initial stage of the network. The multiscale ﬁlter bank consists of three convolutional ﬁlters with
different sizes: two ﬁlters (3×3 and 5×5) are used to exploit
local spatial correlations while 1×1 is used to address spectral
correlations.
As supported by the experimental results, the proposed
network provided enhanced classiﬁcation performance on the
three benchmark datasets over current state-of-the-art approaches using different CNN architectures. The improved
performance is mainly from i) using a deeper network with
enhanced training and ii) joint exploitation of spatio-spectral
information. The depth (the number of layers) and width (the
number of kernels used in each layer) of the proposed network
as well as the number of residual learning modules are determined by cross validation. The classiﬁcation performance also
shows that the proposed network with two residual learning
modules outperforms the one with only one module, which
supports the effectiveness of the residual learning incorporated
into the proposed network.