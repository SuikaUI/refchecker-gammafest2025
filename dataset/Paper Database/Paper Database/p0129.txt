Proceedings of International Joint Conference on Neural Networks, Atlanta, Georgia, USA, June 14-19, 2009
Input-variable Specification for Neural Networks - an Analysis of
Forecasting low and high Time Series Frequency
Sven F. Crone and Nikolaos Kourentzes
Abstract» Prior research in forecasting time series with
Neural Networks (NN) has provided inconsistent evidence on
their predictive accuracy. In management, NN have shown only
inferior performance on well established benchmark time series
of monthly, quarterly or annual frequency. In contrast, NN
have shown preeminent accuracy in electrical load forecasting
on daily or hourly time series, leading to successful real life
applications. While this inconsistency has been traditionally
attributed to the lack of a reliable methodology to model NNs,
recent research indicates that the particular data properties of
high frequency time series may be equally important. High
frequency time series of daily, hourly or even shorter time
intervals pose additional modelling challenges in the length and
structure of the time series, which may abet the use of novel
aims to identify
contrast the
challenges in modelling NN for low and high frequency data in
order to develop a unifying forecasting methodology tailored to
the properties of the dataset. We conduct a set of experiments in
three different frequency domains of daily, weekly and monthly
data of one empirical time series of cash machine withdrawals,
using a consistent modelling procedure. While our analysis
predict high
frequency data, it also identifies a set of challenges in modelling
NN that arise from high frequency data, in particular in
specifying the input vector, and that require specific modelling
approaches applicable to both low and high frequency data.
I. INTRODUCTION
a resurgence
of interest
modelling artificial neural networks (NN) for time series
prediction, both in research and practice . A recent
literature survey reveals over 5,000 publications on NN in
time series prediction, with successful applications across
various forecasting domains (see e.g. ), in academic
research and in practice . However, in management
research, the majority of publications have limited their
evaluation of NN to predicting low frequency
literature review identified that 74 of 102 publications (73%)
analysed the performance of NN on low frequency time
series, i.e. time series of annual, quarterly, monthly or
weekly observation intervals. In contrast, the evaluation of
NN in predicting time series
received lesser attention, despite the widespread existence of
high-frequency data in electrical load forecasting
predictions
Manuscript
Kourentzes
(corresponding author) and Sven F. Crone are with the department of
Management
University
Management
Lancaster, LAI 4YX, United Kingdom. (phone: +44.1524.5-92991; fax:
+44.1524.844885; e-mail: {n.kourentzes;s.crone}@lancaster.ac.uk).
978-1-4244-3553-1/09/$25.00 ©2009 IEEE
macroeconomics . While no common agreement exists
on what constitutes low and high frequency data across
domains, time series of daily or shorter time intervals are
generally characterised as high frequency data . While
all time series essentially consist of combined archetypical
time series patterns of seasonality, trends, levels, structural
breaks, outliers and calendar effects, it is argued that high
frequency data poses a new set of forecasting problems, that
make conventional methods inappropriate and demand
approaches regarding methods,
methodologies
computational
econometrics and finance by Markham and Rakes as
well as Hu et al. suggests that NN can perform particularly
well on high frequency data due to the particular data
properties, which has been supported by some empirical
evidence in electrical load forecasting . However, NN
challenges in predicting data of different time frequencies,
leaving both fields of low-frequency and high-frequency time
series disconnected with inconsistent findings.
The aim of this study is to explore the accuracy and
modelling challenges of NN that arise from different levels
of time series frequency. We conduct a set of experiments to
predict an empirical time series of daily cash withdrawals
taken from the NN5 competition (www.neural-foecastingcompetition.com), which is aggregated to daily, weekly and
monthly levels of time frequency. The stepwise aggregation
enables an analysis of the changes in accuracy and of the
appearance of novel challenges in the modelling process
during the transition from low to high frequency data. While
methodologies to specify the number of hidden layers,
number of hidden nodes in each layer, activation functions,
parameters etc.
on wrapper
approaches) remain largely unaffected by the time series
frequency, the data properties show a direct impact on the
specification and length of the input vector. Consequently,
we evaluate a set of alternative heuristic and statistical
techniques for selecting the time-lagged input variables and
their impact on forecasting accuracy. The accuracy of the
NN is compared to statistical benchmark methods in each of
the frequency domains and in a bottom-up aggregation of the
daily predictions to weekly and monthly levels in order to
evaluate potential
in accuracy in lower
frequency from predictions using high-frequency data.
The paper is organised as follows: section II briefly
introduces the methods and different methodologies of input-
vector specification for NN, followed by information on the
time series and the experimental design in section III.
Section IV discusses the results for each frequency domain
comparison.
characteristic
modelling challenges of NN on different time frequencies,
followed by conclusions and further research in section VI.
II.FORECASTING WITH NEURAL NETWORKS
A. Multilayer Perceptrons for Time Series Prediction
evaluation to
multilayer
perceptron
represents
employed NN architecture . The advantage of MLPs is
that they are well researched regarding their properties and
their proven abilities in time series prediction to approximate
and generalise any linear or nonlinear functional relationship
to any degree of accuracy without any prior assumptions
about the underlying data generating process , providing
a powerful forecasting method for linear or non-linear, nonparametric, data driven modelling. In univariate forecasting
feed-forward architectures of MLPs are used to model
nonlinear autoregressive NAR(p)-processes, using only time
lagged observations of the time series as input variables to
predict future values , or intervention modelling of
NARX(p)-processes using binary dummy variables to code
exogenous events as explanatory intervention variables. Data
are presented to the network as disjunct vectors of a sliding
window over the time series history. The neural network
learns the underlying data generating process by adjusting
the connection weights w =(fJ, y) to minimise an objective
(squared error loss) function on the training data to make
valid forecasts on unseen future data . We employ a
single hidden layer MLP to forecast a future value Xt+h1t :
Xt+hll = f(X, w) = Po +t Phg(~ YhiXi)
with t denoting the point in time, h the forecasting horizon
and X = [xo, xi, ... , xn ] the input vector of the time lagged
observations
parameters
(i = 1, ..., I) and H (h = 1, ..., H) specify the number of input
and hidden units of the network architecture, and g(.) is a
non-linear transfer function in the hidden layer nodes .
Modelling a NN for time series data requires decisions on
a number of architectural parameters, including the number
of input nodes, hidden layers, nodes per hidden layers,
activation
functions,
parameters
algorithm, learning rates, early stopping criteria etc. An
adequate NN architecture is routinely determined by using
simulations on the time series: a set of candidate MLPs is
using different architectural parameters and the
architecture with the lowest in sample error is selected.
B. Input Variable Selection for Time Series Prediction
While the specification of NN architectures is still under
discussion
publications
identified the adequate selection of the input vector as one of
the most important decisions for accuracy. As time series of
different frequency may display varying time series patterns,
including the appearance of multiple levels and forms of
seasonality, changes in the magnitude of seasonality, trend
randomness,
identified for each time series frequency. For the stationary
information
seasonality
potentially
necessary . Consequently, we seek to evaluate multiple
architectures and different approaches of input variable
selection for each time series of a specific time frequency.
Different methodologies to specify input vectors have
been suggested and explored for low frequency data, but
without adequate evaluation on high-frequency data. In order
to reflect possible interactions of the time series frequency
with the input vector methodology and the resulting number
of input nodes we evaluate the four most popular analytical
approaches to specify the input vector (not selecting an input
vector of arbitrary size), as identified by a literature review.
The most common approach of input variable selection for
NN applies a stepwise linear regression model with statistical
testing to identify significant time lags and use those to
specify the input vector for the NN , despite evidence
in econometrics and time series modelling that this may lead
to suboptimal and misspecified input variables.
Alternatively, we may specify the input vector following
the popular statistical Box-Jenkins methodology of ARIMA
modelling, which has demonstrated promising results [23,
The autocorrelation function (ACF) and the partial
autocorrelation
analysed in order to identify and select significant timelagged realisations. As a feed-forward MLP models an
autoregressive
NAR(p)-process
components of a moving average process), we may limit the
conventional
algorithm to
calculate the PACF utilises the Yule-Walker equations,
which estimate the true PACF by minimising the forward
regression error in the least squares sense. Alternatively, the
PACF may be estimated using the Burg algorithm, by
minimising both the forward and backward error, thereby
providing a more accurate estimation of the autoregressive
of the time series
 at the cost of being
computationally more intensive.
A simple expansion of these algorithms combines the
autoregressive lag-structure identified by the PACF with the
information on moving average processes contained in the
statistically
significant in both ACF and PACF, as suggested in .
These four methods warrant further evaluation in order to
establish their comparative accuracy in time series prediction
with MLPs, as we will show in later experiments.
Across all methodologies for input-variables specification,
including stepwise Regression and PACF / ACF analysis,
one problem arises in the mandatory ex ante specification of
the maximum number of lags one should include in the
evaluation. For non-stationary time series, specifying the
input-vector via ACFIPACF will lead to a large number of
significant autocorrelations, essentially requiring a maximum
cut-off of a maximum lag to be considered. Despite the
400 "1\------,----------,--------,-------,----------,--------,---------,
100 OL-------L------"--------L--------L-------'----------::-~----~
Fig. I. Seasonal length plotted against the Euclidean distance between seasons. The asterisks signify the local minima.
substantial impact of this meta-parameter, the issue has not
been explored, with the exception of Balkin and Ord for
the cases of yearly, quarterly and monthly time series of low
frequency. A common practice resorts to heuristic trial and
error approaches, or setting an arbitrary number of lags as
(suboptimal)
heuristics may be feasible for low frequency data, they fail
for high frequency data as the increased length of the time
series and the multiple overlapping patterns can lead to a
large number of significant lags and very long input vectors.
This mirrors a common challenge of statistical tests in data
mining: the sheer size of the available dataset leads to most
test becoming statistically significant . In forecasting
high-frequency time series, the large number of data points
will induce low significance levels and hence indicate most
lags in the ACF and PACF as significant, creating inflated
input vectors. This aspect warrants further investigation. In
ACF and PACF information
may be masked
through multiple overlying seasonalities, that require an
iterative model building and residual analysis for valid
identification.
To limit iterative modelling and identify an efficient
suitable maximum lag of the input-variables we propose a
simple approach to identify the true seasonality and the
maximum seasonal length of the input vector by measuring
the Euclidian distance of a seasonal plot for arbitrary
seasonal lengths. A time series of length 1, ..., n is split into
seasons of increasing length s, with s=1, ...,S and S -S n / 2,
and the Euclidean distance between all n / s seasonal time
series is calculated. The seasonal length that minimises the
Euclidean distance indicates the minimum possible deviation
(in squared error terms) of the seasons, thus providing a
possible seasonality and a suitable input variable to capture
the seasonality. In fig. 1 the development of the Euclidean
distance of the time series NN5-035 (used in section III in
the experimental evaluation) is plotted against the seasonal
length, identifying multiple suitable seasonalities through
seasonality. We may utilise this additional information to
specify suitable lags and a maximum lag-length in addition
identified
conventional
methodologies for input-variable specification .
EXPERIMENTAL D ESIGN
A. Time Series Data
The experiments evaluate the effect of increasing time
frequency on a single time series of daily cash withdrawals
from cash machines in the UK, taken from the recent NN5
competition dataset of 111 time series (ID# NN5-035). The
daily time series consists of two years of data, beginning
March 18th 1996 and ending March 22nd 1998. In order to
avoid the creation of inconsistencies from the aggregation of
the data, the first and last incomplete months that cannot be
aggregated are trimmed from the time series, leaving a time
series of 23 months or 699 days, just less than two full years
of data. The trimmed time series contains 14 missing values,
which are imputed by the average of the neighbouring
observations. To run experiments on weekly and monthly
data of lower frequency the adjusted daily time series is
aggregated by summing cash withdrawals over weeks and
calendar months respectively. A plot of the daily time series,
with both the trimmed and missing values displayed as
shaded observations, and the series aggregated to weekly
data and monthly data is provided in fig. 2.
~::rV~ ' 0 ~tj~~~ ~;:0=
Fig. 2. NN5-035 weekly and monthly aggregated plots
A visual analysis of the three time series reveals various
seasonal patterns around a constant level without any trends,
as confirmed by a Phillips-Perron test on all three time
series. In order to identify single or multiple seasonalities of
different length on the time series of different frequency, an
ACFfPACF-plots,
periodograms
inspections of seasonal year-on-year diagrams were used, of
which fig. 3 shows the seasonal plot for the daily time series.
Fig.3. Seasonal week-on-week diagram for the daily time series
day-of-the-week
seasonal pattern, plus some slight instationarity of the level
of the stacked weekly lines, which can be attributed to a
second seasonality of week in the year. Both periodogram
and ACFfPACF-analysis confirm these patterns, with the
day-of-the-week pattern obviously missing in the data with
lower frequencies of weekly and monthly observations. The
yearly cycle provides some challenges in identification fro~
the truncated time series, as no data on two full years tS
available, which will equally make any modelling difficult.
All time series show a set of systematic seasonal pulses of
Christmas and the New Year's Eve during the last 1.5 weeks
of each year (18 of December until 31 of December), which
are reflected with different intensities in all frequencies of
the 13 last daily, last 2 weekly and last monthly observations.
These time periods are modelled by using an integer dummy
variable as an additional input during MLP training. In
addition, the aggregation from daily to weekly and monthly
frequencies
introduces
asymmetries
to the varying
number of working days per month (31 days in January vs.
28 days in February) and the potentially different number of
days and weeks per year, which is reflected in a binary
dummy variable for the February of each year.
B. Experimental setup
The experimental setup of forecasting horizon, error metrics,
and test dataset is guided by the design of the original NN5
competition. The forecasting horizon is h=1, 2, ..., 56 days
into the future, or the equivalent of I to 8 weeks and 1 to 2
months for the lower time frequencies respectively in order
to allow a bottom-up comparison of the accuracy across a
homogeneous test set despite different time frequencies .
The symmetric mean absolute percent error (sMAPE) is
used to evaluate and compare the competing modelling
approaches, as in the NN5. It computes the absolute error in
percent between the actuals XI and the forecast FI for all
::~~;:h; t("tl~:i:~h fO
:::h time origin: (2)
(XI +F;)/2
Both the validation and test datasets contain 84 days (or
the equivalent of 12 weeks or 3 months for different time
frequency). All models are evaluated using a rolling time
origin evaluation, evaluating the average accuracy across 28
daily time origins (and 4 origins for weekly and 2 for
monthly data respectively) in order to increase the validity
and reliability of the results in contrast to a single fixed
origin evaluation . The accuracy of the competing NN
models is evaluated for statistically significant differences
nonparametric
Nemenyi test, to facilitate an evaluation of nonparametric
models without the need to relax assumptions of ANOYA or
similar parametric tests [34J.
C.Neural Network Architectures
The Evaluation encompasses MLP models using different
input-vector specifications
and statistical benchmarks
compare the predictive accuracy of different approaches. All
architecture
parameters, with the exception of varying the number of
input nodes and hidden nodes. To evaluate the accuracy of
the competing methodologies for input-vector specification,
we will identify lags using the four methodologies of
stepwise regression, PACF Burg-algorithm, PACF Yule-
Walker-algorithm,
algorithm using the Yule-Walker equations. For the weekly
and the monthly time series, the stepwise regression based
models could not identify any significant lags, so no NN was
trained. In addition to these four methodologies, we create a
second set of input-vectors that combine the time lags
specified by each of the methods with the time lags identified
distance, introducing
seasonal lag to each. The NN architectures of input and
hidden nodes for the three aggregation levels of daily,
weekly and monthly data are summarised in table I. Each
input vector methodology is identified by the name of the
underlying algorithm, with the suffix '5' denoting those
extended with the lags from the Euclidian distance chart.
Each MLP is trained with the corresponding number of
nodes as specified through the input-vector methodology. All
topologies
have a single output node with the identity
activation
with iterative
predictions for multiple-steap ahead forecast. An adequate
number of hidden nodes for each time series frequency is
pre-determined from a set of Hi = 1, ... , 12 nodes through
experimentation for each of the time series using errors from
the in-sample data only, selecting a set of Hd=8, Hw=5 and
H =9 hidden nodes for the daily (d), weekly (w) and
monthly (m) time series respectively, all using the hyperbolic
tangent (TanH) activation function.
For training, we apply a standard gradient descent learning
backpropagation
training, applying an initial learning rate of '1=0.5 which is
SUMMARY OFNEURAL NETWORK ARCHITECTURES
Daily Data
Weekly Data
Monthly Data
# of nodes
# of nodes
1,3-9,11,13-16,21,28-29,36,65,108
1,3,5-9, 11, 13-15,20,22,29,36
PCAF+ACF-Yule
Stepwise Regression
1,7,35,56,83-84,99,169,174,182,189
PACF-Yule-S
1,3-9,11,13-16,21,28-29,36,65,108,189
PACF-Burg-S
1,3,5-9, 11, 13-15,20,22,29,36, 189
PACF+ACF-Yule-S
Stepwise Regression-S
1,7,35,56,83-84,99,169,174,182,189
# of nodes
*The Lags specify the time lagged realisations t-n used as inputs, with the number of lags equalling the number of input nodes.
with s=7 for weekly seasonality, and seasonal Naive with
s= 189 using the seasonal lag identified from the Euclidean
distance algorithm. In analogy, three EXSM Variants are
evaluated: one single EXSM without seasonality, seasonal
EXSM with s=7 and with s=189. For weekly and monthly
time series of different seasonal length the Naive level and
single EXSM methods are evaluated.
E. Results on individual time series
Table II provides the SMAPE errors on the test dataset for
the best MLPs, selected as the candidate with the lowest
SMPAE validation
and the statistical
methods. The best MLP candidate with a PACF Yule input
vector outperforms all statistical benchmarks on daily and
weekly time frequency, but not on monthly time series where
the statistical benchmark of single EXSM outperforms all
other methods.
Examining table II reveals that the addition of the seasonal
lag identified through the Euclidean distance approach (-S
suffix models) in the input vector affects positively the
accuracy of both the ANN and the benchmarks. Furthermore,
for the daily time series the ACF-Yule and ACF-Yule-S
0.0515)...
0.0515)...
0.0717)...
0.0717)...
Time Series Frequency
0.2674)...
0.2800)...
0.2800)...
TESTSUBSET SMAPE
Friedman Test
PACFYule -S
PACF Burg-S
ACF-PACF-Yule-S
Stepwise Regression-S
ACF-PACF-Yule
Stepwise Regression
assumes that the forecast Xt+h1t for period t+h will be equal
to the last observation x; For time series with seasonality of
length s, the seasonal Naive method computes a forecast
Xt+h1t equal to the last observation x one season t-h-s ago,
with s depending on the seasonality inherent in the time
series frequency :
reduced each epoch by 1% and a constant momentum term
of qJ=0.4. Each MLP is trained for a maximum of 1000
epochs using early stopping, where training is aborted if the
MSE on the validation data does not improve by 1% within
100 epochs. The weight-vector with the lowest MSE on the
validation set during training is saved and used as the final
set of weights. To facilitate learning for the MLPs, all input
and output data is linearly scaled between [-0.6, 0.6] using
the maxima and minima from training and validation data,
and is presented to the MLP randomly without replacement.
Each MLP is initialised 40 times to account for randomised
starting weights and to provide an adequate sample to
estimate the distribution of the forecast errors in order to
conduct the statistical tests. The MLP initialisation with the
lowest sMAPE on the validation dataset is selected to predict
all values of the test data.
DiStatistical Benchmark Methods
Any empirical evaluation of time series methods requires
the comparison of their accuracy with established statistical
benchmark methods, in order to assess the increase in
accuracy and its contribution to forecasting research (which
is often overlooked in NN experiments ). We compare the
accuracy of MLPs with different input vectors against a set
of statistical benchmark models for level and seasonal time
series (due to the absence of trends), including the Naive
level, Naive season, single Exponential Smoothing (EXSM)
and seasonal EXSM. The method of Naive level,
lowest validation error in italics,
lowest test error (in table) in bold;
** =significant Friedman-test at the 0.01 level; * =significant Friedmantest at 0.05 level;
)... = no significant differences by Nemenyi-test at 0.05
level; no * /)... =Friedman-test / Nemenyi-test insignificant
EXSM (s=l)
EXSM (s=7)
EXSM (s=189)
parameters for stationary and seasonal time series are well
established, due to their proven track record in univariate
time series forecasting . Model selection of the EXSM
method is conducted based on the identified time series
components . Depending on the level of seasonality,
different benchmarks are computed: For daily time series
three naive models are used: Naive level, seasonal Naive
Benchmarks
Naive (s=l)
Naive (s=7)
Naive (s= 189)
DISCUSSION
SMAPEs OF BOTTOM-UP AGGREGATED FORECASTS
A. Computational resources
In modelling high-frequency time series we identified a
number of particular challenges that warrant discussion to
facilitate further research. A fundamental characteristic of
high frequency data - for a given time span of history - are
large datasets. In our preceding experiments, the daily time
series is 700% longer than the weekly time series and 3000%
longer than monthly time series.
Due to the increased size of the datasets, modelling MLPs
for high frequency data require additional computational
resources. In our experiments an identical methodology was
used to find the number of the hidden units for a given input
frequency domains,
differences in processing time were solely caused by the
amount of data resulting from the different time frequencies.
The processing times for the topology-search are provided in
table IV indicating that specifying topologies to forecast
daily data requires 371.1 % more computational time than for
monthly data.
COMPUTATIONAL TIME FOR TOPOLOGY SEARCH IN SECONDS
For daily time series no bottom-up aggregation is feasible.
For weekly time series the bottom-up approach, forecasting
on a daily level and aggregating to weekly forecasts yields
higher forecasts errors of 11.60% in comparison to 7.43%
when using a weekly forecasting model directly.
However, for monthly time series the forecasts conducted
on a higher time series frequency of either daily or weekly
level yield
lower forecast errors
respectively,
conventional forecasting models using monthly data. This
discrepancy may be caused by the presence of short termed
calendar effects (e.g. Christmas) in the test set, which may be
captured and extrapolated on higher
time series
frequencies of daily and weekly data than on monthly data.
Higher frequency data can provide extra detail which may
be lost in the lower frequencies, that aids in the creation of
better forecasts, as the bottom-up comparison in table III
indicates. As a consequence, one may consider forecasting
on higher frequency data even if our decision domain is on a
frequency.
importance of robust modelling of MLPs on high frequency
data, in particular in the light of calendar effects and outliers.
Model used to create forecasts
Computational Time
% increase of time
(in seconds)
on monthly data
Time Series
Daily time series
Weekly time series
Monthly time series
Time series
models, which have 189 inputs, do not perform well. One
explanation can be that the degrees of freedom are so high
that the training of the network is no longer efficient. The
more parsimonious models perform much better.
To establish the significance of the results
comparison of the best method, we conduct nonparametric
statistical tests of significance between the error distributions
of the different methods. First, we employ the Friedman test
to identify significant differences within groups of the MLP
models. Once the Friedman test has established significant
differences of the input-vector candidates, the Nemenyi test
is employed at a 0.05 significance level in order to identify
which models do not have significant differences within that
group. The test-results are indicated in table II. On monthly
time series, no MLP model shows significantly different
errors, and all MLP candidates are outperformed by both
Naive and EXSM benchmarks. On weekly time series the
PACF-Yule,
PACF-Yule-S,
ACF-PACF-Yule
PACF-Yule-S input vector methodologies perform identical,
showing that the inclusion of extra inputs with a maximum
lag-length offer no statistically significant improvements, in
spite of the slightly better results of ACF-PACF-Yule and
ACF-PACF-Yule-S.
Regression,
PACF-Yule-S
Stepwise-Regression-S
outperform all other MLPs and benchmarks, demonstrating
the superiority of the additional maximum lag from the
seasonal diagram for daily data. The statistical test indicate
significant
differences
significant
differences
conventional
input-vector
methodologies without'S' .
This indicates that MLPs
with different input vectors
outperform statistical benchmarks on daily and weekly time
series of high-frequency, while they underperform on lowfrequency data. As the data frequency increases, and more
autoregressive information is captured in the models, MLPs
achieve a better accuracy in comparison to the benchmarks.
Furthermore, there is evidence that the Euclidean distance
minimisation
selected improvements in
accuracy across all low and high frequency domains.
F. Results from a bottom-up comparison
Using the best MLP for each time series in the validation
subset (table II) we create fixed-origin forecasts for 84 days,
8 weeks and 2 months for each time series frequency
respectively.
to facilitate
a valid comparison,
forecast values are aggregated in a bottom-up manner into
time-buckets of lower frequency. For example, we employ a
daily forecasting model using daily data. The 84 daily
forecast values are aggregated across the forecasting horizon
to form forecasts for 8 calendar weeks and 2 months by
mapping days to weeks and months. We then estimate the
accuracy of these weekly and monthly aggregated forecasts
from the weekly and monthly actuals, and compare it to
forecasting directly with a weekly model built on using
weekly data. Weekly forecasts are aggregated to monthly
forecasts accordingly. The results using SMAPE errors are
provided in table III.
Non significant
Significant --- CI I
Fig.5. PACJ<' plots of a short (a) and a long sample of a time series (b)
developed for low-frequency data for high-frequency time
series despite similar time series patterns. Here additional
research is needed to explore corrections to conventional
methodologies, in order to extend the use of statistical test as
filters in the modelling process to high frequency data.
1 C".---------
~ - - -I -
1...._;II~IIIIIII1~I" ;1II11
~ - - _,- -
-1 L-----'-_---'--_--'---_L----.l
All experiments to identify the number of hidden units were
conducted for each time series using the software 'Intelligent
Forecaster' on an InteiCore2 T7500 processor with 202Ghz,
3GB memory using a 32-bit Windows Vista. Valid and
experiments
experiments.
Simulations on high-frequency data will require substantial
computational
resources and the development of robust
methodologies to specify the input vector for NN modelling.
B. Impact ofsample size on statistical test
In addition to the increase in computational time required
for training and testing of NN for high-frequency time series,
the increased size of the datasets creates further challenges.
In particular,
the increased
length of the time series
impacts the validity of statistical tests required e.g. for input
variable selection, by lowering the confidence limits and
hence tightening the confidence intervals. Fig. 4 illustrates
the positive correlation of the tightness of the confidence
intervals of the ACFIPACF with the sample size.
120 observations
1200 observations
Sample size
J<'ig.4. Effect of sample size on confidence interval
individual
autocorrelations
autocorrelations of a time series will exhibit a constant
magnitude, this results in more lags of the ACF and PACF
becoming statistically significant. After some size of the
dataset, the confidence intervals become so tight that nearly
every lag becomes significant, an effect that would equally
hold for the test of statistical significance used in stepwise
regression. As a result, the length of the input vector would
rise drastically with the magnitude of the dataset.
To exemplify the effect of sample size while controlling for
effects of the information content, we create a synthetic time
series of 120 and 1200 observations, the later being ten
replications of the first sample. The results for the two
PACFs calculated on short low frequency dataset A and the
large high-frequency dataset B are provided in figure 5.
It is evident that the ACF of the shorter, low-frequency
time series of 120 observations has far less significant lags
than the ACF of the second sample, which uses 10 times
more observations to represent the increased data of a highfrequency time series with a consistent pattern. This effect is
equally apparent in the specified input-vectors of table l.
As a result, the methodologies based upon statistical test
would construct non-parsimonious models that depend not
on the structure of the data generating process, but merely
the sample size. In addition, the impact of sample size on
CONCLUSIONS
We evaluate different methodologies to specify the input
vector of MLPs across a single time series of increasing time
frequency. The experiments indicate that MLPs are well
suited to predict high-frequency data of weekly and daily
observations
outperform
established
statistical
benchmark methods, while they fail to outperform on lowfrequency data of monthly observations.
As a consequence, we provide evidence that NN may be
better suited to forecast high frequency data rather than the
low-frequency data stemming from the popular M1-, M3-or
NN3-forecasting competitions on which they are routinely
evaluated in the academic forecasting domains. This may
provide an initial explanation of the apparent gap between
their limited merit in empirical evaluations and academic
competitions using low frequency data, and their corporate
success in applications of electrical load forecasting which
routinely employs high-frequency data. These findings are
further supported by external evidence in comparing the
increasing
performance of contenders
of computational
intelligence from the monthly NN3-competition to the daily
NN5-competition in comparison to a consistent statistical
competition
www.neural-forecasting-competition.com for details).
Our experiments further identify a number of challenges in
the modelling process of MLPs for high- and low-frequency
data, associated with the dataset size, the available statistical
optimisation
identification,
computational needs and modelling problems associated with
time aggregation and calendar effects. While our analysis
offers mere initial solutions to these problems, we consider
the identification of these challenges a valuable contribution
as they must be resolved to establish NN as a valid and
reliable method to routinely forecast low- as well as highfrequency data. The initial results - despite their limited
reliability stemming only from a single time series - may
facilitate
approaches
employed for low frequency data in management science,
and also to serve as a starting point to for the development of
a unified methodology to accurately forecast high- as well as
low-frequency
experiments must find a way to control for the increased
amount of data available for MLP training, which may create
interaction
architecture,
accuracy of a NN on datasets of similar data generating
processes.
Furthermore,
experiments
towards causal models using external explanatory variables,
challenges
additional
acquisition or even prediction of uncontrollable, exogenous
variables often warrant the use of mere univariate time series
models. Ideally, such methodologies should scale equally
well towards additional time series of explanatory inputvariables as towards additional data points. Possibly more
important still, issues of understanding the models derived
from selected input variables in order to infer properties of
the data generating process require consideration and may
benefit such methodologies with increased interpretability.
In the future, the analysis must be extended to additional
time series,
of different patterns
seasonality
additional
methodologies of input vector specification to provide a
performance of NN on high- and low-frequency data.