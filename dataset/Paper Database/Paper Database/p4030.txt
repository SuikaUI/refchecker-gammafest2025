This is the accepted manuscript made available via CHORUS. The article has been
published as:
Self-learning Monte Carlo method
Junwei Liu, Yang Qi, Zi Yang Meng, and Liang Fu
Phys. Rev. B 95, 041101 — Published 4 January 2017
DOI: 10.1103/PhysRevB.95.041101
Self-Learning Monte Carlo Method
Junwei Liu1†⇤, Yang Qi1†, Zi Yang Meng2 and Liang Fu1⇤
1Department of physics, Massachusetts Institute of Technology, Cambridge, MA 02139, USA and
2Institute of Physics, Chinese Academy of Sciences, Beijing 100190, China
 
Monte Carlo simulation is an unbiased numerical tool for studying classical and quantum manybody systems. One of its bottlenecks is the lack of general and eﬃcient update algorithm for large
size systems close to phase transition,for which local updates perform badly. In this work, we propose
a new general-purpose Monte Carlo method, dubbed self-learning Monte Carlo (SLMC), in which
an eﬃcient update algorithm is ﬁrst learned from the training data generated in trial simulations
and then used to speed up the actual simulation. We demonstrate the eﬃciency of SLMC in a spin
model at the phase transition point, achieving a 10-20 times speedup.
Monte Carlo (MC) method is a powerful and unbiased
numerical tool for simulating statistical and condensed
matter systems 1–5. MC simulation obtains statistically
exact values of physical observables by sampling a large
number of conﬁgurations according to the Boltzmann
distribution.
Conﬁgurations can be generated sequentially by local update method 6,7. However, when the
system is close to a phase transition, local update can
be highly ineﬃcient as sequentially generated conﬁgurations are strongly correlated, causing a signiﬁcant slowing down in the simulation dynamics. For certain classes
of models, this slowing down can be overcome by global
update methods8–14, where an extensive number of local
variables are changed in a single update. However, for
any generic model, it is highly challenging to design an
eﬃcient global update method.
Inspired by great developments in machine learning15,
in this work we propose a new approach to speed up the
MC simulation. The MC sampling process generates a
sequence of conﬁgurations in a Markov chain, which constitutes a massive set of data containing valuable information about the system. Meanwhile, machine learning
is a powerful technique to uncover unknown properties
in the data and make new predictions. Thus we expect
that machine learning can extract the information hidden in the Markov chain, which we then use to improve
the performance of MC simulation.
Speciﬁcally, we propose a new MC update method
applicable to generic statistical models, dubbed selflearning Monte Carlo (SLMC) method. The essence of
SLMC is to ﬁrst perform a trial simulation with local
update to obtain a sequence of conﬁgurations and their
weights, serving as training data, and then to learn a
rule that guides conﬁguration update in actual simulation. To demonstrate the power of SLMC, we study a
statistical model (see Eq. 1), for which no eﬃcient global
update scheme is known. We ﬁnd that in comparison to
the local update, SLMC signiﬁcantly reduces the autocorrelation time, especially near the phase transition.
Outline of SLMC
Before presenting our method, let
us recall that conﬁgurations in MC simulation can be
updated through a Markov process, where the transition
probability from conﬁguration A to B, P(A ! B), is
required to satisfy the detailed balance principle (DBP)6,
P(A ! B)/P(B ! A) = W(B)/W(A), where W is
the probability distribution of conﬁgurations.
methods can be roughly divided into two types: local
and global.
Local update is a general-purpose, model-independent
method, consisting of two steps.
First, one randomly
chooses a single site in the current conﬁguration and proposes a new conﬁguration by changing the variable on
this site. Second, one decides whether the proposed move
is accepted or rejected based on DBP. If accepted, the
next conﬁguration in Markov chain will be the new one;
otherwise it will be a copy of the current one. Clearly,
the way a local move is proposed in the ﬁrst step is completely general and does not use any knowledge of the
model. Local update works well for many systems, but
su↵ers heavily from the critical slowing down close to
phase transitions8,9. In such cases, the autocorrelation
time within the Markov chain ⌧becomes very large, and
in fact diverges with the system size L as ⌧⇠⌧0Lz at
critical points, where z is the dynamical exponent of MC
simulation.
To overcome the dramatic increase of autocorrelation time for local update, many global update methods
have been developed, such as Swendsen-Wang8, Wol↵9,
worm10, loop11,12 and directed loop13,14 algorithms. In
all these methods, variables on an extensive number of
sites are simultaneously changed in a single MC update,
thus reducing the dynamic exponent z signiﬁcantly. However, unlike the local update, here the proposal of a trial
conﬁguration and the determination of its acceptance are
intricately linked, because the proposed move already
takes into account the DBP. Thus global updates are ingeniously designed methods targeted for special models.
For a given generic model, it is very diﬃcult to design an
eﬃcient global update method.
From the comparison of local and global updates, we
conclude that a general-purpose MC update method that
can outperform local update must satisfy the following
requirements: (1) a large number of sites should be involved in each move that updates the current conﬁguration; (2) the proposal and the acceptance of moves should
be independent.
For systems at the critical point, we
further require the number of sites involved in each move
increase with the system size in order to reduce the dy-
Trial simulation by local update
trial Conf.
Simulating
FIG. 1. (color online) Schematic illustration of learning process (top panel) and simulating process (bottom panel) in
self-learning Monte Carlo.
namical exponent z in MC simulation.
Guided by these requirements, we now propose the detailed procedure of SLMC method. As shown in Fig. 1,
SLMC consists of four steps: (i) perform a trial MC simulation using local update to generate a large number of
conﬁgurations, which serve as training data; (ii) learn an
e↵ective Hamiltonian He↵from this training data; (iii)
propose moves according to He↵in the actual MC simulation; (iv) determine whether the proposed moves will
be accepted or rejected based on the detailed balance
principle of the original Hamiltonian H. Steps (i) and
(ii) constitute the learning process, whereas steps (iii)
and (iv) are repeated in the actual MC simulation to
calculate physical observables.
We further outline how to implement step (ii) and (iii)
in actual simulations for a model to be presented below.
We use machine learning15 in step (ii) to train an e↵ective
Hamiltonian, which can be eﬃciently simulated using a
global update method even though the original Hamiltonian cannot. Then step (iii) can be easily implemented
using this global update.
Model and results:
To demonstrate the power of
SLMC, we study a classical model on a 2D square lattice
where Si = ±1 is the Ising spin on site i. J is the nearest neighbor (NN) interaction and K is the interaction
among the four spins in the same plaquette. We set ferromagnetic interactions, i.e., J > 0 and K > 0. For any
ﬁnite J and K, there is a phase transition from paramagnetic phase at high temperature to ferromagnetic phase
at low temperature, which belongs to the 2D Ising universality class. For K = 0, this model reduces to the
standard Ising model which can be simulated eﬃciently
by the Wol↵method. However, for K 6= 0, no simple and
eﬃcient global update method is known. Below we will
show that SLMC method signiﬁcantly reduces the autocorrelation time near the critical point, using K/J = 0.2
TABLE I. The trained parameters { ˜Jn} of the e↵ective model
in Eq. 2, without and with setting ˜Jn = 0 (n ≥2).
Mean error
as an example. More results can be found in the Supplemental Material (SM).
As outlined before, the initial step of the SLMC is to
train an e↵ective Hamiltonian, He↵, from a sample of
conﬁgurations generated by local update based on the
original Hamiltonian in Eq. 1. We choose He↵to be a
generalized Ising Hamiltonian with two-body spin interactions over various ranges,
He↵= E0 −˜J1
SiSj −. . . ,
where hijin denotes the n-th NN interaction and ˜Jn is
the corresponding interaction parameter.
We now train He↵from the training sample by optimizing E0 and { ˜Jn}. In principle, this can be viewed as
an unsupervised learning process15,16, where a new statistical model He↵is trained using a subset of features
extracted from the conﬁgurations. However, by taking
advantage of knowing H for each conﬁguration, we can
more eﬃciently train He↵through a simple and reliable
linear regression. For the a-th conﬁguration in the sample, we compute its energy Ea [from Eq. 1] and all the
n-th NN spin-spin correlations Ca
hijin SiSj, which
serve as the actual training data. Then, E0 and { ˜Jn}
can be easily trained from a multi-linear regression of
Ea and {Ca
n}, Ea = P
n + E0. The results are as
shown in Table I (Train 1). It is clear that ˜J1 is dominant
and much larger than others, which implies we could set
˜Jn = 0 (n ≥2). And then, by a linear regression, we
can successfully extract the most optimized ˜J1 (Train 2
in Table I). It is found that the mean error is almost the
same to the case without setting ˜Jn = 0 (n ≥2), which
is expected since all ˜Jn (n ≥2) obtained from the multilinear regression are negligible.
Through this training
process, we conclude that only the nearest interaction is
relevant there, thus we only keep this term in the following simulations. We emphasize that this trained model
He↵only approximates the original one for the conﬁgurations that are statistically signiﬁcant in the sample, i.e.,
the ones near the free energy minimum. Thus He↵can be
regarded as an e↵ective model. We notice that, recently,
there are many other attempts to apply machine learning
to MC simulations17–22.
In addition, it should be addressed that the training of
He↵could be self-improved by a reinforced learning process. Usually, a good initial sample could be very hard to
generate using only local update, especially for systems
at the critical temperature Tc or with strong ﬂuctuation.
In this case, we ﬁrst train an e↵ective model He↵using
FIG. 2. (color online) Fitting of the distribution drawn from
a sample of conﬁgurations in a Markov chain. The green dots
represent conﬁgurations in the sample, for which the x axis
shows the feature of the nearest-neighbor spin-spin correlation
C1, and the y axis shows the energy (per site) E/N computed
from the original model in Eq. 1.
a simulation at temperature T > Tc, and then generate
another sample at Tc, using the self-learning update with
He↵learned from the ﬁrst iteration. Later, a more accurate He↵can be learned from the second-iteration sample.
In actual simulations, one can further improve this process by using more iterations, each done with a smaller
sample. More details can be found in the Supplemental
Through this iterative training process, we successfully arrive at the ﬁnal He↵. As shown in Fig. 2, He↵
(Self-Learning Fit) indeed ﬁts the energy of the conﬁgurations that are statistically signiﬁcant in the simulation.
In the main part of the ﬁgure, the data points are concentrated in the vicinity of the ﬁtted line, indicating that
trained He↵is indeed a good description of the low-energy
Following the procedure of SLMC, once training process is ﬁnished, cluster update with the Wol↵algorithm
according to He↵can be constructed. Then, the generated cluster update is accepted or rejected with a probability accounting for the energy di↵erence between the
e↵ective model and the original model. The probability
of accepting a cluster is as follows,
↵(A ! B) = min{1, e−β[(EB−Eeff
B )−(EA−Eeff
where A and B denote the conﬁgurations before and after
ﬂipping the cluster. EA and Ee↵
A denote the energies of a
conﬁguration A, for the original model in Eq. 1 and the
e↵ective model in Eq. 2, respectively. Derivation of Eq. 3
can be found in the SM. With Eq. 3, the detailed balance
is satisﬁed, and the SLMC is exact, despite the use of an
approximate e↵ective model in constructing the cluster.
To test the eﬃciency of the update scheme in SLMC,
we measure the autocorrelation time ⌧, which signiﬁes
FIG. 3. (color online) The decay of autocorrelation functions
as a function of MC steps, obtained using di↵erent update
algorithms. Inset, semi-log plot of the same data.
how correlated the MC conﬁgurations are in the Markov
chain (detailed relation of ⌧with the computational
complexity of MC algorithm can be found in SM). In
Fig. 3, we plot ⌧of the ferromagnetic order parameter
i Si|, where N is the number of sites, measured at each step of Markov chain, generated by di↵erent update algorithms on a square lattice of linear size
L = 40. The simulation is done at Tc, which is determined by the Binder ratio as shown in SM.
We compare results of the local update, the selflearning update using He↵and also a naive Wol↵-like
cluster update with the bare two-body J term from the
original model in Eq. 1 is used to construct a cluster. The
autocorrelation functions generated by all updates decay
with the MC steps ∆t, and autocorrelation time ⌧can
be obtained from ﬁtting in the form of e−∆t/⌧. Our results show that comparing to the local and naive cluster
updates, the self-learning update has the much shorter
In particular, at this system size, the self-learning
update is about 24-times faster than the local update,
while the naive Wol↵-like cluster update does not gain
much speed-up.
While Fig. 3 is an example of the better performance
of SLMC for a ﬁxed system size at Tc, we have further
collected the autocorrelation time ⌧at Tc for local and
self-learning updates with many di↵erent system sizes,
and hence extract the scaling behavior of ⌧with respect
to L. The results are shown in Fig. 4. The blue squares
are the ⌧L, i.e., autocorrelation time for local update,
and it follows ⌧L ⇠L2.2, well consistent with literature
on critical slowing down8,9. The green dots are the ⌧S,
i.e., autocorrelation time for self-learning update. For all
the tested systems size L 80, the ⌧S delivers a large
speedup about 20 times (see inset of Fig. 4 for clarity).
For very large system size, we ﬁnd ⌧S increases exponentially with L, ⌧S / eL/L0 (more details in SM). This is
FIG. 4. (color online) The scaling behavior of autocorrelation
times of local update ⌧L, SLMC update ⌧S, and the restricted
SLMC update ⌧R. Inset is a zooming for L < 80.
because of a ﬁnite energy di↵erence between the e↵ective
model in Eq. 2 and the original model in Eq. 1. Therefore,
the acceptance ratio of ﬂipping the whole cluster in Eq. 3
decreases exponentially as the length of cluster boundary
grows with increasing L, which renders the exponential
increase of the autocorrelation time. But this drawback
in SLMC can be easily remedied by simply restricting the
maximum size of the cluster in Wol↵algorithm23. With
this improvement, the averaged acceptance ratio can be
expected to be ﬁxed and SLMC should have the same
scaling function for autocorrelation time as local update,
⌧R = ⌧0Lz. However, by tuning the maximum size of
cluster, we can achieve a much smaller prefactor ⌧0, and
the optimized maximum cluster size can be automatically
self-learned via a model-independent procedure (more details in SM). This is indeed the case. As shown by the red
dots in Fig. 4, when the growth of the cluster is restricted
to an area within 40 lattice spacing, the autocorrelation
time ⌧R becomes ⌧R / L2.1, which obeys the same power
law as ⌧L, but with a prefactor about 10 times smaller
(More details about the design of this restricted SLMC
is provided in SM). Therefore, although SLMC still suffers from the critical slowing down in the thermodynamic
limit, we can gain a 10-fold speedup. That means SLMC
can achieve much larger system size than local update,
which helps to overcome the ﬁnite size e↵ect. Moreover,
for medium-size systems, the SLMC without restriction
can easily gain a 20-fold speedup, as shown by ⌧S.
Discussion: We now discuss the applicability of SLMC
method to a broader class of problems in statistical and
condensed matter systems. Besides spin systems, many
models of great interest may be transformed into spin
models with short-range interactions5,24, for which ef-
ﬁcient global update methods are available.
cases, SLMC can be readily implemented similar to our
model studied above. In particular, we expect SLMC to
be very useful for studying strongly correlated fermion
systems25,26, where no eﬃcient global update method
is currently known.
Moreover, by employing rapidlydeveloping machine learning techniques, SLMC method
may be able to learn conﬁguration update on its own,
without relying on a given e↵ective Hamiltonian. If realized, this will further increase the eﬃciency and versatility of SLMC.
SLMC may also bridge numerical and theoretical studies. The e↵ective Hamiltonian trained or learned from
the MC simulation may guide the theoretical study of
the original model. The beneﬁt is mutual: theoretical
understanding may improve the accuracy of the e↵ective
model and thus the performance of numerical simulation.
Acknowledgement: We thank Lanjun Wang and Xiao-
Yan Xu for helpful discussions. This work is supported
by the DOE Oﬃce of Basic Energy Sciences, Division
of Materials Sciences and Engineering under Award DE-
SC0010526. LF is supported partly by the David and Lucile Packard Foundation. ZYM is supported by the Ministry of Science and Technology (MOST) of China under
Grant No. 2016YFA0300502, the National Natural Science Foundation of China (NSFC Grants No. 11421092
and No. 11574359), and the National Thousand-Young-
Talents Program of China. JWL and QY thank the hospitality of Institute for Physics, Chinese Academy of Sciences where part of the work is performed.
⇤ ; 
†The ﬁrst two authors contributed equally to this work.
1 K. Binder, ed., The Monte Carlo Method in Condensed
Matter Physics .
2 M. E. J. Newman and G. T. Barkema, Monte Carlo Methods in Statistical Physics .
3 J. E. Gubernatis, ed., THE MONTE CARLO METHOD
IN THE PHYSICAL SCIENCES: Celebrating the 50th Anniversary of the Metropolis Algorithm, Vol. 690, AIP Conference Proceedings (AIP Publishing, Los Alamos, New
Mexico (USA), 2003).
4 D. Landau and K. Binder, A Guide to Monte Carlo Simulations in Statistical Physics .
7 W. K. Hastings, Biometrika 57, 97 .
8 R. H. Swendsen and J.-S. Wang, Phys. Rev. Lett. 58, 86
9 U. Wol↵, Phys. Rev. Lett. 62, 361 .
10 N. Prokof’ev, B. Svistunov, and I. Tupitsyn, Phys. Lett.
A 238, 253 .
11 H. G. Evertz, G. Lana, and M. Marcu, Phys. Rev. Lett.
70, 875 .
12 H. G. Evertz, Advances in Physics 52, 1 .
13 O. F. Sylju˚asen and A. W. Sandvik, Phys. Rev. E 66,
046701 .
14 F. Alet, S. Wessel, and M. Troyer, Phys. Rev. E 71, 036706
15 T. Hastie, R. Tibshirani, and J. Friedman, The Elements
of Statistical Learning .
16 G. Torlai and R. G. Melko, arXiv:1606.02718 .
17 J. Carrasquilla and R. G. Melko, arXiv:1605.01735 .
18 L. Wang, arXiv:1606.00318 .
19 G. Carleo and M. Troyer, arXiv:1606.02318 .
20 P. Broecker, J. Carrasquilla, R. G. Melko, and S. Trebst,
 
21 K. Chng, J. Carrasquilla, R. G. Melko, and E. Khatami,
 
22 H. J. Changlani, H. Zheng, and L. K. Wagner, The Journal
of chemical physics 143, 102814 .
23 G. T. Barkema and J. F. Marko, Phys. Rev. Lett. 71, 2070
24 F. Assaad and H. Evertz, in Computational Many-Particle
Physics, Lecture Notes in Physics, Vol. 739, edited by
H. Fehske, R. Schneider,
and A. Weiße pp. 277–356.
25 J. Liu, H. Shen, Y. Qi, Z. Y. Meng,
and L. Fu,
 
26 X.-Y. Xu, Y. Qi, J. Liu, Z.-Y. Meng, and L. Fu, In preparation.