Beyond Clicks: Modeling Multi-Relational Item Graph for
Session-Based Target Behavior Prediction
 
School of Computer Science and
Technology,
East China Normal University
Wei Zhang∗
 
School of Computer Science and
Technology,
East China Normal University
Shukai Liu
 
 
 
 
Hongyuan Zha
Georgia Institute of Technology
 
Session-based target behavior prediction aims to predict the next
item to be interacted with specific behavior types (e.g., clicking).
Although existing methods for session-based behavior prediction
leverage powerful representation learning approaches to encode
items’ sequential relevance in a low-dimensional space, they suffer
from several limitations. Firstly, they focus on only utilizing the
same type of user behavior for prediction, but ignore the potential
of taking other behavior data as auxiliary information. This is particularly crucial when the target behavior is sparse but important
(e.g., buying or sharing an item). Secondly, item-to-item relations
are modeled separately and locally in one behavior sequence, and
they lack a principled way to globally encode these relations more
effectively. To overcome these limitations, we propose a novel Multirelational Graph Neural Network model for Session-based target
behavior Prediction, namely MGNN-SPred for short. Specifically,
we build a Multi-Relational Item Graph (MRIG) based on all behavior sequences from all sessions, involving target and auxiliary
behavior types. Based on MRIG, MGNN-SPred learns global itemto-item relations and further obtains user preferences w.r.t. current
target and auxiliary behavior sequences, respectively. In the end,
MGNN-SPred leverages a gating mechanism to adaptively fuse
user representations for predicting next item interacted with target
behavior. The extensive experiments on two real-world datasets
demonstrate the superiority of MGNN-SPred by comparing with
state-of-the-art session-based prediction methods, validating the
benefits of leveraging auxiliary behavior and learning item-to-item
relations over MRIG.
CCS CONCEPTS
• Information systems →Personalization; • Computing methodologies →Neural networks.
∗Wei Zhang is the corresponding author. This work is supported by NSFC (61702190),
Shanghai Sailing Program (17YF1404500), and NSFC-Zhejiang (U1609220).
This paper is published under the Creative Commons Attribution 4.0 International
(CC-BY 4.0) license. Authors reserve their rights to disseminate the work on their
personal and corporate Web sites with the appropriate attribution.
WWW ’20, April 20–24, 2020, Taipei, Taiwan
© 2020 IW3C2 (International World Wide Web Conference Committee), published
under Creative Commons CC-BY 4.0 License.
ACM ISBN 978-1-4503-7023-3/20/04.
 
Sequential recommendation, graph neural networks, user behavior
ACM Reference Format:
Wen Wang, Wei Zhang, Shukai Liu, Qi Liu, Bo Zhang, Leyu Lin, and Hongyuan
Zha. 2020. Beyond Clicks: Modeling Multi-Relational Item Graph for Session-
Based Target Behavior Prediction. In Proceedings of The Web Conference
2020 (WWW ’20), April 20–24, 2020, Taipei, Taiwan. ACM, New York, NY,
USA, 7 pages. 
INTRODUCTION
Unlike conventional recommendation algorithms which get accustomed to modeling each user-item interaction separately ,
recent sequential recommendation approaches meet more realistic requirements for its ability of modeling user dynamic interest.
Session-based target behavior prediction is the one of the main
studied problem in this regard, aiming to predict the next item to
be interacted with a user under a specific type of behavior (e.g.,
clicking an item). Based on the predictions, information providers
can effectively deliver items to appropriate users and at the same
time, and users can quickly find the items what they actually want.
Note that we use session-based prediction and session-based recommendation interchangeably throughout this paper.
Early studies for this problem assume that the appearance of the
next item depends only on its previous item in the same
sequence. With such a strong assumption, they could only model
the last item in each sequence and ignore other information from
the sequence. To relieve this assumption, various methods adopt sequential models for session-based recommendation system to learn
behavior sequences. Recurrent Neural Networks (RNN) is commonly leveraged to obtain promising performance. The relevant
methods could roughly be attributed into two categories: singlesession based recommendation models and multi-session
based recommendation models . As the latter category requires the user ID of each behavior sequence should be known in
advance to link multiple sequences of the same user together, it
is not so universal than the first category due to privacy issues
and user scalability problem (e.g., a billion of active users each
day in WeChat). As such, we study session-based target behavior
prediction from the perspective of single-session based modeling.
 
WWW ’20, April 20–24, 2020, Taipei, Taiwan
Wen Wang and Wei Zhang, et al.
In the domain of single-session based behavior prediction, some
studies adopt attention mechanism and outperform the pioneering RNN based methods . Recent advances in
graph neural networks (GNN) further boost the performance
of session-based behavior prediction by modeling each sessionbased behavior sequence as a graph to achieve the state-of-the-art
performance . However, existing studies in this regard still
suffer from several limitations. Firstly, they focus on only using the
same type of user behavior as input for the next item prediction,
but ignore the potential of leveraging other type of behavior as
auxiliary information. This is particularly crucial when the target
behavior is sparse but important (e.g., buying or sharing an item).
Secondly, item-to-item relations are modeled separately and locally,
since both RNN based and GNN based recommendation models
only utilize one behavior sequence each time. It is intuitive that
abundant item-to-item relations are hidden in various behavior sequences. For example, if many other users who have bought item B
after buying item A, the relation between item A and B is especially
vital if a target user just bought item A.
To overcome these limitations, we propose a novel Multi-relational
Graph Neural Network model for Session-based target behavior
Prediction, namely MGNN-SPred for short. The target behavior
we focused on is the aforementioned sparse behavior beyond the
dense click behavior. MGNN-SPred jointly considers target behavior and auxiliary behavior sequences and explores global item-toitem relations for accurate prediction. Specifically, for the purpose
of considering the global item-to-item relations, we build a Multi-
Relational Item Graph (MRIG) based on the past behavior sequences
of all sessions. There might exist multiple relations between two
graph nodes, denoting target and auxiliary behavior types. Based
on MRIG, MGNN-SPred encodes global item-to-item relations into
node representations and further obtains local representations for
current target and auxiliary behavior sequences, respectively. In the
end, MGNN-SPred leverages a gating mechanism to adaptively fuse
the representations from target behavior sequence and auxiliary
behavior sequence to produce current user interest representation.
The main contributions of this work is summarized as follows:
1. We address the two limitations of existing methods by breaking the restriction of only using one type of behavior sequence
in session-based recommendation and exploring another type of
behavior as auxiliary information. We further construct the multirelational item graph for learning global item-to-item relations.
2. To effectively model MRIG w.r.t. target and auxiliary behavior
sequences, we develop the novel graph model MGNN-SPred which
learns global item-to-item relations through graph neural network
and integrates representations of target and auxiliary of current
sequences by the gating mechanism.
3. We carry out extensive experiments and demonstrate MGNN-
SPred achieves the best performance among strong competitors,
showing the benefits of overcoming the two limitations. As a byproduct, we release the source code1 of our model for relevant studies.
1 
RELATED WORK
Session-Based Behavior Prediction. In the literature, the pioneering study in the direction of single-session based recommendation first adopts a recurrent neural network based approach
with past interacted items as the input of different time steps for
session-based recommendation. Following that, improves the
model with data augmentation and the consideration of temporal user behavior shift. In addition to using RNN, also adopts
attention mechanism to capture a user’s sequential behavior and
its main purpose in a current session. Similarly, proposes a
novel attention mechanism to capture both the users’ long-term
interests in general and their short-term attention. More recently,
with the flourish Graph Neural Networks (GNN) methodologies,
 first separates each session sequence into different graphs and
uses graph neural networks to capture complex item transitions
in a specific graph. Afterwards, each session is represented as the
combination of the global preference and current interests of this
session using an attention network. is similar to , which
uses a multi-layered self-attention network as an alternative to
capture long-range dependencies between items within a session.
As discussed in the introduction, these existing relevant methods
suffer from two limitations which motivate the proposal of our
model in this paper.
Multi-Behavior Modeling. Multi-behavior modeling for recommender system aims to leverage other types of user behavior to
boost the recommendation performance on the target behavior. A
few studies have already investigated this scenario from different
perspectives. considers to leverage users’ social interactions
as auxiliary behavior for target behavior prediction by collective
matrix factorization (CMF) techniques. In a similar fashion, 
builds multiple matrices from user different behaviors which cover
user resharing behavior, user commenting behavior, user posting
behavior, etc. CMF is adopted to learn shared user representation
for recommendation as well. proposes multi-feedback Bayesian
personalized ranking (BPR), an extension of the classical Bayesian
personalized ranking approach and tailored for different user behaviors. It differentiates different preference levels between different
user behaviors in the sampling stage for ranking. also considers
the assignment different preference levels of various user behaviors. Instead of BPR, it incorporates this useful information into
element-wise alternating least squares learner. More recently, a
neural network approach is proposed by to learn representations for user-item interactions with different behaviors. Multi-task
learning is conducted to predict multi-behaviors with respect to a
certain item in a cascading way. Our work fundamentally differs
from the above studies since all of them assume the independence
of different user-item interactions while our study is more realistic
by considering to model user behaviors in a sequential setting.
Graph Neural Networks. Graph neural networks are the methods
used to generate representation of graph structured data, such as
social network and knowledge graph. extends Word2vec 
by proposing a model, DeepWalk, to learn node representations
based on sequences sampled from graphs. LINE encodes firstorder and second-order proximity of nodes into a low-dimensional
space. Recently, a surge of methods related on graph convolutional
networks (GCN) have been raised. presents a method with
Beyond Clicks: Modeling Multi-Relational Item Graph for Session-Based Target Behavior Prediction
WWW ’20, April 20–24, 2020, Taipei, Taiwan
Graph Neural Network
Target and auxiliary behavior sequences
Constructing sub-graph
User embedding
Bi-linear product
Ranking by score
Target sub-graph
Auxiliary sub-graph
Figure 1: The architecture of our model. We use a toy MRIG
and two current behavior sequences as input. The number
of recommended items is set to 2.
a graph-based analogue of convolutional architectures, which is
the original version of GCN. Later, a number of improvements,
extensions, and approximations of these spectral convolutions be
proposed . These approaches outperform other methods
based on random walks (e.g., DeepWalk and node2vec). With the
success in mind, an amount of GCN based methods are widely
applied in various domains such as recommendation systems .
But most GCN based methods require that all nodes in the graph
are present in each propagation step of GNN. Different from GCN,
GraphSAGE can train GNN with a minibatch setting. Inspired
by this, we design our GNN to learn from the constructed multirelational item graph for session-based behavior prediction.
TECHNOLOGIES
Problem Definition
For a session 𝑠in the session set 𝑆, let 𝑃𝑠= [𝑝𝑠
3, ..., 𝑝𝑠
denote the target behavior sequence and 𝑄𝑠= [𝑞𝑠
represent the auxiliary behavior sequence. Moreover, we construct
a Multi-Relational Item Graph G = (V, E) based on all behavior
sequences from all sessions, where V is the set of nodes in the
graph containing all available items and E is the edge sets involving
multiple types of directed edges. Each edge is a triple consisting of
the head item, the tail item, and the type of this edge. For instance, if
we construct the graph based on behaviors of sharing and clicking,
then an edge (𝑎,𝑏, share) ∈E means that a user shared item 𝑎and
subsequently shared item 𝑏, and an edge (𝑎,𝑏, click) ∈E means
that a user clicked item 𝑏after clicking item 𝑎. Given the above
notations, we formulate the problem as follows:
Problem 1 (session-based target behavior prediction). Given
a session 𝑠∈𝑆and its target and auxiliary behavior sequences 𝑃𝑠and
𝑄𝑠, along with MRIG G, the target of this problem is to learn a model
that can generate 𝐾items which are most likely to be interacted with
the user of the session in the next.
The overall architecture of the proposed MGNN-SPred is depicted
in Figure 1. The input to MGNN-SPred contains a Multi-Relational
Algorithm 1 Multi-relational item graph construction
Input: Session set 𝑆, both target and auxiliary behavior sequences
𝑃𝑠and 𝑄𝑠, ∀𝑠∈𝑆
Output: MRIG G = (V, E)
1: V ←∅, E ←∅
2: for 𝑠∈S do
V ←V ∪{𝑃𝑠 }
for 𝑖= 2 to |𝑃𝑠| do
V ←V ∪{𝑃𝑠[𝑖]}, E ←E ∪{(𝑃𝑠[𝑖−1], 𝑃𝑠[𝑖], target)}
V ←V ∪{𝑄𝑠 }
for 𝑖= 2 to |𝑄𝑠| do
V ←V∪{𝑄𝑠[𝑖]}, E ←E∪{(𝑄𝑠[𝑖−1],𝑄𝑠[𝑖], auxiliary)}
11: end for
Item Graph (MRIG) and the two types of behavior sequences. SR-
MRIG first learns item correlations from MRIG by graph neural
networks and encode them into item representations. Afterwards,
a user’s two behavior sequences are regarded as two sub-graphs
in the MRIG where the items in each sub-graph are connected
with a virtual node (“T” or “A” in Figure 1), respectively. Subsequently, SR-MRIG aggregates the nodes of each sub-graph to the
corresponding virtual node, thus getting the representation of each
behavior sequence. Finally, to fuse the two behavior representations
and obtain user preference representations, a gating mechanism is
adopted to adaptively decide the importance of different behaviors
and perform weighted summation over them. For the purpose of
recommendation, SR-MRIG calculates each item’s score by user
and item representations via a bi-linear product and use the scores
to rank them for recommendation.
Graph Construction
There are abundant relationships between items lying in users’ historical behaviors. If a user buys item 𝑎, and subsequently buys item
𝑏in the same session, it indicates that item 𝑎and item 𝑏probably
have some dependency, but does not reflect similarity too much
since a user less likely buys two very similar items within a short
duration. In comparison, if a user clicks item 𝑎, and subsequently
clicks item 𝑏, it indicates that item 𝑎and item 𝑏are probably with
large similarity. This is intuitive because a user usually browses a
number of similar items, and picks the most suitable one to buy.
We construct the multi-relational item graph by taking all items
as nodes and each type of behavior corresponds as one directed edge,
denoting different relationships between items. The process of constructing MRIG is shown in Algorithm 1. The both target and auxiliary behavior sequences from all sessions 𝑃𝑠and 𝑄𝑠(∀𝑠∈S) are
provided as input. The algorithm browses all behavior sequences,
collects all items in the sequences as the nodes of the graph, and constructs edges between two consequent items in the same sequence
with their behavior types as the edge types. After constructing the
graph with target and auxiliary behaviors, there are two types of
directional edges in the graph.
WWW ’20, April 20–24, 2020, Taipei, Taiwan
Wen Wang and Wei Zhang, et al.
Item Representation Learning
For each node 𝑣∈V, we use ¯e𝑣∈R|V | denotes its one-hot
representation. Before we feed the one-hot representations of nodes
into GNN, we first convert each of them into a low-dimensional
dense vector e𝑣∈R𝑑by a learnable embedding matrix E ∈R|V |×𝑑:
e𝑣= E⊤¯e𝑣.
After collecting the vectors e𝑣(∀𝑣∈V), we feed them with
MRIG G into GNN to generate global representations of nodes
g𝑣. The representations are expected to encode multiple item-toitem relations. We take node 𝑣as an example for illustration. First
of all, we collect neighbors of node 𝑣. Each node in the graph
has four types of neighboring node sets. According to the type
and direction, we name the four sets as “target-forward”, “targetbackward”, “auxiliary-forward”, and “auxiliary-backward”. Take
the type of “target” as an example, we obtain neighbor groups
corresponding to forward and backward directions as below:
Nt+(𝑣) = {𝑣′|(𝑣′, 𝑣, target) ∈E}, Nt−(𝑣) = {𝑣′|(𝑣, 𝑣′, target) ∈E}.
For the type of “auxiliary", its neighbor groups, i.e., Na+(𝑣) and
Na−(𝑣), are acquired by the same way.
At each step of representation propagation in GNN, we first
aggregate each group of neighbors by mean-pooling to obtain the
representation of this group, defined as below:
𝑣′∈Nt+(𝑣) h𝑘−1
The representations of the three remaining groups are calculated
in a similar fashion. Consequently, for the propose of joint considering different relations between items, we combine these four
representations of different neighbor groups by sum-pooling:
Finally, we update the representation of the center node 𝑣by:
After performing 𝐾iterations, we take the node representation
of the last step as the representation of the corresponding item:
g𝑣= h𝐾𝑣. In practice, we implement the GNN in a minibatch setting
which is inspired by to ensure scalability.
Sequence Representation Learning
We have tried different ways to compute the representation of
the virtual node for the target and auxiliary behavior sequences,
including using attention mechanism to assign different importance
weights to the nodes and performing sub-graph propagating for
several times. Empirically, we have found that simple mean-pooling
could already achieve comparable performance while retaining low
complexity. We denote the summarized representations of target
behavior sequence 𝑃and auxiliary behavior sequence 𝑄as p and q,
respectively, which are given as:
We argue that the two different types of behavior sequence representations might contribute differently when building an integrated
representation. This is because the auxiliary behavior is not exactly
the same with the target behavior to be predicted, and different
users might have different concentration on different behaviors.
For instances, some users might browse the item pages frequently
and click various items arbitrarily, and another users might only
click the items they want to buy. It is self-evident that the contributions of auxiliary behavior sequence for the next item prediction
are different in these situations. We define the following gating
mechanism to calculate the relative importance weight 𝛼:
𝛼= 𝜎(W𝑔[p; q]),
where [p; q] denotes the concatenation of the two representations,
𝜎is the sigmoid function, and W𝑔∈𝑅1×2𝑑is a trainable parameter
of our model. Finally, we obtain the user preference representation
o for the current session by the weighted summation of p and q:
o = 𝛼· p + (1 −𝛼) · q.
Model Prediction and Training
We further calculate the recommendation score 𝑠𝑣of each item
𝑣∈V using the item embedding e𝑣. A bi-linear matching scheme
is employed by:
𝑠𝑣= o⊤We𝑣,
where W ∈𝑅𝑑×𝑑is a trainable parameter matrix of our model.
To learn the parameters of our model, we apply a softmax function to normalize the scores s ∈𝑅|V | over all items to get the
probability distribution ˆy:
ˆy = softmax(s).
Backpropagation for neural networks is adopted to optimize the
model by minimizing the cross-entropy loss of the predicted probability distribution ˆy w.r.t. the ground truth. The loss function is
defined as follows:
𝑦𝑖log( ˆ𝑦𝑖) ,
where (𝑦1, · · · ,𝑦|V |) denotes the one-hot representation of the
ground truth. Note that L𝑅𝑆is easily extended to a minibatch loss.
EXPERIMENT
Table 1: Basic statistics of the datasets.
Time duration
2019/09/17~23
2014/04/01~09/30
#edge of target
#edge of auxiliary
Average length of target
Average length of auxiliary
#training data
#validation data
#test data
Beyond Clicks: Modeling Multi-Relational Item Graph for Session-Based Target Behavior Prediction
WWW ’20, April 20–24, 2020, Taipei, Taiwan
Experimental Setup
Dataset. We evaluate our model on two real-world datasets
named WeChat and Yoochoose. The Yoochoose dataset is obtained
from the RecSys Challenge 2015. The user behavior sequences in
the dataset are already segmented into sessions and all the users are
anonymized. The WeChat dataset is collected from Top Stories (看一
看) of WeChat, where we choose videos are regarded as items. We
randomly select one hundred thousand active users and collect their
behavior records for a duration of one week. Since the duration
is relatively short, we retain an entire behavior sequence of each
user by taking the sequence as a single session. In this paper, we
treat the behavior of purchase in Yoochoose and the behavior of
sharing in WeChat as the target behavior and regard the behavior
of clicking in both datasets as the auxiliary behavior.
Given a session with the target behavior sequence 𝑃= [𝑝1, 𝑝2, ...,
𝑝|𝑃|] and the auxiliary behavior sequence 𝑄= [𝑞1,𝑞2, ...,𝑞|𝑄|], we
adopt a similar way to construct training example as . That
is, we treat each item 𝑝𝑖, (𝑖≥2) as the label and use [𝑝1, 𝑝2, ...𝑝𝑖−1]
as input of target behavior. The treatment for the auxiliary behavior
is a little different, because a user is very likely to click an item
before buying or sharing it. To avoid the auxiliary input already
sees the labels, we only keep the clicked items before the target item
that is also bought or shared by the user. We set a maximum length
𝐿for both types of sequences and only keep the last 𝐿items longer
than the maximum length. Considering the fact that two datasets
have different average sequence length (see details in Table 1), we
set the maximum length 𝐿to 10 for WeChat and 3 for Yoochoose.
We discuss the impact of different maximum length in Section 4.4.3.
We split the datasets in a chronological order for evaluation,
consistent with real situations. We take the first 6/7 of datasets as
the training data, and use 1/3 of the remaining data as the validation
data to determine optimal hyper-parameter settings. MRIG used
throughout the experiments are constructed only based on training
data. The basic statistics of two datasets are summarized in Table 1.
Baselines. We compare the proposed model with several
strong competitors, including state-of-the-art graph neural network
based model for session-based recommendation.
• POP. It just recommends the top-n frequent items in the training
set regardless of behaviors in current sessions.
• Item-KNN . It recommends items most similar to the previously interacted items belonging to the same sessions.
• GRU4Rec . GRU4Rec is the pioneering RNN-based deep sequential model for session-based recommendation.
• NARM . It employs attention mechanism to capture different importance of each item according to their hidden states
obtained by RNN. A weighted integration of different item representations is performed to obtain final representation.
• STAMP . This model learns users’ general interest from the
long-term memory of session context and current interest from
the short-term memory of their last behaviors.
• SR-GNN and GC-SAN . Both of the graph-based models only use a current session to construct graph for applying
GNN to learn item representations. The difference is SR-GNN
represents each session by a traditional attention network while
GC-SAN is based on a multi-layered self-attention mechanism.
Table 2: Evaluation results of all methods.
Table 3: Results of not using auxiliary behavior sequences.
GRU4Rec (w/o a)
NARM (w/o a)
SR-GNN (w/o a)
Ours (w/o a)
• R-DAN. Reasoning-DAN (R-DAN) is used to model both
behavior sequences simultaneously.
• CoAtt. Co-Attention (CoAtt) with alternative calculation
for interactive attention is adopted for comparison.
• HetGNN. Heterogeneous graph neural network is applied
for recommendation, with two edge types and one node type.
It is worth noting only target behavior is considered by the above
baselines originally developed for session-based recommendation,
i.e., GRU4Rec, NARM, STAMP, SR-GNN, and GC-SAN. To make
the comparison more fairable, we revise these methods through
the following manner. We use their original forms to model the
target behavior sequence and auxiliary behavior sequence respectively, And afterwards, we utilize the proposed gating mechanism
to fuse the two types of representations as ours. In addition, we
also compare our model with the baselines in the situation of only
considering target behavior (see Table 3 for details).
Implementation Details. We implement our proposed model
based on Tensorflow. The dimension of item embedding is set to
64. Adam with default parameter setting is adopted to optimize the
model, with the mini-batch size of 64. GNN is ensured to run in
a minibatch setting and the depth 𝐾is set to 2. We terminate the
learning process with an early stopping strategy. We test different
forms of attention computation formulas for the baselines based
on attention mechanism and report their best results. The hyperparameters of baselines are turned on validation datasets as well.
Model Comparison
We consider the top-100 ranked predictions as recommended items.
Following , we adopt HR@100 (H@100), MRR@100 (M@100),
and NDCG@100 (N@100) to evaluate the recommendation performance of all models after obtaining their recommendation lists.
Table 2 shows the performance comparison between our model and
the adopted baselines. (1) The first part of the table corresponds
to the simple baselines. We observe their results are significantly
worse than other methods. (2) The second part involves standard
WWW ’20, April 20–24, 2020, Taipei, Taiwan
Wen Wang and Wei Zhang, et al.
Table 4: Ablation study of MGNN-SPredl.
Ours (w/o ae)
Ours (w/o asg)
Ours (w/o g)
sequential based methods for session-based recommendation. We
observe that their results keep at the same level, except for STAMP
on WeChat. It shows that: 1) taking session-based recommendation as a sequential modeling task can improve performance; 2)
although NARM and STAMP are more advanced approaches which
use attention mechanism to combine hidden representations of
different time steps, they do not show advantages on the sparse
behavior prediction problem we studied (not the same as previous
studies focusing on click prediction). (3) The third part is GNN based
models. SR-GNN and GC-SAN seem to be better than the sequential methods, and HetGNN further boost the performance. (4) The
second-to-last part involves approaches of learning two sequences
in other research domains. Their best results are worse than the
best performance of the above recommendation methods, which
suggests that considering the interaction of items in two sequences
might have no benefit for the studied problem. Finally, we can see
that our method outperforms all the other methods, demonstrating
the superiority of our model for session-based recommendation.
Impact of Auxiliary Behavior Sequence
We choose several representative methods in Table 3 to test whether
considering the auxiliary behavior sequence indeed boosts the
performance of session-based recommendation. The methods with
“(w/o a)" mean removing the auxiliary behavior sequence from
their full version. Firstly, we observe that our proposed model still
consistently achieves better performance in this situation. Moreover,
by comparing each method in Table 2 with its “(w/o a)" version, we
can find every method beats the one of “(w/o a)" with significant
margins. Based on the above illustrations, we demonstrate that
considering the auxiliary behavior sequence is indeed meaningful.
Model Analysis
Ablation Study. We conduct ablation studies of our model,
using “w/o ae" to denote removing the edges related to the auxiliary
behavior, using “w/o asg" to denote that not modeling the subgraph of the auxiliary behavior sequence in getting user preference
representation, and using “w/o g" to indicate merging the two
representations of the target and auxiliary behavior sequences by
simple summation instead of the gating mechanism. Table 4 shows
the corresponding results. We observe that the incorporation of
the auxiliary edge into the built graph is beneficial for the problem
by seeing “w/o ae". The integration of the auxiliary behavior with
target behavior sequence have a notable contribution by seeing “w/o
asg". Besides, we find that the performance becomes worse if we
do not use the gating mechanism to merge the two representations
of the target and auxiliary behavior sequences by investigating
“w/o g". Through the above comparison, we conclude the main
components in our model are effective.
Hit Rate@100
Depth of GNN
(a) WeChat
Hit Rate@100
Depth of GNN
(b) Yoochoose
Figure 2: Results of our model with different depths of GNN.
1 2 3 4 5 7
Hit Rate@100
Sequence length
(a) WeChat
1 2 3 4 5 7
Hit Rate@100
Sequence length
(b) Yoochoose
Figure 3: Results for different maximum lengths.
Impact of Depth of GNN. We test different depth settings
(from 0 to 3) about graph representation propagation. The depth
setting with value 0 means the our model does not use GNN and
could not learn any information from MRIG. Figure 2 shows the
corresponding results. We can see that the performance of depth 0 is
without doubt much worse than the results with depths from 1 to 3.
This comparison clarifies the significance of considering MRIG for
our model. Moreover, the performance becomes significantly better
when the depth grows from 1 to 2, showing modeling high-order
relation between items through GNN is indispensable. When the
number of graph representation propagation is larger than 3, the
representations of nodes might become less distinguishable, which
is not ideal for further improving the performance.
Impact of Sequence Length. We visualize the performance
variation with the change of the maximum behavior sequence
length 𝐿in Figure 3, where we set 𝐿in the range from 1 to 20.
As expected, with larger maximum sequence length at the beginning, the performance of both our model and SR-GNN grows to be
better. After reaching the peaks, the results slightly become worse,
and finally the variation trends turn to be stable. Overall, our model
outperforms SR-GNN consistently. Besides, we find the lengths
with the best performance are not the same in the two datasets.
This is due to the fact the average length of Yoochoose is much
smaller than that of WeChat, as shown in Table 1.
Beyond Clicks: Modeling Multi-Relational Item Graph for Session-Based Target Behavior Prediction
WWW ’20, April 20–24, 2020, Taipei, Taiwan
CONCLUSION
In this paper, we study session-based target behavior prediction.
Two limitations of existing relevant models are addressed: using
only target behavior for next item prediction and lacking a principled way to encode global item-to-item relations. To alleviate the
issues, MGNN-SPred is proposed, with the major novelties of building and modeling of the multi-relational item graph. In addition,
a gating mechanism is adopted to adaptively fuse target behavior
sequences and auxiliary behavior sequences into the user preference representations for the next item prediction. Comprehensive
experiments on two real-world datasets demonstrate MGNN-SPred
achieves the best performance and its design is rational.