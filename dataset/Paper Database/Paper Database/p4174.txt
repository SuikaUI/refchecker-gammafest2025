ISSN 1440-771X
Department of Econometrics and Business Statistics
 
Forecasting time series with
complex seasonal patterns using
exponential smoothing
Alysha M De Livera and Rob J Hyndman
December 2009
Working Paper 15/09
Forecasting time series with complex
seasonal patterns using exponential
Alysha M De Livera
Department of Econometrics and Business Statistics,
Monash University, VIC 3800
Australia.
Email: 
Division of Mathematics, Informatics and Statistics,
Commonwealth Scientiﬁc and Industrial Research Organisation,
Clayton, VIC 3168
Australia.
Email: 
Rob J Hyndman
Department of Econometrics and Business Statistics,
Monash University, VIC 3800
Australia.
Email: 
12 December 2009
JEL classiﬁcation: C22,C53
Forecasting time series with complex
seasonal patterns using exponential
A new innovations state space modeling framework, incorporating Box-Cox transformations, Fourier
series with time varying coefﬁcients and ARMA error correction, is introduced for forecasting complex
seasonal time series that cannot be handled using existing forecasting models. Such complex time
series include time series with multiple seasonal periods, high frequency seasonality, non-integer
seasonality and dual-calendar effects. Our new modelling framework provides an alternative to
existing exponential smoothing models, and is shown to have many advantages. The methods
for initialization and estimation, including likelihood evaluation, are presented, and analytical
expressions for point forecasts and interval predictions under the assumption of Gaussian errors are
derived, leading to a simple, comprehensible approach to forecasting complex seasonal time series.
Our trigonometric formulation is also presented as a means of decomposing complex seasonal time
series, which cannot be decomposed using any of the existing decomposition methods. The approach
is useful in a broad range of applications, and we illustrate its versatility in three empirical studies
where it demonstrates excellent forecasting performance over a range of prediction horizons. In
addition, we show that our trigonometric decomposition leads to the identiﬁcation and extraction of
seasonal components, which are otherwise not apparent in the time series plot itself.
Keywords: exponential smoothing, Fourier series, prediction intervals, seasonality, state space
models, time series decomposition.
Forecasting time series with complex seasonal patterns using exponential smoothing
Introduction
Many time series exhibit complex seasonal patterns. For example, Figure 1(a) shows the number
of retail banking call arrivals per 5-minute interval between 7:00am and 9:05pm each weekday.
There is a daily seasonal pattern with frequency 169 and a weekly seasonal pattern with frequency
169×5 = 845. If a longer series of data were available, there may also be an annual seasonal pattern.
Such multiple seasonal patterns are becoming more common with high frequency data recording.
Further examples where multiple seasonal patterns can occur include daily hospital admissions,
requests for cash at ATMs, electricity and water usage, and access to computer web sites.
Other time series (most commonly weekly data) have patterns with a non-integer frequency. Figure 1(b) shows the weekly United States ﬁnished motor gasoline products in thousands of barrels per
day. The time series clearly exhibits an annual seasonal pattern with frequency 365.25/7 ≈52.179.
In addition, some time series may have dual-calendar seasonal effects. Figure 1(c) shows the daily
electricity demand in Turkey over nine years, from 1 January 2000 to 31 December 2008. A clear
weekly seasonal pattern and an annual seasonal pattern can be observed in the time series. The
annual seasonality consists of two separate seasonal patterns with frequencies of 354.37 and 365.25,
following the Hijri and Gregorian calendars respectively. The Islamic Hijri calendar is based on lunar
cycles and is used for religious activities and related holidays. It is approximately 11 days shorter
than the Gregorian calendar. The Jewish, Hindu and Chinese calendars create similar effects that
can be observed in time series affected by cultural and social events (e.g., electricity demand, water
usage, and other related consumption data), and need to be accounted for in forecasting studies . Unlike the multiple periodicities seen with hourly and daily
data, these dual calendar effects involve non-nested seasonal periods.
Most existing time series models are designed to accommodate simple seasonal patterns with a small
integer-valued periodicity (such as 12 for monthly data or 4 for quarterly data). There are a few
models which attempt to deal with more complex seasonal patterns ,
Harvey et al. , Pedregal & Young , Taylor , Gould et al. , Taylor & Snyder
 , Taylor ), but none that is able to handle all of the complexities above.
In this paper we introduce a new innovations state space modeling framework based on a trigonometric formulation which is capable of tackling all of these seasonal complexities. Using the above
time series, we show that these trigonometric exponential smoothing models provide exceptional
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
5 minute intervals
Number of call arrivals
(a) Number of call arrivals handled on weekdays between 7am and 9:05pm from March 3, 2003, to
May 23, 2003 in a large North American commercial bank.
Number of barrels (Thousand barrels per day)
(b) US ﬁnished motor gasoline products supplied (thousands of barrels per day), from February 1991
to July 2005.
Electricity demand (MW)
(c) Turkish electricity demand data from January 1, 2000, to December 31, 2008.
Figure 1: Examples of complex seasonality showing (a) multiple nested seasonal periods, (b) non-integer
seasonal periods and (c) multiple non-nested and non-integer seasonal periods.
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
out-of-sample forecasting performances and offer an elegant decomposition of complex seasonal time
In Section 2 we discuss the existing exponential smoothing models, their weaknesses and their
inadequacy in handling complex seasonal patterns, and present a modiﬁed, generalized modeling
framework in order to overcome these problems. We then introduce in Section 3 the new trigonometric innovations state space modeling framework, which is capable of handling complex seasonal
patterns, as well as the usual single seasonal patterns, in a straightforward manner with fewer
parameters. Section 4 describes both analytical and simulated prediction distributions, as well as
point and interval predictions for the models. Section 5 presents the methods used for initialization
and estimation, including the derivation of maximum likelihood estimators and the methodology
used in applying the models. In Section 6, we explain the trigonometric formulation as a way of
decomposing complex seasonal time series, which cannot be decomposed using any of the existing
decomposition techniques. The proposed models are then applied to the US gasoline products data,
the call center data and the Turkey electricity demand data in Section 7, and it is shown that these
new trigonometric exponential smoothing models provide outstanding forecasting performances over
a range of forecasting horizons, compared to the existing models. Furthermore, using these applications, we demonstrate the decomposition of complex seasonal time series using our trigonometric
approach. Some conclusions are drawn in Section 8.
Exponential smoothing models for seasonal data
Traditional models
Single seasonal exponential smoothing methods are among the most widely used forecasting procedures in practice . These
methods have been shown to be optimal for a class of innovations state space models , thus allowing a stochastic modelling framework for exponential smoothing
including likelihood calculation, prediction intervals, model selection, and so on. The single source of
error or innovations approach is known to be simple yet robust, and has been shown to have several
advantages over the multiple source of error models .
The most commonly employed seasonal models in the innovations state space modeling framework
include the underlying models for the well-known Holt-Winters’ additive and multiplicative seasonal
exponential smoothing methods. However, these models are inadequate for handling complex
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
seasonal time series such as multiple seasonality, non-integer seasonality and dual-calender effects.
Taylor extended the single seasonal Holt-Winters’ model to accommodate a second seasonal
component in order to handle time series with two seasonal patterns. This requires a large number
of values to be estimated for the initial seasonal components, especially when the frequencies of
the seasonal patterns are high, which may lead to over-parameterization. Gould et al. 
attempted to reduce the over-parameterization of this model by dividing the longer seasonal length
into sub-seasonal cycles that have similar patterns. However, this model is relatively complex and can
only be used in modeling double seasonal patterns when one seasonality is a multiple of the other.
Using six years of British and French electricity demand data, Taylor illustrated that extended
additive seasonal versions of the above models to handle a third seasonal pattern can outperform
the double seasonal exponential smoothing models. However, none of these models can be used to
model complex seasonal patterns such as non-integer seasonality and calendar effects, or time series
with more than two non-nested seasonal patterns.
In addition, the non-linear versions of exponential smoothing models, although widely used, suffer
from some important weaknesses. Akram et al. showed that most non-linear seasonal
exponential smoothing models can be unstable, having inﬁnite forecast variances beyond a certain
forecasting horizon. Of the multiplicative error models which do not have this ﬂaw, Akram et al.
 proved that sample paths will converge almost surely to zero even when the error distribution
is non-Gaussian. Furthermore, for non-linear exponential smoothing models, analytical results for
the prediction distributions are not available.
The models used for exponential smoothing assume that the error process is serially uncorrelated.
However, the assumption of an uncorrelated error process does not always hold. In an empirical
study, using the Holt-Winters’ method for multiplicative seasonality, Chatﬁeld showed that
the error process is correlated and can be described by an AR(1) process. This was further illustrated
by Taylor in a study of electricity demand forecasting using a double-seasonal Holt-Winters’
multiplicative method. Gardner , Reid , and Gilchrist have also mentioned this
issue of correlated errors, in improving the forecast accuracy.
Modiﬁed models
We now consider various modiﬁcations to the standard exponential smoothing models to enable them
to handle a wider variety of seasonal patterns, and to deal with the problems raised above.
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
Extending non-linear exponential smoothing models to handle more than two seasonal patterns
may make these models unnecessarily complex, and the estimation and model selection procedure
may become cumbersome. Also, the problems with non-linear models that are noted above are
also a problem in any extended versions. Consequently, rather than allow non-linear forms, we
restrict attention to linear homoscedastic models but allow some types of non-linearity using Box-Cox
transformations . The notation y(ω)
is used to represent Box-Cox transformed
observations with the parameter ω, where yt is the observation at time t.
We can extend exponential smoothing models to accommodate T seasonal patterns as follows.
= ℓt−1 + φbt−1 +
ℓt = ℓt−1 + φbt−1 + αdt
bt = φbt−1 + βdt
t−mi + γidt
θiϵt−i + ϵt,
where m1,..., mT denote the seasonal periods, ℓt and bt represent the level and trend components
of the series at time t, respectively, s(i)
represents the ith seasonal component at time t, dt denotes
an ARMA(p,q) process and ϵt is a Gaussian white noise process with zero mean and constant
variance σ2. The smoothing parameters are given by α,β,γi for i = 1,..., T, and φ is the dampening
parameter, which gives more control over trend extrapolation when the trend component is damped
 .
The notation BATS(p,q, m1, m2,..., mT) is used for these models. B stands for the Box-Cox transformation, A stands for the ARMA residuals, T stands for the trend component in the model and
S stands for the seasonal components. The arguments indicate the ARMA parameters (p and q)
and the seasonal periods (m1,..., mT). For example, BATS(0,0, m1) with φ = 1 and ω = 1 represents the underlying model for the well-known Holt-Winters’ additive single seasonal method.
The double seasonal Holt-Winters’ additive seasonal model described by Taylor is given by
BATS(0,0, m1, m2) with φ = 1 and ω = 1, and that with the residual AR(1) adjustment in the model
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
of Taylor is given by BATS(1,0, m1, m2). The Holt-Winters’ additive triple seasonal
model with AR(1) adjustment in Taylor is given by BATS(1,0, m1, m2, m3).
The BATS model is the most obvious generalization of the traditional exponential smoothing models
to allow for multiple seasonal periods. However, it is not capable of handling non-integer seasonality,
and it suffers from a very large number of parameters that require estimation; the initial seasonal
component alone contains m1 + m2 + ··· + mT parameters. This becomes a huge number of values
when the frequencies of the seasonal patterns are high. For example, for the call center data shown
in Figure 1(a), 169 + 845 = 1014 initial seasonal values must be estimated.
Trigonometric exponential smoothing models for seasonal data
Consequently, we introduce a new trigonometric representation of seasonal components based on
Fourier series. We could replace the equation for s(i)
in the BATS model with
j,t cos(λ(i)
j t) + β(i)
j,t sin(λ(i)
j,t = α(i)
j,t−1 + κ(i)
j,t = β(i)
j,t−1 + κ(i)
where κ(i)
1 and κ(i)
2 are the smoothing parameters and λ(i)
= 2πj/mi. This is an extended, modiﬁed
single source of error version of a single seasonal multiple source of error representation suggested
by Hannon et al. , and is equivalent to index seasonal approaches when ki = mi/2 for even
values of mi, and when ki = (mi −1)/2 for odd values of mi. But most seasonal terms will require
much smaller values of ki, thus reducing the number of parameters to be estimated.
In the single seasonal multiple source of error setting , an alternative, but equivalent
formulation of representation (2) is preferred , which can be obtained by
re-parameterizing the single seasonal multiple source of error version of (2) using
j,t = s(i)
j,t cos(λ(i)
j t) −s∗(i)
j,t = s(i)
j,t sin(λ(i)
j t) + s∗(i)
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
For our modiﬁed multiple seasonal single source of error formulation, it can be shown (see Appendix A) that the above re-parametrization leads to the following:
j,t = s(i)
j,t−1 cosλ(i)
j,t−1 sinλ(i)
1 cos(λ(i)
j t) + κ(i)
2 sin(λ(i)
= −sj,t−1 sinλ(i)
j,t−1 cosλ(i)
2 cos(λjt) −κ(i)
1 sin(λjt)
This then gives rise to a heteroscedastic error process. However, to be consistent with the homoscedastic nature of the traditional additive innovations state space models, the following representation is
employed in our models:
j,t = s(i)
j,t−1 cosλ(i)
j,t−1 sinλ(i)
= −sj,t−1 sinλ(i)
j,t−1 cosλ(i)
In the single seasonal multiple source of error setting, (2) is equivalent to (4) . In
our multiple seasonal single source of error setting, the seasonal representations (2) and (4) are
equivalent only when the smoothing parameters are equal to zero. This then reduces to a standard
Fourier series representation when the initial state values s(i)
j,0 and s∗(i)
j,0 are set to Fourier series
coefﬁcients for the ith seasonal component. Then, following Koopman & Lee , it can be shown
that s∗(i)
dt . Thus s∗(i)
is proportional to the rate of growth in s(i)
j,t for each seasonal component.
Hence, in the representation (4), the term s(i)
j,t could be deﬁned as the stochastic level term of the ith
seasonal component and the term s∗(i)
as a stochastic auxiliary variable describing the growth in the
level of the ith seasonal component that is needed to describe the change in the seasonal component
over time.
Replacing the seasonal component s(i)
in (1) with that given by (4), a new class of exponential
smoothing models, termed trigonometric exponential smoothing models, is obtained. The notation
TBATS(p,q,{m1, k1},{m2, k2},...,{mT, kT}) is used for these trigonometric models. These models
require the estimation of 2(k1 + k2 + ··· + kT) initial seasonal values, which is expected to greatly
reduce the number of parameters required compared to BATS models. The use of trigonometric
functions also allows the modelling of non-integer seasonal frequencies.
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
Point forecasts, prediction distributions and interval predictions
The BATS and TBATS models can be written in the following linear innovations state space form:
= w ′xt−1 + ϵt
xt = F xt−1 + gϵt,
where w ′ is a row vector, g is a column vector, F is a matrix and xt is the unobserved state vector at
To obtain the matrices in (5a), we ﬁrst deﬁne ˜s(i)
2,t,...,s(i)
ki,t), ˜s∗(i)
1,t ,s∗(i)
2,t ,...,s∗(i)
t , ˜s∗(i)
)′; let 1r = (1,1,...,1) and 0r = (0,0,...,0) be row vectors of length r; let γ(i)
1 1ki, γ(i)
2 1ki, γ(i) = (γ(i)
ϕ = (ϕ1,ϕ2,...,ϕp) and θ = (θ1,θ2,...,θp); let Ou,v be a
u × v matrix of zeros, let Iu,v be a u × v rectangular diagonal matrix with element 1 on the diagonal,
and let a(i) = (1ki,0ki)′. We shall also need the matrices
i=1 Ai, where C (i) and S(i) are ki × ki diagonal matrices with elements cos(λ(i)
j ), respectively, for j = 1,2,..., ki and i = 1,..., T, and where
denotes the direct sum of
the matrices. Let τ = 2
Then the TBATS model can be written in the form (5a) with
ℓt, bt, s(1)
′,..., s(T)
′, dt, dt−1,..., dt−p+1,ϵt,ϵt−1,...,ϵt−q+1
1,φ, a(1)′,..., a(T)′,ϕ,θ
α,β,γ(1)′,...,γ(T)′,1,0p−1,1,0q−1
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
These matrices are for the TBATS model when all of the components are present in the model. When
a component is omitted, the corresponding terms in the matrices must be omitted.
The state space form of the BATS model can be obtained by letting s(i)
t−1,...,s(i)
t−(mi−1))′,
a(i) = (0mi−1,1)′, γ(i) = (γi,0mi−1)′, A =
i=1 ˜Ai, and by replacing 2ki with mi in the matrices
presented above for the TBATS models.
Let ϑ be a vector of all parameters to be estimated in the model, consisting of the smoothing
parameters and the Box-Cox parameter, and let n be the length of the time series, h the length of the
forecast horizon, and yn+h|n ≡yn+h | xn,ϑ the prediction distribution of a future value of the series
given the model, its estimated smoothing parameters and the state vector at the last observation.
A Gaussian assumption for the errors implies that y(ω)
n+h|n is also normally distributed, with mean
n+h|n) and variance V(y(ω)
n+h|n) given by the equations :
n+h|n) = w ′Fh−1xn
where cj = w ′F j−1g. Point forecasts and forecast intervals may be obtained using the inverse
Box-Cox transformation. Point forecasts obtained this way are equal to the median of the conditional
probability density of yn+h|n. Forecast intervals retain the required probability coverage under
back-transformation because the Box-Cox transformation is monotonic.
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
Estimation and model selection
Maximum likelihood estimation
The Box-Cox parameter and smoothing parameters, ϑ, and the initial states, x0, can be estimated
from the observed data y = (y1,..., yn) by maximizing the likelihood. If ϵt ∼N(0,σ2) and x0 and ϑ
are known, then y(ω)
∼N(w ′xt−1,σ2). Thus,
| xt−1,ϑ) =
p(yt | x0,ϑ) = p(y(ω)
Therefore, the log likelihood is given by
2 log(2πσ2) −
The maximum likelihood estimate of the error variance is obtained by letting the partial derivative of
L with respect to σ2 be equal to zero, giving
Then, substituting (8) into (7), multiplying by −2, and omitting constant terms, we obtain
L ∗(ϑ, x0) = nlog
This quantity can be minimized to obtain maximum likelihood estimates.
To start the optimization, we need some initial estimates of x0 and ϑ. If a Box-Cox transformation is
required for the data, an initial value for the Box-Cox parameter ω has to be approximated ﬁrst. This
could be done by inspection of the data under different transformations or simply by letting ω = 0
to start with. (We found this choice led to better model selection and forecasting than other initial
values for ω.)
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
Let m∗= ⌊max(m1,..., mT)⌋. Then we compute a 2 × m∗moving average through the ﬁrst few
seasons of transformed data. Denote this by {ft} (t = m∗/2 + 1, m∗/2 + 2,...), and let zt = y(ω)
For TBATS models, the seasonal component is then approximated using
j cos(λ(i)
j t) + b(i)
j sin(λ(i)
where ˆa(i)
are estimated by regressing zt against the trigonometric terms. The initial seasonal
states for the ith seasonal component can then be set to ˆa(i)
j . For BATS models, we follow the
same procedure but replace ki with mi/2 for even frequencies and (mi −1)/2 for odd frequencies in
equation (10), in order to obtain ˆa(i)
j . Using these values, we deﬁne the initial seasonal state
estimates as ˆz(i)
j cos(λ(i)
j t) + ˆb(i)
j sin(λ(i)
The initial level and trend components can be approximated by computing a linear regression on the
ﬁrst m∗deseasonalized values, against a time variable t = 1,..., m∗. Then set the initial level to be
the intercept of this regression and let the initial trend be equal to the slope. For BATS models with
T = 1, this is equivalent to the procedure proposed by Hyndman et al. .
These initial state values can then be optimized along with the Box-Cox parameter and the smoothing
parameters. In practice, the initial seasonal states can only be optimized when there are a small
number of values. For this reason, when handling high frequency data, the initial seasonal values can
not be optimized in the BATS model. One of the advantages of the TBATS model is that there are
fewer initial seasonal values, and hence the initial seasonal states may be optimized.
For the BATS model, the seasonal values are constrained when optimizing, so that each seasonal
component sums to zero. For both models, using the matrices and vectors D, g and w from equation
(5a), the smoothing parameters are restricted to the forecastibility region given by Hyndman et al.
 . Restricting the parameters in this way, rather than restricting them to the usual parameter
region of , serves two purposes. First, it guarantees stable forecasts. Second, if the usual
parameter region lies within the forecastibility region, then restricting the parameters to the usual
region may lead to inferior forecasts as the maximum likelihood parameters may lie outside that
region. In addition, ARMA coefﬁcients are restricted to the causality and invertibility regions.
Model selection
In this paper, the AIC = L ∗( ˆϑ, ˆx0)+2K is used for choosing between the models, where K is the total
number of parameters in ϑ plus the number of free states in x0, and ˆϑ and ˆx0 denote the estimates
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
of ϑ and x0. When one of the smoothing parameters takes the boundary value 0, the value of K is
reduced by one as the model simpliﬁes to a special case. For example, if β = 0, then bt = b0 for all t.
Similarly, when either φ = 1 or ω = 1, the value of K is reduced by one in each instance to account
for the resulting simpliﬁed model.
In an empirical study, Billah et al. indicated that information criterion approaches, such as
the AIC, provide the best basis for automated model selection, relative to other methods such as the
prediction-validation method. Alternative information criteria such as the AICc or BIC may also be used.
Selecting the number of harmonics ki in the trigonometric models
The forecasts from the TBATS model depend on the number of harmonics ki used for the ith seasonal
component. It would be impractical to consider all possible combinations when searching for the
optimal ki combination. Instead, the following procedure was used to obtain the number of harmonics
for the applications in this paper. In practice we have found that this approach leads to good models
and further computational effort rarely leads to much improvement.
Using the ﬁrst few seasons, we use multiple linear regression applied to (10) to ﬁnd the trigonometric
coefﬁcients. Starting with a single harmonic, we gradually add harmonics, testing the signiﬁcance of
each one using F-tests. Let k∗
i be the number of signiﬁcant harmonics (with p < 0.001 ) for the ith
seasonal component. We then ﬁt the required model to the data with ki = k∗
i , and compute the AIC.
Considering one seasonal component at a time, we repeatedly ﬁt the model to the estimation sample,
gradually increasing ki but holding all other harmonics constant for each i, until the minimum AIC is
Selecting the ARMA orders p and q for the models
In selecting a model, suitable values for the ARMA orders p and q must also be found. We do this
using a two-step procedure. First, a suitable model with no ARMA component is selected. Then
the automatic ARIMA algorithm of Hyndman & Khandakar is applied to the residuals from
this model in order to determine the appropriate orders p and q (we assume the residuals are
stationary). The selected model is then ﬁtted again but with an ARMA(p,q) error component. The
ARMA component is only retained if the resulting model has lower AIC than the model with no ARMA
component.
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
Decomposition of complex seasonal time series
Decomposing a time series into constituent latent subseries is a vital aspect in practical, retrospective
time series analysis such as deseasonalisation, analyzing seasonal effects and isolating latent, quasicyclical components . None of the existing decomposition
methods are capable of handling all of the seasonal complexities described in this paper, such as
multiple seasonality, non-integer seasonality, and dual-calendar effects. Our trigonometric formulation
offers an elegant way of decomposing complex seasonal time series into trend, seasonal and irregular
components. In particular, it leads to the identiﬁcation and extraction of one or more seasonal
components, which may not be apparent in the time series plots themselves.
Using our trigonometric models for multiple seasonal time series, the overall seasonal component
can be decomposed into several individual seasonal components with different frequencies. Each of
these individual seasonal components are obtained by s(i)
of the model and the trend component
is obtained by ℓt. Extracting the trend and seasonal components then leaves behind a covariance
stationary irregular component, denoted by dt in the model.
In decomposing time series, TBATS approach has several important advantages over BATS. First, seasonal components obtained from BATS model are not normalized. Although normalized components
may not be necessary if one is only interested in the forecasts and the prediction intervals, when
the seasonal component is to be analyzed separately or used for seasonal adjustment, normalized
seasonal components are required . Thus, BATS
models have to be modiﬁed, so that the seasonal components are normalized for each time period,
before using them for time series decomposition. In contrast, the trigonometric terms in TBATS
models do not require normalization, and so are more appropriate for decomposition.
Second, in estimating the seasonal components using BATS, a large number of parameters are
required, which often leads to noisy seasonal components. In contrast, a smoother seasonal decomposition is expected from TBATS where the smoothness of the seasonal component is controlled by
the number of harmonics used.
In addition, BATS model cannot be used to decompose time series with non-integer seasonality and
dual calendar effects.
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
Empirical analysis
Application to weekly US gasoline data
Figure 1(b) shows the number of barrels of motor gasoline product supplied in the United States,
in thousands of barrels per day, from February 1991 to July 2005. These data were part of the
Transportation competition. (See www.forecastingprinciples.com/files/T_competition_new.
pdf for details.) The data are observed weekly and show a strong annual seasonal pattern. The
length of seasonality of the time series is m1 = 365.25/7 ≈52.179. The time series exhibits an
upward additive trend and an additive seasonal pattern; that is, a pattern for which the variation
does not change with the level of the time series.
The data consist of 745 observations and were split into two segments: an estimation sample
period (484 observations) and test sample (261 observations). The estimation sample was used to
estimate the initial values, select the appropriate number of harmonics, and estimate the smoothing
parameters. Following the procedure for ﬁnding the number of harmonics to start with, it was found
that only one harmonic was highly signiﬁcant. Hence, starting with k∗
1 = 1, the initial values were
estimated using the heuristic method. The model was then ﬁtted to the whole estimation sample of
484 values and optimized to minimize equation (9). The values of the AIC decreased until k1 = 7,
then started to increase.
In order to investigate the out-of-sample performance, we computed the Root Mean Square Error
(RMSE), deﬁned as
(yt+h −ˆyt+h|t)2,
where p = 261 is the length of the test sample, n = 484 is the length of the estimation sample
and h is the length of the forecast horizon. Further analysis showed that changing the value of k1
from 7 generated worse out of sample results, indicating that the use of the AIC as the criterion for
this model selection procedure is a reasonable choice. Hence, the TBATS(0,0,{365.25/7,7}) model
with ω = φ = 1 was ﬁtted. As a second step, ARMA models were ﬁtted to the residuals with p,q
combinations up to p = q = 5, and it was discovered that the TBATS(0,1,{365.25/7,7}) model
minimizes the AIC.
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
The BATS model was considered next, with m1 = 52, and, following the above procedure, it was
discovered that the BATS(0,1,52) model with ω = φ = 1 minimized the AIC. Figure 2 shows the
out-of-sample RMSEs obtained for the two models, and it can be seen that the trigonometric model
clearly performs better for all lead times.
This result can be explained by some of the advantages the trigonometric representation has over the
traditional seasonal representation. First, the BATS model cannot handle the non-integer frequency,
and hence it had to be rounded off to the nearest integer. Second, the BATS model may be overparameterized, as 52 initial seasonal values have to be estimated for the model. Third, these initial
values cannot be optimized along with the smoothing parameters, due to the high dimensionality of
the optimization space. These problems are overcome in the trigonometric formulation, which allows
for non-integer frequencies and requires fewer initial values to be estimated for the initial seasonal
component, hence allowing them to be optimized.
Decomposition of the Gasoline time series obtained using the ﬁtted TBATS model is shown in Figure 3.
The vertical bars at the right side of each plot are of equal heights but plotted on different scales;
thus providing a comparison of the size of each component. The trigonometric formulation in TBATS
models allows for more randomness to be eliminated from the seasonal component, yet allowing for
those inﬂuential bumps to be revealed.
G G G G G G G G G G G G G G G G G
G G G G G G G G G G G G G
G G G G G G G G G G G G
Figure 2: Out-of-sample
BATS(0,1,52)
TBATS(0,1,{365.25/7,7}).
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
Figure 3: Trigonometric decomposition of the US gasoline data.
Application to call center data
The call center data shown in Figure 1(a) consist of 10,140 observations, that is 12 weeks of data
starting from 3 March 2003 . They contain a daily seasonal pattern with
frequency 169 and a weekly seasonal pattern with frequency 169 ∗5 = 845. The ﬁtting sample
consists of 7,605 observations (9 weeks). The trend appears to be close to zero, and hence the growth
rate bt was omitted from the models.
The model selection procedure led to the model TBATS(3,1,{169,29},{845,15}) with ω = φ = 1
and β = b0 = 0. The BATS model, with m1 = 169 and m2 = 845, was then considered. The model
selection procedure led to the BATS(3,0,169,845) model with ω = 0.317, φ = 1 and β = b0 = 0
was chosen. 
TBATS(3,1,{169,29},{845,15})
The decomposition obtained from TBATS is shown in Figure 5, which clearly exhibits strong daily
and weekly seasonal components. The weekly seasonal pattern seems to be evolving rapidly with
time while the daily seasonal pattern stays relatively more constant. As is seen from the time series
plot itself, the trend component is very small in magnitude compared to the seasonal components.
Application to the Turkey electricity demand data
The Turkey electricity demand data shown in Figure 1(c) have a number of important features that
should be reﬂected in the model structure. Three seasonal components with frequencies m1 = 7,
m2 = 354.37 and m3 = 365.25 exist in the series. The sharp drops seen in the seasonal component
with period 354.37 are due to the Seker and Kurban religious holidays, which follow the Hijri
calendar, while those seen in the seasonal component with frequency 365.25 are due to national
holidays which follow the Gregorian calendar.
In this study, the data, which cover a period of 9 years, are split into two parts: a ﬁtting sample of
n = 2191 observations (6 years) and a post-sample period of p = 1096 observations (3 years). The
order selection procedure was followed and the TBATS(3,2,{7,3},{354.37,23},{365.25,3}) model
with ω = 0.00165 and φ = 1 was selected.
None of the existing exponential smoothing models can handle this time series; however, the BATS
model was applied with the frequencies rounded off to the nearest integer , which is expected to affect the accuracy of the forecasts. In addition, this model
requires the estimation of 354 + 365 + 7 = 726 values for the seasonal component alone.
Figure 6 shows the exceptional post-sample forecasting performance of the TBATS model compared
to the BATS model.
The decomposition of the series obtained by using the chosen TBATS model, is shown in Figure 7.
The ﬁrst panel shows the transformed observations and the second shows the trend component. The
third panel shows the weekly seasonal component which does not seem to have much variation
with time. The fourth panel shows the overall annual component, which is composed of a seasonal
component based on the Hijri calendar with frequency 354.37 and a seasonal component based on
the Gregorian calendar with frequency 365.25, which are shown separately in the ﬁfth and the sixth
panels respectively.
The rather wiggly seasonal components has probably occurred due to the use of a large number of
harmonics in each seasonal component. This is necessary to capture the sharp drops seen in the
time series plot. If we assume that the stochastic seasonal component is augmented by deterministic
holiday effects, we can reduce the number of harmonics required by using dummy variables in
handling those sharp drops which occur due to holidays. Table 1 gives the dates of the holidays
from the Hijri and Gregorian calendars. Seker is a three-day festival when sweets are eaten to
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
Figure 6: Out-of-sample results for the Turkey electricity demand data using BATS(0,0,7,354,365)
and TBATS(3,2,{7,3},{354.37,23},{365.25,3})
Figure 7: Trigonometric decomposition of the Turkey electricity demand data.
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
celebrate the end of the fast of Ramadan. Kurban is a four-day festival when sacriﬁcial sheep
are slaughtered and their meat distributed to the poor. In addition, there are national holidays
which follow the Gregorian calendar as shown in the table. Using a trend component, a seasonal
component and holiday dummy variables, regression was performed on the transformed y(ω)
j cos(λ(i)
j t) + b(i)
j sin(λ(i)
j t) was used in capturing the multiple seasonality
with k1 = 3, k2 = k3 = 1. The estimated holiday effect was then removed from the series and the
remainder was decomposed using TBATS to achieve the decomposition shown in Figure 8.
Religious holidays
Seker holiday
Kurban holiday
National holidays
08 Jan–10 Jan
16 Mar–19 Mar
01 Jan, 23 Apr, 19 May, 30 Aug, 29 Oct
27 Dec–29 Dec
16 Dec–18 Dec
05 Mar–08 Mar
01 Jan, 23 Apr, 19 May, 30 Aug, 29 Oct
05 Dec–07 Dec
22 Feb–25 Feb
01 Jan, 23 Apr, 19 May, 30 Aug, 29 Oct
25 Nov–27 Nov
11 Feb–14 Feb
01 Jan, 23 Apr, 19 May, 30 Aug, 29 Oct
14 Nov–16 Nov
01 Feb–04 Feb
01 Jan, 23 Apr, 19 May, 30 Aug, 29 Oct
03 Nov–05 Nov
20 Jan–23 Jan
01 Jan, 23 Apr, 19 May, 30 Aug, 29 Oct
23 Oct–25 Oct
10 Jan–13 Jan
01 Jan, 23 Apr, 19 May, 30 Aug, 29 Oct
Table 1: The dates of Turkish holidays between 1 January 2000 to 31 December 2006.
The fourth panel shows the overall annual component, which comprises the Hijri seasonal effect
(ﬁfth panel) and the Gregorian seasonal effect (sixth panel). It is seen that this now provides a much
smoother seasonal decomposition and only one harmonic is required for each seasonal component
(i.e., k2 = k3 = 1) in capturing seasonal calendar effects. This analysis demonstrates the capability of
our trigonometric decomposition in extracting those seasonal components which are otherwise not
apparent in graphical displays. Existing decomposition techniques are unable to handle such complex
seasonalities.
In forecasting complex seasonal time series with such deterministic effects, both BATS and TBATS
models may be extended to accommodate regressor variables, allowing additional information to be
included in the models.
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
Figure 8: Trigonometric decomposition of the regressed Turkey electricity demand data.
Concluding remarks
A new state space modeling framework, based on the innovations approach, is developed for
forecasting time series with complex seasonal patterns which cannot be forecast using any current
forecasting approaches. The new approach not only offers an alternative to both linear and non-linear
traditional exponential smoothing models, but also has many advantages and provides additional
options, some of which are not seen in any of the existing forecasting approaches. The new approach
is also capable of decomposing and forecasting time series with multiple seasonality, high frequency
seasonality, non-integer seasonality and dual calendar effects.
The superiority of the new modeling framework in handling such seasonal patterns is illustrated in
three empirical studies, where it is shown to greatly improve the out-of-sample forecasting accuracy.
It is also shown that our trigonometric approach offers an elegant way of decomposing complex
seasonal time series, which cannot be decomposed using any of the existing methods. Table 2
demonstrates that the trigonometric approach requires substantially fewer values to be estimated
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
than traditional seasonal exponential smoothing models in all three applications. Moreover, these
models also overcome the weaknesses of the existing exponential smoothing models, such as the
instability of non-linear models and correlated errors.
Table 2: Number of estimated parameters for each model in each application.
No.parameters
Gasoline data
BATS(0,1,52)
TBATS(0,1,{365.25/7,7})
Call center data
BATS(3,0,169,845)
TBATS(3,1,{169,29},{845,15})
Electricity demand data
BATS(0,0,7,354,365)
TBATS(3,2,{7,3},{354.37,23},{365.25,3})
Acknowledgement
We thank Ralph Snyder and Peter Toscas for helpful comments that improved this paper. We are also
grateful to Derek K. Baker and Merih Aydinalp Koksal for providing the Turkish electricity data.
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing
Appendix A
Equation (2) can be written in the following form:
(cosλjt,sinλjt)′x j,t
x j,t = x j,t−1 + κt,
where x j,t = (αj,t,βj,t)′ and κt = (k1ϵt, k2ϵt)′. We re-parameterize using
x j,t = Aj,t sj,t,
where sj,t = (sj,t,s∗
j,t)′ and Aj,t =
. Then, substituting this into equation
(13), we obtain
Aj,t sj,t = Aj,t−1sj,t−1 + κt
sj,t = A−1
j,t Aj,t−1sj,t−1 + A−1
. Using well-known trigonometric identities, A−1
j,t Aj,t−1 =
, and so we obtain the required result (3).
De Livera and Hyndman: 12 December 2009
Forecasting time series with complex seasonal patterns using exponential smoothing