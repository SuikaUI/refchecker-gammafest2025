TopicMF: Simultaneously Exploiting
Ratings and Reviews for Recommendation
† Nanyang Business School, Nanyang Technological University, Singapore
School of Computer Engineering, Nanyang Technological University, Singapore
{ , , }
Although users’ preference is semantically reﬂected in
the free-form review texts, this wealth of information
was not fully exploited for learning recommender models. Speciﬁcally, almost all existing recommendation
algorithms only exploit rating scores in order to ﬁnd
users’ preference, but ignore the review texts accompanied with rating information. In this paper, we propose a novel matrix factorization model (called TopicMF) which simultaneously considers the ratings and
accompanied review texts. Experimental results on 22
real-world datasets show the superiority of our model
over the state-of-the-art models, demonstrating its effectiveness for recommendation tasks.
Introduction
Recommender systems have become a core component for
today’s personalized online business (e.g., Amazon), whose
heart is a personalization algorithm for identifying the preference of each individual user. The most well-known algorithms utilize the collaborative ﬁltering technique (CF),
which analyzes relationships between users and interdependencies among products, in order to identify new user-item
associations. Among all the CF algorithms, the most successful ones, as demonstrated by the Netﬂix Prize competition , are the latent factor models.
These models try to explain user ratings by characterizing
both items and users on, say, 20 or 100 factors inferred from
rating patterns. In a sense, such factors comprise a computerized alternative to the human created genes. One of the
representative realizations of latent factor models are based
on matrix factorization . In
its basic form, matrix factorization characterizes both items
and users by vectors of factors inferred from user-item rating
matrix. High correspondence between item and user factors
leads to a recommendation. Recently these methods have become popular with good scalability and predictive accuracy.
When learning the latent factor models, an assumption
they take for granted is that a rating score assigned by a user
to an item is determined by all factors with equal importance. Speciﬁcally, the rating is the inner product between
Copyright c⃝2014, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
the corresponding user and item vector. In some cases, biases for different users and items can also be incorporated
 . However, in the real scenario, this might not be the case. Based on our observations,
users usually assign a rating score to an item only based on
a few factors that they care speciﬁcally for this item. For
example, when giving rating score to the movie Die Hard,
different users might care about different factors. To put it
in another way, factors should have different importance degrees when a user rates an item.
On the other hand, recommender systems usually predict
users’ preference based on their previous feedback (e.g. ratings or free-form review texts). A rating score can tell us
whether a user likes or dislikes an item but cannot tell us
why. In contrast, if this rating score is associated with a segment of review text, we can understand why the user likes or
dislikes the item. For example, a user might give the highest
rating score to the movie Die Hard for different reasons (e.g.
fan of Bruce Willis, or the action movies). However, through
the user’s review “Bruce Willis rocks!”, we can infer that
this user likes this movie most possibly because he is a fan
of Bruce Willis. Somewhat surprisingly, the review text has
not been fully exploited for recommendation. Instead, most
of the existing works on recommender systems are focused
on discovering users’ preferences by using the explicit rating scores while the valuable information in review texts is
totally disregarded. Few studies that utilize the text information fail to connect the latent factors from textual information with those from user-item rating matrix, which greatly
impacts the interpretability of the algorithms.
In this paper, aiming at bridging the two gaps mentioned
above, we present a matrix factorization model, called TopicMF, for learning recommender models by factorizing factors using the information semantically hidden in the review texts. Speciﬁcally, we use a biased Matrix Factorization (MF) for rating prediction in recommender systems, and
simultaneously adopt a topic modeling technique (i.e. Nonnegative Matrix Factorization (NMF)) to model the latent
topics in review texts. We align these two tasks by using a
transform from item and user latent vectors to topic distribution parameters. By doing so, we combine latent factors in
rating data with topics in user-review text. Furthermore, we
can cope with the different importance degrees of latent factors by adjusting the transformation function. Note that the
Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence
textual review contains richer information than a single rating score. In this case, our model can thus better handle the
data sparsity (i.e. cold-start) problem than those only considering rating information. The experimental analysis on
22 real-world datasets shows that our method provides better performance than the state-of-the-art latent factor models
for recommendation tasks.
Related Work
In this section, we review several related approaches to our
work, including (1) latent factor-based recommender systems, (2) semantic enhanced recommender systems which
have drawn a lot of attentions recently.
Due to its efﬁciency in dealing with large datasets and
its quite effective performance for recommendation, several low-dimensional matrix approximation methods have
been proposed. These methods focus on ﬁtting the useritem rating matrix using low-rank approximations, and employ the matrix to make further predictions. The low-rank
matrix factorization methods are very efﬁcient in training
since they assume that in the user-item rating matrix, only
a small number of factors inﬂuence preferences, and that
a user’s preference vector is determined by how each factor applies to that user. Low-rank matrix approximations
based on minimizing the sum-squared errors can be easily
solved using Singular Value Decomposition (SVD) . For example, Salakhutdinov et al. propose
a probabilistic graphical model by assuming some Gaussian observation noises on observed user-item ratings. The
proposed model achieves promising prediction results. In
their following work , the
Gaussian-Wishart priors are placed on the user and item
hyper-parameters. Since exact inference is intractable in the
new model, a Gibbs sampling method is proposed to iteratively learn the user and item latent matrices. However, these
latent factor models suffer from the general limitations: 1)
the learnt latent space is not easy to interpret; 2) the assumption of equal importance of factors when generating the ratings differs from the reality.
There are also several works that attempt to combine ratings and review texts together in recommender systems,
referred to as semantic enhanced recommender systems.
These approaches try to interpret the latent factors factorized from the ratings. For example, Ganu et al. depend on the domain knowledge provided by human annotators to extract “explicit” aspects information (e.g. price)
from review texts, and thus to harness rating prediction. Our
work signiﬁcantly differs from it as we aim to automatically learn “implicit” topic aspects from review text, and link
them with latent factors reasonably. Also some works have
considered to automatically identify review dimensions. For
example, fLDA , extended from
matrix factorization, regularizes both user and item factors
in a supervised manner through explicit user features and
the bag of words associated with each item. It adopts discrete factors for items regularized through an LDA prior. On
the contrary, in our model, both the user latent factors and
item factors are optimized simultaneously with the topic parameters. Another similar work, proposed in , recommends scientiﬁc articles to users based on both
content of the articles and users’ historic ratings. Wang et
al. design a supervised topic model which simultaneously considers the textual and user-item rating information.
However, these approaches differ from ours as the latent factors learned through LDA are not necessarily correlated with
the user and item factors from matrix factorization on rating
The closest work to ours is proposed by McAuley and
Jeskovec . They relate latent rating dimensions (user
and item factors) with latent review topics in their HFT
model. However, the latent topics might only relate to latent
user (or item) factors in the HFT, while in our approach, the
latent topics correlate with user and item factors simultaneously, well reﬂecting the real world scenario. Besides, they
learn the topics for each item (or user). In contrast, we learn
the topics for each review, which can better map to users’
rating behavior, and thus further increase the accuracy and
interpretability of rating prediction.
Preliminaries
Problem Formulation
The problem we study is slightly different from traditional
recommender systems which usually only consider the useritem rating matrix. We also take the semantic evidences
into consideration. Suppose there are I users and J items.
Each observed data point is a 4-tuple (i, j, rij, dij) where
i 2 {1, 2, ..., I} is the user index, j 2 {1, 2, ..., J} is the
item index, rij 2 R is the rating value assigned to item j by
user i, and dij is the review text that is written by user i to
item j. dij = −1 means that there is no review text for the
corresponding data point.
The problem we investigate is essentially how to effectively and efﬁciently predict the missing values of user-item
rating matrix by employing the semantic evidences and observed user-item rating matrix.
Matrix Factorization for Recommendation
A promising method in recommender systems is to factorize the user-item rating matrix, and to utilize the factorized user-speciﬁc and item-speciﬁc matrices for further
missing data prediction . In recommender systems,
given I ⇥J user-item rating matrix R = [rij]I⇥J, a lowrank matrix factorization approach seeks to approximate
the rating matrix R by a multiplication of K-rank factors
R ⇡U T V , where U 2 RK⇥I and V 2 RK⇥J. The parameter K controls the number of latent factors for each user
and item which is typically much smaller than I and J.
In this model, each user i is represented by a Kdimensional feature vector ui 2 RK, the i-th column of U,
while each item j is represented by a K-dimensional feature
vector vj 2 RK, the j-th column of V . The predicted rating on item j by user i is equal to the inner product of the
corresponding user and item feature vectors:
i vj + µ + βu(i) + βv(j)
where βu(i) and βv(j) are biased terms regarding to user i
and item j, respectively, and µ is the global biased term.
The objective is to compute the latent representations of
the users and items given the observed rating matrix by minimizing the following regularized squared error loss:
Lrating = min
i,j cij(uT
i vj + µ + βu(i) + βv(j) −rij)2
i kuik2 + λv
j kvjk2 + λB , we introduce different conﬁdence
parameters cij for different rating rij. Besides, in our approach, we can further justify cij as an indicator function
related to the quality of the review dij. The higher quality of
the review indicates a larger cij value. Speciﬁcally, we have
if rij > 0
if rij = 0
where a and b are parameters satisfying a > b ≥0. qij is
the quality (i.e. helpfulness) of dij where qij = 0 if dij =
−1 (review is unavailable). The helpfulness of each review
can be moderately computed if the helpfulness votes are not
available .
The locally optimal solution of U and V can be found
usually with an iterative algorithm , where we update U and V alternately while holding
the other matrix ﬁxed. We can then use Equation 1 to predict
the missing ratings of the items.
Topic Modeling
Topic modeling techniques are employed to uncover hidden
“topics” in review text, where a topic is a distribution over
terms (i.e. words) that is biased around those associated under a single theme. The simplest topic model - Latent Dirichlet Allocation (LDA) is not suitable for our problem. Instead, we use NMF for our research,
since it estimates the probability distribution of each document on the hidden topics independently .
This is the case for our research, as we bound the probability distribution of each review on the hidden topics with the
corresponding latent user and item factors.
Given review dataset [dij]I⇥J and N words (each word
n 2 {1, 2, · · · , N}), let W = [Wdijn]IJ⇥N denote the
word-to-review matrix: Fdijn is the frequency of word n in
review dij. We further re-scale Wdijn = Wdijn/TN, where
TN is the total number of words. Different from MF, NMF
has the constraint that all entries in the decomposed factors
have to be non-negative. NMF tries to ﬁnd two non-negative
matrix factors ⇥2 RIJ⇥K and Φ 2 RN⇥K (K is constraint to be equivalent to the number of factors in Matrix
Factorization) where the product of the two matrices is an
approximation of the original matrix:
where ⇥= (✓dijk), Φ = (φnk), and ✓dijk, φnk ≥0. They
are determined by minimizing:
Lreview =min
⇥,Φ ||⇥ΦT −W ||2
cij(✓dij φT
n −Wdij n)2
where φn 2 RK is the n-th row of Φ, and ✓dij 2 RK is the
ij-th row of ⇥.
The TopicMF Model
Our TopicMF model tries to combine the idea of MF for rating prediction and NMF for uncovering latent topic factors
in review texts. Particularly, we correlate the topic factors
with the corresponding latent factors of both users and items.
To be more speciﬁc, as demonstrated in the Preliminaries
section, we learn a topic distribution (✓dij) for each review
dij. This actually records the extent to which each of K topics is talked by user i for item j.
Given our motivation of linking a user’s rating pattern
with her review pattern, we need to dependently learn the
rating parameters and review parameters. On the one hand,
vj represents a set of certain properties that item j occupies,
while ui represents user i’s preference towards corresponding item features. On the other hand, ✓dij encodes user i’s
preference on the item j. Therefore, we deﬁne that the ✓dij
is simultaneously inﬂuenced by ui and vj (see Figure 1).
Figure 1: The relationship of parameters.
More importantly, each component of ✓dij, e.g. ✓dijk, is
expected to be positively correlated with both the corresponding user factor and item factor (e.g. uik and vik). That
is, if an item has higher absolute1 value of a certain factor,
or a user values higher on a certain factor (in terms of the
absolute value), the corresponding factor is expected to be
discussed more in the review. In order to capture such dependent correlation, we propose the following addition transformation function (abbreviated as A-T):
exp(1|uik| + 2|vjk|)
k0=1 exp(1|uik0| + 2|vjk0|)
where parameters 1 and 2 are introduced to moderate the
transformation. Intuitively, larger 1 means that users are
1In the HFT model , different
from our model, it ignores those factors of negative bigger values,
which might also be talked a lot in the corresponding reviews but
in a relatively negative mood.
more attracted by the dominant properties of target items
(like or dislike), while smaller 1 means that users tend
to evenly talk about all the features of target items. Similarly, large 2 means that users always tend to talk about the
highly important factors they care, while smaller one means
that users care about all the properties and would like to discuss them in the reviews. Formally, 1, 2 ! 1, ✓dij will approach a unit vector that takes the value 1 only for the largest
indexing value of ui or vj. Conversably, if 1, 2 ! 0, ✓dij
approaches an uniform distribution. Note that through the
control of 1 and 2, we fairly achieve one of our goals of
relaxing the assumption of equal importance of factors.
Equation 7 is the multiplication form of transformation
function (abbreviated as M-T) that also captures the monotonic relationship of topic factors with user and item factors.
exp(|uik.vjk|)
k0=1 exp(|uik0.vjk0|)
where serves the same purpose as 1 and 2 in Equation 6.
The two latent spaces in rating matrix R and review matrix
W are thus connected via our proposed two transformation
functions. Besides, the latent space in review matrix can provide semantic descriptions (i.e. topics) for each latent factor
in rating matrix.
The objective of our model is to learn the optimal U and
V for accurately modeling users’ ratings, but at the same
time, obtain most likely topics according to reviews with
the constraint of transformation function. Thus, we reach the
following objective function for our TopicMF model using
NMF for uncovering hidden topics in Equation 5:
L =Lrating + λLreview =
i vj + µ + βu(i) + βv(j)
−rij)2 + λ
cij(✓dij φT
n −Wdij n)2 + λu
where λ is a parameter that balances the performance of rating prediction and topic modeling. Gradient descent is conducted to update U, V , ⇥, Φ, and . The details of using
Equation 6 (referred as TopicMF-AT) to compute the corresponding gradients given Equation 9 are listed as follows2:
i vj + µ + βu(i) + βv(j) −rij) + λuui + λ
1(✓dij φT
n −Wdij n)✓T
dij . ⇤(1 −✓T
dij ). ⇤φT
n . ⇤(ui./|ui|)
i vj + µ + βu(i) + βv(j) −rij) + λvvj + λ
2(✓dij φT
n −Wdij n)✓T
dij . ⇤(1 −✓T
dij ). ⇤φT
n . ⇤(vj./|vj|)
cij(✓dij φT
n −Wdij n)✓dij . ⇤φn(|ui| −✓dij |ui|)
cij(✓dij φT
n −Wdij n✓dij . ⇤φn(|vj| −✓dij |vj|)
2Due to the space limitation, the gradients of the biased terms
are not listed in the paper.
Accordingly, the details of gradient descent of using Equation 7 (referred as TopicMF-MT) is:
i vj + µ + βu(i) + βv(j) −rij) + λuui + λ
n −Wdij n)|vj|. ⇤✓T
dij . ⇤(1 −✓T
dij ). ⇤φT
n . ⇤(ui./|ui|)
i vj + µ + βu(i) + βv(j) −rij) + λvvj + λ
n −Wdij n)|ui|. ⇤✓T
dij . ⇤(1 −✓T
dij ). ⇤φT
n . ⇤(vj./|vj|)
n −Wdij n)⇥
✓dij . ⇤φn
|ui|. ⇤|vj| −✓dij (|ui|. ⇤|vj|)
Recall that our goal is to simultaneously optimize the parameters associated with ratings (i.e. U and V ), and the parameters associated with topics (i.e. ⇥and Φ). And, ⇥are ﬁt
by U and V . As presented above, U and V are ﬁt by gradient descent in Equation 9 or 10, while Φ is updated through
Equation 5. Therefore, we design a procedure that alternates
between the following two steps:
update U, V, ⇥, = argmin
update Φ = argmin
For the ﬁrst step of Equation 11, we update these paramters
through the commonly used non-linear optimization package, L-BFGS3. In NMF, the update of Φ can be accomplished through the well-known projected gradients technique . Since we ﬁx the ⇥in the second step,
the update of Φ is reduced to a sub-problem of Algorithm
2 of the NMF as described in . Thus, we particularly adopt the source code regarding to the sub-problem of
updating Φ when ﬁxing ⇥.
Experiments
In this section, we empirically evaluate the effectiveness of
our model of adopting reviews for recommendation on 22
Amazon datasets, and compare it with three state-of-the-art
approaches.
To make the fair evaluation of our model, we directly generate the 22 Amazon datasets from the datasets provided
by . Each dataset contains
a category of products sold on the Amazon. In particular,
due to our hardware limitation, for some large datasets (over
GB), we sample a portion of the whole dataset by limiting
the number of items up to 5000, respectively. The statistic information is summarized in Table 1. Besides, we randomly subdivide each dataset into the training and testing
sets, where 80% of each dataset is used for training, and the
rest is for testing (see Table 1). Note that we only utilize the
existing reviews in the training dataset for model learning.
3www.chokkan.org/software/liblbfgs/
Table 1: Data description
#users #items #ratings
(training)
(testing) avg. rating
24,069 4,207
automotive 89,246 5,000
13,928 1,651
129,026 5,000 149,510
accessories 66,185 5,000
73,276 5,000 307,045
144,725 5,000 152,251
88,651 5,000
235,925 5,000 241,037
448,574 5,000 482,828 120,170
industrial
&scientiﬁc 21,716 5,000
31,597 5,000 136,623
instrument 58,095 5,000
98,141 5,000
143,846 5,000 136,623
48,310 5,000 221,371
62,764 5,000
&outdoors 218,938 5,000 248,112
tools&home198,290 5,000 207,028
194,347 5,000 194,231
video games194,614 5,000 236,891
57,283 5,000
Baselines and Evaluation Metric
For the competing methods, the HFT (item) is so far the best among the methods that attempt to exploit unstructured textual reviews for recommendation. We therefore choose it as our benchmark method4.
The HFT (item) refers to the one that topics in review text
are associated with item parameters, which is proved to have
better performance than HFT (user) in terms of rating predictive accuracy. We also conduct comparisons with other
state-of-the-art methods, including PMF which only exploits rating information, and
SVD++ that exploits both rating information
and other hidden feedback (e.g. click information). We adopt
the source codes of these two methods provided by My-
MediaLite Recommender System Library5. For all the methods, we set optimal parameters recommended in the literature, and set the number of latent factors (K) as 5.
To measure the performance of these methods, we adopt
the commonly used metric MSE (the mean squared error),
which is deﬁned as the average of the squared error between
the predictions and the ground-truth. Smaller MSE values
normally indicate better performance for rating prediction.
4i.stanford.edu/⇠julian
5www.mymedialite.net/index.html
Performance Comparisons
Here, we show the performance comparison of our proposed
TopicMF model with all baseline methods. The results are
shown in Table 2, where the best performance is in bold font.
“*” indicates the better performance between TopicMF-AT
and TopicMF-MT on each dataset. For HFT (item) and our
method, we report the MSE value after 20 iterations (see
Equation 11). For our method, the balance parameter λ is set
to 1, and λu = λv = λB = 0.001, while other parameters
are ﬁt using L-BFGS package and projected gradient technique6. In order to make fair comparison with HFT (item),
our cij value does not take the review quality into consideration. Instead, we set cij = 1 if rij 6= 0.
As can be seen in Table 2, our method (TopicMF-AT or
TopicMF-MT) performs much better than HFT (item) on
most categories (e.g. baby, video games and gourmet foods),
and can achieve comparable performance (i.e. the difference
is around or less than 1%) on the rest categories (e.g. shoes
and sports&outdoors). Under the categories like baby, video
games and gourmet foods, users are more enthusiastic, and
would like to reveal and express their subjective feelings
and attitudes towards the products they have interest, such
as baby products, video games or favorite foods. Therefore,
more meaningful topics are expected to be derived from each
single review regarding to the items of these categories. Not
surprisingly, the methods that also exploit unstructured reviews, i.e. TopicMF and HFT (item), perform much better
than PMF and SVD++.
On average, as presented in Table 3, across all the
datasets, PMF achieves an MSE of 1.5585, SVD++ achieves
an MSE of 1.4395, while HFT (item) achieves an MSE
of 1.3836. TopicMF-MT performs slightly better than
TopicMF-AT, and they achieve MSE of 1.3468 and 1.3511,
respectively. Besides, TopicMF-MT gains improvements
over SVD++ and HFT (item) up to 6.43% and 2.73%, respectively. We also conduct t-test for the performance difference across 22 datasets, and the results (see Table 3) show
that the performance improvement of our method is statistically signiﬁcant at the 5% level (i.e., p-value < 0.05).
Table 3: The average performance of different methods.
average MSE
HFT (item)
TopicMF-AT
TopicMF-MT
improvement
vs. HFT(item)
Parameter Sensitivity
There are two important parameters in our TopicMF model:
1) the number of latent factors K; and 2) the parameter λ
6www.csie.ntu.edu.tw/⇠cjlin/nmf
Table 2: Performance comparisons of different methods (K = 5).
automotive
accessoriesclothing
health home and
industrial
&scientiﬁc
1.9473 1.4613
1.5536 1.6732
1.6699 1.5460
1.4921 1.5842
HFT (item)
1.7180 1.3059
1.5245 1.4910
TopicMF-AT
1.6676 1.3216
0.2290 1.5256⇤1.4297⇤1.4793⇤
TopicMF-MT
1.6212⇤1.3193⇤
1.4319 1.4811 1.5232⇤
improve vs. SVD++
vs. HFT(item) 1.22%
5.63% -1.03%
jewelry musical
instrument
products patio
software sports&
1.9026 1.9826
1.7158 1.6596
1.7342 1.7556
1.5242 1.3699
HFT (item)
1.5898 1.7474
1.4845 1.4008
TopicMF-AT
1.5945 1.7096
2.2932 1.0787⇤1.4670 1.3680 1.4453⇤
TopicMF-MT
1.5891⇤1.6941⇤
1.0804 1.4553⇤1.3505⇤
improve vs.SVD++
vs.HFT(item) 3.58%
Figure 2: Performance by varying number of latent factors (K) (a) TopicMF-AT; and (b) TopicMF-MT; Performance by varying
parameter λ (c) TopicMF-AT; and (d)TopicMF-MT.
that balances the performance of rating prediction and topic
modeling. Their optimal values cannot be automatically ﬁt
by our algorithms. To investigate the effects of these two parameters, we show the performance of our models by varying one of them meanwhile ﬁxing the other one on the following three datasets: “arts”, “baby” and “jewelry”.
Firstly, we ﬁx λ to its default value 1, and vary the number of latent factors to be 5, 10, 15, and 20, respectively. As
shown in Figures 2(a) and (b), we can see that the performance of our two models is relatively stable, indicating that
our models are not sensitive to the K value. This is different
from the traditional latent factor models which are inclined
to use more factors . This
ﬁnding on the whole the same as . This is mainly because in a review, a user might only
mention a few of all the possible factors.
Next, we ﬁx the parameter K to 5, and vary λ to be values of {0.1, 0.2, 0.5, 1, 2, 5, 10}. The results are shown in
Figures 2(c) and (d). As can be seen, the performance is relatively stable, and only have slight ﬂuctuations as λ varies,
especially when λ ≥1. This demonstrates that our methods
are not very sensitive to parameter λ.
To summarize, given the insensitivity of parameters λ and
K, and automatical optimization of other parameters, our
TopicMF model owns good ﬂexibility.
Conclusion and Future Work
In this paper, we propose a latent factor model, called TopicMF, for recommendation by jointly considering user ratings and unstructured reviews. Speciﬁcally, we use a biased
matrix factorization model that factorizes user-item rating
matrix into latent user and item factors for rating prediction. Simultaneously, we employ the non-negative matrix
factorization technique to derive topics from user unstructured review text. We relate these two tasks by designing
the A-T or M-T transform function to align the topic distribution parameters with the corresponding latent user and
item factors. In this case, we can further improve the accuracy of rating prediction. We conduct experiments on 22
real-world datasets, each of which contains the items of a
category sold on Amazon. Experimental results demonstrate
that our model outperforms the three state-of-the-art methods (i.e. PMF, SVD++, and HFT), and can achieve better
performance for rating prediction.
In the future, we intend to quantitatively analyze the
learned topics for each review, and explore how well these
topics interpret users’ rating behavior. Given these topics,
we will construct user preference models, and then empirically validate them.
Acknowledgements
This work is supported by the MoE AcRF Tier 2 Grant
M4020110.020 and the ACI Seed Funding M4080962.C90
awarded to Dr. Jie Zhang.