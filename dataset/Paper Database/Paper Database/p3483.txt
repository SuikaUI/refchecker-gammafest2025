Frequency decomposition of conditional
Granger causality and application to
multivariate neural ﬁeld potential data
Yonghong Chen
Department of Biomedical Engineering, University of Florida, Gainesville, FL
32611, USA
Steven L. Bressler
Center for Complex Systems and Brain Sciences, Florida Atlantic University,
Boca Raton, FL 33431, USA
Mingzhou Ding
Department of Biomedical Engineering, University of Florida, Gainesville, FL
32611, USA
 
4 September 2018
It is often useful in multivariate time series analysis to determine statistical causal
relations between diﬀerent time series. Granger causality is a fundamental measure
for this purpose. Yet the traditional pairwise approach to Granger causality analysis
may not clearly distinguish between direct causal inﬂuences from one time series to
another and indirect ones acting through a third time series. In order to diﬀerentiate
direct from indirect Granger causality, a conditional Granger causality measure in
the frequency domain is derived based on a partition matrix technique. Simulations
and an application to neural ﬁeld potential time series are demonstrated to validate
the method.
Key words:
Granger causality; Conditional Granger causality; Multiple time series; Frequency
domain; Multivariate autoregressive (MVAR) model; Autoregressive moving
average (ARMA) process; Partition matrix.
Email addresses: (Yonghong Chen), 
(Steven L. Bressler), (Mingzhou Ding).
Introduction
The concept of causality introduced by Wiener and formulated
by Granger has played a considerable role in investigating
the relations among stationary time series. The original deﬁnition of Granger
 , which is well named as Granger causality, refers to the improvement in
predictability of a series that derives from incorporation of the past of a second
series, above the predictability based solely on the past of the ﬁrst series. This
deﬁnition only involves the relation between two time series. As pointed out
by Granger , if a third series is taken into account, a
spurious or indirect causality due to the third series may be detected. Then he
deﬁned a prima facie cause : Y is said to be a prima facie cause
of X if the observations of Y up to time t (Y (τ) : τ ≤t) help one predict X(t+
1) when the corresponding observations of X and Z are available (X(τ), Z(τ) :
τ ≤t). We refer to this idea as conditional Granger causality since it gives a
measure of causality between two time series, X and Y , conditional on a third,
Z. Evaluation of this conditional Granger causality in the time domain is fairly
straightforward through comparison of two predictions of X(t + 1), one when
(X(τ), Z(τ) : τ ≤t) are given, the other when (X(τ), Y (τ), Z(τ) : τ ≤t) are
given. However, evaluating causality by frequency decomposition may allow
more meaningful interpretations in cases where oscillations are involved.
After giving clear measurements of linear dependence and feedback between
two blocks of time series , Geweke also presented a measure of
conditional linear dependence and feedback . Both a time domain measure, consistent with that of Granger, and its frequency decomposition were given. Although Hosoya presented some improvements on Geweke’s
methods and conditional versions ), they have not been widely accepted because his time domain implementation departs from Granger’s original idea, and its physical interpretation
is less clear.
We point out that Geweke’s use of the term ”feedback” is equivalent to ”causality” in the present discussion. In applying Geweke’s frequency-domain conditional Granger causality measure to neural ﬁeld potential data, we have found
that negative values, which have no meaning in terms of causality, may occur
at some frequencies. This ﬁnding casts doubt on the applicability of Geweke’s
method for neural time series analysis. We believe that the negative values result from the lack of identity of estimates of the same spectrum when diﬀerent
autoregressive (AR) models are used. This non-identity of diﬀerent estimates
of the same spectrum is a general practical problem in numerical analysis that
causes errors in Geweke’s implementation because it requires the estimates to
be identical. In this paper, we employ a partition matrix method to overcome
this problem. Comparison of the results from our procedure with Geweke’s
original procedure, clearly shows the validity of the current procedure. In the
following sections: we ﬁrst provide an introduction to Granger causality; then
present an overview of Geweke’s procedure on conditional causality, pointing
out the importance of obtaining a correct measure; and then derive our procedure. Finally, results of simulations and application to neural ﬁeld potential
time series data are provided.
Background
Consider a multiple stationary time series of dimension n, W = {wt}. The
series has the following moving average representation with use of the lag
operator L:
wt = A(L)εt,
where E(εt) = 0, var(εt) = Σ and A0 = In, the n×n identity matrix. Assume
there exists the autoregressive representation:
B(L)wt = εt,
where B0 = In.
Suppose that wt has been decomposed into two vectors xt and yt with k
and l dimensions respectively: wt = (x′
t)′, where the prime denotes matrix
transposition. Denote Wt−1 as the subspace generated by {ws; s ≤t −1}.
Deﬁne Σ1 = var(xt|Xt−1), Σ2 = var(xt|Xt−1, Yt−1), T1 = var(yt|Yt−1), T2 =
var(yt|Xt−1, Yt−1) and Υ = var(wt|Wt−1), where the conditional variance is
taken to be the variance of the residual about the linear projection which accounts for the prediction. The measures of linear causality from Y to X, linear
causality from X to Y, instantaneous linear causality and linear dependence
were respectively deﬁned to be :
FY→X = ln(|Σ1|/|Σ2|),
FX→Y = ln(|T1|/|T2|),
FX·Y = ln(|Σ2| · |T2|/|Υ|),
FX,Y = ln(|Σ1| · |T1|/|Υ|) = FY→X + FX→Y + FX·Y.
The measures of directional linear causality may be decomposed by frequency.
Let the autoregressive representation for X and Y be:
with B11(0) = Ik, B22(0) = Il, B12(0) = 0, B21(0) = 0, var(ε1t) = Σ2, var(ε2t) =
T2. Eq.(4) is actually a partition form of Eq.(2). Let C = cov(ε1t, ε2t). Then
pre-multiplying a transformation matrix
to both sides of Eq.(4), we have the following normalized form:
where ε1t and ˜ε2t are uncorrelated, var(˜ε2t) = T3 = T2 −C′Σ−1
˜B12(0) = 0 but ˜B21(0) ̸= 0 in general. Then Eq.(6) implies the following
spectral decomposition of the spectral density of X:
Sx(λ) = ˜H11(λ)Σ2 ˜H∗
11(λ) + ˜H12(λ)T3 ˜H∗
where ˜H(λ) is the transfer matrix of the normalized autoregressive expression
in Eq.(6). It is obvious that the spectral density of X is decomposed into
an intrinsic part and a causal part, so the measure of linear causality was
suggested as :
fY→X(λ) = ln
| ˜H11(λ)Σ2 ˜H∗
There is also a convergence relation between the measures in the time and
frequency domains:
fY→X(λ)dλ ≤FY→X.
In the above, a Granger causality measure between two (or two blocks of)
time series was given. Before Geweke presented his logarithm version, Pierce
 had introdued a R2 measure which simply takes the ratio of the
variances of two prediction errors. The value of Pierce’s R2 measure is within
 which is more convenient for comparison with correlation coeﬃcients.
However, Geweke’s logarithm version has better statistical properties. There
has also been a measure based on autoregressive moving average(ARMA) models .
Granger causality analysis has been employed in a number of studies of neural
data . The procedure described above has potential applications in
these types of study. For those cases where more than two scalar/block time
series recordings are available, the procedure may be performed to identify
further patterns of neural interaction after a more traditional pairwise analysis. We now consider two simple simulations to illustrate situations in which
conditional Granger causality analysis is important.
Example 1: The case of diﬀerentially delayed driving
We ﬁrst consider a simple system consisting of three variables, each representing an AR process:
x(t) = ξ(t)
y(t) = x(t −1) + η(t)
z(t) = µz(t −1) + x(t −2) + ǫ(t).
where |µ| < 1 is a parameter, and ξ(t), η(t), ǫ(t) are independent white noise
processes with zero mean and variances σ2
3, respectively. The system
conﬁguration is illustrated in Fig. 1(a) where x drives y after the delay of one
time unit and x drives z after the delay of two time units. We note that the
time unit here is arbitrary and has no physical meaning. To be consistent with
the data presented later we assume that the sample rate is 200 Hz. In other
words each time unit is 5 millisecond.
We performed a simulation of this system, with µ = 0.5, σ1 = 1, σ2 = 0.2,
and σ3 = 0.3, to generate a data set of 500 realizations, each 100 points long.
Then, assuming no knowledge of Eq.(10), we ﬁt multivariate autoregressive
(MVAR) models to the generated data set for each pairwise
combination of variables x, y, and z, and calculated the frequency-domain
Granger causality for each pair in each direction, as shown in Fig. 1(b). In the
top two rows of this ﬁgure, we see non-zero Granger causality values across the
spectra of x →y and x →z and zero values across the spectra of y →x and
z →x. These results are indicative of the true unidirectional causal driving
of y and z by x. However, we also see results in the third row of Fig. 1(b)
which appear to indicate unidirectional causal driving of z by y. In fact, we
know from the system conﬁguration that this apparent driving is due to the
common inﬂuence of x on both y and z but with diﬀerent time delays. This
mistaken identiﬁcation of an indirect inﬂuence as being a direct one suggests
the need for the conditional Granger causality measure.
Example 2: The case of sequential driving
Next we consider another simple system, again consisting of three AR processes:
x(t) = ξ(t)
y(t) = x(t −1) + η(t)
z(t) = µz(t −1) + y(t −1) + ǫ(t).
This system conﬁguration consists of sequential driving from x to y, then from
y to z as illustrated in Fig. 2(a). The same numbers of realizations and data
points were generated for the same parameter values, and MVAR models were
again ﬁt to the data. The results of Granger causality analysis in Fig. 2(b)
show an apparent unidirectional causal driving of z by x that is in fact due
to the indirect inﬂuence through y. Again, the mistaken identiﬁcation of an
indirect inﬂuence as being direct suggests the need for the conditional Granger
causality measure.
Note that, although the systems in the above two examples are very diﬀerent, the results of pairwise Granger causality analysis seen in Figs. 1(b) and
2(b) are essentially the same, indicating that the analysis could not distinguish between the two systems. These two examples, although simple, thus
plainly demonstrate that the pairwise measure of Granger causality by itself
may be insuﬃcient to reveal true system relations. We now describe the conditional Granger causality as a potentially useful tool for disambiguating such
situations.
Geweke’s Measure of Conditional Feedback Causality
Now suppose that wt has been decomposed into three vectors xt, yt and zt
with k, l and m dimensions, respectively: wt = (x′
t)′. The measure given
by Geweke for the linear dependence of X on Y, conditional on Z, in the time
domain is:
FY→X|Z = ln
var(xt|Xt−1, Zt−1)
var(xt|Xt−1, Yt−1, Zt−1),
which is consistent with Granger’s deﬁnition of a prima facie cause (Granger,
Time series prediction is achieved by the ﬁtting of MVAR models. In order
to implement Eq.(12), two MVAR models are involved. One is the following
two-variable MVAR model:
with the normalization D11(0) = I, D22(0) = I, D12(0) = 0, and cov(Θt, Ψt) =
0 imposed in order to yield the frequency decomposition of the conditional
dependence. The normalization can be achieved by using a transformation
matrix like Eq.(5).
The other MVAR model used for deriving the frequency decomposition of the
conditional dependence is the following three-variable MVAR model:
with normalization imposed too. The explicit formula of the transformation
matrix to normalize the MVAR model of three time series is given in the
Based on the relations of diﬀerent variances, Geweke derived the following
important relation of the conditional causality in the time domain :
fY→X|Z(λ) = fYΨ→Θ(λ).
In order to get fYΨ→Θ(λ), we need to decompose the variance of Θ into the
frequency domain. To do so, we write Eq.(13) and Eq.(14) in the frequency
If the spectra of X(λ) and Z(λ) from Eq.(17) remain identical to the spectra
from Eq.(18), then we can substitute Eq.(17) into Eq.(18) to get the following
equations:
where Q(λ) = G−1(λ)H(λ). From the ﬁrst equation of Eqs.(19), the spectrum
of Θ is decomposed into the following three obvious parts:
SΘ(λ) = Qxx(λ)ΣxxQ∗
xx(λ) + Qxy(λ)ΣyyQ∗
xy(λ) + Qxz(λ)ΣzzQ∗
xz(λ).(20)
Therefore the measure of causality from YΨ to Θ may be described as:
fYΨ→Θ(λ) = ln
|Qxx(λ)ΣxxQ∗xx(λ)|,
where SΘ(λ) is actually the variance of Θt, namely ΣΘ, since Θt is white noise
in Eq.(13). Considering the relation of Eq.(16), we could get the conditional
causality as :
fY→X|Z(λ) = ln
|Qxx(λ)ΣxxQ∗xx(λ)|,
In the above derivations, the assumption that the spectra of X(λ) and Z(λ)
coming from Eq.(17) and from Eq.(18) are identical is actually very hard to
satisfy numerically due to practical estimation errors. As an example of this
problem, consider Fig. 6, where the dashed curves result from performing
Geweke’s conditional casuality procedure. Note that the negative values seen
here have no interpretation in terms of causality. (A detailed description of
Fig. 6 is given in a later section.) In the following section, we introduce the
partition matrix technique to overcome this problem.
Partition Matrix Improvement
For three blocks of time series xt, yt, zt, we can ﬁt a three-variable MVAR
model as in Eq.(14) and we can also derive its frequency domain expression
as in Eq.(18). From Eq.(18), writing an expression only for X(λ) and Z(λ)
(making partitions) we have:
where ¯Ex(λ) and ¯Ez(λ) have the following moving average expression:
Ey(λ). (24)
We realize that Eq.(23) is actually a summation of multiple ARMA processes,
and that the summation of several ARMA processes is still an ARMA process . However, an unambiguous
representation of the general multivariate ARMA process for the summation
is unknown, although a general univariate ARMA model could be obtained
through a speciﬁc procedure . Alternatively, we
adopt the following procedure to evaluate the conditional Granger causality.
we get the covariance matrix of the noise terms given in Eq.(24):
(Σxy Σzy) +
This covariance matrix is no longer a real matrix, but it is a Hermite matrix, i.e. ¯Σxz(λ) = ¯Σ∗
zx(λ). Therefore we can use the following transformation
matrix to normalize the bivariate model of Eq.(23):
Therefore, in correspondence with the normalized form in Eq.(17), the transfer
matrix G(λ) is now:
Taking the expansion form of this G(λ) matrix to get matrix Q(λ) = G−1(λ)H(λ),
and considering ΣΘ = ¯Σxx, where ¯Σxx comes from Eq.(25), we can still use
Eq.(22) to get the conditional causality.
Applications to Simulated and Neural Field Potential Data
Application to Simulated Data
We performed conditional Granger causality analysis on the delay driving
and sequential driving systems presented above in Section 2. For the delay
driving case (Section 2.1 and Fig. 1), the Granger causality spectrum from y
to z, conditional on x, is presented in Fig. 3. It is obvious from Fig. 3 that the
conditional Granger causality measure eliminated the indirect causal inﬂuence
of y on z which appeared in Fig. 1(b). For the sequential driving case (Section
2.2 and Fig. 2), the Granger causality from x to z, conditional on y, is also
presented in Fig. 3. Clearly, the indirect causal inﬂuence from x to z, which was
indicated in Fig. 2(b), was also eliminated by use of the conditional Granger
causality.
In both cases, we have seen that conditional Granger causality analysis eliminated indirect causal inﬂuences that inadvertently resulted from application
of the pairwise Granger causality measure. Knowing the system equations in
these examples allowed us to verify that the conditional Granger causality
measure yielded a truer depiction of the system relations. We now consider
how the conditional Granger causality measure may provide the same beneﬁt
in the analysis of real neural data.
Application to Neural Field Potential Data
Field potential data were recorded from two macaque monkeys using transcortical bipolar electrodes at 15 distributed sites in multiple cortical areas of one
hemisphere (right hemisphere in monkey GE and left hemisphere in monkey
LU) while the monkeys performed a GO/NO-GO visual pattern discrimination
task . The presence of oscillatory ﬁeld potential activity
in the beta (14-30 Hz) frequency range was recently reported in the sensorimotor cortex of these monkeys during the prestimulus period . In that study, Granger causality analysis was performed for all pairwise
combinations of sensorimotor cortical recording sites. In both monkeys, significant Granger causal inﬂuences were discovered from primary somatosensory
cortex to both primary motor cortex and inferior posterior parietal cortex,
with the latter area also exerting Granger causal inﬂuences on primary motor
In monkey GE, the possibility existed that the causal inﬂuence from the primary somatosensory (Soma) site to one of the inferior posterior parietal sites
(in area 7a) was actually mediated by another inferior posterior parietal site
(in area 7b) (Fig. 4(a)). We therefore used conditional Granger causality analysis to test the hypothesis that the Soma →7a inﬂuence was mediated by the
7b site. In Fig. 4(b) is presented the pairwise Granger causality spectrum from
the Soma site to the 7a site (Soma →7a, light solid curve), showing signiﬁcant causal inﬂuence in the beta frequency range. Superimposed in Fig. 4(b) is
the conditional Granger causality spectrum for the same pair, but with the 7b
site taken into account (Soma →7a|7b, dark solid curve). The corresponding
99% signiﬁcance thresholds are also presented (light and dark dashed lines
which overlap each other). These signiﬁcance thresholds were determined using a permutation procedure that involved creating 500 permutations of the
ﬁeld potential data set by random rearrangement of the trial order. Since the
test was performed separately for each frequency, a correction was necessary
for the multiple comparisons over the whole range of frequencies. The Bonferroni correction could not be employed because these multiple comparisons
were not independent. An alternative strategy was employed following . The Granger causality spectrum was computed for each
permutation, and then the maximum causality value over the frequency range
was identiﬁed. After 500 permutation steps, a distribution of maximum causality values was created. Choosing a p-value at p = 0.01 for this distribution
gave the thresholds shown in Fig. 4(b), (c) and Fig. 5(b) in dashed lines.
We see from Fig. 4(b) that the conditional Granger causality is greatly reduced in the beta frequency range and no longer signiﬁcant, meaning that
the causal inﬂuence from the Soma site to the 7a site is most likely an indirect eﬀect mediated by the 7b site. This conclusion is consistent with the
known neuroanatomy of the sensorimotor cortex 
in which area 7a is connected with area 7b, but not directly with the primary
somatosensory cortex.
From Fig. 4(a) we see that the possibility also existed that the causal inﬂuence
from the Soma site to the primary motor (Mot) site in monkey GE was
mediated by the 7b site. To test this possibility, the Granger causality spectrum
from Soma to Mot (Soma →Mot, light solid curve in Fig. 4(c)) was compared
with the conditional Granger causality spectrum with 7b taken into account
(Soma →Mot|7b, dark solid curve in Fig. 4(c)). In contrast to Fig. 4(b), we
see that the beta-frequency conditional Granger causality in Fig. 4(c) is only
partially reduced, and remains well above the 99% signiﬁcance level. In Fig.
5(a), we see that the same possibility existed in monkey LU of the Soma to
Mot causal inﬂuence being mediated by 7b. However, just as in Fig. 4(c), we see
in Fig. 5(b) that the beta-frequency conditional Granger causality for monkey
LU is only partially reduced, and remains well above the 99% signiﬁcance
The results from both monkeys thus indicate that the Granger causal inﬂuence from the primary somatosensory cortex to the primary motor cortex was
not simply an indirect eﬀect mediated by area 7b. However, we further found
that area 7b did play a role in mediating the Soma to Mot causal inﬂuence
in both monkeys. This was determined by comparing the means of bootstrap
resampled distributions of the peak beta Granger causality values from the
spectra of Soma →Mot and Soma →Mot|7b by Student’s t-test. The signiﬁcant reduction of beta-frequency Granger causality when area 7b is taken into
account (t = 17.2 for GE; t = 18.2 for LU, p <<< 0.001 for both), indicates
that the inﬂuence from the primary somatosensory to primary motor area was
partially mediated by area 7b. Such an inﬂuence is consistent with the known
neuroanatomy , which shows direct connections
between area 7b and both primary motor and primary somatosensory areas.
As a ﬁnal demonstration of the value of using the partition matrix method
outlined in this paper to compute conditional Granger causality, we present
in Fig. 6 a direct comparison of our improved procedure (solid) with Geweke’s
original procedure (dashed) for the Soma →Mot|7b spectra of monkey GE
(Fig. 6(a)) and monkey LU (Fig. 6(b)). From much previous experience working with this ﬁeld potential data , we know that spectra
from these cortical areas typically have a single peak in the beta frequency
range. Geweke’s original method is clearly seen to be deﬁcient in these examples not only by the multiple peaks and valleys across the spectra, but also
by the negative values, which have no physical interpretation. We thus are
conﬁdent that the partition matrix technique is a potentially valuable tool to
be used in the investigation of conditional Granger causality relations between
neural signals.
Acknowledgments
The work was supported by US NIMH grants MH64204, MH070498 and
MH71620, and NSF grant 0090717.
Appendix: Transformation matrix to normalize a model of three
time series
Since the MVAR model, such as in Eq.(14), is usually not normalized, the noise
terms could be correlated with each other. Let us assume that the covariance
matrix is given by:
In order to make the ﬁrst noise term independent, we could use the following
transform:
Then the covariance matrix for the transformed noise terms is:
Σyy −ΣyxΣ−1
Σyz −ΣyxΣ−1
Σzy −ΣzxΣ−1
Σzz −ΣzxΣ−1
Again, to make the second and third noise terms independent, the following
transformation may be made:
−(Σzy −ΣzxΣ−1
xxΣxy)(Σyy −ΣyxΣ−1
Therefore the whole transformation matrix needed to make all three noise
terms independent is:
P = P2 · P1