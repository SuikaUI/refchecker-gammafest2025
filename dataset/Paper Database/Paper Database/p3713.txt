Journal of Computational and Applied Mathematics 88 315-326
JOURNAL OF
COMPUTATIONAL AND
APPLIED MATHEMATICS
RKC: An explicit solver for parabolic PDEs
B.P. Sommeijer 3·*, L.F. Shampine b, J.G. Verwera
"CWl P.O. Box 94079, 1090 GB Amsterdam, The Netherlands
b Mathematics Department, Southern Methodist University, Dallas. TX 75275-0156, USA
Received 3 June 1997; received in revised form 6 October 1997
The FORTRAN program RKC is intended for the time integration of parabolic partial differential equations discretized by
the method of lines. It is based on a family of Runge-Kutta-Chebyshev formulas with a stability bound that is quadratic
in the number of stages. Remarkable properties of the family make it possible for the program to select at each step
the most efficient stable formula as well as the most efficient step size. Moreover, they make it possible to evaluate the
explicit formulas in just a few vectors of storage. These characteristics of the program make it especially attractive for
problems in several spatial variables. RKC is compared to the BDF solver VODPK on two test problems in three spatial
variables. © 1997 Elsevier Science B.V. All rights reserved.
Keywords: Parabolic partial differential equations; Numerical software; Time integration; Runge-Kutta-Chebyshev solver
AMS classification: 65L05; 65M20; 65Y20
1. Introduction
RKC is a variable step size, variable formula code that uses explicit Runge-Kutta formulas to solve
efficiently a class of large systems of mildly stiff ordinary differential equations (ODES). The systems
arising when a parabolic partial differential equation (PDE) is approximated by semi-discretization
exemplify the problems for which RKC is intended. To be more specific, let the initial value problem
for the ODES have the form
d~;t) =F(t, U(t)),
O<t~T, U(O)= Uo,
• Corresponding author. E-mail: .
0377-0427/97/$17.00 © 1997 Elsevier Science B.V. All rights reserved
Pll S0377-0427(97)00219-7
B.P. Sommeijer et al. /Journal of Computational and Applied Mathematics 88 315-326
so that the Jacobian matrix is F'(t, U) = 8F(t, U)/oU. RKC is intended for problems with Jacobians
that are close to normal and that have all their eigenvalues near the negative real axis. These
properties are certainly true when F'(t, U) is symmetric and nonpositive-definite, which is frequently
the case when discretizing elliptic operators.
RKC exploits some remarkable properties of a family of explicit Runge-Kutta formulas of the
Chebyshev-type proposed by van der Houwen and Sommeijer . There is a member of s stages
for all s~2, and there are analytical expressions for its coefficients. All the formulas have stability
regions that include narrow strips about the negative real axis. The length of the strip, the stability
boundary {J(s), is approximated well by 0.653s2• This makes it possible for RKc to solve problems
that are mildly stiff with explicit formulas. A very important property is that because of a recursion
for Chebyshev polynomials, it is possible to evaluate a formula with just a few vectors of working
storage, no matter the number of stages. Most remarkable is that for practical pwposes the local
errors of all members of the family are the same. This means that the code can estimate first the
most efficient step size and then use an estimate of the spectral radius of the Jacobian to determine
the most efficient formula for which this step size is stable. Another important property of the family
is that it is easy to obtain a continuous extension of excellent quality that is "free". This is especially
valuable for a Runge-Kutta formula that might involve a great many stages.
RKC has very modest storage requirements because it uses explicit formulas that can be evaluated
by recursion. It requires at most seven vectors of storage. This makes it attractive for the solution
of PDES in several space variables by semi-discretization. Another advantage of explicit formulas is
that vectorization and/ or parallelization presents no particular difficulties. The code is, for example,
suitable for problems with solutions that are travelling waves because small steps are needed to
resolve fronts accurately. Generally, reaction-diffusion systems
at= V · (K Vu)+ f(u,x, t),
u = u(x, t), x E Rd,
where f is a modestly stiff reaction tenn can be solved efficiently with RK.c. When f gives rise to
severe stiffness, RK.c is not recommended. In such cases it can still be useful as part of an operator
splitting scheme that treats the reaction part at grid points with a standard code for stiff problems.
Likewise, in combination with operator splitting RKC can be useful for systems of transport problems
of advection-diffusion-reaction type
at+ V ·(au)= V · (K Vu)+ f(u,x, t),
u =u(x,t), x E ~d.
Problems of this kind play an important role in the modelling of pollution of the atmosphere, ground
water, and surface water, and are the subject of much current research.
Section 2 presents the family of formulas implemented in RKC. The following section discusses
the properties of the family that are crucial to the success of the solver and how they are exploited
in software. Among the issues discussed are the estimation and control of error, estimation of the
spectral radius and control of stability, and a continuous extension. Section 4 presents results for
two PDES in three spatial variables taken from 315-326
2. RKC's formulas
Historically, the principal goal when constructing Runge-Kutta formulas was to achieve the highest
order possible with a given number of stages s. Stabilized methods are different, in that, the principal
goal is to construct formulas with regions of absolute stability that are as large as possible in a sense
that depends on the intended application. The formulas of RKc are intended for problems like those
arising when parabolic PDES are approximated by semi-discretization. Correspondingly, the goal is to
construct formulas that are stable on a strip containing a long segment of the negative real axis.
The wider the strip, the greater the applicability of the method, but the most important characteristic
of the formula is the length of the segment, the stability boundary {J(s). For the ooEs of semidiscretization, a low-order formula is appropriate because only a modest accuracy is expected of
the approximation to the PDE. When the PDE involves more than one spatial variable, the size of the
system of ooEs grows rapidly as the mesh spacing is decreased. The relatively crude meshes that are
used for this reason lead to relatively large discretization errors in space, hence limits the accuracy
that would be meaningful in the time integration and so favors low-order methods. It turns out that
the higher-order methods require more stages to achieve the same stability, another factor favoring
low-order formulas. For these reasons all the formulas of RKc are of order two.
The formulas of RKc are given in . To avoid confusion, we point out that they are slightly
different from the formulas in (18]. A comprehensive linear stability and convergence analysis of
the formulas is found in . Amongst others, this analysis proves that the RKC formulas do not
suffer from order reduction. The formulas are also studied in the review article along with a
number of related methods.
Let Un denote the approximation to U(t) at t = tn and let r = tn+i tn be the step size in the
current step from tn to tn+I · The formulas of RKc have the form
Y1 =Yo+ ji.1rFo,
Y;=(l - µ1 - v1)Yo + µjYj-1 + v1lJ-2 + ji1rFj-1 + Y/tFo,
j = 2, .. . ,s,
All the coefficients are available in analytical form for arbitrary s;:;:::: 2. They are defined as follows.
Let T1 be the Chebyshev polynomial of the first kind of degree j. Then
b· = TJ'(wo)
wo=l+e/s2,
1-T;'(wo)'
(2~j~s), bo=b2,
T;{w0 ) Tj'(wo)
(2~;·~s- l),
T;'(Wo) Tj(wo)
c, = T;(w0 ) ~ 4'
The approximations show that the arguments tn + C/C all lie within the span of the step to tn + r.
B.P. Sommeijer et al.I Journal of Computational and Applied Mathematics 88 315-326
3. Software issues
RKC is the result of both software and algorithmic development of Sommeijer's code . Broadly
speaking, the implementation is like that of any modem code based on an explicit Runge-Kutta
formula. In this section we describe briefly aspects of the code that are unusual or even unique. Any
modem general-purpose code for initial value problems will estimate the local error at each step and
adjust the step size both to control this error and to solve the problem efficiently. Popular Adams,
BDF, and extrapolation codes also select the formula dynamically. The main difficulty in selecting
the most efficient formula is in estimating the step size that could be used with a formula other
than the one used to take the step. The family of fonnulas implemented in RKc has the remarkable
property that for practical purposes, all the fonnulas have the same accuracy. The stability boundary
of the formulas increases quadratically with the number of stages. By computing an estimate of the
spectral radius, the code is able to determine the most efficient formula that is stable with a step size
predicted to yield the desired accuracy. An important property of the family is that it is possible to
evaluate a formula using just a few vectors of working storage, no matter how large the number of
stages. Still another important property is that it is easy to obtain a continuous extension of excellent
3.1. Error control
For a smooth F in ( 1.1 ), a Taylor series expansion of the local solution at t = tn results in
Un+1=U+rU+2r U+ C31,sr FjF£F +c32,sr FjkF1F +O(r ),
Naturally, the coefficients C31 ,s and C32,s depend on the formula, i.e., on the number of stages
s. However, it is found that both tend rapidly to a constant value as s increases. Indeed, they
are both close to fa for all s ~ 2. This says that the leading term of the local error expansion is
approximately proportional to the third derivative of the solution. As a consequence, the global error
is approximately independent of s. The convergence results in make this precise for linear
problems. Extensive testing with both linear and nonlinear problems has confinned that for practical
purposes, the local error is independent of the number of stages for s ;;?; 2.
Let Le( tn+ 1) be the approximation to the leading term of the local error expansion resulting from
replacing the true s-dependent constants by their limiting values:
Le(tn+I) = -fsr3 d3 U(tn )/dt3•
The simple form of this expression for the error makes it easy to obtain an asymptotically correct
Estn+t = Ts [12(Un - Un+i) + 6r(F(Un) + F(Un+i))].
At each step the estimated local error is controlled so that accuracy tolerances specified by the
user are met. There is a scalar relative error tolerance rtol. The user must ask for some relative
accuracy, but not too much for the precision available. Because the formulas are of order two, the
code is not appropriate for stringent tolerances. The absolute error tolerances can be supplied in the
form of a scalar atol that is applied to all the solution components or as a vector that is applied
B.P. Sommeijer et al/Journal of Computational and Applied Mathematics 88 315-326
to corresponding components. A scalar absolute error tolerance is convenient and saves a useful
amount of storage, but is appropriate only when all the solution components are on the same scale.
These tolerances are used in the weighted RMS norm
l!Estn+1 II= !lw- 1 Estn+1 IJ2,
w= Vm diag(Toli. ... , Tol,,,),
Tolk =atolk +rtolJU.+l.k!,
m is the dimension of the ODE system and Un+l.k the kth component of Un+I · Hence, the step is
accepted if llEstn+t II::::;; 1 and otherwise rejected and redone. The error is controlled by an error per
step criterion, so if all is going well, the arguments in show that reducing the tolerances by a
factor of 0.1 will reduce the error in the numerical solution by a factor of roughly 0.2.
A standard device for reducing the number of rejected steps is to use a fraction of the step
size predicted to be optimal; a relatively small fraction is used in AAc. Watts uses information
gathered at the preceding step to refine the conventional prediction of the optimal step size. Later
Gustafsson et al. derived nearly the same algorithm from the completely different viewpoint of
control theory. Versions of the algorithm are seen in RKSUJTE and RADAu5 . These very successful
codes have demonstrated the value of the refined prediction for reducing the nwnber of step failures,
so RKC also implements a version of the algorithm. Specifically, the prediction for the new step size
after a successful step is given by
'tnew = min( 10, max( 0.1, fac)) '!
with the fraction fac defined by
( 11Estnll11<P+I) ~)
1111cp+1 l
!1Estn+1II1/(p+I)'
where p is the order of consistency, which is in our case equal to two. The conventional prediction
is obtained by deleting the parenthesized term. It is used after a step rejection.
3.2. Initial step size
For the convenience of the user, RKc determines automatically an initial step size. In modern
algorithms for this purpose, the main difficulty is finding a step size that is on scale. Once this
is done, a tentative step size can be refined by means of trial steps. The situation in RKC is special
in two ways. A tentative step size 'to that is on scale is furnished by the reciprocal of the spectral
radius that is computed for stability control. Further, the very simple form of the local error allows
the error that would be made in a step of size r to be estimated with a difference quotient at
a cost of a single function evaluation:
to= 1/u(F'(to, Uo)),
Est= 'to(F(to + •o, Uo + roF(to, Uo)) - F(to, Uo)).
The initial step size 't'511111 is taken to be one-tenth of the largest step size predicted to satisfy the
error test:
't'start = O. l llEstll 1/2.
B.P. Sommeijer et al. I Journal of Computational and Applied Mathematics 88 315-326
3.3. Absolute stability
At each step RKc first selects the "optimal" step size for controlling the local error and then selects a
fonnula for which this step size is absolutely stable. Roughly speaking, the absolute stability regions
of the formulas used are strips containing a segment of the negative real axis, cf. , and the
length of the segment p(s) is approximated well by 0.653s2 • Assuming that the eigenvalues of local
Jacobians lie in such a strip, the spectral radius of the Jacobian is all that is needed to find the
smallest number of stages that yields stability for the step size r:
w(F' (t, U)) ~ 0.653s2•
Problems with constant Jacobians are sufficiently common that users are asked to identify them;
RKC computes the spectral radius only once in such cases.
Sometimes it is easy enough to detennine analytically a reasonably close upper bound on the
spectral radius, using, e.g., Ger8gorin's circle theorem, so RKC allows for this possibility. Generally,
it is not expensive to evaluate such a bound, so the code invokes it at each successful step.
Commonly, RKc estimates the spectral radius automatically using a nonlinear power method. This
is convenient for the user, but it does cost another vector of working storage and some computation.
The basic idea of the power method is simple, but there are a good many ways the method can
degenerate, so considerable care is needed in its implementation. Our implementation takes advantage
of the experience reported in , and here we describe only points that differ from
previous work. An important difference is that it is assumed that the eigenvalues are close to the
negative real axis. A Rayleigh quotient is then much more likely to reflect the magnitudes of the
largest eigenvalues than in the general case of eigenvalues that might have substantial imaginary part.
It is an upper bound on the spectral radius that is needed rather than the spectral radius itself, so the
estimate is increased somewhat and it is then used conservatively in selecting the number of stages.
It is important to hold down the cost of computing the spectral radius. The slope of the solution at
the beginning of a step (which is always available) is likely to be rich in the directions corresponding
to dominant eigenvalues , so it is used to start the power method at the first step. We have found
it very advantageous to retain the computed eigenvector from one estimation of the spectral radius
for use as the starting guess for the next. With such a good guess it is typical that only a few
iterations are needed. Still, the Jacobian should change slowly, so it should not be necessary to
estimate the spectral radius at every step. The spectral radius is estimated on a step failure because
this may indicate a change in the character of the problem. Otherwise, it is estimated for every 25
successful steps since the last estimate. Of course, unnecessary estimates are avoided when there are
repeated step failures.
3.4. Storage
The form (2.1) for the formulas of RKC results from the three-term recursion relation for Chebyshev
polynomials. It could be rewritten in the standard form of an explicit Runge-Kutta formula of s
stages, but (2.1) is much better for computation. One reason will be taken up shortly, but the
most important reason is that it is obvious this form of the formula can be evaluated using just a
few vectors of working storage, no matter how large the number of stages. The precise amount of
storage required by RKC depends on how the code is used, but it never uses more than five vectors
B.P. Sommeijer et al. /Journal of Computational and Applied Mathematics 88 315-326
of storage for the computation itself. This makes it possible for RKC to solve the very large systems
of ooEs arising from semi-discretization of PDES in several spatial variables.
3. 5. Internal stability
For conventional explicit Runge-Kutta methods, the accumulation of roundoff in the course of a
step is unimportant, but that is not the case for methods with a large number of stages. Indeed, in the
application of stabilized methods to parabolic PDES, there can be a serious accumulation of rounding
error, so serious that the number of stages must be limited [19-21). The form (2.1) minimizes this
internal instability, but there is still potential for a growth of roundoff at a modest rate proportional
to s2• For the problems that are the object of RKC and a reasonable working precision, such a growth
presents no difficulties. However, for robustness the number of stages is limited in RKc to prevent an
unacceptable growth of roundoff in the course of a step. According to , a safe assumption about
this growth is that it is bounded by a relative perturbation of 10s2 uround, where uround is the unit
roundoff. The design of RKc emphasizes relative error, so it is required that this perturbation be no
greater than rtol. Should the code find that it needs to use a larger s for stability with the desired
step size, the number of stages is limited and the absolute stability condition ( 3.1) is satisfied by
reducing the step size.
3. 6. Continuous extension
Early codes based on explicit Runge-Kutta methods provide answers at specific points by shortening the step size. This is inefficient, especially when the method has many stages like those of
RKC, so modem codes make use of a continuous extension to obtain cheaply answers anywhere in
the span of a step. Cubic Hermite interpolation to the value and slope at the two ends of a step
proves very satisfactory in the circumstances. It is easy to implement and provides a globally C'
piecewise-polynomial solution. The interpolant is "free" because the slopes are computed for other
purposes. It is shown in that to leading order, the error of this interpolant is independent of
the problem. Further, the error increases smoothly from the beginning of the step to a maximum
at the end of the step. The error at the end of the step is the local error controlled by the code.
Accordingly, to leading order the C' piecewise-polynomial solution is uniformly as accurate as the
values at the mesh points. RI<C is organized so that it can return after each step with the step size
taken and all the information required for interpolation stored in a work array. The interpolant is
evaluated at a point within the span of the step by calling an auxiliary subroutine RKCINT with the
point and the work array as arguments.
4. Numerical examples
In this section we present numerical results for two examples considered in [12). Both are parabolic
PDES in three space dimensions. Moore and Dillon use high-order finite elements for the spatial
discretization and integrate the ODES with DASPK. DASPK is a variant of DASSL that uses Krylov methods
to make practical the evaluation of the implicit BDFS for "large" systems of ODES and DAES .
Because our main purpose here is to illustrate the use of RKC, we have discretized the PDES with
B.P. Sommeijer et al. I Journal of Computational and Applied Mathematics 88 315-326
central differences on a uniform grid. Although the techniques in are very different, solving
the same examples provides some perspective about the use of explicit methods for such problems.
We include results computed with vooPK, a soF code similar to DASPK. It is a modification of vooE 
and is available from netlib: send vodpk.f from ode. It uses a preconditioned Krylov method GMRES
for the solution of the linear systems with matrix A =I - hy F', where F' is the Jacobian. Since
iterative methods such as GMRES require only matrix-vector products, A itself need not be stored.
reducing greatly the memory needed in the solution of three-dimensional PDES. vooPK asks the user to
specify the preconditioner P. For simplicity, in our experiments we used diagonal preconditioning,
i.e., P =I - hy diag(F' ). With this choice, the convergence behavior of GMREs is reasonable and the
storage requirement of 19 vectors is acceptable. In contrast, RKC requires only five vectors for the
first example and six for the second. Default values were used for all the parameters of voDPK. All
computations were performed in double precision ( ~ 16 digits) on an sa1 workstation with a 180 MHZ
MIPS a5000 processor.
Example 1. The first example is the linear heat conduction problem
u,=Au+f(x,y,z,t), O<x,y,z<l, t>O,
where f, u(x, y, z, 0 ), and Dirichlet boundary conditions are specified so that the solution is u(x, y, z, t)
=tanh(5(x+2y+ l.5z-0.5-t)). The problem is solved for O:::;t:::;0.7. A uniform grid with spacing
h = 0.025 is used, corresponding to 393 = 59 319 equations.
An analytical bound for the spectral radius of the Jacobian can be found easily by applying
Gersgorin's circle theorem to the discrete Laplacian. Because three-point central differences are used,
all rows of the matrix corresponding to an interior grid point have the form h-2( ••• 1 ... 1 ... 1 - 6
1. .. 1 ... 1 ... ), where " ... " represents zero entries. For these rows the circle theorem yields a bound
of 12/h2• Rows corresponding to a boundary point have more zero entries because of the Dirichlet
boundary conditions. Thus, 12/h2 is an upper bound for the spectral radius and it turns out that the
true radius is only marginally smaller. For h=0.025, CT:=::;j 19200, so this problem is rather stiff for
Results reported here were computed with scalar tolerances rtol = atol = tol. For a range of tol,
Table 1 presents the following quantities: the integration error at the end of the integration measured
in the maximum norm, the total number of steps with the number of rejected ones parenthesized,
the total number of F -evaluations, the average number of F -evaluations per step (both accepted and
rejected), and the cPu time on the workstation in seconds. The error displayed in the table is the time
integration error, being the difference between the fully discrete numerical solution and a reference
solution of the ODES computed with a stringent tolerance. It would have been easier to compare the
numerical solution to the analytical solution of the PDE, but this would be misleading because it
mixes the error of the spatial discretization of the PDES (being 0.36 · io-2 in the maximum norm)
with the error made in the time integration of the ooEs. For the same tolerances rtol = atol = tol,
Table 2 presents results for voDPK.
We see that both RK.c and vooPK successfully solve the problem for all the tolerances, but RKC is
better at delivering an accuracy comparable to the tolerance. The behavior of vooPK is particularly
unsatisfactory when tol is reduced from 10-5 to 1 o-6 • The efficiency of the solvers is compared in
Fig. I where the CPU time is plotted against the accuracy achieved. RK.C is seen to compete well over
the whole range of tolerances.
H.P. Somrneijer et al. /Journal of Computational and Applied Mathematics 88 315-326
Results for RKC for Example l
0.37· 10- 3
0.39· 10-4
0.65· I0-6
Results for VODPK for Example I
::::> 1000
--------------·------------------·-·-·-------- ·-·-------.. -·--.... ___ _ ·--... __ _
Fig. I. A log-log plot of CPU time versus error for Examples I (left) and 2 (right) for RKC and VODPK.
Example 2. This example is a combustion problem described by the PDES:
Cr=b.c-Dce-bfT,
LT,=b.T+rt.Dce-bfT,
O<x,y,z<l, t>O,
along with the initial condition c(x,y,z,0)= T(x,y,z,0)= 1, homogeneous Neumann boundary conditions for x = y = z = 0 and the Dirichlet conditions c(x, y, z, t) = T(x, y, z, t) = I for x = y = z = 1.
The parameters of the problem are L = 0.9, a= 1, c5 = 20 and D = Re6 /ac5 with R = 5. The dependent
B.P. Sommeijer et al. /Journal of Computational and Applied Mathematics 88 315-326
Results for RKC for Example 2
# F-evals u
Results for YOOPK for Example 2
0.12· I0-2
variables c and T are the concentration and temperature of a chemical that is undergoing a one-step
reaction. The temperature distribution develops a so-called "hot spot" at the origin. Ignition occurs
at a finite time and T increases sharply to about 1 + oc. A reaction front is formed that propagates
towards the boundary planes x = y = z = 1 where it develops a boundary layer and finally ends in
a steady state. Following we solve the problem for O~t~0.3. By the end of this period the
boundary layers have developed and the solution is approaching steady state. A uniform grid with
spacing h was used and the Neumann boundary conditions were discretized by means of central differences with fictitious points outside the region at a distance of 1h. The grid spacing h = l/(N +0.5)
where N is the number of grid points in each of the three spatial variables. In the computations
reported here N = 40, leading to a total of 2 x 403 = 128 OOO equations.
RKC is a natural candidate for the numerical integration of this flame propagation problem. For
one thing, the travelling reaction front limits the step size of any integration scheme, be it implicit
or explicit. For another, the problem becomes locally unstable in the course of the integration ,
so rather small steps are required to obtain an accurate solution in the transient phase, especially
during ignition. Only during the start and near steady state it is possible to increase the step size to
the point that an implicit method is competitive.
Tables 3 and 4 present results in the same way as for the first example. An extra column in
Table 3 shows the number of F-evals needed by RKC for the estimation of the spectral radius.
We see that the overhead for this automatic estimation is negligible. Both solvers integrate this
difficult problem successfully with only a few step rejections. Neither code obtains accuracies comparable to the tolerance, though again RKc is notably better. With vooPK there is a striking change in
accuracy when reducing tol from 10-6 to 10-1 • The low-accuracy achieved by both codes is to be
expected from the local instability of the problem. Fig. l shows that RKC competes well with vooPK
for this problem, too. RKC adapts the formula, i.e., the number of stages s, to the problem and it
B.P. Sommeijer et al I Journal of Computational and Applied Mathematics 88 315-326
step number
Fig. 2. The number of stages s used by RKC when solving Example 2 with to!:;::: io-6 plotted against step number (left)
and against time (right).
may use s that are quite large compared to what is seen in general-purpose codes based on explicit
Runge-Kutta formulas. The variation of s when solving this problem is displayed in Fig. 2.
5. Remarks
Other interesting stabilized explicit methods have been developed by Lebedev and co-workers, see,
e.g., . There are formulas of order up to four . Although they are also based on
Chebyshev polynomials and so possess optimal stability for real negative eigenvalues, the three-term
recursion is not exploited. A code ouMKA based on these formulas is still in an experimental stage,
but numerical results are promising, see [8, Fig. 10.14].
Source code for RKc and some examples can be obtained by anonymous ftp from the address
ftp://ftp.cwi.nl/pub/bsom/rkc. RKC can also be downloaded from (send rkc.f from
ode). It replaces the program in .