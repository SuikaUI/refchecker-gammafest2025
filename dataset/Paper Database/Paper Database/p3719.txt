A survey of swarm intelligence for dynamic optimization: Algorithms and applications
Michalis Mavrovouniotisa, Changhe Lib,∗, Shengxiang Yangc
aSchool of Science and Technology, Nottingham Trent University, Nottingham, NG11 8NS, United Kingdom
bSchool of Automation and Hubei Key Laboratory of Advanced Control and Intelligent Automation for Complex Systems
China University of Geosciences, Wuhan 430074, China
cCentre for Computational Intelligence (CCI), School of Computer Science and Informatics
De Montfort University, The Gateway, Leicester LE1 9BH, United Kingdom
Swarm intelligence (SI) algorithms, including ant colony optimization, particle swarm optimization, bee-inspired algorithms, bacterial foraging optimization, ﬁreﬂy algorithms, ﬁsh swarm optimization and many more, have been proven to be good methods to
address difﬁcult optimization problems under stationary environments. Most SI algorithms have been developed to address stationary optimization problems and hence, they can converge on the (near-) optimum solution efﬁciently. However, many real-world
problems have a dynamic environment that changes over time. For such dynamic optimization problems (DOPs), it is difﬁcult for a
conventional SI algorithm to track the changing optimum once the algorithm has converged on a solution. In the last two decades,
there has been a growing interest of addressing DOPs using SI algorithms due to their adaptation capabilities. This paper presents a
broad review on SI dynamic optimization (SIDO) focused on several classes of problems, such as discrete, continuous, constrained,
multi-objective and classiﬁcation problems, and real-world applications. In addition, this paper focuses on the enhancement strategies integrated in SI algorithms to address dynamic changes, the performance measurements and benchmark generators used in
SIDO. Finally, some considerations about future directions in the subject are given.
Keywords: Swarm intelligence, Dynamic optimization, Ant colony optimization, Particle swarm optimization
1. Introduction
Swarm intelligence (SI) is an important category of optimization methods. SI is the property of a system whereby the collective behaviours of agents that interact locally with their environment cause coherent functional global patterns to emerge.
Different from evolutionary algorithms (EAs), SI algorithms
are inspired from simple behaviours and self-organizing interaction among agents, such as ant colonies foraging, bird ﬂocking, animal herding, bacterial growth, honey bees, ﬁsh schooling, and so on. The term SI was ﬁrst used by Beni in cellular robotic system where simple agents organize themselves
through neighbourhood interactions and later on established in
 .
The mainstream SI algorithms are ant colony optimization
(ACO) and particle swarm optimization (PSO) . Less
popular SI algorithms include artiﬁcial bee colony (ABC) ,
bacterial foraging optimization (BFO) , ﬁreﬂy algorithm
(FA) , artiﬁcial ﬁsh swarm optimization (AFSO) 
and many others. Originally, SI algorithms were designed for
stationary optimization problems. However, many real-world
optimization problems are subject to dynamic environments.
Changes in a dynamic optimization problem (DOP) may occur
∗Corresponding author
Email addresses: 
(Michalis Mavrovouniotis), (Changhe Li),
 (Shengxiang Yang)
in the objective function, constraints, problem instance, Pareto
front or set (in the case of dynamic multi-objective optimization
problems) that cause the optimum to change. Hence, DOPs are
more challenging to address than stationary optimization problems since repeated optimization of the changing optimum is
required .
The ﬁeld of dynamic optimization is closely related with
EAs, known as evolutionary dynamic optimization (EDO) .
However, it has been a growing interest to apply SI algorithms
on different DOPs. EDO has received extensive attention with
several surveys and books ,
whereas SI dynamic optimization (SIDO) has not received
much attention, with exception of some very brief reviews of
PSO in and ACO in included as subsections in the
EDO surveys. The aim of this paper is to extend these reviews of ACO and PSO and provide a comprehensive survey
of existing work done related to SIDO, which also includes the
less popular and recent SI algorithms. The survey will mainly
focus on classifying SI algorithms based on their applications
and reviewing the strategies integrated with SI algorithms to
tackle dynamic changes. The DOPs are mainly classiﬁed into
problems with discrete and continuous spaces and their applications are further classiﬁed. A review of real-world problems
addressed with SI and reviews of performance measurements
and benchmark generators of SIDO are also given.
The rest of the paper is organized as follows.
brieﬂy presents the concept of DOPs and describes the differences between discrete and continuous DOPs and their appli-
 
January 12, 2017
cations. Moreover, it describes the benchmark generators and
performance measurements commonly used in SIDO. Section 3
brieﬂy describes different SI algorithms. Section 4 reviews algorithms and applications of SIDO arranged by classes of problems, i.e., discrete, continuous, constrained, multi-objective,
and classiﬁcation problems. Section 5 reviews the real-world
applications in which SI algorithms are used. Section 6 concludes this paper and summarizes future research issues and directions on SIDO.
2. Dynamic optimization
2.1. Dynamic optimization problem (DOP)
A DOP can be intuitively deﬁned as a sequence of static
problem instances that need to be optimized . The two
main aspects of “dynamism” are deﬁned by the frequency and
magnitude of an environmental change. The former and latter
parameters correspond to the speed and degree at which the environment of the problem changes, respectively. Other aspects
include the predictability, detectability, and time-linkage of dynamic changes . The former two aspects correspond to
whether a dynamic change can be predicted or detected during
the execution or not, respectively, and the latter corresponds to
whether a decision made now to address a dynamic change is
dependent on any earlier decisions or not.
An environmental change may involve the objective function (or functions if a dynamic multi-objective problem is considered ), input variables, problem instances and constraints (e.g., dynamic constrained optimization ).
Formally, a DOP can be deﬁned as follows:
DOP = optimize f(x, t) subject to X(t) ⊆S, t ∈T,
where S is the search space, t is the time, f : S × T →R
is the objective function that assigns a value (i.e., R) to each
possible solution x ∈S and X(t) is the set of feasible solutions
x ∈X(t) ⊆S at time t . Each feasible solution x consists
of optimization variables x = {x1, . . . , xn}. Every solution x ∈
X(t) has a a set of neighbours N(x) ⊆X(t) where N(x) is a
function that assigns a neighbourhood to x. A local optimum
solution is a feasible solution x′ that f(x′, t) ≤f(x, t), ∀x ∈
N(x) for minimization problems or f(x′, t) ≥f(x, t), ∀x ∈N(x)
for maximization problems, respectively.
The global optimum is a feasible solution x∗that minimizes
(or maximizes) the objective function f(x∗, t) ≤f(x, t) ∀x ∈
X(t) for minimization problems (or f(x∗, t) ≥f(x, t) ∀x ∈X(t)
for maximization problems).
2.2. Discrete vs continuous space
There are different classes of optimization problems that differ in the deﬁnition of the search space X(t). In this paper two
fundamental types of problems are considered as follows:
• Discrete optimization problems where all optimization
variables xi are discrete that take values xi
i , . . ., v|Di|
}, i = 1, . . ., n.
• Continuous optimization problems where all optimization
variables xi are continuous that take values xi ∈Di ⊆
R, i = 1, . . ., n.
The main difference between discrete and continuous optimization problems lies in that discrete optimization problems
have a ﬁnite search space. More precisely, they are characterized by a ﬁnite set of variable values, e.g., binary that are
restricted to the values 0 and 1 or objects drawn from a ﬁnite
set of elements. Differently, each variable value within continuous optimization problems may assume an inﬁnite number
of values, e.g., real numbers. Since computers are digital in
nature, representing discrete variables is straight forward. In
contrast, representing continuous variables requires to impose
certain limitation since it is not possible to represent an inﬁnite
number of values.
In the context of the No-Free-Lunch (NFL)1 theorem ,
any optimization problem that runs in a computer system consists of a ﬁnite domain, and thus, can be considered as discrete.
A different approach to NFL showed that the theorem also holds
for arbitrary domains and co-domains . In contrast, other
studies showed that the NFL theorem does not hold
in continuous domains although its soft form of NFL holds in
countably inﬁnite domains. However, in , it was proved
that NFL does hold in continuous domains because the conclusions of the authors in are drawn from their imposition
of the artiﬁcial constraint that functions under consideration be
measurable. Additional artiﬁcial constraints are imposed but
measurability was enough to trivialize NFL.
Nevertheless, the way of addressing discrete and continuous
problems typically differs. For example, in the case of discrete
problems, the set of available values are predeﬁned before starting the optimization process. Hence, an appropriate solver must
select the best possible combination of values to ﬁnd a solution. Such approach may not be efﬁcient in the case of continuous problems. Instead, a ﬂexible ﬂoating point representation
of real-valued variables is typically used by the solver. In this
way, a more efﬁcient way to ﬁnd a solution with the required
accuracy is allowed.
2.3. Applications
Both discrete and continuous optimization problems have a
wide range of applications to be summarized in Tables 2 and
3, respectively, later. Most practical real-world problems in
the ﬁelds of transportation, scheduling, management, production, facility control, consist of a ﬁnite number of possible solutions. Therefore, they can be formulated as discrete optimization problems.
For example, many real-world optimization problems with
network environments, such as road systems, social networks,
telecommunication networks, rail networks, and so on, are often modelled by weighted graphs. A fundamental discrete optimization problem that is modelled by a weighted graph is the
1NFL theorem roughly states that all search heuristics (like the SI solvers
discussed in this paper) have the same performance when averaged over all
possible functions in ﬁnite search domains.
travelling salesman problem (TSP). The TSP has many applications in both routing and scheduling problems, such as the
vehicle routing problem (VRP), which is closely related in the
ﬁeld of transportation, distribution of goods and logistics. The
arc routing counterpart of the VRP, i.e., the capacitated arc routing problem, has also many applications in the real world, such
as the salt routing optimization problem, urban waste collection
problem and snow removal problem.
Differently, the applications in continuous optimization include practical problems in computational ﬁnance, the training of an artiﬁcial neural network that may be used for medical diagnoses, prediction of trafﬁc in a road system, voice and
face recognition, and forecasting weather or customer demands.
Moreover, it may include the design of optimal shapes such as
wings, turbines, engines, power plants and others.
2.4. Measurements
The aim in tracking the moving optimum (TMO) is to ﬁnd
the best solution of the environment at any time. Researchers
view their algorithms from different perspectives in TMO .
Some researchers pay more attention on extreme behaviours of
a system, in particular, the best that the system can do, e.g.,
modiﬁed ofﬂine performance , collective mean ﬁtness
 , best before change . Differently, other researchers
want to observe “how close to the moving optimum a solution
found by an algorithm is” . Therefore, the measurements require that the global optimum value is known during
the dynamic changes, e.g., the ofﬂine error , average score
 , accuracy and other measurements based on the distance between the solutions found by the algorithm and the
global optimum . Others are concerned for measures
which can characterize the population as a whole, e.g., the average performance or the average robustness .
Recently, a new perspective on DOPs has been established,
known as robust optimization over time (ROOT), where the target is to ﬁnd the sequence of solutions which are robust over
time . Particularly, a solution is robust over time when
its quality is acceptable to the environmental changes during
a given time interval. Regarding SI algorithms, so far, TMO
has been mainly used with all of them. In contrast, ROOT has
been used only with PSO algorithms . Robust optimization
was found to be useful when dealing with problem uncertainties
with PSO and ACO , e.g., reducing computational
Apart from measurements that involve the performance of
algorithms, other measurements involve the behaviour of algorithms.
Popular examples are: the diversity of solutions
 , stability , reactivity , robustness
 , cross-entropy , peak cover and λ-branching 2.
Other performance measurements were proposed exclusively to
evaluate the ability of the algorithms to track and locate feasible regions such as: feasible time ratio, optimal region tracking measure, local search cover, number of evaluations for constraints. In addition, existing measurements were modiﬁed for
2Cross-entropy and λ-branching are especially designed for ACO to gather
information of the distribution of the pheromone trails.
dynamic constrained optimization problems such as: the peak
cover to count the number of only feasible regions in each period and the ofﬂine error to consider the best error as normal but
if there is no feasible solution; then the current worst possible
value is considered .
Of course, all the above measurements for DOPs assume a
single objective. Different measurements are used when dealing with multiple objectives such as: spacing , hypervolume
ratio , S- and FS-metrics , accuracy , stability ,
variable space generational distance and maximum spread
2.5. Benchmark generators
Benchmark generators are essential tools in DOPs, due to
the limited theoretical work available in SIDO and generally
in dynamic optimization . They enable researchers to
develop and evaluate new algorithms for DOPs, and more importantly to compare them with existing ones.
2.5.1. The generation of dynamics
A straightforward method, but not efﬁcient, to construct a
dynamic test problem is to switch between different static instances that will cause an environmental change .
benchmark problems that generate dynamic environments following this methodology are speciﬁed for a single problem. In
some other cases, researchers prefer to create their own customized benchmark problems that aim to model some realworld scenarios which again are developed for a speciﬁc problem, or even a speciﬁc instance of
the problem.
Several general purpose dynamic benchmark generators have
been proposed that re-shape the ﬁtness landscape (for continuous problems) or move the search process to a different location of the ﬁtness landscape (for discrete problems). Comprehensive surveys can be found in . Probably the most
commonly used benchmark generators for DOPs are: (1) the
moving peaks benchmark (MPB) ; (2) the generalized dynamic benchmark generator (GDBG) ; (3) the exclusive-or
(XOR) DOP generator for binary-encoded problems ; and
(4) the dynamic benchmark generator for permutation-encoded
problems (DBGP) . The ﬁrst two benchmark generators
work for the continuous domain where they use functions with
adjustable parameters to simulate shifting landscapes. Considering that the continuous space can be modelled as a “ﬁeld of
cones” , then each cone can be adjusted individually to represent different dynamics. Fig. 1 shows the ﬁtness landscapes
of two cases that belong to the MPB and the GDBG, respectively.
Since the continuous space has an inﬁnite number of variable
values, certain limitations are imposed to develop benchmarks
to solve complex mathematical functions. The MPB is one
of the mostly used benchmarks for testing the performance of
algorithms in the continuous space. Each peak in the MPB
problem is a cone shape. This would be easy for an algorithm to
exploit a local optimum in the ﬁtness landscape. To overcome
the limitation of DOPs like the MPB and DF1 (a similar
Fig. 1: The landscape of the MPB (left) and the GDBG (right).
benchmark generator with MPB), the GDBG benchmark was
developed by Li et al. , which was initially proposed for
the 2009 IEEE Competition on Evolutionary Computation for
DOPs. The GDBG has a more complex ﬁtness landscape than
the MPB problem due to a huge number of rotated optima in the
search space. In the GDBG benchmark, there are six basic test
functions and each test function has eight change types, which
are the small step change, large step change, random change,
chaotic change, recurrent change, recurrent change with noise,
dimensional change and number of peaks change. In , the
MPB was modiﬁed to generate ROOT problems. In the original MPB for TMO, all the peaks are changed at the same frequency and severity, whereas on the modiﬁed MPB for ROOT
each peak has its own frequency and severity.
In discrete spaces, the landscape is indistinct and cannot be
deﬁned without reference to the optimization algorithm .
Usually, the components that deﬁne the discrete/combinatorial
optimization problem are modiﬁed and are speciﬁc to the problem. For the dynamic TSP (DTSP), when a change occurs, either nodes may be replaced/removed or the weights of the
arc may increase/decrease . The dynamic changes in
dynamic VRP (DVRP) may occur on the weights of the arcs
 or new customers may be revealed . Dynamic changes
occur when new jobs arrive during the execution for the dynamic job shop scheduling problem (DJSSP) .
changes in the dynamic knapsack problem (DKP) may occur on
the value and weight of items as well as the capacity of knapsack or directly to the objective function . The XOR DOP
can generate a DOP for any binary-encoded problem, which are
special case of discrete problems, by ﬂipping the values from
“0” to “1” and vice verse, according to binary templates. The
DBGP can generate a DOP for any permutation-encoded routing problem, by swapping the nodes of the problem instance
The MPB, GDBG, DBGP, XOR DOP benchmark generators and all other aforementioned benchmarks assume unconstrained and single objective optimization problems. Recently,
benchmark generators for continuous dynamic constrained optimization and continuous dynamic multiobjective optimization are
proposed. But, constrained and multi-objective optimization
under the discrete space has not attracted much attention yet
and deserves future consideration.
2.5.2. Discussion
For benchmarks in the continuous space, most of them take
the following form to generate landscape: f(x, t) = maxgi(x, t).
This way is simple and straightforward. However, it has two
disadvantages. Firstly, it is computationally inefﬁcient. To evaluate a solution, we have to compute the objective value of every
g, and then ﬁnd the best objective value as the objective value of
the solution. Secondly, some peaks may be invisible if they are
covered by higher peaks. In addition, these benchmarks lack of
scenarios of real-world problems.
For benchmarks in the discrete space, the variables of the
problem instance are typically modiﬁed, e.g., the nodes or arcs
of a weighted graph G = (C, L, t) that represent the problem.
Although real-world scenarios are generated with most benchmarks the global optimum value is unknown during dynamic
changes. Hence, if all compared algorithms are performing far
away from the optimum, one will not be able to observe it. A
solution to that is to move the search process into a different
location of the landscape rather than changing it, e.g., using
the DBGP (for permutation-encoded problems) and the XOR
DOP (for binary-encoded problems) that can generate dynamic
environments without affecting the global optimum value. Basically, the encoding of the problem instance is modiﬁed rather
than the search space. However, the real-world scenario ability
is sacriﬁced for the sake of benchmarking.
3. Swarm intelligence algorithms
3.1. Brief description
The area of metaheuristics in SI is chaotic because there are
many “novel” metaheuristics that are basically repeating existing metaheuristics or are not even inspired by nature or
swarms, e.g., the ﬁreworks algorithms inspired by the ﬁreworks
explosions . Nevertheless, this paper focuses only on the SI
metaheuristics applied to DOPs as listed in Table 1.
Generally speaking, all SI algorithms were developed specifically for different optimization problem domains as deﬁned
in Table 1. For example, ACO was developed for a discrete
space whereas the remaining algorithms in Table 1 for a continuous space. The common characteristics of these algorithms
Table 1: Swarm intelligence algorithms applied on DOPs so far
Initial Problem
Exploitation Mechanism
Exploration Mechanism
Ant colony optimization (ACO)
optimization
Construction
according to heuristic information
Consideration of pheromone
trail values
Particle swarm optimization (PSO)
Continuous
optimization
Update the particle positions
towards the global best particle
Velocity update of particles
Artiﬁcial ﬁsh swarm optimization (AFSO)
Continuous
optimization
Prey behaviour
Bacterial foraging optimization (BFO)
Continuous
optimization
Chemotaxis and reproduction steps
Elimination-dispersal step
Artiﬁcial bee colony (ABC)
Continuous
optimization
Neighbourhood search carried by employed and onlooker bees
Fireﬂy algorithm (FA)
Continuous
optimization
Fireﬂy movement according
to attractiveness
Random move of the best
are that they are inspired from nature, population-based, and
iterative. Their differences, apart from their behaviour inspiration, lie in the way the search space is explored and exploited
by the “agents” .
3.1.1. Ant colony optimization (ACO)
ACO was inspired by the foraging behaviour of real ants. The
goal of ants is to ﬁnd the shortest path between their nest and
food sources. ACO metaheuristic is based on several construction steps and on a dynamic memory structure that contains information regarding the quality of previously obtained results
 . Each ant represents a potential solution of the problem. ACO consists of a forward mode where ants construct their
solutions probabilistically based on existing pheromone trails
and heuristic information available a priori. When all ants complete their forward mode they switch to their backward mode
where a shared pheromone table is updated accordingly, i.e.,
the better the solution quality the more pheromone deposited.
There are two main ACO frameworks, i.e., evaporationbased and population-based .
Their difference
lies in the way pheromone is updated. The evaporation-based
framework reduces the pheromone trails gradually by a constant amount to eliminate any previous poor old “decisions”.
The population-based framework uses a population that removes pheromone trails directly when a solution is removed
from the population.
3.1.2. Particle swarm optimization (PSO)
PSO was ﬁrst introduced in to address continuous optimization problems. Each particle represents a potential solution of the problem. More precisely, each particle consists of
a velocity and position vectors, respectively, which are updated
according to the best so far position of the particle and the best
so far position of the swarm.
There are two main models of the PSO algorithm, i.e., the
global best and local best, respectively. Their difference lies in
the neighbourhood structure for each particle. In the global best
model, the neighbourhood of a particle consists of the particles in the whole swarm, which share information between each
other. On the contrary, in the local best model, the neighbourhood of a particle is deﬁned by several ﬁxed particles. Poli et al.
 stated that the global best model converges faster than the
local best model whereas the former model has a higher probability of getting stuck in local optima than the latter model.
Surveys of different PSO variations can be found in .
Both models are used but in different ways due to their
characteristics.
The global best model is normally used in
multi-swarm based algorithms , while the local best
model is commonly used in algorithms with a single swarm
 .
3.1.3. Artiﬁcial bee colony (ABC)
There are several developments of bee-inspired algorithms
such as: ABC, bee colony optimization, bee system, marriage
process bee, honey bee mating optimization, virtual bee algorithm, honey bee algorithm and beehive algorithm. Surveys of
the different developments can be found in . In
this paper, we mainly focus on the ABC algorithms that have
attracted most of the attention, especially in DOPs . In
particular, an ABC algorithm mimics the behaviour of real bees
colonies . A conventional ABC algorithm consists of food
sources, whereas each food source represents a potential solution of the problem. Food sources are updated by three groups
of bees: employed, onlooker and scout bees.
Within the employed bee phase, bees search for new solutions. In particular, each bee produces a new candidate food
source position from the old one. In the case that food sources
with more nectar are found, i.e., the new solutions have better
ﬁtness than the current, then they are updated. Next, the relative probabilities according to the ﬁtness determined from the
employed bee phase are determined in the onlooker bee phase.
Then, onlooker bees select a solution probabilistically in which
the ﬁttest solutions have a higher probability to be selected by
onlooker bees. After that, onlooker bees have the same be-
haviour with the employed bees. Finally, scout bees randomly
reallocate solutions if they are abandoned, e.g., they have not
been updated for a certain time.
3.1.4. Bacterial foraging optimization (BFO)
The BFO algorithm was inspired by the complex organized
activities in bacterial foraging and the survival of bacteria in different environments . A BFO algorithm consists of
several bacteria, which represent solutions in the optimization
problem and consists of three processes: chemotaxis, reproduction, and elimination-dispersal.
In chemotaxis, a bacterium with random direction represents
a tumble and a bacterium with the same direction of the previous step indicates a run. Next in the reproduction process all
bacteria is sorted and only half of the ﬁttest bacteria survive.
Then, the surviving bacteria is split into two identical ones to
form the new bacteria. Finally, in the elimination-dispersion
process, a bacterium is chosen probabilistically to move to a
different random position in the search space. Although this
action maintains the diversity during execution, it may disturb
the optimization process and therefore it is performed after several steps of the reproduction process.
3.1.5. Artiﬁcial ﬁsh swarm optimization (AFSO)
There are several existing developments of ﬁsh-inspired algorithms. A detailed description of developments can be found
in . In this paper, we focus on the AFSO inspired by
the foraging behaviour of real ﬁsh swarms in water world 
which was applied for DOPs. Within AFSO, each artiﬁcial ﬁsh
looks for a position (solution) with more food source (better ﬁtness) by performing three main behaviours: prey, swarm and
follow. The prey behaviour is performed by an artiﬁcial ﬁsh
without considering other swarm members. More precisely, a
target position better than the current is considered randomly
within the visual of the ﬁsh.
The swarm behaviour is a group behaviour and is performed
globally among all members of swarm as follows. Each artiﬁcial ﬁsh consists of a number of neighbours within its visual. If
the central position of the visual ﬁeld is better; then it moves
towards the central position; otherwise, the prey behaviour is
performed again. Similarly, the follow behaviour is performed,
but instead of moving toward the central position, the artiﬁcial
ﬁsh will move toward a better neighbour position within its visual. Otherwise, the prey behaviour is performed again. Basically, the prey behaviour is performed when an artiﬁcial ﬁsh is
not able to move to a better position when the follow or swarm
behaviour is performed. If the algorithm reaches stagnation behaviour some artiﬁcial ﬁshes are selected randomly from the
whole artiﬁcial ﬁsh swarm and are set randomly. The best so
far artiﬁcial ﬁsh position (i.e., solution) is recorded.
3.1.6. Fireﬂy algorithm (FA)
The FA was inspired by the ﬂashing patterns and behaviour
of ﬁreﬂies . An FA is based on three assumptions:
1. all ﬁreﬂies can be attracted by all other ﬁreﬂies
2. the attractiveness of each ﬁreﬂy is proportional to the
brightness of other ﬁreﬂies
3. the landscape of the problem determines the brightness of
Hence, a ﬁreﬂy that is less bright will move toward a more
bright one. Otherwise, if a ﬁreﬂy is not able to locate a brighter
ﬁreﬂy, it will move randomly. Each ﬁreﬂy glows proportionally
to its solution quality, which, together with its attractiveness,
dictates how strong it attracts other members of the swarm.
3.2. Adapting in changing environments
Since all SI algorithms were initially designed for stationary
optimization problems, they share a common property: convergence, i.e., they are designed to converge to the optimum
quickly and precisely. In contrast, DOPs require repeated optimization and tracking of the moving optimum. However, when
an algorithm converges, its adaptation capabilities are lost due
to the diversity loss problem. Therefore, it is important to address the diversity loss problem by increasing/maintaining the
diversity. However, it does not mean that a high level of diversity will lead to better performance . This is because
too much randomization may disturb the optimization process.
Another important aspect of SI algorithms to adapt well in
DOPs is to promote the knowledge transfer. Naturally, knowledge can be transferred from previously optimized environments using SI algorithms, e.g., via pheromone trails with
ACO, via the food sources with ABC and AFSO, via the position of ﬁreﬂies and bacteria with FA and BFO, respectively.
However, it may not be enough to quickly recover when a dynamic change occurs. On the other hand, if too much knowledge is transferred, it may start the optimization process close
to a poor local optimum and get stuck there.
Enhanced SI algorithms have proved to be powerful for different DOPs. The main idea of enhancement strategies integrated to SI algorithms is to achieve a good balance for knowledge transfer and diversity maintenance as shown in Fig. 2. In
addition, these two factors are also conﬂicting because if diversity is not maintained then the algorithm will not be very
ﬂexible to utilise any knowledge transferred.
Fig. 2: Effects of tuning diversity maintenance and knowledge transfer of SI
algorithms in DOPs
4. Swarm intelligence for dynamic optimization
In this section, major SI strategies that tackle dynamic
changes will be reviewed for various classes of problems di-
vided as follows:
• SI in dynamic discrete optimization
• SI in dynamic continuous optimization
• SI in dynamic constrained optimization
• SI in dynamic multi-objective optimization
• SI in dynamic classiﬁcation
Since the ﬁrst two classes have been extensively researched,
they are further classiﬁed by application (see Tables 2 and 3)
and by the type of strategy: (a) increasing diversity after a
change, (b) maintaining diversity during execution, (c) memory
schemes, (d) multiple population3 methods and (e) hybridizations. The remaining classes are current trends in SIDO and
their research is limited.
4.1. SI in dynamic discrete optimization
Many discrete optimization problems, either in stationary or
dynamic environments, are NP-hard, i.e., it is strongly believed that they cannot be solved to optimality within polynomial computation time . Dynamic versions of several popular discrete optimization problems have been addressed using
SI methods.
From Table 2, it can be observed that ACO is mostly used
for discrete/combinatorial problems. Typically, these problems
are represented using weighted graphs G = (C, L), where C is a
set of components and L is a set of links. For example, for the
DTSP or DVRP, the pheromone trails τi j are mapped with both
the components and links of the problem to represent the desirability of visiting component (node) j after component (node) i.
Similarly, the pheromone trails in DJSSP refer to the desirability of choosing operation j directly after operation i. For binaryencoded problems, pheromone trails are associated to the two
possible choices that a component can take. For the DKP the
pheromone trails τi are associated only with the components
and refer to the desirability of adding item i. Therefore, when
a dynamic change occurs, some of the current pheromone trails
will not be compatible with the characteristics of the new environment whereas some others will contain information useful
to guide optimization into promising areas of the search space
Several strategies were proposed to address this issue categorized in the following subsections.
4.1.1. Increasing diversity after a change
Many strategies in DOPs depend on the detection of dynamic
changes. The detection is typically performed by re-evaluating
a solution and whenever a change in its ﬁtness occurs then a
dynamic change is detected. The strategies in this category performs actions whenever a change is detected to increase diversity.
3Population is used as a general term to deﬁne a set of agents. For different
SI algorithms, a population is deﬁned differently, e.g., as colony for ACO and
ABC, as swarm for PSO, AFSO and FA, and as bacteria for BFO.
1. Complete restart.
The pheromone trails of ACO algorithms are re-initialized with an equal amount whenever
a change is detected for DTSP and DVRP .
This corresponds to a complete restart of the algorithm
that optimizes each dynamic change from scratch. Since
the initial phase of an algorithm is highly explorative, the
diversity is increased signiﬁcantly. However, all previous
knowledge gained is destroyed.
2. Partial restart. Other strategies aim to simply increase the
diversity and maintain the knowledge gained, simultaneously, when a change occurs. For example, Guntsch and
Middendorf proposed partial restart strategies
using local information, e.g., the η-strategy and τ-strategy,
which take into account where the dynamic change actually occurs, e.g., which cities are added/removed for
DTSP. The aim of both strategies is to give a higher degree
of re-initialization to the pheromone trails closer to the offended areas. This corresponds to a partial restart of the algorithm because knowledge is maintained and could speed
up the optimization process. However, apart from detecting the period of change, the location of changes needs to
be detected. It may not be always available or requires
extensive computational efforts to detect them. A similar
partial restart strategy via pheromone trails was proposed
for the DJSSP .
Angus and Hendtlass used the old pheromone trails
and modiﬁed proportionally to the maximum pheromone
trail value for DTSP. Similarly, Eyckelhof and Snoek 
proposed a “shaking technique” to regulate the previous
pheromone trails. All pheromone trails are modiﬁed using a logarithmic formula, where the pheromone values
closer to the initial pheromone value are deducted slightly,
whereas higher pheromone values are deducted severely.
The same shaking technique was adopted in a PSO variation that uses a pheromone table as a communication
topology for particles . However, the results
were not as promising as with ACO algorithms that are
more effective for graph problems.
The above strategies performed modiﬁcation via the
pheromone trails directly. In contrast, Rand and Riolo 
repaired the best solution of the previous environment for
the DKP, since it became infeasible by the change, using
a deconstruction technique. The pheromone trails are affected indirectly according to the changes made to the solutions during the repair. In this way, partial knowledge of
the previous environment is preserved. On the same problem but with a different type of dynamic changes that does
not affect the representation of the problem, Baykaso˘glu
and Ozsoydan enhanced the diversity of FA by partially restarting a part of the population when a dynamic
change occurs.
Montemanni et al. addressed the DVRP by dividing the working day into time slices. Basically, the dynamic problem is split into a series of several static problems that are optimized by ACO separately. Pheromone
conservation of the previous static problem was used to
prevent starting the optimization from scratch for the next
Table 2: Swarm intelligence applications for discrete DOPs
Dynamic Travelling Salesman Problem
[110, 54, 111, 66,
44, 65, 55, 21,
115, 35, 55, 116,
[118, 119, 120,
Dynamic Vehicle Routing Problem
124, 125, 48, 49,
37, 33, 126, 127]
 
Dynamic Job Shop Scheduling Problem
 
Dynamic Knapsack Problem
Other Binary-Encoded Functions
Table 3: Swarm intelligence applications for continuous DOPs
Moving Peaks Benchmark
 
[169, 170, 171,
 
 
 
Generalize Dynamic Benchmark Generator
 
 
 
Other Time-Varying Functions
 
 
 
problem. Using time slices, the detection of change is not
necessary. However, the performance of the algorithm depends on the number of time slices that is predeﬁned. A
similar ACO approach was proposed in and a PSO
approach in . More PSO variations using time slices
were proposed by Khouadjia et al. . Each particle keeps track of its best solution which is later used to
form the initial swarm for the next time slice. In contrast,
the initial swarm of the next time slice in is deﬁned
by the previous global best within a given radius.
4.1.2. Maintaining diversity during execution
There are strategies that do not necessarily require the detection of change to increase diversity. Diversity is maintained
during the execution.
In fact, unmodiﬁed ACO algorithms
were applied to the DJSSP and binary-encoded problems
 . Because pheromone evaporation helps to forget unused pheromone trails, it helps the adaptation process when a
dynamic change occurs. Another way is to gather statistics
from the pheromone trails to detect stagnation and re-initialize
the pheromone trails . This way was used to the aforementioned PSO with pheromone matrix for the DTSP .
Based on the pheromone evaporation effect, the pheromone
evaporation rate ρ was adapted during the optimization process
 for DTSP and DVRP to speed up the adaptation. The idea
is to increase the evaporation rate when the algorithm is approaching stagnation behaviour to eliminate pheromone trails
faster. Since the adaptive method required a ﬁxed step size; a
self-adaptive evaporation rate was later proposed to address this
issue . In particular, the evaporation rate is discretized to
a set of values with which pheromone trails are associated. The
ants are responsible to select the appropriate rate at each iteration.
Ankerl and H¨ammerle self-adapted the α and β parameters that control the weight of pheromone trails and heuristic information, respectively. Each ant uses a different set of
these parameters, which initially are the same. This way enables ants to explore different locations of the search space, and
thus, maintain diversity. Liu modiﬁed the decision rule of
ACO instead of adapting the control parameters. A rank-based
non-linear selection pressure function is integrated to the decision rule. Although the integration enhances diversity, it causes
the introduction of new parameters that need to be optimized.
A very popular strategy integrated with ACO is the immigrants scheme . The general idea is
to introduce immigrant ants, either randomly or using the best
from the previous environment, to deposit pheromone trails. In
this way, diversity is maintained. However, if too many random
immigrant ants are generated, they may disturb the optimization
4.1.3. Memory schemes
Another way to transfer knowledge from previous environments is to use an external memory. Typically, promising solutions are stored in the memory and reused when a dynamic
change occurs. Again, this type of strategies require the detection of change to update the memory or even repair it.
One of the most popular ACO for the DTSP is the
population-based ACO (P-ACO) .
P-ACO maintains
a memory of the best ants that is used for updating the
pheromones. When a dynamic change occurs, the ants in the
memory are repaired heuristically, and thus, the pheromone values are modiﬁed. Similarly, with the η-strategy and τ-strategy
mentioned above, the location of changes is required for the
heuristic repair.
The memory-based immigrants ACO uses a limited size memory to store the best representative solution from
several previously optimized environments. The idea is to generate immigrant ants based on the currently best memory to
transfer knowledge and increase diversity simultaneously.
4.1.4. Multiple population methods
The use of separate populations can naturally increase and
maintain diversity. The idea is to allocate different populations
into different areas in the search space.
A multi-colony ACO algorithm where each colony uses a
separate pheromone table in an attempt to maximize the search
area explored was proposed for the DTSP and DVRP
 . An explicit method to keep the colonies into different areas was not applied, but the results showed that it performs
better than a single colony ACO algorithm. In contrast, multicolony ACO in which different colonies, called castes, use the
same pheromone table was proposed in . Each caste
uses different parameter settings that correspond to different behaviour for each caste that can cover different location of the
search space. A similar idea was adopted in PSO for the DVRP
For PSO, a multi-swarm algorithm based on the island model
was proposed for the DVRP .
Particles from different
swarms migrate regularly to others to maintain diversity. A different multi-swarm was introduced in , where the communication was performed only with the arrival of a new environment.
4.1.5. Hybridizations
The strategies in this category emphasize more on the hybridization of the SI algorithm with a local search method. Usually, algorithms enhanced by a local search, known as memetic
algorithms, provide signiﬁcantly better solutions with the price
of increasing the computation time. The idea is to let the main
algorithm provide an initial solution for the local search to optimize. But since local search operators generate strong exploitation the algorithms need to maintain diversity.
The P-ACO described above was improved in ,
where several local search steps based on simple and adaptive
inversions are applied to the iteration best ant. In addition the
diversity is enhanced with the triggered random immigrants entering the memory, whenever all ants stored in the memory are
identical. Recently, another memetic-based ACO was proposed
in that uses a local search whenever a new best solution
is found. Whenever the algorithm is entering stagnation behaviour (very often because of the local search), the pheromone
trails are re-initialized to the maximum value to maintain diversity.
4.2. SI in dynamic continuous optimization
The MPB described in Section 2.5 is the most widely used
problem for DOPs in the continuous space. The key idea to
tackle this problem (and in general multimodal problems as
GDBP) is to locate and track all peaks (local optima) in the
search space. When a change occurs, one of these local optima
may become the global optimum. Other time varying functions
include the Sphere, Ackley, Griewanks, Rastrigin, Rosenbrock,
Schwefel, where a random value chosen from an exponential
distribution is added/subtracted in every dimension. The Sphere
and the two dimensional Rosenbrock functions are unimodal
whereas the remaining functions are multimodal, just like the
MPB and GDBP. Other time varying unimodal functions include the parabolic function.
From Table 3 it can be observed that PSO is mostly used
on continuous problems. Each particle in the swarm has its
own knowledge about its local environment. If the knowledge
helps to solve the problem when a dynamic change occurs, it
will quickly transfer among particles via simple interactions between particles. In this way, the position of the particles will be
updated (essentially) towards the global optimum. Similarly,
other SI algorithms can help to solve the problem but using different interactions. Nevertheless, all SI algorithms may need
some enhancements in some perspective to escape from the previously converged optimum and effectively track the new one.
Several strategies were proposed to address this issue, which
are categorized in the following subsections.
4.2.1. Increasing diversity after a change
Similarly, with the corresponding category of discrete optimization above, the strategies in this category depend on the
detection of change.
In a conventional PSO algorithm was applied on
the time-varying parabolic function that reﬂects a simple unimodal ﬁtness landscape. When a dynamic change occurs, part
of the population is randomly initialized.
4.2.2. Maintaining diversity during execution
Strategies in this this category explicitly maintain the diversity during the execution using different techniques, which are
further grouped as follows.
1. Special mechanisms. Inspired from the atom ﬁeld, Blackwell et al. introduced a multi-charged PSO (mCPSO)
and a multi-quantum swarm optimization (mQSO). In
mCPSO, a part of particles in each swarm, named
“charged” particles, repel each other and circle around
neutral particles. In mQSO, the “quantum” particles move
randomly around the best particle. Both algorithms were
improved by re-initializing the worst performing swarm
whenever all swarms converge for maintaining diversity
 . Li et al. integrated the quantum particles
(from mQSO) to the SPSO to improve its adaptation capabilities. Thereafter, both SPSO and mQSO were further
improved by converting particles to quantum particles for
a single iteration after a dynamic change is detected .
The quantum principle introduced in was also applied in a speciation FA (SFA) algorithm and in a
continuous variation of ACO .
Another example is a BFO for dynamic environments
where chemotaxis is performed every iteration, reproduction is performed every fr iterations, and
elimination-dispersion is performed whenever a dynamic
change occurs. In this way, bacteria will spread out to the
search space, e.g., carrying out exploration.
2. Individual selection. Daneshyari and Yen modiﬁed
both the particle selection and replacement mechanisms
so that the most diversiﬁed particles (measured by the
Hamming distance) are selected and the particles that have
close locations are replaced. Tang et al. proposed a
dynamic BFO (DBFO) that uses a more ﬂexible selection
scheme to maintain diversity, where the selection during
reproduction is made probabilistically, in a way similarly
to the one used in EAs. In , a modiﬁed ABC (MABC)
was proposed with the restriction of the communication
among bees to only the ones that are closer.
3. Operator selection.
A PSO-based memetic algorithm
 was proposed, where two local search operators are
adaptively selected for maintaining the diversity.
4. Randomization. Kojima et al. applied a dynamic
ABC (DABC) algorithm to the dynamic Rastring and
Rosenbrock functions, where independent food sources
are used for each search phase and the cauchy distribution
is taken in the employed phase.
In contrast, other strategies in this category focus on adjusting the neighborhood of an individual to implicitly maintain
the diversity during the optimization process.
For example,
the speciation based PSO (SPSO), proposed by Parrott and Li
 , adaptively organizes a neighbourhoodof particles in
each iteration according to certain principles based on their ﬁtness and distance. In SPSO, the number and size of swarms are
adaptively adjusted by constructing an ordered list of particles,
ranked according to their ﬁtness, with spatially close particles
joining a particular species. The speciation scheme was adopted
in a speciation FA (SFA) algorithm to create sub-swarms.
Similarly, the compound concept derived by a branch of
physics was introduced in PSO .
Instead of the
“ﬁttest ﬁrst” principle in SPSO, swarms are constructed based
on a “worst ﬁrst” principle, but each composite particle consists of three ﬁxed particles. Thereafter, an opposite version
was proposed, where a sub-swarm is generated based on the
“ﬁttest-oriented” principle .
Janson and Middendorf proposed a partitioned hierarchical PSO (PH-PSO) that uses a dynamic tree-based neighbourhood structure. Each particle is placed on a single node
of the tree and particles are arranged hierarchically according
to their ﬁtness. Chen et al. have used a bee life cycle
method to dynamically adjust the size of the colony according
to the local ﬁtness landscape during optimization. Parsopoulos
and Vrahatis proposed a uniﬁed PSO with a constriction
factor, which combines the global and local best PSO variants.
Furthermore, ACO variations that replace the conventional
discrete probability distribution by a continuous are applied on
different time-varying functions and GDBG .
By setting a higher evaporation rate ACO variations can adapt
to changes as described in Section 4.1.
4.2.3. Memory schemes
As mentioned above, the memory scheme aims to transfer
“useful” knowledge from previous search to accelerate the current search. This scheme can also help maintain the diversity.
To implement a memory scheme, an external archive is normally needed. An archive population was used to store good solutions whenever a dynamic change is detected or when a peak
is found in a tri-island model . Best solutions are maintained in an archive whenever a change occurs in the employed
bee phase for a differential ABC algorithm and an improved ABC algorithm . A history-driven SFA (HdSFA)
 algorithm uses two types of memory: a short-term memory, which is responsible for storing information regarding the
current environment, and a long-term memory, which is responsible to store information regarding the previous environments.
The same memory scheme is adopted in PSO . Recently,
SPSO was enhanced with a memory that stores particles from
different species .
4.2.4. Multiple population methods
The multi-swarm scheme is a kind of divide-and-conquer
strategy. Searching in a different area for each swarm means
that the search space is divided into multiple sub-spaces and
each swarm is responsible for searching one sub-space. By doing so, it has several advantages . Firstly, the global diversity can be maintained since swarms search in different areas.
Secondly, tracking multiple optima simultaneously is possible.
Thirdly, any scheme based on a single swarm approach can be
easily extended to a multi-swarm version. Multi-swarm strategies can be classiﬁed to the following categories in terms of the
number of swarms.
1. Static (or ﬁxed) number of swarms. This group of strategies can be further classiﬁed to two types: competing and
collaborative types. For the competing type, swarms compete with each other, i.e., they are not allowed to search
in the same area. On the contrary, in the collaborative
type, swarms are allowed to search in the same area and
cooperate with each other, i.e., they may share information.
Blackwell’s mCPSO and mQSO belong to
the competing type.
Each swarm has an exclusion radius to prevent sub-swarms from overlapping each other.
Similar ideas of the exclusion principle in mQSO were
adopted in other algorithms, such as the multi-swarm modiﬁed AFSO (MAFSO) , multi-swarm FA algorithms , multi-BFO (MBFO) algorithm
 , multi-swarm ABC , and k-means clustering
ABC (CABC) . A typical collaborative type of multiswarm algorithm is the collaborative evolutionary swarm
optimization (CESO) , where two heterogeneous
swarms cooperate with each other. The two swarms follow the crowding differential evolution (CDE) and
PSO models, respectively. The former swarm is responsible for diversity maintenance whereas the latter swarm is
responsible for tracking the global optimum. Similarly, the
dual-swarm approach was adopted in . An evolutionary swarm cooperative algorithm (ESCA) with an
additional swarm, was proposed in . Within ESCA,
three swarms are used and share information among each
2. Dynamic number of swarms. This type of strategies can
be further grouped to two models in terms of the way to
create sub-swarms: regrouping and splitting models. The
regrouping model regroups individuals by a certain means
every iteration or when a certain criterion is satisﬁed, such
as the speciation based PSO (SPSO) and the
randomized regrouping multi-swarm PSO . The clustering PSO (CPSO) algorithm proposed by Li and Yang
 uses a hierarchical clustering method to generate sub-swarms whenever a change is detected. To avoid
change detection, CPSO was later on improved with a new
version, called CPSOR , where random particles are
introduced and clustered into new swarms when the total
number of particles drops to a threshold ratio. The splitting model normally generates sub-swarms by splitting off
from a main swarm when a certain criterion is met, such
as the fast multi-swarm optimization (FMSO) algorithm
 . FMSO starts with a parent swarm. Whenever the
best particle gets better, a child swarm is generated with
the best particle and particles within a given distance from
the best one. Similar ideas were adopted in a multi-swarm
PSO algorithm (mPSO) , and algorithms proposed in
 .
3. Adaptive number of swarms. To efﬁciently solve DOPs
by the multi-swarm scheme, one key issue is to adapt the
number of swarms . This issue becomes
more challenging for DOPs with a changing number of
optima. The basic idea is to increase swarms when current
swarms are converging and remove swarms when they are
over-crowded. Blackwell proposed the self-adaptive
multi-swarm optimizer (SAMO) which is the ﬁrst adaptive method regarding the number of populations. It begins
with a single free swarm (e.g., a non-converging population). Free swarms gradually transform themselves into
converging swarms.
Converging swarms are identiﬁed
when their radius is less than a given convergence radius
rconv). A new free swarm is randomly generated if there
is no free swarm. This way, the number of populations
is able to adaptively change based on the status of current
swarms. An adaptive multi-swarm optimizer (AMSO) was
proposed , where the number of swarms is adjusted
according to the differences of the number of swarms between two successive “checking points”. A multi-swarm
AFSO was proposed , where a child swarm is generated whenever a parent swarm locates a new peak. The
child swarm tracks the peak has been located. Recently,
the number of swarms was adapted using a database
that collects heuristic information of the algorithm behaviour changes to better track multiple optima. Nseef et
al. proposed a multi-colony ABC algorithm. The
number of colonies is adaptively maintained based on the
dynamic change strength.
4.2.5. Hybridizations
The hybridization with different domain knowledge, e.g., genetic algorithms, differential evolution, or other meta-heuristic
methods, e.g., microbial life, fuzzy, and cellular automata, is
also an important research topic.
1. Hybridization with other domain knowledge. For example, a multi-strategy ensemble PSO (MEPSO) uses
Gaussian local search and differential mutation for exploration and exploitation.
A dynamic macro-mutation
operator was introduced in a PSO algorithm .
PSO-based memetic algorithm uses a ring topology
structure and a fuzzy cognition. A fuzzy cognition with
multiple local searches was also used in . An improved mQSO algorithm (mQSOE) uses an evaporation mechanism as used in ACO to penalize the ﬁtness
value of the best position found by each particle in the past.
2. Hybridization
meta-heuristic
Hashemi and Meybodi proposed a hybrid
model of PSO with cellular automata to address DOPs,
where the search space is embedded with cellular automata and is separated into several cells. Each cell is
allowed to contain only a speciﬁed number of particles to
prevent diversity loss. Rezazadeh et al. proposed
an adaptive PSO algorithm. The algorithm uses a fuzzy
C-means mechanism to adapt the exclusion radii and
inertia weight parameters. Karimi et al. proposed particles
inspired from the microbial life that can reproduce new
infant particles to replace the old particles.
4.3. SI in dynamic constrained optimization
Dynamic constrained optimization problems are challenging
because they often affect the feasibility of the algorithmic solutions. Liu transformed the problem into a series of static
constrained optimization problems of different periods. Each
designed static problem is assigned with an individual ﬁtness
function based on the original objective and its constraints. The
PSO algorithm is then applied to each designed problem without the need to take care of the feasibility of the particles. The
experimental results showed that this PSO algorithm can ﬁnd
the optimal solutions on a set of benchmark problems.
Differently, Dewan and Nayak used a penalty based
function with PSO to handle infeasible particles whereas new
types of particles for local search are introduced for feasible
particles. The algorithm was tested on a known benchmark set
and was compared with the results of other EAs. The PSO results are quite competitive in comparison with EAs.
Yin and Sun proposed a novel adaptive mutation PSO
(AMPSO) algorithm based on a generalized dynamic constraints satisfaction strategy.
The mutation operator within
AMPSO is applied to the inactive (e.g., particles that have made
no progress for a number of iterations) or less ﬁt particles of the
swarm according to an adaptively changing mutation probability.
Bu et al. applied a variation of the SPSO with an ensemble of strategies to locate and track feasible regions. The strategies include: a gradient-based repair, an adaptive local search,
constraint handling, memory and prediction strategy.
4.4. SI in dynamic multi-objective optimization
Dynamic multi-objective optimization problems are more
challenging than DOPs (single-objective) because a set of
Pareto optimal solutions needs to be tracked rather than a single
optimal solution. Wei and Wang proposed a hyper rectangle search based PSO algorithm to tackle such problems. The
algorithm utilizes a hyper rectangle search to approximately
predict the next optimal solutions. The experimental results on
a known benchmark set showed that PSO can effectively locate
and track the set of Pareto optimal solutions over time.
Differently, Wei and Jia integrated a new points selection strategy with PSO to generate the initial swarm of the next
time interval, which acts as a restart strategy. In addition, an
attraction based local search operator is incorporated to utilize
the information of the swarm.
A multi-swarm PSO was proposed where each swarm solves
a single objective function independently and communicates
with other swarms to transfer the knowledge . In
order to maintain diversity, a percentage of the swarm are reinitialized whenever a dynamic change is detected by sentry
particles.
4.5. SI in dynamic classiﬁcation
Several PSO algorithms, e.g., QPSO, CPSO and CCPSO,
proposed in dynamic continuous optimization, were applied for
training supervised feed-forward neural networks in classiﬁcation problems . The dynamic changes during training
occur to the decision boundaries, known as concept drift. Since
training a neural network is a continuous optimization problem
the aforementioned algorithms were applied directly. The experimental results showed that QPSO, CPSO and CCPSO had
better classiﬁcation error than a PSO with a restart and a gradient descent algorithm, e.g., back propagation algorithm.
4.6. Discussions
Every strategy for adapting SI to dynamic environments has
advantages and limitations. For example, the diversity maintaining/increasing strategy can well address the diversity loss
issue, but it is hard to know the optimal frequency for diversity
increasing and to design efﬁcient diversity maintaining mechanisms.
Memory schemes are able to help an algorithm to
quickly adapt to new environments, but it does not help in environments with signiﬁcant changes. The multi-swarm strategy is
able to maintain the diversity at the global level, but the optimal
number of swarms and the search area of each swarm are very
hard to conﬁgure.
Due to the advantages and limitations of different strategies
aforementioned, multiple strategies are usually considered in
most studies. For example, in many multi-swarm algorithms,
diversity maintaining and memory strategies are commonly
used to enhance the performance. No matter what strategies are
used, the balance of knowledge transfer and diversity maintenance should always be considered for handling environmental
5. Real-world applications of SI in dynamic environments
In the this section real-world applications that appear in
SIDO are reviewed and classiﬁed into discrete and continuous
applications. The difference between “real-world applications”
and the applications discussed in Tables 2 and 3 is rather arbitrary . In this paper, the applications discussed in Tables 2
and 3 focus on well-known models that aim to model a realworld problem or setting (e.g., multi-objective or constraint
handling). Such models may provide an indication whether
such an application may work in the real-world. On the other
hand, the real-world applications discussed in the following
sections focus in applications that were used in some industries
or were tested on real data.
5.1. Discrete applications
The ﬁeld of network routing has been extensively studied
by ACO algorithms. Generally, the routing problem in networks is deﬁned as the problem of deﬁning path ﬂows to forward incoming data trafﬁc such that the overall network performance is maximized. According to the characteristics of
the processing and transmission components, the trafﬁc ﬂow
pattern, and the performance expected to be delivered of the
network, different types of routing problems can be deﬁned.
Mainly, there are two categories of network routing problems
in which ACO has been applied: wired, e.g., wired best effort
networks and wired quality of service (QoS) networks , and wireless, e.g., mobile ad hoc networks .
The telecommunication algorithms simply rely on the adaptation capabilities of ACO.
Liu et al. proposed a multicast routing protocol based
on AFSO to address the latency and bandwidth constraints
of QoS networks. The simulation results showed that AFSO
achieves promising performance and robustness in real-time
multimedia transmission networks. ABC algorithms were also
studied for mobile ad hoc networks and PSO for
peer-to-peer networks .
Vogel et al. proposed an ACO algorithm to address dynamic changes in the production system. A Position-Operation-
Pheromone matrix is maintained to store the operations. Whenever a new job arrives, the pheromone values are re-initialized.
Their experiments on a real-world data collection showed that
the proposed ACO method outperforms the manual method and
a traditional priority-rule method. In contrast, the ACO method
was outperformed by an EA.
Silva and Runkler addressed the cash machine problem
using a conventional ACO algorithm. Basically, the problem is
that a cash logistics company needs to ﬁll the cash containers
according to their money levels for a number of cash machines
of a speciﬁc bank in Frankfurt. The results showed that ACO is
able to automatically output solutions with the minimum travelling time, considering the distances between the cash machines
and their money levels. However, there are no comparisons
with any other automatic or manual methods.
Nakrani and Tovey used a new bee algorithm (e.g.,
honey bee algorithm development) for the dynamic server allocation in an internet server colony. Foraging bees and ﬂower
patches in their model represent the servers and HTTP dynamic request queues, respectively, in an internet server colony.
Their experimental results on cases of a hosting center with two
and three virtual servers composed from a total of ﬁfty servers
showed that the honey bee algorithm performs better than other
traditional algorithms, especially in highly dynamic and unpredictable internet environments, due to its adaptation capabilities.
Triwate and Luangpaiboon applied a bee algorithm
(e.g., bee algorithm development) to minimize the imbalance of
a dynamic multi-zone dispatching system, where each bee represents a dispatching pattern. The simulation study was based
on real-world data from Thai local transportation ﬁrms. The
authors concluded that the bee algorithm reaches the optimum
very fast on small problems but requires more time for medium
and large size problems.
Wedde et al. used a bee algorithm (e.g., BeeHive algorithm development) to route vehicles on the roads with lower
trafﬁc jams and congestions to minimize transportation times.
The topological road data of eastern German Ruhr District was
considered and several trafﬁc scenarios were generated. The
comparison with a traditional shortest-path algorithm (e.g., Dijkstra algorithm) showed that the BeeHive algorithm has better
congestion handling. This is because the time-linkage of the
problem is considered by BeeHive, which routes vehicles on
different paths dynamically, whereas Dijkstra’s algorithm always selects the shortest one. The authors showed that after
some time heavy congestions occur with Dijkstra-based routing, whereas Bee-based routing remains congestion free.
Sulaiman et al. used an FA to solve the optimal allocation and sizing problem of distributed generation units in distribution networks. For the experiments an IEEE 69-bus distribution test system was used. Their results show that the determination of the optimal location and size of distributed generation
units reduces power losses and improves the voltage proﬁle of
the power system. In addition, the comparison of the proposed
FA with an EA showed comparable results.
Teodorovi´c and Dell’Orco applied a bee algorithm
(e.g., bee colony optimization development) with fuzzy logic
to the ride-matching problem. The problem is to optimize the
routing and scheduling of vehicles and passengers for a given
period of time. The uncertainties in this application appear by
possible delays caused by the passengers or by trafﬁc congestion. The authors considered the ride sharing demand of 97
travellers from Trani, a small city in Italy. The results obtained
by the algorithm are very promising.
Garcia et al. uses an ACO to solve the problem of
path planning for mobile robots with obstacle avoidance. The
workspace (search space) is discretized in a matrix of 50 × 50
nodes, where the mobile robot is able to navigate and build
paths. PSO is used for the same problem with moving obstacles .
Li et al. applied a discrete version of PSO to the resource allocation problem in a cooperative OFDMA system to
maximize the average utility of all mobile stations under multiservice. The correlation between adjacent frames is exploited
to transfer knowledge. Their results proved that knowledge
transfer reduced the computation complexity signiﬁcantly and
achieved better performance in terms of maximizing utility.
Hsu hybridized a PSO with an event-based heuristic to
solve two essential seaside operations planning problems, i.e.,
berth allocation and quay crane assignment problems, simultaneously. The key idea of the approach is to support variable-intime quay crane assignment rather than time-invariant. In this
way, the assignment of quay cranes is utilized because they can
be adjusted accordingly.
Eaton et al. uses an ACO to reschedule trains at junctions and stations when train delays occur.
A new feasible
schedule is generated based on the previous infeasible one using a path-preserving heuristic.
5.2. Continuous applications
The dynamic economic dispatch (DED) problem has been
extensively studied by SI algorithms such as BFO , PSO
 , FA , AFSO and ABC algorithms . Moreover, a hybrid SFLA algorithm outperformed PSO- and ABC-based algorithms.
The main objective of the DED problem is to reduce the opera-
tional costs in an electrical power system without violating a set
of various security and efﬁciency constraints simultaneously.
Niknam et al. used a bee algorithm (e.g., honey bee
mating optimization development) to solve the dynamic optimal power ﬂow4 and minimize the total system generation cost.
The proposed bee algorithm differs from the original development of the bee algorithm because it uses a mutation operator
to increase the population diversity. The experimental results
on 14-,30-, and 118-bus test systems showed that this mutation
improves the quality of the conventional bee algorithm.
Tang et al. proposed a BFO algorithm to solve the
optimal power ﬂow problem with power system dynamic loads.
The reproduction process of the BFO uses a selection scheme
based on the roulette wheel method to maintain diversity. The
dispersion and elimination processes are not considered in order to avoid too much randomization. An IEEE 30- and 118bus test system is used for the experiments. The proposed BFO
algorithm was compared with conventional BFO and PSO on
three different levels of load changes, showing satisfactory performance.
Takano et al. used an ABC algorithm to coordinate
rescue agents in dynamic disaster environments, e.g., a city
after an earthquake occurrence. The algorithm is modiﬁed to
only communicate with nearby bees. The experiments on the
RoboCup Rescue Simulation System showed that ABC can rescue all victims quickly.
FA and PSO were used to tune the proportional
integral derivative controller for an automatic voltage regulator
system. The optimal tuning of the controller is based on the
time-variability of real-world power system operation. Comparisons between the recent FA and PSO algorithms showed
that the former is more robust than the latter. BFO was
also used for the tuning of the controller and was more robust
and efﬁcient than an EA.
Gomes used PSO and FA algorithms as optimization engines on structural mass optimization. The structural optimization of shape and size is considered as highly non-linear.
The problem contains dynamic constraints that may affect the
ﬁtness function. Hence, a penalty function technique is used
to address violations. Three examples of 10-, 37-, and 128truss bar structures were taken into account and showed that
FA performed slightly worse than PSO but both SI algorithms
performed better than traditional optimization methods.
ACO and ABC were applied to the dynamic load balancing
problem . The main objective of the problem is to ﬁnd
the optimal allocation of workloads among systems, e.g., reduce the load from busy resources and transfer them to idle resources. The experimental study on a cluster of four machines
and the Amazon EC2 cloud showed that the ABC is faster than
ACO and other traditional algorithms.
A BFO algorithm was applied to determine the shortest feasible path from a current position to the target position in a
2D space with moving obstacles . The algorithm is able
to avoid obstacles and ﬁnd a path towards the target position.
4The optimal power ﬂow problem may also contain discrete variables.
Similarly, PSO algorithms showed that they are also able to
plan an optimal path for a robot by avoiding moving obstacles
 .
A contaminant source identiﬁcation problem in water distribution networks is a nonlinear programming problem. The aim
of the problem is to search for the location and the time history of the contaminant according to the observed data up to
the current time. Liu et al. used a multi-swarm based
PSO algorithm to solve this problem.
6. Conclusions and future work
This paper attempts to review the related work of SIDO
found from several web-search engines. The most important
applications of SIDO are classiﬁed into continuous or discrete
problems. The strategies used to enhance SI algorithms to cope
with dynamic changes are grouped and extensively discussed.
In addition, SIDO real-world problems are reviewed in this paper.
The review of this paper was constructed as follows. The
search was conducted from ﬁve recognized scientiﬁc databases,
i.e., IEEExplore5, Science Direct6, SpringerLink7, Scopus8 and
Google Scholar9 using terms like “ant colony optimization”
AND (“dynamic environment” OR “dynamic optimization” OR
“dynamic function” OR “time-varying” OR “dynamic problem” OR “dynamic routing” OR “dynamic scheduling” OR
“dynamic multi-objective” OR “dynamic constraint”) for ACO.
The same search format was used for PSO with “particle swarm
optimization” instead and similarly for the other SI algorithms.
The bibliography retrieved includes journal articles, conferences papers, book chapters and technical reports. Then, the
results were categorized by: (a) SI algorithms in Fig. 3 and (b)
year of publication in Fig. 4.
From Fig. 3, it can be observed that ACO and PSO have attracted more attention than the other SI algorithms in SIDO.
This is natural because they were proposed much earlier than
other SI algorithms. It may also be the case that they are more
effective than the recently proposed SI algorithms. This is because in many cases the SI algorithms were using core components from these algorithms. For example, the local best position component of the particle introduced in PSO was used as
an enhancement strategy in many cases in ABC, AFSO, FA and
BFO. From Fig 4, it can be observed that roughly the ﬁeld of
SIDO began to grow in 2001 and gradually grew until 2009.
Since then the ﬁeld has its ups and downs regarding the number
of publications.
In general, all SI algorithms have been mainly applied on
dynamic versions of the corresponding stationary optimization
problems that they were initially developed. For example, ACO
is mainly used in dynamic discrete problems that are modelled
5 
6 
7 
8 
9 
# of publications
Swarm Intelligence Algorithm
Fig. 3: Distribution of publications sorted by swarm intelligence algorithms.
1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015
# of publications
Publication Year
Fig. 4: Distribution of publications sorted by year of publication.
by graphs because it is a graph-search algorithm. Also, the enhancement strategies integrated to the different SI algorithms
usually improve their performance when the changing environments are similar. Finally, a local search operator is a core component of SI algorithms when addressing DOPs. SI algorithms
perform global optimization and they are not accurate in their
output. Hence, a local search operator can signiﬁcantly improve the quality of the output. However, the integration of
local search in SI algorithms has to be done in such a way that
does not signiﬁcantly increase the computation time or waste
evaluations .
Although the research in SIDO showed signiﬁcant increase,
it still has several aspects for future directions that may contribute to further grow the ﬁeld of SIDO, which are summarized
as follows:
• Experimentation protocols: Since there is not any agreed
computational experimentation protocol yet, it may be
necessary to deﬁne different experimentation protocols for
different problem classes, e.g., continuous, discrete and
constrained problems, due to the different characteristics
regarding both the methodologies used and the search
• Benchmark generators:
The ﬁelds of dynamic multiobjective and dynamic constrained optimization are still
young. Most benchmark generators used are simply extensions from the static instances. It may be necessary to
develop benchmark generators especially for these recent
ﬁelds to compare new algorithms developed.
• Avoiding change detection: Change detection methods by
re-evaluating individuals cannot always guarantee a successful detection, especially in the case where a change
does not affect current solutions in the ﬁtness landscape.
Such situations may happen in dynamic environments
where a part of the ﬁtness landscape changes. In addition,
such detection methods will never work in dynamic environments with noise since noise will be misinterpreted
as changes in every re-evaluating operation. Therefore,
avoiding change detection is needed to handle changes
more effectively.
• Modelling real-world scenarios: It will be interesting to
consider other research areas in dynamic optimization that
have attracted less interest and model many real-world scenarios, e.g., constrained DOPs, dynamic multi-objective
problems or even dynamic constrained multi-objective
• Consideration of other prospectives: The tracking moving
optimum (TMO) framework is usually used in SIDO to
tackle DOPs. Recently, a new perspective on DOPs has
been established, known as robust optimization over time
(ROOT), where the target is to ﬁnd the chain of solutions
which are robust over time . Particularly, a solution
is robust over time when its quality is acceptable to the
changing environments during a predeﬁned time interval.
In fact, problems in scheduling and vehicle routing have
the time-linkage property. Therefore, the TMO framework
may not be the best choice, because a decision that improves the performance at present may affect the perfor-
mance in the future. As a result, the overall performance
may be degraded in the long run. So far, ROOT was integrated only with PSO.
• Choice of algorithms: So far, many SI algorithms have
been proposed in the last 30 years. For a speciﬁc problem,
most readers are not sure what algorithms to choose. This
is because making a right choice is again an optimization
problem. Experience and trail-and-error based choice are
still the major ways to make the choice. Therefore, ﬁnding
the right algorithms most suitable for a given problem or
problems with a certain type of properties would also be
an interesting topic in SIDO in the future.
• Theoretical development: Usually, the performance of the
algorithms in DOPs is analyzed empirically, rather than
theoretically, due to the mathematical challenges of SI algorithms, or metaheuristics in general. Although theoretical works exist the research area is still limited. Theoretical development in SIDO should be enhanced signiﬁcantly
in order to have a deep understanding on why and how SI
algorithms work in DOPs.
Acknowledgements
This work was supported by the Engineering and Physical Sciences Research Council (EPSRC) of U.K. under Grant
EP/K001310/1, by the National Natural Science Foundation
of China (NSFC) under Grants 61673331 and 61673355, by
the Hubei Provincial Natural Science Foundation of China under Grant 2015CFA010, and by the 111 project under Grant