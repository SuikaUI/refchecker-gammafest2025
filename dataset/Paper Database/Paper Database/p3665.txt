IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. X, JULY 2019
A Survey of the Usages of Deep Learning for
Natural Language Processing
Daniel W. Otter, Julian R. Medina, and Jugal K. Kalita
Abstract—Over the last several years, the ﬁeld of natural
language processing has been propelled forward by an explosion
in the use of deep learning models. This survey provides a brief
introduction to the ﬁeld and a quick overview of deep learning
architectures and methods. It then sifts through the plethora of
recent studies and summarizes a large assortment of relevant
contributions. Analyzed research areas include several core linguistic processing issues in addition to a number of applications
of computational linguistics. A discussion of the current state of
the art is then provided along with recommendations for future
research in the ﬁeld.
Index Terms—deep learning, neural networks, natural language processing, computational linguistics, machine learning
I. INTRODUCTION
HE ﬁeld of natural language processing (NLP) encompasses a variety of topics which involve the computational processing and understanding of human languages.
Since the 1980s, the ﬁeld has increasingly relied on datadriven computation involving statistics, probability, and machine learning , . Recent increases in computational
power and parallelization, harnessed by Graphical Processing
Units (GPUs) , , now allow for “deep learning”, which
utilizes artiﬁcial neural networks (ANNs), sometimes with
billions of trainable parameters . Additionally, the contemporary availability of large datasets, facilitated by sophisticated
data collection processes, enables the training of such deep
architectures , , .
In recent years, researchers and practitioners in NLP have
leveraged the power of modern ANNs with many propitious
results, beginning in large part with the pioneering work of
Collobert et al. . In the very recent past, the use of deep
learning has upsurged considerably , . This has led to
signiﬁcant advances both in core areas of NLP and in areas
in which it is directly applied to achieve practical and useful
objectives. This survey provides a brief introduction to both
natural language processing and deep neural networks, and
then presents an extensive discussion on how deep learning is
being used to solve current problems in NLP. While several
other papers and books on the topic have been published
 , , none have extensively covered the state-of-theart in as many areas within it. Furthermore, no other survey
Manuscript received MONTH DD, YYYY; revised MONTH DD, YYYY.
Authors are with the University of Colorado at Colorado Springs, 1420 Austin
Bluffs Pkwy. Colorado Springs, Colorado 80918 USA. Corresponding author:
Jugal K. Kalita (email: ). This survey was supported in part
by National Science Foundation grant numbers IIS-1359275 and IIS-1659788.
Any opinions, ﬁndings, conclusions, and recommendations expressed in this
material are those of the authors and do not necessarily reﬂect the views of
the National Science Foundation.
has examined not only the applications of deep learning to
computational linguistics, but also the underlying theory and
traditional NLP tasks. In addition to the discussion of recent
revolutionary developments in the ﬁeld, this survey will be
useful to readers who want to familiarize themselves quickly
with the current state of the art before embarking upon further
advanced research and practice.
The topics of NLP and AI, including deep learning, are
introduced in Section II. The ways in which deep learning has
been used to solve problems in core areas of NLP are presented
in Section III. The section is broken down into several subsections, namely natural language modeling (III-A), morphology
(III-B), parsing (III-C), and semantics (III-D). Applications of
deep learning to more practical areas are discussed in Section
IV. Speciﬁcally discussed are information retrieval (IV-A),
information extraction (IV-B), text classiﬁcation (IV-C), text
generation (IV-D), summarization (IV-E), question answering
(IV-F), and machine translation (IV-G). Conclusions are then
drawn in Section V with a brief summary of the state of the
art as well as predictions, suggestions, and other thoughts on
the future of this dynamically evolving area.
II. OVERVIEW OF NATURAL LANGUAGE PROCESSING AND
DEEP LEARNING
In this section, signiﬁcant issues that draw attention of
researchers and practitioners are introduced, followed by a
brisk explanation of the deep learning architectures commonly
used in the ﬁeld.
A. Natural Language Processing
The ﬁeld of natural language processing, also known as
computational linguistics, involves the engineering of computational models and processes to solve practical problems in
understanding human languages. These solutions are used to
build useful software. Work in NLP can be divided into two
broad sub-areas: core areas and applications, although it is
sometimes difﬁcult to distinguish clearly to which areas issues
belong. The core areas address fundamental problems such
as language modeling, which underscores quantifying associations among naturally occurring words; morphological processing, dealing with segmentation of meaningful components
of words and identifying the true parts of speech of words as
used; syntactic processing, or parsing, which builds sentence
diagrams as possible precursors to semantic processing; and
semantic processing, which attempts to distill meaning of
words, phrases, and higher level components in text. The
application areas involve topics such as extraction of useful
 
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. X, JULY 2019
Fig. 1: Encoder–Decoder Architectures. While there are multiple options of encoders and decoders available, RNN variants are
a common choice for each, particularly the latter. Such a network is shown in (a). Attention mechanisms, such as that present
in (b), allow the decoder to determine which portions of the encoding are most relevant at each output step.
information (e.g. named entities and relations), translation of
text between and among languages, summarization of written
works, automatic answering of questions by inferring answers,
and classiﬁcation and clustering of documents. Often one
needs to handle one or more of the core issues successfully and
apply those ideas and procedures to solve practical problems.
Currently, NLP is primarily a data-driven ﬁeld using statistical and probabilistic computations along with machine
learning. In the past, machine learning approaches such as
na¨ıve Bayes, k-nearest neighbors, hidden Markov models,
conditional random ﬁelds, decision trees, random forests, and
support vector machines were widely used. However, during
the past several years, there has been a wholesale transformation, and these approaches have been entirely replaced, or at
least enhanced, by neural models, discussed next.
B. Neural Networks and Deep Learning
Neural networks are composed of interconnected nodes, or
neurons, each receiving some number of inputs and supplying
an output. Each of the nodes in the output layers perform
weighted sum computation on the values they receive from the
input nodes and then generate outputs using simple nonlinear
transformation functions on these summations. Corrections to
the weights are made in response to individual errors or losses
the networks exhibit at the output nodes. Such corrections are
usually made in modern networks using stochastic gradient
descent, considering the derivatives of errors at the nodes, an
approach called back-propagation . The main factors that
distinguish different types of networks from each other are
how the nodes are connected and the number of layers. Basic
networks in which all nodes can be organized into sequential
layers, with every node receiving inputs only from nodes
in earlier layers, are known as feedforward neural networks
(FFNNs). While there is no clear consensus on exactly what
deﬁnes a deep neural network (DNN), generally networks with
multiple hidden layers are considered deep and those with
many layers are considered very deep .
1) Convolutional Neural Networks: Convolutional neural
networks (CNNs) , , built upon Fukashima’s neocognitron , , derive the name from the convolution operation
in mathematics and signal processing. CNNs use functions,
known as ﬁlters, allowing for simultaneous analysis of different features in the data , . CNNs are used extensively
in image and video processing, as well as speech and NLP
 , , , . Often, it is not important precisely where
certain features occur, but rather whether or not they appear
in particular localities. Therefore, pooling operations, can be
used to minimize the size of feature maps (the outputs of the
convolutional ﬁlters). The sizes of such pools are generally
small in order to prevent the loss of too much precision.
2) Recursive Neural Networks: Much like CNNs, recursive
networks , use a form of weight sharing to minimize
training. However, whereas CNNs share weights horizontally
(within a layer), recursive nets share weights vertically (between layers). This is particularly appealing, as it allows for
easy modeling of structures such as parse trees. In recursive
networks, a single tensor (or a generalized matrix) of weights
can be used at a low level in the tree, and then used recursively
at successively higher levels .
3) Recurrent Neural Networks and Long Short-Term Memory Networks: A type of recursive neural network that has
been used heavily is the recurrent neural network (RNN) ,
 . Since much of NLP is dependent on the order of words
or other elements such as phonemes or sentences, it is useful
to have memory of the previous elements when processing
new ones , , . Sometimes, backwards dependencies
exist, i.e., correct processing of some words may depend on
words that follow. Thus, it is beneﬁcial to look at sentences
in both directions, forwards and backwards, using two RNN
layers, and combine their outputs. This arrangement of RNNs
is called a bidirectional RNN. It may also lead to a better ﬁnal
representation if there is a sequence of RNN layers. This may
allow the effect of an input to linger longer than a single RNN
layer, allowing for longer-term effects. This setup of sequential
RNN cells is called an RNN stack , .
One highly engineered RNN is the long short-term memory
(LSTM) network , . In LSTMs, the recursive nodes are
composed of several individual neurons connected in a manner
designed to retain, forget, or expose speciﬁc information.
Whereas generic RNNs with single neurons feeding back to
themselves technically have some memory of long passed
results, these results are diluted with each successive iteration.
Oftentimes, it is important to remember information from
the distant past, while at the same time, other very recent
information may not be important. By using LSTM blocks,
this important information can be retained much longer while
irrelevant information can be forgotten. A slightly simpler
variant of the LSTM, called the Gated Recurrent Unit (GRU),
has been shown to perform as well as or better than standard
LSTMs in many tasks , .
4) Attention Mechanisms and Transformer: For tasks such
as machine translation, text summarization, or captioning, the
output is in textual form. Typically, this is done through the
use of encoder–decoder pairs. An encoding ANN is used to
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. X, JULY 2019
Fig. 2: Transformer Model. (a) shows a transformer with four ”encoders” followed by four ”decoders”, all following a ”positional
encoder”. (b) shows the inner workings of each ”encoder”, which contains a self-attention layer followed by a feed forward
layer. (c) shows the inner workings of each ”decoder”, which contains a self-attention layer followed by an attentional encoderdecoder layer and then a feed forward layer.
produce a vector of a particular length and a decoding ANN
is used to return variable length text based on this vector. The
problem with this scheme, which is shown in Figure 1(a), is
that the RNN is forced to encode an entire sequence to a
ﬁnite length vector, without regards to whether or not any of
the inputs are more important than others.
A robust solution to this is that of attention. The ﬁrst noted
use of an attention mechanism used a dense layer for
annotated weighting of an RNN’s hidden state, allowing the
network to learn what to pay attention to in accordance with
the current hidden state and annotation. Such a mechanism
is present in Fig. 1(b). Variants of the mechanism have
been introduced, popular ones including convolutional ,
intra-temporal , gated , and self-attention . Selfattention involves providing attention to words in the same
sentence. For example, during encoding a word in an input sentence, it is beneﬁcial to project variable amounts of attention
to other words in the sentence. During decoding to produce
a resulting sentence, it makes sense to provide appropriate
attention to words that have already been produced. Selfattention in particular has become widely used in a state-ofthe-art encoder-decoder model called Transformer . The
Transformer model, shown in Fig. 2, has a number of encoders
and decoders stacked on top of each other, self-attention in
each of the encoder and decoder units, and cross-attention
between the encoders and decoders. It uses multiple instances
of attention in parallel and eschews the use of recurrences and
convolutions. The Transformer has become a quintessential
component in most state-of-the-art neural networks for natural
language processing.
5) Residual Connections and Dropout: In deep networks,
trained via backpropagation , the gradients used to correct
for error often vanish or explode . This can be mitigated
by choosing activation functions, such as the Rectiﬁed Linear
Unit (ReLU) , which do not exhibit regions that are
arˆetically steep or have bosonically small gradients. Also
in response to this issue, as well as others , residual
connections are often used. Such connections are simply those
that skip layers (usually one). If used in every alternating
layer, this cuts in half the number of layers through which
the gradient must backpropagate. Such a network is known
as a residual network (ResNet). A number of variants exist,
including Highway Networks and DenseNets .
Another important method used in training ANNs is
dropout. In dropout, some connections and maybe even nodes
are deactivated, usually randomly, for each training batch
(small set of examples), varying which nodes are deactivated
each batch. This forces the network to distribute its memory
across multiple paths, helping with generalization and lessening the likelihood of overﬁtting to the training data.
III. DEEP LEARNING IN CORE AREAS OF NATURAL
LANGUAGE PROCESSING
The core issues are those that are inherently present in
any computational linguistic system. To perform translation,
text summarization, image captioning, or any other linguistic
task, there must be some understanding of the underlying
language. This understanding can be broken down into at least
four main areas: language modeling, morphology, parsing, and
semantics. The number of scholarly works in each area over
the last decade is shown in Figure 3.
Language modeling can be viewed in two ways. First, it
determines which words follow which. By extension, however,
this can be viewed as determining what words mean, as individual words are only weakly meaningful, deriving their full
value only from their interactions with other words. Morphology is the study of how words themselves are formed. It considers the roots of words and the use of preﬁxes and sufﬁxes,
compounds, and other intraword devices, to display tense,
gender, plurality, and a other linguistic constructs. Parsing
considers which words modify others, forming constituents,
leading to a sentential structure. The area of semantics is the
study of what words mean. It takes into account the meanings
of the individual words and how they relate to and modify
others, as well as the context these words appear in and some
degree of world knowledge, i.e., “common sense”.
There is a signiﬁcant amount of overlap between each of
these areas. Therefore, many models analyzed can be classiﬁed
as belonging in multiple sections. As such, they are discussed
in the most relevant sections with logical connections to those
other places where they also interact.
A. Language Modeling and Word Embeddings
Arguably, the most important task in NLP is that of language
modeling. Language modeling (LM) is an essential piece of
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. X, JULY 2019
Fig. 3: Publication Volume for Core Areas of NLP. The number of publications, indexed by Google Scholar, relating to each
topic over the last decade is shown. While all areas have experienced growth, language modeling has grown the most.
almost any application of NLP. Language modeling is the
process of creating a model to predict words or simple linguistic components given previous words or components .
This is useful for applications in which a user types input, to
provide predictive ability for fast text entry. However, its power
and versatility emanate from the fact that it can implicitly
capture syntactic and semantic relationships among words or
components in a linear neighborhood, making it useful for
tasks such as machine translation or text summarization. Using
prediction, such programs are able to generate more relevant,
human-sounding sentences.
1) Neural Language Modeling: A problem with statistical
language models was the inability to deal well with synonyms
or out-of-vocabulary (OOV) words that were not present in the
training corpus. Progress was made in solving the problems
with the introduction of the neural language model . While
much of NLP took another decade to begin to use ANNs
heavily, the LM community immediately took advantage of
them, and continued to develop sophisticated models, many
of which were summarized by DeMulder et al. .
2) Evaluation of Language Models: While neural networks
have made breakthroughs in the LM ﬁeld, it is hard to quantify
improvements. It is desirable to evaluate language models
independently of the applications in which they appear. A
number of metrics have been proposed, but no perfect solution
has yet been found. , , The most commonly
used metric is perplexity, which is the inverse probability of
a test set normalized by the number of words. Perplexity is a
reasonable measurement for LMs trained on the same datasets,
but when they are trained on different vocabularies, the metric
becomes less meaningful. Luckily, there are several benchmark
datasets that are used in the ﬁeld, allowing for comparison.
Two such datasets are the Penn Treebank (PTB) , and the
Billion Word Benchmark .
3) Memory Networks and Attention Mechanisms in Language Modeling: Daniluk et al. tested several networks
using variations of attention mechanisms. The ﬁrst network
had a simple attention mechanism, which was not fully connected, having a window length of ﬁve. They hypothesized
that using a single value to predict the next token, to encode information for the attentional unit, and to decode the
information in the attentional unit hinders a network, as it is
difﬁcult to train a single parameter to perform three distinct
tasks simultaneously. Therefore, in the second network, they
designed each node to have two outputs: one to encode and
decode the information in the attentional unit, and another to
predict the next tokens explicitly. In the third network, they
further separated the outputs, using separate values to encode
the information entering the attentional unit and decode the
information being retrieved from it. Tests on a Wikipedia corpus showed that the attention mechanism improved perplexity
compared to the baseline, and that successively adding the
second and third parameters led to further increases. It was
also noted that only the previous ﬁve or so tokens carried
much value (hence the selection of the window size of ﬁve).
Therefore, they tested a fourth network which simply used
residual connections from each of the previous ﬁve units. It
was found that this network also provided results comparable
to many larger RNNs and LSTMs, suggesting that reasonable
results can be achieved using simpler networks.
Another recent study was done on the usage of residual
memory networks (RMNs) for LM . The authors found
that residual connections skipping two layers were most effective, followed closely by those skipping a single layer.
In particular, a residual connection was present between the
ﬁrst layer and the fourth, as was between the ﬁfth layer and
the eighth, and between the ninth and the twelfth. It was
found that increasing network depth improved results, but
that when using large batch sizes, memory constraints were
encountered. Network width was not found to be of particular
importance for performance, however, wide networks were
found to be harder to train. It was found that RMNs are capable
of outperforming LSTMs of similar size.
4) Convolutional Neural Networks in Language Modeling:
A CNN used recently in LM replaced the pooling layers with
fully-connected layers . These layers allowed the feature
maps to be reduced to lower dimensional spaces just like the
pooling layers. However, whereas any references to location of
such features are lost in pooling layers, fully-connected layers
somewhat retain this information. Three different architectures
were implemented: a multilayer perceptron CNN (MLPConv)
in which the ﬁlters were not simply linear, but instead small
MLPs ; a multilayer CNN (ML-CNN) in which multiple
convolutional layers were stacked on top of each other; and a
combination of these networks called COM, in which kernel
sizes for ﬁlters varied (in this case they were three and ﬁve).
The results showed that stacking convolutional layers was
detrimental in LM, but that both MLPConv and COM reduced
perplexity. Combining MLPConv with the varying kernel sizes
of COM provided even better results. Analysis showed that the
networks learned speciﬁc patterns of words, such as, “as . .
. as”. Lastly, this study showed that CNNs can be used to
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. X, JULY 2019
capture long term dependencies in sentences. Closer words
were found to be of greatest importance, but words located
farther away were of some signiﬁcance as well.
5) Character Aware Neural Language Models: While most
CNNs used in NLP receive word embeddings (Section III-A6)
as input, recent networks have analyzed character level input
instead. For example, Kim et al. , unlike previous networks , accepted only character level input, rather than
combining it with word embeddings. A CNN was used to
process the character level input to provide representations of
the words. In a similar manner as word embeddings usually
are, these representations were then fed into an encoder–
decoder pair composed of a highway network (a gated network
resembling an LSTM) and an LSTM. They trained the
network on the English Penn Treebank, as well as on datasets
for Czech, German, Spanish, French, Russian, and Arabic.
For every non-English language except Russian, the network
outperformed previously published results in both the
large and small datasets. On the Penn Treebank, results were
produced on par with the existing state of the art . However, the network had only 19 million trainable parameters,
which is considerably lower than others. Since the network
focused on morphological similarities produced by character
level analysis, it was more capable than previous models of
handling rare words. Analysis showed that without the use
of highway layers, many words had nearest neighbors that
were orthographically similar, but not necessarily semantically
similar. Additionally, the network was capable of recognizing
misspelled words or words not spelled in the standard way
(e.g. looooook instead of look) and of recognizing out of
vocabulary words. The analysis also showed that the network
was capable of identifying preﬁxes, roots, and sufﬁxes, as well
as understanding hyphenated words, making it a robust model.
Jozefowicz et al. tested a number of architectures producing character level outputs , , , . Whereas
many of these models had only been tested on small scale
language modeling, this study tested them on a large scale,
testing them with the Billion Word Benchmark. The most
effective model, achieving a state-of-the-art (for single models) perplexity of 30.0 with 1.04 billion trainable parameters
(compared to a previous best by a single model of 51.3 with
20 billion parameters ), was a large LSTM using a character level CNN as an input network. The best performance,
however, was achieved using an ensemble of ten LSTMs. This
ensemble, with a perplexity of 23.7, far surpassed the previous
state-of-the-art ensemble , which had a perplexity of 41.0.
6) Development of Word Embeddings: Not only do neural
language models allow for the prediction of unseen synonymous words, they also allow for modeling the relationships
between words , . Vectors with numeric components,
representing individual words, obtained by LM techniques
are called embeddings. This is usually done either by use
of Principle Component Analysis or by capturing internal
states in a neural language model. (Note that these are not
standard LMs, but rather are LMs constructed speciﬁcally
for this purpose.) Typically, word embeddings have between
50 and 300 dimensions. An overused example is that of the
distributed representations of the words king, queen, man,
and woman. If one takes the embedding vectors for each of
these words, computation can be performed to obtain highly
sensible results. If the vectors representing these words are
respectively represented as ⃗k, ⃗q, ⃗m, and ⃗w, it can be observed
that ⃗k −⃗q ≈⃗m −⃗w, which is extremely intuitive to human
reasoning. In recent years, word embeddings have been the
standard form of input to NLP systems.
7) Recent Advances and Challenges: Language modeling
has been evolving on a weekly basis, beginning with the works
of Radford et al. and Peters et al. . Radford et al.
introduced Generative Pre-Training (GPT) which pretrained a
language model based on the Transformer model (Section
IV-G), learning dependencies of words in sentences and longer
segments of text, rather than just the immediately surrounding
words. Peters et al. incorporated bi-directionalism to capture
backwards context in addition to the forward context, in their
Embeddings from Language Models (ELMo). Additionally,
they captured the vectorizations at multiple levels, rather than
just the ﬁnal layer. This allowed for multiple encodings of
the same information to be captured, which was empirically
shown to boost the performance signiﬁcantly.
Devlin et al. , added an additional unsupervised training
tasks of random masked neighbor word prediction, and nextsentence-prediction (NSP), in which, given a sentence (or other
continuous segment of text), another sentence was predicted to
either be the next sentence or not. These Bidirectional Encoder
Representations from Transformers (BERT) were further built
upon by Liu et al. to create Multi-Task Deep Neural
Network (MT-DNN) representations, which are the current
state of the art in LM. The model used a stochastic answer
network (SAN) , ontop of a BERT-like model. After
pretraining, the model was trained on a number of different
tasks before being ﬁne-tuned to the task at hand. Using MT-
DNN as the LM, they achieved state-of-the-art results on ten
out of eleven of the attempted tasks.
While these pretrained models have made excellent headway in “understanding” language, as is required for some tasks
such as entailment inference, it has been hypothesized by some
that these models are learning templates or syntactic patterns
present within the datasets, unrelated to logic or inference.
When new datasets are created removing such patterns carefully, the models do not perform well . Additionally, while
there has been recent work on cross-language modeling and
universal language modeling, the amount and level of work
needs to pick up to address low-resource languages.
B. Morphology
Morphology is concerned with ﬁnding segments within
single words, including roots and stems, preﬁxes, sufﬁxes,
and—in some languages—inﬁxes. Afﬁxes (preﬁxes, sufﬁxes,
or inﬁxes) are used to overtly modify stems for gender,
number, person, et cetera.
Luong et al. constructed a morphologically aware LM.
An RvNN was used to model the morphological structure. A
neural language model was then placed on top of the RvNN.
The model was trained on the WordSim-353 dataset 
and segmentation was performed using Morfessor . Two
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. X, JULY 2019
models were constructed—one using context and one not. It
was found that the model that was insensitive to context overaccounted for certain morphological structures. In particular,
words with the same stem were clustered together, even if they
were antonyms. The context-sensitive model performed better,
noting the relationships between the stems, but also accounting
for other features such as the preﬁx “un”. The model was
also tested on several other popular datasets , , ,
signiﬁcantly outperforming previous embedding models on all.
A good morphological analyzer is often important for many
NLP tasks. As such, one recent study by Belinkov et al. 
examined the extent to which morphology was learned and
used by a variety of neural machine translation models. A
number of translation models were constructed, all translating
from English to French, German, Czech, Arabic, or Hebrew.
Encoders and decoders were LSTM-based models (some with
attention mechanisms) or character aware CNNs, and the
models were trained on the WIT3 corpus , . The
decoders were then replaced with part-of-speech (POS) taggers
and morphological taggers, ﬁxing the weights of the encoders
to preserve the internal representations. The effects of the
encoders were examined as were the effects of the decoders
attached during training. The study concluded that the use of
attention mechanisms decreases the performance of encoders,
but increases the performance of decoders. Furthermore, it
was found that character-aware models are superior to others for learning morphology and that the output language
affects the performance of the encoders. Speciﬁcally, the
more morphologically rich the output language, the worse the
representations created by the encoders.
Morita et al. analyzed a new morphological language
model for unsegmented languages such as Japanese. They
constructed an RNN-based model with a beam search decoder
and trained it on an automatically labeled corpus and on
a manually labeled corpus. The model performed a number of
tasks jointly, including morphological analysis, POS tagging,
and lemmatization. The model was then tested on the Kyoto
Text Corpus and the Kyoto University Web Document
Leads Corpus , outperforming all baselines on all tasks.
A recent line of work in morphology is universal morphology. This task considers the relationships between the
morphologies of different languages and how they relate to
each other, aiming towards the ultimate goal of a single
morphological analyzer. However, to the authors’ knowledge,
there has been only a single study applying deep learning
to this area , and even then, only as a supporting task
to universal parsing (Section III-C4). For those wishing to
apply deep learning to this task, several datasets are already
available, including one from a CoNLL shared task .
In addition to universal morphology, the development of
morphological embeddings, that take into account the structures of words, could aid in multi-language processing. They
could possibly be used across cognate languages, which would
be valuable when some languages are more resourced than
others. In addition, morphological structures may be important
in handling specialized languages such as those used in the
biomedical literature. Since deep learning has become quite
entrenched in NLP, better handling of morphological components is likely to improve performance of overall models.
C. Parsing
Parsing examines how different words and phrases relate to
each other within a sentence. There are at least two distinct
forms of parsing: constituency parsing and dependency parsing
 . In constituency parsing, phrasal constituents are extracted
from a sentence in a hierarchical fashion. Dependency parsing
looks at the relationships between pairs of individual words.
Most recent uses of deep learning in parsing have been in
dependency parsing, within which there exists another major
divide in types of solutions. Graph-based parsing constructs a
number of parse trees that are then searched to ﬁnd the correct
one. Most graph-based approaches are generative models, in
which a formal grammar, based on the natural language,
is used to construct the trees . More popular in recent
years than graph-based approaches have been transition-based
approaches that usually construct only one parse tree. While
a number of modiﬁcations have been proposed, the standard
method of transition-based dependency parsing is to create a
buffer containing all of the words in the sentence and stack
containing only the ROOT label. Words are then pushed onto
the stack, where connections, known as arcs, are made between
the top two items. Once dependencies have been determined,
words are popped off the stack. The process continues until the
buffer is empty and only the ROOT label remains on the stack.
Three major approaches are used to regulate the conditions in
which each of the previously described actions takes place.
In the arc-standard approach , , all dependents are
connected to a word before the word is connected to its parent.
In the arc-eager approach , , words are connected to
their parents as soon as possible, regardless of whether or not
their children are all connected to them. Finally, in the swaplazy approach , the arc-standard approach is modiﬁed to
allow swapping of positions on the stack. This makes the
graphing of non-projective edges possible.
1) Early Neural Parsing: One early application of deep
learning to NLP, that of Socher et al. , , included
the use of RNNs with probabilistic context-free grammars
(PCFGs) , . As far as the authors are aware, the ﬁrst
neural model to achieve state-of-the-art performance in parsing
was that of Le and Zuidema . Such performance was
achieved on the Penn Treebank for both labeled attachment
score (LAS) and unlabeled attachment score (UAS) by using
an Inside-Out Recursive Neural Network, which used two
vector representations (an inner and an outer) to allow both
top-down and bottom-up ﬂows of data. Vinyals et al. 
created an LSTM with an attention mechanism in a syntactic
constituency parser, which they tested on data from domains
different from those of the test data (the English Web Treebank
 and the Question Treebank as opposed to the Wall
Street Journal portion of the Penn Treebank ), showing that
neural models can generalize between domains. Embeddings
were ﬁrst used in dependency parsing by Stenetorp . This
approach used an RNN to create a directed acyclic graph.
While this model did produce results within 2% of the state
of the art , by the time it reached the
end of a sentence, it seemed to have difﬁculty remembering
phrases from early in the sentence.
2) Transition-Based Dependency Parsing: Chen and Manning pushed the state of the art in both UAS and LAS on
both English and Chinese datasets on the English Penn Treebank. They accomplished this by using a simple feedforward
neural network as the decision maker in a transition-based
parser. By doing so they were able to subvert the problem of
sparsity persistent in the statistical models.
Chen and Manning used a simple greedy search, which was
replaced by Zhou et al. with a beam search, achieving
a signiﬁcant improvement. Weiss et al. improved upon
Chen and Manning’s work by using a deeper neural network
with residual connections and a perceptron layer placed after
the softmax layer. They were able to train on signiﬁcantly more
examples than typical by using tri-training , a process in
which potential data samples are fed to two other parsers, and
those samples upon which both of the parsers agree are used
for training the primary parser.
Another model was produced using an LSTM instead of
a feedforward network . Unlike previous models, this
model was given knowledge of the entire buffer and the entire
stack and had knowledge of the entire history of transition
decisions. This allowed for better predictions, generating stateof-the-art on the Stanford Dependency Treebank , as
well as state-of-the-art results on the CTB5 Chinese dataset
 . Lastly, Andor et al. used a feedforward network
with global normalization on a number of tasks including
part-of-speech tagging, sentence compression, and dependency
parsing. State-of-the-art results were obtained on all tasks on
the Wall Street Journal dataset. Notably, their model required
signiﬁcantly less computation than comparable models.
Much like Stenentorp , Wang et al. used an
alternative algorithm to produce directed acyclic graphs, for
a task called semantic parsing, where deeper relationships
between the words are found. The task seeks to identify what
types of actions are taking place and how words modify
each other. In addition to the typical stack and buffer used
in transition-based parsing, the algorithm employed a deque.
This allowed for the representation of multi-parented words,
which although rare in English, are common in many natural
languages. Furthermore, it allowed for multiple children of
the ROOT label. In addition to producing said graphs, this
work is novel in its use of two new LSTM-based techniques:
Bi-LSTM Subtraction and Incremental Tree-LSTM. Bi-LSTM
Subtraction built on previous work , to represent the
buffer as a subtraction of the vectors from the head and tail
of the LSTM, in addition to using an additional LSTM to
represent the deque. Incremental Tree-LSTM is an extension
of Tree-LSTM , modiﬁed for directed acyclic graphs,
by connecting children to parents incrementally, rather than
connecting all children to a parent simultaneously. The model
achieved the best published scores at the time for fourteen of
the sixteen evaluation metrics used on SemEval-2015 Task 18
(English) and SemEval-2016 Task 9 (Chinese) .
While deep learning had been applied to semantic parsing in
particular domains, such as Question Answering , ,
to the authors’ knowledge, this was the ﬁrst time it was applied
in large scale to semantic parsing as a whole.
3) Generative Dependency and Constituent Parsing: Dyer
et al. proposed a model that used recurrent neural network grammars for parsing and language modeling. Whereas
most approaches take a bottom-up approach to parsing, this
took a top-down approach, taking as input the full sentence in
addition to the current parse tree. This allowed the sentence
to be viewed as a whole, rather than simply allowing local
phrases within it to be considered. This model achieved the
then best results in English generative parsing as well as in
single sentence language modeling. It also attained results
close to the best in Chinese generative parsing.
Choe and Charniak treated parsing as a language
modeling problem, and used an LSTM to assign probabilities
to the parse trees, achieving state-of-the art. Fried et al. 
wanted to determine whether the power of the models came
from the reranking process or simply from the combined
power of two models. They found that while using one parser
for producing candidate trees and another for ranking them
was superior to a single parser approach, combining two
parsers explicitly was preferable. They used two parsers to
both select the candidates and rerank them, achieving state-ofthe-art results. They extended this model to use three parsers,
achieving even better results. Finally, an ensemble of eight
such models (using two parsers) was constructed and achieved
the best results on Penn Treebank at the time.
A model created by Dozat and Manning used a graphbased approach with a self-attentive network. Similarly, Tan
et al. used a self-attentional model for semantic role
labeling, a subtask of semantic parsing, achieving excellent
results. They experimented with recurrent and convolutional
replacements to the feed-forward portions of the self-attention
mechanism, ﬁnding that the feed forward variant had the best
performance. Another novel approach is that of Duong et al.
 , who used active learning. While not perfect, this is a
possible solution to one of the biggest problems in semantic
parsing—the availability of data.
4) Universal Parsing: Much like universal morphology,
universal dependency parsing, or universal parsing, is the
relatively new task of parsing language using a standardized
set of tags and relationships across all languages. While
current parsing varies drastically from language to language,
this attempts to make it uniform between them, in order
to allow for easier processing between and among them.
Nivre discussed the recent development of universal
grammar and presented the challenges that lie ahead, mainly
the development of tree banks in more languages and the
consistency of labeling between tree banks in different (and
even the same) languages. This task has gained traction in
large part due to the fact that it has been a CoNLL shared task
for the past two years. A number of approaches from the
2018 task included using deep transition parsing , graphbased neural parsing , and a competitive model which
used only a single neural model, rather than an ensemble .
The task has begun to be examined outside of CoNLL, with
Liu et al. applying universal dependencies to the parsing
of tweets, using an ensemble of bidirectional LSTM.
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. X, JULY 2019
5) Remaining Challenges: Outside of universal parsing, a
parsing challenge that needs to be further investigated is the
building of syntactic structures without the use of treebanks
for training. Attempts have been made using attention scores
and Tree-LSTMs, as well as outside-inside auto-encoders. If
such approaches are successful, they have potential use in
many environments, including in the context of low-resource
languages and out-of-domain scenarios. While a number of
other challenges remain, these are the largest and are expected
to receive the most focus.
D. Semantics
Semantic processing involves understanding the meaning
of words, phrases, sentences, or documents at some level.
Word embeddings, such as Word2Vec , and GloVe
 , claim to capture meanings of words, following the
Distributional Hypothesis of Meaning . As a corollary,
when vectors corresponding to phrases, sentences, or other
components of text are processed using a neural network, a
representation that can be loosely thought to be semantically
representative is computed compositionally. In this section,
neural semantic processing research is separated into two
distinct areas: Work on comparing the semantic similarity of
two portions of text, and work on capturing and transferring
meaning in high level constituents, particularly sentences.
1) Semantic Comparison: One way to test the efﬁcacy of
an approach to computing semantics is to see if two similar
phrases, sentences or documents, judged by humans to have
similar meaning also are judged similarly by a program.
Hu et al. proposed two CNNs to perform a semantic
comparison task. The ﬁrst model, ARC-I, inspired by Bordes
et al. , used a Siamese network, in which two CNNs
sharing weights evaluated two sentences in parallel. In the
second network, connections were placed between the two,
allowing for sharing before the ﬁnal states of the CNNs. The
approach outperformed a number of existing models in tasks
in English and Chinese.
Building on prior work , , , Yin and Sch¨utze
 proposed a Bi-CNN-MI (MI for multigranular interaction features), consisting of a pretrained CNN sentence
model, a CNN interaction model, and a logistic regressor.
They modiﬁied a Siamese network using Dynamic CNNs 
(Section III-D2). Additionally, the feature maps from each
level were used in the comparison, rather than simply the toplevel feature maps. They achieved state-of-the-art results on
the Microsoft Research Paraphrase Corpus (MSRP) .
He et al. constructed feature maps, which were then
compared using a “similarity measurement layer” followed
by a fully-connected layer and then a log-softmax output
layer within a CNN. The windows used in the convolutional
layers ranged in length from one to four. The network was
trained and evaluated on three datasets: MSRP, the Sentences
Involving Compositional Knowledge (SICK) dataset ,
and the Microsoft Video Paraphrase Corpus (MSRVID) .
State-of-the-art results were achieved on the ﬁrst and the third.
Tai et al. concocted a model using an RvNN with LSTMlike nodes called a Tree-LSTM. Two variations were
examined (constituency- and dependency-based) and tested on
both the SICK dataset and Stanford Sentiment Treebank .
The constituency-based model achieved state-of-the-art results
on the Stanford Sentiment Treebank and the dependency-based
one achieved state-of-the-art results on SICK.
He et al. presented another model , which outperformed that of Tai et al. on SICK. The model formed a
matrix of the two sentences before applying a “similarity focus
layer” and then a nineteen-layer CNN followed by dense layers
with a softmax output. The similarity focus layer matched
semantically similar pairs of words from the input sentences
and applied weights to the matrix locations representing the
relations between the words in each pair. They also obtained
state-of-the-art resuults on MSRVID, SemEval 2014 Task 10
 , WikiQA , and TreeQA datasets.
2) Sentence Modeling: Extending from neural language
modeling, sentence modeling attempts to capture the meaning
of sentences in vectors. Taking this a step further are models,
such as that of Le and Mikolov , which attempt to model
paragraphs or larger bodies of text in this way.
Kalchbrenner et al. generated representations of sentences using a dynamic convolutional neural network (DCNN),
which used a number of ﬁlters and dynamic k-max pooling
layers. Due to dynamic pooling, features of different types and
lengths could be identiﬁed in sentences with varying structures
without padding of the input. This allowed not only shortrange dependencies, but also long-range dependencies to be
identiﬁed. The DCNN was tested in applied tasks that require
semantic understanding. It outperformed all comparison models in predicting sentiment of movie reviews in the Stanford
Sentiment Treebank and in identiﬁcation of sentiment
in tweets . It was also one of the top performers in
classifying types of questions using the TREC database .
Between their requirement for such understanding and
their ease of examination due to the typical encoder–decoder
structure they use, neural machine translation (NMT) systems
(Section IV-G) are splendid testbeds for researching internal
semantic representations. Poliak et al. trained encoders
on four different language pairs: English and Arabic, English
and Spanish, English and Chinese, and English and German.
The decoding classiﬁers were trained on four distinct datasets:
Multi-NLI , which is an expanded version of SNLI ,
as well as three recast datasets from the JHU Decompositional
Semantics Initiative (FrameNet Plus or FN+ , Definite Pronoun Resolution or DPR , and Semantic Proto-
Roles or SPR ). None of the results were particularly
strong, although they were strongest in SPR. This led to the
conclusion that NMT models do a poor job of capturing
paraphrased information and fail to capture inferences that
help in anaphora resolution. (e.g. resolving gender). They did,
however, ﬁnd that the models learn about proto-roles (e.g.
who or what is the recipient of an action). A concurrent work
 analyzed the quality of many datasets used for natural
language inference.
Herzig and Berant found that training semantic parsers
on a single domain, as is often done, is less effective than
training across many domains. This conclusion was drawn
after testing three LSTM-based models. The ﬁrst model was
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. X, JULY 2019
a one-to-one model, in which a single encoder and single
decoder were used, requiring the network itself to determine
the domain of the input. In the second model, a many-tomany model, a decoder was used for each domain, as were
two encoders: the domain speciﬁc encoder and a multidomain
encoder. The third model was a one-to-many model, using
a single encoder, but separate decoders for each domain.
Each model was trained on the “OVERNIGHT” dataset .
Exceptional results were achieved for all models, with a stateof-the-art performance exhibited by the one-to-one model.
Similar conclusions were drawn by Brunner et al. .
who created several LSTM-based encoder–decoder networks,
and analyzed the embedding vectors produced. A single encoder accepting English sentences as input was used, as were
four different decoders. The ﬁrst such decoder was a replicating decoder, which reproduced the original English input.
The second and third decoders translated the text into German
and French. Finally, the fourth decoder was a POS tagger.
Different combinations of decoders were used; one model
had only the replicating decoder while others had two, three,
or all four. Sentences of fourteen different structures from
the EuroParl dataset were used to train the networks.
A set of test sentences were then fed to the encoders and
their output analyzed. In all cases, fourteen clusters were
formed, each corresponding to one of the sentence structures.
Analysis showed that adding more decoders led to more
correct and more deﬁnitive clusters. In particular, using all four
of the decoders led to zero error. Furthermore, the researchers
conﬁrmed a hypothesis that just as logical arithmetic can be
performed on word embeddings, so can it be performed on
sentence embeddings.
3) Semantic Challenges: In addition to the challenges already mentioned, researchers believe that being able to solve
tasks well does not indicate actual understanding. Integrating
deep networks with general word-graphs (e.g. WordNet )
or knowledge-graphs (e.g. DBPedia ) may be able to
endow a sense of understanding. Graph-embedding is an active
area of research , and work on integrating language-based
models and graph models has only recently begun to take off,
giving hope for better machine understanding.
E. Summary of Core Issues
Deep learning has generally performed very well, surpassing
existing states of the art in many individual core NLP tasks,
and has thus created the foundation on which useful natural
language applications can and are being built. However, it is
clear from examining the research reviewed here that natural
language is an enigmatically complex topic, with myriad
core or basic tasks, of which deep learning has only grazed
the surface. It is also not clear how architectures for ably
executing individual core tasks can be synthesized to build
a common ediﬁce, possibly a much more complex distributed
neural architecture, to show competence in multiple or “all”
core tasks. More fundamentally, it is also not clear, how
mastering of basic tasks, may lead to superior performance
in applied tasks, which are the ultimate engineering goals,
especially in the context of building effective and efﬁcient deep
learning models. Many, if not most, successful deep learning
architectures for applied tasks, discussed in the next section,
seem to forgo explicit architectural components for core tasks,
and learn such tasks implicitly. Thus, some researchers argue
that the relevance of the large amount of work on core issues
is not fully justiﬁed, while others argue that further extensive
research in such areas is necessary to better understand and
develop systems which more perfectly perform these tasks,
whether explicitly or implicitly.
IV. APPLICATIONS OF NATURAL LANGUAGE PROCESSING
USING DEEP LEARNING
While the study of core areas of NLP is important to
understanding how neural models work, it is meaningless in
and of itself from an engineering perspective, which values
applications that beneﬁt humanity, not pure philosophical and
scientiﬁc inquiry. Current approaches to solving several immediately useful NLP tasks are summarized here. Note that the
issues included here are only those involving the processing
of text, not the processing of verbal speech. Because speech
processing , requires expertise on several other
topics including acoustic processing, it is generally considered
another ﬁeld of its own, sharing many commonalities with the
ﬁeld of NLP. The number of studies in each discussed area
over the last decade is shown in Figure 4
A. Information Retrieval
The purpose of Information Retrieval (IR) systems is to help
people ﬁnd the right (most useful) information in the right
(most convenient) format at the right time (when they need
it) . Among many issues in IR, a primary problem that
needs addressing pertains to ranking documents with respect to
a query string in terms of relevance scores for ad-hoc retrieval
tasks, similar to what happens in a search engine.
Deep learning models for ad-hoc retrieval match texts of
queries to texts of documents to obtain relevance scores. Thus,
such models have to focus on producing representations of
the interactions among individual words in the query and
the documents. Some representation-focused approaches build
deep learning models to produce good representations for
the texts and then match the representations straightforwardly
 , , , whereas interaction-focused approaches
ﬁrst build local interactions directly, and then use deep neural
networks to learn how the two pieces of text match based
on word interactions , , . When matching a
long document to a short query, the relevant portion can
potentially occur anywhere in the long document and may
also be distributed, thus, ﬁnding how each word in the query
relates to portions of the document is helpful.
Mindful of the speciﬁc needs for IR, Guo et al. built
a neural architecture called DRMM, enhancing an interactionfocused model that feeds quantized histograms of the local
interaction intensities to an MLP for matching. In parallel, the
query terms go through a small sub-network on their own to
establish term importance and term dependencies. The outputs
of the two parallel networks are mixed at the top so that the
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. X, JULY 2019
Fig. 4: Publication Volume for Applied Areas of NLP. All areas of applied natural language processing discussed have witnessed
growth in recent years, with the largest growth occurring in the last two to three years.
relevance of the document to the query can be better learned.
DRMM achieved state-of-the-art performance for its time.
Most current neural IR models are not end-to-end relevance
rankers, but are re-rankers for documents a ﬁrst-stage efﬁcient traditional ranker has deemed relevant to a query. The
representations the neural re-rankers learn are dense for both
documents and queries, i.e., most documents in a collection
seem to be relevant to a query, making it impossible to use
such ANNs for ranking an entire collection of documents. In
contrast, Zamani et al. presented a standalone neural
ranking model called SNRM PRF, that learned sparse representations for both queries and documents, mimicking what
traditional approaches do. Since queries are much shorter
than documents and queries contain much less information
than documents, it makes sense for query representations to
be denser. This was achieved by using, during training, a
sparsity objective combined with hinge loss. In particular, an
n-gram representation for queries and documents was used.
It passed the embedding of each word separately through
an individual MLP and performed average pooling on top.
During training, the approach used pseudo-relevant documents
obtained by retrieving documents using existing models like
TF-IDF and BM25, because of the lack of enough correctly
labeled documents to train large ANN models. The approach
created a 20,000 bit long inverted index for each document
using the trained network, just like a traditional end-to-end
approach. For retrieval, a dot product was computed between
query and document representations to obtain the retrieval
relevance score. The SNRM PRF system obtained the best
metrics (measured by MAP, P@20, nDCG@20, and Recall)
across the board for two large datasets, Robust and ClueWeb.
MacAveney et al. extracted query term representations
from two pre-trained contextualized language models, ELMo
 and BERT , and used the representations to augment three existing competitive neural ranking architectures
for ad-hoc document ranking, one of them being DRMM
 . They also presented a joint model that combined
BERT’s classiﬁcation vector with these architectures to get
beneﬁts from both approaches. MacAveney’s system called
CEDR (Contextualized Embeddings for Document Ranking)
improved performance of all three prior models, and produced
state-of-the-art results using BERT’s token representations.
B. Information Extraction
Information extraction extracts explicit or implicit information from text. The outputs of systems vary, but often the
extracted data and the relationships within it are saved in
relational databases . Commonly extracted information
includes named entities and relations, events and their participants, temporal information, and tuples of facts.
1) Named Entity Recognition: Named entity recognition
(NER) refers to the identiﬁcation of proper nouns as well as
information such as dates, times, prices, and product IDs. The
multi-task approach of Collobert et al. included the task,
although no results were reported. In their approach, a simple
feedforward network was used, having a context with a ﬁxed
sized window around each word. Presumably, this made it
difﬁcult to capture long-distance relations between words.
LSTMs were ﬁrst used for NER by Hammerton . The
model, which was ahead of its time, had a small network
due to the lack of available computing power at the time.
Additionally, sophisticated numeric vector models for words
were not yet available. Results were slightly better than the
baseline for English and much better than the baseline for
German. Dos Santos et al. used a deep neural network
architecture, known as CharWNN, which jointly used wordlevel and character-level inputs to perform sequential classiﬁcation. In this study, a number of experiments were performed
using the HAREM I annotated Portuguese corpus , and
the SPA CoNLL2002 annotated Spanish corpus . For
the Portuguese corpus, CharWNN outperformed the previous
state-of-the-art system across ten named entity classes. It
also achieved state-of-the-art performance in Spanish. The
authors noted that when used alone, neither word embeddings
nor character level embeddings worked. This revalidated a
fact long-known: Joint use of word-level and character-level
features is important to effective NER performance.
Chiu and Nichols used a bidirectional LSTM with a
character-level CNN resembling those used by dos Santos et al.
 . Without using any private lexicons, detailed information
about linked entities, or produce state-of-the-art results on the
CoNLL-2003 and OntoNotes , datasets.
Lample et al. developed an architecture based on bidirectional LSTMs and conditional random ﬁelds (CRFs). The
model used both character-level inputs and word embeddings.
The inputs were combined and then fed to a bidirectional
LSTM, whose outputs were in turn fed to a layer that performed CRF computations . The model, when trained
using dropout, obtained state-of-the-art performance in both
German and Spanish. The LSTM-CRF model was also very
close in both English and Dutch. The claim of this study was
that state-of-the-art results were achieved without the use of
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. X, JULY 2019
any hand-engineered features or gazetteers.
Akbik et al. achieved state-of-the-art performance in
German and English NER using a pre-trained bidirectional
character language model. They retrieved for each word a
contextual embedding that they passed into a BiLSTM-CRF
sequence labeler to perform NER.
2) Event Extraction: Event extraction is concerned with
identifying words or phrases that refer to the occurrence of
events, along with participants such as agents, objects, recipients, and times of occurrence. Event extraction usually deals
with four sub-tasks: identifying event mentions, or phrases
that describe events; identifying event triggers, which are
the main words—usually verbs or gerunds—that specify the
occurrence of the events; identifying arguments of the events;
and identifying arguments’ roles in the events.
Chen et al. argued that CNNs that use max-pooling
are likely to capture only the most important information in
a sentence, and as a result, might miss valuable facts when
considering sentences that refer to several events. To address
this drawback, they divided the feature map into three parts,
and instead of using one maximum value, kept the maximum
value of each part. In the ﬁrst stage, they classiﬁed each word
as either being a trigger word or non-trigger word. If triggers
were found, the second stage aligned the roles of arguments.
Results showed that this approach signiﬁcantly outperformed
other state-of-the-art methods of the time. The following year,
Nguyen et al. used an RNN-based encoder–decoder
pair to identify event triggers and roles, exceeding earlier
results. Liu et al. presented a latent variable neural model
to induce event schemas and extract open domain events,
achieving best results on a dataset they created and released.
3) Relationship Extraction: Another important type of information extracted from text is that of relationships. These
may be possessive, antonymous or synonymous relationships,
or more natural, familial or geographic, relationships. The ﬁrst
deep learning approach was that of Zeng et al. , who
used a simple CNN to classify a number of relationships
between elements in sentences. Using only two layers, a
window size of three, and word embeddings with only ﬁfty
dimensions they attained better results than any prior approach.
Further work, by Zheng et al. , used a bidirectional
LSTM and a CNN for relationship classiﬁcation as well as
entity recognition. More recently, Sun et al. used an
attention-based GRU model with a copy mechanism. This
network was novel in its use of a data structure known as
a coverage mechanism , which helped ensure that all
important information was extracted the correct number of
times. Lin et al. achieve state-of-the-art performance
in clinical temporal relation extraction using the pre-trained
BERT model with supervised training on a biomedical
C. Text Classiﬁcation
Another classic application for NLP is text classiﬁcation, or
the assignment of free-text documents to predeﬁned classes.
Document classiﬁcation has numerous applications.
Kim was the ﬁrst to use pretrained word vectors in a
CNN for sentence-level classiﬁcation. Kim’s work was motivating, and showed that simple CNNs, with one convolutional
layer followed by a dense layer with dropout and softmax
output, could achieve excellent results on multiple benchmarks
using little hyperparameter tuning. The CNN models proposed
were able to improve upon the state of the art on 4 out
of 7 different tasks cast as sentence classiﬁcation, including
sentiment analysis and question classiﬁcation. Conneau et al.
 later showed that networks that employ a large number
of convolutional layers work well for document classiﬁcation.
Jiang used a hybrid architecture combining a deep
belief network and softmax regression . (A deep
belief network is a feedforward network where pairs of hidden
layers are designed to resemble restricted Boltzmann machines
 , which are trained using unsupervised learning and are
designed to increase or decrease dimensionality of data.) This
was achieved by making passes over the data using forward
and backward propagation many times until a minimum
engery-based loss was found. This process was independent of
the labeled or classiﬁcation portion of the task, and was therefore initially trained without the softmax regression output
layer. Once both sections of the architecture were pretrained,
they were combined and trained like a regular deep neural net
with backpropagation and quasi-Newton methods .
Adhikari et al. used BERT to obtain state-of-theart classiﬁcation results on four document datasets.
While deep learning is promising for many areas of NLP,
including text classiﬁcation, it is not necessarily the end-all-beall, and many hurdles are still present. Worsham and Kalita
 found that for the task of classifying long full-length
books by genre, gradient boosting trees are superior to neural
networks, including both CNNs and LSTMs.
D. Text Generation
Many NLP tasks require the generation of human-like
language. Summarization and machine translation convert one
text to another in a sequence-to-sequence (seq2seq) fashion.
Other tasks, such as image and video captioning and automatic
weather and sports reporting, convert non-textual data to text.
Some tasks, however, produce text without any input data to
convert (or with only small amounts used as a topic or guide).
These tasks include poetry generation, joke generation, and
story generation.
1) Poetry Generation: Poetry generation is arguably the
hardest of the generation subtasks, as in addition to producing
creative content, the content must be delivered in an aesthetic
manner, usually following a speciﬁc structure. As with most
tasks requiring textual output, recurrent models are the standard. However, while recurrent networks are great at learning
internal language models, they do a poor job of producing
structured output or adhering to any single style. Wei et al.
 addressed the style issue by training using particular
poets and controlling for style in Chinese poetry. They found
that with enough training data, adequate results could be
achieved. The structure problem was addressed by Hopkins
and Kiela , who generated rhythmic poetry by training
the network on only a single type of poem to ensure produced
poems adhered to a single rhythmic structure. Human evalu-
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. X, JULY 2019
ators judged poems produced to be of lower quality than, but
indistinguishable from, human produced poems.
Another approach to poetry generation, beginning this year,
has been to use pretrained language models. Speciﬁcally,
Radford et al.’s GPT-2 model , the successor of the
GPT model (Section III-A7) has been used. Radford et al.
hypothesised that alongside sequence-to-sequence learning and
attention, language models can inherently start to learn text
generation while training over a vast dataset. As of late 2019,
these pre-trained GPT-2 models are arguably the most effective
and proliﬁc neural natural language generators. Bena and
Kalita used the 774 million parameter GPT-2 model
to generate high-quality poems in English, demonstrating and
eliciting emotional response in readers. Tucker and Kalita generated
poems in several languages—English, Spanish, Ukrainian,
Hindi, Bengali, and Assamese—using the 774 M model as
well. This study provided astonishing results in the fact that
GPT-2 was pre-trained on a large English corpus, yet with
further training on only a few hundred poems in another
language, it turns into a believable generator in that language,
even for poetry.
2) Joke and Pun Generation: Another area which has
received little attention is the use of deep learning for joke
and pun generation. Yu et al. generated homographic
puns (puns which use multiple meanings of the same written
word) using a small LSTM. The network produced sentences
in which ambiguities were introduced by words with multiple
meanings, although it did a poor job of making the puns
humorous. The generated puns were classiﬁed by human
evaluators as machine generated a majority of the time. The
authors noted that training on pun data alone is not sufﬁcient
for generating good puns. Ren and Yang used an LSTM
to generate jokes, training on two datasets, one of which was
a collection of short jokes from Conan O’Brien. Since many
of these jokes pertain to current events, the network was also
trained on a set of news articles. This gave context to the
example jokes. Chippada and Saha generated jokes,
quotes, and tweets using the same neural network, using an
additional input to specify which should be produced. It was
found that providing more general knowledge of other types
of language, and examples of non-jokes, increased the quality
of the jokes produced.
3) Story Generation: While poetry and especially humor
generation have not gained much traction, story generation
has seen a recent rise in interest. Jain et al. used RNN
variants with attention to produce short stories from “oneliner” story descriptions. Another recent study of interest is
that by Peng et al. , who used LSTMs to generate stories,
providing an input to specify whether the story should have a
happy or sad ending. Their model successfully did so while at
the same time providing better coherence than non-controlled
stories. More recent attempts at the task have used special
mechanisms focusing on the “events” (or actions) in the stories
 or on the entities (characters and important objects)
 . Even with such constraints, generated stories generally
become incoherent or lose direction rather shortly. Xu et al.
 addressed this by using a “skeleton” based model to
build general sentences and ﬁll in important information. This
did a great job of capturing only the most important information, but still provided only modest end results in human
evaluation. Drissi et al. followed a similar approach.
The strongest models to date focus on creating high level
overviews of stories before breaking them down into smaller
components to convert to text. Huang et al. generated
short stories from images using a two-tiered network. The ﬁrst
constructed a conceptual overview while the second converted
the overview into words. Fan et al. used a hierarchical
approach, based on CNNs, which beat out the non-hierarchical
approach in blind comparison by human evaluators. Additionally, they found that self attention leads to better perplexity.
They also developed a fusion model with a pretrained language
model, leading to greater improvements. These results concur
with those of an older study by Li et al. who read
documents in a hierarchical fashion and reproduced them in
hierarchical fashion, achieving great results.
4) Text Generation with GANs: In order to make stories
seem more human-like, He et al. used GANs (generative
adversarial networks) to measure human-likeness of generated
text, forcing the network toward more natural reading output.
Generative Adversarial Networks are based on the concept of
a minimax two-player game, in which a generative network
and a discriminative network are designed to work against
each other with the discriminator attempting to determine
if examples are from the generative network or the training
set, and the generator trying to maximize the number of
mistakes made by the discriminator. RankGAN, the GAN
used in the study, measured differences in embedding space,
rather than in output tokens. This meant the story content
was evaluated more directly, without respect to the speciﬁc
words and grammars used to tell it. Rather than simply using
standard metrics and minimizing loss, Tambwekar et al. 
used reinforcement learning to train a text generation model.
This taught the model to not only attempt to optimize metrics,
but to generate stories that humans evaluated to be meaningful.
Zhange et al. used another modiﬁed GAN, referred to as
textGAN, for text generation, employing an LSTM generator
and a CNN discriminator, achieving a promising BLEU score
and a high tendency to reproduce realistic-looking sentences.
Generative adversarial networks have seen increasing use in
text generation recently , .
5) Text Generation with VAEs: Another interesting type of
network is the variational autoencoder (VAE) . While
GANs attempt to produce output indistinguishable (at least to
the model’s discriminator) from actual samples, VAEs attempt
to create output similar to samples in the training set .
Several recent studies have used VAEs for text generation
 , , including Wang et al. , who adapted it by
adding a module for learning a guiding topic for sequence
generation, producing good results.
6) Summary of Text Generation: Humor and poetry generation are still understudied topics. As machine generated texts
improve, the desire for more character, personality, and color
in the texts will almost certainly emerge. Hence, it can be
expected that research in these areas will increase.
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. X, JULY 2019
While story generation is improving, coherence is still a
major problem, especially for longer stories. This has been
addressed in part, by Haltzman et al., who have proposed
“nucleus sampling” to help counteract this problem, performing their experiments using the GPT-2 model.
In addition to issues with lack of creativity and coherence,
creating metrics to measure any sort of creative task is
difﬁcult, and therefore, human evaluations are the norm, often
utilizing Amazon’s Mechanical Turk. However, recent works
have proposed metrics that make a large step toward reliable
automatic evaluation of generated text , . In addition
to the more creative tasks surveyed here, a number of others
were previously discussed by Gatt and Krahmer . The
use of deep learning for image captioning has been surveyed
very recently , , and tasks that generate text given
textual inputs are discussed in the following subsections.
E. Summarization
Summarization ﬁnds elements of interest in documents in
order to produce an encapsulation of the most important
content. There are two primary types of summarization: extractive and abstractive. The ﬁrst focuses on sentence extraction, simpliﬁcation, reordering, and concatenation to relay the
important information in documents using text taken directly
from the documents. Abstractive summaries rely on expressing documents’ contents through generation-style abstraction,
possibly using words never seen in the documents .
Rush et al. introduced deep learning to summarization,
using a feedforward neural networrk. The language model
used an encoder and a generative beam search decoder. The
initial input was given directly to both the language model and
the convolutional attention-based encoder, which determined
contextual importance surrounding the summary sentences and
phrases. The performance of the model was comparable to
other state-of-the-art models of the time.
As in other areas, attention mechanisms have improved
performance of encoder–decoder models. Krantz and Kalita
 compared various attention models for abstractive summarization. A state-of-the-art approach developed by Paulus
et al. used a multiple intra-temporal attention encoder
mechanism that considered not only the input text tokens,
but also the output tokens used by the decoder for previously
generated words. They also used similar hybrid cross-entropy
loss functions to those proposed by Ranzato et al. ,
which led to decreases in training and execution by orders of
magnitude. Finally, they recommended using strategies seen in
reinforcement learning to modify gradients and reduce exposure bias, which has been noted in models trained exclusively
via supervised learning. The use of attention also boosted
accuracy in the fully convolutional model proposed by Gehring
et al. , who implemented an attention mechanism for each
Zhang et al. proposed an encoder-decoder framework, which generated an output sequence based on an input
sequence in a two-stage manner. They encoded the input
sequence using BERT . The decoder had two stages.
In the ﬁrst stage, a Transformer-based decoder generated a
draft output sequence. In the second stage, they masked each
word of the draft sequence and fed it to BERT, and then
by combining the input sequence and the draft representation
generated by BERT, they used a Transformer-based decoder to
predict the reﬁned word for each masked position. Their model
achieved state-of-the-art performance on the CNN/Daily Mail
and New York Times datasets.
F. Question Answering
Similar to summarization and information extraction, question answering (QA) gathers relevant words, phrases, or sentences from a document. QA returns this information in a
coherent fashion in response to a request. Current methods
resemble those of summarization.
Wang et al. used a gated attention-based recurrent
network to match the question with an answer-containing
passage. A self-matching attention mechanism was used to
reﬁne the machine representation by mapping the entire passage. Pointer networks were used to predict the location and
boundary of an answer. These networks used attention-pooling
vector representations of passages, as well as the words being
analyzed, to model the critical tokens or phrases necessary.
Multicolumn CNNs were used by Dong et al. to
automatically analyze questions from multiple viewpoints.
Parallel networks were used to extract pertinent information
from input questions. Separate networks were used to ﬁnd
context information and relationships and to determine which
forms of answers should be returned. The output of these
networks was combined and used to rank possible answers.
Santoro et al. used relational networks (RNs) for
summarization. First proposed by Raposo et al. , RNs
are built upon an MLP architecture, with focus on relational
reasoning, i.e. deﬁning relationships among entities in the data.
These feedforward networks implement a similar function
among all pairs of objects in order to aggregate correlations
among them. For input, the RNs took ﬁnal LSTM representations of document sentences. These inputs were further paired
with a representation of the information request given .
BERT achieved state of theart in QA experiments
on SQuAD 1.1 and SQuAD 2.0 datasets. Yang et al. 
demonstrate an end-to-end question answering system that
integrates BERT with the open-source Anserini information
retrieval toolkit. This system is able to identify answers from
a large corpus of Wikipedia articles in an end-to-end fashion,
obtaining best results on a standard benchmark test collection.
G. Machine Translation
Machine translation (MT) is the quintessential application
of NLP. It involves the use of mathematical and algorithmic
techniques to translate documents in one language to another.
Performing effective translation is intrinsically onerous even
for humans, requiring proﬁciency in areas such as morphology,
syntax, and semantics, as well as an adept understanding and
discernment of cultural sensitivities, for both of the languages
(and associated societies) under consideration .
The ﬁrst attempt at neural machine translation (NMT) was
that by Schwenk , although neural models had previously
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. X, JULY 2019
been used for the similar task of transliteration, converting
certain parts of text, such as proper nouns, into different
languages . Schwenk used a feed-forward network with
seven-word inputs and outputs, padding and trimming when
necessary. The ability to translate from a sentence of one
length to a sentence of another length came about with the
introduction of encoder-decoder models.
The ﬁrst use of such a model, by Kalchbrenner and Blumson
 , stemmed from the success of continuous recurrent representations in capturing syntax, semantics, and morphology
 in addition to the ability of RNNs to build robust
language models . This original NMT encoder-decoder
model used a combination of generative convolutional and recurrent layers to encode and optimize a source language model
and cast this into a target language. The model was quickly
reworked and further studied by Cho et al. and numerous
novel and effective advances to this model have since been
made , . Encoder-decoder models have continuously
deﬁned the state of the art, being expanded to contain dozens
of layers, with residual connections, attention mechanisms,
and even residual attention mechanisms allowing the ﬁnal
decoding layer to attend to the ﬁrst encoding layer . Stateof-the-art results have also been achieved by using numerous
convolutional layers in both the encoder and decoder, allowing
information to be viewed in several hierarchical layers rather
than a multitude of recurrent steps . Such derived models
are continually improving, ﬁnding answers to the shortcomings
of their predecessors and overcoming any need for hand engineering . Recent progress includes effective initialization
of decoder hidden states, use of conditional gated attentional
cells, removal of bias in embedding layers, use of alternative
decoding phases, factorization of embeddings, and test time
use of the beam search algorithm , .
The standard initialization for the decoder state is that
proposed by Bahdanau et al. , using the last backward
encoder state. However, as noted by Britz et al. , using the
average of the embedding or annotation layer seems to lead to
the best translations. Gated recurrent cells have been the gold
standard for sequence-to-sequence tasks, a variation of which
is a conditional GRU (cGRU) , most effectively utilized
with an attention mechanism. A cGRU cell consists of three
key components: two GRU transition blocks and an attention
mechanism between them. These three blocks combine the
previous hidden state, along with the attention context window
to generate the next hidden state. Altering the decoding process
 from Look at input, Generate output token, Update
hidden representation to a process of Look, Update, Generate can simplify the ﬁnal decoding. Adding further source
attributes such as morphological segmentation labels, POS
tags, and syntactic dependency labels improves models, and
concatenating or factorizing these with embeddings increases
robustness further , . For remembering long-term
dependencies, vertically stacked recurrent units have been the
standard, with the optimum number of layers having been
determined to be roughly between two and sixteen ,
depending on the desired input length as well as the presence
and density of residual connections. At test time, a beam
search algorithm can be used beside the ﬁnal softmax layer
for considering multiple target predictions in a greedy fashion,
allowing the best predictions to be found without looking
through the entire hypothesis space .
In a direction diverging from previous work, Vaswani et al.
 , proposed discarding the large number of recurrent
and convolutional layers and instead focusing exclusively on
attention mechanisms to encode a language globally from
input to output. Preferring such ”self-attention” mechanisms
over traditional layers is motivated by the following three
principles: reducing the complexity of computations required
per layer, minimizing sequential training steps, and lastly,
abating the path length from input to output and its handicap
on the learning of the long-range dependencies which are
necessary in many sequencing tasks . Apart from increased accuracy across translation tasks, self-attention models
allow more parallelization throughout architectures, decreasing
the training times and minimizing necessary sequential steps.
At time of writing, the state-of-the-art model generating the
best results for English to German and English to French
on the IWSLT (International Workshop on Spoken Language
Translation) 2014 test corpus is that of Medina and
Kalita , which modiﬁed the model proposed by Vaswani
to use parallel self-attention mechanisms, rather than stacking
them as was done in the original model. In addition to improving BLEU (Bilingual Evaluation Understudy) scores ,
this also reduced training times. Ghazvininejad et al. 
recently applied BERT to the machine translation task, using
constant-time models. They were able to achieve relatively
competitive performance in a fraction of the time. Lample et al.
 attained state-of-the-art results, performing unsupervised
machine translation using multiple languages in their language
model pretraining.
Several of the recent state-of-the-art models were examined
by Chen et al. . The models were picked apart to
determine which features were truly responsible for their
strength and to provide a fair comparison. Hybrid models
were then created using this knowledge, and incorporating the
best parts of each previous model, outperforming the previous
models. In addition to creating two models with both a selfattentive component and a recurrent component (in one model
they were stacked, in the other parallel), they determined four
techniques which they believe should always be employed,
as they are crucial to some models, at best, and neutral to
all models examined, at worst. These are label smoothing,
multi-head attention, layer normalization, and synchronous
training. Another study, by Denkowski et al. , examined
a number of other techniques, recommending three: using
Adam optimization, restarting multiple times, with learning
rate annealing; performing subword translation; and using an
ensemble of decoders. Furthermore, they tested a number of
common techniques on models that were strong to begin, and
determined that three of the four provided no additional beneﬁts to, or actually hurt, the model, those three being lexiconbias (priming the outputs with directly translated words), pretranslation (using translations from another model, usually
of lower quality, as additional input), and dropout. They did
ﬁnd, however, that data-bootstrapping was advantageous even to models that are already
high-performing. They recommended that future developments
be tested on top performing models in order to determine their
realm of effectiveness.
In addition to studies presenting recommendations, one
study has listed a number of challenges facing the ﬁeld .
While neural machine translation models are superior to other
forms of statistical machine translation models (as well as rulebased models), they require signiﬁcantly more data, perform
poorly outside of the domain in which they are trained, fail
to handle rare words adequately, and do not do well with
long sentences (more than about sixty words). Furthermore,
attention mechanisms do not perform as well as their statistical
counterparts for aligning words, and beam searches used for
decoding only work when the search space is small. Surely
these six drawbacks will be, or in some cases, will continue
to be, the focus of much research in the coming years.
Additionally, as mentioned in Section III-D2, NMT models
still struggle with some semantic concepts, which will also
be a likely area of focus in years to come. While examining
some of these failings of NMT can help, predicting the future
of research and development in the ﬁeld is nearly impossible.
New models and methods are being reported on a daily
basis with far too many advancements to survey, and stateof-the-art practices becoming outdated in a matter of months.
Notable recent advancements include using caching to provide
networks with greater context than simply the individual
sentences being translated , the ability to better handle
rare words , , and the ability to translate to and from
understudied languages, such as those that are polysynthetic
 . Additionally work has been conducted on the selection,
sensitivity, and tuning of hyperparameters , denoising of
data , and a number of other important topics surrounding
neural machine translation. Finally, a new branch of machine
translation has been opened up by groundbreaking research:
multilingual translation.
A fairly recent study showed that a single, simple (but
large) neural network could be trained to convert a number
(up to at least twelve) of different languages to each other,
automatically recognizing the source language and simply
needing an input token to identify the output language. Furthermore, the model was found to be capable of understanding,
at least somewhat, multilingual input, and of producing mixed
outputs when multiple language tokens are given, sometimes
even in languages related to, but not actually, those selected.
This suggests that deep neural networks may be capable of
learning universal representations for information, independent
of language, and even more, that they might possibly be
capable of learning some etymology and relationships between
and among families of different languages.
H. Summary of Deep Learning NLP Applications
Numerous other applications of natural language processing
exist including grammar correction, as seen in word processors, and author mimicking, which, given sufﬁcient data,
generates text replicating the style of a particular writer. Many
of these applications are infrequently used, understudied, or
not yet exposed to deep learning. However, the area of sentiment analysis should be noted, as it is becoming increasingly
popular and utilizing deep learning. In large part a semantic
task, it is the extraction of a writer’s sentiment—their positive,
negative, or neutral inclination towards some subject or idea
 . Applications are varied, including product research,
futures prediction, social media analysis, and classiﬁcation
of spam , . The current state of the art uses an
ensemble including both LSTMs and CNNs .
This section has provided a number of select examples
of the applied usages of deep learning in natural language
processing. Countless studies have been conducted in these
and similar areas, chronicling the ways in which deep learning
has facilitated the successful use of natural language in a wide
variety of applications. Only a minuscule fraction of such work
has been referred to in this survey.
While more speciﬁc recommendations for practitioners have
been discussed in some individual subsections, the current
trend in state-of-the-art models in all application areas is to use
pre-trained stacks of Transformer units in some conﬁguration,
whether in encoder-decoder conﬁgurations or just as encoders.
Thus, self-attention which is the mainstay of Transformer
has become the norm, along with cross-attention between
encoder and decoder units, if decoders are present. In fact, in
many recent papers, if not most, Transformers have begun to
replace LSTM units that were preponderant just a few months
ago. Pre-training of these large Transformer models has also
become the accepted way to endow a model with generalized
knowledge of language. Models such as BERT, which have
been trained on corpora of billions of words, are available
for download, thus providing a practitioner with a model that
possesses a great amount of general knowledge of language
already. A practitioner can further train it with one’s own
general corpora, if desired, but such training is not always
necessary, considering the enormous sizes of the pre-training
that downloaded models have received. To train a model to
perform a certain task well, the last step a practitioner must go
through is to use available downloadable task-speciﬁc corpora,
or build one’s own task-speciﬁc corpus. This last training step
is usually supervised. It is also recommended that if several
tasks are to be performed, multi-task training be used wherever
V. CONCLUSIONS
Early applications of natural language processing included
a well-acclaimed but simpleminded algebra word problem
solver program called STUDENT , as well as interesting but severely constrained conversational systems such as
Eliza, which acted as a “psycho-therapist” ), and another
that conversed about manipulating blocks in a microworld
 . Nowadays, highly advanced applications of NLP are
ubiquitous. These include Google’s and Microsoft’s machine
translators, which translate more or less competently from a
language to scores of other languages, as well as a number of
devices which process voice commands and respond in like.
The emergence of these sophisticated applications, particularly
in deployed settings, acts as a testament to the impressive
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. X, JULY 2019
accomplishments that have been made in this domain over
the last sixty or so years. Without a doubt, incredible progress
has taken place, particularly in the last several years.
As has been shown, this recent progress has a clear causal
relationship with the remarkable advances in Artiﬁcial Neural
Networks. Considered an “old” technology just a decade ago,
these machine learning constructs have ushered in progress
at an unprecedented rate, breaking performance records in
myriad tasks in miscellaneous ﬁelds. In particular, deep neural
architectures, have instilled models with higher performance
in natural language tasks, in terms of “imperfect” metrics.
Consolidating the analysis of all the models surveyed, a
few general trends can be surmised. Both convolutional and
recurrent specimen had contributed to the state of the art in the
recent past, however, of very late, stacks of attention-powered
Transformer units as encoders and often decoders, have consistently produced superior results across the rich and varying
terrain of the NLP ﬁeld. These models are generally heavily
pre-trained on general language knowledge in an unsupervised
or supervised manner, and somewhat lightly trained on speciﬁc
tasks in a supervised fashion. Second, attention mechanisms
alone, without recurrences or convolutions, seem to provide
the best connections between encoders and decoders. Third,
forcing networks to examine different features (by performing multiple tasks) usually improves results. Finally, while
highly engineering networks usually optimizes results, there
is no substitute for cultivating networks with large quantities
of high quality data, although pre-training on large generic
corpora seems to help immensely. Following from this ﬁnal
observation, it may be useful to direct more research effort
toward pre-training methodologies, rather than developing
highly-specialized components to squeeze the last drops of
performance from complex models.
While the numerous stellar architectures being proposed
each month are highly competitive, muddling the process of
identifying a winning architecture, the methods of evaluation
used add just as much complexity to the problem. Datasets
used to evaluate new models are often generated speciﬁcally
for those models and are then used only several more times,
if at all, although consolidated datasets encompassing several
tasks such as GLUE have started to emerge. As the
features and sizes of these datasets are highly variable, this
makes comparison difﬁcult. Most subﬁelds of NLP, as well as
the ﬁeld as a whole, would beneﬁt from extensive, large-scale
discussions regarding the necessary contents of such datasets,
followed by the compilation of such sets. In addition to high
variability in evaluation data, there are numerous metrics used
to evaluate performance on each task. Oftentimes, comparing
similar models is difﬁcult due to the fact that different metrics
are reported for each. Agreement on particular sets of metrics
would go a long way toward ensuring clear comparisons in
Furthermore, metrics are usually only reported for the best
case, with few mentions of average cases and variability, or of
worst cases. While it is important to understand the possible
performance of new models, it is just as important to understand the standard performance. If models produce highly
variable results, they may take many attempts to train to the
cutting-edge levels reported. In most cases, this is undesirable,
and models that can be consistently trained to relatively high
levels of performance are preferable. While increasingly large
numbers of randomized parameters do reduce variation in
performance, some variance will always exist, necessitating
the reporting of more than just best-case metrics.
One ﬁnal recommendation for future work is that it be
directed toward a wider variety of languages than it is at
present. Currently, the vast majority of research in NLP is conducted on the English language, with another sizeable portion
using Mandarin Chinese. In translation tasks, English is almost
always either the input or output language, with the other end
usually being one of a dozen major European or Eastern Asian
languages. This neglects entire families of languages, as well
as the people who speak them. Many linguistic intricacies may
not be expressed in any of the languages used, and therefore
are not captured in current NLP software. Furthermore, there
are thousands of languages spoken throughout the world,
with at least eighty spoken by more than 10 million people,
meaning that current research excludes an immense segment
of humankind. Collection and validation of data in underanalyzed languages, as well as testing NLP models using such
data, will be a tremendous contribution to not only the ﬁeld of
natural language processing, but to human society as a whole.
Due to the small amounts of data available in many languages, the authors do not foresee the complete usurpation
of traditional NLP models by deep learning any time in the
near future. Deep learning models (and even shallow ANNs)
are extremely data-hungry. Contrastingly, many traditional
models require only relatively small amounts of training data.
However, looking further forward, it can be anticipated that
deep learning models will become the norm in computational
linguistics, with pre-training and transfer learning playing
highly impactful roles. Collobert et al. sparked the deep
learning revolution in NLP, although one of the key contributions of their work—that of a single uniﬁed model—was
not realized widely. Instead, neural networks were introduced
into traditional NLP tasks, and are only now reconnecting.
In the ﬁeld of parsing, for example, most models continue
to implement non-neural structures, simply using ANNs on
the side to make the decisions that were previously done
using rules and probability models. While more versatile and
general architectures are obviously becoming more and more
of a reality, understanding the abstract concepts handled by
such networks is important to understanding how to build and
train better networks. Furthermore, as abstraction is a hallmark
of human intelligence, understanding of the abstractions that
take place inside an ANN may aid in the understanding of
human intelligence and the processes that underlie it. Just as
human linguistic ability is only a piece of our sentience, so is
linguistic processing just a small piece of artiﬁcial intelligence.
Understanding how such components are interrelated is important in constructing more complete AI systems, and creating a
uniﬁed NLP architecture is another step toward making such
a system a reality.
This goal will also be aided by further advances in computational equipment. While GPUs have signiﬁcantly improved the
ability to train deep networks, they are only a step in the right
IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, VOL. XX, NO. X, JULY 2019
direction . The next step is the wider availability of chips
designed speciﬁcally for this purpose, such as Google’s Tensor
Processing Unit (TPU), Microsoft’s Catapult, and Intel’s Lake
Crest . Ultimately, artiﬁcial neural networks implemented
in traditional von Neumann style computers may not be able
to reach their full potential. Luckily, another old line of work
in computer science and engineering has seen a resurgance
in recent years: neuromorphic computing. With neuromorphic
chips, which implement neural structures at the hardware
level, expected much more widely in coming years ,
the continuation of deep learning and the longevity of its
success can be highly anticipated, ensuring the opportunity
for sustained progress in natural language processing.