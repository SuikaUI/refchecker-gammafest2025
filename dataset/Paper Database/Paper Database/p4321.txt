Research Article
Chanaleä Munien, Absalom E. Ezugwu*
Metaheuristic algorithms for onedimensional bin-packing problems: A survey
of recent advances and applications
 
received November 26, 2020; accepted March 19, 2021
Abstract: The bin-packing problem (BPP) is an age-old NP-hard combinatorial optimization problem,
which is deﬁned as the placement of a set of diﬀerent-sized items into identical bins such that the number
of containers used is optimally minimized. Besides, diﬀerent variations of the problem do exist in practice
depending on the bins dimension, placement constraints, and priority. More so, there are several important
real-world applications of the BPP, especially in cutting industries, transportation, warehousing, and
supply chain management. Due to the practical relevance of this problem, researchers are consistently
investigating new and improved techniques to solve the problem optimally. Nature-inspired metaheuristics
are powerful algorithms that have proven their incredible capability of solving challenging and complex
optimization problems, including several variants of BPPs. However, no comprehensive literature review
exists on the applications of the metaheuristic approaches to solve the BPPs. Therefore, to ﬁll this gap, this
article presents a survey of the recent advances achieved for the one-dimensional BPP, with speciﬁc
emphasis on population-based metaheuristic algorithms. We believe that this article can serve as a reference guide for researchers to explore and develop more robust state-of-the-art metaheuristics algorithms
for solving the emerging variants of the bin-parking problems.
Keywords: bin-packing problem, one-dimensional, nature-inspired, metaheuristic
1 Introduction
The bin-packing problem (BPP) is a combinatorial optimization problem that deals with packing a ﬁnite set
of items with weights into a ﬁnite number of bins without exceeding the speciﬁed maximum capacity of the
bins. This must be done such that the total number of required bins is minimized. The BPP can be viewed as
a special case of the one-dimensional (1D) cutting-stock problem . Research into the classical version of
the BPP dates back into the early 1970s; however, the structure and applications of this problem have been
studied since the 1930s . In terms of computational complexity theory, this problem is known to be NPhard . Therefore, achieving optimal solutions can be time-consuming, speciﬁcally for problem instances
with large sets of items.
The classical 1D BPP can be formally deﬁned as: for a non-negative bin capacity, C, and a list of n items,
, where ai has a value (size or weight) ( )
s ai satisfying the constraint
item must not be larger than capacity of bin), the requirement is to determine the smallest integer t such
Chanaleä Munien: School of Mathematics, Statistics, and Computer Science, University of KwaZulu-Natal, Private Bag Box
X54001, Durban 4000, South Africa, e-mail: 
* Corresponding author: Absalom E. Ezugwu, School of Mathematics, Statistics, and Computer Science, University of KwaZulu-
Natal, Pietermaritzburg, 3201, South Africa, e-mail: 
Journal of Intelligent Systems 2021; 30: 636–663
Open Access. © 2021 Chanaleä Munien and Absalom E. Ezugwu, published by De Gruyter.
This work is licensed under the
Creative Commons Attribution 4.0 International License.
that there is a partition of
. Here, the sum of the sizes of the items
j must not
exceed the maximum capacity. The set Wj can be seen as the contents of a bin with capacity, C .
There are several variations of the 1D BPP that ﬁt diﬀerent applications and have various types of
constraints – a few of which will be brieﬂy mentioned here. Coﬀman et al. introduced the concept of
maximizing the number of items that are packed into a bin, with the intention of modelling processor and
storage allocation problems. Given a ﬁxed number of bins,m, and a list of items, L, the aim of this variant is to
pack the maximum subset of L into the bins in such a way that the maximum bin capacity is never exceeded.
Krause et al. proposed a variant of the BPP problem that places a restriction on the number of items
allowed to be packed into each bin. Hence, for a given non-negative number, k, each bin may contain at most
k items. The authors investigated this problem with task scheduling in mind. Similarly, Coﬀman et al. 
described a generalization of the classical version of the BPP, where arrival and departure times were added
to each item. Hence, the items in a bin occupy the space according to the speciﬁed time interval. This variant
is more practical in particular applications such as problems associated with computer storage allocation.
Other research introduced multidimensional variations. The two-dimensional BPP requires allocating a
ﬁnite set of rectangles into a minimized number of rectangular bins . The three-dimensional problem
(3D) proposed by Martello requires packing a ﬁnite set of 3D rectangular items into a minimized number
of bins. In both problems, the bins must be of a ﬁxed size and overlapping must be avoided.
The classical 1D BPP can be modelled as an Integer Linear Program . Firstly, let u be an upper bound
on the minimum number of bins required to pack all the items. Assume that these bins are numbered as
, . Let n be the number of items to pack. Two binary decision variables are introduced:
is used in the solution
is packed into bin
The constraints enforce that the maximum capacity of the bin must not be exceeded, and that each item
must only be packed into one bin. The goal of the 1D-BPP is to minimize the total number of bins, N, that are
used to pack all n items, this can be estimated as follows:
where Si represents the size, or weight, of each item in the list of n items, andC represents the ﬁxed capacity
of the bins.
Due to the complexity of this problem and the variety of real-world applications that can beneﬁt from
good quality solutions, many approaches have been used to solve the BPP. These approaches include
approximate methods, metaheuristics, and hybrid metaheuristics. In addition, recently, the use of metaheuristic approaches for solving the BPP has become popular. These are incredibly powerful algorithms
Survey of NIM for 1D-BPP
that have successfully been applied to various combinatorial optimization problems , which include the
population-based genetic algorithm (GA) , particle swarm optimization (PSO) , the tabu search ,
and many others. Some main beneﬁts of utilizing metaheuristics are that they easily handle complex
constraints present in real-life applications, and they produce high-quality solutions while requiring
shorter computational time . However, metaheuristics cannot randomly be applied to optimization
problems, but rather, a signiﬁcant amount of knowledge on the subject is required to create a proper
metaheuristic implementation – an example of this is choosing a good representation scheme to ﬁt
the problem at hand.
The aim of this study is to highlight recent nature-inspired metaheuristics that have been applied to
solve the classical 1D BPP and to understand the beneﬁts of this approach, which includes eﬃciency and
high-quality solutions. This survey would invariably provide the much needed guidance to future enthusiastic researchers and industrial practitioners alike, who have interest in adapting the nature-inspired
metaheuristic algorithms to solve the well-known BPP. Speciﬁcally, we may summarize the technical
contributions of this article as follows:
• A state-of-the-art review of widely used metaheuristic algorithms for the 1D BPP.
• Critical analysis of design concepts and solution representation for the implementation of BPP using
nature-inspired population-based metaheuristic algorithms.
• A comparative evaluation of existing literature results for the BPP.
• Suggestions of trending practical application areas for the BPP.
The rest of this work is structured as follows: Section 2 provides an overview of approximate algorithms
and the recent metaheuristics that have been used as the foundation of the adapted nature-inspired
metaheuristics that solve the BPP. Section 3 provides insights into the aforementioned nature-inspired
metaheuristics by elaborating on their key features. Section 4 provides a comparison of results for each
of these metaheuristics. Section 5 presents some of the most intriguing recent application areas of the BPP.
Finally, the concluding remarks and future research direction are discussed in Section 6.
2 Literature review
2.1 Approximate algorithms
Approximate algorithms were the ﬁrst approach to solve the classical 1D BPP. There are two types of
approximation algorithms: online and oﬄine. In online algorithms, the items are considered one by one,
with no knowledge of succeeding items. Hence, the placement of the current item is based solely on the size
of the current item and the already packed items . A compelling concept that is introduced in the context
of online algorithms is that of bounded-space algorithms. Bins can either be open or closed, and items must
only be packed into open bins. When a new bin is added, it is given the status of “open.” In some
algorithms, the bin may be closed due to the inability to add items to the contents (as it may result in
exceeding the maximum capacity). Therefore, a bin-packing algorithm is considered a k-bounded-space
algorithm. This means that if there are k bins open and a single item is packed into a new bin, then one of
the open bins must be closed .
The Next Fit (NF) heuristic packs the maximum number of items that the current bin can contain, and
when there is no available space for the next item, the current bin is closed, a new bin is opened, and this
bin becomes the current bin . The First Fit (FF) heuristic diﬀers from NF in that the bins are not closed.
Each item is packed into the ﬁrst bin that has suﬃcient space. If an item cannot ﬁt into any of the available
bins, a new bin is opened . The Best Fit (BF) heuristic packs an item into the best, or most suitable, bin –
that is, the bin with the smallest available space after including the current item into it. As in FF, if no bin
can ﬁt the current item, a new bin is opened .
Chanaleä Munien and Absalom E. Ezugwu
On the other hand, oﬄine algorithms have also been used to solve this problem. Famous examples are
the NF-Decreasing, BF-Decreasing, and FF-Decreasing algorithms. This type of heuristic processes the data
before packing the items into the bin. Generally, this means that the items are rearranged and sorted in
increasing or decreasing order ; thereafter, these algorithms ﬁll the bins just as the original NF, BF, and
FF algorithms do. These oﬄine algorithms are not guaranteed to return optimal solutions every time.
An example of an algorithm that is both online and oﬄine is the Better-Fit heuristic algorithm (BFH)
 , which removes an existing item from a bin and replaces it with the current item if the current item
better ﬁlls the bin. Moreover, if the packing of the current item results in a smaller available space than the
packing of the existing item, then the latter item is removed from the bin it is in. This “replaced item” is then
packed using the BFH. This continues for all items until better-ﬁt cannot pack a replaced item. In this case,
the BF heuristic is used to pack the object. This algorithm outperforms the BF heuristic in every instance.
The performance of the algorithm is based on the sequence of items. If the items are arranged in decreasing
order, then the results are equivalent to that of BF-Decreasing, and if the items are arranged in increasing
order, the algorithm will place small items into the initial bins. Larger items cannot replace these. Therefore, the best performance is the average case in which the item weights (or sizes) are random .
2.2 Metaheuristic approaches
2.2.1 The ﬁtness-dependent optimizer (FDO)
The FDO was developed in 2019 by Abdullah and Ahmed . It is a swarm intelligent algorithm that models
the characteristics of the reproductive process of bee swarms, along with their collective decision-making
behaviour. Although the FDO is considered a PSO-based algorithm, it calculates the velocity of a particle
diﬀerently – it uses the problem ﬁtness function value to produce weights. These weights then guide the
algorithm’s search agents during the exploitation and exploration phases. Additionally, the FDO algorithm
requires fewer computations than the PSO algorithm for updating the velocity and particle positions .
Bees are social insects who reside in small caves or hollow trees. They work in colonies that are generally
called hives. The three types of bees in a colony include the queen, worker, and scout bees. Each of these bees
has speciﬁc functions according to their traits. The FDO algorithm focuses on the function of the scout bees.
These bees explore their environment in order to locate a suitable place for the colony to build a hive (in other
words, they exploit preferable hives). Once this is found, the bees perform a sort of “dance” to communicate
with the swarm . In the algorithm, each hive that is exploited by a scout bee is seen as a candidate
solution, and the best hive represents a global optimum solution, according to the relative ﬁtness weight.
The advantages of this algorithm are that it is stable in both the exploitation and exploration phases
and that it requires fewer computations than other algorithms. The disadvantage is that it uses a weight
factor in order to control the ﬁtness weights which are, in most cases, ignored . Abdul-Minaam et al. 
took into account these strengths and weaknesses. They adapted the FDO to solve the 1D BPP by replacing
the original way of generating the ﬁrst population with a random generation of the initial population using
an improved FF heuristic and by updating the operating strategies in the original algorithm to improve the
exploration and exploitation phases.
2.2.2 Cuckoo search via Lévy ﬂights
In 2009, Yang and Deb developed the population-based Cuckoo Search via Lévy Flights (CS) metaheuristic
algorithm . This algorithm was inspired by the breeding strategy of certain cuckoo species, as they tend
to lay their eggs in nests belonging to birds of other species or host birds. Often, these cuckoos choose a nest
that contains recently laid eggs. A host bird could react to the realization of a foreign egg in their nest in two
ways – they may get rid of the alien egg by throwing it away, or they may abandon the entire nest and
Survey of NIM for 1D-BPP
rebuild elsewhere. Some cuckoos have evolved such that the female parasite cuckoos can mimic the colours
and patterns of the eggs of the host birds, thereby reducing the probability of their eggs being abandoned.
This technique leads to an increase in reproductivity . These cuckoo eggs tend to hatch before the other
eggs present in the nest. The ﬁrst instinct of the chick is to evict the host eggs by blindly propelling these
eggs out of the nest. This action leads to an increased portion of food provided by the host bird to the cuckoo
chick. The Lévy Flights mechanism replaces the simple random walk to improve the performance of the
algorithm . This mechanism ﬂight is described as a “random walk in which the step-lengths are
calculated with a heavy-tailed probability distribution” .
The advantages of this algorithm include that it uses far fewer parameters than most metaheuristics;
therefore, not much tuning is required, it is straightforward to implement, and it is easily hybridized with
other algorithms. A signiﬁcant disadvantage is that fast convergence cannot be guaranteed because it is
dependent on random walks . Zendaoui and Layeb used these strengths to aid their attempt to
adapt the CS algorithm to solve the 1D BPP by introducing an interesting mechanism, Ranked Order Value
(ROV), in order to convert the results of the original algorithm from a continuous space to a discrete space.
2.2.3 Whale optimization algorithm (WOA)
The WOA was developed in 2016 by Mirjalili and Lewis . This algorithm is a swarm intelligence-based
metaheuristic, and it imitates the hunting strategy of humpback whales. These whales are known for their
ability to use an uncommon hunting strategy, also called the “bubble net” strategy. This is where the whales
cleverly cooperate to trap their prey, ﬁsh, into a ring of air. The whales accomplish this by emitting a stream
of bubbles. These bubbles take two diﬀerent shapes: the ﬁrst is a spiral, and the second is a shrinking circle.
After trapping their prey in these bubbles, the ﬁsh are swallowed by the humpback whales. In the algorithm,
the exploration phase is represented by the hunt for prey, while the hunting strategy utilizing the shrinking
and spiral shapes represents the exploitation phase. The positions of the prey are randomly initialized – this
represents the initial population, which is evaluated to ﬁnd the current best solution.
The advantages of this algorithm include the simplicity of implementation and low computational cost.
On the other hand, the disadvantage is that the algorithm sometimes results in stagnation in local optima,
and that the exploitation phase would be more beneﬁcial if it were improved . Abdel-Basset et al. 
utilized these strengths in their adaptation of WOA to solve the 1D BPP, called the Improved Lévy-based
Whale Optimization Algorithm (ILWOA), developed to solve the BPP. This was accomplished by integrating
various mechanisms including the Largest Order Value (LOV) technique (in order to convert the continuous
results to discrete ones) Lévy Flights, and Chaotic maps to overcome the weaknesses of the original WOA.
2.2.4 Squirrel search algorithm
The Squirrel search nature-inspired optimization algorithm (SSA) was developed in 2018 by Jain et al. .
This algorithm mimics the behaviour of ﬂying squirrels and their eﬃcient movement. The ﬂying squirrels do
not ﬂy, but rather they use a special technique known as gliding. This technique is considered highly
eﬃcient because it is energetically cheap and enables small animals to cover great distances quickly .
There are three primary assumptions in the SSA . First, there is a certain number of ﬂying squirrels in the
forest. Second, each of these squirrels forages for food and utilizes the available food resources dynamically. Finally, there are three types of trees in the aforementioned forest – normal, acorn, and hickory trees.
An advantage of this algorithm is that there is an eﬃcient search space exploration. The disadvantages,
on the other hand, is that it suﬀers from premature convergence and that it is possible, when solving
complex problems, that the algorithm will get trapped in a local optimum . El-Ashmawi and Abd
Elminaam modiﬁed the SSA to solve the 1D BPP with these weaknesses in mind, aiming to improve
on them. The modiﬁed algorithm incorporated randomization in the initial population and tweaks to the
operating strategies to enhance the new generations during exploration.
Chanaleä Munien and Absalom E. Ezugwu
The GA was initially proposed by Holland and has been applied to a vast range of optimization problems.
This algorithm mimics the natural selection process of evolution, based on the teachings of Charles Darwin
 . In GA, solutions are modelled as chromosomes, which can take many diﬀerent forms – for example,
binary strings or real number vectors. A population consists of multiple chromosomes. A ﬁtness function
must be deﬁned so these chromosomes can be decoded and evaluated, and a ﬁtness value can be assigned to
this chromosome. This value is an indication of the strength of that individual in the current population and
dictates the probability of being selected for the creation of the next population. The newer populations are
generated by performing techniques on the chromosomes such as mutation and crossover. Stronger, or more
ﬁt, chromosomes are more likely to be chosen to be carried into the new population after the genetic
operators have been applied, so that the new populations contain better quality solutions.
The advantages of this algorithm include that it has been developed to deal well with complex problems
and parallelism, and it is easy to understand and implement. However, naturally, there are disadvantages to
this metaheuristic – this includes the diﬃculty in formulating the correct ﬁtness function for the given
problem, determining the best population size and parameters such as the crossover and mutation rate,
which governs how often the operators must occur during the iterations of the algorithm. An inappropriate
selection of these parameters and functions may cause the GA to produce results that do not have meaning,
or it may be increasingly diﬃcult for the GA to converge . Quiroz et al. used the GA as a foundation for
their grouping GA, adding grouping mechanisms and a fascinating selection mechanism to solve the BPP.
3 Optimization methods
3.1 Adapting metaheuristics for the 1D BPP
Figure 1 illustrates a general overview of metaheuristic algorithms that are used to solve the 1D BPP. The
algorithm begins by deﬁning parameters, such as population size and any other values that must be
speciﬁed to ensure the algorithm functions as intended. Next, the initial population is generated. This
step is important, and the method chosen to do this impacts the eﬃciency of the algorithm greatly. Next, the
solutions go through the “ﬁt and evaluate” phase. This refers to using approximate algorithms (discussed in
Section 2) to pack the items into bins. This packing is then evaluated by the objective function so that the
solution is assigned a ﬁtness value that will determine it’s position in the population. This phase additionally helps to determine the best solution in the population. This best solution is then stored in memory. The
algorithm will then perform the speciﬁc local and global walks so that the population is improved by adding
solutions with more favourable ﬁtness values and generally discarding of unfavourable or weak solutions.
The “ﬁt and evaluate” phase must be repeated at this stage so that the best solution can be checked against,
and if a better solution than the current best is found, then this solution replaces the best solution in
memory and becomes the current best. Some algorithms may require an update to parameters, but this is
not always the case; therefore, this is optional. Thereafter, the termination criterion is checked. Usually,
termination criterion refers to the number of iterations (generations of population) the algorithm has gone
through. However, the criterion may also be to check if the current best solution is an optimal solution. It is
possible that either one or both of these conditions are checked at this point in the algorithm. If the criterion
has been met, then the algorithm may end and produce the ﬁnal solution. However, if the criterion has not
been met, the algorithm returns to update the population using exploration and exploitation mechanisms,
so that a better solution may be found, and the cycle continues.
Survey of NIM for 1D-BPP
3.2 Adapted metaheuristics for the 1D BPP
All equations have been taken directly from the surveyed papers, and all ﬁgures and algorithms have been
adapted from these papers.
3.2.1 Objective function
If this function is set to be just the number of bins, the algorithm may eventually experience stagnation .
This is due to several possible solutions having the same number of bins, yet diﬀerent representations, and
therefore, various amounts of unused space. In order to avoid such stagnation and move towards ﬁnding
the optimal solutions, the objective function should consider the amount of unused space, as well as the
number of bins for a speciﬁc representation. Hence, the following functions are used:
which essentially entails giving more value to the solution using the least bins and having the least amount
of unused space. So, fillk is the capacity of bin k (it is the sum of the sizes (Si) of all items in the bin), N
represents the number of bins in the solution, C represents the ﬁxed bin capacity, and z represents a
constant that is used to deﬁne the equilibrium of the ﬁlled bin (generally kept at
Figure 1: A generalized metaheuristic algorithms ﬂowchart for the 1D BPP.
Chanaleä Munien and Absalom E. Ezugwu
3.3 Adaptive ﬁtness-dependent optimizer (AFDO)
In 2020, Abdul-Minaam et al. adapted the FDO algorithm to solve discrete optimization problems and
tested it on the BPP, and this was named AFDO. This algorithm aims to improve the solution quality for the
BPP. For the adaptation, the authors suggested using a random initial population and added an update to
the algorithm procedure. In this algorithm , an artiﬁcial bee scout represents a candidate solution to the
BPP. Each solution is a vector of n dimensions where one dimension represents the index of an item, and
another represents the index of the bin that the corresponding item is assigned to. Abdul-Minaam et al. 
found this representation to aid in minimizing the number of bins used while allowing multiple items to be
packed in one bin without exceeding the maximum bin capacity constraint. This can be seen in Figure 2.
Figure 2(a) represents the list of items with their indexes and corresponding weights.
Since the initial population inﬂuences the execution time and quality of the result , the authors
modiﬁed the FF heuristic such that the algorithm takes in a shuﬄed list of items and randomly assigns the
items to the ﬁrst available bin. This allows for the generation of diverse, feasible solutions in the initial
population. Figure 2(b) and (c) represents possible solutions using the modiﬁed FF heuristic.
An additional variable to be considered in this algorithm is the weight factor, wf, that is either set to 0
(neglect the factor) or 1 (lowers the possibility of coverage and increases the level of convergence). This
weight controls the stability of the search and dramatically inﬂuences the movement of the bees towards
the next position. Therefore, it is a parameter that requires testing. The ﬁtness weight is directly impacted by
the weight factor, as shown in equation (1), where (
represents the global best solution’s ﬁtness value
represents the current solution’s ﬁtness value.
The new position of a scout bee relies on the movement rate, pace, and direction. Only a positive
direction is considered in the AFDO algorithm. The pace is computed by considering the current solution
(Xi t, ), a random number, r, generated with uniform distribution (rate), and the ﬁtness weight (the last two
are critical parameters that improve the exploration of the search space), as can be shown in equation (2):
The cases in this equation represent the inﬂuences on the movement direction. In the ﬁrst case, a random
sequence of raw vectors is generated from the current solution, based on the number of bins and items in
the speciﬁc problem instance. As can be shown in Figure 3, the ﬁnal solution of the ﬁrst case is raw vectors,
of the form ⟨
item old bin new bin
. The random number, r, is set to 0.2 and represents the probability
that a task (assignment of an item to a bin) is selected for an update in the aforementioned vector. If a task is
Figure 2: An example of solutions in the population illustrated in ﬁgure (a)–(c).
Survey of NIM for 1D-BPP
selected, a new bin is randomly chosen for the item to be assigned to. This modiﬁcation to the FDO
algorithm provides the possibility of obtaining multiple solutions through the use of randomization. The
number of items, I, is 10.
Therefore,
2, so two raw vectors are produced.
In the second case, the result of the ⊖operator is computed by taking the diﬀerence between the current
solution and the global best solution thus far. This is given in terms of raw vectors, as shown in Figure 4.
The form of the vectors is the same as mentioned previously. If an item is assigned to the same bin in both
solutions, then no change is made. If an item is in two diﬀerent bins in the solutions, then the raw vector is
added to the set. The ⊗operator represents the chance of fw choosing each generated raw vector. Since
0.3, three of the raw vectors are randomly chosen in the ﬁnal output.
After that, the solution’s pace is calculated as in equation (3), and the new solution is introduced, as
shown in Figure 5.
It is worth noting that the reassignment of an item to a bin will only occur if the suggested reassignment
does not cause the bin to overﬂow (in other words, exceed capacity). This is the reason that the ﬁrst and
third raw vectors in the pace in Figure 5 do not aﬀect the resulting solution.
The algorithm continues until a predeﬁned number of iterations is reached or the most optimal solution
Figure 3: An example of using
Figure 4: An example of using (
Chanaleä Munien and Absalom E. Ezugwu
The pseudocode for this algorithm can be seen in Algorithm 1.
Algorithm 1: Pseudocode of adaptive ﬁtness dependent optimizer
initialize: number of items (I), bin capacity (C), number of iterations (tmax), population size (pmax);
generate initial population by using a modiﬁed FF heuristic:
Shuﬄe the list of items;
while list is not empty do
Select an item from the list;
Assign the item to the first available bin;
If the item cannot fit in any available bin, open a new bin;
Update the remaining capacity of the bin that the item was added to
remove the size of the item from the bin’s current capacity ;
improve solutions
evaluate the artificial bee scout
movement of the artificial bee scout
For each bee scout,
in the population,
Evaluate according to objective function;
is set the bee scout with the lowest fitness value;
to the current number of bins in the best solution. ;
For each bee scout,
in the population,
is the optimal number of bins, stop.
Figure 5: An example of updating a solution with pace.
Survey of NIM for 1D-BPP
3.4 Adaptive cuckoo search (ACS) algorithm
The CS algorithm follows three cardinal rules: First, each cuckoo must lay one egg at a time and randomly
chose a nest to dump this egg in. Second, the nests that contain eggs of the highest quality will proceed to
the next generation. Third, there is a ﬁxed number of available hosts, and the host bird discovers the cuckoo
egg with a probability, pa, between 0 and 1 . Additionally, this probability governs the balance between
the local and global explorative walks.
In 2016, Zendaoui and Layeb adapted the cuckoo search algorithm to solve the 1D BPP problem
(ACS). Since the original CS algorithm was designed to solve continuous optimization problems, it could not
directly be applied to solve the discrete BPP. Therefore, the authors proposed utilizing a method that linked
the continuous output of the algorithm to integer representations that correspond to the index of the items
in a given list. The ROV method was employed for this reason – it guarantees the feasibility of new solutions
and avoids creating any additional overhead. This can be shown in Figure 6.
For the representation of solutions in ACS , the authors assume that only one egg is laid in one nest,
and each nest contains a single egg. The egg in this nest is a candidate solution represented by an item
permutation, determined by the ROV. The FF method was used to assign the items to the bins and evaluate
the ﬁtness of a solution. Two essential movements are used to generate new solutions in the ACS. Firstly, a
local random move which can be seen in equation (4). This move is used for exploitation and produces a
new solution by utilizing two randomly selected solutions (xj
t), a Heaviside function, a random
number, ε, drawn from uniform distribution, and s which represents the step size. An example is provided
in Figure 7.
Second, a global random move via Lévy Flights is used for exploration. This is shown in equations (5)
and (6). A scaling factor, α, related to the scale of the problem to be solved must be set. Once the result of the
Lévy Flight is calculated, it is added to the continuous version of the item permutation, and the solution is
ranked once again with ROV, and then evaluated by the objective function. An example is provided in
Figure 6: An example of employing ROV on a continuous solution.
Figure 7: An example of employing the local walk on a current solution.
Figure 8: An example of employing the global walk on a current solution.
Chanaleä Munien and Absalom E. Ezugwu
A fraction, equal to pa (the switching parameter that is predeﬁned), of nests with unacceptable ﬁtness
values are abandoned. In other words, these solutions are replaced with new solutions generated using the
local walk movement. The algorithm tracks the best solution and only replaces this position if a solution
with a lower ﬁtness value is found (since the aim is minimization).
This algorithm continues until the number of iterations has reached a predeﬁned number or if an
optimal solution is found.
The pseudocode for this algorithm can be seen in Algorithm 2.
Algorithm 2: Pseudocode of adaptive cuckoo search algorithm
initialize: number of host nests (n), maximum number of iterations (t), probability of host bird discovering a nest (pa);
Generate the initial population of n host nests, xi where
Generate a new solution by using Lévy Flights;
Use ROV to convert
into an item permutation;
Choose random solution from population;
A fraction of worse solutions are abandoned andnew solutions are generated using local walk
Convert these new solutions to item permutations with ROV;
Replace the new solutions by the item permutations;
Evaluate the fitness of the new solutions;
Rank the solutions according to fitness value to find the current best
solution and store current best;
Although the convergence rate and performance of the original WOA were good and obtained a highquality solution in a negligible time when applied to a continuous search space, Abdel-Basset et al. 
observed that WOA also performed well on combinatorial problems. This observation motivated the attempt
to adapt this algorithm to solve the BPP. Therefore, in 2018, the ILWOA was developed. Three enhancements were made in this algorithm. The deployment of Lévy ﬂights for whale movements improved the
exploration capabilities of WOA, the original algorithm was embedded with a mutation phase in order to
enhance convergence speed, and a logistic chaotic map was utilized to swap between exploitation and
exploration phases eﬃciently.
Survey of NIM for 1D-BPP
Since it was necessary to discretize the search space, the authors used the LOV technique. As shown in
Figure 9, this technique ﬁrst ranks the descending order of continuous values,
, , where 1
to n represents the dimensions of the solution. This results in a sequence,
, . To decode
the solution, the formula used is
, where k represents the corresponding dimension .
The BF heuristic was employed for packing bins with the assigned items. The representation used in
this study was simply a list of items. The Lévy distribution has an inﬁnite mean and inﬁnite variance. This
causes a longer movement from the solution’s current position to the new position, which is much more
eﬃcient for the exploration phase.
For improved diversiﬁcation of the given search space, the WOA combines a couple of exploration
search mechanisms. This is carried through and slightly modiﬁed in the ILWOA. The probability of these
search mechanisms being employed on a candidate solution depends on a switching parameter.
Chaotic maps can be described as: “evolutionary functions that produce a deterministic bounded
sequence of random numbers depending on initial condition” . The authors decided to use logistic
chaotic maps to determine the switching parameter value due to the random-like parameter adaptation
 ; this value is known as p. The value of a coeﬃcient vector from the original WOA, →
C , is replaced by a
random step that is drawn from Lévy distribution (equation (6)). A random variable, r, and p dictate how
the solutions are updated. →
A is calculated as in equation (7). This coeﬃcient vector includes →
represents the shrinking feature of the spiral and decreases from 2 to 0, and →r which represents a random
number between 0 and 1.
The use of two exploration mechanisms introduces improved diversiﬁcation of the search space.
Therefore, the value of →
A inﬂuences whether the best solution or a randomly selected solution will aﬀect
the positions of solutions in the search space. This is explained below.
1, then the update is calculated using equation (8) and the solution is generated using
equation (9). In these equations, the current best solution and the current solution are represented by →( )
x t , respectively.
→= ∣→⋅→( ) −→( )∣
→( + ) = →( ) −→⋅→
However, if
1, then the update is calculated by equation (10), where →( )
is a random
solution chosen from the current population, and the updated solution is generated by equation (11).
→= ∣→⋅→( ) −→( )∣
→( + ) = →( ) −→⋅→
p, then the update is calculated by equation (12) and the position is updated spirally by equation (13).
These equations simulate the whales’ movements around the prey, speciﬁcally, the best solution found thus
far. In equation (13), b is a pre-speciﬁed constant that deﬁnes the shape of the spiral and l is a randomly
selected number in the range [−
→= ∣→( ) −→( )∣
Figure 9: An example of LOV.
Chanaleä Munien and Absalom E. Ezugwu
The additional mutation phase occurs before and after each iteration. In this phase, the current best
number of bins is tested for optimality. If the test is successful, the search stops. However, if the test fails,
the solution is randomly modiﬁed by three operators, namely, swap, displacement, and reversion. The swap
operator randomly chooses and swaps two indexes in the solution. The displacement operator randomly
chooses a subset of items and inserts it into another place in the solution. Finally, the reversion operator
randomly selects a subset of the solution and reverses the order of the items within that subset. These
mechanisms further improve the exploration capabilities of the algorithm. Figure 10 illustrates these
operators. This occurs until the maximum number of iterations has been reached.
The pseudocode for this algorithm can be seen in Algorithm 3.
Algorithm 3: Pseudocode of improved Lévy-based whale optimization algorithm
Generate the initial population;
Use LOV to map continuous population to combinatorial population;
Evaluate population;
x to the current best solution;
perm to the current best permutation;
nbin to the current best number of bins;
while termination criteria has not been met do
→= ∣→⋅→( ) −→( )∣
→( + ) = →( ) −→⋅→
→= ∣→⋅→( ) −→( )∣
→( + ) = →( ) −→⋅→
→= ∣→( ) −→( )∣
For each whale position
with Lévy distribution, and
with logistic map;
Update position with:
Randomly select a position,
Update position with :
Update position with :
Adjust position inside search space boundaries;
Use LOV to map the new solution;
Evaluate new combinatorial solution,
Apply mutation for
Evaluate new permutations;
Survey of NIM for 1D-BPP
3.6 Modiﬁed squirrel search algorithm
In 2019, El-Ashmawi and Abd Elminaam modiﬁed the SSA algorithm in order to apply it to the BPP. This
version of the algorithm generates random but feasible initial solutions. Additionally, various operating strategies are employed to update the locations of the squirrels. This aids in generating new populations during the
exploration phase of the algorithm. The feasible initialization step ensures that the initial population’s randomness explores the solution space in an eﬃcient manner. This was accomplished by improving the BF heuristic –
randomly assigning items from the given list of items to the BF bin (such that total waste is minimized).
The evaluation of the population depends on the values of the ﬁtness function, as is with most
metaheuristics. The population must be sorted according to the ascending order of ﬁtness value. The
best squirrel (the one with the lowest ﬁtness value) is assigned to the hickory tree. Being on this tree
indicates that this particular squirrel is at the optimal food source. In other words, it is a current best
solution. The next three squirrels with relatively low ﬁtness values are assigned to the acorn tree. This
implies that those squirrels are at the normal food source. In other words, these solutions are near-currentbest. Finally, the rest of the squirrels are assigned to the normal tree. This means that these squirrels have
no food source – implying that these solutions are quite far from the current best .
Individual solutions are updated according to the tree that they are assigned to. If a solution is on an
acorn tree, it moves towards the hickory tree, and if it is on a normal tree, it can be moved towards either the
acorn or the hickory tree. The probabilities of these updates are controlled by a random number (
drawn from a uniform distribution, between 0 and 1, and a constant, Pdp. This constant is known as the
“probability of a predator” and it is set beforehand. If the random number is not greater than the speciﬁed
constant, the squirrel’s position is randomly updated – this procedure achieves good exploration of the
search space. These updates are shown in equations (14), (15), and (16). The α β
, , and γ values are random
numbers between 0 and 1. These values denote the gliding distance of each squirrel.
The ⊖operator calculates the diﬀerence between the two solutions and results in a set of swap operators
– diﬀerence means to look at each item–bin entry in the solutions and, if the two solutions have the same
item in the same bin, no swap operator is created, but if the two solutions have the same item in diﬀerent
bins, a swap operator of the form⟨
item number bin number
is added to the set. An example of this can
be seen in Figure 4.
The ⊗operator computes the probability that the swap operators in the set are selected and applied in
the update (the probability is given by α β
, and γ). Based on the result (a number) of this operation, random
solutions are selected from the set. This can also be seen in Figure 4; however, the example uses fw in place
of the random values in this algorithm.
The ⊕operator updates the solution. In other words, it changes the location of the squirrel. This is done by
replacing the item–bin pairs in the chosen solution with the selected swap operators. An example of this is shown
inFigure5;however,insteadofa“setofswapoperators,”“pace”isused.Thesefunctionsareessentiallythesame.
random location otherwise
random location otherwise
random location otherwise
Figure 10: Illustration of mutation operators.
Chanaleä Munien and Absalom E. Ezugwu
If the random number (
1, 2, 3 is less than Pdp, this indicates that a squirrel was not able to reach a
source of food, but survives regardless and moves to a location that is randomly generated. This is done by
generating swap operators randomly and applying the ⊕operator to the solution. This is shown in equation
(17). Oi represents the swap operators, and
where m is the number of swap operators generated.
These random walks introduce improved exploration in the space.
The stopping criterion is based on the number of iterations reached compared to a pre-speciﬁed maximum
number or until the optimal value has been found.
The pseudocode for this algorithm can be seen in Algorithm 4.
Algorithm 4: Pseudocode of modiﬁed squirrel search algorithm
Initialize the population, FS with n individuals and the dimension of the problem, m;
Set tmax to the maximum number of iterations;
according to the equation:
where Si is the size of each item and C is the
ﬁxed bin capacity;
Generate FSi j
, using the improved BF heuristic;
Evaluate the fitness,
according to objective function;
Sort the locations of
in ascending order of fitness value;
to the best global solution
this squirrel is located
on the hickory tree;
to the next three best global solutions these squirrel are located on the acorn tree;
to the remaining solutions these squirrels are located on the normal tree;
to a random subset from
that moves towards the hickory tree;
to the current best solution s number of bins;
with equation 14 ;
Random location using equation 17
with equation 15 ;
Random location using equation 17
with equation 16 ;
Random location using equation 17
then stop;
Return the best solution
Survey of NIM for 1D-BPP
3.7 Grouping genetic algorithm with controlled gene transmission (GGA-CGT)
In 2015, Quiroz et al. published the GGA-CGT to solve the 1D BPP. The authors propose transmitting the
best genes in a chromosome while maintaining the balance between diversity and selective pressure in the
current population.
The algorithm consists of the following features: a novel technique for generating a high-quality initial
population, grouping operators that aid in exploiting the search space of the problem, a rearrangement
operator that aids in exploring the search space, and the balance of the evolution is ensured by the use of a
novel reproduction technique that is capable of preventing premature convergence and governing the
exploration phase.
The initial population is generated with a modiﬁed FF heuristic. Until a predeﬁned number of iterations
is reached or the optimal solution is found, the individuals in the population are recombined and mutated
in a couple of phases. First, some individuals are selected with “controlled selection,” and the gene-level
crossover and FF decreasing heuristic are employed on the selected individuals. Afterwards, “controlled
replacement” is utilized to introduce the oﬀspring. The second phase considers a predeﬁned “lifespan” of
individuals – according to this lifespan, elite individuals with superior ﬁtness values are cloned, and
several individuals are chosen to apply genetic alterations to. These alterations are accomplished with
the use of “adaptive mutation” and “RP” (Rearrangement of Pairs). As in the ﬁrst phase, controlled
replacement is applied to individuals in the second phase, before they are added to the new population.
Algorithm 5 shows the pseudocode for this algorithm.
Algorithm 5: Pseudocode of grouping genetic algorithm with controlled gene transmission
Generate initial population, P, with proposed modiﬁed FF heuristic (FF-n˜);
while generation < max-generation and solution is not optimal
gene level crossover and first fit decreasing heuristic
controlled replacement
controlled selection
adaptive mutation and rearrangement by pairs
controlled replacement
individuals to crossover using controlled selection;
selected individuals;
to introduce offspring;
individuals and clone elite solutions using
to the best
individuals;
to introduce clones;
Update the global best solution;
GGA-CGT uses a group-based encoding scheme – so, there could be various lengths of chromosomes
based on the number of bins used in the speciﬁc solution. Therefore, every gene in a chromosome is a
“group” of items. Each group is packed into a single bin.
The authors introduced a rather interesting method of generating an initial population from a set N of n
items by ﬁrst ﬁnding a subset, N˜ , of n˜ items that have weights greater than half of the ﬁxed bin capacity.
This subset represents items that cannot be packed into a bin with items of the same subset, as this would
cause a bin to overﬂow. The items of N˜ are packed ﬁrst into diﬀerent bins, and then the remaining items of
N (that are not part of N˜ ) are randomly packed into the bins using the FF heuristic.
The grouping crossover operator called the gene-level crossover can be described as follows: A novel
crossover for group-based representation was introduced, whereby the two selected parent solutions are
compared on a gene-level. Two children are produced, as both of the selected solutions are given the
opportunity to be the “ﬁrst father.” First, the operator looks at the bins in each solution according to the
descending order of how full each bin is. This is done so that the oﬀspring have a better chance of inheriting
Chanaleä Munien and Absalom E. Ezugwu
the best bins in the parent solutions. To create the oﬀspring, for every pair of bins, the bin that is more ﬁlled
is inherited ﬁrst. The bins are compared in parallel – so, the ﬁrst bin of the ﬁrst father and the ﬁrst bin of the
second father are considered a pair. After that, the other bin in the pair is inherited. This continues until all
the bins in both parent solutions have been added. In the event of a pair of bins being equally ﬁlled (have
the same amount of available space), the ﬁrst father’s bin is inherited ﬁrst. It can be observed that this
method would result in a duplication of items since every bin from both solutions is added to the child
solution. Therefore, if a bin contains an item that already exists in the solution (i.e., the item can be found in
a previous bin), then the bin containing the duplicate item is eliminated from the child solution. This
elimination may cause the child solution to be invalid since it would not contain all the items from the
problem instance. The method resolves this issue by determining the missing items and placing these items
into the existing bins by using the FF decreasing heuristic. This can be seen in Figure 11.
The grouping mutator operator permits introducing random changes into the population, resulting in
more diversity in the solutions, so there is more exploration of the search space. The proposed mutator
operator promotes transmitting the “best genes” in a chromosome and is applied at the gene level to avoid
the loss of high-quality genes (which are essentially well-ﬁlled bins). This operator eliminates the bins that
have the most available space (are not well-ﬁlled) and reinserts the items from the eliminated bins into the
solution with the help of a rearrangement technique that is discussed later. The operation is called adaptive
because the number of bins that will be eliminated in a solution, nb, is determined by equation (18)
considering: the solution size (m) and how many bins in the solution and not completely ﬁlled ( )
elimination proportion ( )
ε as calculated in equation (19), and the probability of elimination ( )
Pε as calculated in equation (20).
Uniform 0,
where k deﬁnes the rate of change of the elimination proportion, ε, and probability, Pε, concerning the
number of incomplete bins, τ.
The rearrangement heuristic, called “rearrangement by pairs,” or RP, is a technique that must be
implemented in two steps. First, every bin is reviewed to determine the possibility of improving its packing
schema by swapping pairs of already-packed and free items (free items are also known as “missing items”
which are items that need to be placed in a bin but are not present in the solution being repaired). Second,
the remaining items are inserted into the solution through the FF heuristic. This technique has a signiﬁcant
impact on the exploration and exploitation of the search space. Algorithm 7 explains the rearrangement by
pairs procedure. ′
S denotes the result of swapping the items s and p from the bin Bj with an item i from F.
is true if the swap that has occurred results in a bin with a capacity that does not exceed the
ﬁxed maximum capacity, otherwise it is false. Both the items from S and F are considered in pairs. There are
two possibilities for the two pairs of items, as shown in the IF-statements in the algorithm. These statements
say two things: (1) if it can be done, replace the pair of items p and s from the bin with one of the free items
from the pair that have a weight greater than or equal to the sum of the weight of p and s, as long as the
replacement does not cause the bin to overﬂow; (2) if replacing the pair of items from the bin (p and s) with
the free items (i and k) results in the free items ﬁlling the bin equal to or better than the items from the bin,
swap the items p and s with i and k. Then, apply the FF heuristic to reinsert the items in F to make the
solution valid.
Figure 12 shows an example of the adaptive mutator with the rearrangement heuristic.
Survey of NIM for 1D-BPP
Figure 11: An example of the gene-level crossover operator. (a) An example of the list of items in a BPP instance. (b) An example
of a ﬁrst father. (c) An example of a second father. (d) The result of the oﬀspring from the ﬁrst and second father in the
examples. (e) Partial solution after removing duplicates. (f) The completed child solution. Source: .
Chanaleä Munien and Absalom E. Ezugwu
Algorithm 6: Pseudocode of RP (Rearrangement by Pairs)
) – S is the solution to be rearranged and F is the set of free items
Randomly sort the bins of S to obtain a sequence of b bins:
Randomly sort the items of F;
w and Feasible S
w and Feasible S
w and Feasible S
1; go back to while statement;
1; go back to while statement;
1; go back to while statement;
Apply FF to reinsert the items in F to S;
The authors additionally propose a “controlled selection” mechanism that balances the population
diversity and selective pressure. Population diversity permits exploring new areas of the search space,
which positively impacts solution quality and helps avoid premature convergence. The selective pressure
awards ﬁtter individuals in the population with a better chance of being chosen for mutation, reproduction,
and survival. If these attributes are missing from the algorithm, the search process will not be guided but
instead be random, which will result in promising regions of the search space being overlooked. Therefore,
balancing these features greatly improves the GGA-CGT’s performance. Every individual is given the
opportunity to contribute to the succeeding generation of the population; however, the proposed selection
scheme ensures that the best individuals survive.
The controlled selection for crossover is as follows: for nc parents to generate nc children, create two
sets of individuals, G and R, that will serve as parents. B is known as the elite group, which consists of the
best solutions. The ﬁrst set, G, which stands for “good,” contains
solutions randomly chosen from the
best nc solutions in the current population. In contrast, the second set, R, which stands for “random,” also
solutions randomly selected but from the set: population minus B. The random selections are
made with uniform probability. Moreover, because this crossover occurs pairwise between the two sets
(hence, Gi is crossed with Ri, where
c ), the manner in which the sets are chosen avoids a solution
being crossed with itself.
The controlled selection for mutation is as follows: a ﬁxed number of solutions, nm, will be mutated. The
operator is applied to nm of the best solutions in the population. In this case, lifespan plays a role in
determining if cloning occurs. If a chosen solution exists within a speciﬁc lifespan, then it is cloned.
After this, solutions are selected from the population to mutate, according to decreasing ﬁtness values.
The replacement strategy dictates which solutions are eliminated and replaced by the new progeny. The
authors aim to promote exploration by always permitting new solutions to be added. There are two types of
controlled replacement: one for crossover and one for mutation. In the controlled replacement for crossover, the ﬁrst
children generated from the crossover operator replace their parent from the random set,
R (their second father). The remaining children replace solutions from a subset of the population that does
not include the set of best (B) and random (R) solutions. In this latter case, the children either replace
Survey of NIM for 1D-BPP
solutions from the described subset of the population with duplicate ﬁtness (if they exist) or worst solutions. In the controlled replacement for mutation, the cloned solutions either replace solutions with duplicate ﬁtness (if they exist), or the worst solution in the current population.
4 Comparison of results
Since every algorithm described in this article used diﬀerent instances of datasets, and were tested on
hardware with varying hardware speciﬁcations, it would not be possible to conduct a valid comparison of
the metaheuristics with each other. However, the researchers have provided results and compared their
proposed algorithms with various other popular algorithms; therefore, this will be analysed in this section.
The benchmark datasets used in all of the reviewed papers were made available by Scholl et al. and
are divided into easy, medium, and hard classes. These classes have various numbers of items, weights, and
maximum bin capacities. For the easy class, there are 720 instances, and the number of items in each
instance can either be 50, 100, 200, or 500. The bin capacities are 100, 120, or 150. In the medium class,
there are 480 instances, and the number of items in each instance is the same as the easy class; however,
the maximum bin capacity for each instance is 1,000. Finally, for the hard class, there are ten instances, and
there are 200 items in each instance, and the capacity is 100,000. These sets have been used to test several
Figure 12: An example of the adaptive mutator with RP operator. (a) An example of the list of items in a BPP instance. (b) An
example of an individual in the population with bin capacity of 10. (c) Partial solution after elimination of two bins. (d) The
completed child solution. Source: .
Chanaleä Munien and Absalom E. Ezugwu
algorithms, and it provides a way to compare algorithms based on their success in solving these instances.
For the following results, each researcher selected particular instances of these classes to demonstrate the
successes of their algorithms. However, these instances do not necessarily overlap between papers.
The AFDO algorithm was tested on three classes of diverse diﬃculty, and the results were compared
to three other well-known metaheuristics – namely, the PSO, Jaya, and Crow Search (CS) algorithms. In the
easy and medium classes, the AFDO was able to display high eﬃciency in solving the 1D BPP in terms of the
average ﬁtness values. Out of 15 instances of the easy class, the AFDO successfully found all optimal values,
whereas the other three algorithms found between 7 and 9 optimal values. Similarly, for the medium class,
out of ten instances, all ten optimal values were found by the AFDO, whereas the other three algorithms
found ﬁve or six optimal values. However, in the most challenging class (hard), the algorithm did not reach
the optimal number of bins, but it was noted that a better item packing schema was achieved, yielding a
lower number of bins compared to the other algorithms. Hence, AFDO proved to eﬀectively explore the
search space to locate an optimal or near-optimal solution within a reasonable time.
The ACS algorithm was tested on the described dataset. The results were compared to the FF
Decreasing heuristic, the Ant System algorithm, Fireﬂy and Ant Colony algorithm, and the Quantum Cuckoo
Search algorithm. For the easy class, the ACS produced results identical to the other four algorithms in the
chosen instances – these were all optimal values. For the medium class, ACS outperformed other algorithms
in all chosen instances – either achieving optimal or near-optimal results. Finally, for the hard class, the
ACS successfully achieved better near-optimal results and outperformed the other four algorithms. Moreover, the ACS algorithm has fewer parameters to tune, and as a result, it is easier to implement.
The ILWOA was tested against the ACS algorithm, quantum-inspired cuckoo search, ﬁreﬂy algorithm, ﬁreﬂy colony optimization, and ant system algorithm. For the selected instances in the easy class, the
ILWOA performs just like other algorithms and ﬁnds the best-known number of bins. For the instances of
the medium and hard classes, however, the results obtained using ILWOA were not always optimal but
were superior in many cases. The authors also noted that the overall results of the ACS and ILWOA on this
standard benchmark dataset were very similar. However, ILWOA was able to return reasonable solutions
with fewer iterations and search agents.
The modiﬁed squirrel BPP (MSBPP) algorithm was tested against popular metaheuristic algorithms
such as PSO, African Buﬀalo Optimization, and Crow Search Algorithm (CRSA) to solve the BPP. The
authors chose speciﬁc instances of the benchmark datasets from the easy, medium, and hard classes.
For all of these easy class instances, the MSBPP algorithm was able to reach optimal values, whereas
PSO and CRSA failed to reach optimal values for even half of the selected tests. For the medium class,
the MSBPP successfully reached optimal values for 11 of the 12 instances, whereas PSO performed exceptionally poor, reaching optimal values for merely 3 of the 12 instances. For the instances of the hard class,
the MSBPP performed well relative to other algorithms, achieving values much closer to the optimal number
For the GGA-CGT , the authors compared their algorithm to two state-of-the-art algorithms, namely,
Perturbation-SAWMBS (PSAWMBS) and the hybrid improvement heuristic for the 1D BPP (HI_BP). The
authors of GGA-CGT tested their algorithm on a range of BPP datasets but did not report in detail their
ﬁndings on the standard benchmark dataset described above. However, the report stated that optimal
results for all 720 instances of the easy class, 480 instances of the medium class, and 10 instances of the
hard class of the standard benchmark dataset described above were found, just as for the other two
algorithms. It was worth noting that the PSAWMBS was a much faster algorithm and obtained similar
results in the majority of the datasets that were tested. The most thought-provoking ﬁndings of this report
were that for the Hard28 dataset, GGA-CGT was able to ﬁnd optimal results for 16 of the 28 instances, while
the other two algorithms were only able to ﬁnd optimal results for 5 instances. This highlights the superiority of GGA-CGT as the Hard28 dataset is known to be one of the most challenging datasets known for the 1D
Finally, it is very important to highlight here that because the choice of parameter settings can signiﬁcantly aﬀect the quality of solutions generated by the individual metaheuristic optimization algorithms,
several experiments need to be performed in order to ﬁnd the best combination of parameters values that
Survey of NIM for 1D-BPP
would give the desired competitive results. Therefore, depending on the scale of the test problems for which
the algorithms are being evaluated upon, it is suggested that diﬀerent empirical and statistical analysis
options should be explored and adopted to ensure the eﬃcient selection of the parameter values. However,
this approach might be more appropriate for those class of metaheuristics with varying control parameters.
As for those variant of metaheuristics with little or no control parameter, such initial evaluation would not
be necessary. For example, metaheuristic optimization algorithms such as the symbiotic organisms search
algorithm and teaching-learning-based optimization are known to have few or no control
parameters beside the initialized population size, which is a default control parameter setting for all the
global metaheuristic algorithms.
5 Complexity analysis of metaheuristics
There are three challenging areas in algorithm analysis: complexity, convergence, and no-free-lunch theory
 . For the traditional algorithms, complexity analysis is well-established because the algorithms are
deterministic. However, for metaheuristic algorithms, complexity analysis remains a challenging task to
date, partly due to their nondeterministic or stochastic nature. In addition, no generic framework exists for
them. Although, in recent times, dynamic systems and Markov processes have been used to study complexity analysis of metaheuristics algorithms, convergence analysis still remains one of the active research
areas with many encouraging results .
Furthermore, there is a common belief among domain enthusiasts that metaheuristic algorithms tend
to be less complex for implementation. In many cases, the problem sizes are not directly linked with the
algorithm complexity . Although most metaheuristics can often solve immensely challenging NP-hard
combinatorial optimization problems, our understanding of their performance in terms of eﬃciency and
convergence lacks far behind. Moreover, because of the algorithms, diverse application and capability of
solving complex problems like the BPP, metaheuristics can be considered as an eﬃcient way to produce
acceptable solutions in a reasonably practical time. In addition, because metaheuristics are random searchbased techniques, the complexity of the problem of interest makes it impossible to search for every possible
solution or combination, speciﬁcally for large graph size BPPs. Therefore, in most cases, the aim is to ﬁnd
reasonable, feasible solutions in an acceptable timescale. Hence, the general pursuit and idea are to have
eﬃcient but practical algorithms that will work most of the time and produce reasonable quality solutions.
Finally, based on the notion of no-free-lunch theorem that Wolpert and Macready proposed in 1997
 , which states that given any two algorithms A and B, the algorithms will on average perform equally,
that is, if algorithm A performs better than algorithm B for some problems, then algorithm B will outperform
algorithm A for other problems . This implies that no single universally accepted superior algorithm can
solve all types of problems, including the BPPs. However, this does not mean that some algorithms would
not perform better than other algorithms for some speciﬁc kinds of problems. We do not need to measure
performance on average for all functions, but instead, we need to measure how an algorithm performs for a
given class of problems.
6 Recent application areas of BPP
The BPP is an interesting research domain that has over the years received recognition and more comprehensive coverage because of its relevance to industrial applications, especially in cutting (wood and glass
industries), packing (transportation and warehousing), and supply chain management (vehicle, container,
pallet or cargo loading, cutting stock and trim loss problems, packaging design, resource allocation, load
balancing, scheduling, project management, and ﬁnancial budgeting). Therefore, in this section, we present more recent and general application areas of the BPP, and we tried to classify articles that are
Chanaleä Munien and Absalom E. Ezugwu
 
 for older and more theoretical research coverage on the application areas of the BPP.
6.1 Scheduling and resource allocation
The application of BPP to the area scheduling and resource allocation basically deals with the problem of
allocating limited resources or tasks with/without time consideration. Researchers have proposed diﬀerent
approaches or variation of the BPP in this regard. For example, Ojeyinka applied the online and oﬄine
variants of the bin packing heuristics, implemented using the ﬁll function, on the passenger-bus scheduling
and the multiprocessor job scheduling problems. The goal of reducing the timespan needed for a multiprocessor to process all tasks using the BPP is exploited by Coﬀman et al. . The performance of some
scheduling algorithm was evaluated in ref. using the BPP where the operating room time corresponds to
the bin to be minimized. Leinberger et al. showed how multi-capacity bin packing can lead to a highly
sophisticated multi-resource allocation and scheduling. Furthermore, the scheduling of surgical operations
using the BPP was exploited by Van Houdenhoven et al. .
6.2 Production
The BPP has several practical applications in the supply chain sectors, which cut across diﬀerent manufacturing and service orientations. For instance, in manufacturing, the product to be manufactured can be
considered to be a task to be accomplished within a time frame in a production cycle; the plant used for
production is the bin to be allocated to the task (product), and ﬁnally, the goal of minimizing production
cost is achieved by minimizing the number of bins . Smart packing algorithm was designed by Khairuddin et al. using the GA to solve the 3D bin or container packing problem. The authors in ref. then
applied their proposed method to reduce packaging waste due to ineﬀective packaging in the manufacturing process. Two-dimensional packing algorithm was similarly used in ref. to solve the problem of
composite material production in autoclave moulding. The aspect of product delivery using mobile robotics
was exploited in ref. .
6.3 Health care community
The BPP is applied in this area to promote better cooperation between diﬀerent components within the
health care sector to provide an improved health care system. Surgical cases and resource scheduling using
BPP were exploited in refs. . The common goal here is to make optimal use of the operating rooms
by scheduling surgeries that can be combined to achieve high throughput in the system. Patient scheduling
for access to a practitioner was exploited in ref. , they used BPP for eﬀective and optimal scheduling of
patients to available practitioners. In the real sense, this problem is essentially a BPP with the modiﬁcation
that each bin might have a diﬀerent total size. Each doctor forms a bin whose capacity is equal to the
number of free hours in the doctor’s schedule, and each patient is an object to be placed into a bin, whose
size is equal to the number of hours for which she needs to be seen. The overall goal here is to ﬁnd the most
eﬃcient way to schedule patients across doctors, while upholding certain measure of fairness in terms of
workload across the doctors, and maximizing fairness while getting every patient seen by the prescribed
doctors on duty. However, this task would become even more complex and diﬃcult to solve when dealing
with a scenario where the doctors are specialists in diﬀerent subﬁelds and each patient needs to be seen by
a doctor with a certain set of skills under the diﬀerent subﬁelds depending on their medical practice.
Survey of NIM for 1D-BPP
Another interesting application of the BPP is in nurse scheduling, here a consideration of the capacity of the
nurses and the various needs of the patients using BPP are taken into account. A nurse to patient allocation
relative to the BPP was considered in ref. .
6.4 Distribution and inventory
Although some aspect of the distribution and inventory system can be classiﬁed as being part of the
production category, distribution and inventory are well researched using the BPP. The BPP ﬁts in here
because of consideration of sizes and shape, technological and orientation constraints during delivery and
so on. Gupta and Radovanovic considered a scenario of items in the form of a sequence (for delivery or
inventory) that must be packed on arrival. A similar scenario was considered in ref. except that in this
case, additional constraints of no buﬀering and readjustment were added. For an inventory, online order
fulﬁlment is an integral part of e-commerce. Zhang et al. proposed a solution to the dynamic stocking
problem using a mixed integer programming. Besides, without adequate inventory in a warehouse, storage
processing is interrupted. Ravichandran and Sasi proposed a robust solution approach using the BPPbased farm optimization algorithm.
6.5 Logistics
The logistic process, in this case, implies packaging and routing of goods and services for diﬀerent interests.
This industry usually deals with the respective company rules on handling their products; however, this is
by no means an easy task. Sajini Anand and Guericke proposed a variable size BPP to achieve this
objective. A smart packaging scheme was proposed by Khairuddin et al. . A scenario where a decision
must be made from a list of permissible actions upon the arrival of a stochastic request was exploited by
Banerjee and Freund . The authors in ref. used BPP to address the problem of minimization of the
distance of client’s location from the requested item location. The electric cars used are in multi-depots.
6.6 Cloud computing
In cloud computing, the problem of energy eﬃciency and cost of operation can be eﬀectively managed if the
number of servers used for a given task is minimized. This approach greatly ﬁts into BPP, hence, several
studies have been published in this regard. The placements of the virtual machines were considered to be
the bins in ref. . A heuristic method was proposed to solve a smaller version of the problem, with the
primary goal of minimizing the problem objective function. A BPP model that implements the reversed
auction in cloud computing was proposed by Ye et al. . In the same vein, Srirama et al. proposed a
dynamic BPP strategy with auto scaling. In order to solve the complications of scheduling and autoscaling
caused by container layer, Wang et al. proposed an elastic scheduling for microservices (ESMS), which
minimizes the cost of the virtual machines without compromising autoscaling.
7 Concluding remark and future direction
This study has reviewed current nature-inspired, population-based metaheuristics that have been used to
solve the classical 1D BPP. These algorithms were either adaptations or modiﬁcations of other
Chanaleä Munien and Absalom E. Ezugwu
metaheuristics. The mechanisms discussed show how simple it is to discretize a solution space to adapt
algorithms that were created for continuous optimization problems to algorithms that solve discrete optimization problems. Furthermore, the researchers of these reviewed papers focused on improving the
stability of the exploration and exploitation phases of the metaheuristics, which greatly impacts the ﬁnal
solution quality and improved on the weaknesses of the original metaheuristics while leveraging the
strengths. As can be seen, some algorithms are being tailored towards simplicity of implementation,
such as the ACS and ILWOA, while others focus on decreasing computational expense. The former
approach usually results in optimal solutions at the expense of time and resources, while the latter
approach generally produces near-optimal solutions but takes far less time to compute a result.
In general, metaheuristics are widely used optimization tools for ﬁnding near-optimal solutions to large
graph sized problem instances of the BPP in reasonable execution times. Moreover, the metaheuristic
optimization algorithms are often simple to implement and ﬂexible in terms of their adaptability in solving
the 1D BPP in practice. In addition to these beneﬁts, this class of optimization algorithms continue to be
promising tools for numerous NP-Hard optimization problems where the exact solution methods tend to fail
because of the exponential search spaces. However, some disadvantages of the metaheuristic algorithms
include the issue of premature convergence, which can lead the algorithms into getting trapped in local
optimum, and the aspect of parameter ﬁne-tuning, as some of the algorithms would require having to set
the control parameter to meet certain speciﬁed threshold.
For future research, it would be interesting to review hybridized versions of nature-inspired metaheuristic algorithms that have been used to solve the 1D BPP and other variants which involve additional constraints. Furthermore, it will be worth exploring the speciﬁc real-world applications of the metaheuristic
algorithms for solving the BPP and the impact of these implementations. More so, a comparative performance
analysis study of the state-of-the-art implementation of diﬀerent nature-inspired metaheuristic algorithms
can be considered so as to identify the best possible methods for handling the diﬀerent variants of the BPP.
Finally, it would be interesting to further conduct an extensive comparative analysis study to determine the
success of the new generation metaheuristic algorithms presented in ref. on the 1D BPP.
Conﬂict of interest: The authors declare that they have no ﬁnancial nor personal interests that could have
an inﬂuence on the work reported in this article.