CosFace: Large Margin Cosine Loss for Deep Face Recognition
Hao Wang, Yitong Wang, Zheng Zhou, Xing Ji, Dihong Gong, Jingchao Zhou,
Zhifeng Li∗, and Wei Liu∗
Tencent AI Lab
{hawelwang,yitongwang,encorezhou,denisji,sagazhou,michaelzfli}@tencent.com
 
Face recognition has made extraordinary progress owing to the advancement of deep convolutional neural networks (CNNs). The central task of face recognition, including face veriﬁcation and identiﬁcation, involves face
feature discrimination.
However, the traditional softmax
loss of deep CNNs usually lacks the power of discrimination. To address this problem, recently several loss functions such as center loss, large margin softmax loss, and
angular softmax loss have been proposed. All these improved losses share the same idea: maximizing inter-class
variance and minimizing intra-class variance. In this paper, we propose a novel loss function, namely large margin cosine loss (LMCL), to realize this idea from a different
perspective. More speciﬁcally, we reformulate the softmax
loss as a cosine loss by L2 normalizing both features and
weight vectors to remove radial variations, based on which
a cosine margin term is introduced to further maximize the
decision margin in the angular space. As a result, minimum
intra-class variance and maximum inter-class variance are
achieved by virtue of normalization and cosine decision
margin maximization. We refer to our model trained with
LMCL as CosFace. Extensive experimental evaluations are
conducted on the most popular public-domain face recognition datasets such as MegaFace Challenge, Youtube Faces
(YTF) and Labeled Face in the Wild (LFW). We achieve the
state-of-the-art performance on these benchmarks, which
conﬁrms the effectiveness of our proposed approach.
1. Introduction
Recently progress on the development of deep convolutional neural networks (CNNs) has
signiﬁcantly advanced the state-of-the-art performance on
∗Corresponding authors
Loss Layers
Cosine Similarity
Verification
Identification
Learned by Softmax
Learned by LMCL
Cropped Faces
Figure 1. An overview of the proposed CosFace framework. In the
training phase, the discriminative face features are learned with a
large margin between different classes. In the testing phase, the
testing data is fed into CosFace to extract face features which are
later used to compute the cosine similarity score to perform face
veriﬁcation and identiﬁcation.
a wide variety of computer vision tasks, which makes deep
CNN a dominant machine learning approach for computer
vision. Face recognition, as one of the most common computer vision tasks, has been extensively studied for decades
 . Early studies build shallow models with low-level face features, while modern face recognition techniques are greatly advanced driven by deep CNNs.
Face recognition usually includes two sub-tasks: face veriﬁcation and face identiﬁcation. Both of these two tasks
involve three stages: face detection, feature extraction, and
classiﬁcation. A deep CNN is able to extract clean highlevel features, making itself possible to achieve superior
performance with a relatively simple classiﬁcation architecture: usually, a multilayer perceptron networks followed by
 
a softmax loss . However, recent studies 
found that the traditional softmax loss is insufﬁcient to acquire the discriminating power for classiﬁcation.
To encourage better discriminating performance, many
research studies have been carried out .
All these studies share the same idea for maximum discrimination capability: maximizing inter-class variance and minimizing intra-class variance. For example, 
propose to adopt multi-loss learning in order to increase the
feature discriminating power. While these methods improve
classiﬁcation performance over the traditional softmax loss,
they usually come with some extra limitations. For ,
it only explicitly minimizes the intra-class variance while
ignoring the inter-class variances, which may result in suboptimal solutions. require thoroughly scheming the mining of pair or triplet samples, which is an extremely time-consuming procedure. Very recently, proposed to address this problem from a different perspective.
More speciﬁcally, (A-softmax) projects the original
Euclidean space of features to an angular space, and introduces an angular margin for larger inter-class variance.
Compared to the Euclidean margin suggested by , the angular margin is preferred because the cosine of
the angle has intrinsic consistency with softmax. The formulation of cosine matches the similarity measurement that
is frequently applied to face recognition. From this perspective, it is more reasonable to directly introduce cosine margin between different classes to improve the cosine-related
discriminative information.
In this paper, we reformulate the softmax loss as a cosine
loss by L2 normalizing both features and weight vectors to
remove radial variations, based on which a cosine margin
term m is introduced to further maximize the decision margin in the angular space. Speciﬁcally, we propose a novel
algorithm, dubbed Large Margin Cosine Loss (LMCL),
which takes the normalized features as input to learn highly
discriminative features by maximizing the inter-class cosine
margin. Formally, we deﬁne a hyper-parameter m such that
the decision boundary is given by cos(θ1) −m = cos(θ2),
where θi is the angle between the feature and weight of class
For comparison, the decision boundary of the A-Softmax
is deﬁned over the angular space by cos(mθ1) = cos(θ2),
which has a difﬁculty in optimization due to the nonmonotonicity of the cosine function. To overcome such a
difﬁculty, one has to employ an extra trick with an ad-hoc
piecewise function for A-Softmax. More importantly, the
decision margin of A-softmax depends on θ, which leads to
different margins for different classes. As a result, in the
decision space, some inter-class features have a larger margin while others have a smaller margin, which reduces the
discriminating power. Unlike A-Softmax, our approach de-
ﬁnes the decision margin in the cosine space, thus avoiding
the aforementioned shortcomings.
Based on the LMCL, we build a sophisticated deep
model called CosFace, as shown in Figure 1. In the training phase, LMCL guides the ConvNet to learn features with
a large cosine margin. In the testing phase, the face features are extracted from the ConvNet to perform either face
veriﬁcation or face identiﬁcation. We summarize the contributions of this work as follows:
(1) We embrace the idea of maximizing inter-class variance and minimizing intra-class variance and propose a
novel loss function, called LMCL, to learn highly discriminative deep features for face recognition.
(2) We provide reasonable theoretical analysis based
on the hyperspherical feature distribution encouraged by
(3) The proposed approach advances the state-of-the-art
performance over most of the benchmarks on popular face
databases including LFW , YTF and Megaface [17,
2. Related Work
Deep Face Recognition. Recently, face recognition has
achieved signiﬁcant progress thanks to the great success
of deep CNN models . In DeepFace 
and DeepID , face recognition is treated as a multiclass classiﬁcation problem and deep CNN models are
ﬁrst introduced to learn features on large multi-identities
datasets. DeepID2 employs identiﬁcation and veriﬁcation signals to achieve better feature embedding. Recent
works DeepID2+ and DeepID3 further explore
the advanced network structures to boost recognition performance. FaceNet uses triplet loss to learn an Euclidean space embedding and a deep CNN is then trained
on nearly 200 million face images, leading to the state-ofthe-art performance. Other approaches also prove
the effectiveness of deep CNNs on face recognition.
Loss Functions. Loss function plays an important role
in deep feature learning. Contrastive loss and triplet
loss are usually used to increase the Euclidean margin for better feature embedding. Wen et al. proposed
a center loss to learn centers for deep features of each identity and used the centers to reduce intra-class variance. Liu
et al. proposed a large margin softmax (L-Softmax)
by adding angular constraints to each identity to improve
feature discrimination. Angular softmax (A-Softmax) 
improves L-Softmax by normalizing the weights, which
achieves better performance on a series of open-set face
recognition benchmarks . Other loss functions
 based on contrastive loss or center loss also
demonstrate the performance on enhancing discrimination.
Normalization Approaches. Normalization has been
studied in recent deep face recognition studies. normalizes the weights which replace the inner product with cosine
similarity within the softmax loss. applies the L2 constraint on features to embed faces in the normalized space.
Note that normalization on feature vectors or weight vectors achieves much lower intra-class angular variability by
concentrating more on the angle during training. Hence the
angles between identities can be well optimized. The von
Mises-Fisher (vMF) based methods and A-Softmax
 also adopt normalization in feature learning.
3. Proposed Approach
In this section, we ﬁrstly introduce the proposed LMCL
in detail (Sec. 3.1). And a comparison with other loss functions is given to show the superiority of the LMCL (Sec.
3.2). The feature normalization technique adopted by the
LMCL is further described to clarify its effectiveness (Sec.
3.3). Lastly, we present a theoretical analysis for the proposed LMCL (Sec. 3.4).
3.1. Large Margin Cosine Loss
We start by rethinking the softmax loss from a cosine
perspective. The softmax loss separates features from different classes by maximizing the posterior probability of the
ground-truth class. Given an input feature vector xi with its
corresponding label yi, the softmax loss can be formulated
−log pi = 1
where pi denotes the posterior probability of xi being correctly classiﬁed. N is the number of training samples and C
is the number of classes. fj is usually denoted as activation
of a fully-connected layer with weight vector Wj and bias
Bj. We ﬁx the bias Bj = 0 for simplicity, and as a result fj
is given by:
j x = ∥Wj∥∥x∥cos θj,
where θj is the angle between Wj and x. This formula suggests that both norm and angle of vectors contribute to the
posterior probability.
To develop effective feature learning, the norm of W
should be necessarily invariable.
To this end, We ﬁx
∥Wj∥= 1 by L2 normalization. In the testing stage, the
face recognition score of a testing face pair is usually calculated according to cosine similarity between the two feature vectors. This suggests that the norm of feature vector
x is not contributing to the scoring function. Thus, in the
training stage, we ﬁx ∥x∥= s. Consequently, the posterior
probability merely relies on cosine of angle. The modiﬁed
loss can be formulated as
es cos(θyi,i)
j es cos(θj,i) .
Figure 2. The comparison of decision margins for different loss
functions the binary-classes scenarios. Dashed line represents decision boundary, and gray areas are decision margins.
Because we remove variations in radial directions by ﬁxing ∥x∥= s, the resulting model learns features that are
separable in the angular space. We refer to this loss as the
Normalized version of Softmax Loss (NSL) in this paper.
However, features learned by the NSL are not sufﬁciently discriminative because the NSL only emphasizes
correct classiﬁcation. To address this issue, we introduce
the cosine margin to the classiﬁcation boundary, which is
naturally incorporated into the cosine formulation of Softmax.
Considering a scenario of binary-classes for example,
let θi denote the angle between the learned feature vector
and the weight vector of Class Ci (i = 1, 2). The NSL
forces cos(θ1) > cos(θ2) for C1, and similarly for C2,
so that features from different classes are correctly classi-
ﬁed. To develop a large margin classiﬁer, we further require
cos(θ1) −m > cos(θ2) and cos(θ2) −m > cos(θ1), where
m ≥0 is a ﬁxed parameter introduced to control the magnitude of the cosine margin. Since cos(θi) −m is lower than
cos(θi), the constraint is more stringent for classiﬁcation.
The above analysis can be well generalized to the scenario
of multi-classes. Therefore, the altered loss reinforces the
discrimination of learned features by encouraging an extra
margin in the cosine space.
Formally, we deﬁne the Large Margin Cosine Loss
(LMCL) as:
es(cos(θyi,i)−m)
es(cos(θyi,i)−m) + P
j̸=yi es cos(θj,i) ,
subject to
cos(θj, i) = Wj
where N is the numer of training samples, xi is the i-th
feature vector corresponding to the ground-truth class of yi,
the Wj is the weight vector of the j-th class, and θj is the
angle between Wj and xi.
3.2. Comparison on Different Loss Functions
In this subsection, we compare the decision margin of
our method (LMCL) to: Softmax, NSL, and A-Softmax,
as illustrated in Figure 2. For simplicity of analysis, we
consider the binary-classes scenarios with classes C1 and
C2. Let W1 and W2 denote weight vectors for C1 and C2,
respectively.
Softmax loss deﬁnes a decision boundary by:
∥W1∥cos(θ1) = ∥W2∥cos(θ2).
Thus, its boundary depends on both magnitudes of weight
vectors and cosine of angles, which results in an overlapping decision area (margin < 0) in the cosine space. This is
illustrated in the ﬁrst subplot of Figure 2. As noted before,
in the testing stage it is a common strategy to only consider
cosine similarity between testing feature vectors of faces.
Consequently, the trained classiﬁer with the Softmax loss
is unable to perfectly classify testing samples in the cosine
NSL normalizes weight vectors W1 and W2 such that
they have constant magnitude 1, which results in a decision
boundary given by:
cos(θ1) = cos(θ2).
The decision boundary of NSL is illustrated in the second
subplot of Figure 2. We can see that by removing radial
variations, the NSL is able to perfectly classify testing samples in the cosine space, with margin = 0. However, it is
not quite robust to noise because there is no decision margin: any small perturbation around the decision boundary
can change the decision.
A-Softmax improves the softmax loss by introducing an
extra margin, such that its decision boundary is given by:
C1 : cos(mθ1) ≥cos(θ2),
C2 : cos(mθ2) ≥cos(θ1).
Thus, for C1 it requires θ1 ≤θ2
m , and similarly for C2. The
third subplot of Figure 2 depicts this decision area, where
gray area denotes decision margin. However, the margin
of A-Softmax is not consistent over all θ values: the margin becomes smaller as θ reduces, and vanishes completely
when θ = 0. This results in two potential issues. First, for
difﬁcult classes C1 and C2 which are visually similar and
thus have a smaller angle between W1 and W2, the margin is consequently smaller. Second, technically speaking
one has to employ an extra trick with an ad-hoc piecewise
function to overcome the nonmonotonicity difﬁculty of the
cosine function.
LMCL (our proposed) deﬁnes a decision margin in cosine space rather than the angle space (like A-Softmax) by:
C1 : cos(θ1) ≥cos(θ2) + m,
C2 : cos(θ2) ≥cos(θ1) + m.
Therefore, cos(θ1) is maximized while cos(θ2) being minimized for C1 (similarly for C2) to perform the large-margin
classiﬁcation. The last subplot in Figure 2 illustrates the decision boundary of LMCL in the cosine space, where we can
see a clear margin(
2m) in the produced distribution of the
cosine of angle. This suggests that the LMCL is more robust
than the NSL, because a small perturbation around the decision boundary (dashed line) less likely leads to an incorrect
decision. The cosine margin is applied consistently to all
samples, regardless of the angles of their weight vectors.
3.3. Normalization on Features
In the proposed LMCL, a normalization scheme is involved on purpose to derive the formulation of the cosine
loss and remove variations in radial directions. Unlike 
that only normalizes the weight vectors, our approach simultaneously normalizes both weight vectors and feature
vectors. As a result, the feature vectors distribute on a hypersphere, where the scaling parameter s controls the magnitude of radius. In this subsection, we discuss why feature
normalization is necessary and how feature normalization
encourages better feature learning in the proposed LMCL
The necessity of feature normalization is presented in
two respects: First, the original softmax loss without feature
normalization implicitly learns both the Euclidean norm
(L2-norm) of feature vectors and the cosine value of the
angle. The L2-norm is adaptively learned for minimizing
the overall loss, resulting in the relatively weak cosine constraint. Particularly, the adaptive L2-norm of easy samples
becomes much larger than hard samples to remedy the inferior performance of cosine metric. On the contrary, our
approach requires the entire set of feature vectors to have
the same L2-norm such that the learning only depends on
cosine values to develop the discriminative power.
Feature vectors from the same classes are clustered together
and those from different classes are pulled apart on the surface of the hypersphere. Additionally, we consider the situation when the model initially starts to minimize the LMCL.
Given a feature vector x, let cos(θi) and cos(θj) denote cosine scores of the two classes, respectively. Without normalization on features, the LMCL forces ∥x∥(cos(θi) −m) >
∥x∥cos(θj). Note that cos(θi) and cos(θj) can be initially
comparable with each other. Thus, as long as (cos(θi)−m)
is smaller than cos(θj), ∥x∥is required to decrease for minimizing the loss, which degenerates the optimization. Therefore, feature normalization is critical under the supervision
of LMCL, especially when the networks are trained from
scratch. Likewise, it is more favorable to ﬁx the scaling
parameter s instead of adaptively learning.
Furthermore, the scaling parameter s should be set to a
properly large value to yield better-performing features with
lower training loss. For NSL, the loss continuously goes
Figure 3. A geometrical interpretation of LMCL from feature perspective. Different color areas represent feature space from distinct classes. LMCL has a relatively compact feature region compared with NSL.
down with higher s, while too small s leads to an insuf-
ﬁcient convergence even no convergence. For LMCL, we
also need adequately large s to ensure a sufﬁcient hyperspace for feature learning with an expected large margin.
In the following, we show the parameter s should have a
lower bound to obtain expected classiﬁcation performance.
Given the normalized learned feature vector x and unit
weight vector W, we denote the total number of classes
as C. Suppose that the learned feature vectors separately
lie on the surface of the hypersphere and center around the
corresponding weight vector. Let PW denote the expected
minimum posterior probability of class center (i.e., W), the
lower bound of s is given by 1:
log (C −1)PW
Based on this bound, we can infer that s should be enlarged consistently if we expect an optimal Pw for classiﬁcation with a certain number of classes. Besides, by keeping
a ﬁxed Pw, the desired s should be larger to deal with more
classes since the growing number of classes increase the
difﬁculty for classiﬁcation in the relatively compact space.
A hypersphere with large radius s is therefore required for
embedding features with small intra-class distance and large
inter-class distance.
3.4. Theoretical Analysis for LMCL
The preceding subsections essentially discuss the LMCL
from the classiﬁcation point of view. In terms of learning
the discriminative features on the hypersphere, the cosine
margin servers as momentous part to strengthen the discriminating power of features. Detailed analysis about the quantitative feasible choice of the cosine margin (i.e., the bound
of hyper-parameter m) is necessary. The optimal choice of
m potentially leads to more promising learning of highly
discriminative face features. In the following, we delve into
the decision boundary and angular margin in the feature
space to derive the theoretical bound for hyper-parameter
1Proof is attached in the supplemental material.
First, considering the binary-classes case with classes C1
and C2 as before, suppose that the normalized feature vector x is given. Let Wi denote the normalized weight vector,
and θi denote the angle between x and Wi. For NSL, the
decision boundary deﬁnes as cos θ1 −cos θ2 = 0, which is
equivalent to the angular bisector of W1 and W2 as shown
in the left of Figure 3. This addresses that the model supervised by NSL partitions the underlying feature space to
two close regions, where the features near the boundary are
extremely ambiguous (i.e., belonging to either class is acceptable). In contrast, LMCL drives the decision boundary
formulated by cos θ1 −cos θ2 = m for C1, in which θ1
should be much smaller than θ2 (similarly for C2). Consequently, the inter-class variance is enlarged while the intraclass variance shrinks.
Back to Figure 3, one can observe that the maximum
angular margin is subject to the angle between W1 and
W2. Accordingly, the cosine margin should have the limited variable scope when W1 and W2 are given. Speciﬁcally, suppose a scenario that all the feature vectors belonging to class i exactly overlap with the corresponding weight
vector Wi of class i. In other words, every feature vector is
identical to the weight vector for class i, and apparently the
feature space is in an extreme situation, where all the feature vectors lie at their class center. In that case, the margin
of decision boundaries has been maximized (i.e., the strict
upper bound of the cosine margin).
To extend in general, we suppose that all the features are
well-separated and we have a total number of C classes.
The theoretical variable scope of m is supposed to be:
0 ≤m ≤(1 −max(W T
i Wj)), where i, j ≤n, i ̸= j.
The softmax loss tries to maximize the angle between any
of the two weight vectors from two different classes in order
to perform perfect classiﬁcation. Hence, it is clear that the
optimal solution for the softmax loss should uniformly distribute the weight vectors on a unit hypersphere. Based on
this assumption, the variable scope of the introduced cosine
margin m can be inferred as follows 2:
0 ≤m ≤1 −cos 2π
(C ≤K + 1)
(C > K + 1)
where C is the number of training classes and K is the dimension of learned features. The inequalities indicate that
as the number of classes increases, the upper bound of the
cosine margin between classes are decreased correspondingly. Especially, if the number of classes is much larger
than the feature dimension, the upper bound of the cosine
margin will get even smaller.
2Proof is attached in the supplemental material.
Figure 4. A toy experiment of different loss functions on 8 identities with 2D features. The ﬁrst row maps the 2D features onto the Euclidean
space, while the second row projects the 2D features onto the angular space. The gap becomes evident as the margin term m increases.
A reasonable choice of larger m ∈[0,
C−1) should effectively boost the learning of highly discriminative features. Nevertheless, parameter m usually could not reach
the theoretical upper bound in practice due to the vanishing of the feature space. That is, all the feature vectors
are centered together according to the weight vector of the
corresponding class. In fact, the model fails to converge
when m is too large, because the cosine constraint (i.e.,
cos θ1−m > cos θ2 or cos θ2−m > cos θ1 for two classes)
becomes stricter and is hard to be satisﬁed. Besides, the cosine constraint with overlarge m forces the training process
to be more sensitive to noisy data. The ever-increasing m
starts to degrade the overall performance at some point because of failing to converge.
We perform a toy experiment for better visualizing on
features and validating our approach. We select face images from 8 distinct identities containing enough samples to
clearly show the feature points on the plot. Several models
are trained using the original softmax loss and the proposed
LMCL with different settings of m. We extract 2-D features
of face images for simplicity. As discussed above, m should
be no larger than 1 −cos π
4 (about 0.29), so we set up three
choices of m for comparison, which are m = 0, m = 0.1,
and m = 0.2. As shown in Figure 4, the ﬁrst row and
second row present the feature distributions in Euclidean
space and angular space, respectively. We can observe that
the original softmax loss produces ambiguity in decision
boundaries while the proposed LMCL performs much better. As m increases, the angular margin between different
classes has been ampliﬁed.
4. Experiments
4.1. Implementation Details
Preprocessing. Firstly, face area and landmarks are detected by MTCNN for the entire set of training and
testing images. Then, the 5 facial points (two eyes, nose and
two mouth corners) are adopted to perform similarity transformation. After that we obtain the cropped faces which are
then resized to be 112 × 96. Following , each pixel
(in ) in RGB images is normalized by subtracting
127.5 then dividing by 128.
Training. For a direct and fair comparison to the existing
results that use small training datasets (less than 0.5M images and 20K subjects) , we train our models on a small
training dataset, which is the publicly available CASIA-
WebFace dataset containing 0.49M face images from
10,575 subjects. We also use a large training dataset to evaluate the performance of our approach for benchmark comparison with the state-of-the-art results (using large training
dataset) on the benchmark face dataset. The large training
dataset that we use in this study is composed of several public datasets and a private face dataset, containing about 5M
images from more than 90K identities. The training faces
are horizontally ﬂipped for data augmentation. In our experiments we remove face images belong to identities that
appear in the testing datasets.
For the fair comparison, the CNN architecture used in
our work is similar to , which has 64 convolutional layers and is based on residual units . The scaling parameter
s in Equation (4) is set to 64 empirically. We use Caffe 
to implement the modiﬁcations of the loss layer and run the
accuracy (%)
Figure 5. Accuracy (%) of CosFace with different margin parameters m on LFW and YTF .
models. The CNN models are trained with SGD algorithm,
with the batch size of 64 on 8 GPUs. The weight decay is
set to 0.0005. For the case of training on the small dataset,
the learning rate is initially 0.1 and divided by 10 at the
16K, 24K, 28k iterations, and we ﬁnish the training process
at 30k iterations. While the training on the large dataset terminates at 240k iterations, with the initial learning rate 0.05
dropped at 80K, 140K, 200K iterations.
Testing. At testing stage, features of original image and
the ﬂipped image are concatenated together to compose the
ﬁnal face representation. The cosine distance of features
is computed as the similarity score. Finally, face veriﬁcation and identiﬁcation are conducted by thresholding and
ranking the scores. We test our models on several popular public face datasets, including LFW , YTF , and
MegaFace .
4.2. Exploratory Experiments
Effect of m. The margin parameter m plays a key role in
LMCL. In this part we conduct an experiment to investigate
the effect of m. By varying m from 0 to 0.45 (If m is larger
than 0.45, the model will fail to converge), we use the small
training data (CASIA-WebFace ) to train our CosFace
model and evaluate its performance on the LFW and
YTF datasets, as illustrated in Figure 5. We can see
that the model without the margin (in this case m=0) leads
to the worst performance. As m being increased, the accuracies are improved consistently on both datasets, and get
saturated at m = 0.35. This demonstrates the effectiveness
of the margin m. By increasing the margin m, the discriminative power of the learned features can be signiﬁcantly
improved. In this study, m is set to ﬁxed 0.35 in the subsequent experiments.
Effect of Feature Normalization. To investigate the effect of the feature normalization scheme in our approach,
we train our CosFace models on the CASIA-WebFace with
Normalization
MF1 Rank 1
Table 1. Comparison of our models with and without feature normalization on Megaface Challenge 1 (MF1). “Rank 1” refers to
rank-1 face identiﬁcation accuracy and “Veri.” refers to face veriﬁcation TAR (True Accepted Rate) under 10−6 FAR (False Accepted Rate).
and without the feature normalization scheme by ﬁxing
m to 0.35, and compare their performance on LFW ,
YTF , and the Megaface Challenge 1(MF1) . Note
that the model trained without normalization is initialized by softmax loss and then supervised by the proposed
LMCL. The comparative results are reported in Table 1. It
is very clear that the model using the feature normalization
scheme consistently outperforms the model without the feature normalization scheme across the three datasets. As discussed above, feature normalization removes radical variance, and the learned features can be more discriminative in
angular space. This experiment veriﬁes this point.
4.3. Comparison with state-of-the-art loss functions
In this part, we compare the performance of the proposed LMCL with the state-of-the-art loss functions. Following the experimental setting in , we train a model
with the guidance of the proposed LMCL on the CAISA-
WebFace using the same 64-layer CNN architecture described in .
The experimental comparison on LFW,
YTF and MF1 are reported in Table 2. For fair comparison,
we are strictly following the model structure (a 64-layers
ResNet-Like CNNs) and the detailed experimental settings
of SphereFace . As can be seen in Table 2, LMCL consistently achieves competitive results compared to the other
losses across the three datasets. Especially, our method not
only surpasses the performance of A-Softmax with feature
normalization (named as A-Softmax-NormFea in Table 2),
but also signiﬁcantly outperforms the other loss functions
on YTF and MF1, which demonstrates the effectiveness of
4.4. Overall Benchmark Comparison
Evaluation on LFW and YTF
LFW is a standard face veriﬁcation testing dataset in
unconstrained conditions. It includes 13,233 face images
from 5749 identities collected from the website. We evaluate our model strictly following the standard protocol of
unrestricted with labeled outside data , and report the
result on the 6,000 pair testing images.
YTF contains 3,425 videos of 1,595 different people. The average
length of a video clip is 181.3 frames. All the video sequences were downloaded from YouTube. We follow the
Softmax Loss 
Softmax+Contrastive 
Triplet Loss 
L-Softmax Loss 
Softmax+Center Loss 
A-Softmax 
A-Softmax-NormFea
Table 2. Comparison of the proposed LMCL with state-of-the-art
loss functions in face recognition community. All the methods in
this table are using the same training data and the same 64-layer
CNN architecture.
Training Data
Deep Face 
FaceNet 
DeepFR 
DeepID2+ 
Center Face 
SphereFace 
Table 3. Face veriﬁcation (%) on the LFW and YTF datasets.
“#Models” indicates the number of models that have been used
in the method for evaluation.
SIAT MMLAB 
DeepSense - Small
SphereFace - Small 
Beijing FaceAll V2
FUDAN-CS SDS 
CosFace(Single-patch)
CosFace(3-patch ensemble)
Beijing FaceAll Norm 1600
Google - FaceNet v8 
NTechLAB - facenx large
SIATMMLAB TencentVision
DeepSense V2
Vocord - deepVo V3
CosFace(Single-patch)
CosFace(3-patch ensemble)
Table 4. Face identiﬁcation and veriﬁcation evaluation on MF1.
“Rank 1” refers to rank-1 face identiﬁcation accuracy and “Veri.”
refers to face veriﬁcation TAR under 10−6 FAR.
SphereFace
CosFace (Single-patch)
CosFace(3-patch ensemble)
Table 5. Face identiﬁcation and veriﬁcation evaluation on MF2.
“Rank 1” refers to rank-1 face identiﬁcation accuracy and “Veri.”
refers to face veriﬁcation TAR under 10−6 FAR .
unrestricted with labeled outside data protocol and report
the result on 5,000 video pairs.
As shown in Table 3, the proposed CosFace achieves
state-of-the-art results of 99.73% on LFW and 97.6% on
YTF. FaceNet achieves the runner-up performance on LFW
with the large scale of the image dataset, which has approximately 200 million face images. In terms of YTF, our model
reaches the ﬁrst place over all other methods.
Evaluation on MegaFace
MegaFace is a very challenging testing benchmark
recently released for large-scale face identiﬁcation and veriﬁcation, which contains a gallery set and a probe set. The
gallery set in Megaface is composed of more than 1 million face images. The probe set has two existing databases:
Facescrub and FGNET . In this study, we use the
Facescrub dataset (containing 106,863 face images of 530
celebrities) as the probe set to evaluate the performance of
our approach on both Megaface Challenge 1 and Challenge
MegaFace Challenge 1 (MF1). On the MegaFace Challenge 1 , The gallery set incorporates more than 1 million images from 690K individuals collected from Flickr
photos . Table 4 summarizes the results of our models
trained on two protocols of MegaFace where the training
dataset is regarded as small if it has less than 0.5 million
images, large otherwise. The CosFace approach shows its
superiority for both the identiﬁcation and veriﬁcation tasks
on both the protocols.
MegaFace Challenge 2 (MF2). In terms of MegaFace
Challenge 2 , all the algorithms need to use the training
data provided by MegaFace. The training data for Megaface
Challenge 2 contains 4.7 million faces and 672K identities,
which corresponds to the large protocol. The gallery set
has 1 million images that are different from the challenge
1 gallery set. Not surprisingly, Our method wins the ﬁrst
place of challenge 2 in table 5, setting a new state-of-the-art
with a large margin (1.39% on rank-1 identiﬁcation accuracy and 5.46% on veriﬁcation performance).
5. Conclusion
In this paper, we proposed an innovative approach named
LMCL to guide deep CNNs to learn highly discriminative
face features. We provided a well-formed geometrical and
theoretical interpretation to verify the effectiveness of the
proposed LMCL. Our approach consistently achieves the
state-of-the-art results on several face benchmarks. We wish
that our substantial explorations on learning discriminative
features via LMCL will beneﬁt the face recognition community.