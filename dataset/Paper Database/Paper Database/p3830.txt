Knowl Inf Syst 
DOI 10.1007/s10115-006-0034-6
Knowledge and
Information Systems
Eamonn Keogh · Jessica Lin ·
Sang-Hee Lee · Helga Van Herle
Finding the most unusual time series
subsequence: algorithms and applications
Received: 30 November 2005 / Revised: 20 December 2005 / Accepted: 20 February 2006
C⃝Springer-Verlag London Limited 2006
Abstract In this work we introduce the new problem of ﬁnding time series discords. Time series discords are subsequences of longer time series that are maximally different to all the rest of the time series subsequences. They thus capture
the sense of the most unusual subsequence within a time series. While discords
have many uses for data mining, they are particularly attractive as anomaly detectors because they only require one intuitive parameter (the length of the subsequence) unlike most anomaly detection algorithms that typically require many
parameters. While the brute force algorithm to discover time series discords is
quadratic in the length of the time series, we show a simple algorithm that is three
to four orders of magnitude faster than brute force, while guaranteed to produce
identical results. We evaluate our work with a comprehensive set of experiments
on diverse data sources including electrocardiograms, space telemetry, respiration
physiology, anthropological and video datasets.
Keywords Time series data mining · Anomaly detection · Clustering
E. Keogh (B)
Department of Computer Science and Engineering, University of California, Riverside, CA,
E-mail: 
Department of Information and Software Engineering, George Mason University, Fairfax, VA,
E-mail: 
Anthropology Department, University of California, Riverside, CA, USA
E-mail: 
H. V. Herle
David Geffen School of Medicine, University of California, Los Angeles, CA, USA
E-mail: 
E. Keogh et al.
ECG qtdb/sel102 (excerpt)
ECG qtdb/sel102 (excerpt)
Fig. 1 The time series discord found in an excerpt of electrocardiogram qtdb/sel102 (marked in
bold line). The location of the discord exactly coincides with a premature ventricular contraction
1 Introduction
The previous decade has seen hundreds of papers on time series similarity search,
which is the task of ﬁnding a time series that is most similar to a particular query
sequence . In this work, we pose the new problem of ﬁnding the sequence that is least similar to all other sequences. We call such sequences time
series discords. Figure 1 gives a visual intuition of a time series discord found in
a human electrocardiogram.
The fact that the discord in Fig. 1 coincides with the location annotated by
a cardiologist as containing an anomalous heartbeat hints at one possible use of
discords. As we shall show, time series discords are superlative anomaly detectors,
able to detect subtle anomalies in diverse domains.
One reason why discords are particularly suited for the increasingly important
problem of anomaly detection is that they only require a single intuitive parameter, the length of the subsequences to consider. In contrast, many other anomaly
detection algorithms require three to seven unintuitive parameters . With so
many parameters to set, we need access to huge amounts of training data, even
then, avoiding overﬁtting remains a challenge.
Time series discords have other uses. Clustering algorithms can often beneﬁt
from removing a handful of tricky cases, which can be removed from the dataset
before the clustering algorithm is run . We could attempt to deﬁne these “tricky
cases” as ones that do not belong to any cluster; however, this opens the possibility
of a chicken and egg paradox. This effect has been noted in clustering points in
k-dimensional space, but it is also true for time series, and the removal of discords
offers a solution.
This paper makes two fundamental contributions in discovering unusual time
series subsequences. First, while the idea of the “most unusual subsequence” is
intuitive, great care must be taken in creating a workable deﬁnition, otherwise we
will be plagued with uninteresting pathological solutions. We introduce such a definition here and validate it in diverse domains. Second, the brute-force algorithm
to discover the most unusual subsequence requires a quadratic “all to all” comparison, which is untenable for large real-world datasets. We introduce a simple
algorithm that can achieve three to four orders of magnitude speedup on real problems. Our algorithm works by admissibly pruning off some fruitless calculations,
and using heuristics to reorder the search such that as many fruitless calculations
are pruned as possible.
The rest of the paper is organized as follows. In Sect. 2, we review related
work and discuss some background material before introducing our formal deﬁnition of time series discords. In Sect. 3, we consider the brute-force algorithm for
Finding the most unusual time series subsequence: algorithms and applications
ﬁnding discords, and introduce a general framework for speeding up the search
based on admissible pruning and reordering the order in which the search examines the subsequences. Section 4 introduces a particular reordering strategy based
on examining a symbolic version of the data. We perform an extensive empirical
evaluation in Sect. 5 to demonstrate both the utility of discords and our ability to
ﬁnd them quickly. Finally, Sect. 6 offers some conclusions and suggestions for
future work.
2 Related work and background
Our review of related work is exceptionally brief because we are considering a new
problem. Most real-valued time series problems such as motif discovery ,
longest common subsequence matching, sequence averaging, segmentation ,
indexing , etc. have approximate or exact analogues in the discrete world, and
have been addressed by the text processing or bioinformatics communities. However, time series discords do not appear to have a discrete version. Note that the
superﬁcially similar sounding Furthest (Sub)String Problem requires us to build a
string, not to ﬁnd one in the data . As we shall see below, one major use of
discords is in anomaly detection. This topic has been area of extensive research in
recent years, we refer the reader to Keogh et al. , which gives a detailed survey.
2.1 Notation
For concreteness, we begin with a deﬁnition of our data type of interest, time
Deﬁnition 1 Time series: A time series T = t1, . . ., tm is an ordered set of m
real-valued variables.
For data mining purposes, we are often not interested in any of the global
properties of a time series ; rather, we are interested in local subsections
of the time series, which are called subsequences.
Deﬁnition 2 Subsequence: Given a time series T of length m, a subsequence C
of T is a sampling of length n ≤m of contiguous position from T, that is, C =
tp, . . . , tp+n−1 for 1 ≤p ≤m −n + 1.
Since all subsequences may potentially be discords, any algorithm will eventually have to extract all of them; this can be achieved by use of a sliding window.
Deﬁnition 3 Sliding window: Given a time series T of length m, and a userdeﬁned subsequence length of n, all possible subsequences can be extracted by
sliding a window of size n across T and considering each subsequence C p.
Since our task is to ﬁnd the most distant subsequence under some distance
measure Dist(C,M), we will take the time to deﬁne distance.
Deﬁnition 4 Distance: Dist is a function that has C and M as inputs and returns a
nonnegative value R, which is said to be the distance from M to C. For subsequent
deﬁnitions to work we require that the function D be symmetric, that is, Dist(C,
M) = Dist(M,C). We also assume that the two subsequences are of equal length.
E. Keogh et al.
While the deﬁnition of a distance is obvious and intuitive, we need it to exclude
trivial matches. In general, the best matches to a subsequence (apart from itself)
tend to be located one or two points to the left or the right of the subsequence
in question. Such matches have previously been called trivial matches .
As we shall see, it is critical when ﬁnding discords to exclude trivial matches;
otherwise, almost all real datasets have degenerate and unintuitive solutions. We
will therefore take the time to formally deﬁne a non-self match.
Deﬁnition 5 Non-self match: Given a time series T, containing a subsequence C
of length n beginning at position p and a matching subsequence M beginning at q,
we say that M is a non-self match to C at distance of Dist(M, C) if |p −q| ≥n.
We can most easily see the importance of non-self matches for the problem at
hand if we consider the analogy of the problem in the discrete world. Consider the
following string:
abcabcabcabcXXXabcabcabacabc
The eye is immediately drawn to the subsequence of “X,” which surely forms
the discord here. However, if we assume a sliding window length of 3, and that our
distance measure is the hamming distance, then the subsequence that is farthest
from its nearest neighbor subsequence is “bac.” Below, the string is annotated by
subscripts that give the distance to the nearest neighbor for each subsequence of
a0b0c0a0b0c0a0b0c0a0b1c1X1X1X1a0b0c0a0b0c0a1b2a1c0abc
This unexpected and unintuitive result is caused by allowing trivial matches.
While the subsequence XXX may appear unusual, it is only 1 unit distance from
the subsequence XXa, which shares two elements simply shifted by one place. We
can see the difference this makes by annotating the string with the non-self match
distance to its nearest neighbor subsequence:
a0b0c0a0b0c0a0b0c0a0b1c2X3X2X1a0b0c0a0b0c0a1b2a1c0abc
Here the results are much more intuitive. While it is a simple and contrived
example on discrete data, as we shall see, identical remarks apply to real world,
real-valued data. Note that the idea that one must exclude “partial self” comparisons in order to create meaningful deﬁnitions is well known in the bioinformatics
community and increasingly understood in the time series data mining community . We will therefore use the deﬁnition of non-self matches
to deﬁne time series discords:
Deﬁnition 6 Time series discord: Given a time series T, the subsequence D of
length n beginning at position l is said to be the discord of T if D has the largest
distance to its nearest non-self match. That is, “∀subsequence C of T,” non-self
match MD of D, and non-self match MC of C, min(Dist(D, MD)) > min(Dist(C,
Finding the most unusual time series subsequence: algorithms and applications
We will denote the location of the discord as D.l and the distance to the nearest
non-self matching neighbor as D.Dist. We denote the length of the discord as Dn.
We may be interested in examining the top K discords, which we deﬁne as
Deﬁnition 7 Kth time series discord: Given a time series T, the subsequence D
of length n beginning at position p is the Kth-discord of T if D has the Kth largest
distance to its nearest non-self match, with no overlapping region to the ith discord
beginning at position pi, for all 1 ≤i < K. That is, |p −pi| ≥n.
We have deliberately omitted naming a distance function up to this point for
generality. For concreteness, we will use the ubiquitous Euclidean distance measure throughout the rest of this paper .
Deﬁnition 8 Euclidean distance: Given two time series Q and C of length n, the
Euclidean distance between them is deﬁned as
Dist (Q, C) ≡
Each time series subsequence is normalized to have mean zero and a standard
deviation of one before calling the distance function, because it is well understood
that in virtually all settings, it is meaningless to compare time series with different
offsets and amplitudes .
2.2 Some properties of time series discords
Here, we discuss some properties of time series discords to enhance the readers’
understanding of them and to discount some possible research directions for ﬁnding algorithms for quickly locating them.
2.2.1 Discords are not necessary found in sparse space
The idea of considering time series subsequences as points in space has long been
exploited by dozens of indexing techniques , so one might imagine that such
a representation would be useful for the task at hand. We could simply project our
time series into n-dimensional space and use existing outlier detection methods
 . The problem with this idea is the unintuitive fact that discords do not necessarily live in sparse areas of n-dimensional space (conversely, repeated patterns
do not necessarily live in dense parts of the n-dimensional space ). The
full explanation has consequences for other problems and is perhaps deserving of
a separate paper; however, here, we content ourselves with a visual example and
a brief explanation. In Fig. 2, we consider a simple time series consisting of a
slightly noisy sine wave. We introduce an “anomaly” of length 50 by shifting the
entire second half of the time series.
We can now extract all subsequences of length 50, project them into 50dimensional space and measure the local density around each subsequence. Surprisingly, the anomaly is not in the sparsest (or in any other way remarkable)
E. Keogh et al.
synthetic data
non-self distance
synthetic data
non-self distance
Fig. 2 (Top) A synthetic time series with an obvious anomaly. (Middle) The local density of
subsequences of length 50, measured by calculating the number of matching subsequences
within a range of 2. (Bottom) The non-self match to the nearest neighbor for all subsequences of
region of space. However, note that the deﬁnition of non-self match that is at the
heart of time series discords clearly identiﬁes the anomalous region.
The explanation of this unintuitive ﬁnding harkens back to the idea of trivial
matches. Consider a subsequence C located at tp that is “simple,” that is to say it
has only one or two features such as peaks or valleys. This simple subsequence
is very close in n-dimensional space to the subsequences beginning at tp+1,tp−1,
tp+2, etc. In contrast, consider a subsequence M located at tq that is “complex,”
that is to say it has many features such as peaks or valleys. This complex subsequence is relatively far from subsequences beginning at tq+1, tq−1, tq+2, etc. In
other words, simple (and smooth) shapes appear to be in dense neighborhoods because we over-count shifted versions of them. This problem prevents us for using
existing density based algorithms to ﬁnd time series discords. Note that even if
current-density-based algorithms could be adapted to consider non-self distance,
most of them degrade to quadratic time complexity for high dimensionality data.
2.2.2 Discords results are non-combinable
Several generic paradigms for solving problems rely on the ability to decompose
a problem into smaller sub-problems, which can be solved and admissibly recombined. Depending on the exact deﬁnitions, such techniques are variously called
dynamic programming, divide and conquer, bottom-up, etc. . Unfortunately, as
we show below, such ideas are unlikely to help us efﬁciently ﬁnd discords.
Imagine that we break a time series T into two sections, A and B, and that we
ﬁnd the discords for both sections, recording their locations as A.l, B.l and values
as A.dist and B.dist, respectively. Furthermore, imagine that we now concatenate
A and B to reproduce the original time series T (for simplicity, let us assume that
when the discord for T is discovered, it will not span the end of A and the beginning
Finding the most unusual time series subsequence: algorithms and applications
of B). What can we now say about the discord for T? Surprisingly, the answer is
very little. We cannot assume that it will be either in location A.l or in location
|A| + B.l, because both of the two previously discovered discords may have good
matches in the other section. All we can do is give weak bounds. The value of
T.dist is at most max(A.dist, B.dist). The lower bound of T.dist is a trivial zero (to
see this, imagine A = B). As to the location of T.l, we can say nothing.
If we consider the complementary situation, where we know the discord information T.l and T.dist for T, and we split into two new time series A and B, we
are similarly frustrated. Assume that the discord from T happened to fall into A.
We can lower bound A.dist as being greater than or equal to T.dist, but we cannot
provide an upper bound. In addition, we can say nothing about the location of A.l.
As for B.dist and B.l, we can say nothing.
A combination of these two results also frustrates any thought of exploiting a
sliding window algorithm, since ingesting and egressing a single point can change
the location and value of the discords by an arbitrary amount.
The above results suggest that existing algorithms/paradigms are of little utility
for ﬁnding discords. This motivates the introduction of an original algorithm in the
next section.
3 Finding time series discords
The brute force algorithm for ﬁnding discords is simple and obvious. We simply
take each possible subsequence and ﬁnd the distance to the nearest non-self match.
The subsequence that has the greatest such value is the discord. This is achieved
with nested loops, where the outer loop considers each possible candidate subsequence, and the inner loop is a linear scan to identify the candidate’s nearest
non-self match. The pseudo-code is shown in Table 1.
Note that the algorithm requires exactly one parameter, the length of subsequences to consider. The algorithm is easy to implement and produces exact
Table 1 Brute force discord discovery
E. Keogh et al.
results. However, it has one fatal ﬂaw for data mining. It has O(m2) time complexity which is simply untenable for even moderately large datasets.
The following two observations offer hope to improve the algorithm’s running
Observation 1 In the inner loop, we do not actually need to ﬁnd the true nearest neighbor to the current candidate. As soon as we ﬁnd any subsequence that
is closer to the current candidate than the best so far dist, we can abandon that
instance of the inner loop, safe in the knowledge that the current candidate could
not be the time series discord.
Observation 2 The utility of the above optimization depends on the order which
the outer loop considers the candidates for the discord, and the order which the
inner loop visits the other subsequences in its attempt to ﬁnd a sequence that will
allow an early abandon of the inner loop.
While these are simple ideas and only minor modiﬁcations of the original algorithm, for concreteness, we will make them clear. The pseudo-code is shown in
Note that the input has been augmented by two heuristics, one to determine
the order in which the outer loop visits the subsequences, and one to determine
the order in which the inner loop visits the subsequences. Note that the heuristic
for the outer loop is used once, but the heuristic for the inner loop takes the current
candidate into account, and is thus invoked to produce a new ordering for every
iteration of the outer loop.
We have now reduced the discord discovery problem into a generic framework
where all one needs to do is to specify the heuristics. Note that we should not attempt to “cheat” the algorithm. We could provide very good heuristic orderings if
we are allowed to completely solve the brute force problem each time the heuristic
Table 2 Heuristic discord discovery
Finding the most unusual time series subsequence: algorithms and applications
functions are invoked! However, this is simply hiding the time complexity in a different part of the implementation. We must therefore insist that the Outer heuristic
(invoked only once) takes at most O(m) to calculate and the Inner heuristic (invoked m−n times) takes O(1). Note that this requirement precludes the possibility
of using R-trees, K-d trees or other classic indexing algorithms .
It is very important to recognize that while we are using heuristics to speed
up the search for discords, the results of the algorithm are exact, and completely
independent of heuristics used. The heuristics change only the speed of the algorithm.
To gain some intuition into our new algorithm, and to hint at our eventual
solution to this problem, let us consider three possible heuristic strategies:
• Random: We could simply have both the Outer and Inner heuristics randomly
order the subsequences to consider. It is difﬁcult to analyze this strategy since
its performance is bounded from below by O(m) and from above by O(m2) (see
below for explanation) and depends on the data. However, empirically it works
reasonably well. The conditional test on line 9 of Table 2 is often true and the
inner loop can be abandoned early, considerably speeding up the algorithm.
• Magic: In this hypothetical situation, we imagine that a friendly oracle gives us
the best possible orderings. These are as follows: For Outer, the subsequences
are sorted by descending order of the non-self distance to their nearest neighbor, so that the true discord is the ﬁrst object examined. For Inner, the subsequences are sorted in ascending order of distance to the current candidate. For
the Magic heuristic, the ﬁrst invocation of the inner loop will run to completion. Thereafter, all subsequent invocations of the inner loop will be abandoned
during the very ﬁrst iteration. The time complexity is thus one occurrence of
m −n +1 steps for the ﬁrst inner loop, and m −n occurrences of the O(1) step
of each subsequent invocation of the inner loop, giving a total time complexity
of O(m) + O(m) or just O(m). Note that we have m ≫n.
• Perverse: In this hypothetical situation, we imagine that a less than friendly
oracle gives us the worst possible orderings. These are identical to the Magic
orderings with ascending/descending orderings reversed. In this case, we are
back to the original O(m2) time complexity, and we waste some time in the
conditional tests on line 9 of Table 2.
These results are something of a mixed bag for us. They suggest that a linear
time algorithm is possible, but only with the aid of some very wishful thinking.
The Magic heuristic requires a perfect ordering of subsequences in the inner loop,
and any perfect ordering (i.e., sorting) requires at least O(m logm), but we are only
allowed O(1). Furthermore, the only known way to produce the perfect ordering
of subsequences in the outer loop requires O(m2) work, but we are only allowed
O(m) time. The following two observations, however, offer us some hope for a
fast algorithm.
Observation 3 In the outer loop, we do not actually need to achieve a perfect
ordering to achieve dramatic speedup. All we really require is that among the ﬁrst
few subsequences being examined, we have at least one that has a large distance to
its nearest neighbor. This will give the best so far dist variable a large value early
on, which will make the conditional test on line 9 of Table 2 be true more often,
thus allowing more early terminations of the inner loop.
E. Keogh et al.
Observation 4 In the inner loop, we also do not actually need to achieve a perfect
ordering to achieve dramatic speedup. All we really require is that among the ﬁrst
few subsequences being examined we have at least one that has a distance to
the candidate sequence being considered that is less than the current value of the
best so far dist variable. This is a sufﬁcient condition to allow early termination
of the inner loop.
We can imagine a full spectrum of algorithms, which only differ by how well
they order subsequences relative to the Magic ordering. This spectrum spans
{Perverse. . .Random. . .Magic}. Our goal then is to ﬁnd the best possible approximation to the Magic ordering, which is the topic of the next section.
At the risk of redundancy, we again emphasize that this search problem requires a specialized solution, and we cannot leverage off the huge literature on
time series similarity search . Kd-Trees, R-trees and their many variants require O(log(m)) time per lookup, but we can spare only O(1) time. In any case,
these search algorithms support nearest neighbor search, whereas all we require
here is “near-enough” neighbor search, as noted in observation 4.
4 Approximating the magic heuristic
Before we introduce our techniques for approximating the perfect ordering returned by the hypothetical Magic heuristics, we must brieﬂy review the Symbolic
Aggregate Approximation (SAX) representation of time series introduced by Lin
et al. . While there are at least 200 different symbolic approximation of time
series in the literature, SAX is unique in that it is the only one that allows both
dimensionality reduction and lower bounding of Lp norms. Since its relatively
recent introduction, SAX has become an important tool in the time series data
mining toolbox. It has been used to ﬁnd time series motifs , to mine rules
in health data , for anomaly detection , to extract features from a hepatitis
database , for visualization , and a host of other data mining tasks.
4.1 A brief review of SAX
A time series C of length n can be represented in a w-dimensional space by a vector ¯C = ¯c1, . . . , ¯cw. The ith element of ¯C is calculated by the following equation:
j=n/w(i−1)+1
In other words, to transform the time series from n dimensions to w dimensions, the data is divided into w equal sized “frames.” The mean value of the
data falling within a frame is calculated and a vector of these values becomes
the dimensionality-reduced representation. This simple representation is known
as Piecewise Aggregate Approximation (PAA) .
Having transformed a time series into the PAA representation, we can apply a
further transformation to obtain a discrete representation. It is desirable to have a
discretization technique that will produce symbols with equiprobability . In
Finding the most unusual time series subsequence: algorithms and applications
Table 3 A lookup table that contains the breakpoints that divides a Gaussian distribution in an
arbitrary number (from 3 to 5) of equiprobable regions
empirical tests on more than 50 datasets, we noted that normalized subsequences
have highly Gaussian distribution , so we can simply determine the “breakpoints” that will produce equal-sized areas under Gaussian curve.
Deﬁnition 9 Breakpoints: Breakpoints are a sorted list of numbers B
β1,. . .,βa−1 such that the area under a N(0,1) Gaussian curve from βi to βi+1 =
1/a (β0 and βa are deﬁned as −∞and ∞, respectively).
These breakpoints may be determined by looking them up in a statistical table.
For example, Table 3 gives the breakpoints for values of a from 3 to 5.
Once the breakpoints have been obtained we can discretize a time series in the
following manner. We ﬁrst obtain a PAA of the time series. All PAA coefﬁcients
that are below the smallest breakpoint are mapped to the symbol “a,” all coef-
ﬁcients greater than or equal to the smallest breakpoint and less than the second
smallest breakpoint are mapped to the symbol “b,”etc. Figure 3 illustrates the idea.
Note that in this example, the three symbols, “a,” “b,” and “c” are approximately equiprobable as we desired. We call the concatenation of symbols that
represent a subsequence a word.
Deﬁnition 10 Word: A subsequence C of length n can be represented as a word
ˆC = ˆc1, . . . , ˆcw as follows. Let ai denote the ith element of the alphabet, i.e.,
a1 = a and a2 = b. Then the mapping from a PAA approximation ¯C to a word ˆC
is obtained as follows:
iff β j−1 ≤¯ci < β j
Fig. 3 A time series (thin black line) is discretized by ﬁrst obtaining a PAA approximation
(heavy gray line) and then using predetermined breakpoints to map the PAA coefﬁcients into
symbols (bold letters). In the example above, with n = 128, w = 8 and a = 3, the time series is
mapped to the word cbccbaab
E. Keogh et al.
We have now completely deﬁned SAX representation. Note that our observation that normalized subsequences have highly Gaussian distribution is not
critical to correctness of any of the algorithms that use SAX, including the ones
in this work. A pathological dataset that violates this assumption will only affect
the efﬁciency of the algorithms.
4.2 Approximating the Magic Outer loop
We begin by creating two data structures to support our heuristics. We are given
n, the length of the discords in advance, and we must choose two parameters, the
cardinality of the SAX alphabet size a, and the SAX word size w. We defer a
discussion of how to set these parameters until later in this section, but note that
the values of α and w only affect the efﬁciency of our algorithm, not the ﬁnal
result, which depends only on the user supplied length of the discord.
We begin by creating a SAX representation of the entire time series, by sliding
a window of length n across time series T, extracting subsequences, converting
them to SAX words, and placing them in an array where the index refers back to
the original sequence. Figure 4 gives a visual intuition of this, where both a and w
are set to 3.
(m – n) -1
Subsequence extracted
Converted to SAX
Inserted into array
Raw time series
Augmented Trie
(m – n) +1
(m – n) -1
(m – n) -1
Subsequence extracted
Converted to SAX
Inserted into array
Raw time series
Augmented Trie
(m – n) -1
(m – n) -1
Subsequence extracted
Converted to SAX
Inserted into array
Raw time series
Augmented Trie
(m – n) +1
(m – n) -1
Fig. 4 The two data structures used to support the Inner and Outer heuristics. (Left) An array of
SAX words, where the last column contains a count of how often each word occurs in the array.
(Right) An excerpt of a trie with leaves that contain a list of all array indices that map to that
terminal node
Finding the most unusual time series subsequence: algorithms and applications
Note that the index goes from 1 to (m −n) + 1, because the right edge
of n-length sliding window “bumps” against the end of the m-length time
Once we have this ordered list of SAX words, we can imbed them into an
augmented trie where the leaf nodes contain a linked list index of all word occurrences that map there. The count of the number of occurrences of each word can
be mapped back to the rightmost column of the array. For example, in Fig. 4, if
we are interested in the word caa, we visit the trie to discover that it occurs in
locations 1, 3, and 731. If we are interested in the word that occurs at a particular
location, let us say (m −n) −1, we can visit that index in the array and discover
that the word cbb is mapped there. Furthermore, we can see by examining the
rightmost column that there are a total of two occurrences of that particular word
(including the one we are currently visiting). However, if we want to know the
location of the other occurrence, we must visit the trie.
Surprisingly, both data structures can be created in time and space linear in
the length of T . In fact, if we take advantage of the fact that we only need
⌈log2(a)⌉bits for each SAX symbol, then both data structures are signiﬁcantly
smaller than the raw time series data they were derived from.
We can now state our Outer heuristic; we scan the rightmost column of
the array to ﬁnd the smallest count mincount (its value is virtually always 1).
The indices of all SAX words that occur mincount times are recorded, and
are given to the outer loop to search over ﬁrst. After the outer loop has exhausted this set of candidates, the rest of the candidates are visited in random
The intuition behind our Outer heuristic is simple. Unusual subsequences are
very likely to map to unique or rare SAX words. By considering the candidate
sequences that map to unique or rare SAX words early in the outer loop, we have
an excellent chance of giving a large value to the best so far dist variable early
on, which (as noted in observation 3) will make the conditional test on line 9 of
Table 2 be true more often, thus allowing more early terminations of the inner
4.3 Approximating the Magic Inner loop
Our Inner heuristic also leverages off the two data structures shown in Fig. 4.
When candidate i is ﬁrst considered in the outer loop, we look up the SAX word
that it maps to, by examining the ith word in the array. We then visit the trie
and order the ﬁrst items in the inner loop in the order of the elements in the
linked list index found at the terminal nodes. For example, imagine we are working on the problem shown in Fig. 4. If we were examining the candidate C731
in the outer loop, we would visit the array at location 731. Here we would ﬁnd
the SAX word caa. We could use the SAX values to traverse the trie to discover that subsequences 1, 3, 731 map here. These three subsequences are visited
ﬁrst in the inner loop (note that line 8 of Table 1 prevents 731 from being compared to itself). After this step, the rest of the subsequences are visited in random
The intuition behind our Inner heuristic is also simple. Subsequences that
have the same SAX encoding as the candidate subsequence are very likely to
E. Keogh et al.
be highly similar (this fact is at the heart of more than 20 research efforts
 ). As noted in observation 4, we just need to ﬁnd one such
subsequence that is similar enough (has a distance to the candidate than the current
value of the best so far dist variable) in order to terminate the inner loop. Because
our algorithm works by using heuristics to order SAX sequences, we call it HOT
SAX, short for Heuristically Ordered Time series using Symbolic Aggregate Approximation.
4.4 Minor optimizations and parameter setting
There are several minor optimizations we can apply to the heuristic search algorithm. For example, imagine we are considering candidate Ci in the outer loop,
and as we traverse through the inner loop, we ﬁnd that subsequence C j is close
enough to it to allow early abandonment. In addition to saving time with the early
termination, we can also delete C j from the list of candidates in outer loop (if it
has not already been visited). The key observation is that since we are assuming
a symmetric distance measure, if nearness to C j disqualiﬁes candidate Ci from
being the discord, then the same nearness to Ci would also disqualify candidate
C j from being the discord. Empirically, this simple optimization gives a speed-up
factor of approximately 2. In addition, there are several well-known optimizations
to the Euclidean distance that we can use .
As noted above, we must choose two parameters, the cardinality of the SAX
alphabet size a and the SAX word size w. Recall what it is we want to optimize. We would like the distribution of the SAX words to be highly skewed, so
that the discord will map to a SAX word that is unique or rare, and all the other
subsequences will map to SAX words that are very frequent. This is the best situation for both our heuristics. If we choose very large values of a and/or w, almost
all subsequences will map to unique words; if we choose very small values of a
and/or w, all subsequences will map to just a small handful of words. Either of
these situations is bad for our heuristics.
The good news is that there is little freedom for the a parameter; extensive
experiments carried out by the current authors and dozens of
other researchers worldwide suggest that a value of either 3 or 4
is best for virtually any task on any dataset. After empirically conﬁrming this on
the current problem with experiments on more than 50 datasets, we will simply
hardcode a = 3 for the rest of this work. Having ﬁxed a, we performed an exhaustive empirical examination of the role of the w parameter. The best value for this
parameter depends on the data. In general, relatively smooth and slowly changing
datasets favor a smaller value of w, whereas more complex time series favor a
larger value of w. The following observations mitigate the problem of parameter
The speedup does not critically depend on w parameter. After empirically ﬁnding the best value on a particular data we found we could vary the value of w in
the range of 60–150% with less than a 12% decrease in speedup.
Once we learn a good setting on a particular data type, say ECGs, that setting
will also work well on other datasets of the same type (assuming the sampling rate
is the same).
Finding the most unusual time series subsequence: algorithms and applications
5 Empirical evaluation
We begin by showing the utility of time series discords for a several medical domains, then go on to show that our algorithm is able to ﬁnd discords very efﬁciently.
5.1 The utility of time series discords
In this paper, we will only demonstrate the utility of discords as anomaly detectors.
We have done extensive successful experiments in other tasks, such as improving
the quality of clustering and summarization; however, anomaly detection is unique
in that it allows immediate and intuitive visual conﬁrmation. The additional experiments for other tasks, together with many extra anomaly detection experiments
can be found here . We encourage the interested reader to consult this site for
additional examples and larger and more detailed ﬁgures of the experiments shown
After much reﬂection, we have decided not to include comparisons to other
approaches here. There are two reasons for this. Firstly, it is very difﬁcult to make
meaningful comparisons between our method, which requires only one intuitive
parameter, and some of the rival methods that require three to seven parameters
(see for a detailed discussion of this), including some parameters for which
we may have poor intuition, such as Embedding dimension , Kernel function
 , SOM topology or number of Parzen windows.
The second reason we do not compare to other anomaly detectors is that most
algorithms require a separate training dataset (in order to learn the parameters),
whereas our approach ﬁnds anomalies while only examining the test dataset. One
could easily imagine generalizing the discord discovery algorithm to examine only
the test data in the outer loop and only training data in the inner loop. However, we
wish to concentrate on ﬁrst proving our simple intuitive deﬁnitions before creating
generalizations.
5.2 Anomaly detection in electrocardiograms
Electrocardiograms (ECGs) are a time series of the electrical potential between
two points on the surface of the body caused by a beating heart. They are arguably
the most important time series, and as such, there are many annotated test datasets
we can consider. We have already considered the utility of discords in one ECG
in Fig. 1. That was a very simple and “clean” example for clarity; however, it is
remarkable how varied and complex normal healthy ECGs can be. For example,
Fig. 5 shows a very complicated signal with remarkable variability. Surprisingly,
this ECG contains only one small anomaly, which is easily discovered by a discord
detection algorithm.
In Fig. 6, we consider an ECG that has several different types of anomalies.
Here, the ﬁrst three discords exactly line up with the cardiologist’s annotations.
In this ﬁgure we could perhaps spot the anomalies by eye; however, the full time
series is much longer, and impossible to scrutinize without a scrollbar and much
E. Keogh et al.
BIDMC Congestive Heart Failure Database: Record 15
BIDMC Congestive Heart Failure Database: Record 15
Fig. 5 An ECG that has been annotated by a cardiologist (bottom bar) as containing one premature ventricular contraction. The discord256 (bold line) exactly coincides with the heart anomaly
MIT-BIH Arrhythmia Database: Record 108
1st Discord
2nd Discord
3rd Discord
MIT-BIH Arrhythmia Database: Record 108
1st Discord
2nd Discord
3rd Discord
Fig. 6 An excerpt of an ECG that has been annotated by a cardiologist (bottom bar) as containing three various anomalies. The ﬁrst three discord600 (bold lines) exactly coincide with the
In the above cases, we simply set the length of the discords to be approximately
one full heartbeat (note that the two datasets have different sampling rates). Although we found that we could double or half the parameters without affecting the
quality of results, on just a handful of the dozens of ECG datasets we examined,
the discords had a harder time ﬁnding the anomalous heartbeats. One of the authors of the current work, Helga Van Herle, M.D., is a cardiologist. She informed
us that heart irregularities can sometimes manifest themselves at scales signiﬁcantly shorter than a single heartbeat. Armed with this knowledge, we searched
for discords at approximately one-fourth the length of a single heartbeat. In Fig.
7, we show the results of a search with the shorter length discords.
While the result is satisfying in that it immediately locates the anomaly, it
is not obvious from the ﬁgure that the discord is actually different for the other
heartbeats. In Fig. 8 (left) we see a zoom-in of the subsequence surrounding the
QT Database: Record 0606
QT Database: Record 0606
Fig. 7 An ECG that has been annotated by a cardiologist (bottom bar) as containing one premature ventricular contraction. The discord40 (bold line) exactly coincides with the heart anomaly
Finding the most unusual time series subsequence: algorithms and applications
Fig. 8 (Left) A zoom-in of a section of Fig. 7. The ﬁrst heartbeat has been annotated with the
classic PQRST notation. (Right) Five ST waves from Fig. 7 (including the discord) hierarchically
discord, and we can see that the discord falls over the ST wave. In Fig. 8 (right),
we manually extracted four ST waves from the subsequence in Fig. 7 and clustered
them together with the discord. This makes the source of the anomaly apparent.
Note that in the four normal ST waves, after the brief descending section, the
signal rises monotonically. However, the anomalous ST wave has an additional
local peak caused by a premature beat, thus justifying the cardiologist’s diagnosis
of premature ventricular contraction.
5.3 Change detection in patient monitoring
The problem of change detection is fundamentally different from anomaly detection. In anomaly detection, the task is to ﬁnd one or more “different” subsequences
that exist in the background of a normal data. In the problem of change detection,
we assume that the underlying model that produces the signal changes in some
(possibly very subtle) way at various points. The task is to identify the locations
of these change points.
Time series discords do not appear to be likely candidates for change detection, since they look at local patterns, whereas most change detection algorithms
consider global (or at least much larger “local”) information. However, we believe that in some situations, the change in underlying global model may produce
some unusual local shapes because the local pattern must straddle two different
To test this idea, we investigated a time series showing a patient’s respiration (measured by thorax extension), as they wake up. A medical expert, Dr.
J. Rittweger of the Institute for Physiology, Free University of Berlin, manually segmented the data. We choose a discord length corresponding to 32 s because we want to span several breaths. In Fig. 9, we see the outcome of the ﬁrst
experiment.
The ﬁrst discord is a very obvious deep breath taken as the patient opened
their eyes. In contrast, the second discord is much more subtle and difﬁcult to see
at this scale. A zoom-in suggests that Dr. Rittweger noticed a few shallow breaths
that indicated the transition of sleeping states. In both cases the discords straddle
the change in sleeping cycle. We tested many such datasets with equally positive
results. Figure 10 shows another representative example.
E. Keogh et al.
Stage II sleep
Eyes closed, awake/stage I sleep Eyes open, awake
Shallow breaths as waking cycle begins
1st Discord
2nd Discord
Stage II sleep
Eyes closed, awake/stage I sleep Eyes open, awake
Stage II sleep
Eyes closed, awake/stage I sleep Eyes open, awake
Shallow breaths as waking cycle begins
1st Discord
2nd Discord
Fig. 9 The ﬁrst two discords found in a time series of a patient’s respiration as they wake up.
The annotations show in the boxes at the bottom of the screen are provided by a medical expert
Stage II sleep
Stage I sleep
1st Discord
2nd Discord
Stage II sleep
Stage I sleep
1st Discord
2nd Discord
Fig. 10 The ﬁrst two discords found in a time series of a patient’s respiration
5.4 Power demand data exploration
The experiments above were performed in domains where objective answers are
readily available. In this section, we perform an experiment where the only evaluation is the intuitiveness of the discords discovered.
We queried a dataset that measured the power consumption for a Dutch research facility for the entire year of 1997. We wanted to ﬁnd the three most usual
weeks. Note that we did not specify that week should begin at certain day or time.
We initially guessed that a length of 750 would cover an entire week; this turns out
to be a little long, but we show this experiment to avoid “polishing” the results.
Figure 11 shows the result of ﬁnding the top three discords in this dataset.
In Fig. 12 we show a zoom-on of the discords discovered. Intuitively, they are
all unusual in that they are from weeks in which two weekdays are holidays.
3rd Discord
One years power demand at a Dutch research facility
1st Discord
2nd Discord
3rd Discord
One years power demand at a Dutch research facility
1st Discord
2nd Discord
Fig. 11 The ﬁrst three discords found in a dataset of power consumption for a Dutch research
facility for the entire year of 1997
Finding the most unusual time series subsequence: algorithms and applications
Liberation Day
Ascension Thursday
Good Friday
Easter Sunday
Typical Week from the Dutch
Power Demand Dataset
Fig. 12 (Left) A typical week from the Dutch power demand dataset (shown in full in Fig. 11)
shows the classic 9 a.m. to 5 p.m., Monday to Friday, pattern of power demands. (Right) The top
three discords of length 750 shows unusual weeks in that they all contain two holidays
5.5 Shape database exploration
In this experiment we consider a primatological dataset. In particular, we are working with noted physical anthropologist, Dr. Sang-Hee Lee, on various problems
in indexing, classifying and clustering large collections of skulls and bones. The
following two observations allow us to mine this data resource with our discord
discovery tool.
• The idea of converting shapes to time series is at least two decades old. There
are dozens of possible ways to do this, we use the simple method discussed by
Ratanamahatana et al. .
• All our experiments thus far have assumed that the time series subsequences
have been obtained from a sliding window. However, this need not be the case,
the subsequences could come from any collection of individual subsequences,
so long as they are all of the same length. For example, the input could be
individual heartbeats, individual weeks of power demand, or as in this case,
individual shape proﬁles
We ran our discord discovery algorithm on a several large collections of primate skulls . In one experiment we found a strong discord in the Orangutan
(Pongo) database, a database that contains a diverse collection of Orangutan images, including males/females, adults/juveniles, Borneo/Sumatran, etc. Figure 13
shows the discord discovered.
Even a casual visual inspection conﬁrms that the discord discovered is truly
unlike the others, but what is the signiﬁcance of this? To answer this question we
retrieved the original image and showed it to our domain expert. Dr. Lee had an
immediate explanation of our ﬁnding. The skull in question was not an Orangutan,
but a Howler monkey misﬁled by a graduate student! Figure 14 shows the original
image corresponding to the discord.
We calculated the difference between the two shapes by the measuring the Euclidean difference between the discord and the mean of all other time series. Note
that the major differences all have obvious anatomical meaning . The two
largest peaks correspond to most distinctive and unusual feature of the Howler
monkey, its massive jaw (corpus and gonion) which is used to produce its eponymous sound (it is believed to be the loudest land mammal). The Howler monkey
also has a highly angular inion, the ectocranial midline point at the base of the
external occipital protuberance, whereas the Orangutan has the more rounded in-
E. Keogh et al.
Specimen 1
Specimen 17
Specimen 12 (1st Discord)
Specimen 94
Fig. 13 (Top) A shape can be converted to a time series by examining the local curative of
the perimeter. In this case the lateral view of an adult Borneo Orangutan (Pongo pygmaeus
pygmaeus) is converted. (Bottom) A selection of the time series for the Orangutan database
shows that most are similar to each other, but specimen 12 is clearly different to the rest, and is
the discord
ion, which is typical of all the great apes. Finally, the Orangutans do not have
an extruding rhinion (informally “nose,” or more correctly the midline point at
the inferior free end of the internasal suture), whereas the Howler monkey has a
pronounced one .
5.6 Video data exploration
For our ﬁnal experiment on the usefulness discords, we examined a video dataset.
For concreteness, we will brieﬂy discus how the data was extracted.
A Canon ZR40 camcorder with the shutter at 1/60, video size of 720 × 480
pixels, and frame rate of 30 frames/s, was used to record the actions of a female
actor. Only the actor’s right hand was tracked, to facilitate this she wore a red
glove on that hand only. A frame that has good color visibility was selected from
the video sequence. The selected frame is then used to calculate Hue, Saturation,
and Value from each pixel. A region of the color to be tracked (red in this case)
is also selected and this forms the region of interest (ROI). The HSV from each
pixel of the selected frame, along with the mean and covariance from the ROI of
the selected frame form the input to ﬁnd probability distribution for the ROI over
the whole image. The probability distribution uses a multivariate Gaussian and
results in a probability matrix of the size of the image. This resultant matrix is
converted to a binary image by thresholding, and then the resultant binary image
is used to compute the centroid position of the hand. The overall dataset is of very
high quality, however there is some noise and dropouts due to occlusion, etc. The
entire dataset consists of just over 200,000 datapoints.
Finding the most unusual time series subsequence: algorithms and applications
Red Howler
Red Howler
Fig. 14 (Bottom) The discord shown in Fig. 13 belongs to a misﬁled Red Howler Monkey. (Top)
A typical adult Borneo Orangutan for contrast. (Middle) The heavy (green) time series shows
the difference between the two shapes and was annotated by a physical anthropologist
The actor was asked to perform a variety of actions 50 times in a row, with
a short pause in-between. The actions consisted of two classes, “Innocuous,” for
example, pointing to photograph on the wall, and “Threatening,” for example,
drawing a replicate ﬁrearm from a holster and aiming it.
A time series was extracted from a video of an actor performing various actions with and without a replica gun. The time series measures the Y-coordinate
of the actor’s right hand.
The data was originally collected to provide data for a time series classiﬁcation
problem, and has been used for that task many times . We ran our algorithm
to ﬁnd the discord of length 150 (equivalent to 3 s of video), the result is shown in
Fig. 15 An excerpt of a time series that was extracted from a video of an actor performing
various actions with and without a replica gun. A discord of length 150 (3 s of video) was
discovered beginning at time 300
E. Keogh et al.
Hand resting at side
Actor misses holster
swings gun
at target,
Laughing and flailing hand
Hand wobbles
suppresses
Hand resting at side
Actor misses holster
swings gun
at target,
Laughing and flailing hand
Hand wobbles
suppresses
Fig. 16 A zoom-in of a section of Fig. 15 with a ﬁlm strip overall from the original video.
About 10 s into the shoot, the actor misses the holster when returning the gun. An off-camera
(inaudible) remark is made, and the actor looks toward the video technician, and then convulses
with laughter. At one point (frame 415) she is literally bent double with laughter
Recall that the time series is of length 20,000, so the above ﬁgure is only
showing a 10% excerpt. The discord does appear to be intuitive, in that the shape
of the discord appears to be different from that of its neighbors. However, it is not
obvious as to what this discord means, if anything. In Fig. 16 we show a zoom-in
of the discord augmented by screen captures from the original video.
We see that a typical sequence starts with the actor’s hands by her sides, she
grabs the gun from the holster and aims it at a target. The sequence concludes
with the actor retuning the gun to the holster and her hand to her side. For the
ﬁrst two events (from time 1 to 300), the actor makes two successful gun draws.
However, at time 300, when returning the gun to the holster, the actor misses. She
looks at the video technician, who has made a remark, she smiles and attempts to
continue, but she is not looking at the target. She brieﬂy convulses with laughter,
at one point she is literally bent double with laughter, and then quickly regains
composure.
5.7 The utility of HOT SAX search
It is increasingly recognized that comparing algorithm performance by examining
wall clock or CPU time invites the possibility of implementation bias , which
in turn invites the possibility of irreproducible “improvements.” Instead, we measure here the number of times that the distance function is called on line 9 in Tables
1 and 2. A simple analysis of the pseudo-code (conﬁrmed with a proﬁler) tells us
that this single line of code accounts for more than 99% of the running time for
both algorithms. In addition to fairness and reproducibility, there is another pragmatic reason for this metric. For brute force search, this number depends only on
n and m and can simply be computed (recall m is the length of the time series
and n is the length of the subsequence). If we had to actually measure the wall
clock time for brute force search for all the experiments in this work, it would
take several years.
The above metric does not include the time it takes to build the data structures
discussed in Sect. 4.2; however, we note that this is a O(m), one time cost. For
Finding the most unusual time series subsequence: algorithms and applications
log(number of calls to dist)
m, the length of time series T
a factor of 2,902
Brute Force
(all datasets)
qtdbsel102
Random walk
log(number of calls to dist)
m, the length of time series T
a factor of 2,902
Brute Force
(all datasets)
qtdbsel102
Random walk
Fig. 17 The number of calls to the distance function required by brute force and heuristic search
for discord128 over a range of data sizes for ﬁve representative datasets
datasets of a reasonable size (i.e., the datasets shown in Figs. 11 or 12), this overhead takes much less than 0.1% of the total time. Furthermore, as the datasets get
larger, it takes an even smaller percentage of time.
In Fig. 17, we compare the brute force algorithm to the heuristic search algorithm in terms of the number of times the Euclidean distance function on line
9 is called. For the heuristic search we averaged the results for each setting of
dataset/length over 100 runs on different subsets of the data.
Note that as the data sizes increase, the differences get larger. For a time series
of length 64,000, the heuristic algorithm is almost 3000 times faster than brute
force for all datasets. This experiment is actually pessimistic in that we made
sure that the test data did not have any obvious anomalies or unusual patterns. In
general, if there are truly unusual patterns in the time series, the heuristic algorithm
is even faster.
In general, these results strongly suggest that we can reasonably expect at least
three orders of magnitude of a speedup for most problems. To concretely ground
these numbers, consider the following. While our current implementation is in relatively lethargic Matlab, the experiments shown in Figs. 10–12 take a few seconds
using heuristic search, but several hours using brute force search.
To make sure that the above results were not the result of a happy coincidence
of “easy” datasets and the right setting of the single parameter, we repeated the
experiment for every dataset in the UCR Time Series Data Mining Archive over a
range of values for n. We tested all datasets that have a length of at least 16,000;
there are currently 82 such datasets from a diverse set of domains. Figure 18 shows
the results.
This experiment produces pessimistic results in that many of the datasets we
averaged over are exceptionally noisy. In addition, the maximum size of the data
(16 k) was relatively small to allow us to average over many datasets. Nevertheless, the results support the contention that a minimum speedup of two orders of
E. Keogh et al.
n, the discord length
m, the size of the database
Speedup over brute force
n, the discord length
m, the size of the database
Speedup over brute force
Fig. 18 The speed obtained over brute force search for various discord lengths and database
sizes, averaged over 82 diverse datasets
magnitude can be expected for any combination of dataset and value for n, and
even greater speedup can be expected as the datasets get larger.
We also considered the Perverse and Random heuristics on the above problem.
As one might expect, perverse has exactly same performance as brute force search.
The Random heuristic typically produces an approximately 10-fold speedup over
brute force, independent of the value of m, while this is not insigniﬁcant, it is
completely dwarfed by the Magic heuristic.
6 Conclusions and future work
In this work, we have deﬁned time series discords, a new primitive for time series
data mining. We introduced a novel algorithm called HOT SAX to efﬁciently ﬁnd
discords and demonstrated their utility on a host of domains.
Many future directions suggest themselves; most obvious among them are extensions to multidimensional time series, to streaming data, and to other distance
measures. In addition, for truly massive datasets, even the large speedups obtained
may be insufﬁcient for real time interaction. We therefore plan to investigate an
anytime version of our algorithm. Finally, the tentative experiment in Sect. 5.5
suggests that discord discovery may be useful for image datasets, this is an area of
research we are actively pursuing.
Acknowledgements We gratefully acknowledge the datasets donors. We also acknowledge insightful comments from Chotirat Ann Ratanamahatana. We thank the reviewers who made valuable comments and suggestions. Thanks also to Li Wei and Xiaopeng Xi for help with the image
processing algorithms. This research was partly funded by the National Science Foundation under grant IIS-0237918.
Finding the most unusual time series subsequence: algorithms and applications
Reproducible results statement: In the interests of competitive scientiﬁc inquiry, all datasets
used in this work are available at the URL given in .