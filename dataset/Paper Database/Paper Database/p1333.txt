Machine Learning-Based Early Detection of IoT
Botnets Using Network-Edge Trafﬁc
Ayush Kumar∗, Mrinalini Shridhar†, Sahithya Swaminathan†, and Teng Joon Lim‡
∗Singapore University of Technology and Design, Singapore
†National University of Singapore, Singapore
‡University of Sydney, NSW 2008, Australia
Abstract—In this work, we present a lightweight IoT botnet
detection solution, EDIMA, which is designed to be deployed
at the edge gateway installed in home networks and targets
early detection of botnets prior to the launch of an attack.
EDIMA includes a novel two-stage Machine Learning (ML)based detector developed speciﬁcally for IoT bot detection at
the edge gateway. The ML-based bot detector ﬁrst employs ML
algorithms for aggregate trafﬁc classiﬁcation and subsequently
Autocorrelation Function (ACF)-based tests to detect individual
bots. The EDIMA architecture also comprises a malware trafﬁc
database, a policy engine, a feature extractor and a trafﬁc parser.
Performance evaluation results show that EDIMA achieves high
bot scanning and bot-CnC trafﬁc detection accuracies with very
low false positive rates. The detection performance is also shown
to be robust to an increase in the number of IoT devices connected
to the edge gateway where EDIMA is deployed. Further, the
runtime performance analysis of a Python implementation of
EDIMA deployed on a Raspberry Pi reveals low bot detection
delays and low RAM consumption. EDIMA is also shown to
outperform existing detection techniques for bot scanning trafﬁc
and bot-CnC server communication.
Index Terms—Internet of Things, IoT, Malware, Mirai, Reaper,
Satori, Botnet, Botnet Detection, Machine Learning, Anomaly
Detection, Intrusion Detection
I. INTRODUCTION
The Internet of Things (IoT) is a network of sensing
devices with low-power and limited processing capability,
which exchange data with each other and/or systems (e.g.,
gateways, cloud servers), normally using wired (e.g., Ethernet)
and wireless technologies (e.g., RFID, Zigbee, WiFi, Bluetooth, 3G/4G). IoT devices are used in a number of applications such as wearables (ﬁtness trackers, smart watches),
home automation (lighting systems, thermostats, cameras, door
locks) and industrial automation (manufacturing equipment/asset management, process control, plant safety). Globally, the
total number of IoT devices deployed by 2025 is estimated to
reach 41.6 billion .
Unfortunately, hackers are increasingly targeting IoT devices using malware (malicious software) due to the following
reasons – :
• Many legacy IoT devices are connected to the Internet
for which security updates are not installed regularly.
• Low priority is given to security within the development
cycle of IoT devices.
• It is computationally expensive and often infeasible to
implement conventional cryptography in IoT devices due
to processing power and memory constraints.
• Weak login credentials are present in many IoT devices
which are either hard-coded by the manufacturer or
conﬁgured by users.
• Sometimes, backdoors (such as an open port) are left by
IoT device manufacturers to provide remote support for
the device.
• Consumer IoT devices or the gateway through which
they connect to the Internet, often do not have a ﬁrewall
installed.
On October 21, 2016, attackers launched the biggest Distributed Denial-of-Service (DDoS) attack on record using a
botnet consisting of IoT devices (IP cameras, DVRs) infected
with the IoT malware Mirai, targeting the Dyn Domain Name
Service (DNS) servers . The Mirai source code was leaked
in 2017 and since then, it has been re-used by script “kiddies”
as well as professional hackers to build their own IoT malware.
These malware are either variants of Mirai, which perform
a similar brute force scan of random IP addresses for IoT
devices with open TELNET ports and attempt to login using a
built-in dictionary of credentials (e.g., Remaiten, Hajime), or
more sophisticated ones that exploit software vulnerabilities
in IoT devices to execute remote command injections (e.g.,
Reaper, Satori, Masuta, Linux.Darlloz, Amnesia). The various
components of a typical IoT botnet and how they work with
each other is explained in by taking the example of Mirai.
Bots compromised by IoT malware can be used for DDoS
attacks, spamming, phishing and bitcoin mining , .
These attacks can cause network downtime for long periods leading to ﬁnancial losses for Internet Service Providers
(ISP), leakage of users’ conﬁdential data, and unauthorized
exploitation of computational resources. Attacks originating
from IoT botnets have continued unabated and have in fact,
increased since the infamous 2016 Mirai DDoS attack. The
author of IoT malware Satori and its improved versions
(Masuta, Okiru), pleaded guilty in September 2019 to creating
and managing botnets enslaving hundreds of thousands of
IoT devices (including security cameras, DVR systems, home
routers), launching DDoS attacks against various targets (e.g.,
ProxyPipe, a DDoS mitigation ﬁrm) using these botnets and
running DDoS-for-hire services during the 2017-18 period
 . Kaspersky claimed to have detected 105 million attacks
on its IoT honeypots spread over the globe in the ﬁrst six
months of 2019, a signiﬁcant increase from the 12 million
 
attacks detected in 2018 . On April 24, 2019, a botnet
consisting of more than 400,000 IoT devices (home routers,
modems, and other CPEs) launched a massive DDoS attack
against a Content Distribution Network (CDN) company in
the entertainment industry that lasted 13 days with peak attack
ﬂows reaching 292,000 HTTP GET/POST requests per second,
making it one of the largest Layer 7 attacks handled by the
DDoS mitigation ﬁrm, Imperva . DDoS attacks using IoT
botnets continue to grow in number as well as frequency,
according to The State of DDoS Weapons report published
by A10 Networks for the fourth quarter of 2019 .
Furthermore, it is to be expected that many of the infected
devices will remain so for a long time. Most IoT malware do
not persist after the host device undergoes a reboot, but the
device is likely to be reinfected soon by the same or another
malware. Therefore, there exists a strong motivation to detect
these IoT bots and manage them appropriately. It has been
pointed out in that it is futile to attempt to ensure that all
IoT devices are secure-by-construction. Deploying traditional
host-based detection and prevention mechanisms such as antivirus and ﬁrewalls for IoT devices is practically infeasible.
Therefore, security mechanisms for the IoT ecosystem should
be designed to be network-based rather than host-based.
We propose a lightweight IoT botnet detection solution,
EDIMA (Early Detection of IoT Malware Scanning and CnC
Communication Activity), which is designed to be deployed
at the edge gateway installed in home networks and targets
the detection of botnets at an early stage of their evolution
before they can be used for further attacks. EDIMA employs
a two-stage detection mechanism which ﬁrst uses Machine
Learning (ML) algorithms for aggregate trafﬁc classiﬁcation
based on bot scanning trafﬁc patterns, and subsequently Autocorrelation Function (ACF)-based tests which leverage bot-
CnC messaging characteristics at the per-device trafﬁc level
to detect individual bots. We only target IoT botnets with
centralized Command-and-Control (CnC) architecture in this
work. Historically, centralized botnets have been more widely
deployed in real-world networks (PC-based as well as IoT),
compared to Peer-to-Peer (P2P) botnets as they are easier
to set up and manage, though P2P botnets that avoid the single
point-of-failure in centralized botnets are growing in number.
EDIMA also includes a database that stores malware trafﬁc
packet captures, a policy engine which determines the further
course of action if gateway trafﬁc has been classiﬁed as
malicious and a trafﬁc parser/sub-sampler which sorts the
aggregate gateway trafﬁc and optionally sub-samples the trafﬁc
at a speciﬁed rate. EDIMA can be deployed both on physical
edge gateways or as Network Function Virtualization (NFV)
functions at the customer premises in an SDN-NFV based
network architecture, where SDN stands for Software-Deﬁned
Networking. EDIMA can also be deployed alongside an intrusion detection system at the gateway.
Justiﬁcation For ML-based Detection: While TELNET port
scanning can be countered by deploying a ﬁrewall or intrusion
detection system (at the edge gateway) which blocks incoming/outgoing TELNET trafﬁc, malware that exploit software
vulnerabilities targeting application protocols such as HTTP,
SOAP, PHP, etc., are difﬁcult to block using a rule-based
approach because these protocols are used by legitimate trafﬁc
as well. Furthermore, deep-packet inspection IDS is not a practically viable solution for consumer IoT devices (connected to
ISP networks through gateways) which are the focus of our
work. It is computationally too expensive to be deployed at
such gateways and requires specialized hardware. Hence, we
propose to use an ML-based approach instead for detecting
those sophisticated IoT malware. Utilizing carefully selected
malware trafﬁc features independent of application protocols,
ML algorithms can be trained to distinguish between benign
and malicious trafﬁc (containing malware-generated packets).
EDIMA targets IoT botnets at an early stage of their
evolution, when they are scanning for and infecting vulnerable
devices, as the scanning and propagation phase of the botnet
life-cycle stretches over several months . This means that
IoT bots can be detected and isolated long before they can
be used for attacks such as DDoS. If a botnet has reached
substantial size and started launching attacks already, they can
be detected using existing methods in literature and industry
to defend against such attacks.
The major contributions of this paper are listed below:
1) We characterize the scanning and bot-CnC server communication trafﬁc patterns for IoT malware.
2) We propose a lightweight IoT botnet detection solution,
EDIMA, employing a two-stage detection mechanism
which ﬁrst uses ML techniques for aggregate trafﬁc
classiﬁcation at the edge gateway and subsequently, ACFbased tests to detect individual bots. We also evaluate
EDIMA’s detection performance comprehensively.
3) We implement EDIMA using Python, deploy it on a
Raspberry Pi and evaluate its runtime performance.
A preliminary version of this work was presented in .
The following points illustrate the ways in which we have
expanded upon our previous work:
• We have reﬁned the architecture for our proposed IoT
botnet detection solution, EDIMA, and explained the
functions of its modules in greater detail.
• New features have been added for detection of scanning
activity in aggregate gateway trafﬁc.
• We have introduced a novel, second stage for individual
bot detection after the ﬁrst stage of aggregate gateway
trafﬁc classiﬁcation.
• The performance evaluation testbed has been expanded
to include more IoT devices.
• Instead of emulating the behavior of IoT malware to
generate malicious trafﬁc training data as done in our
previous work, we use real, live malware samples.
• Unlike our previous work, we have followed all the
required steps for data processing before applying ML
classiﬁers.
• We have done a performance comparison with few existing works in literature.
• We have also evaluated the scalability performance and
runtime performance of a software implementation of
The rest of this paper is organized as follows. In Section II,
we review a few prominent works on detecting botnets exploiting CnC communication features, intrusion and anomaly detection systems for IoT, detecting attacks originating from IoT
botnets, and IoT device trafﬁc ﬁngerprinting. Subsequently,
in Section III, our proposed IoT botnet detection solution,
EDIMA is presented while in Section IV, the operation
of EDIMA’s modules is described in more detail. Finally,
in Section V, we present the aggregate trafﬁc classiﬁcation
and bot detection performance results for EDIMA, evaluate
the runtime performance of its Python implementation and
compare EDIMA’s performance with previous works.
II. RELATED WORK
Botnet detection using scanning trafﬁc features has not
been adequately addressed in the literature. In particular,
there are no existing works on IoT botnet detection using
scanning trafﬁc features. However, there have been several
prominent works on detecting PC-based botnets using their
CnC communication features. In , ML-based techniques
for CnC trafﬁc detection in Internet Relay Chat (IRC) botnets
have been presented which ﬁrst distinguish between IRC and
non-IRC trafﬁc and then between bot and real IRC trafﬁc.
This approach of classifying trafﬁc into IRC and non-IRC to
detect IRC-based botnets has also been used in other works
 – . A bot infection dialog model has been built in
Bothunter based on which the authors have constructed
three bot-speciﬁc sensors and performed correlation between
inbound intrusion/scan alarms and the infection dialog model
to generate a consolidated report. In Botsniffer , the
authors have captured spatio-temporal similarities between
bots in a botnet (in terms of bot-CnC coordinated activities)
from network trafﬁc and utilized them for botnet detection in
a local area network. BotMiner has proposed a botnet
detection system in which similar CnC communication trafﬁc
and similar malicious activity trafﬁc are clustered, and subsequently cross cluster correlation is performed to detect bots
in a monitored network. A number of other works have used
clustering of ﬂows with similar characteristics to detect botnets
 – .
A few research works have also dealt with intrusion detection systems for IoT. In , the authors have presented
a whitelist-based intrusion detection system for IoT devices,
Heimdall, which uses dynamic proﬁle learning and runs on
IoT gateway routers. An intrusion detection model for IoT
backbone networks has been proposed in which employs
two-layer dimension reduction and later, two-tier classiﬁcation techniques for User-to-Root (U2R) and Remote-to-Local
attack (R2L) detection. Anthi et al. have proposed a
three layer intrusion detection system targeted at smart home
IoT devices, which detects network security attacks through
normal behaviour proﬁling of IoT devices connected to the
network, malicious packets’ identiﬁcation during the attack
and subsequent attack classiﬁcation.
Of late, the research community has been interested in IoT
botnet and attack detection with a number of papers addressing
these problems. There have been a few works on anomaly
detection systems for IoT that build normal communication
proﬁles for IoT devices, i.e., the proﬁles are not expected to
change much over a long period of time (DEFT ). Any
deviation from those proﬁles is ﬂagged as anomalous trafﬁc
(DÏoT , NETRA ). Hamza et al. have proposed a
tool to automatically generate Manufacturer Usage Description
(MUD) proﬁles for a number of consumer IoT devices. Using
those MUD proﬁles, the authors have derived ﬂow rules to
be conﬁgured on SDN switches, identiﬁed their limitations in
detecting network attacks on IoT devices and addressed those
limitations by proposing an anomaly detection-based approach
used in conjunction with an off-the-shelf IDS .
In , an anomaly detection technique built using deepautoencoders has been used to detect attacks launched from
IoT botnets. Statistical features have been extracted from
behavioural snapshots of normal IoT device trafﬁc captures
which are used to train deep learning-based autoencoders (for
each IoT device). Subsequently, the reconstruction error for
trafﬁc observations is compared with a threshold for normalanomalous classiﬁcation. Following a slightly different approach, Kitsune proposes an online unsupervised anomaly
detection system based on an ensemble of autoencoders which
is lightweight in terms of memory footprint and meant to be
deployed on network gateways and routers to detect attacks
on the local network.
Our work addresses few important gaps in the IoT botnet
detection literature. First, botnet detection techniques using
CnC communication features , – are designed for
PC-only networks whereas our botnet detection solution is
designed speciﬁcally for IoT networks. IoT networks pose a
number of unique research challenges as compared to PC-only
• In a typical IoT network, multiple IoT/non-IoT devices
are connected to the Internet through a gateway which
may be a wired/wireless access point (also acting as
a modem) or a cellular base-station whereas PC-only
networks consist of mostly PCs connected to the Internet
directly through modems.
• PC trafﬁc is more user driven and diversiﬁed since a
number of different user-level applications, e.g., browsing, email, word processor, run on a PC simultaneously
and generate trafﬁc based on user behaviour. IoT devices,
on the other hand, are always-connected, run one or
two applications only, and send data to servers regularly
without user intervention. As a result, their trafﬁc has
discernible patterns different from PC trafﬁc.
Moreover, the PC-only botnet detection schemes proposed in
 , – are designed for enterprise networks whereas
our work targets home networks. Also, the PC-only botnet
detection solutions are based on detection of bot-CnC trafﬁc
only whereas our work is based on detection of scanning
activity ﬁrst and subsequently bot-CnC communication for a
more accurate bot detection scheme.
Second, our focus is on detecting botnets irrespective of the
type of CnC communication protocol used (e.g., IRC, SMTP),
unlike . Third, in this work, we aim to detect individual
bots (instead of detecting the network of bots in a botnet
directly) which can then be used towards detecting the botnet.
This can be done, for example, by correlating the positions of
detected bots within a network, or by using techniques based
on clustering algorithms and cross-cluster correlation proposed
in existing works on PC-only botnet detection , .
Fourth, our aim is to detect IoT bots long before they are
used to launch attacks, during the scanning/infection phase,
unlike , . Finally, instead of using normal IoT devices’
trafﬁc ﬁngerprinting and subsequent anomaly detection
 , , we follow the approach of misuse-detection where
we detect IoT bots by utilizing certain distinguishing features
of bot scanning trafﬁc and bot-CnC communication trafﬁc
in succession. The former approach suffers from limitations
such as an inability to narrow down the cause of anomaly,
possibility of misclassiﬁcation of a bot as a legitimate device
type, limited testing against evasive malware which can easily
trick the anomaly detection system by manipulating device
trafﬁc (because ﬁngerprinting is performed at the device-level),
Kitsune suffers from a similar limitation which is
common to most anomaly detection systems, i.e., an inability
to point out the source of anomaly. Further, it has been
tested with one only IoT malware, Mirai, which is relatively
simple to detect and it is difﬁcult to say whether Kitsune will
perform well against other IoT malware in the real-world.
Again, Kitsune is more focused on attack detection rather
than early-stage detection of botnets which is the focus of
our work. Though Kitsune advocates online algorithms as it
is focused on detecting attacks, for the use-case of early-stage
detection of IoT botnets, ofﬂine algorithms are deemed to be
sufﬁcient as botnets take time to evolve before they are used
for attacks. As expected, EDIMA is not free from limitations
too, which is explained in Section V-G. Rather, a combined
approach consisting of EDIMA and IoT device ﬁngerprinting
plus anomaly detection is advocated for a more robust IoT
botnet detection performance.
III. EDIMA ARCHITECTURE
EDIMA is designed to have a modular architecture, as
shown in Fig. 1, with the following components:
1) Feature Extractor: This module extracts features from
the aggregate trafﬁc at the gateway. These features are
then forwarded to the ML-based Bot Detector (MBD),
which is described below, for classiﬁcation during the
execution phase. The Feature Extractor (FE) also sends
features extracted from the aggregate trafﬁc to the ML
Model Constructor (MC), which is also described below,
during the training phase. The feature extraction process
is explained in Section IV-A.
2) ML-based Bot Detector: This is a 2-stage module with
the ﬁrst stage being a coarse-grained one that classiﬁes
the aggregate trafﬁc samples using the features obtained
from FE and the ML model trained and forwarded by
the MC. Depending on the result of the classiﬁcation, the
second ﬁne-grained stage attempts to identify the infected
IoT device(s) from the set of devices connected to the
gateway. More details about the classiﬁcation operation
are given in Section IV-A while the bot detection process
is described in Section IV-B.
3) Trafﬁc Parser/Sub-sampler: The trafﬁc parser (TP) sorts
the combined gateway trafﬁc into trafﬁc sessions. During
the bootstrap (training) phase of EDIMA, it also helps
replay malware trafﬁc samples along with normal trafﬁc
to generate malicious trafﬁc samples. We also propose
an option for trafﬁc sub-sampling as introduced in .
Under this option, the packet trafﬁc from IoT devices is
sampled across the devices and the sub-sampled trafﬁc
is then forwarded to the FE. This operation would help
reduce the storage overhead but there is a trade-off in
terms of detection delay.
4) Malware PCAP Database: This frequently updated
database stores malware trafﬁc pcap ﬁles captured from
private and professional honeypots targeted at IoT malware. We envisage a community of authorized security
researchers who will collect the above pcap ﬁles and
upload them to the database through an online interface.
The ﬁles will be anonymized before uploading to ensure
user privacy. The pcap ﬁles are retrieved by the MC when
5) ML Model Constructor: The ML model used for classifying edge gateway trafﬁc is trained by this module.
We assume a publish-subscribe model where multiple
gateways subscribe to an MC. A separate ML model
is trained for each gateway for optimal performance.
Whenever a gateway comes online, it registers with the
MC. Malicious trafﬁc samples from the Malware PCAP
Database (mDB) are sent to the gateway to generate
malicious aggregate trafﬁc. The feature vectors extracted
from benign (normal trafﬁc with no malicious scanning
packets) and malicious aggregate trafﬁc are subsequently
sent by a gateway’s FE to the MC. The extracted features
are used to train a supervised ML classiﬁer which is then
published to the gateway’s MBD. The number of data
samples required for training depends on a number of
factors such as the model hyper-parameters, the desired
classiﬁcation accuracy/precision/training time, etc. The
MC interacts with a gateway through a Gateway-MC
The gateway’s ML model may have to be re-trained, e.g.,
when the ML model classiﬁes with a low probability, or
when the training dataset is updated, and the new model
is published to the gateway. By stating that the existing
ML model may classify with low probability, we mean
that the classiﬁcation probability falls below a pre-deﬁned
threshold (e.g., 80%).
Further, the training data used to train the ML model
in MC needs to be updated regularly. The training data
representing benign trafﬁc requires periodic updates for
various reasons: a new IoT device may have joined the
gateway, ﬁrmware update to a connected device, etc. If
bot(s) have not been detected in the last trafﬁc session,
the FE extracts features from the subsequent benign
aggregate trafﬁc sessions and forwards them to the MC
through the gateway-MC client. Similarly, the training
data representing malicious trafﬁc needs periodic updates
due to addition of newly discovered IoT malware to
mDB. The MC retrieves the new malware pcap ﬁles
from mDB and publishes them to the TP which replays
those malicious pcap ﬁles at the gateway. The malicious
trafﬁc so obtained is forwarded to the FE which extracts
the malicious trafﬁc features and sends them to the MC
through the gateway-MC client. The period for benign
and malicious training data set updates should be set
separately as the frequency of changes in benign trafﬁc
is expected to be lower than in malicious trafﬁc (due to
new IoT malware being created and discovered almost
every day).
6) Policy Engine: The policy engine (PE) consists of a list
of policies deﬁned by the network administrator, which
determine the course of actions to be taken once an IoT
device connected to the edge gateway has been detected
as a bot. For example, the entire trafﬁc originating from
bots can be blocked by the network administrator. The
underlying IoT devices can be brought back online once
they have been cleared of the malware. The details of this
module are discussed in Section IV-C.
EDIMA’s architecture is designed to be scalable in the sense
that, as the number of gateways in a network increases, more
MCs can be deployed with each MC catering to a group
of gateways. As the MC is implemented in the cloud, the
amount of resources allocated to it can be increased easily,
depending on the requirement. The cloud service using which
MC and mDB are implemented should be secure by industry
standards. This can be ensured by employing cloud services
offered by well-known commercial cloud service providers
(e.g., Amazon, Microsoft, Google).
Fig. 1: EDIMA Architecture
IV. DESCRIPTION OF EDIMA’S COMPONENTS
A. Detection of Scanning Activity in Aggregate Gateway Traf-
The ﬁrst coarse-grained stage of the ML-based Bot Detector
performs classiﬁcation on aggregate gateway trafﬁc rather than
per-device trafﬁc. According to Basil et al. , one needs to
keep track of less ﬁne-grained trafﬁc details while monitoring
aggregate trafﬁc behaviour, compared to inspecting individual
packets. This might result in a lower detection accuracy and
false positives, but offers several advantages such as lower
computational load and faster analysis, thus contributing to
higher scalability. Moreover, using less ﬁne-grained details in
the characterization of malicious trafﬁc results in a detection
scheme which is more resilient to evasion. The attacker would
have to compromise the efﬁciency of the malicious activity to
evade detection.
The aggregate gateway trafﬁc is assumed to belong to either
of the following classes: benign or malicious. Here, benign
trafﬁc refers to gateway trafﬁc which does not consist of bot
scanning packets whereas malicious trafﬁc refers to gateway
trafﬁc that does. The gateway trafﬁc is captured in the form
of trafﬁc sessions which are deﬁned statically as the set of
ingress/egress packets at a network interface over a ﬁxed
time interval. Further, the classiﬁcation algorithm is applied
on these trafﬁc sessions rather than individual packets. This
is because per-packet classiﬁcation is computationally much
more expensive and does not yield any signiﬁcant beneﬁts
over per-session classiﬁcation.
In a trafﬁc session, we extract features from TCP packet
headers only and not the payloads. Though payloads may
be quite helpful for classiﬁcation, it is possible that are
encrypted (e.g., HTTPS trafﬁc). By not depending on payload
information, we ensure that our aggregate trafﬁc classiﬁcation
method works on unencrypted as well as encrypted trafﬁc.
Below are the steps for gateway-level trafﬁc classiﬁcation:
1) Filter each gateway trafﬁc session to include only TCP
2) Perform feature extraction for each trafﬁc session.
3) Apply the trained ML classiﬁer on the extracted feature
vectors and classify the corresponding sessions.
We have carefully identiﬁed the following eight features for
ML classiﬁcation which are relevant for detecting bot scanning
trafﬁc (instead of using generic network trafﬁc features):
1) Number of unique TCP SYN destination IP addresses
2) Number of packets per unique destination IP address
a) maximum
b) minimum
3) Number of TCP half-open connections
4) TCP packet length
a) maximum
b) minimum
Fig. 2: Combined workﬂow of Trafﬁc Aggregator, Feature Extractor and ML-based Bot Detector
The intuition behind selecting the ﬁrst feature is that most IoT
bots generate random IP addresses and send malicious packets
to them. Hence, the number of unique destination IP addresses
in the presence of malware-induced scanning trafﬁc will be
signiﬁcantly higher than benign trafﬁc. The second set of
features was selected because malware typically send very few
scanning packets to the same IP address, in order to cover as
many devices as possible. The third feature seeks to exploit the
fact that while scanning, a bot opens multiple TCP connections
to random IP addresses, the majority of which do not respond
and so the connections remain half-open. Finally, compared to
packet length in benign TCP connections, malware scanning
packet lengths are generally shorter, making the fourth set of
features useful for classiﬁcation.
B. Detection of Individual Bots using Bot-CnC Communication Patterns
Once the aggregate trafﬁc at an edge gateway has been
classiﬁed as malicious, the second ﬁne-grained stage of the
ML-based bot detector attempts to detect the underlying bots
by checking the ingress/egress trafﬁc from each IoT device for
the presence of bot-CnC communication patterns. The set of
IoT devices is sorted according to their IP addresses. For the
sake of efﬁciency, we propose that the set be divided into two
halves, and each half should be checked for bots in parallel.
Here, we are not making any assumptions about the likely
locations of the infected devices in the set. The complete bot
detection algorithm is shown in Algorithm 1. The degree of
parallelization in our algorithm can be increased depending on
the delay requirements.
Periodicity Detection in Bot-CnC Communication In
most existing IoT botnets, including the Mirai-variants ,
there is a periodic exchange of TCP messages ([PSH, ACK],
[ACK]) or UDP messages between the bot and the CnC server.
This assumption is supported by our empirical analysis of
a number of IoT malware samples belonging to different
malware categories (Appendix A-A) as detailed in Section
V-B, all of which exhibited the above bot-CnC communication
behaviour. We would like to point out here that it is practically
infeasible to analyse all possible IoT malware and it is a
general practice followed in botnet detection literature to test
Algorithm 1 Detect_IoT_bots (SET_DEVS)
1: INPUT: SET_DEVS (Set of all IoT devices behind gateway)
2: Initialize Thread1, Thread2, InfectedDevList
3: Thread1:
4: for devindR = 1 to n(SET_DEVS)
Detect_bot_cnc_comm
PERIOD_DETECTED then
Append (InfectedDevList, devindR)
8: end for
9: Thread2:
10: for devindL = n(SET_DEVS) to n(SET_DEVS)
Detect_bot_cnc_comm
PERIOD_DETECTED then
Append (InfectedDevList, devindL)
14: end for
15: return (InfectedDevList)
with malware samples belonging to a few distinct malware
It seems fairly straightforward that to detect the presence of
bot-CnC communication, we ﬁlter the trafﬁc from a potential
bot for UDP packets or TCP packets (with PSH and ACK
ﬂags ON) and check for periodicity in the transmission times
of ﬁltered packets. However, IoT devices also send legitimate
application data to a cloud server periodically. Filtering the
device trafﬁc for TCP/UDP packets alone may lead to false
positives, i.e., device-cloud server trafﬁc may be mistaken for
bot-CnC server messaging trafﬁc.
Therefore, we further exclude IoT application data packets
from our analysis using appropriate packet capture ﬁlters. It
has been observed from the packet captures of uninfected commercial IoT devices and IoT malware running on embedded
devices (Section V-B) that as opposed to the legitimate application data packets from IoT devices, bot-CnC communication
TCP/UDP packets have TCP payload consisting of a few bytes
only. Hence, we build a packet capture ﬁlter to exclude packets
consisting of TCP payload greater than a few bytes (e.g., 5
or 10) from our analysis to obtain TCP/UDP packets related
to bot-CnC communication. Even then, we may be left with
TCP/UDP packets sent by desktops or phones to a server (e.g.,
user requesting for a web page through HTTP GET), though
they are not periodic and can be considered as noise packets.
Subsequently, we sample and encode the ﬁltered packets to
produce a uniformly sampled discrete-time signal using the
approach suggested in for further signal processing. Let
the time of arrival of ﬁltered packets be denoted as tj, where
j = 0,...,N −1 and N is the number of packets. Then, the
encoding function is represented as:
if iT < tj < (i+1)T
where i = 1,2,...,K and T is the sampling time interval.
To detect periodicity in time series data, the usual approach
followed in literature is to calculate the power spectral
density (PSD) of the time series (which can be estimated by a
periodogram). Then, a statistical hypothesis test (e.g., Schuster’s test, Walker’s test) is used to compare a statistic computed from the periodogram’s frequency components against a
threshold to decide between the null hypothesis H0 (underlying
time series is not periodic) and the alternate hypothesis H1
(underlying time series is periodic). The threshold is calculated
from the asymptotic probability distribution (when K →∞) of
the test statistic.
However, in a real-world implementation, we cannot wait to
collect so many samples (for the test statistic to converge to its
asymptotic distribution) as that would lead to a large delay in
bot detection. This is because the typical time interval between
consecutive bot-CnC messages is of the order of few minutes.
To collect a statistically signiﬁcant number of samples, for
example 500, assuming the bot-CnC messaging interval as
1 minute, we would have to capture an IoT device’s trafﬁc
for at least 500 minutes ≈8 hours. Even the Fisher’s test,
which gives an exact probability distribution expression for
calculating the comparison threshold, exhibits poor statistical
power when applied to short length time series (less than
40-50 time points).
In this work, we use the autocorrelation function (ACF).
ACF can be used to reveal hidden periodicity in a signal even
if it is corrupted by noise. For short length time series signal
such as desired in our use case (bot detection), calculating ACF
directly is not very computationally expensive. The unbiased
ACF of discrete time signal e(i) (with mean e) at a lag l can
be estimated as:
i=1 (e(i)−e)(e(i+l)−e)
i=1(e(i)−e)2
We calculate the autocorrelation series corresponding to e(i)
by applying ACF at various lags. Subsequently, the peaks (with
height greater than a pre-deﬁned value) in the autocorrelation
series are found and the inter-peak gaps are calculated. If the
variance of those gaps is lower than a threshold, the discrete
sequence is detected as periodic. The complete algorithm proposed for detecting the presence of bot-CnC communication
is shown in Algorithm 2.
Algorithm 2 Detect_bot_cnc_comm (devind)
1: INPUT: devind (Index of IoT device under consideration)
2: capﬁle = Capture_trafﬁc (devind)
3: capﬁle_ﬁlter = Apply_display_ﬁlter (capﬁle)
4: cap_seq = Encode_pkt_trace (capﬁle_ﬁlter)
5: cap_acf = Calculate_ACF (cap_seq)
6: peaks = Find_peaks (cap_acf, height)
7: peak_diffs = Calculate_peak_gaps (peaks)
8: if Variance (peak_diffs) < thresh then return (PE-
RIOD_DETECTED)
return (PERIOD_NOT_DETECTED)
11: end if
Handling False Positives/Negatives: EDIMA is designed
to handle false positives/negatives in the edge gateway’s
aggregate trafﬁc session classiﬁcation. For example, let us
assume that there is a false positive, i.e., a trafﬁc session is
classiﬁed as malicious though it is benign. The ML-based bot
detector stage after ML classiﬁer (Fig. 2) which detects the bot
device(s) using ACF-based test, would not detect any bot and
therefore EDIMA would know that there was a false positive
in trafﬁc session classiﬁcation. However, assuming that there
is a false negative, i.e., a trafﬁc session is classiﬁed as benign
though it is malicious, the ACF-based test stage would not be
invoked. We propose to handle this by taking the average of
classiﬁcation results for a ﬁxed number of consecutive trafﬁc
sessions subsequent to a session being classiﬁed as benign.
It is expected that by running over multiple sessions, the
classiﬁcation algorithm would be able to distinguish between
true positives and false negative in more sessions than not and
thus the averaging of classiﬁcation results would lead to a true
positive classiﬁcation.
C. Policy Engine
Once a device or set of devices has been detected as bot(s),
the policy engine decides the actions to be taken against those
devices. We envision a set of default policies pre-conﬁgured
by the network administrator along with the capability to make
and update new policies as part of this module. For instance,
some of the expressions for policy conﬁguration can be:
policy-engine –create-policy <policy-name>
policy-engine –add-action <policy-name> –dev <devicename> –action <action-name>
policy-engine –delete-action <policy-name> –dev <devicename> –action <action-name>
policy-engine –delete-policy <policy-name>
We now mention some of the actions which can be taken
by the policy engine. One such action where the bot trafﬁc
is blocked by the network administrator was mentioned in
Section III. Another alternative is to allow the bot to communicate with a few secure domains only for malware infection
remediation . It is also possible to place the bot under
continuous monitoring and deny all other communication
except that required for the functioning of the underlying IoT
V. PERFORMANCE EVALUATION
A. Testbed Description
To evaluate the performance of EDIMA on real devices,
we built a testbed with commercial IoT and non-IoT devices
which are listed in Table II. Typical network applications
running on the laptops/desktops were web browser (accessing web pages, video streaming sites, e.g., YouTube), email
clients, etc. Similarly, applications such as web browser, social
media (Facebook/Twitter/LinkedIn), chat (WhatsApp), etc.,
were running on the smartphones along with a few other
network applications in the background. The devices were
used by 3 staff members in our lab over a period of 4 weeks,
and thus the trafﬁc data collected from those devices reﬂects
real-world users’ behaviour.
Smart bulb
Philips Hue
Smart bulb (LB100)
IP camera (DCS-930L)
IP camera (DCS-5030L)
Smart Plug (HS110)
Smart Switch (INSIGHT)
Smart Home Assistant
SmartThings Hub
Motion Sensor (DCH-S150)
Smart Plug (DSP-W215)
Laptop (Windows OS)
Laptop (Windows OS)
Desktop (Ubuntu OS)
Smartphone (Android OS)
Smartphone (Android OS)
TABLE I: List of IoT and Non-IoT Devices used in our Testbed
The edge gateway where the trafﬁc from all the above
devices was aggregated was a Linksys WRT32X router with
a Marvell Armada 385 88F6820 1.8 GHz dual-core processor,
512MB RAM, 256MB NAND ﬂash memory supporting IEEE
802.11a/b/g/n Wi-Fi standards. The Linksys WRT32X router
comes with out-of-the-box OpenWRT support (Version:
Bleeding Edge). The packet traces collected from the router
were analysed on a Dell OptiPlex 5060 desktop PC with an
Intel Corei5-8500T 2.1GHz six-core processor, 8GB RAM
running Ubuntu 18.04. The testbed schematic and picture are
shown in Fig. 3a and 3b.
B. Data Collection
As mentioned in Section IV-A, we classify aggregate trafﬁc
at the gateway into benign or malicious. Therefore, we need
training data samples to represent both classes. Benign trafﬁc
can be generated through the normal operation of uninfected
devices. However, malicious trafﬁc consists of both benign
trafﬁc as well as malware scanning/infection packets. To
generate malicious trafﬁc, we have three options:
1) Run live malware on the device(s) in our testbed
(a) Schematic of the testbed
(b) Picture of the actual testbed
Fig. 3: Testbed used for performance evaluation of EDIMA
2) Emulate the malware on our testbed
3) Replay live malware trafﬁc on our testbed
The ﬁrst option, though capable of generating the most
realistic malicious trafﬁc, is ruled out as the live malware
may infect other devices connected to the Internet and use
them for attacks. Moreover, none of the IoT devices in our
testbed had any known software vulnerabilities which could
have been exploited by existing IoT malware. We used the
second option in our earlier work . However, emulating
malware requires assumptions about their behaviour (such as
scanning, communication with CnC server) which may not be
fully representative of live malware.
Therefore, in this work, we adopted the third option. We
obtained 23 live IoT malware samples over a period of 3
months from APIs provided by New Sky
Security and malware hosting server links posted by
Bad Packets Report Twitter account , henceforth referred
to as the IoT-BPR-NSS dataset. The FANTASM framework,
provided by DeterLab team for safe experimentation with
live malware based on , was used to run the malware
samples and collect the packet trafﬁc generated by them.
Many of the malware samples were simple variants of each
other as revealed by analysing their trafﬁc using Wireshark.
Those simple variants were discarded as they would not have
added any value to our classiﬁcation dataset. We ended up with
two malware samples, called loligang and echobot by their
authors, which belong to the TELNET and HTTP POST+GET
categories (Appendix A-A) respectively. We could not obtain
malware samples from other categories, as many of those
malware were not active by the time we started collecting samples. We ran loligang and echobot binaries on the FANTASM
testbed for 5 minutes each and captured the corresponding
trafﬁc pcap ﬁles. Malicious trafﬁc was then generated by
replaying the malware trafﬁc collected from FANTASM on
the edge gateway using the tcpreplay utility. We could not
replay the malware trafﬁc on commercial IoT devices in our
testbed as they do not provide a shell to users.
We used trafﬁc session durations of 5, 10 and 15 minutes for this study. 1000 trafﬁc sessions were captured for
benign trafﬁc and a further 1000 sessions for malicious trafﬁc
through our testbed. The malicious trafﬁc sessions consisted of
400 sessions corresponding to loligang, another 400 sessions
corresponding to echobot and the remaining 200 sessions
corresponding to both loligang and echobot trafﬁc replayed at
the OpenWRT router. The features mentioned in Section IV-A
were extracted from the captured sessions. Finally, appropriate
class labels were assigned to the extracted feature vectors.
Apart from the IoT-BPR-NSS dataset, we also considered
the IoT-23 dataset which captured the trafﬁc for 20
IoT malware samples from 2018 to 2019. However, roughly
half the dataset consisted of Mirai or Mirai-like malware
trafﬁc, which we already had from the live malware samples
we had obtained. The other half of the dataset consisted of
more sophisticated centralized and P2P architecture botnet
malware (e.g., Kenjiru, Okiru, Hakai, Hajime). The pcap
ﬁles corresponding to centralized architecture malware did not
contain scanning packet trafﬁc and therefore, we could not use
their data in training EDIMA’s ML algorithms for aggregate
gateway trafﬁc classiﬁcation. The P2P botnet malware trafﬁc
ﬁles were not used as the focus of our work is on centralized
botnet malware.
Both the IoT-23 and IoT-BPR-NSS datasets consisted of
bot-CnC server communication packets. We used them to
verify our assumption that bot-CnC messaging is periodic as
stated in Section IV-B. The malware pcap ﬁles obtained from
those datasets were analysed for bot-CnC messaging packets.
This was done by ﬁltering the the pcap ﬁles for repetitive
connections (including TCP ([PSH, ACK], [ACK]) or UDP
messages) with a suspicious CnC server and checking the
timings of those connections for periodicity.
Justiﬁcation
aggregate trafﬁc training
assumption
periodicity
messaging.
live IoT malware
Verify assumption regarding periodicity of bot-CnC
server messaging only.
Consists of bot-
CnC communication packet traces
for IoT malware.
Test EDIMA’s robustness
to the scaling of number
of IoT devices connected
to the edge gateway.
from 28 different
uninfected
devices collected
at a gateway.
TABLE II: Data sources used in our work
Num_half_open_conn
165.130937
Num_uniq_Ipadd
146.088020
Min_pkt_per_Ipadd
Max_pkt_per_Ipadd
Avg_TCP_pkt_len
Avg_pkt_per_Ipadd
Max_TCP_pkt_len
Min_TCP_pkt_len
TABLE III: χ2 test scores for classiﬁer features
C. Data preparation
The feature vectors obtained in the previous section for
benign and malicious classes were checked for missing values
and handled appropriately. Next, all the values in a feature
vector were scaled using a MinMaxScaler to lie within
the range (0,1). This was done to avoid bias due to different
scales of features. Further, the feature vectors were randomly
permuted so that the sequence in which they were extracted
does not affect the training of the classiﬁer. The combined
benign and malicious feature vectors were randomly divided
into training and test datasets using an 80:20 split.
D. Feature selection
It is possible that some of the features extracted from
training data are redundant or irrelevant with little to no
contribution in improving the ML classiﬁer’s performance.
Feature selection, or selecting a subset of relevant features,
can help in simplifying the ML classiﬁer model, shortening
the time for training and reducing over-ﬁtting. We used the
χ2 statistical test to compute the χ2 test statistic for each
feature from the sample data. The χ2 test values for features
extracted from the 15 minutes trafﬁc session dataset are shown
in Table III. Subsequently, we selected the best k= 6 features
(having test statistic value more than zero) for training our
ML classiﬁers. The selected features ranked by their χ2 test
values are listed below:
1) Number of TCP half-open connections
2) Number of unique TCP SYN destination IP addresses
3) Minimum number of packets per unique destination IP
4) Maximum number of packets per unique destination IP
5) Mean TCP packet length
6) Mean number of packets per unique destination IP address
E. PCA Analysis
In order to visualize the ﬁnal data obtained in the previous
sub-section and check if the benign and malicious data points
are separable using the features proposed, we performed
a Principle Component Analysis (PCA). PCA reduces the
dimensionality and captures the big principal variance in a set
of observations (feature vectors in our case) by generating new
variables, called principle components (PCs). These PCs are
orthogonal to each other and obtained as the eigenvectors of
the largest eigenvalues of the covariance matrix of the original
set of observations. A 2D scatter plot of two PCA components
extracted from the ﬁnal data for 15 minutes trafﬁc session is
shown in Fig. 4. The benign and malicious PC points seem
to be separable using a pair of decision boundaries on either
side of the benign PC points cluster. There will still be a small
number of outliers though, especially around the left decision
boundary which does not provide a clear separation.
Fig. 4: PCA analysis of the ﬁnal prepared data with two components
F. Results
1) Scanning Activity Detection Performance: We trained
the following ML models using the ﬁnal feature vectors
obtained in Section V-D after completing all the data processing steps: Gaussian Naive Bayes’ (GNB), Support Vector
Machine (SVM) and Random Forest (RForest). Subsequently,
the trained ML models are used to predict the class labels
of the test dataset and thereby, the detection performance
of the models is evaluated and compared. In this work,
a 10-fold cross validation (CV) approach is used to tune
the hyper-parameters of the ML classiﬁers for achieving the
highest possible CV scores. The cross validation is based on
training data only without using any information from the test
dataset. The hyper-parameter values so obtained along with
the associated CV scores for the 15 minutes trafﬁc session
data are displayed in Table IV.
Using the tuned hyper-parameters’ values, the average classiﬁcation accuracy (AC), precision (PR), recall (RC) and F1
scores obtained for the ﬁnal classiﬁers over 50 runs are shown
in Table V. It can be observed that the Random Forest classiﬁer
performs the best in terms of classiﬁcation accuracy followed
by SVM classiﬁer and Gaussian Naive Bayes’ classiﬁer. All
the classiﬁers report a precision of close to 1.0, i.e., an
extremely low false positive rate, which is a much desired
property for bot detection. This is because we do not want
benign IoT devices to be classiﬁed as bots which could lead
to further administrative actions on those devices. Moreover,
all the classiﬁers report a recall of close to 1.0 as well, i.e., an
extremely low false negative rate, which is also a much desired
property for bot detection. False negatives lead to bots getting
Hyper-parameter Values
0.98 (+/- 0.02)
priors=None, var_smoothing=1e-3
1.00 (+/- 0.01)
kernel=’rbf’,
gamma=’scale’,
coef0=0.0,
shrinking=True,
probability=False, tol=0.001, cache_size=200,
class_weight=None,
verbose=False,
max_iter=-1,
decision_function_shape=’ovr’,
random_state=None
1.00 (+/- 0.00)
n_estimators=10,
criterion=’gini’,
max_depth=None,
min_samples_split=2,
min_samples_leaf=1,
min_weight_fraction_leaf=0.0,
max_features=’auto’, max_leaf_nodes=None,
min_impurity_decrease=0.0,
bootstrap=True,
class_weight=None
TABLE IV: CV Scores and optimal hyper-parameter values for ML classiﬁers trained
on testbed dataset (15 mins)
classiﬁed as benign IoT devices and as a result, the network
administrator could overlook them while the bots continue
to pose a security threat without being detected. Based on
the classiﬁcation performance obtained above, we use the
Random Forest model for aggregate trafﬁc classiﬁcation while
implementing EDIMA in code.
Performance Comparison With Previous Works: The performance of the proposed aggregate trafﬁc classiﬁer for scanning
activity detection is compared with the botnet scanning trafﬁc
detector introduced in here. We desist from comparing
with Kitsune as it is an anomaly detection system whereas
EDIMA is based on a misuse-detection approach. The two approaches are quite different from each other with anomaly
detection systems typically performing worse in terms of false
positive rates. Further, Kitsune uses per-packet classiﬁcation
whereas EDIMA performs per-session classiﬁcation. If we
wish to use per-session classiﬁcation with Kitsune, we would
have to make signiﬁcant changes in its source code. Also, it
is not possible to use per-packet classiﬁcation with EDIMA
as it is designed to use session-based features due to the
reasons explained in Section IV-A. Other anomaly detectionbased systems for IoT , , are also excluded from
performance comparison due to the reason explained above as
well as lack of publicly available source code.
We split our benign and malicious trafﬁc datasets into
training and test datasets using a 80:20 ratio, which is the split
used during the evaluation of our ML-based aggregate trafﬁc
classiﬁcation algorithm. We construct Hm, the ﬁrst conditional
entropy vector using samples from malicious training data and
Ht, the second conditional entropy vector using a test sample
and samples from malicious training data. The conditional
entropies are calculated using NPEET Python package .
Using the KS test, we attempt to decide whether the test
sample (or trafﬁc session) is similar to malicious trafﬁc in
terms of conditional entropy distribution to classify the test
sample as malicious. A low false positive probability, γ = 0.05
is selected, which gives the test threshold Kγ as 0.51961.
In applying KS test for classiﬁcation of test samples, we
deﬁne true positive (TP) as the event in which a malicious
test sample is found similar to malicious training dataset and
false positive (FP) when a benign test sample is found similar
to malicious training dataset. When the same malicious test
TABLE V: Performance of ML Classiﬁers for Scanning Activity Detection
dataset (consisting of 200 samples) was tested for similarity
with malicious and benign training datasets, the number of TPs
and FPs were calculated as 186 and 168 respectively. It can
be inferred that few test samples were found similar to both
malicious and benign trafﬁc which means that conditional entropy based KS test can not be used for reliable classiﬁcation.
Further, the malicious trafﬁc detection accuracy (or precision
in ML terminology) can be calculated as 186/200 = 93%,
which is lower than the precision of all the ML classiﬁers as
shown in Table V. Thus, based on accuracy and reliability of
classiﬁcation, we can conclude that our ML-based aggregate
trafﬁc classiﬁcation method performs much better than the
conditional entropy based KS test in .
2) Bot-CnC
Communication
Performance:
performance
Detect_bot_CnC_comm
algorithm,
scenario where we we use the malicious trafﬁc dataset (with
a 15 minutes session duration) generated in Section V-B by
replaying the loligang pcap ﬁle. We know from the ground
truth that the loligang pcap ﬁle contains bot-CnC messaging
packets with an approximate periodicity of 60 seconds. Each
pcap ﬁle in the malicious trafﬁc dataset is processed as
1) The packet trafﬁc associated with each connected IP address (corresponding to a device) detected by the gateway
was separated from the aggregate trafﬁc.
2) The devices’ packet streams were ﬁltered, sampled, encoded and mean subtracted as described in Section IV-B
to produce discrete-time sequences.
We evaluate the detection performance of Algorithm 2 on
the discrete-time sequences so obtained in terms of detection
rate (DR) and missed-detection rate (MDR). Detection Rate
is the fraction of the total number of malicious trafﬁc pcap
ﬁles which have been correctly detected as containing bot-
CnC trafﬁc, and Missed-detection Rate is the fraction of the
total number of malicious trafﬁc pcap ﬁles which have been
incorrectly detected as not containing bot-CnC trafﬁc.
In the second scenario, we use the malicious trafﬁc dataset
(with a 15 minutes session duration) generated in Section
V-B by replaying the echobot pcap ﬁle. We know from the
ground truth that the echobot pcap ﬁle contains bot-CnC
messaging packets with an approximate periodicity of 210
seconds. Using the parameter values (given in Table VI), the
detection performance of Algorithm 2 for both the scenarios
speciﬁed above is shown in Table VII. It can be seen that our
algorithm gives a DR of 1.0 and a MDR of 0.0 for both the
scenarios outlined above.
The sub-sampling frequency of 0.1 was selected to keep
the number of samples to be processed by our algorithm
and hence the processing time within a reasonable limit.
The minimum autocorrelation peak height was kept at 0.7
times the maximum autocorrelation peak height (excluding
the peak at lag 0) because any value above that corresponds
to a signiﬁcant degree of autocorrelation. The inter-peak gap
variance threshold was kept at a low value of 0.01 so that only
when the autocorrelation function’s peaks are almost equally
separated is the underlying discrete-time sequence detected as
Trafﬁc sampling frequency
Min. autocorrelation peak height
0.7×(Max. peak height)
Inter-peak gap variance threshold
TABLE VI: Parameter Values for Evaluation of Bot-CnC Communication Detection
Performance
Performance Comparison With Previous Works: We evaluate the performance of the proposed Detect_bot_CnC_comm
algorithm against the botnet detection test developed in 
here. A performance comparison with BotHunter/BotSniffer-
/BotMiner – is not provided as those works detect
CnC communication at the network level using correlationbased techniques whereas EDIMA’s bot-CnC communication
detection algorithm runs on the edge gateway directly connected to IoT devices where the above correlation techniques
cannot be applied. Further, the source code for those works
has not been released, making it difﬁcult for us to replicate
their proposed botnet detection systems.
We use the discrete-time sequences produced during the performance evaluation of our proposed Detect_bot_CnC_comm
algorithm. In order to conﬁrm that those sequences correspond
to the bot-CnC communication trafﬁc as per , we apply
the Walker’s largest sample test (WLST) to the sequences.
Keeping the false positive probability, γ at a low value of 0.1,
the test gives a DR of 0.0 and a MDR of 1.0 for a session
duration of 15 minutes, which is extremely poor compared
to a DR of 1.0 and MDR of 0.0 given by our proposed
Detect_bot_CnC_comm algorithm. This result was somewhat
expected as the Walker’s largest sample test requires a large
number of time samples to be effective and we had only
a limited number of time samples collected in the capture
duration. As mentioned earlier in Section IV-B, in a real-world
implementation, it is not recommended to have long capture
durations as that would lead to a large delay in bot detection.
3) Robustness Test: The number of IoT devices connected
to a gateway needs to be scaled up to test EDIMA’s robustness
and study the effect on its performance. Towards this, we used
the UNSW IoT dataset in which provides pcap ﬁles for
aggregate trafﬁc captured from 28 different uninfected IoT
Testbed (loligang)
Testbed (echobot)
TABLE VII: Bot-CnC Communication Detection performance of Algorithm 2
devices collected at a gateway over 24 hours for 20 days.
Half of the original pcap ﬁles were used in generating benign
trafﬁc. To generate malicious trafﬁc, we replayed the other
half of pcap ﬁles at the OpenWRT router in our testbed (with
all IoT/non-IoT devices disconnected) in addition to a single
loligang pcap ﬁle using the malware trafﬁc replay technique
mentioned in Section V-B. We captured the packet trafﬁc at
the router and followed the same procedure as used for our
testbed dataset to train and test ML classiﬁers.
The aggregate trafﬁc classiﬁcation performance of EDIMA’s
ML-based bot detector using the UNSW IoT dataset for 15
minutes session duration is presented in Table V. Again, the
Random Forest classiﬁer performs the best with accuracy and
precision scores the same as that for our testbed dataset.
However, SVM and Gaussian Naive Bayes’ classiﬁers register
a signiﬁcant drop in accuracy and precision scores compared to
their performance on our testbed dataset. Thus, after more than
doubling the number of IoT devices from 11 to 29 with just
one bot present among the IoT devices, ML classiﬁers such
as Random Forest are still able to accurately detect malicious
aggregate trafﬁc with almost zero false positives.
Theoretically, up to 255 devices can be connected to a
consumer edge gateway (e.g., Wi-Fi router or access point).
The actual number of devices connected though is usually
a lot lower and depends on the type of network in which
the gateway is installed, e.g., home, campus, enterprise, with
home networks (focus of our work) typically consisting of the
lowest number of connected devices out of the three network
types. As long as we are targeting current IoT malware whose
scanning behaviour is quite similar to the malware tested, it
is fair to claim that EDIMA will perform well even when the
number of devices connected to a gateway goes up.
4) Runtime Performance of EDIMA: We have implemented
EDIMA in Python1. Most of the commercially available
consumer gateways/routers run proprietary ﬁrmware on top
of Linux with basic utilities (e.g., Busybox) and a simple
web interface. They do not support Python environment, DB
services or Linux/Python package management which are
required for running EDIMA code. Therefore, it is not possible
to run the code directly on all consumer routers as is. Instead,
we tested the code on a Raspberry Pi 3B+ (RPi) device
with a Broadcom BCM2837B0 1.4GHz quad-core processor,
1GB SDRAM supporting IEEE 802.11.b/g/n/ac wireless LAN
which is similar in conﬁguration to a consumer Wi-Fi router.
The test setup remains similar to our testbed described in
Section V-A, only with the OpenWRT router replaced by RPi
1The source code has not been publicly released due to the terms of our
project funding.
and the exclusion of few devices which require wired Internet
connectivity (e.g., Samsung SmartThings, Philips Hue bridge).
The session duration used for trafﬁc capture is 5 minutes. We
considered three performance quantiﬁers: Throughput, Delay
and Memory statistics.
Throughput refers to the average number of packets per
second that are successfully processed. Now, EDIMA is an
ofﬂine detector, so the number of packets processed per
second by it are not as important as in the case of an online
detector. Further, the percentage of packets dropped (which
get excluded from the bot detection process) is completely
determined by the packet capture function used in EDIMA’s
implementation which depends on the capture speed of the
network card installed on the gateway where EDIMA is
deployed. Therefore, we do not include throughput results in
the ﬁnal runtime performance evaluation.
Two types of Delay can be calculated in the context of
1) average time interval (in seconds) between the arrival of
the ﬁrst malicious packet at the router and the detection
of malicious trafﬁc by EDIMA code (TAD), and
2) average time interval (in seconds) between the detection
of malicious trafﬁc by EDIMA code and the detection of
the ﬁrst bot responsible for malicious trafﬁc (TBD).
Memory statistics refers to the amount of local router (ﬂash)
storage required for storing EDIMA code and the average
RAM consumed when the code is running. The averaging in
all the relevant performance metrics is done over 50 code runs
each. The evaluation results are shown in Table VIII. The
results point towards a system which is quite reasonable in
terms of detection delay (considering that EDIMA is designed
to be an ofﬂine detector), requires minimal storage space and
consumes only a small fraction of the total RAM on an average
415.6 secs
342.4 secs
Local Storage
TABLE VIII: Runtime performance of EDIMA on a Raspberry Pi 3B+
G. Limitations and Future Work
As the Malware PCAP Database consists of pcap samples
from only those IoT malware which have been observed
infecting honeypots, trafﬁc generated by zero-day malware is
not a part of the database and therefore, EDIMA may not be
able to detect bots infected by those malware. Also, EDIMA
uses supervised ML algorithms which means that it can detect
only known malicious trafﬁc patterns. However, supervised
ML algorithms are used much more commonly compared
to unsupervised algorithms in real-world anti-virus and antimalware products to detect virus/malware behaviour as well as
in actual deployments of Network Intrusion Detection Systems
Advanced malware which attempt to evade detection by ED-
IMA may slow down the bot scanning activity to confuse the
trained ML algorithms classifying aggregate gateway trafﬁc
and lower its detection accuracy and precision. However, as
mentioned earlier in this paper, this approach decreases the
scanning efﬁciency of the malware resulting in the slowing
down of malware’s propagation through a network and may
not be desirable for the malware author. Further, this evasion
technique can be countered by increasing the trafﬁc session
duration to capture enough scanning packets though it may
lead to longer classiﬁcation delays.
Evasive malware may also use some other bot-CnC server
messaging mechanism than the ([PSH,ACK], [ACK]) one
to escape ﬁltering and/or force the bot-CnC communication
to be non-periodic (by adding noise trafﬁc for example). If
the attacker does change the bot-CnC messaging protocol,
the detection method can be changed accordingly. Moreover,
our bot-CnC server communication detection algorithm uses
an ACF-based approach which can detect periodicity in the
presence of noise as well if the noise is uncorrelated with
the desired signal (discrete-time sequence extracted from bot-
CnC server trafﬁc). Forcing the bot-CnC communication to be
non-periodic may result in the CnC server losing control of
the bot in between the keep-alive messages and cause the CnC
server to have an unreliable estimate of the number of active,
connected bots. This may lead to a decrease in the impact of
any future attacks launched by the CnC server using its bots.
Adversarial machine learning may also be deployed by
malware authors by changing the bot trafﬁc in subtle ways
so as to avoid detection by EDIMA’s trained ML algorithms.
Additionally, it is possible that some IoT devices connected to
a gateway may already be infected before EDIMA is deployed
and starts running on the gateway. As part of our future
work, it may be interesting to explore ways of detecting and
ﬁltering trafﬁc samples containing trafﬁc from existing bots
before fully deploying EDIMA. One possible approach is to
use a reliable statistical test for checking if the captured trafﬁc
samples are similar to known malicious trafﬁc samples in some
probability measure. Finally, the aggregate trafﬁc classiﬁer
trained by ML Model Constructor may have to be re-trained
due to a number of reasons (mentioned in Section III) and this
may cause a delay in bot detection.
VI. CONCLUSION
We have proposed EDIMA, a lightweight solution for early
detection of IoT botnets in home networks. It detects bots
connected to an edge gateway in two stages- ﬁrst by looking
for scanning and subsequently bot-CnC server communication
trafﬁc patterns. EDIMA consists of a trafﬁc parser, feature
extractor, ML-based bot detector, policy engine, ML model
constructor and a malware PCAP database. The operation
of all the above components was discussed in detail. A
comprehensive performance evaluation of EDIMA using our
testbed setup revealed that it has a close to 100% accuracy
and a very low false positive rate in detecting malicious
aggregate gateway trafﬁc with ML algorithms such as the
Random Forest. The detection performance holds even when
the number of devices is more than doubled, suggesting
that EDIMA’s performance is robust to an increase in the
number of IoT devices connected to the gateway. We also
compared EDIMA’s performance with existing techniques for
bot scanning trafﬁc and bot-CnC communication detection and
found that EDIMA performs much better and more reliably.
Finally, we analysed the runtime performance of a Python
implementation of EDIMA on a Raspberry Pi which showed
low bot detection delays and low RAM consumption.
ACKNOWLEDGMENT
The authors would like to appreciate the National Cybersecurity R&D Lab, Singapore for allowing us to use their
testbed to collect important data which has been used in our
work. This research is supported by the National Research
Foundation, Prime Minister’s Ofﬁce, Singapore under its Corporate Laboratory@University Scheme, National University of
Singapore, and Singapore Telecommunications Ltd.