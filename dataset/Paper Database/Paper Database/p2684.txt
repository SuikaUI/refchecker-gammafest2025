Received August 27, 2019, accepted October 4, 2019, date of publication October 15, 2019, date of current version October 29, 2019.
Digital Object Identifier 10.1109/ACCESS.2019.2947484
A Deep Learning Ensemble Approach for
Diabetic Retinopathy Detection
SEHRISH QUMMAR1, FIAZ GUL KHAN
1, SAJID SHAH
1, AHMAD KHAN1,
SHAHABODDIN SHAMSHIRBAND
2,3, ZIA UR REHMAN1,
IFTIKHAR AHMED KHAN
1, AND WAQAS JADOON
1Department of Computer Science, COMSATS University Islamabad, Abbottabad Campus, Abbottabad 22010, Pakistan
2Department for Management of Science and Technology Development, Ton Duc Thang University, Ho Chi Minh City, Vietnam
3Faculty of Information Technology, Ton Duc Thang University, Ho Chi Minh City, Vietnam
Corresponding author: Shahaboddin Shamshirband ( )
This work was supported in part by the Nvidia Corporation in the form of hardware donation, i.e., Tesla K40 GPU for this project
Diabetic Retinopathy (DR) is an ophthalmic disease that damages retinal blood vessels.
DR causes impaired vision and may even lead to blindness if it is not diagnosed in early stages. DR has
ﬁve stages or classes, namely normal, mild, moderate, severe and PDR (Proliferative Diabetic Retinopathy).
Normally, highly trained experts examine the colored fundus images to diagnose this fatal disease. This
manual diagnosis of this condition (by clinicians) is tedious and error-prone. Therefore, various computer
vision-based techniques have been proposed to automatically detect DR and its different stages from retina
images. However, these methods are unable to encode the underlying complicated features and can only
classify DR’s different stages with very low accuracy particularly, for the early stages. In this research,
we used the publicly available Kaggle dataset of retina images to train an ensemble of ﬁve deep Convolution
Neural Network (CNN) models (Resnet50, Inceptionv3, Xception, Dense121, Dense169) to encode the rich
features and improve the classiﬁcation for different stages of DR. The experimental results show that the
proposed model detects all the stages of DR unlike the current methods and performs better compared to
state-of-the-art methods on the same Kaggle dataset.
INDEX TERMS CNN, diabetic retinopathy, deep learning, ensemble model, fundus images, medical image
I. INTRODUCTION
Diabetic Retinopathy (DR) is one of the major causes of
blindness. DR mutilate the retinal blood vessels of a patient
having diabetes. The DR has two major types: the Non-
Proliferative Diabetic Retinopathy (NPDR) and Proliferative Diabetic Retinopathy (PDR) . The DR in the early
stages is called NPDR which is further divided into Mild,
Moderate, and Severe stages. Where the mild stage has one
micro-aneurysm (MA), a small circular red dot at the end of
blood vessels. In the Moderate stage the MAs rapture into
deeper layers and form a ﬂame-shaped hemorrhage in the
retina. The severe stage contains more than 20 intraretinal
hemorrhages in each of the four quadrants, having deﬁnite
venous bleeding with prominent intraretinal microvascular
abnormalities. PDR is the advanced stage of DR which leads
The associate editor coordinating the review of this manuscript and
approving it for publication was Sabah Mohammed
to neovascularization, a natural formation of new blood vessels in the form of functional microvascular networks that
grow on the inside surface of the retina . The ﬁgure, 1
visually presents the different stages of DR. It is clear from
the given ﬁgure the Normal and Mild stage looks visually
similar. Hence, it is difﬁcult to detect the Mild stage.
Globally, the number of DR patients is expected to increase
from 382 million to 592 million by 2025 . A survey 
conducted in the province of Khyber Pakhtunkhwa (KPK),
Pakistan, report 30% of diabetes patients are affected by DR
in which 5.6% succumbs to blindness. Over time, the mild
NPDR develops into PDR if not controlled in the early stages.
Another survey , conducted in Sindh, Pakistan, observed
130 patients with DR symptoms. It is reported that 23.85%
of the total observed patients were DR in which 25.8% were
diagnosed as PDR patients.
In the early stages of the DR the patients are asymptomatic
but in advanced stages, it leads to ﬂoaters, blurred vision,
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see 
VOLUME 7, 2019
S. Qummar et al.: Deep Learning Ensemble Approach for DR Detection
FIGURE 1. The different stages of DR.
distortions, and progressive visual acuity loss. Hence it is
difﬁcult but utmost important to detect the DR in early stages
to avoid the worse effect of latter stages.
As explained in the previous section, the color fundus
images are used for the diagnosis of DR. The manual analysis
can only be done by highly trained domain experts and is,
therefore, expensive in terms of time and cost. Therefore,
it is important to use computer vision methods to automatically analyze the fundus images and assist the physicians/
radiologists. The computer vision-based methods are divided
into hand-on engineering – and end-to-end learning – . The hand-on engineering methods extract
features using traditional approaches such as HoG ,
SIFT , LBP , Gabor ﬁlters and etc which fails
to encode the variations in scale, rotation, and illumination.
The end-to-end leaning automatically learns the hidden rich
features and thus performs better classiﬁcation. Many handon engineering and end-to-end learning-based approaches
 – are used to detect the DR in Kaggle dataset1 but
no approach is able to detect the Mild stage. The detection
of the mild stage is important for the early control of this
fatal disease. This study focuses to detect all the stages of
DR (including the mild stage) using end-to-end deep ensemble networks. The results show that the proposed approach
outperforms state-of-the-art methods.
Section ?? reviews recent literature to detect and classify diabetic retinopathy. The proposed methodology is presented in
Section III while Section IV contain the results and discussion
followed by conclusion in Section V.
1 
II. RELATED WORK
The classiﬁcation of DR has been extensively studied in the
literature. Gondal et al. proposed a CNN model for
the referable Diabetic Retinopathy (RDR). They used two
publicly available datasets Kaggle and DiaretDB1, where the
Kaggle dataset is used for training and DiaretDB1 is used for
testing. They are doing binary classiﬁcation as normal and
mild stages are considered as non-referable DR where the rest
of the three stages are used as referable DR. The performance
of the CNN model is evaluated based on binary classiﬁcation resulting in sensitivity 93.6% and speciﬁcity 97.6%
on DiaretDB1. Wang et al. proposed a novel architecture that classiﬁes the images as normal/abnormal, referable/
non-referable DR and gets the high AUC on a normal and
referable DR task 0.978 and 0.960 respectively and speci-
ﬁcity is 0.5. Their proposed method uses three networks:
main, attention and crop. The main network uses the Inception model that is trained on ImageNet where the attention network highlights different types of lesions in the
images and crop network’s crop the high attention image.
Quelle et al. proposed three CNN models for binary classiﬁcation and detected DR lesions. They also used the Kaggle
and DiaretDb1 dataset for training and testing respectively.
Diabetic retinopathy has ﬁve (5) stages to classify the occurrence of diseases. The stage-wise classiﬁcation is discussed
by Chanrakumar and Kathirvel introduced the CNN
model with a dropout regularization technique trained on the
Kaggle dataset and tested on DRIVE and STARE dataset.
The accuracy achieved by their model is 94%. They manually
performed an augmentation and preprocessing steps by using
an image editing tool. Moreover, CNN architecture is applied
to the Kaggle dataset proposed by Memon et al. . The
preprocessing is done on the dataset and they used nonlocal
mean denoising and added a delta value to get the equal level
of brightness of the images. For evaluation, the overall kappa
score accuracy is 0.74, for the validation purpose, 10% of the
images were used. Pratt et al. proposed a CNN architecture used for classifying ﬁve stages but could not classify
the mild stage accurately, due to the nature of architecture.
Another limitation is that they used the skewed dataset of
Kaggle that led to the high speciﬁcity with the tradeoff in
low sensitivity. Yang et al. proposed DCNN (Deep Convolution Neural Network) for two stages of DR (normal and
NPDR). The preprocessed data is given as input to the two
networks (local and global). Lesions are highlighted and sent
to the global network for grading. They used class weight and
kappa scores for evaluation of the model. However, the PDR
stage was not considered in their work.
In , , the authors checked the performance of the
Kaggle dataset over different CNN models. Garcia et al. 
proposed a method of using the right and left eye images
separately and applied CNN (Alexnet, VGGnet16, etc.). The
preprocessing and augmentation phases were performed on
the dataset to improve the contrast of images. They achieve
the best results on VGG16 with no fully connected layer
and achieved 93.65% speciﬁcity, 54.47% sensitivity, and
VOLUME 7, 2019
S. Qummar et al.: Deep Learning Ensemble Approach for DR Detection
TABLE 1. Dataset: distribution of different classes.
83.68% accuracy. However, DR stages were not explicitly
classiﬁed in their work. Dutta et al. used Kaggle dataset
with three deep learning models (Feed Forward Neural Network (FNN), Deep Neural Network (DNN), and Convolutional Neural Network (CNN). They used 2000 images out
of 35128 images with a 7:3 validation split. They applied
many preprocessing steps (median, mean, Std deviation, etc.)
and then trained their model on the training dataset. The Best
training accuracy of 89.6% was obtained on DNN.
We can summarize all these works of DR classiﬁcation
problem into two groups. The ﬁrst one is the binary classiﬁcation of DR i.e. either the patient has DR or not. The
problem in this method is we can not identify the severeness
of the disease even after knowing that a patient has DR.
The solution to this problem is multi-class classiﬁcation.
In multi-class classiﬁcation, we classify DR into ﬁve different
classes or stages as discussed in the introduction section. But
most of the related work is unable to properly classify all the
stages of DR, especially the early stages. It is important to
predict the DR at early stages for the cure as in later stages
it is difﬁcult to cure the disease and can lead to blindness.
To the best of our knowledge, no other work has detected the
mild stages of DR, by using the Kaggle dataset which we
have used for our research. Our model can detect the mild
stage and performs better than the current state of the art.
Moreover, in the related work, no one has shown the effect
of a balanced dataset. The imbalanced dataset can lead to
bias in the classiﬁcation’s accuracy. If the samples in the
classes are equally distributed as in the case of a balanced
dataset then the network can learn the features properly, but in
case of unequal distribution network outperforms for highly
sampled class. Moreover, the current CNN architectures for
DR detection lacks to analyze the effect of different hyperparameters tuning (meta-learning) and its implications.
III. PROPOSED METHOD
A. PREPROCESSING
The different preprocessing steps that we perform on input
dataset before giving it to the model are shown in Figure 2
We use the Kaggle2 dataset which contains 35126 color
fundus images, each is of size 3888 × 2951. It contains the
images from ﬁve different classes based on the severity of
diabetic retinopathy (DR). Table 1, shows the distribution
of sample images in different classes of the Kaggle dataset
The distribution of different classes is shown in the ﬁrst row
of Table 1, which is perfectly imbalanced. Training of deep
2 
FIGURE 2. The different preprocessing steps.
networks with imbalance data leads to classiﬁcation biasness.
In the ﬁrst preprocessing step, we resize each input image
shown in Figure 2 (a) to 786 × 512 shown in Figure 2 (b)
by maintaining the aspect ratio to reduce the training overhead of deep networks. Moreover, for balancing the dataset
we performed up-sampling and down-sampling . The
up-sampling (The Table 1, second row) is performed with
augmentation of minority classes by randomly cropping
patches, of size 512 × 512 as shown in Figure 2 (c), followed by ﬂipping and 90o rotation to balance the samples
of different classes, enrich dataset and avoid overﬁlling as
shown in Figure 2 (e). In down-sampling (Table 1, third row)
extra instances of majority classes are removed to meet the
cardinality of the smallest class. In the resultant distributions,
before ﬂipping and rotation, each image is mean normalized to avoid features biasness and speed-up training time,
shown in Figure 2 (d). The dataset is divided into three parts:
training, testing, and validation sets with ratio 64% and 20%
and 16% respectively. During training, the validation set is
used to check and reduce the over-ﬁtting.
B. ENSEMBLE MODEL
Ensemble method is a meta-algorithms that combine several machine learning techniques into one predictive model.
VOLUME 7, 2019
S. Qummar et al.: Deep Learning Ensemble Approach for DR Detection
Algorithm 1 Proposed Algorithm
Require: Fundus Images (X, Y); where Y = {y/y ∈{Normal, Mild, Moderate, Severe, PDR}}
Output : The trained model that classiﬁes the fundus image x ∈X
1 Perform Preprocessing:
• Resize the image to dimension 786 × 512
• Perform augmentation: Randomly crop ﬁve patches, of size 512 × 512, of each image and perform ﬂip ﬂop and 90o
• Mean normalize the each image
Import a set of pre-trained models H = {Resnet50, Inceptionv3, Xception, Dense121, Dense169}.
Replace the last fully connected layer of each model by a layer of (5 × 1) dimension.
foreach ∀h ∈H do
for epochs=1 to 50 do
foreach mini batch (Xi, Yi) ∈(Xtrain, Ytrain) do
Update the parameters of the model h(·) using Eq.(2)
if the validation error is not improving for ﬁve epochs then
α = α × 0.01
foreach x ∈Xtest do
Ensemble the output of all models, h ∈H, using Eq.(3)
It can be used for different objectives such as to decrease
variance (Bagging), bias (boosting), or improve predictions
(stacking). Stacking is a model used to combine information
from multiple predictive models to generate a new model. The
stacked approach often outperform individual models due
to its soothing nature. Stacking highlights each base model
where it performs best and discredits each base model where
it performs poorly. For this reason, stacking is most effective
when the base models are signiﬁcantly different. For this
reason, we used stacking to improve the prediction of our
model, which is evident from our results
The proposed approach ensembles the ﬁve deep CNN
models Resnet50 , Inceptionv3 , Xception ,
Dense - 121 , Dense169 . Algorithm 1 presents the
proposed model in detail. Let H = {Resnet50, Inceptionv3,
Xception, Dense121, Dense169} be the set of pre-trained
models. Each model is ﬁne tuned with the Fundus Images
dataset (X, Y); where X the set of N images, each of size,
512 × 512, and Y contain the corresponding labels, Y =
{y/y ∈{Normal, Mild, Moderate, Severe, PDR}}. We divide
the training set (Xtrain, Ytrain) into mini batches, each of size
n = 8, such that (Xi, Yi) ∈(Xtrain, Ytrain), i = 1, 2, . . . N
iteratively optimizes (ﬁne tuning) the CNN model h ∈H to
reduce the empirical loss:
L(w, Xi) = 1
l(h(x, w), y)
where h(x, w) is the CNN model that predicts class y for
input x given w and l(·) is the categorical cross-entropy
loss penalty function. The Nesterov-accelerated Adaptive
Moment Estimation is used to update the learning
parameters:
wt+1 =wt −
∂wt L(wt, Xi)
where α, ˆm and ˆv are the learning rate, ﬁrst-order moment and
a second-order moment of the gradient respectively. While β1
and β2 represent the decarov Momentum hy rates which are
initially set to 0.9. The Nestelps to know the direction of the
next step and avoid the ﬂuctuations. In the start wt, t = 0,
is initialized to the learned weights of the model h ∈H using
transfer learning . The output layer of each model, h ∈H,
uses SoftMax as an activation function which generates the
probabilities that how much the input belongs to the set
of different classes {Normal, Mild, Moderate, Severe, PDR}.
The learning rate, α, is initially set to 10−2 and decreased by
a factor of 0.1 to 10−5. We use 50 epochs for training with
early stopping if the model starts over-ﬁtting.
In the case of testing, to predict the class label of the
unseen example, we use stacking to combine the results of all
different models and generate a uniﬁed output. The ensemble
approach combines the strengths of individual models and
leads to better performance. The proposed stacking ensemble
is illustrated in Figure 3. Let xtest be a new test sample, then
the ensemble output is given by:
m∗= arg max
∀h∈H h(w, xtest)
VOLUME 7, 2019
S. Qummar et al.: Deep Learning Ensemble Approach for DR Detection
TABLE 2. The distribution of samples in test datasets.
FIGURE 3. Proposed ensemble model.
where h(·) is the ﬁne tuned model, |H| is the cardinality of
the models and m represents the different modalities such that
m ∈{Normal, Mild, Moderate, Severe, PDR}.
In the case of imbalanced training data, the accuracy tends
to bias towards majority classes .
IV. RESULTS AND DISCUSSION
In this section results of the proposed model are compared
with state-of-the-artwork. The proposed model is trained
on a high-end Graphics Processing Unit (GPU). The GPU
used (NVIDIA Tesla k40) contains 2880 CUDA core and
comes with NVIDIA CUDA Deep Neural Network library
(CuDNN) for GPU learning. The deep learning package
Keras3 was used with the4 TensorFlow machine learning back
end library.
A. PERFORMANCE PARAMETERS
To quantitatively evaluate the proposed model we use
accuracy, sensitivity, speciﬁcity, precision, F1 measures,
AUC and ROC as performance metrics.
Accuracy: The accuracy can be calculated in terms of
positive and negative classes:
Accuracy =
TP + TN + FP + FN
where TP (True Positives) is the number of correctly classiﬁed instances of the class under observation, TN (True
Negatives) is the number of correctly classiﬁed instances of
rest of the classes, FP (False Positives) is the number of
miss-classiﬁed instances of rest of the classes and FN (False
Negatives) is the number of miss-classiﬁed instances of the
class under observation.
3 
4 
TABLE 3. Imbalanced confusion matrix.
Recall/Sensitivity: it is the ratio of TP and TP + FN
Sensitivity =
Speciﬁcity: it is the ratio of TN and TN + FP Highlight
Speciﬁcity =
Precision: it is the ratio of TP and TP + FP Highlight
Precision =
F1-Score: it is the weighted harmonic mean of precision
and recall:
F1 = 2 × Precision × Recall
Precision + Recall .
It return score between 0 and 1, where 1 means best score and
0 is the worst.
Receiver Operating Curve (ROC) : plots the true
positive rate (TPR) against the false positive rate (FPR).
Area Under The Curve (AUC) : It represents the
degree or measure of separability of different classes. The
higher the AUC score means the better the model and
vice versa.
To show the effect of the imbalanced dataset we have used
three different datasets that are i) Imbalanced ii) Up Sample
and iii) Down Sample Dataset. In the end, we also have
shown the effect of different hyper-parameters on the overall
performance of the model. The distribution of Test dataset
samples is given in Table 2.
Imbalanced Dataset: The distribution of imbalanced
dataset test samples of different classes is given in the ﬁrst
row of Table 2. However, accuracy is a misleading metric
when the dataset is highly imbalanced , it gives bias
results. In our case, the accuracy achieved is biased towards
the negative class which is class-0 (normal). So along with
accuracy, we have also used other parameters such as Recall,
Precision, Speciﬁcity, F1-score, and ROC-curve to provide
unbiased results. The achieved accuracy, recall, speciﬁcity,
VOLUME 7, 2019
S. Qummar et al.: Deep Learning Ensemble Approach for DR Detection
TABLE 4. Comparison of the proposed method with Pratt et. al .
precision, and F1-score are 80.8%, 51.5%, 86.72%, 63.85%
and 53.74% respectively. Table 3 shows the confusion matrix
of a ﬁnal ensemble model. Where recall, speciﬁcity, precision
and F1-score of each class is shown in Table 4 along with the
comparison of Pratt et al. results. Class 0 give maximum
recall due to the more number of negative samples which
also provides better accuracy. Class 1 gives minimum recall
due to a very minute characteristic and feature which make it
difﬁcult to detect DR stage.
FIGURE 4. Comparison of our model with .
TABLE 5. Confusion of up sample dataset.
Figure 4 shows the summary of our results on an imbalanced dataset and provides a comparison with Pratt et al. .
The model proposed by Pratt is considered for comparing
our results because it uses the same dataset and works on
classifying the ﬁve stages of DR. However, they are unable
to classify the mild stage. In the best of our knowledge,
no other model classiﬁes all the ﬁve stages of DR using
Kaggle dataset. Our model outperforms the Pratt et al. 
model in all performance parameters as shown in ﬁgure 4.
The accuracy, sensitivity, speciﬁcity, precision, and F1-score
of our model and Pratt et al are shown in Figure 4. As our
model improves the accuracy, sensitivity, precision, F1-score
and decreases the speciﬁcity. Moreover, our model detects
and classiﬁes all ﬁve stages of DR. Further for our model we
also calculated the ROC (Receiver Operating Characteristics)
FIGURE 5. ROC-curve of imbalanced dataset.
TABLE 6. Performance measure of each class of up sample dataset.
TABLE 7. Performance measure of each class of down sample dataset.
shows in Figure 5. As the ROC curve shows how our model
distinguishes among classes. The highest AUC of 0.97 is
achieved by class 4 which has 113 samples. The ROC curve
of class-0 is 0.85. The micro and macro average also shows
the overall performance of the model. As, the micro-average
ROC sum up the individual true positive, false positive and
false negative and then map a value on a graph. Where
macro-average takes the average of precision and recall and
map a value on a graph. However, the micro-average ROC
is considered when the dataset is highly imbalanced. The
Result with Balanced Dataset: There are many techniques for
balancing the datasets, such as penalized Models, Anomaly
Detection, etc. , . However, we used up and downsampling because the network preferred to minimize the loss
by just learning to classify the high-occurrence classes well
and ignoring the low-occurrence ones.
VOLUME 7, 2019
S. Qummar et al.: Deep Learning Ensemble Approach for DR Detection
TABLE 8. Configuration of Hyper-parameters in models.
TABLE 9. SGD and Adam with different learning rate on imbalanced, up sample and downsample dataset.
The distribution of Up and Down samples dataset for
training and test sets are shown in Table 1 and Table 2
respectively. The confusion matrix of Up Sample Dataset is
shown in Table 5 and sensitivity, speciﬁcity, precision and
F1-score of each class are given in Table 6.
FIGURE 6. ROC-curve of up sample dataset.
The ROC curve of up sample dataset is shown in Figure 6.
The maximum calculated AUC for class 0 is 0.97, which
shows our model predicts well for this class. On a balanced
dataset, micro and macro average ROC curves have the same
value that is 0.90. For down sample datasets, to remove the
biasness of accuracy we randomly consider ten different subsets of this dataset. Each subset contains 113 images of each
class. All the performance measures for the downsampled
dataset are averaged over the ten subsets. Results of the Down
sampled Dataset is shown in Table 7. The accuracy, recall,
precision, speciﬁcity, and F1-Score achieved by the downsampling are 58.08%, 58.10%, 70.3%, 85.5%, and 53.64%
respectively.
The results obtained for imbalanced and balanced (Random Up and Downsampling) datasets are shown in Table 9.
The trends illustrated that if the learning rate reduces from
0.01 to 1e-05 the recall and accuracy improves, but the
speciﬁcity is affected due to misclassiﬁcation of the positive
class. Table 10 and 11 shows how the change in learning
rate affects the model in classifying the positive class images
based on precision-recall and AUC. As AUC is better when
its value is near to 1 but if the value is 50 or below 50 then
a model is poor. With the learning rate value set to 0.01,
the model train very fast, but misclassiﬁed the positive classes
in both datasets (Imbalanced and Up). When a learning rate
value is reduced to 0.0001 we get a minor improvement in the
model. However, the learning rate value is again decreased
VOLUME 7, 2019
S. Qummar et al.: Deep Learning Ensemble Approach for DR Detection
TABLE 10. SGD with imbalanced, up, and down dataset precision-recall and AUC.
TABLE 11. Adam with imbalanced, up, and down sample dataset precision-recall and AUC.
to 1e-05, the result suggested the major improvement. This
is due to setting the learning rate value very small, which
helps a model to learn the minute features of images. Here,
in an Imbalanced dataset, the AUC curve shows better results
because the model detects only negative class were in up
sample dataset, the value of the AUC curve is also good
because samples are equally distributed. In both (imbalanced
and up) datasets AUC curve shows better results. In Imbalanced dataset results, the sample distribution is unequal as
a negative class has maximum images but in the Up sampled
dataset, the sample distribution is equal, so the model predicts
an accurate result.
Hyper-parameters Setting The parameters of the CNN
which need to be set by the user prior to the ﬁlter learning are
called hyper-parameter. Hyper-parameters are the variables
related to the structure of the network (e.g. number of layers and number units in each layer) training (e.g. learning
rate). These parameters are adjusted before training (before
optimizing the weights and bias). In order to set the values
of other hyper-parameter, we have adopted good practices
from literature. For the learning rate, we have considered
three different values while two optimizers are considered
as shown in Table 8. Table 8 shows ﬁve architecture as
mentioned above are trained with different hyper-parameters.
After completion of training, all architectures are ensembled.
Table 9 shows the accuracy, recall, precision, speciﬁcity, and
F1-score of SGD and Adam optimizer with different learning
rates. The learning rate is decreased from 0.01 to 1e-05. The
performance of the model increases with a decrease in the
learning rate. Also, it can be noted that most of the time SGD
has better performances than Adam.
V. CONCLUSION
Diabetes is one of the fast-growing diseases in recent times.
According to various surveys, a patient having diabetes has
around 30% chances to get Diabetic Retinopathy (DR). DR
has different stages from mild to severe and then PDR
(Proliferative Diabetic Retinopathy). In the later stages of
the diseases, it leads to ﬂoaters, blurred vision and ﬁnally
can lead to blindness if it is not detected in the early
stages. Manual diagnosis of these images requires highly
trained experts and is time-consuming and difﬁcult. Computer vision-based techniques for automatic detection of DR
and its different stages have been proposed in the literature.
In this paper, we focused to classify all the stages of DR,
especially the early stages, which is the major shortcoming of
VOLUME 7, 2019
S. Qummar et al.: Deep Learning Ensemble Approach for DR Detection
existing models. We proposed a CNN ensemble-based framework to detect and classify the DR’s different stages in color
fundus images. We used the largest publicly available dataset
of fundus images (Kaggle dataset) to train and evaluate our
model. The results show that the proposed ensemble model
performs better than other state-of-the-art methods and is also
able to detect all the stages of DR. In future in order to further
increase the accuracy of early-stage, we plan to train speciﬁc
models for speciﬁc stages and then ensemble the outcome in
order to increase the accuracy of early stages.
ACKNOWLEDGMENT
The authors would like to thank Nvidia Corporation for
donating us a Telsa K-40 GPU for our project.