Proceedings of IEEE conference on “Computer Vision and Pattern Recognition” (CVPR), 1998
Markov Random Fields with Eﬃcient Approximations
Yuri Boykov
Olga Veksler
Ramin Zabih
Computer Science Department
Cornell University
Ithaca, NY 14853
Markov Random Fields (MRF’s) can be used for a
wide variety of vision problems. In this paper we focus on MRF’s with two-valued clique potentials, which
form a generalized Potts model.
We show that the
maximum a posteriori estimate of such an MRF can
be obtained by solving a multiway minimum cut problem on a graph. We develop eﬃcient algorithms for
computing good approximations to the minimum multiway cut. The visual correspondence problem can be
formulated as an MRF in our framework; this yields
quite promising results on real data with ground truth.
We also apply our techniques to MRF’s with linear
clique potentials.
Introduction
Many early vision problems require estimating
some spatially varying quantity (such as intensity, texture or disparity) from noisy measurements.
problems can be naturally formulated in a Bayesian
framework using Markov Random Fields . In this
framework, the task is to ﬁnd the maximum a posteriori (MAP) estimate of the underlying quantity. Bayes’
rule states that the posterior probability Pr(f|O) of
the hypothesis f given the observations O is proportional to the product of the likelihood Pr(O|f) and
the prior probability Pr(f).
The likelihood models
the sensor noise, and the prior describes preferences
among diﬀerent hypotheses.
In this paper, we focus on MAP estimation of a
class of Markov Random Fields which generalizes the
Potts model . These MRF’s have Gibbs clique potentials with a particular form that resembles a well.
We begin by describing the generalized Potts model,
and giving an energy function that has a global minimum at the MAP estimate. In section 3 we show that
the global minimum of this energy function can be obtained by ﬁnding a minimum multiway cut on a graph,
and give a greedy method for computing a multiway
cut. Section 4 formulates the visual correspondence
problem as a generalized Potts model.
We demonstrate the eﬀectiveness of our approach
for computing stereo depth in section 5. For example, we have benchmarked several algorithms using
real images with dense ground truth.
Our method
produces an incorrect result at under 3% of the pixels, while correlation-based methods produce approximately 10% errors.
In section 6 we describe some
related work where graph cuts are applied to vision
problems, and we show that our techniques can be
used to eﬃciently compute the MAP estimate of an
MRF with linear clique potentials.
Markov Random Fields
Markov Random Fields were ﬁrst introduced into
vision by Geman and Geman . The MRF framework can express a wide variety of spatially varying priors. An MRF has several components: a set
P = {1, . . . , m} of sites p, which will be pixels; a neighborhood system N = { Np | p ∈P } where each Np is a
subset of pixels in P describing the neighbors of p; and
a ﬁeld (or set) of random variables F = { Fp | p ∈P }.
Each random variable Fp takes a value fp in some
set L = {l1, . . . , lk} of the possible labels (for example,
the possible intensities or disparities). Following a
joint event {F1 = f1, . . . , Fm = fm} is abbreviated as
F = f where f = { fp | p ∈P } is a conﬁguration of
F, corresponding to a realization of the ﬁeld. We will
write Pr(F = f) as Pr(f) and Pr(Fp = fp) as Pr(fp).
In order to be an MRF, F must satisfy
Pr(fp|fS−{p}) = Pr(fp|fNp), ∀p ∈P.
This condition states that each random variable Fp
depends on other random variables in F only through
its neighbors in FNp = {Fq| q ∈Np}.
The key result concerning Markov Random Fields
is the Hammersley-Cliﬀord theorem. This states that
the probability of a particular conﬁguration Pr(f) ∝
C VC(f)), where the sum is over all cliques
in the neighborhood system N. Here, VC is a clique
potential, which describes the prior probability of a
particular realization of the elements of the clique C.
Proceedings of IEEE conference on “Computer Vision and Pattern Recognition” (CVPR), 1998
We will restrict our attention to MRF’s whose
clique potentials involve pairs of neighboring pixels,
Pr(f) ∝exp
V(p,q)(fp, fq)
In general, the ﬁeld F is not directly observable in the
experiment. We have to estimate its realized conﬁguration f based on the observation O, which is related
to f by means of the likelihood function Pr(O|f). In
image restoration, O is the joint event {Ip = ip} over
all p ∈P, where Ip denotes the observable intensity
at pixel p and ip is its particular realization. If Fp denotes the true intensity at p then assuming i.i.d. noise
where g(ip, fp) = Pr(Ip = ip|Fp = fp) represents the
sensor noise model.
We will make a slightly more general assumption.
We will assume that the likelihood can be written as
g(i, p, fp),
where i is a conﬁguration of some ﬁeld I that can be
directly observed and g is a sensor noise distribution
(0 ≤g ≤1). An example of a likelihood function with
this general structure can be found in section 4.
We wish to obtain the conﬁguration f ∈L ×
. . . × L = Lm that maximizes the posterior probability Pr(f|O).
Bayes’ law tells us that Pr(f|O) ∝
Pr(O|f)Pr(f).
It follows that our MAP estimate f
should minimize the posterior energy function
V(p,q)(fp, fq) −
ln (g(i, p, fp)) .
The generalized Potts model
We now consider MRF’s with clique potentials that
resembles a well. If δ(·) represents the unit impulse
function, then u (1 −δ(·)) is a well with “depth” u.
A Generalized Potts Model MRF (GPM-MRF) has a
clique potential for any pair of neighboring pixels p
and q given by
V(p,q)(fp, fq) = u{p,q} · (1 −δ(fp −fq)),
where the coeﬃcient u{p,q} ≥0 speciﬁes the depth
of the well. If u{p,q} is a constant, then this yields
the Potts model . Note that {p, q} is a set, not a
tuple, so V(p,q)(fp, fq) = V(q,p)(fq, fp). These MRF’s
are thus isotropic (i.e., independent of orientation).
The prior probability of a GPM-MRF is therefore
Pr(f) ∝exp
2u{p,q}(1 −δ(fp −fq))
where EN is the set of distinct {p, q} such that q ∈Np.
Each term in the summation above equals 2u{p,q} if
p and q have diﬀerent labels (fp ̸= fq) and zero otherwise.
The coeﬃcient u{p,q} can be interpreted as
a cost of a “discontinuity” between p and q, that is,
the penalty for assigning diﬀerent labels to neighboring pixels p and q. The sum in the exponent above
is proportional to the total cost of discontinuities in
f. The prior probability Pr(f) is therefore larger for
conﬁgurations f with fewer discontinuities.
The posterior energy function of a GPM-MRF is
2u{p,q}(1 −δ(fp −fq))
ln (g(i, p, fp)) .
The MAP estimate f minimizes E(f). Thus, it should
both agree with the observed data and have a small
number of discontinuities.
Note that the clique potential of such an MRF resembles a robust estimator, in that it has a ﬁxed maximum value (in the language of robust statistics, it is redescending). Most vision applications of MRF’s follow
 by introducing a line process that explicitly models discontinuities. showed that if spatial restrictions on discontinuities are ignored, the line process
can be eliminated by using a robust penalty function.
We take a related approach, by using a re-descending
clique potential instead of a line process.
Optimizing the energy function
In this section we show that minimizing the energy
function E(f) in (3) over f ∈Lm is equivalent to solving a multiway cut problem on a certain graph. In section 3.1 we give another formulation of the posterior
energy minimization problem that is equivalent to (3).
This formulation, shown in equation (4), reduces the
search space for f and simpliﬁes our transition to the
graph problem. Then in section 3.2 we construct a
particular graph, and prove that solving the multiway
cut problem on this graph is equivalent to minimizing
the energy function of equation (4). In section 3.3 we
describe an algorithm for approximating the minimum
multiway cut.
Reformulating the energy function
We want to ﬁnd f ∗∈Lm that minimizes E(f) in
(3). It is straightforward to reduce the search space
Proceedings of IEEE conference on “Computer Vision and Pattern Recognition” (CVPR), 1998
for f ∗. Assuming E(f ∗) is ﬁnite, we can always ﬁnd
some constant K(p) for each pixel p satisfying
−ln(g(i, p, f ∗
p)) < K(p).
For example, if no better argument is available we can
always take K(p) = K = E(f) where f is any ﬁxed
conﬁguration of F such that E(f) is ﬁnite.
For a given collection of constants K(p) we deﬁne
Lp = {l ∈L :
−ln(g(i, p, l)) < K(p)}
for each pixel p in P. Each Lp prunes out a set of
labels which cannot be assigned to p in the optimal
For example, if we take K(p) = E(f) as
suggested above, then for l ̸∈Lp a single sensor noise
term −ln(g(i, p, l)) in (3) will exceed the total value
of the posterior energy function E(f) at some con-
ﬁguration f.
Each Lp is a nonempty set, since it
contains f ∗
p . Our search can be restricted to the set
¯L = L1 × . . . × Lm, since f ∗is in ¯L.
It is possible to rewrite −ln(g(i, p, fp)) as
(ln(g(i, p, l)) + K(p))
where ¯K(p) is some constant that does not depend on
fp. It follows that minimizing E(f) in (3) is equivalent
to minimizing
2u{p,q}(1 −δ(fp −fq))
h(i, p, l)
where h(i, p, l) = ln(g(i, p, l)) + K(p) and the minimization takes place over f ∈¯L. Note that h(i, p, l) >
0 for any p ∈P and for any l ∈Lp.
Multiway cut formulation
Consider a graph G = ⟨V, E⟩with non-negative edge
weights, along with a set of terminal vertices L ⊂V.
A subset of edges C ⊂E is called a multiway cut if
the terminals are completely separated in the induced
graph G(C) = ⟨V, E −C⟩.
The cost of the cut C is
denoted by |C| and equals the sum of its edge weights.
The multiway cut problem is to ﬁnd the minimum cost
multiway cut.
We now show that the minimization problem in (4)
is equivalent to a multiway cut problem. We begin by
constructing G. We take V = P ∪L. This means that
G contains two types of vertices: p-vertices (pixels)
and l-vertices (labels). Note that l-vertices will serve
p-vertices (pixels)
terminals (l-vertices or labels)
Figure 1: An example of the graph G = ⟨V, E⟩where
the terminals are L = {l1, . . . , lk} and p-vertices are
elements of P = {1, . . . , p, q, . . . , m}. Each p-vertex is
connected to at least one terminal.
as terminals for our multiway cut problem. Two pvertices are connected by an edge if and only if the
corresponding pixels are neighbors in N. Therefore,
the set EN corresponds to the set of edges between
p-vertices. We will refer to elements of EN as n-links.
Each n-link {p, q} ∈EN is assigned a weight
w{p,q} = 2u{p,q}.
A p-vertex is connected by an edge to an l-vertex
if and only if l ∈Lp. An edge {p, l} that connects a
p-vertex with a terminal (an l-vertex) will be called a
t-link and the set of all such edges will be denoted by
ET . Each t-link {p, l} ∈ET is assigned a weight
w{p,l} = h(i, p, l) +
Note that each p-vertex is connected to at least one
terminal since Lp is non-empty. No edge connects terminals directly to each other. Therefore, E = EN ∪ET .
Figure 1 shows the general structure of the graph G.
Since a multiway cut separates all terminals it can
leave at most one t-link at each p-vertex. A multiway cut C is called feasible if each p-vertex is left with
exactly one t-link. Each feasible multiway cut C corresponds to some conﬁguration f C in ¯L in an obvious
manner: simply assign the label l to all pixels p which
are t-linked to the l-vertex in G(C).
Lemma 1 A minimum cost multiway cut C on G for
terminals L must be feasible.
Proceedings of IEEE conference on “Computer Vision and Pattern Recognition” (CVPR), 1998
Due to equation (6), each t-link {p, l} has a
weight larger then the sum of weights of all n-links adjacent to the p-vertex. If a multiway cut of minimum
cost is not feasible then there exists some p-vertex with
no t-link left. In such a case we will obtain a smaller
cut by returning to the graph one t-link {p, l} for an
arbitrary l ∈Lp and cutting all n-links adjacent to
this p-vertex.
Theorem 1 If C is a minimum cost multiway cut on
G, then f C minimizes E(f) in (3).
Lemma 1 allows to concentrate on feasible
multiway cuts only. Note that distinct feasible multiway cuts C1 and C2 can induce the same conﬁguration f C1 = f C2. However, among all feasible cuts
corresponding to the same f ∈¯L there is a unique
irreducible cut C, where irreducible means that it does
not sever n-links between two p-vertices connected to
the same terminal in G(C). It follows that there is a
one to one correspondence between conﬁgurations f
in ¯L and irreducible feasible multiway cuts on the G.
Obviously, the minimum multiway cut should be
both feasible and irreducible. To conclude the theorem
it suﬃces to show that the cost of any irreducible feasible multiway cut C satisﬁes |C| = A + ¯E(f C), where
A is the same constant for all irreducible feasible multiway cuts. Since C is feasible, the sum of the weights
for t-links in C is equal to
Since C is irreducible, the sum of weights for the nlinks in the cut is equal to
w{p,q}(1 −δ(f C
The theorem now follows from (5) and (6).
Multiway cut minimization
While the general multiway minimum cut problem
is NP-complete, there are provably good approximations with near linear running time , and this is an
area of active research. Approximating cuts, however,
should be used carefully. If C approximates the minimum multiway cut on G within some known bounds,
the value of E(f C) might not be within the same
bounds with respect to the exact minimum of the posterior energy in (3). For example, cuts produced by
the algorithm in are not guaranteed to be even feasible. Here we describe a method that greedily reduces
the cost of multiway cuts on G. Our algorithm generates a cut C such that f C is a local minimum of the
posterior energy function (3) in a certain strong sense.
Our algorithm considers only irreducible feasible
cuts on G. Any such cut can be uniquely represented
by a feasible partition PV = { Vl | l ∈L } of the set
V where l ∈Vl and p ∈Vl implies l ∈Lp. An irreducible feasible cut C corresponds to PV where each
Vl contains l plus all pixels p ∈V connected to l
As an initial solution we can take any irreducible feasible cut.
For example, consider a cut
where Vl = {l} ∪{ p ∈V | l = min Lp }.
At each iteration we consider a ﬁxed pair of distinct labels {l, λ} ⊂L. The basic operation is to improve the current cut C, that is the current feasible
partition PV, by reallocating pixels in Vl ∪Vλ between
the terminals l and λ More speciﬁcally, we solve a
standard two terminal min cut problem on a graph
G{l,λ} = ⟨V{l,λ}, E{l,λ}⟩, where V{l,λ} = Vl ∪Vλ and
E{l,λ} includes all edges in E that connect vertices in
V{l,λ}. The optimal cut on G{l,λ} divides the pixels in
V{l,λ} between the terminals l and λ and, thus, generates the new sets V′
λ. This yields a new feasible
partition P′
V corresponding to an irreducible feasible
cut C′ such that |C′| ≤|C|. If the inequality is strict,
we call the iteration successful and accept the new cut
C′. If not, we stick to the old cut C.
At each iteration we take a new pair of terminals
until all distinct pairs were considered. Then, we start
a new cycle of iterations and consider the pairs of
terminals all over again. The algorithm stops when
no successful iterations were made in a cycle.
obtained multiway cut C yields f C with the following property: the value of the energy function E(f C)
cannot be decreased by switching any subset of pixels
with one common label l to any other common label
λ. This means that f C achieves a local minimum of E
in a richer “move space” than the obvious one where
a move changes the label of a single pixel.
currently developing a more sophisticated algorithm
which achieves an even stronger local minimum, where
the energy function cannot be decreased by switching
any set of pixels to a common label λ.
Each cycle of the algorithm is quadratic in the number of labels and has the same eﬀectively linear time
complexity in the number of nodes as a standard min
cut algorithm. We do not have any bounds on the
number of cycles it takes to complete the algorithm.
Nevertheless, in the visual correspondence applications we considered the algorithm produced promising
results even after the ﬁrst cycle. In section 5 we show
these one cycle results.
Proceedings of IEEE conference on “Computer Vision and Pattern Recognition” (CVPR), 1998
Computing Visual Correspondence
We now describe how these techniques can be applied to the visual correspondence problem, which is
the basis of stereo and motion. Given two images of
the same scene, a pixel in one image corresponds to a
pixel in the other if both pixels are projections along
lines of sight of the same physical scene element. The
problem is to determine this correspondence between
pixels of two images.
We begin by showing how to formulate the correspondence problem as a GPM-MRF, and thus as a
multiway cut problem. We arbitrarily select one of the
images to be the primary image. Let P denote the set
of pixels in the primary image and S denote a set of
pixels of the second image. The quantity to be estimated is the disparity conﬁguration d = { dp | p ∈P }
on the primary image where each dp establishes the
correspondence between the pixel p in the primary image and the pixel s = p ⊕dp in the second image.1
We assume that each dp has a value in L, which is
a ﬁnite set of possible disparities. For simplicity, we
consider conﬁgurations d ∈Lm. (This allows doubleassignments, since distinct pixels p and q in P can
correspond to the same pixel p⊕dp = q ⊕dq.) The information available consists of the observed intensities
of pixels in both images. Let IP = { Ip | p ∈P } and
IS = { Is | s ∈S } be the random ﬁelds of intensities
in the primary and in the second images. Assume also
that ip denotes the observed value of intensity Ip.
Incorporating context
Note that the intensities of pixels in P contain information that can signiﬁcantly bias our assessment
of disparities without even considering the second image. For example, two neighboring pixels p and q in P
are much more likely to have the same disparity if we
know that ip ≈iq. Most methods for computing correspondence do not make use of this kind of contextual
information. An exception is , which describes a
method also based on MRF’s. In their approach, intensity edges were used to bias the line process. They
allow discontinuities to form without penalty on intensity edges. While our MRF’s do not use a line process,
we can easily incorporate contextual information into
our framework.
Formally, we assume that the conditional distribution Pr′(d) = Pr(d | IP) is a distribution of a GPM-
MRF on P with neighborhood system N. Pr′(d) can
be viewed as a “prior” distribution of d before the
1To be precise, p ⊕dp stands for the pixel in S whose 2D
coordinates are obtained by adding the disparity dp to the 2D
coordinates of p.
information in the second image is disclosed. Conditioning on IP permits clique potential “depths”
u{p,q} = U(|ip −iq|),
∀{p, q} ∈EN .
Each u{p,q} represents a penalty for assigning diﬀerent disparities to neighboring pixels p and q in P. The
value of the penalty u{p,q} should be smaller for pairs
{p, q} with larger intensity diﬀerences |ip−iq|. In practice we use an empirically selected decreasing function
U(·). Note that instead of (7) we can set the coeﬃcients u{p,q} according to an output of an edge detector on the primary image. For example, u{p,q} can
be made small for pairs {p, q} where an intensity edge
was detected and large otherwise. Segmentation of the
primary image can also be used.
The following example shows the importance of
contextual information. Consider the pair of synthetic
images below, with a uniformly white rectangle in
front of a uniformly black background.
Primary image (IP)
Second Image (IS)
There is a one pixel horizontal shift in the location of
the rectangle, and there is no noise. Without noise,
the problem of estimating d = { dp | p ∈P } is reduced
to maximizing the prior Pr′(d) under the constraint
that pixel p in P can be assigned a pixel p ⊕dp in S
only if they have the same intensity.
If u{p,q} is the same for all pairs of neighbors {p, q}
in P then Pr′(d) is maximized at the disparity con-
ﬁguration shown either in the left or in the middle
pictures below depending on the exact height of the
rectangle.
u{p,q} = const
u{p,q} = const
u{p,q} ̸= const
Suppose now that the penalty u{p,q} is much smaller
if ip ̸= iq than it is if ip = iq. In this case the maximum of Pr′(d) is achieved at the disparity conﬁguration shown in the right picture. This result is much
closer to human perception.
Sensor noise
The sensor noise is the diﬀerence in intensities between corresponding pixels. We assume that the like-
Proceedings of IEEE conference on “Computer Vision and Pattern Recognition” (CVPR), 1998
lihood function is
Pr′(IS | d) = Pr(IS | d, IP) ∝
g(ip⊕dp|ip)
where d is the true disparity correspondence. Here,
g(is | ip) is the conditional distribution of intensity at
pixel s in the second image given the intensity at pixel
p in the primary image if the two pixels are known to
correspond. The function g is determined by the sensor noise model, and typically g(is | ip) is a symmetric
distribution centered at ip.
Obviously, g(ip⊕dp|ip) can be rewritten as g(i, p, dp)
and therefore the noise model in (8) is consistent with
equation (1). Note that the main idea behind assumption (8) is that sensor noise is independent.
Equations (7) and (8) complete the description of
our GPM-MRF model for visual correspondence. Now
the multiway cut approach of section 3 can be used to
estimate a disparity conﬁguration d.
Experimental results
In this section we give some experimental results
on stereo data that use our greedy multiway cut algorithm of section 3.3. For simplicity, we have used a
uniform noise model for g. We also used a two-valued
function U(|ip −iq|), which has a large value if ip is
close to iq, and a small value otherwise. The parameter values used for the algorithms in the experiments
in this section were determined by hand. We used the
parameters that gave the results with the best overall
appearance. Empirically, our method’s performance
does not appear to depend strongly upon the precise
choices of parameters.
We have benchmarked several methods using a real
image pair with dense ground truth. We obtained an
image pair from the University of Tsukuba Multiview
Image Database for which the ground truth disparity
is known at every pixel. The image and the ground
truth are shown in ﬁgure 2, along with the results from
our method and an image showing the pixels where our
answers are incorrect.
Having ground truth allows a statistical analysis of
algorithm performance.
The table below shows the
number of correct answers that are obtained by various methods. There appear to be some discretization
errors in the ground truth, so it is worth concentrating
on errors larger than ±1 disparity.
Total errors
Errors > ±1
LOG-ﬁltered L1
Normalized correlation
We have also run our method on a number of standard
benchmark images. The results are shown in ﬁgure 3.
Various details in the images (such as the front parking
meter in the meter image and the sign in the shrub
image) are sharp and accurately localized.
Related work and extensions
There has been a signiﬁcant amount of recent work
on computer vision applications of max ﬂow-min cut.
If there are only two possible labels, the multiway cut
problem simpliﬁes to the traditional max ﬂow-min cut.
This allows the MAP estimate to be computed very ef-
ﬁciently, as was shown by Greig, Porteus and Seheult
Our solution can be viewed as a generalization of their result beyond binary images. Other generalizations with quite diﬀerent properties have been
recently proposed by Ferrari et al. .
Recently, Roy and Cox gave a formulation of
the multi-camera stereo problem as a standard two
terminal min cut problem.
The approach in is
quite diﬀerent from our work. Their problem formulation does not use energy minimization; they describe
their method as a generalization of dynamic programming, while we use the MAP-MRF framework.
fact, a graph with a structure similar to that of 
can be used to obtain the exact MAP estimate of the
following MRF.
Suppose that the clique potentials V of equation (2)
are replaced by ˜V(p,q)(fp, fq) = u{p,q} · |fp −fq|. We
require that the label set L = {l1, . . . , lk} consists
of consecutive integers. Such MRF’s appear suitable
for image restoration and stereo matching (assuming
known epipolar geometry), but not for motion. The
MAP estimate of such an MRF can be obtained by
minimizing over f ∈Lm the posterior energy function
2u{p,q}|fp −fq| −
ln (g(i, p, fp)) .
To minimize ˜E(f) we apply our graph techniques
of section 3.2. Consider a graph ˜G deﬁned as follows.
There are two terminals: the source R and the sink S.
For each pixel p we create a set of vertices p1, . . . , pk−1.
We connect them by t-links {tp
1, . . . , tp
k} where tp
{R, p1}, tp
j = {pj−1, pj}, and tp
k = {pk−1, S}.
each pair of neighboring pixels p, q and for each j ∈
{1, . . ., k −1} we create an n-link {pj, qj} with weight
w{p,q} = 2u{p,q}. Each t-link tp
j is assigned a weight
Kp −ln(g(i, p, lj)) where Kp is any constant such that
Kp > (k −1) P
q∈Np w{p,q}.
A cut on the graph ˜G will break at least one tlink for each pixel; we call a cut feasible if it breaks
exactly one t-link for each pixel. Each feasible cut C
Proceedings of IEEE conference on “Computer Vision and Pattern Recognition” (CVPR), 1998
(b) Ground truth
(c) Errors > ±1
(d) GPM-MRF results
Figure 2: Ground truth results
Meter image
GPM-MRF results
Shrub image
GPM-MRF results
Figure 3: Benchmark results. For more images see 
Proceedings of IEEE conference on “Computer Vision and Pattern Recognition” (CVPR), 1998
corresponds to some conﬁguration f C where for each
pixel p we take f C
p = lj if the t-link tp
j is cut by C.
Lemma 2 A minimum cut C on ˜G must be feasible.
Suppose that tp
b are cut. Then we can
ﬁnd a smaller cut by restoring tp
b and breaking n-links
{pj, qj} for all q ∈Np and 1 ≤j ≤k −1. The cost of
the cut will decrease at least by Kp −ln(g(i, p, lb)) −
q∈Np w{p,q} which is strictly positive due to
our choice of Kp.
Theorem 2 If C is a minimum cut on ˜G, then f C
minimizes the posterior energy function ˜E(f).
We follow the same path as in the proof of
Theorem 1.
A cut C is called irreducible if it does
not sever n-links between vertices connected to the
same terminal in ˜G(C). It is easy to show that there
is a one to one correspondence between the set of
all irreducible feasible cuts and the set of all con-
ﬁgurations f ∈Lm. Since the minimum cut has to
be both feasible and irreducible it remains to show
that the cost of any irreducible feasible cut C satisﬁes |C| = A + ˜E(f C).
If C is feasible, the cost
of cutting t-links is P
 Kp −ln(g(i, p, f C
C is also irreducibile the cost of cutting n-links is
{p,q}∈EN w{p,q}|f C
The diﬀerence between ˜G and the graph in lies
in the link weights. Our choice of edge weights guarantees the optimality property of Theorem 2. In contrast, the weights in lack theoretical justiﬁcation.
As a result, their algorithm does not appear to have
any optimality properties.
Note that Ishikawa and Geiger describe an image
segmentation technique that ﬁnds the global minimum
of an energy function closely related to ˜E(f). Their
solution, developed independently before ours, ﬁnds a
minimum cut on a graph similar to ˜G except for some
details. For example, their graph is directed and has
some inﬁnite capacity links, while we employ an undirected graph. We also emphasize the use of contextual
information for selecting penalties u{p,q} as described
in section 4.1. Our experiments suggest that this may
signiﬁcantly improve the results.
Acknowledgments
We thank J. Kleinberg, D. Shmoys and E. Tardos
for providing important references and for insightful
remarks on the content of the paper.
We are also
grateful to Dr. Y. Ohta and Dr. Y. Nakamura for
supplying the ground truth imagery from the University of Tsukuba.
This research has been supported
by DARPA under contract DAAL01-97-K-0104, monitored by ONR.