biblio.ugent.be
The UGent Institutional Repository is the electronic archiving and dissemination platform for all
UGent research publications. Ghent University has implemented a mandate stipulating that all
academic publications of UGent researchers should be deposited and archived in this repository.
Except for items where current copyright restrictions apply, these papers are available in Open
This item is the archived peer-reviewed author-version of:
Hyperspectral Image Classification with Convolutional Neural Networks
Viktor Slavkovikj, Steven Verstockt, Wesley De Neve, Sofie Van Hoecke, and Rik Van de Walle
In: Proceedings of the 23rd Annual ACM Conference on Multimedia Conference, 1159–1162, 2015.
 
To refer to or to cite this work, please use the citation to the published version:
Slavkovikj, V., Verstockt, S., De Neve, W., Van Hoecke, S., and Van de Walle, R. .
Hyperspectral Image Classification with Convolutional Neural Networks. Proceedings of the 23rd
Annual ACM Conference on Multimedia Conference 1159–1162. 10.1145/2733373.2806306
Hyperspectral Image Classiﬁcation with Convolutional
Neural Networks
Viktor Slavkovikj1, Steven Verstockt1, Wesley De Neve1,2,
Soﬁe Van Hoecke1, and Rik Van de Walle1
1Multimedia Lab, Department of Electronics and Information Systems, Ghent University-iMinds
B-9050 Ledeberg-Ghent, Belgium
2Image and Video Systems Lab, Korea Advanced Institute of Science and Technology (KAIST)
Yuseong-gu, Daejeon, 305-732, Republic of Korea
{viktor.slavkovikj, steven.verstockt, wesley.deneve,
soﬁe.vanhoecke, rik.vandewalle}@ugent.be
Hyperspectral image (HSI) classiﬁcation is one of the most
widely used methods for scene analysis from hyperspectral
In the past, many diﬀerent engineered features
have been proposed for the HSI classiﬁcation problem. In
this paper, however, we propose a feature learning approach
for hyperspectral image classiﬁcation based on convolutional
neural networks (CNNs). The proposed CNN model is able
to learn structured features, roughly resembling diﬀerent
spectral band-pass ﬁlters, directly from the hyperspectral input data. Our experimental results, conducted on a commonlyused remote sensing hyperspectral dataset, show that the
proposed method provides classiﬁcation results that are among
the state-of-the-art, without using any prior knowledge or
engineered features.
Categories and Subject Descriptors
I.5.1 [Pattern Recognition]: Models—neural nets; I.5.4
[Pattern Recognition]:
Applications—computer vision;
I.4.8 [Image Processing and Computer Vision]: Scene
Classiﬁcation, convolutional neural networks, deep learning,
hyperspectral imaging
INTRODUCTION
Recent developments of imaging spectroscopy sensors have
enabled acquisition of hyperspectral images with a high spatial resolution, a characteristic which was previously exclusive to standard electrooptical systems. However, unlike the
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from .
MM’15, October 26–30, 2015, Brisbane, Australia.
c⃝2015 ACM. ISBN 978-1-4503-3459-4/15/10 ...$15.00.
DOI: 
standard color pictures, images acquired with hyperspectral
sensors contain much higher spectral resolution. This is advantageous for image analysis, because each hyperspectral
pixel comprises of a large number (in the order of hundreds)
of measurements of the electromagnetic spectrum and carries more information as compared to color pixels, which
provide data only from the visible range of the spectrum. As
a result, hyperspectral image analysis has found numerous
biomedical, forensic, and remote sensing applications [18, 5,
One of the principal techniques in hyperspectral image
analysis is image classiﬁcation, where a label is assigned to
each pixel based on its characteristics. Inference of class labels from hyperspectral data is challenging, however, since
classiﬁcation methods are aﬀected by the curse of dimensionality (i.e., the Hughes eﬀect ). That is, the classiﬁcation
accuracy is poor as the number of training samples required
to populate the high-dimensional spectral space is limited.
Therefore, many diﬀerent feature extraction methods (see
Section 2) have been proposed to tackle the classiﬁcation
problem in hyperspectral images. The goal of feature extraction is to reduce the dimensionality of the hyperspectral
data while preserving as much of the discriminative information as possible, so that in a later stage a classiﬁer can
be trained on the extracted features.
Since it is diﬃcult
to discern potentially relevant features from hyperspectral
data, we approach hyperspectral image classiﬁcation as an
end-to-end learning task, where the assignment of
class labels from hyperspectral input pixels is a single stage
learning process, in which the intermediate feature representations are also learned. The contributions of our paper are
• We propose convolutional neural networks for hyperspectral image classiﬁcation.
• We investigate hyperspectral data augmentation as a
way of mitigating the problem of limited training samples in hyperspectral image classiﬁcation.
The remainder of this paper is organized as follows.
discuss related work in hyperspectral image classiﬁcation in
Section 2. In Section 3, we present the architecture of the
convolutional neural network that was used as basis for our
experiments.
Section 4 describes hyperspectral data augmentation for alleviating the limited training samples problem. In Section 5, we report classiﬁcation results obtained
by the proposed method on a hyperspectral image dataset.
Section 6 concludes the paper.
RELATED WORK
In the past, many diﬀerent feature extraction and classi-
ﬁcation methods have been proposed for hyperspectral images.
Some of the well-established feature extraction approaches are based on dimensionality reduction methods,
such as principal component analysis (PCA) , or independent component analysis (ICA) . These methods are
aimed at projecting the hyperspectral data to a subspace, in
which class separation is performed more eﬀectively. Similarly, to be able to calculate coordinates of data in a lowerdimensional space, manifold learning methods try to
estimate the intrinsic geometry of the manifold embedded
in the high-dimensional hyperspectral data space. Discriminant analysis methods have been used to learn a projection matrix in order to maximize a separability criterion
of the projected data.
Morphological features , on the
other hand, were introduced to take advantage of structural
information present in the images.
They have been successfully combined with support vector machines , which
are known for their good generalization properties for highdimensional data with lower eﬀective dimensionality .
Recently, statistical learning models, such as neural networks, have also been investigated for the purpose of hyperspectral image classiﬁcation. For instance, Li et al. have
proposed a deep belief network (DBN) approach for classi-
ﬁcation of hyperspectral images. The model is a stack of
restricted Boltzmann machines, which are trained by greedy
layer-wise unsupervised learning . However, by reducing
the data to the ﬁrst three PCA components, the spectral
characteristics of the images have not been used in a principal manner by the DBN model. Our proposed approach, by
contrast, fully exploits the available spectral information in
a hyperspectral image.
CNN ARCHITECTURE
Deep CNNs have been successfully applied in solving challenging tasks, such as image classiﬁcation , speech recognition , music information retrieval , and text recognition . However, to our knowledge, CNN models have not
been studied in literature for the purpose of hyperspectral
image classiﬁcation.
Due to network generalization issues , deep CNNs for
image classiﬁcation tasks require a large number of images
to prevent overﬁtting, and thus appear inadequate for the
HSI classiﬁcation problem, where a dataset typically consists of a single capture of a scene. Furthermore, the large
number of bands in hyperspectral images pose a computational challenge for a straightforward application of a CNN
We propose a CNN architecture which integrates both
spatial and spectral information for simultaneous spatialspectral classiﬁcation of hyperspectral images.
The proposed architecture is visualized in Figure 1. The input to
the network consists of the eight-connected neighborhood of
a hyperspectral pixel, to account for the spatial information
context. In order to exploit the original spectral information, all convolutional operations are performed across the
spectral bands. The network consists of 5 layers: three convolutional layers with width 16, followed by two fully connected layers with 800 units each.
Note that the size of
the ﬁlters in the ﬁrst convolutional layer is 9 × 16, where
the ﬁrst dimension accounts for the total number of pixels
in the spatial neighborhood window of the input pixel, and
the second dimension is the width of the ﬁlter. This allows
for simultaneous learning from both the spatial and spectral
1: convolution (9x16) #32
2: convolution (1x16) #32
3: convolution (1x16) #32
4: fully connected #800
5: fully connected #800
pixel label
prediction
hyperspectral pixel
neighborhood
Diagram of the proposed convolutional
neural network architecture for hyperspectral image
classiﬁcation. The size of the ﬁlters in the convolutional layers are indicated as (h × w), and # denotes
the number of convolutional ﬁlters, as well as the
number of hidden units in the fully connected layers.
In order to obtain the CNN architecture from Figure 1,
we experimented with the number of layers, the number of
hidden units in the fully connected layers, and the number and size of the ﬁlters in the convolutional layers.
addition, we tested several modiﬁcations of the original network. Namely, we experimented with max-pooling layers after the convolutional layers, and also with varying the stride
of the convolutions. This worsened the classiﬁcation results,
which is indicative of non-stationarity of statistics across
spectral bands. Testing the hyperbolic tangent activation
function produced slightly better results than rectiﬁed linear
units activation. As a result, we used hyperbolic tangent
activations in all layers exclusive of the last layer, where the
softmax function was used. We also attempted dropout regularization in the fully connected layers, however, this
did not improve the classiﬁcation results.
We trained the network using minibatch gradient descent
and momentum , and we set the size of the minibatches
to 50 samples. We evaluated the model on a held out validation set during training, and we report results on a separate
test set for the model that achieved the best results on the
validation set.
DATA AUGMENTATION
Identifying the classes of pixels from hyperspectral images
to produce labeled training data is a manual task, which is
expensive and time consuming. Therefore, available training
samples for HSI classiﬁcation are scarce. To try to alleviate
this problem, we experimented with simple augmentation
for hyperspectral data. For each class in the hyperspectral
image dataset, we calculate the per-spectral-band standard
deviation of the samples in the training set which belong to
the class. Afterwards, we use the calculated vector of standard deviations σ as a parameter to a zero mean multivariate normal distribution N(0, αΣ), where α is a scale factor,
and Σ is a diagonal matrix containing σ along the main diagonal entries. Finally, the augmented samples for the class
are generated by adding noise sampled from the distribution
N to the original samples. We tried several values for the
scaling factor in the set {1, 0.5, 0.33, 0.25, 0.125}, and ﬁxed
α = 0.25 for the experiments.
The goal of the proposed
hyperspectral data augmentation is to prevent overﬁtting in
cases where a low number of samples are used to train the
EXPERIMENTAL RESULTS
We tested our method on the commonly-used Indian Pines
hyperspectral image dataset . This dataset was acquired
in June 1992 by NASA’s Airborne Visible/Infrared Imaging
Spectrometer (AVIRIS). The Indian Pines scene is a mixed
forest and agricultural site in Northwest Indiana, captured
at about 20 km altitude by the AVIRIS sensor.
The hyperspectral image of the scene consists of 220 bands in the
spectral range from 0.4 µm to 2.5 µm, with a spectral resolution of 10 nm. The whole scene consists of 145 × 145
pixels. There are in total 10,366 labeled samples. With a
moderate geometrical resolution of 20 m per pixel, and 16
land cover classes, this dataset poses a challenging classiﬁcation problem due to the unbalanced number of samples
per class, and high inter-class similarity of samples in the
Table 1: AVIRIS Indian Pines dataset and per class
training sets and corresponding test sets.
Corn-notil
Grass-pasture
Grass-trees
Grass-pasture-mowed
Hay-windrowed
Soybeans-notil
Soybeans-min
Soybeans-clean
Bldg-grass-trees
Stone-steel-towers
For our experiments, we evaluated the classiﬁcation accuracy of the method using a balanced training set per class,
with low number of training samples. We trained the network with 5%, 10%, and 20% of randomly selected labeled
samples per class, and equally divided the remaining labeled
samples into separate validation and test sets. In each case,
we repeated the experiment with and without hyperspectral
data augmentation.
Figure 2: A subset of ﬁlters learned in the ﬁrst convolutional layer of the network. Each subplot represents a (9 × 16) ﬁlter.
Table 2: Classiﬁcation results for the Indian Pines
image on the test sets.
Indian Pines
86.54 ± 0.30
92.70 ± 1.00
96.58 ± 0.55
0.86 ± 0.00
0.93 ± 0.01
0.97 ± 0.01
Non-augment.
85.46 ± 1.73
92.76 ± 0.93
96.54 ± 0.47
0.85 ± 0.02
0.93 ± 0.01
0.96 ± 0.00
The achieved classiﬁcation results for each of the experiments are shown in Table 2. We performed 5 Monte Carlo
runs, where for each run we selected a training set of 5%,
10%, and 20% of the labeled samples, as explained above, to
train our model. In the cases with augmentation, we found
3 fold (per class) augmentation of the training data to give
the best results. We report the average and standard error
of the 5 Monte Carlo runs in terms of the overall classiﬁcation accuracy (OCA), i.e., the number of correctly classiﬁed
samples from the total number of samples in the test set,
and the F1 score, which is weighted so that it accounts for
the imbalance of the classes. From the results in Table 2, it
can be seen that only when using a very low number of augmented labeled samples for training (5%), there is improvement in the classiﬁcation scores over the non-augmented
counterpart. However, we have observed that in all cases
augmentation reduced the number of training iterations signiﬁcantly, as compared with training with the corresponding
non-augmented data.
We have visualized some of the learned ﬁlters from the
ﬁrst convolutional layer of the network in Figure 2. From
the visualization, it is clear that the learned ﬁlters have a
structured shape, and that some of the ﬁlters roughly resemble diﬀerent spectral band-pass ﬁlters.
CONCLUSIONS
Due to the inherent nature of hyperspectral data, discernment of good features for hyperspectral image classi-
ﬁcation is diﬃcult. Therefore, in this paper, we have presented a new approach towards hyperspectral image classi-
ﬁcation based on deep convolutional neural networks. To
evaluate the eﬀectiveness of the method, we performed experiments on a commonly-used hyperspectral image dataset.
Our experimental results have shown that the neural network model can learn structured features resembling diﬀerent spectral band-pass ﬁlters directly from the input data.
These features prove useful for hyperspectral image classi-
ﬁcation, which makes end-to-end learning applicable to hyperspectral scene understanding.
ACKNOWLEDGMENTS
The research activities as described in this paper were
funded by Ghent University and the Interdisciplinary Research Institute iMinds.