Full Matching in an Observational Study of
Coaching for the SAT
Ben B. HANSEN
Among matching techniques for observational studies, full matching is in principle the best, in the sense that its alignment of comparable
treated and control subjects is as good as that of any alternate method, and potentially much better. This article evaluates the practical
performance of full matching for the ﬁrst time, modifying it in order to minimize variance as well as bias and then using it to compare
coached and uncoached takers of the SAT. In this new version, with restrictions on the ratio of treated subjects to controls within matched
sets, full matching makes use of many more observations than does pair matching, but achieves far closer matches than does matching
with k ≥2 controls. Prior to matching, the coached and uncoached groups are separated on the propensity score by 1.1 SDs. Full matching
reduces this separation to 1% or 2% of an SD. In older literature comparing matching and regression, Cochran expressed doubts that any
method of adjustment could substantially reduce observed bias of this magnitude.
To accommodate missing data, regression-based analyses by ETS researchers rejected a subset of the available sample that differed
signiﬁcantly from the subsample they analyzed. Full matching on the propensity score handles the same problem simply and without
rejecting observations. In addition, it eases the detection and handling of nonconstancy of treatment effects, which the regression-based
analyses had obscured, and it makes fuller use of covariate information. It estimates a somewhat larger effect of coaching on the math score
than did ETS’s methods.
KEY WORDS:
Graph algorithm; Matching with multiple controls; Network ﬂow; Optimal matching; Quasiexperiment; Propensity score.
1. INTRODUCTION
During the 1995–1996 academic year, investigators from the
College Board surveyed a random sample of high school junior and senior SAT takers to probe how they had prepared for
the SAT, asking whether they had completed extracurricular test
preparation courses, among other questions. Some 12% of respondents said that they had; the comparison of these to the
remaining 88% comprised the observational study reported by
Powers and Rock .
Powers and Rock estimated coaching effects in several ways,
most of which started from regression models and one of which
involved matching. Matching was not their favorite approach:
“By its nature,” they lamented, matching “signiﬁcantly reduces
sample sizes,” noting that their matched-pairs analysis matched
only a fraction of the uncoached students to coached counterparts . Their disappointment seemed to extend
from pair matching to matching in general, although it is not
clear that it should have. As compared to 1 :k matching or
to matching with a variable number of controls , pair matching is the least ﬂexible and the
least able to make use of a large reservoir of potential controls.
This article revisits Powers and Rock’s matching problem
using the most ﬂexible approach applicable to it, namely optimal full matching . Section 2 explains full
matching and contrasts it with pair matching and similar designs. Full matching remedies the sample reduction problem,
using all of the available sample, as none of Powers and Rock’s
preferred adjustments was able to do; simultaneously, it produces closer matches than do their methods. It turns out that
full matching is in a sense too ﬂexible (Sec. 2.4); Section 3 addresses this by modifying the technique to incorporate certain
restrictions. Full matching, either with or without restrictions,
Ben B. Hansen is Assistant Professor, Statistics Department, University
of Michigan, Ann Arbor, MI 48109-1092 (E-mail: ;
URL: www.stat.lsa.umich.edu/˜bbh). The author thanks Paul R. Rosenbaum,
as well as Luke Bulman, Tanya Henneman, Elizabeth A. Stuart, Yu Xie, and
two anonymous referees for very helpful suggestions. He wishes to acknowledge the College Board, Donald E. Powers, and Donald A. Rock for graciously
sharing the data from their SAT coaching study, Paul W. Holland for his kind
encouragement and for his help in obtaining the data, and the National Science
Foundation for material support (Postdoctoral Fellowship DMS-01-02056).
does a better job with missing data, facilitates fully adjusted
but simple comparisons of treated and control groups, and lays
bare heterogeneities of treatment effect that regression analyses
The context of Powers and Rock’s study was as follows.
The Princeton Review has long claimed its students’ average
beneﬁt to be 140 points in combined SAT score , and during the 1990s Kaplan Educational Centers claimed average beneﬁts of 120 points . The
coaching companies’ ﬁgures appear to be based on studies conducted for them by outside ﬁrms ; but
because neither the studies nor methodological descriptions of
them are published or publicly available, the integrity of their
conclusions is difﬁcult to assess. In contrast, Powers and Rock
found much weaker coaching effects: about 20 points on the
math section and 10 on the verbal. Their analyses assumed,
among other things, constancy of coaching effects. Granting
this and other premises, Powers and Rock’s ﬁndings sharply
refute those of the coaching companies. Section 4 will offer
strong evidence against uniformity of coaching effects, however. Our full matching-based estimation of coaching effects,
also presented in Section 4, relaxes this and others of Powers
and Rock’s assumptions, yielding new evidence on the College
Board’s and the coaching companies’ competing claims. Section 5 abstracts from the coaching study to discuss matching
for observational studies in general.
1.1 Test Scores and Test Preparation in
a National Sample
The data to be analyzed derive from a stratiﬁed random sample of registrants for 1995–1996 administrations of the SAT–I
test, details of which are given by Powers and Rock .
About 6,700 high school juniors and seniors received surveys
asking whether and how they had prepared for the test; the
replies of some 4,200 respondents were linked to the College
Board’s records of their scores on the 1995 or 1996 exams, as
© 2004 American Statistical Association
Journal of the American Statistical Association
September 2004, Vol. 99, No. 467, Applications and Case Studies
DOI 10.1198/016214504000000647
Journal of the American Statistical Association, September 2004
Table 1. Selected Pretreatment Variables
Standardized
Percentage
Math section
Mean SAT at
respondent’s
ﬁrst-choice
1,061–1,123
1,124–1,336
No response
High school
A.A. or B.A.
No response
“Excellent”
math grade
“Good”–“fail”
No response
years taken
No response
well as scores on previous SAT–I or PSAT tests and their answers to the Student Descriptive Questionnaire (SDQ), which
all SAT–I registrants are asked to complete. By their responses
to questions about extracurricular SAT preparation, respondents
split into a treated and a control group, and the data describe the
results of a classical quasiexperiment /sp, where
¯vt and ¯vc are the average values of v in the treatment and control
groups, respectively, and s2
p is the pooled within-group variance
in v.) Yet the table shows only ﬁve covariates; the analysis must
address biases on all 27 of them.
1.2 Missing and Misleading Data in Regression
and in Subclassiﬁcation
In regression-based adjustment, the simplest way to handle
missing data on a covariate is to reject cases without complete
information. In adjustment based on matching or stratiﬁcation,
the method of ﬁrst resort is to merge “missing” with an appropriate level of the covariate, or to treat it as a category unto
itself. Thus missingness becomes part of the proﬁles according
to which study subjects are sorted into strata or matched sets.
Good stratiﬁcations, then, will tend to group subjects that are
comparable in terms both of observed covariate values and of
covariate missingness.
Powers and Rock’s study follows the norms of regression analysis rather than of stratiﬁcation, rejecting all cases
with missing covariate values. Of the seven statistical analyses
they report having done, one used about an eighth of the available sample, three more used about half, another two used three
quarters, and only one, the so-called “Belson model,” used more
than 90% of it. The Belson model was an outlier in another respect: Its estimate of the effect of coaching on math scores was
closer to 30 points than the 15 or 20 found in the other analyses. And the difference of the treated and control groups’ mean
SAT scores is greater for the whole of the sample (41 ± 5 for
SAT–M, 9 ± 5 for SAT–V; n = 3,994) than for the half of the
sample used by three of Powers and Rock’s analyses (35 ± 7
for SAT–M, 6 ± 7 for SAT–V; n = 1,876). The partly missing
observations are decidedly unlike a randomly selected subset of
the sample; to the contrary, their removal from an the analysis
is likely to bias the result.
To illustrate how a stratiﬁcation-based analysis might begin
to address this problem, consider simple stratiﬁcations along
the one or two covariates that most threaten to confound the
comparison of treated subjects to controls. With the College
Board coaching data, race and socioeconomic status (SES)
variables best ﬁt this description. The one race variable sorts
subjects into eight ethnic categories, with only 6% of observations missing. Several of these groups are quite small, and
collapsing seems in order. Given the education setting of the
study, it is natural (1) to sort observations into an Asian–
American category (9%), an underrepresented minority category (8% Black, 3% Mexican American, 1% Native American,
1% Puerto Rican, 3% other Hispanic, 3% other), and White
(66%); and (2) to place the small fraction of item nonrespondents with the largest category, namely White. To account for
SES, SDQ responses give three potential stratiﬁers to choose
from among, namely parents’ income and education levels of
mothers and fathers. All three variables are probably measured
with some error, but it seems that high school students are more
likely to know and less likely to misreport their parents’ education than their parents’ income; and splitting the data into
thirds at the 33%, 67%, and 100% quantiles of mother’s and
of father’s education levels, father’s education better separates
both PSAT-math and PSAT-verbal scores. We stratify the College Board coaching data by race and father’s education level,
grouping students into three categories of father’s education,
plus an additional category for students not reporting it. Call
this the Race-by-SES (Race × SES) subclassiﬁcation; Table 2
shows sizes and compositions of its subclasses.
The Race × SES subclassiﬁcation adjusts for too few of
the available covariates to be taken seriously as an adjustment
unto itself, but it should be noted that it makes a promising
beginning. For instance, the association between PSAT math
scores (grouped as in Table 1) and coaching status is significant at the .05 level in the unstratiﬁed sample, but not in
Hansen: Full Matching in an Observational Study
Table 2. Race × SES Subclasses: Sizes and
Control-to-Treated-Subject Ratios
Father’s education
Percentage
Number of controls
(by race category)
per treated subject
White, or no race reported
High school or less
A.A. or B.A.
Postcollege
Not reported
White (all)
Underrepresented minority
High school or less
A.A. or B.A.
Postcollege
Not reported
Underrepresented
minority (all)
Asian American
High school or less
A.A. or B.A.
Postcollege
Not reported
Asian American (all)
the stratiﬁed sample, when evaluated with the Mantel 
score statistic; and after but not before subclassiﬁcation along
race and SES, a Cochran–Mantel–Haenszel test fails to ﬁnd signiﬁcant differences between coached
and uncoached students in terms of number of semesters taken
of high school English and natural science, English and natural
science grades, and grades in social science and math courses.
Because other variables, such as overall high school grade point
average (GPA) and reported parents’ income, do not become
balanced after stratiﬁcation on SES and race, the analyst must
make one or more additional adjustments taking the remaining
covariates explicitly into account. To effect such an adjustment,
Sections 3 and 4 of this article reﬁne rather than replace the
Race × SES subclassiﬁcation, thus inheriting its gains.
Subclassifying in this way, we have rejected no observations.
Placing subjects with partially missing data into subclasses dedicated to their missingness pattern, as we have done, can solve
the missingness problem only if the unavailable covariate data
are missing at random given those data that are not missing; but
for the analogous strategy in regression contexts, namely casewise deletion, it is necessary that the observations with partial
missingness be like a simple random subsample of the sample
as a whole—which in the present case appears not to be true.
The strategy of creating missingness levels of covariates can
also be used to construct propensity scores. It leads to propensity scores which, when matched or stratiﬁed upon, balance
both covariate-missingness and observed-covariate proﬁles between treated and control groups ; it is well-suited to missingness patterns in which observations tend to lack only few of a large number of covariates.
Such is the case here: On the 23 covariates other than pretest
scores, only one third of the College Board sample have complete data, but two thirds are missing no more than two covariates, and nine tenths lack data on no more than six covariates.
Our propensity score accommodates missing data in this way,
in so doing retaining all 3,994 observations.
Adjustment by stratiﬁcation encourages the analyst to focus
on the data rather than a model for it, and this can be indirectly
beneﬁcial. With these data, for example, there is a temptation to
regard as a pretreatment variable any PSAT or SAT score from a
test sitting earlier than that of the posttest, in order to maximize
sample size in a regression using pretest scores as covariates; recent regression-based studies of coaching for the SAT share in
such a simplifying assumption . But as it turns out, in the College Board’s sample there
are quite a few coached students who got their coaching even
before taking their earliest SAT or PSAT: of 332 coached students reporting the years and months in which their test preparation courses began, one fourth started their courses before
taking either the SAT or the PSAT. Treating as pretests prior test
scores that did not genuinely precede the treatment, as Briggs’
and Powers and Rock’s studies do, may deny credit to coaching programs for gains that they produced. The analysis
to follow treats the 126 coached students with prior tests that
did not precede their coaching, or could not be determined to
have preceded it, the same as students without pretests: In refashioning the covariates for inclusion in a propensity score
model, they are placed in a “pretest-missing” category. To enhance comparability of the groups, a similar accommodation is
made with uncoached students: Those who have prior tests that
only preceded their posttests by a period of less than 6 months
are placed into a “pretest-missing” category, rather than a category based on groupings of pretest scores.
2. CONVENTIONAL MATCHING AND ALTERNATIVES
2.1 Nearest Available versus Optimal Matching
Most commonly, matchings join each treated subject to one
or to a ﬁxed number k ≥2 of controls, and usually this matching is done by a so-called nearest available algorithm. Section 2.2 explores ramiﬁcations of matching treated and control
subjects in only one, preset ratio. As a prelude to that discussion, this section reviews the distinction between optimal and
nearest available matching.
Table 3 presents an artiﬁcial dataset modeled on an unpublished gender equity study conducted by the author. Men and
women university scientists within various departments were to
be compared in terms of their lab space assignments, but ﬁrst
it was necessary to match them on factors that might confound
the comparison. The actual study matched on total grant funding and several other factors, but to simplify the illustration we
consider grant funding alone.
Nearest available, or greedy, matching algorithms move
down the list of treated subjects from top to bottom, at each
Table 3. A Gender Equity Matching Problem: Women and Men
Scientists Are to Be Matched on Grant Funding
log10(grant funding)
log10(grant funding)
Journal of the American Statistical Association, September 2004
step matching a treated subject to the nearest available control,
which is then removed from the list of controls available at the
next step. Matchings are made at a given stage without attention
to how they affect possibilities for later matchings. In the equity
matching problem posed in Table 3, a nearest available algorithm for pair matching would ﬁrst match A to V, then B to Z,
C to X, and ﬁnally D to Y, for a total “cost” (sum of absolute differences in log Grant Funding) of 3.6. Having matched A to V,
Z is the nearest available potential match for B, but matching
B to Z is in fact “greedy,” in that it forces C and/or D to be more
poorly matched at the next stage. In contrast, optimal matching
algorithms optimize global, rather than local, objectives. The
optimal solution for the problem of pairing each of Table 3’s
women with one of its men joins A to V, B to X, C to Y, and
D to Z, for a total cost of 3.4.
For pair matching with a large reservoir of controls, greedy
algorithms often do nearly as well as optimal algorithms
 . But absent an excess of available controls, or with unfortunate orderings of the list of treated
subjects, greedy algorithms can do much worse than optimal
2.2 The Weakness of Fixed-Ratio Matching: Using
More Controls Leads to Larger Biases
Returning to the coaching study, let us match coached and
uncoached students ﬁrst as pairs, and then in ﬁxed proportions
1 :k, letting k grow until all controls have been matched, and let
us compare these alternative matchings to one another. Because
optimal matches are never worse, and often better, than greedy
matches, we generate each match using optimal methods.
Surely the best 1 :1 match is less likely than any 1 :k match,
k ≥2, to join a treated subject to a control that differs appreciably from it; and surely it follows that among all 1 :k matches,
k ≥1, an optimal 1 :1 match most reduces the bias of treatment
to control group comparisons. Yet it would be rash to prefer
1 :1 matches categorically, because when more than one good
potential match is available for each treated subject, there will
be k ≥2 such that some 1 :k match leads to sharper estimates
than do 1 :1 matches, with little penalty in terms of bias. In the
context of our coaching study, how much precision does each
increment to the number of controls buy, and at what cost in
terms of bias?
To appreciate the impact of the number of controls on the effect estimate’s variability, consider that estimate in the context
of a simple linear model. Attach numbers 1,...,n to sample
units; let T and C be the indices of the treated and the control
group, respectively, so that T ∪C = {1,...,n} and T ∩C = ∅,
and let S indicate a partition of the sample into matched and
unmatched sets by mapping indices {1,...,n} of sample units
to 0, for unmatched units, or to positive integers {1,...,S} indicating matched sets. (The sth matched set, 1 ≤s ≤S, is then
represented as S−1[s].) Then the model represents responses of
matched units [i for which S(i) > 0] as follows:
τS(i) + S(i) + εi,
S(i) + εi,
E(ε) = 0, Cov(ε) = σ 2I, σ 2 < ∞,
where 1,...,S are matched-set effects and τ1,...,τS are
treatment–control contrasts, one for each matched set.
Under model (1), in the sth matched set the average difference of treatment- and control-subgroup responses, ¯yst −¯ysc,
unbiasedly estimates τs, and weighted averages wsτs (w ≥0,
ws = 1) may be estimated with weighted averages of these
matched-set response differences, ws ˆτs. Given candidate
stratiﬁcations S:{0,...,n} →{0,...,S} and ˜S:{0,...,n} →
{0,..., ˜S} with weightings w and ˜w, therefore, the quotient
R(S, ˜S) ≡
#(T ∩S−1[s]) · #(C ∩S−1[s])
#(˜S−1[˜s])
#(T ∩˜S−1[˜s]) · #(C ∩˜S−1[˜s])
[#(A) = size or cardinality of A] assesses the relative precision
of estimates based on S and on ˜S. When S and ˜S give rise to
models of form (1) sharing a common value of σ, R(S, ˜S) is
the ratio of SD’s of estimates of w- and ˜w-weighted averages of
stratum treatment/control contrasts.
Comparisons based on this quotient favor 1 :k matchings
with larger values of k. Weighting strata in proportion to the
number of treated subjects they contain is sometimes called
effect of treatment on the treated (ETT) weighting; using
ETT weights, ws ≡#({i ∈T:S(i) = s})/#({i ∈T:S(i) > 0}),
and comparing each matching to a 1 :1 matching, the relative
precision quotients for 1 :1, 1 :3, 1 :5, and 1 :7 matchings are
1.00, .82, .77, and .76. Matchings with multiple controls appear
appreciably more precise.
The relative precision number R(S, ˜S) does not depend on
which subjects S, or ˜S, groups together; for example, any two
1 :5 matches S5 and S′
5 have R(S,S′) = 1. In contrast, biases
attending to a stratiﬁcation S are determined by S’s success at
grouping like with like. Figure 1 shows standardized biases for
the unmatched College Board coaching data and for optimal
1 :1, 1 :3, 1 :5, and 1 :7 propensity score matchings created
Observe that the boxplots at the far left and far right of the
ﬁgure are identical. This is no accident: The matched sets described by the rightmost boxplot exclude no controls and, in the
computation of standardized biases, give all controls the same
weight; the same occurs when covariate biases are calculated
for the unmatched sample. In general, if controls are K times
as numerous as treated subjects, then adjustment using a 1 :K
matching amounts to no adjustment at all.
The pattern in Figure 1 appears in a number of contexts. It
has led authors such as Dehejia and Wahba and Smith
 to conclude that whatever its advantages for variance,
attempting to use most or all of the control reservoir invites
sharp penalties in terms of bias. Full matching will turn out to
involve a very different variance-bias tradeoff, however, making
attractive another explanation of the penalties for increased use
of controls seen in Figure 1: They reﬂect limitations inherent to
ﬁxed-ratio matching.
Hansen: Full Matching in an Observational Study
Figure 1. Covariate Imbalances in 1:k Matching. Each boxplot represents standardized biases in the 99 categories of the 27 categorical
covariates along with standardized bias in the propensity score (which
in each plot is the uppermost outlier). Strictly speaking, the matching
represented at far right is not a 1:7 matching but a blend of six 1 :6 and
494 1 :7 matched sets.
2.3 Full Matching: An Illustration
Full matching subdivides a sample into a collection of
matched sets consisting either of a treated subject and any positive number of controls or a control subject and any positive
number of treated persons. These matchings stand in contrast
to the 1 :k matchings considered in the previous section. For
example, one can readily verify that the optimum placement of
the four women and ﬁve men in Table 3 into matched sets of
one woman and one or two men matches A to V and W, B to X,
C to Y, and D to Z, with total cost 3.8. The optimal full match,
depicted in Table 4, reduces this sum to 3.6. Coincidentally,
it avoids matching any woman to a man whose grant funding
differs from hers by more than a factor of 10—a requirement
that, with the help of full matching, could be insisted upon in
the actual study on which the example is based. In the example
problem, neither pair matching nor matching with one or two
controls could have met such a requirement.
Rosenbaum introduced full matching, Gu and
Rosenbaum did a simulation study of it, and Marcus
 made use of it to assess the Head Start compensatory
education program.
Table 4. Full-Matching Solution to the Matching Problem
Posed by Table 3
log10(grant)
log10(grant)
2.4 Matching to Use Every Control
To judge from Figure 1, no way of matching coached to uncoached students at once balances all measured covariates and
places each available control in some matched set. However,
each matching in Figure 1 joins treated and control subjects in
only a single, ﬁxed ratio; full matching may introduce new possibilities. This section studies the optimal, in the sense of minimizing propensity score distances, full matching of the College
Board sample. By its construction, such a matching cannot fail
to use every available control, but its success or failure at imposing balance upon measured covariates remains to be seen.
For each pair i ∈T and j ∈C, let a discrepancy δij ∈[0,∞]
be given: Small values of δ indicate desirable matches; large
ﬁnite δ’s, matches to be avoided; inﬁnite δ’s, matches that are
forbidden.A full matching is a partition of all or part of the sample into one–one, one–many, and many–one matched sets, none
of which includes forbidden pairings. Formally, by “full matching” let us understand a mapping S of T ∪C into {0,...,S},
S a positive integer, such that each matched set M = S−1[s]
(1 ≤s ≤S) satisﬁes min(#(M ∩T),#(M ∩C)) = 1, and for all
i ∈M ∩T and j ∈M ∩C, δij < ∞. The size of a full matching
S is the ordered pair (#(S−1[{1,...,S}] ∩T),#(S)−1[{1,...,
S}] ∩C), indicating the number of treated and the number of
control units that S places into matched sets. These deﬁnitions
are substantially equivalent to those of Rosenbaum .
Given a full-matching problem (C,T,{δij}), a full match ˜S of
size (c,t) that solves it is optimal among size (c,t) full matches
if it minimizes net discrepancy,
i∈T,S(i)>0
j∈C,S(i)=S( j)
among all size (c,t) full matches S for (C,T,{δij}). An optimal full match is a minimizer of net discrepancy among size
(#(C),#(T)) full matches, that is, full matches that discard no
In the present analysis, discrepancies δij are based on the
propensity score: For i ∈T,j ∈C,
i,j belong to different Race × SES subclasses
otherwise,
where X is the vector of covariates and ˆe(Xi), ˆe(Xj) are ﬁtted
propensity scores. The inﬁnite distances force exact matching
on race and father’s education. An algorithm to ﬁnd optimal
full matches is described in the Appendix.
Full matching was very successful in removing bias due to
observed covariates. The average within-stratum discrepancy
between treateds and controls, understood as distance along the
ﬁtted score, is .05, and the optimal full match removes 99% of
the bias in the ﬁtted score. By contrast, average propensity distances in the optimal 1 :1, 1 :3, and 1 :5 ﬁxed-ratio matchings
were .04, .31, and .69, respectively, with propensity score bias
reductions of 97%, 74%, and 42%. When the sample is partitioned according to the optimal full match, no covariate exhibits
even a hint of association with treatment status; the Cochran–
Mantel–Haenszel χ2 statistics (see Sec. 1.2) are both nonsignificant and uniformly close to 0. Evidently, full matching permits
use of the control reservoir in its entirety, with no discernible
penalty in terms of bias.
Journal of the American Statistical Association, September 2004
Figure 2. Superimposed Barplots Representing Stratum Sizes of the
Optimal Full Match (gray bars, in background; 468 strata) and the Optimal [.5, 2] Full Match (in foreground; 491 strata). The contrast between
the two illustrates that in full matching restrictions on treated-to-control
ratios greatly reduce the number of matched sets that are unusually
heavy with control or treated subjects. Vertically aligned bars represent
a single matched set, with bar heights above the x axis giving the number of controls in it and bar depth below the x axis showing its share of
treated subjects.
Variance is another issue. Relative to the optimal 1 :1
match (S1), the relative precision of the optimal full match
is a disappointing .93. This may be better than the optimal
pair match, but it is worse than every one–many match considered in Section 2.2. For instance, the optimal 1 :3 matching
S3—which substantially reduced covariate imbalances—had
R(S1,S3) = .82. A use of full matching that contains variance
as well as bias is described in the next section.
The optimal full match looks strikingly different from any
ﬁxed-ratio matching. Most notably, it contains some outlandishly large matched sets: as many as six treated subjects
to a control; as many as 161 controls to a treated. Figure 2
represents the composition of its matched sets with stacked
barplots. The black bars in the foreground of Figure 2 represent a matching that will be introduced in Section 3.2, but the
gray bars in the background describe the optimal full matching.
Adjoining upper and lower bars give the numbers of uncoached
and of coached students in a single matched set, with matched
sets arranged from left to right in order of increasing propensity score. This arrangement illustrates the natural tendency for
subjects with high scores to be placed in many–one matched
sets, while low propensity score subjects wind up in one–many
substrata that are heavy with controls.
3. FULL MATCHING WITH RESTRICTIONS
The optimal full match uses all controls and balances every
covariate, but some of its matched sets are too heavy with controls, and in others controls are quite sparse. The disparities
stand behind the optimal full match’s disappointing relative precision. And by altering so drastically the weighting of subjects
implicit in the Race × SES subclassiﬁcation, it engenders estimates of coaching effects that depend quite strongly on a particular propensity score speciﬁcation. This section produces a full
matching that is similar to the matching of Section 2.4 in that it
balances available covariates without rejecting any controls. In
terms of maintaining balance in the relative numbers of treated
and control subjects in any matched set, on the other hand, it
does a good deal better than that matching; this improvement
increases precision, in the sense that it reduces standard errors
of estimates of treatment effects. Some technical preliminaries
are necessary, and it is best to begin with an illustration.
3.1 Full Matching With Restricted
Treated-to-Control Ratios
Let us return for the moment to the matching problem of Table 3. As compared to the optimal pair matching, or to the optimal matching with one or two controls, the optimal full match
given in Table 4 supports assessments of gender equity that have
smaller bias, because it matches men and women more closely
in terms of the one covariate being adjusted for. In terms of
variance, however, it is actually worse than those matchings.
Comparing to pair matching and using ETT weights for each
comparison, the precision of a matching into three pairs and a
1 :2 set is .97, while a 1 :4, 3 :1 full matching (as in Table 4)
has precision 1.27. One remedy for this is to constrain the result of one’s full matching so that the ratios of the numbers of
treated and of control subjects in each matched set are either
homogeneous, as in the optimal pair matching, or at least relatively homogeneous, as they were in the one-to-two controls
solution to the matching problem of Table 3.
Suppose, for concreteness, that we seek a full matching such
that in each matched set, the number of treated subjects divided
by the number of controls ranges from about half up to about
twice what that ratio is in the sample as a whole. For the gender
equity matching problem, the overall ratio of treated (women)
to control subjects (men) is 4 :5, so we would seek individual
matched sets with treated-to-control ratios of about 1 :2.5 up to
1.6 :1. Matched sets with 2.5 controls or 1.6 treated subjects are
of course impossible, so we require a rounding convention. Let
us be permissive rather than strict, interpreting the present requirement so as to permit matched sets with treated-to-control
ratios of 1 :3 up to 2 :1. (By establishing the conventions in
this way, we reduce the potential for inadvertently imposing a
restriction that makes matching infeasible, as would occur in
the equity matching problem if a restricting factor of .75, rather
than 1/2, were placed on the reduction in the ratio of treated
subjects to controls, and if the resulting upper limit of 1.67 controls per treated subject were to be interpreted strictly.)
The full matching that minimizes costs while adhering, under this interpretation, to the half-to-twice restriction on the ratio of women to men is as follows: woman A is matched to men
V and W, and B to X and Y; while women C and D are both
matched to Z. The restrictions lead to a somewhat greater total
cost, 3.7 versus 3.6. Even with restrictions, however, full matching again makes it possible to avoid matching men and women
whose log10(Grant Funding) differs by more than 1. At a small
price, then, one secures a substantial improvement in precision:
Writing Sr for the optimal full matching with constraints and
Sf for Table 4’s unconstrained optimal full matching, one has
R(Sr,Sf ) = .82.
Let us place these ideas into a suitable formalism. A matching S subdivides U if for all subject indices i and j, S(i) =
Hansen: Full Matching in an Observational Study
S(j) entails U(i) = U(j). When S subdivides U, for each
matched set M of S there is a stratum U of U, that is, U =
U−1[s] for some s ≥1, such that M ⊆U. Given a stratiﬁcation U, call the ratio of treated subjects to controls in U
the U-treatment odds for stratum U. When S subdivides U,
a matched set M of S has both S-treatment odds, dS(M),
and U-treatment odds, dU(M), namely the U-treatment odds
for the stratum U of U that contains it. In the gender equity example, the null stratiﬁcation U0 :{A, B, C, D, V, W, X,
→{1} is subdivided by Sr. Regarding women as treated
and men as control subjects, the U0-treatment odds for U0’s
lone stratum, dU0({A, B, C, D, V, W, X, Y, Z}), are 4 :5, as are
the U0-treatment odds in each of Sr’s matched sets; but Sr’s
three matched sets have Sr-treatment odds of dSr({A, V, W}) =
1 :2, dSr({B, X, Y}) = 1 :2, and dSr({C, D, Z}) = 2 :1.
A matching S that subdivides U respects a thickening cap
of u, u ≥1, if the S- and U-treatment odds obey the relation
udU(M):1,
udU(M) > 1
for each matched set M of S. Such an S nowhere increases the
ratio of treated to control subjects to more than roughly u·100%
of what it would have been under U. As a subdivision of the
null stratiﬁcation U0, the restricted full matching Sr respects a
thickening cap of 2.
Similarly, the subdivision of U into S conforms to a thinning
cap of l if 0 ≤l ≤1 and for each matched set M of S,
ldU(M) > 1
ldU(M) ≤1.
As a subdivision of U0, Sr holds to a thinning cap of 1/2.
An [l,u]-subdivision of U is a subdivision of U respecting a
thinning cap of l and a thickening cap of u. An optimal [l,u]subdivision of U is an [l,u]-subdivision of U with minimal net
discrepancy [cf. (3)] among full matches that subdivide U and
conform to thinning and thickening caps of l and u. Sr is an
optimal [.5,2]-subdivision of U0.
3.2 Restricted Full Matching for the
Board Sample
Now let U denote the Race×SES subclassiﬁcation (Sec. 1.2).
We seek an optimal [l,u]-subdivision of U, l < 1 and u > 1,
that adequately balances each covariate while keeping l and u
as close to one as is consistent with this aim.
One-half and two are a natural pair of caps with which to
start: Alter the treatment odds within strata, they say, by no
more than a factor of 2. Against the optimal [.5,2] full match,
testing each of the 27 covariates separately using statistics of
the Mantel–Haenszel (MH) type (cf. Sec. 1.2) yields no results
of signiﬁcance at the nominal .05 level; only with the parents’
income variable is there a hint of association (M2/df = 8.9/4,
p = .06). Alternatively, the battery of tests may be directed
at subjects without missing covariate data. The 27 additional
MH tests that exclude those matched sets containing a subject
missing data on the relevant covariate also fail, for the most
part, to reject null hypotheses of no association. The exceptions are a test giving some thin evidence of association between the parents’ income variable and treatment status, with
Figure 3. Standardized Biases Without Stratiﬁcation or Matching,
Open Circles, and Under the Optimal [.5, 2] Full Match, Shaded Circles.
M2/df = 7.0/3 and p = .07, and a signiﬁcant test of association between treatment status and years of foreign language,
with M2/df = 4.8/1 and p = .03. In short, of 27 covariates,
one associates with treatment status at the .1 level, but not at
the .05 level, and another may appear associated with treatment
status at the .05, but not at the .01, level, depending on how
one handles missing values. One might expect similar results
under random assignment. Figure 3 depicts the optimal [.5,2]
full match’s treatment–control group balance in each category
of each of the 27 covariates, also showing imbalances prior to
matching or stratiﬁcation, for comparison.
In this application, a search among full matches optimal relative to various thinning and thickening caps terminated with
the optimal [.5,2] full match. The search varied the thickening
cap u ﬁrst, before imposing a thinning cap, because under ETT
weightings of stratum effects, u’s impact on precision is greater
than that of the thinning cap l: It is readily conﬁrmed using
(2) that replacing a 1 :1 and a 1 :5 stratum with two 1 :3 strata
yields much more precision than does replacing a 1 :10 and a
1 :50 stratum with two 1 :30 strata. When U is optimally subdivided with thickening caps decreasing from ∞to 10(= 10/1),
to 5(= 10/2), to 10/3, to 10/4 and then to 10/5 or 2, ETTweighted precision increases while none of the 54 MH statistics
for the resulting full matches become signiﬁcant at the .1 level.
The optimal [0,10/6] full matching is still more precise, but
because it has MH statistics that are signiﬁcant at the .1 and .05
levels, we ﬁx the thickening cap at 2.
This leads us to compare optimal [.2,2], [.3,2], ..., and
[.7,2] full matchings. The ﬁrst three of these have no MH statistics that are signiﬁcant at the .1 level, and the last two each
have at least two MH statistics signiﬁcant at the .05 level. Recall
that the optimal [.5,2] matching had one MH statistic signiﬁcant at the .05 level and two more signiﬁcant at the .1 level,
an acceptably small degree of confounding of covariates with
Journal of the American Statistical Association, September 2004
Figure 4. Standardized Biases and Relative Precision [R(·, unconstrained full match)] of Optimal Stratiﬁcations With Variously Constrained Match Ratios.
treatment status. These comparisons lead us to prefer a thinning
cap of .5. (Had we selected ﬁrst a thinning and then a thickening cap rather than the reverse, this procedure would have led
us instead to the optimal [.6,2.5] full match.) Figure 4 displays
standardized biases and relative precisions R(·,U), where U is
the optimal 1 :1 match, for optimal [l,u] full matchings with
various l and u.
3.3 Reduced Sensitivity to Model Speciﬁcation
The model here used to estimate propensity scores lacks interaction terms among its independent variables and involves
no auxiliary modeling of data missingness. This puts it among
the simplest of models one might use for propensity score estimation; it was chosen for this reason. Certainly, more elaborate propensity score models have been used; Rosenbaum
and Rubin , for example, employed a stepwise variable
selection procedure to select main effects and then interaction
terms, and D’Agostino and Rubin modeled item missingness explicitly, ﬁtting their model using the EM algorithm.
The matching strategy taken here, stratifying on variables
strongly predictive of treatment status before full matching with
restrictions, aimed to limit the dependence of the analysis on
any one speciﬁcation of the treatment assignment model. To assess its success at this, a more saturated propensity score model
was ﬁt. As right-hand-side variables, this model has eight interactions and 17 main effects of the original variables, chosen by backward–forward stepwise variable selection. Using
this model’s ﬁtted propensity score, evaluations of thickening
and then thinning caps lead one to prefer an optimal [.4,2] full
match. Call this new matching S2, and the matching selected in
Section 3.2, S1.
Both full matches use all of 3,494 controls, and in most cases
the two matchings place these control subjects into matched sets
of very similar sizes: 20% of the 3,494 go into matched sets of
precisely the same size; for 72% of controls j, the S2-treatment
odds of j’s S2 stratum are no more than 4/3, and no less
than 3/4, of the S1-treatment odds of j’s S1 stratum. Because
a subject’s contribution to our effect estimates is determined by
the conﬁguration of the matched set into which it is placed, it
should be no surprise that the two full matchings lead to similar
estimates of the coaching effect.
4. ESTIMATING TREATMENT EFFECTS
To estimate treatment effects, a model such as (1) must be
supplemented with a causal formalism and appropriate causal
assumptions. For this analysis, the most natural setup is that of
Rubin , who posits random variables Yt and Yc both for
outcomes under the control condition and for outcomes under
the treatment condition. Adding the assumption that these variables are conditionally independent of the treatment assignment
variable (Z) given the covariates (X) makes inference about
treatment effects possible.
Using ETT weighting to combine by-stratum treatment
control differences, the [.5,2] matching leads to aggregate contrasts of 26 points on the math section and 1 point on the verbal.
Under causal assumptions as presently discussed, these estimate effects of coaching on the coached. Using model (1), the
accompanying standard errors are 5 and 5 points. By contrast,
the unadjusted differences of treated and control group means
were 41(±5) and 9(±5) points.
As one might expect, those matchings that fail to reduce
discernible biases to an indiscernible level give higher effect
estimates. For example, the nearly ﬁxed-ratio matching that respects Section 1.2’s subclassiﬁcation while using all controls,
that is, the optimal subdivision of the Race × SES subclassiﬁcation, offers estimates of 30(±5) and 2(±5). Of all
matchings that respect the Race × SES subclassiﬁcation, this
had the most favorable relative precision quotients; yet its estimated standard errors are only negligibly smaller than those
of the [.5,2] match, while its poorer balance translates to apparent biases of one or more standard errors in estimates of the
coaching effect. Conversely, those matchings that did reduce
observed biases to indiscernibility gave lower estimates. The
optimal [.6,2.5] full match of Section 3.2 gives estimates of
23(±5) and 0(±5), and Section 3.3’s [.4,2] full match leads to
estimates of 23(±5) and 0(±5).
4.1 Heterogeneity of Coaching Effects
Unlike both pair matching and analysis of covariance, full
matching’s estimates and standard errors do not assume treatment effects to be the same across units; they average estimates
of individual treatment effects that can, in principle, be quite
different. This is especially advantageous in a coaching study
based on a representative national sample, since coaching programs differ widely in duration, rigor, and approach. As a relaxation of the constant-effect model, consider the hypotheses
of 12 math and 12 verbal effects, one for each Race × SES subclass. By dint of the exact matching on race and father’s education level, the matched-set coaching effects are nested within
subclass coaching effects, and the three models—the constanteffect model, the 12-effects model, and model (1), with its
494 separate treatment effects—can be compared by an analysis of variance (ANOVA). In either the math or the verbal case,
F tests based on the ANOVA reject the constant-effect model
in favor of either the 12-effects model or model (1), and the
12-effects model cannot be rejected from within (1). The hypothesis that there is a single, constant treatment effect is untenable. Granted, given the variety among interventions here
Hansen: Full Matching in an Observational Study
grouped together as “treatments,” there is little to recommend
such hypothesis; yet previous coaching studies have often been
analyzed using regression models that are built upon it.
4.2 Very Large and Very Small Coaching Effects:
Which Are More Plausible?
Is it strange that structured, extended training for the SAT
should produce, on the average, no more than a negligible beneﬁt in verbal scores? In interpreting this result, one should bear
in mind that the control condition is not the absence of preparation for the SAT. In this observational study, “not coached”
means only “did not participate in a program of preparation for
the SAT–I that was held outside of school.” Controls may have,
and by and large did, practice and otherwise prepare for the tests
on their own or in school ; it is possible
that these preparations were sometimes more effective than formal coaching. Indeed, our matching also facilitates estimating
what effect the treatment would have had on the controls, were
they treated, and the results of this calculation suggest that some
controls beneﬁted by selecting alternative test preparations: The
effect of treatment for the controls is estimated at 3 ± 7 points
on the math section and −8 ± 7 points on the verbal. Evidently,
whether and to what degree coaching is beneﬁcial varies greatly
from student to student.
Our analysis’s allowance for heterogeneous coaching effects permits it to speak more directly to the coaching companies’ claims than did Powers and Rock’s analyses. Recall
that the Princeton Review claims its students’ average beneﬁt
is 140 points in the combined score ,
and that Kaplan Educational Centers have said that students
beneﬁt from their courses, on average, by 120 points . Further, a Kaplan spokesman has argued that very different gains are to be expected from Kaplan’s programs as opposed to those of many of its competitors; shorter, cheaper, and
untested programs abound, and smaller beneﬁts are to be expected from them . The multiple-regression type
of analysis favored by Powers and Rock cannot speak directly
to this argument, as they assume uniform treatment effects, but
the matching-based analysis of this article can.
At least 41% of coached students in the College Board sample had been coached by either Kaplan Educational Centers or
the Princeton Review. Consider the hypothesis that Kaplan and
the Princeton Review offer varying coaching beneﬁts that average to 120 points, say. To permit a robust test of this hypothesis,
let us supplement it with the unlikely assumption that all other
companies’ coaching beneﬁts average to 0. Even with models
of form (1), which grant each matched set its own treatment
effect, the upper 95% conﬁdence bounds for the math and verbal effects (of coaching upon the coached) are about 37 and 11
points. Combined, these fall short of the 49-point overall average effect that Kaplan’s and the Princeton Review’s claims
would, at a minimum, entail. The hypothesis is rejected.
5. DISCUSSION: UPDATING THE
LIMITATIONS OF MATCHING
Observational studies compare persons who received a speciﬁed treatment to others who did not, adjusting for pretreatment
differences between treated and comparison groups. Broadly,
these adjustments are effected either by regression modeling or
by stratiﬁcation. Regression adjustments assume that we know
or can reliably discern patterns relating pretreatment, treatment,
and response variables, and require the statistician to specify and ﬁt a corresponding statistical model. Adjustment by
stratiﬁcation assumes only that treatment and control groups
sufﬁciently alike in terms of pretreatment characteristics are
comparable in terms of response to treatment; but it requires
the statistician to make precise what it means for groups to be
sufﬁciently alike prior to treatment, and it requires a method for
grouping subjects into sufﬁciently uniform blocks.
Matching and stratiﬁcation are old and trusted methods of
adjustment for observational studies, but the difﬁculty of implementing them led earlier practitioners to prefer regression.
Cochran warned that in “larger studies... matching becomes impractical.” In smaller and more manageable settings,
Cochran recommended stratiﬁcation as adjustment only for the
one or two most important variables. Adjusting by matching
or stratiﬁcation for more than a few variables seemed hopeless: In one widely cited case, Chapin started with
671 treated subjects and 523 controls but found only 23 treated–
control pairs matching exactly on six categorical covariates.
Citing these concerns, Cochran concluded: “[I]f there are say
4x variables... [then our] recourse is to model construction and
analysis based on the model.”
Cochran gave this pessimistic assessment some 30 years ago.
Advances since then have made observational data no more
amenable to exact matching than they ever were, but the introduction of propensity scores has
greatly facilitated approximate matching on many variables; results possible with propensity scores and optimal full matching
stand in striking contrast with Cochran’s. In analytic studies,
Cochran studied stratiﬁcation on a single variable for
treatment and control groups no more than a standard deviation
apart. The schemes he studied removed as little as 57% and no
more than 89% of the bias along the covariate. In the present
case study, optimal full matching removes as much as 99% of
the bias along a propensity score on which the treated and control means are separated by 1.1 SD’s. In so doing, we have seen,
it reduced to insigniﬁcance biases along 27 covariates, and it
made use of more, not less, of the data than did regressionbased analyses. With ﬂexible matching routines increasingly
available, will regression adjustment for observational studies
soon be obsolete?
APPENDIX: OLSEN’S ALGORITHM: A UNIFIED
APPROACH TO OPTIMAL MATCHING
This appendix presents the algorithm used in this article to create optimal matchings. We employ a variant of the approach of
Rosenbaum , who presented (sec. 7) a general method for translating full-matching problems into network ﬂow problems, which can
in turn be solved efﬁciently using any of several widely available algorithms. According to Section 2.4, full-matching problems may be
associated with triples (T,C,{δij}). A full-matching problem is feasible if it has a solution with ﬁnite total discrepancy. An optimal solution is one in which the average discrepancy within matched sets,
i∈T,j∈C: S(i)=S( j)=s δij/(
s #{(i,j) ∈T × C:S(i) = S(j) = s}),
is as small as it would be under any other solution. Rosenbaum 
represented such a problem as a graph with a node for every treated and
every control, plus a node called “Source” and another called “Drain,”
Journal of the American Statistical Association, September 2004
with edges from Source to each treated node, from i to j when δij < ∞,
and from every control node j to Drain. A network ﬂow problem is associated with this graph in such a way that optimal ﬂows through the
network correspond to optimal full matchings.
By constrained full-matching problem, let us understand a fullmatching problem (T;C;{δij}) accompanied by upper and lower limits (L,U) on the number of controls per treated and upper and lower
limits (˜L, ˜U) on the number of treateds per control; a constrained problem (T;C;{δij};L,U, ˜L, ˜U) is feasible if there exists a solution of the
problem (T;C;{δij}) which respects the constraints. The problem of
ﬁnding an optimal [l,u]-subdivision of a stratiﬁcation U, if one exists, is easily translated to a sequence of constrained full-matching
problems—one for each stratum of U. In the applications discussed
previously, controls outnumber treated subjects in each stratum, with
the consequence that ˜L ≤1 for each constrained full matching problem
that had to be solved.
To handle constrained full-matching problems with ˜L = 1 or 0,
Olsen modiﬁed Rosenbaum’s algorithm in several important ways. First, in addition to Source and Drain nodes and a
node for each study subject, there is an additional node, labeled “Over-
ﬂow,” with edges connecting it to each treated and to each control
node; there is no cost for sending units of ﬂow along these edges.
Second, a negligible amount ε > 0 is added to each discrepancy δij.
In Olsen’s network ﬂow problem, the upper and lower capacity limits
for edges of various types are as follows: for edges from treateds to
controls, ; for an edge from Source to a treated, say i, [0,U]; for
an edge from a treated, i, to Overﬂow, [0,U −L]; for an edge from a
control, j, to Overﬂow, [0, ˜U −1]; and for an edge from a control, j, to
Drain, . The supply (exogenous inﬂow) is 0 at each node except
Source, Drain, and Overﬂow, at which supplies are U · #T, −p · #C,
and p · #C −U · #T, respectively. Here, p is the proportion of available controls that are to be matched to treated subjects; thus p ≤1, and
p < 1 only if ˜L = 0. The constrained full-matching problem is feasible
if and only if the Olsen network ﬂow associated with it is feasible. In
this case, an optimal ﬂow through the network corresponds to a full
match that is optimal among appropriately constrained full matches.
To implement Olsen’s algorithm, I created functions calling the
RELAX-IV network optimization routine of Bertsekas and Tseng
 from the R environment (r-project.org); this code is bundled
together in an add-on package to R, “optmatch,” information about
which can be found on my Web site.
[Received April 2003. Revised January 2004.]