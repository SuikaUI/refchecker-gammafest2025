Behavior Research Methods, Instruments, & Computers
2002, 34 (4), 491-499
Many new and proposed display technologies place
tremendous demands on limited processing resources
and transmission bandwidth. Such demands often involve various combinations of high image resolution, a
large field of view, fast update rates, and low-bandwidth
communication channels. Example applications include
flight, driving, and medical simulators, immersive virtual reality (VR), remote piloting or driving, teleoperation, and videotelephony. Meeting the combined needs
of such applications necessitates a reduction of processing resources and bandwidth.However, because all of the
above-mentioned applications are single-user displays, a
possible solution is to place high image resolution only
at the point of gaze and lower resolutioneverywhere else.
This requires dynamic updating of the high-resolution
display area of interest, or window, whenever the gaze
moves. The most natural method of achieving this is to
use gaze-tracking technology. We will therefore refer to
such displays as gaze-contingent multiresolutional displays (GCMRDs) (for a review, see Reingold, Loschky,
McConkie, & Stampe, in press). GCMRDs produce two
types of savings. First, given that information provided
outside the high-resolution display area of interest is
greatly reduced, there is a reduction in the bandwidth required for transmittingimages. Second, under conditions
in which images are being computer generated (e.g., immersive VR), the rendering requirements are reduced,
because it is simpler to render low-resolution than highresolution image regions, and, therefore, there is a reduction in the need for computer processing resources
(for specific illustrations of such savings, see Reingold
et al., in press).
Whereas much work has been devoted to developing
multiresolutionaldisplays,often calledvariable-resolution,
spatially variant resolution, area-of-interest, or regionof-interest displays , far less work has been done to examine
the effects that such displays have on the perception and
performance of their users .
The present study is concerned particularly with the
perceptual effects of GCMRDs. Previous research in this
area has taken essentially two forms. The aim of the first
line of research has been to find the set of display parameters that results in an imperceptible GCMRD—that
is, one indistinguishable from a constant high-resolution
display .
However, such a display may not always be feasible, or
even needed, for most applications. Thus, most GCMRD
human factors research investigates the perception and
performance effects produced by perceptible GCMRDs
Copyright 2002 Psychonomic Society, Inc.
We gratefully acknowledge David Stampe for his invaluable assistance in programming the experiments and providinginput throughout
the project, and Steve Ito for data collection. Experiment 1 was previously presented at the Human–Computer Interaction International
2001 Conference, and Experiment 3 is to be presented at the Eye Tracking Research & Applications Symposium 2002. Correspondence concerning this article should be addressed to E. M. Reingold,Department
of Psychology, University of Toronto, 100 St. George Street, Toronto,
ON M5S 3G3, Canada (e-mail: ).
Saliency of peripheral targets in
gaze-contingent multiresolutional displays
EYAL M. REINGOLD
University of Toronto, Toronto, Ontario, Canada
LESTER C. LOSCHKY
University of Illinois at Urbana-Champaign, Champaign, Illinois
Gaze-contingent multiresolutional displays (GCMRDs) have been proposed to solve the processing
and bandwidth bottleneck in many single-user displays, by dynamically placing high-resolution in a
window at the center of gaze, with lower resolution everywhere else. The three experiments reported
here document aslowing of peripheraltargetacquisitionassociatedwiththe presenceof agaze-contingent
window. This window effect was shown for displays using either moving video or still images. The window effect was similar across a resolution-definedwindow condition and a luminance-defined window
condition, suggestingthat peripheral image degradation is not a prerequisiteof this effect.The window
effect was also unaffected by the type of window boundary used (sharp or blended). These results are
interpreted in terms of an attentional bias resulting in a reduced saliency of peripheral targets due to
increased competition from items within the window. We discuss the implications of the window effect
for the study of natural scene perception and for human factors research related to GCMRDs.
REINGOLD AND LOSCHKY
(i.e., displays with abnormalities that are quite perceptible to the user). The second line of work may therefore
contribute to our understanding of the operation of the
human visual system while laying the groundwork for
selecting GCMRD system-design characteristics to
achieve specified human performance goals.
The latter line of research has consistently found, for
example, that “degrading” the visual periphery in GCM-
RDs results in shorter saccades and longer search times
 .
Loschky, McConkie, and colleagues have shown that the
shorter saccade lengths were due to a tendency to fixate
more locations in the high-resolution area and fewer in
the degraded area. They explained this as being due to a
reduction in the salience of degraded peripheral saccade
and search targets.
The present study was designed to further explore this
hypothesis of reduced saliency for peripheral targets
(i.e., for targets outside the window). Biresolutional displays were employed with higher resolution inside a
gaze-contingent window and lower resolution outside
the window. Such displays represent the most common
type of GCMRDs and, consequently, it is important to
investigate perception and performance issues related to
this approach. Clearly, the discrete resolution drop-off
method implemented in biresolutional displays doesn’t
match the continuous resolution drop-off function of the
visual system. In particular, biresolutional displays introduce a relatively sharp resolution transition, or edges,
into the visual field, which may produce perceptual
problems. Thus, one of the questions investigated in the
present study concerns whether a more gradual blending
between the two resolution regions would attenuate the
reduction in the salience of degraded peripheral saccade
and search targets. In three experiments, we documented
an interference effect hindering peripheral target acquisition in GCMRDs employing moving video (Experiments 1 and 2) or still images (Experiment 3). In addition, in the latter condition, sharp and blended window
boundaries were contrasted, but this manipulation had
no influence on the magnitude of the interference effect.
EXPERIMENT 1
In this experiment, a GCMRD with full-motion video
was employed,and observers searched for a moving ring
target. The present study posed the following question:If
degraded objects in the visual periphery are less salient
than those in the high-resolution window, will viewing a
scene completely in low resolution make it easier to locate a salient peripheral target? Though counterintuitive,
this might occur if objectsin the high-resolution window
competed for attention with the peripheral target, which
would be less likely to happen when both the foveal and
peripheral regions were degraded. To test this hypothesis, we compared four display conditions: (1) all lower
resolution, (2) a small window, (3) a large window, and
(4) all higher resolution. The dependent variables of interest were initial saccadic latency and total target acquisition time.
Participants. The participants were 18 undergraduate students
at the University of Toronto, who were paid for participating. All
had normal or corrected-to-normal vision and were naive as to the
purpose of the experiment.
Stimuli and Design. The stimuli were full-color video clips shot
from a helicopter flying over landscapes (desert and canyon) containing a target moving against a moving background. The clips were
each approximately 3 sec long, shown at a rate of 30 frames/sec at
320 3 240 pixels. The average luminance was about 60 fL. There
were two versions of each clip: filtered and unfiltered. The unfiltered video clips had an effective resolution of about 11 arc min/line
pair and an average luminance of about 60 fL. The filtered video
clips were produced using a process equivalent to that of a Gaussian
filter (0.5 cycles/deg, or cpd) to filter both the target and the background. The effective resolution of the filtered video clips was
about 85 arc min/line pair using a 26-dB criterion, and the luminance was unchanged. In the filtered images, the target was also filtered, but still discriminable from the background, though sometimes only by target motion.
Resolution-defined windows were created by combining the filtered and unfiltered versions of the same clip, running simultaneously and synchronized in time. The unfiltered version of the video
clip was displayed inside the window, and the blurred version of the
video clip was displayed outside the window. We manipulated the
size of the high-resolution circular window, with all other regions
blurred. There were four display conditions: (1) filtered no window,
(2) filtered small window (1.5º radius), (3) filtered large window
(3º radius), and (4) unfiltered no window (i.e., all higher resolution). Note that in the two window conditions, the level of low-pass
filtering (0.5 cpd) removes a large amount of higher spatial-frequency
information that would otherwise be perceptible in much of the visual periphery . Thus, the filtering
should produce highly noticeable image degradation. All the windows were centered at the participant’s gaze position, as measured
by the EyeLink gaze tracking system (described below). The edges
of the window remained sharp; there was no blending region between the window and the background.
The target, a 1º ring, moved in a straight line at a constant velocity of approximately 8º/sec from the beginning to the end of the
video clip. The color of the target was selected by averaging the
color of the background on which it appeared, and the target’s luminance was raised by 40% to 80% relative to the background. This
coloring technique was designed to make target search dependent
on the motion of the target (i.e., it would be difficult to discriminate
the target from the background in a static scene). There were four
directions of target motion: vertically down the left side, vertically
down the right side, diagonally down and to the left, and diagonally
down and to the right. The backgrounds were 16 video clips of
mountainous and desert terrains shot from a moving helicopter,
some from a forward-looking vantage point, which contained opticflow cues for forward self-motion, and some from directly above
and looking down. All background motion was from the top to the
bottom of the screen, but never in the same direction or at the same
speed as the target motion.
Apparatus. The SR Research Ltd. EyeLink eye-tracking system
used in this research has high spatial resolution (0.01º) and a sampling rate of 250 Hz (4 msec temporal resolution). The three cameras on the EyeLink headband allow simultaneous tracking of both
SALIENCY OF PERIPHERAL TARGETS
eyes and of head position, computing true gaze position with unrestrained head motion. Only the participant’s dominant eye was
tracked in these studies. The EyeLink system uses an Ethernet link
between the eye tracker and display computers to supply real-time
gaze position and saccade event data. The on-line saccade detector
of the eye tracker was set to detect saccades with an amplitude of
0.5º or greater, using an acceleration threshold of 9,500º/sec2 and a
velocity threshold of 30º/sec. Two additional computers, both
66-MHz 486-DX PC compatible, were used to concurrently play
the processed (filtered or high-luminance) and unprocessed video
clips, respectively, and to feed the video to the display computer.
The display computer, a 100-MHz 486-DX PC compatible, controlled stimulus presentation, integrated incoming video signals,
and displayed one channel as background imagery and part of the
other channel as a window at the participant’s point of gaze on a
17-in. ViewSonic 17PS monitor. The display was positioned at a
viewing distance of 60 cm so that the total field of view was 30º
(horizontal) 3 24º (vertical). The total system throughput delay (the
time it takes from the eye movement to a change in the display) was
Procedure. The task for the participants was to acquire (i.e.,
look directly at) a target as rapidly as possible and track it until the
video clip ended. No other response was needed. A trial sequence
began with a fixation dot on a blank screen. The participant fixated
the dot, and the experimenter initiated the trial when the gaze cursor stabilized. The fixation dot disappeared, and after approximately 0.5 sec the video clip started. When the video clip ended, the
fixation dot reappeared, and the next trial began. The participants
received a practice block of 8 trials, followed by four experimental
blocks of 16 trials each, for a total of 64 trials per subject. Each
block contained 4 trials for each of the four display conditions (filtered no window, small window, large window, and unfiltered). In
addition to measuring target acquisition time, the participants’ subjective impressions of image quality were collected.
A 9-point calibration, followed by a 9-point calibration accuracy
test, was performed at the start of the experiment. Calibration was
repeated if the error at any point was more than 1º, or if the average
error for all points was greater than 0.5º. Before each trial, a black
fixation target was presented at the center of the display. The participant fixated this target and the gaze position measured during
the fixation was used to correct any postcalibration drift errors.
Throughout each trial, the experimenter was able to view on a separate monitor the target path, overlaid with a cursor corresponding
to real-time gaze position. If the experimenter judged that gazetracking accuracy had declined, he initiated a full calibration before the next trial. However, this occurred very infrequently.
Results and Discussion
Subjectively, the participants reported that the filtering produced very noticeable peripheral image degradation. Figure 1 summarizes task performance in each of
the four experimental conditions by plotting average
tracking error (distance of gaze from the target) during
the first 1,000 msec of clip viewing. As is shown in the
figure, the unfiltered no-window condition produced
better performance than did the filtered no-window condition, and both of these conditions resulted in better
performance than did either the small or the large window condition(performance did not differ across the two
window conditions).
We used two dependent measures to quantify performance: initial saccadic latency and target acquisition
time. For the purposes of the analyses, a saccade was defined as any eye movement with a peak velocity over a
threshold of 25º/sec and an amplitude of at least 1º. The
latency to first saccade (i.e., initial saccadic latency)was
the time from video onset to the first saccade (in any direction). The latency to acquisitionwas the time from the
start of the video clip (video onset) to acquisition of the
target, defined as the first full 20-msec period in which
the gaze position remained within 2º of the target. Not
includedin the analyses were (1) trials containinga blink
during the period beginning 100 msec prior to video
onset and ending 80 msec following target acquisition,
(2) trials in which acquisition occurred more than 2 sec
Figure 1. Distance of gaze from the target during the first 1,000 msec of clip
viewing in Experiment 1.
REINGOLD AND LOSCHKY
following video onset, (3) trials in which error was greater
than 3º in the first 100 msec after acquisition,(4) trials in
which the average error was greater than 2º after acquisition, and (5) trials in which anticipatory saccades—that
is, any saccades made within 100 msec before or 60 msec
after video onset—were made. In total, 6.1% of the trials were excluded.
As is shown in Figure 2, for both dependent measures,
whereas performance in the unfiltered no-window condition was clearly the best (all ts > 9.71, p < .001), the filtered no-window conditionresulted in better performance
than did either the small or the large window condition(all
ts > 3.37, p < .01). Performance did not significantly differ across the two window conditions (all ts < 1).
The results of the experiment were rather counterintuitive,since more visual information resulted in poorer
target-detectionperformance. Specifically, it is clear that
the biresolutional displays (i.e., gaze-contingent window
conditions) led to inferior performance in comparison
with the filtered no-window (i.e., all low-pass filtered,
low-resolution) condition. Longer initial saccadic latencies in the window conditions were observed, and this
initial slowing was likely responsible for the longer total
target acquisition times. This is the case because the
magnitude of the window effects on initial latencies and
acquisition times were similar. Moreover, across participants, the correlation between these two measures reveals that, on average, 62.3% of the variance in acquisition times can be accounted for by the variance in initial
saccadic latencies.
These findings are consistent with the hypothesis that
the window conditionsreduce the relative salience of the
peripheral targets. However, it is unclear whether the filtering of the peripheral image in the window conditions
(i.e., lower resolution outside than inside the window)
was a prerequisite for producing the reduction in the
salience of the peripheral targets. In other words, it is important to distinguishbetween the effects of filtering and
those of windowing. In order to accomplish that, in the
next experiment, we introduced a gaze-contingent window condition that did not involve degrading the image
outside the window. This would allow for the possibility
of showing an effect of a gaze-contingent window on the
detection of peripheral targets in the absence of peripheral image filtering.
EXPERIMENT 2
In this experiment, two types of window were used:
the standard resolution-defined window, with higher resolution in the window and a low-pass filtered periphery,
and a luminance-defined window in which the luminance inside the window was increased by 20% and luminance outside the window was unchanged. Note that
in the luminance-defined window condition, a window
was present, but the quality of the peripheral image was
preserved (i.e., it was the same as the all-higher-resolution
condition). Two no-window conditions, one in which the
display is uniformlyhigherresolutionand one in which the
display is uniformly low-pass filtered, were used as well.
As in Experiment 1, the task was to detect peripheral target
stimuli moving across the screen. It was hypothesizedthat
the presence of both types of windows, resolution defined
and luminance defined, would impair performance on this
task, indicatingthat the effect of a salient window can impair peripheral task performance independentlyof resolution differences between the central and peripheralregions
of the image. Furthermore, it was hypothesizedthatthe fil-
Figure 2. Initial saccadic latency and target acquisition latency, in milliseconds, as
a function of the four filtering conditions of Experiment 1.
SALIENCY OF PERIPHERAL TARGETS
tering of the periphery in both the window-present and the
window-absent conditions would impair performance, indicating that the degraded quality of the peripheral imagery also impairs detection performance.
Participants. The participants were 60 undergraduate students
at the University of Toronto, who received credit in an introductory
psychology course for participation. All had normal or correctedto-normal vision and were naive as to the purpose of the experiment.
Design. A 2 3 2 (filtering 3 windowing) design was used. There
were two levels of filtering, filtered and unfiltered, and two levels
of windowing, window and no window, for a total of four conditions. The filtered window condition was the previously described
resolution-defined window condition, whereas the unfiltered window condition was the luminance-defined window condition. In the
filtered no-window condition, the image was uniformly low-pass
filtered, and in the unfiltered no-window condition, the image was
uniformly higher resolution.
The four conditions were counterbalanced with the four types of
target motion for a total of 16 combinations. Each combination and
each background scene appeared in a random sequence four times
per block, for a total of 64 trials per block. Three blocks of trials
were used in the experiment. Before the experiment began, the participants were given a practice block of eight trials.
Stimuli. The stimuli were identical to those used in Experiment 1, with the following exceptions. All the windows were
roughly circular with a 3º radius. Luminance-defi ned windows
were created by displaying the unfiltered version of the video clip
across the entire screen, but selectively increasing the luminance
inside the window by 20%.
Apparatus and Procedure. The apparatus and procedure were
identical to those used in Experiment 1.
Results and Discussion
We used the same exclusioncriteria for the data as those
used in Experiment1, and a totalof 5.8% of the trials were
dropped. As in Experiment 1, we measured the participants’ initial saccadic latency and target acquisition latency. Figure 3 illustrates that initial saccadic latencies
and acquisition times were slowed by the presence of a
window, and that this was true for both the resolutiondefined window and the luminance-defined window.
To further explore the effects of windowing and filtering on task performance, 2 3 2 (filtering 3 windowing) within-subjects analyses of variance (ANOVAs)
were conducted,with initial and second saccadic latency,
acquisition time, number and amplitude of saccades
prior to target acquisition, and first-saccade error as dependent variables. The results of these analyses are summarized in Table 1. As can be seen in the table, both filtering and windowing had a negative impact on task
performance. Specifically, both filtering and windowing
produced longer initial saccadic latencies and acquisition times, more saccades, and shorter saccadic amplitudes. In addition, filtering, but not windowing, also resulted in greater first-saccade error (i.e., gaze-to-target
distance)and longer second-saccade latency (i.e., longer
first-fixation duration). The only significant filtering 3
windowing interactionreflected greater reduction in saccadic amplitude caused by the resolution-defined window (1.0º) than by the luminance-defined window (0.6º).
The results of this study show that both the presence
of a window and low-pass filtering of the peripheral target increase the time taken to initiate the first saccade to
a peripheral target and to acquire that target. As was argued earlier, the slowing of initial saccadic latency most
likely mediates the longer total target acquisition times.
This conclusion is consistent with the present finding
that, on trials in which more than a single saccade is executed prior to target acquisition,the latency of the second
saccade is unaffected by the windowing manipulation.
Figure 3. Initial saccadic latency and target acquisition latency, in milliseconds, as a function of the windowing and filtering conditions of Experiment 2.
REINGOLD AND LOSCHKY
The present findingsof longer target acquisition times
and shorter saccades in the window conditions are also
consistent with the results from studies documenting
shorter saccade lengths and longer search times with
GCMRDs having highly degraded peripheries . By distinguishing the effects of windowing and low-pass filtering, the present study suggests that peripheral target detection with GCMRDs may
be negatively impacted not only by the loss of perceptual
detail due to filtering, but also by the mere presence of
the gaze-contingent window. Indeed, for some of the
measures we employed, the windowing effect appears to
be just as strong using a luminance-defined window as a
resolution-defined window. This strengthens the argument that the windowing effect is due to greater relative
salience of objects within the window in comparison to
those outside it, including the target.
Nevertheless, there is an alternative explanationfor the
results of Experiments 1 and 2. Specifically, the window
conditions employed involved a sharp boundary between
the regions inside and outside the window due to the resolution or luminance difference across these display areas.
Consequently, the salience of the window boundary might
be able to explain the longer initial saccadic latencies in
Experiments 1 and 2. If the window boundary is salient, it
might compete with the target for attention when the display initially appears on the screen, thus resulting in the
longerinitialsaccadiclatenciesfound in bothexperiments.
Unfortunately, neitherExperiment1 nor Experiment2 provided any way of distinguishingwhether, relativeto thetarget in the periphery, it is the objects in the window that are
salient or the window boundary that is salient.
Questions regarding the impact of the window boundary on the perception and performance of observers in
GCMRDs are also important for applied reasons. Specifically, when biresolutional displays have been used in
flight simulators,it has frequentlybeen reported that users
prefer larger windows, because with smaller windows
the edges are more visible . If the
findings of Experiments 1 and 2 were shown to be due to
the visibility of the boundary of the window, this would
add further supportto the claim that designers of GCMRD
applications should avoid having such boundaries.
EXPERIMENT 3
In this experiment, we had two chief goals. First, we
wanted to test the hypothesis that a sharp boundary is
necessary to produce the windowing effect of Experiments 1 and 2—that is, a slowing of initial saccadic latencies to a salient peripheral target in the biresolutional
condition relative to an all-low-pass condition. In order
to test this hypothesis, we decided to compare window
conditions in which there was either a sharp or a smooth
resolution boundary. If we were to find that initial saccadic latencies are longer in both the sharp and the
smooth-boundary window conditions than in an all-lowpass filtered condition, as in both Experiments 1 and 2,
this would add strength to the argument that visual
salience is reduced outside the window. If the window
effect disappears when the window boundary is smooth,
then this would suggest that sharp boundaries are generally problematic for perception in GCMRDs.
Second, we wanted to see if we could replicate the
windowing effect of Experiments1 and 2 with a GCMRD
using static images. Since both of the above experiments
used full-motion video, it is possible that the windowing
effects found in those experiments are limited to moving
targets and/or a moving image context. Thus, we decided
to use a GCMRD with static images and static targets. If
the windowing effect from the previous two experiments
generalizes to the static targets and scene contexts, this
Effects of Windowing and Filtering on Mean Initial and Second Saccadic Latency, Acquisition Time, Number and Amplitude of
Saccades Prior to Target Acquisition, and First-Saccade Error in Experiment 2
Unfiltered
Dependent Variable
Interaction
Initial saccade latency (msec)
Second-saccade latency (msec)
(First-fixation duration)
n.s.; p = .36
Acquisition time (msec)
Number of saccades
Amplitude of saccades (deg)
First-saccade error (deg)
n.s.; p = .76
Note—Windowing effects = average performance in window conditions minus average performance in no-window conditions; filtering effects =
average performance in filtered conditions minus average performance in unfiltered conditions.
SALIENCY OF PERIPHERAL TARGETS
would suggest that more general perceptual processes
are involved in the effect, and that image motion is not a
necessary component of it.
Participants. The participants were 45 undergraduate students
at the University of Toronto, who were paid for participating. All
had normal or corrected-to-normal vision and were naive as to the
purpose of the experiment.
Stimuli and Design. The images used were 72 images of residential interiors. The image size was 360 3 240 pixels, and the display subtended 30º 3 24º, filling the entire screen, for resolutions
of 12 pixels per degree horizontally and 10.7 pixels per degree vertically. One target—a 7 3 7 pixel (about 0.6º) white cross with a
black border—was added to each image. The targets were placed on
one of the four diagonals, at a distance of 12º from the central fixation point. For each of the 288 image (72) 3 target-location (4)
combinations, filtered versions were created by using a Gaussian
low-pass filter of 1.0 cpd.
On some trials, a 12º square window was dynamically centered
on the participant’s point of gaze (i.e., the edge of the window was
6º from the center of vision vertically or horizontally; see Figure 4).
Within the window, the image was relatively high resolution (i.e., as
in the unfiltered image). Outside the window, the image was in
lower resolution (i.e., as in the filtered image). Three window display conditions were used: the filtered no-window condition (the
entire image was uniformly low-pass filtered), the sharp-boundary
window condition (a 12º window with no blending region), and the
blended-boundary window condition (a 12º window with a 3º wide
blending region). In the latter condition, a blending function was
used at the edges of the window to mix periphery (filtered) and
foreground (unfiltered) images, with the ratio changing linearly.
For example, moving up, down, left, or right from the participant’s
point of gaze, the image was at full resolution up to 4.5º from the
participant’s point of gaze, was a 50% mix of the full-resolution and
lower-resolution images at 6º, and was all at lower resolution past
7.5º. It is important to note that, as in Experiments 1 and 2, the degree of low-pass filtering used in this experiment (1 cpd) reduced
image resolution outside the window well below the sensitivity limits of the human visual system for much of the visual periphery
 . Thus, the filtering should
have produced very noticeable image degradation. In the blendedboundary window condition, the participants reported that they
were aware that parts of the image were degraded but that they were
unable to perceive the blend (i.e., they perceived smooth degradation into the periphery). In contrast, in the sharp-boundary window
condition, the participants reported perceiving the contours of the
window as an abrupt change in the quality of the image.
Each participant performed in 12 blocks of 72 trials. Across
blocks, each of the 288 image 3 target-location combinations appeared once in each of the three window conditions (filtered no
window, sharp-boundary window, and blended-boundary window),
for a total of 864 trials in the experiment.
Apparatus. The eyetracker and monitor were the same as those
used in Experiments 1 and 2. The display was generated using an
S3 VGA card, and the frame rate was 120 Hz. The average delay between an eye movement and the update of the gaze-contingent window was 14 msec.
Procedure. The procedure was identical to that used in Experiment 1.
Results and Discussion
Custom analysis software was used to process the eye
movement data files. Trials were rejected because of anticipation if the participant made a substantial saccade
(more than 2º) or a blink either before the picture was
presented or less than 70 msec after its appearance. Trials were also rejected if the first saccade made by the
participant was less than 3º in magnitude, or if the directional error of the first saccade was more than 22.5º.
These exclusions accounted for 2.2% and 3.4% of the
total trials, respectively. Analyses were then performed
on the remaining trials. The results show that the target
was generally quite salient, with the initial saccade endpoint falling within 3º or less of the target on 86% of all
trials. Consequently, the best measure of acquisition
speed was deemed to be the initial saccadic latency measure.
As is shown in Table 2, the all-low-pass filtered nowindow conditionproduced reliably shorter mean initial
saccadiclatenciestothe target thandid eitherof thewindow
conditions [no window vs. sharp boundary, t(44)= 7.13,
p < .001; no window vs. blended boundary, t(44)= 6.87,
p < .001], whereas latencies in the sharp- and blendedboundary windows were identical to each other.
The results of Experiment 3 suggest that having a
gaze-contingent window results in longer initial saccadic
latencies than does an all-low-pass filtered image, but
whether the gaze-contingentwindow boundary is sharply
defined or smoothly gradated makes no difference. This
allows us to reject the window-boundary-artifact explanation of our results. This strengthens the argument that
the objects inside the window become relatively more
salient than they otherwise would have been, resulting in
increased competitionfor attentionbetween objectsin the
high-resolution window and the target in the periphery.
The results of Experiment 3 also show that the slowing
of initial saccadic latencies in windowed conditions is a
robust effect and is not dependent on using full-motion
video as in Experiments 1 and 2. However, the 14-msec
windowing effect in the present experiment (see Table 2)
was smaller than the windowing effects in Experiments 1
and 2, which were 58 msec and 40 msec, respectively.
Whether this difference in the size of the windowing effect was due to the full-motion versus the still-image factor, or to some other difference between these studies
(e.g., salience of the target vs. the periphery, color vs.
monochrome images, etc.) will need to be determined by
further research.
GENERAL DISCUSSION
In this study, we demonstrated that programming a
saccade to a peripheraltarget can be disrupted by the presence of a gaze-contingent window. We demonstrated that
Effect of Window Type on Mean Initial Saccadic Latency
in Experiment 3
Initial Saccadic Latency (msec)
Window Type
All low-pass, None
Sharp boundary
Blended boundary
REINGOLD AND LOSCHKY
this windowing effect was obtainedregardless of whether
or not peripheral degradation or filtering is used (Experiment 2) and when either sharp or smooth window boundaries were employed (Experiment 3). This effect appears
to be quite general and was obtained with either moving
video(Experiments1 and 2) or still images(Experiment 3).
We proposean accountof the windowingeffect in terms
of attentional factors. Specifically, we hypothesize a type
of attentional capture caused by the gaze-contingent window, reflecting an increase in saliency of objects inside
the window, and a relative decrease in saliency for peripheral objects . It is this
increased competition between the objects in the window and the peripheral target that causes the windowing
effect we observed.
Our effect is similar to other findings of interference
with performance on peripheral detection tasks as a
function of increased foveal load . For example,
Holmes et al. demonstrated that the mere presence of a foveal item that subjects were instructed to ignore resulted in poorer peripheral task performance . Holmes
et al. interpreted this finding as a general interference effect; the foveal item draws the attention of the observer
and, thus, interferes with processing of other stimuli in
the visual field. Given that this decline in peripheral task
performance was sometimes found to be greater for tar-
Figure 4. (A) A blended-boundary window: The high-resolution area
inside the window fades into the low-resolution background over several
degrees. The mixture of foreground and background images varies linearly within the blending region. The effective window area is set to the
center of the blending region. (B) An illustration of a 12º blendedboundary window (the participant’s gaze position is at the center of the
screen). Filtering outside the window was produced by using a Gaussian low-pass filter of 1.0 cpd.
SALIENCY OF PERIPHERAL TARGETS
gets at larger eccentricities , it was argued that the foveal load reduced the useful field of view, leading to the coining of the controversial term tunnel vision .
Regardless of the mechanism responsible for the windowing effect we documented, this effect has important
implicationsfor human factors research related to GCM-
RDs. Taken together, the windowing effect and previous
findings showing shorter saccade lengths and longer
search times in GCMRDs with perceptible peripheral
image degradation clearly point
to perception and performance costs that may be associated with the use of such GCMRDs.
However, the practical implications of such effects
should vary greatly depending on the specific area of application.In pilotingsituations,split-second delays in reactingtoperipheralstimuli—for example,a missileflare—
can have severe consequences. But there may be no important consequencesfor such a delay in video-telephony
or Internet image download applications. Likewise, we
would expect that under conditions in which it is important to identify a target or to discriminate it from nontargets, the window conditions would undoubtedly be superior to the filtered condition in which considerable
high spatial-frequency information was lost (i.e., no details could be seen). Therefore, the windowing effect we
have shown may be specific to the task of orienting to
salient peripheral targets. Moreover, recently, Loschky
et al. have shown that it is possible to construct
GCRMDs having substantialimage filtering without any
discernible perceptionand performance costs. Unlike the
biresolutionaldisplaysused in the current study,Loschky
et al. employed continuous resolution drop-off
functions derived from psychophysical studies of visual
sensitivity .
It is also noteworthy that the current results showed no
effect of blending the boundary between levels of resolution. This therefore fails to support the claim that such
blending is important in GCMRDs. However, given the
limited nature of the present analyses, it would be premature to draw strong conclusions based on this null result. Clearly, more research is required in order to investigate the perceptual and attentional factors underlying
the windowing effect documented here. Nevertheless,
our preliminary findings indicate that this effect may
have important implications for both applied and basic
investigationsof eye movements during the performance
of complex naturalistic tasks.