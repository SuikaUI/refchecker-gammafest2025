Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 505â€“514
July 5 - 10, 2020. câƒ2020 Association for Computational Linguistics
GCAN: Graph-aware Co-Attention Networks
for Explainable Fake News Detection on Social Media
Department of Statistics
National Cheng Kung University
Tainan, Taiwan
 
Cheng-Te Li
Institute of Data Science
National Cheng Kung University
Tainan, Taiwan
 
This paper solves the fake news detection problem under a more realistic scenario on social media. Given the source short-text tweet
and the corresponding sequence of retweet
users without text comments, we aim at predicting whether the source tweet is fake or
not, and generating explanation by highlighting the evidences on suspicious retweeters and
the words they concern. We develop a novel
neural network-based model, Graph-aware Co-
Attention Networks (GCAN), to achieve the
goal. Extensive experiments conducted on real
tweet datasets exhibit that GCAN can signiï¬cantly outperform state-of-the-art methods by
16% in accuracy on average. In addition, the
case studies also show that GCAN can produce
reasonable explanations.
Introduction
Social media is indispensable in peopleâ€™s daily life,
where users can express themselves, access news,
and interact with each other. Information can further spread through the social network. Opinions
and sentiments on source stories can be reï¬‚ected
by user participation and interaction. The convenient and low-cost essence of social networking
brings collective intelligence, but at the same time
leads to a negative by-product, the propagation of
misinformation such as fake news.
Fake news is a kind of news story possessing intentionally false information on social media . The widespread of fake news can mislead
the public, and produce unjust political, economic,
or psychological proï¬t for some parties . Data
mining and machine learning techniques were utilized to detect fake news . Typical approaches rely on the content of new articles to extract textual features, such
as n-gram and bag of words, and apply supervised
learning (e.g., random forest and support vector machine) for binary classiï¬cation .
NLP researchers also learn advanced linguistic features, such as factive/assertive verbs and subjectivity and writing styles and consistency . Multi-modal context
information is also investigated, such as user pro-
ï¬les and
retweet propagation .
Nevertheless, there are still critical challenges in
detecting fake news online. First, existing contentbased approaches require documents
to be long text, e.g., news articles, so that the representation of words and sentences can be better
learned. However, tweets on social media are usually short text , which produces
severe data sparsity problem. Second, some stateof-the-art models require a rich collection of user comments for every news story, to learn
the opinions of retweeters, which usually provide
strong evidences in identifying fake news. However, most users on social media tend to simply
reshare the source story without leaving any comments . Third, some studies consider that the pathways of information cascade (i.e., retweets) in the social network
are useful for classifying misinformation, and thus
learn the representations of the tree-based propagation structures. However, it is costly to obtain
the diffusion structure of retweets at most times
due to privacy concerns . Many
users choose to hide or delete the records of social
interactions. Fourth, if the service providers or the
government agencies desire to inspect who are the
suspicious users who support the fake news, and
which topics do they concern in producing fake
news , existing models cannot
provide explanations. Although dEFEND can generate reasonable explanation,
it requires both long text of source articles and text
of user comments.
This paper deals with fake news detection under a more realistic scenario on social media. We
predict whether a source tweet story is fake, given
only its short text content and its retweet sequence
of users, along with user proï¬les. That said, we
detect fake news under three settings: (a) short-text
source tweet, (b) no text of user comments, and (c)
no network structures of social network and diffusion network. Moreover, we require the fake news
detection model to be capable of explainability, i.e.,
highlighting the evidence when determining a story
is fake. The model is expected to point out the
suspicious retweeters who support the spreading of
fake news, and highlight the words they especially
pay attention to from the source tweet.
To achieve the goal, we propose a novel model,
Graph-aware Co-Attention Network (GCAN) 1.
We ï¬rst extract user features from their proï¬les
and social interactions, and learn word embeddings from the source short text. Then we use
convolutional and recurrent neural networks to
learn the representation of retweet propagation
based on user features. A graph is constructed
to model the potential interactions between users,
and the graph convolution network is used to learn
the graph-aware representation of user interactions. We develop a dual co-attention mechanism
to learn the correlation between the source tweet
and retweet propagation, and the co-inï¬‚uence between the source tweet and user interaction. The
binary prediction is generated based on the learned
embeddings.
We summarize the contributions as follows. (1)
We study a novel and more realistic scenario of
fake news detection on social media. (2) For accurate detection, we develop a new model, GCAN,
to better learn the representations of user interactions, retweet propagation, and their correlation
with source short text. (3) Our dual co-attention
mechanism can produce reasonable explanations.
(4) Extensive experiments on real datasets demonstrate the promising performance of GCAN, comparing to state-of-the-art models. The GCAN explainability is also exhibited in case studies.
1The Code of GCAN model is available and can be accessed via: 
We organize this paper as follows. Section 2
reviews the relevant approaches to fake news detection in social media. We describe the problem statement in Section 3. Then in Section 4, the details
of our proposed GCAN model will be elaborated.
Section 5 demonstrates the evaluation settings and
results. We conclude this work in Section 6.
Related Work
Content-based approaches rely on the text content
to detect the truthfulness of news articles, which
usually refer to long text. A variety of text characteristics are investigated for supervised learning, including TF-IDF and topic features , language styles (e.g., part of speech,
factive/assertive verbs, and subjectivity) , writing styles and consistency , and social emotions .
Zhao et al. ï¬nd the enquiry phrases from
user responses are useful, and Ma et al. use
recurrent neural networks to learn better representations of user responses.
User-based approaches model the traits of users
who retweet the source story. Yang et al. extract account-based features, such as â€œis veriï¬edâ€,
gender, hometown, and number of followers. Shu
et al. unveil user proï¬les between fake and
real news are signiï¬cantly different. CRNN devise a joint recurrent and convolutional network model (CRNN) to better represent
retweeterâ€™s proï¬les. Session-based heterogeneous
graph embedding is proposed to
learn the traits of users so that they can be identiï¬ed
in shared accounts. However, since such a method
relies on session information, it cannot be directly
applied for fake news detection.
Structure-based approaches leverage the propagation structure in the social network to detect fake
news. Sampson et al. leverage the implicit
information, i.e., hashtags and URLs, to connect
conversations whose users do not have social links,
and ï¬nd such implicit info can improve the performance of rumor classiï¬cation. Ma et al. create a kernel-based method that captures high-order
patterns differentiating different types of rumors.
Ma et al. develop a tree-structured recursive
neural networks to learn the embedding of rumor
propagation structure. Although multi-relational
graph embedding methods are able to effectively learn how different types of entities (related to source news ar-
Table 1: Comparison of related studies. Column notations: news story texts (NS), response comments (RC),
user characteristics (UC), propagation structure (PS),
social network (SN), and model explainability (ME).
For the NS column, â€œSâ€ and â€œLâ€ indicates short and
long text, respectively.
Ma et al. 
Ma et al. 
Liu and Wu 
Ruchansky et al. 
Shu et al. 
ticles) interact with each other in a heterogeneous
information network for classiï¬cation tasks, they
cannot be applied for the inductive setting, i.e., detecting the truthfulness of new-coming tweets.
Hybrid-based approaches consider and fuse
multi-modal context information regarding the
source tweets. CSI learns
the sequential retweet features by incorporating
response text and user proï¬les, and generates suspicious scores of users based on their social interactions. Wang et al. develop an event adversarial neural network to learn transferable features
by removing the event-speciï¬c features, along with
convolutional neural networks to extract textual
and visual features. dEFEND 
jointly learns the sequential effect of response comments and the correlation between news content
and comments, and use an attention mechanism to
provide explainability.
We compare our work and the most relevant studies in Table 1. The uniqueness of our work lies in:
targeting at short text, requiring no user response
comments, and allow model explainability.
Problem Statement
Let Î¨ = {s1, s2...s|Î¨|} be a set of tweet stories,
and U = {u1, u2...u|U|} be a set of users. Each
si âˆˆÎ¨ is a short-text document (also called the
source tweet), given by si = {qi
2, ..., qi
li} indicating li words in story si. Each uj âˆˆU is
associated with a user vector xj âˆˆRd representing the user feature with d dimensions. When
a news story si is posted, some users will share
si and generate a sequence of retweet records,
which is termed a propagation path.
news story si, we denote its propagation path as
Ri = {..., (uj, xj, tj), ...}, where (uj, xj, tj) depicts j-th user uj (with their feature vector xj)
ğ…: product
ğšğ‘”: softmax
à·œğ : product
ğ…T: product
ğšğ‘ : softmax
à·œğ¬1: product
ğŸ: concatenate
à·œğ²: prediction
ğ…T: product
ğšğ‘ : softmax
à·œğ¬2: product
ğ…: product
ğšğ‘: softmax
Æ¸ğœ: product
Source tweet
Retweet Order
Source-Interaction
Co-Attention
Source-Propagation
Co-Attention
Graph-aware
Representation
Source Tweet
CNN-based Propagation
Representation
GRU-based Propagation
Representation
Figure 1: The architecture of our GCAN model.
who retweets story si, and j = 1, 2, ..., K (i.e.,
K = |Ri|). We denote the set of users who retweet
story si as Ui. In Ri, we denote the user who originally shares si as u1 at time t1. For j > 1, user
uj retweets si at tj (tj > t1). Each story si is associated with a binary label yi âˆˆ{0, 1} to represent
its truthfulness, where yi = 0 indicates story si is
true, and yi = 1 means si is fake.
Given a source tweet si, along with the corresponding propagation path Ri containing users uj
who retweet si as well as their feature vectors xj,
our goal is to predict the truthfulness yi of story si,
i.e., binary classiï¬cation. In addition, we require
our model to highlight few users uj âˆˆUi who
retweet si and few words qi
k âˆˆsi that can interpret
why si is identiï¬ed as a true or fake one.
The Proposed GCAN Model
We develop a novel model, Graph-aware Co-
Attention Networks (GCAN), to predict fake news
based on the source tweet and its propagation-based
users. GCAN consists of ï¬ve components. The ï¬rst
is user characteristics extraction: creating features
to quantify how a user participates in online social networking. The second is new story encoding:
generating the representation of words in the source
tweet. The third is user propagation representation:
modeling and representing how the source tweet
propagates by users using their extracted characteristics. The fourth is dual co-attention mechanisms:
capturing the correlation between the source tweet
and usersâ€™ interactions/propagation. The last is
making prediction: generating the detection outcome by concatenating all learned representations.
User Characteristics Extraction
To depict how users participate in social networking, we employ their metadata and proï¬les to de-
ï¬ne the feature vector xj of every user uj. The
extracted features are listed as follows: (1) number of words in a userâ€™s self-description, (2) number of words in ujâ€™s screen name, (3) number of
users who follows uj, (4) number of users that uj
is following, (5) number of created stories for uj,
(6) time elapsed after ujâ€™s ï¬rst story, (7) whether
the uj account is veriï¬ed or not, (8) whether uj
allows the geo-spatial positioning, (9) time difference between the source tweetâ€™s post time and ujâ€™s
retweet time, and (10) the length of retweet path
between uj and the source tweet (1 if uj retweets
the source tweet). Eventually, every user feature
vector xj âˆˆRv is generated, where v is the number
of features.
Source Tweet Encoding
The given source tweet is represented by a wordlevel encoder.
The input is the one-hot vector
of each word in story si.
Since the length of
every source story is different, we perform zero
padding here by setting a maximum length m.
Let E = [e1, e2, ..., em] âˆˆRm be the input vector of source story, in which em is the one-hot
encoding of the m-th word. We create a fullyconnected layer to generate word embeddings,
V = [v1, v2, ..., vm] âˆˆRdÃ—m, where d is the dimensionality of word embeddings. The derivation
of V is given by:
V = tanh(WwE + bw)
where Ww is the matrix of learnable weights, and
bc is the bias term. Then, we utilize Gating Recurrent Units (GRU) to learn the
words sequence representation from V. The source
tweet representation learning can be depicted by:
st = GRU(vt), t âˆˆ{1, ..., m}, where m is the
GRU dimensionality. We denote the source tweet
representation as S = [s1, s2, ..., sm] âˆˆRdÃ—m.
User Propagation Representation
The propagation of source tweet si is triggered by
a sequence of users as time proceeds. We aim at
exploiting the extracted user feature vectors xj,
along with the user sequence spreading si, to learn
user propagation representation. The underlying
idea is that the user characteristics in real news
propagations are different from those of fake ones.
We make use of Gating Recurrent Units (GRU)
and Convolutional Neural Network (CNN) to learn
propagation representations.
Here the input is the sequence of feature vectors of users retweeting si, denoted by PF(si) =
âŸ¨x1, x2, ..., xt, ..., xnâŸ©, where n is the ï¬xed length
of observed retweets. If the number of users sharing si is higher than n, we take the ï¬rst n users. If
the number is lower than n, we resample users in
PF(si) until its length equals to n.
GRU-based Representation.
Given the sequence of feature vectors PF(si) = âŸ¨..., xt, ..., âŸ©,
we utilize GRU to learn the propagation representation. Each GRU state has two inputs, the current
feature vector xt and the previous stateâ€™s output
vector htâˆ’1, and one output vector ht. The GRUbased representation learning can be depicted by:
ht = GRU(xt), t âˆˆ{1, ..., n}, where n is the dimensionality of GRU. We generate the ï¬nal GRUbased user propagation embedding h âˆˆRd by average pooling, given by h = 1
CNN-based Representation.
We take advantage of 1-D convolution neural network to
learn the sequential correlation of user features
in PF(si). We consider Î» consecutive users at
one time to model their sequential correlation,
i.e., âŸ¨xt, ..., xt+Î»âˆ’1âŸ©.
Hence the ï¬lter is set as
Wf âˆˆRÎ»Ã—v. Then the output representation vector C âˆˆRdÃ—(t+Î»âˆ’1) is given by
C = ReLU(Wf Â· Xt:t+Î»âˆ’1 + bf)
where Wf is the matrix of learnable parameters,
ReLU is the activation function, Xt:t+Î»âˆ’1 depicts
sub-matrices whose ï¬rst rowâ€™s index is from t = 1
to t = n âˆ’Î» + 1, and bf is the bias term.
Graph-aware Propagation
Representation
We aim at creating a graph to model the potential interaction among users who retweet source
story si. The idea is that some correlation between
users with particular characteristics can reveal the
possibility that the source tweet is fake. To ful-
ï¬ll such an idea, a graph Gi = (Ui, Ei) is constructed for the set of users who share source story
si (i.e., Ui), where Ei is the corresponding edge set.
Since the true interactions between users are unknown, we consider Gi is a fully-connected graph,
i.e., âˆ€eÎ±Î² âˆˆEi, uÎ± âˆˆUi, uÎ² âˆˆUi, and uÎ± Ì¸= uÎ²,
|Ei| = nÃ—(nâˆ’1)
. To incorporate user features in
the graph, each edge eÎ±Î² âˆˆEi is associated with
a weight Ï‰Î±Î², and the weight is derived based on
cosine similarity between user feature vectors xÎ±
and xÎ², given by Ï‰Î±Î² =
âˆ¥xÎ±âˆ¥âˆ¥xÎ²âˆ¥. We use matrix
A = [Ï‰Î±Î²] âˆˆRnÃ—n to represent weights between
any pair of nodes uÎ± and uÎ² in graph Gi.
A graph convolution network (GCN) layer is created based on the constructed graph Gi for source tweet si. A GCN is a
multi-layer neural network that performs on graph
data and generates embedding vectors of nodes
according to their neighborhoods. GCN can capture information from a nodeâ€™s direct and indirect
neighbors through stacking layer-wise convolution.
Given the matrix A for graph Gi, and X depicting
the matrix of feature vectors for users in Gi, the new
g-dimensional node feature matrix H(l+1) âˆˆRnÃ—g
can be derived by
H(l+1) = Ï( ËœAH(l)Wl),
where l is the layer number, ËœA = Dâˆ’1
the normalized symmetric weight matrix (Dii =
j Aij), and Wl âˆˆRdÃ—g is the matrix of learnable parameters at the l-th GCN layer. Ï is an
activation function, i.e., a ReLU Ï(x) = max(0, x).
Here H(0) is set to be X. We choose to stack two
GCN layers in derive the learned graph-aware representation, denoted as G âˆˆRgÃ—n.
Dual Co-attention Mechanism
We think the evidence of fake news can be unveiled through investigating which parts of the
source story are concerned by which kinds of
retweet users, and fake clues can be reï¬‚ected by
how retweet users interact with each other. Therefore, we develop a dual co-attention mechanism
to model the mutual inï¬‚uence between the source
tweet (i.e., S = [s1, s2, ..., sm]) and user propagation embeddings (i.e., C = [c1, c2, ..., cnâˆ’Î»+1]
from Section 4.3), and between the source tweet
and graph-aware interaction embeddings (i.e., G =
[g1, g2, ..., gn] from Section 4.4). Equipped with
co-attention learning, our model is capable of the
explainability by looking into the attention weights
between retweet users in the propagation and words
in the source tweet. In other words, by extending the co-attention formulation ,
the proposed dual co-attention mechanism aims
to attend to the source-tweet words and graphaware interaction users simultaneously (sourceinteraction co-attention), and also attend to the
source-tweet words and propagated users simultaneously (source-propagation co-attention).
Source-Interaction Co-attention.
compute a proximity matrix F âˆˆRmÃ—n as: F =
tanh(SâŠ¤WsgG), where Wsg is a d Ã— g matrix of
learnable parameters. By treating the proximity
matrix as a feature, we can learn to predict source
and interaction attention maps, given by
Hs = tanh(WsS + (WgG)FâŠ¤)
Hg = tanh(WgG + (WsS)F)
where Ws âˆˆRkÃ—d, Wg âˆˆRkÃ—g are matrices of
learnable parameters. The proximity matrix F can
be thought to transforming user-interaction attention space to source story word attention space,
and vice versa for its transpose FâŠ¤. Then we can
generate the attention weights of source words and
interaction users through the softmax function:
as = softmax , and should
Table 2: Statistics of two Twitter datasets.
# source tweets
avg. retweets per story
avg. words per source
be emphasized separately. Nevertheless, the CNNbased user representations (i.e., features that depict
the sequence of user proï¬les) has been used in the
co-attention mechanism to learn their interactions
with source tweet.
Make Prediction
We aim at predicting fake news using the sourceinteraction co-attention feature vectors Ë†s1 and Ë†g,
the source-propagation feature vectors Ë†s2 and Ë†c,
and the sequential propagation feature vector h.
Let f = [Ë†s1, Ë†g,Ë†s2, Ë†c, h] which is then fed into a
multi-layer feedforward neural network that ï¬nally
predicts the label. We generate the binary prediction vector Ë†y = [Ë†y0, Ë†y1], where Ë†y0 and Ë†y1 indicate
the predicted probabilities of label being 0 and 1,
respectively. It can be derived through
Ë†y = softmax(ReLU(fWf + bf)),
where Wf is the matrix of learnable parameters,
and bf is the bias term. The loss function is devised
to minimize the cross-entropy value:
L(Î˜) = âˆ’y log(Ë†y1) âˆ’(1 âˆ’y) log(1 âˆ’Ë†y0)
where Î˜ denotes all learnable parameters in the
entire neural network. We choose the Adam optimizer to learn Î˜ as it can determine the learning
rate abortively.
Experiments
We conduct experiments to answer three questions:
(1) whether our GCAN model is able to achieve
satisfactory performance of fake news detection,
compared to state-of-the-art methods? (2) how
does each component of GCAN contribute to the
performance? (3) can GCAN generate a convincing
explanation that highlights why a tweet is fake?
Datasets and Evaluation Settings
Data. Two well-known datasets compiled by Ma
et al. , Twitter15 and Twitter16, are utilized. Each dataset contains a collection of source
tweets, along with their corresponding sequences
of retweet users. We choose only â€œtrueâ€ and â€œfakeâ€
labels as the ground truth. Since the original data
does not contain user proï¬les, we use user IDs to
crawl user information via Twitter API.
Competing Methods. We compare our GCAN
with the state-of-the-art methods and some baselines, as listed below. (1) DTC : a decision tree-based model combining user
proï¬les and the source tweet. (2) SVM-TS : a linear support vector machine classi-
ï¬er that utilizes the source tweet and the sequence
of retweet usersâ€™ proï¬les. (3) mGRU : a modiï¬ed gated recurrent unit model for
rumor detection, which learns temporal patterns
from retweet user proï¬le, along with the sourceâ€™s
features. (4) RFC : an extended random forest model combining features
from retweet user proï¬les and the source tweet. (5)
CSI : a state-of-the-art
fake news detection model incorporating articles,
and the group behavior of users who propagate
fake news by using LSTM and calculating the user
scores. (6) tCNN : a modi-
ï¬ed convolution neural network that learns the local variations of user proï¬le sequence, combining
with the source tweet features. (7) CRNN : a state-of-the-art joint CNN and
RNN model that learns local and global variations of retweet user proï¬les, together with the
resource tweet. (8) dEFEND : a
state-of-the-art co-attention-based fake news detection model that learns the correlation between the
source articleâ€™s sentences and user proï¬les.
Model Conï¬guration. Our model is termed
â€œGCANâ€. To examine the effectiveness of our
graph-aware representation, we create another version â€œGCAN-Gâ€, denoting our model without the
graph convolution part. For both our models and
competing methods, we set the number of training epochs to be 50. The hyperparameter setting
of GCAN is: number of retweet users = 40, word
embedding dim = 32, GRU output dim = 32, 1-D
CNN output ï¬lter size = 3, 1-D CNN output dim =
32, and GCN output dim = 32. The hyperparameters of competing methods are set by following the
settings mentioned in respective studies.
Metrics & Settings. The evaluation metrics include Accuracy, Precision, Recall, and F1. We
randomly choose 70% data for training and 30%
for testing. The conducted train-test is repeated 20
Table 3: Main results. The best model and the best competitor are highlighted by bold and underline, respectively.
Improvement
times, and the average values are reported.
Experimental Results
Main Results. The main results are shown in Table 3. We can clearly ï¬nd that the proposed GCAN
signiï¬cantly outperforms the best competing methods over all metrics across two datasets, improving
the performance by around 17% and 15% on average in Twitter15 and Twitter16, respectively. Even
without the proposed graph-aware representation,
GCAN-G can improve the best competing method
by 14% and 3% on average in Twitter15 and Twitter16, respectively. Such promising results prove
the effectiveness of GCAN for fake news detection. The results also imply three insights. First,
GCAN is better than GCAN-G by 3.5% and 13%
improvement in Twitter15 and Twitter16, respectively. This exhibits the usefulness of graph-aware
representation. Second, the dual co-attention mechanism in GCAN is quite powerful, as it clearly outperforms the best non-co-attention state-of-the-art
model CSI. Third, while both GCAN-G and dE-
FEND are co-attention-based, additional sequential
features learned from the retweet user sequence in
GCAN-G can signiï¬cantly boost the performance.
Early Detection. We further report the performance (in only Accuracy due to page limit) by
varying the number of observed retweet users per
source story (from 10 to 50), as exhibited in Figure 2 and Figure 3. It can be apparently found that
our GCAN consistently and signiï¬cantly outperforms the competitors. Even with only ten retweeters, GCAN can still achieve 90% accuracy. Such
results tell GCAN is able to generate accurate early
detection of the spreading fake news, which is cru-
Number of users
Figure 2: Accuracy by # retweet users in Twitter15.
Number of users
Figure 3: Accuracy by # retweet users in Twitter16.
cial when defending misinformation.
Ablation Analysis.
We report how each of
GCAN component contributes by removing each
one from the entire model.
Below â€œALLâ€ denotes using all components of GCAN. By removing dual co-attention, GRU-based representation,
graph-aware representation, and CNN-based representation, we have sub-models â€œ-Aâ€, â€œ-Râ€, â€œ-Gâ€,
Figure 4: GCAN ablation analysis in Accuracy.
Figure 5: Highlighting evidential words via word cloud.
Larger font sizes indicate higher co-attention weights.
and â€œ-Câ€, respectively. Sub-model â€œ-S-Aâ€ denotes
the one without both source tweet embeddings and
dual co-attention. The results are presented in Figure 4. We can ï¬nd every component indeed plays
a signiï¬cant contribution, especially for dual coattention (â€œ-Aâ€) and the representation learning
of user propagation and interactions (â€œ-Râ€ and â€œ-
Gâ€). Since the source tweet provides fundamental
clues, the accuracy drops signiï¬cantly without it
GCAN Explainability
The co-attention weights derived from Section 4.5
attended on source tweet words and retweet users
(source-propagation co-attention) allow our GCAN
to be capable of explainability.
By exhibiting
where attention weights distribute, evidential words
and users in predicting fake news can be revealed.
Note that we do not consider source-interaction coattention for explainability because user interaction
features learned from the constructed graph cannot
be intuitively interpretable.
Explainability on Source Words. To demonstrate the explainability, we select two source
tweets in the test data. One is fake (â€œbreaking:
ks patient at risk for ebola: in strict isolation at
ku med center in kansas city #kwch12â€), and the
other is real (â€œconï¬rmed: this is irrelevant. rt @ks-
9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
Rewteet Order
Figure 6: Visualization of attention weights for user
propagations of 3 fake (upper F1-F3) and 3 true source
tweets. From left to right is retweet order. Dark colors
refer to higher attention weights.
Ans:Â fake news
RetweetÂ Propagation
highlighted
byÂ attention
weightsÂ on
highlighted
byÂ attention
weightsÂ on
BreakingÂ :Â hugeÂ explosionÂ ofÂ anÂ #oil
pipelineÂ belongingÂ toÂ @saudi_aramco
nearÂ sudair,Â #saudiarabia.
Figure 7: Evidential words highlighed by GCAN in
source tweet (upper) and suspicious users highlighed
by GCAN in retweet propagation (bottom), in which
each column is a user characteristic. Note that only few
user characteristics are presented.
dknews: conï¬rmed: #mike-brown had no criminal
record. #fergusonâ€). We highlight evidential words
with higher co-attention weights in font sizes of
word clouds, as exhibited in Figure 5. GCAN predicts the former to be fake with stronger attention
on words â€œbreakingâ€ and â€œstrictâ€, and detects the
latter as real since it contains â€œconï¬rmedâ€ and â€œirrelevant.â€ Such results may correspond to the common knowledge that fake news tends to use dramatic
and obscure words while real news is attended by
conï¬rmed and fact checking-related words.
Explainability on Retweet Propagation. We
aim to exploit the retweet order in propagations to
unfold the behavior difference between fake and
real news. We randomly pick three fake (F1-F3)
and three true (T1-T3) source stories, and plot their
weights from source-propagation co-attention (Section 4.5), as exhibited in Figure 6, in which the
horizontal direction from left to right denotes the
order of retweet. The results show that to determine
whether a story is fake, one should ï¬rst examine
the characteristics of users who early retweet the
source story. The evidences of fake news in terms
of user characteristics may be evenly distributed in
the propagation.
Explainability on Retweeter Characteristics.
The source-propagation co-attention of our GCAN
model can further provide an explanation to unveil
the traits of suspicious users and the words they
focus on. A case study is presented in Figure 7.
We can ï¬nd that the traits of suspicious users in
retweet propagation can be: accounts are not veriï¬ed, shorter account creation time, shorter user
description length, and shorter graph path length
to the user who posts the source tweet. In addition,
what they highly attend are words â€œbreakingâ€ and
â€œpipeline.â€ We think such kind of explanation can
beneï¬t interpret the detection of fake news so as to
understand their potential stances.
Conclusion
In this study, we propose a novel fake news detection method, Graph-aware Co-Attention Networks (GCAN). GCAN is able to predict whether
a short-text tweet is fake, given the sequence of its
retweeters. The problem scenario is more realistic
and challenging than existing studies. Evaluation
results show the powerful effectiveness and the reasonable explainability of GCAN. Besides, GCAN
can also provide early detection of fake news with
satisfying performance. We believe GCAN can be
used for not only fake news detection, but also other
short-text classiï¬cation tasks on social media, such
as sentiment detection, hate speech detection, and
tweet popularity prediction. We will explore model
generalization in the future work. Besides, while
fake news usually targets at some events, we will
also extend GCAN to study how to remove eventspeciï¬c features to further boost the performance
and explainability.
Acknowledgments
This work is supported by Ministry of Science
and Technology (MOST) of Taiwan under grants
109-2636-E-006-017 (MOST Young Scholar Fellowship) and 108-2218-E-006-036, and also by
Academia Sinica under grant AS-TP-107-M05.