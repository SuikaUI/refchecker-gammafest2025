Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 505–514
July 5 - 10, 2020. c⃝2020 Association for Computational Linguistics
GCAN: Graph-aware Co-Attention Networks
for Explainable Fake News Detection on Social Media
Department of Statistics
National Cheng Kung University
Tainan, Taiwan
 
Cheng-Te Li
Institute of Data Science
National Cheng Kung University
Tainan, Taiwan
 
This paper solves the fake news detection problem under a more realistic scenario on social media. Given the source short-text tweet
and the corresponding sequence of retweet
users without text comments, we aim at predicting whether the source tweet is fake or
not, and generating explanation by highlighting the evidences on suspicious retweeters and
the words they concern. We develop a novel
neural network-based model, Graph-aware Co-
Attention Networks (GCAN), to achieve the
goal. Extensive experiments conducted on real
tweet datasets exhibit that GCAN can signiﬁcantly outperform state-of-the-art methods by
16% in accuracy on average. In addition, the
case studies also show that GCAN can produce
reasonable explanations.
Introduction
Social media is indispensable in people’s daily life,
where users can express themselves, access news,
and interact with each other. Information can further spread through the social network. Opinions
and sentiments on source stories can be reﬂected
by user participation and interaction. The convenient and low-cost essence of social networking
brings collective intelligence, but at the same time
leads to a negative by-product, the propagation of
misinformation such as fake news.
Fake news is a kind of news story possessing intentionally false information on social media . The widespread of fake news can mislead
the public, and produce unjust political, economic,
or psychological proﬁt for some parties . Data
mining and machine learning techniques were utilized to detect fake news . Typical approaches rely on the content of new articles to extract textual features, such
as n-gram and bag of words, and apply supervised
learning (e.g., random forest and support vector machine) for binary classiﬁcation .
NLP researchers also learn advanced linguistic features, such as factive/assertive verbs and subjectivity and writing styles and consistency . Multi-modal context
information is also investigated, such as user pro-
ﬁles and
retweet propagation .
Nevertheless, there are still critical challenges in
detecting fake news online. First, existing contentbased approaches require documents
to be long text, e.g., news articles, so that the representation of words and sentences can be better
learned. However, tweets on social media are usually short text , which produces
severe data sparsity problem. Second, some stateof-the-art models require a rich collection of user comments for every news story, to learn
the opinions of retweeters, which usually provide
strong evidences in identifying fake news. However, most users on social media tend to simply
reshare the source story without leaving any comments . Third, some studies consider that the pathways of information cascade (i.e., retweets) in the social network
are useful for classifying misinformation, and thus
learn the representations of the tree-based propagation structures. However, it is costly to obtain
the diffusion structure of retweets at most times
due to privacy concerns . Many
users choose to hide or delete the records of social
interactions. Fourth, if the service providers or the
government agencies desire to inspect who are the
suspicious users who support the fake news, and
which topics do they concern in producing fake
news , existing models cannot
provide explanations. Although dEFEND can generate reasonable explanation,
it requires both long text of source articles and text
of user comments.
This paper deals with fake news detection under a more realistic scenario on social media. We
predict whether a source tweet story is fake, given
only its short text content and its retweet sequence
of users, along with user proﬁles. That said, we
detect fake news under three settings: (a) short-text
source tweet, (b) no text of user comments, and (c)
no network structures of social network and diffusion network. Moreover, we require the fake news
detection model to be capable of explainability, i.e.,
highlighting the evidence when determining a story
is fake. The model is expected to point out the
suspicious retweeters who support the spreading of
fake news, and highlight the words they especially
pay attention to from the source tweet.
To achieve the goal, we propose a novel model,
Graph-aware Co-Attention Network (GCAN) 1.
We ﬁrst extract user features from their proﬁles
and social interactions, and learn word embeddings from the source short text. Then we use
convolutional and recurrent neural networks to
learn the representation of retweet propagation
based on user features. A graph is constructed
to model the potential interactions between users,
and the graph convolution network is used to learn
the graph-aware representation of user interactions. We develop a dual co-attention mechanism
to learn the correlation between the source tweet
and retweet propagation, and the co-inﬂuence between the source tweet and user interaction. The
binary prediction is generated based on the learned
embeddings.
We summarize the contributions as follows. (1)
We study a novel and more realistic scenario of
fake news detection on social media. (2) For accurate detection, we develop a new model, GCAN,
to better learn the representations of user interactions, retweet propagation, and their correlation
with source short text. (3) Our dual co-attention
mechanism can produce reasonable explanations.
(4) Extensive experiments on real datasets demonstrate the promising performance of GCAN, comparing to state-of-the-art models. The GCAN explainability is also exhibited in case studies.
1The Code of GCAN model is available and can be accessed via: 
We organize this paper as follows. Section 2
reviews the relevant approaches to fake news detection in social media. We describe the problem statement in Section 3. Then in Section 4, the details
of our proposed GCAN model will be elaborated.
Section 5 demonstrates the evaluation settings and
results. We conclude this work in Section 6.
Related Work
Content-based approaches rely on the text content
to detect the truthfulness of news articles, which
usually refer to long text. A variety of text characteristics are investigated for supervised learning, including TF-IDF and topic features , language styles (e.g., part of speech,
factive/assertive verbs, and subjectivity) , writing styles and consistency , and social emotions .
Zhao et al. ﬁnd the enquiry phrases from
user responses are useful, and Ma et al. use
recurrent neural networks to learn better representations of user responses.
User-based approaches model the traits of users
who retweet the source story. Yang et al. extract account-based features, such as “is veriﬁed”,
gender, hometown, and number of followers. Shu
et al. unveil user proﬁles between fake and
real news are signiﬁcantly different. CRNN devise a joint recurrent and convolutional network model (CRNN) to better represent
retweeter’s proﬁles. Session-based heterogeneous
graph embedding is proposed to
learn the traits of users so that they can be identiﬁed
in shared accounts. However, since such a method
relies on session information, it cannot be directly
applied for fake news detection.
Structure-based approaches leverage the propagation structure in the social network to detect fake
news. Sampson et al. leverage the implicit
information, i.e., hashtags and URLs, to connect
conversations whose users do not have social links,
and ﬁnd such implicit info can improve the performance of rumor classiﬁcation. Ma et al. create a kernel-based method that captures high-order
patterns differentiating different types of rumors.
Ma et al. develop a tree-structured recursive
neural networks to learn the embedding of rumor
propagation structure. Although multi-relational
graph embedding methods are able to effectively learn how different types of entities (related to source news ar-
Table 1: Comparison of related studies. Column notations: news story texts (NS), response comments (RC),
user characteristics (UC), propagation structure (PS),
social network (SN), and model explainability (ME).
For the NS column, “S” and “L” indicates short and
long text, respectively.
Ma et al. 
Ma et al. 
Liu and Wu 
Ruchansky et al. 
Shu et al. 
ticles) interact with each other in a heterogeneous
information network for classiﬁcation tasks, they
cannot be applied for the inductive setting, i.e., detecting the truthfulness of new-coming tweets.
Hybrid-based approaches consider and fuse
multi-modal context information regarding the
source tweets. CSI learns
the sequential retweet features by incorporating
response text and user proﬁles, and generates suspicious scores of users based on their social interactions. Wang et al. develop an event adversarial neural network to learn transferable features
by removing the event-speciﬁc features, along with
convolutional neural networks to extract textual
and visual features. dEFEND 
jointly learns the sequential effect of response comments and the correlation between news content
and comments, and use an attention mechanism to
provide explainability.
We compare our work and the most relevant studies in Table 1. The uniqueness of our work lies in:
targeting at short text, requiring no user response
comments, and allow model explainability.
Problem Statement
Let Ψ = {s1, s2...s|Ψ|} be a set of tweet stories,
and U = {u1, u2...u|U|} be a set of users. Each
si ∈Ψ is a short-text document (also called the
source tweet), given by si = {qi
2, ..., qi
li} indicating li words in story si. Each uj ∈U is
associated with a user vector xj ∈Rd representing the user feature with d dimensions. When
a news story si is posted, some users will share
si and generate a sequence of retweet records,
which is termed a propagation path.
news story si, we denote its propagation path as
Ri = {..., (uj, xj, tj), ...}, where (uj, xj, tj) depicts j-th user uj (with their feature vector xj)
𝐅: product
𝐚𝑔: softmax
ො𝐠: product
𝐅T: product
𝐚𝑠: softmax
ො𝐬1: product
𝐟: concatenate
ො𝐲: prediction
𝐅T: product
𝐚𝑠: softmax
ො𝐬2: product
𝐅: product
𝐚𝑐: softmax
Ƹ𝐜: product
Source tweet
Retweet Order
Source-Interaction
Co-Attention
Source-Propagation
Co-Attention
Graph-aware
Representation
Source Tweet
CNN-based Propagation
Representation
GRU-based Propagation
Representation
Figure 1: The architecture of our GCAN model.
who retweets story si, and j = 1, 2, ..., K (i.e.,
K = |Ri|). We denote the set of users who retweet
story si as Ui. In Ri, we denote the user who originally shares si as u1 at time t1. For j > 1, user
uj retweets si at tj (tj > t1). Each story si is associated with a binary label yi ∈{0, 1} to represent
its truthfulness, where yi = 0 indicates story si is
true, and yi = 1 means si is fake.
Given a source tweet si, along with the corresponding propagation path Ri containing users uj
who retweet si as well as their feature vectors xj,
our goal is to predict the truthfulness yi of story si,
i.e., binary classiﬁcation. In addition, we require
our model to highlight few users uj ∈Ui who
retweet si and few words qi
k ∈si that can interpret
why si is identiﬁed as a true or fake one.
The Proposed GCAN Model
We develop a novel model, Graph-aware Co-
Attention Networks (GCAN), to predict fake news
based on the source tweet and its propagation-based
users. GCAN consists of ﬁve components. The ﬁrst
is user characteristics extraction: creating features
to quantify how a user participates in online social networking. The second is new story encoding:
generating the representation of words in the source
tweet. The third is user propagation representation:
modeling and representing how the source tweet
propagates by users using their extracted characteristics. The fourth is dual co-attention mechanisms:
capturing the correlation between the source tweet
and users’ interactions/propagation. The last is
making prediction: generating the detection outcome by concatenating all learned representations.
User Characteristics Extraction
To depict how users participate in social networking, we employ their metadata and proﬁles to de-
ﬁne the feature vector xj of every user uj. The
extracted features are listed as follows: (1) number of words in a user’s self-description, (2) number of words in uj’s screen name, (3) number of
users who follows uj, (4) number of users that uj
is following, (5) number of created stories for uj,
(6) time elapsed after uj’s ﬁrst story, (7) whether
the uj account is veriﬁed or not, (8) whether uj
allows the geo-spatial positioning, (9) time difference between the source tweet’s post time and uj’s
retweet time, and (10) the length of retweet path
between uj and the source tweet (1 if uj retweets
the source tweet). Eventually, every user feature
vector xj ∈Rv is generated, where v is the number
of features.
Source Tweet Encoding
The given source tweet is represented by a wordlevel encoder.
The input is the one-hot vector
of each word in story si.
Since the length of
every source story is different, we perform zero
padding here by setting a maximum length m.
Let E = [e1, e2, ..., em] ∈Rm be the input vector of source story, in which em is the one-hot
encoding of the m-th word. We create a fullyconnected layer to generate word embeddings,
V = [v1, v2, ..., vm] ∈Rd×m, where d is the dimensionality of word embeddings. The derivation
of V is given by:
V = tanh(WwE + bw)
where Ww is the matrix of learnable weights, and
bc is the bias term. Then, we utilize Gating Recurrent Units (GRU) to learn the
words sequence representation from V. The source
tweet representation learning can be depicted by:
st = GRU(vt), t ∈{1, ..., m}, where m is the
GRU dimensionality. We denote the source tweet
representation as S = [s1, s2, ..., sm] ∈Rd×m.
User Propagation Representation
The propagation of source tweet si is triggered by
a sequence of users as time proceeds. We aim at
exploiting the extracted user feature vectors xj,
along with the user sequence spreading si, to learn
user propagation representation. The underlying
idea is that the user characteristics in real news
propagations are different from those of fake ones.
We make use of Gating Recurrent Units (GRU)
and Convolutional Neural Network (CNN) to learn
propagation representations.
Here the input is the sequence of feature vectors of users retweeting si, denoted by PF(si) =
⟨x1, x2, ..., xt, ..., xn⟩, where n is the ﬁxed length
of observed retweets. If the number of users sharing si is higher than n, we take the ﬁrst n users. If
the number is lower than n, we resample users in
PF(si) until its length equals to n.
GRU-based Representation.
Given the sequence of feature vectors PF(si) = ⟨..., xt, ..., ⟩,
we utilize GRU to learn the propagation representation. Each GRU state has two inputs, the current
feature vector xt and the previous state’s output
vector ht−1, and one output vector ht. The GRUbased representation learning can be depicted by:
ht = GRU(xt), t ∈{1, ..., n}, where n is the dimensionality of GRU. We generate the ﬁnal GRUbased user propagation embedding h ∈Rd by average pooling, given by h = 1
CNN-based Representation.
We take advantage of 1-D convolution neural network to
learn the sequential correlation of user features
in PF(si). We consider λ consecutive users at
one time to model their sequential correlation,
i.e., ⟨xt, ..., xt+λ−1⟩.
Hence the ﬁlter is set as
Wf ∈Rλ×v. Then the output representation vector C ∈Rd×(t+λ−1) is given by
C = ReLU(Wf · Xt:t+λ−1 + bf)
where Wf is the matrix of learnable parameters,
ReLU is the activation function, Xt:t+λ−1 depicts
sub-matrices whose ﬁrst row’s index is from t = 1
to t = n −λ + 1, and bf is the bias term.
Graph-aware Propagation
Representation
We aim at creating a graph to model the potential interaction among users who retweet source
story si. The idea is that some correlation between
users with particular characteristics can reveal the
possibility that the source tweet is fake. To ful-
ﬁll such an idea, a graph Gi = (Ui, Ei) is constructed for the set of users who share source story
si (i.e., Ui), where Ei is the corresponding edge set.
Since the true interactions between users are unknown, we consider Gi is a fully-connected graph,
i.e., ∀eαβ ∈Ei, uα ∈Ui, uβ ∈Ui, and uα ̸= uβ,
|Ei| = n×(n−1)
. To incorporate user features in
the graph, each edge eαβ ∈Ei is associated with
a weight ωαβ, and the weight is derived based on
cosine similarity between user feature vectors xα
and xβ, given by ωαβ =
∥xα∥∥xβ∥. We use matrix
A = [ωαβ] ∈Rn×n to represent weights between
any pair of nodes uα and uβ in graph Gi.
A graph convolution network (GCN) layer is created based on the constructed graph Gi for source tweet si. A GCN is a
multi-layer neural network that performs on graph
data and generates embedding vectors of nodes
according to their neighborhoods. GCN can capture information from a node’s direct and indirect
neighbors through stacking layer-wise convolution.
Given the matrix A for graph Gi, and X depicting
the matrix of feature vectors for users in Gi, the new
g-dimensional node feature matrix H(l+1) ∈Rn×g
can be derived by
H(l+1) = ρ( ˜AH(l)Wl),
where l is the layer number, ˜A = D−1
the normalized symmetric weight matrix (Dii =
j Aij), and Wl ∈Rd×g is the matrix of learnable parameters at the l-th GCN layer. ρ is an
activation function, i.e., a ReLU ρ(x) = max(0, x).
Here H(0) is set to be X. We choose to stack two
GCN layers in derive the learned graph-aware representation, denoted as G ∈Rg×n.
Dual Co-attention Mechanism
We think the evidence of fake news can be unveiled through investigating which parts of the
source story are concerned by which kinds of
retweet users, and fake clues can be reﬂected by
how retweet users interact with each other. Therefore, we develop a dual co-attention mechanism
to model the mutual inﬂuence between the source
tweet (i.e., S = [s1, s2, ..., sm]) and user propagation embeddings (i.e., C = [c1, c2, ..., cn−λ+1]
from Section 4.3), and between the source tweet
and graph-aware interaction embeddings (i.e., G =
[g1, g2, ..., gn] from Section 4.4). Equipped with
co-attention learning, our model is capable of the
explainability by looking into the attention weights
between retweet users in the propagation and words
in the source tweet. In other words, by extending the co-attention formulation ,
the proposed dual co-attention mechanism aims
to attend to the source-tweet words and graphaware interaction users simultaneously (sourceinteraction co-attention), and also attend to the
source-tweet words and propagated users simultaneously (source-propagation co-attention).
Source-Interaction Co-attention.
compute a proximity matrix F ∈Rm×n as: F =
tanh(S⊤WsgG), where Wsg is a d × g matrix of
learnable parameters. By treating the proximity
matrix as a feature, we can learn to predict source
and interaction attention maps, given by
Hs = tanh(WsS + (WgG)F⊤)
Hg = tanh(WgG + (WsS)F)
where Ws ∈Rk×d, Wg ∈Rk×g are matrices of
learnable parameters. The proximity matrix F can
be thought to transforming user-interaction attention space to source story word attention space,
and vice versa for its transpose F⊤. Then we can
generate the attention weights of source words and
interaction users through the softmax function:
as = softmax , and should
Table 2: Statistics of two Twitter datasets.
# source tweets
avg. retweets per story
avg. words per source
be emphasized separately. Nevertheless, the CNNbased user representations (i.e., features that depict
the sequence of user proﬁles) has been used in the
co-attention mechanism to learn their interactions
with source tweet.
Make Prediction
We aim at predicting fake news using the sourceinteraction co-attention feature vectors ˆs1 and ˆg,
the source-propagation feature vectors ˆs2 and ˆc,
and the sequential propagation feature vector h.
Let f = [ˆs1, ˆg,ˆs2, ˆc, h] which is then fed into a
multi-layer feedforward neural network that ﬁnally
predicts the label. We generate the binary prediction vector ˆy = [ˆy0, ˆy1], where ˆy0 and ˆy1 indicate
the predicted probabilities of label being 0 and 1,
respectively. It can be derived through
ˆy = softmax(ReLU(fWf + bf)),
where Wf is the matrix of learnable parameters,
and bf is the bias term. The loss function is devised
to minimize the cross-entropy value:
L(Θ) = −y log(ˆy1) −(1 −y) log(1 −ˆy0)
where Θ denotes all learnable parameters in the
entire neural network. We choose the Adam optimizer to learn Θ as it can determine the learning
rate abortively.
Experiments
We conduct experiments to answer three questions:
(1) whether our GCAN model is able to achieve
satisfactory performance of fake news detection,
compared to state-of-the-art methods? (2) how
does each component of GCAN contribute to the
performance? (3) can GCAN generate a convincing
explanation that highlights why a tweet is fake?
Datasets and Evaluation Settings
Data. Two well-known datasets compiled by Ma
et al. , Twitter15 and Twitter16, are utilized. Each dataset contains a collection of source
tweets, along with their corresponding sequences
of retweet users. We choose only “true” and “fake”
labels as the ground truth. Since the original data
does not contain user proﬁles, we use user IDs to
crawl user information via Twitter API.
Competing Methods. We compare our GCAN
with the state-of-the-art methods and some baselines, as listed below. (1) DTC : a decision tree-based model combining user
proﬁles and the source tweet. (2) SVM-TS : a linear support vector machine classi-
ﬁer that utilizes the source tweet and the sequence
of retweet users’ proﬁles. (3) mGRU : a modiﬁed gated recurrent unit model for
rumor detection, which learns temporal patterns
from retweet user proﬁle, along with the source’s
features. (4) RFC : an extended random forest model combining features
from retweet user proﬁles and the source tweet. (5)
CSI : a state-of-the-art
fake news detection model incorporating articles,
and the group behavior of users who propagate
fake news by using LSTM and calculating the user
scores. (6) tCNN : a modi-
ﬁed convolution neural network that learns the local variations of user proﬁle sequence, combining
with the source tweet features. (7) CRNN : a state-of-the-art joint CNN and
RNN model that learns local and global variations of retweet user proﬁles, together with the
resource tweet. (8) dEFEND : a
state-of-the-art co-attention-based fake news detection model that learns the correlation between the
source article’s sentences and user proﬁles.
Model Conﬁguration. Our model is termed
“GCAN”. To examine the effectiveness of our
graph-aware representation, we create another version “GCAN-G”, denoting our model without the
graph convolution part. For both our models and
competing methods, we set the number of training epochs to be 50. The hyperparameter setting
of GCAN is: number of retweet users = 40, word
embedding dim = 32, GRU output dim = 32, 1-D
CNN output ﬁlter size = 3, 1-D CNN output dim =
32, and GCN output dim = 32. The hyperparameters of competing methods are set by following the
settings mentioned in respective studies.
Metrics & Settings. The evaluation metrics include Accuracy, Precision, Recall, and F1. We
randomly choose 70% data for training and 30%
for testing. The conducted train-test is repeated 20
Table 3: Main results. The best model and the best competitor are highlighted by bold and underline, respectively.
Improvement
times, and the average values are reported.
Experimental Results
Main Results. The main results are shown in Table 3. We can clearly ﬁnd that the proposed GCAN
signiﬁcantly outperforms the best competing methods over all metrics across two datasets, improving
the performance by around 17% and 15% on average in Twitter15 and Twitter16, respectively. Even
without the proposed graph-aware representation,
GCAN-G can improve the best competing method
by 14% and 3% on average in Twitter15 and Twitter16, respectively. Such promising results prove
the effectiveness of GCAN for fake news detection. The results also imply three insights. First,
GCAN is better than GCAN-G by 3.5% and 13%
improvement in Twitter15 and Twitter16, respectively. This exhibits the usefulness of graph-aware
representation. Second, the dual co-attention mechanism in GCAN is quite powerful, as it clearly outperforms the best non-co-attention state-of-the-art
model CSI. Third, while both GCAN-G and dE-
FEND are co-attention-based, additional sequential
features learned from the retweet user sequence in
GCAN-G can signiﬁcantly boost the performance.
Early Detection. We further report the performance (in only Accuracy due to page limit) by
varying the number of observed retweet users per
source story (from 10 to 50), as exhibited in Figure 2 and Figure 3. It can be apparently found that
our GCAN consistently and signiﬁcantly outperforms the competitors. Even with only ten retweeters, GCAN can still achieve 90% accuracy. Such
results tell GCAN is able to generate accurate early
detection of the spreading fake news, which is cru-
Number of users
Figure 2: Accuracy by # retweet users in Twitter15.
Number of users
Figure 3: Accuracy by # retweet users in Twitter16.
cial when defending misinformation.
Ablation Analysis.
We report how each of
GCAN component contributes by removing each
one from the entire model.
Below “ALL” denotes using all components of GCAN. By removing dual co-attention, GRU-based representation,
graph-aware representation, and CNN-based representation, we have sub-models “-A”, “-R”, “-G”,
Figure 4: GCAN ablation analysis in Accuracy.
Figure 5: Highlighting evidential words via word cloud.
Larger font sizes indicate higher co-attention weights.
and “-C”, respectively. Sub-model “-S-A” denotes
the one without both source tweet embeddings and
dual co-attention. The results are presented in Figure 4. We can ﬁnd every component indeed plays
a signiﬁcant contribution, especially for dual coattention (“-A”) and the representation learning
of user propagation and interactions (“-R” and “-
G”). Since the source tweet provides fundamental
clues, the accuracy drops signiﬁcantly without it
GCAN Explainability
The co-attention weights derived from Section 4.5
attended on source tweet words and retweet users
(source-propagation co-attention) allow our GCAN
to be capable of explainability.
By exhibiting
where attention weights distribute, evidential words
and users in predicting fake news can be revealed.
Note that we do not consider source-interaction coattention for explainability because user interaction
features learned from the constructed graph cannot
be intuitively interpretable.
Explainability on Source Words. To demonstrate the explainability, we select two source
tweets in the test data. One is fake (“breaking:
ks patient at risk for ebola: in strict isolation at
ku med center in kansas city #kwch12”), and the
other is real (“conﬁrmed: this is irrelevant. rt @ks-
9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37
Rewteet Order
Figure 6: Visualization of attention weights for user
propagations of 3 fake (upper F1-F3) and 3 true source
tweets. From left to right is retweet order. Dark colors
refer to higher attention weights.
Ans: fake news
Retweet Propagation
highlighted
by attention
weights on
highlighted
by attention
weights on
Breaking : huge explosion of an #oil
pipeline belonging to @saudi_aramco
near sudair, #saudiarabia.
Figure 7: Evidential words highlighed by GCAN in
source tweet (upper) and suspicious users highlighed
by GCAN in retweet propagation (bottom), in which
each column is a user characteristic. Note that only few
user characteristics are presented.
dknews: conﬁrmed: #mike-brown had no criminal
record. #ferguson”). We highlight evidential words
with higher co-attention weights in font sizes of
word clouds, as exhibited in Figure 5. GCAN predicts the former to be fake with stronger attention
on words “breaking” and “strict”, and detects the
latter as real since it contains “conﬁrmed” and “irrelevant.” Such results may correspond to the common knowledge that fake news tends to use dramatic
and obscure words while real news is attended by
conﬁrmed and fact checking-related words.
Explainability on Retweet Propagation. We
aim to exploit the retweet order in propagations to
unfold the behavior difference between fake and
real news. We randomly pick three fake (F1-F3)
and three true (T1-T3) source stories, and plot their
weights from source-propagation co-attention (Section 4.5), as exhibited in Figure 6, in which the
horizontal direction from left to right denotes the
order of retweet. The results show that to determine
whether a story is fake, one should ﬁrst examine
the characteristics of users who early retweet the
source story. The evidences of fake news in terms
of user characteristics may be evenly distributed in
the propagation.
Explainability on Retweeter Characteristics.
The source-propagation co-attention of our GCAN
model can further provide an explanation to unveil
the traits of suspicious users and the words they
focus on. A case study is presented in Figure 7.
We can ﬁnd that the traits of suspicious users in
retweet propagation can be: accounts are not veriﬁed, shorter account creation time, shorter user
description length, and shorter graph path length
to the user who posts the source tweet. In addition,
what they highly attend are words “breaking” and
“pipeline.” We think such kind of explanation can
beneﬁt interpret the detection of fake news so as to
understand their potential stances.
Conclusion
In this study, we propose a novel fake news detection method, Graph-aware Co-Attention Networks (GCAN). GCAN is able to predict whether
a short-text tweet is fake, given the sequence of its
retweeters. The problem scenario is more realistic
and challenging than existing studies. Evaluation
results show the powerful effectiveness and the reasonable explainability of GCAN. Besides, GCAN
can also provide early detection of fake news with
satisfying performance. We believe GCAN can be
used for not only fake news detection, but also other
short-text classiﬁcation tasks on social media, such
as sentiment detection, hate speech detection, and
tweet popularity prediction. We will explore model
generalization in the future work. Besides, while
fake news usually targets at some events, we will
also extend GCAN to study how to remove eventspeciﬁc features to further boost the performance
and explainability.
Acknowledgments
This work is supported by Ministry of Science
and Technology (MOST) of Taiwan under grants
109-2636-E-006-017 (MOST Young Scholar Fellowship) and 108-2218-E-006-036, and also by
Academia Sinica under grant AS-TP-107-M05.