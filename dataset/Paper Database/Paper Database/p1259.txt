ORIGINAL ARTICLE
Coronavirus herd immunity optimizer (CHIO)
Mohammed Azmi Al-Betar1,2
• Zaid Abdi Alkareem Alyasseri3,4
• Mohammed A. Awadallah5
Iyad Abu Doush6,7
Received: 18 April 2020 / Accepted: 12 August 2020 / Published online: 27 August 2020
 Springer-Verlag London Ltd., part of Springer Nature 2020
In this paper, a new nature-inspired human-based optimization algorithm is proposed which is called coronavirus herd
immunity optimizer (CHIO). The inspiration of CHIO is originated from the herd immunity concept as a way to tackle
coronavirus pandemic (COVID-19). The speed of spreading coronavirus infection depends on how the infected individuals
directly contact with other society members. In order to protect other members of society from the disease, social distancing is
suggested by health experts. Herd immunity is a state the population reaches when most of the population is immune which
results in the prevention of disease transmission. These concepts are modeled in terms of optimization concepts. CHIO
mimics the herd immunity strategy as well as the social distancing concepts. Three types of individual cases are utilized for
herd immunity: susceptible, infected, and immuned. This is to determine how the newly generated solution updates its genes
with social distancing strategies. CHIO is evaluated using 23 well-known benchmark functions. Initially, the sensitivity of
CHIO to its parameters is studied. Thereafter, the comparative evaluation against seven state-of-the-art methods is conducted.
The comparative analysis veriﬁes that CHIO is able to yield very competitive results compared to those obtained by other
well-established methods. For more validations, three real-world engineering optimization problems extracted from IEEE-
CEC 2011 are used. Again, CHIO is proved to be efﬁcient. In conclusion, CHIO is a very powerful optimization algorithm
that can be used to tackle many optimization problems across a wide variety of optimization domains.
Keywords Coronavirus  COVID-19  Herd immunity  Optimization  Nature inspired  Metaheuristic
1 Introduction
Optimization is the process of ﬁnding the best conﬁgurations of some entities following limited resources respecting predeﬁned constraints . The optimization process
can be utilized in several research domains such as health,
engineering, mathematics, economics, linguistics, and science to optimize (minimize or maximize) their objective
 . In order to tackle optimization problems, two types of
optimization methods emerge deterministic-based and
& Mohammed Azmi Al-Betar
 
Zaid Abdi Alkareem Alyasseri
 
Mohammed A. Awadallah
 
Iyad Abu Doush
 
Department of Information Technology, Al-Huson University
College, Al-Balqa Applied University,
P.O. Box 50, Al-Huson, Irbid, Jordan
Department of Information Technology - MSAI, College of
Engineering and Information Technology Ajman University,
Ajman, UAE
Center for Artiﬁcial Intelligence, Faculty of Information
Science and Technology, Universiti Kebangsaan Malaysia,
43600 Bangi, Selangor, Malaysia
ECE Department, Faculty of Engineering, University of
Kufa, Najaf, Iraq
Department of Computer Science, Al-Aqsa University,
P. O. Box 4051, Gaza, Palestine
Computer Science Department, American University of
Kuwait, Salmiya, Kuwait
Computer Science Department, Yarmouk University, Irbid,
Neural Computing and Applications 33:5011–5042
 
(0123456789().,-volV)(0123456789().
approximation-based
Traditionally,
deterministicbased methods are utilized to tackle some optimization
problems with small dimensions and less complexity.
Although they can ﬁnd an exact solution for the optimization problem, they suffer from some dilemmas such as
they cannot be used to tackle the NP-hard problems; they
require heavy mathematical derivation, especially for gradient-based techniques; they can easily be stuck in a local
optima . Thus, they are inefﬁcient in tackling real-world
problems. Consequently, the optimization research communities tend their attentions to utilize approximation
methods for their optimization problems.
Approximation methods have stochastic components to
intelligently overcome the deterministic-based dilemmas.
traditional
approximation-based
heuristic-based in which the optimization problem is constructively tackled element by element until a complete
solution is reached . Heuristic methods are problemspeciﬁc where each optimization problem has its own
heuristic methods; for example, graph coloring problems
saturation
heuristic-based approaches although they can easily ﬁnd a
solution for the optimization problem, and the quality of
the constructed solution is not unfortunately respected. The
ultimate objective of tackling optimization problem is not
only to ﬁnd any solution, but also to ﬁnd a ‘‘good enough’’
solution. Therefore, the emergence of metaheuristic algorithms
approximation-based
acquired high attention due to its superior advantages.
Metaheuristic-based approaches provide a general optimization framework that can iteratively improve the current solution(s) using intelligent knowledge-acquisition
operators with stochastic features controlled by tuned
parameters until an optimal solution is reached . The
operators of the powerful metaheuristic algorithms can
efﬁciently explore several regions in the problem search
space as well as exploit the accumulative knowledge
acquired during the search process. Exploitation and
exploration are contradictory, and achieving the right
balance between them during the search is the main
algorithmic challenge. The main advantages of these
metaheuristic algorithms are : (1) Their simplicity is
adapted for a wide range of optimization problems with
very small tweaking. They are dealt with the optimization problem as black-box mathematically formulated in
terms of objective function and solution representation in
which the problem-speciﬁc knowledge is not necessarily
deeply studied. (2) They do not require mathematicalderivative information in the initial search. (3) They can
easily escape the local optima using their stochasticbased components. Interestingly, the most metaheuristicbased algorithms are originated from
nature-inspired
phenomena which can be categorized into four classes:
evolutionary-based,
swarm-based,
physical-based,
human-based algorithms . These categories of
metaheuristic-based
algorithms
summarized
Evolutionary algorithms (EA) are naturally inspired
from the evolution process initiated with a population of
random individuals. Generation after generation, the gens
of the parent individuals in the population are recombined
and mutated to come up with offspring individuals which
are adopted based on the survival-of-the-ﬁttest principle in
the natural selection scheme. The ﬁrst developed EA is
genetic algorithm (GA) proposed by John Henry Holland in
1960 to utilize the Darwinian principle of natural evolution
 . Swarm-based algorithms are normally inspired by the
social behavior of animal swarms. The main merit of such
class is their ability to collaboratively survive. The earlier
and considered ﬁrst swarm-based algorithms are particle
swarm optimization (PSO) which imitates the bird
ﬂocking social behavior. The particles (solutions) ﬂy
around their environment (search space) searching for the
optimal position (global best). During the ﬂying process,
the best positions (local best) in the path to the optimal
position are recorded. Other base swarm-based optimizer is
ant colony optimization (ACO) , artiﬁcial bee colony
(ABC) , and many others summarized in Table 1.
Physical-based algorithms are inspired by the physical laws
appeared in the universe. The base algorithm of such category is simulated annealing (SA) which imitates thermodynamics process when the metals are cooled and annealed
 . Other physical-based algorithms are summarized in
Table 1. Finally, human-based algorithm stimulates the
human’s behavior, lifestyle, or perception. The base
method of such class is harmony search algorithm (HSA)
in which a group of JAZZ musicians plays the notes of
their instruments, practice after practice until a pleasing
harmony (optimal solution) is obtained . Other popular
human-based algorithms are ﬁreworks algorithm (FA) 
and many others as reported in Table 1.
Apparently, there are a plethora of nature-inspired
algorithms which can be efﬁciently used for a wide range
of optimization problems. However, according to the No
Free Lunch (NFL) theorem, the optimization algorithm
cannot work efﬁciently for all types of optimization problems
Furthermore,
deterministic
heuristic optimization is not workable for problems with
nonlinearity and multimodality. Therefore, the tremendous
developments of metaheuristic algorithms, although come
up with very powerful algorithms, there is still a window to
develop other nature-based metaheuristic algorithms with
intelligence characteristics with hope to tackle some
complex optimization problems powerfully.
Nowadays, human-based nature-inspired phenomenon
is emerged with as algorithms such as HSA or bHC
Neural Computing and Applications 33:5011–5042
achieve pleasing results when compared to other natureinspired algorithms. This paper proposed a new humanbased nature-inspired algorithm coronavirus herd immunity
optimizer (CHIO). Quite recently, the novel 2019 coronavirus evolved and start to spread from Wuhan, China,
since December 2019. Consequently, the virus spread
across several countries and the World Health Organization
(WHO) announces the name of the new contagious disease
to be Coronavirus Disease (COVID-19) .
There are several differences between COVID-19 and
inﬂuenza such as transmission speed, mortality rate, and
reproductive number . The mortality rate higher than
inﬂuenza 3–4%; the reproductive number is higher with
2–2.5; the transmission speed is faster 3–5 days .
Herd immunity is proposed as one of the techniques to
control the COVID19 epidemic outbreak . The proposed algorithm relies on the concept of how to best protect
the community against the disease by converting the
majority of the susceptible population which is not infected
to become immuned. The phases of herd immunity can be
summarized as follows ﬁrst, a group of infected
people will infect another group of people. Second, a large
number of infected people will recover and become
immuned and a small number of people will die. Finally,
after some time the majority of the population will become
protected against the virus.
Recent research conﬁrms the impact of herd immunity
on the spread of COVID-19 as neutralizing antibodies are
detected at many individuals . Another researcher
recommended that herd immunity is a plausible strategy
against COVID-19 .
CHIO is modeled for continuous optimization. Initially, the population individuals are randomly generated
and marked as susceptible, and very few members are
marked infected. According to the basic reproduction
rate (BRr), the herd immunity of the population is
evolved using three rules of spreading the pandemic
following social distancing concepts: susceptible, infected, and immuned cases rules. The population members
are moved from susceptible to infected and from infected
to immuned according to herd immunity threshold by
survival-of-the-ﬁttest
principle.
numbers of infected individuals will reach the fatality
state. The search is stopped when the population reaches
the state of herd immunity. In order to verify the efﬁciency of CHIO, 23 well-known benchmark functions are
used for evaluation. The effect of parameters on CHIO
performance is initially studied. Then, alternative social
distancing strategies are analyzed. Finally, the comparative evaluation against seven well-regarded methods is
provided. The comparative results prove the viability of
the proposed CHIO. For more validations, three realworld engineering optimization problems extracted from
IEEE-CEC 2011 are used. Again, CHIO is proved to be
efﬁcient. In a nutshell, the new CHIO is a very powerful
human-based optimization method that is pregnant with
tremendous and successful developments for those who
are interested to tackle their problems using natural-inspired metaheuristic-based algorithms.
The remaining sections of this paper are as follows:
The proposed CHIO algorithm and the concepts behind it
are introduced in Sect. 2. The performance of the proposed algorithm is evaluated and analyzed in Sect. 3.
Finally, the conclusion and some future directions are
provided in Sect. 4.
Table 1 Nurtured-inspired optimization algorithms
Nurtured-inspired
categories
Nurtured-inspired algorithms
Evaluation-based
Genetic algorithm (GA) , evolution strategy (ES) , genetic programming (GP) , and biogeography-based
optimizer (BBO) 
Swarm-based
Particle swarm optimization (PSO) , ant colony optimization (ACO) , cuckoo search (CS) , bat algorithm
(BA) , ant lion optimizer (ALO) , butterﬂy optimization algorithm (BOA) , dragonﬂy algorithm (DA)
 , fruit ﬂy optimization algorithm (FOA) , grey wolf optimizer (GWO) , krill herd algorithm (KHA) ,
red deer algorithm (RDA) , bird mating optimizer (BMO) , ﬂower pollination algorithm (FPA) , monarch
butterﬂy optimization (MBO) , moth-ﬂame optimization algorithm (MFO) , whale optimization algorithm
(WOA) , ﬁreﬂy algorithm (FA) , artiﬁcial bee colony (ABC) , salp swarm algorithm (SSA) , Harris
hawks optimization (HHO) , and crow search algorithm (CSA) 
Physical-based
Simulated annealing (SA) , multi-verse optimizer (MVO) , sine cosine algorithm (SCA) , water cycle
algorithm (WCA) , electromagnetism-like mechanism (EM) , gravitational search algorithm (GSA) ,
charged system search (CSS) , big bang–big crunch (BBBC) , and Henry gas solubility optimization (HGSO)
Human-Based
Fireworks algorithm (FA) , harmony search algorithm (HSA) , wisdom of artiﬁcial crowds (WAC) , b-hill
climbing (bHC) , Tabu search (TS) , group search optimizer (GSO) , interior search algorithm (ISA)
 , seeker optimization algorithm , social-based algorithm (SBA) , and mine blast algorithm (MBA) 
Neural Computing and Applications 33:5011–5042
2 Coronavirus herd immunity optimizer
Viruses are normally spread and evolved very quickly
among individuals of the population. The health communities normally use a vaccine to build immunity against
viruses. However, new viruses need a period of time until
their vaccine discovered. In the meanwhile, the health care
organizations recommend to treat the virus in one of two
ways: i) They isolate the infected individuals from their
surrounding communities and isolate all the people they
contact. ii) They use herd immunity principle to stop
pandemics where herd immunity accrued when a signiﬁcant portion of a population is immune resulting in protecting susceptible individuals.
2.1 Inspiration
Viruses can be transmitted biologically and it can be
replicated by the amplifying hosts . The novel 2019
coronavirus evolved and start to spread from
Wuhan, China, since December 2019. Consequently, the
virus spread across several countries and the World Health
Organization (WHO) announces the name of the new
contagious disease to be Coronavirus Disease (COVID-19)
 . As of March 27, 2020, the number of cases reaches
532,279 in 199 countries and territories around the world1.
The incubation period of the COVID-19 varies between
2.1 and 11.1 days . As to yet, no powerful remedy for
COVID-19 is found . The fatality rate of COVID-19
can range between 0.25 and 3.0% .
Herd immunity means that the population has a large
number of people that are protected from being infected
(either by vaccination or natural infection) and as a result,
the disease will stop from spreading. This happened
because more than 60% (i.e., herd immunity threshold) of
the population is recovered from the infection. Herd
immunity can affect the epidemic transmission as it can
downsize the spread of the infection . Herd immunity is
proposed as one of the techniques to control the COVID-19
epidemic outbreak . Note that this approach applies the
Darwinian theory about survival-of-the-ﬁttest principle.
According to the social distancing, the COVID-19 can
be transmitted from human to human if the person is in
close contact to another person (within 1.8 meters), by the
droplets originated when the infected person sneezes or
coughs, or when the person touches his/her mouth, nose, or
eyes after contacting a surface or object that has the virus
on it2. The governments followed two approaches to control the spread of COVID-19 as still there is no vaccination
available the in country lockdown or herd immunity3.
A normal person that is not immuned against the virus is
called susceptible. Once infected with the COVID-19, the
person becomes a transmitting case. Now, based on the
strength of the person’s immune system, s/he can be either
recovered (i.e., immuned) or unfortunately dead. Generally
speaking, the elderly immune system is usually weaker
than young people because they would have other diseases
such as diabetes, cardiovascular diseases, or cancer. As a
result, the person’s age plays an important role in being
recovered or not. The average age of the people who are
died in Italy is 81 years .
According to many researchers , the main phases
of achieving herd immunity are as follows:
A large number of infected people infect another large
group of people.
Most of the infected people are recovered, and a small
number are dead.
After a while, most of the population will have
immunity against the disease.
2.2 Herd immunity
Herd immunity refers to a situation where enough people in
a population have immunity to the infection to be able to
effectively stop that disease from spreading. For herd
immunity, it does not matter whether the immunity comes
from vaccination, or from the people who had the disease.
The crucial thing is that they are immune.
As more people become infected with COVID-19, the
disease caused by the virus, there will be more people who
recover and who are then immune to future infection.
Herd immunity is affected by the basic reproduction
rate, which represents how many people will be probably
infected from the transmitting cases. This can indicate how
quickly the disease will spread in the population. Generally
speaking, when the number of immune cases reaches to be
a large percentage of the population (i.e., larger than 60%)
the population will be shielded from having more infected
cases, and such percentage is called herd immunity
threshold.
The transmitting cases pass the infection, and the
immune system of the infected person will preserve an
immunological memory of the disease. This will enable the
infected person to become immune against that virus in the
future, and thus, it will stop the disease from circulation.
The coronavirus herd immunity concept is mathematically modeled to develop the proposed optimization algorithm. The algorithm relies on the concept of how to best
1 
2 
3 
minathan-aiyar/articleshow/74860557.cms
Neural Computing and Applications 33:5011–5042
protect the community against the disease by converting
the majority of the susceptible population which is not
infected to become immuned. As a result, even the
remaining susceptible cases will not be infected because
the immuned population will not be transmitting the disease anymore.
2.3 Population hierarchy
The herd immunity population individuals can be classiﬁed
into three types : susceptible, infected (or conﬁrmed),
and immuned (or recovered) individuals . Figure 2
shows how the three types of individuals are distributed.
The ﬁgure is represented as a tree where the root is the
infected individual and the edges point to the contacted
people. The right part of the ﬁgure shows that if the root
individual is immuned, the virus will not be spread to its
contacted individual. Therefore, it is functionally utilized
as a ﬁrewall against virus pandemics. These types of
individuals can be deﬁned as follows:
susceptible
individuals
individuals
infected by the virus, but it can be infected when they
contact other infected individuals (i.e., did not follow
the recommended social distancing).
infected individuals The individuals of this type have a
conﬁrmed case where they can transmit the virus to
other susceptible individuals who are in direct contact
with according to the social distancing factor.
immuned individuals The individuals who are categorized as immuned are protected against the virus, and
they are not affected by infected individuals. This type
of individual can help the population to stop spreading
the pandemic as can be shown in Fig. 1.
In order to represent the hierarchy of population when the
CHIO is designed in terms of optimization context, the
susceptible individuals take a large portion from the population. The second portion of the population is marked as
infected individuals which are initiated by a small number
which represent the ﬁrst infected individuals appeared in
the population, and this portion of the population grows up
if they did not follow the recommendation of social distancing
individuals are
immuned (i.e., recovered) or dead. The last portion of the
population is the immuned individuals which are initiated
by null and grow up according to how many are the
recovered cases in the population. In the last course of the
run, the majority of individuals are immuned, and therefore, the pandemic is stopped. In CHIO, the improvement
process is derived by susceptible, infected, and immuned
individuals as shown in CHIO procedure section below.
2.4 Social distancing
The concept of social distancing is used in the case of virus
pandemics as a strategy to reduce the spreading of infections . Normally, the governments and health care
institutions suggest such action to advise individuals to
Fig. 1 Herd immunity
Neural Computing and Applications 33:5011–5042
keep a space of 2 meters (6.5 feet) between each other
when going to crowded places . Some other precautionary actions can avoid crowded places such as malls,
schools, and universities.
The effect of social distancing is shown in Fig. 3. The
spread of the disease would decline which can ultimately
result in the outbreak of the pandemic. The transmission
chains of the virus will be broken and would result in
slowing down the spread of the disease and reaching the
pandemic peak with a smaller number of infected cases
 . Therefore, the country’s health care system would be
able to continue to serve a smaller number of infected
The two normal distribution charts presented in Fig. 3
show the effect of social distancing in controlling the
spread of the pandemic. Apparently, the social distancing
would distribute the infected cases on a longer period of
time which reduces the unmet need region (i.e., the health
care services are not satisfactory).
In CHIO, the social distancing concept is achieved
through taking the difference between the current individual and a selected individual from the population which
might be susceptible, infected, or immuned.
2.5 Herd immunity real cases
The concept of using a controlled herd immunity to contain
COVID-19 is used by some countries 33:5011–5042
practice social distancing . The Swedish herd immunity
takes longer than expected . This is presented in Fig. 4
as it shows the number of conﬁrmed cases and deaths in
Sweden from February to May 2020. As of June 28, 2020,
Sweden have 65,137 conﬁrmed cases and 5,280 deaths
Some countries (e.g., UK) allow the spread of the virus
to increase the population herd immunity while protecting
the elderly because they are the most vulnerable to this
virus . The UK government recommended using herd
immunity to contain COVID-19 . Figure 4 shows the
decrease in the number of conﬁrmed cases, and the number
of deaths over time in the UK from February to May 2020.
As of June 28, 2020, the UK have 310,254 conﬁrmed cases
and 43,514 deaths .
2.6 CHIO procedure
Herd immunity strategy is modeled in the proposed optimization algorithm. The concepts of COVID-19 are mapped to the optimization context in Table 2, and the CHIO is
represented as a set of steps which thoroughly discussed
below. The ﬂowchart of CHIO algorithm is illustrated in
Fig. 5 while CHIO is pseudocoded in Algorithm 1. The
algorithm has six main steps discussed as follows:
Step 1 Initialize parameters of CHIO and optimization
problem In this step, the optimization problem is
formulated in the context of objective function as
Fig. 4 COVID-19 conﬁrmed and death cases in the UK and Sweden
Table 2 Bridge between
COVID-19 and optimization
COVID-19 context
Optimization context
(infected, susceptible, immuned) Case
Social distancing
Pick random case and rely on the basic reproduction rate
Mortality rate
Reaching maximum age
Reproductive number
Basic reproduction rate
Transmission speed
Basic reproduction rate
Immunity rate
Fitness value
Possibility of infection
Weak ﬁtness value and inherit COVID-19 features
Fig. 5 Flowchart of CHIO algorithm
Neural Computing and Applications 33:5011–5042
x 2 ½lb; ub
where fðxÞ is the objective function (or immunity rate)
calculated
individual)
ðx1; x2; . . .; xnÞ where xi is the gene (or the decision
variable) indexed by i and n is the total number of genes
in each individual. Note that the value range of each
gene xi 2 ½lbi; ubi where lbi and ubi represent the lower
and upper bounds of gene xi.
CHIO has four algorithmic parameters and two control parameters. The four algorithmic parameters are
C0: which represents the number of initial infected
cases where it is here initiated by one.
iterations.
HIS: which is the population size.
n: which is the problem dimensionality.
The CHIO has two main control parameters to be initialized in this step:
Basic reproduction rate (BRr) which controls the
CHIO operators through spreading the virus pandemic between individuals.
Maximum infected cases age (MaxAge): It determines
the status of the infected cases where cases that reach
MaxAge is either recovered or died.
Step 2 Generate herd immunity population Initially,
CHIO randomly (or heuristically) generates a set of cases
(individuals) as many as HIS. The generated cases are
stored as two-dimensional matrix of size n  HIS in herd
immunity population (HIP) as follows:
where each row j represents a case xj, which is basically
generated as follows:x j
i ¼ lbi þ ðubi  lbiÞ  Uð0; 1Þ,
8i ¼ 1; 2; . . .; n. The objective function (or immunity
rate) for each case is calculated using equation (1).
Furthermore, the status vector (S) of length HIS for all
cases in HIP is also initiated by either zero (susceptible
case) or one (infected case). Note that the number of
ones in (S) is randomly initiated as many as C0.
Step 3 Coronavirus herd immunity evolution This is the
main improvement loop of CHIO. The gene (xj
i) of case
xj is either remain the same or affected by social
distancing using three rules according to the percentage
of the BRr as follows:
3BRr: //infected case
3BRr: //susceptible case
//immuned case
where r generates a random number between 0 and 1.
The three rules can be discussed as follows:
Infected case: Within the range of r 2 ½0; 1
3 BRrÞ, the
new gene value of xj
iðt þ 1Þ is affected by some social
distancing
difference
between current gene and a gene taken from an
infected case xm such as
iðt þ 1Þ ¼ Cðxj
iðtÞÞ ¼ xj
iðtÞ þ r  ðxj
Note that the value xc
i ðtÞ is randomly chosen from any
infected case xc based on the status vector (S) such
that c ¼ fijSi ¼ 1g
Susceptible
3 BRrÞ, the new gene value of xj
iðt þ 1Þ is
affected by some social distancing which is achieved
by the difference between the current gene and a gene
taken from a susceptible case xm such as
iðt þ 1Þ ¼ Nðxj
iðtÞÞ ¼ xj
iðtÞ þ r  ðxj
Note that the value xm
i ðtÞ is randomly spread from any
susceptible case xm based on the status vector (S) such
that m ¼ fijSi ¼ 0g.
Immuned case:Within the range of r 2 ½2
3 BRr; BRrÞ,
the new gene value of xj
iðt þ 1Þ is affected by some
social distancing which is achieved by the difference
between the current gene and a gene taken from an
Neural Computing and Applications 33:5011–5042
immuned case xv such as
iðt þ 1Þ ¼ Rðxj
iðtÞÞ ¼ xj
iðtÞ þ r  ðxj
Note that the value xv
i ðtÞ is spread from the best
immuned case xv based on the status vector (S) such
fðxvÞ ¼ arg
js fkjSk¼2g fðxjÞ:
Step 4 Update herd immunity population The immunity
rate fðxjðt þ 1ÞÞ of each generated case xjðt þ 1Þ is
calculated and the current case xjðtÞ is replaced by the
xjðt þ 1Þ,
fðxjðt þ 1ÞÞ\fðxjðtÞÞ.
increased by one if Sj ¼ 1.
The status vector (Sj) is updated for each case xj
based on the herd immune threshold which utilizes the
following equation:
fðxjðt þ 1ÞÞ\ fðxÞjðt þ 1Þ
^ Sj ¼ 0 ^ is Coronaðxjðt þ 1ÞÞ
fðxjðt þ 1ÞÞ [ fðxÞjðt þ 1Þ
where iscoronaðxjðt þ 1ÞÞ is a binary value equal to one
when the new case xjðt þ 1Þ inherited a value from any
infected case. The MfðxÞ is the mean value of the population immune rates such as
. Note that the
individuals’ immunity rate in the population will be
changed based on the social distancing calculated before,
if the newly generated individual immunity rate is better
than the average immunity rate of the population. This
means that we are starting to have a better-immuned
population. If the newly generated population is strong
enough to be immuned against the pandemic, then we
reach the herd immunity threshold.
Step 5 Fatality cases In case the immunity rate
(fðxjðt þ 1Þ) of the current infected case (Sj == 1) could
not improve for a certain number of iterations as
speciﬁed by the parameter Max Age (i.e., Aj
Max Age), then this case is considered died. After that,
regenerated
lbi þ ðubi  lbiÞ  Uð0; 1Þ,
8i ¼ 1; 2; . . .; n. Furthermore, Aj and Sj are set to zero. This can be useful to
diversify the current population and thus escaping local
Step 6 Stop criterion CHIO repeats Step 3 to step 6 until
the termination criterion which normally depends if the
maximum number of iteration is reached. In this case,
the total number of susceptible and immuned cases
dominate the population. The infected cases are also
disappeared.
3 Experiments and results
In this section, the proposed CHIO algorithm is evaluated
from various aspects by using a set of experiments conducted on 23 test functions. These test functions are circulated widely to evaluate newly established methods. The
characteristics of these test functions are provided in Sect.
3.1. The experimental scenarios that are designed to study
the behavior of CHIO algorithm are summarized in Sect
3.2. The sensitivity of CHIO to its control parameters:
spreading rate (Sr) and maximum age of conﬁrmed cases
(MaxAge) are illustrated in Sects. 3.3 and 3.4, respectively.
Neural Computing and Applications 33:5011–5042
Table 3 Characteristics of 23 test functions. (n: dimension, U: unimodal, M: multimodal)
Test Functions
Schwefel’s problem 2.22
i¼1 jxij? Qn
Schwefel’s problem 1.2
Schwefel’s problem 2.21
maxi jxij; 1  i  n
Rosenbrock
i¼1 100 xiþ1  x2
2þ xi  1
i¼1 xi þ 0:5
i þ random½0; 1Þ
Generalized Schwefel’s
i¼1 xi sin
i  10 cos 2pxi
5.12,5.12]
20 expð0:2
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
i¼1 cos 2pxi
Generalized Penalized
Function 1
10 sin py1
i¼1 ðyi  1Þ2
1 þ 10 sin2ðpyiþ1Þ
þ ðyn  1Þ2g þ Pn
i¼1 uðxi; 10; 100; 4Þ yi ¼ 1 þ
4 uðxi; a; k; mÞ ¼
kðxi  aÞm
kðxi  aÞm
Generalized Penalized
Function 2
0:1 sin2ð3px1Þ þ Pn
i¼1 xi  1
Þ2 1 þ sin2ð3pxi þ 1Þ
þðxn  1Þ2 1 þ sin2ð2pxnÞ
i¼1 uðxi; 5; 100; 4Þ
Shekel’s Foxholes function
i¼1 xiaij
Kowalik’s function
i þbix3þx4
Six-hump camel back
1 þ x1x2  4x2
2þ10 1  1
cos x1 þ 10
Goldstein-Price function
1 þ x1 þ x2 þ 1
Þ2 19  14x1 þ 3x2
14x2 þ 6x1x2 þ 3x2
 30 þ 2x1  3x2
Þ2 18  32x1 þ 12x2
þ48x2  36x1x2 þ 27x2
i¼1 ci exp  P3
j¼1 aij xj  pij
Neural Computing and Applications 33:5011–5042
Thereafter, the effect of the social distancing strategies on
the convergence behavior of the herd immunity evolution
is analyzed in Sect. 3.5. Finally, the comparative evaluation
against the state-of-the-art algorithms is discussed in Sect.
3.1 Test functions
In order to evaluate the performance of the proposed
CHIO, 23 common test functions are considered. All of
these test functions are minimization problems, which are
different in size and complexity. Table 3 provides the main
characteristics of test functions used which includes the
functions names, the test function key, the mathematical
formulation of each test function, the rang which determines the boundary of the search space, the function
dimensions (n), and the optimum solution fðxÞ. The category of each test function is also provided: unimodal
(U) and multimodal (M). It should be noted that the unimodal test functions have a single optimum, while the
multimodal test functions have more than one optimum.
The unimodal test functions are used to evaluate the
exploitation ability of the optimization algorithms, while
the multimodal test functions are used to evaluate the
exploration ability of the optimization algorithms . As
shown in Table 3, F1 – F7 are categorized as unimodal test
functions, while F8 – F23 are categorized as multimodal
test functions. Furthermore, The dimensions of the test
functions F14 – F23 are ﬁxed.
Figure 6 shows the 2D search space for each benchmark
function and the convergence behavior of CHIO of the ﬁrst
solution in the ﬁrst dimension for each benchmark
3.2 Experimental settings
The evaluations of the CHIO performance are tested and
analyzed using different convergence scenarios. The sensitivity of CHIO to its two control parameters (i.e., BRr and
MaxAge) is studied as shown in Table 4: Sen1–Sen8. The
convergence scenarios are conducted based on ad hoc
strategy where the ﬁrst set of scenarios study one operator
and the remaining operators are remaining constant.
The effect of basic reproduction rate (BRr) on the convergence
(BRr ¼ 0:005, BRr ¼ 0:05, BRr ¼ 0:01, and BRr ¼ 0:5)
from Sen1 to Sen4. Note that BRr determines the percentage of the population affected by the coronavirus
pandemic. The smaller the value is, the slower the coronavirus spreading will be.
The effect of the maximum infected age (MaxAge) on the
convergence of CHIO is studied using four numbers
Table 3 (continued)
Test Functions
i¼1 ci exp  P6
j¼1 aij xj  pij
i¼1 ðX  aiÞ X  ai
i¼1 ðX  aiÞ X  ai
i¼1 ðX  aiÞ X  ai
Neural Computing and Applications 33:5011–5042
Fig. 6 Functions and
convergence plots
Neural Computing and Applications 33:5011–5042
(MaxAge ¼ 50,
MaxAge ¼ 100,
MaxAge ¼ 300,
MaxAge ¼ 500) from Sen5 to Sen8. As remembering, the
MaxAge is the maximum number of iterations where the
infected solution remains unimproved. Therefore, a new
solution is constructed from scratch to replace the discarded solution.
The last four convergence scenarios (i.e., Sen9 –
Sen12) are designed to study the social distancing strategy. Recall, the social distancing in herd immunity evolution step has three main rules for infection: susceptible,
infected, and immuned. The ﬁrst two rules update the
generated solution based on the difference between the
current solution and a randomly selected solution. The last
rule updates the generated solution based on the difference between the current solution and the best solution.
Sen9 – Sen12 study four possible combinations of social
distancing strategies: random–random–random, random–
random–best, random–best–random, and random–best–
Note that CHIO replicates 30 runs for each experimental
scenario, the herd immunity size (HIS) used is 30, and the
maximum number of iteration (i.e., Maxitr) is equal to
100,000. The results are statistically recorded in terms of
best, mean, worst, and standard deviation for all designed
scenarios.
3.3 Effect of the basic reproduction rate (BRr)
The effect of the basic reproduction rate (BRr) on the
performance of CHIO using various values of BRr (i.e.,
BRr ¼ 0:005, BRr ¼ 0:05, BRr ¼ 0:1, and BRr ¼ 0:5) has
been studied here. The value of the parameter BRr determines the speed of spreading the coronavirus pandemic
across the population. A higher value of BRr leads to a
higher rate of spreading the disease and thus the exploration becomes large. The results recorded in Table 5
summarize the best, worst, mean, and standard deviation
(Stdev.) of the 23 test functions over 30 replicated runs.
As can be noticed, CHIO in Sen2 can achieve the most
best mean results. This is because a larger value of BRr
increases the exploration, and thus, the search will require
longer time to converge. On the other hand, when the value
of BRr ¼ 0:001, the exploration source of the generated
individuals is not that much, and thus, fast convergence
will be occurred.
As remembering, the ﬁrst seven benchmark functions
are unimodal and they have higher complexity to be solved
due to their ruggedness in the search space. Sen2 can
outperform other three scenarios in ﬁve out of seven
benchmark functions. The next six benchmark functions
(F8–F13) are multimodal, and their dimensions are ﬂexible. The search space of this type of benchmark functions
is not that complex in comparison with unimodal benchmark functions. Interestingly, Sen2 can excel all other
designed scenarios for all multimodal ﬂexible dimensions
benchmark functions. The search space of the last ten
multimodal
dimensions is the simplest where Sen2 can outperform the
other three scenarios in eight of ten benchmark functions.
Apparently,
BRr ¼ 0:01
represented
empower the convergence behavior of CHIO to achieve the
right balance between the exploration and exploitation of
the search space and thus the best performance. Therefore,
the value of BRr ¼ 0:01 will be used in the experiments of
the upcoming designed scenarios.
3.4 Effect of MaxAge
The effect of the maximum age of the infected cases
(MaxAge) on the performance of CHIO using various values
(MaxAge ¼ 50,
MaxAge ¼ 100,
MaxAge ¼ 300,
MaxAge ¼ 500) is investigated in this subsection. The value
Table 4 Twelve experimental
scenarios designed to evaluate
the sensitivity of the proposed
CHIO to its parameters
susceptible
Sen6 = Sen 2
Sen10 = Sen 6
Neural Computing and Applications 33:5011–5042
Table 5 Performance of CHIO algorithm using different settings of BRr
1.1915E-73
0.0000E100
0.0000E100
0.0000E100
9.3388E-02
2.1364E-16
2.0496E-04
5.3245E?03
1.7232E-02
7.1578E218
6.9120E-06
1.7251E?03
1.7232E-02
3.8999E-17
3.7407E-05
1.4528E?03
1.6108E-35
3.6009E2179
5.9705E-27
7.2303E-14
7.1296E?02
2.2255E-09
3.2453E-03
1.5847E?01
2.8919E?01
1.0336E210
1.1464E-04
6.6956E?00
1.3216E?02
4.1628E-10
5.9190E-04
5.2267E?00
1.5125E?03
6.8219E-01
2.7157E-04
6.8886E212
6.5132E?03
1.4758E?02
1.1900E?02
4.1768E?03
3.3855E?03
5.3496E?01
3.8246E101
5.3926E?02
1.1490E?03
4.1604E?01
3.6283E?01
1.1309E?03
2.0556E-01
1.4323E-14
1.7012E-20
4.1184E229
6.5107E?01
8.6072E-02
1.7094E-01
2.6488E?01
5.7485E?00
1.2869E202
3.6961E-02
5.0840E?00
1.5723E?01
2.0007E-02
5.3978E-02
7.1575E?00
6.5458E-04
2.0602E204
5.4126E-03
2.3175E?01
9.6098E?01
1.2583E?00
1.8537E?01
1.1408E?06
1.5704E?01
3.0925E201
3.5249E?00
1.4873E?05
2.4355E?01
4.4332E-01
4.5043E?00
2.7048E?05
0.0000E100
0.0000E100
0.0000E100
1.2089E-03
5.3341E-02
2.1121E-03
4.3919E-05
5.8506E?03
1.7786E-03
7.0403E-05
1.4664E206
1.2989E?03
9.7386E-03
3.8561E-04
8.0180E-06
1.3499E?03
1.8090E-02
2.2048E-03
2.4062E-03
8.4391E204
5.7765E-02
7.5511E-03
8.9773E-03
1.5651E?00
3.2510E-02
4.5852E203
5.4953E-03
3.1551E-01
9.9587E-03
1.3483E-03
1.6943E-03
4.0446E-01
2 1.2569E104
2 1.2569E104
2 1.2569E104
2 1.2569E104
- 1.2451E?04
- 1.2569E?04
- 1.1401E?04
- 8.5119E?03
- 1.2565E?04
2 1.2569E104
- 1.2357E?04
- 1.1176E?04
2.1538E?01
0.0000E?00
3.4241E?02
9.5714E?02
0.0000E100
0.0000E100
0.0000E100
2.1068E-06
1.3049E-04
2.1364E-16
2.9849E?00
1.0683E?02
4.3838E-06
7.1578E218
4.6432E-01
2.8554E?01
2.3818E-05
3.8999E-17
8.5604E-01
2.7109E?01
2.2204E-14
1.5099E214
1.5099E214
6.6650E-05
3.6980E-02
2.9142E-04
9.3130E-01
1.4479E?01
1.2502E-03
1.0244E205
3.1072E-02
5.3867E?00
6.7487E-03
5.3185E-05
1.7003E-01
3.4723E?00
0.0000E100
0.0000E100
0.0000E100
5.3118E-01
5.9121E-02
1.1316E-05
3.6524E-02
4.9415E?01
3.2896E-03
4.4131E207
1.8787E-03
1.5387E?01
1.1039E-02
2.0830E-06
7.4673E-03
1.1417E?01
1.5705E232
1.5705E232
1.5705E232
1.5786E-32
3.6124E-05
1.0144E-15
2.0264E-12
2.7489E?03
2.5452E-06
3.3819E217
6.9156E-14
2.1803E?02
7.4542E-06
1.8520E-16
3.6972E-13
6.5459E?02
Neural Computing and Applications 33:5011–5042
Table 5 (continued)
1.3498E232
1.3498E232
1.3498E232
1.7920E-30
3.1017E-02
8.9261E-29
9.0058E-03
1.5117E?06
1.3740E-03
2.9886E230
3.0019E-04
9.5468E?04
5.7660E-03
1.6294E-29
1.6442E-03
2.9145E?05
9.9800E201
9.9800E201
9.9800E201
9.9800E201
9.9800E-01
9.9800E-01
9.9800E-01
9.9800E-01
9.9800E201
9.9800E201
9.9800E201
9.9800E201
0.0000E?00
0.0000E?00
0.0000E?00
0.0000E?00
5.5859E-04
3.1027E-04
3.1755E-04
3.0749E204
1.0558E-03
7.4299E-04
6.1261E-04
7.2917E-04
7.4781E-04
4.8287E-04
4.2580E-04
3.6978E204
1.0901E-04
1.1762E-04
8.8041E-05
1.0701E-04
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
0.0000E?00
0.0000E?00
0.0000E?00
0.0000E?00
3.9789E201
3.9789E201
3.9789E201
3.9789E201
3.9789E-01
3.9789E-01
3.9789E-01
3.9789E-01
3.9789E201
3.9789E201
3.9789E201
3.9789E201
0.0000E?00
0.0000E?00
0.0000E?00
0.0000E?00
3.0000E100
3.0000E100
3.0000E100
3.0000E100
3.0031E?00
3.0000E?00
3.0000E?00
3.0000E?00
3.0006E?00
3.0000E100
3.0000E100
3.0000E100
7.3438E-04
0.0000E?00
0.0000E?00
0.0000E?00
2 3.8628E100
2 3.8628E100
2 3.8628E100
2 3.8628E100
- 3.8628E?00
- 3.8628E?00
- 3.8628E?00
- 3.8628E?00
2 3.8628E100
2 3.8628E100
2 3.8628E100
2 3.8628E100
0.0000E?00
0.0000E?00
0.0000E?00
0.0000E?00
2 3.3220E100
2 3.3220E100
2 3.3220E100
2 3.3220E100
- 3.2584E?00
- 3.3220E?00
- 3.3220E?00
- 3.3220E?00
- 3.3150E?00
2 3.3220E100
2 3.3220E100
2 3.3220E100
1.8824E-02
0.0000E?00
0.0000E?00
0.0000E?00
2 1.0153E101
2 1.0153E101
2 1.0153E101
2 1.0153E101
- 7.8455E?00
- 1.0153E?01
- 1.0153E?01
- 1.0153E?01
- 9.6105E?00
2 1.0153E101
2 1.0153E101
2 1.0153E101
8.4268E-01
0.0000E?00
0.0000E?00
0.0000E?00
2 1.0403E101
2 1.0403E101
2 1.0403E101
2 1.0403E101
- 6.3599E?00
- 1.0403E?01
- 1.0403E?01
- 1.0403E?01
- 9.4503E?00
2 1.0403E101
2 1.0403E101
2 1.0403E101
1.2046E?00
0.0000E100
0.0000E100
0.0000E100
- 1.0536E?01
- 1.0536E?01
- 1.0536E?01
- 1.0536E?01
- 7.3257E?00
- 1.0536E?01
- 1.0536E?01
- 1.0536E?01
- 9.6771E?00
2 1.0536E101
2 1.0536E101
2 1.0536E101
9.9204E-01
0.0000E?00
0.0000E?00
0.0000E?00
Bold font refers to the best recorded result
Neural Computing and Applications 33:5011–5042
Table 6 Performance of CHIO algorithm using different settings of MaxAge
0.0000E100
0.0000E100
0.0000E100
0.0000E100
7.2289E-18
2.1364E-16
3.2278E-05
5.1485E?00
2.4096E219
7.1578E-18
1.4947E-06
1.7162E-01
1.3198E-18
3.8999E-17
6.1433E-06
9.3998E-01
7.1594E-272
3.6009E-179
9.5408E-111
2.0725E2273
1.0062E-03
2.2255E-09
2.6313E-02
2.3157E-02
5.2922E-05
1.0336E210
9.3354E-04
2.1896E-03
2.0701E-04
4.1628E-10
4.7953E-03
6.3889E-03
2.5397E?00
6.8219E-01
4.6399E-01
2.3176E201
1.8566E?02
1.4758E?02
1.6224E?02
1.2954E?02
6.8452E?01
5.3496E?01
5.4905E?01
4.4860E101
5.1942E?01
4.1604E?01
4.7754E?01
3.9250E?01
1.5053E-14
1.4323E-14
9.3573E-15
8.5950E215
1.3080E-01
8.6072E-02
1.2431E-01
7.4766E-02
2.2018E-02
1.2869E-02
1.8668E-02
1.0511E202
3.6482E-02
2.0007E-02
3.0738E-02
1.9717E-02
6.7196E-04
2.0602E204
3.1663E-03
1.1587E-03
1.0773E?01
1.2583E?00
1.2215E?04
5.7580E?00
7.3006E-01
3.0925E201
4.0829E?02
1.3770E?00
1.9983E?00
4.4332E-01
2.2299E?03
1.6805E?00
0.0000E100
0.0000E100
0.0000E100
0.0000E100
2.1015E-16
2.1121E-03
9.2760E?01
3.9408E-03
7.0050E218
7.0403E-05
3.0920E?00
1.5185E-04
3.8368E-17
3.8561E-04
1.6936E?01
7.2334E-04
2.4045E-03
2.2048E203
2.9042E-03
2.2303E-03
8.9010E-03
7.5511E-03
1.1137E-02
2.3980E-02
5.1565E-03
4.5852E203
5.3464E-03
6.7864E-03
1.5305E-03
1.3483E-03
1.6764E-03
5.1579E-03
2 1.2569E104
2 1.2569E104
2 1.2569E104
2 1.2569E104
- 1.2451E?04
- 1.2569E?04
- 1.1148E?04
- 1.1912E?04
- 1.2565E?04
2 1.2569E104
- 1.2487E?04
- 1.2520E?04
2.1544E?01
0.0000E?00
2.6373E?02
1.3638E?02
0.0000E100
0.0000E100
0.0000E100
0.0000E100
3.4106E-13
2.1364E-16
9.9502E-01
9.0767E?00
3.4106E-14
7.1578E218
3.3179E-02
8.3617E-01
6.4380E-14
3.8999E-17
1.8166E-01
2.2866E?00
1.5099E-14
1.5099E-14
1.1546E214
1.5099E-14
3.9968E-14
2.9142E-04
2.6673E-03
5.0244E-04
2.7534E214
1.0244E-05
1.5374E-04
3.2880E-05
7.1514E-15
5.3185E-05
5.3564E-04
1.0915E-04
0.0000E100
0.0000E100
0.0000E100
0.0000E100
7.4057E-03
1.1316E-05
1.3499E-04
1.1164E?00
2.4690E-04
4.4131E207
1.2273E-05
3.9179E-02
1.3521E-03
2.0830E-06
3.1948E-05
2.0360E-01
1.5705E232
1.5705E232
1.5705E232
1.5705E232
7.5517E-16
1.0144E-15
5.1535E-06
6.2437E-06
2.5172E217
3.3819E-17
1.7178E-07
2.2798E-07
1.3787E-16
1.8520E-16
9.4090E-07
1.1387E-06
Neural Computing and Applications 33:5011–5042
of the parameter MaxAge determines the fatality condition
of the infected cases. The infected cases that are reached
improvement
destroyed, and a new solution will be rebuilt from scratch.
The results recorded in Table 6 summarize the best, worst,
mean, and standard deviation (Stdev.) of the 23 test
Table 6 (continued)
1.3498E232
1.3498E232
1.3498E232
1.3498E232
4.5096E-20
8.9261E-29
2.1435E-08
9.4083E-07
1.5038E-21
2.9886E230
7.4931E-10
5.0727E-08
8.2333E-21
1.6294E-29
3.9111E-09
1.9867E-07
9.9800E201
9.9800E201
9.9800E201
9.9800E201
9.9800E-01
9.9800E-01
9.9800E-01
9.9800E-01
9.9800E201
9.9800E201
9.9800E201
9.9800E201
0.0000E?00
0.0000E?00
0.0000E?00
0.0000E?00
3.5295E-04
3.1027E204
3.1141E-04
3.1057E-04
8.0620E-04
7.4299E-04
6.3479E-04
6.8806E-04
5.2965E-04
4.8287E-04
4.3896E-04
4.3822E204
1.1758E-04
1.1762E-04
9.8883E-05
9.3258E-05
2 1.0316E100
2 1.0316E100
2 1.0316E100
2 1.0316E100
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
2 1.0316E100
2 1.0316E100
2 1.0316E100
2 1.0316E100
0.0000E?00
0.0000E?00
0.0000E?00
0.0000E?00
3.9789E201
3.9789E201
3.9789E201
3.9789E201
3.9789E-01
3.9789E-01
3.9789E-01
3.9789E-01
3.9789E201
3.9789E201
3.9789E201
3.9789E201
0.0000E?00
0.0000E?00
0.0000E?00
0.0000E?00
3.0000E100
3.0000E100
3.0000E100
3.0000E100
3.0000E?00
3.0000E?00
3.0000E?00
3.0000E?00
3.0000E100
3.0000E100
3.0000E100
3.0000E100
0.0000E?00
0.0000E?00
0.0000E?00
0.0000E?00
2 3.8628E100
2 3.8628E100
2 3.8628E100
2 3.8628E100
- 3.8628E?00
- 3.8628E?00
- 3.8628E?00
- 3.8628E?00
2 3.8628E100
2 3.8628E100
2 3.8628E100
2 3.8628E100
0.0000E?00
0.0000E?00
0.0000E?00
0.0000E?00
2 3.3220E100
2 3.3220E100
2 3.3220E100
2 3.3220E100
- 3.3220E?00
- 3.3220E?00
- 3.3220E?00
- 3.3220E?00
2 3.3220E100
2 3.3220E100
2 3.3220E100
2 3.3220E100
0.0000E?00
0.0000E?00
0.0000E?00
0.0000E?00
2 1.0153E101
2 1.0153E101
2 1.0153E101
2 1.0153E101
- 1.0153E?01
- 1.0153E?01
- 1.0153E?01
- 1.0153E?01
2 1.0153E101
2 1.0153E101
2 1.0153E101
2 1.0153E101
0.0000E?00
0.0000E?00
0.0000E?00
0.0000E?00
2 1.0403E101
2 1.0403E101
2 1.0403E101
2 1.0403E101
- 1.0403E?01
- 1.0403E?01
- 1.0403E?01
- 1.0403E?01
2 1.0403E101
2 1.0403E101
2 1.0403E101
2 1.0403E101
0.0000E?00
0.0000E?00
0.0000E?00
0.0000E?00
2 1.0536E101
2 1.0536E101
2 1.0536E101
2 1.0536E101
- 1.0536E?01
- 1.0536E?01
- 1.0536E?01
- 1.0536E?01
2 1.0536E101
2 1.0536E101
2 1.0536E101
v1.0536E101
0.0000E?00
0.0000E?00
0.0000E?00
0.0000E?00
Bold font refers to the best recorded result
Neural Computing and Applications 33:5011–5042
functions over 30 replicated runs. The best solution, as well
as the best mean obtained, is highlighted in bold font. Note
that in the results, the lowest is the best.
The results in Table 6 show that when the value of
MaxAge is equal to 100, the best mean results are obtained.
Note that the best results are highlighted in bold. The
MaxAge refers to the number of iterations for which the
infected cases remain unimproved. This operation can be
considered as a source of exploration. The smaller the
value of MaxAge, the higher the exploration. The value of
MaxAge ¼ 100 seems reasonable to diversify the search.
However, there is no signiﬁcant effect on the value of
MaxAge on the results produced.
3.5 Study of social distancing strategies in herd
immunity evolution
The effect of social distancing strategies on the herd
immunity evolution step is studied using the last four
convergence scenarios (i.e., Sen9 – Sen12). The social
distancing in herd immunity evolution step has three main
rules for infection: infected, susceptible, and immuned.
Sen9 changes the functionality of the social distancing
strategy where the three rules update the generated solution
based on the difference between the current solution and a
randomly selected solution which is called a random–random–random social distancing strategy. Sen10 changes the
functionality of the social distancing strategy and is called
a random–random–best where the infected case and the
susceptible case use a randomly selected solution while the
immuned cases use the difference between the current
solution and the best solution to update the values of the
newly generated solution.
Sen11 assumed that the functionality of the social distancing strategy updates the newly generated solutions
based on the random–best–random strategy where the
infected case uses a randomly selected solution while the
susceptible case uses the difference between the current
solution and the best solution to update the values of the
newly generated solution, while the immuned cases use the
difference between the current solution and the randomly
selected solution to update the values of the newly generated solution. The last scenario (Sen12) adopts random–
best–best social distancing strategy where the infected rule
uses the difference between the current solution and the
randomly selected solution to update the values of the
newly generated solution, while the rules of the susceptible
and immuned cases use the difference between the current
solution and the best solution to update the values of the
newly generated solution.
The results recorded in Table 5 summarize the best,
worst, mean, and standard deviation (Stdev.) of the 23 test
functions over 30 replicated runs. The best solution, as well
as the best mean obtained, is highlighted in bold font. Note
that in the results, the lowest is the best. The results summarized in Table 7 show that Sen9 can achieve the best
mean results for 22 out of 23 benchmark functions. Recall,
Sen9 uses a random–random–random social distancing
strategy. This means that the stochastic strategy in social
distancing is very efﬁcient and empower the convergence
strength of the proposed CHIO.
The convergence behaviour of CHIO using different
social distancing strategies are illustrated in Fig. 7. As can
be noticed, Sen9 adopted random–random–random social
distance strategy shows the best convergence behaviour in
comparison with other three social distancing strategies.
3.6 Comparison with the swarm-based
optimization algorithms
In this section, the performance of the proposed CHIO
algorithm is compared to seven swarm-based algorithms.
The ﬂower pollination algorithm (FPA) , bat algorithm
(BA) , artiﬁcial bee colony (ABC) , sine cosine
algorithm (SCA) , Harris hawks optimization (HHO)
 , salp swarm algorithm (SSA), and JAYA algorithm
 are utilized to deeply investigate the efﬁciency of the
proposed CHIO algorithm when compared against these
algorithms.
It should be noted that all these algorithms are experimented using the same conditions in order to ensure fairness. These conditions include the maximum number of
iterations is 100,000, the size of the population is 30, and
the number of runs is 30 times. The algorithmic parameters
of the other comparative algorithms are p=0.8 in FPA;
fmin ¼ 0, fmax ¼ 1, Aj ¼ 0:95, r0
j ¼ 0:1, a ¼ 0:95, c ¼ 0:95,
and  ¼ 0:001 in BA; a = 2 in SCA; limit = Number of
onlooker bees  n in ABC; and v0 ¼ 0 in SSA.
Table 8 exposes the experimental results of the proposed
CHIO algorithm as well as the other comparative methods
in terms of the best results, worst results, mean of the
results, and the standard derivation when running theses
algorithms 30 independent runs. In Table 8, the best results
are highlighted in bold font.
In terms of the best of the results, it can be observed
from the results provided in Table 8 that all the algorithms
obtained the same optimal results on four test functions
(i.e., F14, F16, F17, and F18). This is because the dimensions of the solutions in these test functions are small, and
the algorithms did not need big effort to reach the optimal
results. On other hand, the HHO algorithm obtained the
best results in 19 test functions, and this is the highest
number of best results reached by one of the comparative
algorithms, while the JAYA and FPA algorithms achieved
Neural Computing and Applications 33:5011–5042
Table 7 Performance of CHIO algorithm using different social distancing strategies
0.0000E100
0.0000E100
0.0000E100
5.6986E-238
6.9210E-192
2.1364E-16
6.5822E?02
2.6445E?03
2.5633E2193
7.1578E-18
2.4379E?01
2.2585E?02
0.0000E?00
3.8999E-17
1.2667E?02
6.9561E?02
3.1404E2284
3.6009E-179
6.9821E-251
1.5648E-43
5.9875E-36
2.2255E-09
5.6621E-24
5.5872E-06
1.9958E237
1.0336E-10
1.8874E-25
1.8624E-07
1.0932E-36
4.1628E-10
1.0338E-24
1.0201E-06
7.8863E-01
6.8219E-01
4.1503E201
8.2422E?00
8.3445E?01
1.4758E?02
5.5907E?01
1.4537E?02
1.4510E?01
5.3496E?01
1.2282E101
6.3900E?01
1.9350E?01
4.1604E?01
1.4082E?01
3.5922E?01
1.0365E-13
1.4323E214
4.1831E-12
7.4064E-08
1.1238E-03
8.6072E-02
3.3300E?01
5.0596E?01
1.1663E204
1.2869E-02
1.9450E?00
2.2038E?00
2.7763E-04
2.0007E-02
7.4795E?00
9.5325E?00
6.6029E-04
2.0602E204
6.2803E-04
1.0870E-02
1.0315E?00
1.2583E?00
3.2189E?06
6.0425E?06
1.6330E201
3.0925E-01
2.2734E?05
3.0083E?05
2.5698E-01
4.4332E-01
7.0727E?05
1.1549E?06
0.0000E100
0.0000E100
0.0000E100
0.0000E100
0.0000E?00
2.1121E-03
3.9047E?03
5.5317E?03
0.0000E100
7.0403E-05
2.8332E?02
4.0554E?02
0.0000E?00
3.8561E-04
8.5671E?02
1.2405E?03
1.8820E-03
2.2048E-03
1.7919E203
3.4210E-03
6.0311E-03
7.5511E-03
5.4759E-01
2.1158E?00
2.9852E203
4.5852E-03
3.0172E-02
7.5764E-02
8.5775E-04
1.3483E-03
1.0903E-01
3.8530E-01
2 1.2569E104
2 1.2569E104
2 1.2569E104
2 1.2569E104
- 1.2569E?04
- 1.2569E?04
- 9.7458E?03
- 1.0143E?04
2 1.2569E104
2 1.2569E104
- 1.2389E?04
- 1.2457E?04
0.0000E?00
0.0000E?00
6.8472E?02
4.6989E?02
0.0000E100
0.0000E100
0.0000E100
0.0000E100
0.0000E?00
2.1364E-16
4.6785E?01
4.8754E?01
0.0000E100
7.1578E-18
5.2139E?00
1.6251E?00
0.0000E?00
3.8999E-17
1.3842E?01
8.9012E?00
1.5099E214
1.5099E214
1.5099E214
1.8652E-14
2.9310E-14
2.9142E-04
1.2547E?01
1.2153E?01
2.0191E214
1.0244E-05
8.2750E-01
1.4744E?00
4.4435E-15
5.3185E-05
3.1494E?00
3.8314E?00
0.0000E100
0.0000E100
0.0000E100
0.0000E100
0.0000E?00
1.1316E-05
3.4024E?01
4.5916E?01
0.0000E100
4.4131E-07
2.0627E?00
3.6401E?00
0.0000E?00
2.0830E-06
7.1892E?00
1.1629E?01
1.5705E232
1.5705E232
1.5705E232
1.5705E232
1.5705E-32
1.0144E-15
3.4909E?05
9.9692E?06
1.5705E232
3.3819E-17
1.1636E?04
3.3236E?05
0.0000E?00
1.8520E-16
6.3735E?04
1.8201E?06
Neural Computing and Applications 33:5011–5042
the best results in 16 test functions. Interestingly, the CHIO
algorithm obtained the best results in 15 test functions,
while ABC, SSA, SCA, and BA get the best results in 12,
10, 8, and 7 test functions, respectively. In comparison
between the proposed CHIO algorithm and each of the
comparative methods, it can be seen that the performance
Table 7 (continued)
1.3498E232
1.3498E232
1.3498E232
1.3498E232
1.3498E-32
8.9261E-29
6.3660E?06
4.4663E?05
1.3498E232
2.9886E-30
3.7489E?05
1.4888E?04
0.0000E?00
1.6294E-29
1.4400E?06
8.1543E?04
9.9800E201
9.9800E201
9.9800E201
9.9800E201
9.9800E-01
9.9800E-01
9.9800E-01
9.9800E-01
9.9800E201
9.9800E201
9.9800E201
9.9800E201
0.0000E?00
0.0000E?00
0.0000E?00
0.0000E?00
3.0836E204
3.1027E-04
3.1304E-04
3.2137E-04
7.8177E-04
7.4299E-04
9.2408E-04
8.5773E-04
4.5139E204
4.8287E-04
5.3261E-04
5.6904E-04
1.1921E-04
1.1762E-04
1.5902E-04
1.5870E-04
2 1.0316E100
2 1.0316E100
2 1.0316E100
2 1.0316E100
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
2 1.0316E100
2 1.0316E100
2 1.0316E100
2 1.0316E100
0.0000E?00
0.0000E?00
1.1709E-07
6.7752E-16
3.9789E201
3.9789E201
3.9789E201
3.9789E201
3.9789E-01
3.9789E-01
3.9789E-01
3.9790E-01
3.9789E201
3.9789E201
3.9789E201
3.9789E201
0.0000E?00
0.0000E?00
1.6938E-16
1.8257E-06
3.0000E100
3.0000E100
3.0000E100
3.0000E100
3.0000E?00
3.0000E?00
3.0001E?00
3.0000E?00
3.0000E100
3.0000E100
3.0000E100
3.0000E100
0.0000E?00
0.0000E?00
2.6272E-05
6.2293E-06
2 3.8628E100
2 3.8628E100
2 3.8628E100
2 3.8628E100
- 3.8628E?00
- 3.8628E?00
- 3.8628E?00
- 3.8626E?00
2 3.8628E100
2 3.8628E100
2 3.8628E100
2 3.8628E100
0.0000E?00
0.0000E?00
4.6999E-08
2.7174E-05
2 3.3220E100
2 3.3220E100
2 3.3220E100
2 3.3220E100
- 3.3220E?00
- 3.3220E?00
- 3.3220E?00
- 3.3086E?00
2 3.3220E100
2 3.3220E100
2 3.3220E100
- 3.3215E?00
0.0000E?00
0.0000E?00
7.0028E-07
2.4435E-03
2 1.0153E101
2 1.0153E101
2 1.0153E101
2 1.0153E101
- 1.0153E?01
- 1.0153E?01
- 7.3062E?00
- 1.0153E?01
2 1.0153E101
2 1.0153E101
- 1.0003E?01
2 1.0153E101
0.0000E?00
0.0000E?00
5.9311E-01
6.7700E-06
2 1.0403E101
2 1.0403E101
2 1.0403E101
2 1.0403E101
- 1.0403E?01
- 1.0403E?01
- 4.5713E?00
- 1.0403E?01
2 1.0403E101
2 1.0403E101
- 1.0072E?01
2 1.0403E101
0.0000E?00
0.0000E?00
1.2791E?00
3.0275E-05
2 1.0536E101
2 1.0536E101
2 1.0536E101
2 1.0536E101
- 1.0536E?01
- 1.0536E?01
- 5.8221E?00
- 1.0536E?01
2 1.0536E101
2 1.0536E101
- 1.0379E?01
2 1.0536E101
0.0000E?00
0.0000E?00
8.6070E-01
1.5540E-05
Bold font refers to the best recorded result
Neural Computing and Applications 33:5011–5042
Table 8 Performance of CHIO algorithm against other swarm-based algorithms
0.0000E100
5.8244E-06
3.6017E-10
0.0000E100
0.0000E100
1.2927E-68
0.0000E100
2.3345E-16
6.9210E-192
1.1328E-03
1.2276E-09
0.0000E?00
0.0000E?00
3.3459E-60
0.0000E?00
4.5276E-16
2.5633E-193
9.0628E-04
7.0399E-10
0.0000E100
0.0000E100
1.2329E-61
0.0000E100
3.1546E-16
0.0000E?00
1.9593E-04
1.7096E-10
0.0000E?00
0.0000E?00
6.0969E-61
0.0000E?00
4.9325E-17
3.1404E-284
6.0440E-02
1.0175E-06
0.0000E100
0.0000E100
5.0467E-49
0.0000E100
7.3926E-16
5.9875E-36
1.4209E-01
2.4602E-06
0.0000E?00
0.0000E?00
2.0949E-46
0.0000E?00
1.0917E-15
1.9958E-37
1.0386E-01
1.4181E-06
0.0000E100
0.0000E100
3.2563E-47
0.0000E100
9.5129E-16
1.0932E-36
2.4849E-02
3.0302E-07
0.0000E?00
0.0000E?00
4.6488E-47
0.0000E?00
6.8723E-17
7.8863E-01
1.5437E-03
1.6382E-11
0.0000E100
3.2448E-06
6.4264E-36
3.7209E-79
4.2495E-01
8.3445E?01
2.7895E-03
5.4407E-11
0.0000E?00
1.8357E?02
1.8345E-29
5.8476E-28
4.7319E?00
1.4510E?01
1.9530E-03
3.1907E-11
0.0000E100
6.1675E?00
7.0321E-31
1.9593E-29
1.3009E?00
1.9350E?01
3.2526E-04
1.1184E-11
0.0000E?00
3.3506E?01
3.3398E-30
1.0674E-28
8.5311E-01
1.0365E-13
2.6070E-03
2.0848E-06
0.0000E100
4.6804E-83
2.2292E?00
9.1151E-81
5.9336E-04
1.1238E-03
4.2459E-02
4.2903E-06
0.0000E?00
1.6300E-73
1.0699E?01
4.1305E-45
3.0871E-02
1.1663E-04
1.3337E-02
2.9055E-06
0.0000E100
8.5571E-75
6.1325E?00
1.3768E-46
1.4670E-02
2.7763E-04
6.1972E-03
5.9361E-07
0.0000E?00
3.0628E-74
1.8150E?00
7.5412E-46
9.0922E-03
6.6029E-04
1.3309E-03
2.9004E-05
2.6646E-19
0.0000E100
0.0000E100
2.5738E?01
1.7761E-04
1.0315E?00
5.4626E-01
1.3386E?02
2.7537E-06
4.6121E-27
3.9866E?00
2.8843E?01
2.4223E-02
1.6330E-01
3.0927E-01
9.1381E?00
2.6568E-07
7.1058E228
1.0631E?00
2.6756E?01
8.2796E-03
2.5698E-01
1.4211E-01
2.9857E?01
5.6154E-07
1.0409E-27
1.7931E?00
7.9304E-01
7.3267E-03
0.0000E100
7.3260E-04
1.7724E-11
1.1350E-12
1.2663E?00
0.0000E100
2.3330E?00
2.7110E-16
0.0000E?00
1.2020E-03
4.6742E-11
1.6681E-08
2.3662E?00
9.2445E-33
3.6950E?00
4.5992E-16
0.0000E100
9.6083E-04
2.8460E-11
2.5973E-09
1.7168E?00
1.0272E-33
2.7519E?00
3.3343E-16
0.0000E?00
1.1017E-04
7.9376E-12
3.5328E-09
2.4362E-01
2.1914E-33
2.7166E-01
5.6644E-17
1.8820E-03
2.0116E-05
1.6440E-05
4.3464E208
3.1598E-04
1.9271E-03
1.2680E-05
1.4464E-02
6.0311E-03
9.7654E-04
1.3617E-04
2.4894E-06
1.8851E-03
1.6701E-02
1.0451E-03
3.6492E-02
2.9852E-03
2.8460E-04
6.0942E-05
6.1503E207
8.0063E-04
7.0015E-03
1.9792E-04
2.7368E-02
8.5775E-04
2.1320E-04
2.4372E-05
5.6438E-07
3.7976E-04
3.8622E-03
1.9364E-04
4.9410E-03
2 1.2569E104
2 1.2569E104
- 3.7358E?03
2 1.2569E104
2 1.2569E104
2 1.2569E104
- 5.2221E?03
2 1.2569E104
- 1.2569E?04
- 1.2569E?04
- 2.7838E?03
- 1.2569E?04
- 9.6524E?03
- 1.2037E?04
- 4.3557E?03
- 1.2569E?04
2 1.2569E104
2 1.2569E104
- 3.2996E?03
2 1.2569E104
- 1.2414E?04
- 1.2533E?04
- 4.8295E?03
2 1.2569E104
0.0000E?00
0.0000E?00
2.9626E?02
3.8584E-06
5.3669E?02
1.2421E?02
2.2396E?02
0.0000E?00
0.0000E100
1.3971E-03
3.9798E?00
0.0000E100
2.0894E?01
3.9798E?00
0.0000E100
0.0000E100
0.0000E?00
2.1810E-01
1.8904E?01
0.0000E?00
6.9959E?01
3.4824E?01
0.0000E?00
0.0000E?00
0.0000E100
3.4020E-02
1.1409E?01
0.0000E100
4.1036E?01
1.7345E?01
0.0000E100
0.0000E100
0.0000E?00
4.1965E-02
4.2913E?00
0.0000E?00
1.2778E?01
6.4939E?00
0.0000E?00
0.0000E?00
Neural Computing and Applications 33:5011–5042
Table 8 (continued)
1.5099E-14
1.2917E-02
1.1456E-06
8.8818E216
4.4409E-15
4.4409E-15
4.4409E-15
2.2204E-14
2.9310E-14
2.6318E-02
2.7045E-06
8.8818E-16
1.5099E-14
2.9570E?00
2.0091E?01
3.2863E-14
2.0191E-14
2.2488E-02
2.1420E-06
8.8818E216
1.0481E-14
2.0943E?00
4.7443E?00
2.8481E-14
4.4435E-15
3.4878E-03
3.3870E-07
0.0000E?00
3.6315E-15
5.7074E-01
8.5925E?00
3.1893E-15
0.0000E100
3.7136E-05
4.4278E-02
0.0000E100
0.0000E100
0.0000E100
0.0000E100
0.0000E100
0.0000E?00
2.2172E-02
5.7588E-01
0.0000E?00
3.9202E-02
9.9984E-02
0.0000E?00
0.0000E?00
0.0000E100
3.8227E-03
2.4429E-01
0.0000E100
9.6025E-03
2.2508E-02
0.0000E100
0.0000E100
0.0000E?00
6.4556E-03
1.1441E-01
0.0000E?00
9.8796E-03
2.0960E-02
0.0000E?00
0.0000E?00
1.5705E232
6.1362E-06
6.7105E-14
1.9368E-16
1.0735E-01
1.5705E232
1.7042E-01
2.0090E-16
1.5705E-32
9.9548E-06
3.7092E-13
1.3567E-09
1.9790E?00
4.1467E-01
7.2099E-01
3.3297E-16
1.5705E232
8.0379E-06
2.0441E-13
2.1282E-10
7.9997E-01
3.1099E-02
2.3448E-01
3.0073E-16
0.0000E?00
8.1735E-07
8.0966E-14
3.5150E-10
6.2292E-01
9.4892E-02
9.7074E-02
3.1383E-17
1.3498E232
7.7966E-05
4.4766E-13
1.3841E-13
1.3498E232
1.3498E232
1.4198E?00
2.2467E-16
1.3498E-32
1.1151E-02
2.2000E-12
8.0172E-09
1.0987E-02
2.1024E-02
1.9365E?00
3.2831E-16
1.3498E232
1.2242E-03
1.1170E-12
1.2539E-09
1.0987E-03
2.1658E-03
1.7143E?00
2.9817E-16
0.0000E?00
3.3624E-03
4.4169E-13
1.8761E-09
3.3526E-03
5.2000E-03
1.3176E-01
2.1200E-17
9.9800E201
9.9800E201
9.9800E201
9.9800E201
9.9800E201
9.9800E201
9.9800E201
9.9800E201
9.9800E-01
9.9800E-01
9.9800E-01
9.9800E-01
9.9800E-01
9.9800E-01
9.9800E-01
9.9800E-01
9.9800E201
9.9800E201
9.9800E201
9.9800E201
9.9800E201
9.9800E201
9.9800E201
9.9800E201
0.0000E?00
0.0000E?00
7.1417E-17
5.3044E-16
8.0766E-10
0.0000E?00
6.0527E-10
0.0000E?00
3.0836E-04
3.0750E-04
3.0749E204
3.0749E204
3.0749E204
3.0749E204
3.0795E-04
3.1349E-04
7.8177E-04
3.0757E-04
1.2232E-03
3.0751E-04
1.2239E-03
3.0749E-04
3.1255E-04
3.8879E-04
4.5139E-04
3.0753E-04
5.5167E-04
3.0749E204
3.3803E-04
3.0749E204
3.0992E-04
3.4468E-04
1.1921E-04
1.8020E-08
4.1185E-04
5.7109E-09
1.6731E-04
1.0795E-19
1.3604E-06
2.1330E-05
2 1.0316E100
2 1.0316E100
2 1.0316E100
2 1.0316E100
2 1.0316E100
2 1.0316E100
2 1.0316E100
2 1.0316E100
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
- 1.0316E?00
2 1.0316E100
2 1.0316E100
2 1.0316E100
2 1.0316E100
2 1.0316E100
2 1.0316E100
2 1.0316E100
2 1.0316E100
0.0000E?00
3.5650E-09
0.0000E?00
5.6082E-16
0.0000E?00
6.7752E-16
1.4940E-07
6.7752E-16
3.9789E201
3.9789E201
3.9789E201
3.9789E201
3.9789E201
3.9789E201
3.9789E201
3.9789E201
3.9789E-01
3.9789E-01
3.9789E-01
3.9789E-01
3.9797E-01
3.9789E-01
3.9791E-01
3.9789E-01
3.9789E201
3.9789E201
3.9789E201
3.9789E201
3.9789E201
3.9789E201
3.9789E201
3.9789E201
0.0000E?00
1.6204E-09
0.0000E?00
2.2414E-15
1.5462E-05
0.0000E?00
5.7809E-06
0.0000E?00
3.0000E100
3.0000E100
3.0000E100
3.0000E100
3.0000E100
3.0000E100
3.0000E100
3.0000E100
3.0000E?00
3.0000E?00
3.0000E?00
3.0000E?00
3.0000E?00
3.0000E?00
3.0000E?00
3.0000E?00
3.0000E100
3.0000E100
3.0000E100
3.0000E100
3.0000E100
3.0000E100
3.0000E100
3.0000E100
0.0000E?00
1.2646E-07
0.0000E?00
3.8803E-15
0.0000E?00
4.8085E-16
9.0569E-10
1.8195E-13
Neural Computing and Applications 33:5011–5042
Table 8 (continued)
2 3.8628E100
2 3.8628E100
2 3.8628E100
2 3.8628E100
2 3.8628E100
2 3.8628E100
- 3.8627E?00
2 3.8628E100
- 3.8628E?00
- 3.8628E?00
- 3.8628E?00
- 3.8628E?00
- 3.8628E?00
- 3.8628E?00
- 3.8549E?00
- 3.8628E?00
2 3.8628E100
2 3.8628E100
2 3.8628E100
2 3.8628E100
2 3.8628E100
2 3.8628E100
- 3.8559E?00
2 3.8628E100
0.0000E?00
4.0695E-07
2.0451E-15
2.1362E-15
2.7101E-15
2.7101E-15
2.6900E-03
2.7101E-15
2 3.3220E100
2 3.3220E100
2 3.3220E100
2 3.3220E100
2 3.3220E100
2 3.3220E100
- 3.1322E?00
2 3.3220E100
2 3.3220E100
- 3.2030E?00
- 3.2031E?00
- 3.1896E?00
- 3.2031E?00
2 3.3220E100
- 1.5784E?00
2 3.3220E100
- 3.3220E?00
- 3.2823E?00
- 3.2150E?00
- 3.3095E?00
- 3.2665E?00
- 3.3220E?00
- 2.9247E?00
- 3.3220E?00
0.0000E?00
5.6979E-02
3.6278E-02
3.8128E-02
6.0328E-02
0.0000E?00
3.5932E-01
1.3550E-15
2 1.0153E101
2 1.0153E101
2 1.0153E101
2 1.0153E101
2 1.0153E101
2 1.0153E101
- 1.0120E?01
2 1.0153E101
- 1.0153E?01
- 1.0153E?01
- 1.0153E?01
- 1.0153E?01
- 2.6305E?00
- 1.0153E?01
- 4.9653E-01
- 1.0153E?01
2 1.0153E101
2 1.0153E101
2 1.0153E101
2 1.0153E101
- 8.1432E?00
2 1.0153E101
- 3.3205E?00
2 1.0153E101
0.0000E?00
2.6309E-07
3.4777E-13
2.6750E-10
2.9755E?00
0.0000E?00
3.2896E?00
2.6309E-07
2 1.0403E101
- 1.0153E?01
2 1.0403E101
2 1.0403E101
2 1.0403E101
2 1.0403E101
- 1.0173E?01
2 1.0403E101
- 1.0403E?01
- 1.0153E?01
- 1.0403E?01
- 1.0403E?01
- 1.8376E?00
- 1.0403E?01
- 5.2404E-01
- 1.0403E?01
2 1.0403E101
- 1.0153E?01
2 1.0403E101
2 1.0403E101
- 8.5511E?00
2 1.0403E101
- 5.3905E?00
2 1.0403E101
0.0000E?00
2.6309E-07
2.8255E-13
5.0350E-10
2.8232E?00
0.0000E?00
3.5424E?00
1.8506E-05
2 1.0536E101
- 1.0153E?01
2 1.0536E101
2 1.0536E101
2 1.0536E101
2 1.0536E101
- 1.0414E?01
2 1.0536E101
- 1.0536E?01
- 1.0153E?01
- 5.1756E?00
- 1.0536E?01
- 2.4205E?00
- 1.0536E?01
- 9.4700E-01
- 1.0536E?01
2 1.0536E101
- 1.0153E?01
- 1.0000E?01
2 1.0536E101
- 9.9954E?00
2 1.0536E101
- 6.2118E?00
2 1.0536E101
0.0000E?00
2.6309E-07
1.6357E?00
4.0765E-10
2.0589E?00
0.0000E?00
2.7930E?00
2.2016E-05
Bold font refers to the best recorded result
Neural Computing and Applications 33:5011–5042
of the CHIO algorithm is similar or better than the BA,
SSA, HHO, JAYA, FPA, SCA, and ABC algorithms in 20,
17, 16, 16, 19, 17, and 21 test functions, respectively.
Similarly, in terms of the results mean, it can be seen
from Table 8 that the performance of all of the comparative
algorithms is similar in four test functions (i.e., F14, F16,
F17, and F18) as they reach the optimal results. The HHO
obtained the best results in 18 test functions, and the proposed CHIO algorithm achieves the best results in 15 test
functions. While the ABC and FPA get the best results in
12 and 10 test functions, respectively. The JAYA and SCA
obtain the best results in eight test functions, while the BA
and SSA get the best results in seven datasets. In comparison between the proposed CHIO algorithm and each of
the comparative methods, it can be seen that the performance of the CHIO algorithm is similar or better than the
BA, SSA, HHO, JAYA, FPA, SCA, and ABC algorithms in
20, 20, 15, 15, 20, 17, and 20 datasets, respectively.
Figure 8 illustrates the convergence behavior of the
proposed CHIO algorithm against the other comparative
algorithms. The x-axis represents the number of iterations,
while the y-axis represents the values of the ﬁtness function. It should be noted that eight out of the 23 test functions are considered in this ﬁgure to show the differences
between algorithms visually. Figure 8 elaborates that the
proposed CHIO algorithm did not have fast convergence
like the other comparative methods, where the convergence
of the CHIO algorithm is gradually improved during the
search. This allows CHIO to avoid the problem of getting
stuck in local optima.
Figure 9 plots the Hamming distance between the
solutions in the population for the proposed CHIO algorithm as well as the other comparative methods. It can be
observed from Fig. 9 that the proposed CHIO algorithm
can maintain a good distance between the population. This
is because the infected case is killed when it is not
improved after a certain number of iterations. Then, these
cases are regenerated from scratch and thus solve the
problem of fast convergence.
Friedman’s statistical test is used to illustrate the average rankings of the proposed CHIO algorithm when compared against other comparative methods. Table 9 shows
the rankings where these rankings are calculated based on
the best results recorded in Table 8. It is worthy to mention
that the lower rankings indicate better performance, while
the signiﬁcant level a = 0.05. Table 9 shows that HHO
algorithm is ranked ﬁrst, while the proposed CHIO algorithm is ranked third. The q-value computed by Friedman’s
Number of iterations
Fitness value
Number of iterations
Fitness value
Number of iterations
Fitness value
Number of iterations
Fitness value
Number of iterations
Fitness value
Number of iterations
Fitness value
Number of iterations
Fitness value
Number of iterations
Fitness value
Fig. 7 Convergence plots of CHIO algorithm using different social distancing strategies
Neural Computing and Applications 33:5011–5042
test is 1.54E-5, which is below the signiﬁcant level. This
value indicates that there are signiﬁcant differences
between the performance of the comparative methods.
Thereafter, the Holm’s procedure as a post hoc technique is used to conﬁrm that there are signiﬁcant differences among the controlled methods (the method with the
ﬁrst rankings) and the remaining comparative methods. It
can be seen from the results recorded in Table 10 that the
hypothesis is accepted. This means that there is a signiﬁcant difference between the HHO algorithm and two of the
other methods (BA, and SCA). On the other hand, there is
no signiﬁcant difference between HHO and the remaining
comparative methods.
Table 11 illustrates the average rankings of the comparative methods, where these rankings are calculated
based on the mean results recorded in Table 8. Table 9
points out that HHO algorithm is ranked ﬁrst, while the
proposed CHIO algorithm is placed second. The q-value
computed by Friedman’s test is 3.97E-5, which is below
the signiﬁcant level. This value indicates that there is a
signiﬁcant difference between the performance of the
comparative methods.
Thereafter, the Holm’s procedure as a post hoc technique is used to conﬁrm that there is a signiﬁcant difference
between HHO and the other comparative methods. It can
be seen from the results recorded in Table 12 that the
hypothesis is accepted. It is clear that there is a signiﬁcant
difference between the HHO algorithm and four of the
comparative methods (BA, JAYA, SSA, and SCA). On the
other hand, there no signiﬁcant difference between HHO
and the remaining comparative methods including the
proposed CHIO algorithm (please refers to the Table 12).
The performance of the CHIO algorithm has been
evaluated using the Wilcoxon signed-rank statistical test
 to verify whether there is a signiﬁcant difference
between CHIO and the other comparative algorithms. The
Wilcoxon signed-rank is applied using the best results of
30 runs for each algorithm with P_value equal 0.05.
Table 13 shows a pair-wise comparison against all algorithms and CHIO, showing whether two algorithms are
Number of iterations
Fitness value
Number of iterations
Fitness value
Number of iterations
Fitness value
Number of iterations
Fitness value
Number of iterations
Fitness value
Number of iterations
Fitness value
Number of iterations
Fitness value
Number of iterations
Fitness value
Fig. 8 Convergence plots of CHIO algorithm against the other swarm-based algorithms
Neural Computing and Applications 33:5011–5042
considered similar (‘–’) or not (‘??’) to each other. The
most algorithm that has been considered similar to CHIO is
ABC with 11 functions. The results show that CHIO and
HHO are similar with ten functions. Finally, FPA is similar
to CHIO in nine functions.
3.7 Real-world engineering optimization
For further validations, the applicability of the proposed
CHIO algorithm on real-world optimization problems is
discussed in this section. The proposed CHIO is tested
using three bound-constrained real-world optimization
problems which are:
Number of iterations
Number of iterations
Number of iterations
Number of iterations
Number of iterations
Number of iterations
Number of iterations
Number of iterations
Fig. 9 Hamming distance of CHIO algorithm against the other swarm-based algorithms
Table 9 Average rankings of
the algorithms calculated using
Friedman’s test (based on the
best results)
Table 10 Holm’s results between the HHO algorithm and other
comparative methods (Based on the best results)
Adjusted q-value
Neural Computing and Applications 33:5011–5042
Parameter estimation for frequency-modulated (FM)
sound waves.
bifunctional
Transmission network expansion planning (TNEP)
It should be noted that details of these problems are
introduced in the 2011 IEEE Congress on Evolutionary
Computation .
The performance of the CHIO algorithm is compared
with nine other comparative methods such as adaptive
population-based simplex algorithm (APS) , adaptive
differential evolution algorithm (ADE) , continuous
differential ant-stigmergy algorithm (CDASA) , differential evolution (DE) , hybrid DE-with random hill
climber (DE-RHC) , genetic algorithm with a new
multi-parent crossover (GA-MPC) , hybrid DE algorithm with adaptive crossover operator (HDE) , hybrid
EA-DE-Memetic algorithm (HMA) , intellects-masses
optimizer (IMO) , artiﬁcial bee colony , accelerated artiﬁcial bee colony algorithm , and krill herd and
artiﬁcial bee colony with information exchange (KHABC)
It should be noted that the parameter settings of the
CHIO algorithm followed the rules of IEEE-CEC 2011 by
having the maximum number of iterations is set to 150,000
and the number of runs is set to 25 times. While the settings
of the other parameters include HIS ¼ 30, BRr ¼ 0:01, and
MaxAge ¼ 100. These settings are obtained from the best
results in the previous sections.
3.7.1 Parameter estimation for frequency-modulated (FM)
sound waves
The performance of the proposed CHIO algorithm when
compared against other comparative methods is reported in
Table 14. It can be observed from Table 14 that the performance of the proposed CHIO is competitive when
compared against other methods.
3.7.2 The bifunctional catalyst blend optimal control
Table 15 lists the optimization results of the proposed
CHIO algorithm when compared against nine comparative
methods. As it can be seen from Table 15, the CHIO
algorithm obtained the optimal results in this problem
based on the best results or the mean of the results. This
proofs the efﬁciency of the proposed CHIO algorithm on
solving this kind of problems.
3.7.3 Transmission network expansion planning (TNEP)
The experimental results of the proposed CHIO algorithm
against other comparative methods are presented in
Table 16. Clearly, the best result obtained by the proposed
CHIO algorithm for this problem is equivalent to the
results in the literature in terms of the best results, the mean
of the results, the median of the results, the worst results,
and the standard deviation.
4 Conclusion and future work
In this paper, a new natural-inspired human-based metaheuristic optimization algorithm is proposed which is
called coronavirus herd immunity optimizer (CHIO) for
global optimization problems. CHIO is inspired by the herd
immunity strategy as a way to tackle the spreading of
coronavirus pandemics (COVID-19). The population is
initiated by several susceptible cases and very few (might
be one) infected cases. During the herd immunity evolution, the population is evolved according to the basic
reproduction rate (BRr) affected by social distancing realized in the way of updating the newly generated individuals
using three intervention with three possible cases: susceptible, infected, and immuned until the herd immunity is
achieved in the population. During the search process,
Table 11 Average rankings of
the algorithms calculated using
Friedman’s test (based on the
mean results)
Table 12 Holm’s results between the HHO algorithm and other
comparative methods (Based on the mean results)
Adjusted q-value
Neural Computing and Applications 33:5011–5042
Table 13 Wilcoxon signed-rank test evaluation between the proposed CHIO algorithm and other methods
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
\1:0E  05
Neural Computing and Applications 33:5011–5042
some fatality cases are occurred according to the maximum
number of iterations (MaxAge) when it remains unimproved
with the infected state. The state of cases are updated
during the search from susceptible to infected and from
infected to immuned according to the herd immunity
threshold, and it depends on the immunity rate of the
generated cases.
The viability of the proposed CHIO is tested using 23
well-known benchmark functions with different size and
complexity: seven unimodal, six multimodal with ﬂexible
dimensions, and ten multimodal with ﬁxed dimensions.
These functions are well circulated in the literature to
evaluate newly proposed optimization algorithms.
Initially, the effect of the control parameters (BRr and
MaxAge) on the convergence behavior of CHIO is studied.
In conclusion, using a small value of BRr is desired to
strike the right balance between exploration and exploitation of the search space. Furthermore, the value of MaxAge
Table 13 (continued)
\1:0E  05
\1:0E  05
\1:0E  05
?? means results is signiﬁcant, and – means results is not signiﬁcant
Table 14 Comparison results of
parameter estimation for
frequency-modulated (FM)
sound waves problem over 25
runs and 150,000 function
evaluations
9.0573E?00
1.7060E?01
1.8311E?01
4.0233E?01
8.1538E?00
2.7725E?00
3.6696E-01
0.0000E100
1.4813E?01
1.1935E?01
1.8698E?01
6.5169E?00
5.0200E-20
8.9100E?00
1.5600E?01
6.3700E?00
0.0000E100
0.0000E?00
3.8526E?00
1.7021E?01
5.6900E?00
3.2789E-18
1.1376E?01
1.0128E?01
2.1171E?01
7.0955E?00
0.0000E100
0.0000E?00
0.0000E?00
0.0000E?00
0.0000E?00
7.2093E-15
1.2362E-11
8.7697E-01
1.1757E?01
3.0439E?00
0.0000E100
0.0000E?00
8.9894E-01
1.2306E?01
3.1266E?00
1.2310E?01
2.2310E?01
2.7790E?01
3.5300E?00
1.1674E-11
6.0847E-10
2.0949E?00
1.1374E?01
4.3064E?00
0.0000E100
1.0854E-27
6.0448E-13
1.3127E-11
2.6388E-12
Bold font refers to the best recorded result
Table 15 Comparison results of
bifunctional catalyst blend
optimal control problem over 25
runs and 150,000 function
evaluations
1.1515E205
1.1516E-05
1.1515E-05
1.1516E-05
4.5343E-10
1.1515E205
1.1515E-05
1.1515E-05
1.1515E-05
4.8070E-19
1.1515E205
1.1515E-05
1.1515E-05
0.0000E?00
1.1515E205
1.1515E-05
1.1515E-05
1.1515E-05
3.8043E-19
1.1515E205
1.1515E-05
1.1515E-05
1.1515E-05
1.6885E-24
1.1515E205
1.1515E-05
1.1515E-05
1.1515E-05
0.0000E?00
1.1515E205
1.1515E-05
1.1515E-05
1.1515E-05
6.1087E-18
1.1515E205
1.1515E-05
1.1515E-05
1.1515E-05
0.0000E?00
1.1515E205
1.1515E-05
1.1515E-05
1.1515E-05
9.9711E-19
1.1515E205
1.1515E-05
1.1515E-05
1.1515E-05
2.0039E-19
Bold font refers to the best recorded result
Neural Computing and Applications 33:5011–5042
does not have a high impact on the performance of CHIO.
However, using a small value of this parameter is necessary
to diversify the search. The social distancing strategies in
the herd immunity evolution are also investigated which
are random–random–random, random–best–random, random–random–best, and random–best–best. In conclusion,
The random–random–random social distancing strategies
in the herd immunity evolution revealed the best performance of CHIO. For comparative evaluation, the proposed
CHIO is compared against seven well-established comparative methods using the same benchmark functions. The
comparative results show that CHIO is very competitive
which is able to obtain 16 out of 23 new results for the testbed functions. For more validations, three real-world
engineering
optimization
IEEE-CEC 2011 are used. Again, CHIO is proved to be
As the proposed CHIO reveals very successful outcomes, CHIO can be widely used in the future for several
kinds of real-world optimization problems. Furthermore,
the optimization structure of CHIO can be improved by
adapting its parameters to result in a parameter-less CHIO.
Also for the future, the binary, discrete, multi-objective
versions of CHIO can be proposed. Another future direction can use the herd immunity threshold as a stop condition for the algorithm.
Compliance with ethical standards
Conflict of interest The authors declare that they have no conflict of