Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1555–1565,
Baltimore, Maryland, USA, June 23-25 2014. c⃝2014 Association for Computational Linguistics
Learning Sentiment-Speciﬁc Word Embedding
for Twitter Sentiment Classiﬁcation∗
Duyu Tang†, Furu Wei‡ , Nan Yang♮, Ming Zhou‡, Ting Liu†, Bing Qin†
†Research Center for Social Computing and Information Retrieval
Harbin Institute of Technology, China
‡Microsoft Research, Beijing, China
♮University of Science and Technology of China, Hefei, China
{dytang, tliu, qinb}@ir.hit.edu.cn
{fuwei, v-nayang, mingzhou}@microsoft.com
We present a method that learns word embedding for Twitter sentiment classiﬁcation in this paper. Most existing algorithms for learning continuous word representations typically only model the syntactic
context of words but ignore the sentiment of text.
This is problematic for sentiment analysis as they usually map words with similar syntactic context but opposite sentiment polarity, such as good and
bad, to neighboring word vectors.
address this issue by learning sentimentspeciﬁc word embedding (SSWE), which
encodes sentiment information in the continuous representation of words. Specifically, we develop three neural networks
to effectively incorporate the supervision
from sentiment polarity of text (e.g. sentences or tweets) in their loss functions. To obtain large scale training corpora,
we learn the sentiment-speciﬁc word embedding from massive distant-supervised
tweets collected by positive and negative
emoticons. Experiments on applying SS-
WE to a benchmark Twitter sentiment classiﬁcation dataset in SemEval 2013
show that (1) the SSWE feature performs
comparably with hand-crafted features in
the top-performed system; (2) the performance is further improved by concatenating SSWE with existing feature set.
Introduction
Twitter sentiment classiﬁcation has attracted increasing research interest in recent years . The objective is to classify the sentiment polarity of a tweet as positive,
∗This work was done when the ﬁrst and third authors
were visiting Microsoft Research Asia.
negative or neutral. The majority of existing approaches follow Pang et al. and employ machine learning algorithms to build classiﬁers from
tweets with manually annotated sentiment polarity. Under this direction, most studies focus on
designing effective features to obtain better classiﬁcation performance. For example, Mohammad
et al. build the top-performed system in the
Twitter sentiment classiﬁcation track of SemEval
2013 , using diverse sentiment
lexicons and a variety of hand-crafted features.
Feature engineering is important but laborintensive. It is therefore desirable to discover explanatory factors from the data and make the learning algorithms less dependent on extensive feature engineering . For the task of
sentiment classiﬁcation, an effective feature learning method is to compose the representation of a
sentence (or document) from the representations of the words or phrases it contains . Accordingly, it is a crucial step to learn the word
representation (or word embedding), which is a
dense, low-dimensional and real-valued vector for
a word. Although existing word embedding learning algorithms are intuitive choices, they are not effective enough if directly used for sentiment classi-
ﬁcation. The most serious problem is that traditional methods typically model the syntactic context of words but ignore the sentiment information
of text. As a result, words with opposite polarity, such as good and bad, are mapped into close
vectors. It is meaningful for some tasks such as
pos-tagging as the two words
have similar usages and grammatical roles, but it
becomes a disaster for sentiment analysis as they
have the opposite sentiment polarity.
In this paper, we propose learning sentimentspeciﬁc word embedding (SSWE) for sentiment
analysis. We encode the sentiment information in-
to the continuous representation of words, so that
it is able to separate good and bad to opposite ends
of the spectrum. To this end, we extend the existing word embedding learning algorithm and develop three neural networks to effectively incorporate the supervision
from sentiment polarity of text (e.g.
or tweets) in their loss functions. We learn the
sentiment-speciﬁc word embedding from tweets, leveraging massive tweets with emoticons as
distant-supervised corpora without any manual annotations.
These automatically collected tweets contain noises so they cannot be directly used
as gold training data to build sentiment classiﬁers, but they are effective enough to provide weakly supervised signals for training the sentimentspeciﬁc word embedding.
We apply SSWE as features in a supervised
learning framework for Twitter sentiment classi-
ﬁcation, and evaluate it on the benchmark dataset
in SemEval 2013. In the task of predicting positive/negative polarity of tweets, our method yields
84.89% in macro-F1 by only using SSWE as feature, which is comparable to the top-performed
system based on hand-crafted features (84.70%).
After concatenating the SSWE feature with existing feature set, we push the state-of-the-art to
86.58% in macro-F1. The quality of SSWE is also directly evaluated by measuring the word similarity in the embedding space for sentiment lexicons. In the accuracy of polarity consistency between each sentiment word and its top N closest
words, SSWE outperforms existing word embedding learning algorithms.
The major contributions of the work presented
in this paper are as follows.
• We develop three neural networks to learn
sentiment-speciﬁc word embedding (SSWE)
from massive distant-supervised tweets without any manual annotations;
• To our knowledge, this is the ﬁrst work that
exploits word embedding for Twitter sentiment classiﬁcation. We report the results that
the SSWE feature performs comparably with
hand-crafted features in the top-performed
system in SemEval 2013;
• We release the sentiment-speciﬁc word embedding learned from 10 million tweets,
which can be adopted off-the-shell in other
sentiment analysis tasks.
Related Work
In this section, we present a brief review of the
related work from two perspectives, Twitter sentiment classiﬁcation and learning continuous representations for sentiment classiﬁcation.
Twitter Sentiment Classiﬁcation
Twitter sentiment classiﬁcation, which identiﬁes
the sentiment polarity of short, informal tweets,
has attracted increasing research interest in recent years. Generally, the methods employed in Twitter sentiment
classiﬁcation follow traditional sentiment classiﬁcation approaches. The lexicon-based approaches
 mostly use a dictionary of sentiment words with their associated sentiment polarity, and incorporate negation and intensiﬁcation to compute the sentiment polarity for
each sentence (or document).
The learning based methods for Twitter sentiment classiﬁcation follow Pang et al. ’s
work, which treat sentiment classiﬁcation of texts
as a special case of text categorization issue. Many
studies on Twitter sentiment classiﬁcation leverage massive noisy-labeled
tweets selected by positive and negative emoticons as training set and build sentiment classiﬁers directly, which is called distant supervision . Instead of directly using the distantsupervised data as training set, Liu et al. 
adopt the tweets with emoticons to smooth the language model and Hu et al. incorporate the
emotional signals into an unsupervised learning
framework for Twitter sentiment classiﬁcation.
Many existing learning based methods on Twitter sentiment classiﬁcation focus on feature engineering. The reason is that the performance of sentiment classiﬁer being heavily dependent on the
choice of feature representation of tweets.
most representative system is introduced by Mohammad et al. , which is the state-of-theart system by
implementing a number of hand-crafted features.
Unlike the previous studies, we focus on learning
discriminative features automatically from massive distant-supervised tweets.
Learning Continuous Representations for
Sentiment Classiﬁcation
Pang et al. pioneer this ﬁeld by using bagof-word representation, representing each word as
a one-hot vector. It has the same length as the size
of the vocabulary, and only one dimension is 1,
with all others being 0. Under this assumption,
many feature learning algorithms are proposed to
obtain better classiﬁcation performance . However,
the one-hot word representation cannot sufﬁciently capture the complex linguistic characteristics of
With the revival of interest in deep learning , incorporating the continuous representation of a word as features has
been proving effective in a variety of NLP tasks,
such as parsing , language
modeling and NER . In the
ﬁeld of sentiment analysis, Bespalov et al. initialize the word embedding by Latent Semantic Analysis and further represent each
document as the linear weighted of ngram vectors for sentiment classiﬁcation. Yessenalina and
Cardie model each word as a matrix and
combine words using iterated matrix multiplication. Glorot et al. explore Stacked Denoising Autoencoders for domain adaptation in sentiment classiﬁcation. Socher et al. propose Recursive Neural Network (RNN) , matrixvector RNN and Recursive Neural Tensor
Network (RNTN) to learn the compositionality of phrases of any length based on the
representation of each pair of children recursively.
Hermann et al. present Combinatory Categorial Autoencoders to learn the compositionality
of sentence, which marries the Combinatory Categorial Grammar with Recursive Autoencoder.
The representation of words heavily relies on
the applications or tasks in which it is used .
This paper focuses
on learning sentiment-speciﬁc word embedding,
which is tailored for sentiment analysis.
Unlike Maas et al. that follow the probabilistic document model and
give an sentiment predictor function to each word,
we develop neural networks and map each ngram to the sentiment polarity of sentence. Unlike Socher et al. that utilize manually
labeled texts to learn the meaning of phrase (or
sentence) through compositionality, we focus on
learning the meaning of word, namely word embedding, from massive distant-supervised tweets.
Unlike Labutov and Lipson that produce
task-speciﬁc embedding from an existing word
embedding, we learn sentiment-speciﬁc word embedding from scratch.
Sentiment-Speciﬁc Word Embedding
for Twitter Sentiment Classiﬁcation
In this section, we present the details of learning sentiment-speciﬁc word embedding (SSWE)
for Twitter sentiment classiﬁcation.
We propose incorporating the sentiment information of
sentences to learn continuous representations for
words and phrases. We extend the existing word
embedding learning algorithm and develop three neural networks to learn
SSWE. In the following sections, we introduce the
traditional method before presenting the details of
SSWE learning algorithms. We then describe the
use of SSWE in a supervised learning framework
for Twitter sentiment classiﬁcation.
Collobert et al. introduce C&W model to
learn word embedding based on the syntactic contexts of words. Given an ngram “cat chills on a
mat”, C&W replaces the center word with a random word wr and derives a corrupted ngram “cat
chills wr a mat”. The training objective is that the
original ngram is expected to obtain a higher language model score than the corrupted ngram by a
margin of 1. The ranking objective function can
be optimized by a hinge loss,
losscw(t, tr) = max(0, 1 −fcw(t) + fcw(tr))
where t is the original ngram, tr is the corrupted
ngram, fcw(·) is a one-dimensional scalar representing the language model score of the input ngram. Figure 1(a) illustrates the neural architecture of C&W, which consists of four layers, namely lookup →linear →hTanh →linear (from
bottom to top). The original and corrupted ngrams are treated as inputs of the feed-forward neural
network, respectively. The output fcw is the language model score of the input, which is calculated as given in Equation 2, where L is the lookup
table of word embedding, w1, w2, b1, b2 are the parameters of linear layers.
fcw(t) = w2(a) + b2
so cooool :D
so cooool :D
so cooool :D
Figure 1: The traditional C&W model and our neural networks (SSWEh and SSWEu) for learning
sentiment-speciﬁc word embedding.
a = hTanh(w1Lt + b1)
hTanh(x) =
if −1 ≤x ≤1
Sentiment-Speciﬁc Word Embedding
Following the traditional C&W model , we incorporate the sentiment information into the neural network to learn sentimentspeciﬁc word embedding. We develop three neural
networks with different strategies to integrate the
sentiment information of tweets.
Basic Model 1 (SSWEh).
As an unsupervised
approach, C&W model does not explicitly capture
the sentiment information of texts. An intuitive
solution to integrate the sentiment information is
predicting the sentiment distribution of text based
on input ngram. We do not utilize the entire sentence as input because the length of different sentences might be variant. We therefore slide the
window of ngram across a sentence, and then predict the sentiment polarity based on each ngram
with a shared neural network. In the neural network, the distributed representation of higher layer are interpreted as features describing the input.
Thus, we utilize the continuous vector of top layer
to predict the sentiment distribution of text.
Assuming there are K labels, we modify the dimension of top layer in C&W model as K and
add a softmax layer upon the top layer.
neural network (SSWEh) is given in Figure 1(b).
Softmax layer is suitable for this scenario because its outputs are interpreted as conditional
probabilities. Unlike C&W, SSWEh does not generate any corrupted ngram. Let f g(t), where K
denotes the number of sentiment polarity labels, be the gold K-dimensional multinomial distribution of input t and P
k(t) = 1. For positive/negative classiﬁcation, the distribution is of
the form for positive and for negative.
The cross-entropy error of the softmax layer is :
lossh(t) = −
k(t) · log(f h
where f g(t) is the gold sentiment distribution and
f h(t) is the predicted sentiment distribution.
Basic Model 2 (SSWEr).
SSWEh is trained by
predicting the positive ngram as and the negative ngram as . However, the constraint of
SSWEh is too strict. The distribution of [0.7,0.3]
can also be interpreted as a positive label because
the positive score is larger than the negative score. Similarly, the distribution of [0.2,0.8] indicates negative polarity. Based on the above observation, the hard constraints in SSWEh should be
relaxed. If the sentiment polarity of a tweet is positive, the predicted positive score is expected to be
larger than the predicted negative score, and the
exact reverse if the tweet has negative polarity.
We model the relaxed constraint with a ranking objective function and borrow the bottom four
layers from SSWEh, namely lookup →linear →
hTanh →linear in Figure 1(b), to build the relaxed neural network (SSWEr). Compared with
SSWEh, the softmax layer is removed because
SSWEr does not require probabilistic interpretation. The hinge loss of SSWEr is modeled as de-
scribed below.
lossr(t) = max(0, 1 −δs(t)f r
+ δs(t)f r
0 is the predicted positive score, f r
the predicted negative score, δs(t) is an indicator
function reﬂecting the sentiment polarity of a sentence,
if f g(t) = 
if f g(t) = 
Similar with SSWEh, SSWEr also does not generate the corrupted ngram.
Uniﬁed Model (SSWEu).
The C&W model
learns word embedding by modeling syntactic
contexts of words but ignoring sentiment information. By contrast, SSWEh and SSWEr learn
sentiment-speciﬁc word embedding by integrating
the sentiment polarity of sentences but leaving out
the syntactic contexts of words. We develop a uni-
ﬁed model (SSWEu) in this part, which captures
the sentiment information of sentences as well as
the syntactic contexts of words. SSWEu is illustrated in Figure 1(c).
Given an original (or corrupted) ngram and
the sentiment polarity of a sentence as the input, SSWEu predicts a two-dimensional vector for
each input ngram. The two scalars (f u
1 ) stand for language model score and sentiment score of the input ngram, respectively. The training
objectives of SSWEu are that (1) the original ngram should obtain a higher language model score
0 (t) than the corrupted ngram f u
0 (tr), and (2) the
sentiment score of original ngram f u
1 (t) should be
more consistent with the gold polarity annotation
of sentence than corrupted ngram f u
1 (tr). The loss
function of SSWEu is the linear combination of two hinge losses,
lossu(t, tr) = α · losscw(t, tr)+
(1 −α) · lossus(t, tr)
where losscw(t, tr) is the syntactic loss as given
in Equation 1, lossus(t, tr) is the sentiment loss
as described in Equation 9. The hyper-parameter
α weighs the two parts.
lossus(t, tr) = max(0, 1 −δs(t)f u
+ δs(t)f u
Model Training.
We train sentiment-speciﬁc
word embedding from massive distant-supervised
tweets collected with positive and negative emoticons1. We crawl tweets from April 1st, 2013 to
April 30th, 2013 with TwitterAPI. We tokenize
each tweet with TwitterNLP ,
remove the @user and URLs of each tweet, and ﬁlter the tweets that are too short (< 7 words). Finally, we collect 10M tweets, selected by 5M tweets
with positive emoticons and 5M tweets with negative emoticons.
We train SSWEh, SSWEr and SSWEu by
taking the derivative of the loss through backpropagation with respect to the whole set of parameters , and use Ada-
Grad to update the parameters. We empirically set the window size as 3, the
embedding length as 50, the length of hidden layer as 20 and the learning rate of AdaGrad as 0.1
for all baseline and our models. We learn embedding for unigrams, bigrams and trigrams separately with same neural network and same parameter
setting. The contexts of unigram (bigram/trigram)
are the surrounding unigrams (bigrams/trigrams),
respectively.
Twitter Sentiment Classiﬁcation
We apply sentiment-speciﬁc word embedding for
Twitter sentiment classiﬁcation under a supervised
learning framework as in previous work . Instead of hand-crafting features, we
incorporate the continuous representation of words and phrases as the feature of a tweet. The sentiment classiﬁer is built from tweets with manually
annotated sentiment polarity.
We explore min, average and max convolutional layers , which have been used as simple and
effective methods for compositionality learning
in vector-based semantics , to obtain the tweet representation. The result is the concatenation of vectors derived from
different convolutional layers.
z(tw) = [zmax(tw), zmin(tw), zaverage(tw)]
where z(tw) is the representation of tweet tw and
zx(tw) is the results of the convolutional layer x ∈
{min, max, average}. Each convolutional layer
1We use the emoticons selected by Hu et al. . The
positive emoticons are :) : ) :-) :D =), and the negative emoticons are :( : ( :-( .
zx employs the embedding of unigrams, bigrams
and trigrams separately and conducts the matrixvector operation of x on the sequence represented
by columns in each lookup table. The output of
zx is the concatenation of results obtained from
different lookup tables.
zx(tw) = [wx⟨Luni⟩tw, wx⟨Lbi⟩tw, wx⟨Ltri⟩tw]
where wx is the convolutional function of zx,
⟨L⟩tw is the concatenated column vectors of the
words in the tweet. Luni, Lbi and Ltri are the
lookup tables of the unigram, bigram and trigram
embedding, respectively.
Experiment
We conduct experiments to evaluate SSWE by incorporating it into a supervised learning framework for Twitter sentiment classiﬁcation. We also
directly evaluate the effectiveness of the SSWE by
measuring the word similarity in the embedding
space for sentiment lexicons.
Twitter Sentiment Classiﬁcation
Experiment Setup and Datasets.
We conduct
experiments on the latest Twitter sentiment classiﬁcation benchmark dataset in SemEval 2013
 . The training and development sets were completely in full to task participants. However, we were unable to download all
the training and development sets because some
tweets were deleted or not available due to modiﬁed authorization status. The test set is directly
provided to the participants. The distribution of
our dataset is given in Table 1. We train sentiment
classiﬁer with LibLinear on the
training set, tune parameter −c on the dev set and
evaluate on the test set. Evaluation metric is the
Macro-F1 of positive and negative categories 2.
Table 1: Statistics of the SemEval 2013 Twitter
sentiment classiﬁcation dataset.
2We investigate 2-class Twitter sentiment classiﬁcation (positive/negative) instead of 3-class Twitter sentiment
classiﬁcation (positive/negative/neutral) in SemEval2013.
Baseline Methods.
We compare our method
with the following sentiment classiﬁcation algorithms:
(1) DistSuper: We use the 10 million tweets selected by positive and negative emoticons as training data, and build sentiment classiﬁer with Lib-
Linear and ngram features .
(2) SVM: The ngram features and Support Vector Machine are widely used baseline methods to
build sentiment classiﬁers . LibLinear is used to train the SVM classiﬁer.
(3) NBSVM: NBSVM is a state-of-the-art performer on many sentiment classiﬁcation datasets, which trades-off between Naive Bayes and NB-enhanced SVM.
(4) RAE: Recursive Autoencoder has been proven effective in many sentiment analysis tasks by learning compositionality
automatically. We run RAE with randomly initialized word embedding.
(5) NRC: NRC builds the top-performed system
in SemEval 2013 Twitter sentiment classiﬁcation
track which incorporates diverse sentiment lexicons and many manually designed features. We
re-implement this system because the codes are
not publicly available 3. NRC-ngram refers to the
feature set of NRC leaving out ngram features.
Except for DistSuper, other baseline methods are conducted in a supervised manner. We do
not compare with RNTN because we cannot efﬁciently train the RNTN model.
The reason lies in that the tweets in our dataset do
not have accurately parsed results or ﬁne grained
sentiment labels for phrases. Another reason is
that the RNTN model trained on movie reviews
cannot be directly applied on tweets due to the differences between domains .
Results and Analysis.
Table 2 shows the macro-
F1 of the baseline systems as well as the SSWEbased methods on positive/negative sentiment classiﬁcation of tweets. Distant supervision is
relatively weak because the noisy-labeled tweets are treated as the gold standard, which affects
the performance of classiﬁer. The results of bagof-ngram (uni/bi/tri-gram) features are not satis-
ﬁed because the one-hot word representation cannot capture the latent connections between words.
NBSVM and RAE perform comparably and have
3For 3-class sentiment classiﬁcation in SemEval 2013,
our re-implementation of NRC achieved 68.3%, 0.7% lower than NRC (69%) due to less training data.
DistSuper + unigram
DistSuper + uni/bi/tri-gram
SVM + unigram
SVM + uni/bi/tri-gram
NRC (Top System in SemEval)
NRC - ngram
SSWEu+NRC-ngram
Table 2: Macro-F1 on positive/negative classiﬁcation of tweets.
a big gap in comparison with the NRC and SSWEbased methods. The reason is that RAE and NB-
SVM learn the representation of tweets from the
small-scale manually annotated training set, which
cannot well capture the comprehensive linguistic
phenomenons of words.
NRC implements a variety of features and
reaches 84.73% in macro-F1, verifying the importance of a better feature representation for Twitter sentiment classiﬁcation. We achieve 84.98%
by using only SSWEu as features without borrowing any sentiment lexicons or hand-crafted rules.
The results indicate that SSWEu automatically
learns discriminative features from massive tweets
and performs comparable with the state-of-the-art
manually designed features. After concatenating
SSWEu with the feature set of NRC, the performance is further improved to 86.58%. We also
compare SSWEu with the ngram feature by integrating SSWE into NRC-ngram. The concatenated
features SSWEu+NRC-ngram (86.48%) outperform the original feature set of NRC (84.73%).
As a reference, we apply SSWEu on subjective classiﬁcation of tweets, and obtain 72.17% in
macro-F1 by using only SSWEu as feature. After combining SSWEu with the feature set of NR-
C, we improve NRC from 74.86% to 75.39% for
subjective classiﬁcation.
Comparision between Different Word Embedding.
We compare sentiment-speciﬁc word embedding (SSWEh, SSWEr, SSWEu) with baseline embedding learning algorithms by only using word embedding as features for Twitter sentiment classiﬁcation. We use the embedding of unigrams, bigrams and trigrams in the experiment.
The embeddings of C&W , word2vec4, WVSA and
our models are trained with the same dataset and
same parameter setting. We compare with C&W
and word2vec as they have been proved effective
in many NLP tasks. The trade-off parameter of
ReEmb is tuned on
the development set of SemEval 2013.
Table 3 shows the performance on the positive/negative classiﬁcation of tweets5.
ReEmb(C&W) and ReEmb(w2v) stand for the use
of embeddings learned from 10 million distantsupervised tweets with C&W and word2vec, respectively. Each row of Table 3 represents a word
embedding learning algorithm. Each column stands for a type of embedding used to compose
features of tweets. The column uni+bi denotes the
use of unigram and bigram embedding, and the
column uni+bi+tri indicates the use of unigram,
bigram and trigram embedding.
uni+bi+tri
ReEmb(C&W)
ReEmb(w2v)
Table 3: Macro-F1 on positive/negative classiﬁcation of tweets with different word embeddings.
From the ﬁrst column of Table 3, we can see that
the performance of C&W and word2vec are obviously lower than sentiment-speciﬁc word embeddings by only using unigram embedding as features. The reason is that C&W and word2vec do
not explicitly exploit the sentiment information of
the text, resulting in that the words with opposite polarity such as good and bad are mapped
to close word vectors. When such word embeddings are fed as features to a Twitter sentiment classiﬁer, the discriminative ability of sentiment
words are weakened thus the classiﬁcation performance is affected. Sentiment-speciﬁc word em-
4Available at We
utilize the Skip-gram model because it performs better than
CBOW in our experiments.
5MVSA and ReEmb are not suitable for learning bigram
and trigram embedding because their sentiment predictor
functions only utilize the unigram embedding.
beddings (SSWEh, SSWEr, SSWEu) effectively
distinguish words with opposite sentiment polarity
and perform best in three settings. SSWE outperforms MVSA by exploiting more contextual information in the sentiment predictor function. SSWE
outperforms ReEmb by leveraging more sentiment information from massive distant-supervised
tweets. Among three sentiment-speciﬁc word embeddings, SSWEu captures more context information and yields best performance.
SSWEr obtain comparative results.
From each row of Table 3, we can see that the
bigram and trigram embeddings consistently improve the performance of Twitter sentiment classi-
ﬁcation. The underlying reason is that a phrase,
which cannot be accurately represented by unigram embedding, is directly encoded into the ngram embedding as an idiomatic unit. A typical
case in sentiment analysis is that the composed
phrase and multiword expression may have a different sentiment polarity than the individual words it contains, such as not [bad] and [great] deal
of (the word in the bracket has different sentiment
polarity with the ngram). A very recent study by
Mikolov et al. also veriﬁed the effectiveness of phrase embedding for analogically reasoning phrases.
Effect of α in SSWEu
We tune the hyperparameter α of SSWEu on the development set by
using unigram embedding as features. As given
in Equation 8, α is the weighting score of syntactic loss of SSWEu and trades-off the syntactic and
sentiment losses. SSWEu is trained from 10 million distant-supervised tweets.
Figure 2: Macro-F1 of SSWEu on the development set of SemEval 2013 with different α.
Figure 2 shows the macro-F1 of SSWEu on positive/negative classiﬁcation of tweets with different α on our development set. We can see that
SSWEu performs better when α is in the range
of [0.5, 0.6], which balances the syntactic context
and sentiment information. The model with α=1
stands for C&W model, which only encodes the
syntactic contexts of words. The sharp decline at
α=1 reﬂects the importance of sentiment information in learning word embedding for Twitter sentiment classiﬁcation.
Effect of Distant-supervised Data in SSWEu
We investigate how the size of the distantsupervised data affects the performance of SSWEu
feature for Twitter sentiment classiﬁcation.
vary the number of distant-supervised tweets from
1 million to 12 million, increased by 1 million.
We set the α of SSWEu as 0.5, according to the
experiments shown in Figure 2. Results of positive/negative classiﬁcation of tweets on our development set are given in Figure 3.
# of distant−supervised tweets
Figure 3: Macro-F1 of SSWEu with different size
of distant-supervised data on our development set.
We can see that when more distant-supervised
tweets are added, the accuracy of SSWEu consistently improves. The underlying reason is that
when more tweets are incorporated, the word embedding is better estimated as the vocabulary size
is larger and the context and sentiment information are richer. When we have 10 million distantsupervised tweets, the SSWEu feature increases
the macro-F1 of positive/negative classiﬁcation of
tweets to 82.94% on our development set. When
we have more than 10 million tweets, the performance remains stable as the contexts of words
have been mostly covered.
Word Similarity of Sentiment Lexicons
The quality of SSWE has been implicitly evaluated when applied in Twitter sentiment classiﬁcation
in the previous subsection. We explicitly evaluate
it in this section through word similarity in the em-
bedding space for sentiment lexicons. The evaluation metric is the accuracy of polarity consistency
between each sentiment word and its top N closest
words in the sentiment lexicon,
Accuracy =
j=1 β(wi, cij)
where #Lex is the number of words in the sentiment lexicon, wi is the i-th word in the lexicon, cij
is the j-th closest word to wi in the lexicon with cosine similarity, β(wi, cij) is an indicator function
that is equal to 1 if wi and cij have the same sentiment polarity and 0 for the opposite case. The
higher accuracy refers to a better polarity consistency of words in the sentiment lexicon. We set N
as 100 in our experiment.
Experiment Setup and Datasets
We utilize
the widely-used sentiment lexicons, namely M-
PQA and HL , to evaluate the quality of word embedding.
For each lexicon, we remove the words that do
not appear in the lookup table of word embedding.
We only use unigram embedding in this section
because these sentiment lexicons do not contain
phrases. The distribution of the lexicons used in
this paper is listed in Table 4.
Table 4: Statistics of the sentiment lexicons. Joint stands for the words that occur in both HL and
MPQA with the same sentiment polarity.
compared to other word embedding learning algorithms.
The accuracy of random result is
50% as positive and negative words are randomly occurred in the nearest neighbors of
each word.
Sentiment-speciﬁc word embeddings (SSWEh, SSWEr, SSWEu) outperform existing neural models (C&W, word2vec) by large
margins. SSWEu performs best in three lexicons. SSWEh and SSWEr have comparable performances. Experimental results further demonstrate
that sentiment-speciﬁc word embeddings are able
to capture the sentiment information of texts and
distinguish words with opposite sentiment polarity, which are not well solved in traditional neural
ReEmb(C&W)
ReEmb(w2v)
Table 5: Accuracy of the polarity consistency of
words in different sentiment lexicons.
models like C&W and word2vec. SSWE outperforms MVSA and ReEmb by exploiting more context information of words and sentiment information of sentences, respectively.
Conclusion
In this paper, we propose learning continuous
word representations as features for Twitter sentiment classiﬁcation under a supervised learning
framework. We show that the word embedding
learned by traditional neural networks are not effective enough for Twitter sentiment classiﬁcation.
These methods typically only model the context information of words so that they cannot distinguish words with similar context but opposite
sentiment polarity (e.g. good and bad). We learn
sentiment-speciﬁc word embedding (SSWE) by
integrating the sentiment information into the loss
functions of three neural networks. We train SS-
WE with massive distant-supervised tweets selected by positive and negative emoticons. The effectiveness of SSWE has been implicitly evaluated by using it as features in sentiment classiﬁcation on the benchmark dataset in SemEval 2013,
and explicitly veriﬁed by measuring word similarity in the embedding space for sentiment lexicons. Our uniﬁed model combining syntactic context
of words and sentiment information of sentences
yields the best performance in both experiments.
Acknowledgments
We thank Yajuan Duan, Shujie Liu, Zhenghua Li,
Li Dong, Hong Sun and Lanjun Zhou for their
great help.
This research was partly supported
by National Natural Science Foundation of China
(No.61133012, No.61273321, No.61300113).