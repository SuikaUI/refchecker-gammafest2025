NBER TECHNICAL WORKING PAPER SERIES
SYNTHETIC CONTROL METHODS FOR COMPARATIVE CASE STUDIES:
ESTIMATING THE EFFECT OF CALIFORNIA'S TOBACCO CONTROL PROGRAM
Alberto Abadie
Alexis Diamond
Jens Hainmueller
Technical Working Paper 335
 
NATIONAL BUREAU OF ECONOMIC RESEARCH
1050 Massachusetts Avenue
Cambridge, MA 02138
January 2007
All authors are affiliated with Harvard's Institute for Quantitative Social Science (IQSS). We thank
Jake Bowers, Dan Hopkins, and seminar participants at the 2006 APSA Meetings in Philadelphia for
helpful comments. Funding for this research was generously provided by NSF grant SES-0350645
(Abadie). The views expressed herein are those of the author(s) and do not necessarily reflect the views
of the National Bureau of Economic Research.
© 2007 by Alberto Abadie, Alexis Diamond, and Jens Hainmueller. All rights reserved. Short sections
of text, not to exceed two paragraphs, may be quoted without explicit permission provided that full
credit, including © notice, is given to the source.
Synthetic Control Methods for Comparative Case Studies: Estimating the Effect of California's
Tobacco Control Program
Alberto Abadie, Alexis Diamond, and Jens Hainmueller
NBER Technical Working Paper No. 335
January 2007, Revised July 2007
JEL No. C21,C23,H75,I18,K32
Building on an idea in Abadie and Gardeazabal , this article investigates the application of synthetic
control methods to comparative case studies. We discuss the advantages of these methods and apply
them to study the effects of Proposition 99, a large-scale tobacco control program that California implemented
in 1988. We demonstrate that following Proposition 99 tobacco consumption fell markedly in California
relative to a comparable synthetic control region. We estimate that by the year 2000 annual per-capita
cigarette sales in California were about 26 packs lower than what they would have been in the absence
of Proposition 99. Given that many policy interventions and events of interest in social sciences take
place at an aggregate level (countries, regions, cities, etc.) and affect a small number of aggregate
units, the potential applicability of synthetic control methods to comparative case studies is very large,
especially in situations where traditional regression methods are not appropriate. The methods proposed
in this article produce informative inference regardless of the number of available comparison units,
the number of available time periods, and whether the data are individual (micro) or aggregate (macro).
Software to compute the estimators proposed in this article is available at the authors' web-pages.
Alberto Abadie
John F. Kennedy School of Government
Harvard University
79 JFK Street
Cambridge, MA 02138
 
Alexis Diamond
Political Economy and Government
Harvard University
1737 Cambridge Street
Cambridge, MA 02138
 
Jens Hainmueller
Department of Government
Harvard University
1737 Cambridge Street
Cambridge, MA 02138
 
Introduction
Economists and other social scientists are often interested in the eﬀects of events or policy
interventions that take place at an aggregate level and aﬀect aggregate entities, such as
ﬁrms, schools, or geographic or administrative areas (countries, regions, cities, etc.). To
estimate the eﬀects of these events or interventions, researchers often use comparative
case studies. In comparative case studies, researchers estimate the evolution of aggregate
outcomes (such as mortality rates, average income, crime rates, etc.) for a unit aﬀected
by a particular occurrence of the event or intervention of interest and compare it to the
evolution of the same aggregates estimated for some control group of unaﬀected units. Card
 studies the impact of the 1980 Mariel Boatlift, a large and sudden Cuban migratory
inﬂux in Miami, using other cities in the southern United States as a comparison group.
In a well-known study of the eﬀects of minimum wages on employment, Card and Krueger
 compare the evolution of employment in fast-food restaurants in New Jersey and its
neighboring state Pennsylvania around the time of an increase in New Jersey’s minimum
wage. Abadie and Gardeazabal estimate the eﬀects of the terrorist conﬂict in the
Basque Country on the Basque economy using other Spanish regions as a comparison group.
Comparing the evolution of an aggregate outcome (e.g., state-level crime rate) between
a unit aﬀected by the event or intervention of interest and a set of unaﬀected units requires
only aggregate data, which are often available.
However, when data are not available
at the same level of aggregation as the outcome of interest, information on a sample of
disaggregated units can sometimes be used to estimate the aggregate outcomes of interest
 .1
Given the widespread availability of aggregate/macro data (for example, at the school,
city, or region level), and the fact that many policy interventions and events of interest in the
social sciences take place at an aggregate level, comparative case study research has broad
1Card uses individual-level data from the U.S. Current Population Survey to estimate the unemployment rates of native workers in Miami and a group of comparison cities before and after the arrival
of the Mariel expatriates to Miami in 1980. Card and Krueger use a telephone survey of fast-food
restaurants in New Jersey and Pennsylvania to estimate average wages and employment in the fast-food
industry in those two states around the time of the increase in minimum wage in New Jersey in 1992.
potential. However, comparative case study research remains limited in economics and
other social sciences, perhaps because its empirical implementation is subject to two elusive
problems. First, in comparative case studies there is typically some degree of ambiguity
about how comparison units are chosen. Researchers often select comparison groups on
the basis of subjective measures of aﬃnity between aﬀected and unaﬀected units. Second,
comparative case studies typically employ data on a sample of disaggregated units and
inferential techniques that measure only uncertainty about the aggregate values of the data
in the population. Uncertainty about the values of aggregate variables can be eliminated
completely if aggregate data are available. However, the availability of aggregate data does
not imply that the eﬀect of the event or intervention of interest can be estimated without
error. Even if aggregate data are employed, there remains uncertainty about the ability
of the control group to reproduce the counterfactual outcome trajectory that the aﬀected
units would have experienced in the absence of the intervention or event of interest. This
type of uncertainty is not reﬂected by the standard errors constructed with traditional
inferential techniques for comparative case studies.
This article addresses current methodological shortcomings of case study analysis. We
advocate the use of data-driven procedures to construct suitable comparison groups, as in
Abadie and Gardeazabal . Data-driven procedures reduce discretion in the choice of
the comparison control units, forcing researchers to demonstrate the aﬃnities between the
aﬀected and unaﬀected units using observed quantiﬁable characteristics. In practice, however, it is often diﬃcult to ﬁnd a single unexposed unit that approximates the most relevant
characteristics of the unit(s) exposed to the event of interest. The idea behind the synthetic
control approach is that a combination of regions often provides a better comparison for
the region exposed to the intervention than any single region alone. For example, in their
study of the economic impact of terrorism in the Basque Country, Abadie and Gardeazabal use a combination of two Spanish regions to approximate the economic growth
that the Basque Country would have experienced in the absence of terrorism. Card 
implicitly uses a combination of cities in the southern United States to approximate the
evolution that the Miami labor market would have experienced in the absence of the Mariel
Relative to traditional regression methods, transparency and safeguard against extrapolation are two attractive features of the synthetic control method. Because a synthetic
control is a weighted average of the available control units, the synthetic control method
makes explicit (1) the relative contribution of each control unit to the counterfactual of
interest; and (2) the similarities (or lack thereof) between the unit aﬀected by the event
or intervention of interest and the synthetic control, in terms of pre-intervention outcomes
and other predictors of post-intervention outcomes. Because the weights can be restricted
to be positive and sum to one, the synthetic control method provides a safeguard against
extrapolation.
In addition, because the choice of a synthetic control does not require access to postintervention outcomes, the synthetic control method allows researchers to decide on study
design without knowing how those decisions will aﬀect the conclusions of their studies.
Rubin and others have advocated that the ability to make decisions on research
design while remaining blind to how each particular decision aﬀects the conclusions of the
study is an important device for promoting research honesty in observational studies.
We describe a simple econometric model that justiﬁes the synthetic control approach
and demonstrate that the conditions of the model are more general than the conditions
under which traditional linear panel data or diﬀerence-in-diﬀerences estimators are valid. In
addition, we propose new methods that allow researchers to perform inferential exercises
about the eﬀects of the event or intervention of interest that are valid regardless of the
number of available comparison units, the number of available time periods, and whether
aggregate or individual data are used for the analysis.
We apply the synthetic control method to study the eﬀects of California’s Proposition
99, a large-scale tobacco control program implemented in California in 1988. We demonstrate that following the passage of Proposition 99 tobacco consumption fell markedly in
California relative to a comparable synthetic control region. We estimate that, by the year
2000, annual per-capita cigarette sales in California were about 26 packs lower than what
they would have been in the absence of Proposition 99. Using new inferential methods
proposed in this paper, we demonstrate the statistical signiﬁcance of our estimates.
Cross-country regressions are often criticized because they put countries side-by-side
regardless of whether they have similar or radically diﬀerent characteristics . The synthetic control method provides an appealing data-driven
procedure to select comparison groups for the study of the eﬀects of events or interventions
that take place at the level of a country. To illustrate the application of the techniques
proposed in this article to cross-country data, we include an appendix where we use the
synthetic control method to estimate the impact of the 1990 German re-uniﬁcation on the
West German economy.
The rest of the article is organized as follows. Section II describes the main ideas behind
the synthetic control approach to comparative case studies of aggregate events. In section
III we apply synthetic control methods to estimate the eﬀect of California’s Proposition
99. Section IV concludes. Appendix A lists the data sources for the application in section
III. Appendix B contains the application of the synthetic control method to the study of
the economic eﬀects of the German reuniﬁcation. Appendix C contains technical details.
Synthetic Control Methods for Comparative Case Studies
A. Comparative Case Studies
Case studies focus on particular occurrences of the events or interventions of interest. Often,
the motivation behind case studies is to detect the eﬀects of an event or policy intervention
on some outcome of interest by focusing on a particular instance in which the magnitude
of the event or intervention is large relative to other determinants of the outcome, or in
which identiﬁcation of the eﬀects of interest is facilitated by some other characteristic of
the intervention. For example, in his classic study of the economic impact of immigration,
Card analyzes the behavior of the Miami labor market in the wake of the 1980 Mariel
Boatlift, when the Mariel immigrants increased the size of the labor force in Miami by 7
percent in a matter of a few months. In comparative case studies, researchers compare units
aﬀected by the event or intervention of interest to a group of unaﬀected units. Therefore,
comparative case studies are only feasible when some units are exposed and others are not
(or when their levels of exposure diﬀer notably).2
To simplify the exposition, we proceed as if only one unit or region is subject to the
intervention of interest.3 In addition, we adopt the terms “region” or “unit” and “intervention” or “treatment”, which can be substituted for “country”, “state”, “city”, etc. and
“event”, “shock”, “law”, etc., respectively for speciﬁc applications.
B. A Motivating Model
The following simple model provides a rationale for the use of synthetic control methods in
comparative case study research. Suppose that we observe J + 1 regions. Without loss of
generality, suppose also that only the ﬁrst region is exposed to the intervention of interest,
so that we have J remaining regions as potential controls. Also without loss of generality
and to simplify notation, we assume that the ﬁrst region is uninterruptedly exposed to the
intervention of interest after some initial intervention period.
it be the outcome that would be observed for region i at time t in the absence of the
intervention, for units i = 1, . . . , J + 1, and time periods t = 1, . . . , T. Let T0 be number of
pre-intervention periods, with 1 ≤T0 < T. Let Y I
it be the outcome that would be observed
for unit i at time t if unit i is exposed to the intervention in periods T0+1 to T. We assume
that the intervention has no eﬀect on the outcome before the implementation period, so
for t ∈{1, . . . , T0} and all i ∈{1, . . . , N}, we have that Y I
it .4 Let αit = Y I
the eﬀect of the intervention for unit i at time t, if unit i is exposed to the intervention in
2In comparative case studies, the main emphasis is sometimes on identiﬁcation of the impact of the
particular event or intervention on hand (internal validity), at the cost of limited immediate generalizability
to other settings (external validity). In other instances, as in the Card and Krueger study on the
employment eﬀects of a minimum wage raise, cases studies are used to test hypotheses previously derived
from theoretical models.
3Otherwise, we could ﬁrst aggregate the data from the regions exposed to the intervention.
4Of course, this is done without loss of generality. If the anticipation of the intervention impacts the
outcome before the intervention is implemented, we can always redeﬁne T0 to be the ﬁrst period in which
the outcome may possibly react to the (anticipated) intervention.
periods T0 + 1, T0 + 2, . . . , T (where 1 ≤T0 < T). Therefore:
Let Dit be an indicator that takes value one if unit i is exposed to the intervention at time
t, and value zero otherwise. The observed outcome for unit i at time t is
it + αitDit.
Because only the ﬁrst region (region “one”) is exposed to the intervention and only after
period T0 (with 1 ≤T0 < T), we have that:
if i = 1 and t > T0,
otherwise.
We aim to estimate (α1T0+1, . . . , α1T). For t > T0,
1t = Y1t −Y N
Because Y I
1t is observed, to estimate α1t we just need to estimate Y N
1t . Suppose that Y N
given by a factor model:
it = δt + θtZi + λtµi + εit,
where δt is an unknown common factor with constant factor loadings across units, Zi is a
(r ×1) vector of observed covariates (not aﬀected by the intervention), θt is a (1×r) vector
of unknown parameters, λt is an unknown common factor with varying factor loadings, µi,
across units, and the error terms εit are unobserved transitory shocks at the region level
with zero mean for all i.
It is important to notice that this model does not rule out the existence of time-varying
measured determinants of Y N
it . The vector Zi may contain pre- and post-intervention values
of time-varying variables, as long as they are not aﬀected by the intervention. For example,
suppose that T = 2, T0 = 1, and that Zit is a scalar random variable for i = 1, . . . , J + 1
and t = 1, 2. Then, if Zi = (Zi1 Zi2)′, θ1 = (β 0) and θ2 = (0 β), we obtain θtZi = Zitβ.
Notice also that the model in (1) does not restrict Zi, µi, and εit to be independent.
Consider a (J × 1) vector of weights W = (w2, . . . , wJ+1)′ such that wj ≥0 for j =
2, . . . , J + 1 and w2 + · · · + wJ+1 = 1. Each particular value of the vector W represents a
potential synthetic control, that is, a particular weighted average of control regions. The
value of the outcome variable for each synthetic control indexed by W is:
wjYjt = δt + θt
Let the (T0 × 1) vector K = (k1, . . . , kT0)′ deﬁne a linear combination of pre-intervention
outcomes: ¯Y K
s=1 ksYis. To simplify the exposition, consider ﬁrst the case: k1 = k2 =
· · · = kT0 = 1/T0. Then, ¯Y K
s=1 Yis is just the simple average of the outcome
variable for the pre-intervention periods.
Suppose that we can choose (w∗
2, . . . , w∗
J+1)′ such that:
Then, it is easy to see that, if PT0
s=1 λs/T0 ̸= 0, then,
(εjs −ε1s) −
j(εjt −ε1t).
Appendix C shows that, under standard conditions, the average of the right hand side of
equation (3) will be close to zero if the number of pre-intervention periods is large relative
to the scale of the transitory shocks. This suggests using
bα1t = Y1t −
for t ∈{T0 + 1, . . . , T} as an estimator of α1t.
Equation (2) can hold exactly only if (¯Y K
1 , Z1) belongs to the convex hull of {(¯Y K
. . . , (¯Y K
J+1, ZJ+1)}. In practice, it is often the case that no set of weights exists such that
equation (2) holds exactly in the data. Then, the synthetic control region is selected so
that equation (2) holds approximately.
This simple model can be easily extended in several directions. Notice ﬁrst that equation
(1) assumes the existence of a single unobserved factor. Multiple unobserved factors can
be controlled for by using as many (linearly independent) combinations of pre-intervention
outcomes in the ﬁrst part of equation (2), instead of a single one, to select the synthetic
control. If M linear combinations of pre-intervention outcomes, ¯Y K1
, . . . , ¯Y KM
, are used
to select the synthetic control, the ﬁrst part of equation (2) becomes, PJ+1
· · · PJ+1
Moreover, the simple linear model presented in this section does not need to hold over
the entire set of regions in any particular sample. Researchers trying to minimize biases
caused by interpolating across regions with very diﬀerent characteristics may restrict the
sample to regions with (¯Y K
j , Zj) suﬃciently close to (¯Y K
1 , Z1) under some distance metric.
As explained below, in contrast with more traditional regression methods, which typically
rely on asymptotic limit theorems for inference, the availability of a small number of regions
to construct the synthetic control does not invalidate our inferential procedures.
Notice that, even if taken at face value, equation (1) generalizes the usual diﬀerencein-diﬀerences (ﬁxed-eﬀects) model commonly applied in the empirical literature.
diﬀerence-in-diﬀerences model allows for the presence of unobserved confounders but restricts the eﬀect of those confounders to be constant in time.
In contrast, the model
presented in this section allows the eﬀects of confounding unobserved characteristics to
vary with time. Notice that the traditional diﬀerence-in-diﬀerences (ﬁxed-eﬀects) model
can be obtained if we impose that λt in equation (1) is constant for all t.
Synthetic controls can provide useful estimates in more general contexts than the factor
model considered so far. Consider, for example, the following autoregressive model with
time-varying coeﬃcients:
i t + βt+1 Zi t+1 + ui t+1,
i t + Πt Zi t + vi t+1,
where ui t+1 and vi t+1 have mean zero conditional on Ft = {Yj s, Zj s}1≤j≤N, s≤t. Suppose
that we can choose {w∗
j}2≤j≤N such that:
j Yj T0 = Y1 T0,
j Zj T0 = Z1 T0.
Then, it is easy to see that the synthetic control estimator is unbiased even if only data for
one pretreatment period are available.5
C. Implementation
Assume that there are J regions not exposed to the event or intervention of interest, so
they can serve as controls. We consider any weighted average of non-exposed regions as a
potential (synthetic) control. Let W be a (J ×1) vector of positive weights that sum to one.
That is, W = (w2, . . . , wJ+1)′ with wj ≥0 for j = 2, . . . , J +1 and w2+· · ·+wJ+1 = 1. Each
value of W represents a weighted average of the available control regions and, therefore, a
synthetic control.6
The outcome variable of interest is observed for T periods for the region aﬀected by
the intervention Y1t, (t = 1, . . . , T) and the unaﬀected regions Yjt, (j = 2, . . . , J + 1, t =
1, . . . , T). Let T0 be the number of pre-intervention periods and T1 = T −T0 the number
of post-intervention periods. Let Y1 be the (T1 × 1) vector of post-intervention outcomes
for the exposed region, and Y0 be the (T1 ×J) matrix of post-intervention outcomes for the
potential control regions.
Let X1 = (Z′
, . . . , ¯Y KM
)′ be a (k × 1) vector of pre-intervention characteristics for
the exposed region, with k = r+M. Similarly, X0 is a (k×J) matrix that contains the same
variables for the unaﬀected regions. That is, the j-th column of X0 is (Z′
, . . . , ¯Y KM
The vector W ∗is chosen to minimize some distance (or pseudo-distance), ∥X1 −X0W∥,
between X1 and X0W, subject to w2 ≥0, . . . wJ+1 ≥0, w2 + · · · + wJ+1 = 1. In particular,
we will consider ∥X1 −X0W∥V =
(X1 −X0W)′V (X1 −X0W), where V is some (k × k)
symmetric and positive semideﬁnite matrix, although other choices are also possible.7
5See Appendix C for details.
6Although we deﬁne our synthetic controls as convex combinations of unexposed units, negative weights
or weights larger than one can be used at the cost of allowing extrapolation. The severity of the extrapolation can be limited by specifying lower and upper bounds for the weights.
7If the relationship between the outcome variable and the explanatory variables in X1 and X0 is highly
nonlinear and the support of the explanatory variables is large, interpolation biases may be severe. In that
case, W ∗can be chosen to minimize ∥X1−X0W∥plus a set of penalty terms speciﬁed as increasing functions
of the distances between X1 and the corresponding values for the control units with positive weights in
W. Alternatively, as mentioned in section II.B, interpolation biases can be reduced by restricting the
comparison group to units that are similar to the exposed units in term of the values of X1.
Although our inferential procedures are valid for any choice of V , the choice of V inﬂuences the mean square error of the estimator (that is, the expectation of (Y1 −Y0W ∗)′(Y1 −
Y0W ∗)). Because V is symmetric and positive semideﬁnite, there exist two (k×k) matrices,
U and A, such that the rows of U, {un}k
n=1, form an orthonormal basis of Rk, A is diagonal
with all diagonal elements, {ann}k
n=1, equal or greater than zero, and V = U ′AU. As a result, the vector W ∗minimizes (H1 −H0W)′A(H1 −H0W), subject to w2 ≥0, . . . wJ+1 ≥0,
w2 + · · · + wJ+1 = 1, where H1 = UX1 and H0 = UX0. In other words, the matrix V assigns weight ann to the linear combination of characteristics in X0 and X1 with coeﬃcients
un. The optimal choice of V assigns weights to linear combination of the variables in X0
and X1 to minimize the mean square error of the synthetic control estimator. Sometimes
this choice can be based on subjective assessments of the predictive power of the variables
in X1 and X0. The choice of V can also be data-driven. One possibility is to choose V
such that the resulting synthetic control region approximates the trajectory of the outcome variable of aﬀected region in the pre-intervention periods. For example, Abadie and
Gardeazabal choose V among positive deﬁnite and diagonal matrices such that the
mean squared prediction error of the outcome variable is minimized for the pre-intervention
periods. Alternatively, if the number of available pre-intervention periods in the sample is
large enough, researchers may divide them into an initial training period and a subsequent
validation period. Given a V , W ∗(V ) can be computed using data from the training period.
Then, the matrix V can be chosen to minimize the mean squared prediction error produced
by the weights W ∗(V ) during the validation period.8
D. Inference
The standard errors commonly reported in regression-based comparative case studies measure uncertainty about aggregate data. For example, Card uses data from the U.S.
8In cases when little is known about the relative predictive power of the pre-intervention variables,
researchers may decide to normalize the variables in X0 and X1 using V equal to the inverse of the
estimated variance-covariance matrix of the variables in X0 and X1 (Mahalanobis distance) or equal to a
diagonal matrix with the elements in the main diagonal equal to the inverses of the sample variances of
the variables in in X0 and X1 (normalized Euclidean distance).
Current Population Survey to estimate native employment rates in Miami and a set of
comparison cities around the time of the Mariel Boatlift. Card and Krueger use
data on a sample of fast-food restaurants in New Jersey and Pennsylvania to estimate the
average number of employees in fast-food restaurants in these two states around the time
when the minimum wage was increased in New Jersey. The standard errors reported in
these studies reﬂect only the unavailability of aggregate data on employment (for native
workers in Miami and other cities, and in fast-food restaurants in New Jersey and Pennsylvania, respectively). This mode of inference would logically produce zero standard errors
if aggregate data were used for estimation. However, perfect knowledge of the value of
aggregate data does not reduce to zero our uncertainty about the parameters of interest.
That is, even if aggregate data are used for estimation, in most cases researchers would
not believe that there is no remaining uncertainty about the value of the parameters of
interest. The reason is that not all uncertainty about the value of the estimated parameters
come from lack of knowledge of aggregate data. In comparative case studies, an additional
source of uncertainty derives from our ignorance about the the ability of the control group
to reproduce the counterfactual of how the treated unit would have evolved in the absence
of the treatment. This type of uncertainty is present regardless of whether aggregate data
are used for estimation or not. The use of individual micro data, as opposed to aggregate
data, only increases the amount of uncertainty if the outcome of interest is an aggregate.
Large sample inferential techniques are not well-suited to comparative case studies when
the number of units in the comparison group and the number of periods in the sample are
relatively small. In this article, we propose exact inferential techniques, akin to permutation
tests, to perform inference in comparative case studies. The methods proposed here produce
informative inference regardless of the number of available comparison units, the number of
available time periods, and whether the data are individual (micro) or aggregate (macro).
However, the quality of some of the inferential exercises proposed in this article increases
with the number of available comparison units. The inferential techniques proposed in this
article extend Abadie and Gardeazabal in several directions.
In their study of the economic eﬀects of terrorism, Abadie and Gardeazabal use
a synthetic control region to estimate the economic growth that the Basque Country would
have experienced in the absence of terrorism. Starting in the late 1960’s, the Basque clandestine organization ETA implemented a terrorist campaign that lasted more than 30 years
and resulted in more than 800 deaths. Although terrorist attacks took place in almost every
region of Spain, most of the attacks and casualties occurred within the Basque Country.
To estimate the economic growth that the Basque Country would have experienced in the
absence of terrorism, Abadie and Gardeazabal construct a synthetic control region
as the combination of other regions in Spain that best reproduced the values of economic
growth predictors for the Basque Country at the start of the terrorist campaign. Abadie
and Gardeazabal show that, during the terrorism years, per capita income in the
synthetic Basque Country without terrorism was up to 12 percent higher than per capita
income in the actual Basque Country with terrorism. To assess the ability of the synthetic
control method to reproduce the evolution of a counterfactual Basque Country without
terrorism, Abadie and Gardeazabal introduce a placebo study, applying the same
techniques to Catalonia, a region similar to the Basque Country but with a much lower
exposure to terrorism. In contrast to the Basque Country, per capita income in the synthetic Catalonia closely tracked the observed per capita income in Catalonia. This exercise
demonstrates that a combination of other Spanish regions chosen to match the economic
characteristics of Catalonia before the outbreak of terrorism provides a suitable control for
Catalonia.
In this paper, we extend the idea of a placebo study to produce quantitative inference
in comparative case studies.
As in classical permutation tests, we apply the synthetic
control method to every potential control in our sample. This allows us to assess whether
the eﬀect estimated by the synthetic control for the region aﬀected by the intervention is
large relative to the eﬀect estimated for a region chosen at random. By construction, this
exercise produces exact inference regardless of the number of available comparison regions,
time periods, and whether the data are individual or aggregate. However, inference becomes
more informative if the number of potential comparison regions is large.
For cases in which the number of available comparison regions is small, one can use the
longitudinal dimension of the data to produce additional placebo studies, as in Bertrand,
Duﬂo, and Mullainathan where the dates of the placebo interventions are set at
random.9, 10
Estimating the Effects of California’s Proposition 99
A. Background
Anti-tobacco legislation has a long history in the United States, dating back at least as far as
1893, when Washington became the ﬁrst state to ban the sale of cigarettes. Over the next 30
years 15 other states followed with similar anti-smoking measures . These early anti-tobacco laws were primarily motivated by moral concerns; health
issues were secondary . Almost 100 years later, after these early laws had long
since been repealed, widespread awareness of smoking’s health risks launched a new wave
of state and federal anti-tobacco laws across the United States and, ultimately, overseas.11
Leading this wave, in 1988, was a voter initiative in California known as Proposition 99,
the ﬁrst modern-time large-scale tobacco control program in the United States.
Proposition 99 increased California’s cigarette excise tax by 25 cents per pack, earmarked the tax revenues to health and anti-smoking education budgets, funded antismoking media campaigns, and spurred local clean indoor-air ordinances throughout the
state .12 Upon initial implementation, Proposition 99 produced more than
$100 million per year in anti-tobacco projects for schools, communities, counties, and at
9See Appendix B for an application of an in-time placebo to the study of the economic impact of the
1990 German reuniﬁcation.
10See Athey and Imbens and Donald and Lang for related work on inference in diﬀerencein-diﬀerences models.
11See Gruber for a survey on tobacco consumption and regulation in the United States. Ireland
imposed a workplace smoking ban in 2004. This was followed by Italy in 2005, and Scotland in 2006.
Belgium, Australia, and the United Kingdom have workplace smoking bans scheduled for 2007 (Borio,
12Proposition 99 assigned tax revenues to six accounts: Physician Services (35 percent), Health Education(20 percent), Hospital Services (10 percent), Research (5 percent), Public Resources (5 percent), and
Unallocated (25 percent) .
the state level. Almost $20 million a year became available for tobacco-related research.
As Glantz and Balbach put it, “[t]hese programs dwarfed anything that any other
state or the federal government had ever done on tobacco.”
Proposition 99 spawned a wave of local clean-air ordinances in California. Before Proposition 99 no city or town in California required restaurants to be 100 percent smoke-free.
From 1989 to 2000 approximately 140 such laws were passed . By 1993 local ordinances prohibiting smoking in the workplace protected nearly two-thirds of the
workers in California . In 1994 the State of California passed
additional legislation that banned smoking in enclosed workplaces. By 1996 more than 90
percent of California workers were covered by a smoke-free workplace policy .
Non-smokers’ rights advocates view the wave of local ordinances passed under the impetus
of Proposition 99 as an important step in the eﬀort to undercut the then existing social
support network for tobacco use in California .
The tobacco industry responded to Proposition 99 and the spread of clean-air ordinances
by increasing its political activity in California at both the state and local levels. Tobacco
lobby groups spent 10 times as much money in California in 1991-1992 as they had spent
in 1985-1986 . In addition, after the passage of Proposition 99, tobacco
companies increased promotional expenditures in California .
In 1991 California passed Assembly Bill 99, a new piece of legislation implementing
Proposition 99.
Contrary to the original mandate of Proposition 99, Assembly Bill 99
diverted a signiﬁcant fraction of Health Education Account funds into medical services
with little or no connection to tobacco . Also in 1991 a new
governor began to exert increasing control over California’s anti-smoking media campaign.
In 1992 Governor Pete Wilson appointed a new Department of Health Services director and
halted the media campaign, which provoked a lawsuit by the American Lung Association
(ALA). The ALA won the suit and the campaign was back by the end of 1992, although
with a reduced budget .
Even so, Proposition 99 was widely perceived to have successfully cut smoking in Cal-
ifornia. From the passage of Proposition 99 through 1999 adult smoking prevalence fell
in California by more than 30 percent, youth smoking levels dropped to the lowest in the
country, and per capita cigarette consumption more than halved . Prior to 1988 per capita cigarette consumption in California trailed
the national average by 22.5 packs; ten years later per capita consumption was 40.4 packs
lower than the national average .
Following early reports of California’s success with Proposition 99, other states adopted
similar policies. In 1993 Massachusetts raised taxes on cigarettes from 26 to 51 cents per
pack to fund a Health Protection Fund for smoking prevention and cessation programs.
Similar laws passed in Arizona in 1995, with a 50-cent tax increase, and Oregon in 1997,
where the tax on cigarettes rose from 38 to 68 cents per pack . In November
1998 the tobacco companies signed a $206 billion Master Settlement Agreement that led the
industry to impose an immediate 45-cent increase in cigarette prices nationwide .
Previous studies have investigated the impact of Proposition 99 on smoking prevalence
using a variety of methods. Breslow and Johnson , Glantz , and Pierce et al.
 show that cigarette consumption in California after the passage of Proposition 99
in 1988 was lower than the average national trend and lower than the linearly extrapolated
pre-program trend in California. Hu, Sung and Keeler use time-series regression
to disaggregate the eﬀects of Proposition 99’s tax hike and media campaign on per-capita
cigarette sales.
A related literature has studied the eﬀect of smoking bans on smoking prevalence.
Woodruﬀet al. show that smoking prevalence in California in 1990 was lower among
workers aﬀected by workplace smoking restrictions than among unaﬀected workers. More
generally, Evans, Farrelly, and Montgomery, , Farrelly, Evans, and Sfekas ,
and Longo et al. have provided evidence on the eﬀectiveness of workplace smoking
The most recently published study similar to ours is Fichtenberg and Glantz , in
the New England Journal of Medicine. This article uses least-squares regression to predict
smoking rates in California as a function of the smoking rate for the rest of the United
States. The regressions in Fichtenberg and Glantz estimate the eﬀect of Proposition
99 as a time trend in per-capita cigarette consumption starting after the implementation of
Proposition 99 in 1989. Fichtenberg and Glantz allow also for a change in this trend
after 1992, when the anti-tobacco media campaign was ﬁrst temporally eliminated and then
reestablished but with reduced funds. Using this regression speciﬁcation, Fichtenberg and
Glantz estimate that during the period 1989-1992 Proposition 99 accelerated the
rate of decline of per-capita cigarette consumption in California by 2.72 packs per year.
Due to program cut-backs after 1992, Fichtenberg and Glantz estimate that during
the period 1993-1997 Proposition 99 accelerated the rate of decline of per-capita cigarette
consumption in California by only 0.67 packs per year.
B. Data and Sample
We use annual state-level panel data for the period 1970-2000. Proposition 99 was passed
in November 1988, giving us 18 years of pre-intervention data. Our sample period begins
in 1970 because it is the ﬁrst year for which data on cigarette sales are available for all
our control states. It ends in 2000 because at about this time anti-tobacco measures were
implemented across many states, invalidating them as potential control units. Moreover, a
decade-long period after the passage of Proposition 99 seems like a reasonable limit on the
span of plausible prediction of the eﬀect of this intervention.
Recall that the synthetic California is constructed as a weighted average of potential
control states, with weights chosen so that the resulting synthetic California best reproduces
the values of a set of predictors of cigarette consumption in California before the passage
13See also Goel and Nelson for a recent literature review on the eﬀectiveness of anti-smoking
legislation.
of Proposition 99. Borrowing from the statistical matching literature, we refer to the set
of potential controls for California as the “donor pool”. Because the synthetic California is
meant to reproduce the smoking rates that would have been observed for California in the
absence of Proposition 99, we discard from the donor pool states that adopted some other
large-scale tobacco control program during our sample period. Four states (Massachusetts,
Arizona, Oregon, and Florida) introduced formal statewide tobacco control programs in
the 1989-2000 period and they are excluded from the donor pool. We also discard all states
that raised their state cigarette taxes by 50 cents or more over the 1989 to 2000 period
(Alaska, Hawaii, Maryland, Michigan, New Jersey, New York, Washington).14
we also exclude the District of Columbia from our sample. Our donor pool includes the
remaining 38 states. Our results are robust, however, to the inclusion of discarded states.
Our outcome variable of interest is annual per capita cigarette consumption at the state
level, measured in our dataset as per-capita cigarette sales in packs. We obtained these data
from Orzechowski and Walker where they are constructed using information on statelevel tax revenues on cigarettes sales. This is the most widely used indicator in the tobacco
research literature, available for a much longer time-period than survey-based measures
of smoking prevalence.
We include in X1 and X0 the values of predictors of smoking
prevalence for California and the 38 potential controls, respectively.
Our predictors of
smoking prevalence are: average retail price of cigarettes, per-capita state personal income
(logged), the percentage of the population age 15-24, and per-capita beer consumption.
These variables are averaged over the 1980-1988 period, and augmented by adding three
years of lagged smoking consumption . Appendix A provides data
sources.15, 16
14Notice that, even if the remaining tax increases substantially reduced smoking in any of the control
states that gets assigned a positive W-weight, this should if anything attenuate the treatment eﬀect estimate
that we obtain for California.
15Average retail prices of cigarettes vary quite a bit across the United States. For example, in 1989,
average retail prices ranged from $1.16 in Kentucky to $1.74 in Nevada.
16Results are robust regardless of which and how many predictor variables we include.
The list of
predictors used for robustness checks include: unemployment, income inequality, poverty, welfare transfers,
crime rates, drug related arrest rates, state cigarette taxes, population density, and numerous variables
to capture the demographic, racial, and social structure of states. Inclusion of these predictors leaves our
results virtually unaﬀected. The weights associated with additional predictors in the matrix V usually are
Using the techniques described in Section II, we construct a synthetic California that
mirrors the values of the predictors of cigarette consumption in California before the passage of Proposition 99. We estimate the eﬀect of Proposition 99 on per-capita cigarette
consumption as the diﬀerence in cigarette consumption levels between California and its
synthetic versions in the years after Proposition 99 was passed. We then perform a series
of placebo studies that conﬁrm that our estimated eﬀects for California are unusually large
relative to the distribution of the estimate that we obtain when we apply the same analysis
to all states in the donor pool.
C. Results
Figure 1 plots the trends in per-capita cigarette consumption in California and the rest
of the United States. As this ﬁgure suggests, the rest of the United States may not provide a suitable comparison group for California to study the eﬀects of Proposition 99 on
per-capita smoking. Even before the passage of Proposition 99 the time series of cigarette
consumption in California and the rest of the United States diﬀered notably. Levels of
cigarette consumption were similar in California and the rest of the United States in the
early 1970’s. Trends began to diverge in the late 1970’s, when California’s cigarette consumption peaked and began to decline while consumption in the rest of the United States
was still rising. Cigarette sales declined in the 1980’s, but with larger decreases in California than in the rest of the United States. In 1988, the year Proposition 99 passed,
cigarette consumption was about 27 percent higher in the rest of the United States relative
to California. Following the law’s passage cigarette consumption in California continued
to decline. To evaluate the eﬀect of Proposition 99 on cigarette smoking in California the
central question is how cigarette consumption would have evolved in California after 1988
in the absence of Proposition 99. The synthetic control method provides a systematic way
to estimate this counterfactual.
As explained above, we construct the synthetic California as the convex combination of
close to zero because the few predictors used in the streamlined baseline model already account for most
of the variation in cigarette consumption over time.
states in the donor pool that most closely resembled California in terms of pre-Proposition
99 values of smoking prevalence predictors. The results are displayed in Table 1, which
compares the pretreatment characteristics of the actual California with that of the synthetic
California, as well as with the population-weighted average of the 38 states in the donor
pool. We see that the average of states that did not implement a large-scale tobacco-control
program in 1989-2000 does not seem to provide a suitable control group for California. In
particular, prior to the passage of Proposition 99 average beer consumption and cigarette
retail prices were lower in the 38 control states than in California. Moreover, prior to the
passage of Proposition 99 average cigarette sales per-capita were substantially higher in
the 38 control states than in California. In contrast, the synthetic California accurately
reproduces the values that smoking prevalence and smoking prevalence predictor variables
had in California prior to the passage of Proposition 99.17
Table 2 displays the weights of each control state in the synthetic California.
weights reported in Table 2 indicate that smoking trends in California prior to the passage
of Proposition 99 is best reproduced by a combination of Colorado, Connecticut, Montana,
Nevada, and Utah. All other states in the donor pool are assigned zero W-weights.
Figure 2 displays per-capita cigarette sales for California and its synthetic counterpart
during the period 1970-2000. Notice that, in contrast to per capita sales in other U.S.
states (shown in Figure 1), per-capita sales in the synthetic California reproduce extremely
well the trajectory of this variable in California for the entire pre-Proposition 99 period.
Combined with the high balance on all smoking predictors (Table 1), this suggests that
the synthetic California provides a sensible approximation to the per-capita cigarette packs
that would have been sold in California in 1989-2000 in the absence of Proposition 99.
Our estimate of the eﬀect of Proposition 99 on cigarette consumption in California is the
diﬀerence between per-capita cigarette sales in California and in its synthetic version after
17Table 1 highlights an attractive feature of synthetic control estimators. Similar to matching estimators,
the synthetic control method forces the researcher to demonstrate the aﬃnity between the region exposed
to the intervention of interest and the regions in the donor pool. As a result, the synthetic control method
safeguards against estimation of “extreme counterfactuals,” that is, those counterfactuals that fall far
outside the convex hull of the data .
the passage of Proposition 99. Immediately after the law’s passage, the two lines began
to diverge noticeably. While cigarette consumption in the synthetic California continued
on its moderate downward trend, the real California experienced a sharp downward kink.
The discrepancy between the two lines suggests a large negative eﬀect of Proposition 99 on
per-capita cigarette sales. Figure 2 plots the yearly estimates of the impacts of Proposition
99, that is, the yearly gaps in per capita cigarette consumption between California and
its synthetic counterpart.
Figure 2 suggests that Proposition 99 had a large eﬀect on
per-capita cigarette sales, and that this eﬀect increased in time. The magnitude of the
estimated impact of Proposition 99 in Figure 2 is substantial. Our results suggest that for
the entire 1989-2000 period cigarette consumption was reduced by an average of almost 20
packs per capita, a decline of approximately 25 percent.
Our analysis produces estimates of the eﬀect of Proposition 99 that are considerably
larger than those obtained by Fichtenberg and Glantz using linear regression methods. In particular, Fichtenberg and Glantz estimate that by 1997 Proposition 99 had
reduced per-capita cigarette sales in California by about 14 packs per year. Our estimates
increase this ﬁgure substantially, to 24 packs per year.18
D. Inference about the eﬀect of the California Tobacco Control Program
To evaluate the statistical signiﬁcance of our estimates, we pose the question of whether
our results could be driven entirely by chance. How often would we obtain results of this
magnitude if we had chosen a state at random for the study instead of California? To
answer this question, we use placebo tests. Similar to Abadie and Gardeazabal 
and Bertrand, Duﬂo, and Mullainathan , we run placebo studies by applying the
synthetic control method to states that did not implement a large-scale tobacco control
program during the sample period of our study.
If the placebo studies create gaps of
18Part of this diﬀerence is likely to be explained by the fact that Fichtenberg and Glantz use percapita cigarette sales in the rest of the United States to reproduce how this variable would have evolved in
California in the absence of Proposition 99. As explained above, after the enactment of Proposition 99 in
California, other states, like Massachusetts and Florida passed similar tobacco control legislation. While
we eliminate these states as potential controls, Fichtenberg and Glantz do not do so, which is likely
to attenuate their estimates.
magnitude similar to the one estimated for California we interpret that our analysis does
not provide signiﬁcant evidence of a negative eﬀect of Proposition 99 on cigarette sales
in California. If, on the other hand, the placebo studies show that the gap estimated for
California is unusually large, relative to the gaps for the states that did not implement
large-scale tobacco control program, we interpret that our analysis provides signiﬁcant
evidence of a negative eﬀect of Proposition 99 on cigarette sales in California.
The idea of the placebo test is akin to the classic framework for permutation inference,
where the distribution of a test statistic is computed under random permutations of the
sample units’ assignments to the intervention and non-intervention groups .
To assess the signiﬁcance of our estimates, we conduct a series of placebo studies by
iteratively applying the synthetic control method used to estimate the eﬀect of Proposition
99 in California to every other state in the donor pool. In each iteration we reassign in our
data the tobacco control intervention to one of the 38 control states. That is, we proceed
as if one of the states in the donor pool would have passed a large-scale tobacco control
program in 1988, instead of California. We then compute the estimated eﬀect associated
with each placebo run. This iterative procedure provides us with a distribution of estimated
gaps for the states in which no intervention took place.
Figure 4 displays the results for the placebo test. The gray lines represent the gap
associated with each of the 38 runs of the test. That is, the gray lines show the diﬀerence in
per-capita cigarette sales between each state in the donor pool and its respective synthetic
version. The superimposed black line denotes the gap estimated for California. As the
ﬁgure makes apparent, the estimated gap for California during the 1989-2000 period is
unusually large relative to the distribution of the gaps for the states in the donor pool.
As Figure 4 indicates, the synthetic method provides an excellent ﬁt for per-capita
cigarette sales in California prior to the passage of Proposition 99. The pre-intervention
mean squared prediction error (MSPE) in California is about 3. The pre-Proposition 99 median MSPE among the 38
states in the donor pool is about 6, also quite small, indicating that the synthetic control
method is able to provide a good ﬁt for per-capita cigarette consumption prior to Proposition 99 for the majority of the states in the donor pool. However, Figure 4 indicates also
that per-capita cigarette sales during the 1970-1988 period cannot be well-reproduced for
some states by a convex combination of per-capita cigarette sales in other states. The state
with worst ﬁt in the pre-Proposition 99 period is New Hampshire, with a MSPE of 3,437.
The large MSPE for New Hampshire does not come as a surprise. Among all the states
in the donor pool, New Hampshire is the state with the highest per-capita cigarette sales
for every year prior to the passage of Proposition 99. Therefore, there is no combination
of states in our sample that can reproduce the time series of per-capita cigarette sales in
New Hampshire prior to 1988. Similar problems arise for other states with extreme values
of per-capita cigarette sales during the pre-Proposition 99 period.
If the synthetic California had failed to ﬁt per-capita cigarette sales for the real California in the years before the passage of Proposition 99 we would have interpreted that much
of the post-1988 gap between the real and the synthetic California was also artiﬁcially created by lack of ﬁt, rather than by the eﬀect of Proposition 99. Similarly, placebo runs with
poor ﬁt prior to the passage of Proposition 99 do not provide information to measure the
relative rarity of estimating a large post-Proposition 99 gap for a state that was well-ﬁtted
prior to Proposition 99. For this reason, we provide several diﬀerent versions of Figure 4,
each version excluding states beyond a certain level of pre-Proposition 99 MSPE.
Figure 5 excludes states that had a pre-Proposition 99 MSPE of more than 20 times the
MSPE of California. This is a very lenient cutoﬀ, discarding only four states with extreme
values of pre-Proposition 99 MSPE, and for which the synthetic method would be clearly
ill-advised. In this ﬁgure there remain a few lines that still deviate substantially from the
zero gap line in the pre-Proposition 99 period. Among the 35 states remaining in the ﬁgure,
the California gap line is now about the most unusual line, especially from the mid 1990’s
Figure 6 is based on a lower cutoﬀ, excluding all states that had a pre-Proposition 99
MSPE higher than ﬁve times the pre-Proposition 99 MSPE for California. Twenty-nine
control states plus California remain in the ﬁgure. The California gap line is now clearly
the most unusual line for almost the entire post-treatment period.
In Figure 6 we lower the cutoﬀeven further and focus exclusively on those states that we
can ﬁt almost as well as California in the period 1970-1988, that is, those states with pre-
Proposition 99 MSPE not higher than twice the pre-Proposition 99 MSPE for California.
Evaluated against the distribution of the gaps for the 19 remaining control states in Figure
6, the gap for California appears highly unusual. The negative eﬀect in California is now
by far the lowest of all. Because this ﬁgure includes 19 control states, the probability of
estimating a gap of the magnitude of the gap for California under a random permutation
of the intervention in our data is 5 percent, a test level typically used in conventional tests
of statistical signiﬁcance.
One ﬁnal way to evaluate the California gap relative to the gaps obtained from the
placebo runs is to look at the distribution of the ratios of post/pre-Proposition 99 MSPE.
The main advantage of looking at ratios is that it obviates choosing a cutoﬀfor the exclusion
of ill-ﬁtting placebo runs. Figure 8 displays the distribution of the post/pre-Proposition 99
ratios of the MSPE for California and all 38 control states. The ratio for California clearly
stands out in the ﬁgure: post-Proposition 99 MSPE is about 130 times the MSPE for the
pre-Proposition 99 period. No control state achieves such a large ratio. If one were to assign
the intervention at random in the data, the probability of obtaining a post/pre-Proposition
99 MSPE ratio as large as California’s is 1/39 = 0.026.
Conclusion
Comparative case study research has broad potential in the social sciences. However, the
empirical implementations of comparative case studies have been plagued by inferential
challenges and ambiguity about the choice of valid control groups. Building on an idea in
Abadie and Gardeazabal , this paper proposes the use of synthetic control methods
to overcome these shortcomings. Our method allows for causal inference in observational
settings with a single treated unit. We use a data-driven procedure to construct a weighted
combination of potential comparison regions that approximate the most relevant characteristics of the units exposed to the intervention.
We show that the conditions under which the synthetic control estimator is valid are
more general than the conditions required for traditional linear panel data or diﬀerence-indiﬀerences estimators. In addition, we propose a method to produce informative inference
regardless of the number of available comparison units, the number of available time periods, and whether the data are individual (micro) or aggregate (macro). Moreover, we
provide software to implement the estimators proposed in this article.
We demonstrate the applicability of the synthetic control method by studying the eﬀects
of Proposition 99, a large-scale tobacco control program that California passed in 1988.
Our results suggest the eﬀects of the tobacco control program are much larger than prior
estimates have reported. We show that if one were to re-label the intervention state in the
dataset at random, the probability of obtaining results of the magnitude of those obtained
for California would be extremely small, 0.026.
Appendix A: Data Sources
In this appendix, we describe the data used in our analysis and provide sources.
• Per-capita cigarette consumption (in packs). Source: Orzechowski and Walker .
These data are based on the total tax paid on sales of packs of cigarettes in a particular
state divided by its total population.
• Average retail price per pack of cigarettes. Source: Orzechowski and Walker .
Price ﬁgures include state sales taxes, if applicable.
• Per-capita state personal income (logged). Source: Bureau of the Census, United
States Statistical Abstract.
Converted to 1997 dollars using the Consumer Price
• State population and percent of state population aged 15-24. Source: U.S. Census
• Per-capita beer consumption. Source: Beer Institute’s Brewer’s Almanac. Measured
as the per-capita consumption of malt beverages (in gallons).
Appendix B: The Economic Impact of the German Reunification
in West Germany
In this appendix, we illustrate the application of the synthetic control method to crosscountry data. For this purpose, we apply the synthetic control method to estimate the
economic impact of the 1990 German reuniﬁcation in the former West Germany (Federal
Republic of Germany). Using the synthetic control method, we construct a synthetic West
Germany as a convex combination of other advanced industrialized countries chosen to
resemble the values of economic growth predictors for West Germany prior to the reuniﬁcation. Our sample of potential controls includes the following OECD member countries:
Australia, Austria, Belgium, Canada, Denmark, Finland, France, Greece, Ireland, Italy,
Japan, the Netherlands, New Zealand, Norway, Portugal, Spain, Sweden, Switzerland,
United Kingdom, and the United States.
We provide a list of all variables used in the analysis at the end of this appendix,
along with data sources.
For each variable we have made sure that the German data
refers exclusively to the territory of the former West Germany. For that purpose, when
necessary, our dataset was supplemented with data from the German Federal Statistical
Oﬃce (Statistisches Bundesamt).
The outcome variable is real per-capita GDP . We rely on a standard set of predictors commonly
used in the economic growth literature. We use the investment rate measured as the ratio
of real domestic investment (private plus public) to GDP. Our proxy for human capital is
the percentage of high school graduates in the total population aged 25 and older. Our
predictors also include the inﬂation rate and the share of value added by the industrial
In addition, we include trade openness, measured by the sum of exports and
imports as a percentage of GDP, among our predictors of economic growth. The inclusion
of additional growth predictors did not change our results substantively.
Table A.1 compares the pre-reuniﬁcation characteristics of the actual West Germany
to those of our synthetic West Germany, and also to those of the population-weighted
average of the 20 OECD countries in the donor pool. The statistics in this table show that
the synthetic West Germany approximates the pre-1990 values of the economic growth
predictors for West Germany far more accurately than the average of our sample of other
OECD countries. This suggests that the synthetic West Germany provides a better control
for the actual West Germany than the average of our sample of other OECD countries.
Table A.2 shows the weights of each country in the synthetic West Germany.
synthetic West Germany is a weighted average of Austria, the United States, Switzerland,
the Netherlands, and Japan, with weights decreasing in this order. All other countries in
the donor pool are assigned zero weights.
Figure A.1 displays the GDP per-capita trajectory of West Germany and its synthetic
counterpart for the 1960-2003 period. The synthetic West Germany almost exactly reproduces the trend of this variable in the actual West Germany for the entire pre-reuniﬁcation
period. This remarkable ﬁt for the pre-treatment period, along with the high balance on
GDP predictors (Table A.1), suggests that our synthetic West Germany provides a sensible estimate of the counterfactual GDP per-capita trend that West Germany would have
experienced in the absence of the German reuniﬁcation.
Our estimate of the eﬀect of the German reuniﬁcation on GDP per-capita in West
Germany is given by the diﬀerence between the actual West Germany and its synthetic
version. We ﬁnd that the German reuniﬁcation did not have much of an eﬀect on West
German GDP per-capita in the ﬁrst two years immediately following reuniﬁcation.
this initial period GDP per-capita in the synthetic West Germany is slightly lower than
in the actual West Germany, which is broadly in line with arguments about an initial
demand boom . From 1992 onwards, however,
the two lines diverge substantially.
While the actual West Germany’s per-capita GDP
growth decelerates, the synthetic West Germany’s per-capita GDP keeps ascending at a
pace similar to that of the pre-uniﬁcation period. The divergence of the two series continues
to grow until the end of the sample period. Our results suggest a pronounced negative eﬀect
of the reuniﬁcation on West German income. They suggest that for the entire 1990-2003
period, GDP per-capita was reduced by about 1,460 USD per year on average, a decline of
approximately 6 percent.
To evaluate the statistical signiﬁcance of our estimate, we conduct a placebo study where
the treatment is reassigned not across units but in time. Thus, instead of running a placebo
study by reassigning reuniﬁcation to diﬀerent countries, we maintain West Germany as the
treated unit but reassign reuniﬁcation to an earlier point in time. The idea is to evaluate
how likely it is to obtain results of the magnitude that we obtain in Figure A.1 when we
apply our methods in a sample period before the reuniﬁcation.
Here we show results for the case when reuniﬁcation is reassigned to the year 1980,
ten years earlier than it actually occurred. Thus, we run the same model as before, but
the pre-treatment period is constrained to be 1960-1980. We also lag our predictors variables accordingly. The results for reassigning reuniﬁcation to years other than 1980 are
substantially identical. They are omitted to economize on space.
Figure A.2 displays the results of our in-time placebo study. Notice that the synthetic
West Germany almost exactly reproduces the evolution of GDP per capita in the actual
West Germany for the entire pre-treatment period. Most importantly, the GDP per-capita
trajectories of West Germany and its synthetic counterpart do not diverge considerably
after 1980. That is, in contrast to the actual 1990 German reuniﬁcation, our 1980 placebo
reuniﬁcation has no perceivable eﬀect. This placebo study shows that a weighted combination of other OECD countries can be used to predict accurately the evolution of GDP
per-capita in West Germany prior to the reuniﬁcation. This suggests that the gap estimated in Figure A.1 reﬂects the impact of the German reuniﬁcation and not a potential
lack of predictive power of the synthetic control.
The data sources employed for this application are:
• GDP per capita . Source: OECD National Accounts . Data for West Germany was obtained from
Statistisches Bundesamt 2005 (Arbeitskreis “Volkswirtschaftliche Gesamtrechnungen
der L¨ander”) and converted using PPP monetary conversion factors .
• Investment Rate: Ratio of real domestic investment (private plus public) to real GDP.
Source: Barro and Lee .
• Schooling: Percentage of secondary school completed in the total population aged 25
and older. Source: Barro and Lee .
• Industry: industry share of value added. Source: World Bank WDI Database 2005
and Statistisches Bundesamt 2005.
• Inﬂation: annual percentage change in consumer prices . Source:
World Development Indicators Database 2005 and Statistisches Bundesamt 2005.
• Trade Openness: Export plus Imports as percentage of GDP. Source: World Bank:
World Development Indicators CD-ROM 2000.
Appendix C: Technical Details
Consider the ﬁrst model in section II.B:
it = δt + θtZi + λtµi + εit.
The weighted average of the outcome in the donor pool, using weights {wj}2≤j≤J+1 is:
jt = δt + θt
As a result,
wj(ε1t −εjt).
To simplify the exposition, we will restrict ourselves to the case that F = 1, so there is one
unobserved factor, and with εit independent across units and in time. The analysis can be,
however, extended to more general settings.19 Consider M (1 × T0)-vectors: K1, . . . , KM.
Let K be the (M × T0) matrix with m-th row equal to Km. For 1 ≤i ≤J + 1 and
1 ≤m ≤M, let ¯Y K
be the M × 1 matrix with m-th row equal to PT0
s=1 kmsYis, where kms
is the s-th element of Km. Similarly, let ¯εK
i and ¯λK be (M × 1) vectors with m-th element
equal to PT0
s=1 kmsεis and PT0
s=1 kmsλs, respectively. Let ¯θK be the (M × r) matrix with
m-row equal to PT0
s=1 kmsθs. We obtain,
Therefore, if ¯λK ̸= 0, then:
λt(¯λK ′¯λK)−1¯λK ′
(θt −λt(¯λK ′¯λK)−1¯λK ′¯θK)
λt(¯λK ′¯λK)−1¯λK ′
wj(ε1t −εjt).
19In particular, it is straightforward to generalize the argument to the case that the series εit are martingale diﬀerences, for i = 1, . . . , J + 1. Generalizations to other settings are also possible. Notice, however,
that even with εit independent across units and in time, the unobserved residual uit = λtµi + εit may be
correlated across units and in time because the presence of the term λtµi.
Suppose that there exist {w∗
2, . . . , w∗
J+1} such that equation (2) holds approximately. Then
jt ≃R1t + R2t + R3t,
R1t = λt(¯λK ′¯λK)−1¯λK ′
R2t = −λt(¯λK ′¯λK)−1¯λK ′¯εK
and R3t = PJ+1
j(εjt −ε1t).
R2t and R3t have mean zero. To analyze the mean of R1t, consider ﬁrst the case of
M = 1 and K = (1/T0, . . . , 1/T0), as in section II.B.
Let λ = (λ1, . . . , λT0)′.
¯λK = Kλ = (1/T0) PT0
s=1 λs, ¯εK
j = (1/T0) PT0
s=1 εjs (for j = 1, . . . , J + 1), and
(1/T0) PT0
Assume that, for some even p, the p-th moments of |εjt| exist for j = 2, . . . , J + 1 and
t = 1, . . . , T0. Using H¨older’s Inequality:
Therefore, applying again H¨older’s Inequality:
Now, using Rosenthal’s Inequality:
j |p ≤C(p) max
where C(p) is the p-th moment of minus one plus a Poisson random variable with parameter equal to one .
jt = E|εjt|2, σ2
(1/T0) PT0
jt, ¯σ2 = maxj=2,...,J+1 σ2
j, and ¯σ =
Similarly, let µp,jt = E|εjt|p,
µp,j = (1/T0) PT0
t=1 µp,jt, and ¯µp = maxj=2,...,J+1 µp,j. We obtain:
≤C(p)1/pJ1/p max
Last equation shows that the bias of the estimator can be bounded by a function that goes
to zero as the number of pre-treatment periods increases.
So far we have considered the case that the synthetic control is chosen to approximate
Z1 as well as the value of an average of pre-treatment outcomes for the treated unit.
Alternatively, consider the case that the synthetic control is chosen to approximate Z1 and
the values of the pretreatment outcomes for the treated unit in M pretreatment periods.
Without loss of generality, assume that we are trying to approximate the values of the
pretreatment outcome for the treated unit in the last M pretreatment periods. Then,
s=T0−M+1 λ2
s=T0−M+1 λt |λs|
s=T0−M+1 λ2
n=T0−M+1 |λn|
Assume that there exist two ﬁnite constant λmin > 0 and λmax < ∞such that λmin ≤
|λt| ≤λmax for all t = 1, . . . , T0. Let ¯R = λmax/λmin. Using the same argument as before,
we obtain:
n=T0−M+1 |λn|
¯¯¯¯¯ ≤C(p)1/pJ1/p max
( ¯R ¯µ1/p
Last equation shows that the bias of the synthetic control estimator can be reduced by
increasing M, the number of pretreatment outcomes that the synthetic control approximates. Notice that M is only restricted to be not greater than the number of pretreatment
periods: M ≤T0.
Consider now the autoregressive model in equation (4). Notice that
αT0 + βT0+1 γT0
Yi T0 + βT0+1 ΠT0 Zi T0 + βT0+1 vi T0+1 + ui T0+1.
Working recursively it is easy to check that, conditional on Yi T0 and Zi T0, for n ≥1, Y N
is a linear function of {uit, vit}T0+1≤t≤T0+n. Then, because {w∗
j}2≤j≤N is a deterministic
function of FT0, and because {uit, vit}T0+1≤t≤T0+n have mean zero conditional on FT0, the
bias of the synthetic control estimator goes to zero as the discrepancies in equation in
equation (5) go to zero.