HAL Id: hal-00354262
 
Submitted on 20 Sep 2010
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of scientific research documents, whether they are published or not.
The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
An informational approach to the global optimization of
expensive-to-evaluate functions
Julien Villemonteix, Emmanuel Vazquez, Eric Walter
To cite this version:
Julien Villemonteix, Emmanuel Vazquez, Eric Walter. An informational approach to the global optimization of expensive-to-evaluate functions. Journal of Global Optimization, 2009, 44 (4), pp.509-534.
￿10.1007/s10898-008-9354-2￿. ￿hal-00354262v2￿
J. Glob. Optim , 44:509-534, DOI 10.1007/s10898-008-9354-2
An informational approach to the global optimization of
expensive-to-evaluate functions
Julien Villemonteix · Emmanuel Vazquez · Eric Walter
Submitted : 3 July 2006
Abstract In many global optimization problems motivated by engineering applications, the number of function
evaluations is severely limited by time or cost. To ensure that each evaluation contributes to the localization of
good candidates for the role of global minimizer, a sequential choice of evaluation points is usually carried out.
In particular, when Kriging is used to interpolate past evaluations, the uncertainty associated with the lack of
information on the function can be expressed and used to compute a number of criteria accounting for the interest
of an additional evaluation at any given point. This paper introduces minimizers entropy as a new Kriging-based
criterion for the sequential choice of points at which the function should be evaluated. Based on stepwise uncertainty reduction, it accounts for the informational gain on the minimizer expected from a new evaluation. The
criterion is approximated using conditional simulations of the Gaussian process model behind Kriging, and then
inserted into an algorithm similar in spirit to the Efﬁcient Global Optimization (EGO) algorithm. An empirical
comparison is carried out between our criterion and expected improvement, one of the reference criteria in the
literature. Experimental results indicate major evaluation savings over EGO. Finally, the method, which we call
IAGO (for Informational Approach to Global Optimization), is extended to robust optimization problems, where
both the factors to be tuned and the function evaluations are corrupted by noise.
Keywords Gaussian process, global optimization, Kriging, robust optimization, stepwise uncertainty reduction
1 Introduction
This paper is devoted to global optimization in a context of expensive function evaluation. The objective is to
ﬁnd global minimizers in X (the factor space, a bounded subset of Rd) of an unknown function f : X →R,
using a very limited number of function evaluations. Note that the global minimizer may not be unique (any
global minimizer will be denoted as x∗). Such a problem is frequently encountered in the industrial world.
For instance, in the automotive industry, optimal crash-related parameters are obtained using costly real tests and
time-consuming computer simulations (a single simulation of crash-related deformations may take up to 24 hours
on dedicated servers). It then becomes essential to favor optimization methods that use the dramatically scarce
information as efﬁciently as possible.
To make up for the lack of knowledge on the function, surrogate (also called meta or approximate) models
are used to obtain cheap approximations . They turn out to be convenient tools for visualizing the function
behavior or suggesting the location of an additional point at which f should be evaluated in the search for x∗.
Surrogate models based on Gaussian processes have received particular attention. Known in geostatistics under
the name of Kriging since the early 1960s , Gaussian process models provide a probabilistic framework
Julien Villemonteix
Renault S.A., Energy Systems Department, 78298 Guyancourt, France
Emmanuel Vazquez
SUPELEC 91192 Gif-sur-Yvette, France
E-mail: 
Eric Walter
Laboratoire des Signaux et Systèmes, CNRS-SUPELEC-Univ Paris-Sud, 91192 Gif-sur-Yvette, France
to account for the uncertainty stemming from the lack of information on the system. When dealing with an
optimization problem, this framework allows the set of function evaluations to be chosen efﬁciently .
In this context, several strategies have been proposed, with signiﬁcant advantages over traditional optimization methods when confronted to expensive-to-evaluate functions. Most of them implicitly seek a likely value
for x∗, and then assume it to be a suitable location for a new evaluation of f. Yet, given existing evaluation
results, the most likely location of a global minimizer is not necessarily a good evaluation point to improve our
knowledge on x∗. As we shall show, by making full use of Kriging, it is instead possible to explicitly estimate
the probability distribution of the optimum location, which allows an information-based search strategy.
Based on these observations, the present paper introduces minimizers entropy as a criterion for the choice of
new evaluation points. This criterion, directly inspired from stepwise uncertainty reduction , is then inserted in
an algorithm similar to the Efﬁcient Global Optimization (EGO) algorithm . We call the resulting algorithm
IAGO, for Informational Approach to Global Optimization.
Section 2 recalls the principle of Kriging-based optimization, along with some general ideas on Gaussian
process modeling that are used in Section 3 to build an estimate of the distribution of the global minimizers.
Section 4 details the stepwise uncertainty reduction approach applied to global optimization, while Section 5
describes the corresponding algorithm and its extensions to noisy problems. Section 6 illustrates the behavior of
the new algorithm on some simple benchmark problems, along with its performances compared with those of the
classical EGO algorithm, chosen for its good compromise between local and global search . Finally, after a
conclusion section and to make this paper self-contained, Section 8 recalls, as an appendix, some more results on
Gaussian process modeling and Kriging.
2 Kriging-based global optimization
When dealing with expensive-to-evaluate functions, optimization methods based on probabilistic surrogate models (and Kriging in particular) have signiﬁcant advantages over traditional optimization techniques, as they require
fewer function evaluations to provide an acceptable solution. Kriging provides not only a cheap approximation of
the function but also an estimate of the potential error in this approximation. Numerous illustrations of this superiority can be found in the literature (see, for instance, ) and many variations have been explored (for extensive
surveys, see and ). As explained in this section, these methods deal with the cost of evaluation using
an adaptive sampling strategy, replacing the optimization of the expensive-to-evaluate function f by a series of
optimizations of a cheap criterion.
2.1 Gaussian process modeling and Kriging
This section brieﬂy recalls the principle of Gaussian process (GP) modeling, and lays down the necessary notation. A more detailed presentation is available in the appendix (Section 8).
When modeling with Gaussian processes, the function f is assumed to be a sample path of a Gaussian random
process F, with mean function m(x) and covariance function k(·, ·) deﬁned over X2. If we denote (Ω, A, P) the
underlying probability space, this amounts to assuming that ∃ω ∈Ω, such that F(ω, ·) = f(·). Whenever
possible, we shall omit the dependence of F in ω to simplify notation.
In particular, given a set of n evaluation points S = {x1, . . . , xn} (the design), ∀xi ∈S the evaluation result
f(xi) is viewed as a sample value of the random variable F(xi). Kriging computes an unbiased linear predictor
of F(x) in the vector space HS = span{F(x1), . . . , F(xn)}, which can be written as
ˆF(x) = λ(x)TFS ,
with FS = [F(x1), . . . , F(xn)]T, and λ(x) the vector of Kriging coefﬁcients for the prediction at x.
Given the covariance function of F, the Kriging coefﬁcients can be computed along with the variance of the
prediction error
ˆσ2(x) = var( ˆF(x) −F(x)).
The covariance function of F is chosen within a parametrized class (for instance, the Matèrn class), and its
parameters are either estimated from the data or chosen a priori (see Section 8.3.2 for details on the choice of a
covariance function).
Once f has been evaluated at all evaluation points in S, the predicted value of f at x is given by
ˆf(x) = λ(x)TfS ,
Fig. 1 Naive approach to optimization using Kriging: (top) prediction ˆf (bold line) of the true function f (dotted line, supposedly
unknown) obtained from an initial design materialized by squares; (bottom) prediction after seven iterations minimizing ˆf.
with fS = [f(x1), . . . , f(xn)]T (fS is viewed as a sample value of FS). The same results could be derived in a
Bayesian framework, where F(x) is Gaussian conditionally to the evaluations carried out (FS = fS), with mean
ˆf(x) and variance ˆσ2(x).
Note that the random processes F(x) and ˆF(x) satisfy
ˆF(xi) = F(xi),
and that the prediction at xi
∈S is f(xi). When f is assumed to be evaluated exactly, Kriging is thus an
interpolation, with the considerable advantage over other interpolation methods that it also provides an explicit
characterization of the prediction error (zero-mean Gaussian with variance ˆσ2(x)).
2.2 Adaptive sampling strategies
The general principle of optimization using Kriging is iteratively to evaluate f at a point that optimizes a criterion
based on the model obtained using previous evaluation results. The simplest approach would be to choose a
minimizer of the prediction ˆf as a new evaluation point. However, by doing so, too much conﬁdence would
be put in the current prediction and search is likely to stall on a local optimum (as illustrated by Figure 1). To
compromise between local and global search, more emphasis has to be put on the prediction error, which can
indicate locations where additional evaluations are needed to improve conﬁdence in the model. This approach
has led to a number of criteria to select additional evaluation points based on both prediction and prediction error.
A standard example of such a criterion is expected improvement (EI) . As the name suggests, it involves
computing how much improvement in the optimum is expected, if f is evaluated at a given additional point. Let
fmin be the best function value obtained so far. The improvement expected from an additional evaluation of f at
x given fS, the results of past evaluations, can then be expressed as
EI(x) = E [max (fmin −F (x) , 0) |FS = fS] .
Since F(x) is conditionally Gaussian with mean ˆf(x) and variance ˆσ2(x),
EI(x) = ˆσ(x)
uΦ(u) + dΦ
Fig. 2 EI approach to optimization using Kriging: (top) prediction ˆf (bold line), 95% conﬁdence intervals computed using ˆσ (dashed
line) and true function f (dotted line); (bottom) expected improvement.
u = fmin −ˆf(x)
and Φ the normal cumulative distribution function. The new evaluation point is then chosen as a global maximizer
of EI(x). An example is given on Figure 2, where the problem that deceived the naive method of Figure 1 is
directly solved with the EI criterion. This method has been used for computer experiments in , while modiﬁed
criteria have been used in and to deal with noisy functions.
In and , a fair number of alternative criteria are presented and compared. Although quite different
in their formulation, they generally aim to answer the same question: What is the most likely position of x∗?
Another, and probably more relevant, question is: Where should the evaluation be carried out optimally to improve
knowledge on the global minimizers?
In what follows, a criterion that addresses this question will be presented, along with its performances. The
reference for comparison will be EI, which is a reasonable compromise between local and global search , and
has been successfully used in many applications.
3 Estimating the density of x∗
Once a Kriging surrogate model ˆf has been obtained, any global minimizer of ˆf is a natural approximation of x∗.
However, it might be excessively daring to trust this approximation as it does not take in account the uncertainty
of the prediction. A more cautious approach to estimating x∗is to use the probabilistic framework associated
with F. Of course, x∗is not necessarily unique, and we shall focus on describing the set of all global minimizers
of f as efﬁciently as possible.
3.1 Probabilistic modeling of the global minimizers of f
According to the GP model, a global minimizer x∗of f corresponds to a global minimizer of this particular
sample path of F. It seems therefore natural to use the GP model of f to obtain a probabilistic model for x∗.
Consider the random set M∗
X of the global minimizers of F over X, i.e. the set of all global minimizers for each
sample path, which for any ω ∈Ωcan be written as
X(ω) = {x∗∈X|F(ω, x∗) = min
u ∈X F(ω, u)}.
To ensure that M∗
X(ω) is not empty for all ω, we assume that F has continuous sample paths with probability
one. This continuity can be ensured through a proper choice of covariance function (see, e.g., ).
Let X∗be a random vector uniformly distributed on M∗
X (from now on, we omit the dependency of M∗
in ω). The probability density function of this random vector conditional to past evaluation results, that we shall
thereafter call conditional density of the global minimizers and denote pX∗|fS(x) , is of great interest, as it allows
one not only to estimate the global minimizers of f (for example, through the maximization of their conditional
density), but also to characterize the uncertainty associated with this estimation. In fact, pX∗|fS(x) contains all of
what has been assumed and learned about the system. However, no tractable analytical expression for pX∗|fS(x)
is available . To overcome this difﬁculty, the approach taken here is to consider a discrete version of the
conditional distribution, and to approximate it using Monte Carlo simulations.
Let G = {x1, . . . , xN} be a ﬁnite subset of X, M∗
G be the random set of global minimizers of F over G, and
G be a random vector uniformly distributed on M∗
G. The conditional probability mass function of X∗
G given fS
(or simply minimizers distribution) is then ∀x ∈G
G|fS(x) = P(X∗
G = x | FS = fS) .
It can be approximated using conditional simulations, i.e., simulations of F that satisfy FS = fS. Assuming that
non-conditional simulations are available, several methods exist to make them conditional . Conditioning by
Kriging seems the most promising of them in the present context and will be presented in the next section.
To keep the presentation simple, we assume in what follows that S ⊂G.
3.2 Conditioning by Kriging
This method, due to G. Matheron, uses the unbiasedness of the Kriging prediction to transform non-conditional
simulations into simulations interpolating the results fS of the evaluations. The idea is to sample from the conditional distribution of the prediction error F −ˆF rather than from the conditional distribution of F, which is
made easier by the fact that the statistical properties of the prediction error do not depend on the result of the
evaluations, nor on the mean m(x) of F(x).
To present this more formally, let Z be a zero-mean Gaussian process with covariance function k (the same as
that of F) and ˆZ be its Kriging predictor based on the random variables Z(xi), xi ∈S, and consider the random
T (x) = ˆf(x) + 
Z(x) −ˆZ(x)
where ˆf is the mean of the Kriging predictor based on the design points in S. Since this Kriging predictor is an
interpolator, at evaluation points in S, we have ˆf(xi) = f(xi). Equation (4) implies that Z(xi) = ˆZ(xi), which
leads to T (xi) = f(xi), ∀xi ∈S. In other words, T is such that all its sample paths interpolate the known
values of f. It is then easy to check that T has the same ﬁnite-dimension distributions as F conditionally to past
evaluation results , simply because the prediction error Z−ˆZ, for Z, has the same distribution as the prediction
error for F , F −ˆF. Note that the same vector λ(x) of Kriging coefﬁcients is used to interpolate the data and the
simulations at design points. Using (3), one can rewrite (6) as
T (x) = Z(x) + λ(x)T [fS −ZS] ,
with ZS = [Z(x1), . . . , Z(xn)]T.
In summary, to simulate F over G conditionally to past evaluation results fS, we can simulate a zero-mean
Gaussian process Z over G, compute the prediction error for each simulation and shift the prediction error around
the desired mean ˆf. This is achieved by the following procedure (illustrated on Figure 3):
– compute, for every point in G, the vector of Kriging coefﬁcients based on the design points in S,
– compute the Kriging prediction ˆf(x) based on past evaluation results fS for every x in G,
– collect non-conditional sample paths of Z over G (provided that a Gaussian sampler is available, setting the
proper covariance for the simulated vector can be achieved using, for example, the Cholesky decomposition),
ˆf + (z −ˆz), ˆf
Fig. 3 Conditioning a simulation: (top) unknown real curve f (doted line), sample points (squares) and associated Kriging prediction
ˆf (bold line); (middle) non-conditional simulation z, sample points and associated Kriging prediction ˆz (bold line); (bottom) the
simulation of the Kriging error z −ˆz is picked up from the non-conditional simulation and added to the Kriging prediction to get the
conditional simulation (thin line).
– apply (7) for each non conditional simulation and at every point in G. That is, to generate t(x), a conditional
simulation of T (x) from a non-conditional simulation z(x) of Z(x), apply
t(x) = z(x) + λ(x)T[fS −zS],
where zS is the sampled valued of Z over S, which is available since S ⊂G.
With this sampling method, it becomes straightforward to estimate PX∗
G|fS. Let x∗
i be a global minimizer of
the i-th conditional simulation (i = 1, . . . , r) over G (if it is not unique, choose one randomly). Then, for any x
in G, a classical estimator is
G |fS(x) = 1
with δ the Kronecker symbol. Figure 4 presents the approximation ˆPX∗
G|fS for an example where locating a global
minimizer is not easy. Knowing the conditional distribution of X∗
G gives valuable information on the areas of X
where a global minimizer might be located, and that ought to be investigated. This idea will be detailed in the
next section.
4 The stepwise uncertainty reduction strategy
The knowledge about the global minimizers of f is summarized by ˆPX∗
G|fS. In order to evaluate the interest of a
new evaluation of f at a given point, a measure of the expected information gain is required. An efﬁcient measure
is conditional entropy, as used in sequential testing in the Stepwise Uncertainty Reduction (SUR) strategy.
This section extends the SUR strategy to global optimization.
Fig. 4 Estimation of the distribution of X∗
G: (top) Kriging interpolation, 95% conﬁdence intervals and sample points; (bottom) estimated distribution of X∗
G using 10000 conditional simulations of F and a regular grid for G.
4.1 Conditional entropy
The entropy of a discrete random variable U (expressed in bits) is deﬁned as:
P(U = u) log2 P(U = u).
H(U) measures the spread of the distribution of U. It decreases as this distribution gets more peaked. In particular
G |fS(x) = 1/N ∀x ∈G ⇒H(X∗
G) = log2(N),
G |fS(x) =
0 if x ̸= x0
1 if x = x0
Similarly, for any event B, the entropy of U relative to the probability measure P(.|B) is
H(U|B) = −
P(U = u|B) log2 P(U = u|B).
The conditional entropy of U given another discrete random variable V is
P(V = v)H(U|V = v),
and the conditional entropy of U given B and V is
H(U|B, V ) =
P(V = v|B)H(U|B, V = v).
Note that H(U|V ) and H(U|B, V ) are, despite the similarity of notation with conditional expectation, deterministic quantities. More details on conditional entropy can be found in .
4.2 Conditional minimizers entropy
Let FQ(x) be a discrete version of F(x), deﬁned as FQ(x) = Q(F(x)) with Q a quantization operator. Q is
characterized by a ﬁnite set of M real numbers {y1, . . . , yM}, and deﬁned ∀u ∈R as
Q(u) = yk with k = min
For optimization problems, the SUR strategy for the selection of the next value of x ∈X at which f will be
evaluated will be based on H(X∗
G|FS = fS, FQ(x)), the conditional entropy of X∗
G given the evaluation results
{FS = fS} and FQ(x) (we shall refer to it later on as conditional entropy of the minimizers, or simply minimizers
Using (10) we can write
G|FS = fS, FQ(x)) =
P(FQ(x) = yi|FS = fS)H(X∗
G|FS = fS, FQ(x) = yi)
G|FS = fS, FQ(x) = yi) = −
G |fS,yi(u) log2 PX∗
G|fS,yi(u) ,
G|fS,yi(u) = P(X∗= u|FS = fS, FQ(x) = yi).
G|FS = fS, FQ(x)) is a measure of the anticipated uncertainty remaining in X∗
G given the candidate
evaluation point x and the result fS of the previous evaluations. Anticipation is introduced in (12) by considering the entropy of X∗
G resulting from every possible sample value of FQ(x). At each stage of the iterative
optimization, the SUR strategy retains for the next evaluation a point that minimizes the expected entropy of the
minimizers distribution after the evaluation, i.e., a point that maximizes the expected gain in information about
The conditional entropy of the minimizers thus takes in account the conditional statistical properties of F
and particularly the covariance function of the model. There lies the interest of the SUR strategy applied to
global optimization. It makes use of what has been previously assumed and learned about f to pick up the
most informative evaluation point. By contrast, the EI criterion (as most standard criteria) depends only on the
conditional mean and variance of F at the design point being considered.
5 Implementing the SUR strategy
5.1 IAGO algorithm
Our algorithm is similar in spirit to the strategy for Kriging-based optimization known as Efﬁcient Global Optimization (EGO) . EGO starts with a small initial design, estimates the parameters of the covariance function
of F and computes the Kriging model. Based on this model, an additional point is selected in the design space to
be the location of the next evaluation of f using the EI criterion. The parameters of the covariance function are
then re-estimated, the model re-computed, and the process of choosing new points continues until the improvement expected from sampling additional points has become sufﬁciently small. The IAGO algorithm uses the
same idea of iterative incorporation of the obtained information to the prior on the function, but with a different
criterion.
To compute the minimizers entropy using (12), a different quantization operator Qx is used for each value of
x to improve the precision with which the empirical mean of entropy reduction over possible evaluation results
is computed. We use the fact that F(x) is conditionally Gaussian with mean ˆf(x) and variance ˆσ2(x) obtained
by Kriging, to select a set of values {y1(x), . . . , yM(x)}, such that
P(FQx(x) = yi|FS = fS) = 1
M ∀i ∈J1 : MK .
Here we used a set of ten possible values (M = 10).
For each of these possible values (or hypotheses F(x) = yi), ˆPX∗
G|fS,yi is computed using conditional
simulations. The minimizers entropy is then obtained using (12). These operations are carried out on a discrete set
of candidate evaluation points (see Section 5.2 for some details on the choice of this set), and a new evaluation of
Input: Set S = {x1, . . . , xn} of evaluation points and corresponding values fS of the function f
Output: Additional evaluation point xnew
Choose G, a discrete representation of X
Set covariance parameters either a priori or by maximum-likelihood estimation based on fS
Compute r non-conditional simulations over G
Compute ˆf(x) and ˆσ(x) over G by Kriging from fS
while the set of candidate points has not been entirely explored
do Take an untried point xc in the set of candidate points
Compute the parameters {y1, . . . , yM} of the quantization operator Q
Compute the Kriging coefﬁcients at every point in G based on evaluation points in S and xc
for i ←1 to M
do Construct conditional simulations using (7) and assuming that f(xc) = yi
Find a global minimizer x∗
k of the k-th conditional simulation over G (k = 1, . . . , r)
Estimate PX∗
G|fS,yi over G using (9)
Compute H(X∗
G|FS = fS, FQ(xc) = yi)
Compute the minimizers entropy given an evaluation at xc using (12)
15. Output xnew that minimizes the conditional entropy over the set of candidate points
Table 1 Selection of a new evaluation point for f.
f is ﬁnally performed at a point that minimizes minimizers entropy. Next, as in the EGO algorithm, the covariance
parameters are re-estimated and the model re-computed. The procedure for the choice of an additional evaluation
point is described in Table 1.
When the number of additional function evaluations is not speciﬁed beforehand, we propose to use as a
stopping criterion the conditional probability that the global minimum of the GP model be no further apart of
fmin = minxi∈S f(xi) (the best function value yet obtained) than a given tolerance threshold δ. The algorithm
then stops when
P(F ∗< fmin + δ|FS = fS) < PStop ,
with F ∗= minx ∈G F(x), and PStop ∈ a critical value to be chosen by the user. Proposed in , this
stopping criterion is well suited here, since evaluating the repartition function of f(x∗) does not require any
additional computation. We can indeed use the conditional simulations that have been performed to approximate
the conditional distribution of X∗
G for this purpose, provided that we keep track, for each of them, not only of a
global minimizer, but also of the minimum. The histogram thus obtained can then easily be transformed into a
simple approximation of the conditional repartition function of the minimum.
5.2 Computational complexity
With the previous notation, n the number of evaluation points, r the number of conditional simulations, N the
number of points in G and M the number of discretized potential evaluation results for an evaluation, the computational complexity for the approximation of the minimizers entropy (Steps 7 to 14 in Table 1) is as follows:
– computing Kriging coefﬁcients at every point in G (Step 8): O(n2N), as (20) (to be found in appendix) has
to be solved N times while changing the n + 1-st evaluation point each time. A large part of the factorization
of the covariance matrix can be reused, and Kriging at an untried point is then simply in O(n2),
– constructing conditional simulations (Step 10): O(nrN) (M is not involved since the main part of the conditioning procedure described by (8) can be carried out outside the loop on the discretized potential evaluation
– locating the global minimizers for each simulation by exhaustive search (Step 11): O(rNM).
Since all other operations are in O(N) at most, evaluating minimizers entropy at any given point requires O(N)
operations.
To complete the description of an implementable algorithm, we must specify a choice for G and a policy
for the minimization of minimizers entropy. What follows is just an example of a possible strategy, and many
variants could be considered.
The simplest choice for G is a uniform grid on X. However, as the number of evaluations of f increases, the
spread of PX∗
G |fS diminishes along with the precision for the computation of the entropy. To keep a satisfactory
precision over time, G can be a random sample of points in X, re-sampled after every evaluation of f with the
distribution ˆPX∗
G|fS. Re-sampling makes it possible to use a set G with a smaller cardinal and to escape, at least
partly, the curse of dimensionality (to resample using ˆPX∗
G|fS, any non-parametric density estimator could be
used along with a sampling method such as Metropolis-Hastings, see, e.g., ).
Ideally, to choose an additional evaluation point for f using IAGO, minimizers entropy should be minimized
over X. However, this of course is in itself a global optimization problem, with many local optima. It would be
possible to design an ad-hoc optimization method (as in ), but this perspective is not explored here. Instead,
we evaluate the criterion extensively over a chosen set of candidate points. Note that only the surrogate model is
involved at this stage, which makes the approach practical. The idea is, exactly as for the choice of G, to use a
space-ﬁlling sample covering X and resampled after each new evaluation. The current implementation of IAGO
simply uses a Latin Hyper Cube (LHC) sample, however, it would be easy to adapt this sample iteratively using
the conditional distribution of the minimizers ˆPX∗
G |fS as a prior. For instance, areas of the design space where
the distribution is sufﬁciently small could be ignored. After a few evaluations, a large portion of the design space
usually satisﬁes this property, and the computations saved could be used to improve knowledge on the criterion
by sampling where ˆPX∗
G|fS is high (using the same approach as for the choice of G).
As dimension increases, trying to cover the factor space while keeping the same accuracy leads to an exponential increase in complexity. However, in a context of expensive function evaluation, the objective is less
to specify exactly all global minimizers (which would be too demanding in function evaluations anyway), than
to use available information efﬁciently to reduce the likely areas for the location of these minimizers. This is
exactly the driving concept behind IAGO. In practice, within a set of one thousand candidate points, picking
an additional evaluation point requires about three minutes with a standard personal computer (and this ﬁgure
is relatively independent of the dimension of factor space). Moreover, the result obtained can be trusted to be a
consistent choice within this set of candidate points, in regard of what has been assumed and learned about f.
5.3 Taking noise in account
Practical optimization problems often involve noise. This section discusses possible adaptations of the optimization algorithm that make it possible to deal with noisy situations, namely noise on the evaluation of f and noise
on the factors.
5.3.1 Noise on the evaluation of f
When the results of the evaluations of f are corrupted by noise, the algorithm must take this fact into account. A
useful tool to deal with such situations is non-interpolative Kriging (see Section 8.2).
If the evaluation at xi ∈S is assumed to be corrupted by an additive Gaussian noise εi with known mean and
variance, the Kriging prediction should no longer be interpolative. The optimization algorithm remains nearly
unchanged, except for the conditional simulations. Sample paths of F, should be built conditionally to evaluation
results, i.e. realizations of the random variables f(xi) + εi for xi ∈S. Since the variance of the prediction
error is no longer zero at evaluation points (in other words, there is some uncertainty left on the values of f at
evaluation points), we ﬁrst have to sample, at each evaluation point, from the distribution of F conditionally to
noisy evaluation results. An interpolative simulation, based on these samples, is then built using conditioning by
Kriging. An example of such a simulation is presented on Figure 5 for a noise variance of 0.01.
5.3.2 Noise on the factors
In many industrial design problems, the variability of the values of the factors in mass production has a signiﬁcant
impact on performance. One might then want to design a system that optimizes some performance measure while
ensuring that performance uncertainty (stemming from noise on the factors) remains under control. These socalled robust optimization problems can generally be written as
with J(x) a cost function reﬂecting some statistical property of the corrupted performance measure f(x + ε),
where ε is a random vector accounting for noise on the factors. Classical cost functions are:
– mean: J(x) = Eε[f(x + ε)],
– standard deviation: J(x) =
varε(f(x + ε)),
– linear combination of mean and standard deviation: J(x) = Eε[f(x + ε)] +
varε(f(x + ε)),
Fig. 5 Example of prediction by Kriging (bold line) of noisy measurements represented by squares. Dashed lines represent 95%
conﬁdence regions for the prediction and the thin solid line is an example of conditional simulation obtained using the method
presented in Section 5.3.1.
– α-quantile: J(x) = Qα(x) with Qα(x) such that P(f(x + ε) < Qα(x)) = α.
Using, for example, the α-quantile as a cost function, it is possible to adapt our optimization algorithm to solve
(14). Given a set of evaluation results fS at noise-free evaluation points, and if it is possible to sample from the
distribution pε of ε, a Monte Carlo approximation ˆQα(x) of Qα(x) is easily obtained by computing ˆf(x + ε)
over a set sampled from pε. The global optimization algorithm can then be applied to Qα(x) instead of f, using
pseudo-evaluations ˆ
S = [ ˆQα(x1), . . . , ˆQα(xn)] (recomputed after each evaluation of f) instead of fS. This
naive approach can certainly be improved, but is sufﬁcient to show the feasibility of a robust approach and to
illustrate on a simple example (to be presented in the next section) the impact of ε on the evaluation points to be
chosen by IAGO.
It is of course possible to combine these ideas and to deal simultaneously with noise both on the factors and
the function evaluations.
6 Illustrations
This section presents some simple examples of global optimization using IAGO, with a regular grid as a set of
candidate evaluation points. An empirical comparison with global optimization using expected improvement is
also presented. The Matérn covariance class will be used for Kriging prediction, as it facilitates the tuning of
the variance, regularity and range of correlation of the underlying random process, but note that any kind of
admissible covariance function could have been used. The parameters of the covariance may be estimated from
the data using a maximum-likelihood approach (see Section 8.3).
6.1 A one-dimensional example
Consider the function with two global minimizers illustrated by Figure 6 and deﬁned by f : x 7−→4[1 −sin(x +
8 exp(x −7))]. Given an initial design consisting of three points, the IAGO algorithm is used to compute six
additional points iteratively. The ﬁnal Kriging model is depicted in the left part of Figure 6, along with the
resulting conditional distribution for the minimizers on the right part. After adding some noise on the function
evaluations, the variant of IAGO presented in Section 5.3.1 is also applied to the function with the same initial
design. In both cases, six additional evaluations have signiﬁcantly reduced the uncertainty associated with the
position of the global minimizers. The remaining likely locations reduce to small areas centered on the two actual
global minimizers. In the noisy case, larger zones are identiﬁed, a direct consequence of the uncertainty associated
with the evaluations.
Figure 7 illustrates robust optimization using the same function and initial design, but considering an additive
zero-mean Gaussian noise on the factors with a standard deviation of 0.2. The cost function used is the 90%quantile Q90%, which is computed on the surrogate model but also, and only for the sake of comparison, on the
true function using Monte Carlo uncertainty propagation (the quantile is approximated using 5000 simulations).
After six iterations of the robust optimization algorithm, the distribution of the robust minimizers is sufﬁciently
peaked to give a good approximation of the true global robust minimizer.
These result are encouraging as they show that the requirement of fast uncertainty reduction is met. The next
section provides some more examples, along with a comparison with EGO, the EI-based global optimization
algorithm.
6.2 Empirical comparison with expected improvement
Consider ﬁrst the function described by Figure 8. Given an initial design of three points, both EI and minimizers entropy are computed. Their optimization provides two candidate evaluation points for f, which are also
presented on Figure 8, along with the post-evaluation prediction and conditional distribution for X∗
G. For this
example, the regularity parameter of the Matérn covariance is set a priori to a high value (2.5). By taking in
account the covariance function of F through conditional simulations, the minimizers entropy uses regularity to
conclude faster. The resulting conditional distribution of the minimizers is then generally more peaked using the
IAGO algorithm than using the EGO algorithm (as illustrated by Figure 8(c) and Figure 8(b)).
Consider now the Branin function (see, for instance, ), deﬁned as
f : [−5, 10] × −→R
(x1, x2) 7−→ x2 −5.1
πx1 −62 + 10  1 −
cos(x1) + 10.
It has three global minimizers x∗
1 ≈(−3.14, 12.27)T, x∗
2 ≈(3.14, 2.27)T and x∗
3 ≈(9.42, 2.47)T, and the global
minimum is approximately equal to 0.4. Given an initial uniform design of sixteen points, ﬁfteen additional
points are iteratively selected and evaluated using the IAGO and EGO algorithms. The parameters of the Matèrn
covariance are estimated on the initial design, and kept unchanged during both procedures. The positions of the
evaluation points are presented on Figure 9 (left), along with the three global minimizers. Table 2 summarizes the
results obtained with EGO and IAGO, based on the ﬁnal Kriging models obtained with both approaches. Note
that the EI criterion in EGO is maximized with a high precision, while minimizers entropy in IAGO is computed
over a thousand candidate evaluation points located on a regular grid. It appears nevertheless that the algorithm
using EI stalls on a single global minimizer, while the minimizers entropy allows a relatively fast estimation of all
three of them. Besides IAGO yields a better global approximation of the supposedly unknown function. If twenty
additional evaluations are carried out (as presented in the right part of Figure 9), the ﬁnal Kriging prediction using
minimizers entropy estimates the minimum with an error of less than 0.05 for all three minimizers (cf. Table 2),
while the use of EI does not improve the information on any minimizer any further. The difference between the
two strategies is clearly evidenced. The EI criterion, overestimating the conﬁdence in the initial prediction, has
led to performing evaluations extremely close to one another, for a very small information gain. In a context
of expensive function evaluation, this is highly detrimental. The entropy criterion, using the same covariance
parameters, does not stack points almost at the same location before having identiﬁed the most likely zones for
the minimizers. The use of what has been assumed and learned about the function is clearly more efﬁcient in this
case, and this property should be highly attractive when dealing with problems of higher dimension.
(a) Kriging prediction and conditional distribution of the global minimizers based on the initial design
(b) Standard IAGO algorithm (noise free case)
(c) IAGO algorithm for noisy evaluations (the additive noise is zero-mean Gaussian with standard deviation 0.2)
Fig. 6 Example of global optimization using IAGO on a function of one variable (dotted line), with an initial design consisting of three
points (represented by squares). Six additional evaluations are carried out (triangles) using two versions of the IAGO algorithm. The
graphs on the left part of the ﬁgure account for the predictions, while the right part presents the corresponding conditional distributions
of the global minimizers.
7 Discussion
7.1 Robustness to uncertainty on the covariance parameters
Jones studied in the potential of Kriging-based global optimization methods such as EGO. One of his most
important conclusion, is that these methods “can perform poorly if the initial sample is highly deceptive”. An
eloquent example is provided on page 373 , where a sine function is sampled using its own period, leading to
a ﬂat prediction over the domain, associated with a small prediction error.
Fig. 7 Example of robust optimization using IAGO and the cost function Q90%. The function f (dotted line), corrupted by an additive
Gaussian noise on the factor (zero mean with a standard deviation of 0.2), is studied starting from the initial design of three points
already used in Figure 6. Six additional evaluations are carried out (triangles), which are used to estimate the cost function based on the
Kriging model (bold line), along with the conditional distribution of the robust minimizers (right). The cost function Q90% estimated,
only for the sake of comparison, from the true function using Monte Carlo uncertainty propagation is also provided (mixed line).
Table 2 Estimation results for the Branin function using the evaluations of Figure 9
15 iterations
35 iterations
15 iterations
35 iterations
Euclidean distance between x∗
ﬁnal estimate
Value of the true function at estimated
Euclidean distance between x∗
ﬁnal estimate
Value of the true function at estimated
Euclidean distance between x∗
ﬁnal estimate
Value of the true function at estimated
This potential for deception is present throughout the IAGO procedure, and should not be ignored. To overcome this difﬁculty, several methods have been proposed (see, e.g., Enhanced Method 4 in or ), which
achieve some sort of robustness to an underestimation of the prediction error and more generally to a bad choice
of covariance function. They seem to perform better than classical algorithms, including EGO.
Comparing the IAGO approach to such methods is an interesting topic for future research. The issue considered here was to demonstrate the interest of the minimizers entropy criterion, and we felt that this had to be done
independently from the rest of the procedure.
It is of course essential to make IAGO robust to errors in the estimation of the covariance parameters. In
many industrial problems, this can be easily done by using prior knowledge on the unknown function to restrict
the possible values for these parameters. For example, experts of the ﬁeld often have information regarding the
range of values attainable by the unknown function. This information can be directly used to restrict the search
space for the variance of the modeling process F, or even to choose it beforehand.
More generally, given the probabilistic framework used here, it should be relatively easy to develop a Bayesian
or minimax extension of IAGO to guide the estimation of the parameters of the covariance function. A comparison with robust methods such as those detailed in will then be essential.
7.2 Conclusions and perspectives
In this paper, a stepwise uncertainty reduction strategy has been used for the sequential global optimization of
expensive-to-evaluate functions. This strategy iteratively selects a minimizer of the conditional minimizers entropy as the new evaluation point. To compute this entropy, a Gaussian random model of the function evaluations
is used and the minimizers entropy is estimated through Kriging and conditional simulations. At each iteration,
the result of the new evaluation is incorporated in the data base used to re-build the Kriging model (with a possible
re-estimation of the parameters of its covariance function).
(a) Initial prediction and minimizers distribution
(b) Prediction and minimizers distribution after an additional evaluation of f chosen with EI
(c) Prediction and minimizers distribution after an additional evaluation of f chosen with minimizers entropy
Fig. 8 Comparison between minimizers entropy and EI: the left side contains the Kriging predictions before and after an additional
evaluation chosen with either EI or minimizers entropy, while the right side presents the corresponding conditional distribution of the
global minimizers.
We have shown on some simple examples that, compared to the classical EI-based algorithm EGO, the
method proposed signiﬁcantly reduces the evaluation effort in the search for global optimizers. The stepwise
uncertainty reduction strategy allows the optimization method to adapt the type of search to the information
available on the function. In particular, the minimizers entropy criterion makes full use of the assumed regularity
of the unknown function to balance global and local searches.
Choosing an adequate set of candidate points is crucial, as it must allow a good estimation of a global minimizer of the criterion, while keeping computation feasible. Promising results have already been obtained with
space-ﬁlling designs, and adaptive sampling based on the conditional density of the global minimizers should be
useful as dimension increases.
(a) 15 iterations using EGO
(b) 35 iterations using EGO
(c) 15 iterations using IAGO
(d) 35 iterations using IAGO
Fig. 9 Fifteen iterations of two optimization algorithms, that differ by their criteria for selecting evaluation points for f, on the Branin
function: (top) the EI criterion is used, (bottom) the minimizers entropy criterion is used with a thousand candidate evaluation points
for f set on a regular grid (squares account for initial data, triangles for new evaluations, and crosses give the actual locations of the
three global minimizers).
Extension to constrained optimization is an obviously important topic for future investigations. When it is
easy to discard the candidate points in X that do not satisfy the constraints, the extension is trivial. For expensiveto-evaluate constraints, the extension is a major challenge.
Finally, the stepwise uncertainty reduction strategy associated with conditioning by Kriging is a promising
solution for the robust optimization of expensive-to-evaluate functions, a problem that is central to many industrial
situations, for which an efﬁcient product design must be found in the presence of signiﬁcant uncertainty on the
values actually taken by some factors in mass production. In addition, robustness to the uncertainty associated
with the estimation of the parameters of the covariance function should also be sought.
8 Appendix: modeling with Gaussian processes
This section recalls the main concepts used in this paper, namely Gaussian process modeling and Kriging. The
major results will be presented along with the general framework for the estimation of the model parameters.
8.1 Kriging when f is evaluated exactly
Kriging is a prediction method based on random processes that can be used to approximate or interpolate
data. It can also be understood as a kernel regression method, such as splines or Support Vector Regression
 . It originates from geostatistics and is widely used in this domain since the 60s. Kriging is also known as
the Best Linear Unbiased Prediction (BLUP) in statistics, and has been more recently designated as Gaussian
Processes (GP) in the 90s in the machine learning community.
As mentioned in Section 2.1, it is assumed that the function f is a sample path of a Gaussian random process
F. Denote by m(x) = E[F(x)] the mean function of F(x) and by k(x, y) its covariance function, written as
k(x, y) = cov(F(x), F(y)).
Kriging then computes the BLUP of F(x), denoted by ˆF(x), in the vector space generated by the evaluations
HS = span{F(x1), . . . , F(xn)}. As an element of HS, ˆF(x) can be written as
ˆF(x) = λ(x)TFS .
As the BLUP, ˆF(x) must have the smallest variance for the prediction error
ˆσ2(x) = E[( ˆF(x) −F(x))2],
among all unbiased predictors. The variance of the prediction error satisﬁes
ˆσ2(x) = k(x, x) + λ(x)TKλ(x) −2λ(x)Tk(x),
K =  k(xi, xj)
, (i, j) ∈J1, nK2
the n × n covariance matrix of F at evaluation points in S, and
k(x) = [k(x1, x), . . . , k(xn, x)]T
the vector of covariances between F(x) and FS
The prediction method assumes that the mean of F(x) can be written as a ﬁnite linear combination
m(x) = βTp(x),
where β is a vector of ﬁxed but unknown coefﬁcients, and
p(x) = [p1(x), . . . , pl(x)]T
is a vector of known functions of the factor vector x. Usually these functions are monomials of low degree in the
components of x (in practice, their degree does not exceed two). These functions may be used to reﬂect some
prior knowledge on the unknown function. As we have none for the examples considered here, we simply use an
unknown constant.
The Kriging predictor at x is then the best linear predictor subject to the unbiasedness constraint E( ˆF(x)) =
m(x), whatever the unknown β. The unbiasedness constraint translates into
βTP Tλ(x) = βTp(x),
For (18) to be satisﬁed for all β, the Kriging coefﬁcients must satisfy the linear constraints
P Tλ(x) = p(x),
called universality constraints by Matheron. At this point, Kriging can be reformulated as follows: ﬁnd the vector
of Kriging coefﬁcients that minimizes the variance of the prediction error (17) subject to the constraints (19).
This problem can be solved via a Lagrangian formulation, with µ(x) a vector of l Lagrange multipliers for the
constraints in (19). The coefﬁcients λ(x) are then solutions of the linear system of equations
with 0 a matrix of zeros. A convenient expression for the variance of the prediction error is obtained by substituting k(x) −P µ(x) for Kλ(x) in (17) as justiﬁed by (20), to get
ˆσ2(x) = E
F(x) −ˆF(x)2 = k(x, x) −λ(x)Tk(x) −p(x)Tµ(x) .
The variance of the prediction error at x can thus be computed without any evaluation of f, using (20) and (21).
It provides a measure of the quality associated with the Kriging prediction. Evaluations of f remain needed to
estimate the parameters of the covariance function of F (if any), as will be seen in Section 8.3.2.
Once f has been evaluated at all evaluation points, the prediction of the value taken by f at x becomes
ˆf(x) = λ(x)TfS ,
with fS = [f(x1), . . . , f(xn)]T (fS is viewed as a sample value of FS).
It is easy to check that (20) implies that
ˆF(xi) = F(xi).
The prediction of f at xi ∈S is then f(xi), so Kriging is an interpolation with the considerable advantage that
it also accounts for model uncertainty through an explicit characterization of the prediction error.
Remark: The Bayesian framework (see, for instance, ) is an alternative approach to derive the BLUP, in
which F is viewed as a Bayesian prior on the output. In the case of a zero-mean model, the conditional distribution
of the function is then Gaussian with mean
E [F(x)| FS = fS] = k(x)TK−1fS,
and variance
Var [F(x)| FS = fS] = k(x, x) −k(x)TK−1k(x),
which are exactly the mean (22) and variance (21) of the Kriging predictor for a model F with zero mean. The
Kriging predictor can also be viewed as the conditional mean of F(x) in the case of an unknown mean, if the
universality constraints are viewed as a non-informative prior on β.
8.2 Kriging when f is evaluated approximately
The Kriging predictor was previously deﬁned as the element of the space HS generated by the random variables
F(xi) that minimizes the prediction error. A natural step is to extend this formulation to the case of a function
whose evaluations are corrupted by additive independent and identically distributed Gaussian noise variables εi
with zero mean and variance σ2ε. The model of the observations then becomes F obs
= F(xi) + εi, i = 1, . . . , n,
and the Kriging predictor for F(x) takes the form ˆF(x) = λ(x)TF obs
with F obs
x1 , . . . , F obs
unbiasedness constraint (19) remain unchanged, while the mean-square error (2) becomes
E[ ˆF(x) −F(x)]2 = k(x, x) + λ(x)T(K + σ2
εIn)λ(x) −2λ(x)Tk(x),
with In the identity matrix. Finally, using Lagrange multipliers as before, it is easy to show that the coefﬁcients
λ(x) of the prediction must satisfy
K + σ2εIn P
The resulting prediction is no longer interpolative, but can still be viewed as the mean of the conditional distribution of F. The variance of the prediction error is again obtained using (21).
8.3 Covariance choice
Choosing a suitable covariance function k(·, ·) for a given f is a recurrent and fundamental question. It involves
the choice of a parametrized class (or model) of covariance, and the estimation of its parameters.
Fig. 10 Matérn covariances with ρ = 0.5, σ2 = 1. Solid line corresponds to ν = 4, dashed line to ν = 1 and dotted line to ν = 0.25.
8.3.1 Covariance classes
The asymptotic theory of Kriging stresses the importance of the behaviour of the covariance near the origin.
This behaviour is indeed linked with the quadratic-mean regularity of the random process. For instance, if the
covariance function is continuous at the origin, then the process will be continuous in quadratic mean. In practice, one often uses covariances that are invariant by translation (or equivalently stationary), isotropic, and such
that regularity can be adjusted. Non-stationary covariances are seldom used in practice, as they make parameter
estimation particularly difﬁcult . Isotropy, however, is not required and can even be inappropriate when the
factors are of different natures. An example of an anisotropic, stationary covariance class is k(x, y) = k(h), with
(x −y)TA(x −y) where (x, y) ∈X2 and A is a symmetric positive deﬁnite matrix.
A number of covariance classes are classically used (for instance, exponential h 7→σ2 exp(−θ|h|α), product
of exponentials, or polynomial). The Matérn covariance class offers the possibility to adjust regularity with a
single parameter . Stein advocates the use of the following parametrization of the Matérn class:
where Kν is the modiﬁed Bessel function of the second kind . This parameterization is easy to interpret,
as ν controls regularity, σ2 is the variance (k(0) = σ2), and ρ represents the range of the covariance, i.e., the
characteristic correlation distance. To stress the signiﬁcance and relevance of the regularity parameter, Figure 10
shows the inﬂuence of ν on the covariance function, and Figure 11 demonstrates its impact on the sample paths.
Since Kriging assumes that f is a sample path of F, a careful choice of the parameters of the covariance is
essential.
8.3.2 Covariance parameters
The parameters for a given covariance class can either be ﬁxed using prior knowledge on the system, or be
estimated from experimental data. In geostatistics, estimation is carried out using the adequacy between the
empirical and model covariances . In other areas, cross validation and maximum likelihood are
mostly employed. For simplicity and generality reasons , the maximum-likelihood method is preferred here.
Using the joint probability density of the observed Gaussian vector, and assuming that the mean of F(x) is
Fig. 11 Three sample paths of a zero-mean Gaussian process with a Matérn covariance. Conventions are as in Figure 10: ν = 4 for
the solid line, ν = 1 for the dashed line and ν = 0.25 for the dotted line.
zero for the sake of simplicity, one obtains the maximum-likelihood estimate of the vector θ of the covariance
parameters (see, for instance, ) by minimizing the negative log-likelihood
2 log 2π + 1
2 log det K(θ) + 1
S K(θ)−1fS .
When the mean for F(x) is unknown, the parameters can be estimated, using for example the REstricted Maximum Likelihood (REML, see ). This is the approach used for the examples in this paper.
Figure 12 illustrates prediction by Kriging with a Matérn covariance, the parameters of which have been
estimated by REML. The prediction interpolates the data, and conﬁdence intervals are deduced from the square
root of the variance of the prediction error to assess the quality of the prediction between data. Figure 12 also
contains a series of conditional simulations (obtained with the method explained in Section 3.2), namely sample
paths of F that interpolate the data. As implied by (23), the Kriging prediction is the mean of these conditional
simulations.
Acknowledgements
The authors wish to thank Donald R. Jones for his comments that greatly contributed to improving the accuracy
and clarity of this paper.