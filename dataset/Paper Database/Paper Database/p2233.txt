IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.21391931
A survey of active learning algorithms for
supervised remote sensing image classiﬁcation
Devis Tuia, Member, IEEE, Michele Volpi, Student Member, IEEE, Loris Copa,
Mikhail Kanevski, Jordi Mu˜noz-Mar´ı
This is the pre-acceptance version, to read the ﬁnal version published in 2011 in the IEEE Journal of Selected Topics in Signal Processing (IEEE JSTSP), please go to: 10.1109/JSTSP.2011.2139193
Deﬁning an efﬁcient training set is one of the most delicate phases for the success of remote sensing image classiﬁcation routines. The complexity of the problem, the limited temporal and ﬁnancial resources,
as well as the high intraclass variance can make an algorithm fail if it is trained with a suboptimal dataset.
Active learning aims at building efﬁcient training sets by iteratively improving the model performance
through sampling. A user-deﬁned heuristic ranks the unlabeled pixels according to a function of the
uncertainty of their class membership and then the user is asked to provide labels for the most uncertain
pixels. This paper reviews and tests the main families of active learning algorithms: committee, large
margin and posterior probability-based. For each of them, the most recent advances in the remote sensing
community are discussed and some heuristics are detailed and tested. Several challenging remote sensing
scenarios are considered, including very high spatial resolution and hyperspectral image classiﬁcation.
Finally, guidelines for choosing the good architecture are provided for new and/or unexperienced user.
Manuscript received April 2010;
This work has been supported by the Swiss National Science Foundation (grants no. 200021-126505 and PBLAP2-
127713/1), and by the Spanish Ministry of Education and Science under projects TEC2009- 13696, AYA2008-05965-C04-03,
and CONSOLIDER/CSD2007-00018.
DT and JMM are with the Image Processing Laboratory, University of Val`encia, Val`encia, Spain. C/ Cat. A. Escardino. 46980
Paterna, Val`encia, Spain. Email: {devis.tuia,jordi}@uv.es, Phone: +34 963544021, Fax: +34 963544353
MV and MK are with the Institute of Geomatics and Analysis of Risk, University of Lausanne, Lausanne, Switzerland. Email:
{michele.volpi,mikhail.kanevski}@unil.ch, Phone: +4121-6923546, Fax: +4121-6923535
LC was with the Institute of Geomatics and Analysis of Risk, University of Lausanne, Lausanne, Switzerland. He is now
with SARMAP SA, Switzerland. Email: , Phone +41 916009365
April 19, 2021
 
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.21391932
Index Terms
Image classiﬁcation, Active learning, Training set deﬁnition, SVM, VHR, Hyperspectral.
I. INTRODUCTION
Nowadays, the recourse to statistical learning models is a common practice for remote
sensing data users; models such as Support Vector Machines (SVM, , ) or neural networks are considered as state of the art algorithms for the classiﬁcation of landuse using
new generation satellite imagery . Applications of such models to very high spatial – 
or spectral – resolution have proven their efﬁciency for handling remote sensing data.
However, the performances of supervised algorithms strongly depend on the representativeness
of the data used to train the classiﬁer . This constraint makes the generation of an appropriate
training set a difﬁcult and expensive task requiring extensive manual analysis of the image. This
is usually done by visual inspection of the scene or by ﬁeld surveys and successive labeling of
each sample.
In the case of ﬁeld surveys, which is usual for medium resolution, hyperspectral or SAR
images, the discovery of a new label is expensive – both in terms of time and money – because
it involves terrain campaigns. Therefore, there is a limit to the number of pixels that can be
acquired. For this reason, compact and informative training sets are needed.
In the case of visual inspection or photo-interpretation, more common in VHR imagery, it is
easier to collect data samples, since the labeling can be done directly on the image. However,
the labeling is often done by mass selection on screen and several neighboring pixels carrying
the same information are included. As a consequence, the training set is highly redundant. Such
a redundancy considerably slows down the training phase of the model. Moreover, the inclusion
of noisy pixels may result in a wrong representation of the class statistics, which may lead to
poor classiﬁcation performances and/or overﬁtting . For these reasons, a training set built
by photointerpretation should also be kept as small as possible and focused on those pixels
effectively improving the performance of the model.
Summing up, besides being small, a desirable training set must be constructed in a smart way,
meaning it must represent correctly the class boundaries by sampling discriminative pixels. This
is particularly critical in very high spatial and spectral resolution image classiﬁcation, which
deal with large and/or complex features spaces using limited training information only .
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.21391933
In the machine learning literature this approach to sampling is known as active learning. The
leading idea is that a classiﬁer trained on a small set of well-chosen examples can perform
as well as a classiﬁer trained on a larger number of randomly chosen examples, while it is
computationally cheaper – . Active learning focuses on the interaction between the user
and the classiﬁer. In other words, the model returns to the user the pixels whose classiﬁcation
outcome is the most uncertain. After accurate labeling by the user, pixels are included into the
training set in order to reinforce the model. This way, the model is optimized on well-chosen
difﬁcult examples, maximizing its generalization capabilities.
The active learning framework has demonstrated its effectiveness when applied to large
datasets needing accurate selection of examples . This is suitable for remote sensing applications, where the number of pixels among which the search is performed is large and
manual deﬁnition is - as stated above - redundant and time consuming. As a consequence,
active learning algorithms gain an increasing interest in remote sensing image processing and
several approaches have been proposed to solve image classiﬁcation tasks. This paper presents the
general framework of active learning and reviews some of the methods that have been proposed
in remote sensing literature. Note that this survey only covers remote sensing application of
active learning principles: for a general introduction and survey of the most recent developments
in the machine learning community, please refer to , .
The remainder of the paper is organized as follows: Section II presents the general framework
of active learning and the families of methods that will be detailed in Sections III to V, as
well as the references to speciﬁc methods. Section VI presents the datasets considered in the
experiments. Section VII compares the different approaches numerically. Section VIII gives an
overview and guidelines for potential users. Section IX concludes the paper.
II. ACTIVE LEARNING: CONCEPTS AND DEFINITIONS
Let X = {xi, yi}l
i=1 be a training set of labeled samples, with xi ∈X and yi = {1, ..., N}.
X is the d-dimensional input space ∈Rd. Let also U = {xi}l+u
i=l+1 ∈X, with u ≫l be the set
of unlabeled pixels to be sampled, or the pool of candidates.
Active learning algorithms are iterative sampling schemes, where a classiﬁcation model is
adapted regularly by feeding it with new labeled pixels corresponding to the ones that are most
beneﬁcial for the improvement of the model performance. These pixels are usually found in the
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.21391934
Algorithm 1 General active learning algorithm
- Initial training set Xϵ = {xi, yi}l
i=1 (X ∈X, ϵ = 1).
- Pool of candidates U ϵ = {xi}l+u
i=l+1 (U ∈X, ϵ = 1).
- Number of pixels q to add at each iteration (deﬁning the batch of selected pixels S).
Train a model with current training set Xϵ.
for each candidate in U ϵ do
Evaluate a user-deﬁned heuristic
Rank the candidates in U ϵ according to the score of the heuristic
Select the q most interesting pixels. Sϵ = {xk}q
The user assigns a label to the selected pixels. Sϵ = {xk, yk}q
Add the batch to the training set Xϵ+1 = Xϵ ∪Sϵ.
Remove the batch from the pool of candidates U ϵ+1 = U ϵ\Sϵ
12: until a stopping criterion is met.
areas of uncertainty of the model and their inclusion in the training set forces the model to solve
the regions of low conﬁdence. For a given iteration ϵ, the algorithm selects from the pool U ϵ
the q candidates that will at the same time maximize the gain in performance and reduce the
uncertainty of the model when added to the current training set Xϵ. Once the batch of pixels
Sϵ = {xm}q
m=1 ⊂U has been selected, it is labeled by the user, i.e. the labels {ym}q
discovered. Finally, the set Sϵ is both added to the current training set (Xϵ+1 = Xϵ ∪Sϵ) and
removed from the pool (U ϵ+1 = U ϵ\Sϵ). The process is iterated until a stopping criterion is met.
Algorithm 1 summarizes the active selection process. From now on, the iteration index ϵ will
be omitted in order to ease notation.
An active learning process requires interaction between the user and the model: the ﬁrst
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.21391935
provides the labeled information and the knowledge about the desired classes, while the latter
provides both its own interpretation of the distribution of the classes and the most relevant
pixels that are needed in order to solve the discrepancies encountered. This point is crucial for
the success of an active learning algorithm: the machine needs a strategy to rank the pixels in the
pool U. These strategies, or heuristics, differentiate the algorithms proposed in the next sections
and can be divided into three main families :
1 - Committee-based heuristics (Section III)
2 - Large margin-based heuristics (Section IV)
3 - Posterior probability-based heuristics (Section V)
A last family of active learning heuristics, the cluster-based, has recently being proposed
in the community : cluster-based heuristics aim at pruning a hierarchical clustering tree
until the resulting clusters are consistent with the labels provided by the user. Therefore, these
strategies rely on an unsupervised model, rather than on a predictive model. Since the aim of
these heuristics is different form that of the other families presented, they will not be detailed
in this survey.
III. COMMITTEE BASED ACTIVE LEARNING
The ﬁrst family of active learning methods quantiﬁes the uncertainty of a pixel by considering
a committee of learners , . Each member of the committee exploits different hypotheses
about the classiﬁcation problem and consequently labels the pixels in the pool of candidates.
The algorithm then selects the samples showing maximal disagreement between the different
classiﬁcation models in the committee. To limit computational complexity, heuristics based on
multiple classiﬁer systems have been proposed in machine learning literature. In , methods
based on boosting and bagging are proposed in this sense for binary classiﬁcation only. In ,
results obtained by query-by-boosting and query-by-bagging are compared using several batch
datasets showing excellent performance of the heuristics proposed. Methods of this family
have the advantage to be applicable to any kind of model or combination of models. In the
remote sensing community, committee-based approaches to active learning have been proposed
exploiting two types of uncertainty: ﬁrst, committees varying the pixels members have been
considered in the query-by-bagging heuristic , . Then, committees based on subsets of
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.21391936
the feature space available have been presented in Di and Crawford . The next two sections
present the algorithms proposed in these papers.
A. Normalized entropy query-by-bagging (nEQB)
In the implementations of , bagging is proposed to build the committee: ﬁrst, k training
sets built on a draw with replacement of the original data are deﬁned. These draws account for a
part of the available labeled pixels only. Then, each set is used to train a classiﬁer and to predict
the u labels of the candidates. At the end of the procedure, k labelings are provided for each
candidate pixel xi ∈U. In , the entropy HBAG of the distribution of the predictions is used
as heuristic. In , this measure has been subsequently normalized in order to bound it with
respect to the number of classes predicted by the committee and avoid hot spots of the value of
uncertainty in regions where several classes overlap. The normalized entropy query-by-bagging
heuristic can be stated as follows:
ˆxnEQB = arg max
HBAG(xi) = −
i = ω|xi)log
i = ω|xi) =
HBAG(xi) is an empirical measure of entropy, y∗
i is the prediction for the pixel xi and
i = ω|xi) is the observed probability to have the class ω predicted using the training
set X by the committee of k models for the sample xi. Ni is the number of classes predicted
for pixel xi , with 1 ≤Ni ≤N. The δ(y∗
i,m, ω) operator returns the value 1 if the classiﬁer using
the m-th bag classiﬁes the sample xi into class ω and 0 otherwise. Entropy maximization gives
a naturally multiclass heuristic. A candidate for which all the classiﬁers in the committee agree
is associated with null entropy and its inclusion in the training set does not bring additional
information. On the contrary, a candidate with maximum disagreement between the classiﬁers
results in maximum entropy, and its inclusion will be highly beneﬁcial.
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.21391937
B. Adaptive maximum disagreement (AMD)
When confronted to high dimensional data, it may be relevant to construct the committee by
splitting the feature space into a number of subsets, or views . Di and Crawford exploit
this principle to generate different views of a hyperspectral image on the basis of the blockdiagonal structure of the covariance matrix. By generating views corresponding to the different
blocks, independent classiﬁcations of the same pixel can be generated and an entropy-based
heuristic can be used similarly to nEQB.
Given a partition of the d-dimensional input space into V disjoint views accounting for data
subsets xv such that SV
v=1 xv = x, the ‘Adaptive maximum disagreement ’ (AMD) heuristic
selects candidates according to the following rule:
ˆxAMD = arg max
xi∈U HMV(xi)
where the multiview entropy HMV is assessed over the predictions of classiﬁers using a speciﬁc
HMV(xi) = −
i,v = ω|xv
i,v = ω|xv
v=1 W ϵ−1(v, ω)δ(y∗
j=1 W ϵ−1(v, ω)
where the δ(y∗
i,v, ω) operator returns the value 1 if the classiﬁer using the view v classiﬁes the
sample yi into class ω and 0 otherwise. Wϵ−1 is a N × V weighting matrix incorporating the
abilities of discrimination between the views in the different classes. At each iteration, Wϵ−1 is
updated on the basis of the true labels of the pixels sampled at iteration ϵ −1:
W ϵ(v, ω) = W ϵ−1(v, ω) + δ(yi,v, ω),
and its columns are normalized to a unitary sum. This matrix weights the conﬁdence of each
view to predict a given class. In , the selection is done on a subset of U containing the
candidate pixels maximizing the uncertainty, which are the pixels for which the committee has
predicted the highest number of classes. This way, the computational load of the algorithm is
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.21391938
IV. LARGE MARGIN BASED ACTIVE LEARNING
The second family of methods is speciﬁc to margin-based classiﬁers. Methods such as SVM
are naturally good base methods for active learning: the distance to the separating hyperplane,
that is the absolute value of the decision function without the sign operator, is a straightforward
way of estimating the classiﬁer conﬁdence on an unseen sample. Let’s ﬁrst consider a binary
problem: the distance of a sample xi from the SVM hyperplane is given by
αjyjK(xj, xi) + b
where K(xj, xi) is a kernel, which deﬁnes the similarity between the candidate xi and the
support vectors xj, which are the pixels showing non zero αj coefﬁcients. The labels yj of the
support vectors are +1 for samples of the positive class and −1 for those on the negative. For
additional information, see SVM literature in , .
This evaluation of the distance is the base ingredient of almost all large margin heuristics.
Roughly speaking, these heuristics use the intuition that a sample away from the decision
boundary (with a high f(xi)) has a high conﬁdence about its class assignment and is thus
not interesting for future sampling.
Since SVM rely on a sparse representation of the data, large margin based heuristics aim at
ﬁnding the pixels in U that are most likely to receive a non-zero αi weight if added to X. In other
words, the points more likely to become support vectors are the ones lying within the margin of
the current model . The heuristic taking advantage of this property is called margin sampling
(MS) , . Recent modiﬁcations of MS, aiming at minimizing the risk of selecting points
that will not become support vectors, can be found in , . MS is the most studied active
learning algorithm in remote sensing. Its ﬁrst application can be found in . Modiﬁcations
of the MS heuristic have been proposed in . Later on, since no cross-information among
the samples is considered in the MS, the questions of diversity in batches of samples have
been considered in , , . The next sections present the MS heuristic and subsequent
modiﬁcations proposed in order to enhance diversity when selecting batches of samples.
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.21391939
(b) MS, Eq. (7)
(c) MCLU, Eq. (9)
(d) |f(x, ω0)|
(e) |f(x, ω1)|
(f) |f(x, ω2)|
Large margin heuristics for a three classes toy example represented in subﬁgure (a). The color intensity represents the
distance from the hyperplane, ranging from black (on the boundary) to white (maximal distance): (b) MS heuristic; (c) MCLU
heuristic; areas in black are the areas of maximal uncertainty, minimizing Eq. (7) or Eq. (9) respectively. Bottom row: absolute
values of per-class distances (d)-(f).
A. Margin sampling (MS)
As stated above, margin sampling takes advantage of SVM geometrical properties, and in
particular of the fact that unbounded support vectors are labeled examples that lie on the margin
with a decision function value of exactly one , . Consider the pool of candidates of Fig. 1(a)
referring to a three classes toy problem. In a multiclass one-against-all setting, the distance to
each hyperplane is represented by Figs. 1(d-f). The ‘margin sampling’ (MS) heuristic performs
sampling of the candidates by minimizing Eq. (7):
ˆxMS = arg min
ω |f(xi, ω)|
where f(xi, ω) is the distance of the sample to the hyperplane deﬁned for class ω in a oneagainst-all setting for multiclass problems. The MS heuristic for the toy problem is reported
in Fig. 1(b). MS heuristic can be found in the literature under the names of ‘most ambiguous’ , ‘binary level uncertainty’ or SVMSIMPLE .
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.213919310
B. Multiclass level uncertainty (MCLU)
In , the idea of margin sampling is extended to multiclass uncertainty (see ). Instead
of dealing with the most uncertain class of the SVM, the ‘multiclass level uncertainty’ (MCLU)
considers the difference between the distance to the margin for the two most probable classes.
ˆxMCLU = arg min
f(xi)MC = max
ω∈N |f(xi, ω)| −max
ω∈N\ω+ |f(xi, ω)|
where ω+ is the class showing maximal conﬁdence, i.e. the argument of the ﬁrst term of Eq. (9)
showing maximal f(xi)MC. A high value of this criterion corresponds to samples assigned with
high certainty to the most conﬁdent class, while a small value represents unreliable classiﬁcation.
Fig. 1(c) illustrates the heuristic in comparison to MS. Although they are very similar, MCLU
performs better in the area where the three classes mix, in the top-right area of the feature
space: in this area, MCLU returns maximal uncertainty as it is evaluated on the basis of all the
per-class decision values, while MS returns an uncertainty slightly lower than on the two-classes
boundaries.
C. Signiﬁcance space construction (SSC)
In , instead of using the distance to the hyperplane as a measure of uncertainty, the support
vector coefﬁcients are used to convert the multiclass classiﬁcation problem into a binary support
vector detection problem. In the ‘signiﬁcance space construction’ (SSC) heuristic, the training
samples related to support vector coefﬁcients are used to deﬁne a second classiﬁcation function
f(x)SSC, where training pixels with αj > 0 (the support vectors) are classiﬁed against training
pixels with αj = 0. Once applied to the pool of candidates, this second classiﬁer predicts which
pixels are likely to become support vectors.
ˆxSSC = argxi∈U f(xi)SSC > 0
Once the candidates more likely to become support vectors have been highlighted, a random
selection among them is done.
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.213919311
D. On the need for a diversity criterion
In applicative scenarios, diversity among samples is highly desirable. Diversity concerns
the capability of the model to reject candidates that rank well according to the heuristic, but are
redundant among each other. Diversity has been studied extensively for margin-based heuristics,
where the base margin sampling heuristic is constrained using a measure of diversity between
the candidates (see Algorithm 2).
The ﬁrst heuristic proposing explicit diversity in remote sensing is found in , where
the margin sampling heuristic is constrained with a measure of the angle between candidates
in feature space. This heuristic, called ‘most ambiguous and orthogonal’ (MAO) is iterative:
starting from the samples selected by MS, U MS ⊂U, this heuristic iteratively chooses the samples
minimizing the highest values between the candidates list and the samples already included in
Algorithm 2 General diversity based heuristic (for a single iteration)
- Current training set Xϵ = {xi, yi}l
i=1 (X ∈X).
- Subset of the pool of candidates minimizing Eq. (7) or (8) U ∗= {xi} (U ∗∈X and U ∗⊂U ϵ).
- Number of pixels q to add at each iteration (deﬁning the batch of selected pixels S).
1: Add the pixel minimizing Eq. (7) or (9) to S.
Compute the user deﬁned diversity criterion between pixels in U ∗and in S (with MAO,
cSV or ABD).
Select the pixel xD maximizing diversity with current batch.
Add xD to current batch S = S ∪xD.
Remove xD to current list of cadidates U ∗= U ∗\ xD.
7: until batch S contains q elements.
8: The user labels the selected pixels. S = {xk, yk}q
9: Add the batch to the training set Xϵ+1 = Xϵ ∪S.
10: Remove the batch from the complete pool of candidates U ϵ+1 = U ϵ\S
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.213919312
the batch S. For a single iteration, this can be resumed as:
ˆxMAO = arg min
xj∈S K(xi, xj)
In , the MAO criterion is combined with the MCLU uncertainty estimation in the ‘multiclass level uncertainty - angle-based diversity’ (MCLU-ABD) heuristic. Te selection is performed
among a subset of U maximizing the MCLU criterion. Moreover, the author generalize the MAO
heuristic to any type of kernels by including normalization in feature space.
ˆxMCLU-ABD = arg
(1 −λ) max
K(xi, xi)K(xj, xj)
where f(xi)MC is the multiclass uncertainty function deﬁned by Eq. (9).
In , the diversity of the chosen candidates is enforced by constraining the MS solution to
pixels associated to different closest support vectors. This approach ensures a certain degree of
diversiﬁcation in the MS heuristic, by dividing the margin in the feature space as a function of the
geometrical distribution of the support vectors. Compared to the previously presented heuristics,
this approach has the advantage of ensuring diversity with respect to the current model, but
does not guarantee diversity of the samples between each other (since two close samples can be
associated to different support vectors).
ˆxcSV = arg min
|f(xi, ω)|
cSVi ̸∈cSVθ
where θ = [1, . . . , q −1] are the indices of the already selected candidates and cSV is the set
of selected closest support vectors.
Finally, diversity can be ensured using clustering in the feature space. In , kernel kmeans – was used to cluster the samples selected by MCLU and select diverse batches.
After partitioning the U MCLU set into q clusters with kernel k-means, the ‘multiclass level
uncertainty - enhanced cluster based diversity (MCLU-ECBD)’ selects a single pixel per cluster,
minimizing the following query function:
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.213919313
ˆxMCLU-ECBD = arg min
m = [1, ...q], xi ∈U MCLU
where cm is one among the q clusters deﬁned with kernel k-means.
In , a hierarchical extension of this principle is proposed to exclude from the selected batch
the pixels more likely to become bounded support vectors. This way, the redundancy affecting
samples close to each other in the feature space among different iterations is controlled along
with the maximization of the informativeness of each pixel. In the ‘informative hierarchical
margin cluster sampling’ (hMCS-i), a dataset composed by i) a subset of the pool of candidates
optimizing the MCLU criterion (U MCLU) and ii) the bounded support vectors sampled at the
previous iteration, is iteratively partitioned in a binary way. The partitioning always considers
the biggest current cluster found and continues until q clusters not containing a bounded support
vector are found. Once the q clusters have been deﬁned, a search among the candidates falling
in these q clusters is performed.
ˆxhMCS-i = arg min
m = [1, ..., q|nbSV
= 0], xi ∈U MCLU
V. POSTERIOR PROBABILITY BASED ACTIVE LEARNING
The third class of methods uses the estimation of posterior probabilities of class membership
(i.e. p(y|x)) to rank the candidates. The posterior probability gives an idea of the conﬁdence of
the class assignment (which is usually done by maximizing it over all the possible classes): by
considering the change on the overall posterior distribution or the per-class distribution for each
candidate, these heuristics use these probability estimates to focus sampling in uncertain areas.
This section details two heuristics, the KL-max and the Breaking ties.
The ﬁrst idea is to sample the pixels whose inclusion in the training set would maximize
the changes in the posterior distribution. An application of these methods can be found in
 , where the heuristic maximizes the Kullback-Leibler divergence between the distributions
before and after adding the candidate. In remote sensing, a probabilistic method based on this
strategy and using a Maximum Likelihood classiﬁer can be found in . In this setting, each
candidate is removed from U and it is included in the training set with the label maximizing
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.213919314
its posterior probability. The Kullbach-Leibler divergence KL is then computed between the
posterior distributions of the models with and without the candidate. After computing this
measure for all candidates, the pixel maximizing the following is chosen:
ˆxKL-max =
j = ω|xj) log p+(y∗
and p+(ω|x) is the posterior distribution for class ω and pixel x, estimated using the increased
training set X+ = [X, (xi, y∗
i )], where y∗
i is the class maximizing the posterior probability.
Recently, the authors of extended this approach, proposing to use boosting to weight pixels
that were previously selected, but were no longer relevant to the current classiﬁer. These heuristics
are useful when used with classiﬁers with small computational cost: since each iteration implies
to train u+1 models, this type of heuristics is hardly applicable with computationally demanding
methods as SVM. Moreover, a selection of batches of pixels is not possible.
B. Breaking ties (BT)
Another strategy, closer to the idea of EQB presented in Section III-A, consists of building
a heuristic exploiting the conditional probability of predicting a given label p(y∗
for each candidate xi ∈U. In this case, note that the predictions for the single candidates
i = arg maxω∈N f(xi, ω) are used. Such estimates are provided by several methods, including
probabilistic neural networks or maximum likelihood classiﬁers. A possibility to obtain posterior
probabilities from SVM outputs1 is to use Platt’s estimation . In this case, the per-class
posterior probability is assessed ﬁtting a sigmoid function to the SVM decision function :
i = ω|xi) =
1 + e(Af(xi,ω)+B)
where A and B are parameters to be estimated (for details, see ). Once the posterior
probabilities are obtained, it is possible to assess the uncertainty of the class membership for
1Even though they are not posterior probabilities from a Bayesian point of view
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.213919315
each candidate in a direct way. In this case the heuristic choses candidates showing a near
uniform probability of belonging to each class, i.e. p(y∗
i = ω|xi) = 1/N, ∀ω ∈N.
The ‘Breaking ties’ (BT) heuristic for a binary problem relies on the smallest difference of
the posterior probabilities for each sample . In a multi-class setting, this reciprocity can
still be conﬁrmed and used, since independently from the number of classes N, the difference
between the two highest probabilities can be indicative of the way an example is handled by the
classiﬁer. When the two highest probabilities are close (“on a tie”), the classiﬁer’s conﬁdence
is the lowest. The BT heuristic can thus be formulated as:
ˆxBT = arg min
where ω+ is the class showing maximal probability, i.e. the argument of the ﬁrst term of Eq. (20).
By comparing Eq. (8) with Eq. (20), it is clear that the link between BT and the MCLU heuristic
when using SVM classiﬁers (see Section IV-B) is really strong.
VI. DATASETS AND SETUP
This Section details the datasets considered and the setup of the experiments performed.
A. Datasets
Active heuristics have been tested on three challenging remote sensing classiﬁcation scenarios
(Fig. 2), whose data distributions are detailed in Fig. 3.
1) Hyperspectral VHR: the two top rows of Fig. 2 show a hyperspectral 1.3m spatial resolution
image of the city of Pavia (Italy) taken by the airborne ROSIS-03 optical sensor . The image
consists of 102 spectral bands of size (1400× 512) pixels with a spectral coverage ranging from
0.43 to 0.86 µm. 5 classes of interest (Buildings, Roads, Water, Vegetation and Shadows) have
been selected and a labeled dataset of 206‘009 pixels has been extracted by visual inspection.
Among the available pixels, 20‘000 have been used for the training set X and candidate set
U. Ten independent experiments have been performed, starting with 5 × 5 = 25 labeled pixels
(5 per class) in X and the remaining pixels in U. When using LDA, 150 pixels (30 per class)
have been included in the starting set. The higher number of starting training pixels used for
LDA is justiﬁed by the requirements of the model : 10.1109/JSTSP.2011.213919316
of the data). In each experiment, 80‘000 randomly selected pixels have been used to test the
generalization capabilities of the heuristics.
ROSIS Pavia
AVIRIS Indian Pines
QuickBird Zurich
Images considered in the experiments: (top) ROSIS image of the city of Pavia, Italy (bands [56 −31 −6] and
corresponding ground survey); (middle) AVIRIS Indian Pines hyperspectral data (bands [40 −30 −20] and corresponding
ground survey); (bottom) QuickBird multispectral image of a suburb of the city of Zurich, Switzerland (bands [3 −2 −1] and
corresponding ground survey).
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.213919317
Vegetation
Band 77 (NIR)
Band 55 (R)
Corn−notill
Grass / pasture
Grass / trees
Hay−windrowed
Soybeans−notill
Soybeans−min
Soybeans−clean
Bldg−grass−tree−drives
Opening 3 x 3
Opening 5 x 5
Closing 5 x 5
Closing 5 x 5
Residential
Commercial
Vegetation
Soi / harvested fields
band 2 (G)
band 3 (R)
band 4 (NIR)
Data distribution of the three images considered. First row: ROSIS image of Pavia: (a) mean spectral proﬁles; (b)
example of data manifold in bands 55 (Red) and 77 (Near infrared). Middle row: AVIRIS Indian Pines: (c) mean spectral
proﬁles; (d) example of data manifold in bands 52, 102 and 208. Bottom row: Zurich QuickBird: (e) mean spectral proﬁles; (f)
data manifold in bands 2 (G), 3 (R) and 4 (NIR).
The data distribution of the ﬁve classes is illustrated in the ﬁrst row of Fig. 3: from the
mean spectra (Fig. 3(a)) the classes are well distinguished and separable with the sole spectral
information and the resulting data manifold (Fig. 3(b)) shows a data distribution which can be
handled by most linear and non linear models.
2) Hyperspectral MR: the second dataset, illustrated in the second row of Fig. 2, is a 220bands AVIRIS image taken over Indiana’s Indian Pine test site in June 1992 . The image is
145 × 145 pixels, contains 16 classes representing different crops, and a total of 10‘366 labeled
pixels. This image is a classical benchmark to validate model accuracy and constitutes a very
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.213919318
challenging classiﬁcation problem because of the strong mixture of the class signatures. Twenty
water absorption channels were removed prior to analysis . In the experiments, classes with
less than 100 labeled pixels were removed, resulting thus in a 12 classes classiﬁcation problem
with 10‘171 labeled pixels (see the ground truth pixels in Fig. 2). Among the available labeled
pixels, 7‘000 were used for the X and U sets. Each experiment starts with 5 × 12 = 60 pixels
(5 per class). As for the previous image, the remaining 3‘171 pixels have been used to test the
generalization capabilities.
Visualization of the spectral mean proﬁles and of the data manifold (second row of Fig. 3)
illustrates a completely different situation with respect to the previous image: high nonlinearity
and strongly overlapping classes characterize this dataset. Therefore, linear classiﬁers do not
perform well on this dataset and will not be considered in the experiments.
3) Multispectral VHR: The third image, illustrated in the last row of Fig. 2, is a 4-bands
QuickBird scene of a suburb of the city of Zurich (Switzerland) taken in 2002. The image is
329×347 pixels with a spatial resolution of 2.4m. Nine classes of interest have been extracted by
careful visual inspection, namely Residential buildings, Commercial buildings, Trees, Vegetation,
Harvested ﬁelds, Bare soil, Roads, Parking lots and Water. Since some of the classes to be
separated are of landuse and have very similar responses in the spectral domain (see, for
instance, the residential and commercial buildings, or roads and parking lots), 16 contextual
bands, extracted using opening (8) and closing (8) morphological operators (see ), have been
added to the four spectral bands, resulting in a 20-dimensional dataset. As for the Pavia dataset,
20‘000 pixels have been extracted for the X and U sets. Each experiment starts with 5×9 = 45
pixels (5 per class). The complexity of this third dataset is conﬁrmed by both the spectra and
the manifold illustrated in the bottom row of Fig. 3. Strong overlaps between the asphalt and the
soil classes are observed, which is also conﬁrmed by the similarity between the spectral proﬁles.
However, the spatial features added improve the differentiation of the classes (see, for instance,
the opening features for the vegetation classes and the closing features for the asphalt classes).
B. Experimental setup
In the experiments, SVM classiﬁers with RBF kernel and LDA classiﬁers have been considered
for the experiments. When using SVM, free parameters have been optimized by 5-fold cross
validation optimizing an accuracy criterion. The active learning algorithms have been run in two
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.213919319
settings, adding N +5 and N +20 pixels per iteration. To reach convergence, 70 (40 in the case
N +20) iterations have been executed for the ﬁrst image, 100 (50) for the second and 80 (50) for
the third. nEQB has been run with committees of 7 models using 75% of the available training
data. For the experiments using LDA, 40 (20) iterations have been performed and nEQB using
12 models and 85% of the data have been used.
An upper bound on the classiﬁcation accuracy has been computed by considering a model
trained on the whole X ∪U set (‘Standard SVM/LDA’ hereafter). The lower bound on performance has been considered by assessing a model using an increasing training set, randomly
adding the same number of pixels at each epoch (‘Random Sampling’ hereafter).
Each heuristic has been run ten times with different initial training sets. All the graphics report
mean and standard deviation of the ten experiments.
VII. NUMERICAL RESULTS
In this section, some of the heuristics presented are compared on the three datasets presented
above. The experiments do not aim at deﬁning which heuristic is best, since they respond
unequally well to different data architectures. Rather, it attempts to illustrate the strengths and
weaknesses of the different families of methods and to help the user in selecting the methodology
that will perform best depending on the characteristics of the problem at hand. The heuristics
studied are the following: nEQB, MS, MCLU, MCLU-ABD and BT. Their comparison with
Random sampling (RS), the base learner (Standard SVM/LDA) and between each other will
show the main differences among the active learning architectures presented.
Figure 4 compares a heuristic for each family presented, when using SVM classiﬁers. In
general, MS performs better than the two other families. This is expected, since MS ranks the
candidates directly using the SVM decision function without further estimations: the slightly
inferior performances of the nEQB and the BT algorithms are mainly due to the small size of
the initial training set, which does not allow these criteria to perform optimally. nEQB uses too
small bags of training pixels and BT cannot estimate the posterior probabilities correctly, because
the ﬁt of Platt’s probabilities is dependent on the number of samples used. As a consequence,
the performances of these two heuristics in the ﬁrst iterations is similar to random sampling,
a behavior already observed in . Summarizing, when using SVMs, the most logical choice
among the families seems to be a large margin heuristic.
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.213919320
Pavia ROSIS
Number of pixels in training set
Overall accuracy
RS, interval of confidence
nEQB, interval of confidence
MS, interval of confidence
BT, interval of confidence
Standard SVM
Number of pixels in training set
Overall accuracy
RS, interval of confidence
nEQB, interval of confidence
MS, interval of confidence
BT, interval of confidence
Standard SVM
Indian Pines AVIRIS
60 230 400 570 740 910 1080 1250 1420 1590 1760
Number of labeled pixels
Overall accuracy
RS, interval of confidence
nEQB, interval of confidence
MS, interval of confidence
BT, interval of confidence
Standard SVM
Number of labeled pixels
Overall accuracy
RS, interval of confidence
nEQB, interval of confidence
MS, interval of confidence
BT, interval of confidence
Standard SVM
Zurich QuickBird
Number of pixels in training set
Overall accuracy
RS, interval of confidence
nEQB, interval of confidence
MS, interval of confidence
BT, interval of confidence
Standard SVM
Number of pixels in training set
Overall accuracy
RS, interval of confidence
nEQB, interval of confidence
MS, interval of confidence
BT, interval of confidence
Standard SVM
The three families of heuristics trained with SVMs (RS = Random Sampling).
Regarding this family, Figs. 5 and 6 illustrate two concepts regarding the two stages of large
margin heuristics: the uncertainty and diversity criteria. Figures 5 compares the MS and MCLU
criteria and shows that both describe the uncertainty of the candidates in a similar way. Therefore,
both can be used for efﬁcient active learning. The use of a diversity criterion seems to slightly
improve the quality of the results (Fig. 6): except for the AVIRIS image – well known for the high
degree of mixture of its spectral signatures – a spectral diversity criterion such as MCLU-ABD
efﬁciently increases performances with little added computational cost. None of the solutions
obtained with the inclusion of the diversity criterion degrade the ones relying on the uncertainty
assumption only.
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.213919321
As stated above, other heuristics must be used for other classiﬁers. Figure 7 compares the
nEQB and BT heuristics applied to the Pavia image using LDA.
In this case, both heuristics perform similarly and show a very interesting behavior: active
sampling helps the LDA to estimate the subspace that better separates data. In fact, when
sampling randomly, noise and outliers can make the estimation of the Fisher’s ratio biased,
resulting in a suboptimal linear combination of variables in the decision function. Sampling and
assigning correct labels to the pixels returned by these heuristics help estimating the correct
per-class extent (covariance) and position (mean). From 330 pixels up, the standard LDA result
is improved by the active learning training sets, providing more harmonious solutions that allow
Pavia ROSIS
Number of pixels in training set
Overall accuracy
RS, interval of confidence
MS, interval of confidence
MCLU, interval of confidence
Standard SVM
Number of pixels in training set
Overall accuracy
RS, interval of confidence
MS, interval of confidence
MCLU, interval of confidence
Standard SVM
Indian Pines AVIRIS
60 230 400 570 740 910 1080 1250 1420 1590 1760
Number of labeled pixels
Overall accuracy
RS, interval of confidence
MS, interval of confidence
MCLU, interval of confidence
Standard SVM
Number of labeled pixels
Overall accuracy
RS, interval of confidence
MS, interval of confidence
MCLU−ABE, interval of confidence
Standard SVM
Zurich QuickBird
Number of labeled pixels
Overall accuracy
RS, interval of confidence
MS, interval of confidence
MCLU, interval of confidence
Standard SVM
Number of labeled pixels
Overall accuracy
RS, interval of confidence
MS, interval of confidence
MCLU, interval of confidence
Standard SVM
Large margin active learning without diversity criterion. An example comparing MS and MCLU (RS = Random
Sampling).
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.213919322
Pavia ROSIS
Number of pixels in training set
Overall accuracy
RS, interval of confidence
MCLU, interval of confidence
MCLU−ABD, interval of confidence
Standard SVM
Number of pixels in training set
Overall accuracy
RS, interval of confidence
MCLU, interval of confidence
MCLU−ABD, interval of confidence
Standard SVM
Indian Pines AVIRIS
60 230 400 570 740 910 1080 1250 1420 1590 1760
Number of labeled pixels
Overall accuracy
RS, interval of confidence
MCLU, interval of confidence
MCLU−ABE, interval of confidence
Standard SVM
Number of labeled pixels
Overall accuracy
RS, interval of confidence
MCLU, interval of confidence
MCLU−ABE, interval of confidence
Standard SVM
Zurich QuickBird
885 1025 1165
Number of labeled pixels
Overall accuracy
RS, interval of confidence
MCLU, interval of confidence
MCLU−ABD, interval of confidence
Standard SVM
Number of labeled pixels
Overall accuracy
RS, interval of confidence
MCLU, interval of confidence
MCLU−ABD, interval of confidence
Standard SVM
Effect of diversity criteria on large margin active learning. An example comparing MCLU and MCLU-ABD (RS =
Random Sampling).
a better generalization.
Summing up, when using methods other than large margin-based algorithms, performances of
the heuristics are similar and the choice must be driven by the speciﬁc constraints of time and
number of iteration allowed. We will come back to these issues in the next section.
VIII. DISCUSSION
Throughout the experiments presented, nearly all the algorithms compared showed fast convergence to the upper bounds represented by the Standard SVM/LDA. At convergence, all
the heuristics outperformed the random selection of pixels. The interest of using multiclass
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.213919323
Number of pixels in training set
Overall accuracy
RS, interval of confidence
nEQB, interval of confidence
BT, interval of confidence
Standard LDA
Number of pixels in training set
Overall accuracy
RS, interval of confidence
nEQB, interval of confidence
BT, interval of confidence
Standard LDA
(b) N + 20
Committee-based and posterior probability heuristics trained with LDA classiﬁers on the Pavia ROSIS image (RS =
Random Sampling).
uncertainty or adding a criterion of diversity has been demonstrated by the experiments above.
Table I summarizes the points raised in this paper and gives a general overview of the methods
Large margin-based methods with diversity criterion seem the most appropriate when using
SVM, while committee-based heuristic leave freedom to the user to exploit the model he is most
conﬁdent with. Moreover, the user can build ensembles of classiﬁers exploiting the intrinsic
advantages of speciﬁc classiﬁers for a given type of image. Weighted committees or boosting
candidates are also possible (see Section III for some references). Probabilistic heuristics have
the advantage of speed, but cannot always provide batches of samples and, if the classiﬁer
does not return such estimates naturally, must rely on further approximations of the posterior
probabilities.
However, it would not be correct to base the choice of the heuristic in a model-based fashion
only. The choice of the best heuristic is problem-oriented and depends on the needs of the user
in terms of time, complexity and size of the batch to be provided at each iteration. This section
draws some guidelines to select the most appropriate heuristic.
A ﬁrst distinction could be done depending on the type of the images considered:
- when dealing with hyperspectral images, which are typically high dimensional, strategies
taking direct advantage of the data structure should be preferred: typically, multi-view
heuristics such as the AMD or the ECBD-ABD are particularly well-suited to this type
of data. The ﬁrst exploits cross-informations directly in the space of the spectral bands,
while the second selects the samples according to spectral angles among the candidates.
- when the initial training set is very small, heuristics based on posterior probabilities should
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.213919324
be avoided, since such estimation strongly depends on the quality of the estimation of the
class statistics (typically in the case of LDA). The same holds for committees-based on
bagging, especially if the bags contain a small share of the original samples.
- when dealing with complex manifolds, in which redundancy can greatly affect the quality
of the sampling and of the resulting training set, approaches based on modeling of the
relationships among samples in the feature space can be strongly beneﬁcial to select pixels
reﬂecting such complexity. The use of kernel k-means in the MCLU-ECBD, in hMCS or
the distance to support vectors in the cSV heuristic provide solutions in this sense.
A second distinction, more related to operational requirements, is based on the type of sampling
to be performed by the user ,
- when working by photointerpretation (typically in VHR imaging), sampling can be done onscreen directly by the user. This allows for large amounts of iterations and can thus be solved
by small batches of samples. In this case complex heuristics favoring spectral diversity are
to be preferred, since the complexity of the heuristics enforcing diversity strongly increases
with the size of the batch considered.
- on the contrary, when sampling is to be done on the ﬁeld (typically in hyperspectral or
mid-resolution images), only a few iterations with large batches are allowed. In this case,
all the heuristics seem to provide the same type of convergence and the user should prefer
simple heuristics such as MCLU, BT or EQB, depending on the model used. In this case,
the spatial location of samples seems to be much more important than the heuristic used: a
pioneering work in this sense can be found in , where MS and BT are exploited with
spatially adaptive cost and the sampling is optimized with respect to the spatial distance
among the samples chosen.
- when sampling is done with moving sensors and the samples are acquired sequentially by
an automatic device, batches of samples are not necessary. In this case models with small
computational cost should be preferred, as they can update fast and almost instantly provide
the next location to be sampled. In this case, BT and KL-max are most valuable.
IX. CONCLUSION
In this paper we presented and compared several state of the art approaches to active learning
for the classiﬁcation of remote sensing images. A series of heuristics have been classiﬁed by
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.213919325
SUMMARY OF ACTIVE LEARNING ALGORITHMS (B : BINARY, M : MULTICLASS, q : NUMBER OF CANDIDATES, k : MEMBERS
OF THE COMMITTEE OF LEARNERS, S : BATCH, SV s : SUPPORT VECTORS, ✓: YES, × : NO).
Reference Batches Uncer- Classiﬁer Diversity Models to train
Large margin
Single SVM
Single SVM
Single SVM + distances to support vectors
Single SVM + distances to already selected pixels
Single SVM + distances to already selected pixels
Single SVM + nonlinear clustering of candidates
Single SVM + nonlinear clustering of candidates and SVs
(q −1) models
probability
Single model
their characteristics into four families. For each family, some heuristics have been detailed and
then applied to three challenging remote sensing datasets for multispectral and hyperspectral
classiﬁcation. Advantages and drawbacks of each method have been analyzed in detail and
recommendations for further improvement have been worded. However, this review is not exhaustive and the research in the ﬁeld is far from being over: there is a healthy and rich research
community developing new heuristics for active sampling that have been or will be presented in
the remote sensing and signal processing community.
Active learning has a strong potential for remote sensing data processing. Efﬁcient training
sets are needed by the users, especially when dealing with large archives of digital images. New
problems are being tackled with active learning algorithms, guaranteeing the renewal of the ﬁeld.
April 19, 2021
IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, PREPRINT. PUBLISHED VERSION : 10.1109/JSTSP.2011.213919326
Some recent examples can be found in the active selection of unlabeled pixels for semi-supervised
classiﬁcation , spatially adaptive heuristics or the use of active learning algorithms for
model adaptation across domains , . Further steps for active learning methods are the
inclusion of contextual information in the heuristics: so far, the heuristics proposed only take
advantage of spectral criteria – or at most include contextual features in the data vector – but
few heuristics directly consider positional information and/or textures. Another crucial issue is
the robustness to noise: since they are based on the uncertainty of the pixels, current heuristics
are useless for images related to high levels of noise such as SAR. This ﬁeld remains, at present,
totally unexplored.
ACKNOWLEDGMENTS
The authors would like to acknowledge prof. Paolo Gamba (Univ. Pavia) who provided the
Pavia dataset, as well as the authors in for the Indian Pines data.