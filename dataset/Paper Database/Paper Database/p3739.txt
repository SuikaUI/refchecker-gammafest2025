Object Detection Networks on
Convolutional Feature Maps
Shaoqing Ren, Kaiming He, Ross Girshick, Xiangyu Zhang, and Jian Sun
Abstract—Most object detectors contain two important components: a feature extractor and an object classiﬁer. The feature
extractor has rapidly evolved with signiﬁcant research efforts leading to better deep convolutional architectures. The object
classiﬁer, however, has not received much attention and many recent systems (like SPPnet and Fast/Faster R-CNN) use
simple multi-layer perceptrons. This paper demonstrates that carefully designing deep networks for object classiﬁcation is just
as important. We experiment with region-wise classiﬁer networks that use shared, region-independent convolutional features.
We call them “Networks on Convolutional feature maps” (NoCs). We discover that aside from deep feature maps, a deep and
convolutional per-region classiﬁer is of particular importance for object detection, whereas latest superior image classiﬁcation
models (such as ResNets and GoogLeNets) do not directly lead to good detection accuracy without using such a per-region
classiﬁer. We show by experiments that despite the effective ResNets and Faster R-CNN systems, the design of NoCs is an
essential element for the 1st-place winning entries in ImageNet and MS COCO challenges 2015.
INTRODUCTION
Most object detectors contain two important components: a feature extractor and an object classiﬁer.
The feature extractor in traditional object detection
methods is a hand-engineered module, such as HOG
 . The classiﬁer is often a linear SVM (possibly with
a latent structure over the features) , a non-linear
boosted classiﬁer , or an additive kernel SVM .
Large performance improvements have been realized by training deep ConvNets for object detection. R-CNN , one particularly successful approach,
starts with a pre-trained ImageNet classiﬁcation
network and then ﬁne-tunes the ConvNet, end-to-end,
for detection. Although the distinction between the
feature extractor and the classiﬁer becomes blurry, a
logical division can still be imposed. For example, an
R-CNN can be thought of as a convolutional feature
extractor, ending at the last pooling layer, followed
by a multi-layer perceptron (MLP) classiﬁer. This
methodology, however, appears rather different from
traditional methods.
A research stream , , , attempting to
bridge the gap between traditional detectors and deep
ConvNets creates a hybrid of the two: the feature
extractor is “upgraded” to a pre-trained deep ConvNet, but the classiﬁer is left as a traditional model,
such as a DPM , , or a boosted classiﬁer
 . These hybrid approaches outperform their HOGbased counterparts , , but still lag far behind R-
CNN, even when the hybrid model is trained endto-end . Interestingly, the detection accuracy of
these hybrid methods is close to that of R-CNN when
• The majority of this work was done when the authors were with
Microsoft Research.
• S. Ren is with University of Science and Technology of China.
• K. He and R. Girshick are with Facebook AI Research.
• X. Zhang is with Xi’an Jiaotong University.
• J. Sun is with Megvii.
using a linear SVM on the last convolutional features,
without using the multiple fully-connected layers1.
The SPPnet approach for object detection occupies a middle ground between the hybrid models and
R-CNN. SPPnet, like the hybrid models but unlike R-
CNN, uses convolutional layers to extract full-image
features. These convolutional features are independent of region proposals and are shared by all regions,
analogous to HOG features. For classiﬁcation, SPPnet
uses a region-wise MLP, just like R-CNN but unlike
hybrid methods. SPPnet is further developed in the
latest detection systems including Fast R-CNN 
and Faster R-CNN , which outperform the hybrid
From these systems , , , a prevalent
strategy for object detection is now: use convolutional
layers to extract region-independent features, followed
by region-wise MLPs for classiﬁcation. This strategy
was, however, historically driven by pre-trained classiﬁcation architectures similar to AlexNet and
VGG nets that end with MLP classiﬁers.
In this paper, we provide an in-depth investigation
into object detection systems from the perspective of
classiﬁers aside from features. We focus on region-wise
classiﬁer architectures that are on top of the shared,
region-independent convolutional features. We call
them “Networks on Convolutional feature maps”, or
NoCs for short. Our study brings in new insights for
understanding the object detection systems.
Our key observation is that carefully designed
region-wise classiﬁers improve detection accuracy
over what is typically used (MLPs). We study three
NoC families: MLPs of various depths, ConvNets of
various depths, and ConvNets with maxout for
latent scale selection, where the latter two are unex-
1. The mAP on PASCAL VOC 2007 is 45-47% , , , 
for hybrid methods, and is 47% for R-CNN that just uses SVM on
the last convolutional layer. Numbers are based on AlexNet .
 
conv layers
conv feature map
Network on Conv feature map (NoC)
feature extrator
object classifier
Figure 1: Overview of NoC. The convolutional feature maps are generated by the shared convolutional layers.
A feature map region is extracted and RoI-pooled into a ﬁxed-resolution feature. A new network, called a
NoC, is then designed and trained on these features. In this illustration, the NoC architecture consists of two
convolutional layers and three fully-connected layers.
plored families in previous works , , . Ablation experiments suggest that: (i) a deep region-wise
classiﬁer is important for object detection accuracy,
in addition to deep shared features; (ii) convolutional
layers for extracting region-wise features are effective,
and are complementary to the effects for extracting
full-image shared features.
Based on these observations, we present an effective
way of plugging “fully convolutional” image classi-
ﬁers (such as ResNets and GoogLeNets ) into
the Faster R-CNN system that was designed for
the “semi-convolutional” VGG nets . We report
that superior image classiﬁcation backbones (e.g., ResNets
and GoogLeNets) do not directly lead to better object
detection accuracy, and a deep, convolutional NoC is
an essential element for outstanding detection performance, in addition to Faster R-CNN and extremely
deep ResNets (more details in Table 8).
In summary, through NoC we investigate the
region-wise classiﬁers from different aspects, which
are orthogonal to the investigation of features. We
believe the observations in this paper will improve the
understandings of ConvNets for object detection and
also boost the accuracy of prevalent detectors such as
Faster R-CNN .
RELATED WORK
Traditional Object Detection. Research on object detection in general focuses on both features and classiﬁers. The pioneering work of Viola and Jones 
uses simple Haar-like features and boosted classiﬁers
on sliding windows. The pedestrian detection method
in proposes HOG features used with linear SVMs.
The DPM method develops deformable graphical
models and latent SVM as a sliding-window classiﬁer.
The Selective Search paper relies on spatial pyramid features on dense SIFT vectors and an
additive kernel SVM. The Regionlet method learns
boosted classiﬁers on HOG and other features.
ConvNet-based Object Detection. Convolutional layers can be applied to images of arbitrary size yielding
proportionally-sized feature maps. In the Overfeat
method , the fully-connected layers are used on
each sliding window of the convolutional feature
maps for efﬁcient classiﬁcation, localization, and detection. In the SPP-based object detection method
 , features are pooled from proposal regions on
convolutional feature maps, and fed into the original
fully-connected layers for classifying.
Concurrent with this work, several papers , ,
 , improve on the SPPnet method, inheriting
the same logical division of shared convolutional features and region-wise MLP classiﬁers. In Fast R-CNN
 , the shared convolutional layers are ﬁne-tuned
end-to-end through Region-of-Interest pooling layers.
In Faster R-CNN , the shared features are also
used for proposing regions and reducing the heavy
proposal burdens. The “R-CNN minus R” method
 waives the requirement of region proposal by
using pre-deﬁned regions in the SPPnet system. In
the Multi-Region method , the features are pooled
from regions of multiple sizes to train an ensemble of
Despite the improvements, these systems , ,
 , , all use MLPs as region-wise classiﬁers.
This logical division naturally applies to a series of
networks, such as AlexNet , Zeiler and Fergus’s
(ZF) net , OverFeat , and VGG nets ,
which all have multiple ﬁne-tunable fc layers. But this
is not the case for fully convolutional classiﬁcation
networks, e.g., ResNet and GoogleNet , that
have no hidden fully-connected (fc) layers. We show that
it is nontrivial for Fast/Faster R-CNN to achieve good
accuracy using this type of networks.
ABLATION EXPERIMENTS
Firstly we present carefully designed ablation experiments on the PASCAL VOC dataset . We note that
experiments in this section are mainly designed based
on the SPPnet system. Particularly, in this section we
consider the following settings: (i) the shared feature
maps are frozen (which are ﬁne-tunable with Fast
R-CNN ) so we can focus on the classiﬁers; (ii)
the proposals are pre-computed from Selective Search
 (which can be replaced by a Region Proposal
Network (RPN) ), and (iii) the training step ends
with a post-hoc SVM (in contrast to the end-to-end
softmax classiﬁer in Fast R-CNN ). We remark that
observations in this section are in general valid when
these restricted conditions are relaxed or removed
 , , as shown in the next section with Faster
R-CNN .
Experimental Settings
We experiment on the PASCAL VOC 2007 set .
This dataset covers 20 object categories, and performance is measured by mAP on the test set of 5k
images. We investigate two sets of training images:
(i) the original trainval set of 5k images in VOC 2007,
and (ii) an augmented set of 16k images that consists
of VOC 2007 trainval images and VOC 2012 trainval
images, following .
As a common practice , , we adopt deep
CNNs pre-trained on the 1000-class ImageNet dataset
 as feature extractors. In this section we investigate
Zeiler and Fergus’s (ZF) model and VGG models
 . The ZF model has ﬁve convolutional (conv)
layers and three fully-connected (fc) layers. We use a
ZF model released by 2. The VGG-16/19 models
have 13/16 conv layers and three fc layers, released
Outline of Method
We apply the conv layers of a pre-trained model
to compute the convolutional feature map of the
entire image. As in , we extract feature maps from
multiple image scales. In this section these pre-trained
conv layers are frozen and not further tuned as in ,
so we can focus on the effects of NoCs.
We extract ∼2,000 region proposals by Selective
Search . We pool region-wise features from the
shared conv feature maps using Region-of-Interest
(RoI) pooling , . RoI pooling produces a ﬁxedresolution (m×m) feature map for each region, in place
of the last pooling layer in the pre-trained model (6×6
for ZF net and 7 × 7 for VGG-16/19). The pooled
feature map regions can be thought of as tiny multichannel images (see Fig. 1).
We consider these m × m-sized feature maps as
a new data source and design various NoC architectures to classify these data. The NoC structures
have multiple layers, and the last layer is an (n+1)way classiﬁer for n object categories plus background,
implemented by an (n+1)-d fc layer followed by
softmax. Each NoC is trained by backpropagation
and stochastic gradient descent (SGD). After network
training, we use the second-to-last fc layer in the
NoC to extract features from regions, and train a
linear SVM classiﬁer for each category using these
features, for a fair comparison with , . The
implementation details follow those in .
For inference, the RoI-pooled features are fed into
2. net/
3. www.robots.ox.ac.uk/∼vgg/research/very deep/
maxout NoC
conv feature
Figure 2: A maxout NoC of “c256-mo-c256-f4096f4096-f21”. The features are RoI-pooled from two
feature maps computed at two scales. In this ﬁgure,
maxout is used after conv+1.
the NoC till the second-to-last fc layer. The SVM
classiﬁer is then used to score each region, followed
by non-maximum suppression .
Next we design and investigate various NoC architectures as classiﬁers on the RoI-pooled features.
Using MLP as NoC
A simple design of NoC is to use fc layers only, known
as a multi-layer perceptron (MLP) . We investigate
using 2 to 4 fc layers. The last fc layer is always (n+1)d with softmax, and the other fc layers are 4,096-d
(with ReLU ). For example, we denote the NoC
structure with 3 fc layers as “f4096-f4096-f21” where
21 is for the VOC categories (plus background).
Table 1 shows the results of using MLP as NoC.
Here we randomly initialize the weights by Gaussian
distributions. The accuracy of NoC with 2 to 4 fc
layers increases with the depth. Compared with the
SVM classiﬁer trained on the RoI features (“SVM on
RoI”, equivalent to a 1-fc structure), the 4-fc NoC
as a classiﬁer on the same features has 7.8% higher
mAP. Note that in this comparison the NoC classiﬁers
have no pre-training (randomly initialized). The gain
is solely because that MLPs are better classiﬁers than
single-layer SVMs. In the special case of 3 fc layers,
the NoC becomes a structure similar to the regionwise classiﬁers popularly used in SPPnet and
Fast/Faster R-CNN , .
Using ConvNet as NoC
In recent detection systems , , , , ,
conv layers in the pre-trained models are thought of
as region-independent feature extractors, and thus are
shared on the entire image without being aware of the
regions that are of interest. Although this is a computationally efﬁcient solution, it misses the opportunities
of using conv layers to learn region-aware features that
are ﬁt to the regions of interest (instead of full images).
We investigate this issue from the NoC perspective,
where the NoC classiﬁers may have their own conv
architecture
SVM on RoI
f4096-f4096-f21
f4096-f4096-f4096-f21
Table 1: Detection mAP (%) of NoC as MLP for
PASCAL VOC 07 using a ZF net. The training set is
PASCAL VOC 07 trainval. The NoCs are randomly
initialized. No bbox regression is used.
architecture
f4096-f4096-f21
1conv3fc NoC
c256-f4096-f4096-f21
2conv3fc NoC
c256-c256-f4096-f4096-f21
3conv3fc NoC c256-c256-c256-f4096-f4096-f21
Table 2: Detection mAP (%) of NoC as ConvNet
for PASCAL VOC 07 using a ZF net. The training
sets are PASCAL VOC 07 trainval and 07+12 trainval
respectively. The NoCs are randomly initialized. No
bbox regression is used.
architecture
2conv3fc NoC
c256-c256-f4096-f4096-f21
mo-c256-c256-f4096-f4096-f21
c256-mo-c256-f4096-f4096-f21
c256-c256-f4096-mo-f4096-f21
c256-c256-f4096-f4096-f21-mo
Table 3: Detection mAP (%) of maxout NoC for PAS-
CAL VOC 07 using a ZF net. The training set is 07+12
trainval. The NoCs are randomly initialized. No bbox
regression is used.
We investigate using 1 to 3 additional conv layers
(with ReLU) in a NoC. We use 256 conv ﬁlters for
the ZF net and 512 for the VGG net. The conv ﬁlters
have a spatial size of 3×3 and a padding of 1, so the
m × m spatial resolution is unchanged. After the last
additional conv layer, we apply three fc layers as in
the above MLP case. For example, we denote a NoC
with 2 conv layers as “c256-c256-f4096-f4096-f21”.
In Table 2 we compare the cases of no conv layer
(3-layer MLP) and using 1 to 3 additional conv layers.
Here we still randomly initialize all NoC layers. When
using VOC 07 trainval for training, the mAP is nearly
unchanged when using 1 additional conv layer, but
drops when using more conv layers. We observe that
the degradation is a result of overﬁtting. The VOC
07 trainval set is too small to train deeper models.
However, NoCs with conv layers show improvements
when trained on the VOC 07+12 trainval set (Table 2).
For this training set, the 3fc NoC baseline is lifted to
56.5% mAP. The advanced 2conv3fc NoC improves
over this baseline to 58.9%. This justiﬁes the effects
of the additional conv layers. Table 2 also shows that
the mAP gets saturated when using 3 additional conv
Using a ConvNet as a NoC is not only effective for
the ZF and VGG nets. In fact, as we show in the next
section (Table 8), this design is of central importance
for Faster R-CNN using ResNets and other fully
convolutional pre-trained architectures.
VOC 07 07+12
SVM on RoI
pre-trained
maxout 2conv3fc NoC
pre-trained
maxout 2conv3fc NoC VGG-16
pre-trained
Table 4: Detection mAP (%) of NoC for PASCAL VOC
07 using ZF/VGG-16 nets with different initialization.
The training sets are PASCAL VOC 07 trainval and
PASCAL VOC 07+12 trainval respectively. No bounding box regression is used.
Maxout for Scale Selection
Our convolutional feature maps are extracted from
multiple discrete scales, known as a feature pyramid
 . In the above, a region feature is pooled from a
single scale selected from the pyramid following .
Next, we incorporate a local competition operation
(maxout) into NoCs to improve scale selection
from the feature pyramid.
To improve scale invariance, for each proposal region we select two adjacent scales in the feature
pyramid. Two ﬁxed-resolution (m × m) features are
RoI-pooled, and the NoC model has two data sources.
Maxout (element-wise max) is a widely considered operation for merging two or multiple competing
sources. We investigate NoCs with maxout used after
different layers. For example, the NoC model of “c256mo-c256-f4096-f4096-f21” is illustrated in Fig. 2. When
the maxout operation is used, the two feature maps
(for the two scales) are merged into a single feature
of the same dimensionality using element-wise max.
There are two pathways before the maxout, and we
let the corresponding layers in both pathways share
their weights. Thus the total number of weights is
unchanged when using maxout.
Table 3 shows the mAP of the four variants of
maxout NoCs. Their mAP is higher than that of the
non-maxout counterpart, by up to 1.8% mAP. We note
that the gains are observed for all variants of using
maxout, while the differences among these variants
are marginal.
Fine-tuning NoC
In the above, all NoC architectures are initialized
randomly. Whenever possible, we can still transfer
weights from a pre-trained architecture and ﬁne-tune
the NoCs. The comparison of random initialization vs.
ﬁne-tuning provides new insights into the impacts of
the well established ﬁne-tuning strategy .
For the ﬁne-tuning version, we initialize the two
4096-d layers by the two corresponding fc layers in the
pre-trained model. As such, the ﬁne-tuned 3-fc NoC
becomes equivalent to the SPPnet object detection
system . For the cases of additional conv layers,
each conv layer is initialized to the identity mapping,
(classiﬁer)
(total) mAP (%)
VGG-16 maxout 2conv3fc
Table 5: Detection results for PASCAL VOC 07 using
VGG nets. The training set is PASCAL VOC 07+12
trainval. The NoC is the ﬁne-tuned version (Sec. 3.4).
No bounding box regression is used.
and thus the initial network state is equivalent to the
pre-trained 3fc structure. We compare the results of
an SVM on RoI, randomly initialized NoC, and ﬁnetuned NoC initialized in the above way. Table 4 shows
the cases of two NoCs.
Unsurprisingly, the ﬁne-tuned models boost the
results. However, it is less expected to see that the
randomly initialized NoCs produce excellent results.
Compared with the SVM counterpart using the same
RoI-pooled features (47.7%, Table 4), the randomly
initialized NoC (60.7%) showcases an improvement of
13.0%, whereas the ﬁne-tuned counterpart (62.9%) has
an extra 2.2% gain. This indicates that the ﬁne-tuning
procedure, for the classiﬁer, can obtain a majority of
accuracy via training a deep network on the detection
Deep Features vs. Deep Classiﬁers
We further show by experiments that a deep classiﬁer
has complementary effects to deep features. Table 5
shows the NoC results using the VGG models .
The mAP of the baseline 3fc NoC is 64.6% with VGG-
16. With the network replaced by the deeper VGG-19,
the depth of shared features is increased by 3, and
the mAP is increased by 0.5% to 65.1%. On the other
hand, when the depth of region-aware classiﬁer is increased (but still using the VGG-16 features), the mAP
is increased by 1.5% to 66.1%. This means that for
exploiting very deep networks, the depth of features
and the depth of classiﬁers are both important.
Error Analysis
Our best NoC using VGG-16 has 68.8% mAP (Table 5).
To separately investigate the gains that are caused
by features (stronger pre-trained nets) and classiﬁers
(stronger NoCs), in Fig. 3 we analyze the errors of
using two sets of pre-trained features (ZF vs. VGG-
16) and two NoCs (3fc vs. maxout 2conv3fc). We use
the diagnosis tool of .
The errors can be roughly decomposed into two
parts: localization error and recognition error. Localization error (“Loc”) is deﬁned as the false positives
that are correctly categorized but have no sufﬁcient
overlapping with ground truth. Recognition error involves confusions with a similar category (“Sim”),
confusions with a dissimilar category (“Oth”), and
confusions with background (“BG”).
Figure 3: Distribution of top-ranked True Positives
(TP) and False Positives (FP), generated by the published diagnosis code of . The types of positive
predictions are categorized as Cor (correct), Loc
(false due to poor localization), Sim (confusion with
a similar category), Oth (confusion with a dissimilar
category), BG (ﬁred on background). The total number
of samples in each disk is the same and equal to
the total number of ground-truth labels . More
explanations are in the main text.
Fig. 3 shows that VGG-16 in general has lower
recognition error than the ZF net, when using the same
classiﬁers (e.g., 1.6%+1.3%+7.4% vs. 3.2%+2.2%+7.4%).
This suggests that the region-independent features
perform more prominent for recognizing object categories. On the other hand, when using a stronger NoC
(maxout 2conv3fc), the localization error is substantially
reduced compared with the 3fc baseline (22.6% vs.
28.1% with ZF, and 20.1% vs. 24.8% with VGG-16).
This suggests that the NoCs mainly account for localizing objects. This can be explained by the fact that
localization-sensitive information is only extracted after RoI pooling and is used by NoCs.
Comparisons of Results
In Table 6 and Table 7, we provide system comparisons with recent state-of-the-art results, including R-
CNN , SPPnet , and the latest Fast/Faster R-
CNN , that are contemporary to this work.
We note that all methods in Table 6 and Table 7 are
based on Selective Search (SS) proposals (∼2,000
regions per image), except for Faster R-CNN that
uses learned proposals.
Our method achieves 71.6% mAP on the PASCAL
VOC 2007 test set. This accuracy is higher than Fast
R-CNN that also uses SS proposals, and lower
than Faster R-CNN that uses learned proposals.
training data
R-CNN + bb
SPPnet 
SPPnet 
Fast R-CNN 
Faster R-CNN 
NoC [ours]
NoC [ours] + bb
Table 6: Detection results for the PASCAL VOC 2007
test set using the VGG-16 model . Here “bb”
denotes post-hoc bounding box regression .
training data
R-CNN + bb
Fast R-CNN 
Faster R-CNN 
NoC [ours]
NoC [ours] + bb
Table 7: Detection results for the PASCAL VOC 2012
test set using the VGG-16 model . Here “bb”
denotes post-hoc bounding box regression .
Nevertheless, Fast/Faster R-CNN , essentially applies a 3-fc NoC structure as the region-wise
classiﬁer, and thus the effect of NoCs is orthogonal to
theirs. This effect is particularly prominent using the
ResNets as we show in the next section.
Summary of Observations
The following key observations can be concluded
from the above subsections:
(i) A deeper region-wise classiﬁer is useful and is
in general orthogonal to deeper feature maps.
(ii) A convolutional region-wise classiﬁer is more
effective than an MLP-based region-wise classiﬁer.
These observations are strongly supported by the
experimental results on the more challenging MS
COCO dataset (Table 8), as we introduced in the next
NOC FOR FASTER R-CNN WITH RESNET
The Fast/Faster R-CNN systems , have shown
competitive accuracy and speed using VGG nets. For
networks similar to ZF and VGG-16, Fast/Faster R-
CNN are naturally applicable and their region-wise
classiﬁers are 3fc NoCs. However, for “fully convolutional” models such as GoogleNets and ResNets
 , there are no hidden fc layers for building regionwise classiﬁers. We demonstrate that the NoC design is an
essential factor for Faster R-CNN to achieve superior
results using ResNets.
Experimental Settings
In this section we experiment on the more challenging MS COCO dataset with 80 categories. We
train the models on the 80k train set, and evaluate
on the 40k val set. We evaluate both COCO-style AP
(@ IoU ∈[0.5, 0.95]) as well as and .
We adopt the same hyper-parameters as in for
training Faster R-CNN on MS COCO.
We compare network architectures of VGG-16 ,
GoogleNet , and ResNet-101 . The VGG-16 has
center crop top-1 error of 28.5% on the ImageNet classiﬁcation val set. Regarding GoogleNet, we train the
BN-Inception model on ImageNet classiﬁcation.
Our reproduced GoogleNet has center crop top-1 error of 26.4%, close to that reported in (25.2%). The
101-layer ResNet is released by the authors of ,
with center crop top-1 error of 23.6%. Both GoogleNet
and ResNet have no hidden fc layer, and instead end
with global average pooling and a 1000-d classiﬁer.
Unlike the above section that is based on the SPPnet
framework, in this section we use the more advanced
Faster R-CNN detector. The main differences are:
(i) the entire networks including the features are ﬁnetuned end-to-end ; (ii) the proposals are learned
by a RPN with features shared; (iii) instead
of post-hoc SVM, a softmax classiﬁer and a jointly
learned bounding box regressor are learned endto-end. Nevertheless, these differences do not affect
the design of the NoCs.
Experimental Results
Table 8 shows the results on MS COCO val. We
discuss by diving the results into 3 cases as following.
Na¨ıve Faster R-CNN. By this we mean that the RoI
pooling layer is na¨ıvely adopted after the last convolutional layer (conv53 for VGG-16, inc5b for GoogleNet,
and res5c for ResNet). In all cases, we set the output
resolution of RoI pooling as 7×7. This is followed by
a 81-d classiﬁer (equivalent to a 1fc NoC).
Table 8 shows that VGG-16 has better AP (21.2%)
than both GoogleNet (15.2%) and ResNet (16.9%),
even though VGG-16 has worse image-level classi-
ﬁcation accuracy on ImageNet. One reason is that
VGG-16 has a stride of 16 pixels on conv53, but
GoogleNet and ResNet have a stride of 32 pixels
on inc5b and res5c respectively. We hypothesize that
a ﬁner-resolution feature map (i.e., a smaller stride)
contributes positively to object detection accuracy. To
verify this, we reduce the stride of GoogleNet/ResNet
from 32 to 16 by modifying the last stride=2 operation
as stride=1. Then we adopt the “hole algorithm” ,
 (“Algorithme `a trous” ) on all following layers
to compensate this modiﬁcation. With a stride of 16
pixels, na¨ıve Faster R-CNN still performs unsatisfactorily, with an AP of 18.6% for GoogleNet and 21.3%
for ResNet.
We argue that this is because in the case of na¨ıve
Faster R-CNN, VGG-16 has a 3fc NoC but GoogleNet
and ResNet has a 1fc NoC (Table 8). As we observed
in the above section, a deeper region-wise NoC is
important, even though GoogleNet and ResNet have
deeper feature maps.
Using MLP as NoC. Using the same settings of feature
fc4096, fc4096, fc81
fc4096, fc4096, fc81
inc5b, `a trous
inc5b, `a trous
fc4096, fc4096, fc81
inc4e,5a,5b, fc81
ResNet-101
ResNet-101
fc4096, fc4096, fc81
ResNet-101
res5c, `a trous
ResNet-101
res5c, `a trous
fc4096, fc4096, fc81
ResNet-101
res5a,5b,5c, fc81
Table 8: Detection results of Faster R-CNN on the MS COCO val set. “inc” indicates an inception block, and
“res” indicates a residual block.
res5c, `a trous
res5c, `a trous
fc4096, fc4096, fcn+1
res5a,5b,5c, fcn+1
Table 9: Detection results of Faster R-CNN + ResNet-
101 on MS COCO val (trained on MS COCO train) and
PASCAL VOC 2007 test (trained on 07+12), based on
different NoC structures.
maps, we build a deeper MLP NoC by using 3 fc
layers (f4096-f4096-fc81). As GoogleNet and ResNet
have no pre-trained fc layers available, these layers
are randomly initialized which we expect to perform reasonably (Sec. 3.4). This 3fc NoC signiﬁcantly
improves AP by about 4 to 5% for ResNet (21.3%
to 26.3% with a stride of 16, and 16.9% to 21.2%
with a stride of 32). These comparisons justify the
importance of a deeper NoC.
Using ConvNet as NoC. To build a convolutional
NoC, we move the RoI pooling layer from the last
feature map to an intermediate feature map that
has a stride of 16 pixels (inc4d for GoogleNet and
res4b22 for ResNet). The following convolutional layers (inc4e,5a,5b for GoogleNet and res5a,5b,5c for
ResNet) construct the convolutional NoC. The `a trous
trick is not necessary in this case.
With the deeper convolutional NoC, the AP is further improved, e.g., from 26.3% to 27.2% for ResNet.
In particular, this NoC greatly improves localization accuracy — ResNet’s is increased by 1.7 points
(from 25.9% to 27.6%) whereas is nearly unchanged (from 48.1% to 48.4%). This observation is
consistent with that on PASCAL VOC (Fig. 3), where
a deep convolutional NoC improves localization.
Table 9 shows the comparisons on PASCAL VOC
for Faster R-CNN + ResNet-101. Both MLP and ConvNet as NoC (76.4%) perform considerably better than
the 1fc NoC baseline (71.9%), though the beneﬁt of
using ConvNet as NoC is diminishing in this case.
Discussions
The above system (27.2% AP and 48.4% )
is the foundation of the detection system in the
ResNet paper . Combining with orthogonal improvements, the results in secured the 1st place
in MS COCO and ImageNet 2015 challenges.
The ablation results in Table 8 indicate that despite
the effective Faster R-CNN and ResNet, it is not direct
to achieve excellent object detection accuracy. In particular, a na¨ıve version of Faster R-CNN using ResNet
has low accuracy (21.3% AP), because its regionwise classiﬁer is shallow and not convolutional. On
the contrary, a deep and convolutional NoC is an
essential factor for Faster R-CNN + ResNet to perform
accurate object detection.
CONCLUSION
In this work, we delve into the detection systems
and provide insights about the region-wise classiﬁers.
We discover that deep convolutional classiﬁers are
just as important as deep convolutional feature extractors. Based on the observations from the NoC
perspective, we present a way of using Faster R-CNN
with ResNets, which achieves nontrivial results on
challenging datasets including MS COCO.