HAL Id: inria-00548506
 
Submitted on 20 Dec 2010
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of scientific research documents, whether they are published or not.
The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Vehicle Categorization: Parts for Speed and Accuracy
Eric Nowak, Frédéric Jurie
To cite this version:
Eric Nowak, Frédéric Jurie. Vehicle Categorization: Parts for Speed and Accuracy. IEEE International
Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS
’05), Oct 2005, Beijing, China. pp.277–283, ￿10.1109/VSPETS.2005.1570926￿. ￿inria-00548506￿
Vehicle Categorization: Parts for Speed and Accuracy
Eric Nowak1,2
Fr´ed´eric Jurie1
1 Laboratoire GRAVIR / UMR 5527 du CNRS - INRIA Rhone-Alpes - UJF - INPG
2 Soci´et´e Bertin - Technologies, Aix-en-Provence
{eric.nowak,frederic.jurie}@inrialples.fr
In this paper we propose a framework for categorization
of different types of vehicles. The difﬁculty comes from the
high inter-class similarity and the high intra-class variability. We address this problem using a part-based recognition system. We particularly focus on the trade-off between
the number of parts included in the vehicle models and the
recognition rate, i.e the trade-off between fast computation
and high accuracy. We propose a high-level data transformation algorithm and a feature selection scheme adapted to
hierarchical SVM classiﬁers to improve the performance of
part-based vehicle models.
We have tested the proposed framework on real data acquired by infrared surveillance cameras, and on visible images too. On the infrared dataset, with the same speedup
factor of 100, our accuracy is 12% better than the standard
one-versus-one SVM.
1. Introduction
Identifying objects captured by a video-camera is a classical application for video-surveillance. Once an object is
detected on an image, a classiﬁcation algorithm analyzes
its region of interest (ROI) to predict the associated object
class. In this study we focus on this classiﬁcation. We propose a framework for fast and accurate classiﬁcation of different types of vehicles images in a natural cluttered background.
Recent state-of-the-art methods are either template or appearance based. In template based methods , recognition is based on distances (e.g. correlations) between an input image and the predeﬁned templates. Appearance-based
methods learn the variability of vehicle appearances
from a set of training examples. Images are represented by a
set of local (so-called part-based approaches) or global features. The advantage of part-based methods is their robustness to pose, illumination and shape variations, and partial
occlusions. A part based object recognition system consists
of three steps . In ﬁgure 1 we illustrate the ﬁrst step
which selects the most useful parts. The example shows discriminative object parts and their detected locations on car
Figure 1: Example of parts. Which ones best discriminate
between classes?
images. The second step combines these parts into object
representations, and the last builds a classiﬁer for the recognition system. The selection of these parts is critical. The
system has to choose those few parts that are discriminative
enough to separate between classes.
To identify an part by correlation is computationally expensive, therefore this paper proposes a new method to select these very few but useful parts. As a ﬁrst contribution,
our approach takes advantage of the tree structure of hierarchical classiﬁers by individually selecting parts for each
classiﬁer-node (see section 3.4). The second contribution
is a new high-level data representation that increases the
recognition accuracy (see section 3.2).
The organization of the paper is as follows. Section 2 describes part-based object classiﬁcation methods of the stateof-the-art. Section 3 presents our method. Experiments are
in section 4.
2. Part-based object classiﬁcation
In this section, we describe state-of-the-art part-based object classiﬁcation methods. We detail the phases of the process: visual codebook computation, part detection, image
representation and multi-class classiﬁcation.
2.1. Visual codebook computation
A part is a representative of local image descriptors that appear frequently in a given dataset. For example, on ﬁgure
1, the wheels on the second and third car image are represented by the second part. A visual codebook is the set
of parts deﬁned to describe the images of a dataset. It is
generally obtained by a quantization algorithm. First, local
image descriptors are computed at different locations and
scales, and then they are grouped by their similarity. Each
group is represented by a so-called part.
Leug and Malik use a ﬁlter bank convolution to describe regularly sampled pixels, and k-means to compute
the parts. Agarwal , Leibe use interest point detectors to determine characteristic locations which are then described by the gray-level values of a ﬁxed size neighborhood. They build their codebook by an agglomerative clustering method. For quantization, Willamowski uses kmeans and Jurie uses a mean-shift based density estimation.
2.2. Part detection
 use interest point detectors, therefore consider the
images at sparse locations. The detection process is fast, but
on the other hand it performs poorly if the object is small, or
if the informative regions are not detectable by the chosen
interest point operator. suggest to use a dense
multi-scale representation, where the patches are detected
on images by multi-scale correlation. This step is computationally expensive, therefore, real-time systems require to
reduce the size of their codebooks (see 3.3).
2.3. Image representation
Agarwal and Leibe use geometric constraints to
model the relation between parts. Agarwal takes into account pairwise relations between parts (distance, orientation). Leibe models the position of parts with respect to the
center of the object they belong to. Alternatively, Willamowski’s bag of features approach ignores the geometric
relations between parts and images are represented by the
occurrences of codebook entries. This simple representation gives surprisingly good results in .
2.4. Multi-class classiﬁcation
This section presents different state-of-the-art multi-class
classiﬁers adapted to “bag of features” image representations.
Decision trees are popular multi-class classiﬁers. Because their construction is based on joint probabilities, other
classiﬁers are a better choice when the dimension of the feature space is high and the training examples are limited.
The most popular choice of generative classiﬁer in case
of high dimensional feature space is the Naive Bayes classi-
ﬁer, because it assumes that the features are independent,
1−7−8−11−18
1−7−8−11−18
Figure 2: HBC classiﬁer principle.
The classes are iteratively separated. Feature selection. 2 features are selected
per classiﬁer (above the nodes); the features used to predict
a class are indicated above the leaves
therefore it avoids to estimate the joint probability. The
Naive Bayes classiﬁer models the probability that a feature vector V belongs to a category Ck as P(V |Ck) =
j P(Vj|Ck).
P(Vj = 0|Ck) and P(Vj = 1|Ck) are
learned during the training phase. An unseen image described by a vector V is affected to the category maximizing
In recent articles the family of discriminative classiﬁers
is dominated by SVMs. They were originally designed for
binary classiﬁcation problems and were extended to
multi-class with “one versus one” (1vs1) and “one versus
the rest” (1vsR) strategies. 1vs1 trains all pairwise combinations of objects. During prediction, the C(C −1)/2 binary classiﬁers are evaluated and the class that receives the
majority of the votes is assigned to the test sample. 1vsR
trains a binary classiﬁer for each class to separate its objects
from the rest. The classiﬁer with the highest conﬁdence determines the label for an unseen test sample. Recently, Rajan proposed a Hierarchical Binary Classiﬁer (HBC)
representing the multi-class problem by a binary tree. This
is illustrated on ﬁgure 2. The root of the tree is the set of
all classes. The nodes are iteratively partitioned in two sets
until they contain only one class. At each node, a binary
classiﬁer separates the partitioned sets. To classify an unseen example, a path from the root to a leaf is followed
in the tree, according to the predictions of the classiﬁernodes. Rajan constructs the tree with an iterative k-means
algorithm (k = 2).
3. The proposed method
In this section we present our framework for vehicle classiﬁcation. We propose a new data transformation and an
efﬁcient integration of feature selection to HBC. First, we
give an overview of the overall framework, and then detail
each component.
3.1. Our framework
Our model is built from a training set of images as follows:
1. Codebook computation.
Our image descriptors are
dense, multi-scale, gray-level pixel intensities computed at local neighborhood. We use mean-shift quantization of to obtain a codebook of size n.
2. Representation of the training set. We use a “bag of
features” approach, and each image of the training set
is represented by a vector of size n.
3. Data transformation. The vectors are transformed into
a higher-level representation (see 3.2)
4. Computation of a HBC classiﬁer. We use Rajan’s iterative k-means to compute the tree adapted to our
dataset .
5. Feature selection adapted to the tree. The most useful
parts are selected for each classiﬁer-node of the tree
For prediction, we follow a path from the root of the
HBC to a leaf as follows:
1. Start path at the root node.
2. Detect on the input image the selected parts for the the
current node. Note: parts are selected during training,
3. Classify the image on the current node to determine
which of the two child nodes is the next node of the
4. Loop over 2-3 until a leaf node is reached. The label
of the leaf node is the predicted label of the image.
Below, we present our data transformation algorithm, we
compare different feature selection strategies and explain
how to use them with HBC. We explain why HBC classi-
ﬁers perform better than other classiﬁers with small codebooks (later section 4.4 conﬁrms it experimentally).
3.2. Data transformation
“Bag of features” approaches represent an image Ii by a
vector Vi, where Vi(j) is the number of detections of the
part j on that image. This information can be transformed
to improve classiﬁcation results. Histogram estimation of
bayesian classiﬁer probabilities requires to quantize individually the values of each Vi. And because they use euclidean distances, linear SVMs also require a data transformation, as the following example shows. Let d(xi, xj)2 =
k=1..n (xk
j )2 be the distance between two support
vectors. If the magnitude of the ﬁrst dimension is higher
than the other ones, the distance becomes d(xi, xj)2 ≃
j)2 and the information from other dimensions is
Below we enumerate standard data transformation methods:
1. Original data (raw): vectors are not modiﬁed, classi-
ﬁers use occurrences.
2. Linear transformation, by feature (ranging). Each
feature dimension is linearly transformed into in
order to give the same importance to all the features.
3. Linear transformation, by image (proba). Each Vi is
independently normalized. After a L1 normalization,
Vi(j) is the probability of ﬁnding the part j on the image Ii.
4. Simple binarization (bin0). If the feature j appears
at least once in the image, Vi(j) = 1 else Vi(j) = 0.
We only consider that a feature appears, and not the
number of times it appears.
We propose a higher-level transformation (binAuto),
that automatically computes the optimal binarization
threshold for each feature. This threshold is chosen among
a list of candidates by a mutual information maximization
process. This process measures how useful each binarization threshold is to the classiﬁcation, and picks the most
informative threshold. This deﬁnition is motivated by the
following consideration. A feature appearing in all images
of all categories is not discriminative. But if it appears often in many images of a category, and rarely in many images of other categories, “a minimum number of detections”
is a discriminative information. The standard binarization
(bin0) removes this information. The original data (raw)
contains this information, but only implicitly. On the contrary, the automatically binarized data (binAuto) explicitly contains this discriminative information.
3.3. Feature selection
In this section, we present different feature selection strategies. In the next section we will explain how to integrate
them efﬁciently to HBC classiﬁers.
Given a codebook of n parts, feature selection tools 
select the n′ < n most useful ones for classiﬁcation. The
optimal sub-codebook requires a NP-compete search, i.e.
the examination of all codebook subsets of size n′. In practice this is not possible, and a sub-optimal search is used.
A wrapper method constructs the sub-codebook iteratively. The subset is initially empty. Iteratively, the part
that gives the largest increase of performance is added to
the subset. In section 4.3, we show that this method gives
the best performance. The weak point of a wrapper method
is its quadratic complexity (O(nn′)).
A more greedy approach assumes that the features are
independent. A utility measure is computed for each part,
and the optimal subset is made of the n′ top ranked features. The complexity of this algorithm is linear (O(n)).
Many utility functions were proposed in text classiﬁcation
applications , here we detail the most commonly used
1. Random selection (rand), to avoid local optimum
problems and redundancy
2. Frequency (freq), to rely more often on available information.
3. Mutual information1 (MI), to measure how useful a
part is to the classiﬁcation problem. Let C be an object category, Vj indicate if the part j is detected on an
object or not. The mutual information between C and
Vj is deﬁned as
I(Vj, C) =
p(c)Freqj,c log(Discrj,c)
Freqj,c = p(vj|c) , Discrj,c =
c p(vj|c)p(c)
MI combines frequency statistics of the part (Freq)
and its discriminativeness (Discr).
4. Odds ratio (OR) selects the most discriminative features. However, as it ignores frequency, it does not
allow a dramatic reduction of the codebook size. OR is
deﬁned as p(vi=1|c=1)
p(vi=0|c=1)
p(vi=0|c=2)
p(vi=1|c=2).
5. Linear SVM hyperplane normal coefﬁcient (omega)
focuses on discriminative parts due to the scalar product of the prediction function: svm(V ) = ωV + b,
V = [V1...Vn]. Thus, if all feature dimensions have
the same range, more important features have higher
associated hyperplane normal coefﬁcient
3.4. Feature selection for HBC
Naive Bayes, 1vsR and 1vs1 classiﬁers respectively require the evaluation of C, C and C(C −1)/2 classiﬁers.
If we run one of the previously described feature selection
tools, we obtain a set of n′ features. These features are useful for the multi-class classiﬁer, but not for each binary classiﬁer. Thus, the selected features are useless during a major
part of the multi-class classiﬁcation. As HBC are evaluated
sequentially, from the root to a leaf, they don’t have this
drawback. This is illustrated on ﬁgure 2. If the root node
classiﬁer predicts that the input image belongs to classes 1,
2 or 4, it is useless to detected the parts 4 and 6, as they are
only useful to separates classes 3 and 5. Instead, the parts 7
and 11 are be detected to discriminate between the classes
1, 2 and 4. This process is computationally efﬁcient because
7 different parts are used for classiﬁcation, but on average
1called mutual information in and information gain in 
an example is classiﬁed with (4 + 4 + 5 + 5 + 4)/5 = 4.4
For this reason, we propose the following feature selection method for HBC: use any of the methods presented in
3.3 to select m features for each classiﬁer-node.
4. Experiments
In the previous section, we have presented two methods
to improve “bag of features“ approaches: feature selection
integrated to hierarchical classiﬁcation and automatic data
binarization. In the following experiments we will show
the effects of each of these methods on an infrared videosurveillance problem. In order to prove that the method is
not limited to the infrared sub-band, we will brieﬂy show
results on a visible light dataset.
4.1. Context
In this section we describe the datasets used to evaluate the
performance of the recognition algorithms.
The ﬁrst dataset is built from infrared images. An image
contains one out of four models of vehicles (1 van, 3 cars) in
a natural cluttered background. The vehicles are seen at different scales (100 to 600 meters), orientations, illumination
conditions and occlusion levels. The dataset is made of approximate regions of interest (ROI) of the vehicles, as if the
vehicles were detected by a realistic tracker (the red rectangles in ﬁgure 5). An approximate ROI is obtained by a random transformation of the exact ROI: its size is multiplied
by m in [0.8, 2], then its position is shifted by (sw.w, sh.h)
pixels, with sw and sh in [−0.4, 0.4], w, h the width, height
of the exact ROI. The dataset contains 250 images of each
vehicle and 1500 images of background. The recognition
algorithm has to discriminate between 4+1 classes.
The second dataset contains visible light images of 8
classes: horse, face, motorbike, car, bike, book, phone (50
images each) and background (400 images).
The prediction accuracy is evaluated by ten-fold crossvalidation. The accuracy is the mean of all classes true positive rate.
4.2. Codebook computation
The codebook is computed with the algorithm mentioned in
section 3.1. The NCC threshold is set to 0.8, which corresponds to an angle of 40 degrees between the two patches.
The scale pyramid has 9 levels, and the scale ratio is 0.91.
The mean-shift algorithm iteratively produces 4000 clusters
— or parts — , the mean shift ball radius is set to 0.8. Figure
3 displays codebook patches frequently and rarely detected
in the IR dataset.
4.3. Feature selection
In this section, we study the effects of feature selection
strategies to decide which one to use in the HBC nodes. We
Figure 3: Above (below) the 80 most (less) frequent words
of the IR database
use raw data and a 1vs1 linear SVM classiﬁer to compare
the different methods. Figure 4 shows the mean recognition
accuracy of each class w.r.t. the percentage of considered
We observe that the codebook contains useless (or redundant) words, because the MI feature selection method
reaches the maximal performance with 40% of the vocabulary with the IR dataset, and 10% with the other dataset.
The wrapper method is the most efﬁcient feature selection
method, because it explicitly optimizes the performance.
Unlike the other ranking measures, the curve grows very
fast. OR and freq give worse performance than rand. In
the visible database, omega also gives worse performance
than rand. This is not the case of MI, which is always
better than rand: on the visible database, +20% with 1%
of the features, +25% with 4% of the features, on the IR
database +15% with 4% of the features.
We can conclude that the vocabulary is very redundant
and it is possible to reduce its size and keep good classiﬁcation performance in the same time. The wrapper method
is the most efﬁcient of the ones we studied; MI is the most
efﬁcient linear method. In the rest of the experiments, we
only consider MI selection because of its lower computational complexity.
4.4. HBC and feature selection
In this section, we compare the effects of different multiclass strategies on the feature selection process. We want to
measure the difference between Hierarchical Binary Classiﬁers and other classiﬁers. We compute two HBC trees:
tree1 is obtained by Rajan’s algorithm , tree2 is
randomly built. 1vs1 and 1vsR are the classical SVM
multi-class classiﬁers, and NaiveBayes is the maximum
likelihood Naive Bayes classiﬁer. The classiﬁcation results
are reported on ﬁgure 6.
We ﬁrst notice that 1vs1 and 1vsR have a better accuracy than tree and NaiveBayes when we use 100%
of the features (4000). However, because we are interested
in computational efﬁciency, the most interesting part of the
graphs is the one with small number of features.
tree1 has a better accuracy than 1vs1 and 1vsR. For example, in the IR database, tree is 10% better than 1vs1
average accuracy
percentage of selected patches
average accuracy
percentage of selected patches
average accuracy
percentage of selected patches
Figure 4: Inﬂuence of feature selection methods. Line 1 (2):
visible database (zoomed). Line 3: IR database.
The regions analyzed by the framework are
showed by the red rectangles.
Transformation
Performance
Transformation
Performance
Table 1: The effects of data transformation. Top: visible
dataset. Bottom: IR dataset
Table 2: The binarization thresholds automatically selected
for the top 7 patches, with a MI ranking. Visible and Infrared databases
with 1% of the patches (i.e. 40), 4% with 3% of the patches
and has the same accuracy with 5% of the patches. In the
other database, tree1 is 18% better than 1vs1 with 1%
of the patches, 8% with 3% of the patches and has the same
performance with 4% of of the patches.
We can also notice that the tree computation is crucial,
because the random tree tree2 is signiﬁcantly worse than
tree1 (ﬁgure 6, last line).
From this observations we can conclude that HBC classiﬁers are more accurate with a small number of features.
4.5. Data transformation
In this section we want to observe the inﬂuence of data
representation on the classiﬁcation accuracy. We compare
the following representations: raw (number of detections),
proba (linear transformation by object), ranging (gives
the same range to all dimensions), bin0 (presence / absence of patch) and binAuto (optimal minimum detection
Proba and ranging are two popular transformation
methods . Compared to the original data (raw), we observe that ranging improves the performance and proba
decreases it. The standard binarization bin0 is also an improvement, since it outperforms ranging.
Our new data transformation method, binAuto, is the
most efﬁcient of the evaluated transformations. For the IR
dataset, binAuto and bin0 give the same improvement
of accuracy: +7 points compared to raw. For the visible
light dataset, binAuto is +9 points better than raw, and
+4 points better than bin0. Figure 7 compares bin0 and
binAuto for the multi-class strategies 1vs1 and tree,
average accuracy
percentage of selected patches
naive bayes
average accuracy
percentage of selected patches
naive bayes
average accuracy
percentage of selected patches
naiveBayes
average accuracy
percentage of selected patches
naiveBayes
Figure 6: Multi-class strategies. Top: visible database (full
graph and zoom).
Bottom: IR database (full graph and
zoom). The graphs show the mean accuracy in function of
the percentage of selected patches.
average accuracy
percentage of selected patches
1vs1 - Bin0
1vs1 - BinA
Tree1 - Bin0
Tree1 - BinA
Figure 7: Automatic binarization increase the performance
of 1vs1 and tree
in the visible database: in both cases, binAuto leads to a
signiﬁcant improvement of the accuracy.
We have to understand why bin0 and binAuto have
the same performance on the IR database, and different ones
on the visible database. Table 2 shows the thresholds that
were automatically selected for the two databases. The optimal thresholds are very high in the visible database — so
bin0 is less informative — whereas they are often zero
in the IR database — so bin0 is a good approximation
of binAuto.
Unlike bin0, the automatic binarization
method can be used in many situations, because it does not
require to set thresholds that are database dependent.
5. Conclusion
We have considered the problem of vehicle recognition for
“bag of features” approach and the trade-off between the
accuracy and the number of parts used in the model – directly affecting the computational speed. We proposed a
new data representation, based on maximum mutual information binarization, that improves the classiﬁcation accuracy. We also proposed a feature selection scheme adapted
to hierarchical classiﬁers, which outperforms feature selection strategies applied to the standard 1vs1 SVM classiﬁer
when the number of parts selected are small. We achieved
good results both for infrared vehicle categorization problem and for more generic visible object categorization problem.
Future works include the evaluation of wrapper methods for hierarchical classiﬁers, and the use of conditional
mutual information to remove redundancy in the selected