Analysis of feedback systems with structured
uncertainties
John Doyle
Indexing terms;
Control theory, Feedback, Robustness, Sensitivity
Abstract: The paper introduces a general approach for analysing linear systems with structured uncertainty
based on a new generalised spectral theory for matrices. The results of the paper naturally extend techniques
based on singular values and eliminate their most serious difficulties.
Introduction
The last several years has seen something of a revolution in
multivariable control theory. Central to this revolution is a
renewed focus on the fundamental issue in feedback design:
providing performance in the face of uncertainty. This development has been supported by a renewed interest in the frequency
domain. An indication of the growing acceptance of these
points of view can be found in the recent Special Issue on
'Linear multivariable control systems' in the February 1981
IEEE Transactions on Automatic Control, where five of the
first six articles [1—5] deal with uncertainty, robustness and
sensitivity using frequency-domain tools.
There are many results of both practical and theoretical
importance which have come out of this research. As a consequence, it is now well known that multivariable sensitivity
and robustness cannot be reliably evaluated one loop at a
time . Singular-value methods have proved useful in
providing both a reliable multivariable measure of sensitivity
and robustness and, more generally, a framework
within which to develop reliable multiloop versions of the
main tools of classical control theory [1—9].
While these results are reasonably well understood within
the control theory community, many of the more subtle
aspects of multivariable feedback systems are less well understood. Multiloop systems have important properties that have
no analogues in the single-loop case, For example, there are
problems caused by the fact that the signals and responses in
multiloop systems vary not only with frequency, but also
with direction. While some published results [8—10] have
given preliminary indications of this, the issue of directionality
in multiloop systems is largely unexplored.
The most serious limitation associated with the methods
based on singular values is that they treat a limited, albeit
important, class of uncertainties. Roughly speaking, most of
these results give, at best, exact characterisation (i.e. involving
necessary and sufficient conditions) of the feedback properties of a system model relative to perturbations which are
norm bounded but otherwise unconstrained. There is no
systematic mechanism for exploiting information about the
structure of a perturbation.
The aim of this paper is to develop techniques for analysing systems with arbitrary constraints on their structure.
Section 2 discusses some particularly important examples of
structured uncertainties in an attempt to motivate the general
results in later Sections.
Sections 3—5 present the main theoretical results. In
Section 3, the block-diagonal perturbation problem is formulated. This problem is quite general since any norm-bounded
perturbation problem, regardless of structure, can be trivially
rewritten as a block-diagonal perturbation problem. This pro-
Paper 2205D, first received 4th May and in revised form 14th September
The author is with Honeywell Inc., MN 17—2375, 2600 Ridgway
Parkway, PO Box 312, Minneapolis, MN 55440, USA
blem leads to the definition of a function n that provides
necessary and sufficient conditions for structured matrix
perturbation problems. Section 4 examines the properties of
the function ju and expresses it in familiar matrix algebraic
terms. Section 5 develops the tools necessary to find gradients
for singular values, which are used in Section 6 to provide
techniques to compute n in important special cases. Section 7
has some examples and a discussion of recent experience in
computing ii, and Section 8 gives a summary and conclusions.
Importance of the block-diagonal perturbation problem
Analysis methods based on singular values have been successful
in providing a framework within which to develop multiloop
generalisations of classical single-loop techniques. While this
has been an important development, singular-value methods
have serious limitations. Consider, for example, the problem
of analysing a linear multivariable feedback system with two
multiplicative perturbations appearing simultaneously at the
inputs and outputs [8—10].
There are essentially two direct applications of singularvalue techniques to this problem. First, the system may be
rewritten to isolate the two perturbations as a single perturbation with a two-block-diagonal structure. This structure can
then be ignored by replacing the block-diagonal perturbation
with one full matrix perturbation. In this configuration,
standard singular-value analysis can be applied. Of course, the
results may be, in general, arbitrarily conservative. A second
approach is simply to treat the two perturbations one at a
time, leading possibly to arbitrarily optimistic answers.
If these first two approaches to the simultaneous perturbation problem happen to give the same results, then the
'true' answer is obviously determined. In general, this will
not be the case. It should be emphasised again that these two
approaches can yield arbitrarily bad estimates; i.e., depending
on the problem, the gap between the upper and lower bounds
may be arbitrarily large. No other information can be obtained
from these bounds other than that the 'true' answer lies
between them. This will become evident in the course of this
An extension of the direct application of singular values is
to analyse the differential sensitivity of the singular values
evaluated at one point relative to perturbations at the other
 . Reference 10 is extremely well written and would provide excellent background for the present paper. However,
this approach suffers from the fundamental difficulty associated with differential sensitivity techniques in not applying to
large perturbations. In addition, the results in Reference 10
provided only directional sensitivity information (i.e. directional derivatives) when singular values are not clustered. If
differential sensitivity methods are to be effective, it is often
important that worst-case directions (as with gradients) be
obtained. The results of this paper can be modified for computing worst-case differential directions for clustered singular
values. Although not developed further here, this may make it
0143-7054/82/060242 + 09 $01.50/0
IEEPROC, Vol. 129, Pt. D, No. 6, NOVEMBER 1982
possible to complete the results in Reference 10 for clustered
singular values.
What is really desired, of course, is an exact analysis of the
original simultaneous independent perturbation problem,
which applies to large perturbations. One application of the
results in this paper is just such an analysis method. This will
be illustrated in Section 7 by a simple 'textbook' example.
The problem of evaluating robustness with respect to simultaneous input and output perturbations is a special case of the
more general problem of evaluating robustness with respect
to perturbations with arbitrary constraints on their structure.
Consider the general problem of an interconnected linear
system with multiple independent norm-bounded perturbations
occurring throughout. By rearranging the system, it is always
possible to isolate the perturbations as a single large blockdiagonal perturbation.
Stability analysis, for example, then essentially boils down
to ensuring that / + MA remains nonsingular at all frequencies
and for all A under consideration. Here, A is a block-diagonal
perturbation and Mis the transfer function from the collective
outputs of the perturbations to their inputs. Readers unfamiliar with manipulating systems to isolate specific components
as a diagonal matrix are encouraged to try some examples and
convince themselves that it can be done. This notion is essential
to understanding how the results in this paper may be applied
to analyse control systems.
The key problem then involves the matrix problem of
determining necessary and sufficient conditions such that
det (/ +MA)¥: 0. All norm-bounded linear perturbation
problems reduce almost trivially to this. The main results in
this paper are a partial solution to the general block-diagonal
perturbation problem and a complete solution for the case
of three or fewer blocks.
Definitions and problem formulation
The following notation will be used throughout:
= alegbra of complex k x k matrices
= unitary matrices in Jf(k)
= maximum singular value of M
= spectral radius = magnitude of largest eigenvalue
= least (most negative) eigenvalue for Hermitian H
= conjugate transpose of M
M2, M3, . . . . , Mn) = block-diagonal matrix with
Mj (not necessarily square) on the diagonal
To provide a description of block-diagonal perturbations, let
JT= (mi, m2,.
. . , mn, kx, k2,...,
kn) be a 2«-tuple of
positive integers. All the definitions that follow depend on
= {diag (tf i 4 , , d2lki
,...,dmilki,dm
{6i*&(dl,d2,...,dK)\d,e[0,~)}
Thus Xb is the set of block-diagonal matrices with structure
determined by Jf whose norm is not greater than 5, and
Xoo is all such matrices with no restriction on the norm.
What is desired is a function (depending, of course, on
with the property that for
det (/ + MA) =£ 0
for all A G X8
if, and only if,
This could be taken as a definition of fi. Alternatively, //
could be defined as
if no A e Xm solves det (/ + MA) = 0
|det(/ + MA) = 0
This definition of ju shows that a well defined function satisfies
eqn. 1. It probably has little additional value since the optimisation problem involved does not appear to have any useful
properties.
In order to proceed further, some additional definitions are
needed. Again, assume the 2«-tuple ^"is given.
%= U{K)C\XX
(block-diagonal unitary matrices)
.,dmIkm)\dteR+
= {diag (i>,, vx
JT, but, to simplify notation, this dependency will not be
explicitly represented. Unless specifically noted otherwise,
^will be assumed to be an arbitrary but fixed 2«-tuple of
positive integers. Let
For each 5 ER, 8 > 0, let X8 <ZJ?{K) be
vn.x,vn,...,vn)\
VjECkJ*l,v;Vj
= 1,/ = 1,2,...,/!}
Note that these definitions all depend on J2f, but to explicitly
represent the dependency (for example, \xx, X^.s, ^ e t c . )
would be unnecessarily cumbersome. Using these definitions,
several useful properties of fi are stated in the following
Section, leading up to the first main result of the paper.
The problem formulation taken here is certainly not the
most general possible. For example, the entire development in
X8 = {diag(A 1,A 1,...,A 1,A 2,A 2,...,A 2,A 3,
and amax(Ay) < 5 for each/ = 1, 2,. . . , n}
IEEPROC, Vol. 129, Pt. D, No. 6, NOVEMBER 1982
An_,, An, An,. . . , A J
this paper could be done with nonsquare perturbations with
no conceptual change in the results or proofs. The notation,
however, would become even more cumbersome than it
already is. The particular approach taken is the simplest that
allows both p and amax: to emerge as special cases of yi. Hopefully, this will aid the reader by maintaining continuity with
standard linear algebra as well as with some of the more
popular existing methods in multivariable control.
Properties of 11
The following properties of/i are easily proven from eqn. 1.
As always, JT= {m\, . . . , mn, kx, . . . , kn) is an arbitrary
2«-tuple for some n G / + , unless specified otherwise, and
fji(AB)<omax(AMB)
fox all A,
forallAGX6
If n = 1 and m t = 1, then
li{M) = amax(M)
x6 = {x/|xe c,ixi<5}
ju(M) = p{M)
(h) For all A € I K a n d for all
(0 For all U G ^ and M G J?(K),
(/) For all D G ^ a n d M
max p ( UM) < /i(A/) < . inf amaje (DMD~l)
(/) For all A G Xoo, there exist U, V G ^and
(m) n is continuous in the usual metric topology on
Property (/) is just a block version of the singular-value decomposition (SVD). Properties (e) and (/) show that JU has as special
cases both the spectral radius and maximum singular value or
spectral norm. Property (i) means that pi is ^-invariant. The
main theorem of this Section will show that the left-hand
inequality in property (k) is actually an equality and thus
that ix is, in some sense, the fundamental ^-invariant. In order
to prove this theorem, some simple lemmas involving polynomial equations are needed.
Suppose p: C fe -*• C is a polynomial in k complex variables
of degree no more that q G 2 for each variable. For z =
(z l 5. . ., zfe)GCfe, let ||z|U = max \zj\ be the usual || • IL
norm on C h. Let z G Cfe be such that p(z) = 0 and \z\ =
min (l|z|Llp(z) = 0); i.e. z is a solution of p(z) = 0 with
minimum || • IU
There exists x i
for ally = 1 , . . .
such that p(x) = 0 and |x/| = ||i
Let Xj = 2j for each z;- such that |z;-1 = ||z|L. If
HzIL for all /, then x=z
satisfies the lemma. So suppose
that one of the components of z, say for convenience zk,
has \zk | < | | z | U . Then p(z) = S p , . ^ , . . . ,zk_x)zk,
each pr is a polynomial in A: — 1 variables. Suppose that for
some r, pr{zx,.
. . , zk_l)i^Q.
This will lead to a contradiction. By continuity of the roots of a polynomial, for any
e > 0 there exists 5 > 0 such that, for each y GCh~l
that || y — ( z ! , . . . , f fe _ j) II < 5, there exists a w G C such
that \w — zk\<e
and Xpr(y)wr
= 0. Then, by choosing e
sufficiently small, there exists a / G C f e ~ 1 and wG C such
that P(j>i,y2,...,yk-i,
vv) = 0 and IICPi,. . ., yk.l,
I L < | | z | U . This contradicts the minimising property of z.
Thus pr(zx,
. . . , zfe _!) = 0 for all r, 0 < r < q, and p(z x,
. . . , zk _!, w) = 0 independent of w. Let xk =\\z IL. This
argument may be repeated for each j = 1, 2,. .. , k so that
either Xj = 2j or Xj = \\z |U and p(x) = 0 for x = ( x 2 , . . .,
jcfe). This completes the proof.
This lemma may seem a bit obscure at first glance. What it
basically says is that if HzIL is to be minimised subject to
the constraint that p(z) = 0, then at least one minimising
solution x lies on the poly disc where each \Xj \ — ||JC|L. This
will allow a great simplification in the characterisation of i±.
First though, note that the proof of lemma 1 immediately
implies the following two additional lemmas.
If z is real [Im(zy) = 0 for all / ] , then there exists
such that p(x) = 0 and \xj \ = \\z IL for all / = 1, 2,. . . , k.
If z is real and non-negative [Im(zy) = 0 and Re(z ;)> 0 for
all/], then there exists x GUk non-negative such thatp(x) = 0
andx;- = ||z||c=.
H(M) = max p(MU)
Suppose MGJ?(K).
If /i(M) = 0, then the result follows
immediately from property (k), and so assume n(M) = 1/8
> 0 . Then there exists A G I 6 (not necessarily unique) such
that omax(A) = 8 and det(/ + MA) = 0. By property (0,
there exist U, KG ^and 2 G ^such that
det(/ + MA) = 0
if, and only if,
det (I+ MUXV*) = 0
This last equation may be viewed as a polynomial in the diagonal elements of 2. By assumption, E is a minimum norm
(now viewed as || • II- on the diagonal elements) solution to
this polynomial. This satisfies the conditions of lemma 3 and
IEEPROC, Vol. 129, Pt. D, No. 6, NOVEMBER 1982
therefore 2 may be replaced by a scalar 5/. Thus
det (I+ MUXV*) = 0
det (/ + 8MUV*) = 0
which implies
p(MUV*) > 1/6 = fi(M)
By property (k), the reverse inequality also holds, and so
max p(MU) = ii(M)
max p(MU) = \=> there exist £/G %f and xGC f e
that Aft/* = XJC. This implies there exist
K, WG^suchthatMWK** = XJC
which implies
p(MWV*) = p{V*MW) > X
which in turn implies
p(V*MW) > X
Similarly,
max p(MU) > X
for all Af G ^ ( X )
This theorem and corollary express /i in terms of familiar linear
algebraic quantities. Note that it is now possible to use the
corollary to define a general matrix decomposition that would
have both the singular-value decomposition and Jordan form
as special cases. While such a unification may prove to be of
a great theoretical interest, it is not essential to the aims of
this paper and will not be pursued further here.
Instead, the remainder of this paper will be devoted to
developing methods to compute ii{M). Unfortunately, the
optimisation problem expressed in the corollary cannot be
solved in general by simple gradient or local techniques.
Examples have been generated which have multiple local
maxima. While recent computational experience with some
alternative algorithms is very promising, no efficient algorithms
have been developed which have proven guaranteed convergence to the global maximum.
An alternative approach will now be taken by considering
the right-hand side inequality of property (k). In important
special cases it will be shown that this inequality is actually
an equality, and that inf a^,^ (DMD~l) has no local minimum
which is not global. In fact, a tedious but straightforward calculation shows that amajc(Z)MZ)~1) is convex inD. The proof
of this is omitted since it is not actually needed for any of the
main results, but it makes this optimisation problem an attrac-
IEEPROC, Vol. 129, Pt. D, No. 6, NOVEMBER 1982
tive alternative. The first step needed for solving infamajc
(DMD~l) is a technique for computing descent directions.
This problem is taken up in the following Section.
Differentiability properties of singular values
This Section will develop the necessary tools for computing
'gradients' for singular values. Although singular values are not
in general differentiable functions of the matrix elements, it
is always possible to compute a generalised gradient which
serves the same purpose as would a gradient. This Section will
be brief and not at all self-contained and only original results
will be proved. An excellent background for this Section is
Reference 10, as well as standard texts [11—13].
Suppose M: SI -+J?(k) is a matrix-valued function whose
elements are real analytic in some neighbourhood SI of 0 G U Q.
Denote by omax(x)
[for amajc(Af(jt)), x G SI] the maximum
singular value of AT as a function of x G£2 C UQ.
The directional derivatives of omax(x)
at JC = 0 depend
only on M{x) to first order, and so without loss of generality
M{x) = Mo + X
for x = (*!, x2 ,. . . , xq). Using the SVD, M(0) may be
written as
Af(0) = MO = o w (O)^ V\ + U2 2 2 V$
Here Ux, Vl,GCkxr
with r the multiplicity of amajc(0) and
[UlU2],[VlV2]EUik)
Suppose amax (0) > 0 [i.e. M(0) * 0]. Then, letting (amajc)0 =
amax (°)> °max (*) m ay b e written as
= \(omax)0
j) + 0(*) I
Hj = Hf = ReiUfMjVi) = hiUfMjVx + V\MfU{)
Define Vt C R q by
Vi = {x£UQ, xj = v*HjV\v*v = 1 and v is an eigen-
for some 0
and denote by coV! the convex hull of Vx. Denote by x = min
(coVi) the unique point x G coV! that minimises
A well known property of convex sets that will be used in the
following theorem is that (x, x) > || x ||2 for all x G coVx .
The significance of Vt is expressed in the following theorem.
If JC =5^ 0, then there exists e0 > 0 such that
°max ( - ex) < (omax)0
for all 0 < e < e0
Let v be a unit eigenvector associated with the eigenvalue
XminiXXjHj)
and let ^ G V , be defined by ys = v*HjV for
7 = 1 , 2 , . . ..tf.T
j) = V*(?XjHj)V = Cx,^» 0
Then from eqn. 2 there exists e0 > 0 such that amax ( — ex)
< iPmax)o for all 0 < e < e0.
This theorem implies that, although omax{x)
is not necessarily
differentiable, x = min (coVx) serve one of the purposes of a
gradient in providing a descent direction. If x =£ 0, then a
direction (for example, —x) can be found which reduces all
the singular values in the cluster. In the special case where
omax(0) has multiplicity one, then Vx trivially reduces to the
ordinary gradient. It may be thought of as the direct limit of
the sets of possible gradients in neighbourhoods of 0. Unfortunately, Vx is a rather awkward set to work with since it
depends, in part, on singular vectors of M{x) for x =£ 0.
As an alternative, consider the set
v2 = {xeuq,xj
= v*Hjv\veCq,v*v = 1}
Clearly, Vx CV 2. While V2 has a much simpler description
than Vx, it serves the same purpose, as is shown by the
following lemma and theorem.
min (coVO = min (coV2)
Let y E V2 and x = min
such that v*v = 1. Then
2XJ(V*HJV)
). Then y}- = v*HjV for some v
for some Jt
Therefore \\x\\< || min (coV2) || and since
j C V2, x = min
It suffices to prove that dist {x, coVj) = dist (x, coV2) for all
xe Uq. Fix jf = (x 1 >... ,xg)e Uq. Define Vt and V2 by
replacing H}- by Hj—Xjl in the definitions of V! and V2,
respectively. Then, by lemma 4,
dist (x,coVi) = || min (coVi) II2 = II min (coV2)||2
= dist (x,coV2)
This holds for any
, and so the proof is complete.
In order to make effective use of V2 in, say, an optimisation
algorithm or a sensitivity calculation, there must be some
reliable algorithm for computing min (coV2) [or maybe
max(coV2) for sensitivity] given the {Mj}. The Appendix
briefly describes an approach to this. The rest of this Section
is concerned with properties of V2 that will prove useful in
the following Section.
Suppose that Hj = Hj* E^(r), / = 1, 2,. . . , q, and let
/: Cr-» UQ be defined by fj(x) = x*HjX for*EC r. Let
Sn = {xGUn + l \xTx =
Note that this notation is not standard.
For r = 2, there exists an affine map g:
f(P2)=g(S2).
3 -> Uq such that
for some /. Then
sin0(cosi// — /sini//)] | _
[sin 6 (cos i// + /sini//)
•d +2Re(6cos0 sin
(l/2)(a-c)cos20
+ sin26 Re(Z>(cosi// + /sini//))
= 0/2) (a+ c)
sin20 sini// .
Let gi :R3 -*• U be the affine map defined by the scalar and
vector in the last equation so that/i(P2) =gi(S2) as shown.
Define gj for / = 2, 3,. . . , q similarly so that the resultant
is affine. Then/(P2) =g(S2) as desired.
defined above, if q = 1 or 2, then f{P2) is
If q = 1 or 2, then for any affine map g:U3
convex. Apply the theorem.
Let f:&^Mq
be defined as above for arbitrary rEI+. If
q = 1 or 2, then f(Pr) is convex.
Let x, y E Cr, x ±y and || * || 2 = \\y \\ 2 = 1. It suffices to
show that z{t) = tf(x) + (1 - 0/00 e/(Pr) for all t E
 . Let
for all; = 1, 2,. . ., q, and let/:C2 -> Uq be defined as before
in terms of the Hj. Then f(x), f(y)€f(P2)Cf(Pr)
f(P2) is convex by the previous corollary. Thus z(t)Ef(P2)
f(Pr) for all t E , and so f(Pr) is convex.
This last corollary implies immediately that,
for fiERa and q = 1 or 2, then the V2 defined as before is
convex. This will prove quite useful in the following Section.
Note that the results of this Section and Appendix could
be used to study the sensitivity of clustered singular values to
infinitesimal parameter variations. The aim of this paper,
however, is to develop techniques for handling large perturbations, and so the following Section will make use of these
results to compute the function \L.
IEEPROC, Vol 129, Pt. D, No. 6, NOVEMBER 1982
Computation of fi
This Section will combine the results of the preceding two
Sections and concentrate on the right-hand side inequality in
property (k) of Section 4. Suppose in this Section that in the
2/i-tuple ^ rrij = 1 for each / (there are no repeated blocks).
Then reduce Jf to an «-tuple 3F = {kx,. . . , kn) and let
Define DMn ^J?(K)
D{x) = diag (exp Oi)/, exp (x 2)/, . . . , exp (xn)f)
ForMoe^?(K), define M: Rn -+^{K) by
M{x) = D(x)M0(D(x)yl
D(x)M0D(-x)
and let amflJC (x), Ui,Vi,Vlt
V2 etc. be defined as in Section 4
for M(x). Let A = f/j and £ = £/2 and assume that M is
normalised so that amajc (0) = 1. Then write
a2 . . . cr] =
and similarly for 5 in terms of {bf} and {fy}. Here a / G C K x l ,
a/ GC f e / x r (similarly for 5). It is then easy to verify that
= 1 if, and only if, 0 G V2(M).
0GV2(M)if, and only if:
(i) there exists.y Gp r such that
if, and only if,
WffyW = l|a,VH
if, and only if,
(iii) for all /, there exists Uj G U(kt) such that
if, and only if,
(iv) there exists f/G ^such that By = UAy
dtog(UltU2,...,Un))
if, and only if,
if, and only if,
(vi) there exists 0 =£ x G C K such that
if, and only if,
(vii) MUx = x
(since omax (M) = 1)
if, and only if,
(viii) p(MU) = 1
Therefore, using property (k) from Section 4, n(M) = 1 if, and
only if, 0GV2(M).
For n < 3, a ^ ( M ) = ii(M) if, and only if, 0 G coV2.
For any «, V2 depends only on « — 1 variables, since V2
lies in the (n — l)-dimensional subspace of Rn orthogonal to
(1, 1,. . . , 1); i.e. D(x)M0D{ — x) is constant along any line
parallel to the line through 0 and (1, 1,. . . , 1). For n < 3, by
the second corollary to theorem 3, V2 = coV2, and the result
then follows from Theorem 1.
These two theorems have important implications for computing (i. Suppose that, conceptually, a gradient search is to be
used to compute
with min(coV2) serving as a gradient when there are clustered
singular values. This search can proceed until a local minimum
is found, i.e. 0GcoV2. [As was mentioned earlier, amax
(DMD'1) is convex in D, and so such a local minimum would
be global.] If, in fact, 0 G V2 at this point, then, by theorem 5,
Ii has also been found. Unfortunately, it is not generally
true that 0 G coV2 implies 0 G V2 •
Theorem 6 implies that, for the case n < 3 (three or fewer
blocks), V2 = coV2, and so such a gradient search would (at
least conceptually) always yield n. This result is rather remarkable since the optimisation involves only n — 1 variables,
regardless of the size of the blocks. Furthermore, in view of
theorem 3 and its corollaries, the computation of the generalised gradients for these cases should be quite straightforward.
This provides the desired technique for exact analysis of
multivariable systems with simultaneous input/output perturbations (i.e. two blocks), as well as more general situations.
Examples and computational experience
Two numerical examples and a discussion of computational
experience are contained in this Section. The examples are
intended to be purely illustrative, and no particular significance should be attributed to them.
The first example uses a 3 x 3 matrix for which n will be
computed for five different structured perturbations. The
nominal matrix is
and the five uncertainty structures are shown in Table 1. The
perturbation in case 1 is block diagonal, and so ji can be
computed directly from M. In cases 2—5, however, the matrix
must be rearranged to make the perturbation block diagonal.
This can always be done by pre- and postmultiplying M by
appropriate matrices, denoted here by L and R, respectively.
The last two columns in Table 1 give JTfor that case and the
corresponding /i (LMR).
Cases 1—3 have three or fewer blocks, and n was computed
using the approach suggested in Section 6. Cases 4 and 5 have
more than three blocks, and n was computed using an algorithm based on theorems 1 and 2. The global maximum was
found for case 4, as was verified by computing infcmojc
(DLMRD~X) and obtaining agreement to within the accuracy
of the algorithms' termination conditions (in this case, four
digits for single precision).
This example illustrates that fi depends heavily on the
assumed structure of the uncertainty. This should not be
interpreted as a limitation on its usefulness. On the contrary,
it emphasises the importance of having a method for analysing
matrix perturbation problems that maintains structure. The
next example illustrates how a particular uncertainty structure
could naturally arise in a feedback system.
The following example was originally constructed by the
author to illustrate that loop-at-a-time analysis was inadequate
for studying simultaneous variations in multiloop systems and
to introduce the use of singular values. An example was published by the author . The actual design analysed here was
IEEPROC, Vol. 129, Pt. D, No. 6, NOVEMBER 1982
proposed by Sain et al. . A thorough and lucid discussion
of this example, including Sain's design, can be found in
Reference 10.
Consider the feedback configuration in Fig. 1, where the
nominal plant P has a transfer function
9 ( s + l )
10 (s + 2)
The feedback compensation K is the product of the two
elements of the compensator in References 15 and 10. Only
the product K affects the system's feedback properties.
Fig. 1 Block diagram for example design
For this example, the nominal plant is considered to
have simultaneous multiplicative perturbations at the
input and output. In applications, such perturbations might
arise from actuators, sensors and unmodelled dynamics. The
perturbations could then be weighted to reflect the fact
that the level of uncertainty varies in frequency and direction.
This example has no physical motivation, and so for simplicity
this system will be evaluated for robustness with respect to
unweighted size of the norm-bounded perturbations. It is
desired to compute the smallest norm-bounded perturbation
(as a function of frequency) which produces instability.
If only one perturbation is considered at a time, then ii
is simply the maximum singular value of the transfer function
(I + PK)-lPK
or (I + KPylKP,
for an output or input
perturbation, respectively. These two transfer
happen to be the same for this example, and their maximum
singular value is plotted as the lower curve in Fig. 2. This
implies, for example, that there exists a destabilising perturbation of norm 1 and that all smaller perturbations can be
tolerated without instability. Unfortunately, this provides very
little information (other than the upper bound) on the tolerable level for simultaneous perturbations; i.e. these maximum
singular values are a lower bound for n for simultaneous
perturbations.
In order to analyse the system for simultaneous variations,
it is rearranged to isolate the A,s as a block-diagonal perturbation in standard feedback configuration, as in Fig. 3. For
this example, one choice is
-(I+PK)~lP
(I + PK)~lPK
Fig. 3 Standard feedback configuration
If the block structure were ignored at this point, then amax
(M) (the upper curve in Fig. 2) would provide a tight bound
on tolerable perturbations A. Unfortunately, amax{M) provides only a conservative bound for the block-diagonal case.
For the structure as given, the corresponding M is plotted
in Fig. 4. This plot has several interpretations. The simplest
is that the system can be stabilised by simultaneous perturbations with norms approximately equal to 0.1, and smaller
perturbations may be tolerated without instability. The
bounds in Fig. 2 were almost useless for this example. More
generally, it is quite easy to construct examples where the gap
for both bounds is arbitrarily large.
The relatively large value of n in this analysis should not be
considered as an indictment of this design. It merely indicates
that the design has poor margins relative to this particular
uncertainty structure; with respect to another structure they
may be much better (for example, the margins for uncertainty
on just one side may be good). A design that tolerated
larger simultaneous variations of the type considered here
frequency, rad/s
Fig. 2 Singular-value bounds
frequency, rad/s
Fig. 4 Plot of M for example design
IEEPROC, Vol. 129, Pt. D, No. 6, NOVEMBER 1982
Table 1: Uncertainty structures
( 1 . 1 . 1 .
(1,1. 1, 1,
would have to sacrifice some other aspect of performance.
There was no physical basis for the uncertainty: it was chosen
to be illustrative. Thus the results should not be interpreted
too broadly.
This example reiterates the point that vastly different
numbers are obtained, depending on the assumed structure of
the problem. For practical problems, the structure is dictated
to a large degree by physical reality and engineering constraints. The extent to which a design engineer can capture and
handle the natural structure determines the extent to which
the conclusions based on any analysis are relevant to the
practical problem. It is hoped that the ideas introduced in this
paper and illustrated in the examples will make a contribution
towards better techniques for handling structured uncertainty
in feedback systems.
An important consideration in the application of n is a
numerical software. In as much as the ideas in this paper are
relatively new and have not been published before, it may be
some time before reliable numerical software (as in Unpack
or Eispack) is available to compute n. The computational
experience to date is most encouraging, however. Programs
have been developed to compute both bounds in property
(k) of Section 4. Recall that the lower bound is always an
equality (see Section 4), but the global maximum may be
difficult to find. The optimisation problem in the upper bound
is convex, but it is only guaranteed to yield n for three or
fewer blocks (see Section 6).
The ratio between the lower and upper bounds produced
by these new programs has been computed for over 50 000
pseudo-randomly generated matrices of dimension three to
ten, mostly with scalar blocks. The worst-case ratio was
approximately 0.95, although examples have been constructed
analytically where the ratio was ^0.85. It is interesting to
note that the ratio seems not to decrease after four dimensions.
This is suggestive but, of course, not conclusive. As expected,
for three dimensions it is always 1 to within reasonable numerical error.
Because the computer programs are experimental, i.e. containing many diagnostics and obviously inefficient code, it is
impossible to draw any meaningful conclusions about computational speed. As a single data point, it took approximately
three times longer to compute the curve in Fig. 4 as it did
to compute the bounds in Fig. 2.
Summary and conclusions
This paper has introduced a general approach for analysing
linear systems with structured uncertainties based on a new
generalised spectral theory for matrices. This basic theory
addresses the norm-bounded perturbation problem with
arbitrary structure. The strongest results are for perturbations
with three or fewer blocks, for which (conceptual) algorithms
with guaranteed convergence were proposed. One application
of these results is a generalisation of standard singular-value
analysis techniques for multivariable feedback systems to treat
simultaneous input/output uncertainty (i.e. two blocks).
These results are merely a beginning, and much more work
remains to be done. For example, existing multivariable
control methods provide little more than minor extensions of
SISO techniques. Initial study indicates that consideration
of multiple simultaneous perturbations leads to wholly new
phenomena, the explanation of which will provide a far deeper
understanding of multiloop feedback systems. Linear multivariable control theory will need to be thoroughly re-examined
in this new light. It is hoped that the more general results in
this paper could also provide the beginning of a nontrivial
theory of decentralised control and/or large-scale systems,
where use of structural information is essential.
IEEPROC, Vol. 129, Pt. D, No. 6, NOVEMBER 1982
Acknowledgments
Many people contributed to this paper, but I would particularly like to thank Dr. Joe Wall, of Honeywell Systems and
Research Center, for his help throughout the research and
writing. Jim Freudenberg of the University of Illinois and
Honeywell SRC made a major contribution to the implementation of the algorithms used in the examples and offered
many useful suggestions regarding the paper.
This work has been supported by Honeywell internal
research and development funding, the US Office of Naval
Reserach under ONR research grant N00014-82-C-0157,
and the US Air Force Office of Scientific Research grant
F49620-82-C-0090.
This work is in the public domain in the USA.