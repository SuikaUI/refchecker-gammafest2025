DeepSonar: Towards Effective and Robust Detection of
AI-Synthesized Fake Voices
Run Wang1, Felix Juefei-Xu2, Yihao Huang3, Qing Guo1,†, Xiaofei Xie1, Lei Ma4, Yang Liu1,5
1Nanyang Technological University, Singapore
2Alibaba Group, USA
3East China Normal University, China
4Kyushu University, Japan
5Institute of Computing Innovation, Zhejiang University, China
With the recent advances in voice synthesis, AI-synthesized fake
voices are indistinguishable to human ears and widely are applied
to produce realistic and natural DeepFakes, exhibiting real threats
to our society. However, effective and robust detectors for synthesized fake voices are still in their infancy and are not ready to
fully tackle this emerging threat. In this paper, we devise a novel
approach, named DeepSonar, based on monitoring neuron behaviors of speaker recognition (SR) system, i.e., a deep neural network
(DNN), to discern AI-synthesized fake voices. Layer-wise neuron
behaviors provide an important insight to meticulously catch the
differences among inputs, which are widely employed for building
safety, robust, and interpretable DNNs. In this work, we leverage
the power of layer-wise neuron activation patterns with a conjecture that they can capture the subtle differences between real
and AI-synthesized fake voices, in providing a cleaner signal to
classifiers than raw inputs. Experiments are conducted on three
datasets (including commercial products from Google, Baidu, etc.)
containing both English and Chinese languages to corroborate the
high detection rates (98.1% average accuracy) and low false alarm
rates (about 2% error rate) of DeepSonar in discerning fake voices.
Furthermore, extensive experimental results also demonstrate its
robustness against manipulation attacks (e.g., voice conversion and
additive real-world noises). Our work further poses a new insight
into adopting neuron behaviors for effective and robust AI aided
multimedia fakes forensics as an inside-out approach instead of
being motivated and swayed by various artifacts introduced in
synthesizing fakes.
CCS CONCEPTS
• Security and privacy →Human and societal aspects of security and privacy; • Information systems →Multimedia information systems; • Computing methodologies →Artificial
intelligence.
DeepFake, fake voice, neuron behavior
ACM Reference Format:
Run Wang, Felix Juefei-Xu, Yihao Huang, Qing Guo, Xiaofei Xie, Lei Ma,
Yang Liu. 2020. DeepSonar: Towards Effective and Robust Detection of AI-
Synthesized Fake Voices. In Proceedings of ACM Conference (Conference’17).
ACM, New York, NY, USA, 10 pages. 
Run Wang’s email: 
† Qing Guo is the corresponding author ( ).
Voice Cloning
Text-to-Speech
Real Voices
Fake Voices
Fake Voices
Degradations
Figure 1: Two types of fake voices, voice cloning and text-to-speech. Voice
cloning is more likely a voice style transfer by giving a "source voice" and
output a cloned style similar "synthesized voice". Text-to-speech can generate
a new voices by any given texts having specific timbre. Degradation indicates
our proposed approach DeepSonar can handle voices that are manipulated by
voice conversions and additive real-world noises.
INTRODUCTION
In August 2019, the wall street journal reported the news titled
"Fraudsters Used AI to Mimic CEO’s Voice in Unusual Cybercrime
Case" . In this report, criminals used AI-based software to impersonate a CEO’s voice and successfully swindled more than $243,000
by speaking on the phone. Recently, advances in AI-synthesized
techniques have shown its powerful capabilities in creating highly
realistically sounded voices , indistinguishable images , and natural videos . Human eyes and ears could be
easily fooled by these realistic DeepFakes . Furthermore, producing DeepFakes is easy with tools like FaceApp, ZAO, etc. Thus,
it also raises security and privacy concerns to everyone while we
are enjoying the fun of these synthesized fakes. Powerful detection
and defense mechanisms should be developed by the community
for fighting against such DeepFakes .
Voice/speech synthesis steps into a new era since DeepMind
developed WaveNet that could generate realistic and convincing voices. Improving the interaction experiences between
machines and humans is the initial idea for developing voice synthesis techniques. Based on this idea, some commercial products
like intelligent customer service are created by using voice synthesis techniques. Unfortunately, some attackers and criminals misuse
them for illegal purposes like a politician giving an unreal statement,
which may cause a regional crisis or someone imitating the victim’s
voice for fraud intentions. All of these can be easily performed without any effort by merely giving texts and a clip of the victim’s real
voice using some open-sourced tools or commercially available
text-to-speech (TTS) systems. Thus, discerning whether a clip of
 
voice is synthesized with AI or spoken by humans is extremely
important in this era when hearing is not believing anymore.
TTS synthesis, voice cloning (VC), and replay attack (RA) are the
three different modalities for synthesizing fake voices . TTS and
VC involve the content regeneration, thus they are more realistic
than RA and are difficult for human ears to distinguish. Therefore,
they are especially worrisome and pose high risks. Figure 1 shows a
more detailed description of the two types of fake voices. Recently,
AI-synthesized fake voices have already drawn attention from the
community. Google launched a challenge competition dedicated to
spoofed voice detection . Farid et al. proposed the first bispectral
analysis method to distinguish human voices and AI-synthesized
voices based on the observation of the bispectral artifacts in fake
voices . However, existing works on discerning AI-synthesized
fake voices all failed in fully tackling the aforementioned TTS and
VC fake voices and thoroughly evaluating their robustness against
manipulation attacks, which is extremely important for a detector
deployed in the wild. Here, manipulation attacks indicate that the
voices are corrupted with real-world noises (e.g., rain, laughing)
or converted by manipulating their signals without altering its
linguistic contents, such as resampling, and shifting of pitch.
Voice synthesis and image synthesis are regularly combined
for producing audio-visual consistent video DeepFakes. Compared
to image synthesis, voice synthesis exhibits some differences and
brings new challenges to detection. Firstly, artifacts in fake voices
could be hardly sounded and provide sufficient clues for forensics.
They are vastly different from artifacts in fake images that are easily
noticed by eyes. Secondly, voice signals are one dimension signals.
It is not as simple to introduce artifacts into the voice synthesis
procedure as in images that have multiple channels spanning two
dimensions spatially. Lastly, for voices recorded indoors or outdoors
where noises are abundant, it is easy for the attackers to fool the
detectors by adding real-world noises in such circumstances, thus
robustness is essential for fake voice detectors.
In this paper, we propose a novel approach, named DeepSonar1
as presented in Figure 1, based on monitoring neuron behaviors of
a DNN-based SR system with a simple binary-classifier to discern
AI-synthesized fake voices. We conjecture that the layer-by-layer
neuron behaviors in DNNs could provide more subtle features and
cleaner signals for the classifiers than raw voice inputs, which
served as an important asset for differentiating real human voices
and fake voices. In this work, we are dedicated to the TTS and VC
fake voices since they are AI-synthesized with content regenerated
that are more indistinguishable than RA to our ears. To the best of
our knowledge, this is the first work employing layer-wise neuron
behaviors to discern AI-synthesized voices and conducting a comprehensive evaluation on its robustness against two manipulation
attacks, 1) voice conversions, and 2) additive real-world noises.
To comprehensively evaluate the effectiveness and robustness of
our approach in discerning AI-synthesized fake voices, our experiments are conducted on three datasets including publicly available
datasets, in which voices are synthesized with commercial products and self-built dataset with available open-sourced tools. In
1Sonar is known as its powerful capabilities in sniffing and probing electronic devices
underwater based on sound signals. We hope that our approach is a sonar in discerning
AI-synthesized fake voices.
the experiments, we aim to evaluate the effectiveness of Deep-
Sonar in distinguishing fake voices synthesized with different languages, synthetic techniques, etc., and investigate the robustness
of DeepSonar in tackling two manipulation attacks (including voice
conversion and additive real-world noises). Experimental results have demonstrated that DeepSonar gives an average accuracy
higher than 98.1% and an equal error rate (EER) lower than 2% on
the three datasets. DeepSonar also outperforms prior work leveraging bispectral artifacts to differentiate fake voices in both
effectiveness and robustness. Our main contributions are summarized as follows.
• New observation of layer-wise neuron behaviors for discerning fake voices. We observe that the layer-wise neuron
behaviors capture more subtle features that provide cleaner signals for the classifiers than raw voice inputs for building effective
and robust fake detectors. Thus, we propose DeepSonar based on
this observation by monitoring neuron behaviors to reveal the
differences between real voices and AI-synthesized fake voices.
• Performing a comprehensive evaluation of the effectiveness and robustness against manipulations attacks. Experiments are conducted on three datasets where voices are synthesized with various techniques, containing English and mandarin
Chinese languages spoken by males and females with different
accents. Experimental results illustrated its effectiveness in discerning fake voices and robustness against two manipulation
attacks, voice conversions and additive real-world noises.
• New insights for fighting against AI aided multimedia fakes.
Instead of investigating the artifacts introduced by various synthetic techniques, our approach presents a new insight by leveraging the power of layer-wise neuron behaviors for differentiating
real and fake in a generic manner. Furthermore, it also demonstrates the potentials for building robust detectors and evasion
attacks, which are important to be deployed in the wild.
RELATED WORK
Voice Synthesis
Voice synthesis can be divided into two categories: 1) non-DNN
based, such as using hidden Markov models (HMMs) and Gaussian
mixture models (GMMs) to learn speech features and replicate them,
and 2) DNN based for synthesizing naturalness speech and even
on unseen words.
The first technique is speech concatenation that concatenates
some pre-recorded speech segments to synthesize a new clip voice
 . The other technique on format analysis uses acoustic models without a human voice as input to generate robotic-sounding
speech . Modeling the human vocal tract and vocal biomechanics is another technique for synthesizing speech, which is known as
articulatory speech synthesis . Some studies explore leveraging
HMM to modulate speech proprietaries like fundamental frequency
and duration . These techniques are widely employed in the
early years for speech synthesis, but suffer from naturalness issues,
which could be easily sounded by human ears.
DNN based. DNN-based speech synthesis techniques directly
map linguistic features to acoustic features by leveraging the power
of DNNs in representation. Various models (e.g., Boltzmann machines , deep belief network , mixed density networks ,
Bidirectional LSTM ) are proposed based on DNNs for synthesizing high quality and natural speech. Some synthesized samples
are available online .
WaveNet developed by DeepMind in 2016 and Tacotron 
created by Google in 2017 are two milestones in speech synthesis.
The two models significantly promote the progress of speech synthesis, which enables large scale commercial applications for building TTS and VC systems. WaveNet originates from PixelCNN 
or PixelRNN and shown its powerful capabilities in modeling
waveforms with a generative model that is trained on a real audio
dataset. Tacotron is an end-to-end speech synthesis model
that can be trained on <text, audio> pairs to avoid large human
annotation efforts. Due to the powerful capabilities of WaveNet and
Tacotron, some commercial products are developed based on them,
such as Baidu TTS , Amazon AWS Polly , and Google Cloud
TTS . Unfortunately, some attackers can maliciously use speech
synthesis techniques and develop fake voices for fraud intentions,
bringing potential security concerns.
Fake Voice Detection
In the past decades, some digital audio forensic studies are working
on detecting various forms of audio spoofing . These approaches
examine metadata of audio files and investigate their actual bytes.
Douglas et al. examine the eleven audio recordings from three
Olympus recorders in the digital header data for audio authentication. Malik et al. propose using acoustic environment signature
as an important feature for detecting audio forgery by verifying the
integrity of digital audio. These studies failed in addressing audio
content that is synthesized.
The most similar work to ours is that is the first study dedicated to AI-synthesized fake voices. In their work, they propose a
bispectral analysis method for detecting AI-synthesized fake voices.
They observe that specific and unusual spectral correlation exhibited in the fake voices synthesized with DNNs, which are called bispectral artifacts. Thus, they explore to use higher-order polyspectral
features for discriminating fake voices. This work is also motivated
by investigating artifacts introduced in fake voices like some recent
studies on detecting fake images . Artifact-based detectors
will be invalid when the artifacts are fixed with some optimization
methods or new synthetic techniques are proposed.
In this paper, instead of investigating the artifacts in raw voices
introduced in synthesis, we explore a new way by monitoring
neuron behaviors of DNN-based SR systems with a simple binaryclassifier to distinguish real and fake voices. The layer-wise neuron
behaviors can capture more subtle features in differentiating real
and fake voices. Experimental results show that our approach outperforms previous work (by investigating bispectral artifacts )
in terms of both effectiveness and robustness.
We first introduce our basic insight in discerning fake voices, and
then present the overview framework of DeepSonar, after which we
detail how to capture the layer-wise neuron behaviors and detect
fake voices with binary-classifier in the following subsections.
Monitoring neuron behaviors is an important technique for hunting
the differences among a set of inputs to DNNs and investigating the
Raw Neurons
Fake Voices
Real Voices
DNN-based Model
Activated Neurons
Neuron Coverage
Layer-wise Neuron Behaviors
Data Collection
Classifier
Figure 2: The framework of our proposed DeepSonar. We collect numerous
real human speeches and fake voices synthesized with VC and TTS techniques as inputs, then a DNN-based SR system is adopted to capture the raw
layer-wise neuron behaviors of inputs and the designed neuron coverage criteria (e.g., ACN and TKAN) is employed to determine the activated neurons
which are more valuable in hunting the subtle differences between inputs, finally a binary-classifier is trained based on the activated layer-wise behaviors
of inputs to predict if a clip of voice is real or fake.
internal behaviors of DNNs, which is widely employed in assuring
the quality of DNNs , protecting the safety of DNNs
like fighting adversarial examples attack , and providing
interpretation for DNNs , etc.
For quality assurance of DNNs, both DeepXplore and Deep-
Gauge introduce neuron coverage as testing criteria to explore
the amount of DNN logic covered by given a set of inputs. Neuron coverage is similar to code coverage in traditional software
testing and used to explore the vulnerabilities of DNNs, which are
susceptible to adversarial examples . In ensuring the safety of
DNNs, NIC and MODE exploit the critical neurons in
DNNs for detecting adversarial examples and fixing issues that lead
to misclassification in DNNs. In providing interpretation for DNNs,
AMI explores the correlation between important neurons and
human perceptible face attributes. Furthermore, the visualization
techniques are also proposed to facilitate the understanding
on the roles of neurons.
According to recent studies, neuron behaviors have demonstrated their powerful capabilities in investigating the internal
behaviors of DNNs and revealing the minor differences among
inputs like adversarial examples and legitimate inputs. In this work,
we conjecture that layer-wise neuron behaviors could capture more
subtle features and produce cleaner signals to a classifier than raw
voice inputs in distinguishing the differences between inputs. Thus,
we propose DeepSonar by monitoring layer-wise neuron behaviors of the DNN-based SR system with a simple binary-classifier to
discern human speeches and AI-synthesized fake voices.
Overview of DeepSonar Framework
We present the overview of DeepSonar framework in Figure 2. In
general, we first collect numerous real and synthesized fake voices
with good diversity in languages, accents, genders, and synthetic
techniques. Real voices are collected from public datasets and available free videos from the internet, which are spoken by humans
in different languages, accents by males or females. In fake voice
collection, we 1) use TTS techniques to synthesize new voices with
merely given texts, and 2) utilize VC techniques to produce a clip of
fake voices having similar timbre to real voices. Then, we adopt a
DNN-based SR system to capture the layer-wise neuron behaviors
for both real and fake voices and determine the activated neurons
with designed neuron coverage criteria. Finally, the captured neuron
behaviors are formed as input feature vectors for training a simple
supervised binary-classifier based on shallow neural networks to
predict whether a clip of voice is a human speech or synthesized.
Layer-wise Neuron Behaviors
Layer and neuron are the basic components in a DNN model. Each
layer in a DNN has its own distinct role in learning the input
representations . A neuron x is the basic unit for representing
the inputs in each layer, whose output is calculated by the activation
function φ, previous layer neurons X
′, weights matrix W , and bias
b, i.e., φ(W · X
Neurons can be classified as activated neurons and inactivated
neurons on a given input, according to recent studies in DNN
testing . Here, an activated neuron means that its output value
is large than a predefined threshold δ, and vice versa. According
to recent studies, activated neurons could carry more information
than inactivate neurons and have a large influence on its following
consecutive layers . Thus, we monitor the activated
neurons to discern the differences among inputs.
In monitoring the layer-wise neuron behaviors, we need to address the following three issues, 1) which DNN-based model is
more suitable for monitoring neuron behaviors? 2) which layers
in the model are elected to monitor neuron behaviors? 3) how to
determine the threshold δ using neuron coverage criteria?
Model selection. In this paper, we monitor the layer-wise neuron behaviors of a third-party DNN-based SR system. Speaker recognition systems aim at determining the identity of speakers by learning the acoustic features mostly with DNN-based models. In this
work, we exploit the DNN-based SR system to serve as a third-party
model for capturing the layer-wise neuron behaviors by leveraging
its power in representing speech in a layer-wise manner.
Layer selection. We select the layers that learn and preserve
valuable representation information of inputs, such as convolutional
and fully-connected layers in typical convolutional neural networks
(CNNs). Here, other layers like pooling without learning substantial
representation information can be seen as redundant layers. It might
be interesting to explore layers that specifically learn the differences
between real and fake voices in future work.
Neuron coverage criteria. We introduce two different neuron
coverage criteria to figure out the threshold δ for determining the
activated neurons. Then, the determined activated neurons in each
selected layer are applied to represent the layer-wise behaviors of
voices. Previous work uses a global threshold to determine if the
neuron is activated or not, which is too coarse . Here, we specify
each layer with a particular threshold. More details on calculating
the threshold δ are presented in the following subsection.
Neuron Coverage Criteria Design
In this paper, we introduce two different neuron coverage criteria
for determining the activated neurons to capture layer-wise neuron
behaviors. The first one counts the number of activated neurons
in each layer, called average count neuron (ACN). The other one
selects neurons having top k values in each layer, named Top-k
activated neuron (TKAN).
(b) Raw Neurons
(c) Activated Neurons
Figure 3: Visualization of three different features in representing real and
fake voices. From the left to right, features are represented by MFCC, raw
layer-wise neuron behaviors, and activated neuron behaviors with designed
neuron coverage criteria, respectively. Here, we select the neuron coverage
criteria TKAN as a presentation example.
ACN. Motivated by the weakness of the global threshold defined
in previous DNN testing studies, we specify each layer l with a
particular threshold δl that is calculated from the training dataset.
The threshold δl is an average value of all the neuron output values
in the layer l of all inputs in the training dataset. We calculate the
threshold δl with the following formula:
x ∈X,i ∈I φ(x,i;θ)
|I | · |X |
where x is the neuron in l-th layer, X is the set of neurons in layer
l, i is an input in the training dataset I, φ is the activation function
for calculating the neuron output value of input i with trained
parameter θ, |X | and |I| represent the number of neurons in layer l
and the number of inputs in training dataset I, respectively. Here,
we define the ACN as follows:
ACN(l,i) = |{x|∀x ∈l,φ(x,i;θ) > δl }|
where i represents the input, x is the neuron in layer l, φ is an
activation function for computing the neuron output value, and δl
is the threshold of the l-th layer calculated by formula (1).
TKAN. Instead of learning a threshold from training datasets to
determine whether a neuron is activated or not, we explore another
neuron coverage criterion by simply selecting neurons whose output value is ranked as top k in its layer. Here, we conjecture that
neurons with large output value are critical neurons that have high
influences in representing inputs for a DNN model. We define the
TKAN as follows:
TKAN(l,i) = {arg max
(φ(x,i;θ),k) : x ∈X }
where the function arg max returns k neuron output values calculated with φ. Here, the k is applied for all the layers in the model.
Figure 3 adopts t-distributed stochastic neighbor embedding
(T-SNE), an algorithm for high-dimensional data visualization, to
visualize the effectiveness of neuron behaviors in hunting the differences between real and fake voices compared with Mel-scale
frequency cepstral coefficients (MFCC), a popular feature in speech
analysis. From L-R, voices are represented with MFCC, raw layerwise neuron behaviors, and activated neurons with designed neuron
coverage criteria, respectively. We can easily find that compared
with MFCC, raw layer-wise neurons can capture the differences
between real and fake in a coarse manners, where the voices are
separated into several relatively independent clusters. Furthermore,
the subtle differences between real and fake voices can be easily
distinguished by applying our designed neuron coverage criteria,
where real and fake are separated into two independent clusters.
Fake Voice Detection
We train a binary-classifier with a shallow neural network to predict whether a clip of voice is human speech or AI-synthesized
fake voice. The inputs of our binary-classifier are the vectorized
captured layer-wise neuron behaviors rather than the raw input
of voices, which are better for a simple classifier to learn the differences between real and fake voices. Additionally, the neuron
behavior inputs are insensitive to manipulations on voices, thus
are robust against various manipulations, such as voice conversion
and additive real-world noises.
Algorithm 1 describes our basic ideas of capturing layer-wise
neurons behaviors for discerning real and fake voices. We train two
supervised binary-classifiers with the same architecture based on
the two different strategies, namely ACN and TKAN. In predicting
an input, we first obtain the layer-wise neuron behaviors with ACN
and TKAN, respectively. Then, the neuron behaviors are formed as
input features into the binary-classifier for prediction. For ACN, the
number of activated neurons in each layer is formed as a feature
vector. For TKAN, the raw value of neuron output, which ranked the
top k in its layer is formed as a feature vector. Finally, the classifier
predicts the voice based on the classifier’s final output score.
EXPERIMENTAL SETTING AND
IMPLEMENTATION
In our experiments, fake voices are collected from three different
datasets including TTS and VC synthesized with various techniques.
To ensure its diversity in languages and genders, English and Mandarin Chinese languages are spoken by males and females containing different accents. The first dataset is a public dataset, called FoR,
created by APTLY lab with the latest open-sourced tools and
commercial speech synthesis products (e.g., Amazon AWS Polly,
Google Cloud TTS, and Microsoft Azure TTS). The real voices in
FoR are collected from open-sourced speech datasets and free available videos on internet like TED talks and YouTube videos, which
cover a good variety of genders, speaker ages, and accents, etc. All
the fake voices are synthesized with latest deep learning-based
techniques, which own high qualities. However, the dataset FoR
only contains the first type TTS fake voices that are synthesized by
given texts.
Therefore, we build the second dataset, a VC fake voice dataset.
The dataset is built by ourselves with an open-sourced tool sprocket
 , which allows to clone the source speaker’s identity into the
target speaker. Sprocket also served as a baseline system in voice
conversion challenge 2018 (VCC18) . Here, real voices are collected from voice conversion challenge 2016 (VCC16) and
VCC18. The second dataset is called Sprocket-VC.
However, fake voices in the first and second datasets are all
spoken in English language, thus we build the third dataset, where
fake voices are all spoken in Mandarin Chinese for evaluating
the capabilities of our approach in tackling different languages.
We adopt the Baidu speech synthesis system that achieves the
best performance in Chinese language synthesis. We give a series
Table 1: Statistics of the three datasets for evaluating the effectiveness and
robustness of DeepSonar. Column Language indicates the language spoken
in the voice samples. Column Real Voice Collection means the sources of real
voices collected in the dataset. All the real and fake voices in FoR are collected
from the second version for-norm in the original dataset where three different
versions are included. Column Model represents the number of techniques for
synthesizing voices. Last two columns Real(#) and Fake(#) denote the number
of real and fake voices in each dataset.
Real Voice Collection
multi-sources
lecture_tts 
Sprocket-VC
VCC16&VCC18
Algorithm 1: Algorithm for discerning fake voices with
two diﬀerent layer-wise neuron behaviors.
:Training and testing dataset of fake and real voices I and
D, DNN-based SR model e
푀, top value 푘
Output:Label 푓푙푎푔
⊲Select layers from e
푀to monitor neuron behaviors.
2 퐿←퐿푎푦푒푟푆푒푙푒푐푡푖표푛( e
⊲Capture layer-wise neuron behaviors with ACN.
4 푋푙is a set of neurons in layer 푙of e
5 V푙counts activated neurons in layer 푙of e
6 for 푖∈I do
푆푙= Í휑(푋푙,푖;휃)
9 for 푙∈퐿,푖∈퐼,푥∈푋do
if 휑(푥,푖;휃) > 훿푙then
⊲Capture layer-wise neuron behaviors with TKAN.
13 푁푙saves activated neuron output value in layer 푙of e
14 for 푖∈I do
푁푙= arg max푘(휑(푋푙,푖;휃),푘)
⊲Train two independent binary-classiﬁers e
퐶푡푘푎푛for ACN
and TKAN with input vector 푉and 푁to discern fake voices.
퐶푎푐푛←퐶푙푎푠푠푖푓푖푒푟푇푟푎푖푛푖푛푔(푉)
퐶푡푘푎푛←퐶푙푎푠푠푖푓푖푒푟푇푟푎푖푛푖푛푔(푁)
⊲Predict whether a clip of voice in D is real or fake.
21 for 푑∈D do
푓푙푎푔←argmax e
퐶푎푐푛(푑), e
23 return 푓푙푎푔
L e n g t h ( s e c o n d s )
R E A L : F o R
F A K E : F o R
R E A L : M
F A K E : M
R E A L : S p r o c k e t - V C
F A K E : S p r o c k e t - V C
Figure 4: Real and fake voices
length distribution in the three
datasets. Y-axis indicates the ratio
of voices that lies in the length
range with an offset ±1.
of ancient poetry as input texts to produce numerous fake
voices. The third dataset is called MC-TTS. More details of the
three datasets are summarized in Table 1. We also present the
length distribution of voices in the three datasets in Figure 4.
In evaluation, we mainly compared our work with a prior work
leveraging bispectral artifacts on fake voices to differentiate human
speech and AI-synthesized fake voices . To the best of our knowledge, this is a SOTA work focused on AI-synthesized fake voice
detection. We implemented this work with open-sourced available
Table 2: Voice conversions and additive real-world noises in manipulation attacks. Voice conversion includes three common transformations when publishing audios. Additive real-world noises are classified into indoor and outdoor environmental sounds. The selected 12 real-world noises from ESC-50
are representative environmental sounds in real scenarios.
Manipulation Attacks
Sound Classes
Voice Conversions
1) resampling, 2) speed, 3) pitch
Real-world Noises
1) breathing, 2) footsteps, 3) laughing
4) mouse-click, 5) keyboard-type, 6) clock-tick
1) engine, 2) train, 3) fireworks
4) rain, 5) wind, 6) thunderstorm
repositories in GitHub . The details of the baseline are introduced
in Section 5.1.
Evaluation Metrics
For a comprehensive evaluation of DeepSonar, we adopt seven different metrics to evaluate the capabilities of DeepSonar in fighting
against TTS and VC in the three datasets.
Specifically, we use accuracy, AUC (area under curve) of ROC
(receiver operating characteristics), F1-score, and AP (average precision) to evaluate whether DeepSonar achieves a higher detection
rate. We use FPR (false positive rate), FNR (false negative rate), and
EER (equal error rate) to get the false alarm rate of DeepSonar in
prediction. These seven metrics are widely served as metrics in
evaluating the performance of classifiers.
Implementation
We design a shallow neural network with five fully-connected layers
as our binary-classifier for discerning fakes. The optimizer is SGD
with momentum 0.9 and the starting learning rate is 0.0001, with a
decay of 1e-6. The loss function is binary cross-entropy.
In monitoring neuron behaviors, we employ a speaker recognition deep network that adopts a ‘thin-ResNet’ as its backend
architecture and select the convolutional and fully-connected
layers to capture the layer-wise neuron behaviors as input features. Our approach is generic to any speech representation system,
which could be easily extended to other systems that have the capability to learn speech representations layer-by-layer. For TKAN,
we empirically set k to 5 with a consideration of the number of
selected layers and training samples. In evaluating the robustness
of DeepSonar against manipulation attacks, we select more than
15 different manipulations to achieve a comprehensive evaluation.
We hope that these 15 different representative voice manipulations
could also serve as a robustness evaluation benchmark for future
research. Table 2 shows the 15 different manipulations, which are
classified as voice conversions by changing voice signals and realworld noises by adding environmental noises. The real-world noise
samples are collected from a public dataset ESC-50 that includes
lots of environmental audio recordings .
EXPERIMENTAL RESULTS
Our evaluation aims to answer the following research questions.
• RQ1: What is the performance of DeepSonar in discerning two
types of fake voices (TTS and VC) synthesized with various
techniques and tackling different languages?
• RQ2: Whether DeepSonar is robust against voice manipulation attacks including voice conversions and additive real-world
noises at various magnitudes?
Detection Results (RQ1)
In this section, we mainly answer the first research question, i.e.,
whether our approach DeepSonar can effectively discern real and
fake voices and tackle different languages. Our experiments are
conducted on the three different datasets (see Table 1). Each dataset
is splitted into three parts, e.g., 60%, 20%, 20% as training, validation and testing, respectively. Specifically, we also compared our
work with previous work using bispectral artifacts (served as a
baseline) and report the detection rate and false alarm rate using
seven different metrics.
Effectiveness of DeepSonar. Table 3 summarizes the experimental results of DeepSonar using two different neuron coverage
criteria for determining activated neurons. DeepSonar gives an
average accuracy >98.1% and an EER <2% on the three datasets and
demonstrates the effectiveness in discerning the two typical fake
voices in both English and Chinese languages. In the first dataset
FoR where voices are synthesized with commercial products and
more challenging than the other two datasets, DeepSonar obtains
an accuracy >99% when employing TKAN, but it reaches an accuracy <90% when adopting ACN. This result illustrates that using
TKAN can be more powerful than ACN in tackling voices synthesized with various commercial-level synthetic techniques. Thus, we
mainly compare our approach using TKAN with the baseline.
Compared with baseline. Table 4 summarizes the results compared with the baseline. Both the baseline and our proposed Deep-
Sonar are trained and tested on the same datasets. Experimental results show that the average performance of DeepSonar using TKAN
significantly outperforms the baseline on the three datasets. The
baseline is a SOTA work using bispectral artifacts in fake voices to
differentiate real and fake voices . They found that higher-order
spectral correlations rarely exist in real human speech while they
are common in AI-synthesized fake voices. In their experiments,
a simple classifier with SVM is adopted to identify the bispectral
artifacts for differentiating real and fake voices. Different from this
work investigating the artifacts introduced in synthesis, we leverage the power of layer-wise neuron behaviors for representing
inputs, which provides cleaner signals than raw voice inputs (e.g.,
bispectral artifacts in voices) for simple binary-classifier in hunting
the differences between real and fake voices.
According to the experimental results in Table 3 and Table 4,
detecting clean AI-synthesized fake voices without any degradation is a relatively easy task by DeepSonar. Unfortunately, voice
manipulations like voices resampling, adding real-world noises are
common in real applications, thus evading manipulation attacks is
important for detectors deployed in the wild. In the next subsection, we mainly discuss the robustness of our approach in tackling
manipulation attacks at various magnitudes.
Evaluation on Robustness (RQ2)
The biggest difference between AI-synthesized fake images and
fake voices lies in that manipulations like voice conversion and
additive real-world noises can be easily camouflaged as regular operations. In this section, we evaluate the robustness of DeepSonar in
tackling voice conversion and additive real-world noises at various
magnitudes to investigate the second research question.
Table 3: Performance of DeepSonar using two different neuron behaviors (e.g.,
ACN and TKAN) in discerning real and fake voices. The last row DeepSonar
represents an average results on the three datasets. ↑means the larger value
the better, while ↓indicates the smaller value the better.
Sprocket-VC
Table 4: Performance of DeepSonar and the baseline using bispectral artifacts
based from Farid et al. , on three datasets in discerning AI-synthesized fake
voices. DeepSonar utilizes TKAN to monitor neuron behaviors. Average result
denotes an average performance of the three approaches on the three different datasets measured by seven metrics. ↑means the larger value the better,
while ↓indicates the smaller value the better.
Farid et al. 
Farid et al. 
Farid et al. 
Farid et al. 
Sample number
Voice Conversions
Resampling
Sample number
Additive Real-world Noises
Figure 5: Signals of voices manipulated by voice conversion and additive realworld noises. In voice conversions, voice upsampling by adding 400, speed ratio set to 0.8 times, pitch-shifted by 4 steps. In additive real-world noises, we
present voice signals by adding four real-world noises including indoors (footsteps) and outdoors (fireworks, train, wind, thunderstorm) noises (SNR=35).
The original clip of synthesized fake voice is from the FoR dataset saying "Do
you feel like eating something".
Experimental settings. In experiments, we select 1, 000 samples including 500 real and 500 fake voices from the testing dataset
in FoR since they are synthesized with commercial products and
more challenging for detection. We also employ TKAN for Deep-
Sonar and compare it with the baseline like in effectiveness evaluation experiment. AUC is adopted for evaluation metrics as it
is often used in the binary-classifier performance evaluation. Additionally, we use signal to noise ratio (SNR) as metrics to evaluate the magnitude of real-world noises. The SNR is defined as
SNR = 20 log
, where log(·) is the logarithm of base 10
and RMS is the root mean square.
By adding noises to voice data, we first need to obtain the RMS
of the noises and voices, respectively. Then, we modify the noise
by multiplying each element with a constant to change the RMS,
thus the desired SNR is achieved. In voice conversion, various voice
manipulations are implemented with the APIs provided by libsora
 . Figure 5 presents a spectral centroid visualization of the two
manipulation attacks, the left is voice conversion and the right is
additive real-world noises. The two manipulations all have obvious
modifications to the signals, which poses challenges to detectors.
Results on voice conversions. Figure 6(a) shows the experimental results of DeepSonar in tackling three typical voice conversions. We could observe that DeepSonar is robust against resampling including upsampling and downsampling without any
performance affected. The average performance is decreased less
than 5% and 15% in stretching the voices and shifting pitches, respectively. Compared to the other two conversions (resampling and
speed), DeepSonar seems to be a little susceptible to pitch shifting.
The main reason is that voices with pitch-shifting have been broken
and can hardly listen to the words in voices when the n_steps for
changing the pitch of voices is larger than 2. The settings for the
three voice conversions are presented as follows.
In voice conversion, resampling indicates a time series of voice
that is resampled from the original sample rate to the target sample
rate, including upsampling and downsampling. Here, the target
sample rate is set with an offset (e.g., −400, 200, 0, 200, 400) to the
original sample rate, where offset 0 servers as a baseline without
resampling. Speed represents time-stretch an audio series by a fixed
rate. The fixed-rate is set to 0.5, 0.8, 1.0, 1.2, 1.4, where 1.0 serves as
a baseline. Pitch means we shift the pitch of a waveform by n_steps
semitones. Here, the n_step is set to −4, −2, 0, 2, 4, where n_step 0
serves as a baseline that no pitch is shifted.
Results on indoor-noises. In additive real-world noises, voices
are added with representative indoors and outdoors environmental
noises. We use SNR to measure the magnitudes of added-noises.
In Figure 6(b), DeepSonar performs well on the five indoor noises
and the average performance decreased less than 10% at the total
five different magnitudes. However, the average performance is
decreased by nearly 20% at the five magnitudes when adding footstep noises. We listened to the added-footstep voices which have
obviously mixed sizzle noises caused by the friction with floors.
Figure 5 also visualizes the differences between original voices and
added-footsteps voices.
Results on outdoor-noises. In Figure 6(c), outdoor environmental noises can be roughly classified into three different categories based on the performance of DeepSonar. Engine and thunderstorm environmental noises are the first categories, where the
average performance of DeepSonar decreased less than 7% at the
five different magnitudes. Fireworks and trains are the second categories, where the average performance of DeepSonar decreased
less than 18% at the five different magnitudes. Wind and rain are
the third categories, where the average performance of DeepSonar
decreased by nearly 25% at the five different magnitudes. We find
that environmental noises wind and rain also mixed with other
voices like raindrops on the ground which is much noisy than other
types of real-world environmental noises.
According to the experimental results in Figure 6, DeepSonar is
also robust against voice conversions except voices are seriously
damaged like shifting pitch with a big step. Additionally, Deep-
Sonar performs well when the additive real-world noises are single
voice without any mixture with other types of noises. In tackling
mixed noises like wind, DeepSonar also holds a high detection
performance at the magnitude measured by SNR larger than 35.
p l i n g , S p e e d , P i t c h
D e e p S o n a r
(a) Voice Conversions
a g n i t u d e ( S N R )
b r e a t h i n g
f o o t s t e p s
l a u g h i n g
o u t h - c l i c k
k e y b o a r d - t y p e
c l o c k - t i c k
D e e p S o n a r
(b) Additive Real-world Noises (Indoors)
a g n i t u d e ( S N R )
e n g i n e
t h u n d e r s t o r m
f i r e w o r k s
D e e p S o n a r
(c) Additive Real-world Noises (Outdoors)
Figure 6: Robustness evaluation of DeepSonar against manipulation attacks at various magnitudes. In voice conversions (a), values in x-axis for resampling are
{-400, -200, 0, 200, 400}, for speed are {0.5, 0.8, 1.0, 1.2, 1.4}, for pitch are {-4, -2, 0, 2, 4}. The dotted lines in the three subfigures represent an average performance of
our approach DeepSonar and the baseline over different voice manipulations at various magnitudes. Large SNR means less noises added.
Compared with baseline. The dotted lines in the three subfigures of Figure 6 show the comparison results with the baseline by
using bispectral artifacts to discern fake voices. To compare the
performance of robustness with baseline, we use the average results
of the two approaches over different types of voice manipulations
at various magnitudes. For example, in Figure 6(b), each point in
the dotted line is an average AUC score of the six additive indoor
noises at the same magnitude. In Figure 6, the dotted line of Deep-
Sonar is above the baseline, indicating that DeepSonar significantly
outperforms the baseline in the two manipulation attacks.
Discussion
DeepSonar achieves competitive results in terms of both effectiveness, and robustness against two manipulation attacks. However,
DeepSonar also exhibits some limitations. First, in adversarial environments, adversaries could add an additional loss function by
modeling the neuron behaviors to generate adversarial voices and
evade detection. However, most learning-based approaches suffer this adversarial noise attack and an obvious trade-off between
generating adversarial voices and evading detection exists. Secondly, real-world noises with a mixture of other types of noises at
a high magnitude could decrease the performance of DeepSonar to
some extent. Voice denoising will be a potential strategy for highintensity mixed noises, which would be our future work to remove
additional environmental noises. Especially, the voice denoising
component is effective without obtaining any prior knowledge of
the noises in the complex environments.
CONCLUSIONS
In this paper, we proposed DeepSonar that discerns AI-synthesized
fake voices by monitoring the learnt neuron behaviors from voice
synthesis system. Overall, our work presents a new insight for detecting AI aided multimedia fakes by monitoring neuron behaviors,
which aims to build an effective and robust detector. Experiments on
the three datasets demonstrate its effectiveness and robustness, with
potential in the real-world noisy environment. In fighting against
AI-synthesized voices in the wild, robustness should be considered
as a priority in designing a detector, since various manipulations
on voices can be easily camouflaged as regular operations, while
manipulation on images is limited and easy to be spotted. Furthermore, the inconsistency of audio and visual in video DeepFakes is
an important clue for DeepFake forensics, thus how to combine
recent advances in fake still image and fake voice detection to spot
the inconsistency is an important topic for future research. Our neuron behaviors based technique may be a promising idea. Producing
and fighting fakes in the AI era is like a mouse and cat game. More
powerful techniques should be continuously developed for fighting
AI aided fakes as new techniques for producing various fakes will
emerge inadvertently. Our future work would continuously investigate how the proposed DeepSonar method can be extended to or
work in tandem with various detectors on other
modalities of the ‘fakes’ such as AI-generated / forged images, and
DeepFake videos, etc.
ACKNOWLEDGMENTS
This research was supported in part by Singapore National Cybersecurity R&D Program No. NRF2018NCR-NCR005-0001, National Satellite of Excellence in Trustworthy Software System No.
NRF2018NCR-NSOE003-0001, NRF Investigatorship No. NRFI06-
2020-0022. It was also supported by JSPS KAKENHI Grant No.
20H04168, 19K24348, 19H04086, and JST-Mirai Program Grant No.
JPMJMI18BB, Japan. We gratefully acknowledge the support of
NVIDIA AI Tech Center (NVAITC) to our research.