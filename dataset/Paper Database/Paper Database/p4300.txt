Multi-Context Attention for Human Pose Estimation
Xiao Chu1 ∗
Wei Yang1 ∗
Wanli Ouyang1
Alan L. Yuille3
Xiaogang Wang1
1 The Chinese University of Hong Kong, Hong Kong SAR, China
2 Tsinghua University, Beijing, China
3 Johns Hopkins University, Baltimore, USA
1{xchu, wyang, wlouyang, xgwang}@ee.cuhk.edu.hk
 
3 
In this paper, we propose to incorporate convolutional
neural networks with a multi-context attention mechanism
into an end-to-end framework for human pose estimation.
We adopt stacked hourglass networks to generate attention maps from features at multiple resolutions with various semantics. The Conditional Random Field (CRF) is
utilized to model the correlations among neighboring regions in the attention map. We further combine the holistic
attention model, which focuses on the global consistency
of the full human body, and the body part attention model,
which focuses on the detailed description for different body
parts. Hence our model has the ability to focus on different
granularity from local salient regions to global semanticconsistent spaces. Additionally, we design novel Hourglass
Residual Units (HRUs) to increase the receptive ﬁeld of the
network. These units are extensions of residual units with
a side branch incorporating ﬁlters with larger receptive
ﬁelds, hence features with various scales are learned and
combined within the HRUs. The effectiveness of the proposed multi-context attention mechanism and the hourglass
residual units is evaluated on two widely used human pose
estimation benchmarks. Our approach outperforms all existing methods on both benchmarks over all the body parts.
1. Introduction
Human pose estimation is a challenging task in computer vision due to the articulation of body limbs, self occlusion, various clothing, and foreshortening. Signiﬁcant
improvements have been achieved by Convolutional Neural Networks (ConvNets) . However,
for cluttered background with objects which are similar to
body parts or limbs, or body parts with heavy occlusion,
ConvNets may have difﬁculty to locate each body parts cor-
∗The ﬁrst two authors contribute equally to this work.
Estimation
Figure 1. Motivation. The 1st row shows the input image, the
holistic attention maps, and the part attention maps. The 2nd row
shows the predicted heatmaps for part locations, where different
colors correspond to different body parts. The 3rd row visualizes the predicted poses. We observe that (a) ConvNets may produce erroneous estimations due to cluttered background and selfocclusion. (b) Visual attention provides an explicit way to model
spatial relationships among human body parts, which is more robust. (c) Part attention maps can help further reﬁne the part locations by addressing the double counting problem.
rectly, as demonstrated in Fig. 1 (a). In the literature, the
combination of multiple contextual information has been
proved essential for vision tasks such as image classiﬁcation , object detection and human pose
estimation . Intuitively, larger context region captures global spatial conﬁgurations of object, while smaller
context region focuses on the local part appearance. However, previous works usually use manually designed multicontext representations, e.g., multiple bounding boxes 
or multiple image crops , and hence lack of ﬂexibility and diversity for modeling the multi-context representations.
 
Visual attention is an essential mechanism of the human
brain for understanding scenes effectively. In this work, we
propose to generate contextual representations with an attention scheme. Instead of deﬁning regions of interest manually by a set of rectangle bounding boxes, the attention
maps are generated by an attention model, which depends
on image features, and provide a principled way to focus on
target regions with variable shapes. For example, an attention map focusing on the human body is shown in Fig. 1 (b).
It helps recover the missing body parts (e.g., legs), and distinguishes the ambiguous background. This allows the diversity of context to be increased, and so contextual region
could be better adapted to each image. Furthermore, instead
of adopting the spatial Softmax normalization widely used
in conventional attention schemes, we design a novel attention model based on Conditional Random Fields, which is
better in modeling the spatial correlations among neighboring regions.
The combination of multiple contextual information has
been proved effective for various vision tasks . To use the attention mechanism to guide multicontextual representation learning, we adopt the stacked
hourglass network structure , which provides an ideal
architecture to build a multi-context attention model.
each hourglass stack, features are pooled down to a very
low resolution, then are upsampled and combined with
high-resolution features. This structure is repeated for several times to gradually capture more global representations. Within each hourglass stack, we ﬁrst generate multiresolution attention maps from features of different resolutions. Secondly, we generate attention maps for multiple
hourglass stacks, which results in multi-semantics attention
maps with various levels of semantic meaning. Since these
attention maps capture the conﬁguration of the full human
body, they are referred to as holistic attention models.
While the holistic attention model is robust to occlusions
and cluttered background, it lacks of precise description for
different body parts. To overcome this limitation, we design
a hierarchical visual attention scheme, which zooms in from
holistic attention model to each body part, namely the part
attention model. This is helpful for precise localization of
the body parts, as shown in Fig. 1 (c).
Additionally, we introduce a novel “Hourglass Residual
Units” as a replacement for the residual unit in our network. It incorporates the expressive power of multi-scale
features while preserving the beneﬁt of residual learning. It
also enables deep networks to have a faster growth of receptive ﬁeld, which is essential for accurately locating body
parts. When using these units within the “macro” hourglass
network, we obtain a nested hourglass architecture.
We show the effectiveness of the proposed end-to-end
differentiable framework on two broadly used human pose
estimation benchmarks, i.e., MPII Human Pose dataset 
and the Leeds Sports Dataset . Our approach outperforms all the previous methods on both benchmarks for all
the body parts. The main contributions of this work are
three folds:
• We propose to use visual attention mechanism to automatically learn and infer the contextual representations,
driving the model to focus on region of interest. Instead
of applying spatial Softmax normalization as in conventional attention models, we tailor the attention scheme for
human pose estimation by introducing CRFs to model
the spatial correlations among neighborhood joints. To
the best of our knowledge, this is the ﬁrst attempt to utilize attention scheme for human pose estimation.
• We use multi-context attention to make the model more
robust and more accurate. Speciﬁcally, three types of
attentions are designed, i.e., multi-resolution attention
within each hourglass, multi-semantics attention across
several stacks of hourglass, and a hierarchical visual attention scheme to zoom in on local regions to see clearer.
• We propose a generic hourglass residual unit (HRU), and
build the nested hourglass networks together with the
stacked hourglass architecture. The HRUs incorporate
features from different scales in the conventional residual
unit. They also enable the network to see larger context
in an earlier stage.
2. Related Work
Human Pose Estimation Articulated human poses were
usually modeled by combination of unary term and graph
models, e.g., mixture of body parts or pictorial
structures . Recently, signiﬁcant progresses have been
achieved by introducing ConvNets for learning better feature representation .
For example, Chen and Yuille introduced the ConvNet
to learn both the unary and the pairwise term of a treestructured graphical model. Tompson et al. used multiple branches of ConvNets to fuse the features from an
image pyramid, and used a Markov Random Field (MRF)
for post-processing. Convolutional Pose Machine incorporated the inference of the spatial correlations among
body parts within the ConvNets.
State-of-the-art performance is achieved by the stacked hourglass network 
and its variant , which use repeated pooling down and
upsampling process to learn the spatial distribution. Our
approach is complementary to previous approaches by incorporating diverse image dependent multi-context representation to guide the human pose estimation.
Multiple Contextual Information The contextual information is generally referred to as regions surrounding
the target locations , object-scene relationships , and object-object interactions . It
has been proved efﬁcient in vision tasks as object classiﬁcation and detection . Recent works mod-
Convolution
Upsampling
Attention Map
Attention Feature
Prediction
Basic Hourglass
Multi-Semantic Attention
Part Attention
Figure 2. Framework. The basic structure is an 8-stack hourglass network. In each stack of hourglass, we generate multi-resolution
attention maps. We also apply multi-semantic attention map to each hourglass as shown in stack 1 to stack 8. Hierarchical Attention
Mechanism for zooming in on local parts is applied in stack 5 to stack 8.
eled contextual information by concatenating multi-scale
features , or by gated functions to control the mutual
inﬂuence of different contexts . The contextual regions,
however, are manually deﬁned as rectangles without considering the objects appearance. In this work, we adopt visual
attention mechanism to focus on regions which are image
dependent and adaptiving for multi-context modeling. Our
approach increases the diversity of contexts.
Visual Attention Mechanism Since the visual attention
model is computationally efﬁcient and is effective in understanding images, it has achieved great success in various tasks such as machine translation , object recognition , image captioning , image question answering , and saliency detection . Existing
approaches usually adopt recurrent neural networks to generate the attention map for an image region at each step, and
combine information from different steps overtime to make
the ﬁnal decision . To the best of our knowledge,
our work is the ﬁrst to investigate the use of attention models for human pose estimation. In addition, our design of the
holistic attention map and the part attention map in learning
attention in hierarchical order and the modeling of attention
from different context and resolution are not investigated in
these works.
3. Framework
An overview of our framework is illustrated in Fig. 2. In
this section, we brieﬂy introduce the nested hourglass architecture, and the implementation of the multi-context attention model, including the multi-semantics, multi-resolution,
and hierarchical holistic-part attention model. The generated attention maps are then used to reweight the features
for automatically infer the regions of interest.
Baseline Network We adopt an 8-stack hourglass network as the baseline network. It allows for repeated
bottom-up, top-down inference across scales with intermediate supervision at the end of each stack. In experiments,
the input images are 256 × 256, and the output heatmaps
are P × 64 × 64, where K is the number of body parts. We
follow previous work to use the Mean Squared
Error as the loss function.
Nested Hourglass Networks We replace the residual units,
which are along the side branches for combining features
across multiple resolutions, by the proposed micro hourglass residual units (HRUs), and obtain a nested hourglass
network , as illustrated in Fig. 3. With this architecture, we
enrich the information received by the output of each building block, which makes the whole framework more robust
to scale change. Details of HRUs are described in Section 4.
Multi-Resolution Attention Within each hourglass, the
multi-resolution attention maps Φr are generated from features of different scales, where r is the size of the features,
as shown in Fig. 5. Attention maps are then combined to
generate the reﬁned features, which are further used to generate reﬁned attention maps and further reﬁned features, as
shown in Fig. 4.
Multi-Semantics Attention Different stacks are with different semantics: lower stacks focus on local appearance,
while higher stacks encode global representations. Hence
attention maps generated from different stacks also encode
various semantic meanings. As shown in Fig. 2, compare
the left knee in Stack 1 with 8, we can see that deeper stacks
with global representations are able to recover occlusions.
Hierarchical Attention Mechanism In the lower stacks,
i.e., stack 1 to stack 4, we use two holistic attention maps
1 and hatt
2 to encode conﬁgurations of the whole human
body. In the higher stacks, i.e., the 5th to the 8th stack,
we design a hierarchical coarse-to-ﬁne attention scheme to
zoom into local parts.
4. Nested Hourglass Networks
In this section, we provide a detailed description of the
proposed hourglass residual units (HRUs). We also provide
comprehensive analysis of the receptive ﬁeld.
4.1. Hourglass Residual Units
Let us ﬁrst brieﬂy recall Residual networks . Deep
residual networks achieves compelling accuracy by an extremely deep stacks of “Residual Units”, which can be expressed as follows,
xn+1 = h(xn) + F(xn, WF
where xn and xn+1 are the input and output of the n-th
unit, and F is the stacked convolution, batch normalization,
and ReLU nonlinearity. In , h(xn) = xn is the identity
In this paper, we focus on human pose estimation, which
larger contextual regions are proved to be important for locating local body parts .
The contextual region
of a neuron is its corresponding receptive ﬁeld.
work, we propose to extend the original residual units by
a micro hourglass branch. The resulted hourglass residual
units (HRUs) have larger receptive ﬁeld while preserve local details, as shown in Fig. 3. We use this module in the
stacked hourglass networks. This architecture is referred to
as “nested hourglass networks” because the hourglass structure is used at both the macro and micro levels.
The mathematical formulation of our proposed HRUs is
as follows:
xn+1 = xn + F(xn, WF
n ) + P(xn, WP
Each HRU consists of three branches. Branch (A), i.e. xn in
(2), is the identity mapping. Hence, the property of ResNet
in handling vanishing gradient is preserved in the HRUs.
Branch (B), i.e. F(xn, WF
n ) in (2), is the residual block
like the ResNet in (1). Branch (C), i.e. P(xn, WP
n ) in (2),
is our new design, which is a stack of a 2 × 2 max-pooling,
two 3×3 convolutions followed by ReLU nonlinearity, and
an upsampling operation.
4.2. Analysis of Receptive Field of HRU
The identity mapping in branch (A) has receptive size of
one. The residual block in branch (B) is a stack of convolutions (Conv1×1 + Conv3×3 + Conv1×1). Hence, the neuron
in the output feature corresponds to a 3 × 3 region of the
input in this HRU. Branch (C) is our added branch. The
structure of this branch is Pool2×2 +Conv3×3 +Conv3×3 +
Deconv2×2. Due to max-pooling, the resolution for convolution in this branch is half of that in branches (A) and (B),
A. Identity mapping branch
C. Hourglass residual branch
B. Residual branch
Figure 3. An illustration of the hourglass residual unit. It consists
of three branches: (A) identity mapping, (B) residual branch, and
(C) hourglass residual branch. The receptive ﬁeld with respect to
the input is 3×3 and 10×10 for the conventional residual branch
and the hourglass residual branch, respectively.
and each neuron in the output feature map corresponds to a
10 × 10 region of the input, which is about 3 times the receptive ﬁeld size of the residual block in branch (B). These
three branches, with different receptive ﬁelds and resolutions, are added together as the output of the HRU. Therefore, the HRU unit increases the receptive ﬁeld size by including the branch (C) while preserves the high-resolution
information by using branches (A) and (B).
5. Attention Mechanism
We shall ﬁrst brieﬂy introduce the conventional soft attention mechanism, and then describe our proposed multicontext framework.
5.1. Conventional Attention
Denote convolutional features by f. The ﬁrst step in obtaining soft attention is to generate the summarized feature
map as follows:
s = g(Wa ∗f + b),
where ∗denotes convolution, Wa denotes the convolution ﬁlters, and g is the nonlinear activation function. s ∈
RH×W summarizes information of all channels in f.
Denote s(l) as the feature at location l in the feature map
s, where l = (x, y), x is the horizontal location and y is
the vertical location. The Softmax operation is applied to s
spatially as follows:
l′∈L es(l′) ,
where L = {(x, y)|x = 1, . . . , W, y = 1, . . . , H}. Φ is the
attention map, where P
l∈L Φ(l) = 1. Then the attention
map is applied to the feature f,
hatt = Φ ⋆f,
where hatt(c) = f(c) ◦Φ,
where c is the index for feature channel. We use ⋆to represent the channel-wise Hadamard matrix product operation. hatt is the reﬁned feature map, which is the feature
reweighted by the attention map, and has the same size as f.
Figure 4. An illustration of the attention scheme.
5.2. Our Multi-Context Attention Model
Our framework makes the following three modiﬁcations
to the attention model. First, we replace the global Softmax in 4 with a CRF to taking local pattern correlations
into consideration. Global spatial Softmax normalizes the
whole image based on a constant factor, which ignores the
local neighboring spatial correlations. But we want attention maps to drive the network to concentrate on the complex human body conﬁgurations. More details are in Section 5.2.1. Second, we generate attention maps based on
features of different resolutions to make the model more robust, as illustrated in Section 5.2.2. Then multi-semantics
attention is obtained by generating attention maps for each
stack of the hourglass, as described in Section 5.2.3. Finally, a hierarchical coarse to ﬁne(i.e. fully body to parts)
attention scheme is used, to zoom into local part regions for
more precise localization, which is introduced in Section
5.2.4. The whole framework is differentiable and trained
end-to-end with random initialization. An illustration of our
attention scheme is shown in Fig. 4.
Spatial CRF Model
In this work, we use Conditional Random Fields (CRFs)
to model the spatial correlation. To make them differentiable, we use the mean-ﬁeld approximation approach to recursively learn the spatial correlation kernel .
The attention map is modeled as a two-class problem.
Denote yl = {0, 1} as the attention label at the i-th location.
In the CRF model, the energy of a label assignment y =
{yl|l ∈L} is as follows:
where ψ(yl) = g(h, l) is the unary term that measures the
inverse likelihood (and therefore, the cost) of the position
l taking the attention label yl = 1.
wl,k is the weight
for compatibility between yl and yk.
Given the image
I, the probability of the label assignment y is P(y|I) =
Z exp(−E(y|I)), where Z is the partition function. The
probability for yl = 1 is obtained iteratively using the
mean-ﬁeld approximation as follows:
Φ(yl = 1)t = σ
wl,kΦ(yk = 1)t−1
where σ(a) = 1/(1 + exp(−a)) is the sigmoid function.
ψu(l) is obtained by convolution from features h.
Prediction
Attention Feat.
Upsampling
Multi-Resolution Attention
Attention map
Figure 5. The multi-resolution attention scheme within an hourglass. In each stack of hourglass, we generate multi-resolution
attention maps from features with different resolutions (a). These
maps are summed into a single attention map, which applies to
features f to generate the reﬁned feature hatt
k wl,kΦ(yj = 1) is implemented by convolving the estimated attention map Φt−1 at the stage t −1 with the ﬁlters.
Initially, Φ(yi = 1)1 = σ(ψu(i)).
In summary, the attention map Φt at the stage t can be
formulated as follows:
Φt = M(s, Wk) =
σ(Wk ∗Φt−1)
t = 1, 2, 3,
where M denotes a sequence of weights-sharing convolutions for the mean ﬁeld approximation, Wk denotes the
spatial correlation kernel. The Wk is shared across different time steps. In our network, we use three steps of
recursive convolution.
Multi-Resolution Attention
As shown in Fig. 5, the up-sampling process generates features of different size r, i.e. fr for r = 8, 16, 32 and 64. sr
is used to generate the attention map Φr using the procedure in (8). The attention map Φr is up-sampled to size 64,
the up-sampled map is denoted by Φ{r→64}. These attention maps correspond to different resolutions. As shown in
Fig. 5 (I), Φ{8→64}, which has lower resolution, and highlights the whole conﬁgure of human body. Φ64, which is
generated with higher resolution, focusing on local body
All up-sampled attention maps are summed up and then
applied to the feature f,
r=8,16,32,64
where the feature f is the output of the last layer in an hourglass stack as shown in Fig. 5. The operation ⋆is illustrated
in Eq. (5).
The conventional way of using an attention map is to directly apply it to the feature which generates it. However,
L.Shoulder
Figure 6. Coarse-to-ﬁne part attention model and the visualization of examplar part attention maps.
the features reﬁned by attention map usually have large
amount of values close to zero, and so a stack of many
reﬁned features makes the back-propagation difﬁcult. To
utilize information from multi-resolution features without
sacriﬁcing training efﬁciency, we generate attention maps
from features with various resolutions, and apply them to
the later features.
In addition to the multi-resolution attention, a reﬁned attention map Φ′ and its corresponding reﬁned feature hatt
generated from hatt
1 ⋆Φ′ = hatt
Multi-Semantics Attention
The above procedure is repeated over stacks of hourglass to
generate attention maps with multiple semantic meanings.
Samples of Φ′ are shown in Fig. 2 from stack 1 to 8. The
attention maps at shallower hourglass stacks capture more
local information. For deeper hourglass stacks, the global
information about the whole person is captured, which is
more robust to occlusion.
Hierarchical Holistic-Part Attention
In the 4th to 8th stacks of hourglass structure, we use the the
reﬁned feature hatt
1 in Eq. (9) to generate the part attention
maps as follows:
Φp = M(sp, Wk
where p ∈{1, · · · , P}, Wa
p denotes the parameters for obtaining the summarization map sp of part p, Wk
the spatial correlation modeling for part p. The part attention map Φp is combined with the reﬁned feature map hatt
to obtain the reﬁned feature map for part p as follows:
The heatmap predication for the pth body joint is based on
the reﬁned features hatt
ˆyp = wcls
Normalized distance
Detection rate (%)
Normalized distance
Detection rate (%)
Tompson et al. NIPS14
Carreira et al. CVPR16
Tompson et al. CVPR15
Pishchulin et al. CVPR16
Lifshitz et al. ECCV16
Gkioxary et al. ECCV16
Raﬁ et al. BMVC16
Insafutdinov et al ECCV16
Wei et al. CVPR16
Tzimiropoulos ECCV16
Newell et al. ECCV16
Figure 7. Comparisons of PCKh curve on the MPII Human Pose
test set on the most challenging body joints, i.e., wrist and ankle.
where ˆyp is the heatmap for the pth part, wcls
is the classiﬁer. In this way, we guarantee that the attention map Φp
is speciﬁc for the body joint p. Some qualitative results of
part attention maps are shown in Fig. 6.
6. Training the model
Each stack in the hourglass produces the estimated
heatmaps for the body joints. We adopt the loss function
in for learning the model. For each stack, the Mean
Squared Error (MSE) loss is computed by
∥ˆyp(l) −yp(l)∥2
where p denotes the pth body part, l denotes the lth location. ˆyp denotes the predicted heatmap for part p, and yp
the corresponding ground-truth heatmap generated by a 2-D
Gaussian centered on the body part location.
The attention maps help to drive the network to focus on
hard negative samples. After several stages of training, the
attention maps ﬁre on human body region, where the true
positive samples are highlighted by attention maps. The re-
ﬁned features are used for learning classiﬁers for the regions
with human body, with easy background regions removed at
the feature level by the learned attention maps. Consequentially, for part attention maps, the classiﬁers focus on classifying each body joint based on well deﬁned human body
regions, without considering the background.
7. Experiments
Dataset We evaluate the proposed method on two widely
used benchmarks, MPII Human Pose and extended
Leeds Sports Poses (LSP) . The MPII Human Pose
dataset includes about 25k images with 40k annotated
poses. The images were collected from YouTube videos
covering daily human activities with highly articulated human poses. The LSP dataset consists of 11k training images
and 1k testing images from sports activities.
Data Augmentation During training, we crop the images
with the target human centered at the images with roughly
the same scale, and warp the image patch to the size
Head Sho. Elb.
Knee Ank. Mean
Pishchulin et al. 
Tompson et al. 
Carreira et al. 
Tompson et al. 
Hu&Ramanan 
Pishchulin et al. 
Lifshitz et al. 
Gkioxary et al. 
Raﬁet al. 
Insafutdinov et al. 
Wei et al. 
Bulat&Tzimiropoulos 97.9
Newell et al. 
Table 1. Comparisons of score on the MPII test set.
Head Sho. Elb.
Knee Ank. Mean
Belagiannis&Zisserman 95.2
Lifshitz et al. 
Pishchulin et al. 
Insafutdinov et al. 
Wei et al. 
Bulat&Tzimiropoulos 
Table 2. Comparisons of score on the LSP dataset.
256×256. Then we randomly rotate (±30◦) and ﬂip the images. We also perform random rescaling (0.75 to 1.25) and
color jittering to make the model more robust to scale and
illumination change. During testing, we follow the standard
routine to crop image patches with the given rough position and the scale of the test human for MPII dataset. For
the LSP dataset, we simply use the image size as the rough
scale, and the image center as the rough position of the target human to crop the image patches. All the experimental results are produced from the original and ﬂipped image
pyramids with 6 scales.
Experiment Settings We train our model with Torch7 
using the initial learning rate of 2.5 × 10−4. The parameters are optimized by RMSprop algorithm. We train
the model on the MPII dataset for 130 epochs and the LSP
dataset for 60 epochs. We adopt the validation split for the
MPII dataset used in to monitor the training process.
7.1. Results
We use the Percentage Correct Keypoints (PCK) 
metric for comparisons on the LSP dataset, and the PCKh
measure , where the error tolerance is normalized with
respect to head size, for comparisons on the MPII Human
Pose dataset.
MPII Human Pose Table 1 reports the comparison of the
PCKh performance of our method and previous state-ofthe-art at a normalized distance of 0.5. Our method achieves
state of the art 91.5% PCKh scores. In particular, for the
most challenging body parts, e.g., wrist and ankle, our
method achieves 1.0% and 1.4% improvement compared
with the closest competitor respectively, as shown in Fig. 7.
BL+MS+HRU+MR
BL+MS+HRU+MR+HP
Figure 8. Component analysis. PCKh scores at threshold of 0.5
on the MPII validation set.
Leeds Sports Pose We train our model by adding the MPII
training set to the extended LSP training set with personcentric annotations, which is a standard routine . Table 2 reports the PCK at threshold of 0.2. Our approach outperforms the state-of-the-art across all the body
joints, and obtains 1.9% improvement in average.
7.2. Component Analysis
To investigate the efﬁcacy of the proposed multi-context
attention mechanism and the hourglass residual unit, we
conduct ablation experiments on the validation set of
the MPII Human Pose dataset. We use an 8-stack hourglass
network as our baseline model if not speciﬁed. The
overall result is shown in Fig. 8. Based on the baseline network (BL), we analyze each proposed component, i.e., the
Multi-Semantics attention model (MS), Hourglass Residual
Units (HRUs), Multi-Resolution attention model (MR), and
the Hierarchical Part attention model (HP), by comparing
the PCKh score.
Multi-Semantics Attention We ﬁrst evaluate the multisemantics attention model.
By adding holistic attention
model at the end of each stack of hourglass (“BL+MS”),
we get an 87.2% PCKh score, which is a 1.2% improvement compared to the baseline model.
Hourglass Residual Unit To explore the effect of the residual pooling unit, we further use the HRUs to replace the
original residual units when combining features from different resolutions (“BL+MS+HRU”), as illustrated in Fig. 2.
The addition of hourglass residual unit result in a further
1% improvement. As discussed in , improvements cannot be easily obtained by simply stacking more than eight
hourglass modules. We provide a way to increase the model
capacity effectively.
Multi-Resolution
generating
resolution
(“BL+MS+HRU+MR”), our method obtains a further
1% improvements.
Hierarchical Attention We also show the improvement
brought by the hierarchical holistic-local attention model.
We replace the reﬁned holistic attention map by a set of part
attention maps from stack four to eight, and obtain the high-
Figure 9. Qualitative evaluation. (a-b) 1st row to 3rd row: 2 input images, 4 attention maps, 6 heatmaps, and 6 predicted poses. (c)
Examples of estimated poses on the MPII test set and the LSP test set (Best viewed in electronic form with 4× zoom in).
PCKh @ 0.5
Figure 10. on the MPII validation set across training.
est mean PCKh score 89.4%. We observe the improvements
are mostly brought by the reﬁned localization of body parts.
In some cases, the part attention model could even correct
the double counting problem, as demonstrated in Fig. 1 (c).
Softmax vs. CRF Finally, we compare the proposed CRF
spatial attention model with the conventional Softmax attention model based on a 2-stack hourglass network. We
compare the accuracy rates, i.e., PCKh at 0.5, on the validation set as training progresses in Fig. 10. The CRF attention model converges much faster and achieves higher
validation accuracy than the Softmax attention model. We
visualize the attention maps generated by these two models, and observe that CRF attention models generates much
more cleaner attention maps compared with Softmax attention model due to its better ability to model spatial correlations among body parts.
7.3. Qualitative Results
To gain insights on how attention works, we compare the
baseline model with the proposed model by visualizing the
attention maps, the score maps, and the estimated poses, as
demonstrated in Fig. 9 (a-b). We observe the baseline model
may has difﬁculty in distinguishing objects with similar appearance with limbs (e.g., the horse leg in Fig. 9 (a)), and
the heavy shadow with ambiguous shape (Fig. 9 (b)). So
the holistic attention maps would be great help for remov-
Figure 11. Failure cases caused by (a) overlapping people, (b)
twisted limbs, (c) illumination, and (d) left/right confusion.
ing cluttered background and reducing ambiguity. For part
attention maps, besides providing more precise localization
for the body parts, they could even help reduce the double
counting problem. For example, the left and right ankle can
be distinguished by incorporating the part attention maps.
Fig. 9 (c) demonstrates the poses predicted by our methods on the MPII test set and the LSP test set. Our method
is robust to extremely difﬁcult cases, e.g., rare poses, cluttered background, and foreshortening. However, as shown
in Fig. 11, our method may fail in some cases which are
also difﬁcult for human eyes, i.e. (a) heavy occlusion and
ambiguity, (b) twisted limbs, (c) signiﬁcant illumination
change, and (d) left/right body confusion caused by clothing/lighting. Please refer to the supplementary materials for
more visualized results.
8. Conclusion
This paper has proposed incorporating multi-context attention and ConvNets into an end-to-end framework. We
use visual attention to guide context modeling. Hence our
framework has large diversity in contextual regions.
Instead of using global Softmax, we introduce CRF for spatial correlation modeling.
We build multi-context attention model along three components, i.e., multi-resolution,
multi-semantics, and hierarchical holistic-part attention
Additionally, an hourglass residual unit was
proposed to enrich the expressive power of conventional
residual unit.
The proposed multi-context attention and
the HRUs are general, and would help other vision