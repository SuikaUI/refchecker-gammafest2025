City University of New York (CUNY)
City University of New York (CUNY)
CUNY Academic Works
CUNY Academic Works
Publications and Research
City College of New York
Measuring knowledge of natural selection: A comparison of the
Measuring knowledge of natural selection: A comparison of the
C.I.N.S., an open-response instrument, and an oral interview
C.I.N.S., an open-response instrument, and an oral interview
SUNY Stony Brook
Irvin Sam Schonfeld
CUNY Graduate Center
How does access to this work benefit you? Let us know!
More information about this work at: 
Discover additional works at: 
This work is made publicly available by the City University of New York (CUNY).
Contact: 
JOURNAL OF RESEARCH IN SCIENCE TEACHING
VOL. 45, NO. 10, PP. 1131–1160 
Measuring Knowledge of Natural Selection: A Comparison of the CINS,
an Open-Response Instrument, and an Oral Interview
Ross H. Nehm,1 Irvin Sam Schonfeld2
1College of Education and Human Ecology, Department of Evolution,
Ecology, and Organismal Biology, The Ohio State University,
333 Arps Hall, Columbus, Ohio 43210
2School of Education, Department of Psychology, The City College,
City University of New York, New York, New York
Received 14 March 2007; Accepted 9 November 2007
Abstract: Growing recognition of the central importance of fostering an in-depth understanding of natural selection
has, surprisingly, failed to stimulate work on the development and rigorous evaluation of instruments that measure
knowledge of it. We used three different methodological tools, the Conceptual Inventory of Natural Selection (CINS), a
modiﬁed version of Bishop and Anderson’s (Bishop and Anderson Journal of Research in Science Teaching 27:
415–427) open-response test that we call the Open Response Instrument (ORI), and an oral interview derived from both
instruments, to measure biology majors’ understanding of and alternative conceptions about natural selection. We
explored how these instruments differentially inform science educators about the knowledge and alternative conceptions
their students harbor. Overall, both the CINS and ORI provided excellent replacements for the time-consuming process of
oral interviews and produced comparable measures of key concept diversity and, to a lesser extent, key concept
frequency. In contrast, the ORI and CINS produced signiﬁcantly different measures of both alternative conception
diversity and frequency, with the ORI results completely concordant with oral interview results. Our study indicated that
revisions of both the CINS and ORI are necessary because of numerous instrument items characterized by low
discriminability, high and/or overlapping difﬁculty, and mismatches with the sample. While our results revealed that both
instruments are valid and generally reliable measures of knowledge and alternative conceptions about natural selection, a
test combining particular components of both instruments—a modiﬁed version of the CINS to test for key concepts, and a
modiﬁed version of the ORI to assess student alternative conceptions—should be used until a more approprite instrument
is developed and rigorously evaluated.  2008 Wiley Periodicals, Inc. J Res Sci Teach 45: 1131–1160, 2008
Keywords: evolution; natural selection; alternative conceptions; assessment
For more than a century, evolutionary theory has without fail demonstrated its explanatory power and
practical utility in a diverse array of empirical contexts within a growing number of scientiﬁc disciplines
 . Nevertheless, learners at all levels of the educational hierarchy in the United
States are characterized by low levels of understanding and acceptance of evolution, as well as myriad
alternative conceptions . The increasing importance of evolutionary theory within the biological
sciences, paradoxically coupled with growing public resistance to it, has focused considerable attention on
the teaching and learning of evolution .
The tenacity of evolutionary alternative conceptions in the face of innovative science instruction , and the persistence of antievolutionary attitudes among educated adults 
Correspondence to: R.H. Nehm; E-mail: 
DOI 10.1002/tea.20251
Published online 7 May 2008 in Wiley InterScience (www.interscience.wiley.com).
 2008 Wiley Periodicals, Inc.
have spurred several research programs to explicate the causes of resistance to evolution, and shed light on
solutions to the problem of this resistance. Speciﬁcally, scholarly work has begun to explore (1) the precise
interrelationships among cognitive, affective, epistemological, and religious variables that contribute to
antievolutionary views in individuals of different ages and educational backgrounds ; (2) the design, implementation, and evaluation of interventions that promote
accurate cognitive models of evolution ; and (3) methods for reducing
levels of antievolutionary attitudes in students and teachers .
Evolutionin general and natural selection in particular continue to function as the conceptual framework
upon which the ever-expanding domain of contemporary biological science is built . Likewise, evolution and natural selection serve as unifying concepts that provide curricular coherence
for the life science strands of the National Science Education Standards as well as many state standards
 . Although the impact of the
national and state standards pertaining to evolution is debatable , no science or science education organizations have questioned the inclusion, or
importance, of evolution and natural selection in these standards.
Growing recognition of the central importance of fostering an in-depth understanding of evolution and
natural selection has, surprisingly, failed to stimulate work on the development and rigorous evaluation of
instruments that measure knowledge of, and alternative conceptions about, natural selection in learners of
different ages and educational backgrounds . This dearth of
attention to assessment makes evaluation of the effectiveness of national and state standards, as well as
particular pedagogical strategies used to teach them, difﬁcult if not impossible. Indeed, only two instruments
for measuring knowledge of natural selection have been developed: (1) Bishop and Anderson’s essay
instrument and (2) the Conceptual Inventory of Natural Selection . Both instruments were developed for populations of undergraduate non-majors; no validated
instruments are available for use on undergraduate majors or biology teachers.
Despite their extensive use by science educators , the CINS and the Bishop and
Anderson essay test remain in need of rigorous validation and replication. Indeed, despite criticisms in the
literature , no empirical work has explored the putative deﬁciencies of
these instruments, and nothing is known about how they differentially capture knowledge of and alternative
conceptions about natural selection. Additionally, neither instrument has been employed to measure
knowledge of, or alternative conceptions about, natural selection in samples primarily comprised of minority
undergraduates. Finally, no work has explored whether these instruments are suitable for the assessment of
evolutionary knowledge in biology majors.
This study focuses on the conceptual understanding of natural selection in minority undergraduate biology
majors, many of whom will go on to become science teachers, medical professionals, and scientists. Speciﬁcally,
we attempt to assess biology majors’ understanding of, and alternative conceptions about, natural selection using
threedifferentmethodologicaltools:(1)theCINS ,(2)anOpenResponseInstrument(ORI)
that was partly derived from Bishop and Anderson’s essay test ; and (3) an extended
oralinterviewbasedonquestionsfrombothinstruments.Weexplorehowthesedifferenttoolsdifferentiallyinform
science educators about the knowledge and alternative conceptions that students harbor, and whether these
instruments are suitable for use with samples of undergraduate biology majors.
Materials and Methods
Sample Characteristics
This study was conducted using two samples (classes) of biology majors in their second semester at a
large minority-serving urban university located in the northeastern United States. Enrollment in the secondsemester course was contingent upon successful completion of the ﬁrst semester of introductory biology,
which covered genetics and cell biology. Student data collected in the second-semester course took place
after instructional units on evolution and natural selection were completed. The racial and ethnic distribution
NEHM AND SCHONFELD
Journal of Research in Science Teaching
of students in both samples closely approximated that of science majors at the institution (Hispanic: 32.5%;
African-American: 30.12%; Asian: 25.5%; native Americans: 0.09%; non-Hispanic White: 11.75%).
Compared to participants in previous evolution-education studies, participants in this study are different: they
are mostly minority undergraduate science majors; they are of slightly older age; a greater proportion is
female. These differences may restrict the comparability of this study to studies of other student populations
and learning contexts.
In Sample G, 100 students voluntarily completed the CINS and ORI (99% participation rate) and 18
students volunteered for associated oral interviews. The mean age of students was 21 years (SD ¼ 4.37) and
their ages ranged from 17 to 35 years. Females comprised 60.6% of the sample. In Sample N, 82 students
completed the ORI only (82% response rate). Instructor-imposed time constraints prevented the
implementation of the CINS in Sample N. As in Sample G, the mean age of students in Sample N was 21
years (SD ¼ 4.24) and their ages ranged from 17 to 36 years. Sample N was also mostly (60.6%) female. The
difference in the proportions ofnon-Hispanic Whitestudents in Samples Nand G (10%vs. 15%,respectively)
was non-signiﬁcant; additionally, the percentage of students who self-reported being taught natural selection
in high schools (99% vs. 84%) was statistically signiﬁcant (p < 0.01).
Characteristics of the Open Response Instrument (ORI) and the Conceptual
Inventory of Natural Selection (CINS)
Two paper-and-pencil instruments were used to measure student knowledge and alternative conceptions
of natural selection. The ﬁrst, referred to as the Open Response Instrument (hereafter: ORI), was developed
using questions from earlier studies: three questions from Bishop and Anderson’s essay test and
two questions from Nehm and Reilly . The instrument thus comprised ﬁve open-ended essay questions:
(1) Please deﬁne natural selection to the best of your ability; (2) Explain why some bacteria have evolved a
resistancetoantibiotics(i.e.,theantibioticsnolongerkillthebacteria);(3)Cheetahs(largeAfrican cats)areable
to run faster than 60 miles per hour when chasing prey. How would a biologist explain how the ability to run fast
evolved in cheetahs, assuming their ancestors could run only 20 miles per hour? (4) Cave salamanders
(amphibian animals) are blind (they have eyes that are not functional). How woulda biologist explainhow blind
cave salamanders evolved from ancestors that could see? (5) If biologists wanted to speed up evolutionary
change, how would they do it? Students were asked to ‘‘Be as complete as you can’’ both on the instrument and
in an oral script, and given one-half page of empty space to answer each question. Just prior to the
implementation of the instrument, the proctors also announced ‘‘Please answer as completely as possible.’’
The ORI was designed to be completed during class in 25 minutes or less, and nearly all students who
participated in a prior study were able to provide detailed responses to the questions under these conditions
 .
The ORI was designed to measure undergraduate biology majors’ knowledge about natural selection at
differing levels of complexity. The ﬁve open-response questions on the instrument (see above) were ordered
such that they began by requesting familiar concrete knowledge (e.g., ‘‘deﬁne natural selection’’) and ended
with unfamiliar abstract problem-solving questions (e.g., ‘‘how might a biologist try to speed up evolutionary
change?’’). These questions, all of which focused on natural selection, were designed to parallel Bloom’s
Taxonomy, which organizes different types of categories of knowledge by levels . For
example, Bloom’s Level 1 Knowledge category includes cognitive tasks involving the observation and recall
of information, such as an awareness of dates, events, places, and major ideas. In contrast, the Level 4
Application categoryincludes tasks such as employing information, methods, or concepts in new situations to
solve problems, which is an example of higher-order thinking. Thus, the ORI attempted to gauge students’
sophistication at solving different types of evolutionary problems.
The second instrument used in this study was the closed-response (multiple-choice) Conceptual
InventoryofNatural Selection (hereafter: CINS)which was developed tomeasure similar types of knowledge
as the ORI . The CINS offered one correct response option for each question (n ¼ 20)
as well as a series of distractors derived from well-documented alternative conceptions (Anderson et al.,
The ORI and CINS differ in several respects: (1) number of questions (5 vs. 20); (2) format of the
questions (open- vs. closed-response); and (3) use of alternative conception distractors (absent in the ORI).
MEASURING KNOWLEDGE OF NATURAL SELECTION
Journal of Research in Science Teaching
Additionally, the ORI was developed in order to measure potential learning gains in biology majors, whereas
the CINS was employed and validated on a cohort of non-majors. The two instruments are nevertheless
similar in several respects: (1) both attempt to measure knowledge of natural selection; (2) both were
designed to be completed in less than 30 minutes; and (3) both were designed for use with samples of college
undergraduates.
The content validity of both instruments is reﬂected in their havingbeen designed by subject area experts
to cover key concepts speciﬁc to the domain of knowledge we call natural selection . Moreover, the ORI was developed with the twin contentvalidational aims of accurately identifying both student knowledge and student alternative conceptions (see
Variable Coding and Tabulation Section).
Discriminant Validity Instrument
In order to explore the discriminant validity of the CINS and ORI, we developed a multiple-choice
science test on a subject other than evolution. This test was developed using questions from the New York
State Regents earth science exams from 2001 to 2006. The Regents exam questions were designed to measure
earth science knowledge in high school students who have taken a year-long earth science class. We
considered a high-school-level, closed-response test on rocks to be appropriate for our study of discriminant
validity for several reasons: (1) the vast majority of undergraduates in our sample did not take the earth
science Regents coursework or exams; (2) the test questions are of a level appropriate for ﬁrst-year college
students; and (3) the test was similar in format and structure to the CINS, and therefore might expose students
who are good at taking multiple-choice exams despite little knowledge of rocks. The closed-response, tenquestion rock test was administered to all oral interview participants (n ¼ 18). We assessed discriminant
validityby examiningthe correlation between participant scores on the CINS and ORI andthe rock test. Cases
of signiﬁcant correlations between the rock test, on the one hand, and the CINS and ORI, on the other, would
call into question the construct validity of the CINS and ORI.
Oral Interviews
Oral interviews were conducted on the voluntary participants from Sample G (see above). The
interviews lasted approximately 25 minutes (mean ¼ 24.8 minutes, min. ¼ 15.5, max. ¼ 39.1). These
participants exhibited a broad array of scores on both the CINS (30–100%, mean ¼ 66%) and the ORI
(58–100%, mean ¼ 80%). To ensure content validity the oral interview was designed such that it
comprised four questions, two from Bishop and Anderson’s original essay test , one from the CINS,
and one from the ORI (1) ‘‘A number of mosquito populations no longer die when DDT (a chemical used to
kill insects) is sprayed on them, but many years ago DDT killed most mosquitoes. Could you explain why
many mosquitoes don’t die anymore when DDT is sprayed on them?’’; (2) ‘‘Seals can remain underwater
without breathing for nearly 45 minutes as they hunt for ﬁsh. How would a biologist explain how the ability
to not breathe for long periods of time has evolved, assuming their ancestors could stay underwater for just
a few minutes?’’; (3) Question 13 from the CINS ; and (4) Question 4 from the ORI
(see above).
Variable Coding and Tabulation
The ﬁrst set of variables extracted from the ORI related to student knowledge of the seven key concepts
of natural selection : (1) the causes of phenotypic variation (e.g.,
mutation, recombination, sexual reproduction); (2) the heritability of phenotypic variation; (3) the
reproductive potential of individuals; (4) limited resources and/or carrying capacity; (5) competition or
limited survival potential; (6) selective survival based on heritable traits; (7) a change in the distribution of
individuals with certain heritable traits.
A coding rubric was developed, piloted, reﬁned, and used to score student responses such that the
use of a key concept in an explanation of evolutionary change counted as one point. Thus, an essay
response that employed all seven key concepts received seven points. After initial scoring, the essays
were blindly recoded using the same rubric in order to test the precision of the coding rubric and the
consistency of the raters. Scorer reliability or cross-rater consistency was assessed by calculating the
NEHM AND SCHONFELD
Journal of Research in Science Teaching
Pearson correlation coefﬁcients between the number of key concepts identiﬁed by each of the two raters.
The results indicated statistically signiﬁcant correlations for both of the ORI questions scored for key
concepts (r ¼ 0.78, p < 0.001; r ¼ 0.77, p < 0.001). Thus, the scoring rubric appeared to be sufﬁciently
clear, and the raters sufﬁciently consistent, for reliable coding of key concepts. The coding rubric was
used to quantify the presence or absence of the seven key concepts in each of the students’ ﬁve essay
questions (see above). These scores were tallied separately for each question, collectively for each
student, and collectively for all students. In addition, the number of different key concepts used among
all ﬁve questions (hereafter: key concept diversity) was scored for each student and collectively for all
The second set of variables extracted from the ORI related to student alternative conceptions concerning
natural selection (hereafter: alternative conceptions). A coding rubric was developed that contained
alternative conceptions about natural selection and evolution. These alternative conceptions have been
extensively documented in the research literature .
This rubric was used in order to measure the magnitude and distribution of commonly observed student
alternative conceptions , as
well as to capture any novel alternative conceptions elicited by the instrument. Cross-rater consistency in
enumerating alternative conceptions was assessed using the Pearson correlation coefﬁcient. Two raters
blindly coded the number of alternative conceptions in the salamander essay question. The analysis produced
statistically signiﬁcant correlations between the raters’ scores (r ¼ 0.82, p < 0.01). Thus, the scoring rubric
appeared to be sufﬁciently clear, and the raters sufﬁciently consistent, for reliable coding of alternative
conceptions.
Student responses were scored such that the use of an identiﬁable alternative conception in an
evolutionary explanation counted as one point, with no upper limit to the number of alternative conceptions
recognized per essay. Unanticipated (i.e., unspeciﬁed on the rubric) alternative conceptions captured in this
manner included (1) survival of the ﬁttest means survival of the ﬁttest species; (2) ‘‘ﬁt’’ ¼dominant and
‘‘unﬁt’’ ¼recessive, in the allelic sense; (3) ‘‘genetic drift’’ ¼ gene ﬂow between different species; (4) drastic
climate change is required for evolution to occur; (5) heritable ‘‘compensation’’ of one trait occurs when
another faculty is lost, for example, ‘‘super’’ hearing or smell was attributed to suddenly blind salamanders;
and (6) humans are incapable of affecting evolution in any way. The coding rubric was used to quantify the
presence or absence of these alternative conceptions, and scores were tallied for each question, collectively
for each student, and collectively for all students. In addition, the number of different alternative conceptions
used among all ﬁve questions (hereafter: alternative conception diversity) was scored for each student and
collectively for all students.
In addition to measuring student performance using separate key concept and alternative conception
measures, we used the Natural Selection Performance Quotient (NSPQ) of Nehm and Reilly to
quantify student knowledge and alternative conceptions. The NSPQ takes a ratio of key concept diversity to
the sum of key concept diversity plus alternative conception diversity, and multiplies it by the ratio of key
concept diversity to total possible key concepts, and thereby produces a single grade-like score (i.e., 0–100).
The ﬁrst term expresses the proportion of the students’ answers that were correct, and the second expresses
how the correct proportion compared to the most complete possible answer .
Exponents were chosen to calibrate the NSPQ scale such that it conformed to our
assessment that four key concepts would result in a score above 65 (i.e., passing). In addition to permitting the
visualization of student knowledge on a single scale, the NSPQ also distinguishes clearly between students
who have problems with their understanding of natural selection, despite displaying signiﬁcant knowledge,
and those students with no alternative conceptions who displayed differing levels of knowledge .
Scoring of the closed-response CINS instrument was more straightforward than scoring the ORI. All
correct CINS responses represented key concepts and all incorrect CINS responses represented alternative
conceptions. Because the CINS contained the same key concept and alternative conception options in several
questions, it was possible to calculate a standardized measure of key concept diversity and alternative
MEASURING KNOWLEDGE OF NATURAL SELECTION
Journal of Research in Science Teaching
conception diversity (in parallel to the ORI diversity variables discussed above). That is, we measured key
concept and alternative conception diversity for each student and collectively among all students.
Scoring of the rock test was based on a percentage score, where 100% represented 10 correct items.
The coding of the oral interview was similar to that of the ORI. A coding rubric was developed, piloted,
reﬁned, and used to score student responses such that the use of a key concept in an explanation of
evolutionary change counted as one point (up to seven total, see above) and the use of an identiﬁable
alternative conception counted as one point, with no upper limit to the number of alternative conceptions
recognized per answer. Tallies were made for the number and diversity of key concepts and alternative
conceptions per person. Additionally, we calculated an overall interview score: 1 ¼ clear evidence of a
faulty mental model of natural selection and numerous alternative conceptions; 0 ¼ ambiguous evidence:
some correct concepts present, some alternative conceptions present, but unclear evidence whether an
accurate mental model of natural selection is being employed; and 1 ¼ clear, unambiguous evidence of an
accurate working model of natural selection lacking alternative conceptions. Cross-rater consistency of oral
interview scores was assessed by calculating Spearman rank-order correlations on overall interview scores
(i.e., 1, 0, or 1). Ten randomly selected interviews were recoded by two independent raters and found to be
very closely matched (n ¼ 10, r ¼ 0.96, p < 0.001). Finally, we note that the oral interviews were blindly
coded prior to comparisons to the ORI, CINS, and rock test scores.
Methodological Framework and Analyses
Both Classical Test Theory (CTT) and Item Response Theory (IRT) were used as analytical and
methodological frameworks for our study. Although IRT is currently considered a more advantageous
psychometric approach , Anderson et al. used CTT to evaluate and validate the
CINS, and we wanted to compare results from our study to theirs using the same methodological framework.
CTT explores item attributes (e.g., item difﬁculty) within the context of the particular population sampled
 . IRT, in contrast, assumes that the characteristics of particular instrument items
are independent of the abilities of the sample participants . CTT is a traditional
psychometric approach that we used as a context for documenting instrument attributes such as reliability and
validity. Speciﬁc measures included the calculation of item discriminability and difﬁculty, and factor
analyses of response correlation patterns. Variable means and correlations, question discriminability,
difﬁculty, and reliability (Cronbach’s a) and principal components analysis (PCA) were calculated for the
CINS and ORI data using SPSS 12.0.
Rasch analysis is an increasingly common IRTapproach for investigating
the reliability and validity of instruments in science education . Rasch
analysis produces conceptually analogous, but empirically different, measures of reliability, validity, and
item difﬁculty than traditional CTT measures . We used WINSTEPS software to perform the Rasch analysis, therein quantifying item difﬁculty, redundancy, and person-item
relationships . Finally, we explored the concordance and discordance of results
derived using traditional and Rasch model analyses.
Open Response Instrument
Quantitative Measures of Student Knowledge Using the ORI. The ORI was used to measure secondsemester biology majors’ knowledge and alternative conceptions of natural selection. Key concept diversity
scores derived from the ORI revealed acceptable averages: 4.33 for Sample N and 3.78 for Sample G.
Similarly, in Sample N, 70% of students employed four or more key concepts and in Sample G 58% of
students employed more than four key concepts. Thus, on average, biology majors were using about four (out
of a possible seven) key concepts of natural selection in their explanations of evolutionary change. We
illustrate several examples of participant key concept use below:
‘‘Natural selection is the unequal survival at reproduction among individuals in a population due to
having unique traits that will be favored or unfavored by the environment.’’ (Sample G, #36. key
concepts: differential survival, variation).
NEHM AND SCHONFELD
Journal of Research in Science Teaching
‘‘It is likely that cheetahs are competing with other predators while chasing prey. Through mutations,
some cheetahs developed the ability to run extremely fast, 60 miles per hour, and it was these cheetahs
that were able to ﬁnd food, survive, have offspring, and pass on their genetic athleticism on to their
offspring.’’ (Sample G, #40. key concepts: causes of variation, heritability, selective survival,
resources, competition).
‘‘The bacteria that had no resistance to a certain antibiotic died quickly, and the bacteria that had some
resistance survived and without competition from the bacteria with no resistance, the bacteria with
resistance increased in ratio to those without resistance.’’ (Sample G, #32. key concepts: competition,
selective survival, change in the frequency of individuals in a population).
‘‘Blind cave salamanders must be a product of genetic drift. As their ancestors populated the cave
(which was a new territory at ﬁrst), the genetic variation was reduced compared to that of their home
population. Over time this caused a change in the allele frequency. This factor as well as mutation may
have led to their having eyes that are not functional. Since the cave is dark the mutation did not hinder
their survival’’ (Sample G, #36. key concepts: genetic variation, inheritance, selective survival based
on heritable traits).
Alternative conception scores revealed a different result than key concept results. Mean alternative
conception diversity was relatively high in both samples: 1.9 in Sample G and 2.4 in Sample N. Additionally,
only 14% of students in Sample G and 30% of students in Sample N employed no alternative conceptions on
the ORI. NSPQ averages, which provide a single metric encompassing both key concept and alternative
conception diversity on a 0–100 scale, were 74 and 79 for Samples G and N, respectively. Overall, while key
concept use was relatively high, alternative conceptions formed a large component of biology majors’
explanations of evolutionary change after a year of biology. Four examples of participant alternative
conception use are shown below:
‘‘Natural selection is the process by which organisms survive over a period of time. The species with
characteristics either genetic or adapted that beneﬁt their survival are the ones that live while the other
less beneﬁcial species dies.’’ (Sample G, #50. alternative conceptions: species vs. individuals, and
acclimation inﬂuences survival).
‘‘Some bacteria have evolved a resistance to antibiotics because they have been exposed to it long
enough, and have evolved some way of making their bodies antibiotic resistant’’ (Sample G, #24
alternative conceptions: environmental exposure causes change).
‘‘The ability to run fast evolved in cheetahs by their leg structure. The ones who were able to run faster
positioned their legs in such a way that over generations of time, it became an environmentally
controlled mutation. Those who were able to run fast were able to survive, thus now cheetahs all can
run fast because the [illegible] cheetahs are dead with their offspring.’’ (Sample G, #50 alternative
conceptions: inheritance of acquired characteristics).
‘‘The salamanders didn’t need sight to survive: their eyes became useless and thus blind. Like our
pinky, useless and eventually it will fall off.’’ (Sample G, #54 alternative conceptions: use and disuse).
Key Concept and Alternative Conception Frequencies. Table 1 summarizes the number, percentage,
and rank of the seven key concepts of natural selection extracted from the ORI from Samples N and G. The
goal of this analysis was to document the most common concepts used by students in their explanations of
evolutionary scenarios. Percentages for each key concept category were calculated relative to the total
number of key concepts mentioned; these percentages therefore do not measure absolute response rates for
each key concept in the sample. In both samples, students employed all seven key concepts to varying
degrees. Key concept six (‘‘certain phenotypes do better and leave more offspring’’) was the most commonly
elicited key concept in both samples (91.5% Sample N; 74% Sample G). ‘‘Overproduction of offspring’’ was
the least commonly used key concept in Sample N (18%), and ‘‘competition’’ was the least commonly used
keyconcept in Sample G (9%). Considerablevariation exists in the relative ranks of key concepts between the
two samples, but both samples produced evidence of key concept use for all of the major conceptual
components of natural selection (Figure 1).
MEASURING KNOWLEDGE OF NATURAL SELECTION
Journal of Research in Science Teaching
The number, percentage, and rank of the seven key concepts of natural selection extracted from the Open Response Instrument (ORI) from Samples N and G
Key Concept
CINS Concept
Description of Concept with CINS
Question Numbers
CINS Responses PER Question
CINS Total Responses
ORI (Sample N)
ORI (Sample G)
Oral Interview
Sample N (%)
ORI Sample G (%)
ORI (N) Rank
ORI (G) Rank
Interview Rank
Origin and
existence of
Random mutations and sexual reproduction produce variations;
while many are harmful or of no consequence, a few are
beneﬁcial in some environments (6B, 19C); individuals of a
population vary extensively in their characteristics (9D, 16C)
29, 64, 54, 89
Variation inheritable Much variation is heritable (7C, 17D)
Limited survival
Production of more individuals than the environment can support
leads to a struggle for existence among individuals of a
population, with only a fraction surviving each generation
Biotic potential
All species have such great potential fertility that their population
size would increase exponentially if all individuals that are
born would again reproduce successfully (1C, 11B)
Natural resources
Natural resources are limited; nutrients, water, oxygen, etc.
necessary for living organisms are limited in supply at any
given time (2A, 14D)
Differential survival Survival in the struggle for existence is not random, but depends
in part on the hereditary constitution of the surviving
individuals. Those individuals whose surviving characteristics
ﬁt them best to their environment are likely to leave more
offspring than less ﬁt individuals (10C, 18B)
Change in a
population
The unequal ability of individuals to survive and reproduce will
lead to gradual change in a population, with the proportion of
individuals with favorable characteristics accumulating over
the generations (4B, 13B)
N/A Population stability
Most populations are normally stable in size except for seasonal
ﬂuctuations (3B, 12A)
N/A Origin of species
An isolated population may change so much over time that it
becomes a new species (8A, 20B)
See text for details on ranking and percentage calculations.
NEHM AND SCHONFELD
Journal of Research in Science Teaching
We also noted the number, percentage, and rank of 31 alternative conceptions (documented from among
all of our instruments) from Sample G using the ORI. The conceptual universe of alternative conceptions
elicited by the ORI was much more diverse than that of key concepts of natural selection (Table 2). As in
Table 1, the percentages for each key concept category were calculated relative to the total number key
concepts mentioned; these percentages therefore do not measure absolute response rates for each key concept
in the sample. Of the 167 alternative conceptions that we documented using the ORI, the three most common
were ‘‘use and disuse,’’ ‘‘inheritance of acquired traits,’’ and ‘‘intention/need,’’ all of which have been welldocumented in the literature. The ORI elicited student responses to only 50% of the alternative conception
categories that we explored. Additionally, no new categories of alternative conceptions were discovered,
although particular questions, such as the ‘‘salamander’’ question, did elicit a large number of consistent but
previously undocumented responses relating to the compensatory enhancement and heritability of other
senses in response to blindness. Overall, constructed responses from Sample G encompassed a very small
universe of alternative conceptions relative to those previously documented in the literature.
Percentages of ‘‘key concepts’’ of natural selection documented using the Open Response Instrument (ORI)
(Samples G and N), the Conceptual Inventory of Natural Selection (CINS), and Oral interview (ORAL). Percentages were
standardized among instruments using the total number of key concepts elicited by each instrument.
MEASURING KNOWLEDGE OF NATURAL SELECTION
Journal of Research in Science Teaching
The number, percentage, and rank of 31 alternative conceptions (documented from among all of our instruments) from Sample G using the Open Response Instrument (ORI)
Misconception Number
Misconception (with CINS Question Number if Applicable)
CINS Responses per Question
CINS Total Responses
ORI Responses
Oral Interview Responses
CINS Frequencies
ORI Frequencies
Interview Frequencies
Interview Rank
Organisms can intentionally become new species over time (an organism tries, wants, or needs
to become a new species) (8C, 8D, 20A, 20D)
28, 22, 14, 28
Mutations are intentional: an organism tries, needs, or wants to change genetically (6A, 6D,
26, 17, 18, 2
Organisms can always obtain what they need to survive (2B, 2C, 2D, 14A, 14B, 14C)
13, 1, 3, 3, 31, 8
Population level off (1B, 11D, 1D)
Mutations occur to meet the needs of the population (4D, 13D)
Mutations are adaptive responses to speciﬁc environmental agents (6C, 15C, 19D)
28, 11, 15
Learned behaviors are inherited (4C, 13C)
Changes in a population occur through a gradual change in all members of a population (4A,
Variations only affect outward appearance, do not inﬂuence survival (9B, 9C, 16B)
Populations always ﬂuctuate widely/randomly (3C, 12D)
Fitness is equated with strength, speed, intelligence or longevity (10A, 10B, 18A, 18C, 18D)
5, 6, 1, 3, 13
When a trait (organ) is no longer beneﬁcial for survival, the offspring will not inherit the trait
There is often physical ﬁghting among one species (or among different species) and the
strongest ones win (5B, 15B)
Populations decrease (3D, 12C)
Traits that are positively inﬂuenced by the environment will be inherited by offspring (7D)
Organisms work together (cooperate) and do not compete (5A, 5C, 15A)
All members of a population are nearly identical (9A, 16A)
Traits acquired during an organism’s lifetime will be inherited by offspring (7A, 17A)
All populations grow in size over time (3A, 12B)
Organisms with many mates are biologically ﬁt (10D)
NEHM AND SCHONFELD
Journal of Research in Science Teaching
Not all organisms can achieve exponential population growth (11C)
Organisms only replace themselves (1A, 11A)
Organisms in a population share no characteristics with others (16D)
The heightening of other senses explains the loss of other sensory structures
Change had to happen; death/extinction not recognized as a possibility
Evolution cannot occur
Goal directedness explains change
Variants considered to be new species
Conﬂation of species-level and individual-level change
Competition among body parts explains gain or loss of features
The environment directly causes change
See text for details on ranking and percentage calculations.
MEASURING KNOWLEDGE OF NATURAL SELECTION
Journal of Research in Science Teaching
Correlations among ORI Question Responses. Correlation analyses were used to explore whether
the ﬁve open-response questions in the ORI evoked comparable magnitudes of key concepts and
alternative conceptions (Tables 3 and 4). In both Samples G and N, the number of key concepts
elicited by the different questions was correlated signiﬁcantly in many cases (Tables 3 and 4, shaded
boxes). In both samples, notable exceptions include the lack of signiﬁcant correlations between the number of
key concepts from the ‘‘speeding-up evolution’’ question and the ‘‘deﬁnition’’ question. Additionally, in
Sample N, the ‘‘salamander’’ question responses were not signiﬁcantly correlated with the ‘‘deﬁnition’’
In contrast to the results found for key concepts, the ﬁve open-response questions in the ORI evoked
different magnitudes of alternative conceptions in most cases (Tables 3 and 4, white boxes). In both samples,
the number of alternative conceptions elicited by the ‘‘deﬁnition’’ question was not correlated with the
number of alternative conceptions elicited by anyother questions. Likewise, alternative conception responses
from the ‘‘bacteria’’ question and the ‘‘speeding-up’’ question were not signiﬁcantly correlated with one
another. The two samples did not provide similar results for several other questions; Sample N, for example,
displayed a greater number of signiﬁcant correlations among questions than did Sample G (Tables 3 vs. 4,
white boxes). In most cases, the correlation analyses provided evidence that the ﬁve open-response questions
elicited comparable magnitudes of key concepts. In contrast, they did not provide evidence that they elicited
comparable magnitudes of alternative conceptions.
Difﬁculty and Discriminability of Open-Response Questions
Difﬁculty of the ORI questions was calculated using the equation p ¼ R/T, where R ¼ the number of
students responding correctly to an item and T ¼ the total number of students . Note
that high percentages indicate low difﬁculty. Because the open-response questions were originally scored
using the total number of key concepts and alternative conceptions, it was necessary to convert these scores
into binary (i.e., right/wrong) scores. Nehm and Reilly considered three key concepts of natural
selection to be a minimal cut-offfor a sufﬁcient answer to an open-ended question about natural selection, and
we used this cut-off value. For the separate alternative conception analyses, we viewed any answer that
included alternative conceptions to be a wrong answer. Using this approach, we calculated separate difﬁculty
Pearson correlation coefﬁcients of the number of key concepts (shaded boxes) and alternative conceptions (white
boxes) elicited among the ﬁve open-response questions in the ORI for Sample G (see materials for the complete
questions)
Definition
Salamander
Speeding-up
Definition
Salamander
Speeding-up
Key Concepts
Misconceptions
NEHM AND SCHONFELD
Journal of Research in Science Teaching
levels for the ﬁve open-response questions from Samples G and N using key concept and alternative
conception scores.
As Table 5 illustrates, all ﬁve open-response questions from Samples G and N have very high difﬁculty
values using the cut-off of three key concepts. Fewer than 50% of students used the minimum number of key
concepts in all questions. Notably, the ‘‘speeding-up’’ question, which we hypothesized would be the most
difﬁcult, was among the most difﬁcult in both samples. However, the ‘‘deﬁnition’’ question, which weviewed
as the least difﬁcult and most concrete recall question, also produced very high difﬁculty scores. In Samples G
and N, using alternative conception scores, the ‘‘salamander’’ question was the only item of high difﬁculty;
more than 50% of biology majors employed alternative conceptions in this question. Overall, the difﬁculty
measures we document indicate that the ORI is challenging for undergraduates who have completed a year of
college biology.
ORI question discriminability was calculated using the equation of Popham :
D ¼ P(h)  P(l), where P(h) ¼ question difﬁculty of the high scoring group, and P(l) ¼ question difﬁculty
of the low scoring group. Forour analyses, we divided the sample along the median . We calculated discriminability values usingboth keyconcepts for each of the ﬁveORI
questions. We considered questions with a discriminability value > 0.30 to be acceptable . We also applied Popham’s equation to the occurrence of alternative conceptions for each of the ﬁve ORI
questions. Although his equation is intended for use with correct responses, we explored whether alternative
conceptions could be used to discriminate between groups.
As Table 5 illustrates, most questions have marginal discriminability values, using key concept and
alternative conception scores. Notable are the extremely low scores of the ‘‘speeding-up’’ question (Table 5,
bottom rows). While manyquestions were found to be of moderate discriminability, the speeding-up question
stood out as being extremely challenging for the biology majors in our samples.
Quantitative Measures of Student Knowledge Using the CINS. The CINS was used to measure second
semester biology majors’ knowledge and alternative conceptions of natural selection on a 0–100 scale.
Sample G (n ¼ 100) had an average CINS score of 62.9% (min. ¼ 20, max. ¼ 100, SD ¼ 19.9). Most students
Pearson correlation coefﬁcients of the number of key concepts (shaded boxes) and alternative conceptions (white
boxes) elicited among the ﬁve open-response questions in the ORI for Sample N (see materials for the complete
questions)
Definition
Salamander
Speeding-up
Definition
Salamander
Speeding-up
Key Concepts
Misconceptions
MEASURING KNOWLEDGE OF NATURAL SELECTION
Journal of Research in Science Teaching
Discriminability (DI) and difﬁculty values for the ﬁve open-response questions from Samples G and N using key concept and alternative conception scores
KC Difﬁculty
KC Difﬁculty
Salamander
Speeding-up
MIS Difﬁculty
MIS Difﬁculty
Salamander
Speeding-up
High ¼ high scoring average of the sample for each question; low ¼ low score averages for each question. KC ¼ key concepts, MIS ¼ alternative conceptions. Note that we also applied Popham’s equation to the
occurrence of alternative conceptions for each of the ﬁve ORI questions. The numbers in columns 2–5 bearing on alternative conceptions represent the proportions of students who employed at least one
alternative conception in answering the question. Although his equation is intended for use with correct responses, we explored whether alternative conceptions could be used to discriminate between groups.
Bold values ¼ high discriminability.
*High difﬁculty.
NEHM AND SCHONFELD
Journal of Research in Science Teaching
found the alternative conception distractors so compelling that most received unsatisfactory scores. Overall,
based on these scores, the CINS appears to be challenging for the second semester biology majors in our
Key Concept and Alternative Conception Frequencies. Table 1 summarizes the number, percentage,
and rank of the seven key concepts of natural selection extracted from the CINS from Sample G. The goal of
this analysis was to identify the most common correct concepts used by students. In Sample G, students
employed the seven key concepts of natural selection to varying degrees (Table 1). In addition, students
responded correctly to the items bearing on ‘‘population stability’’ (CINS items 3B and 12A) and ‘‘origin of
species’’ (items 8A and 20B) 67% and 50% of the time, respectively. Recall that we did not consider these
latter two ideas to be key concepts of natural selection, and they were never mentioned in the ORI or oral
interviews (see below). Key concept six (‘‘certain phenotypes do better and leave more offspring’’) was the
most commonly elicited key concept on the CINS (82%). The second and third most abundant key concepts
were ‘‘limited survival’’ (74.5%: items 5D and 15D) and ‘‘natural resources’’ (70.5%: items 2A and 14D).
The conceptual universe of alternative conceptions elicited by the CINS was much more diverse than
that documented in the ORI (Table 2). We noted the number, percentage, and rank of 31 alternative
conceptions. Of the 730 alternative conceptions that we documented in the CINS, the three most common
were alternative conception #1 (‘‘intention/need relating to speciation,’’ CINS distractors 8C, 8D, 20A, and
20D), alternative conception #2 (‘‘intention/need related to genetic change,’’ items 6A, 6D, 19A, 19B), and
alternativeconception # 3 (‘‘resources,’’ items 2B, 2C, 2D, 14A, 14B, and 14C). The CINS elicited alternative
conception responses to all but 25% of the categories we documented. Interestingly, four of the alternative
conception categories not documented by the CINS were among those that formed the ten most abundant
using the ORI.
Correlation Structure of CINS Questions. PCA was used to explore correlation patterns among
the CINS items. A PCA of varimax rotated scores for Sample G produced eight components with
eigenvalues > 1.0. These eight components collectively accounted for 65.9% of the variance in the data set.
The rotated component matrix values are shown in Table 6. All 20 items had loadings > 0.4 on at least one
component, with PC1 explaining the most variation in the dataset (12.3%). PC1 had the highest loadings for
items 3, 4, 5, 6, 8, 9, 13, 14, 15, and 17. Items 12 and 19 loaded most highly on PC2, items 2 and 20 on PC3,
items 10 and 18 on PC6, items 1 and 11 on PC7, and items 7 and 16 on PC8. Although each of the ten key
concepts of natural selection used in the CINS was represented twice (producing a total of 20 possible correct
key concept answers), many questions about the same key concept did not load highly on the same
components (see Table 6). Notable exceptions of questions that did load together on the same component
included ‘‘biotic potential’’ (items 1 and 11), ‘‘differential survival’’ (items 10 and 18), ‘‘limited survival’’
(items 5 and 15), and ‘‘change in population’’ (items 4 and 13). Thus, unlike Anderson et al.’s sample
of non-majors, we did not ﬁnd strong support for the different components representing distinct evolutionary
concepts in biology majors. Rather, we found one factor that included a highly correlated suite of
key concepts.
Difﬁculty and Discriminability of CINS Questions. As Table 7 illustrates, all 20 multiple-choice
questions from Sample G have relatively low difﬁculty values (i.e., a high percentage of students correctly
answered the questions), with the exception of questions 4 and 6. Overall, these results suggest that the CINS
is moderately challenging for the undergraduates in our sample. Discriminability (DI) was calculated using
the equation of Popham . DI values > 0.30 were considered acceptable . As Table 7 illustrates, about 40% (8/20) of questions have marginal discriminability. Notable
are the extremely low scores of questions 1, 10, and 16 (Table 7, bold). In Anderson et al.’s study of CINS discriminability in college non-majors, they found questions 4 and 9 to have marginal
values, but we did not. The internal consistency reliability of the CINS was satisfactory, with Cronbach’s
Rasch Analyses of CINS Responses. We used Rasch analysis to explore
item difﬁculty, redundancy, and person-item patterns for the CINS dataset from Sample G. The CINS dataset
MEASURING KNOWLEDGE OF NATURAL SELECTION
Journal of Research in Science Teaching
matches the Rasch analysis requirement of having sample sizes 100 and item number 20 . Prior to interpreting the item and person logit scores from the analysis, we explored whether our
dataset ﬁts the Rasch model. In a dataset with good ﬁt, person and item mean squares are expected to be 1.0.
The mean inﬁt and outﬁt for ‘‘persons’’ from our dataset are 1.00 and 1.06 respectively, and for ‘‘items’’ are
0.99 and 1.06, respectively. The mean standardized inﬁt and outﬁt for persons (0.0 and 0.1) and items (0.0 and
0.2) are close to the expected value of 0.0. These values indicate good ﬁt and suggest moderate levels of item
redundancy. The standard deviation of the standardized inﬁt for ‘‘persons’’ and ‘‘items’’ is 0.9 and 1.1,
respectively; both are below the 2.0 cut-off suggested by Bode and Wright . Separation values for
‘‘persons’’ (1.57) and ‘‘items’’ (3.74) are greater than the suggested minimum cut-off value of 1. Overall,
then, our CINS data from Sample G appear to ﬁt the Rasch model.
The ﬁt of individual CINS items to the Rasch model is shown in Table 8. Several authors consider items with mean-square ﬁt (MNSQ) values between 0.8 and 1.3, and standardized z
values (ZSTD) > 2 or <2, to be indicative of poor item ﬁt. As shown in Table 8, CINS items 1, 5, and 13
were discordant with model predictions based on both MNSQ and ZSTD values. Item 1 tested knowledge
about biotic potential, item 5 tested limited survival, and item 13 tested changes in population frequency.
Notably, the parallel questions about the same concepts (items 11, 15, and 4) were not characterized by poor
ﬁt with the model. Interestingly, traditional analysis also uncovered problems with item 1, which was
characterized by a low discriminability value (Table 8). CINS items 5 and 13, however, had acceptable
discriminablity values and difﬁculty values using traditional analyses.
A PCA of CINS question scores produced eight components with eigenvalues > 1.0
High loading
Questions with same concept load together
Questions with same concepts do not load together
These eight components collectively accounted for 65.9% of thevariance in the data set. The component matrix values
are shown below. Bold boxes indicate highest loadings on each component . Lines
connect questions containing the same key concept of natural selection. Note that many questions testing the same
concept (e.g., q8 and q20, on the origin of variation) do not load on the same component.
NEHM AND SCHONFELD
Journal of Research in Science Teaching
Discriminability (DI) and difﬁculty values for the 20 CINS questions
High Group
Difﬁculty (%)
High group ¼ high scoring average of the sample for each question; low ¼ low score averages for each question. KC ¼ key concepts,
MIS ¼ alternative conceptions.
*Questions identiﬁed by Anderson et al. as poor based on low DI values.
CINS item ﬁt statistics derived from the Rasch analysis
MEASURING KNOWLEDGE OF NATURAL SELECTION
Journal of Research in Science Teaching
Table 9 displays a person-item map, which visually summarizes several aspects of the Rasch analysis of
the CINS dataset. The distribution of persons (on the left) and CINS items (on the right) are illustrated on the
same logit scale. Persons at the same position along the scale as a particular item have a 50% chance of
answering the item correctly. Questions of equivalent difﬁculty lie at the same point on the logit scale (e.g.,
questions 8 and 12, 11 and 14, and 2 and 18). Individuals located above an item, however, have an even greater
chance of answering the item correctly (i.e., the item is likely tobe easier forthese individuals). Those persons
A person-item map derived from a Rasch analysis of CINS question responses
from Sample G
The distribution of persons (on the left) and CINS items (on the right) are illustrated
on the same log interval (2 to 4) scale.
NEHM AND SCHONFELD
Journal of Research in Science Teaching
located below an item have a less likely chance of answering it correctly (i.e., the item is more difﬁcult
for them).
Overall, Table 9 demonstrates that the distributions of CINS questions and persons are generally well
matched, except at the high end of the logit scale. Here, questions of sufﬁcient difﬁculty are lacking. As
Table 9 illustrates, CINS item 6 (origin of species) is the most difﬁcult on the logit scale, whereas nearly 15%
of the sample lies above the level of this question. The overall pattern in Table 9 indicates that the CINS
sufﬁciently differentiates the persons in the sample at lower performance levels, but does not differentiate
studentsat the highest performance levels.Additionally, it reveals that equivalentkeyconcept questions inthe
CINS are not of comparable difﬁculty. For example, CINS items 19 and 6 (about ‘‘the origin of species’’), and
items 2 and 14 (about ‘‘population stability’’) have greatly different difﬁculty levels.
In summary, the CINS data demonstrate good ﬁt with the assumptions of the Rasch model and indicate
that the instrument is appropriately matched in difﬁculty level to the sample of biology majors studied here.
Several instrument items of equivalent difﬁculty are present (e.g., items 2 and 18), and there was a lack of
items of sufﬁcient difﬁculty to distinguish high performers. Additionally, CINS items 1, 5, and 13 ﬁt poorly to
model predictions. Finally, the ten paired key concept questions were not in most cases of equivalent
difﬁculty, although some exceptions were noted (e.g., items 10 and 18).
Oral Interview
Oral interviews with 18 participants from Sample G lasted on average 24.6 minutes (min. ¼ 15.5,
max. ¼ 39.1). These participants displayed a broad distribution of knowledge and alternative conception
scores on the ORI and the CINS. The average CINS percentage score among interviewees was 66.4
(min. ¼ 30, max. ¼ 100), whereas the average NSPQ score was 80 (min. ¼ 58, max. ¼ 100). Qualitative
interview scores averaged 0.2 (min. ¼ 1, max. ¼ 1). We provideexamples from two participants (subjects Q
and R) to illustrate differences in student understanding documented in the oral interviews.
Participant Q, who received a composite score of þ1, demonstrates knowledge of several key concepts
of natural selection in question 1: genetic variation produced by cross breeding and rapid generation time,
competition for resources among individuals, and differential survival based on genetic variability. He does
not demonstrate any alternative conceptions.
Interviewer:
A number of mosquito populations no longer die when DDT, which is a chemical used
to kill insects, is sprayed on them, but many years ago DDT killed most mosquitoes.
Could you explain why many mosquitoes don’t die anymore when DDT is sprayed on
Participant Q:
OK . . . ah, well, the DDT used to kill a lot of the mosquitoes because the mosquitoes
didn’t have a lot of resistance to the DDT. But after a certain amount of time all of the
mosquitoes that were more vulnerable to the DDT died and the mosquitoes that
weren’t vulnerable to the DDT survived . . . they had access to more of the stuff in the
environment and less competition from the mosquitoes that didn’t have resistance to
DDT, they survived and were able to take the niche of the mosquitoes that died to
Interviewer:
. . . What is that resistance?
Participant Q:
. . . In a population such as mosquitoes they . . . the generations reproduce pretty
quickly, like you know, thousands of larvae, and it allows for a wide genetic pool, if
anything, so since there is a wide genetic pool there is a greater chance of a mosquito,
or any mosquito at all, developing resistance.
Interviewer:
When you say wide genetic pool, what do you mean by that?
Participant Q:
There is a lot of genetic variability
Interviewer:
Do you know why there is a wide genetic variability?
Participant Q:
Cross breeding.
MEASURING KNOWLEDGE OF NATURAL SELECTION
Journal of Research in Science Teaching
In contrast to participant Q, participant R demonstrates a limited understanding of natural selection and
severalalternativeconceptions. His overall interview scorewas 1. Speciﬁcally, we interpret his responses to
indicate that traits acquired during an organism’s lifetime can be passed on, and in some cases ampliﬁed, and
that this in part explains biotic change in mosquitoes. Notably, he incorporates numerous experiences from
watching television and his daily life into his conceptual explanations for DDT resistance in mosquitoes.
Interviewer:
(mosquito question, same as above).
Participant R:
. . . Well, if at ﬁrst the DDT killed most mosquitoes and now it’s not killing them [any]
more, then a possible explanation would be that when they ﬁrst started exposing the
mosquitoes to the DDT they didn’t have any . . . their immune system was not that
strong to ﬁght the DDT. As time went on they developed some kind of resistance to the
DDT . . . they passed this kind of, um, newly evolved resistance on to the next
generation so . . . passing on this trait from generation to generation . . . it will start
becoming stronger and if the DDT is used on them it wouldn’t kill them . . .
Interviewer:
Can you tell me a little bit more about how that [resistance] would happen, in general
Participant R:
. . . I was watching the discovery channel and there was a man who said he could
develop resistance to the venom of a snake . . . so he started to gradually use little bits
of this venom and started injecting venom into his system and from time to time he
would increase the amount of venom he took into his system . . . he got bitten by the
snake and to the surprise of the doctors this man actually had some kind of resistance
to that venom, in comparison to a normal person who would just die . . . my guess
would be that at ﬁrst the mosquitoes . . . from time to time they kept exposing them to
this kind of chemical . . . those will develop some kind of resistance to this kind of
chemical for them to survive.
Interviewer:
This guy who was injecting the snake venom . . . would one of his children or a certain
percentage of his children also be resistant to the venom/immunity thing?
Participant R:
They might be, but not all the way . . . as he got a resistance.
Interviewer:
Participant R:
. . . If we consider the fact that they are children and their immune systems are not that
strong, but if we compared them to the same age children . . . if you compare both
sides they will have a little bit of resistance.
Interviewer:
His family’s kids might have not as much as he has, but they will have more than a
group of kids that got none?
Participant R:
Interviewer:
Back to the DDT example . . . Do you think before DDT was invented, whatever was
different about the mosquitoes who didn’t die when they were exposed to DDT, were
they different back then, or did they just become different when they were exposed to
DDT . . . Did the DDT make some of them change?
Participant R:
When they introduced the chemical obviously it wouldn’t kill all of them . . .
Interviewer:
Participant R:
Well, in my house recently we had roaches . . . [we introduced bait] and to my surprise,
I mean, it reduced the percentage of the roach more than before I introduced the bait,
so I was kind of thinking, why didn’t it kill the entire race of roach? The partial
conclusion that I could draw is that maybe the places that I put the bait did not fully
expose the roach . . . maybe the ﬁrst batch that got introduced the bait got more of the
food . . . so as time went on the concentration went on . . . if the next batch of roaches
get exposed to it they might have a 50–50 chance of survival . . . just like this man
didn’t start off injecting a whole lot of venom into his system . . . that would be my
conclusion.
NEHM AND SCHONFELD
Journal of Research in Science Teaching
Collectively, all seven key concepts of natural selection documented in the ORI and CINS
were also mentioned by interviewees (Table 1, Figure 1). The CINS topics of ‘‘population stability’’ and
‘‘origin of species,’’ which are not considered key concepts of natural selection here, were not mentioned
by any interviewees. We also scored the number, percentage, and rank of 31 alternative conceptions
documented from the ORI and CINS in the interview sample. The percentages for each alternative
conception category were calculated relative to the total number of responses. Of the 38 alternative
conceptions documented in the interviews (Table 2) the three most common were alternative conception
#12 (‘‘use and disuse’’), alternative conception #18 (‘‘inheritance of acquired traits’’), and alternative
conception #24 (‘‘sensory compensation’’). The interviews elicited responses to only 50% of the
alternative conception categories that we explored. Additionally, no new categories of alternative
conceptions were discovered. Notably, the ten most commonly ranked alternative conceptions in the oral
interviews were identical to the ten most commonly ranked alternative conceptions in the ORI. Overall, the
oral interview results were most similar to the ORI, but they also shared a large number of commonalities to
Correlations among Instrument Variables
In order to determine whether the two paper-and-pencil instruments provided related measures
of natural selection knowledge and alternative conceptions, we calculated correlations among
several different measures derived from the ORI and the CINS. The NSPQ, which quantiﬁes ORI scores
on a single 0–100 scale using both key concepts and alternative conceptions, was signiﬁcantly correlated
with the overall CINS scores (i.e., the percentage of correct responses on a 0–100 scale; n ¼ 100, r ¼ 0.58,
p < 0.001). Several other measures also produced signiﬁcant correlations between the ORI and CINS.
CINS percentages were signiﬁcantly correlated with the ORI key concept diversity measure (see above;
n ¼ 100, r ¼ 0.61, p < 0.001). In addition, ORI alternative conception diversity (see above) was signiﬁcantly
correlated with the number of incorrect CINS responses (i.e., the number of alternative conception
distractors chosen; n ¼ 100, r ¼ 0.42, p < 0.001). In summary, the ORI and CINS appear to be measuring
related information using several different measures of both knowledge and alternative conceptions of natural
selection.
We considered the oral interview to be the most meaningful, detailed, and thorough analysis of student
knowledge. Correlations between the oral interview scores and the paper-and-pencil instruments were
performed tovalidate instrument measures. In the correlational analyses involvingthe oral interview, we used
one-tailed statistical tests in view of the lack of power given the 18 undergraduates who were interviewed.
Likethe pattern found in the larger sample, the correlation between the NSPQ and CINS percentage scorewas
signiﬁcant using the smaller sample of interview subjects alone (n ¼ 18, r ¼ 0.45, p < 0.05). Similarly, the
oral interview score was signiﬁcantly correlated to both the NSPQ score (n ¼ 18, r ¼ 0.74, p < 0.01) and the
CINS percentage score (r ¼ 0.68, n ¼ 18, p < 0.01). The rock test (see above), which was administered to all
interview participants and used for discriminant validity purposes, was not signiﬁcantly correlated with any
knowledge or alternative conception measure (0.30 < r < 0.19).
Discussion
Despite a growing body of research in evolution education, comparatively little attention has been
directed towards the rigorous development and evaluation of instruments that measure knowledge of and
alternative conceptions about evolution and natural selection in learners of different ages and
educational backgrounds . We used three different
methods, the CINS, the ORI essay test, and an oral interview, to assess biology majors’ understanding
of and alternative conceptions about natural selection, as well as the validity and reliability of
each approach (Table 10). Overall, both the ORI and CINS could serve as replacements for the laborintensive process of oral interviews. Both produced comparable measures of key concept diversity and,
to a lesser extent, key concept frequency. By contrast, the ORI and CINS provided clearly different
assessments of both alternative conception diversity and frequency, with the ORI producing a richer
description of alternative conception diversity. Regarding key concepts, the ORI results were
completely concordant with oral interview results. Both the CINS and the ORI included items that could
MEASURING KNOWLEDGE OF NATURAL SELECTION
Journal of Research in Science Teaching
Summary table comparing aspects of the three methods for measuring student knowledge and alternative conceptions of natural selection
Oral interview
Reliability
Strong support. Scorer reliability
established for key concepts and
misconceptions
Strong support. Scorer reliability established
for key concepts and misconceptions
Moderate support. Acceptable alpha
coefﬁcient. Rasch analysis measures also
indicate acceptable reliability
Strong support. Content validity.
Convergent validity evidence
includes signiﬁcant correlations with ORI
Discriminant validity evident by
non-signiﬁcant correlation
with rock test scores
Strong support. Content validity. Convergent
validity evidence includes ORI NSPQ scores
being signiﬁcantly correlated with both CINS
scores and oral interview scores. Discriminant
validity evident by
non-signiﬁcant correlation with rock
test scores
Strong support. Content validity.
Convergent validity evidence includes
CINS scores signiﬁcantly correlated with
both ORI NSPQ scores and oral interview
scores. Discriminant validity evident by
non-signiﬁcant correlation with rock test
Item characteristics
Not applicable
Low discriminability and high difﬁculty
characterize several questions; ‘‘speeding up’’
question too difﬁcult for sample
Low discriminability and high difﬁculty
characterize many questions; no
questions distinguish among high
performers; parallel concept questions
differ greatly in difﬁculty; too many items
of equivalent difﬁculty
Measurement of key
concepts of natural
All seven key concepts documented;
frequencies most similar to ORI
All seven key concepts documented;
frequencies most similar to oral
interview results
All seven key concepts documented;
frequencies least similar to other measures
Measurement of
misconceptions of
natural selection
Universe of misconceptions signiﬁcantly
smaller than found using the CINS,
but excellent concordance with ORI results
Universe of misconceptions signiﬁcantly smaller
than found using CINS, but
excellent concordance with oral
interview results
Greatest diversity of misconceptions
documented, but poor concordance with
both ORI and oral interview patterns
Instrument strengths
All concepts and misconceptions were
captured by the ORI and CINS
Appears to document extant misconceptions most
accurately. Provides results most similar to an
oral interview
Documents key concepts most efﬁciently
Instrument weaknesses
Omission errors problematic; interpretation
of responses can be difﬁcult but this can
be mitigated by scorer practice with a rubric
May not accurately represent the extent of
misconceptions. Permits guessing
Implementation strengths
Rapid results, scoring, and interpretation
Implementation
weaknesses
Highly impractical for use in large samples
Impractical for use in large samples
NEHM AND SCHONFELD
Journal of Research in Science Teaching
be characterized by (a) low discriminability, (b) high overlapping difﬁculty, and (c) mismatches with the
Criticisms of the Bishop and Anderson Test
Anderson et al. provided a series of criticisms of Bishop and Anderson’s openresponse instrument and used these criticisms as justiﬁcation for the development of the CINS. Overall,
Anderson et al. criticized the Bishop and Anderson instrument items as being: (1) simple; (2) hypothetical;
(3) abstract; (4) and unable to probe student understanding of ecological and genetic principles central to
natural selection. If these criticisms were justiﬁed, one would expect that compared to the CINS the Open
Response Instrument (ORI), which is largely derived from the Bishop and Anderson test, would provide
comparatively less reliable and valid information about undergraduate students’ knowledge and alternative
conceptions of natural selection. We explored this question empirically and were not able to support
Anderson et al.’s argument: both the CINS and ORI produced comparable and complementary measures of
students’ knowledge of natural selection. No data in our study provided clear evidence for the superiority of
Our study did provide, however, evidence that calls into question some of Anderson et al.’s criticisms of
the Bishop and Anderson instrument. First, based on high difﬁculty scores for individual questions and the
marginal composite instrument scores from our two samples (i.e., the NSPQ, key concept diversity, and
alternativeconception diversity),it appears that the ORI isnot simple,butrather issufﬁcientlychallenging for
college biology majors. Second, we found ample evidence that the ecological and genetic principles that
underlie the theory of natural selection were indeed elicited by the ORI. All seven ‘‘key concepts’’ of natural
selection were documented using the ORI; these included the causes of phenotypic variation (such as
mutation and recombination) and ecological principles (such as competition and differential survival based
on resources; Table 1, Figure 1). Thus, the criticisms of both simplicity and the inability to elicit fundamental
principles were not supported by our study.
We regard the remaining two criticisms of the Bishop and Anderson test—being hypothetical and
abstract—as potentially accurate but likewise characteristic of Anderson et al.’s CINS. Forexample, when we
consider an individual concept on the CINS, such as the differential survival of guppies intropical streams, we
wonder whether having a student read a paragraph about guppies makes the subsequent questions about them
less hypothetical or abstract relative to, for example, the differential survival of cheetahs on the African
savannah (discussed in the ORI). Although neither we nor Anderson et al. investigated this question
empirically, we consider the contemplation and explanation of all evolutionary scenarios to be necessarily
abstract because they involve the simultaneous consideration of multiple variables in contexts in which
students typically have had no direct experience. Additionally, both the ORI and CINS prompt students to
ponder evolutionary patterns and processes that occur during timescales that are often inaccessible to direct
observation and, more importantly, beyond student contemplation (i.e., hundreds, thousands, or millions of
years). The CINS questions do, however, deal with evolutionary scenarios likely taking place over shorter
timescales than those discussed in the ORI. Nevertheless, we argue that the Bishop and Anderson 
essay test is not unique in prompting students to answer hypothetical and abstract questions, regardless of
whether the questions are based on hypothetical or abstract exemplars. It may be argued, however, that using
hypothetical questions that parallel actual situations, but vary from them in signiﬁcant ways, have the
potential to be misleading and could actually reinforce or propagate alternative conceptions among students.
No studies to our knowledge have investigated this issue. In summary, we ﬁnd, at best, some support for
Anderson et al.’s criticisms of the Bishop and Anderson instrument butarguethat some of their criticisms may
also apply in to the CINS.
Validation of the CINS
Anderson et al. used correlations between scores obtained from seven oral interviews and overall
CINS scores as their primary method for validating their instrument. While this small sample size is
troublesome, primarily because it is the only evidence supportive of thevalidity of their instrument, exclusive
of response patterns themselves. We found Anderson et al.’s interpretation of their oral interview data
problematic. On page 966, for example, Anderson et al. report that:
MEASURING KNOWLEDGE OF NATURAL SELECTION
Journal of Research in Science Teaching
‘‘We were encouraged by our ﬁnding that the seven undergraduate biology majors whom we
interviewed all demonstrated an accurate understanding of natural selection. This suggests to us that it
is possible for students to learn about natural selection and that we should be much more successful
than we currently are with nonmajors.’’
Table 2 in Anderson et al. lists the seven participants’ interview scores and CINS scores.
Interview scores were calculated by coding post-interview transcripts for correct and incorrect ‘‘utterances.’’
According to Anderson et al.’s Table 2, 43% (3/7) of participants received what can only be interpreted as
failing scores on the interview and 57% (4/7) received failing scores on the CINS. Thus, it is unclear why
Anderson et al. considered these students to have an ‘‘accurate understanding of natural selection’’ or
why they were ‘‘encouraged’’ by this result. Additionally, in the abstract of their paper, Anderson et al. indicate that these seven students were non-majors, whereas the above quote suggests that these seven
students were biology majors. If other sources of instrument validation were provided, these confusing
interpretations would be less troubling. Anderson et al.’s use of only seven student interviews to validate the
CINS, and the confusing interpretation of these data, spurred us to investigate the validity of the CINS more
rigorously.
A ﬁnal issue of concern with the validation of the CINS was the absence of evidence of discriminant
validity. Instrument validation typically requires demonstrating that measures not hypothesized to be related
to the measured construct are in fact not signiﬁcantly correlated to scores derived from instrument responses.
In other words, discriminant evidence supports the interpretation that the wrong construct is not being
measured . Because Anderson et al. did not provide evidence
regarding discriminant validity in their validation of the CINS, our study used a closed-response test about
rocks to establish discriminant evidence for both the CINS and the ORI (Table 10).
Comparing and Contrasting the CINS, ORI, and Interview
Figure 2 visually illustrates the concordance of key concept and alternative conception elicitation from
among the CINS, ORI, and oral interview data. Figure 2 demonstrates the excellent concordance of key
concept elicitation using all three methods. As the ﬁgure shows, all three methods elicited the same seven key
concepts of natural selection. This result validates the inference that the three methodologies captured
information about the same construct, and indicated that, in general, the method of elicitation was not
correlated to the content extracted. However, as Figure 1 illustrates, the magnitudes of participant responses
did differ markedly in some cases (e.g., ‘‘limited survival’’ was mentioned by the undergraduates in nearly
80% of CINS responses but in only 30% of interview responses). Thus, while the CINS, ORI, and oral
interview elicit the same types of knowledge among respondents, they do not always reﬂect different strands
of knowledge to the same degree. Taking into consideration the effort required to execute, score, and interpret
the ORI and oral interview data, our results indicate that the CINS would be the most efﬁcient method for
measuring knowledge of the keyconcepts of natural selection in the sample of biology majors that we studied.
These results also indicate that the CINS may, however, overestimate students’ working knowledge of the key
concepts of natural selection (Figure 1).
Unlike the results for key concepts, alternative conception elicitation was signiﬁcantly related to
methodology (Figure 2). Only ﬁve of the same alternative conceptions (of 31) were uncovered by all three
methods (alternative conceptions 1, 6, 8, 12, and 18; see Table 2). Notably, the oral interviews did not elicit
any unique alternative conceptions (Figure 2). Overall, however, the oral interview alternative conception
magnitudes were most similar to the ORI responses (Table 2). In terms of alternative conceptions
uncovered, the oral interview provided equivalent construct concordance with the ORI and CINS; that is,
three alternative conceptions, although not the same three, were elicited by both the instrument and the ORI
and CINS (Figure 2).
Used together, the paper-and-pencil ORI and CINS appear to provide an excellent replacement for
the time-consuming process of oral interviews. While the two paper-and-pencil instruments provided
generally comparable measures of the key concepts of natural selection, they did not provide equivalent
measures of alternative conception diversity or magnitude. Until a new instrument is developed, we
recommend that both the CINS and ORI be used to measure the distribution and magnitude of alternative
conceptions.
NEHM AND SCHONFELD
Journal of Research in Science Teaching
Criterion-Referenced Nature of the CINS
Anderson et al. noted (p. 959) that the CINS is a criterion-referenced test. Although Anderson
et al. demonstrated a degree of content validity for the CINS, they did not adduce evidence that the CINS
possessed other key properties of criterion-referenced tests. For example, a key property of criterionreferenced tests is their capacity to document growth in student knowledge over the course of a period that
starts before a learning experience begins (e.g., prior to a learning module devoted to natural selection) and
ends once the learning experience concludes (e.g., at the conclusion of the natural selection module). Validity
research on a criterion-referenced test could be enhanced with a control group that is not exposed to
the target learning experience . Anderson et al. provide no validity evidence bearing on
the sensitivity of the CINS to growth in knowledge of natural selection. By contrast, Nehm and
Schonfeld demonstrated that an essay test adapted from Bishop and Anderson is sensitive to
knowledge growth.
Criterion-referenced testing downplays psychometric reliability because psychometric reliability
depends on between- and within-person variance components, as those components bear on the test’s ability
to consistently discriminate among individuals . Since criterion-referenced testing anticipates
little pretest variance (most students displaying below-standard performance) and little post-test variance
(most students displaying above-standard performance), reliability in this context is reasonably evaluated
with alternate forms assessing pre-to-post-test gains. Anderson et al. provide no evidence bearing on
this particular type of reliability. By contrast, Nehm and Schonfeld demonstrated consistency in preto-post-course gains using alternate measures of knowledge of natural selection (and concomitant reductions
in alternative conceptions). Finally, creators of criterion-referenced tests typically create a cut-off or standard
score that reﬂects appropriate mastery of the knowledge taught. Anderson et al. did not provide such a
score. By contrast, Nehm and Reilly , using an adaptation of Bishop and Anderson’s test,
arrived at a cut-off score that reﬂected a minimum level of understanding of natural selection.
Carver pointed outthat a criterion-referenced test ‘‘may be referenced to anormativegroup,and a
norm-referenced test, to a criterion’’ (p. 512). Millman and Popham indicated that criterionreferenced tests have conventional psychometric uses such as predictive validity. Moreover, estimates of
A Venn diagram illustrating the distribution of key concepts and alternative conceptions elicited among the
CINS, ORI, and oral interview. See Table 1 for key concept number descriptions and Table 2 for alternative conception
numberdescriptions. * ¼ not considered a key conceptof naturalselection in thisstudy, butconsideredassuch by Anderson
et al. .
MEASURING KNOWLEDGE OF NATURAL SELECTION
Journal of Research in Science Teaching
variance for reliability purposes are suitable to criterion-referenced tests such as the CINS .
Haladyna underlined the point that educators who use criterion-referenced tests should be concerned
with psychometric reliability because errors of measurement can cloud the educators’ ability to distinguish
true passes, false positives, true fails, and misclassiﬁed fails, particularly among students who score near the
cut-off. Although the current paper was not directly concerned with the CINS as a criterion-referenced test,
the paper’s focus on the test’s psychometric properties provides a foundation for future research on the CINS
‘‘edumetric’’ properties.
Instrument Format and Knowledge Measures
Considering that the same student population was used to measure evolutionary knowledge, the
differences in knowledge and alternative conception scores that we document may be a result of different
question formats (i.e., open- vs. closed-response). Bridgeman outlined the three major
advantages toopen-response test items: (1) reductionof measurement error associated with random guessing;
(2) elimination of unintended corrective feedback, that is, if an expected correct answer is not present among
the items, the student knows that a change in strategy is required to solve the problem; and (3) problems
cannot be solved by working backwards from the answers.
Research has also demonstrated that open-response items may measure different cognitive
characteristics than closed-response items. Traub and MacRury , for example, in their literature
review pertaining to proﬁciency measurement using open- and closed-response testing, concluded that the
reasons for differences between the two approaches were not clear, and recommended that both item types
be used in knowledge assessment. Traub and MacRury went on to argue that one should not assume that
both methods assess the same cognitive abilities. Likewise, Kuechler and Simkin found that openand closed-response items on computer programming exams did not correlate highly, and likely tested
different cognitive processes. Collectively, this work argues for the inclusion of open-response items in
knowledge assessments.
In contrast, other work calls into question the beneﬁts of open-response test items. Lukhele, Thissen, and
Wainer , for example, found that the College Board’s AP chemistry and history tests’ open-response
questions added little information beyond that provided by the multiple-choice sections. Lukhele et al. 
went on to question the basic premise that open-response items are more useful and meaningful than multiplechoice items. In a quantitative meta-analysis of construct equivalence, Rodriguez found that when
stem-equivalent items are employed, multiple-choice and constructed response measures tend to correlate
highly. Likewise, Bridgeman found that despite differences in format, open- and closedresponse items produced ‘‘remarkably similar correlational patterns.’’ Overall, there is evidence that openresponse items themselves may not provide more meaningful measures of knowledge; aspects of the
questions themselves may account for these differences.
Educators who favor essay tests look to advantages that include the test’s usefulness in assessing the
student’s ability to relate facts and principles to each other, organize knowledge, and write in clear, accurate
prose. These advantages do not come without costs. First, time is a premium, and frequently students have
insufﬁcient time to demonstrate the above abilities. Second, compared to multiple-choice tests, essay tests
tend to be less economical and less efﬁciently scored . Third, Anastasi pointed out that
because the student writes an essay for a teacher who presumably knows much more about the details of the
subject matter than the student, there is a tendency for the student to develop an approach to writing in which
obscure ideas are written in a telescoped style that is accessible to the teacher; that style unfortunately carries
overto the student’s writing for the general reader. Fourth, although this can be mitigated by the application of
rubrics and other strategies, there is greater subjectivity in scoring essays than in scoring multiple-choice
tests. Fifth, students prefer multiple-choice tests to essay tests . Sixth, constructed-response
tests, including essay tests, compare less favorably to multiple-choice tests in terms of predictive validity
 .
In summary, while there is no consensus on the equivalency of open- and closed-response items, it is
clear that equivalent measures may in some cases be derived using different item formats, and that the greater
similarity between items (i.e., stem equivalency) increases the degree of correlation between measures
NEHM AND SCHONFELD
Journal of Research in Science Teaching
derived from them. The CINS and ORI did not share stem-equivalent questions or formats, and this difference
alone may account for the discrepancies between the results that we document.
Practical Considerations
Many of the advantages and disadvantages of open- and closed-response instruments outlined by
Kuechler and Simkin apply to the CINS and ORI. In our study using the CINS, we found that a
large sample (100) may be scored and analyzed in about an hour, whereas scoring a comparable sample of
open-response instruments requires more than 20 hours. Additionally, scoring the ORI requires considerable
expertise and training, even with a well-designed grading rubric. To ensure the reliability of essay scoring, the
ORI also requires two graders, which adds additional time, effort, and training. Finally, in order to calculate
knowledge and alternative conception measures (e.g., the NSPQ and diversity scores), the ORI requires data
entry and statistical analyses.
The ORI carries additional and more serious disadvantages than time. Students’ aversion to writing may
in some cases lead to limited responses or errors of omission, and poor writing skills may hamper clear
communication, preventing the instructor from recognizing the extent of the student’s knowledge; both
situations will produce scores that inaccurately reﬂect student knowledge. Additionally, because of the time
required to construct responses to the ORI, it is not possible to test a broad array of content knowledge.
Collectively, these factors are likely to deter researchers from implementing the ORI in large samples.
In addition to the general limitations of open-response instruments discussed above, several speciﬁc
limitations were found to characterize the ORI. Several questions had marginal discriminability and high
difﬁculty (Table 5), and the ‘‘speeding-up evolution’’ question appeared to be particularly challenging for the
ﬁrst-year biology majors in our sample (Table 5). Thus, in the student population studied here, the ORI
appears to have intrinsic limitations. It is important to point out that relaxing the benchmark of three key
concepts, which Nehm and Reilly considered to be indicative of understanding natural selection, and
relaxing the benchmark of one alternative conception as being indicative of a wrong answer, would
signiﬁcantly alter both discriminability and difﬁculty values and thereby modify this interpretation.
Nevertheless, relaxing the scoring benchmarks would not transform the ORI into a signiﬁcantly less difﬁcult
test for the biology majors that we studied.
CINS Difﬁculty and Appropriate Populations for Testing
The CINS was originally designed to be of use in measuring knowledge of and alternative conceptions
about natural selection in undergraduate non-majors, but we found it to be well-suited to our sample of ﬁrstyear biology majors. This interpretation is also in linewith data from the original CINS study, wherevery-low
average CINS scores were reported for undergraduate non-majors . Indeed, the
average scores for non-majors in the two samples Anderson et al. studied were failing (41/100, n ¼ 110, and
52/100, n ¼ 96). Although Anderson et al. concluded that their test was well-suited for non-majors,
the average performance scores for their samples, in combination with the marginal CINS scores reported in
the present study of majors, suggest that their instrument may be better suited for ﬁrst-year biology majors.
The marginal discriminability and moderate difﬁculty of many CINS questions documented in our study (and
several items in Anderson et al.’s original study), suggest that this test is very difﬁcult for undergraduate nonmajors.
The Rasch analyses performed here also provide useful information on the ﬁt between the instrument
items and the samplewho took it.As Table 9 illustrates, the biology majorsin our samples arewell-matched to
the distribution of items. The Rasch analyses also provide useful information on the difﬁculty of particular
CINS items and how the instrument could be improved. Speciﬁcally, many questions of redundant difﬁculty
(e.g., items 8 and 12) could be altered to provide a more precise measure of student knowledge using this
instrument. Likewise, if the test is used to measure knowledge in ﬁrst-year biology majors similar to those
studied here, questions that differentiate high performing students will need to be added.
Finally, some researchers may be inclined to use pairs of CINS items that measure the same key concept
of natural selection (e.g., items 2 and 14 concerning ‘‘population stability’’) to measure pre-post-knowledge
gains associated with particular instructional interventions. This inclination should not be acted upon,
however, as the Rasch analysis revealed that parallel items about the same key concepts of natural selection
MEASURING KNOWLEDGE OF NATURAL SELECTION
Journal of Research in Science Teaching
(e.g., items 2 and 14) have greatly different difﬁculty levels. Thus, dividing these parallel pairs of questions
into pre- and post-tests could signiﬁcantly bias learning gain measures. Likewise, the ‘‘salamander’’ and
‘‘cheetah’’ questions from the ORI are also not of comparable difﬁculty, and are therefore not well-suited for
pre-post-testing. In contrast, the bacteria and cheetah questions are most comparable. It would beworthwhile,
however, to develop parallel pairs of CINS items of comparable difﬁculty about the same key concepts of
natural selection for use in pre-post-testing. Likewise, developing a new question of comparable difﬁculty to
the ORI ‘‘salamander’’ question would be beneﬁcial.
Knowledge, Alternative Conceptions, and Sociocultural Contexts
Longstanding work in education and cognition has indicated that science understanding emerges from
complex interactions in localized social, cultural, linguistic, and naturalistic contexts . It has also been shown, however, that some alternative conceptions in science are
widespread and transcend particular racial, cultural, and naturalistic contexts . Because ours is the ﬁrst to study knowledge and alternative
conceptions of natural selection in a sample comprised primarily of underrepresented minorities, it provides
an opportunity to explore whether knowledge and alternative conceptions of natural selection that have been
extensively documented in primarily white, middle-class samples are in fact more widespread .
Overall,our results suggest that while the magnitudes ofalternativeconceptions ofnatural selection may
differ among students from different cultural, ethnic and/or class backgrounds, in most instances the
alternative conceptions themselves do not. For example, Nehm and Schonfeld’s study of 44 biology
teachers, most of whom were not from underrepresented groups, displayed all of the alternative conceptions
documented in the present study. Bishop and Anderson’s study sample, Anderson et al.’s study
sample, and many other samples also comprised mostly white non-Hispanic students, and they likewise documented many of the
alternative conceptions uncovered here. Finally, while the results of this study suggest that alternative
conceptions of natural selection transcend racial, ethnic and/or class boundaries, they do not imply that the
same pedagogical strategies and curricular frameworks will be equally effective for ameliorating alternative
conceptions of natural selection in these different student populations.