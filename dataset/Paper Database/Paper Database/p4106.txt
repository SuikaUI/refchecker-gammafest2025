Leveraging Domain Knowledge in
Multitask Bayesian Network Structure Learning
Diane Oyen and Terran Lane
Department of Computer Science
University of New Mexico
Network structure learning algorithms have aided network discovery in ﬁelds such as bioinformatics, neuroscience, ecology and social science. However, challenges remain in learning informative networks for related sets of tasks because the search space of Bayesian
network structures is characterized by large basins
of approximately equivalent solutions. Multitask algorithms select a set of networks that are near each other
in the search space, rather than a score-equivalent set
of networks chosen from independent regions of the
space. This selection preference allows a domain expert to see only differences supported by the data. However, the usefulness of these algorithms for scientiﬁc
datasets is limited because existing algorithms naively
assume that all pairs of tasks are equally related. We
introduce a framework that relaxes this assumption by
incorporating domain knowledge about task-relatedness
into the learning objective. Using our framework, we introduce the ﬁrst multitask Bayesian network algorithm
that leverages domain knowledge about the relatedness
of tasks. We use our algorithm to explore the effect of
task-relatedness on network discovery and show that
our algorithm learns networks that are closer to ground
truth than naive algorithms and that our algorithm discovers patterns that are interesting.
Introduction
Scientists in domains such as neuroscience use network
structure learning algorithms to discover patterns of interaction in multivariate data. For these datasets, multitask learning algorithms learn robust models even when the number
of data samples collected in a speciﬁc task are limited, but
there are several tasks that are believed to be similar . For example, in group neuroimaging studies, we learn functional brain networks for several
populations of subjects and treat the data from each population as a task. We expect the population-speciﬁc networks
to have a lot in common but not to be identical. Furthermore, we may be able to describe relationships between the
populations, such as a study of functional brain networks for
populations of different ages of subjects. The groups that are
close in age should have the most similar networks.
Copyright c⃝2012, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.
Our goal is to learn the best set of networks that are interesting to the domain expert. The concept of incorporating
human preferences into unsupervised learning objectives is
an active research trajectory in clustering and topic modeling . In these unsupervised learning problems data-driven measures of goodness of the learned model are insufﬁcient and can only be
addressed by incorporating human objectives. We bring this
concept to network structure learning. The search space of
Bayesian network structures is characterized by large basins
of approximately equivalent solutions . Multitask algorithms provide a ﬁrst step toward incorporating a human bias by selecting a set of networks that
are near each other in the search space, rather than a scoreequivalent set of networks chosen from independent regions
of the space .
Existing multitask methods for unsupervised problems
typically assume that all pairs of tasks are equally related.
This assumption makes these algorithms too rigid to handle datasets where different pairs of tasks have widely varying degrees of task-relatedness. Furthermore, they provide
no mechanism for incorporating human objectives for taskrelatedness. A few specialized multitask network discovery applications have recently incorporated speciﬁc domain
knowledge about task-relatedness .
We introduce a framework for multitask structure learning
that relaxes the assumption that tasks are equally related. In
many applications we have prior beliefs about the relatedness of tasks based on metadata or domain expert knowledge. Using our framework, we develop the ﬁrst multitask
Bayesian network structure learning algorithm to incorporate task-relatedness as a parameter. With our algorithm we
explore various factors in the problem space: the number of
tasks, the true similarity between tasks, and the topology of
task-relatedness. We compare the performance of our algorithm with naive algorithms (those without task-relatedness
knowledge). We ﬁnd that our algorithm generalizes to validation data and ﬁts ground truth better than naive algorithms.
Finally, we learn functional brain networks from neuroimaging data with our Bayesian network algorithm. For
a given pool of subjects, there are a number of “natural”
task divisions (e.g, pooling by age or by medication). We
Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence
explore different divisions of subjects into tasks, with corresponding task relatedness metrics and discuss the interesting
patterns found by our algorithm. Domain knowledge about
task-relatedness improves both the robustness of learned
networks and addresses human objectives.
Related Work
Multitask learning algorithms generally represent the similarity among tasks in one of three ways: all tasks are assumed to be equally similar ; the similarity among tasks is estimated
from the same data that is used to train the model ; or the
similarity between tasks is provided by another source such
as task-speciﬁc domain information or an expert . This third option, which we apply to
network discovery, has been used successfully for zeroshot classiﬁcation problems when no training data are available for certain tasks .
Multitask learning has been applied to learn Gaussian
graphical models and Bayesian
networks . Unlike our framework, these models assume that all tasks are equally related. There is recent work
in specialized application-speciﬁc algorithms that share information only between tasks that are believed to be most
similar . These applications demonstrate the beneﬁt of domain knowledge.
Preliminaries: Multitask Structure Learning
Probabilistic graphical models compactly describe joint
probability distributions by encoding independencies in
multivariate data. Multitask learning enforces a bias toward
learning similar independency patterns among tasks.
A Bayesian network B = {G, θ} describes the joint
probability distribution over n random variables X
[X1, X2, . . . , Xn], where G is a directed acyclic graph and
the conditional probability distributions are parameterized
by θ . An edge
(Xi, Xj) in G means that the child Xj is conditionally independent of all non-descendants given its parent Xi. A
Markov random ﬁeld (MRF) encodes similar conditional independencies with an undirected graphical model . The structure of the network, G, is
of particular interest in many domains as it is easy to interpret and gives valuable information about the interaction of
variables.
A set of tasks with data sets Dk and networks Gk for k ∈
{1, . . . , K} can be learned by optimizing:
P(G1:K|D1:K) ∝P(D1:K|G1:K)P(G1:K)
Breaking this into independent single-task learning problems (STL) assumes all tasks are independent of each other,
which simpliﬁes Equation 1 to:
PSTL(G1:K|D1:K) ∝QK
k=1P(Dk|Gk)P(Gk)
Multitask learning (MTL) does not assume that tasks
are independent, however it does generally assume that
P(Dk|Gk) is independent of all other Gi so Equation 1 simpliﬁes to:
PMTL(G1:K|D1:K) ∝P(G1:K)QK
k=1P(Dk|Gk)
In multitask learning, the joint structure prior, P(G1:K),
is used to encode a bias toward similar structures. We can
break down this joint distribution into a product of conditionals, so that P(G1:K) = P(G1) QK
i=2 P(Gi|G1:i−1).
Many multitask algorithms (including those outlined in
this paper), make a further simplifying assumption that
P(Gk|G1:k−1) = Qk−1
i=1 P(Gk|Gi). That is, the joint prior
over structures can be described by pairwise sharing of information among tasks:
Task-Relatedness Aware Multitask Learning
We introduce our general framework for incorporating prior
knowledge about task-relatedness in multitask structure
learning. The goal is to include a weighting scheme for the
amount of information sharing between different pairs of
tasks. First, we deﬁne a symmetric matrix, µ, of size K ×K
where each element, µij ≥0, describes prior information
about the degree of relatedness between tasks i and j. These
values come from a task-relatedness metric that describes
the degree of relatedness of pairs of tasks. We ﬁnd it more
convenient to work with the inverse of the metric so that
µij = 0 means that the tasks are independent, and large values of µij mean a high degree of relatedness. Then, using the
general description of the joint prior over network structure,
in Equation 2, we use µ to weight the transfer bias among
pairs of tasks. With this additional input about the relatedness of tasks, the new Task-Relatedness Aware Multitask
objective (TRAM) to maximize is:
PTRAM (G1:K|D1:K, µ) ∝P(G1:K|µ)
P(G1:K|µ) ≜1
i=2 P(Gi) Qi−1
j=1P(Gi|Gj)µij
Key beneﬁts of the TRAM framework are:
• Introduces a task relatedness metric which allows explicit
control of information sharing between tasks.
• Subsumes MTL (all elements of µ are 1) and STL (all
elements of µ are 0).
• Includes existing application-speciﬁc models as discussed
in the Special Cases section.
• Provides convenient mechanism for incorporating taskrelatedness in multitask network structure learner, such as
our Bayesian network learner discussed in the next section.
This framework is general enough to cover any network discovery algorithm that enforces bias between pairs
of tasks. Extensions would be required to cover higherorder relationships among tasks, such as describing taskrelatedness as a Markov random ﬁeld with appropriate
higher-order potential functions to penalize differences
among related tasks.
Multitask Learning of Bayesian Networks
Our novel task-relatedness aware multitask Bayesian network structure learning algorithm illustrates the use
of the framework. To apply the objective function in
Equation 3 to multitask Bayesian networks we deﬁne
P(Di|Gi) as the Bayesian likelihood score P(D|G) =
P(D|G, θ)P(θ|G)dθ. The prior over structures encodes
the bias toward similar structures by penalizing differences
in edges among tasks:
P(Gi|Gj) ≜
(1 −α)∆(Gi,Gj)
where ∆is a graph distance metric. The parameter α ∈ 
controls the relative strength of ﬁt to data versus bias toward
similar models. When α = 0, the objective function is equivalent to learning the tasks independently. When α = 1 the
only solutions that produce a non-zero probability are those
in which ∆(Gi, Gj) = 0, in other words all structures must
be identical. The parameters are always inferred independently for each task.
Any graph distance metric can be used for ∆depending on the desired deﬁnition of structure similarity. If all Di
come from analogous random variables, the distance metric
can be a simple graph edit distance. In our experiments, we
use edit distance (the number of edge additions, deletions or
reversals necessary to change Gi into Gj).
Optimization of the multitask Bayesian network structure
learning objective proceeds by searching over the space of
DAG for a high-scoring set of DAGs. We follow a commonly
used search heuristic, greedy search, which starts from an
initial structure and then iteratively makes the best change
(edge addition, deletion or reversal) to the network structure until no further improvements can be made. The best
change is the one that gives the greatest improvement in
score. We are optimizing several network structures simultaneously, therefore one edge in each task can be changed
at each iteration. Incorporating the task-relatedness metric
does not incur any computational cost above standard multitask learning.
Special Cases
application-speciﬁc examples from the literature. The dynamic Bayesian network structure learning algorithms with
inter-time segment sharing in Husmeier, Dondelinger, and
L`ebre and Dondelinger, L`ebre, and Husmeier can be written using the TRAM framework
as follows. Each time segment is a task i for which they
learn a graph Gi that is biased toward having a similar structure to the previous time segment, Gi−1. The structure prior
is P(G1:K) = P(G1) QK
i=2(1/Zi) exp(−β∆(Gi, Gi−1)),
where β is a hyper-parameter and ∆(Gi, Gj) is the Hamming distance between edge sets. To ﬁt into our framework,
we write the prior according to Equation 3 with the taskrelatedness metric deﬁned as µij = 1 for i = {2 . . . K} and
j = i −1, and µij = 0 otherwise.
Experiments on Synthetic and fMRI Data
We empirically evaluate our TRAM Bayesian network
learning algorithm on synthetic and real-world data. For
comparison, we also learn each network independently with
single-task learning (STL) and learn a single network structure for all contexts (AVG), so named because this assumes
that there is some “average” network that is representative of
all tasks. Note, AVG learns the same structure for all tasks,
but that the parameters are independent of the other tasks.
We also compare against a standard multitask learning algorithm (MTL) that assumes all tasks are equally related (all
µij = 1) . For these experiments, we use greedy structure search, starting from an
empty network and use a Bayesian score. For TRAM and
MTL, we tune the strength parameter, α, with a small holdout set (10% of the training data). All reported results are
averaged over 10-fold cross validation.
Netsim Data
We use benchmark data from Smith et al. which is
generated from known networks to simulate rich realistic
functional magnetic resonance imaging (fMRI) data. They
generated the data using a hemodynamic response model
 . We quantize the given
continuous data into binary and ﬁt multinomial functions
when learning the networks. We use the benchmark data
for 50 synthetic subjects with 200 training samples per subject from 50-node networks. The given network structures
for all subjects are identical (the functional relationships between nodes are subject-speciﬁc) but we are interested in
models where the structure differs. Therefore, we modify
the structures by re-labeling various numbers of nodes for
some tasks and then combining those re-labelings for other
tasks. For example, at the top of Figure 1 the adjacency matrix for a given network is used as the ﬁrst task. To create a related task, we swap the node labels between a few
pairs of nodes thus changing some edges of the adjacency
matrix as seen in the next task. Re-labeling produces isomorphic networks, so that we can use the data provided and
maintain the general properties of each network while giving
different-looking network structures to the structure learning
algorithms. TRAM is not given the true measure of similarity between tasks, instead we set µij = 1 for each pair of
tasks i, j with an edge in the task-relatedness topology, and
0 otherwise.
Results for NetSim Data
We vary the number of differences between tasks, the number of tasks, and the topology of task-relatedness (see Figure 1). The second row of Figure 1 shows the average percent improvement in likelihood of holdout data for TRAM
Figure 1: NetSim data results. Top row: Our generated task-relatedness topologies. Each square node in the topology graph
represents a task. The square itself is an image of the adjacency matrix of the ground truth network where dots in the images
represent directed edges in the ground truth network. The lines between nodes in the task-relatedness topology indicate that the
two tasks are similar with µij = 1. Second row: TRAM’s percent improvement in likelihood on holdout data over STL, across
values of α for various levels of true task similarity (% changed). Third row: Similarity between tasks for the true networks and
learned networks from TRAM, MTL and STL for 8 tasks as measured by graph edit distance. White squares mean < 30, black
squares mean > 100. Fourth row: Edit distance (down is good) of learned networks to ground truth for the four algorithms for
2, 4, 6, and 8 tasks. Bottom row: Score of learned networks (up is good) for the four algorithms for 2, 4, 6, and 8 tasks.
over STL. On the x-axis, we vary the strength parameter α
on a log scale. When α = 0, the tasks are learned independently (the right end of the plot). As we move across the
plot to the left, the bias toward learning similar models increases until α = 1 at the left end of the plot, where all structures learned are identical to each other. Each line in the plot
corresponds to a generative process of node re-labeling that
changes the node label for the given percentage of nodes in
the network, where high percentages mean there are more
differences in the true networks between tasks. As expected,
the plots show that when the true networks are most similar
(8% changed), the performance gained by TRAM over STL
is greatest. As the number of true differences between networks increases, biasing the models toward each other is still
a large improvement over STL, but if the strength parameter
gets too high then performance degrades.
The bottom three rows of plots in Figure 1 compare the
performance of all algorithms on the datasets with 32%
of nodes relabeled (other results show similar trends and
are omitted for space). The row of grayscale images show
the similarity among task-speciﬁc networks as measured by
graph edit distance. For example, in the true networks for the
chain topology, we see that the ﬁrst task is increasingly dissimilar to the other tasks as we look across the the top row.
STL learns networks that are highly dissimilar to each other
while MTL and TRAM learn networks that are more similar,
reﬂecting the bias in these algorithms. TRAM is the only algorithm that reﬂects the patterns of task similarity given by
the true networks.
Perhaps more importantly, the bottom two rows of Figure 1 indicate that TRAM learns models that are as close
to ground truth as MTL and always better than STL and
AVG. We did not perform experiments on training set
size because existing literature has well documented that
Figure 2: Age groups. Bins of subjects grouped by age for 2, 4, 6,
and 16 tasks. Each box is a task; the width shows the age range and
the height shows the number of subjects in the task. The bottom
row is a histogram of all subjects.
multitask algorithms are most beneﬁcial on small datasets
 . The NetSim data provides 200 samples per task which we ﬁnd is insufﬁcient for
good single-task learning, making the data a good candidate for multitask learning. We ran experiments with smaller
amounts of training data and found those results to be consistent with existing literature.
Network Discovery in fMRI
Functional MRI measures the activation level of voxels in
the brain. Typically, hundreds of such images are collected
over the period of time that a subject is in the scanner. We use
data from a large schizophrenia study, where 384 volumes
are sampled per subject. Voxels are mapped into 150 regions
of interest (ROIs) based on the Talaraich atlas . The fMRI data for each ROI in each subject is
independently detrended and discretized into four levels of
activity. Thus, our data is 150 variables by 384 samples per
subject. We use the same algorithms as with NetSim.
Age-Groups as Tasks
A fundamental question for multitask learning in practice is
— how do we deﬁne a task? While we cannot fully answer
the question in this paper, we do explore how the number
of tasks for a ﬁxed dataset affect the performance of the
learned models. We experiment with dividing our dataset
into various numbers of tasks by grouping subjects into tasks
by age. We take 86 subjects from our dataset (the control
subjects in the schizophrenia study) and group them based
on the age of the subject. Figure 2 shows how we create
4 different learning problems by dividing the dataset into
2, 4, 8, and 16 tasks. The training data is the same across
these problems, but the number of tasks is different. We
deﬁne the task-relatedness values µij = e−(¯ai−¯aj)2/(2σ2)
where ¯ai is the average age of subjects in task i and σ2
is the variance of ages of all subjects. As an example,
µ1j = [1, .89, .67, .37, .18, .09, .03, .005] for the youngest
group (task 1) versus tasks j in order of increasing age for
8 tasks. For comparison, we also try binary-valued µ with
µij = 1 for pairs of tasks i, j that are adjacent to each other
in age-order and 0 otherwise.
Figure 3: Age data task similarity. Edit distance between
learned task-speciﬁc networks. White is <100, black is
Results from the age data are shown in Figures 4 and 3.
Plots 4(b) and 4(c) show TRAMbin and TRAM’s sensitivity
to the strength parameter α as measured by the improvement
in likelihood on test data versus STL. We see that both are an
improvement over STL but TRAMbin appears less sensitive
to α. AVG (the left edge of the plot at log(0)) actually causes
negative transfer that is increasingly bad as the number of
tasks grows. Therefore, some biasing of models helps, but
too much degrades performance.
The Figure 4(a) shows the overall comparison between algorithms of data likelihood on test data. Here, the strength
parameters of TRAMbin, TRAM and MTL have been tuned
on 10% of the training data. We see that splitting the dataset
into more tasks improves the performance of all algorithms,
even though the underlying dataset is the same. TRAMbin is
always the highest performing algorithm, with TRAM and
MTL close behind. The lines appear quite close, but the differences are signiﬁcant everywhere except between TRAMbin, TRAM and MTL for 2 and 4 tasks according to paired
t-tests at p=0.05. The improvement in performance of AVG
is somewhat surprising because tasks share the same structure. However, recall that the parameters of different tasks
are independent, therefore splitting data into tasks also allows AVG to ﬁt parameters to speciﬁc tasks.
Interestingly, TRAMbin and TRAM ﬁnd quite a few network edges that are different for the oldest age group than
for the others (see Figure 3). All algorithms ﬁnd more differences from the oldest group to the others, but for TRAM
and TRAMbin many of these edges exist with high robustness in the oldest group, but none of the others. Other edges
exist with high robustness in the younger groups but never
in the oldest group.
Tasks Deﬁned by Medication Type
Often we want to look at populations of subjects with a certain type of mental illness, but we expect that different drug
treatments will have an effect on brain activity. To address
this, we divide the subjects from the schizophrenia study into
7 tasks. One of the tasks is the group of control subjects. The
other tasks are schizophrenic patients divided into 6 groups
representing the medication they are taking (Figure 5).
(a) All algorithms
(b) TRAMbin
Figure 4: Age data. (a) Likelihood of holdout data. All differences between algorithms are signiﬁcant at p=.05 except for between TRAM,
TRAMbin and MTL at 2 and 4 tasks. (b) TRAMbin’s increase in performance over STL. (c) TRAM’s increase in performance over STL.
Figure 5: Task relatedness for Drug data. Each square is a task,
edges between tasks represent µ = 1.
Figure 6 shows improvement in data likelihood versus
STL. The improvement is greater for TRAM than MTL.
AVG always performs worst of all of the algorithms. As
expected, the improvement of TRAM over STL is greatest when there is the least data (Figure 6(b)). All algorithms
learn networks that show high variation between the control
group and all other tasks. The networks learned by TRAM in
particular show that networks for subjects on Clozapine type
drugs are most similar to those on drug combinations including Clozapine than they are to any other group. On the other
hand, for subjects on Typical type drugs TRAM learns brain
networks that are highly similar to all other groups.
Discussion and Future Work
Task-relatedness knowledge can improve both the robustness of learned networks and address human objectives. A
natural question is how to deﬁne the task-relatedness metric
µ. Previous application speciﬁc algorithms employed binary
task-relatedness weights. Our experiments support the intuition that binary weights that give the topology of tasks that
are directly related is preferable to ﬁne-tuning real-valued
weights. These ﬁndings warrant further investigation. A similar question is how fragile algorithms become when domain knowledge is poor. In practice, we found that using
a misleading µ causes TRAM to produce results equivalent
to MTL, which is not surprising because MTL is a case of
TRAM with a ﬁxed µ. Theoretical deﬁnitions of good taskrelatedness knowledge would be interesting future work.
Another important direction of research is to estimate
task-relatedness from data. However, the data-driven approach answers a different question than addressed in this
paper. Instead, TRAM is incorporating a human-speciﬁed
objective. This concept of incorporating human preferences
into learning objectives is an active research trajectory in
unsupervised learning . In these problems data-driven measures of goodness
of the learned model are insufﬁcient and can only be addressed by incorporating human objectives. We have introduced this concept to network structure learning.
Learning a large number of Bayesian network tasks ef-
ﬁciently is another direction for future work. Currently, no
multitask Bayesian network learning algorithm adequately
addresses this. Task-relatedness knowledge may be useful
to break up the problem into manageable-sized chunks. It
would also be interesting to investigate transferring bias
among only the parts of the Bayesian network model that
we are most interested in and allow a more efﬁcient independent search for other parts of the model.
Conclusion
We have shown that naive assumptions about taskrelatedness limit the effectiveness of multitask learning algorithms. Relaxing these assumptions in the objective function through a task-relatedness metric is a necessary step in
improving the performance of multitask network structure
learning algorithms. We introduced our general framework,
TRAM, for incorporating domain knowledge into multitask
network structure learning objectives. Our framework allows a natural and ﬂexible way to represent domain knowledge. Also, we presented a novel multitask Bayesian network structure learning algorithm with TRAM. Empirical
evaluation shows that leveraging domain knowledge produces models that are both robust and reﬂect a domain expert’s objective.
Acknowledgements
We would like to thank Vince Clark and the Mind Research
Network for providing data and introducing us to this in-
(a) Sensitivity curve
(b) Per-task improvement
Figure 6: Drug dataset results. (a) Increase in performance over
STL across values of the strength parameter for TRAM and MTL.
(b) Improvement over STL for tuned TRAM and MTL. Note tasks
are ordered by increasing number of subjects.
teresting problem. We are grateful to Eric Eaton and Vamsi
Potluru for discussions and feedback on early drafts. Thanks
also to Alex Niculescu-Mizil for providing his multitask
Bayesian network code. This work was supported by the Of-
ﬁce of Naval Research under grant N000141110139 and the
National Science Foundation under grant IIS-0705681.