Opposition-Based
Diﬀerential Evolution
Shahryar Rahnamayan
presented to the University of Waterloo
in fulﬁllment of the
thesis requirement for the degree of
Doctor of Philosophy
Systems Design Engineering
Waterloo, Ontario, Canada, 2007
c⃝Shahryar Rahnamayan 2007
I hereby declare that I am the sole author of this thesis. This is a true copy of the thesis,
including any required ﬁnal revisions, as accepted by my examiners.
I understand that my thesis may be made electronically available to the public.
Shahryar Rahnamayan
Evolutionary algorithms (EAs) are well-established techniques to approach those problems which for the classical optimization methods are diﬃcult to solve. Tackling problems
with mixed-type of variables, many local optima, undiﬀerentiable or non-analytical functions are some examples to highlight the outstanding capabilities of the evolutionary algorithms. Among the various kinds of evolutionary algorithms, diﬀerential evolution (DE) is
well known for its eﬀectiveness and robustness. Many comparative studies conﬁrm that the
DE outperforms many other optimizers. Finding more accurate solution(s), in a shorter
period of time for complex black-box problems, is still the main goal of all evolutionary
algorithms.
The opposition concept, on the other hand, has a very old history in philosophy, set
theory, politics, sociology, and physics. But, there has not been any opposition-based contribution to optimization. In this thesis, ﬁrstly, the opposition-based optimization (OBO)
is constituted. Secondly, its advantages are formally supported by establishing mathematical proofs. Thirdly, the opposition-based acceleration schemes, including opposition-based
population initialization and generation jumping, are proposed. Fourthly, DE is selected as
a parent algorithm to verify the acceleration eﬀects of proposed schemes. Finally, a comprehensive set of well-known complex benchmark functions is employed to experimentally
compare and analyze the algorithms. Results conﬁrm that opposition-based DE (ODE)
performs better than its parent (DE), in terms of both convergence speed and solution
The main claim of this thesis is not defeating DE, its numerous versions, or other optimizers, but to introduce a new notion into nonlinear continuous optimization via innovative
metaheuristics, namely the notion of opposition. Although, ODE has been compared with
six other optimizers and outperforms them overall.
Furthermore, both presented experimental and mathematical results conform with each
other and demonstrate that opposite points are more beneﬁcial than pure random points
for black-box problems; this fundamental knowledge can serve to accelerate other machine
learning approaches as well (such as reinforcement learning and neural networks). And
perhaps in future, it could replace the pure randomness with random-opposition model
when there is no a priori knowledge about the solution/problem.
Although, all conducted experiments utilize DE as a parent algorithm, the proposed
schemes are deﬁned at the population level and, hence, have an inherent potential to be
utilized for acceleration of other DE extensions or even other population-based algorithms,
such as genetic algorithms (GAs). Like many other newly introduced concepts, ODE and
the proposed opposition-based schemes still require further studies to fully unravel their
beneﬁts, weaknesses, and limitations.
Acknowledgements
First of all, special thanks go to my cousin, Jila Roshanzamir, who is my best friend as
well, for her endless and unbelievable pure kindness. Without her wide spread supports,
this work would have never been possible.
No need to say, without my dear parents appreciation and encouragement, this work
was not accomplishable. During this program, my father passed away. However, I could
feel his attendance in my oral defense. I wish peace for his sprit and solace.
I would like to express the deepest thanks to my supervisors, Professor Hamid R.
Tizhoosh and Professor Magdy M.A. Salama, for their continuous support and guidance.
I have learned many academics and ethics matters from them.
Thanks to my thesis committee members for their constitutive comments and guidelines
for the current and also future work.
I would like to thank all anonymous referees for their detailed and valuable comments
on my published papers which helped me to improve the quality of this work. In particular,
thanks to K. Price, the father of DE, for showing his impression about this work which
encouraged me to go further and do my best.
I would like to thank Dr. Seyed Zia Al Din Sadr Al Ashraﬁfor oﬀering beneﬁcial
knowledge about the footprint of the opposition in various sciences.
My thanks go to one-by-one of the colleagues and the staﬀs at the Systems Design
Engineering Department, Vicky Lawrence in particular, for her kindly unlimited help to
solve any sort of student problems.
I am thankful for the ﬁnancial support from the Canadian Institute of Health Research
(CIHR) Fellowship, the Ontario Graduate Scholarship (OGS), the University of Waterloo
President’s Graduate Scholarship, and the Faculty of Engineering Graduate Scholarship.
Finally, I would like to thank all my friends who did whatever they could to help me
to accomplish this work.
To All Human Rights Activists
in general
Mother Tongue Education Activists
in particular
Introduction
Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Scope and Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Outline of the Thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Diﬀerential Evolution (DE): A Short Review
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Why Diﬀerential Evolution? . . . . . . . . . . . . . . . . . . . . . . . . . .
DE Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
A Numerical Example for DE . . . . . . . . . . . . . . . . . . . . . . . . .
Handling Integer and Discrete Variables
. . . . . . . . . . . . . . . . . . .
Boundary Constraints Handling . . . . . . . . . . . . . . . . . . . . . . . .
DE’s Variants and Notations . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Opposition-Based Optimization
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Opposite Points in Continuous Space . . . . . . . . . . . . . . . . . . . . .
Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Uniqueness
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Opposition-Based Optimization (OBO) . . . . . . . . . . . . . . . . . . . .
Deﬁnitions, theorems, and proofs
. . . . . . . . . . . . . . . . . . .
How much better is the opposite point? . . . . . . . . . . . . . . . .
Empirical Veriﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Opposition-Based Diﬀerential Evolution (ODE)
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Opposition-Based Acceleration Schemes . . . . . . . . . . . . . . . . . . . .
Opposition-based population initialization
. . . . . . . . . . . . . .
Opposition-based generation jumping . . . . . . . . . . . . . . . . .
Opposition-Based Diﬀerential Evolution
. . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Empirical Study and Analysis
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Benchmark Test Suite
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Comparison Strategies and Metrics . . . . . . . . . . . . . . . . . . . . . .
Parameter Settings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Experimental Studies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Experiment series 1: comparison of DE and ODE . . . . . . . . . .
Experiment series 2: inﬂuence of dimensionality . . . . . . . . . . .
Experiment series 3: contribution of opposite points . . . . . . . . .
Experiment series 4: eﬀect of population size . . . . . . . . . . . . .
Experiment series 5: eﬀect of various mutation operators . . . . . .
Experiment series 6: proper setting of jumping rate Jr
. . . . . . .
Experiment series 7: comparison with DE and FADE . . . . . . . .
Experiment series 8: comparison with Adaptive LEP and Best L´evy
Experiment series 9: comparison with FEP and CEP . . . . . . . .
Enhancement Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . .
A Sample Application
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Image Thresholding Using micro-ODE
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proposed Image Thresholding Approach
. . . . . . . . . . . . . . . . . . .
Experimental Veriﬁcations . . . . . . . . . . . . . . . . . . . . . . . . . . .
Comparison of micro-DE and micro-ODE . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Conclusions and Future Work
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
A List of Bound Constrained Global Optimization Test Functions
B Enhancement Directions for ODE
B.1 Quasi-Oppositional Diﬀerential Evolution (QODE)
. . . . . . . . . . . . .
Quasi-opposition theorem
. . . . . . . . . . . . . . . . . . . . . . .
Experimental validation
. . . . . . . . . . . . . . . . . . . . . . . .
B.2 ODE with Variable Jumping Rate (ODEVJR) . . . . . . . . . . . . . . . .
Investigated jumping rate models . . . . . . . . . . . . . . . . . . .
Empirical results
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
B.3 Summary
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
List of Tables
Footprints of opposition in diﬀerent ﬁelds . . . . . . . . . . . . . . . . . . .
Probabilities table after adding computations of Group1-Group3 . . . . . .
Probabilities of shown four cases in Figure 3.6 . . . . . . . . . . . . . . . .
Probabilities, ﬁnal result . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Numerical results generated by Algorithm 2
. . . . . . . . . . . . . . . . .
Comparison of experimental and mathematical results . . . . . . . . . . . .
Comparison of experimental and mathematical results for α = 0.75
Comparison of DE and ODE . . . . . . . . . . . . . . . . . . . . . . . . . .
Comparison of DE and ODE for dimension sizes D/2 and 2D . . . . . . . .
Comparison of DE, ODE, and RDE (f1 −f29) . . . . . . . . . . . . . . . .
Continued from Table 5.3 (f30 −f58)
. . . . . . . . . . . . . . . . . . . . .
Comparison of DE and ODE (Np = 50) . . . . . . . . . . . . . . . . . . . .
Comparison of DE and ODE (Np = 200) . . . . . . . . . . . . . . . . . . .
The summarized results from Table 5.1, Table 5.5, and Table 5.6 . . . . . .
Comparison of DE and ODE for three other mutation strategies (f1 −f29)
Continued from Table 5.8 (f30 −f58)
. . . . . . . . . . . . . . . . . . . . .
5.10 The summarized results from Tables 5.1, 5.8, and 5.9 . . . . . . . . . . . .
5.11 Optimal jumping rate for all test functions . . . . . . . . . . . . . . . . . .
5.12 Comparison of DE, ODE, and Fuzzy Adaptive DE (FADE) . . . . . . . . .
5.13 Comparison of ODE, Adaptive LEP, and Best L´evy . . . . . . . . . . . . .
5.14 Comparison of ODE with FEP and CEP . . . . . . . . . . . . . . . . . . .
Thresholding results of proposed approach . . . . . . . . . . . . . . . . . .
Results of objective assessment for test images . . . . . . . . . . . . . . . .
Comparison of micro-DE and micro-ODE on thresholding of test images
A.1 Data for Multi-Gaussian Problem . . . . . . . . . . . . . . . . . . . . . . .
B.1 Comparison of DE, ODE, and QODE . . . . . . . . . . . . . . . . . . . . .
B.2 Comparison of DE, ODE, ODE (TVJR1), and ODE (TVJR2) . . . . . . .
B.3 Pairwise comparison of DE, ODE, ODE (TVJR1), and ODE (TVJR2)
List of Figures
Opposition concept embedded in the Yin-Yang symbol
. . . . . . . . . . .
Greek classical elements
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
Theater Hall example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Classiﬁcation scheme of optimization methods . . . . . . . . . . . . . . . .
Publications on Diﬀerential Evolution (DE)
. . . . . . . . . . . . . . . . .
Illustration of one generate-and-test cycle for DE
. . . . . . . . . . . . . .
A pictorial example for the binary crossover in the DE
. . . . . . . . . . .
A numerical example for DE . . . . . . . . . . . . . . . . . . . . . . . . . .
A pictorial example of the violation by the mutation operation . . . . . . .
A pictorial example for the exponential crossover in the DE . . . . . . . . .
Illustration of a point and its corresponding opposite
. . . . . . . . . . . .
Illustration of increasingly monotone g
. . . . . . . . . . . . . . . . . . . .
All possible situations of xr and xs for a black-box optimization . . . . . .
Similar events are in the same group
. . . . . . . . . . . . . . . . . . . . .
Illustration of why the inequality α > 1/2 holds . . . . . . . . . . . . . . .
Four possible sub-cases when xr and xs are in the same interval
. . . . . .
The e7 is selected to calculate an impact boundary for the α . . . . . . . .
Situations which min|xs −xr| ≥|x −xs| . . . . . . . . . . . . . . . . . . .
Situations which min|x −xs| ≥|xr −xs| . . . . . . . . . . . . . . . . . . .
A general scheme for population-based optimization algorithms
. . . . . .
A ﬁnalized general scheme for population-based optimization algorithms
Opposition-based initialization and generation jumping . . . . . . . . . . .
A pictorial example to show the opposition-based generation jumping . . .
A real example for the opposition-based generation jumping
. . . . . . . .
Opposition-Based Diﬀerential Evolution (ODE)
. . . . . . . . . . . . . . .
Some sample 3-D maps for 2-D functions . . . . . . . . . . . . . . . . . . .
Continued from Figure 5.1. . . . . . . . . . . . . . . . . . . . . . . . . . . .
Sample convergence graphs (DE vs. ODE) . . . . . . . . . . . . . . . . . .
Graphs of success performance (SP) vs. jumping rate . . . . . . . . . . . .
A sample thresholded image . . . . . . . . . . . . . . . . . . . . . . . . . .
Graphical illustration of dissimilarity vs. thresholding value
. . . . . . . .
Continued from Figure 6.2 . . . . . . . . . . . . . . . . . . . . . . . . . . .
B.1 Quasi-opposite region in a one dimensional space
. . . . . . . . . . . . . .
B.2 Quasi-opposite region in a two-dimensional space
. . . . . . . . . . . . . .
B.3 Jumping rate diagrams . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
List of Acronyms
ACO ant colony optimization
AR acceleration rate
CEP classical evolutionary programming
CGA continuous GA
CI conﬁdence interval
DE diﬀerential evolution
EP evolutionary programming
FADE fuzzy adaptive diﬀerential evolution
FEP fast evolutionary programming
FS free search
GAs genetic algorithms
NFC number of ﬁtness function calls
OBL opposition-based learning
OBO opposition-based optimization
ODE opposition-based DE
PSO particle swarm optimization
QODE quasi-oppositional DE
SADE self-adaptive diﬀerential evolution
SP success performance
SR success rate
Std Dev standard deviation
VTR value to reach
Introduction
God created suﬀering and heartache, so that joy might be known as their opposite. Hidden things become manifest through their opposites. But God has
no opposite; so he remains hidden. Light is known as the opposite of darkness.
But God’s light has no opposite. Thus we cannot know him through our eyes.
– Rumi (1207 – 1273) in “Masnawi”
Chapter 1. Introduction
We are witness of the rapidly growing application of the population-based algorithms to
solve real-world nonlinear complex problems. The computational time of these algorithms
depend directly on the dimensionality and complexity of the problem. Although, compared
to traditional methods, these algorithms are more applicable to real-world problems, they
suﬀer from low convergence speed. So far, many attempts have been conducted to make
them as fast as possible. Recently a new direction has been opened for this purpose, namely
employing the opposition concept to make population-based algorithms faster.
Motivation
The footprints of the opposition concept can be observed in many areas around us. This
concept has sometimes been labeled by diﬀerent names. Opposite particles in physics,
antonyms in languages, complement of an event in probability, antithetic variables in simulation, opposite proverbs in culture, absolute or relative complement in set theory, subject
and object in philosophy of science, good and evil in animism, opposition parties in politics,
theses and antitheses in dialectic, opposition day in parliaments, and dualism in religions
and philosophies are just some examples to mention (Table 1.1 contains more examples
and corresponding details). The Yin-Yang symbol in ancient Chinese philosophy is probably the oldest opposition concept which was expressed by human kind (Figure 1.1). Black
and white represent yin (receptive, feminine, dark, passive force) and yang (creative, masculine, bright, active force), respectively. This symbol reﬂects the twisted duality of all
things in nature, namely, receptive vs. creative, feminine vs. masculine, dark vs. bright,
and ﬁnally passive vs. active forces. Even Greek classical elements to explain patterns in
nature (Figure 1.2) mention the opposition concept, namely, ﬁre (hot and dry) vs. water
(cold and wet), earth (cold and dry) vs. air (hot and wet). Cold, hot, wet, dry present the
pair-wised opposite characteristics of these four elements.
It seems that without using the opposition concept, the explanation of diﬀerent entities
1.1 Motivation
Table 1.1: Footprints of opposition in diﬀerent ﬁelds.
Description
Particles/
Such as magnetic poles (N and S), opposite polarities (+
and −), electron-proton in an atom, action-reaction forces in
Newton’s third law, and so on.
A word that means the opposite of another word (e.g.,
hot/cold, fast/slow, top/down, left/right, day/night, on/oﬀ).
Antithetic
Simulation
Antithetic (negatively correlated) pair of random variables
used for variance reduction.
Two proverbs with the opposite advice or meaning (e.g., The
pen is mightier than the sword. Actions speak louder than
words.); proverb or its opposite pair oﬀers an applicable solution based on speciﬁc situation or condition.
Complements
Set theory
a) Relative complement (B −A = {x ∈B|x ̸∈A}), b) Absolute complement (Ac = U −A, where U is the universal
Opposition
A political party or organized group opposed to the government.
Digital design
Output of the inverter gate is one if input is zero and vice
Opposition
Legislation
A day in the parliament in which small opposition parties
are allowed to propose the subject for debate (e.g., Canada’s
parliament has 25 opposition days).
Philosophy
and Religion
Two fundamental principles/concepts, often in opposition to
each other; such as “Yin” and “Yang” in Chinese philosophy
and Taoist religion (Figure 1.1), “subject” and “object” in
philosophy of science, “good” and “evil” in animism, “ahura”
and “ahriman” in Zarathustra.
Philosophy
An exchange of “theses” and “antitheses” resulting in a “synthesis” (e.g. in Hinduism, these three elements are creation
(Brahma), maintenance of order (Vishnu) and destruction or
disorder (Shiva)).
A set of archetypal classical elements to explain patterns in
nature (e.g., the Greek classical elements are Fire (hot and
dry), Earth (cold and dry), Air (hot and wet), and Water
(cold and wet), Figure 1.2).
if-then-else
if condition then statements [else elsestatements], the else
statements are executed when the opposite of the condition
Complement
of an Event
Probability
P(A′) = 1 −P(A).
Revolution
Sociopolitical
A signiﬁcant Socio-political change in a short period of time.
Chapter 1. Introduction
Fig. 1.1: Opposition concept embedded in the Yin-Yang symbol or Taijitu in ancient
Chinese philosophy.
Fig. 1.2: Greek classical elements to explain patterns in nature are Fire (hot and dry),
Earth (cold and dry), Air (hot and wet), and Water (cold and wet).
around us is hard and maybe even impossible. In order to explain an entity or a situation
we sometimes explain its opposite instead. In fact, opposition often manifests itself in a
balance between completely diﬀerent entities. For instance, the east, west, south, and north
can not be deﬁned alone. The same is valid for cold and hot and many other examples.
Extreme opposites constitute our upper and lower boundaries. Imagination of the inﬁnity
is vague, but when we consider the limited, it then becomes more imaginable because its
opposite is deﬁnable.
Sometimes, we apply the opposition concept in our regular life unconsciously. Let us
look at a simple example (see Figure 1.3). Suppose police oﬃcers want to arrest somebody
in a Theater Hall. There are two seat groups (A and B) and entrance doors (a−k), on one
side (Figure 1.3(a)). The seat position of the target person is unknown (like the position
1.1 Motivation
of the solution in a black-box optimization problem) and only two oﬃcers are available. If
the ﬁrst oﬃcer selects the door a, which door should be selected by the second one? What
happens if the ﬁrst oﬃcer selects the door b? If just one oﬃcer is available which door
should be selected by him/her? For the last case since there is no opposite for one oﬃcer,
entering from the middle door (f) supports the highest accessibility.
Let us consider the same example but this time a Theater Hall with entrance doors
on all four sides (Figure 1.3(b)). Now, let us repeat the same questions for this situation.
Increase the number of oﬃcers (like individuals in a population-based optimization method)
and repeat the same questions. When oﬃcer one selects the door h, the second oﬃcer
usually selects d.
Why are the other doors not selected instead?
It seems that even
when we increase the number of oﬃcers the opposition pattern for covering the doors is
still followed (e.g., north-west door is selected versus south-east door). These are oﬃcers’
intuitive decisions in diﬀerent situations, and perhaps they are unaware of the concept of
the opposition but they apply it in order to cover the search space more eﬃciently.
For the ﬁrst time, the concept of opposition-based learning (OBL), in its earlier simple
form, was introduced by Tizhoosh [2005b]. Then, it was applied to accelerate reinforcement learning [Tizhoosh 2005c, 2006]. The main idea behind OBL is the simultaneous
consideration of an estimate and its corresponding opposite estimate (i.e., guess and opposite guess) in order to achieve a better approximation for the current candidate solution.
As an advantage of opposite versus random points, purely random resampling or selection
of solutions from a given population, has a higher chance of visiting or even revisiting
unproductive regions of the search space.
Finding the more accurate solution(s) in a shorter period of time for complex nonlinear
problems, is the main goal of all optimization metaheuristics and still widely open to
research. All of these facts encourage us to employ the opposition concept to accelerate
optimization techniques.
In this study, the population-based algorithms, diﬀerential evolution in particular, is
Chapter 1. Introduction
(a) Theater Hall with entrance doors on one side.
(b) Theater Hall with entrance doors on all four sides.
Fig. 1.3: Theater Hall example.
1.2 Scope and Objectives
selected to be accelerated using the opposition concept. The main reason for selecting
diﬀerential evolution is its high ability to ﬁnd precise solutions for the mixed-typed blackbox global optimization problems [Feoktistov 2006]. The population-based algorithms are
computationally expensive and hence their acceleration is widely appreciated. Among the
various evolutionary algorithms [B¨ack 1996; B¨ack et al. 1997; Schwefel 2003], Diﬀerential
Evolution (DE) is well known for its eﬀectiveness and robustness. Frequently reported
studies demonstrate that the DE outperforms many other optimizers over both benchmark
functions and real-world applications.
Scope and Objectives
The research in this thesis concentrates on the acceleration of the population-based algorithms in general, and the diﬀerential evolution algorithm in particular. According to
the proposed classiﬁcation scheme for optimization methods by Feoktistov (Figure 1.4), DE is a population-based nonlinear continuous global optimization algorithm.
The optimization branch in focus of this research is highlighted by bolded arrows. The
classical DE has been extended to tackle the mixed-type variable optimization problems
[Lampinen and Zelinka 1999b]. The population-based branch covers a wide range of families, such as genetic algorithms (GAs) [Goldberg 1989], particle swarm optimization (PSO)
[Angeline 1998], ant colony optimization (ACO) [Dorigo and St¨utzle 2004], diﬀerential evolution [Storn and Price 1997b], and free search (FS) [Penev and Littlefair 2005]. The focus
of this research is on bound-constraints diﬀerential evolution algorithms.
The main objectives of this research are: 1) constituting the framework of the oppositionbased optimization and corresponding deﬁnitions, theorems, and mathematical proofs
which demonstrate why integration of the opposition concept is valuable in optimization, 2)
proposing the opposition-based acceleration schemes for the population-based algorithms,
3) accelerating diﬀerential evolution by proposed opposition-based schemes, 4) benchmark-
Chapter 1. Introduction
ing and parameter analysis of the ODE by employing a comprehensive test suite of global
optimization problems, 5) proposing possible enhancement directions for ODE. More details about the related contributions are provided in the ﬁnal chapter.
Fig. 1.4: A simple classiﬁcation scheme of optimization methods [Feoktistov 2006]. According to this classiﬁcation, DE is a population-based nonlinear continuous global optimization
method. Opposition-based DE (ODE) is the enhanced version of the DE by the opposition
concept. The optimization branch in focus of this research is highlighted by bolded arrows
and boxes.
Outline of the Thesis
Chapter 2 explains the diﬀerential evolution algorithm and the main reasons to select it as a
parent evolutionary algorithm to implement the proposed opposition-based schemes. Also,
1.3 Outline of the Thesis
this chapter reviews some studies, which compare DE to other well-known optimizers.
It can be skipped if the reader is familiar with DE and its frequently reported higher
performance on benchmark functions and real-world applications.
Chapter 3 covers the details of the opposition-based optimization and corresponding
deﬁnitions, theorems, and proofs. This chapter presents answers to questions concerning
why and how far the opposite points are more valuable than additionally generated random
points. In order to support the mathematical computations, they are compared to the
experimental results as well.
Chapter 4 presents the general schemes of the opposition-based algorithm. Then, these
schemes are embedded inside diﬀerential evolution to introduce ODE. The overall features
of the aforementioned schemes are explained in details.
Chapter 5 contains the empirical study and analysis of the proposed opposition-based
diﬀerential evolution. A comprehensive set of experimental series, including parameter
and comparative studies, are conducted in this chapter. ODE is compared with six other
evolutionary optimizers.
Chapter 6 includes a new optimization-based image thresholding algorithm. It also
compares micro-DE and micro-ODE on thresholding of test images. Finally, the conclusions, contributions, and future works all are addressed in Chapter 7.
Diﬀerential Evolution (DE): A Short
Diﬀerential Evolution, deriving from population-based metaheuristics, inherits
all the best properties of its ancestors: global methods of nonlinear continuous optimization, approximate methods of combinatorial optimization, mixedvariables handling, and so on. In addition, it provides stochastic optimization
principles, distributed searchers, and universal heuristics. All this makes the algorithm a general-purpose optimizer, remaining, with all this going on, simple,
reliable, and fast.
– Vitaliy Feoktistov, 2006 in “Diﬀerential Evolution: In Search of Solutions”
2.1 Introduction
Introduction
Diﬀerential evolution (DE) is a population-based optimization algorithm. The invention
of the DE algorithm goes back to Genetic Annealing by Kenneth Price and solving
the Chebyshev polynomial ﬁtting problem by him and Rainer Storn. In order to solve
Chebyshev problem in continuous space, they modiﬁed the genetic annealing algorithm
from bit-string to ﬂoating-point encoding and consequently switched from logical operators to arithmetic ones. During experiments, they discovered the diﬀerential mutation to
perturb the population of vectors. They also noticed that by using diﬀerential mutation,
discrete recombination, and pair-wise selection, there is no need to apply annealing mechanism; it was removed completely and DE was born. Results of this achievement were
reported in the ICIS technical report in 1995 [Storn and Price 1995]. DE was published in
the Dobb’s Journal [Price and Storn 1997] and then in the Journal of Global Optimization
[Storn and Price 1997b]. By this way, DE’s capacity and advantages were introduced to
the optimization community. Comprehensive history and development of DE is presented
in literature [Feoktistov 2006].
Why Diﬀerential Evolution?
It is important to note why DE was selected as a parent algorithm in this thesis. Simplicity
of the DE is the ﬁrst reason on this track. The compactness of the algorithm and easy-tounderstand steps, both impress any researcher or practitioner to work with the DE.
Working directly with the continuous variables (arithmetic operators instead of logical
operators) is the second attraction feature for this evolutionary algorithm. Unlike many binary versions of the genetic algorithm, DE works with the ﬂoating-point numbers; encoding
and decoding of the variables (which can be the source of inaccuracy) are removed. Consequently, this feature makes DE scalable for high dimensional problems and also time and
Chapter 2. Diﬀerential Evolution (DE): A Short Review
memory eﬃcient. DE’s steps are described using simple numerical and pictorial examples
in Section 2.3.
DE does not need a probability density function (PDF) to adapt the control parameters
 or any
probability distribution pattern for the mutation (dissimilar to the genetic algorithm or
evolutionary programming). DE’s diﬀerent mutation and crossover schemes separate it
from other evolutionary algorithms. Section 2.7 explains diﬀerent DE variants.
The ability of the handling mixed integer, discrete, and continuous variables using some
straightforward approaches makes DE more realistic for a wide range of real-world applications [Lampinen and Zelinka 1999a,b]. Discrete variables can be assumed as a subset of
integer variables. The main advantage of DE, during working with the integer variables,
is that it internally works on continuous space and only switches to the integer space during the evaluation of the objective function. This characteristic supports higher accuracy
compared to some other well-known algorithms (e.g., GAs) which perform in the reverse
manner. More details about handling mixed-type variables are provided in Section 2.5.
Extensions of classical DE are capable of handling boundary constraints and also nonlinear function constraints which both are commonly required in the real-world problems.
This case is covered in Section 2.6.
Most importantly, many comparative studies report the higher robustness, convergence
speed, and solution quality of the DE. This is true over benchmark functions and also
real-world applications. A comprehensive performance study is provided in Benchmarking
Diﬀerential Evolution chapter in [Price et al. 2005]. In this chapter, they ﬁrst compare DE
to 16 other optimizers against ﬁve well-known thirty-dimensional test functions (namely,
Rosenbrock, Ackley, Griewangk, Rastrigin, and Schwefel). For this study, DE’s 16 competitors are:
• Evolutionary programming with adaptive L´evy mutations (ALEP) [Lee and Yao 2004]
2.2 Why Diﬀerential Evolution?
• Attractive and repulsive particle swarm optimization (arPSO)
[Vesterstroem and Thomsen 2004]
• Cooperative co-evolutionary genetic algorithm (CCGA)
[Bergh and Englebrecht 2004]
• Classical evolutionary programming (CEP) [Yao et al. 1999]
• Conventional evolutionary programming with adaptive mutations (CEP/AM)
[Chellapilla 1998]
• Classical evolution strategies (CES) [Yao and Liu 1997]
• Cooperative particle swarm optimization (CPSO-S6) [Bergh and Englebrecht 2004]
• Evolutionary optimization (EO) [Angeline 1998]
• Fast evolution programming (FEP) [Yao et al. 1999]
• Fast evolutionary strategies (FES) [Yao and Liu 1997]
• Hybrid taguchi-genetic algorithm (HTGA) [Tsai et al. 2004]
• Orthogonal genetic algorithm (OGA) [Leung and Wang 2001]
• Particle swarm optimization (PSO) [Angeline 1998]
• Quantum evolutionary algorithm with rotation (QEA/R) [Han and Kim 2004]
• Simple evolutionary algorithm (SEA) [Vesterstroem and Thomsen 2004]
• Stochastic genetic algorithm (StGA) [Tu and Lu 2004].
Chapter 2. Diﬀerential Evolution (DE): A Short Review
Then, they explored previously conducted eight benchmark-function-based comparative
studies and also eleven application-oriented performance comparison studies . Finally, they concluded as follows:
“[...] DE may not always be the fastest method, it is usually the one that
produces the best results, although the number of cases in which it is also the
faster is signiﬁcant. DE also proves itself to be robust, both in how control
parameters are chosen and in the regularity with which it ﬁnds the true optimum. [...] As these researchers have found, DE is a good ﬁrst choice when
approaching a new and diﬃcult global optimization problem is deﬁned with
continuous and/or discrete parameters. ”
Although, DE is almost in its infancy (approx. 10 years old) and is being improved
step-by-step, because of above mentioned reasons, it has established itself as a universal
optimization tool. The sharp growing of the publications on DE conﬁrms this fact clearly
(see Figure 2.1).
2.3 DE Algorithm
Fig. 2.1: Publications on Diﬀerential Evolution (based on information extracted from
Google’s Scholar service).
DE Algorithm
Diﬀerential Evolution is a population-based directed search method [Price 1999]. Like other
evolutionary algorithms, it starts with an initial population vector, which is randomly
generated when no preliminary knowledge about the solution space is available.
vector of the initial population can be generated as follows [Price et al. 2005]:
Xi,j = aj + randj(0, 1) × (aj −bj); j = 1, 2, ..., D,
where D is the problem dimension; aj and bj are the lower and the upper boundaries of
the variable j, respectively. rand(0, 1) is the uniformly generated random number in .
A sample initial population for ODE is shown in Figure 2.2(a).
Let us assume that Xi,G(i = 1, 2, ..., Np) are candidate solution vectors in generation G
(Np : population size). Successive populations are generated by adding the weighted diﬀerence of two randomly selected vectors to a third randomly selected vector. For classical DE
Chapter 2. Diﬀerential Evolution (DE): A Short Review
(a) Population initialization for DE (Np =
9). Contour lines for f(x1, x2) are shown
by ellipses.
(b) Generating diﬀerence vector Xc −Xb.
b and c are the randomly selected indices.
(c) Generating Xa,G + F(Xc,G −Xb,G). a
is the third randomly selected index.
(d) After the crossover if the generated
vector has lower objective value; it will be
replaced with the vector 0.
Fig. 2.2: Illustration of one generate-and-test cycle for DE (starting from vector 0).
2.3 DE Algorithm
(DE/rand/1/bin)1, the mutation, crossover, and selection operators are straightforwardly
deﬁned as follows:
Mutation - For each vector Xi,G in generation G a mutant vector Vi,G is deﬁned by
Vi,G = Xa,G + F(Xc,G −Xb,G),
where i = {1, 2, ..., Np} and a, b, and c are mutually diﬀerent random integer indices
selected from {1, 2, ..., Np}. Further, i, a, b, and c are diﬀerent so that Np ≥4 is required.
F ∈ is a real constant which determines the ampliﬁcation of the added diﬀerential
variation of (Xc,G −Xb,G). Larger values for F result in higher diversity in the generated
population and lower values cause faster convergence. Figures 2.2(b) and 2.2(c) illustrate
vector representation of the (Xc,G −Xb,G) and Xa,G + F(Xc,G −Xb,G), respectively.
Crossover - DE utilizes the crossover operation to generate new solutions by shuﬄing
competing vectors and also to increase the diversity of the population. For the classical
DE (DE/rand/1/bin), the binary crossover (shown by ‘bin’ in the notation) is utilized. It
deﬁnes the following trial vector:
Ui,G = (U1i,G, U2i,G, ..., UDi,G),
if randj(0, 1) ≤Cr ∨j = k,
otherwise.
Cr ∈(0, 1) is the predeﬁned crossover rate, and randj(0, 1) is the jth evaluation of a
uniform random number generator. k ∈{1, 2, ..., D} is a random parameter index, chosen once for each i to make sure that at least one parameter is always selected from the
1This notation is explained in section 2.7.
Chapter 2. Diﬀerential Evolution (DE): A Short Review
mutated vector, Vji,G. Most popular values for Cr are in the range of (0.4, 1) [Das et al.
2005a]. Figure 2.3 presents a pictorial example for the binary crossover.
Fig. 2.3: A pictorial example for the binary crossover in DE (k = 7).
Selection - This is an approach which must decide which vector (Ui,G or Xi,G) should
be a member of next (new) generation, G + 1. For a minimization problem, the vector
with the lower value of objective function is chosen (greedy selection).
This evolutionary cycle (i.e., mutation, crossover, and selection) is repeated Np (population size) times to generate a new population. These successive generations are produced
until meeting the predeﬁned termination criteria. Algorithm 1 presents the details of the
classical DE algorithm. Starting point for the mutation, crossover and selection is indicated
by the comments in the algorithm. The algorithm terminates when the best achieved ﬁtness value (BFV) is smaller than the value to reach (VTR), or the number of ﬁtness
function calls (NFC) exceeds predeﬁned maximum number of function calls (MAXNFC).
2.4 A Numerical Example for DE
Termination strategy can be deﬁned diﬀerently based on the problem nature, application,
or the purpose of the experiment. Limiting the number of generations, the execution time,
or checking some statistics of the population (e.g., diversity or the improvement rate) are
some commonly used termination criteria.
A Numerical Example for DE
In order to illustrate the steps of the DE algorithm a typical numerical example is presented
here [Onwubolu and Babu 2004]. Figure 2.4 shows the procedure of generating one vector
for the next generation. The objective function is f(X) = x1 + x2 + x3 + x4 + x5 and the
dimension size, population size, mutation constant, and crossover constant are 5, 6, 0.8 and
0.5, respectively. The procedure is similar to generate the rest of the next population’s
vectors. As seen, the current generation G has six individuals, Np = 6; and each individual
contains ﬁve parameters, D = 5 (X(x1, x2, x3, x4, x5)). Cost value for each individual is
calculated by f(X) and is shown in the top cell of the corresponding vector.
ﬁrst target vector (individual 1), three mutually diﬀerent vectors are selected randomly
(individuals 2,4, and 6). Then, the noisy vector is calculated as follow:
noisy vector = individual 6+ F×(individual 2 −individual 4)
Consequently, with the crossover of the noisy vector and target vector the trial vector is
generated. Parameters 1 and 5 are selected from noisy vector and the rest from the target
vector. Now, in selection step, the cost value of the trial vector and the target vector is
compared and the vector with the lower cost value (target vector here) is selected and
copied to the next generation G+1.
Chapter 2. Diﬀerential Evolution (DE): A Short Review
Algorithm 1 Diﬀerential Evolution (DE). P0: Initial population, Np: Population size,
V : Noise vector, U: Trial vector, D: Problem dimension, BFV: Best ﬁtness value so far,
VTR: Value-to-reach, NFC: Number of function calls, MAXNFC: Maximum number of
function calls, F: Mutation constant, rand(0, 1): Uniformly generated random number,
Cr: Crossover rate, f(·): Objective function, P ′: Population of the next generation.
1: Generate uniformly distributed random population P0
2: while ( BFV > VTR and NFC < MAXNFC ) do
//Generate-and-Test-Loop
for i = 0 to Np do
Select three parents Xa, Xb, and Xc randomly from current population where
i ̸= a ̸= b ̸= c
//Mutation
Vi ←Xa + F × (Xc −Xb)
//Crossover
for j = 0 to D do
if rand(0, 1) < Cr then
Ui,j ←Vi,j
Ui,j ←Xi,j
//Selection
Evaluate Ui
if (f(Ui) ≤f(Xi)) then
22: end while
2.4 A Numerical Example for DE
Fig. 2.4: A numerical example [Onwubolu and Babu 2004] to illustrate the classical DE
(DE/rand/1/bin) for minimizing a simple objective function, f(X) = x1+x2+x3+x4+x5.
Chapter 2. Diﬀerential Evolution (DE): A Short Review
Handling Integer and Discrete Variables
DE works directly with ﬂoating-point variables, but by applying some minor modiﬁcations
it is able to handle integer variables as well. One of the common ways is simply using
the integer variables during evaluation of the objective function and leaving other parts
unchanged [Onwubolu and Babu 2004]. Following rules present this approach:
f(yj); j = 1, ..., D
xj is a continuous variable,
xj is an integer variable.
xj is a continuous variable,
xj is an integer variable.
Converting a continuous number to the integer can be performed by INT(·) or ROUND(·)
functions. INT(·) truncates the real part of the continuous number and ROUND(·) returns
the closest integer number. If the INT(·) is the conversion case, Eq. 2.1 should be replaced
with the following equation because of truncation eﬀect of INT(·) function:
Xi,j = aj + randj(0, 1) × (aj −bj + 1), j = 1, 2, ..., D.
Through this method, DE internally searches a superset of the solution space instead,
because the integer numbers are the subset of the continuous numbers. This feature increases the population diversity and the robustness of the algorithm as well.
In order to handle discrete variables, the method performs similar to the integer case,
but this time the indices of the discrete numbers are used as integer variables and during
2.6 Boundary Constraints Handling
the objective function evaluation, instead of the integer value of the indices, the discrete
value of the variables is substituted.
Boundary Constraints Handling
DE’s mutation operator can expand the search space to the outside of the predeﬁned
boundaries. For unconstraint boundary problems it can be an advantage, because even
solutions, which are outside the boundaries, can be explored. But, in the revers sense, for
the boundary constraint problems this phenomenon should be prevented. An example of
the violation by the mutation operation is presented in Figure 2.5. Two approaches are
commonly applied to prevent this violation [Onwubolu and Babu 2004] (a) generating a
new random value (re-initialization) for the parameters which violate the boundary constraints or (b) re-performing the mutation operation to achieve a vector with no violating
parameter. The ﬁrst approach can be faster than the second one in overall, because the
second method sometimes needs more than one time repeating the mutation to obtain an
acceptable vector.
DE’s Variants and Notations
Classical DE (DE/rand/1/bin) was explained in the previous sections. There are other
DE variants which are indicated by the notation DE/a/b/c [Mezura-Montes et al. 2006].
In this notation, ‘a’ speciﬁes the vector which should be mutated; it can be the best
vector (‘best’) of the current population or a randomly selected one (‘rand’). ‘b’ is reserved
for the number of diﬀerence vectors which participate in the mutation (1 or 2) and ‘c’
denotes the applied crossover scheme, binary (‘bin’) or exponential (‘exp’). Figure 2.6
presents a pictorial example for the exponential crossover. Crossover procedure starts from
a randomly selected parameter (j = 3 in this example), and copies the parameters of the
Chapter 2. Diﬀerential Evolution (DE): A Short Review
An example of the violation by the mutation operation from the prede-
ﬁned boundary constraints.
u1 (marked by ‘∗’) is located outside the box shown by
[x1,min, x1,max], [x2,min, x2,max].
Uji,G to Vji,G, until the ﬁrst occurance of rand(0, 1) > Cr; then the remaining parameters
from Xji,G are inherited by Vji,G.
As an example, DE/best/2/exp speciﬁes a DE scheme with exponential crossover and
the following mutation:
Vi,G = Xbest,G + F(Xa,G −Xb,G) + F(Xc,G −Xd,G),
where Xbest,G is the best vector in the population. Xa,G, Xb,G, Xc,G, and Xd,G are four
diﬀerent randomly selected vectors (a ̸= b ̸= c ̸= d) from the current population.
Other studies have been conducted to enhance the performance of the classical DE
algorithm, e.g, adaptively determining DE control parameters. The fuzzy adaptive differential evolution algorithm (FADE) was introduced by Liu and Lampinen . They
2.7 DE’s Variants and Notations
Fig. 2.6: A pictorial example for the exponential crossover in DE.
employed a fuzzy logic controller to set the mutation and crossover rates. In the same direction, Brest et al. proposed self-adaptive diﬀerential evolution (SADE). Teo 
proposed a dynamic population sizing strategy based on self-adaptation and Ali and T¨orn
 introduced auxiliary population and automatic calculating of the ampliﬁcation factor, F, for the diﬀerence vector.
Other researchers have experimented with multi-population ideas. Tasoulis et al. 
proposed parallel DE where they assign each subpopulation to a diﬀerent processor node.
Shi et al. partitioned high-dimensional search spaces into smaller spaces and used
multiple cooperating subpopulations to ﬁnd the solution. They called this method cooperative co-evolutionary diﬀerential evolution.
Hybridization with diﬀerent algorithms is another direction for improvement. Sun et al.
 proposed a new hybrid algorithm based on a combination of DE and estimation of
distribution algorithm. This technique uses a probability model to determine promising
regions in order to focus the search process on those areas. Noman and Iba incor-
Chapter 2. Diﬀerential Evolution (DE): A Short Review
porated local search into the classical DE. They employed ﬁttest individual reﬁnement
which is a crossover-based local search. Fan and Lampinen introduced a new local
search operation, trigonometric mutation, in order to obtain a better trade-oﬀbetween
convergence speed and robustness. Kaelo and Ali employed reinforcement learning
and diﬀerent schemes for generating ﬁtter trial points. For more details about DE extensions, variants, and species the reader is referred to literature [Onwubolu and Babu 2004;
Price et al. 2005; Feoktistov 2006].
In this chapter, the main reasons to select DE as a parent algorithm as well as its classical
version were brieﬂy discussed. Diﬀerent DE variants with respect to its mutation strategy
and crossover procedure, were explained and illustrated with some numerical and pictorial
examples. Methods to handle integer/discrete variables and also applying the boundary
constraints, were reviewed shortly.
According to the reported results from many comparative studies, DE presents itself as
a strong candidate to be a universal optimizer. Rapidly growing publications strengthen
this hope.
DE works directly with the continuous space but its extended versions are
capable to tackle mixed-type variable problems. Its capability to handle the constraint
functions as well as multiobjective problems attracts more researchers and practitioners.
DE’s simplicity is another important advantage which helps us to implemented it by
very compact algorithms. The presented DE algorithm in this chapter (Algorithm 1) is
utilized as a parent algorithm for introducing any other enhanced version.
Opposition-Based Optimization
What is wanted is not the will to believe, but the wish to ﬁnd out, which is
the exact opposite.
– Bertrand Russell
Mathematics is a study which, when we start from its most familiar portions,
may be pursued in either of two opposite directions.
– Bertrand Russell in “Introduction to Mathematical Philosophy”
Chapter 3. Opposition-Based Optimization
Introduction
In this chapter deﬁnitions, theorems, and proofs related to opposite points and the opposition - based optimization are presented. The beneﬁt of the opposite points (compared
to independent random inputs) in one dimensional space is investigated through a mathematical proof. Then, this proof is extended to D-dimensional space. Furthermore, the
probability of the opposite points being closer to the solution is calculated mathematically
and veriﬁed experimentally; both results support each other. The main concern of the
presented proofs is black-box optimization problems. Finally, this chapter wants to answer
the following question, in general form: Why are opposite points valuable?
Opposite Points in Continuous Space
Deﬁnitions
Deﬁnition 3.1 Let x be a real number in an interval [a, b] (x ∈[a, b]); the opposite of x,
denoted by ˘x, is deﬁned by
˘x = a + b −x.
Figure 3.1 (top) illustrates x and its opposite ˘x in interval [a, b]. As seen, x and ˘x are
located in equal distance from the interval’s center (|(a + b)/2 −x| = |˘x −(a + b)/2|) and
the interval’s boundaries (|x −a| = |b −˘x|) as well.
This deﬁnition can be extended to higher dimensions by applying the same formula to
each dimension [Tizhoosh 2005b].
Deﬁnition 3.2 Let P(x1, x2, ..., xD) be a point in D-dimensional space, where x1, x2, ..., xD
are real numbers and xi ∈[ai, bi] , i = 1, 2, ..., D. The opposite point of P is denoted by
˘P(˘x1, ˘x2, ..., ˘xD) where
3.2 Opposite Points in Continuous Space
Fig. 3.1: Illustration of a point and its corresponding opposite in one, two, and three
dimensional spaces.
˘xi = ai + bi −xi.
Figure 3.1 illustrates a sample point and its corresponding opposite point in one, two,
and three dimensional spaces.
Uniqueness
Theorem 3.1 (Uniqueness) Every point P(x1, x2, ..., xD) in the D-dimensional space
of real numbers with xi ∈[ai, bi] has a unique opposite point ˘P(˘x1, ˘x2, ..., ˘xD) deﬁned by
˘xi = ai + bi −xi , i = 1, 2, 3, ..., D.
Chapter 3. Opposition-Based Optimization
Proof - Let us consider, without loss of generality, the two space corners a1 and b1 for the
one dimensional case. According to the opposite point deﬁnition, we have |x−a1| = |˘x−b1|
or |˘x −a1| = |x −b1|. Now, assume that a second point x′ is also opposite of x. Then, we
should have |x−a1| = |x′ −b1| or |x′ −a1| = |x−b1|. This, however, means x′ = ˘x. Hence,
˘x is unique.
Opposition-Based Optimization (OBO)
Now, after the deﬁnition of the opposite points we are ready to deﬁne Opposition-Based
Optimization (OBO).
Deﬁnition 3.3 Let P(x1, x2, ..., xD), a point in a D-dimensional space with xi ∈[ai, bi]
(i = 1, 2, 3, ..., D), be a candidate solution. Assume f(x) is a ﬁtness function which is used
to measure candidate optimality. According to opposite point deﬁnition, ˘P(˘x1, ˘x2, ..., ˘xD) is
the opposite of P(x1, x2, ..., xD). Now, if f( ˘P) ≥f(P), then point P can be replaced with
˘P; otherwise we continue with P. Hence, the point and its opposite point are evaluated
simultaneously to continue with the ﬁtter one [Tizhoosh 2005b].
This deﬁnition of OBO is making two fundamental assumptions.
First, one of the
candidate or the opposite candidate is always closer to the solution, and second, considering
the opposition is more beneﬁcial than generating additional random solutions and taking
the best among them.
Empirical evidence for these claims will be provided in section 3.4. However, prior to
providing experimental results, we also want to provide mathematical proofs.
Deﬁnitions, theorems, and proofs
Deﬁnition 3.4 Euclidean distance between two points P(p1, p2, ..., pD) and Q(q1, q2, ..., qD)
in a D-dimensional space is deﬁned by
3.3 Opposition-Based Optimization (OBO)
d(P, Q) =∥P, Q ∥=
(pi −qi)2.
It can be simpliﬁed as follows for a one-dimensional space:
d(P, Q) =∥P, Q ∥= |p −q|.
Theorem 3.2 (First Opposition Theorem) For any (unknown) function y = f(x)
(x ∈[a, b]) with global optimum at xs (xs ̸= (a+b)
), the estimate solution x and its opposite
˘x, we have
Pr (|˘x −xs| < |x −xs|) = 1/2,
where Pr(·) is the probability function. It means candidate solution and its opposite have
the equal chance to be closer to the solution.
Proof - We have Pr(˘x ∈[a, (a + b)/2]|x > (a + b)/2) = 1 and Pr(˘x ∈[(a + b)/2, b]|x <
(a + b)/2) = 1. If xs ̸= (a + b)/2, then Pr(|˘x −xs| < |x −xs|) = 1/2. For xs = (a + b)/2,
then Pr(|˘x −xs| = |x −xs|) = 1.
Now, lets focus on the second assumption of OBO. Suppose the random variables
x1, x2, ... are continuous independent random variables representing the system inputs.
Suppose the performance of the system for given inputs xi is a monotone function g(xi).
We wish to compare the performance of a system with independent inputs with one using
opposition-based inputs. In particular, we wish to maximize some measure of performance
g(x) over possible inputs x. The following theorem shows the beneﬁt of the opposite inputs,
compared to random inputs.
Theorem 3.3 (Second Opposition Theorem) For increasingly monotone g,
Pr (g(xr) < max{g(x), g(˘x)}) =
4, where x is the ﬁrst random guess; ˘x is the opposite
Chapter 3. Opposition-Based Optimization
point of x; and xr is the second random guess.
Fig. 3.2: Illustration of increasingly monotone g, interval boundaries, candidate and opposite candidate solutions.
Proof - Let us prove Pr (g(xr) > max{g(x), g(˘x)}) = 1−Pr (g(xr) < max{g(x), g(˘x)}) =
4 instead (see Figure 3.2),
Pr (g(xr) > max{g(x), g(˘x)}) = Pr
˘x > (a+b)
xr > (a+b)
Pr (xr > ˘x) + Pr
˘x < (a+b)
xr > (a+b)
× Pr(xr > x) = 1
Following results are obtained from this theorem:
1. Pr (g(x) > g(xr)) = 3
2. Pr (g(˘x) > g(xr)) = 3
3. Pr (g(xr) > g(x) ∧g(xr) > g(˘x)) = Pr (g(xr) > max{g(x), g(˘x)}) = 1
Hence, by assuming g is a monotone function, the opposite point has 12.5% (0.375 −
0.25 = 0.125) higher chance to have a higher g value compared to the second random guess.
3.3 Opposition-Based Optimization (OBO)
For the following central opposition theorems (one and D-dimensional), no assumption
regarding the g function will be made.
Theorem 3.4 (Central Opposition Theorem for One-Dimensional Space)
(a) y = f(x) (x ∈[a, b]) is an unknown function with at least one solution xs ∈[a, b]
for f(x) = α; the solution can be anywhere in our search space (i.e., a black-box
optimization problem),
(b) x is the ﬁrst uniform random guess and xr is the second uniform random guess in
[a, b]; candidate solutions should be uniform random numbers because all points have
the same chance to be the solution,
(c) Opposite of x ∈[a, b] is deﬁned as ˘x = a + b −x,
Then Pr (|˘x −xs| < |xr −xs|) > Pr (|xr −xs| < |˘x −xs|).
In other words, the probability that the opposite point is closer to the solution is higher
than probability of a second random guess.
Proof - In order to prove this theorem, we follow an exhaustive proof by covering all
possible situations. Lets say, N diﬀerent points over the interval [a, b] divide it to N + 1
sub-intervals.
So, three points (x ̸= (a + b)/2 ̸= ˘x) divide the interval [a, b] to four
sub-intervals [a, x], [x, (a + b)/2], [(a + b)/2, ˘x], and [˘x, b]. The solution xs and the second
random guess xr can form 16 (4 × 4) diﬀerent ways/combinations in the above mentioned
four sub-intervals. Figure 3.3 illustrates all possible situations for a black-box optimization
problem. We will call each situation an event. Therefore, we have 16 possible events (ei,
i = 1, 2, ..., 16). The probability of all events is equal because the solution (xs), the ﬁrst
random guess (x), and the second random guess (xr) can appear anywhere in the interval
[a, b] for a black-box optimization problem. Hence,
Chapter 3. Opposition-Based Optimization
Pr(ei) = 1
i = 1, 2, . . . , 16.
Fig. 3.3: All possible situations of xr and xs for a black-box optimization problem.
In order to establish an exhaustive proof, we start to calculate the following corresponding probabilities for each event:
px= probability of x being the closest to the solution xs among {x, ˘x, xr},
pr= probability of the second random guess xr being the closest to the solution xs
among {x, ˘x, xr},
3.3 Opposition-Based Optimization (OBO)
p˘x= probability of the opposite point ˘x being the closest to the solution xs among
{x, ˘x, xr}.
Obviously we have
px + p˘x + pr = 1.
Now, all events are categorized into following four groups (see Figure 3.1):
1. Group1 = {e2, e3, e4, e5, e12, e13, e14, e15}, (x, ˘x ∈[xs, xr]).
At least one of x or ˘x is located between the xs and xr.
2. Group2 = {e8, e9}, (min |xs −xr| ≥|x −xs|) ∨(min |xs −xr| ≥|˘x −xs|).
Minimum distance between xs and xr is greater than distance between xs and x/˘x.
3. Group3 = {e7, e10}, (xs ∈[x, (a + b)/2]) ∧(xr ∈[(a + b)/2, ˘x]) or vice versa.
4. Group4 = {e1, e6, e11, e16}, xr and xs are in the same interval.
In order to complete our table of probabilities step by step, the corresponding probabilities (px,pr, and p˘x) are calculated for each group as follows:
Group1: {e2, e3, e4, e5, e12, e13, e14, e15}
When x ∈[xs, xr] and it is closer to solution than ˘x, then x is clearly the closest to
the solution (events: e2, e3, e4, and e5, Figure 3.1). Hence px = 1. Similarly, the same
logic can be applied to ˘x (events: e12, e13, e14, and e15, Figure 3.1). For these cases the
entries can be inserted into the table of probabilities (Table 3.1). Newly added values are
highlighted in boldface.
Group2: {e8, e9}
(1) If min |xs −xr| ≥|x −xs|, so obviously px = 1, applicable to e8.
Chapter 3. Opposition-Based Optimization
Fig. 3.4: Similar events are in the same group.
(2) Similarly, if min |xs −xr| ≥|˘x −xs|, then obviously p˘x = 1, applicable to e9.
These cases are completed in Table 3.1.
Group3: {e7, e10}
Events e7 and e10 are similar cases (Figure 3.1). Let us assume px = α for event e7, so
we have pr = 1 −α because px + p˘x + pr = 1 and p˘x = 0. Analogously, for event e10, we
have p˘x = α, pr = 1 −α, and px = 0. We can complete our table for another two events
(e7 and e10), see Table 3.1.
3.3 Opposition-Based Optimization (OBO)
Table 3.1: Probabilities table after adding computations of Group1, Group2, and Group3
(left to right, respectively).
Now, let us have a preliminary estimate for α. Similar to the reason which was mentioned for Group2 , we can conclude
If min |xr −xs| ≥|x −xs|, so obviously px = 1, this case happens with a probability
of at least 1/2 when xs is in the interval [x, k] (the half of the interval [x, (a + b)/2]), see
Figure 3.5.
Group4: {e1, e6, e11, e16}
For this group, xr and xs are in the same interval. We just need to solve one of them.
Chapter 3. Opposition-Based Optimization
Illustration of why the inequality α > 1/2 holds. k is the center of the interval
[x, (a + b)/2].
Lets select event e1; this case can be decomposed to four possible sub-cases, presented in
Figure 3.6. For these sub-cases, the probabilities are given in Table 3.2. (note the recursive
deﬁnition of the event (1b)). In order to calculate p1x, let
p1x = 1/4 × p1x + 1/4 × α ⇒p1x = α/3.
We know p(ei) = 1/16 (Eq. 3.6), so
px1 = 1/16 × α/3 ⇒p1x = α/48.
And ﬁnally
pr1 = 1 −px1 = 1 −α/48 = (48 −α)/48.
Now, we are ready to complete our table (see Table 3.3). According to our ﬁnal probabilities table, we have
p(ei)pxi = (5 + 25α/24)/16.
3.3 Opposition-Based Optimization (OBO)
Fig. 3.6: Four possible sub-cases when xr and xs are in the same interval.
Table 3.2: Probabilities table of shown four cases in Figure 3.6.
p(ei)pri = (6 −50α/24)/16.
p(ei)p˘xi = (5 + 25α/24)/16.
Now, let us investigate when p˘x > pr:
(p˘x > pr) ⇔5 + 25α
Chapter 3. Opposition-Based Optimization
Table 3.3: Probabilities table, ﬁnal result.
(48 −α)/48
(48 −α)/48
(48 −α)/48
(48 −α)/48
(5 + 25α/24), (6 −50α/24), (5 + 25α/24)
(p˘x > pr) ⇔α > 24/75
This is conﬁrmed with α > 1/2 (Eq. 3.8).
How much better is the opposite point?
Now we want to calculate an impact boundary for α and estimate the value of px, p˘x, and
pr. In the following two steps, we will ﬁnd the lower and the upper boundaries for α.
Step 1. Calculating a lower boundary for α – Without loss of generality, we select
e7 to ﬁnd the impact interval for α (Figure 3.7).
3.3 Opposition-Based Optimization (OBO)
Fig. 3.7: The e7 is selected to calculate an impact boundary for the α.
As mentioned before, if min |xs −xr| ≥|x −xs|, so obviously px = 1. As illustrated in
Figure 3.8, we have
px|min|xs−xr|≥|x−xs| = lim
Psi × Pri.
Psi and Pri denote the probability of the presence of the solution and the second random
guess in the shown intervals.
px|min|xs−xr|≥|x−xs| = lim
22 + ... +
2(N+1) × 1
px|min|xs−xr|≥|x−xs| = lim
25 + ... +
This equation presents inﬁnite geometric series; such series converge if and only if the
absolute value of the common ratio is less than one (|r| < 1). For these kinds of series we
a(1 −rN+1)
Chapter 3. Opposition-Based Optimization
px|min|xs−xr|≥|x−xs| = 4
Fig. 3.8: Situations which min|xs −xr| ≥|x −xs|.
So, we receive
Step 2. Calculating an upper boundary for α – Analogously, If min |x−xs| ≥|xs−xr|,
then pr = 1. So, as illustrated in Figure 3.9, we have
pr|min|x−xs|≥|xs−xr| = lim
pr|min|x−xs|≥|xs−xr| = lim
23 + ... +
3.3 Opposition-Based Optimization (OBO)
pr|min|x−xs|≥|xs−xr| = lim
27 + ... +
Again, we are faced with inﬁnite geometric series and by reusing the Eq. 3.20, we have
pr|min|x−xs|≥|xs−xr| = 1
Fig. 3.9: Situations which min|x −xs| ≥|xr −xs|.
Finally, we have
α ≤(1 −pr|min|x−xs|≥|xs−xr|) = 5
px|min|xs−xr|≥|x−xs| ≤α ≤(1 −pr|min|x−xs|≥|xs−xr|),
Chapter 3. Opposition-Based Optimization
By establishing this boundaries for α and considering Eq.s 3.12 - 3.14, we have
576 ≤px = p˘x ≤845
0.36 ≤px = p˘x ≤0.37.
1152 ≤pr ≤83
0.27 ≤pr ≤0.29.
Hence, the opposite of x (˘x) has a higher chance to be closer to the solution, xs, compared to the second random guess, xr, in a one-dimensional solution space.
The center of the interval [ 4
6] for α is
12 or 0.75. By substituting this mean value in
Eq.s 3.12 - 3.14, we receive
px = p˘x = 0.3613
pr = 0.2773.
Central opposition theorem can be extended to higher dimensions, following theorem
addresses this extension.
Theorem 3.5 (Central Opposition Theorem for D-Dimensional Space)
(a) y = f(X) is an unknown function with X(x1, x2, x3, ..., xD), xi ∈[ai, bi], i = 1, 2, 3, ...,D
and at least one solution at Xs(xs1, xs2, xs3, ..., xsD), xsi ∈[ai, bi], i = 1, 2, 3, ...,D,
3.3 Opposition-Based Optimization (OBO)
(b) X is the ﬁrst uniform random guess and Xr(xr1, xr2, xr3, ..., xrD) is the second uniform
random guess in the solution space,
(c) The opposite point of X(x1, x2, ..., xD) is deﬁned by ˘X(˘x1, ˘x2, ..., ˘xD) where
˘xi = ai + bi −xi, i = 1, 2, 3, ..., D.
∥˘X, Xs∥< ∥Xr, Xs∥
∥Xr, Xs∥< ∥˘X, Xs∥
, where ∥· ∥denotes
the Euclidean distance.
Proof - We have
∥˘X, Xs∥< ∥Xr, Xs∥
∥Xr, Xs∥< ∥˘X, Xs∥
(˘xi −xsi)2 <
(xri −xsi)2
(xri −xsi)2 <
(˘xi −xsi)2
According to the Central Opposition Theorem for one-dimensional space we have
Pr (|˘x −xs| < |xr −xs|) > Pr (|xr −xs| < |˘x −xs|) .
That is true for each dimension in the solution space, so
Pr (|˘xi −xsi| < |xri −xsi|) > Pr (|xri −xsi| < |˘xi −xsi|) , i = 1, 2, 3, ..., D
(˘xi −xsi)2 <
(xri −xsi)2
(xri −xsi)2 <
(˘xi −xsi)2
and the Central Opposition Theorem is also valid for a D-dimensional space.
Chapter 3. Opposition-Based Optimization
Table 3.4: Numerical results generated by Algorithm 2 (µ: Mean, σ: Standard deviation,
CI: Conﬁdence interval).
(0.3616, 0.3618)
(0.3616, 0.3618)
(0.2766, 0.2767)
Empirical Veriﬁcation
In this section, the aforementioned mathematical proofs are experimentally veriﬁed and
the usefulness of the opposite numbers in higher dimensional spaces is investigated. For
this propose, three random points in a D-dimensional space are generated (n times), called
X, Xs, and Xr. Then, the number of times (out of n) which X, ˘X, or Xr is the closest
to the randomly generated solution Xs (measured by Euclidean distance) is counted and
ﬁnally the probability of the closeness of each point is calculated (px, p˘x, and pr).
conducted experiments, n is chosen a large number in order to have an accurate estimation
for probability values. The proposed method for this empirical veriﬁcation is presented in
Algorithm 2. As shown, there are two nested loops, the outer one to feed dimensions and
the inner one to handle n trials for each dimension.
The experiments have been conducted for diﬀerent dimensions ranging from D= 1 to
D=10, 000. In order to attain reliable results, the number of trials n was set to 1, 000, 000.
Results are summarized in Table 3.4.
Results analysis - The mean µ (across all dimensions), standard deviation σ, and
95% conﬁdence interval (CI) of px, p˘x, and pr have been calculated for the results of
dimensions D=1, 2, 3, ..., 10, 000. Low standard deviations and short conﬁdence intervals
show that the probabilities remain the same for all investigated dimensions. The probability
3.4 Empirical Veriﬁcation
Algorithm 2 Calculate px, p˘x, and pr experimentally.
1: Dmax ←10, 000
2: n ←1, 000, 000
3: for D = 1 to Dmax do
for R = 1 to n do
Generate three random points X, Xs, Xr in the D-dimensional space, [ai, bi] =
[−1, 1] for i = 1, 2, 3, ..., D
Calculate the opposite point of X ( ˘X)
Calculate the Euclidean distance of X, ˘X, and Xr from Xs (dX, d ˘
if (dX < d ˘
X) ∧(dX < dr) then
cx ←cx + 1 //x is the closest to the solution
else if (d ˘
X < dX) ∧(d ˘
X < dr) then
c˘x ←c˘x + 1 //˘x is the closest to the solution
else if (dr < dX) ∧(dr < d ˘
cr ←cr + 1 //xr is the closest to the solution
p˘x ←c˘x/n
19: end for
of opposite point p˘x (0.3617) is 0.085 higher than the probability of a second random
guess pr (0.2767). As shown in Table 3.5, interestingly, experimental results conform with
established theorems.
Additional experiments (not presented here) showed that α = 0.75 is a proper value (a
similar experimental method presented in this section is used to simulate e7 and calculate α,
see Figure 3.7). Using this empirical value in Eq.s 3.12 - 3.14, a more accurate comparison
between theoretical and experimental probabilities can be provided (see Table 3.6). As
seen, the probabilities are almost the same.
Chapter 3. Opposition-Based Optimization
Table 3.5: Comparison of experimental and mathematical results.
Mathematical computation
(0.3559, 0.3667)
(0.3559, 0.3667)
(0.2664, 0.2881)
Experimental results
Table 3.6: Comparison of experimental and mathematical results for α = 0.75.
Mathematical computation (α = 0.75)
Experimental results
This chapter established mathematical proofs and provided experimental evidence to verify
the advantage of opposite points, compared to additional random points when dealing
with high-dimensional problems. Both experimental and mathematical results conform
with each other; opposite points are more beneﬁcial than additional independent random
points. Therefore we can conclude that the opposition-based optimization can be utilized
to accelerate searching methods since considering the pair P and ˘P has apparently a higher
ﬁtness probability than pure randomness.
Opposition-Based Diﬀerential
Evolution (ODE)
Therefore, the foundation of the creation was (based) upon opposites.
Necessarily, we are battling because of loss and gain.
– Rumi (1207 – 1273) in “Masnawi”
Chapter 4. Opposition-Based Diﬀerential Evolution (ODE)
Introduction
This chapter discusses how opposition-based optimization can be employed to accelerate
population-based algorithms. In this direction, the opposition-based population initialization and generation jumping schemes are proposed. Simplicity and universality of the
schemes are two main characteristics. The proposed schemes are utilized to introduce the
opposition-based diﬀerential evolution (ODE). The acceleration of the DE algorithm is
targeted by integration of the static opposite points in the initialization step and dynamic
ones in the generation jumping. As it will be mentioned later, the considerable portion
of the acceleration is obtained by generation jumping. The opposition-based initialization
just provides ﬁtter points for the start. The proposed schemes work at the population level
and, for this reason, can be investigated for extension of other population-based algorithms
Opposition-Based Acceleration Schemes
Generally speaking, in order to utilize the advantages of the opposition-based optimization
to accelerate population-based algorithms, many schemes can be suggested and investigated. But, it seems that considering the following features during the design of these
schemes are crucial:
Generality - Proposing general schemes makes it easy to use OBO for a wider range of
population-based optimization methods. Tailored schemes would obviously be more
rigid for generalization. Manipulating the internal operators of the optimizer leads to
lower generality, although, the customized schemes can result a higher performance.
Simplicity - This feature is always desirable. Simplicity supports a higher understandability, and makes any design easy to implement and modify.
Also, in practical
environments, the simple schemes are widely appreciated.
4.2 Opposition-Based Acceleration Schemes
Problem Independency - Proposed schemes have to be universal and capable to solve a
wider range of optimization problems. By equipping the parent optimizer with the
opposition-based schemes, it should not be specialized to solve a group of speciﬁc
problems (e.g., unimodal). This case is experimentally veriﬁable by applying the
algorithm to solve various global optimization problems. In other words, the proposed
schemes should not reduce the universality of the parent optimizer to solve diﬀerent
Eﬀectiveness -
It should be taken into consideration that the evaluation of opposite
points need more function calls and should be controlled smartly to prevent loosing
the beneﬁts through extra computations. Overall, the extra function calls should be
reasonable and bring a beneﬁt to the optimization process. The beneﬁt can be faster
convergence, higher robustness, or higher solution quality. Furthermore, improving
one of these features should not aﬀect the other beneﬁts. During the experimental
veriﬁcation of the proposed algorithm, diﬀerent measures are employed to investigate
each criterion individually.
Any population-based optimization algorithm has two main phases, namely, population
initialization and evolutionary generating of the new population; a general scheme is shown
in Figure 4.1 (A). Three possible stages (marked by gray blocks in Figure 4.1 (B)) are
recognizable to employ opposition-based optimization to accelerate the parent algorithm.
These three stages are:
(1) During population initialization
(2) During population evolution, and
(3) After population evolution
As mentioned before, the evolutionary algorithms are categorized according to the
employed evolutionary operators in their population evolution phase. So, any manipulation
Chapter 4. Opposition-Based Diﬀerential Evolution (ODE)
in this phase reduces the generality of the proposed scheme. Exactly for this reason (to
work at the population level), two stages, (1) and (3), are considered to employ OBO
to accelerate the parent algorithm. Figure 4.2 presents the ﬁnalized general scheme for
this proposal; through this way, two external blocks are selected and one internal block
is removed. These two blocks are called opposition-based population initialization and
opposition-based generation jumping, respectively. In the following subsections, the details
about each block are provided.
Fig. 4.1: (A) A general scheme for population-based optimization algorithms, (B) Three
possible stages (marked by gray blocks) to employ OBO to accelerate (A).
4.2 Opposition-Based Acceleration Schemes
Fig. 4.2: In order to support generality for the opposition-based scheme two external blocks
are chosen ,(1) and (3), to employ OBO. The internal one (2) was removed (see Figure 4.1
Opposition-based population initialization
According to author’s best knowledge, random number generation, in absence of a priori
knowledge, is the commonly used method to create an initial population. But, as mentioned
before, by utilizing OBO we can obtain ﬁtter starting candidates even when there is no a
priori knowledge about the solution(s). Block (1) from Figure 4.3 shows the implementation
of opposition-based population initialization. Following steps explain that procedure:
step 1. Initialize the population P(Np) randomly,
step 2. Calculate opposite population by
OPi,j = aj + bj −Pi,j,
Chapter 4. Opposition-Based Diﬀerential Evolution (ODE)
i = 1, 2, ..., Np ; j = 1, 2, ..., D.
where Pi,j and OPi,j denote the jth variable of the ith population and the oppositepopulation vector, respectively.
step 3. Select the Np ﬁttest individuals from the set {P ∪OP} as the initial population.
According to the above procedure, 2Np function evaluations are required instead of Np
for the regular random population initialization. But, by the opposition-based initialization, the parent algorithm can start with the ﬁtter initial individuals instead, and this is a
one-time cost.
Opposition-based generation jumping
By applying a similar approach to the current population, the evolutionary process can be
forced to jump to a ﬁtter generation. Based on a jumping rate Jr (i.e. jumping probability),
after generating new populations by mutation, crossover, and selection, the opposite population is calculated and the Np ﬁttest individuals are selected from the union of the current
population and the opposite population. As a diﬀerence to opposition-based initialization,
it should be noted here that in order to calculate the opposite population for generation
jumping, the opposite of each variable is calculated dynamically. That is, the maximum
and minimum values of each variable in the current population ([MINp
j]) are used to
calculate opposite points instead of using variables’ predeﬁned interval boundaries ([aj, bj]):
OPi,j = MINp
j −Pi,j, i = 1, 2, ..., Np; j = 1, 2, ..., D.
By staying within variables’ static boundaries, it is possible to jump outside of the
already shrunken search space and lose the knowledge of the current reduced space (converged population). Hence, we calculate opposite points by using variables’ current interval in the population ([MINp
j]) which is, as the search does progress, increasingly
4.2 Opposition-Based Acceleration Schemes
Fig. 4.3: New blocks are illustrated by gray boxes. Block (1): Opposition-based initialization, Block (3): Opposition-based generation jumping (Jr: jumping rate, rand(0, 1):
uniformly generated random number, Np: population size). Block (2) is removed.
smaller than the corresponding initial range [aj, bj]. Block (3) from Figure 4.3 indicates
the implementation of opposition-based generation jumping.
A pictorial example is presented in Figure 4.4 to exhibit opposition-based generation
jumping procedure in 2D space. ‘S’ indicates location of the solution. Dark and light circles
present the points and the opposite points, respectively. As seen, in the resulted population
(shown by the current P), the average distance of the selected candidates (which contains
some original points and the opposite of some others) from the solution is smaller than it
was for population (P) and opposite population (OP), individually.
Chapter 4. Opposition-Based Diﬀerential Evolution (ODE)
Fig. 4.4: A pictorial example to show the opposition-based generation jumping in 2D space
Furthermore, a real example for the opposition-based generation jumping in 2D space
(Np = 1000) is presented in Figure 4.5. The P, OP, {P ∪OP}, and the selected individuals
after the population jumping are shown for some objective functions.
Opposition-Based Diﬀerential Evolution
Now, everything is ready to build opposition-based diﬀerential evolution (ODE). Similar to all population-based optimization algorithms, two main phases are distinguishable
for the classical DE, namely, population initialization and producing new generations.
DE is chosen as a parent algorithm for the proposed general scheme and the mentioned
opposition-based population initialization and generation jumping are embedded inside
DE, to increase the convergence speed. Corresponding ﬂowchart and pseudo-code for the
4.3 Opposition-Based Diﬀerential Evolution
A real example for the opposition-based generation jumping in 2D space
(Np = 1000). Top to bottom, left to right: P, OP, {P ∪OP}, the selected individuals
after the jumping for the following objective functions f1(x) =
(x1 −0.5)2 + (x2 −0.5)2,
(x1 −0.75)2 + (x2 −0.5)2,
(x1 −1)2 + (x2 −0.5)2,
(x1 −1)2 + (x2 −1)2.
Chapter 4. Opposition-Based Diﬀerential Evolution (ODE)
proposed approach (ODE) are given in Figure 4.6 and Algorithm 3, respectively. Block (1)
from Figure 4.6 and steps 2-7 in Algorithm 3 show the implementation of opposition-based
initialization and block (3) and steps 27-34 show the implementation of opposition-based
generation jumping for ODE. The remaining tasks are DE’s regular steps.
Fig. 4.6: Opposition-Based Diﬀerential Evolution (ODE).
4.3 Opposition-Based Diﬀerential Evolution
Algorithm 3 Pseudo-code for Opposition-Based Diﬀerential Evolution (ODE). P0: Initial
population, OP0: Opposite of initial population, P: Current population, OP: Opposite
of current population, D: Problem dimension, [aj, bj]: Range of the j-th variable, Jr:
Jumping rate, minp
j: Minimum/maximum value of the j-th variable in the current
population.
Steps 2-7 and 27-34 are implementations of opposition-based population
initialization and opposition-based generation jumping, respectively.
1: Generate uniformly distributed random population P0
//Begin of Opposition-Based Population Initialization
2: for i = 0 to Np do
for j = 0 to D do
OP0i,j ←aj + bj −P0i,j
6: end for
7: Select Np ﬁttest individuals from set the {P0, OP0} as initial population P0
//End of Opposition-Based Population Initialization
//Begin of DE’s Evolution Steps
8: while ( BFV > VTR and NFC < MAXNFC ) do
for i = 0 to Np do
Select three parents Pi1, Pi2, and Pi3 randomly from current population where i ̸= i1 ̸= i2 ̸= i3
Vi ←Pi1 + F × (Pi2 −Pi3)
for j = 0 to D do
if rand(0, 1) < Cr then
Ui,j ←Vi,j
Ui,j ←Pi,j
Evaluate Ui
if (f(Ui) ≤f(Pi)) then
//End of DE’s Evolution Steps
//Begin of Opposition-Based Generation Jumping
if rand(0, 1) < Jr then
for i = 0 to Np do
for j = 0 to D do
OPi,j ←MINp
Select Np ﬁttest individuals from set the {P, OP} as current population P
//End of Opposition-Based Generation Jumping
35: end while
Chapter 4. Opposition-Based Diﬀerential Evolution (ODE)
A general opposition-based scheme for population-based algorithms is proposed in this
chapter. The details for opposition-based population initialization and generation jumping
are provided, and, these two new blocks are embedded inside classical DE to introduce
the opposition-based DE. In the proposed scheme, evolutionary part of the algorithm is
kept untouched to support a higher generality. The rate of generation jumping can be
controlled by the jumping rate (Jr) and each block (initialization and generation jumping)
works independently. Opposition-based population initialization provides ﬁtter individuals
to start; and the opposition-based generation jumping forces the population to jump and
continue with a ﬁtter generation.
Both newly embedded blocks should accelerate the
convergence rate of the DE. Experimental results will support this expectation. Discussion
about the control parameter (Jr) will be provided later.
Empirical Study and Analysis
The strongest arguments prove nothing so long as the conclusions are not veriﬁed by experience. Experimental science is the queen of sciences and the goal
of all speculation.
– Roger Bacon (c. 1214–1294)
Chapter 5. Empirical Study and Analysis
Introduction
Similar to other evolutionary algorithms and due to stochastic nature, a strong convergence proof for diﬀerential evolution does not exist [Feoktistov 2006]. It means that even
two diﬀerent versions of DE cannot be compared mathematically, such that experimental
comparison is required (unlike deterministic algorithms which can be compared through
algorithm complexity analysis). Like many other studies in this ﬁeld, a comprehensive
benchmark test suite is employed to empirically analyze the ODE. Nine experimental series have been designed and conducted. In subsections 5.5.7-5.5.9, ODE is compared with
six other evolutionary algorithms. Convergence speed, success rate, and solution quality
are three core measures in the following studies.
Benchmark Test Suite
A comprehensive set of benchmark functions, including 58 diﬀerent global optimization
problems, has been employed for performance veriﬁcation of the proposed approach . The deﬁnition of the benchmark functions and their global optimum(s) are listed in Appendix A. Generally, following characteristics are desirable to provide a comprehensive test suite:
Selecting well-known test functions:
All 58 functions are frequently used benchmark problems in global optimization ﬁeld. However, there is no unique standard
test set; researchers usually use a subset of well-known functions to validate their
work. Generally, the size of the test suite is between 5 and 25 functions.
Some sample 3-D maps for 2-D functions from the selected test suite are presented
in Figures 5.1 and 5.2.
5.2 Benchmark Test Suite
(a) f1 (1st De Jong) is unimodal, scalable,
convex, and easy function.
(b) f4 (Rosenbrock’s Valley) is unimodal,
scalable, non-convex, and hard function.
The minimum is inside a long, narrow,
parabolic shaped ﬂat valley
(c) f5 (Rastrigin’s Function) is highly multimodal. The location of the minima are
regularly distributed.
(d) f6 (Griewangk’s Function) has many
regularly distributed local minima and
hard to locate global minimum.
Fig. 5.1: Some sample 3-D maps for 2-D functions selected from the test suite.
Chapter 5. Empirical Study and Analysis
(a) f8 (Ackley’s Problem), the number of
local minima is unknown.
(b) f11 (Easom Function) is unimodal and
the global minimum has a small area relative to the search space.
(c) f18 (Michalewicz Function) has n! local
minima. Steepness of the valleys or edges
makes it a hard optimization problem.
(d) f32 (Schaﬀer’s Function 6) is multimodal and symmetric.
Fig. 5.2: Continued from Figure 5.1.
5.2 Benchmark Test Suite
With a simple, but not exact deﬁnition, all benchmark functions can
be categorized in three groups:
1) Unimodal functions (functions with one global optimum, e.g., Figures 5.1(a),
5.1(b), and 5.2(b)),
2) Multimodal functions with a few local optima (e.g., Figure 5.1(d)),
3) Multimodal functions with many local optima (e.g., Figures 5.1(c), 5.2(a), 5.2(c),
and 5.2(d)).
In general, escaping from local optima to ﬁnd the global optimum is a challenging
task for any optimizer. Generally speaking, the multimodal functions are harder than
unimodal ones, but the functions’ shape can aﬀect the hardness of the problem even
for a unimodal function. As an example, Rosenbrock’s Valley (Figure 5.1(b)) and
Easom Function (Figure 5.2(b)) are unimodal functions, but both are diﬃcult; for
the ﬁrst one the minimum is inside a long, narrow, parabolic shaped ﬂat valley and
for the second one the global minimum has a small area relative to the search space
(small basin).
In our test suite, 23 of functions are unimodal, 18 are multimodal with a few (smaller
than 10) local optima, and 17 are highly multimodal functions.
Scalability:
Possessing 20 scalable functions in our test set provides the opportunity to validate the proposed approach for diﬀerent dimensions. On the other hand,
scalable functions are usually separable (means the parameters can be optimized
individually).
In revers manner, non-scalable functions tend to be nonseparable.
Majority of the functions in our test suite are nonseparable functions, which are
challenging for any optimization contest.
Wide dimension size:
The dimensions of the test functions are distributed mostly
between 2 and 60. In the conducted dimensionality study, 49 low dimensional func-
Chapter 5. Empirical Study and Analysis
tions (D ≤10) and 49 high dimensional functions (D > 10) have been tested.
Including eccentric solution problems:
Sometimes, algorithms are biased toward the center of the searching space. Hence, they perform better with the functions
which the solution is in the center of the search space. To prevent biased results, 33
of the functions have the optimal solutions not located in the center of search space.
Complex structures:
Existence of small attraction basins, saddle points, steep
edges, padding with noise, distributed local optima around the global optimum,
and lack of useful information on function’s global structure (e.g., ﬂat structure) are
some examples which make optimization much more challenging. For each mentioned
source of complexity, there is at least one representative in the test suite.
Comparison Strategies and Metrics
We compare the convergence speed of DE and ODE by measuring the number of function calls (NFC) which is the most commonly used metric in literature [Price et al. 2005;
Vesterstroem and Thomsen 2004; Hrstka and Kuˇcerov´a 2004; Suganthan et al. 2005]. A
smaller NFC means higher convergence speed. The termination criterion is to ﬁnd a value
smaller than the value-to-reach (VTR) before reaching the maximum number of function
calls MAXNFC. VTR is selected as a very small value (e.g. 10−8) to guarantee high accuracy. In order to minimize the eﬀect of the stochastic nature of the algorithms on the
metric, the reported number of function calls (NFC) for each function is the average over
50 trials. In order to compare convergence speeds, we use the acceleration rate (AR) which
is deﬁned as follows, based on the number of function calls for the two algorithms DE and
AR = NFCDE
5.4 Parameter Settings
where AR > 1 means ODE is faster.
The number of times, for which the algorithm succeeds to reach the VTR for each test
function is measured as the success rate (SR) [Suganthan et al. 2005]:
SR = number of times reached VTR
total number of trials
SR is a commonly used metric to quantify the robustness of the algorithms.
Further, the average acceleration rate (ARave) and the average success rate (SRave) over
n test functions are calculated as follows:
These two average metrics help us to have an overall comparison for the entire test suite;
other measures such as number of solved (SR ̸= 0) problems and number of problems for
which the algorithm shows better results than other competitor(s) are taken to account
for this purpose.
Parameter Settings
Parameter settings for all conducted experiments are as follows unless a change is mentioned
(the same setting has been used in literature cited after of each parameter):
• Population size, Np = 100 [Brest et al. 2006; Yao et al. 1999; Lee and Yao 2004]
• Diﬀerential ampliﬁcation factor, F = 0.5 [Storn and Price 1997a; Ali and T¨orn 2004;
Liu and Lampinen 2005; Brest et al. 2006; Rahnamayan and Dieras 2007]
Chapter 5. Empirical Study and Analysis
• Crossover probability constant, Cr = 0.9 [Storn and Price 1997a; Ali and T¨orn 2004;
Liu and Lampinen 2005; Brest et al. 2006; Rahnamayan and Dieras 2007]
• Jumping rate constant, Jr = 0.3 (discussed in subsection 5.5.6)
• Mutation strategy: DE/rand/1/bin (classic version of DE) [Storn and Price 1997a;
Price et al. 2005; Onwubolu and Babu 2004; Brest et al. 2006; Sun et al. 2005]
• Maximum number of function calls, MAXNFC = 106 [Rahnamayan et al. 2006f]
• Value to reach, VTR= 10−8 [Suganthan et al. 2005]
In order to maintain a reliable and fair comparison, (a) the parameter settings are the
same as above for all experiments, unless we mention new settings to serve the purpose
of that parameter study, (b) for all conducted experiments, the reported values are the
average of the results for 50 independent runs, and the last and also more important
one, (c) needless to say, extra ﬁtness evaluations required for the opposite points (both in
population initialization and also generation jumping phases) are counted as well.
Experimental Studies
A comprehensive set of experiments has been conducted and they are categorized as follows. In subsection 5.5.1, DE and ODE are compared in terms of convergence speed and
robustness. The eﬀect of problem dimensionality is investigated in subsection 5.5.2. The
contribution of opposite points to the achieved acceleration results is demonstrated in
subsection 5.5.3. The eﬀect of population size is studied in subsection 5.5.4. Comparison of DE and ODE over diﬀerent mutation operators is performed in subsection 5.5.5.
Discussion about the control parameter, jumping rate, is covered in subsection 5.5.6. And
ﬁnally, ODE is compared with DE, Fuzzy Adaptive DE (FADE), Adaptive LEP, Best L´evy,
5.5 Experimental Studies
Fast Evolutionary Programming (FEP), and Classical Evolutionary Programming (CEP)
in subsections 5.5.7-5.5.9.
Experiment series 1: comparison of DE and ODE
First of all, we need to compare the parent algorithm, DE, with ODE in terms of convergence speed and robustness. The results for solving 58 benchmark functions (see Appendix
A) are given in Table 5.1. The best result for the number of function calls (NFC) and the
success rate (SR) for each function are highlighted in boldface. The average success rates
(SRave) and the average acceleration rate (ARave) on 58 test functions are shown in the
last row of the table.
ODE outperforms DE on 40 test functions (69% of problems) while DE surpasses ODE
on 15 functions (26% of problems). Over the remaining 3 functions (5% of cases) they
perform the same. Except for f4, the rest of 14 functions are low-dimensional functions
(D≤10). Average acceleration rate (ARave) is 1.44 which means ODE is on average 44%
faster than DE. While the average success rate (SRave) for both is equal to 0.86, both
algorithms fail to solve f13, f26, and f27; in addition, DE fails to solve f51 and ODE is
unsuccessful on f4. Some sample graphs for the performance comparison between DE and
ODE are given in Figure 5.3. These curves (best solution vs. number of function calls)
show that ODE converges faster than DE toward the optimal solution.
Results analysis - With the same control parameter settings for both algorithms and
ﬁxing the jumping rate for the ODE (Jr = 0.3), their success rates are comparable while
ODE shows better convergence speed than DE (44% faster overall). Jumping rate is an
important control parameter which, if optimally set, can achieve even better results; the
discussion about this parameter is covered in subsection 5.5.6.
Chapter 5. Empirical Study and Analysis
Table 5.1: Comparison of DE and ODE. D: Dimension, NFC: Number of function calls, SR:
Success rate, AR: Acceleration rate. The last row of the table presents the average success
rates (SRave) and the average acceleration rate (ARave). The best results are highlighted
in boldface. AR> 1 means ODE performs faster.
SRave(DE) = 0.86, SRave(ODE) = 0.86, ARave = 1.44
5.5 Experimental Studies
(a) f1, ODE is 1.83 times faster.
(b) f2, ODE is 1.81 times faster.
(c) f6, ODE is 1.64 times faster.
(d) f8, ODE is 1.72 times faster.
Fig. 5.3: Sample convergence graphs (best solution vs. number of function calls).
Experiment series 2: inﬂuence of dimensionality
In order to investigate the eﬀect of the problem dimensionality, the same experiments are
repeated for D′=D/2 and D′=2D for each scalable function in our test set. All control
parameters remain unchanged. Results for D/2 and 2D are illustrated in Table 5.2 for 40
test functions.
According to the obtained results, ODE surpasses DE on 34 test functions while DE
Chapter 5. Empirical Study and Analysis
outperforms ODE on 2 functions (f4(D=15) and f18(D=5)). Both algorithms are unable to
solve f4(D=60), f19(D=60), f22(D=60), and f51(D=20) before meeting the maximum number of
function calls. The average acceleration rate is equal to 1.73, meaning that ODE performs 73% faster than DE. The average success rate for DE and ODE are 0.82 and 0.81,
respectively.
For 11 functions (f1, f2, f6, f7, f8, f15, f16, f18, f21, f41, and f56), the acceleration rate
(AR) increases as the dimensionality grows. ODE achieves more desirable results for all
but 4 of the functions (f3, f5, f23, and f31) where no improvement can be observed. An
interesting eﬀect for f18 is that for dimensions 5 and 10 (for D= 10 see Table 5.1), DE
performs better than ODE; but when the dimension is increased to 20, ODE shows better
results in terms of NFC and SR. Furthermore, DE cannot solve f24 for D= 60, but ODE
solves it in 35% of the trials.
At the bottom of the Table 5.2, the average success rates and the average acceleration
rates for functions with D/2, 2D are presented. For functions with dimension of D/2,
the overall success rate for DE is 4% higher than ODE’s (0.98 vs. 0.94) and the overall
acceleration rate is 1.67. For functions with dimension of 2D, overall success rate of DE
and ODE are almost the same (0.66 vs. 0.67, respectively). But this value is smaller than
what we had observed for D/2. For this case the overall acceleration rate is 1.81.
Results analysis - Decreasing of the overall success rate for DE and ODE was predictable because if we double the problem dimension, algorithms are sometimes unable to
solve the problem before reaching the maximum number of function calls (which is a ﬁxed
number for all experiments). But as seen, ODE performs better for high dimensional problems. The higher average acceleration rate has been achieved for functions with dimension
5.5 Experimental Studies
Table 5.2: Comparison of DE and ODE for dimension sizes D/2 and 2D for all scalable
functions of the test suite. At the bottom of the table, the average success rates and the
average acceleration rates for functions with D/2, 2D, and for both (overall) are presented.
The best values of NFC and SR for each case are highlighted in boldface.
D/2, SRave(DE) = 0.98, SRave(ODE) = 0.94, ARave = 1.67
2D, SRave(DE) = 0.66, SRave(ODE) = 0.67, ARave = 1.81
Overall, SRave(DE) = 0.82, SRave(ODE) = 0.81, ARave = 1.73
Experiment series 3: contribution of opposite points
In this section, we want to verify that the achieved acceleration rate is really due to
utilizing opposite points and not due to additional sampling. For this purpose, all parts
of the proposed algorithm are kept untouched and instead of using opposite points for the
population initialization and the generation jumping, uniformly generated random points
are employed.
In order to have a fair competition for this case, exactly like what we
underwent for opposite points, the predeﬁned boundaries of variables ([aj, bj]) and the
current interval (dynamic interval, [MINp
j]) of the variables are used to generate
new random points.
Chapter 5. Empirical Study and Analysis
After this modiﬁcation (using additional random numbers instead of opposite numbers),
the random version of ODE (called RDE) is introduced. Now, we are ready to apply this
algorithm to solve our test problems. All control parameters are kept the same to have a
fair comparison. Results for the current algorithm are presented in Table 5.3 (f1 −f29)
and Table 5.4 (f30 −f58); also the results of DE and ODE (from Table 5.1) are repeated in
these tables to ease the comparison among these three competitors (DE, ODE, and RDE).
Two acceleration rates are reported in the last row of the Table 5.4, ARODE =
NFCODE and
NFCRDE compare DE with ODE and RDE, respectively.
As seen, ODE outperforms DE and RDE on 40 functions. DE performs better than
ODE and RDE on 15 functions. The RDE can outperform DE (but not ODE) on just 3
functions f17, f22, and f35 (emphasized in boldface under the ARRDE column). The average acceleration rate (DE vs. RDE) is 0.87; which means the RDE is 13% slower than its
parent algorithm. The average success rate is almost the same for all of them (0.86, 0.86,
and 0.87 for DE, ODE, and RDE, respectively).
Results analysis - Just by replacing the opposite numbers with additional random
numbers - while the random numbers are generated uniformly in the variables dynamic
intervals and the rest of the proposed algorithm is kept untouched - the average acceleration
rate has dropped from 1.44 (ARODE) to 0.87 (ARRDE) which is a 57% reduction in speed.
This clearly demonstrates that the achieved improvements are due to usage of opposite
points, and that the same level of improvement cannot be achieved via additional random
sampling. We had already demonstrated both mathematically and experimentally why
opposite numbers are more beneﬁcial than pure random numbers (see chapter 3).
Experiment series 4: eﬀect of population size
In order to investigate the eﬀect of the population size, the same experiments (conducted
in section 5.5.1 for Np = 100) are repeated for N ′
p = Np/2 and N ′
p = 2Np. The results for
5.5 Experimental Studies
Table 5.3: Comparison of DE, ODE, and RDE. The best result is highlighted in boldface
(f1 −f29).
Np = 50 and Np = 200 are given in Tables 5.5 and 5.6, respectively. In order to discuss
the population size, the overall results of three tables (Table 5.1, Table 5.5, and Table 5.6)
are summarized in Table 5.7.
For Np = 50, the average success rate for DE and ODE is 0.79 and 0.77, respectively
(DE performs marginally better than ODE). But, DE fails to solve 9 functions while ODE
fails on 7. ODE outperforms DE on 35 functions; this number is 15 for DE. The average
acceleration rate is 1.05 for this case (AR=60.16 for f33 is excluded as an exceptional case
in order to avoid non-representative statistics). By carefully looking at the results, we can
Chapter 5. Empirical Study and Analysis
Table 5.4: Continued from Table 5.3 (f30 −f58).
recognize that when the population size is reduced from 100 to 50, four functions (namely,
f3, f5, f19, and f31) for which ODE has outperformed DE, are now (for population size 50)
solved faster by DE. However, this was predictable because the dimension of those functions
are 20, 10, 30, and 30, respectively, and Np = 50 is a small population size to solve these
functions. Many authors have proposed 10D as a proper value for the population size
[Liu and Lampinen 2005; Storn 1996]. On the other hand, as we know, ODE reduces the
population diversity by its selection method. For small population size, we need to reduce
the jumping rate in order to control the diversity reduction. Here, the jumping rate was
5.5 Experimental Studies
Table 5.5: Comparison of DE and ODE (Np = 50).
SRave(DE) = 0.79, SRave(ODE) = 0.77, ARave = 1.05
kept the same (= 0.3) for all population sizes.
As mentioned before, for Np = 100, DE and ODE show an equal average success rate
(SR= 0.86), and they fail to solve an equal number of functions (n(SR=0) = 4). But, ODE
outperforms DE on 40 functions, whereas DE outperforms ODE on 15 functions. The
average acceleration rate is 1.44 for this case.
For Np = 200, ODE outperforms DE on all mentioned measures (0.86, 6, and 39 vs.
0.82, 7, and 15, respectively); and the average acceleration rate is 1.86. As shown in the last
two rows of Table 5.7, ODE performs better than DE in terms of all performance measures.
Chapter 5. Empirical Study and Analysis
Table 5.6: Comparison of DE and ODE (Np = 200).
SRave(DE) = 0.82, SRave(ODE) = 0.86, ARave = 1.68
Results analysis - According to the results of section 5.5.1 and 5.5.2, for the majority
of functions, ODE performs better when the dimension of the scalable problems increases.
On the other hand, for higher dimensional problems a larger population size should be
employed (e.g. Np = 10D). According to results of this section, ODE performs better for
larger population sizes.
5.5 Experimental Studies
Table 5.7: The summarized results from Table 5.1, Table 5.5, and Table 5.6. nDE and
nODE are the number of functions for which DE outperforms ODE and vice versa. nSR=0
is the number of unsolved functions by the algorithm (SR= 0).
Experiment series 5: eﬀect of various mutation operators
More than ten mutation strategies have been developed for DE [Storn and Price 1997a;
Price et al. 2005; Feoktistov 2006]. Although, many researchers report results for one of
these mutation strategies, most works [Storn and Price 1997a; Brest et al. 2006; Sun et al.
2005] use the standard one, namely DE/rand/1/bin, as we did. In this study, three other
well-known mutation strategies, namely, DE/rand/1/exp, DE/rand/2/exp, and DE/rand/
2/bin are selected to investigate the eﬀect of the mutation operator.
The results are
presented in Table 5.8 (for f1 −f29) and Table 5.9 (for f30 −f58). The overall results of
these two tables and Table 5.1 (for DE/rand/1/bin) are summarized in compact form in
Table 5.10 to ease the comparison.
For all mutation strategies, ODE performs better than DE by looking at the total number of function calls, average success rate, number of solved functions, number of functions
for which ODE outperforms DE, and the average acceleration rate.
Results analysis - According to the Table 5.10, the best mutation strategy for
DE and also for ODE is the DE/rand/1/bin.
This conﬁrms choosing mutation strategy DE/rand/1/bin as a standard operator by other researchers [Storn and Price 1997a;
Brest et al. 2006;
Sun et al. 2005].
Furthermore, it is noticeable that the average ac-
Chapter 5. Empirical Study and Analysis
Table 5.8: Comparison of DE and ODE on three diﬀerent mutation strategies (f1 −f29). The best result of
each mutation strategy is emphasized in boldface.
DE/rand/1/exp
DE/rand/2/exp
DE/rand/2/bin
5.5 Experimental Studies
Table 5.9: Continued from Table 5.8 (f30 −f58).
DE/rand/1/exp
DE/rand/2/exp
DE/rand/2/bin
Chapter 5. Empirical Study and Analysis
Table 5.10: The summarized results from Tables 5.1, 5.8, and 5.9.
P NFCi is the total of
number of function calls (just for the functions which all 8 competitors could solve). nSR=0
is the number of unsolved functions (SR = 0). nDE and nODE are the number of functions
for which DE outperforms ODE and vice versa. N is the number of functions for which
the algorithm could outperform seven other algorithms. ARave is the average acceleration
Mutation Strategy
DE/rand/1/bin
DE/rand/1/exp
DE/rand/2/exp
4, 865, 187
1, 207, 478
DE/rand/2/bin
4, 070, 189
1, 119, 580
celeration rate is even higher for other mutation strategies. For the mutation strategy
DE/rand/2/bin, the average acceleration rate 3.03 is the highest.
Experiment series 6: proper setting of jumping rate Jr
In the proposed algorithm, a new control parameter, Jr, is added to DE parameters (F,Cr,
and Np). Although this parameter was ﬁxed for all experiments, the performance of ODE
can vary for diﬀerent Jr values. The jumping rate for our current study was set to Jr = 0.3
without any eﬀort to ﬁnd an optimal value. In some trials, we observed that a jumping
rate higher than 0.6 is not suitable for many functions and causes a premature convergence
or an unusual growing of the number of function evaluations. On the other hand, Jr = 0
means no usage of opposition. With this method, simply the mean value of the 0 and 0.6,
(Jr = 0.3), was selected for all conducted experiments as a default value.
In this section, we try to ﬁnd an optimal jumping rate (Jrop) for each test function from
a discrete set of jumping rate values to answer the question whether a general recommendation for Jr setting can be oﬀered. Now, we are faced with this fundamental question: In
order to ﬁnd the optimal jumping rate, should we look for the minimum number of function
5.5 Experimental Studies
calls (NFC) or the maximum success rate (SR)? Both measures are important factors in an
optimization process. So, two individual objectives should be considered simultaneously.
In order to combine these two measures, a new measure, called success performance (SP),
has been introduced as follows [Suganthan et al. 2005]:
SP = mean (NFC for successful runs)
By this deﬁnition, the two following algorithms have equal performances (SP=100):
Algorithm A: mean (NFC for successful runs)=50 and SR=0.5,
Algorithm B: mean (NFC for successful runs)=100 and SR=1.
SP gives an equal importance weight to NFC and SR. But depending on diﬀerent
applications each of them can be more important than other one. Sometimes success rate
is more crucial than convergence speed and vice versa. For our experiments, gathering
results for unsuccessful case is more time consuming because the algorithm should meet a
maximum number of function calls for termination.
Now, we repeat the conducted experiments in section 5.5.1 for Jr ∈(0, 0.6] with a step
size of 0.1 (i.e. 50 trials per function per jumping rate value Jr ∈{0.1, 0.2, 0.3, 0.4, 0.5, 0.6}).
Due to space limitations, we do not show all results but just the obtained optimal value
for the jumping rate with respect to the success performance as given in Table 5.11.
As seen, the optimal values for the jumping rate are distributed over the discrete interval
(0, 0.6]. However, jumping rates of 0.3 and 0.6 occur more frequently than other values in
this table. Higher jumping rates mostly belong to the low dimensional functions and lower
ones to the high dimensional functions (but this is probably not a general phenomenon).
The average value of the obtained optimal jumping rates ( ¯Jrop) is equal to 0.37 for our test
functions.
Some sample graphs (SP vs. Jr) are shown in Figure 5.4 to illustrate the eﬀect of
jumping rate on success performance. The point speciﬁed by Jr = 0 indicates the success
Chapter 5. Empirical Study and Analysis
Table 5.11: Optimal jumping rate Jrop for all test functions with respect to the success
performance (SP) on interval (0, 0.6] with step-size of 0.1.
performance of the DE; the rest of points (0.1, 0.2, 0.3, 0.4, 0.5, 0.6) show the success performance of ODE. As mentioned before, we can observe a sharp increase in the SP for hard
functions (e.g. f5, f8, f22, f31, and f51) using higher jumping rates. Also, the SP decreases
for easy functions by increasing the jumping rate (see f7, f41, and f56). Almost a smooth
behavior for all functions is recognizable for Jr ∈{0.1, 0.2, 0.3, 0.4} (it was observed even
for many functions whose graphs are not presented here). Hence, working in this interval
([0.1, 0.4]) could be reasonable for unknown optimization problems.
Results analysis - Like DE’s control parameters, optimal jumping rate should have
a problem-oriented value. The conducted experiments suggest the range of [0.1, 0.4] for an
unknown optimization problem. A ﬁrst attempt can be conducted with Jr = 0.37 ( ¯Jrop).
Furthermore, for high dimensional problems, a smaller jumping rate can be suggested.
5.5 Experimental Studies
Fig. 5.4: Graphs of success performance (SP) vs. jumping rate (Jr ∈(0, 0.6] with step
size of 0.1) for sample functions.
Jr = 0 shows the SP of the DE; the rest of points
(0.1, 0.2, 0.3, 0.4, 0.5, 0.6) show the SP of the ODE.
Experiment series 7: comparison with DE and FADE
The primary purpose here is to introduce the notion of the opposition into the design and
implementation of the population-based algorithms, diﬀerential evolution in particular, and
demonstrate its beneﬁts. Many other extensions of DE, if not all, can also be reconsidered
to incorporate the opposition concept.
In this sense, ODE should be regarded as an
example and not as a competitor to other DE versions or other optimizers. However, in
the current section and the following two sections, in order to assess ODE’s performance,
it is compared to the parent algorithm (DE) and also to ﬁve other well-known evolutionary
optimizers in term of solution quality.
ODE is compared with the fuzzy adaptive diﬀerential evolution (FADE) method of
Liu and Lampinen in this section. FADE employs a fuzzy logic controller to set the
Chapter 5. Empirical Study and Analysis
mutation and crossover rates. Liu and Lampinen tested FADE for 10 well-known benchmark functions, of which we have 9 in our test set. The comparison strategy is diﬀerent
for this experiment. The algorithms are run 100 times. Subsequently, for an equal (ﬁxed)
number of function calls the average and standard deviation of the best solutions are calculated for the purpose of comparison. The same settings for parameters [Liu and Lampinen
2005] have been used in the current experiment to assure a fair comparison. The population size is equal to 10D and instead of using the generation number for DE and ODE
an equal number of function evaluations has been used (Np × #Gen.) as the termination
criteria (since in each generation the numbers of function calls for DE and ODE are not
equal). The dimension of the functions, corresponding generation numbers, and obtained
results (best mean and standard deviation of 100 runs) for DE, ODE, and FADE are given
in Table 5.12. Results for FADE are taken from [Liu and Lampinen 2005, Table 6, p. 459].
A two-tailed t-test at a 0.05 signiﬁcance level has been used to compare results of ODE
against those of DE and FADE.
Results analysis - According to the t-test, ODE performs better than DE on 9 functions (out of 16). There is no diﬀerence for the rest of functions. ODE surpasses FADE on
12 functions, and they perform the same on the rest. So, DE and FADE cannot show better
results than ODE even for one function. Although, the comparison of a non-adaptive algorithm (ODE) to an adaptive one (FADE) is not fair but interestingly the results conﬁrm
that ODE outstandingly performs not only better than DE but also better than FADE.
Experiment series 8: comparison with Adaptive LEP and
Best L´evy
Lee and Yao proposed an evolutionary programming (EP) algorithm using adaptive
as well as nonadaptive L´evy mutations. They called the approaches Adaptive LEP and
5.5 Experimental Studies
Table 5.12: Comparison of DE, ODE, and Fuzzy Adaptive DE (FADE). Mean best and standard deviation
(Std Dev) of 100 runs are reported. For DE and ODE, equal number of function calls are used instead of
generation numbers (Np × #Gen.). Two-tailed t-test is used to compare ODE against DE and FADE. ‘†’
indicates that the t value of 99 degree of freedom is signiﬁcant at a 0.05 level of signiﬁcance. fmin indicates
optimal minimum of the function.
Mean Best (Std Dev)
Mean Best (Std Dev)
Mean Best (Std Dev)
3.49 × 10−7 (5.12 × 10−7)†
4.79 × 10−8 (5.81 × 10−8)
1.18 × 10−5 (1.88 × 10−10)†
1.25 × 10−13 (4.88 × 10−14)†
1.73 × 10−64 (1.59 × 10−64)
2.35 × 10−10 (2.97 × 10−21)†
8.0 × 10−3 (2.93 × ×10−2)
4.8 × ×10−3 (1.80 × ×10−2)
2.2 × 10−3 (7.73 × 10−5)
5.30 (9.56 × 10−1)†
5.01 × 10−1 (8.90 × 10−1)
4.16 × 10+1 (1.82 × 10−2)†
3.43 × 10+2 (0.98 × 10+1)†
6.56 × 10+1 (6.80 × 10+1)
2.58 × 10+2 (9.17 × 10+1)†
5.19 × 10−4 (1.9 × 10−3)
1.49 × 10−4 (1.0 × 10−3)
2.4 × 10−3 (1.20 × 10−5)†
6.13 × 10−11 (2.02 × 10−11)†
1.53 × 10−62 (2.38 × 10−62)
5.78 × 10−1 (3.5 × 10−3)†
1.07 × 10−2 (7.4 × 10−3)†
4.8 × 10−3 (3.7 × 10−3)
1.56 × 10−1 (1.20 × 10−2)†
2.33 × 10−6 (2.33 × 10−6)†
7.02 × 10−15 (1.66 × 10−15)
5.9 × 10−2 (1.23 × 10−6)†
−0.9896 (1.3 × 10−3)†
5.1 × 10−3 (9.69 × 10−4)†
8.70 × 10−4 (3.30 × 10−4)
9.16 (1.50 × 10−1)†
1.64 × 10−2 (2.4 × 10−3)†
9.04 × 10−4 (3.41 × 10−4)
1.90 × 10+1 (2.92 × 10−1)†
3.0001 (3.35 × 10−7)†
Chapter 5. Empirical Study and Analysis
Best L´evy, respectively. For the ﬁrst time, a L´evy mutation instead of Gaussian mutation
was employed in EP. According to the reported results, their algorithm performs better
than classical EP in the case of functions with many local optima. These EPs new versions
are tested for 14 benchmark functions, of which we have 12 in our test set. The comparison
strategy is the same as previous experiment. The same settings for generation numbers,
problem dimensions, and population size (Np = 100) [Lee and Yao 2004] have been utilized. The dimension of the functions, corresponding generation numbers, and obtained
results (best mean and standard deviation of 50 runs 1) for ODE, Adaptive LEP and Best
L´evy are given in Table 5.13. Results for Adaptive LEP and Best L´evy are taken from
[Lee and Yao 2004, Table 3, p.12].
Results analysis - According to the t-test, ODE performs better than Adaptive LEP
and Best L´evy on 7 and 8 functions (out of 12), respectively. While, Adaptive LEP and
Best L´evy outperform ODE on 2 functions, individually. Over the rest of functions, the
results are the same with respect to two-tailed t-test.
Experiment series 9: comparison with FEP and CEP
The fast evolutionary programming (FEP) was proposed in [Yao et al. 1999] and was compared to the classical evolutionary programming (CEP).
A 23-function test suite was
utilized to compare the algorithms. Our test suite contains 17 of them. The results to
solve these 17 functions by ODE, FEP and CEP are presented in Table 5.14. In order to
support a fair comparison, the same settings for the generation numbers, problem dimensions, and population size (Np = 100) [Yao et al. 1999] have been utilized. Results for FEP
and CEP are taken from [Yao et al. 1999, Table II-IV].
1The same setting as for Adaptive LEP and Best L´evy in [Lee and Yao 2004].
5.5 Experimental Studies
Table 5.13: Comparison of ODE, Adaptive LEP, and Best L´evy. Mean Best and standard deviation (Std
Dev) of 50 runs are reported. For ODE, equal number of function calls are used instead of generation
numbers (Np × #Gen.). Two-tailed t-test is used to compare ODE against Adaptive LEP and Best L´evy.
‘†’ indicates that the t value of 49 degree of freedom is signiﬁcant at a 0.05 level of signiﬁcance. ‘‡’ stands
for negative t, which means the corresponding algorithm performs better than ODE. fmin indicates optimal
minimum of the function.
Adaptive LEP
Best L´evy
Mean Best (Std Dev)
Mean Best (Std Dev)
Mean Best (Std Dev)
4.48 × 10−27 (7.95 × 10−27)
6.32 × 10−4 (7.6 × 10−5)†
6.59 × 10−4 (6.4 × 10−5)†
0.37 (0.35)
0.041 (0.06)‡
30.63 (22.11)†
24.89 (1.20)
43.40 (31.52)†
57.75 (41.60)†
66.94 (27.40)
5.85 (2.07)‡
12.50 (2.29)‡
4.44 × 10−4 (1.8 × 10−3)
2.4 × 10−2 (2.8 × 10−2)†
1.8 × 10−2 (1.7 × 10−2)†
4.42 × 10−14 (3.09 × 10−14)
1.9 × 10−2 (1.0 × 10−3)†
3.1 × 10−2 (2.0 × 10−3)†
−1.03 (2.35 × 10−5)
−1.031 (0.0)
−1.031 (0.0)
−10.1012 (1.68 × 10−1)
−9.54 (1.69)†
−9.95 (0.99)†
−10.2904 (7.17 × 10−1)
−10.30 (0.74)
−10.40 (1.0 × 10−4)‡
−10.7003 (3.59 × 10−15)
−10.54 (4.9 × 10−5)†
−10.54 (3.1 × 10−3)†
3.0001 (7.77 × 10−5)
3.000 (0.000)
3.000 (0.000)
7.15 × 10−23 (2.00 × 10−22)
6.0 × 10−6 (1.0 × 10−6)†
3.0 × 10−5 (4.0 × 10−6)†
Chapter 5. Empirical Study and Analysis
Table 5.14: Comparison of ODE, FEP, and CEP. Mean Best and standard deviation (Std Dev) of 50 runs are
reported. For ODE, equal number of function calls are used instead of generation numbers (Np × #Gen.).
Two-tailed t-test is used to compare ODE against FEP and CEP. ‘†’ indicates that the t value of 49 degree of
freedom is signiﬁcant at a 0.05 level of signiﬁcance. ‘‡’ stands for negative t, which means the corresponding
algorithm performs better than ODE. fmin indicates optimal minimum of the function.
Mean Best (Std Dev)
Mean Best (Std Dev)
Mean Best (Std Dev)
4.48 × 10−27 (7.95 × 10−27)
5.7 × 10−4 (1.3 × 10−4)†
2.20 × 10−4 (5.9 × 10−4)†
8.85 × 10−11 (1.62 × 10−10)
1.6 × 10−2 (1.4 × 10−2)†
5.0 × 10−2 (6.6 × 10−2)†
24.51 (1.11)
5.06 (5.87)‡
6.17 (13.61)‡
11.61 (11.67)
4.6 × 10−2 (1.2 × 10−2)‡
89.0 (23.1)†
8.86 × 10−4 (3.55 × 10−3)
1.6 × 10−2 (2.2 × 10−2)†
8.6 × 10−2 (0.12)†
4.4 × 10−14 (3.09 × 10−14)
1.8 × 10−2 (2.1 × 10−3)†
9.2 (2.8)†
−1.03 (4.48 × 10−16)
−1.03 (4.9 × 10−7)
−1.03 (4.9 × 10−7)
3.97 × 10−1 (2.24 × 10−16)
3.98 × 10−1 (1.5 × 10−7)
3.98 × 10−1 (1.5 × 10−7)
1.97 × 10−11 (1.29 × 10−11)
8.1 × 10−3 (7.7 × 10−4)†
2.6 × 10−3 (1.7 × 10−4)†
8.23 × 10−2 (0.53)
0.3 (0.5)†
2.0 (1.2)†
577.76 (1125.76)†
1.4 × 10−3 (5.88 × 10−4)
7.6 × 10−3 (2.6 × 10−3)
1.8 × 10−3 (6.4 × 10−3)
1.95 × 10−4 (3.52 × 10−4)
5.0 × 10−4 (3.2 × 10−4)
4.7 × 10−4 (3.0 × 10−4)
−10.0008 (0.71)
−5.52 (1.59)†
−6.86 (2.67)†
−10.2904 (0.71)
−5.52 (2.12)†
−8.27 (2.95)†
−10.7003 (3.58 × 10−15)
−6.57 (3.14)†
−9.10 (2.92)†
3.02 (0.11)
5.6 Enhancement Directions
Results analysis -
As seen in Table 5.14, ODE outperforms FEP and CEP on 9
and 11 functions (out of 17) while FEP and CEP just on 2 and 1 functions present better
results than ODE, respectively. Over the rest of functions, they perform almost the same.
Enhancement Directions
Further attempts are conducted to introduce the following two enhancement directions for
ODE. The reader is refereed to Appendix B for comprehensive details.
First, instead of the opposite points, quasi-opposite points are suggested to be used.
A quasi-opposite point is a randomly generated point between the center of search interval and the opposite point. This new extension is called quasi-oppositional DE (QODE)
[Rahnamayan et al. 2007c]. The QODE employs exactly the same schemes of ODE for
population initialization and generation jumping. A test suite with 15 benchmark functions has been employed to compare performance of DE, ODE, and QODE experimentally.
QODE presents promising results.
Second, a time varying jumping rate (TVJR) model for ODE has been proposed
[Rahnamayan et al. 2007a]. According to this model, the jumping rate changes during
the evolution based on the number of function evaluations. Results conﬁrm that a higher
jumping rate is more desirable during the exploration than during the exploitation.
A Sample Application
In order to introduce a sample application of ODE, a new optimization-based image thresholding approach is proposed (see Chapter 6) [Rahnamayan et al. 2006a]. Then micro-DE
and micro-ODE (DE and ODE with very small population size, Np = 5) have been compared over thresholding of 16 test images. The results conﬁrm that the micro-DE is accelerated 13% just by employing the opposition-based population initialization. Furthermore,
Chapter 5. Empirical Study and Analysis
the proposed thresholding approach is compared with the Kittler method.
The results of the conducted empirical studies in this chapter can be summarized as follows:
• DE and ODE were compared for diﬀerent problem dimensions (D/2, D, and 2D);
the results conﬁrm that ODE performs better over high dimensional and scalable
problems. For these kinds of problems a large population size is required. On the
other hand, ODE performs better with larger population sizes.
These two facts
support each other and make ODE more suitable for higher dimensional problems.
Further study is required to solidify this statement.
• By replacing opposite points with uniformly generated random points in the same
variable range, the acceleration rate was reduced by 57%. Therefore, the contribution
of opposite points to the acceleration process was conﬁrmed and was not reproducible
by additional random sampling.
• DE and ODE were compared for diﬀerent population sizes (Np/2, Np, and 2Np).
ODE performed better for larger population sizes, which is usually required for higher
dimensional problems. In order to achieve better results for smaller population sizes,
low jumping rates are suggested.
• Comparison of DE and ODE over various mutation strategies was also conducted. For
all mutation strategies, ODE performed superior to DE with respect to the number
of function calls, average success rate and other performance measures, such as the
number of unsolved functions.
• The inﬂuence of the jumping rate was studied and the range [0.1, 0.4] was recommended for an unknown optimization problem. Most of the functions presented a
5.8 Summary
reliable acceleration improvement and almost a smooth behavior in this interval. Although, the optimal jumping rate can be somewhere out of this range, higher jumping
rates are generally not recommended.
• ODE was compared with ﬁve other optimizers (other than the classical DE) in terms
of solution accuracy. Its competitors were Fuzzy Adaptive DE (FADE), Adaptive
LEP, Best L´evy, Fast Evolutionary Programming (FEP), and Classical Evolutionary
Programming (CEP). Overall, ODE accomplished better than its six competitors.
Although, comparison of the non-adaptive algorithm (ODE) with the adaptive ones
(FADE and LEP) may not be fair.
• By employing a comprehensive set of benchmark functions, the parent algorithm
(DE) and ODE were compared on 462 optimization exercises during the seven experiment series. Overall, ODE presented promising results in terms of convergence
speed and solution accuracy while the robustness was almost the same as DE’s.
• By replacing opposite points with quasi-opposite points and utilizing lower jumping
rates, the promising results were obtained (see Appendix B). Results of applying DE,
ODE, and QODE to solve 30 test problems show that QODE outperforms DE and
ODE on 22 functions. But still, further investigations are compulsory to have a solid
conclusion about QODE’s capabilities.
• As another enhancement direction for ODE, the time varying jumping rate was proposed and two behaviorally reverse versions (linearly decreasing and increasing functions) were compared with the constant setting (see Appendix B). The results conﬁrm
that the linearly decreasing jumping rate performs better than constant setting and
also than linearly increasing policy.
Image Thresholding Using
The ﬁrst is when an opposite has been deﬁned through its opposite, e.g. good
through evil: for opposites are always simultaneous by nature. Some people
think, also, that both are objects of the same science, so that the one is not
even more intelligible than the other. One must, however, observe that it is
perhaps not possible to deﬁne some things in any other way, e.g. the double
without the half, and all the terms that are essentially relative: for in all such
cases the essential being is the same as a certain relation to something, so that
it is impossible to understand the one term without the other, and accordingly
in the deﬁnition of the one the other too must be embraced. One ought to learn
up all such points as these, and use them as occasion may seem to require.
– Aristotle (322 – 384 BC)
6.1 Introduction
Introduction
In many image processing applications, the crucial role of the image thresholding can be
observed . Numerous thresholding techniques have already been proposed [Sezgin and Sankur 2004; Cheng et al. 2001;
Tizhoosh 2005a; Rahnamayan et al. 2006h]. However, almost all of them are applicationor domain-oriented solutions, suﬀering from lack of universality. Therefore, this research
ﬁeld is still open to investigation and introduction of new robust and universal techniques.
In this chapter, a new thresholding technique is proposed which generates corresponding binary image by minimizing the dissimilarity between the input and the output images. Hence, the grey-level input image itself is directly used to measure the quality of
the threshoded image; thus, this method can be introduced as a candidate for universal
thresholding. DE is employed as an optimizer in the mentioned minimization exercise.
By this way, the thresholding task is changed to an optimization problem. In order to
solve this problem, the DE is employed with a very small population size (Np = 5), called
micro-DE. A small population size results a shorter computation time which is a crucial
factor for the image processing tasks to make them suitable for online applications (e.g.,
robotics or production line control).
After comprehensive evaluation of more than 40 image thresholding techniques, Sezgin
and Sankur concluded that the Kittler [Sezan 1985] is the best overall performing method. For this reason, and like many other thresholding works [Tizhoosh 2005a],
the proposed method is compared with the Kittler. In the ﬁnal part of this chapter, as
a case study, the micro-DE and micro-ODE (micro-DE equipped with opposition-based
initialization) are compared in terms of convergence speed and robustness.
Organization of this chapter is as follows: The proposed image thresholding approach
is presented in section 6.2. Experimental investigation is presented in section 6.3. The
micro-DE and micro-ODE are compared in section 6.4. Finally, the chapter is summarized
Chapter 6. Image Thresholding Using micro-ODE
and concluded in section 6.5.
Proposed Image Thresholding Approach
When we are comparing the input grey-level image and corresponding thresholded version
we perceptually map darker pixels in the input image to the black pixels in the thresholded
image and lighter ones to the white pixels. With this method, we subjectively measure the
quality of the thresholding. The same procedure happens even for a person who knows
nothing about image processing concepts. We will have a high quality thresholded image
when the mentioned similarity is high, or in other words, the dissimilarity is low. So, the
thresholding task can be understood as an optimization problem. Before describing the
new approach, the objective function for this optimization exercise should be deﬁned.
Objective function - For an M × N input grey-level image, I (normalized in ),
and the corresponding thresholded image, B(T) ∈{0, 1}, with the threshold value T, the
objective function f(T) is deﬁned as follows:
|Iij −B(T)ij|.
Minimization of this objective function means minimizing the dissimilarity between the
input image and the thresholded image (see Figure 6.1).
In order to solve this one-dimensional minimization problem, the DE with very small
population size (Np = 5), micro-DE, is utilized. The pseudo-code representation of the
proposed thresholding approach is shown in Algorithm 4.
6.3 Experimental Veriﬁcations
Fig. 6.1: A sample image to show that darker and lighter pixels in input grey-level image
are matchable with black and white pixels in the thresholded image. In order to maximize
the matching level, the dissimilarity between these two images, f(T), should be minimized.
Algorithm 4 Proposed Thresholding Approach (micro-DE version)
1: Random population initialization, P0
2: Calculate objective value (dissimilarity measure) for each individual in the population
//DE’s evolution steps
3: while (satisfying termination criteria) do
7: end while
8: Thresholding input image with the found optimal value of thresholding level, Top
Experimental Veriﬁcations
In order to investigate the performance of the new approach, 16 hard-to-threshold images
were selected; all images are frequently used in the image processing literature [Tizhoosh
2005a; Sezgin and Sankur 2004].
The following micro-DE control parameters are set for all conducted experiments with
no attempt to achieve their optimal values.
• Population size, Np = 5
• Diﬀerential ampliﬁcation factor, F = 0.9
Chapter 6. Image Thresholding Using micro-ODE
• Crossover probability constant, Cr = 0.9
• Strategy: DE/rand/1/bin
• Maximum function calls, NFCMAX=200 (300 for image no. 9)
Threshold results of applying the proposed approach are presented in Table 6.1. As
shown, also corresponding ground-truth image (created manually) and the result of the
Kittler method are given for comparison. By visual evaluation, the new approach, at least
over ten of the images (image no. 1,3,4,6,7,8,11,13,15,16) shows better results than Kittler.
For all images, plot of objective function f(T) versus thresholding value T is presented
in Figures 6.2 and 6.3. Furthermore, the result for the diﬀerent thresholding values is
given on each curve. Asymmetric shapes, ﬂat surfaces, and also steep edges in the plotted
graphs show that the objective function can be challenging although it is a one-dimensional
A wide range of image quality measures have been proposed by image processing researchers [Winkler 2000;
Wang and Bovik 2002;
Martens and Meesters 1998]. In this
section, results of Kittler and the proposed approach are compared by reference-based
objective assessment. Reference or ground-truth images have been manually prepared to
serve as gold/ideal thresholded image for each test image. To compare two binary images,
Misclassiﬁcation Error (ME) [Sezgin and Sankur 2004; Yasnoﬀet al. 1977] can be a reasonable and straightforward measure to use. It calculates the percentage of foreground
pixels which have been assigned wrongly to background and vice versa:
ME = |BO ∩FT| + |FO ∩BT|
|BO| + |FO|
where BO, FO, BT, and FT are the background and foreground pixels of the groundtruth image and the background and foreground pixels of the test image, respectively. | · |
denotes the cardinality of the set.
6.3 Experimental Veriﬁcations
Fig. 6.2: Graphical illustration of dissimilarity (objective function, f(T)) vs. thresholding
value (T). The thresholding results are presented on the curves.
Chapter 6. Image Thresholding Using micro-ODE
Fig. 6.3: Continued from Figure 6.3.
6.3 Experimental Veriﬁcations
Table 6.1: Thresholding results. Input image, corresponding manually created groundtruth (gold) image, result of Kittler method, and result of the proposed approach (micro-
By utilizing this error measure, the similarity index η can be deﬁned as follows:
η = (1 −ME) × 100%.
Chapter 6. Image Thresholding Using micro-ODE
Table 6.2 summarizes the results of objective assessment for 16 test images. Results
of the Kittler and new method are compared with the gold image. The best result, in
each case has been indicated in boldface. According to the mentioned similarity index, the
Kittler shows better results for 5 cases; micro-DE performs better for 10 cases; and for one
case the results is almost the same (results with diﬀerence less than 1% are considered the
Table 6.2: Results of objective assessment for 16 test images. The best result in each case
has been highlighted in boldface. η is the similarity index.
Comparison of micro-DE and micro-ODE
In order to accelerate micro-DE, it is equipped with opposition-based initialization (micro-
ODE). Because of the very small population size and also small number of required function
calls to solve the objective function, the opposition-based generation jumping is not embedded in micro-ODE. Algorithm 5 presents pseudo-code for micro-ODE. The only diﬀerence
between micro-DE and micro-ODE is on the population initialization. The ﬁrst one uses
the random initialization and the second one utilizes the opposition-based initialization.
The minimum values for the objective function, fmin, for each image (kept from the
6.4 Comparison of micro-DE and micro-ODE
Algorithm 5 Proposed Thresholding Approach (micro-ODE version)
1: Random population initialization, P0
2: for i = 0 to Np do
for j = 0 to D do
OP0i,j ←aj + bj −P0i,j
6: end for
7: Select Np ﬁttest individuals from set the {P0, OP0} as initial population P0
8: Calculate objective value (dissimilarity measure) for each individual in the population
//DE’s evolution steps
9: while (satisfying termination criteria) do
13: end while
14: Thresholding input image with the found optimal value of thresholding level, Top
micro-DE experiments), is used as value to reach (VTR) to compare convergence rate and
robustness of micro-DE and micro-ODE. All control parameters are the same as before.
The results of 100 trials per image for both algorithms are summarized in Table 6.3. Micro-
ODE performs faster for 13 images. Both algorithms have the same NFCs for two images.
For thresholding of 16 images, micro-DE needs 875 function calls while this number is 761
for micro-ODE (13% convergence rate improvement). The success rate is almost the same
for both (0.98 vs. 0.99).
Chapter 6. Image Thresholding Using micro-ODE
Table 6.3: Comparison of micro-DE and micro-ODE. Reported NFCs are the average over
100 trials for each image. The smaller NFC in each case has been indicated in boldface.
In this chapter, an optimization-based image thresholding approach has been introduced.
micro-DE segmented the image into two classes by minimizing the dissimilarity between
input grey-level image and binary (thresholded) image. The proposed approach was compared with a well-known method, the Kittler, through an objective assessment. Results
conﬁrmed that the proposed approach is superior to the Kittler algorithm over the selected
The most important part of the proposed approach is the deﬁnition of the objective
6.5 Summary
function. As seen, micro-DE, as an optimizer, minimizes the dissimilarity between greylevel image and thresholded image. This dissimilarity is measured by pixel-by-pixel comparison of the binary and normalized grey-level images. The main drawback is that employing an evolutionary algorithm (DE) to threshold image shows a higher computational time.
Employing the DE with a small population size (micro-DE) was in this direction to make
computation time shorter. Furthermore, micro-DE was accelerated 13% by embedding
opposition-based population initialization while the success rate remaind the same.
Conclusions and Future Work
Reasoning draws a conclusion, but does not make the conclusion certain, unless
the mind discovers it by the path of experience.
– Roger Bacon
Most creative work is a process of people passing ideas and inspirations from
the past into the future and adding their own creativity along the way.
– Joichi Ito
7.1 Conclusions
Conclusions
Finding more accurate solution(s) in a shorter period of time for complex problems is the
main goal of all evolutionary algorithms. Although the opposition concept has a very old
history in other sciences, that is the ﬁrst time that this concept is employed to enhance
population-based algorithms. Conclusions for this attempt can be summarized as follows:
Results are promising, however, the opposition-based optimization is still in its infancy.
Results conﬁrm that the opposition concept has the potential to play a positive role in
optimization.
But, it is important to mention that the current study constitutes the
ﬁrst step of this newly opened direction. Like many other new concepts, opposition-based
optimization needs further studies to shed light on its beneﬁts, weaknesses, and limitations.
In fact, the main claim is not defeating DE or any of its numerous versions but to introduce
a new notion into optimization via metaheuristics; this is the notion of opposition.
As a key point, the performance of the opposition-based optimization is directly depended
on how often and how many opposite points are evaluated. Any individual evaluation costs
a function call. So, a smartly controlled opposition concept is highly advised to prevent
overwhelming of the acceleration beneﬁts by the extra computation load for evaluating
opposite points.
Generally speaking, the high convergence speed and robustness are two conﬂicting objectives. A trade-oﬀbetween the fastness and robustness is essential in evolutionary optimization. These are very similar to the exploration and exploitation. Although, there is
no rigid boundary between them. The optimal division of the search time between these
two steps is a challenging task and problem-oriented.
The optimal control parameters are problem-oriented such that developing a self-adaptive
or adaptive algorithm is a valuable attempt. Many studies conﬁrm that for populationbased algorithms the optimal parameters are problem-oriented. Running limited trials to
Chapter 7. Conclusions and Future Work
determine desirable parameters is a common approach (if not a practical way for time consuming objective functions). For this reason, the self-adaptive/adaptive control parameter
setting would be a valuable improvement.
Introducing an extra control parameter is not appreciated. For ODE, the jumping rate
is added to DE’s three parameters. Having more control parameters makes the optimal
parameter setting and analysis harder.
Higher jumping rates are not recommended because it causes the fast decreasing of
the population diversity and so premature convergence, in particular for the multimodal
problems. Indeed, the generation jumping makes the exploration time shorter which is
directly caused by the jumping rate. For high dimensional problems with small population
size a rather small jumping rate is recommended.
The beneﬁts of opposition-based optimization are not the same for diﬀerent problems.
This is due to using ﬁx settings for the parameters instead of the optimal ones and/or
the diﬀerent characteristics of each problem (e.g., modality, dimension, surface features,
separability of the variables and so on). Similar to all optimization approaches, ODE does
not present a consistent behavior over diﬀerent problems. However, in overall and over the
employed benchmark test suite, ODE performed better than classical DE and ﬁve other
evolutionary optimizers.
The proposed opposition-based schemes are general enough to be applied to other population - based algorithms. The opposition-based schemes work at the population level
and leave the evolutionary part of the algorithms untouched. This generality gives higher
ﬂexibility to these schemes to be embedded inside other population-based algorithms for
further investigation.
Standard benchmark test suite and also benchmarking methodologies are required. Without any uniﬁed test platform and comparison methodology, the concrete judgment among
the competitors is virtually impossible. This shortage can be addressed by the optimization
community. Although, ﬁguring out all aspects of an optimizer by applying it on one test
7.2 Contributions
suite (even a very comprehensive one), seems impossible, it nevertheless supports uniﬁed
comparative studies.
Contributions
The author ﬁrst started to work on image processing [Rahnamayan et al. 2005a,b,c,d,e,f,g,
2006a,h; Kachouie et al. 2006] but when he was faced with computational time problem
of the population-based algorithms, he focused on accelerating them and ﬁnally his studies
has led to the following contributions.
• A general scheme of opposition-based population initialization is proposed to accelerate evolutionary algorithms [Rahnamayan et al. 2006b;
Rahnamayan 2006]. For
the ﬁrst time the opposition concept was employed to accelerate an optimizer.
• A framework for the opposition-based evolutionary algorithm is suggested to accelerate the convergence rate [Rahnamayan et al. 2006g]. The opposition-based generation jumping is employed to achieve a higher acceleration rate.
• The opposition-based diﬀerential evolution (ODE) is introduced [Rahnamayan et al.
2006d,e] and a comprehensive set of experiments is conducted to verify its eﬃciency.
The thesis main contribution will appear in IEEE Transactions on Evolutionary Computation [Rahnamayan et al. 2006f].
• As the thesis’ second major contribution, mathematical proofs conﬁrming experimental veriﬁcations are presented [Rahnamayan et al. 2006c, 2007b] to show why
opposite numbers are beneﬁcial. The achieved results could be valuable not only for
the optimization area but also in the machine learning or soft computing research
Chapter 7. Conclusions and Future Work
• A new image thresholding approach is proposed and it was compared with the Kittler
method. The proposed approach outperforms Kittler method in overall. Furthermore, the results conﬁrm that the micro-ODE is faster than micro-DE because of
opposition-based population initialization.
• The opposition-based DE with variable jumping rate (ODEVJR) is suggested to
enhance ODE’s performance [Rahnamayan et al. 2007a] (see Appendix B). In the
ﬁrst version of ODE, a constant value for jumping rate is used. For the ODEVJR,
two types of time variable jumping rate are investigated (linearly increasing and
decreasing functions). Results conﬁrm that a higher jumping rate is more desirable
during the exploration than during the exploitation phase.
• The quasi-oppositional DE (QODE) is introduced as a potential extension for ODE
[Rahnamayan et al. 2007c] (see Appendix B). The QODE employs exactly the same
schemes of ODE for population initialization and generation jumping; just instead of
opposite the quasi-opposite individuals are utilized. Furthermore, the mathematical
proofs are provided to support the current extension.
• DE is enhanced by local tuning of the ﬁttest individual. A local search approach
has been embedded inside the classical DE. By this way, the method gives an extra chance to local improvement of the best individual in the current population
[Jonasson and Rahnamayan 2006].
Future Work
OBO opens a fresh perspective in the population-based algorithms to accelerate optimization process. Because of this novelty, many studies can be conducted to extend, enhance,
or apply the proposed schemes and algorithms. Some of these directions are as follows:
7.3 Future Work
• Generalizing ODE to handle constrained functions and multi-objective optimization -
For most practical applications, we are faced with constraint functions and also with
multi-objective problems. So far, there are many approaches for handling constraints
in DE and also for multi-objective optimization using DE. All of these proposals can
be borrowed and investigated to generalize ODE to solve multi-objective constrained
• Employing proposed opposition-based schemes to accelerate DE’s enhanced versions or
other population-based algorithms - The proposed opposition-based schemes for population initialization and generation jumping are general enough and can be utilized
to accelerate DE’s extended versions or other population-based algorithms
(e.g., GAs and PSO). However, the introduction of the opposition-based version of
other algorithms still remains widely open to research (such as the opposition-based
continuous GA (CGA) or opposition-based free search (FS) [Penev and Littlefair
• Extending opposition-based optimization to non-continuous (discrete/interger) spaces
- Continuous opposition-based optimization was considered in this study. One obvious extension can be working with discrete variables instead of continuous ones. As
it was mentioned before, DE (and similarly ODE) can work with discrete variables
easily, but further experiments are required to ﬁgure out the performance of ODE
on these sort of problems (e.g., combinatorial problems).
• Developing adaptive/self-adaptive ODE - Adaptive setting of the control parameters
for any optimizer is widely appreciated. The proposed idea in [Brest et al. 2006] for
self-adaptive setting of Cr and F can be used to set Jr.
The opposition-based optimization is simple to implement and open to be used in
many diﬀerent ways for diﬀerent purposes. This study is a starting point in this direction
Chapter 7. Conclusions and Future Work
to conﬁrm the potentials and motivate other researchers in optimization and machine
learning ﬁelds to engage with the opposition concept.
Appendix A
List of Bound Constrained Global
Optimization Test Functions
All algorithms that search for an extremum of an objective function perform
exactly the same, according to any performance measure, when averaged over
all possible objective functions.
– David H. Wolpert and William G. Macready in “No-free-lunch theorem”
Chapter A. List of Bound Constrained Global Optimization Test Functions
• 1st De Jong [Onwubolu and Babu 2004]
with −5.12 ≤xi ≤5.12,
min(f1) = f1(0, ..., 0) = 0.
Unimodal, scalable, convex, and easy function.
• Axis Parallel Hyper-Ellipsoid
with −5.12 ≤xi ≤5.12,
min(f2) = f2(0, ..., 0) = 0.
Unimodal, scalable, convex, and easy function.
• Schwefel’s Problem 1.2
with −65 ≤xi ≤65,
min(f3) = f3(0, ..., 0) = 0.
Unimodal and scalable function.
• Rosenbrock’s Valley [Mor´e et al. 1981]
100(xi+1 −x2
i )2 + (1 −xi)2
with −2 ≤xi ≤2,
min(f4) = f4(1, ..., 1) = 0.
This function is known as the Banana function. It is a non-convex unimodal classic
optimization problem. Locating the minimum is very challenging for many optimizers,
because the optimum is inside a long, narrow, parabolic shaped ﬂat valley.
• Rastrigin’s Function [Storn and Price 1997b]
f5(X) = 10n +
i −10 cos(2πxi)),
with −5.12 ≤xi ≤5.12,
min(f5) = f5(0, ..., 0) = 0.
This function is highly multimodal and the location of the minima is regularly distributed.
• Griewangk’s Function [Onwubolu and Babu 2004]
with −600 ≤xi ≤600,
min(f6) = f6(0, ..., 0) = 0.
This function has many regularly distributed local minima and hard to locate global
Chapter A. List of Bound Constrained Global Optimization Test Functions
• Sum of Diﬀerent Power
|xi|(i+1),
with −1 ≤xi ≤1,
min(f7) = f7(0, ..., 0) = 0.
This is a unimodal scalable function.
• Ackley’s Problem [Storn and Price 1997b]
f8(X) = −20 exp
+ 20 + e,
with −32 ≤xi ≤32,
min(f8) = f8(0, ..., 0) = 0.
The number of local minima is unknown.
• Beale Function
f9(X) = [1.5 −x1(1 −x2)]2 + [2.25 −x1(1 −x2
2)]2 + [2.625 −x1(1 −x3
with −4.5 ≤xi ≤4.5,
min(f9) = f9(3, 0.5) = 0.
• Colville Function
f10(X) = 100(x2 −x2
1)2 + (1 −x1)2 + 90(x4 −x2
3)2 + (1 −x3)2 +
10.1((x2 −1)2 + (x4 −1)2) + 19.8(x2 −1)(x4 −1),
with −10 ≤xi ≤10,
min(f10) = f10(1, 1, 1, 1) = 0.
• Easom Function [Michalewicz 1996]
f11(X) = −cos(x1) cos(x2) exp(−(x1 −π)2 −(x2 −π)2),
with −100 ≤xi ≤100,
min(f11) = f11(π, π) = −1.
This function is unimodal and the global minimum lays in a narrow area relative to the
search space.
• Hartmann Function 1 [Dixon and Szeg¨o 1978]
f12(X) = −
Aij(xj −Pij)2
with 0 ≤xi ≤1,
min(f12) = f12(0.114614, 0.555649, 0.852547) = −3.86278.
Chapter A. List of Bound Constrained Global Optimization Test Functions
It has four local minima.
• Hartmann Function 2 [Dixon and Szeg¨o 1978]
f13(X) = −
Bij(xj −Qij)2
with 0 ≤xi ≤1,
min(f13) = f13(0.20169, 0.150011, 0.476874, 0.275332, 0.311652, 0.6573) = −3.32237.
It has four local minima.
• Six Hump Camel Back Function [Dixon and Szeg¨o 1978; Michalewicz 1996]
f14(X) = 4x2
1 + x1x2 −4x2
with −5 ≤xi ≤5,
min(f14) = f14(0.0898, −0.7126)/(−0.0898, 0.7126) = −1.0316285.
This problem has six local minima, two of them are global.
• Levy Function
f15(X) = sin2(3πx1) +
(xi −1)2(1 + sin2(3πxi+1)) + (xn −1)(1 + sin2(2πxn)),
with −10 ≤xi ≤10,
min(f15) = f15(1, ..., 1) = 0.
This function has approximately 15n local minima.
• Matyas Function
f16(X) = 0.26(x2
2) −0.48x1x2,
with −10 ≤xi ≤10,
min(f16) = f16(0, 0) = 0.
This function is unimodal.
• Perm Function
(ik + 0.5)((1
i xi)k −1)
with −n ≤xi ≤n,
min(f17) = f17(1, 2, 3, ..., n) = 0.
Chapter A. List of Bound Constrained Global Optimization Test Functions
This function is unimodal.
• Michalewicz Function [Onwubolu and Babu 2004]
f18(X) = −
sin(xi)(sin(ix2
with 0 ≤xi ≤π, m = 10,
min(f18(n=2)) = −1.8013, min(f18(n=5)) = −4.687658, min(f18(n=10)) = −9.66015.
This function is multimodal and more diﬃcult for larger m.
• Zakharov Function
with −5 ≤xi ≤10,
min(f19) = f19(0, ..., 0) = 0.
This function is unimodal.
• Branin Problem [Dixon and Szeg¨o 1978]
f20(X) = a(x2 −bx2
1 + cx1 −d)2 + e(1 −f) cos(x1) + e,
with −5 ≤x1 ≤10, 0 ≤x2 ≤15
where a = 1, b = 5.1
4π2, c = 5
π, d = 6, e = 10, f = 1
min(f20) = f20(−π, 12.275)/(−π, 2.275)/(9.42478, 2.475) = 0.3979.
It has three minima.
• Schwefel’s Problem 2.22
with −10 ≤xi ≤10,
min(f21) = f21(0, ..., 0) = 0.
This function is unimodal.
• Schwefel’s Problem 2.21
f22(X) = max
{|xi|, 1 ≤i ≤n},
with −100 ≤xi ≤100,
min(f22) = f22(0, ..., 0) = 0.
This function is unimodal.
• Step Function
(⌊xi + 0.5⌋)2,
with −100 ≤xi ≤100,
min(f23) = f23(−0.5 ≤xi < 0.5) = 0.
This function has steep edges and ﬂat surfaces which makes optimizers prone to get
stuck on those areas.
Chapter A. List of Bound Constrained Global Optimization Test Functions
• Noisy Quartic Function
i + random[0, 1),
with −1.28 ≤xi ≤1.28,
min(f24) = f24(0, ..., 0) = 0.
This is an easy unimodal function which is padded with uniform noise.
• Kowalik’s Function
i + bix3 + x4
with −5 ≤xi ≤5,
min(f25) = f25(0.19, 0.19, 0.12, 0.14) = 0.0003075.
a=[0.1957 0.1947 0.1735 0.1600 0.0844 0.0627 0.0456 0.0342 0.0323 0.0235
0.0246], b−1=[0.25 0.5 1 2 4 6 8 10 12 14 16].
This function is multimodal (with a few local minima).
• Shekel 5 Problem [Dixon and Szeg¨o 1978]
f26(X) = −
(xj −aij)2 + ci
with 0 ≤xj ≤10,
min(f26) = f26(4, 4, 4, 4) ≈−10.1499.
The number of local minima is ﬁve.
Chapter A. List of Bound Constrained Global Optimization Test Functions
• Shekel 7 Problem [Dixon and Szeg¨o 1978]
f27(X) = −
(xj −aij)2 + ci


with 0 ≤xj ≤10,
min(f27) = f27(4, 4, 4, 4) ≈−10.3999.
The number of local minima is seven.
• Shekel 10 Problem [Dixon and Szeg¨o 1978]
f28(X) = −
(xj −aij)2 + ci


with 0 ≤xj ≤10,
min(f28) = f28(4, 4, 4, 4) ≈−10.5319.
The number of local minima is ten.
• Tripod Function
f29(X) = p(x2)(1 + p(x1)) + |(x1 + 50p(x2)(1 −2p(x1)))| + |(x2 + 50(1 −2p(x2)))|,
with −100 ≤xi ≤100,
min(f29) = f29(0, −50) = 0,
Chapter A. List of Bound Constrained Global Optimization Test Functions
where p(x) = 1 for x ≥0 otherwise p(x) = 0.
This function is a non-continuous multimodal function. Optimizers are prone to be
trapped in its two local minima.
• 4th De Jong [Onwubolu and Babu 2004]
with −1.28 ≤xi ≤1.28,
min(f30) = f30(0, ..., 0) = 0.
This is an easy unimodal function.
• Alpine Function
|xi sin(xi) + 0.1xi|,
with −10 ≤xi ≤10,
min(f31) = f31(0, ..., 0) = 0.
This function is multimodal and not symmetrical.
• Schaﬀer’s Function 6
f32(X) = 0.5 + sin2p
1 + 0.01(x2
with −10 ≤xi ≤10,
min(f32) = f32(0, 0) = 0.
This function is multimodal.
• Pathological Function [Onwubolu and Babu 2004]
1 + 0.001(x2
i −2xixi+1 + x2
with −100 ≤xi ≤100,
min(f33) = f33(0, ..., 0) = 0.
This function is multimodal and extremely complex.
• Inverted Cosine Wave Function (Masters) [Onwubolu and Babu 2004]
f34(X) = −
i+1 + 0.5xixi+1)
i+1 + 0.5xixi+1
with −5 ≤xi ≤5,
min(f34) = f34(0, ..., 0) = −n + 1.
This function is multimodal.
• Aluﬃ-Pentini’s Problem [Aluﬃ-Pentini et al. 1985]
f35(X) = 0.25x4
1 + 0.1x1 + 0.5x2
with −10 ≤xi ≤10,
min(f35) = f35(−1.0465, 0) = −0.3523.
The number of local minima is two.
• Becker and Lago Problem [Price 1977]
Chapter A. List of Bound Constrained Global Optimization Test Functions
f36(X) = (| x1 | −5)2 + (| x2 | −5)2,
with −10 ≤xi ≤10,
min(f36) = f36(±5, ±5) = 0.
This function has four minima.
• Bohachevsky 1 Problem [Bohachevsky et al. 1986]
f37(X) = x2
2 −0.3 cos(3πx1) −0.4 cos(4πx2) + 0.7,
with −50 ≤xi ≤50,
min(f37) = f37(0, 0) = 0.
The number of local minima is not known.
• Bohachevsky 2 Problem [Bohachevsky et al. 1986]
f38(X) = x2
2 −0.3 cos(3πx1) cos(4πx2) + 0.3,
with −50 ≤xi ≤50,
min(f38) = f38(0, 0) = 0.
The number of local minima is unknown.
• Camel Back-3 Three Hump Problem [Dixon and Szeg¨o 1975]
f39(X) = 2x2
1 + x1x2 + x2
with −5 ≤xi ≤5,
min(f39) = f39(0, 0) = 0.
The number of local minima is three.
• Dekkers and Aarts Problem [Dekkers and Aarts 1991]
f40(X) = 105x2
2)2 + 10−5(x2
with −20 ≤xi ≤20,
min(f40) = f40(0, ±15) = −24777.
It has three local minima.
• Exponential Problem [Breiman and Cutler 1993]
f41(X) = exp
with −1 ≤xi ≤1,
min(f41) = f41(0, ..., 0) = 1.
This is a unimodal function.
• Goldstein and Price Problem [Dixon and Szeg¨o 1978]
f42(X) = [1 + (x1 + x2 + 1)2(19 −14x1 + 3x2
1 −14x2 + 6x1x2 + 3x2
×[30 + (2x1 −3x2)2(18 −32x1 + 12x2
1 + 48x2 −36x1x2 + 27x2
with −2 ≤xi ≤2,
min(f42) = f42(0, −1) = 3.
The number of local minima is four.
Chapter A. List of Bound Constrained Global Optimization Test Functions
• Gulf Research Problem [Mor´e et al. 1981]
−(ui −x2)x3
where ui = 25 + [−50 ln(0.01 × i)]
with 0.1 ≤x1 ≤100, 0 ≤x2 ≤25.6, 0 ≤x3 ≤5,
min(f43) = f43(50, 25, 1.5) = 0.
• Helical Valley Problem [Wolfe 1978]
f44(X) = 100
(x2 −10θ)2 +
2π arctan x2
2π arctan x2
with −10 ≤xi ≤10,
min(f44) = f44(1, 0, 0) = 0.
This is a steep-sided valley which follows a spiral shaped path.
• Hosaki Problem [Benke and Skinner 1991]
f45(X) = (1 −8x1 + 7x2
2 exp (−x2),
with 0 ≤x1 ≤5, 0 ≤x2 ≤6,
min(f45) = f45(4, 2) ≈−2.3458.
The number of local minima is two.
• Levy and Montalvo 1 Problem [Levy and Montalvo 1985]
f46(X) = π
10 sin2(πy1) +
(yi −1)2[1 + 10sin2(πyi+1)] + (yn −1)2
where yi = 1 + 1
4(xi + 1),
with −10 ≤xi ≤10,
min(f46) = f46(−1, −1, ..., −1) = 0.
The number of local minima is approximately 5n.
• McCormick Problem [McCormick 1982]
f47(X) = sin(x1 + x2) + (x1 −x2)2 −3
with −1.5 ≤x1 ≤4, −3 ≤x2 ≤3,
min(f47) = f47(−0.547, −1.547) ≈−1.9133.
The number of local minima is two.
• Miele and Cantrell Problem [Wolfe 1978]
f48(X) = (exp(x1) −x2)4 + 100(x2 −x3)6 + tan4(x3 −x4) + x8
with −1 ≤xi ≤1,
min(f48) = f48(0, 1, 1, 1) = 0.
The number of local minima is unknown.
Chapter A. List of Bound Constrained Global Optimization Test Functions
Table A.1: Data for Multi-Gaussian Problem
• Multi-Gaussian Problem [Benke and Skinner 1991]
 −((x1 −bi)2 + (x2 −ci)2)/d2
with −2 ≤xi ≤2,
min(f49) = f49(−0.01356, −0.01356) ≈1.29695.
This function has ﬁve local minima and a saddle point.
• Neumaier 2 Problem
for n=4 b = (8, 18, 44, 114),
with 0 ≤xi ≤n,
min(f50) = f51(1, 2, 2, 3) = 0.
This a unimodal function.
• Odd Square Problem
f51(X) = −
cos(Dπ) exp
(xi −bi)2, D = √n(max|xi −bi|),
and b = (1, 1.3, 0.8, −0.4, −1.3, 1.6, −2, −6, 0.5, 1.4, 1,
1.3, 0.8, −4, −1.3, 1.6, −0.2, −0.6, 0.5, 1.4)
with −15 ≤xi ≤15
min(f51) = f51(b) ≈−1.143833.
The number of local minima, as a function of n, is unknown. There are many solutions
• Paviani Problem [Himmelblau 1972]
(ln(xi −2))2 + (ln(10 −xi))2
with 2 ≤xi ≤10,
min(f52) = f52(9.351, 9.351, ..., 9.351) = −45.778.
This a unimodal function.
• Periodic Problem [Price 1977]
f53(X) = 1 + sin2 x1 + sin2 x2 −0.1exp(−x2
with −10 ≤xi ≤10,
min(f53) = f53(0, 0) = 0.9.
The number of local minima is 50.
Chapter A. List of Bound Constrained Global Optimization Test Functions
• Powell’s Quadratic Problem [Wolfe 1978]
f54(X) = (x1 + 10x1)2 + 5(x3 −x4)2 + (x2 −2x3)4 + 10(x1 −x4)4,
with −10 ≤xi ≤10,
min(f54) = f54(0, 0, 0, 0) = 0.
This a unimodal function but it is diﬃcult to ﬁnd the minimum with higher accuracy.
• Price’s Transistor Modeling Problem [Price 1977]
f55(x1, x2, ..., x9) = γ2 +
αk = (1 −x1x2)x3{exp[x5(g1k −g3kx7 × 10−3 −g5kx8 × 10−3)] −1} −g5k + g4kx2,
βk = (1 −x1x2)x4{exp[x6(g1k −g2k −g3kx7 × 10−3 −g4kx9 × 10−3)] −1} −g5kx1 + g4k,
γ = x1x3 −x2x4,
with −10 ≤xi ≤10,
min(f55) = f55(0.9, 0.45, 1, 2, 8, 8, 5, 1, 2) = 0.
The number of local minima is unknown.
• Salomon Problem [Salomon 1995]
f56(X) = 1 −cos(2π ∥x ∥) + 0.1 ∥x ∥,
where ∥x ∥=
with −100 ≤xi ≤100,
min(f56) = f56(0, 0, ..., 0) = 0.
The number of local minima, as a function of n, is unknown. Its landscape is like a
pond with ripples.
• Schaﬀer 2 Problem [Michalewicz 1996]
f57(X) = (x2
2)0.25(sin2(50(x2
2)0.1) + 1),
with −100 ≤xi ≤100,
min(f57) = f57(0, 0) = 0.
The number of local minima is unknown.
• Wood’s Function
f58(X) = 100(x2 −x2
1)2 + (1 −x1)2 + 90(x4 −x2
3)2 + (1 −x3)2 +
10.1[(x2 −1)2 + (x4 −1)2] + 19.8(x2 −1)(x4 −1),
with −10 ≤xi ≤10,
min(f58) = f58(1, 1, 1, 1) = 0.
This function has a saddle point.
Appendix B
Enhancement Directions for ODE
Non-violent resistance implies the very opposite of weakness. Deﬁance combined
with non-retaliatory acceptance of repression from one’s opponents is active, not
passive. It requires strength, and there is nothing automatic or intuitive about
the resoluteness required for using non-violent methods in political struggle and
the quest for Truth.
– Mahatma Gandhi, 1936
The opposite of love is not hate, it’s indiﬀerence.
– Elie Wiesel
B.1 Quasi-Oppositional Diﬀerential Evolution (QODE)
Quasi-Oppositional Diﬀerential Evolution (QODE)
In this section, the eﬀects of replacing opposite numbers with quasi-opposite numbers in
the ODE are investigated. We call the new method QODE which employs exactly the same
schemes of ODE for population initialization and generation jumping. As we know, the
middle point of the search interval has the highest accessability to cover the search space.
But the middle point for the whole population is a unique point and cannot be replaced
with opposite numbers in the ODE algorithm. For this reason and as an option, a random
point between middle point and opposite point can be replaced with opposite number.
Figure B.1 and Figure B.2 show the interval and region which are used to generate these
points in one-dimensional and two-dimensional spaces, respectively.
Illustration of x and its opposite ˘x. The quasi-opposite point, ˘xq, is generated
in the interval [M, ˘x].
Quasi-opposition theorem
Mathematically, we can prove that for a black-box optimization problem, the quasi-opposite
point ˘xq has a higher chance than opposite point ˘x to be closer to the solution. The theorem
can be formulated as follows:
Theorem B.1 (Quasi-Opposition Theorem) Given a guess x, its opposite ˘x and quasiopposite ˘xq, and given the probability function Pr(·), we have
Pr (|˘xq −xs| < |˘x −xs|) > 1/2,
Chapter B. Enhancement Directions for ODE
Fig. B.2: For a two-dimensional space, the point P and its opposite ˘P. The quasi-opposite
point, ˘P q, is generated in that gray area.
where xs is the solution for a black-box optimization problem.
Proof Assume that the solution xs is in one of these intervals: [a, x], [x, M], [M, ˘x], [˘x, b]
([a, x] ∪[x, M] ∪[M, ˘x] ∪[˘x, b] = [a, b]). We investigate all cases:
• xs ∈[a, x] ∨xs ∈[˘x, b] - According to the deﬁnition of opposite point, intervals [a, x]
and [˘x, b] have the same length, so the probability that the solution is in interval
[a, x] or [˘x, b] is equal (x−a
b−a = b−˘x
b−a). Now, if the solution is in interval [a, x], deﬁnitely,
it is closer to ˘xq and in the same manner if it is in interval [˘x, b] it would be closer to
˘x. So, until now, ˘xq and ˘x have the equal chance to be closer to the solution.
• xs ∈[M, ˘x] - For this case ˘xq and ˘x have the equal chance to be closer to the solution.
• xs ∈[x, M] - For this case, obviously, ˘xq is closer to the solution than ˘x.
Now, we can conclude that, in overall, ˘xq has a higher chance to be closer to the solution
than ˘x, because for the ﬁrst two cases they had equal chance and just for last case ([x, M])
˘xq has a higher chance to be closer to the solution.
B.1 Quasi-Oppositional Diﬀerential Evolution (QODE)
This proof is for a one-dimensional space, but it can be extended to D-dimensions
(similar to Central Opposition Theorem).
As proved in one dimensional space, quasiopposite points have a higher chance to be closer to the solution than opposite points
and that is true for all individual dimensions in a D-dimensional space; hence the quasiopposite points have a higher chance in D-dimensional space to be closer to the solution
than opposite points. Now the quasi-oppositional optimization can be deﬁned. That is
very similar to the OBO (see section 3.3, page 30).
Deﬁnition B.1 (Quasi-Oppositional Optimization) Let P(x1, x2, ..., xD) be a point
in a D-dimensional space (i.e.
a candidate solution) and ˘P q(˘xq
2, ..., ˘xq
D) be a quasiopposite point (see ﬁgure B.2). Assume f(·) is a ﬁtness function which is used to measure
the candidate’s ﬁtness. Now, if f( ˘P q) ≥f(P), then point P can be replaced with ˘P q;
otherwise we continue with P. Hence, we continue with the ﬁtter one.
As mentioned before, QODE and ODE have the same population initialization and
generation jumping schemes, the only diﬀerence is that the opposite points are replaced
with quasi-opposite points. Algorithm 6 presents all details for the QODE.
Experimental validation
A set of 15 well-known scalable benchmark functions (chosen from the main test suite),
which contains 7 unimodal and 8 multimodal functions, has been selected for performance
veriﬁcation of QODE. Furthermore, test functions with two diﬀerent dimensions (D and
2D) have been employed in the conducted experiments. By this way, the classical diﬀerential evolution (DE), opposition-based DE (ODE), and quasi-oppositional DE (QODE) are
compared on 30 minimization exercises. The 13 functions (out of 15) have an optimum
in the center of search space. To make it asymmetric, the search space for all of these
functions is shifted as follows:
Chapter B. Enhancement Directions for ODE
Algorithm 6 Quasi-Oppositional Diﬀerential Evolution (QODE)
1: Generate uniformly distributed random population P0
2: //Quasi-oppositional initialization
3: for i = 0 to Np do
for j = 0 to D do
OP0i,j ←aj + bj −P0i,j //Calculating opposite point
Mi,j ←(aj + bj)/2 //Calculating middle point
if (P0i,j < Mi,j) then
QOP 0i,j ←Mi,j + (OP 0i,j −Mi,j) × rand(0, 1) //Calculating quasi-opposite point
QOP 0i,j ←OP 0i,j + (Mi,j −OP 0i,j) × rand(0, 1) //Calculating quasi-opposite point
13: end for
14: Select n ﬁttest individuals from set the {P0, QOP0} as initial population P0
15: //DE’s regular steps
16: while ( BFV > VTR and NFC < MAXNFC ) do
for i = 0 to Np do
Select three parents Pi1, Pi2, and Pi3 randomly from current population where i ̸= i1 ̸= i2 ̸= i3
Vi ←Pi1 + F × (Pi2 −Pi3)
for j = 0 to D do
if (rand(0, 1) < Cr) then
Ui,j ←Vi,j
Ui,j ←Pi,j
Evaluate Ui
if (f(Ui) ≤f(Pi)) then
//Quasi-oppositional generation jumping
if (rand(0, 1) < Jr) then
for i = 0 to Np do
for j = 0 to D do
OPi,j ←MINp
j −Pi,j //Calculating opposite point
Mi,j ←(MINp
j )/2 //Calculating middle point
if (Pi,j < Mi,j) then
QOP i,j ←Mi,j + (OP i,j −Mi,j) × rand(0, 1) //Calculating quasi-opposite point
QOP i,j ←OP i,j + (Mi,j −OP i,j) × rand(0, 1) //Calculating quasi-opposite point
Select n ﬁttest individuals from set the {P, QOP} as current population P
50: end while
B.2 ODE with Variable Jumping Rate (ODEVJR)
If O.P.B.: −a ≤xi ≤a and fmin = f(0, ..., 0) = 0
then S.P.B.:−a + a
2 ≤xi ≤a + a
where O.P.B. and S.P.B. stand for Original Parameter Bounds and Shifted Parameter
Bounds, respectively.
Setting control parameters - Parameter settings for all conducted experiments in
this section are as before (Np = 100, F = 0.5, Cr = 0.9, JrODE = 0.3, MAXNFC = 106, and
VTR= 10−8). Just a new jumping rate for QODE, JrQODE, is set to 0.05. It is set to a
smaller value (JrQODE = 1
6JrODE), because the trials showed that the higher jumping rates
can rapidly reduce the diversity of the population and cause a premature convergence. This
was predictable for QODE, because instead of an opposite point, a random point between
middle point and the opposite point is utilized and hence the variable’s search interval is
prone to be shrunk very fast. A complementary study is required to determine an optimal
value/interval for QODE’s jumping rate.
Results of applying DE, ODE, and QODE to solve 30 test problems are
given in Table B.1. As seen, QODE outperforms others (DE and ODE) on 22 functions,
while ODE surpasses DE and QODE on 6 functions and DE can just outperform ODE
and QODE on one function. DE performs slightly better than ODE and QODE in terms
of average success rate (0.90, 0.88, and 0.86, respectively).
ODE with Variable Jumping Rate (ODEVJR)
In this section, a time varying jumping rate (TVJR) model for opposition-based diﬀerential
evolution (ODE) has been investigated. According to this model, the jumping rate changes
during the evolution based on the number of function evaluations. The same test suite
Chapter B. Enhancement Directions for ODE
Table B.1: Comparison of DE, ODE, and QODE. D: Dimension, NFC: Number of function
calls (average over 50 trials), SR: Success rate, SP: Success performance.
(used for QODE) has been employed to compare performance of DE and ODE with variable
jumping rate settings.
Generally speaking, parameter control in evolutionary algorithms (EAs) can be performed in following three ways [Eiben and Hinterding 1999]: Deterministic, adaptive, and
self-adaptive. The ﬁrst one uses a predeﬁned rule to modify the parameter value without
gaining any feedback from the evolution process. The second one changes the parameter
value based on the information which receives from the search process. The third one
B.2 ODE with Variable Jumping Rate (ODEVJR)
utilizes the same evolutionary approach not only to solve the problem but also to optimize own control parameters by encoding some strategic parameters inside the population
[Rudolph 2001; Hildebrand et al. 1999].
The proposed idea in this section is similar to Das et al. work [2005b]. They utilized
time varying approach for setting of the scale factor F in diﬀerential evolution (DE), which
can be considered as a deterministic approach according to the mentioned categorization.
Investigated jumping rate models
For opposition-based diﬀerential evolution (ODE), a constant value for jumping rate was
used. Here, two types of varying jumping rates are investigated (linearly increasing and
decreasing functions). Three proposed settings for Jr are as follows:
• Jr (constant)= Jrave,
• Jr(TVJR1) = (Jrmax −Jrmin) ×
MAXNFC−NFC
• Jr(TVJR2) = (Jrmax −Jrmin) −(Jrmax −Jrmin) ×
MAXNFC−NFC
where Jrave, Jrmax, and Jrmin are the average, maximum, and minimum jumping rates,
respectively. MAXNFC and NFC are the maximum number of function calls and the current
number of function calls, respectively.
In order to support a fair comparison between these three diﬀerent jumping rate settings, the average jumping rate should be the same for all of them. Obviously, we should
have Jrave =
(Jrmax+Jrmin)
. Following values for these parameters are selected: Jrave = 0.3
and Jrmin = 0 (no jumping), so Jrmax = 0.6. Figure B.3 shows the corresponding diagrams
(jumping rate vs. NFCs) for three following settings:
• Jr(constant) = 0.3,
Chapter B. Enhancement Directions for ODE
• Jr(TVJR1) = 0.6 ×
MAXNFC−NFC
• Jr(TVJR2) = 0.6 −0.6 ×
MAXNFC−NFC
Fig. B.3: Jumping rate vs. NFCs for Jr(ODE) = 0.3, Jr(TVJR1) = 0.6 ×
MAXNFC−NFC
and Jr(TVJR2) = 0.6 −0.6 ×
MAXNFC−NFC
Jr(TVJR1) represents higher jumping rate during exploration and lower jumping rate
during exploitation (ﬁne-tuning); Jr(TVJR2) performs exactly in reverse manner. By these
settings, we can investigate eﬀects of generation jumping during optimization process.
Empirical results
The test set and all parameter settings are the same as for QODE. The only diﬀerence is
the maximum number of function calls, which is 2×105 for f1, f2, f3, f6, f8, f15, f21; 5×105
for f5, f18, f19, f31; and 5×104 for f7, f23, f41, f56. Results of applying DE, ODE (Jr = 0.3),
ODE (TVJR1), and ODE (TVJR2) to solve 15 test problems are given in Table B.2. As
seen, ODE (TVJR1) delivers best success performance (SP) for 13 benchmark functions,
while this number for DE, ODE (Jr = 0.3), and ODE (TVJR2) is 0, 1, and 1, respectively.
B.2 ODE with Variable Jumping Rate (ODEVJR)
Table B.2: Comparison of DE, ODE (Jr = 0.3), ODE (TVJR1), and ODE (TVJR2). D: Dimension, NFC:
Number of function calls (average over 50 trials), SR: Success rate, SP: Success performance.
ODE (Jr = 0.3)
ODE (TVJR1)
ODE (TVJR2)
Chapter B. Enhancement Directions for ODE
Table B.3: Pairwise comparison of DE, ODE (Jr = 0.3), ODE (TVJR1), and ODE
Given number in each cell shows for how many functions the algorithm in
each row outperforms the corresponding algorithm in each column. The last column shows
the total numbers (number of cases which the algorithm outperforms other competitors).
ODE (Jr = 0.3)
ODE (TVJR1)
ODE (TVJR2)
ODE (Jr = 0.3)
ODE (TVJR1)
ODE (TVJR2)
Pairwise comparison of these algorithms is presented in Table B.3. The given number
in each cell indicates for how many functions the algorithm in each row outperforms the
corresponding algorithm in each column. The last column of the table shows the total numbers (number of cases which the algorithm outperforms other competitors); by comparing
these numbers, the following ranking is obtained: ODE (TVJR1) (best), ODE (Jr = 0.3),
ODE (TVJR2), and DE.
The average success rate (shown in the last row of the Table B.2) for DE and ODE
(TVJR2) is marginally better than the other two competitors.
B.3 Summary
In this Appendix, the quasi-oppositional DE (QODE), an enhanced version of the oppositionbased diﬀerential evolution (ODE), was introduced. Both algorithms (ODE and QODE)
use the same schemes for population initialization and generation jumping. But, QODE
uses quasi-opposite points instead of opposite points. The presented mathematical proof
conﬁrms that these points have a higher chance than opposite points to be closer to the solution. Experimental results, conducted on 30 - eccentric minimum - test problems, clearly
show that QODE outperforms ODE.
As another enhancement direction, the time varying jumping rate for opposition-based
diﬀerential evolution was proposed and two behaviorally reverse versions (linearly decreasing and increasing functions) were compared with the constant setting. The results show
that the linearly decreasing jumping rate performs better than constant setting and also
than linearly increasing policy. This means that generation jumping in the exploration
time is more desirable than during exploitation.
Because we are faced with shrunken
search space during the ﬁne-tuning, and the jumping of the individuals may not be advantageous (because the point and the opposite-point are very close together). There is no
exact border between exploration and exploitation stage. Hence, the gradual behavior for
the decreasing and increasing functions are proposed.
The proposed jumping rate function utilizes the maximum number of function calls
(MAXNFC) which may not be exactly known for the black-box optimization problems; this
can be regarded as a disadvantage for this method. Adaptive setting of the jumping rate
can be a desirable solution.
Bibliography
Ali, M. and T¨orn, A. 2000. Optimization of carbon and silicon cluster geometry for
tersoﬀpotential using diﬀerential evolution. In Computational Chemistry and Molecular
Biology : Local and Global Approaches, C.A. Floudas and P.M. Pardalos (Eds.), Kluwer
Academic Publisher. 287–300.
Ali, M. and T¨orn, A. 2004.
Population set-based global optimization algorithms:
Some modiﬁcations and numerical studies. Journal of Computers and Operations Research 31(10), 1703–1725.
Aluffi-Pentini, F., Parisi, V., and Zirilli, F. 1985. Global optimization and stochastic diﬀerential equations. Journal of Optimization Theory and Applications 47, 1–16.
Angeline, P. J. 1998. Evolutionary optimization versus particle swarm optimization:
Philosophy and performance diﬀerences. In Proceedings of the 7th International Conference on Evolutionary Programming VII. Springer-Verlag, London, UK, 601–610.
Babu, B. and Sastry, K. 1999. Estimation of heat transfer parameters in a tricklebed
reactor using diﬀerential evolution and orthogonal collocation. Computers and Chemical
Engineering 23, 327–339.
B¨ack, T. 1996. Evolutionary Algorithms in Theory and Practice : Evolution Strategies,
Evolutionary Programming, Genetic Algorithms. Oxford University Press Inc., USA.
BIBLIOGRAPHY
B¨ack, T., Hammel, U., and Schwefel, H.-P. 1997. Evolutionary computation: Comments on the history and current state. IEEE Transactions on Evolutionary Computation 1(1), 3–17.
Benke, K. and Skinner, D. 1991. A direct search algorithm for global optimization of
multivariate functions. The Australian Computer Journal 23, 73–85.
Bergh, F. V. D. and Englebrecht, A. 2004. A cooperative approach to particle
swarm optimization. Journal of IEEE Transactions on Evolutionary Computation 8(3),
Bohachevsky, M., Johnson, M., and Stein, M. 1986. Generalized simulated annealing for function optimization. Technometrics 28, 209–217.
Bohuslav, R. and Michal, K. 2001. Diﬀerential evolution algorithm in the earthquake
hypocenter location. Pure and Applied Geophysics 158, 667–693.
Breiman, L. and Cutler, A. 1993. A deterministic algorithm for global optimization.
Mathematical Programming 58, 179–199.
Brest, J., Greiner, S., Boˇskovi´c, B., Mernik, M., and ˇZumer, V. 2006. Selfadapting control parameters in diﬀerential evolution: A comparative study on numerical benchmark problems.
Journal of IEEE Transactions on Evolutionary Computation 10(6), 646–657.
Chakraborti, N., De, P., and Prasad, R. 2002. Genetic algorithms based structure
calculations for hydrogenated silicon clusters. Materials letters 55(1), 20–26.
Chellapilla, K. 1998. Combining mutations operators in evolutionary programming.
Journal of IEEE Transactions on Evolutionary Computation 2, 91–96.
BIBLIOGRAPHY
Cheng, H., Jiang, X., Sun, Y., and Wang, J. 2001.
Color image segmentation:
advances and prospects. Journal of Pattern Recognition 34, 2259–2281.
Crutchley, D. and Zwolinski, M. 2004. Globally convergent algorithms for DC operating point analysis for nonlinear circuits. Journal of IEEE Transactions on Evolutionary
Computation 7(1), 2–10.
Das, S., Konar, A., and Chakraborty, U. 2005a. Improved diﬀerential evolution
algorithms for handling noisy optimization problems. In Proceedings of IEEE Congress
on Evolutionary Computation Conference. Napier University, Edinburgh, UK, 1691–
Das, S., Konar, A., and Chakraborty, U. 2005b. Two improved diﬀerential evolution
schemes for faster global search. In Proceedings of the 2005 conference on Genetic and
evolutionary computation . Washington DC, USA, 991–998.
Dekkers, A. and Aarts, E. 1991. Global optimization and simulated annealing. Mathematical Programming 50, 367–393.
Dixon, L. and Szeg¨o, G. 1975. Towards Global Optimization. North Holland, New
Dixon, L. and Szeg¨o, G. 1978. Towards Global Optimization. Vol. 2. North Holland,
Dorigo, M. and St¨utzle, T. 2004. Ant Colony Optimization. MIT Press, USA.
Eiben, A. and Hinterding, R. 1999. Paramater control in evolutionary algorithms.
IEEE Transactions on Evolutionary Computation 3(2), 124–141.
Fan, H.-Y. and Lampinen, J. 2003. A trigonometric mutation operation to diﬀerential
evolution. Global Optimization 27(1), 105–129.
BIBLIOGRAPHY
Fathi, M. and Hildebrand, L. 1997. Model-free optimization of fuzzy rule-based systems using evolution strategies. IEEE Transactions on Systems, Man, and Cybernetics,
Part B 27(2), 270–277.
Feoktistov, V. 2006. Diﬀerential Evolution: In Search of Solutions. Springer, USA.
Fischer, M., Reismann, M., and Hlavackova-Schindler, K. 1999.
estimation in neural spatial interaction modelling by a derivative free global optimization
In Proceedings of the IV Intnational Conference on geocomputation. Mary
Washington College, Fredericksburg, VA, USA.
Goldberg, D. E. 1989. Genetic Algorithms in Search, Optimization and Machine Learning. Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA.
Han, K.-H. and Kim, J.-H. 2004. Quantume-inspired evolutionary algorithms with a
new termination criterion, H gate, and two phase scheme. Journal of IEEE Transactions
on Evolutionary Computation 8(2), 156–169.
Hildebrand, L., Reusch, B., and Fathi-Torbaghan, M. 1999. Directed mutation:
A new self-adaptation for evolution strategies. In Proceedings of the Congress on Evolutionary Computation , IEEE Publications. Vol. 2. Washington, DC, USA,
1550–1557.
Himmelblau, D. 1972. Applied Nonlinear Programming. McGraw-Hill, New York.
Hrstka, O. and Kuˇcerov´a, A. 2004. Improvement of real coded genetic algorithm
based on diﬀerential operators preventing premature convergence. Journal of Advance
in Engineering Software 35, 237–246.
Jonasson, E. and Rahnamayan, S. 2006. Diﬀerential evolution with ﬁttest individual
local tuning. In Proceedings of 10th World Multi Conference on Systemics, Cybernetics
and Informatics . Orlando, USA.
BIBLIOGRAPHY
Joshi, R. and Sanderson, A. 1999. Minimal representation multisensor fusion using differential evolution. Journal of IEEE Transactions on Evolutionary Computation 29(1),
Kachouie, N., Fieguth, P., and Rahnamayan, S. 2006. An elliptical level set method
for automatic TRUS prostate image segmentation. In Proceedings of 6th IEEE International Symposium on Signal Processing and Information Technology .
Vancouver, Canada, 191–196.
Kaelo, P. and Ali, M. M. 2006. Probabilistic adaptation of point generation schemes
in some global optimization algorithms. Optimization Methods and Software 27(3), 343–
Koumousis, V. and Katsaras, C. 2006. A saw-tooth genetic algorithm combining the
eﬀects of variable population size and reinitialization to enhance performance. Journal
of IEEE Transactions on Evolutionary Computation 10(1), 19–28.
Krink, T., Filipie, B., and Fogel, G. 2004. Noisy optimization problems - a particular
challenge for diﬀerential evolution?
In Proceedings of the 2004 IEEE World Congress
on Computational Intelligence . Piscataway, NJ, USA, 332–339.
Kukkonen, S. and Lampinen, J. 2004. An extension of generalized diﬀerential evolution
for multi-objective optimization with constraints. In Proceedings of Parallel Problem
Solving from Nature - PPSN VIII, Springer-Verlag LNCS. Vol. 3242. 752–761.
Lampinen, J. 2004. A constraint handling approach for the diﬀerential evolution. In
Proceedings of the 2002 IEEE World Congress on Computational Intelligence . Vol. 2. Birmingham, UK, 752–761.
Lampinen, J. and Zelinka, I. 1999a. Mechanical Engineering Design Optimization by
Diﬀerential Evolution. McGraw-Hill, London (UK).
BIBLIOGRAPHY
Lampinen, J. and Zelinka, I. 1999b. Mixed variable non-linear optimization by diﬀerential evolution. In Proceedings of Nostradamus-99, 2nd International Prediction Conference. Technical University of Brno, Zlin, Czech Republic, 45–55.
Lee, C. Y. and Yao, X. 2004. Evolutionary programming using mutations based on the
l´evy probability distribution. Journal of IEEE Transactions on Evolutionary Computation 8(1), 1–13.
Leung, Y.-W. and Wang, Y. 2001. An orthogonal genetic algorithm with quantization for global numerical optimization. Journal of IEEE Transactions on Evolutionary
Computation 5(1), 41–53.
Levy, A. and Montalvo, A. 1985. The tunneling algorithm for the global minimization
of functions. Society for Industrial and Applied Mathematics 6, 15–29.
Liu, J. and Lampinen, J. 2005. A fuzzy adaptive diﬀerential evolution algorithm. Journal
of Soft Computing-A Fusion of Foundations, Methodologies and Applications 9(6), 448–
Martens, J. and Meesters, L. 1998. Image dissimilarity. Signal Processing 70, 1164–
McCormick, G. 1982. Applied Nonlinear Programming, Theory, Algorithms and Applications. John Wiley and Sons, New York.
Mezura-Montes, E., Vel´azquez-Reyes, J., and Coello, C. A. C. 2006. A comparative study of diﬀerential evolution variants for global optimization. In Proceedings of
the 2006 conference on Genetic and evolutionary computation . Seattle,
Washington, USA, 485–492.
Michalewicz, Z. 1996.
Genetic Algorithms+Data Structures=Evolution Programs.
Springer-Verlag, Berlin/Heidelberg/New York.
BIBLIOGRAPHY
Mor´e, J., Garbow, B., and Hillstrom, K. 1981. Testing unconstrained optimization
software. ACM Transaction on Mathematical Software 7, 17–41.
Noman, N. and Iba, H. 2005. Enhancing diﬀerential evolution performance with local
search for high dimensional function optimization. In Proceedings of the 2005 conference
on Genetic and evolutionary computation . Washington DC, USA, 967–
Onwubolu, G. C. and Babu, B. 2004. New Optimization Techniques in Engineering.
Springer, Berlin, New York.
Paterlini, S. and Krink, T. 2004. High performance clustering with diﬀerential evolution. In Proceedings of the 2004 IEEE World Congress on Computational Intelligence
 . Piscataway, NJ, USA, 2004–2011.
Penev, K. and Littlefair, G. 2005. Free search - a comparative analysis. Information
Sciences 172(1-2), 173–193.
Plagianakos, V., Magoulas, G., Nousis, N., and Vrahatis, M. 2001. Training
multilayer networks with discrete activation functions. In Proceedings of INNS-IEEE
Int. joint Conf. on neural networks. Vol. 4. Washington DC, USA, 2805–2810.
Price, K. 1994. Genetic annealing. Dr. Dobb’s Journal 220, 127–132.
Price, K. 1999. An Introduction to Diﬀerential Evolution. McGraw-Hill, London (UK).
Price, K. and Storn, R. 1997. Diﬀerential evolution: Numerical optimization made
easy. Dr. Dobb’s Journal 220, 18–24.
Price, K., Storn, R., and Lampinen, J. 2005. Diﬀerential Evolution : A Practical
Approach to Global Optimization, 1st ed. Springer-Verlag, Berlin/Heidelberg/Germany.
BIBLIOGRAPHY
Price, W. 1977. Global optimization by controlled random search. Computer Journal 20,
Rahnamayan, S. 2006. A new initialization scheme for evolutionary optimization methods.
In Proceedings of 10th World Multi Conference on Systemics, Cybernetics and
Informatics . Orlando, USA.
Rahnamayan, S. and Dieras, P. 2007. Eﬃciency competition on N-queen problem:
DE vs. CMA-ES. Submitted to the IEEE Congress on Evolutionary Computation , Singapore.
Rahnamayan, S., Tizhoosh, H., and Salama, M. 2005a. Automated snake initialization for the segmentation of the prostate in ultrasound images. In Proceedings of
International Conference on Image Analysis and Recognition , Springer
Lecture Notes in Computer Science Series. Toronto, Canada, 930–937.
Rahnamayan, S., Tizhoosh, H., and Salama, M. 2005b. Learning image ﬁltering
from a gold sample based on genetic optimization of morphological processing. In Proceedings of 7th International Conference on Adaptive and Natural Computing Algorithms
 , SpringerComputerScience. Coimbra, Protugal, 478–481.
Rahnamayan, S., Tizhoosh, H., and Salama, M. 2005d.
Optimization of object
extraction based on one user-prepared sample. Presented at 5th Annual MOPTA Conference, Modeling and Optimization: Theory and Applications, University of Windsor,
Windsor, Canada.
Rahnamayan, S., Tizhoosh, H., and Salama, M. 2005e. Recognition of subjective objects based on one gold sample. In Proceedings of 5th WSEAS International Conference
on Signal, Speech and Image Processing. Corfu, Greece, 309–314.
BIBLIOGRAPHY
Rahnamayan, S., Tizhoosh, H., and Salama, M. 2005f. Robust object segmentation using genetic optimization of morphological processing chains. In Proceedings of
5th WSEAS International Conference on Signal, Speech and Image Processing. Corfu,
Greece, 248–253.
Rahnamayan, S., Tizhoosh, H., and Salama, M. 2006a. Image thresholding using differential evolution. In Proceedings of the International Conference on Image Processing,
Computer Vision, and Pattern Recognition . Las Vegas, USA, 244–249.
Rahnamayan, S., Tizhoosh, H., and Salama, M. 2006b. A novel population initialization method for accelerating evolutionary algorithms. Elsvier Journal on Computers
and Mathematics with Applications (in press).
Rahnamayan, S., Tizhoosh, H., and Salama, M. 2006c. Opposite of random number
instead of second random number. Presented at 6th Annual MOPTA Conference, Modeling and Optimization: Theory and Applications, University of Waterloo, Waterloo,
Rahnamayan, S., Tizhoosh, H., and Salama, M. 2006d. Opposition-based diﬀerential
evolution algorithms. In Proceedings of the IEEE World Congress on Computational
Intelligence . Vancouver, BC, Canada, 7363–7370.
Rahnamayan, S., Tizhoosh, H., and Salama, M. 2006e. Opposition-based diﬀerential
evolution for optimization of noisy problems. In Proceedings of the IEEE World Congress
on Computational Intelligence . Vancouver, BC, Canada, 6756–6763.
Rahnamayan, S., Tizhoosh, H., and Salama, M. 2006g. Opposition-based evolutionary algorithms. Presented at 6th Annual MOPTA Conference, Modeling and Optimization: Theory and Applications, University of Waterloo, Waterloo, Canada.
BIBLIOGRAPHY
Rahnamayan, S., Tizhoosh, H., and Salama, M. 2006h.
Weighted voting-based
robust image thresholding. In Proceedings of 13th IEEE International Conference on
Image Processing . Atlanta, GA, USA, 1129–1132.
Rahnamayan, S., Tizhoosh, H., and Salama, M. 2007a. Opposition-based diﬀerential
evolution (ODE) with variable jumping rate. In Proceedings of IEEE Symposium on
Foundations of Computational Intelligence . Honolulu, Hawaii, USA, 81–
Rahnamayan, S., Tizhoosh, H., and Salama, M. 2007c. Quasi-oppositional diﬀerential evolution (QODE). Submitted to the IEEE Congress on Evolutionary Computation
 , Singapore.
Rahnamayan, S., Tizhoosh, H., and Salama, M. Dec. 2006f. Opposition-based differential evolution (ODE). Journal of IEEE Transactions on Evolutionary Computation
(in press).
Rahnamayan, S., Tizhoosh, H., and Salama, M. March 2007b. Opposition versus
randomness in soft computing techniques.
Revised version submitted to the Elsevier
Journal on Applied Soft Computing.
Rahnamayan, S., Tizhoosh, H., and Salama, M. Oct. 2005g. Towards incomplete
object recognition. Journal of World Scientiﬁc and Engineering Academy and Society,
Transactions on Systems 4(10), 1725–1732.
Rahnamayan, S., Tizhoosh, H., and Salama, M. Sep. 2005c. Learning robust object
segmentation from user-prepared samples. Journal of WSEAS Transactions on Computers 4(9), 1163–1170.
BIBLIOGRAPHY
Rogalsky, T., Derksen, R., and Kocabiyic, S. 1999. Diﬀerential evolution in aerodynamic optimization. In Proceedings of the 46th Annual Conference of the Canadian
Aeronautics and Space Institute. Montreal, Canada, 29–36.
Rudolph, G. 2001. Self-adaptive mutations may lead to premature convergence. IEEE
Transactions on Evolutionary Computation 5(4), 410–414.
Salomon, M. 2001. Etude de la parallelisation de methodes heuristiques d’optimisation
combinatoire. application au recalage d’images medicales. Ph.D. thesis, Universite Louis
Pasteur, Strasbourg, France.
Salomon, R. 1995. Reevaluating genetic algorithms performance under coordinate rotation of benchmark functions. BioSystems 39(3), 263–278.
Schwefel, H.-P. 1995. Evolution and Optimization Seeking. John Wiley & Sons, New
Schwefel, H.-P. 2003.
Computational Intelligence: Theory and Practice.
Verlag New York, USA.
Sezan, M. 1985. A peak detection algorithm and its application to histogram-based image
data reduction. Journal of Computer Vision, Graphics, Image Processing 29, 47–59.
Sezgin, M. and Sankur, B. 2004.
Survey over image thresholding techniques and
quantative performance evaluation. Journal of Electronic Imaging 13(1), 146–165.
Shi, Y.-J., Teng, H.-F., and Li, Z.-Q. 2005. Cooperative co-evolutionary diﬀerential
evolution for function optimization. In Proceedings of First International Conference in
Advances in Natural Computation . Changsha, China, 1080–1088.
BIBLIOGRAPHY
Storn, R. 1996. On the usage of diﬀerential evolution for function optimization. In
Proceedings of Biennial conference of the North American fuzzy information processing
society. Berkeley, California, USA, 519–523.
Storn, R. and Price, K. 1997a. Diﬀerential evolution- a simple and eﬃcient heuristic for
global optimization over continuous spaces. Journal of Global Optimization, Kluwer 11,
Storn, R. and Price, K. 1997b. Diﬀerential evolution: A simple and eﬃcient heuristic
for global optimization over continuous spaces. Journal of Global Optimization 11, 341–
Storn, R. and Price, K. March 1995. Diﬀerential evolution - a simple and eﬃcient
adaptive scheme for global optimization over continuous spaces. Tech. Rep. TR-95-012,
Suganthan, P. N., Hansen, N., Liang, J. J., Deb, K., Chen, Y. P., Auger, A.,
and Tiwari, S. May 2005. Problem deﬁnitions and evaluation criteria for the cec 2005
special session on real-parameter optimization. Tech. Rep. 2005005, Kanpur Genetic
Algorithms Laboratory, IIT Kanpur, Nanyang Technological University, Singapore And
Sun, J., Zhang, Q., and Tsang, E. P. 2005. DE/EDA: A new evolutionary algorithm
for global optimization. Journal of Information Sciences 169, 249–262.
Tasoulis, D., Pavlidis, N., Plagianakos, V., and Vrahatis, M. 2004.
Parallel diﬀerential evolution. In Proceedings of the Congress on Evolutionary Computation
 , IEEE Publications. Vol. 2. 2023–2029.
Teo, J. 2006. Exploring dynamic self-adaptive populations in diﬀerential evolution. Soft
Computing - A Fusion of Foundations, Methodologies and Applications 10(8).
BIBLIOGRAPHY
Tizhoosh, H. 2005a. Image thresholding using type II fuzzy sets. Journal of Pattern
Recognition 38, 2363–2372.
Tizhoosh, H. 2005b. Opposition-based learning: A new scheme for machine intelligence.
In Proceedings of the International Conference on Computational Intelligence for Modelling Control and Automation . Vienna, Austria, 695–701.
Tizhoosh, H. 2005c.
Reinforcement learning based on actions and opposite actions.
In Proceedings of the International Conference on Artiﬁcial Intelligence and Machine
Learning . Cairo, Egypt.
Tizhoosh, H. 2006. Opposition-based reinforcement learning. Journal of Advanced Computational Intelligence and Intelligent Informatics 10(3), 578–585.
Tsai, J.-T., Liu, T.-K., and Chou, J.-H. 2004. Hybrid taguchi-genetic algorithm for
global numerical optimization. Journal of IEEE Transactions on Evolutionary Computation 8(4), 365–377.
Tu, Z. and Lu, Y. 2004. A robust stochastic genetic algorithm for global numerical
optimization. Journal of IEEE Transactions on Evolutionary Computation 8(5), 456–
Ursem, R. and Vadstrup, P. 2004. Parameter identiﬁcation of induction motors using
diﬀerential evolution. Applied Soft Computing 4(1), 49–64.
Vesterstroem, J. and Thomsen, R. 2004. A comparative study of diﬀerential evolution, particle swarm optimization, and evolutionary algorithms on numerical benchmark
problems. In Proceedings of the Congress on Evolutionary Computation ,
IEEE Publications. Vol. 2. San Diego, California, USA, 1980–1987.
Wang, Z. and Bovik, A. 2002. A universal image quality index. Journal of IEEE Signal
Processing Letters 9(3), 81–84.