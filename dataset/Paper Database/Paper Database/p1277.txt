Machine Learning, 28, 133–168 
c⃝1997 Kluwer Academic Publishers. Manufactured in The Netherlands.
Selective Sampling Using the Query by Committee
YOAV FREUND
 
AT&T Labs, Florham Park, NJ 07932
H. SEBASTIAN SEUNG
 
Bell Laboratories, Lucent Technologies, Murray Hill, NJ 07974
ELI SHAMIR AND NAFTALI TISHBY
{shamir,tishby}@cs.huji.ac.il
Institute of Computer Science, Hebrew University, Jerusalem, ISRAEL
Editor: David Haussler
Abstract. We analyze the “query by committee” algorithm, a method for ﬁltering informative queries from a
random stream of inputs. We show that if the two-member committee algorithm achieves information gain with
positive lower bound, then the prediction error decreases exponentially with the number of queries. We show that,
in particular, this exponential decrease holds for query learning of perceptrons.
Keywords: selective sampling, query learning, Bayesian Learning, experimental design
Introduction
Most of the research on the theory of learning from random examples is based on a paradigm
in which the learner is both trained and tested on examples drawn at random from the same
distribution. In this paradigm the learner is passive and has no control over the information
that it receives. In contrast, in the query paradigm, the learner is given the power to ask
questions. What does the learner gain from this additional power?
Study of the use of queries in learning , has mostly concentrated on algorithms for exact identiﬁcation of the target concept. This type of analysis
concentrates on the worst case behavior of the algorithm, and no probabilistic assumptions
are made. In contrast, we are interested in algorithms that achieve approximate identiﬁcation of the target, and our analysis is based on probabilistic assumptions. We assume that
both the examples and the target concept are chosen randomly. In particular, we show that
queries can help accelerate learning of concept classes that are already learnable from just
unlabeled data.
This question was previously studied by in the PAC learning
framework. They give a negative result, and show that, for a natural set of concept classes,
which they call “dense in themselves”, queries are essentially useless. They show that giving
the learner the ability to ask membership queries (questions of the type “what is the label
of the point x?”) in this context does not enable the learner to signiﬁcantly reduce the total
number of labeled examples it needs to observe. The reason is that if the learner observes
only a small number of examples, either passively or actively, then it can not be sensitive
Y. FREUND, H.S. SEUNG, E. SHAMIR AND N. TISHBY
to slight changes in the target concept and in the underlying distribution. An adversary can
alter the distribution and the target in a way that will not cause the learner to change its
hypothesis, but will increase the error of this hypothesis in a signiﬁcant way. In this paper
we show how some concept classes that are dense in themselves can be learned efﬁciently if
we allow the learner access to random unlabeled examples. This added capability enables
the learner to maintain its sensitivity to the input distribution, while reducing the number
of labels that it needs to know.
Baum , proposed a learning algorithm that uses membership queries to avoid
the intractability of learning neural networks with hidden units. His algorithm is proved
to work for networks with at most four hidden units, and there is experimental evidence
 that it works for larger networks. However, when Baum and Lang
tried to use this algorithm to train a network for classifying handwritten characters, they
encountered an unexpected problem . The problem was that many of
the images generated by the algorithm as queries did not contain any recognizable character,
they were artiﬁcial combinations of character images that had no natural meaning. The
learning algorithm that is analyzed in this paper uses random unlabeled instances as queries
and in this way may avoid the problem encountered by Baum’s algorithm.
In the lines of work described above, queries are explicitly constructed. In contrast,
our work is derived within the query ﬁltering paradigm. In this paradigm, proposed by
 , the learner is given access to a stream of inputs drawn at
random from the input distribution. The learner sees every input, but chooses whether or
not to query the teacher for the label. Giving the learner easy access to unlabeled random
examples is a very reasonable assumption in many real-life contexts. In applications such as
speech recognition, it is often the case that collecting unlabeled data is a highly automatic
process, while ﬁnding the correct labeling of the data requires expensive human work.
Our algorithm uses all of the unlabeled examples and in this way overcomes the problems
pointed out by Rivest and Eisenberg. Learning becomes an interactive process: rather than
requesting the human to label all the examples in advance, we let the computer choose the
exampleswhoselabelsaremostinformative. Initially, mostexampleswillbeinformativefor
the learner, but as the process continues, the prediction capabilities of the learner improve,
and it discards most of the examples as non-informative, thus saving the human teacher a
large amount of work.
In there are several suggestions for query ﬁlters together
with some empirical tests of their performance on simple problems. In the authors suggested a ﬁlter called “query by committee,” (QBC)
and analytically calculated its performance for some perceptron-type learning problems.
For these problems, they found that the prediction error decreases exponentially fast in the
number of queries. In this work we present a more complete and general analysis of query
by committee, and show that such an exponential decrease is guaranteed for a general class
of learning problems.
The problem of selecting the optimal examples for learning is closely related to the
problem of experimental design in statistics ).
Experimental design is the analysis of methods for selecting sets of experiments, which
correspond to membership queries in the context of learning theory. The goal of a good
SELECTIVE SAMPLING USING QUERY BY COMMITTEE
design is to select experiments in a way that their outcomes, which correspond to labels,
give sufﬁcient information for constructing a hypothesis that maximizes some criterion of
accuracy. One natural criterion is the accuracy with which the parameters that deﬁne the
hypothesis can be estimated . In the context of Bayesian estimation a very
general measure of the quality of a query is the reduction in the entropy of the posterior
distribution that is induced by the answer to the query. Similar suggestions have been
made in the perceptron learning literature . A different experimental
design criterion is the accuracy with which the outcome of future experiments, chosen from
some constrained domain, can be predicted using the hypothesis. This criterion is very
similar to criteria used in learning theory. Both criteria are important for us in this paper.
We show that while in the general case the two are not necessarily related, they are related
in the case of the query by committee algorithm. Using this relation we prove the efﬁciency
of the algorithm for some speciﬁc concept classes.
Theresultspresentedinthispaperarerestrictedtoaratherlimitedsetoflearningproblems.
The main restriction is that the concepts are assumed to be deterministic and noiseless. In
the summary we list what we think are the natural extensions of our analysis.
The paper is organized as follows. In Section 2 we present the Bayesian framework
of learning within which we analyze our algorithm. In Section 3 we present some simple
learning problems and demonstrate a case in which the information gain of a query is not the
relevant criterion when we are interested in prediction quality. In Section 4 we describe the
query by committee algorithm. In Section 5 we prove that there is a close relation between
information gain and prediction error for QBC. Using this relation we show in Section 6
that the prediction error decreases exponentially fast with the number of queries for some
natural learning problems. In Section 7 we give a broader view on using unlabeled examples
for accelerating learning, and in Section 8 we summarize and point to some potential future
directions.
Preliminaries
We work in a Bayesian model of concept learning . As
in the PAC model, we denote by X an arbitrary sample space over which a distribution
D is deﬁned. In this paper we concentrate on the case where X is a Euclidean space Rd.
Each concept is a mapping c : X →{0, 1} and a concept class C is a set of concepts. The
Bayesian model differs from the PAC model in that we assume that the target concept is
chosen according to a prior distribution P over C and that this distribution is known to the
learner. We shall use the notation Prx∈D(·) to denote the probability of an event when x is
chosen at random from X according to D.
We assume that the learning algorithm has access to two oracles: Sample and Label. A
call to Sample returns an unlabeled example x ∈X, chosen according to the (unknown)
distribution D. A call to Label with input x, returns c(x), the label of x according to
the target concept. After making some calls to the two oracles, the learning algorithm is
required to output a hypothesis h : X →{0, 1}. We deﬁne the expected error of the
learning algorithm as the probability that h(x) ̸= c(x), where the probability is taken with
respect to the distribution D over the choice of x, the distribution P over the choice of
Y. FREUND, H.S. SEUNG, E. SHAMIR AND N. TISHBY
c and any random choices made as part of the learning algorithm or of the calculation of
the hypothesis h. We shall usually denote the number of calls that the algorithm makes to
Sample by m and the number of calls to Label by n. Our goal is to give algorithms that
achieve accuracy ϵ after making O(1/ϵ) calls to Sample and O(log 1/ϵ) calls to Label.
In our analysis we ﬁnd it most convenient to view the ﬁnite number of instances that are
observed by the learning algorithm as an initial segment of an inﬁnite sequence of examples,
all drawn independently at random according to D. We shall denote such a sequence of unlabeled examples by ⃗X = {x1, x2 . . .}, and use ⟨⃗X, c( ⃗X)⟩= {⟨x1, c(x1)⟩, ⟨x2, c(x2)⟩. . .}
to denote the sequence of labeled examples that is generated by applying c to each x ∈⃗X.
We use ⃗X1...m to denote the sequence of the ﬁrst m elements in ⃗X. We use the terminology of , and deﬁne the version space generated by the sequence of labeled
examples ⟨⃗X1...m, c( ⃗X1...m)⟩to be the set of concepts c′ ∈C that are consistent with c on
⃗X, i.e. that c′(xi) = c(xi) for all 1 ≤i ≤m. We denote the version space that corresponds
to the ﬁrst i labeled examples by Vi = V (⟨⃗X1...i, c( ⃗X1...i)⟩). The initial version space,
V0 = V (∅), is equal to C. The version space is a representation of the information contained
in the set of labeled examples observed by the learning algorithm. A natural measure of the
progress of the learning process is the rate at which the size of the version space decreases.
The instantaneous information gain from the ith labeled example in a particular sequence
of examples is deﬁned to be −log PrP(Vi)/PrP(Vi−1). Summing the instantaneous information gains over a complete sequence of examples we get the cumulative information
gain, which is deﬁned as
I(⟨x1, c(x1)⟩, . . . , ⟨xm, c(xm)⟩) .= −
PrP(Vi−1) = −log PrP(Vm) .
The natural measure of the information that we expect to gain from the label of an unlabeled
example is the expected instantaneous information gain taken with respect to the probability
that each one of the two labels occurs. Let p0 be the probability that the label of xm is 0,
given that c ∈Vm−1 and let V 0
m be the version space that results from the label xm being
0. Deﬁne p1 and V 1
m in the corresponding way for the case c(xm) = 1. We deﬁne the
expected information gain of xi, given Vi−1, to be:
G(xi|Vi−1) .= −p0 log PrP(V 0
PrP(Vi−1) −p1 log PrP(V 1
= −p0 log p0 −(1 −p0) log(1 −p0) .= H(p0) ,
where H(p) denotes the Shannon information content of a binary random variable whose
probability of being 1 is p. We shall use log base 2 in our deﬁnition and measure the
expected information gain in bits.1 The maximal information gain from a single label is
one bit. The information gain is thus a very attractive measure of the gain that can be
expected from asking Label for the label of an example. However, as we show in Section 3,
this measure, by itself, is not sufﬁcient for guaranteeing a large reduction in the expected
prediction error of the algorithm.
The “Gibbs” prediction rule is to predict the label of a new example x by picking a
hypothesis h at random from the version space and labeling x according to it. The random
SELECTIVE SAMPLING USING QUERY BY COMMITTEE
choice of h is made according to the prior distribution P restricted to the version space. It is
a simple observation ), that the expected error of
this prediction error is at most twice larger than the expected error of the optimal prediction
rule which is the Bayes rule. We shall assume that our learning algorithm has access to an
oracle, denoted Gibbs, which can compute the Gibbs prediction for a given example x ∈X
and version space V ⊂C. Each time Gibbs(V, x) is called, a hypothesis h ∈C is chosen
at random according to the distribution P restricted to V , and the label h(x) is returned.
Note that two calls to Gibbs with the same V and x can result in different predictions.
The main result of the paper is that a simple algorithm for learning using queries, that uses
the Gibbs prediction rule, can learn some important concept classes with accuracy that is
exponentially small in the number of calls to Label.
Two simple learning problems
In this section we discuss two very simple learning problems. Our goal here is to give
examples of the concepts deﬁned in the previous section and to show that constructing
queries solely according to their expected instantaneous information gain is not a good
method in general.
Consider the following concept class. Let X = , and let the associated probability
distribution D be the uniform distribution. Let the concept class C, consist of all functions
of the form
where w ∈ . We deﬁne the prior distribution of concepts, P to be the one generated
by choosing w uniformly from .
Theversionspacedeﬁnedbytheexamples{⟨x1, c(x1)⟩, . . . , ⟨xm, c(xm)⟩}is(isomorphic
to) the segment Vi = [max(xi|c(xi) = 0), min(xi|c(xi) = 1)]. Let us denote by ξi the
ratio of the probabilities of the version space before and after observing the ith example,
i.e. ξi = PrPVi/PrPVi−1. The instantaneous information gain of the example ⟨xi, c(xi)⟩
is −log ξi. Given an unlabeled example, the expected instantaneous information gain from
xi is H(ξi). Examples that fall outside the segment have zero expected information gain,
while the example that divides the segment into two equal parts obtains the highest possible
expected information gain of one bit. This agrees with our intuition because the labels
of examples that fall outside the segment are already completely determined by previous
labeled examples, while the label of the example that falls in the middle of the version space
interval is least predictable. It is easy to show that the probability of a prediction error for
the Gibbs prediction rule is equal to the length of the segment divided by three. Thus,
if the learner asks for the label of the example located in the middle of the segment, it is
guaranteed to halve the error of the Gibbs prediction rule. In this case we see that asking the
oracle Label to label the example that maximizes the expected information gain guarantees
an exponentially fast decrease in the error of the Gibbs prediction rule. In contrast, the
expected prediction error after asking for the labels of n randomly chosen examples is
Y. FREUND, H.S. SEUNG, E. SHAMIR AND N. TISHBY
The version space
w2 is somewhere here
Two examples that achieve
the highest information gain
Figure 1. A ﬁgure of the version space and the examples that achieve maximal information gain for the two
threshold learning problem deﬁned below.
The question is whether constructing queries according to their expected information
gain is a good method in general, i.e. whether it always guarantees that the prediction error
decreases exponentially fast to zero.
The answer to this question is negative, to see why this is the case consider the following,
slightly more complex, learning problem. Let the sample space be the set of pairs in which
the ﬁrst element, i, is either 1 or 2, and the second element, z, is a real number in the range
 , i.e. x ∈X = {1, 2} × . Let D be the distribution deﬁned by picking both i and
z independently and uniformly at random. Let the concept class be the set of functions of
c⃗w(i, z) =
where ⃗w ∈ 2. The prior distribution over the concepts is the one generated by choosing
⃗w uniformly at random from 2. In this case each example corresponds to either a
horizontal or a vertical half plane, and the version space, at each stage of learning, is a
rectangle (see Figure 3). There are always two examples that achieve maximal information
gain, one horizontal and the other vertical. Labeling each one of those examples reduces
the volume of the version space by a factor of two. However, the probability that the Gibbs
rule makes an incorrect prediction is proportional to the perimeter of the rectangular version
space, and not to its volume. Thus, if the learner always constructs queries of the same type,
only one of the dimensions of the rectangle is reduced, and the perimeter length stays larger
than a constant. This implies that the prediction error also stays larger than a constant.
We conclude that the expected information gain of an unlabeled example is not a sufﬁcient
criterion for constructing good queries. The essential problem is that the distribution over
SELECTIVE SAMPLING USING QUERY BY COMMITTEE
the examples is completely ignored by this criterion. While one can easily ﬁnd a speciﬁc
solution for the given learning problem, we would like to have a general method that is
sensitive to the distribution of the examples, and is guaranteed to work for a wide variety
of problems. In the next section we present such a method.
The Query by Committee learning algorithm
In the authors devise an algorithm for learning with
querieswhichtheycalled“QuerybyCommittee”andweshallrefertoastheQBCalgorithm.
The algorithm uses as queries examples whose expected information gain is high, however,
rather than constructing the examples, it ﬁlters the more informative examples from the
random unlabeled examples that it gets from the oracle Sample. We discuss the simplest
case in which the committee is of size two. 2
The algorithm proceeds in iterations. In each iteration it calls Sample to get a random
instance x. It then calls Gibbs twice, and compares the two predictions for the label of x.
If the two predictions are equal, it rejects the instance and proceeds to the next iteration. If
the two predictions differ, it calls Label with input x, and adds the labeled example to the
set of labeled examples that deﬁne the version space. It then proceeds to the next iteration.
In the authors treat the query by committee algorithm
as an on-line learning algorithm, and analyze the rate at which the error of the two Gibbs
learners reduces as a function of the number of queries made. In our work we prove general
bounds both on the number of queries and on the number of random examples that the
algorithm tests. In order to do that we consider a batch learning scenario, in which the
learning algorithm is tested only after it has ﬁnished observing all of the training examples
and has ﬁxed its prediction hypothesis.
To do that we deﬁne a termination condition on the iterative process described above.
When the algorithm reaches this a state that fulﬁlls this condition it stops calling Sample
and Label and uses the Gibbs oracle to predict the labels of the instances that it receives
in the test phase. The termination condition is satisﬁes if a large number of consecutive
instances supplied by Sample are all rejected.
We measure the quality of the predictions made by the algorithm in a way similar to
that used in Valiant’s PAC model. We deﬁne the expected error of the algorithm as the
probability that its prediction of the label of a random instance disagrees with that of the
true underlying concept. This probability is taken with respect to the random choice of
the instance as well as the underlying concept. We also allow the algorithm some small
probability of failure to account for the fact that the sequence of instances that it observes
during training is atypical.
We say that the learning algorithm is successful if its expected error is small, when trained
on a typical sequence of instances. More precisely, we deﬁne two parameters, an accuracy
parameter 1 > ϵ > 0 and a conﬁdence parameter 1 > δ > 0. We use the term “training
history” to describe a speciﬁc sequence of random instances and random coin ﬂips used
during learning a speciﬁc hidden concept. For each choice of the hidden concept, we allow
a set of training histories that has probability δ to be marked as “atypical” training histories.
Our requirement is that the expected error over the set of typical training histories is smaller
Y. FREUND, H.S. SEUNG, E. SHAMIR AND N. TISHBY
Input: ϵ > 0 - the maximal tolerable prediction error.
δ > 0 - the desired reliability.
Gibbs- an oracle that computes Gibbs predictions.
Sample- an oracle that generates unlabeled examples.
Label- an oracle that generates the correct label of an example.
Initialize n - the counter of calls to Label – to 0, and set the initial version space, V0, to be
the complete concept class C.
Repeat until more than tn consecutive examples are rejected. Where
ϵ ln π2(n + 1)2
and n is the number of examples that have been used as queries so far.
Call Sample to get an unlabeled example x ∈X drawn at random according to D.
Call Gibbs(Vn, x) twice, to get two predictions for the label of x.
If the two predictions are equal then reject the example and return to the beginning of
the loop. (step 1)
Else call Label(x) to get c(x), increase n by 1, and set Vn to be all concepts c′ ∈Vn−1
such that c′(x) = c(x).
Output as the prediction hypothesis Gibbs(Vn, x).
Figure 2. Query by a committee of two
than ϵ. The parameters ϵ and δ are provided to the learning algorithm as input and are used
to deﬁne the termination criterion. Figure 2 gives a formal description of the algorithm. It
is important to notice that the termination condition depends only on ϵ and δ, and not of
any properties of the concept class. While the performance of the algorithm does depend
on such properties, the algorithm can be used without prior knowledge of these properties.
It is easy to show that if QBC ever stops, then the error of the resulting hypothesis is
small with high probability. That is because it is very unlikely that the algorithm stops if
the probability of error is larger than ϵ (proof is given in Lemma 2). The harder question
is whether QBC ever stops, and if it does, how many calls to Sample and to Label does
it make before stopping? As we shall show in the following two sections, there is a large
class of learning problems for which the algorithm will stop, with high probability, after
O(1/ϵ log 1/δϵ) calls to Sample, and O(log 1/ϵ) calls to Label.
The committee ﬁlter tends to select examples that split the version space into two parts
of comparable size, because if one of the parts contains most of the version space, then
SELECTIVE SAMPLING USING QUERY BY COMMITTEE
the probability that the two hypotheses will disagree is very small. Let us normalize the
probability of the version space to one and assume that an example x partitions the version
space into two parts with probabilities F and 1 −F respectively. Then the probability of
accepting the example x as a query is 2F(1−F) and the information gain from an example
is H(F). . Both of these functions are maximized at F = 0.5 and decrease symmetrically
to zero when F is increased to one or decreased to zero. It is thus clear that the queries
of QBC have a higher expected information gain than random examples. However, it is
not true in general that the expected information gain of the queries will always be larger
than a constant,3 moreover, as we have seen in the Section 3, queries with high information
gain do not guarantee a fast decrease of the prediction error in general. Our proof of the
performance of QBC consists of two parts. In the ﬁrst part, given in Section 5, we show
that a lower bound on the information gain of the queries does guarantee a fast decrease
in the prediction error of QBC. In the second part, given in Section 6, we show that the
expected information gain of the queries of QBC is guaranteed to be higher than a constant
in some important cases.
Relating information gain and prediction error for Query by Committee
In this section we prove that if the expected information gain from the queries used by
QBC is high, then the prediction error of the algorithm is guaranteed to be exponentially
small in the number of queries asked. We shall ﬁrst deﬁne exactly what we mean by high
information gain, and then give the theorem and its proof.
In our analysis we treat runs of the algorithm as initial segments of inﬁnite runs that would
have been generated had there been no termination criterion on the execution of the main
loop in QBC. We denote by ⃗X the inﬁnite sequence of unlabeled examples that would
have been generated by calls to Sample. We use an inﬁnite sequence of integer numbers
I = {1 ≤i1 < i2 < . . .} to refer to the sequence of indices of those examples that are
ﬁltered by QBC from ⃗X and used as queries to Label. This set of examples is denoted ⃗XI.
We denote by M the sequence of integers from 1 to m, and use ⃗XM to denote the ﬁrst m
examples in ⃗X. We use In to denote the ﬁrst n elements of I. Finally, ⃗XIn indicates the
ﬁrst n examples that are used as queries, and ⃗XI∩M indicates the queries that are chosen
from the ﬁrst m unlabeled examples.
We now present the probabilistic structure underlying the query process. A point in the
sample space Ωis a triple ⟨c, ⃗X, I⟩. The probability distribution over this space is deﬁned
as follows. The target concept c is chosen according to P, and each component in the
inﬁnite sequence ⃗X is chosen independently according to D. Fixing c and ⃗X, we deﬁne
the distribution of the ﬁrst n elements of I according to the probability that algorithm QBC
calls the oracle Label on the iterations indexed by In. It is easy to see that the distributions
deﬁned for different values of n are consistent with each other, thus we can deﬁne the
distribution on I as the limiting distribution for n →∞. We denote the distribution we
have deﬁned on the triplets ⟨c, ⃗X, I⟩by ∆and use Pr∆and E∆to indicate the probability
and the expectation taken with respect to this distribution.
Y. FREUND, H.S. SEUNG, E. SHAMIR AND N. TISHBY
We now deﬁne formally what we mean when we say that the queries of QBC are informative.
Deﬁnition. We say that the expected information gain of queries made by QBC for the
learning problem of concept class C,concept distribution P, and input distribution D, is
uniformly lower bounded by g > 0 if the following holds.
For the distribution over ⟨c, ⃗X, I⟩that is generated by P, D and QBC and for every n ≥0,
the expected instantaneous information gain from the n + 1st query, given any sequence of
previous queries and their answers, is larger than g. In our notation we can write this as the
requirement that the following conditional expectation is larger than g almost everywhere:
G(xin+1|V (⟨⃗XIn, c( ⃗XIn)⟩))
⃗XIn, c(XIn)
In somewhat more intuitive terms, a uniform lower bound on the information means that
for any version space that can be reached by QBC with non-zero probability, the expected
information gain from the next query of QBC is larger than g. In Section 6 we shall
prove uniform lower bounds on the information gain of QBC for some important learning
We now give the theorem that relates the bound on the information gain of QBC to its
expected prediction error.
Theorem 1 If a concept class C has VC-dimension 0 < d < ∞and the expected
information gain of queries made by QBC is uniformly lower bounded by g > 0 bits, then
the following holds with probability larger than 1 −δ over the random choice of the target
concept, the sequence of examples, and the choices made by QBC:
• The number of calls to Sample that QBC makes is smaller than
eδ , 160(d + 1)
6, ln 80(d + 1)
• The number of calls to Label that QBC makes is smaller than
n0 = 10(d + 1)
In other words, it is an exponentially small fraction of the number of calls to Sample.4
• The probability that the Gibbs prediction algorithm that uses the ﬁnal version space of
QBC makes a mistake in its prediction is smaller than ϵ.
Before we proceed to prove the theorem, let us give a brief intuitive sketch of the argument
(See Figure 3). The idea is that if a concept class is learnable then, after observing many
labeled examples, the conditional distribution of the labels of new examples is highly
biased to one of the two labels. This means that the information gained from knowing
SELECTIVE SAMPLING USING QUERY BY COMMITTEE
Cumulative
Information
Cumulative
Information
Cumulative
Information
of Queries
Gap between examples
accepted as queries
Random Examples
Figure 3. Each tag on the x axis denotes a random example in a speciﬁc typical sequence. The symbol X under
a tag denotes the fact that the example was chosen as a query.
the label of a random example is small.
This, in turn, means that the increase in the
cumulative information from a sequence of random examples becomes slower and slower
as the sequence gets longer. On the other hand, if the information gained from the queries
of QBC is lower bounded by a constant, then the cumulative information gain from the
sequence of queries increases linearly with the number of queries. It is clear that the
information from the labels of the queries alone is smaller than the information from the
labels of all the examples returned by Sample.
The only way in which both rates of
increase can hold without violating this simple inequality is if the number of examples
that are rejected between consecutive queries increases with the number of queries. As a
result the termination criterion of QBC will hold, and the algorithm will output its ﬁnal
prediction rule after a reasonably small number of queries. The prediction rule that is output
is the Gibbs prediction rule, using the ﬁnal version space that is deﬁned by all the labeled
examples seen so far. The probability of making a prediction error using this rule is, by
deﬁnition, equal to the probability of a disagreement between a hypothesis that is randomly
chosen according to the prior distribution restricted to the version space and a concept that
is independently chosen according to the same distribution. This probability is also equal
to the probability of accepting a random example as a query when using this version space.
The termination condition is fulﬁlled only if a large number of random examples are not
accepted as queries, which implies that the probability of accepting a query or making a
prediction mistake when using the ﬁnal version space is small. We shall prove the theorem
using the following three lemmas.
Lemma 1 If the expected instantaneous information gain of the query algorithm is uniformly lower bounded by g > 0 bits, then
Pr∆(I(⟨⃗XIn, c( ⃗XIn)⟩) < g
The deﬁnition of a uniform lower bound on the expected information gain means
that for any n > 0, for all sequence of of n queries ⟨⃗XIn, c( ⃗XIn)⟩, excluding possibly a set
Y. FREUND, H.S. SEUNG, E. SHAMIR AND N. TISHBY
of measure zero, the expected information gain from the n + 1st query is lower bounded
by g. Put in another way, this means that the random variables
Yi = I(⟨⃗XIi, c( ⃗XIi)⟩) −I(⟨⃗XIi−1, c( ⃗XIi−1)⟩) −g
form a sequence of sub-martingale differences. As the instantaneous information gain is
bounded between 0 and 1, we get that −g ≤Yi ≤1 −g. We can thus use Hoeffding’s
bound on the tails of bounded step sub-martingales 5 from which we
know that for any ϵ > 0
Yi ≤−ϵn) ≤
g + ϵ)g+ϵ(
1 −g −ϵ)1−g−ϵ
Setting ϵ = λg and taking logs we get
i=1 Yi ≤−λgn) ≤
−(1 + λ)g ln(1 + λ) + (1 −(1 + λ)g) ln
exp ((λ −(1 + λ) ln(1 + λ)) gn) .
Choosing λ = 1/2 we get the bound.
Lemma 2 The probability that the predictions made by QBC are wrong (after its main
loop has terminated) is smaller than ϵ with probability larger than 1 −δ/2.
Assume that the probability of a wrong prediction is larger than ϵ. As discussed
in the informal part of the proof, this implies that the probability of accepting a random
example as a query with the ﬁnal version space, is also larger than ϵ. It thus remains to show
that the probability that QBC stops when the probability of accepting a query is larger than
ϵ is smaller than δ/2.
The termination condition of QBC is that all tn examples tested after the nth query
are rejected. If the probability of accepting a random example is larger than ϵ then this
probability is smaller than (1 −ϵ)tn. From the deﬁnition of tn we get that
ϵ ln π2(n+1)2
≤e−ln π2(n+1)2
π2(n + 1)2 .
Summing this probability over all possible values of n from zero to inﬁnity we get the
statement of the lemma.
In itwasshownthatiftheVC-dimensionofaconcept
class is d, then the expected information gain from m random examples is bounded by
(d + 1) log(m/d). Here we show that the probability that the information gain is much
larger than that is very small.
Lemma 3 Assume a concept c is chosen at random from a concept class with VC dimension
d. Fix a sequence of examples ⃗X, recall that ⃗XM denotes the ﬁrst m examples. Then
SELECTIVE SAMPLING USING QUERY BY COMMITTEE
I(⟨⃗XM, c( ⃗XM)⟩) ≥(d + 1) we know that the number of different labelings created by m examples is at most Pd
≤(em/d)d. The expected cumulative
information gain is equal to the entropy (base 2) of the distribution of the labels and is maximized when all the possible labelings have equal probability. This gives an upper bound
of d log em
d on the expected cumulative information gain. Labelings that have cumulative
information gain larger by a than this expected value, must have probability that is smaller
by 2a than the labels in the equipartition case. As the number of possible labelings remains
the same, the total probability of all concepts that give rise to such labelings is at most 2−a.
Choosing a = log em
d we get the bound.
Proof of Theorem 1: We consider a randomly chosen element of the event space ⟨c, ⃗X, I⟩.
Our analysis involves the ﬁrst m0 random examples presented to QBC, ⃗XM0, and the ﬁrst
n0 queries that QBC would ﬁlter if it never halts, ⃗XIn0 . We denote the number of queries
that QBC makes during the ﬁrst m0 examples by n, i.e. n = |I ∩M0|. The claim of the
theorem is that, with probability at least 1−δ, the algorithm halts before testing the m+1st
example, the number of queries it makes, n, is smaller than n0, and the hypothesis it outputs
upon halting has error smaller than ϵ. We shall enumerate a list of conditions that guarantee
that all of these events occur for a particular random choice of examples and of internal
randomization in QBC. By showing that the probability of each of those conditions to fail
is small we get the statement of the theorem.
The conditions are:
The cumulative information content of the ﬁrst n0 queries is at least gn0/2.
From Lemma 1 we get that in order for this condition to hold with probability larger
than 1 −δ/4 it is sufﬁcient to require that
The cumulative information content from the ﬁrst m0 examples is at most
(d + 1)(log em0
From Lemma 3 we get that in order for this condition to hold with probability larger
than 1 −δ/4 it is sufﬁcient to require that
The number of queries made during the ﬁrst m0 examples, n, is smaller than n0.
The condition follows from conditions 1 and 2 if
I(⟨⃗XIn0 , c( ⃗XIn0 )⟩) ≥I(⟨⃗XM0, c( ⃗XM0)⟩)
Y. FREUND, H.S. SEUNG, E. SHAMIR AND N. TISHBY
This is because if n ≥n0 then the information gained from the queries asked during
the ﬁrst m0 examples is larger than the total information gained from the m0 examples,
which is impossible. In order for (10) to hold, it is sufﬁcient to require that
n0 > 2(d + 1)
The number of consecutive rejected examples guarantees that the algorithm stops
before testing the m0 + 1st example.
Notice that the threshold ti increases with i. Thus if at least tn consecutive examples from among the ﬁrst m0 examples are rejected, the algorithm is guaranteed to halt
before reaching the m0 + 1st example. As there are m0 −n rejected examples, the
length of the shortest run of rejected examples is at least (m0 −n)/(n+1). We require
that this expression is larger than tn, and use the fact that condition 3 holds, i.e. that
n < n0. Using these facts it is sufﬁcient to require that
m0 ≥2(n0 + 1)
3δ (n0 + 1)2
The Gibbs prediction hypothesis that is output by the QBC has probability smaller
than ϵ of making a mistaken prediction.
From Lemma 2 we get that the probability of this to happen is smaller than δ/2.
We see that if Equations (8), (9), (11), and (12) hold, then the probability that any of the
four conditions fails is smaller than δ.It thus remains to be shown that our choices of n0 and
m0 guarantee that these equations hold. Combining Equations (8) and (11), we get that it
is sufﬁcient to require that m0 ≥2, d ≥1, and
n0 + 1 = 10(d + 1)
Plugging this choice of n0 into Equation (12), we get the following requirement on m0:
m0 ≥40(d + 1)
·20(d + 1)
It is simple algebra to check that the following choice of m0 and satisﬁes Equations (9)
eδ , 160(d + 1)
6, ln 80(d + 1)
Equations (13) and (15) guarantee that the conditions 1-5 hold with probability at least 1−δ.
SELECTIVE SAMPLING USING QUERY BY COMMITTEE
Concept classes that are efﬁciently learnable using QBC
According to Theorem (1) above, if query by committee yields high information gain, then
it yields a rapidly decreasing generalization error. Here we discuss some geometric concept
classes for which a uniform lower bound on the information gain exists, and hence to which
the theorem is applicable.
Our main analysis is for a learning problem in which concepts are intersections of halfspaces with a compact and convex subset of Rd. In this case the concept class itself can be
represented as a compact and convex subset of Rd and each example partitions the concept
class by a d −1 dimensional hyperplane. In Section 6.1, we sketch a proof of a uniform
lower bound on the information gain of QBC that does not depend on the dimension d, for
the case in which both D and P are uniform. The proof, which is detailed in Appendix A.
is based on a variational analysis of the geometry of the version space. In Section 6.2 this
result is extended to the case of non-uniform input distribution and prior and applied to the
perceptron learning problem.
Uniformly distributed half-spaces
In this subsection we prove a lower bound on the information gain for a simple geometric
learning problem to which we shall refer as the “parallel planes” learning problem.
Figure 4. A ﬁgure of the two dimensional concept class deﬁned by Equation (16) for d = 2. The shaded area
corresponds to a typical convex version space V which is deﬁned by a set of half spaces corresponding to several
examples. This version space is bisected by a new unlabeled example deﬁned by ⃗x and t.
We deﬁne the domain, X, to be the set of all pairs of the form (⃗x, t), where ⃗x is a vector
in Rd whose length is 1, which we refer to as the “direction” of the example, and t is a real
number in the range [−1, +1], to which we refer as the offset (see Figure 6.1). In other
words X = Sd × [−1, +1], where Sd denotes the unit sphere around the origin of Rd. In
this section we assume that the distribution D on X is uniform.6 The concept class, C, is
deﬁned to be a set of binary functions over X, parameterized by vectors ⃗w ∈Rd, ||⃗w||2 ≤1,
that are deﬁned as follows
Y. FREUND, H.S. SEUNG, E. SHAMIR AND N. TISHBY
c ⃗w(⃗x, t) =
⃗w · ⃗x ≥t ,
⃗w · ⃗x < t
We assume that the prior distribution is uniform on Bd—the unit ball of radius one around
the origin. This concept class is very similar to the class deﬁned by the perceptron with
variable threshold. 7 However, note that in this case the threshold, t, is part of the input,
and not a parameter that deﬁnes the concept. This concept class is a bit strange, but as we
shall see, the results we can prove for it can be extended to more natural concept classes
such as the perceptron.
The information gain from random examples vanishes as d goes to inﬁnity. The reason for
this is that in high dimension, the volume of the sphere is concentrated near the equator. A
typical random example will cut the sphere some distance away from the equator, in which
case the sphere will fall into two pieces of very unequal volume. The piece containing
the equator will contain almost all of the volume. This geometric example illustrates why
query algorithms are especially important in high dimensions. Query by committee solves
this problem by choosing two random points in the sphere. Since these two points are likely
to be near the equator, an example that separates them is likely to be near the equator. For
this reason, query by committee can attain an information gain that remains ﬁnite in high
dimensions.
In our proof of the uniform lower bound on the expected information gain of QBC we
use two properties of the version spaces for this concept class. The ﬁrst property is that
each example (⃗x, t) cuts the version space by a plane that is orthogonal to the direction
⃗x and has offset t from the origin.8 As t is uniformly distributed, the planes that cut the
version space in any ﬁxed direction have a uniformly distributed offset that spans the width
of the version space in that direction. The second property is that all version spaces that
can be generated when learning this concept class are bounded convex sets because they
are deﬁned as the intersection of a ball with a number of half-spaces.
As discussed in Section 4, both the expected information gain of an example and the
probability that the example is accepted by QBC are quantities that depend on the ratio
between the probabilities of the two parts of the version space that are created by the
example. Based on these observations we can reduce our problem to a one dimensional
problem. Fix a particular direction ⃗x. Let F⃗x : [−1, +1] → be the fraction of the
version space, V , that is on one side of the plane deﬁned by ⃗x and t, i.e.
F⃗x(t) = Prc ⃗
w∈P (c ⃗w ∈V |c⃗w(⃗x, t) = 0)
w∈P (c ⃗w ∈V )
We call F the volume function of the version space. The probability that QBC accepts the
example (⃗x, t) is 2F⃗x(t)(1−F⃗x(t)), and the expected information gain from the example is
H(F⃗x(t)). As t is uniformly distributed, the expected information gain from the examples
whose direction is ⃗x is
−1 F⃗x(t)(1 −F⃗x(t))H(F⃗x(t)) dt
−1 F⃗x(t)(1 −F⃗x(t)) dt
SELECTIVE SAMPLING USING QUERY BY COMMITTEE
Our result is a lower bound on the value of G(F⃗x). The proof is based on ﬁnding the
convex version space that produces the smallest value of G(F⃗x). This body is constructed
of two isomorphic cones connected at their bases, we call this body a “two-cone”. Barland
 , analyzes a similar problem. He ﬁnds the convex body that
achieves the minimal value of the functional
−1 min(F⃗x(t), 1 −F⃗x(t)) dt. The analysis
of the minimum for this functional is much simpler, interestingly, Barland ﬁnds that the
body which achieves the minimum is the same as the one which achieves the minimum of
the functional G.
Theorem 2 The functional G(F⃗x), deﬁned for volume functions of convex bodies in Rd,
assumes a unique minimum at the two-cones body deﬁned above. The value of G at the
minimum is at least 1/9 + 7/(18 ln 2) > 0.672 bits, for any dimension d.
This theorem gives us a lower bound on the expected information gain of a single query
of QBC for the “parallel planes” learning problem deﬁned at the beginning of this section.
In Section 6.2 we shall use this theorem to prove that QBC is an effective query algorithm
for learning perceptrons.
Here we give the main part of the proof. The more technical details are formulated
in Lemmas 4, 5, 6 and 7, whose proofs are given in appendix A.
The proof is based on a variational analysis of the functional G. We shall show that the
volume function that corresponds to “two-cones” minimizes this functional. We shall show
that any other volume function of a convex body can be slightly altered in a way which
decreases the value of G and maintains the correspondence with some convex body.
We shall bound the value of G(F⃗x) independently of the direction ⃗x. Our bound depends
only on the fact that the version space is a bounded convex set in Rn and that the distribution
in it is uniform. We thus drop the subscript ⃗x from F⃗x(·). As F(−1) = 0, F(+1) = 1, and
H(1) = H(0) = 0, we will, without loss of generality, extend the deﬁnition of F(t) to all
of R by deﬁning it to be zero for t ≤−1 and one for t ≥1. We then redeﬁne the integrals
in the deﬁnition of G(F) in Equation (18) to be from −∞to ∞. It is easy to check that
G(F(t)) = G(F(at + b)) for any a, b ̸= 0. Thus, without loss of generality, the support of
the volume function is [−1, +1] and F(0) = 1/2.
Consider the right half of the body, i.e. the set of points whose t coordinate is at least
0. Take the union of this half with its symmetric reﬂection at the plane t = 0. Similarly,
generate a symmetric body from the left side of the original body. The two resulting bodies
are reﬂection symmetric but usually not convex. Their volume functions are:
It is easy to see that either G(F+) ≤G(F) or G(F−) ≤G(F). Thus, in order to prove
a lower bound on G(F) for all convex bodies, it is sufﬁcient to prove a lower bound for
volume functions that correspond to reﬂection-symmetric bodies for which each half is
Y. FREUND, H.S. SEUNG, E. SHAMIR AND N. TISHBY
convex. Our variational manipulations will apply to one half of the symmetric body (say
t ≥0) and carry over by reﬂection to other half. As we shall show, the minimum for one
half is obtained for a cone with a base at t = 0. Its symmetric reﬂection, the two-cone
body, happens to be a convex body. Thus the two cone body gives the minimum of G(F)
for all convex bodies.
Our goal is thus to ﬁnd the a volume function F : [0, ∞) →[1/2, 1] of the right half of a
convex body, which minimizes the functional
F(x)(1 −F(x))H(F(x)) dx
F(x)(1 −F(x)) dx
We ﬁnd it convenient to deﬁne the functions K(t)
F(t)(1 −F(t)),
Q(x) = H(1/2 −√1 −4x/2). It is easy to verify that H(F) = Q(K), and that Equation (19) can be written as
K(t)Q(K(t)) dt
The changes in G(K) that are induced by small changes in the function K can be approximated by a linear functional, called the Fr´echet derivative,9 as follows
G(K + Ψ) = G(K) +
∇G[K](t)Ψ(t) dt + o
The Fr´echet derivative ∇G[K] is a function from [0, ∞) into R and ∇G[K](t) is the value
of this function at the point t. The derivative is calculated by formally differentiating the
functional ∇G[K] with respect to K(t). Thus
∂K(t) (K(t)Q(K(t))) −
K(s)Q(K(s)) ds
Q(K(t)) + K(t)
∂K(t)Q(K(t)) −G(K)
We ﬁrst consider the behavior of the sum of the ﬁrst two terms in the square brackets.
Denote K(t) by y. A direct calculation shows that Q(y) + y ∂
∂yQ(y) is a strictly increasing
function of y in the range 0 ≤y ≤1/4, which is the range of K(t). It is 0 for y = 0 and 1
for y = 1/4.
As 0 ≤G(K) ≤1 the third term is in the range of the sum of the ﬁrst two terms. As K(t)
is decreasing for positive t, it follows that there is some point w > 0, which is a function of
K, such that for all 0 ≤t ≤w,
∂K(t)G(K(t)) > 0, and for all t > w,
∂K(t)G(K(t)) < 0.
The parameter w is of critical importance in the rest of the paper, and we shall refer to it
is the “pivot point”. In terms of the volume function F, for t > 0, F increases when K
decreases and vice versa. Thus if the variation Ψ(t) is non-negative for points below the
SELECTIVE SAMPLING USING QUERY BY COMMITTEE
pivot point, non-positive for points above the pivot point, and
Ψ(t)2 dt is sufﬁciently
small then G(K(t) + Ψ(t)) < 0 as desired.
We shall construct suitable variations in proving lemma 5. For now, let B be the convex
body whose volume function is F(t). Consider the functions f(t) and r(t) deﬁned as
f(t) = dF(t)
where cd −1 is the volume of the d −1 dimensional unit ball. The function F(t) is equal
to the total volume of the body B in the range (−∞, t], so f(t) is the d −1 dimensional
volume of the slice of B at t. We call r(t) the radius function because if ˜B is a body
of revolution obtained by rotating (the planar graph of) the function t →r(t) around the
axis r(t) = 0, then the volume functions that correspond to ˜B and to B are the same.
Moreover,the following Lemma characterizes radius functions of convex bodies
1. The radius function of any convex body is concave.
2. The body of revolution that is generated by a concave radius function is convex.
The proof of the lemma is given in Appendix A. Thus the search for the minimum of
G(K) over convex bodies (for t ≥0) can be restricted to bodies of revolution created by
rotating a concave radius function r(t).
The proof of the theorem is concluded by proving the following lemmas, the details are
in Appendix A.
Lemma 5 If the convex body with volume function F is not a cone with base at the
hyperplane t = 0 then there exists an admissible variation Ψ such that G(F +Ψ) < G(F).
Lemma 6 The minimum of G over convex bodies is achieved.
From Lemmas 5 and 6 it follows that the minimum of G(F) is achieved for the two-cone
body. Finally a simple calculation gives that
Lemma 7 The value of G(F) for a two-cone body in Rd is at least 1/9 + 7/(18 ln 2) >
0.672 for any dimension d.
This concludes the proof of Theorem 2.
Perceptrons
In this section we apply Theorem 2 to the problem of learning perceptrons. The perceptron
concept class is deﬁned as the following set of binary functions over the unit ball
⃗x · ⃗w ≥0
otherwise ,
Y. FREUND, H.S. SEUNG, E. SHAMIR AND N. TISHBY
where ⃗w, ⃗x ∈Rd, ||⃗w||2 = 1 and ||⃗x||2 ≤1. The prior distributions are within some
constants from the uniform distributions over the respective sets. As each ⃗w is a point on
the surface of a d dimensional sphere, the initial version space is isomorphic to the unit
The section is organized as follows. We start by stating an extension of Theorem 2. We
then discuss a technical issue regarding an initial phase of the learning procedure that is
required in order to make the theorems apply. We then prove the main result of this section,
which shows that, under some mild assumptions, the prediction error of the QBC algorithm,
when learning decreases exponentially fast with the number of queries asked.
Theorem 2 can be generalized to cases where the prior and input distributions are not
exactly uniform. We use the following deﬁnition
Deﬁnition. We say that a density D′ is within λ of D if for every measurable set A, we
have that λ ≤PrD(A)/PrD′(A) ≤1/λ.
Using this deﬁnition, we get the following extension of Theorem 2:
Theorem 3 The value of the functional G(F) for the parallel planes learning problem,
when the prior distribution is within λP of uniform and the input distribution is within λD
of uniform, is at least λ4
PλD(1/9 + 7/(18 ln 2)) > 0.672λ4
PλD bits, independent of the
dimension d.
The proof is in Appendix B.
Using Theorem 3, we can prove that QBC is an efﬁcient query algorithm for the perceptron
concept class when the prior distribution and the distribution of examples are both close
to uniform. We shall prove that there exists a lower bound on the information gain of the
queries of QBC. However, our proof technique requires that the initial version space is not
the complete unit sphere, but is restricted to be within a cone. In other words, there has to
exist a unit vector ⃗w0 such that for any ⃗w ∈V0 the dot product ⃗w · ⃗w0 is larger than some
constant α > 0.
This condition is annoying. However, it is not hard to guarantee that this condition holds
by using an initial learning phase, prior to the use of QBC, that does not use ﬁltering but
rather queries on all the random instances supplied by Sample. Using the results of Blumer
et al. we can bound the number of training examples that are needed to guarantee that the
prediction error of an arbitrary consistent hypothesis is small (with high probability). As
the distribution of the instances is close to uniform, a small prediction error implies that
the hypothesis vector is within a small angle of the vector that corresponds to the target
concept. The details of this argument are given in the following lemma.
Lemma 8 Assume that the distribution of the instances D is within λD from the uniform
distribution in the unit ball. Suppose m random instances are chosen according to D,
labeled according to f ⃗w0(·) and used to ﬁnd a hypothesis f⃗w(·) that is consistent with all
the labeled instances.
where ϵ = λD cos−1(α)
SELECTIVE SAMPLING USING QUERY BY COMMITTEE
then, with probability 1 −δ over the choice of the m random instances, ⃗w · ⃗w0 ≥α.
If ⃗w · ⃗w0 < α then the angle between ⃗w and ⃗w0 is larger than cos−1(α). The
examples on which f ⃗w(⃗x) is incorrect are those vectors in the unit ball for which ⃗x · ⃗w ≥0
and ⃗x · ⃗w0 < 0, or ⃗x · ⃗w < 0 and ⃗x · ⃗w0 ≥0. This deﬁnes a subset of the unit ball,
constructed of two wedges, whose volume is at least cos−1(α) of the volume of the ball. As
the distribution of the instances is within λD from the uniform distribution, the probability
of this set is at least λD cos−1(α).
On the other hand, as the VC dimension of the d dimensional perceptron is d we can
use the classical uniform convergence bounds from . Theorem 2.1
in guarantees that a hypothesis that is consistent with m labeled examples, chosen independently at random from an arbitrary distribution, has error smaller
than ϵ with probability 1 −δ if
Combining these two arguments, we get the statement of the theorem.
Assuming that an initial phase of learning from unﬁltered instances is used to guarantee
a bound on the maximal angle between vectors, we get the following theorem.
Theorem 4 For any α > 0, let Cα be the d dimensional perceptron concept class as
deﬁned in Equation (22), restricted to those concepts c ⃗w, such that ⃗w0 · ⃗w > α for some
unit vector ⃗w0. Let the prior distribution over Cα be within λP of uniform and the input
distribution be within λD from uniform. Then the expected information gain of the queries
of QBC is larger than 0.672α5dλ4
The version space for the perceptron is a region on the d-dimensional unit sphere
that is bounded by a set of great circles. We shall transform this problem into a special case
of the parallel planes learning problem deﬁned in Section 6.1.
Because we assume the existence of the vector ⃗w0 we can deﬁne a one-to-one mapping
of the version space to a bounded convex subset of Rd−1. We can assume, without loss
of generality, that ⃗w0 = {1, 0, . . . , 0}. We can also assume that ||⃗x||2 = 1, because all
instances ⃗x whose length is smaller than 1 can be mapped to ⃗x/||⃗x||2 without changing the
label assigned to them by the concepts. The distribution over the surface of the unit sphere
that is created in this way is within λD of uniform.
In this case the mapping of the concepts is deﬁned by transforming the vector
⃗w = {w1, w2, . . . , wd} that lies on the unit sphere to the d −1 dimensional vector
⃗w′ = {w2/w1, w3/w1, . . . , wd/w1}. The corresponding mapping of the instances maps the
instance⃗x = {x1, . . . , xd}thatliesontheunitspheretothepair⃗x′ = {x2, . . . , xd}/
and t = −x1/
i . It is easy to see that the condition that deﬁnes the perceptron
⃗w · ⃗x ≥0 is equivalent to ⃗x′ · ⃗w′ ≥t, which is the condition that deﬁnes the corresponding
parallel-plane concept.
The condition ⃗w · ⃗w0 > α is, in this case, equivalent to w1 > α. It is easy to check that
the only examples in the transformed concept space that can be labeled both 0 and 1 by
Y. FREUND, H.S. SEUNG, E. SHAMIR AND N. TISHBY
Segement of
the spherical
version space
Projection of the region
to a larger sphere
Maximal angle
between W and W
Projection of the
segment on the
Figure 5. The transformation that maps the spherical version space unto the hyperplane.
some concept in Cα are those for which
i > α. This implies that the increase
in the volume of an inﬁnitesimal part of the instance space is by a factor of at most α−d.
Thus as the distribution over the instances on the surface of the unit sphere is within λD of
uniform, the distribution over the transformed instance space is within αdλD of uniform.
To bound the distance of the prior distribution from uniform, consider the mapping of
an inﬁnitesimally small region of the version space from the sphere to the plane. Figure 5
illustrates this transformation for a two dimensional perceptron. This transformation maps
the hyperspherical region to a larger region in the hyperplane. The factor by which the
volume is increased is between 1 and α−d. This can be seen by separating the transformation
into two steps. In the ﬁrst step, the region on the unit hypersphere is mapped to a region on
a larger hypersphere. The radius of this larger hypersphere is at most α−1, thus the increase
in the volume is by a factor of at most α−(d−1). In the second step, the region on the large
hypersphere is mapped to the hyperplane, as the region is inﬁnitesimally small, it can be
approximated by a linear region. The increase in the volume of the region in this step is by
a factor of α−1. Multiplying the two factors we get α−d.
As the prior distribution over the sphere is within λP of uniform, the distribution over the
hyperplane that is generated by the mapping is within λPαd of uniform.
We thus have a special case of the parallel plane learning problem with close to uniform
distributions. Using Theorem 3, we get the statement of the theorem.
Using an incorrect prior distribution
Up to this point we have made the assumption that the learning algorithm is using the correct
prior distribution on the concept space P. In this section we show how this assumption can
be weakened.
Deﬁnition.
10 We say that a distribution P is λ-dominated by a distribution P if, for any
event A, PrP(A) ≤λPrP′(A).
SELECTIVE SAMPLING USING QUERY BY COMMITTEE
Suppose that QBC uses a distribution P′ that λ-dominates P for some 0 < λ < ∞such
that there is a uniform lower bound on the expected information gain of QBC with respect
to P′. The following theorem replaces Theorem 1 for this case.
Theorem 5 If a concept class C has VC-dimension 0 < d < ∞and the expected
information gain of queries made by QBC when using the prior P′ is uniformly lower
bounded by g > 0 bits, and if P is λc-dominated by P′ for some 0 < λc < ∞then the
following holds with probability larger than 1 −δ over the random choice of the target
concept (with respect to P), the sequence of examples, and the choices made by QBC:
• The number of calls to Sample that QBC makes is smaller than
eδ , 160(d + 1)
6, ln 80(d + 1)
• The number of calls to Label that QBC makes is smaller than
n0 = 10(d + 1)
In other words, it is an exponentially small fraction of the number of calls to Sample.
• The probability that the Gibbs prediction algorithm that uses the ﬁnal version space of
QBC makes a mistake in its prediction is smaller than ϵ.
Note that while the number of calls to Sample increases by about a factor of λ2
c, the number
of queries increases only by an additive term of about 2 log λc.
Sketch of proof: It is clear that the arguments given in the proofs of Lemmas 1 - 3 and
Theorem 1 hold if P is replaced by P′ throughout. This implies that, with high probability,
the error of a Gibbs prediction algorithm that uses the ﬁnal version space of QBC is smaller
than ϵ′, or
ED [Prc∼P′,h∼P′ [c(x) ̸= h(x)]] ≤ϵ′ .
The assumption that P is λc-dominated by P′ implies that
ED [Prc∼P,h∼P [c(x) ̸= h(x)]] ≤λ2
By increasing m0 by a factor of λ2
c we get that λ2
cϵ′ = ϵ, from which the statement of the
theorem follows.
Y. FREUND, H.S. SEUNG, E. SHAMIR AND N. TISHBY
Learning using unlabeled examples and membership queries
The QBC algorithm uses unlabeled examples in order to reduce the number of labeled
examples that it needs to know. While QBC is a very simple algorithm it is not the only
way of using the information provided by random unlabeled examples. In this section we
make the observation that in the learning framework deﬁned in this paper there is a general
scheme for query ﬁltering. This scheme is potentially more computationally intensive than
QBC, however, it is applicable in more generality than QBC.
The main observation is that the oracles Sample and Gibbs, deﬁned in Section 2 allow
the learning algorithm to estimate the expected error of any prediction rule. In this way the
algorithm can calculate the expected improvement of making any particular query.
The prediction rule used by QBC is to select a random consistent hypothesis h using
Gibbs, and then label the instance with h(x). In general, any prediction rule deﬁnes a
conditional distribution of the label given the instance. The error of a prediction rule for a
given instance x ∈X and concept c ∈C is the probability that the prediction assigns to the
incorrect label 1 −c(x). The expected error of the prediction rule is deﬁned by selecting x
at random according to D and a c at random according to P. The oracles Sample and Gibbs
generate random selections from D and P respectively. Thus, disregarding computational
complexity, we can approximate the expected error of any prediction rule using sufﬁciently
large samples of instances and hypotheses.
The dependence of the prediction rule generated by QBC on the labeled instances seen
in the past is deﬁned via the version space V . In general, any learning algorithm deﬁnes a
mapping from sets of labeled instances to prediction rules. The estimate of the error of a
prediction rule thus deﬁnes a measure of the quality of a set of labeled examples. If we are
given an unlabeled instance, we can estimate the distribution of the label of the instance
by using Gibbs. In this way we can estimate the expected reduction in the prediction error
that will result from knowing the correct label of any instance. A reasonable heuristic for
ﬁltering queries is to select those instances that cause the largest reduction in the prediction
error. If after observing any set of labeled instances the learning algorithm can ﬁnd an
instance which reduces the expected prediction error by a constant multiplicative factor,
then the prediction error decreases exponentially fast in the number of queries asked. Of
course, instances that cause such a reduction might not always exist, and even if they exist,
the problem of ﬁnding them efﬁciently is potentially hard.
The algorithm analyzed in this paper, QBC, is an efﬁcient variant of this heuristic. The
general heuristic described above makes a large number of calls to the oracles Sample and
Gibbs, algorithm QBC makes much fewer calls. More speciﬁcally, the dependence of the
number of calls to Sample on the desired error, ϵ is11 ˜O(1/ϵ), which is the same dependence
achieved by the algorithm that makes a query on each instance that it gets from Sample.
The algorithm makes twice as many calls to Gibbs as it makes to Sample. It is not clear
if this is close to optimal, however, it is certainly much smaller than the number of calls
that is suggested in the heuristic described above. The exponential decrease of the error
of QBC as a function of the number of queries has been established for a restricted family
of parameterized concept classes. Establishing the effectiveness of QBC for more general
SELECTIVE SAMPLING USING QUERY BY COMMITTEE
concept classes or proving that it will not be effective for general families of concept classes
is an interesting open problem.
While the general heuristic described in this section is not efﬁcient, it is applicable in
much more general situations than QBC. For example, the outcomes do not have to be
binary or even discrete, and the relation between them and the inputs can be stochastic
rather than deterministic. Finding learning algorithms that learn efﬁciently in this more
general frameworks is another interesting open problem.
We have proved that the Query by Committee algorithm is an efﬁcient query algorithm
for the perceptron concept class with distributions that are close to uniform. This gives
a rigorous proof to the results given in which were
obtained using the replica method of statistical mechanics. It also generalizes their results
by relaxing the requirements on the distribution of the examples and on the prior distribution.
In addition, we show that exact knowledge of the prior distribution is not required. It is
sufﬁcient if the ratio between the assumed prior and actual prior is bounded by a constant
We have proved that, in general, if the queries that are ﬁltered by the query by committee
algorithm have high expected information gain then the prediction error is guaranteed to
decrease rapidly with the number of queries.
By proving that this is the case for the
perceptron learning problem, we have achieved our main result.
We hope that lower bounds on the expected information gain of QBC can be proven for
other concept classes. It seems that it would be very useful, in this context, to generalize
Theorem 1 to allow cases in which the expected information gain is small to occur with
some small probability.
There are several issues that we do not discuss in this paper.
First, one would like
to know whether the results can be extended to concept classes other than perceptrons.
Second, it is of great practical importance to analyze more general scenarios. In the “noisy”
case, the learner sometimes observes a corrupted label, which is different from the correct
label associated with the instance. A related case is the “probabilistic” case, in which the
relationship between the instance and the label is described by a conditional distribution.
An even more general case is the “agnostic” scenario, in which the only assumption is that
there is some joint distribution over instances and labels from which examples are drawn
independently at random. Extending our analysis to any of these more general cases is
an an open problem which is important for making the analysis more relevant to practical
applications.
Though theoretical results for such models are lacking, there is empirical evidence that
extensions of the QBCalgorithm can be used to learn noisy and probabilistic models, such
as hidden Markov models . We believe that the more general
“agnostic” learning scenario and the noisy learning problem are related. It seems useful,
in this context, to extend the size of the committee and use more reﬁned deﬁnitions for
“disagreement” among the committee members.
Y. FREUND, H.S. SEUNG, E. SHAMIR AND N. TISHBY
In this work we have explored some of the power of algorithms for learning using queries
that have access to random unlabeled instances and can make membership queries. This
model of learning is natural in contexts where unlabeled instances are much cheaper than
labeled instances. An interesting theoretical open question is how much more powerful is
this model of learning from queries from the standard model for using membership queries
in statistical learning.
Acknowledgments
Part of this research was done at the Hebrew University of Jerusalem. Freund, Shamir and
Tishby would like to thank the US-Israel Binational Science Foundation (BSF) Grant no.
90-00189/2 for support of their work. We would also like to thank Yossi Azar, Shlomo
Halﬁn, and Manfred Opper for helpful discussions regarding this work.
Appendix A
Proofs of Lemmas 4-7
Proof of Lemma 4: Let us denote by St the convex body in Rd−1 that is deﬁned by the
slice of the convex body B at t. Clearly, f(t) is the volume of St.
We deﬁne the linear combination of two bodies, A and B as:
λ1A + λ2B = {λ1a + λ2b|a ∈A, b ∈B} ,
where λ1, λ2 ∈R. An immediate result of the convexity of B is that for any t1, t2 ∈R,
and any 0 ≤λ1, λ2 ≤1 such that λ1 + λ2 = 1
λ1St1 + λ2St2 ⊆Sλ1t1+λ2t2 .
Using the terminology of the theory of convex bodies, we can say that the set of bodies St,
parameterized by t ∈R is a (one-parameter) concave family of bodies.12
The Brunn-Minkowski theorem states that, for bodies in Rn, “the n-th root of the volume
of the bodies of a linear or concave family is a concave function of the family of parameters”
 ,Subsection 48). In our case, n = d −1 and the family is a
concave family of a single parameter. We thus get the statement of the lemma as a special
case of the Brunn Minkowski theorem.
Proof of Lemma 6: As the value of the functional G(F) is always positive, there must
exist an inﬁmum to the set of values it can achieve on the set of all convex bodies. We denote
this inﬁmum by µ and show that it is achieved as a minimum. In other words, that there
exists a volume function F∞which corresponds to a convex body such that G(F∞) = µ.
Let Bn be a sequence of convex bodies and Fn be the corresponding sequence of volume
functions such that limn→∞G(Fn) = µ. By Lemma 4, we may assume that the bodies Bn
SELECTIVE SAMPLING USING QUERY BY COMMITTEE
Table 1. Notation Table
sample space
sample distribution
{x1, x2, . . .}
unlabeled examples
drawn from X according to D
number of examples
number of queries (labeled examples)
{x1, . . . , xm}
ﬁrst m examples
concept class
target concept
{h ∈C|h(xi) = c(xi), i = 1 . . . n}
version space of ﬁrst n labeled examples
Bayesian prior distribution on C
hypothesis in C
−log PrP(Vm)
cumulative information gain
−p log p −(1 −p) log(1 −p)
binary entropy function
G(xi|Vi−1)
expected information gain from example xi
given version space Vi−1
fractional reduction in version space
{1, . . . , m}
{x1, . . . , xm}
ﬁrst m examples in X
{i1, i2, . . .}
sequence of indices of examples used as queries
{i1, . . . , in}
ﬁrst n elements of I
{xi1, xi2, . . .}
sequence of query examples
{xi1, . . . , xin}
ﬁrst n examples used as queries
lower bound on expected information gain
VC dimension
expected information gain functional
(1 −4x)/2)
variation in K
uniformity parameters of
prior and input distributions
divergence between correct and incorrect priors
Y. FREUND, H.S. SEUNG, E. SHAMIR AND N. TISHBY
are bodies of revolution, and that they correspond to concave radius functions rn(t). We
thus need to show that there exists a concave radius function r∞(t) which is the limit of
rn(t) for n →∞.
The functional G(F) is deﬁned in terms of integrals and the radius functions rn(t) are
continuous and bounded by a constant which depends only on the dimension d. Thus
if rn(t) converges to r∞(t) pointwise then the value of G on the sequence of bodies of
revolution corresponding to rn(t) converges to the value of G on the body corresponding
We prove the lemma by showing the existance of a subsequence of the radius functions
which have a pointwise limit. Using a diagonalization argument, we can pick a subsequence
of rn, indexed by m, such that rm(t) converges pointwise for each rational value of t. It is
easy to see that the limit function r∞(t), deﬁned on the rationals, is concave and continuous
there. We get a concave extension to all real values of t by taking the limit over the rationals:
r∞(t0) = lub(r(τ)|τ < t0, τ rational ) .
Clearly r∞(t) is also concave and continuous and is the pointwise limit of rn(t) for all
t. Thus r∞(t) is the radius function of a concave body B which assumes the minimum
Proof of Lemma 7: The radius function that corresponds to the two-cone body is
r∗(t) = cd max(0, 1 −|t|)
One can compute Gd(r∗) for any ﬁxed d by solving the integral in Equation (18) as follows.
In this case we ﬁnd it more convenient to use the integral over the negative half of the
line as deﬁned in Equation (19).
The volume function in the range −1 ≤t ≤0 is
−∞(r∗(s))d−1ds = (1 + t)d/2 and it is 0 for t < 0.
Plugging this into
Equation (19) we get
(1 −(1+t)d+1
)H( (1+t)d+1
(1 −(1+t)d+1
F 1/d(1 −F)H(F)dF
F 1/d(1 −F)dF
which can be shown by direct calculation to decrease as d →∞. Which gives the general
lower bound of
(1 −F)H(F)dF
18 log 2 .
This proves the statement of the lemma.
Proof of Lemma 5: We shall keep using the notation deﬁned in the proof of Theorem 2.
For each volume function F which does not come from a cone, we construct a variation
that decreases G(F).
SELECTIVE SAMPLING USING QUERY BY COMMITTEE
We describe the variations in terms of adding a variation function, ψ(t) to the radius
function r(t). As we are restricting ourselves to volume functions, it is enough to deﬁne
ψ(t) for 0 ≤t < ∞.
Let us enumerate the requirements on the radius variation function ψ(t), and on the
corresponding volume variation function
F(t) + Ψ(t) = cd−1
0(r(s) + ψ(s))d−1 ds.
We need F(|t|) + Ψ(|t|) to be a volume function. For this to hold we require that
r(t) + ψ(t) is a positive concave function that is nonzero only on a bounded segment
[0, c], c < ∞.
We need to guarantee that
∇G(t)Ψ(t) dt < 0. For that to hold we require that Ψ(t)
is non-positive for all 0 ≤t ≤w and non-negative for all t > w. Where w is the pivot
point for the volume function F. See equation 20 and the discussion following it.
For any given ϵ > 0 we should be able to ﬁnd a radius variation function ψ(t)
such that the change in the corresponding volume function is as small as is desired
Ψ(t)2 dt > 0.
We describe three families of variational functions. For any radius function r that corresponds to a volume function and is not equal to r∗= max(0, 1−|t|), one of these variations
applies, showing that there exists r′(t) such that Gd(r′) < Gd(r). The variations are constructed geometrically. Below is a list of the constructions that should be read alongside
Figure A.1. The basic idea in all three transformations is to “move” volume from place
to place along the projection direction, in such a way that for each point t in a particular
range, volume is moved only from one the right of the points to their left or vice versa. It is
easy to check that each of the conditions 1-3 holds for each of those transformations. In the
descriptions below we shall refer to volume changes are caused by increasing or decreasing
the radius function, note that these are changes in the d-dimensional volume of the revolution body whose volume function corresponds to the radius function, and not in the two
dimensional area described by the changes in the graph. The transformations thus depend
on the dimension of the actual body, however, the qualitative form of the transformation
remains the same for all dimensions. Each transformation takes a parameter λ, which is a
positive number that is set small enough so that condition 3 holds.
If r is not linear in the range 0 ≤t ≤w then transformation 1 is used (see Figure A.1(a)):
(A) Let A be the point (w, r(w)), select a point A′ on the curve deﬁned by r to the left
of A so that the volume decrease caused by changing the curve13 A ⌢A′ to the
chord A −A′ is equal λ/2.
(B) Let B be the point (0, r(0)), select a point B′ slightly above B and connect it to
the (unique) point X on the curve so that the curve B −X ⌢A′ −A is concave.
Choose B′ so that the volume increase caused by changing the curve B ⌢X to
the line B −X is λ/2.
Set λ0 small enough so that this construction is possible for all 0 < λ < λ0.
Y. FREUND, H.S. SEUNG, E. SHAMIR AND N. TISHBY
Transformation 1
Transformation 2
Transformation 3
Figure A.1. The variational transformations
SELECTIVE SAMPLING USING QUERY BY COMMITTEE
Note that for each point 0 ≤t ≤w, at least one of the two following conditions hold:
either volume is only removed from the right of t, or volume is only added to the left
of t. This implies that the volume function, F(t), increases in this range. Because the
amount of volumes that are removed and added are equal, F(t) does not change for t
outside the range [0, w]. This implies that condition 2 holds.
If r does not decrease linearly to zero for t ≥w then transformation 2 is used (see
Figure A.1(a)):
(A) Select A′′ on the curve to the right of A so the volume decrease that is caused by
changing A ⌢A′′ to A −A′′ is λ/2.
(B) Let C be the point at which the curve meets the horizontal axis. Select C′ slightly
to the right of C and connect it to the point Y on the curve so that the curve
C′ −Y ⌢A′′ −A is concave. Choose C′ so that the volume increase caused by
changing C′ −C −Y to C′ −Y is λ/2.
Set λ0 small enough so that this construction is possible for all 0 < λ < λ0.
An argument similar to the one used in transformation 1 holds in this case for t > w.
If neither condition 1 nor 2 holds, and the slopes of the two linear segments are not
equal (i.e. r ̸= r∗), then transformation 3 is used (see Figure A.1(b)):
(A) A point A′ slightly below A is chosen.
(B) A point B′ slightly above B is chosen so that there is no net change in the volume
when changing A −B to A′ −B′.
(C) A point C′ slightly to the right of C is chosen so that there is no net change in the
volume when changing A −C to A′ −C′.
(D) The movement from A to A′ is chosen do that the change in the volume caused
by each of the four changes in r: B −X to B′ −X, A −X to A −X′, A −Y to
A′ −Y and C −Y to C′ −Y is equal to λ/4
In this case the volume function is changed on both sides of the pivot point. Arguments
similar to the one used in transformation 1 shows that condition 2 is met.
Theonlyradiusfunctionstowhichnoneofthosetransformationsapplyisr∗, thusﬁnishing
the proof of the lemma.
Appendix B
Proof of Theorem 3
We ﬁrst prove the dependence on the uniformity of the input distribution, as measured by
λD. In general, any distribution D that is within λD of the uniform distribution µ can be
Y. FREUND, H.S. SEUNG, E. SHAMIR AND N. TISHBY
written as weighted sum of the form λDµ + (1 −λD)ν where ν is some other distribution. Fix the version space and any prior distribution, let the distribution of examples be
D = λDµ + (1 −λD)ν and let gµ, gν be the expected information gains when the examples
are generated according to µ or ν respectively. As gν > 0 we get that the expected information gain when D is within λD of uniform is at least λD times the expected information
gain when D is uniform.
The analysis of the dependence on λP is more involved. We go back to the analysis of
an arbitrary projection of a convex body from the proof of Theorem 2. The main idea there
was to show transformations that increase or decrease the volume function in particular
ranges, in a way that decreased the expected information gain. There, the transformation
involved changing the shape of the body. Here we present a transformation that changes
the density of the prior distribution inside the version space.
We ﬁx a convex body and a direction ⃗x along which this body is projected. We denote
by ρ(t) the average density along the slice of body which is deﬁned by the example (⃗x, t).
The relation between the volume function F, and the radius function r is now
(r(s))d−1ρ(s)ds .
We search for a density distribution of the points in the body, which is within λP of
the uniform distribution, and minimizes the expected information gain from (uniformly
distributed) examples whose direction is ⃗x. Note that the symmetrization argument used in
the proof of Theorem 2 holds for this case too, and we can thus restrict ourselves to functions
r and ρ that are deﬁned only over the positive reals. From the variational derivative of F(t)
for t ≥0 that we computed in Equation (20), we know that G(F) decreases if F(t) is
increased for some t ≤w or if F(t) is decreased for some 0 ≤t ≤w. As we allow
deviations from the uniform prior distribution we can change F without changing the form
of the convex body. We shall now give a variation of ρ that changes ρ(t) in the range
0 ≤t ≤w in a way that decreases G(F). As this variation can be applied to any ρ that
does not have a speciﬁc step-like form in this range, we get that this step-like form of ρ
achieves the minimal value of G(F) for this ﬁxed body and P that is within λP of uniform.
A similar argument can be used to show that ρ(t) must also have a stepwise form in the
range w ≤t.
Assume that there exist 0 < t1 < t2 < w and ϵ, δ > 0 such that 0 ≤t1 −ϵ < t1 + ϵ ≤
t2 −ϵ < t2 + ϵ < w , and such that for all t ∈[t1 −ϵ, t1 + ϵ], ρ(t) < 1/λP −δ, and for
all t ∈[t2 −ϵ, t2 + ϵ], ρ(t) > λP + δ. We add to ρ(t) the following variation function:
t1 −ϵ ≤t ≤t1 + ϵ ,
t2 −ϵ ≤t ≤t2 + ϵ ,
where δ1, δ2 are chosen so that δ ≥δ1, δ2 > 0 and
t1−ϵ (r(s))d−1ds
t2−ϵ (r(s))d−1ds
SELECTIVE SAMPLING USING QUERY BY COMMITTEE
This insures that the volume function does not change outside the range [t1 −ϵ, t2 + ϵ].
It is easy to check that ρ(t) + ψ(t) corresponds to a density distribution that is within
λP of the uniform distribution. Changing the density distribution from ρ(t) to ρ(t) + ψ(t)
decreases F(t) in the range [t1 −ϵ, t2 + ϵ] and does not change F(t) anywhere else. Thus
this change decreases G(F). It is also easy to check that this variation cannot be applied to
ρ if and only if there exists 0 ≤a ≤w such that ρ(t) = 1/λP for 0 ≤t < a and ρ(t) = λP
for a < t ≤w. From this argument and a similar argument for the range t ≥w we get that
the density function that minimizes G(F) must be of the form
0 ≤t ≤a or b ≤t ,
where 0 ≤a ≤w ≤b. We do not have a simple variational argument for determining the
exact value of a and b, however, as we shall see, we can lower bound the information gain
without this explicit knowledge.
We have thus found the form of the density function that minimizes the information gain
for a speciﬁc body (and a speciﬁc projections). Suppose now that we ﬁx the function ρ and
vary the shape of the body, i.e. the radius function r. Going through the construction of the
variational functions ψ in the proof of Theorem 2, we see that the same construction steps
hold verbatim, although special attention needs to meaning of the expression “the volume
decrease is equal to x” as the volume is now deﬁned in terms of the non uniform distribution
speciﬁed by ρ.
The combination of these two arguments shows that the smallest value of G(F) is attained
for the radius function r∗speciﬁed in Equation (A.1), and the average density function ρ∗.
It remains to compute a lower bound on G(F) based on these two facts. This is done by
bounding the ratio between the values of G(F) for the uniform prior and the non uniform
prior cases.
We change the integration variable in Equation (19) from x to F(x):
F(1 −F) H(F) dx
F(1 −F) dx
When written in this form, the dependence of G(F) on the r and ρ enters the equation
through the derivative dx/dF. By bounding the ratio between the values that this derivative
attains in the uniform and the non-uniform cases, we can bound the ratio between the values
that G(F) attains for the uniform and the non-uniform prior distributions.
The volume function that corresponds to the uniform prior distribution is, for −1 ≤x ≤0,
Funif(x) = (1+x)d/2. The volume function that corresponds to the prior distribution deﬁned
Fnon-unif(x) = 1
P (1 + x)d,
−1 ≤x ≤−b,
λP(1 + x)d + c,
−b ≤x ≤−a,
P (1 + x)d + 1 −λ−1
Where c ≥0 is deﬁned by matching the two deﬁnitions of F(−b).
Y. FREUND, H.S. SEUNG, E. SHAMIR AND N. TISHBY
Taking the derivatives of Funif and Fnon-unif we get the following equation for their ratio:
0 ≤F ≤F(−b),
F(−b) ≤F ≤F(−a),
F(−a) ≤F ≤1/2
Using the facts that λP ≤1, c ≥0, and d ≥2 we can bound the ratio of the derivatives
for each of the three cases. For the range −1 ≤x ≤−b we get that
For the range −b ≤x ≤−a we get, using the fact that F is monotone non-decreasing, that
2F(−a) −c ≤
2F(x) −c ≤
2F(−b) −c = λ−1
λP(1 −b)d ≤λ−2
which implies that in the range −b ≤x ≤−a,
1 ≤λ−1/d ≤
Finally, for the range −a ≤x ≤0, we get that
P ≤λP(1 −a)d + c
2F(−a) + λ−1
which implies that
Combining the bounds from Equations (B.5), (B.6), and (B.7), and plugging them into
Equation (B.4), we get that
Using this bound and Equation (B.2) we get that G(Fnon-unif) ≥λ4
PG(Funif). This completes
the proof of the theorem.
SELECTIVE SAMPLING USING QUERY BY COMMITTEE
1. Here, and elsewhere in the paper, log(·), denotes the logarithm over base two, while ln(·) denotes the logarithm
over base e.
2. Our analysis can be extended to larger committees, but the improvement in the performance is minor.
3. For example, consider the case in which the version space contains two disconnected sets in R2, which are
very far from each other, and assume that a random example is very likely to separate these two sets. Suppose
one of the sets has probability ϵ, while the other has probability 1 −ϵ. While most of the examples that
separate the two sets are rejected, the fraction that is accepted can still dominate all other examples. Thus the
expected information gain is close to H(ϵ). As ϵ can be set arbitrarily small, the expected information gain
can be arbitrarily close to zero. It seems that this type of version space can occur only very rarely but we do
not know what are the necessary conditions.
4. Note that the number of calls to Sample is Ω(d/ϵ) ), even if all of the instances are used
as queries to Label.
The bound as it appears in is given for martingales. However, it is easily checked that it is
also true for super-martingales. Reversing the sign of the Yi we get an equivalent theorem for sub-martingales.
6. Actually, it is enough to assume that the distribution of the offset t is uniform for any direction⃗x. No assumption
needs to be made regarding the distribution of ⃗x.
The perceptron concept class is deﬁned as the following set of binary functions over the unit sphere
c ⃗w,t(⃗x)
⃗x · ⃗w ≥t
otherwise .
8. In the following discussion we ignore the distinction between the concepts in C and their parameterization,
and refer to the concept c ⃗w simply as the vector ⃗w.
9. Details on how the Fr´echet derivative is deﬁned and calculated can be found in standard books on variational
analysis, such as .
10. This deﬁnition is a one-sided version of the notion of λ-closeness deﬁned in Deﬁnition 6.2.
11. Ignoring log factors.
12. For the deﬁnition of a convex family of bodies see ,Subsection 24).
13. We use A −B to denote the line segment between the points A and B, and A ⌢B to denote the segment of
a curve that connects A and B. We also use the shorthand A −B ⌢C −D to denote a the concatenation
of a line segment, a curve segment, and another line segment.