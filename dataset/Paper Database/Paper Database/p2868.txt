Mach Learn 68: 267–276
DOI 10.1007/s10994-007-5018-6
TECHNICAL NOTE
A note on Platt’s probabilistic outputs for support vector
Hsuan-Tien Lin · Chih-Jen Lin · Ruby C. Weng
Received: 17 February 2006 / Revised: 7 May 2007 / Accepted: 25 June 2007 /
Published online: 8 August 2007
Springer Science+Business Media, LLC 2007
Abstract Platt’s probabilistic outputs for Support Vector Machines (Platt, J. in Smola, A.,
et al. (eds.) Advances in large margin classiﬁers. Cambridge, 2000) has been popular for
applications that require posterior class probabilities. In this note, we propose an improved
algorithm that theoretically converges and avoids numerical difﬁculties. A simple and readyto-use pseudo code is included.
Keywords Support vector machine · Posterior probability
1 Introduction
Given training examples xi ∈Rn,i = 1,...,l, labeled by yi ∈{+1,−1}, the binary Support
Vector Machine (SVM) computes a decision function f(x) such that sign(f(x)) can be used
to predict the label of any test example x.
Instead of predicting the label, many applications require a posterior class probability
Pr(y = 1|x). Platt proposes approximating the posterior by a sigmoid function
Pr(y = 1|x) ≈PA,B(f ) ≡
1 + exp(Af + B),
where f = f(x).
Let each fi be an estimate of f(xi). The best parameter setting z∗= (A∗,B∗) is determined
by solving the following regularized maximum likelihood problem (with N+ of the yi’s
Editor: Dale Schuurmans.
H.-T. Lin () · C.-J. Lin
Department of Computer Science and Information Engineering, National Taiwan University,
Taipei 106, Taiwan
e-mail: 
e-mail: 
Department of Statistics, National Chengchi University, Taipei 116, Taiwan
e-mail: 
Mach Learn 68: 267–276
positive, and N−negative):
z=(A,B)F(z) = −
ti log(pi) + (1 −ti)log(1 −pi)
for pi = PA,B(fi), and ti =
if yi = +1
if yi = −1
, i = 1,...,l.
Platt gives a pseudo code for solving (2). In this note, we show how the pseudo
code could be improved. We analyze (2) in Sect. 2, and propose a more robust algorithm to
solve it. Better implementation that avoids numerical difﬁculties is then discussed in Sect. 3.
We compare our algorithm with Platt’s in Sect. 4. Finally, a ready-to-use pseudo code is in
Appendix 3.
2 Choice of optimization algorithm
We ﬁrst introduce the simple optimization algorithm used in Platt’s pseudo code . Then, after proving that (2) is a convex optimization problem, we propose a more
robust algorithm that enjoys similar simplicity, and theoretically converges.
2.1 Platt’s approach: Levenberg–Marquardt method
Platt uses a Levenberg–Marquardt (LM) algorithm from Press et al. to
solve (2). The LM method was originally designed for solving nonlinear least-square problems. As an iterative procedure, at the k-th step, this method solves
( ˜Hk + λkI)δk = −∇F(zk)
to obtain a direction δk, and moves the solution from zk to zk+1 = zk +δk if the function value
is sufﬁciently decreased. Here, ˜Hk is a special approximation of the Hessian of the leastsquare problem, I is the identity matrix, and {zk}∞
k=0 is the sequence of iteration vectors.
When λk is large, δk is close to the negative gradient direction. On the contrary, a small λk
leads δk to be more like a Newton’s direction.
In the pseudo code, Platt adapts the following rule for updating λk (Press et al.
If F(zk + δk) < F(zk) then λk+1 ←0.1 · λk ; Else λk+1 ←10 · λk.
That is, if the new solution decreases the function value, λk is reduced, and in the next
iteration a more aggressive direction like Newton’s is tried. Otherwise, δk is unacceptable so
we increase λk to obtain a shorter vector which, more likely being a descent direction, may
lower the function value.
Unfortunately, such an implementation may not converge to the minimum solution of (2).
To the best of our knowledge, existing convergence proofs all require more
complicated or more robust rules for updating λk.
In fact, since (2) is not exactly a least-squares problem, the implementation of
Platt aims for general unconstrained optimization. It is known 
that for unconstrained optimization we should avoid directly dealing with λk. Instead, the
update of λk can be replaced by a trust-region concept, where the size of δk is controlled.
Mach Learn 68: 267–276
Thus, currently the optimization community uses trust-region methods for unconstrained
optimization and the LM method is considered as its “progenitor” has one advantage: simplicity. However, the
above discussion shows that it may not be the best choice for solving (2). Next, we propose
an algorithm that is also simple, but enjoys better convergence properties.
2.2 Our approach: Newton’s method with backtracking
As indicated by Platt , any method for unconstrained optimization can be used for
solving (2). Before we choose a suitable method, we analyze the optimization problem in
more detail. First, the gradient ∇F(z) and the Hessian matrix H(z) = ∇2F(z) are computed:
i=1 fi(ti −pi)
i=1(ti −pi)
i pi(1 −pi)
i=1 fipi(1 −pi)
i=1 fipi(1 −pi)
i=1 pi(1 −pi)
Some analysis of this Hessian matrix is in the following theorem:
Theorem 1 The Hessian matrix H(z) is positive semi-deﬁnite. In addition, H(z) is positive
deﬁnite if and only if min1≤i≤l fi ̸= max1≤i≤l fi.
The proof is in Appendix 1. Therefore, problem (2) is convex (and in general strictly
convex). With such a nice property, we decide to use a simple Newton’s method with backtracking line search . Though the trust-region type method mentioned in the end of Sect. 2.1 may
be more robust, the implementation is more complicated. For this two-variable optimization
problem, simplicity is important, and hence trust-region methods are less favorable.
Algorithm 1 Newton’s method with backtracking line search
Our proposed algorithm is in Algorithm 1. As Hk = H(zk) may be singular, a small
positive diagonal matrix is added to the Hessian. With
∇F(zk)T δk = −∇F(zk)T (Hk + σI)−1∇F(zk) < 0,
the step size αk can be backtracked until the sufﬁcient decrease condition (3) is satisﬁed.
Mach Learn 68: 267–276
If H(z) is positive deﬁnite for all z, the convergence of Algorithm 1 can be established
from, for example, Theorem 10.2 by Nash and Sofer . A simpliﬁed statement is shown
in Theorem 2.
Theorem 2 (Convergence of Algorithm 1 for general F(z))
If F(z) is twice continuously differentiable, H(z) is positive deﬁnite for all z, and F(z)
attains an optimal solution at z∗, then limk→∞zk = z∗.
From Theorem 1, in some rare situations, H(z) is positive semi-deﬁnite but not positive
deﬁnite. Then, Theorem 2 cannot be directly applied. In Appendix 2, we show that if σ > 0,
Algorithm 1 still converges to an optimal solution. Therefore, we get the following theorem:
Theorem 3 (Convergence of Algorithm 1 for (2))
If Algorithm 1 is applied to (2) such that H(z) + σI is always positive deﬁnite, then
limk→∞zk exists and is a global optimal solution.
3 Numerical implementation
Next, we study the numerical difﬁculties that arise when solving (2) using Platt’s pseudo
code. Then, we show our implementation that avoids the difﬁculties.
3.1 Platt’s implementation
Platt uses the following pseudo code to calculate the objective value of (2) for a new
pair of (A,B):
for i = 1 to len {
p = 1/(1+exp(deci[i]*A+B))
// At this step, make sure log(0) returns -200
err -= t*log(p)+(1-t)*log(1-p)
Here, len is l, the number of examples used, and err is the objective value. In addition,
deci[i] is fi, and hence p stores the calculated pi. However, t was lastly assigned to tl
before this loop, and the calculation does not use all ti,i = 1,...,l. Therefore, this pseudo
code does not correctly calculate the objective value of (2).
Furthermore, the above code assumes that log(0) returns −200, which reveals possible
numerical difﬁculties:
1. log and exp could easily cause an overﬂow. If Afi + B is large, exp(Afi + B) →∞. In
addition, when pi is near zero, log(pi) →−∞. Although these problems do not always
happen, considering log(0) to be −200 is not a good solution.
2. 1 −pi = 1 −
1+exp(Afi+B) is a “catastrophic cancellation” when pi is
close to one. That is, when subtracting two nearby numbers that are already results of
ﬂoating-point operations, the relative error can be so large that most digits are meaningless. For example, if fi = 1, and (A,B) = (−64,0), in a simple C++ program with
double precision, 1 −pi returns zero but its equivalent form
exp(Afi+B)
1+exp(Afi+B) gives a more
accurate result. This catastrophic cancellation actually introduces most of the log(0) occurrences.
Almost all algorithms that solve (2) need to face these issues. Next, we will discuss some
techniques to resolve them.
Mach Learn 68: 267–276
3.2 Our implementation
A problem of catastrophic cancellation can usually be resolved by reformulation:
ti logpi + (1 −ti)log(1 −pi)
= (ti −1)(Afi + B) + log
1 + exp(Afi + B)
= ti(Afi + B) + log
1 + exp(−Afi −B)
With (5) or (6), 1 −pi does not appear. Moreover, log(0) never happens.1
Note, however, that even if (5) or (6) is used, the overﬂow problem may still occur. The
problem is not serious if the IEEE ﬂoating-point standard is supported : an
overﬂow leads to a special number INF, which can still be used in further operations. For
example, if a large αk in Line 3 of Algorithm 1 makes the exp operation of (5) to overﬂow
for some Afi + B, the new objective value would also be evaluated as INF. Then, under the
IEEE standard, INF is bigger than the current F(zk), and hence αk is reduced to a smaller
value, with which Afi + B may not cause an overﬂow again.
Furthermore, regardless of whether the IEEE standard is supported, we can replace an
overﬂow operation with an underﬂow one, a rule-of-thumb which has been frequently used
in numerical computation. In general, an underﬂow is much less disastrous than an overﬂow.
Therefore, we propose implementing (4) with the rule:
If Afi + B ≥0 then use (6); Else use (5).
In addition, we can evaluate (1) by a similar trick:
If Af + B ≥0 then use
exp(−Af −B)
1 + exp(−Af −B) ; Else use (1).
The trick can be used in calculating ∇F(z) and H(z) as well: The term 1 −pi in H(z)
can also cause a catastrophic cancellation. An easy solution is to replace 1 −pi with the
If Afi + B ≥0 then use
1 + exp(−Afi −B) ; Else use
exp(Afi + B)
1 + exp(Afi + B).
4 Experiment
We implemented Platt’s pseudo code , ﬁxed the bug that was discussed in the
beginning of Sect. 3.1, and compared it to our proposed algorithm. For fairness, both algorithms were realized in python, and were set with a stopping condition ∥∇F(zk)∥∞< 10−5.
For the value of σ in Algorithm 1, we considered two approaches:
– ﬁxed: use a small ﬁxed σ = 10−12.
– dynamic: apply Theorem 1 to check whether H(z) is positive deﬁnite, and set σ = 0
instead if the condition is true.
We compared the algorithms on two UCI data sets, sonar and shuttle . Only classes 2 and 4 were taken from shuttle to form a binary problem. The values fi
1As pointed out by a reviewer, in many popular languages, log(1+...) can be replaced by log1p(...)
to compute the result more accurately when the operand exp(Afi + B) or exp(−Afi −B) is close to zero.
Mach Learn 68: 267–276
Table 1 Average results of different algorithms for solving (2) on sonar
# iterations
# backtracking
steps per iteration
ours, ﬁxed
ours, dynamic
Table 2 Average results of different algorithms for solving (2) on shuttle
# iterations
# backtracking
steps per iteration
ours, ﬁxed
ours, dynamic
were generated with the scaled data sets by LIBSVM using the RBF kernel . The soft-margin parameter log2 C was varied in −5, −3,...,15, and the kernel
parameter log2 γ was varied in −15, −13,...,3. That is, 110 different problems (2) were
tested for each data set.
Tables 1 and 2 list the average results for each data set. We ﬁrst compared each algorithm
based on the number of overﬂow errors encountered, the number of iterations, and the ﬁnal
objective value F(z). While Platt’s algorithm did reasonably well on sonar, it encountered
numerous overﬂow errors on shuttle, needed more iterations, and sometimes could not return
a solution with decent F(z). On the other hand, our proposed algorithm worked well on both
data sets.
The number of backtracking steps per iteration was also listed for the two approaches of
setting σ. We can see that the ﬁxed approach needed less backtracking steps per iteration on
shuttle. The beneﬁt came from the regularization on some nearly singular H(z). In addition,
the ﬁxed approach is simpler to implement in practice, and hence shall be preferred.
Finally, a simple and robust code is in Appendix 3. It has been integrated into LIBSVM
since version 2.6 . Source code in several popular languages can be
downloaded at 
Acknowledgements
We thank John Platt, S. Sathiya Keerthi, and the anonymous reviewers for helpful
Appendix 1 Proof of Theorem 1
Since the deﬁnition of pi in (1) implies that 0 < pi < 1, we can deﬁne vectors u and v with
√pi(1 −pi), and vi = √pi(1 −pi), respectively. Then
Mach Learn 68: 267–276
By Cauchy inequality,
det(H(z)) =
Since the two diagonal terms and the determinant are all nonnegative, the matrix H(z) is
positive semi-deﬁnite.
From (7), det(H(z)) = 0 if and only if u and v are parallel vectors. Since ui = fivi and
vi > 0, this situation happens if and only if all fi’s are equal. That is, the matrix H(z) is
positive deﬁnite if and only if min1≤i≤l fi ̸= max1≤i≤l fi.
Appendix 2 Proof of Theorem 3
Case 1: H(z) is always positive deﬁnite. If one can prove that
S = {(A,B):F(A,B) ≤F(A0,B0)}
is bounded, then F(A,B) attains an optimal solution within S and Theorem 2 can be applied
to show the convergence.
From Theorem 1, assume without loss of generality that f1 ̸= f2. Let
is invertible, it sufﬁces to show that ˆS = {ˆa:(A,B) ∈S} is bounded. If not, there exists an
inﬁnite sequence {ˆak}∞
k=1 in ˆS such that
k→∞max(|(ˆak)1|,|(ˆak)2|) = ∞.
Then, without loss of generality, there exists an inﬁnite subsequence K such that
limk→∞,k∈K |(ak)1| = ∞. However, since F(Ak,Bk) is the summation of positive terms,
F(Ak,Bk) ≥−t1 log
1 + e(ˆak)1 −(1 −t1)log
1 + e(ˆak)1 .
The right-hand-side above goes to ∞as |(ˆak)1| →∞. Therefore, there exists some k such
that F(Ak,Bk) > F(A0,B0), which somehow contradicts ˆak ∈ˆS. Thus, ˆS is bounded and
the proof is complete.
Case 2: When H(z) is only positive semi-deﬁnite for some z, from Theorem 1, all fi’s
are equal. By considering fi = f for all i, we can deﬁne a = Af + B and a single-variable
function ¯F(a) = F(A,B). Then
¯F ′′(a) =
(1 + ea)2 .
Mach Learn 68: 267–276
By simplifying (3), in Algorithm 1, (H(z) + σI)δ = −∇F(z) is
If σ > 0, the solution δ satisﬁes (δ)1 = f · (δ)2. Then, the ﬁrst (and the second) equation of
the linear system (9) is the same as
¯F ′′(a) +
(f · (δ)1 + (δ)2) = −¯F ′(a).
Interestingly, if we apply Algorithm 1 to minimize ¯F(a) with
f 2+1 added to its Hessian
¯F ′′(a), (10) is exactly the linear system to be solved. Therefore, if a0 = A0f + B0, then for
ak+1 = ak + αk(f · (δk)1 + (δk)2)
= (Ak + αk(δk)1)f + (Bk + αk(δk)2).
Since ¯F(a) is strictly convex from ¯F ′′(a) > 0, similar techniques in Case 1 can be used
to prove that ¯F(a) attains an optimal solution. Therefore, from Theorem 2, the sequence
k=0 globally converges. Then, from (δk)1 = f · (δk)2 and (11),
k→∞ak = (A0f + B0) + (f 2 + 1)
exists. Therefore, limk→∞Bk = B0 + ∞
k=0 αk(δk)2 exists, and so does limk→∞Ak. In addition, they form an optimal solution of minimizing F(A,B).
Appendix 3 Pseudo code of Algorithm 1
We recommend using double precision for the algorithm.
Input parameters:
deci = array of SVM decision values
label = array of booleans: is the example labeled +1?
prior1 = number of positive examples
prior0 = number of negative examples
A, B = parameters of sigmoid
//Parameter setting
maxiter=100
//Maximum number of iterations
minstep=1e-10
//Minimum step taken in line search
sigma=1e-12
//Set to any value > 0
//Construct initial values: target support in array t,
initial function value in fval
hiTarget=(prior1+1.0)/(prior1+2.0), loTarget=1/(prior0+2.0)
len=prior1+prior0 // Total number of data
Mach Learn 68: 267–276
for i = 1 to len {
if (label[i] > 0)
t[i]=hiTarget
t[i]=loTarget
A=0.0, B=log((prior0+1.0)/(prior1+1.0)), fval=0.0
for i = 1 to len {
fApB=deci[i]*A+B
if (fApB >= 0)
fval += t[i]*fApB+log(1+exp(-fApB))
fval += (t[i]-1)*fApB+log(1+exp(fApB))
for it = 1 to maxiter {
//Update Gradient and Hessian (use H’ = H + sigma I)
h11=h22=sigma, h21=g1=g2=0.0
for i = 1 to len {
fApB=deci[i]*A+B
if (fApB >= 0)
p=exp(-fApB)/(1.0+exp(-fApB)), q=1.0/(1.0+exp(-fApB))
p=1.0/(1.0+exp(fApB)), q=exp(fApB)/(1.0+exp(fApB))
h11 += deci[i]*deci[i]*d2, h22 += d2, h21 += deci[i]*d2
g1 += deci[i]*d1, g2 += d1
if (abs(g1)<1e-5 && abs(g2)<1e-5) //Stopping criteria
//Compute modified Newton directions
det=h11*h22-h21*h21
dA=-(h22*g1-h21*g2)/det, dB=-(-h21*g1+h11*g2)/det
gd=g1*dA+g2*dB
stepsize=1
while (stepsize >= minstep){ //Line search
newA=A+stepsize*dA, newB=B+stepsize*dB, newf=0.0
for i = 1 to len {
fApB=deci[i]*newA+newB
if (fApB >= 0)
newf += t[i]*fApB+log(1+exp(-fApB))
newf += (t[i]-1)*fApB+log(1+exp(fApB))
if (newf<fval+0.0001*stepsize*gd){
A=newA, B=newB, fval=newf
break //Sufficient decrease satisfied
Mach Learn 68: 267–276
stepsize /= 2.0
if (stepsize < minstep){
print ’Line search fails’
if (it >= maxiter)
print ’Reaching maximum iterations’
return [A,B]