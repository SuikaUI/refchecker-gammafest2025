Deep Learning on Trafﬁc Prediction: Methods,
Analysis and Future Directions
Xueyan Yin, Genze Wu, Jinze Wei, Yanming Shen, Heng Qi, and Baocai Yin
Abstract—Trafﬁc prediction plays an essential role in intelligent transportation system. Accurate trafﬁc prediction can assist
route planing, guide vehicle dispatching, and mitigate trafﬁc
congestion. This problem is challenging due to the complicated
and dynamic spatio-temporal dependencies between different
regions in the road network. Recently, a signiﬁcant amount of
research efforts have been devoted to this area, especially deep
learning method, greatly advancing trafﬁc prediction abilities.
The purpose of this paper is to provide a comprehensive survey
on deep learning-based approaches in trafﬁc prediction from
multiple perspectives. Speciﬁcally, we ﬁrst summarize the existing
trafﬁc prediction methods, and give a taxonomy. Second, we
list the state-of-the-art approaches in different trafﬁc prediction
applications. Third, we comprehensively collect and organize
widely used public datasets in the existing literature to facilitate
other researchers. Furthermore, we give an evaluation and
analysis by conducting extensive experiments to compare the
performance of different methods on a real-world public dataset.
Finally, we discuss open challenges in this ﬁeld.
Index Terms—Trafﬁc Prediction, Deep Learning, Spatial-
Temporal Dependency Modeling.
I. INTRODUCTION
HE modern city is gradually developing into a smart city.
The acceleration of urbanization and the rapid growth
of urban population bring great pressure to urban trafﬁc
management. Intelligent Transportation System (ITS) is an
indispensable part of smart city, and trafﬁc prediction is an
important component of ITS. Accurate trafﬁc prediction is
essential to many real-world applications. For example, trafﬁc
ﬂow prediction can help city alleviate congestion; car-hailing
demand prediction can prompt car-sharing companies preallocate cars to high demand regions. The growing available
trafﬁc related datasets provide us potential new perspectives
to explore this problem.
Challenges Trafﬁc prediction is very challenging, mainly
affected by the following complex factors:
(1) Because trafﬁc data is spatio-temporal, it is constantly
changing with time and space, and has complex and dynamic
spatio-temporal dependencies.
Xueyan Yin, Genze Wu, Jinze Wei, and Heng Qi are with the School
of Electronic Information and Electrical Engineering, Dalian University of
Technology, Dalian 116024, China.
Yanming Shen is with the School of Electronic Information and Electrical
Engineering, Dalian University of Technology, Dalian 116024, China, and also
with the Key Laboratory of Intelligent Control and Optimization for Industrial
Equipment, Ministry of Education, Dalian University of Technology, Dalian
116024, China (e-mail: ).
Baocai Yin is with the School of Electronic Information and Electrical
Engineering, Dalian University of Technology, Dalian 116024, China, and
also with the Peng Cheng Laboratory, Shenzhen 518055, China.
• Complex spatial dependencies. Fig.1 demonstrates that
the inﬂuence of different positions on the predicted position is different, and the inﬂuence of the same position
on the predicted position is also varying with time. The
spatial correlation between different positions is highly
• Dynamic temporal dependencies. The observed values
at different times of the same position show non-linear
changes, and the trafﬁc state of the far time step sometimes has greater inﬂuence on the predicted time step
than that of the recent time step, as shown in Fig.1. Meanwhile, pointed out that trafﬁc data usually presents periodicity, such as closeness, period and trend. Therefore,
how to select the most relevant historical observations for
prediction remains a challenging problem.
Fig. 1. Complex spatio-temporal correlations. The nodes represent different
locations in the road network, and the blue star node represents the predicted
target. The darker the color, the greater the spatial correlation with the target
node. The dotted line shows the temporal correlation between different time
(2) External factors. Trafﬁc spatio-temporal sequence data is
also inﬂuenced by some external factors, such as weather
conditions, events or road attributes.
Since trafﬁc data shows strong dynamic correlation in both
spatial and temporal dimensions, it is an important research
topic to mine the non-linear and complicated spatial-temporal
patterns, making accurate trafﬁc predictions. Trafﬁc prediction
involves various application tasks. Here, we list the main
application tasks of the existing trafﬁc prediction work, which
are as follows:
Trafﬁc ﬂow refers to the number of vehicles passing
through a given point on the roadway in a certain period
 
The actual speed of vehicles is deﬁned as the distance
it travels per unit of time. Most of the time, due to
factors such as geographical location, trafﬁc conditions,
driving time, environment and personal circumstances of
the driver, each vehicle on the roadway will have a speed
that is somewhat different from those around it.
The problem is how to use historical requesting data to
predict the number of requests for a region in a future
time step, where the number of start/pick-up or end/dropoff is used as a representation of the demand in a region
at a given time.
• Travel time
In the case of obtaining the route of any two points in
the road network, estimating the travel time is required.
In general, the travel time should include the waiting time
at the intersection.
• Occupancy
The occupancy rate explains the extent to which vehicles
occupy road space, and is an important indicator to
measure whether roads are fully utilized.
Related surveys on trafﬁc prediction There are a few
recent surveys that have reviewed the literatures on trafﬁc
prediction in certain contexts from different perspectives. 
reviewed the methods and applications from 2004 to 2013,
and discussed ten challenges that were signiﬁcant at the time.
It is more focused on considering short-term trafﬁc prediction
and the literatures involved are mainly based on the traditional
methods. Another work also paid attention to short-term
trafﬁc prediction, which brieﬂy introduced the techniques
used in trafﬁc prediction and gave some research suggestions.
 provided sources of trafﬁc data acquisition, and mainly
focused on traditional machine learning methods. outlined
the signiﬁcance and research directions of trafﬁc prediction.
 and summarized relevant models based on classical
methods and some early deep learning methods. Alexander et
al. presented a survey of deep neural network for trafﬁc
prediction. It discussed three common deep neural architectures, including convolutional neural network, recurrent neural
network, and feedforward neural network. However, some
recent advancements, e.g., graph-based deep learning, were not
covered in . is an overview of graph-based deep learning
architecture, with applications in the general trafﬁc domain.
 provided a survey focusing speciﬁcally on the use of deep
learning models for analyzing trafﬁc data. However, it only
investigates the trafﬁc ﬂow prediction. In general, different
trafﬁc prediction tasks have common characteristics, and it
is beneﬁcial to consider them jointly. Therefore, there is still
a lack of broad and systematic survey on exploring trafﬁc
prediction in general.
Our contributions To our knowledge, this is the ﬁrst
comprehensive survey on deep learning-based works in trafﬁc
prediction from multiple perspectives, including approaches,
applications, datasets, experiments, analysis and future directions. Speciﬁcally, the contributions of this survey can be
summarized as follows:
• We ﬁrst do a taxonomy for existing approaches, describing their key design choices.
• We collect and summarize available trafﬁc prediction
datasets, which provide a useful pointer for other researches.
• We perform a comparative experimental study to evaluate
different models, identifying the most effective component.
• We further discuss possible limitations of current solutions, and list promising future research directions.
A Taxonomy of Existing Approaches After years of
efforts, the research on trafﬁc prediction has achieved great
progresses. In light of the development process, these methods
can be broadly divided into two categories: classical methods
and deep learning-based methods. Classical methods include
statistical methods and traditional machine learning methods.
The statistical method is to build a data-driven statistical
model for prediction. The most representative algorithms are
Historical Average (HA), Auto-Regressive Integrated Moving
Average (ARIMA) , and Vector Auto-Regressive (VAR)
 . Nevertheless, these methods require data to satisfy certain
assumptions, and time-varying trafﬁc data is too complex
to satisfy these assumptions. Moreover, these methods are
only applicable to relatively small datasets. Later, a number
of traditional machine learning methods, such as Support
Vector Regression (SVR) and Random Forest Regression
(RFR) , were proposed for trafﬁc prediction problem. Such
methods have the ability to process high-dimensional data and
capture complex non-linear relationships.
It was not until the advent of deep learning-based methods
that the full potential of artiﬁcial intelligence in trafﬁc prediction was developed . This technology studies how to
learn a hierarchical model to map the original input directly
to the expected output . In general, deep learning models
stack up basic learnable blocks or layers to form a deep
architecture, and the entire network is trained end-to-end.
Several architectures have been developed to handle largescale and complex spatio-temporal data. Generally, Convolutional Neural Network (CNN) is employed to extract
spatial correlation of the grid-structured data described by
images or videos, and Graph Convolutional Network (GCN)
 extends convolution operation to more general graphstructured data, which is more suitable to represent the trafﬁc
network structure. Furthermore, Recurrent Neural Network
(RNN) , and its variants LSTM or GRU 
are commonly utilized to model temporal dependency. Here,
we summarize the key techniques commonly used in existing
trafﬁc prediction methods, as shown in Fig. 2.
Organization of this survey The rest of this paper is
organized as follows. Section II covers the classical methods
for trafﬁc prediction. Section III reviews the work based on
deep learning methods for trafﬁc prediction, including the
commonly used methods of modeling spatial correlation and
temporal correlation, as well as some other new variants.
Section IV lists some representative results in each task. Section V collects and organizes related datasets and commonly
Fig. 2. Key techniques of trafﬁc prediction methods.
used external data types for trafﬁc prediction. Section VI
provides some comparisons and evaluates the performance of
the relevant methods. Section VII discusses several signiﬁcant
and important directions of future trafﬁc prediction. Finally,
we conclude this paper in Section VIII.
II. CLASSICAL METHODS
Statistical and traditional machine learning models are two
major representative data-driven methods for trafﬁc prediction. In time-series analysis, autoregressive integrated moving
average (ARIMA) and its variants are one of the most
consolidated approaches based on classical statistics and have
been widely applied for trafﬁc prediction problems ( ,
 – ). However, these methods are generally designed
for small datasets, and are not suitable to deal with complex
and dynamic time series data. In addition, since usually only
temporal information is considered, the spatial dependency of
trafﬁc data is ignored or barely considered.
Traditional machine learning methods, which can model
more complex data, are broadly divided into three categories:
feature-based models, Gaussian process models and state
space models. Feature-based methods solve trafﬁc prediction
problem ( – ) by training a regression model based on
human-engineered trafﬁc features. These methods are simple
to implement and can provide predictions in some practical
situations. Gaussian process models the inner characteristics
of trafﬁc data through different kernel functions, which need
to contain spatial and temporal correlations simultaneously.
Although this kind of methods is proved to be effective and
feasible in trafﬁc prediction ( – ), compared to featurebased models, they generally have higher computational load
and storage pressure, which is not appropriate when a mass of
training samples are available. State space models assume that
the observations are generated by Markovian hidden states.
The advantage of this model is that it can naturally model the
uncertainty of the system and better capture the latent structure
of the spatio-temporal data. However, the overall non-linearity
of these models ( – ) is limited, and most of the time
they are not optimal for modeling complex and dynamic trafﬁc
data. Table I summarizes some recent representative classical
approaches.
III. DEEP LEARNING METHODS
Deep learning models exploit much more features and
complex architectures than the classical methods, and can
achieve better performance. In Table II, we summarize the
deep learning architectures in the existing trafﬁc prediction
literature, and we will review these commonly components in
this section.
A. Modeling Spatial Dependency
CNN. A series of studies have applied CNN to capture
spatial correlations in trafﬁc networks from two-dimensional
spatio-temporal trafﬁc data . Since the trafﬁc network is
difﬁcult to be described by 2D matrices, several researches
try to convert the trafﬁc network structure at different times
into images and divide these images into standard grids, with
each grid representing a region. In this way, CNNs can be
used to learn spatial features among different regions.
As shown in Fig. 3, each region is directly connected to its
nearby regions. With a 3×3 window, the neighborhood of each
region is its surrounding eight regions. The positions of these
eight regions indicate an ordering of a region’s neighbors. A
ﬁlter is then applied to this 3×3 patch by taking the weighted
average of the central region and its neighbors across each
channel. Due to the speciﬁc ordering of neighboring regions,
the trainable weights are able to be shared across different
locations.
In the division of trafﬁc road network structure, there are
many different deﬁnitions of positions according to different
granularity and semantic meanings. divided a city into I
CLASSICAL METHODS.
Application task
Statistical methods
 , , , 
 , 
Traditional machine learning methods
Feature-based models
 , 
Gaussian process models
State space models
 , , – , – 
 , , 
Travel time
 , 
Fig. 3. 2D Convolution. Each grid in the image is treated as a region, where
neighbors are determined by the ﬁlter size. The 2D convolution operates
between a certain region and its neighbors. The neighbors of the a region
are ordered and have a ﬁxed size.
× J grid maps based on the longitude and latitude where a
grid represented a region. Then, a CNN was applied to extract
the spatial correlation between different regions for trafﬁc ﬂow
prediction.
GCN. Traditional CNN is limited to modeling Euclidean
data, and GCN is therefore used to model non-Euclidean
spatial structure data, which is more in line with the structure
of trafﬁc road network. GCN generally consists of two type of
methods, spectral-based and spatial-based methods. Spectralbased approaches deﬁne graph convolutions by introducing
ﬁlters from the perspective of graph signal processing where
the graph convolution operation is interpreted as removing
noise from graph signals. Spatial-based approaches formulate
graph convolutions as aggregating feature information from
neighbors. In the following, we will introduce spectral-based
GCNs and spatial-based GCNs respectively.
(1) Spectral Methods. Bruna et al. ﬁrst developed
spectral network, which performed convolution operation for
graph data from spectral domain by computing the eigendecomposition of the graph Laplacian matrix L. Speciﬁcally,
the graph convolution operation ∗G of a signal x with a ﬁlter
g ∈RN can be deﬁned as:
x ∗G g = U
 UT x ⊙UT g
where U is the matrix of eigenvectors of normalized graph
Laplacian L, which is deﬁned as L = IN −D−1
UΛUT , D is the diagonal matrix, Dii = P
j (Aij), A is
the adjacency matrix of the graph, Λ is the diagonal matrix of
eigenvalues, Λ = λi. If we denote a ﬁlter as gθ = diag
parameterized by θ ∈RN, the graph convolution can be
simpliﬁed as:
x ∗G g = UgθUT x,
where a graph signal x is ﬁltered by g with multiplication
between g and graph transform UT x. Though the computation
of ﬁlter g in graph convolution can be expensive due to O
multiplications with matrix U, two approximation strategies
have been successively proposed to solve this issue.
ChebNet. Defferrard et al. introduced a ﬁlter as Chebyshev polynomials of the diagonal matrix of eigenvalues, i.e,
, where θ ∈RK is now a vector of
Chebyshev coefﬁcients, ˜Λ =
λmax Λ −IN, and λmax denotes
the largest eigenvalue. The Chebyshev polynomials are deﬁned
as Tk(x) = 2xTk−1(x) −Tk−2(x) with T0x = 1 and
T1(x) = x. Then, the convolution operation of a graph signal
x with the deﬁned ﬁlter gθ is:
x ∗G gθ = U
where ˜L =
λmax L −IN.
First order of ChebNet (1stChebNet). An ﬁrst-order approximation of ChebNet introduced by Kipf and Welling 
further simpliﬁed the ﬁltering by assuming K
λmax = 2, we can obtain the following simpliﬁed expression:
x ∗G gθ = θ0x −θ1D−1
where θ0 and θ1 are learnable parameters. After further
assuming these two free parameters with θ = θ0 = −θ1. This
can be obtained equivalently in the following matrix form:
x ∗G gθ = θ
To avoid numerical instabilities and exploding/vanishing
gradients due to stack operations, another normalization technique is introduced: IN + D−1
˜A = A+IN and ˜Dii = P
j ˜Aij. Finally, a graph convolution
operation can be changed to:
where X ∈RN×C is a signal, Θ ∈RC×F is a matrix of ﬁlter
parameters, C is the input channels, F is the number of ﬁlters,
and Z is the transformed signal matrix.
To fully utilize spatial information, modeled the trafﬁc
network as a general graph rather than treating it as grids,
where the monitoring stations in a trafﬁc network represent the
nodes in the graph, the connections between stations represent
the edges, and the adjacency matrix is computed based on the
distances among stations, which is a natural and reasonable
way to formulate the road network. Afterwards, two graph
convolution approximation strategies based on spectral methods were used to extract patterns and features in the spatial
domain, and the computational complexity was also reduced.
 ﬁrst used graphs to encode different kinds of correlations
among regions, including neighborhood, functional similarity,
and transportation connectivity. Then, three groups of GCN
based on ChebNet were used to model spatial correlations
respectively, and trafﬁc demand prediction was made after
further integrating temporal information.
(2) Spatial Methods. Spatial methods deﬁne convolutions
directly on the graph through the aggregation process that
operates on the central node and its neighbors to obtain a new
representation of the central node, as depicted by Fig.4. In
 , trafﬁc network was ﬁrstly modeled as a directed graph,
the dynamics of the trafﬁc ﬂow was captured based on the
diffusion process. Then a diffusion convolution operation is
applied to model the spatial correlation, which is a more
intuitive interpretation and proves to be effective in spatialtemporal modeling. Speciﬁcally, diffusion convolution models
the bidirectional diffusion process, enabling the model to
capture the inﬂuence of upstream and downstream trafﬁc. This
process can be deﬁned as:
X:,p ⋆G fθ =
k + θk2(D−1
where X ∈RN×P is the input, P represents the number
of input features of each node. ⋆G denotes the diffusion
convolution, k is the diffusion step, fθ is a ﬁlter and θ ∈RK×2
are learnable parameters. DO and DI are out-degree and indegree matrices respectively. To allow multiple input and output channels, DCRNN proposes a diffusion convolution
layer, deﬁned as:
X:,p ⋆G fΘq,p,:,:
where Z ∈RN×Q is the output, Θ ∈RQ×P ×K×2 parameterizes the convolutional ﬁlter , Q is the number of output
features, σ is the activation function. Based on the diffusion
convolution process, designed a new neural network
layer that can map the transformation of different dimensional
features and extract patterns and features in spatial domain.
 modiﬁed the diffusion process in by utilizing a selfadaptive adjacency matrix, which allowed the model to mine
hidden spatial dependency by itself. introduced the notion
of aggregation to deﬁne graph convolution. This operation
can assemble the features of each node with its neighbors.
The aggregate function is a linear combination whose weights
are equal to the weights of the edges between the node
and its neighbors. This graph convolutional operation can be
expressed as follow:
h(l) = σ(Ah(l−1)W + b),
where h(l−1) is the input of the l-th graph convolutional layer,
W and b are parameters, and σ is the activation function.
Fig. 4. Spatial-based graph convolution network. Each node in the graph can
represent a region in the trafﬁc network. To get a hidden representation of a
certain node (e.g. the orange node), GCN aggregates feature information from
its neighbors (shaded area). Unlike grid data in 2D images, the neighbors of
a region are unordered and varies in size.
Attention. Attention mechanism is ﬁrst proposed for natural
language processing , and has been widely used in various
ﬁelds. The trafﬁc condition of a road is affected by other
roads with different impacts. Such impact is highly dynamic,
changing over time. To model these properties, the spatial
attention mechanism is often used to adaptively capture the
correlations between regions in the road network ( – 
). The key idea is to dynamically assign different weights
to different regions at different time steps. For the sake
of simplicity, we ignore time coordinates for the moment.
Attention mechanism operates on a set of input sequence
x = (x1, . . . , xn) with n elements where xi ∈Rdx, and
computes a new sequence z = (z1, . . . , zn) with the same
length where zi ∈Rdz. Each output element zi is computed
as a weighted sum of a linear transformed input elements:
The weight coefﬁcient αij indicates the importance of xi
to xj, and it is computed by a softmax function:
k=1 exp eik
where eij is computed using a compatibility function that
compares two input elements:
eij = v⊤tanh
 xiW Q + xjW k + b
and generally Perceptron is chosen for the compatibility function. Here, the learnable parameters are v, W Q, W k and b.
This mechanism has proven effective, but when the number
of elements n in a sequence is large, we need to calculate
n2 weight coefﬁcients, and therefore the time and memory
consumption are heavy.
In trafﬁc speed prediction, used attention mechanism
to dynamically capture the spatial correlation between the
target region and the ﬁrst-order neighboring regions of the
road network. combined the GCN based on ChebNet
with attention mechanism to make full use of the topological
properties of the trafﬁc network and dynamically adjust the
correlations between different regions.
B. Modeling Temporal Dependency
CNN. ﬁrst introduced the fully convolutional model
for sequence to sequence learning. A representative work in
trafﬁc research, applied purely convolutional structures
to simultaneously extract spatio-temporal features from graphstructured time series data. In addition, dilated causal convolution is a special kind of standard one-dimensional convolution.
It adjusts the size of the receptive ﬁeld by changing the value
of the dilation rate, which is conducive to capture the longterm periodic dependence. and therefore adopted the
dilated causal convolution as the temporal convolution layer of
their models to capture a node’s temporal trends. Compared
to recurrent models, convolutions create representations for
ﬁxed size contexts, however, the effective context size of
the network can easily be made larger by stacking several
layers on top of each other. This allows to precisely control
the maximum length of dependencies to be modeled. The
convolutional network does not rely on the calculation of
the previous time step, so it allows parallelization of every
element in the sequence, which can make better use of GPU
hardware, and easier to optimize. This is superior to RNNs,
which maintain the entire hidden state of the past, preventing
parallel calculations in a sequence.
RNN. RNN and its variant LSTM or GRU, are neural networks for processing sequential data. To model the non-linear
temporal dependency of trafﬁc data, RNN-based approaches
have been applied to trafﬁc prediction . These models rely
on the order of data to process data in turn, and therefore
one disadvantage of these models is that when modeling long
sequences, their ability to remember what they learned before
many time steps may decline.
In RNN-based sequence learning, a special network structure known as encoder-decoder has been applied for trafﬁc
prediction ( , , – , – ). The key idea
is to encode the source sequence as a ﬁxed-length vector and
use the decoder to generate the prediction.
s = f (Ft; θ1) ,
ˆXt+1:t+L = g (s; θ2) ,
where f is the encoder and g is the decoder. Ft denotes the
input information available at timestamp t, s is a transformed
semantic vector representation, ˆXt+1:t+L is the value of Lstep-ahead prediction, θ1 and θ2 are learning parameters.
One potential problem with encoder-decoder structure is that
regardless of the length of the input and output sequences, the
length of semantic vector s between encoding and decoding
is always ﬁxed, and therefore when the input information is
too long, some information will be lost.
Attention. To resolve the above issue, an important extension is to use an attention mechanism on time axis, which
can adaptively select the relevant hidden states of the encoder
to produce output sequence. This is similar to attention in
the spatial methods. Such a temporal attention mechanism can
not only model the non-linear correlation between the current
trafﬁc condition and the previous observations at a certain
position in the road network, but also model the long-term
sequence data to solve the deﬁciencies of RNN.
 designed a temporal attention mechanism to adaptively model the non-linear correlations between different time
steps. incorporated a standard convolution and attention
mechanism to update the information of a node by fusing the
information at the neighboring time steps, and semantically
express the dependency intensity between different time steps.
Considering that trafﬁc data is highly periodic, but not strictly
periodic, designed a periodically shifted attention mechanism to deal with long-term periodic dependency and periodic
temporal shifting.
GCN. Song et al. ﬁrst constructed a localized spatiotemporal graph that includes both temporal and spatial attributes, and then used the proposed spatial-based GCN
method to model the spatio-temporal correlations simultaneously .
C. Joint Spatio-Temporal Relationships Modeling
As shown in Table II, most methods use a hybrid deep learning framework, which combines different types of techniques
to capture the spatial dependencies and temporal correlations
of trafﬁc data separately. They assume that the relations of
geographic information and temporal information are independent and do not consider their joint relations. Therefore,
the spatial and temporal correlations are not fully exploited
to obtain better accuracy. To solve this limitation, researchers
have attempted to integrate spatial and temporal information
into an adjacency graph matrix or tensor. For example, 
got a localized spatio-temporal graph by connecting all nodes
with themselves at the previous moment and the next moment.
According to the topological structure of the localized spatialtemporal graph, the correlations between each node and its
spatio-temporal neighbors can be captured directly. In ,
Fang et al. constructed three matrices for the historical trafﬁc
conditions of different links, the features of the neighbor links,
and the features of the historical time slots, in which each
row of the matrix corresponds to the information of a link.
Finally, these three matrices were concatenated into a matrix
and reshaped into a 3D spatio-temporal tensor. Attention
mechanism was then used to obtain the relations between the
trafﬁc conditions.
D. Deep Learning plus Classical Models
Recently, more and more researches are combining deep
learning with classical methods, and some advanced methods
have been used in trafﬁc prediction ( – ). This kind of
method not only makes up for the weak ability of non-linear
representation of classical models but also makes up for the
poor interpretability of deep learning methods. proposed
a method based on the generation model of state space and the
inference model based on ﬁltering, using deep neural networks
to realize the non-linearity of the emission and the transition
models, and using the recurrent neural network to realize
the dependence over time. Such a non-linear network based
parameterization provides the ﬂexibility to deal with arbitrary
data distribution. proposed a deep learning framework
that introduced matrix factorization method into deep learning
model, which can model the latent region functions along with
the correlations among regions, and further improve the model
capability of the citywide ﬂow prediction. developed a
hybrid model that associated a global matrix decomposition
model regularized by a temporal deep network with a local
deep temporal model that captured patterns speciﬁc to each
dimension. Global and local models are combined through a
data-driven attention mechanism for each dimension. Therefore, global patterns of the data can be utilized and combined
with local calibration for better prediction. combined a
latent model and multi-layer perceptrons (MLP) to design
a network for addressing multivariate spatio-temporal time
series prediction problems. The model captures the dynamics
and correlations of multiple series at the spatial and temporal
levels. Table III summarizes relevant literatures in terms of
deep learning plus classical methods.
E. Limitations of the Deep Learning-based Method
The strengths of the deep neural network model make it
very attractive and indeed greatly promote the progress in
the ﬁeld of trafﬁc prediction. However, it also possess several
disadvantages compared with classical methods.
• High data demand. Deep learning is highly datadependent, and typically the larger the amount of data,
the better it performs. In many cases, such data is not
readily available, for example, some cities may release
taxi data for multiple years, while others release data for
just a few days.
• High computational complexity. Deep learning requires
high computing power, and ordinary CPUs can no longer
meet the requirements of deep learning. The mainstream
computing uses GPU and TPU. At the same time, with
the increase of model complexity and the number of
parameters, the demand for memory is also gradually
increasing. In general, deep neural networks are more
computationally expensive than classical algorithms.
• Lack of interpretability. Deep learning models are mostly
considered as “black-boxs” that lack interpretability. In
general, the prediction accuracy of deep learning models
is higher than that of classical methods. However, there
is no explanation as to why these results are obtained or
how parameters can be determined to make the results
IV. REPRESENTATIVE RESULTS
In this section, we summarize some representative results of
different application tasks. Based on the literature studied on
different tasks, we list the current best performance methods
under commonly used public datasets, as shown in Table IV.
We can have the following observations: First, the results
on different datasets vary greatly under the same prediction
task. For example, in the demand prediction task, the NYC
Taxi and TaxiBJ datasets obtained the accuracy of 8.385 and
17.24, respectively, under the same time interval and prediction
time. Under the same condition of the prediction task and
the dataset, the performance decreases with the increase of
prediction time, as shown in the speed prediction results on
Q-Trafﬁc. For the dataset of the same data source, due to the
different time and region selected, it also has a greater impact
on the accuracy, e.g., related datasets based on PeMS under
the speed prediction task. Second, in different prediction tasks,
the accuracy of speed prediction task can reach above 90% in
general, which is signiﬁcantly higher than other tasks whose
accuracy rate is close to or more than 80%. Therefore, there
is still much room for improvement in these tasks.
Some companies are currently conducting intelligent transportation research, such as amap, DiDi, and Baidu maps.
According to amap technology annual in 2019 , amap has
carried out the exploration and practice of deep learning in the
prediction of the historical speed of amap driving navigation,
which is different from the common historical average method
and takes into account the timeliness and annual periodicity
characteristics presented in the historical data. By introducing
the Temporal Convolutional Network (TCN) model for
industrial practice, and combining feature engineering (extracting dynamic and static features, introducing annual periodicity,
etc.), the shortcomings of existing models are successfully
solved. The arrival time of a given week is measured based
on the order data, and it has a badcase rate of 10.1%, which
is 0.9% lower than the baseline. For the travel time prediction
in the next hour, designed a multi-model architecture to
infer the future travel time by adding contextual information
using the upcoming trafﬁc ﬂow data. Using anonymous user
data from amap, MAPE can be reduced to around 16% in
The Estimated Time of Arrival (ETA), supply and demand
and speed prediction are the key technologies in DiDi’s
platform. DiDi has applied artiﬁcial intelligence technology in
ETA, reduced MAPE index to 11% by utilizing neural network
and DiDi’s massive order data, and realized the ability to provide users with accurate expectation of arrival time and multistrategy path planning under real-time large-scale requests. In
the prediction and scheduling, DiDi has used deep learning
model to predict the difference between supply and demand
after some time in the future, and provided driver scheduling
service. The prediction accuracy of the gap between supply
and demand in the next 30 minutes has reached 85%. In the
urban road speed prediction task, DiDi proposed a prediction
model based on driving trajectory calibration . Through
comparison experiments based on Chengdu and Xi’an data in
the DiDi gaia dataset, it was concluded that the overall MSE
CATEGORIZATION FOR THE COVERED DEEP LEARNING LITERATURE.
Application task
Spatial modeling type
Temporal modeling type
 , – 
 , , – 
1stChebNet
 , 
CNN (Causal CNN)
GCN+Attention
CNN (1-D Conv) +Attention
Attention only
RNN+Attention
 , 
Attention only
 , 
 , 
1stChebNet
CNN (1-D Conv)
(1-D Conv)
(2-D Conv)
 , , , 
RNN+Attention
GCN(spatial-based)
CNN (Causal CNN)
 , 
GCN+Attention
CNN (1-D Conv)
Attention only
 , 
Attention only
 , 
 , – 
RNN+Attention
1stChebNet
Attention only
 , 
Attention only
Attention only
 , 
Travel time
 , 
CNN (1-D Conv)
CATEGORIZATION FOR THE COVERED DEEP LEARNING PLUS CLASSICAL LITERATURE.
Application task
Spatio-temporal modeling
State space model+MLP
State space model+CNN+RNN
State space model+CNN+RNN
State space model+RNN
State space model+CNN
indicator for speed prediction was reduced to 3.8 and 3.4.
Baidu has solved the trafﬁc prediction task of online route
queries by integrating auxiliary information into deep learning
technology, and released a large-scale trafﬁc prediction dataset
from Baidu Map with ofﬂine and online auxiliary information
 . The overall MAPE and 2-hour MAPE of speed prediction
on this dataset decreased to 8.63% and 9.78%, respectively. In
 , the researchers proposed an end-to-end neural framework
as an industrial solution for the travel time prediction function
in mobile map applications, aiming at exploration of spatiotemporal relation and contextual information in trafﬁc prediction. The MAPE in Taiyuan, Hefei and Huizhou, sampled
on the Baidu maps, can be reduced to 21.79%, 25.99%
and 27.10% respectively, which proves the superiority of the
model. The model is already in production on Baidu maps and
successfully handles tens of billions of requests a day.
V. PUBLIC DATASETS
High-quality datasets are essential for accurate trafﬁc forecasting. In this section, we comprehensively summarize the
public data information used for the prediction task, which
mainly consists of two parts: one is the public spatio-temporal
sequence data commonly used in the prediction, and the
other is the external data to improve the prediction accuracy.
However, the latter data is not used by all models due to the
design of different model frameworks or the availability of the
PREDICTION PERFORMANCE STATISTICS FOR DIFFERENT TASKS.
Application task
Time interval
Prediction window
25.97% 
15.88 
16.78% 
29.21 
11.09% 
31.00 
10.21% 
38.58 
8.31% 
24.74 
60/120/180min
29.9/34.7/37.1 
5/15/30/60min
4.90% /6.80%/8.30%/10.00% 
3.57 /5.12/6.17/7.30 
15/30/60min
2.73% /3.63% /4.31% 
2.74 /3.70 /4.32 
15/30/45/60min
2.68% /3.71% /4.42%/4.85% 
2.93/3.92/4.47/4.83 
15/30/45/60min
5.14%/7.18%/8.51%/9.60% 
3.98/5.47/6.39/7.09 
15/30/45min
5.24%/7.33%/8.69% 
4.04/5.70/6.77 
15/30/45/60min
2.24%/3.02%/3.51%/3.89% 
2.45/3.28/3.75/4.11 
15/30/45/60min
3.92/3.96/3.98/4.00 
15/30/45/60min
5.12/6.05/6.70/7.26 
6.01% 
4.63 
15/30/45/60/
75/90/105/120min
4.52%/7.93%/8.89%/9.24%/
9.43%/9.56%/9.69%/9.78%
21.00% 
13.80% 
17.24 
Travel time
11.89% 
7 rolling time windows
(24 time-points at a time)
16.80% 
Public datasets Here, we list public, commonly used and
large-scale real-world datasets in trafﬁc prediction.
• PeMS: It is an abbreviation from the California Transportation Agency Performance Measurement System
(PeMS), which is displayed on the map and collected
in real-time by more than 39000 independent detectors.
These sensors span the freeway system across all major
metropolitan areas of the State of California. The source
is available at: Based on this system, several sub-dataset versions (PeMSD3/4/7(M)/7/8/-
SF/-BAY) have appeared and are widely used. The main
difference is the range of time and space, as well as the
number of sensors included in the data collection.
PeMSD3: This dataset is a piece of data processed by
Song et al. It includes 358 sensors and ﬂow information
from 9/1/2018 to 11/30/2018. A processed version is
available at: 
2/28/2018,
 
PeMSD7(M): It describes the District 7 of California
containing
 
PeMSD7: This version was publicly released by Song
et al. It contains trafﬁc ﬂow information from 883
sensor stations, covering the period from 7/1/2016
to 8/31/2016. A processed version is available at:
 
Bernardino
8/31/2016,
 
data/PEMS08.
PeMSD-SF: This dataset describes the occupancy rate,
between 0 and 1, of different car lanes of San Francisco
bay area freeways. The time span of these measurements is from 1/1/2008 to 3/30/2009 and the data is
sampled every 10 minutes. The source is available at:
 
PeMSD-BAY: It contains 6 months of statistics on trafﬁc
speed, ranging from 1/1/2017 to 6/30/2017, including
325 sensors in the Bay area. The source is available at:
 
• METR-LA: It records four months of statistics on
trafﬁc speed, ranging from 3/1/2012 to 6/30/2012,
 
• LOOP: It is collected from loop detectors deployed
on four connected freeways (I-5, I-405, I-90 and SR-
520) in the Greater Seattle Area. It contains trafﬁc
state data from 323 sensor stations over the entirely of
2015 at 5-minute intervals. The source is available at:
 
• Los-loop: This dataset is collected in the highway of
Los Angeles County in real time by loop detectors. It
includes 207 sensors and its trafﬁc speed is collected
from 3/1/2012 to 3/7/2012. These trafﬁc speed data is
aggregated every 5 minutes. The source is available at:
 
• TaxiBJ: Trajectory data is the taxicab GPS data and
meteorology data in Beijing from four time intervals:
1st Jul. 2013 - 30th Otc. 2013, 1st Mar. 2014 -
30th Jun. 2014, 1st Mar. 2015 - 30th Jun. 2015, 1st
Nov. 2015 - 10th Apr. 2016. The source is available at: 
data/TaxiBJ.
• SZ-taxi: This is the taxi trajectory of Shenzhen from
Jan.1 to Jan.31, 2015. It contains 156 major roads
of Luohu District as the study area. The speed of
trafﬁc on each road is calculated every 15 minutes.
The source is available at: 
GCN/tree/master/data.
• NYC Bike: The bike trajectories are collected from
 
 
• NYC Taxi: The trajectory data is taxi GPS data for
New York City from 2009 to 2018. The source is
available at: 
• Q-Trafﬁc dataset: It consists of three sub-datasets:
query sub-dataset, trafﬁc speed sub-dataset and road
network sub-dataset. These data are collected in Beijing, China between April 1, 2017 and May 31, 2017,
from the Baidu Map. The source is available at:
 
• Chicago: This is the trajectory of shared bikes in
Chicago from 2013 to 2018. The source is available at:
 
• BikeDC: It is taken from the Washington D.C.Bike System. The dataset includes data from 472 stations and four
time intervals of 2011, 2012, 2014 and 2016. The source
is available at: 
information
inter-city
Government,
range of 2006 to 2014. The source is available at:
 
• T-Drive: It consists of tremendous amounts of trajectories
of Beijing taxicabs from Feb.1st, 2015 to Jun. 2nd 2015.
These trajectories can be used to calculate the trafﬁc
 
• I-80: It is collected detailed vehicle trajectory data
on eastbound I-80 in the San Francisco Bay area in
Emeryville, CA, on April 13, 2005. The dataset is 45
minutes long, and the vehicle trajectory data provides
the precise location of each vehicle in the study area
every tenth of a second. The source is available at:
 
• DiDi chuxing: DiDi gaia data open program provides real
and free desensitization data resources to the academic
community. It mainly includes travel time index, travel
and trajectory datasets of multiple cities. The source is
available at: 
• Travel Time Index data:
The dataset includes the travel time index of Shenzhen,
Suzhou, Jinan, and Haikou, including travel time index
and average driving speed of city-level, district-level,
and road-level, and time range is from 1/1/2018 to
12/31/2018. It also includes the trajectory data of the Didi
taxi platform from 10/1/2018 to 12/1/2018 in the second
ring road area of Chengdu and Xi’an, as well as travel
time index and average driving speed of road-level in
the region, and Chengdu and Xi’an city-level. Moreover,
the city-level, district-level, road-level travel time index
and average driving speed of Chengdu and Xi’an from
1/1/2018 to 12/31/2018 is contained.
Travel data:
This dataset contains daily order data from 5/1/2017 to
10/31/2017 in Haikou City, including the latitude and
longitude of the start and end of the order, as well as
the order attribute of the order type, travel category, and
number of passengers.
Trajectory data:
This dataset comes from the order driver trajectory data
of the Didi taxi platform in October and November 2016
in the Second Ring Area of Xi’an and Chengdu. The
trajectory point collection interval is 2-4s. The trajectory
points have been processed for road binding, ensuring that
the data corresponds to the actual road information. The
driver and order information were encrypted, desensitized
and anonymized.
Common external data Trafﬁc prediction is often inﬂuenced by a number of complex factors, which are usually
called external data. Here, we list common external data items.
• Weather condition: temperature, humidity, wind speed,
visibility and weather state (sunny/rainy/windy/cloudy
• Driver ID:
Due to the different personal conditions of drivers, the
prediction will have a certain impact, therefore, it is
necessary to label the driver, and this information is
mainly used for personal prediction.
• Event: It includes various holidays, trafﬁc control, trafﬁc
accidents, sports events, concerts and other activities.
• Time information: day-of-week, time-of-day.
(1) day-of-week usually includes weekdays and weekends
due to the distinguished properties.
(2) time-of-day generally has two division methods, one
is to empirically examine the distribution with respect to
time in the training dataset, 24 hours in each day can be
intuitively divided into 3 periods: peak hours, off-peak
hours, and sleep hours. The other is to manually divide
one day into several timeslots, each timeslot corresponds
to an interval.
VI. EXPERIMENTAL ANALYSIS AND DISCUSSIONS
In this section, we conduct experimental studies for several
deep learning based trafﬁc prediction methods, to identify the
key components in each model. To this end, we utilize METR-
LA dataset for speed prediction, evaluate the state-of-the-art
approaches with public codes on this dataset, and investigate
the performance limits.
A. Experimental Setup
In the experiment, we compare the performance of six
typical speed prediction methods with public codes on a public
dataset. Table V summarizes the links of public source codes
for related comparison methods.
OPEN SOURCE CODES OF COMPARISON METHODS.
STGCN 
 IJCAI-18
DCRNN 
 
ASTGCN 
 
Graph WaveNet 
 
STSGCN 
 
 
METR-LA dataset: This dataset contains 207 sensors and
collects 4 months of data ranging from Mar 1st 2012 to Jun
30th 2012 for the experiment. 70% of data is used for training,
20% is used for testing while the remaining 10% for validation.
Trafﬁc speed readings are aggregated into 5 minutes windows,
and Z-Score is applied for normalization. To construct the road
network graph, each trafﬁc sensor is considered as a node,
and the adjacency matrix of the nodes is constructed by road
network distance with a thresholded Gaussian kernel .
We use the following three metrics to evaluate different
models: Mean Absolute Error (MAE), Rooted Mean Squared
Error (RMSE), and Mean Absolute Percent Error (MAPE).
(ˆyi −yi)2,
where ˆyi and yi denote the predicted value and the ground
truth of region i for predicted time step, and ξ is the total
number of samples.
For hyperparameter settings in the comparison algorithms,
we set their values according to the experiments in the
corresponding literatures ( , , , , , 
B. Experimental Results and Analysis
In this section, we evaluate the performance of various
advanced trafﬁc speed prediction methods on the graphstructured data, and the prediction results in the next 15
minute, 30 minute, and 60 minute (T=3, 6, 12) are shown
in Table VI.
STGCN applied ChebNet graph convolution and 1D convolution to extract spatial dependencies and temporal correlations. ASTGCN leveraged two attention layers on the basis of
STGCN to capture the dynamic correlations of trafﬁc network
in spatial dimension and temporal dimension, respectively.
DCRNN was a cutting edge deep learning model for prediction, which used diffusion graph convolutional networks
and RNN during training stage to learn the representations of
spatial dependencies and temporal relations. Graph WaveNet
combined graph convolution with dilated casual convolution
to capture spatial-temporal dependencies. STSGCN simultaneously extracted localized spatio-temporal correlation information based on the adjacency matrix of localized spatiotemporal graph. GMAN used purely attention structures in
spatial and temporal dimensions to model dynamic spatiotemporal correlations.
As can be seen from the experimental results in Table VI:
First, the attention-based methods (GMAN) perform better
than other GCN-based methods in extracting spatial correlations. When modeling spatial correlations, GCN uses sum,
mean or max functions to aggregate the features of each
node’s neighbors, ignoring the relative importance of different neighbors. On the contrary, the attention mechanism
introduces the idea of weighting to realize adaptive updating
of nodes at different times according to the importance of
neighbor information, leading to better results. Second, the
performance of the spectral models (STGCN and ASTGCN)
is generally lower than that of the spatial models (DCRNN,
Graph WaveNet and STSGCN). In addition, the results of
most methods are not signiﬁcantly different for 15min, but
with the increase of the predicted time length, the performance
of the attention-based method (GMAN) is signiﬁcantly better
than other GCN-based methods. Since most existing methods
predict trafﬁc conditions in an iterative manner, and their
performance may not be greatly affected in short-term predictions because all historical observations used for prediction are
error-free. However, as long-term prediction has to produce the
results conditioned on previous predictions, resulting in error
accumulations and reducing the accuracy of prediction greatly.
Since the attention mechanism can directly perform multistep predictions, ground-truth historical observations can be
used regardless of short-term or long-term predictions, without
the need to use error-prone values. Therefore, the above
observations suggest possible ways to improve the prediction
accuracy. First, the attention mechanism can extract the spatial
information of road network more effectively. Second, the
spatial-based approaches are generally more efﬁcient than the
spectral-based approaches when working with GCN. Third,
the attention mechanism is more effective to improving the
performance of long-term prediction when modeling temporal
correlation. It is worth mentioning that adding an external data
PERFORMANCE OF TRAFFIC SPEED PREDICTION ON METR-LA.
Graph WaveNet
component is also beneﬁcial for performance when external
data is available.
C. Computational complexity
To evaluate the computation complexity, we compare the
computation time and the number of parameters among these
models on the METR-LA dataset. All the experiments are
conducted on the Tesla K80 with 12GB memory, the batchsize
of each method is uniformly set to 64, T is set to 12, and we
report the average training time of one epoch. For inference,
we compute the time cost on the validation data. The results
are shown in Table VII. STGCN adopts fully convolutional
structures so that it is the fastest in training, and DRCNN
uses the recurrent structures, which are very time consuming.
Compared to methods (e.g., STGCN, DCRNN, ASTGCN,
STSGCN) that require iterative calculations to generate 12
predicted results, Graph WaveNet can predict 12 steps ahead
of time in one run, thus requiring less time for inference.
STSGCN integrates three graphs at different moments into
one graph as the adjacency matrix, which greatly increases
the number of model parameters. Since GMAN is a pure
attention mechanism model that consists of multiple attention
mechanisms, it is necessary to calculate the relation between
pairs of multiple variables, so the number of parameters is
also high. Note that, when calculating the computation time
of GMAN, it displays “out of memory” on our device, due to
the relatively complex design of the model.
COMPUTATION COST ON METR-LA.
Computation time
Number of parameters
Training(s/epoch)
Inference(s)
Graph WaveNet
VII. FUTURE DIRECTIONS
Although trafﬁc prediction has made great progress in recent
years, there are still many open challenges that have not been
fully investigated. These issues need to be addressed in future
work. In the following discussion, we will state some future
directions for further researches.
• Few shot problem: Most existing solutions are data intensive. However, abnormal conditions (extreme weather,
temporary trafﬁc control, etc) are usually non-recurrent,
it is difﬁcult to obtain data, which makes the training
sample size smaller and learning more difﬁcult than
that under normal trafﬁc conditions. In addition, due to
the uneven development level of different cities, many
cities have the problem of insufﬁcient data. However,
sufﬁcient data is usually a prerequisite for deep learning
methods. One possible solution to this problem is to
use transfer learning techniques to perform deep spatiotemporal prediction tasks across cities. This technology
aims to effectively transfer knowledge from a data-rich
source city to a data-scarce target city. Although recent
approaches have been proposed ( , , , 
), these researches have not been thoroughly studied, such
as how to design a high-quality mathematical model to
match two regions, or how to integrate other available
auxiliary data sources, etc., are still worth considering
and investigating.
• Knowledge graph fusion: Knowledge graph is an important tool for knowledge integration. It is a complex relational network composed of a large number of concepts,
entities, entity relations and attributes. Transportation
domain knowledge is hidden in multi-source and massive
trafﬁc big data. The construction, learning and deep
knowledge search of large-scale transportation knowledge
graph can help to dig deeper trafﬁc semantic information
and improve the prediction performance.
• Long-term prediction: Existing trafﬁc prediction methods
are mainly based on short-to-medium-term prediction,
and there are very few studies on long-term forecasting (
 , , ). Long-term prediction is more difﬁcult due to the more complex spatio-temporal dependencies and more uncertain factors. For long-term prediction,
historical information may not have as much impact on
short-to-medium-term prediction methods, and it may
need to consider additional supplementary information.
• Multi-source data: Sensors, such as loop detectors or
cameras, are currently the mainstream devices for collecting trafﬁc data. However, due to the expensive installation
and maintenance costs of sensors, the data is sparse.
At the same time, most existing technologies based on
previous and current trafﬁc conditions are not suited to
real-world factors, such as trafﬁc accidents. In the big data
era, a large amount of data has been produced in the ﬁeld
of transportation. When predicting trafﬁc conditions, we
can consider using several different datasets. In fact, these
data are highly correlated. For example, to improve the
performance of trafﬁc ﬂow prediction, we can consider
information such as road network structure, trafﬁc volume
data, points of interests (POIs), and populations in a city.
Effective fusion of multiple data can ﬁll in the missing
data and improve the accuracy of prediction.
• Real-time prediction: The purpose of real-time trafﬁc prediction is to conduct data processing and trafﬁc condition
assessment in a short time. However, due to the increase
of data, model size and parameters, the running time of
the algorithm is too long to guarantee the requirement
of real-time prediction. The scarce real-time prediction
currently found in the literature , it is a great challenge to design an effective lightweight neural network to
reduce the amount of network computation and improve
network speed up.
• Interpretability of models: Due to the complex structure,
large amount of parameters, low algorithm transparency,
for neural networks, it is well known to verify its reliability. Lack of interpretability may bring potential problems
to trafﬁc prediction. Considering the complex data types
and representations of trafﬁc data, designing an interpretable deep learning model is more challenging than
other types of data, such as images and text. Although
some previous work combined the state space model to
increase the interpretability of the model ( – ),
how to establish a more interpretable deep learning model
of trafﬁc prediction has not been well studied and is still
a problem to be solved.
• Benchmarking trafﬁc prediction: As the ﬁeld grows, more
and more models have been proposed, and these models
are often presented in a similar way. It has been increasingly difﬁcult to gauge the effectiveness of new trafﬁc
prediction methods and compare models in the absence
of a standardized benchmark with consistent experimental
settings and large datasets. In addition, the design of
models is becoming more and more complex. Although
ablation studies have been done in most methods, it
is still not clear how each component improves the
algorithm. Therefore, it is of great importance to design
a reproducible benchmarking framework with a standard
common dataset.
• High dimensionality. At present, trafﬁc prediction still
mainly stays at the level of a single data source, with
less consideration of inﬂuencing factors. With more collected datasets, we can obtain more inﬂuencing factors.
However, high-dimensional features often bring about
“curse of dimensionality” and high computational costs.
Therefore, how to extract the key factors from the large
amount of inﬂuencing factors is an important issue to be
• Prediction under perturbation. In the process of collecting
trafﬁc data, due to factors such as equipment failures, the
collected information deviates from the true value. Therefore, the actual sampled data is generally subject to noise
pollution to varying degrees. The use of contaminated
data for modeling will affect the prediction accuracy of
the model. Existing methods usually treat data processing
and model prediction as two separate tasks. It is of great
practical signiﬁcance to design a robust and effective
trafﬁc prediction model in the case of various noises and
errors in the data.
• The optimal network architecture choice: For a given
trafﬁc prediction task, how to choose a suitable network
architecture has not been well studied. For example, some
works model the historical trafﬁc data of each road as a
time series and use networks such as RNN for prediction;
some works model the trafﬁc data of multiple roads as
2D spatial maps and use networks such as CNN to make
predictions. In addition, some works model trafﬁc data as
a road network graph, so network architectures such as
GNN are adopted. There is still a lack of more in-depth
research on how to optimally choose a deep learning
network architecture to better solve the prediction task
VIII. CONCLUSION
In this paper, we conduct a comprehensive survey of various deep learning architectures fot trafﬁc prediction. More
speciﬁcally, we ﬁrst summarize the existing trafﬁc prediction methods, and give a taxonomy of them. Then, we list
the representative results in different trafﬁc prediction tasks,
comprehensively provide public available trafﬁc datasets, and
conduct a series of experiments to investigate the performance
of existing trafﬁc prediction methods. Finally, some major
challenges and future research directions are discussed. This
paper is suitable for participators to quickly understand the
trafﬁc prediction, so as to ﬁnd branches they are interested in.
It also provides a good reference and inquiry for researchers
in this ﬁeld, which can facilitate the relevant research.