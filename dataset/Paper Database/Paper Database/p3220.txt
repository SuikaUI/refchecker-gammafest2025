Manski, Charles F.
Working Paper
Identification of treatment response with social
interactions
cemmap working paper, No. CWP01/10
Provided in Cooperation with:
Institute for Fiscal Studies (IFS), London
Suggested Citation: Manski, Charles F. : Identification of treatment response with social
interactions, cemmap working paper, No. CWP01/10, Centre for Microdata Methods and Practice
(cemmap), London,
 
This Version is available at:
 
Standard-Nutzungsbedingungen:
Die Dokumente auf EconStor dürfen zu eigenen wissenschaftlichen
Zwecken und zum Privatgebrauch gespeichert und kopiert werden.
Sie dürfen die Dokumente nicht für öffentliche oder kommerzielle
Zwecke vervielfältigen, öffentlich ausstellen, öffentlich zugänglich
machen, vertreiben oder anderweitig nutzen.
Sofern die Verfasser die Dokumente unter Open-Content-Lizenzen
(insbesondere CC-Lizenzen) zur Verfügung gestellt haben sollten,
gelten abweichend von diesen Nutzungsbedingungen die in der dort
genannten Lizenz gewährten Nutzungsrechte.
Terms of use:
Documents in EconStor may be saved and copied for your personal
and scholarly purposes.
You are not to copy documents for public or commercial purposes, to
exhibit the documents publicly, to make them publicly available on the
internet, or to distribute or otherwise use the documents in public.
If the documents have been made available under an Open Content
Licence (especially Creative Commons Licences), you may exercise
further usage rights as specified in the indicated licence.
Identification of treatment
response with social
interactions
Charles F. Manski
The Institute for Fiscal Studies
Department of Economics, UCL
cemmap working paper CWP01/10
IDENTIFICATION OF TREATMENT RESPONSE WITH SOCIAL INTERACTIONS
Charles F. Manski
Department of Economics and Institute for Policy Research, Northwestern University
First Public Draft: October 7, 2009
This Revision: January 11, 2010
This paper develops a formal language for study of treatment response with social interactions, and uses it
to obtain new findings on identification of potential outcome distributions. Defining a person’s treatment
response to be a function of the entire vector of treatments received by the population, I study identification
when shape restrictions and distributional assumptions are placed on response functions. An early key result
is that the traditional assumption of individualistic treatment response (ITR) is a polar case within the broad
class of constant treatment response (CTR) assumptions, the other pole being unrestricted interactions.
Important non-polar cases are interactions within reference groups and distributional interactions. I show
that established findings on identification under assumption ITR extend to assumption CTR. These include
identification with assumption CTR alone and when this shape restriction is strengthened to semi-monotone
response. I next study distributional assumptions using instrumental variables. Findings obtained previously
under assumption ITR extend when assumptions of statistical independence (SI) are posed in settings with
social interactions, but with important caveats. The extended version of assumption SI has no power to
identify counterfactual outcome distributions when social interactions are unrestricted. Random assignment
of realized treatments has strong identifying power when reference groups are small, limited power when
distributional interactions occur in large groups, and generically no power in settings with strong dependence.
Finally, considering models of endogenous social interactions, I show that identification of structural
equations differs from identification of outcome distributions under potential treatments. Analysis of
familiar linear models illustrates this general point.
This research was supported in part by National Science Foundation grant SES-0911181. I have benefitted
from the opportunity to present this work at an invited session of the 2010 North American Winter Meeting
of the Econometric Society. I am grateful for comments from Mike Fu and Guido Imbens.
1. Introduction
This paper studies identification of treatment response in settings with social interactions, where
personal outcomes may vary with the treatment of others. Social interactions are common within households,
schools, workplaces, and communities. Yet research on treatment response has mainly assumed that a
person’s outcome may vary only with his own treatment, not with those of other members of the population.
Some researchers have called this “no interference between units” or the Stable Unit Treatment Value
Assumption. I have called it individualistic treatment response (ITR), to mark it as an assumption that
restricts the form of treatment response functions.
The present analysis extends my earlier work on identification with individualistic response, reported
in Manski , Manski and Pepper , and elsewhere. Here, as there, I ask what can be
learned about outcomes under potential treatments when data on realized treatments and outcomes are
combined with assumptions on treatment response. I emphasize nonparametric assumptions that may be
credible in applications and, hence, primarily report findings of partial rather than point identification.
To set the stage, I now specify basic concepts and notation that will be used throughout the paper.
This requires a modest but essential extension of the setup used in my earlier work. A clear and concise
formal language enormously simplifies analysis of treatment response.
Basic Concepts and Notation
When response is assumed to be individualistic, each member j of population J has observable
covariates x 0 X and a response function y (A): T 6 Y mapping the mutually exclusive and exhaustive
potential treatments t 0 T into outcomes y (t) 0 Y. Person j has an observable realized treatment z 0 T and
realized outcome y / y (z).
Let J be a probability space (J, Ù, P). Then observation of (x , y , z ; j 0 J) reveals P(x, y, z), the joint
distribution of covariates, realized outcomes, and realized treatments. A common research objective has been
to combine this empirical evidence with credible assumptions to learn about the outcome distribution P[y(t)]
that would occur if all persons were to receive a specified treatment t. Interest in P[y(t)] is often motivated
by a decision problem in which a planner chooses between the realized treatments and a policy that mandates
treatment t. Then the planner wants to compare P[y(t)] with P(y).
Now remove assumption ITR, so each person’s outcome may vary with the treatments received by
all members of the population. To express this, I extend the domain of the response function from T to the
Cartesian product of T across the population; that is, T / ×
T. The response function becomes y(A):
T 6 Y, mapping treatment vectors t 0 T into outcomes y (t ) 0 Y. Here t / (t , k 0 J) denotes a potential
treatment vector specifying the treatment to be received by every member of the population. Person j has
observable realized treatment z 0 T and realized outcome y / y (z ), where z / (z , k 0 J).
I will take the research objective to be inference on the outcome distribution P[y(t )] that would occur
if the population were to receive a specified feasible treatment vector t . I will not require that t assign a
common treatment to all persons, nor that it assign treatments randomly. I will suppose that the cardinality
of T is at most countable. This enables an analysis that uses only elementary probability theory, particularly
the Law of Total Probability. Interest in P[y(t )] may be motivated by a decision problem in which a planner
chooses between the realized treatments z and a policy that mandates treatment vector t . Then the planner
wants to compare P[y(t )] with P(y). Instances of such planning problems are studied in Graham, Imbens,
and Ridder and Manski .
In my earlier work studying prediction of outcomes when all persons receive a common treatment,
I have let t denote the specified common treatment. In this paper, I let t be the random variable generated
by (t , j 0 J). Thus, P(x, y, z, t) is the distribution of (x , y , z , t ; j 0 J). I will use ô rather than t to denote a
specific element of T.
The notation introduced above suffices to cover many but not all interesting problems of treatment
response with social interactions. It covers cases in which a planner assigns treatments to individual
members of the population, perhaps medical or educational or economic treatments, who then interact with
one another to produce outcomes. It also covers cases in which a planner allocates persons to groups within
which interactions occur; for example, the treatments in T may be school classrooms, hospital wards, or
prisons. Perhaps the primary restriction of the notation is that it portrays a static planning problem. The
notation does not cover dynamic problems, where initial treatment assignments are followed by the
realization of initial outcomes, then assignment of further treatments, and so on.
Identification of P[y(t )]
Comparison of the setup with and without assumption ITR makes plain that identification without
the assumption presents a much more severe challenge than with it. Given assumption ITR and no further
assumptions, the Law of Total Probability shows that Ç{P[y(t )]}, the identification region for P[y(t )], is the
set of distributions [P(y*z = t)P(z = t) + äP(z
t), ä 0 Ä ], where Ä denotes the space of all probability
distributions on Y. This region is a proper subset of Ä if and only if P(z = t) > 0, which occurs when a
positive fraction of the population receive the same realized and potential treatment. I have previously
reported this simple result in Manski and elsewhere for the case when t assigns a common
treatment to all persons. Section 2.1 below extends it to the general case where t is a vector of treatments
that may vary across the population.
Without assumption ITR or another assumption restricting social interactions, Ç{P[y(t )]} is the
singleton P(y) when z = t and is the set Ä of all distributions whenever z
t . Thus, the empirical evidence
alone is uninformative about P[y(t )] when t has any counterfactual component. Partial or point
identification of P[y(t )] may become feasible when the empirical evidence is combined with assumptions
that restrict the form of the response functions [y (A), j 0 J] and/or the distribution P[x, y(A), z] of covariates,
response functions, and realized treatments. The size and shape of Ç{P[y(t )]} depends on the assumptions
imposed and the treatment vector t under consideration.
Innumerable assumptions and potential treatment vectors may be of interest. This paper is entirely
general with respect to the potential treatment vector. However, I cannot constructively analyze all possible
assumptions. To make progress, I consider some simple nonparametric assumptions that may be credible
in applications. Section 2 studies two shape restrictions on response functions, constant treatment response
(CTR) and semi-monotone treatment response (SMTR). Section 3 combines these shape restrictions with
statistical-independence assumptions that use instrumental variables. Section 4 considers identification using
parametric and nonparametric models of endogenous interactions. Section 5 concludes, calling attention to
some of the many potentially fruitful directions for future research. The remainder of this Introduction gives
a more detailed overview of what lies ahead.
Restrictions on the Shape of Response Functions
Section 2 begins with the assumption of constant treatment response, which states that a person’s
outcome remains constant when t varies within specified subsets of T . I refer to these subsets of T as the
person’s effective treatments. This definition of assumption CTR generalizes one given in Manski and
Pepper , who named the concept in an individualistic-response context considering treatments with
multiple components. There we defined CTR as an exclusion restriction asserting that a person’s outcome
remains constant when some treatment components are altered, holding the other components fixed. We did
not, however, study the identifying power of the assumption.
Considering treatment with social interactions, a leading subclass of constant-response assumptions
assert that interactions may occur within but not across known reference groups. Then a person’s outcome
remains constant when treatment varies outside his reference group. In applied work, a person’s reference
group is often assumed to be the members of his family, neighborhood, school, workplace, or some other
group, depending on the context. One might, for example, assume that treatment interactions may occur
within but not across neighborhoods. Assumption ITR is the special case where each person’s reference
group includes only himself.
As defined here, reference groups are person-specific but non manipulable. Person-specific means
that person k may be a member of person j’s group but not vice versa. Non-manipulability means that a
planner cannot use the treatments in T to alter a person’s reference group. Prediction of outcomes when
treatments can manipulate group composition is not discussed in this paper.
An important subclass of interactions within reference groups assumes that interactions are
distributional. Here the outcome of a person may vary with his own treatment and with the distribution of
treatments among others in his reference group, but does not vary with the size of the group or with
permutations of the treatments received by other group members. A simple form of distributional interaction
is the assumption that a person’s outcome varies only with his own treatment and with the mean treatment
of others in the reference group.
Semi-monotone response is a class of assumptions stating that set T is partially ordered and that
outcomes vary monotonically across ordered pairs of treatment vectors. This class of assumptions was
introduced and studied in Manski in the context of individualistic treatment response. There the set
T was partially ordered and it was assumed that outcomes vary monotonically across ordered pairs of
treatments. Extending the idea to settings with social interactions is straightforward.
Important subcases are reinforcing and opposing interactions. A reinforcing interaction occurs when
a person’s outcome increases both with the value of his own treatment and with the values of the treatments
received by others in the reference group. Consider, for example, vaccination against an infectious disease.
Vaccination of person j may reduce the chance that this person will become ill, and vaccination of other
persons who are in contact with person j may also reduce his probability of illness, reinforcing the effect of
own vaccination. I will use vaccination to illustrate findings on identification in Sections 2.3 and 3.2.
An opposing interaction occurs when a person’s outcome increases with the value of his own
treatment but decreases with the values of the treatments received by others. Consider, for example, training
that provides occupation-specific human capital. Training person j may increase the chance that this person
finds employment in the occupation, but training other persons increases the supply of trained labor and,
hence, may decrease the probability that person j finds employment.
Although this paper is about identification, I would be remiss to entirely ignore estimation with
sample data. To conclude Section 2, I suppose that one poses a version of assumption CTR and observes
a random sample of the population. I show that the identification region for any potential outcome
distribution may be consistently estimated if one observes the realized outcome and effective treatment of
each sample member. However, it generally does not suffice to observe the realized outcome and own
treatment for each member.
Distributional Assumptions Using Instrumental Variables
Having studied the identifying power of shape restrictions alone in Section 2, Section 3 combines
shape restrictions with distributional assumptions that use instrumental variables. In research under
assumption ITR, empirical researchers often pose assumptions about the distribution of response.
Particularly common are assumptions that use an instrumental variable v / v(x, z), where v(@, @): X × T 6 V
is a specified function of observed covariates and realized treatments. Taking the objective to be inference
on P[y(ô)] for a specified ô 0 T, it is common to assume that y(ô) and v are statistically independent; that is,
P[y(ô)*v] = P[y(ô)].
The statistical-independence assumption extends immediately to research on treatment with social
interactions, where the objective is to infer P[y(t )] for a specified t 0 T . Here one may assume that
P[y(t )*v] = P[y(t )]. I first characterize the identifying power of this assumption abstractly. The analysis
extends my earlier work on identification when assumption ITR is combined with independence assumptions
using instrumental variables . I use a vaccination scenario
to illustrate the findings.
I then consider the use of realized treatments as the instrumental variable. Given assumption ITR,
the assumption P[y(ô)*z] = P[y(ô)] point-identifies P[y(ô)]. This assumption has high credibility when
realized treatments are randomly assigned to a large population. I extend the familiar identification argument
to inference under assumption CTR, using appropriate person-specific functions of z as the instrumental
variable. However, this positive finding must be tempered. The extended statistical independence
assumption has no power to identify counterfactual outcome distributions when social interactions are
unrestricted. When interactions are restricted, the extended assumption may not be credible even when y(@)
and z are statistically independent.
Finally, I consider random assignment of realized treatments. Random assignment has strong
identifying power under assumption ITR, but not necessarily with social interactions. I find that random
assignment has different identifying power when reference groups are small and large. The strong power
of random assignment under assumption ITR extends to settings where the population partitions into many
small groups, whatever the nature of the within-group interaction. However, random assignment generically
has no identifying power in large-group settings with strong dependence, where the treatments assigned to
a small set of persons may affect the population outcome distribution. Random assignment has limited
identifying power in large-group settings with distributional interactions.
Models of Endogenous Social Interactions
In the analysis of Sections 2 and 3, response functions are primitives that map treatment vectors into
outcomes. Section 4 considers identification with models of endogenous interactions. The primitive of such
a model is a system of structural equations that take the outcome of each person to be a function of the
treatment vector and of the outcomes of other members of the population. The response functions [y (A),
j 0 J] are a derived concept, called the reduced form of the model.
A large body of econometric research has studied identification of structural equations. However,
our objective is identification of P[y(t )], not identification of structural equations. A model of endogenous
interactions may have identifying power for P[y(t )] if the specified structural equations imply restrictions
on the reduced form. I compare the identifying power of complete and incomplete models. Analysis of two
familiar linear models illustrates that point identification of a complete model is not necessary for point
identification of potential outcome distributions.
2. Restrictions on the Shape of Response Functions
This section studies the identifying power of assumptions that restrict the shape of the treatment
response functions [y (A), j 0 J]. I begin with constant treatment response in Section 2.1 and then add semimonotone treatment response in Section 2.2. Section 2.3 uses vaccination against infectious disease to
illustrate findings. Section 2.4 discusses estimation of identification regions from random sample data.
2.1. Constant Treatment Response
Constant-response assumptions assert that treatment response does not vary over specified sets of
treatment vectors. Section 2.1.1 poses the assumption in abstraction and establishes its identifying power.
Section 2.1.2 specializes to CTR assumptions that restrict social interactions to reference groups. Section
2.1.3 specializes further to distributional interactions.
It will be evident that constant-response assumptions have only limited identifying power.
Nevertheless, they are highly important to analysis of treatment response. They are basic assumptions that
often have high credibility. As such, they provide a foundation on which further assumptions may be placed.
2.1.1. The Assumption in Abstraction
Consider person j. Let c (A): T 6 C be a function mapping treatment vectors onto a set C . A
constant-response assumption asserts that
(1) c (t ) = c (s ) Y y(t ) = y (s ).
Thus, j experiences the same outcome for all treatment vectors that form a level set of c (A). With this in
mind, I shall refer to C as the set of effective treatments for person j.
Suppose that one observes [c (A), y , z ; j 0 J]; thus, function c (A) is an observed covariate. Consider
inference on y (t ). The researcher can infer y (t ) if and only if c (z ) = c (t ). When this event occurs, z and
t are effectively the same treatment from the perspective of person j, yielding the same outcome y (t ) = y (z )
= y . When c (z )
c (t ), assumption CTR and observation of y do not reveal y(t ).
Now consider identification of P[y(t )]. By the Law of Total Probability,
(2) P[y(t )] = P[y(t )*c(z ) = c(t )]AP[c(z ) = c(t )] + P[y(t )*c(z )
c(t )]AP[c(z )
Here P[c(z ) = c(t )] is the fraction of the population for whom [c(z ) = c(t )], and P[y(t )*c(z ) = c(t )] is the
distribution of outcomes conditional on this event. Observation of realized treatments reveals P[c(z ) = c(t )]
and P[c(z )
c(t )]. Assumption CTR implies that P[y(t )*c(z ) = c(t )] = P[y*c(z ) = c(t )]. Observation of
realized treatments and outcomes reveals P[y*c(z ) = c(t )] when P[c(z ) = c(t )] > 0. The empirical evidence
and assumption CTR are uninformative about the counterfactual outcome distribution P[y(t )*c(z )
Hence, the identification region for P[y(t )] is
(3) Ç{P[y(t )]} = {P[y*c(z ) = c(t )]AP[c(z ) = c(t )] + äAP[c(z )
c(t )], ä 0 Ä }.
Observe that the size of Ç{P[y(t )]} varies inversely with P[c(z ) = c(t )]. The region is the singleton
P(y) when P[c(z ) = c(t )] = 1. It expands as P[c(z ) = c(t )] decreases, and becomes uninformative when
P[c(z ) = c(t )] = 0.
2.1.2. Interactions within Reference Groups
Concepts and Notation
It is common in applications to assume that each member of the population has a known reference
groups, with interactions occurring within but not across groups. Let G(j) d J denote the reference group of
person j, let T
T, and let t
/ [t , k 0 G(j)] be the sub-vector of t specifying the treatments
assigned to the members of the group. For j 0 J and t 0 T , let C = T
and c (t ) = t
. Then an effective
treatment for person j is the sub-vector of treatments in his reference group. A person’s outcome remains
constant when treatments outside the group are altered, holding fixed the treatments of persons in the group.
As defined here, reference groups are person-specific, treatment-invariant, and non-manipulable.
Person-specific means that person k may be a member of person j’s group but not vice versa. Such
asymmetry is expressed graphically in social network analysis when a directed path either directly or
indirectly connects person k to j, but no directed path connects j to k. At the extreme, the reference group
for person j might be the entire population while that of person k might be this person alone. It is sometimes
assumed in applications that reference groups are symmetric, with person k being a member of j’s group if
and only if j is a member of k’s group. In such cases, reference groups partition the population into mutually
exclusive and exhaustive sub-populations.
While the reference-group notation G(j) makes the group person-specific, it does not permit the
group to be treatment-specific. I could expand the notation to G(j, t ), letting the group vary with person j’s
own potential treatment, or even to G(j, t ), letting it vary with the entire potential treatment vector.
However, I will reserve the term reference group for cases in which the group who interact is the same,
whatever the treatment vector may be. The general idea of assumption CTR covers cases in which the
persons who interact vary across treatments, but I will not refer to these cases as interactions within reference
Given that reference groups are treatment-invariant, they necessarily are non-manipulable. That is,
a planner cannot use the treatments in T to change a person’s reference group. The general idea of
assumption CTR covers cases in which a planner can manipulate the group with whom a person interacts.
Consider inference on y (t ). The researcher knows the value of y (t ) if and only if z
Applying (3), the identification region for P[y(t )] is
(4) Ç{P[y(t )]} = [P(y*z = t )AP(z = t ) + äAP(z
t ) , ä 0 Ä ].
Two polar cases of interactions within reference groups are unrestricted interactions, where all
reference groups are the entire population, and individualistic treatment response, where all reference groups
are single persons. In the former case, G(j) = J for all j 0 J. Then (4) becomes
(5) Ç{P[y(t )]} = [P(y*z = t )AP(z = t ) + äAP(z
t ), ä 0 Ä ].
All persons face the same realized treatment vector z . Hence, P(z = t ) = 1 if z = t and P(z = t ) = 0 if z
t . Thus, Ç{P[y(t )]} = P(y) if z = t and Ç{P[y(t )]} = Ä if z
t . This result justifies the statement in
the Introduction that observation of realized treatments and outcomes per se is uninformative about the
outcome distribution with a counterfactual treatment vector.
When response is individualistic, G(j) = j for all j 0 J. Then (4) becomes
(6) Ç{P[y(t )]} = [P(y*z = t)AP(z = t) + äAP(z
t), ä 0 Ä }.
Result (6) extends my earlier work on identification with individualistic treatment response. I have earlier
reported (6) for the special case in which the potential treatment vector t assigns the same treatment to all
members of the population; see, for example, Manski . Then the treatment t on the righthand side of (6) is the common treatment, say ô, and t = (ô, ô, . . . . , ô). Now (6) holds in the general case
where t may be any treatment vector, possibly assigning different treatments to different persons.
The size of region (6) varies inversely with the magnitude of P(z = t); that is, with the fraction of the
population who have the same realized and potential treatments. Point-identification occurs if and only if
P(z = t) = 1, which requires that z = t if J is a countable population and permits deviation of z from t only
on a negligible set of persons when J is a continuum. The identifying power of assumption ITR appears
when 0 < P(z = t) < 1. Region (6) grows smoothly from the singleton P(y) to the entire space Ä as P(z = t)
decreases from 1 to 0. This contrasts sharply with the unrestricted-interaction region (5), which equals Ä
whenever P(z = t) < 1.
2.1.3. Distributional Interactions
Region (4) characterized identification under the sole assumption that interactions occur within
reference groups. Applied research often assumes that interactions are distributional. A distributional
interaction is one where the outcome of person j may vary with his own treatment and with the distribution
of treatments among other members of the reference group, but is invariant with respect to the size of the
group and permutations of the treatments received by other members of the group. The distributionalinteraction assumption is empty when a reference group contains one or two persons, but is meaningful when
the reference group is larger.
Consider, for example, vaccination of some children in a community. When considering illness from
an infectious disease, one might think it credible to take each child’s reference group to be the set of children
who attend the same school. One might additionally think it credible to assume that each child’s illness
outcome may depend on his own vaccination treatment and on the rate of vaccination in his school, but not
on the identities of the specific other schoolmates vaccinated.
Formally, let C = T × Ä , where Ä is the space of all distributions on T. For j 0 J with *G(j)* > 1,
let G(j)/j denote the reference group exclusive of person j himself. For t 0 T , let c (t ) = [t , Q(t
) is the within-group distribution of the treatments in t
. That is, for ô 0 T, Q(t
= ô) is the fraction
of the persons in G(j)/j who receive treatment ô when t is the potential treatment vector. For j 0 J with *G(j)*
= 1, the set G(j)/j is empty. To formally cover this case, I define Q(t
) = 0/, where 0/ denotes the empty set.
With this definition of C and c (A), the abstract constant-response region (3) takes the form
(7) Ç{P[y(t )]} = {[P(y*z = t, Q(z ) = Q(t )]AP[z = t, Q(z ) = Q(t )] + äAP(z
t or Q(z )
Q(t ), ä 0 Ä }.
This region is a subset of the region (4) obtained when it was assumed only that interactions occur within
reference groups. Here the researcher knows the value of y (t ) when the event [z = t , Q(z
occurs. Previously, y(t ) was known when z
. The latter event implies the former one.
Functional Interactions
Applied research often assumes not only that interactions are distributional but also that Q(t
affects outcomes solely through some functional of the distribution, say F(t
). A leading case is the mean
interaction, where treatments are real-valued and F(t
), the within-group mean of the treatments
. A mean interaction is equivalent to a distributional interaction when set T has two treatments. It is
a stronger assumption when there are more than two.
Another case of applied interest is the supremum interaction, where treatments are ordered and
). Suppose that a treatment is information that is communicated within a reference group.
Suppose that information treatments are ordered, with ô > ôN meaning that a person with treatment ô receives
all of the information in ôN, plus some more. Then communication within the group ensures that person j
effectively receives treatment sup(t
Whatever functional F may be, let C = T × Ö, where Ö is the range space for F. Let c (t ) = [t ,
)]. Then (3) becomes
(8) Ç{P[y(t )]} =
{[P(y*z = t, F(z ) = F(t )]AP[z = t, F(z ) = F(t )] + äAP(z
t or F(z )
F(t ), ä 0 Ä }.
This region is a subset of the region (7) obtained when it was assumed only that interactions are
distributional. Here the researcher knows the value of y (t ) when the event [z = t , F(z
)] occurs.
Previously, y(t ) was known when [z = t , Q(z
)]. The latter event implies the former one.
2.2. Semi-Monotone Treatment Response
The constant-response assumptions considered in Section 2.1 were nested. Individualistic treatment
response weaky strengthens functional interactions, which weakly strengthens distributional interactions,
which in turn weakly strengthens interactions within a reference group. The various identification regions
presented above were correspondingly nested sets. However, even the assumption of individualistic
treatment response has only limited identifying power.
Smaller identification regions emerge if the assumption that response is constant within level sets
of c(A) is combined with the assumption that response is semi-monotone across level sets. Section 2.2.1 poses
the assumption in abstraction and establishes its identifying power. Sections 2.2.2 and 2.2.3 consider the
important sub-cases of reinforcing and opposing interactions.
2.2.1. The Assumption in Abstraction
Suppose that some constant-response assumption has been imposed. Considering person j, let the
set C of effective treatments be partially ordered. Thus, given a pair of distinct values (c, cN) 0 C × C , either
c < cNor c > cN or (c, cN) are unordered, in which case I write c i cN. Let the outcome space Y be a subset of
the real line. Let t and s be two potential treatment vectors. The assumption of semi-monotone response
asserts that
(9) c (t ) $ c (s ) Y y(t ) $ y (s ).
This assumption strengthens assumption CTR, as the equality c (t ) = c (s ) is equivalent to the two
inequalities c (t ) $ c (s ) and c (t ) # c (s ).
Considering individualistic treatment response, Manski , Proposition S1 showed that
observation of realized treatments and outcomes combined with assumption SMTR yields a sharp bound on
any parameter of the outcome distribution that respects stochastic dominance. It is straightforward to extend
the argument to settings with social interactions.
Consider the outcome of person j when the treatment vector is t . Let y / inf Y and y / sup Y be
the logical lower and upper bounds on outcomes. Combining the empirical evidence with assumption SMTR
yields this sharp bound on y (t ):
(10) c (t ) < c (z ) Y y # y (t ) # y
c (t ) = c (z ) Y y(t ) = y
c (t ) > c (z ) Y y # y (t ) # y
c (t ) i c (z ) Y y # y (t ) # y .
Let y (t ) and y (t ) denote the lower and upper bounds on y (t ) stated in (10). Given that (10) holds
for all j 0 J, the population distribution of y (t ) stochastically dominates that of y(t ), which in turn
dominates that of y (t ). Given that (10) exhausts the available information, the identification region for
P[y(t )] is
(11) Ç{P[y(t )]} = {ä 0 Ä : P[y (t )] $ ä $ P[y (t )]},
where $ denotes the weak stochastic dominance relationship.
Let D be any parameter of the outcome distribution that respects stochastic dominance. For example,
D may be a quantile or the mean of an increasing function of the outcome. Region (11) immediately yields
this sharp bound on D[y(t )]:
(12) D[y (t )] # D[y(t )] # D[y (t )].
Considering individualistic treatment response, Manski , Corollaries S1.1 – S1.3 gave the
explicit form of bound (12) for various D-parameters. The extensions to settings with social interactions are
immediate. In particular, the result for the mean outcome E[y(t )] is
(13) y AP[c(t ) < c(z ) c c(t ) i c(z )] + E[y*c(t ) $ c(z )]AP[c(t ) $ c(z )] # E[y(t )]
# y AP[c(t ) > c(z ) c c(t ) i c(z )] + E[y*c(t ) # c(z )]AP[c(t ) # c(z )].
2.2.2. Reinforcing Interactions
I defined reinforcing interactions verbally in the Introduction. Formally, let treatment set T be
partially ordered. Let person j have reference group G(j) and let T
inherit the partial ordering on T. That
is, given two treatment vectors t and s , let c (t ) $ c (s ) mean that [t $ s , all k 0 G(j)]. A reinforcing
interaction occurs when
(14) [t $ s , all k 0 G(j)] Y y(t ) $ y (s ).
When (14) holds, the response function increases with the treatment that person j receives and with the
treatments of other members of the reference group. Thus, the treatments received by others reinforce a
person’s own treatment.
I earlier gave vaccination against an infectious disease as an example of an interaction that is credibly
reinforcing. Another is provision of tutoring to students in a classroom. It is reasonable to think that tutoring
a student weakly increases his achievement. It may also be reasonable to think that tutoring some students
weakly increases the achievement of all students in the classroom.
Reinforcing Distributional Interactions
The definition of a reinforcing interaction stated in (14) orders treatment vectors only when every
member of the reference group of person j receives at least as large a treatment with t
Suppose that the social interaction is distributional. Then we may strengthen the idea of a reinforcing
interaction by letting c (t ) $ c (s ) mean that [t $ s , Q(t
)]. A reinforcing distributional
interaction occurs when
(15) [t $ s , Q(t
)] Y y(t ) $ y (s ).
The event [t $ s , all k 0 G(j)] implies the event [t $ s , Q(t
)]. Hence, a reinforcing
distributional interaction orders all treatment pairs that are ordered by a reinforcing interaction, and possibly
more. It follows that the present identification region for P[y(t )] is a subset of the one obtained when the
interaction is only assumed reinforcing.
When person j’s reference group is large, the stochastic dominance inequality Q(t
appearing in (15) is well approximated by Q(t
), which includes j in the group distribution. The
latter inequality is simpler to use in some applications. I will use it in Section 2.3.
Reinforcing D-Interactions
A yet smaller identification region results when a distributional interaction is assumed to be a
functional interaction, where the functional is a parameter D that respects stochastic dominance. Now take
c(t ) $ c(s ) to mean that [t $ s , D(t
)]. A reinforcing D-interaction occurs when
(16) [t $ s , D(t
)] Y y(t ) $ y (s ).
The event [t $ s , Q(t
)] implies the event [t $ s , D(t
)]. Hence, a
reinforcing D-interaction orders all treatment pairs that are ordered by a reinforcing distributional interaction,
and possibly more. Therefore, the present identification region for P[y(t )] is a subset of the one obtained
with a reinforcing distributional interaction.
2.2.3. Opposing Interactions
An opposing interaction reverses the direction of the inequality relating a person’s outcome to the
treatments received by other members of his reference group. An opposing interaction occurs when
(17) [t $ s , {t # s , k 0 G(j)/j}] Y y(t ) $ y (s ).
When (17) holds, the response function increases with the treatment that person j receives and decreases with
the treatments of other members of the reference group. Thus, the treatments received by others act in
opposition to a person’s own treatment. I earlier gave occupation-specific training as an example of an
interaction that is credibly opposing.
Opposing distributional and D-interactions are defined in the obvious way. The former occurs when
(18) [t $ s , Q(s
)] Y y(t ) $ y (s ).
The latter occurs when
(19) [t $ s , D(s
)] Y y(t ) $ y (s ).
2.3. Illustration: Vaccination Against Infectious Disease
I will use a simple scenario of vaccination against infectious disease to illustrate the findings of
Sections 2.1 and 2.2. Let T = {0, 1}, with (ô = 1) denoting vaccination and (ô = 0) no vaccination. Let the
outcome of interest be a binary measure of health status, with y = 1 if a person remains in good health and
y = 0 if he becomes ill with the disease. Then sufficient statistics for the distribution P(y, z) of realized
treatments and outcomes are P / P(y = 1*z = 1), P / P(y = 1*z = 0), and p / P(z = 1). The realized
probability of good health is P(y = 1) = pP + (1 ! p)P .
Consider a potential treatment vector t that increases the population rate of vaccination from p to
some q > p. In particular, t sets t = 1 for all persons with z = 1 and for some of those with z = 0. The
objective is to learn P[y(t ) = 1]. One may interpret P[y(t ) = 1] retrospectively as the population rate of good
health that would have occurred if vaccination had been performed for all persons who were actually
vaccinated and for a specified subset of those who were not. Or one may interpret P[y(t ) = 1] prospectively
as the health rate that will occur if treatment vector t is applied to a new population that is identical in
composition to the study population.
The identification region for P[y(t ) = 1] depends on the maintained assumptions. I first assume that
treatment is individualistic and then add the assumption of monotone treatment response, in the sense that
vaccination never lowers health status and may improve it. I next permit distributional interactions and then
specialize to reinforcing distributional interactions.
2.3.1. Individualistic Treatment Response
Suppose that a person’s health status depends only on his own treatment. This assumption is not
credible when considering an infectious disease, but I begin with it to provide contrast with the findings when
social interactions are considered. The identification region under assumption ITR was given in (6). With
a binary outcome, (6) becomes the interval
(20) Ç{P[y(t ) = 1]} = [P(y = 1*z = t)AP(z = t), P(y = 1*z = t)AP(z = t) + P(z
Consider the fraction P(z = t) of the population whose realized and potential treatments coincide.
This includes the group of size p who realize treatment 1, all of whom would continue to receive it under t .
It also includes the group of size 1 ! q who realize treatment 0 and would continue to receive it under t .
Hence, P(z = t) = p + 1 ! q. Correspondingly, P(z
t) = q ! p. Observe that P(z
t) is the width of the
interval on the right-hand side of (20).
Consider P(y = 1*z = t), the probability of good health in the group with (z = t). It is the case that
(21) P(y = 1*z = t) = P(y = 1*z = t, z = 1)AP(z = 1*z = t) + P(y = 1*z = t, z = 0)AP(z = 0*z = t)
= P [p/(p + 1 ! q)] + P(y = 1*z = t, z = 0)A[(1 ! q)/(p + 1 ! q)].
The first equality applies the Law of Total Probability. Our derivation of P(z = t) shows that P(z = 1*z = t)
= p/(p + 1 ! q) and P(z = 0*z = t) = (1 ! q)/(p + 1 ! q). We have P(y = 1*z = t, z = 1) = P because z = 1 Y
t = 1. We have not yet encountered P(y = 1*z = t, z = 0), the probability of good health in the group who
realized treatment 0 and who would continue to receive 0 under t . This conditional probability, which
depends on t , is revealed by the empirical evidence once t is specified. Hence, all quantities on the right-
hand side of (21) are known.
2.3.2. Monotone-Individualistic Treatment Response
Continue to suppose that a person’s health status depends only on his own treatment. Also suppose
that treatment response is monotone in the sense that y(1) $ y (0) for all j 0 J. This is credible in settings
where vaccines do not have adverse side effects. Then vaccination never makes a person worse off and may
improve his health status.
The identification region is given by (13), which reduces in the present case to
(22) Ç{P[y(t ) = 1]} = [P(y = 1*t $ z)AP(t $ z), P(t > z) + P(y = 1*t # z)AP(t # z)].
The inequality t $ z holds in this illustration. Hence, P(t $ z) = 1, P(t > z) = q ! p, and P(t # z) = P(t = z)
= p + 1 ! q. Moreover, P(y = 1*t $ z) = P(y = 1) and P(y = 1*t # z) = P(y = 1*t = z), whose value was derived
in (21). The result is
(23) Ç{P[y(t ) = 1]} = [P(y = 1), q ! p + P(y = 1*t = z)A(p + 1 ! q)].
The lower bound is larger than the one obtained using assumption ITR alone. The upper bound is the same
as with assumption ITR alone.
2.3.3. Distributional Interactions
Now suppose that a person’s health status may depend on his own treatment and on the population
vaccination rate. Then the identification region is given by (7), which becomes
(24) Ç{P[y(t )] = 1} = [P(y = 1*z = t, p = q)AP(z = t, p = q),
P(y = 1*z = t, p = q)AP(z = t, p = q) + P(z
By assumption, q > p in this illustration. Hence, the identification region is . This result should be
expected, because increasing the vaccination rate makes it counterfactual for the entire population.
2.3.4. Reinforcing Distributional Interactions
Continue to suppose that a person’s health status may depend on his own treatment and on the
population vaccination rate. Also suppose that the interaction is reinforcing, with vaccination of an
individual reducing his chance of infecting others. Then (15) holds. Suppose that the population is large,
). Using this approximation, (15) reduces to
(25) t $ s 1 P(t = 1) $ P(s = 1) Y y(t ) $ y (s ).
The identification region is given by (13), which reduces in this case to
(26) Ç{P[y(t ) = 1]} = [P[y = 1*(t, q) $ (z, p)]AP[(t, q) $ (z, p)],
P[(t, q) > (z, p) c (t, q) i (z, p)] + P[y = 1*(t, q) # (z, p)]AP[(t, q) # (z, p)]].
Given that t $ z and q > p, it follows that P[(t, q) > (z, p)] = 1. Hence, (26) reduces to
(27) Ç{P[y(t ) = 1]} = [P(y = 1), 1].
The lower bound is the same as with the assumption of monotone-individualistic response. The upper bound
is 1 because a reinforcing distributional interaction permits the possibility that increasing the vaccination rate
from p to q completely eliminates disease transmission.
2.4. Estimation of Identification Regions with Data on a Random Sample of the Population
The identification analysis of Sections 2.1 and 2.2 supposed that one observes [c (A), y , z ; j 0 J].
Hence, for any potential treatment vector t , one observes [c (z ), c (t ), y ; j 0 J]. This enables computation
of the identification regions for P[y(t )] under assumptions CTR and SMTR, given in (3) and (11)
respectively. To recall, these are
(3) Ç{P[y(t )]} = {P[y*c(z ) = c(t )]AP[c(z ) = c(t )] + äAP[c(z )
c(t )], ä 0 Ä },
(11) Ç{P[y(t )]} = {ä 0 Ä : P[y (t )] $ ä $ P[y (t )]}.
Now suppose that one does not observe [c (z ), c (t ), y ; j 0 J]. Instead, one draws a random sample
of N persons, say J , and observes [c (z ), c (t ), y ; j 0 J ]. Then one may estimate regions (3) and (11) by
their sample analogs
(3N) Ç{P [y(t )]} / {P [y*c(z ) = c(t )]AP [c(z ) = c(t )] + äAP [c(z )
c(t )], ä 0 Ä },
(11N) Ç{P [y(t )]} / {ä 0 Ä : P [y (t )] $ ä $ P [y (t )]},
where P denotes the empirical distribution of J . If the population is uncountable, the laws of large numbers
for random sampling imply that each Ç{P [y(t )]} converges in various senses to the corresponding
Ç{P[y(t )]} as N 6 4. Thus, regions (3) and (11) may be estimated consistently.
This argument requires observation of sample members’ realized effective treatments [c (z ), j 0 J ],
not just their realized own treatments (z , j 0 J ). Excepting the special case of individualistic treatment
response, the effective treatments of sample members generically depend on the treatments received by non-
sample members. If one assumes only that sample member j 0 J has reference group G(j), one must observe
all of the treatments [z , k 0 G(j)]. If assumes a functional interaction, then it suffices to observe z and
). Importantly, one does not need to observe the outcomes realized by non-sample members.
Observation of the treatments received by non-sample members is realistic in some applied settings.
Realized treatments for the entire population may be set by known regulations, may be observable prices,
or may be recorded in accessible administrative databases. When population treatment data are not available
in these ways, a survey researcher might ask sample members to report the treatments received by their
reference groups.
When a researcher only observes the own treatments of sample members, not their effective
treatments, random sampling does not enable consistent estimation of identification regions (3) and (11).
In the presence of social interactions, observation of (z , j 0 J ) generically does not reveal [c (z ), j 0 J ].
Hence, one cannot determine how c (z ) is related to c (t ) for j 0 J .
Other sampling processes may enable consistent estimation in some settings. Suppose, for example,
that the population partitions into uncountably many reference groups, with a finite upper bound on group
size. Then it is easy to see that random sampling of groups, with observation of the realized treatments and
outcomes of all members of each sampled group, enables consistent estimation of potential outcome
distributions.
Researchers sometimes face sampling processes with intermediate inferential problems, where
effective treatments are partially observed. See Sojourner for analysis of treatment response in one
such setting.
3. Distributional Assumptions Using Instrumental Variables
This section combines the shape restrictions of Section 2 with distributional assumptions that use
instrumental variables. In research assuming individualistic response, an instrumental variable (IV) is a
specified function v / v(x, z) of the observed covariates x and realized treatments z. Assumptions typically
restrict how the conditional response distributions P[y(@)*w, v] may vary with v, where w / w(x, z) is another
function of (x, z). When studying treatment with social interactions, I will let v / v(x , z ) and w / w(x , z ).
To simplify the exposition, I will suppress w until Section 3.3, where it is necessary to make it partially
Various distributional assumptions may merit consideration. In research under assumption ITR,
where the objective is to infer P[y(ô)] for a specified ô 0 T, it has been common to assume statistical
independence (SI) or mean independence (MI); that is, P[y(ô)*v] = P[y(ô)] or E[y(ô)*v] = E[y(ô)]. These
assumptions extend directly to research on treatment with social interactions, the objective being inference
on P[y(t )] for a specified t 0 T . Then one may assume that P[y(t )*v] = P[y(t )] or E[y(t )*v] = E[y(t )].
Section 3.1 considers these assumptions in abstraction. The analysis is a simple extension of my
earlier work assuming individualistic response . To
illustrate, Section 3.2 considers a variation on the vaccination scenario of Section 2.3.
In research under assumption ITR, it has been common to point-identify P[y(ô)] by asserting
assumption SI with the realized treatment z as the instrumental variable. Section 3.3 extends the argument
to inference on P[y(t )] under assumption CTR, using c(z ) as the instrumental variable. I use an application
with informational treatments to illustrate.
Section 3.4 applies the analysis of Section 3.3 to settings with random assignment of realized
treatments. Analysis of random assignment is simple under assumption ITR, but subtle issues arise with
social interactions.
The discussion in Section 2.4 of estimation from sample data applies as well to the analysis of
Section 3. Hence, I will not discuss estimation here.
3.1. The Assumption in Abstraction
To begin, observe that all of the findings obtained in Section 2 hold if one poses a shape restriction
and considers identification of P[y(t )*v = í], where í 0 V, the support of v. One simply needs to condition
every reference to P on the event [v = í] and repeat the derivations. Let Ç{P[y(t )*v = í]} denote the
resulting identification region. The identification region for the collection of distributions {P[y(t )*v = í],
í 0 V} is the Cartesian product ×
Ç{P[y(t )*v = í]}. These results hold because the shape restrictions
of Section 2 operate separately on the response function of each member of the population. They restrict the
distribution of response only through aggregation of their implications for individual response.
Now introduce the statistical-independence assumption P[y(t )*v] = P[y(t )]. Then P[y(t )] must lie
within the intersection of the identification regions Ç{P[y(t )*v = í]}, í 0 V. Moreover, every distribution
in this intersection is a feasible value of P[y(t )]. Hence, the identification region for P[y(t )] is
(28) Ç{P[y(t )]} = 1 Ç{P[y(t )*v = í]}.
An analogous derivation holds for inference on E[y(t )] under the mean-independence assumption
E[y(t )*v] = E[y(t )]. In this case, the identification regions obtained in Section 2 are intervals of the generic
form [L (t ), U (t )], í 0 V. The region using assumption MI is the interval
(29) Ç{E[y(t )]} = [sup L (t ), inf U (t )].
í 0 V í 0 V
The assumptions used to derive these identification regions may be jointly testable. The empirical
evidence may reveal that the region in (28) or (29) is empty. If so, then some assumption is incorrect. When
an identification region is non-empty, one cannot reject the maintained assumptions. Of course, a failure to
reject the assumptions does not imply that they are correct.
3.2. Application to Vaccination
To illustrate, consider a vaccination scenario in which the population partitions into two reference
groups. Persons with v = 0 belong to one group and those with v = 1 belong to the other. Treatment
interactions may occur within but not across groups.
Suppose that the realized vaccination rate among persons with v = 0 is lower than among persons
with v = 1; thus, P(z = 1*v = 0) < P(z = 1*v = 1). Consider a potential treatment vector t that equalizes the
vaccination rates of the two groups at an intermediate level q. In particular, t sets t = 1 for all those with
(v = 0, z = 1) and for some of those with (v = 0, z = 0). It sets t = 0 for all those with (v = 1, z = 0) and
for some of those with (v = 1, z = 1). As a result, P(t = 1*v = 0) = P(t = 1*v = 1) = q. The objective is to
learn P[y(t ) = 1].
First consider inference under the assumption of a reinforcing distributional interaction. By the Law
of Total Probability,
(30) P[y(t ) = 1] = P[y(t ) = 1*v = 0]@P(v = 0) + P[y(t ) = 1*v = 1]@P(v = 1).
Application of (27) to the group with v = 0 shows that Ç{P[y(t ) = 1*v = 0]} = [P(y = 1*v = 0), 1]. A
derivation analogous to that yielding (27) shows that Ç{P[y(t ) = 1*v = 1]} = [0, P(y = 1*v = 1)]. The joint
identification region for P[y(t ) = 1*v = 0] and P[y(t ) = 1*v = 1] is the Cartesian product of the marginal
regions. Hence, the identification region for P[y(t ) = 1] is
(31) Ç{P[y(t ) = 1]} = [P(y = 1*v = 0)@P(v = 0), P(v = 0) + P(y = 1*v = 1)@P(v = 1)].
The lower bound occurs if the change in treatment from z to t has no positive health effect on those with
v = 0 and a negative effect on everyone with v = 1. The upper bound occurs if the change makes everyone
with v = 0 healthy and has no negative effect on those with v = 1.
Now consider inference when the assumption of a reinforcing distributional interaction is combined
with assumption SI, namely P[y(t ) = 1*v = 0] = P[y(t ) = 1*v = 1]. Then Ç{P[y(t ) = 1]} is the intersection
of the identification regions obtained above for P[y(t ) = 1*v = 0] and P[y(t ) = 1*v = 1]. Thus,
(32) Ç{P[y(t ) = 1]} = [P(y = 1*v = 0), P(y = 1*v = 1)].
Inspection of region (32) shows that the pair of assumptions used to derive the region are jointly
testable. Suppose the empirical evidence reveals that P(y = 1*v = 0) > P(y = 1*v = 1). Then region (32) is
empty. It follows that at least one of the assumptions is incorrect.
When region (32) is non-empty, it is natural to ask whether the maintained assumptions are credible.
The assumption of a reinforcing interaction seems sensible enough. It is less clear that the interaction is
distributional, as the structure of social networks may affect the transmission of disease.
It may be difficult to assess assumption SI. The fact that t equalizes the vaccination rates of the two
groups may be suggestive, but it does not per se imply equal health outcomes in the two groups. The
assumption may be credible if one somehow knows that members of the two groups have similar
susceptibility to infection and that similar processes are used to assign treatments in the two groups. In the
absence of such information, one may not be able to assess whether or not v is a valid instrumental variable.
3.3. Using Realized Treatments as Instrumental Variables
In research under assumption ITR, it is common to let v = z and assume that P[y(ô)] = P[y(ô)*z] for
a specified ô 0 T. This version of assumption SI may be motivated by knowledge that realized treatments
were randomly assigned, or it may be posed without clear knowledge of the assignment process. In any case,
assumption ITR implies that P[y(ô)*z = ô] = P(y*z = ô). Observation of realized treatments and outcomes
reveals P(y*z = ô) if and only if P(z = ô) > 0. Hence, taking the realized treatment z to be an instrumental
variable that is statistically independent of y(ô) point-identifies P[y(ô)] if and only if P(z = ô) > 0.
An extension of the above familiar result holds for analysis of treatment response under assumption
CTR, the instrumental variable being the realized effective treatment c(z ). Section 3.3.1 derives the
extended result. Section 3.3.2 gives an illustrative application to information treatments.
3.3.1. Identification Using Assumptions CTR and SI
Let the previously suppressed conditioning covariates w include c(t ) and perhaps other functions
of x . It is important to the present analysis to explicitly condition on c(t ). I will continue to suppress other
components of w to simplify the exposition.
Assume that P[y(t )*c(t )] = P[y(t )*c(t ), c(z )] for a specified t . This version of assumption SI
reduces to the familiar P[y(ô)] = P[y(ô)*z] when t = (ô, . . . , ô) and response is individualistic. However, the
instrumental variable c(z ) differs from z when assumption CTR holds but not ITR.
To begin the derivation, let C / c
C and let C(t ) / {ã 0 C: P[c(t ) = ã] > 0}. To enable use of
elementary probability theory, this analysis assumes that C is countable. Successively apply the Law of Total
Probability, assumption SI, and assumption CTR to obtain
(33) P[y(t )] = 3 P[y(t )*c(t ) = ã]P[c(t ) = ã] = 3 P[y(t )*c(t ) = ã, c(z ) = ã]P[c(t ) = ã]
ã 0 C(t ) ã 0 C(t )
= 3 P[y*c(t ) = ã, c(z ) = ã]P[c(t ) = ã].
For each ã 0 C(t ), observation of realized treatments and outcomes reveals P[y*c(t ) = ã, c(z ) = ã] if and only
if P[c(t ) = ã, c(z ) = ã] > 0. By construction, P[c(t ) = ã] > 0 for all ã 0 C(t ). Hence, the empirical evidence
reveals P[y*c(t ) = ã, c(z ) = ã] if and only if P[c(z ) = ã*c(t ) = ã] > 0. It follows that the identification region
for P[y(t )] is
(34) Ç{P[y(t )]} = { 3 P[y*c(t ) = ã, c(z ) = ã]AP[c(t ) = ã] + äAP[c(t ) 0 C (t )], ä 0 Ä },
ã 0 C (t )
where C (t ) / {ã 0 C(t ): P[c(z ) = ã*c(t ) = ã] > 0} and C (t ) / {ã 0 C(t ): P[c(z ) = ã*c(t ) = ã] = 0}.
Observe that P[y(t )] is point-identified when P[c(t ) = ã] > 0 Y P[c(z ) = ã*c(t ) = ã] > 0. Then C (t )
is empty, C (t ) = C(t ), and (34) reduces to
(35) P[y(t )] = 3 P[y*c(t ) = ã, c(z ) = ã]AP[c(t ) = ã].
Contrariwise, P[y(t )] is entirely unknown when P[c(t ) = ã] > 0 Y P[c(z ) = ã*c(t ) = ã] = 0. Then C (t ) is
empty, C (t ) = C(t ), and Ç{P[y(t )]} = Ä .
Two Polar Cases
Region (34) simplifies in the polar case of individualistic response. Then C = T and C(t ) = T(t ) /
[ô 0 T: P(t = ô) > 0]. Also C (t ) = T (t ) / [ô 0 T(t ): P(z = ô*t = ô) > 0] and C (t ) = T (t ) / [ô 0 T(t ): P(z
= ô*t = ô) = 0]. Hence, (34) becomes
(36) Ç{P[y(t )]} = { 3 P(y*t = ô, z = ô)AP(t = ô) + äAP[t 0 T (t )], ä 0 Ä }.
ô 0 T (t )
Region (34) also simplifies in the polar case of an unrestricted interaction. Here, c (z ) = z for all
j 0 J. Thus, c(z ) has a degenerate distribution, implying that assumption SI necessarily holds. Observe that
P[c(t ) = ã] = 1 if ã = t and P[c(t ) = ã] = 0 otherwise. Hence, C(t ) contains the single element t . We have
P[c(z ) = t ] = 1 if z = t and P[c(z ) = t ] = 0 otherwise. Hence, Ç{P[y(t )]}is the singleton P(y) if z = t and
t . This is the same result as holds using the empirical evidence alone.
An Alternative Derivation
Derivation of (34) did not use the general finding (28) expressing the identification region with
assumption SI as the intersection of the regions across values of the instrumental variable. We can
alternatively use (28) to obtain (34).
For each ã 0 C(t ), application of (28) gives
(37) Ç{P[y(t )*c(t ) = ã]} = 1 Ç{P[y(t )*c(t ) = ã, c(z ) = ãN]}.
When ãN = ã, we have established that Ç{P[y(t )*c(t ) = ã, c(z ) = ã]} is the singleton P[y*c(t ) = ã, c(z ) = ã]
if P[c(z ) = ã*c(t ) = ã] > 0 and is Ä otherwise. When ãN
ã, Ç{P[y(t )*c(t ) = ã, c(z ) = ãN]} = Ä . Hence,
the intersection of regions in (37) is P[y*c(t ) = ã, c(z ) = ã] if P[c(z ) = ã*c(t ) = ã] > 0 and is Ä otherwise.
This result and the first equality in (33) imply (34).
Comparison with Assumption CTR Alone
It is instructive to compare the present identification region (34) with the region (3) obtained in
Section 2.1 using assumption CTR alone. When constant response is the only maintained assumption,
observation of y and z reveals y(t ) if and only if c (z ) = c (t ). When the empirical evidence does not reveal
jy (t ), it is uninformative about P[y(t )]. Hence, the size of region (3) grows directly with P[c(z )
When constant response is combined with assumption SI, the empirical evidence reveals P[y(t )*c(t )
= ã] if and only if P[c(z ) = ã*c(t ) = ã] > 0. Hence, the size of region (34) grows with P[c(t ) 0 C (t )].
3.3.2. Application: The Supremum Interaction with Information Treatments
To illustrate, let treatments be ordered items of information, as considered in our discussion of
supremum interactions in Section 2.1. Let the population partition into two reference groups, J and J .
Members of J have individualistic response and, thus, know only the information that they receive directly.
Those in J share information and, thus, know the information received by the most informed member of the
group. Hence, the effective treatments in J and J differ, with c (z ) = z for j 0 J and c (z ) = sup (z , k 0 J )
for j 0 J .
/ max T exist. Consider a potential treatment vector that gives every member of the
population a specified treatment ô < ô
. Then c (t ) = ô for all j 0 J, and assumption SI reduces to P[y(ô)]
= P[y(ô)*c(z )]. Application of (34) shows that P[y(ô)] = P[y*c(z ) = ô], provided that P[c(z ) = ô] > 0.
While this application is technically simple, assessment of the credibility of assumption SI is more
subtle. The informative component of assumption SI is P[y(ô)] = P[y(ô)*c(z ) = ô]. Here P[y(ô)] is the
distribution of outcomes when every member of the population has information ô, while P[y(ô)*c(z ) = ô]
is this distribution in the sub-population who actually know ô and nothing more. Suppose that P(z = ô*J )
> 0 and that P(z = ô
*J ) > 0. Then c (z ) = ô if and only if j 0 J and z = ô. Hence, P[y(ô)*c(z ) = ô] =
P[y(ô)*J , z = ô].
When is the equation P[y(ô)] = P[y(ô)*J , z = ô] credible? There is no unique answer to this question,
but these three conditions suffice:
(a) The distribution of treatment response is the same in both groups; that is, P[y(ô)*J ] = P[y(ô)*J ].
(b) The treatments realized by group J were generated by random assignment.
(c) Group J is sufficiently large that ex ante random assignment of treatments yields ex post statistical
independence of treatment response and realized treatments.
Condition (a) implies that P[y(ô)] = P[y(ô)*J ], while (b) and (c) together give P[y(ô)*J ] = P[y(ô)*J , z = ô].
While the above three conditions are not necessary to point-identify P[y(ô)], it is easy to show that
proper subsets of the conditions yield only partial identification. Suppose that a researcher finds it credible
to assume conditions (b) and (c), but not (a). The empirical evidence and the maintained assumptions then
point-identify P[y(ô)*J ] but are uninformative about P[y(ô)*J ]. Hence, the identification region for P[y(ô)]
is the set of distributions {P[y(ô)*J , z = ô]AP(J ) + äAP(J ), ä 0 Ä }.
Suppose that a researcher finds it credible to assume only condition (b). Situations where (b) holds
but not (c) may occur when treatments are randomly assigned to small groups. Then the empirical evidence
and maintained assumptions do not point-identify P[y(ô)*J ]. They only reveal that P[y(ô)*J ] lies in the set
of distributions {P[y(ô)*J , z = ô]AP(z = ô*J ) + äAP(z
ô*J ), ä 0 Ä }, which is the identification region for
P[y(ô)*J ] under assumption ITR alone. The identification region for P[y(ô)] is {P[y(ô)*J , z = ô]AP(z = ô*J )
ô*J ) + P(J )], ä 0 Ä }.
3.4. Random Assignment of Realized Treatments
To conclude this analysis of distributional assumptions using instrumental variables, I consider
random assignment of realized treatments. It is well appreciated that random assignment has strong
identifying power under assumption ITR. However, this is not always the case with social interactions.
I find that random assignment has different identifying power when reference groups are small and
large. Section 3.4.1 shows that the strong power of random assignment under assumption ITR extends to
settings where the population partitions into many small groups, whatever the nature of the within-group
interaction. Section 3.4.2 shows that random assignment may have no identifying power in large-group
settings with strong dependence, where the treatments assigned to a small set of persons may affect the
population outcome distribution. Section 3.4.3 shows that random assignment has limited identifying power
in large-group settings with distributional interactions.
I assume throughout that J is a large population, in the idealized sense of a continuum, and that the
realized treatments of all members of J are assigned randomly. The ex ante probability distribution on T
produced by the randomization mechanism is denoted q. Thus, q(ô) is the probability that a person is
assigned to treatment ô.
It has been common to perform experiments in which only a finite sample of a large population are
randomly assigned to treatment. Analysis of such experiments requires attention to statistical inference as
well as to identification. I do not undertake this analysis here.
3.4.1. Partition of the Population into Many Small Reference Groups
When J is a continuum and treatments are assigned at random to the entire population, the realized
treatments z are statistically independent of y(A) with ex ante probability one. Under assumption ITR, this
implies that P[y(ô)] = P[y(ô)*z = ô] = P(y*z = ô) for all ô 0 T. As indicated earlier, observation of realized
treatments and outcomes reveals P(y*z = ô) if and only if P(z = ô) > 0. It is the case that P(z = ô) = q(ô).
Hence, random assignment point-identifies P[y(ô)] when the randomization mechanism makes q(ô) > 0.
The above reasoning extends directly to situations in which the population partitions into a
continuum of reference groups, each of equal finite size. For example, the groups might be husband-wife
pairs or they might be pairs of twins. Then assumption ITR holds when the population is defined to be the
collection of groups rather than persons.
The reasoning further extends to situations in which the population partitions into finitely many subcollections of groups, each sub-collection being composed of a continuum of groups of a specific finite size.
For example, each sub-collection might be composed of households of a given size. One need just apply the
argument of the preceding paragraph to each sub-collection of groups.
3.4.2. Interactions with Strong Dependence
An important feature of interactions where the population partitions into many small groups is that
the treatments received by any small set of persons do not materially affect the population outcome
distribution. Let J d J be a small set of persons, in the formal sense that P(J ) = 0. Each member of J
interacts only with the members of his group. Group sizes are bounded in the setting of Section 3.4.1. It
follows that the set of persons who interact with J is small; that is, P[c G(j), j 0 J ] = 0. Hence, varying the
treatments received by J does not affect the outcome distribution in J as a whole.
In some situations, the treatments received by a small set of individuals materially affect the
population outcome distribution. Formally, suppose that there exists a J d J such that P(J ) = 0, but P[y(t )]
varies with (t , j 0 J ). I will say that treatment response then has strong dependence. I borrow this term from
the analysis of stochastic processes, where it connotes a process in which shocks in one period have “longrange” or “long-memory” implications.
Suppose that strong dependence is feasible under the maintained assumptions on treatment response.
Then random assignment of realized treatments generically does not have identifying power. The reason is
that random assignment does not pin down the treatments realized by particular persons—it only places an
ex ante probability distribution on their treatments. Yet strong dependence permits the outcome distribution
to vary with the specific treatments realized by particular persons.
Strong dependence is a broad idea, a full analysis of which is beyond the scope of this paper. To
demonstrate the negative implications for identification using random assignment, it suffices to consider the
special case of pervasive influence.
Pervasive Influence
Pervasive influence formalizes the idea of a population with a set of leaders, role models, or central
nodes. Formally, I will say that a set J of persons may have pervasive influence on population J if the
maintained version of assumption CTR is such that c (t ) varies with (t , k 0 J ) for all j 0 J. Thus, for each
j 0 J, c (t ) and c (s ) are the same effective treatment only if (t = s , k 0 J ).
Random assignment almost never has identifying power when the cardinality of J is infinite, and
it has no identifying power with positive ex ante probability when *J * is finite. This is apparent from
inspection of (34). We found in Section 3.3.1 that, given assumption SI, Ç{P[y(t )]} = Ä if P[c(t ) 0 C (t )]
= 1. When J may have pervasive influence, P[c(t ) 0 C (t )] = 1 if there exists any k 0 J such that z
Random assignment does not pin down the realized treatments (z , k 0 J )—it only establishes an ex ante
probability distribution for them. The ex ante probability that (z = t , k 0 J ) is J
q(t ). This probability
is generically less than one when *J * is finite and zero when *J * = 4. The only exception occurs when (t
= ô, k 0 J ) for some ô 0 T and the randomization mechanism has q(ô) = 1. This degenerate exception aside,
random assignment always yields positive ex ante probability that Ç{P[y(t )]} = Ä . Moreover, Ç{P[y(t )]}
= Ä with ex ante probability one when *J * = 4.
The above reasoning extends immediately to situations in which a finite set of persons may have
pervasive influence on a large sub-population of J, say J , where large means that P(J ) > 0. Then random
assignment yields positive ex ante probability that Ç{P[y(t )*J ]} = Ä . Moreover, Ç{P[y(t )]*J } = Ä with
ex ante probability one when *J * = 4.
3.4.3. Distributional Interactions in Large Groups
Strong dependence cannot occur in large groups with distributional interactions. By definition, a
distributional interaction is the version of assumption CTR in which c (t ) = [t , Q(t
)], where Q(t
the within-group distribution of the treatments in t
. If the group is large, in the formal sense that P[G(j)]
> 0, then variation in the treatments received by a small set of persons does not affect Q(t
). Hence, strong
dependence cannot occur.
In a large group, Q(t
). Random assignment implies that Q(z
) = q, the ex ante
probability distribution on T produced by the randomization mechanism. Hence, assumption SI takes the
form P[y(t )*t, Q(t )] = P[y(t )*(t, Q(t )), (z, q)]. This assumption is credible with random assignment.
Hence, we may apply result (34), which takes the form
(38) Ç{P[y(t )]} = { 3 P[y*(t, Q(t )) = (ô, ã), (z, q) = (ô, ã)]AP[(t, Q(t )) = (ô, ã)]
(ô, ã) 0 C (t )
+ äAP[(t, Q(t )) 0 C (t )], ä 0 Ä },
where C (t ) = {(ô, ã) 0 T × Ä : P[(z, q) = (ô, ã)*(t, Q(t ) = (ô, ã)] > 0} and C (t ) = {(ô, ã) 0 T × Ä : P[(z, q)
= (ô, ã)*(t, Q(t ) = (ô, ã)] = 0}.
Observe that random assignment yields the same distribution q of realized treatments in every large
reference group. Suppose that q places positive ex ante probability on every element of T. Then (ô, ã) 0
C (t ) if and only if ã = q. Hence, (38) reduces to
(39) Ç{P[y(t )]} = { 3 P[y*t = ô, Q(t ) = q, z = ô]AP[t = ô, Q(t ) = q] + äAP[Q(t )
q], ä 0 Ä }.
Thus, random assignment point-identifies the outcome distribution in groups where the potential treatment
distribution Q(t ) equals the ex ante treatment distribution q produced by the randomization mechanism. It
has no identifying power in groups where Q(t )
The above reasoning extends immediately to large groups with functional interactions. One need
only replace distribution Q(t ) with the relevant function F(t ), and q with F(q).
4. Models of Endogenous Social Interactions
4.1. Basic Concepts and Notation
Sections 2 and 3 studied identification of outcome distributions when shape restrictions and
distributional assumptions are placed directly on the response functions [y (@), j 0 J]. Models of endogenous
social interactions assume that there exists a vector of structural functions f / [f (@), j 0 J] such that the
vector of outcomes y (t ) / [y (t ), j 0 J] solve the structural equations
(40) y (t ) = f [t , t , y (t )], j 0 J.
Here t / (t , k 0 J, k
j) and y (t ) / [y (t ), k 0 J, k
j] are the treatment and outcome vectors for the
population exclusive of person j. Function f (@) permits y (t ) to be determined by j’s own treatment as well
as by the treatments and outcomes of other members of the population. The term exogenous interaction
describes t as an argument of f (@), while endogenous interaction describes y (t ).
An outcome vector y (t ) that solves (40) is said to be a reduced form of the structural equations. A
model is complete if (40) has a unique solution for all feasible structural functions f . A model is incomplete
if (40) may have multiple solutions or no solutions. Incomplete models are not abnormal. Structural
equations with multiple solutions may describe games with multiple equilibria. Those with no solutions may
describe games with no equilibria. A researcher may reasonably pose such models. See, for example,
Tamer and Brock and Durlauf .
Research in econometrics has long been concerned with identification of structural functions.
Observation of realized treatments and outcomes reveals that y = f (z , z , y ), j 0 J. Partial or point
identification of f may become feasible when the empirical evidence is combined with shape restrictions or
distributional assumptions on f .
Our objective is identification of outcome distributions under potential treatment vectors. Thus, we
are concerned with the use of endogenous-interactions models to identify the reduced forms of structural
equations, not with identification of structural equations per se. Let t be a counterfactual treatment vector.
A model has identifying power for P[y(t )] if the empirical evidence and the maintained assumptions on f
imply restrictions on P[y(t )].
Section 4.2 characterizes in abstraction the identifying power of complete and incomplete models.
One may obtain more explicit findings by studying particular classes of models. To illustrate, I consider two
familiar linear models. Section 4.3 examines linear models of interactions between pairs of persons. Section
4.4 studies linear models of mean interactions in large reference groups. Sections 4.3 and 4.4 comment on
estimation from sample data, as well as on identification.
4.2. The Identifying Power of Complete and Incomplete Models
4.2.1. Complete Models
It is easy to characterize abstractly the identifying power of complete models. Suppose the empirical
evidence and maintained assumptions imply that the vector of structural functions lies in a set Ö of feasible
vectors. Suppose that (40) has a unique solution for each f 0 Ö, denoted y (t , f ). Let P[y(t , f )] denote the
distribution of outcomes when y (t , f ) is the population outcome vector. Then the set of feasible potential
outcome distributions is {P[y(t , f )], f 0 Ö}.
The above shows that point identification of f is a sufficient condition for point identification of
P[y(t )]. Point identification of f means that Ö is a singleton. Hence, the set {P[y(t , f )], f 0 Ö} is a
singleton.
Importantly, point identification of f is not necessary for point identification of P[y(t )]. Indeed, the
outcome distributions for all potential treatment vectors may be point-identified when f is just partially
identified. I will give illustrative cases in Sections 4.3 and 4.4.
4.2.2. Incomplete Models with Solutions in all States of Nature
Next consider incomplete models having at least one solution to (40) for every feasible value of fJ
and multiple solutions for some values. For each f 0 Ö, let Õ(t , f ) denote the set of solutions to (40). Then
the set of feasible outcome distributions is {P[y(t , f )], y (t , f ) 0 Õ(t , f ), f 0 Ö}.
Now P[y(t )] is generically partially identified. The outcome distribution is point identified only
when all solutions to (40) are permutations of one another, in the sense that all feasible outcome vectors
[y (t , f ) 0 Õ(t , f ), f 0 Ö] yield the same outcome distribution. This is a special circumstance even when
f is point identified.
Researchers sometimes transform incomplete models into complete ones by combining the structural
equations with “equilibrium selection” assumptions predicting the solution to (40) that will occur among the
set of possible solutions. The credibility of such assumptions must be assessed on a case by case basis.
4.2.3. Incomplete Models with No Solution in Some States of Nature
Finally, consider incomplete models having no solution to (40) for some feasible value of f . There
are at least two distinct ways to reasonably interpret non-existence of a solution.
One might interpret non-existence to mean that the structural vector under consideration is not
feasible. One then eliminates the vector from Ö. This done, the situation considered in this section logically
cannot occur.
Alternatively, one might interpret non-existence to mean that the endogenous-interactions model is
silent on the population outcome vector. Then the model has no identifying power. This interpretation is
common in game theory, where a finding that no equilibrium exists is taken to mean that the specified
equilibrium concept makes no prediction about the actions chosen by players.
4.3. Models of Interactions Between Pairs of Persons
Let the population partition into a set K of reference groups composed of pairs of persons. Formally,
J = [(k1, k2), k 0 K], where (k1, k2) is the ordered pair of persons in group k. For each t 0 T and k 0 K, the
outcomes [y (t ), y (t )] solve the pair of simultaneous equations
(41a) y (t ) = f [t , t , y (t )],
(41b) y (t ) = f [t , t , y (t )].
A model of this type might be used to study labor supply in a population of married couples. Let the
ordered pairs be husbands and wives. Let the outcome of interest be hours worked. Let the treatment be a
person’s market wage. One may think it reasonable to assume that labor-supply interactions occur only
within couples, not between them. Within couples, a person’s labor supply may depend on his or her own
wage, the wage of the spouse (an exogenous interaction), and the spouse’s labor supply (an endogenous
interaction).
In the absence of further assumptions, the solution to equations (41) may be any function of (t , t ).
Thus, the endogenous-interactions model thus far restricts the response functions [y (@), j 0 J] only by
requiring that interactions occur within the reference groups K. Imposition of further assumptions may yield
stronger restrictions on response functions.
4.3.1. Linear Models
Empirical researchers often assume the linear model
(42a) y (t ) = á + â t + â t + ã y (t ) + u ,
(42b) y (t ) = á + â t + â t + ã y (t ) + u .
Here (á , . . . , ã ) are parameters and (u , u ) are person-specific variables. Unless ã ã = 1, the implied
reduced form is
á + ã á â + ã â â + ã â u + ã u
(43a) y (t ) = ———— + ————– t + ————– t + ————–
1 ! ã ã 1 ! ã ã 1 ! ã ã 1 ! ã ã
/ ö + ö t + ö t + e ,
á + ã á â + ã â â + ã â u + ã u
(43b) y (t ) = –———– + ————– t + ————– t + ————–
1 ! ã ã 1 ! ã ã 1 ! ã ã 1 ! ã ã
/ ö + ö t + ö t + e ,
where ö / (ö , . . . , ö ) are composite parameters and (e , e ) are composite variables.
The linear model of endogenous interactions posed in (42) implies that the response functions
derived in (43) are linear in treatments. Slope parameters may vary within reference groups but not across
them. For example, if applied to study the labor supply of couples, (43) permits husbands and wives to have
different slope parameters, but it requires all husbands (and all wives) to have the same labor supply
responses to wages.
Although model (42) makes strong assumptions that may lack foundation, it does not yet enable
prediction of outcomes under potential treatment vectors. The reason is that the model does not yet restrict
the person-specific variables (u , u ), k 0 K. Researchers have entertained various assumptions, with the
objective of point identification of the structural parameters (á , . . . , ã ). However, our objective is
identification of outcome distributions under potential treatment vectors, not identification of the structural
parameters.
Leaving aside the question of credibility, a simple way to point-identify outcome distributions is to
assume that E(u , u *z , z ) = 0. Given this mean-independence assumption, evaluation of (43) with the
realized treatments and outcomes yields the linear mean regressions
(44a) E(y *z , z ) = ö + ö z + ö z ,
(44b) E(y *z , z ) = ö + ö z + ö z .
The empirical evidence reveals E(y *z , z ) and E(y *z , z ) on the support of (z , z ). Hence, the parameters
ö are point-identified if the support of (1, z , z ) is not contained in a linear subspace of R .
From here, a short argument shows that P[y(t )] is point-identified. Knowledge of ö, combined with
observation of realized treatments and outcomes, implies knowledge of [(e , e ), k 0 K]. Knowledge of ö
and [(e , e ), k 0 K] implies knowledge of all of the response functions [y (@), y (@), j 0 J]. This yields
knowledge of P[y(t )] for all t 0 T .
Observe that point-identification of the six reduced-form parameters ö does not imply point-
identification of the eight structural parameters (á , . . . , ã ). Indeed, the structural parameters are not pointidentified under the assumptions maintained above. This illustrates the general point that point identification
of a complete endogenous-interactions model is not necessary for point identification of potential outcome
distributions.
Estimation from Sample Data
It remains to discuss estimation from finite-sample data. Econometric analysis of the structural
equations (42) usually presumes that one draws a random sample of groups, with observation of the realized
treatments and outcomes of both members of each sampled group. This obviously enables consistent
estimation of regressions (44a)–(44b). However, sampling groups is not necessary.
Suppose, as in Section 2.4, that one draws a random sample J of persons from the population. With
ex ante probability one, this sample will contain at most one person from any group. Nevertheless, the data
enable consistent estimation of the regressions (44) if one observes the effective treatment (z , z ) of each
sampled person j. The sub-sample who hold role 1 in their groups may be used to estimate the parameters
of (44a), while the sub-sample who hold role 2 are used to estimate (44b). One need not observe the
outcomes of non-sampled group members.
4.4. Models of Distributional Exogenous and Endogenous Interactions in Large Groups
Let the population partition into a set of reference groups characterized by values for a covariate x.
Thus, all persons with the same value of x belong to the same reference group. Let each group be large, and
suppose that distributional exogenous and endogenous interactions may occur within each group. Thus, for
each t 0 T and x 0 X, outcome y (t ) solves the equation
(45) y (t ) = f {t , P(t*x ), P[y(t )*x ]},
where P(t*x ) and P[y(t )*x ]} are the distributions of treatments and outcomes in the group who have
covariate value x .
A model of this type might be posed to study illness from an infectious disease. Let reference groups
be metropolitan areas. Let the outcome of interest measure health status. Let the treatment be binary, taking
the value one if a person is vaccinated and zero otherwise. One may think it reasonable to assume that
interactions occur only within metropolitan areas, not between them. Within an area, illness may depend on
a person’s own vaccination status, on the vaccination rate for the area population (an exogenous interaction),
and on the illness rate for the area population (an endogenous interaction).
In the absence of further assumptions, model (45) restricts the response functions [y (@), j 0 J] only
by requiring that interactions occur within the reference groups defined by values of x. Importantly, the
model thus far does not imply that interactions are distributional in the sense of Section 2.1.3. The reason
is that (45) permits each person’s own treatment to affect his own outcome in a distinct manner. Hence,
P[y(t )*x ] may vary with the group treatment vector t
, not just with the group treatment distribution P(t*x ).
4.4.1. Linear Models
Empirical researchers often assume the linear-in-means model
(46) y (t ) = á + â t + â E(t*x ) + ãE[y(t )*x ] + u .
Here (á, â , â , ã) are parameters and u is a person-specific variable. Taking expectations of both sides,
conditional on x , yields the equilibrium condition
(47) E[y(t )*x ] = á + (â + â )E(t*x ) + ãE[y(t )*x ] + E(u*x ).
Unless ã = 1, the unique equilibrium value of E[y(t )*x ] is
á â + â E(u*x )
(48) E[y(t )*x ] = ——— + –——– E(t*x ) + ———– .
1 ! ã 1 ! ã 1 ! ã
Insertion of the right-hand side of (48) into (46) yields the reduced form
á ãâ + â ã
(49) y(t ) = ——— + â t + –—–—– E(t*x ) + ——– E(u*x ) + u .
1 ! ã 1 ! ã 1 ! ã
Thus, the linear model of endogenous interactions posed in (44) implies that the response functions derived
in (49) are linear in treatments, the slope parameters for own treatments and group-mean treatments being
the same for all members of the population.
Although model (46) makes strong assumptions that may lack foundation, it does not yet enable
prediction of outcomes under potential treatment vectors. The reason is that the model does not yet restrict
the person-specific variables (u , j 0 J). Researchers have studied identification of the structural parameters
under various assumption; see Manski . However, our objective is identification of outcome
distributions under potential treatment vectors, not identification of the structural parameters.
Leaving aside the question of credibility, a simple approach is to impose the mean-independence
assumption E(u*z, x) = 0. With this assumption, evaluation of (49) with the realized treatments and
outcomes yields the linear mean regression
(50) E(y*z, x) = ——— + â z + –—–—– E(z*x) / ö + ö z + ö E(z*x),
1 ! ã 1 ! ã
where ö / (ö , ö , ö ) are composite parameters. The empirical evidence reveals E(y*z, x) on the support
of (z, x). Hence, the parameters ö are point-identified if the support of [1, z, E(z*x)] is not contained in a
linear subspace of R .
From here, a short argument shows that P[y(t )] is point-identified. Knowledge of ö, combined with
observation of realized treatments and outcomes, implies knowledge of (u , j 0 J). Knowledge of ö and (u ,
j 0 J) implies knowledge of all of the response functions [y (@), j 0 J]. This yields knowledge of P[y(t )] for
all t 0 T .
Observe that point-identification of the three reduced-form parameters ö does not imply point-
identification of the four structural parameters (á, â , â , ã). Structural parameter â is point-identified under
the assumptions maintained above, but (á, â , ã) are not. This again illustrates that point identification of
a complete endogenous-interactions model is not necessary for point identification of potential outcome
distributions.
Estimation from Sample Data
Finally, consider estimation from finite-sample data. The realized effective treatment for a person
with covariate x is his own treatment and the group mean treatment E(z*x). Suppose that one draws a
random sample J of persons from the population and observes the realizations (x , y , z ; j 0 J ). This enables
consistent nonparametric estimation of E(z*x). A linear least-squares fit of the observed outcomes to the
observed own treatments and estimates of E(z*x) consistently estimates the parameters of regression (50).
5. Conclusion
This paper has developed a formal language for study of treatment response with social interactions,
and has used it to derive a spectrum of new findings on identification. The basic idea is simple. I first
defined individual treatment response to be a function of the entire vector of treatments received by the
population. I then studied identification when shape restrictions and distributional assumptions are placed
on the response functions.
An early key result was that the traditional assumption of individualistic response is a polar case
within the broad class of constant response assumptions, the other pole being unrestricted interactions.
Important non-polar cases are interactions within reference groups and distributional interactions. I showed
that findings on identification obtained earlier under assumption ITR extend to assumption CTR. These
include identification with assumption CTR alone and when this shape restriction is strengthened to semimonotone response.
I next studied distributional assumptions using instrumental variables. Here too, findings obtained
previously under assumption ITR extend when assumptions of statistical or mean independence are invoked
in settings with social interactions. However, these positive findings had to be tempered. The extended
version of assumption SI has no power to identify counterfactual outcome distributions when social
interactions are unrestricted. When interactions are restricted, the extended assumption may not be credible
even when y(@) and z are statistically independent. Random assignment of realized treatments has strong
identifying power when reference groups are small, but only limited power when distributional interactions
occur in large groups, and generically no power in settings with strong dependence.
The final part of the paper considered models of endogenous social interactions. I emphasized that
identification of structural equations differs from identification of potential outcome distributions. I
compared the identifying power of complete and incomplete models. Analysis of two familiar linear models
illustrated that point identification of a complete model is not necessary for point identification of potential
outcome distributions.
Looking beyond the specific findings reported here, the formal language developed in this paper
enables study of identification under other shape restrictions and distributional assumptions of potential
interest. Considering shape restrictions, assumptions CTR and SMTR address the existence and sign of
treatment interactions but do not restrict magnitudes. One may want to relax the binary idea that person k
either is or is not a member of person j’s reference group. Instead, one might a priori bound the extent to
which k’s treatment may affect j’s outcome. Or one may find it credible to strengthen assumption SMTR
by posing concavity, convexity, or other second-order shape restrictions. A starting point for future analysis
is the Manski study of concave-monotonicity under assumption ITR.