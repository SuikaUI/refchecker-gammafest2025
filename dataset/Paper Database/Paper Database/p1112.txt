Received November 3, 2020, accepted November 9, 2020, date of publication November 16, 2020,
date of current version November 25, 2020.
Digital Object Identifier 10.1109/ACCESS.2020.3037935
A CNN-LSTM Model for Tailings Dam
Risk Prediction
1,2, JINGBIN QU1, QIANG MI1, AND QING LI
1Focused Photonics (Hangzhou) Inc., Hangzhou 310051, China
2National and Local Joint Engineering Laboratories for Disaster Monitoring Technologies and Instruments, China Jiliang University, Hangzhou 310018, China
Corresponding authors: Jun Yang ( ) and Qing Li ( )
This work was supported in part by the National Key Research and Development Program of China under Grant 2017YFC0804604, in part
by the Zhejiang Key Research and Development Program under Grant 2018C03040, and in part by the National Natural Science
Foundation of China under Grant 61701467.
ABSTRACT Tailings ponds are places for storing industrial waste. Once the tailings pond collapses, the
villages nearby will be destroyed and the harmful chemicals will cause serious environmental pollution.
There is an urgent need for a reliable forecasting model, which could investigate the tendency in saturation
line and issue early warnings. In order to ﬁll the gap, this work presents a hybrid network - Long-Short-Term
Memory (LSTM) and Convolutional Neural Network (CNN), namely CNN-LSTM network for predicting
the tailings pond risk. Firstly, the nonliear data processing method was composed to impute the missing value
with the numerical inversion (NI) method, which combines correlation analysis, sensitivity analysis, and
Random Forest (RF) algorithms. Secondly, a new forecasting model was proposed to monitor the saturation
line, which is the lifeline of the tailings pond and can directly reﬂect the stability of the tailings pond.
The CNN was used to identify and learn the spatial structures in the time series, then followed by LSTM
cells for detecting the long-term dependence. Finally, different experiments were conducted to evaluate the
effectiveness of the model by comparing it with other state-of-the-art algorithms. The results showed that
combing CNN with LSTM layers achieves the best score in mean absolute error (MAE), root-mean-square
error (RMSE) and coefﬁcient of determination (R2).
INDEX TERMS Deep learning, forecasting, LSTM network, real-time warning.
I. INTRODUCTION
At least 84 major tailings dam accidents were reported that
caused signiﬁcant damage from 1960–2020 all over the
world . The safety performance of tailings ponds can be
obtained by manual observation or measurement analysis
from speciﬁc sensors. The measurements include the saturation line, displacement, and deformation of the dam body,
seepage ﬂow, and dry beach length.
At present, a large number of researchers are devoted on
tailings pond monitoring and researchers are mainly focusing
on the stability status by monitoring data from sensors and
make early-warnings in time. Zhai et al. put forward the
strategic goals for the development of big data in geology, and
discussed the main problems and solutions facing the development of big data early-warning in geology. Huang et al. 
conducted a tailings pond monitoring and early-warning
The associate editor coordinating the review of this manuscript and
approving it for publication was Yongming Li
system based on three-dimensional GIS, the response time
of the safety monitoring and early warning system is less
than 5 seconds. Li et al. proposed a displacement analysis
method to monitor the displacement of tailings dam online.
In this method, the surface displacement and underground
displacement of the tailings dam could be determined by the
deformation coefﬁcient of the dam bank, and the stability of
the tailings dam was determined according to the displacement value. Yang et al. proposed a machine learning
prediction model to evaluate the saturation line of tailings
pond by water level of tailing dam and local rainfall. Hariri-
Ardebili and Pourkamali-Anaraki presented a classi-
ﬁcation method called FEM-SVM to provide the reliable
analysis of tailings pond, and the stability category of tailings
pond can be evaluated. Gao et al. established remote
sensing interpretation using high-resolution remote sensing
images. As a result, the type, quantity, and geographic location of tailings ponds could be derived from remote sensing
images. Necsoiu et al. used satellite radar interferometry
VOLUME 8, 2020
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see 
J. Yang et al.: CNN-LSTM Model for Tailings Dam Risk Prediction
to monitor the tailings sedimentation by analyzing the images
using synthetic aperture radar. Che et al. assessed the risk
of tailings pond by runoff coefﬁcient, which can simultaneously determine the safety performance of multiple tailings
dams. Dong et al. set up the alarm system based on the
cloud platform, where the phreatic line, rainfall, water level
and limit equilibrium state parameters were used to build the
prediction function, showing good performance in real-time
monitoring. Qiu et al. designed a monitoring system of
saturation line based on mixed programming. In this study,
the saturation line were calculated by ﬂow rate, precipitation transition. Tailings dams are usually located in remote
mountainous areas. The structure is very complicated and the
dam collapse problems are almost nonlinear. As a result, the
stability of the tailings pond cannot be directly observed.
Recently, with the advantages of handling almost any
non-linear and linear problems, whatever low- and highdimensions, neural network and machine learning methods
have been effectively composed in real-time risk analysis
and evaluation , . Zhao conducted a support
vector machine model to analyze the slope reliability. Later,
Hariri-Ardebili and Pourkamali-Anaraki et al. proposed
a support vector machine model to predict the tailing pond
structural behaviour. Similarly, the machine learning method
was also used in the crack damage detection task , .
However, the role of real-time monitoring cannot be equated
with early warning and forecasting. In
other words, risk
prediction methods could help people perceive risk before
it happens. With excellent ability to process time-series,
classic prediction model such as Auto-Regressive Integrated
Moving Average (ARIMA), neural network, and LSTM have
been used in prediction problems , . Prochazka 
detected the different time-series information by the seasonal
change using neural network, which clearly indicates that the
time series will be affected by time changes. Later, Tseng
et al. combined the neural network with seasonal time
ARIMA model to predict the production value of machinery
industry and the soft drink. The researchers analyzed and
identiﬁed the time series information of training data and
gave the prediction value for a few days in advance. Nevertheless, different from LSTM, the ARIMA model only gets
a high score at the condition of data with linear correlation
or without obvious ﬂuctuation. With the rapid development
of deep learning, the CNN and LSTM have been the most
popular networks. The CNN can ﬁlter out the noise data
and extract important features, achieving good performance
in images, speech, and time-series recognition , .
While the LSTM network has the ability to ﬁnd the linear
or non-linear time series information from the shallow and
deep network and combine it with current memory ,
 . In the study of the prediction of the saturation line,
Li et al. demonstrated the feasibility of using a single
LSTM model and the RMSE was less than 0.3. In the air
pollution prediction task, Tao et al. combined with the
addition of a one-dimensional convolution layers before the
GRU model, which obtained good prediction performance.
Similarly, Pan et al. combined CNN and GRU models
in the water level prediction research, which can predict the
water level in the next 5 days. Huang et al. combined the
VMD, CNN, and GRU algorithms to build a hybrid model,
which was used to predict the electricity price in different
seasons. Huang et al. designed a hybrid model that
combines deep neural networks with LSTM for predicting the
PM2.5, which can play a big role in the prevention and control
of PM2.5. These researches provides a good foundation for
the establishment of the CNN-LSTM model in the saturation
line prediction task. Considering the good performance of
CNN and LSTM in the prediction task, a hybrid model CNN-
LSTM may achieve better prediction performance to a large
As the most important factor of stability of tailings dams,
for every 1-meter drop in saturation line, the safety factor
of static stability is increased by 0.05 or more . High
saturation line will lead to a decrease of the dam stability
and even potentially cause leakage, landslide, and dam break
 , . Therefore, the saturation line is called the lifeline
of tailings dams . The stability of tailings dam can be
determined by their saturation line position accurately. It is
imperative to establish accurate models to predict the height
of saturation line and the security situation of tailings ponds.
However, the prediction research of tailings pond is almost
nonexistent and have poor generalization performance. For
this purpose, the goal is to propose a new model that can make
full use of the strengths of deep learning. In more detail, utilizing the hidden information of the previous saturation line,
the model will predict the value and tendency in the next few
days. The proposed model was evaluated by comparing with
state-of-the-art models, which shows the two kinds of CNN-
LSTM models are the most effective choice, especially the
CNN −LSTM2, where convolutional layers play important
roles in grabbing more abstract information and pass it on
to the LSTM layers. In this work, taking Jiande tailings pond,
China, as the study area, three main contributions of the study
are presented:
(1) Proposing a NI method using RF algorithm to ﬁll
missing values, which saved the time-series information of
data as much as possible.
prediction
performance
(3) Comparing the CNN-LSTM model with different
hyperparameters and with other state-of-the-art algorithms.
In this work, Pearson correlation coefﬁcient, feature
importance of RF model, and sensitivity analysis techniques was employed for the saturation line prediction, especially severed as tools of dimensionality reduction. After
the process of dimensionality reduction, only two kinds
of monitoring data were needed to restructure the saturation line data. On this basis, the hybrid CNN-LSTM
model was established for further tailings pond risk
VOLUME 8, 2020
J. Yang et al.: CNN-LSTM Model for Tailings Dam Risk Prediction
II. NUMERICAL INVERSION METHOD
In the monitoring data, due to the problems with sensors and
remote data transmission, a small part of the data was missing
or abnormal. The missing values may have been generated at
any time, and we cannot know when the missing values are
generated in advance. Missing values accounted for 1.82%
of all collected data. However, because missing values may
be generated continuously, for example, no data is generated
at 10 consecutive time points. In this case, the data cannot
provide valid time series information. Due to the existence
of missing data, the accuracy of the model will inevitably be
affected. It should be noticed that, for a time-series prediction
problem, missing value will cause the loss of time dependence, which will restrict the performance of the prediction
model , , , . Hence, we hope to keep the
data with good long-term and short-term continue information. Similarly, instead of deleting the abnormal data directly,
abnormal saturation line value could be reconstructed by the
NI system. The key to the solution is to ﬁnd the relationship
between missing value and other normal values. According
to the special relationship, the missing value could be reconstructed by other normal values. However, it is hard to ﬁnd
the precise computing relationship between the saturation
line values and other features. The method in this study was
to create a direct mapping from the inputs to the outputs,
using machine learning, which has the ability of ﬁnding the
relationship between inputs and outputs .
In other words, the NI method was composed to reconstruct the data from building the RF model. By doing so,
more data are achievable. In more detail, this NI system
includes three steps. First, considering that a large number of
parameters may have a strong correlation, it will be difﬁcult
to evaluate the importance of a single feature. Taking into
account the possibility of missing values for each parameter,
we should choose as few parameters as possible as the input
of NI method. The study site was Jiande copper mine tailings
pond, Hangzhou, Zhejiang Province, China. The monitored
data were collected by different sensors installed in Jiande
tailings pond, including the saturation line, displacement
and deformation of the dam body, seepage ﬂow, and dry
beach length sensors. They ensured that we could obtain
the desired monitoring data in real time. The research data
for this work were collected from the sensors mentioned
above from 2018-03-18 to 2019-04-29. For this study, the
data were from 5 different positions of tailings dam, specifically the 8, 13, 17, 21, 28, 33 stage of the tailings dam,
and the time interval between data was two hours. In total,
8215 data points were collected except the missing values.
Notably, the underground displacement and deformation sensors were assembled by multi-section sensors, including a
total of 60 single sensors, and each sensor measurement
was treated as a feature. The monitoring data had a total
of 82 features. The Pearson correlation coefﬁcients , 
were calculated and a heat map was drawn, which helps
eliminate the characteristics with a strong correlation (correlation coefﬁcient greater than 0.8). There were 64 left in the
FIGURE 1. The Pearson Correlation heat maps. The left side shows the
correlations among original data, the right side shows the correlations
among the remaining features.
ﬁnal data. The Pearson correlation coefﬁcients is deﬁned as
k P mini −P mi
i −(P mi)2]
i −(P ni)2]
where mi, ni are two different variables, k is the number of
variables. From Figure 1, the left side shows the correlations
among original data, and the right side shows the correlations
among the remaining features calculated by Pearson method.
Second, a RF model was composed, where the feature importance ranking generated by RF , was composed by
sorting the features according to how much accuracy they
contributed to the model during building process. Third,
posterior judgment is also required. We also interested in
which features have great impacts on the output of the trained
RF model. Thus, Sobol sensitivity analysis was adopted
to explore the contribution of the individual feature and
which parameters were inﬂuential and drive model outputs
more – , . After establishing the model through
RF, we judged the importance of the features according to
whether reducing the speciﬁed features will cause the model
accuracy to decrease, and ranked the importance of these
features. The feature importance ranking according to the RF
model and sensitivity analysis results are shown in Figure 2,
where the ﬁrst order represents ﬁrst-order sensitivity, total
order represents global sensitivity. They jointly selected x3
(rainfall) and x4 (water level) as the most important parameters. Subsequently, RF was used to create a direct mapping
ﬁnding the linear and nonlinear relationship between inputs
(x3,x4) and outputs (saturation line) to predict the saturation
line . Moreover, the abnormal data were deleted and
replaced with predicted data by NI method. It should be
noticed that rainfall and water level are factors that directly
affect the height of the saturation line, and they have a
similar time-series information. Therefore, the NI method in
this study greatly preserved the time-series information of
the saturation line and generate more achievable values for
further deep learning prediction.
III. CNN-LSTM PREDICTION MODEL
The study aims to develop the construction of a prediction
system for forecasting the saturation line the utilizing stateof-the-art LSTM and CNN networks. What has devoted to
the popularity of the convolutional layer is the fact that it
VOLUME 8, 2020
J. Yang et al.: CNN-LSTM Model for Tailings Dam Risk Prediction
FIGURE 2. The feature importance ranking according to the RF
model(left) and sensitivity analysis(right).
is good at extracting and recognizing the spatial structures
of the time series in the monitoring data, while the LSTM
networks achieve good performance in detecting long-shortterm dependence. In light of this, the principal idea of the
study is to combine the advantages of CNN and LSTM.
The proposed model in the study is named CNN-LSTM
model, including two versions, which include two parts. The
ﬁrst part is convolutional layers and max-pooling layers,
while the second part is the LSTM layers. The convolutional
layers encode the time-series information, while the LSTM
layer decodes the encoded the information from convolutional layers, which later will be ﬂattened and pushed into a
fully-connected layer. The CNN-LSTM auto-encoder model
is shown in Figure 3.
A. CONVOLUTIONAL AND POOLING LAYERS
The convolutional layers and max-pooling layers detect the
spatial structures and features of the saturation line values
together reducing the redundant characteristics, respectively.
More important, the convolutional layer could extract hidden
information in the time dimension, and usually pass higher
quality and denser features to the following layers.
More speciﬁcally, numerous useful convolved features
will be generated by convolution kernels, which are always
more important than the original features. As a subsampling
method, max-pooling layer saves certain information from
the convolved features and reduces the original data dimension. Speciﬁcally, the max-pooling layer helps to collect and
summarize the features from convolutional layer.
B. LONG SHORT-TERM MEMORY (LSTM)
As a popular type of recurrent neural network(RNN), LSTM
achieves good performance in detecting long-term dependencies. The problem named ‘‘lack of memory’’ was solved
after LSTM was proposed, which means the time-series
information cannot be effectively exhibited. Moreover, ‘‘vanishing gradient problem’’ prevents the RNN for long-time
dependencies detecting. The LSTM model is composed of
one memory unit and other three interactive gates: memory
cell, input gate, forget gate, and output gate. The memory
cell memorizes the state from the previous state. The input
gate determines how much input data of the network needs to
be saved to the unit state at the current moment t. The forget
gate controls whether the information will be discarded or
enters the input gate as reserved information at time t −1.
The output gate determines what information will be utilized
as the output. Eqs.(1)–(6) brieﬂy describe the update in the
LSTM layers.
it = σ(Vixt + Wiht−1 + bi)
ft = σ(Vf xt + Wf ht−1 + bf )
ect = tanh(Vcxt + Wcht−1 + bc)
ct = ft ⊗ct−1 + it ⊗ect
ot = σ(Voxt + Woht−1 + bo)
ht = ot ⊗tanh(ct)
The xt is the input data at time t, V∗and W∗denote the
weight matrices, h∗is the hidden state, b∗is the bias. σ
and tanh are the activation function of sigmoid and tanh,
respectively. it,ft,ct and ot stand for the input gate, forget gate,
memory cell and output gate, respectively. The ⊗means the
component-wise operation. Finally, output ht is calculated by
output gate and information in memory cell.
C. CNN-LSTM MODEL FOR PREDICTION
In the study, two different CNN-LSTM structures are utilized.
The ﬁrst version named CNN−LSTM1, which consists of two
convolutional layers of 16 and 32, a max-pooling layer ﬁlters
of 2, a LSTM layer of 50, a ﬂatten layer and a fully-connected
layer in order. The second version named CNN −LSTM2,
which includes one convolutional layer ﬁlters of 32, a maxpooling layer ﬁlters of 2, a ﬂatten layer, two LSTM layers
with unit size of 25, 50, a ﬂatten layer and a fully-connected
layer in order. Different parameters are compared for further
study. The two kinds of CNN-LSTM structures are shown in
Figure 4(a) and Figure 4(b).
IV. DATA PREPARATION
The study site is Jiande copper mine tailings pond, Hangzhou,
Zhejiang Province, China, where the amount of mineral copper metal accounts for about 60% of the province’s total
output. The main mineral products are copper concentrate,
zinc concentrate, sulfur concentrate, and by-product gold and
silver. The tailings pond level is III. Different geological hazard sensors are installed to monitor the surface displacement,
dam body internal displacement, saturation line height, water
level, rainfall, and seepage ﬂow , , , . The
research data for this work were collected from the sensors
mentioned above from 2018-03-18 to 2019-04-29, and the
time interval between data was two hours. The saturation
line value refers to the distance between the tailings dam and
the groundwater, which is measured by liquid level sensors.
VOLUME 8, 2020
J. Yang et al.: CNN-LSTM Model for Tailings Dam Risk Prediction
FIGURE 3. The CNN-LSTM auto-encoder model.
FIGURE 4. The architecture structure of proposed CNN −LSTM1 and CNN −LSTM2.
The tailings dam bank is a slope with steps every 2 meters.
Each step has a level sensor for measuring the saturation line,
and the monitoring data in the study comes from 5 different
positions, speciﬁcally the 8, 13, 17, 21, 28, 33 stage of the tailings dam. The 8, 13, 17, 21, 28, 33 only represent the position
of the measured saturation line. It should be mentioned that
the purpose is to utilize the hidden information of the previous
saturation line by the model, by ﬁnding out the relationship
between data in time series and spatial dimensions, the saturation line value and tendency in the next few days can be
predicted.
After collecting the data, the proposed NI system was
used to ﬁll the missing value, and the abnormal value were
deleted and replaced with predicted value by NI system.
Finally, 8365 data point were used for the further study.
The continuous monitoring value ensures a wide range of
time-series information. It should be noted that the CNN-
LSTM model trained and validated on the 8365 data. Among
the 8365 data, we randomly choose 70% of the data as the
training sets, the 10% as the validation set. The performance
of the models was evaluated on the rest 20% data, which is the
unseen part during the model building process. For keeping
VOLUME 8, 2020
J. Yang et al.: CNN-LSTM Model for Tailings Dam Risk Prediction
FIGURE 5. The monitored saturation line data at different positions.
the long-short-term dependence in the data, these data cannot
be shufﬂed as usual in traditional deep learning studies. Table
1 shows the describe of the collected data, and the ﬁrst three
rows labeled as 1,2 and 3 are historical monitoring data.
The distribution of monitoring data is shown in Figure 5.
As is shown in Figure 5, there is a wide range of variation
in the monitoring data. These changes are largely affected
by tailings pond operations and weather change, such as the
discharge of a large amount of wastewater and waste residue
on a certain day or the experience of heavy rain.
In order to eliminate the impact of different data dimensions on the calculation, we used Z −score normalization on
the data, the formula is as follows:
˙x = xt −µt
where xt is the input data, µt and σt are the averages and
standard deviation of data.
V. EXPERIMENT AND RESULTS
Two different version CNN −LSTM1 and CNN −LSTM2
were evaluated and compared to show the prediction performance. The simulation hardware environment of this experiment is Intel Core CPU i7-8750. GPU is NVIDIA GTX 1060,
and the memory is 6GB. The algorithm is implemented using
Python in conjunction with the TensorFlow framework.
The loss value in the training process of the proposed
model was calculated by root mean square error (RMSE).
In fact, loss calculation during model training and model
evaluation are not the same concept. The loss function is only
used in the process of model building, and the evaluation
function is used to evaluate the completed model. RMSE is
very effective in back-propagation calculation of loss values,
but not enough to accurately evaluate the performance of the
model. RMSE meets an important problem: let us consider
that although the model has an error of less than 0.5% in
the 98% dataset and 95% in the other 2% dataset, the overall
RMSE will be still very high, resulting in this model considered as a poor model. To solve this problem, mean absolute
error (MAE) was utilized to evaluate the performance of the
established model . What’s more, coefﬁcient of determination, denoted as R2 , was also used in the evaluation
methodology. It is the proportion of the total variation of the
dependent.
i=0(yt −yt)2
where yt represents the true value, b
yp represents predicted
saturation line value, yt represents average of true value, and
n is the count of data. Figure 6 shows the prediction results
of CNN −LSTM1 and CNN −LSTM2 on ﬁve different
monitoring sites about 1750 test sets.
In this study, we trained the model for 120 epochs with
a batch size of 64, RMSE as loss function and Adam for
optimizer. The Adam is an improved RMSProp optimizer
combining with the moments trick. It is worth noticing
that in order to reduce the feature loss during the convolutional layers, same padding operation was conducted
during this process. The last but not least, the forecasting
sequence length should be set properly to make sure the
VOLUME 8, 2020
J. Yang et al.: CNN-LSTM Model for Tailings Dam Risk Prediction
FIGURE 6. The prediction results of saturation line at different positions. The green line, red line, orange line represent the
prediction value from CNN −LSTM1, prediction value from CNN −LSTM2 and raw data, respectively. From the prediction result,
we can see the CNN −LSTM2 outperform the CNN −LSTM1.
FIGURE 7. The prediction scatters of saturation line at different positions using CNN −LSTM2.
model performance. The sequence length is the forecasting
horizon, which speciﬁes how many saturation line monitoring
data the model needs at a time to predict the next saturation
line value. Speciﬁcally, we divided the training data into
different sequences of equal length of 10, which means that
we use the ﬁrst 10 data to predict the 11th data. On the
one hand, considering that a longer sequence length will
occupy a huge computer memory, on the other hand, too
VOLUME 8, 2020
J. Yang et al.: CNN-LSTM Model for Tailings Dam Risk Prediction
TABLE 1. Some datasets used for saturation line prediction.
TABLE 2. Prediction performance of the proposed CNN −LSTM1 model
using MAE, RMSE and R2.
TABLE 3. Prediction performance of the proposed CNN −LSTM2 model
using MAE, RMSE and R2.
short time sequence can not detect the long-term and shortterm dependencies between data well. We found through
experiments that set the sequence length to 10 achieves better
performance than, for example, 4, 7, 20. The most important
thing for the hyperparameter selection of the model is the
learning rate of the network, which has a signiﬁcant inﬂuence
on time consumption until convergence . If the learning
rate is set too large, the loss function will be difﬁcult to
converge, resulting in a lower ﬁnal detection accuracy; On the
contrary, a small learning rate will lead to slow convergence
and increase the training time. At ﬁrst, we chose the learning
rate 0.0001, 0.01, 0.001, and then used cross −val −score
from Scikit −learnlib for cross-validation, which can help to
determine the optimal learning rate for each partial network
 . The result shows that the minimum MAE, RMSE, R2
can be obtained when the learning rate is 0.001.
prediction
performance
CNN −LSTM1 and CNN −LSTM2 are shown in Table 2 and
Table 3, respectively. NO.8, NO.13, NO.17, NO.21, NO.28,
TABLE 4. Performance comparison of several machine learning and deep
learning models.
NO.33 means the different station of saturation line mentioned above. The CNN −LSTM1 consists of two convolutional layers of 16 and 32, a max-pooling layer ﬁlters of 2,
a LSTM layer of 50, a ﬂatten layer and a fully-connected
layer. While the CNN −LSTM2 includes one convolutional
layer ﬁlters of 32, a max-pooling layer ﬁlters of 2, a ﬂatten
layer, two LSTM layers of 25, 50, a ﬂatten layer and a fullyconnected layer. From Table 2 and Table 3 combing with
Figure 6, we can conclude that in terms of RMSE, MAE
and R2, the proposed model CNN −LSTM2 outperform the
CNN −LSTM1. More speciﬁcally, the model which includes
one convolutional layer, one max-pooling layer, a ﬂatten
layer, two LSTM layers, a ﬂatten layer and a fully-connected
layer is more accurate. In fact, even the convolutional layer
is good at extraction and recognition, which could detect the
spatial features of the saturation line value well. The deep
and abstract features the convolutional layer learned may be
different from the ordinary time-series information from the
raw data. This is obviously a disadvantage when the monitoring data contains only simple information. Therefore, more
convolutional layers and more convolution kernels cannot
improve the accuracy of the model. While using one convolutional layer is more suitable and two LSTM layers can capture
the long-short-term data dependencies to a signiﬁcant degree
from the result. It is worth noticing that we have tried to add
a new LSTM layer with a unit of 25 to the CNN −LSTM2
model, and 83,154 trainable parameters are generated in the
network. The parameters that need to be trained is 15 times
the total number of data sets. Not only does the model training
take twice as much time, but the model is under-ﬁtting and
performs poorly. The scatter plots of raw data and predicted
saturation line is illustrated in Figure 7, which helps show the
prediction performance more intuitively.
superiority
&CNN −LSTM2, we applied comparative studies with other
state-of-the-art machine learning and deep learning models,
including the support vector regression (SVR), decision tree
regression (DTR), random forest regression (RFR), multilayer perception (MLP), single gate recurrent unit (GRU),
simpleRNN as well as LSTM models. Table 4 presents
the RMSE, MAE and R2 score of these models in the
experiments. The SVR, DTR, RFR models are machine
VOLUME 8, 2020
J. Yang et al.: CNN-LSTM Model for Tailings Dam Risk Prediction
TABLE 5. Prediction cases using different hyperparameters.
learning models, which are essentially different from deep
learning. They do not involve multi-layer networks, so the
calculation time is very short, usually less than 0.1 seconds.
Compared with deep learning, machine learning cannot effectively learn the information between data, so they can not
achieve good performance. In the study, we compared these
traditional machine learning with deep learning models to
highlight the effectiveness of the models. The results demonstrate that the &CNN −LSTM2 method signiﬁcantly outperforms the others in R2. Besides, the runtime for 120 epochs
is much less than other deep learning models. It should be
mentioned that over-ﬁtting is one of the trickiest obstacles
in applied deep learning. Simply checking the accuracy of
the test set cannot effectively prove the accuracy of the
model, because the model may be over-ﬁtted. In this task,
by observing the loss value, the training set error decreases
gradually and tends to be constant. Also, over the test set, the
loss tends to be constant. In addition, it is worth noting that
there is no obvious pattern in the change of data as can be
seen from the original data (Figure 5), and the distribution of
training set and test set are quite different. Even if the test set
and training set data are very different, the model can still
show good predictive performance on the test set. It fully
proves that the model has proves that the model has good
predictive ability and there is no over-ﬁtting.
In order to build the complete saturation line prediction
model and show the reliability of the &CNN-LSTM2 model
together with parameters set, different hyperparameters was
compared, such as batch size, ﬁlters in of the convolutional
layers, max-pooling size, number of LSTM cells in the
experiments. Table 5 lists the different situations of combing
multiple hyperparameters. In term of the evaluation metrics,
although Case 2 and Case 5 achieve a litter bit higher performance than the model using ordinary hyperparameters, the
Runtime is almost twice the &CNN-LSTM2 model, excessive
running time will reduce the real-time performance of prediction, especially when the amount of data is very large.
The disadvantage is more pronounced for a large amount
of data, and this incurs no loss of generality. Case 3 need
the least Runtime but achieve low accuracy. As a result, the
&CNN-LSTM2 with one convolutional layer and two LSTM
layers become the best performer. This is also in full compliance with deep learning logic. Although the padding method
restricts the feature loss of the time-series data to some extent,
the pooling layer inevitably loses part of the data information.
Considering the accuracy and running time of the model, the
model parameters were kept as same as the ordinary model.
To be clear, the batch size is equal to 64, one convolutional
layer ﬁlters of 32, a max-pooling layer ﬁlters of 2, two LSTM
layers of 25 and 50. When the tailings ponds meet more
complex situation, the data will become very complicated and
internal time-series information is harder to calculate. At that
time, single shallow deep learning layer lacks the capability
to capture complex information. Deeper layers of LSTM cells
will be more suitable.
VI. DISCUSSION AND CONCLUSION
In this work, a new method was applied to predict the
safety of tailings pond according to the saturation line using
CNN −LSTM2 model, which is also ﬁrst used in tailings
pond risk prediction. Compared with the traditional methods, the risk evaluation method of tailings ponds has the
characteristics of high accuracy and high real-time performance. The contributions of this work is two fold: Firstly,
a NI system (including Pearson correlation coefﬁcients, sensitivity analysis and random forest algorithms) was applied
for reconstructing missing and abnormal values of saturation line by water level and rainfall. It should be observed
that the water level and rainfall have the same time-series
information with saturation line. Secondly, two CNN-LSTM
models, especially the CNN −LSTM2 model is shown to
outperform other state-of-the-art models, such as SVR, DTR,
RFR, MLP, RNN, GRU and LSTM. Conclusively, although
these models can also achieve good performance, the
VOLUME 8, 2020
J. Yang et al.: CNN-LSTM Model for Tailings Dam Risk Prediction
CNN −LSTM2 still far ahead in RMSE, MAE, R2. Moreover,
the Runtime of CNN −LSTM2 is another advantage, which is
more pronounced in a larger amount of dataset. Thirdly, for
a better understanding of the meaning of hyperparameters,
more experiments were conducted using different Batch size,
convolutional layer ﬁlter size, max-pooling size and LSTM
cell size.
In tailings pond risk prediction task, these experiments
consequently provide applicability of the CNN −LSTM2
is worth mentioning that the CNN −LSTM2
model could also be applied in other time-series predictions
including water level prediction, weather prediction and air
quality prediction. It is evident that the model can not only
to extract and recognize the structures in the time series and
spatial features, but also identify long-term and short-term
series information of the data.
In the future, we will focus on more factors of the safety
monitoring parameters of the tailings pond, such as the underground displacement, ground displacement and dry beach
length. Furthermore the risk level corresponding to the monitoring parameters of the tailings pond should be built to more
intuitively reﬂect the safety of the tailings pond in the future
NOMENCLATURE
Long-Short-Term Memory.
Auto-Regressive Integrated Moving Average.
Convolutional Neural Network.
Numerical inversion.
Random Fores.
Mean absolute error.
Root-mean-square error.
Coefﬁcient of determination.
Recurrent neural network.
The 8th stage of the tailings dam.
The 13th stage of the tailings dam.
The 17th stage of the tailings dam.
The 21th stage of the tailings dam.
The 28th stage of the tailings dam.
The 33th stage of the tailings dam.
Support vector regression.
Decision tree regression.
Random forest regression.
Multilayer perception.
Gate recurrent unit.
Pearson correlation coefﬁcient.
Input gate.
Forget gate.
Memory cell.
Output gate.
Input data after using Z −score.
ACKNOWLEDGMENT
Jun Yang would like to thank Yixuan Sun, a Ph.D. Student
from Purdue University, for giving methodological guidance
and reviewing the article in this research.