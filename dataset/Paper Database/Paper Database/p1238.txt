Self-trained Deep Ordinal Regression for End-to-End Video Anomaly Detection
Guansong Pang1∗,
Cheng Yan2,1∗,
Chunhua Shen1†,
Anton van den Hengel1,
1 The University of Adelaide, Australia
2 Beihang University, China
Video anomaly detection is of critical practical importance to a variety of real applications because it allows
human attention to be focused on events that are likely to
be of interest, in spite of an otherwise overwhelming volume of video. We show that applying self-trained deep ordinal regression to video anomaly detection overcomes two
key limitations of existing methods, namely, 1) being highly
dependent on manually labeled normal training data; and
2) sub-optimal feature learning. By formulating a surrogate two-class ordinal regression task we devise an end-toend trainable video anomaly detection approach that enables joint representation learning and anomaly scoring
without manually labeled normal/abnormal data. Experiments on eight real-world video scenes show that our proposed method outperforms state-of-the-art methods that require no labeled training data by a substantial margin,
and enables easy and accurate localization of the identiﬁed
anomalies. Furthermore, we demonstrate that our method
offers effective human-in-the-loop anomaly detection which
can be critical in applications where anomalies are rare and
the false-negative cost is high.
1. Introduction
Anomaly detection in video is the task of identifying
frames from a video sequence which depict events that deviate signiﬁcantly from the norm. Identifying such anomalous events, e.g., ﬁres, trafﬁc accidents or stampedes, can be
of great practical importance, particularly in guiding timely
responses. The task is made particularly challenging, by the
fact that anomalous events are rare, visually unbounded and
often unidentiﬁable before they occur. It is nonetheless critical in a wide variety of application areas, as it provides a
method for allowing human attention to be focused on the
events that are most likely to be of interest from within an
otherwise overwhelming volume of video.
The practical signiﬁcance of the problem has seen many
∗GP and CY equally contributed to this work. CY’s contribution was
made when visiting The University of Adelaide.
†Corresponding author, e-mail: 
Labeled normal data
(a) Current two-step anomaly detection
Testing data
(b) End-to-end learning of anomaly scores
Self-trained learning and testing
Feature Extraction
Testing data
End-to-end
Figure 1 – Pipelines of (a) two-step and (b) end-to-end anomaly detection.
The two-step approach embodies separate feature extraction/learning and anomaly scoring methods, while the end-to-end approach uniﬁes these two modules and directly learns the anomaly scores
from the raw inputs. Also, the former often requires a set of labeled
normal videos, whereas our approach requires no manual annotation of
normal/abnormal data.
methods for video anomaly detection developed. The majority of existing methods assume the availability of a labeled dataset depicting a set of ‘normal’ events. This includes the dictionary learning-based methods 
and the more recently emerging deep learning-based methods . This assumption signiﬁcantly limits their domain of application, not least because it means
that the system cannot be continuously re-trained without
human involvement, nor applied to database sifting . To
address this issue, here we address what has been termed
‘unsupervised video anomaly detection’ , which requires identifying abnormal frames from a large volume of
video frames with no manually labeled normal/abnormal
training data. This version of the problem may be the only
viable approach in the many application domains where human labeling of video is extremely costly or impossible.
This includes, for example, large-scale video surveillance,
 
Internet video ﬁltering, and industrial process safety monitoring, because in all of these cases the deﬁnition of normal
events is diverse, constantly changing, and unpredictable.
Additionally, these methods often employ a two-step approach as shown in Figure 1(a). This approach ﬁrst learns or
extracts feature representations from labeled normal training data and then employs a deterministic anomaly measure
to calculate the normal/anomaly scores based on the extracted/learned representations. This essentially separates
the feature learning/extraction and anomaly detection modules, leading to inﬂexible and sub-optimal anomaly scoring.
Some previous studies address a similar problem
setting to ours. Although labeled normal training data is
not required, their methods typically adopt a similar twostep approach that ﬁrst extracts features from test data and
builds anomaly scoring models upon the extracted features.
To address the aforementioned two issues, we introduce
an end-to-end approach to unsupervised video anomaly detection based on self-trained ordinal regression. Applying
self-trained ordinal regression enables the development of a
weakly supervised approach to the problem that is amenable
to end-to-end training.
End-to-end training, in turn, enables the optimization of a feature learner that is tailored
speciﬁcally to anomaly detection in the target data, and an
anomaly scoring process that is tailored to the output of this
feature learner. The method is weakly supervised in that it is
initialized using a pre-trained model (e.g., ResNet-50 )
on relevant auxiliary labeled data and initial pseudo labels
of normality and abnormality generated using generic (that
is, not video speciﬁc) anomaly detectors.
To apply self-training ordinal regression we formulate
the problem as a surrogate two-class ordinal regression task,
for which an ordinal regression model is deﬁned to directly learn anomaly scores for pseudo normal and anomalous frames in an iterative fashion, as shown in Figure
The initial pseudo normal and anomalous frames
can be determined based on existing unsupervised methods .
The ordinal regression model stacks
differentiable feature representations and anomaly scoring
learners for end-to-end training. The key intuition underlying this approach is as follows. Although existing methods
cannot produce well optimized anomaly scores, they generally achieve good accuracy in correctly identifying a subset
of normal and anomalous events. These identiﬁed normal
and anomalous events can be leveraged by the end-to-end
anomaly score learner to iteratively improve and optimize
the anomaly scores, resulting in signiﬁcantly better detection performance compared to the initial detection.
We implement our formulation as a self-trained deep ordinal regression network, which is a synthesis of convolutional network-based feature learning and fully connected
network-based anomaly scoring. This facilitates end-to-end
anomaly score optimization. Moreover, our model can offer two important capabilities that are difﬁcult to achieve
with existing methods.
First, the nature of self-training
and end-to-end learning enables effective human-in-theloop anomaly detection. Human experts can easily interact
with our model by providing it with feedback on the detected anomalies which the model can use to update itself
to quickly return more accurate detection results. This is
a critical capability, especially when the anomalies are rare
and the cost of false-negatives is high. Second, our method
can easily generate frame-level saliency maps to effectively
localize the identiﬁed anomalies. In summary, we make the
following two major contributions.
• We show that applying self-training ordinal regression
to video anomaly detection enables a novel formulation of the problem that not only eliminates the need
for manually labeled training data, it enables end-toend training, thus improving detection accuracy.
• We present a novel end-to-end neural network-based
anomaly detection method. The method offers three
critical capabilities: i) it generates optimal anomaly
scores w.r.t. the given ordinal regression loss; ii) it enables effective human-in-the-loop anomaly detection;
and iii) it offers easy and accurate localization of the
identiﬁed anomalies within the corresponding images.
These capabilities are analyzed through extensive experiments on eight different scenes from three realworld video datasets.
1.1. Related Work
Some popular video anomaly detection approaches include low-level feature extraction , dictionary learning and deep learning .
The low-level feature extraction approach focuses on extracting low-level appearance
 , and/or dynamic features , for proﬁling
normal behaviors. The dictionary learning-based approach
learns a dictionary of normal events and identiﬁes the events
that cannot be well represented by the dictionary.
dictionary learning may also be applied to low-level features, such as histogram of gradient (HoG) or histogram of
optical ﬂow (HoF) features , and 3D gradient features . There have been other approaches that aim to
model normal events with compact representations, such as
hashing-based methods and clustering . The
deep learning-based approach also aims to learn a model of
normal events . Most deep learning-based methods use
reconstruction error to measure divergence of the test data
from a set of normal training videos .
Future frame prediction is an alternative deep-learning approach explored in . The aforementioned approaches
 often require
manually labeled normal video samples to train their models. Unlike these approaches, our approach does not require
manual annotation of normal/abnormal data.
Some recent work addressed a similar problem
setting to ours. Permutation tests are used in to deﬁne
the anomaly scores by evaluating the discriminativeness of
a given frame in different groups of frames. Unmasking
 is exploited in to measure the anomalousness
by the classiﬁcation accuracy changes resulting from unmasking. These methods generally include two main steps:
feature extraction/learning and anomaly scoring, which are
performed separately.
This simpliﬁes the feature extraction/learning problem but leads to a feature transform that
is not optimized for the problem, or the data. By contrast,
our approach uniﬁes these two steps to enable end-to-end
optimization of the whole anomaly identiﬁcation process.
Studies have addressed the same problem setting in the machine learning community, such as current state-of-the-art
methods Sp and iForest . Note that they operate on traditional features and their effectiveness on video
data is rarely explored.
Additionally, there has been some work for end-to-end
anomaly detection , but they require labeled normal and/or abnormal data for training.
2. Problem Formulation
The problem that we aim to address is end-to-end learning of anomaly scores for a set of video frames with no
manually labeled normal/abnormal data. Formally, given a
set of K video frames X = {x1, x2, · · · , xK} with no class
label information, our goal is to learn an anomaly scoring
function φ : X 7→R that directly assigns anomaly scores
to the video frames such that φ(xi) > φ(xj) if xi is an
anomalous frame and xj is a normal frame.
We formulate this problem as a self-training ordinal regression task. Speciﬁcally, let C = {c1, c2} be augmented
scalar ordinal class labels with c1 > c2, A ⊂X be a set of
anomalous frame candidates with each frame having an ordinal label c1, N ⊂X (N ∩A = ∅) be a set of normal frame
candidates with each frame having an ordinal label c2, then
the anomaly score learner φ can be formulated as
 φ(x; Θ), yx
where G = A ∪N, L(·, ·) is a regression loss function and
yx = c1 , ∀x ∈A and yx = c2 , ∀x ∈N.
One critical idea in the ordinal regression theory is to
leverage the ordinal dependence in the supervision information to learn an optimal sample ranking function .
To apply this idea to optimize the ranking of anomalies, we
devise the self-training ordinal regression. As c1 > c2,
optimizing the objective in Eqn. (1) will identify Θ∗corresponding to a version of φ(x; Θ∗) that assigns scores to
X such that suspicious abnormal and normal samples have
anomaly scores as close to respective c1 and c2 as possible,
yielding an optimal anomaly ranking.
Since X contains high-dimensional samples, we often
need to map the data onto a low-dimensional space before
the anomaly scoring. Let ψ be a feature mapping function
with parameters Θr and η be an anomaly scoring function
with parameters Θs, then Eqn. (1) can break down into
 η(ψ(x; Θr); Θs), yx
To enable end-to-end training, we need to address two
main problems. First, it requires that φ and ψ can be simultaneously optimized. As is discussed in Section 3.2, deep
neural networks can be designed to address this problem.
Second, we need to generate A and N since they are unknown in the ﬁrst place. To tackle this problem, we ﬁrst
initialize A and N using anomaly scores generated by some
existing unsupervised anomaly detection methods (see Section 3.1), and we iteratively update A and N and retrain φ
until the best φ is achieved (see Section 3.3).
The key idea of this formulation is that existing anomaly
detection methods are able to identify frames that are clearly
members of A and N, but are unable to expand these sets to
accurately cover X. The proposed approach uses each estimate of A and N to further optimize the anomaly scores.
These scores then, in turn, help generate new, more accurate, sets A and N.
This iterative self-training achieves
much better detection performance and coverage than the
initial detection methods support.
It is important to note that the initial set A need not span
the anomalies in X, and may even erroneously contain elements of N. The iterative process means that the model
implicitly deﬁned by Θ is continually being reﬁned. The
membership of A and N is thus constantly being updated to
improve their quality.
3. The Proposed Method
Our formulation is implemented as a self-training deep
neural network for ordinal regression. As shown in Figure 2, our method consists of three major modules. The
ﬁrst module carries out the initial anomaly detection, which
yields the initial membership of A and N. These are then
fed into the end-to-end anomaly scoring module to optimize
Θ and thus the anomaly scores. A corresponding new set of
anomaly scores are then generated, which are used to update the membership of A and N.
3.1. Initial Anomaly Detection
The role of the initial anomaly detection is to obtain a
set of frames that can be identiﬁed as belonging to A and N
with high probability. To achieve this, two state-of-the-art
unsupervised anomaly detection methods, Sp and
Initial anomaly
Pseudo normal frames
Pseudo anomalous frames
Pre-trained
Iterative learning with updated
pseudo labels
End-to-end anomaly score learner
Figure 2 – The proposed framework. Given a set of unlabeled videos, we ﬁrst perform initial detection to generate pseudo anomalous and normal frame
sets. These sets are then used to train a (pre-trained) ResNet-50 model and a fully connected network in a end-to-end fashion. The trained model is
then used to recompute the anomaly scores of all frames. The membership of A and N is updated accordingly, and the process repeated.
iForest , which are designed for feature vector-based
data, are employed to perform the initialization. Combining anomaly scores from different anomaly detectors allows
to identify anomalies with different characteristics and improves the subsequent anomaly candidate selection. Sp is
a very simple yet effective and provable method, which de-
ﬁnes the anomaly score of a given example as the nearest
neighbor distance in a small random subsample of the full
dataset. Let f(·) be a function that extracts feature vectors
from a video frame and z = f(x), its anomaly score is
s1(z) = min
˜z∈S d(z, ˜z),
where S ⊂X is a random subset of X and d(·, ·) represents the Euclidean distance. To obtain statistically stable
performance, for each z, we use the average of a bootstrap
aggregating of m scores to be the ﬁnal anomaly score .
iForest is probably the most widely-used unsupervised anomaly detection method for traditional general multidimensional data in recent years. It posits that anomalies
are susceptible to isolation and builds isolation trees on random data subspaces to identify them. Each tree is grown by
using a random subsample until every data example is isolated, where the feature and cut-point at each tree node are
randomly selected. The inverse of the path length traversed
from the root to a leaf node by x is used as its anomaly score
where h(z) denotes the path length of z in S, E(h(z)) is the
average path length of z over n isolation trees, and c(·) is
the expected path length for a given subsample size.
We rescale the two sets of anomaly scores from these two
detectors into the same range and use their average as the
initial anomaly scores. We then use these anomaly scores
to include the most likely anomalous frames into the pseudo
anomaly set A and the most likely normal frames into the
pseudo normal set N (see Section 4.1 for detail).
3.2. End-to-end Anomaly Score Learner
The end-to-end anomaly score learner takes A and N as
inputs and learns to optimize the anomaly scores such that
the data inputs of similar behaviors as those in A (N) receive
large (small) scores. The score learner can be deﬁned as
a function φ(·; Θ) : X 7→R, which is a sequential stack
of a feature representation learner ψ(·; Θr) : X 7→Q and
an anomaly score learner η(·; Θs) : Q 7→R, where Q ∈
RM is an intermediate feature representation space and Θ =
{Θr, Θs} contains all the parameters to be learned.
Speciﬁcally, the feature learner ψ(·; Θr) is speciﬁed as a
network with H ∈N hidden layers and their weights Θr =
{W1, W2, · · · , WH}, and can be represented as
q = ψ(x; Θr),
where x ∈X and q ∈Q. Different backbones can be used
here. We implement ψ using ResNet-50 due to its superior capability of capturing frame appearance features.
The anomaly score learner η(·, Θs) : Q 7→R is speciﬁed
as a fully connected two-layer neural network. The network
consists of a hidden layer with 100 units and an output layer
with a single linear unit:
η(q; Θs) = w⊺g(q; WH+1),
where q ∈Q, [·]⊺is a matrix transpose operation, g(·)
maps the ResNet-50 features to the hidden layer and Θs =
{WH+1, w} contains the weight parameters of this scoring
learner. Thus, φ(·; Θ) can be formally represented as
φ(x; Θ) = η
 ψ(x; Θr); Θs
which directly maps raw visual inputs to scalar anomaly
scores and can be trained in an end-to-end fashion by minimizing the following loss function:
 φ(x; Θ), yx
= |φ(x; Θ) −yx|,
where yx = c1 when x ∈A and yx = c2 when x ∈N.
Since y takes two scalar ordinal values only, it is a two-class
ordinal regression.
The absolute loss is employed together with stochastic
gradient descent-based optimization to reduce the negative
effects brought by false pseudo labels in A and N. Minimizing this loss enforces an anomaly score close to c1 (c2) for
any frames having similar features as the frames in A (N),
resulting in larger anomaly scores assigned to anomalous
frames than normal frames.
3.3. Iterative Learning via Self-training
We further perform iterative learning using a selftraining approach to iteratively improve our anomaly
The intuition is that the initial anomaly detection results can pose limitations on the performance of our
end-to-end anomaly score learner, since our score learner is
dependent on the quality of pseudo normal and anomalous
frames; on the other hand, our end-to-end anomaly score
optimization is expected to produce better anomaly scores
than the initial anomaly scores, so it can provide pseudo
normal and anomalous frames of better quality and in turn
improve its self-performance.
Self-training, a.k.a. self-learning, is a classic semisupervised learning approach. It ﬁrst trains a model using a
small labeled dataset and then applies the trained model to
unlabeled data to generate more reliable labeled data. Since
we do not have any labeled data, we present a simple strategy to adapt the self-training to an unsupervised setting.
Particularly, at each iteration of the iterative learning, instead of incrementally adding more labeled data, we use the
newly obtained pseudo labels, A and N, to replace the previous ones and then retrain the end-to-end anomaly learner
φ. The main reason for discarding the previous A and N is
because combining the previous and newly obtained pseudo
labels without supervision information can result in worse
pseudo labels. We found empirically that this simple strategy worked very well on different datasets.
Each iteration outputs an optimized φ, so the iterative
learning results in a set of trained models.
Similar to
sequential ensemble learning , we perform an average aggregation of all the sequentially output models to
achieve stable detection performance. Speciﬁcally, the ﬁnal anomaly score of a given x is deﬁned as
score(x) = 1
where φi is the optimized model at the ith iteration.
4. Experiments
4.1. Implementation Details
The initial anomaly detectors, Sp and iForest, are implemented using scikit-learn. They are used with recommended settings as in . Since both Sp and iForest
only work on feature vectors, we need to transform video
data into feature vectors before applying them. Speciﬁcally,
we ﬁrst extract features using the last dense layer of the pretrained ResNet-50 and then apply PCA to reduce the dimensionality using the most important 100 components.
For the end-to-end anomaly score learner, the pre-trained
ResNet-501 is used as our feature learner; the fully connected 100-unit hidden layer uses the ReLU activation function a(u) = max(0, u); the output layer contains a linear
unit; and c1 = 1 and c2 = 0 are used in the pseudo ordinal
class labels to guide the learning (our model also worked
well with other settings of c1 and c2 as long as c1 was suf-
ﬁciently larger than c2). The Stochastic Gradient Descent
(SGD) optimizer with a learning rate 0.005 is used throughout all the experiments. The batch size and the number of
epochs are respectively set to 128 and 50 by default.
To obtain a set of reliable pseudo anomalous frames, we
need to determine A with a sufﬁciently high conﬁdence
level. Particularly, we include the 10% most anomalous
frames into A according to their anomaly scores, because
anomaly scores often follow a Gaussian distribution 
and this decision threshold can provide an approximate 90%
conﬁdence level of making false positive errors in such
cases. However, we may still include normal frames into
A. We further tackle this problem using a weighted random
sampling-based mini-batch generation method, i.e., sampling examples from A with a probability positively proportional to their anomaly scores. To generate the pseudo
normal frame set N, we select the 20% most normal frames
based on the anomaly scores.
This can always help to
achieve a high-quality N because of the overwhelming presence of normal frames in the real-word datasets. These two
cutoff thresholds are used by default as they consistently
obtain substantially improved performance on datasets with
diverse anomaly rates (see Table 1 and Figure 5 for detail).
In the iterative learning, extensive results showed that
our model could often be substantially improved in the ﬁrst
1ResNet-50 is used since this work examines appearance-based anomalies only, which is one of the most common anomalies in video data.
multiple iterations and then plateaued out. Thus, we perform the iterative learning for ﬁve iterations by default.
4.2. Datasets
Three real-world datasets are used in our experiments:
• UCSD . This data is one of the most challenging anomaly detection datasets. It contains the UCSD
Pedestrian 1 data (Ped1) and the UCSD Pedestrian 2
data (Ped2). Ped1 consists of 34 training and 36 test
videos, while Ped2 contains 16 training and 12 test
videos. The anomalies are vehicles, bicycles, skate
borders and wheelchairs crossing the pedestrian areas.
• Subway . This is one of the largest datasets for
video anomaly detection. It includes two videos: the
Entrance gate video of 96 minutes and the Exit gate
video of 43 minutes. The anomalies are passengers
walking towards a wrong direction or escaping tickets.
• UMN . The UMN dataset contains three different
scenes, each with 1,453, 4,144, and 2,144 frames, respectively. In each scene, the normal activity is people
casually walking around while the anomalous activity
is people running in all directions.
Note that anomalies are rare events in real-world applications, but this is violated if only the test set of these datasets
are used, because these test sets can contain a large percentage of anomalous events, e.g., nearly 50% anomalies in the
UCSD test sets. Such test sets are not applicable in our setting. We address this problem by merging the training and
test sets, and train and evaluate our model on the full dataset
with the ground truth used in the evaluation only. This applies to the competing methods unless stated otherwise.
4.3. Performance Evaluation Metrics
Following previous work , the area
under the ROC curve (AUC) is used as the evaluation metric. AUC is calculated using the frame-level anomaly scores
and ground truth. The equal error rate (EER) has also been
used as the evaluation metric in some previous work, but we
agree with that this metric can be misleading for many
real-world applications where the anomalies are very rare.
Therefore, we do not use the EER in our evaluation.
4.4. Effectiveness in Real-world Datasets
As shown in Table 1, we ﬁrst examine the performance
of our method by comparing to 17 state-of-the-art methods.
On all of the scenes, our method is consistently the best
performer among the unsupervised methods that
are evaluated using the same evaluation protocol. Speciﬁcally, compared to Sp + iForest that provides initial anomaly detection results for our method, our method
achieves about 2%-15% AUC improvement. It is impressive that we obtain more than 15% improvement on UCSD-
Ped1 and UCSD-Ped2 where Sp + iForest works less effectively, and that we can also obtain remarkable 8%-12% improvement on different scenes of the UMN data where Sp +
iForest performs very well. This demonstrates our method’s
capability in producing signiﬁcantly better anomaly scores
than the initial scores when the initial detectors perform either fairly well or very well. To have a fair and straightforward comparison with the discriminative framework-based
method , our method is compared with its two variants:
the ﬁrst variant, namely Del Giorno et al. #1 in Table
1, uses ResNet-50 and PCA to extract features as the input to the discriminative framework; and the second variant,
namely Del Giorno et al. #2 in Table 1, uses the features
extracted from the last dense layer in our trained model. The
results show that our method achieves about 5%-25% AUC
improvement over both cases of Del Giorno et al. on all
the datasets.
Compared to the unmasking framework , our method
performs substantially better on the challenging cases
UCSD-Ped1, Subway-Entrance, Subway-Exit and UMN-
Scene2 by a margin of respective 3%, 17%, 7% and 12%,
and performs comparably better on the other datasets.
The unmasking method is improved by a two-sample test
method in . Our method retains similar improvement
over this variant on all scenes except UCSD-Ped2 and
Subway-Exit. Note the results of the unmasking method
and its variant are respectively taken from and 
based on an evaluation protocol different from ours, i.e.,
they are evaluated on the test data rather than the full data.
Compared to the upper block methods, it is very impressive that our method 1) achieves large improvement over
several of these methods, such as Kim et al. , Mahadevan et al. and Mehran et al. on the UCSD data
and Cong et al. on the Subway and UMN datasets;
and 2) performs comparably well to the best methods
 on the UMN data.
However, it is clear
that our AUC score is 10%-22% lower than the methods
 on the UCSD data, showing the substantial gap
between these two types of methods on the very challenging
data. Note that the upper block competing methods are also
based on a different setting from ours and taken here for a
high-level comparison only.
4.5. Human-in-the-loop Anomaly Detection
Existing methods are lack of explicit prior knowledge
of anomalies.
As a result, many anomalous events they
identify are data noises. This section examines whether our
method can effectively interact with human experts to leverage their feedback on the anomalies of their interest to iteratively enhance our model and reduce such false positives.
We simulate the interaction as follows. First, our model
Table 1 – Frame-level AUC performance. Our method is compared with 12 methods that require labeled normal data in the upper block and ﬁve methods
that require no labeled normal/abnormal data in the bottom block. The best performance in each block is boldfaced.
Training Data
All Scenes
Labeled normal data
Kim et al. 
Mahadevan et al. 
Mehran et al. 
Cong et al. 
Xu et al. 
Sun et al. 
Zhang et al. 
Liu et al. 
Nguyen et al. 
Dong et al. 
Ionescu et al. 
Ionescu et al. 
No labeled data
Ionescu et al. 
Liu et al. 
Del Giorno et al. #1
Del Giorno et al. #2
Sp + iForest 
Our method
presents a small set of l top-ranked anomalous frames to
an expert. The expert then picks up two sets of k frames
(k ≪l), with one set of k frames believed to be the anomalies of interest and another set to be normal events. These
frames are employed to ﬁne-tune our model with 20 epochs.
After that, an updated anomaly ranking is again presented
to the expert for the feedback. This human-machine interaction can repeat until the expert obtains the most satisfactory
anomaly ranking results. To better exploit the feedback, we
also include the temporally adjacent frames of the selected
frames with the same label (e.g., the adjacent 5 frames to
the selected frame) into our ﬁne-tuning process.
Figure 3 shows empirical results on two representative
datasets, UCSD-Ped1 and Subway-Exit, with l = ⌊0.1N⌋
and k = 5. UCSD-Ped1 represents a challenging scene with
large improvement space, while Subway-Exit represents a
less challenging scene yet with small improvement space.
Our method can well leverage the limited human feedback
per interaction to gradually and consistently reduce the false
positive errors, achieving more than 6% AUC improvement
on both datasets after 5-round interactions.
4.6. Localizing the Identiﬁed Anomalies
The end-to-end learning of anomaly scores also enables us to leverage existing deep neural network interpretation techniques to localize and understand the anomalous patches within a given frame that are responsible for
large anomaly scores. Here we adapt the state-of-the-art
method, class activation map (CAM) , to achieve this
goal. Particularly, for a given frame x, let pk(i, j) be the
activation of an unit k in the last convolutional layer at a
spatial location (i, j) and wk be the weight for the unit k
w.r.t. anomaly scoring, then based on we can obtain
i,j M(i, j), where M(i, j) = P
k wkpk(i, j) is
the class activation map. The frame-level saliency map can
then be obtained by upsampling the class activation map
to the size of the input frame x. The CAM-based saliency
maps corresponding to some exemplar anomalies are shown
in Figure 4. We can see that the regions corresponding to the
anomalous events of the frames are well highlighted with
high activation values in all four different scenes. Although
our method may be also distracted by normal patches in
some cases, such as the upper patch in Figure 4(b), it is very
impressive for an unsupervised anomaly detection method
to achieve such effective anomalous region localization.
4.7. Ablation Study
Initial Anomaly Detection.
The stability of labeling
pseudo anomalies and normal data using the two ﬁxed cutoff thresholds is examined by looking into the AUC performance on datasets with different anomaly rates, including
5%, 10%, 15% and 20%. The results on Ped1 and Ped2
are shown in Figure 5, with Sp + iForest used as baseline.
This experiment is not applicable on the other datasets as
their anomaly rates are too small. The results show that, despite the anomaly rate varies signiﬁcantly across the examined cases, our method with the default cut-offs can consistently achieve substantial AUC improvement over the baseline that we use to generate initial pseudo labels. This frees
us from tuning the cutoffs on different scenarios. Note that
the increasing performance with increasing anomaly rates is
mainly due to the fact that it becomes easier to obtain better
AUC performance when the anomaly rate is larger.
Network Architecture.
We replace ResNet-50 with
VGG and 3DConv to examine the use of different
architectures. The results are shown in Table 2. It is clear
False Positive Rate
True Positive Rate
H-M 0 (auc=71.7%)
H-M 1 (auc=73.1%)
H-M 2 (auc=75.8%)
H-M 3 (auc=76.3%)
H-M 4 (auc=76.8%)
H-M 5 (auc=78.2%)
False Positive Rate
True Positive Rate
Subway-Exit
H-M 0 (auc=92.7%)
H-M 1 (auc=95.7%)
H-M 2 (auc=97.8%)
H-M 3 (auc=98.0%)
H-M 4 (auc=98.2%)
H-M 5 (auc=98.8%)
Figure 3 – ROC curves of our human-in-the-loop anomaly detection. H-M i indicates the results obtained in the i-th human-machine interaction. Best
viewed in color.
Figure 4 – Manually labeled exemplar anomalies in the original inputs (red rectangles on the left) and the corresponding CAM based saliency maps
yielded by our method (right). Anomalies in subﬁgures (a) and (b) are respectively vehicles and bikes crossing the pedestrian areas in the UCSD data.
The anomaly in subﬁgure (c) is from the Subway-Exit data, a passenger walking towards a wrong direction. Subﬁgure (d) shows the anomaly from the
UMN data, people running in all directions.
Anomaly Rate
Our method
Anomaly Rate
Our method
Figure 5 – AUC performance w.r.t. different anomaly rates.
that our method can work very well using different popular backbones with either shallower or higher-dimensional
convolutional architectures. This indicates that our performance is not dependent on speciﬁc backbones.
Table 2 – AUC performance of using different architectures.
Self-training. To examine the self-training module, Figure 6 shows the AUC results of our method at each iteration
during self-training. Our performance gets larger improvement with increasing iterations in the ﬁrst few iterations on
most datasets and then becomes stable at the 4th or 5th iteration. This shows that the self-training approach can iteratively improve the performance of our method. However,
it should be noted that the performance of our method is
bounded at some points when no extra information is provided, so we stop the iterative learning after a few iterations.
We found empirically that ﬁve iterations are often sufﬁcient
to reach the possibly best performance on different datasets.
All Scenes
Figure 6 – AUC performance of our method at each iteration. ‘t = i’
indicates our model with i iterations.
End-to-end Anomaly Score Learner. The importance
of the end-to-end anomaly score learning is manifested by
comparing the results of our method to Del Giorno et al. 
#2 in Table 1. The anomaly scoring of our method and Del
Giorno et al. #2 take exactly the same feature inputs, but
our method achieves consistently large improvement over
Del Giorno et al. #2 on all the datasets. This is because
the input features are optimized as an integrated part in
our end-to-end score learning, resulting in optimal anomaly
scores; whereas the two-step methods like Del Giorno et
al. #2 on one hand rely on the quality of input feature representations while on the other hand cannot unify
the feature extractor/learner and anomaly scoring, leading
to much less effective performance.
5. Conclusions
We have shown that framing video anomaly detection as
a self-training deep ordinal regression task overcomes some
of the key limitations of existing approaches to this important problem. We additionally devised an end-to-end trained
approach that outperforms the current state-of-the-art by a
signiﬁcant margin. Two key insights gained are that (1)
the end-to-end learning enables better optimized anomaly
scores than the two-step approach and (2) the self-training
ordinal regression approach can be leveraged by our endto-end anomaly score learner to iteratively enhance detection performance. Furthermore, our method offers some
crucial capabilities, including human-in-the-loop anomaly
detection and accurate anomaly localization. We are working on incorporating other features such as motion features
into our model to identify other types of anomalies.
Acknowledgments XB was in part supported by the
NSFC project #61772057 and BNSF project #4202039.