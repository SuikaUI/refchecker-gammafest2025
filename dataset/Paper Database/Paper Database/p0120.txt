Adaptive space transformation: An invariant based method for
predicting aerodynamic coefﬁcients of hypersonic vehicles$
Changtong Luo a,n, Zongmin Hu a, Shao-Liang Zhang b, Zonglin Jiang a
a Institute of Mechanics, Chinese Academy of Sciences, Beijing 100190, China
b Department of Computational Science and Engineering, Nagoya University, Nagoya 464-8603, Japan
a r t i c l e i n f o
Article history:
Received 3 November 2014
Received in revised form
4 August 2015
Accepted 1 September 2015
Available online 27 September 2015
Aerodynamic coefﬁcient
Data correlation
Scaling parameter
Genetic programming
a b s t r a c t
When developing a new hypersonic vehicle, thousands of wind tunnel tests to study its aerodynamic
performance are needed. Due to limitations of experimental facilities and/or cost budget, only a part of
ﬂight parameters could be replicated. The point to predict might locate outside the convex hull of sample
points. This makes it necessary but difﬁcult to predict its aerodynamic coefﬁcients under ﬂight conditions so as to make the vehicle under control and be optimized. Approximation based methods including
regression, nonlinear ﬁt, artiﬁcial neural network, and support vector machine could predict well within
the convex hull (interpolation). But the prediction performance will degenerate very fast as the new
point gets away from the convex hull (extrapolation). In this paper, we suggest regarding the prediction
not just a mathematical extrapolation, but a mathematics-assisted physical problem, and propose a
supervised self-learning scheme, adaptive space transformation (AST), for the prediction. AST tries to
automatically detect an underlying invariant relation with the known data under the supervision of
physicists. Once the invariant is detected, it will be used for prediction. The result should be valid provided that the physical condition has not essentially changed. The study indicates that AST can predict
the aerodynamic coefﬁcient reliably, and is also a promising method for other extrapolation related
predictions.
& 2015 Elsevier Ltd. All rights reserved.
1. Introduction
The prediction of aerodynamic coefﬁcients is very important
for designing a new hypersonic vehicle. Usually, thousands of
wind tunnel tests are carried out to predict its aerodynamic force
coefﬁcients before it can really ﬂy in the sky. A number of parameters including free-stream Mach number, total ﬂow enthalpy,
free-stream
free-stream
number, density ratio across shocks, test gas, and wall-to-total
temperature
aerodynamic
coefﬁcients
 ). Due to the limitations of laboratory equipments and/or cost budget, it is very difﬁcult, if not impossible, to
duplicate all these ﬂight conditions. In many wind tunnel experiments, only a part of them such as Mach number M1 and/or
Reynolds number Re1 could be mimicked, where Mach number is
the ratio of ﬂow velocity and the local speed of sound, and
Reynolds number reﬂects the ratio of inertia and viscous forces.
Meanwhile, even for the mimicked parameters, the ﬂight range
could not be covered by wind tunnels. These make it very difﬁcult
to predict the ﬂight behavior with ground test data. The prediction
process is usually referred as ground to ﬂight data correlation, also
shorten as ground/ﬂight correlation. During the design of a new
hypersonic vehicle, it is an indispensable step.
A number of approximation based methods have been presented for the aerodynamic-coefﬁcient prediction including least
squares regression , artiﬁcial neural
network and
maximum likelihood method , and extrapolation
 . We have also suggested
an adaptive surrogate model to improve the
accuracy of approximation. In general, the prediction results of
these methods are reliable within the convex hull of known data
(interpolation). However, in many cases, the ﬂight parameters
could not be covered by wind tunnels. So the prediction needs to
be done outside the convex hull (extrapolation). However, the
above mentioned methods have poor performance on extrapolation, and their prediction results are not reliable.
Scaling parameter is an entirely different way of data correlation. A
scaling parameter is a function of several aerodynamic parameters so
Contents lists available at ScienceDirect
journal homepage: www.elsevier.com/locate/engappai
Engineering Applications of Artiﬁcial Intelligence
 
0952-1976/& 2015 Elsevier Ltd. All rights reserved.
☆This research has been supported by Innovation Grant of Chinese Academy of
Sciences and the National Natural Science Foundation of China (Grant nos.
90916028 and 11532014).
n Corresponding author.
E-mail addresses: (C. Luo), (Z. Hu),
 (S.-L. Zhang), (Z. Jiang).
Engineering Applications of Artiﬁcial Intelligence 46 93–103
that it can consider the total effect of these parameters. Several such
scaling parameters , including Knudsen number
(suggested by T. von Kármán), Tsien's parameter , Cheng's
rarefaction parameter , and Bird's breakdown parameter
 have already been proposed. However, these parameters
are valid only for high-speed rareﬁed ﬂow, and should not be used for
data correlation in other cases. For example, to study the aerodynamic
performance of near-space hypersonic vehicles, these parameters are
no longer applicable because the ﬂow around them is not a rareﬁed.
Meanwhile, there is no such alternative scaling parameter available to
describe the hypersonic near-space ﬂight ﬂow, and even worse, it is
very difﬁcult to get any of such scaling parameter. Usually, it requires
strong expertise and experience to get a new scaling parameter.
In this work, we found the above mentioned scaling parameters share the common ideas, and they could be uniﬁed in the
sense of space transformations. Based on this discovery, a new
method, referred to as adaptive space transformation (AST), is
proposed. The AST provides a self-learning scheme that can
automatically
parameters.
detecting an invariant relation by analyzing all of the test data
available under the supervision of physicists. Once the invariant
relation is detected, it will be used for prediction. The prediction
result should be reliable provided that its underlying physical
nature remains unchanged (thus the invariant relation still holds).
Comparisons and applications are also carried out to conﬁrm the
prediction capability of AST.
2. Observation and discussion of existing scaling parameters
2.1. Observation
As above mentioned, various scaling parameters, including Knudsen number Kn, Tsien's parameter , Cheng's rarefaction
parameter , and Bird's breakdown parameter 
have been proposed to study the high-speed rareﬁed ﬂow. Macrossan
 has analyzed their relationships and evaluated their performance on correlating drag on bodies in rareﬁed high-speed ﬂow with
Fig. 1. Correlated results with existing scaling parameters and an ideal one. (a) Correlated data with Knudsen number: Kn, which is proportional to
M1=Re1. (b) Correlated data with Tsien's parameter: M1=
. (c) Correlated data with inverse Cheng's parameter:
1=Re1. (d) Correlated curve (the red smooth curve) with an ideal scaling parameter sn ¼ f nðM1; Re1; …Þ. (For interpretation of the references to color in this ﬁgure
caption, the reader is referred to the web version of this paper.)
C. Luo et al. / Engineering Applications of Artiﬁcial Intelligence 46 93–103
three data-sets. He has found out that these scaling parameters are
proportional
M1=Re1; M1=
1=Re1, and
respectively. Macrossan also concluded that Tsien's parameter is better
than the Knudsen number Kn for the drag prediction, and Cheng's
rarefaction parameter performs the best (see Fig. 1) on the prediction.
In fact, all of these scaling parameters transform the original 3dimensional dataset ðM1; Re1; JÞ  R3 of different Mach numbers
into a 2-dimensional dataset ðs; JÞ  R2, where the scaling parameter s is a function of Mach number and Reynolds number,
s ¼ f ðM1; Re1Þ (see Fig. 1). The correlation performance is closely
related to the data distribution of the transformed dataset ðs; JÞ.
Fig. 1 shows that the data distribution in Fig. 1(a) is more scattered
than that in Fig. 1(b), and the data distribution in Fig. 1(c) is the
most centralized among the three. Comparing these facts to the
aforementioned conclusions of Macrossan, we get a scaling parameter that will have a better performance if the transformed data
has a more centralized distribution. If, ideally, there exists an
optimal correlation formula sn ¼ f nðM1; Re1Þ such that all transformed data tend to ﬁt a smooth curve (shown in Fig. 1(d)), it will
be a perfect scaling parameter.
2.2. Discussion
Famous physicists such as von Kármán and Tsien prefer scaling
parameters, rather than approximation based methods, why?
What is the potential idea behind scaling parameters? Is it possible
to get a better scaling parameter for the study of high-speed
rareﬁed ﬂow? Are these scaling parameters still valid for the study
of near-space hypersonic vehicles, in which the free stream is no
longer a rareﬁed ﬂow? If not, how to get a suitable new one? These
questions motivate us to develop a new correlation method. The
answers are as follows.
(a) For the approximation based methods, the result is hard to
interpret and the extrapolation capability is weak. It seems
more natural to predict the aerodynamic coefﬁcient J (such
as lift coefﬁcient CL, drag coefﬁcient CD, lift-to-drag ratio
CL=CD, pitch-moment coefﬁcient Cmz, etc.) by constructing
an approximate model like J ¼ FðM1; Re1; …Þ, where the
approximate model could be created by interpolation,
regression, nonlinear ﬁt, artiﬁcial neural network, or support vector machine, with test data of wind tunnels. This
does work in many applications. However, the result is still
hard to interpret because there are several predictor variables involved such as Mach number M1, Reynolds number
Re1, etc., and some of them might interfere each other. As a
result, the landscape of the response could be a multimodal surface, and it is not easy to tell how these parameters affect the aerodynamic coefﬁcient, even in 3-D
space (illustrated in Fig. 2(a)). Scaling parameter can
reduce a multi-parameter problem into a simpler one,
and the result could be visualized in 2-D space (illustrated
in Fig. 2(d)). This makes it easier to interpret and more
convenient to use. Another fact about approximation based
J=F(M∞, Re∞)
s=f0(M∞, Re∞)
s=fb(M∞, Re∞)
s=f*(M∞, Re∞)
Fig. 2. Detection of an invariant relation with respect to M1 by space transformations. (a) Original test data and their response surface. (b) Transformed data with an initial
scaling parameter. (c) Transformed data with a better scaling parameter. (d) Transformed data with a best scaling parameter.
C. Luo et al. / Engineering Applications of Artiﬁcial Intelligence 46 93–103
methods is that it is very risky to extrapolate directly with
the approximate model. It is helpful to construct a response
surface with test data to visually show the overall inﬂuence
of these parameters on aerodynamic coefﬁcients. But keep
in mind that the response surface holds only within the
range of test data (interpolation), and it could be very
dangerous to use it for prediction outside of test range
(extrapolation) for decision makers. Prediction by extrapolation is not reliable and might lead to damaging outcomes. This will be demonstrated in Section 4.1. For these
reasons, many famous physicists including von Kármán and
Tsien prefer using scaling parameter, rather than approximation based methods for the correlation of aerodynamic
coefﬁcient.
(b) The idea behind scaling parameters is to detect an invariant
relation. After the analysis of the above mentioned scaling
parameters, we ﬁnd that they share the common idea,
invariant detection, which will be described in detail in
Section 3, and thus they could be uniﬁed in the sense of
space transformations.
(c) Existing scaling parameters could be improved. As mentioned
above, there are already several scaling parameters available,
which could be formulated as M1=Re1; M1=
etc., to correlate test data of high speed rareﬁed ﬂow, and M.N.
rarefaction
1=Re1Þ performs the best among them. Note that these
parameters were proposed before 1970s, and the formulas are
obtained manually. At that time, optimization methods in function space such as genetic programming , grammatical evolution , and parse-matrix evolution have not yet been proposed. Nowadays, the genetic programming and its variants are ready to use.
This makes it possible to get a new better scaling parameter.
(d) Existing scaling parameters is no longer valid for the
aerodynamic-coefﬁcient prediction of near-space hypersonic vehicles. In fact, the ﬂow around the near-space
hypersonic vehicles is a continuous ﬂow, not a rareﬁed
ﬂow. Therefore, existing scaling parameters is no longer
valid for the aerodynamic-coefﬁcient prediction, and some
new scaling parameters need to be derived. However, it is
not easy to get any of such scaling parameter. Usually, it
requires strong expertise and experience, as well as complicated theoretical analysis, sufﬁcient experimental and
computational
veriﬁcation.
design an automatic discovery method to search for optimal scaling parameters in function space. So that it can
help the expert derive new scaling parameters more easily.
3. Adaptive space transformation (AST)
3.1. Idea behind parameter correlation
It is a remarkable fact that the abscissa in Fig. 1 is neither the
Mach number M1, nor the Reynolds number Re1, but a function of
literature):
s ¼ M1=Re1; s ¼ M1=
, or s ¼ CnM2
1=Re1, etc. In other words,
Tsien et al. prefer considering the total effect of the involved parameters, M1 and Re1. With the scaling parameter, the original 3-D
data ðM1; Re1; JÞ are transformed into a 2-D space ðs; JÞ (where
s ¼ f ðM1; Re1Þ, J ¼ CD=CDf ). If the scaling parameter works well, the
transformed data will tend to ﬁt a smooth curve. Note that although
these data are measured at different Mach numbers, range from 2.95
to 27, their transformed curves could almost overlap with each other.
This means the proposed scaling parameter revealed an invariant
relation among Mach number M1, Reynolds number Re1, and the
drag coefﬁcient J under these conditions.
Here, the invariant does not imply not varying, but the variations
share the same path, just like the curves’ overlap with each other.
Invariant relation, if exists, is the most important feature of a system.
In fact, invariant detection has been widely accepted in our daily
cognition. For example, there might be many ways to describe an
ellipse. But only if an invariant relation such as “The sum of the distances from any point Pi on a given ellipse to its two foci is a constant
(see Fig. 3(a))” is detected, its essential property is grasped.
The invariant relation has a great recovery capability. For example,
once the above invariant relation is detected, it can help recover the
entire ellipse from a small part of the ellipse. That is, although only a
part of an ellipse (e.g., the lower-left 1/4 part) is known, we can
predict (recover) the rest of it (see Fig. 3(b)). The recover process is
similar to data correlation, in which the objective is also to predict the
unknown part by using the information of the known part.
Note that the kernel of the transformation (also known as
scaling parameter) f must be determined carefully so that the
transformed data ðs; JÞ tend to ﬁt a smooth curve. Unfortunately, it
is not easy to get such a suitable scaling parameter in general
cases. A trivial transformation, including the projection transform,
does not work. For example, Fig. 2(b) shows the projection of a set
of 3-D data with different Mach numbers into the 2-D space ðs; JÞ.
The projected data are four separate curves, and still confusing. So
better transformation kernels (i.e., scaling parameters) are needed.
A better kernel fb could bring these curves closer (Fig. 2(c)).
Hopefully, there might be a best scaling parameter fn in the
function space, which could bring the curves together (Fig. 2(d)).
The four curves of different Mach numbers can overlap with
each other. This means the scaling parameter s ¼ f nðM1; Re1Þ
Fig. 3. Variations and invariant of the ellipse. (a) Detection of an invariant relation. (b) Recovery of the unknown part by the invariant relation.
C. Luo et al. / Engineering Applications of Artiﬁcial Intelligence 46 93–103
revealed an invariant relation about Mach number, represented by the overlapped curve. The variation of J is not
explicitly related to M1. So we can expect that for the data
measured at a new Mach number Mnew, its transformed curve
J ¼ JðsÞ (where s ¼ f nðMnew; Re1Þ) could also overlap with the
previous curves J ¼ Jðf nðMi; Re1ÞÞ; i ¼ 1; 2; 3; 4. Thus, the scaling
parameter s ¼ f nðM1; Re1Þ can be used as a correlation parameter for prediction.
In summary, the potential idea behind the existing scaling
parameters is that they use space transformations to ﬁnd an
invariant to describe the relation between the aerodynamic coef-
ﬁcient and ﬂow parameters. In this sense, all the existing scaling
parameters could be uniﬁed.
3.2. AST method
As discussed in the above sections, regarding the prediction as
a merely mathematical extrapolation might get unreliable result.
Scaling parameter makes prediction in a distinct way. It is essentially a physical based method, which uses the invariant of a system for prediction. However, all the existing scaling parameters
are obtained manually, and it requires strong expertise and
experience to get a working scaling parameter. Perhaps only
experienced physicians are qualiﬁed for this mission. This limits
the application scope of scaling parameters. A new method that
can automatically detect the invariant of a system is desired.
With the development of computational intelligence, especially
in genetic programming (GP), optimization in function space
becomes feasible. This makes it possible to detect the kernel of
space transformation (scaling parameter) automatically. Of course,
keeping in mind that the optimization should be supervised by
physicists. The physicists interact with GP only before and after the
evolution process. For example, the parameter selection, nondimensionalization, and the interval choice should be considered
aforehand, and the optimized result should also be chosen carefully. An unsupervised optimization is likely failed to detect an
invariant. For example, the ﬂight in Mach 3–7 could be considered
as a system, but as the Mach number increases, new physical
phenomena such as dissociation and ionization might arise and
become non-ignorable gradually. In this case, pure mathematical
optimization might result in misleading result.
Therefore,
prediction
mathematics-assisted physical problem, and propose an adaptive
space transformation (AST) method for the prediction. AST is a
supervised self-learning scheme. It tries to automatically detect an
underlying invariant of a system and give a new/better scaling
parameter with the known data under the supervision of physicists. Once the invariant is detected, it will be used for prediction.
The optimization of scaling parameter (i.e., kernel of space
transformation) in the function space could be driven by any
genetic programming (GP) algorithm including the conventional
genetic programming , grammatical evolution , parse-matrix evolution ,
etc. In this work, we use a special version of genetic programming,
parse matrix evolution , since we
know every detail of it, which can help ensure its global convergence. In PME, a chromosome is a parse-matrix with integer
entries, and the mapping process from the chromosome to its
analytical function is based on a mapping table containing terminals and operators. The evolutionary operators are adapted from
traditional crossover and mutation. The crossover might be onepoint, two-point, or cut-and-splice in row, and the mutation is a
kind of random mutation. The height of the parse-matrix can
upper-bound the subtree-level of evolved expression so as to
control the complexity of the resulted function.
Of course, the reader could choose any other GPs for the optimization process. Therefore, more detailed implementation and
performance of GP itself is beyond the discussion scope of this
paper, and we assume that the chosen GP is capable of getting a
global optimal function in probability.
To describe a general AST method is difﬁcult. As an illustrative
example, suppose we need to detect the invariant about Mach
number, an optimal scaling parameter fn could be determined in
the following steps.
(1) Divide the original data into different groups according to the
Mach number: fðMi; Rei;j; Ji;jÞji ¼ 1; 2; …; N; j ¼ 1; 2; …; Mig.
(2) Construct characteristic curves in 2-D space (see Fig. 4(a)):
J ¼ ϕiðsÞ, where s ¼ f kðMi; Rei;jÞ; i ¼ 1; 2; …; N; j ¼ 1; 2; …; Mi.
(3) Optimize and update the transformation kernel fk by genetic
programming such that the characteristic curves tend to
overlap with each other (see Fig. 4(b)).
(4) Repeat steps (2) and (3) until some stopping criteria are
satisﬁed, and output the best transformation kernel fn (as the
optimal scaling parameter) and its corresponding characteristic curves.
In Step 2, a trivial kernel (e.g., the projection transform
f ðMi; Rei;jÞ ¼ Mi)
initialization
s=fk(M∞, Re∞)
s=f*(M∞, Re∞)
Fig. 4. Initial and ﬁnal state of AST. (a) Characteristic curves of a trivial scaling parameter. (b) Transformed curves with an optimal kernel.
C. Luo et al. / Engineering Applications of Artiﬁcial Intelligence 46 93–103
characteristic curves. That is, f0 could be a random kernel if the
user has little knowledge about it. However, a preset f0 is preferred
for an experienced user since a good start might lead to a faster
convergence.
The ﬂowchart of AST could be brieﬂy described in Fig. 5.
3.3. Optimization models of AST method
The most important step in adaptive space transformation
(AST) is the optimization of the kernel function fk in Step (3), in
which the objective is to drive the characteristic curves to overlap
with each other. To this end, an optimization model that can
measure the degree of overlapping is needed, and then the genetic
programming could be applied to ﬁnd an optimal scaling parameter fn from the space of continuous functions CðΩÞ, where Ω is a
compact set in Rm.
Suppose only one parameter x needs to correlate, a typical
optimization model can be formulated as follows:
f ACðΩÞ Gðf Þ ¼
Jϕi f ðxi; yÞ
ϕj f ðxj; yÞ
Jds=Sconvhull
where the function z ¼ ϕiðsÞ describes a characteristic curve in R2,
and the function s ¼ f ðx; yÞ is the transformation kernel to be
optimized. The symbol Sconvhull denotes the area of the convex hull
of all transformed data fðf ðxi; yi;jÞ; zi;jÞjj ¼ 1; 2; …; mig. It is used only
for nondimensionalization. The value of the objective function Gðf Þ
shows how close the characteristic curves are. Each characteristic
curve is determined by a subgroup of the test data with xi ﬁxed:
fðxi; yi;j; zi;jÞj j ¼ 1; 2; …; mig. The characteristic curve can be constructed by any of a robust approximation method such as ﬁtting
or regression.
When more parameters, i.e., x1; x2; …; xm, need to correlate, a
similar optimization model can be formulated in high dimensional
space as follows.
X ¼ ðx1; x2; …; xmÞ; Y ¼ ðy1; y2; …; ynÞ,
S ¼ ðs1; s2; …; spÞ, then
f ACðΩÞ Gðf Þ ¼
S  Rp Jϕi f ðXi; YÞ
ϕj ðXj; YÞ
where the function z ¼ ϕiðSÞ describes the characteristic hypersurface in Rp þ1 with ﬁxed Xi such that it ﬁts its subgroup data
fðXi; Yi;j; zi;jÞjj ¼ 1; 2; …; mig,
S ¼ f ðX; YÞðf :
Rmþ n↦RpÞ is the transformation kernel to be optimized. The
transformed data. The value of the objective function Gðf Þ shows
how close the characteristic hyper-surfaces are. Here the characteristic hyper-surfaces could also be constructed by any of a
robust approximation method such as ﬁtting or regression.
3.4. Properties of kernel function
It is noteworthy that the optimal scaling parameter might be
not unique. In addition, we have the following conclusion.
Proposition 3.1. Let the transformation kernel s ¼ f nðx; yÞ be an
optimal scaling parameter. Then its nontrivial function Fðf nðx; yÞÞ is
still an optimal one.
A typical example is as follows. If the scaling parameter fn is
perfect, i.e., Gðf nÞ ¼ 0, which means the characteristic curves is
already overlapped as a single smooth curve (e.g., Fig. 6(b)).
Therefore, under the nontrivial map of the composite function
FðsÞ ¼ Fðf ðx; yÞÞ, the transformed curve of the smooth curve should
still be a smooth curve (see Fig. 6(c) and (d)).
Although the optimal scaling parameter is not unique, its
capability of prediction is not affected. In fact, any one of the
optimal scaling parameter can be used as the correlation parameter for prediction.
This is similar to the ellipse case mentioned above, where the
invariant is also not unique. As an example, another invariant can
be described as “the eccentricity of a given ellipse e is a constant”.
This invariant could also be used to predict the unknown part of
the ellipse with a piece of it.
3.5. Practical tricks and discussion
Note that there might be an offset between curves after the
transformation, as can be seen from Figs. 2 and 6. In practical
implementations, the offset must be restrained. The penalty
function method has been used
to suppress it in this work.
Another issue about AST method is that the complexity of the
scaling parameter must be controlled. Otherwise, its performance
will degenerate into that of nonlinear ﬁt or regression. In this
paper, the complexity is used as the second objective function, and
the trade-off between the overlap degree of transformed curve
and the complexity of kernel function is analyzed by multiobjective optimization method. Only the knee of Pareto front
 is selected as the best scaling parameter.
For a given system, the invariant does not always exist. The
proposed method is more suitable for those problems with
invariant. However, in case the desired invariant does not exist,
AST can help to get a best scaling parameter, which, in the worst
case, is a ﬁtting function.
4. Prediction results
Prediction capability, especially when the point to predict lies
outside of the known range (extrapolation), is the most important
feature of an correlation method. In this section, the prediction
capability of adaptive space transformation (AST) is tested by
comparing with two state-of-the-art approximate based methods,
support vector machine (SVM) and artiﬁcial neural network
(ANN), since both of the methods have been used for predicting
the aerodynamic coefﬁcients . The proposed
AST method is then applied to two real world problems. One is to
improve the existing scaling parameters Kn, and the other is to
Fig. 5. Flowchart of AST.
C. Luo et al. / Engineering Applications of Artiﬁcial Intelligence 46 93–103
detect a new scaling parameter for the drag prediction of a sharp
cone at hypersonic speeds.
4.1. Test of prediction capability
The toy problem, z ¼ x2 þy2, is used to compare the prediction
capability of AST with SVM and ANN. For all of the three methods,
the learning set consists of 121 sample points, which are uniformly
distributed in ½3; 3  ½3; 3, while the set to predict is spread
across the region ½6; 6  ½6; 6. In this case, most of the points
to predict (about 75%) lies out side of the known range. The predicted surfaces are shown in Fig. 7(a), (c) and (e). To show the
performance of these methods more clearly, a test set of 625
points uniformly distributed in ½6; 6  ½6; 6 is taken to show
the prediction deviation of each method (see Fig. 7(b), (d) and (f).
In this work, the genetic programming method used in AST is
parse matrix evolution (PME), and the characteristic curves are
constructed with an improved version of Kriging regression
method, DACE . The SVM used in this work
is a specialized version for regression, referred to as ϵSVR in
Chang and Lin , with the kernel type of radial basis function
(RBF). Another variant of SVM, νSVR, is also tested on this problem. The parameters of SVR are set to their suggested default
values. The ANN used in this work is a specialized version of the
feed forward network for ﬁtting an input–output relationship . The hidden layer size is
set to 10. The sample data are divided into three parts for training,
validation, and testing. The percentages are 70%, 15% and 15%,
respectively.
Fig. 7 shows that all these methods work well to predict the
value at the new point within the range the sampled region, but
difﬁcult to predict outside of the known range. The predicted value
of ϵSVR is far from its actual one outside the convex-hull (see
Fig. 7(b)). The rescaled mean squared error 1R2 is 0.079 for the
test data within the convex-hull of samples (red in ﬁgure), and
2.061 for all the test data. νSVR has a similar performance. The
1R2 is 0.0866 within the convex-hull, and 2.054 for all. ANN
performs much better (see Fig. 7(d)). The 1R2 is 5:34  10 8
within the convex-hull, and 0.0912 for all. However, if only an
invariant is the detected, the proposed AST method works great on
all valid regions (see Fig. 7(f)). The 1R2 is 1:49  10 8 within the
convex-hull, and 2:56  10 8 for all.
4.2. Practical applications
Affected by random factors and measurement/computation
errors, real-world data are much more complex than the above toy
problem. This makes it more difﬁcult to get a working scaling
parameter. To test the capability of AST method, two real-world
problems are considered. In problem one, the data are read from
s=x/sqrt(y)
s=exp(-x 2/y)
Fig. 6. A typical example with three perfect scaling parameters. (a) Projection of original data. (b) Transformed curves with a perfect scaling parameter. (c) Transformed
curves with the square of the perfect scaling parameter. (d) Transformed curves with another function of scaling parameter.
C. Luo et al. / Engineering Applications of Artiﬁcial Intelligence 46 93–103
Fig. 1 in Macrossan . Since there is already an existing
scaling parameter, the Knudsen number Kn, the objective in this
work is to ﬁnd a better scaling parameter that could bring the
transformed curves (of different Mach numbers, see Fig. 8) closer.
From Fig. 8(b)–(d), we can see that the scaling parameter could be
improved better and better by AST.
Although f3 is the best so far scaling parameter we could ﬁnd,
the transformed curves could not overlap each other. This means
that the scaling parameter f3 is not a perfect one, and the combination of (Kn, M) is not suitable for constructing an scaling parameter. However, a better scaling parameter could be expected if
more information of the data, e.g., Reynolds number, is available.
Fig. 7. Comparison of extrapolation capability of SVR, ANN, and AST. (a) Predicted surface by ϵSVR. (b) Prediction deviation of ϵSVR. (c) Predicted surface by ANN.
(d) Prediction deviation of ANN. (e) Predicted surface by AST. (f) Prediction deviation of AST. (For interpretation of the references to color in this ﬁgure caption, the reader is
referred to the web version of this paper.)
C. Luo et al. / Engineering Applications of Artiﬁcial Intelligence 46 93–103
The second problem is to ﬁnd a scaling parameter for drag
prediction of a sharp cone with 10° half-angle. The full length of
the cone is 1.5 m. The scale of models ranges from 0.1° to 1.0°. The
learning and test data are all obtained by computational ﬂuid
dynamics (CFD) simulation. For the test data, the Mach number of
free stream ranges from 4 to 9, temperature from 50 K to 250 K,
pressure from 560 Pa to 12 560 Pa, angle of attack (AoA) from 0° to
15°. However, the learning data has a much smaller range. All
parameters are shrunk to their lower half part except the AoA. To
get a reasonable result, 1024 cases are simulated, and 24 of outliers
are removed. A part of them with smaller parameters are assigned
to the learning set, and the others are used for testing the prediction capability of AST. All the data are aligned to 8 degree of
AoA (this process is beyond the scope of this paper) for the
invariant detection. Only non-dimensional parameters, Mach
number and Reynolds number are considered to be correlated.
Based on previous studies, the Reynolds number is transformed
with a logarithmic function Log 10ðÞ, and each component of the
data is then linearly mapped to the interval . Or, more speciﬁcally, the minimum xmin and maximum values xmax of each
parameter is normalized to [ymin, ymax] by the formula y¼
(ymaxymin)n(xxmin)/(xmaxxmin) þ ymin, where ymin¼1,
normalized
M ¼ ð21ÞnðM1 4Þ=ð94Þþ1 ¼ ðM1 4Þ=5þ1. Under the above
conditions, Reynolds number Re1 A½1:47E6; 3:69E9. So we get
Log 10ðRe1ÞA½6:17; 9:57, and the normalized Reynolds number
Re ¼ ðLog 10ðRe1Þ6:17Þ=3:4þ1.
Using the information from the 200 learning cases of smaller
parameters, a new scaling parameter s ¼ Re  ð1MÞ is obtained by
AST. It can transform the learning data into a smooth curve
approximatively (see Fig. 9(a)). With this scaling parameter, the
other 800 cases, most of them lies outside of the convex hull of the
learning data, are predicted. The prediction results are compared
with that of their corresponding CFD cases, the deviations are
shown in Fig. 9(b). It shows that the prediction results agree well
with CFD, no matter whether the case is inside (interpolation) the
range of learning set or not (extrapolation). The rescaled mean
squared error 1R2 inside and outside of the convex-hull are
0.0018, and 0.0021, respectively.
Although AST works great on these problem, the extrapolation
capability of AST should not be exaggerated. Keeping in mind that
the extrapolated result is reliable only if the system has not
essentially changed (so that the invariant still holds). For example,
with the increase of ﬂight speed, say M1 415, the real gas effect
will become more and more important, and its inﬂuence on the
coefﬁcient of aerodynamic forces might be non-ignorable. In this
case, the above scaling parameter might be inapplicable and
should be improved. Here, whether the system has essentially
changed or not should be decided by practical physicists. The
decision process is beyond the scope of this paper.
s=f1(Kn, M)
s=f2(Kn, M)
s=f3(Kn, M)
Fig. 8. Improvement of an existing scaling parameter by AST. (a) Correlated data with Kn. (b) Correlated data with s ¼ f 1ðKn; MÞ. (c) Correlated data with s ¼ f 2ðKn; MÞ.
(d) Correlated data with s ¼ f 3ðKn; MÞ.
C. Luo et al. / Engineering Applications of Artiﬁcial Intelligence 46 93–103
As a comparison, ANN and ϵSVR are also applied to predict the
drag coefﬁcient CA of the sharp cone (see Fig.10). The study shows that
both of the algorithms predict well inside the convex-hull of samples
(red in ﬁgure). The rescaled mean squared error 1R2 is 0.0075 and
0.0071, respectively. But the prediction performance degenerates
greatly outside the convex-hull. The rescaled mean squared error
1R2 is 0.1032 and 0.1457, respectively.
5. Conclusion
We found that the existing scaling parameters are essentially
space transformations to detect invariant of the high-speed rareﬁed ﬂow. Based on this discovery, a new method, referred to as
adaptive space transformation (AST), is proposed for the prediction of aerodynamic coefﬁcients. AST tries to detect an invariant
relation of the system by analyzing the known data with genetic
programming. Once the invariant relation is detected, it will be
used for prediction. The prediction result should be reliable provided that the ﬂow around the hypersonic vehicles has not
essentially changed, i.e., no new physical phenomenon, such as
dissociation or ionization, turns up and becomes non-ignorable.
Under this assumption, the underlying physical nature will remain
unchanged, and the invariant relation still holds. That is why the
extrapolation results of AST are more reliable than that of
approximation based methods. Practical results have conﬁrmed its
prediction capability.
The complexity of the transformation kernel (scaling parameter) is well controlled in AST. So the resulted formula is usually
quite concise (e.g., the above result s ¼ Re  ð1MÞ). In addition, the
transformed data could be visualized in a 2-D plane. So the result
is easy to interpret and easy to use.
AST method can help improve existing scaling parameters, as
well as derive a new one for new cases automatically. In this sense,
existing scaling parameters could be regarded as typical solutions
of AST method in the special case (for high-speed rareﬁed ﬂow).
AST provides a reliable method for predicting the aerodynamic
coefﬁcient of hypersonic vehicles.
Although AST is proposed under the background of predicting
aerodynamic coefﬁcients of hypersonic vehicles, it can be used for
other data correlation problems, provided that the underlying
invariant of the concerned system exists.
Acknowledgment
The authors would like to thank the anonymous reviewers for
their constructive comments related to earlier manuscript versions
of this work.
Fig. 10. Prediction deviation of ANN (a) and ϵSVR (b), inside and outside the convex-hull. (For interpretation of the references to color in this ﬁgure caption, the reader is
referred to the web version of this paper.)
Fig. 9. A best scaling parameter and its performance on cone-drag prediction. (a) A best scaling parameter for cone drag prediction. (b) Prediction deviation of AST.
C. Luo et al. / Engineering Applications of Artiﬁcial Intelligence 46 93–103