Improving Conversational Recommender Systems via
Knowledge Graph based Semantic Fusion
Peking University
 
Wayne Xin Zhao*†
Gaoling School of Artificial
Intelligence, Renmin University of
 
Shuqing Bian
School of Information, Renmin
University of China
 
Yuanhang Zhou
School of Information, Renmin
University of China
 
Ji-Rong Wen†
Gaoling School of Artificial
Intelligence, Renmin University of
 
Jingsong Yu
Peking University
 
Conversational recommender systems (CRS) aim to recommend
high-quality items to users through interactive conversations. Although several efforts have been made for CRS, two major issues
still remain to be solved. First, the conversation data itself lacks
of sufficient contextual information for accurately understanding
users’ preference. Second, there is a semantic gap between natural
language expression and item-level user preference.
To address these issues, we incorporate both word-oriented and
entity-oriented knowledge graphs (KG) to enhance the data representations in CRSs, and adopt Mutual Information Maximization
to align the word-level and entity-level semantic spaces. Based on
the aligned semantic representations, we further develop a KGenhanced recommender component for making accurate recommendations, and a KG-enhanced dialog component that can generate informative keywords or entities in the response text. Extensive
experiments have demonstrated the effectiveness of our approach
in yielding better performance on both recommendation and conversation tasks.
CCS CONCEPTS
• Information systems →Recommender systems; • Computing methodologies →Natural language generation.
Conversational Recommender System; Knowledge Graph; Mutual
Information Maximization
∗Corresponding author.
†Also with Beijing Key Laboratory of Big Data Management and Analysis Methods.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from .
KDD ’20, August 23–27, 2020, Virtual Event, USA
© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-7998-4/20/08...$15.00
 
ACM Reference Format:
Kun Zhou, Wayne Xin Zhao*†, Shuqing Bian, Yuanhang Zhou, Ji-Rong
Wen†, and Jingsong Yu. 2020. Improving Conversational Recommender
Systems via Knowledge Graph based Semantic Fusion. In 26th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining (KDD ’20), August 23–
27, 2020, Virtual Event, USA. ACM, New York, NY, USA, 9 pages. https:
//doi.org/10.1145/3394486.3403143
INTRODUCTION
Recently, conversational recommender system (CRS) has become an emerging research topic in seeking to provide
high-quality recommendations through conversations with users.
Different from traditional recommender systems, it emphasizes
interactive clarification and explicit feedback in natural languages,
and has a high impact on e-commerce.
In terms of methodology, CRS requires a seamless integration
between a recommender component and a dialog component. On
one hand, the dialog component clarifies user intents and replies
to the previous utterance with suitable responses. On the other
hand, the recommender component learns user preference and
recommends high-quality items based on contextual utterances.
To develop an effective CRS, several solutions have been proposed
to integrate the two components, including belief tracker over
semi-structured user queries and switching decoder for
component selection .
Although these studies have improved the performance of CRS
to some extent, two major issues still remain to be solved. First, a
conversation mainly consists of a few sentences, lack of sufficient
contextual information for accurately understanding user preference. As shown in Table 1, a user is looking for scary movies similar
to “Paranormal Activity ”, where her/his preference is simply
described by two short sentences. In order to capture the user’s intent, we need to fully utilize and model the contextual information.
In this example, it is important to understand the underlying semantics of the word “scary” and the movie “Paranormal Activity ”.
Apparently, it is difficult to obtain such fact information solely
based on the utterance text. Second, utterances are represented in
natural languages, while actual user preference is reflected over the
items or entities (e.g., actor and genre). There is a natural semantic
gap between the two kinds of data signals. We need an effective
 
Table 1: An illustrative example of a user-system conversation for movie recommendation. The mentioned movies and
important context words are marked in italic blue font and
red font, respectively.
I am looking for some movies
What kinds of movie do you like?
Today I’m in a mood for something scary. Any
similar movies like Paranormal Activity ?
It might be good for you. It is a classic
thriller movie with good plot.
Great! Thank you!
semantic fusion way to understand or generate the utterances. As
shown in Table 1, the system has presented both the recommended
movie and the reason for recommendation. Without bridging the
semantic gap, it is infeasible to generate the text for explaining the
recommendation, e.g., “thriller movie with good plot”.
For enriching the conversation information, external knowledge
graph (KG) has been utilized in CRS . They mainly focus on
incorporating item knowledge, while the word-level enrichment
(e.g., the relation between “scary” and “thriller”) has been somehow
neglected. Furthermore, they have not considered the semantic gap
between natural language and external knowledge. Therefore, the
utilization of KG data is likely to be limited. In essence, the problem
originates from the fact that the dialog component and the recommender component correspond to two different semantic spaces,
namely word-level and entity-level semantic spaces. Our idea is to
incorporate two special KGs for enhancing data representations of
both components, and fuse the two semantic spaces by associating
the two KGs.
To this end, in this paper, we propose a novel conversational recommendation approach via KG based semantic fusion. Specially, we
incorporate a word-oriented KG (i.e., ConceptNet ) and an itemoriented KG (i.e., DBpedia ). ConceptNet provides the relations
between words, such as the synonyms, antonyms and co-occurrence
words of a word; DBpedia provides the structured facts regarding
the attributes of items. We first apply graph neural networks to
learn node embeddings over the two KGs separately, and then propose to apply the Mutual Information Maximization 
method to bridge the semantic gap between the two KGs. The core
idea is to force the representations of nodes in the two KGs to be
close given the word-item co-occurrence in the conversation. In
this way, we can unify the data representations in the two semantic spaces. Such a step is particularly useful to connect contextual
words with items (including the mentioned entities) in conversations. Based on the aligned semantic representations, we further
develop a KG-enhanced recommender component for making accurate recommendations, and a KG-enhanced dialog component that
can generate informative keywords or items in the response text.
To our knowledge, it is the first time that the integration of
dialog and recommender systems has been addressed by using KGenhanced semantic fusion. Our model utilizes two different KGs to
enhance the semantics of words and items, respectively, and unifies
their representation spaces. Extensive experiments on a public CRS
dataset have demonstrated the effectiveness of our approach in
both recommendation and conversation tasks.
RELATED WORK
Conversational recommendation system (CRS) contains two major modules, namely the recommender component and the dialog
component. We first introduce the related work in the two aspects.
Recommender systems aim to identify a subset of items that
meet the user’s interest from the item pool. Traditional methods
are highly based on the historical user-item interaction (e.g., click
and purchase) . However, user-item interaction data is usually sparse. To tackle the data sparsity problem, many techniques
have been developed by utilizing the side information of items,
such as review and taxonomy data . As a comparison, CRS
mainly focuses on the recommendation setting through conversation instead of historical interaction data. Especially, knowledge
graphs have been widely adopted to enhance the recommendation
performance and explainability .
Conversation systems aim to generate proper responses given
multi-turn contextual utterances. Existing works can be categorized into retrieval-based methods and generation-based
methods . The first category of approaches try to find the
most reasonable response from a large repository of historical conversations , and the generation-based methods utilize learnable models to produce the response text. Based on the attentive
seq2seq architecture , various extensions have been made to
tackle the “safe response” problem and generate informative responses .
Early conversational or interactive recommendation systems
mainly utilized predefined actions to interact with users . Recently, several studies started to integrate the two components
for understanding users’ needs and recommend the right items
through natural language conversation . Overall, these
methods emphasize the precise recommendation, while the conversation component is implemented by simple or heuristic solutions.
Specially, a standard CRS dataset has been released in , and a
hierarchical RNN model was proposed for utterance generation.
Furthermore, follow-up studies incorporated external KG
to improve the CRS, where their focus was to mainly enhance the
item representations.
Based on previous studies, we design a novel conversational
recommendation approach by incorporating and fusing word-level
and entity-level knowledge graphs. Via KG fusion, our model is
able to learn better data representations in both recommender and
dialog components, which leads to better performance on item
recommendation and utterance generation.
PRELIMINARIES
Conversational recommendation systems (CRS) aim to recommend
proper items to a user through a multi-turn conversation. In the
conversation, a chat agent analyzes and learns the preference of the
user according to contextual conversation history. Then, it either
generates appropriate recommendations or starts a new round of
conversation for further clarification. The process ends until the
task succeeds or the user leaves. In a CRS, there are two major
components to develop, namely the recommender component and
the dialog component. The two components should be integrated
seamlessly, and successful recommendation is considered as the
final goal.
Formally, let u denotes a user from user set U, i denotes an
item from item set I, and w denotes a word from vocabulary V.
A conversation (or a conversation history) C consists of a list of
utterances, denoted by C = {st }n
t=1, in which each utterance st
is a conversation sentence at the t-th turn. At the t-th turn, the
recommender component selects a set of candidate items It from
the entire item set I according to some strategy, while the dialog
component needs to produce the next utterance st to reply to previous utterances. Note that It can be equal to ∅when there is no
need for recommendation. In such a case, the dialog component
may raise a clarification question or generate a chit-chat response.
Given a n-turn conversation, the goal of a CRS is to generate the
response utterance to the user, including both the recommendation
set In+1 and the reply utterance sn+1.
In this section, we present the KG-based Semantic Fusion approach
to the CRS task, named KGSF. We first introduce how to encode both
word-oriented and item-oriented KGs, and then fuse the semantics
of the two KGs. Based on the fused KGs, we finally describe our
solutions for both recommendation and conversation tasks. The
overview illustration of the proposed model is presented in Fig. 1.
Encoding External Knowledge Graphs
As shown in Table 1, it is difficult to fully understand user preference
and generate a suitable response. We identify the two basic semantic
units in dialog and recommender systems, namely word and item,
respectively. Here, we utilize two separate KGs to enhance the
representations of the basic semantic units on both sides.
Encoding Word-oriented KG. We adopt the widely used ConceptNet as the word-oriented KG. It stores a semantic fact as
a triple ⟨w1,r,w2⟩, where w1,w2 ∈V are words and r is a word
relation. Not all the words in ConceptNet are useful for our task.
Hence, we only consider words that appear in our corpus, and extract their related triples from ConceptNet. We also remove words
with very few triples related to the words in our corpus.
To encode the word-oriented KG, we adopt graph convolutional
neural network (GCN) for capturing the semantic relations
between word nodes. At each update, GCN receives the information
from the one-hop neighborhood in the graph and performs the
aggregation operation as:
V(l) = ReLU(D−1
2 V(l−1)W(l))
where V(l) ∈RV ×dW are the representations of nodes and W(l) is
a learnable matrix at the l-th layer, A is the adjacency matrix of
the graph and D is a diagonal degree matrix with entries D[i,i] =
j A[i, j]. By stacking multiple convolutions, node information can
be propagated along with the graph structure. When the algorithm
ends, we can obtain adW -dimensional representationnw for a word
w. Here, we do not incorporate the relation information, because
the number of relations is large and many relations are not directly
useful to the recommendation task.
Encoding Item-oriented KG. Another kind of semantic units
to consider are items and their related entities. Following , we
utilize DBpedia as item-oriented KG. Similar to ConceptNet,
a triple in DBpedia is denoted by ⟨e1,r,e2⟩, where e1,e2 ∈E are
items or entities from the entity set E and r is entity relation from
the relation set R. To extract the entity subgraph, we collect all the
entities appearing in our corpus by following the approach from .
Starting from these items and entities as seeds, we extract their
one-hop triples on the DBpedia graph.
For item-oriented KG, relation semantics are important to consider. Different from ConceptNet, we utilize R-GCN to learn
item representations on the extracted subgraph. Formally, the representation of node e at (l + 1)-th layer is calculated as:
e′ + W(l)n(l)
where n(l)
∈RdE is the node representation of e at the l-th layer,
Ere denotes the set of neighboring nodes for e under the relation
is a learnable relation-specific transformation matrix for
the embeddings from neighboring nodes with relation r, W(l) is a
learnable matrix for transforming the representations of nodes at
the l-th layer and Ze,r is a normalization factor.
KG Fusion via Mutual Information
Maximization
Above, we obtain the node representations for the word-oriented
KG and item-oriented KG, denoted by two embedding matrices V
(vw for word w) and N (ne for item e), respectively.
In order to bridge the semantic gap between words and items,
we propose to use Mutual Information Maximization technique , called MIM. MIM has been used to mutually improve the
data representations of two coupled signals (e.g., input and output).
Its core idea is based on the concept of Mutual Information (MI).
Given two variables X and Y, their MI is defined as:
MI(X,Y) = DKL(p(X,Y)||p(X)p(Y)),
where DKL is the Kullback-Leibler (KL) divergence between the
joint distribution p(X,Y) and the product of marginals p(X)p(Y).
Usually, MI is difficult to compute. MIM tries to maximize it instead
of seeking the precise value via the following formula:
MI(X,Y) ≥EP [д(x,y)] −EN [д(x ′,y′)],
where EP and EP denote the expectation over positive and negative
samples respectively, and д(·) is the binary classification function
that outputs a real number which can be modeled by a neural
In our setting, we have two kinds of semantic units (namely
words and entities), and would like to align their semantic representation spaces. Given a conversation, we first collect words
(non-stopwords) and entities (including items) from the utterance
text. For an entity-word pair ⟨e,w⟩that co-occur in a conversation, we pull their representations close through a transformation
д(e,w) = σ(n⊤
e · T · vw),
Dialogue Context
Maybe you can see the upcoming
Spider-Man
Lookup Table
S1: Can I help you today?
S2: I would like to
watch a popular movie
S3: I recommend the
Marvel series movie The
Avengers. Have you seen
S4: I have seen it, the
superhero is really cool!
Could you give another
recommendation?
Graph-based Semantic Fusion
Recommender System
Dialogue System
ConceptNet
intelligent
participate
Lookup Table
Spider-Man
Spider-Man
Embeddings
Spider-Man
Figure 1: The overview of our model with a movie recommendation scenario. Here,“SA”, “KA”, and “CA” denotes self-attention,
KG-based attention and context-based attention, respectively.
where ne and vw are the learned node representations for entity e
and word w via KGs, respectively, T ∈RdE×dW is the transformation matrix that aligns two semantic spaces, and σ(·) is the sigmoid
function. To apply the MIM method, we can consider all the wordentity pairs co-occurring in a conversation as positive, while random
word-entity pairs are considered as negative. By integrating Eq. 5
into Eq. 4, we can derive the objective loss over all the conversations
and minimize the loss with an optimization algorithm.
However, a conversation usually contains a number of contextual
words, and it is time-consuming to enumerate all the word-entity
pairs. Besides, some of these words are noisy, which is likely to
affect the final performance. Here, we add a super token ˜w for a conversation, assuming that it is able to represent the overall semantics
of the contextual words. Instead of considering all the word-entity
pairs, we only model the relation between each entity and the super
token ˜w using theд(·) function. We utilize self-attention mechanism
for learning the representation of ˜w:
softmax(b⊤· tanh(Wα V(C))),
where V(C) is the matrix consisting of the embeddings of all the
contextual words in a conversation C, α is an attention weight
vector reflecting the importance of each word, and Wα and b are
parameter matrix and vector to learn. Using such a super token, we
can significantly improve efficiency and identify more important
semantic information from the entire conversation.
In order to effectively align the semantic space of the two KGs,
we adopt the MIM loss for pre-training the parameters of the GNN
models in Section 4.1.1 and 4.1.2, which forces the two semantic
spaces to be close at the beginning. During the fine-tuning stage,
we treat the MIM loss as a regularization constraint for GNN to
prevent overfitting.
With the representations of the fused KGs, we next describe how
to make recommendations and generate utterances in Section 4.3
and 4.4, respectively.
KG-enhanced Recommender Module
Given the learned word and item representations, we study how to
generate a set of items for recommendation in CRS.
A key point for recommendation is to learn a good representation
of user preference. Different from traditional recommender systems,
following , we assume no previous interaction records are
available. We can only utilize the conversation data to infer user
preference.
First, we collect all the words that appear in a conversation c.
By using a simple lookup operation, we can obtain the word or
item embeddings learned through the graph neural networks in
Section 4.2. We concatenate the word embeddings into a matrix
V(C). Similarly, we can derive an item embedding matrix N(C) by
combining the embeddings of items.
Next, we apply the similar self-attentive mechanism in Eq. 6 to
learn a single word vector v(C) for V(C) and a single item vector
n(C) for N(C). In order to combine the two parts of information, we
apply the gate mechanism to derive the preference representation
pu of the user u:
β · v(C) + (1 −β) · n(C),
σ(Wgate[v(C);n(C)]),
Given the learned user preference, we can compute the probability that recommends an item i from the item set to a user u:
Prrec(i) = softmax(p⊤
where ni is the learned item embedding for item i. We can utilize
Eq. 8 to rank all the items and generate a recommendation set to a
user. To learn the parameters, we set a cross-entropy loss as:
−(1 −yij) · log  1 −Pr(j)
+yij · log  Pr(j)
+ λ ∗LMI M,
where j is the index of a conversation,i is the index of an item, LMI M
is the Mutual Information Maximization loss, and λ is a weighted
parameter. Here, we loop the entire collection and compute the
cross-entropy loss. We only present the case that a conversation
has a ground-truth recommendation. While, it is straightforward to
extend the above loss to the case with multiple ground-truth items.
KG-enhanced Response Generation Module
Here, we study how to generate a reply utterance in CRS. We adopt
Transformer to develop the encoder-decoder framework. Our
encoder follows a standard Transformer architecture. We mainly
introduce the KG-enhanced decoder.
To better generate responses at decoding, we incorporate KGenhanced representations of context words and items. After the
self-attention sub-layer, we conduct two KG-based attention layerss
to fuse the information from the two KGs:
MHA(Rn−1, Rn−1, Rn−1),
0 , V(C), V(C)),
1 , N(C), N(C)),
2 , X, X),
where MHA(Q, K, V) defines the multi-head attention function 
that takes a query matrix Q, a key matrix K, and a value matrix V
MHA(Q, K, V) = Concat(head1, . . . , headh)WO,
headi = Attention(QWQ
and FFN(x) defines a fully connected feed-forward network, which
consists of a linear transformation with a ReLU activation layer:
FFN(x) = max(0,xW1 + b1)W2 + b2.
Above, X is the embedding matrix output by the encoder, V(C)
and N(C) are KG-enhanced representation matrices for words and
items in a conversation c, respectively. And, An
are the representations after self-attention, cross-attention with
embeddings from ConceptNet, cross-attention with embeddings
from DBpedia and cross-attention with encoder output, respectively.
Finally, Rn is the embedding matrix from the decoder at n-th layer.
Algorithm 1: The training algorithm for the KGFS model.
Input: The conversation recommendation dataset D, item-oriented
KG G1, and word-oriented KG G2
Output: Model parameters Θд, Θr and Θd.
1 Randomly initialize Θд, Θr and Θd.
2 Pre-train the Θд by minimizing the MIM loss in 4.2.
3 for t = 1 →|D | do
Acquire items’ and words’ representations from G1 and G2 by
Eq. 1 and Eq. 2, respectively.
Acquire v(C) and v(C) by self-attention using Eq. 6.
Acquire pu by gate mechanism using Eq. 7.
Compute Prrec(i) using Eq. 8.
Perform GD on Eq. 9 w.r.t. Θд and Θr .
10 for i = 1 →|D | do
Acquire items’ and words’ representations from G1 and G2 by
Eq. 1 and Eq. 2, respectively.
Acquire Rn by KG-enhanced Transformer using Eq. 14.
Compute Pr(y |y1, · · · , yi−1) using Eq. 18.
Perform GD on Eq. 19 w.r.t. Θd.
16 return Θд, Θr and Θd.
Compared with a standard Transformer decoder, we have two
additional steps in Eq. 11 and 12. The idea can be described using
a transformation chain: generated words
−−−−−→word-oriented KG
−−−−−→item-oriented KG
−−−−−→context words. Following such a
chain, our decoder is able to gradually inject useful knowledge information from the two KGs in a sequential manner. The rationality
for Eq. 12 lies in the fact that we have fused the two KGs as in
Section 4.2.
Different from chit-chat models, the generated reply is expected
to contain the recommended items, related entities and descriptive
keywords. We further adopt the copy mechanism to enhance the
generation of such tokens. Formally, given the predicted subsequence y1, · · · ,yi−1, the probability of generating yi as the next
token is given as:
Pr(yi |y1, · · · ,yi−1) = Pr1(yi |Ri) + Pr2(yi |Ri, G1, G2),
where Pr1(·) is the generative probability implemented as a softmax function over the vocabulary by taking the decoder output
Ri (Eq. 14) as input, Pr2(·) is the copy probability implemented by
following a standard copy mechanism over the nodes of the two
KGs, and G1, G2 denote the two KGs we have used. To learn the
response generation module, we set the cross-entropy loss as:
log  Pr(st |s1, · · · ,st−1)),
where N is the number of turns in a conversation C. We compute
this loss for each utterance st from C.
Parameter Learning
Our parameters to learn are organized by three groups, namely
the KG module, recommender module and conversation module,
denoted by Θд, Θr and Θd respectively. Algorithm 1 presents the
Table 2: Results on recommendation task. Numbers marked
with * indicate that the improvement is statistically significant compared with the best baseline (t-test with p-value
Cold start
Popularity
training algorithm for our KGSF model. The three components
share parameters and affect each other.
To train the joint model, we pre-train the knowledge graph
module Θд using Mutual Information Maximization loss. Next, we
optimize the parameters in Θr and Θд . At each iteration, we first
acquire words’ and items’ representations from the KG module.
Then, we perform the self-attention and gate mechanism to derive
user representations. Finally, we compute a cross-entropy loss by
Eq. 9 with the MIM regularization, and perform gradient descent
to update parameters Θr and Θд.
When the loss of the recommender component converges, we
optimize the parameters in Θd. At each iteration, we first obtain
words’ and items’ representations from the knowledge graph module. Then, we utilize KG-enhanced Transformer to derive the contextual representations. Finally, we compute the cross-entropy loss
by Eq. 19, and perform gradient descent to update parameters in
EXPERIMENT
In this section, we first set up the experiments, and then report the
results and analysis.
Experiment Setup
Dataset. We evaluate our model on the REcommendations
through DIALog (REDIAL) dataset, which is a conversational recommendation dataset released by . This dataset was constructed
through Amazon Mechanical Turk (AMT). Following a set of comprehensive instructions, the AMT workers generated dialogs for
recommendation on movies in a seeker-recommender pair. It contains 10,006 conversations consisting of 182,150 utterances related
to 51,699 movies. This dataset is split into training, validation and
test sets using a ratio of 8:1:1. For each conversation, we start from
the first sentence one by one to generate reply utterances or recommendations by our model.
Baselines. In CRS, we consider two major tasks for evaluation, namely recommendation and conversation.
• Popularity: It ranks the items according to historical recommendation frequencies in the corpus.
• TextCNN : It adopts a CNN-based model to extract textual
features from contextual utterances as user embedding.
• Transformer : It applies a Transformer-based encoderdecoder framework to generate proper responses without information from recommender module.
• REDIAL : This model has been proposed in the same paper
with our dataset . It basically consists of a dialog generation
module based on HRED , a recommender module based on
auto-encoder and a sentiment analysis module.
• KBRD : This model utilizes DBpedia to enhance the semantics of contextual items or entities. The dialog generation module
is based on the Transformer architecture, in which KG information
serves as word bias for generation.
Among these baselines, Popularity and TextCNN are recommendation methods, and Transformer is the state-of-the-art
text generation method. We do not include other recommendation
models, since there are no historical user-item interaction records
except the text of a single conversation. Besides, REDIAL and
KBRD are conversation recommendation methods. We name
our proposed model as KGSF.
Evaluation Metrics. In our experiments, we adopt different
metrics to evaluate the two tasks. For recommendation task, following , we adopt Recall@k (k = 1, 10, 50) for evaluation. Besides the
standard setting, we consider a specific scenario in recommender
systems, namely cold start.
In CRS, this problem can be alleviated to some extent, since we
have conversation contexts. In order to simulate the cold-start scenario in CRS, we only consider the test cases without any mentioned
items in context. This experiment aims to examine whether our
fusion strategy is useful to learn user preference from word-based
utterances. For the conversation task, the evaluation consists of
automatic evaluation and human evaluation. Following , we use
Distinct n-gram (n = 2, 3, 4) to measure the diversity at sentence
level. For CRS, it is particularly important that the dialog system
is able to generate informative replies related to items or entities.
Hence, we introduce a new metric that calculates the ratio of items
in the generated utterances. Different from traditional conversation
tasks, we do not need to generate response resembling the groundtruth utterance. Instead, the final goal is to successfully make the
recommendations. For this reason, we adopt human evaluation
(on a random selection of 100 multi-turn dialogs from the test set)
instead of using BLEU metrics. We invite three annotators to score
the generated candidates in two aspects, namely Fluency and Informativeness. The range of score is 0 to 2. The final performance is
calculated using the average scores of the three annotators.
Implementation Details. We follow the procedure in Algorithm 1 to implement our approach with Pytorch 1. The dimensionality of embeddings (including hidden vectors) is set to 300 and
128, respectively, for conversation and recommender modules. We
initialize word embeddings via word2vec2. In the KG module, we
set the layer number to 1 for both GNN networks. We use Adam
optimizer with the default parameter setting. In experiments,
the batch size is set to 32, the learning rate is 0.001, gradient clipping
restricts the gradients within [0,0.1], and the normalization constant Zv,r of R-GCN in Eq. 2 is 1. During pre-training, we directly
1 
2 
optimize the MIM loss as Section 4.2. While, during fine-tuning,
the weight λ of the MIM loss in Eq. 9 is 0.025. Our code is publicly
available via the link: 
Evaluation on Recommendation Task
In this subsection, we conduct a series of experiments on the effectiveness of the proposed model for the recommendation task.
Table 2 presents the performance of different methods in the two
Evaluation on All Data Setting. We first consider the all data
setting. As we can see, Popularity achieves a comparable performance with TextCNN. For our CRS task, utterance text is likely to
be sparse and noisy, while Popularity utilizes global statistics for
recommending popular items. Second, the two CRS models Redial
and KBRD perform better than Popularity and TextCNN. Compared
with TextCNN, Redial and KBRD only utilize the entities or items in
context to make recommendations. Furthermore, KBRD performs
better than Redial, since it incorporates external KG information.
It indicates that KG data is useful to enhance the data representations and improves the performance of the CRS task. Finally, our
model KGSF outperforms the baselines with a large margin. KGSF
has incorporated both word-oriented and entity-oriented KGs, and
further fuses the two KGs for enhancing the data representations.
Evaluation on Cold Start Setting. For the cold start setting,
first, the heuristic method Popularity performs very well, even
better than TextCNN and ReDial in most cases. A possible reason
is that in real-world recommender systems, a new user is likely
to adopt a popular item. When there are no items or attributes
mentioned in the context, the performance of KBRD and Redial
has decreased substantially. As a comparison, our model KGSF still
performs stably and achieves the best performance among all the
methods. The major reason is that it not only utilizes item-oriented
KG, but also uses word-oriented KG. By aligning the two semantic
spaces, it can capture important evidence from utterance text to
infer user preference in the cold start setting.
Ablation Study. In our model, we have incorporated two
external KGs and adopted the Mutual Information Maximization
method for KG fusion. Here, we would like to examine the contribution of each part. We incorporate two variants of our model for
ablation analysis, namely KGSF w/o MIM and KGSF w/o DB, which
remove the MIM loss and the DBpedia KG, respectively. Overall, we
can see that both components contribute to the final performance.
Besides, after removing the item-oriented KG, the performance
decreases more significantly. It is because once it was removed, the
corresponding fusion component with MIM is also removed.
The Effect of MIM Technique. We adopt the MIM technique to
fuse semantic representations from two KGs. As shown in previous
experiments, it is useful to improve the performance of our model
on the recommendation task. Here, we would like to study whether
its improvement is consistent and stable with the increase of the
iteration number. We gradually increase the number of iterations
for our model on the training set, and report the corresponding
performance on the test set. Figure 2 shows how the performance
of our model varies with the increase of iterations. We can see that
Iterations
KGFS w/o MIM
(a) Recall@10 in test set
Iterations
KGSF w/o MIM
(b) Recall@50 in test set
Figure 2: Performance (Recall@10 and Recall@50) comparison of KGFS with and without the MIM loss on test set.
Table 3: Automatic evaluation results on the conversation
task. We abbreviate Distinct-2,3,4 as Dist-2,3,4. Numbers
marked with * indicate that the improvement is statistically
significant compared with the best baseline (t-test with pvalue < 0.05).
Item Ratio
Transformer
with the MIM technique, our model can achieve a good result with
fewer iterations compared to the variant without MIM. Overall,
besides the performance improvement, the MIM technique is useful
to improve the stability of the training process.
Evaluation on Conversation Task
In this subsection, we construct a series of experiments on the
effectiveness of the proposed model on the conversation task.
Automatic Evaluation. We present the results of the automatic evaluation for different methods in Table 3. First, ReDial
performs better than Transformer in Distinct-2/3/4, since it utilizes
a pre-training RNN model to encode history utterances. While,
Transformer performs better with the metric of Item Ratio. A possible reason is that Transformer architecture adopts the self-attention
mechanism for capturing temporal pairwise interaction, which is
more suitable to model the relations between words and items than
RNN and CNN. Second, among the three baselines, KBRD generates
the most diverse responses and achieves the highest item ratio, i.e.,
containing more mentions of items in the generated text. This model
Table 4: Human evaluation results on the conversation task.
Numbers marked with * indicate that the improvement is
statistically significant compared with the best baseline (ttest with p-value < 0.05).
Informativeness
Transformer
distinct-2
distinct-3
distinct-4
item ratio
KGSF w/o copy
KGSF w/o MIM
KGSF w/o KG-D
Figure 3: Ablation study on conversation task.
utilizes KG information to promote the predictive probability of
entities and items. Compared with these baselines, our KGSF model
is consistently better in all evaluation metrics. KGSF has utilized
the KG information in two major steps, namely the knowledgeenhanced Transformer decoder and the copy mechanism, which
enhances the informativeness of the generated text.
Human Evaluation. Table 4 presents the result of human
evaluation for the conversation task. First, among the three baselines, ReDial performs best in terms of the metric of Fluency, since
it utilizes a pre-training encoder on multiple language tasks .
However, we find that it tends to generate short and repetitive
responses. This is the so-called “safe response" issue in the dialog
generation task. Without additional supervision signal, it is likely
to overfit to the frequent utterances in the training set. Second,
KBRD performs best in terms of Informativeness score among the
three baselines. It utilizes KG data to promote the probability of
low-frequency words. Finally, our proposed model KGSF is consistently better than all the baselines with a large margin. We carefully
design a KG-enhanced Transformer decoder. Our model is able to
utilize contextual information effectively, and generate fluent and
informative responses.
Ablation Study. We also conduct the ablation study based on
three variants of our complete model, include: (1) KGSF w/o KG-D
by removing the KG-based attention layers from the Transformer
decoder, (2) KGSF w/o copy by removing the copy mechanism, and
(3) KGSF w/o MIM by removing the MIM loss. As shown in Figure 3,
first, all the techniques are useful to improve the final performance.
Besides, the KG-based attention layer seems to be more important
in our task, yielding a significant decrease when removed. KG-based
attention layers can effectively inject the fused KG information into
S1: How can I help you today?
Recommender System
S2: I would like to watch a
fantasy movie.
help recommend today fantasy movie
S3: I recommend
Pan’s Labyrinth or Stardust.
Have you seen those?
S4: I have seen these, they are very good.
Do you give another recommendation?
Recommender System
A Wrinkle in
S5: I'm looking forward to seeing
A Wrinkle in Time, but I 'm not
sure if you haven't seen it.
Conversation System
help recommend today fantasy movie perfect have seen good another recommendation
S6: Great! We share the same taste.
Conversation System
Figure 4: A sampled conversation with six-turn utterances
between our CRS agent (recommender) and a real user
(seeker). We use color bars to indicate attention weights of
words in the recommendation component. The first-round
recommendation is unsuccessful, while the second-round
recommendation is successful.
the decoder by multi-head attention mechanism. For the MIM loss,
besides its contribution to the recommendation task (See Table 2),
it also improves the quality of the generated responses, which
indicates its usefulness for KG-based semantic fusion.
Qualitative Analysis
In this part, we present a qualitative example to illustrate how our
model works in practice.
In Fig. 4, a user requests the recommendations on fantasy movies,
and our system accurately identifies the key word “fantasy" by
assigning a larger attention weight. The attention weights are computed by the self-attentive mechanism in Eq. 6 based on the KGenhanced word embeddings. With the focused preference of fantasy, our recommender component returns the candidate “Pan’s
Labyrinth”. While, interestingly, our dialog component not only
includes the mentions of the recommended movie, but also generates another related movie (“Stardust”) in the utterance. Receiving
the response, the user rejects the recommendation since she/he has
watched both movies before. Then, our recommender component
updates the representation of user preference, and returns another
recommendation. Although the words of “have" and “seen" received
a small attention weight by the recommender component, our dialog component also boosts their weights since they are helpful to
generate a more informative reply.
CONCLUSION AND FUTURE WORK
In this paper, we proposed a novel KG-based semantic fusion approach for CRS. By utilizing two external KGs, we enhanced the
semantic representations of words and items, and used Mutual Information Maximization to align the semantic spaces for the two
different components. Based on the aligned semantic representations, we developed a KG-enhanced recommendation component
for making accurate recommendations, and a KG-enhanced dialog component that can generate informative keywords or entities
in the utterance text. By constructing extensive experiments, our
approach yielded better performance than several competitive baselines.
As future work, we will consider using more kinds of external
information to improve the performance of CRS, e.g., user demographics . Besides, we will investigate how to make the utterance more persuasive and explainable for the recommendation
results. Finally, another interesting topic is how to incorporate historical user-item interaction data and start the conversation with a
pre-learned user profile.
ACKNOWLEDGEMENT
This work was partially supported by the National Natural Science Foundation of China under Grant No. 61872369 and 61832017,
Beijing Academy of Artificial Intelligence (BAAI) under Grant No.
BAAI2020ZJ0301, and Beijing Outstanding Young Scientist Program under Grant No. BJJWZYJH012019100020098, the Fundamental Research Funds for the Central Universities, the Research Funds
of Renmin University of China under Grant No.18XNLG22 and
19XNQ047. Xin Zhao is the corresponding author.