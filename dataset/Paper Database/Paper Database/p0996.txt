Behavior Research Methods, Instruments, & Computers
2001, 33 (2), 167-173
Response times in human behavioral experiments are
usually reported in milliseconds,and it is often considered
both necessary and sufficient for stimulus presentation
and response collectionto occur with reliablemillisecond
timing. Achieving and guaranteeing such precision on a
computer can be nontrivial, and this is particularly problematic with multitaskingoperating systems, such as Windows, UNIX, or Linux . One concern is the potentially
indeterminate delays resulting from an operating system
that needs to schedule multiple processes and that can
preempt one process to allow anotherprocess to run. Such
scheduling can impact timing of the critical data collection process. A second concern involves swapping and
memory residency: If a program is partially resident on
disk, there may be a delay while it is read into memory,
and this delay may impact the timing of data collection.
A third concern is that program access to hardware I/O
devices is usually mediated by the operating system; this
decreases the programmer’s control over input and output timing. In this paper, I demonstrate that Linux , a modern UNIX-like operating system, is
fully capable of timing resolutionat the millisecond level
or better, and I describe the facilities used for such programming. I then describe an implemented data collection software system for tapping and music performance
experiments and show that this
moderately complex program processes input and output
with reliable millisecond precision.
This paper is not the first publisheddescription of software for psychology experiments on UNIX-like operating systems. For instance, Perlman described experimentalcontrol software for an early version of UNIX,
but it relied on a timer with only 17-msec resolution.1
Cohen and Massaro described a real-time speech
system for a Silicon Graphics computer, but a high-end
workstation was required. More important, neither Perlman nor Cohen and Massaro provided details on tests of
actual system performance, leaving the timing accuracy
of the systems open to question.
The present paper explicitly addresses the timing performance of Linux, a readily available operating system
that runs on standard PC hardware. Linux is a multiuser,
multitasking operating system kernel that has similar
functionality to the UNIX operating system developed at
Bell Laboratories in the 1970s . Linux is quite robust and runs efficiently on PCs
based on the Intel Pentium chip, as well as on many other
architectures,includingApple Macintoshand DEC Alpha.
It is availableat little or no cost in source-code form. This
paper specificallyaddresses Linux on Pentium-basedcomputers. Although much of the discussion should apply to
Linux on other architectures, as well as to contemporary
versions of UNIX, timing performance may need to be
explicitly verified for different hardware and operating
system combinations.2
REAL-TIME PROGRAMMING IN LINUX
Three capabilitiesare important for real-time programming: (1) the ability to determine the current time with
high precision (at least to the millisecond), (2) the ability
to keep a process from being preempted by another pro-
Copyright 2001 Psychonomic Society, Inc.
The program described here, FTAP, was written for my dissertation
research at Brown University and was originally implemented on a Silicon Graphics computer running the IRIX operating
system. I thank Jim Anderson, David Ascher, Peter Eimas, Mike Tarr,
and Bill Warren for their assistance and support during this period. The
port to Linux and the tests reported here were completed during a postdoctoral fellowship at Ohio State University; I thank Caroline Palmer
and Pete Pfordresher for their assistance and advice, as well as for comments on an earlier version of this paper. I also thank Paul Iddings and
Doug Michels for my early UNIX education, and I extend special thanks
to Shane Ruland for his invaluable and good-natured software and
hardware assistance. Correspondence concerning this article should be
addressed to S. A. Finney, Department of Psychology, Ohio State University, 142 Townshend Hall, 1885 Neil Ave., Columbus, OH 43210
(e-mail: ; FTAP Web site: 
som.ohio-state.edu/ftap).
Real-time data collection in Linux: A case study
STEVEN A. FINNEY
Ohio State University, Columbus, Ohio
Multiuser UNIX-like operating systems such as Linux are often considered unsuitable for real-time
data collection because of the potential for indeterminate timing latencies resulting from preemptive
scheduling. In this paper, Linux is shown to be fully adequate for precisely controlled programming
with millisecond resolution or better. The Linux system calls that subserve such timing control are described and tested and then utilized in a MIDI-based program for tapping and music performance experiments. The timing of this program, including data input and output, is shown to be accurate at the
millisecond level. This demonstrates that Linux, with proper programming, is suitable for real-timeexperiment software. In addition, the detailed description and test of both the operating system facilities
and the application program itself may serve as a model for publicly documenting programming methods and software performance on other operating systems.
cess or being swapped out, and (3) the ability to suspend
process execution for a short (and deterministic) period
of time. Linux providesa numberof system calls and interfaces for these purposes; these will be briefly described
here. More information about each call can be found in
the Linux documentation.
The use of some of these facilities is restricted to a
particular privileged user (the superuser, also known as
“root”). Linux provides a mechanism (the set-user-id, or
“setuid” capability) that allows normal users to execute
certain trusted programs that make use of such privileges.
The system administrator decides whether to allow a
program to be configured as setuid “root.”
Scheduling and Current Time
Access to operating system services in Linux occurs
when a program makes a system call. Three system calls
provide for giving a process high schedulingpriority and
for retrieving the current time.
The gettimeofday call returns the current time, using
a data structure that allows for microsecond precision.
However, this does not necessarily mean that the internal
clock on which the reported time is based is actually accurate to the microsecond.For instance, some early UNIX
systems updated gettimeofday only once every 10 msec.
The actual resolution of gettimeofday thus needs to be
determined.
The sched_setscheduler system call puts a process in
a special class (SCHED_FIFO) of high-priority processes;
such a process will never be preempted by a process in the
normal priority class. Similarly, as soon as a SCHED_FIFO
process is ready to run, it will immediately preempt any
running normal-priority process. If a data collectionprogram is the only active SCHED_FIFO process (which will
usually be the case; system processes run with normal
priority), it will never be preempted by another process.
Such a high-priority process will not prevent the kernel
from servicing hardware device interrupts (which are designed to be processed very quickly);a high-priority process may also voluntarilysuspend processing (see below).
Sched_setscheduler requires root privileges. (Linux also
provides the setpriority system call, which gives a process high priority within the normal scheduling class. As
will be shown below, the setpriority call is not adequate
for real-time programming.)
The mlockall system call locks a process in memory,
preventing it from being swapped out. This is important
because even a high-priority process might be swappedout if it voluntarily relinquished control of the CPU, and
time would then be required to read it back in from disk.
The mlockall system call requires root privileges.
There are thus two important features to be tested.
First, what is the actual timing resolution of gettimeofday? Second, how well does sched_setscheduler work in
giving a process reliable real-time scheduling without
preemption?These questions were addressed by a simple
benchmark program that called gettimeofday 1,000,000
times and recorded the time returned by each call. Of
particularinterest is the elapsed time between successive
calls. A small mean time difference would indicate highresolution updating of the gettimeofday clock. A large
maximum time difference would demonstrate a problem
with worst-case scheduling performance. A low standard
deviation would indicate that the mean time difference is
an accurate characterization of average performance.
Two variables were manipulated in this test. The first
variable was priority condition, with three values: (1) a
process running with normal user privileges, (2) a process with root privileges running with high priority set
by setpriority (using the maximum value of 220) and
locked in core with mlockall, or (3) a process with root
privileges running as a high priority SCHED_FIFO process
(using sched_setscheduler) and locked in core. The second variable was system load—that is, the amount of activity on the system. Running on a loaded system allows
verifying that an intended real-time process actually gets
highest scheduling priority; a real-time process should
not be affected by such a load. Althoughexperimentaldata
collectionshould be done on a relatively quiescentsystem,
it is still important to understand how a data collection
process might respond to unanticipated system activity
(e.g., backgroundsystem processes). There were two different load conditions: (1) a relatively unloaded system
(a single logged-onuser running the test program) or (2) a
system with heavy process contention, with a load consisting of three simultaneous normal priority programs
doing continuous arithmetic. Each of the three priority
conditionswas tested under bothload conditions.The tests
were run on a Gateway Computer with a 350-MHz Pentium II processor and 128 MB of RAM, running a Linux
2.2.12 kernel (RedHat distribution 6.1). There was little
or no network activity, X Windows was not active, and
the machine had been recently rebooted; these factors
can all contributeto system load and affect worst-case performance times in low-priority conditions.
The data from 10 runs of the test program (a total of
10,000,000 calls to gettimeofday) are shown in Table 1.
The mean time difference when running with normaluser priority without any process load was acceptable
(1.29 μsec), as was the worst case time (246 μsec). However, performance degraded dramatically when there was
a process load, with a worst-case time of 840 msec (unacceptable by any reasonable standards). When running
with high priority set by the the setpriority system call,
the unloaded configuration gave acceptable mean and
maximum time differences of 1.23 and 322 μsec; the
Times Between Calls to gettimeofday
Under Different Priority and Load Conditions
Difference
Difference
Configuration
User, no load
User, load
Setpriority, no load
Setpriority, load
SCHED_FIFO, no load
SCHED_FIFO, load
REAL-TIME DATA COLLECTION IN LINUX
timing had less variance than with normal user priority.
However, performance again degraded dramatically under process load, with an unacceptable worst-case time
of 630 msec. The privileged setpriority call, although
giving improved performance relative to a normal user
process, is not adequate.
In contrast,a real-time SCHED_FIFO process had a worstcase time of less than 75 μsec, even under heavy process
load. When the sched_setscheduler call is used to give a
process high priority, Linux provides timing resolution
that is more than sufficient for millisecond resolution
programming.
Process Suspension
Another useful facility in real-time programming is the
ability to suspend processing for a short time (a millisecond or less); such suspension will ideally allow other
processes or process threads to execute. Linux provides
at least three mechanisms for suspendingprocessing, but
two of them have significant drawbacks when fine timing resolution is required.
The first mechanism is the setitimer system call, which
generates signals at fixed time intervals specified in microseconds. A process can set a timer and then suspend
itself; the process will be reactivated when the signal arrives. However, with the default Linux configuration,the
minimum time interval at which such interrupts actually
occur is an unacceptable 10 msec (based on the kernel
HZ variable), even if a user with root privileges requests
a smaller time value.
The second mechanism is the nanosleep system call
(or the related usleep library function), which suspends
the calling process for a time increment specified in
nanoseconds or microseconds. When called from a process in the normal priority class (even one with root privileges), the smallest resolution of these calls is on the
order of 10 or 20 msec, even when a smaller interval is
specified. When called from a high-priority SCHED_FIFO
process, these routinesallow pausing accurately for times
from 2 msec down as low as 5 μsec, but such fine resolution is implemented as a busy wait in the kernel that
does not allow other processes to run. In addition, if a
time greater than 2 msec is requested by such a real-time
process, the minimum resolution returns to 20 msec.
The third (and best) mechanism for implementingprocess suspensionuses the real-time clock device“/dev/rtc.”
The “/dev/rtc” device can be programmed so that a read
system call on the device will return after a specified interval. When called from a process with root privileges,
the specified time can be as little as 0.12 msec (the period of an 8192-Hz clock), and this timer is quite accurate. When a process is blocked on a read on “/dev/rtc,”
other processes or threads will be scheduled for execution. Although “/dev/rtc” is included with standard
Linux (at least on Pentium-based computers), it is not
widely documented; a useful description and code fragment can be found in the “rtc.txt” file in the kernel source
documentation.
Discussion
Three Linux system calls (sched_setscheduler, mlockall, and gettimeofday) provide for accurate process control at the millisecond level or better; in addition, the
“/dev/rtc” real-time clock allows process suspension for
submillisecond time increments. A number of other system calls have been shown to be inadequatefor real-time
purposes. Use of the sched_setscheduler and mlockall
system calls (as well as high-resolution use of “/dev/rtc”)
requires root privileges, but Linux provides the ability
for normal users to run programs using these facilities.
Two additionalpointsare worth making.First, the overhead for Linux system calls is extremely low; the time to
process a gettimeofday system call is on the order of
1 μsec . Second, programming high-priority
processes with sched_setscheduler must be done with
some care. Such processes genuinelyget high scheduling
priority; if not programmed properly,they can completely
monopolize the system, requiring a system reset to regain access to the computer.
THE FTAP PROGRAM
Although the facilities provided by Linux appear suitable for real-time programming at the millisecond level,
the tests described above did not involve complex data
processing, nor was any data actually inputor output.The
adequacy of Linux for real-world data collection has not
yet been established.This section will describe an implemented Linux-based data collection program for an interestingclass of human behavioralexperiments;the realtime performance of the program will be demonstrated
in a rigorous way.
FTAP is a program for tappingand music
performance experiments; it collects finger movement
data (keypresses) from an electronic musical keyboard
and manipulates the auditory feedback to keystrokes in
interesting ways. FTAP can run a wide range of experiments, including synchronization/continuation tasks
 , synchronization tasks
with delayed auditory feedback , continuation tasks with isolated feedback perturbations , and complex alterations of feedback in music performance . It is available
at no cost in source code form from 
ohio-state.edu/ftap.
FTAP uses a MIDI (Music Instrument Digital Interface)
keyboard for input and a MIDI tone generator for auditory output. For present purposes, MIDI can be characterized as a serial data format with 3-byte messages that
specify either Note On (e.g., a keypress on a musical keyboard, which would trigger a tone onset) or Note Off (a
key release, or tone offset). Each message specifies the
key pressed (i.e., the note or pitch value) and the keystroke
velocity (loudness). The MIDI protocol itself does not
provide time stamping of input messages nor scheduling
of output, so one important requirement for a program is
accurate recording of the times of MIDI input and accurate timing of MIDI output.
The basic architecture of FTAP is shown in Figure 1;
processing involves a continuous loop in which the program checks whether there is any pending input (if so, it
is timestamped and processed) and then checks whether
there are any messages scheduled for output. FTAP runs
with root privileges and uses the sched_setscheduler and
mlockall system calls. The disk is not accessed during a
trial; data is stored in RAM and written to the disk at the
end of the trial. In accordance with standard procedure for
UNIX-like operating systems , data collectionshouldbe done on a dedicated
machine with no other users logged on and with unnecessary services (e.g., network activity)kept to a minimum.
The question of whether FTAP provides the desired
millisecond resolution can be addressed at two levels.
The first question is whether FTAP achieves reliable millisecond scheduling in its central processing loop. The
second question is whether the input and output of MIDI
data occur with millisecond precision—that is, does the
underlyingLinux MIDI I/O system provide adequate performance. I will describe tests addressing both of these
issues; importantly, FTAP providesthe capabilityfor any
user to replicate these tests on their own system.
Scheduling Tests
Adequate performance of FTAP requires that the input
and output routines each be called at least once a millisecond; this will allow FTAP to process I/O with millisecond resolution. Because FTAP runs as a continuous
loop of input/output, it is sufficient to test the timing of
either the input or the output routine; the output routine
was arbitrarily chosen for this purpose. During each execution of FTAP, the time between successive calls to the
output routine is measured, and summary statistics
(mean and maximum time differences) are provided to
the experimenter. If the maximum (worst-case) times between scheduling calls are near 1 msec, adequate performance will be achieved.
As a concrete example of scheduling performance,
Finney and Warren reported a synchronization/
continuation tapping experiment run with FTAP, using a
200-MHz Pentium computer and a Linux 2.2 kernel.
Twenty subjects performed 66 trials each, giving a total
of 1,320 trials. The mean trial length was 28 sec, and data
for 60–65 keystrokes were collectedduring each trial. In
total, there was more than 10 h of actual data collection,
with more than 80,000 keystrokes.
For each of the 1,320trials, the mean time between calls
to the output routine was 0.49 msec, well under a millisecond.3 On 1,270 out of the 1,320 trials, the maximum
time between calls to the output scheduler was 1 msec;
on 35 trials there was a single instance of a 2-msec difference, and on 15 trials there was a single instance of a
3-msec difference. These times seem quite acceptable
for 10 h of data collection, particularly because a slight
discrepancy between calls to the output scheduling routine does not mean that any data were actually compromised by even these small amounts (there was no input or
output data to be processed during the majority of scheduling calls). This test demonstrates that FTAP’s internal
scheduling is adequate at the millisecond level.
Data collectionwith FTAP involvesa complex system
beyond the FTAP program itself, including access to a
hardware device for MIDI I/O (a sound card or serial
port; see Figure 2). The diagnostics described in the previous section can detect internal scheduling inconsistencies, but they cannot detect problems at the driver or hardware level—for example,discrepanciesbetween intended
output time and actual output time. Access to the MIDI
interface is mediated by device-specific driver code in the
operating system; Linux does not allow direct access to
a hardware device from an application program. The
programmer is dependenton the driver for adequate timing, which is potentially problematic for real-time programming.4
It is therefore important to verify that the drivers and
hardware can process input and output with millisecond
Figure 1. Basic architecture of the FTAP program; conceptually, inputand output occur simultaneously.The
internal loop indicates control flow, not data flow.
REAL-TIME DATA COLLECTION IN LINUX
resolution, since otherwise the performance of FTAP as
a whole will not have accurate timing. In the general case,
determining the temporal resolution of input and output
on a computer can be very difficult, since it requires the
ability to precisely control the timing of input to the system, as well as the ability to measure the timing of output. However, two aspects of FTAP simplify the verification of I/O performance. First, FTAP uses MIDI for
both input and output; that is, the input message format
(MIDI keystroke data) is identical to the output message
format. Second, FTAP’s functionality includes providing
auditory (MIDI) feedback to input keystrokes. These two
features facilitate a rigorous test of FTAP using a loop
configuration in which the MIDI outputis connected(via
a MIDI cable) back to the MIDI input; an output message will then be immediately received as input (and interpreted as an input keystroke). If FTAP is configured
to give immediate feedback to MIDI input messages, a
single“priming”message can be repeatedlycycledthrough
the system, and the speed with which such a message is
processed gives a measure of FTAP’s overallperformance.
The processing in such a loop test includes a heavy load
on the kernel I/O system of virtually simultaneous MIDI
input and output at a very rapid rate, as well as FTAP program overhead of reading, assembling, and timestamping MIDI input messages, storing them in memory for
later data file output, placing the messages in the output
queue, outputting the messages at the proper time, and
saving the output messages in memory for writing to a
data file. This benchmark provides a much more demanding processing and input/output load than will be
encountered in a human behavioral experiment.
What level of performance should be considered adequate? The transmission rate specified by the MIDI standard is 31.25 kilobaud, equal to 320 μsec per byte, or
0.96 msec for a 3-byte MIDI keypress or key release
message (giving 1,040 messages/sec). Achieving this
hardware-specified rate with such a loop test is the best
performance possible and would achieve the overall goal
of millisecond accuracy.
With the appropriate cable, the test above can be run
in FTAP, using a simple 10-line experiment description
file; such a file is includedin the FTAP distribution. The
performance of this test can be verified by inspection of
the FTAP outputfile, which containsa listing of all MIDI
input and output events with millisecond timestamps.
The test of system performance is how accurately FTAP
can process input messages relative to the rate specified
by the MIDI hardware specification (i.e., one message
every 0.96 msec). This test was run on a 350-MHz Pentium with a Creative Soundblaster-16 Sound/MIDI card,
using a Linux 2.2 kernel but replacing the standard
Linux MIDI driver with a low-cost commercial driver
from 4Front Technologies (http:www.4front-tech.com;
see the discussion below). The test started with FTAP
generatingoneMIDI Note On and one MIDI Note Off output event (separated by 1 msec); this correspondsto a keypress and key release. These events were cycled through
the system as described above, and the test terminated
after 10,000 MIDI input events were received.
For each of 100 runs of this test, the resulting mean
time between input MIDI events was 0.96 msec, exactly
the hardware-specified MIDI transmission rate. The
maximum time difference between inputevents in any run
was 2 msec; this occurred rarely. MaximalMIDI throughput was achieved in this test, and the millisecond level
precision of the entire FTAP system is verified.
I/O Performance Issues:
MIDI Drivers and Hardware
There were some problems in achieving maximal
MIDI throughputwith the above loop benchmark; not all
MIDI card/driver combinations were able to maintain
adequate performance. For example, the combination of
the Linux drivers and a Roland MPU-401 card failed
with overrun errors when the card was used in the UART
mode that allows accessing the raw MIDI data stream.
In addition, the combination of the Soundblaster-16
sound card and the standard Linux MIDI driver (the OSS/
Free driver included with the RedHat 6.1 distribution)
Figure 2. FTAP’s interaction with the Linux I/O system. The accuracy of data collection depends on performance of the entire configuration, not just the FTAP program itself.
processed only one MIDI message every 10 msec with
the loop test. This behavior turned out to be a result of
pollingin the MIDI driver output code (“midibuf.c”); the
driver places MIDI messages in an output queue, and
onlyonce every 10 msec (based on the kernel HZ variable)
is the accumulated output sent to the hardware device.
Using the 4Front MIDI driver mentioned above is one
solution to this problem, since this driver achieves maximal MIDI throughput on the loop benchmark.5
Thus, for real-time performance, the particular MIDI
hardware interface and driver need to be tested; inclusion
of the loop benchmark test with the FTAP distribution
provides users with the capability of doing this.
CONCLUSION
Standard Linux provides facilities for real-time programming that are fully adequate for timing precision at
the millisecond level or better. This has been demonstrated by tests of the Linux system calls themselves and
by tests of an implemented Linux-based experiment program; see also MacInnes and Taylor . A novel feature of the FTAP program is the inclusionof performance
tests that any user can run; this allows experimenters to
validate program performance on their own system and
AlthoughLinuxprovidessupportfor real-time programming, the ability to achieve millisecondresolutionis also
greatly facilitated by developments in computer hardware. Performance issues of major concern in the 1980s
and early 1990s have largely been mitigated by increases
in CPU speed (as well as by the ready availabilityof large
amounts of RAM). For example, with a 500-MHz CPU
chip, there are 500,000 hardware clock cycles per millisecond. Although a clock cycle does not correspond to a
singlemachine-levelinstruction(much less a line of code
in a high-levellanguage), the large amount of processing
that can be completed in a millisecond means that CPU
usage is a relatively minor concern in real-time programming for psychology experiments.
The view that multitasking operating systems are inadequate for real-time programming is thus incorrect, at
least in the case of Linux.I am not claiminghere that Linux
is a better operating system for real-time experiments
than such alternatives as DOS or MacOS, but this paper
has shown that Linux is a suitable platform for such work
(and one that can run on a wide range of hardware). More
generally, the explicitdescriptionof the performance tests
of both the operating system itself and the application
program (and the capabilityfor any user to replicate those
tests) may serve as a useful standard for documentingthe
performance of anypurportedreal-timesystems inpsychological research.