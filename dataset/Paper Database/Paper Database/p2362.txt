Uninformed Students: Student–Teacher Anomaly Detection
with Discriminative Latent Embeddings
Paul Bergmann
Michael Fauser
David Sattlegger
Carsten Steger
MVTec Software GmbH
www.mvtec.com
{paul.bergmann, fauser, sattlegger, steger}@mvtec.com
Abstract—We introduce a powerful student–teacher framework for the challenging problem of unsupervised anomaly
detection and pixel-precise anomaly segmentation in highresolution images. Student networks are trained to regress
the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images.
This circumvents the need for prior data annotation. Anomalies are detected when the outputs of the student networks
differ from that of the teacher network. This happens when
they fail to generalize outside the manifold of anomalyfree training data. The intrinsic uncertainty in the student
networks is used as an additional scoring function that indicates anomalies. We compare our method to a large number
of existing deep learning based methods for unsupervised
anomaly detection. Our experiments demonstrate improvements over state-of-the-art methods on a number of realworld datasets, including the recently introduced MVTec
Anomaly Detection dataset that was speciﬁcally designed to
benchmark anomaly segmentation algorithms.
1. Introduction
Unsupervised pixel-precise segmentation of regions
that appear anomalous or novel to a machine learning
model is an important and challenging task in many
domains of computer vision. In automated industrial inspection scenarios, it is often desirable to train models
solely on a single class of anomaly-free images to segment
defective regions during inference. In an active learning
setting, regions that are detected as previously unknown
by the current model can be included in the training set
to improve the model’s performance.
Recently, efforts have been made to improve anomaly
detection for one-class or multi-class classiﬁcation . However, these algorithms assume
that anomalies manifest themselves in the form of images
of an entirely different class and a simple binary imagelevel decision whether an image is anomalous or not
must be made. Little work has been directed towards
the development of methods that can segment anomalous
regions that only differ in a very subtle way from the
training data. Bergmann et al. provide benchmarks
for several state-of-the-art algorithms and identify a large
room for improvement.
Existing work predominantly focuses on generative
algorithms such as Generative Adversarial Networks
Figure 1: Qualitative results of our anomaly detection method
on the MVTec Anomaly Detection dataset. Top row: Input
images containing defects. Center row: Ground truth regions
of defects in red. Bottom row: Anomaly scores for each image
pixel predicted by our algorithm.
(GANs) or Variational Autoencoders (VAEs)
 . These detect anomalies using per-pixel reconstruction errors or by evaluating the density obtained from the
model’s probability distribution. This has been shown to
be problematic due to inaccurate reconstructions or poorly
calibrated likelihoods .
The performance of many supervised computer vision
algorithms is improved by transfer learning,
i.e. by using discriminative embeddings from pretrained
networks. For unsupervised anomaly detection, such approaches have not been thoroughly explored so far. Recent work suggests that these feature spaces generalize
well for anomaly detection and even simple baselines
outperform generative deep learning approaches .
However, the performance of existing methods on large
high-resolution image datasets is hampered by the use of
shallow machine learning pipelines that require a dimensionality reduction of the used feature space. Moreover,
they rely on heavy training data subsampling since their
capacity does not sufﬁce to model highly complex data
distributions with a large number of training samples.
We propose to circumvent these limitations of shallow
models by implicitly modeling the distribution of training
features with a student–teacher approach. This leverages
the high capacity of deep neural networks and frames
anomaly detection as a feature regression problem. Given
a descriptive feature extractor pretrained on a large dataset
of patches from natural images (the teacher), we train an
ensemble of student networks on anomaly-free training
 
Figure 2: Schematic overview of our approach. Input images are fed through a teacher network that densely extracts features for
local image regions. An ensemble of M student networks is trained to regress the output of the teacher on anomaly-free data. During
inference, the students will yield increased regression errors e and predictive uncertainties v in pixels for which the receptive ﬁeld
covers anomalous regions. Anomaly maps generated with different receptive ﬁelds can be combined for anomaly segmentation at
multiple scales.
data to mimic the teacher’s output. During inference,
the students’ predictive uncertainty together with their
regression error with respect to the teacher are combined
to yield dense anomaly scores for each input pixel. Our
intuition is that students will generalize poorly outside
the manifold of anomaly-free training data and start to
make wrong predictions. Figure 1 shows qualitative results
of our method when applied to images selected from
the MVTec Anomaly Detection dataset . A schematic
overview of the entire anomaly detection process is given
in Figure 2. Our main contributions are:
We propose a novel framework for unsupervised
anomaly detection based on student–teacher learning. Local descriptors from a pretrained teacher
network serve as surrogate labels for an ensemble
of students. Our models can be trained end-to-end
on large unlabeled image datasets and make use
of all available training data.
We introduce scoring functions based on the students’ predictive variance and regression error to
obtain dense anomaly maps for the segmentation
of anomalous regions in natural images. We describe how to extend our approach to segment
anomalies at multiple scales by adapting the students’ and teacher’s receptive ﬁelds.
We demonstrate state-of-the-art performance on
three real-world computer vision datasets. We
compare our method to a number of shallow
machine learning classiﬁers and deep generative
models that are ﬁtted directly to the teacher’s
feature distribution. We also compare it to recently
introduced deep learning based methods for unsupervised anomaly segmentation.
2. Related Work
There exists an abundance of literature on anomaly
detection . Deep learning based methods for the
segmentation of anomalies strongly focus on generative
models such as autoencoders or GANs . These
attempt to learn representations from scratch, leveraging
no prior knowledge about the nature of natural images,
and segment anomalies by comparing the input image to
a reconstruction in pixel space. This can result in poor
anomaly detection performance due to simple per-pixel
comparisons or imperfect reconstructions .
2.1. Anomaly Detection with Pretrained Networks
Promising results have been achieved by transferring
discriminative embedding vectors of pretrained networks
to the task of anomaly detection by ﬁtting shallow machine learning models to the features of anomaly-free
training data. Andrews et al. use activations from
different layers of a pretrained VGG network and model
the anomaly-free training distribution with a ν-SVM.
However, they only apply their method to image classi-
ﬁcation and do not consider the segmentation of anomalous regions. Similar experiments have been performed
by Burlina et al. . They report superior performance
of discriminative embeddings compared to feature spaces
obtained from generative models.
Nazare et al. investigate the performance of different off-the-shelf feature extractors pretrained on an
image classiﬁcation task for the segmentation of anomalies in surveillance videos. Their approach trains a 1-
Nearest-Neighbor (1-NN) classiﬁer on embedding vectors
extracted from a large number of anomaly-free training
patches. Prior to the training of the shallow classiﬁer,
the dimensionality of the network’s activations is reduced
using Principal Component Analysis (PCA). To obtain
a spatial anomaly map during inference, the classiﬁer
must be evaluated for a large number of overlapping
patches, which quickly becomes a performance bottleneck
and results in rather coarse anomaly maps. Similarly,
Napoletano et al. extract activations from a pretrained
ResNet-18 for a large number of cropped training patches
and model their distribution using K-Means clustering
after prior dimensionality reduction with PCA. They also
perform strided evaluation of test images during inference.
Both approaches sample training patches from the input
images and therefore do not make use of all possible
training features. This is necessary since, in their frame-
Figure 3: Pretraining of the teacher network ˆT to output descriptive embedding vectors for patch-sized inputs. The knowledge of
a powerful but computationally inefﬁcient network P is distilled
into ˆT by decoding the latent vectors to match the descriptors
of P. We also experiment with embeddings obtained using selfsupervised metric learning techniques based on triplet learning.
Information within each feature dimension is maximized by
decorrelating the feature dimensions within a minibatch.
work, feature extraction is computationally expensive due
to the use of very deep networks that output only a
single descriptor per patch. Furthermore, since shallow
models are employed for learning the feature distribution
of anomaly-free patches, the available training information
must be strongly reduced.
To circumvent the need for cropping patches and to
speed up feature extraction, Sabokrou et al. extract descriptors from early feature maps of a pretrained
AlexNet in a fully convolutional fashion and ﬁt a unimodal
Gaussian distribution to all available training vectors of
anomaly-free images. Even though feature extraction is
achieved more efﬁciently in their framework, pooling
layers lead to a downsampling of the input image. This
strongly decreases the resolution of the ﬁnal anomaly
map, especially when using descriptive features of deeper
network layers with larger receptive ﬁelds. In addition,
unimodal Gaussian distributions will fail to model the
training feature distribution as soon as the problem complexity rises.
2.2. Open-Set Recognition with Uncertainty Estimates
Our work draws some inspiration from the recent
success of open-set recognition in supervised settings
such as image classiﬁcation or semantic segmentation,
where uncertainty estimates of deep neural networks have
been exploited to detect out-of-distribution inputs using
MC Dropout or deep ensembles . Seeboeck et
al. demonstrate that uncertainties from segmentation
networks trained with MC Dropout can be used to detect
anomalies in retinal OCT images. Beluch et al. show
that the variance of network ensembles trained on an
image classiﬁcation task serves as an effective acquisition
function for active learning. Inputs that appear anomalous
to the current model are added to the training set to
quickly enhance its performance.
Such algorithms, however, demand prior labeling of
images by domain experts for a supervised task, which is
not always possible or desirable. In our work, we utilize
feature vectors of pretrained networks as surrogate labels
for the training of an ensemble of student networks. The
predictive variance together with the regression error of
the ensemble’s output mixture distribution is then used as
Figure 4: Embedding vectors visualized for ten samples of
the MNIST dataset. Larger circles around the students’ mean
predictions indicate increased predictive variance. Being only
trained on a single class of training images, the students manage
to accurately regress the features solely for this class (green).
They yield large regression errors and predictive uncertainties
for images of other classes (red). Anomaly scores for the entire
dataset are displayed in the bottom histogram.
a scoring function to segment anomalous regions in test
3. Student–Teacher Anomaly Detection
This section describes the core principles of our
{I1, I2, . . . , IN} of anomaly-free images, our goal is to
create an ensemble of student networks Si that can later
detect anomalies in test images J. This means that they
can assign a score to each pixel indicating how much
it deviates from the training data manifold. For this,
the student models are trained against regression targets
obtained from a descriptive teacher network T pretrained
on a large dataset of natural images. After the training,
anomaly scores can be derived for each image pixel from
the students’ regression error and predictive variance.
Given an input image I ∈Rw×h×C of width w, height
h, and number of channels C, each student Si in the
ensemble outputs a feature map Si(I) ∈Rw×h×d. It
contains descriptors y(r,c) ∈Rd of dimension d for each
input image pixel at row r and column c. By design, we
limit the students’ receptive ﬁeld, such that y(r,c) describes
a square local image region p(r,c) of I centered at (r, c)
of side length p. The teacher T has the same network
architecture as the student networks. However, it remains
constant and extracts descriptive embedding vectors for
each pixel of the input image I that serve as deterministic
regression targets during student training.
3.1. Learning Local Patch Descriptors
We begin by describing how to efﬁciently construct
a descriptive teacher network T using metric learning
and knowledge distillation techniques. In existing work
for anomaly detection with pretrained networks, feature
extractors only output single feature vectors for patchsized inputs or spatially heavily downsampled feature
maps . In contrast, our teacher network T efﬁciently outputs descriptors for every possible square of
side length p within the input image. T is obtained by
ﬁrst training a network ˆT to embed patch-sized images
p ∈Rp×p×C into a metric space of dimension d using
only convolution and max-pooling layers. Fast dense local
feature extraction for an entire input image can then
be achieved by a deterministic network transformation
of ˆT to T as described in . This yields signiﬁcant
speedups compared to previously introduced methods that
perform patch-based strided evaluations. To let ˆT output
semantically strong descriptors, we investigate both selfsupervised metric learning techniques as well as distilling
knowledge from a descriptive but computationally inef-
ﬁcient pretrained network. A large number of training
patches p can be obtained by random crops from any
image database. Here, we use ImageNet .
Knowledge Distillation. Patch descriptors obtained from
deep layers of CNNs trained on image classiﬁcation
tasks perform well for anomaly detection when modeling
their distribution with shallow machine learning models
 . However, the architectures of such CNNs are
usually highly complex and computationally inefﬁcient for
the extraction of local patch descriptors. Therefore, we
distill the knowledge of a powerful pretrained network
P into ˆT by matching the output of P with a decoded
version of the descriptor obtained from ˆT:
Lk( ˆT) = ||D( ˆT(p)) −P(p)||2.
D denotes a fully connected network that decodes the ddimensional output of ˆT to the output dimension of the
pretrained network’s descriptor.
Metric Learning. If for some reason pretrained networks
are unavailable, one can also learn local image descriptors
in a fully self-supervised way . Here, we investigate
the performance of discriminative embeddings obtained
using triplet learning. For every randomly cropped patch
p, a triplet of patches (p, p+, p−) is augmented. Positive
patches p+ are obtained by small random translations
around p, changes in image luminance, and the addition
of Gaussian noise. The negative patch p−is created by a
random crop from a randomly chosen different image. Intriplet hard negative mining with anchor swap is used
as a loss function for learning an embedding sensitive to
the ℓ2 metric
Lm( ˆT) = max{0, δ + δ+ −δ−},
where δ > 0 denotes the margin parameter and in-triplet
distances δ+ and δ−are deﬁned as:
δ+ = || ˆT(p) −ˆT(p+)||2
δ−= min{|| ˆT(p) −ˆT(p−)||2, || ˆT(p+) −ˆT(p−)||2}.
Descriptor Compactness. As proposed by Vassileios et
al. , we minimize the correlation between descriptors
within one minibatch of inputs p to increase the descriptors’ compactness and remove unnecessary redundancy:
where cij denotes the entries of the correlation matrix
computed over all descriptors ˆT(p) in the current minibatch.
The ﬁnal training loss for ˆT is then given as
L( ˆT) = λkLk( ˆT) + λmLm( ˆT) + λcLc( ˆT),
where λk, λm, λc ≥0 are weighting factors for the individual loss terms. Figure 3 summarizes the entire learning
process for the teacher’s discriminative embedding.
3.2. Ensemble of Student Networks for Deep
Anomaly Detection
Next, we describe how to train student networks Si to
predict the teacher’s output on anomaly-free training data.
We then derive anomaly scores from the students’ predictive uncertainty and regression error during inference.
First, the vector of component-wise means µ ∈Rd and
standard deviations σ ∈Rd over all training descriptors is
computed for data normalization. Descriptors are extracted
by applying T to each image in the dataset D. We then
train an ensemble of M ≥1 randomly initialized student
networks Si, i ∈{1, . . . , M} that possess the identical
network architecture as the teacher T. For an input image
I, each student outputs its predictive distribution over the
space of possible regression targets for each local image
region p(r,c) centered at row r and column c. Note that
the students’ architecture with limited receptive ﬁeld of
size p allows us to obtain dense predictions for each
image pixel with only a single forward pass, without
having to actually crop the patches p(r,c). The students’
output vectors are modeled as a Gaussian distribution
Pr(y|p(r,c)) = N(y|µSi
(r,c), s) with constant covariance
s ∈R, where µSi
(r,c) denotes the prediction made by Si for
the pixel at (r, c). Let yT
(r,c) denote the teacher’s respective
descriptor that is to be predicted by the students. The loglikelihood training criterion L(Si) for each student network then simpliﬁes to the squared ℓ2-distance in feature
(r,c) −(yT
(r,c) −µ)diag(σ)−1||2
where diag(σ)−1 denotes the inverse of the diagonal
matrix ﬁlled with the values in σ.
Scoring Functions for Anomaly Detection. Having
trained each student to convergence, a mixture of Gaussians can be obtained at each image pixel by equally
weighting the ensemble’s predictive distributions. From
it, measures of anomaly can be obtained in two ways:
First, we propose to compute the regression error of
the mixture’s mean µ(r,c) with respect to the teacher’s
surrogate label:
e(r,c) = ||µ(r,c) −(yT
(r,c) −µ)diag(σ)−1||2
(r,c) −(yT
(r,c) −µ)diag(σ)−1
The intuition behind this score is that the student networks
will fail to regress the teacher’s output within anomalous
CNN-Feature
Dictionary
Toothbrush
Transistor
Table 1: Results on the MVTec Anomaly Detection dataset. For each dataset category, the normalized area under the PRO-curve
up to an average false positive rate per-pixel of 30% is given. It measures the average overlap of each ground-truth region with the
predicted anomaly regions for multiple thresholds. The best-performing method for each dataset category is highlighted in boldface.
regions during inference since the corresponding descriptors have not been observed during training. Note that
e(r,c) is non-constant even for M = 1, where only a single
student is trained and anomaly scores can be efﬁciently
obtained with only a single forward pass through the
student and teacher network, respectively.
As a second measure of anomaly, we compute for each
pixel the predictive uncertainty of the Gaussian mixture as
deﬁned by Kendall et al. , assuming that the student
networks generalize similarly for anomaly-free regions
and differently in regions that contain novel information
unseen during training:
v(r,c) = 1
2 −||µ(r,c)||2
To combine the two scores, we compute the means
eµ, vµ and standard deviations eσ, vσ of all e(r,c) and
v(r,c), respectively, over a validation set of anomaly-free
images. Summation of the normalized scores then yields
the ﬁnal anomaly score:
˜e(r,c) + ˜v(r,c) = e(r,c) −eµ
+ v(r,c) −vµ
Figure 4 illustrates the basic principles of our anomaly
detection method on the MNIST dataset, where images
with label 0 were treated as the normal class and all other
classes were treated as anomalous. Since the images of
this dataset are very small, we extracted a single feature
vector for each image using ˆT and trained an ensemble
of M = 5 patch-sized students to regress the teacher’s
output. This results in a single anomaly score for each
input image. Feature descriptors were embedded into 2D
using multidimensional scaling to preserve their relative distances.
3.3. Multi-Scale Anomaly Segmentation
If an anomaly only covers a small part of the teacher’s
receptive ﬁeld of size p, the extracted feature vector
predominantly describes anomaly-free traits of the local
image region. Consequently, the descriptor can be predicted well by the students and anomaly detection performance will decrease. One could tackle this problem by
downsampling the input image. This would, however, lead
to an undesirable loss in resolution of the output anomaly
Our framework allows for explicit control over the size
of the students’ and teacher’s receptive ﬁeld p. Therefore,
we can detect anomalies at various scales by training
multiple student–teacher ensemble pairs with varying values of p. At each scale, an anomaly map with the same
size as the input image is computed. Given L student–
teacher ensemble pairs with different receptive ﬁelds, the
normalized anomaly scores ˜e(l)
(r,c) and ˜v(l)
(r,c) of each scale
l can be combined by simple averaging:
(r,c) + ˜v(l)
4. Experiments
To demonstrate the effectiveness of our approach,
an extensive evaluation on a number of datasets is performed. We measure the performance of our student–
teacher framework against existing pipelines that use shallow machine learning algorithms to model the feature
distribution of pretrained networks. To do so, we compare
to a K-Means classiﬁer, a One-Class SVM (OC-SVM),
and a 1-NN classiﬁer. They are ﬁtted to the distribution of
the teacher’s descriptors after prior dimensionality reduction using PCA. We also experiment with deterministic
and variational autoencoders as deep distribution models over the teacher’s discriminative embedding. The ℓ2reconstruction error and reconstruction probability 
are used as the anomaly score, respectively. We further
compare our method to recently introduced generative
and discriminative deep learning based anomaly detection
models and report improved performance over the state of
the art. We want to stress that the teacher has not observed
images of the evaluated datasets during pretraining to
avoid an unfair bias.
Figure 5: Anomaly detection at multiple scales: Architectures with receptive ﬁeld of size p = 17 manage to accurately segment
the small scratch on the capsule (top row). However, defects at a larger scale such as the missing imprint (bottom row) become
problematic. For increasingly larger receptive ﬁelds, the segmentation performance for the larger anomaly increases while it decreases
for the smaller one. Our multiscale architecture mitigates this problem by combining multiple receptive ﬁelds.
As a ﬁrst experiment, we perform an ablation study
to ﬁnd suitable hyperparameters. Our algorithm is applied to a one-class classiﬁcation setting on the MNIST
 and CIFAR-10 datasets. We then evaluate on
the much more challenging MVTec Anomaly Detection
(MVTec AD) dataset, which was speciﬁcally designed to
benchmark algorithms for the segmentation of anomalous
regions. It provides over 5000 high-resolution images
divided into ten object and ﬁve texture categories. To
highlight the beneﬁt of our multi-scale approach, an additional ablation study is performed on MVTec AD, which
investigates the impact of different receptive ﬁelds on the
anomaly detection performance.
For our experiments, we use identical network architectures for the student and teacher networks, with receptive ﬁeld sizes p ∈{17, 33, 65}. All architectures are simple CNNs with only convolutional and max-pooling layers, using leaky rectiﬁed linear units with slope 5×10−3 as
activation function. Table 4 shows the speciﬁc architecture
used for p = 65. For p = 17 and p = 33, similar
architectures are given in in Appendix A.
For the pretraining of the teacher networks ˆT, triplets
augmented from the ImageNet dataset are used. Images
are zoomed to equal width and height sampled from
{4p, 4p + 1, . . . , 16p} and a patch of side length p is
cropped at a random location. A positive patch p+ for
each triplet is then constructed by randomly translating
OCGAN 
Table 2: Results on MNIST and CIFAR-10. For each method,
the average area under the ROC curve is given, computed across
each dataset category. For our algorithm, we evaluate teacher
networks trained with different loss functions.  corresponds to
setting the respective loss weight to 1, otherwise it is set to 0.
the crop location within the interval {−p−1
4 , . . . , p−1
Gaussian noise with standard deviation 0.1 is added to
p+. All images within a triplet are randomly converted
to grayscale with a probability of 0.1. For knowledge
distillation, we extract 512-dimensional feature vectors
from the fully connected layer of a ResNet-18 that was
pretrained for classiﬁcation on the ImageNet dataset. For
network optimization, we use the Adam optimizer 
with an initial learning rate of 2 × 10−4, a weight decay
of 10−5, and a batch size of 64. Each teacher network
outputs descriptors of dimension d = 128 and is trained
for 5 × 104 iterations.
4.1. MNIST and CIFAR-10
Before considering the problem of anomaly segmentation, we evaluate our method on the MNIST and CIFAR-
10 datasets, adapted for one-class classiﬁcation. Five students are trained on only a single class of the dataset,
while during inference images of the other classes must
be detected as anomalous. Each image is zoomed to the
students’ and teacher’s input size p and a single feature
vector is extracted by passing it through the patch-sized
networks ˆT and ˆSi. We examine different teacher networks by varying the weights λk, λm, λc in the teacher’s
loss function L( ˆT). The patch size for the experiments
in this subsection is set to p = 33. As a measure of
anomaly detection performance, the area under the ROC
curve is evaluated. Shallow and deep distributions models
are trained on the teacher’s descriptors of all available
in-distribution samples. We additionally report numbers
for OCGAN , a recently proposed generative model
directly trained on the input images. Detailed information
on training parameters for all methods on this dataset is
found in Appendix B.
Table 2 shows our results. Our approach outperforms
the other methods for a variety of hyperparameter settings.
Distilling the knowledge of the pretrained ResNet-18 into
the teacher’s descriptor yields slightly better performance
than training the teacher in a fully self-supervised way
using triplet learning. Reducing descriptor redundancy by
minimizing the correlation matrix yields improved results.
On average, shallow models and autoencoders ﬁtted to
our teacher’s feature distribution outperform OCGAN but
do not reach the performance of our approach. Since
for 1-NN, every single training vector can be stored,
Multiscale
Toothbrush
Transistor
Table 3: Performance of our algorithm on the MVTec AD
dataset for different receptive ﬁeld sizes p. Combining anomaly
scores across multiple receptive ﬁelds shows increased performance for many of the dataset’s categories. We report the
normalized area under the PRO curve up to an average falsepositive rate of 30%.
it performs exceptionally well on these small datasets.
On average, however, our method still outperforms all
evaluated approaches.
4.2. MVTec Anomaly Detection Dataset
For all our experiments on MVTec AD, input images
are zoomed to w = h = 256 pixels. We train on anomalyfree images for 100 epochs with batch size 1. This is
equivalent to training on a large number of patches per
batch due to the limited size of the networks’ receptive
ﬁeld. We use Adam with initial learning rate 10−4 and
weight decay 10−5. Teacher networks were trained with
λk = λc = 1 and λm = 0, as this conﬁguration performed
best on MNIST and CIFAR-10. Ensembles contain M = 3
To train shallow classiﬁers on the teacher’s output descriptors, a subset of vectors is randomly sampled from the
teacher’s feature maps. Their dimension is then reduced
by PCA, retaining 95% of the variance. The variational
and deterministic autoencoders are implemented using a
simple fully connected architecture and are trained on
all available descriptors. In addition to ﬁtting the models
directly to the teacher’s feature distribution, we benchmark
our approach against the best performing deep learning
based methods presented by Bergmann et al. on this
dataset. These methods include the CNN-Feature Dictionary , the SSIM-Autoencoder , and AnoGAN .
All hyperparameters are listed in detail in Appendix C.
We compute a threshold-independent evaluation metric
based on the per-region-overlap (PRO), which weights
ground-truth regions of different size equally. This is in
contrast to simple per-pixel measures, such as ROC, for
which a single large region that is segmented correctly
can make up for many incorrectly segmented small ones.
It was also used by Bergmann et al. in . For computing
the PRO metric, anomaly scores are ﬁrst thresholded to
make a binary decision for each pixel whether an anomaly
Output Size
Parameters
Table 4: General outline of our network architecture for training
teachers ˆT with receptive ﬁeld size p = 65. Leaky rectiﬁed linear
units with slope 5×10−3 are applied as activation functions after
each convolution layer. Architectures for p = 17 and p = 33
are given in Appendix A.
is present or not. For each connected component within
the ground truth, the relative overlap with the thresholded
anomaly region is computed. We evaluate the PRO value
for a large number of increasing thresholds until an average per-pixel false-positive rate of 30% for the entire
dataset is reached and use the area under the PRO curve
as a measure of anomaly detection performance. Note that
for high false-positive rates, large parts of the input images
would be wrongly labeled as anomalous and even perfect
PRO values would no longer be meaningful. We normalize
the integrated area to a maximum achievable value of 1.
Table 1 shows our results training each algorithm
with a receptive ﬁeld of p = 65 for comparability. Our
method consistently outperforms all other evaluated algorithms for almost every dataset category. The shallow
machine learning algorithms ﬁtted directly to the teacher’s
descriptors after applying PCA do not manage to perform satisfactorily for most of the dataset categories. This
shows that their capacity does not sufﬁce to accurately
model the large number of available training samples.
The same can be observed for the CNN-Feature Dictionary. As it was the case in our previous experiment
on MNIST and CIFAR-10, 1-NN yields the best results
amongst the shallow models. Utilizing a large number of
training features together with deterministic autoencoders
increases the performance, but still does not match the
performance of our approach. Current generative methods
for anomaly segmentation such as Ano-GAN and the
SSIM-autoencoder perform similar to the shallow methods
ﬁtted to the discriminative embedding of the teacher. This
indicates that there is indeed a gap between methods that
learn representations for anomaly detection from scratch
and methods that leverage discriminative embeddings as
prior knowledge.
Table 3 shows the performance of our algorithm
for different receptive ﬁeld sizes p ∈{17, 33, 65} and
when combining multiple scales. For some objects, such
as bottle and cable, larger receptive ﬁelds yield better
results. For others, such as wood and toothbrush, the
inverse behavior can be observed. Combining multiple
scales enhances the performance for many of the dataset
categories. A qualitative example highlighting the beneﬁt
of our multi-scale anomaly segmentation is visualized in
Output Size
Parameters
(a) Architecture for p = 33.
Output Size
Parameters
(b) Architecture for p = 17.
Table 5: Network architectures for teacher networks ˆT with different receptive ﬁeld sizes p.
5. Conclusion
We have proposed a novel framework for the challenging problem of unsupervised anomaly segmentation
in natural images. Anomaly scores are derived from the
predictive variance and regression error of an ensemble of
student networks, trained against embedding vectors from
a descriptive teacher network. Ensemble training can be
performed end-to-end and purely on anomaly-free training
data without requiring prior data annotation. Our approach
can be easily extended to detect anomalies at multiple
scales. We demonstrate improvements over current stateof-the-art methods on a number of real-world computer
vision datasets for one-class classiﬁcation and anomaly
segmentation.
Appendix A.
Network Architectures
A description of the network architecture for a patchsized teacher network ˆT with receptive ﬁeld of size p = 65
can be found in our main paper (Table 4). Architectures for
teachers with receptive ﬁeld sizes p = 33 and p = 17 are
depicted in Tables 5a and 5b, respectively. Leaky rectiﬁed
linear units with slope 5 × 10−3 are used as activation
function after each convolution layer.
Appendix B.
Experiments on MNIST and CIFAR-10
Here, we give details about additional hyperparameters for our experiments on the MNIST and CIFAR-10
datasets. We additionally provide the per-class ROC-AUC
values for the two datasets in Tables 6 and 7, respectively.
Hyperparameter Settings. For the deterministic ℓ2autoencoder (ℓ2-AE) and the variational autoencoder
(VAE), we use a fully connected encoder architecture of
shape 128–64–32–10 with leaky rectiﬁed linear units of
slope 5 × 10−3. The decoder is constructed in a manner
symmetric to the encoder. Both autoencoders are trained
for 100 epochs at an initial learning rate of 10−2 using the
Adam optimizer and a batch size of 64. A weight decay
rate of 10−5 is applied for regularization. To evaluate the
reconstruction probability of the VAE, ﬁve independent
forward passes are performed for each feature vector. For
the One-Class SVM (OC-SVM), a radial basis function
kernel is used. K-Means is trained with 10 cluster centers
and the distance to the single closest cluster center is
evaluated as the anomaly score for each input sample. For
1-NN, the feature vectors of all available training samples
are stored and tested during inference.
Appendix C.
Experiments on MVTec AD
We give additional information on the hyperparameters used in our experiments on MVTec AD for both
shallow machine learning models as well as deep learning
Shallow Machine Learning Models. For the 1-NN classiﬁer, we construct a dictionary of 5000 feature vectors
and take the distance to the closest training sample as
anomaly score. For the other shallow classiﬁers, we ﬁt
their parameters on 50 000 training samples, randomly
chosen from the teacher’s feature maps. The K-Means
algorithm is run with 10 cluster centers and measures the
distance to the nearest cluster center in the feature space
during inference. The OC-SVM employs a radial basis
function kernel.
Deep-Learning Based Models. For evaluation on MVTec
AD, the architecture of the ℓ2-AE and VAE are identical to the ones used on the MNIST and CIFAR-10
dataset. Each fully connected autoencoder is trained for
100 epochs. We use Adam with initial learning rate 10−4
and weight decay 10−5. Batches are constructed from 512
randomly sampled vectors of the teacher’s feature maps.
The reconstruction probability of the VAE is computed
by ﬁve individual forward passes through the network.
For the evaluation of AnoGAN, the SSIM-Autoencoder,
and the CNN-Feature Dictionary, we use the same hyperparameters as Bergmann et al. in the MVTec AD dataset
paper . Only a slight adaption is applied to the CNN-
Feature Dictionary by cropping patches of size p = 65 and
performing the evaluation by computing anomaly scores
for overlapping patches with a stride of 4 pixels.
Qualitative Results. We provide additional qualitative
results of our method on MVTec AD for three objects
and three textures in Figure 6. For each category, anomaly
maps for multiple defect classes are provided. Our method
performs well across different defect types and sizes.
The results are shown for an ensemble of 3 students
and a multi-scale architecture of receptive ﬁeld sizes in
{17, 33, 65} pixels.
Figure 6: Qualitative results of our method on selected textures (left) and objects (right) of the MVTec Anomaly Detection dataset.
Our algorithm performs robustly across various defect categories, such as color defects, contaminations, and structural anomalies.
Top row: Input images containing defects. Center row: Ground truth regions of defects in red. Bottom row: Anomaly scores for
each image pixel predicted by our algorithm.
Table 6: Results on the MNIST dataset. For each method and digit, the area under the ROC curve is given. For our algorithm, we
evaluate teacher networks trained with different loss functions.  corresponds to setting the respective loss weight to 1, otherwise it
is set to 0.
automobile
Table 7: Results on the CIFAR-10 dataset. For each method and class, the area under the ROC curve is given. For our algorithm, we
evaluate teacher networks trained with different loss functions.  corresponds to setting the respective loss weight to 1, otherwise it
is set to 0.