Regulation of Dynamical Systems to Optimal Solutions of Semideﬁnite
Programs: Algorithms and Applications to AC Optimal Power Flow
Emiliano Dall’Anese, Sairaj V. Dhople, and Georgios B. Giannakis
Abstract— This paper considers a collection of networked
nonlinear dynamical systems, and addresses the synthesis of
feedback controllers that seek optimal operating points corresponding to the solution of pertinent network-wide optimization
problems. Particular emphasis is placed on the solution of
semideﬁnite programs (SDPs). The design of the feedback
controller is grounded on a dual ǫ-subgradient approach, with
the dual iterates utilized to dynamically update the dynamicalsystem reference signals. Global convergence is guaranteed
for diminishing stepsize rules, even when the reference inputs are updated at a faster rate than the dynamical-system
settling time. The application of the proposed framework to
the control of power-electronic inverters in AC distribution
systems is discussed. The objective is to bridge the time-scale
separation between real-time inverter control and network-wide
optimization. Optimization objectives assume the form of SDP
relaxations of prototypical AC optimal power ﬂow problems.
I. INTRODUCTION
This paper addresses the synthesis of feedback controllers
that seek to regulate networked nonlinear dynamical systems
to the optimal solution of a convex constrained optimization
problem. The setup is relevant in several multi-agent-system
applications. In this context, time-scale separation is typically
leveraged to enforce a strict temporal barrier in terms of
when the optimal setpoints are solved for and dispatched to
the dynamical systems. However, operational efﬁciency can
be improved by compressing the time scales and devising
means to synergize the implementation of the optimization
problems and real-time controllers.
Previous efforts in this domain are grounded in the seminal
work , where dynamical systems serve as proxies for
optimization variables and multipliers, and are synthesized
to evolve in a gradient-like fashion to the saddle points of the
Lagrangian function associated with the convex optimization
problem – . Particularly relevant to this paper are the
results reported in , where a continuous-time feedback
controller that seeks Karush-Kuhn-Tucker (KKT) conditions
for optimality of a convex constrained optimization problem
is developed. A heuristic comprising continuous-time dual
ascent and discrete-time reference-signal updates is considered in , and local stability of the resultant closedloop system is established. Distinct from , as well as
The Authors were supported in part by the National Science Foundation
(NSF) through grants NSF-CCF grant no. 1423316 and CyberSEES grant
no. 1442686. S. V. Dhople was also supported in part by the NSF CAREER
award ECCS-1453921.
E. Dall’Anese is with the National Renewable Energy Laboratory,
Golden, CO, USA. S. V. Dhople and G. B. Giannakis are with the Dept. of
ECE and Digital Tech. Center, University of Minnesota, Minneapolis, MN,
USA. E-mail: , {sdhople, georgios}@umn.edu
previous efforts in e.g., – , this work leverages dualsubgradient methods to develop a feedback controller that
steers the dynamical-system outputs towards the solution of
a convex constrained optimization problem. The proposed
scheme involves the update of dual and primal variables
in a discrete-time fashion, with the latter constituting the
reference-input signals for the dynamical systems. When
dual and primal variables are updated at a faster rate than the
system settling time, it is shown that the dual ascent step is
in fact an ǫ-subgradient . This is particularly relevant
in settings where the reference signals may be updated
continuously (within the limits of affordable computational
burden), without necessarily waiting for the underlying dynamical systems to converge to intermediate reference levels.
Convergence of system outputs to the solution of SDPtype problems is established with diminishing stepsize rules
and strictly convex cost functions. Although the framework is outlined for a semideﬁnite program (SDP), similar
convergence claims can be established for other types of
optimization problems.
The application of the proposed framework in the context
of power systems is discussed, with particular emphasis
on distribution networks featuring power-electronic-inverterinterfaced (renewable) energy resources . In particular,
the controller devised in this paper is utilized to steer the
output of inverters towards the solution of an AC optimal
power ﬂow (OPF) problem, which yields steady-state activeand reactive-power injections that are optimal according to
well-deﬁned optimization criteria. Since the AC OPF task
corresponds to a nonconvex optimization problem, an SDP
relaxation , is leveraged. In this context, the objective is to bridge the temporal gap between long-term energy
management and real-time control, to ensure adaptability
to changing ambient conditions and loads, and guarantee
seamless renewable energy integration without compromising system stability – . Similar controllers focused
on an economic dispatch problem have been proposed for
bulk power systems in . Modiﬁed automatic generation
and frequency control methods that incorporate optimization
objectives corresponding to DC optimal power ﬂow (OPF)
problems are proposed for lossless bulk power systems in ,
 . Strategies that integrate economic optimization within
droop control for islanded lossless microgrids are developed
in . Different from the continuous-time controllers developed in , , , the proposed approach accounts for
computational limits in the update of the inverter setpoints
(which naturally lead to discrete-time reference updates), and
considers strict inverter-generation limits.
II. PROBLEM FORMULATION
Consider N nonlinear dynamical systems described by1
˙xi(t) = fi
xi(t), di(t), ui(t)
yi(t) = ri
xi(t), di(t)
i ∈N := {1, . . ., N}
where: xi(t) ∈Rnx,i is the state of the i-th dynamical system
at time t; yi(t) ∈Yi ⊂Rny,i is the measurement of state
xi(t) at time t; ui(t) ∈Yi is the reference input; and di(t) ∈
Di ⊂Rnd,i is the exogenous input. Finally, fi : Rnx,i ×
Rnz,i×Rnd,i×Rny,i →Rnx,i and ri : Rnx,i×Rnd,i →Rny,i
are arbitrary (non)linear functions. Similar to, e.g., , ,
the following system behavior for constant exogenous inputs
and reference signals is presumed.
Assumption 1: For
{di ∈Di}i∈N and reference signals {ui ∈Yi}N
i=1, there
exist equilibrium points {xi}N
i=1 for (1) that satisfy:
0 = fi (xi, di, ui)
ui = ri (xi, di) ,
Notice that in (2b) the equilibrium output coincides with the
commanded input ui. Furthermore, these equilibrium points
are assumed to be locally asymptotically stable.
For given exogenous inputs {di ∈Di}N
i=1, consider the
following optimization problem associated with {ui}N
V∈V,{ui∈Yi} H(V) +
i Aiui + bT
subject to hi(V) + gi(ui, di) = 0, ∀i ∈N
where V ⊂HnV ×nV
is a convex, closed, and bounded subset
of the cone of positive semideﬁnite (Hermitian) matrices;
function H(V) : HnV ×nV
→R is known, strictly convex
and ﬁnite over V; Ai ≻0 and bi ∈Rnx,i, ∀i ∈ND; the
vector-valued function hi(V) : HnV ×nV
→Rny,i is afﬁne;
and, gi(ui, di) : Rny,i × Rnd,i →Rny,i takes the form
gi(ui, di) = Ciui + Didi, with Ci ∈Rny,i×ny,i and Di ∈
Rny,i×nd,i known. Finally, sets {Yi}i∈ND, which deﬁne the
space of possible reference inputs for the dynamical systems,
are assumed to comply to the following requirement.
Assumption 2: Sets {Yi}N
i=1 are convex, closed, and
1Notation. Upper-case (lower-case) boldface letters will be used for
matrices (column vectors); (·)T for transposition; (·)∗complex-conjugate;
and, (·)H complex-conjugate transposition; ℜ{·} and ℑ{·} denote the real
and imaginary parts of a complex number, respectively; j := √−1. Tr(·)
the matrix trace; rank(·) the matrix rank; | · | denotes the magnitude of
a number or the cardinality of a set; vec(X) returns a vector stacking the
columns of matrix X, and bdiag({Xi}) forms a block-diagonal matrix.
RN and CN denote the spaces of N × 1 real-valued and complex-valued
vectors, respectively; N the set of natural numbers; and, HN×N
denotes the
space of N × N positive semideﬁnite Hermitian matrices. Given vector x
and square matrix X, ∥x∥2 denotes the Euclidean norm of x, and ∥V∥2 the
(induced) spectral norm of matrix X. [x]i ([(x)]i) points to the i-th element
of a vector x (vector-valued function f(x)). ˙x(t) is the time derivative of
x(t). Given a scalar function f(x) : Rn →R, ∇xf(x) returns the gradient
∂x1 , . . . ,
∂xn ]T. For a continuous function f(t), f[tk] denotes its value
sampled at tk. Finally, IN denotes the N ×N identity matrix; and, 0M×N,
1M×N the M × N matrices with all zeroes and ones, respectively.
With these assumptions, problem (P1) is a convex program;
moreover, it can be reformulated into a standard SDP form
by resorting to the epigraph form of the cost function.
It is evident from (2b) that (P1) deﬁnes the optimal
operating setpoints of the dynamical systems (1) in terms of
steady-state outputs , . In fact, by utilizing the optimal
solution {uopt
i }i∈ND of (P1) as reference inputs, it follows
from (2b) that each system output will eventually be driven
to the point yi = uopt
In principle, (P1) could be solved centrally by a systemlevel control unit or in a decentralized fashion , ,
and the reference signals {uopt
i }i∈ND could be subsequently
dispatched for the dynamical systems. In lieu of this solution
with strict temporal boundaries, the objective here is to
design a decentralized feedback controller for the dynamical
systems (1), so that the resultant closed-loop system is
globally convergent to an equilibrium point {xi}N
i=1, {yi =
ri(xi, di)}N
i=1, where the values {yi}N
i=1 of the steady-state
outputs coincide with the optimal solution {uopt
i=1 of (P1).
III. FEEDBACK CONTROLLER SYNTHESIS
A. A Primer on Dual Gradient Methods
To streamline exposition, it is convenient to consider
expressing the linear equality constraints (3b) in the compact
form h(V) + g(u, d) = 0, where u := [uT
1, . . . , uT
1, . . . , dT
N]T, h(V) := [hT
1(V), . . . , hT
N(V)]T, and
g(u, d) := Cu + Dd,
with C denoting the block-diagonal matrix speciﬁed as
C := bdiag({Ci}N
i=1) and D formed using {Di}N
i=1. Thus,
recalling that [x]i ([f(x)]i) denotes the i-th element of a
vector x (vector-valued function f(x)), the following is
assumed for the convex program (P1).
Assumption 3: Problem (P1) has a non-empty feasible set
and a ﬁnite optimal cost. Furthermore, the vectors
∇[vecT(V),uT]T[h(V) + g(u, d)]j,
j = 1, . . . ,
are linearly independent.
From the non-emptiness and compactness of the feasible
set, and the continuity of the objective function, it follows
that an optimal solution to (P1) exists , . In par
with the linear independence constraint qualiﬁcation, Assumption 3 ensures existence and uniqueness of the optimal
multipliers . When a set of inequality constraints is added
to (P1), Assumption 3 can be replaced by the Mangasarian-
Fromovitz constraint qualiﬁcation to ensure non-emptiness
and boundedness of the optimal multiplier set .
Let λi ∈Rny,i denote the Lagrange multiplier associated
with equality (3b), and consider the Lagrangian function
corresponding to (3), which is deﬁned as:
L (V, {ui}, {λi}) := H(V) +
i Aiui + bT
i (hi(V) + gi(ui, di)) .
Based on (6), the dual function and the dual problem are
given by (see, e.g., )
V∈V,{ui∈Yi} L(V, {ui}, λ)
qopt := max
where λ := [λT
1, . . . , λT
N]T. Under current modeling assumptions, it follows that the duality gap is zero ; furthermore,
the dual function q(λ) is concave and differentiable .
Consider utilizing a gradient method to solve the dual
problem, which amounts to iteratively performing :
{V[k], {ui[k]}N
V∈V,{ui∈Yi} L(V, {ui}, {λi[k]})
λi[k + 1] = λi[k] + αk+1∇λiL(V[k], {ui[k]}, {λi})
where k ∈N denotes the iteration index, αk+1 ≥0 is the
stepsize, and (9b) is repeated for all i ∈N. In particular,
a non-summable but square-summable stepsize sequence is
adopted in this paper ; that is, there exist sequences
{γk}k≥0 and {ηk}k≥0 such that:
(s1) γk →0 as k →+∞, and P+∞
k=0 γk = +∞;
(s2) γk ≤αk ≤ηk for all k ≥0; and,
(s3) ηk ↓0 as k →+∞, and P+∞
At iteration k, the same step-size αk is utilized for all i ∈N.
Exploiting the decomposablility of the Lagrangian, steps (9)
can be equivalently expressed as:
V[k] = arg min
V∈V H(V) +
i [k] hi(V)
ui[k] = projYi{−A−1
i λi[k] −A−1
λi[k + 1] = λi[k] + αk+1 (hi(V[k]) + gi(ui[k], di)) (10c)
with (10b)–(10c) performed for all i ∈N, and projY{w} :=
arg minu∈Y ∥w−u∥2 denoting the projection of a vector w
onto the convex compact set Y. Finally, notice that from
the compactness of sets V and {Yi}N
i=1, it follows that there
exists a scalar G, 0 ≤G < +∞, such that
∥h(V[k]) + g(u[k], d)∥2 ≤G ,
Using (11), and a stepsize sequence {αk}k≥0 satisfying
(s1)–(s3), it turns out that the dual iterates λ[k] converge to
the optimal solution λopt of the dual problem (8); that is,
∥λopt −λ[k]∥2 →0 as k →∞[18, Prop. 8.2.6], ,
 . Given the strict convexity of the Lagrangian with
respect to all primal variables, iterates V[k] and {ui[k]}N
become asymptotically feasible and their optimal values,
Vopt and {uopt
i=1, can be recovered from (10a) and (10b),
respectively, once λopt becomes available.
B. Dynamical system in-the-loop
Consider a setup where the primal and dual updates in (10)
are performed at discrete time instants t ∈{tk, k ∈N}, and
let V[tk], {ui[tk]}N
i=1, and {λi[tk]}N
i=1 denote the values of
the primal and dual variables, respectively, at time tk. With
these deﬁnitions, steps (10) are modiﬁed to accommodate
the system dynamics in (1) as explained next. At time tk,
the system outputs are sampled as:
yi[tk] = ri (xi(tk), di) ∀i ∈N
and they are utilized to update the dual variables as speciﬁed
in the following [cf. (10c)]:
λi[tk+1] = λi[tk]
+ αk+1 (hi(V[tk]) + Ciyi[tk] + Didi) , ∀i
where the sampled output yi[tk] replaces the primal iterate
ui[tk] on the right-hand-side of (12b). Given λi[tk+1], variables V[tk+1] and {ui[tk+1]}N
i=1 are then updated as:
V[tk+1] = arg min
V∈V H(V) +
i [tk+1] hi(V)
ui[tk+1] = projYi{−A−1
i λi[tk+1] −A−1
i bi}, ∀i. (12d)
Once (12d) is solved, a vector-valued reference signal taking
the constant value ui[tk+1] over (tk, tk+1] is applied to the
dynamical system (1a); i.e., ui(t) = ui[tk+1], t ∈(tk, tk+1].
At time tk+1 the outputs {yi[tk+1]}N
i=1 are sampled again,
and (12b)–(12d) are repeated.
Steps (12b)–(12d) in effect constitute the controller for the
dynamical systems (1). Speciﬁcally, the (continuous-time)
reference signals {ui(t)}i∈ND produced by the controller
have step changes at instants {tk, k ∈N}, are left-continuous
functions, and take the constant values {ui[tk+1]}i∈ND over
the time interval (tk, tk+1]. It is evident that if ui[tk] converges to uopt
as k →∞(and thus ui(t) →uopt
then yi(t) →uopt
as t →∞by virtue of (2).
Suppose for now that the interval (tk−1, tk] is large enough
to allow the outputs of the dynamical systems to converge to
the point {ui[tk]}N
i=1; that is, limt→t−
k ∥yi(t) −ui[tk]∥= 0,
for all k [cf. (2)]. In this ideal case with a time-scale separation between controller and system dynamics, the system
dynamics do not inﬂuence the computation of the primal and
dual updates, and therefore steps (10) and (12) coincide. The
convergence results reported in Section III-A naturally carry
over to this ideal setup. However, a pertinent question here
is whether the closed-loop system (12) is convergent, and to
what points the primal and dual iterates may converge, when
at each instant tk one has that limt→t−
k ∥yi(t) −ui[tk]∦= 0
for at least one dynamical system; that is, no error-free
tracking of the reference signals is guaranteed over each slot
(tk−1, tk]. This may represent the case where, in an effort to
compress the time scales, steps (12b)–(12d) are performed
continuously (within the limits of affordable computational
burden), without necessarily waiting for the underlying dynamical systems to converge to the intermediate reference
levels {ui[tk]}N
i=1. Or, this may represent the case where
outputs are sampled without knowledge of the systems’
settling times. In the following, convergence of the closedloop system (12) is established in this more general setup.
For brevity, collect the system outputs in the vector
1, . . . , yT
N]T. Key is to notice that, given the
strict convexity of L(V, u, λ[tk]) with respect to u, the
pair (V[tk], y[tk]) represents a sub-optimal solution for the
primal update (9a) (and thus for (12c)-(12d)) whenever
k ∥y(t) −u[tk]∦= 0; that is, there exists an ǫ[tk]
such that L(V[tk], u[tk], λ[tk]) ≤L(V[tk], y[tk], λ[tk]) and
L(V[tk], y[tk], λ[tk]) ≤L(V[tk], u[tk], λ[tk]) + ǫ[tk]. Thus,
replacing the optimal primal iterate u[tk] with y[tk] in (12b)
yields an ǫ-subgradient step.
Before elaborating further on the error ǫ[tk], notice that
since sets V and {Yi}N
i=1 are compact, it follows that
∥h(V) + g(y, d)∥2 can be bounded as [cf. (11)]
∥h(V) + g(y, d)∥2 ≤G ,
∀V ∈V, ∀y ∈Y
with Y := Y1 × Y2 × . . . , ×YN. Furthermore, given the
Lipschitz-continuity of the contraction mapping (12d), there
exists a dual variable ˜λ[tk] satisfying [cf. (12d)]
yi[tk] = projYi{−A−1
i ˜λ[tk] −A−1
i bi}, ∀i ∈N
minimizing
Lagrangian
L(V, u, ˜λ[tk])
1[tk], . . . , ˜λ
N[tk]]T replaces λ[tk]. The following will be
assumed for ˜λ[tk].
Assumption 4: There exists a scalar ˜G, 0 ≤˜G < +∞,
such that the bound
∥λ[tk] −˜λ[tk]∥2 ≤˜G∥λ[tk] −λ[tk−1]∥2
holds for all tk, k ≥1.2
In subsequent developments, the following bound (which
originates from Assumption 4) is leveraged:
∥λ[tk] −˜λ[tk]∥2 ≤˜G∥λ[tk] −λ[tk−1]∥2
= ˜G∥αk(h(V[tk−1]) + g(y[tk−1], d))∥2 (17)
Note that (17) follows from the dual update equation
in (12b), and (18) follows from (13).
Three pertinent results that establish convergence of the
overall system (12) are presented next. Lemma 1 provides
an analytical characterization of the ǫ-subgradient step that
may emerge in the considered setup; Lemma 2 establishes
the constraints that (15) imposes on the tracking error
∥y[tk]−u[tk]∥2; and ﬁnally, Theorem 1 leverages Lemma 1
to establish asymptotic convergence of the reference signal
u[tk] and the iterates V[tk] to the optimal solution of (P1).3
Lemma 1: If at time tk, yi[tk] ̸= ui[tk] for at least
one dynamical system, then h(V[tk]) + g(y[tk], d) is an ǫsubgradient of the dual function at λ[tk]. In particular, under
Assumption 4, it holds that
(h(V[tk]) + g(y[tk], d))T (λ −λ[tk])
≥q(λ) −q(λ[tk]) −ǫ[tk] ∀λ ,
2Condition (15) can be re-stated in terms of the output signals y[tk].
Speciﬁcally, letting ξi[tk] := −A−1
i λ[tk]−A−1
bi be the unprojected
reference signal, and assuming that matrix A−1
i is invertible, one has
that (15) is implied by the bound ∥ξ[tk] −y[tk]∥≤¯G∥ξ[tk] −ξ[tk−1]∥,
upon setting ˜G = ¯G∥−A−1
i ∥2∥(−A−1
3Proofs are omitted due to space constrains, and are available in .
where the error ǫ[tk] ≥0 can be bounded as ǫ[tk] ≤
Proof. For notational convenience, deﬁne
su[tk] := h(V[tk]) + g(u[tk], d),
sy[tk] := h(V[tk]) + g(y[tk], d).
Notice that su[tk] and sy[tk] are the gradients of the dual
function (7) evaluated at λ[tk] and ˜λ[tk], respectively ;
i.e., it holds that
u[tk](λ −λ[tk]) ≥q(λ) −q(λ[tk]),
y[tk](λ −˜λ[tk]) ≥q(λ) −q(˜λ[tk]), ∀λ
y[tk](˜λ[tk]−λ[tk]) to both sides of (20c), one gets
that the following holds ∀λ
y[tk](λ −λ[tk]) ≥q(λ) −q(˜λ[tk]) + sT
y[tk](˜λ[tk] −λ[tk]) .
Adding and subtracting q(λ[tk]) to the right-hand-side of the
inequality above,
y[tk](λ −λ[tk]) ≥q(λ) −q(λ[tk])
+ q(λ[tk]) −q(˜λ[tk]) + sT
y[tk](˜λ[tk] −λ[tk]).
With regard to (20d), deﬁne
ǫ[tk] := q(˜λ[tk]) −q(λ[tk]) + sT
y[tk](λ[tk] −˜λ[tk]). (20e)
By using the deﬁnition of the gradient of the dual function
at λ[tk] and applying the Cauchy-Schwartz inequality, one
u[tk](˜λ[tk] −λ[tk]) + sT
y[tk](λ[tk] −˜λ[tk]) (20f)
≤2G ∥˜λ[tk] −λ[tk]∥2
where (13) was used to obtain (20g) from (20f), and (20h)
follows from (18).
Condition (15) implicitly bounds the tracking error
∥y[tk] −u[tk]∥2, as speciﬁed in the following lemma.
Lemma 2: Under Assumption 4, it follows that the tracking error ∥y[tk] −u[tk]∥2, k ∈N, can be bounded as
∥y[tk] −u[tk]∥2 ≤∥−A−1CT∥2 ˜GGαk.
Proof. From the non-expansive property of the projection
operator, the left-hand side of (21) can be bounded as:
∥y[tk] −ui[tk]∥2 ≤∥−A−1CT(˜λ[tk] −λ[tk])∥2
≤∥−A−1CT∥2∥˜λ[tk] −λ[tk]∥2
≤∥−A−1CT∥2 ˜GGαk
where (22) follows from (18).
It can be noticed from (21) that the tracking error is
allowed to be arbitrarily large, but the system output y[tk]
should eventually follow the reference signal u[tk]. In fact,
since the sequence {αk} is majorized by {ηk}, and ηk ↓0,
it follows that ∥y[tk] −u[tk]∥2 →0 as k →∞.
While (21) bounds the error ∥y[tk] −u[tk]∥2, asymptotic
convergence of the reference signal u[tk] as well as of
iterates V[tk] to the optimal solution of the steady-state
optimization problem (P1) is established next.
Theorem 1: Under Assumptions 1–4, and using a stepsize
sequence {αk}k≥0 satisfying conditions (s1)–(s3), the following holds for the closed-loop system (12):
i) {λ[tk]}k≥0 is bounded;
ii) λ[tk] →λopt as k →∞;
iii) V[tk] →Vopt and {ui[tk] →uopt
} as k →∞; and,
iv) yi(t) →uopt
as t →∞, ∀i ∈N.
Statements
conditions
V , {ui }, {yi(0)}, λ , and 0 < tk −tk−1 < ∞,
Proof. i)–ii) Boundedness and convergence of the dual iterates can be proved by leveraging the results of Theorem 3.4
in . In particular, it sufﬁces to show that the following
technical requirement is satisﬁed in the present setup:
αkǫ[tk] < +∞.
From Lemma 1, it follows that the left-hand-side of (23a)
can be bounded as
k ˜GG2 ≤2 ˜GG2
where the second inequality in (23b) follows from the fact
≤ηk for all k. Since P+∞
series (23b) is ﬁnite, and thus (23a) holds.
iii) From the strict convexity of the Lagrangian in the
primal variables, it follows that optimal primal variables
{Voptuopt}
arg minV∈V,u∈U L
 V, u, λopt
iv) At convergence, the reference signal is constant, with
value uopt
i . Then, yi(t) →uopt
as t →∞by (2).
Remark. Problem (3) could be solved either centrally or in
a decentralized fashion, and the reference signals {uopt
could be subsequently dispatched for the dynamical systems.
It is evident that with these solutions the optimization and
local control tasks operate at two different time scales, with
reference signals updated every time that problem (3) is
solved. Further, if relevant problem parameters change during
the solution of (3), strategies operating under time-scale
separation would dispatch outdated setpoints. In contrast,
steps (12) continuously pursue solutions of the formulated
optimization problem by dynamically updating the setpoints,
based on current system outputs and problem parameters. □
IV. DYNAMIC CONTROLLER FOR INVERTERS
Consider a distribution system comprising N + 1 nodes
collected in the set N
:= {0, 1, . . ., N}, with node 0
denoting the secondary of the transformer, and lines represented by the set of undirected edges E := {(m, n)}.
For simplicity of exposition, assume that the system is
balanced, and renewable-interfaced inverters are located at
N\{0}. However, the framework can be readily extended to
account for: unbalanced multi-phase systems (by following
the method in ); load control (by considering fourquadrant inverters); and, nodes with no power generation (by
adding relevant constraints ).
Let Vi ∈C and Ii ∈C denote the phasors for the lineto-ground voltage and the current injected at node i ∈N,
respectively, and deﬁne i := [I0, . . . , IN]T ∈CN+1 and v :=
[V0, . . . , VN]T ∈CN+1. Using Ohm’s and Kirchhoff’s circuit
laws, the linear relationship i = Yv can be established,
where the system admittance matrix Y ∈CN+1×N+1 is
formed based on the system topology and the π-equivalent
circuits of the lines (m, n) ∈E; see e.g., , .
Similar to e.g., – , consider expressing powers and
voltage magnitudes as linear functions of the outer-product
matrix V := vvH. Speciﬁcally, deﬁne Yi := eieT
node i, where {ei}i∈N denotes the canonical basis of RN+1.
Based on Yi, deﬁne also the Hermitian matrices Φi :=
i ), Ψi := j
i ), and Υi := eieT
the net injected powers at node i ∈N can be expressed as
Tr(ΦiV) = ¯Pi−¯Pℓ,i and Tr(ΨiV) = ¯Qi−¯Qℓ,i, respectively,
where ¯Pℓ,i and ¯Qℓ,i denote the active and reactive setpoints
for the demand at node i ∈N\{0}, whereas ¯Pi and ¯Qi are
the active and reactive powers generated. Further, |Vi|2 is
given by |Vi|2 = Tr(ΥiV).
Upon denoting as Vmin and Vmax lower and upper limits
for {|Vn|}N
n=0, matrix V is conﬁned to lie in the set
V1 := {V ⪰0 : rank(V) = 1, V 2
min ≤Tr(ΥiV) ≤V 2
with the constraint |V0| = 1 left implicit.
For prevailing ambient conditions, let P av
denote the
available active power for the inverter at node i ∈N\{0}.
Then, the allowed operating regime for the inverter at node
i is assumed to be Yi = { ¯Pi, ¯Qi : 0 ≤¯Pi ≤P av
i , | ¯Qi| ≤tan θ ¯Pi} (see e.g., , for a more
detailed explanation of possible inverter operating regions)
where Si is the apparent power rating, and θ models power
factor constraints. Set Yi clearly adheres to Assumption 2.
Powers { ¯Pi, ¯Qi}N
i=1 as well as the voltage-related matrix
V model the steady-state operation of the distribution system. For given load and ambient conditions, a prototypical
OPF formulation for optimizing the steady-state operation
of the distribution system can be obtained by constraining
variables V and ( ¯Pi, ¯Qi) to the sets V1 and Yi, respectively,
and using the following mapping between the quantities
explained above with the ones in (3):
ui = [ ¯Pi, ¯Qi]T, di = [ ¯Pℓ,i, ¯Qℓ,i]T , Ci = −I2×2,
Di = I2×2, hi(V) = [Tr(ΦiV), Tr(ΨiV)]T
and H(V) = a
2(Tr(Φ0V))2+bTr(Φ0V), a > 0, b ≥0. With
this mapping, (3b) represents the per-node balance equation
for active and reactive powers, and H(V) captures the cost
of power drawn from (or supplied to) the substation. Unfortunately, the resultant optimization problem is nonconvex
because of the constraint rank(V) = 1. However, in the
spirit of semideﬁnite relaxation , this constraint can be
dropped; thus, V1 is replaced by the convex set
V := {V ⪰0 : V 2
min ≤Tr(ΥiV) ≤V 2
Using V, problem (P1) turns out to be a relaxation of the AC
OPF problem. If the optimal solution has rank(Vopt) = 1,
then the resultant power ﬂows are globally optimal , .
A. Dynamic Controller
Let Pi(t) and Qi(t) denote the active and reactive powers
of inverter i averaged over one AC cycle, respectively, and
consider setting state and output of the system (1) as follows:
xi(t) = [Pi(t), Qi(t)]T ,
yi(t) = xi(t) .
Thus, (1a) models the dynamics of real- and reactive-power
controller at each inverter i, whereas (1b) boils down to a
measurement of the inverter outputs. Dynamic models for
the real and reactive power for inverters operating in a gridconnected mode are discussed in e.g., [11, Ch. 8]. Finally,
variables zi(t) correspond to voltages on the lines connecting
the inverters.
The goal of the controller (12b)–(12d) is to steer the power
output yi(t) = [Pi(t), Qi(t)]T of each inverter i towards the
OPF solution uopt
= [ ¯P opt
]T. During each interval
(tk−1, tk], the reference level ui[tk] = [ ¯Pi[tk], ¯Qi[tk]]T is
updated locally at each inverter i via (12d), based on the most
up-to-date multiplier λi[tk]; while, the primal variable V[tk]
is updated by a central authority (e.g., utility company),
which aims to optimize the network performance. Thus, the
resulting scheme is naturally decentralized, and it entails a
message passing that can be carried out via existing advance
metering infrastructure protocols. Theorem 1 ensures that the
output powers Pi(t), Qi(t) converge to ¯P opt
slot duration 0 < tk −tk−1 < ∞, k ∈N; that is, in an effort
to mitigate the strict time-scale separation between real-time
inverter control and steady-state network optimization ,
steps (12b)–(12d) are performed continuously (within the
limits of affordable computational burden), without waiting
for the inverters to converge to the intermediate reference
levels, and without knowing the inverter controller dynamics.
B. Representative numerical results
Consider an illustrative low-voltage residential distribution
system comprising a step-down transformer and N = 5
nodes featuring inverter-interfaced renewable sources. The
node-node distance is set to 50 m, and the line impedances
are Zmn = 0.0135 + j0.0045Ωfor all (m, n) ∈E. The
optimization package CVX ( is
employed to perform the primal updates. In the numerical
test, the rank of matrix Vopt was 1, meaning that the globally
optimal solution of the OPF was identiﬁed . Voltage limits V min and V max are set to 0.95 pu and 1.05 pu, and the voltage magnitude at the substation is ﬁxed to |V0| = 1. The active and reactive loads are 1.10, 1.10, 1.10, 1.09, 1.10 kW and
826, 828, 829, 821, 830 VAr, respectively. As described in detail in , the operating regions {Yi} of inverters providing
ancillary services are formed based on the power ratings
i=1, which are taken to be 4.66, 4.83, 7.62, 7.62, 7.62
kVA, as well as the available active powers {P av
assumed to be 1.91, 1.95, 3.24, 3.24, 3.24 kW. In the cost
function (3a), the cost of power drawn from the substation
Normalized time t/τ
Inverter 1
Inverter 2
Inverter 3
Inverter 4
Inverter 5
Normalized time t/τ
Normalized time t/τ
Convergence of (12), when the inverter-power dynamics are
approximated as ﬁrst-order systems with time constant τ. Plots illustrate
the evolution of the active powers when the system outputs are measured
at intervals of length: (a) 9τ; (b) 2.7τ; and, 0.9τ.
is H(V) = (Tr(Φ0V))2 + 10 × Tr(Φ0V), whereas Ai =
[1, 0; 0, .01] and bi = [10, 0.1]T, for all i = 1, . . . , 5.
A ﬁrst-order system with time constant τ = 1.1 is utilized
to model the active and reactive power dynamics of each
inverter [11, Ch. 8]. For all i = 1, . . . , 5, the initial states
are set to Pi(0) = Qi(0) = 0; for the voltage related matrix,
the initial iterate is V = I. Finally, the stepsize αk =
k), for k ≥1, is utilized.
As a representative result, Fig. 1 illustrates the evolution of
the active powers generated by the inverters (similar trajectories are obtained for the reactive powers, as well as for the
active and reactive powers drawn from the point of common
coupling). Two setups are considered, depending on the duration of the interval tk −tk−1 between consecutive updates of
variables V[tk] and u[tk]: (a) tk −tk−1 = 9τ; (b) 2.7τ, and,
(b) 0.9τ. Clearly, in setup (a), the output of the ﬁrst-order
systems converge to the reference inputs {ui[tk]} within each
interval (tk−1, tk]; see Fig. 1(a). This yields a dual gradient
step in (12b) and, as expected, the overall scheme converges
to the solution of the of the OPF (P1), which yields the
following active powers: 0.86, 0.93, 0.97, 1.00, 1.01 kW.
In setup (b), updates of V[tk] and u[tk] are performed with
higher frequency, and the output of the dynamical systems
{yi[tk]} are different than the reference signals {yi[tk]} at
each tk, k ≥1. Thus, (12b) constitutes in this case an ǫsubgradient. Nevertheless, outputs {yi[tk]} converge to the
solution of (P1), thus corroborating the claims of Theorem 1.
In spite of the inexact update of the dual variables, the
inverter outputs show a faster convergence to the solution
of (P1) compared to Fig. 1(a). In the third case (c), the time
scales are further compressed, since the update of primal
and dual variables is performed every 0.9τ. By performing
the primal and dual updates more frequently, this scheme
converges markedly faster than (a) to the OPF solution.
V. CONCLUDING REMARKS AND FUTURE WORK
The paper developed a feedback controller for networked
nonlinear dynamical systems, able to steer the system outputs
to the solution of a convex constrained optimization problem.
Global convergence was established for diminishing stepsize
rules and strictly convex cost functions, even when the
dynamical-system reference inputs are updated at a faster
rate than the dynamical-system settling time. The application
of the proposed framework to the control of power-electronic
inverters in AC distribution systems is discussed.