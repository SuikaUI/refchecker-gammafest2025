Proceedings of NAACL-HLT 2016, pages 120–129,
San Diego, California, June 12-17, 2016. c⃝2016 Association for Computational Linguistics
Multi-domain Neural Network Language Generation for
Spoken Dialogue Systems
Tsung-Hsien Wen, Milica Gaˇsi´c, Nikola Mrkˇsi´c, Lina M. Rojas-Barahona,
Pei-Hao Su, David Vandyke, Steve Young
Cambridge University Engineering Department,
Trumpington Street, Cambridge, CB2 1PZ, UK
{thw28,mg436,nm480,lmr46,phs26,djv27,sjy}@cam.ac.uk
Moving from limited-domain natural language generation (NLG) to open domain is
difﬁcult because the number of semantic input combinations grows exponentially with
the number of domains. Therefore, it is important to leverage existing resources and exploit similarities between domains to facilitate
domain adaptation. In this paper, we propose
a procedure to train multi-domain, Recurrent
Neural Network-based (RNN) language generators via multiple adaptation steps. In this
procedure, a model is ﬁrst trained on counterfeited data synthesised from an out-of-domain
dataset, and then ﬁne tuned on a small set of
in-domain utterances with a discriminative objective function. Corpus-based evaluation results show that the proposed procedure can
achieve competitive performance in terms of
BLEU score and slot error rate while signiﬁcantly reducing the data needed to train generators in new, unseen domains. In subjective
testing, human judges conﬁrm that the procedure greatly improves generator performance
when only a small amount of data is available
in the domain.
Introduction
Modern Spoken Dialogue Systems (SDS) are typically developed according to a well-deﬁned ontology, which provides a structured representation of
the domain data that the dialogue system can talk
about, such as searching for a restaurant or shopping for a laptop. Unlike conventional approaches
employing a substantial amount of handcrafting for
each individual processing component , statistical approaches to SDS promise a domain-scalable framework which requires a minimal amount of human intervention . Mrkˇsi´c et al. 
showed improved performance in belief tracking by
training a general model and adapting it to speciﬁc
domains. Similar beneﬁt can be observed in Gaˇsi´c
et al. , in which a Bayesian committee machine was used to model policy learning in a multi-domain SDS regime.
In past decades, adaptive NLG has been studied from linguistic perspectives, such as systems
that learn to tailor user preferences , convey a speciﬁc personality trait ,
or align with their conversational partner .
Domain adaptation was ﬁrst addressed by Hogan et al. using a generator
based on the Lexical Functional Grammar (LFG) fstructures . Although
these approaches can model rich linguistic phenomenon, they are not readily adaptable to data
since they still require many handcrafted rules to
deﬁne the search space. Recently, RNN-based language generation has been introduced . This class of statistical
generators can learn generation decisions directly
from dialogue act (DA)-utterance pairs without any
semantic annotations 
or hand-coded grammars . Many existing adaptation approaches can be directly applied due to the
ﬂexibility of the underlying RNN language model
(RNNLM) architecture .
Discriminative training (DT) has been successfully used to train RNNs for various tasks. By optimising directly against the desired objective function such as BLEU score or
Word Error Rate , the model can
explore its output space and learn to discriminate between good and bad hypotheses. In this paper we
show that DT can enable a generator to learn more
efﬁciently when in-domain data is scarce.
The paper presents an incremental recipe for
training multi-domain language generators based on
a purely data-driven, RNN-based generation model.
Following a review of related work in section 2, section 3 describes the detailed RNN generator architecture. The data counterfeiting approach for synthesising an in-domain dataset is introduced in section 4, where it is compared to the simple model
ﬁne-tuning approach.
In section 5, we describe
our proposed DT procedure for training natural language generators. Following a brief review of the
data sets used in section 6, corpus-based evaluation
results are presented in section 7. In order to assess
the subjective performance of our system, a quality
test and a pairwise preference test are presented in
section 8. The results show that the proposed adaptation recipe improves not only the objective scores
but also the user’s perceived quality of the system.
We conclude with a brief summary in section 9.
Related Work
Domain adaptation problems arise when we have a
sufﬁcient amount of labeled data in one domain (the
source domain), but have little or no labeled data in
another related domain (the target domain). Domain
adaptability for real world speech and language applications is especially important because both language usage and the topics of interest are constantly
evolving. Historically, domain adaptation has been
less well studied in the NLG community. The most
relevant work was done by Hogan et al. .
They showed that an LFG f-structure based generator could yield better performance when trained on
in-domain sentences paired with pseudo parse tree
inputs generated from a state-of-the-art, but out-ofdomain parser. The SPoT-based generator proposed
by Walker et al. has the potential to address
domain adaptation problems. However, their published work has focused on tailoring user preferences and mimicking personality traits .
 proposed a Reinforcement Learning (RL)
framework in which policy and NLG components
can be jointly optimised and adapted based on online user feedback.
In contrast,
Mairesse et al.
 has proposed using active learning to mitigate the data sparsity problem when training datadriven NLG systems. Furthermore, Cuayhuitl et al.
 trained statistical surface realisers from unlabelled data by an automatic slot labelling technique.
In general, feature-based adaptation is perhaps the
most widely used technique . By exploiting correlations and similarities between data
points, it has been successfully applied to problems
like speaker adaptation and various tasks in
natural language processing . In
contrast, model-based adaptation is particularly useful for language modeling (LM) .
Mixture-based topic LMs are widely used in N-gram LMs for domain
adaptation. Similar ideas have been applied to applications that require adapting LMs, such as machine
translation (MT) and
personalised speech recognition .
Domain adaptation for Neural Network (NN)based LMs has also been studied in the past.
A feature augmented RNNLM was ﬁrst proposed
by Mikolov and Zweig , but later applied to
multi-genre broadcast speech recognition and personalised language modeling .
These methods are based on ﬁnetuning existing network parameters on adaptation
data. However, careful regularisation is often necessary .
In a slightly different
area, Shi et al. applied curriculum learning
to RNNLM adaptation.
Discriminative training (DT) is an
alternative to the maximum likelihood (ML) criterion. For classiﬁcation, DT can be split into two
phases: (1) decoding training examples using the
current model and scoring them, and (2) adjusting
the model parameters to maximise the separation
between the correct target annotation and the competing incorrect annotations. It has been successfully applied to many research problems, such as
speech recognition and MT . Recently, Auli and Gao trained
an RNNLM with a DT objective and showed improved performance on an MT task. However, their
RNN probabilities only served as input features to a
phrase-based MT system.
The Neural Language Generator
The neural language generation model is a RNNLM augmented with semantic input features
such as a dialogue act1 (DA) denoting the required
semantics of the generated output. At every time
step t, the model consumes the 1-hot representation
of both the DA dt and a token wt2 to update its internal state ht. Based on this new state, the output
distribution over the next output token is calculated.
The model can thus generate a sequence of tokens
by repeatedly sampling the current output distribution to obtain the next input token until an end-ofsentence sign is generated. Finally, the generated
sequence is lexicalised3 to form the target utterance.
The Semantically Conditioned Long Short-term
Memory Network (SC-LSTM) 
is a specialised extension of the LSTM network .
Like LSTM, SC-LSTM relies on a vector of memory cells ct ∈Rn and a set of elementwise multiplication gates to control how information is stored,
forgotten, and exploited inside the network. The SC-
LSTM architecture used in this paper is deﬁned by
1A combination of an action type and a set of slot-value
pairs. e.g. inform(name=”Seven days”,food=”chinese”)
2We use token instead of word because our model operates
on text for which slot values are replaced by their corresponding
slot tokens. We call this procedure delexicalisation.
3The process of replacing slot token by its value.
the following equations,
dt = rt ⊙dt−1
ct = ft ⊙ct−1 + it ⊙ˆct + tanh(Wdcdt)
ht = ot ⊙tanh(ct)
where n is the hidden layer size, it, ft, ot, rt ∈
 n are input, forget, output, and reading gates respectively, ˆct and ct are proposed cell value and true
cell value at time t, W5n,2n and Wdc are the model
parameters to be learned. The major difference of
the SC-LSTM compared to the vanilla LSTM is the
introduction of the reading gates for controlling the
semantic input features presented to the network. It
was shown in Wen et al. that these reading
gates act like keyword and key phrase detectors that
learn the alignments between individual semantic
input features and their corresponding realisations
without additional supervision.
After the hidden layer state is obtained, the computation of the next word distribution and sampling
from it is straightforward,
p(wt+1|wt, wt−1, ...w0, dt) = softmax(Whoht)
wt+1 ∼p(wt+1|wt, wt−1, ...w0, dt).
where Who is another weight matrix to learn. The
entire network is trained end-to-end using a cross
entropy cost function, between the predicted word
distribution pt and the actual word distribution yt,
with regularisations on DA transition dynamics,
t log(yt) + ∥dT∥+ PT−1
t=0 ηξ∥dt+1−dt∥
where θ = {W5n,2n, Wdc, Who}, dT is the DA
vector at the last index T, and η and ξ are constants
set to 10−4 and 100, respectively.
Training Multi-domain Models
Given training instances (represented by DA and
sentence tuples {di, Ωi}) from the source domain S
(rich) and the target domain T (limited), the goal is
to ﬁnd a set of SC-LSTM parameters θT that can
perform acceptably well in the target domain.
Figure 1: An example of data counterfeiting algorithm. Both slots and values are delexicalised. Slots and
values that are not in the target domain are replaced during data counterfeiting (shown in red with * sign).
The preﬁx inside bracket <> indicates the slot’s functional class (I for informable and R for requestable).
Model Fine-Tuning
A straightforward way to adapt NN-based models to
a target domain is to continue training or ﬁne-tuning
a well-trained generator on whatever new target domain data is available. This training procedure is as
1. Train a source domain generator θS on source
domain data {di, Ωi} ∈S with all values delexicalised4.
2. Divide the adaptation data into training and validation sets. Reﬁne parameters by training on
adaptation data {di, Ωi} ∈T with early stopping and a smaller starting learning rate. This
yields the target domain generator θT.
Although this method can beneﬁt from parameter
sharing of the LM part of the network, the parameters of similar input slot-value pairs are not shared4.
In other words, realisation of any unseen slot-value
pair in the target domain can only be learned from
scratch. Adaptation offers no beneﬁt in this case.
Data Counterfeiting
In order to maximise the effect of domain adaptation, the model should be able to (1) generate acceptable realisations for unseen slot-value pairs based
on similar slot-value pairs seen in the training data,
4We have tried training with both slots and values delexicalised and then using the weights to initialise unseen slot-value
pairs in the target domain. However, this yielded even worse
results since the learned semantic alignment stuck at local minima. Pre-training only the LM parameters did not produce better
results either.
and (2) continue to distinguish slot-value pairs that
are similar but nevertheless distinct. Instead of exploring weight tying strategies in different training
stages (which is complex to implement and typically
relies on ad hoc tying rules), we propose instead a
data counterfeiting approach to synthesise target domain data from source domain data. The procedure
is shown in Figure 1 and described as following:
1. Categorise slots in both source and target domain into classes, according to some similarity
measure. In our case, we categorise them based
on their functional type to yield three classes:
informable, requestable, and binary5.
2. Delexicalise all slots and values.
3. For each slot s in a source instance (di, Ωi) ∈
S, randomly select a new slot s′ that belongs
to both the target ontology and the class of s
to replace s. Repeat this process for every slot
in the instance and yield a new pseudo instance
( ˆdi, ˆΩi) ∈T in the target domain.
4. Train a generator ˆθT on the counterfeited
dataset { ˆdi, ˆΩi} ∈T.
5. Reﬁne parameters on real in-domain data. This
yields ﬁnal model parameters θT.
This approach allows the generator to share realisations among slot-value pairs that have similar functionalities, therefore facilitates the transfer learning
5Informable class include all non-binary informable slots
while binary class includes all binary informable slots.
Television
informable slots
family, *pricerange, batteryrating,
driverange, weightrange,
isforbusinesscomputing
family, *pricerange, screensizerange,
ecorating, hdmiport, hasusbport
requestable slots
*name, *type, *price, warranty, battery,
design, dimension, utility, weight,
platform, memory, drive, processor
*name, *type, *price, resolution,
powerconsumption, accessories, color,
screensize, audio
*inform, *inform only match, *inform on match, inform all, *inform count,
inform no info, *recommend, compare, *select, suggest, *conﬁrm, *request,
*request more, *goodbye
bold=binary slots, *=overlap with SF Restaurant and Hotel domains, all informable slots can take ”dontcare” value
Table 1: Ontologies for Laptop and TV domains
of rare slot-value pairs in the target domain. Furthermore, the approach also preserves the co-occurrence
statistics of slot-value pairs and their realisations.
This allows the model to learn the gating mechanism
even before adaptation data is introduced.
Discriminative Training
In contrast to the traditional ML criteria (Equation 1)
whose goal is to maximise the log-likelihood of correct examples, DT aims at separating correct examples from competing incorrect examples. Given a
training instance (di, Ωi), the training process starts
by generating a set of candidate sentences Gen(di)
using the current model parameter θ and DA di. The
discriminative cost function can therefore be written
F(θ) = −E[L(θ)]
pθ(Ω|di)L(Ω, Ωi)
where L(Ω, Ωi) is the scoring function evaluating
candidate Ωby taking ground truth Ωi as reference.
pθ(Ω|di) is the normalised probability of the candidate and is calculated by
pθ(Ω|di) =
exp[γ log p(Ω|di,θ)]
Ω′∈Gen(di) exp[γ log p(Ω′|di,θ)] (3)
γ ∈[0, ∞] is a tuned scaling factor that ﬂattens the
distribution for γ < 1 and sharpens it for γ > 1. The
unnormalised candidate likelihood log p(Ω|di, θ) is
produced by summing token likelihoods from the
RNN generator output,
log p(Ω|di, θ) =
log p(wt|di, θ)
The scoring function L(Ω, Ωi) can be further generalised to take several scoring functions into account
L(Ω, Ωi) =
Lj(Ω, Ωi)βj
where βj is the weight for j-th scoring function.
Since the cost function presented here (Equation 2)
is differentiable everywhere, back propagation can
be applied to calculate the gradients and update parameters directly.
In order to test our proposed recipe for training
multi-domain language generators, we conducted
experiments using four different domains: ﬁnding a
restaurant, ﬁnding a hotel, buying a laptop, and buying a television. Datasets for the restaurant and hotel
domains have been previously released by Wen et al.
 . These were created by workers recruited
by Amazon Mechanical Turk (AMT) by asking them
to propose an appropriate natural language realisation corresponding to each system dialogue act actually generated by a dialogue system.
the number of actually occurring DA combinations
in the restaurant and hotel domains were rather limited (∼200) and since multiple references were collected for each DA, the resulting datasets are not suf-
ﬁciently diverse to enable the assessment of the generalisation capability of the different training methods over unseen semantic inputs.
In order to create more diverse datasets for the
laptop and TV domains, we enumerated all possible
combinations of dialogue act types and slots based
on the ontology shown in Table 1.
This yielded
(a) BLEU score curve
(b) Slot error rate curve
Results evaluated on TV domain by
adapting models from laptop domain.
Comparing train-from-scratch model (scratch) with model
ﬁne-tuning approach (tune) and data counterfeiting
method (counterfeit). 10% ≈700 examples.
about 13K distinct DAs in the laptop domain and 7K
distinct DAs in the TV domain. We then used AMT
workers to collect just one realisation for each DA.
Since the resulting datasets have a much larger input
space but only one training example for each DA,
the system must learn partial realisations of concepts and be able to recombine and apply them to
unseen DAs. Also note that the number of act types
and slots of the new ontology is larger, which makes
NLG in both laptop and TV domains much harder.
Corpus-based Evaluation
We ﬁrst assess generator performance using two objective evaluation metrics, the BLEU-4 score and slot error rate ERR . Slot error rates were calculated by averaging slot errors over each of the top 5 realisations
in the entire corpus. We used multiple references to
compute the BLEU scores when available (i.e. for
the restaurant and hotel domains). In order to better
(a) BLEU score curve
(b) Slot error rate curve
Figure 3: The same set of comparison as in Figure 2,
but the results were evaluated by adapting from SF
restaurant and hotel joint dataset to laptop and TV
joint dataset. 10% ≈2K examples.
compare results across different methods, we plotted
the BLEU and slot error rate curves against different
amounts of adaptation data. Note that in the graphs
the x-axis is presented on a log-scale.
Experimental Setup
The generators were implemented using the Theano
library ,
and trained by partitioning each of the collected corpora into a training, validation, and testing set in the
ratio 3:1:1. All the generators were trained by treating each sentence as a mini-batch. An l2 regularisation term was added to the objective function for
every 10 training examples. The hidden layer size
was set to be 100 for all cases. Stochastic gradient
descent and back propagation through time were used to optimise the parameters. In order to prevent overﬁtting, early stopping was implemented using the validation set.
During decoding, we over-generated 20 utterances and selected the top 5 realisations for each DA
according to the following reranking criteria,
R = −(F(θ) + λERR)
where λ is a tradeoff constant, F(θ) is the cost generated by network parameters θ, and the slot error
rate ERR is computed by exact matching of the slot
tokens in the candidate utterances. λ is set to a large
value (10) in order to severely penalise nonsensical
outputs. Since our generator works stochastically
and the trained networks can differ depending on the
initialisation, all the results shown below were averaged over 5 randomly initialised networks.
Data Counterfeiting
We ﬁrst compared the data counterfeiting (counterfeit) approach with the model ﬁne-tuning (tune)
method and models trained from scratch (scratch).
Figure 2 shows the result of adapting models between similar domains, from laptop to TV. Because
of the parameter sharing in the LM part of the
network, model ﬁne-tuning (tune) achieves a better BLEU score than training from scratch (scratch)
when target domain data is limited. However, if we
apply the data counterfeiting (counterfeit) method,
we obtain an even greater BLEU score gain. This is
mainly due to the better realisation of unseen slotvalue pairs.
On the other hand, data counterfeiting (counterfeit) also brings a substantial reduction
in slot error rate. This is because it preserves the
co-occurrence statistics between slot-value pairs and
realisations, which allows the model to learn good
semantic alignments even before adaptation data is
introduced. Similar results can be seen in Figure 3,
in which adaptation was performed on more disjoint
domains: restaurant and hotel joint domain to laptop
and TV joint domain. The data counterfeiting (counterfeit) method is still superior to the other methods.
Discriminative Training
The generator parameters obtained from data counterfeiting and ML adaptation were further tuned by
applying DT. In each case, the models were optimised using two objective functions: BLEU-4 score
and slot error rate. However, we used a soft version
of BLEU called sentence BLEU as described in Auli
and Gao , to mitigate the sparse n-gram match
problem of BLEU at the sentence level. In our experiments, we set γ to 5.0 and βj to 1.0 and -1.0 for
(a) Effect of DT on BLEU
(b) Effect of DT on slot error rate
Figure 4: Effect of applying DT training after ML
adaptation. The results were evaluated on laptop to
TV adaptation. 10% ≈700 examples.
BLEU and ERR, respectively. For each DA, we applied our generator 50 times to generate candidate
sentences. Repeated candidates were removed. We
treated the remaining candidates as a single batch
and updated the model parameters by the procedure
described in section 5. We evaluated performance
of the algorithm on the laptop to TV adaptation scenario, and compared models with and without discriminative training (ML+DT & ML). The results
are shown in Figure 4 where it can be seen that
DT consistently improves generator performance on
both metrics. Another interesting point to note is
that slot error rate is easier to optimise compared to
BLEU (ERR→0 after DT). This is probably because the sentence BLEU optimisation criterion is
only an approximation of the corpus BLEU score
used for evaluation.
Human Evaluation
Since automatic metrics may not consistently agree
with human perception , human
testing is needed to assess subjective quality. To do
TV to Laptop
laptop to TV
* p <0.05, ** p <0.005
Table 2: Human evaluation for utterance quality in
two domains.
Results are shown in two metrics
(rating out of 3). Statistical signiﬁcance was computed using a two-tailed Student’s t-test, between the
model trained with full data (scrALL) and all others.
this, a set of judges were recruited using AMT. We
tested our models on two adaptation scenarios: laptop to TV and TV to laptop. For each task, two
systems among the four were compared: training
from scratch using full dataset (scrALL), adapting
with DT training but only 10% of target domain data
(DT-10%), adapting with ML training but only 10%
of target domain data (ML-10%), and training from
scratch using only 10% of target domain data (scr-
10%). In order to evaluate system performance in
the presence of language variation, each system generated 5 different surface realisations for each input
DA and the human judges were asked to score each
of them in terms of informativeness and naturalness
(rating out of 3), and also asked to state a preference between the two. Here informativeness is de-
ﬁned as whether the utterance contains all the information speciﬁed in the DA, and naturalness is de-
ﬁned as whether the utterance could plausibly have
been produced by a human. In order to decrease the
amount of information presented to the judges, utterances that appeared identically in both systems were
ﬁltered out. We tested about 2000 DAs for each scenario distributed uniformly between contrasts except
that allowed 50% more comparisons between ML-
10% and DT-10% because they were close.
Table 2 shows the subjective quality assessments
which exhibit the same general trend as the objective
results. If a large amount of target domain data is
available, training everything from scratch (scrALL)
achieves a very good performance and adaptation is
not necessary. However, if only a limited amount
of in-domain data is available, efﬁcient adaptation
is critical (DT-10% & ML-10% > scr-10%). More-
* p <0.05, ** p <0.005
(a) Preference test on TV to laptop adaptation scenario
* p <0.05, ** p <0.005
(b) Preference test on laptop to TV adaptation scenario
Table 3: Pairwise preference test among four approaches in two domains.
Statistical signiﬁcance
was computed using two-tailed binomial test.
over, judges also preferred the DT trained generator (DT-10%) compared to the ML trained generator (ML-10%), especially for informativeness. In the
laptop to TV scenario, the informativeness score of
DT method (DT-10%) was considered indistinguishable when comparing to the method trained with full
training set (scrALL). The preference test results are
shown in Table 3. Again, adaptation methods (DT-
10% & ML-10%) are crucial to bridge the gap between domains when the target domain data is scarce
(DT-10% & ML-10% > scr-10%). The results also
suggest that the DT training approach (DT-10%) was
preferred compared to ML training (ML-10%), even
though the preference in this case was not statistically signiﬁcant.
Conclusion and Future Work
In this paper we have proposed a procedure for training multi-domain, RNN-based language generators,
by data counterfeiting and discriminative training.
The procedure is general and applicable to any datadriven language generator. Both corpus-based evaluation and human assessment were performed. Objective measures on corpus data have demonstrated
that by applying this procedure to adapt models between four different dialogue domains, good performance can be achieved with much less training data.
Subjective assessment by human judges conﬁrm the
effectiveness of the approach.
The proposed domain adaptation method requires
a small amount of annotated data to be collected of-
ﬂine. In our future work, we intend to focus on training the generator on the ﬂy with real user feedback
during conversation.
Acknowledgments
Tsung-Hsien Wen and David Vandyke are supported
by Toshiba Research Europe Ltd, Cambridge Research Laboratory.