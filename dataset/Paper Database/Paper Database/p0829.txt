IEEE Transadions on Power Systems, Vo1.6, No. 2, May 1991
Electric Load Forecasting Using An Artificial Neural Network
D.C. Park, M.A. El-Sharkawi, R.J. Marks 11,
L.E. Atlas and M.J. Damborg
Department of Electrical Engineering, FT-10
University of Washington
Seattle, M'A 98195
This paper presents an artificial neural network(ANN)
approach to electric load forecasting. The ANN is used
to learn the relationship among past, current and future
temperatures and loads. In order to provide the fore-
casted load, the ANN interpolates among the load and
temperature data in a training data set. The average
absolute errors of the one-hour and 24-hour ahead fore-
casts in our test on actual utility data are shown to be
1.40% and 2.06%, respectively. This compares with an
average error of 4.22% for 24hour ahead forecasts with a
currently used forecasting technique applied to the same
Keywords - Load Forecasting, Artificial Neural
1 Introduction
Various techniques for power system load forecasting have
been proposed in the last few decades. Load forecast-
ing with lead-times, from a few minutes to several days,
helps the system operator to efficiently schedule spinning
reserve allocation. In addition, load forecasting can pro-
vide information which is able to be used for possible
energy interchange with other utilities. In addition to
these economical reasons, load forecasting is also useful
for system security. If applied to the system security as-
sessment problem, it can provide valuable information to
detect many vulnerable situations in advance.
Traditional computationally economic approaches,
such as regression and interpolation, may not give suffi-
ciently accurate results. Conversely, complex algorithmic
methods with heavy computational burden can converge
slowly and may diverge in certain cases.
A number of algorithms have been suggested for the
90 SM 377-2 PWRS
A paper recommended and approved
by the IEEE Power System Engineering Committee of the
IEEE Power Engineering Society for presentation a t the
IEEE/PES 1990 Summer Meeting, Minneapolis, Minnesota,
July 15-19, 1990.
Manuscript submitted August 31,
1989; made available for printing April 24, 1990.
load forecasting problem. Previous approaches can be
generally classified into two categories in accordance with
techniques they employ. One approach treats the load
pattern as a time series signal and predicts the future load
by using various time series analysis techniques [I-71. The
second approach recognizes that the load pattern is heav-
ily dependent on weather variables, and finds a functional
relationship between the weather variables and the sys-
tem load. The future load is then predicted by inserting
the predicted weather information into the predetermined
functional relationship [8-111.
General problems with the time series approach in-
clude the inaccuracy of prediction and numerical insta-
bility. One of the reasons this method often gives inac-
curate results is. that it does not utilize weather infor-
mation. There IS a strong correlat~on between the be-
havior of power consumption and weather variables such
as temperature, humidity, wind speed, and cloud cover.
This is especially true in residential areas. The time
series approach mostly utilizes computationally cumber-
some matrix-oriented adaptive algorithms which, in cer-
tain cases, may be unstable.
Most regression approaches try to find functional re-
lationships between weather variables and current load
demands. The conventional regression approaches use
linear or piecewise-linear representations for the forecast-
ing functions. By a linear combination of these repre-
sentations, the regression approach finds the functional
relationships between selected weather variables and load
demand. Conventional techniques assume, without justi-
fication, a linear relationship. The functional relationship
between load and weather variables, however, is not sta-
tionary, but depends on spatio-temporal elements. Con-
ventional regression approach does not have the versa-
tility to address this temporal variation. It, rather, will
produce an averaged result. Therefore, an adaptable tech-
niaue is needed.
In this paper, we present an algorithm which combines
both time series and regressional approaches. Our algo-
rithm utilizes a layered perceptron artificial neural net-
work (ANN). As is the case with time series approach,
the ANN traces previous load patterns and predicts(2.e.
extrapolates) a load pattern using recent load data. Our
algorithm uses weather information for modeling. The
ANN is able to perform non-linear modeling and adap-
tation. It does not require assumption of any functional
relationship between load and weather variables in ad-
vance. We can adapt the ANN by exposing it to new
data. The ANN is also currently being investigated as a
tool in other power system problems such as security as-
sessment, harmonic load identification, alarm processing,
fault diagnosis, and topological observability [12-181.
0885-8950191/0500-0442$o1.0001991 IEEE
D.C. Park, M.A. El-Sharkawi, R.J. Marks II, L.E. Atlas & M.J. Damborg,
"Electric load forecasting using an artificial neural network", IEEE Transactions on Power Engineering, vol.6, pp.442-449 .
In the next section, we briefly review various load fore-
casting algorithms. These include both the time series
and regression approach. The generalized Delta rule used
to train the ANN is shown in Section 3. In Section 4,
we define the load forecasting problems, show the topolo-
gies of the ANN used in our simulations, and analyze the
performance in terms of errors (the differences between
actual and forecasted loads). A discussion of our results
and conclusions are presented in Section 5.
Previous Approaches
2.1 Time Series
The idea of the time series approach is based on the un-
derstanding that a load pattern is nothing more than a
time series signal with known seasonal, weekly, and daily
periodicities. These periodicities give a rough prediction
of the load at the given season, day of the week , and time
of the day. The difference between the prediction and the
actual load can be considered as a stochastic process. By
the analysis of this random signal, we may get more ac-
curate prediction. The techniques used for the analysis
of this random signal include the Kalman filtering [I],
the Box-Jenkins method , the auto-regressive mov-
ing average (ARMA) model , and spectral expansion
technique 151.
The Kalman filter approach requires estimation of a
covariance matrix. The possible high nonstationarity of
the load pattern, however, typically may not allow an
accurate estimate to be made .
The Box-Jenkins method requires the autocorrelation
function for identifying proper ARMA models. This can
be accomplished by using pattern recognition techniques.
A major obstacle here is its slow performance .
The ARMA model is used to describe the stochastic
behavior of hourly load pattern on a power system. The
ARMA model assumes the load at the hour can be esti-
mated by a linear combination of the previous few hours.
Generally, the larger the data set, the better is the result
in terms of accuracy. A longer computational time for the
parameter identification, however, is required.
The spectral expansion technique utilizes the Fourier
Series. Since load pattern can be approximately con-
sidered as a periodic signal, load pattern can be decom-
posed into a number of sinusoids with different frequen-
cies. Each sinusoid with a specific frequency represents
an orthogonal base . A linear combination of these
orthogonal basis with proper coefficients can represent
a perfectly periodic load pattern if the orthogonal ba-
sis span the whole signal space. However, load patterns
are not perfectly periodic. This technique usually em-
ploys only a small fraction of possible orthogonal basis set,
and therefore is limited to slowly varying signals. Abrupt
changes of weather cause fast variations of load pattern
which result in high frequency components in frequency
domain. Therefore, the spectral expansion technique can
not provide any accurate forecasting for the case of fast
weather change unless sufficiently large number of base
elements are used.
Generally, techniques in time series approaches work
well unless there is an abrupt change in the environmental
or sociological variables which are believed to affect load
pattern. If there is any change in those variables, the
time series technique is no longer useful. On the other
hand, these techniques use a large number of complex
relationships, require a long computational time and
result in a possible numerical instabilities.
Regression
The general procedure for the regression approach is: 1)
select the proper and/or available weather variables, 2)
assume basic functional elements, and 3) find proper co-
efficients for the linear combination of the assumed basic
functional elements.
Since temperature is the most important information
of all weather variables, it is used most commonly in the
regression approach (possibly nonlinear). However, if we
use additional variables such as humidity, wind velocity,
and cloud cover, better results should be obtained.
Most regression approaches have simply linear or piece-
wise linear functions as the basic functional elements . A widely used functional relationship between
load, L, and temperature, T, is
1, i f T 2 O
u(T) = { 0 , otherwise
and ai, Til,
Ti2, and C are constant,
and Til > Tiz for all i.
The variables (L, a;, T, Til, Ti2, and C) are temporally
varying. The time-dependency, however, is not explicitly
noted for reasons of notational compactness.
After the basic functional forms of each subclass of tem-
perature range are decided, the proper coefficients of the
functional forms are found in order to make a represen-
tative linear combination of the basic functions.
Approaches other than regression have been proposed
for finding functional coefficients:
1. Jabbour et al.[ll] used a pattern recognition tech-
nique to find the nearest neighbor for best 8 hourly
matches for a given weather pattern. The corre-
sponding linear regressiuu coefficients were used.
2. An application of the Generalized Linear Square Al-
gorithm(GLSA) was proposed by Irisarri et a1. .
The GLSA, however, is often faced with numerical
instabilities when applied to a large data base.
3. Rahman et a1. have applied an expert system ap-
proach. The expert system takes the advantages of
the expert knowledge of the operator. It makes many
subdivisions of temperature range and forms differ-
ent functional relationships according to the hour of
interest. It shows fairly accurate forecasting. As
pointed out in the discussion of [lo] by Tsoi, it is
not easy to extract a knowledge base from an expert
and can be rather difficult for the expert to articulate
their experience and knowledge.
4. Lu et al. utilize the modified Gram-Schmidt or-
thogonalization process (hfGSOP) to find an orthog-
onal basis set which spans the output signal space
formed by load information. The MGSOP requires a
predetermined cardinality of the orthogonal basis set
ANN Training
Figure 1: Structure of a Three-Layered Perceptron Type
and the threshold value of error used in adaptation
procedure. If the cardinality of the basis set is too
small or the threshold is not small enough, the accu-
racy of the approach suffers severely. On the other
hand, if the threshold is too small, numerical insta-
bility can result. The MGSOP also has an ambiguity
problem in the sequence of input vectors. Different
exposition of input vectors result in different sets of
orthogonal basis and different forecasting outputs.
3 A Layered ANN
3.1 Architecture
An ANN can be defined as a highly connected array of el-
ementary processors called neurons. A widely used model
called the multi-layered perceptron(MLP) ANN is shown
in Figure 1. The MLP type ANN consists of one input
layer, one or more hidden layers and one output layer.
Each layer employs several neurons and each neuron in
a layer is connected to the neurons in the adjacent layer
with different weights. Signals flow into the input layer,
pass through the hidden layers, and arrive at the out-
put layer. With the exception of the input layer, each
neuron receives signals from the neurons of the previous
layer linearly weighted by the interconnect values between
neurons. The neuron then produces its output signal by
passing the summed signal through a sigmoid function
A total of Q sets of training data are assumed to be
available. Inputs of {TI, z2, . . . , zQ} are imposed on the
top layer. The ANN is trained to respond to the cor-
responding target vectors, {c., &, . . . , &), on the bottom
layer. The training continues until a certain stop-criterion
is satisfied. Typically, training is halted when the aver-
age error between the desired and actual outputs of the
neural network over the Q training data sets is less than
a predetermined threshold. The training time required is
dictated by various elements including the complexity of
the problem, the number of data, the structure of net-
work, and the training parameters used.
In this paper, the generalized Delta rule (GDR) is
used to train a layered perceptron-type ANN. An output
vector is produced by presenting an input pattern to the
network. According to the difference between the pro-
duced and target outputs, the network's weights {Wij)
are adjusted to reduce the output error. The error at the
output layer propagates backward to the hidden layer,
until it reaches the input layer. Because of backward
propagation of error, the GDR is also called error back
propagation algorithm.
The output from neuron i, Oi, is connected to the in-
put of neuron j through the interconnection weight Wij.
Unless neuron k is one of the input neurons, the state of
the neuron t is:
where f (2) = l / ( l + e-"), and the sum is over all neurons
in the adjacent layer. Let the target state of the output
neuron be t. Thus, the error at the output neuron can be
defined as
where neuron k is the output neuron.
The gradient descent algorithm adapts the weights ac-
cording to the gradient error, i.e.,
Specifically, we define the error signal as
With some manipulation, we can get the following GDR:
where 6 is an adaptation gain. 6j is computed based on
whether or not neuron j is in the output layer. If neuron
j is one of the output neurons,
If neuron j is not in the output layer,
In order to improve the convergence characteristics, we
can introduce a momentum term with momentum gain cu
to Equation 7.
where n represents the iteration indl .
Once the neural network is trail11
I I produces very
fast output for a given input data.
1 1 only requires a
few multiplications, additions, and calculations of sigmoid
function .
Table 1: Test Data Sets
Test Cases and Results
Hourly temperature and load data for Seattle/Tacoma
area in the interval of Nov. 1, 1988 - Jan. 30, 1989 were
collected by the Puget Sound Power and Light Company.
We used this data to train the ANN and test its perfor-
mance. Our focus is on a normal weekday (i.e. no holiday
or weekends).
Table 1 shows five sets used to test the neural network.
Each set contains 6 normal days. These test data were not
used in the training process of the neural network. This
approach of classifier evaluation is known as a jack-knife
The ANN was trained to recognize the following cases:
Case 1: Peak load of the day
Case 2: Total load of the day
Case 3: Hourly load
Peak load at day d = max (L(1, d), . . . , L(24, d))
Total load at day d =
L(h, d) is the load at hour h on day d.
The neural network structures used in this paper, in-
cluding the size of the hidden layer, were chosen from
among several structures. The chosen structure is the
one that gave the best network performance in terms of
accuracy. In most cases, we found that adding one or
two hidden neurons did not significantly effect the neural
network accuracy.
To evaluate the resulting ANN'S performance, the fol-
lowing percentage error measure is used throughout this
I actual load - forecasted load (
actual load
The topology of the ANN for the peak load forecasting is
as follows;
Input neurons:
Tl(k), T2(k), and T3(k)
Hidden neurons: 5 h~dden neurons
Out,put neuron : L(k)
k = day of predicted load,
L(k) = peak load at day k,
= average temperature at day k,
= peak temperature at day k,
= lowest temperature at day k.
Table 2: Error(%) of Peak Load Forecasting
Table 3: Error(%) of Total Load Forecasting
Table 2 shows the error(%) of each day in the test sets.
The average error for all 5 sets is 2.04 %.
The topology of the ANN for the total load forecasting is
as follows;
Input neurons:
Tl(k), T2(k), and T3(k)
Hidden neurons: 5 hidden neurons
Output neuron : L(k)
k = day of predicted load,
L(k) = total load at day k,
= average temperature at day k,
= peak temperature at day k,
= lowest temperature at day k.
Table 3 shows the error(%) of each day in test sets. The
average error for all 5 sets is 1.68 %.
4.3 Case 3
The topology of the ANN for the hourly load forecasting
with one hour of lead time is as follows;
Input neurons:
k, L(k-2), L(k-1),
T(k-2 , T(k-1), and ?(k)
Hidden neurons:
10 hi den neurons
Output neuron : L(k) d
k = hour of predicted load
L(x) = load at hour x,
T(x) = temperature at hour x,
T(x) = predicted temp. for hour x
In training stage, T(x) was used instead of Ti'(x). The
lead times of predicted temperatures, T(x), vary from 16
to 40 hours.
Table 4 shows the error(%) of each day in the test sets.
The average error for all 5 sets is found to be 1.40 %.
Note that each day's result is averaged over a 24 hour
Table 4: Error(%) of Hourly Load Forecasting
with One Hour Lead Time
(*: Predicted temperatures, ;i', are not available.)
In order to find the effect of the lead time on the. ANN
load forecastmg, we used set 2 whose performance in Ta-
ble 4 was the closest to the average. The lead time was
varied from 1 to 24 hours with a 3 hour interval. The
topology of ANN was as follows:
input neurons :
k, L(24,k), T(24,k),
L m,k), T(m,k), and T(k)
hidden neurons : 1 (h idden neuron
ouput neuron :
k = hour of predicted load
m = lead time,
L(x,k) = load x hours before hour k
T(x,k) = temperature x hours before hour k
T(k) = predicted temperature for hour k
In the training stage, T(x) was used instead of F(x). The
lead times of predicted temperatures, ?(x), vary from 16
to 40 hours.
Figure 2 shows examples of the hourly actual and fore-
casted loads with one-hour and 24-hour lead times. Fig-
ure 3 shows the average errors (%) of the forecasted loads
with different lead hours for test set 2.
From Figure 3, the error gradually increases as the lead
hour grows. This is true up to 18 hours of lead time. One
of the reasons for this error pattern is the periodicity of
temperature and load pattern. Even though they are not
quite the same as those of the previous day, the temper-
ature and system load are very similar to those of the
previous day.
We compare our results with the prediction of Puget
Sound Power and Light Co. (PSPL) in Figure 4. Since
the PSPL forecasts loads with lead times of 16- to 40-
hour, there are 3 overlaps(l8-, 21-, and 24-hour) with our
results. As shown in Figure 4, the average errors for the
18-, 21- and 24-hour lead times are 2.79, 2.65, and 2.06 %,
respectively. This compares quite favorably with errors of
2.72, 6.44, and 4.22 % (18-, 21-, and 24-hour lead times)
obtained by current load forecasting technique using the
same data from PSPL . The current load forecasting
method, in addition, uses cloud cover, opaque cover, and
relative humidity information.
Conclusions
We have presented an electric load forecasting methodol-
ogy using an artificial neural network(ANN). This tech-
nique was inspired by the work of Lapedes and Farber
 . The performance of this technique is similar to the
ANN with locally tuned receptive field . We find it no-
(a) Jan. 24,1989
(b) Jan. 27,1989
Figure 2: Hourly Load Forecasting and Actual Load
(in MW) (solid: actual load, dash: 1-hour lead
forecast, dot: 24hour lead forecast)
table that Moody and Darken's technique is remarkably
similar to the estimation of Gaussian mixture models.
The results shows that the ANN is suitable to inter-
polate among the load and temperature pattern data of
training sets to provide the future load pattern. In order
to forecast the future load from the trained ANN, we need
to use the recent load and temperature data in addition
to the predicted future temperature. Compared to the
other regression methods, the ANN allows more flexible
relationships between temperature and load pattern. A
more intensive comparison can be found in .
Since the neural network simply interpolates among the
training data, it will give high error with the test data
that is not close enough to any one of the training data.
In general, the neural network requires training data
well spread in the feature space in order to provide highly
accurate results. The training times required in our ex-
periments vary, depending on the cases studied, from 3
to 7 hours of CPU time using the SUN SPARK Station
1. However, a trained ANN requires only 3 to 10 millisec-
Lead Time (Hour)
Figure 3: Mean(m) and Standard Deviation(a)
of Errors Vs. Lead Time
Lead Time (Hour)
Figure 4: Mean and Standard Deviation of Errors:
ANN Vs. Conventional Technique Used
onds for testing.
The neural network typically shows higher error in the
days when people have specific start-up activities such as
Monday (for example, on day 1 of set 1 in Table 2), or
variant activities such as during the holiday seasons (for
example, on days 4 & 5 of set 3 in Table 3). In order to
have more accurate results, we may need to have more
sophisticated topology for the neural network which can
discriminate start-up days from other days.
We utilize only temperature information among
weather variables since it is the only information avail-
able to us. Use of additional weather variables such as
cloud coverage and wind speed should yield even better
6 Acknowledgments
This work was supported by the Puget Sound Power
and Light Co., the National Science Foundation, and
the Washington Technology Center at the University of
Washington. The authors thank Mr. Milan L. Bruce of
the Puget Sound Power and Light Co. for his contribu-