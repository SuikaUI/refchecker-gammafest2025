Automatica 41 393‚Äì438
www.elsevier.com/locate/automatica
From experiment design to closed-loop control
HÀöakan Hjalmarsson‚àó
Department of Signals, Sensors and Systems, Royal Institute of Technology, S-100 44 Stockholm, Sweden
Received 9 February 2004; received in revised form 23 August 2004; accepted 15 November 2004
Available online 24 January 2005
The links between identiÔ¨Åcation and control are examined. The main trends in this research area are summarized, with particular focus
on the design of low complexity controllers from a statistical perspective. It is argued that a guiding principle should be to model as well
as possible before any model or controller simpliÔ¨Åcations are made as this ensures the best statistical accuracy. This does not necessarily
mean that a full-order model always is necessary as well designed experiments allow for restricted complexity models to be near-optimal.
Experiment design can therefore be seen as the key to successful applications. For this reason, particular attention is given to the interaction
between experimental constraints and performance speciÔ¨Åcations.
 2005 Elsevier Ltd. All rights reserved.
Keywords: IdentiÔ¨Åcation for control; Statistical analysis; Experiment design; Model validation
1. Introduction
Ever increasing productivity demands and environmental
standards necessitate more and more advanced control methods to be employed in industry. However, such methods usually require a model of the process and modeling and system
identiÔ¨Åcation are expensive. Quoting :
‚ÄúIt is also widely recognized, however, that obtaining the
process model is the single most time consuming task in the
application of model-based control.‚Äù
In Hussain it is reported that three quarters of the
total costs associated with advanced control projects can
be attributed to modeling. It is estimated that models exist
for far less than one percent of all processes in regulatory
control. According to Desborough and Miller , one of
the few instances when the cost of dynamic modeling can
 This paper was not presented at the 13th IFAC symposium on system
identiÔ¨Åcation, SYSID-2003, Rotterdam, NL. This paper was recommended
for publication in the revised form by Guest Editors Torsten S√∂derstr√∂m,
Paul van den Hof, Bo Wahlberg and Siep Weiland.
‚àóTel.: +46 8 7908464; fax +46 8 7907329.
E-mail address: (H. Hjalmarsson).
0005-1098/$ - see front matter  2005 Elsevier Ltd. All rights reserved.
doi:10.1016/j.automatica.2004.11.021
be justiÔ¨Åed is for the commissioning of model predictive
controllers.
It has also been recognized that models for control pose
special considerations. Again quoting :
‚ÄúThere is abundant evidence in industrial practice that
when modeling for control is not based on criteria related
to the actual end use, the results can sometimes be quite
disappointing.‚Äù
Hence, efÔ¨Åcient modeling and system identiÔ¨Åcation techniques suited for industrial use and tailored for control design applications have become important enablers for industrial advances. The Panel for Future Directions in Control,
 , has identiÔ¨Åed automatic synthesis of control algorithms, with integrated validation and veriÔ¨Åcation as one of the major future
challenges in control. Quoting :
‚ÄúResearchers need to develop much more powerful design
tools that automate the entire control design process from
model development to hardware-in-the-loop simulation.‚Äù
Spurred by the recognized problems, identiÔ¨Åcation for
control has been one of the most active areas in system identiÔ¨Åcation over the last decade. Since the joint identiÔ¨Åcation
and control problem shares the same elements as any engineering application where system identiÔ¨Åcation is involved,
H. Hjalmarsson / Automatica 41 393‚Äì438
much work under the ‚Äúumbrella‚Äù of identiÔ¨Åcation for control
has general applicability and it seems fair to say that no
other area of identiÔ¨Åcation has contributed as much to the
basic understanding of system identiÔ¨Åcation during the last
So what are the issues? Well, to get a Ô¨Årst hint consider
the following (oversimpliÔ¨Åed) problem a control engineer
might be faced with:
We have this prior knowledge of the process. You are allowed to perform a closed-loop identiÔ¨Åcation experiment
with the existing controller in the loop. The experiment
should be as short as possible and should disrupt the process minimally. We think we would like the rise-time and
settling-time to be this and that, but we are not really sure.
Of course, the resulting closed-loop should be stable. If you
want to use anything other than a PID-controller, you need
to make a very strong case for why this is necessary.
Clearly, a useful theory should be capable of handling this
type of questions. Below we will try to delineate the main
issues involved.
1.1. The unforgiving nature of feedback
In many applications, performance degrades gracefully
as the accuracy of the model becomes worse. However, in
feedback control instability may lead to disastrous consequences. By the end of the 1980s this issue prompted signiÔ¨Åcant efforts to develop identiÔ¨Åcation frameworks which
can accommodate for various types of prior information and
produce model sets to which the true system is guaranteed
to belong so that it can be checked that a designed (robust)
controller at least stabilizes the system. While there is still
a debate on which assumptions are relevant, this line of research has deÔ¨Ånitely put a Ô¨Ånger on the approximate nature
of system identiÔ¨Åcation.
1.2. The forgiving nature of feedback
There are numerous existing successful applications of
PID-control to non-linear processes which are based on simple, e.g. Ô¨Årst-order, models identiÔ¨Åed from step response
tests. Hence, it is clear that simple, very crude, models often
sufÔ¨Åce to give good or, perhaps more accurately, acceptable
closed-loop performance. Behind this is the rationale for
feedback control: High loop gain in a frequency band makes
the closed loop system insensitive to the quality of the model
and the properties of the open loop system in this frequency
band, provided stability can be maintained; cf. having an integrator in the controller which gives unity steady-state gain
regardless of the open loop steady-state gain.
This observation translates into the fact that one would
want the model set produced by system identiÔ¨Åcation to be
shaped such that high performance can be obtained and also
such that, if desired, additional robustness may be included
with little penalty on performance. This issue relates directly
to the design of the identiÔ¨Åcation experiment. Clearly, if the
experiment ensures that all features of the system relevant
for control design are present in the data, this objective can
be achieved. Another characteristic feature of the control
application is that it may not a priori be known in which
frequency range an accurate model is required since this
depends on performance limitations of the system, some of
which typically are unknown a priori.
1.3. Compatibility requirements
The uncertainty description obtained from system identiÔ¨Åcation is dictated by the model structure and the prior
information used; see Section 2. It may not be directly applicable to a particular control design method. For example,
prediction error methods deliver an ellipsoid in the parameter space whereas robust H‚àûdesign with unstructured
uncertainty assumes frequency by frequency bounds on the
uncertainty. Thus, it may be necessary to outer-bound the
uncertainty description and this should be done so as to not
introduce unnecessary conservatism. Another aspect of this
issue is that the order of a robust controller usually depends
not only on the order of the nominal model but also on the
orders of the weighting Ô¨Ålters describing bounds on model
uncertainty and performance speciÔ¨Åcations. Hence, the uncertainty description may also inÔ¨Çuence the order of the controller.
1.4. Summary
The discussion above can be condensed as follows. The
user has a number of design variables such as experimental
conditions, model structure and the performance speciÔ¨Åcations available. To be able to select these in a systematic way
such that stability and performance are guaranteed involves:
‚Ä¢ ensuring that the ‚Äòtrue‚Äô system is accounted for in the set
of delivered models.
‚Ä¢ understanding which properties of the system have to be
modeled accurately and which can be treated only super-
Ô¨Åcially and how this relates to the performance speciÔ¨Åcations.
‚Ä¢ designing experiments that reveal this information.
‚Ä¢ representing this information mathematically in a way that
is not overly complex.
‚Ä¢ adjusting the performance demands such that the design
becomes robust given the limitations in modeling accuracy.
The Ô¨Årst issue is rather delicate as it involves entities that
are not veriÔ¨Åable, and has quite naturally led to different
approaches.
H. Hjalmarsson / Automatica 41 393‚Äì438
1.5. Outline
We will begin this paper with a part (Sections 2‚Äì6) on general modeling principles, with particular attention to issues
that are of importance for control applications. Modeling
frameworks are discussed in Section 2, where we highlight
the similarity of algorithms ensuing from deterministic and
stochastic approaches. We also elaborate on the importance
of noise prior information. Many considerations in control
are best handled in the frequency domain and in Section 3
we take a closer look at model uncertainty in the frequency
domain. As discussed above, control applications often allow only very approximate models to be used. We therefore,
in Section 4, discuss how to identify restricted complexity
models without compromising statistical accuracy. Stability
and performance guarantees require the true system to be accounted for in the model set delivered by the system identi-
Ô¨Åcation. This relates to model validation which is discussed
in Section 5. In Section 6 our observations are summarized.
The remaining part of the paper is directly concerned with
control related issues. Robust control and its links to system
identiÔ¨Åcation are issues discussed in Section 7. The problem
of directly identifying a restricted complexity model useful
for control design is covered in Section 8. This is followed
by a section on how to model non-linear systems using linear
time-invariant (LTI) models. Model free tuning methods are
discussed in Section 10 while Section 11 covers experiment
design issues. Model validation for control is the theme in
Section 12. The paper concludes with some comments.
We will restrict attention to time-domain identiÔ¨Åcation,
with particular focus on the prediction error method. For
frequency domain methods, the reader is referred to Pintelon
and Schoukens , McKelvey for general treatise
of the subject, and to Chen and Gu and references
therein for more control oriented deterministic approaches.
2. Information content in the data
The question of what information the noisy measurement
data contains regarding the system dynamics is really at
the core of system identiÔ¨Åcation. One can view one part of
system identiÔ¨Åcation as the problem of cleaning up the data
with respect to noise as well as possible. In this section we
will discuss the limitations of what can be achieved in this
2.1. Mathematical models
We will denote the input and output of a dynamical system
by u(t) and y(t), respectively. For a signal x(t), t =1, 2, . . .,
we will use the shorthand notation xN for {x(t)}N
will often omit the time-argument from signals for ease of
exposition. The observed output/input signal sequence that
is available for the system identiÔ¨Åcation will be denoted
ZN = {y(t), u(t)}N
Generally, a model for such a dynamical system will denote a sequence of mappings ft, t = 1, 2, . . . such that
y(t)=ft(ut, et) is the model response to the input sequence
u(t), t = 1, 2, . . . and the unmeasurable signal sequence
(‚Äúnoise‚Äù) e(t), t = 1, 2, . . ..
A model is consistent with the observations ZN if there
exists a noise sequence eN such that y(t) = ft(ut, et), t =
1, . . . , N holds for ZN.
2.2. The concept of unfalsiÔ¨Åcation
That a scientiÔ¨Åc theory may be falsiÔ¨Åed by contradicting evidence but never validated by corroborating evidence
was elaborated on by the philosopher Karl Popper . In system identiÔ¨Åcation, it is clear that none of the
models that are consistent with ZN can be discarded unless
some prior information is available. We call the set of all
such consistent models the set of unprejudiced unfalsiÔ¨Åed
models, which we denote by G(ZN). This set represents the
remaining uncertainty of the system dynamics given the observed data ZN. The information contents in the observed
data corresponds exactly to the set of models that are falsi-
Ô¨Åed by the observed data. The more ‚Äúinformative‚Äù data is,
the larger is the set of candidate models that can be falsi-
Ô¨Åed. The set G(ZN) is of course an enormous set since it
includes all inÔ¨Ånite dimensional non-linear models which
are consistent with the observations. Hence, it may appear
that measurement data provides very little information.
2.3. Introducing priors
The only possible way to reduce the size of the set of
unprejudiced unfalsiÔ¨Åed models is to introduce prior information, both on the system dynamics and the noise. For example, we might immediately be prepared to introduce the
prior that the system is causal. We shall denote by G(ZN)
the set of models consistent with data and the prior information, and we shall refer to this set as the set of unfalsiÔ¨Åed
A common approach is to introduce a parametrized model
structure, e.g.
y = G()u + H()e + (u),
where G and H are transfer functions parametrized by  ‚àà
 ‚äÇRn, where  is an unstructured dynamic term and
where e is a noise signal. Since e may be taken such that
any model in the above structure is unfalsiÔ¨Åed, assumptions
on the noise are also required. This issue is crucial for the
system identiÔ¨Åcation problem.
2.4. Set-membership identiÔ¨Åcation
The set of unfalsiÔ¨Åed models becomes manageable for the
model structure (1) by imposing that  ‚ààS and eN ‚ààSe
for some suitably chosen sets S and Se. Common choices
H. Hjalmarsson / Automatica 41 393‚Äì438
for Se are
Se = {eN : |e(t)|‚©Ωc, t = 1, . . . , N},
We refer to Bai, Nagpal, and Tempo for an analysis
of how these and other types of noise bounds affect the size
of the set of unfalsiÔ¨Åed models.
The unstructured uncertainty  is often taken as LTI and
examples of S are
S = { : ‚à•‚à•‚àû‚©Ω},
(k)q‚àík : |(k)|‚©ΩCk
Above ‚à•¬∑ ‚à•‚àûdenotes the H‚àû-norm, q‚àí1 is the backward
shift operator and 0 <  < 1. IdentiÔ¨Åcation methods that employ this type of constraints have become known as setmembership methods and this has been a very active area of
research during the past two decades. The set of unfalsiÔ¨Åed
models often becomes very complicated and one important
research topic has been to Ô¨Ånd simpliÔ¨Åed characterizations
using outer- and inner-bounding techniques . We refer to Milanese and Milanese, Norton, Piet-Lahanier, and Walter and references therein
for further details on set-membership identiÔ¨Åcation.
2.5. Uncertainty model unfalsiÔ¨Åcation
The combination (3) and (4) together with the model structure
y = G()u + H()(e + u)
has been studied by Kosut and co-workers in a series of papers under the label uncertainty model unfalsiÔ¨Åcation. Based
on results in Poolla, Khargonekar, Tikku, Krause, and Nagpal , it is shown in Kosut and Kosut 
that the set of unfalsiÔ¨Åed models is empty if and only if
there are no  ‚àà and eN ‚ààSe that satisÔ¨Åes a certain matrix inequality. For ARX-models, this is a convex feasibility
problem in the unknowns  and eN.
As pointed out in Kosut , one may compute cmin(),
the smallest c (recall that c deÔ¨Ånes the size of the noise set
Se, cf. (2) and (3)) for which there is some unfalsiÔ¨Åed model
for a given bound  on the unstructured uncertainty . The
graph  ‚Üícmin() is referred to as the uncertainty tradeoff curve and gives a hint on how dynamic versus noise
uncertainty may be traded-off for a set of unfalsiÔ¨Åed models.
2.6. A likelihood approach to unfalsiÔ¨Åcation
One way to treat the noise is to introduce a probability
measure, i.e. a measure of how likely different noise sequences are. Equipped with this measure, we can in principle order all models we can imagine according to how likely
the corresponding noise sequences are. The model corresponding to the most likely noise sequence is the maximum
likelihood (ML) estimate.
2.6.1. Gaussian prior
To be speciÔ¨Åc, let us assume that the noise is Gaussian
white noise with variance  and denote by e(t, M) the noise
signal that makes model M consistent with the observations. Then the negative log-likelihood for this noise signal is
2 log(2) + N
2 log() + 1
e2(t, M). (5)
It is natural to take the set of models that corresponds to
noise sequences with a likelihood higher than a given level
as the set of unfalsiÔ¨Åed models.
2.6.1.1. Case 1: Known noise variance.
When the noise
variance  is known, (5) then leads to the set
e2(t, M)‚©Ωc
for some c. Hence we see that the stochastically motivated
likelihood approach leads to set-membership identiÔ¨Åcation
with the set (3) characterizing the noise under Gaussian assumptions.
The principal difference between the likelihood approach
and a deterministic set-membership approach lies in how c is
chosen. In the likelihood approach one could argue that the
constant c should be selected such that there is only a small
probability that the true system is (erroneously) falsiÔ¨Åed.
To this end, consider that e(t, M) really is Gaussian white
noise with variance , i.e. M is a model that satisÔ¨Åes our
assumptions and should rather not be falsiÔ¨Åed. Then we have
e2(t, M) ‚àº2(N).
By taking c =
22 (N), where 2 (N) is deÔ¨Åned by
P(X‚©Ω2 (N)) = for a 2(N) distributed random variable
X, in (6) the probability of falsifying this model will be
1 ‚àí (e.g. 0.1%).
In practice it is, of course, computationally infeasible to
order all models and some parametrization has to be introduced. In order to focus on the noise issues, we will in the
remaining part of Section 2.6 restrict attention to the following simple model
T(t) + e(t)
where e denotes the noise, where
is a vector of deterministic quantities and where  ‚ààRn is a vector of unknown
model parameters. We will comment brieÔ¨Çy on the case
where unstructured uncertainty is present in Section 2.6.1.4.
H. Hjalmarsson / Automatica 41 393‚Äì438
For (7) we have that
e(t, ) = y(t) ‚àí
is the noise for the model corresponding to parameter vector
. By completing the square, cf. Ljung and Hjalmarsson
e2(t, ) =
e2(t, ÀÜN) + ( ‚àíÀÜN)TRN( ‚àíÀÜN), (9)
where RN and the maximum likelihood estimate ÀÜN (which
in this case corresponds to the least-squares estimate) are
Hence, the set of unfalsiÔ¨Åed models is given by
e2(t, ÀÜN)
+( ‚àíÀÜN)T RN
 ( ‚àíÀÜN)‚©Ω2
The threshold 2 (N) in (11) is data-independent. It is, in
general, possible to obtain a tighter set by letting the threshold be data-dependent. Consider again (9), given the observations, the Ô¨Årst term of the right-hand side is completely
known whereas the second term is known to be 2(n) distributed when  is the true parameter vector. Hence, the set
e2(t, )‚©Ω1
e2(t, ÀÜN) + 2
 : ( ‚àíÀÜN)T RN
 ( ‚àíÀÜN)‚©Ω2
is the set of models having the largest likelihoods and being such that the posterior (to the observation of the data)
probability that the true system is outside this set is 1 ‚àí .
2.6.1.2. Case 2: Unknown noise variance.
When  is unknown it can be included as an unknown parameter in the
model, and, hence, the set of unfalsiÔ¨Åed models consists of
pairs (, ). Now, however, the choice of the threshold for
the likelihood function deÔ¨Åned by (5) becomes somewhat
problematic. It is not possible to a priori set the threshold
so that the true parameters (, ) belong to the set of unfalsiÔ¨Åed models with a pre-speciÔ¨Åed probability, as could
be done when the noise variance was known. However,
given that  is the parameter of interest, one can set the
threshold such that the probability that the true  together
with some  is in the set of unfalsiÔ¨Åed models with a prespeciÔ¨Åed probability. The argument is as follows. Let  be
arbitrary. The parameter  that minimizes VN(M) given 
is given by
2 log(2) + N
This implies that the parameters  that will belong to the set
of unfalsiÔ¨Åed models, i.e. the set of unfalsiÔ¨Åed parameters
, is given by
e2(t, )‚©Ωc
To ensure that the true  (if there is such a parameter) is in
this set with probability , the constant c should be taken as
N ‚àín F (n, N ‚àín) + 1
e2(t, ÀÜN),
where the constant F (n, N‚àín) is deÔ¨Åned by P(X‚©ΩF (n, N‚àí
n)) = where X is F(n, N ‚àín) distributed. This gives that
(13) can be written as
n ( ‚àíÀÜN)T
1/(N ‚àín) N
t=1 e2(t, ÀÜN)
√ó ( ‚àíÀÜN)‚©ΩF (n, N ‚àín)
This follows by way of (9). Now,
n ( ‚àíÀÜN)T
t=1 e2(t, ÀÜN)
is F(n, N ‚àín) distributed when  is the true parameter vector. Thus, the set in (14) contains the true  with probability
as desired if there is such a ‚Äútrue‚Äù parameter.
2.6.1.3. Relation to the prediction error method.
(14) corresponds exactly to a conÔ¨Ådence region for the true
parameter when the least-squares estimate for the model (7)
is used . The probability that the true parameter is outside this set is 1 ‚àí . Hence, we can interpret least-squares identiÔ¨Åcation of linear regression models
under Gaussian assumptions as a likelihood-based unfalsiÔ¨Åcation method. Since the least-squares estimate is identical
to the maximum-likelihood (ML) estimate under these assumptions, the conÔ¨Ådence region is also the smallest possible. That there is a close connection to the ML-method is of
course natural as the likelihood approach to model unfalsi-
Ô¨Åcation is based on the likelihood function.
For model structures beyond the linear regression type,
the equivalence between likelihood-based unfalsiÔ¨Åcation and
H. Hjalmarsson / Automatica 41 393‚Äì438
the conÔ¨Ådence region for the prediction error method (PEM)
and the ML-method can be shown to hold asymptotically.
For brevity, we discuss this for the case when  is unknown
Consider the LTI model structure
y(t) = G(q, )u(t) + H(q, )e(t),
where H is monic, stable and minimum phase, which is
parametrized in terms of  ‚àà ‚äÇRn. The signal e represents noise. The noise given that the parameter vector is 
is given by
e(t, ) = H ‚àí1(q, )(y(t) ‚àíG(q, )u(t)).
This quantity is also known as the prediction error since it is the error in the one-step ahead predictor of
the output when the model corresponding to the parameter
vector  is used.
The prediction error estimate with quadratic criterion is
ÀÜN = arg min
Neglecting transients, this is also the maximum-likelihood
estimate when the distribution is Gaussian and hence it minimizes the negative log-likelihood (5) within the model structure.
Under weak assumptions , it holds that
ÀÜN = ‚àó‚âúarg min
N‚Üí‚àûE{JN()} w.p.1.
It holds also that the prediction error estimate ÀÜN converges
in law to a normally distributed random variable
N(ÀÜN ‚àí‚àó) D
for some covariance matrix P.
Suppose now that the true system is in the model set
(notice that this is an assumption that we have so far not
used in Section 2), i.e.
y(t) = G(q, ‚ó¶)u(t) + H(q, ‚ó¶)e‚ó¶(t),
where e‚ó¶is (a realization of) white noise, for some ‚ó¶‚àà
. Then ‚àó= ‚ó¶ ) and the expression for the covariance matrix
P is given by
P = R‚àí1, where R = E{
T(t, ‚àó)},
(t, ) = ‚àíde(t, )/d.
RN = N ¬∑ R = N ¬∑ E{
T(t, ‚àó)},
it follows from (18) that as N ‚Üí‚àû,
t=1 e2(t, ÀÜN)
(‚ó¶‚àíÀÜN) D
‚àí‚Üí2(n) (22)
and, hence,
 : ( ‚àíÀÜN)T
t=1 e2(t, ÀÜN)
is a conÔ¨Ådence region which asymptotically includes the true
parameter ‚ó¶with probability .
Let us now characterize the set of unfalsiÔ¨Åed models in
the likelihood-based approach given that (19) holds. This is
in general a difÔ¨Åcult task, due to that  appears non-linearly
in the prediction error. However, for small enough bound c,
all models in this set will have to have parameters  close to
the prediction error estimate ÀÜN. In this situation, a second
order Taylor expansion gives
e2(t, ) ‚âà
e2(t, ÀÜN) + ( ‚àíÀÜN)TRN( ‚àíÀÜN)
where RN is given by (21). Compare this with (9). From (22)
we have that, suitably normalized, the second term of the
right-hand side of (24) is approximately 2(n) distributed for
large N. Using these observations, we can now proceed as in
Section 2.6.1.2 to obtain that the set of models corresponding
to the most likely noise sequences and which is large enough
that the probability that the true system belongs to the set is
, can be described approximately by set (23).
For a recent study on conditions for the asymptotic prediction errror theory to be valid, see Bittanti, Campi, and
Garatti . For recent results on Ô¨Ånite sample properties we refer to Weyer and Campi , Campi and Weyer
 . Similar conclusions can also be made when the noise
is not Gaussian but we will not pursue this topic further.
2.6.1.4. Case 3: Unstructured uncertainty present.
model structures of type (1) one can also pursue a likelihood
approach. The set of unfalsiÔ¨Åed models will correspond to a
set of parametric uncertainty, cf. (23), together with the unstructured uncertainty. However, the parametric uncertainty
set will be larger compared to (23) since it corresponds
to all parameters for which there exists a  ‚ààS such
that the likelihood of the corresponding noise sequence is
acceptable.
2.6.2. Uniform prior
The assumption that the noise distribution has support
[‚àíc, c] leads to a set of unfalsiÔ¨Åed models of the type (2)
 . In this set, all models are
equally likely.
The model set is in this case a polyhedron which can be
approximated by an ellipsoid, i.e. with a set of the type (23).
The problem of determining the outerbounding ellipsoid of
H. Hjalmarsson / Automatica 41 393‚Äì438
minimal volume is a convex optimization problem .
2.7. Stochastic embedding
Just as e may be modeled in a stochastic framework, the
unstructured uncertainty  in the model structure (1) may
be modeled in a stochastic framework. This leads to what
is known as the stochastic embedding approach . Notice,
that for a given model structure there may be no model at
all that belongs to this set‚Äîa very powerful result! Poor
models will thus be rejected. Unfortunately, overly complex
models will not be falsiÔ¨Åed and thus overmodelling can be
a problem. One possibility of dealing with this problem is
to use Occam‚Äôs razor:
Pick a model with as low complexity as possible in the
set of unfalsiÔ¨Åed models.
There is often no reason to favor any other model. In
Section 8.11, however, we will see that there may be reasons
for other choices.
In Section 2.6.1.1 we also observed that we could shrink
the size of the set by looking at the data before the threshold was selected. This resulted in the set (12). Notice that
for any given model structure, the set of unfalsiÔ¨Åed models will now be non-empty. By making the threshold data
dependent we have gained in accuracy but the price paid is
that the objectivity of the criterion used in (11) has been
lost. When the noise variance is unknown, there is no objective criterion. As for (12), the set of unfalsiÔ¨Åed models (14)
will be prejudiced on the model structure. Different model
structures now have to be compared against each other in
order to Ô¨Ånd the ‚Äúright‚Äù structure. This leads us to model
validation which we will discuss in Section 5.
To conclude, we have argued that knowledge of the noise
characteristics is extremely valuable. As pointed out, e.g. in
Pintelon and Schoukens and Ljung , the noise
sequence itself can be estimated if periodic inputs are used,
cf. the case when the input is zero, then the output equals
the noise.
2.9. Summary
In this section, we have presented identiÔ¨Åcation as a way
of producing sets of unfalsiÔ¨Åed models and illustrated that
both deterministic and stochastic modeling paradigms Ô¨Åt into
this framework. Interestingly, it seems as if many of these
different approaches result in similar unfalsiÔ¨Åed model sets,
see Reinelt, Garulli, and Ljung .
For stochastic models, we discussed the use of the likelihood function as a criterion for ordering models. This lead
to the deÔ¨Ånition of the set of unfalsiÔ¨Åed models as the set of
models for which the likelihood function is above a certain
threshold. The threshold was determined so that the probability that the true system is outside this set, i.e. is falsiÔ¨Åed,
is smaller than some given (small) number. It was shown that
this set is equivalent to a standard conÔ¨Ådence region for the
prediction error method. The likelihood-based approach to
obtain a set of unfalsiÔ¨Åed models is thus just another way of
viewing the prediction error method. However, an important
insight is that all models in a set of unfalsiÔ¨Åed models have
one thing in common: they all have the likelihood function
larger than a certain threshold. As we will see in Section 4.4,
this observation will be instrumental when discussing statistically accurate models of restricted complexity, i.e. models
having lower order than the true system.
We noted in Section 2.8 that it is difÔ¨Åcult to quantify the
information contents in data when the model structure is
uncertain. However, one recurring theme in this paper will
be that it is possible to ensure that the information required
for our particular application can be made available by
proper experiment design.
There is an on-going healthy cross-fertilization of ideas
between deterministic and stochastic approaches, see e.g.
Ljung and Hjalmarsson , Tj√§rnstr√∂m and Garulli
 , Partington and M√§kil√§ , Hakvoort, Schrama,
and Van den Hof , de Vries and Van den Hof ,
Milanese and Taragna , Tempo, Bai, and Dabbene
 , Bai, Ye, and Tempo . For excellent overviews
of different modeling frameworks we refer to M√§kil√§, Partington, and Gustafsson and Ninness and Goodwin
3. Frequency domain characterization of the set of
unfalsiÔ¨Åed models
In the previous section the discussion was concerned with
the characterization of the set of unfalsiÔ¨Åed models in the
parameter space. However, as we will see in Section 7, when
the model set is to be used for control design it is of interest
to characterize the model set in the frequency domain. We
will in this section focus on the prediction error method.
We will assume that the true system is given by
y(t) = G‚ó¶(q)u(t) + H‚ó¶(q)e‚ó¶(t),
where e‚ó¶is white noise with variance 0 and where H‚ó¶is
stable, monic and minimum phase. We will denote the power
spectral densities of u and H‚ó¶e‚ó¶by
v, respectively.
The model structure is given by (15) with  ‚ààRn.
3.1. The bias error
For the PEM using the LTI model structure (15), the limit
estimate (17) can be characterized indirectly in the frequency
domain using Parseval‚Äôs formula. When the true system,
H. Hjalmarsson / Automatica 41 393‚Äì438
given by (25), is stable and operating in open loop, and when
G and H are independently parametrized, i.e.  = [
and G = G(
); H = H(), the limit estimate is deÔ¨Åned by
‚àó= arg min
|G‚ó¶(ej) ‚àíG(ej,
|H(ej, ‚àó)|2 d
where ‚àóis the limit estimate of . The limit estimate G(
thus minimizes a weighted H2-norm of the error between
the model and the true dynamics. It is thus in general not
possible to guarantee frequency wise error bounds on the
bias error. This may be critical in some applications such as
control design. We shall pursue this issue in Section 4.4.
When (25) holds and the system is operating in closedloop with a stabilizing controller C and an external excitation
r(t) (the reference signal) such that the input signal is given
u(t) = C(q)(r(t) ‚àíy(t))
it holds that ‚àó= arg min
|G‚ó¶(ej) ‚àíG(ej, )|2|CS(G‚ó¶, C)|2
+ |S(G‚ó¶, C)|2
|S(G(), C)|2
|H(ej, )|2 d,
where S(G, C) = 1/(1 + GC). An alternative expression
which characterizes the bias introduced by an erroneous
noise model can be found in Forssell and Ljung .
3.2. Variance of frequency function estimates
A simple characterization of the uncertainty in the frequency domain is in terms of the variance of the frequency
function estimate ÀÜGN(ej)‚âúG(ej, ÀÜN):
Var( ÀÜGN(ej))‚âúE[|G(ej, ÀÜN) ‚àíE[G(ej, ÀÜN)]|2].
Introducing
n,N() = Var( ÀÜGN(ej)) N ¬∑
where we for ease of notation have chosen to indicate only
the dependence of  on n and N explicitly, one can write
Var( ÀÜGN(ej)) = n,N()
whenever Var( ÀÜGN(ej)) is well-deÔ¨Åned. The reason for
this factorization of Var( ÀÜGN(ej)) is that under certain assumptions exact expressions or accurate approximations to
n,N() exists.
The key to such results is a Ô¨Årst order Taylor approximation of the variance1
N ¬∑ Var( ÀÜGN(ej)) ‚âà
dG(ej, )
P dG(ej, )
where the derivatives and P are evaluated at  = ‚àó. This
expression is exact as N ‚Üí‚àûwhen the model structure is
linearly parameterized
G(q, ) = T(q),
in which case dG/d = .
For general parametrizations some caution is necessary when using (29) as it is an approximation, see, e.g.,
Vuerinckx, Pintelon, Schoukens, and Rolain where
this is illustrated for conÔ¨Ådence bounds on estimated zeros.
In the mid-eighties, the following result was derived (presented here for the case of open loop operation) 
m Var( ÀÜGN(ej)) =
where m is the model order. Result (31) implies that
n,N() ‚âàm
for large enough model order m and number of samples N.
A complicating factor in the derivation of (31) is that for
certain model structures such as Box‚ÄìJenkins and outputerror, pole-zero cancellations occur when the model order
exceeds the underlying true system order. In order to ensure a well deÔ¨Åned limit estimate, the cost function has to
be regularized in the analysis. In Ninness and Hjalmarsson
 the effect of this regularization on the variance is
studied and it is shown that as the model order tends to in-
Ô¨Ånity, it is the regularization only that determines the variance. In fact, the result (31) holds for these types of model
structures only when the regularization term is of the form
‚à• ‚àí0‚à•2 for small  > 0. Choosing another regularization
point than the origin will result in another variance.
An approximation of n,N() with, in many cases, improved accuracy was proposed in Ninness, Hjalmarsson, and
Gustafsson . In Xie and Ljung an expression
for n()‚âúlimN‚Üí‚àûn,N() was derived for the case of
a model with Ô¨Åxed denominator and Ô¨Åxed moving average noise model excited by an auto-regressive (AR) input.
This represented a major step forward as no asymptotics
in the number of parameters (or model order) is involved,
thus avoiding the need for regularization. In Ninness and
Hjalmarsson this result was generalized and for the
Box‚ÄìJenkins case of independently parametrized dynamics
and noise models the result reads as follows.
1 x‚àódenotes the complex conjugate transpose.
H. Hjalmarsson / Automatica 41 393‚Äì438
Proposition 3.1. Suppose that the true system is operating
in open loop and given by
y(t) = B‚ó¶(q)
A‚ó¶(q) u(t) + v(t),
where v(t) = H‚ó¶(q)e0(t) for some white noise sequence
e0(t). Assume that the system is in the model set. Let
G(q, ) = q‚àíkB(q)/A(q) with mb parameters in B(q) and
ma parameters in A(q).
Under the condition that
is the stable minimum-phase spectral factor of
the input spectrum, is a polynomial in z‚àí1 of degree at most
ma + mb, it holds that
N‚Üí‚àûN ¬∑ Var( ÀÜGN(ej)) = n()
|ej ‚àík|2 ,
where k, k=1, . . . , ma +mb, are the zeros of zma+mbA‚Ä†(z).
Comparing (34) with (32) we see that the factor m (the
model order) is replaced by a frequency dependent factor
n() which is a function of the poles of A‚Ä†.
Remark 1. Notice that
‚àí n() d=ma +mb and hence
that there is a ‚Äúwater-bed effect‚Äù in that a small n in some
frequency region has to be compensated for by high n in
some other region.
Remark 2. Notice that the result holds, e.g., if the noise
model is of MA-type and the input spectrum is of AR-type
and mb is sufÔ¨Åciently large.
Remark 3. The result seems to hold approximately with
good accuracy also for cases where the system is not in a
Box‚ÄìJenkins model set but when this model structure is Ô¨Çexible enough that the bias error for both the system dynamics
and the noise spectrum is small. A‚ó¶and H‚ó¶should then be
replaced by the corresponding models in the limit N ‚Üí‚àû.
Notice that this implies a different condition on the orders
ma and mb than if the correct model structure was used.
Remark 4. The result seems to hold approximately with
good accuracy also when the input can be well approximated
by an AR-process. The spectral factor corresponding to the
approximating process should then be used instead of
in (33). Notice that this implies a different condition on the
model orders ma and mb than if an input of AR-type was
Remark 5. In closed-loop identiÔ¨Åcation, the variance of
the frequency function estimate is independent of whether
direct, indirect or joint input‚Äìoutput identiÔ¨Åcation is used
when (32) is valid .
As noted in Van den Hof , the variances for these different methods are likely to be different for Ô¨Ånite model orders. Using Proposition 3.1, it is shown in Ninness and Hjalmarsson that the accuracy of different methods may
indeed be very different. This has also been supported by
considerations in the parameter domain (Forssell & Ljung,
Remark 6. For Ô¨Ånite impulse response (FIR) models, an
exact expression for n,N() can be derived when the number of spectral lines in the input equals the model order
 .
3.3. The gain error
Assume now that the true system (25) is in the model set,
i.e. (19) holds. Assume further that the conÔ¨Ådence region for
the prediction error method is given by G(ZN) deÔ¨Åned in
(23). As we will see, for control design purposes it is often
sufÔ¨Åcient to be able to characterize the gain error
| ÀÜGN(ej) ‚àíG‚ó¶(ej)|.
In going from parametric uncertainty to frequency domain
uncertainty the following lemma, which is a special case of
Lemma 3.1 in Wahlberg and Ljung and Theorem 1
in Bombois, Anderson, and Gevers , is useful.
Lemma 3.1. For x, z ‚ààRn, 0 < Q ‚ààRn√ón, it holds
‚áí|zTx|2‚©Ωcz‚àóQz.
When the transfer function is linearly parametrized (30),
Lemma 3.1 applied to the inequality in (23) gives the following upper bound on the gain error
| ÀÜGN(ej) ‚àíG‚ó¶(ej)|2‚©Ω2
N ‚àó(ej)P(ej), ‚àÄ
which holds with probability . In view of (29), the inequality above is equivalent to
| ÀÜGN(ej) ‚àíG‚ó¶(ej)|‚â≤
2 (n) Var( ÀÜGN(ej)),
Using (28), we have the bound
| ÀÜGN(ej) ‚àíG‚ó¶(ej)|‚â≤
2 (n)n,N()
of the gain error which holds with at least √ó 100% probability. Because of its relative simplicity and the explicit appearance of interesting quantities such as input and noise
spectra in the expression, we will use (36) as the generic description of conÔ¨Ådence regions for the gain error in the frequency domain. See Bombois et al. for an insightful discussion on how conÔ¨Ådence bounds in the parameter
domain and the frequency domain relate.
H. Hjalmarsson / Automatica 41 393‚Äì438
Reduced order controller
Data + Priors
Full order model
Full order controller
Reduced order model
Fig. 1. Different possibilities of mapping data and prior information into
a controller of reduced complexity.
We remark that for linearly parameterized models, the
bound (36) is conservative, but at most a factor
tight overbound can easily be derived. For non-linearly
parametrized models, the largest bound on the gain error
can be computed exactly using LMIs , see also Jansson and Hjalmarsson 
for computation of the maximum bound over the frequency
4. A statistical view on restricted complexity modeling
Models of restricted complexity are often adequate in
many applications. In process control for example, Ô¨Årst order models with an additional dead-time are often sufÔ¨Åcient
even though the true process is much more complicated.
Such models can be obtained in (at least) two principally different ways: (1) Direct estimation of a restricted complexity
model or (2) Estimation of a full-order model followed by
model reduction. It is here of interest to know if one method
is to be preferred over the other. By full-order model we
here mean a model which is able to capture the true system
behavior. In practice full order-models do not exist and we
will spend quite some effort in this, and the next, section
discussing this.
In many applications, it is not the model itself that is of
interest but some quantity derived from the model. For various reasons, it is often desirable to limit the mathematical
complexity of this quantity. In control design, e.g., it is the
designed controller that is of interest. Fig. 1 illustrates various ways of obtaining a restricted complexity controller via
identiÔ¨Åcation. The same question as for the case of estimating restricted complexity models arises: Is one of the paths
better than the others?
In this section we will discuss these issues from a statistical perspective.
4.1. Statistical advantages of biased models
From a statistical perspective, approximate modeling is
usually motivated by examples such as the following.
Example 4.1. Consider the following high-order FIR system
ku(t ‚àík) + e‚ó¶(t),
where e‚ó¶(t) is white Gaussian noise with variance e, where
the order n is very large and where the input u is white
Gaussian noise with variance u.
Suppose that one is interested in estimating the static gain
G‚ó¶(ej0) = n
k of the system. In the ML-approach one
would then use a model structure of the same type as (37)
and estimate  = [g1, . . . , gn]T using least squares. The covariance matrix of ÀÜN is approximately e/(Nu)I, where I
denotes the identity matrix, and hence the variance of the estimated static gain ÀÜG(ej0)=n
k=1 ÀÜgk is approximately given
Since the estimate is unbiased, the mean-square error (MSE)
E[| ÀÜG(ej0)‚àíG‚ó¶(ej0)|2] will be the same as the variance error.
We see that due to the high system order n, the uncertainty
can be signiÔ¨Åcant even if the input power is large.
This observation, naturally, prompts the idea that a
(slightly) biased estimate of the transfer function may give
an estimate of the static gain which is better. For example,
using the model structure
u(t ‚àí1) + e(t),
for which the static gain estimate ÀÜG(ej0) is identical to the
estimate of
, will have a mean-square error which approximately is given by
The Ô¨Årst term is the variance of the parameter estimate
caused by the noise e. The second term is the variance of the
parameter estimate caused by the unmodeled dynamics. The
last term is the bias error due to the unmodeled dynamics.
The MSE of the static gain for this biased model is signiÔ¨Åcantly lower than for the ML estimate if only g‚ó¶
1 contributes
signiÔ¨Åcantly to the steady state gain!
The above example indicates that the ML-approach may
be unsuitable when only approximate models are required
for highly complex systems. However, the issue is a bit more
subtle than at Ô¨Årst glance.
4.2. A separation principle
Let ÀÜML be the ML-estimate of  ‚àà ‚ààRn and let
f :  ‚Üí ‚äÇRm with m‚©Ωn. It then holds that f (ÀÜML)
is the ML-estimate of f (). This is the so called invariance
principle for ML-estimation . Hence, it follows under very general conditions on f that if ÀÜML is asymptotically efÔ¨Åcient, i.e. it
is consistent and its asymptotic covariance matrix reaches
the Cram√©r‚ÄìRao lower limit , then f (ÀÜML)
H. Hjalmarsson / Automatica 41 393‚Äì438
is also asymptotically efÔ¨Åcient. In our context this provides
us with a useful principle:
The estimator of some system dependent quantity that
(i) Ô¨Årst estimates a full-order model using an asymptotically efÔ¨Åcient ML estimator, and then
(ii) uses the full-order system estimate obtained in (i), as if
it is the true system, to estimate the desired quantity
is an asymptotically efÔ¨Åcient estimator of this quantity under
general conditions.
The invariance principle can thus be seen as a separation
principle where the estimation problem is separated from
the application dependent part of the problem. We illustrate
this using Example 4.1.
Example 4.2 (Example 4.1 continued). Given the MLestimate ÀÜN = [ ÀÜg1, . . . , ÀÜgn]T of the full-order model in
Example 4.1, one may take y(t) = ÀÜg1u(t ‚àí1) as model, cf.
(38). This will result in a biased estimate of the static gain
with the MSE approximately given by
This expression is the same as the MSE (39) of the static
gain for the biased estimate in Example 4.1, except that the
middle term in (39) is missing. This term is the variance
contribution from the unmodeled dynamics. Hence, by Ô¨Årst
using a full-order model, inÔ¨Çation of the variance due to
unmodeled dynamics can be avoided.
4.3. Applications of the separation principle
There are many applications of the separation principle
presented in Section 4.2, and below some of these will be
discussed.
4.3.1. Model reduction
Suppose that it is known that the true system G‚ó¶belongs
to some model structure parametrized by  ‚àà but that
the desired quantity is a consistent estimate of the frequency
function minimizing
|G‚ó¶(ej) ‚àíG(ej,
where G(q,
) is a low order model parametrized by
the open loop bias expression (26) it is clear that one way
of doing this is to use an output error structure
y(t) = G(q,
)u(t) + e(t),
and directly estimate
. For FIR-models, it is shown in
Tj√§rnstr√∂m and Ljung that this procedure leads to a
higher variance as compared to Ô¨Årst identifying a full-order
FIR-model G(ej, ÀÜN), say, and then performing model reduction by minimizing
|G(ej, ÀÜN) ‚àíG this result is extended to the case when both the true system and the model
structure are of output error type. The results are proved by
explicitly computing, and comparing, the asymptotic covariance matrices for the two estimates.
The same results can be obtained by appealing to the
separation principle in Section 4.2. It is in fact possible to
extend the result slightly: Suppose that the true system is
not of output error type (e.g. of Box‚ÄìJenkins type). Then it
is optimal to Ô¨Årst estimate a full-order model and then to
perform the model reduction as in (42). Directly estimating
an output error model, which also in this case asymptotically
minimizes (41), can never give better statistical accuracy.
4.3.2. Simulation
In Zhu identiÔ¨Åcation for simulation is considered.
It is shown that modeling the spectrum of the noise is better
than ignoring it, even though simulation does not require a
noise model. As in Tj√§rnstr√∂m this is proved by comparing the covariance matrices of the estimated parameters.
This result also follows directly from the separation principle.
4.3.3. IdentiÔ¨Åcation for control
The separation principle is also useful in identiÔ¨Åcation for
control problems and indicates that, from an accuracy point
of view, no matter what the ultimate objective is, be it modeling to tune a simple PID-controller or modeling suitable
for high performance control, one should always Ô¨Årst try to
model as well as possible. After that, any simpliÔ¨Åcations can
be performed without jeopardizing the statistical accuracy.
Hence, returning to Fig. 1, taking the lower path should be
avoided if accuracy is a concern. We also conclude that going from a full-order model directly to a low order controller
or via a high order controller, will not signiÔ¨Åcantly affect
the statistical accuracy. However, there may be other reasons for taking one path or another. Some of the paths may,
e.g., be computationally infeasible, cf. Codrons, Bendotti,
Falinower, and Gevers . We shall return to the application of the separation principle in control applications in
Section 8.
4.3.4. Model validation
The separation principle also applies in model validation.
We shall, however, defer this discussion to Section 5.4.
4.4. Near-optimal restricted complexity models
The issue of biased modeling versus full-order modeling
has yet another twist. Let us return to Example 4.1 once
more but consider now another input signal.
H. Hjalmarsson / Automatica 41 393‚Äì438
Set of least-squares estimates
True parameters
Fig. 2. Example of uncertainty region for the least-squares estimate in
Example 4.3 when n = 2. For further explanations see text.
Example 4.3 (Example 4.1 continued). Suppose that the
allowed input power E[u2(t)] is bounded by the constant
u. Then, clearly a constant input with amplitude ‚àöu is
optimal for estimating the static gain and even though the
ML criterion for the impulse response coefÔ¨Åcients will be
singular, it is easy to show that the estimate of the static
gain will be well-deÔ¨Åned and have variance approximately
equal to e/(Nu), which is lower than, e.g., the minimal
variance (40) for a white input. But now, the same accuracy
is obtained with the simple model (38) since the unmodeled
dynamics do not inÔ¨Çuence the accuracy of the estimate of
; in fact, it is accounted for by this estimate which is now
an unbiased estimate of the static gain!
The example above suggests that a judicious choice of input may allow restricted complexity models to be optimal,
or near-optimal, see also Hildebrand and Gevers 
for further insights. So what property of the identiÔ¨Åcation
problem in Example 4.3 is it that allows the biased estimate
to be optimal? To answer that question, consider, for simplicity, the case when the number of impulse response coefÔ¨Åcients n = 2. Since the input is not persistently exciting
of sufÔ¨Åciently high order, the least-squares criterion will be
minimized by a set of parameter vectors. This set of leastsquares estimates is the solid line in Fig. 2. Also shown in
this Ô¨Ågure is a conÔ¨Ådence region for the true parameter (the
shaded region in the Ô¨Ågure) which in this case is an ellipsoid
that has degenerated into an inÔ¨Ånite strip due to the poorly
exciting input. The least squares estimate of the Ô¨Årst order
model is given by the point ÀÜ
N in the Ô¨Ågure. It lies in the set
of least-squares estimates and is thus optimal. It may seem
as a trivial observation but the conclusion is thus that if the
identiÔ¨Åcation experiment is performed such that the reduced
order estimate belongs to the set of full-order least-squares
estimates, then it will be optimal.
Fig. 3. Example of ellipsoidal uncertainty region for the least-squares
estimate in Example 4.3 when n=2. For further explanations see the text.
Suppose now instead that the input is such that there exists
a unique least-squares estimate ÀÜN. The conÔ¨Ådence region
is then an ellipsoid and let us assume that it is given by the
solid curve in Fig. 3. This region happens to contain a line
segment of the g1-axis (the thick horizontal line segment
in the Ô¨Ågure). This means that any Ô¨Årst order model with a
parameter value on this segment will be as good a candidate
as any second order model inside the conÔ¨Ådence region. It
also means that such a Ô¨Årst order model will possess all
the properties that models in this conÔ¨Ådence region have. In
particular, the distance to the true system in various metrics
can be upper bounded. For the gain error, e.g., the triangle
inequality gives
) ‚àíG‚ó¶(ej)|
) ‚àíG(ej, ÀÜN)| + |G(ej, ÀÜN) ‚àíG‚ó¶(ej)|
2 (n)n,N()
on this line segment. The second inequality follows
from (36) in Section 3.3 (see Section 3 for the notation).
This means that frequency-by-frequency error bounds can
be obtained for restricted complexity models of this type.
Compare this with the general H2-norm characterizations
(26) and (27) which do not allow such an error quantiÔ¨Åcation.
Now, the question remains as to whether it is possible to
directly identify a Ô¨Årst order model such that it lies on the
aforementioned line segment. To this end, recall the important conclusion from Section 2.6 that the ellipsoidal con-
Ô¨Ådence bound actually is a level set for the least-squares
criterion, cf. (9). Hence, suitable low order models are obtained by making the least-squares criterion small. In particular the least-squares estimate for the Ô¨Årst order model
is suitable. This estimate is marked as ÀÜ
N in Fig. 3. It
lies on the boundary of a scaled version of the conÔ¨Ådence
H. Hjalmarsson / Automatica 41 393‚Äì438
ellipsoid, centered around the full-order least-squares estimate (marked by ÀÜN in the Ô¨Ågure). It is the ellipsoid of this
type which tangents the g1-axis. In other words, this ellipsoid is the smallest level set of the least-squares criterion
which includes a point of the g1-axis. We thus conclude that
simple least-squares estimation of a Ô¨Årst order model will
in this case give us a model which is inside the conÔ¨Ådence
region for the full-order model and, hence, which is such
that, e.g., the error bound (43) applies.
The generalization to other estimation problems is
straightforward: Consider an identiÔ¨Åed full-order model
with the (approximate) conÔ¨Ådence region for the true parameter vector described by (23). If there is a point in the
conÔ¨Ådence region where some elements of  are zero, then
these parameters can be omitted in the estimation still giving an estimate which is inside the conÔ¨Ådence region of the
full-order model. We will call such models, near-optimal
reduced complexity models. The norm of the error between
this estimate and the true system parameter vector is at most
a factor 2 of the norm of the error between the full-order
estimate and the true system parameter vector, cf. (43).
Given that the full-order estimate ÀÜN is available it is easy
to test whether a reduced order estimate ÀÜ
N is near optimal
or not. Combining (23) with (24) gives that
e2(t, ÀÜN)‚©Ω2
e2(t, ÀÜN)
has to be satisÔ¨Åed for ÀÜ
N to be a near-optimal reduced complexity estimate.
It should be clear that the bias error is of the same size
as the variance error for this type of estimate. This is in line
with the conclusion in Guo and Ljung that the total
error is minimized by a model where the bias error does not
exceed the variance error.
We conclude this section with an example which illustrates that also the noise model is important for near-optimal
restricted complexity models.
Example 4.4. The true system has order 3 and is given by
0.14q‚àí1u(t)
(1 ‚àí0.8ej/6q‚àí1)(1 ‚àí0.8e‚àíj/6q‚àí1)(1 ‚àí0.45q‚àí1)
+ (1 ‚àí0.95q‚àí1)e0(t),
where the noise variance is 3. The input signal has high-pass
character with variance 1.3.
Consider Ô¨Årst the second order Box‚ÄìJenkins model structure
1 + a1q‚àí1 + a2q‚àí2 u(t) + (1 + cq‚àí1)e(t).
For N = 100 samples we have that the left-hand side of
(44) evaluates to 19.2 whereas the right-hand side bound
is 135. Hence, the estimated model should be near-optimal.
Fig. 4. Mean-square error of estimated frequency functions in Example
4.4. Solid line: Full-order Box‚ÄìJenkins model. Dashed line: Second order
Box‚ÄìJenkins model. Dotted line: Second order output‚Äìerror model.
To assess this, 100 models were estimated using different
noise realizations and the sample mean-square error for the
estimated frequency functions was computed. This error is
shown in Fig. 4 for the reduced order Box‚ÄìJenkins model
(dashed line) and for a full-order Box‚ÄìJenkins model (solid
line). Clearly, the errors for the two different model structures are of the same size.
Fig. 4 also shows the sample mean-square error for an
ensemble of output-error (OE) models
1 + a1q‚àí1 + a2q‚àí2 u(t) + e(t),
using the same noise realizations as in the Box‚ÄìJenkins case.
The sample mean-square error for the OE-models is significantly larger than for the full-order model, except at highfrequencies. The OE-model is thus far from near-optimal despite the fact that there are second-order models that can approximate the true system as well as the full-order model.2
For the OE-model, however, the left-hand side of (44) evaluates to approximately 3.3√ó104 which is signiÔ¨Åcantly higher
than the right-hand side bound of 135. Therefore the OEmodel cannot be near-optimal and it follows that it is not
possible to give any frequency-wise bounds on the error for
this model structure. The only characterization of the error
is given by the bias expression (26) which indicates that the
error should be smaller at high frequencies (as the input is
of high-pass type).
4.5. The separation principle revisited
In this section we have so far argued that one should model
as well as possible in order to reduce the impairing effect
of measurement noise. Referring to the separation principle
in Section 4.2, the full-order model can then be simpliÔ¨Åed
if required without loss of statistical accuracy.
Now, as we will argue in Section 5.2, full-order models
are esoteric quantities so that one always have to contend
2 This we know from the Box‚ÄìJenkins case which uses the same
dynamic model as the OE-model.
H. Hjalmarsson / Automatica 41 393‚Äì438
with restricted complexity models, not at least in control applications. To cope with this, we have introduced the concept
of near-optimal restricted complexity models. Such a model
is in a statistical sense almost as accurate as any identiÔ¨Åed
full-order model would be, had it been possible to use a
such a model. The complexity of such a model thus depends
on the quality of the observed data ZN: A Ô¨Årst order model
may be near-optimal if only poor information is available
whereas it may require a 50th order model when many thousands of high signal-to-noise data samples are available.
The usefulness of near-optimal restricted complexity
models lies not only in that they model the true system almost as accurately as a (thought) full-order model, but also
in that they can be used in the separation principle instead
of the unattainable full-order model! To see this, let =f ()
denote the mapping from the (thought) full-order model
to the model class of interest, let ÀÜN be the (full-order)
ML-estimate and ÀÜ
N a near-optimal restricted complexity
model. We observed in Section 4.2 that ÀÜN = f (ÀÜN) is the
ML-estimate of f (‚ó¶). Furthermore, any point within the
conÔ¨Ådence region associated with ÀÜN will have the same
statistical accuracy as ÀÜN within a factor 2. Now the conÔ¨Ådence regions for ÀÜN and ÀÜN are related simply by the mapping f (due to the construction of ÀÜN) and since ÀÜ
to the conÔ¨Ådence region associated with ÀÜN, f (ÀÜ
N)will belong to the conÔ¨Ådence region associated with f (ÀÜN). Thus,
N) will be a near optimal estimate of f (‚ó¶).
5. Model validation
We saw in Section 2.8 that when a model structure has
been selected, the set of unfalsiÔ¨Åed models G(ZN) can by
deÔ¨Ånition not be falsiÔ¨Åed by the data ZN when the noise
variance is unknown. One could say that the model builder is
trapped inside the model structure. Hence, there is a need to
‚Äúlook over the fence‚Äù to ensure that there are no other model
structures that can represent the data in a more plausible
way, or alternatively test G(ZN) on new data. This is what
model validation is about!
5.1. Model error modeling
Consider the following example.
Example 5.1. Let the residuals of a nominal model be denoted by Œµ(t) and let
(t) = [u(t ‚àí1), . . . , u(t ‚àín)]T.
Then a standard test-statistic, for testing whether the crosscorrelation between Œµ(t) and
(t) is zero, is given by
where RN is deÔ¨Åned in (10) and where ‚à•x‚à•Q‚âú
Normalized
asymptotically
F(n, N ‚àín)- distributed when Œµ is white noise, so a suitable
cross-correlation test is
N ‚©ΩnF (n, N ‚àín).
We can express N somewhat differently. Let ÀÜN be the
least-squares estimate, cf. (10), for the following FIR model
of the residuals:
T(t) + e(t).
It is easy to see that
and hence the test (45) corresponds to testing
ÀÜN ‚©ΩnF (n, N ‚àín).
Comparing with (14) (where for this example e(t, ÀÜN) =
T(t)ÀÜN), we see that this test is closely related to
testing whether the zero model  = 0 belongs to the set of
unfalsiÔ¨Åed models for the above FIR-model of the residuals under the assumption that the residuals can be modeled
by this FIR-model. The difference lies in the denominator
which is an estimate of the variance of the residuals of the
model error model. Above the estimate is conditioned on
that the true parameter in the model error model is zero
which gives the variance of the original residuals whereas
(14) uses the least-squares estimate of the model error estimate. The difference corresponds to the difference between
hypothesis testing and computing conÔ¨Ådence regions.
The above example was used in Ljung to point out
that standard model validation tests such as cross-correlation
tests between residuals and inputs can be interpreted as
Ô¨Årst modeling the residuals, with the resulting model named
model error model, and then testing whether the zero model
is included in the set of unfalsiÔ¨Åed model error models. Instead of just computing yes/no answers to tests such as (45)
it was suggested that an intuitively appealing way of presenting these tests is by plotting the Bode-diagram of the model
error model with uncertainty regions indicated. From this
insight follows also that more complex models than Ô¨Ånite
impulse response (FIR) models can be used and it is recommended that the model structure for the model error model
should be considerably richer than the nominal model. The
reader is also referred to Ljung and Guo for results
on how the model error is bounded by test statistics such
The main message in Ljung is that if the nominal
model is unfalsiÔ¨Åed, i.e. the uncertainty region for the model
error model includes the zero model, then, even though
the nominal model structure (with its own uncertainty description) is unfalsiÔ¨Åed, one should use the nominal model
structure together with the uncertainty region of the model
H. Hjalmarsson / Automatica 41 393‚Äì438
error model. Since the model structure for the model error
model is more Ô¨Çexible than the model structure for the nominal model, this will give a larger, and hence ‚Äúsafer‚Äù, set of
unfalsiÔ¨Åed models.
Notice that this conclusion is completely in line with the
discussion in Section 4.4 if we consider the nominal model
as being of restricted complexity whereas the model error
model is Ô¨Çexible enough to capture all dynamics in the residuals. Then it is the uncertainty set associated with the model
error model that is relevant.
We are here at the crux of the modeling problem‚Äîthe
model builder wants to be sure that his model set includes
the ‚Äòtrue‚Äô system. However, we stress that
even though the conÔ¨Ådence region associated with the
model error model structure may be more conservative compared to the conÔ¨Ådence region for the nominal model, there
is still no guarantee that this set contains the true system
since we in general cannot guarantee that the model error
model captures the remaining dynamics completely.
Nevertheless, the concept of model error modeling has
helped make explicit the necessary leap of faith in system
identiÔ¨Åcation.
This brings us to the next topic on the agenda.
5.2. The true system: a mirage
Consider the following gedanken experiment. A continuous time true system is LTI but inÔ¨Ånite dimensional with
single poles spaced many decades apart. It is excited by a
band-limited input signal which covers frequencies up to a
certain frequency max which includes n of the true system
poles. As more and more data are collected from this setup, the identiÔ¨Åcation procedure appears to converge to an
nth order model which seems to be a correct description of
the true system as this model will pass all validation tests.
This model is in fact a near-optimal restricted complexity
model as the poor excitation at high frequencies make the
uncertainty of a full-order model very high in this frequency
region, cf. Section 4.4. However, as even more data samples
are collected (still using the same input spectrum), eventually the small discrepancies in the system behavior below
frequency max, as compared to an nth order model, will
become detectable from data and the model order may need
to be adjusted (upwards) in order for the model to be unfalsiÔ¨Åed.
From this mental exercise, we can conclude that even what
we may consider as a full-order model, is indeed only a nearoptimal restricted complexity model. As the signal-to-noise
ratio increases, more and more details of the system can be
modeled and, further, a different type of input may give a
drastically different model, which may again appear to be an
excellent model of the true system (for this particular input).
These observations support the arguments brought forward
in Skelton that any model is input dependent and that,
hence, the quest for a model of the true system is futile.
The inclusion of an unstructured dynamic term such as
(4) in set-membership identiÔ¨Åcation can be seen as a way
of incorporating this modeling limitation. In a linear time-varying dynamic term is used to account
for unmodeled dynamics and to prevent the modeling accuracy to increase unrealistically.
The conclusion that the true system cannot be modeled
to an arbitrary degree may seem disappointing. One has to
accept that we are at best working with models that are nearoptimal, cf. Section 4.4. However, the main message in this
contribution will be that by carefully selecting the input,
the system can be forced to reveal the properties that are
relevant for the particular application and this is all that is
needed for a successful application. As already pointed out
in Section 2.9, this will be a recurrent theme in the paper.
We will approach this topic in the next sub-section. We also
refer the reader to Section 6, Section 11 and the concluding
remarks in Section 13 for further elaborations on this topic.
5.3. Validating with conÔ¨Ådence
Suppose that it is critical for the application that any unmodeled dynamics in a certain model structure MME does
not exceed a certain bound. In a robust control context, it
could for example be that the peak gain in a certain frequency band should not exceed a certain value. In such a
situation it would boost the conÔ¨Ådence of the model builder
if it could be ascertained that the model, which we denote
by { ÀÜGN, ÀÜHN}, (and its corresponding uncertainty set) would
be falsiÔ¨Åed if this is the case.
Well, let us examine the outcome if a model error model is
estimated using the structure MME to which the unmodeled
dynamics belongs. For simplicity, let us assume that the true
system is LTI, cf. (25), and that the asymptotic results for
the prediction error method in Section 2.6.1.3 are valid. In
this case the residuals (16) are given by
Œµ = (G‚ó¶‚àíÀÜGN)uF + H‚ó¶
where uF = ÀÜH ‚àí1
N u, and the model ÀÜGN will be falsiÔ¨Åed if
the uncertainty region for the model error model does not
include the zero model.
Using (36) and some simple algebra, this is guaranteed to
|G‚ó¶(ej) ‚àíÀÜGN(ej)| > 2
2 (n)n,N() ¬∑
for some frequency . Above n,N is associated with the
model structure MME. Hence, if we want to ensure that
model errors larger than some function () are detected,
then the experiment should be carried out such that the righthand side of (46) is less than (). We emphasize, again, that
this conclusion is predicated on the assumption that MME
is Ô¨Çexible enough to capture the unmodeled dynamics.
H. Hjalmarsson / Automatica 41 393‚Äì438
Fig. 5. Dashed line: input spectrum. Thin solid line: true system.
Thick solid line: uncertainty region around estimated nominal Ô¨Årst order
Example 5.2. A third order system with a resonance is corrupted by white noise and excited with a low pass input,
also with a resonance (see Fig. 5). The system is identiÔ¨Åed
using a Ô¨Årst order output error model. The model, together
with its uncertainty region (based on that the true system is
in the model set) is shown in Fig. 5. Clearly the model has
missed the resonance peak and the uncertainty region is misleading. The model error is shown in Fig. 6 together with
the bound from (46) based on a 10th order FIR model error
model. We see that we can expect to detect the resonance
in our model error model but not any model error at other
frequencies. In the same Ô¨Ågure, the uncertainty bound for a
10th order FIR model error model is shown. As predicted,
the resonance peak is detected since the uncertainty region
for the model error model does not include zero around the
resonance, whereas the model error at other frequency bands
is not detected.
Notice that condition (46) depends on the input not only
through the input spectrum but also through the factor
n,N(), cf. Proposition 3.1. This has a, perhaps unexpected, implication.
Example 5.3 (Example 5.2 continued). Suppose that the
order of the model error model is increased from 10 to
100. One would then expect the lower bound (46) for detecting unmodeled dynamics to increase signiÔ¨Åcantly. For
the case when (32) holds, it should increase by a factor of
‚àö100/10 ‚âà3.2. The bound is shown in Fig. 7 for the two
cases. We see that there is actually an increase of approximately this factor, except at low frequencies and around
 = /2, which happens to be where the peak of the input
spectrum is located, where there is only a minor increase.
Notice also that even though there is a peak in the input
spectrum at  = /2, it is a factor of 20 smaller than the
input spectrum at low frequencies, cf. Fig. 5. Hence, the
small increase around  = /2 cannot be explained by the
magnitude of the input spectrum around this frequency.
The phenomenon is due to the factor n,N() in (46). The
conditions in Proposition 3.1 are approximately satisÔ¨Åed for
the present example (cf. Remark 3 after Proposition 3.1) so
for large N, n,N ‚âàn with n given by (34). A plot of
n() is shown in Fig. 8 for the two model orders. The
poles in n() consist in this case of the poles 0.9, 0.9,
0.97e¬±j/2 of the stable spectral factor of the input spectrum
and the poles of the FIR-model. The double pole at 0.9 gives
a large contribution to n() at low frequencies, whereas
the complex poles give a large contribution around =/2.
Since all the poles of an FIR-model are at the origin, n()
gets a frequency independent contribution of m from an mth
order FIR-model. Thus, n() increases linearly with the
model order m and this is clearly seen in Fig. 8 since the
solid line (corresponding to m = 100) is offset by 100 ‚àí
10 = 90 above the dashed line (corresponding to m = 10).
However, the relative increase at different frequencies is
vastly different. At frequencies where the poles of the input
spectrum contribute very little, the increase is a factor 10
but at frequencies where the inÔ¨Çuence from the poles of the
input spectrum is signiÔ¨Åcant, the relative increase is much
less. Hence, the relative increase in the uncertainty bound is
much less at low frequencies and, especially, around =/2.
The key observation in Example 5.3 is rather unexpected
and indeed good news as it implies that the input spectrum
may be designed so as to allow very Ô¨Çexible model error
models with only minor penalty in the falsiÔ¨Åcation power
at certain frequency bands. This is also consistent with the
fact that when periodic inputs are used, over-modeling does
not result in increased variance of the estimated frequency
function for frequencies corresponding to the spectral lines
of the input (although problems occur at other frequencies
due to inexact pole/zero cancellations). However, notice also
a large n() gives larger uncertainty bounds so, near peaks
of the input spectrum, the bounds can be signiÔ¨Åcantly worse
than the noise to signal ratio. In these frequency regions the
high-order approximation (32) typically underestimates the
true variance.
5.4. Validating restricted complexity quantities
Let G be a given model and suppose that we would like
to Ô¨Ånd out if this model represents a certain property of the
true system in a sufÔ¨Åciently accurate way. This can often be
formulated as that some function of the error between the
model and the true system should be small. To be explicit,
suppose that the relative error should be smaller than some
function (), i.e.
G(ej) ‚àíG‚ó¶(ej)
Suppose now that we would like to validate this property using a data set ZN. We can now directly refer to the
H. Hjalmarsson / Automatica 41 393‚Äì438
Fig. 6. Dashed line: model error. Solid line: lower bound for model errors that are guaranteed to be detected by a 10th order FIR model error model.
Shaded area: uncertainty region for estimated 10th order model error model.
Fig. 7. Smallest model error magnitude guaranteed to be detected in model validation. Dashed line: m = 10. Solid line: m = 100.
Fig. 8. n(). Dashed line: m = 10. Solid line: m = 100.
separation principle introduced in Section 4.2. An asymptotically efÔ¨Åcient estimate of the relative error is
ÀÜN(ej) = G(ej) ‚àíG(ej, ÀÜN)
where ÀÜN is any asymptotically efÔ¨Åcient full-order estimate
of the true system parameters. A conÔ¨Ådence region for the
relative error can be obtained by mapping the uncertainty set
(23) through the linear transformation ÀÜN. If the resulting
conÔ¨Ådence region for the relative error includes values larger
than () for some frequency , the model is invalidated.
The same technique can be applied when the function is
non-linear in G‚ó¶. However, in this case the resulting conÔ¨Ådence region may be very complex. Then, a Ô¨Årst order Taylor approximation may be used to obtain an approximation
of the conÔ¨Ådence region that depends linearly on the covariance matrix of ÀÜN. In the very interesting contribution
 , it is discussed how to obtain
exact conÔ¨Ådence regions by way of Markov chain Monte
Carlo simulations.
An alternative to the above procedure is to compute a
model error model for the residuals Œµ(t) = y(t) ‚àíG(q)u(t),
and use the conÔ¨Ådence region associated with this model
error model to estimate the size of the relative error. Notice,
however, that this may not give optimal accuracy as opposed
to the use of the separation principle.
6. Half-time intermission
Before we proceed with the second part of the paper which
is directly concerned with how identiÔ¨Åcation and control
interrelates, let us pause and summarize the observations
H. Hjalmarsson / Automatica 41 393‚Äì438
so far: We have in Section 5.2 argued that the quest for a
full-order model is futile, and that the best one can hope to
obtain is a near-optimal restricted complexity model. The
objective of identifying such a model is worthwhile to pursue from a statistical accuracy point of view, leading to the
pragmatic conclusion:
(i) Always Ô¨Årst model as well as possible.
As argued in Sections 4.2 and 4.5, such models are suitable,
from a statistical perspective, for replacing the true system
in subsequent computations of other quantities such as low
order models or the parameters in a controller.
Now, the obvious question is how does one know if one
has obtained a near-optimal restricted complexity model?
Unfortunately, there is no precise answer to this question
as this is a model validation problem, cf. the discussion in
Section 5.1; verifying the condition (44) on the mean-square
error requires the full-order model. It is also important to
realize that uncertainty descriptions based on near-optimal
restricted complexity models are not necessarily reliable.
Compare with Example 4.3, computing uncertainty bounds
based on that the system only has one impulse response
coefÔ¨Åcient will clearly not reÔ¨Çect the true model error. It is
the conÔ¨Ådence region associated with the full-order model
that is relevant. In practice one may
(ii) use a very Ô¨Çexible model structure as benchmark for
computing conÔ¨Ådence bounds and mean-square error.
We now come to the role played by the input, a subject we
have touched on in Section 5.3 and which we will now elaborate further on. Ideally, one should select the input such
that the full-order conÔ¨Ådence region is as large as possible,
while still satisfying the uncertainty speciÔ¨Åcations required
by the application. This would mean a minimum of experimentation on the system and that the simplest possible (from
the point of view of the application) model would be nearoptimal and useful for the application.
In practice, using a very Ô¨Çexible model in lieu of the true
system, as suggested in (ii), would imply a concern whether
the associated conÔ¨Ådence bounds grow so large that they
become useless. To examine this issue further, let us return
to Example 4.3 and notice that the accuracy of the static
gain estimate is independent of the model order! Hence,
in this example, the model builder does not have to worry
at all about that the model estimate will be too uncertain
should it turn out that the true system order was higher than
expected.3 The reason for this lies in the choice of input
signal which is concentrated to one frequency only. This
indicates that (near) sinusoidal inputs may help limit the
variance uncertainty for high-order models. This was also
3 The attentive reader will notice that the argument assumes that the
observation interval is long enough that the complete step-response has
been observed.
the theme in Section 5.3 and we will now use Proposition
3.1 to make this even more explicit.
Suppose that the input spectrum is
|ej ‚àí|2 + Àú
where  < 1 is close to 1 so that the Ô¨Årst term approximately
corresponds to a constant term in the input with amplitude .
Suppose that the conditions of Proposition 3.1 hold. Order
the k in (34) such that 1 = , then it holds
N Var( ÀÜGN(ej))
|ej ‚àí|2 +
|ej ‚àík|2
2(1 ‚àí2)/(|ej ‚àí|2) + Àú
For  ‚âà0, the above expression reduces to
v/ 2 for 
sufÔ¨Åciently close to 1, i.e. the noise to signal ratio at the
zero frequency which is independent of the model order. It
is also easy to see that at frequencies not in a neighborhood
of zero, the impact from the constant part of the input will
The above derivation can be generalized to sinusoidal inputs. We are thus in position to suggest the advice
(iii) select the input such that the model uncertainty at frequency regions of interest is insensitive to the model
complexity.
As we have indicated above (near) sinusoidal inputs are useful from this perspective, whereas wide band inputs such as
white noise do not possess this property.
When the model structure is pre-speciÔ¨Åed one can notice
that broad-band excitation can be difÔ¨Åcult to handle as it
then might not exist a near-optimal restricted complexity
model within the pre-speciÔ¨Åed structure which may render
the error quantiÔ¨Åcation difÔ¨Åcult.
Equipped with (i)‚Äì(iii), which can be viewed as generally
applicable pragmatic guidelines, we are now Ô¨Ånally in position to discuss the control application from a system identi-
Ô¨Åcation perspective. We will continue to use (or abuse) the
concept of a full-order model as it is useful as benchmark
for other methods and as there exists practical implementations in terms of near-optimal restricted complexity models.
7. Links between control and identiÔ¨Åcation
In this section we will discuss how control and identiÔ¨Åcation interact. In Section 7.1 we give a brief review of robust
control. In Section 7.2, the main issues in relation to identiÔ¨Åcation are summarized. These issues are then treated in
subsequent sections.
H. Hjalmarsson / Automatica 41 393‚Äì438
Fig. 9. Closed-loop system.
Fig. 10. Robust control conÔ¨Åguration.
7.1. Robust control
Fig. 9 illustrates a multivariable feedback conÔ¨Åguration
where the controller C and the true system G‚ó¶are LTI. The
closed-loop system equations are
SI(G‚ó¶, C) [C
where SI(G‚ó¶, C)‚âú(I + CG‚ó¶)‚àí1 is the achieved input sensitivity function. Above, r and w are known external excitations. The (1,1)-block of M(G‚ó¶, C) is the complementary
sensitivity function
T (G‚ó¶, C) = (I + G‚ó¶C)‚àí1G‚ó¶C.
The closed-loop system in Fig. 9 is internally stable if and
only if all four closed-loop transfer functions in M(G‚ó¶, C)
are in H‚àû.
Extracting all uncertain elements of the true system G‚ó¶
results in the conÔ¨Åguration in Fig. 10 where  represents
the uncertain elements. Scaling functions have been introduced in the block P so that  is normalized in some way.
The performance is measured by some induced norm from
the external input p (which may consist of r and w in
Fig. 9 and/or other signals of interest) to the signal z. Also
here scalings are introduced so that the desired performance
is that the gain from p to z is less than, e.g., 1. The generalized plant P thus consists of a nominal model G as well as
robust stability and performance weightings. The objective
is to design the controller C such that the closed-loop is stable and the performance criterion is satisÔ¨Åed for all uncertainty blocks  of some pre-speciÔ¨Åed structure. We refer to
Skogestad and Postlethwaite and Zhou, Doyle, and
Glover for comprehensive treatments of the robust
control problem.
7.1.1. Model sets in robust control
The, perhaps, most common uncertainty description in
robust control is multiplicative uncertainty
G‚ó¶= G(I + WI),
where  is unstructured, i.e. a full complex matrix, satisfying
‚à•‚à•‚àû‚©Ω1, and WI is a frequency weighting.
Model uncertainty can also be modeled as perturbations
of the coprime factors X and Y in a normalized coprime
factorization G = X‚àí1Y of a nominal
(X + X)‚àí1(Y + Y ) :
Another useful measure is the -gap metric introduced in
Vinnicombe :
(G1, G2)
(G1(ej), G2(ej))
if W(G1, G2) = 0
otherwise,
where  is the chordal-distance
(G1(ej), G2(ej))
|G1(ej) ‚àíG2(ej)|
1 + |G1(ej)|2 
1 + |G2(ej)|2
W(G1, G2) = wno(1 + G‚àó
Above wno(G) denotes the winding number about the origin
of G(z) as z traces the unit circle, avoiding unit circle poles
and zeros by indentation into the exterior of the unit disc.
Furthermore
(G)) denotes the number of poles in
the complement of the closed (open) unit disc.
7.1.2. Analyzing robustness
The robust stability problem entails checking whether the
feedback conÔ¨Åguration in Fig. 10 is stable for all allowed
perturbations  for a given controller C. Similarly, the robust performance problem entails checking that some performance criterion is satisÔ¨Åed for all allowable perturbations.
The computational complexity of checking these conditions
depends very much on the class of perturbations.
For the unstructured case, i.e. when ‚à•‚à•‚àû‚©Ω1 is the only
condition on , robust stability can be easily checked by
computing the H‚àû-norm of a certain transfer function. Consider, e.g., the case of multiplicative input uncertainty (48).
It is easy to show that
SI(G‚ó¶, C) = [I + (G‚ó¶, G, TI(G, C))]‚àí1SI(G, C)
(G‚ó¶, G, TI) = TIG‚àí1(G‚ó¶‚àíG)
H. Hjalmarsson / Automatica 41 393‚Äì438
is the input relative error G‚àí1(G‚ó¶‚àíG) weighted by the
complementary sensitivity function seen at the input of the
system TI = I ‚àíSI. Hence, if the nominal design SI(G, C)
is stable, a small gain argument gives that robust stability is
guaranteed if
‚à•(G‚ó¶, G, TI(G, C))‚à•‚àû< 1
when GC and G‚ó¶C have the same number of unstable poles.
Robust performance is harder to verify and the structured
singular value  has to be computed for
non-conservative results. For unstructured uncertainty, this
is still a convex optimization problem.
Simple sufÔ¨Åcient conditions for robust performance exist
as well. We illustrate this for multiplicative input uncertainty
(48). Suppose that it is desired that
‚à•WpSI(G‚ó¶, C)‚à•‚àû< 1,
‚àÄG‚ó¶= G(I + WI)
with ‚à•‚à•‚àû‚©Ω1 and where Wp is a scalar weighting function.
From (52) it follows that
(WpSI(G‚ó¶, C))
‚©Ω(WpSI(G, C))((I + (G‚ó¶, G, TI(G, C)))‚àí1)
(WpSI(G, C))
(I + (G‚ó¶, G, TI(G, C)))
(WpSI(G, C))
1 ‚àí((G‚ó¶, G, TI(G, C)))
Hence, robust performance in the sense (55) is guaranteed if
(WpSI(G, C)) + ((G‚ó¶, G, TI(G, C))) < 1, ‚àÄ
which, using (48), results in the condition
(WpSI(G, C)) + (TI(G, C)WI) < 1,
Remark 1. Condition (57) is satisÔ¨Åed if robust stability (54)
and nominal performance (WpSI(G, C)) < 1 both hold
with sufÔ¨Åcient margin . Not surprisingly, one may arrive at
the same condition by considering the performance degradation from the nominal design. The triangle inequality gives
(WpSI(G‚ó¶, C))
‚©Ω(WpSI(G, C)) + (Wp(SI(G‚ó¶, C) ‚àíSI(G, C)))
which leads to (57).
Remark 2. For SISO (single-input/single-output) systems,
(57) is equivalent to (55) since for SISO systems the lefthand side of (56) is the structured singular value for robust
performance.
Robust stability for the set (49) can be checked using the
generalized stability margin
‚à•M(G, C)‚à•‚àí1
if M is stable,
otherwise.
Stability is guaranteed only if bG,C ‚©æ .
The maximum stability margin for a model with normalized coprime factorization G = X‚àí1Y is given by 
where ‚à•¬∑ ‚à•H denotes the Hankel norm . Thus bG gives an upper bound on the maximum
allowable normalized coprime uncertainty.
It can be shown that for bG,C > 0,
bG,C = min
The following result was Ô¨Årst presented in Vinnicombe
Proposition 7.1. Let the model set be a ball in the -gap
metric (50):
{G‚ó¶: (G, G‚ó¶)‚©Ω}
where G is an arbitrary nominal model. Then it holds that
a controller C stabilizes all systems in this set if and only if
The following result also holds .
Proposition 7.2. For a given nominal model G and system
G‚ó¶it holds that G‚ó¶is stabilized by all controllers in the set
{C : bG,C > } if and only if (G, G‚ó¶) < .
The -gap metric is the only metric for which Propositions
7.1 and 7.2 both hold.
Robust stability for real parametric uncertainty is treated
in Rantzer and Megretski . A convex parametrization
of all controllers that stabilize the system for all possible
parameter combinations is provided when the uncertain real
parameters appear linearly in the closed-loop characteristic
polynomial.
7.1.3. Synthesizing robust controllers
For general structures of the uncertainty, robust control
design amounts to minimizing the structured singular value
of a certain transfer matrix with respect to the controller.
There are no generally applicable algorithms for such synthesis problems; for complex perturbations, so called DKiterations may be used
to, at least, decrease .
In Section 7.1.2 it was pointed out that the robust performance condition (55) could be expressed as (57). The latter condition is closely related to the mixed sensitivity H‚àû
WIT (G, C)
H. Hjalmarsson / Automatica 41 393‚Äì438
where S(G, C) = I ‚àíT (G, C) is the sensitivity function.
Thus, H‚àûcontrol design can be used to approximately optimize robust performance in this case .
H‚àûloop-shaping combines classical loop-shaping ideas with modern robust
control. First pre- and post-compensators W1 and W2 are
added to the system to shape the loop gain W2GW 1 of the
nominal system in a desired manner. Then a controller C is
designed such that the stability margin (58) of the shaped
system W2GW 1 is sufÔ¨Åciently large. As discussed in Section 7.1.2, this guarantees robust stability with respect to
perturbations in the coprime factors of the shaped system.
It also means that stability is guaranteed for all systems G‚ó¶
which are such that (W2GW 1, W2G‚ó¶W1) < bW2GW 1,C, cf.
Section 7.1.2.
A simple and very instructive design method is internal
model control (IMC) . The controller C is parametrized in terms of the nominal model G
as C = Q(I ‚àíGQ) where Q is a stable transfer function.
A two-step procedure is employed where in the Ô¨Årst step
Q is determined so as to meet some nominal performance
speciÔ¨Åcation, e.g. ‚à•W2S(G, C)W1‚à•‚àû< 1. In the second
step, Q is augmented with a ‚Äúde-tuning‚Äù Ô¨Ålter F giving
a new ‚ÄúQ‚Äù equal to QF. The Ô¨Ålter F is selected so as to
ensure robust stability. For multiplicative input uncertainty
(48), the robust stability condition (54) can be expressed
as ‚à•QF(G‚ó¶‚àíG)‚à•‚àû< 1 since TI(G, C) = QFG in this
Model reference control is closely related to IMC. Here
the target is to design the controller C such that a particular sensitivity function is obtained, at least nominally. For
example, the nominal design may be such that
T (G, C(G)) = Td
for some desired complementary sensitivity function Td.
Solving for C gives
C(G) = G‚àí1(I ‚àíTd)‚àí1Td.
Naturally, non-minimum phase zeros in G are not allowed
to be canceled in this design. Notice, that with this design it
is possible to parametrize the model G directly in terms of
the optimal controller C:
G(C) = (I ‚àíTd)‚àí1TdC‚àí1.
There is thus a one-to-one relationship between models and
optimal controllers. The parametrization (60) is known in
adaptive control as direct parametrization.
A synthesis procedure for real parametric uncertainty is
presented in Ghulchak and Rantzer . It builds on
Rantzer and Megretski and produces, via convex optimization, a robustly stabilizing controller which is arbitrarily close to the optimal controller.
7.2. IdentiÔ¨Åcation and control
In the preceeding section we have tried to give a Ô¨Çavour
of modern robust control theory. We will now turn to the
problem of using models obtained from system identiÔ¨Åcation in robust control design. An immediate insight is the
following:
The set of unfalsiÔ¨Åed models delivered by system identiÔ¨Åcation generally corresponds to very structured uncertainty
descriptions from the point of view of robust control.
For example ellipsoidal sets in the parameter domain such
as (23), do not readily Ô¨Åt into any of the model set descriptions in Section 7.1.1. As indicated in Section 7.1.3, this in
general means that the robust control design problem becomes very difÔ¨Åcult. In fact, it is often highly non-trivial to
even analyse the robustness properties for a given controller.
In Section 7.3 we report on some recent progress in robustness analysis tailored for ellipsoidal model sets of the type
(23). Awaiting further development in the areas of robustness analysis and control synthesis for general model sets,
an alternative approach has been to outerbound the set of
unfalsiÔ¨Åed models in a way that is congruent with existing
robust control theory. Naturally, it is desired to introduce as
little conservatism as possible in this procedure, as well as
keeping the complexity of the bound to the minimum. In
Section 7.4 we discuss some results in this direction.
In Section 7.5 we review some control design methods
that have been employed in conjuction with identiÔ¨Åed model
Characteristic to existing robust control methods is
that the uncertainty speciÔ¨Åcations are assumed to be prespeciÔ¨Åed. When the identiÔ¨Åcation part of the problem is
taken into account, an additional freedom in the problem
formulation is unleashed in that the experiment design
can be used to inÔ¨Çuence the uncertainty set. Hence, for
given experimental constraints there are experimental conditions for which the resulting uncertainty set is such that
the robust performance speciÔ¨Åcations cannot be improved
upon, i.e. the uncertainty set is optimally shaped (for robust
performance). The complexity of modern robust control
algorithms as well as system identiÔ¨Åcation has (so far)
prohibited explicit solutions to such problems. A further
complicating factor is that industrial practice motivate the
use of restricted complexity models as well as restricted
complexity controllers. The non-transparency of modern
robust control algorithms, induced by their complexity, has
forced deliberations on these topics to rely on simpliÔ¨Åed
arguments and in Section 7.6 we will discuss some insights
that can be obtained.
7.3. Robustness analysis for identiÔ¨Åed models
A simple expression for the ‚Äúreal‚Äù stability margin is derived in . Based on this result, robust stability for identiÔ¨Åed ARX-models is considered in Kosut and
Anserson , see also Raynaud .
H. Hjalmarsson / Automatica 41 393‚Äì438
In a very interesting series of papers , summarized in Gevers, Bombois, Codrons, Scorletti,
and Anderson , Gevers, Bombois and co-workers
have developed analysis tools for the set of unfalsiÔ¨Åed
models obtained in prediction error identiÔ¨Åcation, i.e. (23).
Also building upon Rantzer , given a controller C, a
computable, necessary and sufÔ¨Åcient condition for stability
for all models in (23) is provided. It is also shown that the
largest chordal distance (51) between any model in (23)
and a nominal model G can be computed by convex optimization. Hence, by frequency gridding, the largest -gap
can be computed approximately. Referring to Proposition
7.2, this in turn means that it is possible to characterize the
largest ball (in the -gap metric) of controllers which are
guaranteed to stabilize all systems in (23). It is also shown
that for the performance measure 1(W2M(G‚ó¶, C)W1)
(recall that M is the closed loop transfer function deÔ¨Åned
in (47)), where the frequency weightings W1 and W2 are
block-diagonal, it is possible to compute the worst case
performance over the set (23) via convex optimization.
7.4. Outerbounding the set of unfalsiÔ¨Åed models
Robust stability is the issue in Douma, Van den Hof, and
Bosgra . Consider a ball S of systems in the gap
metric and a corresponding set
C of controllers characterized as being the largest ball in
the gap metric (centered around some nominal controller)
which is such that all controllers in this ball stabilize all
systems in S. It is then shown that there exists a pair of
sets, one which consists of systems and one which consists
of controllers, which are characterized by the double Youla
parametrization and which are such that the set of systems
includes S and the set of controllers include those in C.
Hence, with respect to robust stability, the double Youla
parametrization is less conservative than the gap metric for
representing model sets. By similar arguments it is shown
that the double Youla parametrization is less conservative
than using the -gap and the -gap to characterize model sets.
In Van den Hof it is pointed out that choosing
a model structure such that the model error is afÔ¨Åne in
the performance criterion implies considerable simpliÔ¨Åcations. When the performance is measured by some frequency
weighted element of M(G, C), it is pointed out that the dual
Youla parametrization is one such parametrization. Further
insights on the implications of outerbounding are reported
in Douma and Van den Hof .
Pointwise bounds in the frequency domain are derived in
Wahlberg and Ljung using a set-membership setting.
The effects of unknown impulse response coefÔ¨Åcients, inital condition and an unknown-but-bounded disturbance are
taken into account. Another contribution to the frequency
domain bounding of ellipsoidal parameter sets is Devilbiss
and Yurkovich . ConÔ¨Ådence bounds in the frequency
domain, taking undermodelling explicitly into account, for
the instrumental variable method are developed in Hakvoort
and Van den Hof .
A recent contribution where frequency domain bounds
for a set-memberhip method are derived in Milanese and
Taragna . Here prior assumptions on the decay rate of
the impulse response coefÔ¨Åcients are used to determine the
grid size of frequency points so that intersample variation
can be neglected.
For standard H‚àûmethods to be applicable, the uncertainty bound should be the magnitude of a rational transfer
function. A method that produces such bounds is presented
in Scheid, Bayard, and Yam .
7.5. Control algorithms using identiÔ¨Åed model sets
In this section we will give some examples of control
algorithms that have been developed speciÔ¨Åcally to cope
with model sets produced by identiÔ¨Åcation algorithms.
7.5.1. Ellipsoidal model sets
The problem of minimizing the maximum linear quadratic
regulator (LQR) cost in a model set described by ellipsoidal
parametric uncertainty, such as (23), is studied in Lau, Boyd,
Kosut, and Franklin . It is shown that the solution is
the LQR corresponding to a ‚Äúworst-case‚Äù plant in the model
set. A heuristic algorithm for computing the worst-case plant
is proposed.
In Raynaud, Pronzato, and Walter the design speciÔ¨Åcation is that the closed loop poles should be inside a disc
with a pre-speciÔ¨Åed radius  < 1. The objective is to Ô¨Ånd
the controller that maximizes the volume of a model set of
the type (23) (i.e. the constant 2 (n) in (23)) such that the
closed-loop poles satisfy the design objective for all models in this set. It is remarked that, following Rantzer and
Megretski , the problem can be recast as an inÔ¨Ånite
dimensional convex problem. Instead a lower bound for the
maximum volume, amenable to standard H‚àûrobust control, is used. An alternative path might be to use the method
in Ghulchak and Rantzer which addresses the problem formulated in Rantzer and Megretski .
There is at present no control design method that accounts
for both robust stability and robust performance when the
model set is deÔ¨Åned by (23). For SISO systems it is suggested
in Bombois, Scorletti, Anderson, Gevers, and Van den Hof
 to Ô¨Årst determine the set of controllers for which the
nominal performance is somewhat better than the desired
robust performance. This is a standard H‚àûproblem and
the set can be easily characterized. It is then tested whether
all controllers in this set stabilize all systems in the model
set. A similar test for the performance criterion is presented.
The robust stability test boils down to the computation of
the structured singular value of a certain matrix. If these two
tests are passed, any controller in the set of controllers can
H. Hjalmarsson / Automatica 41 393‚Äì438
7.5.2. Model sets from set-membership identiÔ¨Åcation
IMC is employed in Malan, Milanese, Regruto, and
Taragna . The Q part of the controller, cf. Section
7.1.3, is obtained by solving
ÀÜQ = arg min
‚à•(1 ‚àíQG)W‚à•‚àû
subject to the robust stability condition ‚à•QW A‚à•‚àû< 1 . But it can also be used to analyze how the model uncertainty and the experimental conditions inÔ¨Çuence the performance. Building on Hjalmarsson and Jansson , we
shall pursue such an analysis in this section.
Let us introduce the weighted difference between the
closed-loop system consisting of the true system G‚ó¶controlled by the controller C‚ó¶, and the designed closed-loop
system using the nominal model G with some controller C
J(G‚ó¶, C‚ó¶, G, C)‚âú
(M(G‚ó¶, C‚ó¶) ‚àíM(G, C))
= W1(M(G‚ó¶, C‚ó¶) ‚àíM(G, C))W2,
where wij, i, j = 1, 2 are scalar frequency weights. As this
expression may seem cumbersome, the reader is recommended to restrict attention to the case
J(G‚ó¶, C‚ó¶, G, C) = G‚ó¶SI(G‚ó¶, C‚ó¶)C‚ó¶‚àíGSI(G, C)C
= T (G‚ó¶, C‚ó¶) ‚àíT (G, C),
which corresponds to the choice w11=w12=1, w21=w22=0.
Much of the analysis in the identiÔ¨Åcation for control literature has focused on this (1, 1)-block. However, performance
robustness is equally important for the other transfer functions.
It is natural to consider the difference between the nominal design M(G, C(G)), which usually has some desirable
properties, and the corresponding closed-loop transfer function when the designed controller C(G) is applied to the true
system, i.e. M(G‚ó¶, C(G)). For this reason we introduce
V (G, C)‚âúJ(G‚ó¶, C, G, C)
suppressing for notational convenience the dependence of
V on G‚ó¶. Various norms of V (G, C(G)) can be used to
quantify the performance degradation when the designed
controller is applied to the true system, as compared to the
nominal design.
It is also of interest to consider performance degradation relative to the overall optimal design M(G‚ó¶, C(G‚ó¶))
(which would result if perfect knowledge of G‚ó¶was available in the control design). This can be measured by
norms of J(G‚ó¶, C(G‚ó¶), G‚ó¶, C(G))=W1(M(G‚ó¶, C(G‚ó¶))‚àí
M(G‚ó¶, C(G)))W2. The average squared 2-norm of this
quantity has, e.g., been used in input design which we will
discuss in Section 11.
Notice that when M(G, C(G)) = M is independent of G,
then J(G‚ó¶, C(G‚ó¶), G‚ó¶, C(G)) = ‚àíJ(G‚ó¶, C(G), G, C(G))
so that the performance degradation measures V (G, C(G))
and J(G‚ó¶, C(G‚ó¶), G‚ó¶, C(G)) coincide.
Returning to V, notice that it holds that (recall (53))
(I + )‚àí1SI(G, C) [w12C
where  = (G‚ó¶, G, TI(G, C)). From this expression we
can re-derive the robust stability result (54) and we conclude
once more that the size of the weighted input relative error
 is intimately tied to robust stability.
Regarding robust performance, we can overbound the gain
of V in the following way:
(V (G, C))
‚©Ω((G‚ó¶, G, T (G, C)))
√ó ((I + (G‚ó¶, G, T (G, C)))‚àí1)
2(C) + w2
122(SI(G, C)C) + w2
222(SI(G, C)).
For SISO systems the bound is tight. It is also possible to
derive a similar expression that is based on the weighted
output relative error O = (G‚ó¶‚àíG)G‚àí1T (G, C), see, e.g.
Morari and ZaÔ¨Åriou .
Studying (65), we see that the Ô¨Årst two factors depend
only on the weighted relative model error  while the last
two factors depend solely on the nominal design. We shall
now discuss each factor separately:
‚Ä¢ The Ô¨Årst factor is the gain of the weighted relative error.
Hence, the relative accuracy of the model, as compared to
the designed complementary sensitivity function, can be
used to control robust performance
‚Ä¢ As we have pointed out above, the second factor
stability.
H. Hjalmarsson / Automatica 41 393‚Äì438
according to
((I + (G‚ó¶, G, T (G, C)))‚àí1)
1 ‚àí((G‚ó¶, G, C))
The closer to 1 the gain of , the poorer robustness margin
and the poorer performance. Notice that by combining the
above inequality with the inequality (65), a generalization
of the robust performance condition (57) is obtained.
‚Ä¢ The third factor
11/2(C) + w2
21 becomes large at
frequencies where the controller has a low gain direction.
This can occur, e.g., if the system is ill-conditioned with
large differences in gain in different directions or in the
rare event that the designed closed-loop bandwidth is
lower than the bandwidth of the nominal model.
‚Ä¢ The Ô¨Årst term inside the square root in the fourth factor,
122(SI(G, C)C), is related to the gain from the
reference r to the input u in Fig. 9. It is thus a measure of
the control effort. Hence, this term is large at frequencies
where the bandwidth of the nominal design signiÔ¨Åcantly
exceeds the bandwidth of the nominal model.
The second term w2
222(SI(G, C)) is the gain of the nominal input sensitivity. This term may become large around
the designed bandwidth if, e.g., the designed bandwidth
exceeds the limitations imposed by non-minimum phase
zeros present in the system.
Notice that  is involved both in the robust stability and
the robust performance conditions. The magnitude of this
factor depends on both the quality of the model G and the
control speciÔ¨Åcations (represented by TI(G, C)). It is around
 where the interplay between system identiÔ¨Åcation and control is staged and below we will illustrate some of the tradeoffs that it induces by considering the problem of making
||>1. For simplicity, we will consider the SISO-case only.
Let ÀÜGN be an identiÔ¨Åed model and let C( ÀÜGN) be a controller
designed based on this nominal model (and possibly also its
conÔ¨Ådence region). Since, input and output sensitivities are
the same for SISO systems we shall drop the subscript I in
quantities such as TI, etc.
Trade-off 1: Performance speciÔ¨Åcations versus experimentation effort
Suppose that the set of unfalsiÔ¨Åed models is given by (36).
T ( ÀÜGN, C( ÀÜGN))
2 (n)n,N
with probability . Here T/ ÀÜGN is the designed transfer function from the reference r to the input u in Fig. 9, which we
Fig. 11. Thick solid line: estimated model ÀÜGN. Thin dashed line: desired
complementary sensitivity function T for design 1. Lower dotted line:
desired complementary sensitivity function T for design 2. Thick dashed
line: designed control effort T/ ÀÜGN for design 1. Upper dotted line:
designed control effort T/ ÀÜGN for design 2.
could call the designed control effort. Let SENPR denote the
signal energy density to noise power density ratio N
Then (66) implies roughly that SENPR has to be at least an
order of magnitude larger than the squared designed control
effort in order to guarantee robust performance.
In order to get some insight in what this implies, notice
that in the passband of the designed complementary sensitivity function, |T / ÀÜGN| ‚âà|1/ ÀÜGN|. Typically G‚ó¶, which ÀÜGN
tries to approximate, is of low-pass character with gain larger
than one at low frequencies, and hence the designed control
effort will be (signiÔ¨Åcantly) less than one for frequencies up
to when the system‚Äôs own gain drops below 1, i.e. the open
loop cross-over frequency. Hence, in this frequency range
the model uncertainty may be allowed large while still having a small ‚à•‚à•‚àû. This is the forgiving nature of feedback
giving the model builder some slack. Above this frequency
region the magnitude of |T / ÀÜGN| will increase until the bandwidth of T is reached where it will start to decrease if T
rolls-off faster than ÀÜGN. Thus it is in this frequency region
where an accurate model will be required. More precisely,
for a system that rolls off like 1/n, a SENPR of the order
at least O(2n) is required in this frequency band. This indicates that increasing the closed-loop bandwidth becomes
increasingly expensive with respect to experimentation beyond the open loop system‚Äôs own bandwidth. This is illustrated in Fig. 11 where the designed control effort is shown
for two different choices of designed bandwidth (designs 1
and 2). As the bandwidth is increased above the bandwidth
of the estimated model, the designed control effort increases
signiÔ¨Åcantly implying in turn a drastic increase in the minimum SENPR which is proportional to the square of the designed control effort as mentioned above. We shall discuss
experiment design further in Section 11.
Another important conclusion is that (66) involves quantities which a priori are unknown. Hence, it may be beneÔ¨Åcial
to update the experiment design as more information about
the system is obtained. This leads to adaptive experiment
design which we shall discuss in Section 11.3.
In summary, (66) captures the trade-off between the
input spectrum and the performance speciÔ¨Åcations. The
H. Hjalmarsson / Automatica 41 393‚Äì438
importance of adapting the performance speciÔ¨Åcations to
the system uncertainty is the leading principle in the ‚Äòwindsurfer approach‚Äô, see e.g. Lee et al. . Here the performance is gradually increased along with improved conÔ¨Ådence in the model. See also Schrama , furthermore
see Cadic, Weiland, and Polderman for a recent discussion on the importance of this issue.
Trade-off 2: Performance speciÔ¨Åcations versus model
complexity
Suppose that in order to limit the complexity of the controller, a low order model Glo is to be used. From the separation principle in Section 4.2 we have that the optimal model
is obtained by Ô¨Årst estimating a full-order model ÀÜGML using
ML estimation and then solving
ÀÜGlo = arg min
T (Glo, C(Glo))
The total error ÀÜGlo ‚àíG‚ó¶can be assessed by also computing the variance for ÀÜGlo. However, already the minimum of
the expression above gives useful information. For a given
bound on ||, a lower bound on the complexity of Glo is
obtained. Conversely, given the complexity of Glo, an upper
bound on achievable bandwidth for T is obtained.
8. Direct identiÔ¨Åcation of restricted complexity models
for control: LTI systems
Since the order of the controller typically depends on
the order of the model, it is often desirable to restrict the
complexity of the model. Thus there is a need to identify
restricted complexity models that are suitable for control.
This is the theme of this section. In one line of research
the objective has been to develop identiÔ¨Åcation methods
which directly identify low order models suitable for control design. A minimum requirement in this context has
been methods that work for large data sets. This means that
the focus has been on the bias error |G‚ó¶(ej) ‚àíG(ej, ‚àó)|
and variance aspects have to a large extent been neglected,
cf. Sections 8.3‚Äì8.7.
In order to facilitate the comparison of different methods
only SISO systems will be considered. We deÔ¨Åne as formal
objective to minimize the performance degradation as compared to the nominal control design. This means minimizing
(recall (63)) ‚à•V (G, C(G))‚à•, where ‚à•¬∑ ‚à•is any norm, with
respect to G, in other words the identiÔ¨Åcation is linked to
the control design via a performance degradation criterion.
For ease of comparison, the simple case (62) is considered
throughout Section 8. Notice that V (G, C) then simpliÔ¨Åes to
V (G, C) = T (G‚ó¶, C) ‚àíT (G, C) = S(G, C) ‚àíS(G‚ó¶, C)
= (1 + (G‚ó¶, G, T (G, C)))‚àí1(G‚ó¶, G, T (G, C))
√ó S(G, C),
where  is given by (53) with TI = T (which holds for
SISO systems). We shall occasionally use  to denote some
nominal performance measure, e.g. designed bandwidth.
We will begin this expos√© in Section 8.1 by elaborating on
how to identify restricted complexity models in an asymptotically efÔ¨Åcient way. We will then in subsequent sections
review different approaches that have appeared in the literature. In Section 8.9 stability aspects for such performance
based methods will be considered. From this discussion we
conclude that it is of interest to consider methods which
make the weighted relative error (53) small and in Section
8.10 we discuss how to identify near-optimal restricted complexity models with this property. Finally, in Section 8.11
we discuss preferential identiÔ¨Åcation, an alternative way of
connecting the identiÔ¨Åcation criterion with robust control.
8.1. Asymptotically efÔ¨Åcient identiÔ¨Åcation
From Section 4.2 it follows that it is optimal, with respect to the asymptotic statistical accuracy, to Ô¨Årst identify a
full-order model using an asymptotically efÔ¨Åcient estimator,
and then reduce the complexity according to the following
procedure:
Let G() represent a full-order model, i.e. ‚àÉ‚ó¶s.t. G(‚ó¶)=
G‚ó¶, and let ÀÜML denote the corresponding ML-estimate. Let
) represent a restricted complexity model and deÔ¨Åne
, )‚âúJ(G(), C(G(
J(G1, C1, G2, C2)
(or the simpler (62)). Then, take ÀÜ
as the minimizer
of ‚à•ÀÜJ(ÀÜML,
, )‚à•with respect to
. The variance of
, )‚à•may be estimated numerically using Gauss‚Äô
approximation formula and implicit differentiation of ÀÜJ(,
, ). Hence, for given data, the performance speciÔ¨Åcation  may be adjusted so that achieved
and designed performance are guaranteed to be sufÔ¨Åciently
close as well as to ensure robust stability.
8.2. High-order modeling and model reduction
It may be useful both from practical and computational
points of view to Ô¨Årst estimate a high-order model and
then perform model reduction. The method ASYM, see Zhu
 , is a fully integrated method for identiÔ¨Åcation
for control based on this approach and, hence, very close
in spirit to the use of the separation principle discussed in
Section 8.1. The input design is based on high-order optimal input design; see Section 11.1. A two step approach
is used with a high-order ARX-model estimated in the Ô¨Årst
step, the motivation being its computational simplicity and
that the high-order theory is applicable, cf. Section 3.2 and
(32). Model reduction is performed using the asymptotic
ML method which means minimizing a
frequency weighted L2 criterion where the weighting corresponds to the inverse of an estimate of the variance of
H. Hjalmarsson / Automatica 41 393‚Äì438
the estimated high-order frequency function. The model reduction step is thus asymptotically efÔ¨Åcient as the sample
size and the model order tends to inÔ¨Ånity. Model order selection is also based on the high order variance expression.
To determine the unfalsiÔ¨Åed set of controllers, (36) is used
with n,N() = m (=the model order) which follows from
(32). The method was developed in the early 1990‚Äôs and
it has been successfully applied to numerous multivariable
processes in process industry.
High-order ARX-modeling is also advocated in Rivera
and Jun .
8.3. Direct restricted complexity identiÔ¨Åcation
It may not be convenient to identify a full-order model
and around 1990 several ideas of how to directly identify a nominal model G which approximately minimizes
‚à•V (G, C(G))‚à•2 appeared. As we will outline below, the basic idea is to choose the design variables in the identiÔ¨Åcation
method such that the asymptotic bias expression, e.g. (26),
approximates the L2-norm of the error (67).
The quantity V (G, C) in (67) can also be expressed as
V (G, C) = T (G‚ó¶, C) ‚àíT (G, C)
= (G‚ó¶, G, T (G, C))S(G‚ó¶, C)
= S(G, C)(G‚ó¶‚àíG)CS(G‚ó¶, C).
‚à•V (G, C)‚à•2
|G‚ó¶‚àíG|2|CS(G‚ó¶, C)|2|S(G, C)|2 d.
Comparing this expression with the closed-loop bias expression (27), we see that ‚à•V (G, C)‚à•2
2 corresponds to the Ô¨Årst
term in the closed-loop bias expression (27) if the noise
model is taken as
S‚àí1(G, C).
Hence, the model that minimizes ‚à•V (G, C)‚à•2
2 with respect
to G will be obtained asymptotically when the system is
noise free if the identiÔ¨Åcation is performed in closed-loop
with the controller C using the noise model (69). We will
discuss this approach further in Section 8.5.
Before we proceed, observe that the above derivation can
also be done in the time domain. Let u and y, denote the
input and output, respectively, of the closed-loop system in
Fig. 9 with w ‚â°0 and the controller C in the loop. The
manipulations in (68) correspond in the time domain to
y ‚àíT (G, C)r = (S(G, C) + T (G, C))y ‚àíT (G, C)r
= S(G, C)(y ‚àíGC(r ‚àíy))
= S(G, C)(y ‚àíGu).
The expression (70) is the prediction error (16) when data
are collected in closed-loop with C as the controller and H =
S‚àí1(G, C) as noise model. The only difference compared
to (69) is due to that the spectrum of (70) is weighted with
the reference spectrum which is not the case in (68).
A simpler cost function is obtained by linearizing (62)
with respect to G‚ó¶
J(G‚ó¶, C‚ó¶, G, C)
‚âà((G‚ó¶‚àíG)C‚ó¶+ (C‚ó¶‚àíC)G)S(G, C‚ó¶)S(G, C)
‚âúJ(G‚ó¶, C‚ó¶, G, C).
This gives the approximation
V (G, C)‚âúJ(G‚ó¶, C, G, C) = (G‚ó¶‚àíG)CS2(G, C)
to V (G, C) (63) and instead of minimizing ‚à•V (G, C(G))‚à•2,
‚à•V (G, C(G))‚à•2 could be minimized (or ‚à•V (G(C), C)‚à•2 if
the direct parametrization (60) is used).
Comparing the L2-norm of (71) with the open loop bias
expression (26), we see that open loop identiÔ¨Åcation with
the noise model
u (S2(G, C(G))C(G))‚àí1
corresponds to minimizing V (G, C(G)) under noise free
conditions. We will discuss this approach in Section 8.6.
Remark 1. Comparing (71) with (67), we see that the stability guaranteeing term (1 + )‚àí1 is not present in the approximation V (G, C). Furthermore, comparing with the discussion on conditions on || in Section 7.6, we see that there
is less emphasis on making || small at low frequencies.
Hence, there is a possibility that || > 1 at low frequencies
when (71) is used, with a potential risk for destabilization.
In Sections 8.4‚Äì8.7 we will elaborate on how the expressions above have been used in the literature.
8.4. Model and controller reduction
Expression (71) was, perhaps, Ô¨Årst used for model reduction purposes. Given a full-order model G‚ó¶and a desired complementary sensitivity function, the problem of
Ô¨Ånding a control relevant reduced order model such that
‚à•S(G‚ó¶, C(G))‚à•is as small as possible was examined in
Rivera and Morari . Through the use of a triangle inequality for the sensitivity function, the objective was simpli-
Ô¨Åed into minimizing the norm of J(G‚ó¶, C(G), G, C(G)) =
V (G, C(G)) with respect to G, which in turn was approximated by the norm of V (G, C(G)).
In Rivera and Morari , the function ‚à•V (G, C(G))‚à•
is minimized with respect to G numerically under the assumption that
|S(G, C(G))T (G, C(G))|
is independent of G, cf. IMC and model reference control
(see Section 7.1.3). From this we see that a small relative model error is achieved around the designed bandwidth
where neither of S(G, C(G)) or T (G, C(G)) are small.
H. Hjalmarsson / Automatica 41 393‚Äì438
The problem of controller reduction was also studied in
Rivera and Morari , see alsoAnderson and Liu .
Given the high order controller C‚ó¶, the objective is to determine C such that some norm of
U(G‚ó¶, C)‚âúJ(G‚ó¶, C‚ó¶, G‚ó¶, C)
= T (G‚ó¶, C‚ó¶) ‚àíT (G‚ó¶, C)
is small. Linearizing with respect to C gives
U(G‚ó¶, C) ‚âàC‚ó¶‚àíC
T (G‚ó¶, C‚ó¶)S(G‚ó¶, C‚ó¶)‚âúU(G‚ó¶, C).
A similar procedure as for the model reduction problem is
In fact these model reduction and controller reduction
problems are dual to each other: With a direct parametrization of G in terms of the controller C according to
T (G‚ó¶, C‚ó¶)
1 ‚àíT (G‚ó¶, C‚ó¶)
U(G‚ó¶, C) = ‚àíV (G(C), C).
Hence, the controller reduction problem minC‚à•U(G‚ó¶, C)‚à•
can be seen as the model reduction problem minG‚à•V (G, C)‚à•
where G is parametrized in terms of C according to (75).
A variation of the above controller reduction idea is presented in Landau, Karimi, and Constantinescu . Here,
no Taylor approximation is introduced. For the optimization, a recursive algorithm is employed which uses simulated
closed-loop signals. Boundedness of the closed-loop signals
of the closed loop system with the reduced order controller
is guaranteed under a certain positivity condition.
8.5. Iterative methods
In Section 8.3 we have seen that V (G, C) can be minimized with respect to G using closed-loop identiÔ¨Åcation
with the controller C in the loop when the noise model (69)
is used and data are noise free. Since the objective is to
minimize V (G, C(G)) this suggests the following iterative
procedure. At iteration k:
(i) Identify a model Gk using the noise model (69) and
closed-loop data collected with controller Ck=C(Gk‚àí1)
in the loop.
(ii) Replace Ck with Ck+1 = C(Gk) in the closed loop. Let
k = k + 1 and go to Step (i)
The methods in Zang et al. and Schrama are
examples of this approach. See also ÀöAstr√∂m . Surveys
of this type of methods can be found in Gevers , Van
den Hof and Schrama and Albertos and Sala .
Despite the intuitive character, the above scheme will not
converge to the minimum of V (G, C(G)) . The iterations above correspond to, for some given function g(x, y), trying to minimize the function f () = g(, ) by the iterations
(i) k = arg ming(, k‚àí1).
(ii) Let k = k + 1 and go to Step (i)
Any convergence point ‚àósatisÔ¨Åes that the partial derivative of g with respect to the Ô¨Årst argument x is zero, i.e.
g(‚àó, ‚àó)/x = 0, whereas a necessary condition for optimality is 0 =f ‚Ä≤()=g(, )/x +g(, )/y. Thus convergence to the optimal solution cannot in general be guaranteed. This problem had earlier on been noted in adaptive
control, see Ljung and S√∂derstr√∂m , Anderson et al.
 and Phillips, Kosut, and Franklin . It has also
turned out to be difÔ¨Åcult to establish convergence of the
above procedure. Despite these shortcomings, this type of
method has been found useful and successful applications
exist, see e.g. Partanen and Bitmead , Schrama and
Bosgra , Albertos and Sala . In Section 8.11 we
will see that the uncertainty model unfalsiÔ¨Åcation approach
allows convergent iterative methods to be developed.
The above derivation assumed noise free data. In the
case of noisy data, the bias of the direct prediction error
method cannot be tuned at the user‚Äôs will by the use of a
preÔ¨Ålter/noise-model. This has spurred the development of
a number of closed-loop identiÔ¨Åcation methods for which
this is possible. We refer to Van den Hof , Forssell
and Ljung and Landau, Karimi, and Constantinescu
 for details.
8.6. PreÔ¨Åltering methods
In Section 8.3 we introduced the approximation V (G, C)
(71) to V (G, C) (63) and showed that under noise free conditions ‚à•V (G, C(G))‚à•2 can be minimized asymptotically
with prediction error identiÔ¨Åcation if the noise model is chosen as (72). For noisy data, the bias expression (26) is no
longer valid as the noise model (72) is not independently
parametrized of G . However, this
preÔ¨Åltering method is simple to use as it requires no special
experimental conditions and can be expected to work if the
signal-to-noise ratio is high and some care regarding the designed bandwidth is exercised, see Remark 1 in Section 8.3.
The above idea is the basis in Rivera, Pollard, and Garcia
 where, for numerical reasons, an iterative procedure
is proposed where the estimated model from iteration k ‚àí1
is used in the noise model at iteration k.
In virtual reference feedback tuning (VRFT) data is used to optimize
the controller such that ‚à•T (G‚ó¶, C) ‚àíTd‚à•2, where Td
minimized.
means that ‚à•U(G‚ó¶, C)‚à•2, see (73), is minimized with
T (G‚ó¶, C‚ó¶) = Td. The approximation U(G‚ó¶, C), see (74), is
used and it is observed that U(G‚ó¶, C) can be rewritten as
(1 ‚àíTd)Td(C(T ‚àí1
G0 ‚àíG0) ‚àí1). The L2-norm of this
expression can thus, in the limit N ‚Üí‚àû, be minimized
H. Hjalmarsson / Automatica 41 393‚Äì438
by minimizing the sum of squares of
(1 ‚àíTd)Td(C(rTd ‚àíy) ‚àíu)
with respect to C for an arbitrary noise free data set ZN.
The signal rTd = T ‚àí1
y is called the virtual reference signal.
At Ô¨Årst glance this procedure might seem unrelated to
the preÔ¨Åltering approach discussed in this section. However, the relation (76) between U(G‚ó¶, C), used in VRFT,
and V (G, C(G)), used in the preÔ¨Åltering approach, suggests that there is a close connection. In fact, with the direct
parametrization (60) we see that VRFT corresponds to minimizing ‚à•V (G(C), C)‚à•2, i.e. VRFT can be interpreted as a
preÔ¨Åltering approach using the direct parametrization (60).
A variant of the preÔ¨Åltering approach is proposed in
Holmberg, Valentinotti, and Bonvin . Data are collected in closed-loop with some controller C and from this
data set a model of the complementary sensitivity function
is estimated from which an estimate ÀÜS(G‚ó¶, C) of the sensitivity function S(G‚ó¶, C) can be obtained. Based on (68),
S(G, C)C ÀÜS(G‚ó¶, C) is then used as preÔ¨Ålter in the identi-
Ô¨Åcation. Notice that there is no guarantee either that this
procedure will Ô¨Ånd the model that minimizes V (G, C(G)).
Based on the simplifying assumption that the model error is
only due to noise, an attempt to take the model uncertainty
into account in the control design is done in Holmberg et
al. .
8.7. Data dependent preÔ¨Ålters
A non-parametric estimate of G‚ó¶is given by ÀÜ
xr is a non-parametric estimate of the crossspectrum between r (see Fig. 9) and x. Now, replacing the
true G‚ó¶by this estimate in (62) gives the cost function
, C(G), G, C(G)
S(G, C(G))C(G)
It can be shown that this cost function asymptotically (in
N) converges to ‚à•J(G‚ó¶, C(G), G, C(G))‚à•=‚à•V (G, C(G))‚à•
and that consequently the minimizing G also asymptotically minimizes the desired objective, provided that the the
spectral estimates are consistent . The method can be seen as a simpliÔ¨Åed version of
the optimal method outlined in Section 8.1 with the nonparametric estimate replacing the asymptotically efÔ¨Åcient
ML-estimate.
The cost function (78) can be expressed in the time domain
NM(w)TNM(r))‚àí1TT
NM(ŒµL())TNM(r)‚à•,
ŒµL() = S(y ‚àíG()u),
and where TNM(z) is deÔ¨Åned as as the (N + M ‚àí1) √ó M
lower Toeplitz matrix with [z(0), . . . , z(N ‚àí1), 0, . . . 0]T in
the Ô¨Årst column. Using the Frobenius norm in (79), results in
that the L2-norm is obtained asymptotically in (78) whereas
the 2-norm will result in that the norm in (78) is the L‚àûnorm .
We remark that with the cost function (79) as starting
point it is not obvious that this method actually is a two step
procedure involving a non-parametric estimate of the true
system in the Ô¨Årst step.
8.8. Minimizing average performance degradation
Up till now we have in this section assumed that the same
controller C( ÀÜGN) is used on the true system as on the nominal design. It is possible to obtain an achieved performance
closer to the nominal performance T ( ÀÜGN, C( ÀÜGN)) by replacing C( ÀÜGN) with the controller C which minimizes the
average performance deterioration
E{J(G‚ó¶, C, ÀÜGN, C( ÀÜGN))},
where the expectation is over G‚ó¶in the set of unfalsi-
Ô¨Åed models. This has been explored in Goodwin, Wang,
and Miller , see also Goodwin, Graebe, and Salgado
8.9. Stability, performance and robustness
It may be tempting to conclude that since the nominal design M(G, C) is stable and since ‚à•V (G, C)‚à•(67) is minimized, the achieved closed-loop system T (G‚ó¶, C) is stable.
The truth of this, however, depends on the norm that is used.
In relation to (67) we note that H2- or H‚àû-norms are suitable. However, the methods discussed previously in this section are based on frequency domain expressions that do not
take stability into account, i.e. the norms are of L2 or L‚àû
type. Hence, even if we, as in the case of data-dependent
preÔ¨Åltering, are able to generate the ideal cost function (67),
we get no information whatsoever whether the minimizing
controller stabilizes the true system or not, with one exception and that is when we can match T (G0, C) with T (G, C)
perfectly. One exception to this is the method in Landau et
al. which uses signals generated by closed-loop simulation.
We will use a simple example to illustrate this using
the method presented in Campi et al. . It should be
stressed though, that the problem is not speciÔ¨Åc to this
but intrinsic to all methods which solely aim at
minimizing ‚à•V (G, C(G))‚à•.
4 This method is chosen because of the simple calculations.
H. Hjalmarsson / Automatica 41 393‚Äì438
Example 8.1. Let the true system be a pure time-delay
y(t) = u(t ‚àí1). Suppose that a simple proportional controller C =  is used on the time-delay system. Notice that
the closed-loop is unstable for || > 1.
Let the desired complementary sensitivity function be
Td(ej) = 1 ‚àí + e‚àíj where the parameter  will be discussed later. Clearly, Td cannot be achieved no matter what
controller is used unless  = 1.
Consider now the error signal (77). It can be shown that
when the input is white noise with zero mean and unit variance, then E[Œµ2(t, )] is minimized by
opt = 4 ‚àí1
Hence, for 0 <  < 0.1, |opt| > 1 and the corresponding
closed loop system will be unstable. Hence stability is not
ensured when the desired closed-loop cannot be matched by
the actual closed-loop.
We conclude from Example 8 that the performance speci-
Ô¨Åcations have to be matched to the approximating ability of
the model and that to ensure stability some robust stability
condition has to be included. This in turn means that it is not
sufÔ¨Åcient for a method to be able to tune the bias error optimally, a method also has to be able to provide bounds for the
model error and these have to be accounted for in the control
As we saw in Section 7.6 (Trade-off 1), it becomes typically increasingly expensive to obtain sufÔ¨Åcient process information to ensure robust performance (and stability) as the
bandwidth is increased. Hence, it is natural to gradually increase the speciÔ¨Åed bandwidth. This was recognized in Lee
et al. where the term ‚Äúthe windsurfer approach‚Äù, alluding to how a windsurfer gradually improves his/hers performance, was coined.
An early reference to iterative identiÔ¨Åcation and robust
control is Bayard, Yam, and Mettler . Another contribution is de Callafon and Van den Hof . The issue of
ensuring that the collected information guarantees improved
performance is not addressed (Eq. (4) in de Callafon & Van
den Hof ), instead considerable effort is spent on how
to select uncertainty descriptions and the control design so as
to allow computationally feasible solutions. Interesting applications of this method are reported in de Callafon and Van
den Hof and BZjstrup, Niemann, KjZlstad Poulsen,
and JZrgensen .
Another way to cope with the robustness issue is to introduce caution in controller updates. Assuming the present
controller to be stabilizing (but providing unsatisfactory
performance), the increment in the controller update is limited so as to ensure stability also with the new controller
 .
In Section 8.11 we will discuss a quite different approach
based on robust control.
8.10. Control relevant near-optimal models
In Section 7.1.2 we saw that using a good nominal control
design combined with a model that makes the magnitude of
the weighted relative model error  (deÔ¨Åned in (53)) sufÔ¨Åciently small leads to robust performance, cf. (56). Similar
conclusions were drawn in Section 7.6. We shall now pursue
this idea.
For a full-order model, || is, frequency by frequency,
bounded by (see (66))
T ( ÀÜGN, C( ÀÜGN))
2 (n)n,N
For a near-optimal model5 the bound has to be multiplied
by a factor 2.
Now consider the scenario that the data set ZN is given
and it is required that |()| is bounded by some function.
Then, Ô¨Årstly in order to have a handle on the model error
frequency by frequency, the model complexity has to be
chosen such that the model is near-optimal. Furthermore,
the remaining variable at the user‚Äôs disposal is T which has
to be chosen sufÔ¨Åciently small that the condition on || is
When the input design is at the user‚Äôs disposal, there is
considerably more freedom for the user. For given performance speciÔ¨Åcations and with no restrictions on the model
complexity, (iii) in Section 6 gives that the input should be
designed such that (80) is less than one but not smaller than
necessary. This will give data that are sufÔ¨Åciently informative for the given performance speciÔ¨Åcations while at the
same time minimizing the modeling requirements.
8.11. Preferential identiÔ¨Åcation
So far in this section, the objective has been to ensure
that the identiÔ¨Åcation is performed such that the difference
in performance between the nominal design (using the identiÔ¨Åed model) and the actual design is small, as measured by
the function V. When the control design minimizes an explicit criterion, it is natural to instead study the problem of
how to identify a model ÀÜGN such that this criterion is minimized for the true system when the controller based on ÀÜGN
is used. This problem can be addressed using the separation
principle in a way similar to what was done in Section 8.1.
However, we will not pursue this idea further but instead
discuss an interesting approach pioneered in Krause, Stein,
and Khargonekar for adaptive control.
A bit simpliÔ¨Åed, the idea in Krause et al. can be
summarized as follows:
(i) Use a robust control law: assume that there is a robust
control law C(
) such that when the system signals
5 Recall, see Section 4.4, that a near-optimal model is any model
within the conÔ¨Ådence region of a full-order model.
H. Hjalmarsson / Automatica 41 393‚Äì438
{y(t), u(t)}N
t=t‚ó¶in a closed-loop experiment with this
controller are consistent with certain modeling assumptions parametrized by some vector
(t‚ó¶is a time offset
to allow for a transient phase where the assumptions are
not satisÔ¨Åed), then a certain closed-loop performance
) is guaranteed for this experiment.
One example of modeling assumptions is that
gk u(t ‚àík)
|u(t ‚àík)|2 + c,
with n‚©æm, and
= [g1, . . . , gm, , c]T. Notice that
the bound  on the unmodeled dynamics and the noise
bound c are not assumed known. Notice also that, and
this is important, the assumption regarding the control
law does not mean that the system signals have to satisfy the modeling assumptions for any input; they just
have to be consistent with the assumptions for the experiment at hand.
(ii) Use uncertainty model unfalsiÔ¨Åcation: use an identiÔ¨Åcation method which is able to estimate
on-line and
in closed-loop such that the estimate,
t say, converges
in Ô¨Ånite time t = t‚ó¶< ‚àûwith the estimate
consistent with {y(t), u(t)}t
When (i) and (ii) are satisÔ¨Åed, it follows immediately
that for the adaptive controller C(
t), performance for
{y(t), u(t)}t
t=t‚ó¶is guaranteed by Œ• (
Remark 1. Notice that the obtained
t‚ó¶need not correspond
to a ‚Äútrue‚Äù
, i.e. it does not have to be valid for all possible
inputs to the system; from (i) it sufÔ¨Åces that it holds for the
particular experiment. The same
t‚ó¶does thus not guarantee
performance Œ• (
t‚ó¶) in a new closed-loop experiment. It may
not even guarantee stability.
Remark 1 points to that this is a quite different approach
from what we would normally perceive as robust control.
This seems to be the price paid for not using a priori knowledge of a set to which the true system belongs.
There is considerable freedom in choosing the estimation
algorithm in (ii) and this freedom can be used to achieve
the same performance guarantee as if the true system was
known. In preferential identiÔ¨Åcation , one chooses the model which promises
the best performance for the controller:
t = arg min
where Mt denotes a set which includes all
that cannot be
falsiÔ¨Åed by data up to time t.
Now if (ii) holds for the estimator (82), it holds that performance is guaranteed by Œ• (
t‚ó¶). Suppose now that
a valid description of the true system, meaning that (81)
holds regardless of which input is applied. Then
t =1, 2, . . ., and in view of (82) it holds that Œ• (
The actual performance guarantee after the estimates have
converged is thus at least as good as if a valid
known from the beginning and used for the control design.
Clearly, a very powerful result.
The key issue in the approach is to ensure convergence
of the algorithm. For a generalization of (81), a dead-zone
is used in the parameter update in Sokolov . This
ensures convergence in Ô¨Ånite time without any persistence
of excitation conditions. Notice that the bounds  and c
are not known in advance! The dead-zone implies a slight
degradation of the performance guarantee. One shortcoming
of this algorithm is that the adaptation horizon t‚ó¶is not
known in advance, so that one may have to wait a long
time until convergence and during this transient phase no
performance guarantees are available.
There are various ramiÔ¨Åcations of the above idea, e.g.
Veres and Sokolov and Sokolov . Furthermore,
Veres has adapted the concept to iterative identiÔ¨Åcation and
control .
Computational and complexity issues are the topics of Veres,
Messaoud, and Norton and Xia and Veres .
To conclude, in contrast to the methods in Section 8.5, the
robust control/uncertainty model unfalsiÔ¨Åcation/preferential
identiÔ¨Åcation paradigm has, subject to the limitations discussed above, proven able to produce iterative identiÔ¨Åcation
and control methods which converge with performance gurantees.
9. Direct identiÔ¨Åcation of restricted complexity models
for control: non-linear systems
There is abundant practical evidence that LTI models often
are sufÔ¨Åcient for control design for non-linear systems. In
this section we will discuss some related issues. We will
limit attention to SISO systems.
From a system identiÔ¨Åcation perspective it is of interest
to know how much uncertainty robust (and adaptive) control
can handle. In a series of paper, partly summarized in Guo
 , Guo and co-workers have explored this topic.
9.1. Performance aspects
Let us assume that the system G‚ó¶in Fig. 9 is non-linear
and noise-free and also that w ‚â°0. Let us also assume that
a linear model G is used to design an LTI model reference
controller (59). We will now discuss how to Ô¨Ånd a suitable
model G such that the non-linear feedback system consisting
of the non-linear system and the linear controller deÔ¨Åned
by (59) responds to r with the desired response yd = Tdr.
In Sections 8.1‚Äì8.3 we discussed how restricted complexity
models for LTI systems could be identiÔ¨Åed in closed-loop.
When a non-linear full-order model is available, the method
outlined in Section 8.1 can be adapted to the non-linear
setting. When this is not the case, the ideas in Section 8.3
of closed-loop identiÔ¨Åcation can be used. Notice that no use
H. Hjalmarsson / Automatica 41 393‚Äì438
of that the system is LTI was made in the derivation (70).
Hence, for any system,
y ‚àíTdr = y ‚àíyd = (1 ‚àíTd)(y ‚àíGu),
where u and y are the closed-loop signals with the controller
C = C(G) deÔ¨Åned in (59) in the loop. This expression for
y ‚àíyd was derived in this non-linear setting in Henriksson,
Markusson, and Hjalmarsson and similar observations have been made in Horowitz . Thus, if there is
a model G‚àósuch that the corresponding model C(G‚àó) results in y = yd, then the right-hand side of (83) will be zero
when G = G‚àóand when data is collected with C(G‚àó) as
the controller in the loop. This implies that the model G‚àó
corresponding to the desired controller will be obtained in
closed-loop identiÔ¨Åcation when the desired C(G‚àó) is operating in the loop and if the preÔ¨Ålter 1 ‚àíTd is used in the
identiÔ¨Åcation .
Notice that since the system is non-linear it may very well
happen that G‚àóis non-causal in which case the above idea
breaks down.
Disregarding this, the discussion above supports the intuitively appealing idea that the identiÔ¨Åcation experiments
should be carried out under the desired operating conditions.
A limitation of the argument above is that it is based on
studying one single trajectory and, hence, does not give any
information about the behavior for other reference signals,
and in particular of closed-loop stability. We will return to
how to generate the desired operating conditions in Section
11.3.2 where also an example is presented.
9.2. Control relevant near-optimal models
In Section 8.10 the approach was to ensure robust stability and robust performance by making || small. The motivation was the arguments brought forward in Section 7.6
which in turn were based on the factorization (64) (or the
simpler expression (67)). Now this factorization generalizes
to the non-linear case . For example, (67) still holds where now G‚ó¶is to be interpreted as a
non-linear operator. Furthermore, bounds such as (65) apply if the largest singular value is replaced by some induced
norm it is suggested to use an
induced differential norm as this reduces the conservatism).
For example, the norm of  is bounded by
‚à•T (G, C)W‚à•‚àû
W ‚àí1 G‚ó¶‚àíG
where the second norm is the induced L2-norm
‚à•G‚à•i,2 = sup
where ‚à•u‚à•2=
k |u(k)|2. Above W is an arbitrary linear6
weighting Ô¨Ålter.
6 Invertible non-linear operators can also be used.
This means that when a linear model and linear control
design is sought for a non-linear system, the minimization
of the weighted relative error is still a valid criterion.
In Section 4.4 we discussed near-optimal LTI models of
systems that were themselves LTI. The conclusions from
this section also extend to non-linear systems. This means
that for a non-linear parametric model structure, to which
the true system belongs, the simplest unfalsiÔ¨Åed model can
be used with the total error being less than two times that of
the full-order model structure. Thus, if there is an LTI model
within the conÔ¨Ådence region for the full-order model, this
model can be used. If it exists, such an LTI model can be
obtained by direct least-squares identiÔ¨Åcation as described in
Section 4.4. We remark that it may be non-trivial to compute
the maximum error gain between the model corresponding
to the center of the full-order conÔ¨Ådence region and a model
inside this region. This is, however, an issue more related to
non-linear systems analysis than system identiÔ¨Åcation.
From the above follows that the approach in Section 8.10
carries over to the non-linear setting.
In Ljung the choice of weighting Ô¨Ålter and how
to estimate the non-linear gain ‚à•W ‚àí1(G‚ó¶‚àíG)/G‚à•are discussed. It is pointed out that only lower bounds can be obtained from data and that periodic inputs can be useful since
they allow the noise to be averaged out. Another preliminary contribution in this important area is Schoukens, Pintelon, and Dobrowiecki and in Mosskull, Wahlberg,
and Galic these ideas are used to verify stability of
an induction machine drive.
This issue has also spurred activities in assessing how
‚Äúsmall‚Äù nonlinearities may inÔ¨Çuence parameter estimates
based on linear models. In Enqvist and Ljung it is illustrated that LTI-models may be extremely sensitive to nonlinearities. In Schoukens, Dobrowiecki, and Pintelon 
a general framework is developed for analyzing how linear
estimates are affected by non-linearities of the system when
the input excitation is periodic. For a concise survey of this
framework see Schoukens, Pintelon, Dobrowiecki, and Rolain . Best LTI-approximants for non-linear systems
are discussed in M√§kil√§ & Partington and Enqvist &
Ljung .
9.3. High-order modeling
A three step procedure is proposed in Ling and Rivera
 for identiÔ¨Åcation of control relevant non-linear models. First a non-linear ARX model is estimated. This model
is then transformed into a Volterra series model since such
a model is more applicable to existing control design methods. Finally, a non-linear counterpart to the model reduction
procedure discussed in Section 8.4 is performed.
10. Direct controller tuning
In this section we will discuss two controller tuning
methods, unfalsiÔ¨Åed control and Iterative Feedback Tuning
H. Hjalmarsson / Automatica 41 393‚Äì438
(IFT), where data is mapped directly into the controller. Another method with this property is virtual reference feedback
tuning, cf. Section 8.6. As for VRFT, unfalsiÔ¨Åed control and
IFT were derived without any explicit use of models. However, it is instructive to, as was done for VRFT, also interpret these methods in a modeling framework and this is the
objective of this section.
10.1. UnfalsiÔ¨Åed control
Suppose that some apparatus is going to be constructed
that, when applied to the system, performs a certain task
and that, given only input/output data ZN from the system
and no prior system information whatsoever, we would like
to verify if the designed system satisÔ¨Åes some performance
speciÔ¨Åcations. To be speciÔ¨Åc, let us consider the problem of
testing whether a certain controller C satisÔ¨Åes some given
performance speciÔ¨Åcations. Well, if the controller satisÔ¨Åes
the performance on at least one of the models in the set of
unprejudiced unfalsiÔ¨Åed models G(ZN) (see Section 2.2),
then the controller C cannot be discarded since that particular model may correspond to the true system in which case
the controller would satisfy the speciÔ¨Åcations. We would in
this case say that the controller is unfalsiÔ¨Åed. However, since
the models in G(ZN) have completely arbitrary input/output
behavior, except for the speciÔ¨Åc input‚Äìoutput trajectory de-
Ô¨Åned by ZN, which they all share, it is possible to Ô¨Ånd an unfalsiÔ¨Åed model such that the closed-loop system consisting
of this model and C satisÔ¨Åes every speciÔ¨Åcation that is not
violated when the closed-loop system with C as controller
exhibits the input/output behavior ZN. As we will see, this
makes it often very simple to check whether a given controller can be falsiÔ¨Åed or not by data only. The idea of unfalsiÔ¨Åed control was introduced by Safonov and co-workers
 , see also Kosut .
To illustrate the machinery suppose that the input is generated by a one-degree of freedom controller
u = C(r ‚àíy),
where r is an external reference signal. Suppose also that
a reference model Td is given and that our performance
speciÔ¨Åcations are
‚à•y ‚àíTdr‚à•2‚©Ω‚à•r‚à•2,
‚àÄr : ‚à•r‚à•2 < ‚àû
for a given constant . We now ask the following question:
Given arbitrary input/output data ZN, what can be said about
which controllers satisfy (86)? The key to resolving this
problem is to note that it follows from (85) that for arbitrary
input/output data u, y from the system, the signal
is the reference signal r which with C in the loop would
produce exactly the input/output data u, y. Hence, given
arbitrary input/output data ZN, we can think of the corresponding {rC(t), y(t)}N
t=1 as a (Ô¨Åctitious) closed-loop
data set with the controller C in the loop. The controller is
falsiÔ¨Åed precisely when the speciÔ¨Åcation (86) is not satisÔ¨Åed
for the speciÔ¨Åc signal pair {rC(t), y(t)}N
By, for each time instance, selecting the controller in the
set of unfalsiÔ¨Åed controllers according to some selection
rule, an adaptive unfalsiÔ¨Åed controller is obtained . It has, e.g., been suggested to pick the
most promising controller according to the criterion function which governs the unfalsiÔ¨Åcation process , cf. the discussion on preferential identiÔ¨Åcation in Section 8.11 where the most promising model was
UnfalsiÔ¨Åed control can be given an even Ô¨Årmer relation
to model based control. Under LTI assumptions, the unfalsi-
Ô¨Åed controller that minimizes (86) restricted to r = rC (87),
corresponds to the preÔ¨Åltering approach described in Section 8.6 with the L‚àû-norm employed (instead of the L2norm used in VRFT) and the direct parametrization (60) of
the model .
10.2. Iterative Feedback Tuning
Consider the problem of minimizing the norm of
V (G(C), C) (67) when model reference control is used, i.e.
we are trying to Ô¨Ånd a reduced order controller C that makes
the complementary sensitivity function as close as possible
to the Ô¨Åxed reference model Td. For simplicity, assume that
the system is noise free and w ‚â°0. Parseval‚Äôs formula gives
‚à•V (G(C), C)‚à•2
((T (G‚ó¶, C) ‚àíTd)r(t))2
with r being white noise. One approach is to minimize
(88) numerically using some descent algorithm such as
Gauss‚ÄìNewton. This was a popular approach in the 1950s
and early 1960s.
For this, the sensitivity, i.e. gradient, of (T (G‚ó¶, C)‚àíTd)r
with respect to C is required (or rather the parameters of C
but we will omit this from the discussion). Straightforward
differentiation gives
dC (T (G‚ó¶, C) ‚àíTd)r = C‚àí1T (G‚ó¶, C)(1 ‚àíT (G‚ó¶, C))r
= C‚àí1T (G‚ó¶, C)(r ‚àíy(C)),
where y(C) denotes the output of the closed-loop system
(47) with controller C in the loop, assuming w ‚â°0. Thus
we see that the above sensitivity can be obtained from the
closed loop system (9) under noise-free conditions with controller C in the loop by (1) Ô¨Årst performing an experiment
with r as reference and collecting the output y(C) and (2)
using r ‚àíy(C) as reference in a new experiment whose output is Ô¨Åltered through C‚àí1. In Narendra and Streeter 
an alternative approach where (1) and (2) were done simultaneously through an outer feedback with long time-delay
was proposed.
H. Hjalmarsson / Automatica 41 393‚Äì438
Iterative feedback tuning (IFT) is a generalization of the idea above. The sensitivities of the closed
loop signals with respect to the controller parameters are
computed from two closed-loop experiments as outlined
above. It can be shown that, even in the presence of noise, the
signal sensitivities are unbiased (modulo transient effects)
and hence it is possible to guarantee that any convergence
point of the algorithm corresponds to a stationary point of
the desired objective function by the use of a stochastic
approximation algorithm. The idea can be applied to any,
differentiable, signal based objective function, i.e. not only
(88). IFT has been applied by the chemical multinational
Solvay SA for tuning of PID loops in distillation columns
and evaporators .
From (89) we may also deduce other ways to approximate
the sensitivity. The separation principle in Section 4.2 gives
that if a good estimate ÀÜT of T (G‚ó¶, C) is available, then a
good sensitivity estimate is obtained by replacing T (G‚ó¶, C)
by ÀÜT everywhere in the middle expression of (89).
In De Bruyne and Carrette and Kammer, Bitmead,
and Bartlett it is suggested to avoid the second experiment by replacing T (G‚ó¶, C) in the right-hand side expression of (89) by an estimate obtained using closed-loop data
when C is operating in the loop. In De Bruyne and Carrette
 a parametric model is used whereas a non-parametric
model is employed in Kammer et al. .
The use of signal sensitivities can be seen as local modeling (around the current controller parameters) of how the
closed-loop signals depend on the controller. This has the
important implication that IFT is able to cope with certain
nonlinearities also, cf. Hjalmarsson and Sj√∂berg and
De Bruyne . See also Sj√∂berg et al. for an algorithm tailored especially for non-linear systems.
10.3. De-correlation
An interesting approach is presented in Karimi, Miskovic,
and Bonvin where the controller is tuned such that
y ‚àíyd, where yd is the desired response, is un-correlated
with an instrumental vector which is a function of lagged
values of the reference r. It is shown that this can be done
iteratively as in IFT but that only one experiment is required
per iteration.
11. Experiment design
The reader may have noticed that input design has been
a recurring theme up to now. Let us recapitulate:
‚Ä¢ When the true system is in the model set, (36) gives a
bound on the frequency responses for unfalsiÔ¨Åed models
which depends on the input through the input spectrum as
well as through n,N(), cf. (34).
‚Ä¢ In Section 5.3 we saw that (36) also determines the
strength of any validation statements that can be made.
‚Ä¢ From (iii) in Section 6 we may conclude that an ideal
experiment should reveal exactly the information required
for the control design.
‚Ä¢ In Section 7.6 we saw explicitly in (66) how the, for control, important weighted model error (53) depends on the
experimental conditions.
‚Ä¢ In Section 4.4 it was illustrated that by choosing the input
suitably, the statistical properties of restricted complexity
estimators may be similar to those of the ML-estimate.
One may think of this as that the model bias is tuned by
the data. This relates to our observations in Section 9.1
where it was indicated that using data from the desired
operating conditions is very useful when trying to identify
a restricted complexity model for a non-linear system.
Going back to Section 8.5, we see that this is exactly the
reason why closed-loop identiÔ¨Åcation may help to obtain
‚Äúcontrol relevant‚Äù models for LTI systems as well.
In this section we shall further discuss how experiment design can be used to improve the closed-loop performance.
In Section 11.1 we Ô¨Årst discuss input design for optimal
average performance. We argued in Section 7.2 that the very
high complexity of an optimal input design problem for a
typical control application makes such problems intractable
(at least with existing mathematical machinery). However,
by considering the weighted relative model error, introduced
in Section 7.6, tractable problems can be obtained. We have
already touched on this issue in Section 8.10 and we will
pursue this in Section 11.2 by taking the input design into
Another impeding factor in the use of optimal experiment
design is that the optimal solution depends on the unknown
true system. This problem could be handled by input designs which are robust against uncertainty about the underlying system were it not that also here computational complexity puts severe restrictions on what can be achieved. It
also seems as if robust input design has received very little attention. Apart from the very modest contribution in
Hjalmarsson and Jansson , the author is not aware of
any contributions to this area and we will discuss this topic
very brieÔ¨Çy in Section 11.2.
An alternative, or complement, to robust input design is
adaptive input design where the information gathered in the
experiment is continuously, or batch-wise, used to update
the input design. This is discussed in Section 11.3. Related
to this is the use of pre-tests to gain some preliminary information for further experiment design. This is the topic in
Section 11.4.
Experiment design for multivariable systems is brieÔ¨Çy
discussed in Section 11.5. Finally, Section 11.6 is concerned with certain aspects of input design for near-optimal
A very important part of the experiment design is to ensure
that the input is ‚Äúplant-friendly‚Äù. This means that, apart from
generating informative experiments, the input should be in
line with industrial demands. We will not venture further into
H. Hjalmarsson / Automatica 41 393‚Äì438
this topic but the reader is referred to Rivera, Lee, Braun, and
Mittelmann and Parker, Heemstra, Doyle Pearson,
and Ogunnaike and references therein.
11.1. Optimal average performance input design
One approach to input design is to minimize the average of some performance degradation measure with respect
to the input, subject to constraints on the input and output
spectra. The constraints have traditionally been of L2 type.
One may, e.g., use (recall (63))
E{‚à•V ( ÀÜGN, C( ÀÜGN))‚à•2
where the expectation is over ÀÜGN, as design criterion. An
approximate solution can be derived using the Ô¨Årst order
approximation (71) of V ( ÀÜGN, C( ÀÜGN)), i.e. by instead minimizing
E{‚à•V ( ÀÜGN, C( ÀÜGN))‚à•2
This leads to a so called L-optimal input design problem
where the weighted trace of the covariance matrix (20)
should be minimized. Here the weighting matrix depends
on the problem formulation.
It has been more common to consider
E{‚à•J(G‚ó¶, C(G‚ó¶), G‚ó¶, C(G))‚à•2}
as criterion, which again via a Taylor approximation leads
to an L-optimal input design problem. As mentioned in
Section 7.6, the two criteria (90) and (92) coincide when
M(G, C(G)) is independent of G. One such example is
model reference control. Also minimum variance control of
minimum phase systems Ô¨Åts into this category if, as is relevant for this problem, J in (62) is replaced by the difference
in transfer functions from the white noise disturbance e in
(25) to the output between the true system and the model.
Starting with the now classical reference , there have been a series of contributions to the above
problem based on the variance expression (28) using the
high-order approximation (32), and its closed-loop counterpart, with speciÔ¨Åc applications to identiÔ¨Åcation for control.
When there is a constraint on the output variance, the optimal experiment is to use a controller which is the solution
to an LQG-problem determined solely by the constraints
 . Thus applications with different
objective functions but with the same constraints share the
same optimal experiment. Hence, the optimal experiment is
typically in closed-loop in this case. However, it is worth
noticing that when the noise is white, the solution to the
associated LQG-problem is open loop operation when only
the output variance is constrained.
Instead of relying on (32), the variance expression (29)
can be used directly for input design . In Cooley and Lee 
it is suggested to optimize directly over the input sequence
whereas in Lindqvist and Hjalmarsson it is shown
that when u is the output of a FIR-Ô¨Ålter driven by white noise,
the optimal Ô¨Ålter coefÔ¨Åcients can be computed by convex
optimization. Since any spectrum can be approximated by a
FIR-process the approach is in principle generally applicable. However, when large lags are required, computational
complexity becomes an issue. One can then use other basis functions . Designs for
FIR systems in the case of periodic or Ô¨Ånite samples are discussed in Lee and Jansson and Hjalmarsson .
11.2. H‚àûand robust input design
The designs in the preceding section are all geared towards optimizing the average performance as they are based
on (91) (or (92)). By instead using the bound (66) on the
weighted relative model error  as design criterion, an H‚àû
type of design is obtained with guaranteed robust stability
and robust performance .
A typical problem formulation could be (recall (21))
subject to
T G0 ‚àíG()
( ‚àío)T RN
 ( ‚àío)‚©Ω2 (n),
u() d‚©Ω.
Here the constraints state that the weighted relative error
(recall (53)) || should be smaller than some pre-speciÔ¨Åed
value P for all frequencies  and for all models in the conÔ¨Ådence region (23) (which is given by the second constraint).
Thus the minimum input energy required to meet this objective, and the corresponding input spectrum, are sought. This
type of problem has been coined ‚Äúleast-costly identiÔ¨Åcation
experiments‚Äù in Bombois, Scorletti, Van den Hof, and Gevers . Following (iii) in Section 6, we have that the
bound P should be made small, but not too small in order
to limit the modeling requirements.
It turns out that this type of problem can be approximated by a convex optimization problem that gives solutions close to the optimum . We illustrate with an example.
Example 11.1. The true system is given by
1 ‚àí0.7q‚àí1 u(t) + e(t),
where e(t) is zero-mean white noise with variance 0.1. We
want to estimate a model
1 + aq‚àí1 ,
 = [a b]T,
based on N = 500 samples of input/output data. The input design problem is formulated as in (93) with P = 0.1,
2 (n) = 5.99 (which corresponds to a conÔ¨Ådence level of
95%) and with T given in Fig. 12.
H. Hjalmarsson / Automatica 41 393‚Äì438
Fig. 12. Magnitude plot for Example 11.1. Thick solid line: optimal input
spectrum. Dashed line: white input spectrum with same power as the
optimal input. Thin solid line: desired complementary sensitivity function.
Dash‚Äìdotted line: open loop system.
Fig. 13. Example 11.1. Dots: the estimated model parameters from 1000
Monte Carlo runs based on input design (93). Dashed ellipse: estimated
95% conÔ¨Ådence bound for the parameters for design (93). Dotted ellipse:
conÔ¨Ådence bound when the input is white noise with the same energy
as the design of (93). Contour lines with interval 0.025 are plotted for
‚à•‚à•‚àûand ‚à•‚à•‚àû= 0.1 corresponds to the thick solid contour.
The minimum input power is  = 0.28 with the resulting
input spectrum shown in Fig. 12. The ‚Äúringing‚Äù (barely visible) in the input spectrum at high frequency is due to the
FIR-Ô¨Ålter (order 20) used to shape the input.
Fig. 13 shows the parameter estimates of 1000 Monte
Carlo runs. We see that the estimated models are clustered
inside the contour ‚à•‚à•‚àû= 0.1 as desired. In fact, 96.7%
of the estimated models satisfy the performance constraint.
The reason for a higher percentage compared to the speciÔ¨Åed
95% is due to that also some estimates outside the conÔ¨Ådence
ellipsoid are inside the level curve ‚à•‚à•‚àû= 0.1, see Fig. 13.
It should be noted that, as usual in experiment design, in
order to compute the optimal design in the example, the true
system has to be known. Methods that are robust with respect
to uncertainty about the system is a wide open research Ô¨Åeld.
Optimal input design for low order models may sometimes produce counterintuitive designs. This can be attributed to the strong extrapolation properties over the
frequency axis for low order models. The behavior, and,
hence, the accuracy, at one frequency is highly coupled
to the behavior at another frequency. The input spectrum
obtained in Example 11.1 is quite reassuring in this aspect.
Despite a Ô¨Årst order model, the input energy is largest in the
frequency region between the open loop systems cross-over
frequency and the designed closed-loop system bandwidth.
This is in complete consistency with the discussion of the
performance speciÔ¨Åcations versus experimentation effort
(Trade-off 1) in Section 7.6.
In Section 7.1.2 we saw that robust stability is tied to the
-gap. From Proposition 7.1 we see that the larger the maximum -gap is for a model set, the larger the generalized stability margin bG,C has to be in order to guarantee stability
for systems belonging to the model set. In particular if the
maximum -gap exceeds 1, stability cannot be guaranteed.
This is the motivation for the work in Hildebrand and Gevers which presents a method for minimizing (with
respect to the input spectrum) the worst-case -gap taken
over all models in the conÔ¨Ådence region (23) produced by
prediction error identiÔ¨Åcation.
11.3. Adaptive input design
As we have seen, in the early 1990s several schemes that
iterated between identiÔ¨Åcation and closed-loop control were
proposed. In fact, it was suggested, Schrama, 1992, that high
performance control based on restricted complexity models
required such iterations. However, as we have indicated in
Sections 7.6 and 8.1, this is not necessarily so. It has also
been shown , that the example in
Schrama can be solved without iterations. So the
question is rather what can be gained by iterating between
identiÔ¨Åcation and experimentation?
Clearly, when we are collecting data, we obtain new information about the system. Hence, iterating between identi-
Ô¨Åcation and experimentation is beneÔ¨Åcial if we can improve
our experiment design such that more control relevant information becomes available than if we would have stayed
with our present design. We have seen that there are two
quantities to consider:
‚Ä¢ Minimizing variance. The input should be chosen such as
to minimize the impact from the noise induced errors in
the controller C( ÀÜGN) on the achieved closed-loop performance.
‚Ä¢ Tuning the bias. When the model set is restricted it is important that data contains the features relevant to control.
This is embodied in that the desired operating conditions
should be mimicked as closely as possible.
We remark that these two objectives may be conÔ¨Çicting.
H. Hjalmarsson / Automatica 41 393‚Äì438
11.3.1. Minimizing variance: adaptive input design for LTI
One of the few instances where it has been possible to
prove that iterative identiÔ¨Åcation and control design actually
improves performance is when a full-order model is used
for minimum variance control design. Under the assumption that (32) is valid, it was shown in Hjalmarsson, Gevers,
and DeBruyne that iterating between identiÔ¨Åcation
and subsequent certainty equivalence input design, and experimentation will always improve the average performance
compared to any Ô¨Åx input design (other than the optimal),
provided the experiment time is sufÔ¨Åciently long. Certainty
equivalence input design means that the last estimated nominal model is used instead of the true system in an optimal
input design. In such an approach it would be nice if the
optimal experiment design corresponded to the optimal controller since then such iterations would not conÔ¨Çict with the
control objective. Unfortunately, this seems to hold only for
minimum variance control .7
A potential problem with this approach is that instability
may occur during the identiÔ¨Åcation experiment if the optimal
experiment is in closed-loop and the certainty equivalence
design is based on a model of poor quality. An alternative
which avoids this problem is to tune the input spectrum
adaptively in open loop .
Adaptive designs are also considered in, e.g., Cooley and Lee
 , Lee , Rivera et al. and Lacy, Bernstein,
and Erwin .
11.3.2. Tuning the bias: adaptive input design for
non-linear systems
For non-linear systems, we have in Section 9.1 seen that
it may be advantageous to have the system operating under
the desired conditions when data are collected. It may seem
as if this would require that the system operates in closedloop using an already well-tuned controller which in turn
would mean that there is no need to retune the controller.
However, we would here like to draw the reader‚Äôs attention
to the fact that there exist open loop alternatives that are
competitive. One advantage with collecting data in open loop
is that stability is not an issue.
A systematic method to iteratively generate feed-forward
controls that approach a given output trajectory is iterative
learning control (ILC) . Given an initial ‚Äútrial‚Äù
input u0(t) over the time-horizon t = 1, 2, . . . , N, and the
target output trajectory {yd(t)}N
t=1, the input is iteratively
reÔ¨Åned using the error between the achieved output and the
target output as correction.A simple version of the algorithm
is to update the input at iteration k according to
uk+1(t) = uk(t) + Lk(yd(t) ‚àíyk(t)),
t = 1, . . . , N,
7 As pointed out in Forssell and Ljung this does not hold for a
two-degree of freedom model reference control as claimed in Hjalmarsson
et al. .
Fig. 14. Outputs used to identify linear models in Example 11.2. Solid
line: generated by one step of the ILC algorithm. Dashed line: generated
by white noise input. Dotted line: desired output (shown for comparison).
where Lk is some dynamical operator, typically LTI, which
has to be chosen such that the algorithm converges. It can
be shown, cf. Markusson, Hjalmarsson, and Norrl√∂f ,
that Lk plays the role of a model of the inverse of the system. Observe, e.g., that if Lk is the inverse of the true system, then the desired input will be produced in one iteration
of the above algorithm under noise free conditions. What
makes this algorithm interesting is that the model may be
changed between iterations. Hence, it may be possible to use
quite simple LTI models and still be able to generate an input which drives the system sufÔ¨Åciently close to the desired
operating conditions that data collected from these conditions subsequently can be used to identify a LTI model useful for control design .
Example 11.2. The Van de Vusse system is a non-minimum phase system often used as a
benchmark problem for non-linear process control algorithms . Here the kinetic parameters have been chosen such that the system is
described by
Àôx1 = ‚àí50x1 ‚àí10x2
1 + (10 ‚àíx2)u,
Àôx2 = 50x1 ‚àí100x2 ‚àíx2u,
around the equilibrium point. The objective (chosen solely
to illustrate the preceding discussion and not any speciÔ¨Åc
chemical process control problem) is that the complementary
sensitivity function has the same magnitude as
0.01s + 1.
The system is sampled with sampling time 0.72 s. One iteration in the ILC-algorithm (94) was taken with the initial
input being white noise. The inverse of a second order OE
model, identiÔ¨Åed around the initial trajectory, was used as
L0 in the algorithm. The resulting output (shown as the solid
line in Fig. 14) was used to identify a second order OEmodel on which an internal model controller was designed.
The closed-loop output is shown as the solid line in Fig. 15.
It follows the desired output (the dotted curve in the Ô¨Ågure)
H. Hjalmarsson / Automatica 41 393‚Äì438
Fig. 15. Example 11.2. Closed loop output. Solid line: controller designed
using model identiÔ¨Åed from ILC-data. Dashed line: controller designed
using model identiÔ¨Åed from white noise data. Dotted line: desired output.
quite well. For comparison, a model identiÔ¨Åed using a white
noise input (the output is the dashed line in Fig. 14) with
the same energy was used in the control design instead. The
corresponding closed-loop response is shown as the dashed
line in Fig. 15. The response is signiÔ¨Åcantly more oscillatory.
A more spectacular example can be found in Jansson and
Hjalmarsson where an inverted pendulum is controlled.
We also point out that should the process be operating in
closed-loop (as is often the case) with some poorly tuned
controller, ILC may still be used to generate a reference trajectory {r(t)}N
t=1 such that the operating conditions become
closer to the desired ones.
Another example of adaptive input design for non-linear
systems is Zhao and Kanellakopoulos . Here the system has known structure with linear regressions T
of observable, possibly, non-linear regressors that inÔ¨Çuence
the states. The system structure is such that by observing
the output it is possible to compute the linear combinations
k(t). The input is used to drive the system states such
that the regressors become linearly independent and hence
the unknown parameter vector  becomes identiÔ¨Åable.
11.3.3. Tuning the bias: using non-linear feedback
The relay experiment used in the relay auto-tuner method,
originally proposed in ÀöAstr√∂m and H√§gglund , can be
seen as a way of generating an experiment which provides
information such that the bias in a model is ‚Äútuned‚Äù for control. In Karimi, Garcia, and Longchamp the idea of
relay experiments is combined with tuning using gradients,
cf. Section 10.2.
11.4. Pre-tests ‚Äì Identifying performance limitations
The experiment design is eased signiÔ¨Åcantly if the inherent limitations of the system are known. Often amplitude and
slew-rate constraints on actuators, which limit the achievable bandwidth, are known and this knowledge should be
incorporated in the experiment design, cf. the discussion of
the control effort in Section 7.6.
Non-minimum phase zeros also limit the achievable bandwidth. An explicit variance expression has been derived
which can be used for designing pre-test experiments so that
these zeros can be accurately identiÔ¨Åed . An interesting aspect is that
the asymptotic accuracy of the identiÔ¨Åed zeros is basically
independent of the model order when the prediction-error
method is used. Hence, model order selection is not a critical issue here.
11.5. Input design for multivariable systems
Input design is perhaps most important for multivariable
systems, especially for ill-conditioned processes such as
high-purity distillation columns. To appreciate this, notice
that the low gain directions of the system will be poorly identiÔ¨Åed unless precautions are taken to ensure that the signal
to noise ratios are sufÔ¨Åcient in these directions. The problem
arises as the designed controller will use high gain in these
poorly identiÔ¨Åed directions which may be disastrous for the
closed-loop behavior when the model is poor. The key to
solving this is to use correlated inputs and both open loop
and closed-loop methods have been proposed to this end. In
Jacobsen an open loop grey-box experimental design
is proposed as well as a closed loop method. Another closedloop method is used in Zhu and Butoyi . A general
observation is that attempts to perform SISO identiÔ¨Åcation
on such plants will fail to deliver relevant models, cf. Zhu
and Butoyi and Jacobsen . The approaches in
Cooley and Lee and Lee , already discussed in
Section 11.1, are also applicable to multivariable systems.
11.6. Input design for near-optimal restricted complexity
In Section 4.4 we saw that near-optimal models of restricted complexity exist if the conÔ¨Ådence region for the
full-order model is large enough. For a model structure M
of a certain complexity and a given conÔ¨Ådence level , this
puts an upper bound on how much information from an experiment that is valuable from a statistical point of view. As
more information is added so that the least-squares estimate
for M is no longer inside the conÔ¨Ådence region (corresponding to level ) for the full-order model, there is no longer
any model in M which is near-optimal. Thus, if a certain
complexity of the model structure is pre-speciÔ¨Åed (as well
as the conÔ¨Ådence level), such an upper bound should be incorporated in the experiment design constraints.
12. Validation of control designs
In this section we will discuss some ideas for validation
of control designs. We will focus on validation of stability
H. Hjalmarsson / Automatica 41 393‚Äì438
but the ideas carry over to performance criteria as well. The
discussion will be limited to SISO systems.
12.1. Validating stability using the separation principle
Suppose that G is some model of the open loop system G‚ó¶
which is LTI and that C is an LTI controller which has been
designed using G such that the resulting complementary
sensitivity function is T (G, C). Then, as we have seen in
Section 7.1.2, the achieved closed-loop is guaranteed to be
where  = T (G, C)G‚àí1(G‚ó¶‚àíG).
Suppose that some input‚Äìoutput data set ZN is available
for validation of (95). In Section 5.4 we discussed general
principles for validation of restricted complexity models.
The advice was to use the separation principle. Here this
means Ô¨Årst forming a full-order estimate ÀÜGN of G‚ó¶using
the available data and then computing the estimate
N = T (G, C)G‚àí1( ÀÜGN ‚àíG),
and Ô¨Ånally forming a conÔ¨Ådence region for this estimate.
Using (36) gives
|N(ej) ‚àí(ej)|
2 (n)n,N()
which gives that if
|N(ej)| +
2 (n)n,N()
stability is guaranteed (with probability ).
12.2. Validating stability using power iterations
Suppose now that, instead of using a pre-determined data
set ZN, we have the option of choosing the input. For  LTI
and stable we have that the H‚àû-norm coincides with the
induced L2-norm (84) and that inputs that maximize the
ratio ‚à•u‚à•2/‚à•u‚à•2 are sinusoids with frequency where  has
maximum gain . Hence, it
would be easy to check (95) if such a sinusoid is used as
input. Unfortunately, this frequency is not known a priori
but one may envisage procedures which adapt the frequency
such that the gain is maximized. A simple method in this
spirit is as follows:
(1) Let k = 0 and select an arbitrary input sequence
t=1 with the constraint that ‚à•uk‚à•2 =  for some
constant  > 0.
(2) Perform an experiment where uk(t) is applied to G‚ó¶:
yk(t) = G‚ó¶(q)uk(t), t = 1, . . . , N.
Fig. 16. Magnitude curve of the frequency response in Example 12.1.
(3) Filter the corresponding output through the inverse of
G: G‚àí1yk(t).
(4) Subtract uk(t) from this signal: G‚àí1yk(t) ‚àíuk(t)
Neglecting disturbances, Steps 2‚Äì4 give the signal
zk(t) = (q)uk(t), t = 1, . . . , N.
(5) Let k = ‚à•zk‚à•2/.
(6) Let uk+1(t) = 1
k zk(N + 1 ‚àít), t = 1, . . . , N.
(7) Let k = k + 1 and go to Step 2.
The k computed in Step 5 is clearly an underbound to the
induced L2-norm (84) of .
When the experiments are noise free and performed under
zero initial conditions it can be shown that uk will, modulo
transient effects, converge to a sinusoid with approximately
the desired frequency. Furthermore,
where k, k = 1, 2, . . . are the impulse response coefÔ¨Åcients
of  and where the convergence is monotonic. Thus for N
sufÔ¨Åciently large, a good estimate of ‚à•‚à•‚àûis obtained.
In each iteration, it is the frequency where  has maximum
gain that is ampliÔ¨Åed the most. Due to the normalization in
Step 6, the energy at other frequencies will be damped out
as the iterations proceed. The algorithm is closely related to
the power method for computing the largest eigenvalue of
a symmetric matrix and we therefore call the iterations for
power iterations.
Example 12.1. Let  be of second order with the magnitude curve of the frequency response given in Fig. 16. The
maximum gain is at  ‚âà0.79.
Initially a white input with variance 1 and length N =100
is applied. It gives the output shown as the dashed line in
Fig. 17. Also shown in this Ô¨Ågure is the output after 10
power iterations. Clearly, the latter output is not far from a
sinusoid with frequency around  = 0.79.
In Fig. 18, the estimated gain k is given for the Ô¨Årst
10 iterations together with ‚à•‚à•‚àû(dashed line). Clearly,
the sequence of gain estimates converges exponentially fast
to a rather accurate lower bound for the true gain of the
H. Hjalmarsson / Automatica 41 393‚Äì438
Fig. 17. Outputs in Example 12.1. Dashed curve: initial output. Solid line: output after 10 iterations.
Fig. 18. Solid line: gain versus iteration number in Example 12.1. Dashed
line: H‚àû-norm of .
Fig. 19. Output in Example 12.2 after 10 iterations.
Example 12.2. Power iterations applied to another  gives
the output in Fig. 19 after 10 iterations. It does not even
remotely resemble a sinusoid.
The explanation is that  is not LTI in this case, in fact it
is given by the continuous time system
Àôx2 = ‚àí2x3
1 ‚àí4x2 + u,
sampled with a sampling time T = 0.1.
The maximum of the gain sequence computed in Step 5
in the power iterations still is a lower bound to the induced
L2-norm. This sequence is shown in Fig. 20. Also in this
case, the gain sequence increases monotonically. In Example
6.9 in Khalil an upper bound for the induced L2norm of this system is given as 1/4 (marked as the dashed
line in Fig. 20). From Fig. 20 we see that the lower bound
produced by the power iterations is quite accurate.
There are two conclusions to be drawn from Example
12.2. Firstly, power iterations can be used to detect nonlinearities in a system. If the iterations do not converge to a
sinusoidal signal, the system is non-linear. Secondly, power
iterations may give a useful lower bound on the induced L2norm of certain non-linear systems, cf. Section 9.2. There
is no proof for the latter statement and the author certainly
does not claim that power iterations produce monotonically
increasing lower bounds, or that the produced bounds are
accurate, for general non-linear systems. However, the nice
behavior observed for this and some other non-linear systems is intriguing.
13. Concluding remarks
Looking back at the ground covered in this paper (not to
mention all that regrettably had to be omitted), it is clear
that much progress has been made in this research area since
the book and the SYSID
plenary in Budapest in 1991 , which in many
respects can be seen as triggers for activities in this Ô¨Åeld.
Looking at the problem from a statistical perspective, we
Ô¨Årst remind the reader of the guidelines in Section 6:
(i) Always Ô¨Årst model as well as possible.
(ii) Use a very Ô¨Çexible model structure as benchmark for
computing conÔ¨Ådence bounds and mean-square error.
(iii) Select the input such that the model uncertainty at frequency regions of interest is insensitive to the model
complexity.
Notice that we in (i) do not refer to full-order modeling, the
aim is rather to obtain a near-optimal restricted complexity
model. Following advice (i) ensures good statistical properties and enables the under-modeling to be quantiÔ¨Åed. The
model can subsequently be simpliÔ¨Åed without loss of accuracy. Referring to Fig. 1, this means that going from an nearoptimal restricted model to a low order controller by way of
controller reduction or model reduction will not signiÔ¨Åcantly
inÔ¨Çuence the statistical properties of the procedure. Advice
(ii) ensures a reasonable assessment of the model error and
H. Hjalmarsson / Automatica 41 393‚Äì438
Fig. 20. Solid line: gain versus iteration number in Example 12.2. Dashed line: upper bound on L2-norm.
as we saw in Section 6, (iii) can be ensured by inputs with
large spectral peaks (even though there seems to be more to
understand here).
From (i) follows that identiÔ¨Åcation and control are not as
intertwined as might be believed:
‚Ä¢ For a given data set, producing the set of unfalsiÔ¨Åed models has little to do with the control problem. Once the set
of unfalsiÔ¨Åed models is obtained, what remains is a robust
control problem with, in turn, little to do with the identi-
Ô¨Åcation problem.
There is, however, as pointed out in Section 7.4, an interface
problem between the two areas that cannot be neglected in
that the model set description obtained from system identi-
Ô¨Åcation typically does not Ô¨Åt the present robust control design framework. Much work has been done in this area, cf.
Section 7.4.
In order to use (iii), it is necessary to know the modeling
requirements. For control, we have argued (Sections 7.6,
8.10, 9.2 and 11.2) that these are in principle encapsulated
by the following condition on the weighted relative error:
‚à•(G‚ó¶, ÀÜGN, T )( ÀÜGN, C)‚à•‚©ΩP .
Condition (97) clariÔ¨Åes the roles of the design variables and
how these should be designed and traded off against each
other. For example, for a SISO LTI system the bound (66)
T ( ÀÜGN, C( ÀÜGN))
2 (n)n,N
From this expression we noted in Section 7.6 that there is a
‚Ä¢ control effort versus experimental information trade-off
in force. The more aggressive controller, the more information is necessary in order to guarantee a small ‚à•‚à•.
Condition (98) also provides guidelines for input design,
cf. Section 11.2. High input energy density is required where
the designed control effort, |T ( ÀÜGN, C( ÀÜGN))/ ÀÜGN|, is large,
but should be small where the designed control effort is
small in order to reduce the modeling effort.
Overall, we have argued that the experiment design is the
most important design variable for a successful application
and we can summarize our observations as follows:
‚Ä¢ excite where it may hurt most.
On a principal level, the input should be chosen such
that system properties that are highly detrimental to the
closed-loop performance are revealed by the experiment,
cf. the discussion in Section 5.3, and the discussion of the
performance speciÔ¨Åcations versus experimentation effort
(Trade-off 1) in Section 7.6. See also Example 11.1.
‚Ä¢ do not excite where it does not hurt.
There is no beneÔ¨Åt from knowing what one does not have
to know; in this context it only means that the modeling
problem becomes more complex. Of course, it is typically
a priori difÔ¨Åcult to be aware of which system information
one has to know for the control design and this is one of the
key problems in identiÔ¨Åcation and control. Nevertheless,
it is instructive to keep this advice in mind.
‚Ä¢ adaptation increases accuracy.
Since the true system and the disturbances are unknown,
efÔ¨Åcient resolution of the previous item is facilitated by
adaptive or iterative methods which are able to improve on
the input design so that future data samples contain information of better quality from the control application point
of view. At present, the only result in this direction for
prediction error identiÔ¨Åcation seems to be which in turn is based on some restrictive
assumptions. Notably, preferential identiÔ¨Åcation in conjunction with robust control has proven a viable route for
adaptation, see Section 8.11. It should also be remarked
that there are differing opinions regarding the value of
adaptive input design .
In this context, we would like to draw the attention to the
potential of using the system itself to (semi-)automatically
generate the information of interest. This idea has been used
several times in this paper. In Section 10.2, the system was
used to generate sensitivity information. Iterative Learning
Control was used in Section 11.3.2 to gradually move the
system trajectory closer to the desired one. It was pointed
out in Section 11.3.3 that relay feedback can be seen as
a way of using the system itself to automatically generate a certain type of information. Finally, power iterations
were used in Section 12.2 to estimate the gain of a system.
H. Hjalmarsson / Automatica 41 393‚Äì438
An interesting topic here is to further explore what non-linear
feedback has to offer for automatic generation of suitable
experimental conditions.
In a number of contributions, see e.g. Section 8.5, identi-
Ô¨Åcation in closed-loop has been advocated. While this may
certainly be motivated by many reasons, e.g. safety and the
fact that most processes are already operating in closedloop, there is from the point of statistical accuracy not obvious that closed-loop identiÔ¨Åcation is preferable to open
loop identiÔ¨Åcation. In Section 9.1 we saw that for bias reasons, the experimental conditions should reÔ¨Çect the desired
operation characteristics. A closed-loop experiment with a
poorly tuned controller may in this respect give less useful
data than a well designed open loop experiment, cf. Section 11.3.2. Based on the high order approximation (32) it
follows that when the output variance is constrained, it is optimal with closed-loop identiÔ¨Åcation with a controller that depends on the true system and
the experimental constraints to counter-effect noise induced
uncertainty (variance) effectively. However, also here there
is no guarantee in practice that closed-loop data are more
informative.
While much of the work in the area has focused on LTI
systems, cf. Section 8, there has in recent years been a shift
towards more realistic problem settings where the system is
considered to exhibit different kinds of non-linear behaviors,
cf. Section 9. With the diversity of non-linear systems, one
may expect this research area to proliferate in coming years;
there are, e.g., results emerging for hybrid systems, see, e.g.,
Ferrari-Trecate, Muselli, Liberati, and Morari . This
observation also accentuates the importance of close collaboration with application Ô¨Åelds in order to address relevant
A number of interesting benchmarks have appeared
throughout the years, see, e.g., Graebe and
Landau, Karimi, and Hjalmarsson . To facilitate
the comparison of different algorithms, a set of generally
acknowledged benchmark problems would be most useful.
Despite the leverage that the forgiving nature of feedback
offers, the joint identiÔ¨Åcation and control problem is complex with many aspects that have to be balanced against
each other. Since little effort has been spent so far on packaging algorithms in a way that meets the requirements of
industrial practitioners, cf. Rivera and Jun and Zhu
 , it is not surprising that, as reported in Zhu ,
system identiÔ¨Åcation still has had relatively little impact on
industrial control engineers in general. However, as hopefully evidenced by this survey, the progress in this research
area is very promising and there certainly are interesting
years ahead!
Acknowledgements
During the last decade I have had the privilege to collaborate with Franky De Bruyne, L√°szl√≥ Gerencs√©r, Michel
Gevers, Svante Gunnarsson, Anders Hansson, Weng Khuen
Ho, Henrik Jansson, Kristian Lindqvist, Lennart Ljung,
Ola Markusson, Jonas MÀöartensson, Brett Ninness, Johan
Schoukens, Jonas Sj√∂berg, Bo Wahlberg and Sandor Veres,
on this topic; a process which has lead to many of the
insights in this paper. Thanks guys for enlightening me,
you‚Äôre a great bunch! Special thanks goes to Brett and Bo
for proof-reading early versions of this manuscript, to Johan
for valuable comments and to Henrik for providing Example 11.1. Thanks also to the Ô¨Åve referees for their many
insightful comments which were instrumental in improving
the quality of the paper.
This research has been supported by The Swedish Research Council.