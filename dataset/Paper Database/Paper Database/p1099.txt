Domain Adaptation of Conditional Probability
Models Via Feature Subsetting
Sandeepkumar Satpal and Sunita Sarawagi⋆
IIT Bombay
 
Abstract. The goal in domain adaptation is to train a model using
labeled data sampled from a domain diﬀerent from the target domain
on which the model will be deployed. We exploit unlabeled data from
the target domain to train a model that maximizes likelihood over the
training sample while minimizing the distance between the training and
target distribution. Our focus is conditional probability models used for
predicting a label structure y given input x based on features deﬁned
jointly over x and y. We propose practical measures of divergence between the two domains based on which we penalize features with large
divergence, while improving the eﬀectiveness of other less deviant correlated features. Empirical evaluation on several real-life information extraction tasks using Conditional Random Fields (CRFs) show that our
method of domain adaptation leads to signiﬁcant reduction in error.
Introduction
Most statistical learning techniques are based on the assumption that the training data is representative of the distribution on which the trained model is
deployed. This assumption gets routinely broken in applications like information extraction, speech recognition, text classiﬁcation, and opinion mining that
are being increasingly used at large scales. In most such applications, an oﬄine
phase is used to collect carefully labeled data for training. However, the settings
during deployment could be highly varied with little or no labeled data for that
setting. For example, it is easy to ﬁnd plenty of labeled data for named entity
recognition in news articles but our goal might be to recognize person names
from blogs. It is not easy to ﬁnd labeled data for blogs but there is no dearth of
unlabeled data.
Our goal in domain adaptation is to use labeled data from some domain to
train a model that maximizes accuracy in a target domain for which we only
have unlabeled data available. We concentrate on adapting structured learning
tasks that model the conditional probability of a predicted structure y given
input x as a linear exponential function of features deﬁned over x and y. A
logistic classiﬁer is a special case of such models where the predicted structure
is a single discrete class label. Such conditional models allow users the ﬂexibility
of deﬁning features without bothering about whether they are correlated or not.
⋆Contact author.
J.N. Kok et al. (Eds.): PKDD 2007, LNAI 4702, pp. 224–235, 2007.
⃝Springer-Verlag Berlin Heidelberg 2007
Domain Adaptation of Conditional Probability Models
Therefore, most real-life applications of these models involve a large number of
features, contributing in varying strengths to the prediction task. With overﬁtting avoided using a suitable regularizer, these models provide state-of-the-art
accuracy values in settings where features behave the same way in the training
and target domain . However, we observed that such models are rather
brittle in that they perform very poorly on target data with even a small subset
of features distorted in spite of other highly correlated features remaining intact.
We show how to detect features with large divergence in the two domains and
penalize the more distorted features so that other less deviant correlated features
start exerting a larger inﬂuence. A challenge is designing a reliable measure
of divergence given only unlabeled data from the target domain whereas our
features are deﬁned over function of both labels y and input x. We propose a
measure of distortion as a function of the diﬀerence in expectation over the target
samples and the trained conditional model. We formulate this as an optimization
problem and present eﬃcient algorithms for solving it. On seven real-life datasets,
we show that our domain adapted classiﬁer provides much higher accuracy than
an unadapted model.
The rest of the paper is organized as follows. We discuss related work in
Section 2. We describe our basic learning model in Section 3 and present our
approach to domain adaptation in Section 4. We report results of an empirical
evaluation of our model in Section 5.
Related Work
Transfer learning: In transfer learning the goal is to use available training data from a related domain, along with training data from the target domain,
to train the target classiﬁer. A popular technique is to use the classiﬁer in the
related domain to deﬁne a prior for the classiﬁer trained using the indomain data. For example, proposes to ﬁrst create a classiﬁer using training
data from the related domain. The output parameters are used as the mean of a
Gaussian prior for the second classiﬁer trained using labeled data of the target
domain. A diﬀerent type of prior is deﬁned in where the prior is used to give
more importance to features that are useful across domains. Another interesting
approach is based on replicating features so that shared features exploit labeled
data from both domains whereas domain-speciﬁc features are trained only using
in-domain data . Our goal is diﬀerent in that we do not have any labeled
data from the target domain. Transfer learning is supervised domain adaptation
whereas we are interested in unsupervised domain adaptation.
Structural correspondence learning: A recent proposal for unsupervised
domain adaptation is to deﬁne new features that capture the correspondence
between features in the two domains. The new features are weights of “mini”
classiﬁers that predict value of user-chosen anchor features that remain invariant
across the domains. Successful domain adaptation will require both addition and
deletion of features. Deletion is required for features that are missing or severely
S. Satpal and S. Sarawagi
distorted, whereas when features are substituted, for example, the inter-author
separator is changed from “comma” to a “new line”, addition of features that
capture their correspondence is more useful. Given that most structured learning
tasks involve many correlated features, careful feature subsetting could lead to
signiﬁcant accuracy gains, as we show in this paper.
Robust learning: A diﬀerent approach to handling features that are distorted
in the test data is to learn classiﬁers that are robust to limited amounts of
distortion. For example, shows how to create SVM classiﬁers that provide
good worst case performance with the deletion of any subset of features of size
no more than k. In robust learning a model is trained once unlike in the case
of domain adaptation where the model is retrained to adapt to any systematic
diﬀerence between the two domains.
Correcting sample selection bias: In some cases, the training distribution fails
to be representative of the test distribution because of a selection bias in the
training instances, for example due to active learning. A popular strategy to
correct for the bias is to weight training examples diﬀerentially. Such
methods are not likely to be useful for domain adaptation because all instances
from the train domain could have very small probability in the target domain
and the real issue is that of choosing the right representation through feature
reweighting rather than instance reweighting.
In summary, the problem of unsupervised domain adaptation is related to, but
distinct, from many problems in machine learning. To the best of our knowledge,
domain adaptation via feature subsetting has not been addressed before in the
literature.
Background
The Basic Learning Model
We consider conditional models of structure learning where the goal is to predict
a label y from a structured space Y given an input x. We assume a feature
vector representation F : (x, y) →RK that maps any (x, y) pair to a vector
of K reals. The conditional probability model is a log-linear function over these
features. Thus, Pr(y|x) is this Gibbs distribution
Pr(y|x, w) =
zw(x) exp w · f(x, y)
where w is the parameter vector of the model where the kth component wk
is called the weight of feature fk. The term zw(x) = 
y′ exp w · f(x, y′) is a
normalizing constant.
In practice, each feature fk(x, y) is deﬁned as a sum of local features that
apply over smaller subsets of variables. When the features decompose over cliques
of an undirected graph on labels y, we get Conditional Random Fields . This
Domain Adaptation of Conditional Probability Models
decomposition is exploited for eﬃcient inference over the space of variables y.
For example, in information extraction, the underlying graph is a linear chain
where features decompose over pairs of adjacent variables.
During training the goal is to maximize log-likelihood over a given training
set D = {(xℓ, yℓ)}N
ℓ=1 expressed as
log Pr(yℓ|xℓ, w) =
(w · f(xℓ, yℓ) −log zw(xℓ))
We wish to ﬁnd a w that maximizes L(w). In practice, the norm of w is not
allowed to grow too large to avoid overﬁtting. This is achieved by subtracting a
regularization term R(w) = ||w||γ
with γ = 1 or 2 and a user-provided variance
σ2. The resultant objective is convex, and can thus be maximized by gradient
ascent, or one of many related methods.
During deployment, given an input x, we predict a y for which Pr(y|x) is
maximum. The justiﬁcation for this step is that the test data follows the same
distribution as the training data, using which we learnt a w so as to maximize
the probability of the correct prediction.
Train and Target Data Distributions
In domain adaptation we need to deploy a model in a domain where the distribution of (x, y) is diﬀerent from the distribution from which the training data
was obtained. Let D denote the distribution from which the training sample D
was taken. Let D′ denote the target distribution on which we wish to deploy
the model. We do not have any labeled data from D′, instead we have lots of
unlabeled data D′. Let D′ = {(xℓ)}N ′
In domain adaptation our goal is to use both the labeled samples D from
D and the unlabeled samples D′ from distribution D′ to train a model that
maximizes accuracy on D′. The accuracy in the D distribution is of no interest
to us. Therefore the normal goal during CRF training of maximizing likelihood of
D is not justiﬁed anymore because D is not representative of the distribution on
which the model will be deployed. This is also what makes the problem diﬀerent
from semi-supervised learning where the labeled and unlabeled data come from
the same distribution.
Domain Adaptation
Our approach to domain adaptation is to choose a representation where the
training and test distributions are close, and once that is achieved we can justify
training a model to maximize accuracy on the labeled training domain. Our
starting representation is the user provided feature vector f(x, y). During domain
adaptation we select the subset S of features such that the distance between the
train and target distributions is small in the projected space while maximizing
likelihood on the training data. Our ideal objective of maximizing likelihood of
the target distribution D for which we have no labeled samples
S. Satpal and S. Sarawagi
wkfk(x, y) −log zw(x)
is replaced with the achievable objective
wkfk(x, y) −log zw(x)
such that dist(D, D′|S, D, D′) ≤ϵ.
where dist(D, D′|S, D, D′) is a suitable measure of distance between the two domains in a representation corresponding to the features in set S and as estimated
from the labeled samples D from D and unlabeled samples D′ from D′.
Distance Function
We next discuss how to measure the distance between the two distributions. A
direct approach is to ﬁrst estimate their full (x, y) distributions using sample
data and then measure the distance between the two distributions using some
function like KL distance. This is often diﬃcult and requires a lot of training
data. One of the main reasons for the success of the conditional approach for
structured learning tasks is that they do not require the modeling of the distribution over x.
Recently, proposed to correct for sample selection bias in the training
data by reducing the diﬀerence in the mean of the x features in the training and
target distribution. There are several reasons why this method will not work well
in our setting. First, in structured learning settings, the feature representation is
in terms of both x and y. Even if, we consider the scalar classiﬁcation problem
where we simplify the feature representation to be a cross product of features
deﬁned over x and labels y, we can obtain more accurate distance measures
by comparing the x means of each y separately rather than collapsing them on
single means. Also, the method proposed in assumes that Pr(y|x) is the
same in the training and test distribution. In our case, we assume that there
exist some representation under which the two distributions are the same, but
this is not true for all representations. In particular, this is not true for the
starting representation used during normal training.
We propose to compare the two distributions by comparing component-wise
the means of the features in their (x, y) space. Let Ek
D′ denote the
expected value of the kth feature under distributions D and D′ respectively.
For the training distribution, we estimate it empirically from the sample D as
. For the target distribution D′ since in the sample D′
we have only x values, we use the expected value of the feature as calculated
under the Pr(y|x, w) distribution. Thus,
fk(xℓ, y) Pr(y|xℓ, w)
Domain Adaptation of Conditional Probability Models
Using ED and ED′, we replace dist(D, D′|S, D, D′) with the distance between
the above sample means as 
D′). The precise form of the distance
function will depend on the nature of the speciﬁc features. For example, for
sparse binary features, it is useful to interpret the mean values as probability
of occurrence of a binomial distribution. In such cases, distance measures like
cross-entropy and the log-odds ratio seem meaningful . When the features
are arbitrary real values, a L1 or square distance would be more appropriate.
Overall Objective
In terms of the new distance function, we can rewrite the objective as
wkfk(x, y) −log zw(x)
The above objective presents a diﬃcult combinatorial optimization problem
over the exponentially many subsets of features. We convert the discrete feature selection problem to a soft selection problem by rewriting the constraint
D′) ≤ϵ as K
k=1 |wk|γd(Ek
D′) ≤ϵ′. Also, using the Lagrange
dual formulation, we push the constraints into the objective and get the equivalent objective for an appropriate value of λ as
wkfk(x, y) −log zw(x) −λ
The above formulation has several intuitive interpretations. We can treat this
as a standard accuracy-regularized training method with the only diﬀerence that
the wk are weighted in proportional to the distance between the training and
target distribution along the k-th feature component. A feature with a large
distance should get a smaller weight. Another interpretation is in terms of prior
distributions over the parameters where the variance is not constant over all
features, as is normally the case, but is inversely proportional to the divergence
of the feature over the two distributions. When γ is 1 the prior is a Laplace
distribution and when γ = 2 the prior is a Gaussian distribution with variance
of the kth parameter as
D′). So when the distance is large, the parameter
is likely to stay close to its mean value of 0.
Training Algorithm
We now discuss how we solve the optimization problem in Equation 7. For concreteness, we assume that γ = 2 and the distance function is the square distance
deﬁned as d(Ek
D′)2. The ﬁnal objective then becomes.
L(w) = argmaxw
wkfk(x, y) −log zw(x)) −λ
S. Satpal and S. Sarawagi
y fk(xi, y) exp wf(xi,y)
. The above is a smooth differentiable function of w. We can use standard gradient descent approaches to
solve it. The gradient with respect to the kth parameter is
fk(x, y) −NEk
D,w −2λ(wk(Ek
fj(xi, y)exp wf(xi, y)
(fk(xi, y) −
fk(xi, y′)exp wf(xi, y′)
fj(xi, y) Pr(y|xi)(fk(xi, y) −
fk(xi, y′) Pr(y′|xi))
D′ is the expectation of the product of features j and k with respect
to the empirical x distribution from D′ and Pr(y|w, x). With respect to these
distributions, the term (Ejk
D′,w) represents the covariance between
features j and k. As in normal CRF training , we have to exploit the decomposability of the label space to evaluate these terms tractably.
There are two problem with the above objective.
1. The function is not convex, unlike the normal CRF objective with constant
weighting of the regularizers.
2. The gradient is expensive to compute since the covariance terms are quadratic
in the number of features. In typical structured learning tasks, for example in
information extraction, the number of features tend to be very large.
We address both these issues by following a nested iterative approach to training. In each iteration, we ﬁx feature distances with respect to the current values
of the parameters and ﬁnd the optimum value of the parameters treating the
distance values as constant. This makes the inner optimization problem convex
and linear in the number of features. We found that in practice with two or
three iterations we get most of the beneﬁt of complete training at signiﬁcantly
reduced cost.
Experiments
We evaluate the eﬀectiveness of our proposed method on seven domain adaptation tasks constructed from the following four entity extraction benchmarks.
CoNLL 2003 dataset. The ConLL 2003 dataset1 is a well-known benchmark
for Named Entity Recognition where the goal is to extract entities like persons,
organizations, and locations from news articles.
1 
Domain Adaptation of Conditional Probability Models
Cora citations. Cora citations consists of citations collected from the reference
section of several academic papers. The extraction task is to ﬁnd author names,
titles, venue, and year.
Cora headers. Cora headers consists of headers of research papers covering
ﬁelds like the title, author names, aﬃliations, and abstract of a paper. Even
though headers and citations come from the same repository, the way authors
and titles appear in paper headers is very diﬀerent from the way they appear in
paper citations, making it interesting for domain adaptation.
Citeseer citations. This dataset consists of journal articles we collected from
Citeseer and therefore formatted slightly diﬀerently from the Cora dataset.
Also, unlike Cora it consists only of journal entries. The dataset is available
at 
Table 1. Description of domain adaptation tasks used in our experiments
Train domain
Target domain
#train #test #train #test
Citeseer citations Cora citations
Cora citations
Citeseer citations Author
Title Caps
Citeseer citations All-Caps
Author Caps Citeseer citations All-Caps
Cite Conll
Citeseer citations CoNLL
Conll Cite
Citeseer citations Person
Cora headers
Citeseer citations Title
In Table 1 we provide details of seven domain adaptation tasks created using
various combination of these four datasets as the train and target domains and
the extracted label. In tasks Title Caps and Author Caps the target domain
diﬀers from the train domain only in one respect: all words are fully capitalized
in the target domain whereas in the train domain they are normal text records
with a mix and capital and small letters. The last four columns specify for each
of the two domains, the number of records used during training and testing
respectively. For the target domain, the training documents are unlabeled.
We used a sequential CRF with L2 regularization as our baseline model
for information extraction. The package that we used is downloadable from .
We used the BCEU encoding of the entities where an entity like person name
is decomposed into four labels: Begin-person, Continue-person, End-person, and
Unique-person. Each token contributed two types of features: (1) the token itself
if it was encountered in the training set and, (2) the set of regular expressions
like digit or not, capitalized or not that the token matches. For each label i,
these features where ﬁred for the ith word and two words to the left and right
of the word.
S. Satpal and S. Sarawagi
We evaluated our methods using F1 accuracy2 at the level of individual tokens.
We do not report span-level accuracy because the lack of standardization in what
deﬁnes the boundaries of an entity, makes it diﬃcult to get useful cross-domain
comparison at the span-level. For example, in Citeseer the last punctuation (“.”)
is outside the title entity whereas in Cora it is inside. In each experiment performance was averaged over four runs obtained by varying the subset of instances
used for training and testing. Unless otherwise stated, our default method of
domain adaptation uses γ = 1, λ = 1 and the square log-odd distance function
D′)2. This distance function has been shown to work well for
sparse indicator features commonly found in information extraction tasks. We
used the ϵ-approximation trick proposed in for handling the discontinuity of
the objective when γ = 1.
Overall Improvement with Domain Adaptation
In Table 2 we show the accuracy of the original unadapted model and the adapted
model trained using our method respectively called “Original” and “Adapted”.
Along with the accuracy on the target domain, for comparison we also show
accuracy on the train domain. In all cases, we ﬁnd that the accuracy of the
target domain improves with domain adaptation. In some cases, the accuracy
improvement is very dramatic, for example increasing from 26% to 69% on the
second task.
Table 2. F1 Accuracy before and after domain adaptation
Dataset-Name
Train domain
Target domain
Original Adapted Original Adapted
Title Caps
Author Caps
Cite Conll
Conll Cite
For Title Caps and Author Caps where the target domain is just a fully capitalized version of the train domain, we ﬁnd that the unadapted model performs
very poorly whereas with adaptation we get accuracy comparable to the accuracy
on the train domain. This illustrates the importance of adaptation even in domains that diﬀer only slightly from the training domain. The top few features of
the original model whose weight reduces almost to zero in the adapted model are:
IsInitCapital,
IsInitCapital.left-2,
IsInitCapital.right+2,
W Extract, IsAllSmallCase, IsAllSmallCase.left-2, IsAllSmallCase.
right+2. Most of these are case related features which have no importance in
2 F1 is deﬁned as 2*precision*recall/(precision+recall.)
Domain Adaptation of Conditional Probability Models
the target domain. In contrast, the top few features whose weight increases
signiﬁcantly are Punctuation, Punctuation.left-1, Punctuation.right+1,
W ACM.right+2. These features remain invariant in the two domains since they
are related to punctuation or fully capitalized words.
Another interesting observation from these tables is that on the train domain
while the accuracy does drop after adapting to a diﬀerent domain, the drop
is only slight. This shows that in most cases, the model has other redundant
features that start playing a role when some subset of its features are penalized.
Comparison with Other Methods
In Table 3 we compare our default method of domain adaptation to a number
of other alternatives.
We compare with the recently proposed structural correspondence learning
(SCL) (described in Section 2). We ﬁnd that SCL also shows signiﬁcant
accuracy improvements beyond the original unadapted model but the gain is
lower than our method in all except the last dataset. Since our method of feature
deletion is orthogonal to the SCL approach of feature addition, we also report
results with both methods combined in the “SCL+Our” column of Table 3. In
most cases, the combined method is better than either of the two.
We also compare our method to semi-supervised learning (SSL) proposed
in which adds to the training objective an additional goal of minimizing
entropy labels for the unlabeled documents. In column SSL of Table 3 we show
the results for the weight settings for which we obtained highest accuracy. Quite
predictably, SSL is not competitive as a method of domain adaptation. We show
Table 3. Comparison of our method of domain adaptation with alternatives
Original Adapted SCL SCL+Our SSL x-dist γ = 2 Square-dist
Title Caps
Author Caps
Cite Conll
Conll Cite
the importance of comparing the mean of features in the joint (x, y) space instead
of means along the projected x space as proposed in . The latter is simpler to
optimize because the distance function is independent of w and we get a simple
convex objective. The results shown in column x-dist of Table 3 indicate that in
almost all cases the performance of the x-only distance function is signiﬁcantly
worse than our method.
We vary our choice of γ from 1 to 2, that is using weighted L2 regularizer
instead of L1 in column γ = 2 of Table 3. We ﬁnd that our default of L1 distance
performs much better than L2. This observation agrees with earlier reports on
S. Satpal and S. Sarawagi
the eﬃcacy of feature selection using L1 instead of L2 regularizers. Next, we vary
our default choice of the distance function. We chose log-odds ratio because it
has been found to perform better on sparse Bernoulli features. Instead, if we use
a regular square distance between the expected values of features, we ﬁnd that
the accuracy is much worse as shown in the column marked Square-dist.
Eﬀect of Training Data
Another interesting aspect of domain adaptation is the performance of the
adapted model with increasing training data. In Figure 1 we show the accuracy
of the adapted model on the target domain and the unadapted model on the
train domain with increasing labeled training data. The y axis is the change in
error compared to the error with 10% training data. As expected with statistical
learners, with increasing training data, the error within the domain decreases. In
contrast, the error of the adapted model either stays almost the same or increases
slightly with more out-of-domain training data.
Training percent
Error fraction
Train domain (Cite)
Target domain (Cora)
Training percent
Error fraction
Train domain (cora)
Target domain (cite)
Fig. 1. Eﬀect of increasing labeled training data on train and target domains for tasks
Cite Cora (left) and Cora Cite (right)
Conclusion
In this paper we proposed a new method of unsupervised domain adaptation
that selects a subset of features for which the distance between the train and
target distribution is minimized while maximizing likelihood of the labeled data.
The main challenge in this task is estimating distribution distance in the (x, y)
space in which the model features are deﬁned given only unlabeled samples from
the target domain. We deﬁned a distance measure and a method for solving
the combined optimization problem that is both eﬃcient and leads to signiﬁcant
accuracy improvements. In future, we would like to develop a theoretical analysis
of this algorithm.
Acknowledgments. The work reported here was supported by grants from Microsoft Research and an IBM Faculty award.
Domain Adaptation of Conditional Probability Models