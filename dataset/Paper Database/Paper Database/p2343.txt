Tag Recommendations in Folksonomies
Robert J¨aschke1,2, Leandro Marinho3,4, Andreas Hotho1,
Lars Schmidt-Thieme3, and Gerd Stumme1,2
1 Knowledge & Data Engineering Group (KDE), University of Kassel,
Wilhelmsh¨oher Allee 73, 34121 Kassel, Germany
 
2 Research Center L3S, Appelstr. 9a, 30167 Hannover, Germany
 
3 Information Systems and Machine Learning Lab (ISMLL), University of Hildesheim,
Samelsonplatz 1, 31141 Hildesheim, Germany
 
4 Brazilian National Council Scientiﬁc and Technological Research (CNPq) scholarship holder
Abstract. Collaborative tagging systems allow users to assign keywords—so
called “tags”—to resources. Tags are used for navigation, ﬁnding resources and
serendipitous browsing and thus provide an immediate beneﬁt for users. These
systems usually include tag recommendation mechanisms easing the process of
ﬁnding good tags for a resource, but also consolidating the tag vocabulary across
users. In practice, however, only very basic recommendation strategies are
In this paper we evaluate and compare two recommendation algorithms on
large-scale real life datasets: an adaptation of user-based collaborative ﬁltering
and a graph-based recommender built on top of FolkRank. We show that both provide better results than non-personalized baseline methods. Especially the graphbased recommender outperforms existing methods considerably.
Introduction
Folksonomies are web-based systems that allow users to upload their resources, and to
label them with arbitrary words, so-called tags. The systems can be distinguished according to what kind of resources are supported. Flickr, for instance, allows the sharing
of photos, del.icio.us the sharing of bookmarks, CiteULike1 and Connotea2 the sharing
of bibliographic references, and Last.fm3 the sharing of music listening habits. BibSonomy,4 allows to share bookmarks and BIBTEX based publication entries simultaneously.
To support users in the tagging process and to expose different facets of a resource,
most of the systems offered some kind of tag recommendations already at an early
stage. Del.icio.us, for instance, had a tag recommender in June 2005 at the latest,5 and
also included resource recommendations.6 As of today, nobody has empirically shown
1 
2 
3 
4 
5 06 01 archive.html
6 who like.html
J.N. Kok et al. (Eds.): PKDD 2007, LNAI 4702, pp. 506–514, 2007.
c⃝Springer-Verlag Berlin Heidelberg 2007
Tag Recommendations in Folksonomies
the quantitative beneﬁts of recommender systems in such systems. In this paper, we will
quantitatively evaluate a tag recommender based on collaborative ﬁltering (introduced
in Sec. 3) and a graph based recommender using our ranking algorithm FolkRank (see
Sec. 4) on the two real world folksonomy datasets BibSonomy and Last.fm. We make
the BibSonomy dataset publicly available for research purposes to stimulate research in
the area of folksonomy systems (details in Section 5).
The results we are able to present in Sec. 6 are very encouraging as the graph based
approach outperforms all other approaches signiﬁcantly. As we will see later, this is
caused by the ability of FolkRank to exploit the information that is pertinent to the
speciﬁc user together with input from other users via the integrating structure of the
underlying hypergraph.
Recommending Tags—Problem Deﬁnition and State of the Art
Recommending tags can serve various purposes, such as: increasing the chances of getting a resource annotated, reminding a user what a resource is about and consolidating
the vocabulary across the users. In this section we formalize the notion of folksonomies,
formulate the tag recommendation problem and brieﬂy describe the state of the art on
tag recommendations in folksonomies.
A Formal Model for Folksonomies. A folksonomy F describes the users U, resources
R, and tags T , and the user-based assignment of tags to resources by the ternary relation
Y ⊆U × T × R. We depict the set of all posts by P. The model of a folksonomy we
use here is based on the deﬁnition in .
Tag Recommender Systems. Recommender systems (RS) in general recommend interesting or personalized information objects to users based on explicit or implicit ratings. Usually RS predict ratings of objects or suggest a list of new objects that the user
hopefully will like the most. In tag recommender systems the recommendations are, for
a given user u ∈U and a given resource r ∈R, a set ˜T(u, r) ⊆T of tags. In many
cases, ˜T(u, r) is computed by ﬁrst generating a ranking on the set of tags according to
some quality or relevance criterion, from which then the top n elements are selected.
Related work. General overviews on the rather young area of folksonomy systems and
their strengths and weaknesses are given in . In , Mika deﬁnes a model
of semantic-social networks for extracting lightweight ontologies from del.icio.us. Recently, work on more specialized topics such as structure mining on folksonomies—
e. g. to visualize trends and patterns in users’ tagging behavior—as well as
ranking of folksonomy contents , analyzing the semiotic dynamics of the tagging
vocabulary , or the dynamics and semantics have been presented.
The literature concerning the problem of tag recommendations in folksonomies is
still sparse. The existent approaches usually adapt methods from collaborative ﬁltering or information retrieval. The standard tag recommenders, in practice, are
services that provide the most-popular tags used for a particular resource by means of
tag clouds, i.e., the most frequent used tags are depicted in a larger font or otherwise
emphasized. These approaches address important aspects of the problem, but they still
R. J¨aschke et al.
diverge on the experimental protocol, notion of tag relevance and metrics used, what
makes further comparisons difﬁcult.
Collaborative Filtering
Due to its simplicity and promising results, collaborative ﬁltering (CF) has been one of
the most dominant methods used in recommender systems. In the next section we recall
the basic principles and then present the details of the adaptation to folksonomies.
Basic CF principle. The idea is to suggest new objects or to predict the utility of a
certain object based on the opinion of like-minded users . In CF, for m users and n
objects, the user proﬁles are represented in a user-object matrix X ∈Rm×n. The matrix
can be decomposed into row vectors:
X := [⃗x1, ..., ⃗xm]⊤with ⃗xu := [xu,1, ..., xu,n], for u := 1, . . . , m,
where xu,o indicates that user u rated object o by xu,o ∈R. Each row vector ⃗xu corresponds thus to a user proﬁle representing the object ratings of a particular user. This
decomposition leads to user-based CF (see for item-based algorithms).
Now, one can compute, for a given user u, the recommendation as follows. First,
based on matrix X and for a given k, the set N k
u of the k users that are most similar
to user u ∈U are computed: N k
u := arg maxk
v∈U sim(⃗xu, ⃗xv) where the superscript
in the arg max function indicates the number k of neighbors to be returned, and sim is
regarded (in our setting) as the cosine similarity measure. Then, for a given n ∈N, the
top n recommendations consist of a list of objects ranked by decreasing frequency of
occurrence in the ratings of the neighbors (see Eq. 1 below for the folksonomy case).
CF for Tag Recommendations in Folksonomies. Because of the ternary relational
nature of folksonomies, traditional CF cannot be applied directly, unless we reduce
the ternary relation Y to a lower dimensional space. To this end we consider as matrix X alternatively the two 2-dimensional projections πURY ∈{0, 1}|U|×|R| with
(πURY )u,r := 1 if there exists t ∈T s. t. (u, t, r) ∈Y and 0 else and πUT Y ∈
{0, 1}|U|×|T | with (πUT Y )u,t := 1 if there exists r ∈R s. t. (u, t, r) ∈Y and 0 else.
The projections preserve the user information, and lead to log-based like recommender
systems based on occurrence or non-occurrence of resources or tags, resp., with the
users. Notice that now we have two possible setups in which the k-neighborhood N k
of a user u can be formed, by considering either the resources or the tags as objects.
Having deﬁned matrix X, and having decided whether to use πURY or πUT Y for
computing user neighborhoods, we have the required setup to apply collaborative ﬁltering. For determining, for a given user u, a given resource r, and some n ∈N, the set
˜T(u, r) of n recommended tags, we compute ﬁrst N k
u as described above, followed by:
˜T(u, r) :=
sim(⃗xu, ⃗xv)δ(v, t, r)
where δ(v, t, r) := 1 if (v, t, r) ∈Y and 0 else.
Tag Recommendations in Folksonomies
A Graph Based Approach
The seminal PageRank algorithm reﬂects the idea that a web page is important if there
are many pages linking to it, and if those pages are important themselves. In , we
employed the same underlying principle for Google-like search and ranking in folksonomies. The key idea of our FolkRank algorithm is that a resource which is tagged
with important tags by important users becomes important itself. The same holds, symmetrically, for tags and users, thus we have a graph of vertices which are mutually
reinforcing each other by spreading their weights.
For generating a tag recommendation for a given user/resource pair (u, r), we compute the ranking as described in , and then restrict the result set ˜T(u, r) to the top n
tag nodes.
Evaluation
In this section we ﬁrst describe the datasets we used, how we prepared the data, the
methodology deployed to measure the performance, and which algorithms we used,
together with their speciﬁc settings.
To evaluate the proposed recommendation techniques we have chosen
datasets from two different folksonomy systems: BibSonomy and Last.fm. Table 1 gives
an overview on the datasets. For both datasets we disregarded if the tags had lower or
upper case.
BibSonomy. Since three of the authors have participated in the development of Bib-
Sonomy, 7 we were able to create a complete snapshot of all users, resources (both
publication references and bookmarks) and tags publicly available at April 30, 2007,
23:59:59 CEST.8 From the snapshot we excluded the posts from the DBLP computer
science bibliography9 since they are automatically inserted and all owned by one user
and all tagged with the same tag (dblp). Therefore they do not provide meaningful information for the analysis.
Last.fm. The data for Last.fm10 was gathered during July 2006, partly through the web
services API (collecting user nicknames), partly crawling the Last.fm site. Here the
resources are artist names, which are already normalized by the system.
Core computation. Many recommendation algorithms suffer from sparse data or the
“long tail” of items which were used by only few users. Hence, to increase the chances
of good results for all algorithms (with exception of the most popular tags recommender) we will restrict the evaluation to the “dense” part of the folksonomy, for which
7 
8 On request to a snapshot of BibSonomy is available for research
9 
10 
R. J¨aschke et al.
Table 1. Characteristics of the used datasets
BibSonomy 1,037 28,648 86,563 341,183
96,972 2007-04-30
3,746 10,848
5,197 299,520 100,101 2006-07-01
Table 2. Characteristics of the p-cores at level k
10 2,917 2,045 1,853 219,702 75,565
we adapt the notion of a p-core to tri-partite hypergraphs. The p-core of level k has
the property, that each user, tag and resource has/occurs in at least k posts.
An overview on the p-cores we used for our datasets is given in Table 2. For BibSonomy, we used k = 5 instead of 10 because of its smaller size. The largest k for which a
p-core exists is listed, for each dataset, in the last column of Table 1.
Evaluation methodology. To evaluate the recommenders we used a variant of the
leave-one-out hold-out estimation which we call LeavePostOut. In all datasets, we
picked, for each user, one of his posts p randomly. The task of the different recommenders was then to predict the tags of this post, based on the folksonomy F \ {p}.
As performance measures we use precision and recall which are standard in such
scenarios . With r being the resource from the randomly picked post of user u and
˜T(u, r) the set of recommended tags, recall and precision are deﬁned as
recall( ˜T (u, r)) =
| tags(u, r) ∩˜T(u, r)|
| tags(u, r)|
precision( ˜T (u, r)) =
| tags(u, r) ∩˜T(u, r)|
| ˜T(u, r)|
For each of the algorithms of our evaluation we will now describe brieﬂy the speciﬁc
settings used to run them.
Most popular tags. For each tag we counted in how many posts it occurs globally and
used the top tags (ranked by occurence count) as recommendations.
Most popular tags by resource. For a given resource we counted for all tags in how
many posts they occur together with that resource. We then used the tags that occured
most often together with that resource as recommendation.
Adapted PageRank. With the parameter d = 0.7 we stopped computation after 10
iterations or when the distance between two consecutive weight vectors was less than
10−6. In ⃗p, we gave higher weights to the user and the resource from the post which
Tag Recommendations in Folksonomies
was chosen. While each user, tag and resource got a preference weight of 1, the user
and resource from that particular post got a preference weight of 1 + |U| and 1 + |R|,
FolkRank. The same parameter and preference weights were used as in the adapted
Collaborative Filtering UT. For this collaborative ﬁltering algorithm the neighborhood
is computed based on the user-tag matrix πUT Y . The only parameter to be tuned in
the CF based algorithms is the number k of best neighbors. For that, multiple runs
where performed where k was successively incremented until a point where no more
improvements in the results were observed. For this approach the best values for k were
20 for the BibSonomy and 60 for the Last.fm dataset.
Collaborative Filtering UR. Here the neighborhood is computed based on the userresource matrix πURY . For this approach the best values for k were 30 for the BibSonomy and 100 for the Last.fm dataset.
In this section we present and describe the results of the evaluation. We will see that
both datasets show the same overall behavior: ‘most popular tags’ is outperformed by
all other approaches; the CF-UT algorithm performs slightly better than and the CF-
UR approach approx. as good as the ‘most popular tag by resource’, and FolkRank
uniformly provides signiﬁcantly better results.
The diagrams 1 and 2 show precision-recall plots as usual. A datapoint on a curve
stands for the number of tags used for recommendation (starting with the highest ranked
tag on the left of the curve and ending with ten tags on the right). Hence, the steady
decay of all curves in both plots means that the more tags of the recommendation are
regarded, the better the recall and the worse the precision will be.
BibSonomy. Figure 1 shows the precision and recall of the chosen algorithms. The toprightmost curve depicts the performance of FolkRank and it can clearly be seen that the
graph based algorithm outperforms the other methods in both precision and recall. With
ten recommended tags the recall reaches up to 80%, while the second best results only
reach around 65% with a comparable precision. While CF-UT, CF-UR and the ‘most
popular tags by resource’ algorithms have a quite similiar performance, the adapted
PageRank is signiﬁcantly worse, especially with its dropdown of precision already after
the third recommended tag. Finally, using the most popular tags as recommendation
gives very poor results in both precision and recall.
Let us now look at Table 3. We will focus here on a phenomenon which is unique
for this dataset. With an increasing number of suggested tags, the precision decrease is
steeper for FolkRank than for the collaborative ﬁltering and the ‘most popular tags by
resource’ algorithm such that the latter two approaches for ten suggested tags ﬁnally
overtake FolkRank. The reason is that the average number of tags in a post is around 4
for this dataset and while FolkRank can always recommend the maximum number of
R. J¨aschke et al.
Collaborative Filtering UT
most popular tags by resource
Collaborative Filtering UR
adapted PageRank
most popular tags
Fig. 1. Recall and Precision for BibSonomy p-core at level 5
Table 3. Precision for BibSonomy p-core at level 5
Number of recommended tags
0.724 0.586 0.474 0.412 0.364 0.319 0.289 0.263 0.243 0.225
Collaborative Filtering UT
0.569 0.483 0.411 0.343 0.311 0.276 0.265 0.257 0.243 0.235
most popular tags by resource 0.534 0.440 0.382 0.350 0.311 0.288 0.267 0.250 0.241 0.234
Collaborative Filtering UR
0.509 0.478 0.408 0.341 0.311 0.285 0.267 0.252 0.241 0.234
Collaborative Filtering UT
most popular tags by resource
Collaborative Filtering UR
adapted PageRank
most popular tags
Fig. 2. Recall and Precision for Last.fm p-core at level 10
tags, for the other approaches there are often not enough tags available for recommendation. Hence, less tags are recommended. This is because in the p-core of order 5, for
each post, often tags from only four other posts can be used for recommendation with
these approaches. Consequently this behaviour is even more noticeable in the p-core of
order 3 (which is not shown here).
Tag Recommendations in Folksonomies
Last.fm. For this dataset, the recall for FolkRank is considerably higher than for the
BibSonomy dataset, see Figure 2. Even when just two tags are recommended, the recall
is close to 60 %. Again, the graph based approach outperforms all other methods (CF-
UT reaches at most 76 % of the recall of FolkRank). An interesting observation can
be made about the adapted PageRank: its recall now is the second best after FolkRank
for larger numbers of recommended tags. This shows the overall importance of general
terms in this dataset—which have a high inﬂuence on the adapted PageRank (cf. Sec. 4).
The results clearly show that the graph based FolkRank algorithm outperforms base
line algorithms like ‘most popular tags‘ and collaborative ﬁltering approaches.
Acknowledgement. Part of this research was funded by the EU in the Nepomuk11 (FP6-
027705), Tagora12 , and the X-Media13 (IST-FP6-026978) projects.