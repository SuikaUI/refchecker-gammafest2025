Published as a conference paper at ICLR 2018
COMPOSITIONAL ATTENTION NETWORKS
FOR MACHINE REASONING
Drew A. Hudson
Department of Computer Science
Stanford University
 
Christopher D. Manning
Department of Computer Science
Stanford University
 
We present the MAC network, a novel fully differentiable neural network architecture, designed to facilitate explicit and expressive reasoning. MAC moves away
from monolithic black-box neural architectures towards a design that encourages
both transparency and versatility. The model approaches problems by decomposing them into a series of attention-based reasoning steps, each performed by a
novel recurrent Memory, Attention, and Composition (MAC) cell that maintains
a separation between control and memory. By stringing the cells together and imposing structural constraints that regulate their interaction, MAC effectively learns
to perform iterative reasoning processes that are directly inferred from the data in
an end-to-end approach. We demonstrate the model’s strength, robustness and interpretability on the challenging CLEVR dataset for visual reasoning, achieving
a new state-of-the-art 98.9% accuracy, halving the error rate of the previous best
model. More importantly, we show that the model is computationally-efﬁcient and
data-efﬁcient, in particular requiring 5x less data than existing models to achieve
strong results.
INTRODUCTION
Reasoning, the ability to manipulate previously acquired knowledge to draw novel inferences or
answer new questions, is one of the fundamental building blocks of the intelligent mind. As we
seek to advance neural networks beyond their current great success with sensory perception towards
tasks that require more deliberate thinking, conferring them with the ability to move from facts to
conclusions is thus of crucial importance. To this end, we consider here how best to design a neural
network to perform the structured and iterative reasoning necessary for complex problem solving.
Q: Do the block in front of the
tiny yellow cylinder and the
tiny thing that is to the right
of the large green shiny object
have the same color? A: No
Figure 1: A CLEVR example.
Color added for illustration.
Concretely, we develop a novel model that we apply to the CLEVR
task of visual question answering (VQA).
VQA is a challenging multimodal
task that requires responding to natural language questions about images. However, Agrawal et al. show how the ﬁrst generation
of successful VQA models tends to acquire only superﬁcial comprehension of both the image and the question, exploiting dataset biases rather than capturing a sound perception and reasoning process
that would lead to the correct answer ). CLEVR
was created to address this problem. As illustrated in ﬁgure 1, the
dataset features unbiased, highly compositional questions that require
an array of challenging reasoning skills, such as transitive and logical
relations, counting and comparisons, without allowing any shortcuts
around such reasoning.
However, deep learning approaches often struggle to perform well on tasks with a compositional and
structured nature . Most neural networks are essentially very
large correlation engines that will hone in on any statistical, potentially spurious pattern that allows
them to model the observed data more accurately. The depth, size and statistical nature that allows
them to cope with noisy and diverse data often limits their interpretability and hinders their capacity
 
Published as a conference paper at ICLR 2018
Figure 2: Model Overview. The MAC network consists of an input unit, a core recurrent network and an output unit. (1) The input unit transforms the raw image and question into distributed vector representations.
(2) The core recurrent network reasons sequentially over the question by decomposing it into a series of operations (control)
that retrieve information from the image
(knowledge base) and aggregate the results
into a recurrent memory.
(3) The output
classiﬁer computes the ﬁnal answer using
the question and the ﬁnal memory state.
to perform explicit and sound inference procedures that are vital for problem solving tasks. To mitigate this issue, some recent approaches adopt symbolic structures, resembling the expression trees of
programming languages, that compose neural modules from a ﬁxed predeﬁned collection . However, they consequently rely on externally provided structured representations and functional programs, brittle handcrafted parsers or expert demonstrations,
and require relatively complex multi-stage reinforcement learning training schemes. The rigidity
of these models’ structure and the use of an inventory of specialized operation-speciﬁc modules
ultimately undermines their robustness and generalization capacities.
Seeking a balance between the versatility and robustness of end-to-end neural approaches on the
one hand and the need to support more explicit and structured reasoning on the other, we propose
the MAC network, a novel fully differentiable architecture for reasoning tasks. Our model performs
structured and explicit reasoning by sequencing a new recurrent Memory, Attention and Composition (MAC) cell. The MAC cell was deliberately designed to capture the inner workings of an
elementary, yet general-purpose reasoning step, drawing inspiration from the design principles of
computer architectures. The cell explicitly separates out memory from control, both represented
recurrently, and consists of three operational units that work in tandem to perform a reasoning step:
the control unit updates the control state to attend at each iteration to some aspect of a given question; the read unit extracts information out of a knowledge base, guided by the control and memory
states; and the write unit integrates the retrieved information into the memory state, iteratively computing the answer. This universal design of the MAC cell serves as a structural prior that encourages
the network to solve problems by decomposing them into a sequence of attention-based reasoning
operations that are directly inferred from the data, without resorting to any strong supervision. With
self-attention connections between the cells, the MAC network is capable of representing arbitrarily complex acyclic reasoning graphs in a soft manner, while still featuring a physically sequential
structure and end-to-end differentiabillity, amenable to training simply by backpropagation.
We demonstrate the model’s quantitative and qualitative performance on the CLEVR task and its
associated datasets. The model achieves state-of-the-art accuracy across a variety of reasoning tasks
and settings, both for the primary dataset as well as the more difﬁcult human-authored questions.
Notably, it performs particularly well on questions that involve counting and aggregation skills,
which tend to be remarkably challenging for other VQA models . Moreover, we show that the MAC network learns rapidly and generalizes effectively from an order of magnitude less data than other approaches. Finally, extensive
ablation studies and error analysis demonstrate MAC’s robustness, versatility and generalization
capacity. These results highlight the signiﬁcance and value of imposing strong structural priors to
guide the network towards compositional reasoning. The model contains structures that encourage
it to explicitly perform a chain of operations that build upon each other, allowing MAC to develop
reasoning skills from the ground up, realizing the vision of an algebraic, compositional model of
inference as proposed by Bottou . Although each cell’s functionality has only a limited range
of possible continuous behaviors, geared to perform a simple reasoning operation, when chained
together in a MAC network, the whole system becomes expressive and powerful. TensorFlow implementation of the model is available at 
Published as a conference paper at ICLR 2018
Figure 3: The MAC cell architecture. The MAC recurrent cell consists of a control unit, read unit, and
write unit, that operate over dual control and memory hidden states. The control unit successively attends to
different parts of the task description (question), updating the control state to represent at each timestep the
reasoning operation the cell intends to perform. The read unit extracts information out of a knowledge base
(here, image), guided by the control state. The write unit integrates the retrieved information into the memory
state, yielding the new intermediate result that follows from applying the current reasoning operation.
THE MAC NETWORK
A MAC network is an end-to-end differentiable architecture primed to perform an explicit multi-step
reasoning process, by stringing together p recurrent MAC cells, each responsible for performing one
reasoning step. Given a knowledge base K (for VQA, an image) and a task description q (for VQA,
a question), the model infers a decomposition into a series of p reasoning operations that interact
with the knowledge base, iteratively aggregating and manipulating information to perform the task
at hand. It consists of three components: (1) an input unit, (2) the core recurrent network, composed
out of p MAC cells, and (3) an output unit, all described below.
THE INPUT UNIT
The input unit transforms the raw inputs given to the model into distributed vector representations.
Naturally, this unit is tied to the speciﬁcs of the task we seek to perform. For the particular case of
VQA, it receives a question and an image and processes each of them respectively:
The question string, of length S, is converted into a sequence of learned word embeddings that is
further processed by a d-dimensional biLSTM yielding: (1) contextual words: a series of output
states cw1, . . . , cwS that represent each word in the context of the question, and (2) the question
representation: q =
, the concatenation of the ﬁnal hidden states from the backward
and forward LSTM passes. Subsequently, for each step i = 1, . . . , p, the question q is transformed
through a learned linear transformation into a position-aware vector qi = W d×2d
i , representing
the aspects of the question that are relevant to the ith reasoning step.
The image is ﬁrst processed by a ﬁxed feature extractor pre-trained on ImageNet that outputs conv4 features from ResNet101 , matching prior work
for CLEVR . The resulting tensor is then
passed through two CNN layers with d output channels to obtain a ﬁnal image representation, the
knowledge base KH×W ×d = {kd
h,w=1,1}, where H = W = 14 are the height and width of the
processed image, corresponding to each of its regions.
THE MAC CELL
The MAC cell is a recurrent cell designed to capture the notion of an atomic and universal reasoning
operation and formulate its mechanics. For each step i = 1, . . . , p in the reasoning process, the ith
cell maintains dual hidden states: control ci and memory mi, of dimension d, initialized to learned
parameters m0 and c0, respectively.
The control ci represents the reasoning operation the cell should accomplish in the ith step, selectively focusing on some aspect of the question. Concretely, it is represented by a soft attention-based
weighted average of the question words cws; s = 1, . . . , S.
Published as a conference paper at ICLR 2018
cqi = W d×2d [ci−1, qi] + bd
cai,s = W 1×d(cqi ⊙cw s) + b1
cv i,s = softmax(cai,s)
cv i,s · cw s
Figure 4: The Control Unit (CU) architecture. The control unit attends at each iteration to some part of the
question, by applying soft attention over the question words, and updates the control state accordingly. The
unit’s inputs and outputs are in bold. See section 2.2.1 for details.
The memory mi holds the intermediate result obtained from the reasoning process up to the ith
step, computed recurrently by integrating the preceding hidden state mi−1 with new information
ri retrieved from the image, performing the ith reasoning operation ci. Analogously to the control,
ri is a weighted average over its regions {kh,w|H,W
Building on the design principles of computer organization, the MAC cell consists of three operational units: control unit CU, read unit RU and write unit WU, that work together to accomplish
tasks by performing an iterative reasoning process: The control unit identiﬁes a series of operations,
represented by a recurrent control state; the read unit extracts relevant information from a given
knowledge base to perform each operation, and the write unit iteratively integrates the information
into the cell’s memory state, producing a new intermediate result.
Through their operation, the three units together impose an interface that regulates the interaction
between the control and memory states. Speciﬁcally, the control state, which is a function of the
question, guides the integration of content from the image into the memory state only through indirect means: soft-attention maps and sigmoidal gating mechanisms. Consequently, the interaction
between these two modalities – visual and textual, or knowledge base and query – is mediated
through probability distributions only. This stands in stark contrast to common approaches that fuse
the question and image together into the same vector space through linear combinations, multiplication, or concatenation. As we will see in section 4, maintaining a strict separation between the
representational spaces of question and image, which can interact only through interpretable discrete
distributions, greatly enhances the generalizability of the network and improves its transparency.
In the following, we describe the cell’s three components: control, read and write units, and detail
their formal speciﬁcation. Unless otherwise stated, all the vectors are of dimension d.
THE CONTROL UNIT
The control unit (see ﬁgure 4) determines the reasoning operation that should be performed at each
step i, attending to some part of the question and updating the control state ci accordingly. It
receives the contextual question words cw 1, . . . , cw S, the question position-aware representation
qi, and the control state from the preceding step ci−1 and consists of two stages:
1. First, we combine qi and ci−1 through a linear transformation into cqi, taking into account
both the overall question representation qi, biased towards the ith reasoning step, as well
as the preceding reasoning operation ci−1. This allows the cell to base its decision for the
ith reasoning operation ci on the previously performed operation ci−1.
2. Subsequently, we cast cqi onto the space of the question words.
Speciﬁcally, this is
achieved by measuring the similarity between cqi and each question word cw s and passing the result through a softmax layer, yielding an attention distribution over the question
words cw 1, . . . , cw S. Finally, we sum the words according to this distribution to produce
the reasoning operation ci, represented in terms of the question words.
The casting of cqi onto question words serves as a form of regularization that restricts the space of
the valid reasoning operations by anchoring them back in the original question words, and due to the
use of soft attention may also improve the MAC cell transparency, since we can interpret the control
state content and the cell’s consequent behavior based on the words it attends to.
Published as a conference paper at ICLR 2018
Ii,h,w =[W d×d
i,h,w = W d×2d [Ii,h,w, kh,w] + bd
rai,h,w = W d×d(ci ⊙I′
i,h,w) + bd
rv i,h,w = softmax(rai,h,w)
rv i,h,w · kh,w
Figure 5: The Read Unit (RU) architecture. The read unit retrieves information from the knowledge base
that is necessary for performing the current reasoning operation (control) and potentially related to previously
obtained intermediate results (memory). It extracts the information by performing a two-stage attention process
over the knowledge base elements. See section 2.2.2 for details.
THE READ UNIT
For the ith step, the read unit (see ﬁgure 5) inspects the knowledge base (the image) and retrieves
the information ri that is required for performing the ith reasoning operation ci. The content’s
relevance is measured by an attention distribution rv i that assigns a probability to each element
in the knowledge base kd
h,w, taking into account the current reasoning operation ci and the prior
memory mi−1, the intermediate result produced by the preceding reasoning step. The attention
distribution is computed in several stages:
1. First, we compute the direct interaction between the knowledge-base element kh,w and the
memory mi−1, resulting in Ii,h,w. This term measures the relevance of the element to
the preceding intermediate result, allowing the model to perform transitive reasoning by
considering content that now seems important in light of information obtained from the
prior computation step.
2. Then, we concatenate the element kh,w to Ii,h,w and pass the result through a linear transformation, yielding I′
i,h,w. This allows us to also consider new information that is not
directly related to the prior intermediate result, as sometimes a cogent reasoning process
has to combine together independent facts to arrive at the answer (e.g., for a logical OR
operation, set union and counting).
3. Finally, aiming to retrieve information that is relevant for the reasoning operation ci, we
measure its similarity to each of the interactions Ii,h,w and pass the result through a softmax
layer. This produces an attention distribution over the knowledge base elements, which we
then use to compute a weighted average over them – ri.
Figure 6: Attention maps produced
by a MAC network of length 3.
To give an example of the read unit operation, consider the question in ﬁgure 6, which refers to the purple cylinder in the image.
Initially, no cue is provided to the model to attend to the cylinder, since no direct mention of it is given in the question. Instead,
the model approaches the question in steps: in the ﬁrst iteration
it attends to the “tiny blue block”, updating m1 accordingly to
the visual representation of the block. At the following step, the
control unit realizes it should now look for “the sphere in front”
of the block, storing that in c2. Then, when considering both m1
and c2, the read unit realizes it should look for “the sphere in
front” (c2) of the blue block (stored in m1), thus ﬁnding the cyan
sphere and updating m2. Finally, a similar process repeats in the
next iteration, allowing the model to traverse from the cyan ball to
the ﬁnal objective – the purple cylinder, and answer the question
correctly.
Published as a conference paper at ICLR 2018
= W d×2d[ri, mi−1] + bd
saij = softmax
W 1×d(ci ⊙cj) + b1
i = W 1×dci + b1
Figure 7: The Write Unit (WU) architecture. The write unit integrates the information retrieved from the
knowledge base into the recurrent memory state, producing a new intermediate result mi that corresponds to
the reasoning operation ci. See section 2.2.3 for details.
THE WRITE UNIT
The write unit (see ﬁgure 7) is responsible for computing the ith intermediate result of the reasoning
process and storing it in the memory state mi. Speciﬁcally, it integrates the information retrieved
from the read unit ri with the preceding intermediate result mi−1, guided by the ith reasoning operation ci. The integration proceeds in three steps, the ﬁrst mandatory while the others are optional1:
1. First, we combine the new information ri with the prior intermediate result mi−1 by a
linear transformation, resulting in minfo
2. Self-Attention (Optional). To support non-sequential reasoning processes, such as trees
or graphs, we allow each cell to consider all previous intermediate results, rather than just
the preceding one mi−1: We compute the similarity between the ith operation ci and
the previous ones c1, . . . , ci−1 and use it to derive an attention distribution over the prior
reasoning steps sai,j for j = 0, . . . , i −1. The distribution represents the relevance of
each previous step j to the current one i, and is used to compute a weighted average of the
memory states, yielding msa
i , which is then combined with minfo
to produce m′
i. Note that
while we compute the attention based on the control states, we use it to average over the
memory states, in a way that resembles Key-Value Memory Networks .
3. Memory Gate (Optional). Not all questions are equally complex – some are simpler while
others are more difﬁcult. To allow the model to dynamically adjust the reasoning process
length to the given question, we add a sigmoidal gate over the memory state that interpolates
between the previous memory state mi−1 and the new candidate m′
i, conditioned on the
reasoning operation ci. The gate allows the cell to skip a reasoning step if necessary,
passing the previous memory value further along the network, dynamically reducing the
effective length of the reasoning process as demanded by the question.
THE OUTPUT UNIT
Figure 8: The output unit. A classi-
ﬁer that predicts an answer based on the
question and the ﬁnal memory state.
The output unit predicts the ﬁnal answer to the question based
on the question representation q and the ﬁnal memory mp,
which represents the ﬁnal intermediate result of the reasoning process, holding relevant information from the knowledge
For CLEVR, where there is a ﬁxed set of possible
answers, the unit processes the concatenation of q and mp
through a 2-layer fully-connected softmax classiﬁer that produces a distribution over the candidate answers.
1Both self-attention connections as well as the memory gate serve to reduce long-term dependencies. However, note that for the CLEVR dataset we were able to maintain almost the same performance with the ﬁrst step
only, and so we propose the second and third ones as optional extensions of the basic write unit, and explore
their impact on the model’s performance in section 4.3.
2Note that some questions refer to important aspects that do not have counterpart information in the knowledge base, and thus considering both the question and the memory is critical to answer them.
Published as a conference paper at ICLR 2018
Table 1: CLEVR and CLEVR-Humans Accuracy by baseline methods, previous methods, and our method
(MAC). For CLEVR-Humans, we show results before and after ﬁne-tuning. (*) denotes use of extra supervisory
information through program labels. (†) denotes use of data augmentation. (‡) denotes training from raw pixels.
Human 
Q-type baseline 
LSTM 
CNN+LSTM 
CNN+LSTM+SA+MLP 73.2
N2NMN* 
PG+EE (9K prog.)* 
PG+EE (18K prog.)* 
PG+EE (700K prog.)* 
CNN+LSTM+RN†‡ 
CNN+GRU+FiLM 
CNN+GRU+FiLM‡ 
RELATED WORK
There have been several prominent models that address the CLEVR task. By and large they can be
partitioned into two groups: module networks, which in practice have all used the strong supervision
provided in the form of structured functional programs that accompany each data instance, and large,
relatively unstructured end-to-end differentiable networks that complement a fairly standard stack
of CNNs with components that aid them in performing reasoning tasks. In contrast to modular
approaches , our model is fully
differentiable and does not require additional supervision, making use of a single computational cell
chained in sequence rather than a collection of custom modules deployed in a rigid tree structure.
In contrast to augmented CNN approaches , we suggest that
our approach provides an ability for relational reasoning with better generalization capacity, higher
computational efﬁciency and enhanced transparency. These approaches and other related work are
discussed and contrasted in more detail in the supplementary material in appendix D.
EXPERIMENTS
We evaluate our model on the recent CLEVR task for visual reasoning .
The dataset consists of rendered images featuring 3D-objects of various shapes, materials, colors
and sizes, coupled with machine-generated compositional multi-step questions that measure performance on an array of challenging reasoning skills such as following transitive relations, counting objects and comparing their properties. Each question is also associated with a tree-structured
functional program that was used to generate it, specifying the reasoning operations that should be
performed to compute the answer.
In the following experiments, our model’s training is cast as a supervised classiﬁcation problem
to minimize the cross-entropy loss of the predicted candidate answer out of the 28 possibilities.
The model uses a hidden state size of d = 512 and, unless otherwise stated, length of p = 12
MAC cells.3 While some prior work uses the functional programs associated with each question as
additional supervisory information at training time (see table 1), we intentionally do not use these
structured representations to train our model, aiming to infer coherent reasoning strategies directly
from the question and answer pairs in an end-to-end approach.
We ﬁrst perform experiments on the primary 700k dataset. As shown in table 1, our model outperforms all prior work both in overall accuracy, as well as in each of the categories of speciﬁc
reasoning skills. In particular, for the overall performance, we achieve 98.94% accuracy, more than
halving the error rate of the best prior model, FiLM .
Counting and Numerical Comparison. In particular, our performance on questions about counting
and numerical comparisons is signiﬁcantly higher than existing models, which consistently struggle
3We initialize the word embeddings of our model to random vectors using a uniform distribution. In an earlier version of this work, we used pretrained GloVe vectors, but found that they did not improve the performance
for CLEVR and led to only a marginal improvement for CLEVR-Humans.
Published as a conference paper at ICLR 2018
Accuracy (Val)
Model Ablations
basic write unit (w1)
unshared weights
question vector as control
w/o word attention (c2)
w/o memory-control
Accuracy (Val)
Model Variations
basic write unit (w1)
prediction w/o question (o1)
w/o direct KB elements (r2)
w/ self-attention (w2)
w/ gating (w3)
Figure 9: From left to right: (1) Learning curve of MAC and alternative approaches (accuracy / epoch). (2)
Models’ performance as a function of the CLEVR subset size used for training, ranging from 1% to 100%.
(3),(4) Learning curves for ablated MAC variants. See section 4.3 for details.
on these question types. Again, we nearly halve the corresponding error rate. These are signiﬁcant
results, as counting and aggregations are known to be particularly challenging in the area of VQA
 . In contrast to CNNs, using attention enhances our model’s ability to
perform reasoning operations such as counting that pertain to the global aggregation of information
across different regions of the image.
CLEVR HUMANS AND ERROR ANALYSIS
Figure 10:
Error distribution for CLEVR and
CLEVR-Humans.
We analyze our model’s performance on the CLEVR-Humans dataset
 , consisting of natural language questions collected through crowdsourcing. As such, the dataset has a diverse vocabulary and linguistic variations, and it also demands more varied reasoning
skills. Since the training set is relatively small, comprising 18k samples,
we use it to ﬁnetune a model pre-trained on the primary CLEVR dataset,
following prior work.
As shown in table 1, our model achieves state-of-the-art performance on
CLEVR-Humans both before and after ﬁne-tuning. It surpasses the nextbest model by 5.6% percent, achieving 81.5%. The results substantiate
the model’s robustness against linguistic variations and noise as well as
its ability to adapt to new and more diverse vocabulary and reasoning
skills. The soft attention performed over the question allows the model
to focus on the words that are most critical to answer the question while
paying less attention to irrelevant linguistic variations. See ﬁgure 11, and
ﬁgures 16 and 17 in the appendix for examples.
In order to gain insight into the nature of the mistakes our model makes,
we perform an error analysis for the CLEVR and CLEVR-Humans
datasets (See ﬁgure 10). Overall, we see that most of the errors in the
CLEVR dataset are either off-by-one counting mistakes or result from heavy object occlusions.
For CLEVR-Humans, we observe many errors that involve new reasoning skills that the model has
not been trained for, such as ones that relate to physical properties (stability and reﬂections), relative distances and amounts, commonalities and uniqueness of objects, or negative questions. See
appendix B for further details. Nevertheless, the model does respond correctly to many of the questions that fall under these reasoning skills, as illustrated in ﬁgures 11 and 16, and so we speculate
that the errors the model makes stem in part from the small size of the CLEVR-Human dataset.
COMPUTATIONAL AND DATA EFFICIENCY
We examine the learning curves of MAC and compare them to previous models4: speciﬁcally, FiLM
 , the strongly-supervised PG+EE , and stacked-attention
4For previous models, we use the author’s original publicly available implementations. All the models were
trained with an equal batch size of 64 (as in the original implementations) and using the same hardware – a
single Maxwell Titan X GPU per model. To make sure the results are statistically signiﬁcant, we run each
model multiple (10) times, and plot the averages and conﬁdence intervals.
Published as a conference paper at ICLR 2018
Q: What is the shape of
the large item, mostly
occluded by the metallic
cube? A: sphere 
Q: What color is the
object that is a different
size? A: purple 
Q: What color ball is
close to the small purple
cylinder? A: gray 
Q: What color block is
farthest front? A: purple
Q: Are any objects gold?
Figure 11: CLEVR-Humans examples showing the model performs novel reasoning skills that do not appear
in CLEVR, including: obstructions, object uniqueness, relative distances, superlatives and new concepts.
networks (SA) . As shown in ﬁgure 9, our model learns
signiﬁcantly faster than other approaches. While we do not have learning curves for the recent Relation Network model, Santoro et al. report 1.4 million iterations (equivalent to 125 epochs)
to achieve 95.5% accuracy, whereas our model achieves a comparable accuracy after only 3 epochs,
yielding a 40x reduction in the length of the training process. Likewise, Perez et al. report a
training time of 4 days, equivalent to 80 epochs, to reach accuracy of 97.7%. In contrast, we achieve
higher accuracy in 6 epochs, 9.5 hours overall, leading to a 10x reduction in training time.
In order to study the ability of MAC to generalize from a smaller amount of data, we explore its
performance on subsets of CLEVR, sampled at random from the original 700k dataset. As shown
in ﬁgure 9, MAC outperforms the other models by a wide margin: For 50% of the data, equivalent
to 350k samples, other models obtain accuracies ranging between 70% and 93%, while our model
achieves 97.6%. The gap becomes larger as the dataset size reduces: for 25% of the data, equivalent
to 175k samples, the performance of other models is between 50% and 77%, while MAC maintains
a high 94.3% accuracy.
Finally, for just 10% of the data, amounting to 70k samples, our model is the only one to generalize well, with performance of 85.5% on average, whereas the other leading models fail, achieving
49.0%-54.9%. Note that, as pointed out by Johnson et al. , a simple baseline that predicts
the most frequent answer for each question type already achieves 42.1%, suggesting that answering only half of the questions correctly means that the other models barely learn to generalize from
this smaller subset. These results demonstrate the robustness and generalization capacity of our
architecture and its key role as a structural prior guiding MAC to learn the intended reasoning skills.
Accuracy (Val)
Network Length
Figure 12: Model performance as a function of the
network length.
To gain better insight into the relative contribution of the design choices
we made, we perform extensive ablation studies. See ﬁgure 9 and appendix C for accuracies and learning curves. The experiments demonstrate the robustness of the model to hyperparameter variations such as
network dimension and length, and shed light on the signiﬁcance of various aspects and components of the model, as discussed below:
Question Attention. The ablations show that using attention over the
question words (see section 2.2.1) is highly effective in accelerating learning and enhancing generalization capacity. Using the complete question
q instead of the attention-based control state leads to a signiﬁcant drop of
18.5% in the overall accuracy. Likewise, using unconstrained recurrent
control states, without casting them back onto the question words space (step (3) in section 2.2.1)
leads to a 6x slowdown in the model convergence rate. These results illustrate the importance and
usefulness of decomposing the question into a series of simple operations, such that a single cell
is faced with learning the semantics of one or a few words at a time, rather than grasping all of
the question at once. They provide evidence for the efﬁcacy of using attention as a regularization
mechanism, by restricting the input and output spaces of each MAC cell.
Control and Memory. Maintaining separation between control and memory proves to be another
key property that contributes signiﬁcantly to the model’s accuracy, learning rate and data efﬁciency.
We perform experiments for a variant of the MAC cell in which we maintain one hidden state that
Published as a conference paper at ICLR 2018
Figure 14: Attention maps produced by MAC which provide some evidence for the ability of the model to
perform counting and summation of small numbers. Note how the ﬁrst iterations focus on the key structural
question words “many” and “or” that inform the model of the required reasoning operation it has to perform.
plays both the roles of the control and memory, iteratively attending and integrating information
from both the question and the image. While this approach achieves a ﬁnal accuracy of 93.75%, it
leads to a sharp drop in the convergence rate, as shown in ﬁgure 9, and a 20.2% reduction in the
ﬁnal accuracy for a smaller 10% subset of CLEVR. The results make a strong case for our model’s
main design choice, namely, splitting the computation into two dual paths: one that decomposes the
linguistic information and another that reconstructs the corresponding visual information.
The design choices discussed above were found to be the most signiﬁcant to the model’s overall
accuracy, convergence rate and generalization. Other design choices that were found beneﬁcial include (1) predicting the ﬁnal answer based on both the ﬁnal memory state and the question (see
section 2.3), and (2) considering knowledge base elements directly (step (2) in section 2.2.2), resulting in 19.8% and 11.1% improvement for a 10% subset of CLEVR, respectively. Please refer to
appendix C for further discussion and results.
INTERPRETABILITY
Figure 13: Attention maps produced by MAC, showing how
it tracks transitive relations between objects.
To obtain better insight into the underlying reasoning processes
MAC learns to perform, we study visualizations of the attention distributions produced by the model during its iterative computation,
and provide examples in ﬁgures 13, 14, 17, and 18. Examining the
sequence of attention maps over the image and the question reveals
several qualitative patterns and properties that characterize MAC’s
mode of operation.
First, we observe that both the linguistic and visual attentions of the
model are very focused on speciﬁc terms or regions in the image,
and commonly refer to concrete objects (“the shiny red cube” or the
“metallic cylinder”) or question structural keywords (“or”, “and” or
“how many”). More importantly, the attention maps give evidence
of the ability of the model to capture the underlying semantic structure of the question, traversing the correct transitive relations between the objects it refers to. For instance, we see in ﬁgure 13 how
the model explicitly decomposes the question into the correct reasoning steps: ﬁrst identifying the green ball, then focusing on the
red cylinder that is located left of the ball, and ﬁnally attending to
the yellow cylinder. In the second step, note how the model attends
only to the relevant red cylinder and not to other red rubber things,
correctly resolving the indirect reference in the question. This shows strong evidence of the ability
of the model to perform transitive reasoning, integrating information from prior steps that allows it
to focus only on the relevant objects, even when they are not mentioned explicitly.
In ﬁgure 14, we further see how the model interprets a multi-step counting question, apparently
summing up the amounts of two referenced object groups to produce the correct overall count. These
observations suggest that the model infers and effectively performs complex reasoning processes in
a transparent manner.
Published as a conference paper at ICLR 2018
CONCLUSION
We have introduced the Memory, Attention and Composition (MAC) network, an end-to-end differentiable architecture for machine reasoning. The model solves problems by decomposing them into
a series of inferred reasoning steps that are performed successively to accomplish the task at hand.
It uses a novel recurrent MAC cell that aims to formulate the inner workings of a single universal
reasoning operation by maintaining a separation between memory and control. These MAC cells
are chained together to produce explicit and structured multi-step reasoning processes. We demonstrate the versatility, robustness and transparency of the model through quantitative and qualitative
studies, achieving state-of-the-art results on the CLEVR task for visual reasoning, and generalizing
well even from a 10% subset of the data. The experimental results further show that the model can
adapt to novel situations and diverse language, and generate interpretable attention-based rationales
that reveal the underlying reasoning it performs. While CLEVR provides a natural testbed for our
approach, we believe that the architecture will prove beneﬁcial for other multi-step reasoning and
inference tasks, including reading comprehension, textual question answering, and real-world VQA.
ACKNOWLEDGMENTS
We wish to thank Justin Johnson, Aaron Courville, Ethan Perez, Harm de Vries, Mateusz Malinowski, Jacob Andreas, and the anonymous reviewers for the helpful suggestions, comments and
discussions. Stanford University gratefully acknowledges the support of the Defense Advanced
Research Projects Agency (DARPA) Communicating with Computers (CwC) program under ARO
prime contract no. W911NF15-1-0462 for supporting this work.
Published as a conference paper at ICLR 2018