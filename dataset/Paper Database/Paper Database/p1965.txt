Advance Access publication July 19, 2011
Political Analysis 19:273−286
doi:10.1093/pan/mpr021
Why Process Matters for Causal Inference
Adam N. Glynn
Department of Government, Harvard University, 1737 Cambridge Street, Cambridge,
e-mail: (corresponding author)
Kevin M. Quinn
UC Berkeley School of Law, 490 Simon 7200, Berkeley, CA 94720-7200
e-mail: 
Our goal in this paper is to provide a formal explanation for how within-unit causal process information (i.e.,
data on posttreatment variables and partial information on posttreatment counterfactuals) can help to inform causal inferences relating to total effects—the overall effect of an explanatory variable on an outcome
variable. The basic idea is that, in many applications, researchers may be able to make more plausible
causal assumptions conditional on the value of a posttreatment variable than they would be able to do
unconditionally. As data become available on a posttreatment variable, these conditional causal assumptions become active and information about the effect of interest is gained. This approach is most beneﬁcial
in situations where it is implausible to assume that treatment assignment is conditionally ignorable. We illustrate the approach with an example of estimating the effect of election day registration on turnout.
Introduction
Simple versions of the so-called “Neyman–Rubin causal model” take an essentially black-box approach
to causality—in an ideal randomized experiment, it is not necessary to know how, that is, through what
mechanisms, a particular treatment works in order to consistently estimate a variety of causal effects. All
that is necessary is random assignment of treatment along with assumptions that guarantee that potential
outcomes are well deﬁned for all relevant units. Of course, scholars as diverse as Fisher have argued that one can, and should, posit
causal mechanisms linking the treatment variable to the outcome variable and one should think carefully
about the observable implications of this casual process. This is especially important when confronted
with observational data in which the treatment was not randomized.
Our goal in this paper is to provide a formal explanation for how within-unit causal process information (i.e., data on posttreatment variables and partial information on posttreatment counterfactuals) can
help to inform causal inferences relating to total effects—the overall effect of an explanatory variable on
an outcome variable. The basic idea is that, in many applications, the treatment has not been randomized,
and therefore researchers will have to make assumptions in order to identify causal effects (even on average). As we demonstrate in this paper, researchers may be able to make more plausible causal assumptions
conditional on the value of a posttreatment variable than they would be able to do unconditionally (or conditionally on the measured pretreatment variables). As data become available on a posttreatment variable,
these conditional causal assumptions become active and information about the total effect is gained.
Authors’ note: The authors thank Matt Chingos for his research assistance and Kevin Clarke, Luke Keele, Jay Kaufman, James
Mahoney, the participants of the 2009 meeting of the Midwest Political Science Association, the participants of the 2009 Causal
Workshop at the Banff International Research Station, the participants of the 2009 Summer meeting of the Society of Political
Methodology, two anonymous referees, and the editors for their helpful comments and suggestions.
c⃝The Author 2011. Published by Oxford University Press on behalf of the Society for Political Methodology.
All rights reserved. For Permissions, please email: 
 Published online by Cambridge University Press
Adam N. Glynn and Kevin M. Quinn
Note that this formal explanation is necessary to reconcile the aforementioned advice (that one should
utilize posttreatment variables in an analysis of total effects) with the standard warnings about
posttreatment bias . Both pieces of advice are correct, and the formal explanation presented in this paper demonstrates how to utilize posttreatment variables without inducing posttreatment bias.
To get a sense of the argument, consider the following stylized example. We are interested in the
effect of election day registration (EDR) laws on turnout. We observe data from a single individual,
and we know that in 2004, she did not live in a state with EDR available and that she did not vote in
the 2004 presidential election. Without additional knowledge, all that we can say is that the individual
causal effect of EDR for this person is either 0 (she is a “never voter” and would not have voted even
if EDR had been available) or it is positive (she would have been “helped” to vote by the availability
of EDR). Now, suppose we learn that this person registered to vote thirty days prior to the election in
2004. Since most, if not all, of the presumed effect of EDR provisions on voting is assumed to work
by decreasing the costs of registration and thus increasing registration, it seems that most researchers
would now be more likely to conclude that our hypothetical citizen is a “never voter”—in other words,
enacting an EDR provision in this person’s state in 2004 would not have increased her likelihood of
voting since she was already registered on election day. Obviously, this conclusion depends on strong
assumptions (although these assumptions seem plausible for this scenario), and for many applications,
we may want to weaken these assumptions (or combine them with other types of assumptions). Furthermore, although this story is operating at the individual level, it is not difﬁcult to aggregate over a
number of such individual-level stories in order to estimate the distribution of effects and/or average
A small but growing literature attempts to formalize the use of posttreatment/process information to
improve inference for total causal effects. Rosenbaum demonstrated that conditioning on posttreatment variable could sometimes reduce bias when that variable was a surrogate for a pretreatment
variable. Pearl and its extensions went further, demonstrating
that when the front-door or single-door criteria hold, the average total causal effect could be nonparametrically identiﬁed with the use of posttreatment variables, even when treatment assignment is nonignorable. More recent work has focused on cases when the assumptions necessary for the front-door
technique do not fully hold. VanderWeele and VanderWeele and Robins demonstrated that
posttreatment variables might be used to determine the direction of bias. Joffe ﬁnds bounds for
total effects that utilize the observation of a posttreatment variable, and Kaufman, Kaufman, and MacLehose uses linear programming via the OPTIMIZE program to provide a number of
bounds based on alternative sets of assumptions (some of which involve the observation of a posttreatment
variable).1
This paper contributes to the “bounds” strand of this literature, demonstrating (with an example from
political science) how knowledge of the empirical joint distribution of a treatment variable, a posttreatment variable, and the outcome variable, combined with plausible assumptions regarding causal effects
within some, but not necessarily all, strata of this joint distribution can narrow the usual Manski 
bounds for the effect of interest. This approach is most beneﬁcial in situations where it is implausible to
assume that treatment assignment is conditionally ignorable. We illustrate the approach with an example
of estimating the effect of EDR on turnout. The utility of our approach is highlighted by the fact that
once one thinks seriously about what knowledge of the posttreatment variable (here registration) implies,
it becomes apparent that the effect estimates produced by standard data analytic strategies are implausibly
1There is also a great deal of related work on different causal estimands within the same general class of models (often
when the treatment is randomly assigned or randomly encouraged). For example, instrumental variables estimators and principal stratiﬁcation utilize the same model, and recent work
has related the intent-to-treat effects conditional on principal strata to as-treated effects conditional on the observed compliance behavior . Furthermore, work on indirect effects and mediation analysis in the potential outcomes framework uses this same model .
 Published online by Cambridge University Press
Why Process Matters for Causal Inference
A Framework for Reasoning about Causal Process Information
Causal Inference with Randomized Treatment Assignment: A Review
Much of causal inference centers on questions regarding treatment effects (sometimes known as total
effects). At the unit level, we would write such effects for units i = 1, . . . , n as the difference between the
observed outcome Yi ≡Yi(Xi) and a counterfactual outcome (as long as the counterfactual is assumed to
be well deﬁned). For example, if Xi = x, then the unit-level treatment effect of changing from x to x′ can
be written as the following:
Yi(x′) −Yi(x).
The two values in this contrast are often called potential outcomes, and this model for causal effects is
sometimes known as the potential outcomes model or the Neyman–Rubin causal model .
Unfortunately, although the potential outcome Yi(x) is observable when Xi = x, the other potential
outcome, Yi(x′), is not observable when x ̸= x′ because Yi(x′) is counterfactual. Analogously, when
Xi = x′, Yi(x′) is observable but Yi(x) is not. The fact Yi(x) and Yi(x′) can never be simultaneously
observed for the same unit is sometimes known as the fundamental problem of causal inference .
It is now well known that the most reliable approach to partially solving the FPOC involves randomly
assigning units to the values x and x′ (although there are many different methods of randomization and
some may be more reliable than others depending on the application). In its most simple form, randomization of units to x and x′ allows random draws from the marginal distributions of the potential outcomes
within the sample of i = 1, . . . , n units. If the n sample units are themselves randomly drawn from the
population, then randomization of units to x and x′ allows random draws from the marginal population
distributions, which we denote as FY(x) and FY(x′). Thus, as n →∞, we get consistent estimates of the
marginal population distributions of the potential outcomes.
The FPOC implies that randomization does not provide draws from the joint distribution of potential
outcomes (FY(x),Y(x′)) or the distribution of effects (FY(x′)−Y(x)), however, randomization provides point
identiﬁcation for average effects such as the average treatment effect (ATE) (also known as the average
total effect):
ATE ≡E[Y(x′) −Y(x)]
= E[Y(x′)] −E[Y(x)]
and conditional average treatment effects (CATE) (also known as the conditional average total effects),
CATE ≡E[Y(x′) −Y(x)|W = w]
= E[Y(x′)|W = w] −E[Y(x)|W = w].
It is important to note that W should not be posttreatment, but for many applications, W may be the
treatment itself W = X. An example of this will be presented in Section 3.
Assumptions Based on Pretreatment Variables: A Review
In the absence of randomization, one must use additional assumptions for the identiﬁcation of ATE or
CATE. For example, suppose we want to know the average effect for the units i = 1, . . . , nx for whom
Xi = x. For these units, Yi(x) is observed as Yi, whereas Yi(x′) is unobserved, so for the average effect
of interest,
E[Y(x′) −Y(x)|X = x] = E[Y(x′)|X = x] −E[Y(x)|X = x]
= E[Y(x′)|X = x] −E[Y|X = x]
the quantity E[Y(x′)|X = x] can only be estimated by making assumptions. Nearly always, these
assumptions require the measurement of pretreatment variables in order to make them operational.
 Published online by Cambridge University Press
Adam N. Glynn and Kevin M. Quinn
For example, one very popular assumption is that conditional on a pretreatment variable (or set of
variables) W, the assignment of treatment is ignorable . Intuitively, this
means that the units with Xi = x and Wi = w can be compared directly to units with Xi = x′ and
Wi = w, so that E[Y(x′)|X = x] can be estimated by averaging the Yi values for units with Xi = x′
and Wi = w. The key point is that without measuring W, it is not possible to utilize this assumption for
inference. In other words, the measurement of W makes the ignorability assumption operational.
Another typical example uses a pretreatment variable known as an instrument and involves the use of
alternative assumptions . In the simplest case, a binary instrument (Z) is assumed to
have been assigned ignorably, the effect of Z on a binary X is assumed to be monotonic (and to exist for
at least some units), and the effect of Z on a binary outcome (Y) is assumed to be due entirely to the effect
of Z on X (i.e., an exclusion restriction holds).2 If these assumptions hold, then although E[Y(x′)|X = x]
cannot be estimated precisely (without additional assumptions), the bounds of possible estimates may be
substantively informative . Again, the key point is that without measuring Z, it is not possible
to utilize these assumptions for inference. In this sense, measurement of Z provides information about the
causal effect when the instrumental variables assumptions are plausible.
Assumptions Based on Posttreatment Variables
The remainder of this paper will demonstrate that posttreatment variables can provide information about
causal effects in a manner similar to pretreatment variables. To demonstrate this formally, consider a posttreatment variable M (we could alternatively consider M to be a set of posttreatment variables, but for
simplicity in presentation, we will assume M to be a scalar). Sometimes posttreatment variables are known
as process variables, intermediate variables, or mediating variables. Often the processes described by these
variables are known as mechanisms.
As with the potential outcomes deﬁned above, we can deﬁne the effect of X on M in terms of potential
mediators. For example, if Xi = x, then Mi = Mi(x) and if the counterfactual mediator Mi(x′) is well
deﬁned, then the unit-level treatment effect of changing from x to x′ can be written as the following:
Mi(x′) −Mi(x),
where Mi(x) = Mi is observed and Mi(x′) is unobserved. If the potential mediator Mi(x) is well deﬁned,
and M is part of the process or mechanism by which X affects Y, then the potential outcome Y(x) can be
written as the following:
Yi(x) ≡Y(x, Mi(x)),
which can be interpreted as the value of Y that we would observe if X had been x and M had been what it
would have been if X had been x. If the potential mediator Mi(x′) is well deﬁned, the potential outcome
Yi(x′) can be deﬁned analogously as Y(x′, Mi(x′)).
It is important to note what we have not assumed. We have not assumed that quantities such as
Y(x, Mi(x′)) or Y(x′, Mi(x)) (which involve the values x and x′ simultaneously) are well deﬁned. These
types of quantities are necessary for path analysis (also known as mediation analysis)—the attempt to
decompose total causal effects into path speciﬁc effects—but they are not necessary when using process analysis to learn about total effects (the goal of this paper). Furthermore, we have not assumed that
Y(x, Mi(x)) = Y(x, m) when Mi(x) = m. In words, we do not need to assume that the potential outcome would be the same regardless of how we set the value of the mediator. For this paper, we need only
consider cases when the mediating variable is set by the process of intervening on X.
To see why the consideration of posttreatment variables can make additional assumptions operational,
consider again making inferences about the quantity E[Y(x′)|X = x]. The observation of Mi can aid
this inference because Mi = Mi(x) for these units, and knowing Mi(x) along with some background
knowledge of how X affects M may provide information about Mi(x′). Knowing Mi(x′) can in turn
provide information about Y(x′, Mi(x′)) under some assumptions. A simple example will clarify this.
2Angrist et al. also assumes that the potential outcomes and potential treatments are well deﬁned (i.e., the Stable Unit
Treatment Value Assumption holds).
 Published online by Cambridge University Press
Why Process Matters for Causal Inference
Consider the example presented in Section 1, where treatment (X = 1 if treated, X = 0 if not treated)
is the presence of EDR, the mediating variable is voter registration (M = 1 if registered on election day,
M = 0 if not registered on election day) and the outcome is turnout (Y = 1 if voted, and Y = 0 if
did not vote). Consider the individuals that did not have EDR available (X = 0). For these individuals,
we must make assumptions in order to make inferences about E[Y(1)|X = 0], which is unobserved.
However, suppose we observe that a subset of these individuals registered but did not vote (M = 1 and
Y = 0). Because one cannot vote without registering, we know that Yi(0, Mi(0)) = 0 when Mi(0) =
0 and Yi(1, Mi(1)) = 0 when Mi(1) = 0. If we are further willing to make an exclusion restriction
analogous to the one made in Angrist et al. by assuming that Yi(0, Mi(0)) = Yi(1, Mi(1)) when
Mi(1) = Mi(0) = 1, then it is straightforward to show that the observation of the a posttreatment variable
can make these assumptions operational. If we observe someone who was not treated (Xi = 0) and did
not vote (Yi = 0) so that Yi(0) = 0, then without observing the mediating variable, it is possible that
they would have voted if treated (Yi(1) = 1). However, if we observe that Mi = 1 so that Mi(0) = 1,
then we know that this individual would not have voted if treated (Yi(1) = 0) because Yi(1, Mi(1)) =
Yi(0, Mi(0)) = 0 if Mi(1) = 1 due to the exclusion restriction, and Yi(1, Mi(1)) = 0 when Mi(1) = 0
due to the registration requirement.
This demonstrates one possible way in which posttreatment variables can be used to provide information for causal inferences regarding total effects. There are many others . In Section 3.2, we will discuss the implications of this particular approach
within the context of turnout (and weaken some of these assumptions).
An Illustrative Example: The Effect of EDR on African American Turnout in
Non-EDR States
Many studies utilize cross-sectional Current Population Survey (CPS) data at the individual level3
to address the effects of relaxing registration laws (e.g., early deadlines for registration) on voter turnout.4
As stated in the abstract of Rosenstone and Wolﬁnger , the two key questions of such analyses are,
“After the drastic relaxation of voter registration requirements in the 1960s, do present state laws keep
people away from the polls? More speciﬁcally, which provisions have how much effect on what kinds of
To demonstrate our methods, we address these questions by analyzing 2004 CPS data on African
Americans—one of the most important “kinds of people” considered in this literature due to their history
of disenfranchisement by state laws. We code the relevant variables as the following:
X ∈{0 (No EDR available), 1 (EDR available)}
Y ∈{0 (Did not vote), 1(Voted)}.
Table 1 presents the data on voting behavior on residence in an EDR state in a 2 × 2 table. In addition, we
will, at some points adjust for a number of measured covariates including: family income, age, sex, and
education. All these variables are as deﬁned in the 2004 CPS.
Traditional Approaches that Assume Conditional Ignorability of Treatment Assignment
In this section, we look at two commonly used methods of making casual inferences using cross-sectional
data—logistic regression and matching. The methods differ with respect to the particular functional form
assumptions that are made, but each method makes essentially identical causal assumptions; namely, that
3The results from a weighted least squares analysis at the state level are substantively identical to those presented in this section.
4Unlike the other papers cited here, Achen compares turnout models that ignore registration with turnout models that utilize
regression laws instrumentally to justify the identiﬁcation of traditional effects in the turnout model (e.g., the effect of age on
turnout). Furthermore, Achen examines a model for registration as a prelude to the joint modeling of registration and
 Published online by Cambridge University Press
Adam N. Glynn and Kevin M. Quinn
Relationship between availability of election day registration and individual voting among African
Americans. Each entry is the number of citizens in that category
Did not vote
the counterfactuals are well deﬁned and that treatment assignment is conditionally ignorable given a set of
measured covariates. To be clear, we do not think the conditional ignorability assumption is very plausible
in this setting. As such, we do not put much faith in the accuracy of the resulting estimates. The purpose
of this section is not to provide plausible estimates of the EDR effect but rather to provide some sense of
what typical researchers might infer about the effect of EDR on voting based on the CPS data under study.
One can certainly do better than this. In Section 3.2, we show how one can make more plausible causal
inferences from exactly the same data by utilizing more plausible causal assumptions.
Throughout Section 3, our causal estimand will be a type of CATE known as the ATE on the control
units (ATC). Within the context of our voting application, ATC is formally deﬁned as:
ATC ≡E[Y(1) −Y(0)|X = 0].
In words, ATC is simply the change in turnout we would have expected in current non-EDR states if
EDR had been implemented in all these non-EDR states in 2004. This corresponds most closely to the
Rosenstone and Wolﬁnger question of whether state laws “keep people away from the polls.” It is
also useful to note ATC is simply the fraction of helped (Y(1) = 1, Y(0) = 0) units among the untreated
units minus the fraction of hurt (Y(1) = 0, Y(0) = 1) units among the untreated units. This means that
the sample version of ATC can be written as:
SATC ≡# {Yi(1) = 1, Yi(0) = 0, Xi = 0} −# {Yi(1) = 0, Yi(0) = 1, Xi = 0}
# {Xi = 0}
The population version of ATC can be written analogously. This will be especially relevant for the analysis
in Section 3.2.
Logistic regression
It is common for researchers to apply a logistic regression or probit model to data similar to the CPS
data in order to infer the causal effect of EDR on voting. The extent to which such an enterprise will
be successful depends on the extent to which ignorability holds conditional on the covariates as well as
how accurately the researchers’ regression models approximate the true conditional expectation of voting
given EDR status and the other covariates.
Although researchers typically only report coefﬁcient estimates and their standard errors (or perhaps
simple differences in ﬁtted probabilities), these quantities will not typically correspond directly to ATC.
Nonetheless, it is easy to use such regression results to construct an estimate of ATC . Speciﬁcally, we can estimate ATC with
ATCreg = 1
{µ(X = 1, zi, ˆα, ˆβββ) −µ(X = 0, zi, ˆα, ˆβββ)},
where the i = 1, . . . , nC index represents those individuals in non-EDR states (X = 0), zi is the vector
composed of individual i’s observed covariates (family income, education, sex, age, and a constant term),
E[Y|X = x, z] = µ(X = x, z, α, βββ) =
exp(xα + z′βββ)
1 + exp(xα + z′βββ)
 Published online by Cambridge University Press
Why Process Matters for Causal Inference
is the conditional probability of voting given EDR status and the measured covariates under the logistic
regression model.5 Note that in order to estimate ˆα and ˆβββ, we must utilize observations with X = 1 in
addition to the observations with X = 0 in the regression. However, because we are interested in the
ATE for the X = 0 individuals (ATC), the estimator averages the differences in the estimated regression
functions (the individual terms in Equation (2)) according to the empirical distribution of the covariates
(z) among the control units.6
Table 2 reports results from a series of nine logistic regression models. These models range from the
fairly ﬂexible model 1 in which all two-way interactions are present along with three-way interactions
between (EDR, sex, family income), (EDR, sex, age), and (EDR, sex, education) to the extremely parsimonious model 9 that only includes EDR and a constant term. Looking across the row that provides the
estimates of ATC, we see that these estimates are remarkably stable across the various speciﬁcations—
ranging from 0.096 under the parsimonious model 9 to 0.133 under model 5.7 In all cases, the lower
endpoint of the 95% conﬁdence interval does not fall below 0.056 and is typically closer to 0.09. Taken
as a whole, these results would seem to suggest an effect of EDR on voting among non-EDR-state
African American residents that is around a 10% point increase. Of course, all these estimates rely on
the fairly implausible assumption that assignment to EDR is conditionally ignorable given the measured
covariates.
Propensity score matching
Matching provides an alternative means to estimate the effect of EDR on voting among non-EDR-state
residents that does not rely on the speciﬁc parametric assumptions of logistic regression.8 We proceed
by ﬁtting a propensity score model9 and then using the GenMatch function in the Matching package
 to create a matched data set. One-to-one matches were constructed to achieve balance on
the estimated propensity scores as well as the observed covariates (family income, education, sex, and
Figure 1 provides a visual depiction of the pre- and postmatching conditional distributions of these variables given EDR status. Inspection of these ﬁgures suggests that balance on these variables was reasonable
before matching and was improved by the matching procedure. The variable for which postmatching balance appears the worst is family income.
If we are satisﬁed with the degree of balance obtained by this procedure, we can use the matched data
set to estimate ATC. Table 3 presents this estimate and associated measures of sampling variability. Here,
we see that the matching procedure produces an estimate of ATC that is equal to 0.144 (a 14% point
increase in turnout due to EDR among African Americans) with a 95% conﬁdence interval from almost
0.09 to nearly 0.20.
An Alternative Approach that Does Not Assume Conditional Ignorability
As the results from the “traditional” analyses above appear to be quite stable, one might be tempted
to infer that there is a large (9.5% points or more) effect of EDR on turnout among African American
citizens living in non-EDR states. Of course, there are a number of reasons that we might question these
5It is possible to allow the logistic regression model to include interactions between the treatment variable and the background
covariates. This creates no problems other than making the notation somewhat clumsy. In this case, it should be understood that
µ(X = x, zi, α, βββ) is formed by setting X = x in both the main effect and all interactions in which X appears.
6If we instead wanted an estimate the ATE for all observations, we would average these differences according to the empirical
distribution of the covariates for the control and the treated individuals.
7The change in effect size from speciﬁcation appears to be the result of the changing set of cases (due to the use of list-wise deletion)
that the empirical average is being taken over. In results, not reported here, we ﬁt these same models to the data set consisting of
the 6302 observations with complete data. The estimated value of ATC across these results is remarkably stable around 0.13.
8For recent work in political science using matching see, among others, Ho et al. and Sekhon .
9The propensity score model for the EDR indicator variable with family income, age, education, and sex as the predictor variables
was ﬁt with thin-plate regression splines and the smoothing parameter was chosen with generalized cross validation. Speciﬁcally,
this model was constructed by using the mgcv library in R to ﬁt a binomial generalized additive model with the following formula:
EDR ∼sex + s(famincome, age, educ, by=as.factor(sex)). This allows the probability of treatment to be
an arbitrary smooth function of family income, age, and education that differs across males and females.
 Published online by Cambridge University Press
Adam N. Glynn and Kevin M. Quinn
Logistic regression estimates of the effect of EDR on voting among African Americans. Entries without brackets are point estimates, entries in brackets are 95%
conﬁdence intervals. The row labeled ATC presents the estimate of the ATE on the control units along with the associated 95% conﬁdence interval.
(−10.927, −3.573)
(−11.284, −4.043)
(−11.265, −8.957)
(−11.186, −8.923)
(−1.948, −1.374)
(−7.933, −5.994)
(−10.786, −8.544)
(−12.464, −10.432)
(0.922, 1.026)
(−30.247, 9.114)
(−4.374, 7.853)
(−4.273, 7.81)
(0.59, 1.268)
(0.572, 1.24)
(0.524, 1.187)
(0.573, 1.25)
(0.34, 0.917(
(0.286, 0.833)
Family income
(0.116, 0.22)
(0.112, 0.215)
(0.065, 0.096)
(0.066, 0.097)
(0.116, 0.144)
(0.069, 0.099)
(0.057, 0.088)
(−3.774, 0.827)
(−3.458, 1.058)
(0.307, 0.553)
(0.298, 0.54)
(0.382, 0.619)
(0.316, 0.553)
(0.21, 0.428)
(0.029, 0.054)
(0.029, 0.054)
(0.022, 0.03)
(0.022, 0.029)
(0.015, 0.022)
(0.022, 0.029)
(0.023, 0.03)
(0.02, 0.205)
(0.033, 0.215)
(0.192, 0.25)
(0.192, 0.248)
(0.143, 0.194)
(0.2, 0.257)
(0.251, 0.299)
EDR * family income
(−0.352, 0.229)
(−0.063, 0.111)
(−0.06, 0.115)
(−4.564, 19.82)
(−1.084, 0.318)
(−1.009, 0.396)
Family income * sex
(−0.088, −0.024)
(−0.084, −0.022)
(−0.089, 0.059)
(−0.03, 0.012)
(−0.031, 0.011)
(−0.017, −0.002)
(−0.017, −0.002)
EDR * education
(−0.164, 0.845)
(−0.156, 0.155)
(−0.158, 0.15)
Sex * education
(0.013, 0.129)
(0.006, 0.12)
EDR * family income * sex
(−0.115, 0.241)
EDR * sex * age
(−0.04, 0.047)
EDR * sex * education
(−0.534, 0.091)
(0.09, 0.166)
(0.089, 0.168)
(0.088, 0.168)
(0.094, 0.168)
(0.098, 0.172)
(0.083, 0.165)
(0.092, 0.169)
(0.057, 0.136)
(0.056, 0.134)
 Published online by Cambridge University Press
Why Process Matters for Causal Inference
Distribution of covariates conditional on EDR status before and after matching among African Americans.
The dark bars in the barplots correspond to individuals in EDR states and the lighter bars correspond to individuals in
non-EDR states. Similarly, the solid black lines in the density plots correspond to individuals in EDR states, whereas
the dashed lines correspond to non-EDR state individuals.
seemingly robust results. There are far too few treated units to use as matches for control units (compare
the two rows of Table 1), and there are undoubtedly unmeasured confounding variables that might affect
the analysis or create overlap problems for measured confounding variables.10 In particular, a sensitivity
analysis that incorporates beliefs about unmeasured or unbalanced confounders might result in estimates
that were smaller than 9.5%. However, we do not have to speculate to this extent because there are data
within the 2004 CPS that can be utilized to demonstrate conclusively that the turnout effect cannot feasibly
be as large as the results from the traditional analyses imply. In the remainder of this paper, we detail how
one can more plausibly infer the effect on African American turnout of the adoption of EDR in non-
EDR states using posttreatment variables from the same cross-sectional CPS data as the “traditional”
The basic idea underlying everything that follows is that by noting the equivalence of Yi(x) and
Yi(x, M(x)), we can break the numerator of Equation (1) into a number of pieces that depend on the
10For example, we might think that southern states are fundamentally different than northern states when it comes to the effects of
registration laws on African American turnout. Unfortunately, no southern states had adopted EDR by 2004, so it is not possible
to match southern non-EDR states with southern EDR states.
 Published online by Cambridge University Press
Adam N. Glynn and Kevin M. Quinn
Summary of effect of EDR on voting among those not in EDR states among African Americans-based on a
matching analysis. The number of control (i.e., non-EDR) observations in the analysis is 6000 and the total
unweighted number of observations is 6216
t-statistic
(0.0896, 0.197)
observed values of M (registration) and Y (voting). Although unconditional assumptions about the fraction of helped and hurt units may be difﬁcult to make and defend, assumptions that are conditional on
M, Y (and X) are easier to make and defend. Conditioning on the posttreatment variable M thus allows
one to make use of background information in a way that provides information about ATC without assuming that treatment assignment is (conditionally) ignorable.
In what follows we focus our attention on the upper bound for ATC. Similar reasoning could be used to
calculate the lower bound for this quantity and, if desired, a fully Bayesian analysis could be conducted to
construct point and interval estimates for ATC rather than just its bounds. The point of this section is not
to provide a deﬁnitive estimate of the EDR effect. Instead, this section merely shows how conditioning
on a posttreatment variable allows one to make very plausible assumptions about potential outcomes and
that such assumptions result in an upper bound that is only above the traditional estimates of ATC in
implausible circumstances and therefore shows the traditional estimates of ATC to be implausibly large.
Table 4 presents the data on the non-EDR individuals from Table 1 with a variable included for whether
an individual was registered to vote. We note that this table contains a structural zero and that the data are quite informative for the
remaining three cells so that inference over the parameters of the observed variables is straightforward.
We also note that EDR could not have had a positive effect on the 5170 individuals that voted, and as
implied by the Manski bounds , our estimate for the upper bound of ATC cannot be greater
1276+676+5170 = 0.27. In other words, we cannot estimate the effect of EDR to be more than 27%
for this population of individuals. This upper bound is calculated in the same manner as the “worst-case”
upper bound described in the Hanmer analysis of EDR for earlier years of the CPS.
However, when we observe the mediating variable of registration, we have reason to downgrade this
upper bound even further. Suppose we are willing to assume that there would be a direct effect for only a
small proportion of the 676 individuals that registered and did not vote. Formally, we can state this as the
following:
Assumption 1. (Minimal direct effects among the registered). Yi(1, Mi(1)) −Yi(0, Mi(0)) = 1 when
Mi(1) = Mi(0) = 1 for no more than a small proportion of the X = 0, M = 1, Y = 0 population,
denoted with pdir.
Under Assumption 1, our estimate for the upper bound of ATC cannot be greater than
1276+pdir·676
1276+676+5170.
For example, if we assume that EDR would have had a direct effect on no more than 5% of the already
Individual registration and individual voting among African Americans who did not have EDR available.
Each entry is the number of citizens in that category in the 2004 CPS
X = 0 No EDR
Did not vote
 Published online by Cambridge University Press
Why Process Matters for Causal Inference
Responses to the question: which of the following was the MAIN reason (you/name) (was/were) not
registered to vote? The answers were provided by the 1276 non-EDR individuals who did not register or vote
Main reason provided for not registering
Not interested in the election or politics
My vote would not make a difference
Not eligible to vote
Did not meet registration deadlines
Did not know where or how to register
Did not meet residency requirements/did not live here long enough
Permanent illness or disability
Difﬁculty with English
Other reason
Do not know
No response
registered individuals, then pdir = 0.05 and our estimate for the upper bound of ATC cannot be greater
1276+0.05·676
1276+676+5170 = 0.18. Note that this is an extremely conservative assumption because the most plausible story for a direct effect is based on the additional “advertising” that would accompany the adoption
of EDR, and large randomized studies have found direct mail and phone encouragement effects of around
1% for African Americans .
Having reduced the estimated upper bound from the Manski bound of 27% to the new bound of 18%,11
we can further reduce the bound by considering the 1276 individuals that did not register or vote. The ﬁrst
thing to note is that due to the registration requirement for voting, there can be no direct effects for these
individuals. Formally, we state this as the following:
Assumption 2. (No direct effects among the unregistered). Due to registration laws, Yi(0, Mi(0)) =
Yi(1, Mi(1)) when Mi(1) = Mi(0) = 0.
Under Assumption 2, for those with M = 0, the effect of the treatment on the outcome can only
be positive when the effect of the treatment on the mediator is positive. Thus, we can further reduce
the estimated upper bound for ATC by focusing solely on the effect of EDR on registration for 1276
individuals that did not register or vote. Fortunately, the 2004 CPS contains data that are relevant to exactly
this question. Each of these 1276 respondents that did not register or vote was asked for the main reason
they did not register. The counts of their responses are presented in Table 5. Although these responses do
not provide deﬁnitive information about the percentage of the 1276 that would have registered if EDR had
been available, the ﬁrst three rows of 445 + 46 + 94 = 585 responses clearly imply a lack of interest in
politics, a lack of belief in the efﬁcacy of voting, or an eligibility restriction, and hence we might think that
these individuals would have been extremely unlikely to register in the case that EDR had been available.
We deﬁne a binary variable U on the basis of these responses. For those uninterested individuals in the
ﬁrst three rows of Table 5, we say that U = 1. For the potentially interested individuals in rows 4–12 of
Table 5, we say that U = 0.
Assumption 3. (Limited effects on the mediator among the unregistered and uninterested). Mi(1) −
Mi(0) = 1 for at most a small proportion of the U = 1, X = 0, M = 0, Y = 0 population, who report
themselves to be uninterested or ineligible. We let preg|U=1 denote this proportion.
11Hanmer employs alternative assumptions that do not utilize the measurement of a posttreatment variable in order to reduce
the worstcase upper bound. For example, the upper bound can be reduced by assuming “capped outcomes” (that the average
potential outcome under EDR in the non-EDR states will not exceed the average observed outcome for the EDR states). As noted
in Hanmer , this assumption will be controversial. We have intended our Assumption 1 (and the following Assumptions 2
and 3) to be relatively uncontroversial.
 Published online by Cambridge University Press
Adam N. Glynn and Kevin M. Quinn
Under Assumptions 1–3, our estimate for the upper bound of ATC cannot be greater than
691+preg|U=1·585+pdir·676
1276+676+5170
. For example, if we assume that EDR would have caused no more than 5% of
the 585 uninterested/ineligible individuals to register, then preg|U=1 = 0.05 and our estimate for the upper
bound of ATC cannot be greater than 691+0.05·585+0.05·676
1276+676+5170
= 0.11. Again, note that this is a very conservative assumption. In order for the availability of EDR to have caused the U = 1 individuals to register,
it would have had to interest them in voting as well as making it possible for them to register. Due to the
aforementioned studies on advertising effects, it seems highly unlikely that EDR would have caused more
than 5% of this group to register.
Note that under the very plausible Assumptions 1–3 with pdir = 0.05 and preg|U=1 = 0.05, our
estimate for the upper bound of possible values for ATC is lower than the estimates we obtained using
propensity score matching or using logistic regression models 1–7. This means that using a very simple
analysis based on very plausible assumptions, we now know that most of the estimates we produced using
the traditional analyses are impossibly large.
Furthermore, our estimate for the upper bound of ATC is only slightly higher than the smallest estimates
of ATC that we achieved using the traditional approaches in the previous section (logistic regression
models 8 and 9), and this is only because the upper bound implicitly assumes that all the 691 potentially
interested U = 0 individuals from rows 4–12 of Table 5, who did not register or vote, will be caused to
register and vote by the availability of EDR. It is straightforward to conduct a sensitivity analysis on these
691 individuals by deﬁning the proportion that would have been caused to register and vote as preg|U=0.
Using Assumptions 1–3 with pdir = 0.05 and preg|U=1 = 0.05, Fig. 2 presents the upper bound as a
function of preg|U=0. The dashed lines represent 95% pointwise conﬁdence intervals for the upper bound
(which can be calculated in the standard asymptotic manner because the upper bound is a function of
proportions). As a point of comparison, horizontal lines are presented to represent the estimates using
matching and logistic regression (models 1–9) under conditional ignorability assumptions.
Fig. 2 Comparison of evidence on the effects of EDR on African American turnout in the non-EDR States (ATC). The
upward sloping line represents the upper bound of possible effects under Assumptions 1, 2, and 3 with pdir = 0.05
and preg|U=1 = 0.05, and depending on what proportion of the unregistered (M = 0), nonvoting (Y = 0), but
potentially interested (U = 0) population would be caused to register (and vote) by adoption of EDR (preg|U=0). The
dashed lines represent 95% pointwise conﬁdence intervals for the upper bound. The horizontal lines are presented
for comparison and represent the estimates using matching and logistic regression (Models 1–9) under conditional
ignorability assumptions.
 Published online by Cambridge University Press
Why Process Matters for Causal Inference
There are two important things to note about this ﬁgure. First, as noted above, the matching estimate
and the estimates from the logistic regression models 1–7 are all larger than the upper bound, regardless
of the value for preg|U=0. Second, in order for an estimated upper bound on the possible values for ATC
to be as large as 9.5%, we must have preg|U=0 at least as large as 0.89 = .095·7122−(0.05·585+0.05·676)
other words, if we believe that Assumptions 1–3 are plausible with pdir = 0.05 and preg|U=1 = 0.05, then
in order to believe that the results from models 8 and 9 of the traditional analyses of the previous section
are plausible, we must simultaneously believe that at least 89% of the unregistered individuals in rows
4–12 of Table 5 would have registered and voted had EDR been available to them. We suspect that many
researchers would ﬁnd this amount of voting and registration in a group that had not previously registered
or voted to be implausibly high.
Discussion
Causal assumptions are a necessary part of making causal inferences from nonexperimental data. It is common for researchers to make such assumptions conditional on pretreatment covariates. The assumption
that treatment assignment is conditionally ignorable given some set of measured pretreatment variables
(also known as the “selection on observables” or “no unmeasured confounders” assumption) is frequently
employed. It is extremely rare to see researchers use causal assumptions that are speciﬁed conditional
on the value of a posttreatment variable. In this paper, we have shown how causal assumptions that are
conditional on a posttreatment variable might, in some situations, be more plausible than the standard
conditional ignorability of treatment assignment assumption. Further, in the example we studied, these
more plausible assumptions would cause one to believe that standard estimates of the EDR effect are
implausibly high.
Although there may be relatively few applications that are identical to the EDR example discussed in
this paper, the general point of the paper is still valid and potentially useful in other applications. Our point
is not that researchers should make exactly the same assumptions that we made here; rather, we hope to
convince researchers that it is worthwhile to consider the possibility that subject matter expertise can be
used to specify plausible causal assumptions conditional on values of posttreatment variables rather than
just conditional on pretreatment variables.