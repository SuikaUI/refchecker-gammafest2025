IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 21, NO. 12, DECEMBER 2012
No-Reference Image Quality Assessment
in the Spatial Domain
Anish Mittal, Anush Krishna Moorthy, and Alan Conrad Bovik, Fellow, IEEE
Abstract—We
statistic-based
distortion-generic
blind/no-reference
assessment (IQA) model that operates in the spatial domain.
The new model, dubbed blind/referenceless image spatial quality
distortion-speciﬁc
features, such as ringing, blur, or blocking, but instead uses scene
statistics of locally normalized luminance coefﬁcients to quantify
possible losses of “naturalness” in the image due to the presence
of distortions, thereby leading to a holistic measure of quality. The
underlying features used derive from the empirical distribution of
locally normalized luminances and products of locally normalized
luminances under a spatial natural scene statistic model. No
transformation to another coordinate frame (DCT, wavelet, etc.)
is required, distinguishing it from prior NR IQA approaches.
Despite its simplicity, we are able to show that BRISQUE
is statistically better than the full-reference peak signal-tonoise ratio and the structural similarity index, and is highly
competitive with respect to all present-day distortion-generic
NR IQA algorithms. BRISQUE has very low computational
complexity, making it well suited for real time applications.
BRISQUE features may be used for distortion-identiﬁcation as
well. To illustrate a new practical application of BRISQUE,
we describe how a nonblind image denoising algorithm can
be augmented with BRISQUE in order to perform blind
image denoising. Results show that BRISQUE augmentation
performance
improvements
state-of-the-art
methods. A software release of BRISQUE is available online:
 
for public use and evaluation.
Index Terms—Blind quality assessment, denoising, natural
scene statistics, no reference image quality assessment, spatial
I. INTRODUCTION
ITH THE launch of networked handheld devices which
can capture, store, compress, send and display a variety
of audiovisual stimuli; high deﬁnition television (HDTV);
streaming Internet protocol TV (IPTV) and websites such as
Youtube, Facebook and Flickr etc., an enormous amount of
visual data of visual data is making its way to consumers.
Because of this, considerable time and resources are being
Manuscript received January 16, 2012; revised July 8, 2012; accepted
August 5, 2012. Date of publication August 17, 2012; date of current
version November 14, 2012. This work was supported by the National
Science Foundation under Grant CCF-0728748 and Grant IIS-1116656 and
by Intel Corporation and Cisco Systems, Inc. under the Video Aware Wireless
Networks (VAWN) Program. The associate editor coordinating the review of
this manuscript and approving it for publication was Prof. Alex ChiChung Kot.
The authors are with the Laboratory for Image and Video Engineering,
Department of Electrical and Computer Engineering, University of Texas
 ;
 ; ).
Color versions of one or more of the ﬁgures in this paper are available
online at 
Digital Object Identiﬁer 10.1109/TIP.2012.2214050
expanded to ensure that the end user is presented with a
satisfactory quality of experience (QoE) . While traditional
QoE methods have focused on optimizing delivery networks
with respect to throughput, buffer-lengths and capacity, perceptually optimized delivery of multimedia services is also
fast gaining importance. This is especially timely given the
explosive growth in (especially wireless) video trafﬁc and
expected shortfalls in bandwidth. These perceptual approaches
attempt to deliver an optimized QoE to the end-user by
utilizing objective measures of visual quality.
Objective blind or No-reference (NR) image quality assessment (IQA) refers to automatic quality assessment of an image
using an algorithm such that the only information that the
algorithm receives before it makes a prediction on quality is
the distorted image whose quality is being assessed. On the
other end of the spectrum lie full-reference (FR) algorithms
that require as input not only the distorted image, but also
a ‘clean’, pristine reference image with respect to which the
quality of the distorted image is assessed. Somewhere between
these two extremes lie reduced-reference (RR) approaches that
possess some information regarding the reference image (eg.,
a watermark), but not the actual reference image itself, apart
from the distorted image – .
Our approach to NR IQA is based on the principle that
natural images1 possess certain regular statistical properties
that are measurably modiﬁed by the presence of distortions.
Figure 1(a) and (b) shows examples of natural and artiﬁcial
images from the TID database respectively. The normalized
luminance coefﬁcients (explained later) of the natural image
closely follow Gaussian-like distribution, as shown in Fig. 1(c)
while the same doesnot hold for the empirical distribution of
the artiﬁcial image shown in Fig. 1(d).
Deviations from the regularity of natural statistics, when
quantiﬁed appropriately, enable the design of algorithms capable of assessing the perceptual quality of an image without
the need for any reference image. By quantifying natural
image statistics and refraining from an explicit characterization of distortions, our approach to quality assessment
is not limited by the type of distortions that afﬂict the
image. Such approaches to NR IQA are signiﬁcant since most
current approaches are distortion-speciﬁc – , i.e., they
are capable of performing blind IQA only if the distortion
1‘Natural’ images are not necessarily images of natural environments such
as trees or skies. Any natural light image that is captured by an optical camera
and is not subjected to artiﬁcial processing on a computer is regarded as a
natural image. Of course, image sensors may capture natural radiation other
than visible light, but the images formed may obey different NSS than those
considered here.
1057–7149/$31.00 © 2012 IEEE
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 21, NO. 12, DECEMBER 2012
Normalized luminance
Probability
Gaussian fit
Probability
Gaussian Fit
Underlying Gaussianity of natural images. Examples of (a) natural images and (b) artiﬁcial images from the TID database . (c) shows that
normalized luminance coefﬁcients follow a nearly Gaussian distribution for the natural image (a). (d) shows that this property does not hold true for the
empirical distribution of the artiﬁcial image (b).
that afﬂicts the image is known beforehand, e.g., blur or
noise or compression and so on (see below). Previously, we
have proposed other NSS-based distortion-generic approaches
to NR IQA that statistically model images in the wavelet
domain and in the DCT-domain . Our contribution
here is a new NR IQA model that is purely spatial; that relies
on a spatial NSS model which does not require a mapping
to a different co-ordinate domain (wavelet, DCT, etc.) and so
is ‘transform-free’; that demonstrates better ability to predict
human judgments of quality than other popular FR and NR
IQA models; that is highly efﬁcient; and that is useful for
perceptually optimizing image processing algorithms such as
denoising.
While the presence of a reference image or information
regarding the reference simpliﬁes the problem of quality
assessment, practical applications of such algorithms are limited in real-world scenarios where reference information is
generally unavailable at nodes where quality computation is
undertaken. Further, it can be argued that FR and to a largeextent RR approaches are not quality measures in the true
sense, since these approaches measure ﬁdelity relative to a
reference image. Moreover, the assumption of a pristine nature
of any reference is questionable, since all images are ostensibly
distorted .
The performance of any IQA model is best gauged by its
correlation with human subjective judgements of quality,
since the human is the ultimate receiver of the visual
signal. Such human opinions of visual quality are generally
obtained by conducting large-scale human studies, referred
to as subjective quality assessment, where human observers
rate a large number of distorted (and possibly reference)
signals. When the individual opinions are averaged across the
subjects, a mean opinion score (MOS) or differential mean
opinion score (DMOS) is obtained for each of the visual
signals in the study, where the MOS/DMOS is representative
of the perceptual quality of the visual signal. The goal of
an objective quality assessment (QA) algorithm is to predict
quality scores for these signals such that the scores produced
by the algorithm correlate well with human opinions of
signal quality (MOS/DMOS). Practical application of QA
algorithms requires that these algorithms compute perceptual
quality efﬁciently.
The regularity of natural scene statistics (NSS) has been
well established in the visual science literature, where regularity has been demonstrated in the spatial domain , and
in the wavelet domain . For example, it is well known
that the power spectrum of natural images is a function of
frequency and takes the form 1/f γ , where γ is an exponent
that varies over a small range across natural images.
The product of our research is the Blind/Referenceless
Image Spatial QUality Evaluator (BRISQUE) which utilizes
an NSS model framework of locally normalized luminance
coefﬁcients and quantiﬁes ‘naturalness’ using the parameters of the model. BRISQUE introduces a new model of
the statistics of pair-wise products of neighboring (locally
normalized) luminance values. The parameters of this model
further quantify the naturalness of the image. Our claim is
that characterizing locally normalized luminance coefﬁcients
MITTAL et al.: NR IQA IN THE SPATIAL DOMAIN
in this way is sufﬁcient not only to quantify naturalness, but
also to quantify quality in the presence of distortion.
In this article, we detail the statistical model of locally
normalized luminance coefﬁcients in the spatial domain, as
well as the model for pairwise products of these coefﬁcients.
We describe the statistical features that are used from the
model and demonstrate that these features correlate well with
human judgements of quality. We then describe how we learn
a mapping from features to quality space to produce an
automatic blind measure of perceptual quality. We thoroughly
evaluate the performance of BRISQUE, and statistically compare BRISQUE performance to state-of-the-art FR and NR
IQA approaches. We demonstrate that BRISQUE is highly
competitive to these NR IQA approaches, and also statistically
better than the popular full-reference peak signal-to-noiseratio (PSNR) and structural similarity index (SSIM). We
show that BRISQUE performs well on independent databases,
analyze its complexity and compare it with other NR IQA
approaches. Finally, to further illustrate the practical relevance
of BRISQUE, we describe how a non-blind image denoising
algorithm can be augmented with BRISQUE in order to
improve blind image denoising. Results show that BRISQUE
augmentation leads to signiﬁcant performance improvements
over the state-of-the-art. Before we describe BRISQUE in
detail, we ﬁrst brieﬂy review relevant prior work in the area
of blind IQA.
II. PREVIOUS WORK
Most existing blind IQA models proposed in the past
assume that the image whose quality is being assessed is
afﬂicted by a particular kind of distortion – , .
These approaches extract distortion-speciﬁc features that relate
to loss of visual quality, such as edge-strength at blockboundaries. However, a few general purpose approaches for
NR IQA have been proposed recently.
Li devised a set of heuristic measures to characterize visual
quality in terms of edge sharpness, random noise and structural
noise while Gabarda and Cristobal, modeled anisotropies
in images using Renyi entropy . The authors in 
use gabor ﬁlter based local appearance descriptors to form
a visual codebook, and learn DMOS score vector, associating
each word with a quality score. However, in the process of
visual codebook formation, each feature vector associated with
an image patch is labeled by DMOS asigned to the entire
image. This is questionable as each image patch can present a
different level of quality depending on the distortion process
the image is afﬂicted with. In particular, local distortions
such as packet loss might afﬂict only a few image patches.
Also, the approach is computationally expensive limiting its
applicability in real time applications.
Tang et al. proposed an approach which learns an
ensemble of regressors trained on three different groups of
features - natural image statistics, distortion texture statistics
and blur/noise statistics. Another approach is based on a
hybrid of curvelet, wavelet and cosine transforms. Although
these approaches work on a variety of distortions, each set
of features (in the ﬁrst approach) and transforms (in the
second) caters only to certain kinds of distortion processes.
This limits the applicability of their framework to new
distortions.
We have also developed previous NR QA models in the
past, following our philosophy, ﬁrst fully developed in ,
that NSS models provide powerful tools for probing human
judgements of visual distortions. Our work on NSS based
FR QA algorithms , , , more recent RR models
 and very recent work on NSS based NR QA ,
 , have led us to the conclusion that visual features
derived from NSS lead to particularly potent and simple QA
models .
Our recently proposed NSS based NR IQA model, dubbed
the Distortion Identiﬁcation-based Image INtegrity and Verity Evaluation (DIIVINE) index, deploys summary statistics
derived from an NSS wavelet coefﬁcient model, using a two
stage framework for QA: distortion-identiﬁcation followed by
distortion-speciﬁc QA . The DIIVINE index performs
quite well on the LIVE IQA database , achieving statistical
parity with the full-reference structural similarity (SSIM)
index .
A complementary approach developed at the same time,
named BLind Image Notator using DCT Statistics (BLIINDS-
II index) is a pragmatic approach to NR IQA that operates
in the DCT domain, where a small number of features are
computed from an NSS model of block DCT coefﬁcients .
Efﬁcient NSS features are calculated and fed to a regression
function that delivers accurate QA predictions. BLIINDS-II is
a single-stage algorithm that also delivers highly competitive
QA prediction power. Although BLIINDS-II index is multiscale, the small number of feature types (4) allow for efﬁcient
computation of visual quality and hence the index is attractive
for practical applications.
While both DIIVINE and BLIINDS-II deliver top NR IQA
performance (to date), each of them has certain limitations.
The large number of features that DIIVINE computes implies
that it may be difﬁcult to compute in real time. Although
BLIINDS-II is more efﬁcient than DIIVINE, it requires nonlinear sorting of block based NSS features, which slows it
considerably.
In our continued search for fast and efﬁcient high performance NSS based NR QA indices, we have recently studied the possibility of developing transform-free models that
operate directly on the spatial pixel data. Our inspiration for
thinking we may succeed is the pioneering work by Ruderman
 on spatial natural scene modeling, and the success of the
spatial multi-scale SSIM index , which competes well with
transform domain IQA models.
III. BLIND SPATIAL IMAGE QUALITY ASSESSMENT
Much recent work has focused on modeling the statistics
of responses of natural images using multiscale transforms
(eg., Gabor ﬁlters, wavelets etc.) . Given that neuronal
responses in area V1 of visual cortex perform scale-spaceorientation decompositions of visual data, transform domain
models seem like natural approaches, particularly in view of
the energy compaction (sparsity) and decorrelating properties
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 21, NO. 12, DECEMBER 2012
of these transforms when combined with divisive normalization strategies , . However, successful models of
spatial luminance statistics have also received attention from
vision researchers .
A. Natural Scene Statistics in the Spatial Domain
The spatial approach to NR IQA that we have developed
can be summarized as follows. Given a (possibly distorted)
image, ﬁrst compute locally normalized luminances via local
mean subtraction and divisive normalization . Ruderman
observed that applying a local non-linear operation to logcontrast luminances to remove local mean displacements from
zero log-contrast and to normalize the local variance of the log
contrast has a decorrelating effect . Such an operation may
be applied to a given intensity image I(i, j) to produce:
ˆI(i, j) = I(i, j) −μ(i, j)
σ(i, j) + C
where, i ∈1, 2 . . . M, j ∈1, 2 . . . N are spatial indices, M, N
are the image height and width respectively, C = 1 is a
constant that prevents instabilities from occurring when the
denominator tends to zero (eg., in the case of an image patch
corresponding to the plain sky) and
wk,l Ik,l(i, j)
wk,l(Ik,l(i, j) −μ(i, j))2
where w = {wk,l|k = −K, . . . , K,l = −L, . . . L} is a 2D
circularly-symmetric Gaussian weighting function sampled out
to 3 standard deviations and rescaled to unit volume. In our
implementation, K = L = 3. We show how performance
varies with changes in the window size in the performance
evaluation section.
Ruderman also observed that these normalized luminance
values strongly tend towards a unit normal Gaussian characteristic for natural images. Such an operation can be used
to model the contrast-gain masking process in early human
vision , . We utilize the pre-processing model (1)
in our QA model development and refer to the transformed
luminances I(i, j) as mean subtracted contrast normalized
(MSCN) coefﬁcients. As illustrated in the left column of
Fig. 2, there is high correlation between surrounding pixels
because image functions are generally piecewise smooth aside
from sparse edge discontinuities. Hence we observe a diagonal
kind of structure in the plots shown in the left column.
The normalization procedure greatly reduces dependencies
between neighboring coefﬁcients as is apparent in the plots
shown in the right column.
In order to help the reader visualize what the non-linear
transformation does to an image, Figure 3 plots an image from
the LIVE IQA database , its local mean ﬁeld μ(i, j) and
local variance ﬁeld, σ(i, j) and the MSCN ﬁeld. The variance
ﬁeld highlights object boundaries and other local high contrast
phenomenon. The MSCN ﬁeld, while clearly not entirely
decorrelated, exhibits a largely homogeneous appearance with
a few low-energy residual object boundaries.
Our hypothesis is that the MSCN coefﬁcients have characteristic statistical properties that are changed by the presence
of distortion, and that quantifying these changes will make it
possible to predict the type of distortion affecting an image
as well as its perceptual quality. In order to visualize how
the MSCN coefﬁcient distributions vary as a function of
distortion, Fig. 4 plots a histogram of MSCN coefﬁcients for
a natural undistorted image and for various distorted versions
of it. Notice how the reference image exhibits a Gaussianlike appearance, as observed by Ruderman , while each
distortion modiﬁes the statistics in its own characteristic way.
For example, blur creates a more Laplacian appearance, while
white-noise distortion appears to reduce the weight of the tail
of the histogram. We have found that a generalized Gaussian
distribution (GGD) can be used to effectively capture a broader
spectrum of distorted image statistics, which often exhibit
changes in the tail behaviour (i.e. kurtosis) of the empirical
coefﬁcient distributions where the GGD with zero mean
is given by:
f (x; α, σ 2) =
2β(1/α) exp
and (·) is the gamma function:
The shape parameter α controls the ‘shape’ of the distribution while σ 2 control the variance. We choose the zero mean
distribution, since (generally) MSCN coefﬁcient distributions
are symmetric. The parameters of the GGD (α, σ 2), are estimated using the moment-matching based approach proposed
We deploy this parametric model to ﬁt the MSCN empirical
distributions from distorted images as well as undistorted ones.
For each image, we estimate 2 parameters (α, σ 2) from a
GGD ﬁt of the MSCN coefﬁcients. These form the ﬁrst set
of features that will be used to capture image distortion. To
show that pristine and distorted images are well separated
in GGD parameter space, we took a set of pristine images
from the Berkeley image segmentation database . Similar
kinds of distortions as present in the LIVE IQA database
 - JPEG 2000, JPEG, white noise, Gaussian blur, and fast
fading channel errors were introduced in each image at varying
degrees of severity to form the distorted image set. As shown
in Fig. 5(a), pristine and distorted images occupy different
regions in this parameter space. White noise is very clearly
separated from the pristine image set making it one of the
easiest to gauge the quality of JPEG2000 and fast fading have a
high degree of overlap as fast fading images in LIVE database
are actually multidistorted, ﬁrst compressed into a bitstream
using a JPEG2000 codec, then passed through a Rayleigh fast
fading channel to simulate packet loss .
MITTAL et al.: NR IQA IN THE SPATIAL DOMAIN
Scatter plot between neighboring values of (a) Original luminance coefﬁcients and (b) MSCN coefﬁcients. Rows from top to bottom illustrate
horizontal, vertical, main diagonal, and secondary diagonal neighbors. Notice a high correlation between surrounding pixels with a diagonal structure in the
plots shown in (a). The normalization procedure greatly reduces these dependencies as is apparent in the plots shown in (b).
We also model the statistical relationships between neighboring pixels. While MSCN coefﬁcients are deﬁnitely more
homogenous for pristine images, the signs of adjacent coef-
ﬁcients also exhibit a regular structure, which gets disturbed
in the presence of distortion. We model this structure using
the empirical distributions of pairwise products of neighboring
coefﬁcients
orientations
horizontal (H), vertical (V), main-diagonal (D1) and secondarydiagonal (D2), as illustrated in Fig. 6. Speciﬁcally,
H(i, j) = ˆI(i, j) ˆI(i, j + 1)
V(i, j) = ˆI(i, j) ˆI(i + 1, j)
D1(i, j) = ˆI(i, j) ˆI(i + 1, j + 1)
D2(i, j) = ˆI(i, j) ˆI(i + 1, j −1)
for i ∈{1, 2 . . . M} and j ∈{1, 2 . . . N}.
Under the Gaussian coefﬁcient model, and assuming the
MSCN coeffﬁcients are zero mean and unit variance, these
products obey the following distribution in the absence of
distortion :
f (x, ρ) =
is an asymmetric probability density function,
ρ denotes the correlation coefﬁcient of adjacent coefﬁcents,
and K0 is the modiﬁed bessel function of the second kind.
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 21, NO. 12, DECEMBER 2012
Effect of the normalization procedure. (a) Original image I. (b) Local
mean ﬁeld μ. (c) I −μ. (d) Local variance ﬁeld σ. (e) MSCN coefﬁcients
((I −μ)/σ).
Number of coefficients(Normalized)
Histogram of MSCN coefﬁcients for a natural undistorted image
and its various distorted versions. Distortions from the LIVE IQA database
 . jp2k: JPEG2000. jpeg: JPEG compression. WN: additive white Gaussian
noise. blur: Gaussian blur. ff: Rayleigh fast-fading channel simulation.
While we have found that this density function is a good model
of the empirical histograms of products of adjacent normalized
coefﬁcients, it has only a single parameter, and as such, does
not provide a good ﬁt to the empirical histograms of coefﬁcient
products (Fig. 2) from distorted images. Further, it is not
ﬁnite at the origin. Hence, as a practical alternative, we adopt
the very general asymmetric generalized Gaussian distribution
(AGGD) model . In order to visualize how paired products
vary in the presence of distortion, in Fig. 7, we plot histograms
of paired products along each of four orientations, for a
reference image and for distorted versions of it.
The AGGD with zero mode is given by:
f (x; ν, σ 2
The shape parameter ν controls the ‘shape’ of the distribution while σ 2
are scale parameters that control
the spread on each side of the mode, respectively. The
AGGD further generalizes the generalized Gaussian distribution (GGD) and subsumes it by allowing for asymmetry
in the distribution. The skew of the distribution is a function of
the left and right scale parameters. If σ 2
r , then the AGGD
reduces to the GGD. Although the AGGD is infrequently
used, it has been deployed to model skewed heavy-tailed
distributions of image texture . The parameters of the
AGGD (ν, σ 2
r ), are estimated using the moment-matching
based approach proposed in . Figure 5(b) shows the 3-D
scatter plot between (ν, σ 2
r ) for horizontal paired products
using the same set of images as used for showing separation
in GGD parameter space. It can be visualized that different
distortions occupy different parts of the space. Also, we expect
images to have a better separation when modeled in the high
dimensional space of parameters obtained by ﬁtting AGGD
distributions to paired products from different orientations and
scales together. This ﬁgure also motives the use of (12) to
better capture the ﬁnite empirical density function.
The parameters (η, ν, σ 2
r ) of the best AGGD ﬁt are
extracted where η is given by:
η = (βr −βl)   2
Thus for each paired product, 16 parameters (4 parameters/orientation × 4 orientations) are computed, yielding
the next set of features. Table I summarizes the features
Images are naturally multiscale, and distortions affect image
structure across scales. Further, as research in quality assessment has demonstrated, incorporating multiscale information
when assessing quality produces QA algorithms that perform better in terms of correlation with human perception
 , . Hence, we extract all features listed in Table I
at two scales - the original image scale, and at a reduced
resolution (low pass ﬁltered and downsampled by a factor
of 2). We observed that increasing the number of scales beyond
2 did not contribute to performance much. Thus, a total of
MITTAL et al.: NR IQA IN THE SPATIAL DOMAIN
(a) 2-D scatter plot between shape and scale parameters obtained by ﬁtting GGD to the empirical distributions of MSCN coefﬁcients of pristine
images of Berkeley image segmentation database and simulated distorted images, where similar kinds of distortions as those present in the LIVE IQA
database were introduced in each image at varying degrees of severity.
(b) 3-D scatter plot between shape, left scale, and right scale obtained by ﬁtting AGGD to horizontal paired products using the same set of images as (a).
SUMMARY OF FEATURES EXTRACTED IN ORDER TO CLASSIFY AND QUANTIFY DISTORTIONS
Feature ID
Feature Description
Computation Procedure
Shape and variance
Fit GGD to MSCN coefﬁcients
Shape, mean, left variance, right variance
Fit AGGD to H pairwise products
Shape, mean, left variance, right variance
Fit AGGD to V pairwise products
Shape, mean, left variance, right variance
Fit AGGD to D1 pairwise products
Shape, mean, left variance, right variance
Fit AGGD to D2 pairwise products
Various paired products computed in order to quantify neighboring statistical relationships. Pairwise products are computed along four
orientations—horizontal, vertical, main-diagonal, and secondary-diagonal—at
a distance of 1 pixel.
36 features – 18 at each scale, are used to identify distortions
and to perform distortion-speciﬁc quality assessment. In Fig. 8,
we plot the Spearman’s rank ordered correlation coefﬁcient
(SROCC) between each of these features and human DMOS
from the LIVE IQA database, for each of the distortions in
the database – JPEG and JPEG2000 compression, additive
white Gaussian noise, Gaussian blur and a Rayleigh fast fading
channel distortion, to ascertain how well the features correlate
with human judgments of quality. Note that no training is
undertaken here, the plot is simply to illustrate that each
feature captures quality information and to show that images
are affected differently by different distortions.
B. Quality Evaluation
A mapping is learned from feature space to quality scores
using a regression module, yielding a measure of image quality. The framework is generic enough to allow for the use of
any regressor. In our implementation, a support vector machine
(SVM) regressor (SVR) is used. SVR has previously been
applied to image quality assessment problems , , .
For example, a learning driven feature pooling approach using
SVR was proposed in . Wavelet-domain NSS and singular
value decomposition features have been used to map quality
to human ratings via SVR in and respectively. SVR
is generally noted for being able to handle high dimensional
data . We utilize the LIBSVM package to implement
the SVR with a radial basis function (RBF) kernel.
IV. PERFORMANCE EVALUATION
A. Correlation With Human Opinions
We used the LIVE IQA database to test the performance of BRISQUE, which consists of 29 reference images
with 779 distorted images spanning ﬁve different distortion
categories – JPEG2000 (JP2K) and JPEG compression, additive white Gaussian noise (WN), Gaussian blur (Blur), and
a Rayleigh fast-fading channel simulation (FF). Each of the
distorted images has an associated difference mean opinion
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 21, NO. 12, DECEMBER 2012
−1 −0.8−0.6−0.4−0.2
0.2 0.4 0.6 0.8
Paired product coefficients
Number of coefficients(Normalized)
−1 −0.8−0.6−0.4−0.2
0.2 0.4 0.6 0.8
Paired product coefficients
Number of coefficients(Normalized)
−1 −0.8−0.6−0.4−0.2
0.2 0.4 0.6 0.8
Paired product coefficients
Number of coefficients(Normalized)
−1 −0.8−0.6−0.4−0.2
0.2 0.4 0.6 0.8
Paired product coefficients
Number of coefficients(Normalized)
Histograms of paired products of MSCN coefﬁcients of a natural undistorted image and various distorted versions of it. (a) Horizontal. (b) Vertical.
(c) Main-diagonal. (d) Secondary-diagonal. Distortions from the LIVE IQA database . jp2k: JPEG2000. jpeg: JPEG compression. WN: additive white
Gaussian noise. blur: Gaussian blur. ff: Rayleigh fast-fading channel simulation.
score (DMOS) which represents the subjective quality of the
Since the BRISQUE approach requires a training procedure
to calibrate the regressor module, we divide the LIVE database
into two randomly chosen subsets – 80% training and 20%
testing – such that no overlap between train and test content
occurs. We do this to ensure that the reported results do
not depend on features extracted from known spatial content,
which can artiﬁcally improve performance. Further, we repeat
this random train-test procedure 1000 times and report the
median of the performance across these 1000 iterations, in
order to eliminate performance bias.
Spearman’s
correlation
coefﬁcient
(SROCC) and Pearson’s (linear) correlation coefﬁcient (LCC)
between the predicted score from the algorithm and DMOS
were used to access QA performance. Before computing LCC,
the algorithm scores were passed through a logistic nonlinearity as described in . A value close to 1 for SROCC
and LCC indicate good performance in terms of correlation
with human opinion. These performance indices are tabulated
in Tables II and III respectively2.
We also tabulated the performance of three full-reference
indices: peak-signal-to-noise ratio (PSNR), structural similarity index (SSIM) and multi-scale structural similarity
index (MS-SSIM) . Although PSNR is a poor measure of perceptual quality, it is often used to benchmark
for QA algorithms , . The SSIM and MS-SSIM
indices are popular owing to their performance and simplicity.
We also include the performance of the previously summarized general purpose no-reference algorithms - CBIQ ,
LBIQ , BLIINDS-II and DIIVINE index . We
requested quality scores from authors for CBIQ and
2Further, note that due to randomness of the 1000 trials, there may be a
slight discrepancy between results reported here and elsewhere, however, these
differences in correlations are not statistically signiﬁcant, and are simply an
artifact of the random train-test sampling.
MITTAL et al.: NR IQA IN THE SPATIAL DOMAIN
8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38
Feature number
SROCC of feature with DMOS
Correlation of features with human judgments of quality (DMOS)
for different distortions.
MEDIAN SPEARMAN RANK ORDERED CORRELATION COEFFICIENT
(SROCC) ACROSS 1000 TRAIN-TEST COMBINATIONS ON
THE LIVE IQA DATABASE. ITALICS INDICATE
NO-REFERENCE ALGORITHMS
BLIINDS-II
LBIQ . Implementations of other indices are available
online – . We also reported the correlations obtained
by modeling empirical distributions of MSCN coefﬁcients
(pointwise) alone and pairwise products alone to compare their
relative importance.
B. Variation With Window Size
As observed from the Table IV, the performance of
BRISQUE remains relatively stable with respect to variation in
the window size used to compute the local mean and variances.
However, the performance starts to decrease when it becomes
fairly large as the computations become non-local.
C. Statistical Signiﬁcance and Hypothesis Testing
Figure 9 plots the mean SROCC across the 1000 trials and
the standard deviations of performance across these 1000 trials
for each of the algorithms considered here.
MEDIAN LINEAR CORRELATION COEFFICIENT ACROSS 1000 TRAIN-TEST
COMBINATIONS ON THE LIVE IQA DATABASE. ITALICS INDICATE
NO-REFERENCE ALGORITHMS
BLIINDS-II
MEDIAN SPEARMAN RANK ORDERED CORRELATION COEFFICIENT
(SROCC) ACROSS 1000 TRAIN-TEST COMBINATIONS ON THE
LIVE IQA DATABASE FOR DIFFERENT WINDOW SIZES.
ITALICS INDICATE NO-REFERENCE ALGORITHMS
SSIM MS−SSIM
LBIQ BLIINDS−II DIIVINE BRISQUE
SROCC Value
Mean SROCC and standard error bars for various algorithms across
the 1000 train-test trials on LIVE IQA database.
Although there exist differences in the median correlations
between the different algorithms (see Table II), these differences may not be statistically relevant. Hence, to evaluate
the statistical signiﬁcance of performance of each of the
algorithms considered, we performed hypothesis testing based
on the t-test on the SROCC values obtained from the
1000 train-test trials, and we tabulated the results in Table V.
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 21, NO. 12, DECEMBER 2012
RESULTS OF ONE-SIDED T-TEST PERFORMED BETWEEN SROCC VALUES
OF VARIOUS IQA ALGORITHMS. A VALUE OF “1” INDICATES THAT THE
ROW ALGORITHM IS STATICALLY SUPERIOR TO THE COLUMN
ALGORITHM; “−1” INDICATES THAT THE ROW IS WORSE
THAN THE COLUMN; A VALUE OF “0” GIVES INDICATES
THAT THE TWO ALGORITHMS ARE STATISTICALLY
INDISTINGUISHABLE. ITALICS INDICATE
NO-REFERENCE ALGORITHMS
BLIINDS-II
MEDIAN CLASSIFICATION ACCURACY ACROSS 1000
TRAIN-TEST TRIALS
Classiﬁcation
The null hypothesis is that
the mean correlation for the
(row) algorithm is equal to mean correlation for the (column)
algorithm with a conﬁdence of 95%. The alternate hypothesis
is that the mean correlation of row is greater than or lesser
than the mean correlation of the column. A value of ‘1’ in the
table indicates that the row algorithm is statically superior to
the column algorithm, whereas a ‘−1’ indicates that the row
is statistically worse than the column. A value of ‘0’ indicates
that the row and column are statistically indistinguishable
(or equivalent), i.e., we could not reject the null hypothesis
at the 95% conﬁdence level.
From Table V we conclude that BRISQUE is highly competitive with all no reference algorithms tested and statistically
better than the full reference algorithms PSNR and SSIM.
Given that these measures require additional information in
the form of the reference image, this is by no means a small
achievement. This result suggests that to the extent distortions
can be trained on, one can replace full reference algorithms
such as SSIM with the proposed BRISQUE without any loss of
performance. We note that BRISQUE remains slightly inferior
to the FR MS-SSIM, indicating that there may still be some
room for improvement in performance.
D. Classiﬁcation Accuracy
In order to demonstrate that BRISQUE features can also
be used for explicit distortion-identiﬁcation , we report
the median classiﬁcation accuracy of the classiﬁer for each
of the distortions in the LIVE database, as well as across all
distortions in Table VI.
distortions
‘confused’ the most, Fig. 10 plots the confusion matrix for
Mean confusion matrix for classiﬁer across 1000 trials illustrates
which row(distortion) is confused with which column (distortion). Higher
number indicates greater confusion.
MEDIAN SPEARMAN RANK ORDERED CORRELATION COEFFICIENT
(SROCC) ACROSS 1000 TRAIN-TEST COMBINATIONS ON THE
LIVE IQA DATABASE. ITALICS INDICATE
NO-REFERENCE ALGORITHMS
each of the distortions, where the sum of each row in the
confusion matrix is 1 and actual values represent the mean
confusion percentage across the 1000 train-test trials. We
see from Fig. 10 that FF and JP2K are most confused with
each other which is not surprising, since FF distortion is a
combination of JP2K followed by packet-loss errors. JP2K
and JPEG are also confused sometimes. WN and Blur are
generally not confused with other distortions.
E. Two-Stage Performance
We also investigated the possibility of replacing the one
stage framework, where features are directly mapped to
quality, with a two-stage framework, similar to that proposed
in . In this approach, the same set of features are used to
identify the distortion afﬂicting the image as are then used
for distortion-speciﬁc QA. Such a two-stage approach was
used with recent success for NSS-based blind IQA . In
Table VII, we tabulate the median SROCC value across 1000
trials for the two-stage realization of BRISQUE. We also list
the performances of BRISQUE for comparison purposes. The
slight dip in the performance can be attributed to imperfect
distortion identiﬁcation in the ﬁrst stage of the two-stage
framework.
MITTAL et al.: NR IQA IN THE SPATIAL DOMAIN
TABLE VIII
SPEARMAN’S RANK ORDERED CORRELATION COEFFICIENT (SROCC) ON
THE TID2008 DATABASE. ITALICIZED ALGORITHMS ARE NR IQA
ALGORITHMS, OTHERS ARE FR IQA ALGORITHMS
INFORMAL COMPLEXITY ANALYSIS OF BRISQUE. TABULATED
VALUES REFLECT THE PERCENTAGE OF TIME DEVOTED TO
EACH OF THE STEPS IN BRISQUE
Percentage of time
Pairwise Products and AGGD
F. Database Independence
Having evaluated BRISQUE on the LIVE IQA database,
we now demonstrate that the performance of BRISQUE is not
bound by the database on which it is tested. To show this, we
trained BRISQUE on the entire LIVE IQA database and then
applied BRISQUE to the TID2008 database .
The TID database consists of 25 reference images and 1700
distorted images over 17 distortion categories . Since there
are only 24 natural images, and our algorithm is based on
the statistics of natural images, we test our approach only on
these 24 images. Further, although there exist 17 distortion
categories, we tested BRISQUE only on these distortions
that it is trained for: JPEG, JPEG2000 compression (JP2K),
additive white noise (WN) and Gaussian Blur (blur) – FF
distortion does not exist in the TID database. The results
of applying BRISQUE on TID are tabulated in Table VIII,
where we also list the performance of PSNR and SSIM
for comparison purposes. It should be clear that BRISQUE
performs well in terms of correlation with human perception
of quality and that the performance does not depend on the
G. Computational Complexity
Our description of BRISQUE focused on the relationship
of the statistical features to natural scene statistics and the
effect that distortions have on such statistics. However, given
the small number of features that are extracted (18 per scale)
and the fact that parameter estimation needs to be performed
only 5 times for an entire image, in comparison to parameter
estimation for each block as in BLIINDS-II , the reader
will appreciate the fact that BRISQUE is extremely efﬁcient.
Having demonstrated that BRISQUE performs well in terms
of correlation with human perception, we also now show that
BRISQUE has low complexity. In Table IX we list the relative
percentage of time each of the stages of BRISQUE uses as a
percentage of the time taken to compute the quality of an
image (once trained).
We also compare the overall computational complexity
of BRISQUE with the FR PSNR and the NR BLIINDS-II
COMPLEXITY ANALYSIS OF BRISQUE: A COMPARISON OF THE AMOUNT
OF TIME TAKEN TO COMPUTE VARIOUS QUALITY MEASURES FOR
A 512 × 768 IMAGE ON A 1.8-GHZ SINGLE-CORE
PC WITH 2 GB OF RAM
Time (seconds)
BLIINDS-II
and DIIVINE, and in Table X, we list the time taken (in
seconds) to compute each quality measure on an image of
resolution 512 × 768 on a 1.8 Ghz single-core PC with 2 GB
of RAM. We use unoptimized MATLAB code for all of
these algorithms in order to ensure a fair comparison. We also
list the efﬁciency as a fraction of the time taken to compute
PSNR, to allow for a machine-independent comparison
across algorithms. As Table X demonstrates, BRISQUE is
quite efﬁcient, outperforming the DIIVINE index and the
BLIINDS-II index by a large amount. This suggests that the
spatial-domain BRISQUE an ideal candidate for real-time
blind assessment of visual quality.
V. APPLICATION TO BLIND IMAGE DENOISING
The computational efﬁciency and excellent quality prediction performance makes BRISQUE an attractive option for
practical applications. One such application could be using a
quality measure to augment the performance of image repair
algorithms. In this section, we describe one such approach,
where the BRISQUE features are used to transform a nonblind image denoising algorithm into a blind image denoising
algorithm.
Blind image denoising algorithms seek to reduce the amount
of noise present in corrupted images, without any additional
information such as the noise variance. Although image
denoising is a well studied problem in image processing
 – , blind image denoising remains relatively underexplored , . The proposed algorithms typically address
parameter estimation in an ad-hoc fashion without regard to
natural scene statistics. Here, we demonstrate a systematic
perception-based parameter estimation approach that results
in better denoising performance. We augment a state-of-the-art
image denoising algorithm by using BRISQUE feature-based
parameter prediction to improve performance.
The work closest in concept to this approach is the one
proposed in where image content measures were used to
predict the noise variance in the image, which was then used
for image denoising; however the approach is computationally
intensive and the measure of content in the image may
not be the ideal measure to predict noise variance. In ,
the noisy image is denoised multiple times and quality is
estimated using their proposed no-reference content evaluation
algorithm. Amongst the large set of denoised images produced,
the image with the best content-quality is selected as the
denoised image. As an alternative, we propose a learning based
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 21, NO. 12, DECEMBER 2012
Accurate noise variance as input to the algorithm in produces
poorer quality denoised images: (a) Noisy image (σ = 0.0158, MS-SSIM =
0.9063), (b) denoised with σ
0.0158 (MS-SSIM = 0.9176), and
(c) denoised with σ = 0.0040 (MS-SSIM = 0.9480).
framework where noise parameters are estimated using natural
scene statistics based on BRISQUE features.
The denoising algorithm that we use is the one proposed
in , which requires as input the noise variance in the image.
However, our experiments suggest that when the algorithm
is fed the true accurate noise-variance, the performance of
the denoiser is sub-par. The performance of the algorithm
drastically improves, if a (systematically) different parameter
selected based on perceptual quality is fed as input to the
algorithm. In order to demonstrate this, in Fig. 11, we plot an
image denoised using the true noise variance and that arrived at
using the noise variance from our approach (described below).
Notice that our approach produces better visual quality, and
better objective quality, as gauged by the multi-scale structural
similarity index (MS-SSIM) .
We design our training framework to account for this
discrepency and to ensure that the denoised image attains
the highest visual quality. Our approach proceeds as follows.
Given a large set of noisy images afﬂicted with different
levels of noise, we denoise each image using the denoising
algorithm – BM3D – by providing as input images
distorted with various values of noise variance. The denoised
images so obtained are judged for their quality using MS-
SSIM and the noise parameter corresponding to the image
with the maximum denoised quality is set as the input to the
algorithm. These noise variances are then used in a training
phase, where BRISQUE features are mapped on to the noiseprediction parameter, using SVM regression as before .
Once trained, the automatic parameter prediction approach is
capable of predicting the level of input noise to BM3D, so
that the output denoised image has the highest visual quality.
We note that our training approach resembles that of .
Given a new (unseen) test noisy image, the BRISQUE augmented BM3D approach predicts the accurate input to BM3D
and denoises the image with (as we shall soon see) much
higher visual quality than the baseline. Notice that BRISQUE
augmentation is not limited to the BM3D algorithm; and any
Amount of Noise variance on scale of 1
Quality of denoised image using MS−SSIM
Default BM3D
Mean quality and associated errors at each noise level across
2000 test images for our approach as well as the reference implementation of
non-blind algorithm could be improved by using BRISQUE
natural scene features to produce a blind image denoiser.
show the effectiveness of our algorithm and to
demonstrate its robustness across a large variety of images
and distortion levels, we created a noisy image dataset from
the 300 images present in the Berkeley image segmentation
database . We introduced 10 different levels of Gaussian
noise to each image yielding a total of 3000 noisy images.
The noise variance ranged from 0.001 to 0.5, uniformly
sampled on a logarithmic scale. 1000 images were then used
for training and 2000 for testing thereby ensuring no content
overlap between the two sets. The regression model described
above was trained on 1000 training images and then used to
predict the input parameter on the test images.
Once denoised images are obtained, we compare their
quality (using MS-SSIM) using our approach as well for
the default implementation of the BM3D algorithm and in
Fig. 12, we plot the mean quality and the associated standard
errors at each noise level across the 2000 test images for both
these approaches. It is clear that BRISQUE augmented BM3D
produces much higher quality images than the baseline BM3D.
We also analyzed whether the differences observed in the
quality of the denoised images between our approach and the
reference BM3D implementation are statistically signiﬁcant
using the t-test . Our analysis indicates that for all noise
variances simulated in the present data, our approach is statistically superior to the reference BM3D implementation in
terms of perceived visual quality at the 95% conﬁdence level,
excepting when the noise variance is a tiny 0.0316 - where
the two approaches become statistically indistinguishable.
VI. CONCLUSION
We proposed a natural scene statistic based distortiongeneric blind/no-reference (NR) quality assessment algorithm–
the Blind/Referenceless Image Spatial QUality Evaluator
(BRISQUE) – which operates in the spatial domain. No
MITTAL et al.: NR IQA IN THE SPATIAL DOMAIN
distortion speciﬁc features such as ringing, blur or blocking
were modeled in the algorithm. The algorithm only quantiﬁes
the ‘naturalness’ (or lack thereof) in the image due to presence
of distortions.
We detailed the algorithm and the statistical features
extracted, and demonstrated how each of these features
correlate with human perception. We then undertook a
thorough evaluation of the BRISQUE index in terms of
correlation with human perception and demonstrated that
BRISQUE is statistically better than FR PSNR and SSIM as
well as highly competitive to all NR algorithms compared
demonstrated
performance is
independent of database content and BRISQUE features may
be used for distortion-identiﬁcation as well. Further, we also
showed that BRISQUE is computationally efﬁcient and that
its efﬁciency is superior to other distortion-generic approaches
to NR IQA, thus making BRISQUE an attractive option for
practical applications like image denoising. We demonstrated
this application by augmenting non-blind image denoising
algorithms using the BRISQUE features to produce blind
image denoising algorithms.