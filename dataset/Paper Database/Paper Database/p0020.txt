Inﬂuential Nodes in a Diﬀusion Model for Social
David Kempe1⋆, Jon Kleinberg2⋆⋆, and ´Eva Tardos2⋆⋆⋆
1 Department of Computer Science, University of Southern California
2 Department of Computer Science, Cornell University
Abstract. We study the problem of maximizing the expected spread
of an innovation or behavior within a social network, in the presence
of “word-of-mouth” referral. Our work builds on the observation that
individuals’ decisions to purchase a product or adopt an innovation are
strongly inﬂuenced by recommendations from their friends and acquaintances. Understanding and leveraging this inﬂuence may thus lead to a
much larger spread of the innovation than the traditional view of marketing to individuals in isolation.
In this paper, we deﬁne a natural and general model of inﬂuence propagation that we term the decreasing cascade model, generalizing models
used in the sociology and economics communities. In this model, as in
related ones, a behavior spreads in a cascading fashion according to a
probabilistic rule, beginning with a set of initially “active” nodes. We
study the target set selection problem: we wish to choose a set of individuals to target for initial activation, such that the cascade beginning
with this active set is as large as possible in expectation. We show that in
the decreasing cascade model, a natural greedy algorithm is a 1−1/e−ε
approximation for selecting a target set of size k.
Introduction
Suppose that we are trying to market a product, or promote an idea, innovation
or behavior, within a population of individuals. In order to do so, we can “target” individuals; for instance, this “targeting” could take the form of oﬀering
free samples of the product, demonstrating an innovation, or explaining an idea
(such as the consequences of drug use to teenagers). An important question is
then whom we should target. Clearly, if there were no interaction between the
individuals, this would be straightforward: the eﬀect on each targeted individual could be determined in isolation, and we could choose the set of individuals
with largest (expected) revenue or reach. However, individuals do not exist in a
⋆This research was supported by an Intel Graduate Fellowship and an NSF Graduate
Research Fellowship. e-mail: 
⋆⋆Supported in part by a David and Lucile Packard Foundation Fellowship and NSF
grants 0311333 and 0329064. e-mail: 
⋆⋆⋆Supported in part by NSF ITR grant CCR-0325453, NSF grant CCR-0311333, and
ONR grant N00014-98-1-0589. e-mail: 
vacuum; rather, they form complex social networks based on a multitude of different relations and interactions. By virtue of these interactions, they inﬂuence
each other’s decisions in adopting a product or behavior.
Research in the area of viral marketing takes advantage of these social
network eﬀects, based on the premise that targeting a few key individuals may
lead to strong “word-of-mouth” eﬀects, wherein friends recommend a product to
their friends, who in turn recommend it to others, and so forth, creating a cascade of recommendations. In this way, decisions can spread through the network
from a small set of initial adopters to a potentially much larger group. Given a
probabilistic model for the way in which individuals inﬂuence one another, the
inﬂuence maximization problem consists in determining a set A of k individuals
yielding the largest expected cascade.
The inﬂuence maximization problem has been proposed and studied by Domingos and Richardson , who gave heuristics for the problem in a very general
descriptive model of inﬂuence propagation. In recent work , we obtained provable performance guarantees for approximation algorithms in several simple,
concrete, but extensively studied models from mathematical sociology (see, e.g.,
 for comprehensive introductions to this area).
In this paper, we show that the inﬂuence maximization problem can be approximated in a very general model that we term the decreasing cascade model.
The analysis techniques from our earlier work rely on the concrete forms of
inﬂuence used in that paper, and we show that they cannot be applied to the
general model considered here. We therefore develop a more general framework,
which we believe will be of interest in its own right, for reasoning about dynamic
processes in network models such as these.
The decreasing cascade model
Throughout this paper, we call individuals (nodes) active if they have adopted
the product, and inactive otherwise. We assume that once a node becomes active, it will remain so forever (see for a discussion on how this assumption can
be lifted). We focus on cascade models that capture the dynamics of recommendations in a step-by-step fashion: when a node u ﬁrst becomes active, say at time
t, it is considered contagious. It has one chance of inﬂuencing each previously
inactive neighbor v. A successful attempt will cause v to become active in the
next time step t + 1. If multiple neighbors of v become active at time t, then
their activation attempts are sequenced in an arbitrary order, but we assume
that they all happen within time step t. After a node u has made all its attempts at inﬂuencing other nodes, it remains active, but is now non-contagious.
The process terminates when there are no more contagious nodes.
In order to fully describe the model, we need to specify the probability of
success for node u’s attempt at activating v. In the simplest independent cascade
model , this probability is a constant pv(u), independent of the history of the
process. In general, however, v’s propensity for being activated may change as
a function of which of its neighbors have already attempted (and failed) to
inﬂuence it; if S denotes the set of v’s neighbors that have already attempted to
inﬂuence v, then u’s success probability is denoted by pv(u, S). For this model to
be well-deﬁned, we also need to assume order-independence: if all nodes from a
set T try to inﬂuence v, then the order in which their attempts are made does
not aﬀect the probability of v being active in the end. Formally, if u1, . . . , ur,
1, . . . , u′
r are two permutations of T, and Ti = {u1, . . . , ui−1} as well as
1, . . . , u′
i−1}, then order-independence means that
(1 −pv(ui, S ∪Ti)) =
for all sets S disjoint from T.
From the point of view of inﬂuence maximization, we start by targeting a set
A of individuals for activation at time 1, making them contagious. Afterwards,
the process unfolds as described above, until there are no more contagious nodes;
we say that the process quiesces. Note that this happens after at most n + 1
rounds. At that point, we have some set ϕ(A) of active nodes, which is is a
random variable. The goal is to choose A so as to maximize the expected size
σ(A) := E [|ϕ(A)|] of this ﬁnal set of active nodes. Due to the computational
diﬃculty of this goal (see the discussion below), we will consider approximation
algorithms: for a constant c, we wish to choose a set A for which σ(A) is at least
c times as large as σ(A∗) for any set A∗of k nodes. The quantity c is thus the
approximation guarantee of the algorithm.
The order-independent cascade model is very general — it speciﬁes how each
node inﬂuences each other node, and how the inﬂuence is “attenuated” by previous interactions a node has had. It is also equivalent in a precise sense to
a generalization of Granovetter’s threshold model for social networks (see
Section 3).
In general, it is NP-hard to approximately maximize the size σ(A) of the ﬁnal
active set to within n1−ε, for any ε > 0. The inapproximability follows from a
straightforward reduction, e.g., from VertexCover, and can already be shown
in the case of a hard threshold model , where a node v is activated if at
least a ﬁxed fraction (say, 1/2) of its neighbors are active; this corresponds to
pv(u, S) being 0 if S contains fewer than half of v’s neighbors, and 1 otherwise.
Thus, we study here a natural restriction that we term the decreasing cascade model. In the decreasing cascade model, the functions pv(u, S) are nonincreasing in S, i.e., pv(u, S) ≥pv(u, T) whenever S ⊆T. Intuitively, this restriction states that a contagious node’s probability of activating some v ∈V
decreases if more nodes have already attempted to activate v, and v is hence
more “marketing-saturated”. The decreasing cascade model contains the independent cascade model as a special case, and even for the independent cascade
model, maximizing σ(A) is NP-hard ; in fact, the proof in shows that it is
NP-hard to approximate within 1 −1/e + ε for any ε > 0.
An Approximation Algorithm
In this paper, we analyze the following simple greedy algorithm (Algorithm 1)
for inﬂuence maximization. The approximation guarantee for this algorithm is
the main theorem of this paper:
Algorithm 1 Greedy Approximation Algorithm
1: Start with A = ∅
2: for i = 1 to k do
Let vi be a node (approximately) maximizing the marginal gain σ(A ∪{v}) −
Set A ←A ∪{vi}.
5: end for
Theorem 1. Let A∗be the the set maximizing σ(·) among all sets of k nodes.
1. If the optimal vi is chosen in each iteration, then the greedy algorithm is
a (1 −1/e)-approximation, i.e., the set A found by the algorithm satisﬁes
σ(A) ≥(1 −1/e) · σ(A∗).
2. If the node vi is a 1 −ε approximate best node in each iteration, then the
greedy algorithm is a (1 −1/e −ε′)-approximation, where ε′ depends on ε
polynomially.
Before proceeding with the proof of Theorem 1, a few words are in order
about determining the node vi in the for loop of the algorithm. Even in the simple independent cascade model, it is not clear how to evaluate σ(A) exactly, or
whether this can be done in polynomial time; in fact, we consider the question
of evaluating σ(A) an interesting direction for further research. However, the
cascade process has the property that it can be eﬃciently simulated, simply by
running the probabilistic rule for inﬂuence propagation until quiescence (which,
as noted above, will occur within at most n + 1 rounds). By repeatedly simulating the cascade process and sampling ϕ(A), we can compute arbitrarily close
approximations to σ(A). A straightforward calculation shows that with a number of simulations polynomial in ε, δ, and n, one can obtain a 1±ε approximation
to σ(A), with probability at least 1 −δ. This approximate evaluation of σ(A) in
turn is enough to ﬁnd an element v whose marginal gain σ(A ∪{v}) −σ(A) is
within a factor of 1 −ε′ of maximal.
The idea for the proof of Theorem 1 is to show that σ(A) is a monotone and
submodular function of A. The property of submodularity formally means that
σ(S ∪{w}) −σ(S) ≥σ(T ∪{w}) −σ(T) whenever S ⊆T. Informally, this is
known as the “diminishing returns condition”: the return derived from investing
in node w diminishes as the size of the total investment (set) increases.
These properties of σ(A) are suﬃcient to prove the desired approximation
guarantee, for we can apply a well-known theorem of Nemhauser, Wolsey and
Fischer. The ﬁrst part of the theorem below is due to Nemhauser, Wolsey and
Fischer ; the generalization can be obtained by straightforward modiﬁcations to the proof.
Theorem 2. Let f be a non-negative, monotone, submodular function on sets.
1. The greedy algorithm, which always picks the element v with largest marginal
gain f(S∪{v})−f(S), is a (1−1/e)-approximation algorithm for maximizing
f on k-element sets S.
2. A greedy algorithm which always picks an element v within 1−ε of the largest
marginal gain results in a 1 −1/e −ε′ approximation, for some ε′ depending
polynomially on ε.
Given Theorem 2, in order to prove Theorem 1 (or its approximate version),
it is suﬃcient to establish the following result:
Theorem 3. For the decreasing cascade model, σ(A) is a monotone and submodular function of A.
Remark. The proof of the (1 −1/e) approximation guarantee in was based
on the same outline. In order to establish submodularity for the independent
cascade and linear threshold models of , it was shown that for both models, it is
possible to deﬁne distributions over directed graphs with the following property:
for any set S of nodes, the probability that ϕ(A) = S under the inﬂuence model
is equal to the probability that the nodes of S are exactly the ones reachable from
A in a graph chosen according to the corresponding distribution. Submodularity
then follows readily from the fact that the number of reachable nodes in a ﬁxed
graph is a submodular function of the set of source nodes.
The decreasing cascade model is more general than the models considered
in . In Section 5, we give an instance which provably has no corresponding
distribution on graphs. Therefore, the proof for submodularity becomes more
intricate, and we have to consider the dynamics of the process in a more detailed
Most of the rest of this paper will be concerned with the proof of Theorem
3. We ﬁrst introduce a generalized version of Granovetter’s threshold model 
in Section 3, as a useful reparametrization of the probability space. Using this
threshold model, we then give the proof of Theorem 3 in Section 4.
The General Threshold Model
Recall that the notion of order-independence, as deﬁned in Section 1.1, postulates
that for a given set S of nodes trying to inﬂuence node v, the order in which
these attempts are made does not aﬀect the probability that v will be active once
all the nodes in S have made their attempts. For the proof of Theorem 3, we
require a stronger version of this statement: namely that even if the activation
of nodes, or some activation attempts, are deferred for many time steps, the
ultimate distribution over active sets remains the same.
It is not clear how to argue this fact directly from the deﬁnition of the
cascade model, and we therefore introduce the general threshold model, a natural
generalization of Granovetter’s linear threshold model . The linear threshold
model has been the foundation for a large body of work in sociology; see, e.g.,
 ; its generalization was introduced in . While the General threshold
model is a natural model in its own right, in this work, we are most interested
in it as a reparametrization of the cascade model. Indeed, Lemma 1 proves that
the two models are equivalent.
In the general threshold model , each node v has a monotone activation
function fv : 2V → , and a threshold θv, chosen independently and uniformly
at random from the interval (0, 1]. A node v becomes active at time t + 1 if
fv(S) ≥θv, where S is the set of nodes active at time t. Again, the process
starts with the activation of a select set A at time 1.
The threshold model focuses more on the “cumulative eﬀect” of a node set S’s
inﬂuence on v, instead of the individual attempts of nodes u ∈S. The perhaps
somewhat surprising fact is that for any activation functions fv(·), we can deﬁne
corresponding success probabilities pv(·, ·) such that the distribution over ﬁnal
active sets ϕ(A) is identical under both models, for all sets A.
Speciﬁcally, given success probabilities pv(u, S), we deﬁne the activation functions
fv(S) = 1 −
(1 −pv(ui, Si)),
where S = {u1, u2, . . . , ur}, and Si = {u1, . . . , ui−1}. That fv is well deﬁned
follows from the order-independence assumption on the pv(u, S). Conversely,
given activation functions fv, we deﬁne success probabilities
pv(u, S) = fv(S ∪{u}) −fv(S)
It is straightforward to verify that the activation functions deﬁned via Equation
(1) satisfy Equation (2), and the success probabilities deﬁned via Equation (2)
satisfy Equation (1).
Lemma 1. Assume that the success probabilities pv(u, S) and activation functions fv(S) satisfy Equation (2). Then, for each node set T and each time t, the
probability that exactly the nodes of set T are active at time t is the same under
the order-independent cascade process with success probabilities pv(u, S) and the
general threshold process with activation functions fv(S).
Proof. We show, by induction, a slightly stronger statement: namely that for
each time t and any pair (T, T ′), the probability that exactly the nodes of T are
active at time t, and exactly those of T ′ are active at time t + 1, is the same
under both views. By summing over all sets T ′, this clearly implies the lemma.
At time t = 0, the inductive claim holds trivially, as the probability is 1 for
the pair (∅, A) and 0 for all other pairs, for both processes. For the inductive
step to time t, we ﬁrst condition on the event that the nodes of T are active at
time t −1, and those of T ′ at time t.
Consider a node v /∈T ′. Under the cascade process, v will become active
at time t + 1 with probability 1 −Qr
i=1(1 −pv(ui, T ∪T ′
i)), where we write
T ′ \ T = {u1, . . . , ur} and T ′
i = {u1, . . . , ui−1}. Under the threshold process,
node v becomes active at time t + 1 iﬀfv(T) < θv ≤fv(T ′). Because node v is
not active at time t, and by the Principle of Deferred Decisions, θv is uniformly
distributed in (fv(T), 1] at time t, so the probability that v becomes active is
fv(T ′)−fv(T )
. Substituting Equation (1) for fv(T) and fv(T ′), a simple calculation
shows that
fv(T ′)−fv(T )
i=1(1 −pv(ui, T ∪T ′
Thus, each individual node becomes active with the same probability under
both processes. As both the thresholds θv and activation attempts are independent for distinct nodes, the probability for any set T ′′ to be the set of active
nodes at time t + 1 is the same under both processes. Finally, as the probability
distribution over active sets T ′′ is the same conditioned on any pair (T, T ′) of
previously active sets, the overall distribution over pairs (T ′, T ′′) is the same in
both the cascade and threshold processes.
Lemma 1, which was stated without proof in , shows that the threshold
model is a non-trivial reparametrization of the cascade model. In a natural way,
it allows us to make all random choices at time 0, before the process starts.
An alternate way of attempting to pre-ﬂip all coins, for instance by providing
a sequence of random numbers from for use in deciding the success of
activation attempts, would not preserve order-independence.
The nice thing about this view is that it makes a strong generalization of the
notion of order-independence an almost trivial feature of the model. To formulate
this generalization, we allow each node v a ﬁnite waiting time τv, meaning that
when v’s criterion for activation has been met at time t (i.e., an inﬂuence attempt
was successful in the cascade model, or fv(S) ≥θv in the threshold model), v
only becomes active at time t+τv. Notice that when τv = 0 for all nodes, this is
the original threshold/cascade model.
Lemma 2. Under the general threshold model, the distribution ϕ(A) over active
sets at the time of quiescence is the same regardless of the waiting times τv. This
even holds conditioned upon any random event E.
Proof. We prove the stronger statement that for every choice of thresholds θv,
and every vector τ of waiting times τv, the set Sτ of nodes active at the time
of quiescence is the same as the set S0 of nodes active at quiescence when all
waiting times are 0. This will clearly imply the claim, by integrating over all
thresholds that form the event E. So from now on, ﬁx the thresholds θv.
Let A0,t denote the set of nodes active at time t when all waiting times are
0, and Aτ,t the set of nodes active at time t with waiting times τ. A simple
inductive proof using the monotonicity of the activation functions fv shows that
Aτ,t ⊆A0,t for all times t, which, by setting t to be the time of quiescence of the
process with waiting times τ, implies that Sτ ⊆S0.
Assume now that Sτ ̸= S0, and let T = S0 \ Sτ ̸= ∅. Among the nodes in
T, let v be one that was activated earliest in the process without waiting times,
i.e., T ∩A0,t = ∅, and v ∈A0,t+1 for some time t. Because v was activated, we
know that θv ≤fv(A0,t), and by deﬁnition of v, no previously active nodes are
in T, i.e., A0,t ⊆Sτ. But then, the monotonicity of fv implies that θv ≤fv(Sτ),
so v should be active in the process with waiting times τ, a contradiction.
Proof of Theorem 3
The monotonicity is an immediate consequence of Lemma 3 below, applied with
V = V ′ and p′
v(u, S) = pv(u, S) for all S, v, u. So we focus on submodularity for
the remainder of the proof. We have to show that, whenever A ⊆A′, we have
σ(A ∪{w}) −σ(A) ≥σ(A′ ∪{w}) −σ(A′), for any node w /∈A′.
The basic idea of the proof is to characterize σ(A ∪{w})−σ(A) in terms of a
residual process which targets only the node w, and has appropriately modiﬁed
success probabilities (similarly for σ(A′ ∪{w})−σ(A′)). To show that these residual processes indeed have the same distributions over ﬁnal active sets ϕ({w}) as
the original processes, we use Lemma 2.
Given a node set B, we deﬁne the residual process on the set V \ B: the
success probabilities are p(B)
(u, S) := pv(u, S ∪B), and the only node targeted
is w, targeted at time 1. Let ϕB(w) denote the set of nodes active at the time
of quiescence of the residual process; notice that this is a random variable. We
claim that, conditioned on the event that [ϕ(A) = B], the variable ϕB(w) has
the same distribution as the variable ϕ(A ∪{w}) \ ϕ(A).
In order to prove this fact, we focus on the threshold interpretation of the
process, and assign node w a waiting time of τw = n + 1. By Lemma 2, this
view does not change the distribution of ϕ(A ∪{w}) \ ϕ(A). Then, w is the
only contagious node at time n + 1, and by the conditioning, the other active
(but non-contagious) nodes are those from B. This implies that only nodes from
V \ B will make activation attempts after time n + 1. By using the same order
of activation attempts, and the same coin ﬂips for each pair u, v ∈V \ B, a
simple inductive proof on the time t shows that the set S of nodes is active in
the residual process at time t if and only if the set S ∪B is active in the original
process at time n + t. In particular, this shows that the two random variables
have the same distributions.
Having shown this equivalence, we want to compare the expected sizes of
ϕB(w) and ϕB′(w), when B ⊆B′. We write σB(w) = E [|ϕB(w)|], as well as
σB′(w) = E [|ϕB′(w)|]. First oﬀ, notice that the node set V \ B of the former
process is a superset of V \ B′. Furthermore, for all nodes u, v and node sets S,
the decreasing cascade condition implies that
(u, S) = pv(u, S ∪B) ≥pv(u, S ∪B′) = p(B′)
Lemma 3 below proves the intuitively obvious fact that the combination of a
larger ground set of nodes and larger success probabilities results in a larger set
of activated nodes, i.e.,
σw(B) ≥σw(B′)
Finally, we can rewrite the expected number of active nodes as
σ(A ∪{w}) −σ(A) =
σw(B) · Prob[ϕ(A) = B]
σw(B) · Prob[ϕ(A) = B, ϕ(A′) = B′]
σw(B′) · Prob[ϕ(A) = B, ϕ(A′) = B′]
σw(B′) · Prob[ϕ(A′) = B′]
= σ(A′ ∪{w}) −σ(A′).
The inequality followed by applying Inequality (3) under the sum. In both of the
steps surrounding the inequality, we used that Prob[ϕ(A) = B, ϕ(A′) = B′] = 0
whenever B ̸⊆B′, by the monotonicity of the cascade process. This completes
the proof of submodularity.
Lemma 3. Let V ′ ⊆V , and assume that p′
v(u, S) ≤pv(u, S) for all nodes
u, v ∈V and all sets S. If A′ ⊆A are the targeted sets for cascade processes on
V ′ and V , then the expected size of the active set at the end of the process on V
is no smaller than the corresponding expected size for the process on V ′.
Proof. This claim is most easily seen in the threshold view of the process. Equation (1) shows that the activation functions f ′
v, fv corresponding to the success
probabilities p′
v(u, S) and pv(u, S) satisfy f ′
v(S) ≤fv(S), for all nodes v and sets
S. Then, for any ﬁxed thresholds θv, a simple inductive proof on time steps t
shows that the set of active nodes in the former process (with functions f ′
always a subset of the set of active notes in the latter one (with functions fv).
Since the inequality thus holds for every point of the probability space, it holds
in expectation.
Distributions over Graphs
As mentioned brieﬂy before, the outline of the proof of the (1 −1/e) approximation guarantee in was the same as here. However, a simpler technique was
used to show the submodularity of σ(A).
This technique can be most easily understood in the case of the independent
cascade model, where each activation attempt of a node u on a node v succeeds
independently with probability pv(u). By the deﬁnition of the process, a node
v is active in the end if it is reachable from one of the initially targeted nodes
by a chain of successful activation attempts. If we consider a graph G that
contains a directed arc (u, v) iﬀu’s activation attempt on v succeeded, then
it follows that a node v is active iﬀit is reachable in G from the targeted set
A. Due to the independence of activation attempts, and by the Principle of
Deferred Decisions, the graph G can be generated by including each arc (u, v)
independently with probability pv(u). As the set of nodes reachable from a given
set A is a submodular function of A, and the expected size of the activated set is
a non-negative linear combination (over all possible graphs G) of these functions,
the function σ(A) is shown to be submodular.
This technique can be applied whenever the inﬂuence model allows for a
corresponding distribution on directed graphs G — the fact that we included
each arc independently did not matter. In fact, uses this technique to show
submodularity in two other, less obvious, cases. In this section, we give an instance of the decreasing cascade model for which there is no distribution over
graphs resulting in the same activation probabilities. This example shows that
the techniques used to show submodularity of σ(A) in cannot be applied for
the more general decreasing cascade model.
Our example has ﬁve nodes. Node v could potentially be inﬂuenced by four
nodes u1, . . . , u4. The ﬁrst two nodes to try activating v have a probability of 1
each to succeed, whereas all subsequent attempts fail. The inﬂuences are thus
pv(ui, S) = 1
2 whenever |S| < 2, and pv(ui, S) = 0 otherwise. Notice that this is
indeed an instance of the decreasing cascade model, and order independent.
Assume, for contradiction, that there is a distribution on graphs such that
node v is reachable from a set S with the same probability that S will activate v
in the cascade model. For any set S ⊆{1, 2, 3, 4}, let qS denote the probability
that in this distribution over graphs, exactly the edges from ui to v for i ∈S
are present. Because with probability 1
4, v does not become active even if all
ui are, we know that q∅= 1
4. If u1, u2, u3 are active, then v is also active with
probability 3
4, so the edge (u4, v) can never be present all by itself (if it were,
then the set {u1, u2, u3, u4} together would have higher probability of reaching
v than the set {u1, u2, u3}). Thus, we have that q{i} = 0 for all i. The same
argument shows that q{i,j} = 0 for all i, j.
Thus, the only non-empty edge sets with non-zero probabilities can be those
of size three or four. If node u1 is the only active node, then v will become active
with probability
2, so the edge (u1, v) is present with probability
q{1,2,3} + q{1,2,4} + q{1,3,4} + q{1,2,3,4} = 1
2, while q{1,2,3} + q{1,2,4} + q{1,3,4} +
q{2,3,4} + q{1,2,3,4} = 1 −q∅= 3
4. Therefore, q{2,3,4} = 1
4, and a similar argument
for nodes u2, u3, u4 gives that qS = 1
4 for each set S of cardinality 3. But then,
the total probability mass on edge sets is at least 5
4, as there are four such sets
S, and the empty set also has probability 1
4. This is a contradiction, so there is
no such distribution over graphs.
Conclusions
In this paper, we have presented and analyzed a simple greedy algorithm for
maximizing the spread of inﬂuence in a general model of social inﬂuence termed
the decreasing cascade model. The proof centered on showing that the expected
number of inﬂuenced nodes is a monotone and submodular function of the targeted set, which required new techniques beyond those used in previous work,
including a non-trivial reparametrization of the probability space.
An interesting direction for future work is to investigate which are the most
general inﬂuence models for which provable approximation guarantees can be
achieved. A conjecture in , which is as of yet unresolved, states that whenever
the activation functions fv of the general threshold process of Section 3 are
monotone and submodular at each node v, so is σ(A).
Another direction for future work concerns the evaluation of the function
σ(A). At this point, we do not know if the function can be evaluated exactly in
polynomial time, even for the simplest inﬂuence models.