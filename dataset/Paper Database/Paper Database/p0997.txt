Systematic Topology Analysis and Generation
Using Degree Correlations
Priya Mahadevan
UC San Diego
Dmitri Krioukov
Kevin Fall
Intel Research
Amin Vahdat
UC San Diego
{pmahadevan,vahdat}@cs.ucsd.edu, , 
Researchers have proposed a variety of metrics to measure
important graph properties, for instance, in social, biological, and computer networks. Values for a particular graph
metric may capture a graph’s resilience to failure or its routing eﬃciency. Knowledge of appropriate metric values may
inﬂuence the engineering of future topologies, repair strategies in the face of failure, and understanding of fundamental properties of existing networks. Unfortunately, there are
typically no algorithms to generate graphs matching one or
more proposed metrics and there is little understanding of
the relationships among individual metrics or their applicability to diﬀerent settings.
We present a new, systematic approach for analyzing network topologies. We ﬁrst introduce the dK-series of probability distributions specifying all degree correlations within
d-sized subgraphs of a given graph G.
Increasing values
of d capture progressively more properties of G at the cost
of more complex representation of the probability distribution. Using this series, we can quantitatively measure the
distance between two graphs and construct random graphs
that accurately reproduce virtually all metrics proposed in
the literature. The nature of the dK-series implies that it
will also capture any future metrics that may be proposed.
Using our approach, we construct graphs for d = 0, 1, 2, 3
and demonstrate that these graphs reproduce, with increasing accuracy, important properties of measured and modeled
Internet topologies. We ﬁnd that the d = 2 case is suﬃcient
for most practical purposes, while d = 3 essentially reconstructs the Internet AS- and router-level topologies exactly.
We hope that a systematic method to analyze and synthesize topologies oﬀers a signiﬁcant improvement to the set of
tools available to network topology and protocol researchers.
Categories and Subject Descriptors
C.2.1 [Network Architecture and Design]:
topology; G.3 [Probability and Statistics]: Distribution
functions, multivariate statistics, correlation and regression
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’06, September 11–15, 2006, Pisa, Italy.
Copyright 2006 ACM 1-59593-308-5/06/0009 ...$5.00.
Measurements,
observations
Observed graphs
Selection and
abstraction
Graph metrics
to reproduce
‘growing’ graphs
‘static’ graphs
Simulations
Comparison with the observed
graphs against a set of
important graph properties
Extraction
Construction
Formalization
If graphs differ, refinements are needed:
modify the set of
reproduced graph metrics (on the left)
or abstracted evolution rules (on the right)
Methodologies of network topology research.
analysis; G.2.2 [Graph Theory]: Network problems
General Terms
Measurement, Design, Theory
Network topology, degree correlations
INTRODUCTION
Knowledge of network topology is crucial for understanding and predicting the performance, robustness, and scalability of network protocols and applications. Routing and
searching in networks, robustness to random network failures and targeted attacks, the speed of worms spreading,
and common strategies for traﬃc engineering and network
management all depend on the topological characteristics of
a given network.
Research involving network topology, particularly Internet topology, generally investigates the following questions:
1. generation: can we eﬃciently generate ensembles of
random but “realistic” topologies by reproducing a set
of simple graph metrics?
2. simulations: how does some (new) protocol or application perform on a set of these “realistic” topologies?
3. evolution: what are the forces driving the evolution
(growth) of a given network?
Figure 1 illustrates the methodologies used to answer these
questions in its left, bottom, and right parts, respectively.
Common to all of the methodologies is a set of practicallyimportant graph properties used for analyzing and comparing sets of graphs at the center box of the ﬁgure. Many such
properties have been deﬁned and explored in the literature.
We brieﬂy discuss some of them in Section 2. Unfortunately,
there are no known algorithms to construct random graphs
with given values of most of these properties, since they
typically characterize the global structure of the topology,
making it diﬃcult or impossible to algorithmically reproduce
This paper introduces a ﬁnite set of reproducible graph
properties, the dK-series, to describe and constrain random graphs in successively ﬁner detail. In the limit, these
properties describe any given graph completely. In our approach, we make use of probability distributions, the dKdistributions, specifying node degree correlations within subgraphs of size d in some given input graph. We call dKgraphs the sets of graphs constrained by given values of dKdistributions. Producing a family of 0K-graphs for a given
input graph requires reproducing only the average node degree of the original graph, while producing a family of 1Kgraphs requires reproducing the original graph’s node degree
distribution, the 1K-distribution. 2K-graphs reproduce the
joint degree distribution, the 2K-distribution, of the original graph—the probability that a randomly selected link
connects nodes of degrees k and k′.
3K-graphs consider
interconnectivity among triples of nodes, and so forth. Generally, the set of (d + 1)K-graphs is a subset of dK-graphs.
In other words, larger values of d further constrain the number of possible graphs. Overall, larger values of d capture
increasingly complex properties of the original graph. However, generating dK-graphs for large values of d also become
increasingly computationally complex.
A key contribution of this paper is to deﬁne the series
of dK-graphs and dK-distributions and to employ them for
generating and analyzing network topologies. Speciﬁcally,
we develop and implement new algorithms for constructing
2K- and 3K-graphs—algorithms to generate 0K- and 1Kgraphs are already known. For a variety of measured and
modeled Internet AS- and router-level topologies, we ﬁnd
that reproducing their 3K-distributions is suﬃcient to accurately reproduce all graph properties we have encountered
Our initial experiments suggest that the dK-series has
the potential to deliver two primary beneﬁts. First, it can
serve as a basis for classiﬁcation and uniﬁcation of a variety of graph metrics proposed in the literature. Second, it
establishes a path towards construction of random graphs
matching any complex graph properties, beyond the simple per-node properties considered by existing approaches
to network topology generation.
IMPORTANT TOPOLOGY METRICS
In this section we outline a list of graph metrics that have
been found important in the networking literature.
list is not complete, but we believe it is suﬃciently diverse
and comprehensive to be used as a good indicator of graph
similarity in subsequent sections. In addition, our primary
concern is how accurately we can reproduce important metrics. One can ﬁnd statistical analysis of these metrics for
Internet topologies in and, more recently, in .
The spectrum of a graph is the set of eigenvalues of its
Laplacian L. The matrix elements of L are Lij = −1/(kikj)1/2
if there is a link between a ki-degree node i and a kj-degree
node j; otherwise they are 0, or 1 if i = j. All the eigenvalues
lie between 0 and 2. Of particular importance are the smallest non-zero and largest eigenvalues, λ1 and λn−1, where n
is the graph size. These eigenvalues provide tight bounds
for a number of critical network characteristics including
network resilience and network performance , i.e.,
the maximum traﬃc throughput of the network.
The distance distribution d(x) is the number of pairs of
nodes at a distance x, divided by the total number of pairs n2
(self-pairs included).
This metric is a normalized version
of expansion .
It is also important for evaluating the
performance of routing algorithms as well as of the speed
with which worms spread in a network.
Betweenness is the most commonly used measure of centrality, i.e., topological importance, both for nodes and links.
It is a weighted sum of the number of shortest paths passing through a given node or link. As such, it estimates the
potential traﬃc load on a node or link, assuming uniformly
distributed traﬃc following shortest paths. Metrics such as
link value or router utilization are directly related
to betweenness.
Perhaps the most widely known graph property is the node
degree distribution P(k), which speciﬁes the probability of
nodes having degree k in a graph. The unexpected ﬁnding
in that degree distributions in Internet topologies closely
follow power laws stimulated further interest in topology
The likelihood S is the sum of products of degrees
of adjacent nodes. It is linearly related to the assortativity
coeﬃcient r suggested as a summary statistic of node
interconnectivity: assortative (disassortative) networks are
those where nodes with similar (dissimilar) degrees tend to
be tightly interconnected. They are more (less) robust to
both random and targeted removals of nodes and links. Li
et al. use S in as a measure of graph randomness to show
that router-level topologies are not “very random”: instead,
they are the result of sophisticated engineering design.
Clustering C(k) is a measure of how close neighbors of
the average k-degree node are to forming a clique: C(k) is
the ratio of the average number of links between the neighbors of k-degree nodes to the maximum number of such
. If two neighbors of a node are connected, then
these three nodes form a triangle (3-cycle). Therefore, by
deﬁnition, C(k) is the average number of 3-cycles involving k-degree nodes. Bu and Towsley employ clustering
to estimate accuracy of topology generators. More recently,
Fraigniaud ﬁnds that a wide class of searching/routing
strategies are more eﬃcient on strongly clustered networks.
dK-SERIES AND dK-GRAPHS
There are several problems with the graph metrics in the
previous section.
First, they derive from a wide range of
studies, and no one has established a systematic way to determine which metrics should be used in a given scenario.
Second, there are no known algorithms capable of constructing graphs with desired values for most of the described
metrics, save degree distribution and more recently, clustering .
Metrics such as spectrum, distance distribution,
and betweenness characterize global graph structure, while
known approaches to generating graphs deal only with local,
Figure 2: The dK- and dK-random graph hierarchy.
The circles represent dK-graphs, whereas their centers represent dK-random graphs. The cross is the nK-graph isomorphic to a given graph G.
per-node statistics, such as the degree distribution. Third,
this list of metrics is incomplete. In particular, it cannot include any future metrics that may be of interest. Identifying
such a metric might result in ﬁnding that known synthetic
graphs do not match this new metric’s value: moving along
the loops in Figure 1 can thus continue forever.
To address these problems, we focus on establishing a ﬁnite set of mutually related properties that can form a basis
for any topological graph study.
More precisely, for any
graph G, we wish to identify a series of graph properties
Pd, d = 0, 1, . . . , satisfying the following requirements:
1. constructibility: we can construct graphs having these
properties;
2. inclusion: any property Pd subsumes all properties Pi
with i = 0, . . . , d −1: that is, a graph having property Pd is guaranteed to also have all properties Pi
for i < d;
3. convergence: as d increases, the set of graphs having
property Pd “converges” to G: that is, there exists
a value of index d = D such that all graphs having
property PD are isomorphic to G.
In the rest of this section, we establish our construction of
the properties Pd, which we will call the dK-series. We begin with the observation that the most basic properties of a
network topology characterize its connectivity. The coarsest
connectivity property is the average node degree ¯k = 2m/n,
where n = |V | and m = |E| are the numbers of nodes and
links in a given graph G(V, E). Therefore, the ﬁrst property P0 in our dK-series Pd is that the graph’s average degree ¯k has the same value as in the given graph G. In Figure 2 we schematically depict the set of all graphs having
property P0 as 0K-graphs, deﬁning the largest circle. Generalizing, we adopt the term dK-graphs to represent the set
of all graphs having property Pd.
The P0 property tells us the average number of links per
node, but it does not tell us the distribution of degrees
across nodes. In particular, we do not know the number of
nodes n(k) of each degree k in the graph. We deﬁne property
P1 to capture this information: P1 is therefore the property
that the graph’s node degree distribution P(k) = n(k)/n1
has the same form as in the given graph G.
It is convenient to call P(k) the 1K-distribution. P1 implies at least
as much information about the network as P0, but not vice
versa: given P(k), we ﬁnd ¯k = P kP(k). P1 provides more
information than P0, and it is therefore a more restrictive
metric: the set of 1K-graphs is a subset of the set of 0Kgraphs.
Figure 2 illustrates this inclusive relationship by
drawing the set of 1K-graphs inside the set of 0K-graphs.
Continuing to d = 2, we note that the degree distribution constrains the number of nodes of each degree in
the network, but it does not describe the interconnectivity of nodes with given degrees. That is, it does not provide any information on the total number m(k, k′) of links
between nodes of degree k and k′.
We deﬁne the third
property P2 in our series as the property that the graph’s
joint degree distribution (JDD) has the same form as in
the given graph G.
The JDD, or the 2K-distribution, is
P(k1, k2) = m(k1, k2)µ(k1, k2)/(2m), where µ(k1, k2) is 2 if
k1 = k2 and 1 otherwise. The JDD describes degree correlations for pairs of connected nodes.
Given P(k1, k2), we
can calculate P(k) = (¯k/k) P
k′ P(k, k′), but not vice versa.
Consequently, the set of 2K-graphs is a subset of the 1Kgraphs. Therefore, Figure 2 depicts the smaller 2K-graph
circle inside 1K.
We can continue to increase the amount of connectivity information by considering degree correlations among greater
numbers of connected nodes. To move beyond 2K, we must
begin to distinguish the various geometries that are possible in interconnecting d nodes. To introduce P3, we require
the following two components: 1) wedges: chains of 3 nodes
connected by 2 edges, called the P∧(k1, k2, k3) component;
and 2) triangles: cliques of 3 nodes, called the P△(k1, k2, k3)
component:
As the two geometries occur with diﬀerent frequencies among
nodes having diﬀerent degrees, we require a separate probability distribution for each conﬁguration. We call these two
components taken together the 3K-distribution.
For P4, we need the above six distributions: where instead
of indices ∧, △we use for d = 3, we have all non-isomorphic
graphs of size 4 numbered by 1, . . . , 6. We note that the
1Sacriﬁcing a certain amount of rigor, we interchangeably
use the enumeration of nodes having some property in a
given graph, e.g., n(k)/n, with the probability that a node
has this property in a graph ensemble, e.g., P(k). The two
become identical when n →∞; see for further details.
order of k-arguments generally matters, although we can
permute any pair of arguments corresponding to pairs of
nodes whose swapping leaves the graph isomorphic.
example: P∧(k1, k2, k3) ̸= P∧(k2, k1, k3) ̸= P∧(k1, k3, k2),
but P∧(k1, k2, k3) = P∧(k3, k2, k1).
In the following ﬁgure, we illustrate properties Pd, d =
0, . . . , 4, calculated for a given graph G of size 4, where
for simplicity, values of all distributions P are the total
numbers of corresponding subgraphs, i.e., P(2, 3) = 2 means
that G contains 2 edges between 2- and 3-degree nodes.
Generalizing, we deﬁne the dK-distributions to be degree
correlations within non-isomorphic simple connected subgraphs of size d and the dK-series Pd to be the series of properties constraining the graph’s dK-distribution to the same
form as in a given graph G. In other words, Pd tells us how
groups of d-nodes with degrees k1, ..., kd interconnect.
the ‘dK’ acronym, ‘K’ represents the standard notation for
node degrees, while ‘d’ refers to the number of degree arguments k of the dK-distributions P(k1, . . . , kd) and to the
upper bound of the distance between nodes with speciﬁed
degree correlations. Moving from Pd to Pd+1 in describing
a given graph G is somewhat similar to including the additional d + 1’th term of the Fourier (time) or Taylor series
representing a given function F. In both cases, we describe
wider “neighborhoods” in G or F to achieve a more accurate
representation of the original structure.
The dK-series deﬁnition satisﬁes the inclusion and convergence requirements described above. Indeed, the inclusion requirement is satisﬁed because any graph of size d is a
subgraph of some graph of size d + 1. Convergence follows
from the observation that in the limit of d = n, the set of
nK-graphs contains only one element: G itself. As a consequence of the convergence property, any topology metric we
can deﬁne on G will eventually be captured by dK-graphs
with a suﬃciently large d.
Hereafter, our main concerns with the dK-series become:
1) how well we can satisfy our ﬁrst requirement of constructibility and 2) how fast the dK-series converges toward
the original graph. We address these two concerns in Sections 4 and 5.
The reason for the second concern is that the number of
probability distributions required to fully specify the dKdistribution grows quickly with d: see for the number of
non-isomorphic simple connected graphs of size d. Relative
to the existing work on topology generators typically limited
to d = 1 , we introduce and implement algorithms
for graph construction for
d = 2 and d = 3. We present
these algorithms in Section 4 and then show in Section 5 that
the dK-series converges quickly: 2K-graphs are suﬃcient for
most practical purposes for the graphs we consider, while
3K-graphs are essentially identical to observed and modeled
Internet topologies.
To motivate our ability to capture increasingly complex
graph properties by increasing d, we present visualizations
of dK-graphs generated using the dK-randomizing approach
we will discuss in Section 4.1.4. Figure 3 depicts random
0K-, 1K-, 2K- and 3K-graphs matching the corresponding
distributions of the HOT graph, a representative router-level
topology from . This topology is particularly interesting,
because, to date reproducing router-level topologies using
only degree distributions has proven diﬃcult . However,
a visual inspection of our generated topologies shows good
convergence properties of the dK-series: while the 0K-graph
and 1K-graph have little resemblance with the HOT topology, the 2K-graph is much closer than the previous ones and
the 3K graph is almost identical to the original. Although
the visual inspection is encouraging, we defer more careful
comparisons to Section 5.
CONSTRUCTING dK-GRAPHS
There are several approaches for constructing dK-graphs
for d = 0 and d = 1. We extended a number of these algorithms to work for higher values of d. In Section 4.1, we
describe these approaches, their practical utility, and our
new algorithms for d > 1. In Sections 4.2 and 4.3, we introduce dK-random graphs and dK-space explorations. We
use the latter to determine the lowest values of d such that
dK-graphs approximate a given topology with the required
degree of accuracy.
dK-graph-constructing algorithms
We classify existing approaches to constructing 0K- and
1K-graphs into the following categories: stochastic, pseudograph, matching, and two types of rewiring: randomizing
and targeting. We attempted to extend each of these techniques to general dK-graph construction. In this section, we
qualitatively discuss the relative merits of each of these approaches before presenting a more quantitative comparison
in Section 5.
Stochastic
The simplest and most convenient for theoretical analysis
is the stochastic approach. For 0K, reproducing an n-sized
graph with a given expected average degree ¯k involves connecting every pair of n nodes with probability p0K = ¯k/n.
This construction forms the classical (Erd˝os-R´enyi) random
graphs Gn,p . Recent eﬀorts have extended this stochastic approach to 1K and 2K . In these cases, one ﬁrst
labels all nodes i with their expected degrees qi drawn from
the distribution P(k) and then connects pairs of nodes (i, j)
with probabilities p1K(qi, qj) = qiqj/(n¯q) or p2K(qi, qj) =
(¯q/n)P(qi, qj)/(P(qi)P(qj)) reproducing the expected values of 1K- or 2K-distributions, respectively.
In theory, we could generalize this approach for any d
in two stages:
1) extraction:
given a graph G, calculate
the frequencies of all (including disconnected) d-sized subgraphs in G, and 2) construction: prepare an n-sized set of
qi-labeled nodes and connect their d-sized subsets into different subgraphs with (conditional) probabilities based on
the calculated frequencies. In practice, we ﬁnd the stochastic approach performs poorly even for 1K because of high
statistical variance. For example, many nodes with expected
degree 1 wind up with degree 0 after the construction phase,
resulting in many tiny connected components.
Pseudograph
The pseudograph (also known as conﬁguration) approach
is probably the most popular and widely used class of graphgenerating algorithms. In its original form , it applies
only to the 1K case. Relative to the stochastic approach,
(a) 0K-graph
(b) 1K-graph
(c) 2K-graph
(d) 3K-graph
(e) original HOT graph
Figure 3: Picturizations of dK-graphs and the original HOT graph illustrating the convergence of dK-series.
it reproduces a given degree distribution exactly, but does
not necessarily construct simple graphs.
That is, it may
construct graphs with both ends of an edge connected to
the same node (self-loops) and with multiple edges between
the same pair of nodes (loops).
It operates as follows. Given the number of nodes, n(k),
of degree k, n = Pkmax
k=1 n(k), ﬁrst prepare n(k) nodes with
k stubs attached to each node, k = 1, . . . , kmax, and then
randomly choose pairs of stubs and connect them to form
edges. To obtain a simple connected graph, remove all loops
and extract the largest connected component.
We extended this algorithm to 2K as follows. Given the
number m(k1, k2) of edges between k1- and k2-degree nodes,
k1,k2=1 m(k1, k2), we ﬁrst prepare lists of m(k1, k2)
disconnected edges and label the both ends of each edge
by k1 and k2, k1, k2 = 1, . . . , kmax. Next, for each k, k =
1, . . . , kmax, we create a list of all edge-ends labeled with k.
From this list, we randomly select groups of k edge-ends to
form the k-degree nodes in the ﬁnal graph.
The pseudograph algorithm works well for d = 2. Unfortunately, we could not easily generalize it for d > 2 because
starting at d = 3, d-sized subgraphs overlap over edges. Such
overlapping introduces a series of topological constraints and
non-local dependencies among diﬀerent subgraphs, and we
could not ﬁnd a simple technique to preserve these combinatorial constraints during the construction phase.
The matching approach diﬀers from the pseudograph approach in avoiding loops during the construction phase. In
the 1K case, the algorithm works exactly as its pseudograph
counterpart but skips pairs of stubs that form loops if connected. We extend the matching approach to 2K in a manner similar to our 2K pseudograph approach.
Unfortunately, loop avoidance suﬀers from various forms
of deadlock for both 1K and 2K. In both cases, the algorithms can end up in incomplete conﬁgurations when not all
edges are formed, and the graph cannot be completed because there are no suitable stub pairs remaining that can be
connected without forming loops. We devised several techniques to deal with these problems. With these additional
techniques, we obtained good results for 2K graphs.
in the pseudograph case however, we could not generalize
matching for d > 2 for essentially the same reasons related
to subgraphs’ overlapping and non-locality.
The rewiring approaches are generalizable to any d and
work well in practice. They involve dK-preserving rewiring
as illustrated in Figure 4. The main idea is to rewire random (pairs of) edges preserving an existing form of the dKdistribution. For d = 0, we rewire a random edge to a random pair of nodes, thus preserving ¯k. For d = 1, we rewire
two random edges that do not alter P(k), as shown in Figure 4. If, in addition, there are at least two nodes of equal
degrees adjacent to the diﬀerent edges in the edge pair, then
the same rewiring leaves P(k, k′) intact. Due to the inclusion
property of the dK-series, (d + 1)K-rewirings form a subset
of dK-rewirings for d > 0. For example, to preserve 3K, we
Figure 4: dK-preserving rewiring for d = 0, 1, 2.
permit a 2K-rewiring only if it also preserves the wedge and
triangle distributions.
The dK-randomizing rewiring algorithm amounts to performing dK-preserving rewirings a suﬃcient number of times
for some dK-graph. A “suﬃcient number” means enough
rewirings for this process to lead to graphs that do not
change their properties even if we subject them to additional
rewirings. In other words, this rewiring process converges after some number of steps, producing random graphs having
property Pd. Even for d = 1, there are no known rigorous results regarding how quickly this process converges, but 
shows that this process is an irreducible, symmetric and aperiodic Markov chain and demonstrates experimentally that
it takes O(m) steps to converge.
In our experiments in Section 5, we employ the following
strategy applicable for any d. We ﬁrst calculate the number of possible initial dK-preserving rewirings. By “initial
rewirings” we mean rewirings we can perform on a given
graph G, to diﬀerentiate them from rewirings we can apply
to graphs obtained from G after its ﬁrst (and subsequent)
rewirings. We then subtract the number of rewirings that
leave the graph isomorphic. For example, rewiring of any
two (1, k)- and (1, k′)-edges is a dK-preserving rewiring, for
any d, and more strongly, the graph before rewiring is isomorphic to the graph after rewiring. We multiply this diﬀerence by 10, and perform that number of random rewirings.
At the end of our rewiring procedure, we explicitly verify
that randomization is indeed complete and the process has
converged by further increasing the number of rewirings and
checking that all graph characteristics remain unchanged.
One obvious problem with dK-randomization is that it
requires an original graph G as input to construct its dKrandom versions. It cannot start with a description of the
dK-distribution to generate random dK-graphs as is possible with the other construction approaches discussed above.
To address this limitation, we consider the inverse process of dK-targeting d′K-preserving rewiring, also known as
Metropolis dynamics . It incorporates the following modiﬁcation to d′K-preserving rewiring: every rewiring step is
accepted only if it moves the graph “closer” to Pd. In practice, we can then employ targeting rewiring to construct
dK-graphs with high values of d by beginning with any d′Kgraph where d′ < d. Recall that we can always compute Pd′
from Pd due to the inclusion property of the dK-series. For
instance, we can start with a graph having a given degree
distribution (d′ = 1) , and then move it toward a dKgraph via dK-targeting 1K-preserving rewiring.
The deﬁnition of “closer” above requires further explanation.
We require a set of distance metrics that quantitatively diﬀerentiate two graphs based on the values of
their dK-distributions. In our experiments, we use the sum
of squares of diﬀerences between the existing and target
numbers of subgraphs of a given type.
For example, in
the d = 2 case, we measure the distance between the target graph’s JDD and the JDD of the current graph being
rewired by D2 = P
k1,k2 [mcurrent(k1, k2) −mtarget(k1, k2)]2,
and at each rewiring step, we accept the rewiring only if it
decreases this distance. Note that D2 is non-negative and
equals zero only when reaching the target JDD. For d = 3,
this distance D3 is a sum of squares of diﬀerences between
the current and target numbers of wedges and triangles, and
we can generalize it to Dd for any d.
A potential problem with dK-targeting d′K-preserving
rewiring is that it can be nonergodic, meaning that there
might be no chain of d′K-preserving Dd-decreasing rewirings
leading from the initial d′K-graph to the target dK-graph.
In other words, we cannot be sure beforehand that any two
d′K-graphs are connected by a sequence of d′K-preserving
and Dd-decreasing rewirings.
To address this problem we note that the d′K-randomizing
and dK-targeting d′K-preserving rewirings are actually two
extremes of an entire family of rewiring processes. Indeed,
let ∆Dd = Dd,after −Dd,before be the diﬀerence of distance
to the target dK-distribution computed before and after
a d′K-preserving rewiring step.
As with the usual dKtargeting rewiring, we accept a rewiring step if ∆Dd < 0,
but even if ∆Dd ⩾0, we also accept this step with probability e−∆Dd/T , where T > 0 is some parameter that we
call temperature because of the similarity of the process to
simulated annealing.
In the T →0 limit, this probability goes to 0, and we have
the standard dK-targeting d′K-preserving rewiring process.
When T →∞, the probability approaches 1, yielding the
standard d′K-randomizing rewiring process. To verify ergodicity, we can start with a high temperature and then
gradually cool the system while monitoring any metric known
to have diﬀerent values in dK- and d′K-graphs. If this metric’s value forms a continuous function of the temperature,
then our rewiring process is ergodic.
Maslov et al. performed these experiments in and demonstrated ergodicity in the case with d′ = 1 and d = 2. In our experiments
in Section 5 where d and d′ are below 4, we always obtain a
good match for all target graph metrics. Thus, we perform
rewiring at zero temperature without further considering ergodicity. If however in some future experiments one detects
the lack of a smooth convergence of rewiring procedures,
then one should ﬁrst verify ergodicity using the methodology described above.
For all the algorithms discussed in this section, we do
not check for graph connectedness at each step of the algorithm since: 1) it is an expensive operation and 2) all resulting graphs always have giant connected components (GCCs)
with characteristics similar to the whole disconnected graphs.
dK-random graphs
No dK-graph-generating algorithm can quickly construct
the set of all dK-graphs because: 1) such sets are too large,
especially for small d; and, less obviously, 2) all algorithms
try to produce graphs having property Pd while remaining
unbiased (random) with respect to all other properties. One
can check directly that the last characteristic applies to all
the algorithms we have discussed above.
As a consequence, the dK-graph construction algorithms
result in non-uniform sampling of graphs with diﬀerent val-
Table 1: The summary of dK-series.
dKdistribution
Pd deﬁnes Pd−1
Edge existence probability in
stochastic constructions
Maximum entropy value of (d+1)Kdistribution in dK-random graphs
p0K = ¯k/n
P0K(k) = e−¯k¯kk/k!
¯k = P kP(k)
p1K(q1, q2) = q1q2/(n¯q)
P1K(k1, k2) = k1P(k1)k2P(k2)/¯k2
k′ P(k, k′)
p2K(q1, q2)
(¯q/n)P(q1, q2)/(P(q1)P(q2))
See for clustering in 2K-random
P∧(k1, k2, k3)
P△(k1, k2, k3)
By counting edges, we get P(k1, k2) ∼P
k {P∧(k, k1, k2) + P△(k, k1, k2)} /(k1 −1) ∼
k {P∧(k1, k2, k) + P△(k1, k2, k)} /(k2−1), where we omit normalization coeﬃcients.
ues of properties that are not fully deﬁned by Pd.
speciﬁcally, two generated dK-graphs having diﬀerent forms
of a d′K-distribution with d′ > d can appear as the output
of these algorithms with drastically diﬀerent probabilities.
Some dK-graphs have such a small probability of being constructed that we can safely assume they never arise.
For example, consider the simplest 0K stochastic construction, i.e., the classical random graphs Gn,p.
probabilistic argument, one can show that the naturallyoccurring 1K-distribution (degree distribution) in these graphs has a speciﬁc form: binomial, which is closely approximated by the Poisson distribution: P0K(k) = e−¯k¯kk/k! .
The 0K stochastic algorithm may produce a graph with a
diﬀerent 1K-distribution, e.g., the power-law P(k) ∼k−γ,
but the probability of such an outcome is extremely low. Indeed, suppose n ∼104, ¯k ∼5, and γ ∼2.1, so that the characteristic maximum degree is kmax ∼2000 (we chose these
values to reﬂect measured values for Internet AS topologies).
In this case, the probability that a Gn,p-graph contains at
least one node with degree equal to kmax is dominated by
1/2000! ∼10−6600, and the probability that the remaining
degrees simultaneously match those required for a power law
is much lower.
It is thus natural to introduce a set of graphs that correspond to the graphs most likely to be generated by dKgraph constructing algorithms.
We call such graphs the
dK-random graphs.
These graphs have property Pd but
are unbiased with respect to any other more constraining
property. In this sense, the dK-random graphs are the maximally random or maximum-entropy dK-graphs. Our term
maximum entropy here has the following justiﬁcation. As
we have just seen, 0K-random graphs have the maximumentropy value of the 1K-distribution since their node degree distribution is the distribution with the maximum entropy among all the distributions with a ﬁxed average.2
The 1K-random graphs have the maximum-entropy value
of the 2K-distribution since their joint degree distribution,
P1K(k1, k2) = ˜P(k1) ˜P(k2), where ˜P(k) = kP(k)/¯k , is
the distribution with the maximum joint entropy (minimum
mutual information)3 among all the joint distributions with
2The entropy of a discrete distribution P(x) is H[P(x)] =
x P(x)log P(x). If the sample space is also ﬁnite, then
among all the distributions with a ﬁxed average, the binomial distribution maximizes entropy .
3The mutual information of a joint distribution P(x, y) is
I[P(x, y)] = H[P(x)] + H[P(y)] −H[P(x, y)], where P(x)
and P(y) are the marginal distributions.
ﬁxed marginal distributions.4
The main point we extract from these observations is that
in trying to construct dK-graphs, we generally obtain graphs
from subsets of the dK-space. We call these subsets dKrandom graphs and schematically depict them as centers of
the dK-circles in Figure 2.
These graphs do have property Pd and, consequently, properties Pi with i < d, but
they might not ever display property Pj with j > d since
their jK-distributions have speciﬁc, maximum-entropy values that may be diﬀerent from the jK-distribution values in
the original graph.
dK-space explorations
Often we wish to analyze the topological constraints a
given graph G appears to obey. In other cases, we are interested in exploring the structural diversity among dK-graphs.
If we are attempting to determine the minimum d such that
all dK-graphs are similar to G, we can start with a small
value of d, generate dK-graphs, and measure their “distance” from G. If the distance is too great, we can increase d
and repeat the process. On the other hand, to explore structural diversity among all dK-graphs, we must generate dKgraphs that are not random. These non-random dK-graphs
are still constrained by Pd but have extremely low probabilities of being generated by unperturbed dK-graph constructing algorithms.
We cannot construct all dK-graphs, so we need to use
heuristics to generate some dK-graphs and adjust them according to a distance metric that draws us closer to the types
of dK-graphs we seek. One such heuristic is based on the inclusion feature of the dK-series. Because all dK-graphs have
the same values of dK- but not of (d + 1)K-distributions,
we look for simple metrics fully deﬁned by Pd+1 but not
by Pd. While identifying such metrics can be challenging
for high d’s, we can always retreat to the following two simple extreme metrics:
• the correlation of degrees of nodes located at distance d;
• the concentration of d-simplices (cliques of size d + 1).
These metrics are “extreme” in the sense that they correspond to the (d + 1)-sized subgraphs with, respectively,
the maximum (d) and minimum (1) possible diameter. We
4In reality, the last statement generally applies only to
the class of all (not necessarily connected) pseudographs.
Narrowing the class of graphs to simple connected graphs
introduces topological constraints aﬀecting the maximumentropy form of the 2K-distribution.
can then construct dK-graphs with extreme values, e.g., the
smallest or largest possible, for these (extreme) metrics. The
dK-random graphs have the values of these metrics lying
somewhere in between the extremes.
If the goal is to ﬁnd the smallest d that results in suﬃciently constraining graphs, we can compute the diﬀerence
between the extreme values of these metrics, as well as of
other metrics we might consider.
If this diﬀerence is too
large, then the selected value of d is not constraining enough
and we need to increase it. If the goal is to visit exotic locations in a large space of dK-graphs, then such dK-space
exploration may be used to move beyond the relatively small
circle of dK-random graphs.
To illustrate this approach in practice, we consider 1Kand 2K-space explorations.
For 1K, the simplest metric
deﬁned by P2 is any scalar summary statistics of the 2Kdistribution, such as likelihood S (cf. Section 2). To construct graphs with the maximum value of S, we can run a
form of targeting 1K-preserving rewiring that accepts each
rewiring step only if it increases S. We can perform the opposite to minimize S. This type of experiment was at the
core of recent work that led the authors of to conclude
that d = 1 was not constraining enough for the topology
they considered.
To perform 2K-space explorations, we need to ﬁnd simple
scalar metrics deﬁned by P3. Since the 3K-distribution is
actually two distributions, P∧(k1, k2, k3) and P△(k1, k2, k3),
we should have two independent scalar metrics. The secondorder likelihood S2 is one such metric for P∧(k1, k2, k3). We
deﬁne it as the sum of the products of degrees of nodes located at the ends of wedges, S2 ∼P
k1,k2,k3 k1k3P∧(k1, k2, k3).
Any graphs with the same P∧(k1, k2, k3) have the same S2.
For the P△(k1, k2, k3) component, average clustering ¯C ∼
k1,k2,k3 k1P△(k1, k2, k3) is an appropriate candidate. We
note that these two metrics are also the two extreme metrics
in the sense deﬁned above: S2 measures the properly normalized correlation of degrees of nodes located at distance 2,
while ¯C describes the concentration of 2-simplices (triangles). The 2K-explorations amount then to performing the
following two types of targeting 2K-preserving rewiring: accept a 2K-rewiring step only if it maximizes or minimizes:
1) S2, or 2) ¯C.
EVALUATION
In this section, we conduct a number of experiments to
demonstrate the ability of the dK-series to capture important graph properties. We implemented all the dK-graphconstructing algorithms from Section 4.1, applied them to
both measured and modeled Internet topologies, and calculated all the topology metrics from Section 2 on the resulting
We experimented with three measured AS-level topologies, extracted from CAIDA’s skitter traceroute , Route-
Views’ BGP , and RIPE’s WHOIS data for the
month of March 2004, as well as with a synthetic routerlevel topology—the HOT graph from . The qualitative
results of our experiments are similar for the skitter and
BGP topologies, while the WHOIS topology lies somewhere
in-between the skitter/BGP and HOT topologies.
case of skitter comprising of 9204 nodes and 28959 edges,
we will see that its degree distribution places signiﬁcant constraints upon the graph generation process. Thus, even 1Krandom graphs approximate the skitter topology reasonably
Table 2: Scalar graph metrics notations.
Average degree
Assortativity coeﬃcient
Average clustering
Average distance
Standard deviation of distance distribution
Second-order likelihood
Smallest eigenvalue of the Laplacian
Largest eigenvalue of the Laplacian
Table 3: Scalar metrics for 2K-random HOT graphs
generated using diﬀerent techniques.
well. The HOT topology with 939 nodes and 988 edges is
at the opposite extreme. It is the least constrained; 1Krandom graphs approximate it poorly, and dK-series’ convergence is slowest. We thus report results only for these
two extreme cases, skitter and HOT.
Our results represent averages over 100 graphs generated
with a diﬀerent random seed in each case, using the notation
in Table 2.
Algorithmic Comparison
We ﬁrst compare the diﬀerent graph generation algorithms
discussed in Section 4.1. All the algorithms give consistent
results, except the stochastic approach, which suﬀers from
the problems related to high statistical variance discussed
in Section 4.1.1. This conclusion immediately follows from
Figure 5 and Tables 3 and 4 showing graph metric values for
the diﬀerent 2K and 3K algorithms described in Section 4.1.
In our experience, we ﬁnd that dK-randomizing rewiring
is easiest to use. However, it requires the original graph as
input. If only the target dK-distribution is available and
if d ⩽2, we ﬁnd the pseudograph algorithm most appropriate in practice. We note that our 2K version results in fewer
pseudograph “badnesses”, i.e., (self-)loops and small connected components (CCs), than PLRG , its commonlyknown 1K counterpart.
This improvement is due to the
additional constraints introduced by the 2K case. For example, if there is only one node of high degree x and one
node of another high degree y in the original graph, then
there can be only one link of type (x, y).
Our 2K mod-
Table 4: Scalar metrics for 3K-random HOT graphs
generated using diﬀerent techniques.
3K-randomizing
3K-targeting
Node degree
Clustering
2K Matching
2K Randomizing rewiring
2K Pseudograph
2K Targeting rewiring
2K Stochastic
(a) Clustering in skitter for diﬀerent 2K algorithms
Distance in hops
2K Matching
2K Randomizing rewiring
2K Pseudograph
2K Targeting rewiring
2K Stochastic
(b) Distance distribution in HOT
for diﬀerent 2K algorithms
Distance in hops
3K Randomizing rewiring
3K Targeting rewiring
(c) Distance distribution in HOT
for diﬀerent 3K algorithms
Figure 5: Comparison of 2K- and 3K-graph-constructing algorithms.
Table 5: Numbers of possible initial dK-randomizing
rewirings for the HOT graph.
Possible initial
Possible initial rewirings,
ignoring obvious isomorphisms
435,546,699
iﬁcation of the pseudograph algorithm must consequently
produce exactly one link between these two x- and y-degree
nodes, whereas in the 1K case, the algorithm tends to create many such links.
Similarly, a 1K generator tends to
produce many pairs of isolated 1-degree nodes connected to
each another. Since the original graph does not have such
pairs, i.e., (1,1)-links, our 2K generator, as opposed to 1K,
does not form these small 2-node CCs either.
While the pseudograph algorithm is a good 2K-random
graph generator, we could not generalize it for d ⩾3 (see
Section 4.1.2).
Therefore, to generate dK-random graphs
with d ⩾3 when an original graph is unavailable, we use dKtargeting rewiring. We ﬁrst bootstrap the process by constructing 1K-random graphs using the pseudograph algorithm and then apply 2K-targeting 1K-preserving rewiring
to obtain 2K-random graphs. To produce 3K-random graphs,
we apply 3K-targeting 2K-preserving rewiring to the 2Krandom graphs obtained at the previous step.
Topology Comparisons
We next test the convergence of our dK-series for the skitter and HOT graphs. Since all dK-graph constructing algorithms yield consistent results, we selected the simplest one,
the dK-randomizing rewiring from Section 4.1.4, to obtain
dK-random graphs in this section.
The number of possible initial dK-randomizing rewirings
is a good preliminary indicator of the size of the dK-graph
space. We show these numbers for the HOT graph in Table 5. If we discard rewirings leading to obvious isomorphic
graphs, cf. Section 4.1.4, then the number of possible initial
rewirings is even smaller.
We compare the skitter topology with its dK-random coun-
Table 6: Comparing scalar metrics for dK-random
and skitter graphs.
terparts, d = 0, . . . , 3, in Table 6 and Figure 6. We report
all the metrics calculated for the giant connected component (GCCs). Minor discrepancies between values of average degree ¯k and r result from GCC extractions. If we do
not extract the GCC, then ¯k is the same as that of the original graph for all d = 0, . . . , 3, and r is exactly the same
for d > 1.
We do not show degree distributions for brevity. However, degree distributions match when considering the entire
graph and are very similar for the GCCs for all d > 0. When
d = 0, the degree distribution is binomial, as expected.
We see that all other metrics gradually converge to those
in the original graph as d increases. A value of d = 1 provides a reasonably good description of the skitter topology,
while d = 2 matches all properties except clustering. The
3K-random graphs are identical to the original for all metrics we consider, including clustering.
We perform the 2K-space explorations described in Section 4.3 to check if d = 2 is indeed suﬃciently constraining
for the skitter topology. We observe small variations of clustering ¯C, second-order likelihood S2, and spectrum, shown
in Table 7 and Figure 7. All other metrics do not change, so
we do not show plots for them. We conclude that d = 2, i.e.,
the joint degree distribution provides a reasonably accurate
description of observed AS-level topologies.
The HOT topology is more complex than AS-level topologies. Earlier work argues that this topology cannot be accurately modeled using degree distributions alone . We
therefore selected the HOT topology graph as a diﬃcult case
for our approach.
Distance in hops
(a) Distance distribution
Node degree
Normalized node betweenness
(b) Betweenness
Node degree
Clustering
(c) Clustering
Figure 6: Comparison of dK-random and skitter graphs.
Node degree
Clustering
2K with clustering maximized
2K with clustering minimized
Figure 7: Varying clustering in
2K-graphs for skitter.
Distance in hops
Distance distribution for dK-random and HOT
Node degree
Normalized node betweenness
Figure 9: Betweenness for dKrandom and HOT graphs
Scalar metrics for 2K-space explorations
for skitter.
A preliminary inspection of visualizations in Figure 3 indicates that the dK-series converges at a reasonable rate even
for the HOT graph. The 0K-random graph is a classical random graph and lacks high-degree nodes, as expected. The
1K-random graph has all the high-degree nodes we desire,
but they are crowded toward the core, a property absent in
the HOT graph. The 2K constraints start pushing the highdegree nodes away to the periphery, while the lower-degree
nodes migrate to the core, and the 2K-random graph begins to resemble the HOT graph. The 3K-random topology
looks remarkably similar to the HOT topology.
Of course, visual inspection of a small number of randomly
generated graphs is insuﬃcient to demonstrate our ability
to capture important metrics of the HOT graph.
we compute the diﬀerent metric values for each of the dKrandom graph and compare them with the corresponding
value for the original HOT graph. In Table 8 and Figures 8
and 9 we see that the dK-series converges more slowly for
HOT than for skitter. Note that we do not show clustering plots because clustering is almost zero everywhere: the
HOT topology has very few cycles; it is almost a tree. The
1K-random graphs yield a poor approximation of the original topology, in agreement with the main argument in .
Both Figures 3 and 9 indicate that starting with d = 2, lowbut not high-degree nodes form the core: betweenness is
approximately as high for nodes of degree ∼10 as for highdegree nodes. Consequently, the 2K-random graphs provide
a better approximation, but not nearly as good as it was for
skitter.5 However, the 3K-random graphs match the original HOT topology almost exactly. We thus conclude that
the dK-series captures the essential characteristics of even
particularly diﬃcult topologies, such as HOT, by suﬃciently
increasing d, in this case to 3.
5The speed of dK-series convergence depends both on the
structure and size of an original graph. It must converge
faster for smaller input graphs of similar structure. However,
here we see that the graph structure plays a more crucial
role than its size. The dK-series converges slower for HOT
than for skitter, even though the former graph is an order
of magnitude smaller than the latter.
Table 8: Comparing scalar metrics for dK-random
and HOT graphs.
DISCUSSION AND FUTURE WORK
While we feel our approach to topology analysis holds signiﬁcant promise, a number of important avenues remain for
further investigation. First, one must determine appropriate values of d to carry out studies of interest. Our experience to date suggests that d = 2 is suﬃcient to reproduce
most metrics of interest and that d = 3 faithfully reproduces all metrics we are aware of for Internet-like graphs.
It also appears likely that d = 3 will be suﬃcient for selforganized small-worlds in general. This issue is particularly
important because the computational complexity of producing dK-graphs grows rapidly with d. Studies requiring large
values of d may limit the practicality of our approach.
In general, more complex topologies may necessitate developing algorithms for generating dK-random graphs with
high d’s. We needed higher d to describe the HOT topology
as accurately as the skitter topology. The intuition behind
this observation is that the HOT router-level topology is
“less random” because it results from targeted design and
engineering.
The skitter AS-level topology, on the other
hand, is “more random” since there is no single point of external human control over its shape and evolution. It is a
cumulative result of local decisions made by individual ASes.
A second important question concerns the discrete nature
of our model. For instance, we are able to reproduce 1Kand 2K-distributions but it is not meaningful to consider reproducing 1.4K-distributions. Consider a graph property X
not captured by 1K but successfully captured by 2K.
could turn out that the space of 2K-random graphs overconstrains the set of graphs reproducing X. That is, while
2K-graphs do successfully reproduce X, there may be other
graphs that also match X but are not 2K-graphs.
Fundamental to our approach is that we seek to reproduce important characteristics of a given network topology.
We cannot use our methodology to discover laws governing
the evolutionary growth of a particular network. Rather, we
are restricted to observing changes in degree correlations in
graphs over time, and then generating graphs that match
such degree correlations. However, the goals of reproducing
important characteristics of a given set of graphs and discovering laws governing their evolution are complementary
and even symmetric.
They are complementary because the dK-series can simplify the task of validating particular evolutionary models. Consider the case where a researcher wishes to validate
a model for Internet evolution using historical connectivity information. The process would likely involve starting
with an initial graph, e.g., reﬂecting connectivity from ﬁve
years ago, and generating a variety of larger graphs, e.g.,
reﬂecting modern-day connectivity. Of course, the resulting
graphs will not match known modern connectivity exactly.
Currently, validation would require showing that the graph
matches “well enough” for all known ad hoc graph properties. Using the dK-series however, it is suﬃcient to demonstrate that the resulting graphs are dK-random for an appropriate value of d, i.e., constrained by the dK-distribution
of modern Internet graphs, with d = 3 known to be suﬃcient
in this case. As long as the resulting graphs fall in the dKrandom space, the nature of dK-randomness explains any
graph metric variation from ground truth. This methodology also addresses the issue of deﬁning “well enough” above:
dK-space exploration can quantify the expected variation
in ad hoc properties not fully speciﬁed by a particular dKdistribution.
The two approaches are symmetric in that they both attempt to generate graph models that accurately capture values of topology metrics observed in real networks.
approaches have inherent tradeoﬀs between accuracy and
complexity. Achieving higher accuracy with the dK-series
requires greater numbers of statistical constraints with increasing d. The number of these constraints is upper-bounded by nd (the size of dK-distribution matrices) times the
number of possible simple connected d-sized graphs .6
Achieving higher accuracy with network evolution modeling requires richer sets of system-speciﬁc external parameters . Every such parameter represents a degree of freedom
in a model. By tuning larger sets of external parameters,
one can more closely match observed data. It could be the
case—which remains to be seen—that the number of parameters needed for evolution modeling is smaller than the
number of constraints required by the dK-series to characterize the modern Internet structure with the same degree
of accuracy. However, with the dK-series, the same set of
constraints applies to any networks, including social, biological, communication, etc. With evolution modeling, one
must develop a separate model for each speciﬁc network.
Directions for future work all stem from the observation
that the dK-series is actually the simplest basis for statistical analysis of correlations in complex networks. We can incorporate any kind of technological constraints into our constructions. In a router-level topology, for example, there is
some dependency between the number of interfaces a router
has (node degree) and their average bandwidth (betweenness/degree ratio) . In light of such observations, we can
simply adjust our rewiring algorithms (Section 4.1.4) to not
accept rewirings violating this dependency. In other words,
we can always consider ensembles of dK-random graphs subject to various forms of external constraints imposed by the
speciﬁcs of a given network.
Another promising avenue for future work derives from
the observation that abstracting real networks as undirected
graphs might lose too much detail for certain tasks.
example, in the AS-level topology case, the link types can
represent business AS relationships, e.g., customer-provider
or peering. For a router-level topology, we can label links
with bandwidth, latency, etc., and nodes with router manufacturer, geographical information, etc. Keeping such an-
6Although the upper bound of possible constraints increases
rapidly, sparsity of dK-distribution matrices increases even
faster. The result of this interplay is that the number of nonzero elements of dK-distributions for any given G increases
with d ﬁrst but then quickly decreases, and it is surely 1 in
the limit of d = n, cf. the example in Section 3.
notation information for nodes and links can also be useful for other types of networks, e.g., biological, social, etc.
We can generalize the dK-series approach to study networks
with more sophisticated forms of annotations, in which case
the dK-series would describe correlations among diﬀerent
types of nodes connected by diﬀerent types of links within
d-sized geometries.
Given the level of constraint imposed
by d = 2 and d = 3 for our studied graphs and recognizing
that including annotations would introduce signiﬁcant additional constraints to the space of dK-graphs, we believe that
2K-random annotated graphs could provide appropriate descriptions of observed networks in a variety of settings.
In this paper, all synthetic graphs’ sizes equal to a given
graph’s size. We are working on appropriate strategies of
rescaling the dK-distributions to arbitrary graph sizes.
CONCLUSIONS
Over the years, a number of important graph metrics
have been proposed to compare how closely the structure of
two arbitrary graphs match and to predict the behavior of
topologies with certain metric values. Such metrics are employed by networking researchers involved in topology construction and analysis, and by those interested in protocol
and distributed system performance. Unfortunately, there
is limited understanding of which metrics are appropriate
for a given setting and, for most proposed metrics, there are
no known algorithms for generating graphs that reproduce
the target property.
This paper deﬁnes a series of graph structural properties
to both systematically characterize arbitrary graphs and to
generate random graphs that match speciﬁed characteristics
of the original. The dK-distribution is a collection of distributions describing the correlations of degrees of d connected
nodes. The properties Pd, d = 0, . . . , n, comprise the dKseries. A random graph is said to have property Pd if its
dK-distribution has the same form as in a given graph G.
By increasing the value of d in the series, it is possible to
capture more complex properties of G and, in the limit,
a suﬃciently large value of d yields complete information
about G’s structure.
We ﬁnd interesting tradeoﬀs in choosing the appropriate value of d to compare two graphs or to generate random graphs with property Pd. As we increase d, the set of
randomly generated graphs having property Pd becomes increasingly constrained and the resulting graphs are increasingly likely to reproduce a variety of metrics of interest. At
the same time, the algorithmic complexity associated with
generating the graphs grows sharply. Thus, we present a
methodology where practitioners choose the smallest d that
captures essential graph characteristics for their study. For
the graphs that we consider, including comparatively complex Internet AS- and router-level topologies, we ﬁnd that
d = 2 is suﬃcient for most cases and d = 3 captures all
graph properties proposed in the literature known to us.
In this paper, we present the ﬁrst algorithms for constructing random graphs having properties P2 and P3, and sketch
an approach for extending the algorithms to arbitrary d. We
are also releasing the source code for our analysis tools to
measure an input graph’s dK-distribution and our generator able to produce random graphs possessing properties Pd
for d < 4.
We hope that our methodology will provide a more rigorous and consistent method of comparing topology graphs
and enable protocol and application researchers to test system behavior under a suite of randomly generated yet appropriately constrained and realistic network topologies.
Acknowledgements
We would like to thank Walter Willinger and Lun Li for
their HOT topology data; Bradley Huﬀaker, David Moore,
Marina Fomenkov, and kc claﬀy for their contributions at
diﬀerent stages of this work; and anonymous reviewers for
their comments that helped to improve the ﬁnal version of
this manuscript. Support for this work was provided by NSF
CNS-0434996 and Center for Networked Systems (CNS) at