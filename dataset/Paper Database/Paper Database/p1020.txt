Multi-level Adaptive Active Learning
for Scene Classiﬁcation
Xin Li and Yuhong Guo
Department of Computer and Information Sciences
Temple University
Philadelphia, PA 19122, USA
{xinli, yuhong}@temple.edu
Abstract. Semantic scene classiﬁcation is a challenging problem in computer vision. In this paper, we present a novel multi-level active learning approach to reduce the human annotation eﬀort for training robust
scene classiﬁcation models. Diﬀerent from most existing active learning
methods that can only query labels for selected instances at the target
categorization level, i.e., the scene class level, our approach establishes a
semantic framework that predicts scene labels based on a latent objectbased semantic representation of images, and is capable to query labels
at two diﬀerent levels, the target scene class level (abstractive high level)
and the latent object class level (semantic middle level). Speciﬁcally, we
develop an adaptive active learning strategy to perform multi-level label query, which maintains the default label query at the target scene
class level, but switches to the latent object class level whenever an
“unexpected” target class label is returned by the labeler. We conduct
experiments on two standard scene classiﬁcation datasets to investigate
the eﬃcacy of the proposed approach. Our empirical results show the
proposed adaptive multi-level active learning approach can outperform
both baseline active learning methods and a state-of-the-art multi-level
active learning method.
Keywords: Active Learning, Scene Classiﬁcation.
Introduction
Scene classiﬁcation remains one of the most challenging problems in computer
vision ﬁeld. Diﬀerent from the classiﬁcation tasks in other ﬁelds such as NLP,
where the meanings of features (e.g., words) are perceivable by human beings,
the low-level features of an image are primarily built on some signal responses or
statistic information of mathematical transformations. Though these low-level
features are useful and powerful as proved by numerous works for decades, the
semantic gap between the semantically non-meaningful low-level features and the
high-level abstractive scene labels becomes a bottleneck for further improving
scene classiﬁcation performance. Recent advances on scene classiﬁcation 
and other related tasks such as semantic segmentation and object
X. Li and Y. Guo
(a) coast/city
(b) mountain/coast
(c) ﬁeld/airport
(d) theater/auditorium
(e) airport/mall
(f) terminal/auditorium
Fig. 1: Examples of ambiguous scene categories. (a)-(c) are confusing examples
of outdoor scenes and (d)-(e) are examples of indoor scenes.
detection/recognition have demonstrated the importance of exploiting
semantic information and extracting high-level scene label structures, where a
scene label (e.g., coast) can be viewed as a semantic concept comprising of a
set of important high level visual objects (e.g., sky, sand and sea). The work
in particularly demonstrated the strength of predicting scene labels based
on the high-level object-based representations of images. However, this work
requires supervised training of object detectors, which can signiﬁcantly increase
the demand for human annotation eﬀort. Moreover, to produce a good scene
classiﬁcation model, a suﬃcient amount of target scene labels need to be acquired
as well, which induces expensive human annotation cost. In this work, we address
the important problem of reducing human annotation eﬀort for learning scene
classiﬁcation models.
Active learning is a well studied technique for reducing the cost of manual
annotations by performing selective instance sampling. In contrast to “passive”
learning where the learner uses randomly generated labeled instances, “active”
learners iteratively select the most informative instances to label in an interactive learning process . Traditional active learners query labels for the selected instance at the target prediction label level, which however is not the
best strategy in many cases of scene classiﬁcation tasks. Scene labels are highly
abstractive and semantic labels. Without accurately identifying their high level
object-based semantic representations, some scene labels can be very diﬃcult to
be distinguished from each other even by a human labeler in many scenarios. For
example, it is hard to tell for a human labeler whether the image in Figure 1(b)
is indeed a mountain scene or a coast scene; similarly, it is hard to tell whether
the image in Figure 1(e) is the seating area of a mall or an airport terminal.
From Figure 1 we can see that such ambiguities exist not only among outdoor
scenes but also in indoor scenes. However, the objects contained in these images
Multi-level Adaptive Active Learning for Scene Classiﬁcation
are much more easier to be identiﬁed by a human labeler. The object level labels may successfully infer the scene labels based on the object-based statistical
semantic scene structure induced from the labeled data.
Based on these observations, in this paper we develop a novel multi-level
adaptive active learning approach to reduce the annotation eﬀort of learning
accurate scene classiﬁcation models. This approach is based on a latent objectbased hierarchical scene classiﬁcation model, which involves both scene classiﬁer
and object classiﬁers. It selects both instance and label types to query, aiming to
reduce the overall prediction uncertainty of the multi-class scene classiﬁcation
model over all labeled and unlabeled instances. By default, it performs label
query at the target scene class level and selects instance based on a maximum
conditional mutual information criterion. But whenever an “unexpected” target
scene label is returned by the labeler in a given iteration, it will switch to perform label query at the latent object class level in the next iteration for once.
After querying for a scene label, only the scene classiﬁer will be updated. But if
an object label is queried, both object and scene classiﬁers will be updated. We
conduct experiments on two standard scene classiﬁcation datasets to investigate
the eﬃcacy of the proposed approach. Our empirical results show the proposed
adaptive multi-level active learning approach can outperform a few baseline active learning methods and a state-of-the-art multi-level active learning method.
Related Work
In this section, we present a brief review over the related scene classiﬁcation and
active learning works developed in computer vision ﬁeld.
Scene classiﬁcation has long gained its popularity in the literature. Previous works on scene classiﬁcation can be categorized into two main groups: data
representation centered methods and classiﬁcation model centered methods. In
the ﬁrst group, mid-level representations built from low-level features such as
SIFT or HOG features have been exploited for scene classiﬁcation. For
example, introduces a bag-of-words (BoW) model based on low-level features
to represent a natural scene image. proposes a spatial pyramid matching
model to further improve the BoW model by taking the spatial relationship
between the visual words into account. proposes a novel holistic image descriptor for scene classiﬁcation. More recent eﬀorts have centered on representing
a scene with semantically meaningful information rather than statistic information of low-level hand-designed features. proposes an image representation
based on discriminative scene regions detected using a latent SVM model. 
proposes an object-centered approach called object bank, where each image is
represented as the response map to a large number of pre-trained generic object detectors. Our classiﬁcation model shares similarity with this work on using
the presence of objects as attributes for scene classiﬁcation. However, the object
bank method requires supervised training of a large number of object detectors which is extremely expensive in terms of annotation cost, while the object
classiﬁers in our model are learned on the ﬂy in a semi-supervise manner and
X. Li and Y. Guo
require very limited annotations. Moreover, the object detectors of the object
bank model take the whole image as input, while our object classiﬁers pursue
patch-based training. Another work also proposes an attribute based scene
representation which contains binary attributes to describe the intra- and interclass scene variations. But similar to the object bank method, their attribute
learning is quite expensive and they predict the presence of attributes using the
sliding window technique which further increases the computational cost.
For methods centered on classiﬁcation model development, we would like
to mention a few works with widely used techniques . In , a deformable part-based model (DPM) has been applied to address scene categorization. proposes a prototype based model for indoor scenes that captures the
characteristic arrangements of scene components. proposes a latent structural SVM for the reconﬁgurable version of a spatial bag of words model. These
methods also demonstrate the usefulness of exploiting mid-level representations
for scene classiﬁcation. Nevertheless, all these methods are passive learning methods and require a large number of labeled instances for training.
Active learning methods have been widely used in computer vision ﬁeld to
reduce human labeling eﬀorts in image and video annotation , retrieval
 , recognition and segmentation . These active learning methods iteratively select the most informative instance to annotate according to a given instance selection criterion. Recently, some researchers have observed that exploiting single criterion for instance selection lacks the capacity of handling diﬀerent
active learning scenarios, and an adaptive active learning strategy that integrates
strengths of diﬀerent instance selection criteria has been proposed in . Nevertheless, all these active learning methods are limited to querying labels in the
target prediction label space, and lack suﬃcient capacity of handling the highly
semantic scene classiﬁcation problems and exploiting advanced scene classiﬁcation models, especially when the scene images are ambiguous to categorize as
demonstrated in Figure 1. Our proposed active learning approach will address
the limitation of these current methods by exploiting a latent object-based scene
classiﬁcation model and performing multi-level adaptive label querying at both
the scene class level and the object class level.
There are a number of existing active learning methods that query the labelers for information beyond the target image labels. For example, considers
attributed based prediction models and asks users for inputs on the attribute
level to improve the class predictions, while assuming ﬁxed attribute conﬁgurations for each give image class label. treats the overall object classiﬁcation
problem as a multi-instance learning problem and considers the same type of
labels at two levels, instance level (segments) and bag level (images). These
works nevertheless are still limited to exploiting the same type of standard queries, while another few works have exploited semantic or
multiple types of queries. introduces a new interactive learning paradigm
that allows the supervisor to additionally convey useful domain knowledge using
relative attributes. presents an active learning framework to simultaneously
learn appearance and contextual models for scene understanding. It explores
Multi-level Adaptive Active Learning for Scene Classiﬁcation
three diﬀerent types of questions: regional labeling questions, linguistic questions and contextual questions. However, it does not handle scene classiﬁcation
problems but evaluate the approach regarding the region labels. presents
an active learning approach that selects image annotation requests among both
object category labels and the object-based attribute labels. It shares similarity
with our proposed approach in querying at multi-levels of label spaces, but it
treats image labels and attribute labels in the same way and involves expensive
computations. Nevertheless, these active learning works tackle object recognition problems using pre-ﬁxed selection criteria. Our proposed approach on the
other hand uses an adaptive multi-level active learning strategy to optimize a
latent object-based hierarchical scene classiﬁcation model.
Proposed Method
In this section, we ﬁrst establish the hierarchical semantic scene classiﬁcation
model based on latent object level representations in Section 3.1 and then present
our multi-level adaptive active learning method in Section 3.2.
Hierarchical Scene Classiﬁcation Model
Learning mid-level representations that capture semantic meanings has been
shown to be incredibly useful for computer vision tasks such as scene classiﬁcation and object recognition. In this work, we treat object category values as
high level scene attributes, and use a hierarchical model for scene classiﬁcation
that has a mid-level object representation layer. The work ﬂow of our approach
has four stages: Firstly, we preprocess each image into a bag of patches and a
bag of low-level feature vectors can be produced from the patches. For the sake
of computational eﬃciency, we only used aligned non-overlapping patches. We
expect each patch presents information at the local object level. Secondly, we
perform unsupervised clustering over the patches using a clustering method K-
Medoids and then assign an object class name to each patch cluster by querying
the object level labels for the center patch in each cluster. Thirdly, we train a set
of binary object classiﬁers based on these named clusters of patches using the
one-vs-all scheme. Then for each image, its mid-level object-based representation can be obtained by applying these object classiﬁers over its patches. That is,
each image will be represented as a binary indicator vector, where each entry of
the vector indicates the presence or absence of the corresponding object category
in the image. Figure 2 presents examples of this mid-level object-based representation of images. Finally, a multi-class scene classiﬁer is trained based on the
mid-level representation of labeled images. To further improve the scene classi-
ﬁer, we have also considered using hybrid features to train the scene classiﬁer.
That is, we train the scene classiﬁer based on both the mid-level representation features and the low-level features of the labeled images. This turns out to
be more robust for scene classiﬁcation than using the mid-level representation
alone. More details will be discussed in the experimental section.
X. Li and Y. Guo
Fig. 2: Examples of the mid-level semantic representation employed in our scene
classiﬁcation model. Each 1 value indicates the presence of an object and each
0 value indicates the absence of an object in a given image.
Our system uses logistic regression as the classiﬁcation model at both object
and scene levels. Given the patch labels produced by clustering, for each object
class, we have a set of binary labeled patches {(˜xi, ˜zi)}No
i=1 with ˜zi ∈{+1, −1}.
We then train a probabilistic binary logistic regression classiﬁer for each object
class to optimize a ℓ2-norm regularized log-likelihood function
log P(˜zi|˜xi) + 1
P(˜zi|˜xi) =
1 + exp(−˜zi˜xT
For scene classiﬁcation, given the labeled data L = {(zi, yi)}N
i=1, where zi is
the mid-level indicator representation vector for the i-th image Ii, and yi is its
scene class label, we train a multinomial logistic regression model as the scene
classiﬁer. Speciﬁcally, we perform training by minimizing a ℓ2-norm regularized
negative log-likelihood function
log P(yi|zi) + 1
P(yi = c|zi) =
The minimization problems in both (1) and (3) above are convex optimization
problems, and we employ the trust region newton method developed in to
perform training.
Multi-level Adaptive Active Learning for Scene Classiﬁcation
We can see that our hierarchical scene classiﬁcation model has similar capacity with the object bank method regarding exploiting the object-level representations of images. For object-based representation models, one needs to determine
what object classes and how many of them should be used in the model. The object bank model chooses object classes based on some statistic information drew
from several public datasets and their object detectors are trained on several
large datasets with a large amount of object labels as well. However, our model
only requires object labels for a relatively very small number of representative
patches produced by K-Medoids clustering method to automatically determine
the object classes and numbers involved in our target dataset. In detail, for each
cluster center patch, we will seek an object label from a human labeler through
a crowd-sourcing system and take it as the class label for the whole cluster of
patches. However, due to the preferences of diﬀerent labelers, the labels can be
provided at diﬀerent granularity levels, e.g., “kid” vs “sitting kid”. Moreover,
typos may exist in the given labels, e.g., “groound” vs “ground”. We thus apply
some word processing technique on the collected object labels. When the
given label is a phrase, we will not process it as a new category if one of its
component words is already a category keyword. Hence “sitting kid” will not be
taken as a category if “kid” is already one. After object labels being puriﬁed,
we merge the clusters with the same object labels and produce the ﬁnal object
classes and number for the given data. In our experiments, the numbers of object
classes resulted range from 20 to 50, which ﬁts into the principle of Zipf’s Law
and implies that a small proportion of object classes account for the majority of
object occurrences.
Multi-level Adaptive Active Learning
Let zi denote the mid-level feature vector for image Ii, Y = {1 . . . Ky} denote
the scene class label space, L = {(z1, y1), . . . , (zN, yN)} denote the set of labeled
instances, and U denote the large pool of unlabeled instances. After initializing
our training model based on the small number of labeled instances, we perform
multi-level active learning in an iterative fashion, which involves two types of
iterations, scene level iterations and object level iterations. In a scene level iteration, it selects the most informative unlabeled instance to label at the scene
class level, while in an object level iteration, it selects the most informative unlabeled instance to label at the object class level. An adaptive strategy is used
to perform switch between these two types of iterations.
Scene level iteration. In such an iteration, we select the most informative unlabeled instance to label based on a well-motivated utility measure, named maximum conditional mutual information (MCMI), which maximizes the amount of
information we gain from querying the selected instance:
z∗= arg max
(H(L) −H(L ∪(z, y)))
X. Li and Y. Guo
where the data set entropy is deﬁned as
PL(yi = l|zi) log PL(yi = l|zi)
which measures the total entropy of all labeled and unlabeled instances. PL(y|z)
denotes the probability estimate produced by the classiﬁcation model that is
trained on the labeled data L. Note the ﬁrst entropy term H(L) remains to be
a constant for all candidate instances and can be dropped from the instance
selection criterion, which leads to the selection criterion below:
z∗= arg min
H(L ∪(z, y))
Though Equation (7) provides a principled instance selection criterion, it is impossible to compute given the true label y is unknown for the unlabeled query
instance z. We hence adopt the “optimistic” strategy proposed in to pursue
an alternative optimistic selection criterion below:
(z∗, l∗) = arg min
l∈Y H(L ∪(z, l))
which selects the candidate instance z∗and its a label option l∗that leads to the
smallest total prediction uncertainty over all instances. Once the true label y∗of
the select instance z∗being queried, we added (z∗,y∗) into the labeled set L and
retrain the scene classiﬁer. This optimistic selection strategy however requires
retraining the scene classiﬁer for O(|U|×|Y|) times to make the instance selection
decision: For each of the |U| unlabeled instances, one scene classiﬁer needs to
be trained for each of its |Y| candidate labels. The computational cost can be
prohibitive on large datasets. To compensate this drawback, one standard way
is to use random sub-sampling to select a subset of instances and label classes
to reduce the candidate set in Equation (8).
Object level iteration. Querying labels at the object class level raises more
questions. First, what, image vs patch, should be presented to the human labeler? What information should we query? A naive idea is to present a patch
to the human labeler and query the object class label of the patch. However, it
will be very diﬃcult to select the right patch that contains a perceivable and
discriminative object. Hence, instead of presenting patches to the annotators,
we present a whole image to the labeler and ask whether the image contains a
particular set of selected objects. Such speciﬁc questions will be easy to answer
and will not lead to any ambiguities.
Next, we need to decide which image and what objects to query. We employ a most uncertainty strategy and select the most uncertain image (with the
maximum entropy) to query under the current scene classiﬁcation model:
z∗= arg max
PL(y = l|z) log PL(y = l|z)
Multi-level Adaptive Active Learning for Scene Classiﬁcation
For the selected image z∗, we then select the top M most important objects
regarding the most conﬁdent scene label ˆl∗of z∗under the current scene classiﬁer
to query (We used M = 5 in our experiments later). Speciﬁcally, ˆl∗will be
determined as ˆl∗= arg maxl PL(l|z∗). Then we choose M objects that correspond
to the largest M entries of the weight parameter vector |wˆl∗| under the current
multi-class scene classiﬁer. Our query questions submitted to the annotators will
be in a very speciﬁc form: “Does object oi appear in this image?” We will ask
M such questions, one for each selected object.
The last challenge in the object level iteration is on updating the scene classiﬁcation model after the selected object labels being queried. If the answer for
a question is “No”, we simply re-label all patches of the selected image as negative samples for that object class, and retrain the particular object classiﬁer if
needed. On the other hand, if the answer for a question is “Yes”, it means at
least one patch in this image should have a positive label for the particular object
class. We hence assign the object label to the most conﬁdent patch within the
selected image under the current particular object classiﬁer. Then we will reﬁne
our previous unsupervised patch clustering results by taking the newly gathered
patches into account. Our clustering reﬁne scheme is very simple. Given the previous clustering result with K clusters, we set the new labeled patch as a new
cluster center and perform K-Medoids updates with K + 1 clusters. Note two of
these K+1 clusters share the same object label and we will merge them after the
end of the clustering process. Finally, all object classiﬁers will be updated based
on the new clustering results. Consequently, the mid-level representations of each
labeled image changes as well, and the scene classiﬁer needs to be updated with
the new mid-level features.
Adaptive active learning strategy. The last question one needs to answer to
produce an active learning algorithm is how do we decide which type of iterations
to pursue. We employ an adaptive strategy to make this decision: By default, we
will perform active learning with scene level iterations, as most traditional active
learners pursued. In each such iteration, an instance z∗and its optimistic l∗will
be selected, and its true label y∗will be queried. However, once we found the
true label y∗is diﬀerent from the optimistic guess l∗, which means the strategy
in the scene level iteration has been misled under the current scene classiﬁer, we
will then switch to the object level iteration in the next iteration to gather more
information to strengthen the scene classiﬁcation model from its foundation. We
will switch back to the traditional scene label iteration after that. The overall
multi-level adaptive active learning algorithm is summarized in Algorithm 1.
Experimental Results
We investigate the performance of the proposed active learning approach for
scene classiﬁcation on two standard challenging datasets, Natural Scene dataset
and MIT Indoor Scene dataset. Natural scene dataset is a subset of the LabelMe
dataset, which contains 8 scene categories (coast, forest, highway, inside city,
X. Li and Y. Guo
Algorithm 1 Multi-level Adaptive Active Learning
1: Input: Labeled set L, unlabeled set U, and record set V = Ø;
M: number of objects to query on each image,
K: number of patch clusters.
4: Procedure:
5: Apply K-Medoids clustering on patches {˜xi ∈L}.
6: Query object labels for each cluster center patch.
7: Merge clusters with the same object labels.
8: Train object classiﬁers based on the clusters.
9: Obtain mid-level representation for each image z ∈L ∪U.
10: Train a scene classiﬁer on L.
11: Set itype = 1. %scene level=1, object level = 0
12: repeat
if itype == 1 then
Select (z∗, l∗) from the unlabeled set U based on Equation (8)
and purchase its true label y∗.
Drop z∗from U and add (z∗, y∗) into L.
Retrain the scene classiﬁer on the updated L.
if y∗̸= l∗then
Set itype =0.
Select z∗∈U \ V according to Equation (9).
Predict most conﬁdent scene label ˆl∗for z∗.
Query the top M most important objects based on the absolute
weight values |wˆl∗| for scene class ˆl∗.
Update the clustering result if necessary.
Update object classiﬁers.
Add z∗into V.
Update the mid-level representation for all images.
Update scene classiﬁer on L.
Set itype =1.
31: until run out of money or achieve the aim
mountain, open country, street, and tall building) and each category has more
than 250 images. We randomly selected 100 images from each category and
pooled them together into a training set and used the rest as the test set. We
further randomly selected 5 images per category (40 in total) as the initial labeled
set. MIT indoor scene dataset contains 67 indoor categories and a total of 15, 620
images. The number of images varies across categories, but there are at least 100
images per category. We randomly selected 50 images per category to form the
training set and the rest are used for testing. Within the training set, 2 images are
randomly selected from each category as labeled instances and the rest images
are pooled together as unlabeled instances.
The natural scene dataset has object level annotations available to use and
the MIT indoor scene dataset also has object level annotations for a proportion
Multi-level Adaptive Active Learning for Scene Classiﬁcation
of its images. We thus simulated the human annotators’ answers based on these
available object level annotations for our multi-level active learning. For the MIT
indoor scene dataset, we further preprocessed it by discarding the categories
that contain less than 50 annotated images (at the object level). After this
preprocessing, only 15 categories were left. We produced all non-overlapping
patches in size of 16×16 pixels that cover each image. We used the 128-dimension
SIFT feature as the low-level features in our experiments.
In our experiments, we compared the proposed Multi-Level Adaptive active learning (MLA) method to three baselines: (1) Single-Level Active learning
(SLA) method, which is a variant of MLA that only queries the scene labels; (2)
Single-Level Random sampling (SLR) method, which randomly selects an image
from the unlabeled pool in each iteration and queries its scene label; and (3)
Multi-Level Random sampling (MLR) method, which randomly selects an image
from the unlabeled pool in each iteration and then randomly chooses to query its
object labels or scene label with equal probability. Moreover, we have also compared to the method, Active Learning with Object and Attribute annotations
(ALOA), developed in . This ALOA method is the state-of-the-art active
learner that utilizes both attribute and image labels. We used K = 200 (for the
K-Medoids clustering) and M = 5 for the proposed and the baseline methods.
For the trade-oﬀparameters C in Eq.(1) and Eq. (3), we set C as 10 for the object classiﬁers and 0.1 for the scene classiﬁer, aiming to avoid overﬁtting for the
scene classiﬁer with limited labeled data at the scene level. Starting from the initial randomly selected labeled data, we ran each active learning method for 100
iterations, and recorded their performance in each iteration. We repeated each
experiment 5 times and reported the average results and standard deviations.
Figure 3 presents the comparison results in terms of scene classiﬁcation accuracy on the MIT Indoor scene dataset and the Natural scene dataset. For the
proposed approach MLA and the baselines SLA, MLR, SLR, we experimented
two diﬀerent ways of learning scene classiﬁers. 1 A straightforward way is to learn
the scene classiﬁer based on the mid-level semantic representation produced by
the object classiﬁers. Alternatively, we have also investigated learning the scene
classiﬁer based on hybrid features by augmenting the mid-level representation
with the low-level SIFT features. Such a mechanism was shown to be eﬀective in
 . Speciﬁcally, we built a 500-words codebook with K-Means clustering over
the SIFT features and represented each image as a 500-long vector with vector
quantization. This low-level representation together with the mid-level representation form the hybrid features of images for scene classiﬁcation. The comparison
results based only on mid-level representation are reported on the left column of
Figure 3 for the two datasets respectively; and the comparison results based on
the hybrid features are reported on the right column of Figure 3. We can see in
terms of scene classiﬁcation accuracy, our proposed method MLA beats all other
comparison methods, especially the baselines, across most of the comparison
range, except at the very beginning. At the beginning of the active learning process, ALOA produces the best performance with very few labeled images. Given
1 The ALOA from works in a diﬀerent mechanism with a latent SVM classiﬁer.
X. Li and Y. Guo
MIT Indoor
Number of Iterations
MIT Indoor (Hybrid)
Number of Iterations
Natural Scene
Number of Iterations
Natural Scene (Hybrid)
Number of Iterations
Fig. 3: The average and standard deviation results in terms of scene classiﬁcation
accuracy on both MIT Indoor scene dataset and Natural Scene dataset.
that ALOA uses the state-of-the-art latent SVM classiﬁer, and our approach
uses a simple logistic regression model, this seems reasonable. But the gap between ALOA and the proposed MLA quickly degrades with the active learning
process; after a set of iterations, MLA signiﬁcantly outperforms ALOA. This
demonstrates that our proposed multi-level adaptive active learning strategy is
much more eﬀective and it is able to collect most useful label information that
makes a simple logistic regression classiﬁer to outperform the state-of-the-art
latent SVM classiﬁer. Among the three baseline methods, SLA always performs
the best. On MIT-Indoor dataset, it even outperforms ALOA when only semantic representation is used. This suggests the MCMI instance selection strategy
we employed in the scene level iterations is very eﬀective. On the other hand,
the random sampling methods MLR and SLR produce very poor performance.
Another interesting observation is that at the start of active learning, though
we only have very few labeled instance available for each category, the accuracy
of our latent object-based hierarchical scene classiﬁcation model already reaches
around 12% on 15-category MIT indoor scene subset and reaches around 34%
on Natural scene dataset. This demonstrates the mid-level representation is very
descriptive and useful for abstractive scene classiﬁcation. By comparing the two
versions of results across columns, we can see that with hybrid features, the
proposed MLA produces slightly better results, which suggests that low-level
features and mid-level representation features can complement each other.
Multi-level Adaptive Active Learning for Scene Classiﬁcation
MIT Indoor
Number of Iterations
Entropy of the system
MIT Indoor (Hybrid)
Number of Iterations
Entropy of the system
Natural Scene
Number of Iterations
Entropy of the system
Natural Scene (Hybrid)
Number of Iterations
Entropy of the system
Fig. 4: The entropy reduction results on both MIT Indoor Scene dataset and
Natural Scene dataset.
In addition to scene classiﬁcation accuracy, we have also measured the performance of the comparison methods in terms of system entropy (i.e., data set
entropy). We recorded the reduction of the system entropy with the increasing
number of labeled instances. The ALOA method from uses a Latent SVM
model, the system entropy of which is contributed by both the image classiﬁer
and the model’s inner attribute classiﬁers. However, the entropies of all other
methods are only associated with the target image label predictions, which makes
the computed entropy of ALOA and others not comparable. Therefore, we only
consider the other four methods in this experimental setting. The results are
reported in Figure 4. It is easy to see that the proposed MLA method reduces
the entropy much quickly than other baselines, which veriﬁes the eﬀectiveness of
our proposed adaptive active learning strategy. The curve of MLA is monotone
decreasing, indicating that every query is helpful in terms of entropy reduction.
The curves of the other baselines nevertheless have ﬂuctuations. Among them,
SLA is almost always the runner-up except on the MIT indoor dataset with hybrid features. By comparing the two versions of results across columns, we can
see the system entropy with hybrid features is relatively lower than its counterpart with mid-level semantic representation alone, which again suggests that the
low-level features can provide augmenting information for the mid-level semantic
representations.
X. Li and Y. Guo
Natural Scene
scene class index
Number of Instances
9 10 11 12 13 14 15
MIT Indoor
scene class index
Number of Instances
Fig. 5: Distribution of queried instances in scene label space for the proposed
approach on MIT Indoor and Natural Scene datasets.
Finally, we collected the number of queries in each scene category on the two
datasets for the proposed approach and presented the results in Figure 5. We
can see, obviously the instances are not selected according to a uniform distribution across categories. The total numbers of scene level label queries among
the 100 iterations are 65 and 80 on the MIT Indoor and Natural scene datasets
respectively. The remaining querying eﬀort is on the object-level annotations.
On the MIT indoor dataset, the ratio between the numbers of queries on scene
labels and object annotations is about 2 : 1. In contrast, this ratio is 4 : 1 on the
Natural scene dataset. This observation indicates that our model can adaptively
switch query levels based on the complexity of the data. When the object layout
is easy, it will put more eﬀort on querying scene labels; when the scene becomes
complicated and ambiguous, it will ask more questions about object annotations.
Conclusions
In this paper, we developed a novel multi-level active learning approach to reduce
the human annotation eﬀort for training semantic scene classiﬁcation models.
Our idea was motivated by the facts that latent object-based semantic representations of images are very useful for scene classiﬁcation, and the scene labels
are diﬃcult to distinguish from each other in many scenarios. We hence built
a semantic framework that learns scene classiﬁers based on latent object-based
semantic representations of images, and then proposed to perform active learning with two diﬀerent types of iterations, the scene level iteration (abstractive
high level) and the latent object level iteration (semantic middle level). We employed an adaptive strategy to automatically perform switching between these
two types active learning iterations. We conducted experiments on two standard
scene classiﬁcation datasets, the MIT Indoor scene dataset and the Natural
Scene dataset, to investigate the eﬃcacy of the proposed approach. Our empirical results showed the proposed adaptive multi-level active learning approach
can outperform both traditional baseline single level active learning methods
and the state-of-the-art multi-level active learning method.
Multi-level Adaptive Active Learning for Scene Classiﬁcation