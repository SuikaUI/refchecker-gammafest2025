Spatially Encoding Temporal Correlations to Classify
Temporal Data Using Convolutional Neural Networks $
Zhiguang Wanga,∗, Tim Oatesa
aDepartment of Computer Science and Electric Engineering, University of Maryland
Baltimore County, Baltimore, 21228 Maryland, United States
We propose an oﬀ-line approach to explicitly encode temporal patterns spatially as diﬀerent types of images, namely, Gramian Angular Fields and Markov
Transition Fields. This enables the use of techniques from computer vision for
feature learning and classiﬁcation. We used Tiled Convolutional Neural Networks to learn high-level features from individual GAF, MTF, and GAF-MTF
images on 12 benchmark time series datasets and two real spatial-temporal trajectory datasets. The classiﬁcation results of our approach are competitive with
state-of-the-art approaches on both types of data. An analysis of the features
and weights learned by the CNNs explains why the approach works.
Time-series, Trajectory, Classiﬁcation, Gramian Angular Field,
Markov Transition Field, Convolutional Neural Networks
1. Introduction
The problem of temporal data classiﬁcation has attracted great interest recently, ﬁnding applications in domains as diverse as medicine, ﬁnance, entertainment, and industry. However, learning the complicated temporal correlations
in complex dynamic systems is still a challenging problem. Inspired by recent
successes of deep learning in computer vision, we consider the problem of en-
$Preliminary versions of parts of this paper appear in the Twenty-Ninth AAAI workshop
proceedings on Trajectory-based Behaviour Analytics.
∗Corresponding author.
Email address: (Zhiguang Wang)
 
September 25, 2015
 
coding temporal information spatially as images to allow machines to ”visually”
recognize and classify temporal data, especially time series data.
Recognition tasks in speech and audio have been well studied. Researchers
have achieved success using combinations of HMMs with acoustic models based
on Gaussian Mixture models (GMMs) . An alternative approach is to use
deep neural networks to produce posterior probabilities over HMM states. Deep
learning has become increasingly popular since the introduction of eﬀective ways
to train multiple hidden layers and has been proposed as a replacement for
GMMs to model acoustic data in speech recognition tasks .
These Deep
Neural Network - Hidden Markov Model hybrid systems (DNN-HMM) achieved
remarkable performance in a variety of speech recognition tasks . Such
success stems from learning distributed representations via deeply layered structure and unsupervised pretraining by stacking single layer Restricted Boltzmann
Machines (RBM).
Another deep learning architecture used in computer vision is convolutional
neural networks (CNNs) . CNNs exploit translational invariance within their
structures by extracting features through receptive ﬁelds and learn with
weight sharing. CNNs are the state-of-the-art approach in various image recognition and computer vision tasks . Since unsupervised pretraining
has been shown to improve performance , sparse coding and Topographic
Independent Component Analysis (TICA) are integrated as unsupervised pretraining approaches to learn more diverse features with complex invariances
CNNs were proposed for speech processing because of their invariance to
shifts in time and frequency . Recently, CNNs have been shown to further
improve hybrid model performance by applying convolution and max-pooling in
the frequency domain on the TIMIT phone recognition task . A heterogeneous pooling approach proved to be beneﬁcial for training acoustic invariance
 . Further exploration with limited weight sharing and a weighted softmax
pooling layer has been proposed to optimize CNN structures for speech recognition tasks .
However, except for audio and speech data, relatively little work has explored feature learning in the context of typical time series analysis tasks with
current deep learning architectures. explores supervised feature learning
with CNNs to classify multi-channel time series with two datasets. They extracted subsequences with sliding windows and compared their results to Dynamic Time Warping (DTW) with a 1-Nearest-Neighbor classiﬁer (1NN-DTW).
Our motivation is to explore a novel framework to encode time series as images
and thus to take advantage of the success of deep learning architectures in computer vision to learn features and identify structure in time series. Unlike speech
recognition systems in which acoustic/speech data input is typically represented
by concatenating Mel-frequency cepstral coeﬃcients (MFCCs) or perceptual linear predictive coeﬃcient (PLPs) , typical time series data are not likely to
beneﬁt from transformations applied to speech or acoustic data.
In this work, we propose two types of representations for explicitly encoding
the temporal patterns in time series as images. We test our approach on twelve
time series datasets produced from 2D shape, physiological surveillance, industry and other domains. Two real spatial-temporal trajectory datasets are also
considered for experiments to demonstrate the performance of our approach.
We applied deep Convolutional Neural Networks with a pretraining stage that
exploits local orthogonality by Topographic ICA to “visually” inspect and
classify time series. We report our classiﬁcation performance both on GAF and
MTF separately, and GAF-MTF which resulted from combining GAF and MTF
representations into single image. By comparing our results with the current
best hand-crafted representation and classiﬁcation methods on both time series
and trajectory data, we show that our approach in practice achieves competitive
performance with the state of the art with only cursory exploration of hyperparameters. In addition to exploring the high level features learned by Tiled
CNNs, we provide an in-depth analysis in terms of the duality between time
series and images. This helps us to more precisely identify the reasons why our
approaches work well.
2. Motivation
Learning the (long) temporal correlations that are often embedded in time
series remains a major challenge in time series analysis and modeling. Most realworld data has a temporal component, whether it is measurements of natural
(weather, sound) or man-made (stock market, robotics) phenomena.
Traditional approaches for modeling and representing time-series data fall into three
categories. In time series learning problems, non-data adaptive models, such
as Discrete Fourier Transformation (DFT) , Discrete Wavelet Transformation (DWT) , and Discrete Cosine Transformation (DCT) , compute the
transformation with an algorithm that is invariant with respect to the data
to capture the intrinsic temporal correlation with the diﬀerent basis functions.
Meanwhile, researchers explored in the model-based approaches to model time
series, such as Auto-Regressive Moving Average models (ARMA) and Hidden Markov Models (HMMs) , in which the underlying data is assumed to
ﬁt a speciﬁc type of model to explicitly function the temporal patterns. The estimated parameters can then be used as features for classiﬁcation or regression.
However, more complex, high-dimensional, and noisy real-world time-series data
are often diﬃcult to model because the dynamics are either too complex or unknown. Traditional methods, which contain a small number of non-linear operations, might not have the capacity to accurately model such complex systems.
If implicitly learning the complex temporal correlation is diﬃcult, how about
reformulating the data to explicitly or even visually encode the temporal dependency, allowing the algorithms to learn more easily? Actually, reformulating
the features of time series as visual clues has raised much attention in computer science and physics. The typical examples in speech recognition tasks are
that acoustic/speech data input is typically represented by MFCCs or PLPs
to explicitly represent the temporal and frequency information. Recently, researchers are trying to build diﬀerent network structures from time series for
visual inspection or designing distance measures. Recurrence Networks were
proposed to analyze the structural properties of time series from complex sys-
tems . They build adjacency matrices from the predeﬁned recurrence
functions to interpret the time series as complex networks. Silva et al. extended
the recurrence plot paradigm for time series classiﬁcation using compression
distance . Another way to build a weighted adjacency matrix is extracting
transition dynamics from the ﬁrst order Markov matrix . Although these
maps demonstrate distinct topological properties among diﬀerent time series,
it remains unclear how these topological properties relate to the original time
series since they have no exact inverse operations. One of our contributions is to
propose a set of oﬀ-line algorithm to encode the complex correlations in time series into images for visual inspection and classiﬁcation. The proposed encoding
functions have exact/approximate inverse maps, making such transformations
more interpretable.
3. Encoding Methods
We ﬁrst introduce our two frameworks to encode time series data as images. The ﬁrst type of image is the Gramian Angular ﬁeld (GAF), in which we
represent time series in a polar coordinate system instead of the typical Cartesian coordinates. In the Gramian matrix, each element is actually the cosine
of the summation of pairwise temporal values. Inspired by previous work on
the duality between time series and complex networks , the main idea of the
second framework, the Markov Transition Field (MTF), is to build the Markov
matrix of quantile bins after discretization and encode the dynamic transition
probability in a quasi-Gramian matrix.
3.1. Gramian Angular Field
Given a time series X = {x1, x2, ..., xn} of n real-valued observations, we
rescale X so that all values fall in the interval [−1, 1] or by:
−1 = (xi−max(X)+(xi−min(X))
max(X)−min(X)
max(X)−min(X)
Thus we can represent the rescaled time series ˜X in polar coordinates by encoding the value as the angular cosine and the time stamp as the radius with
the equations below:
φ = arccos ( ˜xi), −1 ≤˜xi ≤1, ˜xi ∈˜X
ti is the time stamp and N is a constant factor to regularize the span of
the polar coordinate system. This polar coordinate based representation is a
novel way to understand time series. As time increases, corresponding values
warp among diﬀerent angular points on the spanning circles, like water rippling.
The encoding map of Eq. 3 has two important properties. First, it is bijective
as cos(φ) is monotonic when φ ∈[0, π].
Given a time series, the proposed
map produces one and only one result in the polar coordinate system with a
unique inverse function. Second, as opposed to Cartesian coordinates, polar
coordinates preserve absolute temporal relations. In Cartesian coordinates, the
area is deﬁned by Si,j =
x(i) f(x(t))dx(t), we have Si,i+k = Sj,j+k if f(x(t))
has the same values on [i, i + k] and [j, j + k]. However, in polar coordinates, if
the area is deﬁned as S′
φ(i) r[φ(t)]2d(φ(t)), then S′
i,i+k ̸= S′
j,j+k. That is,
the corresponding area from time stamp i to time stamp j is not only dependent
on the time interval |i −j|, but also determined by the absolute value of i and
After transforming the rescaled time series into the polar coordinate system,
we can easily exploit the angular perspective by considering the trigonometric
sum between each pair of points to identify the temporal correlation in diﬀerent
time intervals. The GAF is deﬁned as follows:
cos(φ1 + φ1)
cos(φ1 + φn)
cos(φ2 + φ1)
cos(φ2 + φn)
cos(φn + φ1)
cos(φn + φn)
˜X′ · ˜X −
I is the unit row vector [1, 1, ..., 1]. After transforming to the polar coordinate
system, we take the data in a time series as a 1-D metric space. By deﬁning the
inner product < x, y >= x · y −
1 −y2, G is a Gramian matrix:
< ˜x1, ˜x1 >
< ˜x2, ˜x1 >
GAF has several advantages. It provides a way to preserve temporal dependency. When time increases, the position moves from top-left to bottom-right in
the Gramian matrix. The GAF contains temporal correlations, as G(i,j||i−j|=k)
represents the relative correlation by superposition of directions with respect
to time interval k.
The main diagonal Gi,i is the special case when k = 0,
which contains the original value/angular information. With the main diagonal,
we will approximately reconstruct the time series from the high level features
learned by the deep neural network. The GAF images may be large because
the size of the Gramian matrix is n × n when the length of the raw time series
To reduce the size of the GAF images, we apply Piecewise Aggregate
Approximation to smooth the time series while keeping the overall trends.
The full procedure for generating the GAF is illustrated in Figure 1.
Through the polar coordinate system, GAFs actually represent the mutual
correlations between each pair of points/phases by the superposition of the
nonlinear cosine functions.
Diﬀerent types of time series always have their
speciﬁc patterns embedded along the time and frequency dimensions. After the
feature reformulation process by GAF, most diﬀerent patterns are enhanced
even for visual inspection by humans (Figure 2).
3.2. Markov Transition Field
We propose a framework that is similar to for encoding dynamical transition statistics. We develop that idea by representing the Markov transition
probabilities sequentially to preserve information in the temporal dimension.
Time Series 𝑋
Gramian Angular Field
Polar Coordinate
Figure 1: Illustration of the proposed encoding map of the Gramian Angular Field. X is a
sequence of typical time series in ’SwedishLeaf’ dataset. After X is rescaled by Equation. (??)
and optionally smoothed by PAA , we transform it to a polar coordinate system by Equation.
(3) and ﬁnally calculate its GAF image with Equation. (5). In this example, we build GAF
without PAA smoothing, so the GAF has a high resolution of 128 × 128.
Given a time series X, we identify its Q quantile bins and assign each xi to its
corresponding bin qj (j ∈[1, Q]). Thus we construct a Q×Q weighted adjacency
matrix W by counting transitions among quantile bins in the manner of a ﬁrstorder Markov chain along the time axis. wi,j is the frequency with which a
point in quantile qj is followed by a point in quantile qi. After normalization by
j wij = 1, W is the Markov transition matrix:
v11|P (xt∈q1|xt−1∈q1)
v1Q|P (xt∈q1|xt−1∈qQ)
v21|P (xt∈q2|xt−1∈q1)
v2Q|P (xt∈q2|xt−1∈qQ)
vQ1|P (xt∈qQ|xt−1∈q1)
vQQ|P (xt∈qQ|xt−1∈qQ)
It is insensitive to the distribution of X and the temporal dependency on
the time steps ti. However, getting rid of the temporal dependency results in
too much information loss in the matrix W. To overcome this drawback, we
Examples of GAF images on the ’Coﬀee’, ’Gun-Point’, ’Adiac’ and ’50Words’
deﬁne the Markov Transition Field (MTF) as follows:
vij|x1∈qi,x1∈qj
vij|x1∈qi,xn∈qj
vij|x2∈qi,x1∈qj
vij|x2∈qi,xn∈qj
vij|xn∈qi,x1∈qj
vij|xn∈qi,xn∈qj
We build a Q × Q Markov transition matrix W by dividing the data (magnitude) into Q quantile bins. The quantile bins that contain the data at time
steps i and j (temporal axis) are qi and qj (q ∈[1, Q]). Mij in MTF denotes
the transition probability of qi →qj. That is, we spread out matrix W, which
contains the transition probability on the magnitude axis, into the MTF matrix
by considering temporal positions.
By assigning the probability from the quantile at time step i to the quantile at time step j at each pixel Mij, the MTF M actually encodes multi-step
transition probabilities of the time series. Mi,j||i−j|=k denotes the transition
probability between the points with time interval k. For example, Mij|j−i=1
illustrates the transition process along the time axis with a skip step. The main
diagonal Mii, which is a special case when k = 0 captures the probability from
Typical Time Series
Markov Transition Matrx
Markov Transition Field
Figure 3: Illustration of the proposed encoding map of a Markov Transition Field. X is a
sequence of the typical time series in the ’ECG’ dataset. X is ﬁrst discretized into Q quantile
bins. Then we calculate its Markov Transition Matrix W and ﬁnally build its MTF M by
Equation. (8). We reduce the image size from 96 × 96 to 48 × 48 by averaging the pixels in
each non-overlapping 2 × 2 patch.
each quantile to itself (the self-transition probability) at time step i. To make
the image size manageable for more eﬃcient computation, we reduce the MTF
by averaging the pixels in each non-overlapping m × m patch with the blurring
kernel { 1
That is, we aggregate the transition probabilities in each
subsequence of length m together. Figure 3 shows the procedure to encode time
series to MTF.
By scattering the ﬁrst-order transition probability into the temporally ordered matrix, MTFs encode the transition dynamics between diﬀerent time lags
k. We assume that diﬀerent types of time series have their speciﬁc transition
dynamics embedded in the temporal and frequency domains. After the feature
reformulation process by MTF, most transition dynamics are extracted, which
are explicitly obvious for visual inspection (Figure 4).
Figure 4: Examples of MTF images on the ’OSUleaf’, ’ﬁsh’, ’ECG’ and ’Faceall’ datasets.
4. Tiled Convolutional Neural Networks
Tiled Convolutional Neural Networks are a variation of Convolutional
Neural Networks. They use tiles and multiple feature maps to learn invariant
features. Tiles are parameterized by a tile size K to control the distance over
which weights are shared. By producing multiple feature maps, Tiled CNNs
learn overcomplete representations through unsupervised pretraining with Topographic ICA (TICA).
A typical TICA network is actually a double-stage optimization procedure
with square and square root nonlinearities in each stage, respectively. In the
ﬁrst stage, the weight matrix W is learned while the matrix V is hard-coded to
represent the topographic structure of units. More precisely, given a sequence of
inputs {xh}, the activation of each unit in the second stage is fi(x(h); W, V ) =
k=1 Vik(Pq
j=1 Wkjx(h)
)2. TICA learns the weight matrix W in the second
stage by solving:
fi(x(h); W, V )
subject to
W ∈Rp×q and V ∈Rp×p where p is the number of hidden units in a layer
Algorithm 1 Unsupervised pretraining with TICA 
Require: {x(t)}T
t=1, v, s, W, V as input
Ensure: W as output
f old = PT
k=1 Vik(Pn
j=1 Wkjx(t)
j )2, g = f old
∂W , f new = +∞,
while f new > f old do
W new = W −αg
W new = Localize(W new, s)
W new = tieWeights(W new, k)
W new = orthogonalizeLocalRF(W new)
W new = tieWeights(W new, k)
f new = PT
k=1 Vik(Pn
j=1 Wkjx(t)
until convergence
and q is the size of the input. V is a logical matrix (Vij = 1 or 0) that encodes
the topographic structure of the hidden units by a contiguous 3 × 3 block. The
orthogonality constraint WW T = I provides diversity among learned features.
The pretraining algorithm (Algorithm. 1) is based on gradient descent on
the TICA objective function in Equation. 9. The inner loop is a simple implementation of backtracking linesearch. The orthogonalize localRF(W new)
function only orthogonalizes the weights that have completely overlapping receptive ﬁelds. Weight-tying is applied by averaging each set of tied weights.
The algorithm is trained by batch projected gradient descent. Other unsupervised feature learning algorithms such as RBMs and autoencoders require
more parameter tuning, especially during optimization. However, pretraining
with TICA usually requires little tuning of optimization parameters, because
the tractable objective function of TICA allows to monitor convergence easily.
Feature maps 𝑙= 6
Convolutional I
TICA Pooling I
Convolutional II TICA Pooling II
Linear SVM
Receptive Field 8 × 8
Receptive Field 3 × 3
Untied weights 𝑘= 2
Pooling Size 3 × 3
Pooling Size 3 × 3
Figure 5: Structure of the tiled convolutional neural network. We ﬁx the size of receptive
ﬁelds to 8 × 8 in the ﬁrst convolutional layer and 3 × 3 in the second convolutional layer.
Each TICA pooling layer pools over a block of 3 × 3 input units in the previous layer without
wraparound at the boarders to optimize for sparsity of the pooling units. The number of
pooling units in each map is exactly the same as the number of input units. The last layer is
a linear SVM for classiﬁcation. We construct this network by stacking two Tiled CNNs, each
with 6 maps (l = 6) and tiling size k = 2.
Neither GAF nor MTF images are natural images; they have no natural
concepts such as “edges” and “angles”. Thus, we propose to exploit the beneﬁts
of unsupervised pretraining with TICA to learn many diverse features with local
orthogonality. In , the authors empirically demonstrate that tiled CNNs
perform well with limited labeled data because the partial weight tying requires
fewer parameters and reduces the need for a large amount of labeled data. Our
data from the UCR Time Series Repository tends to have few instances
(e.g., the “yoga” dataset has 300 labeled instance in the training set and 3000
unlabeled instance in the test set), so tiled CNNs are suitable for our learning
task. Moreover, Tiled CNNs achieve good performance on large datasets (such
as NORB and CIFAR).
Typically, tiled CNNs are trained with two hyperparameters, the tiling size
k and the number of feature maps l.
In our experiments, we directly ﬁxed
Table 1: Summary statistics of 12 standard datasets
Lightning2
Lightning7
SwedishLeaf
the network structures without tuning these hyperparameters in loops.
experimental settings follow the default deep network structures and parameters in . Tiled CNNs with such conﬁgurations are reported to achieve the
best performance on the NORB image classiﬁcation benchmark. Although tuning the parameters will surely enhance performance, doing so may cloud our
understanding of the power of the representation.
Another consideration is
computational eﬃciency. All of the experiments on the 12 datasets could be
done in one day on a laptop with an Intel i7-3630QM CPU and 8GB of memory
(our experimental platform). Thus, the results in this paper are a preliminary
lower bound on the potential best performance. Thoroughly exploring network
structures and parameters will be addressed in future work. The structure and
parameters of the tiled CNN used in this paper are illustrated in Figure 5.
5. Experiments on Time Series Data
We apply Tiled CNNs to classify using GAF and MTF representation on
twelve tough datasets, on which the classiﬁcation error rate is above 0.1 with
the state-of-the-art SAX-BoP approach . More detailed statistics are
summarized in Table 1. The datasets are pre-split into training and testing sets
for experimental comparisons. For each dataset, the table gives its name, the
number of classes, the number of training and test instances, and the length of
the individual time series.
5.1. Experiment Settings
In our experiments, the size of the GAF image is regulated by the the number
of PAA bins SGAF . Given a time series X of size n, we divide the time series
into SGAF adjacent, non-overlapping windows along the time axis and extract
the means of each bin. This enables us to construct the smaller GAF matrix
GSGAF ×SGAF . MTF requires the time series to be discretized into Q quantile
bins to calculate the Q × Q Markov transition matrix, from which we construct
the raw MTF image Mn×n afterwards.
Before classiﬁcation, we shrink the
MTF image size to SMT F × SMT F by the blurring kernel { 1
m2 }m×m where
SMT F ⌉. The Tiled CNN is trained with image size {SGAF , SMT F } ∈
{16, 24, 32, 40, 48} and quantile size Q ∈{8, 16, 32, 64}. At the last layer of the
Tiled CNN, we use a linear soft margin SVM and select C by 5-fold cross
validation over {10−4, 10−3, . . . , 104} on the training set.
For each input of image size SGAF or SMT F and quantile size Q, we pretrain
the Tiled CNN with the full unlabeled dataset (both training and test set with no
labels) to learn the initial weights W through TICA.Then we train the SVM at
the last layer by selecting the penalty factor C with cross validation. Finally, we
classify the test set using the optimal hyperparameters {S, Q, C} with the lowest
error rate on the training set. If two or more models tie, we prefer the larger
S and Q because larger S helps preserve more information through the PAA
procedure and larger Q encodes the dynamic transition statistics with more
Table 2: Tiled CNN error rate on training set and test set
SwedishLeaf
Our model selection approach provides generalization without being
overly expensive computationally.
5.2. Results and Discussion
We use Tiled CNNs to classify GAF and MTF representations separately
on the 12 datasets. The training and test error rates are shown in Table 2.
Generally, our approach is not prone to overﬁtting as seen by the relatively
small diﬀerence between training and test set errors.
One exception is the
’Olive Oil’ dataset with the MTF approach where the test error is signiﬁcantly
In addition to the slight risk of potential overﬁtting, MTF has generally
higher error rates than GAF. This is most likely because of uncertainty in the
inverse image of MTF. Note that the encoding function from time series to GAF
and MTF are both surjection. The map functions of GAF and MTF will each
produce only one image with ﬁxed S and Q for each given time series X. Because
they are both surjective mapping functions, the inverse image of the map is not
ﬁxed. As shown in a later section, we can approximately reconstruct the raw
time series from GAF, but it is very hard to even roughly recover the signal from
MTF. GAF has smaller uncertainty in the inverse image of its mapping function
because randomness only comes from the ambiguity of cos(φ) when φ ∈[0, 2π].
MTF, on the other hand, has a much larger inverse image space, which results in
large variation when we try to recover the signals. Although MTF encodes the
transition dynamics, which are important features of time series, such features
seem not to be suﬃcient for recognition/classiﬁcation tasks.
Note that at each pixel, Gij, denotes the superstition of the directions at ti
and tj, Mij is the transition probability from the quantile at ti to the quantile
at tj. GAF encodes static information while MTF depicts information about
From this point of view, we consider them as two “orthogonal”
channels, like diﬀerent colors in the RGB image space. Thus, we can combine
GAF and MTF images of the same size (i.e. SGAF = SMT F ) to construct a
double-channel image (GAF-MTF). Since GAF-MTF combines both the static
and dynamic statistics embedded in raw time series, we posit that it will improve
classiﬁcation performance.
In the next experiment, we pretrained and ﬁnetuned the Tiled CNN on the compound GAF-MTF images. Then, we report
the classiﬁcation error rate on test sets.
Table 3 compares the classiﬁcation error rate of our approach with previously
published results of ﬁve competing methods: two state-of-the-art 1NN classiﬁers
based on Euclidean distance and DTW, the recently proposed Fast-Shapelets
based classiﬁer , the classiﬁer based on Bag-of-Patterns (BoP) and
the most recent SAX-VSM approach .
Our approach outperforms 1NN-
Euclidean, fast-shapelets, and BoP, and is competitive with 1NN-DTW and
In addition, by comparing the results between Table 3 and Table 2, we veriﬁed our assumption that combined GAF-MTF images have better expressive
power than the single GAF or MTF alone for classiﬁcation. GAF-MTF images achieves the lower test error rate on ten datasets out of twelve (except
Table 3: Summary of the error rates from 6 recently published best results and our approach.
The symbols ∗, ◁, † and • represent datasets generated from ﬁgure shapes (2D), physiological
surveillance, industry and all remaining temporal signals, respectively.
Lightning2 †
Lightning7 †
OliveOil •
SwedishLeaf ∗
for the ’Adiac’ and ’Beef’ dataset ). On the ’Olive Oil’ dataset, the training
error rate is 6.67% and the test error rate is 16.67%. This demonstrates that
the integration of both types of images into one compound image decreases the
risk of overﬁtting as well as enhancing the overall classiﬁcation accuracy. Thus,
the intrinsic ”orthogonality” between GAF and MTF on the same time series
helps improve the classiﬁcation performance with more comprehensive features.
The multi-channel encoding approach is a scalable framework. The combination
of multiple orthogonal channels into one images potentially improve the classiﬁcation results, decreasing the risk of overﬁtting by a generalized ensemble
framework. Meanwhile, hand-crafted feature integration potentially helps learn
diﬀerent informative features through deep learning architectures.
Figure 6: (a) Original GAF and its six learned feature maps before the SVM layer in Tiled
CNN (top left), and (b) raw time series and approximate reconstructions based on the main
diagonal of six feature maps (top right) on ’50Words’ dataset; (c) Original MTF and its six
learned feature maps before the SVM layer in Tiled CNN (bottom left), and (d) curve of
self-transition probability along time axis (main diagonal of MTF) and approximate reconstructions based on the main diagonal of six feature maps (bottom right) on ”SwedishLeaf”
5.3. Analysis of Learned Features
In contrast to the cases in which the CNN is applied in natural image recognition tasks, neither GAF nor MTF have natural interpretations of visual concepts
(e.g., ”edges” or “angles”). In this section, we analyze the features and weights
learned through the Tiled CNNs to explain why our approach works.
As mentioned earlier, the mapping function from time series to GAF is
surjective and the uncertainty in its inverse image comes from the ambiguity of
cos(φ) when φ ∈[0, 2π]. The main diagonal of GAF, i.e. {Gii} = {cos(2φi)}
allows us to approximately reconstruct the original time series, ignoring the
cos(2φ) + 1
MTF has much larger uncertainty in its inverse image, making it hard to
reconstruct the raw data from MTF alone. However, the diagonal {Mij||i−j|=k}
represents the transition probability among the quantiles in temporal order considering the time interval k. We construct the self-transition probability along
the time axis from the main diagonal of MTF like we do for GAF. Although
such reconstructions less accurately capture the morphology of the raw time series, they provide another perspective of how Tiled CNNs capture the transition
dynamics embedded in MTF.
Figure 6 illustrates the reconstruction results from six feature maps learned
before the last SVM layer on the GAF and MTF. The Tiled CNN extracts
the color patch, which is essentially an adaptive moving average that enhances
several receptive ﬁelds within the nonlinear units by diﬀerent trained weights. It
is not a simple moving average but the synthetic integration by considering the
2D temporal dependencies among diﬀerent time intervals, which is a beneﬁt from
the Gramian matrix structure that helps preserve the temporal information. By
observing the rough orthogonal reconstruction from each layer of the feature
maps, we can clearly observe that the CNNs can extract the multi-frequency
dependencies through the convolution and pooling architecture on the GAF and
MTF images. Diﬀerent feature maps preserve the overall trend while addressing
more details in diﬀerent subphases. As shown in Figures 6(b) and 6(d), the
high-leveled feature maps learned by the Tiled CNN are equivalent to a multifrequency approximator of the original curve.
Figure 7 demonstrates the learned sparse weight matrix W with the constraint WW T = I, which makes eﬀective use of local orthogonality. The TICA
pretraining provides the built-in advantage that the function w.r.t the parameter space is not likely to be ill-conditioned as WW T = 1. As shown in Figure
7 (right), the weight matrix W is quasi-orthogonal and approaching 0 without
very large magnitude. This implies that the condition number of W approaches
1 and helps the system to be well-conditioned.
learned sparse weights W for the last SVM layer in Tiled CNN (left) and its
orthogonality constraint by WW T = I (right).
6. Experiments on Trajectory Data
We have demonstrated the eﬀectiveness of GAF and MTF the benchmark
time series datasets as diverse as shape, physiological surveillance and industry
from the UCR time series repository. In this section we describe an application
of our approaches to classify spatial-temporal trajectory data. The trajectory
data is complex because patterns of movement are often driven by unperceived
goals and constrained by an unknown environment.
To compare our results with other benchmark approaches including the seminal work from , we run experiments on two benchmark datasets, the animal
movement dataset (Animal) and the hurricane track dataset (Hurricane) (Figure 8). Both datasets have trajectories of unequal length. For the ”Animal”
dataset, the x and y coordinates are extracted from animal movements observed
in June 1995. It is divided into three classes by species: elk, deer, and cattle,
as shown in Figure 15. The numbers of trajectories (points) are 38 (7117), 30
(4333), and 34 (3540), respectively. In the ”Hurricane” dataset, the latitude
and longitude are extracted from Atlantic hurricanes for the years 1950 through
Gulf of Mexico
Red: Category 2 Blue: Category 3
Stronger hurricanes tend to
go further than weaker ones
Red: Elk Blue: Deer Black: Cattle
Figure 8: Overview of the trajectory and the RB-TB features learnt in (a).
tracking data (left) and (b). Hurricane data (right)
2006. The Saﬃr-Simpson scale classiﬁes hurricanes into categories 1-5 by intensity. A high category number indicates high intensity. Categories 2 and 3 are
chosen for two classes. The numbers of trajectories (points) are 61 (2459) and
72 (3126), respectively. Both datasets are pre-split into two parts for training
(80%) and testing (20%). Figure 8 shows the overview of the trajectory data.
Table 4 provides the classes, training size, testing size, minimum length and
maximum length of the trajectory data.
6.1. Hilbert Space Filling Curves
Spatial-temporal trajectory data is commonly multi-dimensional. We use
Hilbert Space Filling Curves (SFC) to transform the trajectory into time series
while preserving the spatial-temporal information.
Space ﬁlling has been studied by the mathematicians since the late 19th
century when the ﬁrst graphical representation was proposed by David Hilbert
Table 4: Summary statistics of two trajectory datasets.
Animal Tracking
Figure 9: (a). Hilbert space ﬁlling curve of order {1,2,3,4,5,6} in 2-dimensional space (left)
(b). An example of the transformation from 2-dimensional trajectory to 1-dimensional time
series using HSCF of order 2 (right).
in 1891 .
Space ﬁlling curves provide a linear mapping from the multidimensional space to the 1-dimensional space. This mapping can be thought
of as dividing D-dimensional space into D-dimensional hypercubes with a line
passing through each hypercube. Recently, ﬁlling curve based approaches have
shown to be able to preserve locality between objects in the multidimensional
space in the linear space, and thus have been applied to diﬀerent tasks like
clustering , high dimensional outlier detection , and trajectory query 
and classiﬁcation . Figure 9 (a) shows SFC examples of order {1,2,3,4,5,6}.
Basically, the SFC of order 1 divides the square into 4 area. For the Hilbert
curve with order 2, each sub-area of the curve with order 1 is further divided
into 4 sub-areas. This process goes on as the order of the SFC increases. It
is clear that the number of sub-areas in 2 dimensional SFC is 4order. To convert 2-dimensional data points to 1-dimensional points, each sub-area is integer
numbered from 0 to 4order −1 starting from the lower left corner as 0 to the
lower right corner. All other sub-areas are numbered in order of occurrence
of the corresponding vertex as shown in Figure 9 (b) when order = 2. It also
shows the example transformation process from a 2D trajectory to a sequence of
scalars (time series). The ﬁnal time series generated after SFC transformation
is T = .
We map the trajectory points by the visiting order of the SFC embedded
in the trajectory manifold space to the index sequence by the recorded times.
The produced time series can be used for classiﬁcation using our algorithm.
This adds another hyperparameter called the SFC order, which decides the
granularity of the space ﬁlling curve.
6.2. Experiment Settings
The parameter settings are the same as the previous experiments on UCR
datasets (Section 5). The optimal SFC order is selected together with other
parameters through 5-fold cross validation from {3,4,5,6,7,8,9,10}.
Note that both trajectory datasets have quite small sample size with varying
length. When the trajectory length (as well as the time series length produced
by SFC) is smaller than image size S, we uniformly duplicate each point in
the time series in temporal order to stretch the sequence to length S. If the
diﬀerence between the length of a time series and S is smaller than the original
time series length, the interpolation strategy changes to random duplication
instead of following the temporal order.
6.3. Results and Discussion
Both ’Animal’ and ’Hurricane’ datasets have been used in previous research
 to achieve state-of-the-art classiﬁcation accuracy. Traclass give two algorithms, trajectory-based (TB-only) and region-based + trajectory-based (RB-
TB) approaches based on features used for classiﬁcation on these datastes. They
carefully designed a hierarchy of features by partitioning trajectories and exploring two types of clustering. In , the author used SFC transformation to
linearly map the trajectory data to time series and classiﬁed the sequences based
on symbolic discretization with the multiple normal distribution assumption.
After transforming the 2D trajectory data to time series using SFC, we generate the corresponding GAF and MTF images as shown in Figure 10. However,
we found signiﬁcant overﬁtting with CNNs even using 5-fold cross validation.
This is probably because both the sample size and the time series length of
the trajectory datasets are too small to avoid overﬁtting in neural networks.
(a). GAF of ‘Animal’
(b). GAF of ‘Hurricane’
(d). MTF of ‘Hurricane’
(c). MTF of ‘Animal’
Figure 10: Examples of GAF and MTF images generated from the time series on ’Animal’
and ’Hurricane’ datasets. The time series is produced using SFC from raw 2D trajectory.
Previous work has discussed overﬁtting during cross validation and proposed
potential techniques to address this problem . Here, we applied a simple and straight-forward hyperparameter selection approach to reduce classiﬁer
variance. For a given set of hyperparameter {S, Q, SFCorder}, after cross validation with diﬀerent C values of the linear SVM, we compute the mean and
standard deviation to get the 3σ lower bound over all C by
score3σ = mean(Accuracy) −3 × STD(Accuracy)
By selecting the other hyperparameters {S, Q, SFC −order} with the best
statistical lower bound on the classiﬁer performance over C, the optimal hyperparameters have lower variance while preserving lower bias. Using this hyperparameter selection approach, the classiﬁcation results are reported in Table
We perform better than the TB-Only method on both datasets and almost
as good as the RB-TB method on the ’Hurricane’ dataset. However, both RB-
Table 5: Classiﬁcation accuracy for TB-Only, RB-TB methods, multiple normal distribution
based symbolic distance (NDist) and our algorithm (%).
Animal Tracking
TB and NDist methods outperform ours on the ’Animal’ dataset. As shown in
Figure 8, both region and trajectory based features are useful for classiﬁcation.
For the ’Hurricane’ dataset, direction based features are more useful than region
based features. Direction based features are quite easy to capture using our
approach as the GAF is actually calculating the pairwise direction ﬁelds on
each points in the trajectory data.
For the ’Animal’ dataset, region is very
important as shown in Figure 8 (a). Elk, deer and cattle are almost separable
just using location as their regions are clearly located at the left, right top
and right bottom, respectively.
When transforming the trajectory data into
time series using SFC, two close regions might be mapped to diﬀerent sub-areas
with diﬀerent SFC indexes.
When the indexes of two close regions are also
near, this can be handled by CNNs with its capability to capture the small
shifting-invariance features.
However, CNNs are not good at discriminating
similar images with large shifting from each other.
Thus, when the region
information is preserved by the manner of shifting the speciﬁc patterns largely
in the time series produced by SFC, CNNs might have diﬃculty capturing the
region information.
Although our approach does not overtake other benchmark methods on both
trajectory datasets, we provide a more general framework to encode the spatialtemporal patterns for classiﬁcation tasks. Instead of complicated hand-tuned
features, our approach can be applied to a variety of time series and trajectory
data. When the region of the trajectory is not signiﬁcantly important or the
direction feature dominates, our general methods work quite well.
datasets where the volume of time series/trajectory data is big, our deep neural
network based approach will greatly beneﬁt from the large sample size in both
feature learning and classiﬁcation tasks.
7. Conclusions and Future Work
This paper proposed an oﬀ-line approach to spatially encode the temporal patterns for classiﬁcation using convolutional neural networks. We created
a pipeline for converting trajectory and time series data into novel representations, GAF and MTF images, and extracted high-level features from these using
CNNs. The features were subsequently used for classiﬁcation. We demonstrated
that our approach yields competitive results when compared to state-of-the-art
methods by searching a relatively small parameter space. We found that GAF-
MTF multi-channel images are scalable to larger numbers of quasi-orthogonal
features that yield more comprehensive images. Our analysis of high-level features learned from CNNs suggested Tiled CNNs work like multi-frequency moving averages that beneﬁt from the 2D temporal dependency that is preserved
by the Gramian matrix.
Important future work will involve applying our method to massive amounts
of data and searching in a more complete parameter space to solve real world
problems. We are also quite interested in how diﬀerent deep learning architectures perform on the GAF and MTF images generated from large datasets. Another interesting future direction is to model time series through GAF and MTF
images. We aim to apply learned time series models in regression/imputation
and anomaly detection tasks. To extend our methods to the streaming data, we
suppose to design the online learning approach with recurrent network structures to represent, learn and model temporal data in real-time.
References