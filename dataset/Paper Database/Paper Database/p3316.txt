Proceedings of “Internation Conference on Computer Vision”, Kerkyra, Greece, September 1999
vol.I, p.377
Fast Approximate Energy Minimization via Graph Cuts
Yuri Boykov
Olga Veksler
Ramin Zabih
Computer Science Department
Cornell University
Ithaca, NY 14853
In this paper we address the problem of minimizing
a large class of energy functions that occur in early
vision. The major restriction is that the energy function’s smoothness term must only involve pairs of pixels. We propose two algorithms that use graph cuts to
compute a local minimum even when very large moves
are allowed. The ﬁrst move we consider is an α-βswap: for a pair of labels α, β, this move exchanges
the labels between an arbitrary set of pixels labeled α
and another arbitrary set labeled β.
Our ﬁrst algorithm generates a labeling such that there is no swap
move that decreases the energy. The second move we
consider is an α-expansion: for a label α, this move
assigns an arbitrary set of pixels the label α. Our second algorithm, which requires the smoothness term to
be a metric, generates a labeling such that there is no
expansion move that decreases the energy. Moreover,
this solution is within a known factor of the global minimum. We experimentally demonstrate the eﬀectiveness of our approach on image restoration, stereo and
Energy minimization in early vision
Many early vision problems require estimating
some spatially varying quantity (such as intensity or
disparity) from noisy measurements. Such quantities
tend to be piecewise smooth; they vary smoothly at
most points, but change dramatically at object boundaries. Every pixel p ∈P must be assigned a label in
some set L; for motion or stereo, the labels are disparities, while for image restoration they represent intensities. The goal is to ﬁnd a labeling f that assigns each
pixel p ∈P a label fp ∈L, where f is both piecewise
smooth and consistent with the observed data.
These vision problems can be naturally formulated
in terms of energy minimization. In this framework,
one seeks the labeling f that minimizes the energy
Esmooth(f)
Here Esmooth measures the extent to which f is not
piecewise smooth, while Edata measures the disagreement between f and the observed data. Many diﬀerent energy functions have been proposed in the literature. The form of Edata is typically
Edata(f) =
where Dp measures how appropriate a label is for the
pixel p given the observed data. In image restoration,
for example, Dp(fp) is typically (fp −ip)2, where ip is
the observed intensity of the pixel p.
The choice of Esmooth is a critical issue, and
many diﬀerent functions have been proposed.
regularization-based
 , Esmooth makes f smooth everywhere.
leads to poor results at object boundaries.
Energy functions that do not have this problem are
called discontinuity-preserving.
A large number of
discontinuity-preserving energy functions have been
proposed (see for example ). Geman and Geman’s
seminal paper gave a Bayesian interpretation of
many energy functions, and proposed a discontinuitypreserving energy function based on Markov Random
Fields (MRF’s).
The major diﬃculty with energy minimization for
early vision lies in the enormous computational costs.
Typically these energy functions have many local minima (i.e., they are non-convex). Worse still, the space
of possible labelings has dimension |P|, which is many
thousands.
There have been numerous attempts to
design fast algorithms for energy minimization. Simulated annealing was popularized in computer vision by
 , and is widely used since it can optimize an arbitrary energy function. Unfortunately, minimizing an
arbitrary energy function requires exponential time,
and as a consequence simulated annealing is very slow.
In practice, annealing is ineﬃcient partly because at
each step it changes the value of a single pixel.
The energy functions that we consider in this paper arise in a variety of diﬀerent contexts, including
the Bayesian labeling of MRF’s. We allow Dp to be
Proceedings of “Internation Conference on Computer Vision”, Kerkyra, Greece, September 1999
vol.I, p.378
arbitrary, and consider smoothing terms of the form
V{p,q}(fp, fq),
where N is the set of pairs of adjacent pixels. In special cases such energies can be minimized exactly. If
the number of possible labels is |L| = 2 then the exact
solution can be found in polynomial time by computing a minimum cost cut on a certain graph .
L is a ﬁnite 1D set and the interaction potential is
V (fp, fq) = |fp −fq| then the exact minimum can also
be found eﬃciently via graph cuts . In general,
however, the problem is NP-hard .
In this paper we develop algorithms that approximately minimize energy E(f) for an arbitrary ﬁnite
set of labels L under two fairly general classes of interaction potentials V : semi-metric and metric. V is
called a semi-metric on the space of labels L if for
any pair of labels α, β ∈L it satisﬁes two properties:
V (α, β) = V (β, α) ≥0 and V (α, β) = 0 ⇔α = β.
If V also satisﬁes the triangle inequality
V (α, β) ≤V (α, γ) + V (γ, β)
for any α, β, γ in L then V is called a metric. Note
that both semi-metric and metric include important cases of discontinuity-preserving interaction potentials.
For example, the truncated L2 distance
V (α, β) = min(K, ||α −β||) and the Potts interaction
penalty V (α, β) = δ(α ̸= β) are both metrics.
The algorithms described in this paper generalize
the approach that we originally developed for the case
of the Potts model . In particular, we compute a labeling which is a local minimum even when very large
moves are allowed. We begin with an overview of our
energy minimization algorithms, which are based on
graph cuts. Our ﬁrst algorithm, described in section 3,
is based on α-β-swap moves and works for any semimetric V{p,q}’s. Our second algorithm, described in
section 4, is based on more interesting α-expansion
moves but works only for metric V{p,q}’s (i.e., the additional triangle inequality constraint is required). Note
that α-expansion moves produce a solution within a
known factor of the global minimum of E. A proof of
this can be found in .
Energy minimization via graph cuts
The most important property of these methods is
that they produce a local minimum even when large
moves are allowed.
In this section, we discuss the
moves we allow, which are best described in terms of
partitions. We sketch the algorithms and list their basic properties. We then formally introduce the notion
of a graph cut, which is the basis for our methods.
Start with an arbitrary labeling f
Set success := 0
For each pair of labels {α, β} ⊂L
Find ˆf = arg min E(f ′) among f ′ within
one α-β swap of f (see Section 3)
If E( ˆf) < E(f), set f := ˆf
and success := 1
If success = 1 goto 2
Start with an arbitrary labeling f
Set success := 0
For each label α ∈L
Find ˆf = arg min E(f ′) among f ′ within
one α-expansion of f (see Section 4)
If E( ˆf) < E(f), set f := ˆf
and success := 1
If success = 1 goto 2
Figure 1: Our swap move algorithm (top) and expansion move algorithm (bottom).
Partitions and move spaces
Any labeling f can be uniquely represented by a
partition of image pixels P = {Pl | l ∈L} where Pl =
{p ∈P | fp = l} is a subset of pixels assigned label l.
Since there is an obvious one to one correspondence
between labelings f and partitions P, we can use these
notions interchangingly.
Given a pair of labels α, β, a move from a partition
P (labeling f) to a new partition P′ (labeling f ′) is
called an α-β swap if Pl = P′
l for any label l ̸= α, β.
This means that the only diﬀerence between P and P′
is that some pixels that were labeled α in P are now
labeled β in P′, and some pixels that were labeled β
in P are now labeled α in P′.
Given a label α, a move from a partition P (labeling
f) to a new partition P′ (labeling f ′) is called an αexpansion if Pα ⊂P′
l ⊂Pl for any label l ̸= α.
In other words, an α-expansion move allows any set of
image pixels to change their labels to α.
Note that a move which gives an arbitrary label α to
a single pixel is both an α-β swap and an α-expansion.
As a consequence, the standard move space used in
annealing is a special case of our move spaces.
Algorithms and properties
We have developed two energy minimization algorithms, which are shown in ﬁgure 1. The structure of
Proceedings of “Internation Conference on Computer Vision”, Kerkyra, Greece, September 1999
vol.I, p.379
the algorithms is quite similar. We will call a single
execution of steps 3.1–3.2 an iteration, and an execution of steps 2–4 a cycle. In each cycle, the algorithm
performs an iteration for every label (expansion move
algorithm) or for every pair of labels (swap move algorithm), in a certain order that can be ﬁxed or random. A cycle is successful if a strictly better labeling
is found at any iteration. The algorithm stops after
the ﬁrst unsuccessful cycle since no further improvement is possible. Obviously, a cycle in the swap move
algorithm takes |L|2 iterations, and a cycle in the expansion move algorithm takes |L| iterations.
These algorithms have several important properties. First, the algorithms are guaranteed to terminate
in a ﬁnite number of cycles; in fact, under fairly general assumptions we can prove termination in O(|P|)
cycles . However, in the experiments we report in
section 5, the algorithm stops after a few cycles and
most of the improvements occur during the ﬁrst cycle.
Second, once the algorithm has terminated, the energy of the resulting labeling is a local minimum with
respect to a swap or an expansion move. Finally, the
expansion move algorithm produces a labeling f such
that E(f ∗) ≤E(f) ≤2k·E(f ∗) where f ∗is the global
minimum and k = max{V (α,β) : α̸=β}
min{V (α,β) : α̸=β} (see ).
Graph cuts
The key part of each algorithm is step 3.1, where
graph cuts are used to eﬃciently ﬁnd ˆf. Let G = ⟨V, E⟩
be a weighted graph with two distinguished vertices
called the terminals. A cut C ⊂E is a set of edges
such that the terminals are separated in the induced
graph G(C) = ⟨V, E −C⟩. In addition, no proper subset
of C separates the terminals in G(C). The cost of the
cut C, denoted |C|, equals the sum of its edge weights.
The minimum cut problem is to ﬁnd the cut with
smallest cost.
There are many algorithms for this
problem with low-order polynomial complexity ; in
practice they run in near-linear time for our graphs.
Step 3.1 uses a single minimum cut on a graph
whose size is O(|P|). The graph is dynamically updated after each iteration. The details of this minimum cut are quite diﬀerent for the swap move and
the expansion move algorithms, as described in the
next two sections.
Finding the optimal swap move
Given an input labeling f (partition P) and a pair
of labels α, β, we wish to ﬁnd a labeling ˆf that minimizes E over all labelings within one α-β swap of f.
This is the critical step in the algorithm given at the
top of Figure 1. Our technique is based on computing a labeling corresponding to a minimum cut on a
Figure 2: An example of the graph Gαβ for a 1D image.
The set of pixels in the image is Pαβ = Pα ∪Pβ where
Pα = {p, r, s} and Pβ = {q, . . . , w}.
graph Gαβ = ⟨Vαβ, Eαβ⟩. The structure of this graph
is dynamically determined by the current partition P
and by the labels α, β.
This section is organized as follows. First we describe the construction of Gαβ for a given f (or P).
We show that cuts C on Gαβ correspond in a natural
way to labelings f C which are within one α-β swap
move of f. Theorem 1 shows that the cost of a cut
is |C| = E(f C) plus a constant. A corollary from this
theorem states our main result that the desired labeling ˆf equals f C where C is a minimum cut on Gαβ.
The structure of the graph is illustrated in Figure 2.
For legibility, this ﬁgure shows the case of 1D image.
For any image the structure of Gαβ will be as follows.
The set of vertices includes the two terminals α and β,
as well as image pixels p in the sets Pα and Pβ (that
is fp ∈{α, β}). Thus, the set of vertices Vαβ consists
of α, β, and Pαβ = Pα ∪Pβ. Each pixel p ∈Pαβ is
connected to the terminals α and β by edges tα
p, respectively.
For brevity, we will refer to these
edges as t-links (terminal links). Each pair of pixels
{p, q} ⊂Pαβ which are neighbors (i.e. {p, q} ∈N) is
connected by an edge e{p,q} which we will call an n-link
(neighbor link). The set of edges Eαβ thus consists of
p} (the t-links) and S
p,q∈Pαβ e{p,q} (the
n-links). The weights assigned to the edges are
V{p,q}(α, fq)
V{p,q}(β, fq)
V{p,q}(α, β)
Proceedings of “Internation Conference on Computer Vision”, Kerkyra, Greece, September 1999
vol.I, p.380
Any cut C on Gαβ must sever (include) exactly one tlink for any pixel p ∈Pαβ: if neither t-link were in C,
there would be a path between the terminals; while if
both t-links were cut, then a proper subset of C would
be a cut. Thus, any cut leaves each pixel in Pαβ with
exactly one t-link. This deﬁnes a natural labeling f C
corresponding to a cut C on Gαβ,
p ∈C for p ∈Pαβ
p ∈C for p ∈Pαβ
for p ∈P , p /∈Pαβ .
In other words, if the pixel p is in Pαβ then p is assigned label α when the cut C separates p from the
terminal α; similarly, p is assigned label β when C
separates p from the terminal β. If p is not in Pαβ
then we keep its initial label fp. This implies
Lemma 1 A labeling f C corresponding to a cut C on
Gαβ is one α-β swap away from the initial labeling f.
It is easy to show that a cut C severs an n-link
e{p,q} between neighboring pixels on Gαβ if and only
if C leaves the pixels p and q connected to diﬀerent
terminals. Formally
Property 1 For any cut C and for any n-link e{p,q}:
e{p,q} ̸∈C.
e{p,q} ̸∈C.
e{p,q} ∈C.
e{p,q} ∈C.
These properties are illustrated in ﬁgure 3. The next
lemma is a consequence of property 1 and equation 3.
Lemma 2 For any cut C and for any n-link e{p,q}
|C ∩e{p,q}| = V{p,q}(f C
Lemmas 1 and 2 plus property 1 yield
Theorem 1 There is a one to one correspondence between cuts C on Gαβ and labelings that are one α-β
swap from f. Moreover, the cost of a cut C on Gαβ is
|C| = E(f C) plus a constant.
The ﬁrst part follows from the fact that the
severed t-links uniquely determine the labels assigned
to pixels p and n-links that must to be cut. We now
compute the cost of a cut C, which is
|C∩e{p,q}|. (4)
Property 1(a)
Property 1(b)
Property 1(c,d)
Figure 3: Properties of a cut C on Gαβ for two pixels
p, q ∈N connected by an n-link e{p,q}. Dotted lines
show the edges cut by C and solid lines show the edges
remaining in the induced graph G(C) = ⟨V, E −C⟩.
Note that for p ∈Pαβ we have
V{p,q}(f C
Lemma 2 gives the second term in (4). Thus, the total
cost of a cut C is
p or q ∈Pαβ
V{p,q}(f C
This can be rewritten as |C| = E(f C) −K where
{p,q}∩Pαβ=∅
V{p,q}(fp, fq)
is the same constant for all cuts C.
Corollary 1 The optimal α-β swap from f is ˆf = f C
where C is the minimum cut on Gαβ.
Finding the optimal expansion move
Given an input labeling f (partition P) and a label α, we wish to ﬁnd a labeling ˆf that minimizes E
over all labelings within one α-expansion of f. This is
the critical step in the algorithm given at the bottom
of Figure 1. In this section we describe a technique
that solves the problem assuming that each V{p,q} is
a metric, and thus satisﬁes the triangle inequality (2).
Some important examples of metrics are given in the
introduction. Our technique is based on computing a
labeling corresponding to a minimum cut on a graph
Gα = ⟨Vα, Eα⟩. The structure of this graph is determined by the current partition P and by the label α.
Proceedings of “Internation Conference on Computer Vision”, Kerkyra, Greece, September 1999
vol.I, p.381
Figure 4: An example of Gα for a 1D image. The set of
pixels in the image is P = {p, q, r, s} and the current
partition is P = {P1, P2, Pα} where P1 = {p}, P2 =
{q, r}, and Pα = {s}. Two auxiliary nodes a = a{p,q},
b = a{r,s} are introduced between neighboring pixels
separated in the current partition.
Auxiliary nodes
are added at the boundary of sets Pl.
As before, the graph dynamically changes after each
iteration.
This section is organized as follows. First we describe the construction of Gα for a given f (or P)
We show that cuts C on Gα correspond in
a natural way to labelings f C which are within one
α-expansion move of f. Then, based on a number of
simple properties, we deﬁne a class of elementary cuts.
Theorem 2 shows that elementary cuts are in one to
one correspondence with labelings that are within one
α-expansion of f, and also that the cost of an elementary cut is |C| = E(f C). A corollary from this theorem states our main result that the desired labeling ˆf
equals f C where C is a minimum cut on Gα.
The structure of the graph is illustrated in Figure 4.
For legibility, this ﬁgure shows the case of 1D image.
The set of vertices includes the two terminals α and ¯α,
as well as all image pixels p ∈P. In addition, for each
pair of neighboring pixels {p, q} ∈N separated in the
current partition (i.e. fp ̸= fq) we create an auxiliary
vertex a{p,q}. Auxiliary nodes are introduced at the
boundaries between partition sets Pl for l ∈L. Thus,
the set of vertices is
Vα = { α , ¯α , P ,
Each pixel p ∈P is connected to the terminals α and
¯α by t-links tα
p , correspondingly.
of neighboring pixels {p, q} ∈N which are not separated by the partition P (i.e. fp = fq) is connected by
an n-link e{p,q}. For each pair of neighboring pixels
{p, q} ∈N such that fp ̸= fq we create a triplet of
edges E{p,q} =
e{p,a}, e{a,q}, t¯α
where a = a{p,q}
is the corresponding auxiliary node. The edges e{p,a}
and e{a,q} connect pixels p and q to a{p,q} and the
t-link t¯α
a connects the auxiliary node a{p,q} to the terminal ¯α. So we can write the set of all edges as
The weights assigned to the edges are
V{p,q}(fp, α)
V{p,q}(α, fq)
{p, q} ∈N, fp ̸= fq
V{p,q}(fp, fq)
V{p,q}(fp, α)
{p, q} ∈N, fp = fq
As in section 3, any cut C on Gα must sever (include) exactly one t-link for any pixel p ∈P. This
deﬁnes a natural labeling f C corresponding to a cut C
on Gα. Formally,
In other words, a pixel p is assigned label α if the cut
C separates p from the terminal α and, p is assigned
its old label fp if C separates p from ¯α. Note that for
p ̸∈Pα the terminal ¯α represents labels assigned to
pixels in the initial labeling f. Clearly we have
Lemma 3 A labeling f C corresponding to a cut C on
Gα is one α-expansion away from the initial labeling f.
It is also easy to show that a cut C severs an nlink e{p,q} between neighboring pixels {p, q} ∈N such
that fp = fq if and only if C leaves the pixels p and
q connected to diﬀerent terminals.
In other words,
Property 1 holds when we substitute “¯α” for “β”. We
will refer to this as Property 1(¯α). Analogously, we
can show that Property 1(¯α) and equation (5) establish Lemma 2 for the n-links e{p,q} on Gα.
Proceedings of “Internation Conference on Computer Vision”, Kerkyra, Greece, September 1999
vol.I, p.382
e{p,a} e{a,q}
Property 2(a)
Property 2(b)
Property 2(c,d)
Figure 5: Properties of a minimum cut C on Gα for two
pixel p, q ∈N such that fp ̸= fq. Dotted lines show
the edges cut by C and solid lines show the edges in
the induced graph G(C) = ⟨V, E −C⟩.
Consider now the set of edges E{p,q} corresponding
to a pair of neighboring pixels {p, q} ∈N such that
fp ̸= fq. In this case, there are several diﬀerent ways
to cut these edges even when the pair of severed t-links
at p and q is ﬁxed. However, a minimum cut C on Gα
is guaranteed to sever the edges in E{p,q} depending
on what t-links are cut at the pixels p and q.
The rule for this case is described in Property 2
below. Assume that a = a{p,q} is an auxiliary node
between the corresponding pair of neighboring pixels.
Property 2 A minimum cut C on Gα satisﬁes:
C ∩E{p,q} = ∅.
C ∩E{p,q} = t¯α
C ∩E{p,q} = e{p,a}.
C ∩E{p,q} = e{a,q}.
Property (a) results from the fact that no subset of C
is a cut. The others follow from the minimality of |C|
and the fact that |e{p,a}|, |e{a,q}| and |t¯α
a| satisfy the
triangle inequality so that cutting any one of them is
cheaper than cutting the other two together. These
properties are illustrated in Figure 5.
Lemma 4 If {p, q} ∈N and fp ̸= fq then the minimum cut C on Gα satisﬁes |C∩E{p,q}| = V{p,q}(f C
The equation follows from property 2, equation (5), and the edge weights.
Property 1(¯α) holds for any cut, and Property 2
holds for a minimum cut. However, there can be other
cuts besides the minimum cut that satisfy both properties. We will deﬁne an elementary cut on Gα to be
a cut that satisﬁes Properties 1(¯α) and 2.
Theorem 2 Let Gα be constructed as above given f
Then there is a one to one correspondence
between elementary cuts on Gα and labelings within
one α-expansion of f. Moreover, for any elementary
cut C we have |C| = E(f C).
We ﬁrst show that an elementary cut C is
uniquely determined by the corresponding labeling f C.
The label f C
p at the pixel p determines which of the
t-links to p is in C. Property 1(¯α) shows which n-links
e{p,q} between pairs of neighboring pixels {p, q} such
that fp = fq should be severed. Similarly, Property 2
determines which of the links in E{p,q} corresponding
to {p, q} ∈N such that fp ̸= fq should be cut.
The cost of an elementary cut C is
|C ∩e{p,q}|
|C ∩E{p,q}|.
It is easy to show that for any pixel p ∈P we have
p }| = Dp(f C
p ). Lemmas 2 and 4 hold for elementary cuts, since they are based on Properties 1(¯α)
and 2. Thus, the total cost of a elementary cut C is
V{p,q}(f C
q ) = E(f C).
Therefore, |C| = E(f C).
Our main result is a simple consequence of this theorem, since the minimum cut is an elementary cut.
Corollary 2 The optimal α expansion from f is ˆf =
f C where C is the minimum cut on Gα.
Experimental results
For our experiments, we used three energy functions, each with a quadratic Dp.
The ﬁrst energy
function, called E1, uses the truncated quadratic
V{p,q}(fp, fq) = min(K, (fp −fq)2) (for some constant
K) as its smoothness term. This choice of V does not
obey the triangle inequality, so we minimized E1 using our swap move method. The second (E2) and the
third (E3) energy functions use, correspondingly, the
Potts model and the truncated L2 distance as their
smoothness penalty V .
Both of these obey the triangle inequality and we minimized E2 and E3 with
our expansion move method. We compared against
annealing; we implemented several diﬀerent annealing
variants, and used the one that gave the best performance.
This was the Metropolis sampler with a
linearly decreasing temperature schedule.
Proceedings of “Internation Conference on Computer Vision”, Kerkyra, Greece, September 1999
vol.I, p.383
Image Restoration.
To illustrate the importance
of diﬀerent choices of V , consider the image restoration problem shown in the top row of ﬁgure 7. The
original image contains large constant-intensity regions (the diamonds) which are gradually shaded, as if
there were a light source to the left of the image. This
image is corrupted with normally-distributed noise to
produce the input image shown. This example demonstrates the need for non-Potts energy functions, as
minimizing E2 gives signiﬁcant “banding” problems
(shown in the second image). By selecting an energy
function with a truncated quadratic V{p,q}, we obtain
the improved results shown at right.
The energy computed by our swap move method
is shown below as a function of time.
we produce a very low energy after the ﬁrst iteration, while annealing decreases the energy very slowly.
The energy values that we obtain for this and two
more examples are shown in ﬁgure 6.
The energy
curves as a function of time are very similar to the
diamond example shown above, but are omitted to
save space.
We also include the ratio between annealing’s energy and ours.
The third row for each
image gives the best energy that annealing eventually
achieves, when run until it is making very minimal
progress. In this case, annealing eventually achieves a
small improvement.
It is worthwhile to analyze Esmooth, since in our
experience this correlated much more strongly with
overall image quality than E. This is partly due to
the fact that Dp rises so rapidly; as a result, most
labels can be easily eliminated for a given pixel.
Motion and stereo.
We also did energy minimization on several standard images, including the SRI
tree sequence (taken from a camera moving along a
rail) and the rock stereo pair. We compared our swap
move and expansion move methods (for E1 and E3,
correspondingly) with simulated annealing.
We initialized both methods with the results of normalized
correlation, which are also shown in the ﬁgure.
For both images, the energy that annealing achieves
after more than 15 hours is signiﬁcantly worse than
the energy we obtain in around 200 seconds. We have
experimented with a number of other images and obtained similar results.
Acknowledgements
We thank J. Kleinberg, D. Shmoys and E. Tardos
for providing important input on the content of the
paper. This research has been supported by DARPA
under contract DAAL01-97-K-0104, and by a grant
from Microsoft.