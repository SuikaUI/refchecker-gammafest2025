HAL Id: halshs-00849071
 
 
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of scientific research documents, whether they are published or not.
The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Regional Policy Evaluation: Interactive Fixed Effects
and Synthetic Controls
Laurent Gobillon, Thierry Magnac
To cite this version:
Laurent Gobillon, Thierry Magnac. Regional Policy Evaluation: Interactive Fixed Effects and Synthetic Controls. 2013. ￿halshs-00849071￿
WORKING PAPER N° 2013 – 24
Regional Policy Evaluation: Interactive Fixed
Effects and Synthetic Controls
Laurent Gobillon
Thierry Magnac
JEL Codes: C21, C23, H53, J64, R11
Keywords: Policy evaluation, Linear factor models, Synthetic controls,
Economic geography, Enterprise zones
PARIS-JOURDAN SCIENCES ECONOMIQUES
48, BD JOURDAN – E.N.S. – 75014 PARIS
TÉL. : 33(0) 1 43 13 63 00 – FAX : 33 (0) 1 43 13 63 10
www.pse.ens.fr
CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE – ECOLE DES HAUTES ETUDES EN SCIENCES SOCIALES
ÉCOLE DES PONTS PARISTECH – ECOLE NORMALE SUPÉRIEURE – INSTITUT NATIONAL DE LA RECHERCHE AGRONOMIQU
Regional Policy Evaluation:
Interactive Fixed Eﬀects and Synthetic Controls
Laurent Gobillon
INED and Paris School of Economics
Thierry Magnac
Toulouse School of Economics
First version: October 2012
This version July 4, 2013
In this paper, we investigate the use of interactive eﬀect or linear factor models in regional
policy evaluation.
We contrast treatment eﬀect estimates obtained by Bai ’s least
squares method with the popular diﬀerence in diﬀerence estimates as well as with estimates
obtained using synthetic control approaches as developed by Abadie and coauthors. We show
that diﬀerence in diﬀerences are generically biased and we derive the support conditions that
are required for the application of synthetic controls.
We construct an extensive set of
Monte Carlo experiments to compare the performance of these estimation methods in small
samples. As an empirical illustration, we also apply them to the evaluation of the impact on
local unemployment of an enterprise zone policy implemented in France in the 1990s.
Keywords: Policy evaluation, Linear factor models, Synthetic controls, Economic geography,
Enterprise zones
Introduction1
It is becoming more and more common to evaluate the impact of regional policies using the tools of
program evaluation derived from micro settings . In particular, enterprise and empowerment zone programs have
received a renewed interest over recent years . Those programs
consist in a variety of locally targeted subsidies aiming primarily at boosting local employment or
the employment of residents. Their evaluations use panel data and methods akin to diﬀerence in
diﬀerences that oﬀer the simplest form of control of local unobserved characteristics that can be
correlated with the treatment indicator. Nonetheless, speciﬁc issues arise when studying regional
policies and the tools required to evaluate their impact or to perform a cost-beneﬁt analysis are
diﬀerent from the ones used in more usual micro settings.
The issue of spatial dependence between local units is important in the evaluation of regional
policies. Outcomes are likely to be spatially correlated in addition to the more usual issue of
serial correlation in panel data. There is thus a need for a better control of spatial dependence
and more generally of cross-section dependence when evaluating regional policies. This is why
more elaborate procedures than diﬀerence in diﬀerences are worth exploring and the use of factor
or interactive eﬀect proved to be attractive and fruitful in micro studies . Interactive eﬀect models facilitate the control for cross-section dependence not
only because of spatial correlations but also because areas can be close in economic dimensions
which depart from purely geographic characteristics. This is the case for instance when two local
units are aﬀected by the same sector-speciﬁc shocks because of sectoral specialisation even if these
units are not neighbors.
Second, a key issue in policy evaluation is that treatment and outcomes might be correlated
because of the presence of unobservables. It should also be acknowledged when using regional
data that those unobservables diﬀerencing local units might be multidimensional because the
1We are grateful to participants at seminars in Duke University, INED in Paris, Toulouse School of Economics,
CREST in Paris, ISER at Essex and at the 2012 NARSC conference in Ottawa, for useful comments as well as to
Sylvain Chabé-Ferret for fruitful discussions. We also thank DARES for ﬁnancial support. The usual disclaimer
underlying cycles of economic activities of local units are likely to be multiple. Interactive eﬀect
models are aimed precisely at allowing the set of unobserved heterogeneity terms or factor loadings
that are controled for to have a large dimension.
Moreover, the estimation of linear factor models in panels is relatively easy and asymptotic
properties of estimates are now well known . Yet, there are only a few
attempts in the literature to conduct regional policy evaluations using factor models or using a kindred conditional pseudo-likelihood approach and its properties have been developed and vindicated in a model with factors . Under the maintained assumption that the true model is a linear factor model, we show that synthetic controls are equivalent to interactive eﬀect methods
whenever matching variables (i.e. factor loadings and exogenous covariates) of all treated areas
belong to the (convexiﬁed) support of matching variables of control areas, a case that we call the
interpolation case. This is not true any longer in the extrapolation case, that is, when matching
variables of one treated area at least, do not belong to the support of matching variables in the
control group.
Our third contribution is that we evaluate the relevance and analyze the properties of interactive eﬀect, synthetic control and diﬀerence-in-diﬀerences methods by Monte Carlo experiments. We use various strategies for interactive eﬀect estimation. First, a direct method estimates
the counterfactual for treated units by linear factor methods in a restricted sample where post-
treatment observations for treated units are excluded. The second method estimates a linear factor
model which includes a treatment dummy and uses the whole sample. Propensity score matching
underlies the third method in which the score is conditioned by factor loading estimates obtained
using the ﬁrst method. Imposing common support constraints on factor loadings when estimating
the counterfactual for treated units by linear factor methods provides the fourth method. We
contrast these Monte Carlo estimation results with the ones we obtain by using synthetic controls
and diﬀerence in diﬀerences.
We ﬁnally provide the results of an empirical application of these methods to the evaluation of
the impact of a French enterprise zone program on unemployment exits at the municipality level
in the Paris region. This extends our results in Gobillon et al. in which we were using
conditional diﬀerence-in-diﬀerences methods. We show that the estimated impact is robust to the
presence of factors and therefore to cross-section dependence. We also look at other empirical
issues of interest such as the issue of missing data about destination when exiting unemployment
as well as entries into unemployment.
In the next Section, we brieﬂy review the meager empirical literature that use factor models to
evaluate regional policies. We construct in Section 3 the theoretical set-up and write restrictions
leading to the identiﬁcation of the average treatment on the treated in linear factor models. Next,
we derive the bias of diﬀerence in diﬀerences and describe the linear factor model estimation
procedures.
We derive the conditions that contrast their asymptotic properties with those of
synthetic control methods. Monte Carlo experiments reported in Section 4 evaluate the small
sample properties of the whole range of our estimation procedures. The empirical application and
estimation results are presented in Section 5 and the last section concludes.
Review of the litterature
Kim and Oka estimate an interactive eﬀect model following Bai and provide a
policy evaluation of the impact of changes in unilateral divorce state laws on divorce rates in the
US. They ﬁnd that interactive eﬀect estimates are smaller than diﬀerence-in-diﬀerences estimates.
Furthermore, they estimate their model varying the number of factors and ﬁnd that the model
selection procedures proposed by Bai and Ng are not informative.
Hsiao, Ching and Wan use an interactive eﬀect model to study the eﬀect on Hong Kong’s
domestic product of two policies of convergence with mainland China that were implemented at
the turn of this century. Their observations consist in various macroeconomic variables measured
every quarter over ten years for Hong Kong and countries either in the region or economically
associated with Hong-Kong. The authors argue that interactive models can be rewritten as models
in which interactive eﬀects can be replaced by summaries of outcomes for other countries at the
same dates using a conditioning argument. Indeed, common factors can be predicted using this
information but this entails losses of information since information at current period only is used
to construct these predictions.
Interestingly, Ahn, Lee and Schmidt analyze an interactive eﬀect model and their
method potentially provides eﬃciency improvements over the procedure of Hsiao, Ching and Wan
 . The authors show that the conditional likelihood function (or pseudo-likelihood function
associated to the normal distribution), conditional on a number of period outcomes equal to the
number of factors can be written as a function that does not depend on individual factor loadings.
Assuming out any remaining spatial correlation, they show that conditional likelihood estimates
are consistent for ﬁxed T.
Overall, in a large N and T environment, the most prominent estimation methods were proposed by Pesaran who uses regressions augmented with cross section averages of covariates
and outcomes, and by Bai who uses principal component methods. Westerlund and Urbain
 review quite extensively diﬀerences between these methods.
Theoretical Set-Up
Consider a sample composed of i = 1, ..., N local units observed at dates t = 1, ..., T. A simple
binary treatment, Di ∈{0, 1}, is implemented at date TD < T so that for t ⩾TD > 1, the units
i = 1, ..., N1 are treated (Di = 1). Units i = N1 + 1, ..., N are never treated (Di = 0). For each
unit, we observe outcomes, yit, which might depend on the treatment and the average eﬀect of the
treatment on the treated is our parameter of interest. In Rubin’s notations, we denote by yit (d)
the outcome of an individual i at date t if in treatment status d (where d = 1 in case of treatment,
and d = 0 in the absence of treatment). This hypothetical status should be distinguished from
random variable Di describing the actual assignment to treatment in this experiment.
The average eﬀect of the treatment on the treated can be written when t ≥TD:
E (yit (1) −yit (0) |Di = 1) = E (yit (1) |Di = 1) −E (yit (0) |Di = 1)
A natural estimator of the ﬁrst right-hand side term is its empirical counterpart since the
outcome in case of treatment is observed for the treated at periods t ⩾TD. In contrast, the second
right-hand side term is a counterfactual term since the outcome in the absence of treatment is not
observed for the treated at periods t ⩾TD. The principle of evaluation methods relies on using
additional restrictions to construct a consistent empirical counterpart to the second right-hand
side term . For instance, it is well known that diﬀerence-indiﬀerences methods are justiﬁed by an equal trend assumption:
E(yit(0) −yi,TD−1(0) | Di = 1) = E(yit(0) −yi,TD−1(0) | Di = 0) for t ≥TD.
under which the counterfactual can be written as:
E (yit (0) |Di = 1) = E(yit(0) −yi,TD−1(0) | Di = 0) + E(yi,TD−1(0) | Di = 1) for t ≥TD,
in which all terms on the right-hand side are directly estimable from the data.
The object of this section is to generalize the usual set-up in which diﬀerence in diﬀerences
provide a consistent estimate of the eﬀect of the treatment on the treated (TT) to a set-up
allowing for higher-dimensional unobserved heterogeneity terms. Local units treated by regional
policies could indeed be aﬀected by various common shocks describing business cycles related for
instance to diﬀerent economic sectors. Associated factor loadings would describe the heterogeneity
of exposition of local units to these common shocks. A single dimensional additive local eﬀect as in
the set up underlying diﬀerence-in-diﬀerences estimation is unlikely to describe this rich economic
environment.
Furthermore, we know that diﬀerence in diﬀerences can dramatically fail when
heterogeneity is richer than what is modelled .
In this paper, we restrict our attention to linear models because the number of units is rather
small although extensions to non-linear settings could follow the line of Abadie and Imbens 
at the price of losing the simplicity of linear factor models.
The route taken by Conley and
Taber to deal with small sample issues might also be worth extending to our setting. More
speciﬁcally, linearity makes one wary of issues of interpolation and extrapolation that we shall
highlight in the general framework of linear factor models as well as in the approach of synthetic
controls proposed in the seminal paper by Abadie and Gardeazabal .
We present in the ﬁrst sub-section the maintained speciﬁcation of a linear factor model and
we discuss identifying assumptions. Next, we show that the conventional diﬀerence-in-diﬀerences
estimate is generically biased. We propose an estimation method by linear factor models including
a treatment dummy and derive a rank condition for the identiﬁcation of the average treatment on
the treated. We also propose a direct estimation method by constructing the counterfactual term
in equation (1) using the samples of control and treated units albeit the latter before treatment
only . Finally, we describe the approach
of synthetic controls and analyze its properties when the true model has interactive eﬀects.
Interactive linear eﬀects and restrictions on conditional means
In the conventional case of diﬀerence in diﬀerences (DID) in which covariates are controlled for , the outcome in the absence of treatment is speciﬁed
as a linear function:
yit (0) = xitβ + ˜λi + eδt + εit
in which xit is a 1×K vector of individual covariates, and ˜λi and eδt are individual and time eﬀects.
A limit to this speciﬁcation is that individuals are all aﬀected in the same way by the time eﬀects.
To allow for interactions and make the speciﬁcation richer, we specify the outcome in the absence
of treatment as a function of the interaction between factors varying over time and heterogenous
individual terms called factor loadings as:
yit (0) = xitβ + f ′
λi is a L × 1 vector of individual eﬀects or factor loadings, and ft is a L × 1 vector of time eﬀects
or factors. Note that this speciﬁcation embeds the usual additive model by letting λi =
as, in that case, f ′
tλi = ˜λi + eδt.
The true process generating the data is supposed to be given by equation (4) and is completed
by the description of the outcome in case of treatment:
yit (1) = yit (0) + αit
which, in contrast to the linear speciﬁcation above, is not restrictive.
There are a few usual assumptions that complete the description of the maintained true model.
First, we shall assume that we know the number of factors in the true model described by equation
(4). Various tests regarding the number of factors might be useful to implement but these are fragile . Moreover,
we adopt the assumption that factors are suﬃciently strong so that the consistency condition for
the number of factors and consequently for factors and factor loadings is satisﬁed . This condition reﬂects the fact that factor
loadings can be separated from the idiosyncratic random terms at the limit.2
Moreover, we do not specify the dynamics of factors in the spirit of Doz, Giannone and Reichlin
 . Their speciﬁcation imposes more restrictions on the estimation although inference is more
diﬃcult to develop. This is why we stick to the limited information framework which does not
impose conditions on the dynamics of factors although it could be done in the way explained
by Hsiao, Ching and Wan .
Furthermore, the only available explanatory variables are
not varying over time in our empirical application. This corresponds to the low rank regressor
assumption as deﬁned by Moon and Weidner and under which identifying assumptions
are of a particular form. At this stage however we prefer to stick to the more general format.
A ﬁnal comment is worth making. In treatment evaluation, lagged endogenous variables are
at times included as matching covariates in order to control for possible ex-ante diﬀerences. In
spirit, this is very close to a model with interactive eﬀets because it is well known that a simple
linear dynamic panel data model like:
yit = αyit−1 + ηi + uit
can be rewritten as a static model:
yit = αtyi0 +
1 −α + νit
in which νit is an AR(1) process. Factors are αt and 1 −αt, and factor loadings are yi0 and
This argument could be generalized to more sophisticated dynamic linear models.
2It does not mean that the treatment parameter is not identiﬁed under alternative assumptions.
Restrictions on conditional means
To complete the description of the true data generating process, we now present and comment the
main restrictions on random terms. To keep notations simple and conform with the usual panel
data set up, we generally consider that factors ft are ﬁxed while factor loadings λi are supposed
to be correlated random eﬀects.
We ﬁrst assume that idiosyncratic terms εit are "orthogonal" to factor loadings and that
explanatory variables are strictly exogenous:3
εit ⊥(λi, xi)
in which x′
iT)′ is a [T, K] matrix. This would be without loss of generality when
orthogonality is deﬁned as the absence of correlation as in Bai .
Because of the next
assumption we will adopt, we prefer to interpret orthogonality as mean independence and the
translation of the above assumption is therefore that:
Assumption A1:
E(εit | λi, xi) = 0.
Second, we extend the usual assumption made in diﬀerence-in-diﬀerences estimation by assuming
that the conditioning set now includes unobserved factor loadings:
yit(0) ⊥Di | (xi, λi) ⇔εit ⊥Di | (xi, λi)
and we write this condition as a mean independence restriction:
Assumption A2:
E(εit | Di, λi, xi) = E(εit | λi, xi).
Note that we do not suppose that (λi, xi) and Di are uncorrelated and selection into treatment
can freely depend on observed and unobserved heterogeneity terms.
Finally, deﬁne the average treatment eﬀect over the periods after treatment as:
so that our main parameter of interest is the average treatment on the treated over the periods
after treatment deﬁned as:4
3The extension to the case with weakly exogeneous regressors would follow Moon and Weidner for
4In the case T →∞, those deﬁnitions should be interpreted as limits. Note also that it is generally easy to
design estimates for time-speciﬁc treatment parameters such as E(αit | Di = 1) by restricting the post-treatment
observations to period t only.
Deﬁnition ATT:
α = E(αi | Di = 1) =
E(αit | Di = 1).
Assumptions A1 and A2 are the main restrictions in our set-up and Deﬁnition ATT deﬁnes our
parameter of interest.
The generic bias of diﬀerence-in-diﬀerences estimates
If the true data generating process comprises interactive eﬀects, we now show that the diﬀerencein-diﬀerences estimator is generically biased although we exhibit two interesting speciﬁc cases in
which the bias is equal to zero. For simplicity, we omit covariates or, since covariates are assumed
to be strictly exogenous, implicitly condition on them in this subsection. We also assume for
simplicity that the probability measure of factor loadings in the treated population, dG(λi | Di =
1), and in the control population dG(λi | Di = 0), are dominated by the Lebesgue measure so
that both distributions are absolutely continuous.
We shall show that the condition which is implied by Assumption A2:5
E(yit(0) −yi,TD−1(0) | Di = 1, λi) = E(yit(0) −yi,TD−1(0) | Di = 0, λi) for t ⩾TD
does not imply equation (2) under which the diﬀerence-in-diﬀerences estimator is consistent.
E(yit(0) −yi,TD−1(0) | Di = 1)
= E [E(yit(0) −yi,TD−1(0) | Di = 1, λi)] ,
E(yit(0) −yi,TD−1(0) | Di = 1, λi)dG(λi | Di = 1).
Replacing the integrand using equation (6) yields:
E(yit(0) −yi,TD−1(0) | Di = 1) =
E(yit(0) −yi,TD−1(0) | Di = 0, λi)dG(λi | Di = 1).
Two special cases are worth noting. Firstly, the integrand in the previous expression does not
depend on λi in the restricted case in which there is a single factor ft = 1 and a single individual
eﬀect associated with this factor. In this case, equation (7) can be written as:
E(yit(0) −yi,TD−1(0) | Di = 1)
= E(yit(0) −yi,TD−1(0) | Di = 0)
dG(λi | Di = 1)
= E(yit(0) −yi,TD−1(0) | Di = 0),
5This condition is slightly weaker than A2 because it considers diﬀerences between periods.
which yields equation (2) describing equality of trends.
Alternatively, (perfectly) controled experiments also enables identiﬁcation through diﬀerence
in diﬀerences in spite of using the alternative argument that dG(λi | Di = 1) = dG(λi | Di = 0).
The same equation (2) holds and the treatment parameter is consistently estimable by diﬀerence
in diﬀerences.
This implication is not true in general and we can distinguish two cases. If the conditional
distribution of λi in the treated population is dominated by the corresponding measure in the
control population i.e.:
∀λi such that dG(λi | Di = 0) = 0 we have dG(λi | Di = 1) = 0,
the support of the treated units is included in the support of the non treated units. We shall
describe from now on cases in which support condition (8) holds as an instance of interpolation
and if such a condition is not satisﬁed, as an instance of extrapolation.
In the interpolation case, let:
r(λi) = dG(λi | Di = 1)
dG(λi | Di = 0) < ∞
which is well deﬁned because of the support condition (8) and because distributions are absolutely
continuous. Write equation (7) as:
E(yit(0) −yi,TD−1(0) | Di = 1) =
E(yit(0) −yi,TD−1(0) | Di = 0, λi)r(λi)dG(λi | Di = 0)
which in turn implies that:
E(yit(0) −yi,TD−1(0) | Di = 1)
= E(yit(0) −yi,TD−1(0) | Di = 0)
+Cov (yit(0) −yi,TD−1(0), r(λi) | Di = 0)
The second term in the right hand side can be interpreted as the diﬀerential trend in outcomes
which is due to the time varying eﬀects of factors interacted with unobserved factor loadings. If
there is indeed a factor loading associated to a time-varying factor, the second term is not equal
to zero except under special circumstances as seen above. In the interpolation case, the second
term describes the bias in DID estimates.
In the alternative case of extrapolation, the bias term is derived in a similar way although its
interpretation is less clear since it mixes issues of non inclusive supports with the time varying
eﬀect of factors.
Interactive Eﬀect Estimation in the Whole Sample
We now explore interactive eﬀect methods and exhibit conditions under which these methods
allow the identiﬁcation of the average treatment on the treated parameter.
The observed outcome veriﬁes:
yit = yit(0)1{Dit = 0}+yit(1)1{Dit = 1}
and using equations (4) and (5), it can be written as:
yit = αitItDi + xitβ + f ′
in which Di is the treatment indicator, and It = 1{t ≥TD} is an indicator of treated periods. We
maintain Assumptions A1 and A2 that allow the correlation between Di and λi to be unrestricted
so that selection into treatment can depend on factor loadings. Similarly, the correlation between
It and ft is unrestricted so that the implementation of the treatment can be correlated with
economic cycles which are described here by factors.
We shall rewrite equation (10) as:
yit = αItDi + xitβ + f ′
tλi + εit + (αit −α)ItDi
in which α is the average treatment on the treated parameter as in Deﬁnition ATT.
We now exhibit conditions under which α can be estimated using interactive eﬀect procedures
as proposed by Bai . We start with the case β = 0 which requires a weak rank condition and
then extend it to the general case with covariates which requires a stronger additional assumption
albeit easy to interpret.
Average Treatment Eﬀect on the Treated in the Absence of Covariates
We shall prove that the parameter of interest α is identiﬁed under the two conditions that It is
not equal to a linear combination of factors ft and that the probability of treatment is positive.
We continue considering that T is ﬁxed as well as factors ft and treatment It and we analyze
identiﬁcation as if factors ft were known. This argument extends to the case in which T tends to
inﬁnity by taking limits.
Stack individual observations in individual vectors of dimension [T, 1] :
yi = αDiI[1:T] + F ′λi + εi + ∆iI[1:T]Di
in which yi
(yi1, ., yiT)′, I[1:T]
(I1, ., IT)′, F
(f1, ., fT), εi
(εi1, ., εiT)′ and
∆i = diag (αi1 −α, ..., αiT −α) is a matrix of dimension [T, T]. Set MF = I −F ′(FF ′)−1F and
multiply the previous equation to obtain:
MFyi = αDiMFI[1:T] + MFεi + MF∆iI[1:T]Di.
A necessary condition of identiﬁcation of α using the latter equation stacked over the diﬀerent
individual units is that:
[1:T]MFI[1:T] > 0 and E(Di) > 0,
which means that I[1:T] is not equal to a linear combination of factors and that the probability
of being treated is positive. This is related to the rank condition underlying the identiﬁcation of
parameters as in Proposition 3 in Bai . Furthermore, this condition is also necessary
in equation (12) because the correlation between λi and Di is unrestricted.
This condition is also suﬃcient since E(Di)I′
[1:T]MFI[1:T] is invertible and because we now show
α = (E(DiI′
[1:T]MFI[1:T]))−1E(DiI′
[1:T]MFyi) = (E(Di)I′
[1:T]MFI[1:T])−1E(DiI′
[1:T]MFyi).
Indeed, the correlation between the two right-hand side terms of equation (13), the regressor
DiMFI[1:T] and the error term MFεi + MF(αi −α)I[1:T]Di, is equal to zero. There are two terms
in this correlation that we analyze in turn.
The ﬁrst term is equal to 0 by construction (Assumption A2):
[1:T]MFDiMFεi) = E(I′
[1:T]MFDiMFE(εi | Di)) = 0
since Di is a scalar random variable and variables in the time dimension are supposed to be ﬁxed.
The second term of the correlation above is more interesting and can be written as:
[1:T]MFDiMF∆iI[1:T]Di) = E(I′
[1:T]MFDiMFE(∆iI[1:T] | Di)Di),
which is equal to zero by construction of ∆i since by Deﬁnition ATT:
E(∆iI[1:T] | Di = 1) = E(
(αit −α) | Di = 1) = 0.
Multiplying (13) by I′
[1:T]MFDi and taking the expectation gives (15). This ends the proof that
the average treatment on the treated parameter α is identiﬁed under rank condition (14).
The Case with Covariates
In the general case with covariates, we can write equation (11) as:
yi = αDiI[1:T] + xiβ + F ′λi + εi + ∆iI[1:T]Di
Multiplying this equation by MF, we obtain:
MFyi = αDiMFI[1:T] + MFxiβ + MFεi + MF∆iI[1:T]Di.
Denote the linear prediction of Di as a function of xi as:
Di = vec(xi)′γ + Dix,
and rewrite equation (18) as:
MFyi = αDixMFI[1:T] + MF˜εi + MF∆iI[1:T]Di,
in which ˜εi = εi + xiβ + α.vec(xi)′γI[1:T]. Because xi and vec(xi) are uncorrelated with Dix, the
same non correlation condition as in equation (16) is valid since we have from Assumptions A1 and
A2 that E (εi |Di, xi) = 0. Thus, the second condition derived from equation (17) that remains
to be checked refers to the equality to zero of:
E(∆iI[1:T]DiDix) = E(∆iI[1:T]DiDi) −E((∆iI[1:T]Divec(xi)′γ) = −E(∆iI[1:T]Divec(xi)′γ),
because of the argument employed after equation (17) that uses Deﬁnition ATT. This correlation
is equal to zero under the suﬃcient condition given by:
E(αit | Di = 1, xi) = E(αit | Di = 1),
since it implies that:
E(∆iI[1:T] | Di = 1, xi) = E(∆iI[1:T] | Di = 1) = 0,
by Deﬁnition ATT as above. This condition is stronger than necessary as it would be suﬃcient
to condition on the scalar variable vec(xi)γ.6 Note also that the linear interactive model could be
6In this case, developments following Wooldridge might be appropriate but we do not follow up this
route in this paper.
generalized by conditioning on covariates or interacting covariates with the treatment indicator
and this would substantially weaken this condition as in the static evaluation case .
Consistency and other asymptotic properties of this method can be derived from Bai 
when N −→∞and T →∞. Note also that condition (14) also implies that N1 tends to ∞when
N −→∞. Estimation could also proceed with the estimation method proposed by Ahn, Lee and
Schmidt and thence dispenses with the assumption that T →∞.
Direct Estimation of the Counterfactual
Assumptions A1 and A2 imply that a direct estimation strategy for the treatment on the treated
eﬀects can also be adopted. Estimate ﬁrst the interactive eﬀect model (4) using the sample composed of non treated observations over the whole period and of treated observations before the
date of the treatment t < TD. Orthogonality assumption A2 makes sure that excluding observations i ∈{1, ., N1} and t ≥TD does not generate selection. Second, orthogonality assumption
A1 renders conditions stated by Bai valid and the derived asymptotic properties of linear
factor estimates hold under identifying restrictions as stated in Moon and Weidner .
Various asymptotics can then be considered:
• If N and T tend to ∞, then β, ft and λi for the non treated are consistently estimated (Bai,
• If additionally the number of periods before treatment TD tends to ∞, then λi for the treated
units are consistently estimated.
As for the counterfactual term to be estimated in equation (1), we have for t ⩾TD:
E (yit (0) |Di = 1) = E (xitβ + λ′
ift |Di = 1)
To estimate this quantity, we replace parameters λi, i = 1, ..., N1, β and ft when t ⩾TD by their
consistently estimated values in the right-hand side expression (computed as detailed in Appendix
A.2), and take the empirical counterpart of the expectation. Namely, the treatment on the treated
at a given period is derived by using equation (1) and can be written as:
E (yit (1) −yit (0) |Di = 1) = E(αit | Di = 1) = E (yit (1) |Di = 1) −E (xitβ + λ′
ift |Di = 1) (21)
and its estimate is obtained by replacing unknown quantities by their empirical counterparts.
The average treatment on the treated eﬀect is then obtained by exploiting Deﬁnition ATT and
averaging equation (21) over the periods after treatment.7
An additional word of caution about identiﬁcation is necessary since the rank condition (14)
developed in the previous section also applies although it is not as simple to derive.
summarized in the next proposition:
Proposition 1 Suppose that rank condition (14) does not apply and that the treatment indicator
IT is a linear function of factors:
in which δ is a [L, 1] vector and F is the matrix of factors as deﬁned above. Then for any value of
the treatment eﬀect α, there exists an observationally equivalent factor model in which the value
of the treatment eﬀect is equal to zero.
Proof. Let α be any value and write equation (12) as
yi = αITDi + F ′λi + ˜εi
in which ˜εi includes any idiosyncratic variation of the treatment eﬀect across individuals and
periods. By replacing IT = F ′δ, we get:
αF ′δDi + F ′λi + ˜εi,
F ′(αδDi + λi) + ˜εi,
which provides the alternative factor representation in which the value of the treatment eﬀect is
equal to zero.
This result implies that condition (14) applies to the estimation method derived in this section
as well as to any other estimation method analyzed below.
A single-dimensional factor model
It is well known since Rubin and Rosenbaum that conditions A1 and A2 imply the condition:
E(εit | Di = 1, p(xi, λi)) = 0
7The variance of the estimator can be computed using formulas in Bai and Bai .
in which the distinction between observed variables xi and unobserved variables λi does not matter.
Let µi = p(xi, λi) denote the propensity score.
The condition above suggests the following strategy:
1. Estimate factors and factor loadings using the sample of controls and the subsample of
treated observations before treatment as detailed in Subsection 3.4.
2. Regress Di on xi and ˆλi and construct the predictor of the score ˆµi.
3. Match on the propensity score à la Heckman, Ichimura and Todd , or, under some
conditions, use a single factor model associated to ˆµi.
Synthetic controls
The technique of synthetic controls proposed by Abadie and Gardeazabal and further
explored by Abadie, Diamond and Hainmueller proceeds diﬀerently. It
focuses on the case in which the treatment group is composed of a single unit and uses a speciﬁc
matching procedure of this treated unit to the control units whereby a so-called synthetic control
is constructed. We shall proceed in the same way although as we have potentially more treated
units, we shall repeat the procedure for each of them and then aggregate the result over various
synthetic controls to yield the average treatment on the treated.8
Presentation
We follow the presentation by ADH . An estimator of yit(0) for a single treated unit i ∈
{1, ., N1} after treatment t ≥TD is the outcome of a synthetic control “similar” to the treated
unit which is constructed as a weighted average of non-treated units. We impose similarity of
characteristics xit between treated units and synthetic controls, by weighting characteristics xjt of
8An alternative would be to aggregate the treated units into a single unit ﬁrst. By analogy with what is done
in non-parametric matching, this procedure seems more restrictive because constructing a single synthetic control
leads to less precise estimates than when constructing various synthetic controls. Nonetheless, support conditions
for the validity of the synthetic control method that we ﬁnd might justify such an approach because support
requirements are weaker in the "aggregate" case.
control units, j ∈{N1 + 1, ., N} in such a way that
j xjt = xit for t = 1, ., T
where ω(i)
is the weight of unit j in the synthetic control (such that ω(i)
Similarity between pretreatment outcomes is also imposed in ADH :
where y(k)
ktyjt is a weighted average of pretreatment outcomes in which k = (k1, ., kTD−1)
are weights diﬀering across periods (y(k)
for the treated unit is deﬁned similarly). A set of such pretreatment outcome summaries can be generated using various vectors of weights, k. Nevertheless,
the most general setting is when we consider all pretreatment outcomes, yjt, for t = 1, ..., TD −1.
Indeed, taking linear combinations of pretreatment outcomes or considering the original ones is
equivalent in this general formulation and we dispense with the construction of y(k)
The average treatment on the treated for unit i is estimated as:
In practice, one needs to determine the weights that allow us to construct the synthetic control.
Weights should ensure that the synthetic control is as close as possible to the treated unit i and
thus that conditions (22) and (23) are veriﬁed. Denote zj = (yj1, ., yj,TD−1, xj1, ., xjT)′ (resp. zi)
the list of variables over which the synthetic control is constructed (i.e. pretreatment outcomes
and exogenous variables). Weights are computed using the following minimization program:
in which M is a weighting matrix.9 Note that the resulting weight ω(i) is a fonction of the data
(zi, zN1+1, ., zN).
9M can be chosen in various ways . In our case we set M to the
identity matrix.
Synthetic controls and interactive eﬀects
We now describe this procedure in an interactive eﬀect model as ﬁrst suggested by AHD .
Nonetheless, we show that the absence of bias implies constraints on the supports of the factor
loadings and of exogenous variables and is related to the developments in Section 3.2 above.
To proceed, we need to introduce additional notations. Our linear factor model can be written
at each time period as:
Yt (0) = β′X′
for the untreated,
yit (0) = β′x′
for each treated individual
where ΛU = (λN1+1, ..., λN) is (L, N −N1) and ft is a L column vector. Similarly, Yt (0) and εt
are (N −N1) row vectors and Xt is a (N −N1, K) matrix.
As weights ω(i) =
N1+1, ..., ω(i)
are obtained by equation (25), we have:
yit (0) = Yt (0) ω(i) + ηit for t < TD,
tω(i) + ηitX for t = 1, ..., T
Note that the construction of the synthetic control by equation (27) is allowed to be imperfectly
achieved and the discrepancy is captured by the terms ηit and ηitX. We thus acknowledge that
characteristics of the treated unit, zi = (yi1, ., yi,TD−1, xi1, ., xiT)′, might not belong to the cone
CU generated by the characteristics of control units. First, there are small sample issues when
the number of pre-treatment periods, TD −1, and of covariates, KT, is larger than the number
of untreated units, N −N1. In other words, cone CU lies in a space whose dimension is lower
than the number of vector components, TD −1 + KT . Second and more importantly, even if
TD −1+KT < N −N1, vector zi might not belong to this cone because supports of characteristics
for treated and control units diﬀer. Terms ηit and ηitX capture this discrepancy.
We now analyze what consequences this construction has on the estimation of the treatment
eﬀect. The estimated treatment eﬀect given by equation (24) is a function of
yit(1) −Yt (0) ω(i) = αit + yit(0) −Yt (0) ω(i)
αit + ηit,
in which we have extended deﬁnition (27) to all t ≥TD. The absence of bias of the LHS estimate
with respect to E (αit) can thus be written as E(ηit) = 0. To write this condition as a function of
primitives, we need to replace dependent variables by their values in the model described by (26).
This delivers:
yit(0) −Yt (0) ω(i) = β′x′
tλi + εit −(β′X′
tΛU + εt)ω(i),
tω(i)) + f ′
t(λi −ΛUω(i)) + εit −εtω(i).
Considering that β and ft are ﬁxed and taking expectations yields:
tω(i)) + f ′
tE(λi −ΛUω(i)) + E(εit −εtω(i)),
tω(i)) + f ′
tE(λi −ΛUω(i)),
in which we have used the result derived by ADH that E(εit −εtω(i)) tends to 0 when the
number of pretreatment periods TD tends to ∞.10 This expression should be true for any value of
β and ft and the absence of bias thus implies that:
tω(i)) = 0 and E(λi −ΛUω(i)) = 0.
A suﬃcient condition is established in Appendix B:
Lemma 2 If the support of exogenous variables and factor loadings of the treated units is a subset
of the support of exogenous variables and factor loadings of the non treated units and this latter
set is convex and bounded then condition (28) is satisﬁed at the limit when N −N1 →∞.
We call this case the interpolation case and this relates to the familiar support condition in
the treatment eﬀect literature and to the domination relationship between probability measures
in the treated and control groups seen in equation (8) above.
If this property is not true, the synthetic control method is based on extrapolation since it
consists in projecting λi and xit onto a cone to which they do not belong and this generates a
bias. For instance, to compute the distance between λi and the convex cone conv (ΛU), we could
use the support function and show that:
d (λi, conv (ΛU)) = inf
j∈{N1+1,...,N} (q′λj) −q′λi
in which λj is the j-th column of ΛU. Statistical methods to deal with inference in this setting
could be derived from recent work by Chernozhukov, Lee and Rosen but this is out of the
scope of this paper.
10The main diﬃculty there is to take into account that ω is a random function of zi and zj.
Constraints on linear factor models
The conditions of interpolation implies constraints on the linear factor model that can be imposed
when estimating the parameters involved in (20). They are developed in Appendix A.2.
Monte Carlo experiments
The set-up
The data generating process is supposed to be given by a linear factor model:
yit = αiItDi + f ′
in which the treatment eﬀect, αi, is homogeneous or heterogenous across local units (but not
time for simplicity) and the number of factors L is variable. Residuals εit are supposed to be
independently and identically distributed. We always include additive individual and time eﬀects,
i.e. λi = (λi1, 1, λi2, ...)′ and ft = (1, ft1, ft2...)′ as most economic applications would require. We
did not include any other explanatory variables than the treatment variable itself.
The data generating process is constructed around a baseline experiment and several alternative experiments departing from the baseline in diﬀerent dimensions such as the distribution
of residuals, the number of local units and periods, the correlation of treatment assignment and
factor loadings, the structure of factors, the support of factor loadings and the heterogeneity of the
treatment eﬀect, αi. Experiments are described in detail below. The Monte Carlo aspect of each
experiment is given by drawing new values of {εit}i=1,.,N,t=1,.,T only and the number of replications
is set to 1000.
In the baseline, individual and period shocks εit are drawn in a zero-mean and unit-variance
normal distribution and we experiment an alternative in which shocks are drawn in a uniform
distribution [−
3], the bounds being chosen to get a zero mean and a unit variance.
The numbers of treated units, N1 (resp. total, N) and the numbers of periods before treatment,
TD, (resp. total, T) as well as the number of factors L are ﬁxed at relatively small values in line
with our empirical application developed in the next section and more generally with data used
in the evaluation of regional policies. In the baseline experiment, we ﬁx (N1, N) = (13, 143),
(TD, T) = (8, 20) and L = 3 (including one additive factor). We also experiment with (N1, N) =
(25, 275), (TD, T) = (4, 10) and L varying in the set {2, 4, 5, 6}.
The values of factors ft and factor loadings, λi are drawn once and for all in each experiment.
Factors, ft, for t = 1, ., T, are drawn in a uniform distribution on (except the ﬁrst factor
which is constrained to be equal to 1). Alternatively, we also experiment in having the second
factor in ft given by a. sin(180.t/T) with a > 0 large enough.
The support of factor loadings, λi, is the same for treated units as for untreated units in
our baseline experiment. They are drawn in a uniform distribution on (except the second
factor loading which is constrained to be equal to 1). In an alternative experiment, we construct
overlapping supports for treated and untreated units. This is achieved by shifting the support of
factor loadings of treated units by .5 or equivalently by adding .5 to draws. In another experiment,
supports of treated and untreated units are disjoint by shifting the support of treated units by 1.
Because the original support is , this means that the intersection of the supports of treated
and non-treated units is now reduced to a point. Note that adding .5 (resp. 1) to draws of treated
units creates a correlation between factor loadings and the treatment dummy Di equal to .446
(resp. .706).
The treatment eﬀect is constant, αi = α, in our baseline experiment while in alternative
experiments, the treatment eﬀect is correlated with the second individual factor, the ﬁrst factor
loading, λi1 being the standard linear ﬁxed eﬀect. The heterogenous treatment parameter is thus
written as αi = α + r.
. This speciﬁc form is retained to make sure that the
average treatment on the treated is equal to α by construction as we have:
i=1 αi = α.
In practice, we ﬁx α = .3 which is a value close to ten times the one obtained in our empirical
application, and r = 1.
We evaluate six estimation methods:
1. A direct approach using pretreatment period observations for control and treated units and
post-treatment periods for the non treated only to estimate factors ft and λi in the equation:
yit (0) = f ′
as in Section 3.4. The estimation procedure follows Bai’s method and is based on an EM
algorithm which is detailed in Appendix A.2. A parameter estimate of α is then recovered
from equation (21) replacing the right-hand side quantities by their empirical counterparts.
This estimator is labelled “Interactive eﬀects, counterfactual”.
2. An approach whereby we estimate parameter α applying Bai’s method to the linear model
in which a treatment dummy is the only regressor:
Yit = αItDi + f ′
as in Section 3.3. The resulting estimator is labelled “Interactive eﬀects, treatment dummy”.
3. A matching approach (Subsection 3.5) by which equation (29) is ﬁrst estimated as in the ﬁrst
estimation method. This yields estimates of λi from which a propensity score discriminating
treated and untreated units is computed. We use a logit speciﬁcation for the score and
construct the counterfactual outcome in the treated group in the absence of treatment at
periods t ⩾TD using the kernel method proposed by Heckman, Ichimura and Todd .
If we denote the score predicted by the logit model by ˆµi, the counterfactual of the outcome
for a given treated local unit i at a given post-treatment period is constructed as:
bE (yit (0) |Di = 1) =
where Kh (·) is a normal kernel whose bandwidth is chosen using a rule of thumb .
An estimator of the average treatment on the treated is the average of
yit −bE (yit (0) |Di = 1) over the population of treated local units for dates t ⩾TD. The
resulting estimator is labelled “Interactive eﬀects, matching”.
4. An approach similar to “Interactive eﬀects, counterfactual” in which we impose the constraint λi = ΛUω(i) for any unit i when estimating (29). ΛU is the L × (N −N1) matrix
comprising untreated factor loadings and ω(i) are weights obtained in the synthetic control
method. The estimation method is detailed in Appendix A.2 and the estimator of α is recovered from (21) replacing right-hand side quantities by their empirical counterpart. This
estimator is labelled “Interactive eﬀects, constrained”.
5. The synthetic control approach (Subsection 3.6) whereby the average treatment on the
treated is obtained by averaging equation (24) over the population of treated units. The
resulting estimator is labelled “Synthetic controls”.
6. A standard diﬀerence-in-diﬀerences approach whereby we compute the FGLS estimator taking into account the covariance matrix of residuals (written in ﬁrst diﬀerence).
research presented in Brewer, Crossley and Joyce suggests that this is the appropriate procedure if assumptions underlying diﬀerence in diﬀerences are satisﬁed. The resulting
estimator is labelled “Diﬀ-in-diﬀs”.
In our simulations, the number of iterations for Bai’s method involved in methods (1) to (4)
is ﬁxed to 20, and the number of iterations for the EM algorithm involved in method (1) and (4)
is ﬁxed to 1. When an estimation method using Bai’s approach is implemented, we use the true
number of factors.11
Our parameter of interest is α and we report the empirical mean, median and standard error of each
estimator for every Monte-Carlo experiment. Results in the baseline case are presented in column
1 of Table 1, and unsurprisingly, show that the estimated treatment parameter exhibits little bias
for all methods controling for interactive factors: “Interactive eﬀects, counterfactual”, “Interactive
eﬀects, treatment dummy”, “Interactive eﬀects, matching”, “Interactive eﬀects, constrained”and
“Synthetic controls”. Similarly, the method of “Diﬀ-in-diﬀs”is unbiased in spite of not accounting
for interactive factors since factor loadings are orthogonal to the treatment indicator in the baseline
experiment.
Interestingly, among methods allowing for interactive factors, those with constraints are the
ones achieving the lowest standard errors (“Interactive eﬀects, constrained”and “Synthetic controls”) since using constraints that bind in the true model increases identiﬁcation power. Note also
that the standard error is larger when using the method “Interactive eﬀects, counterfactual”than
when using the method “Interactive eﬀects, treatment dummy”as the structure of the true model
after treatment in the treated group is not exploited. "Diﬀ-in-diﬀs" standard errors lie between
those values.
In Columns 2 and 3 of Table 1, we report results when shifting by .5 or 1 the support of
individual factors for the treated. These shifts have two consequences. First, the validity conditions
11Monte-Carlo simulations are implemented in R. Weights ω(i) in methods (4) and (5) are computed using the
R procedure lsei and the minimization algorithm solve.QP.
are now violated for interactive eﬀect estimation which uses support constraints (“Interactive
eﬀects, constrained”) and for synthetic controls. Second, they make factor loadings correlated
with the treatment dummy. Results show that all methods are severely biased except “Interactive
eﬀects, counterfactual”, “Interactive eﬀects, treatment dummy” and more surprisingly “Diﬀ-indiﬀs”, a case which we investigate further below. The two ﬁrst methods are designed to properly
control for interactive eﬀects and factor loadings whatever the assumption about supports or about
correlations between factor loadings and treatment.
The method “Interactive eﬀects, matching”does not work well because non-treated units close
to treated units in the space of factor loadings are hard to ﬁnd since the support for the treated has
been shifted. As expected, the bias obtained for “Interactive eﬀects, constrained”and “Synthetic
controls” is large. These methods indeed impose that individual eﬀects of treated units can be
expressed as a linear combination of individual eﬀects of non-treated units. These constraints are
violated with a positive probability when the treated unit support is shifted by .5, and always
violated when the support is shifted by 1.
[ Insert Table 1 ]
To investigate further the cause of the surprising small bias of “Diﬀ-in-diﬀs”in the previous
Table, we modiﬁed the structure of factors in the experiment. The ﬁrst factor in ft is now given
by 5. sin(180.t/T). Table 2 shows that the “Diﬀ-in-diﬀs”method can generate much larger biases
in this alternative setting while biases of other methods remain the same. It is even the case
that small sample biases of “Interactive eﬀects, counterfactual”, “Interactive eﬀects, treatment
dummy”become smaller in this alternative experiment.
[ Insert Table 2 ]
Results reported in Table 3 replicate the baseline experiment by drawing simulated residuals
in a uniform distribution
instead of a normal distribution. Biases and standard errors
are much smaller, yet all previous conclusions hold.
[ Insert Table 3 ]
We then make the number of factors vary between two and six (including individual and time
additive eﬀects) to assess to what extent the accuracy of estimates decreases with the number of
factors. Results reported in Table 4 show that for the ﬁrst three methods “Interactive eﬀects, counterfactual”, “Interactive eﬀects, treatment dummy”and “Interactive eﬀects, matching”, the bias
does not vary much and remains below 10%. Interestingly, whereas the standard error markedly
increases with the number of factors for the method “Interactive eﬀects, counterfactual”, it increases much more slowly for the method “Interactive eﬀects, treatment dummy”. This occurs
because factor loadings of the treated are estimated using pre-treatment periods only in the former case whereas in the latter case all periods contribute to the estimation of factor loadings.
When using methods with constraints “Interactive eﬀects, constrained”and “Synthetic controls”,
the bias can be larger than 10% but standard errors remain small. As in the baseline case, the
bias of “Diﬀ-in-diﬀs”is rather small although we know from the previous analysis that changing
the structure of factors could make the bias larger.
[ Insert Table 4 ]
We also experimented with shorter pre-treatment and post-treatment periods by ﬁxing (TD, T) =
(4, 10). Interestingly, results reported in Table 5 show that among methods taking into account
interactive factors, the bias does not vary much except for the method “Interactive eﬀects, counterfactual”for which it becomes close to 100%. This can be explained by the poor identiﬁcation
of the model since the speciﬁcation includes three individual factors which are estimated from
three pre-treatment periods only. Standard errors unsurprisingly decrease with sample size for all
[ Insert Table 5 ]
We also ran alternative simulations using data comprising a larger number of local units,
(N1, N −N1) = (25, 250). Results reported in Table 6 show that, among methods taking into
account interactive factors, the bias is close to zero for the ﬁrst three methods “Interactive eﬀects,
counterfactual”, “Interactive eﬀects, treatment dummy”and “Interactive eﬀects, matching”. The
bias is larger for the methods “Interactive eﬀects, constrained” and “Synthetic controls”, but
smaller for “Diﬀ-in-diﬀs”.
[ Insert Table 6 ]
Finally, experiments in which treatments are heterogenous yield results close to those with homogenous treatments and to save space are not reported here.
There are two interesting conclusions in this analysis which bear upon our empirical application. First, the method of “Interactive eﬀect, counterfactual” seems to be dominated in terms
of bias and precision by the method “Interactive eﬀect, treatment dummy” in all experiments
and we shall thus retain only the second method. Second, the three methods “Interactive eﬀects,
matching”, “Interactive eﬀects, constrained”and “Synthetic controls”seem to behave similarly.
Therefore, we shall retain only one method, synthetic controls, for our application.
Empirical Application
This application is motivated by the evaluation reported in Gobillon et al. of an enterprise
zone program implemented in France on January 1, 1997.
A survey of enterprise zone programs in the US and the UK is presented in this article as well
as many particulars that we do not have the space to develop here.12 The ﬁscal incentives given
by the program to enterprise zones were uniform across the country and consisted in a series of
tax reliefs on property holding, corporate income, and above all on wages. The key measure was
that ﬁrms needed to hire at least 20% of their labor force locally (after the third worker hired) in
order to be exempted from employers’contributions to the national health insurance and pension
system. This is a signiﬁcant tax exemption that represents around 30% of whole labor costs (gross
wage). It is expected that this measure would aﬀect labor demand for residents of these zones and
decrease unemployment. This is why we analyzed the impact of such a program on unemployment
entries and exits over this period.
We restrict our analysis to the Paris region in which 9 enterprise zones ("Zones Franches
Urbaines") were created in 1997. Municipalities or groups of municipalities had to apply to the
program and projects were selected taking into account their ranking given by a synthetic indicator. This indicator whose values have never been publicly released, aggregates ﬁve criteria: the
population of the zone, its unemployment rate, the proportion of youngsters (less than 25 years
old), the proportion of workers with no skill, and ﬁnally the income level in the municipality in
which the enterprise zone would be located. An additional criterium is that the proposed zone
should have at least 10,000 inhabitants. Nevertheless, the views of local and central government
12A data appendix in Section C completes this brief presentation.
representatives who intervened in the geographic delimitation of the zones also played a role in the
selection process. It thus suggests that although the selection of treated areas should be conditioned on the criteria of the synthetic indicator, it is likely that there is suﬃcient variability in the
selection process due to political tampering. In consequence, assumptions underlying matching
estimates are not a priori invalid if observed heterogeneity is controled for. Indeed, the supports
of the propensity score in treated and non treated municipalities largely overlap though there are
some outliers (see Table B2 in the Appendix).
In Gobillon et al. , we provided evidence that controling for the eﬀect of individual
characteristics of the unemployed when studying unemployment exits only moderately aﬀect the
treatment evaluation. For the sake of simplicity, this is why we use raw data at the level of each municipality in the present empirical analysis. Furthermore, the destination after an unemployment
exit, be it a job, non employment or unknown, is quite uncertain in the data since unemployment
spell is often terminated because the unemployed worker is absent at a control. Many exits to a
job might be hidden in the category “Absence at a control”. The empirical contribution of our
paper is that we investigate not only exits to a job as in Gobillon et al. but also unknown
exits as well as entries into unemployment. More generally, we assess the robustness of the results when using estimation methods which deal with the presence of a larger set of unobserved
heterogeneity terms than diﬀerence in diﬀerences.
We use the historical ﬁle of job applicants to the National Agency for Employment (“Agence
Nationale pour l’Emploi” or ANPE hereafter) for the Paris region. This dataset covers the large
majority of unemployment spells in the region given that registration with the national employment agency is a prerequisite for unemployed workers to claim unemployment beneﬁts in France.
We use a ﬂow sample of unemployment spells which started between July 1989 and June 2003
and study exits from unemployment between January 1993 and June 2003. This period includes
the implementation date of the enterprise zone program and allows us to study
the eﬀect of enterprise zones not only in the short run but also in the medium run. These unemployment spells may end when the unemployed ﬁnd a job, drop out of the labor force, leave
unemployment for an unknown reason or when the spell is right censored.
Regarding the geographic scale of analysis, given that enterprise zones are clusters of a significant size within or across municipalities, it would be desirable to try to detect the eﬀect of the
policy at the level of an enterprise zone and comparable neighboring areas. Nevertheless, our data
do not allow us to work at such a ﬁne scale of disaggregation and we retain municipalities as our
spatial units of analysis. Municipalities have on average twice the population of the enterprise
zone they contain. In consequence, any eﬀect at the municipality level measures the eﬀect of local
job creation net of within-municipality transfers.
The Paris metropolitan region on which we focus is inhabited by 10.9 million people and
subdivided into 1,300 municipalities. We only use municipalities which have between 8,000 and
100,000 inhabitants as every municipality comprising an enterprise zone has a population within
this range.
Using propensity score estimation, we select control municipalities whose score is
close to the support of the score for treated municipalities and this restricts further our working
sample to 148 municipalities (135 controls and 13 treatments). On average, about 300 unemployed
workers ﬁnd a job each semester in each of those municipalities. In view of these ﬁgures, we chose
semesters as our time intervals since using shorter periods would generate too much sampling
variability.
Descriptive statistics relative to exits to a job, exits to non-employment, and exits for unknown
reasons can be found in Appendix C.
In Table 7, we report estimation results of the enterprise zone treatment eﬀect obtained with the
most promising methods that were evaluated in the Monte Carlo experiments.13 As explained at
the end of the previous section, we use the interactive eﬀect model with a treatment dummy and
the synthetic control approach, and contrast them with the most popular method of diﬀerence in
diﬀerences.
Standard errors of the “Interactive eﬀect, treatment dummy” estimates are computed using
independently and identically distributed disturbances, an assumption we justify below. More
originally, we derive a conﬁdence interval for the synthetic control estimate which, as far as we
13The only slight modiﬁcation is that for the FGLS ﬁrst diﬀerence estimate, the covariance matrix is kept general
enough to allow for serial correlation of unknown form.
know, has not been derived in the literature. We construct this conﬁdence interval by inverting a
test statistic whose distribution is obtained by using permutation between local units under the
(admittedly strong) assumption of independently and identically distributed disturbances across
local units.
The procedure is as follows. Set the treatment eﬀect to α0 and substract this value to post
treatment outcomes of treated units. Next, draw 1000 times without replacement 13 units in
the whole population (treated and controls) and consider them as the new treated units while
the other 135 are the new controls. Construct synthetic controls in each sample and estimate
treatment eﬀects. Derive from the empirical distribution of estimates the p-value associated to
the null hypothesis that the treatment parameter is equal to zero. Inverting this test for diﬀerent
values of α0 yields the conﬁdence interval that is reported in Table 7. In practice, we apply the
procedure for a large range of values for α0 around the estimated treatment eﬀect. Bounds of the
conﬁdence interval at the 95% level are the values of α0 at which the p-values are equal to 5%.
We analyze three outcomes at the level of municipalities constructed for each 6-month period
between July 1993 and June 2003: exit from unemployment to a job, exit from unemployment
for unknown reasons and entry into unemployment. The outcome describing unemployment exits
(to a job or for unknown reasons) is deﬁned as the logarithm of the ratio between the number
of unemployed workers exiting during the period and the number of unemployed at risk at the
beginning of the period. Entries are similarly deﬁned. Table 7 reports results using our three
estimation methods for each outcome.
Starting with exits to a job, we ﬁnd a small positive and signiﬁcant treatment eﬀect using
the interactive eﬀect method in line with the “Diﬀ-in-diﬀs” estimate and with the ﬁndings in
Gobillon et al. in which we used diﬀerence in diﬀerences but with a more limited number
of periods.14
The size of the interactive eﬀect estimate is slightly larger than the diﬀerencein-diﬀerences estimate and tends to increase with the number of factors that are included in
the estimation. In contrast, the “Synthetic control” estimate is negative and surprisingly quite
precisely estimated.
[ Insert Table 7 ]
In the Monte Carlo experiment, those diﬀerences were interpreted as an issue of disjoint sup-
14This was based on an analysis distinguishing short-run and long-run eﬀects of the program.
ports. We plot in Figure 1, the additive local eﬀect (i.e. the factor loading associated to the constant factor) and the multiplicative factor loading for each control unit (circle) and each treated
unit (triangle) in the case where the model includes only two factors. This graph does not exhibit
any evidence against the null hypothesis that the support of factor loadings for the treated units
is included in the corresponding support for the controls. We tried to construct a test using permutation techniques and we failed to reject the null hypothesis of inclusion of the
supports. In the absence of formal analyses of this test in the literature, we do not know however
if this result is due to the low power of such a test.
[ Insert Figure 1 ]
Another interpretation of the discrepancy between synthetic controls and interactive eﬀects would
come from the presence of serial correlation. When a local eﬀect only is considered as in the
diﬀerence-in-diﬀerences method, serial correlation is still substantial and the estimate of the autocorrelation of order 1 is around .35. In contrast, estimates of the serial correlation in the interactive
eﬀect model are close to zero. Factor models “exhaust”serial time dependence and this is also
true for spatial dependence.15 In contrast, we do not know much about the behavior of synthetic
controls when serial correlation and spatial correlation are substantial. Interestingly, the within
estimate without any correction for serial correlation is also on the negative side and close to the
synthetic control estimate.
Results for other outcomes conﬁrm the diagnostic that synthetic control estimates seem to
have a diﬀerent behavior than interactive eﬀect and diﬀerence-in-diﬀerences estimates. While interactive eﬀect estimates of the treatment eﬀect are undistinguishable from zero when we analyze
exits from unemployment for unknown reasons, diﬀerence in diﬀerences yield a positive but insigniﬁcant estimate and synthetic controls a positive and signiﬁcant estimate. As we have reasons
to believe that the treatment eﬀect should be larger for the outcome recording exits to a job than
for the outcome recording exits for unknown reasons, synthetic control estimates seem incoherent.
Nonetheless, it is true that synthetic control and interactive eﬀect estimates for the treatment
15This result is obtained using a Moran test when the distance matrix is constructed using the reciprocal of the
geographical distance. Other contiguity schemes (for instance, when using discrete distance matrices constructed
using 5 and 10km thresholds) capture positive spatial correlations although they diminish with the number of
eﬀect on entries are very similar while diﬀerence-in-diﬀerences estimates seem too large.
As a robustness check, we report in Table 8 the treatment eﬀect estimates when the propensity
score is controlled for. In the interactive eﬀect and diﬀerence-in-diﬀerences approaches, this is done
by including among the regressors the propensity score interacted with a trend t/T to mimic the
presence of the propensity score in levels in the ﬁrst diﬀerence equation as in Gobillon et al. .
We also include the propensity score among variables used in the construction of synthetic controls.
Results obtained using the method “Interactive eﬀect, treatment dummy”are very close to those
obtained in the baseline case except when studying entries. The treatment eﬀect estimate is larger
when the speciﬁcation includes four or less factors (including an additive one). Treatment eﬀects
for the other outcomes — exits to a job and exits for unknown reasons — when using synthetic
controls are now close to zero. Results obtained with diﬀerence in diﬀerences are similar to those
obtained previously. In summary, once again, synthetic controls estimates are more sensitive to
the speciﬁcation than factor models and diﬀerence-in-diﬀerences estimates. In conclusion, we have
reasons to believe that interactive eﬀect estimates are more credible than other estimates in our
application.
[ Insert Table 8 ]
Conclusion
In this paper, we compared diﬀerent methods of estimation of the eﬀect of a regional policy using
time-varying regional data. Spatial dependence is captured by a linear factor structure that permits conditioning on an extended set of unobserved local eﬀects when applying methods of policy
evaluation. We show how diﬀerence-in-diﬀerences estimates are biased and how linear factor methods following Bai can be applied. We compare diﬀerent versions of these interactive eﬀect
methods with a synthetic control approach and with a more traditional diﬀerence-in-diﬀerences
approach in Monte Carlo experiments. We ﬁnally apply these methods to the evaluation of an
entreprise zone program introduced in France in the late 1990s. In both Monte Carlo experiments
and the empirical application, interactive eﬀect estimates fare well with respect to competitors.
There are quite a few interesting extensions worth exploring in empirical analyses.
First, there is a tension between two empirical strategies in regional policy evaluations . On the one hand, choosing areas in the neighbor-
hood of treated areas as controls might lead to biased estimates since neighbors might be aﬀected
by spillovers or contamination eﬀects of the policy. On the other hand, non neighbors might be
located too far away from the treated areas to be good matches and therefore good controls. This
paper tackles this issue in a somewhat automatic way by letting factor loadings picking out spatial
correlation in the data. A richer robustness analysis would allow to modify the populations of
controls and treatments by playing on the distance between municipalities and locally treated
areas as we did in Gobillon et al. .
Second, it is easy to extend the interactive eﬀect procedures we have analyzed to the case in
which the treatment date varies with time. This is particularly easy in the linear factor model
and this set-up is used by Kim and Oka . In addition, the variability of treatment dates
facilitates the identiﬁcation of the treatment eﬀect since the rank condition (14) used in Section 3.3
for identiﬁcation purposes is no longer needed. The synthetic control approach can also be adapted
when the treatment date varies across treated units by using a variable number of pre-treatment
outcomes to construct the synthetic control.
A word of caution is also in order in case of extrapolation. When supports of exogenous variables and factor loadings of the treated units are not included in the corresponding supports of the
control units, we have seen that unconstrained interactive eﬀect estimation methods perform better
than matching methods such as a constrained Bai method or synthetic controls. This conclusion
is nonetheless due to our Monte Carlo setting in which linear factor models only are considered.
If models were non linear, this asymmetry between methods would disappear. Extrapolation is
indeed a case in which any technique needs some untestable assumptions to achieve identiﬁcation.
Bounds on outcome variations might however lead to partial identiﬁcation of treatment eﬀects.