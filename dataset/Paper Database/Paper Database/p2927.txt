IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 24, NO. 5, MAY 2015
Cross-Domain Person Reidentiﬁcation Using
Domain Adaptation Ranking SVMs
Andy J. Ma, Jiawei Li, Pong C. Yuen, Senior Member, IEEE, and Ping Li
Abstract—This paper addresses a new person reidentiﬁcation
problem without label information of persons under nonoverlapping target cameras. Given the matched (positive) and unmatched
(negative) image pairs from source domain cameras, as well as
unmatched (negative) and unlabeled image pairs from target
domain cameras, we propose an adaptive ranking support vector
machines (AdaRSVMs) method for reidentiﬁcation under target
domain cameras without person labels. To overcome the problems
introduced due to the absence of matched (positive) image pairs
in the target domain, we relax the discriminative constraint to
a necessary condition only relying on the positive mean in the
target domain. To estimate the target positive mean, we make
use of all the available data from source and target domains
as well as constraints in person reidentiﬁcation. Inspired by
adaptive learning methods, a new discriminative model with
high conﬁdence in target positive mean and low conﬁdence in
target negative image pairs is developed by reﬁning the distance
model learnt from the source domain. Experimental results show
that the proposed AdaRSVM outperforms existing supervised or
unsupervised, learning or non-learning reidentiﬁcation methods
without using label information in target cameras. Moreover, our
method achieves better reidentiﬁcation performance than existing
domain adaptation methods derived under equal conditional
probability assumption.
Index Terms—Person re-identiﬁcation, domain adaptation,
target positive mean, adaptive learning, ranking SVMs.
I. INTRODUCTION
A. Background
N RECENT years, person re-identiﬁcation across a camera
network comprising multiple cameras with non-overlapping
views has become an active research topic due to its
Manuscript received July 7, 2014; revised December 24, 2014; accepted
January 9, 2015. Date of publication January 22, 2015; date of current version
March 13, 2015. This work was supported by the Hong Kong Research Grants
Council-General Research Fund through the Hong Kong Baptist University
under Grant 212313 and Grant 12202514. The work of A. J. Ma and P.
Li was supported in part by the Ofﬁce of Naval Research, Arlington, VA,
USA, under Grant N00014-13-1-0764 and in part by the Air Force Ofﬁce
of Scientiﬁc Research, Arlington, VA, USA, under Grant FA9550-13-1-0137.
The associate editor coordinating the review of this manuscript and approving
it for publication was Prof. Carlo S. Regazzoni.
A. J. Ma is now with the Department of Computer Science, Johns Hopkins
University, Baltimore, MD 21218 USA. He was with the Department of
Computer Science, Hong Kong Baptist University, Hong Kong (e-mail:
 ).
J. Li is with the Department of Computer Science, Hong Kong Baptist
University, Hong Kong (e-mail: ).
P. C. Yuen is with the Department of Computer Science, Hong Kong Baptist
University, Hong Kong, and also with the BNU-HKBU United International
College, Zhuhai 519085, China (e-mail: ).
P. Li is with the Department of Statistics and Biostatistics, and the
Department of Computer Science, Rutgers University, Piscataway, NJ 08854
USA (e-mail: ).
Color versions of one or more of the ﬁgures in this paper are available
online at 
Digital Object Identiﬁer 10.1109/TIP.2015.2395715
Comparison between person images from different datasets (better
viewed in color): matched image pairs in (a) PRID and (b) VIPeR 
dataset. There are three major differences
between these two image
sets: 1) different backgrounds; 2) different viewpoint changes; 3) different
illumination conditions.
importance in many camera-network-based computer vision
applications. The goal of person re-identiﬁcation is to
re-identify
disappears
ﬁeld-of-view of a camera and appears in another. Matching
individuals over disjoint cameras can be substantially challenging when variations in illumination condition, background,
human pose and scale are signiﬁcant among those views.
Moreover, the temporal transition time between cameras varies
greatly for each individual which makes the person reidentiﬁcation task even harder.
To address this problem, existing schemes mainly focus
on developing either robust feature representations – 
or discriminative learning models – . For the discriminative learning methods, it is generally assumed that the
label information of persons is available for training. With the
person labels, matched (positive) and unmatched (negative)
image pairs are generated to train the discriminative distance
model. While these methods could achieve encouraging
re-identiﬁcation performance, the assumption that label information is available for all the cameras, could only be
practically feasible in a small-scale camera network.
Contrarily, in the case of large-scale camera network,
collecting the label information of every training subject from
every camera in the network can be extremely time-consuming
and expensive. Therefore, labels of the training subjects may
not be able to be collected from certain cameras. This renders
existing approaches inapplicable, since the person labels are
not available. Apart from this reason, signiﬁcant inter-camera
variations as exempliﬁed in Fig. 1 would also lead to dramatic
performance deterioration, when the distance model learnt
from other camera set with label information is directly applied
to the cameras missing person labels.
These setbacks pose the need for new methods to handle the
afore-described person re-identiﬁcation issue in the large-scale
camera network setting.
1057-7149 © 2015 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted,
but republication/redistribution requires IEEE permission. See for more information.
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 24, NO. 5, MAY 2015
B. Motivation
Motivated by domain adaptation approach (see for a
review), we consider data from the camera set with label
information as the source domain; while data from the camera
set missing label information as the target domain. Here, we
denote the source and target domains as s and t, respectively. Due to non-trivial inter-camera variations as indicated
in Fig. 1, the source and target joint distributions of the positive
or negative tag y and feature vector z for an image pair are
supposed to be different, i.e. Prs(y, z) ̸= Prt(y, z). In order to
overcome the problem of the mismatch of marginal distributions, a mapping , s.t. Prs((z)) ≈Prt((z)), can be learnt
via domain adaptation techniques, see , . In general,
existing unsupervised domain adaptation schemes assume
that, after projection, such  also satisﬁes the equal conditional probability condition, i.e. Prs(y|(z)) ≈Prt(y|(z)).
Since the conditional probability Prs(y|(z)) or Prt(y|(z))
can be interpreted as classiﬁcation score, the condition that
Prs(y|(z)) ≈Prt(y|(z)) implies an equivalence of the
distance models in the source and target domains. In this case,
existing person re-identiﬁcation algorithms, see – , can
be employed to learn the distance model in the source domain
(consisting of projected data with positive and negative image
pairs generated by the label information), which can be
applied to the target domain without signiﬁcant performance
degradation.
However, it is almost impossible to verify the validity of
the assumption that Prs(y|(z)) ≈Prt(y|(z)) in practice.
As a result, there is no way to guarantee that the distance
model learnt from the projected data in the source domain is
equivalent to the target one. Thus, we propose to learn the
target distance model using data from both source and target
domains. If a small amount of positive and negative data is
available in the target domain, multi-task learning , 
or adaptive learning methods , can be employed to
learn the distance model for the target cameras without the
assumption that the conditional distributions are equal with
each other in the source and target domains. However, in
large-scale camera networks, it is still time-consuming and
expensive to label even a small amount of person images. Due
to the absence of label information under target cameras, these
domain adaptation techniques – cannot be applied
directly. To ensure the equality of the conditional probabilities
in the source and target domains, this paper will study on
how to estimate the target label information and incorporate
the labeled data from source domain with the estimated target
label information for discriminative learning.
C. Contributions
The contributions of this paper are two-fold.
• We develop a new method to estimate target positive
information based on the labeled data from the source domain,
negative data (unmatched image pairs generated from nonoverlapping target cameras) and unlabeled data from the target
domain. Without positive image pairs generated by the label
information of persons, we propose to relax the discriminative
constraint into a necessary condition to it, which only relies
on the mean of positive pairs. Since source and target domains
must be related, we estimate the target positive mean by the
labeled data from the source domain. While the estimation
based on the source domain data may deviate from the true
target positive mean, we propose to estimate it in another way
that potential positive data is selected from the unlabeled data
in the target domain by maximizing the positive joint distribution with properties and constraints in person re-identiﬁcation.
To further reduce the estimation error, the two estimations of
the target positive mean are combined to determine the optimal
estimation by the training data.
• We propose a novel Adaptive Ranking Support Vector
Machines (AdaRSVM) method to rank the individuals for
person re-identiﬁcation. Inspired by adaptive learning methods , , RankSVM is employed to learn a distance
model by the labeled data from the source domain. After that,
the estimated target positive mean and target negative data
are used to learn the discriminative model for target domain
by adaptively reﬁning the distance model learnt in the source
Although the motivation of this paper is similar to that in
our conference version , the proposed algorithm is almost
different from the previous one. In this paper, we propose a
new method (different from that in ) to better estimate the
target positive mean by all the available information from both
source and target domains. Besides, the asymmetric domain
adaptation algorithm in this paper is better than the symmetric
one in the previous method, since it is more important to train
a discriminative model for the target domain (rather than both).
Moreover, more experiments have been performed to evaluate
the proposed method, e.g. we add more datasets for evaluation
and compare with two domain adaptation algorithms and
appearance-based methods in this paper.
D. Organization
The rest of this paper is organized as follows. We will
ﬁrst give a brief review on existing person re-identiﬁcation
and domain adaptation methods. Section III will report the
proposed method. Experimental results and conclusion are
given in Section IV and Section V, respectively.
II. RELATED WORKS
Before introducing the proposed method, we give a brief
review on person re-identiﬁcation and domain adaptation in
this section.
A. Person Re-Identiﬁcation
In order to ensure that feature representation of the
person image is less sensitive to large inter-camera variations, many existing re-identiﬁcation methods focus on
extracting robust features. Popular ones include SIFT , ,
texture – , , , color distribution , ,
space-time methods , and pictorial structures .
Besides feature extraction, discriminative distance learning
methods are proposed to further improve the re-identiﬁcaiton
performance. In , person re-identiﬁcation was formulated
MA et al.: CROSS-DOMAIN PERSON REIDENTIFICATION USING DOMAIN ADAPTATION RANKING SVMs
as a ranking problem and the RankSVM model is learnt by
assigning higher conﬁdence to the positive image pairs and
vice versa. Denote xi as the feature vector for image i, x+
for j = 1, · · · , n+
as feature vectors of the images with the
same identity, and x−
il for l = 1, · · · , n−
as feature vectors
of the images with different identities, where n+
the number of the matched (unmatched) observations. The
absolute difference vector for the positive (resp. negative)
image pair of xi and x+
ij (resp. x−
il ) is calculated by z+
ij ) (resp. z−
il = d(xi −x−
il )), where d is an entry-wise
function of absolute values. The weight vector w in RankSVM
is obtained by solving the following optimization problem,
s.t. wT (z+
il ) ≥1 −ξijl,
ξijl ≥0, ∀i, j,l
where ξijl is the slack variable and C is a positive parameter.
Similar to RankSVM, Zheng et al. proposed a Relative
Distance Comparison (RDC) method using a second-order
distance learning model. This method is able to exploit higherorder correlations among different features, compared with
RankSVM. In order to solve the computational complexity
issues in RankSVM and RDC, a Relaxed Pairwise Metric
Learning (RPML) method was proposed by relaxing the
original hard constraints, which leads to a simpler problem
that can be solved more efﬁciently.
supervised
methods , , , Kuo et al. proposed an online-learnt
appearance afﬁnity model to decrease the required number
of labeled samples under some speciﬁc assumptions. On the
other hand, an adaptive feature weighting method was
proposed in under the observation that the universal
model may not be good for all individuals. Different
traditional
per-individual
identiﬁcation
al. addressed a watch list
(set) based
veriﬁcation problem and proposed to transfer the information
from non-target person data to mine the discriminative
information for the target people in the watch list.
B. Domain Adaptation
The main objective of domain adaptation approach is to
adapt the classiﬁcation model learnt from the source domain
to target domain without serious deterioration of recognition
performance. The target domain refers to data from the target
task usually without or with only a small amount of labeled
training data, while there is plenty of labeled training data
in the source domain. In the last decade, many algorithms
(see for a review) have been proposed to solve the joint
distribution mismatch problem, i.e. Prs(y, z) ̸= Prt(y, z).
unsupervised
adaptation,
re-weighting or covariate shift approach learns the
classiﬁcation
re-weighting
samples in the source domain to minimize the approximated
empirical classiﬁcation error in the target domain. To estimate
the sample weights calculated by Prs(z) dividing Prt(z),
many density ratio estimation methods have been
re-weighting,
representation
feature vectors to reduce the difference between features in
the source and target domains. Blitzer et al. proposed
a structural correspondence learning algorithm by selecting
pivot features for natural language processing, while other
methods , , – try to learn a mapping ,
s.t. Prs((z)) ≈Prt((z)). Without label information in the
target domain, these methods assume that the conditional
probabilities are equal to each other in the source and
target domains. And it was shown in that the empirical
classiﬁcation error can be very small under this assumption.
However, this assumption may not be valid, so that the
recognition performance may deteriorate.
For supervised domain adaptation with target labeled data,
existing methods learn an informative prior using the source
domain data and estimate the target model based on such
prior , , , . Based on the assumption that the
recognition tasks in the source and target domains are related,
multi-task learning methods , can be employed to discover the task relationship and learn the classiﬁcation models
in the source and target domains simultaneously. Unlike supervised domain adaptation techniques, unlabeled data in the
target domain are considered together with the labeled data
to learn the target classiﬁcation model for better performance
in – . However, labeling person images for each camera
is expensive, especially in large-scale camera networks applications. Thus, existing supervised or semi-supervised domain
adaptation algorithms cannot be employed directly.
III. DOMAIN ADAPTATION RANKING SVMs FOR
PERSON RE-IDENTIFICATION
To present the algorithm more clearly, let target domain
contain images from a pair of (two) cameras a and b. For
multiple target cameras, multiple classiﬁcation models can be
trained for each camera pair. Since feature extraction is not the
focus of this paper, all general feature representation methods,
e.g. color histogram, can be used to extract feature vectors for
the person images. As indicated in , the absolute difference
space shows some advantages over the common difference
space, so we follow to use the absolute difference vectors
for both positive and negative image pairs. Given two feature
vectors xa
j representing two images under two cameras
a and b, the absolute difference vector zij is deﬁned by
zij = d(xa
j(1)|, · · · , |xa
where x(r) is the r-th element of the input vector x and R is
the dimension of x.
The available training data is introduced as follows. In the
source domain, label information is available, so difference
vectors of positive and negative image pairs can be generated
and denoted as z+
sij and z−
skl, respectively. For the target
domain, the label information of persons is not available, so
positive image pairs cannot be generated. However, negative
image pairs can be easily generated, because same person
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 24, NO. 5, MAY 2015
Proposed domain adaptation framework for person re-identiﬁcation.
cannot be presented at the same instant under different
non-overlapping cameras. Denote the difference vectors for
the target negative image pairs as z−
tij. In addition, unlabeled
image pairs in the target domain are also available and the
unlabeled difference vector is denoted as zu
tkl. The block
diagram of the proposed method is shown in Fig. 2. With
skl in the source domain and z−
tkl in the target
domain, we propose a new method to estimate the target
positive mean m+
t , which will be discussed in Section III-A.
Then, the labeled data from the source domain are used to train
a source distance model ws by employing RankSVM .
At last, the target distance model wt is learnt by the proposed
adaptive ranking SVMs method, which will be presented
in Section III-B.
A. Estimating Positive Mean in Target Domain
Since different feature elements in a feature vector give
different importance in identifying a person, we follow to
use the weighted summation of the absolute difference vector
to calculate the conﬁdent score for the image pairs in the target
domain, i.e. wT
t ztij, where wT
t denotes the transposition of the
target weight vector. If positive image pairs are available,
the scores of positive image pairs must be larger than those of
the negative ones for a discriminative weight vector wt, i.e.
∀i, j, k,l
However, positive image pairs are not available in the target
domain, so we cannot obtain the absolute difference vectors
tij in practice. One way to solve this problem is to determine
the weight vector wt by assigning smaller values to the
difference vectors z−
tkl of negative image pairs using oneclass SVM . Nevertheless, it is possible that the scores of
positive image pairs also decrease when minimizing those of
the negative ones. Thus, it cannot be guaranteed that the learnt
weight vector wt satisﬁes the discriminative constraint (3).
In order to deal with this problem, we propose to learn
the weight vector wt by imposing a necessary condition to
constraint (3).
Taking the summation of constraint (3) over the difference
vectors z+
tij of positive image pairs for all i and j, it has
t denote the mean of positive image pairs in the target
domain. Therefore, a necessary condition to constraint (3) is
given by equation (4) such that the score of the positive mean
is larger than those of the negative image pairs.
While there is no positive data in the target domain, the
target positive difference vectors z+
tij are difﬁcult to estimate
due to the highly data imbalance problem. According to
equation (4), the target positive mean m+
can be used to
give a necessary condition to the discriminative constraint (3).
On the other hand, in domain adaptation, the distance between
source and target domain distributions can be measured by the
distance between the empirical means of the two domains .
Moreover, in one-class classiﬁcation problems, the positive
mean is usually used to represent the positive distribution .
Thus, we propose to estimate the target positive mean for
domain adaptation in person re-identiﬁcation. Although it is
still challenging to estimate the target positive mean without
any positive data, we solve this problem by using both the
labeled data in the source domain and the unlabeled data in
the target domain.
1) Estimating Target Positive Mean by Labeled Data in
Source Domain: To estimate the target positive mean, we
propose to make use of the data with label information of
persons in the source domain. With the label information,
the true means of positive and negative image pairs in the
source domain can be calculated and denoted as m+
respectively. Since the source and target domains are related,
the positive and negative distributions in the source domain
must be related to those in the target domain. We suppose
the relationship can be modeled in a way that the difference
between the positive and negative means in the source domain
is close to that in the target domain, i.e.
denote the target genuine positive and
negative means, respectively.
Since not all of the negative data in the target domain are
available, the true negative mean m−
cannot be calculated.
Instead, we can estimate the negative mean m−
t by the available negative difference vectors z−
tij. With equation (5), the
positive mean in the target domain can be estimated by the
following equation,
The upper bound of the estimation error using equation (6) is
Since lots of negative image pairs can be obtained from
the non-overlapping target cameras, the estimated mean of
negative pairs is close to the true one. Under the assumption
given by equation (5), the upper bound of the estimation error
for the positive mean in the target domain is small.
MA et al.: CROSS-DOMAIN PERSON REIDENTIFICATION USING DOMAIN ADAPTATION RANKING SVMs
2) Estimating Target Positive Mean by Unlabeled Data
in Target Domain: Utilizing the labeled data in the source
domain, equation (6) estimates the target positive mean without using the unlabeled data zu
tkl in the target domain. On the
other hand, m+
t1 may not be a good estimation, if the assumption given by equation (5) is not valid. Therefore, we propose
to estimate the target positive mean in another way based on
the target domain data in this subsection.
Denote the mean calculated by the difference vectors of all
the image pairs in the target domain as mt. It can be calculated
by the following equation,
where Nt, N+
denote the number of the overall,
positive and negative image pairs, respectively. With equation (8), the mean of positive image pairs can be estimated
by the following equation,
t = (Ntmt −N−
However, N+
are difﬁcult to compute, if target
positive samples are not available. On the other hand, the
estimation error for the target positive mean with equation (9)
can be very large, since the number of negative pairs is
much larger than that of positive pairs, i.e. N−
estimation error for the positive mean with equation (9) is
given by the following equation,
t , the division value of N−
is very large.
Therefore, according to equation (10), the estimation error for
the positive mean is very large, even though the error for the
negative mean is small.
To solve this problem, we propose to calculate the mean
by selecting Q potential positive difference vectors from
the unlabeled data zu
tkl and maximizing the following joint
distribution,
tkq lq ,q=1,···,Q Pr(zu
tk1l1, · · · , zu
tk1l1, · · · , zu
tkQlQ are independent with each other given the
positive tag, the optimization problem (11) can be rewritten as
tkq lq ,q=1,···,Q
tkl = Pr(zu
tkqlq|+). We estimate the positive conditional probability pu
tkl as follows. According to the deﬁnition
given by equation (2), if the norm ∥zu
tkl∥of the absolute
difference vector is close to zero, images k and j have a
high probability that they represent the same person, and thus
they form a positive (matched) image pair, i.e. zu
tkl is likely
to be positive. Therefore, we estimate the positive conditional
probability by1
tkl ∝e−∥zu
1While the norm could be more general, we use the l1 norm in our
experiments, and hence the probability becomes a Laplace distribution.
Algorithm 1 Selecting Positive Difference Vectors
Under the independent assumption, potential positives
can be selected by the unlabeled data with top Q scores
tk1l1, · · · , pu
tkQlQ. However, the independent assumption is
not valid. To explain the reasons, we denote Gk· as the set
of difference vectors related to image k under camera a and
those images under the other camera b, i.e.
tkl = d(xa
Let us consider two elements zu
tkl1 and zu
tkl2 in Gk·. Denote the
number of positives and the number of all elements in Gk· as
and Nk, respectively. If zu
tkl1 is positive, the probability
tkl2 is positive is equal to (N+
k −1)/(Nk −1). If zu
negative, such probability becomes N+
k /(Nk −1). Therefore,
the independence is not valid for the unlabeled data in the
same group Gk·. And, we propose to add a constraint to the
optimization problem (12) to ensure the independence, i.e.
tk1l1, · · · , zu
tkQlQ come from different groups Gk· and G·l.2
Thus, we have the following optimization problem,
tkq lq , s.t. k1̸=···̸=kQ,l1̸=···̸=lQ
To solve the optimization problem (15), we propose an
efﬁcient greedy method. Once a potential positive difference
tkqlq is selected, the elements in Gkq· and G·lq are
removed for the constraint in the optimization problem (15).
The algorithmic procedure is given in Algorithm 1. Since
it cannot be guaranteed that the selected unlabeled difference vectors are really generated by the true positive image
pairs, we calculate the mean of them to reduce the negative
impact for wrongly labeling an unlabeled difference vector as
positive, i.e.
tk1l1 + · · · + zu
tk1l1, · · · , zu
tkQlQ are Q unlabeled difference vectors
selected as positive.
2G·l can be deﬁned similarly to Gk·.
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 24, NO. 5, MAY 2015
3) Combining Estimated Target Positive Means: In the
previous discussions, labeled data in the source domain and
unlabeled data in the target domain are used to estimate the
target positive mean and result in two estimations m+
t1 and m+
respectively. Let us consider the target positive mean m+
a random vector. We estimate the conditional distribution of
t1 and m+
t2 as follows. By Bayes’ rule , the
conditional probability Pr(m+
t2) can be computed as
t2) = Pr(m+
t1 and m+
t2 are estimated by the source domain and
target domain data, respectively, they can be considered to
be independent and conditionally independent given the true
positive mean m+
t2) = Pr(m+
t ) = Pr(m+
Substituting equation (18) into equation (17), we get
t2) = Pr(m+
Without any information about the positive distribution, the
prior probability Pr(m+
t ) can be considered as a constant.
Therefore, the key problem is to compute the conditional
probabilities Pr(m+
t1) and Pr(m+
To estimate Pr(m+
t1), it is reasonable to assume that the
probability of the target positive mean is higher if its distance
is closer to m+
t1. On the other hand, when the assumption given
by equation (5) is satisﬁed, m+
t1 is close to the true target
positive mean according to equation (7). Otherwise, m+
not be a good estimation. To measure the uncertainty about
the validity of the assumption (5), we deﬁne Pr(m+
Gaussian distribution as follows,
t1) ∝e−∥m+
where ∥·∥2 denotes l2 norm and σ 2
1 is the variance in Gaussian
distribution to measure the uncertainty. Similarly, Pr(m+
can be deﬁned by
t2) ∝e−∥m+
2 is the variance to measure the uncertainty of the
positive mean estimated by the potential positive difference
vectors selected by Algorithm 1.
With equations (19) (20) (21), the likelihood function of the
target positive mean is given by
t2)) ∝−∥m+
To compute the maximum value of the likelihood function, we
take the ﬁrst derivative of the right hand side in equation (22)
and set it as zero. Then, the optimal estimation of the target
positive mean m+
t is derived as
t1 + (1 −α)m+
where α = σ 2
2 ). Since σ 2
1 ≥0 and σ 2
2 ≥0, the range
of α is 0 ≤α ≤1. And, α is determined by the training data,
which will be discussed in the following section.
B. Adaptive Ranking SVMs
With positive and negative image pairs in the source domain,
RankSVM is employed to learn a source domain distance
model ws. Inspired by the adaptive learning methods , 
for asymmetric domain adaptation, the weight vector wt for
the target domain can be deﬁned as follows,
wt = θws + w
where θ is the coefﬁcient to measure the importance of the
classiﬁer ws trained from the source domain data and w is the
perturbation weight vector adapted for the target domain.
Substituting m+
t and wt by equations (23) and (24), respectively, the inequality (4) becomes
(θws + w)T (αm+
t1 + (1 −α)m+
t2) > (θws + w)T z−
Similar to RankSVM , the order relationship given by
inequality (25) needs to be preserved for discriminability.
Thus, we propose to learn the optimal α, θ and w by solving
the following optimization problem,
2 + μθ2) + C
s.t. (θws + w)T (αm+
t1 + (1 −α)m+
tkl) ≥1 −ξkl,
ξkl ≥0, 0 ≤α ≤1, ∀k,l
where μ is a positive parameter to balance the regularization
terms for w and θ.
The optimization problem (26) can be solved by rewriting
α F(α), s.t. 0 ≤α ≤1
F(α) = min
2 + μθ2) + C
s.t. (θws + w)T (αm+
t1 + (1 −α)m+
ξkl ≥0, ∀k,l
With this reformulation, we can linearly search α from 0 to 1
with the minimal cost. Fixing α, the optimization problem (26)
can be solved efﬁciently by converting it to the standard
RankSVM formulation as in equation (1).
Denote the column concatenation of w and √μθ as v, i.e.
On the other hand, we construct the feature map as
t1 + (1 −α)m+
t1 + (1 −α)m+
MA et al.: CROSS-DOMAIN PERSON REIDENTIFICATION USING DOMAIN ADAPTATION RANKING SVMs
Algorithm 2 Training AdaRSVM
With the notations in (29) and (30), it has the following
equations,
vT f kl = (θws + w)T (αm+
t1 + (1 −α)m+
Therefore, the optimization problem (28) is rewritten as
F(α) = min
s.t. vT f kl ≥1 −ξkl, ξkl ≥0, ∀k,l
optimization
efﬁciently,
reformulate
2∥v∥2 + C 
k,l max(0, 1 −vT f kl)2
Employing the efﬁcient algorithm based on primal
Newton method to solve the optimization problem (33), the
optimal weight vector v can be obtained. Then, the target
weight vector wt is calculated by equations (24) and (29).
At last, the algorithmic procedure for training the proposed
Adaptive Ranking Support Vector Machines (AdaRSVM)
model is presented in Algorithm 2.
IV. EXPERIMENTS
In this section, we ﬁrst give an introduction to the datasets
and settings used for evaluation. Then, the comparison results
are reported in Sections IV-B to IV-E.
Example matched image pairs in (a) CUHK and (b) i-LIDS .
A. Datasets and Settings
Four publicly available datasets, namely PRID3
VIPeR4 , CUHK5 and i-LIDS6 , are used for
evaluating the proposed method. PRID dataset consists of
person images from two static surveillance cameras. In total
385 persons were captured by camera A, while 749 persons
captured by camera B. The ﬁrst 200 persons appeared in
both cameras, and the remainders only appeared in one
camera. In our experiments, the single-shot version is used,
in which at most one image of each person from each camera
is available. VIPeR is a re-identiﬁcation dataset containing
632 person image pairs captured by two cameras outdoor.
CUHK dataset contains ﬁve pairs of camera views. Under
each camera view, there are two images for each person.
Following the single shot setting in , images from camera
pair one with 971 persons are used for experiments. The
i-LIDS Multiple-Camera Tracking (MCT) dataset contains
a number of video clips captured by ﬁve cameras indoor.
In re-identiﬁcation application, total 476 person images from
119 persons are used for experiments as in . Example
images in these four datasets are shown in Fig 1(a), Fig. 1(b),
Fig. 3(a) and Fig. 3(b), respectively.
In our experiments, we use PRID, VIPeR or CUHK as the
target domain. For the i-LIDS dataset, the camera information
is not available. Since the proposed method requires camera information to generate groups deﬁned by equation (14)
for positive difference vector selection, we do not use the
i-LIDS dataset as the target domain. Without the time acquisition information in the PRID, VIPeR and CUHK datasets,
target negative image pairs from non-overlapping cameras
are generated by simulating the synchronization using label
information. Fixing the target domain dataset as PRID, VIPeR
or CUHK, one of the other three datasets is used as the
source domain to train the proposed AdaRSVM. When PRID
is used as the target dataset, 100 out of the 200 image pairs
are randomly selected as the training set, and the others for
testing. If VIPeR is used as the target dataset, 632 image
pairs are randomly separated into half for training and the
other half for testing. For the CUHK dataset, 971 persons
are randomly split as 485 for training and 486 for testing.
Given a query image in the testing data from one camera
view, the evaluation is performed by ranking the person images
from another view. For each source dataset, following ,
3 
4 
5 
6 
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 24, NO. 5, MAY 2015
Example masked results in (a) PRID , (b) VIPeR ,
(c) CUHK and (d) i-LIDS dataset (better view in color).
one positive and one negative image pair for each person are
used for training, while the training data in the target domain
contains only one negative image pair for each person. Each
experiment was repeated ten times and the mean accuracy
is reported.
state-of-the-art
re-identiﬁcation,
Comparison
Learning (RPML) , are used for comparison. Since
the label information of persons is supposed to be not
available in the target dataset, cross-validation cannot be
performed to select the best parameters. Thus, we empirically
set the parameters in existing methods and the proposed
AdaRSVM. The PCA dimension in RPML is set as 80. The
parameter C in RankSVM and the proposed method is set
as 1, while μ in the proposed AdaRSVM is set as 100. For
the number of selected positive difference vectors, Q should
be less than the number of detected persons in each camera,
so we set Q = 90 in PRID, 300 in VIPeR and 450 in CUHK
To evaluate the robustness of the proposed method, we
extract two kinds of features for the detected person images.
The ﬁrst feature (Fea1) is constructed by dividing a person
image into six horizontal stripes and compute the RGB,
YCbCr, HSV color features and two types of texture features
extracted by Schmid and Gabor ﬁlters on each stripe as
reported in , , and . For the second feature (Fea2),
we concatenate the ﬁrst feature with another one with
foreground detection. The spatial hierarchy pose estimation
method with source code online7 is employed to detect
the local human parts as shown in the middle row of Fig. 4.
Though it is reasonable to compute the parts based difference,
the pose estimation is not accurate enough and does not
consider the pair-wise matching relationship. Instead, we use
the estimated human parts to mask the images as shown in
the last row of Fig. 4(a)-4(d) for PRID, VIPeR, CUHK and
i-LIDS datasets, respectively. Then, the masked person
7 
TOP r RANK MATCHING ACCURACY (%) ON PRID USING FEA1
TOP r RANK MATCHING ACCURACY (%) ON PRID DATASET FEA2
image is divided into 3 × 1 vertically overlapped boxes.
Color histogram and SIFT features are extracted on
B. Comparison With Non-Learning Baselines
To evaluate our method, we compare with two commonly
used non-learning based metrics namely L1 and L2 norms as
baselines. The top r rank matching accuracies (%) are shown
in Tables I-VI. From these results, we can see that Fea2 by
concatenating Fea1 and another feature with foreground detection is more discriminative than Fea1. Comparing the results
on VIPeR dataset in Table III and Table IV for Fea1 and Fea2,
respectively, the rank one accuracy of L1 using Fea2 is
over three times higher than that using Fea1. The simple
non-learning methods L1 and L2 can achieve high rank-one
accuracies of 37.97% and 33.53%. Such good performance
may be due to the reason that the combination of foreground
detection and global feature extraction (on a large region of
an image) is very effective for VIPeR dataset.8 On the other
hand, our method achieves better performance than L1 and L2
on the three target datasets with different source domains and
features. Moreover, Table IV shows that when using CUHK
as the source domain, the rank one accuracy of our method on
VIPeR dataset with Fea2 is 9.50% higher than L1 and 13.94%
8It is interesting to further investigate the deeper reasons for the good
performance on VIPeR dataset, but this is not the focus of this paper.
MA et al.: CROSS-DOMAIN PERSON REIDENTIFICATION USING DOMAIN ADAPTATION RANKING SVMs
TOP r RANK MATCHING ACCURACY (%) ON VIPER USING FEA1
TOP r RANK MATCHING ACCURACY (%) ON VIPER USING FEA2
higher than L2. These results convince that the proposed
method can learn useful information from the source domain
and target domain data to robustly improve the recognition
performance with different source domains and features over
the non-learning based methods.
C. Comparison With Supervised Learning Methods
Since label information is assumed to be not available in the
target domain, existing supervised distance learning methods
for person re-identiﬁcation, e.g. RankSVM, RDC and RPML,
cannot be employed to train a discriminative model for the
target domain. For comparison, we use the labeled data from
the source domain to train the RankSVM, RDC and RPML.
Their results are recorded in Tables I-VI. From these tables,
we can see that our method outperforms other supervised
distance learning methods when using the source domain
data for training. For many domain adaptation scenarios, the
improvements by our methods are remarkable. For example,
as shown in Table I, when the source domain is VIPeR or
CUHK, the rank one accuracy of our method on PRID using
Fea1 is higher than twice of others. Moreover, from Table IV,
we can see that our method outperforms RankSVM, RDC
and RPML by over 10% higher rank one accuracy on VIPeR
dataset using Fea2. These results indicate that the proposed
method can make good use of negative data (unmatched image
pairs generated from non-overlapping cameras) and unlabeled
TOP r RANK MATCHING ACCURACY (%) ON CUHK USING FEA1
TOP r RANK MATCHING ACCURACY (%) ON CUHK USING FEA2
data in the target domain to improve the re-identiﬁcation
performance, when the label information of persons is not
available in the target domain.
From Tables II IV VI, we can see that the rank one accuracies of the unsupervised methods L1 and L2 with Fea2 are
lower than 10% on PRID and CUHK datasets, while on VIPeR
they achieve rank one accuracies of 37.97% and 33.53%,
respectively. This means Fea2 is a very discriminative feature
for VIPeR and less discriminative for PRID and CUHK, which
indicates that the same feature can provide different discriminabilities for different datasets/domains. Such differences can
cause that the supervised distance learning algorithms, e.g.
RankSVM, RDC and RPML, may learn the incorrect information by the labeled data from the source domain. Therefore,
in most cases the non-learning methods, e.g. L1 and L2, are
better than the supervised ones as shown in Tables I-VI. Since
our method makes use of the negative and unlabeled data from
the target domain to align the distribution mismatch, it can
outperform both the non-learning methods and the supervised
distance learning algorithms using only labeled data from the
source domain.
We further show the CMC curves of the RankSVM, RDC
and RPML trained by the labeled data from target or source
domain in Figs. 5(a)-(f), Figs. 6(a)-(f) and Figs. 7(a)-(f),
respectively. For the results trained by the source domain
data, the highest accuracy of each rank is recorded across
the three different source datasets. All these ﬁgures show
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 24, NO. 5, MAY 2015
CMC curve comparison of our method and RankSVM trained by labeled data from target or source domain. (a) Results on PRID using Fea1.
(b) Results on VIPeR using Fea1. (c) Results on CUHK using Fea1. (d) Results on PRID using Fea2. (e) Results on VIPeR using Fea2. (f) Results on CUHK
using Fea2.
CMC curve comparison of our method and RDC trained by labeled data from target or source domain. (a) Results on PRID using Fea1. (b) Results
on VIPeR using Fea1. (c) Results on CUHK using Fea1. (d) Results on PRID using Fea2. (e) Results on VIPeR using Fea2. (f) Results on CUHK using Fea2.
that the supervised distance learning methods have a dramatic
deterioration of performance, when the classiﬁcation model is
trained with the data from the source domain. From Fig. 5(e),
Fig. 6(e) and Fig. 7(e), we can see that the rank one accuracy
can be degraded by about 30% with RDC and about 40% with
RankSVM and RPML. This means the joint distributions in
the source and target domains are different with each other
for these datasets. And, the distribution misalignment causes
serious performance degradation in person re-identiﬁcation.
in Figs. 5(a)-(f), Figs.
6(a)-(f) and
7(a)-(f). From
these ﬁgures, we can see that our method outperforms other
learning algorithms using labeled data from source domain, as
well as two non-learning based metrics. In some cases, if the
target positive mean can be estimated with very small error
and represent the target positive data well, our method can
achieve very convincing performance which is close to that of
the supervised learning method using label information in the
MA et al.: CROSS-DOMAIN PERSON REIDENTIFICATION USING DOMAIN ADAPTATION RANKING SVMs
CMC curve comparison of our method and RPML trained by labeled data from target or source domain. (a) Results on PRID using Fea1. (b) Results
on VIPeR using Fea1. (c) Results on CUHK using Fea1. (d) Results on PRID using Fea2. (e) Results on VIPeR using Fea2. (f) Results on CUHK using Fea2.
target domain. For example, the results in Fig. 5(d), Fig. 6(d)
and Fig. 7(d) on PRID dataset using Fea2 show that our
CMC curves are very close to the ones using both positive
and negative labeled data in target domain for training. On the
other hand, it is also possible that the estimated target positive
mean contains error or cannot represent the positive data
well. Under this situation, the performance of our method is
not as good as supervised learning using target labeled data
for training as shown in Figs. 5(b)(c)(e)(f), Figs. 6(b)(c)(e)(f)
and Figs. 7(b)(c)(e)(f). However, by estimating the target
outperforms the
supervised
learning methods using source labeled data for training. This
convinces that estimating target label information can help to
align the joint distributions in source and target domains, so
that the recognition performance has been improved.
D. Comparison With Domain Adaptation Algorithms
In this experiment, we would like to evaluate whether
the equal conditional probability assumption is satisﬁed for
person re-identiﬁcation. Two state-of-the-art domain adaptation methods, Geodesic Flow Sampling (GFS) and
Transfer Component Analysis (TCA) , are used to
projection
marginal distributions between the source and target domains,
i.e. Prs((z)) ≈Prt((z)). For the implementation, we use
the source code provided by the authors for the GFS9 and
re-implement the TCA method. In our experiments, RankSVM
is employed to train the discriminative model by the projected labeled data from the source domain. The best PCA
dimension and number of intermediate subspace in the GFS
are empirically set as 100 and 6, respectively. Linear kernel
9 
is employed in the TCA and the reduced dimension is
set as 100.
The CMC curves of the domain adaptation methods
using Fea2 are shown in Figs. 8(a)-(c), Figs. 9(a)-(c)
and Figs. 10(a)-(c). When the source domain is CUHK or
i-LIDS and target domain is VIPeR, Figs. 9(b)(c) show that the
recognition accuracy by using the domain adaptation methods
GFS and TCA are higher than that of the supervised learning
method which uses labeled data from the source domain for
training. This indicates that the re-identiﬁcation performance
could be improved by aligning the marginal distributions
adaptation settings. Contrarily, simply aligning the marginal
distributions may further degrade the classiﬁers as shown
in Figs. 8(a)-(c) and Figs. 10(a)-(c). The reason could be that
the source and target classiﬁers (also known as conditional
distributions) may become farther away from each other in
the space where the marginal distributions are aligned. On the
other hand, all these ﬁgures show that the supervised learning
method using target label information greatly outperforms
GFS and TCA. This means the equal conditional probability
assumption is not valid for these domain adaptation scenarios
in person re-identiﬁcation, i.e. Prs(y|(z)) ̸= Prt(y|(z)).
Therefore, the joint distributions in the source and target
domains are not equal with each other (Prs(y, (z))
Prt(y, (z))),
distributions
equal (Prs((z))
Prt((z))) after domain adaptation
projection.
From Figs. 8(a)-(c), Figs. 9(a)-(c) and Figs. 10(a)-(c), we
can see that our method clearly outperforms the domain adaptation methods derived based on the equal conditional probability assumption. This convinces that the proposed method
can improve the re-identiﬁcation performance by removing the
IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 24, NO. 5, MAY 2015
CMC curve comparison of our method and Domain Adaptation methods on PRID dataset as the target domain using Fea2. (a) VIPeR as source
domain. (b) CUHK as source domain. (c) i-LIDS as source domain.
CMC curve comparison of our method and Domain Adaptation methods on VIPeR dataset as the target domain using Fea2. (a) PRID as source
domain. (b) CUHK as source domain. (c) i-LIDS as source domain.
CMC curve comparison of our method and Domain Adaptation methods on CUHK dataset as the target domain using Fea2. (a) PRID as source
domain. (b) VIPeR as source domain. (c) i-LIDS as source domain.
assumption that the conditional probabilities in the source and
target domains are equal. Moreover, Figs. 9(b)(c) show that
the rank one accuracies of GFS and TCA are around 30%
with CUHK or i-LIDS as the source domain, while the rank
one accuracies of them are lower than 20% with PRID as the
source domain. This means the domain adaptation methods
with the equal conditional probability assumption may have
over 10% degradation of rank one accuracy when using a
different dataset as the source domain. By estimating the
positive information in the target domain to solve the joint
distribution mismatch problem, our method achieves much
more robust performance (around 45% rank one accuracy)
with different datasets as the source domain.
E. Comparing With Appearance-Based Methods
To demonstrate that the proposed domain adaptation
approach can
outperform unsupervised appearance-based
re-identiﬁcation,
method with state-of-the-art algorithms, including Symmetry-
Accumulation
Custom Pictorial Structures (CPS) , enriched Bio-inspired
MA et al.: CROSS-DOMAIN PERSON REIDENTIFICATION USING DOMAIN ADAPTATION RANKING SVMs
TOP r RANK MATCHING ACCURACY (%) OF STATE-OF-THE-ART
APPEARANCE-BASED ALGORITHMS AND
OUR METHOD ON VIPER
Covariance
Descriptors
encoded by Fisher Vectors (eLDFV) , Color Invariant Signatures (CIS) and enriched Salience Correspondence (eSDC) . Source codes of SDALF,10 CIS11 and
eSDC12 are provided online and used for our experiments,
while the results of CPS, eBiCov and eLDFV are copied from
their papers. The top r rank accuracies of these methods and
the proposed AdaRSVM on VIPeR dataset are recorded in
Table VII. From Table VII, we can see that the appearancebased methods outperform ours when using Fea1 to train the
domain adaptation model. On the other hand, when Fea2 is
used, no matter what the source domain is, our method can
remarkably outperforms the appearance-based algorithms. The
rank one accuracy of our method with CUHK as the source
domain is over 20% higher than that of the best state-of-the-art
appearance-based algorithm. Since the proposed method is
independent of the input features, these results indicate that
domain adaptation approach can improve the performance
remarkably over appearance-based methods by employing a
discriminative feature.
V. CONCLUSIONS
In this paper, we propose a novel Adaptive Ranking Support
Vector Machines (AdaRSVM) method to deal with the problem that label information of persons is not available under
target cameras. Without positive image pairs generated by
the label information of persons, we relax the discriminative
constraint to a necessary condition, which only relies on the
mean of positive pairs. In order to estimate the positive mean
in the target domain, we make use of the labeled data from the
source domain, the negative and unlabeled data from the target
domain. With two estimations of the target positive mean, the
optimal combination is determined by the training data. The
target distance model is trained by adapting the source domain
distance model to target domain.
experiments
method achieve convincing recognition performance for
10 
11 
12 
person re-identiﬁcation. The proposed AdaRSVM not only
outperforms non-learning based methods but also is better than
state-of-the-art discriminative learning methods using labeled
data from the source domain for training. In our experiments,
it is shown that the performance deteriorates dramatically
when using the learnt model trained on source domain to
target domain, which means the joint distributions in source
and target domains are not equal to each other. On the other
hand, compared with two domain adaptation methods for
the alignment of marginal distributions, experimental results
demonstrate that the equal conditional probability assumption
is not valid for person re-identiﬁcation. With the help of
the negative image pairs generated from non-overlapping
target cameras, the proposed AdaRSVM can improve the
re-identiﬁcation performance by estimating the target positive
mean for domain adaptation learning. Moreover, it is also
shown that the proposed domain adaptation method can
remarkably outperform existing appearance-based methods
on VIPeR dataset without using target label information for
While the proposed method only considers single source
domain, multiple source domains are usually available in
practice. Therefore, we will further investigate how to select
or combine different source domains to train a more discriminative domain adaptation model in the future. On the
other hand, our method is developed based on RankSVM.
Since RankSVM does not address the problems for largescale dataset, it may not perform as good as state-of-the-art
large-scale ranking methods, see , when a large amount
of training data is available. Therefore, we are also interested
in developing a new domain adaptation method for large-scale
learning in person re-identiﬁcation.