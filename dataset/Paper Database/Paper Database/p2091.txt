International Journal of Computer Vision 59(2), 167–181, 2004
c⃝2004 Kluwer Academic Publishers. Manufactured in The Netherlands.
Efﬁcient Graph-Based Image Segmentation
PEDRO F. FELZENSZWALB
Artiﬁcial Intelligence Lab, Massachusetts Institute of Technology
 
DANIEL P. HUTTENLOCHER
Computer Science Department, Cornell University
 
Received September 24, 1999; Revised August 26, 2003; Accepted September 17, 2003
This paper addresses the problem of segmenting an image into regions. We deﬁne a predicate for
measuring the evidence for a boundary between two regions using a graph-based representation of the image. We
then develop an efﬁcient segmentation algorithm based on this predicate, and show that although this algorithm
makes greedy decisions it produces segmentations that satisfy global properties. We apply the algorithm to image
segmentation using two different kinds of local neighborhoods in constructing the graph, and illustrate the results
with both real and synthetic images. The algorithm runs in time nearly linear in the number of graph edges and
is also fast in practice. An important characteristic of the method is its ability to preserve detail in low-variability
image regions while ignoring detail in high-variability regions.
image segmentation, clustering, perceptual organization, graph algorithm
Introduction
The problems of image segmentation and grouping remain great challenges for computer vision. Since the
time of the Gestalt movement in psychology , it has been known that perceptual
grouping plays a powerful role in human visual perception. A wide range of computational vision problems
could in principle make good use of segmented images,
were such segmentations reliably and efﬁciently computable. For instance intermediate-level vision problems such as stereo and motion estimation require an
appropriate region of support for correspondence operations. Spatially non-uniform regions of support can be
identiﬁed using segmentation techniques. Higher-level
problems such as recognition and image indexing can
also make use of segmentation results in matching, to
address problems such as ﬁgure-ground separation and
recognition by parts.
Our goal is to develop computational approaches to
image segmentation that are broadly useful, much in
the way that other low-level techniques such as edge
detection are used in a wide range of computer vision
tasks. In order to achieve such broad utility, we believe
it is important that a segmentation method have the
following properties:
1. Capture perceptually important groupings or regions, which often reﬂect global aspects of the image. Two central issues are to provide precise characterizations of what is perceptually important, and
to be able to specify what a given segmentation technique does. We believe that there should be precise deﬁnitions of the properties of a resulting segmentation, in order to better understand the method
as well as to facilitate the comparison of different
approaches.
Felzenszwalb and Huttenlocher
2. Be highly efﬁcient, running in time nearly linear
in the number of image pixels. In order to be of
practical use, we believe that segmentation methods should run at speeds similar to edge detection or
other low-level visual processing techniques, meaning nearly linear time and with low constant factors.
For example, a segmentation technique that runs at
several frames per second can be used in video processing applications.
While the past few years have seen considerable
progress in eigenvector-based methods of image segmentation ,
these methods are too slow to be practical for many
applications. In contrast, the method described in this
paper has been used in large-scale image database applications as described in Ratan et al. . While
there are other approaches to image segmentation that
are highly efﬁcient, these methods generally fail to capture perceptually important non-local properties of an
image as discussed below. The segmentation technique
developed here both captures certain perceptually important non-local image characteristics and is computationally efﬁcient—running in O(n log n) time for n
image pixels and with low constant factors, and can run
in practice at video rates.
A synthetic image with three perceptually distinct regions, and the three largest regions found by our segmentation method (image
320 × 240 pixels; algorithm parameters σ = 0.8, k = 300, see Section 5 for an explanation of the parameters).
clustering
 , our method is based on
selecting edges from a graph, where each pixel corresponds to a node in the graph, and certain neighboring
pixels are connected by undirected edges. Weights on
each edge measure the dissimilarity between pixels.
However, unlike the classical methods, our technique
adaptively adjusts the segmentation criterion based on
the degree of variability in neighboring regions of the
image. This results in a method that, while making
greedy decisions, can be shown to obey certain nonobvious global properties. We also show that other
adaptive criteria, closely related to the one developed
here, result in problems that are computationally difﬁcult (NP hard).
We now turn to a simple synthetic example illustrating some of the non-local image characteristics captured by our segmentation method. Consider the image
shown in the top left of Fig. 1. Most people will say
that this image has three distinct regions: a rectangularshaped intensity ramp in the left half, a constant intensity region with a hole on the right half, and a
high-variability rectangular region inside the constant
region. This example illustrates some perceptually importantpropertiesthatwebelieveshouldbecapturedby
asegmentationalgorithm.First,widelyvaryingintensities should not alone be judged as evidence for multiple
Efﬁcient Graph-Based Image Segmentation
regions. Such wide variation in intensities occurs both
in the ramp on the left and in the high variability region on the right. Thus it is not adequate to assume
that regions have nearly constant or slowly varying
intensities.
A second perceptually important aspect of the example in Fig. 1 is that the three regions cannot be obtained
using purely local decision criteria. This is because the
intensity difference across the boundary between the
ramp and the constant region is actually smaller than
many of the intensity differences within the high variability region. Thus, in order to segment such an image,
some kind of adaptive or non-local criterion must be
The method that we introduce in Section 3.1 measures the evidence for a boundary between two regions
by comparing two quantities: one based on intensity
differences across the boundary, and the other based
on intensity differences between neighboring pixels
within each region. Intuitively, the intensity differences
across the boundary of two regions are perceptually
important if they are large relative to the intensity differences inside at least one of the regions. We develop
a simple algorithm which computes segmentations using this idea. The remaining parts of Fig. 1 show the
three largest regions found by our algorithm. Although
this method makes greedy decisions, it produces results that capture certain global properties which are
derived below and whose consequences are illustrated
by the example in Fig. 1. The method also runs in a
small fraction of a second for the 320 × 240 image in
the example.
The organization of this paper is as follows. In the
next Section we discuss some related work, including both classical formulations of segmentation and
recent graph-based methods. In Section 3 we consider
a particular graph-based formulation of the segmentation problem and deﬁne a pairwise region comparison
predicate. Then in Section 4 we present an algorithm
for efﬁciently segmenting an image using this predicate, and derive some global properties that it obeys
even though it is a greedy algorithm. In Section 5 we
show results for a number of images using the image
grid to construct a graph-based representation of the
image data. Then in Section 6 we illustrate the method
using more general graphs, but where the number of
edges is still linear in the number of pixels. Using this
latter approach yields results that capture high-level
scene properties such as extracting a ﬂower bed as a
single region, while still preserving ﬁne detail in other
portions of the image. In the Appendix we show that a
straightforward generalization of the region comparison predicate presented in Section 3 makes the problem
of ﬁnding a good segmentation NP-hard.
Related Work
There is a large literature on segmentation and clustering, dating back over 30 years, with applications in
many areas other than computer vision . In this section we brieﬂy consider some
oftherelatedworkthatismostrelevanttoourapproach:
earlygraph-basedmethods , region merging techniques , techniques based on mapping image
pixelstosomefeaturespace and more recent formulations in terms of
graph cuts and spectral methods .
Graph-based image segmentation techniques generally represent the problem in terms of a graph G =
(V, E) where each node vi ∈V corresponds to a pixel
in the image, and an edge (vi, v j) ∈E connects vertices
vi and v j. A weight is associated with each edge based
on some property of the pixels that it connects, such
as their image intensities. Depending on the method,
there may or may not be an edge connecting each pair
of vertices. The earliest graph-based methods use ﬁxed
thresholds and local measures in computing a segmentation. The work of Zahn presents a segmentation method based on the minimum spanning tree
(MST) of the graph. This method has been applied
both to point clustering and to image segmentation.
For image segmentation the edge weights in the graph
are based on the differences between pixel intensities,
whereas for point clustering the weights are based on
distances between points.
The segmentation criterion in Zahn’s method is
to break MST edges with large weights. The inadequacy of simply breaking large edges, however, is illustrated by the example in Fig. 1. As mentioned in
the introduction, differences between pixels within the
high variability region can be larger than those between the ramp and the constant region. Thus, depending on the threshold, simply breaking large weight
edges would either result in the high variability region being split into multiple regions, or would merge
the ramp and the constant region together. The algorithm proposed by Urquhart attempts to address
Felzenszwalb and Huttenlocher
this shortcoming by normalizing the weight of an edge
usingthesmallestweightincidentontheverticestouching that edge. When applied to image segmentation
problems, however, this is not enough to provide a reasonable adaptive segmentation criterion. For example,
many pixels in the high variability region of Fig. 1 have
some neighbor that is highly similar.
Another early approach to image segmentation is
that of splitting and merging regions according to how
well each region ﬁts some uniformity criterion . Generally these uniformity criteria obey a subset property, such that when a
uniformity predicate U(A) is true for some region A
then U(B) is also true for any B ⊂A. Usually such
criteria are aimed at ﬁnding either uniform intensity
or uniform gradient regions. No region uniformity criterion that has been proposed to date could be used
to correctly segment the example in Fig. 1, due to the
high variation region. Either this region would be split
into pieces, or it would be merged with the surrounding
A number of approaches to segmentation are based
on ﬁnding compact clusters in some feature space .
These approaches generally assume that the image is
piecewise constant, because searching for pixels that
are all close together in some feature space implicitly
requires that the pixels be alike (e.g., similar color).
A recent technique using feature space clustering
 ﬁrst transforms the data
by smoothing it in a way that preserves boundaries between regions. This smoothing operation has the overall effect of bringing points in a cluster closer together.
The method then ﬁnds clusters by dilating each point
with a hypersphere of some ﬁxed radius, and ﬁnding
connected components of the dilated points. This technique for ﬁnding clusters does not require all the points
in a cluster to lie within any ﬁxed distance. The technique is actually closely related to the region comparison predicate that we introduce in Section 3.1, which
can be viewed as an adaptive way of selecting an appropriate dilation radius. We return to this issue in
Section 6.
Finally we brieﬂy consider a class of segmentation
methods based on ﬁnding minimum cuts in a graph,
where the cut criterion is designed in order to minimize the similarity between pixels that are being split.
Work by Wu and Leahy introduced such a cut
criterion, but it was biased toward ﬁnding small components. This bias was addressed with the normalized
cut criterion developed by Shi and Malik , which
takes into account self-similarity of regions. These cutbased approaches to segmentation capture non-local
properties of the image, in contrast with the early
graph-based methods. However, they provide only a
characterization of each cut rather than of the ﬁnal
segmentation.
The normalized cut criterion provides a signiﬁcant
advance over the previous work in Wu and Leahy
 , both from a theoretical and practical point of
view (the resulting segmentations capture intuitively
salient parts of an image). However, the normalized
cut criterion also yields an NP-hard computational
problem. While Shi and Malik develop approximation methods for computing the minimum normalized
cut, the error in these approximations is not well understood. In practice these approximations are still
fairly hard to compute, limiting the method to relatively small images or requiring computation times
of several minutes. Recently Weiss has shown
how the eigenvector-based approximations developed
by Shi and Malik relate to more standard spectral partitioning methods on graphs. However, all such methods
are too slow for many practical applications.
An alternative to the graph cut approach is to look
for cycles in a graph embedded in the image plane. For
example in Jermyn and Ishikawa the quality of
each cycle is normalized in a way that is closely related
to the normalized cuts approach.
Graph-Based Segmentation
We take a graph-based approach to segmentation. Let
G = (V, E) be an undirected graph with vertices
v ∈V , the set of elements to be segmented, and edges
(vi, v j) ∈E corresponding to pairs of neighboring
vertices. Each edge (vi, v j) ∈E has a corresponding
weight w(vi, v j), which is a non-negative measure of
the dissimilarity between neighboring elements vi and
v j. In the case of image segmentation, the elements in
V are pixels and the weight of an edge is some measure of the dissimilarity between the two pixels connected by that edge (e.g., the difference in intensity,
color, motion, location or some other local attribute).
In Sections 5 and 6 we consider particular edge sets and
weight functions for image segmentation. However, the
formulation here is independent of these deﬁnitions.
In the graph-based approach, a segmentation S
is a partition of V into components such that each
Efﬁcient Graph-Based Image Segmentation
component (or region) C ∈S corresponds to a connected component in a graph G′ = (V, E′), where
E′ ⊆E. In other words, any segmentation is induced
by a subset of the edges in E. There are different ways
to measure the quality of a segmentation but in general
we want the elements in a component to be similar,
and elements in different components to be dissimilar. This means that edges between two vertices in the
same component should have relatively low weights,
and edges between vertices in different components
should have higher weights.
Pairwise Region Comparison Predicate
In this section we deﬁne a predicate, D, for evaluating
whether or not there is evidence for a boundary between two components in a segmentation (two regions
of an image). This predicate is based on measuring the
dissimilarity between elements along the boundary of
the two components relative to a measure of the dissimilarity among neighboring elements within each of the
two components. The resulting predicate compares the
inter-component differences to the within component
differences and is thereby adaptive with respect to the
local characteristics of the data.
We deﬁne the internal difference of a component
C ⊆V to be the largest weight in the minimum spanning tree of the component, MST(C, E). That is,
e∈MST(C,E) w(e).
One intuition underlying this measure is that a given
component C only remains connected when edges of
weight at least Int(C) are considered.
We deﬁne the difference between two components
C1, C2 ⊆V to be the minimum weight edge connecting the two components. That is,
Dif(C1, C2) =
vi∈C1,v j∈C2,(vi,v j)∈E w(vi, v j).
If there is no edge connecting C1 and C2 we let
Dif(C1, C2) = ∞. This measure of difference could
in principle be problematic, because it reﬂects only
the smallest edge weight between two components. In
practice we have found that the measure works quite
well in spite of this apparent limitation. Moreover,
changing the deﬁnition to use the median weight, or
some other quantile, in order to make it more robust to
outliers, makes the problem of ﬁnding a good segmentation NP-hard, as discussed in the Appendix. Thus
a small change to the segmentation criterion vastly
changes the difﬁculty of the problem.
The region comparison predicate evaluates if there
is evidence for a boundary between a pair or components by checking if the difference between the components, Dif(C1, C2), is large relative to the internal difference within at least one of the components, Int(C1)
and Int(C2). A threshold function is used to control the
degree to which the difference between components
must be larger than minimum internal difference. We
deﬁne the pairwise comparison predicate D(C1, C2),
D(C1, C2) =
if Dif(C1, C2) > MInt(C1, C2)
where the minimum internal difference, MInt, is de-
MInt(C1, C2)
= min(Int(C1) + τ(C1), Int(C2) + τ(C2)).
The threshold function τ controls the degree to which
thedifferencebetweentwocomponentsmustbegreater
than their internal differences in order for there to be
evidence of a boundary between them (D to be true).
For small components, Int(C) is not a good estimate
of the local characteristics of the data. In the extreme
case, when |C| = 1, Int(C) = 0. Therefore, we use a
threshold function based on the size of the component,
τ(C) = k/|C|
where |C| denotes the size of C, and k is some constant
parameter. That is, for small components we require
stronger evidence for a boundary. In practice k sets a
scale of observation, in that a larger k causes a preference for larger components. Note, however, that k is
not a minimum component size. Smaller components
are allowed when there is a sufﬁciently large difference
between neighboring components.
Any non-negative function of a single component
can be used for τ without changing the algorithmic
results in Section 4. For instance, it is possible to have
the segmentation method prefer components of certain
shapes, by deﬁning a τ which is large for components
that do not ﬁt some desired shape and small for ones
that do. This would cause the segmentation algorithm
Felzenszwalb and Huttenlocher
to aggressively merge components that are not of the
desired shape. Such a shape preference could be as
weak as preferring components that are not long and
thin (e.g., using a ratio of perimeter to area) or as strong
as preferring components that match a particular shape
model. Note that the result of this would not solely be
components of the desired shape, however for any two
neighboring components one of them would be of the
desired shape.
The Algorithm and its Properties
In this section we describe and analyze an algorithm for
producing a segmentation using the decision criterion
D introduced above. We will show that a segmentation produced by this algorithm obeys the properties of
being neither too coarse nor too ﬁne, according to the
following deﬁnitions.
Deﬁnition 1.
A segmentation S is too ﬁne if there is
some pair of regions C1, C2 ∈S for which there is no
evidence for a boundary between them.
In order to deﬁne the complementary notion of what
it means for a segmentation to be too coarse (to have
too few components), we ﬁrst introduce the notion of a
reﬁnement of a segmentation. Given two segmentations
S and T of the same base set, we say that T is a reﬁnement of S when each component of T is contained in
(or equal to) some component of S. In addition, we say
that T is a proper reﬁnement of S when T ̸= S. Note
that if T is a proper reﬁnement of S, then T can be
obtained by splitting one or more regions of S. When
T is a proper reﬁnement of S we say that T is ﬁner than
S and that S is coarser than T .
Deﬁnition 2.
A segmentation S is too coarse when
there exists a proper reﬁnement of S that is not too
Thiscapturestheintuitivenotionthatifregionsofasegmentation can be split and yield a segmentation where
there is evidence for a boundary between all pairs of
neighboring regions, then the initial segmentation has
too few regions.
Two natural questions arise about segmentations that
are neither too coarse nor too ﬁne, namely whether or
not one always exists, and if so whether or not it is
unique. First we note that in general there can be more
than one segmentation that is neither too coarse nor
too ﬁne, so such a segmentation is not unique. On the
question of existence, there is always some segmentation that is both not too coarse and not too ﬁne, as we
now establish.
Property 1.
For any (ﬁnite) graph G = (V, E) there
exists some segmentation S that is neither too coarse
nor too ﬁne.
It is easy to see why this property holds. Consider
the segmentation where all the elements are in a single
component. Clearly this segmentation is not too ﬁne,
because there is only one component. If the segmentation is also not too coarse we are done. Otherwise, by
the deﬁnition of what it means to be too coarse there
is a proper reﬁnement that is not too ﬁne. Pick one of
those reﬁnements and keep repeating this procedure
until we obtain a segmentation that is not too coarse.
The procedure can only go on for n −1 steps because
whenever we pick a proper reﬁnement we increase the
number of components in the segmentation by at least
one, and the ﬁnest segmentation we can get is the one
where every element is in its own component.
We now turn to the segmentation algorithm, which is
closely related to Kruskal’s algorithm for constructing
a minimum spanning tree of a graph . It can be implemented to run in O(m log m)
time, where m is the number of edges in the graph.
Algorithm 1.
Segmentation algorithm.
The input is a graph G = (V, E), with n vertices
and m edges. The output is a segmentation of V into
components S = (C1, . . . , Cr).
0. Sort E into π = (o1, . . . , om), by non-decreasing
edge weight.
1. Start with a segmentation S0, where each vertex vi
is in its own component.
2. Repeat step 3 for q = 1, . . . , m.
3. Construct Sq given Sq−1 as follows. Let vi and
v j denote the vertices connected by the q-th edge
in the ordering, i.e., oq = (vi, v j). If vi and v j
are in disjoint components of Sq−1 and w(oq) is
small compared to the internal difference of both
those components, then merge the two components
otherwise do nothing. More formally, let Cq−1
the component of Sq−1 containing vi and Cq−1
the component containing v j. If Cq−1
w(oq) ≤MInt(Cq−1
) then Sq is obtained
Efﬁcient Graph-Based Image Segmentation
from Sq−1 by merging Cq−1
. Otherwise
Sq = Sq−1.
4. Return S = Sm.
We now establish that a segmentation S produced
by Algorithm 1 obeys the global properties of being
neither too ﬁne nor too coarse when using the region comparison predicate D deﬁned in (3). That is,
although the algorithm makes only greedy decisions
it produces a segmentation that satisﬁes these global
properties. Moreover, we show that any of the possible non-decreasing weight edge orderings that could
be picked in Step 0 of the algorithm produce the same
segmentation.
In Step 3 of the algorithm, when considering edge oq, if two distinct components are considered
and not merged then one of these two components will
be in the ﬁnal segmentation. Let Cq−1
the two components connected by edge oq = (vi, v j)
when this edge is considered by the algorithm. Then either Ci = Cq−1
or C j = Cq−1
, where Ci is the component containing vi and C j is the component containing
v j in the ﬁnal segmentation S.
There are two cases that would result
in a merge not happening. Say that it is due to
w(oq) > Int(Cq−1
). Since edges are considered in non-decreasing weight order, w(ok) ≥w(oq),
for all k ≥q + 1. Thus no additional merges will
happen to this component, i.e., Ci = Cq−1
. The case
for w(oq) > Int(Cq−1
) + τ(Cq−1
) is analogous.
Note that Lemma 1 implies that the edge causing
the merge of two components is exactly the minimum
weight edge between the components. Thus the edges
causing merges are exactly the edges that would be
selected by Kruskal’s algorithm for constructing the
minimum spanning tree (MST) of each component.
Theorem 1.
The segmentation
produced by
Algorithm 1 is not too ﬁne according to Deﬁnition 1,
using the region comparison predicate D deﬁned in (3).
By deﬁnition, in order for S to be too ﬁne
there is some pair of components for which D does not
hold. There must be at least one edge between such
a pair of components that was considered in Step 3
and did not cause a merge. Let oq = (vi, v j) be the
ﬁrst such edge in the ordering. In this case the algorithm decided not to merge Cq−1
implies w(oq) > MInt(Cq−1
). By Lemma 1 we
know that either Ci = Cq−1
or C j = Cq−1
. Either way
we see that w(oq) > MInt(Ci, C j) implying D holds
for Ci and C j, which is a contradiction.
Theorem 2.
The segmentation
produced by
Algorithm 1 is not too coarse according to Deﬁnition 2,
using the region comparison predicate D deﬁned in
In order for S to be too coarse there must be
some proper reﬁnement, T , that is not too ﬁne. Consider the minimum weight edge e that is internal to a
component C ∈S but connects distinct components
A, B ∈T . Note that by the deﬁnition of reﬁnement
A ⊂C and B ⊂C.
Since T is not too ﬁne, either w(e) > Int(A) + τ(A)
orw(e) > Int(B)+τ(B).Withoutlossofgenerality,say
the former is true. By construction any edge connecting
A to another sub-component of C has weight at least as
large as w(e), which is in turn larger than the maximum
weight edge in MST(A, E) because w(e) > Int(A).
Thus the algorithm, which considers edges in nondecreasing weight order, must consider all the edges
in MST(A, E) before considering any edge from A to
other parts of C. So the algorithm must have formed
A before forming C, and in forming C it must have
merged A with some other sub-component of C. The
weight of the edge that caused this merge must be least
aslargeasw(e).However,thealgorithmwouldnothave
merged A in this case because w(e) > Int(A) + τ(A),
which is a contradiction because the algorithm did
segmentation
Algorithm 1 does not depend on which non-decreasing
weight order of the edges is used.
Any ordering can be changed into another
one by only swapping adjacent elements. Thus it is
sufﬁcient to show that swapping the order of two adjacent edges of the same weight in the non-decreasing
weight ordering does not change the result produced by
Algorithm 1.
Let e1 and e2 be two edges of the same weight that
are adjacent in some non-decreasing weight ordering.
Clearlyifwhenthealgorithmconsiderstheﬁrstofthese
two edges they connect disjoint pairs of components
or exactly the same pair of components, then the order in which the two are considered does not matter.
The only case we need to check is when e1 is between
Felzenszwalb and Huttenlocher
two components A and B and e2 is between one of
these components, say B, and some other component
Now we show that e1 causes a merge when considered after e2 exactly when it would cause a merge
if considered before e2. First, suppose that e1 causes
a merge when considered before e2. This implies
w(e1) ≤MInt(A, B). If e2 were instead considered
before e1, either e2 would not cause a merge and trivially e1 would still cause a merge, or e2 would cause
a merge in which case the new component B ∪C
would have Int(B ∪C) = w(e2) = w(e1). So we
know w(e1) ≤MInt(A, B ∪C) which implies e1 will
still cause a merge. On the other hand, suppose that
e1 does not cause a merge when considered before
e2. This implies w(e1) > MInt(A, B). Then either
w(e1) > Int(A) + τ(A), in which case this would
still be true if e2 were considered ﬁrst (because e2
does not touch A), or w(e1) > Int(B) + τ(B). In this
second case, if e2 were considered ﬁrst it could not
cause a merge since w(e2) = w(e1) and so w(e2) >
MInt(B, C). Thus when considering e1 after e2 we still
have w(e1) > MInt(A, B) and e1 does not cause a
Implementation Issues and Running Time
Our implementation maintains the segmentation S using a disjoint-set forest with union by rank and path
compression . The running
time of the algorithm can be factored into two parts.
First in Step 0, it is necessary to sort the weights into
non-decreasing order. For integer weights this can be
done in linear time using counting sort, and in general
it can be done in O(m log m) time using any one of
several sorting methods.
Steps 1–3 of the algorithm take O(mα(m)) time,
where α is the very slow-growing inverse Ackerman’s
function. In order to check whether two vertices are in
the same component we use set-ﬁnd on each vertex, and
inordertomergetwocomponentsweuseuseset-union.
Thus there are at most three disjoint-set operations per
edge. The computation of MInt can be done in constant
time per edge if we know Int and the size of each component. Maintaining Int for a component can be done in
constant time for each merge, as the maximum weight
edge in the MST of a component is simply the edge
causing the merge. This is because Lemma 1 implies
that the edge causing the merge is the minimum weight
edge between the two components being merged. The
size of a component after a merge is simply the sum of
the sizes of the two components being merged.
Results for Grid Graphs
First we consider the case of monochrome (intensity)
images. Color images are handled as three separate
monochrome images, as discussed below. As in other
graph-based approaches to image segmentation 
we deﬁne an undirected graph G = (V, E), where each
image pixel pi has a corresponding vertex vi ∈V . The
edge set E is constructed by connecting pairs of pixels
that are neighbors in an 8-connected sense (any other
local neighborhood could be used). This yields a graph
where m = O(n), so the running time of the segmentation algorithm is O(n log n) for n image pixels. We use
an edge weight function based on the absolute intensity
difference between the pixels connected by an edge,
w(vi, v j) = |I(pi) −I(p j)|
where I(pi)istheintensityofthepixel pi.Ingeneralwe
useaGaussianﬁltertosmooththeimageslightlybefore
computing the edge weights, in order to compensate for
digitization artifacts. We always use a Gaussian with
σ = 0.8, which does not produce any visible change
to the image but helps remove artifacts.
For color images we run the algorithm three times,
once for each of the red, green and blue color planes,
and then intersect these three sets of components.
Speciﬁcally, we put two neighboring pixels in the same
component when they appear in the same component in
all three of the color plane segmentations. Alternatively
one could run the algorithm just once on a graph where
the edge weights measure the distance between pixels
in some color space, however experimentally we obtained better results by intersecting the segmentations
for each color plane in the manner just described.
There is one runtime parameter for the algorithm,
which is the value of k that is used to compute
the threshold function τ. Recall we use the function
τ(C) = k/|C| where |C| is the number of elements
in C. Thus k effectively sets a scale of observation, in
that a larger k causes a preference for larger components. We use two different parameter settings for the
examples in this section (and throughout the paper),
depending on the resolution of the image and the degree to which ﬁne detail is important in the scene. For
instance, in the 128×128 images of the COIL database
Efﬁcient Graph-Based Image Segmentation
of objects we use k = 150. In the 320 × 240 or larger
images, such as the street scene and the baseball player,
we use k = 300.
The ﬁrst image in Fig. 2 shows a street scene. Note
that there is considerable variation in the grassy slope
leading up to the fence. It is this kind of variability that
our algorithm is designed to handle (recall the high
variability region in the synthetic example in Fig. 1).
The second image shows the segmentation, where each
region is assigned a random color. The six largest components found by the algorithm are: three of the grassy
areas behind the fence, the grassy slope, the van, and
the roadway. The missing part of the roadway at the
lower left is a visibly distinct region in the color image
from which this segmentation was computed (a spot
due to an imaging artifact). Note that the van is also
not uniform in color, due to specular reﬂections, but
these are diffuse enough that they are treated as internal variation and incorporated into a single region.
The ﬁrst image in Fig. 3 shows two baseball players
 . As in the previous example, there is a grassy region with considerable variation.
The uniforms of the players also have substantial variation due to folds in the cloth. The second image shows
the segmentation. The six largest components found by
the algorithm are: the back wall, the Mets emblem, a
large grassy region (including part of the wall under
the top player), each of the two players’ uniforms, and
a small grassy patch under the second player. The large
grassy region includes part of the wall due to the relatively high variation in the region, and the fact that there
is a long slow change in intensity (not strong evidence
for a boundary) between the grass and the wall. This
“boundary” is similar in magnitude to those within the
player uniforms due to folds in the cloth.
Figure 4 shows the results of the algorithm for an
image of an indoor scene, where both ﬁne detail and
larger structures are perceptually important. Note that
the segmentation preserves small regions such as the
name tags the people are wearing and things behind
the windows, while creating single larger regions for
high variability areas such as the air conditioning duct
near the top of the image, the clothing and the furniture. This image also shows that sometimes small
“boundary regions” are found, for example at the edge
of the jacket or shirt. Such narrow regions occur because there is a one or two pixel wide area that is
halfway between the two neighboring regions in color
and intensity. This is common in any segmentation
method based on grid graphs. Such regions can be eliminated if desired, by removing long thin regions whose
color or intensity is close to the average of neighboring
Figure 5 shows three simple objects from the
Columbia COIL image database. Shown for each is the
largest region found by our algorithm that is not part
of the black background. Note that each of these objects has a substantial intensity gradient across the face
of the object, yet the regions are correctly segmented.
This illustrates another situation that the algorithm was
designed to handle, slow changes in intensity due to
Results for Nearest Neighbor Graphs
One common approach to image segmentation is based
on mapping each pixel to a point in some feature
space, and then ﬁnding clusters of similar points . In this section we investigate using the graphbased segmentation algorithm from Section 4 in order
to ﬁnd such clusters of similar points. In this case, the
graph G = (V, E) has a vertex corresponding to each
feature point (each pixel) and there is an edge (vi, v j)
connecting pairs of feature points vi and v j that are
nearby in the feature space, rather than using neighboring pixels in the image grid. There are several possible
ways of determining which feature points to connect
by edges. We connect each point to a ﬁxed number of
nearest neighbors. Another possibility is to use all the
neighbors within some ﬁxed distance d. In any event,
it is desirable to avoid considering all O(n2) pairs of
feature points.
The weight w(vi, v j) of an edge is the distance between the two corresponding points in feature space.
For the experiments shown here we map each pixel
to the feature point (x, y,r, g, b), where (x, y) is the
location of the pixel in the image and (r, g, b) is the
color value of the pixel. We use the L2 (Euclidean)
distance between points as the edge weights, although
other distance functions are possible.
The internal difference measure, Int(C), has a relatively simple underlying intuition for points in feature
space. It speciﬁes the minimum radius of dilation
necessary to connect the set of feature points contained in C together into a single volume in feature
space. Consider replacing each feature point by a ball
with radius r. From the deﬁnition of the MST it can
be seen that the union of these balls will form one
Felzenszwalb and Huttenlocher
A street scene (320 × 240 color image), and the segmentation results produced by our algorithm (σ = 0.8, k = 300).
A baseball scene (432 × 294 grey image), and the segmentation results produced by our algorithm (σ = 0.8, k = 300).
An indoor scene (image 320 × 240, color), and the segmentation results produced by our algorithm (σ = 0.8, k = 300).
single connected volume only when r ≥Int(C)/2.
The difference between components, Dif(C1, C2), also
has a simple underlying intuition. It speciﬁes the minimum radius of dilation necessary to connect at least
one point of C1 to a point of C2. Our segmentation technique is thus closely related to the work of Comaniciu
and Meer , which similarly takes an approach
to clustering based on dilating points in a parameter
space (however they ﬁrst use a novel transformation
of the data that we do not perform, and then use a
ﬁxed dilation radius rather than the variable one that we
Rather than constructing the complete graph, where
all points are neighbors of one another, we ﬁnd a
small ﬁxed number of neighbors for each point. This
results in a graph with O(n) edges for n image
Efﬁcient Graph-Based Image Segmentation
Three images from the COIL database, and the largest
non-background component found in each image (128 × 128 color
images; algorithm parameters σ = 0.8, k = 150).
pixels, and an overall running time of the segmentation method of O(n log n) time. There are many possible ways of picking a small ﬁxed number of neighbors for each point. We use the ANN algorithm to ﬁnd the nearest neighbors for
each point. This algorithm is quite fast in practice,
given a 5-dimensional feature space with several hundred thousand points. The ANN method also allows
the ﬁnding of approximate nearest neighbors, which
runs more quickly than ﬁnding the actual nearest neighbors. For the examples reported here we use ten nearest neighbors of each pixel to generate the edges of the
One of the key differences from the previous section,
where the image grid was used to deﬁne the graph,
is that the nearest neighbors in feature space capture
more spatially non-local properties of the image. In the
grid-graph case, all of the neighbors in the graph are
neighbors in the image. Here, points can be far apart
in the image and still be among a handful of nearest
A synthetic image (40 × 32 grey image) and the segmentation using the nearest neighbor graph (σ = 0, k = 150).
neighbors (if their color is highly similar and intervening image pixels are of dissimilar color). For instance,
this can result segmentations with regions that are disconnected in the image, which did not happen in the
grid-graph case.
Figure 6 shows a synthetic image from Perona and
Freeman and Gdalyahu et al. and its
segmentation, using k = 150 and with no smoothing
(σ = 0). In this example the spatially disconnected regions do not reﬂect interesting scene structures, but we
will see examples below which do.
For the remaining examples in this section, we use
k = 300 and σ = 0.8, as in the previous section.
First, we note that the nearest neighbor graph produces
similar results to the grid graph for images in which
the perceptually salient regions are spatially connected.
For instance, the street scene and baseball player scene
considered in the previous section yield very similar
segmentations using either the nearest neighbor graph
or the grid graph, as can be seen by comparing the
results in Fig. 7 with those in Figs. 2 and 3.
Figure 8 shows two additional examples using the
nearest neighbor graph. These results are not possible
to achieve with the grid graph approach because certain
interesting regions are not spatially connected. The ﬁrst
example shows a ﬂower garden, where the red ﬂowers
are spatially disjoint in the foreground of the image, and
then merge together in the background. Most of these
ﬂowers are merged into a single region, which would
not be possible with the grid-graph method. The second example in Fig. 8 shows the Eiffel tower at night.
The bright yellow light forms a spatially disconnected
region. These examples show that the segmentation
method, coupled with the use of a nearest neighbor
graph, can capture very high level properties of images, while preserving perceptually important region
boundaries.
Felzenszwalb and Huttenlocher
Segmentation of the street and baseball player scenes from the previous section, using the nearest neighbor graph rather than the
grid graph (σ = 0.8, k = 300).
Segmentation using the nearest neighbor graph can capture spatially non-local regions (σ = 0.8, k = 300).
Summary and Conclusions
In this paper we have introduced a new method for
image segmentation based on pairwise region comparison. We have shown that the notions of a segmentation
being too coarse or too ﬁne can be deﬁned in terms of a
function which measures the evidence for a boundary
between pairs of regions. Our segmentation algorithm
makes simple greedy decisions, and yet produces segmentations that obey the global properties of being not
too coarse and not too ﬁne using a particular region
comparison function. The method runs in O(m log m)
time for m graph edges and is also fast in practice,
generally running in a fraction of a second.
Efﬁcient Graph-Based Image Segmentation
The pairwise region comparison predicate we use
considers the minimum weight edge between two regions in measuring the difference between them. Thus
our algorithm will merge two regions even if there is
a single low weight edge between them. This is not
as much of a problem as it might ﬁrst appear, in part
because this edge weight is compared only to the minimum spanning tree edges of each component. For instance, the examples considered in Sections 5 and 6
illustrate that the method ﬁnds segmentations that capture many perceptually important aspects of complex
imagery. Nonetheless, one can envision measures that
require more than a single cheap connection before deciding that there is no evidence for a boundary between
two regions. One natural way of addressing this issue is
to use a quantile rather than the minimum edge weight.
However, in this case ﬁnding a segmentation that is neither too coarse nor too ﬁne is an NP-hard problem (as
shown in the Appendix). Our algorithm is unique, in
that it is both highly efﬁcient and yet captures non-local
properties of images.
We have illustrated our image segmentation algorithm with two different kinds of graphs. The ﬁrst of
these uses the image grid to deﬁne a local neighborhood
between image pixels, and measures the difference in
intensity (or color) between each pair of neighbors.
The second of these maps the image pixels to points in
a feature space that combines the (x, y) location and
(r, g, b) color value. Edges in the graph connect points
that are close together in this feature space. The algorithm yields good results using both kinds of graphs,
but the latter type of graph captures more perceptually
global aspects of the image.
Image segmentation remains a challenging problem,
however we are beginning to make substantial progress
through the introduction of graph-based algorithms
that both help reﬁne our understanding of the problem
and provide useful computational tools. The work reported here and the normalized cuts approach are just a few illustrations of these recent
Appendix: NP-Hardness of D with Quantiles
Intuitively the region comparison predicate D de-
ﬁned in Section 3.1 could be made more robust by
changing the deﬁnition of the difference between two
regions to reﬂect a quantile rather than the minimum weight edge between them. We show that with
this modiﬁcation the problem of ﬁnding a segmentation that is neither too coarse nor too ﬁne becomes
The only difference between the new problem and
the old one is the deﬁnition of the difference between
two regions C1, C2 ∈S in Eq. (2), which becomes
Dif(C1, C2) = Kth w(vi, v j)
where Kth selects the Kth quantile of its arguments
(K should be between zero and one). For example
with K = 0.5 the difference becomes the median edge
weight between the two components. This quantile is
computed over all edges (vi, v j) such that vi ∈C1 and
We reduce the min ratio cut problem with uniform
capacities and demands to the problem of ﬁnding a
good segmentation. The min ratio cut problem with
uniform capacities and demands is the following: we
are given a graph G = (V, E) and another set of edges
F. Each edge in E indicates a unit capacity between
a pair of nodes and each edge in F indicates a unit
demand between a pair of nodes. The value of a cut
(A, B) is the ratio of the total capacity and the total
demand between the sets A and B. So it is the ratio of
the number edges in E crossing the cut and the number
of edges in F crossing the cut. Finding the value of the
minimum ratio cut is an NP-hard problem (cf. Ausiello
et al., to appear).
First we show how to transform an instance of this
problem to one where the sets E and F are disjoint,
without modifying the value of the minimum cut. For
every edge (a, b) ∈E ∩F we create a new node ab,
and exchange the edge in E with the edges (a, ab) and
(b, ab). For a cut with a and b in the same side, its
always better to keep ab in that side too and the value
of the cut is the same as in the original graph. For a
cut with a and b in different sides the node ab can be
in either side and there will be one capacity and one
demand edge crossing the cut and the value of cut is
again the same as in the original graph.
Now we show how to decide if the modiﬁed instance
of the min ratio cut problem has a cut with value at
most v by solving a segmentation problem. Let c be
the number of edges from E crossing a cut (A, B) and
similarly d is the number of edges from F crossing
(A, B). It’s easy to show that the cut value is small
exactly when the fraction of edges crossing the cut that
come from F is large,
Felzenszwalb and Huttenlocher
Deﬁne G′ = (V, E′) where E′ = E ∪F. We let the
edges from E have weight zero and the edges from F
have weight one.
The graph G has a cut with value at most
v if and only if a segmentation of G′ is not one single
component, where Dif is deﬁned in Eq. (6), K = 1 −
1/(v + 1) and τ(C) = 0 for all C.
First we show that if G has a cut (A, B) with
value at most v there exists C ⊆A such that the segmentation {C, ¯C} is not too ﬁne. We just need to ﬁnd C
such that Int(C) = 0 and Dif(C, ¯C) = 1. If G has a cut
(A, B) with value at most v, than Eq. (7) tells us that
d/(c+d) ≥1/(v+1). Remember that there are d edges
of weight one and c edges of weight zero crossing the
cut. So the fraction of weight one edges crossing the
cut is at least 1/(v + 1). Look at the connected components of A using only edges of weight zero. Clearly
Int(C) = 0 for all such components. Let C be the component with largest fraction of weight one edges going
to B. This fraction must be at least 1/(v + 1). Moreover, the fraction of weight one edges between C and
¯C = V −C is at least as large since ¯C = B ∪( ¯C ∩A)
and the there are only weight one edges between C and
¯C ∩A. This implies the fraction of weight zero edges
between C and ¯C is less than 1 −1/(v + 1) = K. So
the Kth quantile weight between C and ¯C is one. Thus
Dif(C, ¯C) = 1 and the segmentation S = {C, ¯C} of
G′ is not too ﬁne. Hence the segmentation of G′ as a
single component is too coarse.
If G′ has a segmentation that is not a single
component S = {C1, . . . , Cl} then the Kth quantile
edge weight between every pair of components Ci and
C j is one (or else the segmentation would be too ﬁne).
Thus the Kth quantile edge weight between C1 and
¯C1 = C2 ∪· · · ∪Cl is one. So the fraction of weight
one edges between C1 and ¯C1 is at least 1/(v + 1).
Equation (7) implies that value of the cut (C1, ¯C1) is
at most v.
It is straightforward to see that the transformation of
the min ratio cut problem to the problem of ﬁnding a
segmentation presented above can be done in polynomial time. This is sufﬁcient to show the hardness of the
segmentation problem.
Theorem 4.
The problem of ﬁnding a segmentation
that is neither too coarse nor too ﬁne using Dif as
deﬁned in Eq. (6) is NP-hard.
Acknowledgments
This work was supported in part by gifts from Intel,
Microsoft and Xerox corporations, in part by DARPA
under contract DAAL01-97-K-0104, and in part by
NSF Research Infrastructure award CDA-9703470.
We would like to thank Shree Nayar, Jianbo Shi and
Daphna Weinshall for use of their images. We would
also like to thank Jon Kleinberg, Eva Tardos and Dan
Ramras for discussions about the algorithm and the NP
hardness result.