Learning Thermodynamics with Boltzmann Machines
Giacomo Torlai and Roger G. Melko
Perimeter Institute for Theoretical Physics, Waterloo, Ontario N2L 2Y5, Canada
Department of Physics and Astronomy, University of Waterloo, Ontario N2L 3G1, Canada
 
A Boltzmann machine is a stochastic neural network that has been extensively used in the layers of deep architectures for modern machine learning applications. In this paper, we develop a
Boltzmann machine that is capable of modelling thermodynamic observables for physical systems in
thermal equilibrium. Through unsupervised learning, we train the Boltzmann machine on data sets
constructed with spin conﬁgurations importance-sampled from the partition function of an Ising
Hamiltonian at diﬀerent temperatures using Monte Carlo (MC) methods. The trained Boltzmann
machine is then used to generate spin states, for which we compare thermodynamic observables to
those computed by direct MC sampling. We demonstrate that the Boltzmann machine can faithfully
reproduce the observables of the physical system. Further, we observe that the number of neurons
required to obtain accurate results increases as the system is brought close to criticality.
INTRODUCTION
Machine learning is a paradigm whereby computer algorithms are designed to learn from – and make predictions on – data. The success of such algorithms in the
area of classifying and extracting features from large data
sets relies on their ability to infer them without explicit
guidance from a human programmer.
Such automatic
encoding proceeds by ﬁrst “training” the algorithm on
a large data set and then asking the trained machine to
perform some task. Currently, many machine learning
applications are performed with neural networks, which
essentially ﬁt the data to a graph structure composed of
many nodes and edges. If the ultimate goal is to perform
classiﬁcation, like in image or speech recognition, the network can be trained on a labelled data set by maximizing the output probability of the correct label (supervised
learning). However, since labelled data is often scarce, a
more eﬀective strategy is to learn the full distribution of
the data using a generative model, which does not require
labels (unsupervised learning). Such generative training
allows the network to extract more information, and also
to generate approximate samples of the distribution. For
the classiﬁcation of data, this training is followed by a
supervised ﬁne-tuning, which can be done with only a
small amount of labelled data.
Although neural networks have been researched for
many decades, the performance required for solving
highly complex problems in real-world applications
has been achieved only relatively recently with deep
learning.1 Here, the networks are made up of several layers stacked such that the output of one layer becomes
the input of the next layer. The ability to learn multiple
levels of representations makes deep learning a very powerful tool in capturing features in high-dimensional data,2
and it drastically improved the performance in complex tasks such image recognition,3 speech recognition4
or natural language understanding.5 Machine learning
also has many applications in physics, and has been
successfully used to solve complex problems, including
searching for exotic particles in high-energy physics,6,
solving dynamical mean-ﬁeld theory in strong correlated
systems7 or classifying the liquid-glass transition.8 More
recently, neural networks has been also employed to identify phases of matter with and without conventional order
parameters,9 and locate the position of phase transitions
to high accuracy.10 In light of this success, one may ask
whether neural networks can be trained for other diﬃcult
problems, such as reproducing statistical-mechanical distributions of classical Hamiltonians in an unsupervised
setting. This would allow one, for example, to train a
neural network using data that has been importancesampled using Monte Carlo (MC) from a partition function, and then to calculate estimators from the distribution produced by the neural network.
A natural candidate neural network for this task is a
Boltzmann machine. A Boltzmann machine is a stochastic neural network, composed of neuron-like nodes forming a network with undirected edges. Each neuron has a
binary value that has a probabilistic element, which depends on the neighbouring units to which it is connected.
The connecting edges weigh inputs to each neuron to de-
ﬁne its state. This architecture, once elaborated, can be
used to produce approximate reconstructions of the original data set. More precisely, a reconstruction is an estimate of the probability distribution of the original input,
which is of course imperfectly contained in the limitedsize training data set. This procedure has been widely
successful, leading Boltzmann machines to become a core
piece of deep learning architectures.
In this paper, we explore the ability of Boltzmann
machines to learn ﬁnite-temperature distributions of the
classical Ising Hamiltonian and, consequently, associated
thermodynamic observables such as energy, magnetization, or speciﬁc heat. We show that faithful recreation of
observables is possible for a ﬁnite-size lattice Ising system. We also demonstrate that the number of neurons
in the networks required to recreate data at the critical
point can be much larger than in the paramagnetic or
ferromagnetic phase. This suggests that deep networks
may be required for the faithful representation of thermodynamics by Boltzmann machines at critical points.11
 
THE BOLTZMANN MACHINE
In constructing a Boltzmann machine, our goal is to
build an approximate model of a target probability distribution. For the sake of concreteness, we will consider
the Boltzmann distribution of N Ising spin variables,
weighted by the partition function, as our target distribution. It is natural to imagine sampling this distribution
with a MC procedure. In addition to producing these
samples, a MC simulation usually calculates estimators
of thermodynamic observables, such as energy or speciﬁc heat, directly from the sampled target distribution.
However, one could instead imagine obtaining estimators
from an approximate distribution constructed to mimic
our target distribution. In this scenario, spin conﬁgurations can be generated by a Boltzmann machine that was
trained by the MC samples of the target distribution. In
this section, we review the concept of sampling the target distribution for an Ising spin Hamiltonian, and detail
the construction and training of a Boltzmann machine.
In Sec. III we present the results for thermodynamic observables obtained from this Boltzmann machine, trained
on ﬁnite-temperature conﬁgurations produced from the
nearest-neighbor Ising ferromagnet.
Target probability distribution and
thermodynamic observables
Consider a system of N
classical spins on a ddimensional lattice, with Ising spin conﬁguration σ =
{σ1, σ2, · · · , σN}, and a generic Hamiltonian HS(σ)
where the S subscript indicates the physical (spin) system. When the system is at thermal equilibrium at temperature T, the “target” probability of a spin conﬁguration σ is given by the familiar Boltzmann distribution
pS(σ, T) = 1
where ZS = Trσe−HS(σ)/T is the canonical partition
With the knowledge of ZS it is possible to
compute all thermodynamic potentials and average values of observables. However, the estimation of the partition function involves a summation over all the 2N states,
which is feasible only for very small systems. The average
value of an observable O can be calculated as
if σk are samples drawn from the distribution pS(σ, T)
at temperature T.
This equation is exact only when
M →∞. However, the sampling process can be done
using Markov Chain MC simulations, leading Eq. (2) to
give an expression for a MC expectation value for ﬁnite
but large M. In the below, we consider expectation values obtained with this procedure to be the exact results
Restricted Boltzmann machine.
The visible units
(blue) are connected to the hidden nodes (red) with a symmetric matrix of weight W . The external ﬁelds in the Hamiltonian are represented by new edges with weights b and c
connecting the visible and hidden nodes respectively with ancillary units (purple and orange) with value clamped to one.
for the target probability distribution. They will be compared to observables calculated from a probability distribution generated by a Boltzmann machine, as we now
Restricted Boltzmann Machine
Given a target probability distribution pS(σ) deﬁned
over a set of random variables σ, our goal is to build a
probabilistic model pλ(σ) which mimics our target distribution. The model is in general characterized by a set
of parameters λ, which we will tune in order to minimize the distance between these two probability distributions. It is advantageous to build a joint probability
distribution on a graph, where conditional independence
between random variables in the corresponding probabilistic model can be better understood with the help of
graph theory and through visualization. We recall that
a graph is a collection of nodes and edges where to each
node is associated a variable σ and each edge represents
a probabilistic relation between nodes. A probabilistic
graphical model deﬁnes a joint probability distribution
pλ(σ) over the graph and conditional independence between the variables σ provides us with a factorization rule
for the distribution. We build the probability distribution over an undirected graph satisfying a local Markov
property (called a Markov random ﬁeld). In particular,
we adopt a bilayer architecture. Symmetric edges connect spin nodes σ ∈{0, 1}N in the so-called “visible”
layer, with “hidden” nodes h ∈{0, 1}nH in the hidden
layer (Fig. 1). The weights of the edges are described
by a matrix W with zero diagonal, where the element
Wij is the weight on the edge connecting hi to σj. We
also introduce two external ﬁelds b and c coupled to the
visible and hidden layers respectively. One can consider
the latter as weights on new edges between each visible
and hidden nodes and an ancillary node, with its variable
“clamped” (or ﬁxed) to one. Moreover, all the variables
in the graph are stochastic, comprising one major diﬀerence between this model, called a restricted Boltzmann
machine, and regular neural networks. The full probability distribution deﬁned by the graph can be written as a
Boltzmann distribution
pλ(σ, h) = 1
where the model parameters are λ = {W , b, c} and the
energy is given by
Eλ(σ, h) = −
As now the joint distribution is deﬁned over two sets of
nodes, the graph distribution over the spins is obtained
by marginalization
pλ(σ, h) = 1
where we introduced an eﬀective visible energy
log(1 + e ci+P
often called the “free energy” in literature on restricted
Boltzmann machines. This probabilistic graphical model
has a very important property used in the inference process of the states of the two layers. Since the state of
any node is sampled from a non-linear function of its inputs (its “activation”), and the activations of nodes in
the same layer are independent from each other (Fig. 1),
it is possible to sample one layer at a time, exploiting fast
linear algebra routines in numerical simulations. Moreover, for a speciﬁc choice of λ, the states of visible and
hidden layers can be inferred exactly with the posteriors pλ(σ | h) and pλ(h | σ). Because the Boltzmann machine is restricted (meaning no intra-layer connections),
the posteriors factorizes nicely as
pλ(σ | h) =
pλ(σj | h),
pλ(h | σ) =
pλ(hi | σ).
All the probabilities can be easily estimated using Bayes
pλ(σj = 1 | h) = σ
Wijhi + bj
with the function σ(x) = (1 + e−x)−1 called a “sigmoid” (a similar expression is obtained for the conditional of the hidden layer). We point out that, although
we are interested here in the generation of visible spin
states, it is straightforward to extend this network for
discriminative tasks. By adding a new layer for the labels, the resulting three-layer neural network can perform classiﬁcation with competitive accuracies on common benchmarks.12–15 Restricted Boltzmann machines
also play a central role in deep learning, for instance in
the greedy layer-by-layer pre-training of deep belief networks16,17 or in their natural multilayer extension called
deep Boltzmann machine.18,19
We have discussed how the Boltzmann machine can
generate an arbitrary probability distribution, provided
a large enough number of hidden nodes, and how we can
obtain the probability pλ(σ). As we already mentioned,
the training process consists of tuning the machine parameters λ until the pλ(σ) is close to the target distribution pS(σ). This is equivalent to solving an optimization
problem where the function to minimize is the distance
between the two distributions. This distance can be de-
ﬁned by the Kullbach-Leibler (KL) divergence
KL (pS || pλ) ≡
pS(σ) log pS(σ)
with equality only if the two distributions are identical.
We build a data set D = {σ(1), . . . , σ(|D|)} by drawing
samples σ from the Ising pS(σ) with Markov chain MC
sampling at temperature T. The probability distribution
underlying the data set is pdata(σ) =
σ′ δ(σ, σ′)
and, if the data set size |D| is large enough, pdata(σ) is
then a good approximation of pS(σ). We can then write
the KL divergence as
KL (pdata ||pλ) = −1
log pλ(σ) −H(pdata)
where the ﬁrst term is called negative log-likelihood and
H(pdata) = −P
σ pdata(σ) log pdata(σ) is the entropy of
the data set.
The optimization problem is solved by
stochastic gradient descent. We choose an initial point
λ(0) in the full conﬁguration space with zero external
ﬁelds and weights Wij randomly drawn from a uniform
distribution centered around zero. Gradient descent optimization consists of updating all the parameters with
λj ←λj −η∇λjKL (pdata || pλ).
The size η of the gradient step, called the “learning rate”,
is kept constant during the training. The increments in
the parameters are obtained by averaging the gradient of
the KL divergence over the entire data set D. However,
since the data set is usually redundant, the updates can
be evaluated on a mini-batch of samples instead, resulting in a larger number of updates for each data set sweep.
This optimization procedure, called stochastic gradient
descent, substantially speeds up the learning, especially
when the data set contains a very large number of samples. On the other hand, for data sets with moderate
number of samples, a common issue in the training of
neural networks is overﬁtting the training data set. Different techniques have been proposed to regularize the
networks and overcome the overﬁtting, such as introducing a weight decay term in the KL divergence cost function,20 or randomly removing some hidden nodes in the
network (called “dropout”21). However, producing training data is not an issue for the cases studied here, where
MC sampling is fast and eﬃcient. Thus, we build a data
set suﬃciently large to avoid using regularization. However, one could envision other cases where MC samples
are expensive, so that regularization would be required.
To obtain an update rule for the gradient descent
we need to take the derivative of the KL divergence
in Eq. (12), which reduces to the derivative of the loglikelihood,
∇λj log pλ(σ) = −∇λjEλ(σ) +
pλ(σ)∇λjEλ(σ).
If we consider for instance the case of λ = W , the derivative of the visible energy is
∇W Eλ(σ) = −
pλ(h | σ) σ h⊤.
Plugging this back into Eq. (13), we obtain
∇W KL (pdata || pλ) = −⟨σ h⊤⟩pλ(h | σ) + ⟨σ h⊤⟩pλ(σ,h).
The ﬁrst average of the correlation matrix σ h⊤can be
easily computed by clamping the spin variables σ to
the sample from the data set, and inferring the state
h of the hidden variables from the conditional distribution pλ(h | σ). In the second term however, the correlation matrix is averaged over the full model distribution
pλ(σ, h), which involves knowledge of the partition function Zλ. To overcome this issue, we instead run a MC
for k Markov steps
σ(0) →h(0) →σ(1) →h(1) →· · · →σ(k) →h(k)
by sampling each layer using the exact conditional distributions. The updates of the stochastic gradient descent
are then obtained by taking the average of Eq. (15) over
a mini-batch D[b] of samples
∇λjKL (pdata || pλ).
with b = 1, . . . , |D|/|D[b]|.
This training algorithm is
called contrastive divergence22 (CDk) and is the most
eﬀective known tool for the training of restricted Boltzmann machines. Note that since the initial state of the
chain is a sample from the data set and thus it already
belongs to the distribution, there is no need for a long
equilibration time. Hence the order k of the chain can
be very low, resulting into a very fast learning procedure. In some cases, only one step (CD1) is suﬃcient to
reconstruct the visible states with low error.
The classical spin system we choose to train the Boltzmann machine on is the Ising Hamiltonian,
HS(σ) = −J
with ferromagnetic interactions J = 1 between nearest
neighbours. As an instructive example we begin by training one machine on a one-dimensional chain with 6 spins.
For such a small system it is possible to compute the partition function, and thus the full probability distribution,
exactly. We prepare a data set of conﬁgurations using
the exact probability distribution and then train a Boltzmann machine using CD5. Because the partition function
of the Boltzmann machine is known, we can compute the
KL divergence for various sets λ, evaluating the performance of the training. By plotting the KL divergence as
a function of the training steps (Fig. 2a) we see how the
distribution generated by the machine improves towards
the data set distribution. We also show the comparison
between the true probability distribution and the ones
produced by the machine at two diﬀerent stages of the
training (Fig. 2b).
Next, we consider the more interesting case of a twodimensional system with N = L × L spins on a square
lattice with periodic boundaries. Contrary to the onedimensional case, this system undergoes a second order phase transition at Tc ≃2.269 from an ordered
ferromagnetic phase (T < Tc) to a disordered paramagnetic phase (T > Tc).
We prepare a data set DT
with 105 binary spin conﬁgurations MC-sampled from
pS(σ, T) for several temperatures in a range centered
around Tc. For each T we train a diﬀerent machine Mτ
which generates a distribution pλτ (σ), where the subscript τ refers to the physical temperature T. For each
machine we collect samples using a diﬀerent number of
hidden nodes while adopting the same external hyperparameters (learning rate, mini-batch size, number of
training steps, initial conditions, etc.). We update the
parameters with CD20 using stochastic gradient descent
with learning rate η = 0.01 and mini-batch size of 50
samples. We initialize the weights W from an uniform
distribution around zero and width w ∝
1/(nH + N).
We note that, although a larger value of contrastive divergence order k is bound to improve the learning, it
also substantially slows down the time required to reach
a solution.
It is natural to ask how the performance of each Boltzmann machine is aﬀected when the training samples are
FIG. 2. KL divergence as a function of training step (a) and
probability distributions (b) for a d = 1 Ising model with
N = 6 spins.
We show the comparison between the exact
probability distribution (red) and the approximate distribution produced by the Boltzmann machine after 10 (green) and
500 (blue) training steps for all of the 26 states σ.
taken at high or low temperature. Moreover, we are interested in whether or not a Boltzmann machine is able
to properly capture the ﬂuctuations that the system undergoes at criticality. Before discussing the quantitative
analysis of the thermodynamics, we give an insight into
the functioning of these machines by showing the histogram of the matrix elements of W (Fig. 3) after the
training at low and high temperature. In these two limits we know what the probability distribution pS(σ, T)
looks like and we can thus obtain a qualitative understanding of the training and sampling processes of the
machines. At very high temperature J/T ≪1 the spins
are completely random, so pS(σ) ≃N/2. In this case
the weights histogram of the high temperature machine
(T = 3.54) displays a sharp peak centered around zero.
This means that the visible and hidden layers are quasidecoupled, and the visible state is random since the activation probability from Eq. (9) is pλ(σj | h) ≃1/2. On
the other hand, at low temperature the two polarized
states σ = 0, 1 are most probable and this causes the
histogram to be wide and ﬂat. When we start the sampling we initialize both visible and hidden layers randomly. There is a spontaneous symmetry breaking and
the machine chooses one of the two polarizations. If the
FIG. 3. Histogram of the relative frequency of appearance
of the weight amplitudes for two Boltzmann machines with
nh = 32 hidden nodes, trained at low and high T for the
d = 2 Ising model with N = 64 spins.
machine chooses the visible state σ = 1 after equilibration, we ﬁnd, by inspecting the hidden states driving the
spins, that the hidden layer is arranged such that only the
nodes connected to the positive weights are active (and
similarly for the opposite state). The activations will be
in this case large and positive and thus pλ(σ = 1 | h) ≃1.
Note that, even though the data set is completely ergodic, once the visible layer has equilibrated into one
polarization state, it is unlikely to switch to the other.
This ergodicity issue is analogous to that faced by local Metropolis updates in MC simulations of the lowtemperature ferromagnet.
We turn now to discuss performance on the full range
of temperatures.
Since for our system it is very challenging to compute the partition function and thus the
KL divergence, we instead characterize the performance
of the machine using Ising thermodynamics observables.
Given an observable O deﬁned on the spin system we can
compare its average value computed on the spins in the
dataset at temperature T,
with that computed on the spin samples produced by
the machine Mτ. After training, we can initialize this
machine with a random conﬁguration and perform block
Gibbs sampling until equilibration. We can then build
another spin data set Sτ with these visible samples and
compute the average as,
O(σ) e−Eλ,τ (σ) ≃
If the machine is properly trained we expect the deviations δO = |⟨O(T)⟩D −⟨O(τ)⟩S| to be small.
FIG. 4. Comparison of the observables generated with the Boltzmann machine with the exact values calculated from the data
set (black) for a d = 2 Ising system with N = 64 spins. The observables considered are energy (a), magnetization (b), speciﬁc
heat (c) and magnetic susceptibility (d). We show the results for Boltzmann machines with hidden nodes nH = 4 (pink),
nH = 16 (orange) and nH = 64 (cyan).
Fig. 4 we plot the energy per spin E, the magnetization M
i σi⟩/N, the speciﬁc heat CV
(⟨E2⟩−⟨E⟩2)/(NT 2) and the magnetic susceptiblity
χ = (⟨M 2⟩−⟨M⟩2)/(NT). For the magnetization, we
ﬁnd that even with a number of hidden nodes as low as
two (not shown), the machine is able to reproduce the
exact behaviour within statistical error. This can be explained, since the learning is based on real-space spin
conﬁguration samples, and thus the magnetization is implicitly encoded into the data set.
In the case of the
energy however, even though we are computing its value
using Eq. (18) applied to the visible units, information
about the local energy constraints is not included in the
data set. This results in a larger discrepancy between the
physical value and that generated with the Boltzmann
Most interestingly, it appears that for a given physical system size N, the Boltzmann machine with a ﬁxed
nh learns best away from criticality. In Fig. 5a we plot
the scaling of the speciﬁc heat with the number of hidden nodes in the machine for ﬁve diﬀerent temperatures.
When the system is in an ordered or a disordered state,
the machines trained on the spins of the corresponding
data sets are able to reproduce the exact values within
statistical error, irrespective to nh.
This is consistent
with the weight histograms in Fig. 3. At high temperature this follows from the two layers being quasi decoupled. For low temperatures we have seen that only the
hidden nodes that connect to positive weights (or negative weights, depending on the polarization of the visible
layer) are set to 1; increasing the number of hidden nodes
will not aﬀect the activation of the visible units. Finally,
when the system is at criticality, it is still possible to
obtain an accurate approximation of the physical distribution, however a clear dependency on the ﬁnite number
of hidden units appears. As illustrated in Fig. 5a, in order to converge the speciﬁc heat at the critical point, the
required nh is signiﬁcantly larger than for T far above or
below the transition. We also note that the same scaling
plot for the magnetization (not reported here) shows no
clear dependencies on nh. Finally, we show in Fig. 5b the
scaling curves at criticality for diﬀerent system sizes. As
expected, the threshold in the number of hidden units
required for faithful learning of the speciﬁc heat grows
with increasing N.
CONCLUSIONS
We have trained a generative neural network called
a restricted Boltzmann machine to produce a stochastic model of a thermodynamic probability distribution.
The physical distributions were produced by Monte Carlo
importance-sampling the spin conﬁgurations of a ddimensional Ising system at diﬀerent temperatures. For a
small system in d = 1, we conﬁrm through an exact cal-
FIG. 5. Scaling of the speciﬁc heat CV with the number of
hidden nodes nH. In (a) we show scaling at diﬀerent temperatures T, when the system is ordered (blue and cyan), disordered (red and pink) and critical (green). In (b) we show the
scaling at criticality for diﬀerent systems sizes L. Dotted lines
represent the exact value computed on the spin conﬁgurations
of the training dataset.
culation that the Boltzmann machine converges to the
physical probability distribution with suﬃcient training
For the more diﬃcult problem of the Ising model in
d = 2, where exact calculations are impossible, we compare thermodynamic observables produced by the Boltzmann machine to those calculated directly by Monte
Spin samples produced by Monte Carlo were
used to train diﬀerent machines at distinct temperatures
above, below, and at Ising criticality Tc. Once trained,
we evaluated diﬀerent thermodynamic estimators on the
samples generated by the Boltzmann machines and show
that they faithfully reproduce those calculated directly
from the Monte Carlo samples. For all training instances
we ﬁxed the values of the hyper-parameters, and varied
the number of hidden nodes. We showed that for T > Tc
and T < Tc, the Boltzmann machine is able to capture
the thermodynamics with only a few hidden nodes. However, near T = Tc, the number of hidden nodes required
to reproduce the speciﬁc heat becomes large, reﬂecting
the increase of ﬂuctuations at criticality. This growth of
hidden nodes required at criticality is reminiscent of the
connection between deep learning and the renormalization group suggested previously.11
Our results demonstrate that Boltzmann machines
may serve as a basic research tool for condensed matter
and statistical mechanics, when coupled together with
standard Monte Carlo sampling techniques.
One application may be to use the approximate conﬁgurations
produced by the trained machine to calculate thermodynamic estimators that may have been overlooked during
the original Monte Carlo sampling (since such conﬁgurations are typically discarded). Similarly, estimator calculation could be completely transferred to the machine, in
order to re-distribute these tasks away from the Monte
Carlo procedure. Conversely, we have demonstrated that
the performance of a Boltzmann machine may be evaluated using a comparison of thermodynamic observables
calculated from both the physical and modelled distribution.
The conceptual elimination of reliance on the
KL divergence may suggest alternatives to evaluating the
performance of such machines in other applications.
Among the many possible future applications, it would
be particularly interesting to train a Boltzmann machine
on conﬁgurations produced in various bases by quantum
Monte Carlo.23 One may ask if a standard restricted
machine like studied in the present paper is suﬃcient
to capture quantum correlations, or if a quantum version of the machine is required.24 It would also be interesting to understand the relationship between the sign
problem in calculations of estimators directly in quantum Monte Carlo versus their approximation by suitablytrained Boltzmann machines.
ACKNOWLEDGMENTS
We would like to thank M. Amin, E. Andriyash, G.
Carleo, J. Carrasquilla, B. Kulchytskyy, D. Schwab, and
M. Stoudenmire for many useful discussions.
This research was supported by Natural Sciences and Engineering Research Council of Canada, the Canada Research
Chair program, the Ontario Trillium Foundation, and
the Perimeter Institute for Theoretical Physics.
Simulations were performed on resources provided by the
Shared Hierarchical Academic Research Computing Network (SHARCNET). Research at Perimeter Institute is
supported through Industry Canada and by the Province
of Ontario through the Ministry of Research & Innovation.
1 Y. LeCun, Y. Bengio,
and G. Hinton, Nature 521, 436
2 G. Hinton, Trends in Cognitive Science 10, 428 .
3 A. Krizhevsky, I. Sutskever,
and G. Hinton, Proc. Advances in Neural Information Processing Systems 25, 1090
4 G. Hinton and et al, IEEE Signal Processing Magazine 29,
82 .
Collobert,
K. Kavukcuoglu, and P. Kuksa, Journal of Machine Learning Research 12, 2493 .
6 P. Baldi, P. Sadowski, and D. Whiteson, Nature Communications 5, 4308 .
7 L. F. Arsenault, O. A. von Lilienfeld,
and A. J. Millis,
 
8 S. S. Schoenholz, E. D. Cubuk, D. M. Sussman, E. Kaxiras,
and A. J. Liu, Nature Physics 12, 469 .
9 J. Carrasquilla and R. G. Melko, arXiv:1605.01735 .
10 L. Wang, arXiv:1606.00318 .
11 P. Mehta and D. J. Schwab, arXiv:1410.3831 .
12 J. Louradour and H. Larochelle, arXiv:1103.4896 .
13 H. Larochelle and Y. Bengio, ICML08 Proceedings of the
25th international conference on Machine learning .
14 T. Schmah, G. E. Hinton, S. L. Small, S. Strother,
R. S. Zemel, Advances in neural information processing
systems , 1409 .
15 H. Larochelle, M. Mandel, R. Pascanu,
and Y. Bengio,
Journal of Machine Learning Research 13, 643 .
16 G. Hinton, S. Osindero, and Y. Teh, Neural computation
18, 1527 .
17 R. Salakhutdinov and I. Murray, ICML’08 Proceedings of
the 25th international conference on machine learning , 872
18 R. Salakhutdinov and G. Hinton, International conference
on artiﬁcial intelligence and statistics , 448 .
19 R. Salakhutdinov and G. Hinton, Neural Computation 24,
1967 .
20 A. Krogh and J. A. Hertz, Advances in neural networks
information processing systems 4, 950 .
21 N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and
R. Salakhudtinov, Journal of Machine Learning Research
2, 1929 .
22 G. Hinton, Neural computation 14, 1771 .
23 G. Carleo and M. Troyer, In preparation .
24 M. H. Amin, E. Andriyash, J. Rolfe, B. Kulchytskyy, and
R. Melko, arXiv:1601.02036 .