The Annals of Applied Statistics
2015, Vol. 9, No. 1, 247–274
DOI: 10.1214/14-AOAS788
⃝Institute of Mathematical Statistics, 2015
INFERRING CAUSAL IMPACT USING BAYESIAN STRUCTURAL
TIME-SERIES MODELS
By Kay H. Brodersen, Fabian Gallusser, Jim Koehler,
Nicolas Remy and Steven L. Scott
Google, Inc.
An important problem in econometrics and marketing is to infer the causal impact that a designed market intervention has exerted on an outcome metric over time. This paper proposes to infer causal impact on the basis of a diﬀusion-regression state-space
model that predicts the counterfactual market response in a synthetic control that would have occurred had no intervention taken
place. In contrast to classical diﬀerence-in-diﬀerences schemes, statespace models make it possible to (i) infer the temporal evolution of
attributable impact, (ii) incorporate empirical priors on the parameters in a fully Bayesian treatment, and (iii) ﬂexibly accommodate
multiple sources of variation, including local trends, seasonality and
the time-varying inﬂuence of contemporaneous covariates. Using a
Markov chain Monte Carlo algorithm for posterior inference, we illustrate the statistical properties of our approach on simulated data.
We then demonstrate its practical utility by estimating the causal
eﬀect of an online advertising campaign on search-related site visits. We discuss the strengths and limitations of state-space models
in enabling causal attribution in those settings where a randomised
experiment is unavailable. The CausalImpact R package provides an
implementation of our approach.
1. Introduction.
This article proposes an approach to inferring the causal
impact of a market intervention, such as a new product launch or the onset of
an advertising campaign. Our method generalises the widely used diﬀerencein-diﬀerences approach to the time-series setting by explicitly modelling the
counterfactual of a time series observed both before and after the intervention. It improves on existing methods in two respects: it provides a fully
Bayesian time-series estimate for the eﬀect; and it uses model averaging to
Received November 2013; revised September 2014.
Key words and phrases. Causal inference, counterfactual, synthetic control, observational, diﬀerence in diﬀerences, econometrics, advertising, market research.
This is an electronic reprint of the original article published by the
Institute of Mathematical Statistics in The Annals of Applied Statistics,
2015, Vol. 9, No. 1, 247–274. This reprint diﬀers from the original in pagination
and typographic detail.
K. H. BRODERSEN ET AL.
construct the most appropriate synthetic control for modelling the counterfactual. The CausalImpact R package provides an implementation of our
approach ( 
Inferring the impact of market interventions is an important and timely
problem. Partly because of recent interest in big data, many ﬁrms have
begun to understand that a competitive advantage can be had by systematically using impact measures to inform strategic decision making. An example is the use of “A/B experiments” to identify the most eﬀective market
treatments for the purpose of allocating resources [Danaher and Rust ,
Seggie, Cavusgil and Phelan , Leeﬂang et al. , Stewart ].
Here, we focus on measuring the impact of a discrete marketing event,
such as the release of a new product, the introduction of a new feature, or
the beginning or end of an advertising campaign, with the aim of measuring
the event’s impact on a response metric of interest (e.g., sales). The causal
impact of a treatment is the diﬀerence between the observed value of the
response and the (unobserved) value that would have been obtained under
the alternative treatment, that is, the eﬀect of treatment on the treated [Antonakis et al. , Claveau , Cox and Wermuth , Heckman
and Vytlacil , Hitchcock , Hoover , Kleinberg and Hripcsak , Morgan and Winship , Rubin ]. In the present
setting the response variable is a time series, so the causal eﬀect of interest
is the diﬀerence between the observed series and the series that would have
been observed had the intervention not taken place.
A powerful approach to constructing the counterfactual is based on the
idea of combining a set of candidate predictor variables into a single “synthetic control” [Abadie and Gardeazabal , Abadie, Diamond and Hainmueller ]. Broadly speaking, there are three sources of information
available for constructing an adequate synthetic control. The ﬁrst is the
time-series behaviour of the response itself, prior to the intervention. The
second is the behaviour of other time series that were predictive of the target series prior to the intervention. Such control series can be based, for
example, on the same product in a diﬀerent region that did not receive the
intervention or on a metric that reﬂects activity in the industry as a whole.
In practice, there are often many such series available, and the challenge is to
pick the relevant subset to use as contemporaneous controls. This selection
is done on the pre-treatment portion of potential controls; but their value
for predicting the counterfactual lies in their post-treatment behaviour. As
long as the control series received no intervention themselves, it is often reasonable to assume the relationship between the treatment and the control
series that existed prior to the intervention to continue afterwards. Thus,
a plausible estimate of the counterfactual time series can be computed up
to the point in time where the relationship between treatment and controls
can no longer be assumed to be stationary, for example, because one of the
BAYESIAN CAUSAL IMPACT ANALYSIS
controls received treatment itself. In a Bayesian framework, a third source of
information for inferring the counterfactual is the available prior knowledge
about the model parameters, as elicited, for example, by previous studies.
We combine the three preceding sources of information using a statespace time-series model, where one component of state is a linear regression
on the contemporaneous predictors. The framework of our model allows us
to choose from among a large set of potential controls by placing a spikeand-slab prior on the set of regression coeﬃcients and by allowing the model
to average over the set of controls [George and McCulloch ]. We then
compute the posterior distribution of the counterfactual time series given
the value of the target series in the pre-intervention period, along with the
values of the controls in the post-intervention period. Subtracting the predicted from the observed response during the post-intervention period gives
a semiparametric Bayesian posterior distribution for the causal eﬀect (Figure 1).
Related work.
As with other domains, causal inference in marketing requires subtlety. Marketing data are often observational and rarely follow the
ideal of a randomised design. They typically exhibit a low signal-to-noise
ratio. They are subject to multiple seasonal variations, and they are often
confounded by the eﬀects of unobserved variables and their interactions [for
recent examples, see Seggie, Cavusgil and Phelan , Stewart ,
Leeﬂang et al. , Takada and Bass , Chan et al. , Lewis
and Reiley , Lewis, Rao and Reiley , Vaver and Koehler ]. Many market interventions, however, fail
to satisfy the requirements of such approaches. For instance, advertising
campaigns are frequently launched across multiple channels, online and of-
ﬂine, which precludes measurement of individual exposure. Campaigns are
often targeted at an entire country, and one country only, which prohibits the
use of geographic controls within that country. Likewise, a campaign might
be launched in several countries but at diﬀerent points in time. Thus, while
a large control group may be available, the treatment group often consists
of no more than one region or a few regions with considerable heterogeneity
among them.
A standard approach to causal inference in such settings is based on a
linear model of the observed outcomes in the treatment and control group
before and after the intervention. One can then estimate the diﬀerence between (i) the pre-post diﬀerence in the treatment group and (ii) the pre-post
diﬀerence in the control group. The assumption underlying such diﬀerencein-diﬀerences (DD) designs is that the level of the control group provides an
K. H. BRODERSEN ET AL.
Inferring causal impact through counterfactual predictions. (a) Simulated trajectory of a treated market (Y ) with an intervention beginning in January 2014. Two other
markets (X1, X2) were not subject to the intervention and allow us to construct a synthetic
control [cf. Abadie and Gardeazabal , Abadie, Diamond and Hainmueller ].
Inverting the state-space model described in the main text yields a prediction of what would
have happened in Y had the intervention not taken place (posterior predictive expectation
of the counterfactual with pointwise 95% posterior probability intervals). (b) The diﬀerence between observed data and counterfactual predictions is the inferred causal impact of
the intervention. Here, predictions accurately reﬂect the true (Gamma-shaped) impact. A
key characteristic of the inferred impact series is the progressive widening of the posterior
intervals (shaded area). This eﬀect emerges naturally from the model structure and agrees
with the intuition that predictions should become increasingly uncertain as we look further
and further into the (retrospective) future. (c) Another way of visualizing posterior inferences is by means of a cumulative impact plot. It shows, for each day, the summed eﬀect
up to that day. Here, the 95% credible interval of the cumulative impact crosses the zero–
line about ﬁve months after the intervention, at which point we would no longer declare a
signiﬁcant overall eﬀect.
adequate proxy for the level that would have been observed in the treatment
group in the absence of treatment [see Lester , Campbell, Stanley and
Gage , Ashenfelter and Card , Card and Krueger , An-
BAYESIAN CAUSAL IMPACT ANALYSIS
grist and Krueger , Athey and Imbens , Abadie , Meyer
 , Shadish, Cook and Campbell , Donald and Lang , Angrist and Pischke , Robinson, McNulty and Krasno , Antonakis
et al. ].
DD designs have been limited in three ways. First, DD is traditionally
based on a static regression model that assumes i.i.d. data despite the fact
that the design has a temporal component. When ﬁt to serially correlated
data, static models yield overoptimistic inferences with too narrow uncertainty intervals [see also Bertrand, Duﬂo and Mullainathan , Hansen
 , Solon ]. Second, most DD analyses only consider two
time points: before and after the intervention. In practice, the manner in
which an eﬀect evolves over time, especially its onset and decay structure,
is often a key question.
Third, when DD analyses are based on time series, previous studies have
imposed restrictions on the way in which a synthetic control is constructed
from a set of predictor variables, which is something we wish to avoid.
For example, one strategy [Abadie and Gardeazabal , Abadie, Diamond and Hainmueller ] has been to choose a convex combination
(w1,...,wJ),wj ≥0,Pwj = 1 of J predictor time series in such a way that
a vector of pre-treatment variables (not time series) X1 characterising the
treated unit before the intervention is matched most closely by the combination of pre-treatment variables X0 of the control units w.r.t. a vector of
importance weights (v1,...,vJ). These weights are themselves determined in
such a way that the combination of pre-treatment outcome time series of the
control units most closely matches the pre-treatment outcome time series of
the treated unit. Such a scheme relies on the availability of interpretable
characteristics (e.g., growth predictors), and it precludes nonconvex combinations of controls when constructing the weight vector W. We prefer to
select a combination of control series without reference to external characteristics and purely in terms of how well they explain the pre-treatment outcome time series of the treated unit (while automatically balancing goodness
of ﬁt and model complexity through the use of regularizing priors). Another
idea [Belloni et al. ] has been to use classical variable-selection methods (such as the Lasso) to ﬁnd a sparse set of predictors. This approach,
however, ignores posterior uncertainty about both which predictors to use
and their coeﬃcients.
The limitations of DD schemes can be addressed by using state-space
models, coupled with highly ﬂexible regression components, to explain the
temporal evolution of an observed outcome. State-space models distinguish
between a state equation that describes the transition of a set of latent variables from one time point to the next and an observation equation that
speciﬁes how a given system state translates into measurements. This distinction makes them extremely ﬂexible and powerful [see Leeﬂang et al.
 for a discussion in the context of marketing research].
K. H. BRODERSEN ET AL.
The approach described in this paper inherits three main characteristics
from the state-space paradigm. First, it allows us to ﬂexibly accommodate
diﬀerent kinds of assumptions about the latent state and emission processes
underlying the observed data, including local trends and seasonality. Second,
we use a fully Bayesian approach to inferring the temporal evolution of
counterfactual activity and incremental impact. One advantage of this is the
ﬂexibility with which posterior inferences can be summarised. Third, we use
a regression component that precludes a rigid commitment to a particular set
of controls by integrating out our posterior uncertainty about the inﬂuence
of each predictor as well as our uncertainty about which predictors to include
in the ﬁrst place, which avoids overﬁtting.
The remainder of this paper is organised as follows. Section 2 describes
the proposed model, its design variations, the choice of diﬀuse empirical
priors on hyperparameters, and a stochastic algorithm for posterior inference based on Markov chain Monte Carlo (MCMC). Section 3 demonstrates
important features of the model using simulated data, followed by an application in Section 4 to an advertising campaign run by one of Google’s
advertisers. Section 5 puts our approach into context and discusses its scope
of application.
2. Bayesian structural time-series models.
Structural time-series models
are state-space models for time-series data. They can be deﬁned in terms of
a pair of equations
t αt + εt,
αt+1 = Ttαt + Rtηt,
where εt ∼N(0,σ2
t ) and ηt ∼N(0,Qt) are independent of all other unknowns. Equation (2.1) is the observation equation; it links the observed
data yt to a latent d-dimensional state vector αt. Equation (2.2) is the state
equation; it governs the evolution of the state vector αt through time. In
the present paper, yt is a scalar observation, Zt is a d-dimensional output
vector, Tt is a d × d transition matrix, Rt is a d × q control matrix, εt is
a scalar observation error with noise variance σt, and ηt is a q-dimensional
system error with a q × q state-diﬀusion matrix Qt, where q ≤d. Writing
the error structure of equation (2.2) as Rtηt allows us to incorporate state
components of less than full rank; a model for seasonality will be the most
important example.
Structural time-series models are useful in practice because they are ﬂexible and modular. They are ﬂexible in the sense that a very large class of
models, including all ARIMA models, can be written in the state-space form
given by (2.1) and (2.2). They are modular in the sense that the latent state
as well as the associated model matrices Zt,Tt,Rt, and Qt can be assembled
BAYESIAN CAUSAL IMPACT ANALYSIS
from a library of component sub-models to capture important features of the
data. There are several widely used state-component models for capturing
the trend, seasonality or eﬀects of holidays.
A common approach is to assume the errors of diﬀerent state-component
models to be independent (i.e., Qt is block-diagonal). The vector αt can then
be formed by concatenating the individual state components, while Tt and
Rt become block-diagonal matrices.
The most important state component for the applications considered in
this paper is a regression component that allows us to obtain counterfactual
predictions by constructing a synthetic control based on a combination of
markets that were not treated. Observed responses from such markets are
important because they allow us to explain variance components in the
treated market that are not readily captured by more generic seasonal submodels.
This approach assumes that covariates are unaﬀected by the eﬀects of
treatment. For example, an advertising campaign run in the United States
might spill over to Canada or the United Kingdom. When assuming the
absence of spill-over eﬀects, the use of such indirectly aﬀected markets as
controls would lead to pessimistic inferences, that is, the eﬀect of the campaign would be underestimated [cf. Meyer ].
2.1. Components of state.
Local linear trend.
The ﬁrst component of our model is a local linear
trend, deﬁned by the pair of equations
µt+1 = µt + δt + ηµ,t,
δt+1 = δt + ηδ,t,
where ηµ,t ∼N(0,σ2
µ) and ηδ,t ∼N(0,σ2
δ). The µt component is the value of
the trend at time t. The δt component is the expected increase in µ between
times t and t + 1, so it can be thought of as the slope at time t.
The local linear trend model is a popular choice for modelling trends because it quickly adapts to local variation, which is desirable when making
short-term predictions. This degree of ﬂexibility may not be desired when
making longer-term predictions, as such predictions often come with implausibly wide uncertainty intervals.
There is a generalisation of the local linear trend model where the slope
exhibits stationarity instead of obeying a random walk. This model can be
written as
µt+1 = µt + δt + ηµ,t,
δt+1 = D + ρ(δt −D) + ηδ,t,
K. H. BRODERSEN ET AL.
where the two components of η are independent. In this model, the slope
of the time trend exhibits AR(1) variation around a long-term slope of D.
The parameter |ρ| < 1 represents the learning rate at which the local trend is
updated. Thus, the model balances short-term information with information
from the distant past.
Seasonality.
There are several commonly used state-component models
to capture seasonality. The most frequently used model in the time domain
γt−s + ηγ,t,
where S represents the number of seasons and γt denotes their joint contribution to the observed response yt. The state in this model consists of
the S −1 most recent seasonal eﬀects, but the error term is a scalar, so
the evolution equation for this state model is less than full rank. The mean
of γt+1 is such that the total seasonal eﬀect is zero when summed over S
seasons. For example, if we set S = 4 to capture four seasons per year, the
mean of the winter coeﬃcient will be −1 × (spring + summer + autumn).
The part of the transition matrix Tt representing the seasonal model is an
S −1× S −1 matrix with −1’s along the top row, 1’s along the subdiagonal
and 0’s elsewhere.
The preceding seasonal model can be generalised to allow for multiple
seasonal components with diﬀerent periods. When modelling daily data, for
example, we might wish to allow for an S = 7 day-of-week eﬀect, as well as an
S = 52 weekly annual cycle. The latter can be handled by setting Tt = IS−1,
with zero variance on the error term, when t is not the start of a new week,
and setting Tt to the usual seasonal transition matrix, with nonzero error
variance, when t is the start of a new week.
Contemporaneous covariates with static coeﬃcients.
Control time series
that received no treatment are critical to our method for obtaining accurate counterfactual predictions since they account for variance components
that are shared by the series, including, in particular, the eﬀects of other
unobserved causes otherwise unaccounted for by the model. A natural way
of including control series in the model is through a linear regression. Its
coeﬃcients can be static or time-varying.
A static regression can be written in state-space form by setting Zt =
βTxt and αt = 1. One advantage of working in a fully Bayesian treatment is
that we do not need to commit to a ﬁxed set of covariates. The spike-andslab prior described in Section 2.2 allows us to integrate out our posterior
uncertainty about which covariates to include and how strongly they should
inﬂuence our predictions, which avoids overﬁtting.
BAYESIAN CAUSAL IMPACT ANALYSIS
All covariates are assumed to be contemporaneous; the present model does
not infer on a potential lag between treated and untreated time series. A
known lag, however, can be easily incorporated by shifting the corresponding
regressor in time.
Contemporaneous covariates with dynamic coeﬃcients.
An alternative to
the above is a regression component with dynamic regression coeﬃcients to
account for time-varying relationships [e.g., Banerjee, Kauﬀman and Wang
 , West and Harrison ]. Given covariates j = 1,...,J, this introduces the dynamic regression component
βj,t+1 = βj,t + ηβ,j,t,
where ηβ,j,t ∼N(0,σ2
βj). Here, βj,t is the coeﬃcient for the jth control series
and σβj is the standard deviation of its associated random walk. We can
write the dynamic regression component in state-space form by setting Zt =
xt and αt = βt and by setting the corresponding part of the transition matrix
to Tt = IJ×J, with Qt = diag ]. Local variability in the treated time
series is captured by the dynamic local level or dynamic linear trend component. Covariate stability is typically high when the available covariates
are close in nature to the treated metric. The empirical analyses presented
in this paper, for example, will be based on a static regression component
(Section 4). This choice provides a reasonable compromise between capturing local behaviour and accounting for regression eﬀects.
An alternative would be to use dynamic regression coeﬃcients, as we
do, for instance, in our analyses of simulated data (Section 3). Dynamic
coeﬃcients are useful when the linear relationship between treated metrics
K. H. BRODERSEN ET AL.
Graphical model for the static-regression variant of the proposed state-space
model. Observed market activity y1 : n = (y1,...,yn) is modelled as the result of a latent
state plus Gaussian observation noise with error standard deviation σy. The state αt includes a local level µt, a local linear trend δt, and a set of contemporaneous covariates xt,
scaled by regression coeﬃcients β̺. State components are assumed to evolve according to
independent Gaussian random walks with ﬁxed standard deviations σµ and σδ (conditional-dependence arrows shown for the ﬁrst time point only). The model includes empirical
priors on these parameters and the initial states. In an alternative formulation, the regression coeﬃcients β are themselves subject to random-walk diﬀusion (see main text). Of
principal interest is the posterior predictive density over the unobserved counterfactual responses ˜yn+1,..., ˜ym. Subtracting these from the actual observed data yn+1,...,ym yields
a probability density over the temporal evolution of causal impact.
and controls is believed to change over time. There are a number of ways
of reducing the computational burden of dealing with a potentially large
number of dynamic coeﬃcients. One option is to resort to dynamic latent
factors, where one uses xt = But + νt with dim(ut) ≪J and uses ut instead
of xt as part of Zt in (2.1), coupled with an AR-type model for ut itself.
Another option is latent thresholding regression, where one uses a dynamic
version of the spike-and-slab prior as in Nakajima and West .
The state-component models are assembled independently, with each component providing an additive contribution to yt. Figure 2 illustrates this process assuming a local linear trend paired with a static regression component.
2.2. Prior distributions and prior elicitation.
Let θ generically denote
the set of all model parameters and let α = (α1,...,αm) denote the full
state sequence. We adopt a Bayesian approach to inference by specifying
a prior distribution p(θ) on the model parameters as well as a distribution
p(α0|θ) on the initial state values. We may then sample from p(α,θ|y) using
BAYESIAN CAUSAL IMPACT ANALYSIS
Most of the models in Section 2.1 depend solely on a small set of variance
parameters that govern the diﬀusion of the individual state components. A
typical prior distribution for such a variance is
where G(a,b) is the Gamma distribution with expectation a/b. The prior
parameters can be interpreted as a prior sum of squares s, so that s/ν is
a prior estimate of σ2, and ν is the weight, in units of prior sample size,
assigned to the prior estimate.
We often have a weak default prior belief that the incremental errors in
the state process are small, which we can formalise by choosing small values
of ν (e.g., 1) and small values of s/ν. The notion of “small” means diﬀerent
things in diﬀerent models; for the seasonal and local linear trend models our
default priors are 1/σ2 ∼G(10−2,10−2s2
y), where s2
t(yt −¯y)2/(n −1)
is the sample variance of the target series. Scaling by the sample variance
is a minor violation of the Bayesian paradigm, but it is an eﬀective means
of choosing a reasonable scale for the prior. It is similar to the popular
technique of scaling the data prior to analysis, but we prefer to do the
scaling in the prior so we can model the data on its original scale.
When faced with many potential controls, we prefer letting the model
choose an appropriate set. This can be achieved by placing a spike-andslab prior over coeﬃcients [George and McCulloch , Polson and
Scott , Scott and Varian ]. A spike-and-slab prior combines
point mass at zero (the “spike”), for an unknown subset of zero coeﬃcients,
with a weakly informative distribution on the complementary set of nonzero
coeﬃcients (the “slab”). Contrary to what its name might suggest, the “slab”
is usually not completely ﬂat, but rather a Gaussian with a large variance.
Let ̺ = (̺1,...,̺J), where ̺j = 1 if βj ̸= 0 and ̺j = 0 otherwise. Let β̺
denote the nonzero elements of the vector β and let Σ−1
denote the rows
and columns of Σ−1 corresponding to nonzero entries in ̺. We can then
factorise the spike-and-slab prior as
p(̺,β,1/σ2
ε) = p(̺)p(σ2
ε|̺)p(β̺|̺,σ2
The spike portion of (2.8) can be an arbitrary distribution over {0,1}J in
principle; the most common choice in practice is a product of independent
Bernoulli distributions,
j (1 −πj)1−̺j,
where πj is the prior probability of regressor j being included in the model.
K. H. BRODERSEN ET AL.
Values for πj can be elicited by asking about the expected model size M,
and then setting all πj = M/J. An alternative is to use a more speciﬁc set
of values πj. In particular, one might choose to set certain πj to either 1
or 0 to force the corresponding variables into or out of the model. Generally,
framing the prior in terms of expected model size has the advantage that the
model can adapt to growing numbers of predictor variables without having
to switch to a hierarchical prior [Scott and Berger ].
For the “slab” portion of the prior we use a conjugate normal-inverse
Gamma distribution,
ε ∼N(b̺,σ2
The vector b in equation (2.10) encodes our prior expectation about the
value of each element of β. In practice, we usually set b = 0. The prior
parameters in equation (2.11) can be elicited by asking about the expected
R2 ∈ as well as the number of observations worth of weight νε the prior
estimate should be given. Then sε = νε(1 −R2)s2
The ﬁnal prior parameter in (2.10) is Σ−1, which, up to a scaling factor, is
the prior precision over β in the full model, with all variables included. The
total information in the covariates is XTX, and so 1
nXTX is the average information in a single observation. Zellner’s g-prior [Zellner , Chipman,
George and McCulloch , Liang et al. ] sets Σ−1 = g
that g can be interpreted as g observations worth of information. Zellner’s
prior becomes improper when XTX is not positive deﬁnite; we therefore
ensure propriety by averaging XTX with its diagonal,
n{wXTX + (1 −w)diag(XTX)}
with default values of g = 1 and w = 1/2. Overall, this prior speciﬁcation
provides a broadly useful default while providing considerable ﬂexibility in
those cases where more speciﬁc prior information is available.
2.3. Inference.
Posterior inference in our model can be broken down into
three pieces. First, we simulate draws of the model parameters θ and the
state vector α given the observed data y1: n in the training period. Second,
we use the posterior simulations to simulate from the posterior predictive distribution p(˜yn+1: m|y1: n) over the counterfactual time series ˜yn+1: m given
the observed pre-intervention activity y1: n. Third, we use the posterior predictive samples to compute the posterior distribution of the pointwise impact
yt −˜yt for each t = 1,...,m. We use the same samples to obtain the posterior
distribution of cumulative impact.
BAYESIAN CAUSAL IMPACT ANALYSIS
Posterior simulation.
We use a Gibbs sampler to simulate a sequence
(θ,α)(1),(θ,α)(2),... from a Markov chain whose stationary distribution is
p(θ,α|y1: n). The sampler alternates between a data-augmentation step that
simulates from p(α|y1: n,θ) and a parameter-simulation step that simulates
from p(θ|y1: n,α).
The data-augmentation step uses the posterior simulation algorithm from
Durbin and Koopman , providing an improvement over the earlier
forward-ﬁltering, backward-sampling algorithms by Carter and Kohn ,
Fr¨uhwirth-Schnatter , and de Jong and Shephard . In brief, because p(y1: n,α|θ) is jointly multivariate normal, the variance of p(α|y1: n,θ)
does not depend on y1: n. We can therefore simulate (y∗
1: n,α∗) ∼p(y1: n,α|θ)
and subtract E(α∗|y∗
1: n,θ) to obtain zero-mean noise with the correct variance. Adding E(α|y1: n,θ) restores the correct mean, which completes the
draw. The required expectations can be computed using the Kalman ﬁlter and a fast mean smoother described in detail by Durbin and Koopman
 . The result is a direct simulation from p(α|y1: n,θ) in an algorithm
that is linear in the total (pre- and post-intervention) number of time points
(m) and quadratic in the dimension of the state space (d).
Given the draw of the state, the parameter draw is straightforward for all
state components other than the static regression coeﬃcients β. All state
components that exclusively depend on variance parameters can translate
their draws back to error terms ηt and accumulate sums of squares of η,
and, because of conjugacy with equation (2.7), the posterior distribution
will remain Gamma distributed.
The draw of the static regression coeﬃcients β proceeds as follows. For
each t = 1,...,n in the pre-intervention period, let ˙yt denote yt with the
contributions from the other state components subtracted away, and let
˙y1: n = ( ˙y1,..., ˙yn). The challenge is to simulate from p(̺,β,σ2
ε| ˙y1: n), which
we can factor into p(̺|y1: n)p(1/σ2
ε|̺, ˙y1: n)p(β|̺,σε, ˙y1: n). Because of conjugacy, we can integrate out β and 1/σ2
ε and be left with
̺| ˙y1: n ∼C( ˙y1: n) |Σ−1
where C( ˙y1: n) is an unknown normalizing constant. The suﬃcient statistics
in equation (2.13) are
= (XTX)̺ + Σ−1
˜β̺ = (V −1
̺ ˙y1: n + Σ−1
N = νε + n,
S̺ = sε + ˙yT
1: n ˙y1: n + bT
To sample from (2.13), we use a Gibbs sampler that draws each ̺j given
all other ̺−j. Each full-conditional is easy to evaluate because ̺j can only
assume two possible values. It should be noted that the dimension of all
K. H. BRODERSEN ET AL.
matrices in (2.13) is P
j ̺j, which is small if the model is truly sparse. There
are many matrices to manipulate, but because each is small, the overall
algorithm is fast. Once the draw of ̺ is complete, we sample directly from
ε|̺, ˙y1: n) using standard conjugate formulae. For an alternative that
may be even more computationally eﬃcient, see Ghosh and Clyde .
Posterior predictive simulation.
While the posterior over model parameters and states p(θ,α|y1: n) can be of interest in its own right, causal impact
analyses are primarily concerned with the posterior incremental eﬀect,
p(˜yn+1: m|y1: n,x1: m).
As shown by its indices, the density in equation (2.14) is deﬁned precisely
for that portion of the time series which is unobserved: the counterfactual
market response ˜yn+1,..., ˜ym that would have been observed in the treated
market, after the intervention, in the absence of treatment.
It is also worth emphasising that the density is conditional on the observed data (as well as the priors) and only on these, that is, on activity
in the treatment market before the beginning of the intervention as well as
activity in all control markets both before and during the intervention. The
density is not conditioned on parameter estimates or the inclusion or exclusion of covariates with static regression coeﬃcients, all of which have been
integrated out. Thus, through Bayesian model averaging, we commit neither
to any particular set of covariates, which helps avoid an arbitrary selection,
nor to point estimates of their coeﬃcients, which prevents overﬁtting.
The posterior predictive density in (2.14) is deﬁned as a coherent (joint)
distribution over all counterfactual data points, rather than as a collection of
pointwise univariate distributions. This ensures that we correctly propagate
the serial structure determined on pre-intervention data to the trajectory
of counterfactuals. This is crucial, in particular, when forming summary
statistics, such as the cumulative eﬀect of the intervention on the treatment
Posterior inference was implemented in C++ with an R interface. Given
a typically-sized data set with m = 500 time points, J = 10 covariates, and
10,000 iterations (see Section 4 for an example), this implementation takes
less than 30 seconds to complete on a standard computer, enabling nearinteractive analyses.
2.4. Evaluating impact.
Samples from the posterior predictive distribution over counterfactual activity can be readily used to obtain samples from
the posterior causal eﬀect, that is, the quantity we are typically interested
in. For each draw τ and for each time point t = n + 1,...,m, we set
:= yt −˜y(τ)
BAYESIAN CAUSAL IMPACT ANALYSIS
yielding samples from the approximate posterior predictive density of the
eﬀect attributed to the intervention.
In addition to its pointwise impact, we often wish to understand the
cumulative eﬀect of an intervention over time. One of the main advantages
of a sampling approach to posterior inference is the ﬂexibility and ease with
which such derived inferences can be obtained. Reusing the impact samples
obtained in (2.15), we compute for each draw τ
∀t = n + 1,...,m.
The preceding cumulative sum of causal increments is a useful quantity
when y represents a ﬂow quantity, measured over an interval of time (e.g.,
a day), such as the number of searches, sign-ups, sales, additional installs or
new users. It becomes uninterpretable when y represents a stock quantity,
usefully deﬁned only for a point in time, such as the total number of clients,
users or subscribers. In this case we might instead choose, for each τ, to draw
a sample of the posterior running average eﬀect following the intervention,
∀t = n + 1,...,m.
Unlike the cumulative eﬀect in (2.16), the running average is always interpretable, regardless of whether it refers to a ﬂow or a stock. However,
it is more context-dependent on the length of the post-intervention period
under consideration. In particular, under the assumption of a true impact
that grows quickly at ﬁrst and then declines to zero, the cumulative impact
approaches its true total value (in expectation) as we increase the counterfactual forecasting period, whereas the average impact will eventually
approach zero (while, in contrast, the probability intervals diverge in both
cases, leading to more and more uncertain inferences as the forecasting period increases).
3. Application to simulated data.
To study the characteristics of our
approach, we analysed simulated (i.e., computer-generated) data across a
series of independent simulations. Generated time series started on 1 January
2013 and ended on 30 June 2014, with a perturbation beginning on 1 January
2014. The data were simulated using a dynamic regression component with
two covariates whose coeﬃcients evolved according to independent random
walks, βt ∼N(βt−1,0.012), initialised at β0 = 1. The covariates themselves
were simple sinusoids with wavelengths of 90 days and 360 days, respectively.
The latent state underlying the observed data was generated using a local
level that evolved according to a random walk, µt ∼N(µt−1,0.12), initialised
K. H. BRODERSEN ET AL.
Adequacy of posterior uncertainty. (a) Example of one of the 256 data sets created
to assess estimation accuracy. Simulated observations (black) are based on two contemporaneous covariates, scaled by time-varying coeﬃcients plus a time-varying local level (not
shown). During the campaign period, where the data are lifted by an eﬀect size of 10%,
the plot shows the posterior expectation of counterfactual activity (blue), along with its
pointwise central 95% credible intervals (blue shaded area), and, for comparison, the true
counterfactual (green). (b) Power curve. Following repeated application of the model to
simulated data, the plot shows the empirical frequency of concluding that a causal eﬀect
was present, as a function of true eﬀect size, given a post-intervention period of 6 months.
The curve represents sensitivity in those parts of the graph where the true eﬀect size is
positive, and 1—speciﬁcity where the true eﬀect size is zero. Error bars represent 95%
credible intervals for the true sensitivity, using a uniform Beta(1,1) prior. (c) Interval
coverage. Using an eﬀect size of 10%, the plot shows the proportion of simulations in
which the pointwise central 95% credible interval contained the true impact, as a function
of campaign duration. Intervals should contain ground truth in 95% of simulations, however much uncertainty its predictions may be associated with. Error bars represent 95%
credible intervals.
at µ0 = 0. Independent observation noise was sampled using εt ∼N(0,0.12).
In summary, observations yt were generated using
yt = βt,1zt,1 + βt,2zt,2 + µt + εt.
To simulate the eﬀect of advertising, the post-intervention portion of the
preceding series was multiplied by 1+e, where e (not to be confused with ε)
represented the true eﬀect size specifying the (uniform) relative lift during
the campaign period. An example is shown in Figure 3(a).
Sensitivity and speciﬁcity.
To study the properties of our model, we began by considering under what circumstances we successfully detected a
causal eﬀect, that is, the statistical power or sensitivity of our approach.
A related property is the probability of not detecting an absent impact,
that is, speciﬁcity. We repeatedly generated data, as described above, under
BAYESIAN CAUSAL IMPACT ANALYSIS
diﬀerent true eﬀect sizes. We then computed the posterior predictive distribution over the counterfactuals and recorded whether or not we would have
concluded a causal eﬀect.
For each of the eﬀect sizes 0%, 0.1%, 1%, 10% and 100%, a total of
28 = 256 simulations were run. This number was chosen simply on the
grounds that it provided reasonably tight intervals around the reported summary statistics without requiring excessive amounts of computation. In each
simulation, we concluded that a causal eﬀect was present if and only if the
central 95% posterior probability interval of the cumulative eﬀect excluded
The model used throughout this section comprised two structural blocks.
The ﬁrst one was a local level component. We placed an inverse-Gamma
prior on its diﬀusion variance with a prior estimate of s/ν = 0.1σy and a
prior sample size ν = 32. The second structural block was a dynamic regression component. We placed a Gamma prior with prior expectation 0.1σy on
the diﬀusion variance of both regression coeﬃcients. By construction, the
outcome variable did not exhibit any local trends or seasonality other than
the variation conveyed through the covariates. This obviated the need to
include an explicit local linear trend or seasonality component in the model.
In a ﬁrst analysis, we considered the empirical proportion of simulations
in which a causal eﬀect had been detected. When taking into account only
those simulations where the true eﬀect size was greater than zero, these
empirical proportions provide estimates of the sensitivity of the model w.r.t.
the process by which the data were generated. Conversely, those simulations
where the campaign had no eﬀect yield an estimate of the model’s speciﬁcity.
In this way, we obtained the power curve shown in Figure 3(b). The curve
shows that, in data such as these, a market perturbation leading to a lift no
larger than 1% is missed in about 90% of cases. By contrast, a perturbation
that lifts market activity by 25% is correctly detected as such in most cases.
In a second analysis, we assessed the coverage properties of the posterior probability intervals obtained through our model. It is desirable to use
a diﬀuse prior on the local level component such that central 95% intervals contain ground truth in about 95% of the simulations. This coverage
frequency should hold regardless of the length of the campaign period. In
other words, a longer campaign should lead to posterior intervals that are
appropriately widened to retain the same coverage probability as the narrower intervals obtained for shorter campaigns. This was approximately the
case throughout the simulated campaign [Figure 3(c)].
Estimation accuracy.
To study the accuracy of the point estimates supported by our approach, we repeated the preceding simulations with a ﬁxed
eﬀect size of 10% while varying the length of the campaign. When given a
quadratic loss function, the loss-minimizing point estimate is the posterior
K. H. BRODERSEN ET AL.
Estimation accuracy. (a) Time series of absolute percentage discrepancy between
inferred eﬀect and true eﬀect. The plot shows the rate (mean ± 2 s.e.m.) at which predictions become less accurate as the length of the counterfactual forecasting period increases
(blue). The well-behaved decrease in estimation accuracy breaks down when the data are
subject to a sudden structural change (red), as simulated for 1 April 2014. (b) Illustration
of a structural break. The plot shows one example of the time series underlying the red
curve in (a). On 1 April 2014, the standard deviation of the generating random walk of
the local level was tripled, causing the rapid decline in estimation accuracy seen in the red
curve in (a).
expectation of the predictive density over counterfactuals. Thus, for each
generated data set i, we computed the expected causal eﬀect for each time
ˆφi,t := ⟨φt|y1,...,ym,x1,...,xm⟩
∀t = n + 1,...,m;i = 1,...,256.
To quantify the discrepancy between estimated and true impact, we calculated the absolute percentage estimation error,
ai,t := |ˆφi,t −φt|
This yielded an empirical distribution of absolute percentage estimation errors [Figure 4(a), blue], showing that impact estimates become less and less
accurate as the forecasting period increases. This is because, under the local
linear trend model in (2.3), the true counterfactual activity becomes more
and more likely to deviate from its expected trajectory.
It is worth emphasising that all preceding results are based on the assumption that the model structure remains intact throughout the modelling
period. In other words, even though the model is built around the idea of
multiple (nonstationary) components (i.e., a time-varying local trend and,
potentially, time-varying regression coeﬃcients), this structure itself remains
BAYESIAN CAUSAL IMPACT ANALYSIS
unchanged. If the model structure does change, estimation accuracy may
We studied the impact of a changing model structure in a second simulation in which we repeated the procedure above in such a way that 90 days
after the beginning of the campaign the standard deviation of the random
walk governing the evolution of the regression coeﬃcient was tripled (now
0.03 instead of 0.01). As a result, the observed data began to diverge much
more quickly than before. Accordingly, estimations became considerably less
reliable [Figure 4(a), red]. An example of the underlying data is shown in
Figure 4(b).
The preceding simulations highlight the importance of a model that is
suﬃciently ﬂexible to account for phenomena typically encountered in seasonal empirical data. This rules out entirely static models in particular (such
as multiple linear regression).
4. Application to empirical data.
To illustrate the practical utility of
our approach, we analysed an advertising campaign run by one of Google’s
advertisers in the United States. In particular, we inferred the campaign’s
causal eﬀect on the number of times a user was directed to the advertiser’s
website from the Google search results page. We provide a brief overview
of the underlying data below [see Vaver and Koehler for additional
The campaign analysed here was based on product-related ads to be displayed alongside Google’s search results for speciﬁc keywords. Ads went live
for a period of 6 consecutive weeks and were geo-targeted to a randomised
set of 95 out of 190 designated market areas (DMAs). The most salient
observable characteristic of DMAs is oﬄine sales. To produce balance in
this characteristic, DMAs were ﬁrst rank-ordered by sales volume. Pairs of
regions were then randomly assigned to treatment/control. DMAs provide
units that can be easily supplied with distinct oﬀerings, although this ﬁnegrained split was not a requirement for the model. In fact, we carried out
the analysis as if only one treatment region had been available (formed by
summing all treated DMAs). This allowed us to evaluate whether our approach would yield the same results as more conventional treatment-control
comparisons would have done.
The outcome variable analysed here was search-related visits to the advertiser’s website, consisting of organic clicks (i.e., clicks on a search result)
and paid clicks (i.e., clicks on an ad next to the search results, for which the
advertiser was charged). Since paid clicks were zero before the campaign,
one might wonder why we could not simply count the number of paid clicks
after the campaign had started. The reason is that paid clicks tend to cannibalise some organic clicks. Since we were interested in the net eﬀect, we
worked with the total number of clicks.
K. H. BRODERSEN ET AL.
The ﬁrst building block of the model used for the analyses in this section
was a local level component. For the inverse-Gamma prior on its diﬀusion
variance we used a prior estimate of s/ν = 0.1σy and a prior sample size
ν = 32. The second structural block was a static regression component. We
used a spike-and-slab prior with an expected model size of M = 3, an expected explained variance of R2 = 0.8 and 50 prior df. We deliberately kept
the model as simple as this. Since the covariates came from a randomised
experiment, we expected them to already account for any additional local
linear trends and seasonal variation in the response variable. If one suspects
that a more complex model might be more appropriate, one could optimise model design through Bayesian model selection. Here, we focus instead
on comparing diﬀerent sets of covariates, which is critical in counterfactual
analyses regardless of the particular model structure used. Model estimation
was carried out using 10,000 MCMC samples.
Analysis 1: Eﬀect on the treated, using a randomised control.
by applying the above model to infer the causal eﬀect of the campaign on
the time series of clicks in the treated regions. Given that a set of unaﬀected
regions was available in this analysis, the best possible set of controls was
given by the untreated DMAs themselves (see below for a comparison with
a purely observational alternative).
As shown in Figure 5(a), the model provided an excellent ﬁt on the precampaign trajectory of clicks (including a spike in “week −2” and a dip at the
end of “week −1”). Following the onset of the campaign, observations quickly
began to diverge from counterfactual predictions: the actual number of clicks
was consistently higher than what would have been expected in the absence
of the campaign. The curves did not reconvene until one week after the end
of the campaign. Subtracting observed from predicted data, as we did in
Figure 5(b), resulted in a posterior estimate of the incremental lift caused
by the campaign. It peaked after about three weeks into the campaign, and
faded away after about one week after the end of the campaign. Thus, as
shown in Figure 5(c), the campaign led to a sustained cumulative increase in
total clicks (as opposed to a mere shift of future clicks into the present or a
pure cannibalization of organic clicks by paid clicks). Speciﬁcally, the overall
eﬀect amounted to 88,400 additional clicks in the targeted regions (posterior
expectation; rounded to three signiﬁcant digits), that is, an increase of 22%,
with a central 95% credible interval of [13%,30%].
To validate this estimate, we returned to the original experimental data,
on which a conventional treatment-control comparison had been carried out
using a two-stage linear model [Vaver and Koehler ]. This analysis
had led to an estimated lift of 84,700 clicks, with a 95% conﬁdence interval
for the relative expected lift of [19%,22%]. Thus, with a deviation of less
BAYESIAN CAUSAL IMPACT ANALYSIS
Causal eﬀect of online advertising on clicks in treated regions. (a) Time series
of search-related visits to the advertiser’s website (including both organic and paid clicks).
(b) Pointwise (daily) incremental impact of the campaign on clicks. Shaded vertical bars
indicate weekends. (c) Cumulative impact of the campaign on clicks.
than 5%, the counterfactual approach had led to almost precisely the same
estimate as the randomised evaluation, except for its wider intervals. The
latter is expected, given that our intervals represent prediction intervals,
not conﬁdence intervals. Moreover, in addition to an interval for the sum
over all time points, our approach yields a full time series of pointwise intervals, which allows analysts to examine the characteristics of the temporal
evolution of attributable impact.
The posterior predictive intervals in Figure 5(b) widen more slowly than
in the illustrative example in Figure 1. This is because the large number of
controls available in this data set oﬀers a much higher pre-campaign predictive strength than in the simulated data in Figure 1. This is not unexpected,
given that controls came from a randomised experiment, and we will see that
this also holds for a subsequent analysis (see below) that is based on yet an-
K. H. BRODERSEN ET AL.
other data source for predictors. A consequence of this is that there is little
variation left to be captured by the random-walk component of the model.
A reassuring ﬁnding is that the estimated counterfactual time series in Figure 5(a) eventually almost exactly rejoins the observed series, only a few
days after the end of the intervention.
Analysis 2: Eﬀect on the treated, using observational controls.
An important characteristic of counterfactual-forecasting approaches is that they do
not require a setting in which a set of controls, selected at random, was exempt from the campaign. We therefore repeated the preceding analysis in the
following way: we discarded the data from all control regions and, instead,
used searches for keywords related to the advertiser’s industry, grouped into
a handful of verticals, as covariates. In the absence of a dedicated set of
control regions, such industry-related time series can be very powerful controls, as they capture not only seasonal variations but also market-speciﬁc
trends and events (though not necessarily advertiser-speciﬁc trends). A major strength of the controls chosen here is that time series on web searches
are publicly available through Google Trends ( 
trends/). This makes the approach applicable to virtually any kind of intervention. At the same time, the industry as a whole is unlikely to be moved
by a single actor’s activities. This precludes a positive bias in estimating the
eﬀect of the campaign that would arise if a covariate was negatively aﬀected
by the campaign.
As shown in Figure 6, we found a cumulative lift of 85,900 clicks (posterior expectation), or 21%, with a [12%,30%] interval. In other words, the
analysis replicated almost perfectly the original analysis that had access to
a randomised set of controls. One feature in the response variable which
this second analysis failed to account for was a spike in clicks in the second
week before the campaign onset; this spike appeared both in treated and
untreated regions and appears to be speciﬁc to this advertiser. In addition,
the series of point-wise impact [Figure 6(b)] is slightly more volatile than
in the original analysis (Figure 5). On the other hand, the overall point
estimate of 85,900, in this case, was even closer to the randomised-design
baseline (84,700; deviation ca. 1%) than in our ﬁrst analysis (88,400; deviation ca. 4%). In summary, the counterfactual approach eﬀectively obviated
the need for the original randomised experiment. Using purely observational
variables led to the same substantive conclusions.
Analysis 3: Absence of an eﬀect on the controls.
To go one step further
still, we analysed clicks in those regions that had been exempt from the
advertising campaign. If the eﬀect of the campaign was truly speciﬁc to
treated regions, there should be no eﬀect in the controls. To test this, we
inferred the causal eﬀect of the campaign on unaﬀected regions, which should
BAYESIAN CAUSAL IMPACT ANALYSIS
Causal eﬀect of online advertising on clicks, using only searches for keywords
related to the advertiser’s industry as controls, discarding the original control regions as
would be the case in studies where a randomised experiment was not carried out. (a) Time
series of clicks on to the advertiser’s website. (b) Pointwise (daily) incremental impact
of the campaign on clicks. (c) Cumulative impact of the campaign on clicks. The plots
show that this analysis, which was based on observational covariates only, provided almost exactly the same inferences as the ﬁrst analysis (Figure 5) that had been based on a
randomised design.
not lead to a signiﬁcant ﬁnding. In analogy with our second analysis, we
discarded clicks in the treated regions and used searches for keywords related
to the advertiser’s industry as controls.
As summarised in Figure 7, no signiﬁcant eﬀect was found in unaﬀected
regions, as expected. Speciﬁcally, we obtained an overall nonsigniﬁcant lift
of 2% in clicks with a central 95% credible interval of [−6%,10%].
In summary, the empirical data considered in this section showed: (i) a
clear eﬀect of advertising on treated regions when using randomised control
regions to form the regression component, replicating previous treatmentcontrol comparisons (Figure 5); (ii) notably, an equivalent ﬁnding when dis-
K. H. BRODERSEN ET AL.
Causal eﬀect of online advertising on clicks in nontreated regions, which should
not show an eﬀect. Searches for keywords related to the advertiser’s industry are used as
controls. Plots show inferences in analogy with Figure 5. (a) Time series of clicks to the
advertiser’s website. (b) Pointwise (daily) incremental impact of the campaign on clicks.
(c) Cumulative impact of the campaign on clicks.
carding control regions and instead using observational searches for keywords
related to the advertiser’s industry as covariates (Figure 6); (iii) reassuringly,
the absence of an eﬀect of advertising on regions that were not targeted (Figure 7).
5. Discussion.
The increasing interest in evaluating the incremental impact of market interventions has been reﬂected by a growing literature on
applied causal inference. With the present paper we are hoping to contribute
to this literature by proposing a Bayesian state-space model for obtaining a
counterfactual prediction of market activity. We discuss the main features
of this model below.
BAYESIAN CAUSAL IMPACT ANALYSIS
In contrast to most previous schemes, the approach described here is fully
Bayesian, with regularizing or empirical priors for all hyperparameters. Posterior inference gives rise to complete-data (smoothing) predictions that are
only conditioned on past data in the treatment market and both past and
present data in the control markets. Thus, our model embraces a dynamic
evolution of states and, optionally, coeﬃcients (departing from classical linear regression models with a ﬁxed number of static regressors), and enables
us to ﬂexibly summarise posterior inferences.
Because closed-form posteriors for our model do not exist, we suggest a
stochastic approximation to inference using MCMC. One convenient consequence of this is that we can reuse the samples from the posterior to obtain
credible intervals for all summary statistics of interest. Such statistics include, for example, the average absolute and relative eﬀect caused by the
intervention as well as its cumulative eﬀect.
Posterior inference was implemented in C++ and R and, for all empirical
data sets presented in Section 4, took less than 30 seconds on a standard
Linux machine. If the computational burden of sampling-based inference
ever became prohibitive, one option would be to replace it by a variational
Bayesian approximation [see, e.g., Mathys et al. , Brodersen et al.
Another way of using the proposed model is for power analyses. In particular, given past time series of market activity, we can deﬁne a point in
the past to represent a hypothetical intervention and apply the model in
the usual fashion. As a result, we obtain a measure of uncertainty about the
response in the treated market after the beginning of the hypothetical intervention. This provides an estimate of what incremental eﬀect would have
been required to be outside of the 95% central interval of what would have
happened in the absence of treatment.
The model presented here subsumes several simpler models which, in consequence, lack important characteristics, but which may serve as alternatives
should the full model appear too complex for the data at hand. One example is classical multiple linear regression. In principle, classical regression
models go beyond diﬀerence-in-diﬀerences schemes in that they account for
the full counterfactual trajectory. However, they are not suited for predicting stochastic processes beyond a few steps. This is because ordinary leastsquares estimators disregard serial autocorrelation; the static model structure does not allow for temporal variation in the coeﬃcients; and predictions
ignore our posterior uncertainty about the parameters. Put diﬀerently: classical multiple linear regression is a special case of the state-space model
described here in which (i) the Gaussian random walk of the local level has
zero variance; (ii) there is no local linear trend; (iii) regression coeﬃcients
are static rather than time-varying; (iv) ordinary least squares estimators
K. H. BRODERSEN ET AL.
are used which disregard posterior uncertainty about the parameters and
may easily overﬁt the data.
Another special case of the counterfactual approach discussed in this paper is given by synthetic control estimators that are restricted to the class
of convex combinations of predictor variables and do not include time-series
eﬀects such as trends and seasonality [Abadie, Diamond and Hainmueller
 , Abadie ]. Relaxing this restriction means we can utilise predictors regardless of their scale, even if they are negatively correlated with
the outcome series of the treated unit.
Other special cases include autoregressive (AR) and moving-average (MA)
models. These models deﬁne autocorrelation among observations rather than
latent states, thus precluding the ability to distinguish between state noise
and observation noise [Ataman, Mela and Van Heerde , Leeﬂang et al.
In the scenarios we consider, advertising is a planned perturbation of the
market. This generally makes it easier to obtain plausible causal inferences
than in genuinely observational studies in which the experimenter had no
control about treatment [see discussions in Antonakis et al. , Berndt
 , Brady , Camillo and d’Attoma , Hitchcock , Kleinberg and Hripcsak , Lewis and Reiley , Lewis, Rao and Reiley
 , Robinson, McNulty and Krasno , Vaver and Koehler ,
Winship and Morgan ]. The principal problem in observational studies
is endogeneity: the possibility that the observed outcome might not be the
result of the treatment but of other omitted, endogenous variables. In principle, propensity scores can be used to correct for the selection bias that arises
when the treatment eﬀect is correlated with the likelihood of being treated
[Rubin and Waterman , Chan et al. ]. However, the propensityscore approach requires that exposure can be measured at the individual
level, and it, too, does not guarantee valid inferences, for example, in the
presence of a speciﬁc type of selection bias recently termed “activity bias”
[Lewis, Rao and Reiley ]. Counterfactual modelling approaches avoid
these issues when it can be assumed that the treatment market was chosen
at random.
Overall, we expect inferences on the causal impact of designed market interventions to play an increasingly prominent role in providing quantitative
accounts of return on investment [Danaher and Rust , Seggie, Cavusgil
and Phelan , Leeﬂang et al. , Stewart ]. This is because
marketing resources, speciﬁcally, can only be allocated to whichever campaign elements jointly provide the greatest return on ad spend (ROAS) if
we understand the causal eﬀects of spend on sales, product adoption or user
engagement. At the same time, our approach could be used for many other
applications involving causal inference. Examples include problems found in
economics, epidemiology, biology or the political and social sciences. With
BAYESIAN CAUSAL IMPACT ANALYSIS
the release of the CausalImpact R package we hope to provide a simple
framework serving all of these areas. Structural time-series models are being
used in an increasing number of applications at Google, and we anticipate
that they will prove equally useful in many analysis eﬀorts elsewhere.
Acknowledgment.
The authors wish to thank Jon Vaver for sharing the
empirical data analysed in this paper.