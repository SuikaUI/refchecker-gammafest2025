AgeDB: the ﬁrst manually collected, in-the-wild age database
Stylianos Moschoglou
Imperial College London
 
Athanasios Papaioannou
Imperial College London
 
Christos Sagonas
Imperial College London, Onﬁdo
 
Jiankang Deng
Imperial College London
 
Irene Kotsia
Middlesex University London
 
Stefanos Zafeiriou
Imperial College London
 
Over the last few years, increased interest has arisen
with respect to age-related tasks in the Computer Vision
community. As a result, several “in-the-wild” databases annotated with respect to the age attribute became available
in the literature. Nevertheless, one major drawback of these
databases is that they are semi-automatically collected and
annotated and thus they contain noisy labels. Therefore,
the algorithms that are evaluated in such databases are
prone to noisy estimates. In order to overcome such drawbacks, we present in this paper the ﬁrst, to the best of
knowledge, manually collected “in-the-wild” age database,
dubbed AgeDB, containing images annotated with accurate
to the year, noise-free labels.
As demonstrated by a series of experiments utilizing state-of-the-art algorithms, this
unique property renders AgeDB suitable when performing
experiments on age-invariant face veriﬁcation, age estimation and face age progression “in-the-wild”.
1. Introduction
Adamantly, one of the most challenging and important
tasks in Computer Vision throughout the years has been
face recognition. This spark of interest in face recognition
was ﬁrstly attributed to security reasons, since automatic facial analysis would assist security agencies in detection of
passport frauds, identiﬁcation of criminals or missing children, restriction of identity thefts, etc. The ﬁrst algorithm
for face recognition was introduced in mid 1960’s and
since then numerous approaches have been proposed in the
literature. Before the advent of deep learning in 2006 ,
construction of algorithms that were used in facial analysis
tasks required huge amount of time, domain speciﬁc knowledge and a delicate engineering process in order to transform the raw facial data in a feature space. The derived
features would then be utilized to produce the ﬁnal classiﬁcation result .
Nevertheless, successful implementation of face recognition applications also requires sufﬁciently large facial
datasets that will be utilized in order to train the algorithms.
For decades and prior to the proliferation of deep learning,
various facial datasets were introduced in the literature. One
common feature of all these datasets was that they contained images which were captured under controlled conditions (e.g., common background, controlled lighting setting, etc.).
This restriction was imposed due to the fact
that the feature extractors did not perform well on “in-thewild” datasets (i.e., datasets that included images captured
in uncontrolled conditions). Some of the most widely used
databases which included images captured under controlled
conditions were the XM2VTS database , the Multi-PIE
database , the AR face database , the Caltech
faces database , the FERET database , the
Yale face database .
During the last few years, an explosion in scientiﬁc research with respect to the development of deep learning architectures for face recognition has been witnessed. Deep
learning comprises a set of methods that are able to automatically discover the patterns that may exist in raw data
and, as a result, feature extractors which were utilized to
transform the raw data are no longer required . This
competitive advantage of deep learning methods against the
conventional algorithms led to the introduction of several
“in-the-wild” databases in the literature. The term “in-thewild” is used to refer to databases that contain images which
have been captured under completely uncontrolled conditions (e.g., varying backgrounds, existence of noise in the
pictures, existence of occlusions in the faces depicted in various images, different types of cameras used to capture the
images, etc.).
Over the past decade, various “in-the-wild” facial
databases became publicly available.
More speciﬁcally,
in 2007 the Labeled Faces “in-the-wild” (LFW) database
 was introduced. LFW contains13,233 images of
5,749 individuals, where 1,680 subjects are depicted in two
or more images and the rest appear only in one image. In
2009, PubFig database was introduced. PubFig is an
“in-the-wild” database, containing 58,797 images of 200
In 2011, YouTube Faces (YTF) database 
was introduced. YTF contains 3,425 videos of 1,595 individuals, where the average length of each video is 181.3
In 2012, WDRef database was introduced.
WDRef contains 99,773 images of 2,995 individuals, where
2,995 subjects have 15 or more images. In 2014, Celeb-
Faces database was introduced. CelebFaces
contains 202,599 images of 10,177 identities (celebrities),
where each identity has about 20 images. In 2014, CASIA-
WebFace database was introduced. CASIA-WebFace
contains 494,414 images pertaining to 10,575 subjects. In
2015, VGG Face dataset was introduced. VGG Face
dataset contains 2.6M image of 2,622 distinct individuals.
Moreover, in 2015, the IARPA Janus Benchmark A (IJB-
A) was introduced. IJB-A contains 5,712 images and
2,085 videos from 500 subjects.
In 2015 and 2016, the
MegaFace database was introduced and extended,
respectively.
MegaFace contains 4.7M images of 672K
individuals.
A table providing an overview of the most
recently introduced aforementioned databases along with
their essential statistics is presented in Table 1.
Due to the recent surge of deep learning, age estimation
from facial images has gradually gathered increased interest in the community. As of today, various deep learning
architectures have been proposed and several databases annotated with regard to the age attribute have been made publicly available. The ﬁrst database which contained images
annotated with respect to the age attribute was FG-NET
 , introduced in 2002. FG-NET includes 1,002 images,
captured under controlled conditions, pertaining to 82 subjects with accurate to the year age annotations. In 2006,
MORPH database was introduced. MORPH contains
1,724 images, pertaining to 464 subjects with accurate to
the year age annotations. In 2008, the UIUC-IFP-Y Internal
Aging Database was introduced, containing 8,000
images, captured under controlled conditions, pertaining to
1600 subjects with accurate to the year age annotations. In
2009, Gallagher group photos was introduced. Gallagher group photos is an “in-the-wild” database containing 28,231 images of 5,080 subjects. As far as the annotation with the regard to the age attribute is concerned, 7
distinct age groups are utilized. Each image is annotated
with a unique group identiﬁer. In 2011, VADANA database
 was introduced. VADANA is an “in-the-wild” database
containing 2,298 images pertaining to 43 subjects. In total
4 age groups are utilized and each image is annotated with
a unique group identiﬁer. In 2014, AdienceFaces database
 was introduced, containing 26,580 “in-the-wild” images of 2,984 subjects. In total 8 age groups are utilized and
each image is annotated with a unique group identiﬁer. In
2014, Cross-Age Celebrity Dataset (CACD) was introduced, containing 163,446 “in-the-wild” images of 2,000
celebrities. Images are annotated with a speciﬁc age label
which is semi-automatically estimated. In 2015, IMDB-
WIKI database was introduced, containing 523,051
“in-the-wild” images pertaining to 20,284 celebrities. Images are annotated with a speciﬁc age label which is semiautomatically estimated. A table providing an overview of
the aforementioned databases along with the newly introduced in this paper AgeDB database is presented in Table
Nevertheless, despite of the increased interest in age estimation “in-the-wild” and the several databases that came
into existence to tackle this task over the last years, no manually collected “in-the-wild” database with accurate to the
year age annotations has been introduced in the literature.
In order to ﬁll this gap in the literature, we present in this
paper the ﬁrst, to the best of our knowledge, manually collected “in-the-wild” age database, dubbed AgeDB. AgeDB
contains images of several subjects annotated with accurate
to the year age labels. The fact that AgeDB is manually collected to ensure the accuracy of the age labels comes with
several advantages:
• AgeDB can be used in age-invariant face veriﬁcation
“in-the-wild” experiments, i.e., the sensitivity in the
performance of face recognition algorithm can be measured as the age gap between instances (images) of the
same subject increases. Since the age labels are clean,
AgeDB ensures a noise-free evaluation of the various
face recognition algorithms.
• AgeDB can be used in age estimation “in-the-wild” experiments. Since the age labels are clean, AgeDB may
be utilized as a benchmark database for such tasks.
• AgeDB can be utilized in face age progression “inthe-wild” experiments, since it is a manually collected
database with large range of ages for each subject. This
property renders AgeDB highly beneﬁcial when training models for age progression experiments.
The structure of the paper is summarized as follows. In
Section 2, we provide all the necessary details pertaining to
the AgeDB database. In Section 3, we present the various
Table 1: Concise overview of the most broadly used “in-the-wild” facial datasets in the Computer Vision community since
2007 onwards.
# Subjects
“In-the-wild”
LFW 
PubFig 
CelebFaces 
CASIA-WebFace 
VGG Face 
IJB-A 
MegaFace 
Table 2: Concise overview of the most broadly used age datasets in the Computer Vision community since 2002 onwards.
# Subjects
Age labels
Noise-free labels
“In-the-wild”
FG-NET 
Accurate to the year
MORPH 
Accurate to the year
IFP-Y 
Accurate to the year
Gallagher 
7 age groups
VADANA 
4 age groups
AdienceFaces 
8 age groups
CACD 
Accurate to the year
IMDB-WIKI 
Accurate to the year
Accurate to the year
experiments we performed on AgeDB. More speciﬁcally,
we perform: i) various age-invariant face veriﬁcation “inthe-wild” experiments utilizing state-of-the-art pre-trained
deep networks and report their performance on AgeDB,
ii) various age estimation “in-the-wild” experiments utilizing state-of-the-art pre-trained deep networks and report their performance on AgeDB, iii) several face ageprogression “in-the-wild” experiments and report their results on AgeDB.
2. The AgeDB database
In this section we thoroughly discuss all the details pertaining to the collection of the AgeDB database
as well as provide the necessary statistics related to
the database.
The database is publicly available at:
 
As aforementioned, AgeDB is a manually collected
database to ensure that the age labels are clean as opposed
to other age databases which have been semi-automatically
collected utilizing crawlers and in which the age labels may
be noisy. In order to achieve noise-free annotation with respect to the age labels, we manually searched for images
through Google Images and subsequently kept only images
where the exact, accurate to the year age of each depicted
subject is explicitly mentioned in the accompanied caption
of the image. An indicative example of the process followed
is provided in Fig. 1.
Moreover, AgeDB is an “in-the-wild” database, meaning
it contains images captured under completely uncontrolled,
real-world conditions (i.e., having different poses, containing noise, bearing various expressions, containing occlu-
Figure 1: Screenshot captured from the Wikipedia lemma
about Albert Einstein ( ﬁg1). Since the
exact year the image was captured is available and also the
birth year is provided, the age label can be subsequently
calculated. For the image depicted in the screenshot, the
age label is 42.
sions, etc.). This feature may prove highly advantageous,
since most of the state-of-the-art deep networks are trained
and evaluated in “in-the-wild” databases.
AgeDB contains 16, 488 images of various famous people, such as actors/actresses, writers, scientists, politicians,
etc. Every image is annotated with respect to the identity,
age and gender attribute. There exist a total of 568 distinct
subjects. The average number of images per subject is 29.
The minimum and maximum age is 1 and 101, respectively.
The average age range for each subject is 50.3 years. A
scatter plot depicting the age distribution of the database is
presented in Fig. 2. Samples from the AgeDB “in-the-wild”
database along with their labels are provided in Fig. 3.
3. Experiments
In this section we present various experiments we performed on AgeDB. More speciﬁcally, we utilize state-ofthe-art algorithms and conduct experiments in tasks as ageinvariant face veriﬁcation “in-the-wild”, age estimation “inthe-wild”, face age progression “in-the-wild” and subsequently show that AgeDB constitutes a proper benchmark
for evaluating state-of-the-art algorithms for the previously
mentioned tasks.
Number of pictures per year
Figure 2: Scatter plot depicting the age distribution in the
AgeDB “in-the-wild” database.
ID: Van Damme, Jean-Claude
ID: Douglas, Michael
ID: Dalton, Timothy
ID: Sinatra, Frank
ID: Disney, Walt
Figure 3: Random images from the AgeDB “in-the-wild”
3.1. Age-invariant face veriﬁcation “in-the-wild”
AgeDB may be utilized for age-invariant face veriﬁcation “in-the-wild” experiments. To this end, following the
procedure of the veriﬁcation protocol described in the LFW
 database, we developed four new age-invariant face
veriﬁcation protocols based on the AgeDB “in-the-wild”
More speciﬁcally, for each protocol we split
AgeDB in 10 folds, with each fold consisting of 300 intraclass and 300 intra-class pairs. The main difference among
the protocols is that in each protocol the age difference of
each pair’s faces is equal to a ﬁxed, predeﬁned value, i.e.,
5, 10, 20 and 30 years. In Table 4, we report the results
from the utilization of the VGG Face deep network. In Table 3, we report the results from the Center Loss and
Marginal Loss methods. Thorough details of the experimental process that was followed are provided in .
It should be noted that this series of experiments was conducted on a subset of the ﬁnal version of the AgeDB, as
AgeDB was further extended by the time it became publicly
available.
3.2. Age estimation “in-the-wild”
Age estimation “in-the-wild” is a challenging problem
in Computer Vision and has recently gained huge interest in
the community, mainly due to the increased penetration of
deep learning techniques in the literature. The challenging
nature of this task is primarily attributed to the fact that the
databases which are publicly available and utilized for age
estimation have been semi-automatically collected and thus
contain age annotations that are noisy. As a result, age prediction based on such databases cannot be accurate, since
the algorithms are trained on data where the labels in the
ﬁrst place are not accurate. To overcome the said disadvantage, we introduce the AgeDB “in-the-wild” database, the
ﬁrst manually collected age database.
The state-of-the-art publicly available pre-trained deep
network for age estimation “in-the-wild” is DEX (Deep EXpectation of apparent age from a single image) ,
winner of the LAP challenge 2015 on apparent age estimation . We hence utilized the publicly available DEX pretrained deep network and performed age estimation in
the totality of pictures included in AgeDB.
Preprocessing
In order to feed the images of AgeDB in the pre-trained network, we followed the preprocessing process described in
 : We ﬁrstly employed the Mathias et al. face detection
algorithm and then used an extra 40% margin on the
initial bounding box boundary. Moreover, we discarded the
images in which the face detector was not able to extract a
proper bounding box containing the face. We then used the
cropped images as input in the pre-trained deep network.
Age estimation
As mentioned in , the output layer of the deep network
corresponds to a 101 dimensional vector v, representing
softmax output probabilities, one for each age between 0
and 100 included. The ﬁnal age estimation is given by the
softmax expected value, i.e.:
where yi are the years corresponding to the n-th class. A
graphical overview of the processed followed in provided
in Fig. 4.
Evaluation
As evaluation protocol we used the standard Mean Absolute
Error (MAE), which is deﬁned as the average of the absolute errors between the estimated age and the ground truth
age. For the AgeDB “in-the-wild” database, the MAE for
the pre-trained DEX deep network is 13.1 years.
3.3. Face age progression “in-the-wild”
Face age progression consists in synthesizing plausible
faces of subjects at different ages. It is considered as a very
challenging task due to the fact that the face is a highly
deformable object and its appearance drastically changes
under different illumination conditions, expressions and
poses. As mentioned in the introductory section, various
databases that contain faces at different ages have been collected in the last couple of years. Although some of these
databases possess huge number of images, they have some
limitations including limited images for each subject that
cover a narrow range of ages and noisy age labels, since
most of them have been collected by employing automatic
procedures (crawlers). AgeDB overcomes the aforementioned shortcomings.
We performed face age-progression “in-the-wild” experiments utilizing the Robust Joint and Individual Variance
Explained (RJIVE) model and other state-of-the-art algorithms for face progression, as mentioned below. In order to train RJIVE, AgeDB was split into M = 10 age
groups: 0−3, 4−7, 8−15, 16−20, 21−30, 31−40, 41−
50, 51 −60, 61 −70 and 71 −100. As a next step, in order
to effectively recover the joint and common components of
the images, the faces of each dataset should be put in correspondence. Therefore, their N = 68 facial landmarks
points are localized using the face detector from , trained
with images provided from 300-W challenge 
and subsequently employed to compute a mean reference
shape. Moreover, the faces of each dataset are warped into
corresponding reference shape by using the piecewise afﬁne
warp function W . RJIVE was then employed to extract
the joint and common components from the warped images.
The performance of RJIVE in face age progression “in-thewild” is qualitatively assessed conducting experiments on
images from the FG-NET dataset . To this end, we compare the performance of RJIVE with the Illumination Aware
Age Progression (IAAP) method , Coupled Dictionary
Learning (CDL) method , Deep Aging with Restricted
Boltzmann Machines (DARB) method , CG , and
Recurrent Face Aging (RFA) method . In Fig. 5, progressed images produced by the compared methods are depicted. Note that all progressed faces have been warped
back and fused with the actual ones.
4. Conclusion
In this paper we introduced the AgeDB database, the ﬁrst
manually collected, “in-the-wild” age database, which contains noise-free identity, gender and accurate to the year age
labels. Moreover, we utilized AgeDB along with state-ofthe-art algorithms and performed a series of experiments in
Table 3: Age-invariant face veriﬁcation in AgeDB utilizing the Centre Loss and Marginal Loss methods.
Accuracy per method
Center Loss
Marginal Loss
Table 4: Age-invariant face veriﬁcation in AgeDB utilizing the VGG Face deep network.
Accuracy per layer
tasks such as age-invariant face veriﬁcation “in-the-wild”,
age estimation “in-the-wild”, face age progression “in-thewild”. Finally, we showed that AgeDB can be utilized as
a benchmark for evaluating state-of-the-art algorithms that
aim to tackle the aforementioned tasks.
5. Acknowledgements
The authors would like to thank Mr.
Polychronis
Zafeiriou for the meticulous collection and annotation of
the AgeDB. S. Moschoglou was supported by the EPSRC
DTA studentship from Imperial College London. A. Papaioannou was funded by the European Community Horizon 2020 [H2020/2014-2020] under grant agreement no.
688520 (TeSLA). J. Deng was supported by the President’s
Scholarship of Imperial College London.
S. Zafeiriou
was partially funded by the EPSRC Project EP/N007743/1
(FACER2VM).