Springer Series in Statistics
P. Bickel, P. Diggle, S. Fienberg, K. Krickeberg,
I. Olkin, N. Wermuth, S. Zeger
Springer Series in Statistics
Andersen!Borgan/Gill/Keiding: Statistical Models Based on Counting Processes.
Atkinson/Riani: Robust Diagnostic Regression Analysis.
Atkinson/Riani!Cerioli: Exploring Multivariate Data with the Forward Search.
Berger: Statistical Decision Theory and Bayesian Analysis, 2nd edition.
Borg/Groenen: Modem Multidimensional Scaling: Theory and Applications.
Brockwell/Davis: Time Series: Theory and Methods, 2nd edition.
Bucklew: Introduction to Rare Event Simulation.
Chan/Tong: Chaos: A Statistical Perspective.
Chen!Shaollbrahim: Monte Carlo Methods in Bayesian Computation.
Coles: An Introduction to Statistical Modeling of Extreme Values.
David/Edwards: Annotated Readings in the History of Statistics.
Devroyel Lugosi: Combinatorial Methods in Density Estimation.
Efromovich: Nonparametric Curve Estimation: Methods, Theory, and Applications.
Eggermont!LaRiccia: Maximum Penalized Likelihood Estimation, Volume I:
Density Estimation.
Fahrmeir!Tutz: Multivariate Statistical Modelling Based on Generalized Linear
Models, 2nd edition.
Fan!Yao: Nonlinear Time Series: Nonparametric and Parametric Methods.
Farebrother: Fitting Linear Relationships: A History of the Calculus of Observations
1750-1900.
Federer: Statistical Design and Analysis for Intercropping Experiments, Volume I:
Two Crops.
Federer: Statistical Design and Analysis for Intercropping Experiments, Volume II:
Three or More Crops.
Ghosh!Ramamoorthi: Bayesian Nonparametrics.
Glaz/Naus/Wallenstein: Scan Statistics.
Good: Permutation Tests: A Practical Guide to Resampling Methods for Testing
Hypotheses, 2nd edition.
Good: Permutation Tests: Parametric and Bootstrap Tests of Hypotheses, 3rd edition.
Gourieroux: ARCH Models and Financial Applications.
Gu: Smoothing Spline ANOV A Models.
Gyorji!Kohler!Krzyzak/ Walk: A Distribution-Free Theory ofNonparametric
Regression.
Haberman: Advanced Statistics, Volume I: Description of Populations.
Hall: The Bootstrap and Edgeworth Expansion.
Hiirdle: Smoothing Techniques: With Implementation in S.
Harrell: Regression Modeling Strategies: With Applications to Linear Models,
Logistic Regression, and Survival Analysis.
Hart: Nonparametric Smoothing and Lack-of-Fit Tests.
Hastie/Tibshirani!Friedman: The Elements of Statistical Learning: Data Mining,
Inference, and Prediction.
Hedayat/Sloane/Stufken: Orthogonal Arrays: Theory and Applications.
Heyde: Quasi-Likelihood and its Application: A General Approach to Optimal
Parameter Estimation.
(continued after index)
Peter J. Brockwell
Richard A. Davis
Time Series:
Theory and Methods
Second Edition
With 124 Illustrations
i Springer
Peter J. 8rockwell
Richard A. Davis
Department of Statistics
Co\orado State University
Fort Coli ins, ca 80523
Mathematical Subject Classification: 62-01, 62MI0
Library of Congress Cataloging-in-Publication Data
Brockwell, Peter J.
Time series: theory and methods / Peter J. Brockwell, Richard A.
(Springer series in statistics)
"Second edition"-Pref.
Inc1udes bibliographical references and index.
ISBN 978-1-4419-0319-8
ISBN 978-1-4419-0320-4 (eBook)
DOI 10.1007/978-1-4419-0320-4
1. Time-series analysis.
1. Davis, Richard A.
II. Title.
III. Series.
519S5---{fc20
Printed on acid-frec paper.
© 1987, 1991 by Springer Science+Business Media New York
Originally published by Springer-Verlag New York, Inc. in 1991
AlI rights reserved. This work may not be translated or copied in whole or in pari without
the written permission of the publisher Springer Science+Business Media, LLC, except
for brief excerpts in connection with reviews or scholarly analysis. Use in connection with
any form of information storage and retrieval, electronic adaptation, computer software, or
by similar or dissimilar methodology now known or hereafter developed is forbidden.
The use of general descriptive names, trade names, trademarks, etc., in this publication, even if
the former are not especially identified, is not to be taken as a sign that such names, as
understood by the Trade Marks and Merchandise Marks Act, may accordingly be used freely
ISBN 978-1-4419-0319-8
springeronline. corn
To our families
Preface to the Second Edition
This edition contains a large number of additions and corrections scattered
throughout the text, including the incorporation of a new chapter on
state-space models. The companion diskette for the IBM PC has expanded
into the software package ITSM: An Interactive Time Series Modelling
Package for the PC, which includes a manual and can be ordered from
Springer-Verlag.*
We are indebted to many readers who have used the book and programs
and made suggestions for improvements. Unfortunately there is not enough
space to acknowledge all who have contributed in this way; however, special
mention must be made of our prize-winning fault-finders, Sid Resnick and
F. Pukelsheim. Special mention should also be made of Anthony Brockwell,
whose advice and support on computing matters was invaluable in the
preparation of the new diskettes. We have been fortunate to work on the
new edition in the excellent environments provided by the University of
Melbourne and Colorado State University. We thank Duane Boes
particularly for his support and encouragement throughout, and the
Australian Research Council and National Science Foundation for their
support of research related to the new material. We are also indebted to
Springer-Verlag for their constant support and assistance in preparing the
second edition.
Fort Collins, Colorado
November, 1990
P.J. BROCKWELL
R.A. DAVIS
* /TSM: An Interactive Time Series Modelling Package for the PC by P.J. Brockwell and R.A.
Davis. ISBN: 0-387-97482-2; 1991.
Preface to the Second Edition
Note added in the eighth printing: The computer programs referred to in the text
have now been superseded by the package ITSM2000, the student version of which
accompanies our other text, Introduction to Time Series and Forecasting, also
published by Springer-Verlag. Enquiries regarding purchase of the professional
version of this package should be sent to pjbrockwell @cs.com.
Preface to the First Edition
We have attempted in this book to give a systematic account of linear time
series models and their application to the modelling and prediction of data
collected sequentially in time. The aim is to provide specific techniques for
handling data and at the same time to provide a thorough understanding of
the mathematical basis for the techniques. Both time and frequency domain
methods are discussed but the book is written in such a way that either
approach could be emphasized. The book is intended to be a text for graduate
students in statistics, mathematics, engineering, and the natural or social
sciences. It has been used both at the M.S. level, emphasizing the more
practical aspects of modelling, and at the Ph.D. level, where the detailed
mathematical derivations of the deeper results can be included.
Distinctive features of the book are the extensive use of elementary Hilbert
space methods and recursive prediction techniques based on innovations, use
of the exact Gaussian likelihood and AIC for inference, a thorough treatment
of the asymptotic behavior of the maximum likelihood estimators of the
coefficients of univariate ARMA models, extensive illustrations of the techniques by means of numerical examples, and a large number of problems for
the reader. The companion diskette contains programs written for the IBM
PC, which can be used to apply the methods described in the text. Data sets
can be found in the Appendix, and a more extensive collection (including most
ofthose used for the examples in Chapters l, 9, 10, 11 and 12) is on the diskette.
Simulated ARMA series can easily be generated and filed using the program
PEST. Valuable sources of additional time-series data are the collections of
Makridakis et al. and Working Paper 109 of Scientific Computing
Associates, DeKalb, Illinois.
Most of the material in the book is by now well-established in the time
series literature and we have therefore not attempted to give credit for all the
Preface to the First Edition
results discussed. Our indebtedness to the authors of some of the well-known
existing books on time series, in particular Anderson, Box and Jenkins, Fuller,
Grenander and Rosenblatt, Hannan, Koopmans and Priestley will however
be apparent. We were also fortunate to have access to notes on time series by
W. Dunsmuir. To these and to the many other sources that have influenced
our presentation of the subject we express our thanks.
Recursive techniques based on the Kalman filter and state-space representations of ARMA processes have played an important role in many recent
developments in time series analysis. In particular the Gaussian likelihood of
a time series can be expressed very simply in terms of the one-step linear
predictors and their mean squared errors, both of which can be computed
recursively using a Kalman filter. Instead of using a state-space representation
for recursive prediction we utilize the innovations representation of an arbitrary Gaussian time series in order to compute best linear predictors and exact
Gaussian likelihoods. This approach, developed by Rissanen and Barbosa,
Kailath, Ansley and others, expresses the value of the series at time t in terms
of the one-step prediction errors up to that time. This representation provides
insight into the structure of the time series itself as well as leading to simple
algorithms for simulation, prediction and likelihood calculation.
These algorithms are used in the parameter estimation program (PEST)
found on the companion diskette. Given a data set of up to 2300 observations,
the program can be used to find preliminary, least squares and maximum
Gaussian likelihood estimators of the parameters of any prescribed A RIMA
model for the data, and to predict future values. It can also be used to simulate
values of an ARMA process and to compute and plot its theoretical autocovariance and spectral density functions. Data can be plotted, differenced,
deseasonalized and detrended. The program will also plot the sample autocorrelation and partial autocorrelation functions of both the data itself and
the residuals after model-fitting. The other time-series programs are SPEC,
which computes spectral estimates for univariate or bivariate series based on
the periodogram, and TRANS, which can be used either to compute and plot
the sample cross-correlation function of two series, or to perform least squares
estimation of the coefficients in a transfer function model relating the second
series to the first (see Section 12.2). Also included on the diskette is a screen
editing program (WORD6), which can be used to create arbitrary data files,
and a collection of data files, some of which are analyzed in the book.
Instructions for the use of these programs are contained in the file HELP on
the diskette.
For a one-semester course on time-domain analysis and modelling at the
M.S. level, we have used the following sections of the book:
1.1-1.6; 2.1-2. 7; 3.1-3.5; 5.1-5.5; 7.1, 7.2; 8.1-8.9; 9.1-9.6
(with brief reference to Sections 4.2 and 4.4). The prerequisite for this course
is a knowledge of probability and statistics at the level of the book Introduction
to the Theory of Statistics by Mood, Graybill and Boes.
Preface to the First Edition
For a second semester, emphasizing frequency-domain analysis and multivariate series, we have used
4.1-4.4, 4.6-4.1 0; 10.1-10. 7; 11.1-11. 7; selections from Chap. 12.
At the M.S. level it has not been possible (or desirable) to go into the mathematical derivation of all the results used, particularly those in the starred
sections, which require a stronger background in mathematical analysis and
measure theory. Such a background is assumed in all of the starred sections
and problems.
For Ph.D. students the book has been used as the basis for a more
theoretical one-semester course covering the starred sections from Chapters
4 through 11 and parts of Chapter 12. The prerequisite for this course is a
knowledge of measure-theoretic probability.
We are greatly indebted to E.J. Hannan, R.H. Jones, S.l. Resnick, S.Tavare
and D. Tjostheim, whose comments on drafts of Chapters 1-8 led to substantial improvements. The book arose out of courses taught in the statistics
department at Colorado State University and benefitted from the comments
of many students. The development of the computer programs would not have
been possible without the outstanding work of Joe Mandarino, the architect
of the computer program PEST, and Anthony Brockwell, who contributed
WORD6, graphics subroutines and general computing expertise. We are
indebted also to the National Science Foundation for support for the research
related to the book, and one of us (P.J.B.) to Kuwait University for providing
an excellent environment in which to work on the early chapters. For permission to use the optimization program UNC22MIN we thank R. Schnabel of
the University of Colorado computer science department. Finally we thank
Pam Brockwell, whose contributions to the manuscript went far beyond those
of typist, and the editors of Springer-Verlag, who showed great patience and
cooperation in the final production of the book.
Fort Collins, Colorado
October 1986
P.J. BROCKWELL
R.A. DAVIS
Preface to the Second Edition
Preface to the First Edition
Stationary Time Series
Examples of Time Series
Stochastic Processes
Stationarity and Strict Stationarity
The Estimation and Elimination of Trend and Seasonal Components
The Autocovariance Function of a Stationary Process
The Multivariate Normal Distribution
Applications of Kolmogorov's Theorem
Hilbert Spaces
Inner-Product Spaces and Their Properties
Hilbert Spaces
The Projection Theorem
Orthonormal Sets
Projection in IR"
Linear Regression and the General Linear Model
Mean Square Convergence, Conditional Expectation and Best
Linear Prediction in L 2(Q, Ji', P)
Fourier Series
Hilbert Space Isomorphisms
§2.10* The Completeness of L 2(0., ~. P)
§2.11 * Complementary Results for Fourier Series
Stationary ARMA Processes
Causal and Invertible ARMA Processes
Moving Average Processes of Infinite Order
Computing the Autocovariance Function of an ARMA(p, q) Process
The Partial Autocorrelation Function
The Autocovariance Generating Function
Homogeneous Linear Difference Equations with
Constant Coefficients
The Spectral Representation of a Stationary Process
Complex-Valued Stationary Time Series
The Spectral Distribution of a Linear Combination of Sinusoids
Herglotz's Theorem
Spectral Densities and ARMA Processes
Circulants and Their Eigenvalues
Orthogonal Increment Processes on [- n, n]
Integration with Respect to an Orthogonal Increment Process
The Spectral Representation
Inversion Formulae
§4.10* Time-Invariant Linear Filters
§4.11 * Properties of the Fourier Approximation h. to J1v.roJ
Prediction of Stationary Processes
The Prediction Equations in the Time Domain
Recursive Methods for Computing Best Linear Predictors
Recursive Prediction of an ARMA(p, q) Process
Prediction of a Stationary Gaussian Process; Prediction Bounds
Prediction of a Causal Invertible ARMA Process in
Terms of Xi, - oo <j ~ n
Prediction in the Frequency Domain
The Wold Decomposition
Kolmogorov's Formula
CHAPTER 6*
Asymptotic Theory
Convergence in Probability
Convergence in r1h Mean, r > 0
Convergence in Distribution
Central Limit Theorems and Related Results
Estimation of the Mean and the Autocovariance Function
Estimation of J1
Estimation of y( ·)and p( ·)
Derivation of the Asymptotic Distributions
Estimation for ARMA Models
The Yule-Walker Equations and Parameter Estimation for
Autoregressive Processes
Preliminary Estimation for Autoregressive Processes Using the
Durbin-Levinson Algorithm
Preliminary Estimation for Moving Average Processes Using the
Innovations Algorithm
Preliminary Estimation for ARMA(p, q) Processes
Remarks on Asymptotic Efficiency
Recursive Calculation of the Likelihood of an Arbitrary
Zero-Mean Gaussian Process
Maximum Likelihood and Least Squares Estimation for
ARMA Processes
Asymptotic Properties of the Maximum Likelihood Estimators
Confidence Intervals for the Parameters of a Causal Invertible
ARMA Process
§8.10* Asymptotic Behavior of the Yule-Walker Estimates
§8.11 * Asymptotic Normality of Parameter Estimators
Model Building and Forecasting with ARIMA Processes
ARIMA Models for Non-Stationary Time Series
Identification Techniques
Order Selection
Diagnostic Checking
Forecasting ARIMA Models
Seasonal ARIMA Models
CHAPTER 10
Inference for the Spectrum of a Stationary Process
The Periodogram
Testing for the Presence of Hidden Periodicities
Asymptotic Properties of the Periodogram
§10.4 Smoothing the Periodogram
Confidence Intervals for the Spectrum
Autoregressive, Maximum Entropy, Moving Average and
Maximum Likelihood ARMA Spectral Estimators
The Fast Fourier Transform (FFT) Algorithm
§10.8* Derivation of the Asymptotic Behavior of the Maximum
Likelihood and Least Squares Estimators of the Coefficients of
an ARMA Process
CHAPTER II
Multivariate Time Series
Second Order Properties of Multivariate Time Series
Estimation of the Mean and Covariance Function
Multivariate ARMA Processes
§ 11.4 Best Linear Predictors of Second Order Random Vectors
Estimation for Multivariate ARMA Processes
§11.6 The Cross Spectrum
Estimating the Cross Spectrum
§11.8* The Spectral Representation of a Multivariate Stationary
Time Series
CHAPTER 12
State-Space Models and the Kalman Recursions
State-Space Models
§12.2 The Kalman Recursions
State-Space Models with Missing Observations
§12.4 Controllability and Observability
Recursive Bayesian State Estimation
CHAPTER 13
Further Topics
Transfer Function Modelling
§13.2 Long Memory Processes
Linear Processes with Infinite Variance
§13.4 Threshold Models
Appendix: Data Sets