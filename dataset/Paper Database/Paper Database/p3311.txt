FFDNet: Toward a Fast and Flexible Solution for
CNN based Image Denoising
Kai Zhang, Wangmeng Zuo, Senior Member, IEEE, and Lei Zhang, Fellow, IEEE
Abstract—Due to the fast inference and good performance,
discriminative learning methods have been widely studied in
image denoising. However, these methods mostly learn a speciﬁc
model for each noise level, and require multiple models for
denoising images with different noise levels. They also lack
ﬂexibility to deal with spatially variant noise, limiting their
applications in practical denoising. To address these issues,
we present a fast and ﬂexible denoising convolutional neural
network, namely FFDNet, with a tunable noise level map as
the input. The proposed FFDNet works on downsampled subimages, achieving a good trade-off between inference speed and
denoising performance. In contrast to the existing discriminative
denoisers, FFDNet enjoys several desirable properties, including
(i) the ability to handle a wide range of noise levels (i.e., ) effectively with a single network, (ii) the ability to remove
spatially variant noise by specifying a non-uniform noise level
map, and (iii) faster speed than benchmark BM3D even on CPU
without sacriﬁcing denoising performance. Extensive experiments
on synthetic and real noisy images are conducted to evaluate
FFDNet in comparison with state-of-the-art denoisers. The results
show that FFDNet is effective and efﬁcient, making it highly
attractive for practical denoising applications.
Index Terms—Image denoising, convolutional neural networks,
Gaussian noise, spatially variant noise
I. INTRODUCTION
HE importance of image denoising in low level vision can
be revealed from many aspects. First, noise corruption is
inevitable during the image sensing process and it may heavily
degrade the visual quality of acquired image. Removing noise
from the observed image is an essential step in various image
processing and computer vision tasks , . Second, from
the Bayesian perspective, image denoising is an ideal test
bed for evaluating image prior models and optimization methods , , . Last but not least, in the unrolled inference via
variable splitting techniques, many image restoration problems
can be addressed by sequentially solving a series of denoising
subproblems, which further broadens the application ﬁelds of
image denoising , , , .
As in many previous literature of image denoising ,
 , , , in this paper we assume that the noise is
This project is partially supported by the National Natural Scientiﬁc
Foundation of China (NSFC) under Grant No. 61671182 and 61471146, and
the HK RGC GRF grant (under no. PolyU 152124/15E).
K. Zhang is with the School of Computer Science and Technology, Harbin
Institute of Technology, Harbin 150001, China, and also with the Department
of Computing, The Hong Kong Polytechnic University, Hong Kong (e-mail:
 ).
W. Zuo is with the School of Computer Science and Technology, Harbin Institute of Technology, Harbin 150001, China (e-mail: ).
L. Zhang is with the Department of Computing, The Hong Kong Polytechnic University, Hong Kong (e-mail: ).
additive white Gaussian noise (AWGN) and the noise level is
given. In order to handle practical image denoising problems,
a ﬂexible image denoiser is expected to have the following
desirable properties: (i) it is able to perform denoising using
a single model; (ii) it is efﬁcient, effective and user-friendly;
and (iii) it can handle spatially variant noise. Such a denoiser
can be directly deployed to recover the clean image when the
noise level is known or can be well estimated. When the noise
level is unknown or is difﬁcult to estimate, the denoiser should
allow the user to adaptively control the trade-off between noise
reduction and detail preservation. Furthermore, the noise can
be spatially variant and the denoiser should be ﬂexible enough
to handle spatially variant noise.
However, state-of-the-art image denoising methods are still
limited in ﬂexibility or efﬁciency. In general, image denoising
methods can be grouped into two major categories, modelbased methods and discriminative learning based ones. Modelbased methods such as BM3D and WNNM are
ﬂexible in handling denoising problems with various noise
levels, but they suffer from several drawbacks. For example,
their optimization algorithms are generally time-consuming,
and cannot be directly used to remove spatially variant noise.
Moreover, model-based methods usually employ hand-crafted
image priors (e.g., sparsity , and nonlocal selfsimilarity , , ), which may not be strong enough
to characterize complex image structures.
As an alternative, discriminative denoising methods aim
to learn the underlying image prior and fast inference from
a training set of degraded and ground-truth image pairs.
One approach is to learn stage-wise image priors in the
context of truncated inference procedure . Another more
popular approach is plain discriminative learning, such as the
MLP and convolutional neural network (CNN) based
methods , , among which the DnCNN method has
achieved very competitive denoising performance. The success
of CNN for image denoising is attributed to its large modeling
capacity and tremendous advances in network training and
design. However, existing discriminative denoising methods
are limited in ﬂexibility, and the learned model is usually
tailored to a speciﬁc noise level. From the perspective of
regression, they aim to learn a mapping function x = F(y; Θσ)
between the input noisy observation y and the desired output
x. The model parameters Θσ are trained for noisy images
corrupted by AWGN with a ﬁxed noise level σ, while the
trained model with Θσ is hard to be directly deployed to
images with other noise levels. Though a single CNN model
(i.e., DnCNN-B) is trained in for Gaussian denoising, it
does not generalize well to real noisy images and works only
 
if the noise level is in the preset range, e.g., . Besides,
all the existing discriminative learning based methods lack
ﬂexibility to deal with spatially variant noise.
To overcome the drawbacks of existing CNN based denoising methods, we present a fast and ﬂexible denoising convolutional neural network (FFDNet). Speciﬁcally, our FFDNet
is formulated as x = F(y, M; Θ), where M is a noise level
map. In the DnCNN model x = F(y; Θσ), the parameters Θσ
vary with the change of noise level σ, while in the FFDNet
model, the noise level map is modeled as an input and the
model parameters Θ are invariant to noise level. Thus, FFDNet
provides a ﬂexible way to handle different noise levels with a
single network.
By introducing a noise level map as input, it is natural to
expect that the model performs well when the noise level map
matches the ground-truth one of noisy input. Furthermore, the
noise level map should also play the role of controlling the
trade-off between noise reduction and detail preservation. It is
found that heavy visual quality degradation may be engendered
when setting a larger noise level to smooth out the details.
We highlight this problem and adopt a method of orthogonal
initialization on convolutional ﬁlters to alleviate this. Besides,
the proposed FFDNet works on downsampled sub-images,
which largely accelerates the training and testing speed, and
enlarges the receptive ﬁeld as well.
Using images corrupted by AWGN, we quantitatively compare FFDNet with state-of-the-art denoising methods, including model-based methods such as BM3D and WNNM 
and discriminative learning based methods such as TNRD 
and DnCNN . The results clearly demonstrate the superiority of FFDNet in terms of both denoising performance
and computational efﬁciency. In addition, FFDNet performs
favorably on images corrupted by spatially variant AWGN.
We further evaluate FFDNet on real-world noisy images,
where the noise is often signal-dependent, non-Gaussian and
spatially variant. The proposed FFDNet model still achieves
perceptually convincing results by setting proper noise level
maps. Overall, FFDNet enjoys high potentials for practical
denoising applications.
The main contribution of our work is summarized as follows:
• A fast and ﬂexible denoising network, namely FFDNet, is
proposed for discriminative image denoising. By taking a
tunable noise level map as input, a single FFDNet is able
to deal with noise on different levels, as well as spatially
variant noise.
• We highlight the importance to guarantee the role of the
noise level map in controlling the trade-off between noise
reduction and detail preservation.
• FFDNet exhibits perceptually appealing results on both
synthetic noisy images corrupted by AWGN and realworld noisy images, demonstrating its potential for practical image denoising.
The remainder of this paper is organized as follows. Sec. II
reviews existing discriminative denoising methods. Sec. III
presents the proposed image denoising model. Sec. IV reports
the experimental results. Sec. V concludes the paper.
II. RELATED WORK
In this section, we brieﬂy review and discuss the two major
categories of relevant methods to this work, i.e., maximum a
posteriori (MAP) inference guided discriminative learning and
plain discriminative learning.
A. MAP Inference Guided Discriminative Learning
Instead of ﬁrst learning the prior and then performing the
inference, this category of methods aims to learn the prior
parameters along with a compact unrolled inference through
minimizing a loss function . Following the pioneer work
of ﬁelds of experts , Barbu trained a discriminative
Markov random ﬁeld (MRF) model together with a gradient
descent inference for image denoising. Samuel and Tappen independently proposed a compact gradient descent
inference learning framework, and discussed the advantages of
discriminative learning over model-based optimization method
with MRF prior. Sun and Tappen proposed a novel
nonlocal range MRF (NLR-MRF) framework, and employed
the gradient-based discriminative learning method to train the
model. Generally speaking, the methods above only learn
the prior parameters in a discriminative manner, while the
inference parameters are stage-invariant.
With the aid of unrolled half quadratic splitting (HQS)
techniques, Schmidt et al. , proposed a cascade of
shrinkage ﬁelds (CSF) framework to learn stage-wise inference
parameters. Chen et al. further proposed a trainable
nonlinear reaction diffusion (TNRD) model through discriminative learning of a compact gradient descent inference step.
Recently, Lefkimmiatis and Qiao et al. adopted a
proximal gradient-based denoising inference from a variational
model to incorporate the nonlocal self-similarity prior. It is
worth noting that, apart from MAP inference, Vemulapalli et
al. derived an end-to-end trainable patch-based denoising network based on Gaussian Conditional Random Field
(GCRF) inference.
MAP inference guided discriminative learning usually requires much fewer inference steps, and is very efﬁcient in
image denoising. It also has clear interpretability because
the discriminative architecture is derived from optimization
algorithms such as HQS and gradient descent , , ,
 , . However, the learned priors and inference procedure
are limited by the form of MAP model , and generally
perform inferior to the state-of-the-art CNN-based denoisers.
For example, the inference of CSF is not very ﬂexible
since it is strictly derived from the HQS optimization under
the ﬁeld of experts (FoE) framework. The capacity of FoE is
however not large enough to fully characterize image priors,
which in turn makes CSF less effective. For these reasons,
Kruse et al. generalized CSF for better performance by
replacing some modular parts of unrolled inference with more
powerful CNN.
B. Plain Discriminative Learning
Instead of modeling image priors explicitly, the plain discriminative learning methods learn a direct mapping function
to model image prior implicitly. The multi-layer perceptron
Fig. 1. The architecture of the proposed FFDNet for image denoising. The input image is reshaped to four sub-images, which are then input to the CNN
together with a noise level map. The ﬁnal output is reconstructed by the four denoised sub-images.
(MLP) and CNNs have been adopted to learn such priors.
The use of CNN for image denoising can be traced back
to , where a ﬁve-layer network with sigmoid nonlinearity
was proposed. Subsequently, auto-encoder based methods have
been suggested for image denoising , . However,
early MLP and CNN-based methods are limited in denoising
performance and cannot compete with the benchmark BM3D
method .
The ﬁrst discriminative denoising method which achieves
comparable performance with BM3D is the plain MLP method
proposed by Burger et al. . Beneﬁtted from the advances in
deep CNN, Zhang et al. proposed a plain denoising CNN
(DnCNN) method which achieves state-of-the-art denoising
performance. They showed that residual learning and batch
normalization are particularly useful for the success of
denoising. For a better trade-off between accuracy and speed,
Zhang et al. introduced a 7-layer denoising network with
dilated convolution to expand the receptive ﬁeld of CNN.
Mao et al. proposed a very deep fully convolutional
encoding-decoding network with symmetric skip connection
for image denoising. Santhanam et al. developed a recursively branched deconvolutional network (RBDN) for image
denoising as well as generic image-to-image regression. Tai
et al. proposed a very deep persistent memory network
(MemNet) by introducing a memory block to mine persistent
memory through an adaptive learning process.
Plain discriminative learning has shown better performance
than MAP inference guided discriminative learning; however,
existing discriminative learning methods have to learn multiple
models for handling images with different noise levels, and are
incapable to deal with spatially variant noise. To the best of
our knowledge, it remains an unaddressed issue to develop a
single discriminative denoising model which can handle noise
of different levels, even spatially variant noise, in a speed even
faster than BM3D.
III. PROPOSED FAST AND FLEXIBLE DISCRIMINATIVE
CNN DENOISER
We present a single discriminative CNN model, namely
FFDNet, to achieve the following three objectives:
• Fast speed: The denoiser is expected to be highly efﬁcient
without sacriﬁcing denoising performance.
• Flexibility: The denoiser is able to handle images with
different noise levels and even spatially variant noise.
• Robustness: The denoiser should introduce no visual artifacts in controlling the trade-off between noise reduction
and detail preservation.
In this work, we take a tunable noise level map M as input to
make the denoising model ﬂexible to noise levels. To improve
the efﬁciency of the denoiser, a reversible downsampling operator is introduced to reshape the input image of size W ×H×C
into four downsampled sub-images of size W
2 ×4C. Here
C is the number of channels, i.e., C = 1 for grayscale image
and C = 3 for color image. In order to enable the noise level
map to robustly control the trade-off between noise reduction
and detail preservation by introducing no visual artifacts, we
adopt the orthogonal initialization method to the convolution
A. Network Architecture
Fig. 1 illustrates the architecture of FFDNet. The ﬁrst layer
is a reversible downsampling operator which reshapes a noisy
image y into four downsampled sub-images. We further concatenate a tunable noise level map M with the downsampled
sub-images to form a tensor ˜y of size W
2 × (4C + 1) as
the inputs to CNN. For spatially invariant AWGN with noise
level σ, M is a uniform map with all elements being σ.
With the tensor ˜y as input, the following CNN consists
of a series of 3 × 3 convolution layers. Each layer is
composed of three types of operations: Convolution (Conv),
Rectiﬁed Linear Units (ReLU) , and Batch Normalization
(BN) . More speciﬁcally, “Conv+ReLU” is adopted for
the ﬁrst convolution layer, “Conv+BN+ReLU” for the middle
layers, and “Conv” for the last convolution layer. Zero-padding
is employed to keep the size of feature maps unchanged
after each convolution. After the last convolution layer, an
upscaling operation is applied as the reverse operator of the
downsampling operator applied in the input stage to produce
the estimated clean image ˆx of size W × H × C. Different
from DnCNN, FFDNet does not predict the noise. The reason
is given in Sec. III-F. Since FFDNet operates on downsampled
sub-images, it is not necessary to employ the dilated convolution to further increase the receptive ﬁeld.
By considering the balance of complexity and performance,
we empirically set the number of convolution layers as 15 for
grayscale image and 12 for color image. As to the channels
of feature maps, we set 64 for grayscale image and 96 for
color image. The reason that we use different settings for
grayscale and color images is twofold. First, since there are
high dependencies among the R, G, B channels, using a
smaller number of convolution layers encourages the model
to exploit the inter-channel dependency. Second, color image
has more channels as input, and hence more feature (i.e.,
more channels of feature map) is required. According to
our experimental results, increasing the number of feature
maps contributes more to the denoising performance on color
images. Using different settings for color images, FFDNet can
bring an average gain of 0.15dB by PSNR on different noise
levels. As we shall see from Sec. IV-F, 12-layer FFDNet
for color image runs slightly slower than 15-layer FFDNet
for grayscale image. Taking both denoising performance and
efﬁciency into account, we set the number of convolution
layers as 12 and the number of feature maps as 96 for color
image denoising.
B. Noise Level Map
Let’s ﬁrst revisit the model-based image denoising methods
to analyze why they are ﬂexible in handling noises at different
levels, which will in turn help us to improve the ﬂexibility
of CNN-based denoiser. Most of the model-based denoising
methods aim to solve the following problem
ˆx = arg min x
2σ2 ∥y −x∥2 + λΦ(x),
2σ2 ∥y −x∥2 is the data ﬁdelity term with noise level
σ, Φ(x) is the regularization term associated with image
prior, and λ controls the balance between the data ﬁdelity
and regularization terms. It is worth noting that in practice λ
governs the compromise between noise reduction and detail
preservation. When it is too small, much noise will remain;
on the opposite, details will be smoothed out along with
suppressing noise.
With some optimization algorithms, the solution of Eqn. (1)
actually deﬁnes an implicit function given by
ˆx = F(y, σ, λ; Θ).
Since λ can be absorbed into σ, Eqn. (2) can be rewritten as
ˆx = F(y, σ; Θ).
In this sense, setting noise level σ also plays the role of setting
λ to control the trade-off between noise reduction and detail
preservation. In a word, model-based methods are ﬂexible in
handling images with various noise levels by simply specifying
σ in Eqn. (3).
According to the above discussion, it is natural to utilize
CNN to learn an explicit mapping of Eqn. (3) which takes the
noise image and noise level as input. However, since the inputs
y and σ have different dimensions, it is not easy to directly
feed them into CNN. Inspired by the patch based denoising
methods which actually set σ for each patch, we resolve the
dimensionality mismatching problem by stretching the noise
level σ into a noise level map M. In M, all the elements are
σ. As a result, Eqn. (3) can be further rewritten as
ˆx = F(y, M; Θ).
It is worth emphasizing that M can be extended to degradation
maps with multiple channels for more general noise models
such as the multivariate (3D) Gaussian noise model N(0, Σ)
with zero mean and covariance matrix Σ in the RGB color
space . As such, a single CNN model is expected to
inherit the ﬂexibility of handling noise model with different
parameters, even spatially variant noises by noting M can be
non-uniform.
C. Denoising on Sub-images
Efﬁciency is another crucial issue for practical CNN-based
denoising. One straightforward idea is to reduce the depth
and number of ﬁlters. However, such a strategy will sacriﬁce
much the modeling capacity and receptive ﬁeld of CNN .
In , dilated convolution is introduced to expand receptive
ﬁeld without the increase of network depth, resulting in a 7layer denoising CNN. Unfortunately, we empirically ﬁnd that
FFDNet with dilated convolution tends to generate artifacts
around sharp edges.
Shi et al. proposed to extract deep features directly from
the low-resolution image for super-resolution, and introduced
a sub-pixel convolution layer to improve computational efﬁciency. In the application of image denoising, we introduce a
reversible downsampling layer to reshape the input image into
a set of small sub-images. Here the downsampling factor is set
to 2 since it can largely improve the speed without reducing
modeling capacity. The CNN is deployed on the sub-images,
and ﬁnally a sub-pixel convolution layer is adopted to reverse
the downsampling process.
Denoising on downsampled sub-images can also effectively
expand the receptive ﬁeld which in turn leads to a moderate
network depth. For example, the proposed network with a
depth of 15 and 3 × 3 convolution will have a large receptive
ﬁeld of 62 × 62. In contrast, a plain 15-layer CNN only has
a receptive ﬁeld size of 31×31. We note that the receptive
ﬁeld of most state-of-the-art denoising methods ranges from
35×35 to 61×61 . Further increase of receptive ﬁeld actually beneﬁts little in improving denoising performance .
What is more, the introduction of subsampling and sub-pixel
convolution is effective in reducing the memory burden.
Experiments are conducted to validate the effectiveness of
downsampling for balancing denoising accuracy and efﬁciency
on the BSD68 dataset with σ = 15 and 50. For grayscale
image denoising, we train a baseline CNN which has the same
depth as FFDNet without downsampling. The comparison of
average PSNR values is given as follows: (i) when σ is small
(i.e., 15), the baseline CNN slightly outperforms FFDNet by
0.02dB; (ii) when σ is large (i.e., 50), FFDNet performs better
than the baseline CNN by 0.09dB. However, FFDNet is nearly
3 times faster and is more memory-friendly than the baseline
CNN. As a result, by performing denoising on sub-images,
FFDNet signiﬁcantly improves efﬁciency while maintaining
denoising performance.
D. Examining the Role of Noise Level Map
By training the model with abundant data units (y, M; x),
where M is exactly the noise level map of y, the model is
expected to perform well when the noise level matches the
ground-truth one (see Fig. 2(a)). On the other hand, in practice,
An example to show the importance of guaranteeing the role of
noise level map in controlling the trade-off between noise reduction and detail
preservation. The input is a noisy image with noise level 25. (a) Result without
visual artifacts by matched noise level 25. (b) Result without visual artifacts
by mismatched noise level 60. (c) Result with visual artifacts by mismatched
noise level 60.
we may need to use the learned model to smooth out some
details with a higher noise level map than the ground-truth
one (see Fig. 2(b)). In other words, one may take advantage
of the role of λ to control the trade-off between noise reduction
and detail preservation. Hence, it is very necessary to further
examine whether M can play the role of λ.
Unfortunately, the use of both M and y as input also
increases the difﬁculty to train the model. According to our
experiments on several learned models, the model may give
rise to visual artifacts especially when the input noise level
is much higher than the ground-truth one (see Fig. 2(c)),
which indicates M fails to control the trade-off between noise
reduction and detail preservation. Note that it does not mean
all the models suffer from such problem. One possible solution
to avoid this is to regularize the convolution ﬁlters. As a
widely-used regularization method, orthogonal regularization
has proven to be effective in eliminating the correlation between convolution ﬁlters, facilitating gradient propagation and
improving the compactness of the learned model. In addition,
recent studies have demonstrated the advantage of orthogonal
regularization in enhancing the network generalization ability
in applications of deep hashing and image classiﬁcation ,
 , , , . According to our experiments, we
empirically ﬁnd that the orthogonal initialization of the convolution ﬁlters , works well in suppressing the above
mentioned visual artifacts.
It is worth emphasising that this section aims to highlight
the necessity of guaranteeing the role of M in controlling
the trade-off between noise reduction and detail preservation
rather than proposing a method to avoid the possible visual
artifacts caused by noise level mismatch. In practice, one may
retrain the model until M plays its role and results in no visual
artifacts with a lager noise level.
E. FFDNet vs. a Single Blind Model
So far, we have known that it is possible to learn a
single model for blind and non-blind Gaussian denoising,
respectively. And it is of signiﬁcant importance to clarify their
differences.
First, the generalization ability is different. Although the
blind model performs favorably for synthetic AWGN removal
without knowing the noise level, it does not generalize well to
real noisy images whose noises are much more complex than
AWGN (see the results of DnCNN-B in Fig. 8). Actually, since
the CNN model can be treated as the inference of Eqn. (1)
and the data ﬁdelity term corresponds to the degradation
process (or the noise model), the modeling accuracy of the
degradation process is very important for the success of a
denoising model. For example, a model trained for AWGN
removal is not expected to be still effective for Poisson noise
removal. By contrast, the non-blind FFDNet model can be
viewed as multiple denoisers, each of which is anchored with
a noise level. Accordingly, it has the ability to control the
trade-off between noise removal and detail preservation which
in turn facilitates the removal of real noise to some extent (see
the results of DnCNN and FFDNet in Fig. 8).
Second, the performance for AWGN removal is different.
The non-blind model with noise level map has moderately
better performance for AWGN removal than the blind one
(about 0.1dB gain on average for the BSD68 dataset), possibly
because the noise level map provides additional information
to the input. Similar phenomenon has also been recognized in
the task of single image super-resolution (SISR) .
Third, the application range is different. In the variable
splitting algorithms for general image restoration tasks, the
prior term involves a denoising subproblem with a current
noise level , , . Thus, the non-blind model can be
easily plugged into variable splitting algorithms to solve various image restoration tasks, such as image deblurring, SISR,
and image inpainting , . However, the blind model does
not have this merit.
F. Residual vs. Non-residual Learning of Plain CNN
It has been pointed out that the integration of residual
learning for plain CNN and batch normalization is beneﬁcial
to the removal of AWGN as it eases the training and tends
to deliver better performance . The main reason is that
the residual (noise) output follows a Gaussian distribution
which facilitates the Gaussian normalization step of batch
normalization. The denoising network gains most from such
a task-speciﬁc merit especially when a single noise level is
considered.
In FFDNet, we instead consider a wide range of noise
level and introduce a noise level map as input. Thus, it
is interesting to revisit the integration of residual learning
and batch normalization for plain CNN. According to our
experiments, batch normalization can always accelerate the
training of denoising network regardless of the residual or
non-residual learning strategy of plain CNN. In particular,
with batch normalization, while the residual learning enjoys
a faster convergence than non-residual learning, their ﬁnal
performances after ﬁne-tuning are almost exactly the same.
Some recent works have proposed to train very deep plain
networks with nearly the same performance to that with residual learning , . In fact, when a network is moderately
deep (e.g., less than 20), it is feasible to train a plain network
without the residual learning strategy by using advanced CNN
training and design techniques such as ReLU , batch
normalization and Adam . For simplicity, we do not
use residual learning for network design.
G. Un-clipping vs. Clipping of Noisy Images for Training
In the AWGN denoising literature, there exist two widelyused settings, i.e., un-clipping , , , and clipping , , of synthetic noisy image to evaluate the performance of denoising methods. The main difference between the
two settings lies in whether the noisy image is clipped into the
range of 0-255 (or more precisely, quantized into 8-bit format)
after adding the noise.
On the one hand, the un-clipping setting which is also the
most widely-used setting serves an ideal test bed for evaluating the denoising methods. This is because most denoising
methods assume the noise is ideal AWGN, and the clipping
of noisy input would make the noise characteristics deviate
from being AWGN. Furthermore, in the variable splitting
algorithms for solving general image restoration problems,
there exists a subproblem which, from a Bayesian perspective,
corresponds to a Gaussian denoising problem , . This
further broadens the use of the un-clipping setting. Thus,
unless otherwise speciﬁed, FFDNet in this work refers to the
model trained on images without clipping or quantization.
On the other hand, since real noisy images are always
integer-valued and range-limited, it has been argued that the
clipping setting of noisy image makes the data more realistic . However, when the noise level is high, the noise will
be not zero-mean any more due to clipping effects . This
in turn will lead to unreliable denoiser for plugging into the
variable splitting algorithms to solve other image restoration
To thoroughly evaluate the proposed method, we also train
an FFDNet model with clipping setting of noisy image, namely
FFDNet-Clip, for comparison. During training and testing
of FFDNet-Clip, the noisy images are quantized into 8-bit
format. Speciﬁcally, for a clean image x, we use the matlab
function imnoise(x, ’gaussian’, 0, ( σ
255)2) to generate
the quantized noisy y with noise level σ.
IV. EXPERIMENTS
A. Dataset Generation and Network Training
To train the FFDNet model, we need to prepare a training
dataset of input-output pairs {(yi, Mi; xi)}N
i=1. Here, yi is
obtained by adding AWGN to latent image xi, and Mi is the
noise level map. The reason to use AWGN to generate the
training dataset is two-fold. First, AWGN is a natural choice
when there is no speciﬁc prior information on noise source.
Second, real-world noise can be approximated as locally
AWGN . More speciﬁcally, FFDNet model is trained on
the noisy images yi = xi + vi without quantization to 8-bit
integer values. Though the real noisy images are generally 8bit quantized, we empirically found that the learned model still
works effectively on real noisy images. For FFDNet-Clip, as
MAIN SPECIFICATIONS OF THE PROPOSED FFDNET
Noise level
patch size
mentioned in Sec. III-G, we use the matlab function imnoise
to generate the quantized noisy image from a clean one.
We collected a large dataset of source images, including
400 BSD images, 400 images selected from the validation set
of ImageNet , and the 4,744 images from the Waterloo
Exploration Database . In each epoch, we randomly crop
N = 128×8, 000 patches from these images for training. The
patch size should be larger than the receptive ﬁeld of FFDNet,
and we set it to 70×70 and 50×50 for grayscale images and
color images, respectively. The noisy patches are obtained by
adding AWGN of noise level σ ∈ to the clean patches.
For each noisy patch, the noise level map is uniform. Since
FFDNet is a fully convolutional neural network, it inherits the
local connectivity property that the output pixel is determined
by the local noisy input and local noise level. Hence, the
trained FFDNet naturally has the ability to handle spatially
variant noise by specifying a non-uniform noise level map.
For clarity, in Table I we list the main speciﬁcations of the
FFDNet models.
The ADAM algorithm is adopted to optimize FFDNet
by minimizing the following loss function,
i=1 ∥F(yi, Mi; Θ) −xi∥2.
The learning rate starts from 10−3 and reduces to 10−4
when the training error stops decreasing. When the training
error keeps unchanged in ﬁve sequential epochs, we merge
the parameters of each batch normalization into the adjacent
convolution ﬁlters. Then, a smaller learning rate of 10−6 is
adopted for additional 50 epochs to ﬁne-tune the FFDNet
model. As for the other hyper-parameters of ADAM, we use
their default settings. The mini-batch size is set as 128, and
the rotation and ﬂip based data augmentation is also adopted
during training. The FFDNet models are trained in Matlab
(R2015b) environment with MatConvNet package and an
Nvidia Titan X Pascal GPU. The training of a single model
can be done in about two days.
To evaluate the proposed FFDNet denoisers on grayscale
image denoising, we use BSD68 and Set12 datasets to
test FFDNet for removing AWGN noise, and use the “RNI6”
dataset to test FFDNet for removing real noise. The
BSD68 dataset consists of 68 images from the separate test set
of the BSD300 dataset . The Set12 dataset is a collection
of widely-used testing images. The RNI6 dataset contains
6 real noisy images without ground-truth. In particular, to
evaluate FFDNet-Clip, we use the quantized “Clip300” dataset
which comprises the 100 images of test set from the BSD300
dataset and 200 images from PASCALVOC 2012 
dataset. Note that all the testing images are not included in
the training dataset.
As for color image denoising, we employ four datasets,
(a) BM3D (26.21dB)
(b) WNNM (26.51dB)
(c) MLP (26.54dB)
(d) TNRD (26.59dB)
(e) DnCNN (26.89dB)
(f) FFDNet (26.93dB)
Fig. 3. Denoising results on image “102061” from the BSD68 dataset with noise level 50 by different methods.
“RNI15” , . The CBSD68 dataset is the corresponding
color version of the grayscale BSD68 dataset. The Kodak24
dataset consists of 24 center-cropped images of size 500×500
from the original Kodak dataset. The McMaster dataset is a
widely-used dataset for color demosaicing, which contains 18
cropped images of size 500×500. Compared to the Kodak24
images, the images in McMaster dataset exhibit more saturated
colors . The RNI15 dataset consists of 15 real noisy
images. We note that RNI6 and RNI15 cover a variety of
real noise types, such as camera noise and JPEG compression
noise. Since the ground-truth clean images are unavailable
for real noisy images, we thus only provide the visual comparisons on these images. The source codes of FFDNet and
its extension to multivariate Gaussian noise are available at
 
B. Experiments on AWGN Removal
In this subsection, we test FFDNet on noisy images corrupted by spatially invariant AWGN. For grayscale image
denoising, we mainly compare FFDNet with state-of-the-art
methods BM3D , WNNM , MLP , TNRD , and
DnCNN . Note that BM3D and WNNM are two representative model-based methods based on nonlocal self-similarity
prior, whereas TNRD, MLP and DnCNN are discriminative
learning based methods. Tables II and III report the PSNR
results on BSD68 and Set12 datasets, respectively. We also
use two CNN-based denoising methods, i.e., RED30 and
MemNet , for further comparison. Their PSNR results on
BSD68 dataset with noise level 50 are 26.34dB and 26.35dB,
respectively. Note that RED30 and MemNet are trained on a
speciﬁc noise level and are less efﬁcient than DnCNN. From
Tables II and III, one can have the following observations.
First, FFDNet surpasses BM3D by a large margin and
outperforms WNNM, MLP and TNRD by about 0.2dB for
a wide range of noise levels on BSD68. Second, FFDNet
is slightly inferior to DnCNN when the noise level is low
(e.g., σ ≤25), but gradually outperforms DnCNN with the
increase of noise level (e.g., σ > 25). This phenomenon
may be resulted from the trade-off between receptive ﬁeld
size and modeling capacity. FFDNet has a larger receptive
ﬁeld than DnCNN, thus favoring for removing strong noise,
(a) CBM3D (25.49dB)
(b) CDnCNN (26.19dB)
(c) FFDNet (26.28dB)
Color image denoising results by CBM3D, CDnCNN and FFDNet
on noise level σ = 50.
while DnCNN has better modeling capacity which is beneﬁcial
for denoising images with lower noise level. Third, FFDNet
outperforms WNNM on images such as “House”, while it
is inferior to WNNM on image “Barbara”. This is because
“Barbara” has a rich amount of repetitive structures, which
can be effectively exploited by nonlocal self-similarity based
WNNM method. The visual comparisons of different methods
are given in Fig. 3. Overall, FFDNet produces the best
perceptual quality of denoised images.
To evaluate FFDNet-Clip, Table IV shows the PSNR comparison with DCGRF and RBDN on the Clip300
dataset. It can be seen that FFDNet-Clip with matched noise
level achieves better performance than DCGRF and RBDN,
showing that FFDNet performs well under the clipping setting.
We also tested FFDNet-Clip on BSD68 dataset with clipping
setting, it has been found that the PSNR result is similar to
that of FFDNet with un-clipping setting.
For color image denoising, we compare FFDNet with
CBM3D and CDnCNN . Table V reports the performance of different methods on CBSD68, Kodak24, and
McMaster datasets, and Fig. 4 presents the visual comparisons.
It can be seen that FFDNet consistently outperforms CBM3D
on different noise levels in terms of both quantitative and
qualitative evaluation, and has competing performance with
THE PSNR(DB) RESULTS OF DIFFERENT METHODS ON SET12 DATASET WITH NOISE LEVELS 15, 25 35, 50 AND 75. THE BEST TWO RESULTS ARE
HIGHLIGHTED IN RED AND BLUE COLORS, RESPECTIVELY
Noise Level
Noise Level
Noise Level
Noise Level
Noise Level
C. Experiments on Spatially Variant AWGN Removal
We then test the ﬂexibility of FFDNet to deal with spatially
variant AWGN. To synthesize spatially variant AWGN, we ﬁrst
generate an AWGN image v1 with unit standard deviation and
a noise level map M of the same size. Then, element-wise
multiplication is applied on v1 and M to produce the spatially
variant AWGN, i.e., v = v1 ⊙M. In the denoising stage, we
take the bilinearly downsampled noise level map as the input
THE AVERAGE PSNR(DB) RESULTS OF DIFFERENT METHODS ON BSD68
WITH NOISE LEVELS 15, 25 35, 50 AND 75
THE AVERAGE PSNR(DB) RESULTS OF DIFFERENT METHODS ON CLIP300
WITH NOISE LEVELS 15, 25 35, 50 AND 60
FFDNet-Clip
to FFDNet. Since the noise level map is spatially smooth, the
use of downsampled noise level map generally has very little
effect on the ﬁnal denoising performance.
Fig. 5 gives an example to show the effectiveness of
FFDNet on removing spatially variant AWGN. We do not
compare FFDNet with other methods because no state-of-theart AWGN denoising method can be readily extended to handle
spatially variant AWGN. From Fig. 5, one can see that FFDNet
with non-uniform noise level map is ﬂexible and powerful
to remove spatially variant AWGN. In contrast, FFDNet with
uniform noise level map would fail to remove strong noise
at the region with higher noise level while smoothing out the
THE AVERAGE PSNR(DB) RESULTS OF CBM3D, CDNCNN AND
FFDNET ON CBSD68, KODAK24 AND MCMASTER DATASETS WITH
NOISE LEVELS 15, 25 35, 50 AND 75
details at the region with lower noise level.
Noise Level
Noise Level
Fig. 5. Examples of FFDNet on removing spatially variant AWGN. (a) Noisy
image (20.55dB) with spatially variant AWGN. (b) Ground-truth noise level
map and corresponding denoised image (30.08dB) by FFDNet; (c) Uniform
noise level map constructed by using the mean value of ground-truth noise
level map and corresponding denoised image (27.45dB) by FFDNet.
D. Experiments on Noise Level Sensitivity
In practical applications, the noise level map may not be
accurately estimated from the noisy observation, and mismatch
between the input and real noise levels is inevitable. If the
input noise level is lower than the real noise level, the noise
cannot be completely removed. Therefore, users often prefer
to set a higher noise level to remove more noise. However,
this may also remove some image details together with noise.
A practical denoiser should tolerate certain mismatch of noise
levels. In this subsection, we evaluate FFDNet in comparison
with benchmark BM3D and DnCNN by varying different input
noise levels for a given ground-truth noise level.
Fig. 6 illustrates the noise level sensitivity curves of BM3D,
DnCNN and FFDNet. Different methods with different input
noise levels (e.g., “FFDNet-15” represents FFDNet with input
noise level ﬁxed as 15) are evaluated on BSD68 images with
noise level ranging from 0 to 50. Fig. 7 shows the visual
comparisons between BM3D/CBM3D and FFDNet by setting
Image Noise Level
Fig. 6. Noise level sensitivity curves of BM3D, DnCNN and FFDNet. The
averaged PSNR results are evaluated on BSD68.
different input noise levels to denoise a noisy image. Four
typical image structures, including ﬂat region, sharp edge, line
with high contrast, and line with low contrast, are selected
for visual comparison to investigate the noise level sensitivity
of BM3D and FFDNet. From Figs. 6 and 7, we have the
following observations.
• On all noise levels, FFDNet achieves similar denoising
results to BM3D and DnCNN when their input noise
levels are the same.
• With the ﬁxed input noise level, for all the three methods,
the PSNR value tends to stay the same when the groundtruth noise level is lower, and begins to decrease when
the ground-truth noise level is higher.
• The best visual quality is obtained when the input noise
level matches the ground-truth one. BM3D and FFDNet
produce similar visual results with lower input noise levels, while they exhibit certain difference with higher input
noise levels. Both of them will smooth out noise in ﬂat
regions, and gradually smooth out image structures with
the increase of input noise levels. Particularly, FFDNet
may wipe out some low contrast line structure, whereas
BM3D can still preserve the mean patch regardless of the
input noise levels due to its use of nonlocal information.
• Using a higher input noise level can generally produce
better visual results than using a lower one. In addition,
there is no much visual difference when the input noise
level is a little higher than the ground-truth one.
According to above observations, FFDNet exhibits similar
noise level sensitivity performance to BM3D and DnCNN in
balancing noise reduction and detail preservation. When the
ground-truth noise level is unknown, it is more preferable to
set a larger input noise level than a lower one to remove noise
with better perceptual quality.
E. Experiments on Real Noisy Images
In this subsection, real noisy images are used to further assess the practicability of FFDNet. However, such an evaluation
is difﬁcult to conduct due to the following reasons. (i) Both the
ground-truth clean image and noise level are unknown for real
noisy image. (ii) The real noise comes from various sources
such as camera imaging pipeline (e.g., shot noise, ampliﬁer
noise and quantization noise), scanning, lossy compression
and image resizing , , and it is generally non-Gaussian,
spatially variant, and signal-dependent. As a result, the AWGN
assumption in many denoising algorithms does not hold, and
the associated noise level estimation methods do not work well
for real noisy images.
Instead of adopting any noise level estimation methods, we
adopt an interactive strategy to handle real noisy images. First
of all, we empirically found that the assumption of spatially
invariant noise usually works well for most real noisy images.
We then employ a set of typical input noise levels to produce
multiple outputs, and select the one which has best trade-off
between noise reduction and detail preservation. Second, the
spatially variant noise in most real-world images is signaldependent. In this case, we ﬁrst sample several typical regions
of distinct colors. For each typical region, we apply different
Fig. 7. Visual comparisons between FFDNet and BM3D/CBM3D by setting different input noise levels to denoise a noisy image. (a) From top to bottom:
ground-truth image, four clean zoom-in regions, and the corresponding noisy regions (AWGN, noise level 15). (b) From top to bottom: denoising results
by BM3D with input noise levels 5, 10, 15, 20, 50, and 75, respectively. (c) Results by FFDNet with the same settings as in (b). (d) From top to bottom:
ground-truth image, four clean zoom-in regions, and the corresponding noisy regions (AWGN, noise level 25). (e) From top to bottom: denoising results by
CBM3D with input noise levels 10, 20, 25, 30, 45 and 60, respectively. (f) Results by FFDNet with the same settings as in (e).
noise levels with an interval of 5, and choose the best noise
level by observing the denoising results. The noise levels at
other regions are then interpolated from the noise levels of
the typical regions to constitute an approximated non-uniform
noise level map. Our FFDNet focuses on non-blind denoising
and assumes the noise level map is known. In practice, some
advanced noise level estimation methods , can be
adopted to assist the estimation of noise level map. In our
following experiments, unless otherwise speciﬁed, we assume
spatially invariant noise for the real noisy images.
Since there is no ground-truth image for a real noisy image,
visual comparison is employed to evaluate the performance
of FFDNet. We choose BM3D for comparison because it is
widely accepted as a benchmark for denoising applications.
Given a noisy image, the same input noise level is used for
BM3D and FFDNet. Another CNN-based denoising method
DnCNN and a blind denoising method Noise Clinic are
also used for comparison. Note that, apart from the non-blind
DnCNN models for speciﬁc noise levels, the blind DnCNN
model (i.e., DnCNN-B) trained on noise level range of 
is also used for grayscale image denoising. For color image
denoising, the blind CDnCNN-B is used for comparison.
Fig. 8 compares the grayscale image denoising results of
Noise Clinic, BM3D, DnCNN, DnCNN-B and FFDNet on
RNI6 images. As one can see, Noise Clinic reduces much
the noise, but it also generates many algorithm-induced artifacts. BM3D, DnCNN and FFDNet produce more visually
pleasant results. While the non-blind DnCNN models perform
favorably, the blind DnCNN-B model performs poorly in
removing the non-AWGN real noise. This phenomenon clearly
demonstrates the better generalization ability of non-blind
model over blind one for controlling the trade-off between
noise removal and detail preservation. It is worth noting that,
for image “Building” which contains structured noise, Noise
Clinic and BM3D fail to remove those structured noises
since the structured noises ﬁt the nonlocal self-similarity prior
adopted in Noise Clinic and BM3D. In contrast, FFDNet
and DnCNN successfully remove such noise without losing
underlying image textures.
Fig. 9 shows the denoising results of Noise Clinic, CBM3D,
CDnCNN-B and FFDNet on ﬁve color noisy images from
RNI15. It can be seen that CDnCNN-B yields very pleasing
results for noisy image with AWGN-like noise such as image “Frog”, and is still unable to handle non-AWGN noise.
Notably, from the denoising results of “Boy”, one can see
that CBM3D remains the structured color noise unremoved
whereas FFDNet removes successfully such kind of noise. We
can conclude that while the nonlocal self-similarity prior helps
to remove random noise, it hinders the removal of structured
noise. In comparison, the prior implicitly learned by CNN is
able to remove both random noise and structured noise.
Fig. 10 further shows more visual results of FFDNet on the
other nine images from RNI15. It can be seen that FFDNet
can handle various kinds of noises, such as JPEG lossy
compression noise (see image “Audrey Hepburn”), and video
noise (see image “Movie”).
Fig. 11 shows a more challenging example to demonstrate
the advantage of FFDNet for denoising noisy images with
spatially variant noise. We select ﬁve typical regions to estimate the noise levels, including two background regions, the
coffee region, the milk-foam region, and the specular reﬂection
region. In our experiment, we manually and interactively set
σ = 10 for the milk-foam and specular reﬂection regions, σ
= 35 for the background region with high noise (i.e., green
region), and σ = 25 for the other regions. We then interpolate
the non-uniform noise level map for the whole image based on
the estimated ﬁve noise levels. As one can see, while FFDNet
with a small uniform input noise level can recover the details
of regions with low noise level, it fails to remove strong noise.
On the other hand, FFDNet with a large uniform input noise
level can remove strong noise but it will also smooth out the
details in the region with low noise level. In contrast, the
denoising result with a proper non-uniform noise level map
not only preserves image details but also removes the strong
Finally, according to the above experiments on real noisy
images, we can see that the FFDNet model trained with unquantized image data performs well on 8-bit quantized real
noisy images.
(a) David Hilbert
(b) Old Tom Morris
(c) Chupa Chups
(d) Vinegar
(e) Building
(f) Marilyn
Fig. 8. Grayscale image denoising results by different methods on real noisy images. From top to bottom: noisy images, denoised images by Noise Clinic,
denoised images by BM3D, denoised images by DnCNN, denoised images by DnCNN-B, denoised images by FFDNet. (a) σ = 14 (15 for DnCNN); (b) σ
= 15; (c) σ = 10; (d) σ = 20; (e) σ = 20; (f) σ = 7 (10 for DnCNN).
(c) Pattern1
(d) Pattern2
Color image denoising results by different methods on real noisy images. From top to bottom: noisy images, denoised images by Noise Clinic,
denoised images by CBM3D, denoised images by CDnCNN-B, denoised images by FFDNet. (a) σ = 28; (b) σ = 15; (c) σ = 12; (d) σ = 40; (e) σ = 45.
F. Running Time
Table VI lists the running time results of BM3D, DnCNN
and FFDNet for denoising grayscale and color images with
size 256×256, 512×512 and 1,024×1,024. The evaluation was
performed in Matlab (R2015b) environment on a computer
with a six-core Intel(R) Core(TM) i7-5820K CPU @ 3.3GHz,
32 GB of RAM and an Nvidia Titan X Pascal GPU. For
BM3D, we evaluate its running time by denoising images
with noise level 25. For DnCNN, the grayscale and color
image denoising models have 17 and 20 convolution layers,
respectively. The Nvidia cuDNN-v5.1 deep learning library is
used to accelerate the computation of DnCNN and FFDNet.
The memory transfer time between CPU and GPU is also
counted. Note that DnCNN and FFDNet can be implemented
with both single-threaded (ST) and multi-threaded (MT) CPU
computations.
From Table VI, we have the following observations. First,
BM3D spends much more time on denoising color images than
grayscale images. The reason is that, compared to gray-BM3D,
CBM3D needs extra time to denoise the chrominance components after luminance-chrominance color transformation.
Second, while DnCNN can beneﬁt from GPU computation for
RUNNING TIME (IN SECONDS) OF DIFFERENT METHODS FOR DENOISING
IMAGES WITH SIZE 256×256, 512×512 AND 1,024×1,024
1,024×1,024
fast implementation, it has comparable CPU time to BM3D.
Third, FFDNet spends almost the same time for processing
grayscale and color images. More speciﬁcally, FFDNet with
multi-threaded implementation is about three times faster than
DnCNN and BM3D on CPU, and much faster than DnCNN
on GPU. Even with single-threaded implementation, FFDNet
is also faster than BM3D. Taking denoising performance and
ﬂexibility into consideration, FFDNet is very competitive for
practical applications.
V. CONCLUSION
In this paper, we proposed a new CNN model, namely FFD-
Net, for fast, effective and ﬂexible discriminative denoising. To
achieve this goal, several techniques were utilized in network
design and training, such as the use of noise level map as
input and denoising in downsampled sub-images space. The
results on synthetic images with AWGN demonstrated that
FFDNet can not only produce state-of-the-art results when
input noise level matches ground-truth noise level, but also
have the ability to robustly control the trade-off between
noise reduction and detail preservation. The results on images with spatially variant AWGN validated the ﬂexibility
of FFDNet for handing inhomogeneous noise. The results
on real noisy images further demonstrated that FFDNet can
deliver perceptually appealing denoising results. Finally, the
running time comparisons showed the faster speed of FFDNet
over other competing methods such as BM3D. Considering
its ﬂexibility, efﬁciency and effectiveness, FFDNet provides a
practical solution to CNN denoising applications.