Propositional Abduction with
Implicit Hitting Sets
Alexey Ignatiev, Antonio Morgado, and Joao Marques-Silva
LaSIGE, Faculty of Science, University of Lisbon, Portugal, email:
{aignatiev,ajmorgado,jpms}@ciencias.ulisboa.pt
Abstract. Logic-based abduction ﬁnds important applications in artiﬁcial intelligence and related areas. One application example is in ﬁnding
explanations for observed phenomena. Propositional abduction is a restriction of abduction to the propositional domain, and complexity-wise
is in the second level of the polynomial hierarchy. Recent work has shown
that exploiting implicit hitting sets and propositional satisﬁability (SAT)
solvers provides an eﬃcient approach for propositional abduction. This
paper investigates this earlier work and proposes a number of algorithmic improvements. These improvements are shown to yield exponential
reductions in the number of SAT solver calls. More importantly, the experimental results show signiﬁcant performance improvements compared
to the the best approaches for propositional abduction.
Introduction
Logic-based abduction ﬁnds relevant applications in artiﬁcial intelligence and
related areas . Given a background theory and a set of manifestations and a set of hypotheses, abduction seeks to
identify a cost-minimum set of hypotheses which explain the manifestation and
are consistent given the background theory. Propositional abduction is hard for
the second level of the polynomial hierarchy, but ﬁnds a growing number of
applications . Noticeable examples of where propositional abduction algorithms can be applied include abductive inference , logic programming , knowledge bases updates , security protocols veriﬁcation , and constraint optimization , among many others.
Given the complexity class of propositional abduction, it is conceptually simple to solve the problem with a linear (or logarithmic) number of calls to a
2 -oracle, e.g. a oracle for quantiﬁed Boolean formulae (QBF) with one quantiﬁer alternation. Unfortunately, in practice QBF solvers are not as eﬃcient as
SAT solvers, and do not scale as well. As a result, recent work on solving propositional abduction focused on using calls to SAT oracles instead of
QBF oracles, following a trend also observed for solving QBF .
This recent work on solving propositional abduction is motivated by the practical success of implicit hitting set algorithms in a number of diﬀerent settings .
 
The contributions of this paper can be summarized as follows. The paper revisits QBF models for solving propositional abduction and proposes a Quantiﬁed
MaxSAT (QMaxSAT) model for propositional abduction. Moreover, the
paper notes that the MaxHS approach for MaxSAT can be readily applied to
QMaxSAT by replacing the oracle used. The paper then investigates the application of implicit hitting sets to solving propositional abduction and identiﬁes
a number of algorithmic improvements. This leads to a new algorithm, Hyper,
for solving propositional abduction. This new algorithm is shown to signiﬁcantly
outperform the current state of the art, solving a large number of instances that
could not be solved with existing solutions. More importantly, the paper shows
that the algorithmic improvements proposed can save an exponential number of
iterations when compared with the current state of the art .
The paper is organized as follows. Section 2 introduces the deﬁnitions used
throughout the paper, and also overviews related work. Section 3 revisits a QBF
model for abduction, which is then used for developing a number of alternative
approaches for solving propositional abduction. Among these, the paper proposes improvements to recent work , which are shown to yield exponential
reductions on the number of SAT oracle calls. Section 4 analyzes the experimental results, running existing and the proposed algorithms on existing problem
instances . Section 4 also provides experimental evidence that the proposed
algorithms for propositional abduction can save an exponential number of oracle
calls in diﬀerent settings. Section 5 concludes the paper, and identiﬁes possible
research directions.
Preliminaries
This section introduces the notation and deﬁnitions used throughout the paper.
Satisﬁability
Standard propositional logic deﬁnitions apply (e.g. ). CNF formulas are de-
ﬁned over a set of propositional variables. A CNF formula (or theory) T is a
propositional formula represented as a conjunction of clauses, also interpreted
as a set of clauses. A clause is a disjunction of literals, also interpreted as a
set of literals. A literal is a variable or its complement. The set of variables of
a theory T is denoted X ≜var(T). The dependency of T on X can be made
explicit by writing T(X). Where convenient, a formula can be rewritten with
a fresh set of variables, e.g. we can replace X by Y , writing T(Y ). Conﬂictdriven clause learning (CDCL) SAT solvers are summarized in . Throughout
the paper, SAT solvers are viewed as oracles. Given a CNF formula F, a SAT
oracle decides whether F is satisﬁable, and returns a satisfying assignment µ if
F is satisﬁable. A SAT oracle can also return a subset of the clauses (i.e. an
unsatisﬁable core U ⊆F) if F is unsatisﬁable.
CNF formulas are often used to model overconstrained problems. In general,
clauses in a CNF formula are characterized as hard, meaning that these must
be satisﬁed, or soft, meaning that these are to be satisﬁed, if at all possible.
A weight can be associated with each soft clause, and the goal of maximum
satisﬁability (MaxSAT) is to ﬁnd an assignment to the propositional variables
such that the hard clauses are satisﬁed, and the sum of the satisﬁed soft clauses
is maximized. Branch-and-bound algorithms for MaxSAT are overviewed in .
Recent work on MaxSAT investigated core-guided algorithms and also the
use of implicit hitting sets .
In the analysis of unsatisﬁable CNF formulas, a number of deﬁnitions are
used. Given an unsatisﬁable CNF formula F, a minimal unsatisﬁable subset
(MUS) M ⊆F is both unsatisﬁable and irreducible. Given an unsatisﬁable CNF
formula F, a minimal correction subset (MCS) C ⊆F is both irreducible and
its complement is satisﬁable. Given an unsatisﬁable CNF formula F, a maximal
satisﬁable subset (MSS) S is the complement of some MCS of F. A largest MSS
is a solution to the MaxSAT problem.
Additionally, it is well-known that MUSes and MCSes are connected
by a hitting set duality. Given a collection Γ of sets from a universe U, a hitting
set h for Γ is a set such that ∀S ∈Γ, h ∩S ̸= ∅. A hitting set h is minimal if
none of its subset is a hitting set. It is straightforward to extend the previous
deﬁnitions to the case where there are hard clauses.
Quantiﬁed Boolean formulas (QBFs) are an extension of propositional logic
with existential and universal quantiﬁers (∀, ∃) . A QBF can be in prenex
closed form Q1x1. . .Qnxn. ϕ, where Qi ∈{∀, ∃}, xi are distinct Boolean variables, and ϕ is a Boolean formula over the variables xi and the constants 0
(false), 1 (true). The sequence of quantiﬁers in a QBF is called the preﬁx and the
Boolean formula the matrix. The semantics of QBF is deﬁned recursively. A QBF
∃x1Q2x2. . .Qnxn. ϕ is true iﬀQ2x2. . .Qnxn. ϕ|x1=1 or Q2x2. . .Qnxn. ϕ|x1=0
is true. A QBF ∀x1Q2x2. . .Qnxn. ϕ is true iﬀboth Q2x2. . .Qnxn. ϕ|x1=1 and
Q2x2. . .Qnxn. ϕ|x1=0 are true. To decide whether a given QBF is true or not, is
known to be PSPACE-complete .
Propositional Abduction
A propositional abduction problem (PAP) is a 5-tuple P = (V, H, M, T, c). V is
a ﬁnite set of variables. H, M and T are CNF formula representing, respectively,
the set of hypotheses, the set of manifestations, and the background theory. c is
a cost function associating a cost with each clause of H, c : H →R+.
Given a background theory T, a set S ⊆H of hypotheses is an explanation
(for the manifestations) if: (i) S entails the manifestations M (given T); and
(ii) S is consistent (given T). The propositional abduction problem consists in
computing a minimum size explanation for the manifestations subject to the
background theory.
Deﬁnition 1 (Explanations for P ). Let P = (V, H, M, T, c) be a PAP.
The set of explanations of P is given by the set Expl(P) = {S ⊆H | T ∧
S ⊭⊥, T ∧S ⊨M}. The minimum-cost solutions of P are given by Explc(P) =
argminE∈Expl(P )(c(E)).
Input: F WCNF formula
Output: (µ, Cost(µ)) MaxSAT assignment and cost
while true do
h ←MinimumHS(K)
(st, µ) ←SAT(F \ h)
// If st, then µ is an assignment
// Otherwise, µ is a core
if st then return (µ, Cost(µ)) K ←K ∪{µ}
Algorithm 1: The MaxHS algorithm 
The complexity of logic-based abduction has been investigated in a number of
works , and is surveyed in . Checking whether S ⊆H is an explanation
for a PAP is DP-complete. Deciding the existence of some explanation is ΣP
2 complete. Finding a minimum-size explanation can be achieved with a linear
number of calls to a ΣP
2 oracle or, if the costs are polynomially bounded, with a
logarithmic number of calls to a ΣP
Example 1 (Example abduction instance.). Consider the propositional abduction
problem instance P = (V, H, M, T, c) with the set of variables V , the set of
hypotheses H, the manifestations M, and the background theory T given by,
V = {x1, x2, x3, x4}
H = {(x1), (x2), (x3)}
M = {(x4)}
T = {(¬x1 ∨x4), (¬x2 ∨¬x3 ∨x4)}
The (propositional) abduction problem for this example is to ﬁnd a minimum
cost subset S of H, such that (i) S is consistent with T (i.e. T ∧S ⊭⊥); and (ii)
S and T entail M (i.e. T ∧S ⊨M). For this instance of propositional abduction,
the minimum cost explanation is then S = {(x1)}.
Related Work
This paper builds on recent work on algorithms for propositional abduction ,
which builds on earlier work on solving maximum satisﬁability with implicit hitting set algorithms . This work is also tightly related with the body of work on
handling hitting sets implicitly , which is also tightly related
with implicit hitting set dualization , but also with abstraction
reﬁnement in QBF solving and optimization .
The use of implicit hitting sets for solving MaxSAT is embodied by MaxHS
(e.g. see ), which is summarized in Algorithm 1. The algorithm computes
minimum hitting sets of a set of sets, each of which represents an unsatisﬁable
Input: PAP P = (V, H, M, T, c)
Output: Minimum cost explanation S
(st, µ) ←SAT(T ∧H ∧(¬M))
if st then return ∅while S ̸= H do
(st, µ) ←SAT(T ∧S ∧(¬M))
if st then K ←K ∪{{h ∈H | µ(h) = 0}} else
(st, µ) ←SAT(T ∧S)
if not st then K ←K ∪{(H \ S)} else return S
S ←MinimumHS(K)
Algorithm 2: The AbHS/AbHS+ abduction algorithm 
subformula of the target formula. This essentially exploits Reiter’s wellknown hitting set relationship between MCSes and MUSes , where an
MCS is a minimal hitting set of the MUSes and vice-versa. Moreover, since a
minimum hitting set is being computed, we are in search of the smallest MCS, i.e.
the MaxSAT solution. In case there are hard clauses, MaxHS needs to take this
into consideration, including checking the consistency of the hard clauses. Besides
MaxHS, recent work on MaxSAT solving is based on iterative unsatisﬁable core
identiﬁcation .
Recent work on propositional abduction builds on MaxHS and proposes a
novel algorithm, AbHS/AbHS+. AbHS mimics MaxHS in that the algorithm
iteratively computes minimum cost hitting sets, which identify a subset S ⊆H.
This set S is then used for checking whether it represents an explanation of
the propositional abduction problem. Since it is a minimum hitting set then,
if the conditions hold, it is a minimum-cost explanation. AbHS is summarized
in Algorithm 2.
As in MaxHS, the algorithm iteratively computes minimum
hitting sets using an ILP solver (line 10). The outcome is a subset S of H. The
abduction conditions are checked with two distinct SAT oracle calls. One oracle
call checks whether T ∧S ∧(¬M) is inconsistent, i.e. whether T ∧S ⊨M. If the
formula is satisﬁable, then the set of sets to hit (K) is updated with another set,
of the clauses in H falsiﬁed by the computed satisfying assignment. If T ∧S ∧
(¬M) is inconsistent, then a second oracle call checks whether T ∧S is consistent.
If it is, then a minimum-cost explanation has been identiﬁed. Otherwise, AbHS
creates a hitting set by requiring that some non-selected clause of H be selected
in subsequently computed minimum hitting sets. For the AbHS+ variant ,
the set added can be viewed as the complements of the literals selecting each
clause in S, i.e. at least some clause in S must not be picked.
There is a vast body of work on exploiting implicit hitting sets. The concept
of exploiting implicit hitting sets is intended to mean that, instead of starting
from an explicit representation of the complete set of hitting sets, hitting sets
are computed on demand, as deemed necessary by the problem being solved.
An earlier example of exploiting implicit hitting sets is the work of Bailey and
Stuckey , in the concrete application to hitting set dualization. The concept
was re-introduced more recently , and then applied in a number of
diﬀerent settings. Among this vast body of work, as will become clear throughout
the paper, our work can be related with abstraction reﬁnement ideas used in
recent expansion-based QBF solvers, namely RAReQS and quantiﬁed
optimization extensions , but now in the context of handling implicit
hitting sets.
Algorithms for Propositional Abduction
This section overviews diﬀerent algorithms for solving propositional abduction,
all of which are based on reducing the problem to QBF.
QBF Model for Abduction
Given a PAP P = (V, H, M, T, c), the problem of deciding whether some set S
is an explanation can be reduced to QBF. S ⊆H is an explanation of P iﬀ:
∃XT(X) ∧S(X) ∧∀Y ¬(T(Y ) ∧S(Y ) ∧¬M(Y ))
is true. (Observe X and Y denote sets of variables, thus highlighting that diﬀerent sets of variables are used.) (2) can be rewritten as follows:
∃Xφ(X) ∧∀Y ψ(Y ),
where φ = T ∧S and ψ = ¬(T ∧S ∧¬M).
As indicated in Section 2, the goal of propositional abduction is to ﬁnd a
minimum cost explanation, i.e. to pick a minimum cost set S ⊆H that is an
explanation of P.
The problem of ﬁnding a minimum cost explanation of P can be reduced to
quantiﬁed maximum satisﬁability (QMaxSAT). Associate a variable ri with
each clause Ci ∈H, and create a set H′ where each clause Ci ∈H is replaced by
(ri∨Ci), to enable relaxing the clause. Let R denote the set of the ri (relaxation)
variables, with |R| = |H|. H′ serves to create a modiﬁed QBF:
∃R∃XT(X) ∧H′(R, X) ∧∀Y ¬(T(Y ) ∧H′(R, Y ) ∧¬M(Y ))
As before, (4) can be rewritten as follows:
∃R∃Xφ(X, R) ∧∀Y ψ(Y, R)
The above QBF can be transformed into prenex normal formal, and represents
the hard part of the QMaxSAT problem. Moreover, the fact that the goal is to
compute a minimum cost explanation of P is modeled by adding a soft clause
(¬ri), with cost c(Ci), for each ri ∈R. Each soft clause denotes a preference not
to include the associated clause in H in the computed explanation.
Example 2. With respect to the PAP from example Example 1, the QBF associated with the hard part of the QMaxSAT problem is:
∃r1,r2,r3∃x1,x2,x3,x4
(¬x1 ∨x4) ∧(¬x2 ∨¬x3 ∨x4)∧
(r1 ∨x1) ∧(r2 ∨x2) ∧(r3 ∨x3)
∀y1,y2,y3,y4
¬[(¬y1 ∨y4) ∧(¬y2 ∨¬y3 ∨y4)∧
(r1 ∨y1) ∧(r2 ∨y2) ∧(r3 ∨y3) ∧(¬y4)]
with the soft clauses being {(¬r1), (¬r2), (¬r3)}.
The QMaxSAT formulation can be used to develop a number of alternative
approaches for solving PAP. These approaches are detailed in the next sections.
Observe that, if the propositional abduction problem is not trivial to solve,
then the QBF (2) is false for S = ∅and S = H.
Abduction with QMaxSAT
Similarly to MaxSAT, a number of algorithms can be envisioned for solving
QMaxSAT. These are analyzed in the subsections below, taking into account
the speciﬁc structure of the reduction of propositional abduction to QMaxSAT.
Iterative QBF Solving A standard approach for solving MaxSAT is iterative
SAT solving . Similarly, we can use iterative QBF solving for QMaxSAT. At
each step, and given cost k, the following pseudo-Boolean constraint is used:
PB(R, k) ≜
c(Ci)ri ≤k
For some positive k, the QBF (5) can be used for iteratively QBF solving as
∃RPB(R, k) ∧∃Xφ(X, R) ∧∀Y ψ(R, Y )
Clearly, binary search can be used to ensure a linear (or logarithmic, depending on whether the costs are bounded) number of ΣP
2 oracle calls . In practice,
most QBF solvers expect clausal representations. Clausiﬁcation introduces one
additional level of quantiﬁcation. Typically, each quantiﬁcation level makes a
QBF formula harder to decide. And thus in practice, QBF solvers scale worse
than SAT solvers, and so this approach is unlikely to scale for large propositional
abduction problem instances.
Core-Guided QBF Solving Core-guided algorithms represent another
approach for solving QMaxSAT. Many variants of core-guided MaxSAT algorithms have been proposed in recent years .
Given the reduction of propositional abduction to QMaxSAT, any coreguided MaxSAT algorithm can be used, provided a core-producing QBF solver
is used .
Nevertheless, for the abduction problem the use of alternative MaxSAT solving approaches, based on MaxHS is amenable to eﬃcient optimizations,
which solely use SAT solvers .
Exploiting MaxHS A recent approach for MaxSAT solving is MaxHS ,
which exploits integer linear programming (ILP) solving, resulting in simpler
SAT oracle calls, at the cost of a possibly exponentially larger number of oracle
calls. Recall that the MaxHS approach for solving MaxSAT is outlined in Algorithm 1.
A straightforward solution for solving QMaxSAT is to replace the SAT oracle
by a QBF oracle in MaxHS. This approach is referred to as QMaxHS, and it was
implemented on top of DepQBF, the known QBF solver which is capable of reporting unsatisﬁable cores if the input QBF is false . It should be noted (and
it is also mentioned in Section 4) that the implementation of QMaxHS performs
quite bad (it cannot solve any benchmark instances considered in Section 4).
A possible explanation of this is that the QBF formulas, which are iteratively
solved by the QBF solver, are too hard even though the original idea of MaxHSlike algorithms is to get (many) simple calls to the oracle. This suggests that
implementing core-guided QMaxSAT algorithms would not pay oﬀas well since
the QBF formulas in core-guided QMaxSAT are much harder to deal with. Recent work on propositional abduction proposed a MaxHS-like approach, but
the QBF oracle call was replaced by two SAT solver calls, which is expected to
outperform QMaxHS.
Exploiting Implicit Hitting Sets
The use of implicit hitting sets for abduction was proposed in recent work .
This work can be viewed as extending the MaxHS algorithm for MaxSAT ,
which is based on implicit enumeration of hitting sets. In contrast to MaxHS,
instead of one SAT oracle call, AbHS uses two SAT oracle calls, one to
check entailment of M by T ∧S and another to check the consistency of T ∧
S. A variant of AbHS, AbHS+, diﬀers on which sets are added to the hitting
set representation. Whereas the connection of MaxHS and AbHS with implicit
hitting sets is clear, the approach used in AbHS+ can be viewed as adding both
only positive clauses and only negative clauses to hit, and so the connection
with hitting sets is less evident. An alternative way of explaining AbHS/AbHS+
is to consider (5). The ILP solver is used for computing some minimum cost
hitting set, which represents a set of clauses S ⊆H. Then, one SAT oracle call
checks ∃Xφ(X), given S, and another SAT oracle call checks ∀Y ψ(Y ), also given
S. (Observe that this second formula corresponds to checking unsatisﬁability.)
This explanation of how AbHS/AbHS+ works is investigated in greater detail
In the following an alternative approach for propositional abduction is developed which, similarly to AbHS/AbHS+, is also based on handling implicit
hitting sets, but which is shown to yield exponential reductions on the number
of oracle calls in the worst case. The new algorithm, Hyper, shares similarities
with MaxHS and also with AbHS/AbHS+ in that minimum hitting sets are also
computed, and an implicit representation of the hitting sets is maintained. However, and in contrast with AbHS/AbHS+, Hyper analyzes the structure of the
problem formulation, and develops a number of optimizations that exploit that
formulation.
The propositional abduction problem formulation can be presented in a
slightly modiﬁed form, i.e. to ﬁnd a smallest cost set S ⊆H, consistent with
T (i.e. a T-consistent set S), which, together with T, entails M. Consider a Tconsistent candidate set S ⊆H. If T ∧S ⊭M, then the formula T ∧S ∧(¬M) is
satisﬁable and the satisfying assignment returned by the SAT oracle is a counterexample explaining why the selected set S is such that T ∧S ⊭M. Moreover,
this satisfying assignment can be used for revealing a (possibly subset-minimal)
set of clauses in H \ S which are falsiﬁed. Clearly, one of these falsiﬁed clauses
must be included (i.e. hit) in any T-consistent set S ⊆H which, together with
T, will entail M. Thus, from each T-consistent candidate set S ⊆H which,
together with T, does not entail M, we can identify a set of clauses, from which
at least one must be picked, in order to pick another T-consistent set S ⊆H,
such that eventually T ∧S ⊨M.
The approach outlined in the paragraph above, although apparently similar
to the description of AbHS/AbHS+, reveals a number of signiﬁcant insights.
First, checking the consistency of S with T can be carried out concurrently with
the selection of S itself. This is also apparent from the QBF formulation (2),
in that all existential quantiﬁers can be aggregated and handled simultaneously.
Thus, each minimum hitting set S is computed while guaranteeing that T ∧S
holds. More importantly, after each set S is picked, it is only necessary to check
whether T ∧S ⊨M, and this can be done with a single SAT oracle call.
Concretely, the next minimum cost hitting set, given the already identiﬁed
sets to hit, is computed guaranteeing that the existential part of (4) is satisﬁed:
∃R∃XT(X) ∧H′(R, X)
The selected set S, identiﬁed by the assignment to the R variables, is then used
for checking the satisﬁability of the second component of QBF (2):
∀Y ¬(T(Y ) ∧S(Y ) ∧¬M(Y ))
Observe that this can be decided with a SAT oracle call.
Thus, a careful analysis of the problem formulation enables improving upon
AbHS and AbHS+, speciﬁcally by eliminating one SAT oracle call per iteration.
However, as shown in the next section, the new algorithm can save an exponentially large number of SAT oracle calls when compared with AbHS/AbHS+.
Input: PAP P = (V, H, M, T, c)
Output: Minimum cost explanation S
(H′, R) ←RelaxCls(H)
B ←T ∧M ∧H′
while true do
(st, h) ←MinimumHS(A, B)
if not st then return ∅S ←{Ci ∈H′ | ri ∈h}
(st, µ) ←SAT(T ∧S ∧(¬M))
if not st then return S W ←PickFalseCls(H \ S, µ)
Y ←GetRelaxationVars(W)
Algorithm 3: Organization of Hyper
Besides the aggregation of the existential quantiﬁers, additional optimizations can be envisioned. Propositional abduction seeks a minimum cost set
S ⊆H such that T ∧S ⊨M. Ideally, one would prefer not to select a set S ⊆H
such that T ∧S ⊭M. Observe that T ∧S ⊨M implies that T ∧S ∧M holds, but
the converse is in general not true. Thus, M can be added to (9), resulting in
requiring that T ∧S ∧M be consistent when selecting the set S. The inclusion
of M when picking a minimum hitting set can also reduce the number of oracle
calls exponentially. This is also investigated in the next section.
The new Hyper algorithm for propositional abduction is shown as Algorithm 3. Clauses in H are relaxed, to allow each clause Ci ∈H to be picked
when the associated relaxation variable ri is assigned value 1. The minimum
hitting sets are computed for the set of sets A, subject to a background theory
B, which conjoins T, M and the relaxed clauses of H. In Hyper minimum hitting
sets are computed with a MaxSAT solver , since the hard part (containing
T, M and H′) plays a signiﬁcant role in deciding consistency. If all hitting sets
have been (implicitly) tried unsuccessfully, then the algorithm terminates and
returns ∅. If not, and if T ∧S ⊨M, then the algorithm terminates and returns
the computed set S. Otherwise, a subset of the clauses in H \ S, which are falsiﬁed by the computed satisfying assignment µ, is identiﬁed, and the associated
relaxation variables are used to create another set to hit, i.e. one of those clauses
must be included in any selected set S.
Additional Optimizations A few additional optimizations are possible, which
can be expected to have some impact in the performance of Hyper. These are
discussed next. The ﬁrst two optimizations are implemented in a variant of Hyper, Hyper⋆. The other optimizations are analyzed to explain why performance
improvements are not expected to be signiﬁcant.
One optimization is to perform partial reduction of the counterexamples computed in lines 11–12 of Algorithm 3. Recall that counterexamples, i.e. sets that
need to be hit next time, comprise clauses of H \ S that are falsiﬁed by a model
µ of T ∧S ∧(¬M). Thus, the counterexamples can be seen as correction subsets
for the partial CNF formula T ∧H ∧(¬M), where T ∧(¬M) is the hard part
and H is the soft part. Observe that instead of computing any correction subset,
one may want to reduce it to get a subset-minimal correction subset (an MCS),
i.e. to try to minimize the number of falsiﬁed clauses in H \ S. In Hyper⋆this is
done using the standard linear search algorithm , which iterates through the
falsiﬁed clauses and tries to satisfy them. In order not to spend too much time
on doing the reduction, the version of Hyper⋆presented here iterates only over
0.2 × m falsiﬁed clauses of the initial counterexample starting from the clauses
of the smallest weight, where m is the size of the initial counterexample.
A second optimization is to start by computing a ﬁxed number of minimum
hitting sets. Given that T ∧H ∧(¬M) is inconsistent, one can enumerate MCSes
of this formula, which must be hit, so that one can eventually prove that there
exists some set S with T ∧S ⊨M. In Hyper, 100 MCSes of T ∧H ∧(¬M)
are computed before starting the process of generating candidate sets S. These
MCSes are computed by size, using MaxSAT-based MCS enumeration .
A third optimization respects the clauses in M. Any Cj ∈M, such that
T ⊨Cj, can be removed from M. In a preprocessing step, each clause in M is
checked for entailment with respect to T. Any entailed clause is removed. This
technique reduces the practical hardness of the formulas checked for unsatisﬁability. Since most of the running time of Hyper is spent on computing minimum
hitting sets, the impact of the technique is expected to be marginal.
A fourth, and ﬁnal optimization respects the clauses in H. Any Cj ∈H that
T ⊨Cj, can also be removed from H, as it will not be included in any minimum
cost hitting set. It should be noted that the gains of this technique should be
also marginal. Since by construction T ∧S is consistent, and the only computed
counterexamples satisfy T ∧S ∧(¬M), then any clause Cj ∈H with T ⊨Cj will
also be satisﬁed. Since, the counterexamples only consider falsiﬁed clauses, then
any clause Cj ∈H entailed by T will never be included in a set to be hit.
Exponential Reductions in Oracle Calls This section argues that the new
Hyper algorithm for solving propositional abduction can save an exponentially
larger number of iterations when compared with the AbHS/AbHS+ algorithm
proposed in earlier work .
Consider a PAP P1 = (V, H, M, T, c), with:
V = {t1, x1, y1, m1, . . . , tn, xn, yn, mn}
H = {(¬x1), (x1 ∨t1), (¬y1), (y1 ∨t1), . . . ,
(¬xn), (xn ∨tn), (¬yn), (yn ∨tn)}
M = {(m1), (m2), . . . , (mn)}
T = {(¬t1 ∨¬t2 ∨. . . ∨¬tn),
(¬t1 ∨m1), . . . , (¬tn ∨mn)}
and c(Ci) = 1 for Ci ∈H. Clearly, P has no solution. For M to be entailed, S
must imply all variables ti to 1; but this causes T ∧S to become inconsistent.
Moreover, there are exponentially many sets S, which are not consistent with T.
AbHS+ will have to enumerate all of these sets S and, for each such set S, it will
use one additional SAT oracle call to conclude that T ∧S is inconsistent. Since
AbHS+ (or AbHS) selects all falsiﬁed clauses when blocking counterexamples of
T ∧S∧(¬M), all subsets of S inconsistent with T will be eventually enumerated.
In contrast, since Hyper ensures consistency between S and T when selecting a
minimum hitting set, this exponentially large number of oracle calls is not observed. (These diﬀerences between AbHS/AbHS+ and Hyper are experimentally
validated in Section 4.)
It should be clear that the exponentially large reduction in the number of
oracle calls obtained with Hyper are hidden in the minimum hitting set extractor.
However, in Hyper the minimum hitting set extractor is based on MaxSAT
(concretely core-guided MaxSAT), and so this hidden complexity is handled
(most often eﬃciently) by the SAT solver.
The inclusion of M to ﬁnd each set S can also potentially save exponentially
many iterations. Consider the following PAP P2 = (V, H, M, T, c):
V = {m, t1, x1, . . . , tn, xn}
H = {(m ∨¬x1), (m ∨x1 ∨t1),
(m ∨¬xn), (m ∨xn ∨tn)}
T = {(¬t1 ∨. . . ∨¬tn)}
In contrast with the previous example, P has a solution, i.e. there exists a subset
S of H (with S = H) such that T ∧S ⊨M. Until the solution is found, all
computed models of T ∧S∧(¬M) will also falsify T ∧S∧M. Any of these models
might be ﬁltered out if any candidate set S is such that T ∧S∧M is consistent. It
should be noted that in this case there is no formal guarantee that the number of
SAT oracle calls must be exponential. This depends on the solutions provided by
the minimum hitting set algorithm used. Essentially, taking M into account when
selecting S guarantees that the picked set S will not be such that T ∧S ⊨¬M. As
the results in the next section conﬁrm, in practice AbHS/AbHS+ can generate
exponentially many candidates S for which T ∧S ⊨¬M.
Experimental Results
This section evaluates the proposed approach to propositional abduction.
Experimental Setup
All the conducted experiments were performed in Ubuntu Linux on an Intel
Xeon E5-2630 2.60GHz processor with 64GByte of memory. The time limit was
set to 1800s and the memory limit to 10GByte for each process to run. A prototype of the Hyper algorithm proposed above was implemented in C++ and
CPU time (s)
(a) PMS instances
CPU time (s)
(b) WPMS instances
Fig. 1: Performance of Hyper, Hyper⋆, AbHS, and AbHS+ for the Abduction
Problem Suite benchmarks.
consists of two interacting parts. One of them computes minimum size hitting
sets of the set of counterexamples, also satisfying T ∧S ∧M. This is achieved
with the use of an incremental implementation of the algorithm based on soft
cardinality constraints , which is a state-of-the-art MaxSAT algorithm that
won several categories in the MaxSAT Evaluation 20151. The other part of the
prototype checks satisﬁability of T ∧S ∧(¬M), where S is a candidate hitting
set reported by the hitting set solver. Note that both parts of the solver were
implemented on top of the well-known SAT solver Glucose 3.02 .
Besides the basic version of Hyper, we also implemented an improved version,
which is below referred to as Hyper⋆and contains the ﬁrst two improvements described in Section 12. Namely, the ﬁrst improvement does partial reduction of
counterexamples by traversing and trying to satisfy 0.2×m clauses of each counterexample, where m is the size of the counterexample. The second improvement
used in Hyper⋆consists in bootstrapping the hitting set solver with 100 MCSes of
MaxSAT formula T ∧H ∧(¬M). It should be noted that bootstrapping the algorithm is not necessary but in some cases it can boost the performance of the main
algorithm. Also note that the MaxSAT solver in both Hyper and Hyper⋆trims
unsatisﬁable cores detected during the solving process at most 5 times.
The performance of Hyper and Hyper⋆was compared to the performance of
the recent state-of-the-art algorithms AbHS and AbHS+3 . Additionally, we
also implemented the QMaxHS approach described in Section 3.3. The implementation was done on top of DepQBF4, the known QBF solver which is capable
or reporting unsatisﬁable cores . However, the performance of QMaxHS is
poor (i.e. in our evaluation it did not solve any instance from the considered
benchmark suite) and we decided to exclude it from consideration.
Abduction Problem Suite
In order to assess the eﬃciency of the new approach to propositional abduction,
the following benchmark suite was used, which was proposed and also considered
in . According to , the benchmark instances were generated based on
crafted and industrial instances from MaxSAT Evaluation 2014 with the use
of the MaxSAT solver LMHS5 and the backbone solver minibones6 .
The reader is referred to for details. The resulting benchmark suite contains
6 benchmarks sets: pms-5, pms-10, pms-15, wpms-5, wpms-10, and wpms-15,
where the number indicates the number of manifestations. In the conducted
experimental evaluation, benchmark sets were aggregated based on their type
(weighted or unweighted) and resulted in two benchmark sets: PMS and WPMS,
having 847 and 795 instances, respectively. The total number of instances is 1642.
The cactus plots reporting the performance of the considered algorithms measured for the considered problem instances is shown in Figure 1. As one can see
in Figure 1a, for PMS benchmark instances, Hyper and Hyper⋆perform significantly better than both AbHS and AbHS+. More precisely, Hyper⋆solves 321
1 See results for MSCG15b at 
2 
3 
4 
5 
6 
1800 sec. timeout
1800 sec. timeout
(a) PMS instances
1800 sec. timeout
1800 sec. timeout
(b) WPMS instances
Fig. 2: Hyper⋆vs AbHS+.
Table 1: The number of iterations and running time per solver for example family
(11). Additionally, for AbHS/AbHS+ the number of iterations of type 2 is also
shown (in parentheses). Value n varies from 1 to 10.
11 (7) 59 (49) 363 (343) 2401 (829)
>1800s >1800s
AbHS+ 6 (2)
125 (32) 388 (64) 978 (128) 2242 (256)
>1800s >1800s
instances (out of 847), which is 76 more (> 31%) than the number of instances
solved by AbHS+ (245). The second best competitor is Hyper, which solves 318
instances being 3 instances behind Hyper⋆. Finally, the worst performance is
shown by AbHS, which solves 174 instances.
In contrast to the unweighted problem instances, the performance of the
new algorithm for weighted instances is penalized by the use of MaxSAT for
computing minimal hitting sets. The reason is that the MaxSAT solver used in
Hyper does not exploit any modern and widely used heuristics to eﬃciently deal
with weights, e.g. Boolean lexicographic optimization or stratiﬁcation .7
7 This conjecture is also suggested by the average numbers of iterations done by
Hyper⋆and AbHS+ for the WPMS benchmarks, which are 69 and 229, respectively.
Since Hyper⋆does signiﬁcantly fewer iterations (on average) and solves around the
Table 2: The number of iterations and running time per solver for example family
(12). Value n varies from 1 to 10.
54 133 350 878
AbHS+ 0.0s 0.1s 0.1s 0.2s 0.3s 2.0s 15.5s 168.8s >1800s >1800s
0.0s 0.0s 0.0s 0.0s 0.0s 0.0s 0.0s
This can explain a similar performance shown by Hyper and Hyper⋆compared
to AbHS+. More precisely, Hyper⋆is able to solve 398 instances (out of 795).
AbHS+ comes second solving 389 instances while Hyper is 2 instances behind
AbHS+ (387 solved). The worst performance is shown again by AbHS, which
solves 252 instances.
Regarding the performance of the virtual best solver (VBS), the data for
both sets of benchmarks can be seen in Figure 1 and it is the following. For
PMS, the VBS aggregating Hyper, Hyper⋆as well as AbHS+8 is able to solve
328 instances, which is 7 more instances than what Hyper⋆can solve alone. In
contrast, for the WPMS instances the picture is diﬀerent: the VBS solves 425
instances, which is 27 and 36 more instances than what Hyper⋆and AbHS+
can solve separately. This indicates that Hyper⋆and AbHS+ complement each
other in this case, which suggests building a portfolio of the solvers for weighted
instances. The performance comparison between AbHS+ and Hyper⋆is detailed
in the scatter plots shown in Figure 2 and also conﬁrms this conclusion.
Although the experimental results for the abduction problem suite show clear
performance gain of the proposed Hyper algorithm over the state-of-the-art in
propositional abduction (AbHS+), it is important to mention that the benchmark suite was generated (see ) from the MaxSAT instances by ﬁltering out
those of them that are hard for MaxHS-like MaxSAT solvers, i.e. MaxHS 
and LMHS . This fact suggests that applying similar ideas for generating
problem instances by targeting MaxSAT formulas that are easier for another
family of MaxSAT algorithms, e.g. the core-guided algorithms based on soft cardinality constraints (recall that the MaxSAT solver in Hyper is one of them),
would result in even better performance of Hyper. Moreover, the experimental
results for the weighted benchmarks emphasize the importance of applying modern techniques (e.g. Boolean lexicographic optimization and stratiﬁcation) targeting speciﬁcally weighted instances. Having implemented such improvements,
one could expect Hyper to perform better for problem instances with weights.
same number of instances as AbHS+ does, we assume that the calls to the MaxSAT
oracle are harder (on average).
8 AbHS is excluded from the VBS since it does not contribute to its performance.
Oracle Calls in AbHS+
This section studies the number of iterations for the considered approaches for
the families of examples described in Section 12. For both examples (11) and
(12) we generated 10 instances varying size n of the instance from 1 to 10 in
order to show how the number of iterations grows with the growth of size n for
each approach.9
Recall that example (11) aims at showing the importance of adding the theory
clauses into the hitting set solver by saving an exponential number of iterations
related to candidates that are not consistent with the theory. In AbHS/AbHS+
the consistency check is done through the second SAT call and results in a counterexample blocking the candidate (AbHS+ also blocks its supersets). The idea
of proposing example family (11) is, thus, to show that the number of iterations
of this type (let us call them iterations of type 2 because they are related with
the 2nd SAT call) in AbHS and AbHS+ can be exponentially larger than the
number of iterations done by Hyper10. Indeed, Table 1 conﬁrms this conjecture
indicating that the number of iterations of type 2 in AbHS+ grows exponentially
with the growth of n, i.e. it is exactly 2n (see the values in parentheses), while the
number of iterations done by Hyper is negligible. The situation gets even more
dramatic for AbHS. (As one can see, the total number of iterations performed
by AbHS and AbHS+ grows even faster.) The running time spent by AbHS and
AbHS+ also grows signiﬁcantly with the growth of n. As a result, AbHS and
AbHS+ cannot solve any instances for n > 4 and n > 8, respectively, within
1800 seconds. Observe that Hyper reports the result for each n immediately.
Regarding example (12), it shows the importance of adding M into the hitting
set solver. Table 2 conﬁrms that it can save an exponential number of iterations.
As one can observe, the number of iterations grows exponentially with growing
value n for AbHS and AbHS+. Note that in this case AbHS and AbHS+ behave
similarly to each other, which is why Table 2 does not have a separate row for
AbHS+. Analogously to the previous case, the performance of the solver (i.e. its
running time) is severely aﬀected by the number of iterations. Analogously to
the previous example and in contrast to AbHS and AbHS+, the basic version of
Hyper does signiﬁcantly fewer iterations and spends almost no time for each of
the considered instances.
9 It should be noted that the pseudo-code in Algorithm 2 (taken from ), as well as
the actual source code, needs to be modiﬁed for AbHS+ to produce correct results
when a PAP does not have a solution, as is the case with example (11). When
blocking previously computed hitting sets, AbHS+ can generate clauses both with
positive literals and clauses with negative literals and, for a PAP without solution,
it will eventually compute an empty hitting set, denoting that there is no solution
to the constraints added as sets to hit. As a result, the pseudo-code (and the source)
needs to test for the case when the minimum hitting set returned is empty, in which
case it must return ‘no solution’. This ﬁx was added to AbHS+ to get the results
presented in this section.
10 In order test the number of iterations, all the optimizations related to Hyper⋆were
turned oﬀand, thus, the basic version of Hyper was considered instead.
Conclusions
Abduction ﬁnds many applications in Artiﬁcial Intelligence, with a large body
of work over the years. Recent work investigated propositional abduction, and
proposed the use of a variant of the implicit hitting set algorithm MaxHS for
solving the problem .
This paper identiﬁes several sources of ineﬃciency with earlier work, and proposes a novel, implicit hitting set inspired, algorithm for propositional abduction.
The novel algorithm, Hyper, is shown to outperform the recently proposed algorithms AbHS and AbHS+ on existing problem instances. In addition, the paper
demonstrates that the proposed improvements can result in exponential savings
on the number of SAT oracle calls, which helps explain the observed performance
improvements. In a broader context, this paper contributes to the recent body of
work on implicit hitting set algorithms, and identiﬁes algorithmic optimizations
that can be signiﬁcant in other contexts.
A number of research directions can be envisioned. These include improvements to the MaxSAT solver used for computing minimum hitting sets, as this
represents the main bottleneck of the Hyper algorithm. Additional work will
involve applying Hyper to a larger range of problem instances.