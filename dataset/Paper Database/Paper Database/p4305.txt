The eﬀect of data encoding on the expressive power of variational quantum machine
learning models
Maria Schuld,1 Ryan Sweke,2 and Johannes Jakob Meyer2
1Xanadu, Toronto, ON, M5G 2C8, Canada
2Dahlem Center for Complex Quantum Systems,
Freie Universit¨at Berlin, 14195 Berlin, Germany
 
Quantum computers can be used for supervised learning by treating parametrised quantum circuits as models that map data inputs to predictions. While a lot of work has been done to investigate
practical implications of this approach, many important theoretical properties of these models remain unknown. Here we investigate how the strategy with which data is encoded into the model
inﬂuences the expressive power of parametrised quantum circuits as function approximators. We
show that one can naturally write a quantum model as a partial Fourier series in the data, where
the accessible frequencies are determined by the nature of the data encoding gates in the circuit.
By repeating simple data encoding gates multiple times, quantum models can access increasingly
rich frequency spectra. We show that there exist quantum models which can realise all possible
sets of Fourier coeﬃcients, and therefore, if the accessible frequency spectrum is asymptotically rich
enough, such models are universal function approximators.
A popular approach to quantum machine learning
uses trainable quantum circuits as machine learning
models similar to neural networks. Quantum gates –
the building blocks of quantum circuits – are used to
encode data inputs x = (x1, . . . , xN) as well as trainable weights θ = (θ1, . . . , θM). The circuit is measured
multiple times to estimate the expectation of some observable, and the result is interpreted as a prediction.
The overall computation implements a “quantum model
function” fθ(x), a machine learning model that is based
on quantum computing. This approach is known by different names such as variational circuits , quantum
circuit learning , quantum neural networks , or
parametrised quantum circuits .
A lot of work has been done to understand the practical details of this approach, leading to useful training
strategies and ways to emulate and extend classical machine learning methods .
body of literature, motivated by the dilemma of investigating the performance of quantum machine learning
when only small-scale experiments are physically possible, tries to understand the potential power of variational circuits from a theoretical perspective . Still, only little is known about the actual function
classes that quantum circuits give rise to. Can quantum
models express any function in the input x, or are they
limited to a speciﬁc class of functions? Can this class
of “learnable functions” be characterised in a meaningful way, and can the characterisation be used to guide
design choices and potential applications for these quantum models?
In this paper we investigate these questions in a
framework focused on the role of data encoding.
consider standard models from the literature that consist of multiple “circuit layers”, each made up of a data
encoding (circuit) block and a trainable (circuit) block,
and assume that input features x ∈R are encoded by
gates of the form eixH, where H is an arbitrary Hamil-
FIG. 1. Illustration of the main result of this paper, shown
for one-dimensional inputs x ∈R: quantum models consisting of layers of trainable circuit blocks W = W(θ) and data
encoding circuit blocks S(x) can be written as a weighed
ω cωeiωx. The data encoding circuit determines the
frequencies ω, and the remainder of the circuit architecture
determines the coeﬃcients cω. If the ω are integer-valued (or
integer-valued multiples of a base frequency ω0), the sum becomes a partial Fourier series, which allows us to systematically study properties of the function class a given quantum
model can learn.
tonian. Our main tool is the natural representation of
such quantum models as a Fourier-type sum
cω(θ)eiωx,
where ωx is the inner product. We show that the frequency spectrum Ω⊂RN is solely determined by the
eigenvalues of the data-encoding Hamiltonians while the
design of the entire circuit controls the coeﬃcients cω
 
that a quantum model can realise (see Fig.1). The representation of quantum models as Fourier-type sums characterises the function families that a given class of quantum models can learn via two interrelated properties.
The ﬁrst property is the frequency spectrum Ω, which
determines the functions eiωx that the quantum model
“has access to”. The second property is the expressivity
of the coeﬃcients {cω} that a class of quantum models
can control, which determines how the accessible functions can be combined. In many natural settings, the
frequencies are integers, Ω⊂ZN, and the sum becomes
a multi-dimensional partial Fourier series
cn(θ)einx,
where the einx are orthogonal basis functions. We use
the nomenclature partial Fourier series to indicate the
fact that only a subset of the Fourier coeﬃcients are nonzero. The Fourier series formalism allows us to study
quantum models using the rich techniques developed in
Fourier analysis.
First, we consider the popular strategy of encoding
an input into single-qubit rotations, and show that repeating the encoding r times either sequentially or in
parallel allows the model to access frequency spectra Ω
consisting of r frequencies. This places into a broader
context an observation made in Ref. , which states
that encoding a data feature only once into the angle of
a single qubit rotation restricts the function class that
quantum models can learn to a simple sine function (or
equivalently, a Fourier series with a single frequency).
Second, we provide bounds for the maximum number
of frequencies and Fourier coeﬃcients a quantum model
can control for more general data encoding strategies.
Finally, we study the universality of quantum models.
We show that for suﬃciently ﬂexible trainable circuit
blocks there exists a quantum model which can realise
any possible set of Fourier coeﬃcients. If, asymptotically, the accessible frequency spectrum is rich enough,
then such models are universal function approximators.
This follows from the fact that Fourier series with arbitrary coeﬃcients can approximate any square integrable
function on a given interval .
A few existing studies are related to our work. For
example, P´erez-Salinas et al. considered quantum
models with sequentially repeated data encodings and
conjectured that they are universal function approximators under a special kind of classical data pre-processing.
Killoran et al. have shown that many neural networks can be naturally emulated on a photonic quantum computer, and point out that such quantum models
therefore inherit universality. The majority of quantum
machine learning papers concerned with questions of expressivity and universality , however, interpret
these concepts from a quantum information perspective,
which asks whether a circuit can express any quantum
computation, not any function in the inputs. However,
in the context of (supervised) machine learning, quantum universality does not necessarily imply universal
function approximation; a quantum circuit able to realise arbitrary unitary evolutions may only be able to express a limited class of functions f(x).1 From the function expressivity view-point, Ref. has investigated
the pseudo-dimension of a particular class of quantum
models, an expressivity metric which allows one to characterize learnability and generalization power of the associated model. Also the essential role of data encoding
for quantum machine learning has been emphasised in
previous papers.
For example, it was remarked that
data encoding determines the features that quantum
models represent , the decision boundaries they
can learn , as well as the measurements that optimally distinguish between data classes . A central
contribution of this paper is to systematically combine
the study of data encoding with that of the expressivity
of quantum models.
We present our results as follows: Section I introduces
the basic idea of writing quantum models as partial
Fourier series. Section II puts the tool to use and analyses the expressivity of quantum models, which leads to a
proof that quantum models are universal in Section III.
Section IV discusses practically relevant implications.
Note: After publishing the preprint of this article, we
were made aware that the connection between Fourier
series and quantum machine learning models with repeated data-encoding has already been established in
Ref. . While there is signiﬁcant overlap between this
work and ours, we provide a novel universality result,
as well as a systematic development of this connection
through practically relevant examples.
QUANTUM MODELS AS PARTIAL
FOURIER SERIES
First, we introduce our basic tool: the natural representation of a quantum model as a partial Fourier series.
For simplicity, the majority of our presentation
will focus on the case of univariate functions with inputs x ∈R, but we generalise this to multivariate functions in Appendix A, which is used for the analysis of
universality in Section III.
We deﬁne a (univariate) quantum model fθ(x) as the
expectation value of some observable with respect to a
state prepared via a parametrised quantum circuit, i.e.
fθ(x) = ⟨0| U †(x, θ)MU(x, θ) |0⟩,
where |0⟩is some initial state of the quantum computer,
U(x, θ) is a quantum circuit that depends on the input x and a (possibly empty) set of parameters θ, and
1 As an extreme example, consider a parametrised quantum circuit that encodes the data into gates acting on qubits which
are never entangled with the measured qubits – in which case
f(x) is a constant function, and the resulting machine learning
model trivial.
M is some observable. The prediction of the quantum
model at a speciﬁc point x is estimated in practice by
running the circuit multiple times and averaging over
the measurement results.2 The quantum circuit itself
is constructed from L layers, each consisting of a data
encoding circuit block S(x) and a trainable circuit block
W(θ) controlled by the parameters θ (see Fig. 1). The
data encoding block is the same in every layer and consists of gates of the form G(x) = e−ixH, where H is a
Hamiltonian that generates the “time evolution” used
to encode the data. Since we want to focus on the role
of the data encoding, and to avoid further assumptions
on how the trainable circuit blocks are parametrised, we
view the trainable circuit blocks as arbitrary unitary operations, W(θ) = W, and drop the subscript of fθ from
here on.3 With this assumption, the overall quantum
circuit has the form
U(x) = W (L+1)S(x)W (L) . . . W (2)S(x)W (1).
Note that the encoding strategy is very natural, since
the physical control parameters of quantum dynamics
usually enter as time evolutions of Hamiltonians – the
most prominent example being Pauli rotations.
model includes “parallel encodings” that repeat the encoding on diﬀerent subsystems , as well as “data
reuploading”, where the encoding is repeated multiple times in sequence (see Fig. 2). With a small
amount of classical pre-processing this model includes
even many quantum machine learning algorithms that
are not based on the principles of parametrised circuits
(see also Section IV A).
Our goal is to write f as a partial Fourier series
with integer-valued frequencies (if Ω= {−K, . . . , K},
then we call (5) a truncated Fourier series). The ﬁrst
step is to note that one can always ﬁnd an eigenvalue decomposition of the generator Hamiltonian H = V †ΣV
where Σ is a diagonal operator containing H’s eigenvalues λ1, ..., λd on its diagonal. The data encoding unitary becomes S(x) = V †e−ixΣV , and we can “absorb”
V , V † into the arbitrary unitaries W ′ = V WV †. Hence,
without loss of generality we will assume that H is diagonal. This allows us to separate the data-dependent
expressions from the remainder of the circuit in each
2 Note that the quantum model is a theoretical construction,
since physical measurements will always result in an estimate
of the output expectation, making f a random variable – a
complication that we will ignore here.
3 Of course, in realistic near-term settings these unitaries are implemented as short gate sequences and are by no means universal, and there are many interesting questions around how a
speciﬁc parametrisation inﬂuences the properties of the resulting quantum model.
FIG. 2. The general quantum model considered in this paper
includes qubit-based circuits where the encoding subroutine
consists of a single-qubit gate G(x), which is often used in
The picture illustrates two special cases investigated in Section II: (a) shows a circuit where the scalar input feature x is encoded by one single-qubit gate, which can
be repeated r = L > 1 times but always acts on the same
qubit, and (b) repeats the encoding gate r times in “parallel” using only one layer. Note that the trainable blocks
W (purple rectangles) represent arbitrary unitaries, which in
practice would be implemented as a sequence of local gates
component i of the quantum state U(x) |0⟩,
[U(x) |0⟩]i =
e−i(λj1+···+λjL)x
. . . W (2)
For ease of notation we introduce the multi-index j =
{j1, . . . , jL} ∈[d]L, where [d]L denotes the set of any L
integers between 1, . . . , d. We can then denote the sum
of eigenvalues for a given j by Λj = λj1 +· · ·+λjL, and
[U(x) |0⟩]i =
e−iΛjxW (L+1)
. . . W (2)
To consider the full quantum model from Eq. (3) we
need to take into account the complex conjugation of
this expression as well as the measurement, and get
ei(Λk−Λj)xak,j,
where the ak,j contain the terms stemming from the
arbitrary unitaries and measurement,
1k1(W ∗)(2)
j1j2 . . . (W ∗)(L+1)
. . . W (2)
The second step consists of grouping all terms in the
sum (8) whose basis function ei(Λk−Λj)x have the same
frequency ω = Λk−Λj. All frequencies accessible to the
quantum model are contained in its frequency spectrum
Ω= {Λk −Λj, k, j ∈[d]L}.
This yields
where the coeﬃcients are obtained by summing over all
ak,j contributing to the same frequency
We note that the frequency spectrum Ωhas the following important properties: 0 ∈Ω, and for every frequency ω ∈Ω, we have also that −ω ∈Ω. Additionally,
since cω = c∗
−ω, Eq. (11) realises a real-valued function.
We will therefore denote with K = (|Ω| −1)/2 the size
of the spectrum, as it quantiﬁes how many independent non-zero frequencies the model has access to. The
largest available frequency D = max(Ω) is called the degree of the spectrum. Furthermore, the coeﬃcients cω
are determined by the arbitrary gates W (1) . . . W (L+1)
(which absorbed the V , V † from the encoding Hamiltonians), as well as by the measurement observable. As a
consequence, a quantum model’s frequency spectrum is
solely determined by the eigenvalues of the data encoding gates, while its Fourier coeﬃcients depend on the
entire circuit, as was claimed in Fig. 1. While so far we
have not imposed restrictions on the frequencies ω, one
can see that for integer-valued eigenvalues λ1, . . . , λd,
the frequencies in Ωare themselves integer-valued, and
Eq. (11) yields the real-valued partial Fourier series from
Eq. (5). As we will show in the following section, common data encoding strategies in near-term quantum machine learning fulﬁll the property of an integer-valued
frequency spectrum. Even if the eigenvalues of the encoding gate generators, and therefore the accessible frequencies ω ∈Ω, are merely integer-valued multiples of
a “base frequency” {n1ω0, n2ω0, . . . }, the treatment is
still analogous to the integer case (see Appendix B). We
therefore focus much of our analysis on this case.
For both integer or non-integer frequencies, the expressivity of a quantum model is determined by two different properties: the frequency spectrum of the quantum model, including its size and degree, and the expressivity of the coeﬃcients controlled by the model. As
we will show in the next section, these two properties
give us insights into the function classes that diﬀerent
quantum models can learn.
THE EXPRESSIVITY OF QUANTUM
We proceed to use the Fourier series formalism to investigate the expressivity of quantum models. We start
with an analysis of the popular strategy of
using single-qubit Pauli rotations in the encoding subroutine S(x) in order to showcase the practical value
of the approach. We then characterise the limits of a
quantum model’s expressivity for a given data encoding
gate in more general terms.
A single Pauli-rotation encoding can only learn
a sine function
As a “warm-up” application of the Fourier series
formalism, we start by considering a simple quantum
model with L = 1, where we use a single-qubit gate
G(x) = e−ixH to encode the input x into the circuit (see
also Fig. 2a with L = 1),
U(x) = W (2)G(x)W (1).
As a single-qubit gate generator, H has two distinct
eigenvalues (λ1, λ2). We can without loss of generality
always rescale the energy spectrum to (−γ, γ) because
the global phase is unobservable. We note that the class
of such encoding gates includes Pauli rotations, with
H = (1/2)σ for σ ∈{σx, σy, σz}, for which γ = 1
aim to show that models of the type (13) always lead
to functions of the form f(x) = A sin(2γx + B) + C
where A, B, C are constants determined by the nonencoding part of the variational circuit, which reproduces the prior observation from . A sine function
can be described by a truncated Fourier series of degree
1 – and in the next section we will go on to show how
one can systematically increase the degree by repeating
the encoding gate.
First, since we can absorb the factor γ into the data
input by re-scaling it via ˜x = γx, we can assume without
loss of generality that the eigenvalues of H are always
λ1 = −1, λ2 = 1. From Eq. (10) we can immediately
see that the spectrum of the quantum model is given by
Ω= {−2, 0, 2} (since the possible diﬀerences λk1 −λj1
for λk1, λj1 ∈{−1, 1} are −1−(1), −1−(−1), 1−(1), and
1 −(−1)). The Fourier coeﬃcients in Eq. (12) become
Mii′(W ∗)(1)
12 (W ∗)(2)
Mii′(W ∗)(1)
11 (W ∗)(2)
and the quantum model’s frequency spectrum consists
of a single non-zero frequency:
f(x) = c−2ei2˜x + c0 + c2e−i2˜x
= c0 + 2|c2| cos(2˜x −arg(c2)),
A parametrised quantum model is trained with
data samples (white circles) to ﬁt a target function g(x) =
n=−1 cne−nix or g′(x) = P2
n=−2 cne−nix with coeﬃcients
c0 = 0.1, c1 = c2 = 0.15 −0.15i.
The variational circuit is of the form f(x) = ⟨0| U †(x)σzU(x) |0⟩where |0⟩
is a single qubit, and U
= W (2)Rx(x)W (1).
(round blue symbols) are implemented as general rotation
gates parametrised by three learnable weights each, and Rx
(square blue symbols) is a single Pauli-X rotation. The left
panels show the quantum model function f(x) and target
function g(x), g′(x), while the right panels show the mean
squared error between the data sampled from g and f during
a typical training run. Feeding in the input x as is (top row),
the quantum model easily ﬁts the target of degree 1. Rescaling the inputs x →2x causes a frequency mismatch, and
the model cannot learn the target any more (middle row).
However, even with the correct scaling, the variational circuit cannot ﬁt the target function of degree 2 (bottom row).
The experiments in this paper were all performed using the
PennyLane software library .
where arg(c2) is the complex phase of c2. For Pauli rotations, one has ˜x = γx = x
2, and we recover the result
of with A = 2|c2|, B = −π/2 −arg(c2), and C = c0.
Importantly, we have not assumed anything about the
number of qubits, the nature of the unitaries W, or the
measurement M.
This illustrates a key point of this
paper: even with the ability to implement very wide
and deep quantum circuits (which may even be classically intractable to simulate), the expressivity of the
corresponding quantum model is fundamentally limited
by the data encoding strategy.
To support this ﬁnding, Fig. 3 shows numerical evidence: encoding data via a Pauli-X rotation results in
a quantum model that can only learn to ﬁt a Fourier
series of a single frequency – and only if that frequency
is exactly matched by how the data is scaled.
Repeated Pauli encodings linearly extend the
frequency spectrum
Given the severe limitations exposed in the previous
section, a natural question is how we can extend the
accessible frequency spectrum of a quantum model. To
this end, we demonstrate in this section that by using
either single-layer models with L = 1 where the encoding gate is repeated r times in parallel (as per Fig. 2b),
or multi-layer models with L > 1 where the encoding
gate is eﬀectively repeated r = L times in series (as per
Fig. 2a), one can systematically increase the degree of
the truncated Fourier series to r. We note once again
that both of these techniques have been utilised in prior
practical applications , and as such the observations we make here oﬀer insight into the properties
of these models.
Firstly, let us consider the case of single-qubit Pauli
rotations repeated in parallel (Fig. 2b). This is a special
case of our base model in Eq. (3), with L = 1, and
S(x) = e−i x
2 σr ⊗. . . ⊗e−i x
where σj ∈{σx, σy, σz}. The fact that all rotation gates
commute (as they act on diﬀerent qubits) allows us to
diagonalise H by diagonalising each rotation gate individually. Doing this, we ﬁnd that
S(x) = Vre−i x
r ⊗. . . ⊗V1e−i x
:= V e−ixΣV †,
where σ(q)
is the (diagonal) r-qubit operator which acts
non-trivially, via σz, only on the q’th qubit. Performing
the calculation yields Σ = diag (λ1, . . . , λ2r), with the
r + 1 unique entries
2, p ∈{0, . . . , r},
which are all possible sums of r values ±1/2. According
to Eq. (10), the frequency spectrum for L = 1 contains
diﬀerences of any two of these eigenvalues, and we get
Ωpar = {λk1 −λj1| k1, j1 ∈{1, . . . , 2r}}
p, p′ ∈{0, . . . , r}}
= {p −p′ | p, p′ ∈{0, . . . , r}}
= {−r, −(r −1), . . . , 0, . . . , r −1, r}.
Hence, a univariate quantum model with r parallel
Pauli-rotation encodings can be expressed as a truncated Fourier series of degree r.
Interestingly, the same scaling eﬀect is achieved by a
single-qubit Pauli rotation encoding repeated layer-wise
(Fig. 2a). Consider the quantum model in Eqs. (3) and
(4), for L = r > 1 layers, where S(x) = exp(−i(x/2)σj)
is a single-qubit Pauli rotation (i.e. σj ∈{σx, σy, σz})
which acts on the same qubit in each layer. The circuit
in Eq. (4) becomes
U(x) = W (L+1)e−i x
2 σLW (L) . . . W (2)e−i x
2 σ1W (1).
Diagonalizing the Pauli rotations as before, then gives
us Σ = (1/2)σz for all encoding layers. The frequency
spectrum from Eq. (10) is a sum of 2r terms of value
Ωseq = {(λk1 + · · · + λkr) −(λj1 + · · · + λjr) |
k1, . . . , kr, j1, . . . , jr ∈{1, 2}}.
After a short calculation, one ﬁnds that Ωseq = Ωpar.
Again, a quantum model with r sequential repetitions
of the single-qubit Pauli encoding can be expressed as a
truncated Fourier series of degree r. The growth mechanism of a quantum model’s frequency spectrum via parallel and sequential repetitions of single-qubit Pauli encodings is numerically illustrated in Fig. 4.
Limits of expressivity
The representation of quantum models as Fouriertype sums immediately allows us to derive upper bounds
on the expressivity of such quantum models when using L repetitions of an encoding gate of dimension
d (which is at most the size of the overall Hilbert
Firstly, let us consider the maximum spectrum size K(L, d) of a quantum model, quantifying
the number of frequencies it can “support” or “has access to”.
Since the frequency spectrum is deﬁned as
Ω= {(λj1 + . . . λkL) −(λj1 + · · · + λkL)} (where the indices j1, . . . , jL, k1, . . . , kL run over all dimensions of the
encoding gate, from 1 to d), the frequencies are sums of
2L terms, each having d potential values. As a result,
they can at most realise d2L distinct values – irrespective
of whether the eigenvalues are real or integer-valued.
Since the size K counts the pairs −ω, ω ∈Ωas one and
excludes the “zero frequency”, we get
As an example, if data is encoded in a single-qubit encoding gate, we recover the result from the previous
sections where the model has degree 22
2 −1 = 1. Using
L diﬀerent encoding gates increases this to 22L
we have seen, further assumptions on the eigenvalues
allow us to make this bound a lot tighter; for example
when the L repetitions use the same single-qubit encoding gate, K = L.
An interesting question is whether there is a single
quantum gate which can encode data into a quantum
model that supports the frequency spectrum Ω∞=
Fitting a truncated Fourier series of degree 5,
n=−5 cne2inx with cn = 0.05−0.05i for n = 1, . . . , 5
and c0 = 0, using a quantum model that repeats the encoding r = 1, 3, 5 times in sequence (left) and in parallel (right).
Increasing r allows for closer and closer ﬁts until r = 5 ﬁts
the data almost perfectly in both cases - illustrating that
parallel and sequential repetitions of Pauli encodings extend
the Fourier spectrum in the same manner. All models were
trained with at most 200 steps of an Adam optimiser with
learning rate 0.3 and batch size 25. For the “parallel” simulations, the W are not arbitrary unitaries but implemented
by a smaller ansatz of three layers of parametrised rotations
as well as entangling CNOT gates, as per Ref. , which is
depicted by the hollow rounded gate symbols. The quantum
model still easily ﬁtted the target function, which suggests
that the results of this paper are of relevance for realistic
quantum models.
{−∞, . . . , −1, 0, 1, . . . , ∞} of a full Fourier series. The
answer is yes: the ubiquitous phase shifts in continuousvariable (CV) quantum systems, which correspond to a
free evolution of a harmonic oscillator, have the number
operator ˆn = diag(0, 1, 2, . . . ) as a generator.
While the frequency spectrum of a quantum model
can directly be derived from the input encoding gates,
the ﬂexibility in the coeﬃcients is a lot harder to investigate systematically (we will do so for special cases
in the universality proofs in Section III). In principle,
every block W (1), . . . , W (L+1), as well as the measurement observable, contribute to every Fourier coeﬃcient.
This means that only a few degrees of freedom in the
gates may change an exponentially large (or, in the
case of continuous-variable quantum computing, inﬁnite) amount of Fourier coeﬃcients.
However, these
Fourier coeﬃcients are not arbitrary, but functions of
the limited degrees of freedom of the quantum circuit,
and a quantum circuit of a certain structure may only
be able to realise a small subset of the entire set of all
possible Fourier coeﬃcients {cn}.
To arbitrarily control K + 1 complex Fourier coeﬃcients, we need at least
FIG. 5. Real and imaginary parts of the ﬁrst six Fourier coeﬃcients sampled from 100 randomly initialised L = 1 quantum
models. The models share the same encoding strategy of parallel Pauli-X rotations (square symbols) but vary in the ansatz
and number of layers for the trainable unitaries W. Circuit A uses an ansatz of trainable arbitrary single qubit rotations
and layer-dependent entangling structure proposed in and already used in Fig. 4, while Circuit B uses trainable Pauli-X
rotations with a simple entangling structure. The plots suggest that the “expressivity” of the trainable circuit block – here
represented by increasing the number of times l an ansatz is repeated – has little inﬂuence on the distribution of the Fourier
coeﬃcients, as opposed to the type of ansatz.
M ≥2K + 1 real degrees of freedom – in other words,
parameters θ = (θ1, . . . , θM) – in the quantum circuit.
As a special case, we saw that repeating a Pauli encoding L times supports a spectrum of size L, which means
that we need at least 2L degrees of freedom in the quantum circuit to control the Fourier coeﬃcients arbitrarily
– a scaling that is realistic for shallow circuits to “utilise
the full power” of the frequency spectrum.
While a systematic analysis of how a parametrised
ansatz for the trainable blocks W impacts the control
of a quantum model’s Fourier coeﬃcients exceeds the
scope of this paper, our simulations suggest that even
quantum models with shallow trainable circuit blocks
W give rise to rich subsets of Fourier coeﬃcients (see
Fig. 5). However, as the ﬁgure shows, an ansatz may
structurally set a certain Fourier coeﬃcient to zero. An
interesting further observation is that the variance of the
coeﬃcients decreases with higher orders.
Mathematically, this property stems from the fact that the number of terms in the sum of Eq. (12) tends to decrease
with larger frequencies, since there are fewer ways to
construct those frequencies by the diﬀerence Λj −Λk
of sums of encoding generator eigenvalues.
that the Fourier coeﬃcients of square-integrable functions show a similar behaviour, which contributes to the
convergence of such series.
QUANTUM MODELS ARE
ASYMPTOTICALLY UNIVERSAL
In the previous sections we have seen, at least for univariate functions, that certain quantum models can be
written as partial Fourier series, in which the accessible frequencies are fully determined by the spectra of
the Hamiltonians generating the data-encoding gates.
Additionally, by using Pauli rotations as an explicit example, we have shown that by repeating such encodings,
either in parallel (L = 1) or in series (L > 1), it is possible to realise a truncated Fourier series, with the number
of accessible frequencies determined by the number of
data-encoding gate repetitions. In light of these results,
it is clear that if we allow for suﬃciently many repetitions of simple data-encoding gates (such as Pauli rotations), or for Hamiltonians with large enough dimension and suitably non-degenerate spectra, then quantum
models can realise arbitrary frequency spectra.
However, as discussed in the previous section, the expressivity of a quantum model is determined not only
by the accessible frequency spectrum, but also by the
ﬂexibility one has in adjusting the contributions of the
frequencies, i.e., with which ﬂexibility the Fourier coeﬃcients can be chosen. In this section we show that
if one allows for trainable circuit blocks which are ﬂexible enough to realise arbitrary global unitaries, then
there exists an L = 1 quantum model which can realise
all possible sets of Fourier coeﬃcients. Combined with
the observations from the previous sections, this allows
us to show that such quantum models are asymptoti-
cally universal, in the sense that if we allow the global
Hilbert space dimension (or the number of ﬁnite dimensional subsystems) to tend to inﬁnity, then such a quantum model can approximate, to arbitrary accuracy, any
square-integrable function on a suitable domain.
More speciﬁcally, we consider the (multivariate) single layer quantum model fθ : RN →R deﬁned via
fθ(x) = ⟨0|U †(θ, x)MU(θ, x)|0⟩,
U(θ, x) = W (2)(θ(2))S(x)W (1)(θ(1)),
with θ(1), θ(2) ⊆θ and
S(x) := e−ix1H1 ⊗. . . ⊗e−ixNHN .
The above model is a natural extension of the univariate L = 1 model we explored in previous sections. In
Appendix A we show that it naturally realises a multivariate Fourier series, with the frequency spectrum fully
determined by the spectra of the data-encoding Hamiltonians {Hl}, and the Fourier coeﬃcients determined
by the remainder of the circuit.
It is important to emphasise that in practical applications one would typically consider trainable circuit
blocks whose circuit depth scales in a controlled way
with respect to the number of qubits in the circuit.
However, we will in this work assume that the trainable circuit blocks are suﬃciently ﬂexible to realise arbitrary global unitaries, which may require exponential
circuit depth when decomposed into natural primitive
gate sets.
Given this, the asymptotic universality of
quantum models with either constant, logarithmic or
polynomial circuit depth trainable blocks remains an
interesting open question.
With this assumption on the trainable circuit blocks,
we can drop the explicit dependence on θ, and by absorbing W (1) into the initial state |Γ⟩, and W (2) into the
observable M, consider instead the equivalent model
f(x) = ⟨Γ|S†(x)MS(x)|Γ⟩,
where the universality of W (1) and W (2) is reinterpreted
as the assumption that |Γ⟩can be an arbitrary state,
and M an arbitrary observable.
In order to simplify
things further, we will also make the additional assumption that all data-encoding Hamiltonians are equal – i.e.,
S(x) := e−ix1H ⊗. . . ⊗e−ixNH
We are interested in a reasonable notion of universality in the asymptotic regime of inﬁnitely many available
subsystems. To formalise this, we introduce the concept
of a Hamiltonian family {Hm | m ∈N} where Hm acts
on m subsystems of dimension d. An explicit example
FIG. 6. Multivariate L = 1 quantum model considered for
the universality theorem.
Here, S(x) consists of featureencoding gates acting on diﬀerent subsystems (green boxes).
The Hamiltonians that generate these gates are deﬁned to
increase the “richness” of their spectrum with growing dimension of the subsystems (red arrows). Since we assume
that the circuit depth and structure of the trainable unitaries W (1) and W (2) is suﬃcient to allow for the realisation
of arbitrary unitary operations, the trainable circuits grow
in dimension along with the total system size.
of such a family is a simple tensor product of Pauli rotations, as studied in Section II B, which corresponds to
the Hamiltonian
As illustrated in Fig. 6, such a Hamiltonian family de-
ﬁnes a family of models {fm} via
fm(x) = ⟨Γ|S†
Hm(x)MSHm(x)|Γ⟩,
where for each m, the measurement M and the state
|Γ⟩(or equivalently the unitaries W (1) and W (2)) are
the learnable elements of the model.
Now, given some Hamiltonian Hm with eigenvalues
{λ1, . . . , λdm}, we call
ΩHm = {λj −λk | j, k ∈{1, . . . , dm}}
the frequency spectrum associated with Hm. To achieve
universality, we need a Hamiltonian family whose frequency spectrum asymptotically contains any integer
frequency. We formalise this via the following notion:
a Hamiltonian family {Hm} is a universal Hamiltonian
family if it has the property that for all K ∈N there
exists some m ∈N such that
ZK = {−K, . . . , 0, . . . , K} ⊆ΩHm.
As we have seen in the previous section, the Hamiltonian family deﬁned by the Hamiltonians in Eq. (34)
is indeed a universal Hamiltonian family, with m = K.
As the possible number of frequencies grows exponentially, one could think of more complicated Hamiltonian
families in which the required number of available subsystems only grows logarithmically m = O(log K), at
the cost of more complicated, global Hamiltonian terms.
With this setup, we can now state the following universality result:
Theorem. Let {Hm} be a universal Hamiltonian family, and {fm} the associated quantum model family, de-
ﬁned via Eq. (35). For all functions g ∈L2([0, 2π]N),
and for all ϵ > 0, there exists some m′ ∈N, some state
, and some observable M such that
||fm′ −g||2 ≤ϵ.
A full proof is given in Appendix C, however in the
following we will provide a sketch of the proof in order
to give an outline of the ideas and techniques. The proof
begins by noting that any square-integrable function g
on a ﬁnite interval can be approximated by a truncated
Fourier series to arbitrary precision. We therefore reduce the task to ﬁnding a quantum model for this truncated Fourier series. The universality property of the
Hamiltonian family implies that the multivariate models we consider can express all necessary frequencies to
perform that approximation. We then show how to use
the freedom in choosing the initial state and the observable to reproduce the truncated Fourier series of g exactly, leading to an approximation by a quantum model
with arbitrary precision.
Note that the statement that there exists some state
|Γ⟩and some observable M is equivalent to the statement that the target function can be learned by the relevant model (under the assumption the trainable circuit
blocks are suﬃciently ﬂexible). As any frequency spectrum is asymptotically accessible, due to the assumption
of a universal Hamiltonian family, the universality theorem is essentially equivalent to the statement that with
suﬃciently ﬂexible circuit blocks such quantum models
can realise any set of Fourier coeﬃcients.
PRACTICAL IMPLICATIONS FOR
QUANTUM MACHINE LEARNING
In this last section, we discuss the scope and practical
relevance of our results for quantum machine learning.
First, we motivate that many quantum models proposed
in the literature that do not immediately ﬁt the base
model from Eq.
(3) can still be analysed within our
framework under the assumption that they encode classically pre-processed features φ(x) instead of the original features x. Second, we summarise guidelines that
can help with the design of quantum machine learning
algorithms.
Classical pre-processing
The base model used in this paper makes the assumption that a data feature is encoded into a subroutine
S(x) which consists of gates G(x) = e−ixH. We motivate in this section that many quantum machine learning algorithms which use other strategies of data encoding actually perform an implicit pre-processing of the
data, and then use the “time-evolution” encoding studied here. The results of this paper are hence valid for
the new features resulting from the pre-processing step.
For example, the standard encoding procedure of
traditional (and some NISQ ) quantum algorithms, associates the n-bit binary representation of
each (scalar) input feature x with an n-qubit basis state,
such as x 7→|01011⟩.
The pre-processing step therefore maps original features x to the angles φ(x) =
(φ1(x), . . . , φn(x)) with which the n qubits have to be
rotated to reﬂect every binary decimal digit of x (i.e.,
π for |1⟩or 0 for |0⟩).
Our investigation here states
that the quantum model for a single input feature corresponds to a multi-dimensional Fourier series in the
angles, with a frequency spectrum size of at most n. In
other words, the pre-processing changed the accessible
Fourier spectrum by changing the features.
Another example is so-called “amplitude encoding”
(i.e., ), which associates an input vector x with
the values of the amplitudes of a quantum state. Practically, this requires S(x) to be an arbitrary state preparation routine that is parametrised by some angles computed from x.
The classical pre-processing therefore
maps the original input to the set of angles used in the
state preparation, x 7→φ(x).
Pre-processing is also sometimes used in encoding
strategies that directly feed input features into Pauli
rotations.
One example was used in Figs. 3 and 4,
where we re-scaled the inputs by a classical hyperparameter.
In Ref. it has been proposed to make
these hyperparameters trainable (which in the light of
the present analysis would allow for an adaptive “frequency matching” and may help to increase the expressivity of small quantum circuits). Another example is to construct higher-order features that are arithmetic combinations of the original inputs, like φ1(x) =
x1x2, φ2(x) = x2x3, . . . , as used in the quantum feature
map proposed in Ref. .
These examples suggest that implicit pre-processing
can extend the function classes that quantum models
can learn even further. However, care needs to be taken
when making theoretical claims about the power of a
quantum machine learning algorithm, which is, strictly
speaking, a result of the quantum algorithm plus the
speciﬁc pre-processing strategy. In particular, comparisons to classical machine learning models should identify the pre-processing strategy and consider feeding the
same pre-processed features to the classical model.
Practical insights
Finally, we want to summarise how the results of this
paper can be used to understand and evaluate diﬀerent
design decisions of quantum machine learning models:
If data is encoded via a Hamiltonian time evolution, we can naturally describe the class of functions
that quantum models can learn as partial Fourier series.
The Hamiltonian deﬁnes the available frequencies in the
series, and the gates that do not encode data deﬁne the
Fourier coeﬃcients.
If data is encoded into single-qubit Pauli rotations, the number of rotations used limits the number
of frequencies that the model has access to.
Repeating an encoding gate can help to increase the frequency
spectrum, and thereby the expressivity of a quantum
Quantum models naturally learn periodic functions in the data. One should therefore consider appropriate data re-scaling strategies, to make sure the data
lies within the period of the function class. The natural representation of quantum models as Fourier series
may suggest that time-series learning and signal processing tasks are particularly suitable applications for
quantum machine learning. It may also hint at inherent
regularising properties of quantum models that exclude
higher-order Fourier frequencies.
Classical pre-processing of the data, such as creating more features, can give small models more expressivity by enriching the frequency spectrum.
Adjusting the entries of the observable freely was
a key ingredient in proving universality of quantum circuits in Section III. Fixing the observable in a quantum
model therefore limits its applicability. This fact suggests that parametrising the observable itself may be a
key ingredient for ﬂexible quantum models.
Ideally, one would hope that our results could provide concrete guidelines for the design of quantum machine learning models.
However, in practical settings
the process of model selection should be guided not
purely by model expressivity, but rather through the
expected generalisation performance of the model function class, as captured by capacity metrics such as the
VC-dimension or Rademacher complexity . While
such capacities can be calculated for very simple function classes, calculating such metrics for more complex
model classes, such as the quantum models studied
here, is signiﬁcantly harder.
Additionally, in modern
over-parametrised models, which can often ﬁt even randomised training data perfectly , more sophisticated
approaches are necessary to understand generalisation
capacity . In light of this, the insights on how to
make models more expressive should not be misinterpreted as recommendations for how to design good quantum models – a question which is much more complex
and whose answer depends strongly on the context.
CONCLUSION
In this work we presented a systematic mapping between a large class of quantum machine learning models and partial Fourier series, which has allowed us to
explore and quantify the eﬀect of commonly used dataencoding mechanisms on the expressivity of these quantum models. We believe that this framework both lays a
foundation for further theoretical analysis, and can serve
as a useful guide in the search for suitable applications
of such models. Additionally, this work provides a connection between quantum machine learning and ideas
from the classical machine learning literature, such as
neural networks with periodic activation functions ,
and parametrised Fourier series as an alternative to neural networks .
As mentioned throughout the paper, a variety of interesting questions remain. Firstly, can the framework
developed here help us to understand and quantify the
generalisation capacity of quantum models, and therefore guide model selection in a meaningful way? In particular, by using the representation of a quantum model
as a partial Fourier series, can one calculate meaningful modern generalisation measures and use these
for the development of model-selection guidelines? Secondly, we have proven our universality result under the
assumption of exponential depth trainable circuit blocks
(which provides a reasonable notion of asymptotic universality with respect to circuit depth).
In practical
settings however one is interested in trainable circuit
blocks with depth restrictions. Can one prove universality of such quantum models with either constant, logarithmic or polynomial depth trainable circuit blocks?
In order to answer this question our toolbox needs to
be developed further to understand how the structure
of the trainable circuit blocks inﬂuences the set of accessible Fourier coeﬃcients. Finally, it is currently unclear
for which concrete applications quantum models may
be naturally suited, or oﬀer any sort of advantage over
classical techniques, such as neural networks. Another
question is therefore whether one can use knowledge of
the function class expressed by quantum models, as developed in this work, to suggest natural applications for
quantum machine learning.
Code to reproduce the ﬁgures and explore further
settings can be found in the following GitHub repository:
 
power_of_quantum_models.
ACKNOWLEDGEMENTS
MS wants to thank Nathan Killoran, Nicolas Quesada
and Josh Izaac for helpful discussions.
RS and JJM
acknowledge funding from the BMWi under the PlanQK
initiative. The authors endorse Scientiﬁc CO2nduct 
and provide a CO2 emission table in Appendix D.
 Jarrod R McClean, Jonathan Romero, Ryan Babbush,
and Al´an Aspuru-Guzik, “The theory of variational
hybrid quantum-classical algorithms,” New Journal of
Physics 18, 023023 .
 Jonathan Romero and Alan Aspuru-Guzik, “Variational
quantum generators: Generative adversarial quantum
machine learning for continuous distributions,” arXiv
 
 Kosuke Mitarai, Makoto Negoro, Masahiro Kitagawa,
and Keisuke Fujii, “Quantum circuit learning,” Physical
Review A 98, 032309 .
 Edward Farhi and Hartmut Neven, “Classiﬁcation with
quantum neural networks on near term processors,”
arXiv preprint arXiv:1802.06002 .
 Jarrod R McClean, Sergio Boixo, Vadim N Smelyanskiy,
Ryan Babbush, and Hartmut Neven, “Barren plateaus
in quantum neural network training landscapes,” Nature Communications 9, 1–6 .
 Marcello Benedetti, Erika Lloyd, Stefan Sack, and Mattia Fiorentini, “Parameterized quantum circuits as machine learning models,” Quantum Science and Technology 4, 043001 .
 Mateusz Ostaszewski, Edward Grant,
and Marcello
Benedetti, “Quantum circuit structure learning,” arXiv
 
 James Stokes,
Josh Izaac,
Nathan Killoran,
Giuseppe Carleo, “Quantum natural gradient,” Quantum 4, 269 .
 Guillaume Verdon, Jacob Marks, Sasha Nanda, Stefan
Leichenauer, and Jack Hidary, “Quantum hamiltonianbased models and the variational quantum thermalizer
algorithm,” , arXiv:1910.02071 [quant-ph].
 Guillaume Verdon, Trevor McCourt, Enxhell Luzhnica, Vikash Singh, Stefan Leichenauer,
Hidary, “Quantum graph neural networks,”
 
 Iris Cong, Soonwon Choi, and Mikhail D Lukin, “Quantum convolutional neural networks,” Nature Physics 15,
1273–1278 .
 Jin-Guo Liu and Lei Wang, “Diﬀerentiable learning of
quantum circuit born machines,” Physical Review A 98,
062324 .
 Aram Harrow and John Napp, “Low-depth gradient
measurements can improve convergence in variational
hybrid quantum-classical algorithms,” arXiv preprint
 
 Carlo Ciliberto, Andrea Rocchetto, Alessandro Rudi,
and Leonard Wossnig, “Fast quantum learning with
statistical guarantees,” arXiv preprint arXiv:2001.10477
 M. Cerezo, Akira Sone, Tyler Volkoﬀ, Lukasz Cincio,
and Patrick J. Coles, “Cost-function-dependent barren
plateaus in shallow quantum neural networks,” ,
 
 Lennart Carleson, “On convergence and growth of partial sums of Fourier series,” Acta Mathematica 116,
135–157 .
 Adri´an P´erez-Salinas, Alba Cervera-Lierta, Elies Gil-
and Jos´e I Latorre, “Data re-uploading for a
universal quantum classiﬁer,” Quantum 4, 226 .
 Nathan Killoran, Thomas R Bromley, Juan Miguel Arrazola, Maria Schuld, Nicol´as Quesada, and Seth Lloyd,
“Continuous-variable quantum neural networks,” Physical Review Research 1, 033063 .
 Sukin Sim, Peter D Johnson, and Al´an Aspuru-Guzik,
“Expressibility and entangling capability of parameterized quantum circuits for hybrid quantum-classical algorithms,” Advanced Quantum Technologies 2, 1900070
 Hongxiang Chen, Leonard Wossnig, Simone Severini,
Hartmut Neven, and Masoud Mohseni, “Universal discriminative quantum neural networks,” arXiv preprint
 
 Yuxuan Du, Min-Hsiu Hsieh, Tongliang Liu,
Dacheng Tao, “The expressive power of parameterized
quantum circuits,” arXiv preprint arXiv:1810.11922
 Jacob Biamonte, “Universal variational quantum computation,” arXiv preprint arXiv:1903.04500 .
 Matthias C Caro and Ishaun Datta, “Pseudo-dimension
of quantum circuits,” arXiv preprint arXiv:2002.01490
 Maria Schuld and Nathan Killoran, “Quantum machine
learning in feature Hilbert spaces,” Physical Review
Letters 122, 040504 .
 Vojtˇech Havl´ıˇcek, Antonio D C´orcoles, Kristan Temme,
Aram W Harrow, Abhinav Kandala, Jerry M Chow,
“Supervised
quantum-enhanced feature spaces,” Nature 567, 209–
212 .
 Ryan LaRose and Brian Coyle, “Robust data encodings
classiﬁers,”
 
 Seth Lloyd, Maria Schuld, Aroosa Ijaz, Josh Izaac, and
Nathan Killoran, “Quantum embeddings for machine
learning,” arXiv preprint arXiv:2001.03622 .
 Francisco Javier Gil Vidal and Dirk Oliver Theis, “Input redundancy for parameterized quantum circuits,”
Frontiers in Physics 8, 297 .
 Patrick Rebentrost, Masoud Mohseni, and Seth Lloyd,
“Quantum support vector machine for big data classiﬁcation,” Physical Review Letters 113, 130503 .
 Maria Schuld, Alex Bocharov, Krysta M Svore,
Nathan Wiebe, “Circuit-centric quantum classiﬁers,”
Physical Review A 101, 032308 .
 Thomas Hubregtsen, Josef Pichlmeier, and Koen Bertels, “Evaluation of parameterized quantum circuits: on
the design, and the relation between classiﬁcation accuracy, expressibility and entangling capability,” arXiv
 
 Naoko Koide-Majima and Kei Majima, “Quantum
circuit-like
classical machine-learning algorithm with similar performance to quantum circuit learning,” arXiv preprint
 
 Masaya Watabe, Kodai Shiba, Masaru Sogabe, Katsuyoshi Sakamoto,
and Tomah Sogabe, “Quantum
circuit parameters learning with gradient descent using backpropagation,” arXiv preprint arXiv:1910.14266
 Carsten
and Francesco Petruccione, “Quantum classiﬁer with tailored quantum kernel,” arXiv preprint
 
 Jian Zhao, Yuan-Hang Zhang, Chang-Peng Shao, Yu-
Chun Wu, Guang-Can Guo,
and Guo-Ping Guo,
“Building quantum neural networks based on a SWAP
test,” Physical Review A 100, 012334 .
 Ville Bergholm,
Josh Izaac,
Maria Schuld,
Christian Gogolin, M. Sohaib Alam, Shahnawaz Ahmed,
Juan Miguel Arrazola, Carsten Blank, Alain Delgado,
Soran Jahangiri, Keri McKiernan, Johannes Jakob
Meyer, Zeyue Niu, Antal Sz´ava,
and Nathan Killoran, “PennyLane:
Automatic diﬀerentiation of hybrid quantum-classical computations,” arXiv preprint
 
 Michael A Nielsen and Isaac Chuang, “Quantum computation and quantum information,” .
 Shai Shalev-Shwartz and Shai Ben-David, Understanding machine learning: From theory to algorithms .
 Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals, “Understanding deep
learning requires rethinking generalization,”
 
 Yiding Jiang, Behnam Neyshabur, Hossein Mobahi,
Dilip Krishnan,
and Samy Bengio, “Fantastic generalization measures and where to ﬁnd them,”
 
 Vincent Sitzmann, Julien NP Martel, Alexander W
Bergman, David B Lindell,
and Gordon Wetzstein,
“Implicit neural representations with periodic activation
functions,”
 
 Abylay Zhumekenov, Malika Uteuliyeva, Olzhas Kabdolov, Rustem Takhanov, Zhenisbek Assylbekov,
Alejandro J Castro, “Fourier neural networks:
comparative study,” arXiv preprint arXiv:1902.03011
 Sander Wahls, Visa Koivunen, H Vincent Poor,
Michel Verhaegen, “Learning multidimensional fourier
series with tensor trains,” in 2014 IEEE Global Conference on Signal and Information Processing (GlobalSIP)
 pp. 394–398.
 “Scientiﬁc co2nduct,” online.
 Ferenc
“Summability
multi-dimensional
trigonometric fourier series,”
 , arXiv:1206.1789
[math.CA].
Appendix A: Partial Fourier Series Representation of Multivariate Functions
In this section we show how a certain class of L = 1 quantum models naturally realise multivariate Fourier
series. On the one hand, this shows a way in which the univariate case analysed in the paper can easily generalise
to multivariate models by encoding the features into diﬀerent quantum subsystems.
On the other hand, the
multivariate model described in this section is a quantum model whose asymptotic universality is stated and
discussed in Section III, and proven in Appendix C.
More speciﬁcally, we consider a quantum model of the form
f(x) = ⟨0|
(W (1))†S†(x)(W (2))†
W (2)S(x)W (1)
S(x) := e−ix1H1 ⊗. . . ⊗e−ixNHN .
Without loss of generality, instead of explicitly considering arbitrary unitaries W (1) and W (2), we can “absorb” the
unitaries into the initial state and measurement and consider the equivalent model
f(x) = ⟨Γ|S†(x)MS(x)|Γ⟩,
j1,...,jN=1
γj1,...,jN |j1⟩⊗. . . ⊗|jN⟩
is some arbitrary state, and M is some arbitrary observable. To simplify the index handling, we introduce the
multi-indices j ∈[2d]N with which we can rewrite
Additionally, as argued before we can without loss of generality assume that all Hamiltonians are diagonal, i.e.,
Hk = diag(λ(k)
1 , . . . , λ(k)
With this assumption, we note that S(x) is diagonal with entries
[S(x)]j,j = e−ix·λj,
where we have deﬁned
λj = (λ(1)
j1 , . . . , λ(N)
Given this, we see that
j γk[S†(x)MS(x)]j,k
j γkMj,keix·(λk−λj),
which is indeed a partial multivariate Fourier series, with the accessible frequencies fully determined by the spectra of
the encoding Hamiltonians {Hk}, and the Fourier coeﬃcients determined by the trainable unitaries (or equivalently,
the state and observable).
Appendix B: Non-integer frequencies
In the main text, we put our focus on quantum models with integer-valued frequency spectra, as they naturally
arise when using Pauli rotation gates and allow for analysis with the techniques of Fourier series. Here we will
brieﬂy discuss why many quantum models with non-integer-valued frequency spectra can be treated similarly.
First, note that we can always decompose functions of the form eiωx into a Fourier series of integer-valued
frequencies, i.e.,
(−1)n sin ωπ
sinc(ω −n)einx,
with sinc(z) = sin(πz)/πz. However, as we can see from this expression, any non-integer frequency in general
“contributes” to inﬁnitely many Fourier coeﬃcients. It turns out that a rather general case of quantum models
with non-integer frequencies can be handled equivalently, namely if the frequencies are integer multiples of some
basic frequency ω0,
Ω= {0, ±n1ω0, ±n2ω0, . . . }.
This condition is equivalent to all frequencies in Ωbeing mutually commensurable, i.e., the ratio of any two
frequencies is a rational number. This is the case in many natural settings, for example if encodings with noninteger frequencies are repeated in parallel alike to the Pauli encodings in Section II.
Basis functions of the form eixnω0 are periodic functions on the interval [0, 2π/ω0]. This means that the generated
Fourier-type sum in Eq. (11) can be understood like the partial Fourier series in Eq. (5), but on a diﬀerent interval.
Alternatively, one can imagine re-scaling the data by ˜x = x/ω0, with which
ω0 ω = ei˜xn.
While this strategy could in principle be applied to any frequency spectrum where the frequencies are mutually
commensurable, one has to be aware that ω0 is as least as small as the smallest diﬀerence between frequencies in
Ω. If very close frequencies are present in the spectrum, the data will have to be re-scaled by a very large factor to
an interval where the generated Fourier coeﬃcients may be sparse and the approximation quality poor.
Appendix C: Proof of the universality theorem
We provide in this section a proof of the universality theorem stated in Section III, which we restate for completeness:
Theorem. Let {Hm} be a universal Hamiltonian family, and {fm} the associated quantum model family, deﬁned
via Eq. (35). For all functions g ∈L2([0, 2π]N), and for all ϵ > 0, there exists some m′ ∈N, some state |Γ⟩∈Cdm′
and some observable M such that
||fm′ −g||2 ≤ϵ.
Proof. To begin with, we note that we can approximate any given g ∈L2([0, 2π]N), up to an arbitrarily small error
in L2 norm, by using a truncated Fourier series . More speciﬁcally, for any given ϵ > 0, there exists some K ∈N
and some set of coeﬃcients {cn | n ∈ZN
K}, with cn = c∗
−n, such that
||˜g −g|| ≤ϵ.
In order to prove the theorem we therefore only need to show that there exists an m′ ∈N, some state |Γ⟩and some
observable M so that the associated quantum model fm′ generates the Fourier series ˜g. Recall that the quantum
model was deﬁned as
fm(x) = ⟨Γ|S†
Hm(x)MSHm(x)|Γ⟩,
SHm(x) := e−ix1Hm ⊗. . . ⊗e−ixNHm.
In Appendix A, we have seen that we can express the output of the model as
j γkMj,keix·(λk−λj),
where the multi-indices j and k have N entries that iterate over all 2d basis states of the d qubit subsystems. Let
ΩHm be the frequency spectrum of Hm, as deﬁned in Eq. (36). As the {Hm} form a universal family of Hamiltonians
by assumption, we can choose an m′ ∈N so that
ZK = {−K, . . . , 0, . . . , K} ⊆ΩHm′.
The accessible frequency vectors λj −λk independently contain all possible combinations of the frequencies in ΩHm′.
The vector-valued frequency spectrum for the multivariate case is therefore the Cartesian product of N copies of
Ω= ΩHm′ × · · · × ΩHm′
As ZK ⊆ΩHm′ we naturally have that ZN
K ⊆Ω, which means that the Fourier series generated by the chosen model
contains all terms that are necessary to construct the Fourier series ˜g.
We can now revisit Eq. (C7) and show that we can leverage the freedom of choosing both the initial state |Γ⟩
and the observable M arbitrarily to adjust all terms in the sum of Eq. (C7) freely up to the complex-conjugation
symmetry that guarantees that the model output is a real-valued function. To this end, we ﬁrst observe that an
exchange of the multi-indices j and k yields the complex conjugate of the original term:
j γkMj,keix·(λk−λj)i∗
j,keix·(λj−λk)
kγjMk,je−ix·(λk−λj).
Other than that, the coeﬃcients can be freely chosen. To this end, we ﬁx our initial state as the equal superposition
state which can be prepared by applying a Hadamard gate to every qubit in the system. This gives γj = 1/
and results in the model
fm′(x) = 2−Nd X
Mj,keix·(λk−λj).
With this choice, we see that the coeﬃcients are directly proportional to the diﬀerent entries of the observable M.
Recall that our initial goal was to construct the Fourier series ˜g with coeﬃcients {cn} where n ∈ZN
K. We already
argued that all those are accessible in the frequency spectrum of our model because of the universal nature of the
Hamiltonian family {Hm}. As any frequency corresponds to one or more pairings of multi-indices j and k, we can
always select a set of these multi-indices such that it is in one to one correspondence with the frequencies present
in the Fourier series ˜g:
I = {(j, k) ∈[2d]N × [2d]N | for all n ∈ZN
K there is exactly one pair (j, k) so that λj −λk = n}.
With this it is now straightforward to use the freedom to choose our observable to ﬁx fm′ = ˜g by choosing the
diagonal and upper-triangular elements of M via
2Ndcn if λj −λk = n and (j, k) ∈I
0 otherwise
after which the lower-triangular elements are ﬁxed by the constraint that the observable is Hermitian.
Appendix D: CO2 Emission Table
Numerical simulations
Total Kernel Hours [h]
Thermal Design Power Per Kernel [W]
Total Energy Consumption Simulations [kWh]
Average Emission Of CO2 In South Africa [kg/kWh] ≈1.5
Total CO2 Emission For Numerical Simulations [kg]
Total CO2 Emission For Transport [kg]
Total CO2 Emission [kg]
Were The Emissions Oﬀset?