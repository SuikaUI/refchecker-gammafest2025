SIAM REVIEW
Vol. 38, No. 3, pp. 367-426, September 1996
() 1996 Society for Industrial and Applied Mathematics
ON PROJECTION ALGORITHMS FOR SOLVING CONVEX
FEASIBILITY PROBLEMS*
HEINZ H. BAUSCHKEt AND JONATHAN M. BORWEINt
Abstract. Due to their extraordinary utility and broad applicability in many areas of classical mathematics and
modem physical sciences (most notably, computerized tomography), algorithms for solving convex feasibility problems continue to receive great attention. To unify, generalize, and review some of these algorithms, a very broad and
flexible framework is investigated. Several crucial new concepts which allow a systematic discussion of questions on
behaviour in general Hilbert spaces and on the quality ofconvergence are brought out. Numerous examples are given.
Key words, angle between two subspaces, averaged mapping, Cimmino’s method, computerized tomography,
convex feasibility problem, convex function, convex inequalities, convex programming, convex set, Fej6r monotone
sequence, firmly nonexpansive mapping, Hilbert space, image recovery, iterative method, Kaczmarz’s method, linear
convergence, linear feasibility problem, linear inequalities, nonexpansive mapping, orthogonal projection, projection
algorithm, projection method, Slater point, subdifferential, subgradient, subgradient algorithm, successive projections
AMS subject classifications. 47H09, 49M45, 65-02, 65J05, 90C25
1. Introduction, preliminaries, and notation. A very common problem in diverse areas
of mathematics and physical sciences consists of trying to find a point in the intersection
of convex sets.
This problem is referred to as the convex feasibility problem; its precise
mathematical formulation is as follows.
Suppose X is a Hilbert space and C1
CN are closed convex subsets
with nonempty intersection C:
C10’’’("ICN
Convexfeasibility problem:
Find some point x in C.
We distinguish two major types.
1. The set Ci is "simple" in the sense that the projection (i.e., the nearest point mapping)
onto Ci can be calculated explicitly; Ci might be a hyperplane or a halfspace.
2. It is not possible to obtain the projection onto Ci; however, it is at least possible to
describe the projection onto some approximating superset of Ci. (There is always a trivial
approximating superset of Ci, namely, X.) Typically, Ci is a lower level set of some convex
One frequently employed approach in solving the convex feasibility problem is algorithmic. The idea is to involve the projections onto each set Ci (resp., onto a superset of Ci) to
generate a sequence ofpoints that is supposed to converge to a solution ofthe convex feasibility
problem. This is the approach we will investigate. We are aware of four distinct (although
intertwining) branches, which we classify by their applications.
I. Best approximation theory.
Properties: Each set Ci is a closed subspace. The algorithmic scheme is simple
("cyclic" control).
Basic results: yon Neumann
103, Thin. 13.7], Halperin .
Comments: The generated sequence converges in norm to the point in C that is closest
to the starting point. Quality of convergence is well understood.
References: Deutsch .
*Received by the editors July 7, 1993; accepted for publication (in revised form) June 19, 1995. This research
was supported by NSERC and by the Shrum Endowment.
Department of Mathematics and Statistics, Simon Fraser University, Burnaby, British Columbia, Canada V5A
$6 ( and jborwein@cecm,sfu.ca).
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
Areas ofapplication: Diverse. Statistics (linear prediction theory), partial differential
equations (Dirichlet problem), and complex analysis (Bergman kernels, conformal
mappings), to name only a few.
II. Image reconstruction: Discrete models.
Properties: Each set Ci is a halfspace or a hyperplane. X is a Euclidean space (i.e.,
a finite-dimensional Hilbert space). Very flexible algorithmic schemes.
Basic results: Kaczmarz , Cimmino , Agmon , Motzkin and Schoenberg .
Comments: Behaviour in general Hilbert space and quality of convergence only partially understood.
References:
Censor , Censor and Herman , Viergever ,
Sezan .
Areas of application: Medical imaging and radiation therapy treatment planning
(computerized tomography), electron microscopy.
III. Image reconstruction: Continuous models.
Properties: X is usually an infinite-dimensional Hilbert space. Fairly simple algorithmic schemes.
Basic results: Gubin, Polyak, and Raik .
Comments: Quality of convergence is fairly well understood.
References: Herman , Youla and Webb , Stark .
Areas ofapplication: Computerized tomography, signal processing.
IV. Subgradient algorithms.
Properties: Some sets Ci are of type 2. Fairly simple algorithmic schemes ("cyclic"
or "weighted" control).
Basic results: Eremin , Polyak , Censor and Lent .
Comments: Quality of convergence is fairly well understood.
References: Censor , Shor .
Areas ofapplication: Solution of convex inequalities, minimization of convex nonsmooth functions.
To improve, unify, and review algorithms for these branches, we must study a flexible
algorithmic scheme in general Hilbert space and be able to draw conclusions on the quality
ofconvergence. This is our objective in this paper.
We will analyze algorithms in a very broad and adaptive framework that is essentially
due to Flgtm and Zowe . (Related frameworks with somewhat different ambitions were
investigated by Browder and Schott .) The algorithmic scheme is as follows.
Given the current iterate X (n), the next iterate xn+) is obtained by
where every Pi
(n) is the projection onto some approximating superset C
n) of Ci, every 0
a relaxation parameter between 0 and 2, and the )}n),s are nonnegative weights summing up
to 1. In short, xn+l is a weighted average of relaxed projections ofxn.
Censor and Herman expressly suggested the study of a (slightly) restricted version of
(.) in the context of computerized tomography. It is worthwhile to point out that the scheme
(.) can be thought of as a combination of the schemes investigated by Aharoni, Berman, and
Censor and Aharoni and Censor . In Euclidean spaces, norm convergence results were
obtained by Flm and Zowe for (,) and by Aharoni and Censor for the restricted version.
However, neither behaviour in general Hilbert spaces nor quality of convergence has been
much discussed so far. To do this comprehensively and clearly, it is important to bring out
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
some underlying recurring concepts. We feel these concepts lie at the heart ofmany algorithms
and will be useful for other researchers as well.
The paper is organized as follows.
In 2, the two important concepts of attracting mappings and Fejr monotone sequences
are investigated.
The former concept captures essential properties of the operator A(n),
whereas the latter deals with inherent qualities of the sequence (xn).
The idea of afocusing algorithm is introduced in 3. The very broad class of focusing
algorithms admits results on convergence. In addition, the well-known ideas of cyclic and
weighted control are subsumed under the notion of intermittent control. Weak topology results
on intermittent focusing algorithms are given. We actually study a more general form of the
iteration (.) without extra work; as a by-product, we obtain a recent result by Tseng 100] and
make connections with work by Browder and Baillon .
At the start of 4, we exclusively consider algorithms such as (.), which we name projection algorithms. Prototypes of focusing and linearlyfocusing (a stronger, more quantitative
version) projection algorithms are presented. When specialized to Euclidean spaces, our
analysis yields basic results by Flm and Zowe and Aharoni and Censor .
The fifth section discusses norm and particularly linear convergence. Many known sufficient sometimes ostensibly different looking conditions for linear convergence can be thought
of as special instances of a single new geometric concept--regularity.
Here the N-tuple
Cv) is called regular if"closeness to all sets Ci implies closeness to their intersection
C." Four quantitative versions of (bounded) (linear) regularity are described. Having gotten
all the crucial concepts together, we deduce our main results, one of which states in short that
linearly focusing projection algorithm
intermittent control
imply linear convergence.
"nice" relaxation parameters and weights
Cv) boundedly linearly regular
This section ends with results on (bounded) (linear) regularity, including a characterization of
regular N-tuples of closed subspaces.
Section 6 contains a multitude of examples of algorithms from branches I, II, and III.
The final section examines the subgradient algorithms ofbranch IV, to which our previous
results also apply. Thus, a well-known Slater point condition emerges as a sufficient condition
for a subgradient algorithm to be linearly focusing, thus yielding a conceptionally simple
proof of an important result by De Pierro and Iusem . It is very satisfactory that analogous
results are obtained for algorithms suggested by Dos Santos and Yang and Murty
For the reader’s convenience, an index is included.
We conclude this section with a collection of frequently-used facts, definitions, and notation.
The "stage" throughout this paper is a real Hilbert space X; its unit ball {x
is denoted Bx.
FACTS 1.1.
(i) (parallelogram law) If x, y
IIx + Yll a + IIx
2(llxll a + IlYlla).
(ii) (strict convexity) If x, y
Ilxll + IlYll
(iii) Every bounded sequence in X possesses a weakly convergent subsequence.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
(i) is easy to verify and implies (ii).
(iii) follows from the Eberlein-,mulian
theorem (see, for example, Holmes [67,
All "actors" turn out to be members of the distinguished class of nonexpansive mappings.
A mapping T
D ----+ X, where the domain D is a closed convex nonempty subset of X, is
called nonexpansive if
for all x, y 6 D.
YlI, for all x, y 6 D, then we say T is an isometry. In contrast, if
Tyll < IIx
y ll, for all distinct x, y 6 D, then we speak of a strictly nonexpansive
mapping. If T is a nonexpansive mapping, then the set of all fixed points Fix T, which is
defined by
is always closed and convex [58, Lem. 3.4].
FACT 1.2 (demiclosedness principle). If D is a closed convex subset of X, T
D -----+ X
is nonexpansive, (xn) is a sequence in D, and x 6 D, then
x 6 Fix T,
where, by convention, "--+" (resp., "---") stands for norm (resp., weak) convergence.
Proof. This is a special case of Opial’s [84, Lem. 2].
It is obvious that the identity Id is nonexpansive and easy to see that convex combinations of
nonexpansive mappings are also nonexpansive. In particular, ifN is a nonexpansive mapping,
then so is
ot)Id + aN
for all ot 6
These mappings are called averaged mappings. A firmly nonexpansive mapping is a nonexpansive mapping that can be written as
1/2Id + gN
for some nonexpansive mapping N.
FACT 1.3. If D is a closed convex subset of X and T
X is a mapping, then the
following conditions are equivalent.
(i) T is firmly nonexpansive.
Tyll 2 < (Tx
y) for all x, y 6 D.
Id is nonexpansive.
for example,
Zarantonello’s
Thm. 12.1].
A mapping is called relaxedfirmly nonexpansive if it can be expressed as
ot)Id / otF
for some firmly nonexpansive mapping F.
COROLLARY 1.4. Suppose D is a closed convex subset of X and T
-----+ X is a
mapping. Then T is averaged ifand only if it is relaxedfirmly nonexpansive.
The "principal actor" is the projection operator. Given a closed convex nonempty subset
C of X, the mapping that sends every point to its nearest point in C (in the norm induced by
the inner product of X) is called the projection onto C and denoted Pc.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
FACTS 1.5. Suppose C is a closed convex nonempty subset ofX with projection Pc. Then
(i) Pc is firmly nonexpansive.
X, then Pcx is characterized by
(C- Pcx, x- Pcx) <_0.
Proof See, for example, [109, Lem. 1.2] for (i) and [109, Lem. 1.1] for (ii).
Therefore,
projection
firmly nonexpansive
relaxed firmly nonexpansive = averaged
isometry =, nonexpansive = strictly nonexpansive.
The associated function d(., C)
called the distancefunction to C; it is easy to see that d (., C) is convex and continuous (hence
weakly lower semicontinuous).
A good reference on nonexpansive mappings is Goebel and Kirk’s recent book . Many
results on projections are in Zarantonello’s
The algorithms’ quality of convergence will be discussed in terms of linear convergence:
a sequence (Xn) in X is said to converge linearly to its limit x (with rate fl) if fl
[0, 1[ and
there is some ot >_ 0 such that (s.t.)
for all n.
PROPOSITION 1.6. Suppose (Xn) is a sequence in X, p is some positive integer, and x is
a point in X. If (Xpn)n converges linearly to x and (llXn
xll)n is decreasing, then the entire
sequence (Xn)
converges linearly to x.
Proof There is some ot > 0 and/ 6
[0, 1[ s.t.
for all n.
Now fix an arbitrary positive integer rn and divide by p with remainder; i.e., write
wherer{0,1
We estimate
and the result follows.
Finally, we recall the meaning of the following.
If S and Y are any subsets of X, then span S, c--6-n-vs, S, inty S, icrS, and intS denote,
respectively, the span of S, the closed convex hull of S, the closure of S, the interior of S with
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
respect to (w.r.t.) Y, the intrinsic core ofS (= intsS, where affS is the closed affine span of
S ), and the interior of S (= intx S).
S is called a cone if it is nonempty, convex, and closed under nonnegative scalar multiplication. If S is the intersection of finitely many halfspaces, then S is a polyhedron.
If r is a real number, then r+ := max{r, 0} is called the positive part ofr. In the context
of sequences of real numbers, lim (resp., lim) stands for limes superior (resp., limes inferior).
Occasionally, we will use the quantifiers
(for all) and 3 (there exists) to avoid monstrous
sentences.
2. Two useful tools" Attracting mappings and Fej6r monotone sequences. We focus on two important concepts.
The first generalizes the idea of averaged (resp., strictly)
nonexpansive mappings.
DEFINITION 2.1. Suppose D is a closed convex nonempty set, T
D ---> D is nonexpansive, and F is a closed convex nonempty subset of D. We say that T is attracting w.r.t. F
if for every x
IlTx- fll < Ilx- fll.
In other words, every point in F attracts every point outside F. A more quantitative and
stronger version is the following.
We say that T is strongly attracting w.r.t. F if there is some x > 0 s.t. for every x 6
Alternatively, if we want to emphasize x explicitly, we say that T is K-attracting w.r.t.F.
In several instances, F is Fix T; in this case, we simply speak of attracting, strongly attracting,
or K-attracting mappings.
REMARKS 2.2. Some authors do not require nonexpansivity in the definition of attracting
mappings; see, for example, Bruck’s "strictly quasi-nonexpansive mappings" , Elsner,
Koltracht, and Neumann’s "paracontracting mappings" , Eremin’s "F-weakly Fej6r maps"
 , and Istratescu’s "T-mappings" [69, Chap. 6]. For our purposes, however, the above
definitions are already general enough. As we will see, the class ofstrongly attracting mappings
contains properly all averaged nonexpansive mappings and thus all relaxed projections--the
mappings we are primarily interested in.
We would like to mention (but will not use) the fact that the class of attracting mappings
properly contains all three ofthe following classes: the class of strictly nonexpansive mappings,
Bruck and Reich’s strongly nonexpansive mappings 19], and a very nice class ofnonexpansive
mappings introduced by De Pierro and Iusem [41, Def.
]. The mapping x
ln(1 + ex)
is a first example of a mapping that is strictly nonexpansive but not averaged; hence the class of
attracting mappings is genuinely bigger than the class of strongly attracting mappings. Finally,
neither class contains isometries with fixed points.
The asserted proper containment statements are demonstrated by the following example.
EXAMPLE 2.3. Suppose D is a closed convex symmetric interval in I that contains the
interval [-1, + 1
strictly. Let
iflxl _< 1,
otherwise.
T is nonexpansive and Fix T
T is not strictly nonexpansive.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
T is not strongly nonexpansive (in the sense of Bruck and Reich ); in particular,
T is not averaged [19, Prop. 1.3].
T is not nonexpansive in the sense of De Pierro and Iusem [41, Def. 1 ].
T is attracting.
T is strongly attracting if and only if D is compact.
LEMMA 2.4 (prototype of a strongly attracting mapping). Suppose D is a closed convex
nonempty set, T
D is firmly nonexpansive with fixed points, and c E ]0, 2[. Let
et)Id + etT andfix x
Fix T. Then
Tx) >_ [Ix
Tx[[ 2 and (x
Tx) -ot2[lx
(iv) R is (2- ot)/o-attracting:
[[x- f[[2_ [[Rx
f[[2 > (2- ot)/ot[]x- Rxl[ 2
(2- or)or[Ix- rx[[ 2.
Proof. (i) is immediate.
(ii): Since T is firmly nonexpansive, we obtain
_< (rx- f,x
xl[ 2 / [Ix
== 0 <_ (x
(iii) is a direct calculation:
]Ix -/[[z_ ](1 -)(x
[(1 -c)2]]x -/11 z / 2]]Tx -/]]2 / 2c(1 -c)(x
f[[2_ ly2llx_ f[[2_ Ot2IITx_ f[[2
ot2[llx_ fl]2 / ]]rx- fll2- 2(x- f, Tx
Tx) -o/2 Ix
(iv): By (ii), (iii), and the definition of R, we get
f[I2- [IRx
Tx) -ot2[[x
(2- c)/cllx- Rxll 2.
Note that (i) and (iii) are actually true for an arbitrary nonexpansive mapping T; this
will, however, not be needed in what follows.
Since projections are firmly nonexpansive
(Facts 1.5.(i)), we immediately obtain the following result which slightly improves Flm and
Zowe’s [53, Lem. 1].
COROLLARY 2.5. If P is the projection onto some closed convex nonempty set S and
ot 6 ]0, 2[, then R
ot)Id + otP is (2
ot)/ot-attracting w.r.t. S andfor x
ot)od2 (x, S).
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
DEFINITION 2.6. Suppose (xn) is a sequence in X. We say that (Xn) is asymptotically
regular if
EXAMPLE 2.7. Suppose D is a closed convex nonempty set, F is a closed convex nonempty
subset of D, and (Tn),>_0 is a sequence of nonexpansive self mappings of D, where each Tn is
ten-attracting w.r.t. F and limntCn > 0. Suppose further the sequence (Xn) is defined by
x0 6 D arbitrary,
Xn+l := Tnxn
for all n _> 0.
Then (Xn) is asymptotically regular.
Proof Fix f 6 F and choose 0 < x < limnXn. Then for all large n,
tcllXn-1 -xnll z _< [[Xn-1- fll2- IlXn
Summing these inequalities shows that En IlXn-1
2 is finite; the result follows.
COROLLARY 2.8. Suppose D is a closed convex nonempty setand T
D ---+ D is strongly
attracting withfixedpoints. Then the sequence ofiterates (Tnxo)n>_O is asymptotically regular
for every xo
REMARK 2.9. The corollary is well known for firmly nonexpansive and, more generally,
strongly nonexpansive mappings (see [19, Prop. 1.3 and Cor. 1.1]).
In the literature, the
conclusion of the corollary is often "T is asymptotically regular at x0." We hope the reader
accepts this as an a posteriori justification for introducing the notion of an asymptotically
regular sequence.
The next propositions show that (strongly) attracting mappings respect compositions and
convex combinations.
PROPOSITION 2.10. Suppose D is a closed convex nonempty set, T1
are attracting, and N/N_.I Fix Ti is nonempty. Then
(i) Fix (TN TlV-I
/N= Fix Ti and TNTN-I
T1 is attracting.
(ii) Ifevery Ti is xi-attracting, then TN TlV-1.." T1 is min{tcl
tCu}/2N-l-attracting.
Proof It is enough to prove the proposition for N
2; the general case follows inductively.
Clearly, Fix T1 f) Fix T2 _
Fix (TET1).
To prove the other inclusion, pick f 6
Fix (T2T). It is enough to show that f 6 Fix T1. If this were false, then T1 f
Fix T2. Now
fix f 6 Fix T1 f3 Fix T2. Then, since T2 is attracting,
IIT2(Tlf)- fll < IITlf- fll _< IIf- fll,
which is absurd. Thus Fix T1
Fix (T2 T1). It remains to show that T2T1 is attracting.
Fix x 6 D \ Fix (T2 T1), f 6 Fix (T2 T1). Ifx
Tx, then T2x 5 x and hence
fl]. Otherwise x
TlX; then IIT2Tlx
fll _< I]TlX
either case, TT1 is attracting.
(ii): Given x 6 D, f 6 Fix (T2T1), we estimate
IIx- T2Txll
2 <_ (llx- Tlxll / IITlx
Zxll / IITx
fll2- IITlX- fll2)
/ (llTlx- fll2- IIT2TlX
fll2- IIT2Tx- fl12).
min{tcl, K2}
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
REMARK 2.11. Let X D {0}, D := X, N := 2, and T1 "= T2 := -Id. Then
Fix T C Fix T2
Fix (T2T);
hence the formula on the fixed point sets given in (i) of the last proposition does not hold in
general for nonexpansive mappings.
PROPOSITION 2.12. Suppose D is a closed convex nonempty set, T1
are attracting, and /N=I Fix T/is nonempty. Supposefurther )1
)N > 0 with N=I )i
(i) Fix (z/N=I i T/)
N/N=I Fix T/and=1 )i Ti is attracting.
(ii) Ifevery Ti is zi-attracting, then /N=I )i Ti is min{zl
XN}-attracting.
Proof. Again we have only to consider the case when N
(i): Once more, Fix T1 f) Fix T2_
Fix (.1 T1 + )2 T2). Conversely, pick f
Fix ()1 T1 +
.2 T2), f 6 Fix T1 fq Fix T2. Then
IIZTIf / X2T2f
JZll / .211T2f
fll / Z211f
Hence the above chain of inequalities is actually one of equalities. This, together with the
strict convexity of X, implies f
Tf. Next, we show that )1T1 + 2T2 is attracting.
,kl Tlx + ,k2T2x and f 6 Fix ()1 T1 + )2 T2). Then x ’
Fix T1 Y Fix T2 and thus
II)lT1X + .2T2x- fll
)llZx- fll + )211Z=x- fll
fll + Z=IIx
(ii): If tc "= min{xl, to2}, x
Fix (;kl T1 + .2T2), then
(ZZx + XeZ2x)ll 2
Zlxll + Z211x
_< Zca IIx- Zlxll
2 --I-z2x2llx- Z2xll
_< l([IX- fll2- IlTlX- fll2)
-k- )2(l[x
f[I 2 -II()lTlX -+- 2T2x)
REMARK 2.13.
In contrast to the last remark, the above proof shows that the formula
Fix (y/N__ i T/)
-]/N=I Fix T/holds even if the T/’s are not attracting.
EXAMPLE 2.14. Suppose $1
SN are closed convex nonempty sets with projections
PN and with nonempty intersection. Then
P1 + P2 P1 +"" + PNPN-I’’" P1
is strongly attracting, Fix T
/N=I Si, and the sequence of iterates (Tnxo) is asymptotically
regular for every x0.
The second concept captures essential properties of iterates of nonexpansive mappings.
DEFINITION 2.15. Suppose C is a closed convex nonempty set and (xn) is a sequence in
X. We say that (Xn)n>0 is Fejgr monotone w.r.t. C if
for all c s C and every n > O.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
THEOREM 2.16 (basic properties of Fej6r monotone sequences). Suppose the sequence
(Xn)n>_O is Fejdr monotone w.r.t. C. Then
(i) (Xn) is bounded and d(Xn+l, C) < d(xn, C).
(ii) (Xn) has at most one weak clusterpoint in C. Consequently, (Xn) converges weakly
to some point in C ifand only ifall weak cluster points of (Xn) lie in C.
(iii) Ifthe interior ofC is nonempty, then (Xn) converges in norm.
(iv) The sequence (Pcxn) converges in norm.
(v) Thefollowing are equivalent:
1. (Xn) converges in norm to some point in C.
2. (Xn) has norm cluster points, all lying in C.
3. (Xn) has norm cluster points, one lying in C.
4. d(xn, C)
Moreover, if (xn) converges to some x
C, then IlXn
<_ 2d(xn, C)for all n > O.
(vi) Ifthere is some constant or > O s.t. otd2(xn, C) < d2(xn, C) -d2(Xn+l C)for every
n, then (Xn) converges linearly to some point x in C. More precisely,
ot)n/2d(xo, C) for every n > O.
Proof (i) is obvious.
(ii): For any c 6 C, the sequence (llxn 2- 2(Xn, C)) converges. Hence ifwe suppose Cl, 6’2
are two weak cluster points of (Xn) in C, then we conclude that the sequence ((xn, c
converges and that (Cl, Cl
6"2). Thus Cl
(iii): Fix co 6 int C and get e > 0 s.t. co + Bx c__ C.
for all n > 0.
We can assume Xn
Xn+ 1. Then co + e (Xn
Xn+1)/IlXn
C and hence, by Fej6r
monotonicity,
Squaring and expanding yields the claim.
The claim implies 2ellXn
2 for all n, k > 0. Because
the sequence (llXn
C0112) converges, we recognize (Xn) as a Cauchy sequence.
(iv): Applying the parallelogram law Ila
2 / 211bll 2
2 to a :--
Xn+ and b := Pcxn
Xn+k, we obtain for all n, k > 0,
2llecxn+k --Xn+ll
2 -+" 211ecxn -Xn+kll
--4[[(ecxn+l + Pcxn)/2- Xn+k[[ 2
<_ 2llecxn+k -x+[[ 2 + 2[[Pcxn -Xn+[[ 2
_< 2(11Pcx
We identify (PCXn) as a Cauchy sequence because (llx
ecxnl[) converges by (i).
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
(V): The equivalences follow easily from (i), (iv), and the definition of Fej6r monotonicity.
The estimate follows from letting k tend to infinity in
ecxn + ecxn
Pcxnll-H IIPCXn -xll
2d(xn, C).
(vi): Summing the given inequalities shows that d2(xn, C) tends to 0; therefore, (x)
converges to some point x in C by (v). The estimate on the rate of convergence of (Xn) follows
easily from the estimate given in (v).
REMARKS 2.17. As far as we know, the notion of Fej6r monotonicity was coined by
Motzkin and Schoenberg in 1954. Moreau inspired (iii); see also [69, Thm. 6.5.3].
(iv) rests on an ideaby Baillon and Brezis [8, Lemme 3] and partially extends [46, Thm. 3.4.(c)].
Finally, (v) and (vi) appeared implicitly in Gubin, Polyak, and Raik’s [60, Proof of Lem. 6].
EXAMPLE 2.18 (Krasnoselski/Mann iteration). Suppose C is a closed convex nonempty
C -----+ C is nonexpansive with fixed points, and the sequence (x,) is given by
Xn-t-1 "= (1 --tn)Xn + tnTx
for all n > 0 and some sequence (tn)n>0 in . Then (x) is Fej6r monotone w.r.t. Fix T.
REMARKS 2.19. In the early days, the Krasnoselski/Mann iteration was studied in Hilbert
space. Some authors then implicitly used properties of Fej6r monotone sequences; see [79,
Proof of Thm. 1] and [90, Proof of Thm. 2]. However, tremendous progress has been made
and today the iteration is studied in normed or even more general spaces (see for
further information).
EXAMPLE 2.20 (Example 2.14 continued). The sequence (Tnxo) converges weakly to
some fixed point of T for every x0.
Proof (Tnxo) is asymptotically regular (Example 2.14) and Fej6r monotone w.r.t. Fix T
(Example 2.18). By the demiclosedness principle, every weak limit point of (Tnxo) lies in
Fix T. The result now follows from Theorem 2.16.(ii).
REMARK 2.21. Alternatively, one can use Baillon, Bruck, and Reich’s results on averaged
mappings [9, Thms. 1.2 and 2.1
to understand the last example. In fact, using a suitable modification of [9, Thm. 1.1], one can show that (Txo) converges in norm whenever S1
are closed affine subspaces.
REMARK 2.22. We conclude this section by mentioning a method due to Halpern 
which generates a sequence that converges in norm to the fixed point of T that is closest to the
starting point. For extensions of Halpern’s result, the interested reader is referred to Lions’s
 , Wittmann’s
104], and the first author’s
3. The algorithm: Basic properties and convergence results.
Setting. Suppose D is a closed convex nonempty set and C1
CN are finitely many
closed convex subsets of D with nonempty intersection:
c .= N/N=, C .
N} (we will often refer to
as an index) and all n > 0, suppose that
D is firmly nonexpansive with
 is a relaxation parameter and
otn))Id + 0/
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
is the corresponding relaxation of T/(n) (underrelaxed if ot
n) 6 , overrelaxed if o/
 ), that---i(’(n))/N-1- in is a weight, i.e., v=l )v}
1, and finally that
EL1 )vn)R{
is the corresponding weighted average of the relaxations.
With these abbreviations, we define the algorithm by the sequence
D arbitrary,
A (n)x (n)
for all n > 0,
with the implicit assumption that the sequence (X (n)) lies in D. We also define the set of active
I (n) := {i 6 (1
and we say
is active at n or n is activefor
if.m > 0; i.e.,
6 I (’). We always assume that
every index is picked infinitely often; i.e.,
is active at infinitely many n (this is sometimes
referred to as repetitive control; see ). To facilitate the presentation, we abbreviate
#!n) :--- zn)o/n)[2_ zN
for every index
and n > 0.
For convenience, we introduce some more notions. We say the algorithm is asymptotically
regular if every sequence generated by the algorithm is. We say the algorithm is unrelaxed
for all n and every index
active at any n; note that in this case the algorithm
reduces to a product of firmly nonexpansive mappings. We say the algorithm is singular if
I (n) is a singleton for every n. Singular algorithms are also called row-action methods (see,
for example, ). Finally, we say the algorithm is weighted if I (n)
N} for all n;
the reader may also find the words "parallel" or "simultaneous" in the literature.
REMARK 3.1. The algorithm is a direct generalization of Flgtm and Zowe’s algorithm .
In fact, one just chooses X finite dimensional and T/(n) as the projection onto a hyperplane
containing Ci. We will examine their algorithm in detail in 4.
LEMMA 3.2 (basic properties of the algorithm).
D and n > O, then
l-)v!n).(n)
(n).(n) Ti(n)
Ilx(n) -xl12- ]lx(n/) -xll2
+ 2-J!n)otn)(x
(n) Ti(n)x (n)
--)v (n)ol}n)
AiEl(n) C and n > O, then
Izllxn)- Ti(n)xnll2
Ci and m > n > O, then
Nl=n AiE1 (l)
-lz!l)llxq)
In particular, this estimate holds whenever x
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
(iv) The sequence (x(n)) is Fejdr monotone w.r.t. C and hence is bounded. Also,
(v) Ifn > O, then
(n)Aiin IIxn
Proof (i): We omit the somewhat tedious and lengthy but elementary calculation. It is
easy to see that "(i) == (ii) == (iii) == (iv)" (use Lemma 2.4.(ii)). (v) is immediate by the
definition of the algorithm.
Using the tools from the previous section, we obtain the following corollary.
COROLLARY 3.3 (sufficient conditions for norm convergence).
(i) Ifthe interior ofC is nonempty, then the sequence (x(n) converges in norm to some
point in D.
(ii) If the sequence (X (n)) has a subsequence (xn’) with d(x (n’), C) ----+ 0, then the
entire sequence (xn) converges in norm to some point in C.
Proof. This follows from Lemma 3.2.(iv) and Theorem 2.16.
REMARK 3.4. If the interior of C is empty, then the convergence might only be weak:
Genel and Lindenstrauss present an example of a firmly nonexpansive self mapping T of
some closed convex nonempty set in 2 such that the sequence of iterates (Tnxo) converges
weakly but not in norm for some starting point x0. (A norm convergent method is mentioned
in Remark 2.22.) Since (Tnxo) is Fej6r monotone w.r.t. Fix T (Example 2.18), we conclude
that Fix T has empty interior and norm convergence of the algorithm needs some hypothesis.
COROLLARY 3.5 (asymptotically regular algorithms).
The algorithm is asymptotically
regular whenever
(i) li_.__m,:n aai,fo
> Ofor every index
2for every index i.
(ii) limn:n activefor
(i): There exists an
(5 > 0 s.t. for all n sufficiently large, ],/,n)
(5 for every
active at n. Lemma 3.2.(iv) implies that n Y.i:i activeatn IIx<n
Tixn)ll 2 is finite.
Consequently,
Zi:i active at n xn
On the other hand, by Lemma 3.2.(v),
x(n)II _< Zi:i active atn A’i
Hence (X(n)) is asymptotically regular.
(ii): By Lemma 2.4.(iv) and Proposition 2.12, every A (n) is ten-attracting w.r.t. C, where
active at n}. The hypothesis guarantees li__mnXn > 0, so the
conclusion follows from Example 2.7.
The following simple example shows that the algorithm is not necessarily asymptotically
EXAMPLE 3.6. Suppose X := , N := 1, T(1
n) :-- PI01
n) " 2. Then X (n)
(--1)nx(0); hence the sequence (x(n)) is not asymptotically regular for x () 5 0.
The algorithm should converge at least weakly to some point; however, as the last example
shows, further assumptions are necessary.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
DEFINITION 3.7. We say the algorithm is focusing if for every index
and every subsequence (x(nk)) of the algorithm,
T/(n)x () -+ 0 ]
implies x E C
active at n
Thanks to the demiclosedness principle, we immediately obtain a first example.
EXAMPLE 3.8. Suppose N :-- 1, T
:=-- T, and C1 := Fix T. Then the algorithm is
REMARK 3.9. As almost all upcoming results show, the concept of a focusing algorithm
is crucial. It can be viewed as a generalization of the demiclosedness principle for firmly nonexpansive mappings. The concept itself is investigated in Proposition 3.16 (cf. Theorem 4.3,
Corollary 4.9, Theorem 7.7, and Theorem 7.12).
THEOREM 3.10 (dichotomy I). Suppose the algorithm isfocusing. If lirn: activefor
0for every index i, then the sequence (x(m) either converges in norm to some point in C or
has no norm cluster points at all.
Proof In view of the Fej6r monotonicity of (x()) and Theorem 2.16.(v), it suffices to
show that any norm cluster point of (x()) lies in C. Suppose to the contrary that the theorem
were false. Then there is some subsequence (x()) converging to some point x
/in :-" {i E {1
then lou is nonempty. We assume, after passing to a subsequence if necessary, that
I (nk) U I (n+l) U... U i(nk+l--1)
Now get m 6 {n
minimal s.t. I (m) f"l lout . Thus for nk < m < m, we
have I (m)
CC_. /in. Since x 6 ["lieli, Ci, Lemma 3.2.(iii)yields IIx(n>--xll >_ IIx(m>--xll, which
X (ml) "-"-+ X.
After passing to another subsequence if necessary, we can assume that there is some index
for all k.
By Lemma 3.2.(iv), +cxz >
(m) IIx(m)
ri(m)x (m) 2. By (2) and the hypothesis
), we conclude that
X (ml)- ri(ml)x (ml)
Because the algorithm is focusing, (1), (2), and (3) imply x
Ci, which is a contradiction
lout. Therefore, the proof is complete.
REMARKS 3.11. The finite-dimensional version of the last theorem is relatively recent and
was discovered (in some form or another) independently by Flgtm and Zowe , Tseng 100],
and Elsner, Koltracht, and Neumann . Unfortunately, since firmly nonexpansive mappings
are not weakly continuous in general (see, for example, Zarantonello’s [109, Example on
p. 245]), the proofdoes not work in the weak topology.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
COROLLARY 3.12.
Suppose X is finite dimensional and the algorithm is focusing.
Ofor every index i, then the sequence (x(n) converges in norm to some
limn:n activefor
point in C.
Proof (x) is bounded (Lemma 3.2.(iv)) and hence possesses a norm cluster point. Now
apply Theorem 3.10.
REMARK 3.13 (guaranteeing the "liminf" condition).
A simple way to guarantee
lim: active for
> 0 for some index
is to assume the existence of some
_< or}m _< 2
for all large n active at i,
because then/zln > 3. Moreover, this assumption is equivalent to (cf. to Corollary 3.5)
limn:n active for
lim: active for
Flm and Zowe used this assumption with great success; see also Example 4.18.
EXAMPLE 3.14 (Tseng’s framework 100, Thm. 1 ]). Suppose X is finite dimensional and
the algorithm is singular. Suppose further T/( :=_ T/, Ci
Fix T/, and there is some e > 0
s.t. e _< or}n _< 2
e for all n and every index i. Then the sequence (x(n) converges in norm
to some point in C.
Proof The demiclosedness principle readily implies that the algorithm is focusing. By
the last remark, li___m,,:,, active for
> 0 for every index i. The result follows from the last
corollary.
DEFINITION 3.15. Given an algorithm, we say that (Tim) converges actively pointwise to
T/for some index
for every d
n:n active for
PROPOSITION 3.16 (prototype of a focusing algorithm). Suppose T1
are firmly nonexpansive and let Ci "= Fix T/for every index i. If (T/(n)) converges actively
pointwise to Ti for every index i, then the algorithm isfocusing.
Proof. Fix an index
and a subsequence (x(nk) of (x() with x (nk
active at every nk. We must show that x
Ci. Fix any u 6 X. Because
Po is nonexpansive,
() Pz)u), x (’)
for all k.
Let k tend to infinity; then, by hypothesis on (T/(n)) and (x(n)), we conclude that
Since u has been chosen arbitrarily, we might as well choose u
x + tv, where v is an
arbitrary vector and
(Ti Po(x + tv)
(x + tv), v) <_ 0;
hence, by letting
tend to 0, we get (T/Pox
x, v) <_ O. For v
Ti Pox, we obtain
x= Ti Pvx.
But x 6 D, so Pox
x and therefore x 6 Fix T/
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
REMARKS 3.17.
The last proofis a special case ofan argument ofBaillon [7, Chapitre 6, D6monstration
du Th6orme 1.3].
Note that the last proposition gives another explanation of the fact that the algorithms
of Examples 3.8 and 3.14 are focusing.
DEFINITION 3.18 (control). We say the algorithm is cyclic if
for n > 1,
where we use
N} as remainders. If there is a positive integer p s.t.
I (n) U i(n+l) U
for every index
and all n > 0,
then we speak of an intermittent or p-intermittent algorithm or of intermittent control. Following Censor , we call an algorithm almost cyclic if it is intermittent and singular. We say
the algorithm considers only blocks and speak of block control (cf. ) and a block algorithm
if the following two conditions hold.
1. There is a decomposition J1 N
N} with Jm
and Jm (q Jm’
for all m, m’ 6 {1
2. There is a positive integer p s.t. for all n > 0 and every m
M}, I (n’)
for some n’ 6 {n, n +
n + p- 1}.
Finally, if we want to emphasize that the active indices do not necessarily follow some
form of control, then we use the phrases random control and random algorithm. Clearly,
almost cyclic
considers only blocks
intermittent
REMARKS 3.19.
Recently, block algorithms have received much attention in radiation therapy treatment planning; see and the subsection on polyhedra in 6.
Equivalent to the phrase "almost cyclic" is Amemiya and Ando’s "quasi-periodic"
 or Browder’s "admissible (for finitely many sets)"
THEOREM 3.20 (weak topology results).
(i) Suppose the algorithm isfocusing and intermittent. Iflimn:n activefori Ii
every index i, then the sequence (xn) is asymptotically regular and converges weakly to some
point in C.
(ii) Suppose the algorithm isfocusing and p-intermittentfor some positive integer p.
1)n :-" min{/z}/ "rip <
< (n + 1)pand/active at l} for all n > O.
"qt-o0’ then the sequence (xn) has a unique weak cluster point in C.
precisely, there is a subsequence (X (nkp)) converging weakly to this unique weak clusterpoint
of (xn) in C s.t.
(nk+l)p--1
which implies
X (nkp+rk)
X (nkp+sk) ---"+ 0
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
for all sequences (r), (sk)
In particular,
this happens whenever
li--mn:n activefor tz
) > Ofor every index i.
(iii) Suppose the algorithm isfocusing and the sequence (x(n)) converges weakly to some
point x lf_,
+cx for some index
Ci. Consequently, if,n
for every index i, then x
(i): (x()) is asymptotically regular (Corollary 3.5.(i)). Suppose to the contrary
that (x (n)) does not converge weakly to some point in C. Then, by the Fej6r monotonicity of
(x(’)) and Theorem 2.16.(ii), there exists an index
and a subsequence (x()) converging
weakly to some point x
Ci. Because the algorithm is intermittent, we obtain m with
n < m < nk + p
for all k > 0.
Since the algorithm is asymptotically regular, we have x (n’)
X (m’) "--’+ 0 and hence
(x(mk))k converges weakly to x.
Since the algorithm is focusing, we conclude that
T/(m)X (mk)
On the other hand, by Lemma 3.2.(iv), +cx >
Izm)llx(m)
Ti(mk)x(m)ll2. This contra-
dicts the hypothesis on ,].L
); thus (i) holds.
(ii): Fix momentarily c
C. Then, by Lemma 3.2.(iii) and the definition of vn,
IIx((n+l)P)
c112 > l)n Z
for all n >_ 0. Summing over n and considering the hypothesis on (Vn), we obtain a subsequence
(x(nkP))k s.t.
By Lemma 3.2.(v), we also have
X (nlp+rk)
X (nkp+sl) " 0
for all sequences (r), (s) in {0,
1}. After passing to a subsequence if necessary,
we may assume that (x(nP)) converges weakly to some x 6 D.
Fix any index i.
Since the algorithm is intermittent, there is some sequence (r) in
x (nkp+rk)
(this follows from (**) with s
for all k.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
X (nkp+rl)- Ti(nkp+rk)X (nkp+rk)
Since the algorithm is focusing, (1), (2), and (3) imply x e Ci. The claim follows.
By Theorem 2.16.(ii), x is the unique weak cluster point of (x(n)) in C. The proof of (ii)
is complete.
(iii)" By Lemma 3.2.(iv), +cxz > En /zl
T/(n)x(n) 2. Since we assume En/zl
+cxz, the limes inferior of the sequence
T/(n)x(n) II)n’ n active for
must equal 0.
Since the algorithm is focusing, we readily see that x is in C. The entire
theorem is proven.
REMARKS 3.21.
(i) is our basic weak convergence result.
(ii) is a generalization of an
idea due to Trummer [97, Thm.
]. Tseng’s
100, Thm. 2] is also a result on the existence of
a unique weak cluster point of (x (n)) in C; his hypothesis, however, is somewhat contrasting:
he considers less general relaxation parameters and weights but more general control.
can be viewed as a generalization of Flgtm and Zowe’s [53, Thm. 2] (see also Corollary 3.24
and Example 4.18.(ii)) and Aharoni and Censor’s [3, Thm. 1] (see also Corollary 4.17 and
Example 4.19).
COROLLARY 3.22.
D are firmly nonexpansive, Ci
Fix T/, and (T/(n)) converges actively pointwise to Ti. Supposefurther there is some
(n) for all n > 0 and every index
active at n. If the algorithm is
intermittent, then the sequence (x(n)) converges weakly to some point in C.
Proof The algorithm is focusing (Proposition 3.16) and lirnn... active for
every index
(Remark 3.13). The result now follows from Theorem 3.20.(i).
REMARKS 3.23.
(i) (a special case of a theorem of Browder) If the algorithm is almost cyclic and
T/, then the last corollary gives
17, Thm. 5 for finitely many sets].
(ii) (a remark of Baillon) If the algorithm is almost cyclic and unrelaxed, then the last
corollary gives Baillon’s [7, Chapitre 6, Remarque 11.2].
COROLLARY 3.24. Suppose the algorithm isfocusing and the interior of C is nonempty.
+cxfor every index i, then the sequence (X(n)) converges in norm to some point
Proof It is immediate from Corollary 3.3.(i) and Theorem 3.20.(iii).
COROLLARY 3.25. Suppose X isfinite dimensional and the algorithm isfocusing and pintermittent. If
21"00 (where v is defined as in Theorem 3.20.(ii)), then the sequence
(x(n)) converges in norm to some point in C.
Proof By Theorem 3.20.(ii), (x(n)) has a weak cluster point x 6 C. Since X is finite
dimensional, the point x is a norm cluster point of (x(n)). Now apply Corollary 3.3.(ii).
REMARK 3.26 (guaranteeing the "divergent sum" condition).
One way to guarantee
"--OO for some index
is to assume that there exists some
e for all n
This corresponds (in the case when the T/’s are projections) to Flm and Zowe’s [53, Thm. 2]
(see also Example 4.18.(ii)). Another way is to assume that
the algorithm is singular
-,n:n active for
because then the preceding sum equals n/z}
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
4. Harvest time I: Projection algorithms. From now on, we consider exclusively the
following situation.
Setting. We maintain the hypotheses of the last section, where we defined the algorithm.
In addition, we assume that T/<n is the projection onto some closed convex nonempty setCn
containing Ci"
(n) :-- ei
(n) "= Pcn) and Cf"
for every index
and all n > 0.
We also assume that D := X; that is possible since projections are defined everywhere. We
abbreviate
for every index
and refer to the algorithm in this setting as the projection algorithm. We say the projection
algorithm has constant sets ifCn
Ci for all n > 0 and every index i.
REMARK 4.1. The projection algorithm is formally a slight generalization of Flm and
Zowe’s algorithm (cf. Remark 3.1). Nevertheless, since we allow infinite-dimensional
Hilbert spaces and assume less restrictive hypotheses, we will obtain a number of genuinely
more general results.
Ofcourse, all the results ofthe previous section may be applied to the projection algorithm.
However, before we can do so, we first must understand the meaning of afocusing projection
algorithm. A first prototype is formulated in terms of set convergence in the sense ofMosco
 (see for a good survey article on set convergence), it is essentially a reformulation
of Tsukada’s
characterization of Mosco convergence.
LEMMA 4.2. Suppose
Sn) is a sequence ofclosed convex sets and there is some closed
convex nonempty set S with S
Sn for all n. Then thefollowing conditions are equivalent.
Ps pointwise in norm.
S in the sense of Mosco; i.e., thefollowing two conditions are satisfied.
(a) For every s
S, there exists a sequence (Sn) converging in norm to s with Sn
(b) If (Snk)k is a weakly convergent sequence with Snk
Sn for all k, then its weak limit lies
(iii) If (Xn)k is a weakly convergent sequence with Xn
PsnXnk ----
O, then its weak
limit lies in S.
Moreover, ifone (and hence each) ofthe above conditions is satisfied, then
Proof "(i)==(ii)": This is the Hilbert space case of Tsukada’s [101, Thm. 3.2]. The
proof of "(ii)=(iii)" and the "Moreover" part is easy and is thus omitted.
THEOREM 4.3 (first prototype of a focusing projection algorithm). If (Pi<n) converges
actively pointwise to Pi for every index i, then the projection algorithm is focusing and
Nn:n activefor C
n) for every index i.
Proof. Apply Lemma 4.2 to (cn))n:n active for
for every index i.
EXAMPLE 4.4. Suppose Ci
n) and (cn))n is decreasing; i.e.,
cl) __. C2)
cn)__, c[n+l)
for all n > 0 and every index i.
Then the projection algorithm is focusing. If, furthermore, the projection algorithm is intermit-
]2,!n) > 0 for every index
then the sequence (x(n)) is asymptotically
tent and lirnn:n active for
regular and converges weakly to some point in C.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
Proof. Mosco proved that a decreasing sequence of closed convex sets converges to its
intersection in his sense [82, Lem. 1.3]. The last theorem and the last lemma imply that the
projection algorithm is focusing. The result now follows from Theorem 3.20.(i).
REMARK 4.5. Baillon obtained the last example when the algorithm is in addition almost
cyclic and unrelaxed [7, Chapitre 6, Remarque 11.6].
EXAMPLE 4.6 (random projections). Suppose the projection algorithm is singular, unrelaxed, and has constant sets. If for some index j the set Cj is boundedly compact, then the
sequence (X (n)) converges in norm to some point in C. In particular, this holds whenever X is
finite dimensional.
Proof The last example shows that the algorithm is focusing. Also,
n > 0 and every index
active at n. The sequence (x(n))n: active for j lies in Cj and thus must
have a norm cluster point; therefore, by Theorem 3.10, the entire sequence (x(’) converges
in norm to some point in C.
REMARKS 4.7.
The finite-dimensional version of the last example also follows from
Aharoni and Censor’s [3, Thm. 1], Flftm and Zowe’s [53, Thm. 1], Tseng’s [100, Thm. 1], and
Eisner, Koltracht, and Neumann’s [51, Thm. 1]. We discuss generalizations of Example 4.6
in 6. Not too much is known when the compactness assumption is dropped. It is known that
weak convergence is obtained whenever
(ii) each Ci is a subspace,
but no example is known where the convergence is not actually in norm.
Case (i) is also known as von Neumann’s alternating projection algorithm. Since projections are idempotent, one can view the sequence generated by the random projection algorithm
as an alternating projection algorithm. In
13], we discussed this algorithm in some detail and
provided sufficient conditions for norm (or even linear) convergence.
In 1965, Amemiya and Ando proved weak convergence for Case (ii)mthis is still
one of the best results. Recently, the first author obtained norm convergence for Case
(ii) whenever a certain condition (which holds, for example, if all subspaces have finite codimension) is satisfied.
In order to formulate the second prototype of a focusing projection algorithm (as well
as the norm and linear convergence results in the following sections), we require some more
definitions.
DEFINITION 4.8. We say a projection algorithm is linearlyfocusing if there is some fl > 0
13d(x(, Ci)
for all large n and every index
active at n.
We speak of a stronglyfocusing projection algorithm if
d(x (nk), Cnl))
active at n
implies d(x(), Ci)
for every index
and every subsequence (x()) of (x()).
By Definition 3.7 and the weak lower semicontinuity of d (., Ci), we obtain the following:
linearly focusing =:
strongly focusing ==
COROLLARY 4.9 (second prototype of a focusing projection algorithm). Every linearly
focusing projection algorithm isfocusing.
REMARK 4.10. Flm and Zowe used linearly focusing projection algorithms in
Euclidean spaces with great success (see also Example 4.18).
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
COROLLARY 4.11 (prototype of a linearly focusing projection algorithm). Ifthe projection
algorithm has constant sets, then it is linearlyfocusing.
COROLLARY 4.12 (prototype of a strongly focusing projection algorithm). Suppose the
projection algorithm isfocusing. Ifthe terms ofthe sequence (x(n)form a relatively compact
set, then the projection algorithm is strongly focusing. In particular, this happens whenever
X isfinite dimensional or the interior ofC is nonempty.
Proof Suppose not. Then we get e > 0, x 6 X, an index i, and a subsequence (x(n)k
x, xn- pinkx (n -+ 0,
active atria, but
x(n- Pixnkll >- e for all k. Since
the algorithm is focusing, x
Ci. After passing to a subsequence ifnecessary, we may assume
(by the compactness assumption) that x(n -+ x. But then x’)
Pix’ --+ x
which is absurd.
Therefore, the projection algorithm is strongly focusing.
If X is finite
dimensional, then the terms of (xn) form a relatively compact set because (xn) is bounded
(Lemma 3.2.(iv)). Finally, if int C
0, then (x’) converges in norm (Corollary 3.3.(i)). The
proof is complete.
The two prototypes of a focusing projection algorithm (cf. Theorem 4.3 and Corollary 4.9)
are unrelated, as the following examples demonstrate.
EXAMPLE 4.13. Suppose X := I, N := 1, C :-- C1 :-- {0}, CIn :-- [0, 1/(n 4- 1)],
:= 2. Then the projection algorithm is strongly focusing and the sequence (Cn)
of compact convex decreasing sets converges to C1 in the sense ofMosco (Example 4.4 and
Corollary 4.12). However, the projection algorithm is not linearlyfocusing. Indeed, for n > 1,
d(x(n) Cn))
EXAMPLE 4.14. Suppose X "= I, N "= 1, C := C1 := {0}, Cn ’= (-1)" , and
X) 6 X arbitrary. Then the p ojection algorithm is linearlyfocusing since x
=- 0 6 C for
n > 2. However, the sequence (C) of compact convex sets does not converge to C in the
sense ofMosco.
Having gotten a feeling for the concept of a linearly focusing projection algorithm, we
document its usefulness through a dichotomy result inspired by Aharoni and Censor’s [3,
Proof of Thm. 1 ].
THEOREM 4.15 (dichotomy II). Suppose the projection algorithm is linearlyfocusing and
there is some
for all large n and every index
active at n. Then
the sequence (x(n)) either converges in norm or has no norm cluster points at all.
Proof Assume to the contrary that (x (n)) has at least two distinct norm cluster points,
say y and z. Get/ > 0 s.t. d(x (l) Ci) < d(x (1), C{l)) for all large
and every index
at I. Fix c 6 C. Since y
C (otherwise, the sequence (x(n)) would converge in norm by
Corollary 3.3.(ii)), the set of indices I := {i 6 {1
N}’y q Ci} is nonempty. Define
B := y 4- rBx, where r
(1/2) min({llY
} implies Ilx (z)- cll- [Ix
cll >_ }/1 Z)l)"
On the one hand, by Lemma 3.2.(ii), the definition of/, and Ily
x(ll >_ d(y, Ci)
d(x (l, Ci),
iix(Z/_cll 2 >
[i " (x(l) Cl))
l22"2(x, ci
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
On the other hand,
cll + IIx <z+l>
and the norm of the latter factor is at most 2(r + IlY
cll). Altogether, ?’1
2f12r2/(2(r +
ell)) does the job and Claim
is verified.
[ implies IIx
Yll _< ?’2Z )I
N} \ I, the point y is fixed under the nonexpansive mapping R})
(cf. Facts 1.5.(i), Fact 1.3.(iii), and Corollary 1.4); thus we estimate
IIx(e- yll +
Z>{llR}x(Z>- x(ll + IIx
IIx (l)- Yll +Y
,klS{2d(xq), Ci)r}
)}){2(d(y, Ci) .qt_ ilxq
yll) + r}.
Therefore, ?’2
2 max{d(y, Ci)
I} + 3r does the job and Claim 2 is also verified.
The rest is done quickly. Set
and find n large s.t. Ilx
Yll < 3; thus x (") 6 B. Now z is another norm cluster point of
(x (n)) and has positive distance to B, so there is a minimal m > n with x (m)
B. By the Fej6r
monotonicity of (x(")) and Claim 1,
By Claim 2, however,
Y + ?’2ZE )}l) <
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
which contradicts y
Therefore, the sequence (x (n)) has at most one norm cluster
REMARK 4.16. As Example 3.6 demonstrates, some assumption is necessary to guarantee
at most one norm cluster point.
COROLLARY 4.17. Suppose the projection algorithm is linearlyfocusing and there is some
for all large n and every index
active at n. Supposefurther that
X is finite dimensional or the interior of C is nonempty. Then the sequence (x (n)) converges
in norm to some point x. Ifn
+cx for some index i, then x
Ci. Consequently, if
+zfor every index i, then x
0, then (x)) converges in norm by Corollary 3.3.(i).
If X is finite
dimensional, then (x)) has a norm cluster point; thus, by the last theorem, (x (n)) is also norm
convergent. The result now follows from Theorem 3.20.(iii).
The next two examples follow immediately.
EXAMPLE 4.18 (Flm and Zowe’s framework [53, Thms.
and 2]). Suppose X is finite
dimensional, the projection algorithm is linearly focusing, and there is some
for all large n and every index
active at n. Then the sequence (xm) converges
in norm to some point x.
(i) If lirn: active for
> 0 for every index i, then x 6 C.
(ii) If int C
+cxz for every index i, then x
EXAMPLE 4.19 (Aharoni and Censor’s framework [3, Thm. 1]).
Suppose X is finite
dimensional, the projection algorithm has constant sets (and is therefore linearly focusing by
Corollary 4.11), and there is some e > 0 s.t. e _< o
e for all large n and every
active at n. Then the sequence (x (n)) is norm convergent and its limit lies in ’]iEl Ci,
REMARKS 4.20.
Under the assumption on the relaxation parameters in the preceding examples, the
condition lim: active for
> 0 is equivalent to lim.
> 0 (cf to
active for
Remark 3.13) and the conditionn ti"
+cx is equivalent to’
to Remark 3.26) for every index i.
Example 4.18.0) follows not only from Corollary 4.17 but also from Theorem 3.10.
The next example shows that ifone drops the assumption
+cx inExample 4.19,
then one cannot expect the limit of (x (n)) to lie in Ci.
EXAMPLE 4.21. Let X "= R, N "= 2, C1 "= C
) :]-cx, 0], and C2 "= C(
[0, +cx[. Suppose x () > 0, al
3/2, and )I) < 2/3 for all n. Then
and therefore
lim x (n) 6 C
lim x (") -0
THEOREM 4.22. Given a projection algorithm, suppose
Pi(n)) converges actively pointwise to Pi for every index i. Suppose further there is some subsequence (n’) of (n) s.t. for
every index i,
for some Ol
]0, 2] and i
]0, l]. Ifthe interior ofC is nonempty, then the sequence (x (n))
converges in norm to some point in C.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
Proof By Corollary 3.3.(i), (X(n)) converges in norm to some point x. We must show
that x 6 C.
Pi(n’)x(n’)
for every index i.
_< [Ix (n’)
x II, we have Pi(n’)x (n’)
Pi(n’)x ----+ O. Since
i > 0, we see that
is active at n’ for all large n’. The assumption on (Pi(n)) implies
pi(n’x --+ Pix. The claim follows.
ol}n’))x(n’) _..ot
"(n’)Pi(n’)x(n’)
hence, by taking limits along the subsequence (x(n’)) and by the claim,
E/N=I ’i ((1
Proposition 2.12 implies that x 6 C; the proof is complete.
EXAMPLE 4.23 (Butnariu and Censor’s framework [20, Thm. 4.4]). Suppose X is finite
dimensional, the projection algorithm has constant sets, and the relaxation parameters depend only on n, say o/
o/(n) for every index
and all n. Suppose further there is some
subsequence (n’) of (n) s.t. for every index i, i
--’+ i for some/’i > 0.
(i) If there is some
< o/(n) < 2
for all large n, then the sequence (x(n)
converges in norm to some point in C.
(ii) If the interior of C is nonempty and there is some subsequence (n") of (n’) s.t.
ot (n’ --+ 2, then the sequence (x(n)) converges in norm to some point in C.
(i): The assumption on the weights implies En
--’OO for every index
Thus (i) follows from Example 4.19. (ii) is immediate from Theorem 4.22.
REMARK 4.24. Note that the last theorem works especially when o/
2. Since in this
0, none of the previous results are applicable. If we drop the assumption that
0, then the conclusion of the last theorem need not hold; see Example 3.6.
DEFINITION 4.25 (control). We say the projection algorithm considers remotest sets if for
every n, at least one remotest index is active; i.e.,
Ir()m "= {i
d(x (n), Ci)
max{d(x (n), Cj)
1... N}} (3 1 (n) # 0.
Following Censor , we speak of remotest set control if the projection algorithm is singular
and considers remotest sets. Obviously,
remotest set control
considers remotest sets.
THEOREM 4.26 (weak topology results). Suppose the projection algorithm is strongly
focusing and considers remotest sets.
Suppose further that (i (n)) is a sequence of active
remotest indices; i.e.,
Ir()mfor all n.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
+oo, then there is a subsequence (X(nkl)k of (X (")) s.t.
max{d(x (nk), Cj)
1... N} ---+ O,
and (X(nk))k converges weakly to the unique weak cluster point of (X(n)) in C.
(ii) /flirn
nPt,i(n) > O, then (x (n)) converges weakly to some point in C and
max{d(x(n), Cj)" j
(i): By Lemma 3.2.(iv), the series Yn
() c,()a is convergent. Hence
limnd(x(n)
0. Thus we can extract a subsequence (x(n))k and fix an index
d(x(n), C}n)) ---> 0, ( =- i, and (x(n)) converges weakly. Since the algorithm is strongly
focusing and considers remotest sets, we conclude that
max{d(x(n), Cj)
By weak lower semicontinuity of d(., Cj) for every index j, the weak limit of (X (nk)) lies in C.
By Theorem 2.16.(ii), (x(n)) has at most one weak cluster point in C; therefore, (i) is verified.
(ii) is proved similarly,
REMARK 4.27. Remotest set control is an old and successful concept. In 1954, Agmon
and Motzkin and Schoenberg studied projection algorithms for solving linear inequalities
using remotest set control. Bregman
16] considered the situation when there is an arbitrary
collection of intersecting closed convex sets. We will recapture Agmon’s main result [1,
Thm. 3] and some generalizations in 6.
5. Guaranteeing norm or linear convergence: Regularities. We uphold the notation
of the preceding sections; in particular, we remember that C1
CN are closed convex sets
with nonempty intersection C.
Norm convergence and (bounded) regularity.
DEFINITION 5.1. We say that the N-tuple of closed convex sets (C1
CN) is regular if
max {d(x, Cj)
1...N] <_ 8
If this holds only on bounded sets, i.e.,
XD Sboundede >0 8>0
max{d(x, Cj)
then we speak of a boundedly regular N-tuple (C1
Although the definition of (bounded) regularity is independent of the order of the sets,
we prefer to think of C1
CN as a tuple. The geometric idea behind this definition is
extremely simple: "If you are close to all sets, then the intersection cannot be too far away." In
13], we utilized this notion to formulate some norm convergence results for von Neumann’s
alternating projection algorithm for two sets.
The results of this subsection will illustrate the usefulness of this concept in our present
framework.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
THEOREM 5.2. Suppose the projection algorithm is stronglyfocusing and p-intermittent
for some positive integer p. Supposefurther the N-tuple (C1,
CN) is boundedly regular
Pn :-- min{/*/)
< (n + 1)p
and/active at l} for all n > O.
+oo, then the sequence (x(m) converges in norm to some point in C. In particular,
0for every index i.
this happens whenever limn:n activefor
Proof By Theorem 3.20.(ii), we obtain a subsequence (x(nP) of (xn) s.t. (xP)
converges weakly to the unique weak cluster point of (x) in C, say x,
(l) Cl)) -----+ O,
X (nkp+rk)
for all sequences (r) in {0
}. Fix any index i. Because the projection algorithm
is intermittent, we get a sequence (r) in {0
I (np+r) for all k. Then, by
(*), d(x (np+r) C{np’+-r))
"’-’+ O. Since (x(nkp-t-r))k also converges to x (by (**)) and the
projection algorithm is strongly focusing, we deduce that
d(x(nkp+r), Ci) -----+ O.
Hence, by (**), d(x(p, Ci) ----> O. Since
has been chosen arbitrarily, we actually have
max{d(x(np, Cj)
1... N} ----+ O.
and (x("P)
consequently,
d(x (np), C)
O. Therefore, by Corollary 3.3.(ii), (X(n)) converges in norm to x.
THEOREM 5.3. Suppose the projection algorithm is strongly focusing and considers remotest sets. Suppose further the N-tuple (C1
CN) is boundedly regular and (i() is a
sequence ofactive remotest indices. Ify
"Jl"OO, then the sequence (x(n)) converges in
norm to some point in C. In particular, this happens whenever lim nli(
Proof By Theorem 4.26.(i), there exists a weakly convergent subsequence (x(n)) of
(x(n)) with max{d(x (n), Cj)
1... N} --+ 0. Since (Ca
CN) is boundedly regular,
we get d(x (n), C) ----+ O. Now apply Corollary 3.3.(ii).
In order to make use of these theorems, we must know when an N-tuple (C1
is boundedly regular. Fortunately, our observations on bounded regularity of a pair in 
generalize easily to the N-set case.
PROPOSITION 5.4.
(i) Ifsome set Ci is boundedly compact, then the N-tuple (C1
CN) is boundedly
(ii) Ifthe N-tuple (C1
CN) is boundedly regular and some set Ci is bounded, then
CN) is regular.
(iii) IfX isfinite dimensional then every N-tuple (C1
CN) is boundedly regular
Proof. An easy modification of [13, Thm. 3.9 (resp., Thm. 3.15) given for two sets] yields
(i) (resp., (ii)). (iii) follows from (i).
REMARK 5.5. We gave an example
13, Ex. 5.5] of a pair which is not boundedly regular;
therefore, bounded regularity requires some assumption.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
Linear convergence and (bounded) linear regularity. The following stronger and more
quantitative version of (bounded) regularity allows us to discuss rates ofconvergence.
DEFINITION 5.6. We say that the N-tuple of closed convex sets (C1
CN) is linearly
regular if
d(x, C) < x max{d(x, Cj)
Again, if this holds only on bounded sets, i.e.,
XD__Sboundedtcs>Ox S
d(x, C) < xs max{d(x, Cj)
then we say that (C1
CN) is boundedly linearly regular.
linearly regular =
boundedly linearly regular
boundedly regular.
THEOREM 5.7. Suppose the projection algorithm is linearly focusing and intermittent.
Suppose further the N-tuple (C1
CN) is boundedly linearly regular and there is some
< ot}nl < 2
< n) for all large n and every index
active at n. Then the
sequence (x (nl) converges linearly to some point in C; the rate ofconvergence is independent
ofthe starting point whenever (C1
CN) is linearly regular
Suppose the projection algorithm is p-intermittent.
Fix any index i.
for all k >_ 0, we get m with kp <_ m, < (k + 1)p
I(m). Now X (m’)
Am-l)... AP)x kp) and, by Lemma 2.4.(iv) and Proposition 2.12.(ii),
j active at n}-attracting w.r.t. C
for all n > 0.
Hence, by the assumption on the relaxation parameters, A (n) is /2-attracting w.r.t. C for all
large n. Thus, by Proposition 2.10.(ii),
A(m’-l)... A (p)
is -----:-attracting w.r.t. C
for all large k.
Since the projection algorithm is linearly focusing, there is some/3 > 0 s.t. fld(x (n), Cj) <
d(x (n) Cn)) for all large n and every index j active at n. Now
d2(x (Ip), Ci)
x(mk)[[ + d(x (mk), Ci))2
(p) --x(m) I]:Z + 2d2(x(m), Ci);
here the first inequality follows from the nonexpansivity of d (., C
and the second one is just
"(a + b) 2 < 2a2 / 2b2.
Fix an arbitrary point c 6 C. On the one hand, for all large k,
IIA(m-l)... A(kP)x(kP)
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
On the other hand, by the assumptions on /3, relaxation parameters, weights, and by
Lemma 3.2.(ii) and Remark 3.13, we estimate for all large k that
altogether
d2(x (kp), Ci) <
which, after choosing c "= Pcx(kp), yields
d2(x (kp) Ci) <
d2(x((k+l)P)
has been chosen arbitrarily, the last estimate is true for every index i, provided
that k is large enough.
CN) is boundedly linearly regular, we obtain for
S := {x (n "n > 0} a constant Xs > 0 s.t.
d(x (n), C) < tcsmax{d(x (n), Cj)
for all n > 0.
Note that if (C1
CN) is linearly regular, then the constant Xs can be chosen independent
of S. Combining gives
d2(x(P) C)<tc}(2
(d2(x (kp) C)-d2(x ((k+l)p) C)).
Therefore, by Theorem 2.16.(vi) applied to (x(P)), the sequence (X(kp)) converges linearly
to some point x in C. By Theorem 2.16.(i) and Proposition 1.6, the entire sequence (x (n))
converges linearly to x; the rate of convergence is independent of the starting point whenever
CN) is linearly regular.
THEOREM 5.8. Suppose the projection algorithm is linearly focusing and considers remotest sets.
Suppose further the N-tuple (C1
CN) is boundedly linearly regular and
(i (n)) is a sequence of active remotest indices.
> O, then the sequence (x (n))
converges linearly to some point in C; the rate ofconvergence is independent of the starting
point whenever (C1
CN) is linearly regular.
First, since the projection algorithm is linearly focusing, we get/3 > 0 s.t.
d(x (n), Ci
d(x (n), c}n)) for all n and every index
active at n. Second, since (C1
is boundedly linearly regular, we obtain for S "= {x (n)
n > 0} a constant Xs > 0 s.t.
d(x(), C) <_ xs max{d(x (n), Cj)
1... N} for all n >_ 0. Once more, the constant xs can
be chosen independent of S whenever (C1
CN) is linearly regular. Third, there is some
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
(n) > 6 for all large n. Putting this together and using Lemma 3.2.(ii), we estimate
6 > 0 s.t.t.l.,i(n)
for all large n that
d2(x(n), C) <_ t max{d2(x (n), Cj)
(11xn)- Pcxn)
(d2(x (n), C) -d2(x(n+l), C)).
Therefore, by Theorem 2.16.(vi), (x(n/) converges linearly to some point in C (again with a
rate independent of the starting point whenever (C1
CN) is linearly regular).
(Bounded) linear regularity: Examples. Having seen the power of (bounded) linear
regularity, we now investigate this concept itself and provide basic prototypes.
PROPOSITION 5.9. If each set Ci is a closed convex cone, then the following conditions
are equivalent.
CN) is regular.
CN) is linearly regular.
CN) is boundedly linearly regular.
Proof Adapt the proof of 13, Thm. 3.17].
REMARK 5.10. It follows that (i), (ii), and (iii) are equivalent if
CN are closed convex translated cones with a common vertex (a simple
translation argument),
CN are closed affine subspaces with nonempty intersection.
THEOREM 5.11 ((bounded) linear regularity: reduction to pairs). If each of the N
(C1 ("1 C2, C3),
(C1 f") C2 [")... [") CN-2, Cu-1),
C2 (")... O Cu_2
is (boundedly) linearly regular, then so is the N-tuple (C
Proof We consider the case when all pairs are boundedly linearly regular; the case when
all pairs are linearly regular is treated analogously. Fix a bounded set S and get (by hypothesis)
KN_ > 0 s.t. for every x 6 S, we have the estimates
d(x, CI f3 C2)
d(x, ClC2fqC3)
d(x, C 0... (3 Cu)
tCl max{d(x, CI), d(x, C2)},
K2 max{d(x, C1 0 C2), d(x, C3)},
/(N-1 max{d(x, C f3... fq CN_I) d(x, CN)};
hence d(x, C1 (").." f-) CN) <_ K1K2
IgN-1 max{d(x, Cj)
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
For bounded linear regularity of pairs, we gave the following sufficient condition (see
[13, Cor. 4.5]).
FACT 5.12. Suppose E, F are two closed convex sets. If 0 6 icr (E
F), then the pair
(E, F) is boundedly linearly regular. In particular, this happens whenever
(i) 0 6 int (E
F is a closed subspace.
Combining the two preceding results immediately yields the following.
COROLLARY 5.13. If
0 6 icr (C1
C2) N icr ((C1 f3 C2)
("1 icr ((C N... C CN-1)
then the N-tuple (C1
CN) is boundedly linearly regular.
COROLLARY 5.14. ifCN ("lint (C1 N
CN_ 1) # 0, then (C
CN) is boundedly
linearly regular.
REMARK 5.15. These sufficient conditions for bounded linear regularity do depend on the
order of the sets, whereas bounded linear regularity does not. Consequently, these conditions
might still be applicable after a suitable permutation of the sets.
In applications, the N sets almost always have additional structure. One important case is
when all sets are closed subspaces. In the following, we will completely characterize regularity
of an N-tuple of closed subspaces. We begin with the case when N
Recall that the angle y
y (C, C2) 6 [0, rr/2] between two subspaces C, C2 is given
by (see Friedrichs or Deutsch )
sup{(c, c2) :C1 G C1 ()(C1
C2) -1-, c2 G C2
C2)1, Ilclll
PROPOSITION 5.16. If C1, C2 are two closed subspaces and y is the angle between them,
then thefollowing conditions are equivalent.
(i) y > 0.
(ii) C1 + C2 is closed.
(iii) C13- + C2
is closed.
(iv) (C, C2) is linearly regular
(v) (C, C2) is boundedly linearly regular.
(vi) (C1, C2) is regular.
(vii) (CI, Ce) is boundedly regular.
Proof "(i)==(ii)" is due to Deutsch [42, Lem. 2.5.(4)] and Simoni ( , a proof can
be found in [13, Lem. 4.10]). "(ii)==,(iii)" is well known (see Jameson’s [70, Cor. 35.6]).
"(ii)==,(iv)c==(v)e==(vi)=(vii)": Combine Fact 5.12.(ii) and Proposition 5.9.
"(vii)=(i)": Let us prove the contrapositive. Suppose y
0. Then we obtain two
sequences (c)) (c()
for every n, and
(clm, c(2n)) ---+ 1
Expanding Ilcl
2 yields cl
----> O. On the one hand, if we define x () "=
n) + c))/2, then, by the parallelogram law,
On the other hand,
PCIfqC2x(n)
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
Altogether, (X (n)) is bounded, d(x (n), C1)
0, d(x (n), C2) --’--+ 0, but d(x (n) C1 N C2)
--* 1. Therefore, (C1, C2) is not boundedly regular and the proof is complete.
A short excursion into a useful product space. We buildmin the spirit of Pierra -the product space
x := I-I/= (x, t.,
and define the diagonal
and the product
B "= I-[=1Ci.
This allows us to identify the set C with A q B. Then (see, for example, ) for x, y 6 X,
and the projections onto A and B are given by
(PlXl, P2x2
PROPOSITION 5.17. /f0 6 icr (A- B), then (A, B) is boundedly linearly regular.
Proof. This is nothing but Fact 5.12 applied in X.
We now tackle the N-subspace case.
LEMMA 5.18.
If each set Ci is a closed subspace, then the following conditions are
equivalent.
(i) C- 4-... 4- C is closed.
(ii) A + B is closed.
(iii) (A, B) is (boundedly) (linearly) regular.
Proof. Denote C1x 4-... 4- Cx by S and consider
T :X --+ X:(Xl
Xl 4-’’’ 4- XN.
Clearly, T is onto and kernel T
A+/-. By a useful consequence of the open mapping theorem
(see, for example, Holmes’s [67, Lem. 17.HI),
S is closed == A
+/- 4- I-I/N=, C/ is closed.
Now apply Proposition 5.16 to A and B in X.
THEOREM 5.19 (linear regularity and subspaces). Ifeach set Ci is a closed subspace, then
the following conditions are equivalent.
(i) C- 4-... 4- C is closed.
CN) is linearly regular
CN) is boundedly linearly regular
CN) is regular
CN) is boundedly regular
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
Proof "(i)===(ii)"" By the last lemma, there is some tc > 0 s.t.
d (x, A N B) < x max{d (x, A), d (x, B)}
for every x 6 X.
In particular, if x 6 X and x
x) 6 A, then
d2(x,/ B) _< tc2d2(x, B);
therefore, the linear regularity of (C
CN) follows from
d2(x, C) <_ tc2(d2(x, C1) +... -+- d2(x, CN))/N
< K 2 max{dZ(x, Ci)
"(ii)===(iii)<===(iv):=:=(v)" follows from Proposition 5.9.
"(v):=:=(i)": We prove the contrapositive. Suppose C( +
+ CNz is not closed. Then,
by the preceding lemma, (A, B) is not boundedly regular. We thus obtain a bounded sequence
(x(n) s.t.
d(x(m, A) --+ 0,
d(x, B) --+ 0, but limd(x, A N B) > 0.
to be the first coordinate of Pzxx.
Then the sequence (x() is bounded,
1 /N=I d2(x(n) Ci
O, but limd2(x<m /N=I Ci) > 0. Therefore, (C1
CN) is not
boundedly regular and the proof is complete.
REMARKS 5.20.
Browder implicitly proved "(i)===(ii)" of the last theorem in .
It is interesting that, unless N
2, the closedness of the sum C1 +
not related to the regularity of the N-tuple (C1
CN). Indeed, for N > 3, take
two closed subspaces C1, C2 with nonclosed sum. (i)" Set C3 :-
CN) is not regular (Proposition 5.16), but the sum CI +
closed. (ii)" Set C3
"= CN "= {0}; then (C
CN) is regular, but the sum
+ CN is not closed. Altogether, the closedness of the sum C +... + CN
is neither necessary nor sufficientfor regularity ofthe N-tuple (C
For closed intersecting affine subspaces, a corresponding version of the last theorem
can be formulated (since regularity is preserved under translation of the sets by some
fixed vector).
Applying the last theorem to orthogonal complements yields the following characterization.
If each set Ci is a closed subspace, then the following conditions are
equivalent.
(i) C1 +... + CN is closed.
(ii) There is some tc > 0 s.t. for every x 6 X,
Pc,+...+cux
/"" / Pcux II).
(iii) For every bounded sequence (x()),
max{llPcix(ll’i
1... N} --+ 0
IIPc,+...+CNX<II -----> O.
COROLLARY 5.21.
Suppose each set Ci
is a closed subspace.
Then the N-tuple
CN) is linearly regular whenever
(i) at least one subspace isfinite dimensional or
(ii) all subspaces except possibly one havefinite co-dimension.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
Proof (i): Using Proposition 5.16, induction on N, and the well-known fact that the sum
ofa closed subspace and afinite-dimensional subspace is closed (see, for example, Jameson’s
[70, Prop. 20.1]), we obtain readily that C( +
+ CN is finite co-dimensional and closed.
Now apply the last theorem.
(ii)" If without loss of generality C1
CN-I are finite co-dimensional, then Ci
is finite dimensional. Again, C- +...+C is closed and the last theorem applies.
Once more, an analogous version of the last corollary holds for closed intersecting affine
subspaces. We state the most important case.
COROLLARY 5.22 (linear regularity and intersecting hyperplanes).
If each set Ci is a
hyperplane, then the N-tuple (C1
CN) is linearly regular.
We now give another important class of linearly regular N-tuples.
FACT 5.23 (linear regularity and intersecting halfspaces). If each set Ci is a halfspace,
then the N-tuple (C1
CN) is linearly regular.
REMARK 5.24. In 1952, Hoffman proved this fact, relying on some results by Agmon
for Euclidean spaces. It turns out that his proof also works for Hilbert spaces; a detailed
proof will appear in the thesis of the first author.
The following result shows how one builds more examples of (boundedly) (linearly)
regular tuples.
PROPOSITION 5.25. Suppose (C1
CN) is a (boundedly) (linearly) regular N-tuple
{1,..., N} is a disjoint decomposition of
N}; i.e., Jm 7 0 and
Ofor m, m’
m} and m 7 m’. Ifwe set
for every rn
then the M-tuple (D
Dt) is (boundedly) (linearly) regular.
Proof Suppose (C,
Co) is linearly regular. Then there is some x > 0 s.t. d(x, C f
N CN) <_ X maxn d(x, Cn) for every x 6 X; thus
_< x max d(x, Cn)
x max max d (x, Cn)
_< x max d(x, Dm).
Therefore, (D
Dt) is linearly regular. The proofs of the remaining cases are similar
and thus are omitted,
COROLLARY 5.26 (linear regularity and intersecting polyhedra). Ifeach set Ci is a polyhedron, then the N-tuple (CI,
CN) is linearly regular.
We finish this section with a result on the "frequency" (in the sense of Baire category) of
boundedly linear N-tuples. Quite surprisingly, "bounded linear regularity is the rule." Since
we will not use this result in what follows, we only sketch a proof. For basic results on the
Hausdorff metric, we recommend Klein and Thompson’s ; for basic results on Baire
category see, for example, Holmes’s [67,
THEOREM 5.27. Suppose 7" is the set ofall N-tuples oftheform (C1
CN), where each
set Ci is bounded closed convex and the intersection=
Ci is nonempty. Then the subset of
all boundedly linearly regular N-tuples is residual in 7- (equipped with the Hausdorffmetric).
Sketch ofa Proof We work in the product space X.
Step 1: Show that 7" is a closed subset in the complete metric space consisting of all
closed subsets of X equipped with the Hausdorff metric.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
Step 2: Denote by
the subset of 7" consisting of all boundedly linearly regular N-tuples.
Deduce from Proposition 5.17 thatifB
Tand0 6 int (A-B), thenB .
Step 3: Define (.9 := {/3 6 7"
0 6 int (A- B)} and show that 69 is dense in T (given
T, consider the "nearby" (C1 + Bx
CN + Bx) in (9 for small
Step 4: Prove that (_9 is open in T. Indeed, denote the Hausdorff metric by h, fix B 6 69,
> 0 s.t. Bx_
A- B. Suppose B’ 6 T with h(B, B’) < /2. Then
A-B c_ A-B’ + Bx.
By Rhdstr6m’s cancellation lemma [87, Lem.
Bx __c A- W;
thus B’ 6 (9.
Conclusion. TZ is residual in T because 7
69 and (9 is open and dense in T.
REMARK 5.28. In view of Theorems 5.7, 5.8, and 5.27, we can loosely say that "linear
convergence is the rule for certain algorithms." The restriction that every Ci be bounded is not
really severe since a reduction to this case can be made as soon as the starting point is chosen.
6. Harvest time lh Examples. In this section, numerous examples for our results are
given. To demonstrate the applicability ofourframework, we mainly chose examples that are
closely related to known results and only occasionally comment on (sometimes very substantial) possible generalizations.
"Fairly" general sets.
Random control.
EXAMPLE 6.1. Suppose the projection algorithm is linearly focusing and some set Cj is
boundedly compact. Suppose further that
(i) lirnn:
active for
> 0 for every index
(ii) there is some
< o n _< 2
and n: active for
+oe for every
and all large n active for i.
Then the sequence (x() converges in norm to some point in C.
(n).2(x(n)
Proof. By Lemma 3.2.(iv), the sum --,n:n active for j I&j
)is finite. Since the
projection algorithm is linearly focusing, the assumptions on (/x}) imply the existence of a
subsequence (x(’) of (x(n) with
d(x (n’), Cj)
j is active at n’.
After passing to a subsequence if necessary, we can assume that (Pjx(n’)) is norm convergent;
hence, so is (x(n’). Therefore, the sequence (x(n) has a norm cluster point. If (i) holds, then
the result follows from Theorem 3.10. Otherwise (ii) holds and then the result follows from
Theorems 4.15 and 3.20.(iii).
REMARKS 6.2.
This result improves Examples 4.6, 4.18.(i), and 4.19.
As we commented in Remarks 4.7, the problem becomes much harder without a
compactness assumption. Nevertheless, some interesting results were obtained by
Bruck , Youla , and Dye and Reich .
An immediate consequence of Example 6.1 is the following.
EXAMPLE 6.3 (Bruck’s [18, Cor. 1.2]). Suppose the projection algorithm is singular and
has constant sets where (at least) one is boundedly compact.
If there is some e > 0 s.t.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
e for every index i, then the sequence (x (n)) converges in norm to some
point in C.
REMARK 6.4. Bruck’s proof is quite different and is highly recommended.
Intermittent control. We start with some results on linear convergence.
EXAMPLE 6.5 (Browder’s [17, Thin. 3]).
Suppose the projection algorithm is almost
cyclic, unrelaxed, and has constant sets. Suppose further that 0
C and for every r > 0, there
is some K > 0 s.t.
Kr max{d(x, Ci)
{0} and the sequence (X(n)) converges linearly to 0.
Proof. By (.), obviously C N rBx
Since r can be chosen arbitrarily large, it
follows that C
{0}. Thus (.) states that d(x, C)
Ilxll _< max{d(x, Ci)
i.e., the N-tuple (C
CN) is boundedly linearly regular. The result now follows from
Theorem 5.7.
EXAMPLE 6.6 (Youla and Webb’s [108, Thm. 3]). Suppose the projection algorithm is
cyclic and has constant sets. Suppose further the relaxation parameters satisfy 0 < or}
O/i < 2 for every index
and all n active for i. If there is some index j 6
then the sequence (X (n)) converges linearly to some point in C.
Proof By Corollary 5.14 (cf. Remark 5.15), the N-tuple (C
CN) is boundedly
linearly regular. Now apply Theorem 5.7.
REMARK 6.7. An extended version ofYoula and Webb’s well-written paper is Youla’s 106].
Analogously, we can prove the following.
EXAMPLE 6.8 (Gubin, Polyak, and Raik’s [60, Thm. 1.(a)]).
Suppose the projection
algorithm is cyclic and has constant sets. Suppose further there is some e > 0 s.t. e < 0/}
e for every index
and all n active for i. If there is some index j 6
then the sequence (X (n)) converges in norm (in fact, linearly) to some point in C.
REMARK 6.9. Gubin, Polyak, and Raik’s paper is a cornerstone for this field and
contains many original results and applications.
REMARK 6.10. The preceding examples all followed from Theorem 5.7 and the results
on bounded linear regularity. Since Theorem 5.7 allows more general control, other iterations
are covered as well. For example, the conclusions of the last three examples remain valid if
we replace "(almost) cyclic" by "weighted." Similarly, adjusting Theorem 5.2 yields various
examples on norm converge.
The following results on weak convergence follow readily from Theorem 3.20.(i).
EXAMPLE 6.11 (Browder’s 17, Thm. 2] for finitely many sets). Suppose the projection algorithm is almost cyclic, unrelaxed, and has constant sets. Then the sequence (x(n) converges
weakly to some point in C.
REMARK 6.12 (cyclic projections). If in the last example "almost cyclic" is replaced by
"cyclic," then one obtains the method ofcyclic projections; the conclusion of the last example
becomes Bregman’s [16, Thm. 1]. The case when the sets Ci do not necessarily intersect is
discussed in some detail in .
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
EXAMPLE 6.13 (Crombez’s [38, Thm. 3]). Suppose the projection algorithm is weighted
and has constant sets
Suppose further the relaxation parameters and weights satisfy 0 <
_= )i for every index
and all n. Then the sequence (x(n))
converges weakly to some point in C.
REMARK 6.14. Crombez assumed in addition that one of the sets is the entire space
(which has the identity as projection).
Consideration of remotest sets control.
EXAMPLE 6.15 (Gubin, Polyak, and Raik’s [60, Thm. 1.(a)] for finitely many sets). Suppose the projection algorithm has remotest set control and constant sets. Suppose further there
is some e > 0 s.t. e < otm < 2
e for every index
and all n active for i. If there is some
index j 6 {1
then the sequence (x()) converges linearly to some point in C.
Proof The projection algorithm is linearly focusing and the N-tuple (C1
boundedly linearly regular (Corollary 5.14 and Remark 5.15). The result follows from Theorem 5.8.
EXAMPLE 6.16 (Bregman’s
16, Thm. 2] for finitely many sets). Suppose the projection
algorithm is unrelaxed and has remotest set control and constant sets. Then the sequence (x("))
converges weakly to some point in C.
Proof. It is immediate from Theorem 4.26.(ii).
Subspaces.
EXAMPLE 6.17 (Browder’s [17, Cor. to Thm. 3]). Suppose the projection algorithm is
almost cyclic, unrelaxed, and has constant sets that are closed subspaces. If
is closed, then the sequence (x (n)) converges linearly.
Proof Combine Theorems 5.7 and 5.19.
EXAMPLE 6.18 (a remark on Smith, Solmon, and Wagner’s [94, Thm. 2.2]). Suppose the
projection algorithm is cyclic, unrelaxed, and has constant sets that are closed subspaces. If
the angle between
()... ["1 CN
is positive for every index
}, then the sequence (X (n)) converges linearly.
Proof Combine Theorems 5.7 and 5.11 and Proposition 5.16.
REMARKS 6.19.
In the last two examples, the two quite different looking hypotheses on the subspaces
turned out to be special instances ofbounded linear regularity. This, together with
Theorem 5.7, explained linear convergence.
It follows from Amemiya and Ando’s work that the limits of the sequences of the
two previous examples equal
The grandfather of these results on subspaces is the following.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
Suppose the projection algorithm is cyclic, unrelaxed, and has constant
sets that are closed subspaces.
Then the sequence (x(n) converges in
norm to Pcxo
The 2-subspace version is due to von Neumann [103, Thm. 13.7]; Halperin [61,
Thm. 1 proved the N-subspace version. The reader will note that there is no hypothesis on the subspaces (and, however, no conclusion on the rate ofconvergence). Since
bounded regularity and linear regularity ofan N-tuple ofsubspaces are the same (Theorem 5.19), our framework is incapable of recapturing the von Neumann/Halperin
result. For applications, though, one is often interested in linear convergence resuits. Those follow under additional hypotheses that imply regularity (see the last
two examples) and are thus covered by our framework. The best and most complete
reference on the von Neumann/Halperin framework and its impressive applications
is Deutsch’s survey article ; see also Deutsch and Hundal’s recent .
Although mathematically intriguing, controls that are different from intermittent or
remotest set control seem to be oflittle use for applications; consider, for example, two
closed subspaces with closed sum and with intersection {0}. A singular unrelaxed
projection algorithm for these two sets converges linearly whenever its control is
intermittent or considers remotest sets (cf. Theorems 5.7 and 5.8). However, if we
consider, for example, the random control version where we project onto the first
subspace whenever n is a power of 2, and onto the second subspace otherwise, then
the resulting sequence (xn) is not linearly convergent.
Hyperplanes. Hyperplanes play an important role in applications for two reasons. First,
the solution of a system of linear equations is nothing but the intersection of the corresponding
hyperplanes.
Second, projections onto hyperplanes can be calculated easily.
In fact, if a
hyperplane Ci is given by
{x E X: (ai, x) --bi}
for some ai
X \ {0} and bi G ], then, for every x 6 X,
ai and d(x, Ci)
Intermittent control.
EXAMPLE 6.20. Suppose the projection algorithm is intermittent and has constant sets
that are hyperplanes. Suppose further there is some e > 0 s.t. e < 0/}
e and e < }n)
for all large n and every index
active at n. Then the sequence converges linearly to some
point in C with a rate independent of the starting point.
Proof. Combine Theorem 5.7 and Corollary 5.22.
The following special cases of the last example are well known.
EXAMPLE 6.21 (Herman, Lent, and Lutz’s [64, Cor.
], Trummer’s [97, Thm. 5]). Suppose
X is finite dimensional and the projection algorithm is cyclic and has constant sets that are
hyperplanes. Suppose further there is some
e for all large n and
every index
active at n. Then the sequence (x(n) converges linearly to some point in C with
a rate independent of the starting point.
EXAMPLE 6.22 (Kaczmarz , Gordon, Bender, and Herman ). Suppose X is finite
dimensional and the projection algorithm is cyclic, unrelaxed, and has constant sets that are
hyperplanes.
Then the sequence (x(n) converges linearly to some point in C with a rate
independent of the starting point.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
REMARKS 6.23.
The precursor of these results is certainly the last example, which was discovered by
Kaczmarz as early as 1937.
Kaczmarz’s method is well understood even in the infeasible case; we refer the
interested reader to Tanabe’s and Trummer’s .
The iteration described in Example 6.21 is also known as "ART" (algebraic reconstruction technique).
EXAMPLE 6.24 (Trummer’s [97, first part of Thm. 1]). Suppose X is finite dimensional
and the projection algorithm is cyclic and has constant sets that are hyperplanes.
defined as in Theorem 5.2 and Yn 1)n
-’-’(X), then the sequence (x(n)) converges in norm to
some point in C.
Proof It is immediate from Theorem 5.2.
REMARKS 6.25.
Trummer also investigated the infeasible case; see .
Using Theorem 5.2, we can similarly recapture Trummer’s [97, second part of
], where he describes an iteration that yields a nonnegative solution (assuming
there exists at least one).
REMARK 6.26.
Herman et al. used block control variants of Example 6.20 for
image reconstruction.
Their algorithms are based on a (more matrix-theoretic) framework
by Eggermont, Herman, and Lent .
Weighted control.
EXAMPLE 6.27 (Trummer’s [98, Thm. 8]).
Suppose X is finite dimensional and the
projection algorithm is weighted, unrelaxed, and has constant sets that are hyperplanes Ci
bi }. If the weights are given by
E--a Ilaj 112’
then the sequence (x (n)) converges linearly to some point in C.
Proof The control is 1-intermittent; thus, the result follows from Example 6.20.
REMARK 6.28. Trummer even allowed infeasible systems and identified the limit; see .
THEOREM 6.29. Suppose the projection algorithm is weighted and has constant sets that
are hyperplanes Ci
bi }. Suppose further there exists a subsequence
(n’) of (n) and some
’) for all n
and every index
If span {a
is at least two dimensional, then the sequence (xn)) converges in norm
to some point in C.
Proof. Without loss of generality, we assume ]]ai
1 for every index i. Fix x 6 C.
Then, by Lemma 3.2.(i),
(n)_ Pjx(n)
for all n > 0. Summing over n and remembering that each set Ci is a hyperplane, we obtain
a convergent series whose general term
((ai,x (n))
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
tends to O. Hence, along the subsequence (x(n’)), we have
((ai, x (n’))
((aj, x(n’))
bj)aj ---+ 0
Now fix any index
and obtain another index j
s.t. {ai, aj
are linearly independent.
Then, by (,),
(ai, x (n’))
bi ----+ O.
Thus d(x(’, Ci)
[(ai, x(n’)
has been chosen arbitrarily, we conclude
max{d(x(n’, Ci)
and further, by linear regularity of (C1
CN) (Corollary 5.22),
The result follows from Corollary 3.3.(ii).
The following classical example is now obvious.
EXAMPLE 6.30 (Cimmino’s method in Hilbert space). Suppose the projection algorithm is weighted and has constant sets that are hyperplanes Ci
Suppose further the relaxation parameters and weights satisfy
for all n >_ 0 and every index i.
If span {al
aN} is at least two dimensional, then the
sequence (x()) converges in norm to some point in C.
REMARKS 6.31.
For Euclidean spaces, the last example was known to Cimmino as far back as 1938.
His method has a nice geometric interpretation: one obtains x (n+l) from x (n) by
reflecting x () in all N hyperplanes and then taking a weighted average.
As Example 3.6 shows, the assumption on span {al
aN} is essential.
Due to their parallelizability, Cimmino’s and related methods with weighted control
are currently used with great success; see Censor’s survey article .
We present a variation ofCimmino’s method that includes a method suggestedby Ansorge.
EXAMPLE 6.32 (a generalization of Ansorge’s method ). Suppose X is finite dimensional and the projection algorithm has constant sets where CN
X. Suppose further that
1, X’= AN > 0, oI
") ...= o/)_.1
)N)f(d(x (n), Ci))
7=1 f(d(x (n), Cj))
for some strictly increasing continuous function f
[0, +or[ --
[0, +cx[ with f(0)
Then the sequence (x (n)) converges in norm to some point in C.
Proof. Clearly, the projection algorithm is strongly focusing and considers remotest sets.
The N-tuple (C1
CN) is boundedly regular (Proposition 5.4.(iii)). Suppose that (i()) is
a sequence of active remotest indices. Then
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
If -n a(n)
"--OO, then we are done by Theorem 5.3. Otherwise Zn "i(n) < "--(X) and hence
---+ O. Now (x(")) is bounded and f is continuous; thus (_,j f(d(x (’) Cj))),, is a
bounded sequence. Consequently,
f(d(x (n), Ci)) < f(d(x (n), Ci.)) --’-+ 0
for every index i,
which implies that
max{d(x(n, Ci)
1... N} ----+ O.
Because of the bounded regularity of (C1
CN), we get d(x (n), C)
-----+ 0; now Corollary 3.3.(ii) completes the proof.
REMARK 6.33. Ansorge’s method arises when the sets C1
Cv-1 are hyperplanes
andf=l.lfory >0.
Halfspaces. Halfspaces play an important role for essentially the same reasons hyperplanes do:
their intersection describes the solution of the corresponding system of linear
inequalities (this problem is also referred to as the linearfeasibility problem) and the projections are easy to calculate. Indeed, if a halfspace Ci is given by
(ai, x) < bi}
for some ai
X \ {0} and bi , then, for every x 6 X,
ai and d(x, Ci)
Some of the algorithms for finding a solution of the linear feasibility problem discussed below
have been used with great success in radiation therapy treatment planning; we refer the reader
to Censor, Altschuler, and Powlis’s interesting survey article .
Intermittent control.
EXAMPLE 6.34. Suppose the projection algorithm is intermittent and has constant sets
that are halfspaces. Suppose further there is some
for all large n and every index
active at n. Then the sequence (x<) converges linearly to
some point in C with a rate independent of the starting point.
Proof. Combine Theorem 5.7 and Fact 5.23.
We deduce readily the next two examples.
EXAMPLE 6.35 (Gubin, Polyak, and Raik’s [60, Thm. 1.(d)], Herman, Lent, and Lutz’s [64,
]). Suppose the projection algorithm is cyclic and has constant sets that are halfspaces.
Suppose further there is some
for all large n and every index
active at n. Then the sequence (x(n) converges in norm to some point in C.
REMARKS 6.36. By Example 6.34, the rate ofconvergence ofthe sequence (x(n)) is actually
linear and independent of the starting point. Herman, Lent, and Lutz assumed additionally
that X is finite dimensional. Mandel [78, Thm. 3.1] offered an upper bound for the rate of
convergence for the case when X is finite dimensional and 0 < or}nl
EXAMPLE 6.37 (Censor, Altschuler, and Powlis’s [25, Alg. 3]). Suppose the projection
algorithm considers only blocks and has constant sets that are hyperplanes. Suppose further
there is some
> 0 s.t. e < 0/}
e for all n > 0 and every index i. Suppose finally that
for every index i, there is some i > 0 s.t. ,}n)
,i for all n active for i. Then the sequence
(x(n) converges linearly to some point in C with a rate independent of the starting point.
REMARKS 6.38. Censor, Altschuler, and Powlis offered no results on convergence;
however, Aharoni and Censor’s [3, Thm. 1] yields norm convergence of (x(n) in Euclidean
spaces. We thus add two features. First, we remove the restriction on finite dimensionality.
Second, we establish linear convergence.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
Weighted control. The following two examples are also consequences ofExample 6.34.
EXAMPLE 6.39 (Eremin’s [52, Cor. to Thm. 1.2]). Suppose the projection algorithm is
weighted and has constant sets that are halfspaces. Suppose further the relaxation parameters
and weights satisfy
0 < oln) Ol < 2,
for every index
and all n. Then the sequence (x (n)) converges linearly to some point in C
with a rate independent of the starting point.
EXAMPLE 6.40 (the feasible case of De Pierro and Iusem’s [39, Lem. 8]). Suppose X
is finite dimensional and the projection algorithm is weighted and has constant sets that are
halfspaces. Suppose further there is some e > 0 s.t. e < ot
e, 0 < )n)
for every index
and all n. Then the sequence (x(n) converges in norm to some point in C.
REMARKS 6.41. In the last example, the rate of convergence of the sequence (x(n) is
actually linear and independent of the starting point. For a slightly more restrictive scheme,
De Pierro and Iusem could also identify the limit of (x(n) in the infeasible case as a least
squares solution; see .
Consideration of remotest sets control.
EXAMPLE 6.42. Suppose the projection algorithm considers remotest sets and has constant
sets that are halfspaces. Suppose further that (i (n) is a sequence of active remotest indices.
If limti(, > 0, then the sequence (x(n) converges linearly to some point in C with a rate
independent of the starting point.
Proof Combine Theorem 5.8 and Fact 5.23.
EXAMPLE 6.43 (Gubin, Polyak, and Raik’s [60, Thm. 1.(d)]). Suppose the projection
algorithm has remotest set control and constant sets that are halfspaces. If there is some 6- > 0
s.t. 6- < ot
6- for all n and every index
active at n, then the sequence (x(n) converges
linearly to some point in C with a rate independent of the starting point.
Proof. We have for any index
active at n,
(n) (n)(2- Yf=l Aj
(2- 0n)) >
the result thus follows from the previous example.
The basic result in this subsection is due to Agmon and Motzkin and Schoenberg. It dates
back to as early as 1954.
EXAMPLE 6.44 (Agmon’s [1, Thm. 3], Motzkin and Schoenberg’s [83, Case 1 in Thm. 1
and Thm. 2]). Suppose X is finite dimensional and the projection algorithm has remotest set
control and constant sets that are halfspaces. If 0 < o/}n)
19/ < 2 for all n and every index
active at n, then the sequence (x() converges in norm to some point in C.
Proof. This is a special case of the preceding example.
REMARKS 6.45.
While Agmon considered only the case when ot
1, he already obtained linear
convergence of (x) with a rate independent of the starting point.
Motzkin and Schoenberg did not establish linear convergence; they discussed, however, the case when ot
It follows from Example 6.43 that the rate of convergence is linear and independent
of the starting point. Again, Mandel provided an upper bound for the rate; see [78,
Thm. 2.2].
THEOREM 6.46. Suppose N > 2, the projection algorithm has constant sets that are
halfspaces Ci
(ai x) <_ bi }, and violated constraints correspond exactly to active
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
indices; i.e., ifx (n)
Supposefurther that there is some
> 0 s.t. e < otn), )In) for all large n and every index
active at n and that
I(n)= {i} implies otn) < 2-e.
Suppose finally that if and j are two distinct indices, then
either {ai, aj
is linearly independent
Cj (equivalently, X \ Cj
but never both.
Then the sequence (x (n)) converges in norm to some point in C.
Proof We assume without loss that Ilai
1 for every index
and that x (n)
all n (otherwise, the projection algorithm becomes constant anyway). Clearly, the projection
algorithm is linearly focusing and considers remotest sets, so let (i (n)) be a sequence of active
remotest indices. Since the N-tuple (C
CN) is linearly regular (Fact 5.23), we can also
assume that Yn
phi(n) < .gf_ (otherwise, we are done by Theorem 5.3). Hence
.(n) (n)(2- E;= Lj
Ai(n)oti(n)
I (n) is not a singleton
for all large n.
Otherwise, there would be a subsequence (n’) of (n) s.t. I (n’)
{i(n’)}. On the other
hand, iCn’
> e2, which would contradict t*iCn ----+ O. Hence Claim 1 is
By Claim 1, we can find a subsequence (n’) of (n) and two distinct indices i, j s.t.
{i,j}_I (n’)
for alln’.
{ai, aj} is linearly independent.
Otherwise, X \ Ci c_ Cj. Since x’’
Ci, we would conclude x’’
Cj, which would
contradict j
In’. Thus Claim 2 holds.
Similarly to the proof of Theorem 6.29, we get
Pix(n’)- Pjx
(n’) ---+ 0
((ai,x(n’)) --bi)ai- ((aj, x (n’))
Now (ai, x(n’))
d(x (n’), Ci) and (aj, x (n’))
d(x (n’), Cj); hence Claim 2 implies
in particular that d(x (’) Ci) ---> O, or, recalling that
(n’) _= i,
max{d(x (n’), Cl)
1... N} ---+ O.
The linear regularity of (C
CN) yields d(x (’), C)
Now apply Corollary
EXAMPLE 6.47 (Censor and Elfving’s framework [26, Alg. 1]).
Suppose X is finite
dimensional, N >
2, and the projection algorithm has constant sets that are halfspaces.
Define 1(n)
x (n) q Ci} for alln > 0, and letml
given constants with
1. Suppose further the relaxation parameters and weights
are chosen according to the following cases.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
/-(n) is empty. Then choose the relaxation parameters and weights as you wish (the
projection algorithm becomes constant anyway).
{i(n)} is a singleton. Then set
n) :=--2mi(n and I (n "-{i(n}.
t("l contains at least two indices Then set
ifx () 6Ci,
ffn) : 2 and Zn)me
otherwise.
Suppose finally that if
and j are two distinct indices, then
either {ai, aj} is linearly independent
Cj (equivalently, X \ Cj_
but never both.
Then the sequence (x()) converges in norm to some point in C.
Proof This is a special case of the previous example.
REMARKS 6.48.
Censor and Elfving also investigated an iteration [26, Alg. 2] that is more general
than the iteration in Example 6.47. Their method of proof is more matrix theoretic
and is quite different from ours.
They claimed that the last example does not need the hypothesis (.). This is, however, false since otherwise a suitable modification of Example 3.6 would yield a
counterexample.
It is possible to recapture Cimmino’s method (Example 6.30)for pairwise distinct
hyperplanes by describing each hyperplane {x
by the corresponding two halfspaces {x
(ai, x) < bi}, {x E X
(-ai, x) < -bi} and then
applying the previous example.
This nice observation is due to Censor and Elfving. The assumption that the hyperplanes are pairwise distinct is not really severe; it
merely means that "each hyperplane should be counted only once."
REMARK 6.49.
More algorithms for solving the linear feasibility problem are given
Polyhedra. The class of polyhedra is large: it contains the class of halfspaces, the class
ofhyperplanes, and the class of finite-co-dimensional affine subspaces. It is generally not easy
to calculate projections onto polyhedra; there are, however, besides the examples discussed
in the previous subsections, two additional important exceptionshyperslabs and the finitedimensional positive cone.
A hyperslab Ci is given by
(ai, x) <_ bi}
for some ai
X \ {0} and two real numbers ci <_ bi. Then, for every x,
(ai, x))+[
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
The positive cone in X :-d
d}. Its projection is given by x
)i=1 for every
EXAMPLE 6.50 (Censor, Altschuler, and Powlis’s [25, Alg. 4]).
Suppose X is finite
dimensional and the projection algorithm has constant sets that are hyperslabs except CN
X+. Suppose further the projection algorithm considers only blocks, where the number of
blocks is M and JM
{N}. If there is some
< ot" _< 2
< )" for all n
and every index
active at n, then the sequence (xn) converges linearly to some point in C
with a rate independent of the starting point.
Proof By Corollary 5.26, the N-tuple (C
CN) is linearly regular. Now apply
Theorem 5.7.
REMARK 6.51. Again, Aharoni and Censor’s [3, Thm. 1] guarantees norm convergence.
We obtain in addition linear convergence.
7. Harvest time III: Subgradient algorithms.
Theory. We return to the setting of 4, where we defined projection algorithms. Loosely
speaking, "a projection algorithm that for at least one index
chooses its supersets C
Ci to be halfspaces constructed from subgradients of a fixed convex function" is called a
subgradient algorithm. Before we make this "construction" precise, we collect some basic
facts on subgradients.
DEFINITION 7.1. Suppose f
I is a convex function. Given a point x0 6 X, the
X" (x*, x -xo) < f (x)
f (xo) for all x 6 X}
is called the subdifferential of f at xo and is denoted Of(xo). The elements of Of(xo) are
called subgradients of f at xo. If Of(xo) is nonempty, then f is said to be subdifferentiable
The importance of this concept stems from the easy-to-verify fact that
x0 is a minimizer of f
Deeper are the following facts: for proofs see, for example, Ekeland and Temam’s [50,
Chap. I: Cor. 2.5, Prop. 5.3, Prop. 5.2, and Cor. 2.3].
FACTS 7.2. Suppose f
is a convex function and x0 6 X. Then
(i) f is continuous at x0 and Of (xo) is a singleton if and only if f is lower semicontinuous and Gteaux differentiable at x0. In this case, the unique subgradient of f at x0 coincides
with the Gteaux derivative of f at x0.
(ii) If f is continuous at x0, then f is subdifferentiable at x0.
(iii) If X is finite dimensional, then f is continuous and subdifferentiable everywhere.
LEMMA 7.3. Suppose f
is a convexfunction, xo
X, and f is subdifferentiable at xo. Supposefurther S := {x
f (x) < 0} is nonempty. For any g(xo)
define the closed convex set H by
H "= H(f, xo, g(xo)) "= {x
f(xo) + (g(xo), x
S. Ifg(xo) =/= O, then H is a halfspace; otherwise, H
Ilg(x)llZ g(x)
otherwise.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
(iii) d(xo, H)
iff (xo) > O,
otherwise.
Proof. (i): If s a S, then f (xo) + (g(xo), s
xo) < f(s) < 0 and hence s
Use Facts 1.5.(ii) to verify the candidate for Pl4Xo.
(iii) follows immediately
from (ii).
REMARK 7.4. The importance of the halfspace defined in the last lemma is explained by
the following. Suppose we want to find a point in S; i.e., we look for a solution of the convex
feasibility problem f(x) < O.
If f(xo) < O, then we are done. Otherwise f(xo) > 0.
is usually "hard" to solve f(x)
0 (otherwise, we would just solve); therefore, we instead
consider afirst-order approximation of f, say
f(x) "= f(xo) + (g(xo), x
for some g(xo)
and solve f(x0)
0, to which a solution is given by
IIg(x0)II 2 g(xo).
We now give the precise definition of a subgradient algorithm.
DEFINITION 7.5. Suppose for some index
N} and for all n every set Cn of a
given projection algorithm is of the form
n(fi, x (n), gi(x(n)))
fi(x (n)) "Jt- (gi(x(n)),x
x (n)) < O}
for some fixed convex function j5
, where j5 is subdifferentiable at every x n) and
Ofi (xn). Suppose further that
X" fi(x) 5 0}.
Then we call this projection algorithm a subgradient algorithm. Every such index
a subgradient index; the set of all subgradient indices is denoted I0.
REMARKS 7.6.
Subgradient algorithms and projection algorithms are closely related in the following
(i) Every subgradient algorithm is a projection algorithm (by definition).
(ii) Every projection algorithm with constant sets can be viewed as a subgradient algorithm. To see this, one chooses fi := d(., Ci) and takes into account
NCi (X) ("] BX
otherwise,
where Nci (x)
x, x*) < 0} is the normal cone of Ci at x.
The aim of subgradient algorithms is to solve convex feasibility problems. For a good
survey on subgradient algorithms and other methods for solving convex feasibility
methods, see Censor’s .
The reader should be warned that our use of the term "subgradient algorithm" is not
quite standard. In the literature, "subgradient algorithms" may refer to considerably
more general algorithms; see, for example, Shor’s .
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
We now provide a fairly large class of focusing subgradient algorithms to which our
previous results are applicable.
THEOREM 7.7 (prototype of a focusing subgradient algorithm).
Given a subgradient
algorithm, suppose the subdifferentials off are nonempty and uniformly bounded on bounded
setsfor every index
Io. Supposefurther Pi(n)) converges actively pointwise to Pi for every
N} \ Io. Then the subgradient algorithm isfocusing.
Fix an index
N}. Suppose (x(n)) is a subsequence of (x() with
--+ O, and
is active at nk for all k. We must show that x
In view of Lemma 4.2, we need only consider the case when
Io. Then, by weak lower
semicontinuity of )6,
j(x) _< limjS(x(").
If j (x(n) < 0 infinitely often, then clearly f/(x) _< 0 and so x
Ci. Otherwise f/(x() > 0
for all large k. Since the sequence (x(n)) is bounded, there is some M > 0 s.t. the norm of
every subgradient of f/at x( is at most M. Thus, by Lemma 7.3.(iii),
0 +-- d(x(), C{))
Ilgi(x(n))l
hence j(x (n)) --+ 0. Therefore, f/(x) < 0 and x
The property that 0j5 is uniformly bounded on bounded sets is a standard assumption for
theorems on subgradient algorithms; see, for example, . We now characterize
this property.
PROPOSITION 7.8 (uniform boundedness of subdifferentials on bounded sets). Suppose
X -----+ ]R is a convexfunction. Then thefollowing conditions are equivalent.
(i) f is bounded on bounded sets.
(ii) f is (globally) Lipschitz continuous on bounded sets.
(iii) The subdifferentials off are nonempty and uniformly bounded on bounded sets.
Proof. "(i)==,(ii)" can be found in Roberts and Varberg’s [88, Proof of Thm. 41.B].
"(ii)==(iii)": By Facts 7.2.(ii), f is subdifferentiable everywhere. It is enough to show
that the subgradients of f are uniformly bounded on open balls centered at 0. So fix r > 0
and obtain (by assumption) a Lipschitz constant for f on int rBx, say L. Now fix x 6 int rBx
and get s > 0 s.t. x + sBx c_ int rBx. Pick any x*
Of (x) and b
(x*, sb) < f (x + sb)
f (x) < Lsllbll;
thus IIx*ll
sup(x*, Bx) < L and therefore the subgradients of f are uniformly bounded on
int rBx by L.
"(iii)==(i)":
It is enough to show that f is bounded on rBx for every r >
assumption, there is some M > 0 s.t. the norm of any subgradient of f at any point in rBx is
atmostM. Fixx
rBx. On the one hand, pickx*
Of(x). Then (x*, 0-x) < f(O)-f(x);
thus f(x) <_ f(O) + (x*, x) < f(O) + Mr. Hence f is bounded above on rBx by f(0) + Mr.
On the other hand, picking x
Of (0) shows similarly that f is bounded below on rBx by
Mr. Altogether, f is bounded on rBx and the proof is complete.
COROLLARY 7.9. If X is finite dimensional, then every convex function from X to N is
subdifferentiable everywhere and its subdifferentials are uniformly bounded on bounded sets.
Proof. By Facts 7.2.(iii), any convex function from X to R is continuous everywhere.
Since X is finite dimensional, this function attains its minimum and maximum on bounded
closed sets; in particular, it is bounded on bounded closed sets. The result now follows from
the previous proposition.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
REMARKS 7.10.
The last corollary implies that if X is finite dimensional, then every convex function
from X to IR can be used in Theorem 7.7.
As the following example demonstrates, the assumption that X is finite dimensional in
the last corollary cannot be dropped. Consequently, the convex function constructed
below cannot be used in Theorem 7.7.
EXAMPLE 7.11. Define the function f by
]I{" x. (Xn)
Then f is everywhere finite, convex, continuous, and subdifferentiable. However, on Bx,
neither is the function f bounded nor are the subdifferentials of f uniformly bounded.
Proof Fix an arbitrary x
(xn) 6 X. Then, on the one hand, Xn
O. On the other
---+ 1. Hence, eventually
thus f (x) is finite. Also, f is, as the supremum of convex and lower semicontinuous functions
convex and lower semicontinuous too. Therefore, f is everywhere continuous (see, for example, [50, Chap. I: Cor. 2.5]) and subdifferentiable (Fact 7.2.(ii)). Choosing x
vector in X shows that
sup f(Bx) > f(x)= n;
thus f is unbounded on Bx. The proof of "(iii)===(i)" in the last proposition shows that the
subgradients of f are not uniformly bounded on Bx.
Under a Slater-type constraint qualification, we even obtain linearly focusing subgradient
algorithms.
THEOREM 7.12 (prototype of a linearly focusing subgradient algorithm). Given a subgradient algorithm, suppose that there is some Slater point
and that the subdifferentials of f are nonempty and uniformly bounded on bounded setsfor
every subgradient index
Io. Supposefurther there is some
fld(x (n), Ci)
d(x(), C}n))
for every index
N} \ Io and all large n activefor i. Then the subgradient algorithm
is linearlyfocusing.
Proof Fix any index
N}. It is sufficient to show that there is some/i > 0 s.t.
tid(x (n) Ci) <_ d(x(, C})
for all large n active for i.
N} \ Io. Then/i
/ does the job for (,).
Since (x (n)) is bounded, there is someM > 0 s.t. for alln > 0,
_< M and the norm of every subgradient of
at every x (") is at most M. Now
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
fix n active for i. Without loss, we assume that j (x (n)) > 0 (otherwise, (,) holds trivially).
6-’---f/()>0,
)): + )x()) _< (1
))j () + )fi (x ("))
We estimate
d2(x (n), Ci)
(f/(x(n)) )
j5 (x(") +
< (J(X(n)))
d(x(, C)llgi(x()l
Therefore, (.) holds with fli
6-/M2 and the proof is complete.
Censor and Lent’s framework. We investigate in this subsection a framework essentially suggested by Censor and Lent . They considered (cf. Example 7.14) subgradient
algorithms where every index is a subgradient index; i.e., Io
C=. N Ci-Nx
is the set of solutions of the convex feasibility problem
fi(x) <_ 0
where each j is a continuous convex function from X to R.
THEOREM 7.13 (Censor and Lent’s framework in Euclidean spaces). Suppose X is finite
dimensional. Then the sequence (x() converges in norm to some point in C whenever one
ofthefollowing conditions holds.
0for every index i.
(i) (random control) li___mn:n activefor
(ii) (intermittent control) The subgradient algorithm is p-intermittent and Yn Vn
+CX (where Vn is defined as in Theorem 3.20.(ii)).
Proof. By Theorem 7.7 and Corollary 7.9, the subgradient algorithm is focusing. Now
(i) follows from Corollary 3.12, whereas (ii) is immediate from Corollary 3.25.
We now obtain Censor and Lent’s fundamental result as a special case of the last theorem.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
EXAMPLE 7.14 (Censor and Lent’s [28, Thm.
]). Suppose X is finite dimensional and the
subgradient algorithm is almost cyclic. Suppose further there is some
for all n and every index
active at n. Then the sequence (xn) converges in norm to
some point in C.
THEOREM 7.15 (Censor and Lent’s framework in Hilbert spaces). Suppose the projection algorithm is p-intermittent and the functions fi have nonempty and uniformly bounded
subdifferentials on bounded sets.
(i) If li__mn:n activefor
> 0 for every index i, then the sequence (xn) converges
weakly to some point in C.
(ii) IfYn vn
+cxz (where Vn is defined as in Theorem 3.20.(ii)), then the sequence
(xm) has a (unique) weak cluster point in C.
Proof. By Theorem 7.7, the subgradient algorithm is focusing. The result is now immediate from Theorem 3.20.
EXAMPLE 7.16 (Eremin’s [52, Thm. 1.1 for convex functions and subgradients]). Suppose
1 and fl has nonempty and uniformly bounded subdifferentials on bounded sets.
(i) If there is some
< 1, then the sequence (x") converges weakly
to some point in C.
(ii) If limn otl" < 2 and Zn O/I
"-OO, then the sequence (x) converges weakly
to some point in C.
REMARKS 7.17.
Eremin considered a more abstract iteration scheme.
In view ofTheorem 7.15, the assumptions in Example 7.16 can be weakened to "there
?" for (i), and "Ym /
---o" for (ii).
THEOREM 7.18 (Censor and Lent’s framework with a Slater point). Suppose eachfunction
j has nonempty and uniformly bounded subdifferentials on bounded sets and there is some
Slater point Yc
(c) < O, for every index i. Then the sequence (xn) converges in
norm to some point in X, say x.
+cxzfor every index i, then x E C.
(ii) Ifthe subgradient algorithm is intermittent and there is some
< )n for all large n and every index
active at n, then x
C and the sequence
(xn) converges linearly to x.
Proof By Theorem 7.12, the subgradient algorithm is linearly focusing. The Slater point
: lies in the interior of Ci
j(x) < 0}; thus : 6 int C and (C1
boundedly linearly regular (Corollary 5.14). (i) follows from Theorem 3.20.(iii), whereas (ii)
follows from Theorem 5.7.
EXAMPLE 7.19 (De Pierro and Iusem’s [40, Thm. 2]). Suppose X is finite dimensional
and there is some Slater point
6 C. Suppose further the subgradient algorithm is almost
cyclic and there is some
<_ otn < 2
for all n and every index
active at n.
Then the sequence (xn) converges linearly to some point in C.
Proof Combine Corollary 7.9 and Theorem 7.18.(ii).
REMARK 7.20. De Pierro and Iusem’s proof is different from ours. They obtain Example 7.19 via an investigation of an iteration that converges finitely when a Slater point exists
(but may diverge otherwise).
EXAMPLE 7.21 (Eremin’s [52, Thm. 1.3]). Suppose each function f/has nonempty and
uniformly bounded subdifferentials on bounded sets and there is some Slater point : 6 C. If
0 < )n =- )i and 0 < otn -= oti < 2 for every index i, then the sequence (xn) converges
linearly to some point in C.
The subgradient algorithm is weighted; hence it is 1-intermittent and Theorem 7.18.(ii) applies.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
Polyak’s framework. In this subsection, we concentrate on a framework suggested by
Polyak . He considered a subgradient algorithm where
Hence the set C
fl (x) _< 0} describes the solutions of the convex
feasibility problem
fl(x) _< 0,
where fl is a continuous convex function from X to R.
We can view Polyak’s framework as a special case of Censor and Lent’s framework by
2 and letting f2
d (., C2). We now "translate" some results obtained in the last
subsection to this framework.
For example, Theorem 7.15.(i) becomes the following theorem.
THEOREM 7.22. Suppose theprojection algorithm is 2-intermittent and thefunction f has
nonempty and uniformly bounded subdifferentials on bounded sets. If limn:n activefor
and 2, then the sequence (x(n)) converges weakly to some point in C.
EXAMPLE 7.23 (Polyak’s [86, Thm. 1]).
Suppose the function f has nonempty and
uniformly bounded subdifferentials on bounded sets.
If the subgradient algorithm is cyclic
and there is some e > 0 s.t. e < O/I
converges weakly to some point in C.
A "translation" of Theorem 7.13.(ii) yields the following theorem.
THEOREM 7.24.
Suppose X is finite dimensional.
If the subgradient algorithm is 2intermittent and }-n Vn
+cx (where 13n is defined as in Theorem 3.20.(ii)), then the sequence
(x (n)) converges in norm to some point in C.
EXAMPLE 7.25 (a special case of Allen et al.’s [4, Prop. 7]). Suppose X is finite dimensional, the subgradient algorithm is cyclic, and there is some e > 0 s.t. 0 < O/2n < 2
for all n _> 0. If Z,, O/2,
+cx, then the sequence (x()) converges in
norm to some point in C.
Proof. The subgradient algorithm is certainly 2-intermittent; hence define Vn as in The-
(2n)-. Therefore, Yn v,
orem 3.20.(ii) and check that v
the result follows from Theorem 7.24.
REMARKS 7.26.
An inspection of the proof shows that we can replace the assumptions on (O/I2n)) by
the more general "n, etl’(2n (2- O/I2
Allen et al. also investigated the situation where it is allowed that fl takes the
value +x and C is empty.
The next theorem does not follow from Censor and Lent’s framework. The necessary
work, however, is modest.
THEOREM 7.27. Suppose the subgradient algorithm is intermittent and there is some
C2 with f (c) < O. Supposefurther f has nonempty and uniformly bounded subdifferentials
on bounded sets. Ifthere is some e > 0 s.t. e < O/i
e and e <_ i
for all large n and
every index
active at n, then the sequence (x(m) converges linearly to some point in C.
Proof. By Theorem 7.12, the subgradient algorithm is linearly focusing.
C2 f int C1, the pair (C1, C2) is boundedly linearly regular (Corollary 5.14). Now apply
Theorem 5.7.
EXAMPLE 7.28 (a case of Polyak’s [86, Thm. 4]). Suppose the subgradient algorithm
is cyclic and there is some
6 C2 with f (,) < 0. Suppose further f has nonempty and
uniformly bounded subdifferentials on bounded sets. If there is some
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
for all n, then the sequence (x (n)) converges linearly to some
point in C.
REMARKS 7.29. On first sight, Polyak’s framework looks fairly special since it deals
only with one function. A standard trick, however, allows one to handle finitely many convex
functions. Suppose we are given M continuous convex functions 1
qM from X to R. If
we want to solve the convex feasibility problem
then we simply set
i (x) < 0,
fl :=max{el
C1 :={x EX: f(x) <_0},
and we see that C
C 7 C2 are precisely the solutions of the above problem. Hence all
methods discussed in this subsection are applicable. For example, the reformulation of the
last theorem to this situation yields a partial generalization of Polyak’s [86, Thm. 6]. It only
remains to describe Ofl. The reader can find a formula in Ioffe and Tihomirov’s book [68,
Thm. 3 on p. 201f] that becomes in our setting
Off (x) =conv
A generalization of Dos Santos’s framework. In this section, we discuss a generalization of a framework due to Dos Santos (cf. Example 7.34). On first sight, this framework
looks like a subgradient algorithm; it is, however, actually a projection algorithm as defined
in 4. It works as follows.
Suppose we are given M continuous convex functions i, from X to R that are partitioned
into N (< M) "blocks," where the ith block consists of Mi functions
for every index i,
so that M +... + MN
i,k(X) 5 0 for k
for every index i;
/N=I Ci is the set of solutions of the convex feasibility problem
i,:(x) <0,
As always, we assume feasibility; i.e., C is nonempty.
Given a point x (n), we define N continuous convex functions
,k(X(l’l))
X -.---+ It
where we use the convention that
and where Oi,(x(n))
Oi,(x(n) and
are nonnegative real numbers with1 i,k
for every index
Mi. We further set
(nl(x(n)) :=
for every index
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
and note that gn) (x(n)) E Ofi
(n) (x(n)). Sticking to the notation ofLemma 7.3, we finally define
N closed convex sets by
n) "= H(fi(n),x(n, gn(x(n))
for every index i.
Then Lemma 7.3 (and the convention
:= 0) yields the following lemma.
LEMMA 7.30. For every index
and all n >_ O,
x" f,()i (x) _< 0}
,k(x) <_ 0}
(ii) Pi(x(
(iii) d(x(, Cn)
By Lemma 7.30.0), we are thus given a projection algorithm to which we refer as the
generalizedDS algorithm. Dos Santos gave an excellent motivation for a special case
of the generalized DS algorithm. Of course, now we wish to bring our convergence results
into play; hence, we must know what makes a generalized DS algorithm (linearly) focusing.
DEFINITION 7.31 (control).. We say that the generalized DS algorithm considers most
violated constraints if there is some v > 0 s.t. for every index i, there is some k 6
toi,k >_ z
for all n _> 0.
THEOREM 7.32 (prototype of a (linearly) focusing generalized DS algorithm). Suppose
the generalized DS algorithm considers most violated constraints and thefunctions dpi, have
nonempty and uniformly bounded subdifferentials on bounded sets.
(i) Then the generalized DS algorithm isfocusing.
(ii) Suppose that in additionfor every index
at least one of the following conditions
1. There is some Slater point i
)i,k (.i) < 0
for every k
2. Each )i,k is a distancefunction to some closed convex set Ci,k and the Mi-tuple
is boundedly linearly regular.
Then the generalized DS algorithm is linearlyfocusing.
Proof. First, we get L1 > 0 s.t. []7ti,k(X(n)[[ < L1 for all n > 0, every index i, and all
Second, we get r > 0 s.t. for all n > 0 and every index i,
"(" > r for
b/+ (X (n)
). Now fix an index
and n > 0 and
assume (without loss, as we will see) that x(
C. It is convenient to abbreviate
qk :--i,+k (X (n)
l[ri,k (X (n)
iii,(x(.))ll, z "-iii,g(x())ll
and to let any appearing k’s range in {k 6
0}. Using the convexity of
and (.)2, we estimate
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
(n) (x(n))
[[g}n)(x(n))l[
k 09kqkZkll
> (Y cq)2 E coqk.
By choice of r and L1, we conclude that
d(x) C)) >
for every index
and all n > 0.
Note that if xn
C, then (,) holds trivially.
If (x’) is a weakly convergent subsequence of (xn) with weak limit x and
0, then, by (,)
limn, max+ (x’) < 0.
is weakly lower
semicontinuous, this implies +
Mi. Hence x
Ci and the generalized DS algorithm is focusing.
(ii): Case 1" Condition I holds. Get L > 0 s.t. I[i
Le for all n
0. Now fix
and n. Define
min {-i,k (.)}
):-e ]0, 1].
min{-i,()} + max{/,+(x(n))}
Then one readily verifies that Oi,k(Y) < 0 for all k; thus y
Ci. We estimate
d2(x(n), Ci) <_ IIx>
< (maxk{i+k(x(n))}) L.
min{-i,k()}
Combining the previous estimate with (.) yields
z min, {--i,k() d(x ("), Ci) < d(x", C{")
for all n > 0.
Case 2: Condition 2 holds. Because (Ci,1
Ci,Mi) is boundedly linearly regular, there
exists some L3 > 0 s.t.
d(x", Ci) < L3 maxd(x", Ci,)
L31naxi,(x")
for all n > 0.
Fix an index i. Combining the last estimate with (.) this time yields
’-f--d(x (n) Ci) 5 d(x (’0 Cn))
for all n > O.
In both cases, we have found an inequality that makes the generalized DS algorithm linearly
Having identified nice classes of (linearly) focusing generalized DS algorithms, we could
now systematically "translate" our previous results to this situation; again, we opt for a small
selection.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
Dos Santos’s original framework. Dos Santos considered the situation when N
and we set L := M1,
bl :’- bl,1
bL :-- I,M1,
1, and b2,1
d(., C2) for some closed convex nonempty set C2. Thus C
C1 ("l C2 is
the set of solutions of the convex feasibility problem
We refer to the generalized DS algorithm in this framework as the DS algorithm.
THEOREM 7.33 (Dos Santos’s original framework). Suppose the DS algorithm is intermittent and considers most violated constraints and there is some E > 0 s.t.
< ;Z}n for all n and every index
active at n. Suppose further each qb has nonempty
and uniformly bounded subdifferentials on bounded sets.
(i) Then the sequence (x (nl) converges weakly to some point in C. Consequently, ifX
isfinite dimensional then the sequence (x(n) converges in norm to some point in C.
(ii) If there is some
C2 s.t. () < Ofor k
L, then the sequence (x
converges linearly to some point in C.
(i): By Theorem 7.32.(i), the DS algorithm is focusing. The result now follows
from Remark 3.13 and Theorem 3.20.(i).
(ii): On the one hand, the DS algorithm is linearly focusing (Theorem 7.32.(ii)). On
the other hand,
6 C2 N int C1, so (C1, C2) is boundedly linearly regular (Corollary 5.14).
Altogether (Theorem 5.7), the sequence (x(n) converges linearly to some point in C.
EXAMPLE 7.34 (Dos Santos’s [47, Thm.]).
Suppose X is finitedimensional, the DS
algorithm is cyclic, and there is some
> 0 s.t. e < 0/I
e and o/n) 1 for all n > 0.
Suppose further 0 < COl,k
=- cok for k
1,..., L. Then the sequence (xn)) converges in
norm to some point in C.
Since COk > 0 for all k, the DS algorithm certainly considers most violated
constraints. Now combine Corollary 7.9 and Theorem 7.33.(i).
REMARKS 7.35.
1, Dos Santos’s and Polyak’s frameworks coincide.
Dos Santos reports good numerical results on his algorithm. Theorem 7.33.(ii) shows
that the qualitative performances of his and Censor and Lent’s frameworks are comparable (cf. Theorem 7.18 and Example 7.19).
The polyhedral framework. The polyhedral framework is the special case of the generalized Dos Santos framework, where bi, is the distance function to some polyhedron Ci, for
every index
Mi. Throughout this subsection, we investigate this situation.
THEOREM 7.36 (polyhedron framework). In the polyhedralframework, suppose the generalized DS algorithm considers most violated constraints. Supposefurther it is intermittent
or considers remotest sets. Suppose finally there is some
< otn <_ 2
<_ )n for all n and every index
active at n. Then the sequence (xn) converges linearly
to some point in C with a rate independent of the starting point.
Proof. For every index i, the Mi-tuple (Ci,1
Ci,Mi) is linearly regular (Corollary 5.26).
Hence, by Theorem 7.32.(ii), the generalized DS algorithm is linearly focusing. Now each Ci
is also a polyhedron; thus by Corollary 5.26, (C1
CN) is linearly regular. Therefore, the
result follows from Theorem 5.7 (for intermittent control) or Theorem 5.8 (if the algorithm
considers remotest sets).
REMARK 7.37. If N
M, each Ci,1 is a halfspace, o)(n)
O)i > 0, and there is some
e > 0 s.t. e < or}n_
E for all n and every index i, then we recapture Example 6.40
(which is due to De Pierro and Iusem ).
We register two more special cases.
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS
EXAMPLE 7.38 (Merzlyakov’s [80, Thm.]). In the polyhedral framework, suppose X is
finite dimensional, N
1, each Cl,i is a halfspace, and the generalized DS algorithm considers
most violated constraints. Suppose further 0 < oI
converges linearly to some point in C with a rate independent of the starting point.
REMARK 7.39. Merzlyakov actually considered a more general version, where the
co(n) need not necessarily sum up to 1
EXAMPLE 7.40 (Yang and Murty’s ). In the polyhedral framework, suppose X is
finite dimensional, each Ci,k is a halfspace, and there is some
> 0 s.t. the generalized DS
algorithm satisfies
for all n, every index i, and all k
Mi. Suppose further the relaxation parameters
satisfy 0 < o
oe < 2 for all n and every index i. Then the sequence (x()) converges
linearly to some point in C with a rate independent of the starting point whenever one of the
following conditions holds.
1. (basic surrogate constraint method: ) N
2. (sequential surrogate constraint method: ) The generalized DS algorithm
is cyclic.
3. (parallel surrogate constraint method: ) There is some e’ > 0 s.t. x (n)
implies )) > e’ for all n and every index i.
Proof Obviously, the generalized DS algorithm considers most violated constraints. The
first condition is a special case of the second one, which in turn follows from Theorem 7.36.
The assumption in the third condition guarantees that the algorithm considers remotest sets;
hence, this case is also covered by Theorem 7.36.
Acknowledgments. It is our pleasure to thank Yair Censor, Frank Deutsch, Sjur Flhm,
Krzysztof Kiwiel, Adrian Lewis, Alex Simoni6, Levent Tunnel, Jon Vanderwerff, and two
referees for helpful suggestions.
Final remarks. This attempt to review and unify is necessarily incomplete--it is impossible to keep track of all relevant manuscripts in the field. We thus wish to apologize to
the contributors who should have been included here but are not. The manuscript is merely
a snapshot of what the authors knew in mid-1993; time, of course, has not stood still. The
manuscripts sent to us recently by Combettes [30-371, Garcfa-Palomares , and Kiwiel
 deal with exciting new generalizations and deserve much attention. A synthesis of a
selection of these results may be found in the first author’s Ph.D. thesis .
active index, 378
active remotest index, 390
Aharoni and Censor’s framework, 389
algorithm, 378
almost cyclic algorithm, 382
almost cyclic control, 382
alternating projections, 386
angle, 396
asymptotically regular algorithm, 378
asymptotically regular sequence, 374
attracting mapping, 372
averaged mapping, 370
block algorithm, 382
block control, 382
bounded linear regularity, 393
bounded regularity, 391
boundedly linearly regular, 393
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
H.H. BAUSCHKE AND J. M. BORWEIN
boundedly regular, 391
Butnariu and Censor’s framework, 390
Censor and Elfving’s framework, 408
Censor and Lent’s framework, 414
Cimmino’s method, 405
consideration of remotest sets control, 390
considers most violated constraints, 418
considers only blocks, 382
considers remotest sets, 390
converges actively pointwise, 381
converges linearly, 371
convex feasibility problem, 367
cyclic algorithm, 382
cyclic control, 382
cyclic projections, 401
demiclosedness principle, 370
distance function, 371
Dos Santos’s original framework, 420
DS algorithm, 420
Fej6r monotone sequence, 375
firmly nonexpansive mapping, 370
fixed points, 370
Flgtm and Zowe’s framework, 389
focusing algorithm, 380
focusing subgradient algorithm, 412
generalized DS algorithm, 418
halfspace, 406
has constant sets, 385
hyperplane, 403
hyperslab, 409
index, 377
intermittent algorithm, 382
intermittent control, 382
intrinsic core, 372
isometry, 370
linear convergence, 371
linear regularity, 393
linearly regular, 393
linearly focusing projection algorithm, 386
linearly focusing subgradient algorithm, 413
linear feasibility problem, 406
Mosco convergence, 385
nonexpansive mapping, 370
overrelaxation, 378
parallel algorithm, 378
parallel control, 378
parallelogram law, 369
Pierra’s product space formalization, 397
Polyak’s framework, 416
polyhedral framework, 420
polyhedron, 372
positive cone, 410
positive part, 372
projection, 370
projection algorithm, 385
random algorithm, 382
random control, 382
random projections, 386
regular, 391
regularity, 391
relaxation parameter, 377
relaxed firmly nonexpansive mapping, 370
remotest set control, 390
sequence of active remotest indices, 390
sequence of the algorithm, 378
singular algorithm, 378
singular control, 378
Slater point, 413
strictly nonexpansive mapping, 370
strict convexity, 369
strongly attractive mapping, 372
strongly focusing projection
algorithm, 386
subgradient algorithm, 411
subgradient index, 411
Tseng’s framework, 381
underrelaxation, 378
unrelaxed algorithm, 378
unrelaxed control, 378
von Neumann’s alternating projection
algorithm, 386
von Neumann/Halperin’s framework, 403
weight, 378
weighted algorithm, 378
weighted control, 378
Downloaded 06/06/13 to 134.148.10.12. Redistribution subject to SIAM license or copyright; see 
ALGORITHMS FOR CONVEX FEASIBILITY PROBLEMS