Collaborative Deep Learning for Recommender Systems
Hong Kong University of
Science and Technology
 
Naiyan Wang
Hong Kong University of
Science and Technology
 
Dit-Yan Yeung
Hong Kong University of
Science and Technology
 
Collaborative ﬁltering (CF) is a successful approach commonly used by many recommender systems. Conventional
CF-based methods use the ratings given to items by users
as the sole source of information for learning to make recommendation. However, the ratings are often very sparse in
many applications, causing CF-based methods to degrade
signiﬁcantly in their recommendation performance. To address this sparsity problem, auxiliary information such as
item content information may be utilized.
Collaborative
topic regression (CTR) is an appealing recent method taking
this approach which tightly couples the two components that
learn from two diﬀerent sources of information. Nevertheless, the latent representation learned by CTR may not be
very eﬀective when the auxiliary information is very sparse.
To address this problem, we generalize recent advances in
deep learning from i.i.d. input to non-i.i.d. (CF-based) input and propose in this paper a hierarchical Bayesian model
called collaborative deep learning (CDL), which jointly performs deep representation learning for the content information and collaborative ﬁltering for the ratings (feedback)
matrix. Extensive experiments on three real-world datasets
from diﬀerent domains show that CDL can signiﬁcantly advance the state of the art.
Categories and Subject Descriptors
H.1.0 [Information Systems]: Models and Principles—
General; J.4 [Computer Applications]: Social and Behavioral Sciences
Recommender systems; Deep learning; Topic model; Text
INTRODUCTION
Due to the abundance of choice in many online services,
recommender systems (RS) now play an increasingly signif-
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for proﬁt or commercial advantage and that copies bear
this notice and the full citation on the ﬁrst page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior speciﬁc permission and/or a fee. Request
permissions from .
KDD’15, August 10-13, 2015, Sydney, NSW, Australia.
c⃝2015 ACM. ISBN 978-1-4503-3664-2/15/08 ...$15.00.
DOI: 
icant role . For individuals, using RS allows us to make
more eﬀective use of information.
Besides, many companies (e.g., Amazon and Netﬂix) have been using RS extensively to target their customers by recommending products
or services. Existing methods for RS can roughly be categorized into three classes : content-based methods, collaborative ﬁltering (CF) based methods, and hybrid methods. Content-based methods make use of user proﬁles or
product descriptions for recommendation. CF-based methods use the past activities or preferences, such as
user ratings on items, without using user or product content
information. Hybrid methods seek to get the best
of both worlds by combining content-based and CF-based
Because of privacy concerns, it is generally more diﬃcult
to collect user proﬁles than past activities.
Nevertheless,
CF-based methods do have their limitations. The prediction accuracy often drops signiﬁcantly when the ratings are
very sparse. Moreover, they cannot be used for recommending new products which have yet to receive rating information from users. Consequently, it is inevitable for CF-based
methods to exploit auxiliary information and hence hybrid
methods have gained popularity in recent years.
According to whether two-way interaction exists between
the rating information and auxiliary information, we may
further divide hybrid methods into two sub-categories: loosely
coupled and tightly coupled methods. Loosely coupled methods like process the auxiliary information once and then
use it to provide features for the CF models. Since information ﬂow is one-way, the rating information cannot provide
feedback to guide the extraction of useful features. For this
sub-category, improvement often has to rely on a manual
and tedious feature engineering process. On the contrary,
tightly coupled methods like allow two-way interaction.
On one hand, the rating information can guide the learning of features. On the other hand, the extracted features
can further improve the predictive power of the CF models
(e.g., based on matrix factorization of the sparse rating matrix). With two-way interaction, tightly coupled methods
can automatically learn features from the auxiliary information and naturally balance the inﬂuence of the rating and
auxiliary information. This is why tightly coupled methods
often outperform loosely coupled ones .
Collaborative topic regression (CTR) is a recently
proposed tightly coupled method. It is a probabilistic graphical model that seamlessly integrates a topic model, latent
Dirichlet allocation (LDA) , and a model-based CF method,
probabilistic matrix factorization (PMF) . CTR is an
 
appealing method in that it produces promising and interpretable results. Nevertheless, the latent representation
learned is often not eﬀective enough especially when the auxiliary information is very sparse.
It is this representation
learning problem that we will focus on in this paper.
On the other hand, deep learning models recently show
great potential for learning eﬀective representations and deliver state-of-the-art performance in computer vision 
and natural language processing applications.
deep learning models, features are learned in a supervised
or unsupervised manner. Although they are more appealing
than shallow models in that the features can be learned automatically (e.g., eﬀective feature representation is learned
from text content), they are inferior to shallow models such
as CF in capturing and learning the similarity and implicit
relationship between items. This calls for integrating deep
learning with CF by performing deep learning collaboratively.
Unfortunately, very few attempts have been made to develop deep learning models for CF. uses restricted Boltzmann machines instead of the conventional matrix factorization formulation to perform CF and extends this work
by incorporating user-user and item-item correlations. Although these methods involve both deep learning and CF,
they actually belong to CF-based methods because they do
not incorporate content information like CTR, which is crucial for accurate recommendation. uses low-rank matrix
factorization in the last weight layer of a deep network to signiﬁcantly reduce the number of model parameters and speed
up training, but it is for classiﬁcation instead of recommendation tasks. On music recommendation, directly
use conventional CNN or deep belief networks (DBN) to assist representation learning for content information, but the
deep learning components of their models are deterministic
without modeling the noise and hence they are less robust.
The models achieve performance boost mainly by loosely
coupled methods without exploiting the interaction between
content information and ratings. Besides, the CNN is linked
directly to the rating matrix, which means the models will
perform poorly when the ratings are sparse, as shown in the
following experiments.
To address the challenges above, we develop a hierarchical
Bayesian model called collaborative deep learning (CDL) as
a novel tightly coupled method for RS. We ﬁrst present a
Bayesian formulation of a deep learning model called stacked
denoising autoencoder (SDAE) .
With this, we then
present our CDL model which tightly couples deep representation learning for the content information and collaborative
ﬁltering for the ratings (feedback) matrix, allowing two-way
interaction between the two. Experiments show that CDL
signiﬁcantly outperforms the state of the art. Note that although we present CDL as using SDAE for its feature learning component, CDL is actually a more general framework
which can also admit other deep learning models such as
deep Boltzmann machines , recurrent neural networks
 , and convolutional neural networks .
The main contribution of this paper is summarized below:
• By performing deep learning collaboratively, CDL can
simultaneously extract an eﬀective deep feature representation from content and capture the similarity and
implicit relationship between items (and users). The
learned representation may also be used for tasks other
than recommendation.
• Unlike previous deep learning models which use simple
target like classiﬁcation and reconstruction ,
we propose to use CF as a more complex target in a
probabilistic framework.
• Besides the algorithm for attaining maximum a posteriori (MAP) estimates, we also derive a sampling-based
algorithm for the Bayesian treatment of CDL, which,
interestingly, turns out to be a Bayesian generalized
version of back-propagation.
• To the best of our knowledge, CDL is the ﬁrst hierarchical Bayesian model to bridge the gap between stateof-the-art deep learning models and RS. Besides, due
to its Bayesian nature, CDL can be easily extended
to incorporate other auxiliary information to further
boost the performance.
• Extensive experiments on three real-world datasets from
diﬀerent domains show that CDL can signiﬁcantly advance the state of the art.
NOTATION AND PROBLEM FORMULA-
Similar to the work in , the recommendation task considered in this paper takes implicit feedback as the training and test data. The entire collection of J items (articles
or movies) is represented by a J-by-S matrix Xc, where row
j is the bag-of-words vector Xc,j∗for item j based on a vocabulary of size S. With I users, we deﬁne an I-by-J binary
rating matrix R = [Rij]I×J. For example, in the dataset
citeulike-a Rij = 1 if user i has article j in his or her personal library and Rij = 0 otherwise. Given part of the ratings in R and the content information Xc, the problem is to
predict the other ratings in R. Note that although we focus
on movie recommendation (where plots of movies are considered as content information) and article recommendation
like in this paper, our model is general enough to handle
other recommendation tasks (e.g., tag recommendation).
The matrix Xc plays the role of clean input to the SDAE
while the noise-corrupted matrix, also a J-by-S matrix, is
denoted by X0. The output of layer l of the SDAE is denoted by Xl which is a J-by-Kl matrix. Similar to Xc, row
j of Xl is denoted by Xl,j∗. Wl and bl are the weight matrix and bias vector, respectively, of layer l, Wl,∗n denotes
column n of Wl, and L is the number of layers. For convenience, we use W+ to denote the collection of all layers of
weight matrices and biases. Note that an L/2-layer SDAE
corresponds to an L-layer network.
COLLABORATIVE DEEP LEARNING
We are now ready to present details of our CDL model.
We ﬁrst brieﬂy review SDAE and give a Bayesian formulation of SDAE. This is then followed by the presentation of
CDL as a hierarchical Bayesian model which tightly integrates the ratings and content information.
Stacked Denoising Autoencoders
SDAE is a feedforward neural network for learning
representations (encoding) of the input data by learning to
predict the clean input itself in the output, as shown in
Figure 2. Usually the hidden layer in the middle, i.e., X2 in
the ﬁgure, is constrained to be a bottleneck and the input
layer X0 is a corrupted version of the clean input data. An
Figure 1: On the left is the graphical model of CDL. The part inside the dashed rectangle represents an
SDAE. An example SDAE with L = 2 is shown. On the right is the graphical model of the degenerated CDL.
The part inside the dashed rectangle represents the encoder of an SDAE. An example SDAE with L = 2 is
shown on the right of it.
Note that although L is still 2, the decoder of the SDAE vanishes.
To prevent
clutter, we omit all variables xl except x0 and xL/2 in the graphical models.
Figure 2: A 2-layer SDAE with L = 4.
SDAE solves the following optimization problem:
{Wl},{bl} ∥Xc −XL∥2
where λ is a regularization parameter and ∥· ∥F denotes the
Frobenius norm.
Generalized Bayesian SDAE
If we assume that both the clean input Xc and the corrupted input X0 are observed, similar to , we can
deﬁne the following generative process:
1. For each layer l of the SDAE network,
(a) For each column n of the weight matrix Wl, draw
Wl,∗n ∼N(0, λ−1
(b) Draw the bias vector bl ∼N(0, λ−1
(c) For each row j of Xl, draw
Xl,j∗∼N(σ(Xl−1,j∗Wl + bl), λ−1
2. For each item j, draw a clean input 1
Xc,j∗∼N(XL,j∗, λ−1
Note that if λs goes to inﬁnity, the Gaussian distribution
in Equation (1) will become a Dirac delta distribution 
centered at σ(Xl−1,j∗Wl + bl), where σ(·) is the sigmoid
function. The model will degenerate to be a Bayesian formulation of SDAE. That is why we call it generalized SDAE.
Note that the ﬁrst L/2 layers of the network act as an encoder and the last L/2 layers act as a decoder. Maximization
1Note that while generation of the clean input Xc from XL
is part of the generative process of the Bayesian SDAE, generation of the noise-corrupted input X0 from Xc is an arti-
ﬁcial noise injection process to help the SDAE learn a more
robust feature representation.
of the posterior probability is equivalent to minimization of
the reconstruction error with weight decay taken into consideration.
Collaborative Deep Learning
Using the Bayesian SDAE as a component, the generative
process of CDL is deﬁned as follows:
1. For each layer l of the SDAE network,
(a) For each column n of the weight matrix Wl, draw
Wl,∗n ∼N(0, λ−1
(b) Draw the bias vector bl ∼N(0, λ−1
(c) For each row j of Xl, draw
Xl,j∗∼N(σ(Xl−1,j∗Wl + bl), λ−1
2. For each item j,
(a) Draw a clean input Xc,j∗∼N(XL,j∗, λ−1
(b) Draw a latent item oﬀset vector ϵj ∼N(0, λ−1
and then set the latent item vector to be:
vj = ϵj + XT
3. Draw a latent user vector for each user i:
ui ∼N(0, λ−1
4. Draw a rating Rij for each user-item pair (i, j):
Here λw, λn, λu, λs, and λv are hyperparameters and Cij is
a conﬁdence parameter similar to that for CTR (Cij = a if
Rij = 1 and Cij = b otherwise). Note that the middle layer
XL/2 serves as a bridge between the ratings and content information. This middle layer, along with the latent oﬀset ϵj,
is the key that enables CDL to simultaneously learn an effective feature representation and capture the similarity and
(implicit) relationship between items (and users). Similar to
the generalized SDAE, for computational eﬃciency, we can
also take λs to inﬁnity.
The graphical model of CDL when λs approaches positive
inﬁnity is shown in Figure 1, where, for notational simplicity,
we use x0, xL/2, and xL in place of XT
2 ,j∗, and XT
respectively.
Figure 3: NN representation for degenerated CDL.
Maximum A Posteriori Estimates
Based on the CDL model above, all parameters could be
treated as random variables so that fully Bayesian methods
such as Markov chain Monte Carlo (MCMC) or variational
approximation methods may be applied. However, such
treatment typically incurs high computational cost. Besides,
since CTR is our primary baseline for comparison, it would
be fair and reasonable to take an approach analogous to that
used in CTR. Consequently, we devise below an EM-style
algorithm for obtaining the MAP estimates, as in .
Like in CTR, maximizing the posterior probability is equivalent to maximizing the joint log-likelihood of U, V, {Xl},
Xc, {Wl}, {bl}, and R given λu, λv, λw, λs, and λn:
∥XL,j∗−Xc,j∗∥2
∥σ(Xl−1,j∗Wl + bl) −Xl,j∗∥2
2 (Rij −uT
If λs goes to inﬁnity, the likelihood becomes:
∥vj −fe(X0,j∗, W+)T ∥2
∥fr(X0,j∗, W+) −Xc,j∗∥2
2 (Rij −uT
where the encoder function fe(·, W+) takes the corrupted
content vector X0,j∗of item j as input and computes the
encoding of the item, and the function fr(·, W+) also takes
X0,j∗as input, computes the encoding and then the reconstructed content vector of item j. For example, if the number of layers L = 6, fe(X0,j∗, W+) is the output of the third
layer while fr(X0,j∗, W+) is the output of the sixth layer.
From the perspective of optimization, the third term in
the objective function (2) above is equivalent to a multi-layer
perceptron using the latent item vectors vj as target while
the fourth term is equivalent to an SDAE minimizing the reconstruction error. Seeing from the view of neural networks
(NN), when λs approaches positive inﬁnity, training of the
probabilistic graphical model of CDL in Figure 1(left) would
degenerate to simultaneously training two neural networks
overlaid together with a common input layer (the corrupted
input) but diﬀerent output layers, as shown in Figure 3.
Note that the second network is much more complex than
typical neural networks due to the involvement of the rating
When the ratio λn/λv approaches positive inﬁnity, it will
degenerate to a two-step model in which the latent representation learned using SDAE is put directly into the CTR.
Another extreme happens when λn/λv goes to zero where
the decoder of the SDAE essentially vanishes. On the right
of Figure 1 is the graphical model of the degenerated CDL
when λn/λv goes to zero. As demonstrated in the experiments, the predictive performance will suﬀer greatly for both
extreme cases.
For ui and vj, coordinate ascent similar to is used.
Given the current W+, we compute the gradients of L with
respect to ui and vj and set them to zero, leading to the
following update rules:
ui ←(VCiVT + λuIK)−1VCiRi
vj ←(UCiUT + λvIK)−1(UCjRj + λvfe(X0,j∗, W+)T ),
where U = (ui)I
i=1, V = (vj)J
j=1, Ci = diag(Ci1, . . . , CiJ)
is a diagonal matrix, Ri = (Ri1, . . . , RiJ)T is a column vector containing all the ratings of user i, and Cij reﬂects the
conﬁdence controlled by a and b as discussed in .
Given U and V, we can learn the weights Wl and biases
bl for each layer using the back-propagation learning algorithm. The gradients of the likelihood with respect to Wl
and bl are as follows:
∇WlL = −λwWl
∇Wlfe(X0,j∗, W+)T (fe(X0,j∗, W+)T −vj)
∇Wlfr(X0,j∗, W+)(fr(X0,j∗, W+) −Xc,j∗)
∇blL = −λwbl
∇blfe(X0,j∗, W+)T (fe(X0,j∗, W+)T −vj)
∇blfr(X0,j∗, W+)(fr(X0,j∗, W+) −Xc,j∗).
By alternating the update of U, V, Wl, and bl, we can ﬁnd
a local optimum for L . Several commonly used techniques
such as using a momentum term may be used to alleviate the
local optimum problem. For completeness, we also provide
a sampling- based algorithm for CDL in the appendix.
Prediction
Let D be the observed test data. Similar to , we use the
point estimates of ui, W+ and ϵj to calculate the predicted
E[Rij|D] ≈E[ui|D]T (E[fe(X0,j∗, W+)T |D] + E[ϵj|D]),
where E[·] denotes the expectation operation. In other words,
we approximate the predicted rating as:
j)T (fe(X0,j∗, W+∗)T + ϵ∗
Note that for any new item j with no rating in the training
data, its oﬀset ϵ∗
j will be 0.
EXPERIMENTS
Extensive experiments are conducted on three real-world
datasets from diﬀerent domains to demonstrate the eﬀectiveness of our model both quantitatively and qualitatively2.
We use three datasets from diﬀerent real-world domains,
two from CiteULike3 and one from Netﬂix, for our experiments. The ﬁrst two datasets, from , were collected in
diﬀerent ways, speciﬁcally, with diﬀerent scales and diﬀerent
degrees of sparsity to mimic diﬀerent practical situations.
The ﬁrst dataset, citeulike-a, is mostly from . The second dataset, citeulike-t, was collected independently of the
ﬁrst one. They manually selected 273 seed tags and collected
all the articles with at least one of those tags. Similar to ,
users with fewer than 3 articles are not included. As a result, citeulike-a contains 5551 users and 16980 items. For
citeulike-t, the numbers are 7947 and 25975. We can see that
citeulike-t contains more users and items than citeulike-a.
Also, citeulike-t is much sparser as only 0.07% of its useritem matrix entries contain ratings but citeulike-a has ratings in 0.22% of its user-item matrix entries.
The last dataset, Netﬂix, consists of two parts. The ﬁrst
part, with ratings and movie titles, is from the Netﬂix challenge dataset.
The second part, with plots of the corresponding movies, was collected by us from IMDB 4. Similar
to , in order to be consistent with the implicit feedback
setting of the ﬁrst two datasets, we extract only positive ratings (rating 5) for training and testing. After removing users
with less than 3 positive ratings and movies without plots,
we have 407261 users, 9228 movies, and 15348808 ratings in
the ﬁnal dataset.
We follow the same procedure as that in to preprocess
the text information (item content) extracted from the titles and abstracts of the articles and the plots of the movies.
After removing stop words, the top S discriminative words
according to the tf-idf values are chosen to form the vocabulary (S is 8000, 20000, and 20000 for the three datasets).
Evaluation Scheme
For each dataset, similar to , we randomly select
P items associated with each user to form the training set
and use all the rest of the dataset as the test set. To evaluate and compare the models under both sparse and dense
settings, we set P to 1 and 10, respectively, in our experiments. For each value of P, we repeat the evaluation ﬁve
times with diﬀerent randomly selected training sets and the
average performance is reported.
As in , we use recall as the performance measure
because the rating information is in the form of implicit
2Code and data are available at www.wanghao.in
3CiteULike allows users to create their own collections of
articles. There are abstract, title, and tags for each article. More details about the CiteULike data can be found at
 
4 
feedback . Speciﬁcally, a zero entry may be due to
the fact that the user is not interested in the item, or that the
user is not aware of its existence. As such, precision is not
a suitable performance measure.
Like most recommender
systems, we sort the predicted ratings of the candidate items
and recommend the top M items to the target user. The
recall@M for each user is then deﬁned as:
recall@M =
number of items that the user likes among the top M
total number of items that the user likes
The ﬁnal result reported is the average recall over all users.
Another evaluation metric is the mean average precision
(mAP). Exactly the same as , we set the cutoﬀpoint at
500 for each user.
Baselines and Experimental Settings
The models included in our comparison are listed as follows:
• CMF: Collective Matrix Factorization is a model
incorporating diﬀerent sources of information by simultaneously factorizing multiple matrices. In this paper,
the two factorized matrices are R and Xc.
• SVDFeature: SVDFeature is a model for featurebased collaborative ﬁltering. In this paper we use the
content information Xc as raw features to feed into
SVDFeature.
• DeepMusic: DeepMusic is a model for music recommendation mentioned in Section 1. We use the variant, a loosely coupled method, that achieves the best
performance as our baseline.
• CTR: Collaborative Topic Regression is a model
performing topic modeling and collaborative ﬁltering
simultaneously as mentioned in the previous section.
• CDL: Collaborative Deep Learning is our proposed
model as described above. It allows diﬀerent levels of
model complexity by varying the number of layers.
In the experiments, we ﬁrst use a validation set to ﬁnd
the optimal hyperparameters for CMF, SVDFeature, CTR,
and DeepMusic. For CMF, we set the regularization hyperparameters for the latent factors of diﬀerent contexts to 10.
After the grid search, we ﬁnd that CMF performs best when
the weights for the rating matrix and content matrix (BOW)
are both 5 in the sparse setting. For the dense setting the
weights are 8 and 2, respectively. For SVDFeature, the best
performance is achieved when the regularization hyperparameters for the users and items are both 0.004 with the
learning rate equal to 0.005. For DeepMusic, we ﬁnd that
the best performance is achieved using a CNN with two convolutional layers. We also try our best to tune the other hyperparameters. For CTR, we ﬁnd that it can achieve good
prediction performance when λu = 0.1, λv = 10, a = 1,
b = 0.01, and K = 50 (note that a and b determine the con-
ﬁdence parameters Cij). For CDL, we directly set a = 1,
b = 0.01, K = 50 and perform grid search on the hyperparameters λu, λv, λn, and λw. For the grid search, we split
the training data and use 5-fold cross validation.
We use a masking noise with a noise level of 0.3 to get the
corrupted input X0 from the clean input Xc. For CDL with
more than one layer of SDAE (L > 2), we use a dropout rate
 of 0.1 to achieve adaptive regularization. In terms
of network architecture, the number of hidden units Kl is set
to 200 for l such that l ̸= L/2 and 0 < l < L. While both K0
and KL are equal to the number of words S in the dictionary,
KL/2 is set to K which is the number of dimensions of the
SVDFeature
SVDFeature
SVDFeature
Figure 4: Performance comparison of CDL, CTR, DeepMusic, CMF, and SVDFeature based on recall@M
for datasets citeulike-a, citeulike-t, and Netﬂix in the sparse setting. A 2-layer CDL is used.
SVDFeature
SVDFeature
SVDFeature
Figure 5: Performance comparison of CDL, CTR, DeepMusic, CMF, and SVDFeature based on recall@M
for datasets citeulike-a, citeulike-t, and Netﬂix in the dense setting. A 2-layer CDL is used.
Table 1: mAP for three datasets
citeulike-a
citeulike-t
SVDFeature
learned representation. For example, the 2-layer CDL model
(L = 4) has a Bayesian SDAE of architecture ‘8000-200-50-
200-8000’ for the citeulike-a dataset.
Quantitative Comparison
Figures 4 and 5 show the results that compare CDL, CTR,
DeepMusic, CMF, and SVDFeature using the three datasets
under both the sparse (P = 1) and dense (P = 10) settings.
We can see that CTR is a strong baseline which
beats DeepMusic, CMF, and SVDFeature in all datasets
even though DeepMusic has a deep architecture.
sparse setting, CMF outperforms SVDFeature most of the
time and sometimes even achieves performance comparable to CTR. DeepMusic performs poorly due to lack of ratings and overﬁtting.
In the dense setting, SVDFeature is
signiﬁcantly better than CMF for citeulike-a and citeuliket but is inferior to CMF for Netﬂix.
DeepMusic is still
slightly worse than CTR due to the reasons mentioned in
Section 1.
To focus more speciﬁcally on comparing CDL
with CTR, we can see that for citeulike-a, 2-layer CDL outperforms CTR by a margin of 4.2%∼6.0% in the sparse setting and 3.3%∼4.6% in the dense setting.
If we increase
the number of layers to 3 (L = 6), the margin will go up
to 5.8%∼8.0% and 4.3%∼5.8%, respectively. Similarly for
citeulike-t, 2-layer CDL outperforms CTR by a margin of
10.4%∼13.1% in the sparse setting and 4.7%∼7.6% in the
dense setting. When the number of layers is increased to 3,
Table 2: Recall@300 in the sparse setting (%)
citeulike-a
citeulike-t
the margin will even go up to 11.0%∼14.9% and 5.2%∼8.2%,
respectively. For Netﬂix, 2-layer CDL outperforms CTR by
a margin of 1.9%∼5.9% in the sparse setting and 1.5%∼2.0%
in the dense setting. As we can see, seamless and successful integration of deep learning and RS requires careful designs to avoid overﬁtting and achieve signiﬁcant performance
Table 1 shows the mAP for all models in the sparse settings. We can see that the mAP of CDL is almost or more
than twice of CTR. Tables 2 and 3 show the recall@300 results when CDL with diﬀerent numbers of layers are applied
to the three datasets under both the sparse and dense settings. As we can see, for citeulike-t and Netﬂix, the recall
increases as the number of layers increases. For citeulike-a,
CDL starts to overﬁt when it exceeds two layers.
the standard deviation is always very small (4.31 × 10−5 ∼
9.31 × 10−3), we do not include it in the ﬁgures and tables
as it is not noticeable anyway.
Note that the results are somewhat diﬀerent for the ﬁrst
two datasets although they are from the same domain. This
is due to the diﬀerent ways in which the datasets were collected, as discussed above.
Speciﬁcally, both the text information and the rating matrix in citeulike-t are much
sparser.5 By seamlessly integrating deep representation learning for content information and CF for the rating matrix,
CDL can handle both the sparse rating matrix and the
5Each article in citeulike-a has 66.6 words on average and
that for citeulike-t is 18.8.
Figure 6: Performance of CDL based on recall@M
for diﬀerent values of λn on citeulike-t. The left plot
is for L = 2 and the right one is for L = 6.
sparse text information much better and learn a much more
eﬀective latent representation for each item and hence each
Figure 6 shows the results for diﬀerent values of λn using citeulike-t under the dense setting. We set λu = 0.01,
λv = 100, and L to 2 and 6. Similar phenomena are observed when the number of layers and the value of P are
varied but they are omitted here due to space constraints.
As mentioned in the previous section, when λn is extremely
large, λn/λv will approach positive inﬁnity so that CDL degenerates to two separate models. In this case the latent
item representation will be learned by the SDAE in an unsupervised manner and then it will be put directly into (a
simpliﬁed version of) the CTR. Consequently, there is no
interaction between the Bayesian SDAE and the collaborative ﬁltering component based on matrix factorization and
hence the prediction performance will suﬀer greatly. For the
other extreme when λn is extremely small, λn/λv will approach zero so that CDL degenerates to that in Figure 1 in
which the decoder of the Bayesian SDAE component essentially vanishes. This way the encoder of the Bayesian SDAE
component will easily overﬁt the latent item vectors learned
by simple matrix factorization. As we can see in Figure 6,
the prediction performance degrades signiﬁcantly as λn gets
very large or very small. When λn < 0.1, the recall@M is
already very close to (or even worse than) the result of PMF.
Qualitative Comparison
To gain a better insight into CDL, we ﬁrst take a look at
two example users in the citeulike-t dataset and represent
the proﬁle of each of them using the top three matched topics. We examine the top 10 recommended articles returned
by a 3-layer (L = 6) CDL and CTR. The models are trained
under the sparse setting (P = 1). From Table 4, we can speculate that user I might be a computer scientist with focus on
tag recommendation, as clearly indicated by the ﬁrst topic
in CDL and the second one in CTR. CDL correctly recommends many articles on tagging systems while CTR focuses
on social networks instead. When digging into the data, we
ﬁnd that the only rated article in the training data is ‘What
drives content tagging: the case of photos on Flickr’, which
is an article that talks about the impact of social networks
on tagging behaviors. This may explain why CTR focuses
its recommendation on social networks. On the other hand,
CDL can better understand the key points of the article (i.e.,
tagging and CF) to make appropriate recommendation accordingly. Consequently, the precision of CDL and CTR is
70% and 10%, respectively.
From the matched topics returned by both CDL and CTR,
user II might be a researcher on blood ﬂow dynamic theory particularly in the ﬁeld of medical science. CDL cor-
Table 3: Recall@300 in the dense setting (%)
citeulike-a
citeulike-t
rectly captures the user proﬁle and achieves a precision of
100%. However, CTR recommends quite a few articles on
astronomy instead. When examining the data, we ﬁnd that
the only rated article returned by CTR is ‘Simulating deformable particle suspensions using a coupled lattice-Boltzmann
and ﬁnite-element method’. As expected, this article is on
deformable particle suspension and the ﬂow of blood cells.
CTR might have misinterpreted this article, focusing its recommendation on words like ‘ﬂows’ and ‘formation’ separately.
This explains why CTR recommends articles like
‘Formation versus destruction: the evolution of the star cluster population in galaxy mergers’ (formation) and ‘Macroscopic eﬀects of the spectral structure in turbulent ﬂows’
(ﬂows). As a result, its precision is only 30%.
From these two users, we can see that with a more eﬀective
representation, CDL can capture the key points of articles
and the user preferences more accurately (e.g., user I). Besides, it can model the co-occurrence and relations of words
better (e.g., user II).
We next present another case study which is for the Net-
ﬂix dataset under the dense setting (P = 10). In this case
study, we choose one user (user III) and vary the number of
ratings (positive feedback) in the training set given by the
user from 1 to 10. The partition of training and test data
remains the same for all other users.
This is to examine
how the recommendation of CTR and CDL adapts as user
III expresses preference for more and more movies. Table 5
shows the recommendation lists of CTR and CDL when the
number of training samples is set to 2, 4, and 10. When
there are only two training samples, the two movies user III
likes are ‘Moonstruck’ and ‘True Romance’, which are both
romance movies. For now the precision of CTR and CDL is
close (20% and 30%). When two more samples are added,
the precision of CDL is boosted to 50% while that of CTR
remains unchanged (20%).
That is because the two new
movies, ‘Johnny English’ and ‘American Beauty’, belong to
action and drama movies.
CDL successfully captures the
user’s change of taste and gets two more recommendations
right but CTR fails to do so. Similar phenomena can be observed when the number of training samples increases from
4 to 10. From this case study, we can see that CDL is sensitive enough to changes of user taste and hence can provide
more accurate recommendation.
COMPLEXITY ANALYSIS AND IMPLE-
Following the update rules in this paper, the computational complexity of updating ui is O(K2J + K3), where K
is the dimensionality of the learned representation and J is
the number of items.
The complexity for vj is O(K2I +
K3 + SK1), where I is the number of users, S is the size
of the vocabulary, and K1 is the dimensionality of the output in the ﬁrst layer.
Note that the third term O(SK1)
is the cost of computing the output of the encoder and it
is dominated by the computation of the ﬁrst layer.
Table 4: Interpretability of the latent structures learned
user I (CDL)
in user’s lib?
top 3 topics
1. search, image, query, images, queries, tagging, index, tags, searching, tag
2. social, online, internet, communities, sharing, networking, facebook, friends, ties, participation
3. collaborative, optimization, ﬁltering, recommendation, contextual, planning, items, preferences
top 10 articles
1. The structure of collaborative tagging Systems
2. Usage patterns of collaborative tagging systems
3. Folksonomy as a complex network
4. HT06, tagging paper, taxonomy, Flickr, academic article, to read
5. Why do tagging systems work
6. Information retrieval in folksonomies: search and ranking
7. tagging, communities, vocabulary, evolution
8. The complex dynamics of collaborative tagging
9. Improved annotation of the blogosphere via autotagging and hierarchical clustering
10. Collaborative tagging as a tripartite network
user I (CTR)
in user’s lib?
top 3 topics
1. social, online, internet, communities, sharing, networking, facebook, friends, ties, participation
2. search, image, query, images, queries, tagging, index, tags, searching, tag
3. feedback, event, transformation, wikipedia, indicators, vitamin, log, indirect, taxonomy
top 10 articles
1. HT06, tagging paper, taxonomy, Flickr, academic article, to read
2. Structure and evolution of online social networks
3. Group formation in large social networks: membership, growth, and evolution
4. Measurement and analysis of online social networks
5. A face(book) in the crowd: social searching vs. social browsing
6. The strength of weak ties
7. Flickr tag recommendation based on collective knowledge
8. The computer-mediated communication network
9. Social capital, self-esteem, and use of online social network sites: A longitudinal analysis
10. Increasing participation in online communities: A framework for human-computer interaction
user II (CDL)
in user’s lib?
top 3 topics
1. ﬂow, cloud, codes, matter, boundary, lattice, particles, galaxies, ﬂuid, galaxy
2. mobile, membrane, wireless, sensor, mobility, lipid, traﬃc, infrastructure, monitoring, ad
3. hybrid, orientation, stress, ﬂuctuations, load, temperature, centrality, mechanical, two-dimensional, heat
top 10 articles
1. Modeling the ﬂow of dense suspensions of deformable particles in three dimensions
2. Simpliﬁed particulate model for coarse-grained hemodynamics simulations
3. Lattice Boltzmann simulations of blood ﬂow: non-newtonian rheology and clotting processes
4. A genome-wide association study for celiac disease identiﬁes risk variants
5. Eﬃcient and accurate simulations of deformable particles
6. A multiscale model of thrombus development
7. Multiphase hemodynamic simulation of pulsatile ﬂow in a coronary artery
8. Lattice Boltzmann modeling of thrombosis in giant aneurysms
9. A lattice Boltzmann simulation of clotting in stented aneursysms
10. Predicting dynamics and rheology of blood ﬂow
user II (CTR)
in user’s lib?
top 3 topics
1. ﬂow, cloud, codes, matter, boundary, lattice, particles, galaxies, ﬂuid, galaxy
2. transition, equations, dynamical, discrete, equation, dimensions, chaos, transitions, living, trust
3. mobile, membrane, wireless, sensor, mobility, lipid, traﬃc, infrastructure, monitoring, ad
top 10 articles
1. Multiphase hemodynamic simulation of pulsatile ﬂow in a coronary artery
2. The metallicity evolution of star-forming galaxies from redshift 0 to 3
3. Formation versus destruction: the evolution of the star cluster population in galaxy mergers
4. Clearing the gas from globular clusters
5. Macroscopic eﬀects of the spectral structure in turbulent ﬂows
6. The WiggleZ dark energy survey
7. Lattice-Boltzmann simulation of blood ﬂow in digitized vessel networks
8. Global properties of ’ordinary’ early-type galaxies
9. Proteus : a direct forcing method in the simulations of particulate ﬂows
10. Analysis of mechanisms for platelet near-wall excess under arterial blood ﬂow conditions
the update of all the weights and biases, the complexity
is O(JSK1) since the computation is dominated by the ﬁrst
layer. Thus for a complete epoch the total time complexity
is O(JSK1 + K2J2 + K2I2 + K3).
All our experiments are conducted on servers with 2 Intel E5-2650 CPUs and 4 NVIDIA Tesla M2090 GPUs each.
Using the MATLAB implementation with GPU/C++ acceleration, each epoch takes only about 40 seconds and each
run takes 200 epochs for the ﬁrst two datasets. For Netﬂix
it takes about 60 seconds per epoch and needs much fewer
epochs (about 100) to get satisfactory recommendation performance. Since Netﬂix is much larger than the other two
datasets, this shows that CDL is very scalable. We expect
that changing the implementation to a pure C++/CUDA
one would signiﬁcantly reduce the time cost.
CONCLUSION AND FUTURE WORK
We have demonstrated in this paper that state-of-the-art
performance can be achieved by jointly performing deep representation learning for the content information and collaborative ﬁltering for the ratings (feedback) matrix.
as we know, CDL is the ﬁrst hierarchical Bayesian model to
bridge the gap between state-of-the-art deep learning models
and RS. In terms of learning, besides the algorithm for attaining the MAP estimates, we also derive a sampling-based
algorithm for the Bayesian treatment of CDL as a Bayesian
generalized version of back-propagation.
Among the possible extensions that could be made to
CDL, the bag-of-words representation may be replaced by
more powerful alternatives, such as . The Bayesian nature of CDL also provides potential performance boost if
other side information is incorporated as in . Besides, as
Table 5: Example user with recommended movies
Movies in the training set: Moonstruck, True Romance, Johnny English, American Beauty, The
Princess Bride, Top Gun, Double Platinum, Rising Sun, Dead Poets Society, Waiting for Guﬀman
# training samples
Top 10 recommended
movies by CTR
Pulp Fiction
Best in Snow
A Fish Called Wanda
A Clockwork Orange
Terminator 2
Being John Malkovich
Good Will Hunting
A Clockwork Orange
Raising Arizona
Monty Python and the Holy Grail
Sling Blade
Sling Blade
Being John Malkovich
Bridget Jones’s Diary
Raising Arizona
Raising Arizona
A Fish Called Wanda
The Graduate
A Streetcar Named Desire
Saving Grace
The Untouchables
The Graduate
The Full Monty
Monster’s Ball
Saving Private Ryan
# training samples
Top 10 recommended
movies by CDL
Pulp Fiction
Good Will Hunting
The Big Lebowski
Best in Show
Pulp Fiction
The Usual Suspect
The Big Lebowski
A Few Good Men
Raising Arizona
Monty Python and the Holy Grail
The Big Chill
The Big Lebowski
Pulp Fiction
One Flew Over the Cuckoo’s Nest
The Matrix
Sense and Sensibility
As Good as It Gets
Sling Blade
Goodfellas
The Usual Suspect
The Matrix
CaddyShack
remarked above, CDL actually provides a framework that
can also admit deep learning models other than SDAE. One
promising choice is the convolutional neural network model
which, among other things, can explicitly take the context
and order of words into account. Further performance boost
may be possible when using such deep learning models.
ACKNOWLEDGMENTS
This research has been partially supported by research
grant FSGRF14EG36.