IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 17, NO. 4, AUGUST 1998
Speckle Reduction and Contrast Enhancement
of Echocardiograms via Multiscale
Nonlinear Processing
Xuli Zong,* Andrew F. Laine, and Edward A. Geiser
Abstract— This paper presents an algorithm for speckle reduction and contrast enhancement of echocardiographic images.
Within a framework of multiscale wavelet analysis, we apply
wavelet shrinkage techniques to eliminate noise while preserving
the sharpness of salient features. In addition, nonlinear processing
of feature energy is carried out to enhance contrast within
local structures and along object boundaries. We show that
the algorithm is capable of not only reducing speckle, but also
enhancing features of diagnostic importance, such as myocardial
walls in two-dimensional echocardiograms obtained from the
parasternal short-axis view.
Shrinkage of wavelet coefﬁcients via soft thresholding within
ﬁner levels of scale is carried out on coefﬁcients of logarithmically transformed echocardiograms. Enhancement of echocardiographic features is accomplished via nonlinear stretching followed by hard thresholding of wavelet coefﬁcients within selected
(midrange) spatial-frequency levels of analysis.
We formulate the denoising and enhancement problem, introduce a class of dyadic wavelets, and describe our implementation of a dyadic wavelet transform. Our approach for
speckle reduction and contrast enhancement was shown to be less
affected by pseudo-Gibbs phenomena. We show experimentally
that this technique produced superior results both qualitatively
and quantitatively when compared to results obtained from
existing denoising methods alone. A study using a database of
clinical echocardiographic images suggests that such denoising
and enhancement may improve the overall consistency of expert
observers to manually deﬁned borders.
Index Terms— Contrast enhancement, denoising, echocardiograms, multiscale representations, nonlinear processing, speckle
reduction, ultrasound images, wavelet shrinkage.
I. INTRODUCTION
OISE and artifacts can cause signal and image degradations for many medical imaging modalities. Different
image modalities exhibit distinct types of degradation. Radiographs often exhibit low contrast while images formed
with coherent energy, such as ultrasound, suffer from speckle
noise. Image degradation can have a signiﬁcant impact on
image quality and thus affect human interpretation and the
Manuscript received March 31, 1997; revised July 22, 1998. The Associate
Editor responsible for coordinating the review of this paper and recommending
its publication was C. Meyer. Asterisk indicates corresponding author.
*X. Zong was with the Department of Computer and Information Science
and Engineering, University of Florida, Gainesville, FL 32611 USA. He is now
with GE Corporate Research and Development, P.O. Box 8, Building K-1,
Room NMR-136, Schenectady, NY 12301 USA (e-mail: ).
A. F. Laine is with the Center for Biomedical Engineering, Columbia
University, New York, NY 10027 USA.
E. A. Geiser is with Echocardiography Research Laboratory, Department
of Medicine, University of Florida, Gainesville, FL 32610 USA.
Publisher Item Identiﬁer S 0278-0062(98)08049-5.
accuracy of computer-assisted methods. Poor image quality
often makes feature extraction, analysis, recognition, and quantitative measurements problematic and unreliable. The promise
of image restoration and contrast enhancement has motivated
a considerable amount of research in imaging science and
medical imaging – . The denoising and feature enhancement techniques developed in this study may help to improve
the accuracy and reliability of image processing algorithms
targeting both qualitative and quantitative problems.
Image formation under coherent waves results in a granular
pattern known as speckle. The granular pattern is correlated
with the surface roughness of an object being imaged. In
 , Goodman presented an analysis of speckle properties
under coherent irradiance. The primary differences between
laser and ultrasound speckle were pointed out by Abbott and
Thurstone in terms of coherent interference and speckle
production. For speckle reduction, earlier techniques include
temporal averaging , , median ﬁltering, and homomorphic Wiener ﬁltering . Similar to temporal averaging,
one speckle reduction technique used frequency and/or
angle diversity to generate multiple uncorrelated syntheticaperture radar (SAR) images which were summed incoherently
to reduce speckle. Homomorphic Wiener ﬁltering is a method
which converts multiplicative noise into additive noise and
applies Wiener low-pass ﬁltering to reduce noise. In , a
coherent image was decomposed into three components, one
of which, called subresolvable quasi-periodic scatter, causes
speckle noise. The component was eliminated by a harmonic
analysis algorithm. An algorithm based on the maximumlikelihood principle and a wavelet regularization procedure for
the logarithm of a radar image was also developed to reduce
speckle in . A wavelet-based method for speckle reduction
was ﬁrst reported by Guo et al. . In the method of Guo
et al., wavelet shrinkage of the logarithmically transformed
image is applied to speckle reduction of SAR images. They
also proposed several approaches to combine the data from
polarization to achieve better performance. During the last two
decades, modality speciﬁc image enhancement schemes have
been developed and studied in the literature , , , .
Speciﬁcally, various spatial and frequency-based techniques
 , , , have been developed for ultrasound image
enhancement. A method called statistical enhancement 
used the local standard deviation of a surrounding region
centered around each pixel to replace its value to enhance
edges in ultrasound images.
0278–0062/98$10.00 1998 IEEE
ZONG et al.: SPECKLE REDUCTION AND CONTRAST ENHANCEMENT OF ECG’S
At ﬁrst glance, denoising and feature enhancement appear
to be two conﬂicting objectives. However, they are simply two
sides of the same coin. The purpose of denoising is to eliminate
noise, especially those that exist primarily in high-frequency
bands, while methods of feature enhancement attempt to
enhance speciﬁc signal details. The difference is that features
often occupy a wider frequency band than noise. It is even
more difﬁcult to achieve both objectives when signal details
are corrupted by noise. Traditional spatial and ﬁltering-based
methods for denoising often reduce noise at the price of blurred
features while single-scale conventional methods for contrast
enhancement may amplify noise. Single-scale representation
of a signal in time (or pure frequency) are problematic
when attempting to discriminate signal from noise. In our
approach, we achieve denoising and feature enhancement
under a framework of multiscale wavelet analysis. We seek to
eliminate noise while restoring or enhancing salient features.
Through multiscale representation by a discrete dyadic wavelet
transform (DWT) with a ﬁrst-order derivative of a smoothing
function as its basis wavelet we can distinguish feature energy
from noise reasonably well. The objectives of denoising and
feature enhancement are achieved by simultaneously lowering
noise energy and raising feature energy through judicious
nonlinear processing of wavelet coefﬁcients in the transform
domain. Through parameterized processing, we are able to
achieve a ﬂexible control and the potential to reduce speckle
and restore (or even enhance) contrast along features, such as
object boundaries. As in our earlier work , this approach
for speckle reduction and contrast enhancement is less affected
by pseudo-Gibbs phenomena . Our approach is similar to
the method reported by Guo et al. . The differences are
that 1) different wavelets and multiscale overcomplete representations are used in our approach, and 2) an enhancement
mechanism is incorporated into our denoising process.
This paper is organized as follows. Section II presents a
ﬁnite-level discrete DWT which is formulated in two dimensions. Our method for speckle reduction and contrast
enhancement under multiscale wavelet analysis is described
in Section III. This includes speckle noise modeling, wavelet
shrinkage for noise reduction, nonlinear stretching (feature
energy gain) for contrast restoration and enhancement, and
the complete algorithm in overview. Section IV presents experimental results, analysis, and discussions. In Section V,
we describe a study using clinical images to test the performance of denoising/enhancement on the consistency and
reliability to manually deﬁned borders by expert observers.
We show via quantitative measurements that borders deﬁned
by experts on denoised and feature-enhanced echocardiograms
were more consistent than those detected on the corresponding
(unprocessed) speckled echocardiograms. Finally, Section VI
concludes the paper.
II. DISCRETE DYADIC WAVELET TRANSFORM
The multiscale DWT developed by Mallat and Zhong 
has been previously applied in areas including edge detection,
texture analysis, noise reduction, and image enhancement. A
ﬁnite-level discrete DWT of a 2-D discrete function
A 3-level DWT decomposition and reconstruction of a 2-D function.
can be represented as
is a wavelet coefﬁcient at scale
and spatial orientation
horizontal and two for vertical),
is a coarse scale
approximation at the ﬁnal level
and position
details about DWT’s, we refer the reader to .
The ﬁnite-level dyadic wavelet decomposition in (1) forms
a complete representation for a J-level DWT. For a particular
class of 2-D dyadic wavelets, such as the ﬁrst-order derivatives
of spline smoothing functions, Mallat and Zhong showed
that the ﬁnite-level direct and inverse discrete DWT of a 2-D
discrete function can be implemented in terms of four ﬁlters,
The four ﬁlters should satisfy the following
perfect decomposition and reconstruction conditions:
The dyadic wavelet decomposition in (1) can be formulated
in terms of the following recursive relations between the two
in the Fourier domain as
The reconstruction
from a dyadic wavelet decomposition
can be represented recursively as
is the complex conjugate of
The DWT decomposition and reconstruction based on the above recursive relations
are shown as a block diagram in Fig. 1. The reconstructed
is equal to
when no processing is performed
The ﬁnite impulse response (FIR) ﬁlters
shown in Table I were deﬁned in , similar to those
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 17, NO. 4, AUGUST 1998
IMPULSE RESPONSES OF FILTERS H(!); G(!);K(!); AND L(!)
FIR ﬁlters
0.001953125
 0.00390625
 0.03515625
 0.14453125
 0.36328125
0:63671875
0.36328125
0.14453125
0.03515625
0.00390625
0.001953125
developed in . The discrete function
is deﬁned as
Our speckle reduction and contrast enhancement were accomplished in the transform domain by judicious
multiscale nonlinear processing of such wavelet coefﬁcients
obtained in this manner
III. SPECKLE REDUCTION AND CONTRAST ENHANCEMENT
Ultrasound imaging techniques are widely used in medical
diagnosis. Its noninvasive nature, low cost, portability, and
real-time image formation make ultrasound imaging an attractive means for medical diagnosis, especially in cardiology. One
of the limitations of ultrasound images is poor image quality
affected by speckle noise. Speckle reduction remains a difﬁcult
problem due to the lack of reliable models to estimate noise.
Speckle under different imaging media, such as laser, radar, or
ultrasound, may appear distinct. However, the granular pattern
under each of these media is produced by coherent interference
related to the roughness of object surfaces. An approximate
speckle noise model is formulated here without temporal
averaging. We apply this speckle noise model within a framework of multiscale wavelet analysis for speckle reduction and
feature enhancement of echocardiographic images. By incorporating a feature enhancement mechanism into a denoising
process, we are able to not only reduce noise, but also restore
features of importance to cardiology. Since in this paper we
are more interested in noise reduction and feature enhancement
of images, the problems of denoising and enhancement are
formulated directly in two dimensions.
A. Approximate Speckle Noise Model
An accurate and reliable model of speckle noise is desirable
for efﬁcient speckle reduction. It remains a difﬁcult problem.
Jain presented a general model for speckle noise as
is an unknown 2-D function, such as a
noise-free original image, to be recovered,
noisy observation of
multiplicative and additive noise respectively,
variables of spatial locations,
Since the effect
of additive noise (such as sensor noise) is considerably small
compared to that of multiplicative noise (coherent interfering)
in echocardiograms,
(8) can be approximated by
To separate the noise from the original image, we take a
logarithmic transform on the both sides of (9)
Equation (10) can also be rewritten as
Now we can approximate
as additive white noise
and may apply various wavelet-based approaches for additive
noise reduction. With uniform sampling, we obtain the
discrete version of (11) as
are sampling periods along horizontal and
vertical directions,
are sampling shifts. A DWT
is a linear transform, so we have
Since speckle noise lies in high spatial frequency, it will
reduce to near zero after a ﬁnite number of repeated smoothing
operations, so
In fact, at most a ﬁve-level
wavelet decomposition is needed to smooth out noise for
most noise reduction applications we conducted. This is why
we carry out speckle noise reduction through eliminating
noise energy
For image restoration
purposes, it is desirable to recover
by reducing
in the wavelet
domain. For noise reduction and feature enhancement, we
want to further increase the sharpness of features of interest,
such as myocardial boundaries, through nonlinear stretching
via feature energy gain on signal details
Jain showed a similar homomorphic approach [1, pp.
313–316] for speckle reduction of images with undeformable
objects through temporal averaging and homomorphic Wiener
ﬁltering. The motion and deformable nature of human hearts
through time prevents us from getting the same status of the
left ventricle for multiple frames. Since we treated noise and
features differently, we were able to accomplish a better result
than denoising only algorithms.
B. Wavelet Shrinkage and Feature Emphasis
During the last few years, a number of wavelet-based denoising techniques , , , , , were developed
while several wavelet-based contrast enhancement methods
 , , were available. To achieve both objectives of
denoising and enhancement, we need 1) a representation which
can separate features from noise, 2) effective denoising and
feature enhancement techniques. Wavelet shrinkage methods,
ZONG et al.: SPECKLE REDUCTION AND CONTRAST ENHANCEMENT OF ECG’S
such as hard thresholding and Donoho’s soft thresholding,
have been investigated for speckle reduction of images on
a logarithmic scale. An advantage of soft thresholding is
that it provides smoothness while hard thresholding preserves
features. After converting multiplicative noise into additive
noise [see (10)] through a log homomorphic transform, we
apply soft thresholding at ﬁne scales (such as levels 1 and/or
2) and hard thresholding within middle levels (such as levels
3 and/or 4) to eliminate noise. We also applied a method of
nonlinear contrast stretching in a wavelet domain to enhance
myocardial features. In our approach, we take advantage of
both thresholding methods. Donoho’s soft thresholding method
 was developed on an orthonormal wavelet transform
 , primarily with Daubechies’s Symmlet 8 basis wavelet.
Previous denoising results have shown some undesirable side
effects, including pseudo-Gibbs phenomena . By employing
a DWT and an antisymmetric basis wavelet with few oscillations, we are relatively free from such side effects after
denoising. Our experiments show that a DWT with a ﬁrstorder derivative of a smoothing function as its basis wavelet
can separate feature energy and noise energy in the transform
domain. In this algorithm, we adopt regularized soft thresholding (wavelet shrinkage) to remove noise energy within
the ﬁner scales and nonlinear processing of feature energy
to enhance contrast. Hard thresholding is incorporated for
preserving features while removing small noise perturbations
within the middle levels of analysis. The wavelet shrinkage
and feature emphasis techniques were described in , which
are reﬁned and included here for the completeness of the
algorithm.
1) Wavelet Shrinkage by Soft Thresholding: Soft thresholding operation can be represented as
where the threshold parameter
is proportional to the noise
is the result of soft thresholding and has the
same sign as
if nonzero. Expression
is deﬁned as
otherwise.
DWT coefﬁcients can be modiﬁed for noise reduction by
is, in general,
a threshold related to the noise level, orientation, and scale.
Donoho’s method of soft thresholding uses a single global
threshold. Since noise coefﬁcients under a DWT have average
decay through ﬁne-to-coarse scales, we regulate soft thresholding by applying coefﬁcient dependent thresholds at distinct
scales. Fig. 2 shows a soft thresholding operation compared
with hard thresholding.
The regulated threshold
can be computed through a
linearly decreasing function
is the standard deviation,
is a decreasing factor
between two consecutive levels,
is a maximum factor
Thresholding methods for denoising, where v(x) is an input to
thresholding operators and u(x) is the output.
A simple scaling factor function.
is a minimum factor,
For the case of an unknown noise level, we use
to estimate the noise level of a signal or image. Threshold
is primarily calculated using
and a decreasing factor
Fig. 3 shows one simple scaling factor
function for the computation of regulated thresholds.
2) Feature Emphasis by Generalized Adaptive Gain: Adaptive gain nonlinear processing , has been successfully
utilized to enhance features in digital mammography. The
adaptive gain operation was generalized to incorporate hard
thresholding to avoid amplifying noise and remove small noise
perturbations within middle scales . A generalized adaptive
gain (GAG) operator is deﬁned as
is a gain factor, and
can be computed as
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 17, NO. 4, AUGUST 1998
A sample GAG function.
An algorithm for speckle reduction and contrast enhancement.
is simply an enhancement operator, and
are selected parameters. When
the expression is equivalent to an adaptive gain operator in
 . The interval
serves as a sliding window for
feature selectivity. It can be adjusted to emphasize features
within a speciﬁc range of variation. The GAG operator is
used to accomplish contrast enhancement through nonlinear
stretching of wavelet coefﬁcients. By selecting a gain, a window, and other parameters, we achieve distinct enhancement.
Thus, through this nonlinear operator, DWT coefﬁcients are
processed for feature enhancement by
where position
the domain of
Fig. 4 presents an adaptive
gain function with feature selectivity.
3) Overview of Algorithm for Speckle Reduction and Feature Enhancement: The functionality and operations of the
algorithm can be approximated by the formula
For the denoising operator
enhancement operator
, we have added the subscript and
superscript
to show the selectivity of various parameters in
the two operations. In (22),
is a recovered image of
an unknown
deﬁned by (8) with features enhanced.
The complete algorithm with six major steps is shown as a
block diagram in Fig. 5.
Our test images included noise-induced spikes among
wavelet coefﬁcients at ﬁner scales due to a signiﬁcant amount
of intensity drop caused by signal cancellation under coherent
interference. We incorporated a spatially weighted averaging
Results of denoising and enhancement. (a) A noisy ED frame. (b)
Wavelet shrinkage denoising-only method. (c) DWT-based denoising and
enhancement.
Results of denoising and enhancement. (a) A noisy ES frame. (b)
Wavelet shrinkage denoising-only method. (c) DWT-based denoising and
enhancement.
operation during denoising to further diffuse the pulse energy
within one or two octaves of high frequency. For instance,
we used a 3
3 window to smooth wavelet coefﬁcients at the
ﬁrst level before applying wavelet shrinkage to clinical image
processing under Section V. The center pixel had weight four,
the four horizontal and vertical neighbor pixels had weight
two, and the four diagonal neighbor pixels had weight of one.
IV. EXPERIMENTAL RESULTS AND DISCUSSIONS
Our multiscale homomorphic algorithm for speckle reduction and feature enhancement was tested on echocardiograms
of varying quality. These image sequences were acquired
from the parasternal short-axis view. Figs. 6 and 7 present
the results of denoising with or without feature enhancement
on end diastolic (ED) and end systolic (ES) frames. The
speckled original frames are shown ﬁrst. Results from wavelet
shrinkage denoising only and denoising with enhancement are
shown in the Fig. 6(b) and (c), respectively. Fig. 8 shows
a nonlinear operator for enhancing the image in Fig. 7(a).
This operator looks much different from Fig. 4 because of the
log transform. Experimental results are also compared with
other speckle reduction techniques, such as median ﬁltering,
extreme sharpening combined with median ﬁltering , ,
homomorphic Wiener ﬁltering, and a wavelet shrinkage denoising , . Figs. 9 and 10 show sample results of the
above mentioned methods on two typical frames from two
different echocardiographic sequences with the left ventricle
as the region of interest. Since the noise-free original image
was not available for our test image, the homomorphic Wiener
ﬁltering method used the Gaussian low-pass ﬁltered version
as an approximation of the original
image and applied Wiener smoothing ﬁlter [1, pp. 280–281]
to reduce speckle from the noisy image. Fig. 9(a) is a sample
noisy image. The result of median ﬁltering with a 5
ZONG et al.: SPECKLE REDUCTION AND CONTRAST ENHANCEMENT OF ECG’S
A GAG function for processing an ECG in Fig. 7(a). The parameter
setting are b = 0:08; c = 10:0; T1 = 0:03; T2 = 0:05; and T3 = 0:4:
is shown in Fig. 9(b). Fig. 9(c) displays a sample result of
extreme sharpening combined with median ﬁltering. The result
from homomorphic Wiener ﬁltering is shown in Fig. 9(d). The
last image, Fig. 9(e) and (f), displays the result from wavelet
shrinkage denoising only and our denoising and enhancement
algorithm. The setting of parameters for Fig. 9(e) are as
follows. Wavelet shrinkage denoising was applied only at the
ﬁrst and second levels with the scaling factor in (16) being 0.4
and 0.2, respectively. Fig. 9(e) shows the result of denoising.
Fig. 9(f) resulted from the same denoising parameters plus
a feature enhancement operation before reconstruction. The
feature enhancement operation was performed only at the third
and fourth levels. The parameters were
In this experiment,
we used relatively large thresholds for wavelet shrinkage
compared to those used in the next experiment. More noise
has been removed, therefore, we set
, so that there
would be no further reduction in noise during feature enhancement. We can ﬁne tune the thresholds and
to optimize
the noise reduction and feature preservation. The parameter
setting for Fig. 10(e) are as follows. We have also applied
wavelet shrinkage denoising at the ﬁrst and second levels with
the scaling factor in (16) being 0.35 and 0.15, respectively.
Fig. 10(e) shows the result of the denoising only method.
Fig. 10(f) had the same denoising parameters plus feature
enhancement. The parameters for feature enhancement at the
third and fourth levels are
The algorithm produces smoothness inside a uniform region and contrast along structure
and object boundaries in addition to speckle reduction. The
denoised and enhanced results of noisy echocardiographic
images from this algorithm appear to outperform the results
from soft thresholding denoising alone. Our current algorithm
is implemented such that most parameters are set dynamically
for adaptive denoising and feature enhancement.
The parameters used in the algorithm, including those shown
in Fig. 8, were adjusted by trial-and-error. Through our study
and experiments, we suggest that the following guidelines will
Results of various denoising methods. (a) Original image with
speckle noise. (b) Median ﬁltering. (c) Extreme sharpening combined with
median ﬁltering. (d) Homomorphic Wiener ﬁltering. (e) Wavelet shrinkage
denoising only. (f) DWT-based denoising with enhancement.
help to ﬁne tune these parameters and to produce enhancement
results. To enhance ﬁne signal details, such as microcalciﬁcations in mammographic images, we try to modify wavelet
coefﬁcients at the ﬁrst three levels . This is because
edges with small sizes can be characterized by relatively large
wavelet coefﬁcients at the ﬁrst few levels. To avoid amplifying
digitization noise, we add less energy gain to wavelet coefﬁcients at the ﬁrst level than those at the second and third levels.
For enhancing a large structure boundary, such as myocardial
borders, we add gain primarily to coefﬁcients at the third and
fourth levels. As expected, increasing signal energy at the ﬁne
scales enhanced high-frequency features such as sharpened
step edges, while increasing signal energy at the coarse scales
improved the visibility of large structures and object boundaries. The histogram and energy distribution of wavelet coefﬁcients at each level and orientation can provide helpful information for identifying the distribution of noise and feature coefﬁcients, and we can adjust all related parameters accordingly.
The settings of
are as follows. In a noisy image, coefﬁcients below
are more likely attributed to noise, where
is the maximum
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 17, NO. 4, AUGUST 1998
Results of various denoising methods. (a) Original image with
speckle noise. (b) Median ﬁltering. (c) Extreme sharpening combined with
median ﬁltering. (d) Homomorphic Wiener ﬁltering. (e) Wavelet shrinkage
denoising-only method. (f) DWT-based denoising and enhancement.
coefﬁcient at level
and orientation
(horizontal or vertical).
These coefﬁcients are set to zero to suppress noise. For an
image with a high level of noise,
can be set relatively large.
The parameter
can be set close to zero for a relatively noisefree image. The coefﬁcients in the range of
are considered at risk for enhancement because they can
represent noise or weak feature coefﬁcients with a relatively
equal chance. They are left unchanged to avoid amplifying
noise. The coefﬁcients in the range of
are really what we want to enhance by adding gain. The
contrast of a feature with coefﬁcients larger than
is already good, so we leave those coefﬁcients unchanged. We
can adjust
toward zero to enhance weak features
with coefﬁcients in the range of
helps to achieve the overall
enhancement while a small window can be used for selected
enhancement. An enhancement function with a large
(17) adds more gain to selected wavelet coefﬁcients and the
parameter can be adjusted to achieve a distinct effect of feature
enhancement. Parameter
can be used to control the shape of
an enhancement function.
V. CLINICAL CASE STUDY
A study of clinical images was conducted to investigate
the effect of denoising on the consistency and reliability to
manually deﬁned borders of the left ventricle in 2-D short-axis
echocardiographic images by expert observers. Experimental
results indicate the algorithm is promising. Borders deﬁned by
experts exhibit less variation after processing. It seems that in
echocardiograms, where no real borders are clearly visible and
are often incomplete, expert borders usually indicate a close
range where real borders may occur. When two expert borders
agree with each other, the range of real borders is more likely
limited around the two expert borders. The study of clinical
images shows that denoising and feature enhancement help
the consistency and reliability of manually deﬁned borders by
expert observers.
The set of test images included in our study of clinical
images was selected from an echocardiographic database exhibiting diverse image quality. Sixty systolic sequences of
2-D short-axis echocardiographic images were selected. Half
of the test images were rated as good quality while the
rest were considered as poor quality. For more details about
how these echocardiographic sequences were acquired, see
reference . Statistical results have shown that there is
some improvement in consistency and reliability for manually deﬁned borders by expert observers examining denoised
images compared to their original noisy images. Quantitative
measurements were calculated in terms of the mean of absolute
border differences (MDistDiff) in distance (mm) and the mean
of border area differences (MAreaDiff) in cm
The border
difference was measured by its close approximation in 64
radial directional difference from an estimated center 
of the left ventricle. MAreaDiff is deﬁned as the absolute
area difference of two borders. Manually deﬁned borders by
experts looking at poor images were improved after denoising.
The statistical results of quantitative measurements of two
sets of borders manually deﬁned by two experts are shown
in Table II. The statistical computation results listed under
the column “Ori” are the quantitative measurements between
two sets of expert borders on the original speckled images
while the results under the column “Enh” are based on the
denoised and enhanced images. It is worth mentioning that
a single set of denoising and enhancement parameters was
used to process all the test echocardiographic images used in
this study. We suggest that a single value set of parameters
should sufﬁce for denoising and enhancing a class of images
with a similar noise pattern and selected features. For the
clinical images of this study, wavelet shrinkage denoising was
applied at the ﬁrst and second levels with the scaling factors
in (21) being 0.15 and 0.12, respectively. The parameters
for feature enhancement at the third and fourth levels are
The values
of C at level 3 and 4 are 8 and 40, respectively. We used
relatively small thresholds to avoid over-smoothing the images
and added more gain at level 4 than level 3.
Fig. 11 shows the correlation between the areas delineated
by the two expert observers. The four diagrams in Fig. 11(a)
present the correlation of ED Epi (epicardial) border areas,
ZONG et al.: SPECKLE REDUCTION AND CONTRAST ENHANCEMENT OF ECG’S
QUANTITATIVE MEASUREMENTS OF MANUALLY DEFINED BORDERS
All Images
Ori versus Enh
Good Images
Ori versus Enh
Poor Images
Ori versus Enh
Area correlation between manually deﬁned borders by two expert
cardiologist observers: (a) on the original noisy images and (b) on the denoised
images with features restored or enhanced.
ES Epi border areas, ED Endo (endocardial) border areas, and
ES Endo border areas on the original noisy images. The four
diagrams in Fig. 11(b) show similar results for the denoised
images with features restored or enhanced. The solid lines in
the ﬁgure are the linear regression lines, while the dash and
dotted lines are ideal regression lines. From the diagrams, it
is clear that the points which represent the two expert border
areas on the same denoised image are, in general, more toward
Border difference variation on the original images. (a) Distribution
of Epi ED border differences. (b) Distribution of Epi ES border differences.
(c) Distribution of Endo ED border differences. (d) Distribution of Endo ES
border differences. The solid lines are the third-order polynomial ﬁtting curves.
the ideal regression line. Additional improvement can be seen
on the Endo area correlation for the denoised images. In most
echocardiograms, there is usually less Endo border information
than Epi border information. Noisy border information affects
border interpolation by human observers for the manually
deﬁned borders. After denoising, Endo border information is
improved, so the expert border areas tend to agree with each
other, especially ES Endo areas. The statistical computation
results shown in Table II, support this analysis.
Fig. 12 shows the distributions of mean border differences
on the original images; 1) the distribution of Epi ED border differences, 2) the distribution of Epi ES border differences, 3) the
distribution of Endo ED border differences, and 4) the distribution of Endo ES border differences. A mean border difference
was computed along 64 equiangular radial segments from a
common center . Each of the line segments intersects
the two manual borders, each once. The absolute difference
between the two intersection points along each segment was
computed before averaging. Fig. 13(a)–(d) shows the distributions of mean border differences on the enhanced images, similar to Fig. 12(a)–(d). The solid lines in Figs. 12 and 13 are the
third-order polynomial ﬁtting curves in a least-squares sense.
With the same scale for both Figs. 12 and 13, Fig. 13 shows
that border distance differences for enhanced images have
smaller means and standard deviations than the corresponding
IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 17, NO. 4, AUGUST 1998
Border difference variation on the enhanced images. (a) Distribution
of Epi ED border differences. (b) Distribution of Epi ES border differences.
(c) Distribution of Endo ED border differences. (d) Distribution of Endo ES
border differences. The solid lines are the third-order polynomial ﬁtting curves.
differences for the original noisy images as shown in Fig. 12.
For more details about this study, we refer the reader to .
VI. CONCLUSIONS
In this paper, we presented a multiscale homomorphic
approach for speckle reduction and feature enhancement. We
showed that two conﬂicting objectives of denoising and enhancement can be achieved through multiscale nonlinear processing. Through a ﬁne-to-coarse scale space analysis of a
speckled image on a logarithmic scale, distinct behaviors of
noise and features can be differentiated. We took advantage of
both soft thresholding and hard thresholding wavelet shrinkage
techniques. Nonlinear stretching of wavelet coefﬁcients was
subsequently performed for feature restoration and enhancement. The algorithm was tested by applying it to a variety
of ultrasound images from an echocardiographic database
exhibiting diverse image quality. Subjective image quality
was improved. The statistical results from a study of clinical images show overall improvement in the consistency of
borders manually deﬁned by expert observers after denoising
and enhancement.