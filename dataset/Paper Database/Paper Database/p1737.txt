Is neocortex essentially multisensory?
Asif A. Ghazanfar1 and Charles E. Schroeder2
1Program in Neuroscience, Department of Psychology, Green Hall, Princeton University, Princeton, New Jersey, 08540, USA
2Cognitive Neuroscience and Schizophrenia Program, Nathan S. Kline Institute for Psychiatric Research, 140 Old Orangeburg Rd,
Orangeburg, New York, 10962, USA
Although sensory perception and neurobiology are
traditionally investigated one modality at a time, real
world behaviour and perception are driven by the
integration of information from multiple sensory
sources. Mounting evidence suggests that the neural
underpinnings of multisensory integration extend into
early sensory processing. This article examines the
notion that neocortical operations are essentially multisensory. We ﬁrst review what is known about multisensory processing in higher-order association cortices
and then discuss recent anatomical and physiological
ﬁndings in presumptive unimodal sensory areas. The
pervasiveness of multisensory inﬂuences on all levels of
cortical processing compels us to reconsider thinking
about neural processing in unisensory terms. Indeed,
the multisensory nature of most, possibly all, of the
neocortex forces us to abandon the notion that the
senses ever operate independently during real-world
cognition.
Introduction
Early investigations of the cerebral cortex and its role in
perception recognized that the convergence and integration of information from different sensory modalities is
an essential component of cognition . In traditional
models of the sensory brain, however, multisensory
integration is deferred until after extensive ‘unisensory’
processing has occurred . This view arose from early
neuroanatomical studies in cats and monkeys, which
suggested few if any interconnections between somatosensory, auditory and visual cortices , and experimental
lesions of discrete regions, which appeared to produce
unimodal behavioural deﬁcits .
Rapidly accumulating evidence on multisensory processing in primates and other mammals directly challenges this classical view. Strikingly, several anatomical
studies suggest that the substrate for multisensory
integration is already present at the primary cortical
level . In fact, the work published to date may reveal
only the ‘tip of the iceberg’, as ongoing studies continue to
reveal extensive interactions among low-level sensory
areas and between those areas and association cortex.
Here, we review multisensory processes involving vision,
audition and somatosensation across the neocortical
mantle. We advance the perspective that multisensory
inﬂuences are integral to primary as well as higher-order
cortical operations. Although chemosensory processes are
not considered here, it is noteworthy that pervasive
multisensory interactions are also characteristic of these
sensory systems .
Recasting the role of lower- and higher-order cortical
processes in the light of multisensory interactions will
compel us to reconsider the wisdom of reducing sensory
perception and cognition into unimodal components. That
is, the neurobiological data reviewed here suggest that
focusing solely on unisensory processes will continue to
provide us only with an impoverished view of both brain
and behavior. The recent recognition of this fact by many
scientists has led to different research strategies that are
providing unique and fruitful perspectives in our understanding of perception and cognition .
Multisensory regions of higher-order association cortex
Several cortical areas were considered multisensory by
virtue of their connections with multiple unimodal areas
 , their single neuron responses to multisensory input
 , and the behavioural deﬁcits of patients with
lesions in these areas . Thus, included among the
classical multisensory cortical areas of primates were the
superior temporal sulcus (STS), the intraparietal (IP)
complex, and the frontal cortex (Figure 1a). In this section,
we will review the structural and functional evidence for
each of these regions in turn.
The superior temporal sulcus
A host of neuroimaging studies have demonstrated multisensory convergence in the human STS region (see for
review). Direct neuronal recordings from the corresponding superior temporal polysensory (STP) region in
monkeys have revealed that neurons can respond to both
visual and auditory stimuli in both the upper 
and lower banks . Roughly, 36–38% of STS neurons
appear to be multimodal in the anterior part of the STS
 , and w12% in the caudal portion of STS . These
early monkey studies, however, did not systematically
investigate whether single STS neurons integrate auditory and visual information. Recently, however, Barraclough et al. measured the integrative properties of
single neurons using biologically relevant dynamic
stimuli, including vocalizations, ripping paper and
human walking. They showed that 23% of neurons
responsive to the sight of biological motion could be
signiﬁcantly modulated by the corresponding auditory
component. Importantly, multisensory modulation was
Corresponding authors: Ghazanfar, A.A. ( ); Schroeder, C.E.
( ).
TRENDS in Cognitive Sciences
Vol.10 No.6 June 2006
www.sciencedirect.com
1364-6613/$ - see front matter Q 2006 Elsevier Ltd. All rights reserved. doi:10.1016/j.tics.2006.04.008
dependent upon the auditory signal being congruent with
the visual cue.
The intraparietal sulcus and area Tpt
The intraparietal region is part of a larger network for
orchestrating multisensory-guided movements in space.
One major node in that network is the lateral intraparietal
(LIP) area of the posterior parietal cortex . Although
LIP was long considered a unimodal visual area, neurons
in LIP are now known to be multisensory, receiving a
convergence of eye position, visual and auditory signals
 . During delayed-saccade tasks, where a monkey
subject must plan eye movement to a remembered target
in the periphery of extrapersonal space, LIP neurons are
modulated by the onset of either visual or auditory cues
(depending the modality of the remembered target) and
responses to both types of sensory targets are spatially
tuned . Several subsequent studies suggested that the
sensory responses in LIP driven by any input modality
have a complex task dependence , although the
strength of this dependence and its operational rules
remain open questions.
Another node in the network for sensory guided
movements is the ventral intraparietal area (VIP), located
adjacent to LIP in the fundus of the intraparietal sulcus of
monkeys. VIP neurons respond to visual, auditory,
somatosensory and vestibular stimuli, and for bi- or
trimodal VIP neurons, receptive ﬁelds (RFs) driven
through different modalities usually overlap in space
 . Figure 2a shows an example of VIP neuron with
overlapping visual and auditory RFs. Like LIP neurons,
VIP neurons are likely to have task-dependent responses.
At the temporo-parietal junction, area Tpt is reported
to contain a multimodal representation of space as well
 . Area Tpt occupies the posterior-most portion of the
superior temporal plane and the superior temporal gyrus,
at the border of auditory, somatosensory and visual
cortices. It contains trimodal neurons with RFs over the
head-neck-shoulder region, leading to the speculation that
Tpt might be involved in orienting the head in space .
Frontal and prefrontal cortices
Relatively few studies have directly investigated multisensory processing in prefrontal cortex. Monkeys trained
to make associations between high/low frequency tones
and two different colors in a delayed match-to-sample
task, however, have prefrontal neural responses that
respond to both the auditory and visual stimuli .
More recently, Romanski and colleagues (Sugihara et al.,
personal communication) adduced data from the ventrolateral prefrontal cortex which showed that neurons there
integrate the auditory and visual components of vocal
signals and that the integration was dependent on the
congruence between the two signals.
Just posterior and ventral to the lateral prefrontal
cortex, the premotor cortex contains neurons with
responses to visual, auditory and somatosensory inputs
 . The RFs of these cells tend to be located around
the upper body, including the face, arm and upper torso
(Figure 2b). Indeed, even auditory responses seem tuned
to nearby sound sources independent of sound intensity
 . For the most part, multisensory neurons are
clustered in a ‘polysensory zone’ located just below the
spur of the arcuate sulcus in the dorsal part of premotor
Auditory, visual and somatosensory
Auditory and visual
Auditory and somatosensory
Ventral premotor
Principal sulcus
Ventral intraparietal
area (VIP)
Lateral intraparietal
area (LIP)
Temporoparietal
area (Tpt)
Superior temporal
Caudomedial auditory
belt area (CM)
Auditory core and lateral
belt areas
Primary and
visual areas
Principal sulcus
Superior temporal
Intraparietal region
Somatosensory areas 3b and 1
Visual area MT
(within the STS)
Ventrolateral
prefrontal cortex
TRENDS in Cognitive Sciences
Figure 1. (a) Traditional scheme of the cortical anatomy of multisensory areas in the primate brain. (b) Modern scheme of the cortical anatomy of multisensory areas. Colored
areas represent regions where there have been anatomical and/or electrophysiological data demonstrating multisensory interactions. In V1 and V2, the multisensory
interactions seem to be restricted to the representation of the peripheral visual ﬁeld. Dashed gray outlines represent opened sulci.
TRENDS in Cognitive Sciences
Vol.10 No.6 June 2006
www.sciencedirect.com
area F4. The function of these neurons appear to be
‘defense’ related: monkeys (and humans) are exquisitely
sensitive to visual, auditory and multisensory looming
signals that indicate approaching danger and
microstimulation of the ‘polysensory zone’ elicits defensive-like movements . Consistent with these ﬁndings,
visual responses in the primary motor cortex are
particularly sensitive to expanding ‘looming-like’ optic
ﬂow stimuli .
The ectosylvian and lateral suprasylvian sulcus in cats
Inactivation of multisensory association cortical areas in
the cat has a direct inﬂuence not only the integrative
properties of superior collicular neurons , but can also
inﬂuence orienting behavior. Cats typically show multisensory enhancement of orienting to congruent visual–
auditory spatial targets when stimuli are near threshold.
When the anterior ectosylvian sulcus or the rostral lateral
suprasylvian sulcus is cryogenically inactivated, the
multisensory behavioral enhancement is disrupted, but
the inactivation does not impair orientation to unimodally
presented targets . Based on these data, it is clear that
association cortical areas have an important role to play in
multimodally driven behaviours. Nevertheless, for many
behaviors (if not all) and contexts, synthesis of information from different modalities might be achieved,
enhanced or processed in parallel through the interaction
interactions might (i) enhance behavioral outcomes in
conjunction with association cortex, (ii) be sufﬁcient for
certain behaviors, and/or (iii) be necessary for others.
Multisensory processes in unisensory areas
Visual and somatosensory processing in auditory cortex
Functional imaging and later, event related potential
 studies, raised the possibility of audio-tactile and
audio-visual interactions in human auditory cortex.
Localization of these effects in the superior temporal
plane was independently supported by techniques that
have better anatomical resolution, including magnetoencephalography and fMRI .
In parallel to the human studies, intracranial recordings have directly conﬁrmed multisensory convergence in
auditory cortex in macaque monkeys . Importantly, these studies have used a combination of singleunit, multi-unit and ﬁeld potential measurements which
might uncover instances of multisensory processes not
discernable through an examination of either type of
neuronal signal alone. The initial report of non-auditory
inputs used multi-contact electrode recordings in
awake monkeys which allowed them to measure neural
signals from multiple cortical layers concurrently. In this
paradigm, the somatosensory responses triggered by
electrical stimulation of the median nerve have approximately
co-localized
responses, and have a similar, although not identical,
feedforward laminar proﬁle (i.e. the initial response onset
is in Layer 4). The laminar proﬁle of the median nerveevoked somatosensory response contrasts strongly with
that of nearby visual inputs, which have a ‘feedback’
laminar proﬁle (i.e. the initial response occurs above and
below Layer 4) .
A subsequent study used single microelectrode
recordings in anesthetized monkeys to conﬁrm that
convergence occurs at the single neuron level. Fu et al.
 further showed that, although proprioceptive and
vibratory inputs are present, the dominant somatosensory
input is a cutaneous representation of the head and neck.
The anatomical reconstruction of these effects is depicted
in Figure 3a; note that the localization of somatosensory
responses appears to exclude A1. Recently, these ﬁndings
were extended by an fMRI study in the anesthetized
monkey which demonstrated that auditory and tactile
stimuli presented simultaneously lead to enhanced
activity (i.e. multisensory integration) in a region posterior and lateral to the primary auditory cortex (AI) in
what is presumably the caudo-lateral belt area, CL 
(Figure 3b). In addition to somatosensory and visual
Auditory RF
Elevation (deg)
Azimuth (deg)
Azimuth (deg)
Azimuth (deg)
Spikes (Hz)
Spikes (Hz)
TRENDS in Cognitive Sciences
Figure 2. (a) Visual and auditory receptive ﬁelds of a ventral intraparietal area neuron. The receptive ﬁelds are spatially congruent. Horizontal and vertical axes indicate
mapping range. The mean neural activity is color-coded. Spontaneous level of activity is indicated by the white line in the color bar. Crosses indicate locations of maximal
spike discharge. The far right panel shows the superposition of the receptive ﬁelds from the two modalities. (Reproduced with permission from ). (b) The overlapping
visual and tactile receptive ﬁelds of a multisensory neuron at a premotor cortical site. Electrical stimulation of this site elicits a complex defensive posture involving a facial
squint, a head turn, and movement of the arm and hand into a guarding position. (Reproduced with permission from ).
TRENDS in Cognitive Sciences
Vol.10 No.6 June 2006
www.sciencedirect.com
inputs, eye position inputs into auditory cortex have been
observed , and these clearly invade A1 as well as
surrounding belt regions (Figure 3c).
Non-auditory modulation of primary auditory cortex
(A1) has also been observed under conditions in which
visual cues and bar press responses were relevant to an
auditory sensory task; interestingly, the ability of the
same cues and behavior to modulate auditory cortical
activity disappears when the monkey performs a similar
visual task . Finally, non-auditory modulation of A1
has been observed during studies of audiovisual communication both in humans and monkeys .
In monkeys, nearly all multisensory integrative responses
in the lateral belt and A1 were speciﬁc to face–voice
integration: if the face was replaced by a high contrast
dynamic disc mimicking mouth movements ,
integration was not as frequently observed (Figure 4a,b).
Thus, as in the STS multisensory interactions are
optimized by for congruent multisensory stimuli.
Auditory and somatosensory processing in visual cortex
Auditory sensitivity was reported by early studies in the
cat visual cortex . Morrell reported that up to 41% of
visual neurons could be driven by auditory stimuli and
that these neurons showed a remarkable degree of
auditory spatial tuning . In monkeys, the strongest
case for audiovisual convergence in visual cortex comes
from anatomical tracing studies. The primary visual (V1)
area receives inputs from the core and belt regions of
auditory cortex and the upper bank of the STS . The
pattern of inputs into V1 is not uniform – connections with
auditory cortex occur primarily in the representation of
the peripheral visual ﬁeld . The auditory cortical
projections to both V1 and V2 terminate primarily in
cortical layers 1 and 6 (a ‘feedback’-style projection) .
Beyond the low level visual cortices, large-scale
mapping techniques have revealed that auditory and
somatosensory stimuli can even activate parts of the
inferotemporal (IT) cortex. For example, Poremba et al.
 used 2-deoxyglucose utilization to delineate the
extent of awake rhesus monkey neocortex activated by
complex auditory stimuli. They found that large expanses
of the neocortex were activated by sounds, including
unimodal visual areas in the temporal and parietal lobes.
This extensive activation of visual areas by auditory
stimuli is reminiscent of an earlier ﬁnding by Pribram et
al. : using auditory clicks as stimuli and ﬁeld potential
recordings in anesthetized monkeys, they found that,
beyond traditional auditory areas, much of the superior
temporal gyrus, insula and parts of the parietal lobe were
responsive. Single unit recordings in monkeys performing
a crossmodal delayed-match-to-sample task also revealed
sample- and delay-period auditory activity in IT
cortex. These data suggest that ventral temporal lobe may
represent objects and events independent of modality. In
support of this, a recent fMRI study demonstrated that an
area overlapping the fusiform face area is activated not
only by familiar faces, but by familiar voices as well .
Cutaneous head/neck
Propioceptive elbow
Cutaneous hand
Vibration sensitive
Auditory only
Figure 3. Distributions of non-auditory inputs into auditory cortex derived from three
separate studies in macaque monkeys. (a) Locations and relative proportions of
cutaneous head/neck, cutaneous hand, proprioceptive, vibratory somatosensory
inputs (colors as in key) to caudo-medial area, based on microelectrode mapping
during acute recording experiments in two anesthetized monkeys. White symbols
denote locations that were tested for somatosensory and auditory inputs but had
only the latter. The inset depicts the composite reconstruction of the four
hemispheres tested (Reproduced with permission from ). (b) Integration of
touch and sound in the anesthetized monkey auditory cortex. Activation map is
overlaid on anatomical image for tone stimulation (encoded in red voxels) and
multisensory integration (encoded in blue voxels). The location of integration is
posterior and lateral to the primary auditory cortex, presumably in the caudo-lateral
belt region. (Reproduced with permission from ). (c) 3-D reconstruction of an
individual macaque brain showing the location of eye-position-sensitive regions in
auditory cortex. The superimposed dots indicate the positions of the electrode
penetrationsand theline indicatestheboundary ofthe coreareas (A1/R).An example
of adjacent sections, taken at the level of the white arrow, and stained to show glial
scars left by electrode penetrations (arrows, lower section). Bottom panels: surface
view of each superior temporal plane is expanded (left hemisphere on the left, right
hemisphere on the right). Individual penetration locations are indicated by dots.
Numbers indicate the local best frequencies (in kHz). The white arrow in the right
panel corresponds to the white arrow in the 3-D reconstruction at the upper left. The
red dots signify penetrationsites that were tested for eye position effects; nearly all of
the sites tested had eye position effects. The black dots signify penetrations made
earlier, unrelated experiments in this subject; these help to functionally establish
core/belt boundaries. (Adapted from .)
TRENDS in Cognitive Sciences
Vol.10 No.6 June 2006
www.sciencedirect.com
Extrastriate visual cortical areas also appear to be
activated during tactile perception (see for review).
Haptic object discrimination and identiﬁcation activates
the lateral occipital complex (LOC) , a human
visual cortical area homologous to macaque IT cortex.
Perception of tactile motion activates the human MT
complex . These studies reinforce the earlier
suggestion that extrastriate visual cortical regions
are recruited in a task-speciﬁc manner, such that the
speciﬁc areas of extrastriate visual cortex that mediate
Microvolts
Proportion of enhanced responses (%)
Proportion of suppressed responses (%)
Enhancement
Suppression
Voice onset time (ms)
219 256 332
Voice onset time (ms)
Disc + voice
Voice alone
Face + voice
Figure 4. Multisensory integration of faces and voices in monkey auditory cortex. (a) One frame of a ‘coo’ face at maximal mouth opening for one stimulus monkey and the
corresponding frames from the ‘disc’ control videos. Time waveform below represents the coo vocalization paired with both videos. (b) Auditory cortical responses to
multimodal vocalization shown in (a). Rectiﬁed local ﬁeld potential responses to FaceCVoice (FCV), DiscCVoice (DCV) and Voice alone (V) components were compared.
Discs were dynamic and mimicked the aperture and displacement of the mouth in the original video. The solid vertical line indicates the onset of the Face or Disc signal.
Dotted vertical lines indicate the onset and offset of the Voice signal. Graphs represent the mean of 10 repetitions. Histograms show enhanced response that was speciﬁc to
the combination of faceCvoice, but not discCvoice. (c) Relationship between voice onset time and multisensory integration. Proportion of enhanced (nZ93) and suppressed
(nZ40) responses across the different voice onset time categories. Note that enhancement was more frequently observed for short voice onset times, whereas suppression
was more common at longer voice onset times. ‘gt’ represents grunts, ‘co’ represents coos. (All ﬁgures reproduced with permission from ).
Box 1. Multisensory integration beyond the neocortex
The abundance of multisensory interactions in the neocortex begs the
question: Do subcortical structures integrate the senses as well? Given
the extensive connections between the neocortex and the superior
colliculus, the thalamus and the amygdala, it is reasonable to assume
that regions beyond the neocortex are multisensory.
The pioneering studies by Stein and colleagues of multisensory
integration in the cat superior colliculus outlined key principles of
multisensory integration that have served to guide investigations in
other species and brain structures. Their subsequent studies show that
multisensory integration in superior colliculus depends on input from
neocortex , and thus appears to contribute more directly to motoric
orienting than to perceptual processing. Studies of the superior
colliculus in behaving monkeys have extended our knowledge of the
subtleties of integration in this structure .
In the primate amygdala, many neurons respond to visual, auditory
and somatosensory stimuli . These neurons are not distributed
randomly throughout this structure: rather, visually responsive
neurons are clustered in the anterior portion of the basolateral nucleus,
and neurons responsive to auditory stimuli are clustered in the
posterior portion . A smaller percentage of neurons respond to
multiple modalities. In contrast to the many multisensory studies
suggesting that behaviorally relevant, familiar stimuli are needed to
drive responses, in the amygdala neurons respond most vigorously to
novel, unfamiliar stimuli.
Thalamic structures also appear to be multisensory in nature. A recent
physiological study demonstrated multisensory integration in the rat
thalamus. Komura et al. trained rats to perform an auditory spatial
discrimination task in which either auditory cues or auditory–visual cues
were presented. Importantly, only the auditory cues were 100%
predictive; the visual cues could either be in agreement with the auditory
cue or conﬂicting. In this context, almost 15% of auditory thalamic
neurons were modulated by the visual cues. When the visual cue was
congruent with the auditory cue, responses were enhanced. By contrast,
when the visualcue was in conﬂict,auditoryresponsesweresuppressed.
TRENDS in Cognitive Sciences
Vol.10 No.6 June 2006
www.sciencedirect.com
particular visual tasks, such as object recognition or
directional discrimination are recruited in the corresponding tactile tasks.
Visual and auditory activation of somatosensory cortex
Very few physiological studies have searched somatosensory cortex for visual and/or auditory responses. Studies
by Fuster and colleagues show that in monkeys trained to
make visual–haptic or auditory–haptic associations, a
subset of somatosensory cortical neurons would, like the
prefrontal neurons described above, respond both to the
visual/auditory cue and the tactile stimulus . In
somatosensory, as in visual cortex, the best case for
multisensory convergence may be based on anatomy.
Anatomical tracer studies in marmosets reveal projections
from visual areas FST and MT to somatosensory Areas 1
and 3b, as well as connections between auditory cortex
and several somatosensory areas, including S2 .
We should note here that multisensory processes
are not the exclusive domain of the cortical mantle
(Box 1). Indeed, the pioneering neurophysiological work
investigated multisensory integration in the superior
colliculus. Furthermore, across cortical regions, it may
be the case that the border zones between sensory speciﬁc
areas may be patches of multisensory neurons (Box 2).
Higher-order versus lower-order cortical areas
The ﬁndings reviewed here demonstrate that both higherorder association areas and presumptive unisensory areas
of the cerebral cortex are in fact multisensory in nature
(Figure 1b). The research deﬁning the speciﬁc role each
type of cortical area plays in real-world sensory/cognitive
processing suggests the emergence of two broad themes.
First, the multisensory processes in association cortex
reinforce the widely held view that a primary role of these
regions is to compute a veridical representation of the
outside world. For example, in parietal areas such as LIP,
VIP and area Tpt, there is a high degree of spatial
correspondence between the RFs from different modalities
(Figure 2). Along the same lines, activity in the temporal
lobe (e.g. STS and extrastriate areas) seems to represent
more concept-related events – the modality-independent
Box 2. The border regions between sensory areas
How discrete are the borders between sensory cortical areas? Using
the rat as a model system, Wallace et al. mapped single-neuron
responses across a large expanse of the postero-lateral neocortex
encompassing the primary auditory, somatosensory and visual areas.
They found that, as expected, within each of these unimodal areas
there were few neurons that responded to an ‘inappropriate’ modality.
However, between sensory-speciﬁc areas, there were clusters of
neurons that not only responded to inputs from more than one
modality, but were capable of integrating these multisensory inputs
(see Figure I). For example, the border between visual and auditory
cortex had neurons that were enhanced or suppressed when stimuli
from these modalities were presented simultaneously. The same was
true for the other borders. These data are generally supported by
similar studies using different methods. Field potential recordings by
Barth and colleagues found that the border of rat secondary
somatosensory cortex (SII) is multisensory and able to integrate
auditory with somatosensory signals . Indeed, they found a rather
large zone of cortex between SII and auditory cortex that is multisensory . Even within the human STS, there appear to patches of
unimodal regions that overlap to produce a border zone that is
multisensory in nature .
Although it is clear that the border zones between sensory-speciﬁc
cortical areas are biased towards multisensory representation in
primates as well as rodents, it does not appear that ‘proximity’ is the
sole determinant of multisensory convergence across the neocortex.
For example, in addition to the multisensory visual–auditory convergence predicted by its location at the border between visual and
auditory cortices, STS receives somatosensory input , which is
not predicted by a proximity rule. A similar example is found in the
lateral intraparietal area (LIP), which exhibits visual–somatosensory
convergence, as predicted by its location between visual and
somatosensory cortices, but also receives auditory input, again not
predicted by a proximity rule.
Multisensory incidence
TRENDS in Cognitive Sciences
Figure I. The distribution of multisensory neurons in the rat sensory neocortex.
Numbers and lines depict the subdivisions on the dorsal surface of cortex. Red
is parietal cortex, green is temporal cortex, and blue is occipital cortex. Filled
circles show electrode penetrations and the size of the circles indicate the
relative incidence of multisensory neurons at each site. Insets show the results
of higher resolution sampling in the transitional regions between sensory
areas. V, visual cortex; A, auditory cortex; S, somatosensory cortex. Horizontal
scale barsZ250 mm. (Reproduced with permission from .)
TRENDS in Cognitive Sciences
Vol.10 No.6 June 2006
www.sciencedirect.com
representations of objects, individuals or motion. The role
of temporal cues has not been systematically investigated
in these areas and will probably be important, although its
precision might be entirely context- or task-dependent.
Second, a characteristic of low-level multisensory
interactions appears to be a lack of spatial precision. For
example, somatosensory input to auditory cortex appears
widespread, and although it might be biased towards the
upper body surfaces, it lacks a precise somatotopic
representation . Similarly, anatomical cross connections between low-level visual and auditory areas appear
to target the peripheral visual ﬁeld representations,
pointedly avoiding the more precise central visual ﬁeld
representations . Thus, the degree to which low level
multisensory processes contribute to spatially precise
higher-order multisensory representations is an open
question (see also Box 3). On the other hand, low-level
multisensory interactions are characterized by a high
degree of temporal precision. For example, during
audiovisual vocalization processing in auditory cortex
 , the sign of the integration appeared to be dependent
on the timing between the initial mouth movement and
the onset of the auditory component of the vocal signal
(Figure 4c). The longer the time interval between the
initial mouth movement and the onset of the voice, the
greater the likelihood of observing response suppression.
By contrast, a short time interval leads to enhanced
responses. One hypothesis is that the primary function of
non-auditory inputs is to reinforce unisensory auditory
processing. For example, Schroeder and colleagues posit
that non-auditory inputs reset the phase of ongoing
oscillations in auditory cortex so that arrival of crucial
auditory input coincides with peaks in the oscillatory cycle
(Lakatos et al., personal communication).
Conclusions
The integration of information from different sensory
systems is a fundamental characteristic of perception and
cognition – qualitatively different kinds of information
from the various sense organs are put together in the
brain to produce a uniﬁed, coherent representation of the
outside world. Traditionally, it has been assumed that
the integration of such disparate information at the
cortical level was the task of specialized, higher-order
association areas of the neocortex. In stark contrast to this
assumption, the neurobiological data reviewed here
suggest that much, if not all, of neocortex is multisensory
(Figure 1b). This necessarily forces us to reconsider the
validity of probing the brain unimodally and suggests a
different perspective when considering other aspects of
cognition – from cognitive development to social cognition.
For example, it is likely that neither the brain nor
cognition develops one sensory modality at a time ,
nor do we represent individuals in one modality at a time
 . The world is barrage of sensory inputs, our
perception is a uniﬁed representation of it, and the
neocortex is organized in a manner to make the
underlying processes as efﬁcient as possible.
Acknowledgements
We thank Joost Maier for his helpful comments on an earlier draft of this
manuscript. C.E.S. acknowledges support from the National Institute of
Mental Health (MH61989 and TW05674).