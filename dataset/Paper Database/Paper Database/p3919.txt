Local Characterizations of Causal Bayesian Networks∗
Elias Bareinboim
Cognitive Systems Laboratory
Computer Science Department
University of California Los Angeles
 
Carlos Brito
Computer Science Department
Federal University of Cear´a
 
Judea Pearl
Cognitive Systems Laboratory
Computer Science Department
University of California Los Angeles
 
The standard deﬁnition of causal Bayesian networks (CBNs) invokes a global condition according
to which the distribution resulting from any intervention can be decomposed into a truncated product dictated by its respective mutilated subgraph.
We provide alternative formulations which emphasizes local aspects of the causal process and can
serve therefore as more meaningful criterion for
testing coherence and network construction.
ﬁrst examine a deﬁnition based on “modularity”
and prove its equivalence to the global deﬁnition.
We then introduce two new deﬁnitions, the ﬁrst interprets the missing edges in the graph, and the
second interprets “zero direct effect” (i.e., ceteris
paribus). We show that these two formulations are
equivalent but carry different semantic content.
Introduction
Nowadays, graphical models are standard tools for encoding
distributional and causal information [Pearl, 1988; Spirtes et
al., 1993; Heckerman and Shachter, 1995; Lauritzen, 1999;
Pearl, 2000; Dawid, 2001; Koller and Friedman, 2009]. One
of the most popular representations is a causal Bayesian network, namely, a directed acyclic graph (DAG) G which, in addition to the traditional conditional independencies also conveys causal information, and permits one to infer the effects
of interventions. Speciﬁcally, if an external intervention ﬁxes
any set X of variables to some constant x, the DAG permits us to infer the resulting post-intervention distribution,
denoted by Px(v), 1 from the pre-intervention distribution
The standard reading of post-interventional probabilities
invokes cutting off incoming arrows to the manipulated variables and leads to a “truncated product” formula [Pearl,
∗This work was supported in parts by National Institutes of
Health #1R01 LM009961-01, National Science Foundation #IIS-
0914211 and #IIS-1018922, and Ofﬁce of Naval Research #N000-
14-09-1-0665 and #N00014-10-1-0933.
1[Pearl, 2000] used the notation P(v | set(t)), P(v | do(t)),
or P(v | ˆt) for the post-intervention distribution, while [Lauritzen,
1999] used P(v ∥t).
1993], also known as “manipulation theorem” [Spirtes et al.,
1993] and “G-computation formula” [Robins, 1986]. A local characterization of CBNs invoking the notion of conditional invariance was presented in [Pearl, 2000, p.24] and
will be shown here to imply (and be implied by) the truncated product formula.
This characterization requires the
network builder to judge whether the conditional probability
P(Y | PAy) for each parents-child family remains invariant under interventions outside this family. [Tian and Pearl,
2002] provides another characterization with respect to three
norms of coherence called Effectiveness, Markov and Recursiveness, and showed their use in learning and identiﬁcation
when the causal graph is not known in advance.
In this paper, we use the concepts of “conditional invariance” and “interventional invariance” to formulate and compare several deﬁnitions of CBNs. The ﬁrst assures invariance
of conditional probabilities for each family, while the other
two assure the invariance of the distribution of each variable
under different interventions. We show that these three deﬁnitions are equivalent to the global one, and lead to the same
predictions under interventions.
The rest of the paper is organized as follows. In Section
2, we introduce the basic concepts, and present the standard
global and local deﬁnitions of CBNs together with discussion
of their features. In Section 3, we prove the equivalence between these two deﬁnitions. In Section 4, we introduce two
new deﬁnitions which explicitly interprets the missing links
in the graph as representing absence of causal inﬂuence. In
Section 5, we prove the equivalence between these deﬁnitions
and the previous ones. Finally, we provide concluding remarks in Section 6.
Causal Bayesian networks and interventions
A causal Bayesian network (also known as a Markovian
model) consists of two mathematical objects: (i) a DAG G,
called a causal graph, over a set V = {V1, ..., Vn} of vertices, and (ii) a probability distribution P(v), over the set V
of discrete variables that correspond to the vertices in G. The
interpretation of such a graph has two components, probabilistic and causal.2
2A more reﬁned interpretation, called functional, is also common
[Pearl, 2000], which, in addition to interventions, supports counterfactual readings. The functional interpretation assumes determinis-
In M. Croitoru, S. Rudolph, N. Wilson, J. Howse, and O. Corby (Eds.),
GKR 2011, LNAI 7205, Berlin Heidelberg: Springer-Verlag, pp. 1-17, 2012.
TECHNICAL REPORT
The probabilistic interpretation [Pearl, 1988] views G
as representing conditional independence restrictions on P:
each variable is independent of all its non-descendants given
its parents in the graph.
This property is known as the
Markov condition and characterizes the Bayesian network
absent of any causal reading.
These conditional independence restrictions imply that the joint probability function
P(v) = P(v1, ..., vn) factorizes according to the product:
P(vi | pai)
where pai are (assignments of) the parents of variables Vi in
The causal interpretation views the arrows in G as representing potential causal inﬂuences between the corresponding variables and, alternatively, the absence of arrows represents no direct causal inﬂuence between the corresponding
variables. In this interpretation, the factorization of eq. (1)
still holds, but the factors are further assumed to represent
autonomous data-generation processes, that is, each family
conditional probability P(vi | pai) represents a stochastic
process by which the values of Vi are assigned in response to
the values pai (previously chosen for Vi’s parents), and the
stochastic variation of this assignment is assumed independent of the variations in all other assignments in the model.
Moreover, each assignment process remains invariant to
possible changes in the assignments processes that govern
other variables in the system. This invariance assumption is
known as modularity and it enables us to predict the effects
of interventions, whenever interventions are described as speciﬁc modiﬁcation of some factors in the product of eq. (1).
The most elementary intervention considered is the atomic
one, where a set X of variables is ﬁxed to some constant
X = x. The following deﬁnitions will facilitate subsequent
discussions.
Deﬁnition 1 (Interventional distributions). Let P(v) be a
probability distribution on a set V of variables, and let
Px(v) denote the distribution resulting from the intervention do(X = x) that sets a subset X of variables to constant
x. Denote by P∗the set of all interventional distributions
Px(v), X ⊆V , including P(v), which represents no intervention (i.e., X = ∅). Additionally, P∗is such that for all
X ⊆V , the following property holds:
i. [Effectiveness] Px(vi) = 1, for all Vi ∈X whenever vi is
consistent with X = x;
Deﬁnition 2 (Conditional invariance). We say that Y is conditional invariant to X given Z, denoted (Y ⊥⊥ci X | Z)P∗,
if intervening on X does not change the conditional distribution of Y given Z = z, i.e., ∀x, y, z, Px(y | z) = P(y | z).
To capture the intuition behind atomic interventions,
[Pearl, 2000] proposed the following local deﬁnition of causal
Bayesian networks:
tic functional relationships between variables in the model, some of
which may be unobserved. Complete axiomatizations of deterministic counterfactual relations are given in [Galles and Pearl, 1998;
Halpern, 1998].
Deﬁnition 3 .
A DAG G is said to be locally compatible with a set of interventional distributions P∗if and only if the following conditions hold for every Px ∈P∗:
i. [Markov] Px(v) is Markov relative to G;
ii. [Modularity] (Vi ⊥⊥ci X | PAi)P∗, for all Vi /∈X whenever pai is consistent with X = x. 3
We shall show (Sec. 3) that modularity permits us to answer queries about the effect of interventions, or causal effects. A causal effect of variable X on variable Y written
Px(y), stands for the probability that variable Y attains value
y if we enforce uniformly over the population the constraint
X = x. The standard deﬁnition of causal Bayesian networks
is based on a global compatibility condition, which makes
explicit the joint post-intervention distribution under any arbitrary intervention.
Deﬁnition 4 .
A DAG G is said to be globally compatible with a set of interventional distributions P∗if and only if the distribution
Px(v) resulting from the intervention do(X = x) is given by
the following expression:
{i|Vi̸∈X} P(vi | pai)
v consistent with x.
otherwise.
Equation (2) is also known as the truncated factorization
product of eq. (1), with factors corresponding to the manipulated variables removed. The truncated factorization follows
from Deﬁnition 3 because, assuming modularity, the postintervention probabilities P(vi | pai) corresponding to variables in X are either 1 or 0, while those corresponding to
unmanipulated variables remain unaltered.
The two deﬁnitions emphasize different aspects of the
causal model; Deﬁnition 3 ensures that each conditional probability P(vi | pai) (locally) remains invariant under interventions that do not include directly Vi, while Deﬁnition 4 ensures that each manipulated variable is not inﬂuenced by its
previous parents (before the manipulation), and every other
variable is governed by its pre-interventional process. Because the latter invokes theoretical conditions on the datagenerating process, it is not directly testable, and the question whether a given implemented intervention conforms to
an investigator’s intention (e.g., no side effects) is discernible
only through the testable properties of the truncated product
formula (2). Deﬁnition 3 provides in essence a series of local tests for Equation (2), and the equivalence between the
two (Theorem 1, below) ensures that all empirically testable
properties of (2) are covered by the local tests provided by
Deﬁnition 3.
3Explicitly, modularity states: P(vi|pai, do(s)) = P(vi|pai)
for any set S of variables disjoint of {Vi, PAi}.
The equivalence between the local and
global deﬁnitions
We prove next that the local and global deﬁnitions of
causal Bayesian networks are equivalent. To the best of our
knowledge, the proof of equivalence has not been published
Theorem 1 (Equivalence between local and global compatibility). Let G be a DAG and P∗a set of interventional distributions, the following statements are equivalent:
i. G is locally compatible with P∗
ii. G is globally compatible with P∗
Proof. (Deﬁnition 3 ⇒Deﬁnition 4)
Given an intervention do(X = x), X ⊆V, assume that
conditions 3:(i-ii) are satisﬁed. For any arbitrary instantiation v of variables V, consistent with X = x, we can express
Px(vi | pai)
Px(vi | pai)
{i|vi /∈X}
Px(vi | pai)
eﬀectiveness
{i|vi /∈X}
Px(vi | pai)
def.3:(ii)
{i|vi /∈X}
P(vi | pai)
which is the truncated product as desired.
(Deﬁnition 4 ⇒Deﬁnition 3)
We assume that the truncated factorization holds, i.e., the
distribution Px(v) resulting from any intervention do(X =
x) can be computed as eq. (2).
To prove effectiveness, consider an intervention do(X =
x), and let vi ∈X. Let Dom(vi) = {vi1, vi2, ..., vim} be the
domain of variable Vi, with only one of those values consistent with X = x. Since Px(v) is a probability distribution,
we must have P
j Px(Vi = vij) = 1. According to eq. (2),
all terms not consistent with X = x have probability zero,
and thus we obtain Px(vi) = 1, vi consistent with X = x.
To show Deﬁnition 3:(ii), we consider an ordering π :
(v1, ..., vn) of the variables, consistent with the graph G
induced by the truncated factorization with no intervention
i P(vi | pai).
Now, given an intervention
Px(vi | pai)
Px(vi, pai)
vj /∈{Vi,PAi} Px(v)
vj /∈{PAi} Px(v)
vj /∈{Vi,PAi,X}
vk /∈X P(vk | pak)
vj /∈{PAi,X}
vk /∈X P(vk | pak)
P(vi | pai) ×
vj /∈{Vi,PAi,X}
vk /∈X,k̸=i P(vk | pak)
vj /∈{PAi,X}
vk /∈X P(vk | pak)
The last step is due to the fact that variables in {Vi, PAi} do
not appear in the summations in the numerator. Rewriting the
numerator, breaking it in relation to variables before and after
vi, we obtain
vj /∈{Vi,PAi,X}
P(vk | pak) =
P(vk | pak)
P(vk | pak)
Note that P
P(vk | pak) = 1 because all Vj >
Vi appear in the summation. Thus, we obtain
vj /∈{Vi,PAi,X}
P(vk | pak) =
P(vk | pak)
Similarly for the denominator,
vj /∈{PAi,X}
P(vk | pak) =
P(vk | pak)
Observe that eqs. (6) and (7) are identical, equation (4) reduces to Px(vi | pai) = P(vi | pai) as desired.
To show Deﬁnition 3:(i), we ﬁrst use the truncated factorization
{i,vi /∈X}
P(vi | pai)
def.3:(ii)
{i,vi /∈X}
Px(vi | pai)
eﬀectiveness
Px(vi | pai)
Finally, def. 3:(i) follows from the deﬁnition of Markov compatibility .
Alternative characterization of Causal
Bayesian Networks
We state next a local deﬁnition of CBNs which focuses on the
absence of edges in the causal graph, i.e., the missing-links
representing absence of causal inﬂuence.
Deﬁnition 5 (Missing-link causal Bayesian network). A DAG
G is said to be missing-link compatible with a set of interventional distributions P∗if and only if the following conditions
i. [Markov] ∀X ⊆V, Px(v) is Markov relative to G;
ii. [Missing-link] ∀X ⊂V, Y ∈V, S ⊂V, Px,s,pay(y) =
Ps,pay(y) whenever there is no arrow from X to Y in G,
pay is consistent with {X = x, S = s} and X, {Y }, S
are disjoint.
iii. [Parents do/see] ∀Y
∈V, X ⊂V, Px,pay(y) =
Px(y | pay) whenever pay is consistent with X = x
and X, {Y } are disjoint.
Condition (ii) requires that when we set X to some value
while keeping the variables S ∪PAy constant, the marginal
distribution of Y remains unaltered, independent of the value
of X, whenever there is no edge between X and Y , i.e., an intervention on X does not change Y ’s distribution while holding constant its parents. In addition to the missing-link condition, 5:(iii) describes the relationship inside each family, i.e.,
the effect on Y should be the same whether observing (seeing) or intervening (doing) on its parents PAy.
Note that the missing-link condition is not sufﬁcient on
its own to characterize causal Bayesian networks – condition
5:(iii) is also necessary when there is a link between any two
variables. To illustrate, consider a DAG G with only two binary variables A and B, and an edge from A to B. Without
condition 5:(iii), the interventional distribution Pa(b) is unconstrained, which allows Pa(b) ̸= P(b | a). However, Deﬁnition 3 implies Pa(b) = P(b | a) since A is the only parent
of B. Condition 5:(iii) ensures this equality.
To facilitate comparison to previous deﬁnitions, we next
deﬁne the notion of interventional invariance:
Deﬁnition 6 (Interventional invariance). We say that Y is interventional invariant (II) to X given Z, denoted (Y ⊥⊥iiX |
Z)P∗, if intervening on X does not change the interventional
distribution of Y given do(Z = z), i.e., ∀x, y, z, Px,z(y) =
Note that deﬁnitions 2 and 6 represent different types of
causal invariance, the former claims invariance given an observation, while the latter claims invariance given an intervention. Interpreting CBNs in these terms, Deﬁnition 3 assumes modularity of each family in terms of conditional invariance (i.e., (Y ⊥⊥ci X | PAy)P∗, ∀X), while Deﬁnition
5 expresses the absence of causal effect in terms of interventional invariance (i.e., (Y ⊥⊥ii X | PAy, S)P∗, ∀S, X).
We believe that Deﬁnition 5 is more intuitive because it relies exclusively on causal relationships in terms of which the
bulk of scientiﬁc knowledge is encoded. We further discuss
this intuition in the next section.
Note that conditional independence claims encoded by the
CBNs are of the form (Y ⊥⊥NDY | PAy)P∗, and the II
claims are of the form (Y ⊥⊥ii X | PAy, S)P∗, ∀X, S. In
both cases, PAy is required to separate Y from other variables. In the observational case Y is separated from its nondescendants, while in the experimental one it is separated
from all other variables. This is so because in the experimental case, an intervention on a descendant of a variable Z
cannot inﬂuence Z (as is easily shown by d-separation in the
mutilated graph).
A characterization based on Zero Direct Effect
The missing-link deﬁnition requires advance knowledge
about parent sets, which is not necessarily available in the
network construction. In this section, we extend the previous
deﬁnition and propose a new characterization based on the
notion of Zero direct effect, which is more aligned with our
intuition about causal relationships, especially these emanating from typical experiments.
Deﬁnition 7 (Zero direct effect). Let X ⊂V, Y ∈V and
SXY = V −{X, Y }. 4 We say that X has zero direct effect
on Y , denoted ZDE(X, Y ), if
(Y ⊥⊥ii X | Sxy)
Now, we introduce the deﬁnition of CBNs motivated by
this notion:
Deﬁnition 8 (Zero direct effect (ZDE) causal Bayesian network). A DAG G is ZDE compatible with a set of interventional distributions P∗if the following conditions hold:
i. [Markov] ∀X ⊆V, Px(v) is Markov relative to G;
ii. [ZDE] ∀X, Y ∈V, ZDE(X, Y ) whenever there is no
arrow from X to Y in G;
iii. [Additivity] ∀X
V, ZDE(X, Y )
and ZDE(Z, Y ) ⇒ZDE(X ∪{Z}, Y ) ;
iv. [Parents do/see] ∀Y
∈V, X ⊂V, Px,pay(y) =
Px(y | pay) whenever pay is consistent with X = x
and X, {Y } are disjoint.
The main feature of Deﬁnition 8 is condition (ii), which
implies that varying X from x to x′ while keeping all other
variables constant does not change Y ’s distribution – this corresponds to an ideal experiment in which all variables are kept
constant and the scientist “wriggles” one variable (or set) at
a time, and contemplates how the target variable reacts (i.e.,
ceteris paribus).
This condition is supplemented by condition 8:(iii), which
has also an intuitive appeal: if experiments show that separate
interventions on X and Z have no direct effect on Y , then
a joint intervention on X and Z should also have no direct
effect on Y . Conditions (i) and (iv) are the same as in the
missing-link deﬁnition.
One distinct feature of this new deﬁnition emerges when
we test whether a given pair < G, P∗> is compatible. First,
the modularity condition of Deﬁnition 3 requires that each
family is invariant to interventions on all subsets of elements
“outside” the family, which is combinatorially explosive. In
contrast, condition (ii) of Deﬁnition 8 involves singleton pairwise experiments which are easier to envision and evaluate.
4We use {A, B} to denote the union of A and B.
Put another way, when the ZDE condition does not hold, it
implies the existence of an edge between the respective pair
of nodes thus providing fewer and easier experiments in testing the structure of the graph. Further, one should test the
Markov compatibility of P and the new induced graph G.
We now show that all three local deﬁnitions of causal
Bayesian networks stated so far are equivalent.
Theorem 2. Let G be a DAG and P∗a set of interventional
distributions, the following statements are equivalent:
i. G is locally compatible with P∗
ii. G is missing-link compatible with P∗
iii. G is ZDE compatible with P∗
Note that the notion of “parents set”, though less attached
to modularity and invariance, is still invoked by the last
two compatibility conditions.
We believe therefore that it
is an essential conceptual element in the deﬁnition of causal
Bayesian networks.
Equivalence between the local deﬁnitions of
causal Bayesian network
Deﬁnition 9 (Strong Markov Condition). Each variable is interventionally independent of every other variable after ﬁxing
its parents. That is, for all Y ∈V and X ⊆V −{Y, PAY}
Px,pay(y) = Ppay(y), for all x, y, pay
[Zde-CBN] ⇒[local-CBN]
In this subsection, we assume that the four conditions in the
deﬁnition of the Zero direct effect causal Bayesian network
are valid for a given graph G and set P∗.
The ﬁrst result simply extends the Zero direct effect semantics to subset of variables:
Lemma 1. Zde(W, Y ) holds for every W
Proof. Note that W does not contain parents of Y . Then,
[Zde] gives that, for every U in W, we have Zde(U, Y ).
But then, it follows directly by [Additivity], that Zde(W, Y )
The next Lemma shows that the strong Markov condition
is also valid for G and P∗.
Lemma 2. For all Y ∈V and X ⊂V −{Y, PAY}, the
relation (Y ⊥⊥ii X | PAY) holds.
Proof. Let T1 = V −{Y, PAY}, and note that SY T1 =
PAY. Since T1 does not have parents of Y , by Lemma 1,
we have Zde(T1, Y ), that is
Pt1,syt1 (y) = Psyt1 (y) = Ppay(y)
Now, let T2 = V −{Y, X, PAY}, and note that SY T2 =
{X, PAY}. Since T2 does not have parents of Y , by Lemma
1, we have Zde(T2, Y ), that is
Pt2,syt2 (y) = Psyt2 (y) = Px,pay(y)
Since (T1 ∪SY T1) = (T2 ∪SY T2), we obtain
Px,pay(y) = Ppay(y)
Lemma 3. The condition of [Modularity] is valid for G and
Proof. Fix a variable Y and X ⊂V−{Y }. We need to show
Px(y | pay) = P(y | pay)
Applying the condition [Parents do/see] to both sides in the
equation above, we obtain
Px,pay(y) = Ppay(y)
and we immediately recognize here a claim of the strong
Markov condition.
Finally, the observation that the condition [Markov] is
present in both deﬁnitions, we complete the proof that G is
a local causal Bayesian network for P∗.
[local-CBN] ⇒[Zde-CBN]
In this subsection, we assume that the two conditions in the
deﬁnition of the local causal Bayesian network are valid for a
given graph G and set P∗.
Lemma 4. For all Y ∈V and X ⊂V−{Y, PAY} we have
Px,pay(pay | y) = 1
whenever Px,pay(y) > 0, and pay is compatible with x.
Proof. This is an immediate consequence of the property of
[Effectiveness], in the deﬁnition of P∗.
Lemma 5. The condition [Parents do/see] is valid for G and
Proof. Fix a variable X ⊂V and consider an arbitrary instantiation v of variables V, and pay consistent with x.
Consider the intervention do(X = x), and given the condition [Modularity], Px(y | pay) = P(y | pay), Y /∈X.
Now consider the intervention do(X = x, PAY = pay),
and again by the condition [Modularity] Px,pay(y | pay) =
P(y | pay). The r.h.s. coincide, therefore
Px(y | pay)
Px,pay(y | pay)
Bayes thm.
Px,pay(pay | y)Px,pay(y)
Px,pay(pay)
eﬀectiveness
Px,pay(pay | y)Px,pay(y)
We consider two cases.
If Px,pay(y) > 0, by lemma 4
Px,pay(pay | y) = 1, and then substituting back in eq. (10)
we obtain Px(y | pay) = Px,pay(y). If Px,pay(y) = 0,
substituting back in eq.
(10) we obtain Px(y | pay) =
Px,pay(pay | y) ∗0 = 0, and then Px(y | pay) =
Px,pay(y).
Lemma 6. The condition [Zde] is valid for G and P∗.
Proof. Fix Y, X ∈V such that there is no arrow pointing
from X to Y . Let SXY = V −{X, Y }. We want to show
Px,sxy(y) = Psxy(y), for all x, y, sxy
Note that PAy ⊆Sxy, and then by the [Parent do/see] condition we have to show
xy(y | pay) = Ps′
xy(y | pay)
xy = Sxy −{PAy}.
The condition [Modularity] implies that Px,s′
pay) = P(y | pay). Again by [Modularity], we obtain
P(y | pay) = Ps′
xy(y | pay). Applying [Parents do/see],
[Zde] follows.
Lemma 7. The condition [Additivity] is valid for G and P∗.
Proof. Fix X ⊂V and Z, Y
Let Sxzy = V −
{X, Y, Z}. Assume Zde(X, Y ) and Zde(Z, Y ). For the sake
of contradiction, suppose that Zde(X ∪{Z}, Y ) is false.
We can rewrite it based on the law of total probability,
P{x,z},sxzy(y | pay)P{x,z},sxzy(pay) ̸=
Psxzy(y | pay)Psxzy(pay)
Notice that there is only one conﬁguration of pay consistent
with sxzy in both sides because PAy ⊆Sxzy and [Effectiveness]. Then, this equation reduces to
P{x,z},sxzy(y | pay) ̸=
Psxzy(y | pay)
We reach a contradiction given [Modularity].
The proof for the Missing-link CBN is analogous.
Conclusions
We ﬁrst proved the equivalence between two characterizations of Causal Bayesian Networks, one local, based on modularity, and the other global, based on the truncated product
formula. We then introduced two alternative characterizations of CBNs, proved their equivalence with the previous
ones, and showed that some of their features make the tasks
of empirically testing the network structure, as well as judgmentally assessing its plausibility more manageable.
Another way to look at the results of our analysis is in terms
of the information content of CBNs, that is, what constraints
a given CBN imposes on both observational and experimental ﬁndings. For a probabilistic Bayes network the answer is
simple and is given by the set of conditional independencies
that are imposed by the d-separation criterion. For a CBN,
the truncated product formula (2) imposes conditional independencies on any interventional distribution Px(v). But this
does not sum up the entire information content of a CBN.
Equation (2) further tells us that the relationship between any
two interventional distributions, say Px(v) and Px′(v), is not
entirely arbitrary; the two distributions constrain each other
in various ways. For example, the conditional distributions
Px(vi|pai) and Px′(vi|pai) must be the same for any unmanipulated family. Or, as another example, for any CBN we
have the inequality: Px(y) ≥P(x, y) [Tian et al., 2006].
A natural question to ask is whether there exists a representation that encodes all constraints of a given type. The
modularity property of Deﬁnition 2 constitutes such a representation, and so do the missing-link and the ZDE deﬁnitions.
Each encodes constraints of a given type and our equivalence
theorems imply that all constraints encoded by one representation can be reconstructed from the other representation
without loss of information.