The Use of Machine Learning Algorithms in Recommender Systems:
A Systematic Review
Ivens Portugal, Paulo Alencar, Donald Cowan
S0957-4174(17)30833-3
10.1016/j.eswa.2017.12.020
Reference:
ESWA 11721
To appear in:
Expert Systems With Applications
Received date:
27 May 2016
Revised date:
7 December 2017
Accepted date:
8 December 2017
Please cite this article as: Ivens Portugal, Paulo Alencar, Donald Cowan, The Use of Machine Learning
Algorithms in Recommender Systems: A Systematic Review, Expert Systems With Applications ,
doi: 10.1016/j.eswa.2017.12.020
This is a PDF ﬁle of an unedited manuscript that has been accepted for publication. As a service
to our customers we are providing this early version of the manuscript. The manuscript will undergo
copyediting, typesetting, and review of the resulting proof before it is published in its ﬁnal form. Please
note that during the production process errors may be discovered which could affect the content, and
all legal disclaimers that apply to the journal pertain.
The final publication is available at Elsevier via © 2018. This manuscript version is made
available under the CC-BY-NC-ND 4.0 license 
 
 
The Use of Machine Learning Algorithms in
Recommender Systems: A Systematic Review
Ivens Portugal
David R. Cheriton School
of Computer Science
University of Waterloo
200 University Avenue West
Waterloo, Canada - N2L 3G1
 
Paulo Alencar
David R. Cheriton School
of Computer Science
University of Waterloo
200 University Avenue West
Waterloo, Canada - N2L 3G1
 
Donald Cowan
David R. Cheriton School
of Computer Science
University of Waterloo
200 University Avenue West
Waterloo, Canada - N2L 3G1
 
Abstract—Recommender systems use algorithms to provide
users with product or service recommendations. Recently, these
systems have been using machine learning algorithms from
the ﬁeld of artiﬁcial intelligence. However, choosing a suitable
machine learning algorithm for a recommender system is difﬁcult
because of the number of algorithms described in the literature.
Researchers and practitioners developing recommender systems
are left with little information about the current approaches in
algorithm usage. Moreover, the development of recommender
systems using machine learning algorithms often faces problems
and raises questions that must be resolved. This paper presents
a systematic review of the literature that analyzes the use
of machine learning algorithms in recommender systems and
identiﬁes new research opportunities. The goals of this study are
to (i) identify trends in the use or research of machine learning algorithms in recommender systems; (ii) identify open questions in
the use or research of machine learning algorithms; and (iii) assist
new researchers to position new research activity in this domain
appropriately. The results of this study identify existing classes
of recommender systems, characterize adopted machine learning
approaches, discuss the use of big data technologies, identify types
of machine learning algorithms and their application domains,
and analyzes both main and alternative performance metrics.
Keywords—systematic review of the literature, recommender
systems, machine learning, machine learning algorithms, application domains, performance metrics
1. INTRODUCTION
Recommender systems (RSs) are used to help users ﬁnd new
items or services, such as books, music, transportation or even
people, based on information about the user, or the recommended item . These systems
also play an important role in decision-making, helping users
to maximize proﬁts or
minimize risks .
Today, RSs are used in many information-based companies
such as Google , Twitter
 , LinkedIn , and Netﬂix . The ﬁeld of RS has its origins
in the mid-1990s with the introduction of Tapestry , the ﬁrst RS.
As the RS ﬁeld evolved, researchers studied the use of
algorithms from machine learning (ML), an area of artiﬁcial
intelligence (AI). ML has been studied since the late 1950s
 , with the emergence of the ﬁeld of AI. Today,
there is a plethora of ML algorithms , clustering , Bayes network , to name a few types), which are used in applications
that range from vacuum cleaner robots and assistance for disabled people to pattern recognition in images , or self-driving vehicles .
The potential application of ML algorithms is vast and the ﬁeld
looks very promising.
ML algorithms are being used in RSs to provide users with
better recommendations. However, the ML ﬁeld does not have
a clear classiﬁcation scheme for its algorithms, mainly because
of the number of approaches and the variations proposed in the
literature . As a consequence, it becomes
difﬁcult and confusing to choose an ML algorithm that ﬁts
one’s need when developing an RS. In addition, researchers
may ﬁnd it challenging to track the use and the trends of ML
algorithms in RSs.
One way to assist researchers and practitioners ) in choosing which ML algorithm to use in an RS is the
study of the RS and ML ﬁelds. Research about RSs containing
ML algorithms implemented in the literature can help show
trends and provide a direction for future studies.
This paper provides a systematic review to investigate how
ML algorithms used in RSs are studied and used; and what
are the trends in ML algorithm research and development.
It is expected that, with this systematic review, researchers
and practitioners can obtain more information about the RS
ﬁeld, and make better implementation or research decisions.
The goals of this study are to (i) identify trends in the use
or research of machine learning algorithms in recommender
systems; (ii) identify open questions in the use or research of
machine learning algorithms; and (iii) assist new researchers
to position new research activity in this domain appropriately. The results of this study identify existing classes of
recommender systems, characterize adopted machine learning
approaches, discuss the use of big data technologies, identify
 
 
types of machine learning algorithms and their application domains, and analyze main and alternative performance metrics.
This paper is organized as follows: Section 2 describes
the theoretical background needed; Section 3 explains the
systematic review protocol, and Section 4 explains the results
of this study. Section 5 presents conclusions and future work.
2. THEORETICAL BACKGROUND
This section gives an overview of the two main research
ﬁelds related to this article, namely recommender systems and
machine learning.
2.1 Recommender Systems
Recommender systems (RSs) use artiﬁcial intelligence (AI)
methods to provide users with item recommendations. For
example, an online bookshop may use a machine learning
(ML) algorithm to classify books by genre and then recommend other books to a user buying a speciﬁc book. RSs were
introduced in 1992 when Tapestry, the ﬁrst RS, appeared. Its
authors used the term collaborative ﬁltering to refer to the
recommendation activity. This term is still used to classify
RSs. RSs are divided into three main categories to drive
the recommendations: collaborative, content-based, and hybrid
ﬁltering .
First, RSs using a collaborative approach consider the user
data when processing information for recommendation. For
instance, by accessing user proﬁles in an online music store,
the RS has access to all the user data, such as the age, country,
city, and songs purchased. With this information, the system
can identify users that share the same music preference, and
then suggest songs bought by similar users.
Second, RSs with a content-based ﬁltering approach base
their recommendations on the item data they can access.
As an example, consider a user who is looking for a new
computer using an online store. When the user browses a
particular computer (item), the RS gathers information about
that computer and searchers in a database for computers that
have similar attributes, such as price, CPU speed, and memory
capacity. The result of this search is then returned to the user
as recommendations.
The third category describes RSs that combine the two previous categories into a hybrid ﬁltering approach, recommending items based on the user and the item data. For example,
on a social network, an RS may recommend proﬁles that
are similar to the user (collaborative ﬁltering), by comparing
their interests. In a second step, the system may consider the
recommended proﬁles as items and thus access their data to
search for new similar proﬁles (content-based ﬁltering). In the
end, both sets of proﬁles are returned as recommendations.
When using a collaborative or a hybrid ﬁltering approach,
RSs must gather information about the user in order to
develop recommendations. This activity can be done explicitly
or implicitly. Explicit user data gathering happens when users are aware they are providing their
information. For instance, when registering for a new online
service, users usually ﬁll in a form that asks their name,
age, and email. Other forms of explicit user data gathering
 are
when users express their preferences by rating items using a
numerical value or a preference such as a Facebook “like.”
Implicit user data gathering accesses information about the
user indirectly. For example, when visiting an online store,
the server at the online store exchanges messages with the
user’s computer, and based on that, the store’s RS may know
the browser the user is using, as well as the user’s country.
More advanced applications monitor user clicks and keystroke
Besides the common recommendation process, in which
users are presented with items that might be of interest,
recommendations can be provided in other ways. Trust-based
recommendations take into consideration the trust relationship that users have between them.
A trust relationship is a link in a social network to a friend
or a related connection. Recommendations based on trust are
worth more than those that do not have trust links. Contextaware recommendations are based on the context of the user. A context
is a set of information about the current state of the user,
such as the time at the user location (morning, afternoon,
evening), or their activity (idle, running, sleeping). The amount
of context information to be processed is high, making contextaware recommendations a challenging research ﬁeld. Riskaware recommendations are a subset
of context-aware recommendations and take into consideration
a context in which critical information is available, such as
user vital signs. It is risk-aware because a wrong decision
may threaten a user’s life or cause damage. Some examples
are recommending pills to be taken or stocks the user should
buy or, sell.
2.2 Machine Learning
Machine Learning (ML) uses computers to simulate human learning and allows computers to identify and acquire
knowledge from the real world, and improve performance of
some tasks based on this new knowledge. More formally, ML
is deﬁned as follows: “A computer program is said to learn
from experience E with respect to some class of tasks T and
performance measure P, if its performance at tasks in T, as
measured by P, improves with experience E” . Although the ﬁrst concepts of
ML originated in the 1950s, ML was studied as a separate
ﬁeld in the 1990s . Today, ML algorithms are used in several areas besides
computer science, including business , advertising
 and medicine happens when algorithms are provided with training
data and correct answers. The task of the ML algorithm is to
learn based on the training data, and to apply the knowledge
that was gained using real data. As an example consider an
ML learning algorithm being used for book classiﬁcation in
a bookstore. A training set (training data + answers) can be
a table relating information about each book to a correct
classiﬁcation. Here, information about each book may be title,
author, or even every word a book contains. The ML algorithm
learns with the training set. When a new book arrives at
the bookstore, the algorithm can classify it based on the
knowledge about book classiﬁcation it has acquired.
In unsupervised learning , ML
algorithms do not have a training set. They are presented with
some data about the real world and have to learn from that data
on their own. Unsupervised learning algorithms are mostly focused on ﬁnding hidden patterns in data. For example, suppose
that an ML algorithm has access to user proﬁle information in
a social network. By using an unsupervised learning approach,
the algorithm can separate users into personality categories,
such as outgoing and reserved, allowing the social network
company to target advertising more directly at speciﬁc groups
ML algorithms can also be classiﬁed as semi-supervised.
Semi-supervised learning occurs when algorithms work with a
training set with missing information, and still need to learn
from it. An example is when an ML algorithm is provided
with movie ratings. Not every user rated every movie and so,
there is some missing information. Semi-supervised learning
algorithms are able to learn and draw conclusions even with
incomplete data.
Lastly, ML algorithms might have a reinforcement learning
approach. Reinforcement learning 
occurs when algorithms learn based on external feedback given
either by a thinking entity, or the environment. This approach
is analogous to teaching dogs to sit or jump. When the dog
performs the action correctly, the dog receives a small treat
(positive feedback). It does not receive any treat (negative
feedback) if it performs the wrong action. As an example
in the computer science ﬁeld, consider an ML algorithm
that plays games against an opponent. Moves that lead to
victories (positive feedback) in the game should be learned
and repeated, whereas moves that lead to losses (negative
feedback) are avoided.
ML has become quite popular recently with the increase
in processor speed and memory size. As a consequence,
the ﬁeld now has a large number of algorithms that use
mathematical or statistical analysis to learn, draw conclusions
or infer data. This number continues to increase as evidenced
by the number of scientiﬁc publications that propose variations
or combinations of ML algorithms. For that reason, ML
algorithms have been categorized based on the purpose for
which they are designed. Some examples of classiﬁcation
can be found in and
 , although the ﬁeld still does not have any
standard classiﬁcation.
3. SYSTEMATIC REVIEW
When developing RSs, software engineers must decide on
the speciﬁc recommender algorithm of all those available. This
choice has signiﬁcant effect on the rationale of the RS, on
the data that will be needed from users and recommendation
items, and on performance issues. The number of algorithm
variations and combinations in the literature makes this choice
a challenging task.
This large number of recommender algorithms, which appears to be constantly growing and changing, makes software
engineering for RSs a continuing challenge. Trying to develop
tools to make RS development easier is a moving target, as
new studies must be done to observe new open problems and
trends, and further enrich the knowledge base.
For these reasons the authors conducted a systematic review
to analyze the development of RSs containing ML algorithms.
This systematic review follows the procedures of and has, as goals, to:
1) identify trends in the use or research of ML algorithms
2) identify open questions in the use or research of ML
algorithms,
3) assist new researchers to position new research activity
in this domain appropriately.
This systematic review has one restriction. The authors decided to limit the set of studies investigated to those describing
an experiment or a validation study. The main reason for this
restriction is that several publications in the literature propose
new algorithms that are never tested or validated. Thus, by
including this restriction, this systematic review is able to
analyze the performance metrics of the ML algorithms, such
as precision, recall, and f-measure.
This review examines the following three research questions
RQ1. What are the trends in recommender system use and research when implementing a machine learning algorithm?
RQ2. What are the trends in machine learning algorithm use
and research when developing a recommender system?
RQ3. What are the main sources of articles of machine learning
algorithms research when embedded in recommender
The protocol for this systematic review has three main steps.
The ﬁrst step is to gather as many publications as possible
using scientiﬁc search engines. The authors then analyze the
studies that were retrieved and apply an initial exclusion
criteria. The second step is to read the abstract of the remaining
papers and apply an additional exclusion criteria. The third
and last step is to read the entire study and gather data from
it, or apply a third set of exclusion criteria. All the data is
then compiled and is used to answer the research questions
discussed earlier.
 
 
To answer the ﬁrst research question, the authors investigated the type of ﬁltering strategy used in the recommender
system being described in a study. The approach to answering
the second question involved more data. The publication
proposed in the publications had its classiﬁcation (supervised,
unsupervised, etc), their type (clustering, decision tree, etc)
investigated, as well as its support for distributed technologies
(Hadoop, MapReduce). The performance metrics that describe
each ML algorithm inspected in this systematic review were
analyzed. The third question is answered by inspecting the
conferences and journals in which the studies were published,
and the surveys that were returned by the search query.
To strengthen the validity of the review the authors applied
certain exclusion criteria (EC) to the studies that were included
in this systematic review. These criteria and the rationale are
presented next.
EC1. Studies must be peer-reviewed articles, published in a
conference, journal, press, etc. For example, conference
entries are not considered for review.
EC2. Books, letters, notes, and patents are not included in the
EC3. Graduate theses are not considered for review.
EC4. The abstract does not provide enough information.
EC5. The authors must have access to the studies, otherwise
studies are not considered for review.
EC6. Studies must be primarily in English or French. Studies
in languages other than English or French are excluded.
EC7. Studies must be unique. If a study is repeated, other
copies of that study are not included in this review.
EC8. Only primary studies are included in this review. For
example, surveys of the literature are not considered for
EC9. Studies that do not describe a recommender system
approach are not considered for review.
EC10. Studies that do not describe a machine learning approach
are not considered for review.
EC11. Studies that do not describe a machine learning approach
sufﬁciently well are not considered for review.
EC12. Studies that do not describe an experiment or validation
study are not considered for review.
EC13. Studies that do not describe performance metrics (e.g.
accuracy, precision, recall) are not included in this review.
There are some synonyms that denote RSs. Based on
 this systematic
review considers RS terms that replace “recommender” by
“recommendation” and it does not consider any “machine
learning” synonyms. Synonyms for the term “experiment”
are “experimentation,” “evaluation,” “assessment,” and “validation.” All of these terms were featured in the search query
(SQ), which is presented as follows:
SQ. ((“recommender system” OR “recommendation system”)
AND (“machine learning”) AND (“experiment” OR “experimentation” OR “evaluation” OR “assessment” OR
“validation”))
This search query inspects the study title, abstract and
Table 3.1: Number of studies in this systematic review
Total retrieved
Not peer-reviewed study
Books, letters, notes, or patents
Graduate Thesis
Subtotal retained
Additional
Excluded after reading the abstract
Not able to access study
Study in foreign language
Subtotal retained
Additional
based on the
entire study
Repeated studies
Not primary studies
Not about recommender systems
Not about machine learning
Does not explain algorithm
Does not include validation study
Does not include performance metrics
Total retained studies
keywords, and attempts to ﬁnd terms that relate to the ﬁeld
of RS, ML, and provide some indication that the proposed
approach was validated. Studies must also contain the term
“machine learning” in the title, abstract, or keywords. To
retrieve studies that were assessed, the search query also looks
for the terms “experiment” or its synonyms.
The search query was used on three popular academic
search engines Scopus1, Web of Science2, and IEEEXplore3 on
August 26th, 2016. The search returned 215 publication entries
that were reviewed for quality. Scopus returned 196 studies,
followed by Web of Science with 33 studies, and IEEEXplore
with 31 studies. The titles of the studies were inspected to ﬁnd
duplicates among search engines. After that they were ready
to be ﬁltered by the exclusion criteria previously explained.
The results are summarized on Table 3.1.
The number of studies to be read in the systematic review
decreased from 215 to 121 when ﬁltered by the exclusion criteria. Fifteen of the study entries were conference or proceeding
descriptions and are excluded because they are not written
scientiﬁc work. After reading the abstract of the studies, the
authors were conﬁdent that 17 studies were not related to
the goal of this systematic review and decided to exclude
them. The authors did not have access to ﬁve studies, even
after asking help from colleagues and visiting libraries. These
studies were then not inspected in this systematic review. Two
studies were in Chinese and another one was in Japanese. Four
studies had a copy returned by the search string. These studies
present the same results and were not counted twice. Only the
original study was considered in this systematic review. After
reading the studies, those who did not focus their proposal on
the key research ﬁelds of this review were excluded. Moreover,
studies that did not explain the ML algorithm being used, or
did not describe a validation study, or its results were also
excluded from this systematic review. In the end, 121 primary
studies were retained and analyzed. The list of all studies is
1 
2 
3 
 
 
presented in the Tables A.1 and A.2 in the Appendix.
One last important point to mention is that the studies
reviewed may propose more than one ML algorithm. As a
consequence, some of the results presented on the next chapter
are focused on the number of studies, while others are focused
on the number of algorithms. The 121 studies described a total
of 205 ML algorithms that are either totally new, or modiﬁcations or optimization of existing ones. Finally, algorithms can
be validated in one or more application domains. This also
impacts some results shown in the next section.
4. SYSTEMATIC REVIEW RESULTS
The reading process focused on ﬁnding three types of
information: one that relates to the RS being described (its
classiﬁcation), another that relates to the ML algorithm (its
type, application domain, and performance metrics), and ﬁnally information about the source of the study (publication
venue). The abstract and introduction of each paper was
read, as well as the description of the proposed approach.
Sometimes, when pieces of data were well described the entire
section did not need to be read. The conclusion and future
work sections of each study ware also read looking for open
problems or research directions.
The authors developed a spreadsheet with an identiﬁcation
of each study with many columns for noting the pieces
of information previously described. After reading all the
studies, the authors processed the information contained in
the spreadsheet and organized it in a presentable manner. The
results and conclusions are presented in the following sections.
4.1 Recommender Systems
Recommender systems can be classiﬁed by content-based,
collaborative, or hybrid ﬁltering. Usually, content-based approaches use the following two strategies to recommend
items to users, according to : classiﬁer-based or
neighbor methods. In the ﬁrst method, users are associated
with proﬁles, and a new item is presented to the classiﬁer.
The classiﬁer then decides whether the item should be recommended or not based on the item’s contents. Nearest-neighbor
methods store items that the user has checked or rated and
use an underlying network of items (where similar items have
similar properties) to discover the user interest for a new item.
Collaborative ﬁltering RSs are subdivided in the following categories, according to : neighborhood-based and model-based methods. The
ﬁrst method also stores the relationship user-item (the user
interest for an item) in a user proﬁle, but it uses a similarity
network of users to evaluate whether a new item should
be recommended. In contrast, model-based methods use the
stored ratings to produce a predictive model for the user.
Hybrid approaches do not seem to follow any categorization.
Table 4.1 shows how many studies describe at least one
approach in each of the classiﬁcations explained in previous
paragraphs, as well as the studies themselves. Results point
to a signiﬁcant number of collaborative ﬁltering approaches
when developing RSs with ML algorithms. More than half of
the studies describe a collaborative approach for ﬁltering, with
a stronger emphasis on a neighborhood-based method.
The authors decided to observe the timeline of the publication of each study. The results are shown in Figure 4.1 and
also conﬁrms that collaborative ﬁltering with a neighborhoodbased method is well researched. In the ﬁgure, one clearly
sees a spike in the year 2012 that indicates a trend in this
research area in recent years. One reason might be the reallife applicability of collaborative ﬁltering approaches in social
networks for example, or on the web with spatial-temporal
applications such as the online network platform for room
renting AirBnb4 or the transportation network company Uber5.
Another important conclusion drawn from Table 4.1 and
Figure 4.1 is the minimal research effort focused on hybrid
approaches. Hybrid ﬁltering helps overcome limitations of
the other two approaches. However, throughout the years,
research on this type of ﬁltering with ML algorithms has
been low, despite the fact that some studies show that it gives
more accurate recommendations than other types of ﬁltering
 .
4.2 Machine Learning Algorithms
ML algorithms can initially be classiﬁed as supervised,
semi-supervised, unsupervised, or reinforcement learning. It
is worth calculating the number in each category in this
systematic review. However, since studies may propose more
than one ML algorithm, it is more reasonable to do an analysis
on the algorithm level, instead of the study one. Therefore,
Table 4.2 shows the number of ML algorithms found in the
studies of this systematic review that described themselves
under one of these ML classiﬁcations.
There is a clear research interest in supervised learning ML
algorithms for RSs. One main reason for this result is that most
of the algorithms analyzed were modiﬁcations or optimization
of well-known ML algorithms. Unsupervised learning had also
an expressive result. Lastly, there is plenty of room for research
in semi-supervised or reinforcement learning for RSs that new
researchers may explore.
The authors also separated ML algorithms into types based
on to present the number
of ML algorithms of each type analyzed in this review. Some
algorithms had clear classiﬁcations because they were small
variations of well-established algorithms (e.g. incremental
matrix factorization is a variant of the matrix factorization
algorithm). Other algorithms, popular in the ﬁeld, were not
grouped with the algorithms of the same type (e.g. k Nearest
Neighbors is a clustering algorithm, but has its own entry).
However, some algorithms do not seem to ﬁt in any category.
For these cases, the algorithm was listed under a new category
with its own name (e.g. Personality diagnosis).
Other important considerations are that some studies described approaches that involve many ML algorithms. When
identiﬁed, these approaches were listed under the “Ensemble”
4 
5 
 
 
Table 4.1: Classiﬁcation of recommender systems
Classiﬁcation of recommendation system
of studies
Content-based ﬁltering / Classiﬁer-based
 
Content-based ﬁltering / Neighbor-based
 
Collaborative ﬁltering / Neighborhood-based
 
Collaborative ﬁltering / Model-based
 
entry. The ensemble strategy for machine learning has several
ways of being implemented (e.g. bagging, boosting, random
forest). However, this systematic review does not differentiate
among them in the analysis. Other studies do not follow traditional ensemble techniques, and use different ML algorithms
in different parts of a greater recommendation strategy. These
approaches were listed under the “Various” entry. Table 4.3
shows detailed results, while table 4.4 provides an alternative
classiﬁcation.
When inspecting the tables, one can observe again the
emergence of collaborative ﬁltering approaches with clustering
algorithms being the one most researched in RS development.
Together with Support Vector Machines (SVM), collaborative
approaches constitute a quarter of the results. Ensemble methods are also at the top of the tables, but this result happened
because many researchers trying different methods opted to
combine their methods in an Ensemble as one additional trial.
Some ML algorithms ranked low in this systematic review
despite their popularity. It is the case of the Neural Network
or the K Means algorithms. Since this systematic review is
focused on the application domain of RS development, these
algorithms are not being researched enough, which opens
opportunities for future studies.
4.3 Big Data Technologies
ML algorithms, by deﬁnition, improve their performance
with access to more data. Similarly, the more data that is
 
 
Figure 4.1: Timeline of the classiﬁcation of the studies
Number of studies
Content-based ﬁltering / Classiﬁer-based
Content-based ﬁltering / Neighbor-based
Collaborative ﬁltering / Neighborhood-based
Collaborative ﬁltering / Model-based
Hybrid ﬁltering
Table 4.2: Machine learning approach
Number of ML
algorithms
of studies
Supervised learning
 
Semi-supervised learning
 
Unsupervised learning
 
Reinforcement learning
 
 
 
Table 4.3: Types of machine learning algorithms
Type of Machine Learning Algorithm
Number of ML
algorithms
of studies
 
Support Vector Machines (SVM)
 
 
Decision Tree
 
Matrix Factorization
 
k Nearest Neighbors
 
Latent Semantic Analysis
 
Logistic Regression
 
 
Clustering
 
 
Association Rule
 
Kernel Methods
 
 
Frequency Counting
 
Least Squares
 
Neural Network
 
Regression Tree
 
Sim. metric - Cosine Similarity
 
Dictionary Learning
 
Gradient Descent
 
Latent Dirichlet Allocation
 
Linear Model
 
Linear Regression
 
Pearson Correlation
 
Staked Regression
 
Cross-temporal Link Prediction
 
Euclidean Distance
 
Gaussian Processes
 
Graphical Model
 
Learning Automata
 
Mahalanobis Classiﬁer
 
Markov Model
 
Lagrange Multiplier
 
Mixture Model
 
Optimal Path Forest
 
Personality Diagnosis
 
Probabilistic Latent Semantic Analysis
 
Q-Learning
 
Regularization Methods
 
Shortest Path
 
Simil. metric - Geosemantic Proximity
 
Simil. metric - Aggregate Function
 
Simil. metric - WordNet Class Distance
 
Single Value Decomposition (SVD)
 
 
 
Table 4.4: Types of machine learning algorithms (alternative classiﬁcation)
Type of Machine Learning Algorithm
Number of ML
algorithms
of studies
Clustering
 
Kernel Methods
 
 
Decision Tree
 
Graphical Model
 
Regression
 
Similarity Metric
 
 
Association Rule
 
 
Neural Network
 
Frequency Counting
 
Dictionary Learning
 
Gradient Descent
 
Linear Model
 
Cross-temporal Link Prediction
 
Learning Automata
 
Mahalanobis Classiﬁer
 
Markov Model
 
Lagrage Multiplier
 
Mixture Model
 
Optimal Path Forest
 
Personality Diagnosis
 
Probabilistic Latent Semantic Analysis
 
Q-Learning
 
Regularization Methods
 
Shortest Path
 
 
 
Table 4.5: Big Data technologies
Big Data Technologies
Number of studies
 
Other studies
provided to an RS, the better should be its recommendations.
The evolution of technology has spawned research into new
ways of handling data. One such phenomenon is called Big
Data , which has produced the
Hadoop distributed infrastructure and the MapReduce programming model
 . Because Big Data has a direct
impact in RS development and ML algorithms , the authors decided to look for
studies that have a discussion of Big Data in the description
of their proposed algorithms. Table 4.5 shows the number of
studies that included Big Data in their discussion or proposals.
Among the studies that described some Big Data adaptations, Baldominos et al. used Big Data for storage.
The proposed architecture that provides on demand tools for
analysis uses the storage technologies HDFS (Hadoop Distributed File System) and HBase6 for
persistence logs and structured information about the execution
and predictions. Another study , in the
health domain, uses data from distributed datasets to make
predictions. The description of the Big Data technologies used
in the prediction process was not the focus of the study. Lastly,
Geng et al. proposes a neural network-based algorithm
that is applied to the image domain and, according to the
authors, easily scales to large networks.
Although as mentioned earlier, it is clear that few studies
had their proposals adapted for a Big Data reality, with distributed technologies or performance-optimized programming
paradigms. This Big Data apporach appears to represent a large
research opportunity for RS development.
4.4 Application Domains
This systematic review investigates the application domains
used in the studies analyzed. A primary study may propose
multiple algorithms, which may be validated in many different
application domains. This means that the authors may investigate the application domains on a per algorithm or a per
study basis. The authors opted for the latter approach so that
the number of algorithms proposed in a single study does not
affect the ﬁnal result of the application domain analysis. The
results of the analysis are shown on Table 4.6.
The application domain of Movies is the one mostly used
with 31 occurrences among the 121 studies. One reason for
this result is the ease of access to data in the movie domain.
The University of Minnesota maintains a dataset with several
6 
movie ratings, named MovieLens7, which is widely used.
Another source of user ratings is the Internet Movie Database
(IMDb)8, which contains millions of titles and ratings that can
be used to build a testing dataset.
The social domain ranks in the second place. This domain
accounts for algorithms aimed to work on social networks, or
applications that connects different users. This use conﬁrms
the trend of collaborative approaches in RS development with
ML algorithms. The tourism and the coding domains ranked
low, revealing opportunities for research, since data in these
domains are rich and easily accessible.
4.5 Performance Metrics
The main goal of this systematic review is to identify trends
of ML algorithm use in RS development that can assist future
researchers in their studies. The authors decided to take a
deeper look at how the algorithms are being used by inspecting
the performance metrics that researchers use to describe ML
algorithms. These metrics may be accuracy metrics, such
as Precision or Recall, or alternative metrics, such as User
Preference or Coverage.
The analysis starts with an understanding of some of the
performance metrics that have been proposed. Figure 4.2
shows a tree containing several metrics at the leaf nodes,
followed by their classiﬁcations as one goes up in the tree.
Although not complete, this tree provides an overview of the
many metrics that can be used to evaluate ML algorithms.
In this systematic review, the authors found many of the
metrics expressed by Figure 4.2, but also found many other
metrics not described in the ﬁgure. Tables 4.7 and 4.8 present
metrics that were used to describe an algorithm. Note that
the numbers do not add up to 121 studies or 205 algorithms.
The reason is that an algorithm may use one or more metrics
to describe its performance. Therefore, since there is at least
one metric per algorithm, one should expect the number of
metrics to be greater than the number of algorithms. Another
consideration is sorting of the methods. The authors decided to
sort the results, where well-known performance metrics were
together and speciﬁc metrics were at the bottom of the table.
By inspecting Tables 4.7 and 4.8, one may note that
Precision, Recall and F-measure, are among the most popular
performance metrics used in the studies of this systematic
review, totalling almost 50% of all occurrences. One reason
that may explain this result is that these metrics are the ones
most often explained in textbooks. Most of the times, studies
provided the three metrics together, since they are related, but
as seen in the table, it is not for all the cases. Some studies
provide only the Precision, or only the F-measure. The authors
did not calculate the missing values so the results would not
be affected. Two variants of the F-measure metric were used
by studies, created by changing one of the parameters of the
metrics. The studies does not explain the reason for the change.
Accuracy ranks high as well with 49 occurrences, mainly
because of its intuitive nature when evaluating ML algorithms.
7 
8 
 
 
Table 4.6: Application Domains
of studies
 
 
 
 
E-commerce
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Restaurant
 
Advertisement
 
 
 
 
 
 
Mobile Phones
 
 
 
Another important result is the large number of studies evaluating their proposals in terms of the error in the prediction by
using the RMSE (Round Mean Squared Error) and the MAE
(Mean Absolute Error) metrics. MAE had 123 occurrences,
and ranks in the ﬁrst position. The simplicity of the calculation
of these metrics may be the reason for this result.
A study of the occurrence of each metric shows the popularity of some metrics, as well introduces other metrics to
researchers. However, the authors decided to break down the
most popular metrics and observe how the algorithms actually
performed, as reported by the studies. The authors decided
to plot all of the values for some of the performance metrics
displayed at the top of Table 4.7 to discover any trends, or
any studies that stand out. However, plotting tens of studies is
not feasible. Many values are overwritten by others values and
the ﬁgure becomes unreadable. Therefore, the authors display
the best and worst value of each plot, and in another plot, the
authors present the top 10 studies for each metric analyzed.
Some important considerations are as follows. The analysis
of the performance metrics is per algorithm, which means that
studies that proposed more than one algorithm are repeated in
the plots. Moreover, as a study may validate its ML algorithm
with different versions of the same data, the authors decided
to report the results related to the richer data. For example,
MovieLens provides three sizes of their movie ratings dataset:
100K, 1M, and 10M data values, where K is thousands and M
is millions. This systematic review analyzes the results related
only to the larger dataset. This is done to simulate the real
world as much as possible.
A similar decision is taken regarding parameters of the
algorithms. Many times, studies report the results of an ML
algorithm assuming many different parameters. In this case,
this systematic review considers the best result for analysis.
This is done for the beneﬁt of other researchers who may
be searching for an algorithm that is better than a certain
threshold.
 
 
Table 4.7: Performance Metrics
Number of ML
algorithms
of studies
 
 
 
R-Precision
 
 
 
 
 
Normalized
 
 
 
 
 
Rate (CTR)
 
Kullback-Leibler
divergence
 
NARG 
 
Shortcut Gain
 
Squared Error)
 
Coefﬁcient
 
 
Rank Score Measure (RSM)
 
 
 
Figure 4.2: An overview of performance metrics )
Table 4.8: Performance Metrics (cont.)
Number of ML
algorithms
of studies
PPE (Percentage
of Positive Evaluations)
 
 
 
Rank Score
 
Deviation (AAD)
 
Absolute Error
 
 
 
 
Convergence
 
Error function
 
Error (MRE)
 
 
 
Lastly, performance results may be reported using the 0-100
range or a 0-1 range. For the former case the authors reduced
the result to the range of 0-1 simply by dividing the reported
result by 100. This is done to make results comparable, and
it does not affect the ﬁnal result of the analysis.
Figure 4.3 presents the plots for Precision (Figures 4.3a and
4.3b), Recall (Figures 4.3c and 4.3d), and F-measure (Figures
4.3e and 4.3f), followed by a discussion of the results.
Figure 4.3 shows that one study ranked very well on
Precision, Recall, and F-measure. This study uses Bayesian algorithms (BayesNet and Naive Bayes)
as well as Decision Trees (J48 pruned and unpruned) to
recommend points of interest (POIs) to users. According to
the authors, the two main differences from other approaches
are the use of a user’s context, because at different contexts,
different items may be relevant or not to the user. A multiagent system (MAS) is also developed to handle requests.
Overall, many algorithms performed well in Precision,
Recall, and F-measure. The best for each metric is shown in
the top 10 plot.
Figure 4.4 shows the results for the Accuracy metric (Figures 4.4a and 4.4b). There is a quick drop in accuracy among
the algorithms, with few ranking above 80% accuracy. The
accuracy metric is one of the most intuitive ones, and should
not be overlooked, since it gives an initial perception of how
the ML algorithm is performing.
Figure 4.5 shows the breakdown of performance results for
RMSE (Round Mean Squared Error) (Figures 4.5a and 4.5b),
MAE (Mean Absolute Error) (Figures 4.5c and 4.5d), and
MAP (Mean Average Precision) (Figures 4.5e and 4.5f).
Two important points to be mentioned are as follows. One
may notice that plots of the ML algorithms related to error
metrics, such as RMSE and MAE, show the lower values on
top, instead of the bottom, so that the best performing studies
are shown on the top. The second point relates to MAP. This
metric did not have a relevant number of occurrences and for
that reason, the two plots about this metric are very similar.
The MAP plot about all studies was included for completeness.
On the plots for both the RMSE and the MAE metrics,
few studies had an excellent result. In the RMSE case, most
of the studies that reported this metric had a value greater
than 0.8. Care should be taken since the greater the error
the larger difference between what is expected and what is
predicted. In the RMSE result, Dinuzzo et al. reported
the value of 5.2, and in the MAE result, Bauer and Nanopoulos
 reported the value of 4.0234. Few studies reported
MAP values, but the plots were included in this discussion
because of the simplicity of the metric and the possible interest
of researchers in the results.
Finally, Figure 4.6 shows the breakdown of results for
the metrics ROC (Receiver Operating Characteristic curve)
(Figures 4.6a and 4.6b) and AUC (Area Under the ROC Curve)
(Figures 4.6c and 4.6d). It should be noted that both metrics
did not have a large number of occurrences in the studies
analyzed in this systematic review, but they were included in
this discussion owing to their academic importance.
It should be noticed that the study also
reported a high value of ROC for their algorithms. In terms of
AUC, most of the studies performed well and reported high
values of AUC. Although not very popular, these two metrics
can also be used by other researchers in their analysis to
improve the ﬁndings or the amount of detail of their proposals.
4.6 Alternative Performance Metrics
This section presents alternative metrics that can also be
used to describe the performance of ML algorithms in RS
development. These metrics are well described in another
study with examples and suggested ways of capturing data and calculating results. The
eight metrics are user preference, coverage, conﬁdence, trust,
novelty, serendipity, diversity, utility, risk, robustness, privacy,
and scalability. Some of them are discussed in the next few
paragraphs.
User preference, as its name suggests, relates to the opinion
of the user about the recommendations made by the RS.
Users are more likely to choose approaches that predict items
that match their preferences. Although the description is easy,
gathering user data to achieve high user preference is not.
The main method to obtain data about user preference is
the use of questionnaires. The coverage metric relates to the
items that can be recommended to the users that can receive
recommendations. There are speciﬁc ways to calculate the
coverage and one should refer to for more details.
Two additional alternative metrics are diversity and scalability. To discuss diversity, one must understand similarity,
since these two concepts are antagonistic. If the results are not
similar, then that means they are diverse. Lastly, scalability
does not mean much to the user, but important both to
researchh and performance. Scalability relates to how wellprepared the algorithms is to handle growth in the amount
of data. Most of the time, algorithms need more memory or
computation power to manipulate large amounts of data.
Table 4.9 shows the number of algorithms that included
a discussion on alternative metrics in its description. The
difference between the “Textual” and “Numeric” entries in
the table is because that discussion can be in the written form,
with considerations or suppositions, or it can be based on a
formula. The last column shows the studies that discussed the
algorithms. The difference between the number of algorithms
presented in the third column, and the number of studies of
the fourth column exists because a study may propose more
than one algorithm.
In addition, Table 4.9 displays four new alternative metrics:
transparency, quality, perplexity, and sensitivity. The papers
that reported values for those metrics do not provide a formal
deﬁnition. For that reason, they were presented in this systematic review, but not explained. One ﬁnal note is that the
perplexity metric is the closest one to another metric deﬁned
in : serendipity, which describes
how surprising the successful recommendations are.
 
 
Figure 4.3: A breakdown of the performance results for Precision, Recall, and F-measure
(a) Precision - Top 10
 
 
 
 
 
 
 
 
 
 
(b) Precision
(c) Recall - Top 10
 
 
 
 
 
 
 
 
 
 
(d) Recall
(e) F-measure - Top 10
 
 
 
 
 
 
 
 
 
 
(f) F-measure
 
 
Figure 4.4: A breakdown of the performance results for Accuracy
(a) Accuracy - Top 10
 
 
 
 
 
 
 
 
 
 
(b) Accuracy
Many studies have a numeric discussion of coverage with
formulas to describe their values. By inspecting these studies,
the authors noticed that they use speciﬁc formulas and no
standard is deﬁned. The same happened to the sensitivity
metric. This table describes many alternative performance
metrics used to evaluate ML algorithms in RS development
and introduces these metrics to those that did not know them.
Other metrics described in 
did not have any occurrence in the studies of this systematic
review and therefore were not included in the results table.
4.7 Analysis of the Sources
This section describes a different perspective on the analysis of the primary studies, and helps researchers ﬁnd more
information about ML algorithms for RS development. The
discussion focuses on other surveys and sources (e.g. conferences, journals) related to this systematic review.
This systematic review adopted an exclusion criteria that
limited the papers included in our study to primary studies.
This means that secondary studies such as other literature
reviews were not analyzed. However, these secondary studies
hold valuable knowledge that improves the research on the
ﬁeld and may be beneﬁcial to other researchers. For that
reason, Table 4.10 presents the secondary studies that were
excluded from this systematic review.
These secondary studies were not assessed for quality, but
they were returned by the search string of this systematic
review and are expected to cover the main research ﬁelds of
interest, such as recommender systems and machine learning
algorithms. The full reference to each secondary study is found
at the end of this study.
Moreover, domain experts that contributed to this work
shared other secondary studies that also relate to at least one of
the research ﬁelds of this systematic review. They are different
from those presented on Table 4.10 and may be also beneﬁcial
to researchers in the ﬁeld. Secondary studies suggested by
domain experts were not included in the analysis of this
systematic review because of the exclusion criteria previously
explained. The studies are shown in Table 4.11.
The search string used in this systematic review also returned conference and journal entries. Since these entries
are not peer-reviewed, they were not inspected based on the
exclusion criteria. However, researchers may ﬁnd it beneﬁcial
to know the conferences or journals that are reporting on the
research ﬁelds of recommender systems and machine learning
algorithms. Table 4.12 lists the sources (e.g. conferences,
journals) returned by the search string of this systematic review
with the year in which they were held. The list is sorted by
Finally, the authors decided to list the sources of the
primary studies inspected in this review and rank them by the
number of studies found in each source. Popular sources may
contain papers with similar interests to the research ﬁelds of
this systematic review and indicate possible places to submit
publications. Tables 4.13 and 4.14 present the sources of the
primary studies with the number of studies retrieved from
each source. In the table, two of the sources show up as
important sources of RS and ML algorithms: “Lecture Notes in
Computer Science” and “Expert Systems with Applications”.
5. CONCLUSIONS AND FUTURE WORK
Currently, recommender systems (RS) are widely used in
e-commerce, social networks, and several other domains.
Since the introduction of RSs in mid 1990s, research in RSs
has been evolving. One progressive step in RS history is
the adoption of machine learning (ML) algorithms, which
allow computers to learn based on user information and to
personalize recommendations further. Machine learning is an
Artiﬁcial Intelligence (AI) research ﬁeld that encompasses
algorithms whose goal is to predict the outcome of data
processing. ML has made major breakthroughs in the ﬁelds
of image recognition, search engines, and security. However,
the ML ﬁeld has several algorithms described in the literature,
with varied characteristics. The literature lacks a classiﬁcation
 
 
Figure 4.5: A breakdown of the performance results for RMSE, MAE, and MAP
(a) RMSE - Top 10
 
 
 
 
 
 
 
 
 
 
(c) MAE - Top 10
 
 
 
 
 
 
 
 
 
 
(e) MAP - Top 10
 
 
 
 
 
 
 
 
 
Figure 4.6: A breakdown of the performance results for ROC and AUC
(a) ROC - Top 10
 
 
 
 
 
 
 
 
 
(c) AUC - Top 10
 
 
 
 
 
 
 
 
 
 
system for algorithms showing the environment in which they
are most suitable. Therefore, researchers in RSs do not have a
clear view of the trends in ML algorithm usage to decide on
where to focus their research efforts. This study then proposes
a systematic review to observe the ML algorithms that are used
in RSs as well as the trends and open questions in this research
The systematic review collected 121 primary studies, after
ﬁltering out some based on exclusion criteria. All publications
were read and the conclusions are as follows. There is a
trend for collaborative approaches in RS development, especially with the use of neighborhood-based methods. Hybrid
approaches are still a research opportunity. A timeline with the
number of primary studies published in recent years conﬁrms
the trends and the opportunities mentioned.
Regarding the ML algorithms, both supervised and unsupervised learning are being well researched. Clustering
algorithms, as well Ensemble, and Support Vector Machines
(SVM) are among the ones most used. One may note again the
presence of neighborhood-based approaches among the ML
algorithms. The focus on Big Data technologies still remains
a research opportunity, with few studies even mentioning
massive data storage and analysis. The application domain
of movies ranks as ﬁrst among others mainly because of
MovieLens, a simple dataset available online. Finally, MAE,
Precision, Recall, and F-measure are the most used performance metrics to evaluate ML algorithms in RS development,
and Coverage is the most used alternative metric.
This systematic review has also included an analysis of the
sources of the primary studies that were selected. The analysis
presents surveys of the literature as well as conferences and
journals that may be of interest to researchers working on
similar topics.
This study has several contributions to research in expert
and intelligent systems. It presents a comprehensive overview
of ML algorithms in RSs that assists application developers
by helping them to identify the algorithms, their types, and
trends in the use of speciﬁc algorithms. This study also
provides existing classes of evaluation metrics and ranks the
ML algorithms based on these metrics. From this result,
researchers and practitioners are able not only to be familiar
with the most used evaluation metrics, but also to investigate
further the approaches that have the high rankings. In addition, this study identiﬁes and presents trends in the use of
 
 
Table 4.9: Alternative Performance Metrics
algorithms
Preference
 
 
Meybodi, 2010;
J. Li & Za¨ıane,
2004; Middleton
Taghipour et al.,
et al., 2015)
Scalability
Baldominos
et al., 2015)
Transparency
et al., 2007)
al., 2016)
Perplexity
Sensitivity
ML algorithms for RSs in different application domains. For
example, researchers and practitioners can become aware of
the algorithms that have been applied in a speciﬁc domain
(e.g. movie, news, e-commerce). Lastly, sources of primary
and secondary studies are provided. These sources can help
researchers and developers to position new research activity
in this domain appropriately.
In the future, more studies on the use of Clustering,
Ensemble, and SVM algorithms in RSs can be developed
to observe the implications of their use, performance, and
utility. Moreover, RS development lacks studies analyzing
early stages, such as requirements and design, and late stages,
such as maintenance. Other research opportunities involve the
investigation of Big Data technologies, which offer a wide
variety of methods to support the storage and analysis of
massive data. The authors also believe that many other open
questions involving research topics related to RSs and ML
algorithms should be investigated, including the application
of collaborative approaches in social networks and spatialtemporal domains.
ACKNOWLEDGMENT
The authors would like to thank the reviewers for their
valuable comments, which helped to improve our systematic
review. The authors also thank the Natural Sciences and
Engineering Research Council of Canada (NSERC), and the
Ontario Research Fund of the Ontario Ministry of Research,
Innovation, and Science for their ﬁnancial support for this