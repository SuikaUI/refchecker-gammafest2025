Deep Transfer Learning for Multiple Class Novelty Detection
Pramuditha Perera and Vishal M. Patel
Department of Electrical and Computer Engineering,
Johns Hopkins University, Baltimore, MD 21218, USA
 , ∗
We propose a transfer learning-based solution for the
problem of multiple class novelty detection. In particular,
we propose an end-to-end deep-learning based approach in
which we investigate how the knowledge contained in an external, out-of-distributional dataset can be used to improve
the performance of a deep network for visual novelty detection. Our solution differs from the standard deep classiﬁcation networks on two accounts. First, we use a novel
loss function, membership loss, in addition to the classical cross-entropy loss for training networks. Secondly, we
use the knowledge from the external dataset more effectively to learn globally negative ﬁlters, ﬁlters that respond
to generic objects outside the known class set. We show that
thresholding the maximal activation of the proposed network can be used to identify novel objects effectively. Extensive experiments on four publicly available novelty detection datasets show that the proposed method achieves
signiﬁcant improvements over the state-of-the-art methods.
1. Introduction
In recent years, intelligent systems powered by artiﬁcial
intelligence and computer vision that perform visual recognition have gained much attention , , . These systems observe instances and labels of known object classes
during training and learn association patterns that can be
used during inference. A practical visual recognition system should ﬁrst determine whether an observed instance is
from a known class. If it is from a known class, then the
identity of the instance is queried through classiﬁcation.
The former process is commonly known as novelty detection (or novel class detection) in the literature.
Given a set of image instances from known classes, the
goal of novelty detection is to determine whether an observed image during inference belongs to one of the known
classes. Novelty detection is generally a more challenging
∗This work was supported by the NSF grant 1801435.
Known Classes
Novel classes
Out-ofdistributional
Out-of-distributional
Figure 1. Novelty detection in dog-breed classiﬁcation.
Sample images. Right: Feature representation. Both known (ﬁrst
row) and novel (second row) images are images of dogs. Given
known images, the goal of novelty detection is to reject novel images. In order to do so, the knowledge of out-of-distributional
images (ﬁnal row), in this case non-dog images, are used to learn
a suitable representation.
task than out-of-distribution detection since novel object samples are expected to be from a similar distribution
to that of known samples.
In practice, the knowledge on unknown classes is not
entirely absent. Given a set of known classes from a certain problem domain, generally unknown class data from
the same problem domain is unavailable.
However, in
some cases it is possible to obtain data outside the known
class from different problem domains, which we refer to
as out-of-distributional samples. For example, for a dogbreed recognition application, ImageNet dataset that
contains images of objects may be considered as out-ofdistributional data as shown as in Figure 1. However, since
the out-of-distributional data are from a different problem
domain, they do not approximate the distribution of the
novel samples well.
Nevertheless, since the deep-models produce generalizable features, the knowledge of out-of-distributional samples can be transferred to the original problem to aid novelty
detection. When the problem considered is a c class problem, and when the out-of-distributional data of C classes are
available, the following three strategies are used to transfer
knowledge for novelty detection in the literature:
1. Fine-tuning: Network is ﬁrst pre-trained on the out-of-
 
distributional data and later ﬁne-tuned on the training data
of the given domain. Novelty is queried by thresholding the
ﬁnal activation score .
Feature Extraction: Conventional novelty detection
techniques , , are used based on the ﬁne-tuned
3. Fine-tune (c + C): Network is ﬁrst pre-trained on the
out-of-distributional data. Both the training data and the
out-of-distributional data are used to perform ﬁne-tuning in
(c + C) classes together. Novelty is determined in the same
way as in approach 1.
We note that in all these baselines,
the out-ofdistributional data is employed in the training process. In
fact, any novelty detection method operating on the pretrained/ﬁnetuned deep features are implicitly making use of
the out-of-distributional data. In this work, we introduce
a new framework to perform novelty detection based on
transfer learning. First, we show that using cross-entropy
loss alone for training is not optimal for the novelty detection task. Secondly, we empirically show that the out-ofdistributional data can be used more effectively in training to produce better novelty detection performance with
respect to considered baseline solutions. Speciﬁcally, we
make following primary contributions in this paper.
1. We propose an end-to-end novelty detection framework
based on deep learning. To the best of our knowledge, this is
one of the ﬁrst end-to-end deep learning solutions targeting
visual novelty detection.
We introduce a new loss function, membership loss
which has a similar functionality to that of the cross-entropy
loss but encourages an embedding that produces high activation for known object classes consistently.
3. We propose to take advantage of large-scale external
datasets to learn the globally negative ﬁlters to reduce high
activations caused by the novel images.
4. We show empirically, that the proposed method outperforms the baseline novelty detection methods across four
publicly available datasets.
2. Related Work
Object classiﬁcation schemes are often equipped with
a suitable mechanism to detect novel objects. For example, Eigenfaces was accompanied by a reconstruction error-based novel object detection method. In sparse
representation-based classiﬁcation (SRC) algorithm ,
Sparsity Concentration Index (SCI) was proposed for the
same purpose. In contrast, there is no formal novelty detection mechanism proposed for deep-learning based classiﬁcation. In its absence, thresholding the highest class activation score of the deep model has been used as a baseline in the literature . As an alternative, several recent
works have proposed novelty detection schemes based on
deep features , . In the same spirit, it is also a possibility to use classical novelty detection tools such as Kernel
PCA , Kernel null space-based novelty detection (KN-
FST) and its variants , on deep features. KNFST
operating on deep-features produces the current state of the
art performance in visual novelty detection . However,
advantages of deep-learning are not properly exploited in
all of these approaches due to the absence of an end-to-end
learning framework.
On the other hand, novelty detection problem has a close
resemblance to both anomaly detection , , , 
and open-set recognition problems , . Therefore, it
is possible to solve anomaly detection using tools proposed
in these alternative domains. In anomaly detection, given a
single normal class, the objective is to detect out-of-class instances. One-class SVM and SVDD are two of the
most widely used tools in anomaly detection. Novelty detection can be viewed as an anomaly detection problem if all
known classes are considered as a single augmented class.
On the other hand, objective in open-set recognition (OSR)
is similar to that of novelty detection. But in addition, OSR
requires correct classiﬁcation of samples detected as known
samples. Therefore, it is also possible to use open-set recognition tools to perform novelty detection. However, we note
that due to subtle differences in objectives, OSR algorithms
are not optimal for novelty detection.
In the proposed framework, maximal activation of the ﬁnal layer of a deep network is considered as a statistic to perform novelty detection. We design the network and choose
loss functions appropriately so that this statistic is low for
novel objects compared to the known object classes.
3. Background
In this section, we brieﬂy review how deep networks
produce activations in response to input stimuli. Based on
this foundation, we introduce the notion of positive ﬁlters
and negative ﬁlters.
Consider a c class fully-supervised
object classiﬁcation problem with a training image set
x = x1, x2, . . . , xn and the corresponding labels y =
y1, y2, . . . , yn where yi ∈{1, 2, . . . c}. Deep convolutional
neural networks (CNNs) seek to learn a hierarchical, convolutional ﬁlter bank with ﬁlters that respond to visual stimuli
of different levels. In c class classiﬁcation, the top most
convolutional ﬁlter activation g is subjected to a non-linear
transformation to generate the ﬁnal activation vector f ∈Rc
(for example, g is the conv5-3 layer in VGG16 and conv5c
in Resnet50. f is the fc8 and fc1000 layers in the respective
networks). In a supervised setting, network parameters are
learned such that arg max f = yi for ∀i ∈{1, 2, . . . , n}.
This is conventionally done by optimizing the network parameters based on the cross-entropy loss.
If there exist k ﬁlters in the top most convolution ﬁlter
bank, its output g is a set of k number of activation maps.
The ﬁnal activation vector of the network f is a function of
Figure 2. Positive and negative ﬁlters of the sand snake class in the
Resnet50 trained on ILSVRC12 dataset. Top: weights of the fully
connected layer corresponding to the sand snake class. We call
ﬁlters associated with positive weights as positive ﬁlters of sand
snake class. All other ﬁlters are named as negative ﬁlters. Bottom:
Visualization of top negative and positive ﬁlters. These patterns
are likely to produce high activation in these ﬁlters. We note top
positive ﬁlters are activated by snake-like structures.
g. For a given class i, there exists some ki ﬁlters in the ﬁlter
bank (1 ≤ki ≤k) that generally generates positive activation values. These activations provide supporting (positive)
evidence that an observed image is from class i. Conversely,
all remaining ﬁlters provide evidence against this hypothesis. Activation score of each class in f is determined by
taking into account the evidence for and against each class.
For the remainder of the paper, we call ﬁlters that provide
evidence for and against a particular class as positive ﬁlters
and negative ﬁlters of the class, respectively.
This concept can be easily explained by taking the
Resnet architecture as an example.
In Resnet, ﬁnal
convolution output g is subjected to global average pooling followed by a fully connected layer. Therefore, the ith
component of the ﬁnal activation vector f can be written as
fi = Wi × GAP(g), where GAP is global average pooling
operation (mean of ﬁlter map) and W is the weight matrix
of the fully connected layer. Here, activation of the ith class
is a weighted summation of mean feature maps found in g.
From the above deﬁnition, ﬁlters associated with positive
weights for a given class in W can be identiﬁed as positive
ﬁlters for that particular class. Conversely, ﬁlters associated with the negative weights become negative ﬁlters of
the class.
For example consider the Sand Snake class appearing in
the ILSVRC12 dataset . Shown in Figure 2 (top) are
the weights associated with the Sand Snake class in the ﬁnal fully connected layer of the Resnet50 network trained
on the ILSVRC12 dataset. We recognize ﬁlters associated
with positive and negative weights as positive and negative
ﬁlters, respectively for the given class. In Figure 2 (bottom)
we visualize per-unit visualization of top positive and top
negative ﬁlters for the considered class using the DeepVis
toolbox (these are the images that are most likely to activate the corresponding ﬁlters). By observation, we notice
that the top positive ﬁlters are activated when the network
observes structures similar to snakes. On the other hand, the
top negative ﬁlters are unrelated to the appearance of sand
4. Deep Novelty Detection
Based on the above background, we propose to learn the
distributions of known object classes using a CNN framework with the objective of performing joint classiﬁcation
and novelty detection. In our formulation, assuming each
known class has a unique single label, we force the ﬁnal activation vector f to model the probability distribution vector of known classes. Formally, for a given data-label pair
(xi, yi), we expect fi = 1 and fj = 0, ∀j ̸= i. Once such a
representation is learned, arg max f returns the most-likely
class of an observed sample. Then, max f yields the likeliness of the sample belonging to the most likely class. Similar to binary classiﬁcation, identity I of a test instance can
be queried using hard thresholding. In order to learn a representation suitable for the stated objective, we use conventional classiﬁcation networks as the foundation of our work
and propose the following two alternations.
1. Membership loss. Assuming each known class has a
unique single label, if the observed image is from a known
class, only a single positive activation should appear in f.
We observe that when cross-entropy loss is used, this is not
the case. To alleviate this, we introduce a new loss called
membership loss in addition to the cross-entropy loss.
2. Globally negative ﬁlters. In a classiﬁcation setting, a
negative ﬁlter of a certain class is also a positive ﬁlter of another class. In other words, there exist no explicit negative
ﬁlters. In our formulation, we propose to generate globally
negative ﬁlters (ﬁlters that generate negative evidence for all
known classes) to reduce the possibility of a novel sample
registering high activation scores.
4.1. Limitations of Cross-Entropy Loss
When a classiﬁcation network is trained, each element
fi of the activation vector f is ﬁrst normalized using the
softmax function to arrive at a normalized activation vector
˜f as in, ˜fj = efj/
efj. When it is assumed that all image
classes appearing during inference are known ahead of time,
jth element of vector ˜f is interpreted as the likelihood of the
input image xi belonging to the jth class. Neural networkbased classiﬁcation systems are learned by minimizing the
cross-entropy loss which is the negative log likelihood of
the correct class ˜f. However, since this is a relative measure,
the learned representation deviates from our objective due
to the following reasons.
Firstly, even a low activation of the ground truth class
could yield a low cross-entropy provided that the activaconv5_3
Conventional CNN
Calculator
Playing Cards
Proposed Method
Positive Filters (Calculator)
Globally Negative Filters
Figure 3. (a) Activations of known (Calculator) and unknown samples (Playing Cards) in a VGG16 model. In conventional CNN, both
known and unknown samples activates similar conv5-3 ﬁlters and results in a similar fc8 activation map. Novelty detection of the novel
sample fails due to high activation scores present in fc8 layer. In the proposed method, Calculator object activates ﬁlters related to
Calculators whereas top activated ﬁlters in Playing Cards is unrelated to known classes (globally negative). Since all activations in fc8
are very small for the Playing Cards object, it can be detected as a novel sample by thresholding. (b) Top positive ﬁlters and top globally
negative ﬁlters of the calculator class.
tions of all other (non-matching) classes are very low. As
a result, lower score values may not get heavily penalized
during training. Therefore, a model trained using the crossentropy loss may end up producing low activation scores
for known classes during inference. In closed set classiﬁcation, this behavior will not cause complications as long
as the correct class records the highest score. However, in
threshold-based novelty detection, this poses a problem as
having low scores for the positive class will result in false
negatives. Secondly, the cross-entropy loss does not penalize activations of unrelated classes as long as the correct
class produces the highest activation. As a result, inaccurate
cross-class relationships are encouraged during training.
In order to illustrate this point, we trained a VGG16 
based CNN classiﬁcation network using the ﬁrst 128 classes
of the Caltech256 dataset. For the considered example, the
Calculator class (indexed at 27) is a known class and the
Playing Cards class (indexed at 163) is a novel class. Shown
in Figure 3 are the activations of conv5-3 and fc8 layers of
the network for two inputs of the two classes. As can be
seen from this ﬁgure, when the network observes a calculator object (known object), it correctly associates the highest
score in f to the correct class (class 27). However, there
is also a signiﬁcant miss-association between the calculator
class and coin (class 43), keyboard (class 45), dice (class
55) and joystick classes (class 120).
4.2. Membership Loss
In our approach, we ﬁrst independently translate each
activation score value fi into the range 0 −1 using the
sigmoid(σ) function. We interpret each transformed activation score as the probability of the input image belonging to each individual class. If the ground truth label of a
given observation x is y, we aim at learning a function that
produces absolute probabilities for the membership of each
class as follows
P(y = i) = σ(f(x)i) ∀i ∈{1, 2, . . . c}.
Ideally, the learned transformation will produce f(x)i = 1
for i = y and f(x)i = 0, otherwise. We denote the risk of
associating a higher score with a wrong class (f(x)i = 1
for i ̸= y ) as RW 1 and risk of associating a low score with
the correct class (f(x)i = 0 for i = y) as RC0. We deﬁne
the membership loss LM as the risk of classiﬁcation as
LM(x, y) = RC0(x, y) + λRW 1(x, y),
where λ is a positive scalar. With our formulation, we deﬁne
RW 1(x, y) = [1 −P(y = 1)]2 = [1 −σ(f(x)y)]2. Here,
the quadratic term is introduced to impose a heavy penalty
on very high deviations. Similarly, RC0(x, y) becomes,
RC0(x, y) =
[P(i = 1)]2
[σ(f(x)i)]2.
By substitution, we get
LM(x, y) = [1 −σ(f(x)y)]2 + λ
[σ(f(x)i)]2.
Here, the parameter λ controls relative weight given to each
risk source. In our experiments, we set λ = 5. Taking the
partial derivative of the membership loss yields the following back-propagation formula
−2[1 −σ(f(x)i)] × σ(f(x)i)′
c−1σ(f(x)i) × σ(f(x)i)′
for i ̸= y,
where, σ(f(x)i)′ = σ(f(x)i)(1 −σ(f(x)i)).
The proposed membership loss does not operate on the
closed-set assumption. It takes individual score values into
account in an absolute sense. Therefore, when the membership loss is used, known samples that produce small activations will be penalized regardless of the score values of the
other classes. When the membership loss is used together
with the cross-entropy loss, the network learns a representation that produces relatively higher activation scores for
the correct class. For example, consider the fc8 activation
map of the proposed method for the Calculator object input
shown in Figure 3. There, we observe that the correct class
(indexed at 27) produces a large positive score whereas all
other classes produce negative scores.
4.3. Globally Negative Filters
When a conventional classiﬁcation network is used,
novel images are often able to produce very high activation
scores there by leading to false positive detections. Such
an example is shown in Figure 3(bottom) where a Playing
Cards instance has produced a very high activation score
in the index corresponding to the Calculator class (indexed
at 27). Final activation score of a class is generated based
on the responses of the positive and negative ﬁlters as discussed in Section 3. Once the network is trained, given an
input of a particular known class, the input stimulates some
positive ﬁlters and negative ﬁlters associated with the class.
If the model is well trained, the response of the positive ﬁlters exceeds the response of the negative ﬁlters to produce a
high positive activation score.
Given this background, it is interesting to investigate
how a novel sample is able to produce a high activation
Let us revisit activations of Playing Cards image
(novel image) shown in Figure 3 (bottom). In this example, Playing Cards image has stimulated some positive ﬁlters of the Calculator class despite the differences in content. At the same time, by chance, it has not produced suf-
ﬁcient stimulation in negative ﬁlters of the Calculator class,
thereby producing a large positive activation in f. This can
be clearly observed in Figure 3 where both the Calculator
and the Playing Cards images have activated similar ﬁlters
in the conv5-3 layer.
To this end, we make the following proposal. We wish
to learn a set of ﬁlters that are stimulated generally by natural images and produce evidence against all known classes.
In other words, these ﬁlters are negative ﬁlters with respect
to all known classes - hence we call them globally negative
ﬁlters. If any of such ﬁlters are stimulated during inference,
it would prove greater evidence that the observed image is
novel. However, this proposal will succeed only if the globally negative ﬁlters are stimulated by arbitrary images outside the known class set.
In order to learn the globally negative ﬁlters, we propose a joint-learning network structure. In addition to the
known object dataset, we use the out-of-distributional data
samples in training. For the remainder of the paper we refer the out-of-distributional dataset as the reference dataset.
We learn features that can perform classiﬁcation in both the
known dataset and the reference dataset. If the reference
dataset has C classes, once trained, the ﬁlter bank will contain positive ﬁlters of all c + C classes. Filters associated
with the reference dataset will likely act as negative ﬁlters
for all classes in the known dataset, thereby be globally negative. In this framework, the globally negative ﬁlters are
likely to respond to arbitrary natural images provided that
the reference dataset is a large-scale diverse dataset.
In Figure 3, we show the impact of using the globally
negative ﬁlters. Visualization of top activated ﬁlters for the
Calculator class are shown at the top in Figure 3(b). As
can be seen from this ﬁgure, these ﬁlters are positively corelated with the Calculator class. With the new formulation,
we observe that playing cards object activates some extra
ﬁlters which are not in common with the calculator class
(highlighted in red). At the bottom of Figure 3(b) we visualize ﬁlters with the highest activation for the Playing Cards
object. By inspection, these two visualizations look arbitrary and do not have an obvious association with any of the
Caltech256 classes. We interpret these ﬁlters as instances
of the globally negative ﬁlters. Due to the availability of
more negative evidence, the overall activation value of the
playing cards object has been drastically reduced.
4.4. Training Procedure
We propose a network architecture and a training mechanism to ensure that the network learns the globally negative
ﬁlters. For this purpose, we use an external multi-class labeled dataset which we refer to as the reference dataset.
We ﬁrst select a CNN backbone of choice (this could be a
simple network such as Alexnet or a very deep/complex
structure such as DenseNet ). Two parallel CNN networks of the selected backbone are used for training as
shown in Figure 4(a). The only difference between the two
parallel networks is the ﬁnal fully-connected layer where
the number of outputs is equal to the number of classes
present in either dataset. For the purpose of our discussion,
we refer the sub-network up to the penultimate layer of the
CNN as the feature extraction sub-network.
Initially, weights of the two feature extraction subnetworks are initialized with identical weights and they are
kept identical during training. Final layer of both parallel
networks are initialized independently. Weights of these
two layers are learned during training without having any
dependency between each other. During training, two mini
batches from two datasets (reference dataset (R) and known
classes (T)) are considered and they are fed into the two
branches independently.
We calculate the cross-entropy
loss (Lce) with respect to the samples of the reference
dataset and both the membership loss (Lm) and the crossentropy loss with respect to the samples of known classes.
The cumulative loss of the network then becomes a linear
combination of the two losses as follows,
CumulativeLoss = Lce(R) + α1 Lce(T) + α2 Lm(T).
In our experiments, we keep α1, α2 = 1. The cumulative
loss is back-propagated to learn the weights of the two CNN
Reducing membership loss and cross-entropy
loss with respect to the known-class dataset increases the
potential of performing novelty detection in addition to classiﬁcation as discussed in the preceding sub-section. On the
other hand, having good performance (low cross-entropy
loss) in the reference dataset suggests the existence of ﬁlters that are responsive to generic objects provided that the
reference dataset is sufﬁciently diverse. When classes appearing in the reference dataset do not intersect with known
classes, these ﬁlters serve as the globally negative ﬁlters.
Figure 4. Proposed architecture for novelty detection. We use an
external multi-class dataset (reference dataset (R)) in addition to
the known object dataset (T). Two parallel CNN networks with
identical structure and weights are used to extract features from
both datasets. We train separate classiﬁer networks operating on
the same feature to perform classiﬁcation in either dataset. During inference, novelty detection is performed by thresholding the
maximal activation of the bottom branch of the network.
4.5. Testing (Novelty Detection)
During inference, we propose to use the setup shown in
Figure 4(b) where we only consider the bottom CNN branch
of the training network. Given a test image x, we perform a
forward pass using the learned CNN network to obtain the
ﬁnal feature f(x). The largest element of f(x), max f(x) is
thresholded using a predetermined threshold γ to arrive at
the identity of the test image. If the yielded score is below the threshold γ, we identify the test sample to be novel.
In a practical system, threshold γ is chosen considering the
percentile of the matched score distribution (for example
threshold can be chosen to be 95th percentile if the accepted
false negative rate is 5%) . In addition to the novelty detection procedure, the same network structure can be used to
perform classiﬁcation as well. Here, arg max f(x) yields
the identity of the predicted class for the test sample x. We
note that this step is identical to the classiﬁcation procedure
used in the standard CNN-based classiﬁcation.
5. Experimental Setup and Results
In this section, we present experimental results for the
novelty detection task. We ﬁrst describe the baseline methods used for comparison.
Then, we introduce the four
datasets used for evaluation. Finally, we discuss the obtained results followed by the analysis of the proposed
5.1. Baseline Methods
We evaluate the proposed method on four novelty detection databases and we compare its performance with the
standard novelty detection schemes. We use the following baseline comparisons based on the AlexNet and the
VGG16 features ﬁne-tuned on the given dataset.
1. Finetune : fc8 feature scores of the trained deep
model are thresholded to detect novel samples.
2. One-class SVM : A one-class SVM classiﬁer is
trained for all known classes. The maximum SVM score
is considered during the inference.
3. KNFST , : Deep features are normalized and histogram intersection kernel method is used to generate inner
products between the samples.
4. Local KNFST : Deep features with histogram intersection kernel is considered with 600 local regions.
5. OpenMax : Activations of penultimate layer of a
deep model are used to construct a single channel classwise mean activation vectors (MAV) and the corresponding
Weibull distributions.
6. K-extremes : Mean activations of the VGG16 fc7
features are considered for each class and top 0.1 activation
indexes are binarized to arrive at the Extreme Value Signatures.
7. Finetune(c+C): A (c+C) class CNN is trained by treating classes of the reference dataset as the additional class.
In addition, we evaluate the performance based on the pretrained deep features (trained on the ILSVRC12 database)
for KNFST and local KNFST methods.
Whenever pretrained features are use they are denoted by the sufﬁx pre.
5.2. Datasets
We use four publicly available multi-class datasets to
evaluate the novelty detection performance of the proposed
Caltech-256
FounderType-200
Figure 5. Sample images from the evaluation datasets. Each column contains images taken from a single class of each dataset.
Caltech256 Dataset. The Caltech256 dataset is a fully annotated dataset which consists of 30607 images from 256
object classes. Following the protocol presented in , we
ﬁrst sorted the class names alphabetically and picked the
ﬁrst 128 classes as the known classes and considered the
images from the remaining 128 classes as the novel images.
Caltech-UCSD Birds 200 (CUB 200) Dataset. The CUB-
200 dataset includes 6033 images belonging to 200 distinct
bird categories. Ground truth labels for each image are provided. In our experiment, we sorted names of the bird categories alphabetically and used the ﬁrst 100 classes as the
known classes. The remaining classes were used to represent novel images.
Stanford Dogs Dataset. This dataset is a subset of the ImageNet dataset and was originally intended for ﬁne-grain
classiﬁcation. There are 20580 images belonging to 120
different dog breeds in this dataset. We considered the ﬁrst
60 classes as the known classes and treated the remaining
classes as the novel classes during performance evaluation.
FounderType-200 Dataset.
This dataset is a collection
of Chinese character images in different font types. The
dataset is organized based on the font-type. In total there are
200 different font-types with 6763 images from each class
in this dataset. Following the same convention as before, we
picked the ﬁrst 100 classes to represent the enrolled classes.
The remaining 100 classes were used to simulate the novel
In all datasets, following the protocol in , images
of the enrolled classes were randomly split into two even
sets to form training and testing datasets of the enrolled
classes. Images of the novel classes were used only during
testing. When ﬁnetuning/extracting features from the caltech256 dataset following , we used the pretrained model
trained on the Places365 dataset . For all other tasks, we
used the pretrained model trained on the ILSVRC12 dataset.
Accordingly, the validation sets of Places365 was used as
the reference dataset for Caltech256. For all other tasks the
validation set of ILSVRC12 was considered.
5.3. Results
We evaluated all methods based on the VGG16 and the
AlexNet features. We used the training codes provided by
the authors when evaluating the KNFST and the local
KNFST methods. Performance of each method is evaluated using the area under the receiver operating characteristics (AUC) curve. Obtained AUC values for each method
are tabulated in Table 1 for all datasets1.
Table 1. Novelty detection results (AUC of the ROC curve) on the
evaluation datasets. The best performing method for each dataset
is shown in bold. Second best method is shown in italics.
Caltech-256
FounderType
Finetune , 
One-class SVM 
KNFST pre 
KNFST , 
Local KNFST pre 
Local KNFST 
K-extremes 
OpenMax 
Finetune(c + C)
Deep Novelty (ours)
When baseline methods are considered, a variance in
performance can be observed across datasets. In general,
K-extremes has reported below-par performances compared
to the other methods. When the number of enrolled classes
are very high, the mean activation signature of a class looses
its uniqueness. This is why K-extremes method fails when
very large number of classes are enrolled as suggested in
 . In the Caltech-256 and CUB-200 datasets, thresholding deep activations and OpenMax has yielded better results
among the baseline methods. In Caltech256, this has improved marginally when the reference dataset (ILSVRC12)
is incorporated.
This method has performed reasonably
well in the FounderType-200 dataset but it’s performance
in the Standford Dogs dataset is not convincing. In general,
KNFST has out-performed local KNFST except for in the
Standford Dogs dataset. KNFST (and local KNFST) operating on the ﬁnetuned deep features have performed better
in general compared to the pre-trained deep features. This
trend has changed only in the Standford Dogs dataset. Here
we note that none of the baseline methods have yielded consistent performance across datasets.
In comparison, the proposed method is able to produce
the best performance across all datasets. When AlexNet is
used as the back-bone network, there is an improvement of
about 3.0% over the baselines in the CUB-200 and Standford Dogs datasets. In the other two datasets this margin is
2.0%. In the Caltech256, CUB-200 and FounderType-200
datasets, the improvements in AUC are in excess of 2.0%
for the VGG16 model. In the Standford Dogs dataset, the
proposed method is able to introduce a signiﬁcant advancement of more than 7.0% in AUC compared with the baseline methods. In general, we note that in datasets where
the baseline performance is already very good, as in the
CUB-200 and FounderType 200 datasets, the improvement
of the proposed method is relatively small. On the other
hand, when the baseline performance is poor, the proposed
method is able to generate a signiﬁcant improvement in the
performance.
 
5.4. Ablation Study
In this subsection, we investigate the impact of each individual component of the proposed framework. For the
purpose of the ablation study, we use the validation dataset
of the ILSVRC12 dataset as the reference dataset. It should
be noted that ﬁgures reported in this subsection are different from Table 1 due to this reason. Starting from the traditional CNN architecture, we added one component of the
proposed framework at a time and evaluated the novelty detection performance on the Caltech-256 dataset as a case
study. Testing protocol presented in the preceding subsection was followed in all cases. Considered cases are as follows.
a) Single CNN with the cross-entropy loss (AUC 0.854).
This is the CNN baseline where a CNN is trained using the
enrolled classes conventionally.
b) Single CNN with the cross-entropy loss+membership
loss (AUC 0.865). The network architecture is the same
as in case (a). In addition to the cross-entropy loss, the
membership loss is calculated with respect to the enrolled
c) Two Parallel CNNs with cross-entropy loss (AUC
0.864). The network structure proposed in Figure 4(a) is
used. In contrast, only the cross-entropy loss is used in the
bottom sub-network.
d) Proposed method (AUC 0.906).
Proposed structure
Figure 4(a) is used for training.
In the proposed method, we introduced membership loss
and a parallel network structure as contributions. From the
case study conducted, it appears that the novelty detection
performance improves compared to the baseline even when
one of the contributions are used. Moreover, we observe
that the two contributions compliment each other and generate even better results when combined together.
5.5. Impact of the Reference Dataset
In the proposed method, we assumed the availability of a
reference dataset with large number of classes. In this subsection, we investigate the impact of the reference dataset
by varying the reference dataset of choice. In particular,
we use the ILSVRC12, Caltech-256 and Standford Dogs
datasets as the reference datasets to perform novelty detection using the proposed method in the CUB-200 dataset.
Results obtained are tabulated in Table 2. Here we have included the performance of the best baseline method for the
CUB-200 dataset (Finetune) from Table 1 as a baseline.
Compared to ILSVRC12, when Caltech-256 is used as
the reference dataset, AUC drops by 0.005%.
This further drops by 0.008% when the Standford Dogs dataset is
used. The ILSVRC12 dataset contains 1000 image classes
and has signiﬁcant variance in images within each class.
Caltech-256 is a similar multi-class dataset but with fewer
Both of these datasets contain natural images.
However since ILSVRC12 has more classes and more intraclass variance, we expect it to generate globally negative
ﬁlters better. Therefore, the performance drop of Caltech-
256 compared to ILSVRC12 is expected.
On the other
hand, the Standford Dogs dataset only contains images of
dogs. Therefore, ﬁlters learned using this dataset may not
be generic to get stimulated by the arbitrary inputs. Therefore, the drop in the performance is justiﬁed. In conclusion,
we note that the proposed method is able to out-perform
baseline novelty detection methods even when the reference
dataset is varied. However, better results are obtained when
a larger dataset with high degree of intra-class variation is
used as the reference dataset.
Table 2. Impact of the reference dataset used. Results of the case
study conducted on the CUB-200 dataset by varying the reference
Caltech-256
Novelty Detection AUC
5.6. Impact on Classiﬁcation Accuracy
When a test image is present, the proposed method produces a set of class activation scores. It is still possible to
perform classiﬁcation using the same system by associating the test image with the class containing the highest activation. In what follows, we consider test samples of the
known classes and perform closed-set classiﬁcation in the
same experimental setup described in Section 5.3. In other
words, we do not consider novel samples for the purpose
of this study. Obtained classiﬁcation accuracies for the four
datasets are tabulated in Table 3. Although the proposed
method is designed for the purpose of novelty detection,
we note that the proposed changes have contributed towards
increasing the classiﬁcation accuracy of the system as well.
This is because the membership loss explicitly enforces correct class to have a high score and all other classes to have
scores closer to zero.
Table 3. Classiﬁcation accuracy obtained for conventional ﬁnetuning and the proposed method for the four evaluation datasets.
Caltech-256
FounderType
Proposed Method
6. Conclusion
We presented an end-to-end deep learning-based solution for image novelty detection. We build up on the conventional classiﬁcation networks and introduce two novel
contributions; namely, membership loss and a training procedure that produces globally negative ﬁlters. In the proposed method, novelty is quarried simply by thresholding
the highest activation of the output vector. We demonstrate
the effectiveness of the proposed method on four publicly
available multi-class image datasets and obtain state-of-theart results.