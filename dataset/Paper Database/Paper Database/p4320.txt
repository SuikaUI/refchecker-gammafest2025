Knowledge-Deﬁned Networking
Albert Mestres∗, Alberto Rodriguez-Natal∗, Josep Carner∗, Pere Barlet-Ros∗, Eduard Alarc´on∗,
Marc Sol´e†, Victor Munt´es-Mulero†, David Meyer‡, Sharon Barkai§, Mike J Hibbett¶, Giovani Estrada¶,
Khaldun Ma‘ruf∥, Florin Coras∗∗, Vina Ermagan∗∗, Hugo Latapie∗∗, Chris Cassar∗∗, John Evans∗∗, Fabio Maino∗∗,
Jean Walrand†† and Albert Cabellos∗
∗Universitat Polit`ecnica de Catalunya † CA Technologies
‡ Brocade Communication
§ Hewlett Packard Enterprise
¶ Intel R&D
∥NTT Communications
∗∗Cisco Systems
†† University of California, Berkeley
Abstract—The research community has considered in the past
the application of Artiﬁcial Intelligence (AI) techniques to control
and operate networks. A notable example is the Knowledge Plane
proposed by D.Clark et al. However, such techniques have not
been extensively prototyped or deployed in the ﬁeld yet. In this
paper, we explore the reasons for the lack of adoption and
posit that the rise of two recent paradigms: Software-Deﬁned
Networking (SDN) and Network Analytics (NA), will facilitate the
adoption of AI techniques in the context of network operation
and control. We describe a new paradigm that accommodates and
exploits SDN, NA and AI, and provide use cases that illustrate its
applicability and beneﬁts. We also present simple experimental
results that support its feasibility. We refer to this new paradigm
as Knowledge-Deﬁned Networking (KDN).
Keywords—Knowledge Plane, SDN, Network Analytics, Machine
Learning, NFV, Knowledge-Deﬁned Networking
INTRODUCTION
D. Clark et al. proposed “A Knowledge Plane for the
Internet” , a new construct that relies on Machine Learning (ML) and cognitive techniques to operate the network.
A Knowledge Plane (KP) would bring many advantages to
networking, such as automation (recognize-act) and recommendation (recognize-explain-suggest), and it has the potential
to represent a paradigm shift on the way we operate, optimize
and troubleshoot data networks. However, at the time of this
writing, we are yet to see the KP prototyped or deployed.
One of the biggest challenges when applying ML for
network operation and control is that networks are inherently
distributed systems, where each node (i.e., switch, router) has
only a partial view and control over the complete system.
Learning from nodes that can only view and act over a small
portion of the system is very complex, particularly if the
end goal is to exercise control beyond the local domain. The
emerging trend towards centralization of control will ease
this ﬂavor of complexity. In particular, the Software-Deﬁned
Networking (SDN) paradigm decouples control from the
data plane and provides a logically centralized control plane,
i.e. a logical single point in the network with knowledge of
the whole.
In addition to the ”softwarization” of the network, current
network data plane elements, such as routers and switches, are
equipped with improved computing and storage capabilities.
This has enabled a new breed of network monitoring techniques, commonly referred to as network telemetry . Such
techniques provide real-time packet and ﬂow-granularity information, as well as conﬁguration and network state monitoring
data, to a centralized Network Analytics (NA) platform .
In this context, telemetry and analytics technologies provide
a richer view of the network compared to what was possible
with conventional network management approaches.
In this paper, we advocate that the centralized control offered
by SDN, combined with a rich centralized view of the network
provided by network analytics, enable the deployment of the
KP concept proposed in . In this context, the KP can use ML
and Deep Learning (DL) techniques to gather knowledge about
the network, and exploit that knowledge to control the network
using logically centralized control capabilities provided by
SDN. We refer to the paradigm resulting from combining SDN,
telemetry, Network Analytics, and the Knowledge Plane as
Knowledge-Deﬁned Networking.
This paper ﬁrst describes the Knowledge-Deﬁned Networking (KDN) paradigm and how it operates. Then, it describes
a set of relevant use-cases that show the applicability of such
paradigm to networking and the beneﬁts associated with using
ML. In addition, for some use-cases, we also provide early
experimental results that show their feasibility. We conclude
the paper by analyzing the open research challenges associated
with the KDN paradigm.
A KNOWLEDGE PLANE FOR SDN ARCHITECTURES
This paper restates the concept of Knowledge Plane (KP) as
deﬁned by D. Clark et al. in the context of SDN architectures. The addition of a KP to the traditional three planes of
the SDN paradigm results in what we call Knowledge-Deﬁned
Networking. Fig. 1 shows an overview of the KDN paradigm
and its functional planes.
The Data Plane is responsible for storing, forwarding and
processing data packets. In SDN networks, data plane elements are typically network devices composed of line-rate
programmable forwarding hardware. They operate unaware of
the rest of the network and rely on the other planes to populate
their forwarding tables and update their conﬁguration.
The Control Plane exchanges operational state in order
to update the data plane matching and processing rules. In
an SDN network, this role is assigned to the –logically
centralized– SDN controller that programs SDN data plane
forwarding elements via a southbound interface, typically
using an imperative language. While the data plane operates
 
MANAGEMENT
KDN planes
at packet time scales, the control plane is slower and typically
operates at ﬂow time scales.
The Management Plane ensures the correct operation and
performance of the network in the long term. It deﬁnes the
network topology and handles the provision and conﬁguration
of network devices. In SDN this is usually handled by the SDN
controller as well. The management plane is also responsible
for monitoring the network to provide critical network analytics. To this end, it collects telemetry information from the data
plane while keeping a historical record of the network state and
events. The management plane is orthogonal to the control and
data planes, and typically operates at larger time-scales.
The Knowledge Plane, as originally proposed by Clark, is
redeﬁned in this paper under the terms of SDN as follows:
the heart of the knowledge plane is its ability to integrate behavioral models and reasoning processes oriented to decision
making into an SDN network. In the KDN paradigm, the KP
takes advantage of the control and management planes to obtain a rich view and control over the network. It is responsible
for learning the behavior of the network and, in some cases,
automatically operate the network accordingly. Fundamentally,
the KP processes the network analytics collected by the management plane, transforms them into knowledge via ML, and
uses that knowledge to make decisions (either automatically or
through human intervention). While parsing the information
and learning from it is typically a slow process, using such
knowledge automatically can be done at a time-scales close to
those of the control and management planes.
KNOWLEDGE-DEFINED NETWORKING
The Knowledge-Deﬁned Networking paradigm operates by
means of a control loop to provide automation, recommendation, optimization, validation and estimation. Conceptually, the
KDN paradigm borrows many ideas from other areas, notably
from black-box optimization , neural-networks in feedback
control systems and autonomic self-* architectures . In
addition, recent proposals share the same vision stated in this
Forwarding elements
controller
Human decision
Automatic decision
KDN operational loop
paper . Fig. 2 shows the basic steps of the main KDN
control. In what follows we describe these steps in detail.
a) Forwarding Elements & SDN Controller →Analytics
Platform: The Analytics Platform aims to gather enough
information to offer a complete view of the network. To that
end, it monitors the data plane elements in real time while
they forward packets in order to access ﬁne-grained trafﬁc
information. In addition, it queries the SDN controller to
obtain control and management state. The analytics platform
relies on protocols, such as NETCONF (RFC 6241), NetFlow
(RFC 3954) and IPFIX (RFC 7011), to obtain conﬁguration
information, operational state and trafﬁc data from the network.
The most relevant data collected by the analytics platform is
summarized below.
Packet-level and ﬂow-level data: This includes DPI
information, ﬂow granularity data and relevant trafﬁc
Network state: This includes the physical, topological
and logical conﬁguration of the network.
Control & management state: This includes all the information included both in the SDN controller and management infrastructure, including policy, virtual topologies,
application-related information, etc.
Service-level telemetry: In some scenarios the analytics platform will also monitor service-level information
(e.g., load of the services, QoE, etc). This is relevant
to learn the behavior of the application or service, and
its relation with the network performance, load and
conﬁguration.
External information: In some scenarios it may be useful
to also have access to external information, such as
social networks (e.g., amount of people attending a
sports event), weather forecasts, etc. that may have a
strong impact on the network.
In order to effectively learn the network behavior, besides
having a rich view of the network, it is critical to observe as
many different situations as possible. As we discuss in Section
V, this includes different loads, conﬁgurations and services. To
that end, the analytics platform keeps a historical record of the
collected data.
b) Analytics Platform →Machine Learning: The heart of
the KP are the ML and Deep Learning algorithms, able to learn
from the network behavior. The current and historical data
provided by the analytics platform are used to feed learning
algorithms that learn from the network and generate knowledge
(e.g., a model of the network). We consider three approaches:
Supervised learning: The KP learns a model that describes the behavior of the network, i.e. a function that
relates relevant network variables to the operation of
the network. The obtained model reﬂects correlations on
the network behavior that are of interest to the network
operator (e.g., the performance of the network as a
function of the trafﬁc load and network conﬁguration).
Supervised learning requires labeled training data and
some feature engineering (e.g., feature construction and
feature selection) to decide the relevant features prior to
using them in ML algorithms.
Unsupervised learning: It is a data-driven knowledge
discovery approach that can automatically infer a function that describes the structure of the analyzed data.
Unsupervised learning does not require previously labeled samples and can highlight correlations in the data
that the network operator may be unaware of. As an
example, the KP may be able to discover how the local
weather affects the link’s utilization.
Reinforcement learning (RL): In this approach a software
agent aims to discover which actions lead to an optimal
conﬁguration. Formally in RL, the environment is typically modeled as a stochastic ﬁnite state machine where
the agent sends inputs (actions) and receives outputs
(observations and rewards). Then, the goal of the agent
is to ﬁnd the actions that maximize the rewards. As
an example the network administrator can set a target
policy, for instance the delay of a set of ﬂows, then
the agent acts on the SDN controller by changing the
conﬁguration and for each action receives a reward,
which increases as the in-place policy gets closer to the
target policy. Ultimately, the agent will learn the set of
conﬁguration updates that result in such target policy.
Recently, deep reinforcement learning techniques have
provided important breakthroughs in the AI ﬁeld, notable
examples are , .
Please note that learning can also happen ofﬂine and
applied online. In this context knowledge can be learned
ofﬂine training a neural network with datasets of the
behavior of a large set of networks, then the resulting
model can be applied online.
c) Machine Learning →Intent Language: The KP eases
the transition between telemetry data collected by the analytics
platform and control speciﬁc actions. Traditionally, a network
operator had to examine the metrics collected from network
measurements and make a decision on how to act on the
network. In KDN, this process is partially ofﬂoaded to the
KP, which is able to make -or recommend- control decisions
taking advantage of ML techniques. The KP expresses control
KDN APPLICATIONS
Supervised
Unsupervised
Reinforcement
Closed Loop
Automation
Optimization
Improvement
Automation
Optimization
Validation
Estimation
What-if analysis
Recommendation
decisions via an Intent-driven language (see Section III-d),
which eases the transition between the high-level decisions
made by the KP and the imperative language used by data
plane elements.
Depending on whether the network operator is involved or
not in the decision making process, there are two different sets
of applications for the KP. We next describe these potential
applications and summarize them in Table I.
Closed loop: When using supervised or reinforcement
learning, the network model obtained can be used ﬁrst
for automation, since the KP can make decisions automatically on behalf of the network operator. Second,
it can be used for optimization of the existing network
conﬁguration, given that the learned network model can
be explored through common optimization techniques to
ﬁnd (quasi)optimal conﬁgurations. Both applications can
be also achieved using reinforcement learning, please
note that with some techniques this can be achieved
online and model-free. In the case of unsupervised learning, the knowledge discovered can be used to improve
automatically the network via the intent interface offered
by the SDN controller, although this requires additional
research efforts.
Open loop: In this case the network operator is still
in charge of making the decisions, however it can rely
on the KP to ease this task. When using supervised
learning, the model learned by ML can be used for
validation. In this case, the network administrator can
query the model to validate the tentative changes to
the conﬁguration before applying them to the system.
The model can also be used as a tool for performance
estimation and what-if analysis, since the operator can
tune the variables considered in the model and obtain
an assessment of the network performance. When using
unsupervised learning, the correlations found in the
explored data may serve to provide recommendations
that the network operator can take into consideration
when making decisions.
d) Intent Language →SDN controller: Both the network
operators and the automatic systems that make decisions on
their behalf express their intentions towards the network in the
form of a declarative language. This serves to offer a common
interface to both human and automatic decisions makers and
to deﬁne precisely how the abstract intent should be translated
into speciﬁc control directives. In contrast, the communication
between the SDN controller and data plane devices is done
using imperative languages.
Using declarative languages for the SDN northbound interface has been widely discussed in the SDN literature ,
 . Among these declarative languages, the so-called Intent-
driven ones (e.g. NEMO1, GBP2) are gaining traction in the
industry at the time of this writing. Such languages allow
abstract network directives to be rendered into speciﬁc control
In that sense, the SDN controller receives the declarative
primitives through its northbound interface and then renders
the Intent-driven language into speciﬁc imperative control
actions. This is possible since it has a complete and global
view of the network and can actuate on all the network devices
from a centralized point. That way, it can ﬁnd the appropriate
control instructions to apply that reﬂect the expressed intent.
At the time of this writing, there are already controllers (e.g.,
OpenDaylight3) able to render some Intent-based languages
e) SDN controller →Forwarding Elements: The parsed
control actions are pushed to the forwarding devices via
the controller southbound protocols in order to program the
data plane according to the decisions made at the KP. The
controller may as well rely on management protocols (e.g.
NETCONF) to reconﬁgure the data plane devices, if necessary.
The forwarding elements at the data plane operate now based
on the updated operational state and conﬁguration pushed by
the SDN controller.
This section presents a set of speciﬁc uses-cases that illustrate the potential applications of the KDN paradigm and the
beneﬁts a KP based on ML may bring to common networking
problems. For two representative use-cases, we also provide
early experimental results that show the technical feasibility
of the proposed paradigm. All the datasets used in this paper
can be found at .
A. Routing in an Overlay Network
The main objective of this use-case is to show that it is
possible to model the behavior of a network with the use of
ML techniques. In particular, we present a simple proof-ofconcept example in the context of overlay networks, where an
Artiﬁcial Neural Network (ANN) is used to build a model of
the delay of the (hidden) underlay network, which can later be
used to improve routing in the overlay network.
Overlay networks have become a common solution for deployments where one network (overlay) has to be instantiated
on top of another (underlay). This may be the case when a
physically distributed system needs to behave as a whole while
relying on a transit network, for instance a company with geodistributed branches that connects them through the Internet.
Another case is when a network has to send trafﬁc through
another for which it is not interoperable, for example when
trying to send Ethernet frames over an IP-only network.
In such cases, an overlay network can be instantiated by
means of deploying overlay-enabler nodes at the edge of the
transit network and then tunneling overlay trafﬁc using an
1 
2 
3 
Overlay nodes
Overlay network with a hidden underlay
encapsulation protocol (e.g. LISP (RFC 6830), VXLAN (RFC
7348), etc). In many overlay deployments the underlay network
belongs to a different administrative domain and thus its details
(e.g. topology, conﬁguration) are hidden to the overlay network
administrator (see Fig. 3).
Typically, overlay edge nodes are connected to the underlay
network via several links. Even though edge nodes have no
control over the underlay routing, they can distribute the trafﬁc
among the different links they use to connect to it. Edge nodes
can use overlay control plane protocols (e.g. LISP) to
coordinate trafﬁc balancing policies across links. However, a
common problem is how to ﬁnd best/optimum per-link policies
such that the global performance is optimized. An efﬁcient
use of edge nodes links is critical since it is the only way the
overlay operator can control –to a certain extent– the trafﬁc
path over the underlay network.
Overlay operators can rely on building a model of the underlay network to optimize the performance. However, building
such a model poses two main challenges. First, neither the
topology nor the conﬁguration (e.g., routing policy) of the underlay network are known, and thus it is difﬁcult to determine
the path that each ﬂow will follow. Second, mathematical or
theoretical models may fall short to model such a complex
ML techniques allow modeling hidden systems by analyzing
the correlation of inputs and outputs in the system. In other
words, ML techniques can model the hidden underlay network
by means of observing how the output trafﬁc behaves for
a given input trafﬁc (i.e., f(routing policy, trafﬁc) = performance). For instance, if two edge node links share a transit
node within the -hidden- underlay network, ML techniques
can learn that the performance decreases when both of those
links are used at the same time and therefore recommend trafﬁc
balancing policies that avoid using both links simultaneously.
1) Experimental Results: To assess the validity of this
approach we carried out the following simple experiment. We
have simulated a network with 12 overlay nodes, 19 underlay
Samples in the training set
Evolution of the MSE (Mean Squared Error) as a function of the
size of the training set.
elements and a total of 72 links. From the KP perspective, only
the overlay nodes that send and receive trafﬁc are seen, while
the underlay network is hidden. The network is simulated using
Omnet++4 with the following characteristics: overlay nodes
randomly split the trafﬁc independently of the destination node,
the underlay network uses shortest path routing with constant
link capacity, constant propagation delay and Poisson trafﬁc
generation.
We train an ANN using Pylearn2–Theano 0.7. The ANN has
one hidden layer, with a sigmoid activation function, and it is
trained using the following input features: the amount of trafﬁc
among pairs of the overlay nodes and the ratio of trafﬁc that
is sent to each link. The average delays among paths obtained
in the simulation are used as output features. Please note that
the ANN does not have access to any information regarding
the underlay. We train the network with 9,600 training samples
and we use 300 -separate samples– to validate the results.
With this use-case we aim to learn the function that relates
the trafﬁc and the routing conﬁguration of the overlay network
with the resulting average delay of each path. The results
show that the accuracy of the model is reasonably high, with
a relative error of roughly 1% when using 3,000 training
samples. This error is computed as the average relative error
of the delay of all paths in each of the 300 samples of the
test set. Fig. 4 shows the accuracy (Mean Squared Error) as a
function of the size of the training data set. The ﬁgure shows
a typical exponential delay commonly found in ML.
B. Resource Management in an NFV scenario
This use-case shows how the KDN paradigm can also
be useful in the context of Network Function Virtualization
(NFV). NFV is a networking paradigm where network
functions (e.g., ﬁrewalls, load-balancers, etc.) no longer require
speciﬁc hardware appliances but rather are implemented in the
form of Virtual Network Functions (VNFs) that run on top of
general purpose hardware.
4 
The resource management in NFV scenarios is a complex
problem since VNF placement may have an important impact
on the overall system performance. The problem of optimal
Virtual Machine (VM) placement has been widely studied
for Data Center (DC) scenarios (see and the references
therein), where the network topology is mostly static. However, in NFV scenarios the placement of a VNF modiﬁes
the performance of the virtualized network. This increases
the complexity of the optimal placement of VNFs in NFV
deployments.
Contrary to the overlay case, in the VNF placement problem
all the information is available, e.g. virtual network topology,
CPU/memory usage, energy consumption, VNF implementation, trafﬁc characteristics, current conﬁguration, etc. However,
in this case the challenge is not the lack of information
but rather its complexity. The behavior of VNFs depend on
many different factors and thus developing accurate models is
challenging.
The KDN paradigm can address many of the challenges
posed by the NFV resource-allocation problem. For example,
the KP can characterize, via ML techniques, the behavior of
a VNF as a function of the collected analytics, such as the
trafﬁc processed by the VNF or the conﬁguration pushed by
the controller. With this model, the resource requirements of
a VNF can be modeled by the KP without having to modify
the network. This is helpful to optimize the placement of this
VNF and, therefore, to optimize the performance of the overall
1) Experimental results: To validate this use-case we model
the CPU consumption of real-world VNFs when operating
under real trafﬁc. We have chosen two different network
pieces, an Open Virtual Switch (OVS v2.0.25) and Snort
(v2.9.6.06). We have tested OVS with two different set of rules
and controller conﬁgurations: as a SDN-enabled ﬁrewall and
as a SDN-enabled switch. In both cases, we have aimed to
have a representative conﬁguration of real-world deployments.
To measure the CPU consumption of both VNFs we have
deployed them in VMs (Ubuntu 14.04.1 running on top of
VMware ESXi v5.5). The VNFs are virtually connected (using
gigabit links) to two VMs that generate and receive trafﬁc. The
trafﬁc used in this experiment was replayed using tcpreplay
(version 3.4.4) from an on-campus DPI infrastructure. The
campus network serves around 30k users. Details about the
trafﬁc traces can be found in . To represent the trafﬁc, we
extract off-line a set of 86 trafﬁc features in 20 second batches:
number of packets, number of 5-tuple ﬂows, average length,
number of different IPs or ports, application layer information,
among others. In the learning process, we use the Matlab ANN
toolbox with one hidden layer, where the input are all the trafﬁc
features, and the output is the measured CPU consumption. In
this case we aim to learn the function that relates the trafﬁc
features with the CPU consumption.
We train the ANN with 600 samples for the OVS ﬁrewall
model and 900 samples for Snort and the OVS switch. To
assess the validity of the model we use different samples as
5 
6 
Num Packets
CPU consumption
Measured points and the built model using two different features for
two different VNF (only showing the most relevant feature)
Probability
OVS+controller
Cumulative Distribution Function of the relative error in the three
a test set, 150 and 200 samples respectively. To show the
complexity of the model and the need to use ML, we ﬁrst
present the results when only one feature is used for prediction.
Fig. 5 shows that the model is non-linear and requires a multidimensional model. In particular, the ﬁgure plots the predicted
CPU consumption (line) and the measured data (dots) as a
function of the trafﬁc feature used for prediction. The number
of ﬂows is used as predictor for the ﬁrewall, while the number
of packets is used for Snort. Both ﬁgures show that, when
only selecting one feature, the model is not accurate and nonlinear, which motivates the use of ML. Fig. 6 shows a CDF
of the relative error of the full model when trained with all
the features, demonstrating that the model achieves reasonable
C. Knowledge extraction from network logs
Operators typically equip their networks with a logging
infrastructure where network devices report events (e.g., link
going down, packet losses, etc.). Such logs are extensively
used by operators to monitor the health of the network and to
troubleshoot issues. Log analysis is a well-known research ﬁeld
(e.g., see and the references therein) and, in the context
of the KDN paradigm, it can also be used in networking. By
means of unsupervised learning techniques, a KDN architecture can correlate log events and discover new knowledge,
which can be used by the network administrators for network
operation using the open-loop approach, or that can be handled
automatically in a closed-loop solution via the Intent interface
offered by the SDN controller. The following table shows some
speciﬁc examples:
EXAMPLES OF KNOWLEDGE DISCOVERY USING NETWORK
LOGGING AND UNSUPERVISED LEARNING.
Node N is always congested around 8pm and
Services X and Y have an above-average number of clients
Abnormal number of BGP UPDATES messages sent
and Interface 3 is ﬂapping
Fan speeds increase in node N with frequency Y
Optics in interface Y fail
D. Short and long-term network planning
Over time, network deployments typically have to face an
increment in trafﬁc load (e.g., higher throughput) and service
requirements (e.g., less latency, less jitter, etc). Network operators have to deal with such increments and prepare the
network in advance, in a process usually known as network
planning. Network planning includes designing the network
topology, selecting the speciﬁcations of the network hardware
and deciding the trafﬁc policies that distribute the trafﬁc over
the network. The objective of network planning is that in the
long run the network meets the requirements of the network
operator (and its subscribers, if any), that is to plan ahead
to prevent potential bottlenecks, packet losses or performance
drops .
Network planning techniques commonly rely on computer
models managed by experts that estimate the network capacity
and forecast future requirements. Since this process is prone to
errors, network planning typically results in over-provisioning.
A KDN architecture can develop an accurate network model
based on the historical data stored in the analytics platform.
As a simple example, KDN can learn the relation between the
number of clients (or the number of services) and the load and
thus, accurately estimate when a network upgrade is required.
CHALLENGES AND DISCUSSION
The KDN paradigm brings signiﬁcant advantages to networking, but at the same time it also introduces important
challenges that need to be addressed. In what follows we
discuss the most relevant ones.
New ML mechanisms: Although ML techniques provide
ﬂexible tools to computer learning, its evolution is partially
driven by existing ML applications (e.g., Computer Vision, recommendation systems, etc.). In this context the KDN paradigm
represents a new application for ML and as such, requires
either adapting existing ML mechanisms or developing new
ones. A notable example are graphs, in networking, graphs
are used to represent topologies, a fundamental part of the
performance and features of a network. In this context, only
preliminary attempts have been proposed in the literature to
create sound ML algorithms able to model the topology of
systems that can be represented through a graph , .
Although such proposals are not tailored to network topologies,
their core ideas are encouraging for the computer networks
research area. In this sense, the combination of ML techniques
such as Q-learning techniques, convolutional neural networks
and other deep learning techniques may be essential to make
a step further in this area.
Non-deterministic networks: Typically networks operate
with deterministic protocols. In addition, common analytical
models used in networking have an estimation accuracy and
are based on assumptions that are well understood. In contrast,
models produced by techniques do not provide such guarantees
and are difﬁcult to understand by humans. This also means
that manual veriﬁcation is usually impractical when using
models. Nevertheless, ML models work well when the training
set is representative enough. Then, what is a representative
training set in networking? This is an important research
question that needs to be addressed. Basically, we need a deep
understanding of the relationship between the accuracy of the
ML models, the characteristics of the network, and the size
of the training set. This might be challenging in this context
as the KP may not observe all possible network conditions
and conﬁgurations during its normal operation. As a result, in
some use-cases a training phase that tests the network under
various representative conﬁgurations can be required. In this
scenario, it is necessary to analyze the characteristics of such
loads and conﬁgurations in order to address questions such
as: does the normal trafﬁc variability occurring in networks
produce a representative training set? Does ML require testing
the network under a set of conﬁgurations that may render it
New skill set and mindset: Networking started as a
hardware-centric ﬁeld of engineering, where pioneers designed
and built hardware routers and switches. Since then, a new
set of software engineering skills have become increasingly
important. At the time of this writing, network devices already
incorporate sophisticated pieces of software. With the rise of
the SDN paradigm, software development has become even
more important in networking. This has created an important
shift on the required expertise of networking engineers and
researchers. The KDN paradigm further exacerbates this issue,
as it requires a new set of skills: ML techniques and, in general,
knowledge of Artiﬁcial Intelligence tools. This represents an
important change in the mindset of the people working both
in the industry and academia.
Standardized Datasets: In many cases, progress in ML
techniques heavily depends on the availability of standardized
datasets. Such datasets are used to research, develop and
benchmark new AI algorithms. Some researchers argue that
the cultivation of high-quality training datasets is even more
important that new algorithms, since focusing on the dataset
rather than on the algorithm may be a more straightforward
approach. The publication of datasets is already a common
practice in several popular ML application, such as image
recognition . In this paper we advocate that we need similar
initiatives for the computer network AI ﬁeld, were public
training sets from experimental networks are published and
used for research and development. All datasets used in this
paper are public and can be found at .
CONCLUSIONS
In this paper, we introduced the concept of Knowledge-
Deﬁned Networking (KDN) a novel paradigm that combines Software-Deﬁned Networking, Network Analytics and
Machine Learning to ultimately provide automated network
control. We also presented a set of use-cases and preliminary experimental evidence that illustrate the feasibility and
advantages of the proposed paradigm. Finally, we discussed
some important challenges that need to be addressed before
completely achieving the vision shared in this paper. We
advocate that addressing such challenges requires a truly interdisciplinary effort between the research ﬁelds of Artiﬁcial
Intelligence, Network Science and Computer Networks.
ACKNOWLEDGMENT
This work has been partially supported by the Spanish
Ministry of Education under grant FPU2012/01137, by the
Spanish Ministry of Economy and Competitiveness and EU
FEDER under grant TEC2014-59583-C2-2-R, and by the
Catalan Government under grant 2014SGR-1427.