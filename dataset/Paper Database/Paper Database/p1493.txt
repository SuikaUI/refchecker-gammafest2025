Mach Learn 73: 215–220
DOI 10.1007/s10994-008-5087-1
Guest editor’s introduction: special issue on inductive
transfer learning
Daniel L. Silver · Kristin P. Bennett
Received: 1 October 2008 / Accepted: 1 October 2008 / Published online: 21 October 2008
Springer Science+Business Media, LLC 2008
1 Introduction
Inductive transfer or transfer learning refers to the problem of retaining and applying the
knowledge learned in one or more tasks to develop efﬁciently an effective hypothesis for a
new task. While all learning involves generalization across problem instances, transfer learning emphasizes the transfer of knowledge across domains, tasks, and distributions that are
similar but not the same. For example, learning to recognize chairs might help to recognize
tables; or learning to play checkers might improve the learning of chess. While people are
adept at inductive transfer, even across widely disparate domains, we have only begun to develop associated computational learning theory and there are few machine learning systems
that exhibit knowledge transfer.
Inductive transfer invokes some of the most important questions in artiﬁcial intelligence.
Amongst its challenges are questions such as:
• What is the best representation and method for retaining learned background knowledge?
How does one index into such knowledge?
• What is the best representation and method for transferring prior knowledge to a new
• How does the use of prior knowledge affect hypothesis search heuristics?
• What is the nature of similarity or relatedness between tasks for the purposes of learning?
Can it be measured?
• What role does curriculum play in the sequential learning of tasks?
The papers in this special issue consider several of these problems.
D.L. Silver ()
Jodrey School of Computer Science, Acadia University, Wolfville, NS, Canada B4P 2R6
e-mail: 
K.P. Bennett
Department of Mathematical Sciences, Rensselaer Polytechnic Institute, Troy, NY 12180-3590, USA
e-mail: 
Mach Learn 73: 215–220
2 Brief history of inductive transfer
Research in inductive transfer began in the early 1980s with discussions on inductive bias,
generalization and the necessity of heuristics for developing accurate hypotheses from small
numbers of training examples. Mitchell’s work in 1980 deﬁned ﬁve categories of inductive
bias, and amongst these were “analogy with previously learned tasks” and “knowledge of the
task domain” . Utgoff and others followed up this work by pointing out that,
ideally, a learning system should be able to change its inductive bias to tailor its preference
for hypotheses according to the task being learned . The ability to change
inductive bias requires that the learning system have prior knowledge about some aspect of
the task domain. Furthermore, it suggests that the accumulation of prior knowledge at the
inductive bias level is a useful characteristic for any learning system.
From 1986 to 1995 there were a number of important early papers that examined the
efﬁciency of model development and the performance of models as a function of inductive transfer. In 1994, the ML-COLT workshop on “Constructive Induction and Change of
Representation” played an important role by examining the many ways of generating or
modifying model representations automatically . Workshop
attendees emphasized the futility of bias-free learning and the need to investigate systems
that used prior domain knowledge as a source of inductive bias. A good bibliography of
papers from this period can be found at NIPS’05 workshop .
The ﬁrst major meeting on inductive transfer occurred in 1995 at the NIPS workshop on
“Learning to Learn” in Vail, Colorado . The workshop focused
on the need for lifelong machine learning methods that retain and reuse learned knowledge.
The co-organizers of that workshop were Rich Caruana, Danny Silver, Jon Baxter, Tom
Mitchell, Lorien Pratt, and Sebastian Thrun. The fundamental motivation for this meeting
was the acceptance that machine learning systems would beneﬁt from manipulating knowledge learned from related prior experience and that this would enable them to move beyond
task-speciﬁc tabula rasa induction. The 1995 workshop identiﬁed the following as the most
important areas for future research:
• The relationship between computational learning theory and selective inductive bias;
• The tradeoffs between storing or transferring knowledge in representational and functional form;
• Methods of turning concurrent parallel learning into sequential lifelong learning methods;
• Measuring relatedness between learning tasks for the purposed of knowledge transfer;
• Long-term memory methods and cumulative learning; and
• The practical applications of inductive transfer and lifelong learning systems.
The workshop resulted in a series of articles published in special issues of Connection Science and Machine Learning , and a book entitled “Learning to Learn” .
Research in inductive transfer continued after 1995 under a variety of names: bias learning, speedup learning, learning to learn, machine life-long learning, knowledge transfer,
transfer learning, multiple task learning, knowledge consolidation, context-sensitive learning, knowledge-based inductive bias, meta-learning, and incremental, cumulative, and continual learning. The years 2003 through 2005 saw a renewed interest in multi-task learning
using kernel and Bayesian approaches that established new frameworks for inductive transfer and deﬁning task relatedness. For a an extensive list of publications please see NIPS’05
workshop .
Between 1995 and 2005 there were approximately ten workshops or symposia related
to inductive transfer. Most notably there was a series of workshops on meta-learning, that
Mach Learn 73: 215–220
began with the 1995 ECML’95 Workshop on Learning at the Knowledge Level. In addition
there have been workshops on context-sensitive learning, life-long learning, and learning in
a priori unknown or dynamic domains. For a complete history of workshops and symposia
please see NIPS’05 workshop .
In 2005, the second major workshop on inductive transfer was held. This one-day workshop entitled “Inductive Transfer: 10 Years Later” examined the progress that had been made
over the previous ten years, the questions and challenges that remained, and the opportunities for new applications of inductive transfer systems. The workshop was co-organized by
Danny Silver, Rich Caruana, Kristin Bennett, Goekhan Bakir, Massimiliano Pontil, Stuart
Russell, and Prasad Tadepalli.
In particular, the workshop organizers identiﬁed three major goals: (1) To summarize the
work in the area of inductive transfer so as to develop a taxonomy of research indicating open
questions, (2) To share new theories, approaches and algorithms regarding the accumulation
and use of learned knowledge for the purposes of more effective and efﬁcient learning, (3)
To discuss a more formal inductive transfer community (or special interest group) that might
begin by offering a repository website, benchmarking data and testing methods, shared software, and links to various research programs and other resources. The workshop was also
intended to discuss more forward looking questions such as:
• Under what conditions is inductive transfer difﬁcult? When is it easy?
• What are the fundamental requirements for continual learning and transfer?
• What new mathematical models and frameworks capture or demonstrate transfer learning?
• What are the latest and most advanced demonstrations of transfer learning including
Bayesian approaches, kernel methods, and reinforcement learning?
• What can be learned from transfer learning in humans and animals?
• What are the latest psychological, neurological, and computational theories of knowledge
transfer in learning?
Based on 25 original submissions, the workshop featured eight paper presentations, four
invited speakers, two panel discussions and a poster session. For details see NIPS’05 workshop .
3 Overview of this special issue
This issue on inductive transfer developed from the 2005 NIPS workshop. All 2005 workshop authors and invited speakers were invited to submit papers. From the 13 submitted papers ﬁve were selected for this special issue. These ﬁve papers cover a wide range of recent
work in inductive transfer: theory , kernel-SVM
 , hierarchical Bayesian , reinforcement learning
 , and neural networks .
The paper “Flexible latent variable models for multi-task learning” 
by Jian Zhang, Zoubin Ghahramani and Yiming Yang presents a Hierarchial Bayesian probabilistic framework for multi-task learning, where related task parameters share a common
structure through a set of latent variables. By making statistical assumptions, the framework
can be used to support a set of important latent variable models for different multi-task scenarios. The algorithm alternates between unsupervised and supervised steps. Unsupervised
learning at the task domain level determines common representation parameters. This is followed by supervised learning at the task level to determine task-speciﬁc values for these
Mach Learn 73: 215–220
parameters. By learning the related tasks jointly, the approach is able to get a better estimation of the shared components and thus achieve a better generalization capability compared
to conventional approaches where the learning of each task is carried out independently. The
distributional assumption of latent variables can be seen as estimating the density of task parameters and, in this way, provides a statistical explanation of task relatedness. The paper
presents efﬁcient algorithms for the empirical Bayes method as well as point estimation.
Empirical studies on synthetic and real-world classiﬁcation datasets show the effectiveness
of the proposed models in two evaluation settings: a standard multi-task learning setting and
a transfer learning setting.
“Convex multi-task feature learning” by Andreas Argyriou,
Theodoros Evgeniou and Massimiliano Pontil introduces a method for learning sparse representations shared across multiple tasks that can be considered a generalization of single-task
1-norm method of regularization. The method is based on a novel non-convex regularizer
which controls the number of learned features common across the tasks such that it both couples the tasks and enforces sparsity of representation. The method is proven to be equivalent
to solving a convex optimization problem for which there is an iterative algorithm which
converges to an optimal solution, and is therefore the ﬁrst convex optimization formulation
for multi-task feature learning. Similar to the ﬁrst paper, this algorithm alternately performs
a supervised and an unsupervised step, where in the former step it learns task-speciﬁc functions and in the latter step it learns common-across-tasks sparse representations for these
functions. The authors develop a novel and computationally efﬁcient extension of the algorithm that learns sparse non-linear representations using kernels. Experiments on simulated
and real data sets demonstrate that the proposed method leads to shared features common
across related tasks and improved model performance relative to learning each task independently. The algorithm can also be used, as a special case, to select those variables that
are common across the tasks without learning a speciﬁc task.
Shai Ben-David’s and Reba Schuller Borbely’s paper “A notion of task relatedness yielding provable multiple-task learning guarantees” 
makes a signiﬁcant theoretical step forward by formalizing one perspective on the nature
of relatedness between tasks for multiple task learning. Prior theory on inductive transfer
has treated the notion of relatedness using a functional approach that relies
on the assumption that the tasks share a common optimal inductive bias that reduces the
learning method’s search space to a common optimal subset of hypotheses. In contrast,
Ben-David and Borbely’s approach focuses on the sample generating distributions underlying the learning tasks, and deﬁnes task relatedness as an explicit relationship between these
distributions. They provide a formal framework for this notion of task relatedness. Consider
a set F of transformations f : X →X on the input space X. Tasks are considered F-related
if, for some ﬁxed probability distribution over X × {0,1}, the data in each of these tasks
is generated by applying some f ∈F to that distribution. This notion of task relatedness
is relevant to a variety of real-life multi-task learning scenarios; for example, the situation
where many different sensors collect data for the same classiﬁcation problem (intrusion detection). In this case, there will be a set of mathematical transformations F such that the data
distributions collected by of all sensors are F-related. It also allows the formal derivation
of generalization bounds (based on a generalized VC-dimension parameter) that are strictly
stronger than the previously known bounds for multi-task learning scenarios. The authors
give precise conditions under which the bounds guarantee generalization on the basis of
smaller sample sizes.
“Transfer in Variable-Reward Hierarchical Reinforcement Learning” 
by Neville Mehta, Sriraam Natarajan, Prasad Tadepalli, and Alan Fern considers inductive
Mach Learn 73: 215–220
transfer in the context of related Reinforcement Learning (RL) tasks. These RL tasks, derived from Semi-Markov Decision Processes (SMDPs), share the same transition dynamics
but have different reward functions that are linear in a set of reward features. The focus
here is on learning efﬁciency. The authors formally deﬁne the transfer learning problem as
developing an efﬁcient algorithm to solve any SMDP drawn from a ﬁxed distribution after
experiencing prior related SMDP tasks. The paper introduces an online algorithm to solve
this problem called Variable-Reward Reinforcement Learning (VRRL). VRRL compactly
stores prior optimal value functions for SMDPs, and uses them to initialize optimally the
value function for a new SMDP. The method is generalized to a hierarchical RL setting
where the different SMDPs share the same task hierarchy. Empirical studies with VRRL on
a domain of real-time strategy games demonstrates that learning efﬁciency improves through
inductive transfer, especially in hierarchical settings where the overall value functions are
decomposed into subtask value functions that can be used in different SMDPs.
In the ﬁnal paper, Danny Silver, Ryan Poirier and Duane Currie present context-sensitive
multi-task learning, or csMTL, in a paper called “Inductive Transfer with Context-Sensitive
Neural Networks” . csMTL is presented as a method of inductive transfer
which uses a single output back-propagation neural network and additional contextual inputs
for learning multiple tasks. The approach converts the problem of developing hypotheses
for multiple tasks to one of developing a single hypothesis for all tasks that are indexed
(or biased) by the context inputs. With csMTL, all free parameters (connection weights)
in the network are shared as compared to only those below a common feature layer, as
with a standard MTL network. Testing on seven synthetic and real-world domains of tasks
shows that the method can produce hypotheses that are as good as or better than standard
MTL neural networks. The authors argue that the reason for this performance improvement
is a reduction in the number of effective free parameters in the csMTL network brought
about by weight update constraints due to the shared output node and the context inputs.
Experiments using decision trees and support vector machines provides initial evidence that
not all machine learning methods have the ability to use csMTL encoded data to affect
beneﬁcial inductive transfer.
We trust that the mix of articles collected in this special issue will spark further interest
and curiosity in inductive transfer. There is much work to be done in this area in terms of new
computational learning theory and the application of existing algorithms and techniques.
We are very grateful to all authors for their submissions to this special issue and for their
work in improving and polishing their articles. We would also like to thank the referees for
their reviews and helpful comments to authors that have led to improvements in content and
format. Finally, we are particularly grateful to the Editor-in-Chief, Foster Provost, for the
opportunity to compile this special issue and to the editorial staff of Machine Learning for
their kind assistance.