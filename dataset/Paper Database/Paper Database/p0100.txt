Detecting Anomalous Structures
by Convolutional Sparse Models
Diego Carrera, Giacomo Boracchi
Dipartimento di Elettronica,
Informazione e Bioingegeria
Politecnico di Milano, Italy
{giacomo.boracchi, diego.carrera}@polimi.it
Alessandro Foi
Department of Signal Processing
Tampere University of Technology
Tampere, Finland
 
Brendt Wohlberg
Theoretical Division
Los Alamos National Laboratory
Los Alamos, NM, USA
 
Abstract—We address the problem of detecting anomalies in
images, speciﬁcally that of detecting regions characterized by
structures that do not conform those of normal images. In the
proposed approach we exploit convolutional sparse models to
learn a dictionary of ﬁlters from a training set of normal images.
These ﬁlters capture the structure of normal images and are
leveraged to quantitatively assess whether regions of a test image
are normal or anomalous. Each test image is at ﬁrst encoded
with respect to the learned dictionary, yielding sparse coefﬁcient
maps, and then analyzed by computing indicator vectors that
assess the conformance of local image regions with the learned
ﬁlters. Anomalies are then detected by identifying outliers in these
indicators.
Our experiments demonstrate that a convolutional sparse
model provides better anomaly-detection performance than an
equivalent method based on standard patch-based sparsity. Most
importantly, our results highlight that monitoring the local group
sparsity, namely the spread of nonzero coefﬁcients across different
maps, is essential for detecting anomalous regions.
Keywords—Anomaly Detection, Convolutional Sparse Models,
Deconvolutional Networks.
INTRODUCTION
We address the problem of detecting anomalous regions in
images, i.e. regions having a structure that does not conform
to a reference set of normal images . Often, anomalous
structures indicate a change or an evolution of the datagenerating process that has to be promptly detected to react accordingly. Consider, for instance, an industrial scenario where
the production of ﬁbers is monitored by a scanning electron
microscope (SEM). In normal conditions, namely when the
machinery operates properly, images should depict ﬁlaments
and structures similar to those in Figure 1(a). Anomalous
structures, such as those highlighted in Figure 1(b), might
indicate a malfunction or defects in the raw materials used,
and have to be automatically detected to activate suitable
countermeasures.
Detecting anomalies in images is a challenging problem.
First of all because, often, no training data for the anomalous
regions are provided and it is not feasible to forecast all
the possible anomalies that might appear. Second, anomalies
in images might cover arbitrarily shaped regions, which can
be very small. Third, anomalies might affect only the local
structures, while leaving macroscopic features such as the
average pixel-intensity in the region untouched.
Our approach is based on convolutional sparse models,
which in were shown to effectively learn mid-level features
of images. In convolutional sparse representations, the input
image is approximated as the sum of M convolutions between
a small ﬁlter dm and a sparse coefﬁcient map xm, i.e. a spatial
map having few non-zero coefﬁcients. A convolutional sparse
model is a synthesis representation , where the image is
encoded with respect to a dictionary of ﬁlters, yielding sparse
coefﬁcient maps. The decoding consists in adding all the outputs of the convolution between the ﬁlters and corresponding
coefﬁcient maps.
Structures from normal images are modeled by learning a
dictionary of M ﬁlters {dm} from a training set of normal
images. Learned ﬁlters represent the local structure of training
images, as shown in Figure 2(a). Each test image is encoded
with respect to the learned ﬁlters, computing the coefﬁcient
maps that indicate which ﬁlters are activated (i.e. have nonzero
coefﬁcients) in each local region of the image. In normal
regions we expect the convolutional sparse model to describe
the image well, yielding sparse coefﬁcient maps and a good
approximation. This is illustrated in Figure 2(b), where the
green patch in the left half belongs to a normal region and has
only few ﬁlters activated: the corresponding coefﬁcient maps
are sparse. In contrast, in regions characterized by anomalous
structures, we expect coefﬁcient maps to be less sparse or to
less accurately approximate the image. The red patch inside
the right (anomalous) half of Figure 2(b) shows coefﬁcient
maps that are not sparse.
We detect anomalies by analyzing a test image and the corresponding coefﬁcient maps in a patch-wise manner. Patches,
i.e. small regions having a predeﬁned shape, are thus the
core objects of our analysis. For each patch we compute a
low-dimensional indicator vector that quantitatively assesses
the goodness-of-ﬁt of the convolutional model, namely the
extent to which the patch is consistent with normal ones.
Indicators are then used to determine whether a given patch is
normal or anomalous. Given the above considerations, the most
straightforward indicator for a patch would be a vector stacking
the reconstruction error and the sparsity of the coefﬁcient maps
over each patch.
However, in our experiments we show that the sparsity of
the coefﬁcient maps is too loose a criterion for discriminating
anomalous regions, and that it is convenient to consider also
the spread of nonzero coefﬁcients across different maps. In
particular we observed that, while normal regions can be
Fig. 1: Examples of SEM images depicting a nanoﬁbrous material produced by an electrospinning process: Fig. (a) does not
contain anomalies, and is characterized by speciﬁc structures also at local-level. Fig. (b) highlights anomalies that are clearly
visible among the thin ﬁbers.
typically approximated by few ﬁlters, the representation of
anomalous ones often involves many ﬁlters. Therefore, we
include in the indicator vector a term measuring the a local
group-sparsity of the coefﬁcient maps, and show that this is
information is effective at discriminating anomalous regions.
Summarizing, the contribution of the paper is two-fold.
First, we develop a novel approach for detecting anomalies by
means of convolutional sparse models describing the structures
of normal images. Second, we show that the local group sparsity of the coefﬁcient maps is a relevant prior for discriminating
anomalous regions.
The remainder of the paper is organized as follows:
Section II provides an overview of related works, while
Section III formulates the anomaly-detection problem. The
proposed approach is outlined in Section IV while details
about convolutional sparse representations and the indicator
vectors are provided in Sections IV-A and IV-B, respectively.
Experiments are presented and discussed in Section V.
RELATED WORKS
Anomaly detection , refers to the general problem of
detecting unexpected patterns both in supervised scenarios
(where training samples are labeled as normal, or either normal
and anomalous) and in unsupervised scenarios (where training
samples are provided without labels). Anomaly detection is
also referred to as novelty detection , , , in particular
when anomalies are intended as patterns that do not conform to
a training set of normal data. In the machine learning literature,
novelty detection is formulated as a one-class classiﬁcation
problem . In this paper, we shall refer to the patterns
being detected as anomalies, despite the novelty detection
context. An overview of novelty-detection methods for images
is reported in .
Convolutional sparse models were originally introduced
in to build architectures of multiple encoder layers, the
so-called deconvolutional networks. These networks have been
shown to outperform architectures relying on standard patchbased sparsity when learning mid-level features for object
recognition. More sophisticated architectures involving both
decoder and encoder layers showed to be effective in visual
recognition tasks, such as supervised pedestrian detection 
and unsupervised learning of object parts . Deconvolutional
networks are strictly related to the well-known convolutional
networks , which in contrast are analysis representations,
where the image is subject to multiple layers where it is
directly convolved against ﬁlters. Convolutional sparse models
have not previously been used for the anomaly-detection
problem, such as that considered in this work. For simplicity,
we presently develop and describe a single-layer architecture,
although more layers may also be used.
Convolutional sparse models can be seen as extensions
of patch-based sparse models , the former providing a
representation of the entire image while the latter independently represent each image patch. Patch-based sparse models
have been recently used for anomaly detection purposes ,
where an unconstrained optimization problem is solved to
obtain the sparse representation of each patch in a test image.
Then, the reconstruction error and the sparsity of the computed
representation are jointly monitored to detect the anomalous
structures. In anomalies are detected by means of a
speciﬁc sparse-coding procedure, which isolates anomalies as
data that do not admit a sparse representation with respect to
a learned dictionary. Sparse representations have been used
for detecting unusual events in video sequences , by
monitoring the functional minimized during the sparse coding
stage. The detection of structural changes – a problem closely
related to anomaly detection – was addressed in , where
sparse representations were used to sequentially monitor a
stream of signals.
Convolutional sparse models offer two main advantages
compared to patch-based ones: ﬁrst of all, they directly support
the use of multiscale dictionaries , whereas this is not
straightforward for standard patch-based sparse representations. Second, the size of the patch that has to be analyzed
in the anomaly detection can be arbitrarily increased at a
negligible computational overhead when convolutional sparse
models are exploited. In contrast, this requires additional
training and also increases the computational burden in
the case of patch-based sparsity.
Learned Filters
Training Image
Test Image
Feature maps
anomalous patch
Feature maps
normal patch
Fig. 2: (a) Learned dictionary (8 ﬁlters are of size 8 × 8 and 8 are of size 16 × 16) reports the prominent local structures of
the training image. (b) A test image used in our experiments: the left half represents the normal region (ﬁlters were learned
from the other half of the same texture image), while the right half represents the anomalous region. The ideal anomaly detector
should mark all pixels within the right half as anomalous, and all pixels within the left half as normal. The coefﬁcient maps
corresponding to the two highlighted regions (red and green squares) have approximately the same ℓ1 norms. However, the
right-most ﬁgures show that there is a substantially different spread of nonzero elements across coefﬁcient maps. Thus, in this
example the local group sparsity of the coefﬁcient maps is more informative than sparsity for discriminating anomalous regions.
Feature maps have been rescaled for better visualization.
PROBLEM FORMULATION
Let us denote by s : X →R+ a grayscale image, where
X ⊂Z2 is the regular pixel grid representing the image domain
having size N1 × N2. Our goal is to detect those regions in a
test image s where the structures do not conform to those of
a reference training set of normal images T.
To this purpose, we analyze the image locally, and formulate the detection problem in terms of image patches. In
particular, we denote
sc := Πcs = {s(c + u), u ∈U}, ∀c ∈X
the patch centered at a speciﬁc pixel c ∈X, where U is a
neighborhood of the origin deﬁning the patch shape, and Πc
denotes the linear operator extracting the patch centered at
pixel c. We consider U a square neighborhood of
pixels (indicating by P the cardinality of U), even though
patches sc can be deﬁned over arbitrary shapes.
We assume that patches in anomaly-free images are drawn
from a stationary, stochastic process PN and we refer to
these as normal patches. In contrast, anomalous patches are
generated by a different process PA, which yields unusual
structures that do not conform to those generated by PN .
The training set T is used to learn a suitable model
speciﬁcally for approximating normal images. Instead, no
training samples of anomalous images are provided, thus it
is not possible to learn a model approximating anomalous
regions. In this sense, PA remains completely unknown.
Anomalous structures are detected at the patch level: each
patch sc is tested to determine whether it does or does not
conform to the model learned to approximate images generated
by PN . This will result in a map locating anomalous regions
in a test image.
We treat the low and high-frequency components of images
separately; we perform a preprocessing to express s as
s = sl + sh,
where sl and sh denote the low-frequency and high-frequency
components of s, respectively. Typically, sl is ﬁrst computed
by low-pass ﬁltering s and then sh = s −sl.
In particular, we compute the convolutional sparse representation of sh with respect to a dictionary of ﬁlters learned
to describe the high-frequency components of normal images.
Restricting the convolutional sparse representation to the highfrequency components allows the use of few small ﬁlters in
the dictionary. For each patch sc we compute a vector gh(c)
that simultaneously assesses the accuracy and the sparsity of
the convolutional representation around c. The low-frequency
content of s is instead monitored by computing the sample
moments of sl(·) over patches, yielding vectors gl(·). Then,
for each patch, we deﬁne the indicator vector g(c) as the
concatenation of gh(c) and gl(c). Anomalies are detected as
patches yielding outliers in these indicator vectors.
Let us brieﬂy summarize the proposed solution, presenting
the high-level scheme in Algorithms 1 and 2; details about
convolutional sparse representations and indicators are then
provided in Section IV-A and IV-B, respectively.
Training: Anomalies are detected by learning a model
describing normal patches from the training set T. In particular,
we learn a dictionary of ﬁlters {dm} yielding convolutional
sparse representation for high-frequency components of normal
images (Algorithm 1, line 1 and Section IV-A1). The indicator
vectors are then computed from all the normal patches, as
described in Section IV-B, and a suitable conﬁdence region
Rγ that encompasses most of these indicators is deﬁned
(Algorithm 1, lines 2 and 3).
Testing: During operation, each test image s is preprocessed to separate the high frequency content sh from the low
frequency content sl (Algorithm 2, line 1). The convolutional
sparse representation of sh with respect to the dictionary {dm}
is obtained by the sparse coding procedure described in Section IV-A2 (Algorithm 1, line 2). Then, for each pixel c, gh(c)
is computed by analyzing the convolutional representation of
sh in the vicinity of c, and gl(c) is computed by analyzing
sl in the vicinity of c (Algorithm 1, lines 4 and 5). The
indicator vector g(c) is then obtained by stacking gh(c) and
gl(c), namely g(c) = [gh(c), gl(c)]′. Any indicator g(c) that
falls outside a conﬁdence region Rγ estimated from normal
images is considered an outlier and the corresponding patch
anomalous (Section IV-B3, Algorithm 1, line 7).
Input: training set of normal images T:
1. Learn ﬁlters {dm} solving (4)
2. Compute gh(·) (9) and gl(·) (10) for all the normal
patches, deﬁne g as in (11)
3. Deﬁne Rγ in (12) setting the threshold γ > 0
Algorithm 1: Training the anomaly detector using convolutional sparse models.
Input: test image s:
1. Preprocess the image s = sl + sh
2. Compute the coefﬁcient maps {xm} solving (7)
3. foreach pixel c of s do
Compute gh(c) as (9)
Compute gl(c) as (10)
Deﬁne g(c) = [gl(c), gl(c)]′ as (11)
if g(c) /∈Rγ then
c belongs to an anomalous region
c belongs to a normal region
Algorithm 2: Detecting anomalous regions using convolutional sparse models.
A. Convolutional Sparse Representations
Convolutional sparse representations express the highfrequency content of an image s ∈RN1×N2 as the sum of M
convolutions between ﬁlters dm and coefﬁcient maps xm, i.e.
where ∗denotes the two dimensional convolution, and the
coefﬁcient maps xm ∈RN1×N2 have the same size of the
image s. Filters {dm}1 might have different sizes, but are
typically much smaller than the image.
Coefﬁcient maps are assumed to be sparse, namely only
few elements of each xm are nonzero, thus ∥xm∥0 (the number
of nonzero elements) is small. Sparsity regularizes the model
and prevents trivial solutions of (3).
1For notational simplicity we omit m ∈{1, . . . , M} from the collection
of ﬁlters and coefﬁcient maps.
1) Dictionary learning: To detect anomalous regions we
need a collection of ﬁlters {dm} that speciﬁcally approximate
the local structures of normal images. These ﬁlters represent
the dictionary of the convolutional sparse model, and can
be learned from a normal image s provided for training.
Dictionary learning is formulated as the following optimization
dm ∗xm −sh
subject to ∥dm∥2 = 1,
m ∈{1, . . . , M} ,
where {dm} and {xm} denote the collections of M ﬁlters and
coefﬁcient maps, respectively. To simplify the notation, (4)
presents dictionary learning on a single training image s,
however, extending (4) to multiple training images is straightforward .
The ﬁrst term in (4) denotes the reconstruction error, i.e.
the squared ℓ2 norm of the residuals, namely
dm ∗xm −sh
(dm ∗xm)(c) −sh(c)
while the ℓ1 norm of the coefﬁcient maps is deﬁned as
In practice, the penalization term in (4) promotes the sparsity
of the solution , namely the number of nonzero coefﬁcients
in the feature maps. Thus, the ℓ1 norm is often used as
replacement of ℓ0 norm to make (4) computationally tractable.
The constraint ∥dm∥2 = 1 is necessary to resolve the scaling
ambiguity between dm and xm (i.e. xm can be made arbitrarily
small if the corresponding dm is made correspondingly large).
We solve the dictionary learning problem using an efﬁcient
algorithm that operates in Fourier domain. Learned ﬁlters
typically report the prominent local structures of training
images, as shown in Figure 2(a).
We observe that ﬁlters {dm} learned in (4) may have
different sizes , which is a useful feature for dealing with
image structures at different scales. Figure 2(a) provides an
example where 8 ﬁlters of size 8 × 8 and 8 ﬁlters of size
16 × 16 were simultaneously learned from a training image.
2) Sparse Coding: The computation of coefﬁcient maps
{xm} of an input image sh with respect to a dictionary {dm}
is referred to as sparse coding, and consists in solving the
following optimization problem :
dm ∗xm −sh
where ﬁlters {dm} were previously learned from (4).
The sparse coding problem (7) can be solved via the
Alternating Direction Method of Multipliers (ADMM) algorithm , exploiting an efﬁcient formulation in the
Fourier domain. The dictionary-learning problem is typically
solved by alternating the solution of (4) with respect to the
coefﬁcient maps {xm} when ﬁlters are ﬁxed (sparse coding)
and then with respect to the ﬁlters {dm} when coefﬁcient maps
B. Indicators
To determine whether each patch sc is normal or anomalous we compute an indicator vector g(c) that quantitatively
assesses the extent to which sc is consistent and with normal
patches. Indicators g(c) are computed from the decomposition
of s in (2) to assess the extent to which the dictionary {dm}
matches the structures of sh around c (Section IV-B1), as well
as the similarity between low frequency content of Πcsl and
normal patches (Section IV-B2).
1) High-Frequency Components: In anomalous regions ﬁlters are less likely to match the local structures of sh, thus
it is reasonable to expect the sparse coding (7) to be less
successful, and that either the coefﬁcient maps would be less
sparse or that (3) would yield a poorer approximation. This
implies that we should monitor the reconstruction error (5) and
the sparsity of coefﬁcient maps (6), locally, around c. However,
we observed that monitoring the sparsity term (6) is too loose
a criterion for discriminating anomalous regions.
To improve the detection performance, we take into consideration also the distribution of nonzero elements across
different coefﬁcient maps. This choice was motivated by the
empirical observation that often, within normal regions –
where ﬁlters are well matched with image structures – only few
coefﬁcient maps are simultaneously active; in contrast, within
regions where ﬁlters and image structures do not match, more
ﬁlters are typically active. Figure 2(b) compares two coefﬁcient
maps within normal and anomalous regions, and shows that in
the latter case more ﬁlters are active. For this reason, we also
include a term in g(h) to monitor the local group sparsity of
the coefﬁcient maps, namely:
(xm(c + u))2 .
The indicator based on the high frequency components of
the image is deﬁned as
∥Πc (sh −P
m dm ∗xm)∥2
where ﬁrst and second components represent the reconstruction
error of sc and the sparsity of the coefﬁcient maps in the
vicinity of c, respectively: these directly refer to the terms
in (7), thus inherently indicate how successful the sparse
coding was. The third element in (11) represents the group
sparsity, and indicates the spread of nonzero elements across
different coefﬁcient maps in the vicinity of pixel c.
2) Low-Frequency Components: Anomalies affecting the
low frequency components of s are in principle easy to detect
as these affect, for instance, the average value of each patch.
We analyze the ﬁrst two sample moments over patches Πcsl,
extracted from sl. More precisely, for each pixel c of sl we
where µc = P
u∈U sl(u + c)/P denotes the sample mean and
u∈U(sl(u + c) −µc)2/(P −1) the sample variance
computed over the patch of sl centered in c.
Both gh and gl can be stacked in a single vector to be
jointly analyzed when testing patches, namely
This is the indicator we use to determine whether a patch
is anomalous or not, analyzing both the high and the low
frequency content in the vicinity of pixel c.
3) Detecting Anomalous Patches: We treat indicators as
random vectors and detect as anomalous all the patches yielding indicators that can be considered outliers. Therefore, we
build a conﬁdence region Rγ around the mean vector for
normal patches, namely:
(φ −g)T Σ−1(φ −g) ≤γ
where g and Σ denote the sample mean and sample covariance
matrix of indicators extracted from normal images in T, and
γ > 0 is a suitably chosen threshold. Rγ represents an highdensity regions for indicators extracted from normal patches,
since the multivariate Chebyshev’s inequality ensures that, for
a normal patch sc, holds
Pr({g(sc) /∈Rγ}) ≤2
where Pr({g(sc) /∈Rγ}) denotes the probability for a normal
patch sc to lie outside the conﬁdence region (false-positive detection). Therefore, outliers can be simply detected as vectors
falling outside a conﬁdence region Rγ, i.e.
(g(c) −µ)T Σ−1(g(c) −µ) > γ,
and any patch sc yielding an indicator g(c) satisfying (14) is
considered anomalous.
EXPERIMENTS
We design two experiments to assess the anomaly-detection
performance of convolutional sparse representations and, in
particular, the advantages of monitoring the local group sparsity of the coefﬁcient maps. In the ﬁrst experiment we detect
anomalies by monitoring both the low and high frequency
components of an input image, while in the second experiment
we exclusively analyze the high-frequency components. The
latter experiment is to assess the performance of detectors
based exclusively on sparse models.
Considered Algorithms: We compare the following four
algorithms built on the framework of Algorithm 1 and 2:
Convolutional Group: a convolutional sparse model
is used to approximate sh. Anomalies are detected by
analyzing the indicator g in (11) which includes also
the local group sparsity of the coefﬁcient maps (8).
The indicator has ﬁve dimensions.
Convolutional: the same dictionary of ﬁlters for the
Convolutional Group solution is used to approximate
sh, however, the local group sparsity term of the
coefﬁcient maps (8) is not considered in g. Thus, the
indicator has four dimensions.
Fig. 3: Ten of the textures selected from Brodatz dataset
(textures 20, 27, 36, 54, 66, 83, 87, 103, 109, 111). For
visualization purposes, we show only 240 × 240 regions
cropped from the original images, which have size 640 × 640.
Patch-based: a standard sparse model rather
than a convolutional sparse model is used to describe
patches extracted from sh, as in . The indicator
includes the reconstruction error and the sparsity of
the representation. To enable a fair comparison against
convolutional sparse models, the indicator includes the
sample mean over each patch from sh and sl, as well
as the sample variance over each patch from sl. The
indicator has ﬁve dimensions.
Sample Moments: no model is used to approximate
the image and we compute the sample mean and
variance over patches from sl and sh. The indicator
has four dimensions.
In the second experiment, where only the high-frequency
content of images is processed, the same algorithms are
used. In particular, the Convolutional Group computes threedimensional indicator (gh), the Convolutional computes a twodimensional indicator (only the ﬁrst two components of gh are
used), the Patch-based operates only on sh computing a threedimensional indicator and the Sample Moments also operates
on sh computing a two-dimensional indicator.
We learned dictionaries of 16 ﬁlters (8 ﬁlters of size 8 × 8
and 8 of size 16 × 16), solving (4) with λ = 0.1. The same
value λ was used also in the sparse coding (7). The dictionaries
in the patch-based approach are 1.5 times redundant, and
learned by . In all the considered algorithms, indicators
are computed from 15 × 15 patches.
Preprocessing: We perform a low-pass ﬁltering of each
test image s to extract the low frequency components. More
precisely, sl corresponds to the solution of the following
optimization problem
2 ∥sl −s∥2
where ∇sl denotes the image gradient, α > 0 regulates the
amount of high frequency components in sl (in our tests α =
10). The problem (15) can be solved as a linear system and
admits a closed-form solution.
Dataset: To test the considered algorithms we have selected 25 textures from the Brodatz dataset having a
structure that can be properly captured by 15 × 15 ﬁlters and
Fig. 4: Example of anomaly-detection performance for the
Convolutional Group algorithm. Any detection (red pixels) on
the left half represents a false positive, while any detection on
the right half a true positive. The ideal anomaly detector would
here detect all the points in the left half and none on the right
half. Patches across the vertical boundary are not considered
in the anomaly detection to avoid artifacts. As shown in the
highlighted regions, most of false positives in this example are
due to structure that do not conform to the normal image in
Figure 2(a).
patches (10 of the selected textures are shown in Figure 3).
A dataset of test images has been prepared by splitting each
texture image in two halves: the left half was exclusively used
for training, the right half for testing. The right halves of the
25 textures are pair-wise combined, creating 600 test images
by horizontally concatenating two different right halves. An
example of test image is reported in Figure 2(b). We consider
the left half of each test image as normal and the right half
as anomalous, therefore we perform anomaly detection using
the model learned from the texture on the left half. Note that,
since anomalies are detected in a patch-wise manner, having
anomalies covering half test image does not ease the anomaly
detection task with respect to having localized anomalies like
those in Figure 1(a).
Figures of Merit: The anomaly detection performance are
assessed by the following ﬁgures of merit:
FPR, false positive rate, i.e. the percentage of normal
patches detected as anomalous.
TPR, true positive rate, i.e. the percentage of correctly
detected patches.
Figure 4 provides an example of false positives and true
positives over a test image (the left half being normal, the
right half anomalous).
Both FPR and TPR depend on the speciﬁc value of γ used
when deﬁning Rγ. To enable a fair comparison among the
considered algorithms we consider a wide range of values for
γ and plot the receiver operating characteristic (ROC) curve
for each method. In practice, each point of a ROC curve
corresponds to the pair (FPR, TPR) achieved for a speciﬁc
value of γ. When computing FPR and TPR, we exclude
patches overlapping the vertical boundary between different
ROC curves from s = sh + sl
Convolutional Group
Convolutional
Patch-based
Sample Moments
(a) The Area Under the Curve values are: Convolutional Group: 0.9520;
Convolutional: 0.9317; Patch-Based: 0.9422; Sample Moments: 0.9048
ROC curves from sh
Convolutional Group
Convolutional
Patch-based
Sample Moments
(b) The Area Under the Curve values are: Convolutional Group: 0.9198;
Convolutional: 0.8578; Patch-Based: 0.8836; Sample Moments: 0.7706
Fig. 5: ROC curves for the algorithm considered in Section V, obtained by varying the parameter γ in the deﬁnition of the
conﬁdence region Rγ. Figure (a) shows the performance in detecting anomalies when the whole spectrum of the images is
considered, while in Figure (b) are reported the ROC curves obtained by monitoring sh.
Figures 5(a) and 5(b) report the average ROC curves2
when processing the whole image spectrum and high frequency
components only, respectively. The Area Under the Curve
(AUC) is the typical scalar metric to compare the detection
performance: AUC values are indicated in the captions of the
Figures and in Figure 6, which displays the AUC averaged
over all the images having a speciﬁc texture as normal.
Discussions: These experiments indicate that convolutional
sparsity provides an effective model for describing local image
structures and detecting anomalous regions. In both the ROC
curves of Figure 5, the best performance is achieved when
considering the group sparsity of the coefﬁcient maps, suggesting that the spread of nonzero coefﬁcients across different
maps is relevant information for detecting anomalies. This
clearly emerges from Figure 5(a), where the Convolutional
Group algorithm substantially outperforms the others, and from
Figure 5(b) which shows an increased performance gap when
anomalies can be only perceived from the high-frequency
components.
CONCLUSIONS
We have presented a novel approach for detecting anomalous structures in images by learning a convolutional sparse
model that describes the local structures of normal images.
Convolutional sparse models are shown to be effective at detecting anomalies in the high frequency components of images,
and this is essential in applications where the anomalies are
2The curves were averaged over the whole dataset setting the same FPR
not very apparent from the low-frequencies of the image, or
where anomalies affecting the low frequency content have not
to be detected.
Our experiments also show that the local group sparsity
of the coefﬁcient maps is an essential information for assessing whether regions in a test image conform or not the
learned convolutional sparse model. In our ongoing work we
will investigate whether the local group sparsity represents a
general regularization prior for convolutional sparse models,
and design a speciﬁc sparse-coding algorithm that leverages a
penalization term to promote this form of regularity.