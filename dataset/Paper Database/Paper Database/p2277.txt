Bayesian Analysis 
1, Number 3, pp. 403–420
Subjective Bayesian Analysis: Principles and
Michael Goldstein∗
We address the position of subjectivism within Bayesian statistics.
We argue, ﬁrst, that the subjectivist Bayes approach is the only feasible method
for tackling many important practical problems. Second, we describe the essential
role of the subjectivist approach in scientiﬁc analysis. Third, we consider possible
modiﬁcations to the Bayesian approach from a subjectivist viewpoint. Finally, we
address the issue of pragmatism in implementing the subjectivist approach.
Keywords: coherency, exchangeability, physical model analysis, high reliability
testing, objective Bayes, temporal sure preference
Introduction
The subjective Bayesian approach is based on a very simple collection of ideas. You
are uncertain about many things in the world. You can quantify your uncertainties as
probabilities, for the quantities you are interested in, and conditional probabilities for
observations you might make given the things you are interested in. When data arrives,
Bayes theorem tells you how to move from your prior probabilities to new conditional
probabilities for the quantities of interest.
If you need to make decisions, then you
may also specify a utility function, given which your preferred decision is that which
maximises expected utility with respect to your conditional probability distribution.
There are many compelling accounts explaining how and why this view should form
the basis for statistical methodology; see, for example, Lindley and the accompanying discussion. Careful treatments of the Bayesian approach are given in, for example,
Bernardo and Smith , O’Hagan and Forster and Robert . In particular, Lad provides an excellent introduction to the subjectivist viewpoint, with
a wide ranging collection of references to the development of this position.
Moving from principles to practice can prove very challenging and so there are many
ﬂavours of Bayesianism reﬂecting the technical challenges and requirements of diﬀerent
ﬁelds. In particular, a form of Bayesian statistics, termed “objective Bayes” aims to
gain the formal advantages arising from the structural clarity of the Bayesian approach
without paying the “price” of introducing subjectivity into statistical analysis. Such
attempts raise important questions as to the role of subjectivism in Bayesian statistics.
This account is my subjective take on the issue of subjectivism.
My treatment is split into four parts. First, the subjectivist Bayes approach is the
only feasible method for tackling many important practical problems, and in Section
∗Department
Mathematical
University
 
c⃝2006 International Society for Bayesian Analysis
Subjective Bayesian Analysis
2 I’ll give examples to illustrate this. Next, in Section 3, I’ll look at scientiﬁc analyses, where the role of subjectivity is more controversial, and argue the necessity of the
subjective formulation in this context. In Section 4, I’ll consider how well the Bayes
approach stands up to scrutiny from the subjective viewpoint itself. In Section 5, I’ll discuss the issue of pragmatism in implementing the subjectivist approach. In conclusion,
I’ll comment on general implications for developing the full potential of the subjectivist
approach to Bayesian analysis.
Applied subjectivism
Among the most important growth areas for Bayesian methodology are those applications that are so complicated that there is no obvious way even to formulate a more
traditional analysis. Such applications are widespread; for many examples, consult the
series of Bayesian case studies volumes from the Carnegie Mellon conference series.
Here are just a couple of areas that I have been personally involved in, with colleagues
at Durham, chosen so that I can discuss, from the inside, the central role played by
subjectivity.
High reliability testing for complex systems
Suppose that we want to test some very complicated system - a large software system
would be a good example of this. Software testing is a crucial component of the software
creation cycle, employing large numbers of people and consuming much of the software
budget. However, while there is a great deal of practical expertise in the software testing
community, there is little rigorous guidance for the basic questions of software testing,
namely how much testing a system needs, and how to design an eﬃcient test suite for
this purpose.
Though the number of tests that we could, in principle, carry out is
enormous, each test has non-trivial costs, both in time and money, and we must plan
testing (and retesting given each fault we uncover) to a tight time/money budget. How
can we design and analyse an optimal test suite for the system?
This is an obvious example of a Bayesian application waiting to happen. There is
enormous uncertainty and we are forced to extrapolate beliefs about the results of all
the tests that we have not carried out from the outcomes of the relatively small number
of tests that we do carry out. There is a considerable amount of prior knowledge carried
by the testers who are familiar with the ways in which this software is likely to fail, both
from general considerations and from testing and ﬁeld reports for earlier generations of
the software. The expertise of the testers therefore lies in the informed nature of the
prior beliefs that they hold. However, this expertise does not extend to an ability to
analyse, without any formal support tools, the conditional eﬀect of test observations
on their prior beliefs, still less to an ability to design a test system to extract optimum
information from this extremely complex and interconnected probabilistic system.
A Bayesian approach proceeds as follows. First, we construct a Bayesian belief net.
In this net, the ancestor nodes represent the various general reasons that the testers
Michael Goldstein
may attribute to software failure, for example incorrectly stripping leading zeroes from
a number. The links between ancestor nodes show relationships between these types of
failure. The child nodes are the various test types, where the structuring ensures that all
tests represented by a given test node are regarded exchangeably by the testers. Second,
we quantify beliefs as to the likely levels of failure of each type and the conditional eﬀects
of each failure type on each category of test outcome. Finally, we may choose a test
suite to optimise any prespeciﬁed criterion, either based on the probability of any faults
remaining in the system or on the utility of allowing certain types of failure to pass
undetected at software release. This optimality calculation is tractable even for large
systems. This is because what concerns us, for any test suite, is the probability of faults
remaining given that all the chosen tests are successful, provided any faults that are
detected will be ﬁxed before release.
In principle, this methodology, by combining Bayesian belief networks with optimal
experimental design, is massively more eﬃcient and ﬂexible than current approaches.
Is the approach practical? From our experiences working with an industrial partner, I
would say deﬁnitely yes. A general overview of the approach that we developed is given
in Wooﬀet al. . As an indication of the potential increase in eﬃciency, we found,
in one case study, that Bayesian automatic design provided eight tests which together
were more eﬃcient than 233 tests designed by the original testing team, and identiﬁed
additional tests that were appropriate for checking areas of functionality that had not
been covered by the original test suite. This is not a criticism of the testers, who were
very experienced, but simply illustrates that optimal multi-factor probabilistic design
is very diﬃcult. The value of the subjectivist approach lies in translating the complicated but informal generalised uncertainty judgements of the experts into a language
which allows for precise and rigorous analysis. In system testing, the careful use of this
language oﬀers enormous potential for clarity and eﬃciency gains.
Of course, there are many issues that must be sorted out before such beneﬁts can
be realised, from the construction of user-friendly interfaces for building the models
to (a much larger obstacle!)
the culture change required to recognise and routinely
exploit such methods. However, the subjective Bayes approach does provide a complete
framework for quantifying and managing the uncertainties of high-reliability testing. It
is hard to imagine any other approach which could do so.
Complex physical systems
Many large physical systems are studied through a combination of mathematical modelling, computer simulation and matching against past physical data, which can, hopefully, be used to extrapolate future system behaviour; for example, this accounts for
much of what we claim to know about the nature and pace of global climate change.
Such analysis is riddled with uncertainty. In climate modelling, each computer simulation can take between days and months, and requires many input parameters to be
set, whose values are unknown. Therefore, we may view computer simulations with
varied choices of input parameters as a small sample of evaluations from a very high
dimensional unknown function. The only way to learn about the input parameters is
Subjective Bayesian Analysis
by matching simulator output to historical data, which is, itself, observed with error.
Finally, and often most important, the computer simulator is just a model, and we need
to consider the ways in which the model and reality may diﬀer.
Again, the subjectivist Bayesian approach oﬀers a framework for specifying and
synthesising all of the uncertainties in the problem. There is a wide literature on the
probabilistic treatment of computer models; a good starting point with a wide collection of references is the recent volume Santner et al. . Our experience at Durham
started with work on oil reservoir simulators, which are constructed to help with all the
problems involved in eﬃcient management of reservoirs. Typically, these are very high
dimensional computer models which are very slow to evaluate. The approach that we
employed for reservoir uncertainty analysis was based on representing the reservoir simulator by an emulator. This is a probabilistic description of our beliefs about the value
of the simulator at each input value. This is combined with statements of uncertainty
about the input values, about the discrepancy between the model and the reservoir and
about the measurement uncertainty associated with the historical data. This completely
speciﬁed stochastic system provides a formal framework allowing us to synthesise expert
elicitation, historical data and a careful choice of simulator runs. While there are many
challenging technical issues arising from the size and complexity of the system, this speciﬁcation does allow us to identify “correct” settings for simulator inputs (often termed
history matching in the oil industry), see Craig et al. , and to assess uncertainty
for forecasts of future behaviour of the physical system, see Craig et al. . Our
approach relies on a Bayes linear foundation (which I’ll discuss in Section 4) to handle
the technical diﬃculties involved with the high dimensional analysis; for a full Bayes
approach for related problems, see Kennedy and O’Hagan .
Our approach has been implemented in software employed by users in the oil industry, through our collaborators ESL (Energy SciTech Limited). This means that we get
to keep track, just a little, of how the approach works in practice. Here’s an example
of the type of success which ESL has reported to us. They were asked to match an
oil ﬁeld containing 650 wells, based on one million plus grid cells (for each of which
permeability, porosity, fault lines, etc. are unknown inputs). Finding the previous best
history match had taken one man-year of eﬀort. Our Bayesian approach, starting from
scratch, found a match using 32 runs (each lasting 4 hours and automatically chosen
by the software), with a fourfold improvement according to the oil company measure
of match quality. This kind of performance is impressive, although, of course, these
remain very hard problems and much must still be done to make the approach more
ﬂexible, tractable and reliable.
Applications such as these make it clear that careful representation of subjective
beliefs can give much improved performance in tasks that people are already trying
to do. There is an enormous territory where subjective Bayes methods are the only
feasible way forward. This is not to discount the large amount of work that must often
be done to bring an application into Bayes form, but simply to observe that for such
applications there are no real alternatives. In such cases, the beneﬁts from the Bayesian
formulation are potentially very great and clearly demonstrable. The only remaining
issue, therefore, is whether such beneﬁts outweigh the eﬀorts required to achieve them.
Michael Goldstein
This “pain to gain” ratio is crucial to the success of subjective Bayes applications. When
the answer really matters, such as for global climate change, the pain threshold would
have to be very high indeed to dissuade us from the analysis.
By explicitly introducing our uncertainty about the ways in which our models fall
short of reality, the subjective Bayes analysis also does something new and important.
Only technical experts are concerned with how climate models behave, while everybody
has an interest in how global climate will actually change. For example, the Guardian
newspaper leader on Burying Carbon tell us that “the chances of the
Gulf Stream - the Atlantic thermohaline circulation that keeps Britain warm - shutting
down are now thought to be greater than 50% .” This sounds like something we should
know. However, I am reasonably conﬁdent that no climate scientist has actually carried
an uncertainty analysis which would be suﬃcient to provide a logical bedrock for such
a statement. We can only use the analysis of a global climate model to guide rational
policy towards climate change if we can construct a statement of uncertainty about the
relation between analysis from the climate model and the behaviour of the real climate.
To further complicate the assessment, there are many models for climate change in
current use, all of whose analyses should be synthesised as the basis of any judgements
about actual climate change. Specifying beliefs about the discrepancy between models
and reality is unfamiliar and diﬃcult. However, we cannot avoid this task if we want
our statements to carry weight in the real world. A general framework for making such
speciﬁcations is described in Goldstein and Rougier .
Scientiﬁc subjectivism
The role of subjectivism in scientiﬁc enquiry
In the kind of applications we’ve discussed so far, the only serious issues about the role
of subjectivity are pragmatic ones. Each aspect of the speciﬁcation, whether part of
the “likelihood function” or the “prior distribution,” encodes a collection of subjective
judgements.
The value of the Bayesian approach lies ﬁrst in providing a language
within which we can express all these judgements and second in providing a calculus
for analysing these judgements.
Controversy over the role of subjectivity tends to occur in those areas of scientiﬁc
experimentation where we do appear to have a greater choice of statistical approaches.
Laying aside the obvious consideration that any choice of analysis is the result of a host
of subjective choices, there are, essentially, two types of objections to the explicit use of
subjective judgements; those of principle, namely that subjective judgements have no
place in scientiﬁc analyses; and those of practice, namely that the pain to gain ratio is
just too high.
These are deep issues which have received much attention; a good starting place for
discussion of the role of Bayesian analysis in traditional science is Howson and Urbach
 . Much of the argument can be captured in simple examples. Here’s one such,
versions of which are often used to introduce the Bayesian idea to people who already
Subjective Bayesian Analysis
have some familiarity with traditional statistical analysis.
First, we can imagine carrying out Fisher’s famous tea-tasting experiment. Here
an individual, Joan say, claims to be able to tell whether the milk or the tea has been
added ﬁrst in a cup of tea. We perform the experiment of preparing ten cups of tea,
choosing each time on a coin ﬂip whether to add the milk or tea ﬁrst. Joan then tastes
each cup and gives an opinion as to which ingredient was added ﬁrst. We count the
number, X, of correct assessments. Suppose, for example, that X = 9.
Now compare the tea-tasting experiment to an experiment where an individual,
Harry say, claims to have ESP as demonstrated by being able to forecast the outcome
of fair coin ﬂips. We test Harry by getting forecasts for ten ﬂips. Let X be the number
of correct forecasts. Suppose that, again, X = 9.
Within the traditional view of statistics, we might accept the same formalism for
the two experiments, namely that, for each experiment, each assessment is independent
with probability p of success. In each case, X has a binomial distribution parameters 10
and p, where p = 1/2 corresponds to pure guessing. Within the traditional approach,
the likelihood is the same, the point null is the same if we carry out a test for whether
p = 1/2, and conﬁdence intervals for p will be the same.
However, even without carrying out formal calculations, I would be fairly convinced
of Joan’s tea tasting powers while remaining unconvinced that Harry has ESP. You
might decide diﬀerently, but that is because you might make diﬀerent prior judgements.
This is what the Bayesian approach adds. First, we require our prior probability, g
say, that Harry or Joan is guessing. Then, if not guessing, we need to specify a prior
distribution q over possible values of p. Given g, q, we can use Bayes theorem to update
our probability that Harry or Joan is just guessing and, if not guessing, we can update
our prior distribution over p. We may further clarify the Bayesian account by giving
a more careful description of our uncertainty within each experiment based on our
judgements of exchangeability for the individual outcomes. This allows us to replace
our judgements about the abstract model parameter p with judgements about observable
experimental outcomes as the basis for the analysis.
Therefore, the Bayes approach shows us exactly how and where to input our prior
judgements.
We have moved away from a traditional view of a statistical analysis,
which attempts to express what we may learn about some aspect of reality by analysing
an individual data set. Instead, the Bayesian analysis expresses our current state of
belief based on combining information from the data in question with whatever other
knowledge we consider relevant.
The ESP experiment is particularly revealing for this discussion. I used to use it
routinely for teaching purposes, considering that it was suﬃciently unlikely that Harry
would actually possess ESP that the comparison with the tea-tasting experiment would
be self-evident. I eventually came to realise that some of my students considered it
perfectly reasonable that Harry might possess such powers. While writing this article,
I tried googling “belief in ESP” over the net, which makes for some intriguing reading.
Here’s a particularly relevant discussion from an article in the September 2002 issue of
Michael Goldstein
Scientiﬁc American, by Michael Sherme, titled “Smart People Believe Weird Things”.
After noting that, for example, around 60% of college graduates appear to believe in
ESP, Sherme reports the results of a study that found “no correlation between science
knowledge (facts about the world) and paranormal beliefs.” The authors, W. Richard
Walker, Steven J. Hoekstra and Rodney J. Vogl, concluded: “Students that scored well
on these [science knowledge] tests were no more or less sceptical of pseudo-scientiﬁc
claims than students that scored very poorly. Apparently, the students were not able to
apply their scientiﬁc knowledge to evaluate these pseudo-scientiﬁc claims. We suggest
that this inability stems in part from the way that science is traditionally presented to
students: Students are taught what to think but not how to think.” Sherme continues as
follows: “To attenuate these paranormal belief statistics, we need to teach that science
is not a database of unconnected factoids but a set of methods designed to describe and
interpret phenomena, past or present, aimed at building a testable body of knowledge
open to rejection or conﬁrmation.”
The subjective Bayesian approach may be viewed as a formal method for connecting
experimental factoids. Rather than treating each data set as though it has no wider
context, and carrying out each statistical analysis just as though this were the ﬁrst
investigation that had ever been carried out of any relevance to the questions at issue,
we consider instead how the data in question adds to, or changes, our beliefs about
these questions.
If we think about the ESP experiment in this way, then we should expand the problem description to reﬂect this requirement. Here is a minimum that I should consider.
First, I would need to assess my probability for E, the event that ESP is a real phenomenon that at least some people possess. This is the event that joins my analysis
of Harry’s performance with my generalised knowledge of the scientiﬁc phenomenon at
issue. Conditional on E, I should evaluate my probability for J, the event that Harry
possesses ESP. Conditional on J and on J complement, I should evaluate my probabilities for G, the event that Harry is just guessing and C, the event that either the
experiment is ﬂawed or Harry is, somehow, cheating; for example, the coin might be
heads biased and Harry mostly calls heads. This is the event that captures my generalised knowledge of the reliability of experimental procedures in this area. If there
is either cheating or ESP, I need a probability distribution over the magnitude of the
What do we achieve by this formalism?
First, this gives me a way of assessing
my actual posterior probability for whether Harry has ESP. Second, if I can lay out
the considerations that I use in a transparent way, it is easy for you to see how your
conclusions might diﬀer from mine. If we disagree as to whether Harry has ESP, then we
can trace this disagreement back to diﬀering probabilities for the general phenomenon,
in this case ESP, or diﬀerent judgements about particulars of the experiment, such as
Harry’s possible ability at sleight of hand. More generally, by considering the range of
prior judgements that might reasonably be made, I can distinguish between the extent
to which the experiment might convince me as to Harry’s ESP, and the eﬀect it might
have on others. I could even determine how large and how stringently controlled an
experiment would need to be in order to have a chance of convincing me of Harry’s
Subjective Bayesian Analysis
powers. More generally, how large would the experiment need to be to convince the
wider community?
The above example provides a simple version of a general template for any scientiﬁc
Bayesian analysis. There are scientiﬁc questions at issue. Beliefs about these issues
require prior speciﬁcation. Then we must consider the relevance of the scientiﬁc formulation to the current experiment along with all the possible ﬂaws in the experiment
which would invalidate the analysis. Finally, a likelihood must be speciﬁed, expressing
data variability given the hypotheses of interest.
There are two versions of the subsequent analysis. First, you may only want to know
how to revise your own beliefs given the data. Such private analyses are quite common.
Many scientists carry out at least a rough Bayes assessment of their results, even if they
never make such analysis public.
Second, you may wish to publish your results, to contribute to, or even to settle,
a scientiﬁc issue. It may be that you can construct a prior speciﬁcation that is very
widely supported. Alternately, it may be that, as with the ESP experiment, no such
generally agreed prior speciﬁcation may be made. Indeed, the disagreement between
experts may be precisely what the experiment is attempting to resolve. Therefore, our
Bayesian analysis of an experiment should begin with a probabilistic description whose
qualitative form can be agreed on by everyone. This means that all features, in the
prior and the likelihood, that cause substantial disagreement should have explicit form
in the representation, so that diﬀering judgements can be expressed over them. There
is a rich literature on elicitation, dealing with how generalised expert knowledge may
be converted into probabilistic form; for a recent overview, see Garthwaite et al. .
As with each other aspect of the scientiﬁc argument, such elicitation has two aims;
ﬁrst, to obtain sensible prior values and second, to make clear the scientiﬁc basis for
assigning these values. Statistical aspects of the representation may employ standard
data sharing methodologies such as meta-analysis, multi-level modelling and empirical
Bayes, provided all the relevant judgements are well sourced. We can then produce
the range of posterior judgements, given the data, which correspond to the range of
“reasonable” prior judgements held within the scientiﬁc community. We may argue that
a scientiﬁc case is “proven” if the evidence should be convincing given any reasonable
assignment of prior beliefs. Otherwise, we can assess the extent to which the community
might still diﬀer given the evidence. We should make this analysis at the planning stage
in order to design experiments that can be decisive for the scientiﬁc community or to
conclude that no such experiments are feasible.
All of this is clear in principle, though implementation of the program may be
diﬃcult in individual cases. Each uncertainty statement is a well sourced statement
of belief by an individual. If individual judgements diﬀer and if this is relevant, then
such diﬀerences are reﬂected in the analysis. In practice, it is unusual to ﬁnd such a
subjectivist approach within scientiﬁc analysis. Let us therefore consider objections and
alternatives to the subjective Bayesian approach.
Michael Goldstein
Objections and alternatives to scientiﬁc subjectivism
The principled objection to Bayesian subjectivism is that the subjective Bayesian approach answers problems wrongly, because of unnecessary and unhelpful appeals to
arbitrary prior assumptions, which should have no place in scientiﬁc analyses. Individual subjective reasoning is inappropriate for reaching objective scientiﬁc conclusions,
which form the basis of consensus within the scientiﬁc community.
This objection would have more force if there was a logically acceptable alternative. I
do not here want to dwell on the diﬃculties in interpretation of the core concepts of more
traditional inference, such as signiﬁcance and coverage properties: a valid conﬁdence
interval may be empty, for example when constructed by the intersection of a series of
repeated conﬁdence intervals; a statistically signiﬁcant result obtained with high power
may be almost certainly false, and so forth. Further, I do not know of any way to
construct even the basic building blocks of the inference, such as the relative frequency
probabilities that we must use if we reject the subjective interpretation, that will stand
up to proper logical scrutiny. Instead, let us address the principled objection directly.
We cannot consider whether the Bayes approach is appropriate without ﬁrst clarifying
the objectives of the analysis. When we discussed the analysis of physical models, we
made the fundamental distinction between analysis of the model and analysis of the
physical system.
Analysing various models may give us insights but at some point
these insights must be integrated into statements of uncertainty about the system itself.
Analysing experimental data is essentially the same. We must be clear as to whether
we are analysing the experiment or the problem.
In the ESP experiment, the question is whether Harry has ESP, or, possibly, whether
ESP exists at all. If we analyse the experimental data as part of a wider eﬀort to address
our uncertainty about these questions, then external judgements are clearly relevant.
As described above, the beliefs that are analysed may be those of an individual, if that
individual can make a compelling argument for the rationality of a particular belief speciﬁcation, or instead we may analyse the collection of beliefs held by informed individuals
in the community. The Bayes analysis is appropriate for this task, as it is concerned
to evaluate the relevant kinds of uncertainty judgements, namely the uncertainties over
the quantities that we want to learn about, given the quantities that we observe, based
on careful foundational arguments using ideas such as coherence and exchangeability to
show why this is the unavoidable way to analyse our actual uncertainties.
On the other hand, suppose that, for now, we only want to analyse the data from
this individual experiment. Our goal, therefore, cannot be to consider directly the basic
question about the existence of ESP. Indeed, it is hard to say exactly what our goal
is, which is why there often is so much confusion in discussions between proponents of
diﬀerent approaches. All that we can say informally is that the purpose of such analysis
is to provide information which will be helpful at some future time for whoever does
attempt to address the real questions of interest. We are now in the same position as the
modeller; we have great freedom in carrying out our analyses but we must be modest
in the claims that we make for them.
Subjective Bayesian Analysis
This is the world in which we ﬁnd objective Bayes methodology. What does the
word “objective” mean in this context? It does not mean that there is an objective
status for the statements made by the methodology, as the approach doesn’t oﬀer any
other testable meaning for probability statements beyond the uncertainty judgements
of the individual. Nor does it mean that there is some objectively testable property that
the answers derived by the analysis will necessarily satisfy. Thus, we have no way to
judge in what sense, and to what degree, we should have conﬁdence in the conclusions
of an objective Bayes analysis. It does not even mean that there is some objectively
testable principle that has been used to assemble the ingredients of the analysis.
Instead, as with many other uses of the term, objective here usually means that
we are not attempting to address the question at issue (should we think that Harry
has ESP?) but instead we are constructing a model for the inference by introducing
and attempting to answer some surrogate question which is less challenging. I’m not
sure what the question would be here - perhaps we imagine somebody who has just
arrived on this planet and we wonder what our stranger would conclude if immediately
confronted by Harry’s performance. Of course, if we formulate this surrogate question
too precisely then we will not be able to answer it; after all, we have no idea what such a
stranger would actually conclude. This ambiguity can sometimes be benign. If we have
a very large experiment, then a simple automatic choice of prior, along with some large
sample approximation argument to show that the conclusion is not overly sensitive to
the choice of prior, may save a lot of time and eﬀort as compared to a full subjectivist
analysis while reaching substantially the same conclusion. However, the value of such
an analysis still lies in the robust approximation to the full subjectivist analysis.
When analysis of the current experiment is sensitive to the prior speciﬁcation, as
in our ESP experiment, it is clear that there is no objective answer to the question of
Harry’s powers, based on analysis of the given data. To pretend otherwise is to enter
the world of pseudo-science to which we alluded above, in which we behave just as those
science students who appear unable to make the links between reason, experience and
observation. Subjective Bayesian analysis is hard but necessary precisely because it
does concern such a fully rounded assessment.
There are two dangers as we move away from the subjective Bayes analysis. First,
we may calculate results in which we have no conﬁdence. Second, we may be unsure
what our analysis even claims to represent. And if statisticians risk confusion as to the
meaning of their analyses, how much greater is the danger for those non statisticians who
rely on the output of statistical analyses? As a current and tragic example, the General
Medical Council for the UK has just ruled that Professor Sir Roy Meadow should be
struck oﬀthe medical register due to serious professional misconduct for giving evidence
beyond his expertise at a trial which led to a mother being wrongfully jailed for the
murder of her two baby sons. Much of the evidence of misconduct is based around Prof
Meadow’s statement at the trial that there was just a “one in 73 million” chance that
two babies with the given background could each suﬀer cot death. (This ﬁgure was
apparently obtained by squaring the circa 8,500 to one chance of a single baby dying of
cot death in a family.) The actual odds are now considered to be far less extreme. The
GMC ﬁtness to practise panel said in its verdict that Prof Meadow had failed in his
Michael Goldstein
duty to check the validity of his statistics. There are many features of the case which
are worthy of comment. Of particular relevance is Prof. Meadows defence of his claim.
The following comes from the Guardian, July 2nd, 2005.
“Prof Meadow, whose evidence was used in the cases of three other women wrongly
accused of killing their babies, said he had been quoting the statistic from a highly
respected report on sudden infant deaths, which at the time had yet to be published.
Defending his right to use the report in his evidence at Mrs Clark’s trial, he said, “I was
quoting what I believed to be a very thorough study ... by experts, several of whom I
knew and respected.” Nicola Davies QC, representing Prof Meadow, asked: “Did you
have any diﬃculty with quoting statistics from the study?” He replied: “To me it was
like I was quoting a radiologist’s report or a piece of pathology ... I was quoting the
statistics, I wasn’t pretending to be a statistician.”
I have not seen the study in question, although I have read claims that Prof Meadow
quoted some calculations from the study which were taken out of context, ignoring the
conditions and qualiﬁcations around the quoted values. However, the general attitude
displayed to the statistical analysis, conferring on it a purely objective and value-free
status, surely lies at the heart of the issue. Prof Meadow’s professional misfortune may
only have been that the statistical ‘mistake’ for which he is blamed was suﬃciently
elementary that it could easily be argued that overlooking the error was professionally
negligent. I can easily envisage a more sophisticated treatment, say an ‘objective Bayes’
analysis, which, by placing ‘uninformative’ priors on certain key parameters in a more
elaborate version of the model, could make essentially the same ‘error’ but in a way
which would be far harder to detect. As statistical analyses become more sophisticated
and more diﬃcult for anyone but an expert statistician to check, it becomes increasingly
important that the meaning of the statistical analysis is clearly conveyed. Any statistician who does a Bayesian analysis for a problem with important practical consequences
but does not make good and clear use of informed judgements, and then labels that
analysis as ‘objective’, should be aware of the misunderstandings and mistakes that will
follow when their claim is taken precisely at face value.
Pure subjectivism
We have argued that the subjective Bayes approach is successful in practice, and is
invaluable for serious scientiﬁc analysis. This, however, leaves open possible criticisms
of the Bayes approach from the subjective viewpoint itself.
Carrying out a careful
Bayesian analysis can prove very diﬃcult.
In part this is because such an analysis
requires an extremely detailed level of prior probabilistic belief speciﬁcation. Typically,
we ﬁnd it diﬃcult to make detailed speciﬁcations in a way which genuinely corresponds
to our prior beliefs. Therefore, artiﬁcial, conventional prior forms are used, often bearing
only a limited relation to our prior beliefs, so that the resulting Bayesian analysis bears
only a limited relation to our actual judgements.
Is such a detailed speciﬁcation really a necessary consequence of the subjectivist
approach? No, I believe that this is a misunderstanding of the full subjectivist position,
Subjective Bayesian Analysis
which I will now brieﬂy consider.
Conditional and posterior probability
A true subjectivist formulation should start by recognising the limited abilities of the
individual to make large collections of uncertainty speciﬁcations. It is precisely this
consideration that led de Finetti, in de Finetti , the most careful statement of
the subjectivist position yet written, to chose expectation rather than probability as
his primitive for the subjectivist theory. With expectation as primitive, we can assess
directly whatever sub-collection of probabilities and expectations we consider ourselves
able to specify at any given time, whereas, if probability is the primitive, then we
must specify every probability before we can specify any expectation. Unfortunately,
the liberating aspect of this approach is somewhat lost in de Finetti’s development, as
changes in beliefs are still carried out by conditioning on events, which again requires a
ﬁnely detailed level of prior speciﬁcation ).
Therefore, we must also consider whether it is an intrinsic part of the subjectivist
position that beliefs should change by conditioning via Bayes theorem. This question
cuts to the heart of the Bayes position, as it is impossible to demonstrate any deﬁnitive
sense in which beliefs should change by conditioning. You might think that someone,
somewhere has proved that conditioning is the correct way to modify beliefs, at least
under certain conditions. However, all that can be proved is results such as the following. Suppose that you specify a joint probability distribution for a collection of random
quantities. Suppose that you also write down a rule for changing your probabilities for
some of the quantities, as a function of the numerical values of the remaining quantities.
If this rule for changing your probabilities is not the usual conditional probability formula, then you can be made a sure loser, in the usual sense of placing a sequence of bets
that pay oﬀdepending on various combinations of outcomes of the random quantities.
This is not a demonstration that beliefs should change by conditioning: all that
it does is to eliminate non-Bayesian rules for updating beliefs in the class of rules
based exclusively on current beliefs and the values of the observables. The fundamental
question remains as to what relevance probabilities that are declared conditional on the
outcome of certain events should hold for the actual posterior probabilities that you
assign when you do learn of the outcomes. By the time that you observe the data, you
may have come across further unanticipated but relevant information (or you may not,
and this also is relevant information), and you may well have further general insights
about the problem, by study of relevant literature, deeper mathematical treatment or
careful data analysis. None of this corresponds to Bayesian conditioning. Indeed, I
cannot remember ever seeing a non-trivial Bayesian analysis which actually proceeded
according to the usual Bayes formalism. All of this illustrates the simple observation
that there is no stronger reason why there should be a rule for going from prior to
posterior beliefs than that there should be such a rule for constructing prior beliefs in
the ﬁrst place. (For example, any attempt to view conditional beliefs as the beliefs that
you “should” hold were you to observe the conditioning event and “nothing else” is
Michael Goldstein
doomed to self-contradiction, as the fact that you observed nothing else was not part of
the original conditioning event, and would be informative were it to be included in the
conditioning.)
For the above reasons, all attempts to present the Bayesian approach as a normative
theory, which describes how we should, in principle, modify our beliefs given evidence,
must be fundamentally incomplete. They are analogous to a similar discussion as to
whether and when, say, a global climate model is right or wrong. This is the wrong
question. We know that the global climate model diﬀers from the actual climate - they
are two quite diﬀerent things. Instead, our two tasks are ﬁrst to identify why we consider
that a particular climate model is informative for climate, and second to quantify the
value of this information, by considering the residual uncertainty in climate behaviour,
given the analysis of the climate model.
If we view the Bayes formalism as providing a model for belief change which is neither
normative nor descriptive, then the natural questions are ﬁrst, why do we consider this
model relevant to actual problems of belief change, and second, how do we describe the
discrepancy between this model and the reality of changing beliefs? Our answers to these
questions are as follows; for details see Goldstein . We begin by distinguishing
between your current conditional probabilities P(A|B), P(A|Bc) and your posterior
probability Pt(A) that you will assign at future time t after you have observed either
B or Bc. We need a temporal principle to link beliefs that you specify now with those
that you will specify at time t. This link is provided by the temporal sure preference
(TSP) principle, which is as follows.
“If you are sure that at future time t you will prefer the (small) random penalty A
to the (small) random penalty B, then you should not now prefer B to A.”
TSP places a very weak requirement on your temporal preferences, which would
certainly be satisﬁed within the conventional Bayesian formulation. However, unlike
the Bayes formalism, which seeks to make today’s speciﬁcation logically compelling for
tomorrow’s revision of belief, TSP places our preferences in the right order, requiring
logical certainty in the future to be compelling for our current belief evaluations.
If we accept TSP for the current inference, then we can show )
that this establishes the following stochastic relationship between conditional and posterior probabilities, namely that at the present moment you must make the speciﬁcation
Pt(A) = P(A|B) + R,
where P(A|B) is the conditioning of A on the partition B = (B, Bc), namely
P(A|B) = P(A|B)B + P(A|Bc)Bc,
where B, Bc are the indicator functions for the corresponding events, and R is a further
random quantity with
E(R) = E(R|B) = E(R|Bc) = 0.
Subjective Bayesian Analysis
This corresponds closely to the interpretation that we have earlier suggested for
mathematical models of physical systems. For example, a climate model does not tell
us what will actually happen, but instead is useful, for example, in giving us a mean
forecast, with associated variance, whose value lies in reducing, but not eliminating, our
uncertainty about climate behaviour. Similarly, from (1), we are justiﬁed in viewing
P(A|B) as providing a mean forecast for our future judgements, while the residual
quantity R expresses the uncertainty in the conditional mean forecast. Informally, the
larger the variance of P(A|B) as compared to the variance of R, the more informative
a formal Bayes inference based on conditioning on B will be for the actual posterior
judgement on A. As the variance of Pt(A) is ﬁxed, we may both increase the variance
of P(A|B) and decrease the variance of R by reﬁning the partition B.
Bayes linear inference
The above argument clariﬁes the logical status of a Bayesian analysis. It also frees us
from the tyranny of conditioning. Even though (1) concerns probabilities, this relation
can only be derived within a formalism which starts with expectation as primitive. In
that formulation, probabilities are just expectation statements, and (1) is a special case
of the following general result. Suppose that D is a vector of quantities which will be
observed by time t. Given TSP, your current beliefs about your posterior expectation
Et(X) for any other random vector X, speciﬁed at time t, must satisfy the following
relations:
X = Et(X) + S
Et(X) = ED(X) + R,
where ED(X) is the Bayes linear mean for X determined by
ED(X) = E(X) + Cov(X, D)(Var(D))−1(D −E(D)
and R, S are further random quantities, with
E(R) = E(S) = Cov(R, D) = Cov(S, D) = Cov(R, S) = Cov(S, Et(X)) = 0.
The Bayes linear analysis is based on direct speciﬁcation of means, variances and
covariances; for an overview of the Bayes linear approach to statistics see Goldstein
 . From (2), (3), the Bayes linear analysis for X bears the same relation to the
actual posterior judgement for X that the posterior judgement for X bears to the
quantity X itself. Bayesian conditioning is simply the special case of (3) in which D
comprises the indicator functions for a partition.
If conditioning is not the operation underpinning the Bayesian analysis, then the
requirement of full probabilistic speciﬁcation can be seen as an arbitrary imposition.
We may make full probabilistic speciﬁcations where this is natural and straightforward;
this representation will maximise the proportion of uncertainty expressed by ED(X).
Michael Goldstein
However, this is a reﬁnement of degree, not of kind. If the extra information is worth the
eﬀort in prior speciﬁcation and analysis that is required, then the full Bayes approach is
worthwhile. Otherwise, a simpler analysis is appropriate. Placing the subjectivist analysis within a logical framework which distinguishes between the model for the inference
and the actual inference gives us control of the level of detail of our prior speciﬁcation
and analysis, while reminding us of the requirement to relate the formal analysis to the
larger inferential problem, which should always be our primary concern. Of course, this
raises further questions as to precisely how such inferences should be conducted. This is
largely unexplored territory; for theoretical underpinnings embedding statistical models
derived from exchangeability judgements within this more fully subjectivist view, see
Goldstein . Subjectivist theory oﬀers a language and framework rather than a
complete description of belief representation and inference. Whether such a complete
description could ever be provided is, in my subjective opinion, extremely doubtful.
Pragmatic subjectivism
The practical objection to routine use of subjective Bayesian analysis is that it is too
hard, because of the diﬃculty of specifying well founded prior distributions for the
quantities of interest in complicated problems. Any analysis is a pragmatic compromise
between what we might ideally wish to do and what it is feasible to do. In particular,
we may make pragmatic compromises in the following situations.
When it doesn’t aﬀect the answer
As we have suggested, it is often instructive to consider how wide a range of prior
judgements may be brought into broad agreement by the experimental data. If we have
suﬃcient data to overwhelm most reasonable assignments of prior beliefs, then we can
sidestep the subjectivist speciﬁcation, unless we are interested in analysing the way that
our beliefs have changed as a result of the experiment.
We may take a similar shortcut if the amount of data is rather less, but we feel that
our beliefs are suﬃciently vague that they may be overridden by even a small amount of
data. Alternatively, there may be some aspects of our speciﬁcation which, while present
for formal completeness in our uncertainty description, have very little impact on the
main issues which the analysis addresses.
In all such cases, we may employ simple automatic methods for prior speciﬁcation,
as we may demonstrate by analysis that this will have only a small eﬀect on the ﬁnal
conclusions.
When we are making a preliminary study
We make careful subjectivist speciﬁcations because we want to infer meaningful uncertainties about real situations. However, much of scientiﬁc investigation is preliminary
Subjective Bayesian Analysis
to this stage. We may study data arising in unfamiliar contexts in order to suggest
qualitative ideas which we may subsequently take forward in more careful and critical
quantitative studies. If a simple analysis can bring out the most important messages of
the data quickly and cleanly, then this may be suﬃcient. Similarly, we may study simple
models for complicated phenomena to try to gain qualitative insights into the kind of
behaviour that we might anticipate the system to follow, and therefore to guide us in
producing more realistic system models. In such cases, a full subjective prior speciﬁcation may be irrelevant and unnecessary to the aims of the study. If we want to produce
Bayesian output, then a simple vague or objective prior speciﬁcation may be adequate
to the analysis. All that we must be sure of in such cases is that everyone understands
that the analysis does not claim to oﬀer well-sourced uncertainty statements about real
When the problem is not important
We have observed that the practical quantity governing the value of the subjective
analysis is the “pain to gain” ratio.
For a given level of stochastic complexity, the
subjective analysis takes the same amount of eﬀort when nobody cares about the answer
or when the answer is of enormous importance. Common sense tells us not to waste too
much eﬀort in producing impeccable solutions to problems which were not worth careful
consideration in the ﬁrst place. The only qualiﬁer to this is that many people progress
through their careers by tackling problems with increasingly important consequences. It
is arguably a good idea to obtain practice in careful analysis on problems where mistakes
will not have disastrous consequences, rather than waiting for a critical problem on which
to gain subjectivist Bayesian skills.
When we are under-resourced
Suppose that a study aims to make uncertainty statements which will be applied to
an important real world problem and for which our prior speciﬁcation will be highly
relevant to the conclusions, but that we are not resourced adequately to support a full
subjectivist analysis. We are now faced with diﬃcult choices, for which there is no
fully satisfactory solution. We may decide that the value of the incomplete analysis
outweighs possible misinterpretation of the results. There are no strict guidelines as to
how to conduct an analysis under such resource constraints. In principle, we should
identify those aspects of the problem which are most sensitive to prior judgements and
those aspects for which prior knowledge appears most likely to be well formed and
speciﬁc, and aim to give careful subjective representation to each such aspect. For the
remaining features of the analysis, we may be able to employ simple standard prior
forms, without too much damage to our conclusions, and ideally, we would be able to
demonstrate this by supporting sensitivity analysis. Failing this happy outcome, we
should proceed with extreme caution, making clear to all participants the degree of
approximation in our conclusions, and, if necessary, identifying precisely the additional
resource which would be required in order to produce an analysis whose conclusions
Michael Goldstein
could be used with conﬁdence.
On not being be too pragmatic
While pragmatism is an excellent quality, it should not be used as an excuse for not
doing the job properly. My impression is that, in many ﬁelds, people may indeed be
taking an overly pragmatic stance. Thus, experimenters will argue for large budgets
for their experiments, and modellers will invest enormous eﬀorts in constructing and
running their models, and this process is well understood and accepted within science.
However, very few people outside of the Bayesian community are even aware of the
potential beneﬁts of carrying out a careful Bayesian statistical analysis and so it is up
to us to be aggressive in making the case for the value of such an approach. When
enormous time, eﬀort and investment has gone into experimenting, collecting data,
theorising and modelling, it is unfortunate, to say the least, if nobody takes the ﬁnal
step of bringing all these considerations together into a coherent statement as to what
our uncertainty should be as a result of all of this eﬀort.
Concluding comments
The subjective Bayes approach is alive and well and proving very successful in many
important practical applications. However, much of the potential of the approach is
still to be realised. Subjectivist analysis may appear daunting, but what is diﬃcult
is making reasoned judgements about complex situations within any framework at all.
The subjectivist approach does not make these diﬃculties vanish, but it does oﬀer a
coherent language and tool set for analysing all of the uncertainties in complicated
problems, and therefore provides the best method that I know for analysing uncertainty
in important real world problems. But who, in practice, will carry out such analyses?
Modellers are skilled at modelling, theorists develop theory, experimenters spend
their time experimenting and statisticians tend to view their role as analysing data.
These are all essential skills. But we are missing the specialism which moves beyond
these comfort zones and puts all these activities together. When we properly recognise,
develop and apply the ideas and methods of subjectivist analysis, then we will ﬁnally
be able to carry out that synthesis of models, theory, experiments and data analysis
which is necessary to make real inferences about the real world.