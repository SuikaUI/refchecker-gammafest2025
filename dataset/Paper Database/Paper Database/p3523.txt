Eﬀective and Eﬃcient Similarity Index for Link Prediction of Complex Networks
Linyuan L¨u1, Ci-Hang Jin1, and Tao Zhou1,2∗
1Department of Physics, University of Fribourg, Chemin du Muse, Fribourg 1700, Switzerland
2Department of Modern Physics, University of Science and Technology of China, Hefei 230026, P.R. China
Predictions of missing links of incomplete networks like protein-protein interaction networks or
very likely but not yet existent links in evolutionary networks like friendship networks in web society
can be considered as a guideline for further experiments or valuable information for web users. In
this paper, we introduce a local path index to estimate the likelihood of the existence of a link
between two nodes. We propose a network model with controllable density and noise strength in
generating links, as well as collect data of six real networks. Extensive numerical simulations on
both modeled networks and real networks demonstrated the high eﬀectiveness and eﬃciency of the
local path index compared with two well-known and widely used indices, the common neighbors
and the Katz index. Indeed, the local path index provides competitively accurate predictions as
the Katz index while requires much less CPU time and memory space, which is therefore a strong
candidate for potential practical applications in data mining of huge-size networks.
PACS numbers: 89.20.Hh, 89.75.Hc
INTRODUCTION
Many complex systems can be well described by networks where nodes present individuals or agents, and
links denote the relations or interactions between nodes.
Complex network is therefore becoming an useful tool in
analyzing a wide range of complex systems. Recently,
the understanding of structure, evolution and function
of networks has attracted much attention from physics
community . Another important scientiﬁc issue relevant to network analysis, namely the Information
Retrieval , however, received less attention. Originally, Information Retrieval aims at ﬁnding material of
an unstructured nature that satisﬁes an information need
from large collections . It can be also viewed as dealing
with prediction of links between words and documents,
and is now further extended to standing for a number
of problems on link mining . Actually, link prediction
problem is a long-standing challenge in modern information science, and a lot of algorithms have been proposed
based on Markov chains and machine learning processes
by computer science community . However, their works have not caught up the current progress
of the study of complex networks, especially they lack
serious consideration of the structural characteristics of
networks which may indeed provide useful information
and insights for link prediction.
The problem of link prediction aims at estimating the
likelihood of the existence of a link between two nodes,
based on observed links and the attributes of nodes. It
can be categorized into two classes: One is the prediction
of missing links in sampling networks, such as the food
webs and the world wide webs; the other is the prediction
of links that may exist in the future of evolving networks,
like the on-line social networks. In addition, the link pre-
∗Electronic address: 
diction algorithms (or other algorithms based on similar
techniques) can also be applied to solve the link classi-
ﬁcation problem in partially labeled networks ,
such as the prediction of protein functions and to
distinguish the research areas of scientiﬁc publications
Up to now, most of the algorithms are designed according to the deﬁnition of node similarity. Node similarity can be deﬁned just using the essential attributes
of nodes, namely two nodes are considered to be similar if they have many common features .
group of similarity indices is based solely on the network
structure, which is called structural similarity and can
be further classiﬁed as node-dependent, path-dependent
and mixed methods.
An introduction and comparison
of some similarity indices is presented in Ref.
which the Common Neighbors , Jaccard coeﬃcient
 , Adamic-Adar Index and Preferential Attachment are classiﬁed to be the node-dependent indices,
while Katz Index , Hitting Time , Commute Time
 , Rooted PageRank , SimRank and Blondel
Index are classiﬁed to be the path-dependent indices.
Besides, Leicht, Holme and Newman proposed a measure
to quantify the node similarity based on the assumption
that two nodes are similar if their immediate neighbors
in the network are themselves similar . This leads to
a self-consistent matrix formulation of similarity that can
be evaluated iteratively using the adjacency matrix. This
similarity index can also be considered as a candidate for
accurate link prediction.
Besides the similarity-based prediction algorithms,
some more complicated methods are proposed recently.
Clauset, Moore and Newman proposed an algorithm
based on the hierarchical network structure .
Firstly, they use a hierarchical random graph to statistically ﬁt the real network data. Then the dependence
of the lateral-connection probability on the depth of the
nodes in the hierarchy can be inferred. Finally, one can
predict the missing links of the network according to the
lateral-connecting probability by ranking them in the descending order.
Furthermore, many eﬀorts have been
done for designing the recommender systems . Actually, the process of recommending items to a user can be
considered as the prediction of missing links in the useritem bipartite network . Especially, physicists have
recently proposed some information recommendation algorithms based on physical processes, such as energy diffusion and heat conduction . Although the
relevant issue has not been fully explored, it highlights
a possibility to improve the accuracy and eﬃciency of
link prediction algorithms by applying classical physics
There are many diﬃculties for the studies of link prediction.
One is the sparsity of the target networks
 , which leads to a serious problem that the
prior probability of a link is typically quite small, resulting in large diﬃculties in building statistical models. The other problem is the huge size of real systems
that requires highly eﬃcient algorithms. However, the
complexity of computational time and memory, being a
crucial factor in real applications, has not been systematically investigated. Generally speaking, the accuracy
of an algorithm and its computational complexity have
positive correlation, namely higher accuracy usually implies higher complexity. Note that, any highly accurate
algorithm will become meaningless if the consuming time
or memory is unacceptable. Therefore, designing an accurate and fast algorithm is a big challenge, especially
for sparse and huge networks.
In this paper, we introduce a so-called local path index
to characterize the node similarity. Extensive numerical
simulations on both modeled networks and real networks
demonstrate that this similarity index is simultaneously
highly eﬀective (its prediction accuracy is much higher
than the common neighbors, and competitive with the
Katz index) and highly eﬃcient (the time and space required to compute it are much less than those for the
Katz index). Especially, when the network is huge, the
local path index shows great advantage compared with
the Katz index since computing the latter asks for a CPU
time scaling as cube of the network size while computing
the former requires a linear CPU time as the network size.
We therefore think this local path index is a strong candidate for potential practical applications in data mining
of huge-size complex networks.
Considering an unweighted undirected simple network
G(V, E), where V is the set of nodes and E is the set
of links. The multiple links and self-connections are not
allowed. For each pair of nodes, x, y ∈V , we assign a
score, sxy. Since G is undirected, the score is supposed
to be symmetry, say sxy = syx. All the nonexistent links
are sorted in decreasing order according to their scores,
and the links in the top are most likely to exist. In this
Accuracy (AUC)
FIG. 1: (Color online) Prediction accuracy vs. the strength
of randomness for three similarity indices: CN (circles), LP
(triangles) and Katz index (squares).
The network size,
N = 1000, and the degree, k = 10, are ﬁxed.
point is obtained by averaging over 10 independent realizations. When approaching the purely random case, p = 1, the
accuracies of CN and LP go below 0.5, which is an artifact
of the speciﬁc constrain on identical degree. That is, in the
purely random case, two unconnected nodes with higher degrees in the training set are of less probability to be connected
in the probe set since the total degree is identical for every
node, however, they generally have more common neighbors
and thus higher similarity.
paper, we adopt the simplest framework, that is, to directly set the similarity as the score, so the higher score
means the higher similarity, and vice versa. In some link
prediction algorithms, the scores may be not directly related to a certain similarity measurement, but describe
the existence likelihood of links ,
and in some other algorithms, scores may be generated
by an integration of some similarities of node pairs in the
neighborhood of the target links, such as the collaborative ﬁltering method .
In this paper, we compare the prediction accuracies
and computational complexity of three similarity indices:
Common Neighbors (CN), Katz Index and a newly proposed similarity index, namely Local Path Index (LP index or LP for short). Their deﬁnitions and relevant motivations are introduced as follows:
(i)Common Neighbors, which is also called structural
equivalence in Ref. . In common sense, two nodes, x
and y, are more likely to form a link in the future if they
have many common neighbors. For a node x, let Γ(x)
denote the set of neighbors of x. The simplest measure
of the neighborhood overlap is the directed count:
sxy = |Γ(x) ∩Γ(y)|,
where |Q| is the cardinality of the set Q. It is obvious
that sxy = (A2)xy, where A is the adjacency matrix, in
which Axy = 1 if x and y are directly connected and
Accuracy (AUC)
FIG. 2: (Color online) Prediction accuracy vs. network density for three similarity indices: CN (circles), LP (triangles)
and Katz index (squares). Since in this model, every node has
the same degree, we therefore directly use degree to denote
the network density. The network size, N = 1000, and the
strength of randomness, p = 0.2, are ﬁxed. Each data point
is obtained by averaging over 10 independent realizations.
Axy = 0 otherwise. Note that, (A2)xy is also the number
of diﬀerent paths with length 2 connecting x and y. Newman used this quantity in the study of collaboration
networks, showing the correlation between the number of
common neighbors and the probability that two scientists
will collaborate in the future. Some more complicated
measures, such as Salton Index , Jaccard Index ,
Sørensen Index and Adamic-Adar Index , can
also be categorized into CN-based measures. However,
recently, extensive empirical analysis has demonstrated
that the simplest CN (i.e., Eq. (1)) performs even better
than those complicated variants . Therefore, we
here select CN as the representative of all CN-based measures. Although CN consumes little time and performs
relatively good among many local indices, due to the insuﬃcient information, its accuracy can’t catch up with
the measures based on global information. One typical
example is the Katz Index .
(ii) Katz Index. This measure is based on the ensemble
of all paths, which directly sums over the collection of
paths and exponentially damped by length to give the
short paths more weights. The mathematical expression
βl · |paths<l>
where paths<l>
is the set of all paths with length l connecting x and y, and β is a free parameter controlling the
weights of the paths. Obviously, a very small β yields a
measure close to CN, because the long paths contribute
very little. The S matrix can be written as (I−βA)−1−I.
Note that, β must be lower than the reciprocal of the
Node Neighbors
FIG. 3: (Color online) An illustration of time complexity in
calculating CN and LP indices. (a) A fully connected network
with four nodes as the example. (b) Lists of the neighborhood
of each node. (c) Process of how to determine all the similarities relevant to node 1.
maximum of the eigenvalues of matrix A to ensure the
convergence of Eq. (2).
(iii)Local Path Index. To provide a good tradeoﬀof
accuracy and complexity, we here introduce an index that
takes consideration of local paths, with wider horizon
than CN. It is deﬁned as
S = A2 + ǫA3,
where S denotes the similarity matrix and ǫ is a free parameter. Clearly, this measure degenerates to CN when
ǫ = 0. And if x and y are not directly connected (this is
the case we are interested in), (A3)xy is equal to the number of diﬀerent paths with length 3 connecting x and y.
Although it needs more information than CN, it is still a
local measure of relatively lower complexity than global
Choosing these three indices for comparison is because they all can be classiﬁed to path-dependent similarities with uniﬁed form as sxy = P βl · |paths<l>
where for CN, l = 2; for LP, l = 2, 3; and for Katz,
l = 1, 2, 3, · · · , ∞. Since we are only interested in the indirectly connected node pairs, Katz Index can be treated
as a measure considering l = 2, 3, · · · , ∞. Note that, all
these three indices are used to quantify the structural
equivalence, with an latent assumption that the link itself indicated a similarity between two endpoints (see,
for example, the Leicht-Holme-Newman index and
transferring similarity ). An issue worth future exploration is whether a certain similarity measure on regular
equivalence (see Ref. for the mathematical deﬁnition
of regular equivalence and Ref. for a recent application on the prediction of protein functions) can provide
better predictions.
To test the algorithmic accuracy, the observed links, E,
is randomly divided into two parts: the training set, ET ,
is treated as known information, while the probe set, EP ,
is used for testing and no information in the probe set is
allowed to be used for prediction. Clearly, E = ET ∪EP
and ET ∩EP = ∅. In this paper, the training set always
contains 90% of links, and the remaining 10% of links
constitute the probe set. We use a standard metric, area
under the receiver operating characteristic (ROC) curve
 , to quantify the accuracy of prediction algorithms.
In the present case, this metric can be interpreted as the
probability that a randomly chosen missing link (a link
in EP ) is given a higher score than a randomly chosen
nonexistent link (a link in U \ E, where U denotes the
universal set). In the implementation, among n times of
independent comparisons, if there are n′ times the missing link having higher score and n′′ times the missing link
and nonexistent link having the same score, we deﬁne the
accuracy as n′+0.5n′′
. If all the scores are generated from
an independent and identical distribution, the accuracy
should be about 0.5. Therefore, the degree to which the
accuracy exceeds 0.5 indicates how much better the algorithm performs than pure chance. Readers are encouraged to see the Refs. for more information about
how to evaluate the accuracy of prediction algorithms.
In this section, we compare the three similarity indices in modeled networks with controllable density and
randomness. Although the real networks have complex
structural properties , such as the community structure, the mixing pattern and the rich-club phenomenon,
as a start point, we only consider a very simple model,
and to eliminate the eﬀect of degree heterogeneity, we assume that every node has an identical degree, k. In this
model, each node is characterized by a 10-dimensional
vector with each element a randomly selected real number in the interval (−1, 1).
This vector represents the
node’s intrinsic features, such as the attributes of an object and the proﬁles of a person. Two nodes are considered to be similar and thus of high probability to connect to each other if they share many close attributes.
Therefore, we deﬁne the intrinsic similarity between two
nodes as the scalar product of the corresponding vectors,
xy = ⃗fx · ⃗fy = sI
where ⃗fx is the vector of node x, and the superscript
emphasizes that this similarity is intrinsic and can not
be observed in the real systems.
Given the network size, N, and the degree of each
node, k, this model starts with an empty network but
N nodes, that is, each node is of degree zero. At each
time step, a node with the smallest degree is randomly
selected (generally, there are more than one node having
Computation Time (ms)
Slope=2.89
Slope=1.13
Slope=1.06
FIG. 4: (Color online) A log-log plot about how the computational time (in microsecond) depends on the network size for
three indices, CN (circles), LP (triangles) and Katz (squares).
The node degree, k = 10, and the strength of randomness,
p = 0.2, are ﬁxed. Each data point is obtained by averaging
over 10 independent realizations. All computations were carried out in a desktop computer with a single Intel (R) Xeon
(TM) processor (3.00 GHz) and 2GB EMS memory.
the smallest degree). Among all other nodes whose degrees are smaller than k, this selected node will connect
to the most similar node with probability 1 −p, while
a randomly chosen one with probability p. This process
will terminate when all nodes are of degree k. The parameter p ∈ represents the strength of randomness
in generating links, which can be understood as noise or
irrationality that exists in almost every real system.
In Fig. 1 and Fig. 2, we report the comparison of algorithmic accuracy for those three similarity indices. Data
points are corresponding to the optimal values of β (for
Katz index) or ǫ (for LP index) subject to the highest
accuracies. Clearly, both Katz index and LP index perform remarkable better than the simple CN index. As
shown in Fig. 1, when the strength of randomness/noise
is weak, LP index gives competitive result as Katz index,
while for highly noisy cases, LP index performs even better. Whatever the similarity index, a link prediction algorithm is expected to give higher accuracy for a denser
network, which is in accordance with what observed in
Fig. 2. In the area with lacking information (i.e., small
k) or rich information (i.e., large k), LP index performs
slightly better than CN index, while in the middle with
typical degree as the real networks, LP index can perform
much better than the CN index.
The reason why the CN index performs remarkably
poorer than LP index is that the probability that two
node pairs are assigned the same similarity by CN is
high. That is to say, CN index is less distinguishable,
especially in the relatively sparse networks. For example, in the case N = 1000, p = 0 and k = 10, there
are about 5 × 105 node pairs, 94.01% of which are as-
Computation Time (ms)
Slope=2.78
Slope=1.84
FIG. 5: (Color online) A log-log plot about how the computational time (in microsecond) depends on the node degree for
three indices, CN (circles), LP (triangles) and Katz (squares).
The network size, N = 1000, and the strength of randomness,
p = 0.2, are ﬁxed. Each data point is obtained by averaging
over 10 independent realizations. The hardware environment
is the same as what we stated in the caption of Figure 4.
signed zero score, and for all non-zero scores, 79.87% are
As shown later, the real cases may be even worse,
for instance, in a router-level Internet with 5022 nodes,
99.59% of node pairs are assigned zero score by CN, while
for all those non-zero scores, 91.11% of which are assigned
score one. The additional information involving the next
nearest neighbors introduced by LP index can make the
similarities much more distinguishable, thus remarkably
enhance the accuracy. Note that, if the maximal number of paths with length three connecting two arbitrary
nodes is Pmax, any ǫ in the interval (0,
Pmax ) will give out
exactly the same predictions. Therefore, the prediction
accuracy for LP index is not sensitive to the parameter
ǫ when ǫ is not so large.
Indeed, setting ǫ as a small
positive number like 0.01 one can obtain a near optimal
accuracy, usually less than 1% smaller than the real optimum (see also Table II, where we compare the optimal
AUC values with the values obtained by setting ǫ = 0.01
for the six real networks). In ﬁnding the optimal value of
β, one can ﬁrst calculate the maximal eigenvalue of the
adjacency matrix, and the optimal β is always smaller
than its reciprocal. It is then easy to approach the optimal β. For example, the optimal values of β for relevant
data points shown in Fig. 1 and Fig. 2 are all no larger
than 0.03.
Next, we discuss the computational complexities of the
three similarity indices. In calculating the CN index, for
each node, denoted by x, we ﬁrst search all x’s neighbors
(called the step 1), and then lay out the neighbors of
each of x’s neighbors, respectively (called the step 2). If
a node y appears n times in the step 2, sxy = n. Since the
time complexity to traverse the neighborhood of a node
is simply k, the time complexity in calculating CN index
is O(Nk2). Analogously, for LP index, what we need to
do is go one step further (called the step 3) to check all
neighbors of each of x’s second-order neighbors, respectively. If a node y appears n times in x’s second-order
neighborhood and m times in x’s third-order neighborhood, sxy = n + ǫm. Therefore, the time complexity in
calculating the LP index is O(Nk3). An detailed illustration for an example network consisted of four nodes is
shown in Fig. 3. For the Katz index, the time complexity
is mainly determined by the matrix inversion operator,
which is O(N 3) . In Fig. 4 and Fig. 5, we report the
numerical results about computational complexity of the
three similarity indices, which are well in accordance with
the analysis. Beside the time complexity, memory space
is another limitation for algorithmic implementation for
huge-size networks. In calculating CN and LP indices,
the memory required are of the order O(Nk), while for
the Katz index, it is of the order O(N 2).
In a word,
compared with the widely applied CN index and Katz
index, the LP index is not only highly eﬀective (i.e., accurate), but also highly eﬃcient (i.e., required relatively
less memory and CPU time).
EMPIRICAL ANALYSIS
In this paper, we consider six representative networks
drawn from disparate ﬁelds: (i) PPI.— A protein-protein
interaction network containing 2617 proteins and 11855
interactions . Although this network is not connected
(it contains 92 components), most of nodes belong to the
giant component, whose size is 2375. (ii) NS.— A network of coauthorships between scientists who are themselves publishing on the topic of networks . This network contains 1589 scientists, and 128 of which are isolated. Here we do not consider those isolated nodes. The
connectivity of NS is not good. It is consisted of 268 connected components, and the size of the largest connected
component is only 379. (iii) Grid.— An electrical power
grid of western US , with nodes representing generators, transformers and substations, and links corresponding to the high voltage transmission lines between them.
This network contains 4941 nodes and is well connected.
(iv) PB.— A network of the US political blogs . The
original links are directed, here we treat them as undirected ones. PB has 1224 nodes and the giant component
contains 1222 nodes. (v) INT.— The router-level topology of the Internet, which is collected by the Rocketfuel
Project . INT has 5022 nodes and is well connected,
while it is an extremely sparse network with average degree being only 2.49. (vi) USAir.— the network of US air
transportation system, which contains 332 airports and
2126 airlines . Note that, all the similarity indices
considered here, as well as those well-known indices (except the preferential attachment index) reported in Refs.
 , will give zero score to a pair of nodes located in
two disconnected components. Therefore, here we only
TABLE I: The basic topological features of the giant components of the six example networks. N and M are the total
numbers of nodes and links, respectively. ⟨k⟩is the average
degree of the network. ⟨d⟩is the average shortest distance between node pairs. C and r are clustering coeﬃcient and
assortative coeﬃcient , respectively. Nodes with degree 1
are excluded from the calculation of clustering coeﬃcient. H
is the degree heterogeneity, deﬁned as H =
⟨k⟩2 , where ⟨k⟩
denotes the average degree.
2375 11693 9.847
4.59 0.388 0.454 3.476
4.93 0.798 -0.082 1.663
2.669 15.87 0.107 0.003 1.450
1222 16717 27.360 2.51 0.360 -0.221 2.970
5.99 0.033 -0.138 5.503
2126 12.807 2.46 0.749 -0.208 3.464
consider the giant component, and when preparing the
probe set, we also make sure that the remain training set
representing a connected network. Actually, each time
before removing of a link to the probe set, we ﬁrst check
if this removal will make the training network disconnected.
Table 1 summarizes the basic topological features of the giant component of those networks. Brief
deﬁnitions of the monitored topological measures can be
found in the table caption, for more details, please see
the review articles .
We apply the link prediction algorithm on the six real
networks, and the accuracies is shown in Table 2, with
those entries corresponding to the highest accuracies being emphasized by black. Clearly, the LP index always
performs better than the CN index, especially, for INT,
the AUC is sharply improved from 0.653 to 0.943. Except Grid, the LP index gives competitively accurate
predictions as the Katz index. Grid is a strongly localized network with most of links being of short geographical lengths, and thus the average topological distance
of Grid, ⟨d⟩= 15.87, is much larger than the other ﬁve
example networks. Although Grid is geographically localized, the clustering coeﬃcient is relatively small and
it lacks short loops since such loops are redundant and of
lower eﬃciency in the engineering viewpoint. Actually, in
Grid, when a link is removed, it is usually hard to ﬁnd a
very short path (like of length 2 or 3) connecting the two
endpoints. Therefore, the CN and LP indices, considering only very short paths, fail to re-ﬁnd the correlation
between two directly connected nodes if the link is removed. In addition, we note that the optimal value of ǫ
for USAir is negative. In USAir, the large-degree nodes
are densely connected and share many common neighbors. Even without the contribution of ǫA3, the links
among large-degree nodes are assigned very high scores,
thus the additional item, ǫA3, changes little of their relative positions. Considering two small local airports, x
and y, which are connected to their local central airports,
TABLE II: Accuracies of the three similarity indices, measured by the area under the ROC curve (AUC). Each number is obtained by averaging over 10 independent realizations.
The entries corresponding to the highest accuracies are emphasized by black. For LP and Katz indices, the AUC values
are corresponding to the optimal parameter. LP* denotes the
LP index with a ﬁxed parameter ǫ = 0.01. The very small difference between the optimal case and the case with ǫ = 0.01
suggests that in the real application, one can directly set ǫ as
a very small number, instead of ﬁnding out its optimum that
may cost much time.
0.970 0.988 0.697 0.941 0.943 0.960a
Katz 0.972 0.988 0.952 0.936 0.975
aFor USAir, the optimal value of ǫ is negative. See the explanation
bFor USAir, we set ǫ = −0.01.
x′ and y′. Of course, many hubs are common neighbors
of x′ and y′, and x′ and y′ may be directly connected.
If the link (x, x′) is removed, the similarities between x
and other nodes are all zero. Otherwise, the similarities
sxy′ (by x-x′-hub-y′), sxy (by x-x′-y′-y), and sxh where
h represents a hub node (by x-x′-hub-h or x-x′-y′-h) are
positive due to the contributions of paths with length 3.
There are many links connecting small local airports and
local centers, some of which are removed, and the others are kept in the testing set. According to the above
discussion, the removed links have lower score than the
nonexistent links due to the additional item ǫA3. In a
word, the very speciﬁc structure of USAir (the hierarchical organization consisted of hubs, local centers and
small local airports) makes the LP index with positive ǫ
worse than the simple CN corresponding to ǫ = 0, which
is also the reason why negative ǫ performs even better.
Table 3 presents the computation time of the link prediction algorithm on the three similarity indices. Clearly,
CN costs the least. Note that, the computational complexity in calculating the LP index is very sensitive to
the average degree, while the one in calculating the Katz
index is very sensitive to the network size. Therefore,
the algorithm using LP index has great superiority for
the huge-size and sparse networks compared with the
one adopting the Katz index.
Take INT as an example, the algorithm using the Katz index runs about one
day while the one using the LP index takes less than half
minute. Since the real challenge on computational complexity is always relevant to the huge-size real networks,
which are mostly very sparse , the LP index is much
more practical than the Katz index. As a ﬁnal remark,
one may concern that whether to employ higher-order
paths is worthwhile in practice, like to deﬁne a similarity
TABLE III: Computation time (in microsecond) of the link
prediction algorithm on the three similarity indices of the six
example networks. The hardware environment is the same as
what we stated in the caption of Figure 4.
Katz 8073316 27479 69961063 1051528 72550935 17603
TABLE IV: Comparison of the accuracies of the original local
path index (n = 3, see Eq. (3)) and the higher-order local
path index (n = 4, see Eq. (5)), measured by the area under
the ROC curve (AUC). Each number is obtained by averaging
over 10 independent realizations. The AUC values reported
here are corresponding to the optimal parameter. The average
shortest distance and the improvement (%) by considering
higher-order paths are also laid out in this Table, and all
the six real networks are ordered by their shortest average
distances.
5.99 15.87
0.941 0.970 0.988 0.943 0.697
0.937 0.973 0.989 0.959 0.759
Improvement -0.104 -0.425 0.309 0.101 1.70
index in the form
S = A2 + ǫA3 + ǫ2A4.
We give a brief discussion on this issue in Appendix A.
CONCLUSION AND DISCUSSION
In this paper, we introduced a local path index to estimate the likelihood of the existence of a link between two
nodes. We propose a network model with controllable
density and noise strength in generating links. The LP
index provides slightly more accurate predictions than
the Katz index, especially in the highly noisy cases. We
further use six representative real networks to test the
three similarity indices, showing that the LP index can
provide competitively accurate predictions as the Katz
index. Compared with the Katz index, the LP index requires much less CPU time and memory space, and is
therefore more practical. Ignored the degree-degree correlation, the time complexities in calculating LP index
and Katz index are O(N⟨k⟩3) and O(N 3), respectively.
Hence for the huge (i.e., very large N) and sparse (i.e.,
very small average degree ⟨k⟩) networks, the advantage
of the LP index is striking.
Highly accurate predictions are signiﬁcant in practice.
For example, many biological networks, such as
protein-protein interaction networks, metabolic networks
and food webs, the discovery of links/interactions costs
much in the laboratory or the ﬁeld. Instead of blindly
checking all possible interactions, to predict in advance
based on the interactions known already and focus on
those links most likely to exist can sharply reduce the
experimental costs if the predictions are accurate enough
 . For some others like the friendship networks in
web society, very likely but not yet existent links can be
suggested to the relevant users as recommendations of
promising friendships. These recommendations can help
users ﬁnding new friends and thus enhance their loyalties
to the web sites. Besides the practical signiﬁcance, it is
worthwhile to emphasize that the study of link prediction can also provide some theoretical insights about the
structural organization. For example, in this paper, the
unexpected results on Grid and USAir give evidence to
some speciﬁc structural properties that are not straightforwardly notable. Another example is that the preferential attachment index usually gives poor predictions, and
when it works relatively good, it implies that the testing
network has strong rich-club phenomenon . Although the focus of this paper is not to investigate the
relations between suitable similarity indices and network
structures, we believe it is an interesting issue worth further studies.
In this paper, we only considered the link prediction
problem in static networks.
However, many real networks are evolving all the time, and the links created
in diﬀerent times should be assigned diﬀerent weights in
principle. This time-involved link prediction problem is
rarely investigated and of course worths a serious study
in the future . Most of previous studies in relevant
direction only test the algorithmic accuracy in real networks. Here we argue that the modeled networks should
be used, because one can control some meaningful parameters in a model, which can not be directly observed
in the real networks (e.g., the strength of noise or irrationality). We hope the proposed model could become a
prototype in testing the accuracy of link prediction algorithms, however, it is currently too simple and to make it
closer to the real networks, such as introducing controllable degree heterogeneity and degree-degree correlation,
is very helpful.
This paper concerns only the simple networks, however, the local path index can be easily extended to more
complicated cases. For example, we can handle the directed networks by replacing the original adjacency matrix, A, by an asymmetry one, the weighted networks
by replacing A by a weighted matrix, and the networks
with self connections by assigning nonzero diagonal elements. Actually, Murate and Moriyasu have already
investigated the link prediction problem in weighted networks, however, the credibility of their work is recently
challenged by the empirical evidence that the weak ties
may play a more important role in link prediction than
the strong ties .
Acknowledgments
The authors acknowledge valuable discussion with Yi-
Cheng Zhang.
This work is partially supported by
the Swiss National Science Foundation (Project 205120-
113842). C.-H.J. acknowledges the Future and Emerging
Technologies programmes of the European Commission
FP7-COSI-ICT (Project QLectives, Grant No. 231200).
T.Z. acknowledges the National Natural Science Foundation of China (Grant Nos. 10635040 and 60744003).
APPENDIX A: SIMILARITY INDEX INVOLVING
HIGHER-ORDER PATHS
A straightforward method to extend the local path index is to consider the higher-order paths. Such a similarity index is of the form
S = A2 + ǫA3 + ǫ2A4 + · · · + ǫn−2An,
where n > 2 is the maximal order. As shown in Fig. 3,
the computational complexity in an uncorrelated network
is O(N⟨k⟩n), which grows fast with the increasing of n
and will exceed the complexity for calculating the Katz
index for large n. We therefore concentrate on the case
of n = 4, equivalent to the one shown in Eq. (5).
As shown in Table IV, the improvements of accuracy
are not much except for the power grid. Sometimes, to
introduce higher-order relations will even decrease the
accuracy, like for USAir and PB. The results are very
sensitive to the average shortest distances of networks.
If ⟨d⟩is very short, to consider paths with length three
seems enough, and the addition item, ǫ2A4, will make
little eﬀort (e.g., PPI, NS and INT) or even negative
eﬀort (e.g., USAir and PB). Only when the network is of
long average shortest distance, to consider higher-order
relations may be cost-eﬀective. Since most real networks
exhibit strongly small-world eﬀect , a local
path index taking into account paths with length no more
than three may be practically suﬃcient.
 R. Albert and A.-L. Barab´asi, Rev. Mod. Phys. 74, 47
 S. N. Dorogovtsev and J. F. F. Mendes, Adv. Phys. 51,
1079 .
 M. E. J. Newman, SIAM Rev. 45, 167 .
 S. Boccaletti, V. Latora, Y. Moreno, M. Chavez and D.-
U. Huang, Phys. Rep. 424, 175 .
 L. da F. Costa, F. A. Rodrigues, G. Travieso and P. R.
U. Boas, Adv. Phys. 56, 167 .
 G. Salton and M. J. McGill, Introduction to Modern Information Retrieval .
 G. Salton, Automatic text processing:
the transformation, analysis, and retrival of information by computer
 .
 C. D. Manning, P. Raghavan and H. Sch¨utze, Introduction to Information Retrieval .
 L. Getoor and C. P. Diehl, Link mining: A survey, in
Proceeding of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining .
 R. R. Sarukkai, Computer Networks 33, 377 .
 A. Popescul and L. Ungar, Statistical relational learning
for link prediction, in Workshop on Learning Statistical
Models from Relational Data .
 M. Bilgic, G. M. Namata and L. Getoor, Combining collective classiﬁcation and link prediction, Workshop on
Mining Graphs and Complex Structures at the IEEE International Conference on Data Mining, .
 K. Yu, W. Chu, S. Yu, V. Tresp and Z. Xu, Stochastic
Relational Models for Discriminative Link Prediction, in
Advance in Neural Information Processing Systems 19
 .
 P. Holme and M. Huss, J. R. Soc. Interface 2 327.
 B. Gallagher, H. Tong, T. Eliassi-Rad, and C. Falousos,
Using ghost edges for classiﬁcation in sparsely labeled networks, in Proceeding of the ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining
 .
 D. Lin, An information-theoretic deﬁnition of similarity,
in Proceedings of the International Conference on Machine Learning, Madison, August, .
 D. Liben-Nowell and J. Kleinberg, J. Am. Soc. Inf. Sci.
&. Technol. 58, 1019 .
 F. Lorrain and H. C. White, J. Math. Sociol. 1, 49 .
 P. Jaccard, Bulletin de la Societe Vaudoise des Science
Naturelles 37, 547 .
 L. A. Adamic and E. Adar, Social Networks 25, 211
 A.-L. Barab´asi and R. Albert, Science 286, 509 .
 L. Katz, Psychmetrika 18, 39 .
 F. Gobel and A. Jagers, Stochastic Processes and Their
Applications 2, 311 .
 F. Fouss, A. Pirotte, J.-M. Renders and M. Saerens,
IEEE Trans. Knowl. Data Eng. 19, 355 .
 S. Brin and L. Page, Computer Networks and ISDN Systems 30, 107 .
A Measure of
Structural-Context Similarity, in Proceedings of the ACM
SIGKDD International Conference on Knowledge Discovery and Data Mining .
 V. D. Blonder, A. Gajardo, M. Heymans, P. Senellart, P.
V. Dooren, SIAM Rev. 46, 647 .
 E. A. Leicht, P. Holme and M. E. J. Newman, Phys. Rev.
E 73, 026120 .
 A. Clauset, C. Moore and M. E. J. Newman, Nature 453,
98 .
 S. Redner, Nature 453, 47 .
 G. Adomavicius and A. Tuzhilin, IEEE Trans. Know. &
Data Eng. 17, 734 .
 T. Zhou, Personal Recommendation in User-Object Networks, in J. Zhou (ed.), Complex Sciences .
 T. Zhou, J. Ren, M. Medo, and Y.-C. Zhang, Phys. Rev.
E 76, 046115 .
 T. Zhou, L.-L. Jiang, R.-Q. Su, Y.-C. Zhang, Europhys.
Lett. 81, 58004 .
 Y.-C. Zhang, M. Medo, J. Ren, T. Zhou, T. Li, and F.
Yang, Europhys. Lett. 80, 68003 .
 Y.-C. Zhang, M. Blattner, and Y.-K. Yu, Phys. Rev. Lett.
99, 154301 .
 L. Getoor, ACM SIGKDD Explorations Newsletter 5, 84
 J. O’Madadhain, J. Hutchins and P. Smyth, ACM
SIGKDD Explorations Newsletter 7, 23 .
 M. Rattigan and D. Jensen, ACM SIGKDD Exploration
Newsletter 7, 41 .
 Z. Huang, X. Li, H. Chen, Link prediction approach
to collaborative ﬁltering,
In Proceedings
of the 5th
ACM/IEEE-CS Joint Conference on Digital Libraries
 .
 M. E. J. Newman, Phys. Rev. E 64, 025102 .
 T. Sørensen, Biol. Skr. 5, 1 .
 T. Zhou, L. L¨u and Y.-C. Zhang, Eur. Phys. J. B (to be
published), arXiv: 0901.0553.
 D. Sun, T. Zhou, J.-G. Liu, R.-R. Liu, C.-X. Jia, and
B.-H. Wang, Phys. Rev. E 80, 017101 .
 D. R. White and K. P. Reitz, Social Networks 5, 193
 J. A. Hanely and B. J. McNeil, Radiology 143, 29 .
 S. Geisser, Predictive inference: An introduction .
 J. L. Herlocker, J. A. Konstan, K. Terveen, and J. T.
Riedl, ACM Trans. Inf. Syst. 22, 5 .
 G. H. Golub, C. F. Van Loan, Matrix Computation .
 C. von Merging, R. Krause, B. Snel, M. Cornell, S. G.
Oliver, S. Fields and P. Bork, Nature 417, 399 .
 M. E. J. Newman, Phys. Rev. E 74, 036104 .
 D. J. Watts and S. H. Strogatz, Nature 393, 440 .
Mapping the
blogosphere:
Are conservative bloggers more prominent, Presentation to BlogTalk Downunder, Sydney, 2005, available at
 
 N. Spring, R. Mahajan, D. Wetherall and T. Anderson,
IEEE/ACM Trans. Networking 12, 2 .
 V. Batageli and A. Mrvar, Pajek Datasets, available at
 
 M. E. J. Newman, Phys. Rev. Lett. 89, 208701 .
 J. Liu and D.-S. Deng, Physica A 388, 3643 .
 T. Murata and S. Moriyasu, Link prediction of social networks based on weighted proximity measures, In Proc.
IEEE/WIC/ACM International Conf. Web Intelligence
 .
 L. L¨u and T. Zhou, Role of Weak Ties in Link Prediction of Complex Networks, In Proc. 18th ACM Conf. Inf.
Knowl. Management ,