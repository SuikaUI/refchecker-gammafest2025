The Annals of Statistics
2004, Vol. 32, No. 6, 2385–2411
DOI 10.1214/009053604000000698
© Institute of Mathematical Statistics, 2004
CENTRAL LIMIT THEOREM FOR SEQUENTIAL MONTE CARLO
METHODS AND ITS APPLICATION TO BAYESIAN INFERENCE
BY NICOLAS CHOPIN
Bristol University
The term “sequential Monte Carlo methods” or, equivalently, “particle
ﬁlters,” refers to a general class of iterative algorithms that performs Monte
Carlo approximations of a given sequence of distributions of interest (πt). We
establish in this paper a central limit theorem for the Monte Carlo estimates
produced by these computational methods. This result holds under minimal
assumptions on the distributions πt, and applies in a general framework
which encompasses most of the sequential Monte Carlo methods that have
been considered in the literature, including the resample-move algorithm of
Gilks and Berzuini [J. R. Stat. Soc. Ser. B Stat. Methodol. 63 127–146]
and the residual resampling scheme. The corresponding asymptotic variances
provide a convenient measurement of the precision of a given particle ﬁlter.
We study, in particular, in some typical examples of Bayesian applications,
whether and at which rate these asymptotic variances diverge in time, in order
to assess the long term reliability of the considered algorithm.
1. Introduction.
Sequential Monte Carlo methods form an emerging, yet
already very active branch of the Monte Carlo paradigm. Their growing popularity
comes in part from the fact that they are often the only viable computing
techniques in those situations where data must be processed sequentially. Their
range of applicability is consequently very wide, and includes nonexclusively
signal processing, ﬁnancial modeling, speech recognition, computer vision, neural
networks, molecular biology and genetics, target tracking and geophysics, among
others. A very good introduction to the ﬁeld has been written by Künsch ,
while the edited volume of Doucet, de Freitas and Gordon provides an
interesting coverage of recent developments in theory and applications.
Speciﬁcally, sequential Monte Carlo methods (alternatively termed “particle
ﬁlters” or “recursive Monte Carlo ﬁlters”) are iterative algorithms that produce
and update recursively a set of weighted simulations (the “particles”) in order
to provide a Monte Carlo approximation of an evolving distribution of interest
πt(dθt), t being an integer index. In a sequential Bayesian framework, πt(dθt)
will usually represent the posterior distribution of parameter θt given the t ﬁrst
observations. The term “parameter” must be understood here in a broad sense, in
Received November 2002; revised March 2004.
AMS 2000 subject classiﬁcations. Primary 65C05, 62F15, 60F05; secondary 82C80, 62L10.
Key words and phrases. Markov chain Monte Carlo, particle ﬁlter, recursive Monte Carlo ﬁlter,
resample-move algorithms, residual resampling, state-space model.
that θt may include any unknown quantity which may be inferred from the t ﬁrst
observations, and is not necessarily of constant dimension. We denote by t the
support of πt(dθt).
The study of the asymptotic properties of sequential Monte Carlo methods is
admittedly a difﬁcult problem, and some methodological papers [Liu and Chen
 , e.g.] simply state some form of the law of large numbers for the most
elaborate algorithms, that is, the Monte Carlo estimates are shown to converge
almost surely to the quantity of interest as H, the number of particles, tends toward
inﬁnity. More reﬁned convergence results have been obtained, such as the central
limit theorem of Del Moral and Guionnet , later completed by Del Moral
and Miclo , or upper bounds for the Monte Carlo error expressed in various
norms [Crisan and Lyons , Crisan, Gaines and Lyons , Crisan
and Doucet , Del Moral and Guionnet , Künsch and Le Gland
and Oudjane ]. Unfortunately, it has been, in general, at the expense of
generality [with the exception of Crisan and Doucet ], whether in terms of
computational implementation (only basic algorithms are considered, which may
not be optimal) or of applicability (the sequence πt has to be generated from some
speciﬁc dynamical model that fulﬁlls various conditions).
In this paper we derive a central limit theorem that applies to most of the
sequential Monte Carlo techniques developed recently in the methodological
literature, including the resample-move algorithm of Gilks and Berzuini ,
the auxiliary particle ﬁlter of Pitt and Shephard and the stochastic remainder
resampling scheme [Baker ], also known as the residual resampling
scheme [Liu and Chen ]. No assumption is made on the model that generates
the sequence of distributions of interest (πt), so that our theorem equally applies to
those recent algorithms [Chopin , Del Moral and Doucet and Cappé,
Guillin, Marin and Robert ] that have been developed for contexts that
widely differ from the standard application of sequential Monte Carlo methods,
namely, the sequential analysis of state space models.
The appeal of a central limit theorem is that it provides an (asymptotically) exact
measure of the Monte Carlo error, through the asymptotic variance. This allows for
a rigorous comparison of the relative efﬁciency of given algorithms. In this way, we
show in this paper, again by comparing the appropriate asymptotic variances, that
the residual resampling scheme always outperforms the multinomial resampling
scheme, and that the Rao–Blackwell variance reduction technique of Doucet,
Godsill and Andrieu is, indeed, effective.
The most promising application of our central limit theorem is the possibility to
assess the stability of a given particle ﬁlter (in terms of precision of the computed
estimates) through the time behavior of the corresponding asymptotic variances.
This is a critical issue since it is well known that sequential Monte Carlo methods
tend to degenerate in a number of cases, sometimes at a very fast rate. We consider
in this paper some typical Bayesian problems, such as the sequential analysis of
state-space models. We will show that under some conditions stability can be
CENTRAL LIMIT THEOREM FOR SEQUENTIAL MONTE CARLO METHODS 2387
achieved at least for “ﬁltering” the states, that is, for approximating the marginal
posterior density πt(xt), where xt stands for the current state at iteration t.
The paper is organized as follows. Section 2 proposes a generic description
of particle ﬁlters, establishes a central limit theorem for computed estimates in
a general framework and draws some conclusions from this result. Section 3
discusses the stability of particle ﬁlters through the time behavior of the asymptotic
variances provided by the central limit theorem. Proofs of theorems are put in the
2. Central limit theorem for particle ﬁlters.
2.1. General formulation of particle ﬁlters.
In full generality, a particle
system is a triangular array of random variables in  × R+,
θ(j,H),w(j,H)
where  is some space of interest. The variables θ(j,H) are usually called
“particles,” and their contribution to the sample may vary according to their
weights w(j,H). We will say that this particle system targets a given distribution π
deﬁned on  if and only if
j=1 w(j,H)ϕ(θ(j,H))
j=1 w(j,H)
holds almost surely as H →+∞for any measurable function ϕ such that the
expectation above exists. A ﬁrst example of a particle system is a denumerable set
of independent draws from π, with unit weights, which obviously targets π. In this
simple case, particles and weights do not depend on H, and the particle system is
a sequence rather than a triangular array. This is not the case in general, however,
and, while cumbersome, the dependence in H will be maintained in notation to
allow for a rigorous mathematical treatment.
Now assume a sequence (πt)t∈N of distributions deﬁned on a sequence of
probabilized spaces (t). In most, if not all, applications, t will be a power
of the real line or some subset of it, and, henceforth, πt(·) will also denote the
density of πt with respect to an appropriate version of the Lebesgue measure.
A sequential Monte Carlo algorithm (or particle ﬁlter) is a method for producing
a particle system whose target evolves in time: at iteration t of the algorithm, the
particle system targets πt, and therefore allows for Monte Carlo approximations
of the distribution of (current) interest πt. Clearly, particle ﬁlters do not operate in
practice on inﬁnite triangular arrays but rather manipulate particle vectors of ﬁxed
size H. One must keep in mind, however, that the justiﬁcation of such methods is
essentially asymptotic.
The structure of a particle ﬁlter can be decomposed into three basic iterative
operations, that will be referred to hereafter as mutation, correction and selection
steps. At the beginning of iteration t, consider a particle system ( ˆθ(j,H)
t−1 ,1)j≤H,
that is, with unit weights, which targets πt−1. The mutation step consists in
producing new particles drawn from
where kt is a transition kernel which maps t−1 into P (t), the set of probability
measures on t. The “mutated” particles (with unit weights) target the new
distribution ˜πt(·) =
 πt−1(θt−1)kt(θt−1,·)dθt−1. This distribution ˜πt is usually
not relevant to the considered application, but rather serves as an intermediary
stage for practical reasons. To shift the target to the distribution of interest πt,
particles are assigned weights
with υt(·) = πt(·)/ ˜πt(·).
This is the correction step. The particle system (θ(j,H)
)j≤H targets πt.
The function υt is referred to as the weight function. Note that the normalizing
constants of the densities πt and ˜πt are intractable in most applications. This is why
weights are deﬁned up to a multiplicative constant, which has no bearing anyway
on the estimates produced by the algorithm, since they are weighted averages.
Finally, the selection step consists in replacing the current vector of particles by
a new, uniformly weighted vector ( ˆθ(j,H)
,1)j≤H , which contains a number n(j,H)
of replicates of particle θ(j,H)
, n(j,H) ≥0. The n(j,H)’s are random variables such
j n(j,H) = H and E(n(j,H)) = Hρj, where the normalized weights are given
ρj = w(j,H)
and where dependencies in H and t are omitted for convenience. In this way, particles whose weights are too small are discarded, while particles with important
weights serve as multiple starting points for the next mutation step. There are various ways of generating the n(j,H)’s. Multinomial resampling [Gordon, Salmond
and Smith ] amounts to drawing independently the H new particles from
the multinomial distribution which produces θ(j,H)
with probability ρj. Residual
resampling [originally termed “stochastic remainder sampling” in the genetic algorithm literature, Baker , then rediscovered by Liu and Chen ]
consists in reproducing ⌊Hρj⌋times each particle θ(j,H)
, where ⌊·⌋stands for the
integer part. The particle vector is completed by H r = H −
j⌊Hρj⌋independent
draws from the multinomial distribution which produces θ(j,H)
with probability
(Hρj −⌊Hρj⌋)/H r. Systematic resampling [another method initially proposed
in the genetic algorithm ﬁeld, Whitley , then rediscovered by Carpenter,
Clifford and Fearnhead ; see also Crisan and Lyons for a slightly
CENTRAL LIMIT THEOREM FOR SEQUENTIAL MONTE CARLO METHODS 2389
different algorithm] is another interesting selection scheme, which is such that the
number of replicates n(j,H) is ensured to differ from Hρj by at most one. We
failed, however, to extend our results to this third selection scheme.
The structure of a particle ﬁlter can be summarized as follows:
1. Mutation: Draw for j = 1,...,H,
where kt :t−1 →P (t) is a given probability kernel.
2. Correction: Assign weights to particles so that, for j = 1,...,H,
where ˜πt(·) =
 πt−1(θt−1)kt(θt−1,·)dθt−1.
3. Selection: Resample, according to a given selection scheme,
The ﬁrst mutation step, t = 0, is assumed to draw independent and identically
distributed particles from some instrumental distribution ˜π0.
It is shown without difﬁculty that the particle system produced by this generic
algorithm does iteratively target the distributions of interest, that is, the following
convergences hold almost surely:
 →E ˜πt(ϕ),
j=1 w(j,H)
j=1 w(j,H)
 →Eπt(ϕ),
as H →+∞, provided these expectations exist. These convergences will be
referred to as the law of large numbers for particle ﬁlters.
2.2. Some examples of particle ﬁlters.
The general formulation given in the
previous section encompasses most of the sequential Monte Carlo algorithms described in the literature. By way of illustration, assume ﬁrst that the distributions πt
are deﬁned on a common space, t = . In a Bayesian framework, πt will usually be the posterior density of θ, given the t ﬁrst observations, πt(θ) = π(θ|y1: t),
where y1: t denotes the sequence of observations y1,...,yt. If particles are not
mutated, kt being the “identity kernel” kt(θ,·) = δθ, we have ˜πt = πt−1 for t > 0,
and our generic particle ﬁlter becomes one of the variations of the sequential importance resampling algorithm [Rubin , Gordon, Salmond and Smith 
and Liu and Chen ]. The weight function simpliﬁes to
υt(θ) = π(θ|y1: t)/π(θ|y1: t−1) ∝p(yt|y1: t−1,θ)
in a Bayesian model, where p(yt|y1: t−1,θ) is the conditional likelihood of yt,
given the parameter θ and previous observations.
Gilks and Berzuini propose a variant of this algorithm, namely, the
resample-move algorithm, in which particles are mutated according to an MCMC
[Markov chain Monte Carlo; see, e.g., Robert and Casella ] kernel kt, which
admits πt−1 as an invariant density. In that case, we still have ˜πt = πt−1, and the
expression for the weight function υt is unchanged. The motivation of this strategy
is to add new particle values along iterations so as to limit the depletion of the
particle system.
Now consider the case where πt is deﬁned on a space of increasing dimension
of the form t = Xt. A typical application is the sequential inference of a
dynamical model which involves a latent process (xt), and πt stands then for
density π(x1: t|y1: t). Assume kt can be decomposed as
1: t−1,dx1: t) = κt(x∗
1: t−1,dx1: t−1)qt(xt|x1: t−1)dxt,
where κt :Xt−1 →P (Xt−1) is a transition kernel, and qt(·|·) is some conditional
probability density. If κt admits πt−1 as an invariant density, the weight function
is given by
υt(x1: t) =
πt−1(x1: t−1)qt(xt|x1: t−1).
Again, the case where κt is the identity kernel corresponds to some version of the
sequential importance resampling algorithm, while setting κt to a given MCMC
transition kernel with invariant density πt−1 leads to the resample-move algorithm
of Gilks and Berzuini . The standard choice for qt(·|·) is the conditional
prior density of xt, given x1: t−1, as suggested originally by Gordon, Salmond
and Smith , but this is not always optimal, as pointed out by Pitt and
Shephard and Doucet, Godsill and Andrieu . In fact, it is generally
more efﬁcient to build some conditional density qt which takes into account the
information carried by yt in some way, in order to simulate more values compatible
with the observations.
These two previous cases can be combined into one, by considering a dynamical
model which features at the same time a ﬁxed parameter θ and a sequence of latent
variables (xt), so that t =  × Xt, and πt stands for the joint posterior density
π(θ,x1: t|y1: t).
CENTRAL LIMIT THEOREM FOR SEQUENTIAL MONTE CARLO METHODS 2391
2.3. Central limit theorem.
The following quantities will play the role of
asymptotic variances in our central limit theorem. Let, for any measurable
ϕ :0 →Rd, V0(ϕ) = Var ˜π0(ϕ), and by induction, for any measurable ϕ :
Vt(ϕ) = Vt−1
Vt(ϕ) = Vt
Vt(ϕ) = Vt(ϕ) + Varπt(ϕ),
The notation Ekt (ϕ) and Varkt (ϕ) is shorthand for the functions µ(θt−1) =
Ekt(θt−1,·){ϕ(·)} and (θt−1) = Varkt(θt−1,·){ϕ(·)}, respectively. Note that these
equations do not necessarily produce ﬁnite variances for any ϕ. We now specify the
classes of functions for which the central limit theorem enunciated below will hold,
and, in particular, for which these asymptotic variances exist. Denoting by ∥· ∥the
Euclidean norm in Rd, we deﬁne recursively
to be the set of measurable
functions ϕ :t →Rd such that for some δ > 0,
E ˜πt∥υt · ϕ∥2+δ < +∞,
and that the function θt−1
→Ekt(θt−1,·){υt(·)ϕ(·)} is in
t−1. The initial set
contains all the measurable functions whose moments of order two with respect to
˜π0 are ﬁnite.
THEOREM 1.
If the selection step consists of multinomial resampling, and
provided that the unit function θt
→1 belongs to
for every t, then for
, Eπt(ϕ), Vt(ϕ) and Vt(ϕ) are ﬁnite quantities, and the following
convergences in distribution hold as H →+∞:
j=1 w(j,H)
j=1 w(j,H)
→N {0,Vt(ϕ)},
 ˆθ (j,H)
→N {0, Vt(ϕ)}.
A proof is given in the Appendix. In the course of the proof an additional
central limit theorem is established for the unweighted particle system (θ(j,H)
produced by the mutation step, which targets ˜πt. This result is not given here,
however, for it holds for a slightly different class of functions, and is of less
practical interest. The assumption that the function θt
→1 belongs to
deserves further comment. Qualitatively, it implies that the weight function υt has
ﬁnite moment of order 2 + δ with respect to ˜πt, for some δ > 0, and, therefore,
restricts somehow the dispersion of the particle weights. It also implies that
contains all bounded functions ϕ. In practice this assumption will be fulﬁlled, for
instance, whenever each weight function υt is bounded from above, which occurs
in many practical settings.
A central limit theorem also holds when the selection step follows the residual
sampling scheme of Liu and Chen , but this imposes some change in the
expression for the asymptotic variances. The new expression for Vt(ϕ) is
Vt(ϕ) = Vt(ϕ) + Rt(ϕ),
Rt(ϕ) = E ˜πt{r(υt)ϕϕ′} −
E ˜πt{r(υt)}
E ˜πt{r(υt)ϕ}
E ˜πt{r(υt)ϕ}
and r(x) is x minus its integer part.
THEOREM 2.
The results of Theorem 1 still hold when the selection steps
consists of residual resampling, except that the asymptotic variances are now
deﬁned by equations (3), (4) and (7).
The proofs of Theorems 1 and 2 (given in the Appendix) rely on an induction
argument: conditional on past iterations, each step generates independent (but not
identically distributed) particles, which follow some (conditional) central limit
theorem. In contrast, the systematic resampling scheme is such that, given the
previous particles, the new particle system is entirely determined by a single draw
from a uniform distribution; see Whitley . This is why extending our results
to this third selection scheme seems not straightforward, and possibly requires an
entirely different approach.
The appeal of the recursive formulae (3)–(5) and (7) is that they put forward
the impact of each new step on the asymptotic variance, particularly the additive
effect of the selection and mutation steps. In the multinomial case, an alternative
expression for the asymptotic variance is
where Et is the functional operator which associates to ϕ the function
Et(ϕ):θt−1
→Ekt(θt−1,·){υt(·)ϕ(·)},
and Ek+1: t(ϕ) = Ek+1 ◦··· ◦Et(ϕ) for k + 1 ≤t, Et+1: t(ϕ) = ϕ. This closed
form expression is more convenient when studying the stability of the asymptotic
variance over time, as we will illustrate in the next section. A similar formula for
the residual case can be obtained indirectly by deriving the difference between the
multinomial and the residual cases, that is, for t > 0,
t (ϕ) −Vt(ϕ) =
Rk{Ek+1: t(ϕ)} −Varπk{Ek+1: t(ϕ)}
CENTRAL LIMIT THEOREM FOR SEQUENTIAL MONTE CARLO METHODS 2393
where Vt(ϕ), V r
t (ϕ) are deﬁned through the recursions (3)–(5) and (3), (4) and (7),
respectively. In the following, we will similarly distinguish the residual case
through an r-sufﬁx in notation.
2.4. First conclusions.
A ﬁrst application of this central limit theorem is to
provide a rigorous justiﬁcation for some heuristic principles that have been stated
in the literature, see, for instance, Liu and Chen . Inequalities in this section
refer to the canonical order for symmetric matrices, that is to say A > B (resp.
A ≥B) if and only if A −B is positive deﬁnite (resp. positive semideﬁnite).
First, it is preferable to compute any estimate before the selection step, since
the immediate effect of the latter is a net increase in asymptotic variance: Vt(ϕ) >
Vt(ϕ) for any nonconstant function ϕ. In this respect one may wonder why
selection steps should be performed. We will see that the immediate degradation
of the particle system is often largely compensated for by gains in precision in the
future iterations.
Second, residual sampling always outperforms multinomial resampling. Let
ϕ :t →Rd and ¯ϕ = ϕ −Eπt(ϕ). Then
Rt(ϕ) = Rt( ¯ϕ) ≤E ˜πt{r(υt) ¯ϕ ¯ϕ′} ≤Varπt(ϕ),
since r(x) ≤x. It follows from this inequality and (11) that V r
t (ϕ) ≤Vt(ϕ).
Actually, a substantial gain should be expected when using the residual scheme
since the inequality above is clearly not sharp.
Our central limit theorem also provides a formal justiﬁcation for resorting to
“marginalized” particle ﬁlters, as explained in the following section.
2.5. Marginalized particle ﬁlters.
In some speciﬁc cases it is possible to
decompose the density πt(θt) into πm
t (λt|ξt), with θt = (ξt,λt) lying in
t × t, in such a way that it is possible to implement a particle ﬁlter
that targets the marginal densities πm
rather than the πt’s. When this occurs,
this second algorithm usually produces more precise estimators (in a sense that
we explain below) in the ξt-dimension. The idea of resorting to “marginalized”
particle ﬁlters has been formalized by Doucet, Godsill and Andrieu , and
implemented in various settings by Chen and Liu , Chopin and
Andrieu and Doucet , among others.
Doucet, Godsill and Andrieu’s justiﬁcation for resorting to “marginalized” particle ﬁlters is that they yield importance weights with a smaller variance than their “unmarginalized” counterpart, which suggests that the produced
estimates are also less variable. This is proven by a Rao–Blackwell decomposition, and, consequently, “marginalized” particle ﬁlters are sometimes referred to
as “Rao–Blackwellized” particle ﬁlters. We now extend the argument of these authors by proving that the asymptotic variance of any estimator is, indeed, smaller
in the “marginalized” case. Assume decompositions of πt and ˜πt of the form
πt(θt) = πm
t (λt|ξt),
˜πt(θt) = ˜πm
t (ξt) ˜πc
t (λt|ξt),
where (ξt,λt) identiﬁes to θt, and πm
t , are, respectively, marginal
and conditional densities of ξt and λt. Consider two particle ﬁlters, tracking,
respectively, (πt) and (πm
t ). It is assumed that both ﬁlters implement the same
selection scheme (whether multinomial or residual), and that their mutation steps
consist in drawing, respectively, from kernels kt and km
t , which are such that the
following probability measures coincide on t =
t−1(λt−1|ξt−1)kt{(ξt−1,λt−1),(dξt,dλt)}dλt−1
t (ξt−1,dξt) ˜πc
t (λt|ξt)dλt,
for almost every ξt−1 in
t−1. Note that in full generality it is not always possible
to build a kernel km
from a given kt which satisﬁes this relation. As illustrated
by the aforementioned references, however, it is feasible in some cases of interest.
This equality implies, in particular, that
t−1(ξt−1)km
t (ξt−1,·)dξt−1 = ˜πm
Asymptotic variances and other quantities are distinguished similarly through the
m-sufﬁx for the marginal case, that is, Vt(ϕ) and V m
t (ϕ), and so on.
THEOREM 3.
For any ϕ :
t →Rd such that ϕ ∈
, we have V m
Vt(ϕ) and V m,r
t (ϕ). These inequalities are attained for a nonconstant ϕ
if and only if πc
t (·|ξt) = ˜πc
t (·|ξt) for almost every ξt ∈
t, for any t ≥0.
As suggested by the condition for equality above or more clearly exhibited in the
proof in the Appendix, marginalizing allows for canceling the weight dispersion
due to the discrepancy between conditional densities ˜πc
t , while the part due
to the discrepancy between marginal densities πm
t remains identical.
Beyond the small number of cases where this marginalization technique can be
effectively carried out, this result has also strong qualitative implications. In the
following sections we will study the behavior of the time sequence Vt(ϕ) in order
to measure whether and at which rate a given particle ﬁlter “diverges.” In this
respect, we will be able in some cases to build a marginalized particle ﬁlter whose
rate of divergence is theoretically known, thus providing a lower bound for the
actual rate of divergence of the considered particle ﬁlter.
3. Stability of particle ﬁlters.
3.1. Sequential importance sampling.
The sequential importance sampling
algorithm is a particle ﬁlter that alternates mutation and correction steps, but does
not perform any selection step. Weights are consequently not initialized to one at
each iteration, and are rather updated through
CENTRAL LIMIT THEOREM FOR SEQUENTIAL MONTE CARLO METHODS 2395
We suppress any notational dependence on H since it is meaningless in such a
case. Due to its speciﬁc nature, this algorithm needs to be treated separately. Since
particles are not resampled, they remain independent through iterations. It follows
via the standard central limit theorem that
→N {0,V sis
where the corresponding asymptotic variance is
(ϕ) = E ˜πt
and ˜πt denotes this time the generating distribution of particles θ(j)
obtained by
the recursion of mutation kernels kt(·,·), that is,
˜πt−1(θt−1)kt(θt−1,·)dθt−1,
the distribution ˜π0 being arbitrary. Sequential importance sampling is rarely an
efﬁcient algorithm, but the value of V sis
(ϕ) can serve as a benchmark in some
occasions, as we will see in the following.
3.2. Sequential importance sampling and resampling in the ﬁxed parameter
In the ﬁxed parameter case, that is, t =  and πt(θ) = π(θ|y1: t), πt is
expected to become more and more informative on θ, and to eventually converge
to a Dirac mass at some point θ0. Sequential importance sampling and resampling
algorithms typically diverge in such a situation, since they generate once and for all
the set of particle values from ˜π0, a majority of which are presumably far from θ0.
The following result quantiﬁes this degeneracy effect.
THEOREM 4.
Let ϕ : →Rd, ϕ ∈
. Then under regularity conditions
given in the Appendix, there exist positive constants c1, c2 and c3 such that
(ϕ)∥≍c1tp/2−1,
t (ϕ)∥≍c2tp/2,
∥Vt(ϕ)∥≍c3tp/2,
as t goes toward inﬁnity, where ∥· ∥denotes the Euclidean norm, p is the
dimension of  and V r
t (ϕ), Vt(ϕ) refer here to the sequential importance
resampling case, that is, kt(θ,·) = δθ.
The conditions mentioned above amount to assuming that πt is the posterior
density of a model regular enough to ensure the existence and asymptotic
normality of the maximum likelihood estimator. Under such conditions, πt can be
approximated at ﬁrst order as a Gaussian distribution centered at θ0 with variance
I (θ0)−1/t, where I (θ0) is the Fisher information matrix evaluated at θ0. The
results above are then derived through the Laplace approximation of integrals;
see the Appendix. At ﬁrst glance, it seems paradoxical that V sis
(ϕ) converges to
zero when p = 1. Note, however, that the ratio Vt(ϕ)/Varπt(ϕ), which measures
the precision of the algorithm relative to the variation of the considered function,
is likely to diverge even when p = 1, since typically Varπt(ϕ) ≍I (θ0)−1/t as
That the sequential importance resampling algorithm diverges more quickly
than the sequential importance sampling algorithm in this context is unsurprising:
when particles are not mutated, the only effect of a selection step is to deplete the
particle system. In this respect, we have for any nonconstant function ϕ,
t (ϕ) ≤Vt(ϕ).
The proof of this inequality is straightforward.
Due to its facility of implementation and the results above, it may be
recommended to use the sequential importance sampling algorithm for studying
short series of observations, provided that the dimension of  is low. But,
in general, one should rather implement a more elaborate particle ﬁlter which
includes mutation steps in order to counter the particle depletion. A further
implication of these results is the following. Consider a dynamical model
which involves a ﬁxed parameter θ, and assume that the marginal posterior
distributions π(θ|y1: t), obtained by marginalizing out latent variables x1: t, satisfy
the regularity conditions of Theorem 4. Then, following the argument developed
in Section 2.5, we get that the rate of divergence of the sequential importance
resampling algorithm for this kind of model is at least of order O(tp/2), where
p is the dimension of this ﬁxed parameter.
3.3. Sequential importance sampling and resampling for Bayesian ﬁltering
and smoothing.
For simplicity we assume that πt(x1: t) = π(x1: t|y1: t) is the
posterior density of a state space model with latent Markov process (xt), xt ∈X,
and observed process (yt), yt ∈Y, which satisﬁes the equations
yt|xt ∼f (yt|xt)dyt,
xt|xt−1 ∼g(xt|xt−1)dxt.
We distinguish two types of functions: those which are deﬁned on common
dimensions of the spaces t = Xt, say, ϕ :x1: t →ϕ(xk), for t ≥k, and those
which are evaluated on the “last” dimension of t, that is, ϕ :x1: t →ϕ(xt).
Evaluating these two types of functions amounts to, respectively, “smoothing” or
“ﬁltering” the states.
The sequential importance sampling algorithm is usually very inefﬁcient in
such a context, whether for smoothing or ﬁltering the states. We illustrate this
phenomenon by a simple example. Assume the tth mutation step consists of
drawing xt from the prior conditional density g(xt|xt−1), which is usually easy
CENTRAL LIMIT THEOREM FOR SEQUENTIAL MONTE CARLO METHODS 2397
to implement. Consider two evolving particles θ(j)
1: t with weights w(j)
j = 1,2. We have
log f (yk|x(1)
f (yk|x(2)
Assuming that the joint process (yt,x(1)
) is stationary, the sum above
typically satisﬁes some central limit theorem of the form
log f (yk|x(1)
f (yk|x(2)
→N (0,σ 2),
where the limiting distribution is centered for symmetry reasons. Note that
this convergence is with respect to the joint probability space of the simulated
processes x(j)
, j = 1,2 and the observation process (yt), while all our previous
results were for a given sequence of observations. In this way, (13) yields that
the ratio of weights of the two particles either converges or diverges exponentially
fast. More generally, when H particles are generated initially, very few of them
will have a prominent weight after some iterations, thus leading to very unreliable
estimates, whether for smoothing or ﬁltering the states. The algorithm suffers from
the curse of dimensionality, in that its degeneracy grows exponentially with the
dimension of the space of interest t.
We now turn to the sequential importance resampling algorithm, and remark
ﬁrst that, for ϕ :x1: t →ϕ(x1) and t > 0,
Vt(ϕ) ≥V r
t (ϕ) > V sis
provided ϕ is not constant. The proof of this inequality is straightforward. The
sequential importance resampling algorithm is even more inefﬁcient than the
sequential importance sampling algorithm in smoothing the ﬁrst state x1, because
the successive selection steps only worsen the deterioration of the particle system
in the x1 dimension. This is consistent with our claim in Section 2.4 that a selection
step always degrades the inference on past and current states, but may possibly
improve the inference on future states. In this respect, the algorithm is expected to
show more capability in ﬁltering the states, and we now turn to the study of the
ﬁltering stability.
The functional operator Et which appears in the expression for Vt(ϕ), see (9),
summarizes two antagonistic effects: on one hand, the weight distortion due to
the correction step, and, on the other hand, the rejuvenation of particles due to
the application of the kernel kt. Stability will be achieved provided that these two
effects compensate in some way.
For simplicity, we assume that the state space X is included in the real line and
that the studied ﬁltering function ϕ :x1: t →ϕ(xt) is real-valued. Recall that for
the sequential importance resampling algorithm, kt is given by
1: t−1,dx1: t) = δx∗
1: t−1qt(xt|x∗
1: t−1)dxt,
for some given conditional probability density qt(·|·). We assume that qt only
depends on the previous state xt−1, and, therefore, deﬁnes a Markov transition.
The ability of qt to “forget the past” is usually expressed through its contraction
coefﬁcient [see Dobrushin ]
∥qt(·|x′) −qt(·|x′′)∥1,
where ∥· ∥1 stands for the L1-norm. Note ρt ≤1, and if ρt < 1, qt is said to be
strictly contractive. Deﬁne the variation of a given function ϕ by
|ϕ(x) −ϕ(x′)|.
Then the coefﬁcient ρt measures the extent to which the application qt “contracts”
the variation of the considered function, that is, for any x′,x′′ ∈X,
qt(x|x′)ϕ(x)dx −
qt(x|x′′)ϕ(x)dx
 ≤ρtϕ.
Furthermore, it is known [Dobrushin ] that if qt is such that, for all
x,x′,x′′ ∈X,
qt(x|x′′) ≤C,
then its contraction coefﬁcient satisﬁes ρt ≤1 −C−1. We therefore make such
assumptions in order to prove the stability of the sequential importance resampling
algorithm.
THEOREM 5.
Assume that ϕ < +∞and there exist constants C, f and ¯f
such that, for any t ≥0, x,x′,x′′ ∈X, y ∈Y,
g(x|x′′) ≤C,
qt(x|x′′) ≤C,
0 < f ≤f (y|x) ≤¯f .
Then Vt(ϕ) is bounded from above in t , Le Gland and Oudjane and most especially, Künsch
 ], except that these authors rather consider the stability of some
distance (such as the total variation norm of the difference) between the “true”
ﬁltering density πt(xt) and the empirical density computed from the particle
system. In fact, Del Moral and Miclo [ , page 36] proved that the actual
variance of the Monte Carlo error is bounded from above over time under
similar conditions. Unfortunately, all these results, including ours, require strong
assumptions, such as (15), that are unrealistic when X is not compact. Further
research will hopefully provide weaker assumptions, but this may prove an
especially arduous problem.
CENTRAL LIMIT THEOREM FOR SEQUENTIAL MONTE CARLO METHODS 2399
3.4. Resample-move algorithms, variance estimation.
Following Gilks and
Berzuini , we term “resample-move algorithm” any particle ﬁlter algorithm
which includes an MCMC step in order to reduce degeneracy, as described in
Section 2.2. It seems difﬁcult to make general statements about such algorithms
and we will rather make informal comments.
The ﬁxed parameter case is especially well behaved. Basic particle ﬁlters
diverge only at a polynomial rate, as seen in Section 3.2, in contrast with the
exponential rate for state-space models. Adding (well-calibrated) MCMC mutation
steps should, consequently, lead to stable algorithms in many cases of interest. In
fact, it is doubtful that a mutation step must be performed at each iteration to
achieve stability. Chopin argues and provides some experimental evidence
that it may be sufﬁcient to perform move steps at a logarithmic rate, that is, the nth
move step should occur at iteration tn ∼exp(αn).
Situations where a latent process intervenes seem less promising. Smoothing
the states is especially a difﬁcult problem, and we do not think that there is
any solution for circumventing the curse of dimensionality that we have pointed
out in the previous section. Even if mutation steps are performed at every
iteration, the MCMC transition kernels should themselves suffer from the curse of
dimensionality, in that their ability to rejuvenate particles of dimension t is likely
to decrease with t.
Resample-move algorithms remain an interesting alternative when the considered dynamical model includes a ﬁxed parameter θ. MCMC mutation steps should
avoid depletion in simulated values of θ, and make it possible at least to ﬁlter the
states and estimate the parameter under reasonable periods of time. Unfortunately,
the corresponding MCMC transition kernels will often depend on the whole past
trajectory, so that long term stability remains uncertain.
In such complicated setups it is necessary to monitor at least numerically the
degeneracy of the considered particle ﬁlter algorithm. We propose the following
method. Run k, say k = 10, parallel independent particle ﬁlters of size H. For any
quantity to be estimated, compute the average of the k corresponding estimates.
This new estimator is clearly consistent and asymptotically normal. Moreover, the
computational cost of this strategy is identical to that of a single particle ﬁlter of
size kH, while the obtained precision will be also of the same order of magnitude
in both cases, that is to say {Vt(ϕ)/(kH)}1/2. This method does not, therefore,
incur an unnecessary computational load, and allows for assessing the stability of
the algorithm through the evolution of the empirical variance of these k estimates.
A.1. Proofs of Theorems 1 and 2.
We start by outlining some basic
properties of the sets
with respect to linearity. The set
is stable through
linear transformations, that is, ϕ ∈
if M is a d′ × d matrix
of real numbers. In particular, if the vector function ϕ = (ϕ1,...,ϕd)′ belongs to
, then each of its coordinates belongs to
t . The converse proposition is also
true. Finally, we have Vt(Mϕ + λ) = MVt(ϕ)M′ for any constant λ ∈Rd, and this
relation also holds for the operators Vt and Vt. Proving these statements is not
difﬁcult and is left to the reader.
The proof works by induction with Lemmas A.1–A.3 for Theorem 1, and
Lemmas A.1, A.2 and A.4 for Theorem 2. The inductive hypothesis is the
following. For a given t > 0, it is assumed that for all ϕ ∈
 ˆθ (j,H)
 −Eπt−1(ϕ)
→N {0, Vt−1(ϕ)}.
LEMMA A.1 (Mutation).
Under the inductive hypothesis, we have
 −E ˜πt(ψ)
→N {0, Vt(ψ)}
for any measurable ψ :t →Rd such that the function µ:θt−1
→Ekt(θt−1,·){ψ(·)−
E ˜πt(ψ)} belongs to
t−1 and there exists δ > 0 such that E ˜πt∥ψ∥2+δ < +∞.
We assume that ψ is real-valued (d = 1). The generalization to d > 1
follows directly from the Cramér–Wold theorem and the linearity properties stated
Let ¯ψ = ψ −E ˜πt(ψ), µ(θt−1) = Ekt(θt−1,·){ ¯ψ(·)}, σ 2(θt−1) = Varkt(θt−1,·){ ¯ψ(·)}
0 = Eπt−1(σ 2). We have Eπt−1(µ) = 0, and by Jensen’s inequality,
Varkt(θt−1,·){ψ(·)}
Ekt(θt−1,·){ψ(·)2}
E ˜πt|ψ|(2+δ)
2/(2+δ) < +∞,
which makes it possible to apply the law of large numbers for particle ﬁlters to σ 2,
σ 2θ(j,H)
almost surely.
ν(θt−1) = Ekt(θt−1,·){| ¯ψ(·) −µ(θt−1)|2+δ}
≤21+δ Ekt−1(θt−1,·)| ¯ψ(·)|2+δ +
Ekt−1(θt−1,·) ¯ψ(·)
≤22+δ Ekt−1(θt−1,·)| ¯ψ(·)|2+δ
where (19) comes from the Cr inequality and (20) from Jensen’s inequality, we
deduce that
Eπt−1(ν) ≤22+δE ˜πt|ψ|2+δ < +∞.
CENTRAL LIMIT THEOREM FOR SEQUENTIAL MONTE CARLO METHODS 2401
This inequality ensures that the expectations deﬁning ν in (18) (and, similarly,
those deﬁning µ and σ 2) are ﬁnite for almost every θt−1. It follows that
 →Eπt−1(ν)
almost surely,
and combining this result with (17), we obtain the almost sure convergence of
j=1 ν(θ(j,H)
j=1 σ 2(θ(j,H)
t−1 )}(2+δ)/2
j=1 ν(θ(j,H)
j=1 σ 2(θ(j,H)
t−1 )}(2+δ)/2 →0.
Let TH = H −1/2 H
j=1 ¯ψ(θ (j,H)
), St−1 denote the sigma-ﬁeld generated by the
random variables forming the triangular array ( ˆθ(j,H)
t−1 )j≤H, that is, the particle
system at time t −1, and µH = E(TH |St−1). Conditional on St−1, the ¯ψ(θ(j,H)
form a triangular array of independent variables which satisfy the Liapunov
condition, see (21), and have variances whose mean converges to σ 2
0 , see (17).
Therefore [Billingsley , page 362], the following central limit theorem for
triangular arrays of independent variables holds:
(TH −µH)|St−1
Since Eπt−1(µ) = 0 and µ ∈
t−1, we have also, by applying (16) to the
function µ,
µH = H −1/2
 ˆθ (j,H)
→N {0, Vt−1(µ)}.
The characteristic function of TH is
TH (u) = E{exp(iuTH )}
= E[exp(iuµH)E{exp(iuTH −iuµH)|St−1}],
where E{exp(iuTH −iuµH)|St−1} is the characteristic function of TH −µH
conditional on St−1, which according to (22) converges to exp(−σ 2
0 u2/2). It
follows from (23) that
exp(iuµH)E{exp(iuTH −iuµH)|St−1} D
0 u2/2 + iuZ),
where Z is a random variable distributed according to N {0, Vt−1(µ)}. The
expectation of the left-hand side term converges to the expectation of the righthand side term following the dominated convergence theorem, and this completes
the proof.
LEMMA A.2 (Correction).
, assume the inductive hypothesis
holds and the function θt
→1 belongs to
j=1 w(j,H)
j=1 w(j,H)
→N {0,Vt(ϕ)}.
Let ¯ϕ = ϕ −Eπt(ϕ). For notational convenience we assume that
d = 1, but the generalization to d ≥1 is straightforward. It is clear that the vector
function ψ = (υt · ¯ϕ,υt)′ fulﬁlls the conditions mentioned in Lemma A.1, and as
such satisﬁes
→N {0, Vt(ψ)}.
Then, resorting to the δ-method with function g(x,y) = x/y, we obtain
j=1 υt(θ(j,H)
) ¯ϕ(θ(j,H)
j=1 υt(θ(j,H)
where V = {(∂g/∂x,∂g/∂y)(0,1)}Vt(ψ){(∂g/∂x,∂g/∂y)(0,1)}′ = Vt{υt · (ϕ −
Eπtϕ)}. The left-hand side term is unchanged if we replace the υt(θ(j,H)
)’s by the
weights w(j,H)
, since they are proportional.
LEMMA A.3 (Selection, multinomial resampling).
Let Vt(ϕ) = Vt(ϕ) +
Varπt(ϕ) and assume the particle system is resampled according to the multinomial
scheme. Then, under the same conditions as in Lemma A.2,
 ˆθ (j,H)
→N {0, Vt(ϕ)}.
The proof is similar to that of Lemma A.1. Assume d = 1, denote
by St the sigma-ﬁeld generated by the random variables (θ(j,H)
and let ¯ϕ = ϕ −Eπt(ϕ), TH = H −1/2 H
j=1 ¯ϕ( ˆθ(j,H)
) and µH = E(TH |St).
Conditional on St, TH is, up to a factor H −1/2, a sum of independent draws
from the multinomial distribution which produces ¯ϕ(θ(j,H)
) with probability
j=1 w(j,H)
. Then, as in Lemma A.1, we have
(TH −µH)|St
where this time σ 2
0 = Varπt(ϕ), which is the limit as H →+∞of the variance of
the multinomial distribution mentioned above. The proof is completed along the
same lines as in Lemma A.1.
CENTRAL LIMIT THEOREM FOR SEQUENTIAL MONTE CARLO METHODS 2403
LEMMA A.4 (Selection, residual resampling).
Let Vt(ϕ) take the value given
by (7) and assume the particle system is resampled according to the residual
resampling scheme. Then, under the same conditions as in Lemma A.2,
 ˆθ (j,H)
→N {0, Vt(ϕ)}.
The proof is identical to that of Lemma A.2, except that conditional
on St, TH is H −1/2 times a constant, plus a sum of independent draws from the
multinomial distribution described in Section 2.1. This yields a different value
0 = E ˜πt{r(υt) · ϕ2} −
E ˜πt{r(υt)}
E ˜πt{r(υt) · ϕ}
In addition, we also have to make sure that the number of these independent
draws H r tends toward inﬁnity. In fact, H r/H →E ˜πt[r(νt)]. To see this, consider
H r/H −H −1
where Hρj = υt(θ(j,H)
j υt(θ(j,H)
)}, see Section 2.1, so that the
difference above should eventually be zero as H −1 
j υt(θ(j,H)
) →1. More
precisely, we have |r(x)−r(y)| ≤1, in general, and r(x)−r(y) = x −y provided
|x −y| < ε and r(x) ∈[ε,1 −ε] for any ε < 1/2. Therefore, assuming that
j υt(θ(j,H)
)}−1 ∈[1 −ε′,1 + ε′] for some ε′ > 0 and H large enough, we
get that the sum above should be zero plus something bounded from above by the
proportion of particles such that ε′υt(·) > 1/2 or r{υt(·)} /∈[ε′υt(·),1 −ε′υt(·)].
This proportion can be made as small as necessary.
A.2. Proof of Theorem 3.
t →Rd and ¯ϕ = ϕ −Eπt(ϕ) = ϕ −
t (ϕ) for a given t ≥0. To simplify notation, it is assumed that d = 1, but
the adaptation to the general case is straightforward. All quantities related to
the “marginalized” particle ﬁlter are distinguished by the m-sufﬁx. For instance,
t (ϕ) stands for the function ξt
t (ξt,·){υm
t (·)ϕ(·)}, in agreement with the
deﬁnition of Et(ϕ) in (10). In this respect, the marginal weight function υm
t (·), and if we deﬁne the “conditional” weight function υc
t (λt|ξt) =
t (λt|ξt)/ ˜πc
t (λt|ξt), we have the identity
υt(θt) = υm
t (λt|ξt).
It follows from (12) that
t−1{Et( ¯ϕ)} = Ekm
t ¯ϕE ˜πct (υc
since E ˜πct (υc
t ) = 1, and by induction, we show similarly, for k ≤t, that
k {Ek+1: t( ¯ϕ)} = Em
k+1: t( ¯ϕ).
Hence, for k ≤t,
E ˜πk[{υkEk+1: t( ¯ϕ)}2] = E ˜πm
kEk+1: t ¯ϕ}2
k+1: t( ¯ϕ)}2],
by Jensen’s inequality. From the closed form (9) of Vt(ϕ), we deduce the inequality
t (ϕ) ≤Vt(ϕ) for the case when the selection step follows the multinomial
scheme. Alternatively, if the selection step consists of residual resampling, let
ϕ = ϕ −E ˜πt{r(υt)ϕ}/E ˜πt{r(υt)}. Then
t (ϕ) = E ˜πt{r(υt)ϕ2} −E ˜πm
t )ϕ2} + {E ˜πm
E ˜πct r(υt) −r(υm
and since E ˜πct (υt) = υm
t , we have E ˜πct ⌊υt⌋≤⌊υm
t ⌋, hence E ˜πct r(υt) ≥r(υm
consequently, Rt(ϕ) ≥Rm
t (ϕ) for any ϕ. It is then easy to show by induction that
the desired inequality is also veriﬁed in the residual case.
A.3. Regularity conditions and proof of Theorem 4.
Let π0(θ) denote the
prior density and p(y1: t|θ) the likelihood of the t ﬁrst observations, so that through
Bayes formula,
πt(θ) = π(θ|y1: t) ∝π0(θ)p(y1: t|θ).
Let lt(θ) = logp(y1: t|θ). The following statements are assumed to hold almost
1. The maximum ˆθt of lt(θ) exists and converges as t →+∞to θ0 such that
π0(θ0) > 0 and ˜π0(θ0) > 0.
2. The matrix
is positive deﬁnite and converges to I (θ0), the Fisher information matrix at θ0.
3. There exists  > 0 such that
{lt(θ) −lt( ˆθt)}
4. The functions π0(θ) and lt(θ) are six-times continuously differentiable, the
partial derivatives of order six of lt(θ)/t are bounded on any compact set
′ ⊂, and the bound does not depend on t and the observations.
CENTRAL LIMIT THEOREM FOR SEQUENTIAL MONTE CARLO METHODS 2405
5. ϕ : →Rd is six-times continuously differentiable, ϕ′(θ0) ̸= 0.
For convenience, we start with the one-dimensional case (p = 1). The Laplace
approximation of an integral [see, e.g., Tierney, Kass and Kadane ] is
ψ(θ)exp{−th(θ)}dθ
= (2π/t)1/2σ exp{−t ˆh}
σ 2 ˆψ′′ −σ 4 ˆψ′ ˆh′′′ + 5
12σ 6 ˆψ ˆh′′′ −1
4σ 4 ˆψ ˆhiv
t−1 + O(t−2)
where hats on ψ, h and their derivatives indicate evaluation at the point which
minimizes h, and σ = −(1/ˆh′′)1/2. This approximation remains valid for a
function ht depending on t, provided that the ﬂuctuations of ht or its derivatives
can be controlled in some way. Conditions above allow, for instance, for applying
this approximation to the functions ht,1(θ) = −lt(θ)/t and ht,2(θ) = −2lt(θ)/t;
see Schervish [ , page 446] for technical details. It is necessary, however,
to assume that ψ(θ0) ̸= 0, so that ψ is either strictly positive or strictly negative
at least in a neighborhood of θ0. Since V sis
(ϕ) = V sis
(ϕ + λ) for any λ ∈R, we
assume without loss of generality that ϕ(θ0) ̸= 0. V sis
(ϕ) equals
 ψ1(θ)p(y1: t|θ)2 dθ −2Eπt(ϕ)
 ψ2(θ)p(y1: t|θ)2 dθ
 π(θ)p(y1: t|θ)dθ}2
+ {Eπt(ϕ)}2  ψ3(θ)p(y1: t|θ)2 dθ
 π(θ)p(y1: t|θ)dθ}2
where ψ1 = π0(θ)2ϕ(θ)2/ ˜π0(θ), ψ2 = π0(θ)2ϕ(θ)/ ˜π0(θ) and ψ3 = π0(θ)2/
˜π0(θ). Combining the appropriate Laplace approximations, we get that
× [ψ1( ˆθt) −2Eπt(ϕ)ψ2( ˆθt) + {Eπt(ϕ)}2ψ3( ˆθt) + At−1 + O(t−2)]
{π0( ˆθt) + Bt−1 + O(t−2)}2
{ϕ( ˆθt) −Eπt(ϕ)}2 + A ˜π0( ˆθt)π0( ˆθt)−2t−1 + O(t−2)
˜π0( ˆθt){1 + Bπ0( ˆθt)−1t−1 + O(t−2)}2
where A is the sum of O(t−1) terms corresponding to the three Laplace expansions
of the numerator, and B is the O(t−1) term of the denominator. Since ϕ( ˆθt) −
Eπt(ϕ) = O(t−1), t = I (θ0) + O(t−1) and ψ( ˆθt) = ψ(θ0) + O(t−1) for any
continuous function ψ, we get through appropriate derivations that
(ϕ) = I (θ0)1/2ϕ′(θ0)2
2π1/2 ˜π0(θ0) t−1/2 + O(t−3/2).
Derivations in multidimensional cases are much the same, except that notation
is more cumbersome. When p > 1, the factor t−1/2 in the Laplace expansion is
replaced by t−p/2, so that in the ratio (24) we get a factor tp/2, and since the tp/2
terms cancel as in the one-dimensional case, the actual rate of divergence is tp/2−1,
and this completes the ﬁrst part of the proof.
In the sequential importance resampling case (multinomial scheme), qt(θ,·) =
δθ and ˜πt = πt−1, and according to (9),
Vt(ϕ) = V sis
Then through a direct adaptation of expansions above we obtain a divergence rate
for Vt(ϕ) of order (t
k=0(t −k)p/2−1) = O(tp/2). For the residual case, it follows
from (11) and (25) that
t (ϕ) = V sis
The difﬁculty in this case is that the noncontinuous function r(·) takes part in
the expression for Rk(·), see (8). It is clear, however, that the Laplace expansion
can be generalized to cases where regularity conditions for the likelihood and
other functions are fulﬁlled only locally around θ0. The additional assumption
that πt(θ0)/πt−1(θ0) is not an integer for any t > 0 allows r(υt) to be six-times
continuously differentiable in a neighborhood around θ0, and, therefore, makes it
possible to expand the terms of the sum above, which leads to a rate of divergence
of order O(tp/2) in the same way as in the multinomial case.
A.4. Proof of Theorem 5.
As a preliminary, we state without proof the
following inequality. Let ϕ,ψ :R →R such that ϕ ≥0, supψ ≥0 and infψ ≤0.
(ϕψ) ≤supϕ · ψ.
Due to particular cancelations, the weight function υt(x1: t) only depends on
xt−1 and xt in the state space case
υt(x1: t) = υt(xt−1,xt) ∝f (yt|xt)g(xt|xt−1)
qt(xt|xt−1)
Straightforward consequences of this expression are the identities
πt(xt|xt−1) =
qt(xt|xt−1)υt(xt−1,xt)
 qt(x|xt−1)υt(xt−1,x)dx ,
πt+1(xt+1|xk) =
 πt(xt|xk)qt+1(xt+1|xt)υt+1(xt,xt+1)dxt
 πt(xt|xk)qt+1(x|xt)υt+1(xt,x)dxt dx ,
CENTRAL LIMIT THEOREM FOR SEQUENTIAL MONTE CARLO METHODS 2407
for k < t, where πt(xt|xk) denotes the conditional posterior density of xt given xk
and the t ﬁrst observations, that is, πt(xt|xk) = π(xt|xk,y1: t) = π(xt|xk,yk+1: t).
We start by proving some useful lemmas.
LEMMA A.5.
The conditional posterior density πt(xt|xk), k < t, deﬁnes a
Markov transition from xk to xt whose contraction coefﬁcient is less than or equal
to (1 −C−2)t−k.
This is adapted from Künsch . For xk,x′
k,xk+1 ∈X, k < t,
πt(xk+1|xk)
πt(xk+1|x′
k) = g(xk+1|xk)p(yk+1: t|x′
k)p(yk+1: t|xk) ≤C2,
since g(xk+1|xk) ≤Cg(xk+1|x′
p(yk+1: t|x′
k)p(yk+1: t|xk+1)dxk+1
g(xk+1|xk)p(yk+1: t|xk+1)dxk+1.
Therefore, the contraction coefﬁcients of Markov transitions πt(xk+1|xk) and
πt(xt|xk) are less than or equal to, respectively, (1 −C−2) and (1 −C−2)t−k.
LEMMA A.6.
Let λ be a probability density on X and h(x|x′) a conditional
probability density deﬁning a Markov transition on X. Then for any x′ ∈X, y ∈Y,
 f (y|x)h(x|x′)dx
 f (y|x)h(x|x′′)dx} ≤1 + ρhCf ,
where ρh is the contraction coefﬁcient of h(·|·), and Cf = ¯f /f −1.
It follows from the deﬁnition of ρh [see (14)] that for x′,x′′ ∈X,
f (y|x)h(x|x′)dx −
f (y|x)h(x|x′′)dx
 ≤ρh( ¯f −f )
and therefore,
f (y|x)h(x|x′)dx
f (y|x)h(x|x′′)dx
+ ρh( ¯f −f ),
 f (y|x)h(x|x′)dx}
 f (y|x)h(x|x′′)dx} ≤1 + ρh
 f (y|x)h(x|x′′)dx}
LEMMA A.7.
Let ρ = 1 −C−1 and ρ2 = 1 −C−2. Then for k < t,
(1 + ρρi−1
for any real-valued ﬁltering function, ϕ :x1: t →ϕ(xt).
Let ¯ϕ = ϕ −Eπt(ϕ). Note the arguments of Ek+1: t( ¯ϕ) are x1: k in
general, but in the case considered in Section 3.3 it only depends on xk and is
therefore treated as a function X →X. For the sake of clarity, we treat the case
k = t −2, but the reasoning is easily generalized. The following decomposition is
deduced from identity (28):
Et−1: t( ¯ϕ)(xt−2)
= Eqt−1(xt−1|xt−2){υt−1(xt−2,xt−1)Et( ¯ϕ)(xt−1)}
= Eqt−1(xt−1|xt−2){υt−1(xt−2,xt−1)}Eπt−1(xt−1|xt−2){Et( ¯ϕ)(xt−1)}.
It follows from (27) that the ﬁrst term satisﬁes
Eqt−1(xt−1|xt−2){υt−1(xt−2,xt−1)} ∝
f (yt−1|xt−1)g(xt−1|xt−2)dxt−1,
where the proportionality constant can be retrieved by remarking that the
expectation of this term with respect to πt−2 equals one and, therefore,
Eqt−1(xt−1|xt−2){υt−1(xt−2,xt−1)}
 f (yt−1|xt−1)g(xt−1|xt−2)dxt−1
Eπt−2(xt−2){
 f (yt−1|xt−1)g(xt−1|xt−2)dxt−1}
according to Lemma A.6. Note πt−2(xt−2) denotes the πt−2-marginal density
of xt−2. It follows from the decomposition above and the inequality in (26) that
Et−1: t( ¯ϕ) ≤(1 + ρCf )ψ,
where ψ is the function
ψ(xt−2) = Eπt−1(xt−1|xt−2){Et( ¯ϕ)(xt−1)}
= Eπt−1(xt−1|xt−2)
Eqt(xt|xt−1){υt(xt−1,xt) ¯ϕ(xt)}
Note that ψ does take positive and negative values, since the expectation of
Et−1: t( ¯ϕ) with respect to πt−2 is null. We now decompose ψ in the same way,
ψ(xt−2) = Eπt−1(xt−1|xt−2)
Eqt(xt|xt−1){υt(xt−1,xt)}
Eπt(xt|xt−2){ ¯ϕ(xt)},
CENTRAL LIMIT THEOREM FOR SEQUENTIAL MONTE CARLO METHODS 2409
by consequence of the identity (29). The expectation of the ﬁrst term with respect
to πt−1(xt−2) equals one, so that
Eπt−1(xt−1|xt−2)
Eqt(xt|xt−1){υt(xt−1,xt)}
 πt−1(xt−1|xt−2)f (yt|xt)g(xt|xt−1)dxt−1 dxt
Eπt−1(xt−2){
 πt−1(xt−1|xt−2)f (yt|xt)g(xt|xt−1)dxt−1 dxt}
≤1 + ρρ2Cf ,
according to Lemmas A.5 and A.6. Resorting again to inequality (26), we get
ψ ≤(1 + ρρ2Cf )ρ2
which leads to the desired inequality, and this completes the proof of Lemma A.7.
To conclude the proof of Theorem 5, remark that E ˜πk(υk) = 1. Therefore,
υk(xk−1,xk) =
f (yk|xk)g(xk|xk−1)/qk(xk|xk−1)
E ˜πk(x1: k){f (yk|xk)g(xk|xk−1)/qk(xk|xk−1)}
≤C2 ¯f /f ,
and since the expectation of the function Ek+1: t{ϕ −Eπt(ϕ)} with respect to πk
is null, the function Ek+1: t{ϕ −Eπt(ϕ)} is ensured to take positive and negative
values, so that
 ≤Ek+1: t
and, ﬁnally,
≤C4( ¯f /f )2
(1 + ρρi−1
Cf )2ρ2(t−k)
≤C4( ¯f /f )2 exp
≤C4( ¯f /f )2 exp{2ρCf /(1 −ρ2)}ρ2(t−k)
It follows from (9) that Vt(ϕ) is bounded from above by a convergent series.
Acknowledgments.
This paper is the fourth part of my Ph.D. thesis, defended
on March 2003 at Université Pierre et Marie Curie, Paris. It was inspired in
part by Hans Künsch’s lectures on particle ﬁlters at the “Summer School on
Advanced Computational Methods for Statistical Inference,” Luminy, September
2001, and beneﬁted from helpful comments by Christian Robert, Hans Künsch,
Eric Moulines, Pierre Del Moral, one anonymous referee and an Associate Editor.