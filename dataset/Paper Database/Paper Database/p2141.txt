Linguistic Issues in Language Technology  LiLT
Submitted, October 2011
On Achieving and Evaluating
Language-Independence in NLP
Emily M. Bender
Published by CSLI Publications
LiLT volume 6, issue 3
October 2011
On Achieving and Evaluating
Language-Independence in NLP
Emily M. Bender, University of Washington
Introduction
Language independence is commonly presented as one of the advantages
of modern, machine-learning approaches to NLP, and it is an important
type of scalability. If technology developed for one language can be
ported to another merely by amassing appropriate training data in
the second language, then the eort put into the development of the
technology in the
rst language can be leveraged to more e
create technology for other languages. In cases where the collection
of training data represents minimal eort (compared to the algorithm
development), this can be very e
cient indeed.
In this position paper, I critically review the widespread approaches
to achieving and evaluating language independence in the
eld of computational linguistics and argue that, on the one hand, we are not truly
evaluating language independence with any systematicity and on the
other hand, that truly language-independent technology requires more
linguistic sophistication than is the norm. The rest of the paper is structured as follows: In ¬ü2, I motivate the interest of language independence
in NLP systems, explore how it is standardly pursued, and make recommendations for how it could be done better, by leveraging the results
of linguistic typology. In ¬ü3, I survey the papers from ACL2008: HLT
and EACL 2009 to give a picture of how language independence is
currently evaluated in our
eld. ¬ü4 presents a quick check-list of rec-
LiLT Volume 6, Issue 3, October 2011.
On Achieving and Evaluating Language-Independence in NLP.
Copyright c
‚Éù2011, CSLI Publications.
2 / LiLT volume 6, issue 3
October 2011
ommendations for more typologically-informed NLP, in etiquette-book
style. Finally, ¬ü5 reviews some work which goes against the trend and
explicitly addresses the intersection between computational linguistics
and linguistic typology.
Language independence: Why and how
Why language independence?
Truly language-independent NLP technology would be very valuable
from both practical and scienti
c perspectives. From a practical perspective, it would enable more cost-e
cient creation of NLP technology
across many dierent language markets as well as more time-e
creation of applications in situations which require quick ramp-up 
or the scramble to produce EnglishHaitian Creole translation systems1). In addition, language independence means that technology is
more likely to be deployed for languages that have less economic clout.
NLP technology for so-called low-density languages also has scienti
interest: As argued by Bender and Langendoen , computational
methods have much to oer the enterprise of linguistic analysis, but
many of these computational methods rely on the availability of other
NLP resources, such as POS taggers or parsers. Finally, in the ideal
scenario, language-independent NLP systems can teach us something
about the nature of human language, and what human languages share
in common.
Thus there are practical and scienti
c reasons to be interested in
creating technology that scales from one to many languages. A related
question that doesn't get asked too often is, which languages? There are
several possible answers to this question, but only some of them make
sense. Beginning with those that don't, we have All logically possible
sets of string-meaning pairs and All possible sets of string-meaning
pairs that could be used as communication systems. The reasonable
answers include things like All currently spoken human languages
(of which Ethnologue lists 6,9092), All languages spoken in X country/continent, All languages spoken by at least N people, and All
languages with established writing systems. Two points emerge here:
rst is that when we claim language independence, we should specify over which set we are claiming independence. The second is that,
as soon as we restrict our attention to actually existing human lan-
 
020410.aspx (accessed 3/30/10).
2 accessed 7/23/09
On Achieving and Evaluating Language-Independence in NLP / 3
FIGURE 1 Schematic diagram of machine learning
guages (or some subset thereof), we are working with the same domain
as linguistic typologists. The results of linguistic typology describe the
range of variation in human languages (and tendencies of co-variation
across properties of human language) and can be used to inform NLP
systems. This idea is taken up in ¬ü2.3.
How is language independence currently pursued?
In papers published at ACL, EACL and similar venues, it is common to
assert that the methods presented apply to other languages (in some
cases with the hedge that certain kinds of resourcese.g., a WordNet
are required). While this is often true, it is not the case that apply
entails work. That is, just because the software could be run over
training and test data from a dierent language,3 doesn't mean that
it will work equally or even reasonably well. And if it doesn't work
reasonably well, then it is not truly language independent.
At the same time, much is often made of the lack of linguistic knowledge encoded in the algorithms. Figure 1 presents a very schematic diagram of machine learning approaches to language: The diagram begins
with annotated data, which is fed into a feature extraction program, resulting in features which are fed to the learner, which in turn produces
a model. When the annotations are for example just word boundaries
and the features are n-gram counts, or when the annotations are tree
or dependency structures using notions which we believe could be applied to any language and the features are arbitrary subparts of those
trees, then arguably these algorithms are language-independent in the
sense that they have not been created on the basis of any particular
explicit analysis of the language at hand. In other words, they could be
applied without great eort to any other language.
However, the lack of explicitly encoded linguistic knowledge does
not ensure that the approach has not been tuned to the development
language. Consider for example the case of word-based n-gram models.
On the face of it, n-gram models code in no linguistic knowledge. They
treat natural language text as simple sequences of symbols and auto-
3In some cases, this would require preprocessing, e.g., sentence- or wordboundary detection, which can be non-trivial .
4 / LiLT volume 6, issue 3
October 2011
matically re
ect the hidden structure through the way it aects the
distributions of words in various (
at, unstructured) contexts. However,
the eectiveness of n-gram models in English (and similar languages)
is partially predicated on two properties of those languages: relatively
low levels of in
ectional morphology, and relatively
xed word order.
As is well-known by now , languages
with more elaborate morphology (more morphemes per word, more
distinctions within the same number of morphological slots, and/or
fewer unin
ected words) present greater data sparsity problems for ngram language models. This data sparsity limits the ability of n-gram
models to capture the dependencies between open-class morphemes,
but also between closed-class morphemes. The information expressed
by short function words in English is typically expressed by the in-
ectional morphology in languages with more elaborate morphological
systems. Word-based n-gram models have no way of representing the
function morphemes in such a language. In addition, for n-gram models
to capture inter-word dependencies, both words have to appear in the
n-gram window. This will happen more consistently in languages with
relatively
xed word order, as compared to languages with relatively
free word order.4
Thus even though word-based n-grams models can be built without
any hand-coding of linguistic knowledge, they are not truly language
independent. Rather, their success depends on typological properties
of the languages they were
rst developed for. A more linguisticallyinformed (and thus more language independent) approach to n-gram
models is the factored language model approach of Bilmes and Kirchho
 . Factored language models address the problems of data-sparsity
in morphologically complex languages by representing words as bundles
of features, thus capturing dependencies between sub-word parts of
adjacent words.
A second example of subtle language dependence comes from Dasgupta and Ng , who present an unsupervised morphological segmentation algorithm meant to be language-independent. Indeed, this
work goes much further towards language independence than is the
norm (see Section 3). It is tested against data from English, Bengali,
Finnish and Turkish, a particularly good selection of languages in that
it includes diversity along a key dimension (degree of morphological
complexity), as well as representatives of three language families argues, however, that free word order isn't as much of a problem at it might appear to be, because local order (within phrases) is relatively stable
even when global order (of major sentence constituents) is
uid in the languages
studied so far.
On Achieving and Evaluating Language-Independence in NLP / 5
European, Uralic, and Altaic). Furthermore, the algorithm is designed
to detect more than one pre
x per word, which is important for
analyzing morphologically complex languages. However, it seems unrealistic to expect a one-size-
ts-all approach to be achieve uniformly high
performance across varied languages, and, in fact, it doesn't. Though
the system presented in Dasgupta and Ng 2007 outperforms the best
systems in the 2006 PASCAL challenge for Turkish and Finnish, it still
does signi
cantly worse on these languages than English (F-scores of
66.2 and 66.5, compared to 79.4).
This seems to be due to an interesting interaction of at least two
properties of the languages in question. First, the initial algorithm for
discovering candidate roots and a
xes relies on the presence of bare,
ected roots in the training vocabulary, extracting a string as a
candidate a
x (or sequence of a
xes) when it appears at the end (or
beginning) of another string that also appears independently. In Turkish and Finnish, verbs appear as bare roots in many fewer contexts
than in English.5 This is also true in Bengali, and the authors note
that their technique for detecting allomorphs is critical to
nding outof-vocabulary roots (those unattested as stand-alone words) in that
language. However, the technique for
nding allomorphs assumes that
roots exhibit the character changes during attachment, not su
(p.160), and this is where another property of Finnish and Turkish becomes relevant: Both of these languages exhibit vowel harmony, where
the vowels in many su
xes vary depending on the vowels of the root,
even if consonants intervene. Thus I speculate that at least some of the
reduced performance in Turkish and Finnish is due to the system not
being able to recognize variants of the same su
xes as the same, and,
in addition, not being able to isolate all of the roots.
Of course, in some cases, one language may represent, in some objective sense, a harder problem than another. For example, the dif-
culty of learning the gender classi
cation of nouns depends on the
number of genders to classify the nouns into, as well as the reliability
of phonological cues to gender (e.g., word endings) in the language at
hand.6 Another clear example is English letter-to-phoneme conversion,
which, as a result of the lack of transparency in English orthography,
is a harder problem that letter-to-phoneme conversion in other lan-
5In Finnish, depending on the verb class, the bare root may appear in negated
present tense sentences, in second-person singular imperatives, and third-person
singular present tense, or not at all . In Turkish,
the bare root can function as a familiar imperative, but other forms are in
 .
6Thanks to Jeremy Nicholson for pointing out this type of example.
6 / LiLT volume 6, issue 3
October 2011
guages. Not surprisingly, the letter-to-phoneme systems described in
e.g. Jiampojamarn et al. 2008 and Bartlett et al. 2008 do worse on
the English test data than they do on German, Dutch, or French. On
the other hand, just because one language may present a harder problem than the other doesn't mean that system developers can assume
that any performance dierences can be explained in such a way. If one
aims to create a language-independent system, then one must explore
the possibility that the system includes assumptions about linguistic
structure which do not hold up across all languages.
The conclusions I would like to draw from these examples are as
follows: A truly language-independent system works equally (or nearly
equally) well across languages. When a system that is meant to be language independent does not in fact work equally well across languages,
it is likely because something about the system design is making implicit assumptions about language structure. These assumptions are
typically the result of over
tting to the original development language(s). Here I use the term over
tting metaphorically, to call out
the way in which, as the developers of NLP methodology, we rely on our
intuitions about the structure of the language(s) we're working with and
the feedback we get by testing our ideas against particular languages.
Feature design is inspired by a kind of tacit linguisticsour knowledge
of familiar languagesand success (and failure) on development and
test sets from speci
c familiar languages drives the research process. In
the next subsection, I will argue that the best way to achieve language
independence is by using explicit, rather than tacit, linguistics and by
including, rather than eschewing, linguistic knowledge.
How should language independence be pursued?
Typically, when we think of linguistic knowledge-based NLP systems,
what comes to mind are complicated, intricate sets of language-speci
rules. While I would be the last to deny that such systems can be both
linguistically interesting and the best approach to certain tasks , my purpose here is to point out that there are other
kinds of linguistic knowledge that can be fruitfully incorporated into
NLP systems. In particular, the results of linguistic typology represent
a rich source of knowledge that, by virtue of being already produced
by typologists, can be relatively inexpensively incorporated into NLP
Linguistic typology is an approach to the scienti
c study of language
which was pioneered in its modern form by Joseph Greenberg in the
On Achieving and Evaluating Language-Independence in NLP / 7
1950s and 1960s .7 In the intervening decades,
it has evolved from a search for language universals and the limits of
language variation to what Bickel characterizes as the study of
what's where why. That is, typologists are interested in how variations on particular linguistic phenomena are distributed throughout the
world's languages, both in terms of language families and geography,
and how those distributions came to be the way they are.
For the purposes of improving language-independent NLP systems,
we are primarily concerned with what and where: Knowing what
(how languages can vary) allows us to both broaden and parameterize
our systems. Knowing where also helps with parameterizing, as well
as with selecting appropriate samples of languages to test the systems
against. We can broaden our systems by studying what typologists have
to say about our initial development languages, and identifying those
characteristics we might be implicitly relying on. This is eectively
what Bilmes and Kirchho did in generalizing n-gram language
models to factored language models. We can parameterize our systems
by identifying and speci
cally accommodating relevant language types
(what) and then using databases produced by typologists to map
c input languages to types (where).8
As noted in ¬ü2.1, the practical point of language independence is
not to be able to handle in principle any possible language in the universe (human or extraterrestrial!), but to improve the scalability of
NLP technology across the existing set of human languages. There are
approximately 7,000 languages spoken today, of which 347 have more
than 1 million speakers.9 An NLP system that uses dierent parameters
or algorithms for each one of a set of known languages is not language
independent. One that uses dierent parameters or even algorithms for
dierent language types, and includes as a
rst step the classi
of the input language, either automatically or with reference to some
external typological database, is language independent, at least in the
relevant, practical sense.
The preeminent typological database among those which are currently publicly available is WALS: The World Atlas of Linguistic Struc-
7See Ramat to appear for discussion of much earlier approaches.
8In the case of systems working with language pairs, the relevant question could
be how typologically similar the two languages are. Cromier√®s and Kurohashi ,
for example, suggest that the information added by using parsing as a component
of statistical MT systems is more important when the source and target languages
have very dierent syntactic structures.
9 accessed 6 February 2009
8 / LiLT volume 6, issue 3
October 2011
tures Online .10 WALS currently includes 142
chapters studying linguistic features, each of which de
nes a dimension
cation, describes values along that dimension, and then classi-
es a large sample of languages. It is also possible to view the data on
a language-by-language basis. These chapters represent concise summaries, as well as providing pointers into the relevant literature for
more information.
To give a sense of how this information might be of relevance to NLP
or speech systems, here is a brief overview of three chapters:
Maddieson studies tone, or the use of pitch to dierentiate
words or in
ectional categories. He classi
es languages into those with
no tone systems, those with simple tone systems (a binary contrast
between high and low tone), and those with more complex tone systems (more than two tone types). Nearly half of the languages in the
sample have some tone, and Maddieson points out that the sample in
fact underestimates the number of languages with tone. Information
about the presence or absence (and nature) of a tone system has obvious implications for speech processing applications investigates pre
xing and su
xing in in
ectional morphology, looking at 10 common types of a
xes (from case a
nouns to adverbial subordinator a
xes on verbs), and using them to
classify languages in terms of tendencies towards pre
xing or su
xing.11 His resulting categories are: little a
xation, strongly su
xing, equal pre
xing and su
xing, weakly pre
strongly pre
xing. The most common category (382/894 languages)
is predominantly su
xing. Information about the degree of a
in a language and where in the word a
xes tend to appear is useful
for lemmatizers, morphological analyzers, bag-of-words approaches to
information retrieval, and many other tasks.
Dryer investigates the expression of clausal negation. One
nding of note is that all languages studied use dedicated morphemes
to express negation. This contrasts with the expression of yes-no questions which can be handled with word order changes, intonation, or
no overt mark at all. The types of expression of clausal negation that
Dryer identi
es are: negative a
x, negative auxiliary verb, and negative
particle. In addition, some languages are classi
ed as using a negative
word that may be a verb or may be a particle, as having variation
between negative a
xes and negative words, and as having double (or
10Available online at: 
11For the purposes of this study, he sets aside less common in
ectional strategies
such as in
xing, tone changes, and stem changes.
On Achieving and Evaluating Language-Independence in NLP / 9
two-part) negation, where each negative clause requires two markers,
one before the verb, and one after it. Negation, and in particular, the
detection of negation in running text is of great interest in biomedical NLP , sentiment analysis, and other
meaning-extracting applications. Clausal negation is not the only kind
of negation. Nonetheless, knowing how to
nd it crosslinguistically can
be useful.
These examples illustrate several useful aspects of the knowledge
systematized by linguistic typology: First, languages show variation beyond that which one might imagine looking only at a few familiar (and
possibly closely related) languages. Second, however, that variation is
still bounded: Though typologists are always interested in
categories that stretch the current classi
cation, for the purposes of
computational linguistics, we can get very far by assuming the known
types exhaust the possibilities. Finally, because of the work done by
linguists and typologists, this knowledge is available as high-level generalizations about languages, of the sort that can inform the design of
linguistically-sophisticated, language-independent NLP systems. Furthermore, even if typological information about a particular language
is incomplete, we can often estimate some of the missing values probabilistically on the basis of what is known about the language and
typological implications (see ¬ü5.1).
Typological information can be incorporated into NLP systems in
several dierent ways: (i) Understanding the typological properties of
familiar languages, and how other languages can vary on these same
dimensions, can help inform the search for hidden assumptions about
language structures in NLP systems. (ii) For some applications, it might
make sense to create a range of models and/or include parameters to
tune the system to dierent typological properties. These properties
could then be detected or alternatively looked up as a preprocessing
step. (iii) Typological knowledge can also be used directly in otherwise
unsupervised machine learning systems , by taking advantage of known tendencies
towards covariation across linguistic dimensions.
This section has framed language-independence as a valuable goal in
computational linguistics as well as a potential bene
t of using machinelearning methods, and argued that the best way to achieve it is to
directly consider how the typological properties of the development
languages might have informed the design of the system and that the
eld of linguistic typology is a rich source of information for computa-
10 / LiLT volume 6, issue 3
October 2011
tional linguists looking to extend the cross-linguistic scalability of their
systems. In the next section, I will consider how we can improve our
evaluation of the language independence.
Evaluating language independence: A report card
As discussed in ¬ü2.2, even systems built without any explicit languagespeci
c knowledge can rely for their success on typological properties of
the development languages. It follows that we can't deduce languageindependence from algorithm design, but rather must prove it with
appropriate evaluation methodologies. Ideally, this would involve heldout test languages, with divergent typological properties and drawn
from dierent language families, but this is exceedingly rare, appearing
in only 2 of the 217 papers surveyed here: Xia et al. 2009 and Davidov and Rappoport 2009. Short of every paper considering multiple,
diverse languages, the
eld as a whole should be considering a wide
range of languages. In order to get a sense of how well we meet this
goal, I surveyed the papers from ACL2008: HLT (119 long papers) and
EACL 2009 (98 regular papers). Not all of these papers explicitly claim
language independence of the methodologies they use (and a few are
explicitly language speci
c), but enough are in the style of knowledgelean, machine-learning heavy research that it seems fair to evaluate
them all together. Indeed, it seems that language independence is often
assumed rather than stated, as will be further discussed below.
Table 1 presents the distribution of the papers according to how
many dierent languages or language pairs were studied. The nine papers studying no language pairs were presenting abstract formal proofs
regarding grammar formalisms, algorithms for e
cient computation of
common machine learning paradigms, and the like. More than threequarters of the papers in each conference looked at exactly one language
or language pair explore whether better alignments lead to better translations, across 6 language pairs, in each direction (12 MT systems),
collecting data from a variety of sources. Nivre and McDonald 
present an approach to dependency parsing which integrates graphbased and transition-based methods, and evaluate the result against
the 13 datasets provided in the CoNLL-X shared task de
ne a task of crosslingual concept lexicalization, in which a set of words instantiating a
concept (e.g., apple, banana, . . . for `fruit') are input in one language,
and a set of words describing the same concept are output in another
language. This methodology was evaluated against 100 language pairs,
involving 46 languages. 45 of the language pairs had English as the
source, 45 had English as the target, and 10 had English as neither
source nor target. Mukherjee et al. develop a network-based
method to explore the co-occurrence of consonant phonemes across the
phoneme inventories of natural languages. They apply this method to
the UPSID data set (phoneme inventories from 317
languages) and
nd evidence for the linguistic notions of markedness
and implicational universals in phoneme inventories. In this case, the
study is not evaluating a claim or technique against multiple languages,
but rather exploring typological facts across a sample of 317 languages.
Finally, Xia et al. approach the problem of language identi
cation in the contexts of short linguistic examples harvested from linguistics papers on the web. Their dataset is drawn from the ODIN database
 , and includes approximately 600 languages.
As so much work in computational linguistics is driven by the availability of data sets, it is encouraging to see multilingual data sets such
as those from ODIN and the CoNLL-X shared task become available.
eld as a whole will be in a better position to test (and improve)
12 / LiLT volume 6, issue 3
October 2011
Indo-European
Portuguese
Afro-Asiatic
Sino-Tibetan
Australian
TABLE 2 Languages studied in ACL 2008 papers, by language genus and
the cross-linguistic applicability of various methods to the extent that
more such datasets are produced. It is worth noting, however, that the
sheer number of languages tested is not the only important factor: Because related languages tend to share typological properties, it is also
important to sample across the known language families. The three
outlier studies from EACL 2009 continue to fare well even when language families are taken under consideration. That same is not true,
however, of the remaining 204 papers: The modest coverage of linguistic
diversity is reduced when viewed from this angle.
Tables 2 and 3 tabulate the studies by language, genus and family for
ACL2008: HLT and EACL 2009, respectively, for those papers that presented methodologies concerned with producing results in one language
at a time.12 The
rst thing to note in these tables is the concentration
12The very interesting study by Snyder and Barzilay on multilingual approaches to morphological segmentation was di
cult to classify. Their methodology
involved jointly analyzing two languages at a time in order to produce morphological segmenters for each. Since the resulting systems were monolingual, the data
from these studies are included in Table 2. Conversely, Garera and Yarowsky 
and Navigli use information from German and Italian, respectively, to aid in
On Achieving and Evaluating Language-Independence in NLP / 13
Indo-European
Portuguese
Afro-Asiatic
Sino-Tibetan
TABLE 3 Languages studied in EACL 2009 papers by language genus and
family, exclusive of Mukherjee et al. 2009 and Xia et al. 2009
14 / LiLT volume 6, issue 3
October 2011
of work on English: 63% of the single-language studies in ACL and
55% of the single-language studies in EACL concerned English.13 In
addition, languages closely related to English are overrepresented, with
the Germanic genus accounting for 71-72% of the studies in the two
conferences and the Indo-European family as a whole 85% at ACL and
91% at EACL.
Ethnologue14 lists 94 language families. ACL2008: HLT papers studied seven (the six shown in Table 2, plus Uralic, represented by Finnish
in Table 5). EACL papers studied eight (see Tables 3 and 7). Of course,
the distribution of languages (and perhaps more to the point, speakers) is not uniform across language families. Table 4 gives the
populous language families, again from Ethnologue.15 These language
families together account for almost 85% of the world's population.
Next we turn to the language-pair studies: papers on machine translation, bilingual lexicon construction, transliteration, etc. Tables 5 and
6 catalog the language-pair studies from ACL2008: HLT and EACL
2009 respectively.16 The EACL table does not include information
about the language pairs studied by Davidov and Rappoport . I
have chosen to exclude this paper because it is an outlier: the 100 language pairs studied there would swamp the data from the 81 language
pairs studied in the other 21 papers tabulated here.
In the EACL data at least, we see more diversity of language family
in the language-pair studies than in the single language studies: only
53% of the language pair studies paired English (or French) with an
Indo-European language, and a total of seven language families are
explored as against four in the single language studies. The tally of
language-pair studies by genus and family is shown in Table 7. Nonetheless, one thing jumps out from these tables: the predominance of English. Every language pair in the ACL papers and in every language pair
but three in the EACL papers involved English on one side or the other. The three EACL studies
a task evaluated in English. Since they don't also evaluate in German and Italian,
these studies are included in Table 6 in order to represent the non-English languages.
13Mukherjee et al. 2009 and Xia et al. 2009 did not include lists of the languages
used, and are not included in these numbers.
14 
February 2009.
15Ibid. Example languages are included to give the reader a sense of where these
language families are spoken, and are deliberately chosen to represent the breadth
of each language family while still being relatively recognizable to a computational
linguistics audience.
16Tables 6 and 7 include data points from Schroeder et al. 2009, a paper on
multisource machine translation.
On Achieving and Evaluating Language-Independence in NLP / 15
Language family
Living languages
% population
Indo-European
Sino-Tibetan
Niger-Congo
Afro-Asiatic
Austronesian
TABLE 4 Five most populous language families, from Ethnologue
Symmetrical pair
English, Chinese
English, Arabic
English, French
English, Spanish
TABLE 5 Language pairs studied in ACL 2008 papers
16 / LiLT volume 6, issue 3
October 2011
Symmetrical pair
English, French
English, Chinese
English, Greek
English, Japanese
English, Malay
French, Italian
French, Dutch
French + Swedish
French + Spanish
French + Portuguese +
Danish + Italian
TABLE 6 Language pairs studied in EACL 2009 papers, exclusive of
Davidov and Rappoport 2009
not involving English instead chose French, which is not typologically
very distant from English. By restricting our attention in this way, we
are failing to test any methodology against language pairs where both
languages are morphologically complex, or both languages have relatively free word order, or both languages show frequent zero anaphora,
In general, this picture is not very encouraging regarding the linguistic diversity of studies in computational linguistics. Perhaps most astonishing, however, is the fact that, of the 45 papers studying only English
at EACL, 33 neglected to state directly that English was the language
under study.17 In some cases, it was possible to tell that English was
in fact the language in question because the authors cited linguistic
resources for English (e.g., (English) WordNet or the
(English) Penn Treebank ). In others, the only
clue was linguistic examples given in English, or statements about how
the data was collected (from undergraduates) in combination with the
authors' a
liations (US institutions). While the generalizations aren't
clear cut, it seems that this tendency is more pronounced in papers on
tasks to do with extracting meaning from text (fact extraction, sentiment analysis, and summarization) than it is in papers relating to
analysis of language structure directly (parsing, POS tagging, etc.).
None of the papers working on bilingual (e.g., MT, bilingual lexicon
extraction, etc.) tasks failed to identify the languages being studied.
Only one paper that didn't directly identify its languages was work-
17This phenomenon was also observed in the ACL papers, but not systematically
coded in the survey, so I can only report numbers for EACL here.
On Achieving and Evaluating Language-Independence in NLP / 17
L1, L2 genus
L1, L2 family
English, Romance
English, Indo-European
English, Germanic
English, Slavic
English, Romance + Germanic
English, Greek
English, Indic
English, Chinese
English, Sino-Tibetan
English, Semitic
English, Afro-Asiatic
English, Finnic
English, Uralic
English, Southern Dravidian
English, Dravidian
English, Japanese
English, Japanese
English, Sundic
English, Austronesian
French, Romance
French, Indo-European
French, Germanic
TABLE 7 Language pairs studied in ACL 2008 and EACL 2009 papers by
genus and family, exclusive of Davidov and Rappoport 2009
ing on languages other than English: Dinarelli et al. evaluate
reranking for spoken language understanding against two corpora, one
described as a corpus of Italian, and the other described as being produced by a French project NLP research. These suggestions are
aimed at both authors and reviewers, or rather, at members of the NLP
community in both their author and reviewer guises.
Do state the name of the language that is being studied, even if it's
English. Acknowledging that we are working on a particular language
foregrounds the possibility that the techniques may in fact be languagespeci
c. Conversely, neglecting to state that the particular data used
were in, say, English, gives false veneer of language-independence to
Do state the set of languages that the system is meant to generalize to. Is it designed to handle any language with a written tradition?
Any human language currently or recently spoken? Indo-European languages? Morphologically simple/complex languages?
Do explicitly note which aspects of the methodology are intended to
be language-independent, and which are explicitly language-dependent.
This will help reviewers (and eventually readers) understand and evaluate the crosslinguistic applicability of the methods. Those with knowledge of particular languages or linguistics in general will be better able
to provide feedback in terms of where the language independence is
likely to break down.
Don't require new methods to be tested against the same old languages or language pairs for comparability of results. This kind of tendency in conference reviewing in particular can narrow (and in fact
probably already has narrowed) the focus of the
eld and can sti
work that pushes the boundaries of language independence.
Do evaluate claims of language independence by testing the algorithm against multiple languages. In a truly strict evaluation, we would
separate development languages from test languages the way we sepa-
18An anonymous reviewer points out that the data that I have collected isn't
really longitudinal. It could well be that the diversity found in 2008 and 2009 is an
improvement over years past. If so, this is a laudable trend. Regardless, we have a
ways to go.
On Achieving and Evaluating Language-Independence in NLP / 19
rate development data from test data.
Don't evaluate language independence by only testing against related and/or typologically similar languages. Success of a system developed for one language on data from another shows that the system
generalizes somewhat, but to the extent that the languages share typological properties, the evidence of ability to generalize is weak.
Do develop parallel data sets for typologically interesting samples
of languages. The more multilingual data sets (with standardized annotations across languages) that are available, the easier it will be for
NLP researchers to evaluate claims of language independence. The more
these multilingual data sets represent typologically balanced samples,
the better these evaluations will be. The data set produced by Nivre
et al. for the 2007 CoNLL shared tasks is a good step in this
direction, though the languages included lack genealogical and typological diversity.
Do expect comparable performance across languages from languageindependent systems. When performance varies, do error analysis based
on typological properties, exploring what it is about the languages that
makes the algorithm more successful in one or the other, and how that
might relate to assumptions in the algorithm itself.
Do talk to linguists. Linguists can be very helpful in detecting implicit assumptions about linguistic structure in descriptions of algorithms, and their input can be very valuable in the design stage as well
as in error analysis (see previous point).
Do make use of typological information. The hard work of collecting
this information has already been done (or is being done) by linguists.
Making use of it does not make a machine-learning NLP system any less
general: typologists are already studying the largest set of languages it
makes sense to generalize over.
There are many factors that can make it di
cult to follow these
recommendations.19 These include: (i) pressures from funding agencies
to work on particular languages of interest, (ii) scarcity of annotated
(and curated) data from languages outside the well-studied few and (iii)
the importance of shared data sets and shared tasks for comparability
across studies. I believe the solution is to be alert for opportunities to
extend the range of data sets to languages that are otherwise understudied, and to pursue them when they arise. In addition, as reviewers,
we should recognize the value added of working with other languages
when we review both papers and grant proposals.
19I am grateful to Fei Xia for helpful discussion of these points.
20 / LiLT volume 6, issue 3
October 2011
Computational Linguistics and Linguistic Typology
This section reviews the small but growing body of literature working
at the intersection of computational linguistics and linguistic typology.
Some of this work is leveraging results from linguistic typology for
applications in computational linguistics. Other studies are applying
computational methods to discover typological generalizations. This is
potentially useful for typology (giving back), but also for computational
linguistics: If it leads to better typological information, that in turn
could engender more language-independent NLP systems.
Computational approaches to typology
The advent of large, publicly available databases of typological properties, in particular WALS , has opened the door
to the application of computational methods to traditional questions of
linguistic feature co-occurrence in typology.20 Two studies in this area
are Daum√© III and Campbell 2007 and Bakker 2008. Using dierent statistical modeling techniques, Daum√© III & Campbell and Bakker each
mine the data in WALS to look for typological implications, i.e., tendencies for languages with one property or set of properties to also have
another property. In both cases, the authors discover known typological implications , as well as new candidates.
Computational techniques can also be applied to the related set of
questions of linguistic co-development, i.e., genealogical relationships
between languages as well as areal eects, or the in
uence of languages
in contact on one another. Daum√© III uses the feature and geographical data from WALS as input to a Bayesian model designed
to discover areal groupings. Taking a somewhat dierent approach,
Nakhleh et al. build a model (called `perfect phylogenetic networks') that can accommodate both mutual descent and borrowing
across languages, and apply it to data from Indo-European languages
to estimate the degree of isolation of the various sub-families in the
early development of these languages.
Leveraging typology in computational linguistics
Looking the other direction, the results of linguistic typology can be
integrated into computational linguistics in at least two ways: to inform the design of models meant to be cross-linguistically applicable,
or directly as information incorporated into such models. Schutlz and
Kirchho 2006, a thorough investigation of issues in multilingual speech
20Though see Dryer 2009.
On Achieving and Evaluating Language-Independence in NLP / 21
processing, nicely illustrates the
rst approach. The second chapter of
that work provides an overview of the relevant aspects of linguistic typology (and supporting concepts from linguistics)
that can impact the way that speech systems work across languages.
Chapter 4 provides an overview of the state-of-theart in multilingual acoustic modeling, relying on cross-linguistic analysis of phoneme inventories (sound systems) to motivate the design of
language-independent and language-adaptive acoustic models. Other
chapters address multilingual dictionaries , multilingual language modeling , and various
applications.
Integrating results of linguistic typology as a knowledge source can
be useful for both stochastic and knowledge-engineering approaches to
NLP. On the stochastic side, Schone and Jurafsky use typological implications 
and Bakker aim to discover) as prior information in a Bayesian
approach to inducing class labels in a POS tagging system.21 One can
imagine similarly using typological generalizations to create the prototypes used by Haghighi and Klein for unsupervised grammar
induction. On the knowledge engineering side, the Grammar Matrix
project has been creating libraries of implemented HPSG analyses which
can be added on to a cross-linguistic core grammar through a web-based
customization system.22 These libraries are intended to cover all known
variants of each phenomenon, and are therefore based on a thorough
review of the relevant typological literature.
Conclusion
Building systems that can work for any natural language is a laudable
goal for NLP systems, and a plausible bene
t of the machine learning approach. I have argued in this paper, that, contrary to popular
belief, it is a goal that is not achievable without linguistic knowledge.
Fortunately, linguistic typology can help. The set of currently spoken
human languages is interestingly large, but not in
nite. We know from
linguistic typology that the variation is bounded, though greater than
you might guess from just one or two languages. In the previous section, I have brie
y reviewed how results from linguistic typology are
beginning to be incorporated into computational linguistic research.
21Unfortunately, this system was only ever tested on English.
22The customization system can be accessed here:
 
22 / LiLT volume 6, issue 3
October 2011
Furthermore, I have argued that if we're serious about language independence as a goal, it needs to be re
ected in how we evaluate NLP
systems. In particular, we need to broaden the range of languages we
work with on a regular basis, sampling carefully to cover an interesting range of typological characteristics and language families. Finally,
to truly evaluate language independence, we should include held-out
languages as well as held-out data in our evaluations.
An anonymous reviewer suggests that most computational linguists
are computer scientists and are not particularly interested in nor attuned to issues of language independence. On the contrary, I would
argue that anyone engaged in the scienti
c analysis of language or linguistic data, with or without the assistance of computers, is by de
nition a linguist, and therefore responsible for understanding the issues
that arise in analyzing natural languages. While it is of course not reasonable to expect everyone working in NLP to have a dual degree, I
believe it is reasonable to expect some coursework or other studies in
linguistics as well as a high degree of collaboration with researchers
fully trained in linguistics.
In this context, it is fair to distinguish between people specializing
in NLP and people specializing in machine learning who use NLP as
an application area. The former should have some familiarity with linguistics. The latter should at least have some familiarity with linguists.
More generally, it is both reasonable and productive to have people
specializing in machine learning apply their algorithms to application
areas including NLP. In such collaborations, however, the speci
of tasks and evaluation metrics should involve subject matter experts,
in this case (computational) linguists.
Of course, for these collaborations to work, linguists have to keep
up their end of the bargain as well, and not all work in linguistics is
ciently grounded in data to
t the needs of computational linguists.
It is easy to see how a computer scientist could decide that linguistics
is not helpful on the basis of a course in mainstream theoretical linguistics. One of the goals of this paper has been to encourage the NLP
community to look further into the available sub
elds of linguistics,
and in particular to highlight the potential of the sub
eld of linguistic
typology to provide both very useful information and a perhaps more
compatible perspective on linguistic data.
Acknowledgments
This paper is a revised and expanded version of Bender 2009. I am
grateful to Stephan Oepen, Timothy Baldwin, Fei Xia, Jeremy Nichol-
References / 23
son and two anonymous reviewers for helpful discussion. Any remaining
infelicities are my own. This material is based in part upon work supported by the National Science Foundation under Grant No. 0644097.
Any opinions,
ndings, and conclusions or recommendations expressed
in this material are those of the author and do not necessarily re
the views of the National Science Foundation.