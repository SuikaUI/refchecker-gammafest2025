Psychonomic Bulletin & Review
2000, 7 (2), 208-256
A comparison of two response time models
applied to perceptual matching
TRISHA VAN ZANDT
Johns Hopkins University, Baltimore, Maryland
HANS COLONIUS
University ofOldenburg, Oldenburg, Germany
ROBERT W. PROCTOR
Purdue University, West Lafayette, Indiana
Two models, a Poisson race model and a diffusion model, are fit to data from a perceptual matching
task. In each model, information about the similarity or the difference between two stimuli accumulates toward thresholds for either response. Stimulus variables are assumed to influence the rate at
which information accumulates, and response variables are assumed to influence the level of the response thresholds. Three experiments were conducted to assess the performance ofeach model. In Experiment 1, observers performed under different response deadlines; in Experiment 2, response bias
was manipulated by changing the relative frequency of same and different stimuli. In Experiment 3,
stimulus pairs were presented at three eccentricities: foveal, parafoveal, and peripheral. We examined
whether the race and diffusion models could fit the response time and accuracy data through changes
only in response parameters (for Experiments 1 and 2) or stimulus parameters (for Experiment 3).
Comparisons between the two models suggest that the race model, which has not been studied extensively, can account for perceptual matching data at least as well as the diffusion model. Furthermore,
without the constraints on the parameters provided by the experimental conditions, the diffusion and
the race models are indistinguishable. This finding emphasizes the importance of fitting models across
several conditions and imposing logical psychological constraints on the parameters of models.
For close to 50 years, response time (RT) studies have
been a major focus of attention in cognitive psychology
 . Over this time,
a great deal has been learned about how performance in
cognitive tasks changes with such factors as stimulus intensity, response bias, and so forth. The relationship between RT and other behavioral variables, such as accuracy,
is of considerable interest. For instance, it is well known
that a person can decrease RT at the expense of decreasing accuracy; this is the ubiquitous speed-accuracy tradeoff that appears in most, if not all, cognitive tasks .
The most successful models of RT and accuracy and,
consequently, of the speed-accuracy tradeoff are sequential sampling models. These models assume that, in
Portions of this work were presented at the 23rd Annual Meeting of
the Society for Mathematical Psychology, University ofToronto, 1990.
The project was made possible with Grants MH-44640 from NIMH and
SBR-9702291 from NSF. The authors thank In Jae Myung for advice
on model comparison statistics and the reviewers, F. Gregory Ashby,
Gordon Logan, and Philip Smith for many helpful comments that greatly
improved this paper, as well as Lester Krueger for comments on an earlier draft. Correspondence concerning this article should be addressed
to T. Van Zandt, Psychology Department, Ohio State University, 1885
Neil Avenue, Columbus, OH 43210-1222.
a choice response task, an observer engages a process of
sequentially sampling from the stimulus that results in a
gradual accumulation of information at some late stage
of processing. A response is executed when the level of
information exceeds some threshold or criterial amount
required for that response. The speed-accuracy tradeoff
arises as the thresholds are moved. If the thresholds are
far from the starting point of the process, more information will be needed to reach them, and more time will be
required for that information to accumulate. The system
will be less likely to accumulate a large amount of erroneous information, and so accuracy will be higher than
when the thresholds are closer to the starting point. For
closer thresholds, it will not take as long to accumulate
the necessary amount of information; consequently, RTs
will be faster. However, the probability that erroneous information causes the system to reach threshold will be
larger, producing a higher error rate.
Sequential sampling models have been examined
within a variety of experimental contexts, including signal detection, psychophysical discrimination, recognition memory, categorization, and perceptual matching.
One result of their far-flung success is the general acceptance ofthe idea that these models provide an adequate
description of the relation between RT and accuracy in
simple and choice RT tasks. There are two major classes
Copyright 2000 Psychonomic Society, Inc.
of models that have dominated the literature, which will
be examined in this paper: random walks and race models. The major difference between these two types of
models lies in how information is stored at the critical response selection stage. The race models postulate the existence ofcounters, modules that store separately the information for each response. In contrast, the random
walk models require only a single counter that stores information that can be either positive or negative. In particular, we will compare the popular diffusion model , which can be classified as a type ofrandom
walk, and a Poisson race model .
These models will be applied to data from a perceptual matching task, in which observers are asked to determine whether two elements of a stimulus pair are the
same or different. The perceptual matching paradigm
was chosen to evaluate the sequential sampling models
for two reasons. First, the pattern of RTs and accuracies
provides an interesting challenge for modeling. Correct
same responses are often faster than correct different responses. This is called thefast-same effect. Yet, incorrect
different responses tend to be more frequent than incorrect same responses. This is called thefalse-different effect . This pattern ofRTs
and accuracies suggests that fast same responses are not
due simply to a bias to respond same . If this were the case, same responses would
be more frequently wrong than different responses. A
successful model must not only illustrate how same responses can be speeded, relative to different responses,
but also how such a result could arise without response
biases. However, as will be evident in this study, the fastsame/false-different pattern is not always obtained . Viable models ofthe
matching process must also be able to predict the lack of
an effect of stimulus type on RTs and accuracies.
The second reason to choose perceptual matching is
that, in similar paradigms, at least two random walk models have been investigated: Krueger's noisy operator theory and Ratcliff's diffusion model. The
race model has not, until this point, been applied to data
from perceptual matching. Because ofthe number ofand
relationships between parameters in the random walk
and race models, the fast-same/false-different pattern of
data can be captured quite easily by both types of models. The issue, then, is whether both types ofmodels can
accommodate changes in RT and accuracy through reasonable changes in parameters . In the present sequence of experiments, we manipulated conditions designed to influence the rate ofinformation accumulation, as well as the thresholds for
same/different response selection.
Although both the race and the random walk models
may capture the relationship between speed and accuracy
in a single condition, to be considered adequate models
of behavior in choice response tasks, they must also be
TWO RESPONSE TIME MODELS
able to explain differences between conditions through
appropriate changes of their parameters. Townsend and
Ashby have called this the principle ofcorrespondent change. For example, a race model may be able to fit
the patterns in RT and accuracy under different levels of
response bias, but perhaps this account requires changes
in the parameters associated with accumulation rates.
This would be an unsatisfactory fit ofthe model, because
the mechanisms of the process require that thresholds,
not accumulation rates, change with bias.
In what follows, we discuss the random walk and race
models. We present the random walk models that have
already been proposed to account for matching data. We
also discuss the Poisson race model in some detail, because it has not previously been considered in this context. Then we present the results from three experiments
designed to test the models. Our analyses show that both
random walk and race models have some success accounting for the data. In particular, the Poisson race
model does at least as well as the diffusion model and provides a computationally simpler characterization of the
response selection process. Although we are concentrating only on perceptual matching in this paper, it should
be emphasized that we do not intend our results to be
limited to this paradigm. We hope, by presenting a comprehensive description ofour modeling efforts, to help guide
future research in other choice reaction tasks.
INFORMATION ACCUMULATION
Sequential sampling models have been studied extensively for simple and choice reactions, beginning with the
earliest counter models and random walk models . Occasionally,
the race and random walk classes of models have been
pitted against each other . In the following sections, we present several
sequential sampling models of response selection. We
focus, in particular, on the ral)dom walk models that have
been applied to matching and the race models that have
been applied to other types of choice response tasks.
Random Walk Models
Noisy operator theory. Krueger's noisy operator theory proposes that the presence of noise in the information-processing system perturbs stimulus features
with some small probability. Some differences will be perceived even between identical stimuli, but, on average,
same pairs will have fewer perceived differences than dif
ferent pairs. The comparison process must determine
whether the difference registered by a single glance at the
display (onepass) is large enough to conclude that the pair
is different. It counts the number ofmismatching features
between the two stimuli, rechecking or recounting when
the number ofmismatches is neither small enough to conclude same nor large enough to conclude different. The
VAN ZANDT, COLONIUS, AND PROCTOR
process keeps a count ofthe total number of differences
perceived over passes ofthe display. Because of the tendency for noise to make some same pairs look different,
different errors will occur more frequently, but different
stimulus pairs will be more likely to be rechecked, resulting in slower different RTs: the fast-same/false-different
Krueger's model can be characterized as a random walk in discrete state space (the number of mismatches) and discrete time (the number of passes). The
noisy operator theory differs from other random walk
models in that, on every pass, the distributions of the
number of perceived mismatches change according to
the number of differences perceived on the previous
pass. It is therefore nonstationary, and explicit expressions for the RT distributions have not been derived.
Krueger showed good fits ofthe model to the RT
histograms for several experimental conditions in singleand multielement matching. The model also predicted
the false-different pattern, although, in absolute terms,
the model predicted accuracies that were higher than
those observed.
The diffusion model. A diffusion model was proposed
by Ratcliff to explain RTs and accuracy in recognition memory. Since its first appearance, it has been applied to a range of tasks, including visual search , typing ,
detection , simple twochoice tasks , and
matching . The diffusion model assumes
that the process begins with no information about the appropriate response. Over time, stimulus properties drive
the information level up or down, toward one response
boundary or another (see Figure 1, top right). When the
information level reaches one ofthe two boundaries, the
process ends, and the response is selected according to
the boundary that was crossed.
This model was originally applied to matching with
sequential presentations, in which the two elements of a
stimulus pair are presented one at a time, imposing a
memory load on the process. The memory representation of the first stimulus (a letter string) is assumed to
decay over time. On presentation ofthe second stimulus,
the amount ofoverlap between the elements ofthe stimulus pair is computed. Pairs that are identical will overlap a lot, whereas pairs that are different will not overlap
as much. This overlap determines the rate at which evidence drifts toward one response boundary or the other.
Activation
,-------------u::IO
Z I"""+-----~'It;/_~~----t-__l
ht------------,---Ks = K D
Figure 1. The diffusion (top panel) and race (bottom panel) models. For the diffusion model, drift rates are randomly
sampled from one of two possible distributions, depending on the stimulus presented. In the race model, events are
recorded on two independent counters, with rates determined by the stimulus presented. Both models accumulate information until a threshold is exceeded (in the race model) or a boundary is crossed (in the diffusion model).
Ifthe overlap is less than some critical value (equal to zero
without loss of generality; see Figure I, top, left), the
state of the system drifts, on average, in the negative direction, toward the boundary for a different response. If
the overlap is greater than that critical value, the system
drifts in the positive direction, toward the boundary for a
same response. To account for the fast-samelfalse-different
pattern, the model assumes changes in the placement of
the response boundaries, as well as in the critical value
for the amount ofoverlap.
Some important characteristics of the diffusion process should be noted. It is the limiting case for a random
walk in which the time steps of the walk and the size of
the steps up or down become infinitely small. The position ofthe diffusion at any point in time is normally distributed, with a mean equal to the product of the drift rate
and time. In Ratcliff's applications ofthe diffusion model
 , the drift
rate is also a random variable, normally distributed with
some mean and variance. Each stimulus type (same and
different in the matching paradigm) gives rise to its own
drift rate distribution. For example, same pairs will give
rise to higher mean overlap than will different pairs. Determining a critical overlap value is, therefore, equivalent
to the placement ofa criterion in signal detection theory.
The RTs and accuracies predicted by the model are produced not by a single diffusion process, but by a mixture
of diffusions with varying drift rates.
The diffusion model has been applied to a wide range
ofchoice RT tasks, whereas the noisy operator theory is
a theory ofperceptual matching only. Moreover, the diffusion model is a well-studied and well-understood statistical process, whereas the noisy operator theory is a
nonstationary simulation model for which an explicit
mathematical characterization does not exist. Therefore,
we focused on the diffusion model in this paper.
Race Models
Race models were first explored by LaBerge 
and then by Pike . The
clearest distinction between a race and a random walk
model is the number ofmechanisms on which information
accumulates. For a random walk, information is summed
on a single mechanism and can increase and decrease
over a trial. Race. models assume that information toward
alternative responses accumulates in parallel and monotonically over the course ofa trial. The counters storing the evidence may be completely independent or correlated to some
degree . The first counter to
accumulate information to a threshold "wins" the race and
determines the response. To compare between the race
and the random walk (or diffusion) representations, it is
convenient to think of the random walk as reflecting the
momentary difference between two counters in a race. The
random walk, then, is equivalent to a race between two
perfectly and negatively correlated counters.
TWO RESPONSE TIME MODELS
Instance theory. Perhaps the most familiar example
ofa race model was presented by Logan in
his theory ofautomaticity. Logan proposed that the performance ofa task depends initially on an algorithm, or
series of steps, that takes the performer from the stimulus to a correct response. Each exposure to a stimulusresponse pair results in the storage ofan instance ofthat
pair in memory. The completion ofthe algorithm occurs
in parallel with the retrieval of the appropriate response
from memory. As more and more instances enter the
race, the more and more likely it is that the memory process will finish first. Skilled performance of a task thus
develops with practice and relies more heavily on the
memory ofparticular stimulus-response pairs than does
unskilled performance. Logan demonstrated good
fits of this model to the entire RT distribution and explained not only how the mean RTs decrease as a power
function of practice , but
also how the entire RT distribution decreases as a power
function ofpractice. Colonius discussed the mathematical assumptions of instance theory and more clearly laid
out the conditions under which the RT distributions can
change as they do .
Vickers' accumulator model. Another well-studied
model is Vickers' accumulator model, which
has been applied to psychophysical discrimination data
in expanded judgment tasks. In these tasks, partial information about a stimulus is presented to an observer at
time steps over the course of a trial. This paradigm is
motivated by the idea that sequential sampling models
accumulate information over time by repeatedly sampling from the stimulus or a mental representation ofthe
stimulus. So, for example, if an observer's task is to determine whether a presented tone is of a high or a low
frequency and if the perceptual effect of the tone varies
according to signal detection theoretic principles, sequentially sampling the tone gives rise to a series ofrandom perceived frequencies. One way to gain experimental
control over this process is to explicitly give the observer
a sequence oftones, each ofa random frequency selected
from a distribution with a high or a low mean.
The accumulator model assumes that the presentation
ofa stimulus sample results in a percept that is compared
with an internal referent (a criterion, as in signal detection theory). The difference between the stimulus and the
referent is added to one counter ifit is positive and to an
alternative counter ifit is negative. This difference is a random variable, normally or exponentially distributed. The model
operates in discrete time, like the standard random walk
and the noisy operator theory, and in continuous state
space. This model has been quite successful in accounting for RT distributions, accuracy, and confidence judgments in the expanded judgment task.
The Poisson race model. The Poisson race model, the
focus of attention in this paper, was originally proposed
by Pike and later generalized by Townsend and
VAN ZANDT, COLONIUS, AND PROCTOR
Ashby . It assumes that counters are independent
and accumulate evidence in parallel over the course of a
trial (see Figure I, bottom half). Evidence arrives at each
counter in unit increments and is summed until one counter
reaches a threshold level of information. The time between units is an exponentially distributed random variable, with some rate that depends on the stimulus. For
same stimulus pairs, the accumulation rate for the same
counter will be high, whereas that for the different counter
will be low. When a different stimulus pair is presented,
the rate for the different counter will be high, and the rate
for the same counter will be low. Because the time between units is exponentially distributed, the accumulation of counts is a Poisson process. The time to select a
response is determined by the time required for the fastest counter to reach threshold. It is a continuous time, discrete state process, in comparison with Vickers' 
discrete time, continuous state accumulator model and
the continuous time, continuous state diffusion model.
The race model can readily generate the fast-same/falsedifferent pattern through the relative differences between
rates ofaccumulation and thresholds ofthe two counters.
An important aspect of the Poisson race model is the
fact that the counters are represented by two renewal processes. A renewal process is one in which the interarrival
times (the times between the arrival ofinformation units)
are independent and identically distributed. So, the mean
and the variance of the interarrival times do not change,
regardless of the duration of the process or the number
of units that have arrived. Such processes typically are
used to describe patterns of events that occur over time,
such as light bulb replacements or traffic flow. The discrete state assumption, which follows from the idea that
information arrives in units and so an integer number of
these are accumulated, is made only for convenience and
can be relaxed without affecting any of the discussion
and results to follow .
The choice of the exponential as the interarrival time
distribution is not strictly necessary but can be defended
as a starting point. First, the exponential yields the computationally simplest case. Second, as was shown by
Khintchine and, more generally, by Grigelionis
 , under general conditions the superposition (i.e.,
the pooling of the output) of a number of renewal processes with arbitrary interarrival time distributions becomes a Poisson process when the number of contributing processes becomes very large. Ifa counter is thought
ofas a neural module receiving a flow of information arriving from many concurrent processes, the Poisson process provides an appropriate description of the behavior
ofthe accumulator mechanism over time. Finally, Ashby
 has shown that if the distribution of any processing time component in a sequence is exponentially distributed and if the other components are stochastically
independent and have nondecreasing hazard functions,
the RT hazard function must asymptote to a constant.
Most empirical RT hazard functions asymptote to a constant, consistent with the hypothesis that at least one
component of the process is exponential.
Besides choosing a different interarrival time distribution, there are various other ways to modify and/or generalize the basic Poisson race model that could be taken
into consideration . These
include the delayed process, in which unknown factors
(which might be incorporated into a residual or base
time) are included in the first interarrival time, a deadtime model, in which each counter is shut down for a
(possibly random) amount oftime after registering an arrival , and an imperfect model, in which,
with some probability 1C, each counter fails to register an
arriving bit of evidence. It turns out that 1C would not be
an observable parameter, because the only change in the
model would be that the accumulation rate would be reduced by a factor 1C. The delayed process is equivalent to
the case in which the residual time is a random variable
 -a reasonable assumption that would
create more than a few mathematical difficulties. The plain
Poisson race model is very flexible, and these variants of
the model should only be considered ifsuggested by empirical findings.
A final important aspect of the race model is the assumption that the counters act in a stochastically independent way. Interestingly, it turns out that the independence assumption is not that strong at all. Townsend
 and Marley and Colonius have shown that
if only the RT of the winner in the race and its identity
(i.e., the same or different counter) are observable, which
is the case when only RT and the response executed are
collected as data, any race between imperfectly correlated counters can be represented as a race between independent counters. This nonidentifiability result, owing
to the limited observability of the race, discourages any
elaborate modeling of some form of stochastic dependence between the counters in the absence of empirical
evidence to demand it.
The Poisson race (or, simply, race) model is presented
in this paper as an alternative to the diffusion model. The
race model has not been studied in any detail and yet has
much to recommend it. One primary appeal ofthe model
rests in the relative tractability of its mathematics. The
equations required to derive predictions from the diffusion model are complex, and it can be difficult to simulate . However, the purpose ofthis paper
is not to pit the two models against each other to show
that one is "right" and the other "wrong." Indeed, it may
not be possible to do so . The purpose of this
study is to demonstrate that the much discussed but
never tested race model is able to account for RT and accuracy data at least as well as the more complex diffusion model and, so, might be an attractive modeling option for perceptual matching, as well as for other
two-choice response tasks. The extent to which we can
discriminate between the race and the diffusion models
will be discussed later.
Having discussed sequential sampling models and their
application to perceptual matching, we will now present
data from three experiments. These experiments were designed to exploit the principle of correspondent change
 . Using this principle, we can
evaluate the race and diffusion models by examining how
parameters change with changes in experimental conditions, while simultaneously evaluating goodness of fit.
The equations describing the density and distribution
functions for each model, as well as accuracies, are given
in Appendix A.
EXPERIMENTS
Three experiments were conducted to determine
whether the race and the diffusion models can produce
the observed RT and accuracy patterns when the parameters of the models were constrained to vary in ways appropriate for the experimental conditions. In the first experiment, the behavior of the response thresholds was
examined under different levels of speed stress induced
by response deadlines. The hypothesis was that the observers should increase their thresholds when the deadline is increased. That is, as much evidence as possible
should be accumulated before a response is selected. Consequently, mean RT and accuracy should increase with
increasing deadline, as long as the observers know the
deadline for a given set of trials. The race model should
fit these data through elevations in the response thresholds,
and the diffusion model should fit these data through increases in the distances ofthe boundaries from the starting point of the process. If the deadlines are intermixed
within a set of trials, the observers should not be able to
adjust response criteria appropriately. The race model
and the diffusion model should fit these data with a single set ofparameters. For both experimental conditions,
the rate at which information accumulates should remain
constant over all deadlines.
In the second experiment, bias was manipulated by
varying the relative probability ofsame and different pairs.
When same pairs are more likely than different pairs, the
same threshold in the race model should be lowered, or,
equivalently, the different threshold should be elevated.
For the diffusion model, the starting point should move
closer to the upper (same) boundary when same pairs are
more likely and closer to the lower (different) boundary
when different pairs are more likely. The race model and
the diffusion model must be able to fit the data across bias
conditions with a single set of rate parameters and by
varying the thresholds in the appropriate directions.
The third experiment used different display conditions
intended to influence accumulation or drift rates. Letter
pairs were presented with different separations, increasing the distances ofeach letter from the fovea and increasing the rate at which spurious information accumulates
 . Under
these conditions, response thresholds should be elevated,
to avoid errors based on unreliable evidence. This eleva-
TWO RESPONSE TIME MODELS
tion should produce an increase in mean RT, owing to the
longer time required to accumulate evidence to criterion.
An increase in errors should be observed at the widest
separation at which the effects of perceptual noise and,
hence, the amount of spurious information are greatest.
For the race model, the rate parameters should, therefore,
increase for the "incorrect" counter and potentially decrease for the "correct" counter. For the diffusion model,
the drift rates should decrease as stimulus width increases.
When different stimulus conditions are presented in distinct sets oftrials, participants will adjust response criteria to compensate . To avoid such shifts
of criteria, stimulus conditions were intermixed within
sets oftrials. The race and diffusion models should, therefore, fit these data through changes in the accumulation
and drift parameters alone, using a single set of thresholds and boundaries for all conditions.
Participants. Three graduate students from Purdue University,
3 graduate students from The Johns Hopkins University, and 6 undergraduate students from Purdue University volunteered to participate in Experiments 1,2, and 3, respectively. The 6 Purdue University undergraduates participated to fulfill a course requirement.
Each participant was naive as to the purposes of the experiments
and had normal or corrected-to-normal vision.
Apparatus. All the stimuli were generated by and presented on
PC-style microcomputers running in text mode. The screens were
refreshed at a 60-Hz rate, and the stimuli appeared light on a dark
background. Stimulus onset and offset, deadlines, and intertrial intervals, as well as accuracy and RT information, were controlled
and recorded by software. All responses were made by pressing the
"Z" key in the lower left corner ofthe computer keyboard with the
left index finger (for same responses) or the "/" key in the lower right
corner of the computer keyboard with the right index finger (for
different responses).
Stimuli. The stimulus items were the letters "K" and "X," appearing in pairs. Thus, four displays were possible: K K, X X, K X,
and X K. Letters were presented in the center of the screen, separated by one or more blank spaces. A "-" centered immediately
below the blank spaces served as a warning stimulus and fixation
point. All the characters were composed ofpoints in a 9 X 8 matrix,
subtending a visual angle of 0.53° horizontally and 0.89° vertically
when viewed from a distarice of 33 cm. Experiments I and 2 used
only foveal displays, in which only a single space separated the letters and the entire display subtended 1.59° of visual angle. Experiment 3 also used parafoveal and peripheral displays, in which 8 and
16 blank spaces separated the letters. Parafoveal displays subtended
5.3° horizontally, and peripheral displays subtended 9.5° horizontally. A headrest was used in Experiments 2 and 3 to fix the viewing distance at 33 cm.
Procedure. A trial began with the presentation ofthe warning stimulus for 50 msec (in Experiments I and 3) or 500 msec (in Experiment 2). Immediately after the warning, the stimulus was presented
for 50 msec. The screen was then erased until a response was made.
In Experiments I and 3, response deadlines were imposed. After
each response, the RT was compared with the deadline. Ifthe RT was
less than the deadline, the screen remained blank until the deadline
expired, and then the RT was presented in the center of the screen
for 500 msec. The screen was again erased and remained blank for
an intertrial interval of I,000 msec. Ifthe RT was over the deadline,
the RT and the message "TOO SLOW" was presented immediately
after the response for 500 msec. The screen was then erased and re-
VAN ZANDT, COLONIUS, AND PROCTOR
mained blank for an intertrial interval of 1,000 msec. The participant was told how many responses had been made correctly and executed under the deadline 1,000 msec after the last trial in each
block. In Experiment 3, the deadline was always 1,000 msec. For
blocked sessions in Experiment I, when the deadline changed, the
deadline for the following block of trials was also presented. The
participant was also encouraged to take a short break. The first trial
of the next block began 3,000 msec after the participant pressed a
key, indicating readiness to begin. No feedback about response accuracy was presented until the end ofa block oftrials, when the participant was told how many responses had been executed correctly
and how many responses had been executed under the deadline.
In Experiment 2, no deadlines were imposed. After a response,
accuracy feedback was provided in the form ofa 500-msec tone for
incorrect responses. After feedback, a I,OOO-msec intertrial interval
ensued, followed by the warning signal for the next trial.
Design: Experiment 1. The participants performed for 12
sessions on different days. There were 6 mixed and 6 blocked presentation sessions, which alternated each day, beginning with the
mixed session on the Ist day. The first 2 days were considered practice, and practice data were not included in any analysis. Each session was composed ofnine subblocks of 108 trials, for a total of 972
trials per session. For blocked sessions, the nine subblocks were
grouped into three blocks of each deadline (500, 750, and
1,000 msec). The three deadlines were presented in a different random order each day. Before each block, the participant was told
what the deadline would be for the next three subblocks of trials.
For mixed sessions, each subblock was composed ofan equal number (36) of 500-, 750-, and I,OOO-msec deadline trials, pseudorandomly intermixed. The participant was not told what the deadline
would be on any trial. For both mixed and blocked blocks, an equal
number (27) ofeach display type was presented, giving 54 same and
diffirent trials in each block.
To ensure a relatively uniform distribution of display types and
deadlines across the trials in a mixed block, each subblock was further divided into nine smaller sets of 12 trials. Within each 12-trial
set, each display was presented at each deadline in a random order.
This strategy ensured that the participants would not change their
expectations toward the end ofa block because of, say, a large number of I,OOO-msec deadline trials that occurred at the beginning of
the block. The same strategy was used for blocked trials, except that
the deadline was the same for all the trials within the 12-trial set.
Each display type was presented three times within each set in a
random order.
Design: Experiment 2. The participants performed for five sessions on different days. Each session was composed ofthree blocks
of 360 trials, one at each level of bias (in a different random order
each day). The participants were informed of the number of same
versus different pairs before each block. Under different bias, 80%
(288 of360) of the trials were different pairs. Under no bias, same
and different pairs were equally likely (180 trials each). Under same
bias, 80% of the trials were same pairs. The first and last 36 trials
of each block were not included in any analysis. Thus, there were
1,440 trials in each bias condition.
Design: Experiment 3. All three display widths were presented
within blocks. The participants performed three blocks of 324 trials each day across a period of4 days. Each display type and width
was presented equally often within a block. The first two blocks performed on the Ist day were not included in the analyses, for a total
of3,240 trials, 1,080 trials with each display width.
We will now discuss the results ofthe experiments in
terms ofthe mean RTs and accuracies. Because these results are not the focus of this article, we do not present
the statistics of the tests that we performed. Any effects
noted were significant (p < .05).
In Experiment 1, mean correct RTs and accuracies
increased with increasing deadline in the blocked condition (386,443, and 462 msec and .87, .94, and .95 proportion correct for the 500-, 750-, and 1,000-msec deadlines, respectively, averaged over participants). In contrast,
few differences were observed over the three deadlines
for the mixed condition (396, 397, and 396 msec and .88,
.88, and .87 proportion correct for the 500-, 750-, and
1,000-msec deadlines, respectively, averaged over participants).
Only Participant 3 showed a fast-same effect of 19 msec,
whereas Participants 1 and 2 showed no such effect. Participants 1and 2 also showed no effect ofpair type on accuracy of responding, whereas Participant 3 did in the
mixed condition. In this condition, his false same responses outnumbered his false different responses, indicating a bias to respond same (.21 and .16 for false same
and different responses, respectively). The data for the
3 participants, therefore, did not show strong effects ofpair
type on efficiency ofperformance. The simultaneous increase in mean RT and accuracy with increasing deadline when deadlines were blocked is consistent with an
adjustment ofthresholds upward or away from the starting point of the accumulation process.
In Experiment 2, accuracy decreased and mean correct
RT for different responses increased as bias shifted from
predominantly different to predominantly same (496,536,
and 603 msec and .98, .94, and .83 proportion correct for
the 20%, 50%, and 80% bias conditions, respectively, averaged over participants). This pattern was reversed for
same responses (573,545, and 474 and .87, .94, and .97
proportion correct for the 20%, 50%, and 80% bias conditions, respectively, averaged over participants). These
results are consistent with an adjustment of the same
threshold downward or toward the starting point and of
the different threshold upward or away from the starting
point as the number ofsame pairs increases.
Participants 2 and 3 demonstrated an overall fast-same
effect. The size ofthis effect was 44 msec for Participant 2
and 35 msec for Participant 3. There was a tendency for
a fast-same effect for Participant 1 (7 msec). Only Participant 1showed any main effect ofpair type on accuracy;
her responses to same pairs were more accurate (.95) than
her responses to different pairs (.92), which indicates a
bias to respond same, and not a false-different effect.
In Experiment 3, accuracy decreased, whereas mean
correct RT increased, with increases in the width of the
displays (545, 575, and 591 msec and .94, .89, and .82
proportion correct for the 1.5°,5.1°, and 9.5° displays, respectively, averaged over participants). All the participants
save one showed a fast-same effect, which was particularly pronounced for the IS displays. All the participants save one showed a false-different effect at all
widths, but it was greatest for the 9.5° displays: Responses
to same stimuli were less accurate than responses to different stimuli. The increase in correct mean RTs with increasing display width is consistent with a decrease in
the rate ofaccumulation. It cannot be due to an elevation
in the thresholds alone, because threshold adjustments
would lead to a corresponding increase in accuracies. Accuracies were decreasing, however, suggesting that the
incorrect accumulation rate was increasing as the correct
accumulation rate was decreasing. In the diffusion model,
this would correspond to both same and different mean
drift rates converging toward zero.
This pattern of effects is consistent with Krueger's
 noisy operator theory. If participants elevate the
different threshold, relative to the same threshold, to compensate for the perceptual noise in the wider displays, the
same responses should be faster than the different responses when the evidence is less noisy, as in the 1.5
0 displays. When the quality of the evidence deteriorates as
stimuli are moved into the periphery, perceptual noise
would tend to make all the pairs look different. Thus, an
increase in false-different errors should be observed. This
is consistent with the finding that whereas the fast-same
effect was present for the foveal displays, false-different
errors predominated in the peripheral displays.
Discussion
Over the three experiments, each manipulation (deadlines, bias, and stimulus width) resulted in a unique pattern of effects between mean RTs and accuracies. With
increasing response deadline, both mean RTs and accuracies increased. With changes in bias from differentto
same, mean RTs and accuracies increased for the different response and decreased for the same response. With
increasing stimulus width, mean RTs increased, and accuracies decreased. There was no clear fast-samelfalsedifferent pattern in these data, probably owing to several
factors, including the fact that the fast-samelfalse-different
pattern is stronger and more reliable with successive than
with simultaneous presentation and that the participants received extensive
practice responding to a small set ofstimulus pairs. Therefore, we will not discuss the fast-samelfalse-different effect in the analyses to follow.
The stimulus presentation was very brief. This ensured
that the observers would make a significant number of
mistakes and that eye movements would not be possible.
This also implies that the process of information accumulation in which the observers engaged could not be
based on the physical stimulus but, rather, on an internal
representation of that stimulus. For the fits of the models, we made the simplifying assumption that the stimulus representation did not decay over time. For the race
model, the decaying representation is fairly easy to implement, however (Smith & Van Zandt, in press).
The race model and the diffusion model will now be fit
to these data, in an attempt to recover the RT distributions
and accuracies through adjustments of the appropriate
parameters. These fits will be contrasted with fits achieved
TWO RESPONSE TIME MODELS
through inappropriate adjustments of the parameters. It
will be demonstrated that both models fit the RT distributions when the parameters are appropriately constrained,
although the diffusion model has difficulty fitting both
the RT distributions and the accuracies.
FITTING THE
RACE AND DIFFUSION MODELS
In this section, we investigate the diffusion and race
models by way of their fits to the entire RT distribution
and the accuracy data. The experimental conditions were
such that the primary change in parameters should be localized to response thresholds for Experiments 1 and 2,
and to accumulation rates in Experiment 3. The general
procedure used for fitting the models will first be outlined, followed by the results ofthe fits and an interpretation of the parameters.
To fit any model, several choices must be made, including what aspect ofthe data should be used to fit the model
(the data summary), what objective function should be
minimized, and which algorithm should be used for the
minimization procedure. We will discuss each of these
choices in turn and then describe how these choices were
applied to the data.
The Data Summary
There are a number of alternatives regarding the data
summary to which the models could be fit. For example,
Ratcliff routinely fits the diffusion model to RT
quantiles smoothed by an ex-Gaussian distribution. The
ex-Gaussian is the distribution ofthe sum ofan exponential and a normal random variable, and it has been shown
to provide excellent fits to most empirical RT densities
 . To fit the diffusion model, Ratcliffgenerates its density function for a
set ofparameters and fits a second ex-Gaussian density to
the diffusion density. His strategy is to vary the parameters
of the diffusion so that the ex-Gaussian parameters estimated from the diffusion are as close as possible to the ex-
Gaussian parameters estimated from the data. This roundabout way offitting the diffusion has been very successful
and results in a smooth, well-behaved objective functionthe sum of squared deviations between the data-derived
and diffusion-derived ex-Gaussian parameters.
This procedure was attempted at first and then abandoned, because the ex-Gaussian did not fit the densities
well for several participants. Despite the past success of
the ex-Gaussian distribution, this result is not particularly
surprising. In Experiment 1, for example, the empirical
densities at the 500-msec deadline showed very little skew,
and the ex-Gaussian is a positively skewed distribution (see
Figures 2 and 3). Fits of the models' density functions
were also attempted directly to histogram and quantile estimates ofthe density function, but good fits were difficult
VAN ZANDT, COLONIUS, AND PROCTOR
...... Unconstrained
-Appropriate
---Inappropriate
Figure 2. Predicted densities ofthe unconstrained, appropriate, and inappropriate race models (dotted, solid, and dashed lines,
respectively) and the observed densities (open symbols) for Participant 1 for each deadline in the blocked condition ofExperiment 1.
The deadline (500,750, or 1,000 msec) is noted on each panel. Correct diffrrent response times (RTs) are presented on the left, and
correct same RTs are presented on the right.
to achieve with these estimates (see Van Zandt, in press-a).
Similar problems were encountered with maximum likelihood techniques.
For the experiments presented above, the models' distribution functions were fit to the deciles ofthe RT distribution . For each condition and
display type, the RTs corresponding to the Oth, 10th, ... ,
90th, and lOOth percentiles were computed by linear interpolation. An empirical estimate of the distribution
function is, therefore, provided by F(t;) = .Ii, i = 0, I,
... , lO for each quantile to, tl, t2, ... ,tlO • Van Zandt (in
press) has shown that fits of distributions to quantiles
yield more accurate parameter estimates at smaller sample sizes than do fits to any density estimate and that the
accuracies of the estimates were generally comparable
with those obtained by using maximum likelihood. Finally,
and most important for our purposes, fits to the deciles
worked when all else failed.
The Objective Function
The objective function to be minimized by the fitting
algorithm was the next decision that had to be made, although our choices were limited by the data summary we
selected. Among possible options were the sum ofsquared
deviations between the predicted (F) and the observed
(F) percentiles
and the X2 goodness-of-fit statistic
{.lO - [F(ti+l) - F(t;)]}
x2 = NL; -"-----------''--
F(ti+l) - F(t;)
where N is the number of responses used for the estimate F. In addition, to fit both the distribution and the
mean RTs and accuracies simultaneously, some function
ofthe difference between the predicted and the observed
means and accuracies had to be included in the objective
function. For the fits of the distribution, either the sum
ofsquared error or the X2 statistic was used, and to this was
added the sum of squared errors for the correct and incorrect mean RTs, plus the sum ofsquared errors for the
same and different response probabilities, weighted by
the number oftrials. The number oferror responses was
too small to fit the error RT distributions directly.
TWO RESPONSE TIME MODELS
12 r--,-----,....----,-----,-----,r------,
12 r--,-----,....---,---....,..-----,----,
.. ·····Unconstrained
-Appropriate
---Inappropriate
oL---L._rllt-":'-:--.:::::3~--..--..L------I
12 r---,----....----,-----,----r------,
oL--:-:---4I~~_~~_~__...__
12 r--,----....----,------,------,....----,
o L--.J.._.....~--.:lil!III........._
...._-....I..----J
oL---'---4J£--I-_-=-......_-'----.l.------.J
12 r--,-----,....---,---....,..-----,----,
oL-....--:'-::---4!~":'-:--.:ll!!lII--.__.._--'-------I
12 r--,-----,....----,-----,-----,r------,
Figure 3. Predicted densities ofthe unconstrained, appropriate, and inappropriate race models (dotted, solid, and dashed lines,
respectively) and the observed densities (open symbols) for Participant 1 for each deadline in the mixed condition ofExperiment 1.
The deadline (500, 750, or 1,000 msec) is noted on each panel. Correct different response times (RTs) are presented on the left, and
correct same RTs are presented on the right.
The probabilities were weighted to ensure that a large
part ofthe minimization routine was concentrated on fitting the probabilities. When the X2 statistic was used as
the objective function for the distributions, weighting the
probabilities by the number of observations put the X2
statistic and the squared difference ofprobabilities on an
equivalent scale, so that the size of the X2 statistic did
not swamp the contribution ofthe probabilities to the objective function.
We considered both the sums ofsquared errors and the
X2 statistics for the distribution fits because, for different
data sets, one or both of these functions could be either
well behaved or very unstable. That is, although the surface of the function defined by the sum of squared errors for one participant may be relatively smooth and
promote rapid convergence to a global minimum and a
"good fit," that same objective function for a different
participant's data or for a different model may not yield a
good fit. The goal ofthe fits was to find parameter values
for each model that resulted in a small X2 statistic. Because
using the X2 statistic itselfas an objective function proved
to be computationally difficult in some circumstances,
the more simple sum ofsquared errors was used when possible; minimizing this function often minimized the X2
statistic also. This was true most often for the race model.
When the sum ofsquared errors did not yield low X2 values, the X2 statistic itself was minimized. For the diffusion model, direct X2 minimization proved to be most effective, because minimizing the sums ofsquared errors did
not generally yield low X2 statistics and did not recover
the observed means and accuracies.
Frequently, it proved to be impossible to fit both the
RT distributions and the response probabilities simultaneously. In this circumstance, the objective functions
without the weighted sums of squares of mean RTs and
probabilities were fit, resulting in small X2 values but significant failures to recover the response probabilities. This
phenomenon was extensively explored and will be discussed below.
The Algorithm
The final decision concerned the algorithm to be used
to minimize the objective function. There are many minimization routines we could have used, including STEPIT,
simplex, genetic algorithms, simulated annealing, gradient descent, the secant method, and so forth, and we tried
VAN ZANDT, COLONIUS, AND PROCTOR
several ofthese. After a great deal ofexploration, we devised an iterative simplex routine. A downhill simplex
algorithm was the workhorse ofthe minimization procedure. A simplex is an N-dimensional geometric figure with N + I vertices; for N = 2, a simplex
is a triangle. In the minimization problem, N is the number ofparameters ofthe model to be fit. Every vertex of
the simplex represents a possible set of solutions for the
N parameters. The objective function is evaluated at each
vertex, and the simplex reflects, expands, and contracts itself around the vertex that gave the lowest value of the
objective function. When a minimum is found, the N + 1
vertices ofthe simplex converge, and the simplex shrinks
to a single point.
For the iterative simplex, an initial set ofstarting values
was selected, and the simplex converged to a (possibly
local) minimum value of the objective function. The obtained parameters were then perturbed by some random
amount, to construct the vertices of a new simplex oriented around the newly found minimum. The simplex
then converged again to a (possibly new) minimum. This
process was repeated from as few as 6 to as many as 40
times, and on each iteration, the standard deviation ofthe
perturbations increased. Thus, the volume ofthe simplex
increased with each iteration, covering a larger and larger
region of the parameter space. The overall effect is not
unlike simulated annealing. After simplex found a local
minimum, the iterative process attempted to "shake" the
function into a still lower region of the parameter space
by increasing the volume ofthe simplex.
A great amount of effort was expended in arriving at
the best-fitting parameter values for each ofthe models.
It is important to recognize that a fit is a fit, regardless
of the method used to achieve it. Other routines, objective functions, or overall strategies may produce better
fits or worse fits. An important consideration of the fitting method is the properties of the recovered parameters. If the errors between the model and the observed
distribution function are normally distributed with equal
variance, methods ofleast squares (fits that minimize the
sum of squared deviations between the model and the
data) ensure that the parameter estimates are unbiased
(on average, they equal the true parameter values) and
have minimum variance. Minimizing the X2 and sums of
squared errors are both consistent with methods of least
squares, and the quantiles of the empirical distribution
are normally distributed random variables. However, we
also added the sum ofsquared error ofthe mean RTs and
accuracies to the X2 or sum of squared error, so we cannot be assured ofunbiased estimates. We checked the accuracy ofthe recovered parameters in a simulation study,
which we will discuss later, to verify that these procedures were able to recover race and diffusion parameters
under a range of conditions.
Another problem is knowing that the sum of squared
error has actually been minimized. Searching complicated
parameter spaces is something of an art, and there is no
way to be sure that the minimum found in such a space
is local or global. Therefore, caution must be exercised
when attempting to make comparisons between models,
especially when one seems to fit the data and the other
does not. Just because a good fit has not been found for
a particular model does not mean that one does not exist.
We took several steps to ensure that we could make comparisons between the models. First, we computed more
than one goodness-of-fit statistic. The fact that the X2
statistic was minimized in the fitting routine precludes
its use as an objective goodness-of-fit measure, although
this is fairly standard practice . Also, the X2 statistic is notoriously sensitive to
large sample sizes and will tend to be "significant" even
when no interesting differences exist between observed
and expected values. Therefore, we also computed
Kolmogorov-Smimoffand the root-mean squared (RMS)
statistics. The Kolmogorov-Smirnoff goodness-of-fit
test is a nonparametric test ofthe difference between two
distribution functions. Unfortunately, like the X2 statistic, it is not optimal for our purposes. The Kolmogorov-
Smirnoff test loses power when the parameters of the
theoretical distribution are unknown or estimated, and
the asymptotic behavior ofthe statistic is unknown . A better statistic, as we will demonstrate, is
the RMS. The RMS is a statistic representing lack offit,
commonly used in structural equation modeling . Also, we searched the
parameter spaces extensively before each fit, so that the
best possible starting values could be used. When possible (for the race model), the maximum-likelihood estimates of the parameter values also were calculated and
used as starting values in the minimization.
Finally, as we mentioned above, we conducted a study
in which each model was simulated and then each model
was fit back to the data from each simulation. Not only
does this procedure verify the accuracy ofthe fitting routines, it also gives an indication ofwhat a bad fit really is.
When a model that is known to be wrong is fit to a data
set, the ways in which it fails can give insight into the fits
of the model to a data set where the underlying process
is unknown. For example, if the model consistently fails
to fit the accuracies, that same model's failure to fit the
accuracies for an empirical data set might then be diagnostic ofa general failure of the model.
For each participant's data, the correct RT quantiles
for same and different stimuli for each condition were computed, using linear interpolation, as was described above.
For each fit, the same and different distributions, mean
correct and incorrect RTs, and same and different response
accuracies were fit simultaneously. To each data set, the
race and diffusion models were fit, and for each model,
three conditions were examined. In the first condition, all
the parameters were free to vary across the three experimental conditions to produce the best fit possible (unconstrained fits). In the second condition, only the threshold
parameters were allowed to vary, consistent with experimental conditions that would produce changes in response bias or in the total amount ofinformation required
for a decision (Experiments 1and 2; rate-constrained fits).
In the third condition, only the rate parameters were allowed to vary, consistent with experimental conditions that
would produce changes in the quality or the amount ofinformation available for each response (Experiment 3; biasconstrained fits).
There are seven important parameters in the race model:
the two criteria K s and K o, one for the same and the
other for the different counter; four rates, Ai}' where i =
S, D andj = S, D for the stimulus and counter, respectively; and a residual time Ter encompassing those processes of encoding and response not represented in the
race model. In the unconstrained fits, there are values for
Ks' Ko' ADS' ADD, Aso' ASS, and Ter for each response
deadline, bias, or stimulus condition (a total of 7 X 3 =
21 parameters). For rate-constrained fits, where only
bias is free to vary across condition, the rates and Ter are
the same for each condition, and the thresholds Ks and
KD change (a total of 5 + 2 X 3 = 11 parameters). For
bias-constrained fits, only rates vary across condition,
while thresholds and Ter are constant (a total 00 +4 X 3 =
15 parameters). In the mixed condition in Experiment I,
an additional constraint was imposed on the thresholds:
in the rate-constrained fits, the thresholds also were held
constant (a total of7 parameters).
There are six critical parameters in the diffusion model.
The early stage of the model requires the means of the
drift rate for each stimulus type (-~o and ~s) and their
TWO RESPONSE TIME MODELS
variance (1}2). The diffusion process requires two additional parameters, a and z, the upper boundary to respond
different and the starting point of the accumulation process. Finally, there is a residual or base time component
Ter • In the unconstrained fits, there are values for a, z,
~D' ~s, 1}2, and Ter for each response deadline, bias, or
presentation condition (a total of6 X 3 = 18 parameters).
For rate-constrained fits, where only a and z are free to
vary across condition, the same drift rate values and Ter
are used for each condition, and three pairs ofvalues for
a and z are used (a total of4 + 2 X 3 = 10 parameters).
For bias-constrained fits, only drift rates vary across condition, while a, Z, 1}2, and Ter are constant (a total of 4 +
2 X 3 = 10 parameters). In the mixed condition in Experiment I, an additional constraint was imposed on a and
z: In the rate-constrained fits, these also were held constant (a total of6 parameters). The diffusion coefficient,
s2, is not an identifiable parameter for individual fits (although the ratio oftwo diffusion coefficients is) and was
set to O.l-a value consistent with Ratcliff's early
fits of the diffusion model.
For the diffusion model, all the parameters were entered
into the simplex simultaneously. For the race model, a
grid search was performed over all pairs ofthreshold values, beginning from Ks = 1, Ko = I. The iterative simplex
operated at each grid point, and threshold values were
chosen that yielded the smallest objective function. The
data from each experiment will now be considered separately, and the fits of each model will be discussed in
turn. At the end ofthe discussion ofeach experiment, the
overall findings will be summarized, and the two models
will be compared. It will be shown that both models fit
the RT distributions well and that both models performed
Parameter Values and X2 Statistics ofthe Appropriate Race Model
for Each Participant (P) in Each Condition of Experiment J
Note-Deadlines (Dead) are given in milliseconds. Significance levels for rate-constrained fits are calculated
using 14 degrees of freedom for the blocked condition and 16 degrees of freedom for the mixed condition.
lp < .001.
VAN ZANDT, COLONIUS, AND PROCTOR
well when the parameters were constrained. However, the
diffusion model had significant difficulty in explaining
both RT distributions and response accuracy.
Experiment 1
In Experiment 1, conditions were such that, ifan accumulation process was responsible for the participants'
performance, the participants should adjust thresholds
upward or away from the starting point ofthe process as
deadline increased across blocks. The critical models in
this case are those that are rate constrained. That is, rate
should not vary across experimental conditions to account
for the data. The rate-constrained fits are, therefore, appropriate for this experiment, and bias-constrained fits are,
therefore, inappropriate. In the following sections, we present in some detail the results ofthe appropriate fits and
discuss more briefly the results ofthe inappropriate and
unconstrained fits.
The Race Model
Response time distributions. Unconstrained, appropriate, and inappropriate fits ofthe race model are shown
for one typical participant (Participant I) in Figures 2
(blocked deadlines) and 3 (mixed deadlines). It is difficult
to distinguish between the three fits on these plots because,
overall, the fits were all reasonable and very similar.
The best-fitting parameters and X2 statistics for the
appropriate fits are presented in Table 1. 1The parameters
change in sensible ways across the three deadline conditions: The accumulation rates for the different counter
when the stimulus pair was different (ADD) are larger than
the accumulation rates for the different counter when the
stimulus pair was same (Aso), and a similar pattern holds
for the same counters. In the blocked condition, the thresholds KsandKo are smallest under the 500-msec deadline
and increase as the deadline increases. In the mixed condition, a single pair of thresholds accounts for performance under all three deadlines, consistent with the hypothesis that the participants would be required to operate
under the same thresholds for all deadlines if the deadline for each trial is unknown. In contrast, the parameters
recovered from unconstrained and inappropriate fits do
not vary in sensible ways, given the conditions ofthe experiment and the hypothesized mechanisms of the race
model (see Appendix B).
The total X2 statistics for all fits, summed over deadline
and display type, are given in Table 2. The differences between the observed and the theoretical distributions
shown in Figures 2 and 3 are small, but most ofthe X2 statistics show significant differences between the observed
and the theoretical distributions, even for the appropriate
fits (see note 1). This may be because ofthe sensitivity of
the X2 statistic to large sample sizes. In Table 3 are presented the Kolmogorov-Smirnoffstatistics for all the fits.
For unconstrained fits, none of the deviations was large
enough to reach significance, despite the large X2 values
given for these fits in Table 2. The Kolmogorov-Smirnoff
statistics show that although there are some failures of
the model in the blocked conditions, there are no interesting differences at all in the mixed condition. The deviations, although significant, are small in light ofthe abil-
Overall X2 Goodness-of-Fit Statistics for Each Model Fit
to Each Participant's (P) Data in Experiments 1,2, and 3
and Also for Each Model Fit to Each Simulation
Experiment
Simulations
Note-Simulations I and 2 are rate- and bias-constrained race models, respectively,
and Simulations 3 and 4 are rate- and bias-constrained diffusion models, respectively.
Unc, unconstrained; App, appropriate; Inapp, inappropriate; B, blocked; M, mixed.
lp < .001.
TWO RESPONSE TIME MODELS
Kolmogorov-8mirnoff Statistics and Significance Levels for the
Unconstrained (Unc), Appropriate (App), and Inappropriate (Inapp)
Race and Diffusion Model Fits for Each Participant (P) in Experiment 1
Note-Significance levels are calculated from the sample sizes (N) and critical values D 05 = 1.36/VN and
DOl = 1.63/VN. Deadlines (Dead) are given in milliseconds.
ity of the model to capture the gross aspects of the RT
distributions. Recall, however, that the power of the
Kolmogorov-Smirnoff test is reduced because of estimated parameters.
One issue regarding comparisons between the different fits is whether the appropriate and inappropriate fits
of the race model accounted for any more or less of the
variance than did the unconstrained fits. The unconstrained model had the most parameters, and so it fit the
best. This was confirmed with likelihood ratio tests . In the majority of cases, both the appropriate and the inappropriate fits accounted for significantly
less variance than did the unconstrained fits. Unfortunately, there is no good way to determine whether the appropriate model fit more or less well than the inappropriate model. This is because, although the appropriate
and inappropriate models are nested within the more general unconstrained model, they are not nested versions
of each other, and neither are they independent. This
means that their respective X2 statistics are not independent, eliminating the possibility offorming an F-ratio to
test for equality. Furthermore, they have different numbers ofparameters, and so the X2 statistics cannot be directly compared. Similar issues arise when we attempt to
compare the fits of race and diffusion models. We will
discuss this issue shortly, when we present the results of
the RMS analysis.
Means and accuracies. The parameters recovered
from the fits were used to calculate the predicted mean
correct and incorrect RTs and accuracies. These means
were plotted against the observed means, and the result
is shown in Figure 4. The correct RTs were fit well by all
three models. The accuracies were also well fit by the
unconstrained and appropriate models. The inappropriate model, shown by the open triangles, had more difficulty accounting for the accuracies.
VAN ZANDT, COLONIUS, AND PROCTOR
The Diffusion Model
Response time distributions. Unconstrained, appropriate, and inappropriate fits of the diffusion model are
shown for Participant I in Figures 5 and 6. As for the race
model fits, it is difficult to distinguish between the three
fits on these plots because, overall, the fits were reasonable and very similar. There are, however, notable failures
of the appropriate model.
The best-fitting parameters and X2 statistics for the appropriate fits are presented in Table 4. The parameters
change in sensible ways across the three deadlines in the
blocked condition: Although the drift rates are constant,
the boundaries a and z are smallest under the 500-msec
deadline and increase as the deadline increases. In the
mixed condition, a single pair of boundary values accounts for performance under all three deadlines. In contrast, the parameters recovered from the unconstrained
and inappropriate fits do not vary in sensible ways (see
Appendix B).
The total X2 statistics for all fits, summed over deadline
and display type, are presented in Table 2. Unlike the race
model fits, there are few significant differences between
observed and theoretical distributions. The Kolmogorov-
Smimoff statistics (see Table 3) show that although the
appropriate model failed for Participant I, there are no
large differences between the observed and the predicted
distributions for Participants 2 or 3. The deviations from
the observed distribution for Participant I are quite large
and raise some concern about the viability of the appropriate diffusion model for this participant.
Likelihood ratio tests again were used to determine the
relative goodness of fit of the constrained and unconstrained models. As for the race model, nearly all of the
All three models have difficulty predicting incorrect
mean RTs. The predicted mean incorrect RTs were consistently slower than the observed mean incorrect RTs.
Sometimes, the race model is criticized for being unable
to predict error RTs that are faster than correct RTs. This
criticism is invalid for the models we are investigating
here, because neither the thresholds nor the rates are
constrained to be equal .
(Note also the predicted error RTs less than 350 msec,
which are faster than any of the predicted correct RTs.)
The failure ofthe models to accommodate fast error RTs
is not, therefore, attributable to a shortcoming ofthe race
model in general. Rather, it is possible that something
else (variability in the starting point ofthe accumulation
levels or "fast guesses") is producing fast incorrect responses that decrease the mean. There is a strong linear
relationship (r = .92) between observed and predicted
error RTs for the appropriate model, a pleasant surprise
given that error RTs were not given much consideration
in the fits ofthe model. The inappropriate model produced
the error RTs, shown as open lriangles, that were less well
correlated with the observed error RTs (r = .73).
Observed Probability
Observed Incorrect RT (in s)
1,---,----,-----t'8---r---/i,\_,,
.75 =_---'__----'-__--L__-'-_-----J
0.3 "'-_--'--__.L.-_--'--__'---_---'-_...........l
Do Inappropriate
o Same - Appropriate
<> Different - Appropriate
• Unconstrained
Observed Correct RT (in s)
Figure 4. Predicted probability of a correct response (top
panel), mean correct response times (RTs; middle panel), and
mean incorrect RTs (lower panel) of the unconstrained, appropriate, and inappropriate race models (dots, open squares and
diamonds, and open triangles, respectively) versus the observed
probability, mean correct RTs, and mean incorrect RTs for each
participant, deadline, and condition of Experiment 1.
TWO RESPONSE TIME MODELS
········Unconstrained
-Appropriate
---Inappropriate
Figure 5. Predicted densities ofthe unconstrained, appropriate, and inappropriate diffusion models (dotted, solid, and dashed
lines, respectively) and the observed densities (open symbols) for Participant 1 for each deadline in the blocked condition of Experiment I. Correct different response times (RTs) are presented on the left, and correct same RTs are presented on the right.
constrained fits accounted for significantly less variance
than did the unconstrained fits. We will discuss the goodness of fit for the appropriate versus the inappropriate
fits below, when direct comparisons are made between the
race and the diffusion models.
Means and accuracies. The parameters recovered
from the fits to the distribution functions were used to calculate the mean correct and incorrect RTs and accuracies.
These means were plotted against the observed means and
the result is shown in Figure 7. As for the race model, the
correct RTs are fit well by all three models. Unlike the
race model, the observed incorrect RTs are not too fast;
the predicted and observed mean incorrect RTs are about
equal. However, the predicted and the observed mean incorrect RTs are not as well correlated for the diffusion
model as for the race model (for the race model, r = .84,
and for the diffusion model, r = .68). Unlike the race
model fits, there is no significant failure ofthe inappropriate model for the means. The inappropriate diffusion
model does as well as the appropriate diffusion model at
predicting the means.
Unlike the race model, the diffusion model fails to predict the accuracy data. Whereas accuracy varied from 75%
to 99%, parameters recovered for the diffusion process
produced accuracy close to 100% for each participant,
condition, and model. Because the diffusion model has
been quite successful at accounting for accuracy and RT
data in the past , we
explored this failure of the model at great length. Many
different starting values for the parameters were used in
the iterative simplex algorithm. Stepwise fits were attempted, in whiCh the values ofthe boundary parameters
were fixed to guarantee fits ofthe accuracies and the drift
rates and variance were then free to fit the distribution.
A genetic algorithm, which does not rely on finding good
starting values, was also used.2 Both sums ofsquared errors and X2 statistics were used as objective functions.
Other objective functions were tried. For all ofthese options, it was determined that either the distributions could
be fit well at the expense of the accuracies or the accuracies could be fit well at the expense ofthe distributions.
To attempt to map out the objective function and determine why the diffusion model fits were failing, we entered the accuracies and the distributions into the overall
objective function separately. The distribution objective
function was the X2 statistic, and the accuracy objective
function was the sum ofsquared differences between the
observed and the predicted accuracies, multiplied by
VAN ZANDT, COLONIUS, AND PROCTOR
Unconstrained
-Appropriate
---Inappropriate
Figure 6. Predicted densities ofthe unconstrained, appropriate, and inappropriate diffusion models (dotted, solid, and dashed
lines, respectively) and the observed densities (open symbols) for Participant 1 for each deadline in the mixed condition of Experiment 1. Correct different response times (RTs) are presented on the left, and correct same RTs are presented on the right.
their sample sizes. With equal weights on both the distribution and the probability functions, simplex did not minimize on the basis ofaccuracy. The distributions were fit
well, and predicted accuracy was always very close to
100%. As the weight given to accuracy increased, relative to that given to the distributions, the results remained
the same; even the best-fitting parameter values were almost equal, until a critical point. At this point, accuracy
was fit perfectly, but the distribution fits were very poor.
No relative weighting could be determined that resulted
in intermediate fits to both probabilities and distributions. The fact that this occurred with several objective
functions and several minimization routines suggests that
it is not simply the choice offitting techniques that caused
the diffusion model to fail.
Comparing the Race and the Diffusion Models
Both the race model and the diffusion model fit the RT
distributions well. When the parameters were constrained,
the race model accounted for RTs in conditions in which
the thresholds were both increasing and constant. The
diffusion model also fit the RT distributions well when
appropriately constrained. The race model had difficulty
fitting the incorrect mean RTs, although the predicted
values were highly correlated with the observed values.
The diffusion model did no better. The most puzzling failure was the diffusion model's inability to predict the accuracy data and the RT distributions simultaneously.
Many techniques were used to try to find parameter values for the diffusion model that would accommodate these
data, but none was successful.
Both models did well overall, and both models had
strengths and weaknesses. It is difficult to determine from
these data whether one model did "better" than another.
Similarly, it is difficult to discriminate between the appropriate and the inappropriate fits for a particular model. Although the appropriate race model accounted for accuracies and RT distributions, the appropriate diffusion
model's fits to the RT distributions were superior to
those of the race model, as is evidenced by the much
smaller X2 and insignificant Kolmogorov-Smirnoff statistics. To directly compare the two models and the appropriate and inappropriate fits, the RMS was calculated
for each fit. To calculate the RMS, the X2 statistics for
the RT distributions were added to three X2 statistics
measuring the fits to the accuracies across the three
deadlines (an additional six degrees offreedom). The resulting X2 variable was divided by the number of data
TWO RESPONSE TIME MODELS
Parameter Values and X2 Statistics for the Fit of the Appropriate
Diffusion Model to Each Participant's (P) Data from Experiment 1
Note-Significance levels are calculated with 15 degrees offreedom for the blocked
condition and 16 degrees of freedom for the mixed condition. Deadlines (Dead) are
given in milliseconds.
tp < .001.
points fit (60 deciles plus 6 accuracies) minus the total
number of parameters (which varied according to the
model fit). The square root of this statistic is the RMS.
The RMS is an ordinal lack offit measure that can be
used to distinguish between nested, nonnested, or misspecified models . The model with the smallest RMS is selected as
the best fitting. It penalizes each model by the number of
parameters required, because the value of the RMS increases as the number of parameters increases. If a
model fits perfectly, the RMS will equal zero. On average, ifthe X2 statistic is used for the RMS, the RMS should
equal I. Notice also that, by entering the response probabilities into the overall X2 calculations for the race and
diffusion models, the diffusion model has been severely
penalized for its inability to fit the accuracies. The RMSs
are shown in Table 5 for each model, fit to each participant and each condition. Ifa model predicts an accuracy
of I for a particular condition, the X2 statistic will be either 0 (if no errors were made) or infinite (if any errors
at all were made). In the latter situation, the RMS is given
by an asterisk, indicating a number too large to compute.
This situation arose only for the race model; although the
diffusion model predicted very high accuracies, it did
not usually predict perfect accuracy. The race model predicted perfect accuracy when the "incorrect" accumulation rates were very small.
The critical comparisons to be made are between the
appropriate and the inappropriate models and between
the race model and the diffusion model. The lowest constrained RMS is in boldface font. The diffusion model,
penalized for poor fits to accuracy, did not yield RMSs
as low as those ofthe race model. For Participants I and
2, the appropriate race model gives the lowest RMS for
both mixed and blocked conditions. For Participant 3, the
inappropriate race model gave the lowest RMS. However,
the differences between the two RMSs was very small
(1.46 vs. 1.37 for the blocked condition and 1.28 vs. 1.27
for the mixed condition) and well within one standard error (.0951 vs..0988 for the blocked condition and .0919
vs..0988 for the mixed condition).3 Therefore, it is safe
to conclude that, for the race model, the appropriate fits
were as good as or better than the inappropriate fits for all
the participants. This was also the case for the diffusion
model; although the inappropriate fits yielded slightly
smaller RMSs in the blocked condition, they were very
close to the RMSs for the appropriate fits. Disregarding
the poor fits to the accuracies for the diffusion model,
both models performed quite well in terms ofaccounting
for the RT data by way of changes in the appropriate parameters. Most important, the race model performed at
least as well as the diffusion model.
Experiment 2
In Experiment 2, the conditions were such that, if any
accumulation process was responsible for the participants' performance, the participants should adjust thresholds depending on the probability of same or different
stimulus pairs. For the race model, the same threshold
should decrease as the probability of a same stimulus
increases, and this decrease may be offset by a corresponding increase in the different threshold. For the diffusion
model, the starting point z should move toward the upper
boundary a as the probability of a same stimulus increases, and this movement may be accompanied by an
overall increase in a, resulting in a greater difference between a and the lower boundary O. For both models, the
changes in the threshold and boundary parameters should
VAN ZANDT, COLONIUS, AND PROCTOR
be reversed as the probability of a different stimulus increases. As for Experiment I, the appropriate models are
those that are rate constrained. Rate should not need to vary
across experimental conditions to account for the data.
The Race Model
Response time distributions. Unconstrained, appropriate, and inappropriate fits ofthe race model are shown
for one typical participant (Participant I) in Figure 8.
Unlike the race model fits from Experiment 1, these
fits are poor, for both the appropriate and the inappropriate fits.
The best-fitting parameters and X2 statistics for the appropriate fits are presented in Table 6. The parameters
change in sensible ways across the three bias conditions:
The correct accumulation rates are larger than the incorrect accumulation rates, and the same thresholds decrease
as the proportion of same pairs increases. At the same
time, the different thresholds increase as the proportion
ofsame pairs increases. The parameters recovered from
unconstrained and inappropriate fits do not vary in sensible ways (see Appendix B).
For all three bias conditions combined, the X2 values
are not as small as those obtained for the fits in Experiment I (see Table 2). All the combined statistics are significant at a p < .00I level. In Table 7 are presented the
Kolmogorov-Smirnoff statistics for the differences between the observed and the theoretical distributions. Although both the appropriate and the inappropriate fits were
poor, as is indicated by a large number of significant
Kolmogorov-Smirnoff statistics, the appropriate model
managed to fit more distributions than did the inappropriate model. Likelihood ratio tests showed that the constrained fits accounted for significantly less variance
than did the unconstrained fits.
Means and accuracies. The parameters recoveredfrom
the fits to the distribution functions were used to calculate the predicted mean correct and incorrect RTs and accuracies. These predicted means were plotted against the
observed means, and the result is shown in Figure 9. As
in Experiment I, the correct RTs are fit very well. Also,
there is a tendency, as in Experiment I, for the model to
predict incorrect RTs that are slower than the data. Unlike Experiment I, the model had some trouble recovering the accuracies. Although the appropriate model predicted the different accuracies well, as is shown by the
open diamonds on the plot, the same accuracies were not
fit well at all. The unconstrained and inappropriate fits
could not recover the accuracy data.
Observed Probability
Observed Incorrect RT (in s)
.75 ""--_--'__--1.__---'--__--'-_------'
0.3 ""--_....L-_---'--_-----''-----_...L-_--'-_--'
6- Inappropriate
o Same - Appropriate
o Different - Appropriate
• Unconstrained
Observed Correct RT (in s)
Figure 7. Predicted probability of a correct response (top
panel), mean correct response times (RTs; middle panel), and
mean incorrect RTs (lower panel) of the unconstrained, appropriate, and inappropriate diffusion models (dots, open squares
and diamonds, and open triangles, respectively) versus the observed probability, mean correct RTs, and mean incorrect RTs
for each participant, deadline, and condition of Experiment 1.
The Diffusion Model
Response time distributions. Unconstrained, appropriate, and inappropriate fits of the diffusion model are
shown for Participant I in Figure 10. As for the race model
fits, the fits are not as good for either of the constrained
models as they were in Experiment 1.
TWO RESPONSE TIME MODELS
Root-Mean Squared Statistics for Each Model Fit to
Each Participant's (P) Data in Experiments 1,2, and 3
and Also for Each Model Fit to Each Simulation
Race Model
Diffusion Model
Experiment
Simulations
Note-An asterisk indicates a number too large to be computed. Vnc, unconstrained;
App, appropriate; Inapp, inappropriate; B, blocked; M, mixed.
The best-fitting parameters and X2 statistics for the
appropriate diffusion model are presented in Table 8 for
all the participants. With constant drift rates, the boundary a remains relatively constant across conditions, and
z steadily approaches a as same bias increases. The X2
statistics indicate significant differences overall for all
the participants (see Table 2), although the individual fits
to Participant 2's data did not show any significant differences. The Kolmogorov-Smirnoffstatistics in Table 7
indicate poor fits of the model for Participant 3 and for
Participant I's same responses under different bias, which
can easily be seen in Figure 10. Likelihood ratio tests
showed that the constrained fits accounted for significantly less variance than did the unconstrained fits.
Means and accuracies. The recovered parameters were
used to calculate the predicted mean correct and incorrect RTs and accuracies. The predicted means were plotted against the observed means, and the result is shown
in Figure II. The mean correct RTs are fit well by all three
models, except for the slowest mean RTs, where the model
predicts that they should be slower than they are. Unlike
previous fits, the correlation between the predicted and
the observed incorrect RTs for all models is low (r = .46).
As in Experiment I, the diffusion model fails to predict
the accuracy data.
Comparing the Race and the Diffusion Models
Unlike Experiment I, both the race model and the diffusion model failed to fit the data in significant ways, even
when all the parameters were free to vary. One aspect of
the data, not apparent in Figure 8 or 10, that seemed to contribute to this failure was the fact that the RT distributions
crossed. For each participant in several conditions, one
distribution from one condition (say, 20% same) would initially be greater than another (say, 50% same), but later
the other distribution (50% same) would be greater. Some
numerical investigations ofthe race and diffusion models
suggest that the conditions under which crossovers can be
predicted are fairly limited, although it appears that both
can predict crossovers by using reasonable parameter values . For example,
for the rate-constrained race model, with rates ofA.ss = 36
and A.so = 4, ifthe thresholds for one condition are K s =
2 and Ko = 6 and for another condition K s = 4 and Ko =
2, the distributions for correct same RTs will cross. However, because the model was required to fit six distributions
simultaneously, the parameters may not have been able to
vary in ways that couldcapture these crossovers.
The participants may have changed both rates and bias
across the three conditions. Such changes would have provided the flexibility needed to produce crossovers. (Generally, the unconstrained fits ofthe models produced the
observed crossovers.) By necessity, the bias conditions
were blocked, and the experiment took several days to
complete, which would have allowed for such broad parameter changes. Ratcliff fit the diffusion model
to perceptual matching data collected under conditions
of bias induced by changing instructions, and his fits
also required changes in both rates and thresholds across
conditions. One reason, then, why the models could not
fit the data well when all the parameters were free to vary
is that the data were formed from a mixture ofseveral sets
of parameters, used across blocks and days. Van Zandt
and Ratcliff have examined the behavior ofvari-
VAN ZANDT, COLONIUS, AND PROCTOR
.. Unconstrained
-Appropriate
---Inappropriate
Figure 8. Predicted densities ofthe unconstrained, appropriate, and inappropriate race models (dotted, solid, and dashed lines,
respectively) and the observed densities (open symbols) for Participant 1 for each bias condition in Experiment 2. Correct different response times (RTs) are presented on the left, and correct same RTs are presented on the right.
able parameters on RT distributions and have shown that
the resulting data need not look at all like the distributions
predicted by the process that actually generated the data.
It is possible that, in the present case, a diffusion or a race
was indeed responsible for producing the data but that
parameter variability is obscuring the fits ofthe models.
To compare the fits ofthe constrained and the unconstrained models, as well as the fits of the race and the
diffusion models, the RMS was calculated as in Experiment 1. The RMS statistics are shown in Table 5. Although the statistics are somewhat larger for these data
than for those of Experiment I, the smallest RMSs are
comparable. The appropriate race model performed best
for Participants I and 2, and the appropriate diffusion
model performed best for Participant 3. The fact that these
models showed the smallest lack of fit indicates that for
Parameter Values and X2 Statistics ofthe Appropriate Race Model
for Each Participant (P) in Each Bias Condition of Experiment 2
Note-Significance levels are calculated with 14 degrees offreedom for each level of
*p < .00I.
TWO RESPONSE TIME MODELS
Kolmogorov-Smimoff Statistics and Significance Levels for the Unconstrained (Unc),
Appropriate Rate-Constrained (App), and Inappropriate Bias-Constrained (Inapp)
Race and Diffusion Model Fits for Each Participant (P) in Experiment 2
Race Model
Diffusion Model
Note-Significance levels are calculated from the sample sizes (N) and the critical values Dos = 1.36/VN
and DOl = 1.63/VN.
tp < .0 I.
both the race and the diffusion models, the parameters
need to change in sensible ways to best account for the
data. The race model gave the smallest lack offit for 2 of
3 participants, indicating again that the race model is
doing as well as or better than the diffusion model for
these data.
Experiment 3
In Experiment 3, the conditions were such that, if any
accumulation process was responsible for the participants'
performance, correct accumulation or drift rates should
decrease as the elements ofthe stimulus pairs move away
from the fixation point. For the race model, incorrect accumulation rates should also increase as stimulus width
increases. The critical models for these data are those
that are bias constrained. Bias should not need to vary
across experimental conditions to account for the data.
The Race Model
Response time distributions. Unconstrained, appropriate, and inappropriate fits ofthe race model are shown
for one typical participant (Participant 6) in Figure 12.
All three race models fit the data well, and it is difficult
to distinguish between the curves on each graph.
The best-fitting parameters and X2 statistics for the
appropriate fits are presented in Table 9. With thresholds
held constant, the correct accumulation rates decreased
as stimulus width increased. The incorrect accumulation
rates either changed very little or increased as stimulus
width increased. Furthermore, the different thresholds
Ko were larger than the same thresholds Ks. This is consistent with Krueger's noisy operator theory; because noise tends to make stimuli appear different, the
different threshold must be elevated to prevent fast, erroneous different responses. As in previous fits, most of
the X2 statistics are signaling significantly poor fits. However, the Kolmogorov-Smirnoffstatistics (see Table 10)
show few differences between the observed and the theoretical distribution functions, with the exception ofParticipant 4. Most ofthe likelihood ratio tests indicated that
the appropriate and inappropriate fits accounted for significantly less variance than did the unconstrained fits.
Means and accuracies. The parameters recovered
from the fits to the distribution functions were used to
calculate the predicted mean correct and incorrect RTs and
accuracies. These predicted means were plotted against
the observed means, and the result is shown in Figure 13.
As in the previous experiments, the correct RTs are fit
very well by all the models. However, the mean incorrect
RTs are not predicted by any ofthe models; there is no correlation between the predicted and the observed mean incorrect RTs (r = .00). As in Experiment 1, but not Experiment 2, the accuracies are fit well by the unconstrained
and appropriate models. The inappropriate model failed
to predict accuracies well at all, producing accuracies all
along the range from 0 to 1.
The Diffusion Model
Response time distributions. Unconstrained, appropriate, and inappropriate fits of the diffusion model are
shown for Participant 6 in Figure 14. Each model fits well,
and it is difficult to discriminate between them. The bestfitting parameters and X2 statistics for the appropriate
fits are presented in Table 11. With the upper boundary
and starting point held constant, the drift rate parameters
for both the different and the same stimulus pairs decreased
VAN ZANDT, COLONIUS, AND PROCTOR
with increasing stimulus width. However, the X2 statistics
indicate significant failures ofthe model for almost every
fit, as well as overall (see Table 2). The Kolmogorov-
Smimoffstatistics, on the other hand, show that a few, but
not all, of the fits significantly failed. Likelihood ratio
tests showed that for Participants 2 and 5, the appropriate
and inappropriate fits accounted for significantly more
variance than did the unconstrained fits, but the fits for
all the other participants were worse when the models
were constrained.
Means and accuracies. The parameters recovered
from the fits to the distribution functions were used to calculate the predicted mean correct and incorrect RTs and
accuracies. These predicted means were plotted against
the observed means, and the result is shown in Figure 15.
The correct RTs are fit well by all the models, including
the rate-constrained model. As for the race model, there
is little correlation between the predicted and the observed
incorrect RTs for all the models (r = .25). As in all the
previous fits, the diffusion model fails to predict the accuracy data.
Comparing the Race and the Diffusion Models
In the fits ofthe race and diffusion models to the data
from Experiments I and 2, fits were better when parameters were appropriately constrained than when they
were inappropriately constrained. This was not the case
for all the participants in Experiment 3. The RMS statistic was calculated for each model, and these are shown
in Table 5. The RMSs were smaller overall for the race
model than for the diffusion model for each participant.
Although the appropriate race model performed best for
Participants 1,2, and 3, the inappropriate race model performed best for Participants 4,5, and 6. However, the inappropriate race model could not predict the accuracy
data, whereas the appropriate model did quite well in this
respect. This is indicated by the rather large RMSs for
the inappropriate model for Participants 4, 5, and 6, as
compared with the smaller RMSs for the appropriate
model for Participants 1,2, and 3.
For the diffusion model, the fits actually seemed to improve under the inappropriate model, as is demonstrated
by the smaller X2 statistics, fewer significant deviations
as indicated by the Kolmogorov-Smimoff statistics, and
smaller RMSs. As in all the previous fits, the diffusion
model failed to predict the accuracy data.
Observed Probability
D. Inappropriate
o Same - Appropriate
<> Different - Appropriate
• Unconstrained
Observed Correct RT (in s)
In three experiments, conditions were varied so that,
in Experiments 1 and 2, the models should be fit well
through changes in bias parameters alone, whereas in
Experiment 3, the models should be fit well through
changes in the rate parameters alone. In Experiment 1,
the rate-constrained race model fit the data from all 3 participants in the mixed and blocked conditions well. In
Experiment 2, none of the models achieved satisfactory
Observed Incorrect RT (in s)
0.3 1<:-_...L.-_---L_---l__..L-_-'-_--'
Figure 9. Predicted probability of a correct response (top
panel), mean correct response times (RTs; middle panel), and
mean incorrect RTs (lower panel) of the unconstrained, appropriate, and inappropriate race models (dots, open squares and
diamonds, and open triangles, respectively) versus the observed
probability, mean correct RTs, and mean incorrect RTs for each
participant and bias condition of Experiment 2.
TWO RESPONSE TIME MODELS
10 r-~---""----'----~--____'''''-----'
10 ,...-.....,...----,----,-----,-----.-----,
....... Unconstrained
-Appropriate
---Inappropriate
o'-....L----'~L-----'----.2Ildliiiiil....__---.J
10 r-~--____,;__---.----__,_--__r----,
ol.-.-'-----<lIIIL--'-----...:!I!IiII
10 r-~--____,;__---.----__,_--____,;__-__,
0l.-.-'--"~...J----'-----..:::!!!!3ilclll
10 r-~--__,,...----,-----,---__r------,
OL--L-_...4L-_--'-~_IIiIIIIl_._....._--.J
10 ,...-__,_--____,----,---.....,...----,--__,
o'-...........L-L-_......::..:~-
Figure 10. Predicted densities ofthe unconstrained, appropriate, and inappropriate diffusion models (dotted, solid, and dashed
lines, respectively) and the observed densities (open symbols) for Participant 1 for each bias condition in Experiment 2. Correct
different RTs are presented on the left, and correct same RTs are presented on the right.
fits, suggesting either that the models were inappropriate or that changes in strategies across blocks oftrials resulted in a mixture ofprocesses with different parameter
values. Despite the poor fits, the models that allowed for
changes in bias gave smaller lack-of-fit measures than
did the models that allowed for changes in rates. For Experiment 3, the data from halfofthe participants were fit
best by the appropriate race model, and those from the
other half were fit best by the inappropriate race model.
However, the inappropriate model failed to predict the
accuracy data. The diffusion models did not give lackof-fit measures as small as those given by the race models, except for Participant 3 in Experiment 2.
The purpose of these fits was to demonstrate that the
race model can fit RT data from a choice RT task as well
as the diffusion model can. Overall, with the exception
ofthe data from Experiment 2, the two models fit the RT
distributions well through variations in parameters that
Parameter Values and X2 Statistics of the Appropriate Diffusion Model
for Each Participant (P) in Each Bias Condition of Experiment 2
Note-Significance levels are calculated with 14 degrees of freedom for each level of
lp < .001.
VAN ZANDT, COLONIUS, AND PROCTOR
were generally appropriate to the experimental conditions. However, only the race model was able to fit the RTs
from three conditions in each experiment simultaneously
with the accuracies from those conditions.
To determine more precisely the quality of the fits
for the different models, it is important to know what the
fits would look like when the models are correct or incorrect. For instance, what appears to be a lack of fit of
one of the models in a particular condition may, in fact,
be an expected deviation for that model. If, say, fits of a
race model to data derived from a race fail to accommodate error RTs, owing to small sample sizes or to chance,
the failure of the race model to fit error RTs in the data
from these experiments should be discounted. Furthermore, it is important to determine, by fitting the diffusion model to data produced by a diffusion, whether the
inability of the diffusion model to fit the accuracy data
is due to the specific procedures used to fit the model or,
even worse, an error in the complex routines that calculate probability and the distribution functions. To answer
these questions, the four models examined above (rateand bias-constrained race and diffusion models) were
simulated, and observations were collected in three "conditions" designed to produce changes in mean RT and accuracy comparable with those obtained in the present experiments. The empirical distributions were estimated in
exactly the same way as those for the experimental data,
and the four models were fit back to the data from the four
simulations, using exactly the same procedures as those described above.
SIMULATION STUDIES
Observed Probability
Observed Correct RT (in s)
0.3 "'-------'-------'------'-----'---------'
Inappropriate
o Same - Appropriate
o Different - Appropriate
• Unconstrained
Observed Incorrect RT (in s)
Figure 1I. Predicted probability of correct response (top
panel), mean correct response times (RTs; middle panel), and
mean incorrect RTs (lower panel) of the unconstrained, appropriate, and inappropriate diffusion models (dots, open squares
and diamonds, and open triangles, respectively) versus the observed probability, mean correct RTs, and mean incorrect RTs
for each participant, deadline, and condition of Experiment 2.
Four questions have been raised that will be answered
in this section. The first involves the accuracy ofthe fitting routines. Because the objective function did not have
any ofthe nice properties that guarantee unbiased and minimum variance parameter estimates, we needed to verify
that we could, in fact, recover accurate parameters. The
second question involves the diffusion model's surprising
inability to account for the accuracies in the three experiments. By fitting the diffusion model to race and diffusion data, we can verify both that the diffusion model can
fit RTs and accuracies simultaneously when it is the correct model and also that when it is fit to the wrong model,
its failure to fit RTs and accuracies simultaneously is diagnostic ofa general failure ofthe model. The third question deals with the goodness-of-fit statistics we have
used. OfX2 , Kolmogorov-Smirnoff, and RMS, we need
to determine which, if any, accurately reflect good and
bad fits. We would like for our goodness-of-fit statistic
to diagnose a good fit when the right model is fit to the
data and a bad fit when the wrong model is fit to the data.
Finally, we need to know the extent to which the race
model is able to fit data from a diffusion process, and vice
versa. The extent to which we can distinguish between
TWO RESPONSE TIME MODELS
....... Unconstrained
-Appropriate
---Inappropriate
Figure 12. Predicted densities ofthe unconstrained, appropriate, and inappropriate race models (dotted, solid, and dashed
lines, respectively) and the observed quantiles (open symbols) for Participant 6 for each stimulus condition in Experiment 3.
Correct different response times (RTs) are presented on the left, and correct same RTs are presented on the right.
them determines how hard we should try to verify that
one or the other is true.
Two race and two diffusion models were simulated in
three conditions. The bias parameters ofone race and one
diffusion model increased across conditions, and the rate
parameters of the other race and diffusion models decreased across conditions. The parameter values used for
the bias- and rate-constrained simulations are shown in
Tables 12A and 128. For each condition, 800 trials were
performed, resulting in sample sizes that were comparable with those obtained from each participant in Experiment I. These four simulations should be viewed as data
from four different experiments. Two ofthe experiments
(I and 3) required shifts in thresholds, and the other two
(2 and 4) required shifts in rates across conditions.
For the rate-constrained models, accuracy and RT increased as "condition" increased. This is comparable
with the effects observed with an increasing response
deadline in Experiment I. For the bias-constrained models, accuracy decreased with increasing RTs as condition
increased. This is similar to the effects observed in Experiment 3 as stimulus width increased. The bias-constrained
diffusion model had RTs that were much longer and variable than any observed in the experiments and any observed for the other models (see Figure 19). This is a result of the parameters that were chosen for this model.
This difference is important because it will provide a
challenge for the other models to fit.
Unconstrained, rate-constrained, and bias-constrained
fits of the race model and the diffusion model to each
simulation are presented in Figures 16-19. Each figure
shows the fits of the six models to one simulation. The
rate-constrained and bias-constrained race simulations are
presented in Figures 16 and 17, respectively, and the rateconstrained and bias-constrained diffusion simulations
are presented in Figures 18 and 19, respectively. Panel A
ofeach figure shows the fits ofthe race models to the dif
ferent and same responses, and panel B shows the fits of
the diffusion models to the different and same responses.
Fits ofthe appropriate and inappropriate models are shown
as solid and dashed lines, respectively. The unconstrained
fits are shown as dotted lines.
From Figures 16 and 17, it appears that both the appropriate rate-constrained and the inappropriate biasconstrained race models fit the data from the rateconstrained race simulations well. The diffusion models
did not fit as well, although some of the fits are very
close. For the bias-constrained race simulations, the ap-
VAN ZANDT, COLONIUS, AND PROCTOR
Parameter Values and X2 Statistics of the Appropriate Race Model
for Each Participant (P) for Each Visual Angle of Experiment 3
Note-Significance levels are calculated with 13 degrees of freedom for each visual angle.
Ip < .001.
propriate bias-constrained race model fit, whereas the
inappropriate rate-constrained race model did not. When
the diffusion models were fit to the bias-constrained race
simulations, the inappropriate rate-constrained model fit
well, but not the appropriate bias-constrained model.
From Figures 18 and 19, it appears that for the rateconstrained diffusion simulations, only the appropriate
rate-constrained diffusion model fit well, although the
inappropriate bias-constrained race model did not do too
badly. For the bias-constrained diffusion simulations, the
appropriate bias-constrained and unconstrained race
model fits are poor. The shape ofthe fitted race model is
an exponential, in comparison with the nonmonotonic and
unimodal density ofthe diffusion model. Both the appropriate and the inappropriate diffusion models fit well.
Do the Fitting Routines Accurately Recover
the Parameters of the Model?
The best-fitting parameters recovered for the models
are given in Tables 13 and 14 for the race and diffusion
model fits, respectively. The parameters recovered for the
appropriate models are not exactly equal to those used
for the simulations, but they are quite close. This variation from the true parameter values occurs because the
model is trying to fit random fluctuations in the data and
succeeds. Because the models have only been fit to a single simulation, we cannot determine the degree or extent
of bias in the recovered parameters. However, it is clear
that the routines we used can find best-fitting parameters
that are very close to the true parameters for the race and
diffusion models.
Can the Diffusion Model Account for
Response Times and Accuracies Simultaneously?
The parameters given in Tables 13 and 14 were used
to compute the predicted accuracies and correct and incorrect RTs for the race and diffusion models. These predictions were plotted against the observed values, and
the results are shown in Figure 20. The figure shows the
predictions generated for the race and the diffusion
model fits in the left and right panels, respectively. Each
fit is identified by whether or not the model is correct
(e.g., race fit to race) or incorrect (e.g., race fit to diffusion) and appropriate (e.g., rate-constrained fit to rateconstrained) or inappropriate (e.g., rate-constrained fit
to bias-constrained). So, for example, the points marked
by circles (incorrect, inappropriate) on the left panel
show the predictions of the rate-constrained and biasconstrained race models for the bias-constrained and
rate-constrained diffusion data, respectively. The open
circles in the right panel mark the corresponding predictions of the diffusion model for the race data.
The critical plot is in the upper right. The most important thing to note from this figure is the fits of the correct, appropriate diffusion model to the diffusion data
(diamonds). The diffusion fits recovered the accuracy simultaneously with the RT distributions. Furthermore,
the incorrect fits ofthe diffusion models (circles and triangles) to the race data produced predicted accuracies
that were near 1for every fit ofthe diffusion model to the
race data. The inappropriate diffusion model (squares) also
had trouble accounting for accuracy. Therefore, we can
conclude that the diffusion model is able to account for
RTs and accuracies simultaneously and that its failure to
do so for our experiments is indicative ofa more general
failure of the diffusion model for these matching data.
The recovered parameters were also used to compute
the predicted mean correct and incorrect RTs, and these
are plotted against the observed mean correct and incorrect RTs. For the race and diffusion model fits in the center left and right panels, the mean correct RTs were recovered well for all simulations. However, both the race
TWO RESPONSE TIME MODELS
Kolmogorov-Smirnoff Statistics and Significance Levels for the Unconstrained (Unc),
Appropriate Bias-Constrained (App), and Inappropriate Rate-Constrained (Inapp)
Race and Diffusion Model Fits for Each Participant (P) in Experiment 3
Race Model
Diffusion Model
Note-Significance levels are calculated from the sample sizes (N) and the critical values D 05 = 1.36/VN
and DOl = 1.63/VN.
and the diffusion fits tended to underestimate slow mean
incorrect RTs from the diffusion simulation, regardless
of whether or not they were fit by the diffusion model.
This finding suggests two things. First, the fitting procedure cannot necessarily recover the mean incorrect RTs,
even when the model is exactly right. Second, because
the models consistently overestimated the incorrect RTs
from the experimental data, the fast incorrect RTs observed in the experiments may be due to a different process, such as fast guessing, rather than to a misspecified
accumulator model.
Which Goodness-of-Fit Statistics
Accurately Diagnose the Correct Model?
The overall X2 statistics for each fit are given in Table 2,
and the Kolmogorov-Smirnoff statistics are given in
Table IS. The X2 statistics generally mirror the results
obtained by looking at Figures 16-19. According to the
X2 statistics, when a correct and appropriate model was
fit to the simulated data, it fit well. However, other fits
were also good. The unconstrained race and diffusion
models seemed to fit all four simulations well. The inappropriate bias-constrained race model fit the rateconstrained race simulation (I), and the inappropriate
rate-constrained race model fit the bias-constrained race
simulation (2). The incorrect bias-constrained race model
also fit the bias-constrained diffusion simulation (4).
The rate-constrained diffusion model fit all four simulations well, and the inappropriate (and incorrect) biasconstrained diffusion model fit the rate-constrained race
well. Likelihood ratio tests were performed for these fits
in the same way as for the experimental data. In general,
only when the correct model was fit to the simulated data
was there no significant decrement in fit for the constrained models. The other fits (with the exception ofthat
of the rate-constrained diffusion model to the biasconstrained race simulation) showed significantly less
variance accounted for by the constrained fits.
VAN ZANDT, COLONIUS, AND PROCTOR
....l..----l
Observed Correct RT (in s)
0.4 "'--..L...>""--_-'--_--'-_-'-_--'-_----I._--'
Observed Incorrect RT (in s)
The X2 statistics do not generally distinguish between
correct and incorrect fits, although all the significant X2
statistics were associated with incorrect or inappropriate
models (a perfect correct rejection rate). Examining the
Kolmogorov-Smirnoff statistics next leads to very similar conclusions as those for the X2 statistics. However,
the KolmogoTOv-Smirnoff statistics show that the biasconstrained diffusion model had significant problems fitting the rate-constrained race simulation. Also, the rateconstrained diffusion model had slight difficulty fitting
the rate-constrained race simulation.
The X2 and Kolmogorov-Smirnoffgoodness-of-fit statistics are consistent but ambiguous. The rate-constrained
race model is well fit by three ofthe four models (not considering the unconstrained fits); the bias-constrained race
model is well fit by two ofthe models; the rate-constrained
diffusion simulation is well fit only by the rate-constrained
diffusion model; and the bias-constrained diffusion model
is well fit by three of the models. Fortunately, the RMS
statistic (Table 5) clears the situation up a bit. For the race
simulations (1 and 2), it is clear that the best-fitting model
for each is the appropriately constrained race model.
Similarly, the best-fitting model for the rate-constrained
diffusion simulation (3) is the rate-constrained diffusion
modeL The bias-constrained diffusion simulation (4) is fit
best by the bias-constrained diffusion model, although the
bias-constrained race model also has a very low (one standard error's difference) RMS. In examining the density
functions produced by the race model, however, it is clear
that the fits are poor; the bias-constrained race model is
an exponential density that fits the tails quite well but
cannot accommodate the leading edge of the curve.
In sum, the X2 and Kolmogorov-Smirnoffstatistics were
very similar, although the Kolmogorov-Smirnoff detected some differences that the X2 did not. (Note that the
Kolmogorov-Smirnoff test does not suffer from lack -of
power in this case, because the parameters ofthe models
are known.) Usually the X2 statistic tends to reject models that are correct, especially when the sample sizes are
large, rather than fail to reject inappropriate models. Van
Zandt (in press-a) examined the behavior of the X2 statistic for a large number of simulated fits of different
models, including the diffusion and the race models. She
showed that, for fits to the distributions from a single experimental condition, the diffusion model yielded significant (p < .05) X2 statistics between 7% and 11% of
the time (for sample sizes between 500 and 1,000), and
the race model yielded significant X2 statistics between
45% and 49% ofthe time. Our results are not as bad, because the models were constrained by three experimental conditions. This allowed for far more accurate parameter estimation (especially for the race model) than
can be obtained from a single condition.
The best diagnostic of fit is the RMS statistic. The
smallest RMS statistic for each fit was given by the correct fit. In the one situation in which the RMS statistic
f:::, Inappropriate
o Same - Appropriate
o Different - Appropriate
• Unconstrained
Q)... 0.45
f:::,f:::,
f:::,f:::,f:::, f:::, f:::,
f:::,f:::,
Observed Probability
Figure 13. Predicted probability of a correct response (top
panel), mean correct response times (RTs; middle panel), and
mean incorrect RTs Oower panel) of the unconstrained, appropriate, and inappropriate race models (dots, open squares and
diamonds, and open triangles, respectively) versus the observed
probability, mean correct RTs, and mean incorrect RTs for each
participant and stimulus condition of Experiment 3.
TWO RESPONSE TIME MODELS
....... Unconstrained
-Approprtate
---lnappropr1ate
Figure 14. Predicted densities of the unconstrained, appropriate, and inappropriate diffusion models (dotted, solid, and
dashed lines, respectively) and the observed quantiles (open symbols) for Participant 6 for each stimulus condition in Experiment 3. Correct different response times (RTs) are presented on the left, and correct same RTs are presented on the right.
could be argued to be ambiguous, the alternative model
was clearly wrong. The RMS statistic took into account
the simultaneous fit to accuracy and RT, and so the poor
recovery ofaccuracy data by inappropriate models helped
distinguish between the fits.
expected to fit both the RT and the accuracy data simultaneously, and goodness of fit was penalized to the extent that the models failed to do this. The information
provided by these criteria, together with an application of
the principle of correspondent change, uniquely identifies the correct model for each simulation.
To What Extent Can the Race Model
Mimic the Diffusion Model and Vice Versa?
As we have noted, there is some potential ambiguity
between the race and the diffusion models. When all the
parameters are free to vary, the race model can mimic the
diffusion model, and vice versa. Examining the density
functions, it appears that the rate- and bias-constrained
diffusion models can mimic the rate- and bias-constrained
race models (Figures 16B and 17B) and that the biasconstrained race model can mimic the rate-constrained
diffusion model (Figure 18A). However, we have demonstrated that we can disambiguate between these models by considering a number of sources of information
simultaneously. First, the models were fit to a number of
experimental conditions, and the parameters ofthe models were constrained by those conditions. Second, a
number of different goodness-of-fit statistics were used
to discriminate among the fits. Third, the models were
GENERAL DISCUSSION
The race model and the diffusion model were compared
across three experiments. In the experiments, the participants performed a perceptual matching task under a
number of conditions designed to influence particular
parameters ofeach model. In Experiment I, same and different responses were made under three deadlines, which
should have induced the participants to change response
thresholds. In one condition, the different deadlines were
presented within the same block of trials, which should
have prevented the participants from changing response
thresholds. In Experiment 2, the probabilities ofsame and
different stimulus pairs varied across blocks of trials,
which also should have induced the participants to change
response thresholds. In Experiment 3, stimulus pairs
were presented at one ofthree angles ofseparation, which
VAN ZANDT, COLONIUS, AND PROCTOR
Parameter Values and X2 Statistics of the Appropriate Diffusion Model
for Each Participant (P) for Each Visual Angle of Experiment 3
Note--Significance levels are calculated with 14 degrees of freedom for each visual
tp < .001.
should have changed the rates at which information could
accumulate toward alternative responses.
Both the race and the diffusion models fit the RT data
for Experiment 1. Most important, the fits ofthe models
to the data when the rates were constrained across the
three deadline conditions were good and were at least as
good as the fits ofthe model when the rates were allowed
to vary. When deadlines were intermixed within blocks
oftrials, a single set ofparameters successfully fit all six
RT distributions across the three deadlines. When the fits
to accuracy and distributions were considered together,
the (appropriate) rate-constrained race model fit the data
best. The diffusion model, because it could not predict
the accuracy data, did not fit the data as well as did the
race model.
Both the race and the diffusion models fit the RT data
well for Experiment 3. Most important, for most of the
participants, the fits ofthe models to the RT distributions
were better when the rates varied across stimulus conditions than when response thresholds varied. When the
fits to accuracy and distributions were considered together, the data from halfofthe participants were fit better when rates were constrained and thresholds varied.
This was because the fits were penalized by the models'
inability to fit accuracy. Overall, the race model fit the
data better than the diffusion model, again because ofthe
diffusion model's problems with the accuracy data.
Neither model fit the RT data well for Experiment 2.
Part ofthe problem with these data may be the fact that the
RT distributions (for the same responses) crossed in different conditions. Neither model seemed able to predict
crossed RT distributions with the constraints imposed on
the parameters. One possible reason for the models' failure with these data is the fact that the different bias conditions were presented in different blocks of trials. This
could have allowed the participants to engage different
strategies under different conditions, resulting in a mixture of processes with different parameters across conditions. Such a mixture also could result solely as a consequence ofthe differing numbers ofsame and different trial
repetitions across the blocks, since the repetition ofevents
(such as the complete repetition ofa same pair or the repetition of a same response) likely contributes to changes
in accumulation rates across trials (see, e.g., Hommel,
I998}-a process similar to priming. Consistent with this
notion, fits were poor when either the threshold or the rate
parameters were held constant but improved when both
were free to vary. Despite the poorer fits ofthe constrained
models, the appropriate models showed smaller lack-offit statistics than did the inappropriate models.
To get a better idea ofthe ways in which the models fail
and to determine how flexible the models are, a simulation
study was conducted. The two models were simulated
under conditions that mimicked those of Experiments I
and 3. The threshold parameters varied for conditions in
Experiment I, and the rate parameters varied for conditions in Experiment 3. The race models, when fit to the
simulated race data, recovered the original parameters of
the simulation fairly accurately. The rate-constrained race
model fit only the simulated rate-constrained race data.
The bias-constrained race model not only fit the simulated
race data, but also seemed to fit the bias-constrained diffusion simulation. However, even though the goodnessof-fit statistics were small, close inspection ofthe densities showed that the race model failed to fit the diffusion
simulation.
TWO RESPONSE TIME MODELS
Parameter Values Used to Simulate the
Rate-Constrained and Bias-Constrained Race and Model
The appropriate diffusion models fit the simulated diffusion RTs well, and fairly accurate parameters were recovered. The rate-constrained diffusion model fit even the
simulated race RTs, whereas the bias-constrained diffusion fit model only the simulated bias-constrained diffusion RTs. Therefore, the models are quite flexible; for
example, the diffusion model can account for RTs simulated by a race model if the parameters of the diffusion
model are allowed to vary. Similarly, the race model can
account for RTs simulated by a diffusion model ifthe parameters are allowed to vary. However, when the fits are
attempted over a number ofexperimental conditions, the
extent of the models' flexibility decreases. Accounting
for both RT and accuracy also raised problems for misspecified models.
A striking feature of the fits to the data from the experiments was the inability ofthe diffusion model to account for both RT and accuracy. The misspecified models
in the simulation studies also failed to recover the accuracy. The major purpose ofthe simulation studies was to
determine that accurate parameters could be recovered
for these models and that the fits ofthe models could reproduce the simulated RTs and accuracies. Therefore,
the inability of the diffusion model to recover the accuracies observed in the experiments was not due to any of
the routines or algorithms we chose to fit the models.
This suggests that the diffusion model may not be appropriate for our matching data.
The purpose of the present study was to demonstrate
that the race model should be given consideration equal
to that for the diffusion model. By showing that the race
model can fit RT and accuracy data at least as well as the
diffusion model and that the race model can do so by appropriate changes in bias and rate parameters, we have
accomplished this goal.
Observed Probability
Observed Correct RT (in s)
6. Inappropriate
o Same - Appropriate
o Different - Appropriate
• Unconstrained
.6 "'--------'-----'--------'-------'
0.4 "'--------'-------'-------'.-----'
0.75 ,--,....------,---,-......,-A:-..A---,---"
0.4 "'---='---'----'-----'-----'----'------'
Observed Incorrect RT (in s)
Parameter Values Used to Simulate the
Rate-Constrained and Bias-Constrained Diffusion Model
Figure 15. Predicted probabilityofa correct response (top panel),
mean correct response times (RTs; middle panel), and mean incorrect RTs (lower panel) ofthe unconstrained, appropriate, and
inappropriate diffusion models (dots, open squares and diamonds, and open triangles, respectively) versus the observed
probability, mean correct RTs, and mean incorrect RTs for each
participant and stimulus condition of Experiment 3.
Diffusion/rate
Diffusion/bias
VAN ZANDT, COLONIUS, AND PROCTOR
Condition 1
... Unconstrained
-Appropriate
---Inappropriate
Condition 2
Condition 2
Condition 3
Condition 3
Condition 1
Unconstrained
-Appropriate
---Inappropriate
Condition 2
Condition 2
Condition 3
Condition 3
Figure 16. Predicted densities ofthe unconstrained, appropriate, and inappropriate race (A) and diffusion (B) models (dotted, solid, and dashed lines, respectively) and the observed densities (open symbols) for the simulation ofthe rate-constrained
race model. Correct difj'erent response times (RTs) are presented on the left, and correct same RTs are presented on the right.
TWO RESPONSE TIME MODELS
Condition 1
Condition 1
...... Unconstrained
-Appmpriate
---Inappropriete
Condition 2
Condition 2
Condition 3
Condition 3
Condition 1
Condition 1
. Unconstrained
-Appropriate
---Inappropriate
Condition 2
Condition 2
Condition 3
Condition 3
Figure 17. Predicted densities ofthe unconstrained, appropriate, and inappropriate race (A) and diffusion (8) models (dotted, solid, and dashed lines, respectively) and the observed densities (open symbols) for the simulation ofthe bias-constrained
race model. Correct different response times (RTs) are presented on the left, and correct same RTs are presented on the
VAN ZANDT, COLONIUS, AND PROCTOR
Parameter Values and X2 Statistics of the Unconstrained, Rate-, and
Bias-Constrained Race Model Fits to Each Condition for Each Simulation
Unconstrained
Diffusion/rate
Diffusion/bias
Rate constrained
{ 112.62:1:
Diffusion/rate
Diffusion/bias
{ 156.48:1:
Bias constrained
Diffusion/rate
{ 77.67:1:
Diffusion/bias
Note-Significance levels for unconstrained fits are calculated with 11 degrees offreedom for each condition.
For rate-constrained fits, there are 14 degrees of freedom for each condition, and for bias-constrained fits,
there are 13 degrees of freedom for each condition.
tp < .001.
Is There a "Correct" Model?
An obvious question that could be asked at this point
is whether these results indicate that the race model or
the diffusion model is more appropriate for these data.
That is, is one model true and the other false? Both models are very powerful and can accommodate a wide range
of data. Both models fit the data from several experimental conditions with appropriate changes in parameters. It could be argued that the mechanisms underlying
both models are used in different circumstances. The diffusion model with upper and lower response boundaries
is mathematically equivalent to a race between two correlated diffusions with single response boundaries. One
possibility is that observers can switch between a strategy ofmonitoring the difference between two counters (a
random walk or diffusion process) and one of monitoring the absolute levels of each counter (a race process),
depending on the task requirements or the capacity available to perform the task.
One reason why this question cannot be answered at
present is that both ofthe models fit the RT data to a statistically acceptable level (in different conditions), and
trying to distinguish between them on the basis ofgoodness offit puts too heavy an emphasis on statistical analyses in the model-selection process. As was clearly discussed by Roberts and Pashler (in press), the fact that a
model can be made to fit a set of data is not strong evidence for that model. Demonstrating that a model fits
data does not show what the model cannot do, says nothing about whether the variability ofthe data would allow
the model to be ruled out, and does not show whether the
model could have fit a different pattern of data. Furthermore, the fact that one model can be fit to the data does
not exclude the possibility that other, quite different
TWO RESPONSE TIME MODELS
.... Unconstrained
-Appropriate
---Inappropriate
Condition 1
7.--."....----,--...;..--,.----.---..---.........--,
Condition 1
Lj~1·t.--_--L__.:::::I~..
-...L...--.J-..J
7r-,.---y---,.----..:--.r::..:....--r-----.---,---,
Condition 2
Condition 2
Condition 3
Condition 3
B7r-.--,...---r----r=.:....---.----,----r-,
.... Unconstrained
-Appropriate
---Inappropriate
Condition 2
Condition 1
0l...Jil..'____'___~~..
'____.......J
7r-"T""--r----.,.--.....---r-----,----.----,
7r-"T""--r-----,--.....---r-----,.-----r---,
Condition 2
Condition 1
Condition 3
7.---"T""--r----.,.--.....---.,..----,---.---,
Condition 3
Figure 18. Predicted densities of the unconstrained, appropriate, and inappropriate race (A) and diffusion (B) models (dotted, solid, and dashed lines, respectively) and the observed densities (open symbols) for the simulation ofthe rat~onstrained
diffusion model. Correct dijferent response times (RTs) are presented on the left, and correctsame RTs are presented on the right.
VAN ZANDT, COLONIUS, AND PROCTOR
... Unconstrained
-Appropriate
---Inappropriete
Condition 1
3r----.----~..__---.,.----,------,
3,------r---r-----r------r--
Condition 1
Condition 2
----'___=='1':.~:::I::3C=t...£¢..,;¢L<l.__J
3.--------r----.....,----,-----,...--.......,
Condition 2
Condition 3
a U"~/¢:J'L--'-
----'__-==~~~~-~-~¢~¢~¢!..!.¢.J¢
Condition 3
Unconstrained
-Appropriate
---Inappropriate
Condition 1
3,..---.,.---....:..;.==-------,,------.--.......,
3.----,------,---.:....:.::..:.-....----~-___.
Condition 1
Condition 2
Condition 2
a L..L_-'-
-=-r.~:::!:~=t...£o..,;¢L· .<W:.J
Condition 3
Condition 3
o Ul.JL_....L.
-'-....:......:....:::..-.::L0::......:o'---"o~
a L....::.LL_--'-
.:....:....:o:..,:¢::..2.
0 ,2.o..2jo
Figure 19. Predicted densities ofthe unconstrained, appropriate, and inappropriate race (A) and diffusion (B) models (dotted, solid, and dashed lines, respectively) and the observed densities (open symbols) for the simulation ofthe bias-eonstrained
diffusion model. Correct different response times (RTs) are presented on the left, and correct same RTs are presented on the
TWO RESPONSE TIME MODELS
Parameter Values and X2 Statistics ofthe Unconstrained, Rate-, and
Bias-Constrained Diffusion Model for Each Simulation in Each Condition
Unconstrained
Diffusion/rate
Diffusion/bias
Rate constrained
Diffuse/rate
Diffuse/bias
Bias/constrained
Diffusion/rate U
Diffusion/bias n
Note-Significance levels for unconstrained fits are calculated with 12 degrees of
freedom for each condition, and for rate- and bias-constrained fits there are 14 degrees
of freedom for each condition.
tp < .001.
models could also be fit to the same data . One way to distinguish between models
is by setting up experimental conditions in which one
model predicts a different pattern ofresults than does another and collecting data. Several theoretical findings
 suggest, however, that it may be difficult or impossible to find experimental conditions by which to distinguish between the race and random walk classes of
Therefore, it may be inappropriate to ask which model
is correct. Both models form frameworks within which
hypotheses about response selection mechanisms can be
devised and tested. In this capacity, both models allow
for a clarity of certain ideas and predictions that verbal
theorizing alone cannot. Ifeither ofthe models is as powerful and wide-reaching as the other, the reasons for selecting one over the other mustcome down to ease ofuse.
On this basis, the race model is clearly superior to the diffusion process. The expressions for fitting and simulating the race model are far more tractable than those of
the diffusion model, even ifthe drift parameter ofthe diffusion is a constant rather than a normally distributed random variable. It was much easier to fit and simulate the
race models than it was to fit and simulate the diffusion
It may be possible to distinguish between the two types
ofmodels on the basis ofother data, such as response confidence judgments or double responses, where the observer attempts
to "undo" the already executed response by executing the
other response . For the race
model, both response confidence and the execution of a
VAN ZANDT, COLONIUS, AND PROCTOR
Diffusion Fits
Observed Probability
Observed Probability
Observed Correct RT (in s)
Observed Correct RT (in s)
Observed Incorrect RT (in s)
Observed Incorrect RT (in s)
Correct Model
Incorrect Model
Inappropriate
Inappropriate
Appropriate
Appropriate
Unconstrained
Unconstrained
Figure 20. Predicted probability of correct response (top panels), mean correct response times (RTs; middle panels),
and mean incorrect RTs (lower panels) ofthe unconstrained, rate-, and bias-constrained race and diffusion models versus the observed probability, mean correct RTs, and mean incorrect RTs for each simulation. The race model data are
shown in the left panels, and the diffusion model data are shown In the right panels. Fits ofthe race model to the race data
or of the diffusion model to the diffusion data are plotted as open squares, diamonds, and solid dots, and fits of the diffusion model to the race data or of the race model to the diffusion data are plotted as open circles, triangles, and dots.
Fits of a rate- or bias-constrained model to rate- or bias-constrained data are appropriate (open diamonds and triangles), but fits of a rate- or bias-constrained model to bias- or rate-constrained data are Inappropriate (open squares and
TWO RESPONSE TIME MODELS
Kolmogorov-Smimoff Statistics and Significance Levels for the Unconstrained (Unc),
Rate-, and Bias-Constrained Race and Diffusion Model Fits for Each Simulation
I. Race/rate
2. Race/bias
3. Diffusion/rate
4. Diffusion/bias
Note-Significance levels are calculated from the sample sizes (N) and the critical values Dos = 1.36/VN
and 0.01 = 1.63/VN.
double response are assumed to depend on the relative
difference between the levels of activation on the two
counters. If this difference is very small, response confidence will be small. Furthermore, ifthe system does not
shut down completely after one threshold is exceeded,
the likelihood of both counters exceeding their thresholds at nearly the same time will be high when the relative
difference between them is small, resulting in a double response. The random walk models cannot account for such
data without modification, because the relative difference between the perfectly correlated counters is always
the same on every response.
The race model has been criticized on several grounds,
one being how it handles error RTs, and the other being
the behavior of the model as thresholds are increased. It
is true that if the rates are equal for the two stimulus
types (same and different-i.e., ADD = Ass and ADS =
Aso), error RTs must always be slower than correct RTs
 . Because these conditions did not hold for the fits ofthe model
presented here, this criticism is unwarranted . Furthermore, as is shown in most ofthe
plots of observed versus predicted mean RT, there are
many predicted and observed mean incorrect RTs that are
less than the predicted and observed mean correct RTs.
It is also true that as the threshold increases for a particular counter, more and more exponential deviates are
added to the total response time. Therefore, the finishing
time for the counter tends to be normally distributed.
However, the observed RT is the minimum of two random variables that are, as both thresholds become large,
normally distributed. The minimum of two normals is
not normally distributed, even in the limit. The criticism
that the race model must predict normally distributed
RTs, therefore, is also unwarranted. But the minimum
distribution of two normal random variables does not
necessarily predict the extent of skewness observed in
the data. The skewness ofthe distribution depends on the
degree ofoverlap between the two distributions. Ifthe two
normal distributions are separated by several standard
deviations, the skew will be small, and the minimum distribution will take the shape of the normal distribution
with the smallest mean. Therefore, the race model may
have difficulty in the limit with skew. It may also be appropriate to assume that thresholds do not become very
large, because of capacity limitations or time pressure
when speed is an issue. Under this assumption, the normality problem will not arise.
What Happened to the Diffusion Model?
An unexpected problem arose with the fits ofthe diffusion model. Although the diffusion model fit the RT distributions very well, probably better than the race model
did, it could not simultaneously account for accuracy. This
is in contrast to other good fits of the diffusion model to
both RTs and accuracy . However, in other applications of the
diffusion model, rarely have any goodness-of-fit criteria
VAN ZANDT, COLONIUS, AND PROCTOR
been applied to the RT fits. It is possible that in these other
applications, ifthe X2 or Kolmogorov- Smirnoffstatistics
were computed, they would show significant failures of
the diffusion model to fit the RTs. Fits by eye, showing that
the predicted and the observed curves are generally consistent with each other, do not guarantee that significant differences do not exist between the curves. Therefore, this
project is one ofthe first times that such measurements have
been taken ofthe diffusion model .
It is also possible that the diffusion model simply has trouble with perceptual matching data. The conditions of the
task may be such that the race process was the best way to
characterize task performance, perhaps because ofthe simultaneous presentation ofthe elements ofthe pair or the
fact that only two elements were compared, rather than a
more complicated letter string. Empirical work is required
to determine whether this is the case.
One handicap faced by the diffusion model is that it
had fewer parameters than did the race model. The drift
coefficient was held constant at S2 = 0.1 because, for a
single distribution, it is unobservable. The drift coefficient scales all the other parameters, so that for any s2, a
set ofparameters can be found that leave the distribution
unchanged. However, the ratio oftwo drift coefficients is
observable, and so we might have allowed the ratio ofcoefficients to vary across conditions. Because ofthe added
complexity that this would have implied for our fits, we
did not attempt this.
The fact that no parameters could be found to fit the
diffusion model to both RTs and accuracies should not
necessarily be taken as an indication of its failure. Excellent fits may very well be possible with parameters that
were not found in these analyses. However, the fact that
such parameters were difficult to find may be attributed
to the complexity of the diffusion model. The diffusion
equations are quite complicated and unstable for various
time values. Allowing the drift rate to vary makes the
problem much worse, because each prediction then requires a numerical integration ofthe already complicated
expressions over all the possible drift rates. The race
model does not suffer from this problem, although rates
and thresholds for the model could, if theoretical concerns warranted, be allowed to vary as well.
It should be noted that the drift variance arises from a
theoretically motivated source, perceptual encoding, and
that, therefore, the diffusion model is more complete
than the race model. It provides an explanation for how
information is transformed into evidence toward alternative responses. The race model presented here does
not specify how information arrives from earlier stages.
However, a similar mechanism can be constructed for the
race model, resulting in variable accumulation rates (Van
Zandt, in press-b). For instance, suppose that noise in the
processing system tends to make stimulus pairs register
at least some difference, even when the members of the
pair are identical. The amount of difference to which a
pair gives rise is a random variable that depends on the pair
type. Ifthere is some total amount ofcapacity that can be
allocated to each counter, the number of perceived mismatches would determine how much of that capacity is
allocated to the different counter. The rest would be allocated to the same counter. On each trial, the amount of
capacity allocated to each counter is a random variable
determined by the number ofperceived mismatches. Although this mechanism could have been exploited in the
present project, it was not necessary to do so. The race
model already fit the data reasonably well, and the additional flexibility provided by varying rates (or thresholds) would only have made the fits better.
Conclusions
The relative merits of random walk and race model
representations have been debated. However, the results
of Townsend and Marley and Colonius 
have suggested that random walk models may have representations equivalent to those of independent race
models. Race models have not been studied as extensively as the diffusion models. This study demonstrates
that the race model is a viable model of response selection in a choice RT task, perceptual matching.
Race models can predict RT and accuracy . The diffusion
model can also predict RT and accuracy, although it had
problems doing so in the present study. Both the race and
the diffusion models are most useful as frameworks within
which subtle aspects ofperformance can be investigated.
The calculations required to determine the predicted mean
RTs, accuracy, and the RT distributions from a random
walk or a diffusion model are considerably more complicated than those required for the race model. Eventually,
data may be found that the random walk or the diffusion
representation can describe but the race representation
cannot. Until then, the greater tractability ofthe race model
and its now-demonstrated ability to produce the observed patterns ofaccuracy and RT suggest that the race
model may be a more useful representation of the response selection process than is the diffusion model, at
least in certain situations.